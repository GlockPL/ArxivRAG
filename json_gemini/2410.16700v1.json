{"title": "AskBeacon - Performing genomic data exchange and analytics with natural language", "authors": ["Anuradha Wickramarachchi", "Shakila Tonni", "Sonali Majumdar", "Sarvnaz Karimi", "Sulev K\u00f5ks", "Brendan Hosking", "Jordi Rambla", "Natalie A. Twine", "Yatish Jain", "Denis C. Bauer"], "abstract": "Enabling clinicians and researchers to directly interact with global genomic data resources by removing technological barriers is vital for medical genomics. AskBeacon enables Large Language Models to be applied to securely shared cohorts via the GA4GH Beacon protocol. By simply \u201casking\u201d Beacon, actionable insights can be gained, analyzed and made publication-ready.", "sections": [{"title": "Introduction", "content": "GA4GH (Global Alliance for Genomics and Health) introduced the Beacon protocol\u00b9 to standardise the exchange of genomic and phenotypic information. The underlying schema is designed for clinical and research use and enables industry-standard security and data governance practices. Beacon can jointly query genotypic and phenotypic data, with metadata information encoded through ontologies. However, empowering the community to perform these advanced queries requires a user-interface that can hide the underlying complexities, such as query combinations across collections (Cohorts and Datasets), entity types (Individuals, Biosamples, Runs, Analyses and Genomic variants) and return types (Records, Boolean, Counts), as well as translating medical or colloquial terminology to an ontology code, for example, SNOMED.\nWe developed AskBeacon to abstract the complexities of the Beacon schema using large language models (LLMs). AskBeacon is a web interface (Supplementary Section 1) on top of sBeacon\u00b2, a cloud-based production-ready implementation of the Beacon protocol. It acts as the interpreter between a clinical or research question and the Beacon schema-formatted query (Figure 1)."}, {"title": "Method", "content": "For example, using AskBeacon, clinicians and researchers can validate in their data whether the genetically determined sex differences in Parkinson's Disease 3 are due to X-linked (RPL104) or autosomal (SNCA5) genetic factors. Using natural language, users can perform currently expert-only steps such as, a) translating \u201cParkinson's disease\u201d to an ontology code, b) identifying individuals in the cohort with the relevant genotypes c) constructing the right query to obtain the data, and d) analysing the data using custom scripts to visualize the results.\nAskBeacon can query across federated repositories in the global Beacon Network', where each node can be stood up securely and efficiently using an implementation of the Beacon protocols, like sBeacon. This enables even small clinical and research groups, e.g. from underrepresented populations, to share genomic data and enable the secure, fully consented, and controlled query across human genetic diversity (Supplementary Section 2)."}, {"title": "Modular use of LLM to keep pace with innovation", "content": "AskBeacon is methodology agnostic, enabling new LLMs to be added as they become available. Here, we tested the chat facility of currently available open (Ollama10, HuggingFace\u00b9\u00b9) and commercial or closed-weighted models (OpenAI models GPT3.512 and GPT 413, Anthropic model Claude 3.514), as well as two different architectures (parallel and multi-step) for extracting the necessary information to populate a valid Beacon query (Supplementary Section 3). Specifically, we tested the individual components of a successful query, such as scope extraction, granularity extraction, variants extraction and filter extraction as well as query validity (Supplementary Section 4).\nThe parallel extraction approach was more resilient to network failures, incorrect inputs, partial inputs and malformed LLM, however it consumes more tokens compared to multi-step extractor.\nThe multi-step approach can instead pick the suitable next chain depending on previous input or terminate chains early resulting in lower token consumption. However, failures at any point can terminate the query without extracting any information (Supplementary Section 4). Parallel workflows better scale to future throughputs with the elevated token consumption offset by an expected decrease in cost.\nOverall, Gemma 2 was the most suitable open model for both parallel and multistep workflows (Supplementary Table 4.1 and 4.2) with average F1 scores of 0.92 and 0.81 for scope, granularity, variant, and filter extraction whereas GPT models were the most suitable commercial models with F1 scores of 0.91 and 0.81 respectively. Gemma 2's superior performance in parallel workflow may be due to its training on knowledge distillation rather than the next token prediction of GPT-415. Commercial models overall had greater performance than open-weight models, probably due to the larger model size and up-to-date knowledge of bioinformatics and genome beacons. We have also presented LLM specific analyses of performance in Supplementary Section 5."}, {"title": "Context management for building progressively complex interactions across multiple topics", "content": "AskBeacon manages chat histories to enable users to build on previous queries. These history objects contain the summary of a conversation, specifically the variants, filters, chosen scope and granularity. This enables AskBeacon to request additional information to generate a Beacon compliant query. As shown in Figure 1.3 the sBeacon User Interface (UI) allows the addition of multiple tabs so different queries can be maintained in parallel, enabling concurrent but independent querying."}, {"title": "AskBeacon keeps the human in the loop", "content": "AskBeacon keeps data extraction separate from data analysis to enable checkpointing from the human expert. All inferences are verified with the user to ensure elements such as ontology terms or genomic locations queried are aligned with the research question (Figure 1.2). Furthermore, the generated code for the data transformation and plotting is presented in an editor view to be amended by the users as needed (Figure 1.5). Following the execution of code, both standard output and error streams are made available to aid debugging and assist in code improvements (Supplementary Section 6)."}, {"title": "Security measures", "content": "The analysis and exchange of sensitive data demands strict guard-rails to prevent misuse, leakage or exploitation by malicious actors. While all LLM vendors assure data privacy and security contractually, AskBeacon augments this by keeping sBeacon as the conduit between the data and the LLM, so that data is never exposed to the LLM directly. sBeacon ensures the safety of underlying data through state-of-the-art data security, with user management adhering to GA4GH protocol guidelines. sBeacon also ensures that AskBeacon's data extractors operate at the same level of access as the active user, hence no data can be extracted through AskBeacon that the user does not already have access to. AskBeacon's analytics is protected by using static code analysis and sandboxing, preventing accidental exposure of source code, files or runtime variables. We also perform static code analysis before any code execution and remove code with adversarial effect."}, {"title": "Conclusion", "content": "We built AskBeacon to leverage the GA4GH's Beacon protocol by enabling genomic data analysis using natural language through LLMs across the global Beacon network. In the future, we will extend the conversation capability to combine data extraction and analytics task, while retaining our extensive human checkpointing. This will enable users to ask comparative questions between cohorts, with AskBeacon automatically choosing the best statistical and visualization method. Given that Beacon is a discovery tool, differences in return values need to be considered, e.g. while some beacons return individual genotypes others might return summary statistics that are incompatible with each other. This also extends to differences in ontologies. We will leverage efforts from the terminology community to translate between different dictionaries and develop principles for beacons to communicate across different abstraction levels."}]}