{"title": "Generative AI\u2019s aggregated knowledge versus web-based curated knowledge", "authors": ["Ted Selker", "Yunzi Wu"], "abstract": "This paper explores what kinds of questions are best served by the way generative AI (GenAI) using Large Language Models(LLMs) that aggregate and package knowledge, and when traditional curated web-sourced search results serve users better.\nAn experiment compared product searches using ChatGPT, Google search engine, or both helped us understand more about the compelling nature of generated responses. The experiment showed GenAI can speed up some explorations and decisions. We describe how search can deepen the testing of facts, logic, and context. We show where existing and emerging knowledge paradigms can help knowledge exploration in different ways.\nExperimenting with searches, our probes showed the value for curated web search provides for very specific, less popularly-known knowledge. GenAI excelled at bringing together knowledge for broad, relatively well-known topics. The value of curated and aggregated knowledge for different kinds of knowledge reflected in different user goals. We developed a taxonomy to distinguishing when users are best served by these two approaches.", "sections": [{"title": "STRUCTURE OF PAPER", "content": "This paper proceeds along the following arc. The introduction presents a descriptive context for knowledge recording and exploration.\nWe tested consumers in an experiment that involved a comparative car-buying exploration. This study included elements such as pre-test questionnaires, think-aloud protocols, and evaluations focusing on the time spent, the quantity and quality of alternatives considered, as well as post-test assessments.\nA comparison of paradigms also inbcluded hundreds of probe queries using Google search and ChatGPT. These probes led to the creation and testing of 12 knowledge seeking personas, each with differing needs. This effort aimed to provide a representative exploration of various user types. For each persona, we proposed a range of experiences designed to highlight the differences between search engines and Generative AI (GenAI) tools. We include emblematic portions of a few of these instructive probes in this paper.\nThe quality of results from both approaches not only helped us delineate important differences between the two paradigms but also shed light on varying online knowledge needs. The paper concludes by proposing new user interface values for these emerging paradigms, tailored to the cognitive needs for information absorption."}, {"title": "INTRODUCTION", "content": "People spend their lives collecting knowledge to create their understanding of topics and areas that matter to them. They consider the building blocks of existing solutions and sometimes imagine new ones they would like to try.\nArtificial Intelligence is a broad term that carries the implications of simulating human intelligence and has a history focused on computer reasoning, representation, and learning [15]. The Machine Learning (ML) component has become a powerhouse for useful classification work across various industries. Databases and early search engines relied on humans to manually classify knowledge [1, 6]. While today's search system classification still begins with human knowledge labeling, the most advanced ML technology layers deep structural connections to respond to complex queries [2].\nSearch connects keywords using Boolean operators and presents lists of solutions relevant to knowledge and opportunities related to these queries [10]. \"The search results draw from an Al representation of all curated knowledge on the internet. Some search technologies utilize AI to generate web pages that serve as sources of information, as opposed to 'official' sources. For instance, search results for a restaurant often present a page compiled by the search engine, which aggregates information about the restaurant rather than relying solely on the restaurant's own description. Should we trust the restaurant to describe itself accurately, or could an aggregation of various sources offer a more trustworthy account?\"\nA popular direction in AI involves training high dimensional predictive Transformer to form language solutions This approach leads to the creation of so-called Large Language Models(LLMs) [3, 5]. GenAI starts with human prompt questions, including human-defined information and presentation goals. The LLM based solutions aggregate and package it as a solution such as a story, poem, image, computer program, etc.[14].\nIn conversation, people are accustomed to not having all stories correct or complete. The value of discovering, evaluating, and expanding one's conceptions is best verified through traceable provenance. Whether in a street conversation or while viewing online information, source provenance must be made apparent to accumulate facts rather than rhetoric, thereby distinguishing reliable sources from fabricated stories. The search paradigm that has enabled us to find web information is valued for its ability to produce referenced responses."}, {"title": "An Evolution of Knowledge Tools", "content": "Technology has been aiding us in using language for a long time [3]. While we still use graphite pencils to make marks, printers have allowed writers to create copies for distribution or editing. Displays now enable writers to view and modify writing at will.\nStandardizing spelling and syntax made it easier for people to understand each other's writing. In 1604 Robert Cawdrey [7] standardized spelling in the first dictionary. Cut-and-paste and word completion features were introduced with Emacs, offering accuracy and flexibility in reorganizing thoughts.\nWord-completion pull-down menus became a sought-after feature to speed up typing in Japanese word processors. Computer spell check became a valuable tool in the late 1970s. \"Do What I Mean\" (DWIM) added the ability to search for syntactic context and consistency in the 1980s [4, 18].\nIn 1981, EPISTLE [11] was already using AI to improve authors' syntax [13]. Empathetic language responses were first demonstrated in the 1960s with Eliza [19]. Systems like HearsayII in the 1970s allowed people to play chess by talking to a computer [9]."}, {"title": "Knowledge Interaction Scenarios", "content": "Long before the introduction of GenAI, searching for results on the web was blurred. Search engines themselves reinterpret queries and produce results. Personal assistants like Siri also try to reduce questions from a person to an actionable query or action. We posed detailed questions to both the Alexa personal assistant and ChatGPT.\nWhen asked, \"What is a quark?\" both Alexa and ChatGPT give answers that seem to be condensed Wikipedia knowledge. Both of these platforms have limited corpora and knowledge bases compared to the web. Updating the indices of search systems is an up-to-the-second and ongoing comprehensive activity while updating GenAI systems is not yet as encompassing. While Both have models of discourse, ChatGPT also has a model of persuasion, generating plausible results and filling in gaps with fanciful ideas. Alexa lacks the GenAI capability of filling in gaps with likely- sounding responses, as people do in conversation. So far, Alexa and ChatGPT both feel less reliable than internet searches for different reasons. Alexa finds an answer, while GenAI may try to prioritize and package top answers."}, {"title": "New Scenarios for Knowledge Interaction", "content": "Search has changed the way we find, use, and acquire things. The multiple goals of search have shifted its focus from finding a perfect answer to a negotiated set of results that both the search engine and the user interact with. Early purpose-built search engines were limited to finding web pages. Today's search engines serve multiple goals, providing marketing results, sales results, website results, video results, scholarly results, how-to results, and AI website-produced omposite results. A menu bar on Chrome allows Google Chrome users to focus on shopping, images, videos, news, maps, books, flights, and finance. We have many goals in mind. The multifaceted goals of the search system mean that one searches and then finds themselves entangled in commercial opportunities that support the search business. A more specialized search engine might help us focus. Perhaps the search engine shouldn't be promoting a new outfit, toolkit, or vacation opportunity when one is searching for a story's veracity and provenance. The CEO of a large search engine company was asked why Yahoo was presenting a married man with ads for breast enhancement and dating services. They said he said, \"We tried to remove those ads, but the advertising opportunity generates a lot of revenue.\" Focusing these systems solely on users' goals will improve their reputation as well as productivity. With a subscription-based model, ChatGPT has so far avoided cluttering solutions with predatory results.\nStarting in the 1990s, we were part of a class that projected a screen with a stream of Google search results for everything said. It was done in a yes-and-instigating manner that added to the conversation. Now we have much better tools. Let's explore some scenarios and the value they can bring."}, {"title": "GenAl Can Feel Natural to Use", "content": "A few weeks after ChatGPT's initial release, we were amazed by a group of octogenarians discussing their use of the technology. One of them recited a competent poem that ChatGPT had written for them in iambic pentameter, using Shakespearean language to discuss a current topic on their minds."}, {"title": "Al Can Provide Entertainment", "content": "At a rain-forest resort in Sylhet, a group of people had asked ChatGPT to write a poem in the style of the most famous Bangladeshi poet. We watched in awe as of the groups sang it as a song in Bengali."}, {"title": "Al Can Generate Sophisticated Suggestions", "content": "We employed ChatGPT to author apologies for training examples about communication affect. Although the Al's suggestions became repetitive after a few sentences, they still helped people write training utterances almost 10 times faster.\nA writer consulted ChatGPT for insights into disruptions following the Spanish flu pandemic, aiming to draw comparisons with expected disruptions after the COVID-19 pandemic. Upon fact-checking, the writer found that some of the Al-generated ideas were spurious. However, many were useful and even inspired the writer to come up with additional ideas. As a result, the time taken to complete the periodical article was significantly reduced."}, {"title": "Knowledge exploration needs guidance", "content": "A friend asked ChatGPT about the best recording Shirley Temple made, and it said she never recorded. \"It's worth noting that Shirley Temple, despite her fame as a child actress in the 1930s, retired from acting at the age of 22 and did not release any songs during her career.\" This statement, of course, was incorrect. The follow-up question aimed to provide more information, and ChatGPT then contradicted itself by noting her many real recordings."}, {"title": "GenAI Can Create We can search online support services like Stack Overflow to help us learn from other's programming examples", "content": "On the other hand, GenAI is now compiling all known code with tools like Copilot, assisting people in programming. Users can specify algorithms, the programming language to be used, and the desired output to receive working programs. By critiquing the result, they can prompt Copilot to fix bugs, change the approach, or even port the program to another language within seconds. Still, customizing these examples can be an extensive task that requires articulating specific requests as questions. However, programming complex tasks by asking questions can feel like trying to drive a car from the back seat.\nWhile people are accustomed to conversation, search engines do not facilitate conversational or narrative interactions. When GenAI returns problematic responses and buggy programs, it initiates a conversation. One potential advantage of chat over search is that it encourages us to pause and evaluate the conversation. The clickbait nature of search tools may lead us to make hasty decisions without adequate consideration.\nWe can rely on chat systems for complete and organized responses, but people commonly state that (as with people) we can't trust them for truthfulness. Still, conversation may not be the most effective way to uncover facts or, to analyze and resolve bugs in a computer program. Critiquing and asking questions is different from creating. The critical inquiries of an art historian are not the creative acts of an artist.\nWe spend our lives communicating to learn and accomplish tasks. One challenge is to develop a repertoire of knowledge and communication tools that are both valuable and productive. The search paradigm has been transformative, making older internet tools like Archie, Veronica, and WAIS forgettable. It provides us with access to the world's knowledge.\nSearch serves various knowledge needs. While newer versions now aggregate information about specific enterprises, such as restaurants or other businesses, they typically focus on displaying multiple alternative links that could be followed. Finding information is different from synthesizing a solution. The search paradigm is not designed to build knowledge, critically analyze discourse, or formulate solutions. The ease of accessing various forms of knowledge is now enhanced by the corpus of all digitized information. The AI-generated aspect added to search engines today might seem helpful, but represents a different kind of information not curated by people. But how might we compare the curated knowledge access of search with the new GenAI paradigms?\nToday's search engines are expected to respond appropriately to a wide range of informational needs. They aim to differentiate and present results tailored to a person's needs in well under a second. However, achieving this level of precision is challenging without understanding the context, background, and objectives of the request.\nThe GenAI paradigm draws from a portion of the same online knowledge that is available to legacy search systems. A key question arises: Can the automatically-generated narratives, which bring together parts of many disparate sources of knowledge, compete with the precise knowledge we all curate to be accessed by search engines? This question involves not just the quality and appropriateness of the knowledge but also its digestibility. While we often believe that we'll recognize what we want when we see it, the reality may be more complex.\nThe search systems of the past 20 years have enabled us to access a vast array of publicly presented information. However, the importance of structurally-coherent stories often outweighs the significance of knowing where and how we found something. Recent work has focused on demonstrating that helping people understand which GenAI results can be trusted may improve their decision-making [16, 17]. We designed an experiment to see if the GenAI results might change the speed and way people make decisions.\nA consumer purchasing experiment was designed to demonstrate how the different paradigms worked for people who believed in and also for people who didn't believe in GenAI."}, {"title": "Consumer experiment method", "content": "The primary aim of our experiment is to examine how using both legacy and new knowledge exploration platforms effects on complex, knowledge-based user decisions, such as buying a car. The study seeks to contrast how knowledge gathered from the web via legacy search engines and newly introduced GenAI aids consumers in this process. What are the most and least effective aspects of these online information access paradigms?\nThe study hypothesizes that a GenAI tool offers a spectrum of choices and hypothetical solutions, although these may not always be actionable. A combination of chat and search functionalities contribute to generating more actionable solutions, even though users may sometimes lack a systematic approach. When relying solely on search engines, users often find it challenging to initiate the process and may become bogged down in details, even though the results are more specific.\nWe began by recruiting individuals who are contemplating buying a car shortly and who reside in the U.S. The experiment was designed to last approximately one hour.\nBefore the experiment, participants answered a questionnaire to gauge their familiarity with search engines and GenAI chatbots. The questionnaire also aimed to explore their decision-making approach when it comes to buying a car. Participants were required to complete three tasks. Task 1: Use only a search engine for information gathering. Task 2: Use only ChatGPT3.5 for the same purpose. Task 3: Use both ChatGPT3.5 and a search engine, in an order of their choosing. Each participant was tasked with researching a car purchase based on real-world scenarios and goals, such as finding the best car within a specific budget or comparing various car models while focusing on different lifestyle needs and preferences. They used Google search and ChatGPT3.5 tools to find several options, compare them, and narrow their choices down to two.\nWe employed screen recording, facial expressions, and verbal reactions to gain insights into their challenges, thought patterns, and decision-making processes. The task was designed to be ecologically valid as a realistic, complex task."}, {"title": "Response to the experiments", "content": "We included three sections in our consumer experiment: pre-survey, three tasks, and post-survey.\nIn our pre-survey, we asked two questions to understand the participants' car purchase history and habits, All had purchased at least one car and 60% said that they would buy a car based on the brand their family already owned, the other 40% rest would base it on what they found in a search.\nOur purchasing experiment included three tasks. For each task, we asked the same question: \"What might be different about using search or ChatGPT for finding cars?\" The reason we asked the same question was to compare the differences before, during, and after participants used ChatGPT3.5 for the search task.\nTask One: Use only Google search to find a car.\nParticipants opened a browser and used the Google search box to learn about cars that meet the following require- ments: a car suitable for an active lifestyle, that is safe, reliable, and also good for transporting kids.\nThey found several options, compared them, and identified differences. In the end, they narrowed their choices down to two .\nTask Two - Use only ChatGPT to find a car.\nParticipants used GenAI to find cars that meet the following requirements: suitable for an urban, luxury lifestyle, and good for transporting kids. They came across various alternatives  and assessed the distinctions between them. Finally, they settled on two final options .\nTask Three - Use Both Google search and GenAI to find a car.\nParticipants checked details about cars that met the criteria for a rural lifestyle, fuel efficiency, low maintenance costs, and suitability for transporting kids-using both Google search and ChatGPT. After discovering multiple options , they evaluated and distinguished the differences among them. Ultimately, they whittled their selections down to just two .\nEach participant's time spent on the task was documented ."}, {"title": "Interpretation of consumer experiment", "content": "Pre-survey findings. All participants had prior experience purchasing one or more vehicles. Participants were very focused on their preconceptions about different car brands and types. Even when viewing new information, they relied on their own research and familial car ownership when proposing a car purchase."}, {"title": "Consumer Experiment Observations", "content": "GenAI packages and organizes a spectrum of choices and hypothetical solutions, but these may not always be actionable.\nSupported: Participants found that ChatGPT offered a broad range of options but raised concerns about its accuracy. This suggests that while ChatGPT can generate a variety of choices, these may not always inspire action.\nA combination of chat and search functionalities helps in generating more actionable solutions.\nSupported: Participants who used both Google search and ChatGPT found that they could obtain a more comprehen- sive list of options. This suggests that the combination does indeed provide more actionable solutions.\nUsers may sometimes lack a systematic approach.\nPartially Supported: While the study doesn't directly address this, the feedback that ChatGPT helps in \"brainstorming and critical thinking\" suggests that users find the chat format helpful in structuring their approach.\nWhen relying solely on search engines, users often find it challenging to initiate the process and may get bogged down in details."}, {"title": "Evaluating search and GenAl results for 12 personas", "content": "Our first set of evaluations focused on exploring various approaches to knowledge exploration, leading us to create 12 distinct search information exploration personas. For each persona, we began with assumptions about the utility of both curated and aggregated knowledge. These assumptions were then tested through specific search scenarios to evaluate the effectiveness of different types of responses. Due to space limitations, we are unable to present all the scenario results or delve into the setup, data, and interpretation in detail within this paper. These additional insights are included in Appendices A and B.\nIn the following sections, we present the personas, hypotheses, the two most useful prompt topics, and our interpre- tations. Format of data format below:\n(1) Persona name hypothesis text\n\u2022 Topics: useful prompt topics.\n\u2022 Interpretation of if search or GenAI gave better results.\n(1) A Do It Yourself person describes an individual when they are attempting to fix or build things on their own, without professional expertise or tools. They often search for how-to guides or tutorials to solve problems without needing to consult an expert or enroll in a course. Such behavior presents monetary opportunities in the realms of education, materials, and services.\n\u2022 Topics 1. garden shed, 2. car not starting\n\u2022 Search included steps, images, and videos.\nPersona prompts best served by Search.\n(1) A recreational intellectual describes an individuals who seeks to stay updated in a particular field, even if they are unlikely to contribute original work to it. Their searches typically focus on well-known facts, whether trivial or more substantive. Since these intellectual pursuits are often undertaken for entertainment, search engines could also appropriately suggest related entertainment options, such as food and drink.\n\u2022 Topics 1. trivia, 2. cultures\n\u2022 Search tended to provide more complete knowledge.\n(2) A Do It Yourself person describes an individual when they are attempting to fix or build things on their own, without professional expertise or tools. They often search for how-to guides or tutorials to solve problems without needing to consult an expert or enroll in a course. Such behavior presents monetary opportunities in the realms of education, materials, and services.\n\u2022 Topics 1. garden shed, 2. car not starting\n\u2022 Search included steps, images, and videos.\n(3) A hobbyist applies to people who are actively participating in a specific nonprofessional interest, often in the company of others who share the same passion. These individuals frequently seek out communities and avenues"}, {"title": "A communicator describes individuals who are engaging in the process of scripting presentations", "content": "They assemble content with the intent to share, educate, or document information. GenAI is revolutionizing this domain with its innovative paradigm for creating such materials.\n\u2022 Topics 1. blog writing support, 2. writing a friendly manual for software\n\u2022 GenAI Chat supported user writing and style goals!"}, {"title": "Persona experiment discussion", "content": "The topics revealed several differences for what kinds of prompts were best served by search curated web knowledge and which were better served by packaged GenAI aggregated knowledge. An interesting finding is that while there are many knowledge needs that are better served with search there are huge benefits to GenAI for communicating ideas to people.\n\u2022 For very specific requests such as how to replace a fender-well in a 2010 Prius GenAI gave a generic list of steps and tools that weren't appropriate; search gave specific results with video demonstrations for our specific car. Note: We replaced a fender well in our driveway without a jack in under 30 minutes using a screwdriver, and a wrench the responses asked for but knew we needed things both online information systems had missed: several new clips and a knife to pop the tough old ones out.\n\u2022 Explorations for commonly-available information yielded similar results with the two approaches but GenAI will package it in a comprehensive form that is easy to scan.\n\u2022 As Maps is closely integrated with search systems, one might expect search to perform better with spatial responses. This was noted by the consumer above who was looking for a getaway. Still, the GenAI's ability to assemble responses from various sources gave excellent answers.\n\u2022 GenAI results were easier to look through as they presented in narrative form and didn't have the clutter of advertising and other search goals not intended in the question.\n\u2022 GenAI had the added advantage of showing a prioritization of results explicitly.\n\u2022 GenAI had the ability to continue to follow, expand and focus a question is demonstrated well in examples such as a student using it as a tutor.\n\u2022 GenAI results coming as a presentation is demonstrated well for a communicator whose result will be a presentation."}, {"title": "Why GenAl Appeals to Users", "content": "From calculators, interfaces like spreadsheets, and modeling systems, to query languages, digital assistants, bots, and search, computers answer our questions in various ways. Now, we are enamored with the ease of solving problems using GenAI. What are the key elements that make GenAI more accessible and appealing compared to other question-answering paradigms?\n\u2022 Is it because proposed solutions are easier to follow than a taxonomic list?\n\u2022 Do people take naturally to the output because it shows the confidence of a proponent presenting a solution?\n\u2022 Is it because it answers with proposed solutions, not facts?\n\u2022 Is it the way it adds in connective plausible ideas that give smooth transitions? Are these \"hallucinated\" fantasies plausible ideas useful for reinforcing known facts? In making things fit together, people also add such plausible but inaccurate ideas to connect facts to and get away with them in promoting a narrative.\n\u2022 Is it the output language of formulating various kinds of prose structure that mimics the kinds we are used to people producing?\n\u2022 Do people take naturally to the input because people are accustomed to discourse?\n\u2022 Is the output valued because a story, right or wrong, is how people learn and remember?\n\u2022 Is it the way it presents ideas with a persuasive stance that draws us in as any promoting stance does?\n\u2022 Is it because the query can refine a previous result to make it even more appropriate?\nAll these factors help make GenAI attractive to users. But people using these tools also note limitations. The average ChatGPT user recognizes that the tool does not know the source of its knowledge, but tempers that with follow-up questions to guide the system to refine the answer. GenAI informs with narrative, but the structure can come off as formulaic and recognizable. They might still see these responses as a gift of something in the form they will need to produce, presented as an example they might even use. The scenario seems to speak to cognitive processes we are all familiar with from working with people. The results are presented in standard paragraphs and story structures we are used to. People recognize the results as well-produced first drafts. GenAI might lead users to more fully consider results and use search more powerfully to get to solutions.\nThe Opportunities To Support People's Explorations and Expositions Are Vast. Ideas come from a deep knowledge of many areas. The knowledgeable person, like repositories of online information, has representational and analytic knowledge of what they are working on. The \"team\" consists of people and AI-based knowledge resources that will have a range of solutions with purposeful idea-development discussions.\nGenAI output responses being in specific coherent readable text softens incorrect responses with confident contextual style. With similar requests, today's GenAI makes lists that repeat or recognize style and structure."}, {"title": "CONCLUSION", "content": "This paper explores when search engines or GenAI systems better serve users' knowledge needs Our quantitative purchasing experiment found even sceptical participants valued GenAI's efficiency for gathering knowledge to putting a decision in context.\nOur qualitative comparison of 12 personas and knowledge gathering scenarios indicated that search engines can provide superior results for factual and niche knowledge.\nGenAI was more efficient and comprehensive for synthesizing perspectives in overviews or presentations. GenAI excels for questions requiring a verbal or media product to be created.\nIn both experiments, the paradigms showed complementary strengths of the two knowledge access paradigm's suiting different goals. Advancing verifiable generative workflows could augment knowledge-building by combining provenance from search with contextual perspectives from AI as Perplexity attempts to do [8]. While further research is needed, these findings suggest that integrating the unique advantages of search and GenAI could empower more robust knowledge exploration. Overall, this paper demonstrates the value each approach offers for varied user needs."}, {"title": "Broader uses of LLM AI", "content": "The last 20 years have shown the value of using keywords to access comprehensive knowledge sources. The value of these comprehensive data sources has changed the way we do everything, from play to work, to education, and to procurement.\nSearch systems now take on many goals, from creating website like results to promoting goods and services, and even helping with physical directions.\nUntil the current generation of GenAI, the work products we created with our knowledge seemed to be a different problem than finding the information. The value of a story to learn and remember is well known. GenAI also incorporates the context of recent requests in responses. Decisions are always made in contexts. While complex interfaces can be overwhelming, part of the user experience for GenAI might become deploying reasonable search goals in context. But real context has to be established by the writer; a GenAI story has to be put into one's own words to be yours and believable.\nThe acquisition of facts has become fraught. Fake facts are found not just in GenAI's hallucinations, but also in things people make up or repeat to support or create some strategic social or political movement. There used to be the idea that social media would help break down social barriers. It now seems that social media solving social problems was an early mirage. Fantasies are stories rooted enough in reality that people imagine and often hope they will become reality. More than hallucinations, GenAI creates fantasies. At least parts of fantasies are, or can become, reality. Without checking out what in fantasy is true or achievable, people can echo each other's fantasies in a spiral of confabulation.\nBut communication and knowledge are important."}, {"title": "COMMENT TO REVIEWERS", "content": "GenAI responses are changing and improving rapidly at the moment. We are willing fortify our experiment with more subjects using an updated ChatGPT if reviewers believe it is useful in the lead-up to publication."}, {"title": "Appendix A: Data from Taxonomy of Knowledge Exploration Persona", "content": "\u2022 Fact Checker\nSearch assumption: would provide the latest and most authoritative sources for the respective topics.\nChatGPT assumption: might mention global databases like NASA's Climate Change and Global Warming data and resources, or refer to historical sources for World War II.\nScenario 1: Sarah is a journalist preparing an article on climate change. She is looking for trustworthy data on global temperature changes. Her query might be: \"What are the authoritative sources of global temperature data over the past 50 years?\"\nSearch shows articles from Climate.gov, NOAA's report, NASA, and Work meteorological organization. Users can directly read related articles.\nChatGPT answers were more direct and focused\nScenario 2 Bob is an author whose writing a historical novel. He needs to verify some facts about World War II. He might ask: \"Can you provide sources on the number of casualties during World War II?\"\nSearch provides papers and articles which contain detailed graphics and data\nChatGPT default model: can't provide or cite sources in real-time, but gives an estimation.\nChatGPT web browsing model(Beta) recommended the Wikipedia page Scientist Search This would provide the latest publications and active researchers in the respective fields.\nChatGPT It may provide general information on who is considered a leader in the field and notable studies until its last update. Scenario\nScenario 1Dr. Johnson is researching gene therapy. He wants to stay updated on the latest findings. He might ask: \"Who are the leading researchers in gene therapy and what are their recent publications?\" Search It offered more articles that allow use to pick what they want to read\nChatGPT ChatGPT 4 web browsing model provided a few new projects of a top cell and gene therapy company. ChatGPT aggregated three articles and generated them for user to read.\nScenario 2 Lisa is studying astrophysics and needs to validate her thesis on black holes. She might ask: \"What are the most recent studies on the formation of black holes?\"\nSearch VS. ChatGPT gave relative similar results because ChatGPT4 web browsing model grabbed the first articles of Bing\n\u2022 Recreational Intellectual\nSearch assumption: Could provide detailed and up-to-date information on these topics.\nChatGPT assumption: It might provide interesting facts about the solar system or Japanese customs based on the data it was trained on.\nScenario 1 Tom is a trivia enthusiast preparing for a quiz night. He might ask: \"Can you provide me with interesting facts about the solar system?\"\nSearch VS. ChatGPT As a topic with a large amount of data, the knowledge provided by search and ChatGPT is similar As a topic with a larger amount of resources, the knowledge provided by Search and ChatGPT is similar\nScenario 2Jane enjoys learning about different cultures. She might ask: \"What are some unique customs and traditions in Japan?\"\nSearch The search article has a more comprehensive knowledge introduction on this subject, it presents a wide range of areas, such as greeting, entering houses, food, festivals, and arts.\nChatGPT Had a more concise and focused direction\n\u2022 Do It Yourself (DIY) Person\nSearch assumption:Could yield detailed guides, videos, or forums discussing these issues.\nChatGPT assumption: May provide a general step-by-step guide on building a garden shed or possible reasons why a car won't start.\nScenario 1 Anna wants to build a garden shed. She could ask: \"How do I build a garden shed and what materials do I need?\"\nSearch The articles include steps, images, and videos, Search is much better than ChatGPT in terms of DIY.\nChatGPT Provide detailed steps, along with suggestions, such as general size, type recommendations, etc\nScenario 2 Peter's car won't start, he wants to try fixing it himself. He might ask: \"What are the common reasons a car won't start?\"\nSearch VS. ChatGPT gave similar answers. They provides common problems about the question.\n\u2022 Hobbyist\nSearch assumption: It offers updated information, recent discussions, and newer platforms or locations\nChatGPT assumption: Might suggest places to find stamp collectors online, or popular bird-watching locations in North America based on pre-existing knowledge.\nScenario 1 Richard is a stamp collector. He might ask: \"Where can I find other stamp collectors to share my collection with?\"\nSearch shares more details about collectors and suggestions, and provides videos. In this scenario, Google search will be better ChatGPT introduces multiple channels and parsing\nScenario 2 Emily loves bird-watching. She might ask: \"What are the best locations for bird-watching in North America?\"\nSearch The problem triggered Google's traveling mode, which provides features such as plane prices, accommodations, maps, and more\nChatGPT 4's web browsing model crawls the first article on the search page to provide 10 articles suitable for bird watching\n\u2022 Merchant\nSearch assumption:offers the most recent trends, market analyses, and potential customer demographics.\nChatGPT assumption: It could mention general trends or consumer behaviors based on data up to 2021.\nScenario 1 Lucy owns a boutique clothing store. She might ask: \"What are the upcoming fashion trends in fall 2023?\" Search matched with the assumption. It provides the visualized answer.\nChatGPT 4 web browning model gave some good recommendations. But it is not as good as Google search.\nScenario 2 Jack sells handmade wooden furniture. He could ask: \"Who are my potential customers for handmade furniture and where can I find them?\" Search The search provides a glance at guidance,, frequently asked questions, as well as videos\nChatGPT 4 divides this problem into two parts. On the one hand, it provides professional categories, such as homeowner, interior designers, business, antique collector, etc., and then provides corresponding ways to find customers according to these categories. This way is much clearer and more compliant.\n\u2022 Constructor\nSearch assumption:might offer the latest advancements, techniques, and best practices."}, {"title": "Take-home messages", "content": "Chat aggregated references making them easier to look through. Search gave broader results. Search gave specific examples to explore. Search gave better visualizations for spatial information. Specialized websites have presentation advantages. Web visual results again had advantages. Similar for common topics. Search shows specific results for specific opportunities, ChatGPT prioritizes results without the bias of advertising for skill improvement goals. Search is better for viewing results a lot of media or specific results are relevant. Search was able to give videos. For common topics they were alike. ChatGPT gave comprehensive results that helped. As a tutor Chat allowed followup questions that really help. Chat responds in the form that the user is requesting content."}]}