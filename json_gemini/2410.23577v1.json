{"title": "MS-Glance: Non-semantic context vectors and the applications in supervising image reconstruction", "authors": ["Ziqi Gao", "Wendi Yang", "Yujia Li", "Lei Xing", "S. Kevin Zhou"], "abstract": "Non-semantic context information is crucial for visual recognition, as the human visual perception system first uses global statistics to process scenes rapidly before identifying specific objects. However, while semantic information is increasingly incorporated into computer vision tasks such as image reconstruction, non-semantic information, such as global spatial structures, is often overlooked. To bridge the gap, we propose a biologically informed non-semantic context descriptor, MS-Glance, along with the Glance Index Measure for comparing two images. A Global Glance vector is formulated by randomly retrieving pixels based on a perception-driven rule from an image to form a vector representing non-semantic global context, while a local Glance vector is a flattened local image window, mimicking a zoom-in observation. The Glance Index is defined as the inner product of two standardized sets of Glance vectors. We evaluate the effectiveness of incorporating Glance supervision in two reconstruction tasks: image fitting with implicit neural representation (INR) and undersampled MRI reconstruction. Extensive experimental results show that MS-Glance outperforms existing image restoration losses across both natural and medical images. The code is available at https://github.com/Z7Gao/MSGlance.", "sections": [{"title": "1. Introduction", "content": "In recent years, research in computer vision (CV) has increasingly incorporated global semantic information, inspired by the human visual perception process [23] where understanding is driven by high-level semantic cues rather than focusing on individual pixels. For example, the Vision Transformer (ViT) [11], a prominent neural network architecture, captures long-range dependencies within an image and generates powerful feature representations through vision-language pretraining [60]. In the field of image reconstruction, advanced models have also achieved success in incorporating semantic information. For instance, in super-resolution, architectures such as U-Net utilize multiple layers of convolutional and downsampling operations to progressively extract high-level semantic information [25,61,80]. Besides, in undersampled MRI reconstruction, some researchers utilize semantic segmentation networks to assist in the reconstruction process [14,28,55].\nHowever, in human vision, semantic conception [67] is not the only way to portray the recognition; it can also be interpreted as a reconstruction procedure of the scene that doesn't involve semantic understanding [48,49,54,63]. A pioneering study [54] shows that human vision gleans a large amount of meaningful information from a single glance. Several experimental studies followed [49,63], suggesting that recognition of the real world may start from encoding global configuration since no perception of individual objects or detailed features can be made in such a short time. A representative computational model, Spatial Envelope [48], models the structure of real-world scenes by a set of perceptual properties including naturalness, openness, roughness, ruggedness, and expansion. Further, Michelle Greene et al. [19] experimentally shows that statistical and structural cues extracted from very brief (e.g. 19 ms and masked) exposures allow for above-chance categorization of scenes, verifying the Spatial Envelope model and the existence of a reconstruction-based recognition.\nCurrent image reconstruction algorithms primarily focus on pixel-wise similarity or high-level semantic information, often overlooking non-semantic, statistical, and structural information. Although Structural Similarity Index Measure (SSIM) [73] is widely used for evaluating image quality, it only captures local information from neighboring pixels without accounting for structural information from distant pixels. On the other hand, S3IM [75] improves SSIM in the application of novel view synthesis with Neural Radiance Field (NeRF) [45] by applying SSIM to random patches. However, the Gaussian-kernel-based computation of SSIM assumes weighting the central pixels while suppressing the edge pixels, limiting its ability to represent global context, as global context does not inherently focus on the center.\nTo bridge this gap, we propose Multi-Scale Glance (MS-Glance), a novel non-semantic descriptor of image context, inspired by the human recognition process that bypasses the semantic concept. MS-Glance includes local and global Glance vectors. A global Glance vector is formulated by randomly retrieving pixels from an image with an explicit rule and a local Glance vector is formed by flattening a local window of an image. Given two Glance vectors, their Glance Index is the inner product between two sets of standardized Glance vectors. Since MS-Glance is a descriptor of image context, it can be seamlessly integrated into existing image reconstruction models as a plug-and-play component, enhancing the quality of the reconstructed images.\nWe show the applicability of MS-Glance loss in two scenarios: image fitting with implicit neural representation (INR) and supervised undersampled MRI reconstruction with DRDN [85]. For image fitting, we training SIREN [64], a neural representation capable of modeling signals with fine details, with MS-Glance loss. Using MS-Glance leads to the best SIREN representation ability on datasets of common objects, human faces, and MRI brain scans. For undersampled MRI reconstruction, we propose a novel air prior that allows rule-based pixel selection for MS-Glance. Experiments are conducted on two public datasets, IXI and FastMRI, encompassing various MRI acquisition scenarios and different organs. Extensive experimental results demonstrate that incorporating Glance not only enhances the performance of existing models but also improves image reconstruction quality for both natural and medical images.\nThe contributions of this work are as follows. First, we propose a biologically inspired non-semantic context descriptor, MS-Glance, along with the Glance Index Measure and Glance loss specifically designed for image comparison. Second, we demonstrate its ability to improve learned image representation through INR image fitting. Third, we apply it to training undersampled MRI reconstruction networks, showcasing its utility in image restoration tasks. Additionally, we introduce a novel perception prior, MRI air prior, and incorporate it with the construction of MS-Glance vectors for MRI reconstruction. Finally, extensive experiments on a wide range of datasets show that the MS-Glance loss outperforms existing loss functions used in image restoration, such as L1+SSIM [69] and LPIPS [17]."}, {"title": "2. Related work", "content": "2.1. Image non-semantic information\nWhile semantic information has been extensively utilized in various computer vision tasks, research on non-semantic information of images, such as structural and layout features, remains limited. Cao et al. [1] introduced the concept of Non-Semantic Facial Parts (NSFP), which identifies the most discriminative patches for face recognition and retrieval. However, their method relies on predefined features like SIFT, limiting the performance. Murrugarra et al. [46] proposed non-semantic transfer from attributes that may belong to different domains, but focuses solely on texture, which is only a small subset of non-semantic information. In autonomous driving, Anas et al. [3] represented point clouds with non-semantic features for environment interpretation, localization, and mapping; yet their work is specific to point clouds rather than images. In NeRF, Xie et al. [75] applied SSIM on reorganized random image patches. Still, their work is also application-specific and relies on the original pixel-based SSIM computation with a local focus center.\n2.2. Image reconstruction\nImage reconstruction [29, 69, 78] in CV refers to the task of recovering or restoring an image from incomplete, corrupted, or undersampled data. Here, we primarily introduce two image reconstruction tasks: Implicit Neural Representation (INR) and undersampled MRI reconstruction.\n2.2.1 Implicit Neural Representation (INR)\nINR parameterizes a given discrete image f in a continuous fashion. The image defines a dataset\n$D = \\{(x_i, f(x_i)); f : R^2 \\rightarrow R^3\\}$"}, {"title": "3. Method", "content": "In this section, we formulate a novel non-semantic image descriptor of image context, Glance Vector, and a novel Glance Similarity Index Measure, GlanceIM, that benefits the training image reconstruction network.\n3.1. Glance Vector\nGiven an image $I \\in R^{h\\times w}$, we mimic the human recognition process that bypasses the semantic concept with a set of global and local Glance Vectors.\n3.1.1 Global Glance Vector\nFirstly, we retrieve the global image context from $I$. A set of $n \\cdot m$ pixels, where $n\\cdot m <h\\cdot w$, is randomly selected from $I$, denoted by $S$:\n$S = \\{I_{ij} | (i, j) \\in\\Omega\\}$\nwhere $\\Omega\\subseteq \\{1,...,h\\}\\times\\{1,...,w\\}$ is the set of coordinates corresponding to the selected pixels. Secondly, a Glance vector is formulated by randomly retrieving $n_g \\cdot m_g$ pixels from $S$ and forming a vector of shape $v_i \\in R^{n_g}$.\nWe extract Glance vectors in a window-based computation: reshape $S$ into a 2D matrix, $S$, of shape $n \\times m$ and apply a 2D window of shape $n_g \\times m_g$, resulting in $L_G$ sub-matrices, $\\{V_i|l = 1,...,L_G\\}$. Different from SSIM [73] and S3IM [75], the kernel is uniform, instead of circular-symmetric Gaussian weighting, since the stochastic global context is a group-based term and should not have a focus center. Moreover, we apply a unit stride to form a dense representation of the image context. The corresponding Glance vectors are obtained by flattening each submatrix $V_i$ into a one-dimensional vector $v_i$. The dense set of global Glance Vectors is represented as:\n$V_{Global} = \\{v_l \\in R^{n_g m_g} |l = 1,..., L_G\\}$\n$V_{Global}$ provides a more compact and computationally efficient representation of the global context embedded in $S$. The construction of $V_{Global}$ can leverage prior knowledge of human perception by translating it into a pixel selection rule that emphasizes perceptually important structure."}, {"title": "3.1.2 Local Glance Vector", "content": "Dedicated image reconstruction requires a closer look at the local image context. As such, we additionally extract a set of local Glance vectors from the original image $I$. We apply the 2D uniform window of shape $n_g \\times m_g$ to $I$ and produce a set of local Glance Vector by flattening. The dense set of local Glance Vectors is represented as:\n$V_{Local} = \\{v_l \\in R^{n_g m_g} |l = 1,..., L_L\\}$\nMulti-scale Glance (MS-Glance) Vectors $V$ are defined as the union of Global and Local Glance Vectors:\n$V = V_{Local} \\cup V_{Global}$"}, {"title": "3.2. Glance Index", "content": "Given two Glance vectors $v_i$ and $v_\\nu$ from $V$, the similarity between them is defined as the dot product of their standardized versions. The standardization of each vector involves subtracting the mean and dividing by the standard deviation of its elements. Specifically, the normalized Glance Vectors are denoted as $\\tilde{v}_i$ and $\\tilde{v}_\\nu$, where\n$\\tilde{v_i} = \\frac{v_i - \\mu_{v_i}}{\\sigma_{v_i}}, \\qquad \\tilde{v_\\nu} = \\frac{v_\\nu - \\mu_{v_\\nu}}{\\sigma_{v_\\nu}}$\nHere, $\\mu_{v_i}$ and $\\sigma_{v_i}$ represent the mean and standard deviation of the elements in vector $v_i$, respectively. The similarity $S(v_i, v_\\nu)$ between them is given by:\n$S(v_i, v_\\nu) = \\tilde{v_i} \\cdot \\tilde{v_\\nu}$\nThis Glance similarity measure reflects the correlation between the two vectors after accounting for their respective means and variances.\nThe normalized Glance Vectors $\\tilde{v}_i$ and $\\tilde{v}_\\nu$ take values in $R^{n_v \\times m_v}$, where each element $\\tilde{v}_{li}$ follows a standard normal distribution $N(0,1)$. The inner product $S(v_i, v_\\nu)$ of the normalized Glance Vectors lies within the range:\n$-1 \\leq S(v_i, v_\\nu) \\leq 1$\nThe maximum value is achieved when the vectors are perfectly aligned, and the minimum value is achieved when they are perfectly anti-aligned.\nFrom an algebraic perspective, The similarity of $(v_i$ and $v_\\nu)$ is equal to a normalized covariance term: From an algebraic perspective, the similarity of $v_i$ and $v_\\nu$ is equal to a Pearson correlation coefficient:\n$S(v_i, v_\\nu) = \\frac{\\tilde{v_i} - \\mu_{v_i}}{\\sigma_{v_i}} \\cdot \\frac{\\tilde{v_\\nu} - \\mu_{v_\\nu}}{\\sigma_{v_\\nu}}$\n(1)\n$= \\frac{1}{\\sigma_{v_i} \\cdot \\sigma_{v_\\nu}} \\sum_{i=1}^{N_v M_v} [(v_{i,i} \u2013 \\mu_{v_i})(v_{i',i} \u2013 \\mu_{v_\\nu})]$\n(2)\n$=\\frac{Cov(v_i, v_\\nu)}{\\sigma_{v_i} \\cdot \\sigma_{v_\\nu}}$\n(3)\nWe add a small constant $C_s$ to both the numerator and denominator [73] of the Glance Index to avoid numerical instability."}, {"title": "3.3. Glance Index Measure", "content": "Given two images $I_0$ and $I_1$, their Glance Index Measure (GlanceIM) is defined as the average of the Glance Index over two sets of MS-Glance Vectors, $V_0$ and $V_1$, which are extracted from two images in the same way:\n$GlanceIM(I_0, I_1) = \\frac{1}{|V_0|} \\sum_{v_0 \\in V_0, v_1 \\in V_1} S(v_0, v_1)$\nwhere $V_0$ and $V_1$ are the sets of Glance Vectors randomly sampled in the same manner from images $I_0$ and $I_1$, respectively. GlanceIM($I_0, I_1$) lies within the range (-1,1), where a value of 1 indicates perfect similarity (the images are identical in terms of global structure), and -1 indicates complete dissimilarity (the images are maximally different).\nGlanceIM can be used as a loss for supervising image restoration networks by changing its range into [0, 2]:\n$L_{Glance}(I_0, I_1) = 1 \u2013 GlanceIM(I_0, I_1)$"}, {"title": "4. Applications", "content": "This section demonstrates how MS-Glance improves supervised image reconstruction. We first choose a simple regression task, fitting an image with INR then demonstrate the applicability of MS-Glance and the novel air prior in undersampled MRI reconstruction, spanning various acquisition scenarios and organs.\nGlance Loss Implementation. We validate MS-Glance and decompose it MS-Glance into Local Glance and Global Glance, which represent the Glance Vector sets used for computing GlanceIM. For 3-channel RGB images, the Glance vectors are defined as flattened 1D vectors of shape $3 \\cdot n_g m_g$ to leverage the correlation information among channels. For 2-channel complex-valued MRIs, the Glance vectors are extracted from the image magnitude, which is the root-sum-of-square of the two channels that represent the real and imaginary parts. This operation allows us to directly incorporate MRI air prior when constructing $V_{Global}$. We set $n_g = m_g = 16$, $n = m = 96$, and $C_s = 0.03$.\nComparsion and Evaluation. For comparison with existing losses, we add several common losses for training image restoration networks, including a feature-based loss, Perceptual Loss (LPIPS) [82], a local-structure-emphasized loss, SSIM Loss [73], and Stochastic SSIM (S3IM) [75], a recent loss used in NeRF for multi-view synthesis. We use the official implementation of LPIPS\u00b9 and S3IM\u00b2 and follow their default settings. For SSIM, we keep the default setting in Pytorch\u00b3 and set its local window size to 16, the same as our $n_g$ and $m_g$, and stride to 1. This gives us a direct comparison of our Local Glance and SSIM - two metrics that both focus on local regions. The image reconstruction performance is evaluated with peak signal-to-noise ratio (PSNR) and structural similarity index measure (SSIM).\nAll code is written in PyTorch and experiments are carried on an NVIDIA 3090 GPU with 24 GB memory. During training, gradient clipping is deployed for all."}, {"title": "4.1. Image Fitting with INR", "content": "In this section, we show how MS-Glance improves network reconstruction ability over existing losses based on an implicit neural network, SIREN [64]."}, {"title": "4.2. Undersampled MRI reconstruction", "content": "In this section, we show the effectiveness of Glance in a real-world application, undersampled MRI reconstruction. We use a popular recurrent learning backbone, Dilated Residual Dense Network (DRDN) [85] for training and use the standard loss for training image-domain MRI reconstruction networks, L1 [79], as the baseline.\nModel Implementation. DRDN's input is a 2-channel undersampled MRI image and the output is a 2-channel reconstructed image. It stacks densely connected atrous layers and thus has a large receptive field while preserving image details. We use the official implementation of DRDN and change its recurrent number into 3 due to the GPU memory limit. DRDN is trained with an Adam optimizer and a learning rate of 0.0001 for 40 epochs for IXI and 20 epochs for FastMRI, and the model checkpoints used for evaluation are the one that produces the best PSNR on the validation set.\nDataset and simulation. We use Proton Density weighted (PD-w) MRI from one simulation dataset, the IXI brain dataset, and one raw dataset, the FastMRI [79] knee dataset. For IXI, we take 576 Volumes and uniformly sample slice-wise and then split volume-wise, resulting in 2455 slices for training and 700 slices for testing (matrix size = 256x256). The FastMRI dataset includes 1,172 volumes of single-coil complex-valued PD-w k-space. We use the official dataset split and drop the first and last five noisy slices from each volume, resulting in 25012 training slices and 5145 testing slices (matrix size = 320\u00d7320). Image normalization is done by normalizing image magnitude into [0,1].\nWe simulate the Uniform 1D undersampling using the random mask generation function from the official implementation of [79]. The undersampled images are obtained by applying the Fourier Transform to the corresponding ground truth images, masking with a randomly generated uniform 1D mask, and applying the inverse Fourier Transform."}, {"title": "5. Ablation studies", "content": "5.1. The selection of n \u00b7 m and ng mg\nMS-Glance extracts the global context of an image by randomly retrieving a subset of $n \\cdot m$ pixels.$n_g\\cdot m_g$ is the shape of Glance vectors. We show the effect of using different values when fitting the INR on the CoCo dataset in"}, {"title": "6. Discussion", "content": "6.1. MS-Glance and SSIM\nSSIM [73] computes image similarity in a window-based way and emphasizes the center pixel with a Gaussian kernel. SSIM is the product of three statistics: luminance l, contrast c, and structure s:\n$l(x,y) = \\frac{2\\mu_x\\mu_y + C_1}{\\mu_x^2 + \\mu_y^2 + C_1}, c(x, y) = \\frac{2\\sigma_x\\sigma_y + C_2}{\\sigma_x^2 + \\sigma_y^2 + C_2},$\n$s(x,y) = \\frac{\\sigma_{xy} + C_3}{\\sigma_x\\sigma_y + C_3}$\nwhere $\\mu_x, \\mu_y$ represents the pixel sample mean of two windows x and y, $\\sigma_x, \\sigma_y$ represents the variance of x, y and $\\sigma_{xy}$ represents covariance of x, y. The SSIM structure term resembles the formulation of the Glance Index. However, the construction of Global Glance vectors gathers pixels across the image, rather than in local windows like SSIM. Additionally, when we combine the l and c of SSIM with our Glance Index, we witness a performance drop. We argue that the non-semantic image context we try to capture is highly correlated with image structure and thus is better measured by our proposed Glance Index unitarily. Moreover, MS-Glance does not assume locality or center for each window, since the image context is statistics-based and does not have a focus center. Ablation studies about the kernel selection can be found in the supplementary.\n6.2. Future Work\nMS-Glance incorporates multi-scale, non-semantic image context into supervised image reconstruction. It can be deployed in other low-level vision tasks such as super-resolution, deblurring, and compression. Also, the stochasticity property of Global Glance allows for integrating more perception priors. Future work includes combining MS-Glance with other explicit appearance priors [40, 41] and learned implicit priors such as pixel correlation [30]."}, {"title": "8.2.1 Uniform Kernel and Gaussian Kernel", "content": "The uniform window kernel is a key distinction between the Glance Index Measure and methods like SSIM and S3IM. To conduct a comprehensive ablation study, we replaced our uniform kernel with their Gaussian kernel on both tasks. For MRI reconstruction, we use the IXI dataset under two acceleration rates. For INR fitting, we use the Coco dataset."}, {"title": "8.2.2 Glance Index Measure and SSIM", "content": "While we compare our method with SSIM loss in all experiments, we also highlight the connection between the Glance Index Measure and SSIM, which is discussed in detail in the main paper. In this section, we provide additional experimental results to compare the performance of the Glance Index Measure against SSIM. As mentioned in the main paper, the structural term of SSIM computes covariance similarly to how the Glance Index Measure operates. However, SSIM also incorporates luminance (l) and contrast (c) terms. To account for this, we extend our Glance Index Measure by integrating the computation of l and c, multiplying them with the original Glance Index Measure. We tested this modified approach across both tasks.\nWe perform the evaluation on both tasks. For MRI reconstruction, we use the IXI dataset under two acceleration rates. For INR fitting, we use the Coco dataset. Table 7 demonstrates the effectiveness of the Glance Index Measure, particularly in global scenarios. The current Glance Index Measure shows that MS-Glance and Global Glance remain superior. However, the Local Glance enhanced with l and c exhibits improved performance, especially in SSIM computations. This improvement is expected, as it directly optimizes a term similar to SSIM itself. Additionally, we explored combining the original Global Glance design with the new Local Glance incorporating l and c, with results shown in the last row. This approach, however, did not perform as well as the original MS-Glance design, suggesting a conflict between the two approaches."}, {"title": "8.3. Additional Details", "content": "8.3.1 Implementation of MS-Glance\nIn the Global Glance process, we randomly select pixels and shuffle them 10 times, resulting in more Glance vectors for computing the Global Glance Index Measure. As shown in Table 8, shuffling leads to a slight improvement in performance. The experiments are carried out on the Coco dataset."}, {"title": "8.3.2 Architecture of DRDN", "content": "We choose DRDN as the network for undersampled MRI reconstruction. Its strong performance has been validated by their original experiments and many recently established works [7, 65]. DRDN [85] customizes the local and global structure design for the MRI reconstruction task. It uses a Squeeze-and-excitation Dilated Residual Dense Block (SDRDB) as the backbone. The main diagram is shown in Figure 7.\nGlobally, DRDN consists of an initial feature extraction module (two sequential 3 \u00d7 3 convolution layers), multiple SDRDBs followed by global feature fusion (a concatenation operation for all SDRDBs' output), and global residual learning enhanced by a Squeeze-and-excitation on the residual branches.\nThe structure in each SDRDB is shown in Figure. In each SDRDB, there are four densely connected atrous convolution layers, local feature fusion, Squeeze-and-Excitation, and local residual learning."}, {"title": "7. Conclusion", "content": "In this paper, we show how to leverage the non-semantic image context, which can be captured by human vision, for supervising image reconstruction networks. We propose MS-Glance, a novel biologically inspired multi-scale descriptor of non-semantic image context and its loss form. We demonstrate its effectiveness in improving image reconstruction through two tasks: INR fitting and undersampled MRI reconstruction. Finally, extensive experiments on a wide range of natural and medical datasets show that the MS-Glance loss outperforms existing loss functions used in image restoration."}, {"title": "8. Supplementary Materials", "content": "Here, we show some additional results mentioned in the main paper: qualitative results on fitting the Astronaut image and ablation studies on the Glance's window kernel and distance measure. We also add additional details on MS-Glance's implementation and the network architecture of DRDN, which we use for undersampled MRI reconstruction experiments."}, {"title": "8.1. More qualitative results of Astronaut", "content": "Astronaut is a color image of the astronaut Eileen Collins. In Figure 6, we compare the step-wise reconstruction of Astronaut by SIREN and SIREN+MSGlance. The reconstructed images and the corresponding SSIM error maps are visualized. MS-Glance reconstructs the image details faster (the blue boxes in step 40) and ends up with a finer reconstruction (the blue boxes in step 500)."}]}