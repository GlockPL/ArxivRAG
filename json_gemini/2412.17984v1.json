{"title": "ICPR 2024 Competition on Domain Adaptation and Generalization for Character Classification (DAGECC)", "authors": ["Sofia Marino", "Jennifer Vandoni", "Emanuel Aldea", "Ichraq Lemghari", "Sylvie Le H\u00e9garat-Mascle", "Fr\u00e9d\u00e9ric Jurie"], "abstract": "In this companion paper for the DAGECC (Domain Adaptation and Generalization for Character Classification) competition organized within the frame of the ICPR 2024 conference, we present the general context of the tasks we proposed to the community, we introduce the data that were prepared for the competition and we provide a summary of the results along with a description of the top three winning entries. The competition was centered around domain adaptation and generalization, and our core aim is to foster interest and facilitate advancement on these topics by providing a high-quality, lightweight, real world dataset able to support fast prototyping and validation of novel ideas.", "sections": [{"title": "1 Introduction", "content": "In the rapidly evolving field of computer vision, the ability to develop robust and accurate models that can perform well across diverse scenarios is of paramount importance. Two critical concepts that have emerged as cornerstones in achieving this objective are domain adaptation and domain generalization.\nDomain adaptation is a transfer learning technique that aims to improve the performance of models in a target domain by leveraging knowledge from a different but related source domain. This approach is crucial because traditional machine learning models often struggle to generalize well when the data distribution changes between the training (source) and testing (target) domains. In real-world applications, such as autonomous driving [24][31][17], surveillance systems [14][5][18] or industrial quality control [20][27][30], this shift in data distribution is a common occurrence due to factors like varying weather conditions, lighting, or camera angles. Domain adaptation, therefore, plays a vital role in enhancing the model's resilience and adaptability to these changes, ensuring consistent performance and reliability.\nOn the other hand, domain generalization is a technique that seeks to develop models that can generalize well to any unseen target domain, without requiring access to any target domain data during training. This is a more challenging task than domain adaptation, as it requires the model to learn a universal representation that can capture the underlying data structure across multiple domains. The importance of domain generalization lies in its potential to create models that can truly adapt to any new environment, making them highly valuable for real-world applications where the target domain may be unknown or constantly changing [4][19][3][13].\nThe importance of datasets in the context of domain adaptation and domain generalization cannot be overstated. Diverse and representative datasets are crucial for training models that can effectively learn and adapt to different domains. For domain adaptation, the availability of well-labeled source and labeled or unlabeled target domain datasets is essential, as it allows the model to learn the underlying data distributions and map the knowledge from the source to the target domain. On the other hand, domain generalization typically relies on multi-domain datasets, where the model is trained on data from several different but related domains. This exposure to a variety of data distributions during training helps the model to learn a more universal representation, enabling it to generalize better to unseen target domains. Moreover, the quality and diversity of datasets can significantly influence the performance of these techniques, making the curation and selection of appropriate datasets a critical aspect of their success. Thus, the development and availability of comprehensive and diverse datasets are vital for advancing research and applications in domain adaptation and domain generalization.\nThe competition on Domain Adaptation and Generalization for Character Classification (DAGECC) aims to foster advancements in domain adaptation and domain generalization techniques by introducing a novel dataset comprising real images of digits and characters captured from serial numbers on manufactured objects. In particular, we focus on an image classification task for industrial serial number recognition. In industrial environments, serial part numbers play a critical role in ensuring traceability and streamlining the management of diverse components (e.g., preventive maintenance, analytics, etc.). However, the manual process of reading and recording these serial numbers is both labor-intensive and prone to errors. As a result, the development of an automated serial number recognition system that can work seamlessly across multiple parts holds tremendous potential for improving operational efficiency in industrial environments.\nTo address this challenge, we are introducing Safran-MNIST, a brand new dataset suite that comprises images of serial numbers extracted from diverse avionic parts manufactured by Safran, an international high-technology group and world leader operating in the aviation (propulsion, equipment and interiors), defense and space markets. The content resembles that of the well-known MNIST dataset of handwritten digits [16], hence the name, but with a focus on industrial contexts. The Safran-MNIST dataset suite offers a realistic representation of industrial serial number images, encompassing variations in lighting"}, {"title": "2 Competition overview", "content": "The competition encompasses two primary tasks: (i) Domain Generalization and (ii) Unsupervised Domain Adaptation. The central objective of this competition is to investigate and foster progress in domain adaptation and domain generalization methodologies, specifically in the context of character recognition."}, {"title": "2.1 Datasets", "content": "DAGECC competition is based on the brand new Safran-MNIST dataset suite, specially crafted for the application of character recognition. Characters have been extracted from larger images of Safran's avionic parts acquired from aircraft engines returned from flights, that have to be periodically inspected for predictive maintenance and security reasons. They correspond to product references or serial numbers engraved on metal parts with various techniques which are widely used for traceability (laser, pencil, or micro percussion engraving).\nThe Safran-MNIST dataset suite comprises two datasets, namely Safran-MNIST-D[28] and Safran-MNIST-DLS5[21], which are used in the two tasks respectively. Specifically:\nDataset for Task 1 Domain Generalization: Target data for this task consists of real-world Safran-MNIST-D dataset containing RGB images of size 128 \u00d7 192 pixels representing digits ranging from 0 to 9. Each image in this dataset belongs to a distinct class. We annotated 1684 images for testing and 421 images for validation. Since target data is not to be used in this task, the validation and testing datasets and associated ground-truth are released at the end of the competition. Sample\nDataset for Task 2 - Unsupervised Domain Adaptation: Target data for this task consists of real-world Safran-MNIST-DLS dataset containing variable size gray-scale images of 32 characters. Specifically, this dataset includes 10 digits ranging from 0 to 9, 20 letters (A, B, C, D, E, F, G, H, J, K, L, M, N, P, R, S, T, U, W and Y) and 2 symbols (/ and .). Each image in this dataset belongs to a distinct class. We manually annotated 3448 images for testing and 862 for validation. Furthermore, we provided 9314 unlabeled images for training. Sample"}, {"title": "2.2 Description of tasks", "content": "Task 1 - Domain Generalization: The aim of this task is to develop models that can generalize well to an unseen target domain, without requiring access to any target domain data during training. Thus, participants could not use any data from the target domain, which as the new Safran-MNIST-D dataset that contains images of numbers ranging from 0 to 9. In addition, participants were granted the freedom to use publicly available data or generated data from various source domains, such as MNIST [16], MNIST-M [11], SVHN [22], HASYv2 [26], DIGITS [1], EMNIST [6]. This allowed participants to leverage existing datasets or generate realistic synthetic data to train their models without compromising the requirement of no access to the target domain. Note that we deliberately not imposed any dataset for the source domain in order to let participants find and explore relevant datasets (or combinations/derivations of datasets) adapted to the task, provided that these are publicly available. Proprietary data were not allowed in order to facilitate the reproducibility of results.\nTask 2 - Unsupervised Domain Adaptation: This task is focused on unsupervised domain adaptation methods, in which we provided unlabeled data from a target domain: the new Safran-MNIST-DLS dataset, which comprises images of 32 classes depicting numbers, alphabetic characters, and symbols. Participants had access to the unlabeled target data during training. Furthermore, participants were tasked with sourcing a suitable dataset that can serve as the source data for domain adaptation. This could involve either finding an existing publicly available dataset or generating a synthetic dataset that aligns with the problem domain, using traditional image processing techniques or generative AI provided that the generative model has been trained on public data.\nFor both tasks, participants could use any publicly available and appropriately licensed data to pre-train their models.\nNote that data from one task of the competition could not be exploited for the other task."}, {"title": "2.3 Evaluation metric", "content": "Macro-averaged F1-score was selected as evaluation metric in this competition to take into account the imbalanced nature of the dataset. This metric is described as follows:\n$FMacro = \\frac{\\sum_{k=1}^{K} F_{k}}{K}$\nFor class k,\n$F = \\frac{2TPk}{2TPk + FPk + FNk},$"}]}