{"title": "Detecting and Characterising Mobile App Metamorphosis in Google Play Store", "authors": ["D. Denipitiyage", "B. Silva", "K. Gunathilaka", "S. Seneviratne", "A. Mahanti", "A. Seneviratne", "S. Chawla"], "abstract": "Abstract\u2014App markets have evolved into highly competitive and dynamic environments for developers. While the tradi- tional app life cycle involves incremental updates for feature enhancements and issue resolution, some apps deviate from this norm by undergoing significant transformations in their use cases or market positioning. We define this previously unstudied phenomenon as 'app metamorphosis.'\nIn this paper, we propose a novel and efficient multi-modal search methodology to identify apps undergoing metamorphosis and apply it to analyse two snapshots of the Google Play Store taken five years apart. Our methodology uncovers various metamorphosis scenarios, including re-births, re-branding, re-purposing, and others, enabling comprehensive characterisation. Although these transformations may register as successful for app developers based on our defined success score metric (e.g., re-branded apps performing approximately 11.3% better than an average top app), we shed light on the concealed security and privacy risks that lurk within, potentially impacting even tech-savvy end-users.", "sections": [{"title": "I. INTRODUCTION", "content": "The mobile app industry is highly competitive and with over 2.5 million apps on the Google Play Store [1] and 1.5 million apps on the Apple App Store [2], it can be difficult for apps to stand out from the crowd. To be successful, app developers need to create innovative and user-friendly apps, update existing apps, and respond to new operating system features and market demands.\nWhile the typical life cycle of an app involves releasing it to the app market and periodically updating it to add new features or fix bugs and security issues, some apps deviate from this pattern of incremental updates. Instead, they undergo dramatic changes in their use cases or market positioning. The methods to match apps between two different time spans and observe such dramatic transformations remain largely unexplored. We define this relatively unknown phenomenon as \"app metamorphosis\" and there are multiple reasons and implications of it based on our findings.\nFor instance, sometimes developers may use the re-branding strategy to uplift a struggling app. This re-branding will involve changing the app's name, logo, or overall look and feel. The aim is to improve the app's image or to make it more relevant to a new target audience. Re-branding can also happen after a merger or an acquisition, as in the case of the popular short video-sharing social networking app TikTok, which used to be called Musical.ly with a slightly different purpose of sharing short lip-synced videos [3].\nSimilarly, some developers looking to extend the useful life of their successful apps employ the re-purposing strategy. Re-purposing an app means changing its core functionality or purpose. This enables the developers to change their app's core functionality while retaining its app audience, download numbers, ratings, etc. Equally, some developers may re-purpose their apps when their core functionalities become redundant due to them being added to the operating system as standard features. For example, due to hardware advances in smartphone cameras, some camera apps such as Noah Camera became photo editors.\nDevelopers can also attempt to revive apps by re-birthing them. That means re-introducing a previously discontinued or an about-to-change app under a new identity (i.e., a new app ID), with minimum or no functionality change compared to the original one. This is a major undertaking, but it can be a successful way to create a new and improved app that is more likely to succeed. As an example, once UNO &\nFriends were discontinued by Ubisoft, it was revived back by a different developer Mattel163 as UNO! and became successful by reaching a wider audience. One of the other and potentially adverse reasons for re-birthing is to overcome bans imposed by Google on developers. \nTo date, motivations for app metamorphosis are not fully understood as there have been no systematic studies that have focused on this aspect of the mobile app ecosystem. An investigation of app metamorphosis that focuses on the char- acteristics and prevalence of app metamorphosis will provide further insights into how the mobile app ecosystem is evolving. Moreover, such a study will help app market operators to iden- tify different forms of app metamorphosis and their impact on the apps and enable developers to understand the implications of the actions. It is also important to understand how successful or unsuccessful the apps that underwent metamorphosis are. This will provide insights to the app developers to make decisions on app updates and monetisation strategies. Finally, there can be privacy and security implications because of these app transformations.\nTo this end, in this paper, we compare two snapshots of the Google Play Store that are five years apart and propose a"}, {"title": "II. RELATED WORK", "content": "Various empirical studies have been conducted on Google Play Store and other app stores focusing on different aspects such as; general statistics related to apps [4], [5], advertising and analytics library behaviours [6], [7], characterising and detecting malware and malpractices [8], [9], [10], [11], [12], [13], and privacy and security analysis of one specific type of apps [14], [15]. However, only a limited amount of work focused on studying the evolution of apps over a longer time period.\nApp life cycle in Google Play - The usual life cycle of an app in Google Play Store involves the developer publishing the app by selecting some of the metadata such as category, content rating, and self-reporting data collection and sharing practises [16], [15]. Once it is published, the app will be updated periodically to release new features or fix bugs. The vast majority of the apps will continue to be like this; however, some apps may get discontinued (i.e., no further updates), removed from Google Play Store (i.e., either developer decides to remove the app, or Google removes the app or ban the devel- oper for various reasons [17]) or go through \u201cmetamorphosis\u201d which is the focus of this paper.\nTo date, the app life cycle has been characterised pre- dominantly from an app update point of view. For instance, Pothuraju et al. [18] claim that nearly 76% of apps did not get any update in Play Store within their monitoring dataset for a period of approximately six months while a minority got nearly hundreds of updates which may point to newly released apps that could require many bug fixes. Though these updates are supposed to fix bugs or provide better security, Moller et al. [19] noted that even after a week of an update, app users still tend to use the older version. Vincent et at. [20] used PlayDrone [4] to extract permission usage of apps and observed that popular apps request additional dangerous permissions with subsequent updates.\nAnother body of work checked how some individual app libraries, such as advertising and analytic libraries, are being updated [21], [22]. However, in all these cases, the apps do not go through \u201cmetamorphosis\", and app developers remain the same. We also note that the app life cycle we consider in this paper is different from the app life cycle considered by some works [23], [24], which focus on the app usage point of view, such as when a user installs an app, and abandon it after using it for a period of time.\nDisguising (or misleading) app users Beyond malware, multiple works explored various disguises and malpractices happening in Google Play Store. Such work is related to ours because when detecting \"app metamorphosis\", we can incur\""}, {"title": "III. DATASETS", "content": "We use two main datasets in our work. These are two snapshots of the Google Play Store, collected in 2018 and 2023, respectively. They contain app metadata (e.g., app ID, app name, app category/genre, app description, developer name, etc.), app creatives (e.g., app icons and app screenshots), and for free apps, APK app executables. The 2018 dataset that was collected as a part of our previous work [28] contains metadata of over one million apps that were collected between January and March 2018. The 2023 dataset contains metadata of 1,280,142 apps and was collected between January and November 2023. The data was collected using a Python-based crawler that started from an initial seed of apps, sourced by various top-lists in the Google Play Store progressively discovering new ones. To avoid any disturbances to the app market operation, we conducted our crawl conservatively at a low rate.\ni) Top-k apps in 2018 and 2023 datasets - Our key objective in this work is to identify apps that went through notable re-transformations between the two snapshots. To get better insights and to avoid low-quality apps affecting our results as noise, we focus only on the top-k apps in the 2018 dataset and their relevant counterpart in 2023. To identify the top-k apps in each dataset, we use the same method proposed by [17] in sorting the datasets. That is, we sort the set of crawled apps in a dataset (either the 2018 dataset or the 2023 dataset), first based on the number of downloads, second based on rating count, and third based on the average stars and select the first k apps. Next, we constructed a 'validation-set' and a 'test- set' to fine-tune hyper-parameters of the app similarity search algorithm and to evaluate the performance. We discuss our search algorithm later in the Sec. IV.\nii) Validation-sets - When we are searching for a counterpart app between the two datasets, there may be or may not be a matching app. For example, an app may have been discontinued. To properly capture this idea, there must be ground-truth sets on matches and no matches to fine-tune our algorithm; therefore, we create two validation-sets."}, {"title": "IV. SIMILARITY SEARCH ALGORITHM", "content": "Our objective is to identify a 2023 counterpart app for a given 2018 app (a 'match') or else to return a 'no-match' if such an app does not exist. We follow a multimodal search mechanism to obtain the mappings between the two datasets, and we specifically do not rely on app ID matching in this process. The reason is that metadata-based matching allows us to identify cases of metamorphosis better and to observe whether the developers continued with the same app ID or introduced a new identity.\nOur methodology consists of four main steps. i) obtain neural embeddings for app icons and app descriptions, and TF-IDF vector representations for app names and developer names, ii) for a given app, retrieve a set of nearest neighbour apps considering each modality, iii) perform modality-wise majority voting to obtain the top-candidate apps for a given app. iv) decide if we could select an app as a 'match' from the candidate app list (further discussed in Sec. IV-D) or else decide it as a 'no-match'. We show the end-to-end pipeline of the proposed method. In the figure, we use the query app's embedding representations to retrieve results as search keys and the retrieved results (more specifically, retrieved app IDs) as values. The following subsections explain these steps in detail.\nA. Representation of different modalities\nAs inputs for the search methodology, We use metadata extracted from the Play Store and more specifically, they are app icon, app description, app name and developer name for both datasets 2018 and 2023. We selected these based on the prior work and our own investigations on the available metadata that are in spotlight for target app users. For example, developers use same name to maintain brand consistency for their apps, compared to the developer email, which is often not publicly available and developers might use different email addresses for different apps to avoid confusion.\n1) App icon embeddings: The app icon serves as the initial point of visual engagement for users, often functioning as a distinctive trademark representing the developer's brand identity. Therefore, a matching pair of apps is likely to have a similar visual 'styling' and similar 'content' information, emphasising the need to encode both such information. StyTr2 introduced by [31] is a popular transformer-based framework with style and content encoders, both producing output embeddings of the shape (1\u00d7512). Additionally, we experiment with vision transformer content encoder embeddings [32] as well as style and content embeddings from VGG19 architecture as proposed in [28]. We identify which style and content embed- ding combination produces the best results for both 'matches' and 'no-matches' by evaluating possible combinations against our validation dataset.\n2) App description embeddings: Despite large language generative models being popular, text embedding transformer models, due to their unique encoding capabilities, allow us to obtain rich vector representations for text sequences [33]. Therefore, we use the MPNet [34] model to encode the long app descriptions into the vectors, $v_d$ of shape (1\u00d7768). MPNet is a language model similar to BERT [35] and allows to obtain vector representations of text. It considers masked language modelling such as BERT and permuted language modelling such as XLNet [36] in a unified view and thus inherits the advantages of both methods.\n3) App name and Developer name embeddings: Since the app and developer names have limited meaningfulness as natural language, as well as they are very short texts, we employ TF-IDF vectorisation to encode app names and developer names instead of using MPNet embeddings. We represent each app and developer name as a vector of size (1\u00d74,096) where the vocabulary contains 4,096 most frequent 1-4 grams when 200,000 app descriptions were used to build the vocabulary.\nB. Nearest neighbours of each modality\nIdentifying potential apps that underwent \u201cmetamorphosis\" involves taking a query app from the top-10,000 apps in the 2018 dataset and identifying the most similar app (if there is any) among the 1,280,142 odd apps in the 2023 dataset. This requires identifying close apps along each modality presented in Sec. IV-A using nearest neighbour search. However, the vanilla version of the nearest neighbour search is highly inefficient here because of the larger queried set, the number of modalities, and the sizes of the embeddings.\nInstead, we use the indexing options provided in the Faiss library [37] to create an Inverted File Index of the queried embeddings to narrow the search scope. First, we create sharded indexes for small batches of embeddings, and we build the final index on disk by merging sharded indexes into one larger index. We created five such indexes for each modality (represented by an embedding type; app icon - content, app icon - style, app name, app description and developer name), and they are queried for nearest neighbours using the query app's embeddings.\nFor a single query, we obtain five different nearest neighbour sets corresponding to the five modalities we consider in the descending order of the similarity with the query app's embedding vectors.\nC. Majority voting\nStarting of the app similarity search algorithm is a majority voting scheme based on four modalities (we have excluded the 'developer name' to be discussed later). \nIn each iteration, we select the app that has the most number of occurrences in each row-wise-position as the most common result. In the figure, each of these selections are visualised in the grey colour box.\nAs shown , in step 1, app B is selected as the most common occurrence since it appears as the top choice in two separate modalities (occurrence count = 2). Then the remaining apps (A and C) from that position are carried forward to the next iteration. This ensures all potentially similar apps are considered in subsequent row-wise-positions to be iteratively repeated. As shown in step 3, we exclude app D from the selection space since it has already been selected in the second position. When multiple apps appear with the same frequency, we make a random selection. Step 4 indicates this by randomly selecting app M, while both M and N have equal number of occurrences. The final output is the list of nearest neighbours (vertical list in grey colour) and their corresponding occurrence count for a given query app.\nNote that we handle developer names in a slightly different way as step number 5 that is not shown in . Since some developers publish more than one app, if we use the developer name as a modality in the neighbour search, the result with the highest occurrence count may not be the desired matched result. For example, if we have the same developer for app X and app Y, then there is no straightforward way to mention X and Y both in the same position in the app developer neighbour list. Therefore, for each row-wise- position, we check the app with the most occurrence count (e.g., app B in step 1) is developed by the same developer of that row-wise-position's app-developer modality result. If so, we consider it as a modality match and add one more to the occurrence count (e.g., app Z in app-developer modality position is the same developer as app B, then we add 1 to the occurrence count in step 1). We only change the occurrence count list (if applicable) in this step.\nD. Match or No-match?\nUpon retrieving the list of nearest neighbour apps for a given query app, we identify a matching app as the first neighbour app in the list's descending order that agrees with following two criteria.\n\u2022\nWe define a hyper-parameter $\\alpha$ such that the number of modalities that contributed for an app to be selected as a nearest neighbour (i.e., the occurrence count) should be equal or greater than $\\alpha$. We call this hyper-parameter as 'occurrence count threshold'.\nWe calculate the change of star rating count, representing the number of users who have rated the app, between the neighbour app and the query app. It should be positive. Our intuition here is that a matching app should have grown in the rating counts over the past five years.\nHowever, if all the apps in the nearest neighbour search list show a negative star rating count change with respect to the query app, then we only consider the first criteria. But, if no app satisfies the first criteria, we denote it as query app not having a match. The threshold value $\\alpha$ is selected based on an ablation study we conducted, and we discuss this . It is also worth noting here that having a no-match result does not mean that we exclude that particular app from metamorphosis analysis. We further utilise them to identify and analyse interesting transitions of apps .\""}, {"title": "V. PERFORMANCE ANALYSIS OF APP SIMILARITY SEARCH", "content": "In this section, we evaluate the similarity search algorithm based on the validation and test sets described in Sec. III. To summarise, when we are using the validation-set for identifying 'matches', then we have 500 query apps from 2018 to be matched to a counterpart app among 5000 apps in 2023 dataset. When we are identifying 'no-matches', we query the same 500 apps from 2018 to be 'not-selected' among the 4500 in 2023 dataset because the matching 500 apps of 2023 are removed in this setting. Test-sets are used to observe the performance after the hyper-parameters are selected and they work in a similar setting too; 100 apps in 2018 to match among 1000 total in 2023 for 'matches' and the same 100 apps among 900 in 2023 for 'no-matches'. Next we will discuss what are the hyper-parameters we validate our model with. We make two hyperparameter choices based on the performance on the validation set.\n\u2022\nWe explore six different combinations of style and con- tent embeddings.\n\u2022\nWe explore five different occurrence count thresholds ($\\alpha$\nvalues) from 1 to 5.\nWe evaluate a occurrence count threshold, $\\alpha$ for each embedding combination and report the harmonic mean of the two scenarios. We show the results in Table I. As can be seen, the combination of StyTr\u00b2 content embeddings and VGG19 style embeddings produce the best performance at the voting threshold $\\alpha$ = 3. We used this hyperparameter combination to obtain the main results of the paper.\nWe also observe that the accuracy of the no-match scenario increases when we increase the thresholds. This is expected because as we increase the thresholds, the number of modali- ties an app should be included to select as a match increases. On the other hand, the accuracy decreases with the increased thresholds when there is a match. This happens because, as the threshold increases, an app should be included in more modalities in order to be selected as a match, therefore, the conditions become more restrictive. The following subsections describe the performance metrics we use and the performance of the test set.\nA. Performance metrics\nWe measure the performance of our method on test set and compare with an existing baseline using accuracy, precision@1 and recall@1 matrices.\n1) Accuracy: We take the harmonic mean of the accuracies when there is a match and when there is no-match. We use harmonic mean instead of the arithmetic mean because we need accuracy in both scenarios to contribute equally.\n2) Precision and Recall: We define Precision and Recall based on the following definitions. For a match scenario, there can be i) a correct match (true positive), ii) an incorrect match (false positive), and iii) no result when there is a correct match available (false negative). Note that there are no true negative occurrences since we are considering matches and no-matches separately. We define the Precision and Recall for a match scenario as in Eq. 1 and Eq. 2.\n$\\text{Precision} = \\frac{\\text{True Positives}}{|\\text{True Positives}|+ |\\text{False Positives}|}$ (1)\n$\\text{Recall} = \\frac{\\text{True Positives}}{\\text{True Positives}| + |\\text{False Negatives}|}$ (2)\nFor non-match scenarios, the algorithm can output either no match (True Positive) or an incorrect match (False Negative). Therefore we define only Recall for the non-match as defined in Eq. 2. Note that Recall and Accuracy are similar for the no-match scenario.\nWhen we report our results as precision@1 and recall@1, we only consider the first matching result for each method when calculating scores.\nB. Performance analysis\nWe compare our method with the method proposed by Karunanayaka et al. [28]. In [28], the authors proposed a nearest neighbour search for the weighted sum of each em- bedding, including the app icon (style and content) and app description. We adapt their method using $\\alpha$, $\\beta$, $\\theta$, $\\gamma$ and $\\delta$ [28] as the weights for image content embeddings, image style embeddings, developer name embedding, app description em- bedding and app name embeddings, respectively. In addition to those weights, we use an additional threshold parameter to decide the apps that do not have any matching apps. Then, we choose the optimal values for those weights and the threshold using the Bayesian optimisation [38] on the validation dataset considering the integer values between 1 and 10. We report the results for the best-performed values of $\\alpha$, $\\beta$, $\\theta$, $\\gamma$, $\\delta$ and the threshold and results for our method in Table II.\nAs can be seen from the results, our method provides better results when the app is included within the search space (i.e., with matches). Conversely, the method proposed by [28] demonstrates higher accuracy for no-matches. Nonetheless, [28] becomes infeasible to use when the queried dataset and the number of search keys are larger, given that it uses a brute force approach, comparing the search key with embeddings of all apps in the queried data multiple times for different types of embeddings.\nC. Success score\nWe introduce 'success score' (SS) as a parameter that we can use to evaluate the performance of each app progressing from 2018 to 2023. In high-level, we expect a positive SS to indicate an app that has been performing well such that there is no risk of that app going obsolete and a negative SS to indicate an app not performing well.\nThe success of an Android app could intuitively be associ- ated with the number of downloads and the number of ratings it received from the app users, both ultimately impacting the direct and in-direct revenue incoming to the developers. However, an increase in these counts does not necessarily mean an app is performing better due to the natural growth of the Android user base over a period of time: 2.3 billion worldwide devices in 2018 to approximately 3.6 billion in 2023 [39], [40], [41].\nConsidering this factor, we define the Success Score (SS) for an app based on the Compound Annual Growth Rate (CAGR) of downloads and ratings offset by the natural growth in the Android ecosystem over a time span of t years. As specified in Eq. 3, when we calculate $CAGR_{\\text{#downloads}}$, the term $N_{\\text{initial}}$ is the download count of 2018 app, $N_{\\text{final}}$ is the download count of counterpart 2023 app and t = 5 years. $CAGR_{\\text{#ratings}}$ is similarly calculated based on the star rating count and $CAGR_{\\text{#Andro}}$ is calculated based on the increase of android devices over the five years, 2.3B to 3.6B.\n$\\text{CAGR} = (\\frac{N_{\\text{final}}}{N_{\\text{initial}}})^{\\frac{1}{t}}-1$ (3)\n$\\text{SS} = \\frac{1}{2} \\text{CAGR}_{\\text{#downloads}} + \\frac{1}{2} \\text{CAGR}_{\\text{#ratings}} - \\text{CAGR}_{\\text{#Andro}}$ (4)\nAccording to the Eq. 4, SS value of x indicates that the aver- age number of downloads and user ratings have increased x% better than the average growth of android eco-system growth per year. Moving forwards, we discuss SS as a percentage (e.g. SS=0.145 is interpreted as 14.5%) for convenience."}, {"title": "VI. CHARACTERISATION OF APP METAMORPHOSIS", "content": "In this section, we provide a characterisation of different types of metamorphosis categories listed . We explain how to identify each category using our search methodology, analysis and insights on the causes and effects of metamor- phosis, followed by interesting examples.\nFirst, we use our search algorithm on the top 10,000 apps from the 2018 dataset (Fig. 5a) to identify their corresponding apps among the 1.3 million apps in the 2023 dataset (Fig. 5b). \nFirst, we check if our algorithm gives a match or a no-match. If it is a match, we observe if the app ID in 2018 is identical to the app result we get in 2023. If they are not identical (i.e., 2018 app ID \u2260 2023 app ID), then we check whether the 2018 original app ID exists in the 2023 dataset; if it exists, we analyse them further. Lastly, for any of the 2018 top 10k apps that our algorithm gives no-match, we check again if those 2018 app IDs exist in the 2023 dataset and analyse further.\nA. Summary of mappings\nAs shown , a total of 4,518 apps get a match in D23 having the same app ID between the two datasets (blue arrow). Nonetheless, only 61.6% of them are still among the Top 10k of D23. The rest were mostly in between the top 10k and 50k. We observe an average success score (SS) of 10.01% for these 4,518 apps, and this score is more influenced by download count (~20% more contribution) rather than user rating. These apps are likely not to have gone through drastic transformations as our algorithm has already returned a match, and the app IDs are the same between the two datasets. We use their SS numbers as the baseline to compare with the SS numbers of different metamorphosis categories.\nWe observe 298 apps that our algorithm matched, without the same app ID among the matching pairs (teal and purple arrows). They suggest that the original app continued to 2023 with a different identity, which we identify as a potential re- birth that is discussed later in Sec. VI-B. Out of those 298, 116 had the same app ID linked to other apps in the 2023 dataset (green arrow) that our algorithm did not find as similar. Furthermore, there are 2,070 other examples in the 2018 dataset initially returned again as no-matches, but the same app ID exists in the 2023 dataset (yellow arrow). Both of these scenarios suggest that the developer has decided to re-brand or re-purpose those apps, resulting in major changes to the app description, name and app icon; hence why our methods did not match them. We discuss this further in Sec. VI-C and Sec. VI-D.\nWe also discuss other interesting adaptations by the app developers, such as changes in the genre, content-rating, revenue-model and developer-transitions. Furthermore, devel- opers might opt to keep multiple versions of the same app or could develop apps targeted at particular user demographics. We discuss them in detail in Sec. VI-E to Sec. VI-J.\nFinally, there are 3,114 apps, for which our method gives no matches, and the same app IDs are no longer present in D23 (orange arrow), indicating either the developers have discontinued those apps or they have been removed by Google (e.g. due to spamming [17]). When an app is discontinued, it is likely caused by the applications of such apps no longer being required or being replaced by progressive versions. Majority of these discontinuations were from tech giants such as Google, Samsung, HTC or from popular game developers such as Gameloft, and Electronic Arts."}, {"title": "B. Re-born apps", "content": "Re-born apps are characterised by their initial discontinu- ation, followed by a reappearance where either the original developer or a new one reintroduces the same app concept.\nIdentification: We select matched apps from the similarity search where the 2018 app ID is different from the 2023 app ID. We found a total of 298 belonging to this condition (cf. Fig. 5: 116 in purple and 182 in teal). We further filter them by selecting the apps with a release day in D23, which is later than the last update day in D18, and obtain 88 potential apps for re-birth. We manually validated these 88 apps and found that 74 of them (84.1%) are indeed actual re-births, indicating our identification method works.\nAnalysis - Because of the app ID change, any market presence the 2018 app gained is discontinued and the new app has to start afresh. As a result, the average success score (SS) for an app in this category is -14.81%, and they struggle to be within the top 10k category in D23 as further illustrated in Fig. 5 with only 20.4% of the apps represented by purple and teal colours are in the top 10k of 2023. We note the following observations while analysing the re-born apps.\n\u2022\nIn , we plot the cumulative distribution function (CDF) of SS scores of re-born apps. It further shows that the success of re-born apps is inferior compared to the baseline SS-CDF of nearly 5,000 matched apps between the datasets, which remain in the top 10k (cf. Sec. VI-A). Here, we also observe that nearly ~ 70% of apps in re- born category have a negative SS compared to ~ 32% in the baseline CDF.\n\u2022\nDespite the negative average SS in this category, 30.13% of apps such as, Bowmasters, MONOPOLY, VLC for Android have managed to recover (SS>0) and even build upon their user base and ratings within or less than five years time span.\n\u2022\nGames are often (~ 27%) re-introducing the progressive versions as re-births. An already established user base would actively follow newer versions, therefore contribut- ing to pushing the SS towards a positive value. This allows the developers to discontinue the old version after the transition period to reduce the maintenance cost of multiple apps. Changing the original app to a newer version while re-birthing the former using a new app ID is very rare. But we observed one such example as shown \n\u2022\nWe identify that sometimes developers change their orig- inal app into a totally new type of app using the same app ID (i.e., re-purposed - discussed more in Sub.Sec. VI-D). However, they do not want to discontinue their original app to keep the revenue stream. They get a new app ID and introduce the original app again, which is a re- birth. For example, AppLock@DoMobile changed their AppLock Theme Nightclub app to a game called Block puzzle and re-introduced the AppLock Theme Nightclub under a different app ID \n\u2022\n29.5% of manually verified re-births happen with devel- oper name changes. Even if the app name, description and visual data allow us to verify them as the same app being re-introduced, a malicious actor could easily employ the same strategy and introduce counterfeit apps as re-births when one app gets discontinued. This puts even a tech- savvy user in a vulnerable position as Google Play Store does not provide the history of an app developer. We further discuss this in Sec. VII.\nExamples - We have identified notable apps while observing this category, including Uno [42] and Flickr [43] . In both of those examples, the original app lost the existing user base as the app ID was discontinued. However, different developers re-introduced very similar apps without a major change in the functionality. In 2019, SmugMug acquired Flickr from the former owner Yahoo and reintroduced it as a new app with significant changes. However, the SS of the app is -38.8%, indicating that it experienced a significant loss of its user base during this transition. Conversely, the Uno app has a positive SS of 0.7%. Despite a decrease in its rating count, as reflected by a $CAGR_{\\text{ratings}}$ of -0.3%, games like Uno naturally has a high demand, evidenced by $CAGR_{\\text{downloads}}$ of 20.2%."}, {"title": "C. Re-branded apps", "content": "Some apps in Google Play can stagnate after a while because they no longer attract new users, stalling the growth of app-related revenue. In such settings, a developer may opt to change an app's outlook drastically, fine-tune some degree with features or perhaps may opt to transfer/sell the app to a new developer, again resulting in drastic changes to the app according to new ownership. We identify this change as app re-branding.\nIdentification: We select non-matched apps from similarity search where the 2018 app ID still exists in 2023 dataset . A re-branded app could potentially have changed in the outlook (app icon, visual style and colour schemes, app name) but should have a similar context in the app description. (A drastic change in app description indicates that the app may have been re-purposed rather than re-branded). Therefore, we further filter previous results by selecting the apps with app name and app icon content embeddings having a smaller cosine similarity (< 0.7; i.e., these features are likely changed) and app description cosine similarity being higher (>0.4; i.e., still the descriptions remain relatively unchanged) between 2018 and 2023 counterparts.\nAnalysis: From previous criteria, we retrieved 322 apps that potentially underwent re-branding. Since we know the app ID"}, {"title": "D. Re-purposed apps", "content": "Contrary to what is discussed before"}, {"title": "Detecting and Characterising Mobile App Metamorphosis in Google Play Store", "authors": ["D. Denipitiyage", "B. Silva", "K. Gunathilaka", "S. Seneviratne", "A. Mahanti", "A. Seneviratne", "S. Chawla"], "abstract": "Abstract\u2014App markets have evolved into highly competitive and dynamic environments for developers. While the tradi- tional app life cycle involves incremental updates for feature enhancements and issue resolution, some apps deviate from this norm by undergoing significant transformations in their use cases or market positioning. We define this previously unstudied phenomenon as 'app metamorphosis.'\nIn this paper, we propose a novel and efficient multi-modal search methodology to identify apps undergoing metamorphosis and apply it to analyse two snapshots of the Google Play Store taken five years apart. Our methodology uncovers various metamorphosis scenarios, including re-births, re-branding, re-purposing, and others, enabling comprehensive characterisation. Although these transformations may register as successful for app developers based on our defined success score metric (e.g., re-branded apps performing approximately 11.3% better than an average top app), we shed light on the concealed security and privacy risks that lurk within, potentially impacting even tech-savvy end-users.", "sections": [{"title": "I. INTRODUCTION", "content": "The mobile app industry is highly competitive and with over 2.5 million apps on the Google Play Store [1] and 1.5 million apps on the Apple App Store [2], it can be difficult for apps to stand out from the crowd. To be successful, app developers need to create innovative and user-friendly apps, update existing apps, and respond to new operating system features and market demands.\nWhile the typical life cycle of an app involves releasing it to the app market and periodically updating it to add new features or fix bugs and security issues, some apps deviate from this pattern of incremental updates. Instead, they undergo dramatic changes in their use cases or market positioning. The methods to match apps between two different time spans and observe such dramatic transformations remain largely unexplored. We define this relatively unknown phenomenon as \"app metamorphosis\" and there are multiple reasons and implications of it based on our findings.\nFor instance, sometimes developers may use the re-branding strategy to uplift a struggling app. This re-branding will involve changing the app's name, logo, or overall look and feel. The aim is to improve the app's image or to make it more relevant to a new target audience. Re-branding can also happen after a merger or an acquisition, as in the case of the popular short video-sharing social networking app TikTok, which used to be called Musical.ly with a slightly different purpose of sharing short lip-synced videos [3].\nSimilarly, some developers looking to extend the useful life of their successful apps employ the re-purposing strategy. Re-purposing an app means changing its core functionality or purpose. This enables the developers to change their app's core functionality while retaining its app audience, download numbers, ratings, etc. Equally, some developers may re-purpose their apps when their core functionalities become redundant due to them being added to the operating system as standard features. For example, due to hardware advances in smartphone cameras, some camera apps such as Noah Camera became photo editors.\nDevelopers can also attempt to revive apps by re-birthing them. That means re-introducing a previously discontinued or an about-to-change app under a new identity (i.e., a new app ID), with minimum or no functionality change compared to the original one. This is a major undertaking, but it can be a successful way to create a new and improved app that is more likely to succeed. As an example, once UNO &\nFriends were discontinued by Ubisoft, it was revived back by a different developer Mattel163 as UNO! and became successful by reaching a wider audience. One of the other and potentially adverse reasons for re-birthing is to overcome bans imposed by Google on developers. \nTo date, motivations for app metamorphosis are not fully understood as there have been no systematic studies that have focused on this aspect of the mobile app ecosystem. An investigation of app metamorphosis that focuses on the char- acteristics and prevalence of app metamorphosis will provide further insights into how the mobile app ecosystem is evolving. Moreover, such a study will help app market operators to iden- tify different forms of app metamorphosis and their impact on the apps and enable developers to understand the implications of the actions. It is also important to understand how successful or unsuccessful the apps that underwent metamorphosis are. This will provide insights to the app developers to make decisions on app updates and monetisation strategies. Finally, there can be privacy and security implications because of these app transformations.\nTo this end, in this paper, we compare two snapshots of the Google Play Store that are five years apart and propose a"}, {"title": "II. RELATED WORK", "content": "Various empirical studies have been conducted on Google Play Store and other app stores focusing on different aspects such as; general statistics related to apps [4], [5], advertising and analytics library behaviours [6], [7], characterising and detecting malware and malpractices [8], [9], [10], [11], [12], [13], and privacy and security analysis of one specific type of apps [14], [15]. However, only a limited amount of work focused on studying the evolution of apps over a longer time period.\nApp life cycle in Google Play - The usual life cycle of an app in Google Play Store involves the developer publishing the app by selecting some of the metadata such as category, content rating, and self-reporting data collection and sharing practises [16], [15]. Once it is published, the app will be updated periodically to release new features or fix bugs. The vast majority of the apps will continue to be like this; however, some apps may get discontinued (i.e., no further updates), removed from Google Play Store (i.e., either developer decides to remove the app, or Google removes the app or ban the devel- oper for various reasons [17]) or go through \u201cmetamorphosis\u201d which is the focus of this paper.\nTo date, the app life cycle has been characterised pre- dominantly from an app update point of view. For instance, Pothuraju et al. [18] claim that nearly 76% of apps did not get any update in Play Store within their monitoring dataset for a period of approximately six months while a minority got nearly hundreds of updates which may point to newly released apps that could require many bug fixes. Though these updates are supposed to fix bugs or provide better security, Moller et al. [19] noted that even after a week of an update, app users still tend to use the older version. Vincent et at. [20] used PlayDrone [4] to extract permission usage of apps and observed that popular apps request additional dangerous permissions with subsequent updates.\nAnother body of work checked how some individual app libraries, such as advertising and analytic libraries, are being updated [21], [22]. However, in all these cases, the apps do not go through \u201cmetamorphosis\", and app developers remain the same. We also note that the app life cycle we consider in this paper is different from the app life cycle considered by some works [23], [24], which focus on the app usage point of view, such as when a user installs an app, and abandon it after using it for a period of time.\nDisguising (or misleading) app users Beyond malware, multiple works explored various disguises and malpractices happening in Google Play Store. Such work is related to ours because when detecting \"app metamorphosis\", we can incur\""}, {"title": "III. DATASETS", "content": "We use two main datasets in our work. These are two snapshots of the Google Play Store, collected in 2018 and 2023, respectively. They contain app metadata (e.g., app ID, app name, app category/genre, app description, developer name, etc.), app creatives (e.g., app icons and app screenshots), and for free apps, APK app executables. The 2018 dataset that was collected as a part of our previous work [28] contains metadata of over one million apps that were collected between January and March 2018. The 2023 dataset contains metadata of 1,280,142 apps and was collected between January and November 2023. The data was collected using a Python-based crawler that started from an initial seed of apps, sourced by various top-lists in the Google Play Store progressively discovering new ones. To avoid any disturbances to the app market operation, we conducted our crawl conservatively at a low rate.\ni) Top-k apps in 2018 and 2023 datasets - Our key objective in this work is to identify apps that went through notable re-transformations between the two snapshots. To get better insights and to avoid low-quality apps affecting our results as noise, we focus only on the top-k apps in the 2018 dataset and their relevant counterpart in 2023. To identify the top-k apps in each dataset, we use the same method proposed by [17] in sorting the datasets. That is, we sort the set of crawled apps in a dataset (either the 2018 dataset or the 2023 dataset), first based on the number of downloads, second based on rating count, and third based on the average stars and select the first k apps. Next, we constructed a 'validation-set' and a 'test- set' to fine-tune hyper-parameters of the app similarity search algorithm and to evaluate the performance. We discuss our search algorithm later in the Sec. IV.\nii) Validation-sets - When we are searching for a counterpart app between the two datasets, there may be or may not be a matching app. For example, an app may have been discontinued. To properly capture this idea, there must be ground-truth sets on matches and no matches to fine-tune our algorithm; therefore, we create two validation-sets."}, {"title": "IV. SIMILARITY SEARCH ALGORITHM", "content": "Our objective is to identify a 2023 counterpart app for a given 2018 app (a 'match') or else to return a 'no-match' if such an app does not exist. We follow a multimodal search mechanism to obtain the mappings between the two datasets, and we specifically do not rely on app ID matching in this process. The reason is that metadata-based matching allows us to identify cases of metamorphosis better and to observe whether the developers continued with the same app ID or introduced a new identity.\nOur methodology consists of four main steps. i) obtain neural embeddings for app icons and app descriptions, and TF-IDF vector representations for app names and developer names, ii) for a given app, retrieve a set of nearest neighbour apps considering each modality, iii) perform modality-wise majority voting to obtain the top-candidate apps for a given app. iv) decide if we could select an app as a 'match' from the candidate app list (further discussed in Sec. IV-D) or else decide it as a 'no-match'. We show the end-to-end pipeline of the proposed method. In the figure, we use the query app's embedding representations to retrieve results as search keys and the retrieved results (more specifically, retrieved app IDs) as values. The following subsections explain these steps in detail.\nA. Representation of different modalities\nAs inputs for the search methodology, We use metadata extracted from the Play Store and more specifically, they are app icon, app description, app name and developer name for both datasets 2018 and 2023. We selected these based on the prior work and our own investigations on the available metadata that are in spotlight for target app users. For example, developers use same name to maintain brand consistency for their apps, compared to the developer email, which is often not publicly available and developers might use different email addresses for different apps to avoid confusion.\n1) App icon embeddings: The app icon serves as the initial point of visual engagement for users, often functioning as a distinctive trademark representing the developer's brand identity. Therefore, a matching pair of apps is likely to have a similar visual 'styling' and similar 'content' information, emphasising the need to encode both such information. StyTr2 introduced by [31] is a popular transformer-based framework with style and content encoders, both producing output embeddings of the shape (1\u00d7512). Additionally, we experiment with vision transformer content encoder embeddings [32] as well as style and content embeddings from VGG19 architecture as proposed in [28]. We identify which style and content embed- ding combination produces the best results for both 'matches' and 'no-matches' by evaluating possible combinations against our validation dataset.\n2) App description embeddings: Despite large language generative models being popular, text embedding transformer models, due to their unique encoding capabilities, allow us to obtain rich vector representations for text sequences [33]. Therefore, we use the MPNet [34] model to encode the long app descriptions into the vectors, $v_d$ of shape (1\u00d7768). MPNet is a language model similar to BERT [35] and allows to obtain vector representations of text. It considers masked language modelling such as BERT and permuted language modelling such as XLNet [36] in a unified view and thus inherits the advantages of both methods.\n3) App name and Developer name embeddings: Since the app and developer names have limited meaningfulness as natural language, as well as they are very short texts, we employ TF-IDF vectorisation to encode app names and developer names instead of using MPNet embeddings. We represent each app and developer name as a vector of size (1\u00d74,096) where the vocabulary contains 4,096 most frequent 1-4 grams when 200,000 app descriptions were used to build the vocabulary.\nB. Nearest neighbours of each modality\nIdentifying potential apps that underwent \u201cmetamorphosis\" involves taking a query app from the top-10,000 apps in the 2018 dataset and identifying the most similar app (if there is any) among the 1,280,142 odd apps in the 2023 dataset. This requires identifying close apps along each modality presented in Sec. IV-A using nearest neighbour search. However, the vanilla version of the nearest neighbour search is highly inefficient here because of the larger queried set, the number of modalities, and the sizes of the embeddings.\nInstead, we use the indexing options provided in the Faiss library [37] to create an Inverted File Index of the queried embeddings to narrow the search scope. First, we create sharded indexes for small batches of embeddings, and we build the final index on disk by merging sharded indexes into one larger index. We created five such indexes for each modality (represented by an embedding type; app icon - content, app icon - style, app name, app description and developer name), and they are queried for nearest neighbours using the query app's embeddings.\nFor a single query, we obtain five different nearest neighbour sets corresponding to the five modalities we consider in the descending order of the similarity with the query app's embedding vectors.\nC. Majority voting\nStarting of the app similarity search algorithm is a majority voting scheme based on four modalities (we have excluded the 'developer name' to be discussed later). \nIn each iteration, we select the app that has the most number of occurrences in each row-wise-position as the most common result. In the figure, each of these selections are visualised in the grey colour box.\nAs shown , in step 1, app B is selected as the most common occurrence since it appears as the top choice in two separate modalities (occurrence count = 2). Then the remaining apps (A and C) from that position are carried forward to the next iteration. This ensures all potentially similar apps are considered in subsequent row-wise-positions to be iteratively repeated. As shown in step 3, we exclude app D from the selection space since it has already been selected in the second position. When multiple apps appear with the same frequency, we make a random selection. Step 4 indicates this by randomly selecting app M, while both M and N have equal number of occurrences. The final output is the list of nearest neighbours (vertical list in grey colour) and their corresponding occurrence count for a given query app.\nNote that we handle developer names in a slightly different way as step number 5 that is not shown in . Since some developers publish more than one app, if we use the developer name as a modality in the neighbour search, the result with the highest occurrence count may not be the desired matched result. For example, if we have the same developer for app X and app Y, then there is no straightforward way to mention X and Y both in the same position in the app developer neighbour list. Therefore, for each row-wise- position, we check the app with the most occurrence count (e.g., app B in step 1) is developed by the same developer of that row-wise-position's app-developer modality result. If so, we consider it as a modality match and add one more to the occurrence count (e.g., app Z in app-developer modality position is the same developer as app B, then we add 1 to the occurrence count in step 1). We only change the occurrence count list (if applicable) in this step.\nD. Match or No-match?\nUpon retrieving the list of nearest neighbour apps for a given query app, we identify a matching app as the first neighbour app in the list's descending order that agrees with following two criteria.\n\u2022\nWe define a hyper-parameter $\\alpha$ such that the number of modalities that contributed for an app to be selected as a nearest neighbour (i.e., the occurrence count) should be equal or greater than $\\alpha$. We call this hyper-parameter as 'occurrence count threshold'.\nWe calculate the change of star rating count, representing the number of users who have rated the app, between the neighbour app and the query app. It should be positive. Our intuition here is that a matching app should have grown in the rating counts over the past five years.\nHowever, if all the apps in the nearest neighbour search list show a negative star rating count change with respect to the query app, then we only consider the first criteria. But, if no app satisfies the first criteria, we denote it as query app not having a match. The threshold value $\\alpha$ is selected based on an ablation study we conducted, and we discuss this . It is also worth noting here that having a no-match result does not mean that we exclude that particular app from metamorphosis analysis. We further utilise them to identify and analyse interesting transitions of apps .\""}, {"title": "V. PERFORMANCE ANALYSIS OF APP SIMILARITY SEARCH", "content": "In this section, we evaluate the similarity search algorithm based on the validation and test sets described in Sec. III. To summarise, when we are using the validation-set for identifying 'matches', then we have 500 query apps from 2018 to be matched to a counterpart app among 5000 apps in 2023 dataset. When we are identifying 'no-matches', we query the same 500 apps from 2018 to be 'not-selected' among the 4500 in 2023 dataset because the matching 500 apps of 2023 are removed in this setting. Test-sets are used to observe the performance after the hyper-parameters are selected and they work in a similar setting too; 100 apps in 2018 to match among 1000 total in 2023 for 'matches' and the same 100 apps among 900 in 2023 for 'no-matches'. Next we will discuss what are the hyper-parameters we validate our model with. We make two hyperparameter choices based on the performance on the validation set.\n\u2022\nWe explore six different combinations of style and con- tent embeddings.\n\u2022\nWe explore five different occurrence count thresholds ($\\alpha$\nvalues) from 1 to 5.\nWe evaluate a occurrence count threshold, $\\alpha$ for each embedding combination and report the harmonic mean of the two scenarios. We show the results in Table I. As can be seen, the combination of StyTr\u00b2 content embeddings and VGG19 style embeddings produce the best performance at the voting threshold $\\alpha$ = 3. We used this hyperparameter combination to obtain the main results of the paper.\nWe also observe that the accuracy of the no-match scenario increases when we increase the thresholds. This is expected because as we increase the thresholds, the number of modali- ties an app should be included to select as a match increases. On the other hand, the accuracy decreases with the increased thresholds when there is a match. This happens because, as the threshold increases, an app should be included in more modalities in order to be selected as a match, therefore, the conditions become more restrictive. The following subsections describe the performance metrics we use and the performance of the test set.\nA. Performance metrics\nWe measure the performance of our method on test set and compare with an existing baseline using accuracy, precision@1 and recall@1 matrices.\n1) Accuracy: We take the harmonic mean of the accuracies when there is a match and when there is no-match. We use harmonic mean instead of the arithmetic mean because we need accuracy in both scenarios to contribute equally.\n2) Precision and Recall: We define Precision and Recall based on the following definitions. For a match scenario, there can be i) a correct match (true positive), ii) an incorrect match (false positive), and iii) no result when there is a correct match available (false negative). Note that there are no true negative occurrences since we are considering matches and no-matches separately. We define the Precision and Recall for a match scenario as in Eq. 1 and Eq. 2.\n$\\text{Precision} = \\frac{\\text{True Positives}}{|\\text{True Positives}|+ |\\text{False Positives}|}$ (1)\n$\\text{Recall} = \\frac{\\text{True Positives}}{\\text{True Positives}| + |\\text{False Negatives}|}$ (2)\nFor non-match scenarios, the algorithm can output either no match (True Positive) or an incorrect match (False Negative). Therefore we define only Recall for the non-match as defined in Eq. 2. Note that Recall and Accuracy are similar for the no-match scenario.\nWhen we report our results as precision@1 and recall@1, we only consider the first matching result for each method when calculating scores.\nB. Performance analysis\nWe compare our method with the method proposed by Karunanayaka et al. [28]. In [28], the authors proposed a nearest neighbour search for the weighted sum of each em- bedding, including the app icon (style and content) and app description. We adapt their method using $\\alpha$, $\\beta$, $\\theta$, $\\gamma$ and $\\delta$ [28] as the weights for image content embeddings, image style embeddings, developer name embedding, app description em- bedding and app name embeddings, respectively. In addition to those weights, we use an additional threshold parameter to decide the apps that do not have any matching apps. Then, we choose the optimal values for those weights and the threshold using the Bayesian optimisation [38] on the validation dataset considering the integer values between 1 and 10. We report the results for the best-performed values of $\\alpha$, $\\beta$, $\\theta$, $\\gamma$, $\\delta$ and the threshold and results for our method in Table II.\nAs can be seen from the results, our method provides better results when the app is included within the search space (i.e., with matches). Conversely, the method proposed by [28] demonstrates higher accuracy for no-matches. Nonetheless, [28] becomes infeasible to use when the queried dataset and the number of search keys are larger, given that it uses a brute force approach, comparing the search key with embeddings of all apps in the queried data multiple times for different types of embeddings.\nC. Success score\nWe introduce 'success score' (SS) as a parameter that we can use to evaluate the performance of each app progressing from 2018 to 2023. In high-level, we expect a positive SS to indicate an app that has been performing well such that there is no risk of that app going obsolete and a negative SS to indicate an app not performing well.\nThe success of an Android app could intuitively be associ- ated with the number of downloads and the number of ratings it received from the app users, both ultimately impacting the direct and in-direct revenue incoming to the developers. However, an increase in these counts does not necessarily mean an app is performing better due to the natural growth of the Android user base over a period of time: 2.3 billion worldwide devices in 2018 to approximately 3.6 billion in 2023 [39], [40], [41].\nConsidering this factor, we define the Success Score (SS) for an app based on the Compound Annual Growth Rate (CAGR) of downloads and ratings offset by the natural growth in the Android ecosystem over a time span of t years. As specified in Eq. 3, when we calculate $CAGR_{\\text{#downloads}}$, the term $N_{\\text{initial}}$ is the download count of 2018 app, $N_{\\text{final}}$ is the download count of counterpart 2023 app and t = 5 years. $CAGR_{\\text{#ratings}}$ is similarly calculated based on the star rating count and $CAGR_{\\text{#Andro}}$ is calculated based on the increase of android devices over the five years, 2.3B to 3.6B.\n$\\text{CAGR} = (\\frac{N_{\\text{final}}}{N_{\\text{initial}}})^{\\frac{1}{t}}-1$ (3)\n$\\text{SS} = \\frac{1}{2} \\text{CAGR}_{\\text{#downloads}} + \\frac{1}{2} \\text{CAGR}_{\\text{#ratings}} - \\text{CAGR}_{\\text{#Andro}}$ (4)\nAccording to the Eq. 4, SS value of x indicates that the aver- age number of downloads and user ratings have increased x% better than the average growth of android eco-system growth per year. Moving forwards, we discuss SS as a percentage (e.g. SS=0.145 is interpreted as 14.5%) for convenience."}, {"title": "VI. CHARACTERISATION OF APP METAMORPHOSIS", "content": "In this section, we provide a characterisation of different types of metamorphosis categories listed . We explain how to identify each category using our search methodology, analysis and insights on the causes and effects of metamor- phosis, followed by interesting examples.\nFirst, we use our search algorithm on the top 10,000 apps from the 2018 dataset (Fig. 5a) to identify their corresponding apps among the 1.3 million apps in the 2023 dataset (Fig. 5b). \nFirst, we check if our algorithm gives a match or a no-match. If it is a match, we observe if the app ID in 2018 is identical to the app result we get in 2023. If they are not identical (i.e., 2018 app ID \u2260 2023 app ID), then we check whether the 2018 original app ID exists in the 2023 dataset; if it exists, we analyse them further. Lastly, for any of the 2018 top 10k apps that our algorithm gives no-match, we check again if those 2018 app IDs exist in the 2023 dataset and analyse further.\nA. Summary of mappings\nAs shown , a total of 4,518 apps get a match in D23 having the same app ID between the two datasets (blue arrow). Nonetheless, only 61.6% of them are still among the Top 10k of D23. The rest were mostly in between the top 10k and 50k. We observe an average success score (SS) of 10.01% for these 4,518 apps, and this score is more influenced by download count (~20% more contribution) rather than user rating. These apps are likely not to have gone through drastic transformations as our algorithm has already returned a match, and the app IDs are the same between the two datasets. We use their SS numbers as the baseline to compare with the SS numbers of different metamorphosis categories.\nWe observe 298 apps that our algorithm matched, without the same app ID among the matching pairs (teal and purple arrows). They suggest that the original app continued to 2023 with a different identity, which we identify as a potential re- birth that is discussed later in Sec. VI-B. Out of those 298, 116 had the same app ID linked to other apps in the 2023 dataset (green arrow) that our algorithm did not find as similar. Furthermore, there are 2,070 other examples in the 2018 dataset initially returned again as no-matches, but the same app ID exists in the 2023 dataset (yellow arrow). Both of these scenarios suggest that the developer has decided to re-brand or re-purpose those apps, resulting in major changes to the app description, name and app icon; hence why our methods did not match them. We discuss this further in Sec. VI-C and Sec. VI-D.\nWe also discuss other interesting adaptations by the app developers, such as changes in the genre, content-rating, revenue-model and developer-transitions. Furthermore, devel- opers might opt to keep multiple versions of the same app or could develop apps targeted at particular user demographics. We discuss them in detail in Sec. VI-E to Sec. VI-J.\nFinally, there are 3,114 apps, for which our method gives no matches, and the same app IDs are no longer present in D23 (orange arrow), indicating either the developers have discontinued those apps or they have been removed by Google (e.g. due to spamming [17]). When an app is discontinued, it is likely caused by the applications of such apps no longer being required or being replaced by progressive versions. Majority of these discontinuations were from tech giants such as Google, Samsung, HTC or from popular game developers such as Gameloft, and Electronic Arts."}, {"title": "B. Re-born apps", "content": "Re-born apps are characterised by their initial discontinu- ation, followed by a reappearance where either the original developer or a new one reintroduces the same app concept.\nIdentification: We select matched apps from the similarity search where the 2018 app ID is different from the 2023 app ID. We found a total of 298 belonging to this condition (cf. Fig. 5: 116 in purple and 182 in teal). We further filter them by selecting the apps with a release day in D23, which is later than the last update day in D18, and obtain 88 potential apps for re-birth. We manually validated these 88 apps and found that 74 of them (84.1%) are indeed actual re-births, indicating our identification method works.\nAnalysis - Because of the app ID change, any market presence the 2018 app gained is discontinued and the new app has to start afresh. As a result, the average success score (SS) for an app in this category is -14.81%, and they struggle to be within the top 10k category in D23 as further illustrated in Fig. 5 with only 20.4% of the apps represented by purple and teal colours are in the top 10k of 2023. We note the following observations while analysing the re-born apps.\n\u2022\nIn , we plot the cumulative distribution function (CDF) of SS scores of re-born apps. It further shows that the success of re-born apps is inferior compared to the baseline SS-CDF of nearly 5,000 matched apps between the datasets, which remain in the top 10k (cf. Sec. VI-A). Here, we also observe that nearly ~ 70% of apps in re- born category have a negative SS compared to ~ 32% in the baseline CDF.\n\u2022\nDespite the negative average SS in this category, 30.13% of apps such as, Bowmasters, MONOPOLY, VLC for Android have managed to recover (SS>0) and even build upon their user base and ratings within or less than five years time span.\n\u2022\nGames are often (~ 27%) re-introducing the progressive versions as re-births. An already established user base would actively follow newer versions, therefore contribut- ing to pushing the SS towards a positive value. This allows the developers to discontinue the old version after the transition period to reduce the maintenance cost of multiple apps. Changing the original app to a newer version while re-birthing the former using a new app ID is very rare. But we observed one such example as shown \n\u2022\nWe identify that sometimes developers change their orig- inal app into a totally new type of app using the same app ID (i.e., re-purposed - discussed more in Sub.Sec. VI-D). However, they do not want to discontinue their original app to keep the revenue stream. They get a new app ID and introduce the original app again, which is a re- birth. For example, AppLock@DoMobile changed their AppLock Theme Nightclub app to a game called Block puzzle and re-introduced the AppLock Theme Nightclub under a different app ID \n\u2022\n29.5% of manually verified re-births happen with devel- oper name changes. Even if the app name, description and visual data allow us to verify them as the same app being re-introduced, a malicious actor could easily employ the same strategy and introduce counterfeit apps as re-births when one app gets discontinued. This puts even a tech- savvy user in a vulnerable position as Google Play Store does not provide the history of an app developer. We further discuss this in Sec. VII.\nExamples - We have identified notable apps while observing this category, including Uno [42] and Flickr [43] . In both of those examples, the original app lost the existing user base as the app ID was discontinued. However, different developers re-introduced very similar apps without a major change in the functionality. In 2019, SmugMug acquired Flickr from the former owner Yahoo and reintroduced it as a new app with significant changes. However, the SS of the app is -38.8%, indicating that it experienced a significant loss of its user base during this transition. Conversely, the Uno app has a positive SS of 0.7%. Despite a decrease in its rating count, as reflected by a $CAGR_{\\text{ratings}}$ of -0.3%, games like Uno naturally has a high demand, evidenced by $CAGR_{\\text{downloads}}$ of 20.2%."}, {"title": "C. Re-branded apps", "content": "Some apps in Google Play can stagnate after a while because they no longer attract new users, stalling the growth of app-related revenue. In such settings, a developer may opt to change an app's outlook drastically, fine-tune some degree with features or perhaps may opt to transfer/sell the app to a new developer, again resulting in drastic changes to the app according to new ownership. We identify this change as app re-branding.\nIdentification: We select non-matched apps from similarity search where the 2018 app ID still exists in 2023 dataset . A re-branded app could potentially have changed in the outlook (app icon, visual style and colour schemes, app name) but should have a similar context in the app description. (A drastic change in app description indicates that the app may have been re-purposed rather than re-branded). Therefore, we further filter previous results by selecting the apps with app name and app icon content embeddings having a smaller cosine similarity (< 0.7; i.e., these features are likely changed) and app description cosine similarity being higher (>0.4; i.e., still the descriptions remain relatively unchanged) between 2018 and 2023 counterparts.\nAnalysis: From previous criteria, we retrieved 322 apps that potentially underwent re-branding. Since we know the app ID"}, {"title": "D. Re-purposed apps", "content": "Contrary to what is discussed before, some apps may experience quite a significant loss of interest over time and may no longer provide useful services to the user base. For example, rapid developments in the Android operating system could cause many popular apps such as camera, file management, battery optimisation and other utility apps to become obsolete quickly. The developers may want to relaunch them by overhauling the original functionality; we call them"}]}]}