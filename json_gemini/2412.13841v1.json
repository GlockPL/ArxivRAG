{"title": "AI PERCEPTIONS ACROSS CULTURES: SIMILARITIES AND DIFFERENCES IN EXPECTATIONS, RISKS, BENEFITS, TRADEOFFS, AND VALUE IN GERMANY AND CHINA", "authors": ["Philipp Brauner", "Felix Glawe", "Gian Luca Liehner", "Luisa Vervier", "Martina Ziefle"], "abstract": "As artificial intelligence (AI) continues to advance, understanding public perceptions\u2014including biases, risks, and benefits-is critical for guiding research priorities, shaping public discourse, and informing policy. This study explores public mental models of AI using micro scenarios to assess reactions to 71 statements about AI's potential future impacts. Drawing on cross-cultural samples from Germany (N=52) and China (N=60), we identify significant differences in expectations, evaluations, and risk-utility tradeoffs. German participants tended toward more cautious assessments, whereas Chinese participants expressed greater optimism regarding Al's societal benefits. Chinese participants exhibited relatively balanced risk-benefit tradeoffs (\u03b2 = -0.463 for risk and \u03b2 = +0.484 for benefit, r2 = .630). In contrast, German participants showed a stronger emphasis on AI benefits and less on risks (\u03b2 = \u22120.337 for risk and \u03b2 = +0.715 for benefit, r2 = .839). Visual cognitive maps illustrate these contrasts, offering new perspectives on how cultural contexts shape AI acceptance. Our findings underline key factors influencing public perception and provide actionable insights for fostering equitable and culturally sensitive integration of AI technologies.", "sections": [{"title": "1 Introduction", "content": "While the origins of Artificial Intelligence (AI) date back several decades (Hopfield 1982; Rumelhart, G. E. Hinton, and Williams 1986; McCarthy et al. 2006), development accelerated due to increased computing power, availability of training data (Deng et al. 2009), improved algorithms and Deep Learning (DL) (Lecun, Bengio, and G. Hinton 2015), and a surge in funding (Statista 2022). Many real-world-applications emerged and examples of AI applications include its use in education (L. Chen, P. Chen, and Z. Lin 2020), healthcare (Amunts et al. 2024), journalism (Diakopoulos 2019), farming (Holzinger et al. 2024), as well as manufacturing and production (Brauner, Dalibor, et al. 2022). All of which promise societal benefits in terms of efficiency, innovation, and convenience but, at the same time, raise fundamental concerns, including risks related to privacy infringement, job displacement (Acemoglu and Restrepo 2017), and ethical challenges for both individuals and society as a whole (Awad et al. 2018)."}, {"title": "2 Related Work", "content": "The related work is structured as follows: First, we introduce the psychometric model used for measuring individual risk and utility perceptions within our study which is widely adopted in the field of technology perception in general. Second, we provide a brief overview on studies on the public perception of AI. And third, we present studies on culture differences in AI perception, with a focus on works addressing Germany and China."}, {"title": "2.1 Risk Perception and the Psychometric Model", "content": "Individual risk and benefit perceptions influence attitudes, usage intentions, or actual behaviors (Witte and Allen 2000; Hoffmann, Post, and Pennings 2015; Huang, Dai, and Xu 2020). Risk can be conceptualised from two perspectives (Fischhoff et al. 1978; Aven and Renn 2009): On the one hand, risk can be modelled as the likelihood of negative events multiplied by the severity of the negative consequences (that is expected values). However, difficulties arise if probabilities and consequences cannot easily be modelled for complex and multifaceted fields, such as the potential"}, {"title": "2.2 General Public Perception of AI", "content": "Research indicates a dynamic and multifaceted landscape of attitudes and perceptions of AI that are shaped based on time, usage context, cultural background, and individual differences. Given the breadth of tasks and domains affected by AI, providing an exhaustive account of public perceptions, especially concerning risk-utility tradeoffs, is challenging. Further, the unprecedented adoption of ChatGPT following its public release in 2022 (Hu 2023) has further intensified scholarly interest in AI. Consequently, we will give a brief but necessarily incomplete overview of this rapidly evolving field that has yet to be consolidated.\nFor instance, Fast and Horvitz (2017) examined three decades of AI coverage in the New York Times, highlighting a marked increase in public interest in AI after 2009. Their findings revealed a blend of optimism and concern, with AI generally portrayed in a more favorable than unfavorable light. More recently, however, anxieties regarding loss of control and ethical challenges have become increasingly pronounced, contrasting with continued optimism, particularly regarding AI's potential in healthcare.\nPublic surveys suggest that general population often lacks an understanding of AI's technical achievements and lim-itations, leading to misconceptions about its functions and potential risks (Ipsos 2022). Research also indicates that public concern regarding the ethical use of AI is increasing, particularly as awareness of biased algorithms and dis-criminatory outcomes has risen (O'Neil 2016).\nA study from the UK investigated common narratives about AI and identified four pessimistic and four optimistic themes (Cave, Coughlan, and Dihal 2019). It suggests that AI is often linked to anxiety, as only two of eight identified narratives outweighs the benefits over the concerns (such as the idea that AI could make life easier). Further, partici-pants reported to feel powerless over AI as developments in the realm of AI are driven by government and corporate interests. Only half of the respondents could provide a plausible definitions of what AI is, while a quarter thought AI is equivalent to robots.\nTwo different studies addressed the perception of AI in each country individually. In Germany, public perception of AI is marked by a mix of admiration for its potential and fear of its risks, particularly cybersecurity threats. Many view AI as a \"black box\", leading to uncertainties and biased control beliefs (Brauner, Hick, et al. 2023). Germans tend to have a cautious approach, with lower trust in AI correlating with a perception of higher risks and lower likelihood of positive impacts. This cautious stance is reflected in the need for promoting AI literacy to facilitate informed decision-making (Brauner, Hick, et al. 2023). Cui and Wu (2019) investigated the link between media usage and perception of AI in China. The study measured several factors including media usage frequency, risk perception, benefit perception, policy support, personal relevance, and perceived knowledge. It found a strong public support for AI and the perception of Al's benefits generally outweighs the perceived risks. In the study, media usage was only linked to benefit perceptions; which may be due government controlled media that portrays AI in a positive light Interestingly, personal relevance reduced media influence, fostering more critical perspectives among individuals highly engaged with AI."}, {"title": "2.3 Culture and AI and Technology Perception", "content": "Grassini and Ree (2023) shows that cultural backgrounds significantly shape attitudes towards AI. For instance, indi-viduals from the UK and USA exhibit distinct patterns in perceiving AI as either a threat or a benefit, influenced by their cultural contexts, age, and gender. A recent study examined how generative artificial intelligence (genAI) aligns with values across countries (Globig et al. 2024). Findings showed that people felt genAI fell short of their desired outcomes. Perceptions of alignment differed by region: Western countries were generally more sceptical and perceived"}, {"title": "3 Method", "content": "The aim of this study is to explore how culture influences public perceptions of AI and whether individuals from different cultural backgrounds have similar or differing expectations, valuations and risk-utility tradeoffs in regard to AI. As AI and its implications is a wide and complex field, we did not focus on a single AI-application but rather on a wide range of differing topics. We created a survey for participants from Germany and China that captured the perception of AI across a wide range of topics using micro scenarios as well as a set of demographic and exploratory user variables."}, {"title": "3.1 Capturing AI Perception using Micro Scenarios", "content": "The survey asked participants to assess a randomized random subset of 15 out of 71 micro-scenarios (Brauner 2024). Each micro scenario is a brief statement on potential AI developments, capabilities, or impacts in the next decade that is evaluated on the same four outcome variables."}, {"title": "3.2 Demographics and Exploratory Personality Traits", "content": "Besides the micro scenario evaluations, the survey also queried the participants demographic and explanatory user factors. For the demographics, we asked for the participants' country of origin, age in year, and gender (male, female, diverse, or no answer (Spiel, Haimson, and Lottridge 2019)) as well as their highest educational attainment and current employment.\nSince technology can be perceived as a social actor (Reeves and Nass 1996; Fogg and Tseng 1999), we hypothesized that trust would influence the overall evaluation of AI. Therefore, we measured interpersonal trust using the three-item KUSIV3 scale (Nie\u00dfen, C. Beierlein, et al. 2021). The scale shows strong psychometric properties while being quick to administer at the same time. We further measured the participants' technology readiness (or technology commitment) using a subset of items from the Technology Commitment Scale (Neyer, Felber, and Gebhardt 2016). This describes an individual's tendency to embrace and effectively use new technologies. We hypothesize that this trait positively influences attitudes towards AI. Additionally, we measured the participants willingness to take or tolerate risks on the single-item Risk Proneness Short Scale (R-1) (Nie\u00dfen, Groskurth, et al. 2020). We propose that risk proneness is associated with the perceived risk of AI and may negatively impact the overall evaluation of AI. Lastly, we also administered the General Attitude towards AI scale (GAAIS) with its positive and negative sub scales (Schepman and Rodway 2022) to study how an overall AI assessment relates to the evaluation of many different applications of AI. Figure 1 illustrates the design of the survey."}, {"title": "3.3 Sample Acquisition", "content": "To recruit participants for this survey, we used our personal social networks and asked for forwarding the survey link to others (convenience and snowball sampling). One Chinese graduate candidate provided significant assistance by disseminating the survey to friends, colleagues, and family members.\nAll data is available for interested scholars, see below."}, {"title": "3.4 Scales", "content": "In addition to age and gender, we assessed four explanatory user variables using established scales. Except for the scale measuring interpersonal trust (KUSIV3, \u03b1 = .540), all other scales demonstrated good to very good internal reliability. The technology readiness scale had a reliability of a = .723, the positive subscale of the General Attitude towards AI (GAAIS-pos) showed very good internal consistency (a = .800), and the negative subscale (GAAIS-neg) also exhibited high reliability (a = .770)."}, {"title": "3.5 Data Cleaning and Analysis", "content": "In total 188 people from 28 different countries participated in the study. Based on our sampling method, the majority came from China and Germany, but we also had participants from India, the United States, and Great Britain.\nWe filtered the data for non-matching participants (excluding participants from other countries than Germany or China) and incomplete, or low quality responses based based on a) the participant must have completed the full survey b) the participant is not classified as a speeder (less than 1/3 of the median survey duration of 9.6 minutes); the latter is usually considered sufficient for detecting meaningless data (Leiner 2019)).\nAfter filtering, the resulting dataset consists of 112 surveys. The filter rate of 41.5% is typical for voluntary and unrewarded surveys, especially, as we had to exclude participants from other countries.\nWe analyzed the data using both parametric and non-parametric methods, including Chi-square (x2) tests, Bravais-Pearson correlation coefficients (r), Multivariate Analysis of (Co-)Variance (MAN(C)OVA), and (Hierarchical) Mul-tiple Linear Regressions. For the omnibus MANOVA/MANCOVA tests, we used Pillai's trace (V) as the test statistic. We also assessed the assumptions underlying each test and report any violations. Missing responses were deleted on a test-wise basis. In line with common practice in the social sciences, we set the Type I error rate at 5% (\u03b1 = .05) for statistical significance. All data and associated calculations are publicly accessible through our data repository (see the data availability statement)."}, {"title": "3.6 Sample I \u2013 China", "content": "The first sample consists of 60 participants (52.7% of the whole sample) reporting being from China. The age of the participants ranged from 18\u201361 years with a median age of 28 years. 16 participants reported being male, 41 reported being female and 1 person preferred not to disclose their gender identity. The sample is fairly educated with 50.0% (29) holding a Bachelor's, 27.6% (16) holding a Master's, and 10.3% (6) a PhD degree.\nNone of the explanatory factors showed a significant association with the demographic variables age or gender. The largest observed correlation was between age and GAAIS-Neg (r = .343); however, this correlation was not statisti-cally significant (p = .083)."}, {"title": "3.7 Sample II \u2013 Germany", "content": "The second sample consists of 52 participants (47.3%) reporting being from Germany. The age ranged from 18-75 years with a median age of 25 years. 29 participants reported being male, 21 reported being female, and 2 preferred not"}, {"title": "4 Results", "content": "The results section is structured as follows. First, we analyse the differences between both samples in terms of the explanatory variables. Second, we investigate if and how the country of origin influences the overall AI expectancy and valuation, as well as the perceived risk and benefits, followed by a brief presentation of the highest/lowest evaluated topics for each sample and dimension. Next, we analyse how the topic evaluations are interrelated and analyse the risk-benefit tradeoffs for the samples. Finally, we will explore how individual differences affect the perceptions of AI."}, {"title": "4.1 Differences between the samples in the explanatory variables", "content": "First, we analyse similarities and differences between both samples in terms of the explanatory user variables. Hereto, we calculated a Multivariate Analysis of Covariance (MANCOVA) with the sample as independent variable, age and gender as covariates, and the exploratory variables General Attitudes towards Artificial Intelligence (positive and negative), interpersonal trust, technology readiness, and risk proneness as dependent variables.\nOverall, the sample (V = .280, F(5,95) = 7.405, p < .001) as well as gender (V = .239, F(5,95) = 5.964,\np < .001) have a strong and significant effect on the explanatory user factors, with the effect of the sample being stronger than that of gender. Surprisingly, the sample has a significant effect only on reported technology readiness (p < .001), with higher scores for participants from Germany (M = 4.51, SD = 0.60) compared to participants from China (M = 4.06, SD = 0.50). In contrast, gender has a slightly lower but significant influence on most explanatory variables. Specifically, genders differ in terms of interpersonal trust, with women reporting higher trust scores (M = 4.17, SD = 0.70) than men (M = 3.87, SD = 0.89), and in technology readiness, where women report lower scores (M = 4.06, SD = 0.46) compared to men (M = 4.59, SD = 0.63)."}, {"title": "4.2 Cross-Cultural Differences in Overall AI Expectations, Risk Perception, Utility, and Attributed Value", "content": "A MANOVA with the sample as independent variable and expectancy, risk, utility, and overall value as dependent variables shows a significant overall effect (V = 0.415, F(1,104) = 17.06, p < .001) as well as significant individual differences on three of the four dependent variables.\nOn average, in both samples, the expectation that the statements surveyed will materialize in the next decade is above neutral: With an average of 11.9% for the sample from China and an average of 22.2% for the sample from Germany. However, this difference is statistically not significant (F(1,104) = 2.7173, p = .102 > .05). The average risk assessments of the topics of the participants from China is significantly lower (3.5%) than that of the participants from Germany (18.4%) (F(1,104) = 2.717, p = .021)). Further, participants from China evaluate the various projections on the potential impact of AI as significantly more beneficial than participants from Germany. This difference is not only statistically significant but also becomes visually apparent in the analysis of the box and violin plots (2): For the Chinese sample, most of the topics are evaluated from neutral to positive, whereas the distribution of the responses from the German sample are broader and located on both sides of the scale. Also, participants from China report a higher average perceived utility (21.5%) than the participants from Germany (7.1%) (F (1,104) = 6.502, p = 0.012)). Lastly, the average perceived value (or sentiment) of queried topics is significantly higher for participants from China (20.1%) than for participants from Germany (-12.4%) (F(1,104) = 53.628), p < .001)."}, {"title": "4.3 Expectancy", "content": "Although participants from China and Germany do not differ significantly in their overall expectations across all queried topics, there are notable differences in specific AI-related statements. Figure 3 illustrates the expectations that the samples from Germany (y-axis) and China (x-axis) hold regarding AI's capabilities and implications over the"}, {"title": "4.4 Attributed Value", "content": "Next, we analyze how the two samples differ in the average attributed value towards the AI-related projections. Fig-ure 4 presents the average evaluations from the German sample (y-axis) and the Chinese sample (x-axis). The inter-pretation of the points' locations is similar as above.\nAgain, we do not iterate over each individual statement and instead refer to the detailed data in Table 4. However, a key observation is that the regression line runs parallel to but significantly below the diagonal, indicating that participants from Germany report a substantially lower overall sentiment toward the queried topics.\nBeyond these general trends, certain topics reveal notable differences between the two samples. Participants from China evaluated the statements that AI may be misused by criminals (-50.0%), that AI might determine warfare (-33.3%), and that AI could supervise their private lives (-25.0%) the least. For participants from Germany, the statements with the lowest evaluations were that AI knows all secrets (-100.0%, with all participants rating this item with the lowest possible score), that AI may decide about our lives (-83.3%), and that AI may consider humans as a threat (-70.4%).\nParticipants from China rated the proposition that AI will raise the standard of living the highest (71.4%), followed by Al increasing the wealth of many people (63.6%) and making societies more sustainable (63.6%). In contrast, participants from Germany evaluated the statement that AI will explain decisions (75.0%), followed by the expectation that AI will improve our health (54.2%) and promote innovation (52.4%) the highest.\nOutliers with notable discrepancies between participants from China and Germany include views on whether AI ex-plains its decisions (China: 33.3%, Germany: 75.0%), whether AI could develop its own consciousness (China: -6.1%, Germany: +33.3%), whether AI will know personal secrets (China: +16.7%, Germany: -100.0%), and whether AI will become integrated into human bodies (China: +50.0%, Germany: -33.3%).\nFigure 4 suggests two key points: First, evaluations show greater alignment compared to expectations, as indicated by the narrower gray area representing the 95% confidence interval around the regression line. Second, respondents from China appear to hold a more optimistic view on the statements, derivable by the downward shift in the regression line's intercept in the figure."}, {"title": "4.5 Perceived Risks", "content": "In the sample from China, participants rated the statement that AI might control food production with a relatively low risk perception (-40.0%). Similarly, they attributed low risk to the idea that AI could serve as a conversation partner in elderly care (-33.3%) or remain subordinate to humans in working life (-33.3%). On the other hand, they viewed AI supervising private life (40.0%) and surpassing human intelligence (40.0%) as more risky. The highest risk perception in the Chinese sample was that AI could be misused by criminals, which received a risk score of 100.0% (all responded selected the maximum on the scale)."}, {"title": "4.6 Perceived Benefits", "content": "In the Chinese sample, participants attributed the lowest utility to the idea that AI might supervise private life (-37.0%), destroy humanity (-28.6%), or be misused by criminals (-25.0%). They viewed Al as offering significant utility in making society more sustainable (60.6%), optimizing itself (61.9%), and deciding who gets an important financial loan (62.5%).\nIn the German sample, participants found the idea that AI would know personal secrets to have the least utility (-86.7%), followed by AI deciding matters of life and death (-63.0%) or no longer being controllable by humans (-55.6%). They also perceived low utility in AI preferring certain groups of people (-55.6%). However, they rated AI's potential to promote innovation (71.4%), raise the standard of living (71.4%), learn faster than humans (81.0%), and explain its decisions (83.3%) as highly beneficial."}, {"title": "4.7 Topic Correlations and the Risk Utility Tradeoff", "content": "Next, we analyse how the different evaluation dimensions of the topics are related and if both samples differ in the tradeoff between perceived risks and benefits and what contributes to overall attributed value most. For this, we calculated a multiple linear regression analysis to examine the relationship between the perceived value of AI and the two predictor variables perceived risk and perceived utility.\nFirst, we calculated a multiple linear regression with perceived risk, benefit and their interaction as well as the sample indicator as predictors and overall attributed value as dependent variable (Chow 1960)2. The model, including the predictors and their interaction term, explained a significant portion of the variance in value mean (R2 = .812, F(4,137) = 148, p < .001). The significance of the sample indicator suggests that the regression models of both samples are significantly different. Table 2 details the regression model.\nConsequently, we calculated two linear regression for each sample with risk, benefit, and the risk-benefit interaction as predictors and value as dependent variables. For both samples, the models were statistically significant and provided a strong fit for predicting the overall value (sample from Germany: R2 = .839, F(3, 67) = 116.04, p < .001; sample from China: R2 = .630, F(3,67) = 38.09, p < .001).\nFor the sample from Germany, the intercept is negative (-0.103) and significant (p < .001), suggesting a baseline negative value toward AI statements when risk and utility are zero. In contrast, for subjects from China, the intercept is positive (+0.103) and also significant (p < .001), indicating a baseline positive value.\nThe coefficient for perceived risk is negative and significant for both the samples from Germany (\u03b2 = -0.337) and China (\u03b2 = -0.463). This indicates that as perceived risk increases, overall value attributed towards the AI statements decreases across both countries. The larger and negative coefficient for China suggests that perceived risk has a stronger negative impact on value for Chinese participants compared to German participants.\nThe coefficient for perceived utility is positive and significant (p < .001) for both groups: \u03b2 = +0.715 for subjects from Germany and \u03b2 = +0.484 for subjects from China. This indicates that higher perceived utility leads to a more favorable overall value towards AI statements. The effect of perceived utility is stronger for German participants than for Chinese participants, as shown by the larger coefficient for Germany.\nThe interaction term between risk and utility is not significant for either country. This suggests that the combined effect of risk and utility on attributed value does not significantly deviate from their individual effects. Table 2 details all three regression models. Figure 5 illustrates the different risk-utility tradeoffs between the participants from China and from Germany by plotting the risk (x-axis) and utility (y-axis) evaluations for each topic for both samples."}, {"title": "4.8 The Role of Individual Differences on the Perception of AI", "content": "Lastly, we analyse if individual differences influence the assessment of AI. With regards to the associations between the four assessment variables interpreted as an individual user factor, both samples show a similar pattern. First, as for the evaluations of the topics, there is an inverse relationship between perceived risk and utility in both the sample"}, {"title": "5 Discussion", "content": "In this study, we investigated how cultural differences shape the evaluation of AI, by studying the perception of AI of participants from Germany and China as an example. We asked our participants to evaluate 71 statements on the"}, {"title": "5.1 Limitations", "content": "This study is not without limitations. First, we relied on convenience and snowball sampling, yielding a highly educated academic sample for both countries. Although we only sampled a snapshot of the respective populations, we assume that the differences in AI perception will equally emerge in more diverse samples, as both samples are comparable in terms of age and gender, but already exhibit substantial differences in the evaluation of Al's risk, benefits, and overall evaluation.\nSecond, while culture encompasses a wide range of influences, including values, beliefs, social norms, language, and individual experiences, we solely used the country of origin as a pragmatic proxy for culture (Schwartz 2006). Countries typically have dominant cultural frameworks that shape the structures individuals grow up within. Hence, we conclude that our work contributes to the understanding of cultural differences in technology and AI perception, but suggest extending this evidence with a larger, more diverse, and culturally broader sample. In addition, we suggest to include more nuanced cultural aspects in the survey beyond the home country (e.g., Hofstede's cultural dimensions (1984)), to get a better understanding how culture and the factors that constitutes culture affect technology perception and the risk-utility tradeoffs involved.\nA third concern is the under-sampling of the individual topics per sub-group owing to the small sample size. While the individual evaluations of statements and their placement on the maps should be considered with caution, key claims made in the article- i.e., different overall evaluations in terms of risk, utility, and value and differences in the risk-utility tradeoffs-build on aggregations across many statements and across many participants and thus sufficiently many measurements\u00b3 (cf. Bernoulli (1713).\nLastly, the study examined a wide range of AI-related statements across a few dependent variables using micro scenar-ios (Brauner 2024). This method captures heuristic evaluations rather than detailed assessments of benefits, barriers, and implications. As the results show strong and systematic patterns, this suggests reliable measurements and insights into the broader perception of AI and the influence of culture. However, this does not reveal the specific motives behind the evaluations of individual topics. Given Al's impact on individual lives and society, each topic warrants in-depth qualitative and quantitative studies to enhance our understanding. This can help practitioners, researchers, and policymakers better align AI with human needs."}, {"title": "6 Conclusion and Outlook", "content": "While Germans exhibit a cautious and risk-aware attitude towards AI, the Chinese public is more optimistic, which may be influenced by cultural and governmental factors. Understanding these differences is crucial to adapt products and services for the respective markets as well as for developing effective AI communication strategies, policies, and governance.\nEffective public engagement strategies must consider these cultural differences to address specific concerns and pro-mote responsible AI development tailored to each context (Kelley et al. 2021; O'Shaughnessy et al. 2022). Addi-tionally these findings can foster mutual understanding and in turn enable a better collaboration between German and Chinese partners."}]}