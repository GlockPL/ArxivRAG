{"title": "Social Distancing Induced Coronavirus Optimization Algorithm (COVO): Application to Multimodal Function Optimization and Noise Removal", "authors": ["Om Ramakisan Varma", "Mala Kalra"], "abstract": "The metaheuristic optimization technique attained more awareness for handling complex optimization problems. Over the last few years, numerous optimization techniques have been developed that are inspired by natural phenomena. Recently, the propagation of the new COVID-19 implied a burden on the public health system to suffer several deaths. Vaccination, masks, and social distancing are the major steps taken to minimize the spread of the deadly COVID-19 virus. Considering the social distance to combat the coronavirus epidemic, a novel bio-inspired metaheuristic optimization model is proposed in this work, and it is termed as Social Distancing Induced Coronavirus Optimization Algorithm (COVO). The pace of propagation of the coronavirus can indeed be slowed by maintaining social distance. Thirteen benchmark functions are used to evaluate the COVO performance for discrete, continuous, and complex problems, and the COVO model performance is compared with other well-known optimization algorithms. The main motive of COVO optimization is to obtain a global solution to various applications by solving complex problems with faster convergence. The error in the fitness function for the COVO model is 1.23\u00d710-18, which is significantly lower than the error values achieved by other existing models: EHO at 4.38\u00d710-8, SSA at 10.12, SSO at 4.05\u00d710-10, SFO at 26.5, BOA at 4.20\u00d710\u22129, BWO at 3.58\u00d710-5, SMO at 1.04, CVOA 2.95\u00d710-8, SRO 2.40\u00d710-8, and GBRUN 13.27. At last, the validated results depict that the proposed COVO optimization has a reasonable and acceptable performance.", "sections": [{"title": "I. INTRODUCTION", "content": "Engineering design optimization is complex due to non-linearity and strict design rules, where conventional algorithms often miss global optimality. Metaheuristic algorithms are increasingly popular for efficient design, simulating physical processes while adapting to unknown factors and resource limitations [1].\nThe optimization algorithm is an integral part of any optimization process [2]. An optimization algorithm simulates physical processes and is key to efficient, durable solutions, requiring multiple evaluations. Image processing operations in computer vision aim to reduce complexity or improve image quality [3].\nOptimizers are essential for finding optimal solutions, as there are various optimization methods. Gradient-based and gradient-free algorithms are used [4], with gradient-based techniques like steepest descent and Gauss-Newton using derivative information, and the Nelder-Mead downhill simplex method using goal values [5].\nDeterministic and stochastic algorithms are two types of algorithms. A deterministic algorithm operates in a mechanically deterministic manner without any randomness. If we start with the same beginning position, such an algorithm will arrive at the same end position. Deterministic algorithms like hill climbing (HC) and downhill simplex are notable examples [6]. Stochastic algorithms introduce randomness, leading to different outcomes even with the same starting point. Randomization in algorithms, such as genetic algorithms, introduces unpredictability through methods like crossover and mutation rates. Heuristics use trial and error for problem-solving, while metaheuristics operate at a higher level, guiding these search strategies [6], [7].\nThe metaheuristic approach provides a flexible optimization model that enhances solutions through adaptive, probabilistic processes guided by variable adjustments until an optimal result is achieved [8]. Sophisticated metaheuristic algorithms explore and exploit the search space, leveraging accumulated knowledge to solve problems. They adapt to various optimization tasks, require no derivative knowledge, and can avoid local optima [9], [10].\nRemarkably, most metaheuristic-based techniques are primarily derived from natural events and may be divided into four categories: evolutionary, swarm, physical, and human-based algorithms [11], [12]. Evolutionary algorithms (EA) simulate natural selection, selecting the fittest individuals for reproduction over generations. John Henry Holland introduced genetic algorithms (GA) in 1960, inspired by Darwin's concept of gradual evolution [13] [14]. The collaborative behaviors of animal swarms inspire swarm-based algorithms. Particle swarm optimization (PSO), mimicking bird swarming, is this type's most popular and widely used algorithm. [15]. Particles (solutions) navigate the search space to find the global best, noting the local best along the way. This approach includes various swarm-based optimizers, such as ant colony optimization (ACO) and artificial bee colony (ABC) [16]. Physical-based algorithms, such as simulated annealing (SA), are grounded in cosmic principles and mimic the thermodynamic cooling process of metal annealing [17]. Finally, human-based algorithms inspire humans' habits, livelihood, or perspectives. The harmony search algorithm (HSA) [18] is indeed a fundamental technique of this class, wherein a collection of JAZZ players rehearse their devices' tones unless they achieve a pleasant harmony (optimal solution). Firefly algorithm (FA) [19] and many others constitute additional, prominent human-based algorithms. There appears to be a multitude of nature-inspired algorithms that may have been utilised to solve various optimization issues effectively. However, an optimization technique cannot achieve good performance for all optimization problems, as per the \u201cNo Free Lunch (NFL)\" hypothesis [20].\nMany deterministic and heuristic optimization techniques struggle with non-linearity and multimodality, highlighting the need for new nature-inspired algorithms to address complex objective functions effectively. Recently, a human-based nature-inspired phenomenon has arisen since techniques like HSA [18] and B -hill climbing (\u03b2 HC) [21] produce positive findings, contrasting to specific other nature-inspired algorithms.\nThe COVID-19 epidemic has inspired the development of various metaheuristic algorithms, reflecting our dynamic modern environment. The CVA [22] draws inspiration from strategies aimed at containing epidemics and reducing infection rates. The CVA fails to address the spread of infection between countries, resulting in low algorithm convergence accuracy and premature convergence. CHIO has several drawbacks, such as complex mathematical formulations, inadequate real-time optimization, numerous control parameters, and a high convergence tolerance. CVSO [23] is inspired by the spread of the Coronavirus across different communities, focusing on its movement, prevalence, and death rate. Its limitation lies in the scope and size of these communities, which can significantly affect the virus's transmission and intensity.\nResearchers are developing metaheuristics that mimic the spread patterns of the coronavirus. COVID-19, caused by the SARS-CoV-2 virus, spreads much faster than typical respiratory illnesses like the cold. Social distancing aims to reduce transmission and delay, decrease the epidemic peak, and relieve pressure on healthcare systems. Traditional optimization algorithms, such as genetic and particle swarm optimization, often struggle with complex, high-dimensional, and dynamic problems, facing issues like premature convergence and poor exploration of solution spaces. To address these challenges, there is an increasing demand for innovative metaheuristic algorithms that offer improved efficiency, adaptability, and convergence. This study introduces the Social Distancing Induced Coronavirus Optimization Algorithm (COVO), inspired by the concept of social distancing to reduce COVID-19 transmission. The significant contributions of this research work are as follows.\n\u2022 Proposing a novel Social Distancing Induced Coronavirus Optimization Algorithm (COVO)\n\u2022 The proposed COVO algorithm considers the social distancing parameter, which has been suggested as a significant solution for reducing the spreading rate of COVID-19.\n\u2022 The proposed COVO algorithm is validated using 13 standard benchmark functions (F1-F13).\n\u2022 Demonstrates COVO's effectiveness by comparing its performance with several well-known optimization algorithms, showing competitive results regarding convergence speed and solution accuracy."}, {"title": "II. LITERATURE REVIEW", "content": "Simulated Annealing (SA) [17] is one of the first metaheuristic algorithms, and it was essentially a modified version of the Metropolis-Hastings algorithm that was used in a different situation [24]. Genetic algorithms' three essential components are crossover, mutation, and fittest selection. Each solution is represented by a chromosome, a string of characters. A crossover of two-parent strings generates offspring by swapping parts or genes of the chromosomes.\nAnt Colony Optimization (ACO), replicate ant foraging behavior, using pheromone concentrations as chemical message [25]. These algorithms excel in discrete optimization problems, but research is ongoing, and few approaches currently address the associated challenges.\nParticle swarm optimization (PSO) is based on natural swarm behaviour like fish and bird schooling. In a quasi-stochastic way, this method explores the space fitness function by changing the particle (search agents) trajectories as piecewise routes generated by positional vectors. The Harmony Search Algorithm (HSA) [18] is a music-inspired algorithm developed with the help of a musician's description of the improvisation process.\nCuckoo Search (CS) [26] is used to find optimal solutions to complex problems by mimicking the process of cuckoos laying eggs and the host birds' efforts to identify and remove foreign eggs from their nests. According to recent research, CS has the potential to be considerably more efficient than PSO and GA. Tabu search [27], and artificial immune system [28] are other metaheuristic algorithms that are as popular and efficient.\nBee algorithms mimic different aspects of bee behavior, with forager bees optimizing nectar collection by exploring various food sources [8]. Pheromone concentrations can be more directly connected to goal functions in the virtual bee algorithm (VBA) invented by Xin-She Yang in 2005 [29]. D. Karaboga, on the other hand, invented the ABC optimization method in 2005 [30].\nThe bat algorithm (BA) [31] is a recent metaheuristic model inspired by the echolocation behaviour of microbats. Most bats use brief, frequency-modulated sounds spanning about an octave, while some rely on constant-frequency signals.\nJC Bansal et al. [32] have developed Spider Monkey Optimization (SMO), which leverages the fission-fusion social structures of spider monkeys to balance exploration and exploitation while effectively navigating local and global optimal solutions. Avinash Sharma et al. have proposed an Ageist SMO (ASMO) based on a spider monkey population's age difference [33], [34].\nWang et al. [35] have proposed the Elephant Herding Optimization (EHO) algorithm, inspired by elephant herding behavior, featuring a clan updating operator and a clan separating operator for updating the positions of elephants and matriarchs within clans.\nThe Virus Optimization Algorithm (VOA) simulates virus attacks [36]. It will be further improved in 2020 by reducing the number of parameters that need to be set and hence making it self-adaptive [37].\nSalehan and Deldari created Coronavirus optimization (CVO), miming COVID-19 behaviour [38]. SIR mathematical models are used to analyze COVID-19 epidemic behaviour. CVO is a feasible and effective approach for resolving application issues. The limitation of CVO includes a lack of implementation to optimize real-time problems and several different control parameters. In [39], the PID controller was designed for brushless DC (BLDC) motors with several disturbances by optimizing CVOA.\nMirjalili et al.[40] have developed the Salp Swarm Optimization (SSO) method, which organizes a randomly generated population into leaders and followers to optimize through exploration and exploitation phases, inspired by deep-sea salp behavior.\nArora and Singh [41] have developed the butterfly optimization algorithm (BOA), based on butterflies' natural behavior in foraging and mating. Despite global and local search capabilities, BOA may experience slow convergence.\nShadravan et al. [42] have developed the Sailfish Optimizer (SFO), inspired by hunting sailfish, using sailfish for intensification and sardines for search space diversification. SFO balances these strategies to prevent early convergence.\nHayyolalam and Kazem [43] have proposed the black widow optimization (BWO) algorithm in 2020, inspired by black widow spider mating behaviour. BWO offers good results, is fast-converging, and avoids local optima.\nThe Sparrow search algorithm (SSA), developed by Xue and Shen in 2020 [44], optimizes sparrows' foraging, predatory, and anti-predatory behavior, but struggles with insufficient stimulation and stagnant exploitation due to poor trade-offs.\nHub\u00e1lovsk\u00e1 et al. [45] have proposed the Botox Optimization Algorithm (BXOA), a novel human-based metaheuristic algorithm that simulates the effects of Botox injections on the human body. The limitations of BXOA include limited applicability, parameter tuning is complex, and there is a risk of premature convergence.\nAl-Baik et al. [46] developed the Pufferfish Optimization Algorithm (POA), a bio-inspired metaheuristic mimicking pufferfish behavior, with exploration and exploitation phases for efficient high-dimensional optimization. However, POA has limitations, such as no guarantee of finding a global optimum and no assumptions about implementation success.\nIn [47], the authors proposed the Coronavirus Optimization Algorithm (CVOA) to model virus spread and infection, avoiding arbitrary initialization and iteration termination. However, it faces challenges like exponential growth of infected populations and the absence of a candidate reduction mechanism, affecting performance and convergence.\nThe Novel COVID-19 Based Optimization Algorithm (C-19BOA) [48], uses bio-inspired methods to improve power system performance. Inspired by the virus's spread and adaptation, it incorporates social distancing, mask use, and antibody rate, revolutionizing problem-solving by leveraging nature's strategies.\nKhalid et al. [49] have proposed MOCOVIDOA, a novel algorithm for multi-objective optimization inspired by the dynamics of the coronavirus, enabling simultaneous resolution"}, {"title": "III. SOCIAL DISTANCING INDUCED CORONAVIRUS OPTIMIZATION ALGORITHM (COVO)", "content": "One of the most critical challenges of the 21st century is to prevent SARS-CoV-2 and COVID-19 diseases [55]. The virus migrated to multiple nations, forcing the World Health Organization (WHO) to designate it as a new contagious disease. Coronavirus cases are increasing rapidly as shown in Figure 1. Figure 1 shows the total number of COVID-19 cases surpassing 704 million by May 2024, as reported by WHO [56]. The data indicates steady growth, with significant increases until mid-2022, followed by a plateau. Though vaccinations and medications are available for COVID-19, identifying the infected patients earlier is essential to treat them immediately and prevent the spreading of the virus to others. COVID-19 has a mortality rate that varies from country to country between 0.25 and 3.0 per cent [57]. Natural immunity refers to a large number of people in a society who are immune to illness (either by vaccination or spontaneous infection), and as a result, the pathogen is unable to disseminate. It occurred since more than 60% of the community had survived the illness (herd immunity threshold). Natural immunity can potentially impact pandemic dissemination by slowing the spread of disease. One of the strategies recommended to prevent the COVID-19 pandemic breakout is herd immunity. It's important to note that this method employs Darwin's notion of the survival of the fittest."}, {"title": "B. Methodology", "content": "A novel Social Distancing Induced Coronavirus Optimization (COVO) algorithm is proposed in this research work. It is introduced to reduce the spreading rate of the virus around the globe. The social distancing parameter is integrated with the COVO model to reduce or interrupt the transmission of COVID-19 amongst the population.\nAlgorithm 1 shows the pseudo-code of the COVO algorithm. COVO algorithm replicates WHO-recommended methods for reducing COVID-19 disease transmission and improving public health. The WHO and various countries have implemented a few mitigating strategies in response to COVID-19. These practices include quarantine, isolation, personal cleanliness, wearing plastic screens and face masks in public, restricting people's movement, and avoiding large-group public meetings. The social distancing strategy's goal is to maintain a safe gap between people, reducing the chances of getting an infection. The COVO attempts to tackle optimization constraints by simulating social distance, a one-stop mitigation technique. COVO's demonstrated strengths in both multimodal function optimization and noise removal suggest that it can be a valuable tool for a range of optimization problems. Its performance improvements over other algorithms make it a preferable choice for applications requiring reliable and efficient optimization solutions. The goal is to find the population's fittest and healthiest individual, which correlates to a near-optimal solution for an optimization problem.\nStep 1: Initialization of population and parameters\nThe population pop is initialized as follows.\n$pop=[P_1, P_2, ..., P_N]$\nHere, each solution $p_i \\in pop$ in the population is a person and N represents the size of the population. In addition, the parameters are initialized as specified in TABLE I. $P_{die}$ and $D_{rate}$ are generated using the random chaotic map [61] using Eq. (1) and Eq. (2), respectively.\n$P_{die} = abs(P_{die} + b \u2212 abs(p \u2013 2\u03c0))* np.sin(2\u03c0 * P_{die})$ (1)\n$D_{rate} = abs(D_{rate} + b \u2212 abs(p \u2013 2\u03c0))* np.sin(2\u03c0 * D_{rate})$ (2)\nWithin this pop, only one individual is referred to as a zero-infected patient (PZ). This individual identifies the first infected person. If there are no identified previous local minima, then PZ is suggested to undergo random initialization."}, {"title": "Step 2: Disease propagation", "content": "Step 2: The search vectors $X_i$ are initialized randomly. Here $i = 1,2,..., m; j = 1,2,..n$ Here, m denotes the number of search agents and n indicates the dimension length.\nStep 3: The opposite solutions are generated using the Opposition learning behaviour [62].\nStep 4: Disease propagation\nThe valuation of the diverse cases takes place based on the individual.\n(a) Based on the death rate for COVID-19, each infected individual is said to have a dying probability $P_{die}$. With this $P_{die}$, the infected population expires, and the case fatality ratio varies in terms of age, health condition, and locality. From these individuals, COVID-19 couldn't spread to others.\n(b) The live infected persons spread the virus to new individuals (intensification). As per the given probability $P_{(spreader)}$, two sorts of spreading categories are considered: ordinary spreaders and super-spreaders.\n(i) Ordinary spreaders: New individuals are affected by the infected population based on the regular spreading rate $S_{rate}$.\n(ii) Super-spreaders: Based on the super-spreading rate $SS_{rate}$, the new individuals are affected by the infected individuals. Once the infected individual becomes a super-spreader, he can share the virus with 15 healthy persons.\n(c) To ensure diversification, the super-spreader and ordinary individuals could travel in the search space to explore new solutions. The travelling probability $P_{travel}$ is available among these infected individuals, and using this $P_{travel}$, they propagate the disease and spread it to travellers with different travelling rates $T_{rate}$\n\u2713 For zero-infected patients (PZ), If $P_{travel}=0$, the solutions are updated by verifying two criteria.\n(i) If the social distancing parameter $H_{dist}$ is lower than the threshold value T (i.e., $H_{dist} <T$ ), then update the solution using Eq. (3).\n$X = L +(U-L)$ (3)\nHere Land U are the upper and lower bounds of the solutions.\n(ii) If the social distancing parameter $H_{dist}$ is greater than the threshold valueT (i.e., $H_{dist}>T$), then update the solution using Eq. (4).\n$X = L + (U \u2013 L).S_{rate}$ (4)\nHere, $H_{dist}$ the social distancing parameter shows the minimum safe distance between two individuals $X_i$ and $X_j$.\nThis operator simulates the social distancing policy. Obviously, not all people engage in social distancing at any given time, but only a proportion of the population follows this policy. As the disease spreads, the importance of social distancing becomes more apparent, and people are forced to be more observant.\n$H_{dist_{ij}}=\\begin{cases} A-dist \\text{ if } dist\\le A\\\\ dist \\text{ if } dist \\ge A \\end{cases}$ (5)\nHere, the current distance between two persons at instance t is computed as $dist_{ij} = |X_{i}^{t} -X_{j}^{t}|$\n\u2713 For zero infected patients (PZ), if $P_{travel} =1$, then update the solution using Eq. (6).\n$X = L +(U \u2013 L).SS_{rate}$ (6)\nStep 5: Fitness Computation"}, {"title": "Step 5: Fitness Computation", "content": "Compute the fitness Fit of all the individuals using Eq. (7). The fitness function Fit is fixed as a minimization of error E and this E includes the 13 benchmark functions $f_1$ \u2013 $f_{13}$.\n$Fit = min(E)$ (7)\nStep 6: Population updating Based on this $P_{die}$, the solution is updated is carried out.\n\u2022 If $Fit > P_{die}$, then a newly infected patient is identified and updated using Eq. (8). Then, move to Step 7.\n$X_{new}= X_{old}\u00b1 X_{old}[Fit.P_{die}]$ (8)\n\u2022 If $Fit \u2264 P_{die}$ , this patient is said to be dead, newly infected patients are generated by proceeding to Step 2.\nThree different populations (Deaths, Recovered population, and Newly infected population) are considered for each generation.\n(a) Deaths- If an infected person expires, they are added to this population but are not considered again.\n(b) Recovered population- The infected individuals who recover are transmitted to the recovered population. These recovered individuals may get re-infected with a probability $P_{reinfected}$ - The people within this population might get affected over any iteration, provided that the re-infection criterion is satisfied. On the other hand, the isolated individuals maintaining social distance remain in recovered population if the isolation probability $P_{isolation}$ is satisfied. $P_{isolation}$ is uncertain as it varies from country to country. After each iteration, the count of the infected population rapidly lessens by following various social isolation measures.\n(c) New infected population- At every iteration, all the individuals affected by the virus are considered. The number of repeated new individuals increases with each iteration, so it is recommended to eliminate such repeated individuals before proceeding to the next iteration.\nStep 7: If $X_{new}$ ,= $X_{old}$; then the newly infected population cannot infect the new individuals. So, move to the termination stage. Otherwise repeat step 2."}, {"title": "Termination-", "content": "One of the most intriguing aspects of the suggested method is its capacity to terminate without requiring any parameters. This scenario arises because the healed and diseased populations continue to expand over time, while the newly afflicted community has been unable to infect new people. The number of infected persons is predicted to rise for a given amount of repetitions. Despite this, since the healthcare infrastructure is too large, and the diseased population deteriorates with time, the number of infected people will indeed be lower than the current total population at a certain point in time. In addition, the stop criterion can be adjusted to provide a specified number of iterations. The social distance idea assists in meeting the stopping requirement as well. Social distancing is used to update the population until terminating requirements are satisfied. Ultimately, the person with the best fitness will be introduced as the best solution to the situation."}, {"title": "A. Convergence Analysis", "content": "The convergence analysis has been done for the 13 standard benchmark fitness functions (F\u2081 - F\u2081) (unimodal) (F - F,) and (F, - F\u2081\u2081) (multimodal). The convergence of the COVO algorithm is compared with EHO [35], SSO [40], SSA [44], SFO [42], BOA [41], BWO [43], SMO [32], CVOA [47], SRO [53], and GBRUN [54] respectively. The error in fitness value acquired for the 13 standard benchmark functions is shown in Figure 5. It has been observed that the COVO algorithm has performed better than the traditional models in all 13 cases; hence, the COVO algorithm is highly convergent. For function F, the cost function of COVO is lower than the existing models at the higher count of iterations, and this clearly says that the proposed model can be applied for acquiring global solutions even for complex optimization problems. The fitness function F\u2082 is lower with COVO, even under higher variation in the count of the fitness evaluations. The error in fitness function F13 is lower than the existing models like EHO [35], SSO [40], SSA [44], SFO [42], BOA [41], BWO [43], SMO [32], CVOA [47], SRO [53], and GBRUN [54] respectively. The convergence performance of various optimization methods compared to the proposed COVO algorithm shows varying levels of effectiveness. EHO achieves a fitness value of 2.99\u00d710-2, indicating moderate convergence, while SSA struggles with a much higher value of 1.80\u00d7102. SSO shows a fitness value of 4.69\u00d710\u22124, reflecting reasonable convergence, but still trails behind COVO. SFO demonstrates weak convergence with a value of 3.72\u00d710\u00b9, and BOA achieves a fitness value of 3.83\u00d710-3, which, although better, remains less effective than COVO. BWO's fitness value of 1.99 indicates moderate convergence, whereas SMO performs poorly with a value 4.36. As the number of fitness evaluations increases, algorithms typically refine their search and improve solution quality. COVO's ability to maintain lower error rates throughout this process suggests that it effectively utilizes each evaluation to enhance solution accuracy and avoid degradation in performance. Thus, the COVO algorithm is proven to provide a higher convergence speed to the solutions and can be applied to different applications."}, {"title": "B. Statistical Analysis", "content": "The statistical evaluation has been conducted based on 5 significant aspects: mean, median, best, standard deviation, and worst. All these evaluations have been carried out for 13 standard benchmark fitness functions (F\u2081-F\u2081) (unimodal) (F - F,) and (F, - F\u2081\u2081) (multimodal). COVO's mean values for functions like F\u2081 and F2 are very low, showing that the algorithm consistently performs well on these benchmarks. However, mean values for functions like F5 and F7 are higher, which might suggest less effectiveness compared to other functions. The outcomes observed are manifested in Table IV. With a fitness function error of 1.23\u00d710-18, COVO demonstrates exceptional precision in its optimization capability. In contrast, SMO encounters greater difficulty in optimization tasks, with an error of 1.04. SSA, with an error of 10.12, also struggles, highlighting its limitations in achieving the same level of accuracy as COVO in this scenario. The performance in multimodal function optimization and noise removal applications is demonstrated through its low best and median fitness values, consistent mean values, and relatively low standard deviation. COVO's ability to efficiently explore and exploit the search space leads to faster convergence on high-quality solutions. This is evident from the algorithm's superior mean and median fitness values, which indicate that COVO consistently finds better solutions more quickly than its competitors."}, {"title": "C. Application of Social Distancing Induced COVO for noise removal", "content": "To portray that the proposed work applies to solving a complex optimization problem, we have validated it with a signal noise removal application. Initially, we collected the ECG signals S(t) and contaminated them with Gaussian noise N(t) as Y(t) = S(t) * N(t). The primary assumption behind the Independent Component Analysis (ICA) problem is that the source signals are independent during the recording period. The contaminated signal Y(t) is subjected to Independent component analysis (ICA) for noise removal. In order to reconstruct the original ECG signals S(t) precisely, the unmixing matrix W of ICA is optimized using the COVO model. In fact, ICA has been applied to diverse applications; the notable one among them is blind source separation. The ECG, which has been infected by Gaussian noise with mean=0, standard deviation=1, and variance=1, is presented for de-noising using COVO and the fitness function. Back projecting the signal from the demixed version to eliminate noise is made using the inverse of the optimized matrix W. The discrepancy between the original and reconstructed ECG is measured using Mean Square Error (MSE). COVO's robust performance in noise removal tasks is attributed to its ability to handle noisy environments effectively. By maintaining a controlled interaction between solutions, COVO reduces the impact of noise on the optimization process and achieves cleaner results.\nThe residual noise and ECG distortion after the filtering procedure are the primary causes of MSE. The findings are shown in Table V, which shows the MSE between the original signal and the reconstructed signal, which was accomplished using COVO to remove noise. The MSE has also been used to compare the original and contaminated signals. MSEo-r is the MSE between the original and reconstructed ECG signal; MSEo-c is the MSE between the original and Gaussian noise-contaminated signal. Results for MSE between the original and reconstructed ECG demonstrate that COVO improves the demixing matrix for noise reduction. For a given interval, the original ECG, contaminated ECG, and reconstructed ECG are presented in Figure 6."}, {"title": "D. Computational Time Analysis", "content": "The time metrics indicate the computational time required by each algorithm to solve a set of benchmark problems. Lower time values suggest better performance in terms of computational efficiency. displays the time analysis of the proposed method."}, {"title": "E. Statistical Test Analysis", "content": "The p-value from the Friedman test indicates the probability of observing the test results under the null hypothesis, which states that there are no significant differences between the algorithms. The p-value is above 0.05, suggesting that differences in performance between EHO and other algorithms are not statistically significant. Common significance levels are 0.05 or 0.01. If a p-value is less than the chosen significance level, it indicates a statistically significant difference between algorithms."}, {"title": "F. P-Test and T-test", "content": "Table IX provides the analysis of P-Test and T-Test. Most algorithms have relatively high p-values in the P-Test results. For instance, COVO has the highest p-value (0.936619), suggesting that differences in performance metrics between COVO and other algorithms are not significant. Higher T-Test values indicate a larger difference between the means, while lower values suggest smaller differences."}, {"title": "V. CONCLUSION", "content": "In this paper, a unique nature-inspired metaheuristic optimization technique for global optimization problems, called the Social Distancing Induced Coronavirus Optimization Algorithm (COVO), is described. The COVO algorithm uses a social distance strategy to try to stop the COVID-19 pandemic from spreading. This study uses 13 benchmark functions to evaluate the proposed COVO with eight cutting-edge metaheuristic approaches. Additionally, the three real-world engineering challenges from IEEE-CEC 2011 are used to validate the obtained optimization. In fact, the outcomes demonstrate that the COVO model works well and will be widely used in the ensuing decades to address a wide range of real-world issues. In addition, with the parameter-free COVO model, parameters self-improve in the future. Moreover, versions that are binary, discrete, and multi-objective are taken into consideration for further investigation."}]}