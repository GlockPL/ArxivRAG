{"title": "NL2OR: Solve Complex Operations Research Problems Using Natural Language Inputs", "authors": ["Junxuan Li", "Ryan Wickman", "Sahil Bhatnagar", "Raj Kumar Maity", "Arko Mukherjee"], "abstract": "Operations research (OR) uses mathematical models to enhance decision-making, but developing these models requires expert knowledge and can be time-consuming. Automated mathematical programming (AMP) has emerged to simplify this process, but existing systems have limitations. This paper introduces a novel methodology that uses recent advances in Large Language Model (LLM) to create and edit OR solutions from non-expert user queries expressed using Natural Language. This reduces the need for domain expertise and the time to formulate a problem. The paper presents an end-to-end pipeline, named NL2OR, that generates solutions to OR problems from natural language input, and shares experimental results on several important OR problems.", "sections": [{"title": "1 Introduction", "content": "Operations research (OR) is a field that has been widely used to enhance decision-making by creating and using mathematical models of real-world situations to find solutions [9]. A major stream of OR solution is to use mathematical programs (MP) which consist mathematical representations of decision variables, optimization objectives, and decision constraints. For instance, in the area of e-commerce order fulfillment, a resource allocation MP aims to minimize total fulfillment cost, utilizing limited inventories located across the merchant's warehouse/retailing network. The feasible fulfillment decisions are required to satisfy operational constraints, e.g. channel restrictions, region restrictions, logistic restrictions, and etc.. Another OR problem example, in the area of resource scheduling optimization, a scheduling planner aims to optimize the utilization of human agent resources to accomplish tasks with skill set specifications. The feasible scheduling decisions are required to satisfy operational constraints, e.g. staffing requirements, shift scheduling, skill matching and etc.. For physical tasks,"}, {"title": "2 Related Works", "content": "the scheduling planner will also need to minimize agent traveling, and making sure agent traveling schedules satisfy time windows for both task reservations and agent shifts. In both examples, the MP aims to optimize a certain objective function, subject to a set of operational constraints.\nHowever, in the related industries, modeling an OR problem and developing an MP solution will require specialized knowledge set (e.g. mathematical modeling and operations research algorithm design training). For instance, in the e-commerce order fulfillment example, one needs to have knowledge in inventory optimization, transportation optimization, and logistics optimization. Therefore, the development of MP solutions is often left to a small group of domain experts. Moreover, developing and deploying a computer-based solution may take months. This long development cycle can be a barrier to OR solution adoption, especially in the context of small and medium-sized enterprises.\nTo overcome this barrier, the field of automated mathematical programming (AMP) has emerged, aiming to automate the process of developing MP solutions. AMP aims to enable non-experts to develop and deploy MP solutions with little or no human intervention. AMP systems can be divided into two categories: closed-box and open-box systems.\nClosed-box AMP systems use machine learning techniques to learn the map-ping between the input data and the optimal solution [23,11]. These systems require no prior knowledge of the mathematical structures. However, the so-lutions produced by black-box systems are often sub-optimal and cannot be guaranteed to satisfy operational constraints.\nOpen-box AMP systems, on the other hand, are based on mathematical pro-gramming techniques and require the user to specify the mathematical model of the problem [10,13,21]. These systems start from detailed business logics and a problem data set, and generate a solver-specific script (also known as a concrete model) for user to review. After the generated model being reviewed and validated, it is able to guarantee that the solution satisfies the operational constraints, and can often produce optimal solutions. However, the user needs to have a good understanding of the mathematical program-ming problem and how to interface with a variety of solvers/libraries (e.g. Gurobi, CPLEX, ORtools, AMPL).\nTo mitigate the limitations these drawbacks of existing closed- and open-box AMP systems, we propose a novel methodology that create new OR solutions and edit existing OR solutions using natural language (NL) queries. Recent ad-vances in natural language processing (NLP) have led to the development of large language models (LLMs) that can be used for human language text generation. These models have been used for various tasks, such as language translation, question answering, and text summarization [6,24,5,4,1,16]. We propose to use LLMs to generate markup language passages for OR problems, which can then be converted into programming language passages. This technique entails ob-taining user input for an OR problem, formulating an NL prompt grounded in the user input, generating a domain-specific language (DSL) that captures the OR problem, transforming the DSL into an executable script (with a suitable"}, {"title": "2.1 Large Language Models", "content": "A large language model (LLM) [25] is a sequence-to-sequence model designed for predicting sequences of text-based tokens. This model has undergone training on a substantial volume of text data to enhance its ability to generate accu-rate predictions for sequences of tokens in a given context. In recent years, the"}, {"title": "2.2 Automated Mathematical Programming", "content": "An automated mathematical programming (AMP) system aims to automate the process of developing MP solutions with little of no human intervention. The first research stream of AMP focuses on developing an inference system to derive solutions based on historical data. [23] surveys ML-enhanced approaches that solve mix-integer programming and combinatorial optimizations. For ex-ample, researchers have found a close-box system using neural network approx-imations significantly improves the efficiency of modeling and solving the class of SCIP problems in the OR space. The other stream of AMP research con-siders the formulation of the MP problem to be articulated in natural language and subsequently translated into MP solutions utilizing LLMs [10,13,21]. Recent studies have demonstrated the efficacy of leveraging pretrained LLMs for AMP tasks [10,13,21,12]. Due to their capacity to obviate the need for custom model training or fine-tuning, pretrained LLMs emerge as an appealing solution for AMP endeavors. Our work differentiates from existing research, as we focus on creating and editing abstract OR models, and our approach is solver-agnostic."}, {"title": "3 Methodology", "content": "The main objective is of NL2OR is to convert a natural language description of an OR problem into an OR model, and then generate executable artifacts. These executables are known as abstract models, which have data input contracts. By providing data following an input contract, a concrete model instance can be solved by a selected solver. By solving the concrete model, the NL2OR pipeline can generate problem solutions with reports. This takes considerable engineering efforts to develop various parts of the pipeline. In this section, we will go through the architecture of our system in-depth. An overview of the architecture is given in Figure 1.\nThe NL2OR pipeline is composed of four major components: Domain Spe-cific Language (DSL) Generator, Framework for OR Analytics (FORA) Builder, FORA Executor and Report Generator. The pipeline starts by admitting a user"}, {"title": "3.1 DSL Generator", "content": "The input constract of the DSL generator variates based on a job type, i.e. creation or edition. A creation job only requires a user query, while a edition job also requires providing an original model YAML file.\nGiven a user input, the first step in the DSL generator is to construct a DSL generation prompt. Prompt engineering is directly interlinked with the quality of the LLM output. We streamline this process by automating prompt construc-tion within our system. A prompt builder module is designed to automatically generate a prompt for the LLM by amalgamating various components, includ-ing instructions, syntax overview for the (OR) model YAML, few-shot learning instances, and the user's specific problem statement. Subsequently, this con-structed prompt is inputted into the LLM to facilitate the generation of the DSL, for a new OR model or an updated model.\nAn illustrative example of a model generation prompt is depicted in Figure 2. From the user's perspective, the complexities involved in OR model YAML and LLM prompts are abstracted away. Users must only provide a query elucidating the OR problem they aim to address. By concealing these technical intricacies, we empower users to focus solely on articulating and engaging with solutions to their OR problems without being burdened by the internal mechanics of the system. See Figure 2 for an illustration of building a food purchasing planning optimization problem.\nFollowing the generation of the OR model YAML, i.e. the DSL, it undergoes a series of validation, correction, and processing steps facilitated by error detection mechanisms to ensure its integrity as a valid OR model. Initially, the YAML is subjected to syntax error rectification, which involves automatically correcting property names, validating correctly labeled constraints, and rectifying various Python expression errors. These corrections aim to preempt the need for YAML regeneration if syntax errors are the only remaining issues.\nSubsequently, beyond syntax correction, early error detection mechanisms are deployed to identify irreparable errors. These mechanisms include schema validation, detection of redefined variable declarations, and identification of un-defined variables. Upon detection of any of these errors, the system throws an error and logs it; as such, errors cannot be rectified programmatically."}, {"title": "3.2 FORA Builder and Executor", "content": "After the LLM post-processing step, assuming successful completion, a model YAML file is transpiled into an FORA model. This transpile step primarily in-volves the instantiation of entities within the internal FORA library, with meta-data declared in the InputData property of the YAML. The InputData property"}, {"title": "3.3 Report Generator", "content": "Once FORA is employed to execute a concrete model, yielding a solution or status log, the Report Generator facilitate further analysis of the results, storing this solution in a database may be necessary. The responsibility of construct-ing the database schema for the solution falls under the purview of the report summarization step. The report prompt builder plays a vital role in this process by assimilating details about the OR problem and its solution, abstracting any information related to sensitive user data, and generating a report prompt tai-lored for the LLM. Utilizing this prompt, the LLM generates a database schema designed explicitly for the solution to the OR model. An illustrative example of the resulting database schema is presented in Figure 7.\nAfter establishing this database schema, the report YAML undergoes pro-cessing, and the OR solution is transformed into an intermediate data format conducive to being seamlessly written as rows to a database. This transforma-tive step prepares the OR solution data for efficient storage and retrieval in a structured database environment."}, {"title": "4 Experiments", "content": ""}, {"title": "4.1 OR Model Creation", "content": "For initial experimentation aimed at assessing the capabilities of NL2OR, we evaluate its proficiency in generating a valid OR model that can be executed from a specified user query. The experimentation involved assessing NL2OR across a spectrum of 30 distinct OR problem instances, spanning various scenarios en-countered in practical applications. A comprehensive overview of these problem instances is presented in Table 1. Additionally, we explored the performance of NL2OR using two different LLM models, gpt-35-turbo-16k and gpt-4-32k, each"}, {"title": "4.2 OR Model Edit", "content": "An essential practical application of NL2OR is editing existing OR models. We characterize OR model edits as introducing alterations or augmentations to the properties outlined in the OR model YAML. Such refinement proves invalu-able when addressing minor adjustments necessary to accommodate evolving customer or business demands or validating prospective alterations to the foun-dational system upon which the model relies. This is also known as What-if analysis. For instance, this functionality proves invaluable when integrating a new product into a resource allocation problem or assessing the impact of up-dated material constraints on the resultant outcomes.\nThe test data is constructed as follows. We select 15 validated OR model YAML as original YAMLs, and we use GPT-4 to create possible model update"}, {"title": "5 Conclusion and Future Work", "content": "In this paper, we propose a novel methodology that creates new OR solutions and edits existing OR solutions using natural language (NL) queries. Our proposed method can significantly reduce the time and effort required to model and solve complex OR problems, which reduces the time required to formulate a prob-lem in a solver-specific format and provides a framework for the development of an interactive OR problem-solving tool that can be used by non-experts. We have implemented the proposed methodology as an end-to-end pipeline, named NL2OR, that can 1) take natural language input and generate an abstract OR model; 2) resolve data mapping and triage solvers to provide a solution to the generated OR problem; 3) edit the generated OR model for what-if analysis. We have evaluated NL2OR across a spectrum of more than 30 distinct OR problem instances, spanning various scenarios encountered in practical applications. The results demonstrate that NL2OR can generate valid OR models with high accu-racy and low latency. Additionally, we have shown that NL2OR can effectively edit existing OR models. In future work, we plan plan to explore the use of other LLM/SLM models on the performance of NL2OR. Additionally, we plan to ex-plore the use of reinforcement learning to improve the performance of NL2OR. Finally, we plan to evaluate the performance of NL2OR on a larger dataset of OR problems and to compare its performance with existing AMP systems."}]}