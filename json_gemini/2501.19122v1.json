{"title": "FedRTS: Federated Robust Pruning via Combinatorial Thompson Sampling", "authors": ["Hong Huang", "Hai Yang", "Yuan Chen", "Jiaxun Ye", "Dapeng Wu"], "abstract": "Federated Learning (FL) enables collaborative model training across distributed clients without data sharing, but its high computational and communication demands strain resource-constrained devices. While existing methods use dynamic pruning to improve efficiency by periodically adjusting sparse model topologies while maintaining sparsity, these approaches suffer from issues such as greedy adjustments, unstable topologies, and communication inefficiency, resulting in less robust models and suboptimal performance under data heterogeneity and partial client availability. To address these challenges, we propose Federated Robust pruning via combinatorial Thompson Sampling (FedRTS), a novel framework designed to develop robust sparse models. FedRTS enhances robustness and performance through its Thompson Sampling-based Adjustment (TSAdj) mechanism, which uses probabilistic decisions informed by stable, farsighted information instead of deterministic decisions reliant on unstable and myopic information in previous methods. Extensive experiments demonstrate that FedRTS achieves state-of-the-art performance in computer vision and natural language processing tasks while reducing communication costs, particularly excelling in scenarios with heterogeneous data distributions and partial client participation. Our codes are available at: https://github.com/Little000/FedRTS.", "sections": [{"title": "1. Introduction", "content": "Federated learning (FL) (McMahan et al., 2017; Li et al., 2019; Kairouz et al., 2021) enables edge devices with private local data to collaboratively train a model without sharing data. However, substantial computational and communication demands for training deep learning models often exceed the resource limitations of edge devices in cross-device FL scenarios. Although neural network pruning (Han et al., 2015; Molchanov et al., 2019a; Ma et al., 2021) offers a promising solution by removing redundant parameters, traditional pruning methods depend on resource-intensive dense model training, rendering them impractical for privacy-preserved and resource-constrained FL environments.\nTo address these challenges, recent federated pruning frameworks (Bibikar et al., 2022; Qiu et al., 2022; Tian et al., 2024; Jiang et al., 2022; Huang et al., 2024; 2023; Munir et al., 2021) have adopted dynamic pruning techniques (Evci et al., 2020; Raihan & Aamodt, 2020; Jayakumar et al., 2020) within FL. These frameworks employ a two-loop training process: in the inner loop, model weights are updated through standard FL rounds with fixed model topology; in the outer loop, the server adjusts the model topology by pruning and reactivating parameters (Evci et al., 2020), as illustrated in Fig. 1 (left). This iterative process generates a specialized sparse model without dense model training, significantly reducing computational costs.\nDespite these advancements, existing frameworks suffer from three critical challenges in model topology adjustment (Bibikar et al., 2022; Qiu et al., 2022; Tian et al., 2024; Jiang et al., 2022; Huang et al., 2024; 2023; Munir et al., 2021), as illustrated in Fig. 1 (left). 1). Greedy adjustment: Current methods rely on myopic, aggregated information from a small subset of participating clients, ignoring data from the majority of unseen clients and prior knowledge. This leads to greedy adjustments and reduced robustness (Kairouz et al., 2021). 2). Unstable topology: Deterministic adjustments based solely on aggregated information are prone to instability due to heterogeneous data distributions, resulting in unstable model topologies. 3). Communication inefficiency: Transmitting extensive auxiliary data (e.g., full gradient matrices) for topology updates imposes high communication costs. These limitations hinder the ability of current methods to handle client availability, data heterogeneity, and communication costs effectively, ultimately leading to suboptimal performance and inefficient resource utilization.\nTo address these challenges, we reframe federated prun-"}, {"title": "2. Preliminary and Challenges", "content": "2.1. Federated Dynamic Pruning\nIn federated pruning, N resource-constrained clients collaboratively train a sparse model using their local datasets Dn, n \u2208 {1,2,...,N}. Given the target density d', the objective is to solve the following optimization problem:\n$\\min_{\\mathbb{W},m} \\sum_{n=1}^N p_n.f_n (W, m, D_n), \\quad \\text{s.t.} \\quad d \\leq d', \\tag{1}$\nwhere W represents the model weights, $m \\in \\{0,1\\}^{|W|}$ denotes the sparse model topology (also called mask), $f_n (\\cdot)$ is the objective function for client n, d is the density of the topology m, and pn is set as the proportion of the dataset size of client n, typically set as $p_n = |D_n|/\\sum_{i=1}^N |D_i|$.\nTo solve the problem in Eq. 1 under the target density constraint d', existing federated pruning frameworks (Bibikar et al., 2022; Qiu et al., 2022; Tian et al., 2024; Jiang et al., 2022; Huang et al., 2024; 2023; Munir et al., 2021) apply dynamic pruning techniques (Evci et al., 2020; Raihan & Aamodt, 2020; Jayakumar et al., 2020) within FL. These frameworks iteratively adjust sparse on-device models during training while maintaining the density level d. The process begins with a sparse model initialized via random pruning and follows a two-loop training procedure: In the inner loop, the model topology m remains fixed, and the model weights are updated through traditional FL rounds. After AT inner loops, as illustrated in Fig. 1 (left), the framework enters the outer loop, where clients upload additional data (specifically, the gradients of the pruned weights)"}, {"title": "2.2. \u0421\u041c\u0410\u0412-Based Problem Formulation", "content": "The Combinatorial Multi-Armed Bandit (CMAB) (Chen et al., 2013; Slivkins et al., 2019; Kong et al., 2021) is a sequential decision-making framework where an agent selects combinations of arms (called super arms) with unknown reward distributions. The objective is to maximize cumulative rewards by balancing the exploration of uncertain arms and the exploitation of high-performing ones.\nWe formulate the topology adjustment as a CMAB problem, where each link mi in the model topology serves as an arm. In each outer loop t for topology adjustment, the server selects an action St, which includes K arms, where K = d' (W). Selected arms i \u2208 St are activated (mt,i = 1), while others i \u2209 St are deactivated (mt,i = 0). After playing action, the new sparse weights $W_t = W_{agg}\\odot m_t$ will be distributed to the clients for further training, where $W_{agg}$ is the aggregated weights. The server then observes outcomes $X_t = (X_{t,1},\\ldots, X_{t,m})$, drawn from distributions with unknown expectation \u03bc. After that, the server obtains the unknown rewards $R_t = R(S_t, X_t)$. At the next round t + 1, the previous information {X|1 < \u315c < t} is the input to the adjustment algorithm to select the action St+1. Following previous work (Kong et al., 2021), we assume that the expected reward of an action St only depends on St and and the mean vector \u00b5, i.e., there exists a function r such that $E[R_t] = E_{X_t}[R(S_t, X_t)] = r(S_t, \\mu)$."}, {"title": "2.3. Challenges in Previous Methods", "content": "From the CMAB aspect, after taking the action St, previous federated pruning methods observe the delay outcomes Xt at the next outer loop t + 1, where $X_{t,i} = 1$ if i is the index of the top magnitude of aggregated weights $|W_{t-1}^{agg}|$ or gradients $|G_{t-1}^{agg}|$; otherwise, $X_{t,i} = 0$. Treating the outcomes ${X_t}$ as the feedback, the next action St+1 is selected, i.e., $S_{t+1} = \\{i|X_{t,i} = 1\\}$. Thereby these methods face three significant challenges:\nGreedy Adjustment: Existing frameworks only observe the outcomes in the outer loop, ignoring the inner loop. Moreover, they discard all previous information ${X|1 \\leq t \\leq t-1}$, which is myopic, excluding information from unseen clients and previous data, leading to a greedy topology adjustment that is difficult to exploit from a global view.\nUnstable Topology: Previous ignore the expectation of distribution \u03bc and make a deterministic decision based on unreliable outcomes Xt. It is hard to maximize the reward expectation $r(S_t, \\mu)$ and may select an arm with a low expectation, leading to an unstable topology."}, {"title": "3. Methodology", "content": "In this section, we present FedRTS, a novel federated pruning framework designed to develop robust model topologies, as illustrated in Fig. 2. We begin by detailing the TSAdj mechanism, which serves as the core component for searching robust sparse topologies. Next, we provide an overview of the FedRTS algorithm that integrates TSAdj. Finally, we provide the theoretical regret upper bound of TSAdj."}, {"title": "3.1. Thompson Sampling-based Adjustment", "content": "We find that the core source of the aforementioned challenges in existing federated dynamic pruning frameworks lies in deterministic decision strategies and myopic observations. Therefore, we propose the Thompson Sampling based Adjustment (TSAdj) mechanism, which includes probabilistic decision strategy and farsighted observations. Moreover, TSAdj effectively reduces the communication overhead.\nCompared to directly using myopic outcomes to make deterministic decisions, our proposed TSAdj maintains individual prior probability distributions P for each link in the model topology m during training. The higher feedback a link i has gained from previous observations, the closer the expectation of its probability E[Pi] approaches 1, indicating a higher likelihood of being selected. In the outer loop for topology adjustment, instead of deterministically selection based on outcomes Xt, the server samples random variables $ \\xi \\sim P$ and selects an action St on the topology as follows:\n$S_t = \\{ i | \\xi_i \\in \\text{Top}( \\xi, K ) \\}, \\tag{2}$\nwhere Top(\u03be, K) denotes the set of top K elements of \u03be. The action St is derived from the expectation of the prior distribution, E[P], which provides a more stable topology compared to existing approaches.\nUnlike existing approaches that develop the outcomes using immediate and myopic data in the outer loop, TSAdj derives much more comprehensive outcomes Xt from both the inner and outer loops. After performing action St, the outcome Xt is observed in the end of loop t, and is formulated as a combination of individual outcomes $X_t^r$ and aggregated"}, {"title": "3.2. FedRTS", "content": "FedRTS is a novel federated learning framework designed to address the limitations of existing dynamic sparse training methods by integrating the Thompson Sampling-based Adjustment (TSAdj) mechanism, as illustrated in Fig. 2. The framework begins with an initialized model weight and sparse topology sampled from Beta distributions P. FedRTS employs a two-loop training process to iteratively update model weights and refine the sparse topology.\nIn the inner loop, the model topology remains fixed while the server updates the model weights and distribution P based on semi-outcomes. In the outer loop, the server collects the full outcomes by requiring clients to upload the top-k gradient indices of inactivated weights. Using this information, the server applies TSAdj to make robust topology adjustments, and the updated topology is then distributed to clients. FedRTS continues this iterative process until model convergence. The details of FedRTS are shown in Algo. 2 and Sec. B.2.\nBy integrating TSAdj, FedRTS introduces a novel approach to sparse topology adjustment. Leveraging Thompson Sampling, it mitigates the instability caused by unstable aggressive topology, ensuring smoother convergence through probabilistically guided adjustments based on historical information. This adaptive adjustment strategy enhances the robustness of the sparse topology and improves overall model performance in FL tasks."}, {"title": "3.3. Theoretical Analysis", "content": "For simplifications, we omit the inter loop of FedRTS to isolate the TSAdj mechanism and consider only semi-outcomes, i.e., ignore the outcomes Xti that i \u2209 St. We also consider the following assumption and approximation:\nAssumption 3.1. (Independent Magnitude) Magnitude of model weights are mutually independent.\nAssumption 3.2. (Threshold Approximation) The discriminative function h(\u00b7) in Eq. 4 and 5 can be approximated by a threshold \u03c3, i.e., h(i, x, \u03ba) \u2248 1x\u2265\u03c3\u00b7\nAssumption 3.1 aligns with standard magnitude pruning practices, while Assumption 3.2 holds empirically, as weights often exhibit a Gaussian-like distribution under L2 regularization and normalization techniques. Therefore, under assumptions 3.1 and 3.2, the outcomes Xt,i become:\n$X_{t,i} = \\begin{cases}\n1 & | W_{t,i}^{agg} | \\ge \\sigma + (1 - \\gamma) \\sum_n p_n 1_{|W_{t,i}^n| \\ge \\sigma}, i \\in S_t,\n\\end{cases} \\tag{8}$"}, {"title": "3. Methodology", "content": "In this section, we present FedRTS, a novel federated pruning framework designed to develop robust model topologies, as illustrated in Fig. 2. We begin by detailing the TSAdj mechanism, which serves as the core component for searching robust sparse topologies. Next, we provide an overview of the FedRTS algorithm that integrates TSAdj. Finally, we provide the theoretical regret upper bound of TSAdj."}]}