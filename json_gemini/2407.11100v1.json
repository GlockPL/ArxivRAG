{"title": "Building Intelligence Identification System via Large Language Model Watermarking: A Survey and Beyond", "authors": ["Xuhong Wang", "Haoyu Jiang", "Yi Yu", "Jingru Yu", "Yilun Lin", "Ping Yi", "Yingchun Wang", "Qiao Yu", "Li Li", "Fei-Yue Wang"], "abstract": "Large Large Language Models (LLMs) are increasingly integrated into diverse industries, posing substantial security risks due to unauthorized replication and misuse. To mitigate these concerns, robust identification mechanisms are widely acknowledged as an effective strategy. Identification systems for LLMs now rely heavily on watermarking technology to manage and protect intellectual property and ensure data security. However, previous studies have primarily concentrated on the basic principles of algorithms and lacked a comprehensive analysis of watermarking theory and practice from the perspective of intelligent identification. To bridge this gap, firstly, we explore how a robust identity recognition system can be effectively implemented and managed within LLMs by various participants using watermarking technology. Secondly, we propose a mathematical framework based on mutual information theory, which systematizes the identification process to achieve more precise and customized watermarking. Additionally, we present a comprehensive evaluation of performance metrics for LLM watermarking, reflecting participant preferences and advancing discussions on its identification applications. Lastly, we outline the existing challenges in current watermarking technologies and theoretical frameworks, and provide directional guidance to address these challenges. Our systematic classification and detailed exposition aim to enhance the comparison and evaluation of various methods, fostering further research and development toward a transparent, secure, and equitable LLM ecosystem.", "sections": [{"title": "1 Introduction", "content": "Large Language Models (LLMs) have become increasingly important for driving innovation across multiple industries. From automated customer service to complex natural language understanding tasks, the applications of LLMs are expanding. However, as LLMs become more widely used, the challenges to protect security, compliance, and user privacy have become increasingly severe, highlighting the urgent need for robust identity recognition systems.\nIdentity recognition plays a crucial role across various sectors in modern society [1], from financial transactions [2] and healthcare [3] to border security [4] and online services [5]. The application of identity recognition technology is ubiquitous, ensuring user authentication and authorization, and serving as the cornerstone of security and privacy. In fact, all existing governance frameworks and security systems rely on the effective operation of identity recognition systems [6]. Despite the widespread application of identity recognition systems in many fields, such systems have yet to be fully established in the realm of artificial intelligence (AI). This is primarily due to the complexity and dynamic nature of the AI domain, where traditional identity recognition methods struggle to meet the demands of AI systems. The core issues of identity recognition involve achieving distinguishability, unforgeability, and traceability. These issues are particularly critical in the context of LLMs, where the characteristics of textual data, the openness of LLMs, and the extensive applications of LLMs make identity recognition even more complex.\nCurrently, watermarking technology is regarded as a potential solution to address the three core issues in identity recognition [7]. It can covertly embed identity information without compromising the quality of the original data [8], ensuring distinguishability. By integrating cryptography, watermarking technology ensures the unforgeability of information and enables traceability through detection. This technology offers an innovative strategy for intellectual property protection and data security in the field of LLMs. Given the urgent need to protect intellectual property and ensure the traceability of security responsibilities in complex LLM application scenarios, it is essential to establish effective techniques and theoretical frameworks for embedding and extracting watermarks.\nAlthough some existing literature reviews [9\u201312] have gradually focused on these issues, most studies primarily introduce the basic principles of algorithms. They lack a comprehensive analysis of watermarking as the cornerstone of identity recognition systems for LLMs and do not adequately address the multifaceted conflicts of interest encountered by LLMs in actual operation. This article innovates the existing LLM watermarking systems from three main aspects: application, theory, and evaluation, thereby providing theoretical and practical support for the secure, transparent, and fair use of LLMs. The main contributions of this article are as follows.\nApplication: In Section 2, we illustrate that the LLM application system is transitioning from a centralized setup, dominated by model technology service providers, to a multi-centric design that prioritizes identity verification and behavior traceability. We also explored the different preferences of data providers, technology service providers, users, and third-party regulators regarding various aspects of identity recognition systems within a multi-center LLM application framework. This novel perspective deepens our understanding of the rights and responsibilities of participants in LLM community. It also promotes the establishment of a fairer and more secure AI application environment.\nTheory: In Section 3, we address the limitations of current LLM watermarking technology by developing a theoretical system based on mutual information theory [13]. The comprehensive mathematical foundation establishes a formulaic framework and classifies LLM watermarking technologies into five primary processes: generation, embedding, attack, extraction, and reconstruction. The optimization object and constraints of each process are elaborated with mathematical formulas, allowing researchers to accurately develop and enhance the watermarking techniques based on corresponding roles and stages.\nEvaluation: In Section 4, we have synthesized the performance evaluation metrics for LLM watermarks from multiple perspectives, encapsulating the preferences of various LLM entities in their application of watermarking techniques for identity recognition. This summary contributes to the development of a comprehensive and standardized evaluation system, prompting consideration of security issues related to LLM watermarking, and outlines new research trajectories and technological orientations.\nThrough these three core contributions, our article significantly expands the scope of watermarking applications within LLMs. For the first time, we put watermarking techniques within the context of the identification applications of LLMs, providing robust technical support for addressing the challenges of security and transparency in LLMs. This integration serves a dual purpose: it enhances the traceability of content generated by LLMs, allowing each output to be reliably traced back to its originating model, and it substantially boosts the trustworthiness of LLMs in various application scenarios by ensuring the authenticity and provenance of the content. Finally, we have highlighted some challenges that still exist in the current watermarking technology and theoretical systems, and suggested potential solutions for these challenges. We hope this work will spark further research and discussion, propelling LLM technology towards a trustworthy and verifiable future while safeguarding user interests."}, {"title": "2 Establishing Identification System through LLM Watermarking", "content": ""}, {"title": "2.1 Future Trends in LLM Applications", "content": "Currently, the research and development of LLMs are in a period of rapid growth, benefiting from the swift enhancement of computing power and the accumulation of large volumes of high-quality data. The life cycle of LLMs can generally be divided into stages of data preparation, training and testing, deployment and application, and monitoring and maintenance. Entities and participants typically involved in the life cycle of LLMs include training data providers (such as Stardust AI\u00b9, Scale AI\u00b2, etc.), model technology service providers (such as OpenAI\u00b3, Anthropic\u2074, etc.), LLM users, and certain public regulators and trusted third parties (PRTTPs) (governments, non-profit organizations, etc.)5.\nHowever, people tend to focus on the iteration of technology (models, algorithms, and data) while neglecting issues of security and rights protection in the application processes of LLMs. As shown in the left part of Fig. 1, in the existing LLM R&D system, technology service providers play a dominant role in every step, from data preparation and model training to final deployment and maintenance, relying on their technical reserves and commercial needs. This centralized system allows technology service providers to monopolize the entire LLM technology market through technological barriers and resource advantages, making it difficult for other participants to develop or achieve breakthroughs independently. Overall, this system makes the development of technology, model compliance, and user privacy security dependent on the ethical standards of technology service providers, which is not conducive to the overall development of the AI ecosystem.\nTypically, once the LLM technologies have been widely promoted and enter a period of stabilization, the LLM community shifts its focus from solely valuing the technology to emphasizing regulatory compliance, user privacy, and the security of the technology. This shift transforms the original technology-centric centralized operational system into a balanced, multi-centric system involving multiple participants, as illustrated in the right part of Fig. 1. In this system, the influence of users and PRTTPs is significantly enhanced. PRTTPs are responsible for obtaining and verifying security and trust declarations from data providers and technology service providers, as well as handling risk reports from general LLM users. Meanwhile, LLM users, while ensuring their security and privacy, will authorize the collection of their preferences to model technology service providers and gain potential benefits."}, {"title": "2.2 Identity Recognition System in LLMs", "content": "In the current digital era, identity recognition technology is critical for safeguarding information security. Traditional identity recognition techniques, such as Multi-Factor Authentication (MFA) [14], biometric technologies [15] (including fingerprint [16] and facial recognition [17]), and Single Sign-On (SSO) [18], are primarily employed to authorize and identify individuals within human communities, relying on biometric features, behavioral patterns, and language analysis to verify identities. For instance, some studies identify individuals by modeling their interaction behaviors with devices [19] and their language styles [20]. However, an effective identity recognition system has yet to emerge in the LLM community.\nDue to the capacity of LLMs to generate text of high quality and diversity, it poses a novel challenge to authenticate whether a segment of text is the output of a particular LLM, and to confirm that it has not been unauthorizedly altered or counterfeited. Traditional identity recognition technologies are not applicable in this scenario, as they cannot be directly implemented on the text content or LLMs.\nWatermarking technology is a crucial method for identity recognition in the field of computer science [21\u201324]. Traditionally used for copyright protection in images, audio, and video [25]. Watermarking embeds secret information without compromising original data quality. With the rise of LLM technology, embedding watermark information in LLMs themselves and their related applications has become an indispensable area of research. Watermarking enables verification of text origin from specific LLMs, thereby enhancing copyright protection, intellectual property preservation, and content authenticity. Moreover, watermarking aids in tracing content dissemination, preventing misinformation, and ensuring transparency and traceability in compliance with legal and regulatory standards. Consequently, watermarking technology has emerged as an innovative and indispensable mechanism for identification in the context of LLM applications."}, {"title": "2.3 Identification System from Different Views", "content": "In practical application scenarios, data providers can use watermarks to protect the copyright of their training data, ensuring that the training data are not arbitrarily altered or copied. Technology service providers wish to use watermarking technology to protect their model copyrights, preventing their models from being repackaged or stolen, and enabling them to track the usage of their models. LLM users need watermarking technology to protect their privacy rights, preventing their confidential information from being sold. PRTTP will ensure the security of LLMs by verifying the presence of watermarks at multiple stages; once any security issues are identified, it is crucial to ensure that the source of the problem can be traced and resolved. The following sections detail the four distinct entities of the watermark system and elucidate how each can establish its own watermarking technology framework."}, {"title": "2.3.1 Training Data Providers", "content": "For training data providers, the infinite replicability of data poses an uncontrollable risk of data breaches as it circulates. Currently, the most effective way to prevent the unauthorized dissemination of data is to secretly add a unique, strong watermark [26] to the data without altering the quality of the dataset itself [27]. This ensures that the data can still be verified for its initial copyright even after being redistributed, modified, or otherwise processed. Some researchers have proposed even more in-depth solutions, demonstrating that watermarked data used for LLM training can have its watermark information detected in the text generated by the LLM, which is referred to as radioactivity [28]. Once this knowledge is embedded into unauthorized LLMs, data providers can identify whether their watermark is present in the models based on the response to certain specific watermark triggers. Moreover, since a training dataset is likely to be copied and sold multiple times, the most crucial aspect of protecting copyright and preventing data leaks or unauthorized distribution is identifying the source of the leakage. To address this, encoding a unique watermark message for each dataset to be distributed and embedding it into the data with a covert watermark is an essential option.\nTherefore, training data providers need to focus on watermarking techniques that offer high fidelity and transparency, meaning the watermarking should be done in a way that does not degrade the quality of the text. Moreover, the watermark embedded by the data providers should have the capability of multi-bit information encoding to enable the identification of the data purchasers. Besides, the watermark should possess high robustness and radioactivity, allowing for the detection of watermarks in text content generated by unauthorized models if the data are used for illegal training."}, {"title": "2.3.2 Model Technology Service Providers", "content": "For technology service providers, watermarking technology helps protect model copyrights and monitor the usage of models. To address the costs and technical difficulties faced during the pre-training of LLMs, some technology service providers might opt to use data generated by well-trained models for training, which has formed a system similar to teacher-student model distillation. This imitation has sparked concerns over the copyright of unauthorized distilled models, especially when the corpus data of these distilled models come from closed-source LLMs (such as GPT-4). In the constantly evolving landscape of AI copyright protection, it is crucial to emphasize the importance of protecting intellectual property while maintaining the integrity and practicality of AI models. The development and implementation of watermarking technology enables model developers to protect their innovations from unauthorized use and distribution effectively.\nTo protect the intellectual property of models and prevent the unauthorized use of developed LLMs through distillation by offenders, technology service providers should embed watermarks only when the model is invoked by users, without affecting the model's own training process. This approach meets the technology service providers' pursuit of model performance. Additionally, it substantiates the model's ownership and facilitates the tracking of its distribution and usage [29]. This helps prevent the model from being copied or tampered with by unauthorized third parties."}, {"title": "2.3.3 Public Regulators and Trusted Third Parties", "content": "With the rapid advancement of AI technology, especially the widespread use of LLMS in content creation, the roles of public regulators and trusted third parties (PRTTPs) in watermarking systems have become critical. Policymakers and civil society are increasingly focused on the safe use of these technologies, as shown by the EU AI Act, the NDAA for Fiscal Year 2024 [30], and voluntary commitments to label AI-generated content. These initiatives emphasize the need for transparency in content sources, including clear marking of watermarks and content origins, as well as guidelines for content certification and watermarking developed by the U.S. Department of Commerce following the AI Executive Order of October 30, 2023 [31]. These guidelines aim to help the public easily identify the authenticity of online information.\nLLM watermarking technology is considered key to ensuring the safety, compliance, and ethical integrity of AIGC throughout its entire lifecycle. To this end, PRTTPS should make the following efforts:\n1.  Establishing clear watermarking technical standards and usage norms, setting up certification programs for watermark service providers, and promoting success stories and best practices.\n2.  The implementation of education and training programs, especially aimed at enhancing the understanding of watermarking technology among all participants, further reinforces this process. This involves not only educating parties on how to select and utilize watermark services correctly but also emphasizing the importance of adopting these measures to ensure that all involved can effectively use watermarking technology to identify AIGC.\n3.  Establishing strict oversight and enforcement mechanisms is equally important, ensuring that all parties rigorously adhere to the regulations and standards for watermark usage, thereby guaranteeing the correct and secure application of watermarking technology.\n4.  Providing the general public with access to open watermark interfaces for LLMs allows users to add watermarks to their own data or to verify through watermarking whether a piece of data contains their private information. This approach helps track the usage and flow of data, preventing unauthorized dissemination of the data across the internet.\nThese requirements are not isolated but necessitate multi-party collaboration among data providers, model technology service providers, watermark technology service providers, and PRTTPs. Through a cooperation framework that spans different sectors and industries, we can facilitate information sharing and technological advancement. These measures encourage deep reflection on the safe use of AI technology and lay a solid foundation for maintaining public trust in AIGC. By establishing industry standards, implementing rigorous certification processes and audits, providing comprehensive education and training, enforcing vigilant supervision and execution, promoting best practices, and fostering collaborative multi-party partnerships, we can ensure the safe and responsible development of LLMs and other AI technologies."}, {"title": "2.3.4 Users of LLMS", "content": "Watermarking technology can help LLM users in verifying the copyright and legitimacy of the models, while also serving as a tool to protect the security of user data and privacy. Users should opt for LLM services verified by PRTTPs. The model providers usually require such verified service providers to apply data watermarking technology to ensure that the input data is used only for the current service and is not accessed or misused by third parties. LLM users can ensure that watermarks are embedded in their prompts by choosing services with publicly verifiable watermarking technology. Users can verify the use and flow of their data through a public watermark verification interface, preventing unauthorized distribution of their data on the internet. Watermarking technology plays a crucial role in protecting personal privacy and can also alleviate users' privacy and security concerns on another level, thereby promoting the further popularization of LLM technology.\nMoreover, LLM users will gradually transition from mere users to becoming a more deeply involved and crucial part of the LLM application ecosystem. Firstly, users can trade their private data through some form of anonymization, collaborating with data providers to co-create datasets. This not only generates profit but also enhances the overall efficiency of the LLM application system. Secondly, users will engage in in-depth cooperation with PRTTPs. If the model produces unsafe answers or if copyright infringement is detected, users can report these issues to PRTTPs by clicking the report button. PRTTPs can thus centralize the originally dispersed and unequal user oversight power through this method, better standardizing the development of LLM technology."}, {"title": "2.4 Guidance for Implement Watermarking", "content": "All entities should establish their own rights protection system using watermarking technology based on their position within the LLM application ecosystem and their relationships with other entities. The rights that need protection, the entities that need identification, the limitations encountered when using watermarking technology, and some basic requirements are organized in Table 1. Based on the descriptions in the table, entities can find the corresponding watermarking technologies in Section 3 and deploy their watermarking schemes according to the different basic requirements."}, {"title": "3 LLM Watermarking Technology", "content": ""}, {"title": "3.1 Overview", "content": "In this section, we formally define watermarking in LLMs and explore its application in securely and covertly transmitting information. Watermark algorithms for LLMs involve the processes of generation, embedding, extraction, and reconstruction, as shown in Fig. 2. To help the readers better understand, we have listed the main symbols used in the article in the notation table 2.\nWe denote that the watermark message m, the N-vectors text sequence SN = (s1, s2,...,sN), the N-vectors watermarked text sequence TN = (t1, t2,...,tN), the D-elements watermark security parameter KD = (k1,k2, ..., kD), and the watermark W take their values in message space M, original sequence space S, watermarked sequence space T, watermark security parameter space K, and watermark space W respectively. We require that S and T are isomorphic, indicating that there is a one-to-one correspondence between their elements while preserving the structure of the spaces. Moreover, S and T must obey identical distributions to ensure that the watermarking process does not alter the statistical properties of the original sequences. This is crucial for the stealth and efficacy of the watermark. Additionally, the watermark space W should be compatible with the original sequence space S, where compatibility refers to the ability of the watermark signal W to be embedded into the original signal SN without introducing detectable statistical differences.\nA watermark W is produced by the watermark generation module, followed by the generation of the watermarked text sequence TN via watermark embedding process. During text dissemination, not only are attackers likely to be present, but the message itself may also be subjected to cutting, substitution, rewriting, and reordering among other operations. An attack channel Attack(T'N | TN) may apply some of the above operations to process the sequence TN to the corrupted sequence T'N. The extractor, utilizing the watermark security parameter and the text sequence T'N under examination, retrieves the watermark W'. Subsequently, the reconstruction decodes W' to calculate the estimated value m' of the message initially transmitted.\nThe watermarking system of LLMs can be analyzed by defining the watermark message m, the statistical model for the sequence SN output by the LLM according to the prompt, and the watermark security parameter KD. This includes the distortion function, constraints on the acceptable distortion levels for both the watermark embedding and the watermark attacker, and the information available to each party. The goal of the watermarking algorithm is to seek the maximum reliable transmission rate of m over any possible watermarking strategy and any attack that satisfies the specified constraints. Consequently, the entire watermarking process can be described using principles of information theory. To better understand the watermarking framework, we first explain the key parameters in the diagram:\n\u2022 Sequence SN: Assume the input prompt is denoted as Prompt, and the sequence SN \u2208 S is composed of elements $s_1, s_2,...,s_N$, where N is the length of the sequence. The process by which the LLM generates a sequence can be represented as"}, {"title": null, "content": "\\[\begin{equation} P(S_N|Prompt) = \\prod_{i=1}^{N} P(s_i | s_1, s_2, ..., s_{i-1}, Prompt). \tag{1} \\end{equation}\\]\nIn this equation, P(SN | Prompt) is the probability of generating the sequence SN given the input Prompt. P(si | s1, s2,..., si\u22121, Prompt) is the conditional probability of generating the next element si given the input Prompt and the first i - 1 elements of the sequence.\nThe LLM considers the sequence generated so far, s1, s2,..., si\u22121, along with the input prompt, and then predicts the probability distribution for the next word si. Once the model predicts the probability distribution for si, it selects the next word based on this distribution, which could either be the word with the highest probability or a word sampled randomly according to the distribution. This process is repeated until the entire sequence SN is generated or a certain termination condition is met."}, {"title": "\u2022 Watermark Message m:", "content": "m\u2208 Mrepresents the message that needs to be encoded. Depending on the amount of information encoded, watermarks can be categorized into one-bit watermarks and multi-bit watermarks. The one-bit watermarking technique is both mature and stable; however, it is limited to encoding a single bit of information specifically, indicating whether the text was generated by a particular LLM. One-bit watermarks cannot meet the growing demand for customized information in LLM applications. For example, embedding model and version information in the watermark can effectively track the source of text among multiple LLMs. In contrast, multi-bit watermarks allow for carrying more customizable information. However, designing a practical multi-bit watermark method is a challenging task because multi-bit watermarks are more complex than one-bit watermarks. Consequently, embedding a multi-bit watermark can have a greater impact on the text quality compared to embedding a one-bit watermark. After the watermark generation module encodes m, it must be reliably transmitted to the watermark extraction module during message transmission to ensure the success rate of watermark detection. Here, m is independent of (SN, KD).\n\u2022 Security Key KD: KD \u2208 K represents the identity tag used to provide identity information to a text sequence. Introducing KD serves two primary purposes. Firstly, it is crucial to identify LLMs that utilize the same watermarking algorithms. This identity tag can take forms such as a secret key, providing the generator with information about the identity of the LLM that generated the text sequence SN. Secondly, KD can be introduced at various stages, offering more flexibility in the identity verification process. Additionally, KD provides a known source of randomness during the extraction phase, allowing for the use of randomized codes, a standard technique to enhance transmission performance in communications.\nThe dependency between the original sequence SN and the identity tag KD can be quantified by the joint distribution P(SN, KD). In public watermarks (blind watermarks), SN and KD are independent, meaning the identity tag is completely unrelated to the original text sequence. This independence implies that identity verification does not require the original text, facilitating public verification. Conversely, for private watermarks, if there is a dependency between SN and KD, such as SN being a function of KD, validating the identity tag requires access to the original text sequence or the original encoding parameters."}, {"title": "3.2 Problem Definition", "content": "Different LLM watermarking algorithms have distinct parameters and settings at each stage, playing various roles throughout the watermarking process. The existing LLM watermark algorithms are summarized in Fig. 3 categorized by the different phases of the watermarking process.\ni) Watermark generation: The watermarking algorithm encodes the text SN generated by an LLM, the watermark security identity KD, and the watermark message m through the function f. Initially, the watermark information m must be converted into a feature suitable for embedding, generating the corresponding watermark signal W. The method of generation simultaneously affects the watermark's"}, {"title": null, "content": "\\[\begin{equation} W = f(S^N,m, K_D) \tag{2} \\end{equation}\\]\n\\[\begin{equation} f:S\\times M\\times K \\rightarrow W. \tag{3} \\end{equation}\\]\nThe function f is the mapping of the sequence SN generated by the LLM, the watermark message m, and the watermark security parameter KD to the watermark signal W.\nWe define two key concepts: Attack Robustness and Security Robustness. From an information-theoretic perspective, these concepts for the watermark signal W can be characterized by mutual information I. Attack Robustness represents the ability to withstand attacks against the watermark. A larger I(SN; W) indicates a stronger dependency between the generated watermark W and the original sequence, signifying a higher capability to resist watermark attacks. Conversely, Security Robustness refers to the capacity to prevent the deduction of the watermark message from the watermarked sequence TN. A smaller I(m; W) signifies a weaker dependency between the generated watermark W and the watermark message m, thereby inhibiting the inference of the watermark message m from W.\nTo simultaneously consider Attack Robustness and Security Robustness, the optimization goal is"}, {"title": null, "content": "\\[\begin{equation} \\underset{f_N}{max} \\quad I(S^N; W) - \\lambda I(m; W) \tag{4} \\\\  \\text{s.t.} \\begin{cases} (i) \\quad W = \\underset{f_N}{arg \\quad max} \\quad I(S^N; W) - \\lambda I(m; W) \\\\  (ii) \\quad I(m; W) \\leq \\epsilon, \\end{cases} \\end{equation}\\]\nwhich aims to maximize the mutual information I(SN; W) between the original sequence SN and the watermark W, while minimizing the mutual information I(m; W) between the watermark message m and the watermark W. Ideally, I(m; W) should be zero, indicating that m and W are completely uncorrelated, thereby achieving complete transparency of the watermark. The parameter \u03bb is a positive trade-off coefficient that adjusts the balance between these two objectives. Furthermore, \u03f5, a very small positive number, quantifies the security robustness of the watermark.\nii) Watermark Embedding: After obtaining the watermark signal W through the generation phase, it is necessary to embed W into the watermark carrier (i.e., the original text sequence SN) to produce the watermarked text sequence TN. We define the operation of embedding the watermark as the function Emb:"}, {"title": null, "content": "\\[\begin{equation} T^N = Emb(S^N,W). \tag{5} \\end{equation}\\]\nThe Emb function may employ simple techniques such as addition, concatenation, or more complex watermark embedding operations. These could include embedding the watermark W from various perspectives, such as format, vocabulary, and syntax at the data level or by manipulating the training and inference processes of LLMs at the model level. Integrating Formula 2, the embedding operation can be expressed as\nTN = Emb(SN, f(SN,m, KD)).\nFrom the perspective of watermark Text Quality, the mutual information I(SN;TN) between the embedded text sequence TN and the initial sequence SN"}, {"title": null, "content": "\\[\begin{equation} \\underset{Emb}{max} \\quad I(S^N;T^N) - \\theta I(W;T^N) \\\\  \\text{s.t.} \\quad \\frac{1}{\\left|S^N\\right| \\left|K_D\\right| \\left|M\\right|} \\sum_{S^N\\in S} \\sum_{K_D\\in K} \\sum_{M\\in M} D_N(S^N,T^N) =  \\\\ \\frac{1}{\\left|S^N\\right| \\left|K_D\\right|} \\sum_{S^N\\in S} \\sum_{K_D\\in K} p(S^N, K_D) \\times D_N(S^N,T^N) < D_{Emb}. \tag{6} \\end{equation}\\]\nThe watermark Transparency is also subject to an average distortion constraint Demb. The definition of the distortion constraint involves an average over the distribution p(SN, KD) and a uniform distribution over the messages. A non-negative bounded distortion function $d_{Emb}(x_i, y_j) = \\begin{cases} 0,  x_i = y_j \\\\  a, a > 0, x_i \\neq y_j \\end{cases}$ exists between elements of the sets S and T. This average distortion Demb is the value of the average distortion"}, {"title": null, "content": "\\[\begin{equation} D_{Emb} = \\sum_{S^N\\in S} \\sum_{T^N\\in T} p(T^N) p(S^N | T^N) d_N(S^N,T^N). \tag{7} \\end{equation}\\]\nThe distortion function is extended to N-dimension-vectors by $d_N(S^N,T^N) = \\frac{1}{N} \\sum_{i=1}^{N} d_{Emb}(s_i, t_i)$. This constraint further limits the degree of distortion in the text sequence with the embedded watermark ensuring the transparency of the watermark.\nWatermark embedding techniques can be classified into two main categories: data-centric watermark embedding and model-centric watermark embedding. Each methodology has distinct features and application contexts, collectively laying the technological foundation for the protection of intellectual property, model security, and the authentication of data and models.\niii) Watermark Extraction: The function \u00a2 : T\u00d7K \u2192 W' is the extractor mapping, which takes the watermarked text TN and the watermark security parameters KD, and maps them to the extracted watermark signal W':"}, {"title": null, "content": "\\[\begin{equation} W' = \\phi(T^N, K_D). \tag{8} \\end{equation}\\]\nAt this stage, we revisit the watermark embedding process of text length N, constrained by distortion Demb, which can be defined as a triplet (M, f, $) where: Mis the watermark message space.\niv) Watermark Reconstruction: After extracting the watermark signal W', it is necessary to decode the watermark message m' from W'. To approach the channel capacity with a reliable transmission rate of the watermark message, a jointly optimal decoding rule, designed corresponding to the generation phase, should be adopted to compute the estimated value of the original watermark message m'.\nIf the Maximum A Posteriori (MAP) decoding principle is adopted to minimize the error probability:"}, {"title": null, "content": "\\[\begin{equation} m' = \\underset{m \\in M}{arg \\quad max} \\quad p(m | W', K_D). \tag{9} \\end{equation}\\]\nOther decoding rules can also be adopted, such as correlation rules, normalized correlation rules, or trigger-based rules.\nv) Watermark Attacks: With the advancement of watermarking technologies, attack methods targeting watermarks have also evolved. These attacks aim to undermine the effectiveness of watermarks and, in some cases, completely remove them, posing a threat to content security and copyright maintenance. Notably, these methods of attack not only represent potential threats but are also utilized to assess the robustness of watermarking technologies. This, in turn, helps developers improve and fortify watermark algorithms.\nAdversary's capabilities. If watermark attacks occur throughout the watermarking algorithm cycle, we consider an adversary with black-box input-output access to the language model. In public watermark mode, the adversary is aware of all the details of the public algorithm. In private watermark mode, the adversary knows the watermark implementation but lacks knowledge of the security key KD and the encryption component of the watermark generation algorithm.\nThis adversary has the capacity to modify the sequence TN within a distortion constraint. Given the distortion function between elements of the sequence spaces S and S', denoted as $d_{atk}(,),$ subject to the distortion constraint Datk. The attack channel Attack(T'N|TN) is defined as a sequence of conditional probability mass functions (p.m.f.) from space S to S', where the distortion is evaluated relative to the original LLM sequence SN rather than the watermarked sequence TN:"}, {"title": null, "content": "\\[\begin{equation} E{d_{atk}(T^N, T'^N)} =  \\sum_{m,S^N,T^N,K_D, T'^N} d_{atk}(S^N,T'^N)P(T'^N | T^N)P(S^N,K_D) \\leq D_{atk}. \tag{10} \\end{equation}\\]\nAdversary's objective. The primary objective of the adversary is to render the watermark extraction algorithm ineffective. Specifically, the adversary aims to produce a T'N such that $(T'^N, K_D) \\neq W$, while ensuring that T'N remains a minor modification of the LLM-generated watermark sequence TN."}, {"title": "3.3 Watermark Generation", "content": ""}, {"title": "3.3.1 Vocabulary-partitioning-based Methods", "content": "Watermarks generated through vocabulary partitioning usually utilize a pseudo-random function (implemented as a hash function) to generate random seeds. These seeds are used to divide the vocabulary into distinct lists, ensuring that a subset of tokens from a particular list is output more frequently during token generation. The watermark is generated by biasing the selection of tokens towards specific lists."}, {"title": "3.3.2 Model-learning-based Methods", "content": "Model-based learning methods employ deep learning techniques, such as GPT [47], BERT [48], to generate watermarks. These methods leverage the learning and generative capabilities of deep learning models, using a trained watermark generation model to directly produce watermarks W or embedded representations of watermarked sequences.\nIn contrast to other methods, this technique create the watermark that is intricately embedded into the content, enhancing security and robustness against tampering. Correspondingly, watermark extraction is typically performed using a dedicated decoder or a watermark detection network. This dual-model framework ensures that the embedded watermarks can be accurately retrieved, even when the content has undergone modifications or compression. By maintaining the watermark generation model as proprietary while making the watermark detection model publicly accessible, a"}, {"title": "3.3.3 Custom-rules-based Methods", "content": "The methods proposed in this section involve generating watermarks by applying specific rules. The core principle is to design a set of rules or algorithms that modify or mark text data and models", "Techniques": "These methods involve poisoning the training data"}]}