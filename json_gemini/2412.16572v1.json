{"title": "BREAKING THE CONTEXT BOTTLENECK ON LONG TIME SERIES\nFORECASTING", "authors": ["Chao Ma", "Yikai Hou", "Xiang Li", "Yinggang Sun", "Haining Yu", "Zhou Fang", "Jiaxing Qu"], "abstract": "Long-term time-series forecasting is essential for planning and decision-making in economics, energy,\nand transportation, where long foresight is required. To obtain such long foresight, models must be\nboth efficient and effective in processing long sequence. Recent advancements have enhanced the\nefficiency of these models; however, the challenge of effectively leveraging longer sequences persists.\nThis is primarily due to the tendency of these models to overfit when presented with extended inputs,\nnecessitating the use of shorter input lengths to maintain tolerable error margins. In this work, we\ninvestigate the multiscale modeling method and propose the Logsparse Decomposable Multiscaling\n(LDM) framework for the efficient and effective processing of long sequences. We demonstrate that\nby decoupling patterns at different scales in time series, we can enhance predictability by reducing\nnon-stationarity, improve efficiency through a compact long input representation, and simplify the\narchitecture by providing clear task assignments. Experimental results demonstrate that LDM not\nonly outperforms all baselines in long-term forecasting benchmarks, but also reducing both training\ntime and memory costs.", "sections": [{"title": "1 Introduction", "content": "Time series analyses are widely used across various industries, including power load forecasting, anomaly detection in\ncredit fraud, imputation in environmental monitoring, and user classification based on their behavior history. Among\nthese tasks, time series forecasting is an important analytical technique that uses historical sequences to predict future\noutcomes. Based on the length of the forecast horizon, time series forecasting can be divided into short-term and long-\nterm categories. Because time series are nearly stationary in short-term, i.e, the mean and variance of the data do not\nvary much over time, short-term forecasting is usually easier. Long-term forecasting, on the other hand, is much more\ncomplicated due to various non-stationary factors, especially trends. Certain planning tasks, including infrastructure\ndevelopment, climate change adaptation, urban planning, resource management, and supply chain optimization, demand\nthe foresight that only long-term forecasting can provide. As a result, long-term forecasting proves to be more broadly\napplicable across diverse fields, such as economics and finance[1, 2, 3, 4], energy[5, 6, 7], transportation[8, 9, 10],\nenvironment[11, 12], and industry[13, 14, 15].\nLong-term Time-Series Forecasting (LTSF) relies on effective and efficient handling of long contexts and modeling\nof long-term dependencies. Recent advancements have led to the development of network architectures specifically\ndesigned to exploit the intrinsic properties of time series data, such as periodicity[16, 17, 18], multiscale[19, 20],\nsegmented[21, 22], and non-stationary[23, 24, 25]. Among these methods, the multiscale modeling approach[26], as\nexemplified by TimeMixer[19], has demonstrated significant promise in long-term dependencies modeling. This is\nparticularly due to its close alignment with real-world phenomena such as traffic, which exhibits patterns at multiple\ntemporal levels, including daily and hourly variations. The TimeMixer model leverages temporal patterns across different\nsampling scales with two main modules: the Past-Decomposable-Mixing (PDM) and the Future-Multipredictor-Mixing\n(FMM). The PDM module independently mixes seasonal and trend components at different scales. The FMM module\nintegrates multiple forecasters to exploit complementary capabilities in multi-scale observations for improved accuracy.\nHowever, the sampling approach exhibits three key limitations that limit its range of application:\n1. Insufficient context. Prediction error for current methods is only acceptable when using shorter inputs. The\ntrends provided by multiscale downsampling cover only a short time period, resulting in a lack of sufficient\ncontext for the model to learn and generalize effectively.\n2. None-stationarity. When the input sequence is non-stationary, the downsampling process subsequently\nintroduces additional non-stationary components across multiple scales, thereby increasing complexity and\ncreating additional challenges for the model.\n3. Not generally applicable. Multiscale downsampling components require specially designed communication\nor aggregation modules to be aggregated together (like PDM). This introduces significant additional overhead,\nwhich compromises generality and scalability.\nThe issue of short input sequences was identified early[27] and was particularly acute in early Transformer methods,\nsuch as Informer[28], Autoformer[16], and FEDformer[17], as illustrated in Fig.(1a). Overfitting to noise in the input\nsequence is a major cause. Previous works[17, 29] employed Fourier analysis to reduce overfitting by randomly selecting\nfrequency components, which lowers computational complexity but does not fully solve the problem. Recent methods,\nsuch as PatchTST[22], Crossformer[21], and iTransformer[30], expand the reception field to address this issue, but risk\nlosing local details and increasing memory costs. Regarding the non-stationary issue, methods such as RevIN[25] and\nthe Non-Stationary Transformer[24] have introduced two-stage normalization approaches that partially alleviate the\nproblem. Nevertheless, managing non-stationary signals remains a significant challenge for neural networks. General\napplicability is a highly desirable trait. However, downsampling-based multiscale methods exhibit task overlap between\ndifferent scales when handling low-frequency information, leading to conflicts during final aggregation. There are two\nsolutions: one uses a serial structure in which each layer handles a different scale, as seen in N-HITS[20], Multiscale\nViT[31], and MeMViT[32]. The other introduces modules for cross-scale communication, such as TimeMixer[19],\nHRViT[33], and CrossViT[34]. Both methods impose constraints on the predictor, reducing general applicability and\nincurring additional overhead. These limitations are prevalent in current LTSF methods and continue to affect existing\nmultiscale analysis approaches. Our proposed Logsparse Decomposable Multiscaling (LDM) framework addresses\nthese limitations while achieving both high performance and efficiency.\nTo the best of our knowledge, this is the first work to investigate multiscale decomposition methods in LTSF. In our\nexperiments, LDM achieves state-of-the-art results on all long time-series forecasting benchmarks, while significantly\nreducing both training time and memory usage. Our contributions can be summarized as follows:\n\u2022 We introduce the Logsparse Scale, which, for the first time, addresses overfitting issues associated with long\nsequences in multiscale scenarios (see Fig.1b). A longer context enables the model to capture multi-scale\nfeatures more effectively.\n\u2022 We present a straightforward multiscale decomposition method for arbitrary-scale multi-resolution analysis,\neffectively addressing the non-stationarity problem inherent in current downsampling approaches.\n\u2022 We propose a generally applicable framework, Logsparse Decomposable Multiscaling (LDM), which signifi-\ncantly enhances the performance of existing forecasting approaches while reducing training time and memory\noverhead."}, {"title": "2 Related Work", "content": "Current mainstream methods, mostly based on MLP and Transformer, have addressed the issue of error accumulation\ninherent in autoregressive prediction approaches, particularly prevalent in recurrent neural networks[35, 36]. Early Trans-"}, {"title": "2.1 Time Series Forecasting", "content": "former variants primarily focused on reducing attention complexity, exemplified by approaches like Autoformer[16] and\nFEDformer[17], Informer[28] which introduced Fourier analysis and sequence decomposition methods into time series\nforecasting. The latest Transformer method, PatchTST[22], Crossformer[21] adopts strategies such as channel-wise\nindependence and Patch embedding methods, which enhanced temporal dependencies modeling abilities, effectively\nenhancing prediction accuracy. MLP-based techniques often exploit inductive biases from time series analysis, as\nexemplified by N-BEATS[37] and N-HITS[20], which employ boosting techniques. Non-stationary Transformer[24]\nand RevIN[25] focus on analyzing non-stationarity, TimesNet[18] leverages multi-periodicity, TSMixer[38] and\niTransformer[30] captures multivariate correlations, and TimeMixer[19] exploits multiscale features. However, the\noptimal input size for these methods is often much shorter than the prediction length, creating a significant bottleneck\nfor LTSF[39].\nThis raises the question: What determines the input size of neural networks for time series forecasting? Through a\ncomparative analysis of mainstream methods, we observe a positive correlation between token size and input length.\nToken size, referring to the model's smallest processing unit (or receptive field), determines how much input a model\ncan handle. For instance, Autoformer[16] and FEDformer[17], which treat individual time points as tokens, perform\nbest with a context window of 96. In contrast, models like PatchTST[22] and Crossformer[21], using tokens of 8 to 16\ntime points, extend the window to 336. MLP-based models, such as TSMixer[38], N-BEATS[37], and N-HITS[20],\nhandle up to 512 due to their ability to process entire sequences as tokens. Token size also significantly impacts model\nbehavior. Models with smaller tokens[40, 41, 28, 17, 22] excel at capturing local variations like subtle periodicities,\nwhile those with larger tokens emphasize global patterns, such as mean and variance[37, 20, 38]. Based on these\nobservations, we propose: Token size governs the input length a model can accommodate. However, larger tokens risk\nmissing local variations. A model that processes tokens of varying sizes simultaneously, as in Multiscale Modeling[26],\nmay provide the optimal solution."}, {"title": "2.2 Multiscale Modeling", "content": "Multiscale Modelling is widely used in Computer Vision [42, 43, 44, 45, 46], e.g. in Multi-view stereo (MVS)\n[47, 48, 49, 50] and Dense prediction [51, 52] rely on multi-scale features to improve prediction accuracy, while\nefficiency can be improved in video and image recognition[31, 53, 54]. In the field of time-series forecasting, recent\nmultiscale research efforts include N-HITS[20] and TimeMixer[19]. In terms of multiscale modelling, N-HITS belongs\nto a serial structure, stacking multiple layers of MLPs, with early layers using lower temporal resolution, and the final\npredictions are generated by aggregating the predictions produced by each layer. TimeMixer belongs to a parallel\nstructure, where each scale is modelled independently by a multilayered feed-forward neural network as well as a linear\npredictor, and features of each scale is aggregated by the proposed decomposable multiscale mixing layer. However, the\noverhead of the mixing layers is substantial. Our approach leverages the efficiency of parallel structures in multiscale\nmodeling while eliminating the need for a mixing layer, achieving both high performance and computational frugality."}, {"title": "3 Methodologies", "content": "Preliminaries. LTSF can be modeled as a sequence-to-sequence (seq2seq) supervised learning task[55]. For a\nmultivariate dataset, starting from an early time point L to a near end point T H, sample a portion of historical data\nxt and future data yt at each time point t to form a sequence pair{xt, yt}${T-H}_{t=L}$, where T is the length of the dataset.\nGiven a multivariate historical sequence $x_t \\in \\mathbb{R}^{M \\times L}$ at time t, where L is the context window size (or input sequence\nlength), the objective of LTSF is to predict its future sequence $y_t \\in \\mathbb{R}^{M \\times H}$, where H is the prediction length. The\nmultivariate time series comprises multiple dimensions, where each dimension $i \\in \\{1, 2, ..., M \\}$ represents a separate\ntime series $x^{(i)} \\in \\mathbb{R}^L$, referred to as a channel. Our framework handles multiple channels simultaneously but ignores,\npotential correlations between channels, as cross-dimensional dependencies[38, 21] are beyond the scope of this study.\nWe formalize the LTSF problem f as follows:\nf: {x}\u2192{y}"}, {"title": "3.1 Logsparse Scale", "content": "According to Dow Theory[56], the stock market's price trends are categorized into three levels of duration and\ngranularity: Primary, Secondary, and Minor, with an emphasis on long-term trends and recent fluctuations. This theory\nposits that daily fluctuations from a month ago are generally not considered significant for current forecasting. Drawing\ninspiration from this, we propose the Logsparse scale, designed to mitigate the issue of input overfitting, which leads to\nInsufficient context.\nThe concept of Logsparse was introduced in LogTrans[57] as a variant of the attention mechanism, in which the\ndensity of attention computations grows increasingly sparser on a logarithmic scale as the time interval increases.\nLogsparse Scale adopts this principle, focusing selectively on high-frequency components over time, as shown in\nFig.2(a). Implementing this concept is straightforward: it involves adding a new truncation step, named Logsparse\ntruncation, at the end of the current downsampling approach, as shown in Fig.2(b). The concept of Logsparse truncation\ninvolves selectively reducing the length of sequences based on their scale, with a focus on diminishing the length of\nhigh-frequency, small-scale sequences more significantly than that of large-scale sequences. This method is particularly\nuseful in contexts where it is beneficial to compress data while preserving the most significant, large-scale information.\nSparsity Parameter \u03b7. This new parameter \u03b7, which ranges between 0 and 1 (inclusive of 1 but exclusive of 0),\nquantifies the degree of sparsity. The closer \u03b7 is to 1, the less aggressive the truncation, meaning sequences are kept\nlonger. Conversely, a smaller \u03b7 value leads to more substantial truncation, effectively \"diluting\" the sequence by\nreducing its length more significantly.\nThe formula for the post-truncation length $L_n$ of a component at scale n is given by:\n$L_n = min(\\frac{p_n}{\\eta}, L_n)$\nwhere \u03b7 adjusts the scale factor inversely with the sparsity degree, meaning that a smaller \u03b7 (indicating higher sparsity)\nresults in a smaller limit for $L_n$, thus enforcing a more significant reduction in sequence length."}, {"title": "3.2 Multiscale Decomposition", "content": "The problem of None-stationarity can be mitigated by using decomposition methods. For example, the Discrete\nWavelet Transform (DWT)[58] is also a multiscale method that decomposes the time series into one non-stationary"}, {"title": "3.3 Logsparse Decomposable Multiscaling Framework", "content": "We propose the Generally applicable framework named Logsparse Decomposable Multiscaling(LDM). LDM does not\nrely on any aggregation or communication modules, nor does it make any assumptions about the predictor."}, {"title": "3.4 Transformer-based Predictor", "content": "Transformer models like PatchTST excel in LTSF due to their patch embedding\nlayers, while FEDformer is better suited for short-term forecasts, focusing on\nindividual time points. Our goal is to develop a unified predictor capable of\nhandling both long and short-term forecasts, eliminating the need for separate\nmodels for different time scales. To this end, we integrate both traditional\nvanilla embeddings and innovative patch embedding layers to process input series\nseparately, as illustrated in Fig. 5. This approach aims to leverage the strengths\nof both embedding techniques to enhance the model's forecasting capabilities\nacross different time scales.\nGiven the sequence s and the corresponding scale p, the input sequence S is\nunfolded into a 2D tensor as follows:\n$S^{2D} = Unfold_p(Padding(S^{1D}))$\nHere, Padding(\u00b7) adds zeros to extend the time series along the temporal dimen-\nsion, ensuring compatibility with Unfoldp(\u00b7), where both the unfold size and\nstride are set to p. The resulting 2D tensor, $S^{2D}$, features dimensions $R^{Mxcxp}$,\nwhere each row correlates with a patch embedding $w_1 \\in R^{Mxcxd_{model}}$ and each\ncolumn correlates with a vanilla embedding $w_2 \\in R^{Mxp xd_{model}}$. These two sets\nof embedding vectors undergo processing through separate Transformer encoders,"}, {"title": "4 Experiments", "content": "We first demonstrate the SoTA performance of the framework using the proposed predictor, and then use multiple models\nas predictors to demonstrate that the framework is generally applicable. We will then argue that such performance\nimprovements actually stem from reduced costs, thanks to multiscale decomposition which converts a complex problem\ninto a set of simple problems. Finally, we dissect the characteristics of the method through ablation experiments and\ninterpretability analyses. We begin by outlining the experimental setup, which follows the established configurations of\nprevious studies[28, 16, 17, 22, 59]."}, {"title": "4.1 Protocols", "content": "Benchmarks. We evaluate the performance of our framework on eight main-stream benchmarks, including Weather,\nTraffic, Electricity, Solar-energy and 4 ETT datasets(ETTh1, ETTh2, ETTm1, ETTm2), which have been extensively\nused in previous works[28, 16, 17, 22, 59] and publicly available at [16]. Training/Validation/Test sets are zero-mean\nnormalized with the mean and std of Training set, with the data split into proportions of 7:1:2 respectively. The Statistics\nof all benchmarks are gathered in Table 1.\nBaselines. We selected eight popular State of The Art(SoTA) models as baselines, including FEDformer[17],\nAutoformer[16], Informer[28], Non-Stationary[24], TimesNet[18], TimesMixer[19], Crossformer[21] and\nPatchTST[22]. TimesMixer(MLP-based) is current SoTA baseline, and PatchTST is Transformer-based SoTA baseline.\nSetup. We follow the experimental setup of mainstream methods [22]. The input length is set to 960 or 1680 most case,\nsometimes 336 for short-term forecasting, according to the multi-periodicity. And the prediction length is varied with\nH = {96, 192, 336, 720}. We utilize the Adam optimizer with Mean Squared Error($MSE = \\sum_{i=1}(y_i - \\hat{y_i})^2$) as the\nloss function and evaluate using Mean Absolute Error(MAE =$\\sum_{i=1} |y_i \u2013 \\hat{y_i}|$) and MSE as metrics. The details of\nthe hyperparameter settings are shown in Table 2. All experiments were conducted on a single Nvidia A40 48GB GPU.\nThe source code is available at: https://github.com/Houyikai/LDM-Logsparse-Decomposable-MultiScaling."}, {"title": "4.2 Performance Analysis", "content": "SOTA Performence. We first evaluate the SoTA performance of the LDM framework with a previously proposed\npredictor3.4. Tables 3 and 4 concisely summarize the evaluation results of various methods, with baselines indicating the"}, {"title": "4.3 Efficiency Analysis", "content": "Previous subsection demonstrated the high performance of LDM, next we will show that LDM can also reduces cost,\nincluding training time and memory size.\nComplexity. We first analyzed the computational complexity, as detailed in\nTable 6. As a benchmark, the computational complexity of a Transformer scales\nquadratically with the input length L. Crossformer and PatchTST employ patch\nembedding and channel independence[22], resulting in a complexity that is\nquadratic with respect to the number of tokens $L_{seg} << L$ and linear with variate\nnumber M, where p is the token size and s is the stride. The LDM is broadly\ncategorized under this approach, and its performance largely hinges on the input\nlength of the initial scale, L1. However, due to the application of Log-sparse\nTruncation, L\u2081 is significantly less than L, resulting in a substantially reduced\noverhead for the LDM compared to models like the Crossformer or PatchTST.\nThis reduction enable the framework to take and use long contexts as input.\nEfficiency. We conducted experiments to measure the training time and memory\nusage (as reported by nvidia-smi) as we increased the sequence length from 96\nto 1440 for various models: PatchTST (a patch embedding Transformer) [22],\nFEDformer (a vanilla embedding Transformer) [17], TsMixer (a MLP model) [38], and DLinear (a linear model) [61].\nThese models are representative of their respective types. Utilizing the ETTm2 dataset with a fixed prediction length of\n96, the results are depicted in Fig. 7. The LDM model demonstrates lower training time and memory costs compared to\nother Transformer-based approaches, and it performs approximately on par with Linear and MLP models. This suggests\nthat even with a tenfold increase in input sizes and multiple levels of decomposition, LDM remains a more practical\napproach."}, {"title": "4.4 Model Analysis", "content": "Hyper-parameter Sensitivity. We evaluate the effect of two hyper-parameters: input length L, Sparsity \u03b7 and number\nof scales. Table 7 shows the results of L and \u03b7 in different settings. L in most cases tend to favour the longer the better,\nbut not absolutely. The situation of n is slightly more complicated, but $\\frac{1}{8}$ is a good balance, which is often used in the\nmain experiment. Decomposition makes each element simple, but larger number of scales is not always better as too\nmany can accumulate errors in the final aggregation. Two scales which will decompose into 3 elements is optimal, as\nshown in Table 8.\nAblation Study. Our approach introduces two components: the Multistate Decomposition(MD) in the LDM and the\nVanilla Embedding added in the predictor. Our ablation implemented on the ETTh1 dataset in line with previous\nwork[28, 21]. Two ablation versions are 1) without VE, 2) further without MD based on 1) which degenerate into a\nDSW embedding (none-overlapping Patch Embedding) Transformer[21]. The results are shown in Table 9. Removing\nVE impairs the model in long-term forecasting (336 and 720) because, as stated previously 3.4, prediction of large-\nscale components is effectively transformed into a short-term prediction task due to downsampling, and VE is more\nadvantageous in short-term forecasting. The problem is further exacerbated by remove MD."}, {"title": "4.5 Forecastability and Interpretability", "content": "Forecastability. Previous work[60] has suggested that the forecastability of a sequence is related to its information\nentropy, with lower entropy indicating stronger predictability. A sparse spectrum, where the energy of the signal is\nconcentrated in a few main frequencies, ensures lower information entropy. As shown in the small frames in Fig.8,\nmulti-scale decomposition results in sparse spectra at each scale, with most of the energy concentrated around a primary\nfrequency component. This decomposition not only simplifies the data spectrum but also makes underlying trends and\ncycles more apparent. Consequently, this helps models make more accurate predictions by reducing data complexity.\nInterpretability. The interpretability of our method stems from the separation of features at different scales. This\nseparation makes the features at each scale more distinct and independent, which facilitates identification and inter-\npretation. Fig.9 shows examples of expand forecasting results. By observing the model's behavior at different scales\nfacilitates a better understanding of the model. A simple example of using it as a debugging method is to check whether\nthe predicted results of each component meet expectations."}, {"title": "5 Conclusion", "content": "In this paper, we explore multiscale analysis methods for LTSF and introduce the Logsparse Decomposable Multiscaling\n(LDM) framework. Our findings indicate that the decomposition-based multiscale analysis method outperforms\ntraditional downsampling methods in terms of performance, versatility, and efficiency, even the efficiency of single-scale\nmodels. We further show that multiscale decomposition effectively reduces information entropy by generating a sparse"}]}