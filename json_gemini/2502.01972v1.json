{"title": "Layer Separation: Adjustable Joint Space Width Images Synthesis in Conventional Radiography", "authors": ["Haolin Wang", "Yafei Ou", "Prasoon Ambalathankandy", "Gen Ota", "Pengyu Dai", "Masayuki Ikebe", "Kenji Suzuki", "Tamotsu Kamishima"], "abstract": "Rheumatoid arthritis (RA) is a chronic autoimmune disease characterized by joint inflammation and progressive structural damage. Joint space width (JSW) is a critical indicator in conventional radiography for evaluating disease progression, which has become a prominent research topic in computer-aided diagnostic (CAD) systems. However, deep learning-based radiological CAD systems for JSW analysis face significant challenges in data quality, including data imbalance, limited variety, and annotation difficulties. This work introduced a challenging image synthesis scenario and proposed Layer Separation Networks (LSN) to accurately separate the soft tissue layer, the upper bone layer, and the lower bone layer in conventional radiographs of finger joints. Using these layers, the adjustable JSW images can be synthesized to address data quality challenges and achieve ground truth (GT) generation. Experimental results demonstrated that LSN-based synthetic images closely resemble real radiographs, and significantly enhanced the performance in downstream tasks. The code and dataset will be available.", "sections": [{"title": "1. Introduction", "content": "Rheumatoid arthritis (RA) is a chronic autoimmune inflammatory disease characterized by joint swelling and tenderness, resulting in progressive joint destruction combined with severe disability. In the diagnosis and management of RA, radiographic analysis plays a crucial role, and changes in joint space width (JSW) are recognized as a key indicator for assessing and monitoring disease progression (Aletaha & Smolen, 2018; Platten et al., 2017). However, conventional radiographic analysis relies heavily on the expertise and judgment of radiologists, which is limited by subjectivity, leading to low accuracy and sensitivity. Therefore, the development of computer-aided diagnostic (CAD) methods is considered urgent and significant (Kingsmore et al., 2021; Stoel et al., 2024). Deep learning-based CAD methods in joint space narrowing (JSN) progression quantification (Ou et al., 2023; Wang et al., 2023), JSW quantification (Langs et al., 2008), and Sharp/van der Heijde (SvdH) scoring (Hirano et al., 2019), are critically dependent on annotated data from experienced radiologists. Nevertheless, publicly available datasets with comprehensive annotations are scarce, while private datasets referenced in existing studies are typically small (often limited to 100 - 200 conventional radiographic images) (Stoel et al., 2024; Ahalya et al., 2022). Additionally, the existing datasets are further exacerbated by insufficient variety, inconsistent imaging quality, and significant imbalances in JSW distribution (early-stage RA samples are much larger than late-stage samples), as shown in Figure 1. Meanwhile, the limitations of conventional radiography and the complexity of the joint structures pose significant challenges for accurate joint annotation (joint classification and mask labeling). These limitations in annotated data critically hinder the performance of deep learning models and reduce the applicability of advanced models that require large datasets.\nTo address these data challenges, synthetic data has recently emerged as a promising approach in medical imaging (Koetzier et al., 2024). By generating image datasets that encompass diverse pathological features, varying levels of severity, and different regions, synthetic data enriches the data information available for model training. Synthetic data effectively tackles challenges related to limited patient populations, inconsistent data quality, and imbalanced distributions of disease stages. In addition, synthetic data mitigates biases introduced during data collection (Paproki et al., 2024), such as those arising from variations in equipment, operators, or patient populations, which enhances the objectivity and consistency. Significant advancements in synthetic medical imaging, driven by Variational Autoencoders (VAEs) (Doersch, 2016), Generative Adversarial Networks (GANs) (Goodfellow et al., 2020), and diffusion models (Ho et al., 2020), have revolutionized dataset augmentation, multi-modal imaging, and the generation and removal of pathological features. GANs have enhanced CT and MRI data by preserving essential features while increasing variability, and diffusion models have further improved image quality (Al Khalil et al., 2023; Khader et al., 2022). Multi-modal synthesis and modality conversion enable cross-modal analysis and enhance diagnostic robustness (Liu et al., 2021; Abu-Srhan et al., 2021). Pathology generation and removal models, such as tumor synthesis in MRI/CT and pulmonary nodule generation in radiography, have significantly improved related model performance (Cohen et al., 2021; Dai et al., 2024; Chen et al., 2024).\nA GAN-based framework, BLS-GAN (Wang et al., 2024), was proposed integrated with imaging principles to achieve bone region generation in conventional radiography of joints, effectively eliminating overlapped regions, which offers a significant contribution to RA research. Although it successfully extracts the upper and lower bone textures, its primary focus is on the generation of bone regions, with a comparative limitation in the generation of soft tissue and layer separation between bone and soft tissue. Given that soft tissue is a critical component of joint structures, its realistic generation is essential to enhance the realism and diversity of bone region generation. Without the generation of soft tissue, this work is limited to tasks involving partially background-free quantification of JSN progression.\nAt present, there is a notable gap in research concerning the synthetic data for RA, and an absence of comprehensive data synthesis methods. Furthermore, traditional data augmentation with generation models faces significant limitations, particularly in their inability to effectively adjust JSW and address the challenges posed by imbalanced data distribution. However, the layer separation method employed by BLS-GAN warrants attention. Separately extracting the tissue layers of the image, followed by adjusting bones and reconstruction, can be considered as a process for constructing synthetic data for RA.\nThis work proposes an innovative finger joint Layer Separation Networks, LSN, to achieve a high-accuracy separation of upper bone, lower bone, and soft tissue layers, with the aim of providing foundational support for more comprehensive and diverse synthetic data. Specifically, our research contributions are as follows.\n\u2022 Layer separation networks: A novel network architecture to achieve highly realistic separation of bones and soft tissue layers simultaneously. Soft tissue discrimination network and random shifting function are introduced to achieve smooth and realistic soft tissue generation.\n\u2022 Adjustable JSW images synthesis: A challenging scenario in synthetic data, adjustable JSW images synthesis is introduced, and a state-of-the-art image synthesis method is proposed. The synthetic images are highly realistic, providing a valuable resource for advancing research in RA.\n\u2022 Improvement of downstream tasks: The synthetic joint data demonstrates the potential to significantly improve the accuracy, stability, and robustness of downstream tasks while reducing the reliance on annotated training data."}, {"title": "2. Methodology", "content": "2.1. Problem Formulation\nWe propose a challenging research scenario for RA synthetic images: Adjustable JSW Images Synthesis. The problem formulation in the adjustable JSW images synthesis involves (i) layer separation for soft tissue, upper and lower bones, (ii) reconstruction from the layer images after shifting (specified parameters or random parameters). This requires addressing several critical challenges: (i) ensuring that the generated layer images adhere to the radiographic imaging principles in the overall image, (ii) eliminating the bone overlap in finger joints caused by disease progression or improper hand positioning, (iii) generating clear and homogeneous soft tissue layers that are devoid of bone shadows and conform to radiographic characteristics."}, {"title": "2.2. Layer Separation Networks", "content": "Assuming that in conventional radiography of finger joints, the joint image is formed only through the overlap of upper, lower bones and soft tissue textures, following specific principles. The LSN is proposed to extract layer images of the upper bone, lower bone, and soft tissue in conventional finger joint radiography. As shown in Fig. 2, the LSN consists of three basic sub-networks: the layer image generation network, the segmentation-based supervision network, and the soft tissue discrimination network. We define the generated layer images as 0, ..., i, ..., n, where n is set to 2 and 0 is set as the soft tissue layer, 1 and 2 are set as the lower bone and upper bone layers.\nLayer Image Generation Network We perform a generation network to separate the texture in the layer domain and generate images that conform to the texture distribution of each layer. The backbone network here can be any generation network; we performed transUnet (Chen et al., 2021) here. The input is the joint image J and its corresponding masks $M = \\{M_0, ..., M_n\\}$. The output of the generation network is defined as $L = \\{L_0, ..., L_n\\}$. Assuming the layer image generator is denoted as $N_G$, the generation process can be defined as Eq.1\n$L = N_G(J). M$ (1)\nSegmentation-based Supervision Network We integrate a segmentation network for pixel-level supervision. The network outputs masks with three channels containing upper and lower bones without overlapped regions, and soft tissue. Through the principle of adversarial generation, the network achieves pixel-level differentiation of soft tissue, bones, and overlapped bone region distributions in the shifted reconstruction joint image, which enables unsupervised optimization without layer-independent GT images while partially mitigating the bone shadows. The segmentation network supports the use of various backbones. In this study, Unet is employed as the backbone.\nThe layer images from the generation network L serve as the input. The output is defined as $M' = \\{M'_0, ..., M'_n\\}$."}, {"title": "Layer Separation: Adjustable Joint Space Width Images Synthesis in Conventional Radiography", "content": "Suppose that the segmentation network is denoted as $N_S$. Therefore, the supervision process can be defined as Eq.2, where Ms represents the segmentation mask.\n$M_S = N_S(R')$ (2)\nSoft Tissue Discrimination Network In our perspective, the presence of bone shadows in the soft tissue severely affects the quality of the generated results. Thus, we introduce a discrimination network to achieve bone shadow segmentation and supervise the generation network. Our objective can be described as ensuring the bone shadow regions in the generated soft tissue images are indistinguishable, while maintaining a consistent texture distribution between bone shadow and non-bone shadow regions. Therefore, the discrimination network is structured to produce a lower loss when bone shadows are present and a higher loss when bone shadows are absent or substantially reduced. Meanwhile, for adversarial training, the loss function of the generation network is formulated as the dual counterpart of the loss function in the discrimination network.\nThe soft tissue layer images $L_0$ serve as the input to the network. The output is defined as $M_D$. Suppose that the discrimination network is denoted as $N_D$. Therefore, the discrimination process can be defined as Eq.3.\n$M_D = N_D(L_0)$ (3)\nRadiography Imaging Principles based Reconstruction According to the principles of conventional radiography, different tissues exhibit varying absorption rates. Tissues with higher density demonstrate greater absorption, while those with lower density exhibit weaker absorption, resulting in radiographic representations (Bushberg & Boone, 2011; Huda & Abrahams, 2015). In the presence of tissue overlap, the X-ray absorption by the upper tissues influences the imaging of the lower tissues, showing an exponential decay.\nTherefore, we introduce a reconstruction process for layer images. In this process, the image is reconstructed according to the reconstruction function $f_R$, as defined in Eq. 4, where R denotes the reconstructed image. Specifically, the images of the absorption rate can be defined as 1 \u2212 L.\n$R = f_R(L) = 1 - \\prod_{i=0}^n(1 - L_i)$ (4)\nRandom Shifting To remove bone shadows more accurately and introduce the synthesis process into the network architecture, we incorporate a random shifting process of bones, which serves as a supervisory mechanism for the generation network. Our generation process adheres to the principles of radiographic imaging. Ideally, given accurately generated soft tissue, reconstruction after random shifting will not introduce bone shadows, and the reconstructed images can be correctly segmented by the supervision network.\nThe input element A is randomly shifted according to the function $f_S$, as defined in Eq. 6, where A' represents the shifted elements and t denotes the shifting matrix with translation $x_i, y_i$ and rotation $\u03b8_i$. Therefore, the reconstructed shifted image R' and the shifted mask M' can be defined as R' = $f_R(f_S(L,t))$, M' = $f_S(M,t)$\n$t_i = \\begin{bmatrix} \\cos(\\theta_i) & -\\sin(\\theta_i) & x_i \\\\ \\sin(\\theta_i) & \\cos(\\theta_i) & y_i \\end{bmatrix}$ (5)\n$A' = f_S(A,t) = \\{A_0, A_i \\cdot t_i |i = 1, ..., n\\}$ (6)\nLoss Function We construct the loss function based on binary cross entropy (BCE) loss $L_b(y, \u0177)$ (Yeung et al., 2022) and root mean squared error (RMSE) loss $L_r(y, \u0177)$ (Chai & Draxler, 2014), where y represents the predicted value and \u0177 represents the GT.\nFor the supervision of the generation network, the network loss function consists of three parts: reconstruction loss, supervision network loss, and soft tissue discrimination loss, which can be defined as Eq. 7, where $M_\\cap = \\cap_{i=1} M_i, M_U = U_{i=1} M_i$. According to experimental experience, the weights of each loss function are as follows: \u03b1 = 0.6, \u03b2 = 0.3, \u03b3 = 0.1.\n$L_0 = L_r(R, J) + L_r(R_0, J_\\cap)$ (7)\n$L_1 = L_b(N_S(R'), M')$ \n$L_2 = 1 - L_b(N_D(L_0), M_U)$\n$L = \u03b1L_0 + \u03b2L_1 + \u03b3L_2$\nIn addition, we train the supervision and discrimination networks simultaneously and independently. The input of the supervision network is the original image J, and the corresponding GT is the masks without overlapped regions, denoted as $M' = \\{M_1 - M_\\cap, \u2026\u2026, M_n \u2013 M_\\cap\\}$. The loss function is defined as Eq. 8.\n$L_S = L_b(N_D(J), M')$ (8)\nAs for the soft tissue discrimination network, the input of the network is the generated soft tissue layer image $L_0$, and the corresponding GT is the union of bone masks $M_U$. The loss function is defined as Eq. 9.\n$L_D = L_b(N_D(L_0), M_U)$ (9)\nPseudo Images and Two-stage training In order to improve the stability and accuracy of the network, we create pseudo-images $J'$ for two-stage training, with overlapped regions based on non-overlapped images by modifying the image processing described in BLS-GAN (Wang"}, {"title": "Layer Separation: Adjustable Joint Space Width Images Synthesis in Conventional Radiography", "content": "et al., 2024). In particular, the correction parameter k is determined by solving the Laplace equation, after which the shifted upper and lower bones are reconstructed, and the soft tissue region is subsequently spliced, defined as Eq. 10, where J' and M' represent the image and the corresponding masks with random scaling and translation. $B = \\{B_i = J' \u2022 M'_i | i = 1, ..., n\\}$represents the bone region with soft tissue texture.\n$J = (1 \u2212 k (1 \u2013 B_i)) + J'\u22c5 U M'_i$ (10)\nWe perform the first stage using pseudo-images as dataset D1. Specifically, since the pseudo-images are created from non-overlap images, we can effectively obtain non-overlap upper and lower bone GT. Therefore, B and the randomly shifted B' = $f_S (B, t_b)$ are included as GT, and the modified loss function is denoted as Eq. 11, where $R_0 = f_R(L)$. $M_b, M'_b = \\{M_1, ..., M_n\\}$, $R'_0 = f_R(f_S(L, t_b))$. M, $M' = f_S(M_b, t_b)$. In addition, when training the segmentation network, J (non-overlap) is also used as a non-overlap image sample for the loss function, denoted as Eq.12. The weights of the loss functions are as follows: \u03b1' = 0.5, \u03b2' = 0.2, \u03b3' = 0.2, \u03b4' = 0.1; \u03b1\" = 1, \u03b2\" = 0.4, \u03b4' = 0.4.\n$L_3 = 0.5 \u00d7 L(R_0, B) + 0.5 \u00d7 L(R'_0, B')$\n$L = \u03b1' L_0 + \u03b2' L_1 + \u03b3' L_2 + \u03b4' L_3, if epoch > m$ (11)\n$\u0108 = \u03b1'' L_0 + \u03b2'' L_1 + \u03b4' L_3, if epoch < m$\n$L_S = 0.5 \u00d7 L_b(D(\u0134), M') + 0.5 \u00d7 L_b(D(J), M)$ (12)\nIn the second training, due to the absence of GT for the upper and lower bones in real images, we continue to apply the original loss function and utilize both pseudo and real images as a dataset D2. Therefore, the training pipeline can be defined as Algorithm 1.\nImplementation The networks were implemented on a workstation with three GPUs (NVIDIA GeForce GTX 2080 Ti). The generation, supervision, and discrimination networks were trained using the AdamW optimizer with an initial learning rate as follows: $\u03b7_G = 1e-4$, $\u03b7_S = 1e-4$, $\u03b7_D = 5e-4$, decreasing by 0.5 every 100 epochs. The image size processed by LSN is set to 256 \u00d7 256. In our practice, we commence by performing first-stage training on D1, extending this preparatory phase across 300 epochs and m is set to 200, with a batch size of 12. Subsequently, we refine the loss function and GT, maintaining the same batch size, for an additional 100 epochs on D2 to optimize the performance of our networks."}, {"title": "Layer Separation: Adjustable Joint Space Width Images Synthesis in Conventional Radiography", "content": "2.3. Adjustable JSW Image Synthesis\nUsing the layer images generated from LSN, the adjustable JSW synthetic image $J*$ can be efficiently achieved. The process is as follows: (i) By applying the shifting function $f_S$ with specified or random parameters in a predefined range to the upper and lower bones; (ii) Reconstructing the shifted bone layers with the soft tissue layer by $f_R$. A substantial dataset of synthetic images with varying JSW can be created from a single input image, as illustrated in Eq.13, where $t*$ denotes the shifting parameters. Combined with the original annotations (e.g., JSW and SvdH), the shifting parameters can be used to produce GT of this synthetic image.\n$J^* = f_R(f_S(L,t^*))$ (13)\n3. Experiments\n3.1. Joint Image Dataset\nThe original real joint image dataset in BLS-GAN (Wang et al., 2024) was used for training and testing. The dataset contains 430 MCP joints for 1,594 joint images with corresponding annotated bone masks, which are divided into training and testing sets at a 3:1 ratio by joint.\nFor downstream tasks, the JSW of each image was annotated using the method developed based on the layer separation, under the guidance of experienced radiologists. Specifically, the method enabled manual alignment of the upper and lower bones by adjusting their positions to align the boundaries of the joint contact surfaces, where the JSW value was defined as zero. Thus, the JSW was subsequently calculated as the difference between the displacements of the bone layers. The annotated JSW data will be made publicly available. Meanwhile, we constructed the SvdH-like score annotations based on JSW annotations according to the SvdH scoring definition (Van der Heijde, 2000; Van der"}, {"title": "Layer Separation: Adjustable Joint Space Width Images Synthesis in Conventional Radiography", "content": "Heijde et al., 1999). Specifically, the annotations were established according to the following criteria: 0: normal; 1: 100%-75% of normal JSW; 2: 75%-50% of normal JSW; 3: 50%-25% of normal JSW; 4: less than 25% of normal JSW (normal average joint space: 1.75 mm (Pfeil et al., 2007)).\n3.2. Reconstruction Images Evaluation\nDue to the absence of GT for layer images, the evaluation was conducted exclusively on reconstructed images and real images. The network predicted the upper bone, lower bone, and soft tissue layers, subsequently reconstructing the images through the reconstruction function, which were compared to the corresponding real images for evaluation. The performance assessment employed four quantitative metrics: mean squared error (MSE), structural similarity index (SSIM), peak signal-to-noise ratio (PSNR), and Fr\u00e9chet Inception Distance (FID).\nAs illustrated in Table 1, LSN demonstrated strong performance across various finger joints, showing exceptional stability and adaptability, and consistently produced high-quality generation outcomes. Figure 3 further underscored the ability of LSN to generate accurate and clear layer images for both bones and soft tissue. Even under challenging conditions involving bone overlap, especially with large overlap sizes, the method effectively reconstructed the upper and lower bone layers while eliminating overlaps. Furthermore, the soft tissue layer generated by the network was characterized by a uniform texture devoid of bone shadows. In particular, the shifted reconstruction images closely resembled the real images and were free of bone shadows. Overall, the proposed method achieved accurate layer separation from single-joint images, providing a solid data foundation for generating synthetic images.\n3.3. Ablation Study\nAn ablation study was performed to evaluate the impact of individual sub-networks on the overall network performance. This study involved a stepwise evaluation of various pipeline configurations, including the supervision network $N_S$, discrimination network $N_D$, and the first-stage training $T_1$, using the generation network $N_G$ and reconstruction function $f_R$ as the Baseline. We also conducted a specific study for the random shifting function $f_S$, given its extensive application in multiple processes in the architecture.\nThe results presented in Table 2 and Figure 4 demonstrated that the sub-networks, functions, and training strategies integrated into the LSN collectively contributed to and enhanced the final results. Specifically, the incorporation of $N_S$ effectively guided the generation network in the absence of bone layer GT and under conditions of random shifting,"}, {"title": "Layer Separation: Adjustable Joint Space Width Images Synthesis in Conventional Radiography", "content": "thereby partially mitigating the appearance of bone shadows in the soft tissue layer. The inclusion of $N_D$ substantially reduced bone shadows in the soft tissue layer, although it introduced a trade-off by slightly reducing the accuracy of the reconstructed images. The incorporation of $T_1$ significantly enhanced both accuracy and stability. The introduction of $f_S$ enabled effective supervision of texture generation in each layer, which was essential for suppressing bone shadows at the edges of the original bone region in the soft tissue layer. This also facilitated the generation of soft tissue layers with uniform texture distribution and enhanced realism. Additionally, while excluding $N_D$ resulted in higher quantitative metrics, the generated soft tissue layers contained pronounced bone shadows, rendering the results clinically unacceptable. In contrast, the inclusion of $N_D$ produced more homogeneous and clinically viable soft tissue layers, although with slightly lower metric scores, which aligned with the main objectives of this study.\n3.4. Visual Turing Test\nWe conducted a visual Turing test on a set of 100 images (real and synthetic images in a 1:1 ratio), as shown in Fig. 5, which was explained to the subjects. Five subjects with 13, 18, 20, 27, and 32 years of experience as radiological technologists participated in the test.\nAs shown in Table 3, the results of the visual Turing test indicated that the experts demonstrated moderate proficiency in distinguishing between real and synthetic images, achieving an average accuracy of approximately 0.7. However, substantial variability was observed among individual experts. In particular, R1 and R3 exhibited high sensitivity and specificity, while R5 performed poorly in all metrics, underscoring the challenges associated with recognizing synthetic images. These results suggest that the generated images effectively replicate the characteristics of real images to a certain extent, exhibiting a similar texture distribution. Consequently, even experienced experts face considerable difficulty in differentiating between synthetic and real images. Compared to Wang et al. (2024), our task is more complex and difficult, which is primarily due to the additional generation of soft tissue and synthesis steps, including the random shifting of bones and reconstruction."}, {"title": "Layer Separation: Adjustable Joint Space Width Images Synthesis in Conventional Radiography", "content": "3.5. Improvement in Downstream Tasks\nWe verified the improvement of the model in downstream tasks by introducing LSN synthetic data pre-training in controlled experiments (Pre-training pipeline: downstream model + pre-training; Control pipeline: downstream model), where synthetic data is created in multiples from the original images, and the GT is automatically generated by the LSN. Downstream tasks include JSN progress quantification, JSW quantification, and SvdH-like JSN score qualification. The networks in the experiment were trained to full convergence with a uniform total number of epochs.\nJSN Progress Quantification For the JSN progress quantification, we performed the deep registration method proposed in (Wang et al., 2023). The evaluation of the experimental results followed the metrics established in (Ou et al., 2023), including the mean squared error (MSE), standard deviation (\u03c3), and phase standard deviation (\u03c3').\nAs shown in Table 4, the pre-training pipeline outperformed the control pipeline, achieving lower values across all three evaluation metrics. The reduction in MSE reflected a modest improvement in accuracy. Moreover, the decreases in the two standard deviation metrics (\u03c3, \u03c3') indicated substantial enhancements in stability and robustness. These experimental results aligned with the expected performance gains associated with the pre-training, demonstrating its effectiveness in improving both accuracy and consistency.\nJSW Quantification For the JSW quantification, the conventional method typically employs a supervised edge detection algorithm combined with edge distance calculation, which heavily depends on manual annotation. Therefore, the experiments conducted a ResNet50-based regression net-"}, {"title": "Layer Separation: Adjustable Joint Space Width Images Synthesis in Conventional Radiography", "content": "work for JSW quantification. The evaluation of outcomes was conducted using metrics including mean squared error (MSE), mean absolute error (MAE), explained variance score (EVS), and the coefficient of determination (R2).\nAs presented in Table 4, the overall accuracy of JSW quantification using the regression method remained relatively low, due to the abandonment of edge detection, which was consistent with historical observations in practical applications. However, the pre-trained pipeline demonstrated significantly enhanced performance across multiple evaluation metrics compared to the control pipeline. These improvements were evident in all aspects of the evaluation, underscoring the effectiveness of LSN synthetic image pre-training in substantially improving the accuracy, stability, and robustness of the JSW measurement model.\nSvdH-like JSN Score Qualification For the SvdH-like JSN score qualification, a ResNet-50-based classification network was employed as the downstream task network for evaluation. The experimental results were evaluated using several performance metrics, including accuracy (ACC), sensitivity (SEN), specificity (SPC), and precision (PRE).\nThe SvdH scoring system, as a qualification system based on human visual assessment, often involves redundancy and ambiguity. Consequently, a straightforward division and construction of an SvdH-like scoring system based on JSW could not fully and accurately simulate the original SvdH system. This limitation was reflected in the overall accuracy, which remains below 0.95. Nonetheless, in the SvdH-like scoring system, as presented in Table 4, the integration of LSN synthetic images pre-training has led to notable improvements across multiple evaluation metrics compared to the control pipeline. These enhancements demonstrate the effectiveness of the pre-training pipeline in boosting the accuracy, stability, and robustness of the model.\nReduced Annotations for Training The performance of downstream models in registration, regression, and classification is highly dependent on the amount and diversity of annotated training data used during the training stage (Jaipuria et al., 2020). Therefore, we studied the relationship between the amount of real annotated images and the performance of downstream task models in controlled experiments. Specifically, for real annotated data, we reduced it by a certain ratio (5%, 10%, 20%, 40%, 80% of the original"}, {"title": "Layer Separation: Adjustable Joint Space Width Images Synthesis in Conventional Radiography", "content": "datasets), and for synthetic data, we reduced the original real data used to create synthetic data and amplified it into an equal amount of synthetic data.\nAs illustrated in Figure 6, the control pipeline exhibits a linear correlation between performance and the number of annotated training data, highlighting the critical role of the influence of the number of annotated training data on the final results. With limited training data, the network demonstrated issues such as instability, overfitting, and susceptibility to local optimization. Notably, tasks trained with a minimal amount of annotated data (e.g., 5%) showed pronounced overfitting, and the model failed to converge in some cases. In contrast, the pre-training pipeline achieved significantly greater stability and accuracy under the same conditions. Even with a limited amount of annotated data (e.g., 5% and 10%), the network demonstrated relatively stable performance and maintained its ability to train and fine-tune effectively. The results underscore that incorporating synthetic data pre-training significantly enhanced the robustness and reliability of the downstream models, leading to more stable and accurate outcomes. It also reduced the dependence on high-precision, manually annotated data.\n4. Conclusion\nIn this study, the Layer Separation Networks is proposed and implemented for layer separation and adjustable JSW image synthesis, which effectively addresses existing challenges in"}, {"title": "Layer Separation: Adjustable Joint Space Width Images Synthesis in Conventional Radiography", "content": "data distribution and variety, and achieves the generation of GT annotation. Experimental results demonstrated that LSN generates high-quality images of the upper, lower bone, and soft tissue layer images, aligning with imaging principles. Furthermore, the reconstructed images exhibit a high similarity to the original images and perform well in the Turing test. Additionally, evaluation of downstream tasks indicated that synthetic data pre-training significantly enhanced the robustness, stability and accuracy of downstream models. This study can provide a valuable support for RA-related research and CAD development."}, {"title": "Software and Data", "content": "If a paper is accepted, the code and dataset will be publicly available with the camera-ready version of the paper whenever appropriate."}, {"title": "Impact Statement", "content": "This paper presents work whose goal is to advance the field of Machine Learning. There are many potential societal consequences of our work, none which we feel must be specifically highlighted here."}]}