{"title": "OpenCity: Open Spatio-Temporal Foundation Models for Traffic Prediction", "authors": ["Zhonghang Li", "Long Xia", "Lei Shi", "Yong Xu", "Dawei Yin", "Chao Huang"], "abstract": "Accurate traffic forecasting is crucial for effective urban planning and transportation management, enabling efficient resource allocation and enhanced travel experiences. However, existing models often face limitations in generalization, struggling with zero-shot prediction on unseen regions and cities, as well as diminished long-term accuracy. This is primarily due to the inherent challenges in handling the spatial and temporal heterogeneity of traffic data, coupled with the significant distribution shift across time and space. In this work, we aim to unlock new possibilities for building versatile, resilient and adaptive spatio-temporal foundation models for traffic prediction. To achieve this goal, we introduce a novel foundation model, named OpenCity, that can effectively capture and normalize the underlying spatio-temporal patterns from diverse data characteristics, facilitating zero-shot generalization across diverse urban environments. OpenCity integrates the Transformer architecture with graph neural networks to model the complex spatio-temporal dependencies in traffic data. By pre-training OpenCity on large-scale, heterogeneous traffic datasets, we enable the model to learn rich, generalizable representations that can be seamlessly applied to a wide range of traffic forecasting scenarios. Experimental results demonstrate that OpenCity exhibits exceptional zero-shot predictive performance. Moreover, OpenCity showcases promising scaling laws, suggesting the potential for developing a truly one-for-all traffic prediction solution that can adapt to new urban contexts with minimal overhead. We made our proposed OpenCity model open-source and it is available at the following link: https://github.com/HKUDS/OpenCity.", "sections": [{"title": "1 INTRODUCTION", "content": "Transportation is an essential component of urban activities, serving as the fundamental infrastructure that supports the efficient movement of people and goods within cities [33, 41]. Precise traffic forecasting allows for proactive traffic management, enabling transportation planners to anticipate and mitigate potential congestion, delays, and disruptions [13, 17]. This, in turn, enhances the overall efficiency and sustainability of urban transportation networks, fostering the real-world intelligent transportation systems.\nThe success of deep learning has empowered spatio-temporal models for traffic forecasting. These models leverage deep neural networks to learn effective representations that can better capture the spatial and temporal dependencies inherent in urban traffic data. However, despite these advancements, current traffic prediction models often face significant limitations in terms of generalization.\nCross-Regional Model Spatial Generalization. Firstly, A key limitation of current traffic prediction models is their struggle with spatial generalization. These models often fail to perform well when applied to unseen regions or cities, as traffic patterns and dynamics can vary considerably across geographical locations due to factors like infrastructure, demographics, and urban planning [1]. Existing models typically learn from data limited to specific regions, making them unable to effectively generalize their knowledge to capture the unique characteristics of unfamiliar traffic environments.\nThis issue is critical, as it is impractical to deploy comprehensive sensor networks across entire urban areas to collect traffic data [15, 26]. A more viable approach is to build models that can generalize well to unseen regions using only partial data. Additionally, developing spatio-temporal models that are applicable across different cities would significantly reduce deployment and maintenance costs [15, 40]. However, when these models are applied in new locations, they often experience a significant drop in predictive performance, hindering their wider applicability. This spatial generalization challenge is crucial to address in order to create traffic forecasting solutions that can be seamlessly deployed across diverse urban settings without extensive retraining or fine-tuning.\nTemporal Generalization for Long-term Forecasting. Current traffic prediction models excel at short-term forecasting, such as anticipating conditions for the next hour [3, 12]. However, their ability to generalize to longer time frames, like days or weeks ahead, is notably limited. This limitation is largely due to the models' poor generalization ability in effectively handling the evolving temporal distribution shifts that occur over longer time horizons in practical urban scenarios. As the forecasting timeframe increases, these models struggle to capture and account for the dynamic changes in traffic patterns that influence long-term traffic conditions.\nThis limitation presents a considerable obstacle for city planners and transportation agencies striving to devise effective long-term strategies. Precise long-term traffic forecasts are crucial for a range of applications, including proactive infrastructure planning, public transit scheduling, and event logistics coordination. Despite their importance, existing models often fall short when it comes to providing reliable predictions beyond the immediate future.\nIn recent years, the remarkable capabilities of large foundation models have captured significant attention across various domains. These models, trained on vast and diverse datasets, have demonstrated exceptional performance in natural language processing (NLP) [2, 28] and computer vision (CV) [10, 16] tasks, showcasing their remarkable abilities to comprehend and generalize from complex data. While the success of foundation models has been"}, {"title": "2 PRELIMINARIES", "content": "Spatio and Temporal Unit Generation. Traffic data is inherently spatio-temporal in nature, reflecting the dynamic patterns and spatial distribution of transportation networks. It is typically represented as a two-dimensional matrix \\(X \\in \\mathbb{R}^{R \\times T}\\), where each element corresponds to a specific traffic metric (e.g., flow, speed, or demand), for a given region r and time interval t. There are two prevalent forms of spatial region unit used to model traffic data:\n\u2022 i) Sensor-based Traffic Network: The traffic data is collected through an irregular sensor network across major roads. Each sensor represents a region, and the region relationships are modeled using a graph \\(G = (V, E, A)\\), where V are regions, E are edges, and \\(A \\in \\mathbb{R}^{R \\times R}\\) is a weighted adjacency matrix capturing spatial dependencies, based on geographical distance.\n\u2022 ii) Grid-based Traffic Network: the urban area is partitioned into a regular grid of uniform square blocks, often with dimensions of 1km \u00d7 1km. This grid-like spatial representation allows the transportation network to be modeled using a graph structure, where each grid block is represented as a node, and the connections between neighboring regions are captured as edges.\nTraffic Flow Forecasting. The task of traffic forecasting is to use data from the past H time steps \\((X_{t_1-H+1:t_1})\\) to predict traffic data \\(Y_{t_1+1:t_1+F}\\) for the future F time steps. This involves exploring the complex spatial and temporal patterns inherent in traffic data to"}, {"title": "3 METHODOLOGY", "content": "3.1 Spatio-Temporal Embedding for\nDistribution Shift Generalization\nThe design of our spatio-temporal embedding layer is driven by the need to address the distribution shift across both spatial and temporal dimensions in traffic prediction tasks. In real-world intelligent transportation systems, traffic flow patterns can vary considerably across different geographical regions and time periods. This inherent data heterogeneity presents a major obstacle for traffic prediction models, as they need to generalize their performance to new environments or scenarios where the underlying data distribution may be drastically different from the training data.\n3.1.1 In-Context Normalization for Zero-Shot Generalization. Existing approaches often leverage statistical features of the training data, such as mean and standard deviation, for data normalization. However, these summary statistics may be inadequate or non-transferable when the test data exhibits significant data heterogeneity and has no spatial overlap with the training data distribution. To address this challenge and accommodate zero-shot traffic prediction tasks, we employ instance normalization IN() to process the data. This approach utilizes the mean and standard deviation of the individual input instances \\(X_{r,t} \\in \\mathbb{R}^{T}\\) for each region, rather than relying on the global training set statistics. The formalization of this process is as follows:\n\\[\\hat{X_{r,t}} = IN(X_{r,t}) = \\frac{X_{r,t} - \\mu_r}{\\sigma_r}\\]\nWhere \\(\\mu(X_r)\\) and \\(\\sigma(X_r)\\) are the mean and standard deviation of the input instance \\(X_r\\), respectively. Subsequent denormalization is applied to the prediction outputs to achieve more accurate results. Studies [10, 34] indicate that instance normalization effectively mitigates distribution shifts between training and test sets, advantageous for our zero-shot traffic prediction scenarios.\n3.1.2 Patch Embedding for Efficient Long-Term Prediction. The proposed OpenCity model is designed to address long-term traffic prediction, which often involve processing an increased number of input time steps. This can lead to significant computational and memory overhead. To mitigate these issues, we employ a patch-based approach [5, 27] to partition the data along the temporal dimension. We define P as the patch length, specifying the number of time steps grouped into a single patch, and S as the stride size, determining the overlap between successive patches. After the patch operation, the input data \\(X_r \\in \\mathbb{R}^{T}\\) is reshaped to \\(X_P \\in \\mathbb{R}^{P \\times N}\\), where N is the number of blocks, calculated as \\(N = \\frac{T-P}{S} + 1\\). Our patch embedding scheme offers several key advantages:\n\u2022 Handling Temporal Distribution Shift. By considering one hour of traffic data as the length of a single patch and adjusting the stride accordingly (\\(S = P\\)), our model can effectively handle the temporal distribution shifts often encountered in long-term traffic prediction. This allows the model to capture and adapt to the evolving patterns in traffic data over extended time horizons.\n\u2022 Computational Efficiency. The patch-based processing significantly reduces the computational and memory requirements, as the model operates on a smaller number of input patches rather than the entire temporal sequence. This enables more efficient and scalable long-term traffic prediction, making the model suitable for real-world deployments.\nAfter the patch-based partitioning of the input data, we employ a linear transformation and positional encoding to obtain the final spatio-temporal data embedding \\(E_r \\in \\mathbb{R}^{P \\times d}\\). This embedding serves as the input to the subsequent model components:\n\\[E_r = W_e \\cdot X_P + PE(X)\\]\nHere, \\(W_e \\in \\mathbb{R}^{N \\times d}\\) is the weight parameter, and PE denotes the Sinusoidal Position Encoding [35], which helps the model capture temporal relationships within each patch. Our temporal patch embedding schema compresses the input time steps, enabling the model to efficiently perform long-term traffic prediction and overcome challenges posed by increased input time steps, which is crucial for accurate long-term forecasting.\n3.2 Spatio-Temporal Context Encoding\nTo capture the complex spatio-temporal patterns inherent in traffic data, our model integrates both temporal and spatial context cues. By explicitly modeling the interplay between these two critical"}, {"title": "YtI+1:tI+F = f(Xt1-H+1:t1)", "content": "uncover the underlying dynamics that drive changes in traffic flow.\n\\[Y_{t_I+1:t_I+F} = f(X_{t_1-H+1:t_1})\\]\nwhere \\(f()\\) represents the spatio-temporal prediction function.\nSpatio-Temporal Generalization. In this work, we propose a foundation model to empower traffic prediction with strong generalization capabilities across both spatial and temporal dimensions.\n(i) Temporal Generalization for Long-term Forecasting. Most existing traffic prediction models are limited to forecasting only short-term (e.g., next hour) traffic variations. These models often struggle to generalize well to long-term traffic forecasting due to their poor temporal generalization ability. However, in practical applications, long-term traffic forecasting (e.g., days or weeks into the future) is critically important and highly beneficial for various transportation planning and management tasks.\n(ii) Spatial Generalization for Zero-Shot Forecasting. In real-world intelligent transportation systems, data heterogeneity and scarcity pose significant challenges. For instance, traffic flow patterns can vary substantially across different geographical regions within a city, and also differ considerably between cities. This presents a major obstacle for current traffic flow prediction models, as they often struggle to generalize their performance to new locations where little or no historical data is available.\nGiven the discussion above, we can formally define the traffic flow prediction task with strong spatio- temporal generalization:\n\\[Y_{t_I+1:t_I+F} = f(X_{t_1-H+1:t_1})\\]\nDifferent from the predictive function (f(.)) in existing spatio-temporal models, the proposed f(.) is a generalized spatio-temporal foundation model. This model can be directly utilized to make predictions on downstream unseen traffic data X, which has no overlap with the training data X. f(\u00b7) is pre-trained on a diverse set of traffic data sources. It captures the underlying patterns and relationships that govern traffic dynamics across different spatial and temporal contexts. This enables zero-shot traffic flow forecasting without requiring any additional fine-tuning or adaptation steps."}, {"title": "4 EVALUATION", "content": "In our experimental evaluation, we address the following six key research questions to validate the capabilities of our model:\n\u2022 RQ1: Can the proposed OpenCity model effectively generalize to zero-shot and long-term traffic forecasting scenarios?\n\u2022 RQ2: How effectively does the proposed OpenCity framework integrate cross-data traffic patterns into a single and coherent model in supervised learning environments?\n\u2022 RQ3: Does the model have the capability to rapidly generalize to new transportation forecasting demands as they emerge?\n\u2022 RQ4: What are the individual contributions of the different modules to the performance gains of the OpenCity approach?\n\u2022 RQ5: How the model's parameter count and training data volume scale to affect its overall forecasting performance?\n\u2022 RQ6: Compared to existing large-scale spatio-temporal prediction models, what key advantages does our approach offer in terms of prediction performance and efficiency?\n4.1 Experimental Setup\n4.1.1 Data Sources and Characteristics. The model's generalization capabilities and predictive performance were extensively evaluated using a diverse set of large-scale, real-world public datasets covering various traffic-related data categories, including Traffic Flow, Taxi Demand, Bicycle Trajectories, Traffic Speed Statistics, and Traffic Index Statistics, from regions across the United States and China, such as New York City, Chicago, Los Angeles, the Bay Area, Shanghai, Shenzhen, and Chengdu. In addition, we released 3 versions OpenCity based on parameter size: OpenCitymini (2M), OpenCitybase (5M), and OpenCityplus (26M). Further details on all experimental datasets are provided in the Appendix.\nIn the pre-training stage of the OpenCity approach, we leveraged a wealth of transportation data, encompassing the traffic flow, traffic speed, and taxi demand datasets. This expansive dataset covers a total of 10,110 regions and 352,796 time points, amounting to an astounding 151,089,924 observations. For the testing phase, we selected data that was outside the training set, allowing us to assess the model's generalization performance across a diverse range of traffic prediction scenarios. These scenarios include:\n\u2022 Cross-Region Zero-Shot Evaluation: Assessing the OpenCity's ability and robustness to generalize to unseen regions within a city, without the need for additional training.\n\u2022 Cross-City Zero-Shot Evaluation: Examining the model's capacity to adapt to completely new cities, leveraging the knowledge acquired during the original training process.\n\u2022 Cross-Task Zero-Shot Evaluation: Testing the model's ability to forecast different types of traffic-related data, including traffic flow, speed, and demand, without any additional training.\n\u2022 Unified Model Supervised Evaluation: Evaluating the versatility and adaptability of our unified OpenCity within a supervised learning framework, focusing on its ability to handle diverse spatio-temporal traffic scenarios.\n\u2022 Cross-Data Fast Adaptation Evaluation: Measuring the model's cost-efficient adaptation capabilities to new traffic datasets while requiring only a small amount of additional training data, in contrast to the need for extensive retraining from scratch."}, {"title": "4.2 Zero-shot vs. Full-shot Performance (RQ1)", "content": "In this section, we focus on evaluating the zero-shot generalization capability of the OpenCity. After its pre-training phase, the OpenCity is directly applied to zero-shot prediction tasks on various downstream datasets, including Cross-Region, Cross-City, and Cross-Category settings. In contrast, the baseline models are developed under a supervised learning framework, where they undergo training on these downstream datasets before being tested. The experimental setups are labeled as Zero-shot for the OpenCityand Full-shot for the baselines, with the results displayed in Table 2. The best performance is highlighted in bold, while the second-best performance is indicated with an underline.\n(i) Outstanding Zero-shot Prediction Performance. OpenCity achieves significant zero-shot learning breakthroughs, outperforming most baselines even without fine-tuning. This highlights the approach's robustness and effectiveness at learning complex spatiotemporal patterns in large-scale traffic data, extracting universal insights applicable across downstream tasks.\nOpenCity consistently secures top or second positions on several datasets, and maintains a competitive performance gap within 8% MAE even when not leading. This outstanding zero-shot prediction performance underscores the OpenCity's versatility and adaptability in handling diverse traffic datasets without extensive retraining. A crucial advantage is its readiness for immediate deployment in new scenarios, significantly reducing the time and resources typically required by traditional supervised approaches, offering substantial benefits for practical applications.\n(ii) Exceptional Cross-Task Generalization. Our model was evaluated across four distinct traffic data categories: traffic flow (CAD3, CAD5), traffic speed (PEMS07M, TrafficSH), taxi demand (CHI-TAXI), and bicycle trajectories (NYC-BIKE). The baseline analysis revealed that while various models performed exceptionally well on specific data types, none could consistently deliver top-tier results across all categories. For instance, GWN, STGCN, and AST-GCN each exhibited remarkable capabilities in predicting traffic flow (CAD3, CAD5), taxi demand (CHI-TAXI), and traffic speed (TrafficSH) respectively. However, they struggled to maintain that level of performance in other domains. In contrast, the OpenCity consistently delivered high-quality results across all tested categories, underscoring its exceptional robustness and versatility.\nTo assess the versatility of our OpenCity framework, we evaluated its cross-category zero-shot generalization during testing. This involved incorporating bicycle trajectory data (NYC-BIKE), despite its absence in pretraining. The results were highly promising, as OpenCity maintained excellent performance on both MAE and RMSE metrics, further validating its universality and ability to adapt across diverse data types in real-life urban scenarios.\n(iii) Strong Long-term Forecasting Capabilities. A key strength of our OpenCity architecture is its exceptional temporal generalization ability, which enables it to outperform baseline methods in long-term traffic prediction tasks. Many existing models often struggle to maintain accurate forecasts over extended time horizons, as they tend to overfit to historical patterns and fail to adequately capture the dynamic and evolving nature of traffic conditions. In contrast, OpenCity has demonstrated a remarkable capacity to learn universal spatio-temporal representations from diverse traffic data sources. This allows the model to generate robust predictions that remain reliable even as traffic patterns shift and evolve over time.\n4.3 Exceptional Supervised Performance (RQ2)\nTo further validate the advantage of our OpenCity over current baseline methods, we conducted a supervised learning evaluation. In this setting, the OpenCity is directly compared to the baseline approaches, which are built in an end-to-end training manner. This supervised evaluation allows us to assess the OpenCity's performance when trained on the target datasets, in contrast to the zero-shot generalization setting previously explored.\nAs illustrated in Table 2, the results indicate that our OpenCity maintains excellent performance in the supervised setting and holds a leading advantage in most evaluation metrics. Additionally, we observed that most baseline models underperformed on the CAD-X dataset, possibly due to their tendency to overfit historical spatiotemporal patterns, making it challenging for them to generalize to"}, {"title": "4.4 Model Fast Adaptation Capabilities (RQ3)", "content": "This section evaluates the swift adaptation abilities of our OpenCity for downstream tasks. We focus on a previously unseen traffic dataset and employ an \"Efficient Fine-tuning\" approach, where only the model's prediction head (the last linear layer) is updated with a maximum of three training epochs. As detailed in Table 3, the zero-shot performance of OpenCity on some indicators is not as robust as the full-shot performance of the baseline models, likely due to variations in traffic patterns and data sampling. However, after efficient fine-tuning, OpenCity's performance substantially improves, outperforming all compared models. Remarkably, the training time for OpenCity comprises only 2%-32% of that required by the baselines. This rapid adaptability underscores OpenCity's potential as a foundational traffic forecasting model, capable of quickly adapting to new spatio-temporal data categories.\n4.5 Ablation Study (RQ4)\nTo assess the individual contributions of the various components within our proposed OpenCity model, we conducted an ablation study using the CAD3 and NYC-BIKE datasets in zero-shot scenarios. The evaluation results are presented in Figure 3."}, {"title": "4.6 Scaling Law Investigation (RQ5)", "content": "We explored the scalability of OpenCity along both data and parameter dimensions, as illustrated in Figure 4. Parameter Scalability: We investigated 3 versions - OpenCitymini (2M), OpenCitybase (5M), and OpenCityplus (26M) parameters. Data Scalability: For modelplus, we utilized 10%, 50%, and 100% of the pre-training data to explore the benefits of incorporating more data. To standardize comparisons, the vertical axis represents relative prediction error values. The results show that OpenCity's zero-shot generalization performance progressively improves as both parameter and data scale increase. This suggests OpenCity's ability to extract valuable knowledge from extensive datasets, with its learning capabilities enhanced by parameter expansion. The demonstrated scalability potential supports OpenCity's prospect as a foundational model for general transportation applications.\n4.7 Comparison with Large Spatio-Temporal\nPre-trained Models (RQ6)\nIn this section, we compare our proposed OpenCity with other prominent large spatio-temporal pre-trained models, including UniST [44] and UrbanGPT [20], known for their strong zero-shot generalization. We utilized the CHI-TAXI dataset, which was not included in the pre-training phase for any of the three models, for our evaluation. Detailed settings are provided in the Appendix. The results in Table 4 show that OpenCity maintains a significant performance advantage over other advanced large-scale spatio-temporal models. Additionally, OpenCity and UniST exhibit notable efficiency improvements compared to UrbanGPT. This may be due to UrbanGPT's reliance on the LLM for making predictions through a question-and-answer format, which hinders its ability to process batch data efficiently. The proposed OpenCity model achieves a win-win in performance and efficiency, highlighting its potential as a powerful large-scale model for traffic benchmarks."}, {"title": "5 RELATED WORK", "content": "Deep Urban Traffic Prediction Models. The rise of deep learning has propelled deep spatio-temporal (ST) models to the forefront of the urban computing, known for their exceptional performance. These models analyze temporal and spatial correlations within historical data to forecast future trends. Prevalent temporal frameworks include recurrent neural networks (RNN)[43], temporal convolutional networks (TCN) [38], and attention networks [49]. Spatial correlations are typically encoded using graph convolution (GCN) [42], graph attention (GAT)[49], and hypergraph neural networks (HGNN) [39]. Ongoing research refines these temporal and spatial encoding strategies, including multi-scale [36] and multigranularity learning [7], as well as adaptive [1, 37] and dynamic graph modeling [9, 48]. Researchers also explore cutting-edge techniques, such as neural ordinary differential equation for continuous time modeling [6, 14] for advancing the spatio-temporal learning.\nSpatio-Temporal Self-Supervised Learning. Self-supervised learning (SSL) has emerged as an effective augmentation strategy for spatio-temporal learning. Existing SSL paradigms can be broadly categorized into: (1) Spatio-Temporal Contrastive SSL, which leverages contrastive learning to capture spatial and temporal correlations [18, 46]; (2) Spatio-Temporal Generative SSL, utilizing generative pretext tasks to model the underlying spatio-temporal dynamics via masked autoencoding [21, 30]; and (3) Spatio-Temporal Predictive SSL, incorporating auxiliary tasks that predict future spatio-temporal patterns with heterogeneity-aware data augmentation [11]. While these approaches aim to enhance the performance and generalization of spatio-temporal learning models, they are still limited by the constraints of zero-shot forecasting capabilities.\nLeveraging Large Language Models in Urban Computing. The emergence of large language models (LLMs) has prompted research integrating their benefits into urban computing through three main paradigms: (1) Works like STLLM [23] and TPLLM [29] employ LLM architectures as ST encoders, fine-tuning for ST representation learning. (2) These efforts leverage LLMs' linguistic capabilities to enhance predictions, using in-context learning for model generalization enhancement [20] and interpretable generation [8]. (3) LLMs as ST Agents: This approach bridges LLMs with tools to facilitate traffic-related queries and reasoning based on human instructions [4]. While LLMs can improve spatio-temporal model performance, two key limitations exist: First, Computational Demands: LLMs' high computational requirements reduce efficiency, posing challenges for real-world deployment. Second, Reliance on POI Data: Most approaches heavily rely on the manually-collected, rich textual Point-of-Interest (POI) information, limiting generalization. To address these limitations, there is a need to develop more efficient and highly-generalized models that can learn universal spatio-temporal patterns across diverse transportation scenarios."}, {"title": "6 CONCLUSION", "content": "The work introduces OpenCity, a scalable spatio-temporal foundation model for traffic prediction that achieves precise zero-shot prediction performance across multiple traffic forecasting scenarios. By employing the Transformer encoder architecture as the backbone to model dynamic spatio-temporal dependencies and pre-training on the large-scale traffic datasets, OpenCity demonstrates exceptional zero-shot predictive performance on various downstream tasks, matching the results of state-of-the-art baseline models in full-shot scenarios. The proposed OpenCity framework can effectively handle data with varying distributions and boasts high computational efficiency. Along with the promising scaling laws observed, this paves the way for the development of a powerful, generalized traffic prediction solution that can be readily applied to diverse urban environments and transportation networks."}, {"title": "A APPENDIX", "content": "In the appendix, we have provided comprehensive details on the OpenCity model, including the training and optimization procedures, dataset information, experimental settings, hyperparameter configurations, baseline explanations, evaluation metrics, and descriptions of the deployment experiments. This supplementary material aims to offer readers a thorough understanding of the technical aspects and experimental setup behind our work.\nA.1 Model Training and Optimization\nTo learn robust spatio-temporal representations, our model leverages multiple large-scale traffic datasets for pre-training. This approach allows the model to capture the inherent complexities and dependencies within transportation networks by leveraging diverse data sources. During the training process, we randomly complete one step of training using data from a specific dataset, with one training epoch covering all available training data. Our model adopts a supervised training paradigm to complete this pre-training stage.\nAfter obtaining the output from the L-th layer of the spatiotemporal encoding network, we flatten the features and use a linear layer to obtain the prediction \\(Y \\in \\mathbb{R}^{R \\times T}\\). Following previous research [1, 22], we use the absolute error as the loss function L:\n\\[L = \\frac{1}{RT} \\sum_{r=1}^{R} \\sum_{t=1}^{T} |\\hat{Y_{r,t}} - Y_{r,t}| \\quad (11)\\]\nOur model is designed to capture the intricate spatial and temporal dependencies inherent in transportation networks by leveraging multi-dataset pre-training. This approach enables the model to learn robust spatio-temporal representations that can generalize well to a wide range of scenarios, including spatial generalization with zero-shot prediction and temporal generalization with long-term forecasting. By pre-training on diverse datasets, the model can extract meaningful features and patterns that are transferable across different spatial and temporal domains, enhancing its versatility and performance in real-world traffic forecasting tasks.\nA.2 Comprehensive Experimental Settings\nA.2.1 Data Sources and Characteristics. To comprehensively evaluate the generalization capabilities and predictive performance of the OpenCity approach, we conducted training and testing across a diverse set of large-scale public real-world datasets. These datasets cover multiple traffic-related data categories from various regions, including the United States and China, spanning several major cities such as New York City, Chicago, Shanghai, and others. (i) Traffic flow Data [25, 32]: CAD-X and PEMS-X from California; (ii) Taxi Demand Data [20]: X-TAXI from New York City and Chicago; (iii) Bicycle Trajectory Data [20]: X-BIKE from New York City; (iv) Traffic Speed Statistics [44]: Traffic-X from major cities in China; (v) Traffic Speed Statistics [19, 42]: METR-LA, PEMS-BAY, and PEMS07M from Los Angeles, the Bay Area, and California; (vi) Traffic Index Statistics [26]: X-DIDI from Shenzhen and Chengdu. The taxi demand datasets, bicycle trajectory datasets, and traffic speed statistics datasets (Traffic-X) used in this study are grid-based in nature, while the remaining datasets are sensor-based. To distinguish between the specific districts or cities represented within each dataset, the \"X\" placeholder is utilized.\nThe detailed statistics for all datasets used in this paper is shown in Table 5. Considering that a large number of regions might lead to excessive GPUs memory overhead, we segmented datasets CAD4, CAD7, CAD8, and CAD12 according to the order of nodes. Specifically, the number of regions in CAD4-1, CAD4-2, CAD4-3, and CAD4-4 are 621, 610, 593, and 528; in CAD7-1, CAD7-2, and CAD7-3 are 666, 634, and 559; in CAD8-1 and CAD8-2 are 510 and 512; and in CAD12-1 and CAD12-2 are 453 and 500. Additionally, the last column of Table 5 indicates whether each dataset was utilized for pre-training in OpenCity. To evaluate the model's performance in a supervised setting, we reserved a portion of the data from the datasets involved in the supervised experiments for evaluation.\nA.2.2 Hyperparameter Configuration. We release three different versions of the OpenCity model, each with varying parameter counts: OpenCitymini (2M parameters), OpenCitybase (5M parameters), and OpenCityplus (26M parameters). We scale the OpenCity architecture by increasing the dimensions of the hidden layers and the number of layers in the spatio-temporal encoder, as detailed in Table 1. For our long-term traffic forecasting focus, we set the historical and future time spans (H and F) to 1 day. This configuration is determined by the aggregation frequency - when the frequency is 5 minutes, H = F = 288. Furthermore, we set the patch length P and stride S to one-hour time spans, which correspond to a value of 12 when the aggregation frequency is 5 minutes.\nThe regional embedding dimensionality k is set to 8 and the balancing weight \\(a\\) is set to 0.05. The dropout ratios for the attention matrix \\(d_a\\) and the spatio-temporal network \\(\\delta\\) are set to 0.3 and 0.1, respectively. We maximize the batch size settings based on the GPU memory usage across the different models. Additionally, the hyperparameters for all baseline configurations adhere to the settings provided in the original papers or the official released codes. All training and testing are conducted on a server equipped with 8 \u00d7 NVIDIA A100-SXM4-40GB GPUs.\nA.2.3 Detailed Experimental Setup. The detailed settings of different experiments and the division of datasets are as follow:\nZero-shot Evaluation Setup: In the zero-shot evaluation, the proposed OpenCity model is directly used for testing, while the baselines are trained and tested in a supervised setting. For the traffic flow datasets (CAD3, CAD5) and the traffic speed datasets (PEMS07M, TrafficSH), the split ratios for training, validation, and testing sets are 0.5, 0.1, and 0.4, respectively. For the taxi demand dataset (CHI-TAXI) and the bicycle trajectory dataset (NYC-BIKE), these ratios are 0.2, 0.2, and 0.6. All the above datasets are unavailable during the pre-training phase of OpenCity.\nSupervised Evaluation Settings: In the supervised scenario, the pre-trained OpenCity model is directly employed for evaluation. Contrary to the zero-shot setting, all these datasets are included in the pre-training phase. For the CAD8-1, CAD8-2, and CAD12-2 datasets, the proportions for training, validation, and testing are set at 0.8, 0.1, and 0.1, respectively. For the PEMS-BAY dataset, these ratios are 0.5, 0.1, and 0.4. In the case of the NYC-TAXI dataset, all data from 2016 to 2020 are used as the training set, data from the first two months of 2021 serves as the validation set, and data from the remaining ten months of 2021 is used as the test set."}, {"title": "A.2.4 Evaluation Metrics for Traffic Prediction", "content": "The experiments utilize three widely used evaluation metrics in traffic forecasting and regression tasks: Mean Absolute Error (MAE), Root Mean Square Error (RMSE), and Mean Absolute Percentage Error (MAPE). MAE measures the average absolute difference between the predicted values and true labels, RMSE captures the standard deviation of the prediction errors, and MAPE represents the average absolute percentage difference between the predicted values and true labels. Lower values for these metrics indicate better performance of the model, as they quantify the errors between the predicted values and true labels from different perspectives.\nA.2.5 Baseline Description. We selected 10 advanced spatiotemporal prediction models as baselines, all of which have demonstrated considerable success in traffic prediction tasks. Given that most of these models are primarily designed for short-term predictions, we have enhanced their long-term prediction capabilities by applying patch embedding, as introduced in Section 3.1.2. The selected baseline models fall into the following three categories: RNN-Based Spatio-temporal Prediction Models:\n\u2022 AGCRN [1]: This model incorporates learnable node embeddings into recurrent neural networks (RNNs), enabling it to capture the region-specific spatio-temporal evolution patterns."}, {"title": "A.3 Model Deployment", "content": "In this section, we examine the deployment-related challenges associated with OpenCity. Given that the datasets for all our experiments are derived from real-world scenarios and align with actual prediction environments, the performance of our model in deployment settings has been validated in the aforementioned experiments. Our focus here extends to assessing the efficiency of OpenCity in practical applications. In contrast to offline prediction, online evaluation typically involves processing a single batch of predictions within a specific timeframe, dictated by the regular intervals at which traffic data is updated and aggregated (e.g., every 5 minutes, every 2 hours, 1 day). We deployed OpenCity on a single NVIDIA A100-SXM4-40GB GPU and evaluated its prediction speed across cities of varying sizes. The task involved predicting the next day's traffic trends based on the data from the previous day.\nAccording to the results presented in Table 6, OpenCity is capable of delivering predictions in an exceptionally short period. Even in cities with numerous regions and fine-grained prediction requirements, OpenCity completes individual predictions in less than 3 seconds. This remarkable efficiency not only demonstrates the model's robustness but also reinforces OpenCity's potential to serve as a foundational model for traffic prediction."}]}