{"title": "OpenCity: Open Spatio-Temporal Foundation Models for Traffic Prediction", "authors": ["Zhonghang Li", "Long Xia", "Lei Shi", "Yong Xu", "Dawei Yin", "Chao Huang"], "abstract": "Accurate traffic forecasting is crucial for effective urban planning and transportation management, enabling efficient resource allocation and enhanced travel experiences. However, existing models often face limitations in generalization, struggling with zero-shot prediction on unseen regions and cities, as well as diminished long-term accuracy. This is primarily due to the inherent challenges in handling the spatial and temporal heterogeneity of traffic data, coupled with the significant distribution shift across time and space. In this work, we aim to unlock new possibilities for building versatile, resilient and adaptive spatio-temporal foundation models for traffic prediction. To achieve this goal, we introduce a novel foundation model, named OpenCity, that can effectively capture and normalize the underlying spatio-temporal patterns from diverse data characteristics, facilitating zero-shot generalization across diverse urban environments. OpenCity integrates the Transformer architecture with graph neural networks to model the complex spatio-temporal dependencies in traffic data. By pre-training OpenCity on large-scale, heterogeneous traffic datasets, we enable the model to learn rich, generalizable representations that can be seamlessly applied to a wide range of traffic forecasting scenarios. Experimental results demonstrate that OpenCity exhibits exceptional zero-shot predictive performance. Moreover, OpenCity showcases promising scaling laws, suggesting the potential for developing a truly one-for-all traffic prediction solution that can adapt to new urban contexts with minimal overhead. We made our proposed OpenCity model open-source and it is available at the following link: https://github.com/HKUDS/OpenCity.", "sections": [{"title": "1 INTRODUCTION", "content": "Transportation is an essential component of urban activities, serving as the fundamental infrastructure that supports the efficient movement of people and goods within cities [33, 41]. Precise traffic forecasting allows for proactive traffic management, enabling transportation planners to anticipate and mitigate potential congestion, delays, and disruptions [13, 17]. This, in turn, enhances the overall efficiency and sustainability of urban transportation networks, fostering the real-world intelligent transportation systems.\nThe success of deep learning has empowered spatio-temporal models for traffic forecasting. These models leverage deep neural networks to learn effective representations that can better capture the spatial and temporal dependencies inherent in urban traffic data. However, despite these advancements, current traffic prediction models often face significant limitations in terms of generalization.\nCross-Regional Model Spatial Generalization. Firstly, A key limitation of current traffic prediction models is their struggle with spatial generalization. These models often fail to perform well when applied to unseen regions or cities, as traffic patterns and dynamics can vary considerably across geographical locations due to factors like infrastructure, demographics, and urban planning [1]. Existing models typically learn from data limited to specific regions, making them unable to effectively generalize their knowledge to capture the unique characteristics of unfamiliar traffic environments.\nThis issue is critical, as it is impractical to deploy comprehensive sensor networks across entire urban areas to collect traffic data [15, 26]. A more viable approach is to build models that can generalize well to unseen regions using only partial data. Additionally, developing spatio-temporal models that are applicable across different cities would significantly reduce deployment and maintenance costs [15, 40]. However, when these models are applied in new locations, they often experience a significant drop in predictive performance, hindering their wider applicability. This spatial generalization challenge is crucial to address in order to create traffic forecasting solutions that can be seamlessly deployed across diverse urban settings without extensive retraining or fine-tuning.\nTemporal Generalization for Long-term Forecasting. Current traffic prediction models excel at short-term forecasting, such as anticipating conditions for the next hour [3, 12]. However, their ability to generalize to longer time frames, like days or weeks ahead, is notably limited. This limitation is largely due to the models' poor generalization ability in effectively handling the evolving temporal distribution shifts that occur over longer time horizons in practical urban scenarios. As the forecasting timeframe increases, these models struggle to capture and account for the dynamic changes in traffic patterns that influence long-term traffic conditions.\nThis limitation presents a considerable obstacle for city planners and transportation agencies striving to devise effective long-term strategies. Precise long-term traffic forecasts are crucial for a range of applications, including proactive infrastructure planning, public transit scheduling, and event logistics coordination. Despite their importance, existing models often fall short when it comes to providing reliable predictions beyond the immediate future.\nIn recent years, the remarkable capabilities of large foundation models have captured significant attention across various domains. These models, trained on vast and diverse datasets, have demonstrated exceptional performance in natural language processing (NLP) [2, 28] and computer vision (CV) [10, 16] tasks, showcasing their remarkable abilities to comprehend and generalize from complex data. While the success of foundation models has been"}, {"title": "2 PRELIMINARIES", "content": "Spatio and Temporal Unit Generation. Traffic data is inherently spatio-temporal in nature, reflecting the dynamic patterns and spatial distribution of transportation networks. It is typically represented as a two-dimensional matrix $X \\in \\mathbb{R}^{R \\times T}$, where each element corresponds to a specific traffic metric (e.g., flow, speed, or demand), for a given region r and time interval t. There are two prevalent forms of spatial region unit used to model traffic data:\n\u2022 i) Sensor-based Traffic Network: The traffic data is collected through an irregular sensor network across major roads. Each sensor represents a region, and the region relationships are modeled using a graph $G = (V, E, A)$, where V are regions, E are edges, and $A \\in \\mathbb{R}^{R \\times R}$ is a weighted adjacency matrix capturing spatial dependencies, based on geographical distance.\n\u2022 ii) Grid-based Traffic Network: the urban area is partitioned into a regular grid of uniform square blocks, often with dimensions of 1km \u00d7 1km. This grid-like spatial representation allows the transportation network to be modeled using a graph structure, where each grid block is represented as a node, and the connections between neighboring regions are captured as edges.\nTraffic Flow Forecasting. The task of traffic forecasting is to use data from the past H time steps $(X_{t_1-H+1:t_1})$ to predict traffic data $Y_{t_1+1:t_1+F}$ for the future F time steps. This involves exploring the complex spatial and temporal patterns inherent in traffic data to"}, {"title": "3 METHODOLOGY", "content": "3.1 Spatio-Temporal Embedding for\nDistribution Shift Generalization\nThe design of our spatio-temporal embedding layer is driven by the need to address the distribution shift across both spatial and temporal dimensions in traffic prediction tasks. In real-world intelligent transportation systems, traffic flow patterns can vary considerably across different geographical regions and time periods. This inherent data heterogeneity presents a major obstacle for traffic prediction models, as they need to generalize their performance to new environments or scenarios where the underlying data distribution may be drastically different from the training data.\n3.1.1 In-Context Normalization for Zero-Shot Generalization. Existing approaches often leverage statistical features of the training data, such as mean and standard deviation, for data normalization. However, these summary statistics may be inadequate or non-transferable when the test data exhibits significant data heterogeneity and has no spatial overlap with the training data distribution. To address this challenge and accommodate zero-shot traffic prediction tasks, we employ instance normalization $IN()$ to process the data. This approach utilizes the mean and standard deviation of the individual input instances $X_r \\in \\mathbb{R}^T$ for each region, rather than relying on the global training set statistics. The formalization of this process is as follows:\n$X_{r,t} = IN(X_{r,t}) = \\frac{X_{r,t} - \\mu_r}{\\sigma_r}$ (3)\nWhere $\\mu(X_r)$ and $\\sigma(X_r)$ are the mean and standard deviation of the input instance $X_r$, respectively. Subsequent denormalization is applied to the prediction outputs to achieve more accurate results. Studies [10, 34] indicate that instance normalization effectively mitigates distribution shifts between training and test sets, advantageous for our zero-shot traffic prediction scenarios.\n3.1.2 Patch Embedding for Efficient Long-Term Prediction.\nThe proposed OpenCity model is designed to address long-term traffic prediction, which often involve processing an increased number of input time steps. This can lead to significant computational and memory overhead. To mitigate these issues, we employ a patch-based approach [5, 27] to partition the data along the temporal dimension. We define P as the patch length, specifying the number of time steps grouped into a single patch, and S as the stride size, determining the overlap between successive patches. After the patch operation, the input data $X_r \\in \\mathbb{R}^T$ is reshaped to $X_P \\in \\mathbb{R}^{P \\times N}$, where N is the number of blocks, calculated as $N = \\frac{T-P}{S} + 1$. Our patch embedding scheme offers several key advantages:\n\u2022 Handling Temporal Distribution Shift. By considering one hour of traffic data as the length of a single patch and adjusting the stride accordingly (S = P), our model can effectively handle the temporal distribution shifts often encountered in long-term traffic prediction. This allows the model to capture and adapt to the evolving patterns in traffic data over extended time horizons.\n\u2022 Computational Efficiency. The patch-based processing significantly reduces the computational and memory requirements, as the model operates on a smaller number of input patches rather than the entire temporal sequence. This enables more efficient and scalable long-term traffic prediction, making the model suitable for real-world deployments.\nAfter the patch-based partitioning of the input data, we employ a linear transformation and positional encoding to obtain the final spatio-temporal data embedding $E_r \\in \\mathbb{R}^{P \\times d}$. This embedding serves as the input to the subsequent model components:\n$E_r = W_e \\cdot X_P + PE(X)$ (4)\nHere, $W_e \\in \\mathbb{R}^{N \\times d}$ is the weight parameter, and PE denotes the Sinusoidal Position Encoding [35], which helps the model capture temporal relationships within each patch. Our temporal patch embedding schema compresses the input time steps, enabling the model to efficiently perform long-term traffic prediction and overcome challenges posed by increased input time steps, which is crucial for accurate long-term forecasting."}, {"title": "3.2 Spatio-Temporal Context Encoding", "content": "To capture the complex spatio-temporal patterns inherent in traffic data, our model integrates both temporal and spatial context cues. By explicitly modeling the interplay between these two critical dimensions, OpenCity is able to better understand the multifaceted factors influencing transportation patterns. This integrated approach enables our framework to generate more accurate forecasts across a diverse range of time horizons and geographic areas.\n3.2.1 Temporal Context Encoding. Our model effectively captures the distinct temporal patterns in traffic data, such as periodic variations caused by daily or weekly routines, as well as complex non-linear dependencies over longer timescales. Specifically, we leverage patch-based segmentation to extract features related to the time of day, $z^{(d)} \\in \\mathbb{R}^T$, and the day of the week, $z^{(w)} \\in \\mathbb{R}^T$, and employ linear layers to generate time-specific embeddings that encode these temporal context cues. By explicitly modeling the periodic nature of traffic flow, our approach is well-equipped to make accurate predictions, even for long-term forecasting horizons where these temporal patterns become increasingly relevant.\n$D = concat[W_1z^{p(d)}, W_2z^{p(w)}]$ (5)\nThe temporal context is extracted as $z^{p(d)}, z^{p(w)} \\in \\mathbb{R}^{P \\times N}$ after patch-based segmentation. We use linear layers parameterized by $W_1, W_2 \\in \\mathbb{R}^{N \\times d/2}$ to generate time-of-day and day-of-week embeddings, which are then concatenated into the final temporal encoding $D \\in \\mathbb{R}^{P \\times d}$ and integrated into our model.\n3.2.2 Spatial Context Encoding. Traffic patterns vary across regions due to their unique geographical characteristics, such as the higher volumes experienced at transportation hubs. To capture these regional attributes, we incorporate the underlying spatial context within the traffic network. First, we calculate the normalized Laplacian matrix $\u2206 = I \u2212 D^{-1/2}AD^{-1/2}$, where I and D are the identity and degree matrices, respectively. We then perform an eigenvalue decomposition, obtaining $A = UAU^T$, with U and A as the eigenvalue and eigenvector matrices. The k smallest non-trivial eigenvectors are used as the region embeddings $\u03a6 \\in \\mathbb{R}^{R \\times k}$, encoding the structural information of the traffic network. These embeddings are then processed through a linear layer to obtain the final spatial encodings $C \\in \\mathbb{R}^{R \\times d}$."}, {"title": "3.3 Spatio-Temporal Dependencies Modeling", "content": "3.3.1 Temporal Dependencies Modeling. To highlight the strong generalization capabilities of our foundation model for long-term forecasting, it can effectively handle both periodic and dynamic traffic patterns. Specifically, we build our pre-trained spatio-temporal model upon our developed TimeShift Transformer architecture to encode time-dependent relationships. This allows our model to capture the traffic patterns from two complementary perspectives:\n\u2022 Periodic Traffic Transitions. Our model captures the periodic, recurring traffic patterns, such as hourly, daily, and weekly cycles. By encoding these cyclical variations, our approach can better account for the inherent regularities in transportation network.\n\u2022 Dynamic Traffic Patterns. Beyond just periodic variations, our temporal encoder also captures the complex, non-linear temporal dynamics and evolving trends in the traffic data over time.\nOur model's ability to encode both the periodic and dynamic aspects of temporal information enables strong generalization capabilities, making it well-suited for real-world traffic forecasting across diverse time horizons. This versatile understanding of the multifaceted factors influencing transportation patterns allows accurate predictions of not only regular, recurring traffic behaviors, but also unpredictable, evolving changes in conditions.\nModeling Periodic Traffic Transitions. To learn the periodic patterns in the traffic, we leverage both temporal embeddings D and spatial embeddings C. Our objective is to uncover the correlations between historical traffic patterns and future instances. Specifically, we update the temporal embeddings into two components:\n\u2022 $D_{his} \\in \\mathbb{R}^{R \\times P \\times d}$: This captures the historical temporal signals.\n\u2022 $D_{pre} \\in \\mathbb{R}^{R \\times P \\times d}$: This represents the anticipated temporal information for future predictions.\nOur model explicitly models both historical and future-oriented temporal patterns, allowing it to better learn and leverage the periodic nature of the traffic time series.\nTo ensure dimension alignment, we extend the temporal embeddings along the spatial domain, and the spatial embeddings across the temporal axis. We then construct the inputs to a multi-head attention mechanism: the future spatio-temporal embeddings as the query, the historical spatio-temporal embeddings as the key, and the historical spatio-temporal data representations as the value.\n$Q^h = W_Q^h (D_{pre} + C_r); K^h = W_K^h (D_{his} + C_r); V^h = W_V^h E$ (6)"}, {"title": "4 EVALUATION", "content": "In our experimental evaluation, we address the following six key research questions to validate the capabilities of our model:\n\u2022 RQ1: Can the proposed OpenCity model effectively generalize to zero-shot and long-term traffic forecasting scenarios?\n\u2022 RQ2: How effectively does the proposed OpenCity framework integrate cross-data traffic patterns into a single and coherent model in supervised learning environments?\n\u2022 RQ3: Does the model have the capability to rapidly generalize to new transportation forecasting demands as they emerge?\n\u2022 RQ4: What are the individual contributions of the different modules to the performance gains of the OpenCity approach?\n\u2022 RQ5: How the model's parameter count and training data volume scale to affect its overall forecasting performance?\n\u2022 RQ6: Compared to existing large-scale spatio-temporal prediction models, what key advantages does our approach offer in terms of prediction performance and efficiency?"}, {"title": "4.1 Experimental Setup", "content": "4.1.1 Data Sources and Characteristics. The model's generalization capabilities and predictive performance were extensively evaluated using a diverse set of large-scale, real-world public datasets covering various traffic-related data categories, including Traffic Flow, Taxi Demand, Bicycle Trajectories, Traffic Speed Statistics, and Traffic Index Statistics, from regions across the United States and China, such as New York City, Chicago, Los Angeles, the Bay Area, Shanghai, Shenzhen, and Chengdu. In addition, we released 3 versions OpenCity based on parameter size: OpenCitymini (2M), OpenCitybase (5M), and OpenCityplus (26M). Further details on all experimental datasets are provided in the Appendix.\nIn the pre-training stage of the OpenCity approach, we leveraged a wealth of transportation data, encompassing the traffic flow, traffic speed, and taxi demand datasets. This expansive dataset covers a total of 10,110 regions and 352,796 time points, amounting to an astounding 151,089,924 observations. For the testing phase, we selected data that was outside the training set, allowing us to assess the model's generalization performance across a diverse range of traffic prediction scenarios. These scenarios include:\n\u2022 Cross-Region Zero-Shot Evaluation: Assessing the OpenCity's ability and robustness to generalize to unseen regions within a city, without the need for additional training.\n\u2022 Cross-City Zero-Shot Evaluation: Examining the model's capacity to adapt to completely new cities, leveraging the knowledge acquired during the original training process.\n\u2022 Cross-Task Zero-Shot Evaluation: Testing the model's ability to forecast different types of traffic-related data, including traffic flow, speed, and demand, without any additional training.\n\u2022 Unified Model Supervised Evaluation: Evaluating the versatility and adaptability of our unified OpenCity within a supervised learning framework, focusing on its ability to handle diverse spatio-temporal traffic scenarios.\n\u2022 Cross-Data Fast Adaptation Evaluation: Measuring the model's cost-efficient adaptation capabilities to new traffic datasets while requiring only a small amount of additional training data, in contrast to the need for extensive retraining from scratch."}, {"title": "5 RELATED WORK", "content": "Deep Urban Traffic Prediction Models. The rise of deep learning has propelled deep spatio-temporal (ST) models to the forefront of the urban computing, known for their exceptional performance. These models analyze temporal and spatial correlations within historical data to forecast future trends. Prevalent temporal frameworks include recurrent neural networks (RNN)[43], temporal convolutional networks (TCN) [38], and attention networks [49]. Spatial correlations are typically encoded using graph convolution (GCN) [42], graph attention (GAT)[49], and hypergraph neural networks (HGNN) [39]. Ongoing research refines these temporal and spatial encoding strategies, including multi-scale [36] and multi-granularity learning [7], as well as adaptive [1, 37] and dynamic graph modeling [9, 48]. Researchers also explore cutting-edge techniques, such as neural ordinary differential equation for continuous time modeling [6, 14] for advancing the spatio-temporal learning.\nSpatio-Temporal Self-Supervised Learning. Self-supervised learning (SSL) has emerged as an effective augmentation strategy for spatio-temporal learning. Existing SSL paradigms can be broadly categorized into: (1) Spatio-Temporal Contrastive SSL, which leverages contrastive learning to capture spatial and temporal correlations [18, 46]; (2) Spatio-Temporal Generative SSL, utilizing generative pretext tasks to model the underlying spatio-temporal dynamics via masked autoencoding [21, 30]; and (3) Spatio-Temporal Predictive SSL, incorporating auxiliary tasks that predict future spatio-temporal patterns with heterogeneity-aware data augmentation [11]. While these approaches aim to enhance the performance and generalization of spatio-temporal learning models, they are still limited by the constraints of zero-shot forecasting capabilities.\nLeveraging Large Language Models in Urban Computing. The emergence of large language models (LLMs) has prompted research integrating their benefits into urban computing through three main paradigms: (1) Works like STLLM [23] and TPLLM [29] employ LLM architectures as ST encoders, fine-tuning for ST representation learning. (2) These efforts leverage LLMs' linguistic capabilities to enhance predictions, using in-context learning for model generalization enhancement [20] and interpretable generation [8]. (3) LLMs as ST Agents: This approach bridges LLMs with tools to facilitate traffic-related queries and reasoning based on human instructions [4]. While LLMs can improve spatio-temporal model performance, two key limitations exist: First, Computational Demands: LLMs' high computational requirements reduce efficiency, posing challenges for real-world deployment. Second, Reliance on POI Data: Most approaches heavily rely on the manually-collected, rich textual Point-of-Interest (POI) information, limiting generalization. To address these limitations, there is a need to develop more efficient and highly-generalized models that can learn universal spatio-temporal patterns across diverse transportation scenarios."}, {"title": "6 CONCLUSION", "content": "The work introduces OpenCity, a scalable spatio-temporal foundation model for traffic prediction that achieves precise zero-shot prediction performance across multiple traffic forecasting scenarios. By employing the Transformer encoder architecture as the backbone to model dynamic spatio-temporal dependencies and pre-training on the large-scale traffic datasets, OpenCity demonstrates exceptional zero-shot predictive performance on various downstream tasks, matching the results of state-of-the-art baseline models in full-shot scenarios. The proposed OpenCity framework can effectively handle data with varying distributions and boasts high computational efficiency. Along with the promising scaling laws observed, this paves the way for the development of a powerful, generalized traffic prediction solution that can be readily applied to diverse urban environments and transportation networks."}, {"title": "A APPENDIX", "content": "In the appendix, we have provided comprehensive details on the OpenCity model, including the training and optimization procedures, dataset information, experimental settings, hyperparameter configurations, baseline explanations, evaluation metrics, and descriptions of the deployment experiments. This supplementary material aims to offer readers a thorough understanding of the technical aspects and experimental setup behind our work.\nA.1 Model Training and Optimization\nTo learn robust spatio-temporal representations, our model leverages multiple large-scale traffic datasets for pre-training. This approach allows the model to capture the inherent complexities and dependencies within transportation networks by leveraging diverse data sources. During the training process, we randomly complete one step of training using data from a specific dataset, with one training epoch covering all available training data. Our model adopts a supervised training paradigm to complete this pre-training stage.\nAfter obtaining the output from the L-th layer of the spatio-temporal encoding network, we flatten the features and use a linear layer to obtain the prediction $Y \\in \\mathbb{R}^{R \\times T}$. Following previous research [1, 22], we use the absolute error as the loss function L:\n$L = \\frac{1}{RT} \\sum_{r=1}^{RT} \\sum_{t=1}^{RT} |(\\hat{Y}_{r,t} - Y_{r,t})|$ (11)\nOur model is designed to capture the intricate spatial and temporal dependencies inherent in transportation networks by leveraging multi-dataset pre-training. This approach enables the model to learn robust spatio-temporal representations that can generalize well to a wide range of scenarios, including spatial generalization with zero-shot prediction and temporal generalization with long-term forecasting. By pre-training on diverse datasets, the model can extract meaningful features and patterns that are transferable across different spatial and temporal domains, enhancing its versatility and performance in real-world traffic forecasting tasks.\nA.2 Comprehensive Experimental Settings\nA.2.1 Data Sources and Characteristics. To comprehensively evaluate the generalization capabilities and predictive performance of the OpenCity approach, we conducted training and testing across a diverse set of large-scale public real-world datasets. These datasets cover multiple traffic-related data categories from various regions, including the United States and China, spanning several major cities such as New York City, Chicago, Shanghai, and others. (i) Traffic flow Data [25, 32]: CAD-X and PEMS-X from California; (ii) Taxi Demand Data [20]: X-TAXI from New York City and Chicago; (iii) Bicycle Trajectory Data [20]: X-BIKE from New York City; (iv) Traffic Speed Statistics [44]: Traffic-X from major cities in China; (v) Traffic Speed Statistics [19, 42]: METR-LA, PEMS-BAY, and PEMS07M from Los Angeles, the Bay Area, and California; (vi) Traffic Index Statistics [26]: X-DIDI from Shenzhen and Chengdu. The taxi demand datasets, bicycle trajectory datasets, and traffic speed statistics datasets (Traffic-X) used in this study are grid-based in nature, while the remaining datasets are sensor-based. To distinguish between the specific districts or cities represented within each dataset, the \"X\" placeholder is utilized."}]}