{"title": "Implementation of an Asymmetric Adjusted Activation Function for Class Imbalance Credit Scoring", "authors": ["Xia Li", "Hanghang Zheng", "Kunpeng Tao", "Mao Mao"], "abstract": "Credit scoring is a systematic approach to evaluate a borrower's probability of default (PD) on a bank loan. The data associated with such scenarios are characteristically imbalanced, complicating binary classification owing to the often-underestimated cost of misclassification during the classifier's learning process. Considering the high imbalance ratio (IR) of these datasets, we introduce an innovative yet straightforward optimized activation function by incorporating an IR-dependent asymmetric adjusted factor embedded Sigmoid activation function (ASIG). The embedding of ASIG makes the sensitive margin of the Sigmoid function auto-adjustable, depending on the imbalance nature of the datasets distributed, thereby giving the activation function an asymmetric characteristic that prevents the underrepresentation of the minority class (positive samples) during the classifier's learning process. The experimental results show that the ASIG-embedded-classifier outperforms traditional classifiers on datasets across wide-ranging IRs in the downstream credit-scoring task. The algorithm also shows robustness and stability, even when the IR is ultra-high. Therefore, the algorithm provides a competitive alternative in the financial industry, especially in credit scoring, possessing the ability to effectively process highly imbalanced distribution data.", "sections": [{"title": "1. Introduction", "content": "Credit scoring is a vital component of financial risk management, helping financial institutions evaluate the creditworthiness of clients, both individuals and enterprises, and their ability to repay loans. It estimates the likelihood that a borrower will default on a loan within a certain period following the credit evaluation."}, {"title": "2. Related Works", "content": "In credit scoring, binary classification on imbalanced datasets has been a topic of significant interest because the biased nature can impair method performance. Data-level preprocessing targets rebalancing the samples by either increasing the volume of minority samples or decreasing the volume of majority samples. The simplest forms of these methods are random oversampling and random undersampling. SMOTE is a widely used and effective protocol for solving this problem. Recently, generative adversarial networks and their modified versions have drawn increasing attention in credit scoring"}, {"title": "3. Methodology", "content": "This study commences with the resampling of the original datasets sourced from Kaggle, aiming to fabricate sub-datasets spanning diverse IRs. Through initial feature engineering, a suite of sub-datasets, each exhibiting varying IRs, are prepared. A novel IR-dependent adjusted factor, denoted as G (IR, \u03b1, \u03b2), is integrated into the learning algorithm. Subsequently, a pretraining process is carried out, and a baseline dataset is carefully chosen to calibrate and find the hyper-parameters a and \u03b2 (details can be seen in Section 3.2.2, on the development of ASIG). The adjustment factor G is established as solely dependent on the IR and can be used for other datasets. Various classifiers are then trained on these sub-datasets, with their performance, robustness, and stability subjected to an exhaustive comparative analysis. The framework of this study is depicted in Fig. 1 and Fig. 2."}, {"title": "3.1 Data Preprocessing", "content": "In open-source datasets for credit scoring, IR ranges from approximately ~1 to ~200. This reflects a default rate among banking clients of about ~0.5% to ~50%. Such an elevated default rate is incongruent with the majority of real-world credit-lending scenarios. This study concentrates on default ratios that are more representative of actual industry practices, stipulating that the IR of the datasets employed for training and prediction should span from 20 to 300, correlating to default rates ranging from 5% to a mere 0.3%.\nWe select four datasets for method learning and analysis-all sourced from the Kaggle platform. These datasets include GiveMeSomeCredit (GMC), default-of-credit-card-clients (Credit Card, original from UCI dataset), Chinese Banks (CHN Banks), and lending-club (Lending Club, original from the"}, {"title": "3.2 The Formulation of ASIG", "content": ""}, {"title": "3.2.1 Cost-sensitive Learning Revisited", "content": "Cross-entropy (CE) loss is ubiquitously employed as a metric to quantify the misclassification cost between the predicted probabilities and the actual binary labels. The rudimentary binary cross-entropy loss is as follows:\n$L(y, P) =- \\frac{1}{N} \\sum_{j=1}^{N} (y_{j}\\log(p_{j}) + (1 - y_{j}) \\log (1 - p_{j})) $\nwhere N represents the number of samples; yj is the ground truth with a binary label for sample j; and yj = 1 if the clients defaults but is otherwise 0. Pj denotes the predicted probability for sample j, calculated by the Sigmoid function represented as follows:\n$P_{j} = \\text{Sigmoid} (Z) = \\frac{1}{1+\\text{exp} (-Z)} $\nThe Score Z from (2) is derived from the matrix weighted product of the feature weights for each sample. The computation of CE loss from (1) signifies that both positive and negative samples have equivalent significance in the cost metric. Given that negative samples constitute the majority of the dataset, they dominate the gradient within the learning process. This predominance is a principal cause in the suboptimal performance often observed in binary classifiers for biased distributed data. The focal loss is engineered to mitigate the challenges by intensifying the learning emphasis on difficult, misclassified instances. It applies a modulating term to the CE loss to focus learning on hard misclassified examples. Focal loss is defined as follows:"}, {"title": "3.2.2 The Development of ASIG", "content": "Prevailing assumptions posit that imbalanced classes adhere to a normal distribution, an assumption that may not encapsulate the skewed nature of credit-scoring samples distributions. When evaluating loss via the Sigmoid activation function, it presupposes that the distribution of target samples (the rare events) aligns with a binomial distribution. This is exemplified in (1), where the predicted probability of a positive sample is denoted as p\u2081, and conversely, 1 pj for the negative. Nonetheless, the distribution of infrequent samples is typically long-tailed and positively skewed, a discrepancy that becomes increasingly significant in methods designed for financial credit loan predictions. Based on the above assumption, we introduce a modified asymmetric element to the Sigmoid function to more accurately represent spaces that are non-normally distributed.\nThe proposed ASIG is a simple yet effective alternative adjustment for the activation function. Our strategy involves using a pretraining process to find a set of optimized hyper-parameters, a and \u03b2, which are then used to formulate the asymmetric adjusted factor G~ (IR, \u03b1, \u03b2) to encapsulate the effect of the dataset's imbalanced distribution inside the activation function and to calculate an alternative probability, Alter_P, which reflects the biased nature of the dataset by shifting the probability calculated by traditional activation function. The pretraining process is shown in Fig. 4."}, {"title": "4. Discussion", "content": "In this section, we first explain the working mechanism of the ASIG-embedded cost function. Compared with traditional CE loss, the ASIG-embedded loss emphasizes the misclassification cost of positive samples while deemphasizing that of negative samples. Subsequently, we show a comparison of the ASIG-embedded-classifier with other classifiers on resampled datasets across wide-ranging IRs. We explore the resilience and consistency of these classifiers by observing the impact of varying IRs. Given the typical scenarios encountered in the financial sector-where the default rate is generally below 5%-we select datasets with IRs ranging from 20 to 300, contingent upon the adequacy of positive samples (defaulters) for the GMC and CHN Banks datasets, and from 20 to 120 in scenarios"}, {"title": "4.1 The ASIG Effects", "content": "The asymmetric adjusted factor G(IR, \u03b1, \u03b2) embedded in ASIG is designed to translocate the Sigmoid curve along the x-axis and thus shift the output probability (by lowering down the decision threshold of the negative samples), as depicted in Fig. 5a. The original Sigmoid curve (represented by the blue line) shifts rightward along the x-axis, thereby engendering an asymmetric characteristic and shifting the decision boundary of the classifier. Current studies have shown interest in the introduction of an asymmetric element to the learning process. ASL reflects the asymmetric characteristics of a positive-negative sample imbalance to the loss-computation process by modifying the cost function. Several research works used the GEV regression to make up for the shortcomings of logistic regression in imbalance classification. In comparison, ASIG directly introduces the asymmetric adjustment factor before the calculation of the probability of the positive sample (the output of the Sigmoid function). Fig. 5b illustrates a sequence of paired values for a and \u03b2 across wide-ranging IRs. The value of G increases with the IRs, reaching a plateau once the IR has surpassed 200. Given the symmetric nature of the Sigmoid function, with an unsaturated domain spanning around (-2, 2) in Fig. 5a, it is inferred that a saturated adjusted factor value of 2 constitutes the boundary. The shift of the symmetric Sigmoid curve can be intuitively interpreted as it lowers the value of probability calculated through an activation function, thus leading the classifiers to pay more attention to the defaulters during the learning process to optimize the total loss during the training process. Fig. 5c shows the correlation between the cost and the input value Z for a single sample-prediction process in two cases. When predicting a sample of which the ground truth is negative (a good customer, y = 0, bottom image), the misclassification cost using the ASIG-embedded-classifier is smaller compared with that from CE loss. When predicting a positive sample (a defaulted customer, y = 1, top image), the misclassification cost is emphasized, as the cost calculated from the ASIG-embedded-classifier is higher than that from CE. Emphasizing misclassification cost is an effective way to pay more attention to the positive sample, which has been applied in several loss-function improvements specific to the class-imbalanced scenario. ASIG modifies the decision boundary by adjusting the output of the input value z, thus implementing this mechanism.\nThe integration of the ASIG confers several key advantages. First, it proactively reduces the probability (the output from the input value Z) derived from the activation output, yielding more conservative predictions for positive events and thereby incentivizing classifiers to allocate increased attention to positive samples. Second, it shows a good generalization capacity and computational simplicity. The adjusted factor G is found by pretraining one financial dataset and can be used for other datasets with similar structures (tabular) and downstream scenarios (financial credit scoring). Its incorporation occurs subsequent to the computation of the input value Z and remains invariant throughout the training process. Consequently, it can be considered a constant coefficient for each training set, ensuring computational simplicity."}, {"title": "4.2 Method Performance", "content": "The GMC dataset serves as the foundational baseline for pretraining the hyper-parameter, specifically for the optimization of a and \u03b2. Upon calibrating these parameters, the ASIG method shows superior performance over competing classifiers across datasets with IRs ranging from 20 to 170. The performance details of the methods are listed in Tables 2, and the general performance plot is shown in Fig. 6. The overall performance of the ASIG method (ASIG-embedded-classifiers), alongside LGB, LGB-focal, and XGB, outperforms that of other classifiers, notably outshining decision tree, KNN, and random forest. Specifically, the ASIG method shows superior performance over LGB and LGB-focal in datasets, with IRs spanning from 20 to 170. However, in datasets characterized by exceedingly high IRs, a pronounced performance degradation is observed at the \"breaking point\" a threshold where significant declines vary across different datasets. Additionally, an escalation in variance is noted among classifiers in regions with elevated IRs.\nSpecifically, as shown in Fig. 5 and Table 2, the proposed classifier outperforms LGB by an average of 1.1%, XGB by 2.2%, LGB-focal by 2.6%, random forest by 6.7%, as well as KNN and decision tree by a substantial 25.3% and 30.1%, respectively. As the IR increases, the ASIG method maintains comparable AUC scores with LGB and LGB-focal. Random forest's performance is approximately 11% worse than its AUC on lower IRs. In scenarios with medium-high IRs (IR < 170), LGB, LGB-focal, XGB, and the ASIG method consistently exhibit robust and high performance, underscoring the algorithms' resilience and their relative insensitivity to distributional shifts in this range. LGB's performance shows a marginal decline as the IR increases, dropping from 0.856 to 0.816, while LGB-focal sees a decrease of 4.3%. The AUC score of the ASIG method decreases from 0.861 to 0.815. The marked performance downturn of LGB and the ASIG method at ultra-high IRs suggests limitations in stability under such conditions. However, they show an acceptable performance decrement at higher IRs, specifically at 230 and 260, indicating a degree of robustness amid increased class disparity."}, {"title": "4.3 Robustness and Stability", "content": "In addressing class-imbalance issues, it is imperative that robustness and stability are given equal consideration to method performance. An ideal classifier not only exhibits high efficacy on datasets characterized by a significant IR but also maintains minimal performance deterioration and consistent variance in the face of escalating IRs."}, {"title": "5. Conclusion", "content": "In this study, we have put efforts to mitigate the pronounced impact of IRs on the discriminative capacity of methods within the realm of financial credit scoring. We have introduced a simple yet effective activation function, the ASIG, that incorporates an IR-dependent adjusted factor, G(IR, \u03b1, \u03b2), into the Sigmoid function. This is further embedded in the focal loss and enhanced the performance of classifier. The ASIG-embedded-classifier showed effectiveness and generalization capacity on various datasets with similar structures (tabular), different IRs in financial credit scoring. The integration of the ASIG imparts an asymmetric characteristic to the classifier, thereby counteracting the effects of a highly imbalanced distribution on binary classification challenges.\nThe ASIG method, alongside a suite of conventional baseline algorithms, undergoes training across various datasets with diverse IRs. As anticipated, a decrease in method performance is observed with the rising IRs. Notably, when the IRs escalate from 20 to 170, the ASIG method consistently outperforms other classifiers across nearly all sub-datasets. For example, it surpasses LGB by an average of 1.1% and XGB by 2.2% in the GMC dataset. Moreover, the ASIG method exhibits robustness and stability within the tested range of IRs, aligning well with the data distributions commonly encountered in financial banking and credit-loan scenarios. Despite the superior performance of the ASIG-embedded-classifier over other classifiers, an increase in IRs leads to fluctuations and augmented variances across all methods.\nGiven the demonstrated efficacy, resilience, and consistency of the ASIG method on datasets with high IRs, we believe that this algorithm is a viable contender for credit scoring in the financial sector. It is particularly advantageous for applications with highly imbalanced data distributions. Future work will focus on the detailed theoretical mechanisms of the ASIG, a comprehensive study on the effects of pretraining the optimized ASIG hyper-parameter on different datasets, and the engineering implementation of the optimization process for finding improved form and hyper-parameter of the ASIG."}]}