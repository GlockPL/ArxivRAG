{"title": "DCNet: A Data-Driven Framework for DVL Calibration", "authors": ["Zeev Yampolsky", "Itzik Klein"], "abstract": "Autonomous underwater vehicles (AUVs) are underwater robotic platforms used in a variety of applications. An AUV's navigation solution relies heavily on the fusion of inertial sensors and Doppler velocity logs (DVL), where the latter delivers accurate velocity updates. To ensure accurate navigation, a DVL calibration is undertaken before the mission begins to estimate its error terms. During calibration, the AUV follows a complex trajectory and employs nonlinear estimation filters to estimate error terms. In this paper, we introduce DCNet, a data-driven framework that utilizes a two-dimensional convolution kernel in an innovative way. Using DCNet and our proposed DVL error model, we offer a rapid calibration procedure. This can be applied to a trajectory with a nearly constant velocity. To train and test our proposed approach a dataset of 276 minutes long with real DVL recorded measurements was used. We demonstrated an average improvement of 70% in accuracy and 80% improvement in calibration time, compared to the baseline approach, with a low-performance DVL. As a result of those improvements, an AUV employing a low-cost DVL, can achieve higher accuracy, shorter calibration time, and apply a simple nearly constant velocity calibration trajectory. Our results also open up new applications for marine robotics utilizing low-cost, high-accurate DVLs.", "sections": [{"title": "I. INTRODUCTION", "content": "Autonomous underwater vehicles (AUVs) play a significant role in a variety of marine and underwater applications. For example, oceanographic surveys [1, 2], underwater structure inspection such as gas pipelines [3-5], and detection of oil leaks [6, 7]. During the AUVs mission, the navigation solution is critical for the mission's success [8, 9]. The navigation solution, which is the position, velocity, and orientation of the AUV, is commonly provided by inertial sensors, Doppler velocity log (DVL), acoustic positioning, and other sensors such as pressure sensors [10, 11].\nThe DVL is an acoustic sensor that utilizes the Doppler frequency shift effect. It transmits acoustic beams to the seafloor, which are then reflected back. By using the frequency shift, the DVL is able to calculate each beam's velocity and then to estimate the AUV velocity [12, 13].\nThe DVL measurements are subject to different types of error sources and noise that influence the measurement quality and accuracy [14, 15]. To cope with such effects, DVL calibration is performed prior to mission start. In such a process, the error terms are estimated and calibrated for [16, 17]. Commonly, the calibration process requires the AUV to sail at sea level while using a reference velocity sensor to determine the AUV's"}, {"title": "II. PROBLEM FORMULATION", "content": ""}, {"title": "A. DVL Velocity", "content": "For a DVL with an \"x\" configuration, referred to as the \"Janus\" configuration, the direction of each beam in the DVL's body frame can be expressed as [25, 28]:\n$b_i = [cos \\psi_i sin \\alpha, sin \\psi_i sin \\alpha, cos \\alpha]_{1x3}$ (1)\nwhere $\\psi_i$ and $\\alpha$ refer to the pitch and yaw angles of beam i = 1, 2, 3, 4, respectively. For all beams, the pitch angle remains constant, whereas the yaw angle is given by\n$\\psi_i = (i - 1) \\frac{\\pi}{2} + \\frac{\\pi}{4} [rad]$, i = 1,2,3,4. (2)\nBy stacking all beam projection vectors from (1), the transformation matrix $H \\in R^{4x3}$ is formed:\n$H = \\begin{bmatrix} b_1 \\\\ b_2 \\\\ b_3 \\\\ b_4 \\end{bmatrix}_{4x3}$ (3)\nThe estimated velocity vector, expressed in the DVL frame, is\n$v_{DVL}^d = (H^T H)^{-1} H^T y$ (4)\nThe DVL error model is given by [12]:\n$\\tilde{y} = [H v_{AUV}^d (1 + S_{DVL})] + b_{DVL} + O_{DVL}$ (5)\nwhere $\\tilde{y}$ is the measured beam velocity vector, $v_{AUV}^d$ is the AUV velocity expressed in the DVL frame, $S_{DVL}$ is the scale factor applied over the beams, $b_{DVL}$ is the additive bias vector, and $O_{DVL}$ is the additive zero mean Gaussian white noise vector."}, {"title": "B. GNSS Based DVL Calibration", "content": "During the calibration process the AUV follows a predetermined trajectory while sailing at sea level, allowing GNSS-RTK velocity measurements of the AUV, while in parallel maintaining sufficient depth for the DVL to provide measurements. The GNSS-RTK and DVL measurements are related using the following error model [16]:\n$v^d = (1 + k)R (R_n v^n + \\omega_n^b \\times I_{DVL}) + \\delta v_d$ (6)\nwhere $v^n$ is the AUV reference velocity provided by the GNSS-RTK in the navigation frame, $R$ is the transformation matrix from the navigation to the body frame, $\\omega_n^b$ is the angular velocity of the AUV, and $I_{DVL}$ is the lever-arm between the DVL and the AUV center of mass. Matrix $R$ is the constant and known transformation matrix from the DVL to the body frame, $k$ is the scale factor applied over the reference velocity in the DVL frame, and $\\delta v_d$ is the additive zero mean Gaussian white noise. Note that the term $\\omega_n^b \\times I_{DVL}$ is usually neglected since the lever-arm is generally small and can be measured and compensated [21]. Thus, (6) reduces to:\n$v^d = (1 + k)R_n v^n + \\delta v_d$ (7)\nwhere $R_n^d$ is the transformation matrix from the navigation from to the DVL frame. By applying a vector norm on the error model presented in (7), the following is achieved [29]:\n$||v^d|| = (1 + k) ||R_n v^n||$. (8)\nFurther development of (8) produces the following scalar scale factor estimation:\n$k_t = \\frac{||v^d_t||}{||R_n v^n_t||} - 1, t = 1, ..., T$ (9)\nwhere $k_t$ is the estimated scalar scale factor at time step t that is applied to the measured DVL velocity as presented in (7). Note that $k_t$ is 1) a scalar scaling factor, thus the same scaling factor is applied over all three velocity axes, and 2) is an estimate at a single time step t, out of the entire calibration recording with T time steps. To estimate a single scaling factor and mitigate the zero mean Gaussian white noise effect, the average of all T time steps of $k_t$ is calculated as follows:\n$k = \\frac{1}{T} \\sum_{t=1}^T k_t$. (10)\nThis is the baseline approach, which provides the estimated scalar scale factor at the end of the calibration procedure."}, {"title": "III. PROPOSED APPROACH", "content": "In this section we present five different DVL error models and the derivation of our DCNet approach."}, {"title": "A. DVL Error Models", "content": "In our preliminary work [26] we proposed the following DVL error model:\n$v^d = (1 + K_{DVL}) R v^n + b_{DVL} + \\delta v_d$ (11)\nwhere $K_{DVL}$ is the scale factor vector:\n$K_{DVL} = [k_x, k_y, k_z]^T \\in R^3$ (12)\n$b_{DVL}$ is the bias vector:\n$b_{DVL} = [b_x, b_y, b_z]^T \\in R^3$ (13)\nand $\\delta v_d$ is the zero mean Gaussian white noise. Note that, as presented in (12) and (13), the scale factor and bias error terms can be modeled as scalars or vectors. When only a single type of error term is presented (bias or scale factor), four different DVL error models can be deduced from (11), as we presented in [26]."}, {"title": "B. Proposed DVL Calibration Neural Network", "content": "Our proposed approach, DVL calibration neural network (DC-Net), is a data-driven approach utilizing a deep learning (DL) neural network (NN) framework to estimate the error terms in the different EM1 - EM5 as presented in Section III-A. Our NN, presented in Figure 2, is suitable for all EMs. This is a multi-head network with input, output, and three major parts, as described below:\n1) Input Size: The input to the network is the same as the input to that presented in (7); that is the DVL and GNSS-RTK velocity vectors that were transformed to body frame, denoted as $v_{DVL}^d$ and $v_{GNSS}^n$, respectively. The input size is < batch size \u00d7 6 \u00d7 window size >, where 6 is the number of stacked velocity axes, which are the DVL and GNSS-RTK XYZ axes, and 10 is the selected window size that is described in subsection IV-A.\n2) 1DCNN Head: The input velocity vectors are subtracted to produce $v_{sub}^b$, which has has only three axes, X, Y, and Z. The subtraction vector goes through two 1D convolution layers each followed by a LeakyReLU activation function (21). The vector $v_{sub}^b$ is the subtraction of the GNSS-RTK from the DVL as follows:\n$v_{sub}^b = v_{DVL}^d - v_{GNSS}^n$. (14)\nWe used the subtraction, because, if we consider a scalar scale factor error model such as EM1, we can use (7) as follows:\n$v_{sub}^b = (1 + K_{DVL})R_n v^n - v_{GNSS}^n$ (15)\nAt this point we ignore $\\delta v_d$ since it can be averaged out. Recall that we use the GNSS-RTK as the reference and we assume $R = I_3$, thus resulting in\n$R_n v^n = v_{GNSS}^n$ (16)\nBy using (16) with (15) we derive the following:\n$v_{sub}^b = (1 + K_{DVL})v_{GNSS}^n - v_{GNSS}^n = v_{GNSS}^n + K_{DVL} \\cdot v_{GNSS}^n - v_{GNSS}^n. = K_{DVL} v_{GNSS}^n$ (17)\nConsidering that we are using several training trajectories, we expect that the FC batch will be able to extract the error terms more easily when provided with the concatenated outputs of the two CNN heads, given the derived input (15) to the 1DCNN.\n3) 2DCNN Head: Is passed with the two velocity vectors, the GNSS-RTK and the DVLs, as presented in the input, through three 2D convolution layers, each followed by a LeakyReLU activation function (21). The first convolution's layer kernel is dilated by 3 \u00d7 1, while the other two are dilated by 1 \u00d7 1. This way, instead of processing the extracted features by the 1D convolution layers only once concatenated and passed through the FC batch, using the 2D convolution kernel allows us to extract features and process information stored in both vectors from the start through the first convolution layer. The dilated kernel in the first 2D convolution layer allows the first layer to process simultaneously the corresponding axes of the DVL and GNSS-RTK velocity; i.e., process both X axes. The motivation for the dilation is to enable the network to mimic the information extraction as in the subtraction vector, $v_{sub}^b$. 4) FC Batch: consists of four FC layers. Each layer of the first three is followed by a LeakyReLU activation function (21) and then by a dropout layer III-C4. The"}, {"title": "C. DCNet Formulation and Training Process", "content": "In this section, we will examine the mathematical formulation of DCNet and the training process.\n1) Fully Connected Neural Network: Neurons are the building blocks of a NN, where each neuron in the FC layer is defined by [25]:\n$z_i^{(l)} = \\sum_{j=1}^{\\eta(l-1)} W_{ij}^{(l)} a_j^{(l-1)} + b_0^{(l)}$ (18)\nwhere $W_{ij}^{(l)}$ is the learnable weight of the $i^{th}$ neuron in the $l^{th}$ layer that is connected to the $j^{th}$ neuron in the $(l \u2013 1)^{th}$ layer. The term $b_0^{(l)}$ is the bias of the $i^{th}$ neuron in the $l^{th}$ layer, and $a_j^{(l-1)}$ is the output of the $j^{th}$ neuron in the $(l \u2013 1)^{th}$ layer. Each convolution layer is structured in a similar way where each kernel sized $m_1 \u00d7 m_2$ contains $m_1 \u00d7 m_2$ neurons.\n2) Convolution Neural Network: CNNs are constructed similarly to a FC layer, and expand the single neuron (18) to a kernel (filter) of size $m_1 \u00d7 m_2$ neurons [25]:\n$C_{ij}^{(l)} = \\sum_{\\alpha=0}^{m_1} \\sum_{\\beta=0}^{m_2} w_{\\alpha \\beta}^{(l)} a_{(i+\\alpha)(j+\\beta)}^{(l-1)} + b^{(l)}$ (19)\nwhere $C_{ij}^{(l)}$ is the output of the kernel, and $w_{\\alpha \\beta}^{(l)}$ is the weight of the kernel in the $(\\alpha, \\beta)$ position in the $l^{th}$ convolution layer. The term $a_{(i+\\alpha)(j+\\beta)}^{(l-1)}$ is the output of the preceding convolution layer, and $b^{(l)}$ is the bias of the $l^{th}$ convolution layer.\n3) Nonlinear Activation Functions: Traditionally, each neuron's output, whether of a FC layer (18) or a convolution layer (19), passes through a nonlinear activation function, otherwise a NN acts as a linear regression model [30]:\n$a_i^{(l)} = h(z_i^{(l)})$ (20)\nwhere $z_i^{(l)}$ is the $i^{th}$ neuron in the $l^{th}$ layer output\u2014in this case a FC layer (18)\u2014h is the activation function, and $a_i^{(l)}$ is the output of the activation function employed. In this work we use the following nonlinear activation functions:\n1) Leaky Rectified Linear Unit (LeakyReLU): An activation function that scales negative values and does not change positive values [30]:\n$LeakyReLU(C_{ij}^{(l)}) = \\begin{cases} C_{ij}^{(l)}, & \\text{if } C_{ij}^{(l)} \\geq 0 \\\\ \\alpha \\cdot C_{ij}^{(l)}, & \\text{otherwise} \\end{cases}$ (21)\nwhere $\\alpha$ is the scaling factor of the negative value, and $C_{ij}^{(l)}$ is the input to the function, in this case a convolution layer kernel output (19) since LeakyReLU is applied over the convolution layers output both in the 1DCNN and the 2DCNN heads.\n2) Hyperbolic Tangent Function (Tanh): A continuous and differentiable nonlinear activation function, which outputs values within a defined range of [-1, 1] $\\in$ R as in [30]:\n$Tanh(z_i^{(l)}) = \\frac{e^{z_i^{(l)}} - e^{-z_i^{(l)}}}{e^{z_i^{(l)}} + e^{-z_i^{(l)}}}$ (22)\nwhere e is the Euler constant, and $z_i^{(l)}$ is the FC layer output, which is the input to this activation function. As described in Section III, the TanH activation function is applied over the first three layers in the FC batch.\n4) Regularization: During training, overfitting occurs when the NN learns noise patterns present in training data, which results in a low loss value during training but fails to generalize and performs poorly on the test data [31]. In this work, we use dropout regularization [32] to mitigate the overfitting problem. With dropout, some neurons are not used during training with probability 1 \u2013 p, as follows [32]:\n$r \\sim Bernoulli(p)$\n$\\tilde{a}_i = r a_i$\n$a_j^{(l+1)} = w_{ji}^{(l+1)} (\\tilde{a}) + b_j^{(l+1)}$ (23)\nwhere r is a random variable sampled from a Bernoulli distribution with p probability, a is the activation function output over the $i^{th}$ neuron (20), and the term $\\tilde{a}$ is the dot product of r and a. The dot product, $\\tilde{a}$, is fed as input to the $j^{th}$ neuron in the $(l+1)^{th}$ layer after dropout was applied. The terms $w_{ji}^{(l+1)}$ and $b_j^{(l+1)}$ are the weights and biases as described in Section III-C1.\n5) Training Process: The training process aims to determine the weights and biases of all the neurons comprising the NN, in order to achieve the lowest possible loss function score. The loss function used in this study is the mean squared error (MSE) loss function:\n$J(y_i, \\hat{y}_i) = \\frac{1}{N} \\sum_{i=1}^N ||y_i - \\hat{y}_i||_2$ (24)\nwhere $J()$ is the MSE function, $y_i$ is the GT value, $\\hat{y}_i$ is the network estimation, and N is the number of samples. Forward passing refers to the process of passing the input through the network's various layers, such as (18) and (19). Based on the output of the network, the loss function value is calculated and derived with respect to the weights and biases of the NN. As part of the training process, the derivations are used to minimize the loss value in the next forward pass, by updating"}, {"title": "IV. EXPERIMENTAL RESULTS", "content": ""}, {"title": "A. Data Collection and Processing", "content": "To validate our proposed approach, data recorded using the University of Haifa's \"Snapir\u201d AUV was used. This data was provided in [25] and [34] and can be found at their associated GitHub repositories. Figure 5 shows an image of the AUV during a mission. \"Snapir\" is a torpedo-shaped AUV measuring 5.5 meters in length and 0.5 meters in diameter. The \"Snapir\" employs a Teledyne RD Instruments Work Horse Navigator DVL, with a sampling rate of 1Hz and accuracy of 0.6 cm/s while traveling at 3 m/s [14].\nA total of ten trajectories were recorded in two separate sea experiments. In the first, nine trajectories, referred to as T1 - T9, were recorded with a total time of 243 minutes. In the second experiment, an additional trajectory was recorded (referred to as T10) with a total time of 33 minutes of recordings. Figure 6 presents the AUV velocity, expressed in the body frame, as a function of time during the T4 and T6.\nNext, trajectory T10 was divided into two parts. The first 200 seconds were allocated for evaluating the calibration parameters based on our trained network and are referred to as the calibration dataset T10Cal. The remaining 1800 seconds of T10 are part of the test dataset and are referred to as T10Test. The training dataset contains of trajectories T1-T5 while the test datasets includes trajectories T6-T9 and T10Test. The motivation for this selection is twofold: 1) T10 is the trajectory recorded in a different sea experiment, thus making it the calibration dataset aims to generalize and increase our model robustness as we train on trajectories from a different sea experiment. 2) T10Cal represents a simple nearly constant velocity trajectory, thus if we are able to learn the calibration parameters solely on T10Cal, we also offer a simple effective trajectory for the calibration process.\nAll the recordings contain the DVL measured velocity. To produce the sensor noise, we applied a moving average (MA) filter over all ten trajectories. We used a MA filter with a five second window [35]:\n$\\hat{x}_i = \\frac{1}{11} \\sum_{j=i}^{i+5} x_j$ (27)\nwhere T is the total recording length, $x_j$ is the original velocity vector at time step j, and $\\hat{x}_i$ is the MA filtered velocity vector. The filtered data is then referred to as our ground-truth (GT) data.\nTo produce the low-cost DVL measurements and the reference GNSS-RTK, we employed a noising pipeline presented in Figure 7, which takes as input the GT velocity. The noising pipeline is designed to mimic the beams error model (5), transformation to the DVL frame (4), and later to the body frame. Additionally, the pipeline outputs the GNSS-RTK measurements by applying a zero mean Gaussian white noise to the GT measurements as follows:\n$\\hat{v}_{GNSS} = v_{GT} + O_{GNSS-RTK}$ (28)\nwhere $O_{GNSS-RTK} \\sim N(0, 0.005 m/s^2)$ and remains constant whenever the pipeline is used. Note that $S_{DVL}, b_{DVL}$, and $O_{DVL}$ are the only parameters that affect the noising pipeline outcome."}, {"title": "V. CONCLUSION", "content": "This work proposes and examines the benefits of data-driven approaches in the DVL calibration process. Most works in the literature require complex trajectories accompanied by model-based nonlinear estimation filters for such a calibration task. In this work we offer a data-driven framework with a simple, yet efficient, calibration network called DCNet. We suggested five different calibration error models for the evaluation over two different types of DVL. For training the network we used a dataset of 175 minutes while the test dataset was 98 minutes long. Both datasets contain real-world recorded DVL measurements. Using EM5, we showed that DCNet outperforms the baseline approach by achieving an 80% improvement in calibration time. That is, instead of 100 seconds required for the calibration procedure, ours require only 20 seconds. Moreover, we demonstrate that during those 20 seconds the AUV should maintain a nearly constant velocity trajectory and does not require any complex maneuvering. In terms of the velocity accuracy, EM5 obtained an average of 70% improvement over the baseline in terms of the velocity RMSE. In summary, this paper presents an end-to-end data-driven calibration approach that reduces the calibration process complexity while maintaining high accuracy. This holds true only for low performance (low-cost) DVL. Therefore, our work opens up the possibility of using low-cost DVLs and achieving higher accuracy. As a consequence, different types of marine robotic systems will be able to use low-cost DVLs with high accuracy opening them up for use in new applications."}]}