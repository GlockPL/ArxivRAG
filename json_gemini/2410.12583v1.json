{"title": "STRUX: An LLM for Decision-Making with Structured Explanations", "authors": ["Yiming Lu", "Yebowen Hu", "Hassan Foroosh", "Wei Jin", "Fei Liu"], "abstract": "Countless decisions shape our daily lives, and\nit is paramount to understand the how and why\nbehind these choices. In this paper, we intro-\nduce a new LLM decision-making framework\ncalled STRUX, which enhances LLM decision-\nmaking by providing structured explanations.\nThese include favorable and adverse facts re-\nlated to the decision, along with their respective\nstrengths. STRUX begins by distilling lengthy\ninformation into a concise table of key facts. It\nthen employs a series of self-reflection steps to\ndetermine which of these facts are pivotal, cate-\ngorizing them as either favorable or adverse in\nrelation to a specific decision. Lastly, we fine-\ntune an LLM to identify and prioritize these\nkey facts to optimize decision-making. STRUX\nhas been evaluated on the challenging task of\nforecasting stock investment decisions based\non earnings call transcripts and demonstrated\nsuperior performance against strong baselines.\nIt enhances decision transparency by allowing\nusers to understand the impact of different fac-\ntors, representing a meaningful step towards\npractical decision-making with LLMs.", "sections": [{"title": "1 Motivation", "content": "Decision-making is complex, as it requires the eval-\nuation of various determinants that can influence\noutcomes (Eigner and H\u00e4ndler, 2024). This abil-\nity is crucial across multiple fields, ranging from\nhealthcare, where decisions can determine patient\nhealth outcomes (Lehman et al., 2022), to finance,\nwhere investment choices can impact financial sta-\nbility (Keith and Stent, 2019; Liu et al., 2023). For\nLLMs to be effective, they must not only identify\nrelevant facts but also weigh the favorable and un-\nfavorable aspects to reach insightful conclusions.\nTo date, it remains unclear whether LLMs can ef-\nfectively balance multiple factors in complex sce-\nnarios to make rational decisions.\nLLMs also produce lengthy, plain text explana-\ntions that can sometimes overwhelm users with too\nmuch information or ambiguity (Vafa et al., 2021;\nAlkhamissi et al., 2023; Sharma et al., 2023; Ye\net al., 2023; Wang et al., 2024). As we increasingly\nrely on those LLMs for critical decision-making, it\nis important to prioritize transparency and account-\nability (Ludan et al., 2023). We propose structuring\nthese explanations into a table format, where each\nfact is listed with a 'strength level' that measures\nits influence on the decision-making process. This\napproach not only facilitates review and modifica-\ntion of various facts by humans, but also enhances\nthe transparency of the decisions made.\nFurther, a significant advantage of LLMs is their\nability to reason through complex scenarios, which\ncan enhance the decision-making processes (Shinn\net al., 2023; Yao et al., 2023; Zeng et al., 2024;\nBand et al., 2024). Notably, DeLLMa (Liu et al.,\n2024) uses classical decision theory to help LLMs\nmake decisions under uncertainty. It infers a utility\nfunction through prompting and optimizes the ex-\npected utility using Monte Carlo estimation. Feng\net al. (2024) calculate decision probabilities using\na Bayesian model and present results on datasets\nsuch as Common2Sense (Singh et al., 2021) and\nPlaSma (Brahman et al., 2023). In contrast, our ap-\nproach involves fine-tuning an LLM with domain-\nspecific knowledge to ensure it prioritizes support-\ning facts accurately. Training instances are gener-\nated via a series of reflection steps, without relying\non human annotations.\nOur research explores the potential of using earn-\nings call transcripts to forecast stock investment de-\ncisions (Sawhney et al., 2020; Medya et al., 2022;\nLopez-Lira and Tang, 2023; Ni et al., 2024). Pub-\nlicly traded companies in the U.S. are mandated by\nthe Securities and Exchange Commission (SEC) to\nregularly report their financial performance, often\nthrough earnings calls. These calls include presen-\ntations from senior executives, such as the CEO and\nCFO, followed by a Q&A session with financial an-\nalysts. The objective is to reassure investors about\nthe company's management and strategy. With the\nrise of LLMs in financial services (Zhu et al., 2021;\nSang and Bao, 2022; Cao et al., 2024; Reddy et al.,\n2024), analyzing earnings call transcripts to guide"}, {"title": "2 The STRUX System", "content": "STRUX is tasked with predicting a company's post-\nearnings stock trend to inform the investment deci-\nsion. It is set to select the most relevant facts from\na provided fact table, ensuring a balanced represen-\ntation of positive and negative facts affecting the\nstock price. Each selected fact must then be eval-\nuated for its potential impact on the stock's price\nmovement. A \u201c+\u201d symbol indicates a positive im-\npact, with the number of symbols varying from one\n(+) to three (+++) showing the increasing strength.\nConversely, a \"-\" symbol denotes a negative im-\npact, with one (-) to three (---) symbols reflecting\nthe severity of the negative influence.\nOur system then combines and analyzes all the\nselected facts to forecast the direction of the stock\nprice movement. The outcomes include: Strongly\nBuy (SB), Buy (B), Hold (H), Sell (S), or Strongly\nSell (SS). It also provides a justification elaborat-\ning on its rationale, focusing on the key facts that\ninfluence this decision. As illustrated in Figure 1,\nour structured explanations consist of three com-\nponents: {supporting facts, decision, and brief jus-\ntification}. Supporting facts can be both favorable"}, {"title": "2.1 Generating Structured Explanations\nThrough Self-Reflection", "content": "We create a fact table from each company's earn-\nings call transcript to summarize key financial met-\nrics, which are crucial for making informed invest-\nment decisions. Following Koa et al. (2024), we in-\nput executive speeches from either the Prepared Re-\nmarks or Q&A sessions into the LLM. Summaries\nare proportional in input length. Each speech from\nthe Prepared Remarks is summarized into 3-5 key\nfacts, while those from the Q&A session are con-\ndensed into 1-3 key facts. The fact table was gen-\nerated using OpenAI's gpt-4o-mini-2024-07-18;\nrefer to the Appendix for the prompt. It distills es-\nsential information from a lengthy transcript, high-\nlighting key aspects of a company's financials (Cho\net al., 2021, 2022).\nReflection. We use a series of reflective steps to\ncreate training instances without requiring human\nannotations. This reflection was performed by GPT-\n40-mini, aiming to help the model learn from its\nmistakes. When the model makes a poor invest-\nment decision, we notify it of the error and prompt\nit to identify any significant flaws in its fact selec-\ntion, strength assignment, or reasoning processes.\nWe also provide a list of previous incorrect deci-\nsions, including the reasons behind those decisions.\nImportantly, we ask the model to come up with a\ndifferent decision from its previous ones without\nrevealing the correct answer. This approach allows\nus to observe the model's independent decision-\nmaking that emerges from reflection. Our prompt\nused for reflection can be found in the Appendix.\nDemonstrations and Comparisons. Our \u2018demon-\nstrations' data contains training instances where\noutput y has a correct decision post-reflection. We\nutilize this data to fine-tune Llama3, helping it pri-\noritize relevant facts and make accurate decisions.\nThe 'comparisons' data consists of paired outputs,\ny and y*, where y* is the output with the correct"}, {"title": "2.2 Fine-tuning LLMs for Decision-Making", "content": "STRUX+SFT. We start with the base LLM model,\nLlama3-8b-Instruct, and fine-tune it using our\ndemonstrations data to develop the SFT model\n\\(p_{\\theta}(y|x)\\). Specifically, the input x is a fact table\ncreated from an earnings call transcript, and the out-\nput y includes structured explanations that contain\n{supporting facts, a decision, a brief justification}.\nAs illustrated in Equation 1, the fine-tuning process\naims to minimize the negative log-likelihood of the\ndata. Here, y* ~ \u03c0(\u00b7|x) represents the demonstra-\ntions provided by gpt-4o-mini-2024-07-18, each\nof which contains the correct decision.\n\\(L_{SFT}(\\theta) = -E_{x\\sim D,y^*\\sim\\pi(\\cdot|x)}[log p_{\\theta} (y^*|x)]\\) (1)\nSTRUX+RL. In reinforcement learning, we start\nwith a policy \\(p_{o_{\\theta}}(y|x) = p_{\\theta}(y|x)\\) and fine-tune the\npolicy \\(p_{o_{\\theta}}(y|x)\\) using a reward function \\(r_{\\phi}(x, y)\\).\nWe employ proximal policy optimization to opti-\nmize the expected reward. This process involves\nrepeatedly choosing an instance from our training\nset, calculating the reward for the model's response\nwith the reward function, then updating model pa-\nrameters towards maximizing the reward. Follow-\ning (Ziegler et al., 2020), we include a penalty\n\\(\\beta log \\frac{p_{\\theta'}(y|x)}{p_{\\theta}(y|x)}\\) to the reward to prevent \\(p_{\\theta'}(y|x)\\) from\ndiverging too far from \\(p_{\\theta}(y|x)\\) where the learned"}, {"title": "3 Earnings Call Transcripts", "content": "Our dataset includes 11,950 quarterly earnings call\ntranscripts from the Motley Fool website, collected\nby Hu et al. (2024), covering the period from 2017\nto 2024. It contains transcripts from 869 compa-\nnies listed on the NASDAQ 500 and S&P 500, with\nan average of 10,187 tokens per transcript. Due to\nresource limits, we construct a balanced training\nset with 100 transcripts from each of the 11 finan-\ncial sectors. Our test set consists of 587 transcripts\nfrom 2024, carefully chosen to ensure they were\nnot part of the LLM pretraining, which has a cutoff\nup to December 2023. Our study focuses on the tex-\ntual information of these transcripts and excludes\nacoustic features. The ground-truth investment de-\ncisions are based on a stock's performance 30 days\npost-earnings; they are categorized as Strongly Buy,\nBuy, Hold, Sell, or Strongly Sell."}, {"title": "4 Experimental Results", "content": "We evaluated our STRUX against strong baselines\nfor forecasting stock investment decisions. This"}, {"title": "5 Conclusion", "content": "STRUX marks a notable step in using LLMs for\ndecision-making. It integrates structured explana-\ntions into the decision-making process through a\nseries of reflective steps. STRUX not only leads to\nhigher accuracy but also improves the transparency\nof LLM decisions, making it a valuable tool for\ncomplex decision-making scenarios."}, {"title": "6 Limitations", "content": "STRUX represents a significant advancement in\nusing LLMs for decision-making, particularly in\nfinancial contexts. However, it's crucial to refine its\nfact extraction capabilities, as inaccuracies in data\nselection can impact decision quality. Additionally,\npredicting stock movements is inherently complex\nand influenced by various external factors like data\nquality and market nuances. Users are advised\nto carefully consider these aspects to maximize\nSTRUX's effectiveness and accuracy in real-world\napplications. With ongoing enhancements, STRUX\nhas the potential to revolutionize decision-making\nacross diverse sectors."}, {"title": "A Implementation Details", "content": "For STRUX+SFT, we fine-tune the system for three\nepochs with a learning rate of 1e-5, adjusted using\na cosine scheduler. A warm-up ratio of 0.1 is set\nto ease the model into training, and we use the\nAdam optimizer configured with betas=(0.9, 0.999)\nand epsilon=1e-08. Our Reward Model (RM) also\nruns for three epochs, using a learning rate of 1e-4.\nIt shares the same cosine scheduler and warm-up\napproach. For our STRUX+RL using Proximal\nPolicy Optimization (PPO), the training lasts two\nepochs with the learning rate set to 1e-5.\nOur summarizer is instructed to focus on sig-\nnificant details that could impact the stock price,\nincluding financial performance, future outlooks\nand guidance, strategic decisions, company direc-\ntion, market trends, competitive positioning, etc. It\nalso incorporates three historical financial metrics:\nearnings per share (EPS), revenue trends, and his-\ntorical stock price, gathered from Alpha Advantage.\nThese metrics are classified into three categories:\n'Bullish' (indicating strong financial health), 'Sta-\nble' (showing steady metrics), and 'Bearish' (sug-\ngesting investor pessimism). We focus on speeches\nfrom company executives and omit input from or-\nganizers and analysts."}]}