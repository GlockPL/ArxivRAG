{"title": "LTLBench: Towards Benchmarks for Evaluating Temporal Logic Reasoning in Large Language Models", "authors": ["Weizhi Tang", "Vaishak Belle"], "abstract": "Temporal reasoning (TR) is a critical component of artificial intelligence, encompassing understanding and processing temporal information and relationships between events. To discover and study the TR ability in Large Language Models (LLMs), various datasets have been constructed in different ways for evaluating various aspects of TR ability. Our work proposes a novel approach to design and develop a pipeline for constructing datasets to evaluate the TR ability of LLMs by leveraging random directed graph generation, LTL formula, and the NuSMV model checker. Based on the pipeline, we have also constructed a dataset as a benchmark, namely LTLBench, consisting of 2,000 TR challenges and evaluated six LLMs with it. Furthermore, we have conducted additional experiments to discover the impact of increasing the number of events and formula operators on the complexity of TR problems and the performance of LLMs. We have demonstrated that although LLMs exhibit some promise in handling TR challenges, they still struggle with complex TR. We expect this work can offer insights into TR ability in LLMs while also providing a valuable tool for future TR evaluations.", "sections": [{"title": "1 Introduction", "content": "Temporal reasoning (TR) is a fundamental and critical aspect of artificial intel-ligence, that encompasses understanding, processing, and reasoning about thetemporal information and relationships between events, which is essential forhandling and solving problems in various scenarios [20, 4, 27]. Recently, LargeLanguage Models (LLMs) have demonstrated and shown promise and emer-gence of various reasoning abilities, including but not limited to mathematicalreasoning [9, 31, 12], commonsense reasoning [3, 31], and theory of mind reason-ing [21, 14, 23, 24]. Nevertheless, there still remains a lack of definitive consensusregarding the emergence, performance, and robustness of their ability to tackleTR challenges. Several studies have demonstrated that although LLMs haveshown some promise with TR ability, they still struggle with TR and there isa substantial gap on the performance of handling and solving TR challengesbetween the state-of-the-art LLMs and humans [5, 30, 2]. Furthermore, sinceTR ability is crucial for handling and processing temporal information and re-lationships between temporal events and TR problems are ubiquitous amongmany activities [27], for LLMs, in their frequently mentioned and utilized sce-nario, question and answering, correctly comprehending temporal informationand handling temporal tasks is necessary and warranted to provide efficient andhelpful responses. In addition, LLMs are also discussed and used in various wayssuch as embodied agent [18, 29, 17] for which planning and decision making un-avoidably intertwine with TR. Therefore, it is necessary and important to studyand discover the TR ability of LLMs.\nIn order to discover and evaluate the TR ability of LLMs, various benchmarkshave been developed in previous studies using various dataset construction ap-proaches, aiming at evaluating the TR ability of LLMs from different perspectivesand at different levels of complexity. For example, in [32], they utilize GPT-3.5to generate graph-based TR problems based on the temporal knowledge graphYAGO11k [7]. Additionally, in [8], they employ random graph generation as afoundation and preparation to form rule-based and different types of temporalfacts and questions. In order to further discover the TR ability of LLMs andpush the boundaries of evaluation of TR ability, we proposed and designed anovel pipeline for TR dataset construction which allows for the controllable andscalable generation of TR problems at any level of complexity and size. Basedon it, we have also generated and constructed a dataset consisting of 2,000 TRproblems as a benchmark, namely LTLBench.\nInspired by [8], although our approach also involves random graph gener-ation as the prerequisite and preparation for subsequent problem generations,the methodology differs a lot from it in terms of the usage of generated graphsand subsequent problem generations. In our approach, a generated TR problemmainly consists of a context that depicts the situation of a TR problem and ahypothesis requiring LLMs to judge its validity against the given context of theproblem. In addition, the core components in the process of dataset generationinvolve a randomly generated directed graph which forms the preparation forsubsequent problem generations, a random linear temporal logic (LTL) formulathat serves as the hypothesis regarding a given problem context, and the NuSMVmodel checker [6] which allows for running the code which represents the events,the transitions between events, and also the LTL formula to provide the groundtruth label for the TR problem.\nIt is worth noting that although complex LTL is always discussed and usedin the context of formal and program verification, basic and reasonably complexLTL tasks are ubiquitous in many daily tasks. For example, if people are out ofmilk, they will eventually buy it, which can be formalized in an LTL formula as G(OutOfMilk \u2192 F(BuyMilk)), and also if the traffic light is green, it will then"}, {"title": "2 Related Work", "content": "Temporal reasoning has recently obtained substantial attention and study [32,\n8, 2, 5, 11, 16, 26]. In the work [2], they point out the deficiencies of LLMsin terms of their ability to understand and handle temporal information andreasoning. Additionally, in [32], they introduce and propose a framework, TG-LLM, to improve the performance of LLMs in tackling TR tasks. Nevertheless,the evaluation and enhancement of TR ability in LLMs are still in progress andneed more effort and study."}, {"title": "2.2 TR Benchmarks", "content": "To evaluate TR ability of LLMs, various TR datasets and benchmarks havebeen developed and constructed in different approaches for evaluating differentaspects of TR ability of LLMs at varying levels of complexity [8, 30, 32, 2,\n19, 22, 28]. For instance, in [32], a TR dataset is constructed by leveraginga large temporal knowledge graph, YAGO1lk [7], and utilizing GPT-3.5 andrule-based Python script to generate TR challenges. However, in the work [8],they leverage graph generation and use rule-based methods without introducingLLMs to generate TR tasks, highlighting and focusing on temporal semanticsand arithmetic reasoning. Additionally, in [30], they introduce a TR datasetconsisting of various temporal aspects such as order, arithmetic, frequency, andduration. Our work introduces a novel pipeline for generating TR problems basedon graph generation, LTL formula, and the NuSMV model checker, allowing forthe control of the complexity and size of problems."}, {"title": "3TR Problem Generation Pipeline", "content": "The pipeline to generate a single TR problem consists of four stages: (1) RandomDirected Graph Generation, (2) LTL Formula Generation, (3) NuSMV CodeGeneration, and (4) Natural Language Generation. Figure 1 demonstrates theoverview of the process for a TR problem generation."}, {"title": "3.1 Random Directed Graph Generation", "content": "During this stage, a directed graph is randomly generated with a given numberof events $n$ where $n > 1$ to ensure the formation of transitions between events."}, {"title": "3.2 LTL Formula Generation", "content": "Based on the events generated in the graph, we employed and slightly modifiedthe algorithm designed by [33] to generate an LTL formula with a given numberof operators $m$ where $m > 0$. The LTL operators include unary and binaryoperators. Unary operators, for example, include but are not limited to X whichindicates that for a given event $\\phi$, $X\\phi$ denotes that the event $\\phi$ will occur at\nthe next moment, and F for which $F\\phi$ means that event $\\phi$ will eventually occur\nat some point in the future. Binary operators include but are not limited to $\\&$\nrepresenting logical AND and $|$ representing logical OR. The given number ofoperators refers to the number of unary and binary LTL operators contained"}, {"title": "3.3 NuSMV Code Generation", "content": "Given the information of events from the graph and the LTL formula, this stageaims at converting and representing them in NuSMV code. The generation ofthe NuSMV code is divided into two parts: (1) context generation and (2) LTL-SPEC generation. The context describes the situation of the TR problem whileLTLSPEC represents a hypothesis regarding the context.\nFor the context generation, it includes event definitions, initial event setup,and event transitions setup. Based on the generated graph, the events and theirtransitions are converted into the context part of the NuSMV code while aninitial event is set up randomly and also converted into the NuSMV code. Asshown in Listing 1.2, Lines 2-3 define the three events, Line 5 sets up the initialevent which is event3, and Lines 6-12 construct the transitions of events in which,for instance, Line 7 shows that event2 can follow event\u2081. In addition, Line 11indicates that event2 remains to itself and after event2, no other events canhappen, if there is no other transition specified from event2 to eventi where$i \\neq 2$.\nFor LTLSPEC generation, we convert the generated LTL formula into codethat complies with NuSMV, as illustrated at Line 13 in Listing 1.2 which repre-sents the LTL formula shown in Listing 1.1.\nThe generation of the NuSMV code aims at providing the ground truth labelfor the TR problem. The generated code will be executed by the NuSMV modelchecker to give the ground truth label during the generation process."}, {"title": "3.4 Natural Language Generation", "content": "During this stage, the events information in the graph and the LTL formula willbe converted and represented in natural language. Similar to the NuSMV codegeneration, this stage can also be divided into two parts: (1) context generationand (2) hypothesis generation. The context describes the situation of the problem"}, {"title": "4 Experiment Settings", "content": "To evaluate the TR ability of LLMs, based on the pipeline, we generated andconstructed a dataset, LTLBench, consisting of 2,000 problems. Each problemfeatures the number of events $n = 3$ and the number of formula operators $m = 3$.\nAdditionally, to explore the impact of changes in the number of formula oper-ators, we conducted evaluations on newly generated problems with the fixednumber of events $n = 2$ while varying the number of formula operators forwhich $m\\in \\{1, 2, 3, 4, 5, 7, 9\\}$. For each $(n, m_i)$, such as $(2, 1)$ indicating that thenumber of events is 2 and the number of operators is 1, there are 300 problemsgenerated as a dataset for evaluation. Similarly, we fixed the number of formulaoperators $m = 2$ and varied the number of events for which $n \\in \\{2, 3, 4, 5, 7, 9\\}$ toexamine the effects of changing the number of events while keeping the numberof operators constant. In addition, for all generated datasets, their distributions"}, {"title": "5 Results and Analyses", "content": "We have evaluated the selected models on LTLBench which consists of 2,000generated TR problems with the number of events $n = 3$ and the number offormula operators $m = 3$. The metrics consisting of Accuracy, F1, and AUC areshown in Table 1.\nFrom the metrics, all Accuracy and AUC of LLMs are above 0.5. In addition,the model, qwen:72b-chat, demonstrates the highest Accuracy at 0.60, F1 at 0.59,and AUC at 0.60 while the llama3:70b-instruct also shows a similar performance.It may indicate that they show promise and ability to handle TR challenges.Nevertheless, the modest metrics signify that they still struggle with complexTR problems.\nIn addition, the averages of Accuracy, F1, and AUC for the models with largeparameter sizes are 0.58, 0.58, and 0.58 respectively, while for the models withsmall parameter sizes, they are 0.54, 0.52, and 0.54 respectively. It unsurprisinglyindicates that models with large parameter sizes may surpass the models withsmall parameter sizes when handling these complex TR challenges, although thedifference between the performance is modest."}, {"title": "5.2 Impact of increasing m", "content": "The selected models are also evaluated on the additional constructed datasets,where the number of events is fixed to $n = 2$ while the number of formula opera-tor m increases from 1 to 9, specifically $m \\in \\{1, 2, 3, 4, 5, 7, 9\\}$. The performancein terms of Accuracy and AUC of the evaluated models is shown in Figure 3.\nAs shown in Figure 3a, the accuracy of models significantly drops from $m = 1$\nto $m = 2$ regardless of the models with large parameter sizes or models with"}, {"title": "5.3 Impact of increasing n", "content": "In addition, the selected models are also evaluated with the number of formulaoperators fixed to $m = 2$ while the number of events n where $n > 1$ increases from2 to 9, specifically $n \\in \\{2,3,4,5,7,9\\}$. The performance in terms of Accuracyand AUC of the evaluated models is shown in Figure 4.\nAs shown in Figure 4a and Figure 4b, the Accuracy and AUC of modelsshow a trend to decrease while the number of events increases. Although it isnot as obvious and significant as the case when n is fixed and m increases, itstill indicates that increasing the number of events will also introduce a certainlevel of complexity. In addition, as the same case discussed in Section 5.2, asthe number of events increases, models with large parameter sizes show indif-ferent performance to the models with small parameter sizes since their AUCapproaches 0.5, indicating random guessing."}, {"title": "6 Implications", "content": "We designed a pipeline for constructing TR datasets to evaluate the TR abilityof LLMs. The pipeline is controllable and scalable to be able to introduce anylevel of complexity of TR by modifying the number of events and the numberof formula operators. Future work can leverage this pipeline to generate TRproblems at a certain level of complexity depending on specific needs."}, {"title": "7 Limitations and Future Work", "content": "Considering the difficulty of generated TR problems, we only included a subset ofLTL operators in the TR problem generation pipeline but excluded several LTLoperators such as U (Until) and R (Release). However, adding and incorporatingmore LTL operators should be easy and straightforward to enable future workto evaluate the more complex TR ability of LLMs.\nIn addition, although we have intensively and comprehensively evaluated sixmodels, due to the unavoidable heavy computation costs, we did not run theevaluation on GPT-4 and other LLMs exhaustively. Nevertheless, future work"}, {"title": "8 Conclusion", "content": "In this study, we designed a pipeline for generating and constructing the TRdatasets based on the random graph generation, LTL formula, and the NuSMVmodel checker. Based on the pipeline, we have generated a dataset, LTLBench,consisting of 2,000 TR challenges and taken intensive and comprehensive eval-uations on it with the six selected models in which three are the models withlarge parameter sizes while the other three models are in small parameter sizes.We have demonstrated that although LLMs show promise and emergence inhandling the TR problem, they still struggle with it. We expect our work tooffer insights into the TR ability of LLMs and to provide a valuable tool for TRevaluation while hoping it can pave the way for future more intelligent LLMs orAI systems requiring handling complex TR tasks."}]}