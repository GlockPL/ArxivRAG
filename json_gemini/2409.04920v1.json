{"title": "MoistNet: Machine Vision-based Deep Learning Models\nfor Wood Chip Moisture Content Measurement", "authors": ["Abdur Rahman", "Jason Street", "James Wooten", "Mohammad\nMarufuzzaman", "Veera G. Gude", "Randy Buchanan", "Haifeng Wang"], "abstract": "Quick and reliable measurement of wood chip moisture content is an ev-\nerlasting problem for numerous forest-reliant industries such as biofuel, pulp\nand paper, and bio-refineries. Moisture content is a critical attribute of\nwood chips due to its direct relationship with the final product quality. Con-\nventional techniques for determining moisture content, such as oven-drying,\npossess some drawbacks in terms of their time-consuming nature, potential\nsample damage, and lack of real-time feasibility. Furthermore, alternative\ntechniques, including NIR spectroscopy, electrical capacitance, X-rays, and\nmicrowaves, have demonstrated potential; nevertheless, they are still con-\nstrained by issues related to portability, precision, and the expense of the\nrequired equipment. Hence, there is a need for a moisture content determi-\nnation method that is instant, portable, non-destructive, inexpensive, and\nprecise. This study explores the use of deep learning and machine vision to\npredict moisture content classes from RGB images of wood chips. A large-\nscale image dataset comprising 1,600 RGB images of wood chips has been\ncollected and annotated with ground truth labels, utilizing the results of\nthe oven-drying technique. Two high-performing neural networks, Moist-\nNetLite and MoistNetMax, have been developed leveraging Neural Architec-\nture Search (NAS) and hyperparameter optimization. The developed models\nare evaluated and compared with state-of-the-art deep learning models. Re-\nsults demonstrate that MoistNetLite achieves 87% accuracy with minimal\ncomputational overhead, while MoistNetMax exhibits exceptional precision\nwith a 91% accuracy in wood chip moisture content class prediction. With\nimproved accuracy (9.6% improvement in accuracy by MoistNetMax com-\npared to the best baseline model ResNet152V2) and faster prediction speed\n(MoistNetLite being twice as fast as MobileNet), our proposed MoistNet\nmodels hold great promise for the wood chip processing industry to be effi-\nciently deployed on portable devices, such as smartphones.", "sections": [{"title": "1. Introduction", "content": "Wood chips are crucial raw materials for various industries, including bio-\nfuel, pulp and paper, and bio-refineries. The moisture content (MC) of wood"}, {"title": "2. Materials and Method", "content": "In this section, we present the data acquisition process, the development\nof MoistNet models, a comprehensive list of baseline models, and the evalu-\nation metrics used for performance assessment."}, {"title": "2.1. Wood Chip Dataset Acquisition", "content": null}, {"title": "2.1.1. Chip Sourcing", "content": "Wood chip MC class prediction is an inherently challenging task due to\nthe heterogeneity of the chips. Such heterogeneity could come from differ-\nent perspectives, including plant type, chipping method, source of the chips,\nchip size, and so on. In this study, we collected wood chips from two different\nsources, as shown in Figure 1. While both sources were bio-fuel processing\nplants, the wood chips obtained from each source exhibited significant dif-\nferences. Specifically, the chips from source 1 were gathered from the forest\nenvironment and referred to as inwood chips. On the other hand, the chips\nfrom source 2 were collected from end-cuts of kiln-dried lumber from a lumber\nmill and referred to as lumber chips. For source 2, we collected two distinct\nbatches of lumber chips. It is worth noting that wood chips are typically"}, {"title": "2.1.2. Wood Chip Sample Preparation", "content": "Raw wood chips exhibit a broad range of MC, which can vary depending\non the location within the chip pile. In the center of the pile, the MC can\nsignificantly decrease, reaching as low as 25% (Iwan et al., 2017). Conversely,\nin the upper and outer parts, it can increase to 65-70% compared to the\ninitial MC (Iwan et al., 2017). Since Deep Learning (DL) techniques require\na diverse dataset encompassing various MC ranges, we artificially adjusted\nthe MC of the chips first by completely drying them and then adding a\ncertain amount of water.\nTo ensure that the raw wood chips were completely dry, we utilized an\noven dryer set at 105\u00b0C for 24 hours to remove the existing MC. Subsequently,\na rotating mortar mixer was employed to effectively mix water with the chips.\nThe amount of water to be added was calculated using Equation (1).\n\n$M_{water} = M_{wet} \\times mc \\%$ (1)"}, {"title": "2.1.3. Sample Image Acquisition", "content": "The wood chips were placed in foil trays with dimensions of 29.2 cm \u00d7\n22.9 cm \u00d7 6.4 cm. Each tray contained wood chips weighing between 300-\n550 grams. Figure 3 demonstrates the distribution of weights of wood chips\ntaken in each tray for capturing RGB images. We have carefully designed a\ndata collection station that consists of a closed box (with a door) as shown\nin Figure 4(a). Two ring-shaped white lights were installed at the top of the\nbox as illustrated in Figure 4(b). We used such a closed box to ensure the\nsame lighting condition for each sample. Plankenb\u00fchler et al. (2020) used\ngreen lights for wood chip quality assessment. However, lighting color didn't"}, {"title": "2.1.4. Data Labelling", "content": "For any machine learning-based method of wood chip MC class predic-\ntion, data labeling is the most time-consuming step. The dependence on the\nconventional oven drying process to create ground truth labels is one of the\nmajor bottlenecks. In this study, we also had to rely on the oven-drying\nprocess to get the actual MC values. We measured the weight of the wood\nchip samples along with the tray when the image collection was complete.\nThen the samples were placed in an oven dryer pre-heated to 105\u00b0C for 24\nhours. Finally, we measured the weight again after completion of the drying\noperation and calculated the MC of the samples using the Equation (2).\n\n$mc (%) = \\frac{(m_{wet} - m_{t}) - (M_{dry} - m_{t})}{(M_{wet} - m_{t})} \\times 100$ (2)\n\nwhere, $m_{wet}$, $m_{dry}$, and $m_{t}$ refer to the weight of wood chips before drying,\nthe same after drying, and the weight of the tray, respectively. We planned to\nprepare at least 10 different moisture levels each 5% apart starting from 5%.\nHowever, due to the heterogeneity of the chips and instrumental errors, we"}, {"title": "2.2. Development of MoistNet", "content": "In this work, we employed Neural Architecture Search (NAS) and hyper-\nparameter optimization using two search spaces to automate the development\nof the MoistNet model. NAS is the systematic process of automating the ar-\nchitecture engineering of deep learning models (Elsken et al., 2019). NASNet\n(Zoph et al., 2018) is one such architecture that is optimized on the CIFAR10\n(Krizhevsky et al., 2009) dataset and then applied to the ImageNet (Deng\net al., 2009) dataset to achieve state-of-the-art results. Figure 6 demonstrates\nthe pipeline for MoistNet model development."}, {"title": "2.3. Baseline Models", "content": "We evaluated the performance of our proposed MoistNet models by com-\nparing them with sixteen state-of-the-art deep image classification models.\nThe baseline models were grouped into different categories based on their\narchitectural characteristics:\n1. ResNet (He et al., 2016a,b): ResNet models are known for their deep ar-\nchitecture and residual connections. They include ResNet50, ResNet50V2,\nResNet101, ResNet101V2, ResNet152, and ResNet152V2, which offer\nvarying depths for image classification tasks.\n2. Inception (Szegedy et al., 2016, 2017): Inception models, including\nInceptionV3 and InceptionResNetV2, employ inception modules that\nenable efficient multi-level feature extraction by combining filters of\ndifferent sizes.\n3. MobileNet (Howard et al., 2017): MobileNet is a lightweight deep-\nlearning model designed specifically for mobile and embedded devices.\nIt achieves a good balance between accuracy and computational effi-\nciency.\n4. DenseNet (Huang et al., 2017): DenseNet models, including DenseNet121,\nDenseNet169, and DenseNet201, employ densely connected convolu-\ntional layers, enabling feature reuse and strong gradient flow through-\nout the network.\n5. Xception (Chollet, 2017): Xception is an extension of the Inception ar-\nchitecture that replaces the traditional inception modules with depth-\nwise separable convolutions, enabling more efficient and effective fea-\nture extraction.\n6. EfficientNet (Tan and Le, 2019): EfficientNet models, such as Efficient-\nNetB0, EfficientNetB1, and EfficientNetB2, leverage compound scal-\ning to achieve state-of-the-art performance by balancing model depth,\nwidth, and resolution for efficient and effective feature representation."}, {"title": "2.4. Evaluation Metrics", "content": "We employed a set of evaluation metrics to evaluate the performance\nof the baselines and MoistNet, focusing on classification performance and\ncomputational efficiency. Accuracy, precision, recall, and F1-score have been\nused to measure classification performance. These metrics were calculated\nusing Equations (8) - (11), where TP, TN, FP, and FN represent true positive,\ntrue negative, false positive, and false negative, respectively.\n\n$Accuracy = \\frac{TP+TN}{TP+TN+FP + FN}$ (8)\n\n$Precision = \\frac{\u03a4\u03a1}{TP+FP}$ (9)\n\n$Recall = \\frac{\u03a4\u03a1}{TP+FN}$ (10)\n\n$F1 score = \\frac{2 \\times Precision \\times Recall}{Precision + Recall}$ (11)\n\nOn the contrary, the computational efficiency of the model has been eval-\nuated comprehensively based on several factors, including training time, in-\nference time, and number of parameters in the model. For training time"}, {"title": "3. Experiments and Results", "content": "In this section, we illustrated the experimental setup for NAS, hyper-\nparameter optimization, the training pipeline for the MoistNet model, and\nthe baseline models. We discussed the results from different viewpoints and\nperformed an extensive sensitivity analysis to gain valuable insights into the\nMoistNet models. Finally, we discuss the broader environmental, economic,\nor logistical implications of the proposed deep learning-based MC class pre-\ndiction method for industry applications."}, {"title": "3.1. NAS and Hyperparameter Optimization", "content": "We collected a total of 1600 images of the wood chip samples, including\ntwo sources, with each source contributing 800 images (see Figure 1). Addi-\ntionally, within source 2, there were two batches, with each batch containing\n400 images. To accommodate the data requirements of deep learning models,\nwe adopted a random patch-generation strategy. This involved generating 10\nsmall random patches, each measuring 300 \u00d7 300 pixels, from the original raw\nimage, which had dimensions of 1920 \u00d7 1080 pixels. Figure 7 showcases an ex-\nample of a raw image and the resulting random patches generated. Through"}, {"title": "3.2. Performance of MoistNet and Baselines", "content": "Employing the NAS and hyperparameter optimization, we introduced\ntwo neural networks: MoistNetLite and MoistNetMax. Figure 8 and Figure\n9 illustrate the architectures of the MoistNetLite and MoistNetMax, respec-\ntively. MoistNetLite is a lightweight architecture comprised of an image\ntranslation layer, three consecutive layers of convolution, max pooling, and\ndropout, and a global average pooling layer followed by a dense layer. On the\nother hand, MoistNetMax is a deeper network with ResNet152V2 architec-\nture as the backbone. In the MoistNetMax model, the input layer is followed\nby a random flip layer, the backbone (ResNet152V2), and then a global aver-\nage pooling layer. Both MoistNetLite and MoistNetMax have a classification\nlayer with a softmax activation function at the top. MoistNetLite demon-\nstrated comparable performance with minimal computational overhead (14\ntimes less number of parameters and two times faster inference compared\nto the fastest baseline MobileNet). On the contrary, MoistNetMax exhibits\nexceptional precision at the expense of increased computational complexity.\nMoistNetMax achieved 9.6% additional precision compared to the highest\nperforming baseline ResNet152V2.\nWe trained each baseline along with the MoistNet models for 200 epochs\nwith an early stopping callback to halt the training if no improvement in\nvalidation accuracy was observed for 20 consecutive epochs. We employed\na 4-fold cross-validation strategy to evaluate the performance. The reason\nbehind the value of K = 4 is explained later in Section 3.3.2. Following this\nstrategy, we used three folds for training and the remaining one-fold for test-\ning. The training samples were again divided into 0.8:0.2 proportions to get\nthe training and validation sets. Figure 10 demonstrates the training pipeline\nand data partition strategy. During training, the model that performed the\nbest on the validation set was saved and after the completion of the training,\nthe saved model was used to evaluate the performance on the test set. We\nhave used several data augmentation techniques to increase the robustness\nof the model, including random rotation, translation, zoom, and vertical and\nhorizontal flip.\nWe used a batch size of 16, optimizer Stochastic Gradient Descent (SGD)\n(Bottou, 2010) with a learning rate of 0.0001 and momentum of 0.9. All the\nmodels were trained from scratch by initiating the weight randomly. How-\never, a random seed was selected to make the results reproducible. For the\nbaseline models, we removed the top Imagenet classification head and added\na global average pooling layer along with a fully connected layer and a clas-"}, {"title": "3.3. Sensitivity Analysis", "content": null}, {"title": "3.3.1. Change in Dataset", "content": "Until now all analysis was carried out on the dataset from source 1. How-\never, we obtained wood chips from an alternative source (referred to as \u2018source\n2') in two distinct batches labeled as \u2018batch 1' and \u2018batch 2'. Consequently,\nwe conducted analogous experiments mentioned previously on batch 1, and"}, {"title": "3.3.2. Change in Cross-Validation Setting", "content": "In our study, we implemented a K-fold cross-validation strategy with\nK = 4. It is common practice in machine learning modeling to utilize 5-\nfold or 10-fold cross-validation. However, we specifically chose K = 4 for a\nparticular reason. Our dataset consisted of image data from various classes,\nsuch as wood chips with different MCs, arranged in four trays. To ensure a\ncomprehensive evaluation, we captured 20 images from each tray by shuffling\nthe wood chips before image capture. We aimed to perform a group K-fold\ncross-validation, treating images taken from the same tray as a group. As\nthere were four trays for each class, we set the value of K as 4 for both types\nof cross-validation. To compare the performance of the 18 models, as shown\nin Table C.1 (see Appendix C), between K-fold and Group-K-fold cross-\nvalidation, we conducted a paired t-test on the F1-scores. The purpose was\nto determine if there were any significant differences in performance between\nthe two cross-validation approaches. We formulated the null hypothesis and\nalternate hypothesis as:\nHo: There is no significant difference between the K-fold and Group-K-fold\nresults.\nH\u2081: There is a significant difference between the K-fold and Group-K-fold\nresults.\nWe calculated the value of the test statistic t using Equation 13:\n\n$t = \\frac{\\bar{x}_{diff}}{\\frac{S_{diff}}{\\sqrt{n}}}$ (13)"}, {"title": "3.3.3. Change in Hyperparameters", "content": "To assess the influence of hyperparameters, including batch size, learn-\ning rate, optimizer, and weight initialization, on the performance of Moist-\nNet models, a sensitivity analysis was conducted. To expedite the analysis,\nthe experiments were carried out on a single fold instead of utilizing cross-\nvalidation.\nIn the case of batch size, it was observed that both MoistNet models\ndisplayed sensitivity to this hyperparameter. Figure 14(a) and (d) illustrate\nthat the highest accuracy was achieved when the batch size was set to 16\nfor both models. Notably, for MoistNetLite, a batch size of 4 also yielded\ncomparable results. It is important to mention that we could not explore\nbatch sizes of more than 16 due to computational resource constraints.\nWhile changing the learning rate, we found both models to be sensitive.\nPerformance of the Moist NetLite showed a downward trend with an increase\nin the learning rate except for 0.001, as shown in Figure 14(b). MoistNetLite\nachieved the highest precision at a 0.001 learning rate. However, a learning\nrate of more than 0.001 did not result in convergence. MoistNetMax, on the\nother hand, showed a consistent increase in performance when the learning\nrate was decreased, as shown in 14(e), and achieved the best result with a\nlearning rate of 10-5. We did not try learning rate smaller than 10-5 because\nthe performance started to flatten from 5 \u00d7 10-5 to 10-5.\nOptimizers play one of the most critical roles in deep learning model train-\ning. In this study, we found Adam to be the best-performing optimizer for\nthe MoistNetLite model, as shown in Figure 14 (c). On the other hand, Fig-\nure 14 (f) shows that Adagrad and SGD performed better for MoistNetMax.\nWeight initialization is another important parameter to consider. There are\nseveral ways to initialize the weights of the model, including random initial-"}, {"title": "3.4. Broader Implications of MoistNet", "content": "While the current MC determination method requires hours to provide\nprecise measurements, the proposed image-based MoistNet method gets it\ndone instantaneously. Thus, it is possible to optimize the drying time by\nefficiently assessing the moisture content of incoming woodchips to achieve\nthe desired moisture level. This efficient and precise way of tuning the drying\nprocess ensures that the woodchips are not excessively dried, which not only\nconserves energy but also reduces emissions and unnecessary fuel costs. Ad-\nditionally, the MC of woodchips is critical in pelletizing, affecting the binding\ncharacteristics of the pellets, their durability, and energy content.\nIn addition to the wood pellet industry, the MC of wood chips has a\nhuge impact on the pulp and paper industry. The pulping behavior and the\nenergy requirements for pulping and drying processes are largely dependent\non the MC measurement. Thus, a fast and precise assessment of MC can\nlead to energy savings and increased production efficiency. In other wood\nchip-reliant fuel production facilities, knowing the moisture content allows\nfor better control of combustion processes, reducing emissions of pollutants\nand helping facilities comply with environmental regulations. Essentially,\nthis MoistNet-based approach promotes efficient drying by preventing over-\ndrying, thereby minimizing environmental impact and operational expenses."}, {"title": "4. Conclusions and Future Work", "content": "Moisture content measurement is a crucial and time-consuming task in\nthe wood chip-reliant industries. To overcome the shortcomings of the ex-\nisting methods, we have proposed an image-based solution to the wood chip\nMC class prediction task. First, an extensive image dataset with carefully cu-\nrated labels has been developed. Then we proposed two deep learning model\narchitectures, namely MoistNetLite and MoistNetMax, generated through"}, {"title": "CRediT Author Statement", "content": "Abdur Rahman: Conceptualization, Methodology, Software, Formal\nanalysis, Data Curation, Writing - Original Draft, Visualization. Jason\nStreet: Conceptualization, Data Curation, Writing - Review & Editing,\nFunding acquisition. James Wooten: Conceptualization, Data Curation,\nWriting - Review & Editing, Funding acquisition. Mohammad Maru-\nfuzzaman: Conceptualization, Writing - Review & Editing, Supervision,\nFunding acquisition. Veera G. Gude: Conceptualization, Funding acquisi-\ntion. Randy Buchanan: Conceptualization, Funding acquisition. Haifeng\nWang: Conceptualization, Methodology, Writing - Review & Editing, Fund-\ning acquisition."}, {"title": "Declaration of Competing Interest", "content": "The authors declare that they have no known competing financial inter-\nests or personal relationships that could have appeared to influence the work\nreported in this paper."}, {"title": "Data Availability", "content": "Data will be made available on reasonable request."}]}