{"title": "SAVER: A Toolbox for Sampling-Based, Probabilistic Verification of Neural Networks", "authors": ["Vignesh Sivaramakrishnan", "Krishna C. Kalagarla", "Rosalyn Devonport", "Joshua Pilipovsky", "Panagiotis Tsiotras", "Meeko Oishi"], "abstract": "We present a neural network verification toolbox to 1) assess the probability of satisfaction of a constraint, and 2) synthesize a set expansion factor to achieve the probability of satisfaction. Specifically, the tool box establishes with a user-specified level of confidence whether the output of the neural network for a given input distribution is likely to be contained within a given set. Should the tool determine that the given set cannot satisfy the likelihood constraint, the tool also implements an approach outlined in this paper to alter the constraint set to ensure that the user-defined satisfaction probability is achieved. The toolbox is comprised of sampling-based approaches which exploit the properties of signed distance function to define set containment.", "sections": [{"title": "1 INTRODUCTION", "content": "Neural networks (NN) have shown great promise in myriad domains, often demonstrating performance on part with, or even surpassing, traditional methods. They have even been embedded as elements of safety-critical systems, such as in quadrotor motion planning [1, 2], autonomous driving [3], aircraft collision avoidance [4], and aircraft taxiing [5]. However, the deployment of NNs in safety-critical domains introduces significant challenges, particularly regarding their robustness to input uncertainties and adversarial attacks. These challenges currently represent one of the primary barriers to the broader adoption of NNs in such domains. For instance, in contexts such as malware detection and sparse regression, existing works have shown that adversarial inputs can be crafted with relative ease to exploit vulnerabilities in NNs [6, 7].\nTo address these concerns, the formal verification of NNs has emerged as a critical area of research. Broadly speaking, verification approaches can be categorized into two types: deterministic and probabilistic. Deterministic verification provides binary guarantees that the outputs of a NN satisfy a specific condition for all inputs within a defined set. This type of verification is crucial for worst-case safety guarantees. Several state-of-the-art techniques have been developed in this domain, including mixed-integer linear programming [8-11], satisfiability modulo theories [12, 13], semidefinite programming [14-17], and reachability analysis [18]. These methods typically assume a bounded input uncertainty set, centered around some nominal input.\nOn the other hand, probabilistic verification focuses on assessing the likelihood that a NN satisfies a safety condition under uncertain or random inputs, which may be unbounded. Such uncertainties can arise naturally from environmental noise, signal processing errors, or other exogenous disturbances. Furthermore, adversarial noise, even when imperceptible, can significantly alter NN outputs, particularly in deep networks for tasks like image classification [19, 20].\nProbabilistic verification addresses the key question: Given a random input vector x0 and a neural network f, what is the probability that the output y = f(x) lies within a predefined safety set C? Specifically, we seek to ensure that this probability exceeds a certain user-defined threshold, expressed as\n$P_y(C) \\geq 1 - \\Delta$,\n(1)\nwhere \u0394 \u2208 (0, 1) represents the satisfaction probability.\nA major challenge in probabilistic NN verification is the difficulty of propagating input uncertainty through highly nonlinear mappings. Existing approaches to computing or approximating the chance constraint in (1) can be categorized as either analytical or sampling-based. Analytical methods include the propagation of confidence ellipsoids using approximate networks, f, which reduces the verification problem to a semidefinite program [21], and the use of characteristic functions to propagate input distributions exactly in ReLU networks, drawing on concepts from discrete-time dynamical systems and Fourier transforms [22]. The PROVEN framework [23] approximates the safety probability using linear approximations and concentration inequalities for (sub-)Gaussian inputs with bounded support. Using similar ideas, other methods such as CC-Cert [24] combine Cramer-Chernoff bounds with sample propagation to estimate the safety probability, while more recent approaches use branch-and-bound techniques to simultaneously upper and lower bound the probability of safety [25]. Alternatively, scenario-based approaches compute safety certificates by solving chance-constrained programs based on the number of samples, either by directly lower-bounding the success probability [26] or by determining the largest norm ball Be that is likely to enclose the output [27].\nIn this paper, we present SAVER: SAmpling-based VERification of Neural Nets, a Python toolbox for sampling-based probabilistic verification. We use the Dvoretzky-Kiefer-Wolfowitz Inequality [28] and scenario optimization approach [29], which provide bounds on the number of samples necessary to validate a specification to a desired probability as in (1). To encode the set specifications, we define the sets as SDFs, whose properties allow us to expand the set should the original specification not achieve the satisfaction probability. We apply this approach on a three examples: 1) the containment of feedforward neural network's output, 2) the robustness of an image classifier, and 3) the resulting position of a aircraft with noise added to the neural network."}, {"title": "2 PROBLEM FORMULATION", "content": "Let (\u03a9, \u039c(\u03a9), P) be a probability tuple. The set 2 is the set of all possible outcomes, \u039c(\u03a9) is the set of events, i.e., a \u03c3-algebra, where each event is a set of outcomes, and a function P: \u039c(\u03a9) \u2192 [0, 1] which assigns a probability to each set in the \u03c3-algebra. A random variable is a measurable function, y : \u03a9 \u2192 \u0423. We denote the space of random variables as y \u2208 LP (\u03a9, \u039c(\u03a9), P) =\n{y: \u03a9 \u2192 Y| \u222by|y(w)|P dP(w) < \u221e}. The probability that y will take on a value in S we represent by a probability measure, $P_y (S) = P(y^{\u22121}(S)) = P (\\{\u03c9 \u2208 \u03a9|y(\u03c9) \u2208 S\\})$ for S \u2208 M(Y). We denote a constraint set C\u2208 M(Y) through a measurable signed distance function (SDF) gc: \u0423 \u2192 R,\n$g_C(y) := \\begin{cases}inf_{p \\in C} ||p - y||, y \\in Y\\backslash C, \\\\ -inf_{p \\in Y\\backslash C} ||p - y||, y \\in C.\\end{cases}$\n(2)\nPut simply, the SDF says that the point y \u2208 Y is within the set if its output is negative or zero and positive otherwise. Set operations such as union, intersection, and set difference are readily captured using SDFs. We use SDFs to formulate the two NN verification problems the toolbox solves, stated formally here and depicted graphically in Figure 1.\nPROBLEM 1. Given a neural network, f : X \u2192 Y, a SDF gc: Y\u2192 R, and a probability of satisfaction \u2206 \u2208 (0, 1), determine if\n$P(\\{w: g_C (f(x(w))) \\leq 0\\}) \\geq 1 - \\Delta$,\n(3)\nwhere 1 \u2013 \u0394\u2208 (0, 1) is the probability of satisfaction.\nPROBLEM 2. Given a neural network, f : X \u2192 \u0423, \u0430 SDFgc: \u0423 \u2192 R, and a probability of satisfaction \u2206 \u2208 (0, 1), solve the optimization problem,\n$\\\\underset{\\theta}{\\text{minimize}} \\theta$,\n(4a)\nsubject to $P (\\{w : g_C(f(x(w))) - \\theta \\leq 0\\}) \\geq 1 - \\Delta$. (4b)\nThat is, we find a new set $C^* = \\{y \\in Y : g_C(y) - \\theta^* \\leq 0\\}$, where $\u03b8^*$ is the optimal solution of (4), such that it satisfies (1).\nREMARK 1. Note that both Problem 1 and 2 are focused on probabilistic verify neural networks. However, this formulation is generic, and so f could also represent a dynamical system with a neural network in the loop, or other functions.\nSolving Problem 1 is crucial for determining whether neural network or a system with a neural network in the loop satisfies specifications with a given probability. We use Problem 2 for:\n(1) enlargement: identify how much larger set must be to ensure the satisfaction likelihood 1 - A\n(2) reduction: shrink the set C, in the event that the desired specification can be satisfied with high probability."}, {"title": "3 SAMPLING-BASED VERIFICATION", "content": "To evaluate the expression on the left hand side of the inequality in (3), we rewrite the probability of neural network output residing in the set as a cumulative distribution function (CDF),\n$\\Phi_{g_c (f(x))} (y) = E[1\\{g_c (f(x)) \\leq y\\}],$\n(5)\n$= P(\\{\u03c9 \u2208 \u03a9| g_c (f(x(w))) \\leq y\\}).$\nWe can approximate (5) empirically as,\n$\\hat{\\Phi}_{g_c(f(x))}^N (y) = \\frac{1}{N} \\sum_{i=1}^N I(g_c (f(x_i)) \\leq y),$ (6)"}, {"title": "3.1 Dvoretzky-Kiefer-Wolfowitz Inequality", "content": "One way to determine how many samples are needed to estimate (5) via (6) is via the Dvoretzky-Kiefer-Wolfowitz (DKW) inequality [28], which provides a bound on the difference between the empirical distribution function $\\hat{\\Phi}_{g_c(f(x))}$ and the true CDF $\\Phi_{g_c(f(x))}$. Formally, given N i.i.d. samples, the DKW inequality states that for any error tolerance \u03f5 > 0,\n$P (\\sup_x |\\hat{\\Phi}_{g_c (f(x))} (x) - \\Phi_{g_c (f(x))} (x)| > \\epsilon) \\leq 2e^{-2N\\epsilon^2}$ (7)\nFurther, to determine the number of samples N an obtain an empirical CDF from (6) that is within e to the actual one in (5) with confidence level 1 \u2013 \u03b2, we can rearrange (7) to obtain,\n$N \\geq \\frac{1}{2\\epsilon^2} ln(\\frac{2}{\\beta}).$\n(8)\nTherefore, solving Problem 1 is merely a matter of using (7) to compute the number of samples via a user specified \u03f5, \u03b2\u2208 (0, 1). For Problem 2, we first note that (4) is equivalent to the definition of the quantile function.\nDEFINITION 1. The quantile function Q: [0, 1] \u2192 R is the inverse of the CDF, provided that $\u03a6_{gc(f(x))}(x)$ is continuous and non-decreasing. Formally, for p\u2208 [0, 1], the quantile function is given by\n$Q(p) = inf \\{x \\in R : \\Phi_{g_c(f(x))}(x) \\geq p\\}.$\n(9)\nIn other words, Q(p) returns the value x such that the probability of a random variable being less than or equal to x is at least p.\nWe can even use root-finding, such as the bisection algorithm, to find the smallest \u03f5 such that,\n$\\Phi_{g_c (f(x))} (\\theta^*) = 1 - \\Delta$.\n(10)"}, {"title": "3.2 Scenario Optimization", "content": "Scenario optimization constructs data-driven approximations of solutions for the chance-constrained optimization problem\n$\\underset{\\theta \\in \\Theta^{n_\\theta}}{\\text{minimize}} c^T\\theta$\n(11a)\nsubject to $P (\\{\u03c9 : h(x(\u03c9), \u03b8) \u2264 0\\}) \u2265 1 \u2212 \u0394$, (11b)\nwhere h: Rn \u00d7 Rno \u2192 R is convex with respect to its second argument 0. Instead of directly evaluating the chance constraint, which is generally impractical, the scenario approach approximately enforces the constraint in (11) by utilizing samples of x, yielding the scenario relaxation\n$\\underset{\\theta \\in \\Theta^{n_\\theta}}{\\text{minimize}} c^T\\theta$\n(12a)\nsubject to $h(x^{(i)},\u03b8) \u2264 0$, i = 1, ..., N. (12b)\nAn optimal solution \u03b8* of (12) will not be an optimizer of (11) due to the sampling approximation since the set of optimizers is generally of measure zero; however, the set of feasible solutions, i.e., values of 0 that satisfy the chance constraint while not necessarily minimizing the objective, has positive measure that we can bound. In particular, a sufficient condition that an optimal solution of (12) be a feasible solution of (11) with probability \u2265 1 - \u03b2 is that the number of samples N satisfies the bound\n$N \\geq \\frac{2}{\\Delta} (log \\frac{1}{\\beta} + n_\\theta log \\frac{e}{\\Delta})$. (13)\nwhere \u03b2\u2208 (0, 1) is the confidence parameter, and ne is the number of decision variables. With a user-specified confidence parameter \u03b2 and the number of decision variables ne, we have that the optimal solution 0* results in satisfaction of the chance constraint with probability 1 \u2013 A with confidence 1 \u2013 \u03b2 [29].\nFor the neural network verification problem, we can pose the optimization problem in (4) as follows,\n$\\underset{\\theta \\in R}{\\text{minimize}} \\theta$,\n(14a)\nsubject to $g_C (f(x^{(i)})) - \\theta \\leq 0$, i = 1, ..., N, (14b)\nwhere we can determine the desired number of samples by setting no to 1. Note that, if 0* \u2264 0, then we satisfy the specification, thereby solving Problem 1. Should 0* > 0, then we address Problem 2, where we determine the expansion of the set to ensure 1 \u2013 \u0394 constraint satisfaction.\nNote that the optimization problem in (14) is convex, because the decision variable @ is linear. Further, the optimization problem does not require the convexity of the set specified by the SDF. We can solve the optimization problem by Algorithm 1."}, {"title": "4 TOOLBOX FEATURES", "content": "We can start a sampling-based verification problem by the following functions:\nHere, verify.usingDKW and verify.usingScenario initialize sampling-based verification problem using DKW or scenario optimization respectively. Both functions take Delta corresponding to \u0394, the user-defined satisfaction probability. In the function verify.usingDKW, the input variables betaDKW and epsilonDKW, and Delta correspond to \u03b2 and \u03f5 respectively which appear in (8). In function verify.usingScenario, the input variables betaScenario corresponds to \u03b2 in Section 3.2, the confidence for which the probability of satisfaction is greater than 1 \u2013 \u0394.\nThe toolbox consists of two SDFs: 1) norm-ball and 2) polytopes. We present the norm-ball with an example implementation of a two norm-ball (Figure 3),\n$g_c(p) = ||p-c||_2 - r$.\n(15)\nThe function which implements this in our toolbox is:\nThe function sdfs.norm requires variables center and zeroRadius which correspond to c and r in (15). The function utilizes \"norm=\" variable to define what norm the SDF is, and is a two norm by default. For sake of space, we do not expand on the implementation of the polytope SDF except in subsection 5.2 where we utilize it for image robustness. A SDF is added to the verification task calling the following functions with normSDF as an input argument:\nShould the user desire to change the specification in the verification problem, calling addSpecification from the verification problem with a new input variable for the specification, e.g., newSDF.\nNote that for this toolbox, the samples must come from a user-defined sampling function or simulator. To provide the number of samples to the sampler or simulator, we provide the user with the following functions which output the number of samples:\nWe add samples to verification problem by evaluate the following function with the variable outputSamples:\nShould the user desire to change samples for the verification problem, calling samples from the verification problem with a new input variable of samples, e.g. newOutput Samples.\nTo address Problem 1, we can call the following function for either sampling-based approach:\nShould we not be able probabilistically satisfy the specification, we can solve Problem 2 to determine what how much the set must grow to ensure the satisfaction probability."}, {"title": "5 EXAMPLES", "content": "We present three examples that highlight the usage of our sampling-based verification approach. All experiments were run on a Intel 10900K with 128GB RAM running PopOS 22.04 with Python 3.10.12. The examples in Sections 5.1 and 5.2 utilize PyTorch to conduct evaluations of the neural network and are then converted to NumPy arrays."}, {"title": "5.1 Feedforward Neural Network with ReLU Activations", "content": "We employ our sampling-based verification tool on a simple feedforward neural network with ReLU activation functions similar to [22]. As we show in Figure 4, the network takes in samples from a standardized Cauchy distribution, a distribution with undefined moments, passes through the network which consists 4 inputs, 2 layers, each with 10 neurons, and 2 outputs. The set specification we wish to ensure for a satisfaction probability of 1 \u2013 A = 0.999 is a two norm ball of radius 20,000,\n$C = \\{y \\in R^2: ||y||_2 \\leq 20,000\\}$.\n(16)\nThis results in a SDF,\n$g_c(p) = ||p||_2 - 20,000$.\n(17)\nSince a Cauchy distribution is heavy tailed distribution, we set a conservative estimate of how large the set must be, in hopes of reducing the set.\nWe run both the DKW and scenario-based approaches from our toolbox and present the results in Figure 5, along with the samples. For the DKW approach, we utilize a confidence, 1 \u2013 \u03b2, of 0.999 and an error from the true CDF, e, of 0.001, resulting in requiring 3800452 samples. The scenario approach uses the same confidence as DKW, requiring 12, 510 samples for the verification task. The analysis we conduct with both the DKW and scenario approaches indicate that we do satisfy the specification with 0.999 probability, thereby addressing Problem 1. Nonetheless, to reduce our initial estimate of the set, we solve (4) in Problem 2 with both the DKW and scenario approach which result in $\u03b8^{DKW} = -19232.62$ and $\u03b8^{Scenario} = -3779.28$ respectively. Specifically, the DKW-based approach results in a reduction relative to an empirical CDF with known error relative to the true CDF that holds with a specific confidence. In contrast, the scenario-based approach results in a larger set expansion as it prioritizes probabilistic satisfaction of the specification with user-defined confidence."}, {"title": "5.2 Image Classifier", "content": "We also validated the sampling-based approach by examining the robustness of a Convolutional Neural Network (CNN) classifier trained on a normalized MNIST dataset [34]. Specifically, we evaluated whether the classifier maintains a high probability of correct classification on noisy versions of an originally correctly classified image of the digit 7.\nTo formalize the requirement of correct classification, we define a constraint set C in the logit space y \u2208 R10 of the classifier. Logits are the outputs from the last layer of a neural network before applying the softmax function, representing the raw, unnormalized class scores. The constraint set is a polytope in the logit space which specifies that the classifier's output is '7'. Let y = f(x) denote the logit vector output by the CNN for a normalized input image x, where yi is the logit corresponding to class i. The condition for the correct classification as '7' is ensured by enforcing that the logit for class '7' (denoted as y7) is the highest among all classes. In matrix form, these constraints can be expressed as:\n$C = \\{y \\in R^{10}: Ay \\leq b\\}.$\n(18)\nwhere each row in A includes a +1 for y7, a -1 for a particular yi (where i \u2260 7), and 0 elsewhere, b is a zero vector.\nWe then compute the SDF gc for the polytope C. This function quantifies how far the logit vector y is from the boundary of C, providing a measure of classification stability:"}, {"title": "5.3 TaxiNet", "content": "We validated the sampling-based approach on the TaxiNet benchmark shown in Figure 7. TaxiNet consists of a neural network which predicts heading angle and the cross track position from images from a camera attached on the right wing of a Cessna 208B Grand Caravan taxiing at 5 m/s down runway 04 of Grant County International Airport [35]. The crosstrack and heading angle are fed into a proportional controller,\n$\u03c8 = -0.74p - 0.44\u03b8$,\n(20)\nwhere & is the steering angle of the aircraft. Gaussian noise to each pixel, i.e. w ~ N(0, 50), corrupts the downsampled image that is fed into TaxiNet.\nThe aircraft starts at cross-track position po = 5 meters, heading angle 00 = 10 degrees, and runway down-track position of 322 meters. At 422 meters, wish to validate whether the cross-track position is within 1 meter of the centerline of the runway,\n$C = \\{p \\in R : |p| \\leq 1\\}.$\n(21)\nThe SDF is,\n$g_c(p) = |p| - 1$,\n(22)\nwhere we have taken the one norm deviation from the aircraft's crosstrack position. Figure 8 visually overviews the experiment and specification, (22), in orange. After we solve the root finding problem that attempts to compute the quantile in (9), solving Problem 2 to find (10).\nWe require that the specification in (22) be satisfied to with 1 - A = 0.9 probability. To determine if the specification is satisfied, we specify \u20ac = 0.1 and \u03b2 = 0.001 for (7), resulting in requiring 381 samples for the DKW-based approach. For the scenario approach, we specify a confidence of \u03b2 = 0.001 to (13), requiring 126 samples. We therefore ran the simulator for 381 times over a span of two hours. This resulted in determining that, by Problem 1, we did not satisfy the specification in (22). Thus, we solve Problem 2, to determine a @ that satisfies the probability of satisfaction 1 \u0394. Therefore, we proceed to solve (4) in Problem 2 with the DKW and scenario methods, resulting in $\u03b8^{DKW} = 0.9$ and $\u03b8^{Scenario} = 1.25$, respectively."}, {"title": "6 CONCLUSION", "content": "In this paper, we have presented SAVER, a sampling-based toolbox for probabilistic verification of neural networks. The toolbox provides two approaches to obtain the number of samples necessary to verify whether we satisfy a specification. In addition, the toolbox is also able to modify the set through the usage of SDFs in order to achieve tha satisfaction probability. To show the efficacy of this toolbox, we have presented its usage in three examples with different objectives."}]}