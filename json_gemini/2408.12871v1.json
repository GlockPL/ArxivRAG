{"title": "DeepDelveAI: Identifying AI Related Documents in Large Scale Literature Data", "authors": ["Zhou Xiaochen", "Liang Xingzhou", "Zou Hui", "Lu Yi", "Qu Jingjing"], "abstract": "This paper presents DeepDelveAI, a comprehensive dataset specifically curated to identify AI-related research papers from a large-scale academic literature database. The dataset was created using an advanced Long Short-Term Memory (LSTM) model trained on a binary classification task to distinguish between AI-related and non-AI-related papers. The model was trained and validated on a vast dataset, achieving high accuracy, precision, recall, and F1-score. The resulting DeepDelveAI dataset comprises over 9.4 million AI-related papers published since Dartmouth Conference, from 1956 to 2024, providing a crucial resource for analyzing trends, thematic developments, and the evolution of AI research across various disciplines.", "sections": [{"title": "1. Introduction", "content": "This paper introduces an innovative approach for automatically identifying AI-related literature from a vast database of publications, resulting in the creation of a specialized Al literature dataset, which we have named DeepDelveAI. The core of this approach is the development and training of a Long Short-Term Memory (LSTM) network model to identify research papers in the AI domain from a broad academic paper dataset.\nIdentifying AI-related papers is a meaningful yet challenging task. Artificial intelligence (AI) is revolutionizing various sectors, including healthcare, finance, and transportation, due to its ability to process vast amounts of data and make intelligent decisions. For researchers, policymakers, and industry stakeholders, identifying and analyzing these publications is crucial for understanding the current state and future directions of Al research. Identifying papers in the Al field not only facilitates quantitative analysis of Al research progress and thematic changes but also helps observe the integration of AI with interdisciplinary research and its trends. However, identifying AI-related papers is a challenging objective. The surge in AI applications has led to a significant increase in AI-related documents, yet there is currently no clear categorization of AI papers, nor a sufficiently robust benchmark for defining research within the Al domain.\nOur approach involves constructing and training an LSTM model to identify AI-related research papers from a large corpus. Long Short-Term Memory (LSTM) networks, a type of Recurrent Neural Network (RNN), are designed to capture long-term dependencies in sequential data. LSTM networks can learn complex patterns and relationships within text, making them particularly effective for text classification tasks. Previous research has demonstrated the superiority of LSTM networks in various Natural Language Processing (NLP) applications, including sentiment analysis and text summarization.\nWe started by constructing the training dataset based on assumptions derived from expert evaluations. We hypothesized that papers published at certain academic conferences, such as NeurIPS (formerly NIPS), the International Conference on Learning Representations (ICLR), and the International Conference on Machine Learning (ICML), are all AI-related. Concurrently, we randomly selected papers from topics that are clearly outside the AI domain to form another part of the training data. The LSTM model was trained on this binary-classification dataset. The results showed that the model achieved an accuracy of over 98% on the test set, which are the major conference and journal in the artificial intelligence field. Additionally, we tested the model's predictions on papers published in the journal of other disciplines, finding a 73.6% consistency with human judgment. Finally, we applied this validated model to identify AI-related research across a base of over 92 million papers, identifying over 9.4 million papers that are closely related to the AI field. This achievement not only enhances the efficiency of identifying AI-related literature from large-scale datasets but also provides a valuable resource for subsequent analysis and research on Al research trends and developments."}, {"title": "2. Research Objective", "content": "The primary objective of this research is to develop an automated method for identifying scholarly articles that pertain to artificial intelligence within a large-scale corpus of academic literature. This process involves the preparation of two distinct categories of data: AI-related papers (is_ai) and non-AI papers. These datasets are used to train a machine learning model capable of performing binary classification tasks on the larger dataset. The overarching goal is not only to efficiently and accurately classify vast amounts of academic papers into AI-related and non-AI categories but also to curate a reliable AI research database. This credible database will serve as a foundational resource for future studies, which may involve analyzing trends in AI research emphasis, thematic shifts, and exploring the integration and impact of AI in interdisciplinary research fields."}, {"title": "3. Methodology", "content": "To effectively identify AI-related papers within a large-scale literature database, we designed and implemented a comprehensive workflow (figure 1). This process encompasses key steps such as data preparation, preprocessing, model training, evaluation, and prediction, ensuring accurate extraction of research relevant to the field of artificial intelligence. Below is the flowchart of my research process:"}, {"title": "3.1 Data preparation", "content": "The dataset for model training is extracted from a huge database called ZHICHUANG Dataset [1], consisting of a comprehensive collection of over 92.31 million papers from different countries spanning nearly 120 years, including various features"}, {"title": "3.2 Expert Evaluation Dataset (EED)", "content": "To assess the model's reliability, we perform a model-expert consistency assessment using a collection of nuanced data, which we refer to as the Expert Evaluation Dataset (EED). This dataset comprises 500 articles randomly sampled from a selection of journals detailed in the Appendix 1. The chosen journals are widely recognized for their relevance to the field of artificial intelligence, although not every article they publish pertains to AI."}, {"title": "3.3 Data loading and processing", "content": "To efficiently handle the large dataset, the data is read in chunks of 20,000 rows, allowing for processing without exceeding memory limits. For each chunk, the paper_title, paper_summary, and author_keyword_json columns are converted to string format to ensure consistency. These columns are then concatenated to form a comprehensive text representation for each paper, and the associated annotation is_ai are extracted.\nThe data is split into training and testing sets with an 80/20 ratio for each chunk, ensuring a representative sample for model evaluation. The training texts are vectorized using CountVectorizer, transforming them into a matrix of token counts, with the same transformation applied to the test data. CountVectorizer is a tool provided by the scikit-learn library that converts a collection of text documents to a matrix of token counts. It creates a vocabulary of all tokens in the dataset and assigns a unique integer index to each token. Each document is then represented as a vector, where each element corresponds to the count of a specific token in that document [2].\nThe vectorized data is then converted into PyTorch tensors for compatibility with the LSTM model. The data is loaded into DataLoader objects, a PyTorch utility that manages batching with a batch size of 32 and shuffling during training, optimizing both memory usage and computational efficiency. This structured approach ensures that the model is trained and evaluated on consistent and well-prepared data, facilitating accurate predictions."}, {"title": "3.4 LSTM Network", "content": "The LSTM network in this study is structured to effectively process and classify text data, capturing the intricate patterns and dependencies within the text. The input layer of the network accepts the vectorized text data, transforming the input sequences into a format suitable for processing by subsequent layers.\nAt the core of the model lies the LSTM layer, which is designed to capture long-term dependencies in sequential data. This layer consists of multiple hidden units and layers, enabling the network to learn complex patterns from the data. The LSTM layer processes the input sequences, maintaining the context of the text over time and capturing relevant features for classification.\nTo enhance the training process, a batch normalization layer is applied to the outputs of the LSTM. Batch normalization is a technique that normalizes the activations of the previous layer by scaling and shifting the data, which helps stabilize and accelerate the training process by reducing internal covariate shifts [3]. By maintaining the distribution of the data throughout the network, batch normalization leads to more stable and efficient training, reducing the sensitivity to initialization and allowing for higher learning rates.\nFollowing the LSTM layer, a fully connected layer is employed to map the features extracted by the LSTM to the desired output dimension, which in this case is binary classification. This layer transforms the learned features into the final output, indicating whether a paper is related to \u0391\u0399.\nTo prevent overfitting, a dropout layer is incorporated into the network. Dropout is a regularization technique that randomly sets a fraction of the input units to zero during training, which helps in breaking the co-adaptation of neurons and forces the network to learn more robust features [4]. By effectively reducing the network's reliance on any single neuron, dropout promotes generalization and mitigates overfitting, leading to better performance on unseen data.\nFinally, a ReLU (Rectified Linear Unit) activation function is applied within the network. ReLU is a widely used activation function in deep learning due to its simplicity and effectiveness. It introduces non-linearity into the model by outputting the input directly if it is positive, and zero otherwise, which allows the network to learn complex patterns and relationships within the data [5]. This non-linearity enhances the model's ability to capture intricate features in the text, thereby improving its classification performance.\nThis architecture, combining LSTM with batch normalization, fully connected layers, dropout, and ReLU activation, is designed to leverage the strengths of each component, resulting in a robust and effective model for text classification tasks."}, {"title": "3.5 Training and Evaluation", "content": "The training and evaluation of the LSTM model are conducted through a systematic process to ensure robust performance and reliable results. The model is trained using the Adam optimizer, an adaptive learning rate optimization algorithm designed for efficient and effective training of deep learning models [6]. Adam combines the advantages of two other extensions of stochastic gradient descent, namely AdaGrad and RMSProp, making it particularly suitable for handling large datasets and sparse gradients. By adapting the learning rate individually for each parameter, Adam ensures stable convergence during training. Various configurations of learning rates and weight decay parameters are tested to identify the optimal settings for minimizing the cross-entropy loss.\nData is processed in batches to optimize memory usage and enhance training efficiency. The DataLoader class in PyTorch facilitates the handling of data batching and shuffling, ensuring that each mini-batch is diverse and representative of the overall dataset. This approach helps in stabilizing the training process and improving the generalization capability of the model.\nDuring training, for each batch, the model's predictions are compared against the actual is_ai value using the cross-entropy loss function. This loss function measures the difference between the predicted probability distribution and the true distribution of the annotations. The calculated loss is then backpropagated through the network, allowing the optimizer to update the model parameters. This iterative process of forward and backward passes continues over a predefined number of epochs, gradually reducing the loss and improving the model's accuracy.\nThe evaluation of the model's performance is carried out on the test set after each epoch. Key metrics such as accuracy, precision, recall, and F1-score are computed to assess the effectiveness of the model. These metrics provide a comprehensive evaluation of the model's classification performance, highlighting both its strengths and potential areas for improvement. The evaluation process involves calculating the loss and accuracy on the test data without updating the model parameters, ensuring an unbiased assessment of the model's generalization ability. This rigorous training and evaluation methodology ensures that the LSTM model is well-tuned and capable of accurately classifying AI-related research papers."}, {"title": "4. Results and Discussion", "content": "The LSTM network is configured with an input dimension corresponding to the feature size of the vectorized text data, a hidden dimension of 128 units, and an output dimension for binary classification. The model includes dropout layers set at 0.5 to mitigate overfitting and batch normalization layers to stabilize and accelerate the training process. The ReLU activation function is used to introduce non-linearity, enhancing the model's learning capability.\nThe training process explores different configurations of the Adam optimizer, experimenting with learning rates of 0.001 and 0.0005, and weight decay values of le-4 and 5e-4. Models are trained for 50 epochs with a batch size of 32, ensuring sufficient learning iterations while maintaining computational efficiency. During training, the model's predictions are compared against the actual annotations using the cross-entropy loss function, and the optimizer updates the model parameters to minimize this loss. Data is processed in batches using the DataLoader class in PyTorch, optimizing memory usage and training efficiency."}, {"title": "Model 1: Learning Rate 0.0005, Weight Decay 1e-4", "content": "The training accuracy shows a steady increase, reaching approximately 99.5%, while the test accuracy stabilizes around 98.7%. The training loss decreases sharply initially and then gradually flattens out, while the test loss shows more fluctuation but generally remains stable. This configuration indicates a well-generalized model with high training and test accuracy."}, {"title": "Model 2: Learning Rate 0.0005, Weight Decay 5e-4", "content": "The training accuracy increases steadily, reaching about 99.0%, and the test accuracy stabilizes around 98.6%. The training loss decreases sharply initially and then levels off, while the test loss remains relatively stable with minor fluctuations. The higher weight decay seems to slightly reduce overfitting, as indicated by the closer alignment of training and test accuracy."}, {"title": "Model 3: Learning Rate 0.001, Weight Decay 1e-4", "content": "The training accuracy shows a steady increase, reaching approximately 99.5%, while the test accuracy stabilizes around 98.6%. The training loss decreases rapidly initially and then gradually flattens, with the test loss remaining stable but showing more variability. This configuration indicates strong performance with high accuracy and relatively low loss, suggesting that the lower learning rate helps in fine-tuning the model's parameters effectively."}, {"title": "Model 4: Learning Rate 0.001, Weight Decay 5e-4", "content": "The training accuracy increases steadily, reaching about 98.75%, and the test accuracy stabilizes around 98.6%. The training loss decreases sharply initially and then levels off, with the test loss remaining relatively stable and showing minor fluctuations. The higher weight decay in combination with the higher learning rate appears to result in a slight reduction in overfitting, as indicated by the close alignment of training and test accuracy and loss.\nFrom the analysis of the graphs, it is evident that all four configurations yield high accuracy and low loss, demonstrating the effectiveness of the LSTM model for classifying AI-related research papers. Some differences between the configurations can be noted:\nLearning Rate: The lower learning rate of 0.0005 generally helped in achieving a more stable and gradually improving performance. This suggests that a lower learning rate is beneficial for fine-tuning the model's parameters more effectively, leading to better generalization.\nWeight Decay: Higher weight decay values (5e-4) appear to slightly reduce overfitting, as seen in the closer alignment of training and test accuracies. This indicates that incorporating a higher weight decay can help in regularizing the model and preventing it from fitting too closely to the training data.\nTo further assess the models, accuracy, precision, recall, and F1-score are utilized as evaluation metrics. The performance of the four models, as measured by these metrics,"}, {"title": "5. Expert Judging", "content": "To evaluate the model's performance more rigorously, we employed the Expert judging to assess the model's consistency with the assessments of human experts. We engaged Al specialists and domain experts to categorize the EED articles into AI-related and non-AI-related categories. Simultaneously, our trained Long Short-Term Memory (LSTM) model was used to predict the AI relevance of the EED articles. A comparative analysis was then conducted between the model's predictions and the expert annotations to measure the model's alignment with expert judgment on this set of data, which is characterized by ambiguity.\nIn the expert judgment process, each paper underwent an independent review by three experts. The final annotation for each paper was established based on a majority vote. Specifically, if two out of the three experts deemed a paper to be AI-related, that classification was accepted.\nUpon comparing the model's predictions with the expert-classified results, we found discrepancies in 132 out of the 500 papers, which corresponds to a consistency rate of 73.6%. This notable variance underscores the inherent challenges in automatic classification, even when employing advanced models such as LSTM. It also emphasizes the necessity for ongoing refinement and validation of such models, particularly when they are applied to extensive datasets. The findings indicate that while the LSTM model demonstrates effectiveness, there is scope for enhancing its predictive accuracy to more closely align with expert judgment."}, {"title": "6. Database Introduction: DeepDelveAI", "content": ""}, {"title": "6.1 Overview", "content": "The DeepDelveAI dataset is a refined collection of AI-related academic papers, meticulously curated from the comprehensive Intelligent Innovation database. From the original Intelligent Innovation Dataset, we have filtered and identified 9479846 papers that are specifically related to artificial intelligence, spanning from the years 1956 to 2024. The size of the DeepDelveAI database is approximately 17.08 GB. To ensure efficient and rapid data retrieval, the database is supported by a meticulously indexed structure, with an index size of 1.54 GB."}, {"title": "6.2 Data Composition", "content": "The DeepDelveAl dataset comprises various features, including essential data such as paper titles, abstracts, and author-provided keywords. The LSTM model predicts a binary feature, \"is_ai,\" indicating whether a paper is AI-related (1) or not (0). Detailed information of the database"}, {"title": "6.3 Data Analysis", "content": "The analysis presented in this section spans a historical arc, specifically from 1956 to 2023. The cutoff at 2023 is due to the fact that publication data for the year 2024 has yet to be fully compiled. The year 1956 holds a pivotal place in history. That summer, an iconic conference took place at Dartmouth College in the United States' eastern region, which was a seminal event in the annals of academic progress. It was within the halls of this conference that the term artificial intelligence was first officially articulated, heralding a new era in scientific exploration and technological advancement.\nWe briefly analyzed the annual growth in the number of articles and authors, the changes in document types and over time, and the distribution of the language in which the documents were written."}, {"title": "7. Conclusion", "content": "The LSTM network has proven to be a robust and effective model for classifying AI-related research papers based on their textual content. Its ability to capture long-term dependencies and intricate patterns within the text makes it particularly well-suited for this task. The evaluation metrics\u2014accuracy, precision, recall, and F1-score-demonstrate that the model generalizes well to unseen data, providing reliable classifications of AI-related papers.\nThe primary objective of this research was to develop and validate the DeepDelveAl database, a comprehensive and credible repository of AI-related literature. Through rigorous analysis and classification, we have curated a reliable dataset that serves as a valuable resource for understanding Al research trends and developments. The visualizations of publication types, author contributions, and language distributions offer further insights into the characteristics of the Al research landscape from 1956 to 2023.\nFuture work will focus on leveraging the DeepDelveAI database to uncover deeper research patterns and trends, further contributing to the understanding of AI research evolution. Additionally, exploring other advanced neural network architectures and ensemble methods could further enhance the classification performance and provide even more nuanced insights into the AI research landscape. Ensuring the continued reliability and comprehensiveness of the DeepDelveAI database remains a key priority as we aim to maintain it as a critical resource for the AI research community."}, {"title": "Data and Code Availability", "content": "The processed dataset, DeepDelveAI, is openly accessible on Hugging Face at\nhttps://huggingface.co/datasets/DeepDelve/1956-2024. The raw data used in this\nstudy can be accessed at https://opendatalab.com/Gracie/ZHICHUANGDATA.\nAdditionally, the code, model, and expert judgement that support the main findings of\nthis study are available on https://zenodo.org/records/13352465."}]}