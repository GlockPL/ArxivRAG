{"title": "ROBUST MULTI-BIT TEXT WATERMARK WITH LLM-BASED PARAPHRASERS", "authors": ["Xiaojun Xu", "Jinghan Jia", "Yuanshun Yao", "Yang Liu", "Hang Li"], "abstract": "We propose an imperceptible multi-bit text watermark embedded by paraphrasing with LLMs. We fine-tune a pair of LLM paraphrasers that are designed to behave differently so that their paraphrasing difference reflected in the text semantics can be identified by a trained decoder. To embed our multi-bit watermark, we use two paraphrasers alternatively to encode the pre-defined binary code at the sentence level. Then we use a text classifier as the decoder to decode each bit of the watermark. Through extensive experiments, we show that our watermarks can achieve over 99.99% detection AUC with small (1.1B) text paraphrasers while keeping the semantic information of the original sentence. More importantly, our pipeline is robust under word substitution and sentence paraphrasing perturbations and generalizes well to out-of-distributional data. We also show the stealthiness of our watermark with LLM-based evaluation. We open-source the code: https://github.com/xiaojunxu/multi-bit-text-watermark.", "sections": [{"title": "Introduction", "content": "Text watermark aims to encode some imperceptible signal into a piece of text so that people are able to decode the signal from the text (Liu et al., 2024). It can be useful in various applications such as copyright protection and hidden message communication. With the development of Large Language Models (LLMs), there is also a growing need to track misinformation spread by LLMs using text watermark injected to model outputs (Kirchenbauer et al., 2023).\nWe study the methodology of injecting a multi-bit watermark message into a piece of text by paraphrasing. The watermarked text will keep the semantic meaning of the original text after paraphrasing. Another paired decoder will be used to decode the message from the watermarked text. Unlike lexical-based watermarks which inject watermarks by synonym substitutions, the paraphrasing-based method has a larger action space for watermark injection and also is more robust under perturbations. However, there are also challenges in designing paraphrasing-based watermarks, as it is unclear on how to properly inject imperceptible but detectable watermark signal while keeping the text quality and original semantic meaning.\nIn this work, we propose a paraphrasing-based watermark by simultaneously fine-tuning an LLM-based paraphraser as the encoder and train a LLM-based text classifier as the decoder. The pipeline is shown in Figure 1. In the encoding stage, we will paraphrase the input text conditioned on a user-chosen key to generate the water-marked text. In the decoding stage, we will extract the code from the input text with the decoder and compare with the previously chosen key to see if it is watermarked by the user.\nThe key to produce a high-quality text watermark in our method is to train a good encoder-decoder pair. For the decoder, we can train it with standard classification loss so that it can better classify between \u201cbit-0 texts\" and \"bit-1 texts\". For the encoder, we would like to fine-tune it so that its generated text can be better classified by the decoder. Inspired by (Xu et al., 2024), we show that we can use the decoder as a reward model to evaluate how well the paraphrased text generated by the encoder can be correctly classified. Thus, we can use PPO-based RL techniques to finetune the encoder so that the injected watermark can be better decoded. We adopt a co-training framework so that the encoder and decoder are alternatively updated during the training process.\nThrough experiments, we show that our experiments can achieve a very high watermark detection performance while maintaining the paraphrasing fidelity. We achieve over 95% bit accuracy and over 0.99 detection AUC, both outperforming existing methods significantly. In addition, we can apply a simple repetition-based strategy and improve the detection AUC to over 0.9999. In addition, our method also shows a good robustness under word substitution and sentence paraphrasing perturbations. We also evaluate our methods over out-of-distributional"}, {"title": "Preliminary", "content": ""}, {"title": "Multi-bit Text Watermark", "content": "The goal of the work is to inject a multi-bit watermark message into a piece of text by paraphrasing. Formally speaking, in the watermark injection stage, we are given an original text $x^o$ and a watermark message $M \\in {0,1}^\\ast$. We will inject watermark by generating a new watermarked text with a encoder $x^w = E(x^o, M)$. To extract the watermark, we will use a watermark decoder $M' = D(x^w)$ to decode the injected watermark. We hope that the decoded bits should match the prefix of the designed watermark message, i.e., $M' = M[: len(M')]$. Note that this is a vary-length watermark, where the length of watermark message is dependent on the length of text - the longer the text is, the more information we can encode in the watermarked text. This is contrary to the fix-length text watermark (e.g. (Zhang et al., 2024b)), where the watermark code is a fixed length for any given input text. The length of $M'$ depend on different watermark designs, and we will introduce them in Section 3.1.\nWe have the following requirements on the paraphrased text:\n\u2022 Fidelity: The watermarked text should not change the meaning of the original text. The similarity $sim(x^o, x^w)$ should be high.\n\u2022 Accuracy: The watermark decoder should accurately decode the watermark message. The error rate $|M' - M[: len(M')]|_0$ should be low.\n\u2022 Robustness: The watermark message should still exist after the watermarked text undergoes some per-turbation. Let $M_{pert} = D(pert(x^w))$ denote decoded message from perturbed watermarked text. We hope that the error rate after perturbation $|M_{pert} - M[: len(M_{pert})]|_0$ should be low.\n\u2022 Stealthiness: The watermark should not be easily detected by human eyes. We evaluate it with the criteria that human cannot easily detect the watermarks in the text. Formally speaking, let $M_h = D_{human}(x)$ be the human guess on the watermark code. We hope that $|M_h - M[: len(M)]|_0$ should be high, i.e. human guess on the watermark code has a high error rate."}, {"title": "Background: PPO", "content": "Proximal Policy Optimization (PPO) (Schulman et al., 2017) is a standard way to optimize a language model towards a high reward calculated by some pre-defined reward functions $r(x) \\in R$, where x is the input text (i.e. a"}, {"title": "Methodology", "content": ""}, {"title": "Overview", "content": "We illustrate the high-level pipeline of our watermark in Figure 1. Our core idea is to inject the watermark into a piece of text by paraphrasing the text to include the imperceptible watermark signal, which can be later decoded by a text classifier. To encode a watermark message into a piece of text, we will apply a LLM-based paraphraser conditioned on one watermark bit (0 or 1). The watermark bit is initialized as the first bit of the watermark message, and updated to later bits during the token-by-token generation process. Different segments in the generated text will correspond to different bits in the message code. To decode the watermark message from a piece of watermarked text, we will divide the text into multiple segments, and then apply the LM-based classifier to determine the watermark bit for each segment. The concatenated message is the decoded watermark message.\nText Segmentor Note that both processes require a mechanism to divide a text into segments, so that we can assign one bit to each segment of the text to inject multi-bit watermark code. We use a \"text segmentor\" S to do the segmentation, which will operate in two different modes during encoding and decoding.During encoding, it will take the current generated text and output a boolean value $S(x|mode=E) \\in {0,1}$ to determine whether the next token will belong to a new segment. During decoding, it will take a piece of text x as input and segment it into a list of segments $S(x|mode=D) = [x_1,x_2,...]$. In this work, we choose to do the segmentation on the sentence-level, i.e. every sentence in the text is a segment. We view it as a simple yet robust choice, as word-level injection/deletion will not change the segmentation, and paraphrasing will also keep the sentence order in most cases."}, {"title": "Encoder: LLM-based Paraphraser", "content": "The encoder E aims to paraphrase the input text based on a given watermark code and get $x^w = E(x^o, M)$ based on LLMs. Our design of the encoder is to have two LLM-based paraphrasers $(\\theta_0, \\theta_1)$ and use them alternatively in the token-by-token generation process, which is based on the current watermark code determined by the sentence segmentor. Formally speaking, let $x^w = f(x^o, x_t; \\theta_i)$ denote the process of generating the next token when paraphrasing the input $x^o$ parametrized by $\\theta_i$. The encoding algorithm is shown in Alg. 1. We track the current watermark bit, and the next token is generated with the corresponding paraphraser $\\theta_{bit}$. After each generation step, we check whether the next token will be in a new segment by calculating $S(x^t; mode=E)$. If the new segment starts, we will update bit to be the next bit in the watermark message."}, {"title": "Decoder: LLM-based Text Classifier", "content": "The decoder D will decode the watermark code from a piece of text and get $M' = D(x^w) \\in {0,1}^\\ast$. We use $g(x; \\theta_d) \\in {0,1}$ to denote a binary classifier on a text with parameters $\\theta_d$, and use $g_p(x; \\theta_d) \\in (0, 1)$ to denote the predicted probability of class-1. The decoding algorithm is shown in Alg. 2. We will segment the input text into multiple segments $S(x; mode=D)$, then apply the classifier to each segment to calculate the decoded watermark."}, {"title": "Co-training Framework", "content": "The training framework is inspired by (Xu et al., 2024), which shows that the text classifier can be viewed as a \"reward model\" to finetune LLMs with PPO, and that the text classifier and the LLM can be trained alternatively. In our work, we will alternate between two goals: optimizing the decoder ($\\theta_d$) and optimizing the paraphrasers"}, {"title": "Experiments", "content": ""}, {"title": "Setting", "content": "Model and Training Settings We use a relatively small TinyLlama-1.1b model architecture (Zhang et al., 2024a) for $\\theta_0$, $\\theta_1$ and $\\theta_d$, as we observe that small models can already achieve a good performance in paraphras-ing and watermarking. We show the experiments with larger Llama-2-7b models in Appendix C. The detailed prompt used by the pararphrasers are shown in Figure 3 in Appendix A. The encoder and decoder are trained and evaluated on the C4 RealNewsLike dataset (Raffel et al., 2020), processed using standard settings in (Kirchen-bauer et al., 2023; Xu et al., 2024; Lau et al., 2024). Without specification, we will use texts with 128 tokens for training and evaluation. We fine-tune the model for 10,000 steps with batch size of 4. We use $\\lambda_w = 0.1$, $\\lambda_s = 1.0$ and $\\lambda_{KL} = 0.02$ as the coefficients. In the initialization stage, we will generate the paraphrased data $x_{para}^{SFT}$ with Pegasus paraphraser (Zhang et al., 2020), and use $\\lambda_{JS} = 1.0$ for the intialization loss.\nMetric We evaluate three types of metrics of a text watermark. The first type is the bit-wise accuracy, which evaluates how good the multi-bit watermark code is extracted. This includes the bit-wise accuracy (Bit Acc) of the decoded watermark and the number of total bits injected in the text (Bit Num). The second type is the text-wise accuracy, which evaluates how well we can tell the watermarked text apart from other non-watermarked text. We will evaluate the decoder on both watermarked and non-watermarked texts, and calculate the area under ROC curve (AUC) and true positive rate under 1%, 0.01% false positve (TPR@FPR=1%, TPR@FPR=0.01%). For the fidelity, we calculate the similarity with the all-mpnet-base-v2\u00b9 model following the setting in (Lau et al., 2024).\nBaselines We evaluate various baseline methods with different design ideas:\n\u2022 RemarkLLM (Zhang et al., 2024b). The idea is to use a fixed-length multi-bit watermark key and train a Transformer-based paraphraser with a watermark detector. The paraphraser is trained with Gumbel reparametrization techniques to minimize the decoding error. We use the T5-based paraphraser in their original setting and evaluate both the 4-bit version and 8-bit version of the watermarking model.\n\u2022 KGW (Kirchenbauer et al., 2023) and KTH (Kuditipudi et al., 2023). They are LLM-based watermarks aiming to inject watermark to LLM-generated texts by altering the token sampling strategy during the generation stage of a LLM. Note that their methods are not directly comparable with ours, as they are not designed to watermark non-LLM-generated text. For comparison, we adapt them to watermark any"}, {"title": "Performance", "content": "We show the watermark performance in Table 1. We can observe that our method achieves a better performance than existing methods on both bit-wise accuracy and text-wise accuracy. Our method also has high information density, with approximately one bit per 23 tokens (128/5.57). In addition, we also observe a higher similarity score compared to baseline methods. This might be surprising at first glance. We owe it to the reason that we add a similarity reward during the PPO process, so that the model is fine-tuned to achieve a good paraphrasing performance.\nMultiple run In paraphrasing-based watermark, we can run the paraphraser multiple times and return the result with best watermark detection rate. This method is adopted in previous methods (Zhang et al., 2024b; Lau et al., 2024). In this section, we evaluate how different methods improve with multiple runs of the paraphraser. The results are shown in Figure 2. We can observe that our methods can scale to over 0.99 bit accuracy and 0.9999 detection AUC with five repeats of the paraphraser. Since we use a 1.1B small model which can be run in parallel efficiently, we view it as a good tradeoff to repeat five times and achieve a better watermark performance. Other methods also get a performance boost with more repeats, but there is still a clear performance gap.\nExample and Analysis on Stealthiness We show several examples of the watermarked text and their original version in Table 5 in Appendix B. The sentences of class 0 and class 1 are marked with blue and green respectively. All the sentences are correctly classified by the decoder. From our observation, it is difficult to tell a significant difference between the two classes of sentences, confirming the stealthiness of our watermark.\nTo further validate the stealthiness of our watermark, we prompt GPT with in-context learning to see if it can tell the difference between the two classes of sentences. Specifically, we provide GPT with ten class-0 and ten class-1 sentences, and ask it to classify which class a new sentence belongs to. The detailed prompt is shown in Figure 4 in Appendix A. We evaluate 1,000 class-0 and 1,000 class-1 sentences, and the accuracy is 57.0%, which is close"}, {"title": "Robustness", "content": "In this section, we study the robustness of our watermark. The evaluation pipeline follows the standard protocal we first generate a watermarked text, then modify the text with text-level perturbations, and finally test whether we can still detect the watermark in the text. We will evaluate word substitution and sentence paraphrasing, which are two most popular perturbations on texts. In addition to our benign-trained model, we also evaluate the adversarially trained model (denoted as Ours-AdvT), which has the knowledge of perturbation during training and will use the perturbed text when training the decoder.\nWord Substitution For paraphrasing attack, we will randomly substitute {5%, 10%, 20%} tokens in the text with another randomly chosen token (uniformly sampled from the vocabulary). We show the results in Table 2. The adversarial training model uses 10% of word substitution during the training process. We can observe that our original model can already outperform all the baselines when perturbed with word substitutions. With the knowledge of perturbation during the training process, we can further improve the performance and achieve over 0.99 detection AUC even when 10% of the tokens are randomly substituted.\nSentence Paraphrasing For sentence paraphrasing, we consider three types. Following Lau et al. (2024), we will translate the sentence to Spanish and then back to English with a Llama2-7B model, denoted as \"Translate\". We will also directly prompt a Llama2-7B model to paraphrase the sentence, denoted as \u201cLlamaPara\u201d. The detailed prompts used to do the translation and paraphrasing are shown in Figure 5 and 6 in Appendix A. In addition, following (Xu et al., 2024), we also paraphrase the sentence with the Pegasus (Zhang et al., 2020) paraphraser, denoted as \u201cPegasusPara\"."}, {"title": "OOD", "content": "As our pipeline relies on a data-driven training process, we would like to evaluate how it performs on potential out-of-distribution data. In this section, we will evaluate our model, previously trained on the C4 dataset, on various other datasets, including Anthropic HH-RLHF (HH) (Bai et al., 2022), Synthetic instruction\u00b2(Instruct), PKU SafeRLHF (PKU) (Ji et al., 2024), Reward\u00b3, UltraFeedback(UltraF) (Cui et al., 2024), FineWeb (Penedo et al., 2024) and Pile uncopyrighted(Pile)4 datasets. Among the datasets, HH, Instruct, PKU, Reward and UltraF are QA datasets for alignment and we use their answers as the original texts. FineWeb is a dataset consisting of articles from the Internet. Pile is a dataset consisting of cleaned texts from different sources.\nThe performance of our model is shown in Table 4. We can observe that our model can generally achieve a good performance on different datasets, indicating its good generalization capability. We do observe a relatively weak performance on the Pile task, which we view as a result of the frequent structural texts (e.g. XML languages) in the dataset. Nevertheless, we emphasize that we can always include a new data domain in the training process, so that they become \u201cin-domain\" and can achieve a higher performance."}, {"title": "Related Works", "content": "Text Watermarks People have been studying text watermarks for a long time in order to protect copyrights (Liu et al., 2024). Early works on text watermarks focus on synonym substitution or other direct changes in the text. (Topkara et al., 2006) proposes to add watermarks to a text by replacing the most ambiguous words with synonyms"}, {"title": "Discussion", "content": "Watermark Bit Rate Unlike some existing methods like remarkLLM (Zhang et al., 2024b), we cannot manu-ally set the number of watermark bits injected to the text. Instead, the watermark length will be dependent on the text length, i.e. the longer the text is, the more information we will be able to inject. However, we view it possible to adjust the bit rate of our watermark with different approaches. First, we may add a length penalty term in the SFT or PPO process, so that the parpahrasers tend to generate longer/shorter sentences. Second, instead of our current design with two paraphrasers and a binary classification decoder, we can also use K paraphrasers and a K-way classification. By doing so, each bit becomes K-ary and thus carries more information.\nChoice of Text Segmentor Throughout the work, we use a sentence-level segmentor to divide text into dif-ferment segments. This is a simple yet effective choice, as it is generally robust under word substitution or parapharsing. However, it may be exploited by some adversary to decrease our model performance by, for exam-ple, merging or splitting sentences in the text. Potential directions to improve the segmentor include segmenting the text with more dedicated rules or with ML-based models on the semantic level, which we leave as future work.\nControlling the Style of Watermark As we use a data-driven method to train the paraphrasers for watermark-ing, we cannot explicitly choose the style of the watermark. Nevertheless, we may implicitly control the style by choosing appropriate data during the initialization process. For example, if we hope that the paraphraser only does synonym substitution, we can perform the initialization step by doing SFT on synonym-based paraphrasing data. The learned pattern will be inherited in the final paraphrasers given the KL constraint in Eqn. 5."}, {"title": "Conclusion", "content": "In this work, we propose a multi-bit text watermark by paraphrasing a piece of text to inject watermark signals. We show that our pipeline achieves very high detection accuracy with good fidelity and stealthiness. In addition, our method is robust under different attacks. Our method sheds new light on the study of text watermarks."}, {"title": "Prompts Used in the Experiments", "content": "We show the detailed prompts used in the experiments as below:\n\u2022 Figure 3: prompt used in the encoder.\n\u2022 Figure 4: prompt used to do in-context classification with GPT.\n\u2022 Figure 5: prompt used to translate a text with Llama-2-7B.\n\u2022 Figure 6: prompt used to paraphrase a text with Llama-2-7B.\nWe did not make special efforts to optimize these prompts."}, {"title": "Examples of Watermarked Texts", "content": "We show the watermarked texts generated by our pipeline in Table 5. Blue and green texts correspond to class-0 and class-1 texts respectively. We view it difficult to tell a difference between the two classes of texts from human eyes."}, {"title": "Experiments on Llama-2-7B Models", "content": "We show the results of using Llama-2-7B model as the paraphraser in Table 6. Note that the RemarkLLM method does not support Llama models, so we do not evaluate the method; the Waterfall method on 7B models can support a larger k, so we included results of \u043a = 1,2, 4 in the table. We can observe that our model keeps a high performance with the 7B models. We do not see an improvement compared with the 1.1B models, which we guess is because that fine-tuned 1.1B models already have the capability to paraphrase texts, so that a larger model may not help. On the other hand, baseline methods can have a better fidelity with the larger model. The Waterfall methods are able to use larger K to inject strong watermarks, and the strongest \u043a = 4 case can achieve a comparable performance with our model, though there would be a drop on the fidelity."}]}