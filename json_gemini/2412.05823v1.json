{"title": "DapperFL: Domain Adaptive Federated Learning with Model Fusion Pruning for Edge Devices", "authors": ["Yongzhe Jia", "Xuyun Zhang", "Hongsheng Hu", "Kim-Kwang Raymond Choo", "Lianyong Qi", "Xiaolong Xu", "Amin Beheshti", "Wanchun Dou"], "abstract": "Federated learning (FL) has emerged as a prominent machine learning paradigm in edge computing environments, enabling edge devices to collaboratively optimize a global model without sharing their private data. However, existing FL frameworks suffer from efficacy deterioration due to the system heterogeneity inherent in edge computing, especially in the presence of domain shifts across local data. In this paper, we propose a heterogeneous FL framework DapperFL, to enhance model performance across multiple domains. In DapperFL, we introduce a dedicated Model Fusion Pruning (MFP) module to produce personalized compact local models for clients to address the system heterogeneity challenges. The MFP module prunes local models with fused knowledge obtained from both local and remaining domains, ensuring robustness to domain shifts. Additionally, we design a Domain Adaptive Regularization (DAR) module to further improve the overall performance of DapperFL. The DAR module employs regularization generated by the pruned model, aiming to learn robust representations across domains. Furthermore, we introduce a specific aggregation algorithm for aggregating heterogeneous local models with tailored architectures and weights. We implement DapperFL on a real-world FL platform with heterogeneous clients. Experimental results on benchmark datasets with multiple domains demonstrate that DapperFL outperforms several state-of-the-art FL frameworks by up to 2.28%, while significantly achieving model volume reductions ranging from 20% to 80%. Our code is available at: https://github.com/jyzgh/DapperFL.", "sections": [{"title": "1 Introduction", "content": "Federated Learning (FL), an emerging distributed machine learning paradigm in edge computing environments [1, 2], enables participant devices (i.e., clients) to optimize their local models while a central server aggregates these local models into a global model [3]. In contrast to traditional centralized machine learning paradigms, FL facilitates the collaborative training of a global model by distributed clients without the need for transmitting raw local data, thus mitigating privacy concerns associated with data transmission [2]."}, {"title": "2 Related Work", "content": "Heterogeneous Federated Learning. In heterogeneous FL, diverse system capabilities and data distributions across clients often result in performance degradation of the global model [18\u201320]. Extensive studies have made efforts to address these heterogeneity issues through various solutions. For example, studies in [10, 21, 22, 11, 23, 12] adopt model sparsification techniques to reduce the volume of local models, thereby involving low-capability clients in the FL process. The studies in [17, 24, 25] leverage dedicated objective functions and specialized training steps to address the data heterogeneity issue, with studies in [17, 25] allowing clients to conduct varying numbers of local updates and consequently alleviating system heterogeneity issue. Several studies [5, 26, 27] selectively optimize or transmit a fraction of the local model's parameters to reduce computational or communication resource consumption. Studies in [28-30] split the model into several sub-models and offload a subset of sub-models to the server for updating, therefore alleviating the training burden of clients. However, these heterogeneous FL frameworks commonly assume the data heterogeneity (i.e., non-IID data) exclusively involves distribution shifts in the number of samples and/or labels, while neglecting the existence of domain shifts.\nDomain Generalization (DG). DG is originally proposed in centralized machine learning paradigms to address the problem of domain shifts. Existing centralized studies assume access to the entire dataset during the model training process and propose various solutions to achieve DG [31]. For example, the studies in [32\u201334] focus on learning domain-invariant representations that can be generalized to unseen domains. In contrast to learning domain-invariant representations, several studies (e.g., [35\u201338]) train a generalizable model across multiple domains leveraging meta-learning or transfer learning techniques. Additionally, there are studies (e.g., [39, 40, 13]) that focus on the characteristics of domains, enhancing the generality of the model by properly augmenting the style of domain or instance. Unfortunately, the fundamental assumption of centralized machine learning is not satisfied in FL, where the dataset is distributed among clients who are restricted from sharing their data. Despite a few recent studies exploring DG approaches in FL [41, 14, 15, 9] through representation learning, prototype learning, and/or contrastive learning techniques, they typically neglect the inherent system heterogeneity feature of FL. Consequently, these approaches have shown limited effectiveness in heterogeneous FL due to strict resource constraints. In contrast, we explored a distributed model pruning approach that leverages both the local domain knowledge and the global knowledge from all clients, thereby reducing resource consumption in heterogeneous FL with the presence of domain shifts. Additionally, we design a specific regularization technique for updating the pruned local models, thereby further enhancing model performance across domains."}, {"title": "3 DapperFL Design", "content": "DapperFL comprises two key modules, namely Model Fusion Pruning (MFP) and Domain Adaptive Regularization (DAR). The MFP module is designed to compress the local model while concurrently addressing domain shift problems, and the DAR module employs regularization generated by the compressed model to further mitigate domain shift problems and hence improve the overall per-"}, {"title": "3.2 Model Fusion Pruning on Edge Devices", "content": "In this subsection, we present the design of the MFP module employed by DapperFL. The goal of the MFP module is to tailor the footprint of the local model for edge devices in the presence of domain shifts in the local data, thereby addressing the system heterogeneity problem. Inspired by the spirit of the transfer learning [42\u201344], MFP fuses the global model $W^{t-1}$ into the fine-tuned local model $w$ to learn the cross-domain knowledge. This avoids over-fitting the model to the local domain while enhancing the generality of the model. After that, MFP calculates a binary mask matrix $M$ to generate the pruned local model. The detailed pruning process is described in Algorithm 1.\nSpecifically, in the initial epoch of each communication round $t \\in [1,T]$, the MFP module first fine-tunes the global model $W^{t-1}$ on local data $D_{i}$ to produce local model $w$ (in line 1). We utilize one epoch of local training to determine the pruned models for the following reasons: 1) Additional local epochs do not significantly enhance the model's performance, which justifies the use of a single epoch for efficiency. As noted in [45], experiments have demonstrated that extending local training beyond one epoch yields results comparable to those achieved with just one epoch. 2) In previous domain generalization-related FL research, such as [45], one epoch is also employed to collect local domain information. This method has proven adequate for capturing essential features and domain characteristics. 3) Pioneering research in model design and neural architecture search, such as [46],"}, {"title": "3.3 Domain Adaptive Regularization", "content": "In FL, each client $i \\in C$ possess private local data $D_{i} = \\{x_{i}, y_{i}\\}_{N_{i}}$, where $x \\in X$ denotes the input, $y \\in Y$ denotes the corresponding label, and $N_{i}$ represents the local data sample size. The data distribution $p_{i}(x, y)$ of client $i$ typically varies from that of other clients, i.e., $p_{i}(x) \\neq p_{j}(x), p_{i}(x|y) \\neq p_{j}(x|y)$, leading to the domain shifts problem. Due to the existence of domain shifts, representation $z_{i}$ generated by the local encoder varies among different clients, resulting in degraded prediction results of the local predictor. To address the domain shifts problem, we design a DAR module to enhance the performance of DapperFL across multiple domains while maintaining compatibility with the MFP module.\nSpecifically, the DAR module introduces a regularization term to the local objective to alleviate the bias of representations $z_{i}$ on different clients adaptively. To achieve this goal, we first segment each pruned local model $w \\odot M$ into two parts, i.e., an encoder $w_{e} \\odot M_{e}$ and a predictor $w_{p} \\odot M_{p}$, where"}, {"title": "3.4 Heterogeneous Model Aggregation", "content": "Despite the MFP module and the DAR module being capable of alleviating domain shift issues, the heterogeneous local models generated by the MFP module cannot be aggregated directly using popular aggregation algorithms. Therefore, we propose a specific FL aggregation algorithm for DapperFL to effectively aggregate these heterogeneous local models.\nTo preserve specific domain knowledge while transferring global knowledge to the local model, the central server first recovers the structure of local models before aggregating. Specifically, in each communication round $t$, the pruned local model is recovered as follows:\n$w_{i}^{t}= w \\odot M + W^{t-1} \\odot \\bar{M}$"}, {"title": "4 Experimental Evaluation", "content": "Implementation Details. We implement DapperFL with a real-world FL platform FedML [49] with deep learning tool PyTorch [50]. We build the FL environment with a client set $C$ containing 10 heterogeneous edge devices and a central server on the FedML platform. Following a convention setting [5, 25, 51], we categorize these heterogeneous devices into 5 levels according to their system capabilities, i.e., $C_{i} \\in C (l \\in [1, 5])$, where $C_{l}$ represents device set belongs to level $l$. The system capabilities of devices in set $C_{l}$ decrease as level $l$ increases. Our experiments are conducted on a GPU server with 2 NVIDIA RTX 3080Ti GPUs. Each experiment is executed three times with three fixed random seeds to calculate average metrics and ensure the reproducibility of our results.\nDatasets and Data Partition. We evaluate DapperFL on two domain generalization benchmarks, Digits [52-55] and Office Caltech [56] that are commonly used in the literature for domain generalization. The Digits consists of the following four domains: MNIST, USPS, SVHN, and SYN. The Office Caltech consists of the following four domains: Caltech, Amazon, Webcam, and DSLR. For each benchmark, we distribute the simulated 10 clients randomly to each domain while guaranteeing that each domain contains at least one client and that each client only belongs to one domain. To generate non-IID local data, we randomly extract a proportion of data from the corresponding domain as the statistical characteristics vary among domains. Following the conventional data partition setting [15], we set 1% as the local data proportion of Digits and 20% as that in Office Caltech based on the complexity and scale of the benchmarks.\nModels. We adopt ResNet10 and ResNet18 [57] as the backbone models for Digits and Office Caltech, respectively. In the following evaluations, both the DapperFL and comparison frameworks train the models from scratch for a fair comparison.\nComparison Frameworks. We compare DapperFL with 8 state-of-the-art (SOTA) FL frameworks, including FedAvg [3], MOON [16], FedSR [14], FPL [15], FedDrop [10], FedProx [17], FedMP [11],"}, {"title": "4.2 Performance Comparison", "content": "Model Performance Across Domains. Tables 1 and 2 respectively provide detailed analyses of model accuracy on the Digits and Office Caltech benchmarks. The term \u201cSystem Heter.\u201d indicates whether the respective framework supports system heterogeneity.\u201d The results are reported as model accuracy with corresponding standard deviations in brackets.\nAs shown in both Tables 1 and 2, DapperFL achieves the highest global accuracy on both the Digits and Office Caltech benchmarks compared with the comparison frameworks. On Digits and Office Caltech, DapperFL's global accuracy is 0.13% and 2.28% better than the runner-up, respectively. This indicates that the global model learned by DapperFL is more robust across all domains and therefore possesses better domain generalization. Moreover, DapperFL always achieves competing accuracy on individual domains and even the best domain accuracy on the SYN, Amazon, and DSLR. This demonstrates that the DAR module of DapperFL implicitly encourages the encoder to learn domain-invariant representations, resulting in DapperFL being unlikely to over-fit on the specific"}, {"title": "4.3 Ablation Study", "content": "Effect of Key Modules in DapperFL. We evaluate the performance of DapperFL with and without the MFP and DAR modules, individually and in combination. The following configurations are considered: \"DapperFL w/o MFP+DAR\", DapperFL without the MFP and DAR modules. \"DapperFL w/o DAR\", DapperFL without the DAR module. \"DapperFL w/o MFP\", DapperFL without the MFP module. \"DapperFL\", the complete DapperFL framework. It is noteworthy that when the MFP module is not employed in DapperFL, it performs model pruning using $l_{1}$ norm on the local models directly."}, {"title": "4.4 Experimental Setup", "content": "We run DapperFL on the Office Caltech benchmark 40 times, adopting a distinct e of less than 0.2 each time. The values are selected using the Bayesian search. The results are presented in Fig. 7.\nAs illustrated, the Bayesian search-based automatic selection mechanism indicates that model accuracy is likely to reach a higher level when e approaches 0.2, aligning with our default setting of \u20ac = 0.2. It is noteworthy that, owing to the nature of Bayesian search, the sampled e values are not uniformly distributed, as they tend to bias towards the optimal e that maximizes model accuracy."}, {"title": "5 Conclusion", "content": "We have described our proposed FL framework DapperFL tailored for heterogeneous edge devices with the presence of domain shifts. Specifically, DapperFL integrates a dedicated MFP module and a DAR module to achieve domain generalization adaptively in heterogeneous FL. The MFP module addresses system heterogeneity challenges by shrinking the footprint of local models through personalized pruning decisions determined by both local and remaining domain knowledge. This effectively mitigates limitations associated with system heterogeneity. Meanwhile, the DAR module introduces a specialized regularization technique to implicitly encourage the pruned local models to learn robust local representations, thereby enhancing DapperFL's overall performance. Furthermore, we designed a specific aggregation algorithm for DapperFL to aggregate heterogeneous models produced by the MFP module, aiming to realize a robust global model across multiple domains. The evaluation of DapperFL's implementation on a real-world FL platform demonstrated that it outperforms several SOTA FL frameworks on two benchmark datasets comprising various domains.\nLimitations and Future Work. Despite its potential in addressing system heterogeneity and domain shifts, DapperFL introduces four hyper-parameters X0, Amin, e, and y associated with the DG performance of the global model. A potential future direction involves the automatic selection of these hyper-parameters, therefore enhancing the flexibility and accessibility of the DapperFL."}]}