{"title": "Intent-Enhanced Data Augmentation for Sequential Recommendation", "authors": ["Shuai Chen", "Zhoujun Li"], "abstract": "The research on intent-enhanced sequential recommendation algorithms focuses on how to better mine dynamic user intent based on user behavior data for sequential recommendation tasks. Various data augmentation methods are widely applied in current sequential recommendation algorithms, effectively enhancing the ability to capture user intent. However, these widely used data augmentation methods often rely on a large amount of random sampling, which can introduce excessive noise into the training data, blur user intent, and thus negatively affect recommendation performance. Additionally, these methods have limited approaches to utilizing augmented data, failing to fully leverage the augmented samples. We propose an intent-enhanced data augmentation method for sequential recommendation (IESRec), which constructs positive and negative samples based on user behavior sequences through intent-segment insertion. On one hand, the generated positive samples are mixed with the original training data, and they are trained together to improve recommendation performance. On the other hand, the generated positive and negative samples are used to build a contrastive loss function, enhancing recommendation performance through self-supervised training. Finally, the main recommendation task is jointly trained with the contrastive learning loss minimization task. Experiments on three real-world datasets validate the effectiveness of our IESRec model.", "sections": [{"title": "Introduction", "content": "The recommendation system, as a crucial tool for information filtering, has developed over several decades. From early content-based recommendations to today's sequential recommendations, recommendation systems have undergone multiple technological transformations and methodological innovations. The concept of recommendation systems can be traced back to the early 1990s, when recommendation methods were predominantly content-based. This approach recommends items with similar characteristics by analyzing users' preferences for the content features of items (such as text, images, etc.). For example, Lang [Lan95] proposed a content-based news recommendation system in his study, which utilized users' preferences for news articles to recommend new content. This method leverages text analysis and feature extraction techniques to capture user interests and provide relevant recommendations, thereby enhancing user satisfaction and engagement.\nIn the mid-1990s, Collaborative Filtering (CF) methods gradually emerged and became the mainstream in recommendation system research. Collaborative filtering techniques recommend items by analyzing the similarities between users or between items. These methods are mainly divided into user-based collaborative filtering (User-Based CF) and item-based collaborative filtering (Item-Based CF). User-based CF identifies users similar to the target user and recommends items based on the preferences of those similar users, while item-based CF finds items similar to the target item and recommends those items to the user. Resnick et al.'s study [RIS+94] was one of the early representatives of collaborative filtering, where they proposed the GroupLens system, which utilized users' historical rating data for recommendations. This approach constructs a user-item rating matrix and analyzes the similarity between users' ratings to make recommendations.\nEntering the 21st century, with the enhancement of computational power and the accumulation of large-scale data, matrix factorization (MF) techniques gained widespread attention in recommendation systems. Matrix factorization decomposes the user-item rating matrix into two low-dimensional"}, {"title": "Methodology", "content": "In this section, we first introduce the task definition of sequential recommendation, followed by the construction of our IESRec model, and finally, we explain how the model performs joint training and prediction."}, {"title": "Task Definition", "content": "This chapter focuses on the sequential recommendation task, defined as follows: Given a user-item interaction graph G = (V,E), where V represents the set of all nodes, and E represents the set of all edges. The set of user and item nodes in Vare denoted as U and I, respectively. Each user u \u2208 U has a chronologically ordered sequence of interacted items Iu = [i,..., it, ..., iu], where |Iu| represents the number of item nodes interacted with by user u, and it \u2208 I indicates the item interacted with by user u at time t. For each user u, the task of sequential recommendation is to predict the list of items that the user u is most likely to interact with at the next time point based on the historical interaction sequence Iu. The top k items from the ranked list are then selected, and metrics such as recall or NDCG are calculated to evaluate the quality of the ranking results."}, {"title": "Model Framework", "content": "The framework of our IESRec model is shown in Figure 2. By generating intent sequences at different positions in the original sequence and inserting them into the corresponding locations, we accomplish the enhancement of positive and negative samples. These enhanced samples, along with the original samples, are jointly trained to improve the model's sequential recommendation performance. Next, we will introduce our model in detail from three aspects: intent insertion data augmentation, behavior sequence encoding, and contrastive learning training."}, {"title": "Intent Insertion Data Augmentation", "content": "In this section, we introduce how to apply the intent insertion method for data augmentation suitable for sequential recommendation tasks, including both positive and negative sample generation. First, our data augmentation is based on the sliding window data augmentation technique. For simplicity, all user behavior sequences mentioned below are the result of sliding window processing. In the sequential recommendation task, the behavior sequence fragments of users reflect their intents. Unlike most data augmentation methods based on random sampling, our intent insertion data augmentation method generates positive and negative samples by inserting artificial user behavior sequences at different positions within the sequence data.\nFor the generation of intent-inserted positive samples, given the current user u's behavior sequence Iu = [i, i2, ...,i4], for each adjacent node pair [i,i+1], t = 1,2,..., T \u2013 1, we attempt to insert an artificial sequence of length K, [i\u0173, in,...,ix], between the two nodes. The artificial sequence is constructed as follows: First, for each item node, we traverse all the data in the training set and define the set of all nodes appearing after the target node as the adjacency set of that item node. Second, we randomly select an element from the adjacency set of node it as the value of it, and continue this process iteratively until the value of ik is determined. At this point, if i+1 belongs to the adjacency set I of ik, then the artificial sequence meets the requirements and is inserted between [iu, i+1] as an intent-inserted enhanced positive sample. The enhanced sample is as follows:\n\u012au = [i,\u2026\u2026\u2026, it, i\u2081, \u2026\u2026\u2026, ik, i+1,\u2026, i4]  (1)\nThe sequence [i, in,\u2026\u2026, ix] is the inserted artificial sequence, whose start and end are dependent on the characteristics of the nodes in the original sequence. It serves as a dynamic extension and reinforcement of the user intent reflected in the original sequence. This positive sample augmentation will be mixed into the training set for direct training and will also be used alongside the generated negative samples for contrastive learning.\nFor the generation of intent-inserted negative samples, given the behavior sequence Iu = [i\u0171, i\u00bd, . . ., i4], we insert an artificial subsequence of length K at the end of the sequence for data augmentation. Since the insertion is at the end of the original sequence, this effectively acts as a prediction of the user's intent and an extension of the behavior sequence. As a result, the labels in the training set no longer align with the user intent reflected by the extended behavior sequence, and this data augmentation is considered as generating negative samples. Specifically, we use a method similar to the one for constructing positive samples. Based on the last node it and its adjacency set, we construct a sequence of length K, [i,i,..., ix]. Unlike positive sample construction, negative sample construction does not require that the adjacency set of the last node includes the next node from the original sequence. Therefore, the augmented negative sample we obtain is:"}, {"title": "Behavior Sequence Encoding", "content": "In our IESRec model, we use a Transformer encoder to encode each item sequence. First, the user's behavior sequence Iu is transformed into an embedding representation S\u00b2 = [s\", \u00a4, ..., . . ., s\u0173,..., s, . . ., s], s where s is the d-dimensional embedding vector of item su. To preserve the temporal order information of the item sequence, we construct a positional encoding matrix P \u2208 RT\u00d7d, where T represents the maximum length of all sequences. The item embeddings and positional encodings are summed to form the input vector at time point t for the Transformer:\nh = st + pt (3)\nHere, ho\u2208 Rd is the initial input vector at time point t, and pt is the positional encoding at time t. Subsequently, we use the multi-head attention mechanism to compute the representation of each item node. Assuming H\u00ba = [h, h\u2081, . . ., h] is the initial vector representation of the sequence, we input it into a multi-head Transformer encoder (Trm) with L layers:\nH\u00b9 = Trm(H\u00b0) (4)\nThe final hidden vector ht in the set of hidden vectors from the last layer HL = [h, h{, ..., h] is selected as the final representation of the user behavior sequence Su. For convenience in subsequent usage, we denote it as hu.\""}, {"title": "Contrastive Learning Training", "content": "In this section, we introduce how contrastive learning enhances the model's ability to interpret and predict the user's dynamic intent within behavior sequences. Our core objective is to enable the model to better identify the user's current intent when processing behavior sequences, thus making more accurate predictions. To achieve this, we adopt the contrastive learning paradigm, utilizing the augmented user behavior sequences, including both positive and negative samples, to improve the model's robustness and predictive capability.\nSpecifically, the positive sample pairs for contrastive learning consist of the original sequence Iu and its corresponding intent-inserted positive augmented sequence Iu, where we expect the model's prediction results for these two sequences to be as similar as possible. On the other hand, the negative sample pairs consist of the original sequence Iu and its corresponding negative augmented sequence \u00ce\u2122, where we expect the model's predictions for these two sequences to be as different as possible. We then use a contrastive loss function to train the model, maximizing the similarity of positive sample pairs and minimizing the similarity of negative sample pairs. The contrastive loss function is defined as follows:\nLc = \u2212log  exp(sim(hu, \u04ba\u0438)/\u03c4)\n exp(sim(hu, hu)/T) (5)\nHere, hu, hu, and hu represent the representations of the original sequence and its corresponding positive and negative sample sequences, respectively. sim(,) denotes the similarity measure, and in our experiments, we use the inner product of vectors as the similarity metric. is the tempera-ture parameter that controls the intensity of contrastive learning. Through the contrastive learning paradigm, we enhance the model's recommendation performance and robustness when dealing with highly complex user intent in behavior sequences."}, {"title": "Joint Training and Prediction", "content": "The model's final loss function combines the loss from the main recommendation task and the con-trastive learning loss. The loss for the main recommendation task consists of the model's loss on the original training set and the loss on the positive samples, as shown below:\nL = Lrec + Lrec + \u03bbLc (6)\nHere, Lrec and Crec represent the cross-entropy losses on the original training set and the generated positive sample data, respectively. We use the hyperparameter \u03bb to adjust the weight of the contrastive learning loss. In the subsequent experiments, we will analyze the effects of \u03bb and on the model's recommendation performance. During prediction, we do not consider the contrastive learning module or positive sample data augmentation; instead, we directly use the trained model to predict the user's next behavior based on the encoded behavior sequence."}, {"title": "Experiments", "content": "In this section, we first describe our experimental setup, including an introduction to the datasets, baseline models, evaluation metrics for model performance, and training details. We then provide an overall comparison of the performance of our model against the baseline models, followed by ablation experiments for our model. Finally, we conduct a sensitivity analysis of the model's hyperparameters."}, {"title": "Experimental Setup", "content": "In this subsection, we first introduce the datasets used for all the experiments in this chapter. We then introduce the baseline models against which we compare our model, categorizing these baseline models. The evaluation metrics refer to the criteria used in our experiments to assess the performance of the sequential recommendation task, following the standard conventions in academia for this task. Lastly, we outline the detailed configurations used for model training."}, {"title": "Dataset Introduction", "content": "We conduct experiments on three subsets of the widely-used Amazon dataset [MTSVDH15]. The Amazon dataset contains user review data from the Amazon website from 1996 to 2014. The dataset includes information such as user IDs, product IDs, ratings, review text, and timestamps. This dataset is extensively used in the study of recommendation systems, text mining, and sentiment analysis. Specifically, we conduct experiments on three subsets: Beauty, Clothing, and Sports.\nThe Beauty subset contains user reviews and ratings related to beauty and personal care products. This subset includes a wide range of beauty products, such as skincare, cosmetics, and perfumes. The users in this subset provide detailed ratings and reviews of beauty products, focusing on aspects like product efficacy, packaging, and scent. Although the product variety is extensive, the dataset is relatively sparse, as user purchasing and reviewing behavior in the beauty category is relatively scattered.\nThe Clothing subset contains user reviews and ratings related to clothing, footwear, and accessories. This subset covers various types of apparel, including men's and women's clothing, sportswear, shoes, and accessories. Users in this subset typically provide reviews about size, comfort, style, and quality. Due to the fast product turnover and strong seasonality, users' purchasing and reviewing behavior exhibits time sensitivity.\nThe Sports subset contains user reviews and ratings related to sporting goods and outdoor equipment. This subset includes equipment for various sports and outdoor activities, such as sports gear, fitness equipment, and outdoor gear. Users in this subset often review the functionality, durability, and performance of the products, covering a wide range of sports and outdoor activity scenarios.\nWe remove any user and item nodes that appear less than five times in the dataset. The details of the three datasets are presented in Table 1, including the number of users and items, the number of user-item interactions, the average length of user behavior sequences, and the density of each dataset."}, {"title": "Baseline Models", "content": "We compare our model with several classical works in the field of sequential recommendation. These baseline models are divided into two categories: the first category consists of methods that do not use the contrastive learning paradigm, and the second category includes methods that utilize contrastive learning. The details of these baseline models are as follows:\n\u2022 GRU4Rec[HKBT16] was the first to apply Gated Recurrent Neural Networks (GRU) to sequential recommendation tasks.\n\u2022 BERT4Rec[SLW+19] models data for sequential recommendation tasks by adopting the masked node paradigm, inspired by natural language processing tasks.\n\u2022 SASRec [KM18] was the first to use a unidirectional self-attention mechanism to model sequential recommendation tasks.\n\u2022 CL4Rec[XSL+22] uses cropping, masking, or reordering as data augmentation techniques, and then applies the contrastive learning paradigm for modeling sequential recommendation tasks.\n\u2022 ICLRec[CLL+22] enhances recommendation performance and model robustness by introducing latent intents in user behavior sequences into the sequential recommendation model, using contrastive self-supervised learning (SSL) to maximize the consistency between sequence views and their corresponding intents.\n\u2022 DuoRec[QHYW22] proposes a contrastive learning method to address representation degradation in sequential recommendation, thus improving the performance of the recommendation system.\n\u2022 DCRec[YHX+23] introduces a new debiased contrastive learning paradigm, which combines sequential pattern encoding with global collaborative relationship modeling through an adaptive compliance-aware augmentation method. This approach aims to resolve popularity bias issues in recommendation systems and effectively captures item transition patterns within sequences and cross-sequence user dependencies, significantly enhancing recommendation performance.\n\u2022 MAERec[YXH23] proposes a simple and effective graph-masked autoencoder-enhanced sequential recommendation system. By adaptively and dynamically extracting global item transition information for self-supervised augmentation, it avoids the dependence on high-quality embedding contrastive views present in existing contrastive learning models, addressing issues like label scarcity and noise in user behavior data, thereby significantly improving representation capability and recommendation performance in sequential recommendation tasks."}, {"title": "Evaluation Metrics", "content": "We use two commonly used evaluation metrics to assess the recommendation performance of our IES-Rec model and the baseline models: Hit Rate (HR) [GNOT92] and Normalized Discounted Cumulative Gain (NDCG) [JK02]. HR is a simple and intuitive metric that measures whether the recommendation system can include the items that users are genuinely interested in within the recommendation list. It represents the proportion of test users for whom the system successfully recommends at least one item of interest. The formula for HR is as follows:\nHR =  \u03a3\u03ba\u03b5\u03c5 I(rank(u) \u2264 k)\n|U| (7)\nHere, U is the set of all users. I(\u00b7) is an indicator function that returns 1 when the condition inside the parentheses is true, and 0 otherwise. rank(u) is the position of the relevant item for user u in the recommendation list. k is the length of the recommendation list, and |U| is the total number of users. NDCG is a ranking-aware evaluation metric used to measure the quality of the recommendation list, with higher scores indicating that the items users are genuinely interested in appear earlier in the list. We adopt the full-ranking strategy [KR20], where the match scores between the given user nodes and all item nodes are ranked from highest to lowest to evaluate the model's recommendation performance. In our experiments, the recommendation list length is set to K = 10, 20, 50, meaning we use HR@10, HR@20, HR@50, and NDCG@10, NDCG@20, NDCG@50 to test the models."}, {"title": "Training Details", "content": "We use the recently released self-supervised learning framework SSLRec [RXY+24] for our experiments. For models not included in this framework, we use the official code and configurations for training. During the data preparation phase, we process the raw data uniformly and fix the training, validation, and test sets, ensuring that all models are compared using the same training and test data. The behavior data of all users is sorted chronologically, with the last 50 behavior records used as the test set. Skipping the last behavior, the previous 50 records (starting from the second to last) are used as the validation set, and the preceding 50 records (starting from the third to last) are used as the training set. The maximum sequence length is fixed at 50, with any length exceeding this being truncated, and shorter sequences are padded with extra placeholders.\nDuring training, the learning rate is uniformly set to 0.001, and the batch size is set to 512. The embedding dimension for all nodes is fixed at 64. The models are trained using the Adam optimizer [KB15], with all dropout values set to 0.5. We apply an early stopping mechanism to determine when to stop training, specifically monitoring the MRR metric on the validation set after each training epoch. If there is no improvement after 10 consecutive checks, training is stopped.\nIn terms of hardware, all model training and inference tasks were conducted on an Intel i7-13700K CPU and an NVIDIA TITAN RTX GPU."}, {"title": "Overall Performance Comparison", "content": "In our research on recommendation algorithms from a graph perspective, we conducted a comprehensive comparison between our IESRec model and a series of baseline models. This comparison focused on the Beauty, Clothing, and Sports datasets, evaluating their performance based on two metrics: Hit Rate (HR) and Normalized Discounted Cumulative Gain (NDCG). The data is presented in Table 2. The results indicate that our model significantly outperforms the baseline models across all datasets, with a detailed analysis provided below.\n\u2022 Dataset-specific analysis: In the Beauty dataset, our IESRec model performed exceptionally well in both HR and NDCG metrics. Specifically, at K = 50, IESRec achieved an HR of 0.1818, significantly higher than the best-performing baseline model MAERec (HR of 0.1787). For the NDCG metric, our model scored 0.0640, also notably higher than the second-best model MAERec (NDCG of 0.0603). These results indicate that our model has a higher hit rate and ranking quality for beauty product recommendations, allowing it to more accurately capture user preferences. In the Clothing dataset, our model similarly excelled, achieving an HR of 0.0647 at K = 50, significantly outperforming the best baseline model MAERec (HR of 0.0614). For the NDCG metric, our model scored 0.0214, surpassing all baseline models. In the Sports dataset, our model showed outstanding performance. IESRec achieved HR and NDCG scores of 0.1112 and 0.0366 at K = 50, respectively, significantly surpassing all baseline models. In contrast, the best-performing baseline model MAERec scored 0.1100 in HR and 0.0338 in NDCG. Our model demonstrated higher precision and user satisfaction in recommending sports and outdoor equipment."}, {"title": "Ablation Study", "content": "In this section, we evaluate the impact of several key components of the model on recommendation accuracy. Specifically, we gradually remove parts of the designed model architecture and observe the changes in accuracy across the three datasets. This approach allows us to quantitatively assess the contribution of our model design to the recommendation performance. Based on modifications to the model structure, we generate two variants of our IESRec model:\n\u2022 w/o PS (without positive samples in training data): This variant removes the positive sample data generated by intent insertion from the training data (while retaining sliding window data augmentation). The contrastive learning module is still preserved.\n\u2022 w/o CL (without contrastive learning module): This variant removes the contrastive learning module. In this case, the model is trained only using the sliding window-augmented training samples and the positive samples generated by intent insertion."}, {"title": "Hyperparameter Sensitivity Analysis", "content": "In our IESRec model, two important hyperparameters are used in the contrastive learning module: \u03bb and \u03c4. \u03bb represents the importance of the contrastive loss function in the overall loss function, and Tis the temperature coefficient in the contrastive loss function. By adjusting these two hyperparameters, we can influence the role of contrastive learning during model training, thereby optimizing the model's recommendation performance. Figure 3 shows the performance of the IESRec model in terms of HR@20 and NDCG@20 on the Beauty, Clothing, and Sports datasets under different values of \u03bb and T.\nEffect of hyperparameter \u5165: In the Beauty and Sports datasets, as A decreases, the model's performance in both HR and NDCG metrics initially improves and then stabilizes. Specifically, when A is small, the weight of the contrastive loss is lower, and the model mainly relies on the original loss function for optimization. Proper integration of contrastive learning helps to improve model performance. As A increases and the weight of the contrastive loss grows, the recommendation performance declines. Once A reaches a certain range, model performance tends to stabilize. This suggests that for these datasets, the contrastive loss does not need to be heavily weighted to achieve optimal results. In the Clothing dataset, changes in A have a relatively greater impact on model performance. Overall, as A decreases, both HR and NDCG metrics improve to varying degrees, and the effect is strongly related to the value of the other hyperparameter. This indicates that in the Clothing dataset, the weight of the contrastive loss has a more uncertain effect on model performance, and both hyperparameters jointly influence the final recommendation results.\nIn the Beauty and Sports datasets, the effect of Ton model performance is fairly consistent. As Tincreases, both the HR and NDCG metrics improve. A value that is too small may lead to an overly strong effect from contrastive learning, causing the model to perform poorly in capturing subtle differences. Thus, it is necessary to find a balance. In the Clothing dataset, the effect of T is more pronounced and is strongly related to the value of A. When A is small, increasing results in slight performance improvement, but the overall performance does not reach its best. When A is larger, the impact of Ton recommendation performance becomes inconsistent. This suggests that in the Clothing dataset, the effects of these two hyperparameters are interdependent, and finding a reasonable combination of both is key to achieving optimal results."}, {"title": "Conclusion", "content": "In this chapter, we propose an intent-enhanced sequential recommendation algorithm, IESRec, aimed at addressing issues such as increased data noise and blurred user intent, which are common in current data augmentation methods for sequential recommendation algorithms. IESRec generates positive and negative samples using the concept of intent insertion. First, we generate positive samples by inserting artificial user intent sequences into non-terminal positions in the sequence data. These inserted sequences are derived from the user's historical behavior data and maintain intent continuity with the preceding and following subsequences at the insertion point. Second, we generate negative samples by inserting similar artificial sequences at the end of the sequence data. The generated positive samples are mixed into the training set for training. Additionally, both positive and negative samples are used to construct the contrastive loss function, which is jointly trained with the main task to enhance the overall model performance.\nExperimental results on the Beauty, Clothing, and Sports datasets show that the IESRec model significantly outperforms the baseline models. In the ablation experiments, we demonstrated the effectiveness of our data augmentation method. Furthermore, by tuning the hyperparameters in the contrastive learning process, we further improved model performance, verifying the effectiveness of contrastive learning in sequential recommendation tasks. In summary, the IESRec model, by designing a novel intent-sequence-insertion-based data augmentation method, significantly improves the accuracy and stability of sequential recommendation."}]}