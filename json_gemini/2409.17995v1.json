{"title": "Joint Localization and Planning using Diffusion", "authors": ["Lukas Lao Beyer", "Sertac Karaman"], "abstract": "Diffusion models have been successfully applied to robotics problems such as manipulation and vehicle path planning. In this work, we explore their application to end-to-end navigation \u2013 including both perception and planning by considering the problem of jointly performing global localization and path planning in known but arbitrary 2D environments. In particular, we introduce a diffusion model which produces collision-free paths in a global reference frame given an egocentric LIDAR scan, an arbitrary map, and a desired goal position. To this end, we implement diffusion in the space of paths in SE(2), and describe how to condition the denoising process on both obstacles and sensor observations. In our evaluation, we show that the proposed conditioning techniques enable generalization to realistic maps of considerably different appearance than the training environment, demonstrate our model's ability to accurately describe ambiguous solutions, and run extensive simulation experiments showcasing our model's use as a real-time, end-to-end localization and planning stack.", "sections": [{"title": "I. INTRODUCTION", "content": "Denoising diffusion probabilistic models [1] have shown to be a powerful tool for sampling from complicated, high-dimensional distributions, achieving state-of-the-art performance on tasks such as image generation [2], motion planning [3] and control [4]. In this paper, we introduce a diffusion model that can solve a vehicle navigation task consisting of localization and planning in arbitrary 2D environments. In particular, our model is conditioned on a 2D obstacle map, raw LIDAR sensor measurements, and a desired goal state, and produces collision-free paths in the global map frame (see Fig. 1). We also demonstrate how this model's output can serve to control a vehicle with real-time online replanning. To the best of our knowledge, this is the first paper exploring the joint global vehicle localization and planning problem using diffusion. However, there is a significant amount of existing work on applications of diffusion to several problems in robotics.\nDiffusion planning and RL. Diffuser [3] uses a diffusion model in conjunction with a guidance function learned via reinforcement learning (RL) to perform a variety of planning tasks. The use of hand-designed guidance to enforce test-time conditions, such as obstacle avoidance, in diffusion models for planning [5], has also been explored. Offline RL has been shown to benefit from diffusion models to represent policies [6], and conditional diffusion models have been used to behavior-clone a model-based 2D pathplanner [7].\nWe note that these contributions generally do not consider the geometry of the diffused states specially, performing diffusion in Euclidean space, and do not address the global"}, {"title": "II. PRELIMINARIES", "content": "In this work, we focus on vehicles traversing 2D environments. Therefore, we consider paths parameterized by $N$ approximately uniformly spaced pose samples $T = [T_1, ...,T_N] \\in SE(2)^N$, where each pose $T \\in SE(2)$ consists of a heading $R \\in SO(2)$ as well as a position $X \\in \\mathbb{R}^2$ in the global coordinate frame. We use similar notation $R \\in SO(2)^N$ and $X \\in \\mathbb{R}^{2N}$ for sequences of rotations and translations, respectively. We also assume that positions are scaled such that their coordinates do not fall far outside of the [-1,1] range.\n\nA. Forward and Reverse Diffusion Processes on SE(2)\nTo define a forward and reverse diffusion process on SE(2), we follow the development of diffusion modeling on SE(3) by Yim et al. [11]. In particular, we leverage the fact that SE(2) can be identified with SO(2) \u00d7 R\u00b2 in order to define a forward process $(T(t))_{t>0}$ on SE(2) by considering diffusion on SO(2) and $\\mathbb{R}^2$ separately:\n$\\begin{equation}\nd R(t) = g(t)dB_t^{(2)} \\text{ and } dX(t) = g(t)dB_t^{\\mathbb{R}^2}.\n\\end{equation}$\nHere, $g(t)$ is the diffusion coefficient, and $dB_t^{(2)}$ and $dB_t^{\\mathbb{R}^2}$ denote Brownian motion on SO(2) and $\\mathbb{R}^2$, respectively. As in Karras et al.'s EDM model [16], we choose to skip the drift term.\nLet $T^{(t)} = T^{(t_{f}-t)}$, where $t_f$ denotes the final timestep of the forward diffusion process. Define $R^{(t)}$ and $X^{(t)}$ equivalently. Let $p_t$ denote the density of $T^{(t)}$. Then, following Song et al. [17] and De Bortoili et al. [9], the time reversal of the forward process (1) is given by\n$\\begin{equation}\nd T(t) = g^2(t_f -t) \\nabla \\log p_{t_f-t}(T(t)) + g(t_f-t) [dB_t^{(2)}, dB_t^{\\mathbb{R}^2}],\n\\end{equation}$\nso that for $t \\in [0, t_f]$, we have $T^{(t)} \\sim p_{t_f-t}.\n\nB. Score Modeling on SE(2)\nTo sample from the data distribution $p_0$ by running reverse diffusion, we approximate the intractable Stein score $\\nabla \\log p_t$. Using denoising score matching (DSM), a neural network $s_{\\theta}(t, \\cdot)$ is trained to minimizing the DSM loss\n$\\begin{equation}\nL(\\theta) = \\mathbb{E}[x_t ||\\nabla \\log p_{t|0}(T(t) | T(0)) - s_{\\theta}(t, T(t))||^2]\n\\end{equation}$\nwith weights $\\lambda_t > 0$ and $t \\in [0, t_f]$ [17]. Since we designed the diffusion processes on SO(2) and $\\mathbb{R}^2$ to be independent (1), note that the conditional score\n$\\begin{equation}\n\\nabla \\log p_{t|0}(T(t) | T(0)) = [\\nabla_{R(t)} \\log p_{t|0}(R(t) | R(0)), \\nabla_{X(t)} \\log p_{t|0}(X(t) | X(0))]\n\\end{equation}$\ncan be computed by considering the rotation and translation separately [11]. Here, we have for the Euclidean part of"}, {"title": null, "content": "the score that $\\nabla_x \\log p_{t|0}(x | y) = \\sigma^{-2}(t)(y - x)$, where we refer to Karras et al.'s EDM formulation [16] for the definition of $\\sigma(t)$ in terms of the diffusion coefficient $g(t)$. In the case of angles $\\phi, \\psi \\in SO(2)$, the score is instead computed by differentiating the wrapped normal [18] pdf:\n$\\begin{equation}\n\\nabla_{\\phi} \\log p_{t|0}(\\phi | \\psi) = \\nabla_{\\phi} \\log \\sum_{k \\in \\mathbb{Z}} \\exp(-\\frac{(\\psi - \\phi - 2\\pi k)^2}{2\\sigma^2(t)}).\n\\end{equation}$\nIn practice, we observe that the series converges rapidly on $[-\\pi, \\pi)$, so we truncate it summing only over $k \\in [-10, 10]$ and compute the derivative using automatic differentiation, or use the Euclidean score as an approximation in the case where $\\sigma(t)$ is small."}, {"title": "III. DIFFUSION LOCALIZATION AND PLANNING MODEL", "content": "We explore a diffusion model for jointly performing global localization and planning in the context of behavior cloning of a model-based pathplanner. We procedurally generate a dataset $D = \\{S_i\\}_{i \\in \\mathbb{Z}}$ of example scenarios and demonstrations. Each scenario $S = (\\mathcal{E}, \\mathcal{O}, G, T^*)$ consists of a randomly generated environment occupancy map $\\mathcal{E} \\in \\{0, 1\\}^{H \\times W}$, an noisy egocentric LIDAR sensor observation $\\mathcal{O} \\in \\mathbb{R}^{N_{rays}}$, a goal pose $G \\in SE(2)$, and an expert demonstration produced by a model-based pathplanner in the form of a collision free path $T^* \\in SE(2)^N$.\n\nA. Denoising Network\nWe describe our score approximator in terms of a \"denoiser\u201d $f_{\\theta}(t, \\cdot) : SE(2)^N \\rightarrow SE(2)^N$, as follows:\n$\\begin{equation}\ns_{\\theta}(t, T(t)) = \\nabla \\log p_{t|0}(T(t) | f_{\\theta}(t, T(t))).\n\\end{equation}$\nNote that we have omitted writing explicit dependencies on $\\mathcal{E}, \\mathcal{O}$ and $G$ for notational simplicity. However, $f_{\\theta}$ and the entire diffusion processes are to be understood as being conditioned on $\\mathcal{E}, \\mathcal{O}$ and $G$ as applicable. More explicitly, we write $f_{\\theta}(t, \\cdot)$ in terms of the conditional 1D U-Net [19] $F_{\\mathcal{E}}(\\cdot | X_{cond}) : \\mathbb{R}^{N \\times (4 + d_{local})} \\rightarrow \\mathbb{R}^{N \\times 4}$ as\n$\\begin{equation}\nf_{\\theta}(t, T(t)) = f_{out}(F_{\\mathcal{E}}(f_{in}(T(t), \\mathcal{E}) | f_{cond}(t, \\mathcal{O}, G))).\n\\end{equation}$\nHere, $f_{in}(\\cdot, \\mathcal{E}): SE(2)^N \\rightarrow \\mathbb{R}^{N \\times (4 + d_{local})}$ encodes the position $(x, y)$ and rotation angle $\\phi$ of each input pose $T(t)$ as a vector $[x \\, y \\, \\cos(\\phi) \\, \\sin(\\phi)]$ and concatenates a $d_{local}$-dimensional local conditioning vector to each encoded input pose. An additional global conditioning vector is computed by $f_{cond}$ and applied via FiLM modulation [20]. This global conditioning vector always includes the goal pose and a sinusoidal positional embedding of the current timestep $t$. Finally, $f_{out}: \\mathbb{R}^{N \\times 4} \\rightarrow SE(2)^N$ undoes the pose transformation and encoding to recover the denoised path.\n\nB. Obstacle Avoidance\nWe propose a simple local conditioning strategy to con-dition the denoising network on the obstacle map $\\mathcal{E}$. To this end, we first encode $\\mathcal{E}$ into a feature map via a learned encoder network $G_{\\mathcal{E}}: \\mathbb{R}^{H \\times W} \\rightarrow \\mathbb{R}^{d_{local} \\times H \\times W'}$. The encoded map $G_{\\mathcal{E}}(\\mathcal{E})$ is then sampled (via bilinear interpolation) at"}, {"title": "IV. DATASET GENERATION", "content": "Our training dataset consists of smooth, obstacle-free paths traversing cluttered 2D environments between randomized start and goal positions. Each example scenario is generated by placing a variable number of circular obstacles of randomized position and radius. We render the obstacle map to a 64 x 64 pixel bitmap serving as the environment map $\\mathcal{E}$. The vector of LIDAR ray lengths $\\mathcal{O}$ is computed by casting 64 rays in the rendered environment map $\\mathcal{E}$, starting from the ground truth start position until hitting an obstacle.\nThe reference path $T^*$ is generated in three steps: shortest path search, spline fitting and optimization, and heading"}, {"title": "V. IMPLEMENTATION AND EVALUATION", "content": "We evaluate our model first on the pure localization task to verify the effectiveness of the proposed conditioning technique, assessing global localization accuracy, generalization to out-of-distribution environments, and distributional modeling capability. We then demonstrate our model on the full navigation task consisting of joint global localization and planning, starting with a quantitative evaluation of success rate on our synthetic dataset and ending with an application to real-time closed-loop control in a realistic scenario. All reported runtimes are measured on an NVIDIA RTX A5000 GPU, and models are trained on two RTX A6000 GPUs for one week.\n\nA. Implementation Details\nThe first three layers of a ResNet-18 [22] network are used as the environment and localization encoders $G_{\\mathcal{E}}$ and $H_{\\mathcal{E}}$, producing 8\u00d78 feature maps from the 64 \u00d7 64 input obstacle maps. To generate the high resolution feature maps shown in Fig. 3, we train a model using a larger U-Net as the environment encoder, but find it does not significantly improve planning or localization performance. The pose denoising network $F_{\\theta}$ is a 1D U-Net with three down-/upsampling and stages and four ResNet blocks in each stage.\n\nB. Global Localization\nNext, we evaluate the quality of a diffusion-based global localization model. This model leverages the LIDAR observation conditioning described in Section III-C to condition"}, {"title": "VI. CONCLUSIONS & FUTURE WORK", "content": "In this work we have developed a diffusion-based model which can jointly perform global localization on a given map using LIDAR observations and plan a collision-free path. We demonstrate that the diffusion framework's powerful distributional modeling abilities enable the model to gracefully handle degenerate scenarios where multiple solutions may exist. Furthermore, we find the proposed conditioning strategies effectively allow our model, trained only on a narrow set of synthetic examples, to navigate realistic floorplans and other out-of-distribution scenarios.\nWhile we show that we can already successfully deploy this model for end-to-end online replanning and control tasks, we identify several directions for future work. First, we would like to extend our joint localization and planning model for prediction of multiple timesteps in order to enable the model to better leverage the coupling of perception and control through methods like Diffusion Forcing [23]. Next, it would be interesting to explore the full navigation problem including mapping, instead of relying on the availability of a map, as well as extensions of our method to SE(3) with camera images instead of LIDAR scans. Additionally, it would be interesting to investigate the use of test-time guidance [5] instead of or in combination with the current conditional diffusion model. Finally, we would like to reconsider the need of an expert planner for dataset generation by instead training our model for use on vehicles with more complex dynamics using online reinforcement learning.\nWe hope that our work on joint global localization and planning can be a useful stepping stone towards generalizable and robust end-to-end navigation, enabling the learning of richer behavior than traditional navigation pipelines that rely on decoupled perception and planning."}]}