{"title": "Evolving Deeper LLM Thinking", "authors": ["Kuang-Huei Lee", "Ian Fischer", "Yueh-Hua Wu", "Dave Marwood", "Shumeet Baluja", "Dale Schuurmans", "Xinyun Chen"], "abstract": "We explore an evolutionary search strategy for scaling inference time compute in Large Language Models. The proposed approach, Mind Evolution, uses a language model to generate, recombine and refine candidate responses. The proposed approach avoids the need to formalize the underlying inference problem whenever a solution evaluator is available. Controlling for inference cost, we find that Mind Evolution significantly outperforms other inference strategies such as Best-of-N and Sequential Revision in natural language planning tasks. In the TravelPlanner and Natural Plan benchmarks, Mind Evolution solves more than 98% of the problem instances using Gemini 1.5 Pro without the use of a formal solver.", "sections": [{"title": "1. Introduction", "content": "How can a large language model (LLM) be guided to think deeper about a complex problem and leverage inference time compute to improve its problem solving ability? Prior research has investigated various strategies for leveraging inference time compute, such as chain-of-thought [41, 21], self-consistency [39], sequential revision based on feedback [36, 30, 8, 19, 1], and search guided by auxiliary verifiers or evaluators [43]. When a solution evaluator is available, search strategies have an advantage of being able to reliably improve problem solving ability with increased compute. For example, methods such as Best-of-N [4, 24, 25] and tree search [37] naturally exploit additional compute to explore a larger set of solution candidates, thereby increasing the probability of finding a successful solution.\nTo better exploit inference time compute, we propose an evolutionary search strategy for LLMs that combines free-flowing stochastic exploration with large-scale iterative refinement. We refer to this approach as Mind Evolution. As illustrated in Figure 1, Mind Evolution is a genetic search strategy that evolves a diverse population of candidate solutions, leveraging an LLM to generate, recombine and refine solution candidates based on feedback from an evaluator. The overall process is analogous to combining divergent thinking (free-flowing parallel idea exploration) with convergent thinking (idea evaluation and selection), considered as hallmarks of intelligent problem solving behavior [14].\nUnlike Best-of-N, which searches broadly by generating independent candidates for evaluation, Mind Evolution searches both broadly and deeply, exploring a diverse set of candidates and refining the most promising alternatives. Unlike sequential reasoning approaches, such as self-refinement or tree search [37, 25], which require evaluation of individual reasoning steps, Mind Evolution performs global refinement of complete solutions, and therefore only requires a global solution evaluator rather than a stepwise process reward. Also, typical of evolutionary methods, Mind Evolution can be easily parallelized.\nThere has been prior work on combining evolutionary search with LLMs, primarily in the literature on evolutionary program generation [34, 17, 29, 23, 6]. However, this prior work focuses on searching through formal program spaces, using guidance from execution feedback or code explanation. By contrast, Mind Evolution is not restricted to searching in a formal space. This allows Mind Evolution to be applied to problems that are not formalized, or remain difficult to formalize, as long as a programmatic solution evaluator is available. In particular, we focus on natural language planning tasks where candidate solutions can still be automatically parsed, evaluated and critiqued using an implementable oracle evaluator. This approach exploits the observation that it is often easier to evaluate the quality of a candidate solution than it is to generate good solutions for a given problem [11].\nIn the domain of natural language planning, we consider the TravelPlanner [42] and Natural Plan [47] benchmarks, where constraint satisfaction problems are expressed in natural language without any explicit formalization of the underlying objectives, constraints or variables. These problems require a set of interconnected decisions that satisfy a set of global and local constraints. For example, in TravelPlanner, a travel plan should be produced that respects various accommodation and dinning constraints, while also considering budget limitations and other preferences, all expressed solely in natural language. To date, LLMs have yet to achieve good performance on these tasks"}, {"title": "2. Related Work", "content": "Pairing LLMs with Evolutionary Search In addition to the program generation studies discussed in Section 1, several recent works have explored combining LLMs and evolution for numerical optimization [26, 3] and combinatorial optimization [28, 44]. The problem spaces we tackle in this work, such as natural language planning, can also be viewed as combinatorial optimization problems \u2013 optimizing plans subject to constraints specified in natural language. In contrast to these previous studies, we focus on evolving solutions in natural language spaces instead of formal spaces. This removes the requirement of task formalization, which requires significant effort and expert knowledge for each task instance.\nOther works have also applied evolutionary search to prompt optimization, with the goal of improving performance on target tasks [45, 10, 15]. Among these, EvoAgent [45] also evaluated their approach on the TravelPlanner benchmark. In contrast to our work, which performs evolutionary search directly on"}, {"title": "3. Method", "content": "Mind Evolution employs a genetic search strategy, combined with an LLM and a tailored set of prompts, to orchestrate an efficient search for solutions to natural language planning tasks. Before describing Mind Evolution in detail, we first provide a brief overview of language-based genetic algorithms.\n3.1. Language-based Genetic Algorithm Overview\nGenetic algorithms [18, 12, 31] are a meta-heuristic inspired by natural selection. In a genetic algorithm, a population of candidate solutions is evolved toward populations that contain a greater proportion of higher quality individuals with respect to a target optimization objective. Such an objective is also often referred to as the \"fitness\" function. Each individual candidate has a genetic representation that can be mutated and recombined with others.\nEvolutionary search usually begins with a population of independently generated candidate solutions. In each generation, the fitness of every individual is evaluated with respect to the target objective. Candidates are then stochastically selected for reproduction based on their fitness (\"selection\"). In reproduction, the genetic representations of selected parents are combined (\u201ccrossover\") and potentially altered (\u201cmutation\") to produce new child solutions. Such a process creates the next generation of children, which then enter the population. Population fitness generally increases over successive generations, as parents with greater fitness are more likely to be selected for recombination.\nIsland Model To sustain diversity in an evolving population it is also helpful to introduce an island model [38, 5], where distinct sub-populations (\"islands\") are created and evolved independently between \u201cmigration\u201d and \u201cisland reset\u201d events that occur at specified frequencies. For a migration operation, the solutions on one island are stochastically chosen based on fitness to migrate to an adjacent island. For an Island Reset operation, the populations on islands with low overall fitness are replaced by strong solutions from the global population, which also has a selection effect. The island model has been adopted in recent successful efforts, such as FunSearch [34].\nLanguage-based Genetic Representation The individual candidates in a language-based genetic algorithm are represented by natural language. This allows the strong language understanding and generation capabilities of an LLM to be leveraged to implement powerful recombination (crossover and mutation) and island reset operations through prompting.\n3.2. Mind Evolution\nFigure 1 illustrates the design of Mind Evolution, with its hyperparameters listed in Table 1. The core components of Mind Evolution are:\n1. the specific choices for the selection and migration operations;\n2. the set of prompts that implement the initialization, recombination (crossover and mutation), and island reset operations with an LLM;\n3. the fitness function that evaluates the quality of a given solution and optionally provides feedback on issues detected.\nThe overall evolution process is repeated until a valid solution is found, or until  N_{gens} generations have been completed, after which the best scoring candidate is returned.\nFitness Evaluation As discussed in Section 1, we implement a fitness function for each problem domain, where candidate solutions are parsed and evaluated programmatically. In principle, any function that can evaluate solution quality can be used, including LLM evaluation. The evaluation function plays three key"}, {"title": "4. Experiments", "content": "Tasks We evaluate Mind Evolution on three benchmark natural language planning domains: two tasks from Natural Plan [47], including Trip Planning (Section 4.2) and Meeting Planning (Section 4.3), and the TravelPlanner [42] benchmark (Section 4.1). (We omit the Calendar Scheduling task from Natural Plan, since these problems can be solved by enumeration.) Implementation details for each task is provided in Appendix A, including the prompts (Appendix A.1) and evaluation functions used (Appendix A.2).\nModels We use Gemini 1.5 Flash (gemini-1.5-flash-001) as the default LLM in our experiments below. The hyperparameters used when applying Mind Evolution to Flash are specified in Table 1. In addition to evaluating Mind Evolution with the Flash model, we also investigate a two-stage approach, where Gemini 1.5 Pro model (gemini-1.5-pro-exp-0827) is used to tackle problems that are not solved within the  N_{gens} generation limit. Such a two-stage approach provides better cost-efficiency than using the Pro model on every problem instance. When applying Mind Evolution to the Pro model we alter the hyperparameters from those specified in Table 1 to:  N_{convs} = 8,  N_{seq} = 3,  N_{parent} = 10,  P_{rno parents} = 1/5.\nBaselines For each task, we compare Mind Evolution to three baseline search strategies that use the same solution evaluator and task-specific prompts:\n1. 1-Pass, where a solution is proposed using a single forward pass of the LLM.\n2. Best-of-N [4], where up to 800 candidate solutions are independently generated until a successful solution is found (the same upper bound as Mind Evolution).\n3. Sequential-Revision+, where 10 candidate solutions are proposed independently, then revised separately for 80 turns using the RCC process (Figure 2). Note that 10 independent threads of 80-turn refinements are used instead of a single 800-turn refinement, because we rarely observe improvements after 80 turns. This baseline is similar to running 10 trials of multi-turn Reflexion [36].\nAdditionally, for reference, we also include an additional 1-Pass baseline that uses OpenAI 01-preview."}, {"title": "4.1. TravelPlanner", "content": "TravelPlanner [42] is a natural language planning benchmark that simulates the problem of organizing a trip plan for a user who expresses preferences and constraints. We focus on the sole-planning mode (see [42] for details), where each problem instance consists of a list of options regarding accommodation, restaurants, attractions and transportation, plus additional constraints that specify user preferences for budget, cuisine, etc. A plan is evaluated based on whether it satisfies the user preferences and common-sense constraints.\nTable 2 gives detailed results that compare the overall Success Rate and computational cost of Mind Evolution versus the baseline strategies. In terms of Success Rate, Mind Evolution clearly outperforms the baseline strategies, achieving over 95%. By comparison, Sequential-Revision+ provides a reasonable baseline, achieving almost 83%, while Best-of-N struggles, achieving only 55.6%. Overall, these results demonstrate a clear advantage of an evolutionary strategy that combines a broad search, through stochastic exploration, with a deep search that leverages an LLM for solution refinement.\nConsidering the two-stage approach, where Mind Evolution uses Gemini 1.5 Pro for any unsolved problems, we find that nearly the entire dataset can be solved, achieving a 100% success rate on validation and 99.9% on test problems respectively. The only work we are aware of that comes close to this success rate is [16], which uses GPT-4 for auto-formalization then leverages a formal solver to achieve 98.9% and 97.0% on validation and test respectively. Mind Evo-"}, {"title": "4.2. Natural Plan \u2013 Trip Planning", "content": "The Trip Planning task [47] involves finding an itinerary that consists of a sequence of cities to visit and number of days in each that satisfies flight connectivity and scheduling constraints see Table 3 for a problem instance. We split the benchmark into 320 validation and 1,280 test instances (described in more detail in Appendix B).\nThe results in Table 2 again show that Mind Evolution strongly outperforms the baselines on this task, achieving 96.2% on the validation and 94.1% on the test instances. Table 2 also shows a qualitative comparison between the results produced by Mind Evolution and the baseline strategies. Note that Best-of-N performs better in this scenario (77.2%), even beating Sequential-Revision+ (74.4%). We find that for the two-stage approach, Mind Evolution achieves 100% on the validation set and 99.6% on the test set. These findings again highlight the benefit of evolutionary search versus simple sampling and sequential refinement.\nFinally, we note that the difficulty of this task varies with the number of cities to visit, ranging from 3 to 10. Figure 4 shows a breakdown of the Success Rate in terms of number of cities, where the relative advantage of Mind Evolution appears to increase as the number of cities grows."}, {"title": "4.3. Natural Plan \u2013 Meeting Planning", "content": "For the Meeting Planning task a sequence of meetings should be scheduled to maximize the number of meetings between individuals subject to availability, location and travel time constraints [47]. This task differs from TravelPlanner and Trip Planning in that not every meeting can be scheduled for every problem instance, implying that it is not possible to know whether an optimal solution has been reached. There-"}, {"title": "4.4. Analysis and Ablation Studies", "content": "To understand how Mind Evolution's performance scales, and how the different components affect its behavior, we provide additional measurements and ablations to gain additional insight.\nScaling Regarding scaling, Figure 6 reports the Success Rate achieved by Mind Evolution across the planning tasks as a function of the number of generations. These results clearly show steady improvement for Mind Evolution as the number of generations is increased.\nTo compare the scaling of Mind Evolution to that of the baseline search methods, we also plot the Success"}, {"title": "5. A Challenging New Task: StegPoet", "content": "We introduce a challenging new task, StegPoet, where a hidden message should be stenographically encoded [33] into a piece of creative writing. Even though the"}, {"title": "A. Implementation Details", "content": "Here we describe the implementation details of Mind Evolution. The code will be made available.\nA.1. Prompt Design\nWe first use Meeting Planning as an example to illustrate the structure of the prompts used. The prompts, as well as the model responses when parent solutions are given, are shown in Figures 12-16. The prompts begin with general instructions and a general problem definition, few-shot examples, then a task description. The few-shot examples help the LLM understand the problem and generate solutions closer to the desired formats. For TravelPlanner, we take two 3-day example plans from the training set and use them across all tasks (3-7 days). For Trip Planning, we take two example plans from the few-shot examples provided by the benchmark and use them across all tasks. For Meeting Planning, we use the 5-shot examples provided by the benchmark for each task.\nAfter the task description, we include parent solutions with corresponding evaluation feedback, followed by critical thinking instructions (in Figures 14-15). These instructions lead the LLM to improve the parent solutions, following the Refinement through Critical Conversation (RCC) process described in Section 3.2. The critical thinking instructions include problem-specific Strategy/Question prompts based on findings in each validation set (ablated in Section 4.4). In the model responses, one can see that the LLM follows the critical thinking instructions in playing the critic role to analyze the parent solutions, and playing the author role to propose a new solution.\nWe also give an example of the prompt and a model response for TravelPlanner, which has the same structure, in Figures 17-22.\nA.2. Evaluation Functions\nIn this work, solutions are evaluated programmatically with a function. As described in Section 3.2, an evaluation function has three main roles: (1) scoring solutions by measuring the optimization objective, if any; (2) verifying whether the solution satisfies given constraints; and (3) providing corresponding textual feedback. Specifically, we score natural language plans by penalizing the constraints that are not satisfied, the objectives that are not maximized, and for not following the required solution format. Thus the maximum score for all tasks is zero. We also provide textual feedback that describes how the constraints are not satisfied and how the objectives are not maximized."}]}