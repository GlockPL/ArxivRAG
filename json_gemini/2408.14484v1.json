{"title": "Agentic Retrieval-Augmented Generation for Time Series Analysis", "authors": ["Chidaksh Ravuru", "Sagar Srinivas Sakhinana", "Venkataramana Runkana"], "abstract": "Time series modeling is crucial for many applications, however, it faces challenges such as complex spatio-temporal dependencies and distribution shifts in learning from historical context to predict task-specific outcomes. To address these challenges, we propose a novel approach using an agentic Retrieval-Augmented Generation (RAG) framework for time series analysis. The framework leverages a hierarchical, multi-agent architecture where the master agent orchestrates specialized sub-agents and delegates the end-user request to the relevant sub-agent. The sub-agents utilize smaller, pre-trained language models (SLMs) customized for specific time series tasks through fine-tuning using instruction tuning and direct preference optimization, and retrieve relevant prompts from a shared repository of prompt pools containing distilled knowledge about historical patterns and trends to improve predictions on new data. Our proposed modular, multi-agent RAG approach offers flexibility and achieves state-of-the-art performance across major time series tasks by tackling complex challenges more effectively than task-specific customized methods across benchmark datasets.", "sections": [{"title": "1 INTRODUCTION", "content": "Time series modeling underpins a vast spectrum of real-world applications, including demand planning [21], anomaly detection [54], inventory management [52], energy load forecasting [24], weather modeling [31], and many others. However, it is not without its challenges. High dimensionality, non-linearity, sparsity, and distribution shifts all pose significant hurdles. Successfully navigating these challenges in time series analysis applications necessitates both considerable domain knowledge and the design of neural network architectures tailored to address task-specific goals, leading to better performance. In contrast to task-specific approaches, which employ different architecture designs for time series analysis, foundational pre-trained large language models (LLMs), such as OpenAI's GPT-4 [29] and Google's Gemini [34, 39], with their strong generalization and logical reasoning capabilities, have shown remarkable versatility across a broad spectrum of natural language processing (NLP) tasks, requiring minimal fine-tuning[17] or only a few demonstrations[2] for adaptation to niche tasks. Open-source, small-scale pretrained language models (SLMs), such as Google Gemma ([40]) and Meta LLAMA ([1, 41]), offer cost-effective domain customization through Parameter Efficient Fine-Tuning (PEFT) ([15, 16]) techniques using task-specific labeled datasets. Additionally, these smaller models can be further aligned with human preferences using Direct Preference Optimization (DPO) [8], a fine-tuning technique that utilizes paired preference data, such as datasets of preferred and dispreferred responses. However, SLMs may lack the reasoning and generalization capabilities of large-scale proprietary language models. The potential of foundational SLMs designed for universal time series applications (a single-model-fits-all approach), such as diverse time series tasks like classification, anomaly detection, forecasting, imputation, and others, remains largely unexplored but holds great promise. This approach contrasts sharply with the traditional approach of using customized, task-specific methods ([43, 49, 50]) for time series modeling for various applications. Adapting SLMs designed for NLP tasks for time series modeling to capture trends and patterns within the complex data, though unconventional, offers a clear possibility for providing unique insights. However, this is a challenging task as SLMs are trained primarily on text corpora, which operates on discrete tokens, while time series data is inherently continuous. Furthermore, SLMs may lack the inherent ability to detect and interpret time series patterns and trends like seasonality, cyclicity, or outliers, due to the absence of related pretraining knowledge. Moreover, current LMs designed for time series analysis ([14, 20, 56]) rely on a fixed-length window of past observations to generate predictions, which may be inadequate for capturing complex patterns and trends present in time series data, thus hindering accurate modeling. Smaller window sizes may capture local patterns but miss broader trends, while larger window sizes can capture more context but may overlook finer details. In recent times, Retrieval-Augmented Generation (RAG) or Retrieval-Augmented Language Modeling (RALM) [23, 33, 37] combines pre-trained language models with information retrieval from external knowledge bases to augment text generation capabilities for open-ended question-answering(ODQA)[38] tasks or for improved language modeling for text summarization, completion with improved accuracy. While regular RAG methods augment generation with retrieved knowledge for ODQA tasks, Agentic RAGs take this further by being instruction-following agents that can tackle complex goals through multi-step reasoning and iterative refinement cycles using repeated retrievals over a knowledge base to ensure the final response aligns with the end user request. In this work, we propose an Agentic RAG framework for time series analysis to improve task-specific outcomes by addressing challenges like distributional shifts, fixed window limitations in time series data. Our Agentic RAG framework presents a hierarchical, multi-agent architecture composed of a master (top-level) agent and specialized sub-agents customized for specific time series tasks. The top-level agent acting as the orchestrator analyzes the incoming user request, determines its nature and complexity, and then routes (or delegates) it to the corresponding task-specific sub-agent to produce the desired output. Similarly to how regular RAG frameworks retrieve relevant information from external knowledge bases like documents, databases, or access the real world through APIs, this Agentic RAG framework leverages distinct prompt pools as internal knowledge bases for each sub-agent focused on specific time series tasks. As specialized knowledge repositories tailored to each sub-agent's time series task, the prompt pools store both domain and task-specific knowledge as key-value pairs. This facilitates easy reuse and sharing within and across datasets, promoting knowledge sharing and transfer, reducing the need to relearn or rediscover patterns from scratch. Each 'key' represents a specific pattern (seasonality, cyclicality, etc.), and the 'value' contains details about that pattern. When processing new input data, the sub-agent retrieves the most relevant prompts from the pool based on similarity. These prompts provide contextual knowledge about related historical patterns and trends, improving generalization to new scenarios. This knowledge-augmentation approach, by conditioning on past patterns, allows the sub-agent access to a broad spectrum of task-specific knowledge regardless of historical occurrence, enabling it to learn and adapt to diverse trends within complex data for improved predictions. Each sub-agent utilizes pre-trained, SLMs like Gemma[40] and Llama 3[1]. We fine-tune each SLM using instruction-tuning on task-specific datasets and optimize them for time series tasks such as forecasting, imputation, or other related tasks. Additionally, we fine-tune using DPO[8] through a dynamic masking technique to align the SLMs task-specific outputs to preferred and non-preferred outcomes, providing adversarial feedback[47] through a binary classification task. The master agent for sub-agent orchestration utilizes the 'ReAct' prompting technique [45], encouraging the general-purpose SLM to think step-by-step and use external tools (sub-agents, each utilizing a fine-tuned SLM for specific time series tasks) to generate responses. The master agent can even chain sub-agents together to handle complex, multi-step time series analysis tasks, addressing more intricate challenges. However, in this work, the sub-agents operate in isolation, each handling only a single, specific task."}, {"title": "2 PROBLEM FORMULATION", "content": "Consider a time series dataset characterized by N univariate time series, with sequential data collected over T timestamps, represented as a data matrix \\(X \u2208 R^{N\u00d7T}\\). Each row in this matrix represents a univariate time series, and each column corresponds to data collected at a specific timestamp. To refer to data from a specific time series or timestamp, we use subscripts and superscripts, respectively. For instance, \\(X_i = X_{i,:}\\) denotes the data from the i-th time series, and \\(X^t = X_{:,t}\\) denotes the data at timestamp t."}, {"title": "2.1 Forecasting", "content": "We utilize a sliding window [10, 46] of size t, to construct time series subsequences \\(S_t = X_{t-\u03c4+1:t} \u2208 R^{N\u00d7\u03c4}\\), which have been observed over previous t-steps prior to current time step t to predict about the future values for the next v-steps, \\(S_{t+1} = X_{t+1:t+v} \u2208 R^{N\u00d7v}\\)."}, {"title": "2.2 Missing Data Imputation", "content": "We utilize a binary mask matrix \\(M \u2208 {0, 1}^{N\u00d7T}\\), where \\(M_{i,t} = 0\\) indicates that the value \\(X_{i,t}\\) is missing, and \\(M_{i,t} = 1\\) indicates that the value is observed in the data matrix \\(X \u2208 R^{N\u00d7T}\\). Missing data can follow random or block patterns[4, 26, 27] across the N univariate time series and T timestamps. We utilize observed values \\(X^{obs} = X \u2299 M\\) to estimate the missing values \\(X^{miss} = X \u2299 (1-M)\\). \u2299 denotes element-wise multiplication. We utilize a sliding window of size \u03c4 over the observed samples \\(X^{obs}\\), to construct subsequences \\(S_t^{obs} = X_{t-\u03c4+1:t} \u2208 R^{N\u00d7\u03c4}\\), which have been observed over previous t-steps prior to the current time step t. These observed samples are used to predict the missing values for the next v-steps, \\(S_{t+1}^{miss} = X_{t+1:t+v} \u2208 R^{N\u00d7v}\\) by leveraging spatio-temporal dependencies within the data."}, {"title": "2.3 Anomaly Detection", "content": "Assuming the time series dataset exhibits normal behavior during the initial \\(T_{train}\\) timestamps, any pattern deviating from the normal behavior in subsequent timestamps \\(t > T_{train}\\) is anomalous. Data observed after \\(T_{train}\\) is considered the test dataset. We use a sliding window to construct samples from previous time steps \\(S_t \u2208 R^{N\u00d7\u03c4}\\) to predict future values of multiple time series \\(S_{t+1} \u2208 R^{N\u00d7v}\\). The framework predictions are denoted by \\(\\hat{S}_{t+1} \u2208 R^{N\u00d7v}\\). In the unsupervised anomaly detection task, it computes the robust normalized anomaly scores \\((\\hat{A}_{t+1})\\) for each variable i across the time steps in the training set \\(T_{train}\\). This information regarding the variables helps in accurately localizing the anomalies within the test set.\n\\[\\hat{A}_{t+1} = |S_{t+1} - \\hat{S}_{t+1}|\\]\nWe compute the simple moving average of the maximum value of anomalousness score\\((\\hat{A}_{t+1})\\) across the multiple variables at time point t + 1 over the validation set as given,\n\\[Th = \\underset{t\u2208T_{val}}{max}\\ \\hat{A}_{t+1};\\ \\hat{A}_{t+1} =  \\frac{\\sum_{i=1}^{w_a+1} max(\\hat{A}_{t+1})} {|N|}\\]\nwhere \\(w_a\\) denotes the number of time points in the moving average calculation. \\(T_{val}\\) denotes the time points in the validation set. We set the anomaly detection threshold\\((\\hat{Th})\\) as the moving averaged maximum anomaly value for time t + 1, \\(\\hat{A}_{t+1}\\) over the validation data. During inference, time points with an anomaly score above the threshold were flagged as anomalies."}, {"title": "2.4 Classification", "content": "We perform unsupervised K-means clustering, identifying (K) optimal clusters or regimes and assigning cluster labels \\(C\u2208R^T\\) to each time point in the data matrix \\(X \u2208 R^{N\u00d7T}\\). Then, a sliding window approach is employed to predict the cluster labels for the next v steps \\(S_{t+1} = X_{t+1:t+v} \u2208 R^{N\u00d7V}\\) based on the observed sample \\(S_t = X_{t-\u03c4+1:t} \u2208 R^{N\u00d7\u03c4}\\) over the previous t time steps."}, {"title": "3 PROPOSED METHOD", "content": "The proposed framework offers a novel approach to time series analysis by leveraging a hierarchical, multi-agent architecture. It comprises a master agent that coordinates specialized sub-agents, each dedicated to a specific time series task such as forecasting, anomaly detection, or imputation. These sub-agents employ pre-trained language models and utilize prompt pools as internal knowledge bases, storing key-value pairs representing historical patterns and trends. By retrieving relevant prompts from these pools, the sub-agents can augment their predictions with contextual knowledge about related past patterns, enabling them to adapt to diverse trends within complex time series data. The framework's modular design, combined with the strengths of individual sub-agents, allows for improved performance across various time series analysis tasks, surpassing the limitations of traditional fixed-window methods."}, {"title": "3.1 Dynamic Prompting Mechansim", "content": "Current time series methods typically utilize past data within a predefined window length to understand historical trends and predict task-specific outcomes. However, this approach may not be optimal because there is no universally ideal window length for all time series data. A larger window length might obscure short-range dependencies, while a smaller window length might fail to capture long-range dependencies. Existing methods fail to capture the full complexity of diverse trends and patterns within the complex data required for accurate time series modeling. Adjusting the window length in real-world scenarios can be challenging and computationally expensive. Achieving this goal is an ambitious task, given the current state of research in this field. To address the challenges of non-stationarity and distributional shifts in real-world data, we utilize a differentiable dynamic prompting mechanism[3]. This mechanism allows traditional time series methods to access related past knowledge by retrieving the same group of prompts from the prompt pool for effective adaptive learning on new, similar input data. The dynamic prompting approach utilizes a shared pool of prompts stored as key-value pairs. For time series applications, each prompt is represented by a key vector encoding the essential global characteristics associated with that prompt. The corresponding value matrix contains specific knowledge related to those trends or patterns, such as seasonality, cyclicality, irregularities, and other effects. The key vector acts as an identifier or query vector to retrieve relevant prompts from the pool based on similarity to the input new data, providing a form of conditioning or context about historical patterns to enhance the predictions. This allows the time series methods to effectively leverage encoded knowledge from past experiences, enhancing their predictions by recognizing and applying learned patterns from the shared prompt pool to the new input data. The pool of prompts P contains a set of M distinct key-value pairs as follows:\n\\[P = {(k_1, v_1), (k_2, v_2), ..., (k_M, v_M)}\\]\nHere, M is the total number of prompts in the pool, \\(k_m \u2208 R^d\\) is the key vector of the m-th prompt, and \\(v_m \u2208 R^{l\u00d7d}\\) is the corresponding prompt value matrix with length l and dimensionality d. In order to retrieve the most relevant prompts for a given input time series \\(S = X_{\u03c4-1+1:t} \u2208 R^\u03c4\\), we first linearly project it into d-dimensional embeddings \\(\\hat{S} \u2208 R^d\\). We then utilize a score-matching function \u03b3 to measure the similarity between the input and each prompt key:\n\\[\u03b3 (\\hat{S}, k_m) = \\frac{{\\hat{S}k_m}}{|\\hat{S}||k_m|}\\]\nwhere \u03b3 computes the cosine similarity between the input embedding \\(\\hat{S}\\) and the prompt key \\(k_m\\). The top-K prompts with the highest similarity scores are selected, where 1 \u2264 K < M. Let \\(I = {j_1, j_2, ..., j_k}\\) be the set of indices corresponding to the top-K most relevant prompts retrieved from the pool P for the given input time series S. The selected prompts, along with the original input, are concatenated to form the input embedding \\(\bar{S}\\) as follows:\n\\[\\bar{S} = [v_{j_1};...;v_{j_k};\\hat{S}]\\]\nwhere \\(\bar{s} \u2208 R^{(KI+1)\u00d7d}\\). We linearly project s to d-dimensional representation as follows:\n\\[s = W \\bar{s}\\]\nwhere \\(W\u2208 R^{d\u00d7(KI+1)d}\\) is a learnable weight matrix. In summary, it aims to improve time series modeling efficiency on the task-specific performance by allowing the framework to recognize and apply learned patterns across non-stationarity datasets with distributional shifts via the shared prompt representation pool."}, {"title": "3.2 Fine-Tuning/Preference Optimization SLMs", "content": "Current pretrained SLMs, such as Google's Gemma and Meta's Llama-3 models, are designed with a context length of 8K tokens. However, they struggle to process long input sequences that exceed their pretraining context window. This is because the limited length of the context window during pretraining restricts their effectiveness during inference when dealing with longer texts. SLMs with an improved context length can better capture long-term spatio-temporal dependencies and complex patterns that unfold over extended periods, which is essential for accurate predictions and understanding seasonal or cyclic trends. We build upon recent work [19] to improve how SLMs handle long sequences without fine-tuning. A two-tiered attention mechanism (grouped and neighbor attention) allows SLMs to process unseen long-range dependencies, enabling SLMs to naturally handle extended text and maintain performance. It outperforms fine-tuning methods on multiple NLP benchmarks, demonstrating a significant step forward for SLMs in managing long text sequences. Nevertheless, fine-tuning general-purpose SLMs on task-specific data and objectives can still provide significant performance gains and allow for customization and adaptation to the unique challenges and requirements of different time series analysis tasks. Instruction-tuning of SLMs captures complex task-specific spatio-temporal dependencies and improves prediction accuracy. We perform instruction-tuning of SLMs with an improved context length [19](32K tokens) using parameter-efficient fine-tuning (PEFT) techniques on their associated specific tasks (e.g., forecasting, imputation) using the corresponding time-series datasets. This approach could significantly enhance the effectiveness of SLMs in processing extensive time-series data. We leverage Direct Preference Optimization (DPO; [32]), which involves randomly masking 50% of the data and performing binary classification task to predict the corresponding correct task-specific outcomes. This is done to steer the predictions of the SLMs toward more reliable outcomes in the specific context of time series analysis, favoring preferred responses over dispreferred responses."}, {"title": "4 EXPERIMENTS", "content": "Datasets: We evaluate the proposed Agentic-RAG framework on four tasks: forecasting, classification, anomaly detection, and imputation. To comprehensively evaluate the framework performance against several baselines, we conducted experiments using both univariate and multivariate benchmark datasets across multiple time series tasks. The variants include Agentic-RAG with SelfExtend-Gemma-2B-instruct, Gemma-7B-instruct, and Llama 3-8B-instruct. We utilized several real-world traffic-related datasets (PeMSD3, PeMSD4, PeMSD7, PeMSD7(M), PeMSD8) obtained from the Caltrans Performance Measurement System (PeMS) [5] for forecasting, classification, and imputation. To ensure consistency with prior research[7], these datasets are preprocessed by aggregating 30-second data points into 5-minute averages. Additionally, publicly available traffic prediction datasets (METR-LA, PEMS-BAY) [22] are utilized, with data aggregated into 5-minute intervals, resulting in 288 observations per day. For anomaly detection, we evaluate the proposed Agentic-RAG framework on publicly available multivariate datasets, conducting a comprehensive benchmark comparison against baseline methods."}, {"title": "5 RESULTS", "content": "Tables 3-4 present a performance comparison of the Agentic-RAG framework variants with baseline methods on seven benchmark datasets (PeMSD3, PeMSD4, PeMSD7, PeMSD7M, PeMSD8, METR-LA, and PEMS-BAY) on the forecasting task. We report experimental results from a previous study [7] for a fair and rigorous comparison. Tables 5-6 show the performance of Agentic-RAG framework variants on time-series anomaly detection on benchmark datasets. We present experimental results of baseline methods from earlier studies [6, 11, 13, 43]. Our proposed framework outperforms baseline methods across the benchmark datasets, showing significant improvements on the forecasting and anomaly detection tasks. We present experimental results on missing data imputation and classification tasks in the appendix. Experimental results on univariate datasets across all time series tasks are discussed in the appendix."}, {"title": "6 CONCLUSION", "content": "In this work, we propose an Agentic RAG framework to address the challenges of distribution shifts, and fixed-length subsequences in time series analysis. The framework overcomes these challenges by leveraging a hierarchical, multi-agent architecture with specialized sub-agents for various time series tasks. Each sub-agent utilizes a prompt pool as its internal knowledge base to store historical patterns and trends. The sub-agent retrieves relevant prompts and utilizes the corresponding knowledge to improve predictions on new, unseen data. This modular design with task-specific sub-agents and knowledge augmentation outperforms traditional methods in handling complex time series analysis tasks."}, {"title": "A MULTIVARIATE SPATIO-TEMPORAL DATASETS", "content": null}, {"title": "A.1 Missing Data Imputation", "content": "Time series imputation is a critical step in time series analysis. It addresses a common issue in this field: missing values within datasets. These missing values can arise from sensor failures, data transmission errors, or incomplete records. By imputing these gaps, time series imputation ensures the quality and reliability of subsequent analyses. The Agentic-RAG framework achieves this by handling seasonality, trends and capturing the inherent spatio-temporal dependencies within the data. Ultimately, imputation improves data quality, enabling more accurate analysis, modeling, and decision-making. In essence, it plays a vital role by maintaining data integrity and enabling reliable analysis. To evaluate the Agentic-RAG framework's ability to handle missing data, we simulated two types of missingness patterns: point missing and block missing[9, 35]. These patterns represent varying degrees of data availability. To achieve this, we introduced synthetic missingness into time series datasets following these patterns. For point missing, individual values were randomly omitted with a probability threshold (p), controlling the overall percentage of missing data. The block missing pattern involves removing contiguous, multi-period, multi-time series segments. This is done by randomly selecting start and end times, as well as start and end time series, to define uniform blocks with an average length of (1). All data points within each block are then omitted. Furthermore, two block missing patterns are considered: temporal and spatial. For temporal block missing, contiguous multi-period segments are removed from a given time series. This is done by randomly selecting start and end times, creating stretches of unavailable temporal data. For spatial block missing, contiguous blocks are removed across multiple related time series at specific time points. This involves randomly selecting the start and end time series, resulting in missing spatial data at the chosen time points. Both patterns show varying levels of missing information in the time series data. In summary, point missing refers to sporadic gaps in the data, while block missing involves the absence of entire contiguous multi-period and multi-series segments. Block missing can further be categorized into two types: temporal block missing, where contiguous segments are removed within a single time series, and spatial block missing, where contiguous blocks are removed across multiple related time series, mimicking realistic scenarios of faulty data collection. In the context of time series imputation, \"in-sample\" and \"out-of-sample\" imputation refer to distinct evaluation settings. In-sample imputation involves the imputation method reconstructing missing values within a given fixed input sequence, St, using all available observed data within that sequence. Out-of-sample imputation involves training the imputation method using the fixed sequence St to impute missing points in a future sequence, St+1. In this work, we utilize out-of-sample settings, as this approach mimics real-world scenarios and rigorously assesses the Agentic-RAG framework's robustness and generalizability by evaluating its ability to handle new, unseen data. The simulated datasets with missing values were then used to evaluate the missing data handling capabilities of the proposed Agentic-RAG framework. We split multiple benchmark datasets in chronological order with a ratio of 7:1:2 for the METR-LA and PEMS-BAY datasets and a ratio of 6:2:2 for the other datasets into training, validation, and test sets. We evaluated the Agentic-RAG framework's performance on simulated data using multiple imputation metrics (e.g., RMSE, MAE, and MAPE). This analysis helps us understand how well the framework handles time series data with missing values, particularly how its performance changes as the percentage of missing data increases. We establish the Agentic-RAG framework, trained on complete data (no missing values), as a strong performance benchmark. This benchmark allows us to evaluate the framework's effectiveness in imputing missing data under different conditions of data incompleteness. Tables 7 and 8 present the imputation results on standard benchmark datasets with different missingness patterns, while the framework performs slightly worse than the baseline for minimal missing data. Its accuracy degrades more significantly as the data becomes more incomplete, regardless of the specific missingness pattern. Our proposed Agentic-RAG framework demonstrates robustness to missing data by focusing on the available observations for imputing missing values, thereby avoiding the introduction of potentially inaccurate estimates that could obscure the underlying trends and patterns within the time series data. Additionally, the Agentic-RAG framework effectively captures the complex non-linear intra- and inter-time series dependencies and this leads to more reliable imputation. The experiments show that our framework can learn the spatiotemporal dependencies from partially observed data with various missingness patterns, resulting in lower imputation errors."}, {"title": "A.2 Time Series Classification", "content": "Time series classification is a crucial task with applications across various domains. In time series analysis, regimes, or clusters represent distinct behavioral modes, operating conditions, or states of the system underlying the data. Identifying and characterizing these regimes is crucial for understanding the complex patterns and dynamics within the data. This allows for more accurate modeling, forecasting, and decision-making in applications where time series analysis is essential. The emergence of different regimes or clusters can stem from changes in the data generation process, external conditions, or the inherent non-stationarity and multivariate nature of the time series. This reflects the rich information content and complexity often encountered in real-world time series data. To evaluate the proposed Agentic-RAG framework's ability to handle time series classification tasks, an unsupervised clustering approach was employed for data labeling. We first applied k-means clustering to the original time series datasets, determining the optimal number of clusters (k) using established techniques such as the elbow method or silhouette analysis. The optimal clusters were treated as class labels, representing distinct regimes within the time series, and each time series was assigned the corresponding cluster label, creating a labeled classification dataset. We adopted a time-based division strategy to split multiple benchmark datasets into training, validation, and testing sets. The METR-LA and PEMS-BAY datasets were split at a 7:1:2 ratio, while other datasets used a 6:2:2 split. We evaluated the framework's performance on the held-out test set using standard classification metrics: accuracy, precision, recall. This methodology allowed us to assess the framework's ability to learn the underlying patterns and relationships associated with each cluster/class and its overall effectiveness in classifying time series data based on inherent complex spatio-temporal regimes, paving the way for its practical application in real-world scenarios."}, {"title": "B UNIVARIATE DATASETS", "content": "We conducted several experiments to evaluate the proposed Agentic-RAG framework variants: SelfExtend-Agentic-RAG with Gemma-2B, SelfExtend-Agentic-RAG with Gemma-7B, and SelfExtend-Agentic-RAG with Llama-8B, on the univariate datasets for multiple time series analysis tasks such as forecasting and imputation."}, {"title": "B.1 Forecasting and Imputation", "content": "The ETT (Electricity Transformer) datasets [53], ETTh1, ETTh2, ETTm1, and ETTm2, are popular benchmarks used for evaluating and benchmarking univariate time series forecasting methods. They provide a challenging benchmark due to the presence of complex patterns, such as trends, seasonality, and irregularities, which are commonly found in real-world time series data. ETTh1 and ETTh2 are two hourly time series datasets containing observations of electricity transformers from two different locations. ETTm1 and ETTm2 are two monthly time series datasets containing observations of electricity transformers from two different locations. In this work, we utilize the ETT datasets [53] to evaluate the Agentic-RAG framework for both forecasting and missing data imputation tasks. The Table 11 shows the performance of various methods on the multi-horizon forecasting task using a lookback window of size 512. It presents mean squared error (MSE) and mean absolute error (MAE) for nine models (GPT4TS[57], PatchTST[28], TimesNet[42], FEDFormer [55], LightTS[48], N-BEATS[30], Agentic-RAG w/Gemma-2B, Agentic-RAG w/Gemma-7B, and Agentic-RAG w/Llama-8B) across four datasets (ETTh1, ETTh2, ETTm1, ETTm2) at different time horizons (96, 192, 336, 720). This allows for a comprehensive analysis of forecasting accuracy and robustness of Agentic-RAG framework across varying prediction lengths. The performance of various methods for imputing missing data (point and block missing) and their effectiveness in out-of-sample imputation settings are compared in Tables 12 and 13."}, {"title": "C ENVIRONMENTAL IMPACT", "content": "Our Agentic-RAG framework training process, involving multiple variants running for extended periods, increases our energy consumption and carbon footprint. Accurate quantification of the carbon footprint of deep learning experiments is essential for promoting sustainable practices in artificial intelligence research and development. A crucial aspect of this endeavor is estimating the energy consumption and associated greenhouse gas emissions during the computationally intensive training processes. This is calculated by determining the Total Graphics Power (TGP), which represents the maximum power draw of the GPU, including the GPU chip itself and other components like memory and additional circuitry. For example, the NVIDIA P100 GPU has a TGP of 300 watts, while the NVIDIA T4 GPU has a TGP of 70 watts. By multiplying the TGP by the training time, we can estimate the energy consumption, which is then converted to carbon emissions using a region-specific carbon intensity factor. This factor accounts for the energy mix (coal, natural gas, renewables, etc.) used to generate electricity in the geographic area where the computations are performed. Considering a 725-GPU hours training experiment and using an estimated carbon intensity factor of 0.0007 metric tons CO2e per kWh for the year 2024 (for more information on the carbon intensity of electricity, you can visit CO2 Intensity - Our World in Data), the calculated carbon footprint would be 152.25 kg CO2e for the NVIDIA P100 GPU and 35.525 kg CO2e for the NVIDIA T4 GPU. Note: kg CO2e stands for kilograms of carbon dioxide equivalent. The average person in the United States emits approximately 43.8 kg of carbon dioxide equivalent (CO2e) per day. Given the emissions of 152.25 kg CO2e for the NVIDIA P100 GPU and 35.525 kg CO2e for the NVIDIA T4 GPU, it would take a single person's emissions approximately 3.5 days to match the emissions of the P100 GPU and approximately 0.8 days (or 19 hours) to match the emissions of the T4 GPU. While the calculated carbon footprint provides valuable insight, the actual energy consumption and resulting emissions may vary due to factors like GPU utilization and regional energy sources. Nonetheless, quantifying the carbon footprint is a crucial step towards understanding and mitigating the environmental impact of deep learning research, paving the way for more sustainable and responsible practices in artificial intelligence."}, {"title": "D HYPERPARAMETER OPTIMIZATION", "content": "Hyperparameter optimization involves training the Agentic-RAG framework variants multiple times with different hyperparameter settings. This can be computationally expensive, especially for complex pre-trained language models or large datasets. We optimized the hyperparameters for the best-performing Agentic-RAG w/Llama-8B variant. For simplicity and in the interest of time, we have utilized the same settings for evaluating the performance of Agentic-RAG with w/Gemma-2B and w/Gemma-7B variants for both multivariate and univariate datasets across all tasks. In our experiments, we optimized the training process for supervised fine-tuning using a batch size from {16, 32, 64}, learning rate from {1e-5, 5e-5, 1e-4}. The training was conducted over epochs in the range of {10, 15, 20} with a warmup step count from {500, 1000, 1500} and a weight decay for regularization from {0.01, 0.05, 0.1}. We used gradient accumulation steps for stabilized training convergence from {2, 4, 8} and employed the AdamW optimizer. To manage memory and computational efficiency, we applied 4-bit quantization for QLORA, with hyperparameters including a low-rank ('r') from {16, 32, 64}, an ('a') from {32, 64, 128}, and a dropout from {0.05, 0.1, 0.2}. For preference tuning, the hyperparameter ('\u03b2') was set in the range of {0.2, 0.4, 0.6} and learning rate from {5.0e - 7, 1.0e - 6, 5.0e - 6}. The optimal hyperparameters for training were chosen to achieve a balance between performance and computational efficiency. The optimal hyperparameters for supervised fine-tuning were a batch size of 16 and a learning rate of 1e-5, trained over 15 epochs with 500 warmup steps and a weight decay of 0.01, utilizing the AdamW optimizer. Gradient accumulation steps were set to 2. QLoRA quantization was applied with 4-bit precision, and its specific hyperparameters included a low-rank (r') of 16, an alpha (a') of 32, and a dropout rate of 0.05. Preference optimization was performed with a learning rate of 5.0e-7 over 3 epochs and a beta value of 0.2."}, {"title": "E ABLATION STUDY", "content": "To understand the contribution of each component within our proposed Agentic-RAG framework", "conducted": "n\u2022 (a) Effect of dynamic prompting mechanism(DPM):\nWe compared the performance of the Agentic-RAG framework with and without the dynamic prompting mechanism.\n\u2022 (b) Role of sub-agent specialization(SAS):\nWe evaluated the Agentic-RAG framework using a single", "fine-tuning(NIT)": "nWe compared the performance of SLMs with instruction-tuning against their performance without any fine-tuning.\n\u2022 (d) Effectiveness of direct preference optimization (DPO):\nWe evaluated the framework's performance with and without DPO and assessed how aligning SLMs with preferred outcomes impacts the accuracy and reliability of predictions.\nOur study investigates the impact of different components on the overall performance of the"}]}