{"title": "MetaDE: Evolving Differential Evolution by Differential Evolution", "authors": ["Minyang Chen", "Chenchen Feng", "Ran Cheng"], "abstract": "As a cornerstone in the Evolutionary Computation (EC) domain, Differential Evolution (DE) is known for its simplicity and effectiveness in handling challenging black-box optimization problems. While the advantages of DE are well-recognized, achieving peak performance heavily depends on its hyperparameters such as the mutation factor, crossover probability, and the selection of specific DE strategies. Traditional approaches to this hyperparameter dilemma have leaned towards parameter tuning or adaptive mechanisms. However, identifying the optimal settings tailored for specific problems remains a persistent challenge. In response, we introduce MetaDE, an approach that evolves DE's intrinsic hyperparameters and strategies using DE itself at a meta-level. A pivotal aspect of MetaDE is a specialized parameterization technique, which endows it with the capability to dynamically modify DE's parameters and strategies throughout the evolutionary process. To augment computational efficiency, MetaDE incorporates a design that leverages parallel processing through a GPU-accelerated computing framework. Within such a framework, DE is not just a solver but also an optimizer for its own configurations, thus streamlining the process of hyperparameter optimization and problem-solving into a cohesive and automated workflow. Extensive evaluations on the CEC2022 benchmark suite demonstrate MetaDE's promising performance. Moreover, when applied to robot control via evolutionary reinforcement learning, MetaDE also demonstrates promising performance. The source code of MetaDE is publicly accessible at: https://github.com/EMI-Group/metade.", "sections": [{"title": "I. INTRODUCTION", "content": "The Differential Evolution (DE) [1-4] algorithm, introduced by Storn and Price in 1995, has emerged as a cornerstone in the realm of evolutionary computation (EC) for its prowess in addressing complex optimization problems across diverse domains of science and engineering. DE's comparative advantage over other evolutionary algorithms is evident in its streamlined design, robust performance, and ease of implementation. Notably, with just three primary control parameters, i.e., scaling factor, crossover rate, and population size, DE operates efficiently. This minimalistic design, paired with a lower algorithmic complexity, positions DE as an ideal candidate for large-scale optimization problems. Its influential role in the optimization community is further cemented by its extensive research attention and successful applications over the past decades [5-7], with DE and its derivatives often securing top positions in the IEEE Congress on Evolutionary Computation (CEC) competitions.\nDespite the well recognized performance, DE is not without limitations. Particularly, some studies indicate that DE's optimization process may stagnate if it fails to generate offspring solutions superior to their parents [8, 9]. To avert this stagnation, selecting an appropriate parameter configuration to enhance DE's search capabilities becomes crucial.\nHowever, the No Free Lunch (NFL) theorem [10] suggests that a universally optimal parameter configuration is unattainable. For example, while a higher mutation factor may aid in escaping local optima, a lower crossover probability might be preferable for problems with separability characteristics.\nTo address the intricate challenge of parameter configuration in DE, researchers often gravitate towards two predominant strategies: parameter control and parameter tuning [11-13]. Parameter control is a dynamic approach wherein the algorithm's parameters are adjusted on-the-fly during its execution. This adaptability allows the algorithm to respond to the evolving characteristics of the problem landscape, enhancing its chance of finding optimal or near-optimal solutions. Notably, DE has incorporated this strategy in several of its variants. For instance, jDE [14] adjusts the mutation factor and crossover rate during the run, while SaDE [15] dynamically chooses a mutation strategy based on its past success rates. Similarly, JaDE [16] and CoDE [17] employ adaptive mechanisms to modify control parameters and mutation strategies, respectively.\nIn contrast, parameter tuning is a more static methodology, wherein the optimal configuration is established prior to the algorithm's initiation. It aims to discover a parameter set that consistently demonstrates robust performance across various runs and problem instances. Despite its potential for reliable outcomes, parameter tuning is known for its computational intensity, often necessitating dedicated optimization efforts or experimental designs to identify the optimal parameters, which may explain its limited exploration in the field. Viewed as an optimization challenge, parameter tuning is also referred to as meta-optimization [18]. This perspective gave rise to MetaEA, which optimizes the parameters of an EA using another EA.\nDespite MetaEA's methodological elegance and simplicity, it confronts the significant challenge of depending on extensive function evaluations. Fortunately, the inherent parallelism within MetaEA, across both meta-level and base-level populations, renders it particularly amenable to parallel computing environments. However, a notable disparity exists between methodological innovations and the availability of advanced computational infrastructures, thus limiting MetaEA's potential due to the lack of advanced hardware accelerations such as GPUs. To bridge this gap, we introduce the MetaDE approach, which embodies the MetaEA paradigm by employing DE in a meta-level to guide the evolution of a specially tailored Parameterized Differential Evolution (PDE).\nDesigned with adaptability in mind, PDE can flexibly adjust its parameters and strategies, paving the way for a wide range of DE configurations. As PDE interacts with the optimization problem at hand, the meta-level DE observes and refines PDE's settings to better align with the problem's characteristics. Amplifying the efficiency of this nested optimization approach, MetaDE is integrated with a GPU-accelerated EC framework, thus weaving together parameter refinement and direct problem-solving into a seamless end-to-end approach to black-box optimization. In summary, our main contributions are as follows."}, {"title": "II. PRELIMINARIES", "content": "1) Overview of DE: As a typical EC algorithm, DE's essence lies in its differential mutation mechanism that drives the evolution of a population. The operational cycle of DE unfolds iteratively, with each iteration embodying specific phases, as elaborated in Algorithm 1:\n\nDE progresses through cycles of mutation, crossover, and selection, persisting until it encounters a termination criterion. This could manifest as either reaching a predefined number of generations or achieving a target fitness threshold. The algorithm's adaptability allows for the spawning of myriad DE variants by merely tweaking its mutation and crossover operations. Specifically, DE variants follow a unified naming convention: DE/x/y/z, where x identifies the base vector used for mutation, y quantifies the number of difference involved, and z typifies the crossover method employed. For example, the DE variant as presented in Algorithm 1 is named as DE/rand/1/bin."}, {"title": "2) Parameter Modulation in DE", "content": "DE employs a unique mutation mechanism, which adapts to the problem's natural scaling. By adjusting the mutation step's size and orientation to the objective function landscape, DE embraces the contour matching principle [20], which promotes basin-to-basin transfer for enhancing the convergence of the algorithm.\nAt the core of DE's mutation is the scaling factor F. This factor not only determines the mutation's intensity but also governs its trajectory and ability to bypass local optima. Commonly, F is set within the [0.5, 1] interval, with a starting point often at 0.5. While values outside the [0.4,1] range can sometimes yield good results, an F greater than 1 tends to slow convergence. Conversely, values up to 1 generally promise swifter and more stable outcomes [21]. Nonetheless, to deter settling at suboptimal solutions too early, F should be adequately elevated.\nParallel to mutation, DE incorporates a uniform crossover operator, which is often labeled as discrete recombination or binomial crossover in the GA lexicon. The crossover constant CR also plays a pivotal role, which determines the proportion of decision variables to be exchanged during the generation of offspring. A low value for CR ensures only a small portion of decision variables are modified per iteration, thus leading to axis-aligned search steps. As CR increases closer to 1, offspring tend to increasingly reflect their mutant parent, thereby curbing the generation of orthogonal search steps [5].\nFor classical DE configurations, such as DE/rand/1/bin, rotational invariance is achieved only when CR is maxed out at 1. Here, the crossover becomes wholly vector-driven, and offspring effectively mirror their mutants. However, the optimal CR is intrinsically problem-dependent. Empirical studies recommend a CR setting within the [0, 0.2] range for problems characterized by separable decision variables. Conversely, for problems with non-separable decision variables, a CR in the proximity of [0.9, 1] is more effective [5].\nThe adaptability of DE is evident in its wide spectrum of variants, each distinct in its mutation and crossover strategies with delicate parameter modulations. In the following, we will detail seven mutation strategies and three crossover strategies, all of which are widely-recognized in state-of-the-art DE variants. Here, the subscript notation in x specifies the individual selection technique. For instance, xr and Xbest correspond to randomly selected and best-performing individuals respectively, whereas xi represents the currently evaluated individual."}, {"title": "Mutation Strategies:", "content": "1. DE/rand/1:\n$v_i = x_{r_1} + F \\cdot (x_{r_2} - x_{r_3}).$ (1)\n\n2. DE/best/1:\n$v_i = x_{best} + F \\cdot (x_{r_1} - x_{r_2}).$ (2)\n\n3. DE/rand/2:\n$v_i = x_{r_1} + F \\cdot (x_{r_2} - x_{r_3}) + F \\cdot (x_{r_4} - x_{r_5}).$ (3)\n\n4. DE/best/2:\n$v_i = x_{best} + F \\cdot (x_{r_1} - x_{r_2}) + F \\cdot (x_{r_3} - x_{r_4}).$ (4)\n\n5. DE/current-to-best/1:\n$v_i = x_i + F \\cdot (x_{best} - x_i) + F \\cdot (x_{r_1} - x_{r_2}).$ (5)\n\n6. DE/current-to-pbest/1:\n$v_i = x_i + F \\cdot (x_{pbest} - x_i) + F \\cdot (x_{r_1} - x_{r_2}).$ (6)\n\n7. DE/current-to-rand/1:\n$u_i = x_i + K_i \\cdot (x_{r_1} - x_i) + F \\cdot (x_{r_2} - x_{r_3}).$ (7)\nHere, $K_i$ is a random number from U(0, 1). This strategy, originally proposed in [22], emphasizes rotational invariance. By bypassing the crossover phase, it directly yields the trial vector u. Thus, it is ideal for addressing non-separable rotation challenges and has been a cornerstone for multiple adaptive DE variations."}, {"title": "Crossover Strategies:", "content": "1. Binomial Crossover:\n$u_{i,j} =\n\\begin{cases}\nv_{i,j},& \\text{if } r < CR \\text{ or } j = j_{rand}\\\\\nx_{i,j},& \\text{otherwise,}\n\\end{cases}$ (8)\n\n2. Exponential Crossover:\n$u_{i,j} =\\begin{cases}\nv_{i,j}& \\text{if } j = (n)_d, (n + 1)_d, ..., (n + L - 1)_d\\\\\nx_{i,j}& \\text{otherwise,}\n\\end{cases}$ (9)\n\n3. Arithmetic Recombination:\n$u_i = x_i + K_i \\cdot (v_i - x_i),$ (10)\n$u_i = x_i + K_i \\cdot (v_i - x_i)$\n$= x_i + K_i(x_{r_1} + F \\cdot (x_{r_2} - x_{r_3}) - x_i)$\n$= x_i + K_i \\cdot (x_{r_1} - x_i) + K_i \\cdot F(x_{r_2} - x_{r_3}),$ (11)"}, {"title": "3) Adaptive DE", "content": "The development of parameter adaption in DE has witnessed significant advancements over time, from initial endeavors in parameter adaptation to recent sophisticated methods that merge multiple strategies. This subsection traces the chronological advancements, emphasizing the pivotal contributions and their respective impacts on adaptive DE.\nThe earliest phase in DE's adaption centered on the modification of the crossover rate CR. Pioneering algorithms such as SPDE [23] incorporated CR within the parameter set of individuals, enabling its simultaneous evolution with the decision variables of the problem to be solved. This strategy was further refined by SDE [24], which assigned CR for each individual based on a normal distribution. Subsequent research efforts shifted focus to the scaling factor F. In this context, DETVSF [25] dynamically adjusted F, fostering exploration during the algorithm's nascent stages and pivoting to exploitation in later iterations. Building on this, FaDE [26] employed fuzzy logic controllers to optimize mutation and crossover parameters.\nThe DESAP [27] algorithm marked a significant paradigm shift by introducing self-adapting populations and encapsulating control parameters within individuals. Successive contributions like jDE [14], SaDE [15], and JaDE [16] accentuated the significance of parameter encoding, integrated innovative mutation strategies, and emphasized archiving optimization trajectories using external repositories. Further, EPSDE [21] and CODE [17] enhanced the offspring generation process, amalgamating multiple strategies with randomized parameters.\nThe contemporary landscape of adaptive DE is characterized by complex methodologies and refined strategies. Algorithms such as SHADE [28] and LSHADE [29] championed the utilization of success-history mechanisms and dynamic population size modifications. Notable developments like ADE [30] introduced a biphasic parameter adaptation mechanism. The domain further expanded with algorithms like LSHADE-RSP [31], IMODE [32], and LADE [33], emphasizing mechanisms such as selective pressure, the integration of multiple DE variants, and the automation of the learning process.\nUndoubtedly, the adaptive DE domain has witnessed transformative growth, with each phase of its evolution contributing to its current sophistication. However, despite these advancements, many adaptive strategies remain empirical and hinge on manual designs, while their effectiveness is not universally guaranteed."}, {"title": "B. Distributed DE", "content": "The integration of distributed (i.e., multi-population) strategies also significantly enhances the efficacy of DE. Leading this advancement, Weber et al. conducted extensive research on scale factor interactions and mechanisms within a distributed DE framework [34-36], followed by ongoing developments along the pathway [7]. For example, some works such as EDEV [37], MPEDE [38] and IMPEDE [39] adopted multi-population frameworks to ensemble various DE variants/operators, while the other works such as DDE-AMS [40] and DDE-ARA [41] employed multiple populations for adaptive resource allocations.\nDespite the achievements, current implementations of distributed DE often focus predominantly on algorithmic improvements, while overlooking potential enhancements from advanced hardware accelerations such as GPU computing. Besides, the design of these distributed strategies often features intricate and rigid configurations that lack proper flexibility."}, {"title": "C. MetaEAS", "content": "Generally, the term meta refers to a higher-level abstraction of an underlying concept, often characterized by its recursive nature. In the context of EC, inception of the Meta Evolutionary Algorithms (MetaEAs) can be traced back to the pioneering works of Mercer and Sampson [42] in the late 1970s. Under the initiative termed meta-plan, their pioneering efforts aimed at enhancing EA performance by optimizing its parameters through another EA. Although sharing similarities with hyperheuristics [43\u201345], a major difference distinguishes MetaEAs: while hyperheuristics often delve into selecting and fine-tuning a set of predefined algorithms, MetaEAs concentrate on the paradigm of refining the parameters of EAs by EAs. Notably, MetaEAs are also akin to ensemble of algorithms, such as EDEV [37] and CoDE [17], which amalgamate diverse algorithms to ascertain the most efficacious among them.\nAdvancing the meta-plan concept, MetaGA [46] emerged as a significant milestone. Here, a genetic algorithm (GA) was deployed to fine-tune six intrinsic control parameters, namely: population size, crossover rate, mutation rate, generation gap, scaling window, and selection strategy. The efficacy of this approach was gauged using dual metrics: online and offline performance.\nThe evolution of the concept continued with MetaEP [47], which offers a meta-level evolutionary programming (EP) that could concurrently evolve optimal parameter settings. Another pivotal contribution was the Parameter Relevance Estimation and Value Calibration (REVAC) [48], which served as a meta estimation of distribution algorithm (MetaEDA). Utilizing a GA at its core, REVAC iteratively discerned promising parameter value distributions within the configuration space. Innovations in the domain persisted with the Gender-based GA (GGA) [49], inspired by natural gender differentiation, and other notable methods like MetaCMAES [50]. As articulated in the PhD thesis by Pedersen [18], a profound insight into MetaEA revealed that while contemporary optimizers endowed with adaptive behavioral parameters offered advantages, they were often eclipsed by streamlined optimizers under appropriate parameter tuning. This thesis, which embraced DE as one of its optimization tools, employed the Local Unimodal Sampling (LUS) heuristic for tuning parameters such as NP, F, and CR.\nCulminating the discourse, the work in [51] demonstrated the scalability of MetaEAs by harnessing it within a large-scale distributed computing environment. With the (\u03bc, \u03bb)-ES steering the meta-level tuning, base-level algorithms like GA, ES, and DE were adeptly optimized. For DE, parameters optimized encompassed NP, mutation operator, F, CR, and PF (parameter for the either-or strategy), enhancing MetaEAs' prowess in addressing intricate, large-scale optimization problems. Recently, the MetaEA paradigm has also been employed for automated design of ensemble DE [52].\nThe field of MetaEAs has shown steady progress since its inception in the 1970s. However, despite the achievements, the landscape of MetaEAs research still confronts certain limitations. Notably, the research, while promising, has predominantly remained confined to smaller-scale implementations. The anticipated leap to large-scale experiments, especially those that might benefit from GPU acceleration, remains largely uncharted. This underscores an imperative need for more extensive empirical validations and the exploration of contemporary computational resources to fully realize the potential of MetaEAs."}, {"title": "D. GPU-accelerated EC Framework", "content": "To capitalize on the advancements of modern computing infrastructures, we have seamlessly integrated our proposed MetaDE with EvoX [19], a distributed GPU-accelerated computing framework for scalable EC. This integration ensures that MetaDE enables efficient execution and optimization for large-scale evaluations.\nThe EvoX framework provides several distinctive features. Primarily, it is designed for optimal performance across diverse distributed systems and is tailored to manage large-scale challenges. Its user-friendly functional programming model simplifies the EC algorithm development process, reducing inherent complexities. The framework cohesively integrates data streams and functional elements into a comprehensive workflow, underpinned by a sophisticated hierarchical state management system. Moreover, EvoX features a rich library of EC algorithms, proficient in addressing a wide array of tasks, from black-box optimization to advanced areas such as deep neuroevolution and evolutionary reinforcement learning."}, {"title": "III. PROPOSED APPROACH", "content": "The foundational premise of MetaDE is to utilize a core DE algorithm to evolve an ensemble of parameterized DE variants. Within this framework, the core DE, which tunes the parameters, is termed the evolver. In contrast, each parameterized DE variant, which optimizes the problem at hand, is termed the executor. This section commences by augmenting the parameterization of DE in a more general manner, such that DE is made evolvable by spawning various DE variants by modulating the parameters. Then, this section details the integration of proposed MetaDE within a meta-framework, together with a brief introduction to the GPU-accelerated implementation."}, {"title": "A. Augmented Parameterization of DE", "content": "To make DE evolvable, this subsection introduces the Parameterized Differential Evolution (PDE), an extension of the standard DE designed to augment its flexibility through the parameterization of mutation and crossover strategies. While PDE retains the foundational principles of standard DE, its distinctiveness lies in its capability to generate a multitude of strategies by modulating the parameters.\nIn the standard DE framework, tunability is constrained to the adjustments of the F and CR parameters, and strategies are bound by predefined rules. To augment this limited flexibility, PDE introduces a more granular parameterization. Building upon DE's notation DE/x/y/z, PDE encompasses six parameters: F (scale factor), CR (crossover rate), bl (base vector left), br (base vector right), dn (difference number), and cs (crossover scheme). The combined roles of bl and br determine the base vector, leading to a strategy notation for PDE expressed as DE/bl-to-br/dn/cs.\nEach parameter's nuances and the array of strategy combinations they enable are elaborated upon in the subsequent sections.\n1) Scale Factor Fand Crossover Rate CR: The scale factor F and crossover rate CR serve as pivotal parameters in DE, both represented as real numbers.\n2) Augmented Parameterization of Mutation: The distinctiveness of PDE lies in its ability to generate a multitude of mutation strategies by modulating parameters bl, br, and dn.\n3) Augmented Parameterization of Crossover: Parameter cs defines the crossover strategies in PDE, comprising those elaborated in Section II-A: binomial crossover, exponential crossover, and arithmetic recombination. Specifically, cs is encoded as: 1: bin, 2: exp, and 3: arith, representing"}, {"title": "Algorithm 2 Parameterized DE (PDE)", "content": "Input: D, NP, $G_{max}$, F, CR, bl (base vector left), br (base vector right), dn (difference number), cs (crossover scheme)\n1: Initialize population $X = \\{x_1, x_2,..., x_{NP}\\}$\n2: Evaluate the fitness of each individual in the population\n3: Generate mutation function M(X) according to bl, br, dn:\n$v = x_{bl} + F \\cdot (x_{br} \u2014 x_{bl}) + F \\cdot (\\Delta_1 + ... + \\Delta_{dn})$\n4: According to cs, choose a crossover function C(V, X) in (8-10)\n5: g = 0\n6: while $g G_{max}$ do\n7: Generate NP mutant vectors: V = M(X)\n8: Perform crossover for all mutant vectors: U = C(V, X)\n9: Evaluate the fitness of U\n10: Make selection between U and X\n11: g=g+1\n12: end while\n13: return the best fitness"}, {"title": "B. Architecture of MetaDE", "content": "Atop the proposed PDE, this subsection further introduces the architecture of MetaDE. The main target of MetaDE is to evolve the parameters of PDE through an external DE, empowering PDE to identify optimal parameters tailored to the target problem.\nAs illustrated in Fig. 2, MetaDE is structured with a two-tiered optimization architecture. The upper tier, termed the evolver, leverages DE to evolve the parameters of PDE. In contrast, the lower tier consists of a collection of executors that each run the parameterized PDE instance to optimize the objective function. Every individual in the evolver, represented as xi, is decoded into a parameter configuration \u03b8i with six elements: F, CR, bl, br, dn, and cs. For the evaluation of each individual, the configuration \u03b8 is directed to its respective executor PDEi for objective function optimization. The final fitness y* as identified by each executor, is subsequently set as the fitness of the corresponding xi individual.\nThe architecture of MetaDE is streamlined for simplicity. Building upon this architecture, MetaDE integrates two tailored components: the one-shot evaluation method and the power-up strategy. These components further enhance the adaptability and efficiency of the executors, thereby elevating the overall performance of MetaDE."}, {"title": "C. One-shot Evaluation Method", "content": "Within the context of an executor driven by DE itself, the inherent stochastic nature can lead to variability in the optimal fitness values returned. Historically, several evaluation techniques, such as repeated evaluation [53], F-racing [54], and intensification [55], have been put forth to tackle this inconsistency. Yet, these often come at the cost of an exorbitant number of functional evaluations (FEs). To address this issue, we introduce the one-shot evaluation method.\nSpecifically, the method mandates each executor to undertake a singular, comprehensive independent run, subsequently returning its best-found solution. A distinguishing aspect of this method is the consistent allocation of the same initial random seed to every executor. As the algorithm progresses, this uniform seed ensures that the PDE fine-tunes its parameters in a consistent manner, thereby identifying optimal parameters tailored to the given seed environment. Essentially, this strategy embeds the seed as an integral facet of the problem domain."}, {"title": "D. Power-up Strategy", "content": "During the independent runs of an executor, the allocation of FEs plays a pivotal role in determining both the quality of solutions and computational efficiency. Allocating an excessive number of FEs indiscriminately can lead to undue computational resource consumption without necessarily improving solution quality. To address this issue, we propose the power-up strategy.\nThe essence of this strategy is dynamic FE allocation: while earlier iterations receive a moderate number of FEs to ensure resource efficiency, a more generous allocation (fivefold) is reserved for the terminal iteration within the evolutionary process. This strategy ensures that the executor has the resources for a thorough and comprehensive evaluation during its most crucial phase \u2013 the final generation of the evolver."}, {"title": "E. Implementation", "content": "As outlined in Algorithm 3, MetaDE draws its simple algorithmic workflow from conventional DE. MetaDE adopts DE/rand/1/bin as the evolver. The initialization phase (Line 1) spawns the MetaDE population within the parameter boundaries [lb, ub]. During the evaluation phase (Lines 6-11), each individual is decoded into a parameter blueprint and directed to an independent PDE instance (executor) for problem resolution. Running for a predetermined iteration count G', each executor subsequently reports the best fitness. Notably, Line 10 encapsulates the essence of the power-up strategy: for MetaDE's concluding iteration (g = Gmax), the evaluation quota is amplified to 5 \u00d7 G' for the executors."}, {"title": "Algorithm 3 MetaDE", "content": "Input: D, NP, $G_{max}$, lb (lower boundaries of PDE's parameters),\nub (upper boundaries of PDE's parameters), NP' (population\nsize of PDE), G' (max generations of PDE)\n1: Initialize population $X = \\{x_1, x_2,..., x_{NP}\\}$ between [lb, ub]\n2: Initialize the fitness of X: y = inf\n3: g = 0\n4: while $g G_{max}$ do\n5: Generate trial vectors U by mutation and crossover\n6: /* The mutation and crossover scheme used is rand/1/bin */\n7: Decode each trial vector u into parameters:\nF = u[1], CR = u[2], bl = floor(u[3]), br = floor(u[4]),\ndn = floor(u[5]), cs = floor(u[6])\n8: if g $G_{max}$ then\n9: y = PDE(D, NP', G', F, CR, bl, br, dn, cs)\n10: else\n11: y = PDE(D, NP', 5 * G', F, CR, bl, br, dn, cs)\n12: end if\n13: Make selection between U and X\n14: g=g+1\n15: end while\n16: return the best individual and fitness"}, {"title": "IV. EXPERIMENTAL STUDY", "content": "In this section, we conduct detailed experimental assessments of MetaDE's capabilities. First, we comprehensively benchmark MetaDE against several representative DE variants and CEC2022 top algorithms to gauge its relative performance on the CEC2022 benchmark suite [56]. Then, we investigate the optimal DE variants obtained by MetaDE in the benchmark experiment. Finally, we apply MetaDE to robot control tasks.\nAll experiments were conducted on a system equipped with an Intel Core i9-10900X CPU and an NVIDIA RTX 3090 GPU. For GPU acceleration, all the algorithms and test functions were implemented within EvoX [19]."}, {"title": "A. Benchmarks against Representative DE Variants", "content": "1) Experimental Setup: The CEC2022 benchmark suite for single-objective black-box optimization was utilized for this study. This suite includes basic (F\u2081 - F5), hybrid (F6 - F8), and composition functions (F9 - F12), catering to various optimization characteristics such as unimodality/multimodality and separability/non-separability.\nFor benchmark comparisons, we selected seven representative DE variants: DE (rand/1/bin) [4], SaDE [15], JaDE [16], CoDE [17], SHADE [28], LSHADE-RSP [31], and EDEV [37], which encapsulate a spectrum of mutation, crossover, and adaptation strategies. All algorithms were reimplemented using EvoX, with each capable of running in parallel, including the concurrent evaluation and reproduction. Their respective descriptions are as follows:\n2) Performance under Equal Wall-clock Time: In this part, we set equal wall-clock time (60 s) as the termination condition for running each test. This approach aligns with the practical constraints of modern GPU computing, where execution time serves as a more meaningful and comparable measure of performance across algorithms. Since all algorithms in our experiments are implemented with GPU parallelism, this setup ensures fairness by standardizing the computational resources and focusing on efficiency within the same time budget.\nSpecifically, MetaDE adopted the same population size setting as in previous experiments (i.e., 100 for both evolver and executor), while the population size of the other DE variants was increased to 1,000. This adjustment significantly enhances the concurrency of the other DE variants when utilizing GPU accelerations, thereby preventing insufficient convergence."}, {"title": "B. Comparisons with Top Algorithms in CEC2022 Competition", "content": "To further assess the performance of MetaDE, we compare it with the top 4 algorithms from the CEC2022 Competition on Single Objective Bound Constrained Numerical Optimization.\nThe top 4 algorithms from the CEC2022 Competition are EA4eig [57], NL-SHADE-LBC [58], NL-SHADE-RSP-MID [59], and S-LSHADE-DP [60]:"}, {"title": "C. Investigation of Optimal DE Variants", "content": "This part provides an in-depth examination of the optimal DE variants obtained by MetaDE in Section IV-A2, as summarized in Table VI. The optimal parameters correspond to the best individual in the final population of MetaDE. The table only displays the optimal parameters for the ten listed problems, as the remaining problems are relatively simpler, with numerous DE variants capable of locating the optimal solutions of the problems. Furthermore, the optimal parameters presented in the table represent the best results of MetaDE derived from the finest run out of 31 independent trials.\nAll the problems in the table are characterized by both multimodality and non-separability. Additionally, to further depict the characteristics of the problems' fitness landscapes, we computed both the fitness distance correlation (FDC) [61] and the ruggedness of information entropy (RIE) [62]; the former measures the complexity (difficulty) of the problems, while the latter characterizes the ruggedness of the landscape.\nAnalyzing the obtained data, it is evident that no single set of parameters or strategies consistently excels across all problems. Parameters such as F and CR exhibit variability across problems without adhering to a specific trend. Similarly, the selection of base vectors (bl and br) does not show a uniform preference either. Regarding the fitness landscape characteristics of each problem, the selection of parameters exhibits distinct patterns.\nThese observations align with the No Free Lunch (NFL) theorem [10], thus underscoring the importance of distinct optimization strategies tailored for diverse problems. Conventionally, the optimization strategies have oscillated between seeking a generalist set of parameters for broad applicability and a specialist set tailored for specific problems. However, the dynamic nature of optimization problems, where even minute changes like a different random seed can pivot the problem's dynamics, highlights the challenges of a generalist approach. In contrast, MetaDE provides a simple yet effective approach, showing promising generality and adaptability."}, {"title": "D. Application to Robot Control", "content": "In this experiment, we demonstrate the extended application of MetaDE to robot control. Specifically, we adopted the evolutionary reinforcement learning paradigm [63] as illustrated in Fig. 8. The experiment was conducted on Brax [64] for robotics simulations with GPU acceleration."}, {"title": "Fig. 8: Illustration of robot control via evolutionary reinforcement learning.", "content": "The evolutionary algorithm optimizes the parameters of a population of candidate policy models for controlling the robotics behaviors. The simulation environment returns rewards achieved by the candidate policy models to the evolutionary algorithm as fitness values.\nThis experiment involved three robot control tasks: \"swimmer\", \"hopper\", and \"reacher\". As summarized in Table VII, we adopted similar policy models for these three tasks, each consisting of a multilayer perceptron (MLP) with three fully connected layers, but with different input and output dimensions. Consequently, the three policy models comprise 1410, 1539, and 1506 parameters for optimization respectively, where the optimization objective is to achieve maximum reward of each task. MetaDE, vanilla DE [1", "28": "LSHADE-RSP [31", "37": "CSO [2", "66": "were applied as the optimizer respectively.\nThe iteration count for PDE within MetaDE was set to 50, while other algorithms maintained a population size of 100. Each algorithm was run independently 15 times. Considering the time-intensive nature of the robotics simulations, we set 60 minutes as the termination condition for each run.\nAs shown in Fig. 9, it is evident that MetaDE achieves the best performance in the Swimmer tasks, while slightly outperformed by CMA-ES and CSO in the Hopper and Reacher task. An interesting observation from the reward curves is that MetaDE almost reaches optimality nearly at the first generation and does not show further significant improvements thereafter. To elucidate this phenomenon, Fig. 10 provides the fitness distribution of MetaDE's initial population, indicating that MetaDE harbored several individuals with considerably high fitness from the initial generation. In other words, MetaDE was able to generate high-performance DE variants for these problems even by random sampling. This can be"}]}