{"title": "Human-like object concept representations emerge naturally in multimodal large language models", "authors": ["Changde Du", "Kaicheng Fu", "Bincheng Wen", "Yi Sun", "Jie Peng", "Wei Wei", "Ying Gao", "Shengpei Wang", "Chuncheng Zhang", "Jinpeng Li", "Shuang Qiu", "Le Chang", "Huiguang He"], "abstract": "The conceptualization and categorization of natural objects in the human mind have long intrigued cognitive scientists and neuroscientists, offering crucial insights into human perception and cognition. Recently, the rapid development of Large Language Models (LLMs) has raised the attractive question of whether these models can also develop human-like object representations through exposure to vast amounts of linguistic and multimodal data. In this study, we combined behavioral and neuroimaging analysis methods to uncover how the object concept representations in LLMs correlate with those of humans. By collecting large-scale datasets of 4.7 million triplet judgments from LLM and Multimodal LLM (MLLM), we were able to derive low-dimensional embeddings that capture the underlying similarity structure of 1,854 natural objects. The resulting 66-dimensional embeddings were found to be highly stable and predictive, and exhibited semantic clustering akin to human mental representations. Interestingly, the interpretability of the dimensions underlying these embeddings suggests that LLM and MLLM have developed human-like conceptual representations of natural objects. Further analysis demonstrated strong alignment between the identified model embeddings and neural activity patterns in many functionally defined brain ROIs (e.g., EBA, PPA, RSC and FFA). This provides compelling evidence that the object representations in LLMs, while not identical to those in the human, share fundamental commonalities that reflect key schemas of human conceptual knowledge. This study advances our understanding of machine intelligence and informs the development of more human-like artificial cognitive systems.", "sections": [{"title": "Introduction", "content": "The ability to categorize and conceptualize objects forms the bedrock of human cognition, influencing everything from perception to decision-making. When confronted with diverse objects, humans can often differentiate their categories and concepts by making structured comparisons between them. This process is an essential part of human cognition in tasks ranging from everyday communication to problem-solving. In this cognitive process, our mental representations serve as a substrate, aiding in the recognition of objects1,2, formation of categories3\u20135, organization of conceptual knowledge6,7, and the prediction of behaviors based on experiences. Therefore, understanding the structure of these representations is a fundamental pursuit in cognitive neuroscience and psychology8\u201310, underpinning significant research advancements in the field. For instance, various studies have identified potential dimensions that organize these representations, such as animals versus non-animals11\u201314, natural versus human-made15,16, manipulation versus shelter versus eating17, large versus small18,19, or hand- versus mouth- versus foot-related actions20.\n\nThe cognitive plausibility of deep learning systems has sparked significant debate21,22, with recent works often focusing on diverse neural networks pretrained on limited datasets for specific computer vision tasks like image classification23\u201327. While these endeavors have led to notable advancements28\u201331, the critical question remains unanswered: can human-like psychological representations naturally emerge without task-specific training? LLMs, such as OpenAI's ChatGPT and Google's Gemini, have emerged as potent tools in text and image understanding, generation, and reasoning. These models exhibit impressive capabilities in tasks like object identification, information categorization, concept communication, and inference. Unlike conventional methods, LLMs utilize generic neural network architectures with billions of parameters, trained through next token prediction on massive text corpora (and images for MLLMs) comprising trillions of tokens. Despite ongoing debates about their capacities32\u201334, one potential strength lies in their adeptness at problem-solving with minimal task-specific training, often requiring only straightforward task instructions without parameter updates. These features raised the question of whether they have developed human-like conceptual representations about natural objects.\n\nIn this study, we proposed a novel data-driven approach to investigate the core dimensions of mental representations in LLM (here ChatGPT-3.5) and MLLM (here Gemini Pro Vision). Inspired by previous work conducted on human similarity judgments using visual object images, we adopted a similar methodology to both the LLM and MLLM. Unlike presenting visual stimuli to human participants and vision language model, we presented corresponding textual descriptions of visual images to the language-only model. Harnessing the models' ability to perform a triplet odd-one-out task, a well-established paradigm in cognitive psychology10,15,16,35, we collected extensive datasets comprising 4.7 million triplet similarity judgments for both the LLM and MLLM. Each dataset is rich in triple similarity judgment entries, drawn from a pool of 1,854 unique objects. This diverse collection enables the examination and capture of visual and conceptual mental representations spanning a wide array of natural objects.\n\nUsing a representation learning method previously designed for human participants15,36, we identified 66 sparse, non- negative dimensions underlying LLMs' similarity judgements that lead to excellent predictions of both single-trial behavior and similarity scores between pairs of objects. We demonstrated that these dimensions are interpretable, exhibited spontaneous semantic clustering, and characterized the large-scale structure of LLMs' mental representations of nature objects. Furthermore, by comparing the identified dimensions with the core dimensions observed in human cognition, we found close correspondence between model and human embeddings. Finally, we demonstrated that there was strong alignment between the model embeddings and neural activity patterns in many functionally defined, category selective brain ROIs (e.g., EBA, PPA, RSC and FFA), underscoring the generalization of these learned mental representations and offering a compelling evidence that the object representations in LLMs, while not identical to those in the human, share fundamental commonalities that reflect key schemas of human conceptual knowledge. These results enrich the growing body of work characterizing the emergent characteristics of LLMs37\u201343, showcasing their potential to capture and reflect human-like conceptualizations of real-world objects."}, {"title": "Results", "content": "Our initial step involved selecting a wide range of objects that mirror real-life scenarios. The THINGS database44 was our selection, encompassing 1,854 living and non-living objects frequently encountered in daily life, illustrated in Figure 1a.\nNext, we needed a behavioral task paradigm conducive to understanding LLMs' mental representations and comparing them effectively with those of humans. While prior studies have leveraged classical behavioral assessments from various disciplines like economics45, mathematics38,46, and psychology38,46 to study LLMs' behavior, these approaches have been limited in assessing core dimensions of mental representation. We opted for the triplet odd-one-out task (referencing Figures 1b-d, see Methods) due to its proven effectiveness in modeling human mental dimensions10,15,16,35,47.\nThen, the collection of a large-scale behavioral similarity judgment dataset involving these objects and tasks became imperative. Given the monumental scale of the task\u2014around 1.06 billion triplet judgments for 1,854 objects under the odd-one-out task\u2014it was unfeasible to execute comprehensively. However, leveraging insights from previous studies15,16, we adopted a strategy where a substantial approximation of the entire similarity matrix could be achieved using a small fraction (about 0.44%) of the total judgments. Human similarity judgments from 4.7 million trials have been collected using the online crowdsourcing platform Amazon Mechanical Turk16. For LLMs, we collected their behavioral data from identical trials as employed in the human experiments. Subsequently, we introduced a similarity space derived from these judgments using the Sparse Positive Similarity Embedding (SPoSE) method15,36 (depicted in Figure 1e). This approach involved the initial random initialization of object points in a high-dimensional feature space, followed by the optimization of object weights along these dimensions to craft an embedding predicting behavioral judgments in the triplet task. This process furnished a dimensional model of the similarity space, unveiling axes underscoring object variations and associating each object with scores on these dimensions. Finally, validation of the generalization capabilities of learned mental embeddings from LLMs on previously unseen datasets and their correlation with neural activity in the brain emerged as a crucial step. In this context, we turned to the Natural Scenes Dataset (NSD)48 and the Representational Similarity Analysis (RSA) method49, as illustrated in Figures 1f-g.\n\nLow-dimensional embeddings identified from LLMs are stable and predictive. Given the stochastic nature of the SPOSE modeling method (see Methods), we conducted dozens of reruns with distinct random initializations, yielding embeddings with slightly varying dimensions. Firstly, we assessed the correlation between any pair of the available dimensions and pruned out redundant dimensions (keeping only one) that exhibited correlations exceeding a specified threshold value (here, 0.4). This was done because most dimensions in the reruns were redundant (consistently appearing in different runs, thus highly correlated with their counterparts), and only one randomly selected dimension needed to be retained from multiple highly redundant dimensions. Subsequently, a reproducibility score was computed for each retained dimension (see Methods). To facilitate comparison with the 66 core dimensions identified from humans16, we selected the top 66 dimensions with the highest reproducibility scores, thus finalizing the embeddings with a 66-dimensional representation.\n\nIn Figure 2a, all dimensions within the LLM embedding displayed reproducibility scores exceeding 0.51 (with a maximum value of 1). Out of the 66 dimensions, 37 exhibited reproducibility scores surpassing 0.90, while 48 scored higher than 0.80. Transitioning to Figure 2b, the MLLM embedding showcased reproducibility scores above 0.36 for all dimensions except one related to 'coarse pattern/many things', which registered a score of 0.22. Specifically, 31 out of the 66 dimensions attained reproducibility scores over 0.80, with 47 surpassing 0.60. The human embedding dimensions depicted in Figure 2c mirrored comparable outcomes. These findings indicate that the results presented are not unique to the particular model run we examine, but instead are stable properties of the embedding space for these objects.\n\nUtilizing the SPOSE method, an object embedding is derived from a subset of potential triplet judgments, significantly lowering the amount of required data collection to manageable levels (4.7 million trials accounts for approximately 0.44% of all possible triplets involving 1854 objects). To assess the fidelity of the resulting embedding, we conducted an evaluation by exhaustively gathering triplet judgments for a group of 48 objects not included in the SPOSE model's training data. By computing choice probabilities for each object pair, serving as a proxy for their similarity, we compared this measured similarity matrix with the one predicted by the model's embedding (see Methods). Illustrated in Figures 2d-f, a strong correlation was observed between the model-predicted and behaviorally measured Representational Similarity Matrices (RSMs) (correlation coefficients: 0.71 for LLM, 0.85 for MLLM, and 0.9 for human), validating that the 66-dimensional embeddings we analyze closely reflect the similarity space underlying the corresponding behavioral judgments. This result highlights that despite the extensive object pool and the intricacies of natural stimuli, a substantial portion of the large-scale representational structure of objects measured through similarity judgements can be captured by a fairly low-dimensional embedding.\n\nNext, we evaluated the ability of these low-dimensional embeddings to predict individual choices in the odd-one-out task using a held-out test set. As illustrated in Figure 2g, the model achieved accuracies of 56.7% (\u00b10.22%), 63.4% (\u00b10.25%), and 64.1% (\u00b10.18%) for LLM (here, ChatGPT-3.5; a preliminary test of GPT-4 indicated better performance, as shown in Supplementary Figure S1), MLLM, and human, respectively (chance = 33.3%). To contextualize this performance, we estimated the noise ceiling of the behavioral data for each model by repeatedly sampling 1,000 randomly selected triplets 25 times and assessing the consistency of choices for each triplet. Averaged across those triplets, the noise ceilings (upper limits) in fitting individual-trial behavior data were 65.1% (\u00b10.96%), 73.8% (\u00b11.12%) and 67.2% (\u00b11.04%) for LLM, MLLM, and human, respectively. Hence, these low-dimensional embeddings demonstrated the capacity to predict LLM, MLLM, and human behavior with accuracies reaching up to 87.1%, 85.9%, and 95.4% of the optimal achievable accuracy, showcasing remarkable predictive prowess at the individual-trial level given the inherent data noise.\n\nOverall, the SPOSE approach yielded a low-dimensional, stable and predictive mental embedding that was excelled in both predicting triplet similarity judgments and reconstructing the representational space underlying these judgments. This suggests that LLM (especially MLLM) judgments of natural objects are principled and structured. In the following sections, we delve into this embedding to reveal key schemas that underlie these judgments and their specific connections to the human mental embedding.\n\nEmergent object category information. It has been shown that natural object categories are an emergent property of mental embeddings derived from human similarity judgments15,35. To examine whether mental embeddings derived from LLM and MLLM show any emergent object category similarity structure, we used 18 unique high-level categories identified in the THINGS database44 and used a cross-validated nearest-centroid classifier to predict category membership for each of the 1,112 objects of these categories (see Methods).\n\nAs shown in Figure 2h, the LLM embeddings demonstrated an 83.4% top-1 accuracy (chance performance: 5.56%), while the MLLM achieved 78.3%. In contrast, human embeddings exhibited maximal object categorization capacity, with top-1 accuracy of 87.1%. Figure 3 illustrates the global structure of the acquired embeddings through a multidimensional scaling (MDS)-initialized t-SNE plot (dual perplexity: 5 and 30; 1,000 iterations) containing 1,854 objects. Objects with similar dimensional values in the embedding are visually proximate in the plot, highlighting that items from the same category tend to cluster together across LLM, MLLM, and human data. Thus, these models have learned an embedding space that inherently captures some object category structures without explicit representational pressure to do so. Overall, outcomes from LLM and MLLM further validate the known distinctions between animate and inanimate items, as well as man-made versus natural objects, aligning with prior human-centric studies15.\n\nThe embedding dimensions of the LLMs are interpretable and informative. The SPoSE modeling approach offers a notable advantage by providing an interpretable embedding with accessible dimensions. While past research has delved into the interpretation of multidimensional mental representations in humans15,16, this marks the inaugural exploration for LLMs. Our initial focus was on analyzing these dimensions to uncover the essential properties that LLM and MLLM prioritize when evaluating similarity among natural objects.\n\nIn Figure 4, we visually represent interpretability for selected dimensions (in LLM and MLLM) by showcasing object images weighted most heavily in those dimensions. Visual inspection suggests that these dimensions are interpretable, reflecting both conceptual and perceptual traits of the depicted objects. We assigned intuitive labels (e.g., \u2018animal-related' and 'food-related'; see Methods) to each dimension identified from LLM and MLLM at the top of each row. From the results, we observed that certain dimensions appear to convey semantic categorization, such as those linked to food, animals, vehicles, or tools (see Figure 4a). Some dimensions seem to capture perceptual features like hardness, value, disgust, temperature, or texture (see Figure 4b). Additionally, some dimensions in MLLM seem to reflect global spatial properties, such as cluttered, crowded or spectacular related (see Figure 4c). However, these dimensions are not found in LLM. Some dimensions express shape attributes (flatness, elongation, spiculate; see Figure 4d), color (see Figure 4d), and even user specificity-whether items are intended for children, adults, everyday consumers, or experts (see Supplementary Figure S2a). Moreover, dimensions outlining physical composition emerge, distinguishing between objects made of wood, ceramic, metal, or other materials (see Supplementary Figure S2b). Environment-related distinctions also surface, like land-based versus sea-based or indoor versus outdoor contexts (see Supplementary Figure S2c). See Supplementary Figures S3-S7 for a visual display of all 66 dimensions. Notably, each dimension within LLM or MLLM embodies a blend of multiple attributes, accommodating diverse interpretations. We provide a single interpretation for each dimension here to showcase the concepts they represent. Overall, the dimensions extracted from LLM and MLLM demonstrate interpretability, disclosing fine-grained differences across various aspects of natural objects. Together with the dimension labels identified from humans16, the dimension labels identified from LLM and MLLM were listed in Supplementary Table S1, for ease of reference.\n\nAfter confirming the interpretability of object dimensions, we can explore what dimensions a given object is composed of. For that purpose, in Figure 5a, we employ circular bar plots (rose plots) to visually represent a variety of objects, where the angle and color of a petal denote the object dimension, and the length of the petal signifies the extent to which that dimension is expressed in the object. For example, the image of 'almond' is predominantly characterized by being food related, plant related and stacked. In contrast, a 'satellite' is primarily associated with electronics, flying related, technology related, movement and transportation. This visual representation demonstrates the specificity of certain dimensions, tailored to individual object. When comparing LLM, MLLM, and humans, we observe that some dimensions, particularly those related to color or texture, may be missed completely when relying solely on texts instead of images in the odd-one-out task. In addition, the visualization demonstrates that objects are indeed characterized by a rather small number of dimensions, indicating that not all 66 dimensions are required for every similarity judgment. To quantify this observation, we evaluated the predictive accuracy of the learned embedding by progressively eliminating less significant dimensions for each object. By zeroing out the dimension with the lowest weight iteratively and assessing the impact on the model's predictive capacity, we identified that retaining 3 to 8 dimensions for LLM, 2 to 10 for MLLM, and 7 to 13 for humans (note that these dimensions may differ between different objects) sufficed to achieve 95-99% of the full model's performance in explaining behavioral judgments within the odd-one-out context, as shown in Figure 5b.\n\nComparison of core dimensions in LLMs and Humans. The above analysis has already shown that LLM and MLLM, similar to humans15, also have the stable and predictive underlying mental representations and that their dimensions are interpretable. Now, we would like to explore what kind of relationship exists between the core dimensions of LLMs and those of humans. The results, depicted in Figure 6, reveal that 31 of 66 LLM dimensions and 42 of 66 MLLM dimensions exhibit strong correlations with human dimensions (r > 0.4), indicating a substantial alignment between core dimensions of MLLM and humans. In MLLM, several human dimensions are subdivided (e.g., \"food-related\" into \"food-related\" and \"vegetable-related\"; \"animal-related\" into \u201canimal-related\" and \u201cinsect-related\"), or amalgamated differently (e.g., \"food-related\", \"plant-related\", and \"green-related\" merging into \"vegetable-related\"; \"animal-related\" and \"disgusting/slimy\" merging into \"insect-related\"). Similar adaptations are observed in LLM. Furthermore, a few MLLM dimensions, such as \"summer-related/lite,\" were not previously identified in humans and display weak associations with existing human dimensions. A comparison between LLM and human dimensions reveals that LLM captures numerous cognitive dimensions of humans, especially in semantic categories. However, due to its language-based nature, LLM lacks dimensions related to visual sensory aspects like color, shape, and space. Nevertheless, within LLM, a nuanced semantic distinction emerges, as evidenced by discerning between \u201cfrozen treats/drink\" and \u201chot drink-related\". On the other hand, evaluating MLLM against human core dimensions indicates greater congruence between MLLM and humans. While MLLM still lacks specific color-related dimensions (e.g., \"red\", \"black\"), it now possesses some dimensions related to shape (e.g., \"grainy\", \"round/curvature-related\") and spatial characteristics (e.g., \"serried/stacked\", \u201cdense/many small things\"), owing to its multimodal abilities. This indicates that MLLM, akin to humans, is capable of perceiving a large amount of information through vision.\n\nRelationship to the cerebral representational geometries. To the extent that brain-like capacity is indicative of human-like representation in this similarity regime, we would expect these LLMs to have embedding spaces with at least some emergent brain-like correspondence, but not as strong as human mental embedding space. Thus, we next examined the degree to which LLMs' embedding spaces have an emergent brain-like correspondence, relative to the human mental embedding space. This analysis involved leveraging human brain responses sourced from the NSD dataset48, which provides comprehensive fMRI data capturing neural responses from eight subjects exposed to numerous natural scene images (see Methods). This dataset effectively probes the cerebral representational geometries evoked by a wide array of objects and scenes.\n\nTo establish the connection between LLM and MLLM representations with brain responses across the whole brain, we employed a method based on representational similarity known as searchlight RSA49 (refer to Figure 7a; see Methods). This approach entails fitting independent linear rating models for each embedding dimension, utilizing weighted combinations of CLIP image and text features50 to predict the univariate response profiles (see Methods). Subsequently, these dimension rating models are utilized to predict multi-dimensional pattern responses for new objects, leading to the establishment of the predicted representational geometry within this embedded space. The comparison between this predicted RSM and the searchlight brain sector's RSM serves as a crucial indicator of how well the LLM's embedding aligns with that specific brain region.\n\nThe noise-normalized similarity score, averaged across eight subjects and across all voxels in a given brain Region of Interest (ROI) for each model, is depicted in Figure 7b. It should be noted that we did not adopt the same odd-one-out paradigm to infer the 66-dimensional embeddings for the CLIP model50 (here used as a strong baseline51), considering that CLIP cannot effectively follow task instructions. Instead, we directly used the visual and textual embeddings of the CLIP model itself, denoted by CLIPvision and CLIPtext, respectively. When looking at average brain similarity score within an ROI, embeddings derived from human and MLLM perform substantially better than embeddings derived from LLM and the CLIP model, while differences between the human and MLLM are relatively small. It is important to note that these summarized results reflect average responses across all voxels in a specific ROI, and therefore they do not reflect spatial patterns within it. Critically, when analyzing ROI averages especially in ROIs containing numerous voxels-meaningful spatial prediction patterns may be obscured (i.e., models with seemingly similar average comparisons might contain distinct fine-grained spatial information).\n\nFigure 7c presents the detailed results of the spatial searchlight analysis overlaid on the cortical map of subject S1, with corresponding outcomes for subjects S2-S8 depicted in Figure S8. Various well-defined ROIs were highlighted across different anatomical and semantic categories (EarlyVis: early visual cortex; Scene, PPA: parahippocampal place area, OPA: occipital place area, RSC: retrosplenial cortex; Body, EBA: extrastriate body area; Face, FFA-1: fusiform face area 1, FFA-2: fusiform face area 2; Mind and Language, TPOJ-1: temporoparietal junction 1, AG: angular gyrus, Broca, MTL: medial temporal lobe). In addition, 2D histograms comparing LLM and MLLM with human performance across all brain voxels are shown in the bottom left and right sections, where voxel densities are displayed on a logarithmic scale. Notably, LLM achieves approximately 85% of human performance across most voxels, while MLLM closely approaches and occasionally exceeds human performance levels. For clarity, only the voxels that are significantly outperform chance (P < 0.05, FDR-corrected, one-sided test) were plotted in the cortical maps.\n\nFor visual comparison, fine-grained spatial cortical maps illustrating human, LLM, and CLIP performances on the left hemisphere of subject S1 were depicted in Figures 7d-f. The visual inspection reveals that MLLM and human representations exhibit significantly closer alignment with the brain within the specified ROIs compared to LLM and CLIP. Beyond overall performance metric, peaks in the cortical maps align with scene-selective52 (PPA, RSC, OPA), body-selective53 (EBA) and face-selective54,55 (FFA, OFA) ROIs. This alignment suggests that the fundamental dimensions of MLLM effectively capture semantic relationships in scene understanding, mirroring human cognitive processes. Furthermore, both the overall performance levels and the pattern consistency in the searchlight RSA analyses remain stable across subjects S1-S8 (refer to Figure 7c for subject S1 and Supplementary Figure S8 for subjects S2-S8)."}, {"title": "Discussion", "content": "The present study provides a comprehensive investigation into the schema of object concept representations in LLM and MLLM, and their relationship to representations of the human mind and brain. By collecting two large-scale datasets of 4.7 million triplet judgments, we derived the stable and predictive 66-dimensional embeddings that capture the underlying similarity structure of real-world objects. An interesting finding is that the object embeddings learned from LLM and MLLM judgments naturally cluster according to semantic categories, mirroring the structure observed in human mental representations. This suggests that despite their fundamentally different architectures and training processes compared to the humans, LLM and MLLM have developed human-like conceptual representations of natural objects. The interpretability of the dimensions underlying these embeddings further reinforces this notion, as they appear to reflect the key schemas of human object understanding.\n\nNotably, the MLLM demonstrated particularly strong performance in predicting individual behavioral choices, reaching up to 85.9% of the noise ceiling. This highlights the advantages of integrating visual and linguistic information, as the MLLM was able to develop more nuanced and human-like object representations compared to the language-only LLM. This aligns with previous findings suggesting that multimodal learning can lead to more robust and generalizable representations56\u201358. Furthermore, the strong alignment between the model embeddings and neural activity patterns in many functionally defined brain ROIs (e.g., EBA, PPA, RSC and FFA), provides further evidence that the object representation in MLLM share fundamental commonalities with human conceptual knowledge. This suggests that the dimensions derived from MLLM may tap into similar underlying cognitive and neural mechanisms that shape human object understanding.\n\nOther applications of the identified low-dimensional embeddings. The identified low-dimensional mental embeddings have the potential for a variety of applications beyond the current study. For instance, these embeddings could be used to investigate the alignment and fusion of representations between humans and machines. Examining the correspondence between model and human embeddings could shed light on the common schemas governing object representations, and inform the development of more seamless human-machine interfaces and collaborative systems. From a practical standpoint, the interpretable dimensions underlying the object embeddings could inform the development of more human-like artificial cognitive systems. By understanding the factors that shape object representations in LLMs, we can work towards designing Artificial Intelligence (AI) systems that can better align with human conceptual understanding and interact with human in a more natural and intuitive way. This could have far-reaching implications for a wide range of applications, from intelligent personal assistants to robotic systems.\n\nIn addition, the large-scale behavioral datasets collected in this study contribute a valuable resource for the research community. These datasets can serve as an important benchmark for evaluating and comparing the representational abili- ties of different AI models, as well as for studying the underlying cognitive processes that shape human object conceptualization.\n\nRelationship to the other related studies. Both the human brain and modern large-scale pretrained AI models are intricate systems, presenting challenges due to their complexity. Dimensionality reduction techniques are commonly employed to simplify these systems and analyze their behavior. However, determining the optimal dimensions remains a persistent challenge. Recent research has utilized the \u201clow-rank\u201d59 and \u201cdistributed information bottleneck\u201d60 hypotheses to identify suitable latent dimensions, ensuring they capture the crucial aspects of the original high-dimensional network. These hypotheses can be supported by our finding that the LLMs have developed human-like object representations from the aggregation of their fundamental dimensions, just as the human brain can give rise to rich and nuanced conceptual representations through the interplay of relatively simple neural mechanisms. Exploring these low-dimensional yet powerful organizing structures could lead to a deeper understanding of the essential building blocks of cognition, both in biological and artificial systems.\n\nMore broadly, previous fMRI studies have unveiled diverse organizational principles within the brain for effectively processing and integrating external stimuli. For example, the primary visual cortex demonstrates retinotopy through the interplay of visual eccentricity and angle selectivity61,62. Recent work on neural representations of emotions identified three spatially overlapping dimensions\u2014polarity, complexity, and intensity\u2014in the right TPJ, contributing to an \u201cemotionotopy\u201d model63. Moreover, several previous studies have demonstrated that the principle of dimension organization also applies to the representation of other higher-order information64\u201370. Our study can be seen as an extension of these prior studies to conceptual representations of large-scale natural objects, but the difference is that we do not require the underlying dimensions to be orthogonal to each other.\n\nTypically, the representations used by neural network models have been identified by scrutinizing the activation patterns of artificial neurons71\u201374. However, the efficacy of neuron-level approaches diminishes as AI systems expand in both depth and the number of model parameters. In this context, an alternative approach inspired by cognitive psychology involves examining Al systems' representations through their behaviors. Cognitive psychologists have spent decades developing methods for elucidating the content of individuals' mental representations, such as the structure of object categories and the utilities assumed to different choice actions15,75. These mental representations, while not directly observable, can be inferred through the analysis of behavior. Our study diverges from those neuron-level analysis methods by focusing on recovering representations from LLMs using behavioral methods, making our work complementary to existing approaches. Actually, probing LLMs from a cognitive perspective has recently become a significant research direction32,76\u201380. This involves dissecting how LLMs process and understand information, mimicking cognitive processes observed in humans. By delving into the operational mechanisms of these large-scale models, researchers aim to uncover insights into various domains such as color processing81, emotion analysis82,83, memory encoding84,85, morality86 and decision-making37,87,88. Understanding the parallels and divergences between human cognition and the functioning of LLMs opens up new avenues for exploring the frontiers of AI and cognitive science34, shedding light on how LLMs can replicate, augment, or diverge from human-like cognitive abilities.\n\nLimitations and future directions. One potential limitation of this study is that the analysis mainly focuses on ChatGPT-3.5 and Gemini-Pro-Vision, which might not be fully representative. Nevertheless, we argue that these two models have already shown impressive problem-solving capabilities across diverse domains that were traditionally exclusive to humans. While the primary analysis centers on these two models, the methodology can readily extend to other state-of-the-art LLMs like GPT-4V89, Claude-3, or LLaMa-3. Exploring the object representations within a diverse range of AI architectures could reveal the generalization ability of the identified key dimensions, as well as shed light on the unique strengths and limitations of various modeling strategies. This flexibility highlights the potential for broader implications and uses of our analytical approach in the evolving landscape of AI research. It is also worth noting that using different language prompts may elicit varied responses from LLMs, even when given the same input. In this study, the language prompts we used were carefully designed. We think that these considerations have a negligible impact on the study's overall conclusions.\n\nAnother potential limitation of the current study is that the object embeddings were derived from similarity judgments solely depending on textual or visual stimuli. The advantage of using visual rather than textual stimuli is that it may provide additional purely perceptual information that is relevant for judging the similarity of objects and that might not come to mind immediately when using texts. Future work could explore the paradigm of multimodal stimuli. Investigating how the object representations in LLMs evolve with the incorporation of textual, visual, auditory, and other sensory modalities could shed further light on their internal representation mechanisms."}, {"title": "Methods", "content": "Stimuli and triplet odd-one-out task. In selecting stimulus objects, our preference was for the THINGS database44, a resource designed to encompass 1,854 living and non-living objects based on their practical usage in daily life. During the triplet odd-one-out task, participants (humans or LLMs) encountered three objects drawn from the THINGS database, either through images or textual descriptions. Their objective was to identify the object with the highest dissimilarity among the three. This task evaluates the relationship between two objects considering the context set by a third object. Featuring a diverse range of objects, this method provides a systematic means to assess perceived similarity unaffected by context, thus minimizing response bias. Moreover, it enables the measurement of context-dependent similarity, such as by restricting similarity evaluations to specific higher-level categories like animals or vehicles.\n\nBehavioral responses from humans. The dataset utilized in our research originated from a recent study16, where 4.7 million human similarity assessments were gathered via the Amazon Mechanical Turk online crowdsourcing platform. This dataset was repurposed for our investigation.\n\nCollecting behavioral responses from LLM. For our study, we gathered all human-used similarity judgments, totaling 4.7 million trials. To solicit responses from ChatGPT-3.5 (gpt-3.5-turbo) and GPT-4 (gpt-4-0314), we employed a prompt where each image was represented by its object name and descriptions, as image input processing was not supported by these models. Due to cost constraints, GPT-4 only amassed a total of 2,171 trials, primarily for initial comparisons with ChatGPT-3.5. \nThe prompt structure used was standardized: \u201cGiven a triplet of objects {'[Object_A]', '[Object_B]', '[Object_C]'}, which one in the triplet is the odd-one-out? Please give the answer first and then explain in detail.\u201d In practice, '[Object_A]', '[Object_B]', and '[Object_C]' were replaced with the respective object descriptions for each trial. The temperature parameter, dictating response randomness in GPT models, was set to 0.01. To assess the upper limit of predictability under dataset randomness (the noise ceiling), we randomly selected 1,000 triplets and conducted 25 trials for each using the same prompt, evaluating consistency in choices across trials.\n\nCollecting behavioral responses from MLLM. Regarding collecting behavioral responses from MLLM, more specifically Gemini Pro Vision (v1.0), we adopted a similar strategy. The prompt we used is as follows: \"You are shown three object images side by side and are asked to report the image that was the least similar to the other two. You should focus your judgment on the object, but you are not given additional constraints as to the strategy you should use. If you did not recognize the object, you should base your judgment on your best guess of what the object could be. 1. Tell me your answer. 2. Tell me the location of the object you have chosen. 3. Explain the reasons.\" In some trials, the Gemini Pro Vision model refused to respond because it believed that the given images contained some unknown sensitive information. In this case, we applied a method akin to image replacement to address the issue.\n\nThe temperature parameter for determining response randomness in Gemini Pro Vision was also configured to 0.01, with images displayed at 512 x 512 pixels. Similarly, to gauge the noise ceiling and potential predictability, we additionally sampled 1,000 randomly chosen triplets and ran 25 trials for each of them using the same prompt for each trial and estimated the consistency of choices for each triplet across trials.\n\nNatural Scene Dataset (NSD). NSD, recognized as the largest neuroimaging dataset linking brain insights with artificial intelligence, involves richly sampled fMRI data from 8 subjects. Across 30-40 MRI sessions, each subject observed between 9,000-10,000 distinct natural scenes using whole-brain gradient-echo EPI at 1.8 mm isotropic resolution and 1.6 s TR during 7T scanning. Image stimuli were drawn from the COCO dataset\u2079\u2070, with corresponding captions retrievable using COCO ID. To assess the transferability of mental representations from humans and LLMs across datasets, 44 images from the NSD dataset's test set were chosen (because these images were shared by all 8 subjects,```json\nand they align with semantic categories in the THINGS database). Additionally, fMRI responses linked to these 44 images across all 8 subjects were earmarked for subsequent analysis.\n\nSparse Positive Similarity Embedding (SPoSE). Utilizing the SPoSE approach15,36, we derived embedding representations for 1,854 objects based on similarity judgment data from LLM and MLLM, respectively. The PyTorch implementation for this process can be accessed at https://github.com/ViCCo-Group/SPOSE. Initially, an embedding matrix X was created with random weights in the range of 0 to 1 across 100 latent dimensions for each object, resulting in a 1854-by-100 matrix. Stochastic gradient descent was subsequently applied to fine-tune this embedding matrix using odd-one-out responses. The optimization objective function aimed to minimize a combination of cross-entropy loss concerning triplet choice probabilities for all options and an L1-norm on the weights to promote sparsity:\n\n$\\min_{f(x)} = \\sum_{i,j,k} \\log \\left( \\frac{\\exp (x_i x_j)}{\\exp (x_i x_j) + \\exp(x_i x_k) + \\exp (x_j x_k)} \right) + \\lambda \\sum_{i} |x_i|$ (1)\n\nwhere x corresponds to an object vector; i, j and k to the indices of the current triplet; n to the number of triplets; and m to the number of objects. The regularization parameter \u03bb, which controls the trade-off between sparsity and model performance, was determined using cross-validation on the training set (\u03bb = 0.004 for LLM, 0.0035 for MLLM and 0.00385 for humans). In addition to sparsity, the optimization was constrained by strictly enforcing weights in the embedding X to be positive. The minimization of this objective was carried out using stochastic gradient descent with an Adam optimizer91 (with default parameters) and a batch size of 100 on triplet odd-one-out judgments. After the optimization was complete, dimensions with weights below 0.1 for all objects were eliminated. Finally, the dimensions underwent sorting based on the sum of their weights across objects in descending order.\n\nThis model operates under two key theoretical assumptions. Firstly, it postulates sparsity within the embedding space dimensions, indicating that each object primarily influences certain dimensions rather than all. Secondly, it assumes positivity in these dimensions. Consequently, an object's weight on a specific dimension signifies the extent of the related property within the object. These assumptions diverge from typical dimensionality reduction approaches like Principal Component Analysis (PCA), which assume dense dimensions across the real number spectrum. Furthermore, SPOSE facilitates cross-correlations among dimensions while PCA assumes independence. Consequently, SPoSE often uncovers a greater number of dimensions, reflecting finer details or attributes, which are more easily interpretable compared to PCA dimensions. Notably, the weight an object holds on a dimension directly corresponds to the presence of the associated property within the object.\n\nReproducibility of embedding dimensions. Considering the stochastic nature of the optimization process, the SPOSE method yields varying sets of dimensions upon each reiteration. To assess the stability of the 66-dimensional embedding, we conducted 20 model runs with distinct random initializations. Evaluating each original dimension against all dimensions in the 20 reference embeddings, we identified the best-matching dimension based on the highest correlation. Consistent with previous research15, a Fisher z-transform was applied to these correlations, averaged across the 20 reference embeddings, and then reversed to obtain a mean reliability value for each dimension across all 20 embeddings.\n\nCategory prediction. Evaluating the representational embeddings' categorization performance involved testing them across 18 out of the 27 THINGS database categories. Objects falling into multiple categories were excluded from the analysis, resulting in the removal of 9 categories. Among these excluded categories, 7 were subcategories or had less than ten unique objects post-filtering. The remaining 18 categories included clothing, toy, vehicle, container, electronic device, animal, furniture, body part, food, musical instrument, plant, home decor, sports equipment, office supply, part of car, medical equipment, tool, and weapon, totaling 1,112 objects. Classification was conducted through leave-one-object-out cross-validation. Training involved computing category centroids by averaging the 66-dimensional vectors of all objects within each category, excluding the left-out object. The category membership of the excluded object was predicted based on the smallest Euclidean distance to the respective centroid. This process was iterated for all 1,112 objects, with prediction accuracy averaged across the dataset.\n\nDimension naming. In defining the human mental embedding, the dimension names from a previous investigation were employed as references16. However, for LLM and MLLM, each of the 66 dimensions within the embedding was associated with common-sense labels through a straightforward naming task. This task involved participants observing a 1-by-12 array of object images, tasked with identifying the shared property depicted in the images. Each array consisted of images selected from the top of one dimension from the embedding. Ten participants were instructed to provide concise labels, limited to 1\u20132 words, describing the arrayed images. Subsequently, word clouds were generated to visualize participant responses, showcasing the distribution of labels based on frequency, utilizing the wordcloud function in MATLAB (Mathworks) with default settings. Finally, the lead authors of this study gave intuitive labels for each dimension, taking into account their own judgment and the feedback provided by the participants.\n\nSearchlight RSA. For fMRI, local cerebral RSMs were computed in subject space within a grey-matter spherical region (6 mm diameter) centered at each voxel location. RSA analyses assessed the Spearman correlation r between the local cerebral RSMS and each of the three mental embedding RSMs.\n\nDimension rating for NSD images. We predicted the 66 object dimensions for each image within the NSD dataset. Specifically, we leveraged the OpenAI-trained CLIP model50 (with \u2018ViT-L/14' as the backbone), which is a multimodal model trained on image-text pairs and which was recently demonstrated to yield excellent prediction of human similarity judgments92,93. For each of the 1,854 object images in the THINGS dataset, we extracted the image and text features from the final layer of the CLIP image and text encoders, respectively. Subsequently, for each of the 66 dimensions of LLM (or MLLM, or Human), we fitted a ridge regression model to predict dimension values, using a concatenation of the extracted image and text features from CLIP as input. The optimal regularization hyperparameters were determined by using cross-validation. These trained regression models were then applied to the extracted features across all images in the NSD dataset. Focusing on the subset of 44 distinct test images, we utilized these predicted 66-dimensional embeddings to compare them with brain fMRI recordings using searchlight RSA.\n\nVisualization of cerebral cortex. To visualize the analytical outcomes across the entire cortical region, we employed flattened cortical surfaces derived from individual subjects' anatomical images. FreeSurfer\u2079\u2074 facilitated the generation of cortical surface meshes from T1-weighted anatomical images. This process involved applying five relaxation cuts on each hemisphere's surface and excluding the corpus callosum. Subsequently, functional images were registered to the anatomical images and mapped onto the surfaces for visualization purposes using Pycortex\u2079\u2075."}]}