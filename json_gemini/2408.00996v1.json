{"title": "IncidentNet: Traffic Incident Detection, Localization and Severity Estimation with Sparse Sensing", "authors": ["Sai Shashank Peddiraju", "Kaustubh Harapanahalli", "Edward Andert", "Aviral Shrivastava"], "abstract": "Prior art in traffic incident detection relies on high sensor coverage and is primarily based on decision-tree and random forest models that have limited representation capacity and, as a result, cannot detect incidents with high accuracy. This paper presents IncidentNet a novel approach for classifying, localizing, and estimating the severity of traffic incidents using deep learning models trained on data captured from sparsely placed sensors in urban environments. Our model works on microscopic traffic data that can be collected using cameras installed at traffic intersections. Due to the unavailability of datasets that provide microscopic traffic details and traffic incident details simultaneously, we also present a methodology to generate a synthetic microscopic traffic dataset that matches given macroscopic traffic data. IncidentNet achieves a traffic incident detection rate of 98%, with false alarm rates of less than 7% in 197 seconds on average in urban environments with cameras on less than 20% of the traffic intersections.", "sections": [{"title": "I. INTRODUCTION", "content": "In 2019, traffic accidents alone caused approximately 28 million incidents, risking people's safety [1]. According to the study [2] conducted across 2268 US counties, a 5-minute delay in emergency response increased fatality rates by 46%, while response times under 7 minutes reduced fatality rates by 58% in urban and rural areas. Along with traffic accidents, cargo spills, stalled vehicles, road maintenance, and other emergency scenarios are also traffic incidents. Traffic incidents are generally defined as non-recurring events that reduce the roadway's capacity [3]. These incidents lead to secondary issues such as road congestion and delayed emergency support [4]. This motivates the need to work towards detecting traffic incidents quickly, improving emergency response time, and improving traffic re-routing time.\nFaster and more accurate incident detection presents two main challenges. (i) Need for an algorithm to detect, locate, and estimate the severity of incidents in urban regions: Most existing traffic incident detection algorithms, such as [5], are tailored for highways. However, the existing algorithms for urban regions, like [6], introduced an algorithm that compares current traffic conditions, including travel times, to a predefined threshold, and [7] proposed a pattern-matching algorithm that uses a database of GPS trajectories to identify incidents. However, the performance of such comparative and pattern-matching algorithms heavily depends on thresholds, requiring continuous adjustment due to traffic's dynamic nature. (ii) Non-availability of microscopic datasets: Existing well-known public datasets like PEMS [8], San Francisco I- 880 [9], and METR-LA [10] primarily use inductive loop detectors to capture macroscopic data focusing on highways by aggregating metrics like average vehicle speed and average flow-rate density obtained through these sensors without any vehicle distinguishing features. This level of aggregation makes it challenging to get high accuracy in dynamic urban settings. Alternatively, datasets using GPS sensors like NYC Taxi Data [11] and Bluetooth sensors like Highway 99-W [6] offer microscopic features but suffer from issues like signal loss and interference and data latency [12], [13], hindering their use in time-critical traffic incident detection tasks.\nOwing to the vast development of Computer Vision and the quality of cameras over the last decade, the deployment and utility of cameras for traffic use cases have increased in urban environments and highways [14]. They can capture microscopic data like speed, location, timestamp, direction, and unique vehicle identifiers for each vehicle. Due to this, developments have focused on traffic incident detection approaches within the camera's field of view [15]. However, incidents outside their field of view remain undetected. Deploying cameras to increase coverage to 100% is challenging and not desirable. So, in this paper, we develop methods to identify incidents outside the camera's field of view using existing infrastructure, even with sparse coverage of roads in urban regions. We address these challenges through our two key contributions:\n\u2022\tA repeatable approach for generating realistic fine-grain synthetic datasets using traffic flow data within a microscopic traffic simulator, facilitating researchers with more realistic data. Our method takes readily available coarse-grain public traffic flow data. It generates a synthetic dataset using traffic data within a simulator that closely matches the coarse-grain distributions of the public traffic flow real-world dataset.\n\u2022\tA novel technique that can detect and localize a traffic incident without the incident being directly in the field of view of a visual sensor. Localization of the incident is achievable without knowing the precise distance"}, {"title": "II. RELATED WORKS", "content": "The PEMS [8] Bay dataset collects traffic data using inductive loop detectors placed throughout the highways in the Bay area and other parts of California. Traffic metrics like average speed, occupancy, and vehicle count are gathered and aggregated at 5-10 minute intervals without distinguishing information about individual vehicles. I-880 [9] and METR- LA [10] also capture macroscopic data through inductive loop detectors, similar to the PEMS dataset. These datasets (i) don't capture the nuance details essential for better accuracy detection in urban areas, and (ii) primarily originate from highway and freeway sensors, not reflecting urban-level traffic dynamics, making it difficult to build accurate incident detection systems. We address these challenges by simulating fine-grained traffic using microscopic traffic simulation built on real-world coarse datasets.\nVarious incident detection algorithms and their metrics like Detection Rate (DR), False Alarm Rate (FAR), Mean time to detect (MTTD), region (type of road), and type of data (microscopic and macroscopic) have been summarized in Ta- ble I. [5] used multiple highway cameras to detect incidents via spatial trajectory anomalies but did not address complex scenarios like ramps or lane closures. [19], [23] used the XGBoost algorithm for highway incident detection with [23] also calculating incident severity. However, they make predictions every 5 minutes, introducing increased incident detection time. In urban settings, [6] and [7] detected in- cidents using comparative and pattern-matching approaches with thresholds but failed to work well in dynamic traffic conditions, and they also require the installation of additional infrastructure to enable communication. Alternatively, [20] utilized a deep learning approach using traffic volume data from inductive loop detectors to detect incidents. However, its reliance on an adjacency matrix representing a sensor network and using macroscopic data raises scalability and efficiency concerns. Also, similar to [23], they predict incidents at 5-minute intervals, leading to delayed incident detection.\nIncident detection algorithms reliant on data from all sensors during inference face efficacy challenges as some sensors may become non-functional over time. This was shown in the report [24], which highlighted that about 25% of New York's traffic sensors were nonfunctional during the survey. This has not been a focus area in previous studies, making it a crucial problem to be addressed.\nB. Limitations of Existing Incident Detection and Localiza- tion Methods\nA. Challenges of Macroscopic Datasets"}, {"title": "III. MICROSCOPIC TRAFFIC DATASET GENERATION", "content": "Most real-world traffic flow information is macroscopic, but we need microscopic data to detect incidents accurately in urban environments. We can obtain microscopic data through simulators such as SUMO [25], VSIM [21], and AIMSUN [26]. We do this in three parts: (i) Microscopic traffic flow simulation from macroscopic data, (ii) Traffic incident simulation, and (iii) Dataset generation.\nIt's essential to model macroscopic data such as publicly available vehicle counts to create realistic traffic simulations, as simulators don't have this capability inherently. The city of Tempe provides vehicle count data aggregated and reported every 15 minutes for multiple days. We use a 24-hour period of data as shown in Fig. 1 and generate microscopic traffic information that can produce vehicle counts for every second, allowing simulators to use this data to simulate the traffic. We start by computing the average vehicle counts across all roads of interest at every time step in an urban region.\nWe then apply Fast Fourier Transforms (FFT) [27] to the averaged vehicle count data points as shown in Fig. 2 and obtain the top two frequencies to build a non-linear equation that can approximately model the average traffic behavior over time, represented by the Equation 1.\n$f(t) = A_1 sin(B_1t + C_1) + A_2 sin(B_2t + C_2) + D + \\alpha$ (1)\nIn this equation, $\\Lambda$ represents the damping factor (= 0.01); $\\delta$ represents the amount by which the parameters are updated in each step; J is the Jacobian matrix of partial derivative of the Equation 1 with respect to its parameters; f(t) represents the vehicle count that we obtain from Equation 1.\nTraffic incidents are simulated by halting vehicle(s). Depending on the likelihood of incident occurrence per vehicle, we first determine if we must insert an incident. If we have to insert an incident, we select one of the two incident types, halted vehicle and multi-vehicle crashes, for a duration also picked randomly based on the probability of the incident's severity depending on the two types of incidents. Once an incident is inserted, the radius of impact of the incident is calculated based on the severity of the incident. Inside the radius of impact, the vehicles are slowed down to emulate real-world crash behavior. It is challenging to categorize incidents as there is no direct access\nA. Microscopic Traffic Flow Simulation from Macroscopic Data\nB. Traffic Incident Simulation\nC. Dataset Generation"}, {"title": "IV. TRAFFIC INCIDENT DETECTION, LOCALIZATION AND SEVERITY ESTIMATION", "content": "The captured raw dataset has (i) low variance as data is captured second, and traffic does not change significantly in such short intervals, leading to repeated data, (ii) frequent zero values, which are important from a data perspective but difficult to use from a deep learning perspective, like traffic counts, which makes sense for data, but acts as a sparse value for deep learning approaches and (iii) missing critical features such as vehicle travel time, limiting its effectiveness in training deep learning models. We consider data pre- processing approaches to overcome these challenges.\nAs travel time between intersections is an essential metric for incident detection, we used vehicle re-identification [28] to compute the travel time between all possible combinations of two contiguous intersections based on the sensor placements. Incorporating these travel times, junction mean speed, vehi- cle count, and vehicle occupancy into our dataset resulted in a feature-rich data source, significantly improving the dataset's utility and addressing the raw dataset's challenges.\nDue to the presence of outlier data points, for example, when vehicles make unscheduled stops, we apply rolling window averages to reduce their impact. This technique involves averaging historical and current data, which allows us to smooth out anomalies in the dataset. If the current duration is labeled as an incident in the raw data, we label the rolling window average data points as incidents.\nDespite these pre-processing efforts, we still observe missing data due to vehicles bypassing major intersections through interior roads and not getting re-identified. However, it still represents valuable information on traffic behavior. So, it is crucial to consider deep learning approaches that can better handle missing data.\nSelf-attention-based transformer models have worked excep- tionally well to understand long-range sequences. TabNet [18] is an architecture designed for interpretable learning from tabular data. For training, the data is processed by the TabNet encoder, which uses a decision-making decoder to classify the results. Each TabNet encoder block comprises an attentive transformer block, a learnable mask, and a feature transformer. The learnable mask performs a soft selection of salient features, which are processed by the feature transformer, and the attentive transformer learns the\nA. Feature Extraction from Raw Data\nB. Model Selection"}, {"title": "V. EXPERIMENTAL SETUP", "content": "We generate simulation files using the OSM Web Wizard for a continuous period of 30 days to simulate traffic flow for the selected Tempe region and generate the microscopic data using the process described in our approach.\nA. Simulation Setup for Dataset Generation"}, {"title": "VI. RESULTS", "content": "To validate that our simulated data accurately reflects real- world conditions in the Tempe region, we aggregated the mi- croscopic simulation data to match the time frame of Tempe's macroscopic real-world traffic count data. This produces a distribution similar to the original data represented in Fig. 2. To assess the similarity, we used the Kolmogorov-Smirnov (KS) test [17], which evaluates the similarity between two distributions by calculating two metrics: KS statistic and p-value. The KS statistic measures the maximum discrepancy between the distribution functions of datasets. The p-value measures the probability of low discrepancy between the two datasets. The null hypothesis is true when both distributions are similar. We reject the null hypothesis if the p-value is below the accepted significance of 0.05.\nThe Tempe Department of Transportation provides the vehi- cle count data for just four days, and the days on which they were collected are randomly presented. Of the 30- day simulated data, we selected four days randomly for validation. We observed that, though there is variation in the KS Statistic and the p-value, all of them pass the cut- off according to the algorithm as shown in Fig. 5, indicating similarity between the simulated and original data.\nWe evaluated all the models on a newly generated evaluation dataset for the same region, consolidated in Table IV. We observe that XGBoost's performance improves drastically compared to the model's performance on microscopic data, showing the importance of considering microscopic datasets for traffic incident detection. Our TabNet approach is more accurate than XGBoost, with a DR of 98% and FAR of 6.26%. The downside we observed is that the MTTD is 197.44s, almost 100s higher than XGBoost. However, this is offset by the much lower FAR, which indicates that our model has the ability to report incidents more accurately while remaining fast enough to be within the 7-minute mark, as defined in [2]. The inference time of the TabNet model on the Intel Xeon W-2555 CPU was 5 ms, providing timely insights and supporting real-time decision-making.\nSensing hardware is fallible and degrades over time, thus it is reasonable to assume that not all cameras will be working at all times. It is vital for a model to be able to work even in such conditions. So, we test our model's performance with increasing levels of sparsity. We start with a realistic sensor deployment at 8 of the 43 possible intersections and scale down to just 3 intersections.\nIn Fig. 6, we observe with increased sensor sparsity that our model still retains the capability to detect if an inci- dent occurs, but the accuracy of localization and severity predictions is reduced. Interestingly, with only six sensors, the MTTD does not increase much. However, the MTTD increases more drastically with fewer than 6 sensors. The FAR also increases with an increase in sparsity. Although we observe this increase, we show our model is still capable of predicting metrics, even during infrastructure anomalies.\nGiven that our model works in urban regions, we test if our approach works in a highway scenario. We used an 8- mile highway stretch, inserted the sensors on every available ramp, and simulated the microscopic dataset. We trained and evaluated using XGBoost and our model. The metrics obtained are shown in Table V. XGBoost model performed better than the previous works shown in Table I. Our model performed better than XGBoost in terms of DR and FAR, with a very minimal increase in the MTTD, proving that our approach works in both urban regions and highways.\nA. Our Microscopic Data Matches Very Well with Real- World Macroscopic Data\nB. IncidentNet is Better at Detecting Incidents in Urban Regions Compared to the Previous Works\nC. IncidentNet Works Even In Sparse Sensing Condition\nD. IncidentNet can Detect Incidents on Highways"}, {"title": "VII. CONCLUSION", "content": "In this paper, we have shown that IncidentNet can success- fully detect traffic incidents with a high detection rate in urban roads using microscopic sensor data. In particular, the results confirm that using just 3 instrumented intersec- tions of the 43 possible IncidentNet can accurately detect, localize, and classify incidents in a large area, marking a significant advancement in traffic management technologies. Building upon this supervised model, a promising next step is implementing a semi-supervised version of IncidentNet. This would allow the model to continually improve and handle recurring congestion when deployed in real-world settings. This work also highlights the importance of sensor placement in sparse sensing scenarios, highlighting the need for an algorithm to efficiently place sensors while maximiz- ing the incident detection rate in sparse sensing. Further investigation could extend to categorizing incidents into more classes and enhancing localization accuracy, possibly including rough estimation of distances of incidents from the intersections. Additionally, extending to other regions is part of the future scope of this work."}]}