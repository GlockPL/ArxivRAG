{"title": "Explaining Model Overfitting in CNNs via GMM Clustering", "authors": ["Hui Dou", "Xinyu Mu", "Mengjun Yi", "Feng Han", "Jian Zhao", "Furao Shen"], "abstract": "Convolutional Neural Networks (CNNs) have demonstrated remarkable prowess in the field of computer vision. However, their opaque decision-making processes pose significant challenges for practical applications. In this study, we provide quantitative metrics for assessing CNN filters by clustering the feature maps corresponding to individual filters in the model via Gaussian Mixture Model (GMM). By analyzing the clustering results, we screen out some anomaly filters associated with outlier samples. We further analyze the relationship between the anomaly filters and model overfitting, proposing three hypotheses. This method is universally applicable across diverse CNN architectures without modifications, as evidenced by its successful application to models like AlexNet and LeNet-5. We present three meticulously designed experiments demonstrating our hypotheses from the perspectives of model behavior, dataset characteristics, and filter impacts. Through this work, we offer a novel perspective for evaluating the CNN performance and gain new insights into the operational behavior of model overfitting.", "sections": [{"title": "1. Introduction", "content": "In recent years, Convolutional Neural Networks (CNNs) have exhibited remarkable success across a multitude of applications, particularly in the domain of computer vision. Although CNNs exhibit impressive performance, they are frequently regarded as \"black-box models\", characterized by a lack of transparency and interpretability in their decision-making processes [1]. This lack of transparency presents significant challenges, particularly in crucial domains like medical diagnosis, autonomous driving, and risk assessment, where a comprehensive understanding of model decisions is paramount for trust and reliability [2, 3, 4].\nThe interpretability of CNNs remains a pressing issue due to the absence of standardized methods. Various approaches have been proposed to elucidate the learning mechanisms of CNNs [5, 6, 7]. It is widely accepted that the convolutional filters in CNNs function as feature extractors [8, 9]. While these extracted features are implicit to human understanding and need further processing, techniques such as visualization and spectral analysis can enhance our comprehension of them [10, 11]. Typically, extracted features are multifaceted and intricately intertwined [12], with this entanglement becoming more pronounced as the model depth increases [8]. Additionally, research suggests that filters in shallower layers tend to extract fundamental features such as shape, color, or texture, which are common across various classes. Conversely, filters in deeper layers tend to learn abstract concepts such as eyes, body parts and so on [13]. These features are often more class-specific, thereby contributing to the CNN's classification capacity.\nIn this paper, we explain CNNs by exploring the relationship between the clustering results of feature maps and model overfitting. Given a pre-trained model, we cluster all the feature maps corresponding to individual filters as shown in Fig 1. We further visualize the clustering results, where each data point corresponds to one feature map generated by one input image. As illustrated in Fig 2, in the normal cases, the feature maps exhibit effective clustering results, aligning with the conventional perspective that filters function as clustering functions. In rare cases, small clusters or outliers points may appear in the clustering results. For convenience, samples corresponding to outlier points and samples in small clusters are called outlier samples. We name the filter corresponding to this rare type of clustering result as anomaly filter. We find that the presence of the anomaly filter suggests potential overfitting of CNNs. Experiments are devised to validate this assumption, yielding the following hypotheses:\n\u2022 Anomaly filters increase in overfitting models. We observe models at different epochs during the training process and find a substantial increase in the number of anomaly filters when the model is overfitting.\n\u2022 Outlier samples contribute to model overfitting. We find that during the training process, the gradients of outlier samples are typically several times larger than those of normal ones. This means that the model overlearns details in unusual samples, which may lead to overfitting of the model.\n\u2022 Discarding anomaly filters enhances the generalization ability of the model. We compare the accuracy changes of the training datasets and validation datasets before and after pruning the anomaly filters in the overfitting models. We find that pruning anomaly filters leads to a decrease in accuracy on the training datasets and an increase in accuracy on the validation datasets. It means that after pruning the anomaly filters, the generalization ability of the model is improved.\nIn this paper, we primarily analyze the relationship between model overfitting and the anomaly filters in CNNs. The principal contributions of our method are outlined as follows:"}, {"title": "2. Related Work", "content": "Numerous methods have been proposed to improve the interpretability of CNNs, and certain patterns have been identified. For instance, researchers have observed that filters can function as feature extractors, learning intertwined and multifaceted features from images [8, 12]. Additionally, filters in shallower layers often learn generic features such as shape, color, and texture, whereas filters in deeper layers tend to extract abstract and discriminative concepts like eyes, body parts, etc [13]. Here, we highlight some notable techniques:\nNetwork Visualization: Visualization emerges as one of the most explicit and intuitive methods for unveiling hidden patterns in models. It encompasses two primary aspects: activation maximization and saliency map. Activation maximization generates inputs that maximize the activation for a specific neuron, thereby visualizing patterns learned by models. However, the images generated by activation maximization tend to be intricate and peculiar to human observers, necessitating techniques such as regularization to further optimize the results. Nguyen et al. [8] introduced Multifaceted Feature Visualization and center-biased regularization to yield clearer and more comprehensive interpretability results. Saliency maps assign importance scores pixel-by-pixel. Class Activation Mapping (CAM) in [14] generates a class activation map by multiplying the feature map of the last convolutional layer with relevant weights. However, it replaces the fully connected layer with global average pooling (GAP), thus requiring modification and retraining of the original models. Grad-CAM, introduced by Selvaraju et al. [15], further incorporates gradients as the role of relevant weights. It requires no modification of models, only the backpropagation of gradients, thereby generating more flexible class activation maps. Layer-wise Relevance Propagation [16] propagates the correlation of output back to quantify the contribution of each neuron/filter to the final prediction. It introduces some basic rules to obtain the decomposition of relevance in terms of messages sent to neurons of the previous layers. Neural Network Scanner (NNS) emulates the way fMRI works and scans given ANN models [17]. It is used to visualize neuron learning results for different components of neural networks in a unified way.\nFeature Attribution: While saliency maps primarily assign attributions at the pixel level, other model-agnostic algorithms for feature attribution have been introduced. Local Interpretable Model-agnostic Explanations (LIME) [18] is a technique for explaining classifier predictions in an interpretable and faithful manner. The main idea is to locally learn a model with better interpretability (such as a linear model or decision tree) around the prediction to serve as a substitute for the original model. Thus, LIME provides interpretation locally. SHapley Additive exPlanations (SHAP) [19] conducts feature attribution inspired by game theory. It introduces the Shapley value from game theory to calculate the contribution of relevant features, thus having a solid theoretical foundation.\nSemantic Information: Algorithms aimed at extracting semantic information from models, which align better with human understanding, have been explored. One approach involves incorporating human-defined knowledge. Testing with Concept Activation Vectors (TCAV) [20] learns hyperplanes that separate samples with or without a certain concept, thereby quantifying the degree to which a user-defined concept influences a classification result. Zhang et al. [12] construct explanatory graphs for CNNs where each node corresponds to a specific concept. This method is based on the assumption of spatial relationships in CNNs. Another approach named Interpretable Convolutional Neural Network [21] involves modifying model architecture to mimic the way humans process information. It utilizes delicate masks and designed loss functions, enabling filters to learn single concepts instead of entangled combinations, making it more understandable to humans.\nAmong these methods, visualization is the most intuitive and explicit one. However, it is subjective due to the lack of common standards, often necessitating additional explanations from human observers. Feature attribution provides stronger theoretical foundations. Nevertheless, when applied to CNNs, it requires pre-defined artificial features such as superpixels. Moreover, solid theoretical foundations often result in algorithms with high complexity. Semantic information closely aligns with how we process visual input, but human-defined knowledge or artificial modifications may not align with the inherent nature of models, potentially introducing biases to interpretations. In other words, improvements in interpretability often come at the cost of performance or accuracy."}, {"title": "3. Method", "content": "In this section, we aim to evaluate and interpret CNNs at the filter level. As shown in Fig 3, we begin by clustering the feature maps corresponding to each filter using Gaussian Mixture Model (GMM). The number of cluster classes K is assigned meticulously and dynamically. Subsequently, we establish criteria for identifying distinct patterns, referred to as the anomaly filters, which offer valuable insights into the CNN behavior. An anomaly filter possesses the following three defining attributes:\n\u2022 Unbalanced class distribution. In the normal filters, the distribution of data points within clusters tends to be relatively balanced. However, in anomaly filters, the clustering results may show small clusters and outlier points. The presence of these small clusters and outliers is the primary characteristic of the anomaly filter.\n\u2022 Abnormally high CH Index. We utilize the Calinski-Harabasz Index (CH Index) [22] as a metric to evaluate the quality of clustering results. The anomaly filter demonstrates an abnormally high CH Index due to the presence of outlier points that are significantly distant from normal clusters.\n\u2022 Sufficiently large activation values. This criterion ensures that the feature maps corresponding to the studied filters exhibit substantial activation values, indicating their relevance and warranting further investigation.\nThe detailed steps are listed as follows."}, {"title": "3.1. Filter-based Clustering", "content": "We begin by acquiring the feature maps F\u00b9 of a certain layer I consisting of C channels and $F^l \\in R^{Batch\\times C\\times W\\times H} = [F_1^l, F_2^l, ..., F_C^l]$. To facilitate subsequent clustering, we reshape and reduce the dimension of the original F\u00b9. Through concatenating, we obtain $S^l \\in R^{Batch\\times C\\times (W*H)}$, on which Principal Component Analysis (PCA) is applied. Specifically, we reduce the dimension to 2 for further visualization and obtain $D^l \\in R^{Batch\\times C\\times 2}$. Eventually, D\u00b9 is acquired for the following clustering.\nIn this work, we employ a probability-based clustering algorithm called GMM. GMM assumes that data are drawn from a mixture of Gaussian distributions with different parameters \u03c0\u03ba, \u03bc\u03ba, \u03a3\u03ba. While \u03bc\u03ba and \u03a3\u03ba represent the mean and variance of the kth Gaussian distribution respectively, \u03c0\u03ba denotes the weight of the kth Gaussian distribution. Therefore, p(x) depicts the distribution where each data point x is sampled:\n$p(x) = \\sum_{k=1}^K \\pi_k N(x|\\mu_k, \\Sigma_k).$\nWe apply GMM at the filter level. For $D \\in R^{Batch\\times 2}$ in channel c, the classical Expectation-Maximization (EM) algorithm [23] is used for iterative optimization of relevant parameters. For each data point x in the two-dimensional space, we initially calculate the posterior distribution of x belonging to a certain class:\n$p(z=k|x) = \\frac{\\pi_k N(x|\\mu_k, \\Sigma_k)}{\\sum_l^K \\pi_k N(x|\\mu_k, \\Sigma_k)}$\nwhere z is a hidden variable denoting the class to which x belongs. Subsequently, the posterior distribution is used for reestimation of the marginal likelihood of the given data D and parameter optimization:\n$\\pi_k, \\mu_k, \\Sigma_k = arg \\max_{\\pi_k, \\mu_k, \\Sigma_k} (\\sum_{i=1}^C ln (\\sum_{k=1}^K \\pi_k N(x|\\mu_k, \\Sigma_k)))$\nAfter several iterations, x is assigned to the class that maximizes the posterior distribution in Eq. (2). GMM takes advantage over traditional K-means, for GMM conducts soft clustering where the probability of data belonging to each class is calculated. Moreover, the nature of GMM allows it to fit clusters of all shapes and sizes, while K-means is limited to spherical clusters. However, it should be noted that GMM still requires a preassigned class number K, which determines the total number of Gaussian distributions in Eq. (1). The selection of K will be further discussed in Section 3.3."}, {"title": "3.2. Filter Evaluation", "content": "Since the filter possesses the ability to cluster, it offers a novel perspective for exploring models by assessing the clustering results on feature maps. Naturally, filters that yield high-quality clustering results are deemed more significant to the model, as feature maps have likely captured common and useful information. Conversely, filters that produce poor-quality clustering results are considered to play a less impactful, or even detrimental, role in the model. Therefore, it is crucial to propose reasonable metrics for evaluating clustering. Here we adopt the CH Index as our metrics:\n$CH = \\frac{SSB/(K-1)}{SSW/(N - K)},$\nwhere\n$SSW = \\sum_{i=1}^K \\sum_{j=1}^{|C|} |x_{ij} - m_i|^2,$\nand\n$SSB = \\sum_{i=1}^K |C_i| \\cdot |m_i - m|^2.$\nIn Eq. (4), SSB and SSW stand for between-class and within-class divergence matrix respectively. While SSB is calculated using the weighted Euclidean distance between each cluster center m\u1d62 and data center m, SSW takes the sum of Euclidean distance between each data point x\u1d62\u2c7c and the corresponding cluster center m\u1d62. CH Index adopts an intuitive way of measuring the quality of clustering, wherein high-quality clusters should exhibit close resemblance within the same class while being distinguishable across different classes.\nCH Index serves as a simple yet efficient metric for evaluating clustering in an unsupervised manner. In this work, we conduct filter-by-filter evaluations for the clustering results formed by $D^l \\in R^{Batch\\times C\\times 2}$ and perform horizontal comparison within individual layers."}, {"title": "3.3. Dynamic Assignment of the Number of Classes", "content": "In the aforementioned cluster methods, emphasis has been placed on the preassigned class number K. We have also illustrated that clusters of each filter indicate certain patterns it has learned, although the exact number remains elusive. To tackle this issue, we intend to dynamically assign the number of classes for each filter. All that is required is to determine an approximate range, from which we select K as the final choice that yields the highest CH Index. The reason is that the highest CH Index indicates the optimal fit of the selected K to the behavior of filters, thus it can approximate the number of patterns learned."}, {"title": "3.4. Anomaly Filter Selection", "content": "CH Index offers us quantitative filter evaluation. Through further visualization, a distinctive yet significant pattern in the clustering results is revealed. Fig 3 has shown some typical clustering results. In normal scenarios, clustering results exhibit the pattern characterized by evenly distributed data points. However, a distinct pattern emerges where the majority of points cluster around the zero point (or a specific point), with a few outliers lying far away, thereby forming small clusters and outlier points.\nThere are three specific characteristics in the clustering results of an anomaly filter: 1. Unbalanced class distribution. 2. Abnormally high CH Index. 3. Sufficiently large activation values. As we visualize the clustering results of the anomaly filters in Fig 3, we notice that a typical rare case scenario occurs when most of the data points cluster around zero point while only a few outliers are situated far away. While the majority of data form two or three clusters, outliers may form several individual clusters, thus contributing to characteristic 1. The characteristic 2 bears a close relation with the nature of CH Index itself. As observed in Eq. (4), an abnormally high CH Index may occur when SSW is extremely small in magnitude and SSB is significantly large. Eventually, to eliminate interference factors in the process of anomaly filter selection, we place a threshold on the magnitude of feature map activations, which efficiently excludes trivial situations where the filters are scarcely activated. The characteristic 3 aids in excluding redundant filters and shifting the focus towards filters that significantly impact model performance. We consider the anomaly filter as a crucial indicator for analyzing the behavior of models, which will be explored further in the following section."}, {"title": "4. Experiment", "content": "In previous sections, we have introduced a novel method for CNN interpretation and evaluation on a channel-by-channel basis through clustering, and we have also emphasized the importance of the anomaly filter. Through metic-ulous analysis of the characteristics of the anomaly filters, we consider it as a potential indicator of overfitting, offering fresh insights into the CNN interpretation. Here we devise three experiments to demonstrate the relationship between the anomaly filter and model overfitting. They are conducted across three CNN models and datasets.\nModels: To demonstrate the broad applicability of our method, we select three models of varying architectures. Our experimentation encompasses classical CNNs such as AlexNet [24] and LeNet-5 [25], alongside a three-layer simple CNN with a filter configuration of 32-64-64. These models differ in depth, kernel size, channel number, etc., thereby validating the generalizability of our approach."}, {"title": "4.1. Anomaly filters increase in overfitting models", "content": "To investigate the relationship between the anomaly filters and model overfitting, we focus on the variations in anomaly filter counts within the same model across different epochs. We employ the CrossEntropy loss function and the Adam optimizer for training the models, with the epoch number set to 100. During the training process, we assess model overfitting based on the validation accuracy. Fig 4(a) illustrates a typical training curve for a simple CNN on CIFAR-10. The accuracy on validation datasets initially ascends before descending, while the loss exhibits the inverse trend. Additionally, we plot its anomaly filter curve in Fig 4(b), depicting how the numbers of anomaly filters change in different epochs. We notice that the numbers of anomaly filters show a trend of fluctuation and rise, where the number of anomaly filters is relatively small in the well-trained epoch and large in the overfitting phase.\nAdditionally, we conduct a pairwise comparison by selecting a well-trained model and an overfitting model from each training process. We designate well-trained models as those demonstrating generalization when the loss curve bottoms out and the accuracy curve peaks. Conversely, for overfitting models, we select those from later epochs where there is a noticeable decline in validation accuracy. As shown in Fig 4(a), the well-trained model is highlighted in black and the overfitting model is highlighted in green. Subsequently, we apply our algorithm to the well-trained models and the overfitting models respectively, and tabulate the numbers of anomaly filters. The result is listed in Table 2. Notably, in this experimental setup, no apparent overfitting is observed for AlexNet on Fashion-MNIST. In other cases, we observe a higher incidence of anomaly filters in the overfitting models compared to their well-trained counterparts. Based on the aforementioned findings, we can confidently consider the anomaly filters as indicators of overfitting."}, {"title": "4.2. Outlier samples contribute to model overfitting", "content": "In this section, we investigate the relationship between the outlier samples and model overfitting. As mentioned in [26], sharp minimizers of training functions precipitate overfitting. The overfitting models exhibit a propensity to adjust to minor fluctuations in training data, resulting in abnormally high gradients for certain parameters. In our experiment, we quantify the impact of samples on model overfitting by calculating their gradient values. As shown in Table 1, we filter out samples that form clusters comprising no more than 5 data points as the outlier samples. This categorizes the data into outlier samples and normal samples. Subsequently, we calculate the absolute gradient values on the well-trained models and the overfitting models respectively. Here we adopt the back-propagation algorithm, wherein the loss is propagated layer-by-layer in the form of gradients.\nWe calculate the gradients of each layer and summarize their averages in Table 3. Firstly, we can observe that both the outlier samples and the normal samples exhibit higher gradients in the overfitting models compared with the well-trained models. Secondly, upon comparing the outlier samples with the normal samples, we observe that the outlier samples tend to have higher gradients in both the well-trained models and the overfitting models. For instance, in LeNet-5 trained on CIFAR-10, the gradients of outlier samples are over ten times higher than those of normal samples. This suggests that models develop more complex decision hyperplanes around outlier samples to accurately classify them, a characteristic symptom of overfitting. Thus, we elucidate the relationship between overfitting and anomaly filters from the perspective of samples."}, {"title": "4.3. Discarding anomaly filters enhances the generalization of the model", "content": "In this section, we conducted a pruning experiment to assess the impact of anomaly filters on the model's generalization ability. The anomaly filter was masked by setting its values to zero. If an anomaly occurs on the ReLU or maxpool layer, we simply mask the corresponding upper convolutional filter. In this way, we conduct masking at the filter level. Accuracy on the validation dataset is calculated to evaluate the impact of the masked filter on the entire model. It should be noted that stricter rules have been applied in this experiment to screen out the anomaly filter, as masking too many filters will inevitably lead to a decline in accuracy. Consequently, there is no anomaly filter on Fashion-MNIST.\nWe first conduct masking on a single filter (single-filter masking) and summarize the results in Table 4. Table 4 shows the percentage of rise in validation accuracy and that of drop in training accuracy due to single-filter masking respectively. We can observe that the majority of single-filter maskings directly increase the validation accuracy while decreasing the training accuracy, indicating improved generalization ability of the masked models. Better results are possible when we apply stricter rules when screening out the anomaly filter. Additional experiment is carried out to further verify the effectiveness of single-filter masking of the anomaly filters. We carry out random single-filter masking and summarize the results in Table 5. Notably, single-filter maskings of the anomaly filters result in fewer accuracy drops compared to random maskings in all scenarios. Thus, the experiment demonstrates that removing anomaly filters helps enhance the model's generalization ability.\nIn addition, we take a simple CNN on CIFAR-100 as an example for detailed analysis. We mask anomaly filters on the model. As depicted in Table 6, upon applying the masked models to the outlier samples, a notable alteration in the classification results is observed. We can see that most outlier samples are misclassified samples. Among 179 outlier samples, 107 outlier samples are always misclassified before and after the masking operation. Only 26 correctly classified outlier samples maintain their respective classifications. The outlier samples are sensitive to changes in the model fitting curve. 30 out of 179 outlier samples shift from being correctly classified to being misclassified and 16 outlier samples are reclassified from misclassification to correct classification. It indicates that the drop in accuracy is primarily caused by misclassification of the outlier samples, ultimately contributing to improved generalization ability. In this way, we clarify the relationship between the anomaly filters and the generalization ability of the model by conducting pruning."}, {"title": "5. Conclusion and Future work", "content": "In this paper, we present a novel method to investigate the relationship between CNN filters and model overfitting, It is compatible with the nature of CNNs by adopting the idea of GMM clustering. By clustering the feature maps corresponding to individual filters, we identify the anomaly filters that exhibit a close correlation with model overfitting. We propose three hypotheses: 1. Anomaly filters increase in overfitting models. 2. Outlier samples contribute to model overfitting. 3. Removal of anomaly filters enhances the generalization ability of the model. To validate these hypotheses, we design three experiments. By incorporating CNN models of different architectures, the method is proven to have broad applicability. The architectures utilized in this study are relatively primitive. Future investigations will explore the application of our method to more sophisticated CNN models such as ResNet, aiming to uncover additional underlying patterns. The inclusion of residual modules in ResNet introduces complexities that pose significant challenges to further analysis. Additionally, we will explore novel metrics for evaluating clustering results, which would better incorporate semantic information."}]}