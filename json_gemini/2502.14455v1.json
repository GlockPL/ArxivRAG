{"title": "An Efficient Ground-aerial Transportation System for Pest Control Enabled by Al-based Autonomous Nano-UAVs", "authors": ["Luca Crupi", "Luca Butera", "Alberto Ferrante", "Alessandro Giusti", "Daniele Palossi"], "abstract": "Efficient crop production requires early detection of pest outbreaks and timely treatments; we consider a solution based on a fleet of multiple autonomous miniaturized unmanned aerial vehicles (nano-UAVs) to visually detect pests and a single slower heavy vehicle that visits the detected outbreaks to deliver treatments. To cope with the extreme limitations aboard nano-UAVs, e.g., low-resolution sensors and sub-100 mW computational power budget, we design, fine-tune, and optimize a tiny image-based convolutional neural network (CNN) for pest detection. Despite the small size of our CNN (i.e., 0.58 GOps/inference), on our dataset, it scores a mean average precision (mAP) of 0.79 in detecting harmful bugs, i.e., 14% lower mAP but 32\u00d7 fewer operations than the best-performing CNN in the literature. Our CNN runs in real-time at 6.8 frame/s, requiring 33 mW on a GWT GAP9 System-on-Chip aboard a Crazyflie nano-UAV. Then, to cope with in-field unexpected obstacles, we leverage a global+local path planner based on the A* algorithm. The global path planner determines the best route for the nano-UAV to sweep the entire area, while the local one runs up to 50 Hz aboard our nano-UAV and prevents collision by adjusting the short-distance path. Finally, we demonstrate with in-simulator experiments that once a 25 nano-UAVs fleet has combed a 200\u00d7200 m vineyard, collected information can be used to plan the best path for the tractor, visiting all and only required hotspots. In this scenario, our efficient transportation system, compared to a traditional single-ground vehicle performing both inspection and treatment, can save up to 20 h working time.", "sections": [{"title": "1 Introduction", "content": "Heterogeneous ground-aerial autonomous robots combine the advantages of both (i.e., agile flying drones and high-payload ground vehicles) and mitigate the limits of each, i.e., reduced payloads and exploration speed respectively, leading to efficient autonomous transportation systems [8, 32]. Many different transportation applications can benefit from this pattern, from warehouse management [55] to traffic monitoring and control [52], precision agriculture [49], and emergency response scenarios [50]. In all these cases, combining accurate analysis (e.g., from a flying drone) with decentralized decision-making processes (e.g., optimal path planning) leads not only to the obvious economic advantage of reducing costs (e.g., transportation and delivery costs) but also to additional social and environmental benefits, of saved time and resources.\nThis work addresses smart farming crop production, enabling prompt, precise, and efficient treatments in cultivated fields. To reach the goal of timely fine-grained treatments (up to single plants) in the event of pest outbreaks, accurate pest detection and optimal planning of routes for slow machinery are of the essence. Reducing the use of pesticides not only brings economic benefits for farmers but also reduces the environmental impact of mass production. This work addresses this challenge by designing a two-level autonomous transportation system. The forefront is represented by a fleet of miniaturized autonomous unmanned aerial vehicles (UAVs), a new class of inexpensive airborne called nano-UAVs [35, 36] as big as the palm of one hand, i.e., sub-50 g weight and less than 10 cm in diameter. Instead, on the ground, we rely on an automated tractor acting as the backbone for the heavy-duty job [6, 62], i.e., pest control in the environment. Thanks to their agility, nano-UAVs can quickly act as probes to comb vast cultivated areas, looking for the first signs of pest outbreaking, leaving the fine-grained treatment (e.g., spraying chemicals) to the bulky and slow tractor.\nHowever, the agility of nano-UAVs comes with ultra-constrained onboard resources, such as simple sensors, a few tens of MB of memory, and sub-100 mW for the onboard computational power [46]. Nevertheless, our nano-UAVs are required to i) analyze, in real-time, images acquired on board for detecting harmful insects, and ii) fly autonomously, following a pre-defined path but avoiding collisions with unexpected dynamic obstacles. To cope with this scenario, we employ a commercial off-the-shelf (COTS) Crazyflie nano-UAV featuring an STM32 microcontroller unit (MCU) and extended with a low-resolution camera, an 8\u00d78 Time-of-Flight (ToF) depth sensor, and an ultra-low power Greenwaves Technologies (GWT) GAP9 multi-core System-on-Chip (SoC).\nWe address the former task by optimizing and deploying a State-of-the-Art (SoA) vision-based deep learning model, i.e., SSDLite-MobileNetV3 [22], re-trained for pest detection and running on the GAP9 SoC. Instead, the latter task is handled with a global+local path planning approach [40], where both planners are based on the A* algorithm [19], a graph-based path planning algorithm. The vast cultivated field is split into 40\u00d740 m areas due to the limited battery lifetime of nano-UAVs (i.e., ~6 min). For each area, we convert a static 2D occupancy map [15] of the field (i.e., a vineyard in our case) in an 8-connected graph [18]. Before the mission starts, the global path planner computes the optimal path for each nano-UAV on such a graph, enforcing the complete exploration of the area. Then, during the mission, the local planner, running on the STM32 aboard our nano-UAVs, takes in input a local occupancy map of 4\u00d74 m continuously updated from the onboard depth sensor. Therefore, the local planner can adjust the path if a new obstacle lies on the pre-computed global path. Thanks to the real-time performance of the local planner up to 50 Hz, we achieve the desired reactive obstacle avoidance functionality.\nOur main contribution is a novel integrated transportation system that combines autonomous ground and aerial vehicles. We design, optimize, and deploy a SoA convolutional neural network (CNN) capable of achieving up to 0.79 mean average precision (mAP) for accurate pest detection,"}, {"title": "2 Related works", "content": "In this section, we first go over insect detection and control and then focus on the problem of routing in autonomous vehicles."}, {"title": "2.1 Pest detection and control", "content": "Traditional techniques to avoid spreading dangerous insects in cultivated fields have employed coarse-grained use of pesticides spraying entire fields, with the downside of potential health issues, environmental impact [24], and waste of resources. More fine-grained control of pest outbreaks can be achieved by relying on humans to visually inspect crops and manually treat only where needed, but this approach is expensive and potentially dangerous for human operators. An important step forward in the precise treatment of pests has been achieved by introducing insect traps, originally monitored by humans [48] and later on, thanks to the advent of battery-powered embedded systems featuring automatic bug detection capabilities. This novel technology, also called smart traps [51], has been successfully utilized against the Cydia pomonella [28] and the Popillia japonica [45], leaving the final chemical treatment either to humans [48] or by autonomous ground robots [62].\nSoA insect detectors, employed in combination with smart traps, leverage image-based computationally intensive deep learning models [2, 59, 60, 60], as surveyed by [63]."}, {"title": "2.2 Routing for autonomous transportation systems", "content": "In our scenario, vehicle routing must be addressed at two different levels: global and local. Global routing consists of defining the overall path to follow in order to completely explore an area or visit a set of points of interest, while minimizing some cost metric. This problem is widely known in literature as the traveling salesman problem (TSP). Local routing, instead, consists of reactive planning of a local path, following some goal while avoiding unexpected obstacles the vehicle might encounter. The work by Marin-Plaza et al. [40], similarly to ours, presents a partitioning of the routing problem between global routing, for the overall path, and local routing, for obstacle avoidance. However, they focus on a setting with a single land vehicle.\nGlobal routing. The TSP is a well-known optimization problem: the objective is to find the route the salesman has to travel to visit a set of destinations, represented as nodes in a graph, which minimizes some cost metrics. Our global routing scenario falls within the category of multiple traveling salesman problem (MTSP), which is a generalization of TSP to the multiple agent setting [9], generally cooperative. In this scenario, common metrics to minimize are the total path length among agents (Min-Sum) or the maximum path length (Min-Max). Variations of MTSP may involve multiple depots from which the salesman can depart or arrive, as well as constraints on departing and arriving at the same depot. Moreover, specific applications may adopt additional optimization objectives, like travel time or resource consumption minimization.\nIn some cases (e.g., UAVs), additional constraints might be considered, like fuel or physical maneuverability. The MTSP problem can be decomposed into a node assignment part, in which each node in the exploration graph is assigned to a specific agent, and a path planning part, in which the path over the assigned sub-graph is computed independently for each agent. Exact methods for the multiple depots MTSP have been proposed [42, 61]. However, these are computationally expensive in general. The most widely adopted approaches are so-called meta-heuristics, which use optimization algorithms to find near-optimal solutions with less computational demands. In this category, evolutionary approaches, such as genetic algorithms (GA), have been widely adopted [1, 4, 69], while also particle swarm optimization (PSO) [67], ant colony optimization (ACO) [38] and artificial bee colonies (ABC) [66] have been proposed to address the task.\nMarket-based approaches have also been explored to a lesser extent [14, 30, 31]. These techniques treat the optimization process as an auction, in which tasks (nodes) are assigned based on the agent's bidding. In recent years, research on the MTSP has moved to take UAVs into account. Wichmann and Korkmaz [68] proposed an approach based on location clustering for task assignment and GA to path definition in the context of wireless sensory networks and mobile sinks. Hayat et al. [20], proposes a classical GA algorithm with a time minimization objective for UAVs in search and rescue missions, while Du [13] proposes GA combined with a hierarchical approach to solving the planning task in the context of pesticide spraying in precision agriculture. Chen et al. [10] specifically addresses the problem of energy constraints in UAVs, in the context of coverage path planning, using a modified GA which explicitly considers the resource limitations of such vehicles. Conversely, Ma et al. [39] proposed a routing algorithm that accounts for explicit constraints in task execution time (i.e., travel time) by using task clustering and a modified GA for constrained path planning. Hu et al. [25], differently from previous work, proposes the usage of reinforcement learning (RL) for task (node) assignment, while single path planning can be handled by any available solver.\nLocal routing. Local routing consists of solving the problem of finding an optimal local path (i.e., a path relative to the robot's vicinity w.r.t. its speed and distance from objects), which minimizes deviation from the global path, while avoiding collisions. Usually, this is implemented by minimizing some cost function that accounts for real-time information coming from onboard sensors (e.g., LIDAR, sonar, and cameras). Overall, these algorithms modify the robot's planned path to implement reactive behavior in the autonomous vehicle while still reaching some goal. Marin-Plaza et al. [40], adopts the time elastic band (TEB) algorithm [53], which formulates the local routing problem as finding the optimal sub-path in a dynamic hyper-graph which jointly represents the global path (as a sequence of vehicle states) and feasibility constraints (e.g., velocity, obstacles). The optimization problem is then solved by a non-linear programming solver, and the hyper-graph's sparsity plays an important role in terms of computation time.\nHossain et al. [21] propose a local routing algorithm based on combining the dynamic window approach (DWA) [16], for optimal velocity planning, with an improved follow the gap method (FGM) [57], for obstacle avoidance. DWA tries to find the optimal velocity, given the robot's physical constraints, to reach the goal while avoiding static obstacles, resulting in non-reactive behavior. FGM, on the other hand, determines the optimal approach angle to avoid collision by fitting in the largest gap between observed obstacles. This approach is strongly geared towards safety rather than"}, {"title": "3 System implementation", "content": "In this section, we first introduce the nano-UAV platform used in our work, along with the Webots simulation employed. Afterward, we discuss the deep learning models we port to our platform for the detection of pest insects and the routing algorithms we adopt for path planning."}, {"title": "3.1 Robotic platform", "content": "Our work relies on a Crazyflie 2.1\u00b2 nano-UAV for the exploration of the vineyard that consumes, on average, evaluated with wind speeds between 0.5 and 3.4 m/s, ~8.8 W [43], including the electronics."}, {"title": "3.2 Insect detector", "content": "To address insect detection and classification, we utilize a CNN that we designed [11] to fit the computational constraints of the GAP9. Specifically, we focus on fine-tuning, testing, and deploying a MobileNet-based architecture [22] that was originally pre-trained on the COCO dataset [37]. Fine-tuning, a well-known method in transfer learning [70], involves adapting a model trained on one task \u2013 such as image classification on the COCO dataset [37] \u2013 to a similar task in a different domain while taking advantage of the general features learned in the original training.\nAs Figure 4 reports, we selected the MobileNetV3 architecture combined with an SSDLite detector, which is a variant of the MobileNetV3 with SSD, as proposed in [7] for edge device deployment. The backbone of the network is a MobileNetV3 [22] model, consisting of 3.44 M parameters and requiring 584 MMAC per inference, similar to the architecture described in [7]. The SSDLite detector, serving as the network's head, modifies the standard SSD by replacing regular convolutions with depth-wise separable convolutions. This change significantly reduces computational cost \u2013 up to 3.3\u00d7 \u2013 without affecting the mAP, as shown in Table 1. The SSDLite detector also includes a non-maximal suppression layer to filter out redundant or low-confidence predictions. This model takes a 320\u00d7240 pixel image as input and outputs multiple bounding boxes along with class labels and confidence scores. We fine-tune the network over 300 epochs using an SGD optimization algorithm with a learning rate of 0.00025. The training process follows a learning rate schedule with a momentum of 0.9, a weight decay of 0.0005, a warmup phase of 10 epochs, and a minimum learning rate of 0.00005."}, {"title": "3.2.1 Dataset", "content": "Since our task is insect detection, we adopt the dataset from Butera et al. [7], which includes more than 3,300 images of insects, spanning three classes: Popillia japonica, Cetonia aurata, and Phyllopertha horticola. The first is a dangerous pest insect, while the other two, often mistaken for the first, are not. In total, the dataset contains 1,422, 1,318, and 877 samples for each class, respectively. Note that the dataset is the result of a strict filtering process starting from a collection of more than 36,000 images gathered through the Internet. This ensures the near-absence of duplicates that could harm model evaluation. Even though the dataset is not publicly available, a similar dataset can be built by means of popular image search engines, e.g., Google, Flickr, using the 3 insect names as search keys. Figure 5 shows examples of the three insect classes. The dataset was split into training and testing data, with an 80-20% ratio."}, {"title": "3.2.2 Deployment", "content": "To deploy the CNN, we use a platform-specific tool, NN-Tool, developed by GWT, that converts Python code into C code tailored for the GAP9 SoC. NN-Tool supports deployment from onnx or tflite files. In our case, we fine-tune the MobileNetV3 with the SSDLite detector (pre-trained on COCO in PyTorch) on our dataset to produce a float32 CNN, which is then converted into an onnx file. To ensure compatibility with NN-Tool, non-maximal suppression is implemented outside of the neural model, as it is not supported by the tool. NN-Tool also handles tensor tiling and memory hierarchy management, optimizing usage across all on-chip memory levels. As the GAP9 has a single-precision FPU, we deploy the network in float16 and int8 formats. Additionally, we utilize the NE16 hardware accelerator for CNN applications, which requires CNNs quantized in int8. Thus, we deploy on the GAP9 SoC three versions of our CNN: float16, int8, and int8 with NE16 acceleration. Although the platform includes an FPU for hardware-based floating point operations, we still apply int8 quantization to reduce memory usage with minimal accuracy loss, as can be seen in section 4.1.1. For quantization, we estimate the range of float32 values to map into int8, using a subset of the training data to compute expected activation values for the neural network's layers."}, {"title": "3.3 Routing", "content": "The routing algorithm that we use for obstacle avoidance relies on A*. This algorithm takes as input a 2D occupancy map, the source (us, vs), and the destination (ud, vd), which are defined on the map with the horizontal and vertical coordinate (u, v). The algorithm aims to find the optimal path"}, {"title": "3.3.1 Simulation and onboard implementation", "content": "Webots is an open-source, cross-platform simulator that integrates a model of the Crazyflie 2.1 nano-UAV, accurately simulating its dynamics and all of its sensors, including the camera. We use the simulator to develop and test our routing algorithms in the three different areas described in Section 3.3."}, {"title": "4 Results", "content": "In this section, we report our system's results for both pest detection and the global+local planning task. Furthermore, we provide an analysis of the benefits of employing a flying-ground cooperative system w.r.t. traditional ground pest treatment robots."}, {"title": "4.1 Insect detector", "content": "Following, we discuss the detection performance of our CNN for Popillia japoninca, and we evaluate their performance on the selected embedded architecture."}, {"title": "4.1.1 Object detection performance", "content": "In this section, we assess the detection accuracy of each insect class, with a particular focus on identifying Popillia japonica. To evaluate the network's performance, we use the mAP, a standard object detection metric ranging from 0 to 1. A detection is considered correct if the Intersection over Union (IoU) between the predicted bounding box and the ground truth is at least 0.5, following the COCO standard [37]. The network is tested on a set of 660 samples with the most numerically accurate data type, i.e., float32, and exploring variations in deployment float16 and int8 (quantized) formats.\nWhen considering models in float32, the SSDLite-MobileNetV3 (320\u00d7240 input) reaches an mAP of 0.80. Additionally, when deploying the SSDLite-MobileNetV3 in float16 to leverage the single-precision FPUs on the GAP9 SoC, we observe no significant mAP drop compared to its double-precision counterpart, i.e., mAP is equal to 0.80 in float32 and float16. Lastly, when switching from float32 to int8 quantized version, the mAP reduction is less than 2%."}, {"title": "4.1.2 Embedded system deployment performance", "content": "In this section, we conduct a comprehensive evaluation of the performance of all models deployed on the GAP9Shield. Table 4 details three GAP9 SoC configurations, with voltages ranging from 0.65 V to 0.8 V, enabling clock speeds of up to 370 MHz. For our experiments, we adopt the maximum efficiency configuration, which provides optimal battery life while maintaining the target throughput.\nTable 5 presents a detailed analysis of each model's memory requirements, inference latency per image, and total power consumption, including both compute unit and off-chip memory usage. The model is evaluated using different data types (float16 and int8). The peak memory usage is determined based on the network layer with the highest memory demand for input tensors, weights, and outputs. NN-Tool on the GAP9 can efficiently manage memory across the 1.6 MB on-chip L2 and up to 32 MB of off-chip memory.\nWe deploy the SSDLite-MobileNetV3 with a fixed input size of 320\u00d7240\u00d73 (RGB) across three configurations: i) float16 running on general-purpose CL with FPU hardware support, ii) int8 quantized running on the CL, and iii) int8 using the NE16 convolutional accelerator. The float16 version, while supported by the hardware FPU, requires the most memory to store all the weights (~7 MB) and the most peak memory during execution (at most ~3.6 MB). Furthermore, it is the slowest, processing at 2.1 frame/s with 40.6mW of power consumption. By contrast, the int8 version running on the NE16 accelerator requires only 3.4 MB of memory for all the weights while requires a peak 1.8 MB memory for the execution, reaching 6.8 frame/s while consuming 34 mW. Table 5 reports the peak memory required during the execution of the networks. We do not deploy the float32 version of the network since the GAP9 SoC does not have hardware support for this type of computations and, as such, this will result in a sub-optimal performance, in terms of throughput and power consumption, due to the soft-float emulation required which is not justified due to the iso-accuracy w.r.t. the float16 version of the network."}, {"title": "4.2 Routing", "content": "We evaluate our routing w.r.t. its effectiveness in visiting the predefined waypoints and from a latency standpoint."}, {"title": "4.2.1 Waypoints visited", "content": "We evaluate our system using the three different maps described previously in Section 3.3.1: Env 1, Env 2, and Env 3. We perform one run for each map represented in Figure 6, gradually increasing the number of obstacles. The number of obstacles is expressed as a percentage of the total area of the map, and we test five different configurations: 0%, 1%, 2%, 5%, and 10%. The obstacles are cylindric barrels of 1 m\u00b2 randomly positioned in the map without overlapping waypoints and checking that there is always at least one path available to reach the next waypoint of the path. In this experiment, we compare all the routing methods described before each evaluated on every randomly generated configuration of obstacles. The algorithms reported are:\n\u2022 Blind (B), i.e., the UAV follows the predefined path without considering the obstacle seen by the ToF sensor.\n\u2022 Random (R), the UAV performs a path composed of segments with uniformly sampled random orientation in [\u2212\u03c0, \u03c0] and length between 0 and min(dist, 4 m) where dist represents the minimum distance retrieved at that instant by the ToF sensor. The random path is executed until the end of the battery, i.e., 5 min and considering ~1 min to return to the starting point.\n\u2022 Weighted (W) uses local routing with the weighted cost metric.\n\u2022 Shortest (S) uses local routing, considering only the distance between visited cells as a cost metric.\nAs expected, the best-performing routing algorithms are the global ones in all environments; in fact, they are always able to find a solution for the considered path. The use of a global occupancy map allows the finding of globally optimal solutions for the paths and provides feasible path solutions even if local solutions are not available due to the presence of obstacles in the local occupancy map. If we limit the knowledge to a local map, i.e., the map created from the ToF sensor data, the local routing with the W cost metrics achieves the best results in terms of the percentage of waypoints visited w.r.t. the total number of waypoints on the map. It achieves up to 100% of waypoints visited in Env1 and Env2 with all obstacle configurations, while in Env 3, it reaches the end of the path, i.e., 100% of waypoints visited, only in the case of 0% and 1% of the total area occupied by obstacles. Further increasing the percentage of occupied area leads to a decrease in the portion of path completed bottoming at 50% in the case of 10% of area occupied, i.e., 160 obstacles on the map. Still, the routing method provides an improvement over the B and R baselines that reach up to 45%.\nThe S cost metric underperforms in local routing compared to the weighted (W) cost metric. In particular, in our smallest environment, Env 1, the S cost metric yields the lowest performance among all methods. Paths generated with the S metric are more likely to encounter blockages when obstacles are nearby and partially obscured. Although the W cost metric can occasionally face similar issues, it does so less frequently under the same conditions (environment and obstacle positions). Local routing with the W metric demonstrates higher reliability, and blockages are encountered less often than with the S metric. This limitation can be effectively mitigated by introducing random yaw adjustments and forward movements toward a free direction when a blockage occurs."}, {"title": "4.2.2 Onboard computing time", "content": "Figure 10 reports the onboard measurements of the time to compute a solution for the five different obstacles shown in Figure 9. In particular, the W cost metric requires up to 12\u00d7 the time required to find a solution with the S cost metric. This is the case since the S cost metric allows the pruning of the paths that need to be saved because the cost depends only on the distance and thus has a branching factor b* that is lower than the W cost metric. This results in an expansion phase with a lower number of nodes in the case of the S cost metric, which consequently leads to a proportionally lower amount of memory required w.r.t. the W cost metric."}, {"title": "4.3 Complete system performance", "content": "In this section, we evaluate the performance of our flying-ground cooperative system in the treatment of pest insects in a 200\u00d7200 m vineyard. The vineyard is initially split into 25 areas of 40\u00d740 m, and one UAV per area executes an exploration looking for the Popillia japonica that takes only ~5 min considering an average speed of the UAV of 1 m/s. After the exploration phase is completed, a ground robot capable of performing pest control visits all the points where an insect has been detected.\nTo evaluate the improvement in time achieved by the ground robot to perform pest control over the vineyard, we analyze two conditions:\n\u2022 no prior exploration with nano-UAVs, i.e., the ground robot needs to explore the entire field;\n\u2022 prior exploration with nano-UAVs with a variable number (N \u2208 [0,50]) of randomly positioned hotspots in the vineyard.\nThe prior exploration with the nano-UAVs creates a map of the hotspots in the field that the ground robot explores in a second step to perform pest control. The improvement is evaluated by comparing the time required by the ground robot to perform pest control on the entire vineyard, i.e., no prior exploration, w.r.t. the case the ground robot performs the pest control only in the hotspots found by the UAVs. We report the average time required by the ground robot to perform pest control over five runs per configuration."}, {"title": "5 Discussion and system limitations", "content": "Our system employs compact nano-UAVs for both greenhouses and outdoor applications. Indoor environments provide ideal conditions with no weather constraints, while outdoor functionality is limited by weather conditions (e.g., wind speeds up to 3.5 m/s [43] and no rain). Though primarily demonstrated for pest detection, the system can also be applied to tasks like dry plant detection, crop monitoring, and counting. For Popillia japonica, optimal deployment conditions are sunny days with light winds and temperatures around 29 \u00b0C [44] that fit the nano-UAVs' ideal operating conditions.\nNano-UAVs are of particular interest for pest detection because they have a lower environmental impact than standard-sized drones that are currently used for this application. In fact, nano-UAVs produce noise up to 40 dB [58] while their bigger counterpart reaches up to 75 dB [27], as such nano-UAVs provide an interesting solution that reduces the impact on the environment.\nWe test the system across varying hotspot densities (0 to 50) and three crop arrangements (environments 1, 2, and 3), highlighting its advantages over ground robots for early pest detection. Performance is influenced more by obstacle density than by the overall environment layout, thanks to the reliance on local path planning for obstacle avoidance. We now analyze in detail the limitations of our insect detector and of the routing algorithm."}, {"title": "5.1 Insect detector", "content": "The dataset used in our work contains images gathered online rather than images taken directly from a nano-drone. This implies the presence of both pictures where the insects appear in close proximity, and pictures where the insects are much smaller relative to image size. On average, target insects cover 17.1% of an image's total pixels (8.9% for Popillia japonica, 19.8% for Phyllopertha horticola, 22.5% for Cetonia aurata). Figure 12 provides a visual reference for this. From left to right, bounding boxes occupy, on average, 0.9%, 23.9% and 41.9% of the image's total pixels. We believe nano-drones can produce similar images, given their small size and capability of flying between vineyards' rows, close to vines. However, we point out that a real-world deployment would likely benefit from a model trained directly on images acquired by the drones during exploration."}, {"title": "5.2 Routing", "content": "Blockages are a typical problem when relying on local planning strategies, they can occur when obstacles cover the entire FoV of the depth sensor, as reported in Figure 13. In fact, in this condition, the local planner provides a solution that passes through the uncertain region of the map. However, when the UAV starts moving toward the uncertainty region, the depth sensor detects the presence of an obstacle that intersects the new locally planned path. This causes a new iteration of the local planner, which provides a new solution that belongs to the uncertainty region that will result in a collision as soon as the UAV moves towards it.\nThe first solution involves maintaining a record of the surroundings based on the current depth measurement. This approach uses the same local planning algorithm proposed in this work, namely A*, applied to a local map that includes the current depth measurement along with all previous measurements within a 4\u00d74 m area used for local planning. This method gradually maps objects larger than the sensor's FoV, which might otherwise obscure entirely the area ahead of the sensor and cause blockages. While this approach reduces the frequency of blockages, it does not eliminate them, as objects exceeding 4 m in size can still lead to blockages in the current implementation. Other local solutions to mitigate the blockages issue rely on reinforcement learning and swarm cooperation. Still, in our use case, that does not involve communication between UAVs and limits the knowledge of the map to a local instance of 4\u00d74 m obstacles that occlude the entire FoV may always result in blockages. To avoid the blockage issue, a reliable solution is to perform obstacle avoidance on the global map, which cannot be done on our nano-UAVs due to the platform's computational constraints."}, {"title": "6 Conclusions", "content": "This work presents the building blocks for a novel, efficient transportation system applied to a pest detection and control scenario in vineyards, relying on flying and ground robots. We propose an implementation of the pest detection system that runs onboard the Crazyflie 2.1 nano-UAV on the ultra-low power multi-core GWT GAP9 SoC. Due to the limited resources available on this platform, we explore and deploy a CNN-based detection system, i.e., the SSDLite-MobileNetV3 CNN (584 MMAC/inference), scoring an mAP of 0.79 with a throughput of 6.8 frame/s at 33 mW on the GAP9 SoC.\nWe integrate the CNN-based insect detector with an obstacle avoidance algorithm running onboard the Crazyflie 2.1 nano-UAV to allow the autonomous exploration of vineyards. Our local routing A*-based obstacle avoidance algorithm is able to reach up to 100% of the planned waypoints, avoiding all the obstacles in two out of three environments with increasing complexity (from 0 to 10% of the entire area covered with 1 m\u00b2 obstacles)."}]}