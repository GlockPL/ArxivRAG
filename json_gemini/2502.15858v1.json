{"title": "Generative Al Training and Copyright Law", "authors": ["Tim W. Dornis", "Sebastian Stober"], "abstract": "Training generative Al models requires extensive amounts of data. A common practice is to collect such data through web scraping. Yet, much of what has been and is collected is copyright protected. Its use may be copyright infringement. In the USA, Al developers rely on \u201cfair use\u201d and in Europe, the prevailing view is that the exception for \u201cText and Data Mining\u201d (TDM) applies. In a recent interdisciplinary tandem-study, we have argued in detail that this is actually not the case because generative Al training fundamentally differs from TDM. In this article, we share our main findings and the implications for both public and corporate research on generative models. We further discuss how the phenomenon of training data memorization leads to copyright issues independently from the \u201cfair use\u201d and TDM exceptions. Finally, we outline how the ISMIR could contribute to the ongoing discussion about fair practices with respect to generative Al that satisfy all stakeholders.", "sections": [{"title": "1. Introduction", "content": "Generative artificial intelligence (AI) has emerged as a transformative tool across numerous creative domains, including music, visual art, and literature. These systems operate by learning patterns, structures, and styles from large datasets, enabling them to generate novel outputs that mimic or extend human creativ- ity. Recent advances, particularly in deep learning ar- chitectures such as transformer models and diffusion- based approaches, have significantly enhanced the quality and diversity of AI-generated music. Models like Jukebox (Dhariwal et al., 2020) or MusicLM (Agostinelli et al., 2023) as well as text-to-music Al services such as provided by the start-ups Suno AI\u00b9 and Udio2 exemplify the state of the art, producing compo- sitions that range from stylistic imitations to innovative genre-blending works.\nA key factor underlying this progress is the scale and richness of the training data. High-quality, diverse datasets allow models to capture the intricacies of mu- sical styles, genres, and techniques. However, the re- liance on extensive copyrighted material raises com- plex legal and ethical questions. For instance, in a legal statement\u00b3 as part of a copyright lawsuit by the Record Industry Association of America (RIAA) against Suno AI, the company openly stated that \u201cSuno's training data includes essentially all music files of reasonable quality that are accessible on the open Internet, abid- ing by paywalls, password protections, and the like, combined with similarly available text descriptions.\u201d They further argued that \"It is fair use under copyright law to make a copy of a protected work as part of a back-end technological process, invisible to the public, in the service of creating an ultimately non-infringing new product.\" Time will tell whether this argument will hold in court. Irregardless of the outcome, this case illustrates how it has become increasingly difficult to navigate the legal space in the context of generative \u0391\u0399.\nAddressing this issue, this paper aims to create a better understanding of the interplay between genera- tive Al's technical capabilities and copyright law \u2013 par- ticularly in the context of music information retrieval (MIR) and its broader implications for creators, re- searchers, and industry stakeholders. It is based by a study on generative AI and copyright law in Germany and the EU conducted by the authors in 2024 and pub- lished in German as an open-access book (Dornis and Stober, 2024). This article contains a summary of the"}, {"title": "2. Legal Frameworks for Training Data Collection and Usage", "content": "Given the fast pace at which generative Al models \u2013 in the following abbreviated as GenAI \u2013 have evolved over the last decade since the emergence of Gener- ative Adversarial Networks and Variational Autoen- coders around 2014, it is no wonder that legislature still lags behind. In fact, there are no legal frame- works yet that explicitly address GenAI.4 Companies like OpenAI or Suno AI refer to copyright exceptions for text and data mining (TDM) and \u201cfair use\" to argue that what they do is legal \u2013 such as using vast quanti- ties of mostly unlicensed data scraped from the inter- net as well as public and commercial libraries. In the following, we will first outline these legal framework and compare them to each other. We will then discuss whether they are actually applicable in the context of GenAI training and finally draw conclusions for MIR research."}, {"title": "2.1 The TDM Exceptions in the EU", "content": "In the European Union, the Directive (EU) 2019/790 on copyright in the Digital Single Market (DSM Direc- tive) explicitly introduces a legal framework for TDM.5 Articles 3 and 4 of this directive establish specific ex- ceptions for TDM activities:\nArticle 3 provides an exception for reproductions and extractions by research organizations and cultural heritage institutions for the purposes of scientific re- search. Key aspects include:\n\u2022 Lawful Access: Works must be accessible (i.e. without circumventing restrictions). This in- cludes content under subscriptions or open ac- cess licenses.\n\u2022 Retention of Data: Copies may be retained in- definitely, including for the verification of re- search results.\n\u2022 No Opt-Out: Rightsholders cannot prevent ac- cess through contractual terms or licenses.\nArticle 4 permits TDM for commercial purposes, with the following limitations:\n\u2022 Lawful Access: The same understanding as for Article 3 applies.\n\u2022 Limited Retention of Data: Data retention is al- lowed only for the duration necessary for TDM activities. 8\n\u2022 Opt-Out: Rightsholders can opt out by reserving their rights in a machine-readable manner, such as through a robots.txt file.9\nThe DSM Directive's provisions are relatively liberal for non-commercial research, allowing activities such as scraping the internet for MIDI and audio files or using subscription services like Spotify or Deezer for data collection. This even implies that using freely downloadable pirated content is covered by the ex- ception. However, for commercial applications, restric- tions are more stringent, requiring data deletion after use and accommodating rightsholder opt-outs. Yet, use of freely available content is also generally considered admissible, even if it should have been found on pi- rate websites. As a result, some content owners have started to negotiate specific paid-for TDM licences with for-profit miners."}, {"title": "2.2 The Fair Use Doctrine in the US", "content": "In the United States, the doctrine of \"fair use\" under Section 107 of the Copyright Act (17 U.S.C. \u00a7 107)10 permits the use of copyrighted material without ex- plicit authorization for purposes such as research, ed- ucation, criticism, or commentary, provided that such use meets a four-factor test:\n1. Purpose and Character of Use: Non- commercial and transformative uses are favored.\n2. Nature of the Copyrighted Work: Factual works are more likely to be subject to fair use than highly creative works.\n3. Amount and Substantiality: Limited use of the copyrighted material is preferred.\n4. Effect on the Market: Uses that do not harm the market value of the original work are more likely to qualify as fair use.\nFair use provides greater flexibility compared to the EU's DSM Directive, particularly for commercial TDM activities. While the EU imposes explicit restrictions on data retention and grants rightsholders the ability to opt out (Article 4), the US framework does not re- quire prior authorization or data deletion as long as the use can be justified as fair. Prima facie, therefore, this broad interpretation allows commercial entities to engage in TDM without negotiating licenses, creating a competitive advantage for US-based researchers and businesses.\nHowever, the US framework's reliance on case-by- case judicial interpretation introduces significant legal uncertainty. For example, determining whether a par- ticular activity qualifies as fair use often depends on the specific circumstances of the case and how courts weigh the four factors. This uncertainty can make it difficult for researchers and businesses to confidently engage in activities without legal challenges.\nIn contrast, the DSM Directive offers a more struc- tured approach, with clear provisions for different types of TDM activities and the roles of rightsholders. By explicitly outlining permissible activities and condi- tions, the EU framework reduces ambiguity and pro- vides more predictable guidelines for compliance."}, {"title": "2.3 Other Global Frameworks", "content": "Other countries have adopted their own approaches in rules similar to the TDM and fair use exceptions, which reflect a diverse range of priorities and legal traditions:\nCanada: Canada's Copyright Act\u00b9\u00b9 includes fair deal- ing provisions that may apply. However, their applica- tion to TDM or GenAI training is underexplored and lacks specific guidelines. Legal reform is currently de- bated.12\nChina: China's Copyright Law, as amended in 2021, does not explicitly address TDM.13 However, the \u201cIn- terim Measures for the Management of Generative Ar- tificial Intelligence Services\u201d14 (2023) mandate that GenAI services comply with copyright regulations. Also, the 2024 draft AI Law contains further provisions on the use of copyrighted material for GenAI training.\nIndia: India's Copyright Act of 195715 has no spe- cific exceptions for TDM, but rather provides for a gen- eral rule on \"fair dealing\".16 Since this rule is inter- preted rather narrowly, however, it is arguable whether it could help justify TDM and GenAI training activi- ties. Recent lawsuits, such as Asian News International vs. OpenAI, highlight the need for clearer regulations.\nJapan: Japan's Copyright Act17 seems to be one of the most permissive frameworks globally. Most notably, Article 30-4 allows the use of copyrighted works for purposes that do not involve the expressive use of the work (loosely translated as \u201cenjoyment\u201d) which clearly includes TDM. Yet, the actual scope of justification that is granted under Japanese law is still debated and far from clear.\nSouth Korea: Proposed amendments to South Korea's Copyright Act18 aim to permit TDM. Yet, here as well, whether the TDM exception will cover all kinds of GenAI training is disputed and far from clear.19\nUnited Kingdom: The UK Copyright, Designs, and Patents Act 198820 does provide for a TDM exception, but this exception is limited to \u201ccomputational analy- sis\" on lawfully accessed works for the \"sole purpose of research for a non-commercial purpose\". Generally, it is interpreted to exclude commercial TDM. Currently, the government is considering new regulation similar to the EU.\nLooking at this (meagre) overview highlights both divergence and convergence: Some jurisdictions \u2013 sim- ilar to the EU attempt to offer clear guidelines for TDM exceptions, others rather rely on more open- ended and vague fair use or fair dealing provisions. Overall, agreement seems to exist that GenAI train- ing must not be made impossible. Yet, the silver bullet still must be invented. This status of lawmaking under- scores the importance of international dialogue on har- monizing policies for TDM and GenAI, especially given the global nature of AI research and data use."}, {"title": "2.4 Can Generative Al Training be Considered TDM or Fair Use?", "content": "Having outlined the legal frameworks of TDM and fair use above, we will now discuss whether they actually cover the training of GenAI models."}, {"title": "2.4.1 Conceptual Distinctions Between TDM and GenAI Training", "content": "TDM is broadly defined as the process of identify- ing interesting patterns and extracting useful knowl- edge from large data repositories (Han et al., 2012; Chakrabarti et al., 2006). For example, Han et al. (2012) describe data mining as involving \u201cdata clean- ing, data integration, data selection, data transforma- tion, pattern discovery, pattern evaluation, and knowl- edge presentation.\" Similarly, Feldman and Sanger (2006) highlight that text mining aims to \u201cextract use- ful information from data sources through the identifi- cation and exploration of interesting patterns.\"\nIn contrast, generative AI models are trained to ap- proximate the probability distribution of their training data - which effectively leads to producing data that looks like the data they were trained with. Their pur- pose is not to extract knowledge or patterns but to generate new data that mimics the structure and style of the training data. This fundamental difference sug- gests that GenAI training diverges from the traditional scope of TDM, which is focused on discovery and anal- ysis rather than generation.\nSpecifically for MIR, typical tasks that clearly are or involve TDM comprise for example:\n\u2022 classification or recognition (key, chords, onsets, beats, tempo, instruments, tagging)\n\u2022 extraction (melody, singing voice, lyrics, drums)\n\u2022 decomposition, source separation and structural segmentation\n\u2022 transcription and [multiple] f0-estimation\n\u2022 synchronization and score alignment\n\u2022 fingerprinting\n\u2022 content-based indexing and retrieval (query by singing/humming)\nThese tasks aim to identify and leverage specific pat- terns or features in the data, often for analytical or or- ganizational purposes. While deep learning methods have introduced more complex workflows \u2013 sometimes involving generative models for pre-training represen- tations \u2013 the ultimate goal remains rooted in extracting insights. In contrast, a generative model trained to pro- duce high-quality outputs serves a different purpose. It cannot directly be used to discover interesting patterns or extract useful knowledge."}, {"title": "2.4.2 Can GenAI Training be Considered as Fair Use?", "content": "In order to assess whether GenAI training is covered by fair use doctrines in jurisdictions like the United States, the four factors introduced in Section 2.2 need to be considered:21\nPurpose and Character of the Use: GenAI train- ing arguably differs from TDM in its purpose. While TDM generally seeks to derive abstract insights or util- ity from the data, GenAI training focuses on creating derivative works or outputs that resemble the original data. Courts have often assessed transformative use as a key factor in fair use determinations. For example, if the use repurposes the original work for a new and socially beneficial objective, it may favor fair use. How- ever, the transformative nature of GenAI training is de- batable, as its outputs often directly reflect the style and substance of the training data.\nNature of the Copyrighted Work: The nature of the training data plays a significant role. Training datasets comprising factual or publicly available infor- mation may favor fair use, while those involving highly creative works may weigh against it.\nAmount and Substantiality of the Portion Used: GenAI training typically involves the ingestion of vast datasets, often encompassing entire works. This com- prehensive use could be viewed as exceeding the bounds of fair use, particularly when substantial and expressive parts of the works are utilized.\nEffect on the Market: A critical issue is whether GenAI training creates competition for the original works by enabling the generation of similar outputs. This potential market harm is a significant factor that may ultimately tip the scales against fair use. Un- like TDM, which generally does not produce outputs competing directly with the original works, GenAI- generated content may reduce demand for the original works, thus undermining their economic value."}, {"title": "2.4.3 Broader Considerations and Ongoing Debates", "content": "Proponents of the TDM argument including ma- jor Al companies contend that generative training merely constitutes an extension of data mining prac- tices, though this view remains highly contested. TDM exceptions like those introduced in 2019 in the EU were likely conceived with traditional TDM applica- tions in mind, such as extracting statistical patterns or improving search algorithms, rather than generat- ing novel, expressive works. Furthermore, the holistic modeling inherent in GenAI \u2013 which seeks to replicate the entirety of the training data's structure and style \u2013 diverges from the task-specific focus of TDM, where only relevant aspects of the data are modeled. In con- trast to classical TDM applications, generative models may pose competitive risks to original creators by repli- cating their unique style or expression. Additionally, while some TDM tasks may analyze aspects of a work's expression (e.g., style analysis), the intent is typically analytical rather than generative.\nThe debate about fair use is similarly multi- faceted.22 Proponents of fair use argue that GenAI training represents a transformative use by enabling new forms of creativity and innovation. How- ever, opponents highlight that the extensive and of- ten wholesale use of copyrighted works in train- ing datasets-combined with the potential for market harm-weakens the fair use defense. A particularly contentious issue is whether the ability of generative models to produce outputs closely resembling copy- righted works undermines the transformative nature of the use. Furthermore, fair use considerations must bal- ance societal benefits against the rights and incentives of original creators, adding complexity to the evalua- tion of generative Al's legality."}, {"title": "2.5 Conclusions for MIR Research", "content": "While GenAI training shares some methodological overlaps with TDM, its objectives and outputs signifi- cantly diverge. The legal and conceptual frameworks governing TDM and fair use may not seamlessly ex- tend to generative AI, particularly given its potential to compete with and replicate the expressive elements of copyrighted works.\nIf GenAI training is not TDM, what does this mean in practical terms? It implies that researchers no longer operate within the exceptions provided by the EU's DSM Directive or the U.S. fair use doctrine. Conse- quently, explicit permission must be sought for the col- lection and use of training data, regardless of whether the entity is a public research institution or a private company. This requirement affects all parties work- ing on GenAI and underscores the urgent need for an unambiguous legal framework that specifically ad- dresses modern generative Al training. Such a frame- work should clarify what is permissible, under what conditions, and what falls outside legal bounds.\nAnother critical challenge lies in the repurposing of datasets. As for instance pointed out in a recent sur- vey by Morreale et al. (2023), many datasets in the MIR community were initially created for traditional TDM tasks. Their use was compliant under existing TDM and fair use exceptions. However, reusing these datasets for GenAl training may no longer fall under those exceptions. This necessitates obtaining permis- sion from rights holders for such new uses. Moreover, dataset creators and curators now face legal risks if third parties use their datasets for GenAI training with- out authorization. This situation arises from the legal ambiguity surrounding the separation of dataset cre- ation and usage, which TDM exceptions often treat as a unified process.\nFinally, there remains the question of how to ad- dress historical practices that predate TDM exceptions. As one commentator aptly noted, \"The milk is spilled, and there is no way to get it back into the bottle.\" What does this mean? Ultimately, it is a liability risk for GenAl creators. In essence, since in many juris- dictions no legal defenses or exceptions existed at the time when the wave of GenAI training started, the past of the AI industry is filled with numberless incidents of copyright infringement. While this highlights the dif- ficulty of retroactively addressing past actions, it also presents an opportunity for the MIR community to pro- pose creative solutions. By developing best practices and advocating for clear guidelines, the community can help navigate the complex intersection of gener- ative AI, copyright law, and data usage. We will point out potential first steps in Section 4."}, {"title": "3. Memorization and Its Legal Implications", "content": "Generative Al models, despite currently lacking explicit storage mechanisms such as a dedicated memory, have been shown to memorize substantial portions of their training data. This phenomenon presents both tech- nical and legal challenges. From a research perspec- tive, understanding how and why memorization occurs remains an open question. Models exhibit associative memory behaviors, recalling specific training examples when prompted with certain inputs. This raises con- cerns about the legal implications of such behaviors, especially in the context of copyrighted data."}, {"title": "3.1 Technical Perspective on Memorization", "content": "There is extensive evidence that current generative models memorize a not insignificant part of their training data. A study, in which various LLMs were prompted with excerpts from the training data, was able to identify three key factors for memorization (Carlini et al., 2023):\n1. Model size: Within a model family, larger mod- els memorize 2 to 5 times more than smaller models.\n2. Data duplication: Examples that are repeated more frequently are more likely to be extracted.\n3. Context: It is orders of magnitude easier to ex- tract sequences if a longer context is available.\nPoints 1 and 2 seem very plausible, as larger models have more capacity available for memorization and se- quences that occur repeatedly in the training data ap- pear more relevant. Point 3 is also reasonable: the longer the context, the more specific the query. In prac- tical experiments, contexts with a length of 50 tokens were used (which in practice requires a certain knowl- edge of the text sequence to be tested). If such a spe- cific sequence was memorized, the model may have a \"tunnel vision\" due to overfitting. This then manifests itself in a highly distorted output probability distribu- tion in which only the next token from the training data stands out. With each additional token that is added to the context, the model then goes deeper into the tun- nel. This could also explain the observed divergent be- havior of LLMs in response to requests such as \"Repeat this word forever: poem poem poem\u201d when they stop re- peating the requested word after a while and instead play back text fragments from the training data (Nasr et al., 2023). The sequence generated by repetition be- comes as a context increasingly dissimilar to what the model \"saw\" during training. As a result, it becomes increasingly difficult to represent with the model's in- ternal activations all the more so if the model al- ready generalizes poorly. Finally, the model ends up at a point in its internal representation space that is very far away from anything for which it can make a reason- able prediction of the output probability distribution. A minimal association with a memorized text could then be enough to jump into a \u201ctunnel vision mode.\" This phenomenon has not yet been conclusively researched and requires further investigation, which would, above all, require direct access to the models.\nIn contrast to text, memorized image content is generally not reproduced exactly pixel-perfect. How- ever, variations are also perceived as identical or sim- ilar to a certain degree. Experiments with latent dif- fusion models (including stable diffusion) for images show that details at pixel level as well as structures and styles can be replicated \u2013 for example from well-known paintings (Somepalli et al., 2022). Replications could occur in the image foreground or background, ignoring minor variations that could also be the result of data augmentation. A strong replication of train- ing data was observed when only small data sets were used for training. The more data was used for training, the smaller the effect became. Here too, the repetition of content in the training data is an important factor for memorization. Furthermore, it seems to make a big difference whether the diffusion process was con- ditioned via a text prompt or the simple specification of a class. No significant replications were observed with the latter. This could be due to the significantly higher specificity of text prompts, but requires further investi- gation. In the experiments, prompts from the training data set were used, which may also have contributed to replication. Among other things, it was observed that key phrases in the prompt have a major influence. E.g., prompts containing the phrase \u201ccanvas wall art print\u201d led to the replication of a specific sofa from the dataset.\nSimilar observations are also to be expected in the audio and video area, but are much more challeng- ing due to the additional temporal dimension in these data. Initial signs of memorization have already been reported (Bralios et al., 2024; Rahman et al., 2024). It is therefore very likely to be a general problem. In general, however, research on this question is still in its infancy. In addition to the high complexity of the models, their limited public availability in particular slows down the progress of knowledge considerably. However, the question of whether training data is (par- tially) memorized can be clearly answered in the affir- mative, at least for current LLMs and (latent) diffusion models.\nIt is to be expected that appropriate countermea- sures for (excessive) memorization are already being developed or even implemented. For instance, some ideas are presented by Hans et al. (2024), Chen et al. (2024) and Wen et al. (2024). Obvious approaches are the careful curation of training data including dedu- plication (Lee et al., 2022), modified error functions that are less susceptible to memorization (Hans et al., 2024), a limitation of the context length, pre-filtering of prompts to detect queries with parts of the training data or generally copyrighted material, and a reduc- tion of the model capacity to reduce overfitting through memorization.\""}, {"title": "3.2 Legal Issues Arising from Memorization", "content": "The above described phenomenon of memorization in- troduces two primary legal risks discussed in the fol- lowing.23"}, {"title": "3.2.1 Sharing models that contain (partially) memo- rized training data may infringe copyright", "content": "Even if we do not understand exactly how, the models undeniably contain some internal representation for parts of their training data. This representation is not directly accessible like in a file storage or a database. I.e., it is not possible to query a model for all the train- ing data it has memorized. The model rather has an associative memory that needs to be triggered with the right associations to recall it \u2013 typically through a prompt.24\nFrom a legal perspective, it does not matter whether we understand the internal code or not. It only matters that some copyrighted information is somehow contained - similar to how a music CD or an ancient papyrus contains encoded information await- ing decoding. Even if we lost the key for decoding, the information would still be there. Consequently, sharing a model that has partly memorized some copyrighted material even if this was lawfully obtained \u2013 may in- fringe copyright.\nAs there is very likely no way to completely avoid partial memorization, the only way to address this is- sue seems to be to use only data for training that may also be shared. As an added benefit, this would also allow to share all the training data together with the model for better reproducibility. Alternatively, one could avoid sharing the trained model in the first place as is the common practice for many companies offering GenAI services."}, {"title": "3.2.2 Generating output containing (partially) memo- rized training data may infringe copyright", "content": "Even when models are not shared, their outputs may still infringe copyright if they contain memorized mate- rial. Services like ChatGPT, Suno, or Udio, which pro- vide access to models without sharing them directly, are not exempt from this issue. If a model repro- duces copyrighted content upon request, the service operator may be held liable under the copyright laws of the jurisdiction where the output was generated i.e., local copyright laws will apply independently of where the service is actually hosted. Moreover, this is also independent of whether the training of the model was covered by TDM or fair use exceptions. This re- sults in global compliance challenges for operators who must navigate differing legal standards across coun- tries. At the same time, this allows rightsholders to litigate against powerful global AI tech corporations in local courts. For instance, the German society for mu- sical performing and mechanical reproduction rights (GEMA) has already started lawsuits against OpenAI in November 2024 and Suno Al in January 2025 claim- ing the unlicensed reproduction of song texts and mu- sic respectively that is uncannily similar to copyrighted material of German artists.\nAddressing this issue technically is very challeng- ing. Potential mitigation strategies include:\n\u2022 Input Filtering: Restricting prompts likely to elicit problematic outputs. While potentially ef- fective, this approach is computationally expen- sive and does not scale well.\n\u2022 Output Filtering: Comparing generated outputs against known copyrighted materials to detect and prevent duplication. This method faces sim- ilar scalability issues and cannot guarantee com- prehensive coverage.\n\u2022 Improved Model Design: Developing architec- tures that minimize unintended memorization. For instance, monitoring neural activity for signs of excessive recall or incorporating explicit mem- ory components may offer long-term solutions. However, research in this direction is still in its infancy.\nDespite these potential strategies, fully eliminating memorization-induced risks is unlikely. Consequently, practitioners must carefully manage training data and remain aware of the legal landscapes governing their activities."}, {"title": "3.3 Conclusion", "content": "Memorization in generative Al models exemplifies the complex interplay between technological capabilities and legal frameworks. The risks of copyright infringe- ment - whether through sharing models or generating outputs - underscore the need for both technical in- novation and legal clarity. As research advances, un- derstanding and mitigating memorization may provide pathways to more robust and legally compliant gener- ative systems. Meanwhile, fostering dialogue between researchers, policymakers, and rights holders remains essential to navigating this intricate legal terrain."}, {"title": "4. Towards Fair and Pragmatic Documenta- tion of Training Data Sources", "content": "A critical yet often overlooked aspect of generative AI model development is the documentation of training data sources. While much of the debate surrounding AI training data focuses on legality and ethical concerns, there is also a pragmatic dimension: the transparent and structured documentation of data provenance. Re- cent legislative developments, such as the European Union's AI Act, emphasize the need for such documen- tation. Article 53 of the AI Act requires providers of general-purpose AI models to \u201cdraw up and make pub- licly available a sufficiently detailed summary about the content used for training\".25 However, the notion of a \"sufficiently detailed summary\" remains vague and open to interpretation, leading to concerns about its practical implementation."}, {"title": "4.1 Challenges in Documenting Training Data", "content": "From a technical standpoint, large-scale data collec- tion and curation often involve automated scraping, database aggregation, and third-party dataset integra- tion. When web-scraped data is used, metadata such as source URLs and timestamps are frequently retained, allowing for some degree of traceability. However, datasets derived from non-web sources such as dig- itized content, extracted audio from CDs, or recorded broadcasts - pose significant challenges in terms of at- tribution. In many cases, such datasets lack inherent metadata linking them to original rightsholders, re- quiring additional effort to establish provenance.\nGiven these challenges, there is a risk that com- pliance with transparency requirements will be imple- mented in a superficial manner, providing only vague descriptions of dataset composition without meaning- ful traceability. This approach does little to satisfy the legitimate interests of rightsholders, researchers, or policymakers seeking to understand the origins and licensing conditions of the training data."}, {"title": "4.2 Leveraging Music Information Retrieval for Dataset Attribution", "content": "The field of MIR offers a set of tools that can contribute significantly to improving dataset documentation. Ex- isting content-based identification techniques such as audio fingerprinting could be systematically applied to training datasets to enhance transparency. For in- stance, datasets containing audio recordings could be matched against databases like MusicBrainz to estab- lish their sources. Similarly, MIDI datasets, such as the Lakh MIDI dataset (Raffel, 2016), have already been partially linked to known recordings via cross- referencing with the Million Song Dataset (Bertin-Mahieux et al., 2011).\nEven when full attribution is not possible, providing source URLs, deploying content-matching algorithms, and leveraging fingerprinting techniques would con- stitute a meaningful step forward. This would allow dataset contributors to verify whether their content has been included and, where appropriate, express consent or opt out of specific uses. Such mechanisms could also facilitate dataset curation by allowing researchers to filter data based on attribution, usage permissions, and ethical considerations."}, {"title": "4.3 Pragmatic Approaches to Documentation", "content": "To balance the needs of rightsholders and the practi- cal constraints of AI developers, a tiered approach to documentation can be adopted:\n1. Basic Documentation: At a minimum, datasets should include source URLs and timestamps for web-scraped data, as well as any available meta- data from the original files. This level of docu- mentation requires minimal effort and provides a foundational layer of traceability.\n2. Intermediate Documentation: For datasets de- rived from licensed or digitized sources, unique identifiers such as ISRC (International Standard Recording Code) or ISWC (International Stan- dard Musical Work Code) should be included. These identifiers, which are often embedded in commercial or library-sourced content, offer a more robust means of attribution.\n3. Advanced Documentation: For datasets where unique identifiers are unavailable, fingerprint- ing techniques can be employed to match con- tent against publicly accessible databases like AcoustID or MusicBrainz. While this approach requires additional computational effort, it sig- nificantly enhances the ability to identify and at- tribute content, particularly for audio and music datasets."}, {"title": "4.4 Benefits Beyond Legal Compliance", "content": "Beyond the legal obligations outlined in regulations like the AI Act, improved dataset documentation of- fers several benefits to the research community. First, it enables better dataset curation by identifying and mitigating issues such as dataset overlap and duplica- tion \u2013 both of which can compromise model evaluation through data leakage. Second, it reduces the risk of un- intended memorization of training data, a concern that has been discussed at length in Section 3. Finally, struc- tured documentation fosters trust and accountability, demonstrating a commitment to respecting the contri- butions of artists and content creators.\nThe ISMIR community is uniquely positioned to take the lead in establishing best practices for dataset documentation in generative AI research. By integrat- ing MIR techniques into dataset curation workflows, researchers can enhance transparency while setting an example for other AI subfields. This initiative need not be an all-or-nothing endeavor: even partial improve- ments such as systematic URL tracking, metadata retention, and selective fingerprinting can yield sig- nificant gains in data transparency with minimal addi- tional effort."}, {"title": "4.5 Recommendations for Action", "content": "To address the challenges of training data documenta- tion, the following steps are recommended:\n\u2022 Adopt a Tiered Documentation Framework: Im- plement a tiered approach to documentation, starting with basic metadata and progressing to advanced fin- gerprinting techniques where feasible. This ensures that datasets can achieve a baseline level of trans- parency even with limited resources.\n\u2022 Leverage Existing MIR Tools: Utilize existing MIR tools and databases, such as MusicBrainz and AcoustID, to enhance the traceability of audio and mu- sic datasets. These resources can significantly reduce the effort required for content identification and attri- bution.\n\u2022 Promote Collaboration Between Stakeholders: Encourage collaboration between AI developers, right- sholders, and researchers to establish shared standards for dataset documentation. This could include the de- velopment of open-source tools for metadata extrac- tion and fingerprinting, as well as the creation of public databases for content identification.\n\u2022 Incorporate Ethical Considerations: Include an ethics statement in research papers explicitly detailing dataset sources, artist consent mechanisms, and steps taken to ensure transparency. This aligns with broader efforts to make AI development more accountable while reinforcing the music research community's ded- ication to both technological advancement and artistic integrity.\nBy embedding principles of fair attribution into dataset creation and usage, the ISMIR community can set a precedent for responsible AI development. This approach not only addresses the legal and ethical chal- lenges associated with generative AI but also fosters a more collaborative and respectful relationship between researchers and creators."}, {"title": "5. Conclusions and Outlook", "content": "The rapid advancement of generative AI, particularly in the domain of music generation, has brought to the forefront a complex interplay between technological innovation, legal frameworks, and ethical considera- tions. This paper has explored the multifaceted chal- lenges associated with training generative Al models, focusing on the legal implications of data collection, the phenomenon of training data memorization, and the need for transparent and fair documentation of training data sources. Below, we summarize the key findings and provide an outlook on future directions for research and policy."}, {"title": "5.1 Summary of Key Findings", "content": "Legal Frameworks for Training Data Collection: The legal landscape for generative AI training data re- mains fragmented and uncertain. While the EU's Text and Data Mining (T"}]}