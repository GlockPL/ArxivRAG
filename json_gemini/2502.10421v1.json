{"title": "DRIVE: Dynamic Recognition in Vehicles using snnTorch", "authors": ["Heerak Vora", "Param Pathak", "Parul Bakaraniya"], "abstract": "Spiking Neural Networks (SNNs) mimic biological brain activity, processing data efficiently through an event-driven design, wherein the neurons activate only when inputs exceed specific thresholds. Their ability to track voltage changes over time via membrane potential dynamics, helps retain temporal information. This study combines SNNs with PyTorch's adaptable framework, snnTorch, to test their potential for image-based tasks. We introduce DRIVE, a vehicle detection model that uses spiking neuron dynamics to classify images, achieving 94.8% accuracy and a near-perfect 0.99 AUC score. These results highlight DRIVE's ability to distinguish vehicle classes effectively, challenging the notion that SNNs are limited to temporal data. As interest grows in energy-efficient neural models, DRIVE's success emphasizes the need to refine SNN optimization for visual tasks. This work encourages broader exploration of SNNs in scenarios where conventional networks struggle, particularly for real-world applications requiring both precision and efficiency.", "sections": [{"title": "I. INTRODUCTION", "content": "Artificial intelligence (AI) advances in recent years have led to many developments among neural network architectures, each trying to mimic the complexity of biological neural systems. One such architecture Spiking Neural Networks (SNNs) stands out due to its ability to emulate temporal characteristics of biological neurons more closely than conventional and traditional artificial neural networks (ANNs). SNNs are based on encoding through spikes generated when a neuron's membrane potential surpasses a specific threshold. It is similar to the way in which neurons operate using electrical impulses known as action potentials [1]. This mechanism of firing allows SNNs to process information using timing of spikes an approach known as temporal coding. SNNs can adapt the synaptic weights effectively using spike-timing-dependent plasticity, providing a robust framework for learning. To make working with and implementing SNNs easier, snnTorch proves to be a significant tool. It is a Python package designed to incorporate spiking neurons by extending the capabilities of PyTorch. [2]. This framework architecture supports exploration on both small and large networks through various neuron models with features for spike generation, data conversion and visualization. This integration helps conduct research and experiments requiring high performance in real time applications such as computer vision and robotics. There have been numerous attempts at providing effective models for image detection particularly utilizing convolutional neural networks (CNNs) and other traditional methods [3], [4]. These models often require substantial computational resources and energy consumption. SNNs offer an alternative in this aspect providing comparable performance while significantly reducing power consumption and enhancing computational efficiency [1]. This proves to be critical in applications such as image detection that may be further leveraged to construct real time systems and applications such as autonomous vehicles. Through this paper, we aim to utilize these capabilities of SNN using snnTorch implementation for vehicle detection. This represents an innovative approach wherein we explore whether employing SNNs can match the performance at a task that traditionally relies heavily on methods such as convolutional neural networks (CNNs). It helps us investigate if temporal processing can enhance the efficiency of present algorithms without compromising their performance. Such algorithms would be capable of operating under constrained resources which would be significant for applications such as autonomous vehicles."}, {"title": "II. LITERATURE REVIEW", "content": "SNN has very wide scale applications and is considered 3rd generation of neural networks [5]. Research on the same has just been initialized and is still under progress. Very few researchers have studied this under-appreciated method and identified its core principles [6]. For facilitating seamless implementation of SNNs, there exist several frameworks which help in training and utilization, particularly snnTorch [2]. These frameworks may be used for many varied applications such as the usage of Lava framework for bayesian optimization [7], and resource allocation [8]. One such application of SNN, image detection, has few derived methodologies with considerable accuracy namely AMOS (80.97%) [9], Spikformer V2 (94.80%) [10], S-ResNet30 wider (92.66%) [11], and CSNN-blurr9 (92.85%) [12]. Niu et al. [13], presents a thorough review summarizing and tracking the research progress of SNN for image recognition. Through this paper, we aim to establish a better methodology for image detection using snnTorch implemention."}, {"title": "III. PROPOSED METHODOLOGY", "content": "snnTorch is a library that aims to bridge the gap between traditional deep learning approaches and biologically inspired neural computations. This allows researchers to explore applications in which conventional approaches already excel but SNN may be used to enhance efficiency and computational overhead such as image detection. snnTorch enables integration with PyTorch's autograd system which makes it seamless to incorporate SNNs into existing architectures. The architecture of snnTorch is built around core components that create a functional spiking neural network together. It commonly works on Leaky Integrate-and-Fire (LIF) neurons due to their simplicity and biological plausibility [1]. The working of snnTorch architecture starts with the input layer. This consists of neurons that receive data encoded as spikes. The encoding method allows network to process temporal information. The method works on frequency of spikes over time that represent intensity of values. Here, higher intensity corresponds to more frequent spikes. The output of this layer goes through to the hidden layers. It consists of multiple types of spiking neurons arranged in various configurations. Users can define these layers using PyTorch constructs in snnTorch while incorporating spiking behaviour through the neuron classes. The layer consisting of output neurons that generate spike trains corresponding to class predictions is the output layer. Our model employs a similar training process for vehicle image detection that further emphasizes applications such real-time processing capabilities for autonomous vehicles, robotics and computer vision. These applications relied upon approaches such as CNNs traditionally [3]. The novelty of our project lies in integrating advanced techniques such as surrogate gradients and batch normalization within our model architecture that employs SNN using snnTorch implementation and leverage the unique temporal processing abilities to reduce computational overhead as well as achieve a performance on par with CNNs for image detection particularly vehicle image detection. We aim to utilize a multi-layer feedforward architecture for accomplish this objective. It would be composed of spiking neurons designed specifically for vehicle image detection tasks that make up three fully connected layers. These layers are applied with batch normalization after each linear transformation."}, {"title": "IV. RESULTS AND DISCUSSION", "content": "The dataset we used in this research is the \"Vehicle Detection Image Set\", extracted from Kaggle [19]. The dataset has two classes, Vehicle and Non-Vehicle, that add up to 17,760 images; out of which we utilized around 1070 images in both the classes. The images were pre-processed to maintain uniformity by resizing them to 128x128 pixels while at the same time preserving their aspect ratio. Moreover, padding was applied to maintain a consistent square shape for all images, with grayscale conversion to simplify the processing. The pixel values were normalized to the range [0, 1] for enhancing model compatibility. In order to get a balanced distribution during training, the pre-processed dataset was randomly shuffled.\nFor evaluating and training our mode, we split the data into training and testing sets, assigning 80% and 20% to the sets respectively. The splitting helps in substantiating the model's generalizability and predictive powers.\nThe hyperparameters play a very important role in influencing the model's efficacy and overall performance. As shown in Table II., we use a batch size of 30 that helps in balancing the computational efficiency and stability of the gradient. A learning rate of le-3 fits best for our model ensuring steady convergence during training, with the 20 epochs to allow sufficient iterations for the model to learn. A hidden layer of size 64 lets the model adequately learn the complex patterns, while the membrane potential decay rate of 0.95 maintains a balance between spiking activity and temporal memory. The number of simulation steps per input is set to 50 are carefully tuned to optimize the SNN model.\nThe categorical cross-entropy rate loss function is used in the training process which leads the model to minimize errors by calculating the difference between predicted and actual outputs. The AdamW optimizer which is known for its ability to balance weight updates along with weight decay, is also used for ensuring efficient convergence while at the same time preventing overfitting."}, {"title": "V. CONCLUSION", "content": "To summarize, our study showed the breakthrough potential of the snnTorch mechanism in transforming image detection within the Spiking Neural Networks. Our model DRiVE has consistently demonstrated excellent predictive accuracy and ability to differentiate between two classes, asserting its readiness in industrial scenarios. Moreover, an accuracy of 94.82% and an AUC score of 0.99 further underpin its robustness and its discerning ability. It paves the way for future research to explore more use cases using the snnTorch model. With its proven performance, DRIVE establishes itself as a reliable framework for advancing real-world applications in fields like autonomous systems and intelligent transportation."}], "equations": ["\\theta_{t+1} = \\theta_{t} - \\eta \\frac{m_{t}}{\\sqrt{v_{t}} + \\epsilon}", "\\sigma'(u) = \\frac{1}{(1 + |u|)^2}", "V_t = \\beta V_{t-1} + I_t", "\\theta_{t+1} = \\theta_t - \\eta \\nabla L(\\theta_t)", "m_t = \\beta_1 m_{t-1} + (1 - \\beta_1) \\nabla L(\\theta_t)", "v_t = \\beta_2 v_{t-1} + (1 - \\beta_2) (\\nabla L(\\theta_t))^2", "\\hat{m} = \\frac{m_t}{1 - \\beta_1}", "\\hat{v} = \\frac{v_t}{1 - \\beta_2^t}", "\\theta_{t+1} = \\theta_{t} - \\eta \\frac{\\hat{m}}{\\sqrt{\\hat{v}} + \\epsilon} + \\lambda \\theta_t", "L = - \\sum_{i=1}^{C} y_i \\log(\\hat{y_i})", "\\hat{x_i} = \\frac{x_i - \\mu}{\\sqrt{\\sigma^2 + \\epsilon}}", "y_i = \\gamma \\hat{x_i} + \\beta"]}