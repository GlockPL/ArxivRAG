{"title": "KKA: Improving Vision Anomaly Detection through Anomaly-related Knowledge from Large Language Models", "authors": ["Dong Chen", "Zhengqing Hu", "Peiguang Fan", "Yueting Zhuang", "Yafei Li", "Qidong Liu", "Xiaoheng Jiang", "Mingliang Xu"], "abstract": "Vision anomaly detection, particularly in unsupervised settings, often struggles to distinguish between normal samples and anomalies due to the wide variability in anomalies. Recently, an increasing number of studies have focused on generating anomalies to help detectors learn more effective boundaries between normal samples and anomalies. However, as the generated anomalies are often derived from random factors, they frequently lack realism. Additionally, randomly generated anomalies typically offer limited support in constructing effective boundaries, as most differ substantially from normal samples and lie far from the boundary. To address these challenges, we propose Key Knowledge Augmentation (KKA), a method that extracts anomaly-related knowledge from large language models (LLMs). More specifically, KKA leverages the extensive prior knowledge of LLMs to generate meaningful anomalies based on normal samples. Then, KKA classifies the generated anomalies as easy anomalies and hard anomalies according to their similarity to normal samples. Easy anomalies exhibit significant differences from normal samples, whereas hard anomalies closely resemble normal samples. KKA iteratively updates the generated anomalies, and gradually increasing the proportion of hard anomalies to enable the detector to learn a more effective boundary. Experimental results show that the proposed method significantly improves the performance of various vision anomaly detectors while maintaining low generation costs.", "sections": [{"title": "I. INTRODUCTION", "content": "Unsupervised anomaly detection is one of the most important fields of anomaly detection, where no prior information on anomalies is available, while there are normal samples for reference [1]-[5]. Unsupervised methods often struggle to achieve satisfactory results due to the difficulty of learning effective boundaries between anomalies and normal samples. This challenge is particularly pronounced for visual data, where even images within the same category can exhibit significant variations, further complicating anomaly detection. To address this issue, some generation-based anomaly detection methods have been proposed. However, anomalies generated by these methods often result from random factors and deviate significantly from real-world scenarios [6]. Furthermore, excessive randomness in the generated anomalies provides limited guidance for defining boundaries, resulting in wasted computational resources and minimal improvement.\nAs depicted in the left part of Figure 1, in the context of unsupervised vision anomaly detection, anomalies such as airplanes significantly deviate from normal samples like cats. Consequently, the detector can more easily differentiate anomalies from normal samples, which we refer to as \u201ceasy anomalies\u201d. Conversely, when anomalies, such as dogs, resemble normal samples, the detector struggles to learn an effective boundary between normal samples and anomalies. We refer to such anomalies as hard anomalies. Hard anomalies, due to their close resemblance to normal samples, are often more difficult to obtain but have a stronger influence on the detector's learned boundary.\nRecently, large language models (LLMs) like GPT-3.5 [7] and GLM-4 [8] have garnered widespread attention due to their vast pretrained knowledge and powerful abilities in understanding and generation [9]. Based on this, some researchers have attempted to employ LLMs to distinguish anomalies [10], [11]. While LLMs offer a promising research direction for anomaly detection, their substantial parameter scale presents challenges for deployment on most edge devices. This limitation is especially problematic in vision anomaly detection scenarios, such as video surveillance systems that rely on edge computing [12]\u2013[14]. Besides, previous studies [15] indicate that the collaboration between large and small models can match, or even exceed, the performance of large models alone. Thus, we focus on improving the performance of the small vision detector by extracting anomaly-related knowledge from LLMs, and we refer to the knowledge about hard anomalies in LLMs as key knowledge.\nWe propose Key Knowledge Augmentation (KKA), which leverages the anomaly-related knowledge from LLMs, particularly key knowledge, to generate plausible anomalies tailored to various anomaly detection scenarios. Specifically, KKA first randomly samples normal samples and designs prompts to enable LLMs to generate anomaly-related knowledge, and the knowledge is then used to create various anomaly images for detector training. To further enhance the detector's performance, KKA trains a confusion evaluator to identify hard anomalies among the generated images. Besides, the text descriptions of hard anomalies will be used to iteratively train LLMs to extract more key knowledge. As shown in the right part of Figure 1, with augmented key knowledge from LLMs, detector can learn a clearer boundary for normal samples and anomalies.\nThe main contributions of this paper can be summarized as follows:\n\u2022 We analyzed the issues of existing generation-based methods from the perspective of generated anomalies.\n\u2022 We propose extracting anomaly-related knowledge, particularly key knowledge, from LLMs and iteratively optimizing the detector's performance with a specially designed LLM.\n\u2022 We extensively evaluate the proposed Key Knowledge Augmentation (KKA) on various datasets and achieve excellent results. For example, on CIFAR-100, KKA improves the AUC of the recent generation-based method SimpleNet from 74.62% to 84.04%, while generating only about 5% of the samples produced by SimpleNet."}, {"title": "II. RELATED WORK", "content": "Anomaly detection has a very wide range of applications, such as detecting defects in industrial products [16]\u2013[18], financial fraud [19], [20], as well as video surveillance [21]\u2013[23]. No matter in which scenario, anomalies are sparse and unpredictable [24].\nUnsupervised anomaly detection is one of the most important fields of anomaly detection. When training a detector using only normal samples, distinguishing anomalies with diverse distributions becomes challenging [25], [26]. Particularly in the case of images, samples from the same class may exhibit significant variation, which can obscure the boundary between normal samples and anomalies in the latent space [1]. Consequently, a growing number of studies focus on improving detector's performance by generating additional samples. CMDA [5] increases the sample size by interpolating between text and images, thereby enhancing the detector's discriminative capacity. SimpleNet [6] generates anomalies by introducing Gaussian noise into the image feature space and trains the detector at the feature level. ReContrast [27] combines feature reconstruction and contrastive learning by using two different encoders to generate distinct versions of the same sample, thereby enhancing the detector's ability to discriminate across diverse distributions.\nMotivated by the advanced comprehension, powerful generation capabilities, and vast prior knowledge of LLMs, recent studies have increasingly explored integrating anomaly detection with LLMs. Semantic Anomaly Detection [10] introduces a monitoring framework that utilizes LLMs to detect semantic anomalies in vision-based policies, aiming to identify failures at the system level. LAnguage-based VAD (LAVAD) [11] employs LLMs to detect anomalies through analysis of scene descriptions. AnomalyLLM [28] effectively identifies anomalies by detecting significant discrepancies between the features of LLMs and those of a smaller anomaly detector. Although the aforementioned methods have improved anomaly detectors with the help of LLMs, the large parameter scale of LLMs limits the applicability of these methods [12]\u2013[14]. On the other hand, prior studies indicate that smaller specialized models can achieve performance comparable to, or even exceeding, that of general large models on specific distributions [15], [29]. Consequently, this paper focuses on employing LLMs to enhance small anomaly detectors."}, {"title": "III. METHOD", "content": "In this section, we present the proposed Key Knowledge Augmentation (KKA). First, we introduce the symbols and their corresponding meanings, as outlined in Table I.\nDue to the sparsity and diversity of anomalies, anomaly detection methods, specifically unsupervised anomaly detection, often train a feature extractor \u03d5 with normal samples $X_n$. During testing, the detector calculates the anomaly score in the latent space learned by \u03d5 with a distance metric, such as Mahalanobis distance, to discriminate normal samples and anomalies [1], [5]:\n$S_k = (z - \\mu_k)^T\\Sigma_k^{-1}(z - \\mu_k), z = \\phi(x)$ (1)\nwhere $x \\in X_n$ is the normal sample, $z \\in Z$ is the output of \u03d5, k denotes different clusters in the latent space, $\u03bc_k$ and $\u03a3_k$ are the sample mean and sample covariance, respectively.\nWhen anomalies deviate significantly from the normal distribution (i.e., easy anomalies, $X_{ea}$), the detector can effectively distinguish between normal samples and anomalies with Eq.1. However, when normal samples and anomalies are more similar (i.e., hard anomalies, $X_{ha}$), the performance of unsupervised anomaly detection is considerably reduced.\nWe propose leveraging the extensive prior knowledge of LLMs to predict anomalies, especially those closely resembling normal samples, thereby enhancing the performance of anomaly detectors. Specifically, we introduce Key Knowledge Augmentation (KKA), and the proposed method is illustrated in Figure 2.\nWe use text to represent the knowledge within LLMs, and the knowledge of normal samples in the training data can be expressed as $X_n$. KKA first selects text descriptions that can represent the normal distributions from $X_n$:\n$X = [x_1^t, x_2^t,..., x_{nk}^t] = arg\\underset{X}{min}[s_1, s_2, ..., s_K]$ (2)\nwhere K denotes the number of clusters of normal images, s is the anomaly score calculated by Eq.1, $[x_1^t, x_2^t,..., x_{nk}^t]$ are text descriptions of selected image list that best fits the normal distributions.\nThen, KKA generates textual anomaly $x_a^t$ with different prompts according to the normal samples. For example, in Figure 2, the normal samples are \"Gaura lindheimeri Engelm. & A. Gray\" (a type of flower), and the part of the prompt for generating anomalies is:\n\"Please generate new sentences that describe flowers. The sentences should follow the exact structure and style of the example below: $X_n$.\n\"The textual anomaly $x_a^t$ generated by LLMs can be formatted as:\n$P_{\\theta_L}(x_a^t | x_n) = \\prod_{i}^{|x_a^t|}P_{\\theta_L}(y_i| x_n, y_{1:i-1})$ (3)\nwhere LLMs $\u03b8_L$ generates a current token yi based on a context of the previous i \u2013 1 tokens, and prompts.\nThereafter, we can get anomaly image $x_a$ with textual anomaly $x_a^t$ and a text-to-image model such as Stable Diffusion $P_{\\theta_s}$ [30]:\n$x_a \\leftarrow P_{\\theta_s}(x_a^t, x_n)$ (4)\nwhere $x_a^t$ is the generated anomaly image corresponding to $x_a^t$.\nBy running Eq.4 multiple times, we can obtain an anomaly image dataset $X_a$. Intuitively, the detector trained with $X_n$ and $X_a$ is already more effective in distinguishing between normal images and anomaly images, compared to unsupervised methods. However, anomalies generated by Eq.3 and Eq.4 include numerous easy anomalies, $X_{ea}^a$, since hard anomalies, $X_{ha}^a$ must meet specific distribution conditions and demonstrate similarity to normal images.\nIn order to get more hard anomalies $X_{ha}^a$, KKA follows Deep SAD [31] to train a confusion evaluator $\u03b8_c$ with $X_n$ and $X_a$, which learns a transformation that minimizes the volume of a data-enclosing hypersphere in the latent space Z:\n$\\underset{W}{min} \\frac{1}{M} \\sum_{j=1}^{M}(||\\phi_c(x_a^i) -c||^2 + \\frac{1}{\\lambda}||W||^2), \\lambda > 0$ (5)\nwhere W is the set of weights of $\u03b8_c$, M is the number of anomalies, c is the predetermined center of hypersphere. Eq.5 tends to project normal samples near the hypersphere center c, while pushing away anomalies from c.\nThen, KKA calculates the distance from each sample to the center c in the latent space, and selects anomalies whose distance to c is shorter than that of certain normal samples. Such process can be formatted as:\n$x_{ha}^a \\leftarrow DF(\\phi_c(x_a), c) < max(DF(\\phi_c(x_n), c))$ (6)\nwhere DF is the distance function. Overall, Eq.6 aims to identify hard anomalies that are easily confused with normal samples, while samples that do not satisfy Eq.6 are considered easy samples.\nTo extract more key knowledge about hard anomalies from LLMs, KKA follows the Direct Preference Optimization (DPO) [32] to fine-tune LLMs:\n$\\mathcal{L} (\\theta_L^{'}, \\theta_L) = \\mathbb{E}_{(x_a^{ha}, x_a^{ea})}\\[log\\sigma(\\beta log \\frac{P_{\\theta_L^{'}}(x_a^{ha} | x_n)}{P_{\\theta_L}(x_a^{ha} | x_n)} - \\beta log \\frac{P_{\\theta_L^{'}}(x_a^{ea} | x_n)}{P_{\\theta_L}(x_a^{ea} | x_n)})]$\n(7)\nwhere \u03c3 is the sigmoid function, $\u03b8_L^{'}$ is the fine-tuning LLM, $\u03b8_L$ is the original LLM.\nAfter fine-tuning, we can extract more key knowledge from LLMs, and generate more hard anomalies by:\n$x_a^{t^{'}} \\leftarrow P_{\\theta_L^{'}}(x_n^t | x_n) = \\prod_{i}^{|x_n^t|}P_{\\theta_L^{'}}(y_i| x_n, y_{1:i-1})$\n$x_a^{a^{'}} \\leftarrow P_{\\theta_s}(x_a^{t^{'}}, x_n), N(x_a^{ha}) > N(x_a^{ea})$\n(8)\nwhere $N(.)$ denotes the number of hard anomaly images.\nIn each iteration of updating anomaly dataset, KKA can get a new anomaly dataset $X_a$ with $x_a$. To accommodate the varying needs of detectors for easy and hard anomalies in different scenarios, we divide KKA into KKA (add) and KKA (rep). KKA (add) continuously increases the number of anomalies (gradually increase the proportion of hard anomalies), while KKA (rep) maintains a constant number of anomalies by continuously replacing easy anomalies with harder ones. The whole process of KKA is summarized in Algorithm 1."}, {"title": "IV. EXPERIMENTS", "content": "In this section, we present our experimental setup, evaluate the proposed method on multiple datasets, conduct ablation studies, perform hyperparameter analyses and convergence analysis. The code and data for the proposed method are provided for research purposes.\nWe conduct experiments on three distinct datasets, each containing class labels that facilitate the classification of normal samples and anomalies.\nCIFAR-100 [33]. The CIFAR-100 image classification dataset comprises 20 superclasses with a total of 100 subclasses, each containing 600 images (500 for training and 100 for testing). Each image is assigned both a fine label and a coarse label. In this paper, we designate one superclass (comprising 5 subclasses) as normal samples, while the remaining 19 superclasses (95 subclasses) are considered anomalies.\nOxford-102 [34]. This dataset includes 8,189 image-text pairs of flowers across 102 distinct classes. In our experiments, one flower class is designated as the normal sample, while the remaining 101 classes are considered anomalies.\nUCM-Caption [35]. This dataset comprises 21 classes of land-use images, with five distinct sentences used to describe each image. We randomly select two classes as normal samples, while the remaining 19 are designated as anomalies.\nIn this paper, we focus on extracting anomaly-related knowledge and generating anomaly images for unsupervised anomaly detection.\nThe unsupervised baselines can be grouped into three categories: (1) methods based on raw data, such as SSD [36]; (2) methods that use cross-modal information to generate additional samples, such as CMDA; and (3) methods that produce anomalies, such as SimpleNet [6]. The proposed KKA belongs to the third category.\nFor KKA, the feature extractor's learning rate is set to 0.0001, with a scheduler adjustment at 50 epochs or 40 epochs. The batch size is 32, and the optimizer is Adam. The number of training epochs on the CIFAR-100, Oxford-102, and UCM-Caption datasets is 150, 200, and 300, respectively. Additionally, the generated anomaly dataset is updated 3, 2, and 2 times for CIFAR-100, Oxford-102, and UCM-Caption, respectively.\nTable II presents KKA's performance in both addition and replacement modes, along with the results of unsupervised methods with and without generated samples. KKA demonstrates strong generality, as it can be incorporated into supervised anomaly detection methods (such as SAD) as well as generation-based anomaly detection methods (such as SimpleNet). In general, introducing KKA leads to a significant improvement in detection performance. For instance, on the CIFAR-100 dataset, KKA improves SimpleNet's AUC from 74.62% to 84.04% while generating only approximately 5% of the samples produced by SimpleNet. Moreover, the superior performance of KKA based on SimpleNet demonstrates that extracting key knowledge from LLMs, rather than generating anomaly samples through random noise, is better suited for vision anomaly detection. The results of Recontrast [27] and ReContrast (No pre-training) clearly demonstrate the effectiveness of pre-training. In scenarios without anomalies, pre-trained models can integrate prior knowledge that can roughly help the detector understand what anomalies might be. Based on pre-trained model, Recontrast+KKA further introduces key knowledge specific to particular anomaly scenarios, resulting in additional performance improvements. Overall, the results in Table II indicate that the samples generated by KKA outperform those generated by SimpleNet using random noise, ReContrast with multi-view samples, and CMDA with cross-modal information. This also demonstrates that knowledge extracted from LLMs is more practically relevant for specific anomaly detection scenarios.\nWe conduct ablation experiments to demonstrate the importance of key knowledge (hard anomalies). To alleviate concerns that performance improvements may be due to an increase in data volume, we present the results of KKA (replacement). KKA (replacement) maintains a fixed number of anomalies while gradually increasing the proportion of hard anomalies with each iteration. The related results are presented in Table III, where (0) denotes the initially generated anomalies, and (1), (2), and (3) represent the first, second, and third iterations of the updated anomaly dataset, with higher numbers indicating a greater proportion of hard anomalies.\nRelated results indicate that increasing the proportion of hard anomalies (1, 2, 3), can significantly enhance detector's performance. For CIFAR-100, the AUC consistently improves with each iteration. In contrast, while detector's performance also improves on the Oxford-102 and UCM-Caption datasets, it is less stable due to differences in data volume: CIFAR-100 includes 2500 normal samples, whereas Oxford-102 and UCM-Caption contain only 51 and 158 normal samples, respectively. An excessive number of hard anomalies may cause the detector to overlook the fewer normal samples. Meanwhile, on Oxford-102 and UCM-Caption, the AUC for KKA (0) is 92.88% and 72.33%, while the detector achieves 94.31% and 74.60% on the second iteration. The improvement in detector's performance achieved by increasing the proportion of hard anomalies clearly demonstrates the importance of key knowledge (hard anomalies) in anomaly detection.\nFigure 4 further illustrates the relationship between the number of generated anomalies and the number of hard anomalies. In Figure 4, orange points represent KKA applied to increase hard anomalies, while pink points represent the different number of initial anomalies (including more easy anomalies). The results show that increasing the number of initial anomalies has little effect on the detector's performance. Moreover, once the number of generated anomalies reaches 400, the detector's performance plateaus. Datasets with a higher proportion of hard anomalies can easily outperform those with a larger number of easy anomalies. This indicates that hard anomalies contain more meaningful information for anomaly detection.\nWe demonstrate the iterative process of generating anomalies by KKA on the Oxford-102 dataset, and the results are presented in Figure 3.\nIn the initial generation, the anomalies exhibit high randomness, featuring flowers of various colors and shapes extracted from the prior knowledge of LLMs, ensuring the diversity of anomalies. In the first iteration, guided by the selected hard anomalies, KKA extracts key knowledge from the prior information of LLMs, making the anomalies more difficult to distinguish from normal samples. As a result, the generated images in iteration 1 contain elements that resemble normal samples, such as smaller flowers and a pink coloration. In the second iteration, the influence of key knowledge becomes more prominent in the generated anomalies. Although the anomalies remain distinguishable from normal samples, their characteristics increasingly resemble those of normal samples, with a higher proportion than in the previous iteration.\nWe visualize the latent spaces learned by the unsupervised methods, SSD, and the proposed KKA in Figure 5 to demonstrate that the proposed method learns more distinct boundaries between normal samples and anomalies.\nAs illustrated in Figure 5a, the latent space learned by SSD is more chaotic. In contrast, in Figure 5b, the latent space learned by KKA can clearly separate most normal samples and anomalies, as there are clear distribution differences between blue dots and red dots. More specifically, while SSD is able to project some of the red points to relatively concentrated areas (i.e., easy anomalies), there are still a large number of red points interspersed with the blue points (i.e., hard anomalies).\nIn real-world scenarios, anomalies are inherently difficult to predict. They may not follow patterns like those in the Flower-102 or UCM datasets, where normal samples and anomalies generally belong to the same class. Instead, anomalies are more likely to originate from two aspects: similar distributions (i.e., the same superclass but different subclasses) and distinct distributions (i.e., different superclasses). To further validate the effectiveness of KKA, we restructured the CIFAR-100 dataset by selecting one class as the normal samples and treating the remaining 99 classes as anomalies. The results are presented in Table IV. It is evident that when only one subclass is used as normal samples, the task is relatively easier compared to using a superclass (comprising five subclasses) as normal samples. This is because the distribution of normal samples is more homogeneous, allowing the detector to more focus on their distribution. Furthermore, the results of KKA in Tables II and IV exhibit a consistent pattern: as the number of iterations increases, the detector's performance improves. This further underscores the important role of hard anomalies in anomaly detection.\nIn Figure 6, we demonstrate that the anomalies generated by KKA consistently enhance the performance of the best-performing baseline, ReContrast. Notably, all settings for Re-Contrast and ReContrast with KKA are identical. As illustrated in Figure 6, with the more realistic anomaly samples generated by KKA, ReContrast can converge faster and more effectively. This is because the anomalies are no longer random, unrealistic content but rather real-world images in the same \u201cstyle\u201d as the normal samples. Besides, during the first epoch, the key knowledge extracted by KKA increased ReContrast's accuracy from approximately 0.25 to 0.83, while the loss decreased by nearly 1. Such results highlight the crucial role of hard anomalies generated from key knowledge in improving detector's performance."}, {"title": "V. CONCLUSION", "content": "Unsupervised anomaly detection, particularly in the visual domain, faces a significant challenge in distinguishing normal samples from diverse anomalies. Existing generation-based anomaly detection methods alleviate such issue by generating anomalies that deviate from the normal distribution. However, generated samples lacking real-world knowledge guidance are often unrealistic and overly broad, lacking specificity with respect to normal samples. This paper proposes extracting key knowledge about anomalies from the extensive prior knowledge of LLMs and generating anomaly images. To overcome the limitations of random anomaly generation, we categorize the generated anomalies into easy anomalies and hard anomalies according to their level of confusion by a trained feature extractor. By iteratively increasing the proportion of hard anomalies, the proposed method can further improve the detector's effectiveness."}]}