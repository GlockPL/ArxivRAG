{"title": "CliMB: An AI-enabled Partner for Clinical Predictive Modeling", "authors": ["Evgeny Saveliev", "Tim Schubert", "Thomas Pouplin", "Vasilis Kosmoliaptsis", "Mihaela van der Schaar"], "abstract": "Despite its significant promise and continuous technical advances, real-world applications of artificial intelligence (AI) remain limited. We attribute this to the \u201cdomain expert-AI-conundrum\": while domain experts, such as clinician scientists, should be able to build predictive models such as risk scores, they face substantial barriers in accessing state-of-the-art (SOTA) tools. While automated machine learning (AutoML) has been proposed as a partner in clinical predictive modeling, many additional requirements need to be fulfilled to make machine learning accessible for clinician scientists.\nTo address this gap, we introduce CliMB, a no-code AI-enabled partner designed to empower clinician scientists to create predictive models using natural language. CliMB guides clinician scientists through the entire medical data science pipeline, thus empowering them to create predictive models from real-world data in just one conversation. CliMB also creates structured reports and interpretable visuals. In evaluations involving clinician scientists and systematic comparisons against a baseline GPT-4, CliMB consistently demonstrated superior performance in key areas such as planning, error prevention, code execution, and model performance. Moreover, in blinded assessments involving 45 clinicians from diverse specialties and career stages, more than 80% preferred CliMB over baseline GPT-4. Overall, by providing a no-code interface with clear guidance and access to SOTA methods in the fields of data-centric AI, AutoML, and interpretable ML, CliMB empowers clinician scientists to build robust predictive models.", "sections": [{"title": "1 Introduction", "content": "Individualized risk prediction is a key enabler of precision medicine [1]. There are many use cases\nfor predictive models; we will highlight three illustrative examples. First, individualized survival\npredictions can guide the use of adjuvant therapy for patients with early invasive breast cancer [2].\nSecond, predictive models can guide clinical pathways such as identifying high-risk patients during\nradiotherapy. Providing these individuals with supplemental clinical evaluations reduces costs while\nimproving patient outcomes [3]. Finally, risk predictions can also facilitate timely interventions,\ne.g. to reduce mortality in patients at risk of sepsis [4].\nMachine learning (ML) methods offer increasingly powerful solutions for risk prediction. These\ninclude methods and tools to improve data quality [5, 6, 7, 8, 9, 10, 11], optimize model performance\n[12, 13, 14, 15, 16], and enhance transparency and interpretability [17, 18, 19]. However with few\nexceptions, current clinical risk scores are either created with classical statistical methods or a small\nrange of ML methods (random forests appear to dominate [20, 21]). This narrow focus is a problem\nin prediction because, as highlighted by the \"no free lunch\" theorem, no single method is deemed\nideal for all prediction problems [22, 1]. Overall, the breadth of ML methodology being used in\nclinical risk prediction (and other applications) remains limited and thus the potential of AI in\nmedicine unfulfilled [23].\nWe argue that this is the result of a fundamental conundrum: on the one hand, domain experts\n(e.g., clinician scientists) should be able to build predictive models; on the other hand, there are\nlargely impenetrable barriers to using SOTA methods. Solving this domain expert-AI-conundrum\npromises to be transformative for the medical field thanks to more individualized healthcare. More-\nover, widespread application of predictive modeling in medicine will scale the identification of real-\nworld needs that should be addressed by the ML community. Overall, a solution to the conundrum\nwould enable progress in reality-centric AI adoption and development."}, {"title": "1.1 Clinician scientists should be able to build predictive models", "content": "Why is clinical expertise crucial? The primary goal of applying ML in the medical domain-and\nindeed in any domain is not to explore difficult challenges or develop novel methods that achieve\nbetter performance on toy benchmarks. The true value of ML in healthcare lies in its potential to\naddress real-world medical challenges and thereby improve patient outcomes. To ensure a predictive\nmodel will serve an actual need, the process of building it should begin with a clinical problem that\nrequires predictions [24]. Clinicians are at the forefront of patient care with a deep understanding\nof medicine and awareness of clinical needs. They can identify a clear problem and setting where\npredictions would be promising [25]. Thus, in the clinical domain, clinicians should set the agenda\nfor the development of predictive tools. The necessity of domain expertise is best illustrated by\nreflecting on the surge in ML models during the COVID-19 pandemic. At the time, hundreds of\nmodels with little to no impact were created, in part because efforts were not domain expert-driven\n[26]. Domain expertise is required not only to set the agenda but also throughout the development\nprocess. In addition, domain expertise is necessary for data exploration and engineering, which are\nusually the most time-intensive phases of data science projects [27]. In fact, many of the models\ncreated during the pandemic were built by AI researchers who lacked the medical expertise needed\nto identify flaws in the medical data [26]. Although the subsequent model-building process may"}, {"title": "1.2 Clinician scientists face largely impenetrable access barriers", "content": "Why is risk prediction hardly accessible? Substantial resources and expertise are currently\nrequired to develop predictive models [1]. As explained above, no single ML method will be ideal"}, {"title": "1.3 Requirements for human-centric AI/ML partners for predictive modeling", "content": "To resolve the domain expert-AI-conundrum and make ML accessible to clinician scientists without\nthe need for a data scientist, an AI-enabled partner is needed that builds on developments in\nAutoML, data-centric AI, and ML interpretability. We refer to this kind of tool as a partner\nrather than a \u201cco-pilot\u201d because it would not merely enhance a clinician scientist's (the pilot's)\ncapabilities but rather augment the clinician scientist's skill set with a new class of capabilities. We\nconsulted with clinician scientists, ML researchers, statisticians, and software engineers to distill\nthe requirements that an ideal partner for predictive modeling in medicine would fulfill. They are\nlisted below:\nHolistic support. The partner should accompany the domain expert through all stages\nof their data science project. Before starting the project, an ideal partner would check the\nalignment between the user's goal, their data, hardware and software. For easy access and an\n(albeit modular) off-the-shelf solution, tools for all phases of the predictive modeling pipeline\nwould be combined. These phases include (1) data exploration, (2) data engineering, (3) model\nbuilding, and (4) model exploitation [43]. Holistic support encompasses not only execution\nbut also planning, which is an underexplored area [44].\nUsability. To truly empower domain experts, the AI/ML partner must be user-friendly.\nUsability hinges on automation and interfaces. Most basic tasks should be automated, re-\nquesting human feedback only when critical decisions must be made. Communication should\noccur through natural language, a universal interface [45]. Additionally, the visual presenta-\ntion must be clear and easy to navigate. Improved usability will also enhance interpretability\nand transparency.\nBest practices. Data science best practices should be followed to create predictive models\nthat perform well, generalize effectively, and maintain clinical validity. E.g., model building\nshould be optimized using AutoML. User misconceptions should be identified and interactively\naddressed.\nRobustness. As evidenced in section 3.2, large language models (LLMs) often deviate from\ntheir intended plans, leading to incomplete or suboptimal outcomes. A truly effective AI/ML\npartner, however, must adhere to robust yet adaptable strategies to prevent it from veering\noff course and neglecting critical steps.\nInterpretability. Interpretability and transparency should be integrated at all stages to al-\nlow the domain expert to critically appraise processes and outcomes. Interpretability metrics\nshould be made accessible through interactive explanations, contextualization, and visualiza-\ntions.\nModularity. An ideal AI/ML partner should be designed to scale with future methodologies,\nmodularly incorporate novel tools as they emerge, and accommodate existing tools the user\nwishes to integrate alongside off-the-shelf solutions.\nVersatility. Within reasonable boundaries, an AI/ML partner should dynamically adapt to\nuser requests. For example, it should be possible to revisit previous phases of the data science\npipeline if the need arises at a later stage of the project.\nPrivacy. Privacy is a key concern in medicine [46]. If sensitive medical data are used for\ndata science tasks, appropriate privacy features must be an integral part of any tools that\naccess these data."}, {"title": "1.4 An AI-enabled partner for clinical predictive modeling", "content": "In this article, we introduce the Clinical predictive Model Building partner (CliMB), a no-code\nchatbot that empowers clinician scientists to build predictive models using only natural (specialist)"}, {"title": "2 Methods", "content": ""}, {"title": "2.1 Meeting the human-centric AI/ML partner requirements", "content": "We built CliMB to fulfill the universal requirements for a clinician scientist-centric AI partner.\nCliMB offers holistic support for end-to-end predictive modeling. Its user-friendly natural language\ninterface is complemented by an interactive dashboard, which allows the user to easily view data\nand data transformations, figures, and progress on the structured plan. This structured plan for\npredictive modeling is aligned with data science best practices and includes all relevant subtasks\n(for details see Table 7). For instance, CliMB checks for data leakage an issue that was regu-\nlarly overlooked by clinician scientists before we added this subtask. CliMB's reasoning unit, in\ncombination with the memory unit, and the use of external tools ensure robustness. The reasoning\nunit is largely responsible for adherence to the structured plan. The memory unit stores logs and"}, {"title": "2.2 Design of CliMB", "content": "In this section, we describe the information flow through CliMB. CliMB adheres to data science best\npractices, guiding users through their projects. These projects can be divided into the following\nphases: (1) data exploration, (2) data engineering, (3) model building, and (4) model exploitation\n[43].\nThe objective is to build predictive models for the user's problem using real-world medical\ndatasets. Therefore, the clinician scientist plays a central role within CliMB's human-in-the-loop\nframework. Other key components include the reasoning unit, the action unit, the memory, and\nthe user interface (see Figure 3).\nThe reasoning unit receives information from the user, external tools invoked by the action\nunit, and through self-reflection. The reasoning unit (detailed in section 2.3) integrates this input,\nupdates the project plan, and assigns tasks to the action unit. It ensures robustness in following\nthe planned stages necessary for predictive modeling. Planning assistance is necessary to make ML\naccessible but has been underexplored compared to execution assistance [44]. This likely stems\nfrom the fact that many AutoML tools seem to cater mostly to data scientists wanting to enhance"}, {"title": "2.3 Reasoning unit", "content": "CliMB's reasoning unit formalizes the clinician scientist-AI partner collaboration problem as a\ntransparent episodic multi-armed bandit [56]. This formalism enables the description of both the\nsequence of decisions made by CliMB to build a predictive model with its accompanying visual-\nizations and report, and the feedback mechanism informing the next decision. The division of the\nend-to-end application into planned subtasks is made possible by the episodic nature of the model.\nThis formalism is used to structure, through in-context learning, a locally deployed pre-trained\nlanguage model lrea (see Figure 4). Let T be the vocabulary of tokens used by Irea. Therefore,\ntexts generated by lrea belong to T*."}, {"title": "Feedback", "content": "The feedback provides interpretations of the current state of the task with additional\ninformation, guiding CliMB in selecting the next action. The feedback is expressed in natural\nlanguage: FCT*. The feedback is produced after executing an action by querying a feedback\nsource qi : f\u00a3 ~ qi(x+, a\u00a3).\nThere are three sources for feedback (i \u2208 {1,2,3}):\nExternal tools\nSelf-reflection of the LLM\n\u2462Clinician scientist\nWe prioritize feedback from sources (i) or (ii) to maximize CliMB's autonomous behavior, resorting\nto human interaction only when necessary. Thus, the cost of an action Cr,a \u2208 {0,1} for a \u2208 A and\nx \u2208 X is defined as Cx,a = 1 if it queries the clinician scientist and Cx,a = 0 if it queries another\nsource. The cost of the stop action is always 0."}, {"title": "Terminal reward and AI/ML partner objective", "content": "In CliMB, the terminal action stop is\ntied to an assessment by the clinical researcher of the episode process and resulting state. The\nepisodic terminal reward, R\u00ba for the episode p, is binary (R\u00ba \u2208 {0,1}), provided by the clinician\nscientist, corresponding to a quality and trustworthiness check. Thus, the episodic reward is 1\nif the clinician scientist gives their approval and 0 otherwise. CliMB's objective is to maximize\nterminal rewards, leading to the completion of the subtasks required to obtain the final output\n(model, visuals, report), while minimizing action costs, i.e., human interactions."}, {"title": "Robust Planning", "content": "A plan is defined as a set of subtasks E. The subtask attributed to episode\npis denoted ep. The plan is completed when all subtasks \u00ea \u2208 E are achieved, meaning there exists\nan episode p\u2208 N where ep = \u00ea and Rp = 1. This guarantees robustness as it ensures that all\nsteps of the data science pipeline are followed according to best practices. Although & is fixed, the\norder of completing subtasks is adjusted during the process, based on the problem, current progress,\nand feedback: ep = CliMB(x1, RP-1). The plan & is described in a dashboard section which is\nregularly updated to track the progress of the different subtasks."}, {"title": "Tools available", "content": "Let A be the set of actions available to a general-purpose LLM, including\nplanning, text generation, ideation, etc. In CliMB, we provide the AI/ML partner with a code inter-\npreter and multiple machine learning tools necessary for acting on the state. Without these coding\ntools, A alone would not suffice for performing the required actions and iterating autonomously\nbased on the tool's results. Depending on the episode type, the set of tools available G may vary\nbut can be categorized as shown in Table 2.\nThus, the set of continuation actions A is enriched by the available tools G, increasing the range\nof potential actions for the AI partner: A = A\u00ae \u222a G."}, {"title": "Scalability", "content": "We propose CliMB as a modular framework, adaptable to various tasks depending\non the diversity of episode types defined and the quality of available tools G. Since this paper\nfocuses on generating risk prediction models for clinician scientists, the episode types correspond to\nthe subtasks required to achieve this goal, and the tools provided are data science tools. However,\nthe framework could be applied to other tasks, and the quality of results could be enhanced by\nimproving the set of tools."}, {"title": "2.4 End-to-end Pipeline", "content": "CliMB's ability for robust planning, as described in section 2.3, is realized by its reasoning unit.\nCliMB guides the user through a medical data science project by following an explicit (yet adapt-\nable) plan aligned with best practices. Each necessary stage [43] is ensured to be completed unless\nthe user explicitly decides to skip it. In this section, we outline the standard pipeline, which can\nbe adapted to meet specific user needs. A detailed overview of the plan is available in Table 7.\nAlignment check. CliMB verifies whether the hardware is suitable and whether the dataset\ncan be loaded and used. Background information on the dataset and the clinician scientist's\nresearch question(s) is confirmed to ensure alignment between CliMB's capabilities and the\nuser's requirements.\nData exploration. CliMB performs detailed exploratory data analysis, generates descriptive\nstatistics, and creates informative figures for each variable. The meaning of each column and\nthe expected data type is confirmed with the user.\nData engineering. This phase includes data type conversion and the explicit discussion and\nhandling of missing values. Additionally, any changes requested by the user are performed.\nFor full transparency, data changes are highlighted within the dashboard. Feature selection\nis conducted using random-forest-based algorithms.\n\u2462 Model building. Model building is optimized using SOTA AutoML risk prediction software\n(AutoPrognosis 2.0 [13]). Currently, classification, regression, and time-to-event (survival)\nanalysis can be performed.\nModel exploitation. In this phase, model performance is evaluated, and depending on\nthe project type, additional insights are provided to the user. Interpretability methods are\nemployed to assess feature importance [54, 55] and, for classification tasks, stratify samples\n(easy, ambiguous, hard) [11]. Once all steps are completed and the clinician scientist is\nsatisfied with the results, a summary report of the study is generated.\nWe show the breakdown of CliMB project stages' tasks and subtasks in appendix 6.3, and an\nillustration of the advantages of CliMB's approach in robustly planning an AI-enabled data science\nproject in appendix 6.4."}, {"title": "2.5 Hardware and Software", "content": "CliMB is implemented in Python, with backward compatibility up to Python 3.8. The software\nis compatible with all major operating systems: Windows, Linux, and macOS. The miniconda\n[57] package and environment manager is used to facilitate code and tool execution. Automatic\ninstallation of PyPI [58] (pip-installable) packages in a dedicated code execution environment is\nimplemented.\nThe experiments were carried out using the gpt-4-0125-preview model with a 128,000-token\ncontext window via an Azure OpenAI Service [59] deployment. However, all OpenAI and Azure\nOpenAI Service provisions of the gpt3.5-turbo, gpt4(-turbo), and gpt4o class models are com-\npatible through the Python openai library [60]. Compatibility with other commercial and open-\nsource LLMs is available through simple extension, hence CliMB is not limited to the models used\nhere. The packages required for CliMB tools, such as AutoPrognosis 2.0 [13] or HyperImpute [8],\nare installed as part of the CliMB setup.\nThe hardware used for developing and running CliMB was a workstation running Ubuntu 24.04,\npowered by an Intel Core i9-10900K 10-core, 20-thread CPU, 64 GB of system memory, and an\nNVIDIA GeForce RTX 3090 GPU (24 GB VRAM). We estimate the minimum system specifications\nfor running CliMB to be: a CPU with at least 4 cores, 16 GB of system RAM; optionally, a GPU\nwith at least 4 GB of memory is advantageous for running some of the deep learning models.\nHowever, it should be noted that the appropriate computing requirements depend significantly on\nthe size of the user's dataset."}, {"title": "3 Results", "content": ""}, {"title": "3.1 Illustrative end-to-end sessions with clinician scientists", "content": "We tested CliMB's capabilities to assist real-world clinician scientists in creating predictive models\nfrom their medical datasets. Predictive models for various use cases and diseases were created\nduring these sessions. Illustrative logs are included in the appendix. We further include a video\nof a full CliMB session here https://youtu.be/76XuROK3F5Y. Figure 5 provides snippets from\nthis session in which a transplant surgeon built a predictive model for graft function at 12 months.\nThese snippets highlight just a few of the versatile capabilities of CliMB."}, {"title": "3.2 Systematic comparison against baseline GPT-4", "content": "We systematically compare CliMB with a baseline GPT-4 software system. The latter is imple-\nmented as a gpt4-turbo chat interface with code execution capabilities with self-reflection. The\nLLM, its parameters, and the code execution environment implementation are equivalent in both\nthe baseline and CliMB to ensure a fair comparison. Python code execution with self-reflection,\naccess to (at least some) pip-installable libraries and a working directory, as implemented in the\nbaseline, appears to be similar to ChatGPT's [61] approach to code execution and data analysis\nas of August 2024, based on empirical observation of the ChatGPT online portal's code generation\nbehavior (for instance, generated code and feedback from exceptions can be confirmed by assessing"}, {"title": "3.3 Clinician feedback", "content": "To get a first impression of CliMB's perceived usefulness in real-world application, we gathered\nfeedback from clinicians at the Cambridge AI in Medicine Summer School [62]. As part of the\nsummer school curriculum, video demonstrations (see appendix 6.6) were shown to participants,\ninitially without any additional commentary, allowing them to focus fully on the videos. In these\nvideos, the same type of predictive model was built from the same dataset twice: once with baseline\nGPT-4, once with CliMB. While the goal of the summer school session was to demonstrate, how\nCliMB truly enables the attendees to build predictive models, there was no indication as to which\ntool was being used in either demonstration, effectively resulting in a blinded evaluation. Following"}, {"title": "4 Discussion", "content": "CliMB is a first-of-its-kind solution to the domain expert-AI-conundrum for clinical research. It\nmeets the universal requirements outlined in section 1.3, as explained in section 2.1."}, {"title": "4.1 CliMB outperforms baseline GPT-4", "content": "In section 3.2, we demonstrated that CliMB consistently outperforms baseline GPT-4 across multi-\nple dimensions. First, CliMB typically avoids a variety of potential failures during different stages\nof the data science project. It also exhibits a strong capability to identify dataset-specific issues,\nsuch as potential data leaks or risks of overfitting. By successfully flagging these issues in nearly ev-\nery instance, CliMB minimizes risks that could compromise the validity of the models. In contrast,\nbaseline GPT-4 consistently overlooked these issues, which raises concerns about its reliability in\nreal-world applications."}, {"title": "4.2 Limitations", "content": "Our work has several limitations that are outlined below.\nWhile the need for technical skills is mostly eliminated, clinician scientists who want to build\nand use predictive models still require other skills and knowledge. Specifically, they need a\nbasic understanding of ML and a thorough understanding of their dataset to avoid overreliance\non the system.\nThe predictive models created with CliMB require further validation and must be tested for\nclinical effectiveness and safety before deployment [63]. Therefore, clinicians who wish to\ndeploy predictive models in practice need a proficient level of AI expertise. By that, we mean\nan understanding of the ethical implications of integrating AI in medicine and the ability to\ncritically evaluate the predictive models created with CliMB.\nFinally, CliMB should undergo more systematic evaluation in collaboration with clinician\nscientists from various disciplines. This process should encompass all types of predictive\nproblems and utilize datasets of varying sizes with different dataset-specific challenges."}, {"title": "4.3 Future vision", "content": "In this work, we present a core technology that is both versatile, making it applicable across various\nspecialties, and modular, allowing it to scale with ease. CliMB can be augmented with additional\ntools to handle multi-modal data. Moreover, future versions can expand to include machine learning\nmethodology beyond risk prediction (e.g., causal machine learning for CATE estimation [64]) or\nhandle competing risks during survival analysis [65]. In addition to expanding the core version, we"}, {"title": "5 Acknowledgments", "content": "We thank Andres Floto, Tim Oosterlinck, Andriy Melnik, Tom Callender, Janet Allen, Rachel\nSmith, Will Brown, and Courtney Kremler for their invaluable clinical knowledge and feedback on\nCliMB and Andrew Rashbass, Nabeel Seedat, Jiashuo Liu, Nicol\u00e1s Astorga, Alicia Curth, Paulius\nRauba, Robert Davis, Claudio Fanconi, Paul Schubert, and Favian Bauer for helpful discussions.\nThis work was supported by Microsoft's Accelerate Foundation Models Academic Research initia-\ntive. TS acknowledges scholarships from the Medical Faculty at Heidelberg University and the\nGerman Academic Scholarship Foundation. VK acknowledges funding as a Paul I. Terasaki Scholar\n(G106170)."}, {"title": "6 Appendix", "content": ""}, {"title": "6.1 Software architecture", "content": "The software architecture of CliMB is founded on the following design principles:\n1. LLM, tool, and environment-agnostic. CliMB is not tied to a particular LLM in its\ndesign, set of tools (locally executable, predefined code snippets with a human readable doc-\numentation), or code execution environment. The LLM used can be changed via simple\nextension of the Engine class, new tools can be defined as needed, and the code execution\nenvironment is compartmentalized, flexible and managed via conda. A notable limitation\ncurrently is that only Python code execution environments are supported, but this choice is\nbased on the observation that the most extensive set of ML and data science libraries are\navailable primarily in Python.\n2. Modular. The CliMB software design is modular, broadly following the SOLID [67] design\nprinciples. The main concepts in the architectures are: Engine, which defines how reasoning\nand action units work via the LLM; Message, which stores the details of each interaction\nstep (between the LLM, user, tools, and code execution); UI which defines a user interface\ncompatible with the rest of the architecture; and the code execution environment logic.\n3. Extensible. The two preceding points make CliMB extensible - the key components of the\nsystem can be built upon in a straight-forward fashion. In addition, a structured plan that\ndefines the details of the project to be performed between the LLM and the user can be\ncustomized easily, via a JSON configuration file."}, {"title": "6.2 Data privacy considerations", "content": "The approach to data privacy considerations used in CliMB is further elaborated in this section.\nThis approach was chosen in order to ensure a level of data privacy that is compatible with the\nrequirements of certain non-public datasets. The use of each dataset utilized in the experiments\nreported was approved with the clinician scientist acting as the data steward. In addition, no\npersonally identifiable fields were present in any of the datasets, and all identification reference fields\n(e.g. database IDs that may correspond to data records of a specific patient, procedure, treatment\netc.) were replaced with randomly generated values prior to use with CliMB. The following key\npoints characterize CliMB's current approach to data privacy:\n1. Local storage of data. All dataset files (original or modified in any way by CliMB) are\nstored locally on the user's machine. Hence, the data files are never uploaded to any third-\nparty (LLM provider's, or other) servers.\n2. Local code execution. All code execution performed by CliMB, either through code gen-\neration or predefined tool invocation occurs locally on the user's machine. Hence, no working\ndirectory files of any kind (including saved predictive models, image files, tool output artifacts\netc.) leave the user's machine."}, {"title": "6.3 Structured plan", "content": "This section provides additional details of the structured plan used in CliMB in order to improve\nproject planning robustness. The plan is displayed in Table 7. In addition to the task and subtask\nnames, the plan contains a more detailed description for each. The \"subtask selection\" field indicates\nif the subtask is to be issued always (\u201cmandatory\"), or depending on certain conditions checked\nagainst the project memory (\u201cconditional\u201d) \u2013 conditional subtasks have a corresponding condition\nspecification, e.g. \"applicable to survival analysis\".\""}, {"title": "6.4 Illustration of the planning process", "content": "CliMB's reasoning unit coordinates the project flow through iterative execution of the underly-\ning subtasks. The structured plan defined for the project provides \"checkpoints\" that represent\nguardrails (consider, \"can we proceed to the next stage of the workflow given the current state of\nthe data?\") and best practices (\u201cthe recommended approach in situation X is Y\u201d).\nThis is well-illustrated through the scenario shown in Fig 7. Given that the \"model building\"\nproject stage requires, among other points, that there are no missing values present, the plan for the\n\"data engineering\" stage contains the appropriate missing data handling checkpoint. This manifests\nitself as an evaluation of the dataset for missing values and execution of several subtask actions (all\ninformed by user-guided decisions through feedback): column-wise missingness evaluation, row-wise\nmissingness evaluation, investigation of the target variable's missing values, and imputation. On\nthe output of this process, the dataset is devoid of missing values, and it is safe to proceed to the\nsubsequent \"model building\" work.\nIn the absence of this approach, we find that the stochastic nature of LLMs leads to frequent\ninconsistencies in the state of the project as it progresses (including the dataset, model, and other\nfiles in the working directory, as well as the actual tasks undertaken), and consequently machine\nlearning project best practices are sometimes not followed."}, {"title": "6.5 Interaction log examples", "content": ""}, {"title": "6.5.1 Baseline GPT-4 failure cases", "content": ""}, {"title": "Example 1: incorrect missing value handling", "content": "In the following example we see the failure case of baseline GPT-4 deciding to drop all missing\nvalues in order to avoid a code execution error (ultimately caused by missing values not being\nsupported by the model to be fitted). This resulted in dropping the vast majority of the rows,\nleaving only 14 samples. The failure was not noticed by the system."}, {"title": "Example 2: failure to fully complete planned work", "content": "In the following example, we observe the system failing to fully complete its intended work steps. In\nparticular, during exploratory data analysis, an attempt to generate a correlation matrix is made,\nbut abandoned due to an exception encountered. In addition, while the the work plan initially\nintends to perform feature selection, this ends up boiling down to simply listing the categorical and\nnumeric variables and using them in the following predictive study stage, rather than using any\nfeature selection method, or querying the user's domain knowledge."}, {"title": "Example 3: failure to check for data leakage", "content": "In this example, we observe that baseline GPT-4 tends not to pick up on the presence of likely data\nleakage (or, indeed, the identifier) columns, as it lacks a structured set of checks in the workflow\nthat would ensure this."}, {"title": "6.5.2 CliMB examples", "content": "An example of an entire CliMB session can be watched here: https://youtu.be/76XuR0K3F5Y.\nWe provide examples below that show the advantages of the advanced reasoning approach and other\nfeatures of CliMB. The below examples are sourced from a different session from the recording and\nhence there are minor differences."}, {"title": "Example 1: Data exploration", "content": "This example demonstrates CliMB's approach to getting a detailed and relevant data analysis via\nfeedback from the user and the available tools (EDA and descriptive statistics)."}, {"title": "Example 2: Handling of missing values", "content": "The following example demonstrates how CliMB utilizes a multi-step approach to handling missing\ndata, avoiding common missing data pitfalls, and querying user input when necessary using code\ngeneration and available tools."}, {"title": "6.6 Video demonstrations", "content": "The two video demonstrations used in the Cambridge AI in Medicine Summer School [62] in order\nto gather clinician feedback are referenced below.\n\u2022 Example 1: Baseline GPT-4 session. https://youtu.be/Kyppni0KvoE,\n\u2022 Example 2: CliMB session. https://youtu.be/9u4lleFPMm8."}, {"title": "6.7 Consent form", "content": "Before participating in the polls described in section 3.3", "information": "n1. Introduction\nYou are invited to participate in a research study that aims to understand how an AI-enabled,\ninteractive chatbot can empower clinicians to build their own predictive models. We are particu-\nlarly interested in your perceptions of the responses provided by this chatbot. Before you decide\nto participate, it is important that you understand the purpose of this research and what your\nparticipation will involve. Please take the time to read the following information carefully.\n2. What is the purpose of this research?\nThe primary goal of this research project is to assess the utility of various AI-powered, interactive\nchatbots designed to assist clinicians like you in building predictive models from clinical datasets.\nPredictive models can serve multiple purposes. For example, they can help identify patients at high\nrisk for requiring acute care during radiotherapy, enabling clinicians to provide targeted attention.\nOther models have previously been developed to predict the survival benefits of adjuvant therapy\nfor breast cancer patients. In this study, the chatbot you will see is designed to assist in building\nsuch predictive models. However, our focus is on understanding your perception of how the chatbot\ncommunicates and displays information. Specifically, we are interested in how you evaluate different\ntools across several metrics. Please note that you will not be aware of which tool generated which\nresponse. This study does not assess your abilities or intelligence; we are solely interested in your\nopinions on the chatbot responses.\n3. What data will be collected and how?\nDuring this study, we will collect data related to your preferences. You will be presented with a\nset"}]}