{"title": "Federated Smoothing Proximal Gradient for Quantile Regression with Non-Convex Penalties", "authors": ["Reza Mirzaeifard", "Diyako Ghaderyan", "Stefan Werner"], "abstract": "Abstract-Distributed sensors in the internet-of-things (IoT) generate vast amounts of sparse data. Analyzing this high-dimensional data and identifying relevant predictors pose substantial challenges, especially when data is preferred to remain on the device where it was collected for reasons such as data integrity, communication bandwidth, and privacy. This paper introduces a federated quantile regression algorithm to address these challenges. Quantile regression provides a more comprehensive view of the relationship between variables than mean regression models. However, traditional approaches face difficulties when dealing with nonconvex sparse penalties and the inherent non-smoothness of the loss function. For this purpose, we propose a federated smoothing proximal gradient (FSPG) algorithm that integrates a smoothing mechanism with the proximal gradient framework, thereby enhancing both precision and computational speed. This integration adeptly handles optimization over a network of devices, each holding local data samples, making it particularly effective in federated learning scenarios. The FSPG algorithm ensures steady progress and reliable convergence in each iteration by maintaining or reducing the value of the objective function. By leveraging nonconvex penalties, such as the minimax concave penalty (MCP) and smoothly clipped absolute deviation (SCAD), the proposed method can identify and preserve key predictors within sparse models. Comprehensive simulations validate the robust theoretical foundations of the proposed algorithm and demonstrate improved estimation precision and reliable convergence.", "sections": [{"title": "I. INTRODUCTION", "content": "The internet-of-things (IoT) landscape has been transformed by the adoption of cyber-physical systems characterized by numerous distributed devices and sensors that revolutionize data collection and decision-making processes. In this decentralized environment, traditional methods relying on centralized data aggregation are impractical due to substantial computational, energy, and bandwidth demands, as well as significant privacy concerns [1,2]. Federated learning (FL) offers a solution by enabling collaborative model training across edge devices, reducing privacy risks and the need for centralized data storage [3,4].\nDespite these advancements, FL struggles with outlier data, particularly from heavy-tailed distributions, which can distort learning outcomes and undermine model reliability [5,6]. This highlights the need for robust approaches like quantile regression [7], which analyzes predictor-response relationships across different data quantiles. Quantile regression is particularly beneficial in applications such as wind power prediction [8], uncertainty estimation in smart meter data [9], and load forecasting in smart grids [10], where it manages data variability and intermittency, enhancing stability and efficiency.\nSparse regression techniques are crucial for managing complex IoT data, as they efficiently process vast, heterogeneous data from distributed sensors, providing robust solutions across various fields [11,12]. For instance, in genetics, they help elucidate quantitative traits [13]; in bioinformatics, they refine gene selection in microarray studies [14]; in finance, they enhance risk management models [15]; and in ecology, they clarify relationships between environmental factors and species distribution [16]. To further improve adaptability and efficacy within federated learning, sophisticated penalization methods like the minimax concave penalty (MCP) [17] and smoothly clipped absolute deviation (SCAD) [18] could be integrated. Despite their non-convex and non-smooth nature, MCP and SCAD have some advantages that make them interesting alternatives to the traditional 11-penalty, e.g., they selectively shrink coefficients, effectively reducing the bias and adapting more flexibly across the sparsity spectrum of models [19]-[21].\nHowever, despite numerous available optimization techniques for 11-penalized quantile regression, including sub-gradient methods, primal-dual approaches, and the alternating direction method of multipliers (ADMM) which have established a solid framework for addressing sparsity in centralized settings [22]-[25], the optimization techniques for SCAD or MCP penalized models remains limited. Initially, techniques such as majorization-minimization (MM) and local linear approximation (LLA) have been employed to construct and solve surrogate convex functions that approximate the original non-convex problems [26,27]. Although these methods facilitate the optimization process, they often involve secondary convergence iterations within each loop, which can result in slower overall convergence and potential precision losses. Building on these concepts, the recently proposed sub-gradient algorithm specifically addresses weakly convex functions and offers a more streamlined approach to handling non-convex penalties in quantile regression [28]. A recent innovation in this field is the Single-loop Iterative ADMM (SIAD) algo-"}, {"title": "II. PRELIMINARIES", "content": "This section defines concepts and notations necessary for deriving the federated smoothing proximal gradient (FSPG) algorithm in Section III. In particular, we briefly review sparse quantile regression utilizing non-convex penalties for sparsity and outlier handling, and smoothing approximations aiding gradient-based optimization for non-smooth objectives.\nConsider a scalar variable Y and a predictor vector x of dimension P. The conditional cumulative distribution function is defined as $F_Y(y|x) = P(Y \\le y|x)$. For a given $\\tau \\in (0,1)$, the $\\tau$th conditional quantile, $Q_Y(\\tau|x)$, is given by $Q_Y(\\tau|x) = \\inf\\{y : F_Y(y|x) > \\tau\\}$. The linear model for quantile regression relates $Q_Y(\\tau|x)$ to $x \\in \\mathbb{R}^P$ as follows [36]:\n$Q_Y (\\tau|x) = x^T \\beta_\\tau + q$"}, {"title": "A. Sparse Quantile Regression Framework", "content": "where $\\beta_\\tau \\in \\mathbb{R}^P$ represents the coefficients of the regression model, and $q_\\tau \\in \\mathbb{R}$ is the $\\tau$th quantile of the error term, both being unknown and require estimation.\nWith a dataset consisting of n pairs $\\{x_i, Y_i\\}_{i=1}^n$ and a chosen $\\tau$, we can estimate the model parameters by solving the following optimization problem [36]:\n$\\hat{w} = \\underset{w}{\\text{arg min}} \\frac{1}{n} \\sum_{i=1}^{n} \\rho_\\tau(Y_i - x_i^T w),$\nwhere $x_i = [x_i, 1] \\in \\mathbb{R}^{P+1}$ is the augmented input (feature) vector including a bias term, and $w = [\\beta_\\tau, q_\\tau] \\in \\mathbb{R}^{P+1}$ encapsulates the regression parameters and the intercept, while function $\\rho_\\tau(u) = u(\\tau - \\mathbb{I}(u < 0))$ is the check loss function with $\\mathbb{I}(\\cdot)$ being the indicator function [36].\nTo enhance inference by incorporating model coefficient priors, we integrate a penalty function $P_{\\lambda,\\gamma}(w)$, transforming the optimization problem in (2) to the following form [21]:\n$\\hat{w} = \\underset{w}{\\text{arg min}} \\frac{1}{n} \\sum_{i=1}^{n} \\rho_\\tau(Y_i - x_i^T w) + P_{\\lambda,\\gamma}(w),$\nwhich can be alternatively expressed as:\n$\\hat{w} = \\underset{w}{\\text{arg min}} \\frac{1}{n} ||y - X^T w||_1 + \\eta P_{\\lambda,\\gamma}(w).$\nIn the federated setting, we consider a network consisting of L edge devices (clients), each with its local dataset $\\{X^{(l)},y^{(l)}\\}$, where $y^{(l)} \\in \\mathbb{R}^{M_l}$ is a column vector of responses and $X^{(l)} \\in \\mathbb{R}^{M_l \\times (P+1)}$ is a matrix presenting the extended feature vectors, including a bias term. We assume $n = \\sum_{l=1}^{L} M_l$, $X = [(X^{(1)})^T,\\dots,(X^{(L)})^T]^T$, and $y = [(y^{(1)})^T,\\dots, (y^{(L)})^T]^T$. Thus, the objective function (4) can thus be rewritten as:\n$\\underset{w}{\\text{min}} \\sum_{l=1}^{L} g_l(w) + \\eta P_{\\lambda,\\gamma}(w),$\nwhere $g_l(w) = \\frac{1}{M_l} \\sum_{i=1}^{M_l} \\rho_\\tau(y_i^{(l)} - (x_i^{(l)})^T w) =  \\frac{1}{M_l} ||y^{(l)} - (X^{(l)})^T w||_1 + \\frac{1}{M_l} \\sum_{i=1}^{M_l} (y_i^{(l)} - (x_i^{(l)})^T w)I((y_i^{(l)} - (x_i^{(l)})^T w) < 0)$ represents the local loss function for client l.\nWhile the l\u2081 norm penalty is widely adopted for inducing sparsity, it often leads to biased estimates. To address this issue, our approach utilizes the minimax concave penalty (MCP) [17] and the smoothly clipped absolute deviation (SCAD) [18] as alternatives. These penalties are formulated as $P_{\\lambda,\\gamma}(w) = \\sum_{p=1}^{P} g_{\\lambda,\\gamma}(w_p)$, which help to reduce this bias and enhance model sparsity. These penalties are defined as follows, with the constraints that $\\gamma \\ge 1$ for MCP and $\\gamma > 2$ for SCAD [17,18]:\ng_{\\lambda,\\gamma}^{\\text{MCP}} (w_p) = $\begin{cases}\n  \\lambda |w_p| - \\frac{w_p^2}{2\\gamma}, & |w_p| \\le \\gamma \\lambda \\\\\n  \\frac{\\gamma \\lambda^2}{2}, & |w_p| > \\gamma \\lambda\n\\end{cases}\nand\ng_{\\lambda,\\gamma}^{\\text{SCAD}}(w_p) = $\begin{cases}\n  \\lambda |w_p|, & |w_p| \\le \\lambda \\\\\n  \\frac{\\lambda^2 - 2\\gamma \\lambda |w_p| + w_p^2}{2(\\gamma-1)}, & \\lambda < |w_p| \\le \\gamma \\lambda \\\\\n  \\frac{(\\gamma+1)\\lambda^2}{2}, & |w_p| > \\gamma \\lambda\n\\end{cases}\nThese penalties effectively distinguish between active and inactive coefficients, which makes them highly suitable for sparse modeling. Notably, both MCP and SCAD exhibit weak convexity for specific p values, ensuring that $g_{\\lambda,\\gamma}(w) + \\frac{\\rho}{2} w^2$ remains convex [37]. This aspect, detailed in prior work, highlights the nuanced efficiency of these functions in the context of sparse quantile regression [33,34].\nThe proximal gradient method is a powerful optimization algorithm that enables optimization in a central machine without access to local data. However, conventional proximal gradient algorithms in the non-convex setting typically assume the presence of a smooth component [32]. Modifications such as a time-varying penalty parameter have been proposed to extend proximal gradient methods to non-smooth functions [35]. However, these approaches do not guarantee that each iteration will monotonically improve the objective function value. This limitation underscores the need for a novel federated proximal gradient algorithm that is better suited to the non-smooth and federated setting of federated penalized quantile regression [35]. In this context, a smoothing approach can be practical to ensure improvement in each iteration."}, {"title": "B. Smoothing Approximation", "content": "Handling non-smooth functions in optimization presents significant challenges, primarily as we cannot exploit the beneficial properties of smooth functions, such as gradient-based convergence guarantees. A common strategy to overcome this limitation is to employ smoothing techniques, which involve replacing non-smooth functions with smooth approximations. These smoothed functions are easier to optimize, particularly within the proximal gradient framework we propose in this paper.\nWe begin by introducing a smoothing function, which approximates a non-smooth function g with a smooth surrogate $\\tilde{g}$, thereby facilitating a more streamlined optimization trajectory.\nDefinition 1 [38]: Let $\\tilde{g}: \\Omega \\subseteq \\mathbb{R}^m \\times (0, +\\infty) \\rightarrow \\mathbb{R}$ serve as a smoothing approximation of g, with $g : \\Omega \\subseteq \\mathbb{R}^m \\rightarrow \\mathbb{R}$ exhibits local Lipschitz continuity. The smoothing function $\\tilde{g}$ satisfies the following properties:\n1) Differentiability: $\\tilde{g}(\\cdot,\\mu)$ is continuously differentiable over $\\mathbb{R}^m$ for any $\\mu > 0$. Additionally, for every $x \\in \\Omega$, $\\tilde{g}(x,\\cdot)$ is differentiable over $(0, +\\infty]$.\n2) Convergence Criterion: For every $x \\in \\Omega$, $\\lim_{\\mu \\rightarrow 0^+} \\tilde{g}(x, \\mu) = g(x)$.\n3) Bound on Gradient: There exists a positive constant $K_{\\tilde{g}}$ such that $|\\nabla_{\\mu}\\tilde{g}(x,\\mu)| \\le K_{\\tilde{g}}$ for all $\\mu \\in (0,+\\infty)$ and $x \\in \\Omega$.\n4) Gradient Convergence: The condition $\\lim_{z \\rightarrow x, \\mu \\rightarrow 0} \\nabla_z \\tilde{g}(z, \\mu) \\subseteq \\partial g(x)$ is satisfied. Moreover, for each $x \\in \\mathbb{R}^m$, the smoothing function $\\tilde{g}$ upholds:"}, {"title": "III. FEDERATED SMOOTHING PROXIMAL GRADIENT FOR PENALIZED QUANTILE REGRESSION", "content": "In order to address the challenges arising from the lack of Lipschitz differentiability in our objective function, we here introduce the federated smoothing proximal gradient (FSPG) algorithm. This algorithm incorporates a dynamically increasing penalty parameter to enhance convergence properties. The core of FSPG involves approximating the non-smooth term $||y^{(l)} - (X^{(l)})^T w||_1$ with a sum of smooth functions, following the smoothing approach described in [38]. Specifically, we employ a smoothing approximation function for each term $|y_i^{(l)} - (x_i^{(l)})^T w|$, defined as:\n$g(y_i^{(l)} - (x_i^{(l)})^T w,\\mu) = \\frac{(y_i^{(l)} - (x_i^{(l)})^T w)^2}{2\\mu}, y_i^{(l)} - (x_i^{(l)})^T w < \\mu,$\n$g(y_i^{(l)} - (x_i^{(l)})^T w,\\mu) = |(x_i^{(l)})^T w| - \\frac{\\mu}{2}, (x_i^{(l)})^T w < \\mu$\nTo aggregate these approximations, we introduce the function h(.), which sums up the smooth approximations for all elements in each local dataset. This results in the expression:\n$h(y_i - (X_i^{(l)})^T w,\\mu) =  \\frac{1}{2} (y_i^{(l)} - (x_i^{(l)})^T w)^2$\n$\\mu$\n$+ I() (y_i - (x_i)^T w).$\nUsing the approximation provided, we reformulate the objective function as follows:\n$\\underset{w}{\\text{min}} \\sum_{l=1}^{L} \\tilde{g}_l (w,\\mu) + \\eta P_{\\lambda,\\gamma}(w),$\nwhere $\\tilde{g}_l(w,\\mu) = h(y^{(l)} - (X^{(l)})^T w, \\mu)$ represents the smoothed local loss function for client l. The approximation becomes increasingly precise as $\\mu$ approaches zero, aligning the approximate objective function with the true objective.\nTo iteratively refine the approximation, we update the parameters $\\mu$ and $\\sigma$ at each iteration using the following rules, where $c > 0$, $\\beta > 0$, and $d \\in (0,1)$:\n$\\sigma^{(k+1)} = c (k + 1)^d,$\n$\\mu^{(k+1)} = \\frac{\\beta}{(k+1)^d},$\nThe above update rules balance smoothness and precision. As the algorithm advances, $\\mu$ decreases, aligning the smoothed objective function more closely with the original non-smooth function, enhancing precision. Simultaneously, $\\sigma$ increases, stabilizing iterative updates with a stronger penalty and improving convergence properties.\nSubsequently, each client l computes its gradient with respect to $w^{(k)}$ as follows:\n$\\nabla \\tilde{g}_l (w^{(k)}) = \\frac{1}{M_l} \\sum_{i=1}^{M_l} \\nabla \\tilde{g}(y_i^{(l)} - (x_i^{(l)})^T w^{(k)},\\mu),$\nwhere\n$\\nabla_fy\\frac{g(y_i^{(l)} - (x_i^{(l)})^T w^{(k)},\\mu)}{\\mu} (y_i^{(l)} - (x_i^{(l)})^T w^{(k)}), y_i^{(l)} - (x_i^{(l)})^T w^{(k)} < \\mu,$\n$\\frac{\\partial y}{ y (g(y_i^{(l)} - (x_i^{(l)})^T w^{(k)},\\mu))sign{x_i^Tx w^{(k)})},x_i^Tw^{(k)} < \\mu,$$\nFollowing the local gradient updates, each client communicates this gradient to the central server. The server aggregates these gradients to update the global model parameter w using the following formula:\n$w^{(k+1)} = \\underset{w}{\\text{arg min}} \\sum_{l=1}^{L} ((\\nabla \\tilde{g}_l (w^{(k)}, \\mu^{(k+1)}),(w - w^{(k)}) + \\frac{\\sigma^{(k+1)}}{2} ||w - w^{(k)}||^2) + \\eta P_{\\lambda,\\gamma} (w),$\nwhere each component $w_p$ of w is individually updated via the proximal operator to maintain sparsity:\n$w_p^{(k+1)} = \\underset{w_p}{\\text{arg min}} \\eta g_{\\lambda,\\gamma} (w_p) + \\frac{\\sigma^{(k+1)}}{2} ||w_p - a_p||^2,$\n=$ Prox_{\\gamma_x, \\lambda_p} (\\frac{a_p}{\\sigma^{(k+1)}}).$"}, {"title": "IV. CONVERGENCE PROOF", "content": "Establishing the convergence of the proposed proximal gradient algorithm requires validating four essential conditions: boundedness, sufficient descent, subgradient bound, and global convergence, as highlighted in [41, Theorem 2.9]. To this end, we start by demonstrating the boundedness of the augmented Lagrangian, formalized in Lemma 1 below.\nLemma 1. The function $\\Phi_\\sigma (w, w', \\mu) = \\sum_{l=1}^{L} \\tilde{g}_l(w', \\mu) + \\eta P_{\\lambda,\\gamma}(w) + \\frac{\\sigma}{2} ||w - w'||^2$ is lower bounded.\nProof. Consider the function $\\Phi_\\sigma (w, w', \\mu)$ defined as above. We will examine each term to establish the lower bound:\n1) The term $\\sum_{l=1}^{L} \\tilde{g}_l(w', \\mu)$ represents the sum of smoothed local loss functions across L clients. By construction, the smoothed approximation of the quantile loss function $\\tilde{g}_l$ is designed to be always greater than or equal to the actual quantile loss function, which in turn is non-negative. Therefore, this term is non-negative for all w and $\\mu > 0$.\n2) The regularization term $\\eta P_{\\lambda,\\gamma}(w)$ involves penalties based on MCP and SCAD, both of which are non-negative for any w. These penalties are designed to induce sparsity while ensuring the overall term remains non-negative.\n3) The quadratic term $\\frac{\\sigma}{2} ||w - w'||^2$ is non-negative, as it is the squared Euclidean norm of the difference between w and w', scaled by a positive constant $\\sigma$.\nBy combining these observations, we conclude that $\\Phi_\\sigma (w, w', \\mu)$, being the sum of non-negative terms, is itself"}, {"title": "V. SIMULATION RESULTS", "content": "In this section, we present an extensive simulation study to evaluate the efficacy of our federated smoothing proximal gradient (FSPG) algorithm in the context of sparse quantile regression. We compare the FSPG with leading contemporary approaches, including the proximal gradient descent with increasing penalty (PGD) [35] and the sub-gradient method (SUB) [33] tailored for federated settings, and the smoothing time-increasing penalty ADMM (SIAD) [34] as a benchmark for centralized scenarios. Our evaluation criteria include convergence rate, efficiency in minimizing the mean square error (MSE) across both synthetic and real-world datasets, as well as accuracy in recognizing active and non-active coefficients. Additionally, we compare the performance and convergence dynamics of the FSPG algorithm against the Federated Huber Loss Proximal Gradient (FHPG) - a variant of FSPG with static $\\mu$and $\\sigma$ parameters - focusing on the MSE performance. This examination aims to highlight the nuanced advantages and potential trade-offs inherent in using the FSPG approach to quantile regression.\nWe evaluate the performance of the FSPG algorithm across six distinct simulation scenarios. In these evaluations, the penalty parameters are set to $\\gamma_{SCAD} = 3.1$, $\\gamma_{MCP} = 2.4$, $\\beta = 4$, and $c = $\nFor all synthetic data scenarios, we fix $\\kappa = 0.055$, and the results are averaged over 1000 independent experiments. The primary performance metric for synthetic data is the MSE, defined as $E||\\hat{w} - w||^2$. We assess algorithm performance"}, {"title": "VI. CONCLUSION", "content": "This paper introduced the federated smoothing proximal gradient (FSPG) approach, a novel approach for handling sparse-penalized quantile regression with non-convex and non-smooth penalties in federated settings. We rigorously demonstrated the convergence behavior of the FSPG, highlighting its efficiency with a sub-gradient bound rate of $o(\\frac{1}{k^{d/2 + 1/2}})$ for the proximal gradient steps. This represents a significant enhancement over traditional methods such as the sub-gradient (SUB) algorithm and proximal gradient descent with time-increasing penalty (PGD). Uniquely, FSPG guarantees quantifiable improvements in model accuracy with each iteration, a feature not consistently provided by other methods. The algorithm achieves a reduction in the fluctuation of coefficients across successive iterations at a rate of $o(\\frac{1}{k^{1+d/2}})$, markedly superior to conventional methods. This advantage underscores the superior optimization dynamics of our approach, especially suited for the federated settings. Empirical results confirm that FSPG is more capable of providing accurate coefficients in complex scenarios, and excels in precisely identifying active and non-active coefficients. This capability ensures more reliable and interpretable models, which are crucial for practical applications requiring precise predictive analytics. As a result, the FSPG algorithm emerges as a robust and efficient framework for addressing the complex challenges posed by non-smooth and non-convex objective functions in federated quantile regression. This method significantly advances the field by enhancing the reliability and interpretability of the models in decentralized data environments."}]}