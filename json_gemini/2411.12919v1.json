{"title": "Enhancing Deep Learning-Driven Multi-Coil MRI Reconstruction via Self-Supervised Denoising", "authors": ["Asad Aali", "Marius Arvinte", "Sidharth Kumar", "Yamin I. Arefeen", "Jonathan I. Tamir"], "abstract": "Purpose: To examine the effect of incorporating self-supervised denoising as a pre-processing step for training deep learning (DL) based reconstruction methods on data corrupted by Gaussian noise. K-space data employed for training are typically multi-coil and inherently noisy. Although DL-based reconstruction methods trained on fully sampled data can enable high re-construction quality, obtaining large, noise-free datasets is impractical.\n\nMethods: We leverage Generalized Stein's Unbiased Risk Estimate (GSURE) for denoising. We evaluate two DL-based reconstruction methods: Diffusion Probabilistic Models (DPMs) and Model-Based Deep Learning (MoDL). We evaluate the impact of denoising on the performance of these DL-based methods in solving accelerated multi-coil magnetic resonance imaging (MRI) reconstruction. The experiments were carried out on T2-weighted brain and fat-suppressed proton-density knee scans.\n\nResults: We observed that self-supervised denoising enhances the quality and efficiency of MRI reconstructions across various scenarios. Specifically, employing denoised images rather than noisy counterparts when training DL networks results in lower normalized root mean squared error (NRMSE), higher structural similarity index measure (SSIM) and peak signal-to-noise ratio (PSNR) across different SNR levels, including 32dB, 22dB, and 12dB for T2-weighted brain data, and 24dB, 14dB, and 4dB for fat-suppressed knee data.\n\nConclusion: We showed that denoising is an essential pre-processing technique capable of improving the efficacy of DL-based MRI reconstruction methods under diverse conditions. By refining the quality of input data, denoising enables training more effective DL networks, potentially bypassing the need for noise-free reference MRI scans.\n\nKeywords: MRI, accelerated reconstruction, self-supervised denoising, generative diffusion models, deep learning", "sections": [{"title": "Introduction", "content": "Magnetic resonance imaging (MRI) is a crucial imaging modality in clinical practice, offering detailed anatomical and functional information without ionizing radiation. Nonetheless, MRI is hindered by prolonged acquisition times, resulting in increased costs, patient discomfort, and motion-related artifacts that degrade image quality [1]. To mitigate these issues, accelerated MRI techniques have been developed to reduce scan time by acquiring fewer data points [2-7].\n\nClinically, the most prevalent method to accelerate MRI reconstruction is parallel imaging, which utilizes multiple receiver coils to acquire undersampled k-space data [2, 8-10]. Although parallel imaging is effective, it suffers from noise amplification and residual aliasing at high acceleration rates, compromising image quality and diagnostic utility. Recent years have witnessed advances in applied supervised machine learning techniques for accelerated MRI reconstruction, broadly categorized into two primary approaches: end-to-end methods [11-14] and generative probabilistic methods [15-20]. Competitive end-to-end deep learning (DL) methods train unrolled models by integrating a neural network architecture with conventional optimization to map undersampled k-space measurements to a high-quality coil-combined image. Although these methods typically deliver high-quality reconstructions, this performance is limited to in-distribution data (i.e., where the sampling pattern, field of view, and resolution are matched at training and at inference time), as the methods are conditioned on the measurement model [21, 22]. Generative methods [17, 18, 23-26], conversely, learn a prior distribution from fully sampled data and decouple prior learning from the forward model. Reconstruction is then formulated as a Bayesian inverse problem, for example as an approximation to posterior sampling. This approach allows greater flexibility, as the learned prior can be trained once and then applied to various inverse problems, regardless of the forward model.\n\nBoth end-to-end and generative approaches rely on the availability of large, high-quality, fully sampled datasets, which can be difficult and costly to acquire [27, 28]. Recent studies have introduced several self-supervised training and reconstruction methods that do not require fully sampled data [29-36]. By creating specialized loss functions, these self-supervised techniques demonstrate that models trained on undersampled data can be utilized for high-quality reconstructions. In many practical scenarios involving low signal-to-noise ratio (SNR) data, such as low-field MRI, the available training data are inherently noisy [37-39]. Several self-supervised denoising methods have been introduced, circumventing the need for paired fully sampled noise-free images during training [40-51]. Self-supervised denoising methods for MRI applications have also been devel-"}, {"title": "Theory", "content": "Multi-Coil Magnetic Resonance Imaging\n\nMulti-coil MRI is a linear inverse problem, with the forward operator A comprising the coil sensitivity operator S, Fourier transform F, and sampling operator P [8]. An image (without loss of generality assumed to be 2D) $X \\in \\mathbb{C}^{N_x \\times N_y}$ is acquired using $N_c$ coils, with measurements in k-space. $N_x$ and $N_y$ are sample counts in frequency and phase encoding directions, respectively. The vectorized measurements are:\n\n$y = PFSx + \\eta,$\\\n      \t$\nwhere $x \\in \\mathbb{C}^{N_xN_y}$ is the vectorized image, $S \\in \\mathbb{C}^{N_cN_xN_y \\times N_xN_y}$ denotes the sensitivity map operator that models the spatial sensitivities of the coils, F is the Fourier transform applied across each coil, and $P\\in \\mathbb{C}^{(N_xN_cN_c/R)\\times N_cN_xN_y}$ is the sampling operator that selects a subset of k-space locations, reducing the acquisition time by a factor of R.\n\nThe problem becomes ill-conditioned due to the undersampling of k-space, which results in missing information and noise amplification. Reconstructing the original signal x from the undersampled k-space measurements y is known as accelerated MRI reconstruction. This problem is commonly formulated as an optimization problem, where the goal is to find the estimate $\\hat{x}$ that balances data consistency with regularization. One approach is to solve the regularized least squares problem:\n\n$\\hat{x} = \\underset{x}{\\text{argmin}} \\frac{1}{2} ||y - Ax||_2^2 + \\lambda R(x),$\\\n      \t[2]\n$\\text{data consistency} \\quad \\quad \\quad \\text{regularization}$\nwhere the first term, $||y- Ax||_2^2$, enforces consistency between the measured data y and the predicted measurements Ax, assuming Gaussian noise. The second term, $R(x)$, is a regularization term that incorporates prior knowledge about the distribution of x. Common choices include $l_1$-norm-based regularization, which promotes sparsity in certain transform domains, and total variation (TV) regularization, which encourages smoothness while preserving edges. Such regularizers are effective at reducing noise and undersampling artifacts while preserving key image features. This regularized formulation helps stabilize the solution, ensuring that the reconstruction is both accurate and robust to noise and undersampling artifacts. Deep learning methods utilize prior knowledge of the underlying distribution by learning from the training data. When a statistical model for $p_x(x)$ is available, the regularizer can be expressed as the negative log-likelihood:\n\n$R(x) = -log p_x(x).$\t[3]\n\nDistribution Learning using Noisy Measurements\n\nIn MRI, measurements are inherently noisy due to various physical and environmental factors, including the receiver coils' thermal noise, noise due to the body, and the acquisition system's imperfections. These noisy measurements introduce additional challenges when learning statistical priors about the ground-truth signals, as the noise corrupts the data, making it difficult to approximate the underlying signal distribution accurately. Equation [1] describes a single set of measurements, such as those acquired during a single MRI scan. In practice, we often have access to a set of noisy but fully sampled measurements obtained from different ground-truth signals $x^{(i)}$. These measurements, denoted as $y^{(i)}$, are described as:\n\n$y^{(i)} = FS^{(i)}x^{(i)} + \\eta^{(i)},$\\\n      \t[4]\nwhere $S^{(i)}$ denotes the coil sensitivity map corresponding to the i-th sample, F is the 2D Fourier transform, and $\\eta^{(i)}$ represents Gaussian noise, which is assumed to have zero mean and covariance matrix $C^{(i)}$. The superscripts indicate that each sample in the set can have different ground-truth signals, linear operators, and noise realizations."}, {"title": "Self-Supervised Denoising", "content": "One approach to learning a prior R(x) from noisy MRI measurements is applying self-supervised denoising [52-57] as a pre-processing step. The goal is to train a parametric model $g_{\\phi}(A^H y)$, parameterized by $\\phi$, that maps a noisy estimate $A^H y$ to its clean counterpart x, where $A^H$ is the Hermitian transpose (adjoint) operator. The model $g_{\\phi}$ is learned such that it minimizes the difference between the model's output and the clean data $x^{(i)}$. When ground-truth data $x^{(i)}$ are available for each noisy measurement $y^{(i)}$, the optimal model parameters $\\phi^*$ could be learned by minimizing the supervised loss function based on empirical expectation:\n\n$\\mathcal{L}_{Sup, \\phi}(x) = \\frac{1}{i} \\sum || g_{\\phi}(A^H y^{(i)}) - x^{(i)} ||^2.$\t[5]\n\nHowever, in most practical cases, ground-truth data are not available. Hence, we utilize GSURE [58] to obtain an unbiased estimate of the supervised loss based on the noisy measurements alone. This allows training without access to the true signal x(i). When the measurements y(i) are corrupted by independent and identically distributed (i.i.d.) Gaussian noise with a known covariance matrix $\\sigma^2 I$, the GSURE expression for the self-supervised loss is given by [58]:\n\n$\\mathcal{L}_{GSURE, \\phi}(A^H y; \\sigma) = \\frac{||g_{\\phi}(A^H y)||^2}{\\sigma^2} + \\frac{1}{2} div_x (g_{\\phi} \\frac{A^H y}{\\sigma^2}) - \\frac{||A^H y||^2}{\\sigma^2},$\\\n      \t[6]\n\nHere, $A^{\\dagger}$ denotes the pseudo-inverse of the matrix A, and the term $div_x(g_{\\phi}(x))$ represents the divergence of the function $g_{\\phi}$ at the point x, defined as:\n\n$div_x(g_{\\phi}(x)) = \\sum_i \\frac{\\partial [g_{\\phi}(x)]_i}{\\partial x_i}.$\t[7]\n\nThe computation of the full divergence in [7] requires evaluating the partial derivatives for each dimension of x, which is computationally expensive, especially for high-resolution MRI images. To address this, we approximate the divergence using a Monte Carlo method, following the approach in [41]. The Monte Carlo estimate is computed using a single realization of zero-mean Gaussian noise $b \\sim \\mathcal{N}(0, I)$ and a small constant $\\epsilon$. The approximation is given by:\n\n$div_x(g_{\\phi}(x)) \\approx b^T (\\frac{g_{\\phi}(x + \\epsilon b) - g_{\\phi}(x)}{\\epsilon}),$\\\n      \t[8]\n\nThis approximation drastically reduces the computational cost of evaluating the divergence while maintaining sufficient accuracy for training the denoising model. The GSURE loss function does not depend on the ground-truth data x, yet it has the remarkable property that its expectation is an unbiased estimate of the supervised loss. Specifically, it holds that for a fixed A:\n\n$\\mathbb{E}_{x,y} [\\mathcal{L}_{GSURE, \\phi}(A^H y; \\sigma)] = \\mathbb{E}_{x,y} [\\frac{||g_{\\phi}(A^H y)||^2}{\\sigma^2} - 2g_{\\phi}^T(\\frac{A^H y}{\\sigma^2}) \\frac{(A^H y)}{\\sigma^2}],$\\\n      \t[9]\n\nup to a constant factor [58]. In practice, the expectation E is taken over x, y, and A according to [61]. The GSURE formulation serves as a reliable training loss for self-supervised learning in the absence of clean data, and it can be directly applied to scenarios where noisy measurements are available. GSURE loss can handle scenarios with varying noise levels $\\sigma^{(i)}$ across different images, as is often the case in MRI acquisitions. In particular, this matches the setting where each coil can have different noise levels, in addition to different noise levels in each acquisition in a training set. This flexibility makes GSURE particularly well-suited for learning from noisy, real-world MRI data."}, {"title": "Methods", "content": "Diffusion Probabilistic Models (DPMs) for Inverse Problems\n\nDiffusion probabilistic models (DPMs) have recently shown potential as powerful generative models for solving ill-posed inverse problems, including accelerated MRI reconstruction. These models generate unconditional samples from a target distribution $p_0$ by iteratively refining noisy observations of the form $x_t = x_0 + \\sigma(t) \\eta_t$, where $\\eta_t \\sim \\mathcal{N}(0, I)$ (for all t) represents Gaussian noise, and $\\sigma(t)$ defines a time-dependent noise schedule. The primary objective of the DPM is to gradually denoise $x_t$ and generate an image $x_0 \\sim p_0(x_0)$. This generative process is modeled by a stochastic differential equation (SDE) [23, 26], which governs the backward denoising process:\n\n$dx = -2\\delta(t) (\\mathbb{E}[x_0|x_t] - x_t) dt + g(t) dw,$\\\n      \t[10]\n\nwhere w denotes the standard Wiener process, g(t) is called the diffusion coefficient, and $\\mathbb{E}[x_0|x_t]$ is the model's estimate of the clean image at time t based on the noisy input. In inverse problem settings, the challenge is to recover $x_0$ from noisy, undersampled measurements y, which requires sampling from the posterior distribution $p(x_0|y)$. This process combines prior knowledge of the distribution with the likelihood of the measurements given a clean image. The stochastic process for this is modeled by a corresponding backward stochastic differential equation (SDE), similar to the generative process:\n\n$dx = -2\\delta(t) (\\mathbb{E}[x_0|x_t, y] - x_t) dt + g(t) dw.$\t[11]\n\nBayes' rule allows this posterior to be factored as $p(x_0|y) \\propto p(y|x_0) p(x_0)$, where $p(x_0)$ is the prior learned by the model, and $p(y|x_0)$ represents the likelihood of the measurements given $x_0$.\n\nFor most practical forward operators, computing the likelihood $p(y|x_t)$ in closed form is computationally intractable. Various approximation methods have been proposed to leverage DPMs for inverse problems [17, 60, 62-66]. An effective approximation technique is Diffusion Posterior Sampling (DPS) [60], which estimates $x_0$ using the noisy intermediate state $x_t$ and substitutes the intractable likelihood $p(y|x_t)$ with the conditional likelihood $p(y|\\hat{x_0})$, where $\\hat{x_0}$ is an estimate of $x_0$ derived from the intermediate noisy state $x_t$. Specifically, DPS approximates $p(y|x_t)$ by $p(y|x_0 = \\mathbb{E}[x_0|x_t])$, resulting in the following update equation:\n\n$dx = -2\\delta(t) \\sigma(t) (\\frac{\\mathbb{E}[x_0|x_t] - x_t}{\\sigma(t)} + \\gamma \\nabla_{x_t} log p(y|x_0 = \\mathbb{E}[x_0|x_t])) dt + g(t) dw,$\t[12]\n\nwhere $\\gamma_t$ is a guidance parameter that modulates the influence of the data consistency term. The parameter $\\gamma_t$ is typically adjusted based on the noise level $\\sigma(t)$, with higher noise levels necessitating stronger guidance to ensure data fidelity.\n\nDPMs allow for decoupling of prior learning from the measurement model, while their stochastic nature allows for uncertainty quantification by generating a distribution of possible solutions instead of just a single-point estimate. If a single-point estimate is desired, then these solutions can be averaged to form an approximate conditional expectation. This property is advantageous in scenarios with highly undersampled data, where multiple plausible reconstructions can exist.\n\nModel-Based Deep Learning (MoDL) for Inverse Problems\n\nModel-based deep learning (MoDL) [14] and other unrolled neural networks [67] are end-to-end models that alternate between deep neural networks and differentiable optimization blocks. The MoDL framework in particular integrates the physics of the forward problem into a deep neural network architecture through the conjugate gradient algorithm. This makes it particularly well-suited for solving ill-posed inverse problems. The overall objective is to solve the following optimization problem (equation [2]):\n\n$\\hat{x} = \\underset{x}{\\text{argmin}} ||y - Ax||_2^2 + \\lambda ||R_\\theta(x)||^2,$\t[13]\n\nwhere A represents the forward operator, data consistency term $||y - Ax||_2^2$ ensures the reconstruction matches the acquired measurements, regularization term $||R_\\theta(x)||^2$ imposes learned prior information to reduce artifacts, and $\\lambda$ controls the trade-off between data fidelity and regularization. The regularization term $R_\\theta(x)$ is expressed as $x - D_\\theta(x)$, where $D_\\theta(x)$ is the estimate of x after removal of noise and aliasing artifacts. The overall steps of this optimization are expressed as an alternating minimization between data consistency and denoising. The unrolled iterations comprising the full network are trained end-to-end, with the CNN-based denoiser $D_\\theta$ shared across all iterations. $D_\\theta$ is applied after the data-consistency update to remove residual artifacts, generating a refined reconstruction at each iteration, giving the objective:\n\n$\\hat{x} = \\underset{x}{\\text{argmin}} ||y - Ax||_2^2 + \\lambda ||x - D_\\theta(x)||^2.$\t[14]\n\nTo train the supervised MoDL network, we utilize the normalized root mean squared error (NRMSE) objective between reconstructed images $\\hat{x}_i = H_\\theta(y_i, A_i)$ and the fully sampled images $x_i$:\n\n$L(x_i, \\hat{x}_i) = \\frac{||x_i - H_\\theta(y_i, A_i)||_2}{||x_i||_2},$\\\n      \t[15]\n\nwhere $x_i$ are the fully sampled images, while $H_\\theta(y_i, A_i)$ are the corresponding reconstructions generated by the MoDL network given the undersampled measurements $y_i$ and forward operator $A_i$. Here, $H_\\theta$ refers to the entire MoDL network, which includes all unrolls of the data-consistency and denoising steps, while $D_\\theta$ specifically denotes the CNN-based denoiser applied in each iteration.\n\nBy incorporating the forward operator A and the physics of the acquisition process directly into the architecture, MoDL ensures that the reconstructions are physically plausible and consistent with the measured data. Moreover, unrolling the iterative process allows the network to learn a reconstruction procedure that mimics traditional model-based methods, while CNN provides a flexible, data-driven regularization. However, a notable drawback of the MoDL framework is that the forward model A is coupled during training, meaning that the model may not generalize well when the forward operator differs during testing or deployment, leading to generalization errors [14]."}, {"title": "Proposed Approach", "content": "To demonstrate proof-of-principal, we use the fastMRI [59] dataset as the source of our training data, which is preprocessed following the appropriate forward model defined in equation [1]. Although fastMRI data are fully sampled, they are inherently noisy. Typically, a noise prescan is available that can be used for pre-whitening [68]. As fastMRI does not provide this information, we use noise-only patches from the multi-coil images to estimate the multi-coil noise covariance matrix. To prepare the data for GSURE-based denoising, we apply noise pre-whitening using the Berkeley Advanced Reconstruction Toolbox (BART) [69] and normalize the k-space data to account for variations in signal intensity across scans. This step reduces variability in signal levels, ensuring that noise and signal intensities are comparable across scans. Formally, we define the pre-whitened, normalized k-space as:\n\n$y^* = FSx^* + \\eta^*,$\\\n      \t[16]\n\nwhere $\\eta^* \\sim \\mathcal{N}(0, \\sigma_{\\eta^*}^2 I)$ represents the normalized noise term with variance $\\sigma_{\\eta^*}^2$. The core of our approach involves learning the perturbed distribution of minimum mean square error (MMSE) denoised data. Although this formulation is distinct from directly learning the true distribution of clean data at arbitrary noise levels, we aim to decouple GSURE denoising from distribution learning. A schematic of the training pipeline is provided in Figure 1. By accounting for noise, we hypothesize that it is possible to learn an approximate distribution of the clean images from denoised measurements. We propose a structured two-stage approach, trained sequentially:\n\nMMSE Denoising: We train a function $g_\\phi$ to output minimum mean-square error (MMSE)-denoised, coil-combined images $x_{MMSE}$ from noisy multi-coil k-space data. This function is learned using the self-supervised GSURE training objective described in equation [6], where the GSURE network takes the adjoint of the measurements as input, scaled by the estimated noise variance.\n\nDeep Learning-Driven MRI Reconstruction: We train deep neural networks on the denoised outputs of $g_\\phi$ to learn the distribution for subsequent accelerated MRI reconstruction:\n\nDPM-based Reconstruction: We utilize DPMs trained using the Elucidating Diffusion Models (EDM) [26] architecture and perform reconstruction using DPS [60].\n\nMoDL-based Reconstruction: We use supervised MoDL [14] (end-to-end)."}, {"title": "Experimental Setup", "content": "Data\n\nFor training, we utilize k-space data from fully sampled T2-weighted brain and fat-suppressed proton-density knee scans from fastMRI [59]. We extract 5 central slices from each volume for both anatomies, resulting in a total of 10,000 brain slices and 2,000 knee slices. The k-space data are first converted into coil images by applying the inverse Fourier transform (IFFT), and these coil images are then cropped to matrix sizes of 384 \u00d7 320 for brain and 440 \u00d7 368 for knee. After noise pre-whitening, we normalize k-space data by first cropping a 24 \u00d7 24 center region of k-space, then reconstructing this auto-calibration signal (ACS) region using the root sum-of-squares (RSS). We use the 99th percentile of the ACS reconstruction to normalize pre-whitened k-space. We define the SNR of the pre-whitened and normalized dataset $y^*$ as:\n\n$SNR = 10 log_{10} (\\frac{||y^*||_2}{\\sigma_{\\eta^*}})^2,$\t[17]\n\nwhere $\\sigma_{\\eta^*}^2$ represents the noise variance after pre-whitening and normalization. The brain dataset has an average native SNR of 32 dB, while the knee dataset has an average SNR of 24 dB.\n\nFor accelerated reconstruction, we retrospectively undersample 100 examples per anatomy using the same pre-processing steps. Random sampling is performed in the phase-encode direction with acceleration factors of R 4 and R = 8, and a fully sampled 24 \u00d7 24 calibration region. We add additional noise to the k-space data to simulate different SNR levels. This is appropriate because the data were pre-whitened."}, {"title": "Evaluation Metrics", "content": "Reconstructions are compared with the native SNR fully sampled images and a mask is applied to the comparison images to only compare regions of the image containing anatomy. For quantitative assessment, we use (1) normalized root mean squared error (NRMSE) computed on the complex-valued images, (2) structural similarity index measure (SSIM), and (3) peak signal-to-noise ratio (PSNR). We emphasize that this evaluation is inherently biased, as native SNR images are inherently noisy [38]; nonetheless, it provides a good proxy for reconstruction quality at lower SNR levels."}, {"title": "Experiments", "content": "We present a comprehensive evaluation of our proposed approach across different anatomies, noise levels, reconstruction techniques, and acceleration factors. We compare the reconstruction quality, denoising efficacy, and the impact of training on noisy versus GSURE-denoised data, providing quantitative and qualitative insights. We divide our experiments into three main categories:\n\nSelf-Supervised Denoising with GSURE: We assess the effectiveness of GSURE denoising applied to pre-whitened and normalized noisy measurements. Independent denoisers were trained for both brain and knee datasets and for each SNR level: 32 dB, 22 dB, and 12 dB for brain data, and 24 dB, 14 dB, and 4 dB for knee data. After training, the denoisers were applied to the adjoint of the k-space data $x_{adj}$ to generate MMSE-denoised estimates $\\hat{x}_{MMSE}$.\n\nUnconditional Sampling with EDM: We examine the performance of EDM-based priors trained on noisy vs GSURE-denoised data by conducting qualitative evaluation of the generated scans across each anatomy and SNR level.\n\nAccelerated MRI Reconstruction: We evaluate the performance of our approach on undersampled and noisy k-space data using various reconstruction techniques. These experiments were designed to assess how well the models manage undersampling across different SNR levels. These experimentes are further divided for a comprehensive exploration of reconstruction quality and efficiency: (1) MRI reconstruction with DPS, (2) Knee pathology reconstruction with DPS, (3) MRI reconstruction speed with DPS, and (4) MRI reconstruction with MoDL. We also conducted statistical tests for experiments (1) and (4), to test whether there is a significant difference in the reconstruction performance of deep learning models trained on GSURE-denoised vs noisy data. We applied the non-parametric Wilcoxon signed-rank test"}, {"title": "Implementation Details", "content": "For GSURE training, we employed a UNet-style architecture [70] for both anatomies, comprising approximately 65 million trainable parameters. The Adam optimizer was used for all experiments, with fixed learning rates (\u03bb) tailored to the SNR levels of each dataset. Specifically, for brain data, we set x = 1 \u00d7 10\u20134 across all SNR levels, while for knee data, \u5165 was set to 5 \u00d7 10-7 for 24 dB and 4 dB SNR, and 5 \u00d7 10-6 for the 14 dB SNR level. The Monte Carlo divergence estimation $\\epsilon$ was set to 0.001 to balance computation accuracy and efficiency. All models were trained for 200 iterations.\n\nFor DPM training, we followed the EDM loss formulation [26]. The noise distribution was defined using $\\sigma_{min}$ = 0.002 and $\\sigma_{max}$ = 80, with the learning rate dynamically adjusted according to the noise schedule and training step, as outlined in [26]. Each DPM model was trained over 3,000 iterations, using the same UNet-style architecture as the GSURE training, with 65 million parameters. Pre-processing and architectural configurations were consistent between GSURE and DPM experiments. Batch sizes were set according to GPU availability, with 15 for brain experiments and 12 for knee experiments on A100 GPUs, and 8 for brain and 6 for knee experiments on A40 GPUs. For DPS inference, a 500-step linear noise schedule was employed, with $\\sigma_{min}$ = 0.004 and $\\sigma_{max}$ = 10, utilizing the Euler solver. The same network architecture as the GSURE and EDM models was used during inference, with hyperparameters fixed across all anatomies and SNR levels. MoDL models were trained using a lighter UNet architecture containing approximately 1.9 million trainable parameters. The number of unrolls was set to 6 iterations per forward pass. Training was conducted over 10 epochs with a batch size of 1, using a learning rate of X = 0.0003. The model's input and output channels were designed to process the real and imaginary components of the MRI data, ensuring compatibility with the pre-processing steps in other experiments."}, {"title": "Results", "content": "Self-Supervised Denoising with GSURE\n\nWe report error metrics for denoising experiments averaged across 100 validation examples in Supporting Table S1. Denoising performance degrades with decreasing SNR, with higher error values observed at lower SNRs. Supporting Figure S1 provides examples of the denoising experiments (xadj and $x_{MMSE}$) across varying SNRs. While noise reduction is evident, signal distortion becomes more pronounced as the SNR decreases, indicating a trade-off between noise removal and signal fidelity.\n\nUnconditional Sampling with EDM\n\nFigures 2 and 3 show prior samples from GSURE-EDM and Naive-EDM across each anatomy and SNR level. GSURE-EDM models consistently produce higher quality priors than Naive-EDM models. As SNR decreases, GSURE-EDM models offer qualitatively more accurate and realistic approximations of the fully sampled native SNR data, while Naive-EDM models retain noise.\n\nAccelerated MRI Reconstruction\n\nError metrics averaged across 100 validation examples for each anatomy are reported under Tables 1 and 2. Below, we describe the key experiments:"}, {"title": "MRI Reconstruction with DPS", "content": "We compare the performance of Naive-DPS and GSURE-DPS and report error metrics across various inference conditions, averaging the results over five random seeds. Figures 4 and 5 display reconstructions and the difference images. At lower SNRS, GSURE-DPS consistently outperforms Naive-DPS both quantitatively and qualitatively. However, at the native SNR, both methods show comparable performance. The box plots in Figures S2 and S3 further illustrate the performance distributions across validation data, with GSURE-DPS consistently outperforming Naive-DPS at lower SNRs."}, {"title": "Knee Pathology Reconstruction with DPS", "content": "We select a knee sample with visible pathology (meniscus tear) and average the results over five random seeds to ensure robustness and reduced variability. We evaluate inference SNR levels ranging from 24 dB to 10 dB, with models trained at a fixed SNR of 14 dB. Figure 6 shows reconstruction examples along with variance maps (across the five seeds) at 100\u00d7 brightness. GSURE-DPS exhibits stable reconstruction quality as inference SNR decreases, showing lower variation across seeds. GSURE-DPS outperforms Naive-DPS at lower inference SNRs as illustrated in Figure 7."}, {"title": "MRI Reconstruction Speed with DPS", "content": "We evaluate reconstruction speed by measuring the number of posterior averages required to reach a target NRMSE. The error metrics were averaged across 100 validation examples (Figure 8). GSURE-DPS consistently required fewer averages to achieve the target NRMSE. For example, for the knee 24 dB SNR dataset, GSURE-DPS achieved NRMSE \u2248 0.167 after two averages, while Naive-DPS required five seeds."}, {"title": "MRI Reconstruction with MoDL", "content": "We evaluate reconstructions across various SNRS and report error metrics averaged over 100 examples. Figures S4 and S5 show the box plot distributions of the NRMSE. GSURE-MODL outperforms Naive-MoDL in low-SNR scenarios, while showing comparable performance at high inference SNRs. In high inference SNR and extremely low training SNR cases (out-of-distribution), Naive-MoDL performs slightly better."}, {"title": "Discussion", "content": "Our study aimed to assess whether denoising of training data could enhance deep learning-based MRI reconstruction quality for noisy, undersampled multi-coil MRI scans across two distinct reconstruction approaches: (1) generative modeling (represented by DPS), and (2) end-to-end supervised learning (represented by MoDL).\n\nOur experiments showed that denoising can enhance reconstruction quality across various SNR levels and anatomies. Notably, in DPS experiments, models trained on GSURE-denoised data at a fixed SNR consistently outperformed Naive-DPS models. An observation from Tables 1 and 2 is that occasionally GSURE-DPS trained at low SNRs (12 dB for brain and 4 dB for knee), compared to models trained at higher SNRs, often yield better reconstruction performance across all inference SNRs, suggesting that models trained on GSURE-denoised data demonstrated better robustness and generalization to challenging inference conditions. These findings are consistent with recent works [30, 36], which similarly observed that models trained on corrupted data (after addressing the corruption) occasionally outperform models trained on native SNR fully sampled data.\n\nIn addition to improving quantitative metrics, our proposed pipeline demonstrated qualitative robustness, particularly in the knee pathology experiment. GSURE-DPS reconstructions exhibited more graceful degradation at lower inference SNR levels compared to Naive-DPS. This suggests that GSURE-DPS can not only improve accuracy, but also reduce uncertainty in reconstruction outputs.\n\nIn the MoDL experiments, we observed that GSURE-MoDL outperformed Naive-MoDL in most scenarios, particularly at low SNR levels. However, an important observation was that in out-of-distribution cases (low training SNR and high inference SNR), Naive-MoDL performed better. However, GSURE-MODL delivered superior or comparable in-distribution performance.\n\nAnother interesting observation was the difference in performance between brain and knee anatomies at similar SNR levels. For instance, denoising and posterior evaluation metrics for knee scans at 14 dB consistently displayed worse error metrics compared to brain scans at 12 dB. We hypothesize that this may stem from our SNR definition based on maximal signal intensity in the image domain, which can vary due to differences in anatomical structures.\n\nDenoising is a fundamental signal processing step and there is a rich history connecting denoising to image reconstruction [71]. At their core, DPMs successively denoise a series of noisy images to arrive at a sample from a target distribution. Through Tweedie's formula [71], there is a direct connection between the MMSE denoiser and the score, which DPMs aim to learn. As a result, it"}, {"title": "Conclusion", "content": "This study"}]}