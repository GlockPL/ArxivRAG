{"title": "Generating the Traces You Need: A Conditional Generative Model for Process Mining Data", "authors": ["Riccardo Graziosi", "Massimiliano Ronzani", "Andrei Buliga", "Chiara Di Francescomarino", "Francesco Folino", "Chiara Ghidini", "Francesca Meneghello", "Luigi Pontieri"], "abstract": "In recent years, trace generation has emerged as a significant challenge within the Process Mining community. Deep Learning (DL) models have demonstrated accuracy in reproducing the features of the selected processes. However, current DL generative models are limited in their ability to adapt the learned distributions to generate data samples based on specific conditions or attributes. This limitation is particularly significant because the ability to control the type of generated data can be beneficial in various contexts, enabling a focus on specific behaviours, exploration of infrequent patterns, or simulation of alternative \"what-if\" scenarios.\nIn this work, we address this challenge by introducing a conditional model for process data generation based on a conditional variational autoencoder (CVAE). Conditional models offer control over the generation process by tuning input conditional variables, enabling more targeted and controlled data generation. Unlike other domains, CVAE for process mining faces specific challenges due to the multiperspective nature of the data and the need to adhere to control-flow rules while ensuring data variability. Specifically, we focus on generating process executions conditioned on control flow and temporal features of the trace, allowing us to produce traces for specific, identified sub-processes. The generated traces are then evaluated using common metrics for generative model assessment, along with additional metrics to evaluate the quality of the conditional generation.", "sections": [{"title": "I. INTRODUCTION", "content": "Process mining (PM) [1] is a research field that focuses on the analysis, monitoring, and improvement of business pro-cesses based on event logs. Within this field, generative models have emerged in recent years as crucial tools for generating new event trace samples that replicate process behavior [2]\u2013[9]. These models support a range of applications, including anomaly detection [7], [10], predictive monitoring [2], what-if scenario analysis [11] and conformance checking [12]. An important yet underexplored aspect of trace generation is the ability to produce traces that follow different distributions from the training data, allowing exploration of various dimensions of interest within the process. These dimensions may include exploring what-if scenarios, expanding variants of interest (especially when significant for the process analysis but nu-merically low), or exploring resource contingency plans.\nAccording [13], generative models can be categorized into two main families: Data-Driven Process Simulation (DDPS) and Deep Learning (DL). DDPS constructs explicit process models from data, esnuring that complete information about the simulation is always available. These models are beneficial for providing insights into specific subprocesses and allow to modify almost every aspect of the simulation. However, DDPS often relies on oversimplified assumptions, leading to unrealistic simulations and data generation. Moreover, they struggle to capture long-term dependencies. DL models are statistical models that accurately capture the correlations be-tween features in the generated samples. Despite their accu-racy, DL models are \"black box\u201d systems, making it chal-lenging to transparently expose the underlying process model. More importantly, existing DL-based generative models are rigid, limiting the generation of distributions different from the training data. This constraint significantly inhibits the exploration of specific scenarios or dimensions of interest. Hybrid models, which integrate the accuracy of DL techniques with the transparency of explicit process models, have been re-cently introduced [14], [15]. While they may have potential to"}, {"title": "II. BACKGROUND", "content": "In this section we introduce the main concepts useful to understand the remainder of the paper.\nAn event log L records the executions of a business process in terms of execution traces. A trace x consists of a sequence of ordered events $x = (e_1, e_2, ... e_n)$. Events are characterized by multiple attributes (data attributes): primarily, an event refers to an activity label and a timestamp indicating when the activity was executed. It may also include information about the resource executing or initiating the activity, and other data attributes. Some attributes are static and consistent throughout the trace's execution, known as trace attributes. Data associated with events and traces in event logs are also called data payloads. We can represent a trace x as:\n$x = ((a_1, \\tau_1, d_1),..., (a_n, \\tau_n, d_n))$                                                    (1)\nwhere $a_i$ is the i-th activity executed in the trace, $\\tau_i$ is its timestamp, and $d_i$ is a vector containing its data payload, including static trace attributes."}, {"title": "B. Conditional Variational Autoencoders (CVAEs)", "content": "Autoencoders are neural network architectures used for unsupervised learning tasks [18]. They consist of an encoder, E, and a decoder, De, representing non-linear transforma-tions parametric to 0 and $\\phi$, respectively. The encoder maps the input data x into a latent representation $z = E(x)$, while the decoder output $\\hat{x} = D_e(z)$ should reconstruct the original input from the latent representation. Mathematically, an autoencoder aims to minimize the reconstruction error between the input and the output:\n$L_{AE}(x, \\theta, \\phi) = J_{rec}(x, \\hat{x}).$                                                      (2)\nwhere $J_{rec}$ denotes some kind of distance/error function over the data space (e.g., $||x - \\hat{x}||^2$ in the case $x, \\hat{x} \\in \\mathbb{R}^N$).\nVariational autoencoders (VAEs) [19] lift this basic autoen-coder architecture to the level of a generative model where x and z are interpreted as observed and latent random variables, respectively, such that the joint distribution of x and z is factored as $p_\\theta(x|z) \\cdot p(z)$, where $p_\\theta(x|z)$ is a distribution to be learned, and the latent prior p(z) is typically set to a standard multivariate Gaussian distribution (i.e., $p(z) = \\mathcal{N}(\\tilde{0}, I)$, where I is an identity matrix).\nVAEs are trained to minimize the (expectation over the real data distribution of the) following negative Evidence Lower Bound (ELBO) $L_{vae}$, consisting of a reconstruction loss term (echoing that in Eq. (2)) plus a regularization term, which is computed as the Kullback-Leibler (KL) divergence between a learned latent distribution $q_\\phi(z|x)$ and the latent prior p(z), with a factor $\\beta$ controlling the strength of the regularization:\n$L_{vae}(x, \\theta, \\phi) = J_{vae}(x, \\theta, \\phi) + \\beta \\cdot KL(q_\\phi(z|x) || p(z))$                                                          (3)\nwhere $\\phi$ and $\\theta$ denote the parameters of the encoder and decoder sub-nets, now modelling the learned distributions $q(z|x)$ and $p_\\theta(x|z)$, respectively, while the reconstruction term is $J_{vae}(x, \\theta, \\phi) = -E_{z \\sim q_\\phi(z|x)} ln p_\\theta(x|z)$.\nConditional variational autoencoders (CVAEs) incorporate conditional information into both the encoder and the decoder. In CVAEs, both the encoder and the decoder take the input data x and conditioning variables c as inputs [16]. The conditional variable c represents the specific condition or attribute that"}, {"title": "III. RELATED WORK", "content": "Generative DL models have been extensively studied in recent years in the PM field. The primary idea behind most of these models, in the context of predictive process monitoring, is to generate a trace by iteratively predicting the next activity for a prefix. For instance, [2] introduces an LSTM-based method [20] that generates the remaining sequence of events with associated timestamps, given a trace prefix. This approach uses one-hot encoding to represent activities, which struggles with high-dimensional inputs, i.e., processes with a large number of activities.\nIn [3], an LSTM neural network is used to generate event sequences, addressing the dimensionality issues with embed-dings for activities. However, this method does not handle numerical features and thus cannot generate event timestamps. Other approaches for activity sequence generation include an LSTM-based method in [4], n-grams encoding with neural networks in [5], and Markov models, RNN, and automata-based models in [6]. Despite their variety, these methods share a common limitation: they do not generate timestamps.\nIn [7] and [10], generative methods based on GRU neural networks and variational auto-encoders respectively, have been applied for anomaly detection.\nIn [8], the authors combine elements from prior work to build an accurate LSTM-based generative model that generates events with timestamps and associated roles, and can pro-duce traces from scratch using an \u201challucination\u201d mechanism. To ensure sufficient variability in the generated traces, the selection of the next events is performed using a random sampling method based on the predicted probability distribu-tion outputted by the model. While this method increases the variability of the generated traces, it may occasionally produce traces inconsistent with the global process distribution. In [9], an LSTM model for predicting the next event and its timestamp, is trained adopting a generative adversarial network (GAN) approach."}, {"title": "IV. APPROACH", "content": "In this section we present a conditional variational autoen-coder (CVAE) architecture for the generation of traces. In this work, we consider the generation of traces with only activities $a_i$, timestamps $\\tau_i$, and static traces attributes, which can be numerical $d_{num}$ and categorical $d_{cat}$. The trace (1) can then be rewritten as $x = {(d_{num}, d_{cat}), ((a_1, \\tau_1), ..., (a_n, \\tau_n))}$.\nIn order to be able to apply the CVAE to business processes, we had to adapt it by employing encoder and decoder architec-tures suitable for handling both sequential data (control flow and timestamps) and non-sequential data (trace attributes). The model is depicted in Figure 1.\nIn particular, for sequential data, we drew inspiration from seq2seq models, which are commonly used in NLP, where an encoder model maps a variable-length input sequence to a fixed size vector, which is then \u201cunrolled\u201d back to a variable-length sequence by a decoder model [23].\nThe following sections explain the preprocessing steps, the encoder and decoder architectures, the training approach, and the generation process of new traces."}, {"title": "A. Preprocessing", "content": "In the preprocessing phase a trace x is properly manipulated to be feed to the encoder. Each event's timestamp $\\tau_i$ is decomposed into two parts: (i) the trace arrival time $\\tau_1$, which corresponds to the timestamp of the first event in the trace, and is handled by the model in the same way as a numerical trace attribute; and (ii) the event interarrival time $t_i := \\tau_i - \\tau_{i-1}$. The event interarrival time is normalized using the 95th percentile value instead of the maximum value. While this causes some values to be outside the [0, 1] range, we found it useful in practice in order to ignore outlier timestamps, i.e. very high interarrival time, that could cause the normalization to squash event interarrival times to an exceedingly narrow range close to zero. Numerical trace attributes are preprocessed by normalizing them to the [0,1] interval using min-max normalization."}, {"title": "B. Encoder", "content": "The goal of the encoder is to map any trace x and condi-tioning variable c to the mean vector $\\mu_c$ and variance vector $\\sigma_\\alpha$, that fully specify the multivariate Gaussian distribution $q(z|x, c) = \\mathcal{N}(\\mu_{r.c}, diag(\\sigma_{x,c}))$, with a diagonal covariance matrix, for the latent variables z (the subscripts in $\\mu_{x,c}$ and $\\sigma_\\alpha$, will be omitted whenever the dependency of these parameters on x and c is clear from the context). Firstly, in the encoder each categorical variable (activities and categor-ical attributes) is passed through its own embedding layer and transformed into a numerical vector. Then, the encoder consists of two paths: the first makes use of an LSTM layer to handle activities and timestamps, the second employs a fully connected layer for each trace attribute. Thereafter, outputs of the two paths are concatened together, the conditional variable is added, and lastly two fully connected layers are used to map to mean $\\mu$ and variance $\\sigma$ vectors."}, {"title": "C. Decoder", "content": "After sampling a latent space vector z from the Gaussian distribution $\\mathcal{N}(\\mu_{x,c}, diag(\\delta_{x,c}))$ identified by the encoder, the goal of the decoder is to generate a trace from z that is as similar as possible (modulo a certain level of variability) to the original trace x.\nFirst of all, since we are in a conditional setting, the conditional variable c is concatenated to z. Then, a fully connected layer upsamples z to a higher dimension vector $z_u$. This approach, even though it has been criticized in previous NLP works [24], has proven effective in our case to improve decoder performances. Activities and timestamps are obtained from $z_u$ using two different autoregressive LSTMs. At each time step i, the activity LSTM takes as input both $z_u$ and the previously reconstructed activity $a_{i-1}$ (for the first time step, a special End Of Trace (EOT) token is used) and outputs the current activity $\\hat{a_i}$. The timestamp LSTM takes as input, in addition to $z_u$ and the previous event interarrival time $t_{i-1}$, also the current reconstructed activity $\\hat{a_i}$, and outputs the current event interarrival time $\\hat{t_i}$.\nDifferent configurations has been tested, namely (i) not using the latent space as input for each time step, (ii) not con-ditioning the timestamp LSTM to the current activity $\\hat{a_i}$ and (iii) using a shared LSTM for both activities and timestamps. However, the first configuration yielded poor reconstructed control flows, whereas the second and third configurations resulted in poor timestamp reconstruction.\nCategorical and numerical attributes reconstruction follows different paths, one for each attribute, composed of a sequence of two fully connected layers and ReLU activations. For both activity and categorical attributes predictions, the model outputs a probability distribution for each possible value and the argmax operator is used to select the most likely one."}, {"title": "D. Training", "content": "We train the model end-to-end with backpropagation, opti-mizing the CVAE loss function (4). In particular, the recon-struction loss of a reconstructed trace $\\hat{x} \\sim p_\\theta(x|z, c)$ with respect to its ground-truth trace x is the sum of the following loss components:\n\u2022 Binary Cross Entropy (BCE) loss of each trace activity\n\u2022 Mean Squared Error (MSE) loss of each event interarrival time\n\u2022 BCE loss of each categorical attribute of the trace\n\u2022 MSE loss of each numerical attribute of the trace\nTo prevent vanishing of the KL divergence loss we make use of a technique called KL cyclical annealing, which varies $\\beta$ following a linear cyclical schedule as training progresses [25]. When $\\beta < 1$, the model is able to focus more on improving reconstruction. In our tests without cyclical annealing, the KL divergence loss decreased to nearly zero whereas the reconstruction loss did not improve much."}, {"title": "E. Generation", "content": "After the model has been trained, new traces can be gener-ated by randomly sampling a latent space vector z from the multivariate standard Gaussian distribution $\\mathcal{N}(\\tilde{0}, I)$, attaching a conditional variable to it and feeding the resulting vector to the decoder network. The conditional variable makes it possible to limit the generation of traces to the specified variable only.\nThe decoder activity LSTM recurrently generates activities for the trace until the EOT token gets generated or until a fixed"}, {"title": "V. EVALUATION", "content": "In this section, we present the evaluation methodology used to assess the outcomes of conditional generative models for trace generation. We compare our method (denoted as cvae) with the DL generative model from [8]. We aim to address the following research questions:\nRQ1 Quality of Generated Traces: How is the quality of the generated traces, in terms of temporal and control-flow dimensions, compared to other state-of-the-art generative models?\nRQ2 Variability vs. Compliance: What is the trade-off be-tween the variability of the generated traces and their compliance with the original process, compared to other state-of-the-art generative models?\nRQ3 Effectiveness of Conditional Control: How effective is the control provided by the conditional variable in guiding the generative model to produce specific types of traces?\nRQ1 aims to investigate the overall quality of the generation, focusing on three main aspects: the control-flow, the temporal distribution of events and the distribution of trace cycle times. RQ2 aims at assessing the capability of the model to produce original traces different from the one of the training set, while keeping them meaningful with respect to process constraints. Finally, RQ3 aims at analysing the effectiveness of the model's conditional mechanism and its ability to correctly reproduce the various types of traces defined by the conditional variable."}, {"title": "A. Datasets", "content": "Our evaluation considers four examples based on three real-world event logs, preprocessed to remove incomplete traces. For each example, we define a binary conditioning"}, {"title": "B. Methodology", "content": "Each dataset is obtained by adding a trace attribute to every trace, containing the value of the conditional labelling, as defined in the previous section. Each dataset is then split in training, validation and test set in chronological order. Our model is trained using the following hyperparameters: Embedding size (categorical attributes and activities) = 5, LSTM hidden size = 200, Latent space size = 10, Learning rate = 3 \u00d7 10-4, Dropout = 5%, Batch size = 256, Number of KL annealing cycles = 8.\nDuring training, the validation set is used to activate an early stopping mechanism, which stops the training when the loss function, computed on the validation set, does not improve for 100 epochs, and outputs the model with the best loss. This only applies when evaluating the full loss function (\u03b2 = 1, i.e., KL annealing cycles are excluded by early stopping)."}, {"title": "C. Metrics", "content": "We present the framework for the evaluation of the gen-erative model. To assess the quality of the generated traces, we adopt a subset of the metrics introduced in [17] within the domain of simulation models. These metrics quantify the \"dissimilarity\" between the generated traces and those in the test set by computing the Earth Mover's Distance (EMD) of their respective distributions along different temporal and control flow dimensions:\n\u2022 Event time distribution within the trace, in the case of metric Relative Event Distribution (RED);\n\u2022 Cycle times, in the case of metric Cycle Time Distribution (CTD);\n\u2022 Event class N-grams, in the case of metric N-Gram Distance (NGD), which we specifically computed by setting N = 2 (2GD), using the directly-follow graphs of the generated and test traces.\nInspired by the work in couterfactual generation in PM [29], we consider a further metrics measuring the compliance of the generated traces with the process implicit constraints:\n\u2022 Conformance score (CONF) measures the average num-ber of DECLARE constraints [30] satisfied by the gener-ated traces. The DECLARE constraints are mined from the event log with a support of 90%.\nTo quantify the variability of the generated traces we focus on the control-flow and compute the number of new variants generated with respect to those in the training and test log. Finally, to assess the conditional generation we compute the actual conditional ratio of the generated traces. To do so we recompute a-posteriori the conditional labelling, as defined in Sect. V-A, and compare the conditional rate with the ones of the training and test log."}, {"title": "D. Benchmarks", "content": "As mentioned at the beginning of this section we compare our method with the LSTM model introduced in [8], which has been identified as the state-of-the-art deep generative model for PM in [13]. Since this method is not aware of the conditional variable, we leverage it in the following two ways:\n\u2022 we train it on the full training set and use it to uncondi-tionally generate traces. We denote this method as lstm1;\n\u2022 we train two separate models on the two subsets of the training data identified by the value of the binary conditional variable. We then generate traces using both models to reproduce the conditional ratio of the training set. We denote this method as lstm2.\nTo provide an additional point of comparison, we also consider the original log itself as a baseline reference for the metrics RED, CTD, and 2GD. To achieve this, we split the"}, {"title": "VI. RESULTS", "content": "In this section, we present the obtained results. We start by showcasing an example of conditional generation with cvae in Table II, where we list the control-flow of two pairs of traces generated for the experiment Traffic_Fines. Each pair of traces is generated by the same value of the latent variable z but with different values of the conditional variable c. These two examples can be interpreted as \u201cwhat-if\u201d scenarios. When c = F, in both cases the fine is paid by the offender within a short time. When c = T, the offender appeals in the two traces to the Judge and to the Prefecture, respectively. This causes delays, and, as a consequence, a penalty is added six months after from the issuance of the fine, and this is known to be a process constraint [31] when answering RQ3 we will show that the robustness under process constraints is not an accident of this example, but is a general feature of our model. The first example ends with the Payment activity, indicating that the appeal has been denied. In contrast, the second example shows that the appeal to the prefecture has been accepted, and no payment is due.\nWe start the analysis of the results by answering RQ1. In Figure 2 we plot the values of the temporal (RED, CTD) and control-flow (2GD) metrics computed for each of the four experiments described in Section V-A. We can observe that cvae consistently outperforms the competing Istm models in all three metrics: relative event distribution (RED), trace cycle time (CTD) and 2-grams (2GD). It is also worth noting that the cvae boxplots often overlap with the train_log ones, indicating that it correctly reproduces the distributions of the training set for these three metrics. In summary, the quality of the traces generated by the cvae appears to be much higher than those of the Istm models on both the control-flow and temporal aspects. Finally, we observe that across different logs and metrics, the boxplots of all three generative models are significantly narrower than the ones of the baseline. Compared to a pure data sampling approach (as in the baseline), these models appear more stable in producing representative trace samples. However, all three methods likely fail to capture the full variability of the original logs.\nTo address RQ2, we report in Table III the average number of variants generated by the models that already appear in the training or test sets. We observe that, compared to the Istm1 and Istm2 models, which almost always generate new variants, depending on the dataset, from 15% to 77% (from 1% to 42%) of the variants generated by the cvae model already appear in the training log (test log). Looking at the CONF values"}, {"title": "VII. CONCLUSIONS", "content": "In this paper, we introduced a conditional variational auto encoder for trace generation. We showed that our method outperforms current state-of-the-art generative models for trace generation in terms of the quality of the traces' control-flow, cycle time and event temporal distribution, as well as of their compliance with process implicit constraints. Moreover, we showed that it is possible to robustly control the generation process by setting the conditional variable, so as to generate only the traces of interest or to simulate \"what-if\" scenarios. In the future, we plan to extend the log generation by also taking into account resources and to improve the reproduction of the traces temporal distribution."}]}