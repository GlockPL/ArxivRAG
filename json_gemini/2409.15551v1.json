{"title": "Revise, Reason, and Recognize: LLM-Based Emotion Recognition via Emotion-Specific Prompts and ASR Error Correction", "authors": ["Yuanchao Li", "Yuan Gong", "Chao-Han Huck Yang", "Peter Bell", "Catherine Lai"], "abstract": "Abstract-Annotating and recognizing speech emotion using prompt engineering has recently emerged with the advancement of Large Language Models (LLMs), yet its efficacy and reliability remain questionable. In this paper, we conduct a systematic study on this topic, beginning with the proposal of novel prompts that incorporate emotion-specific knowledge from acoustics, linguistics, and psychology. Subsequently, we examine the effectiveness of LLM-based prompting on Automatic Speech Recognition (ASR) transcription, contrasting it with ground-truth transcription. Furthermore, we propose a REVISE-REASON-RECOGNIZE prompting pipeline for robust LLM-based emotion recognition from spoken language with ASR errors. Additionally, experiments on context-aware learning, in-context learning, and instruction tuning are performed to examine the usefulness of LLM training schemes in this direction. Finally, we investigate the sensitivity of LLMs to minor prompt variations. Experimental results demonstrate the efficacy of the emotion-specific prompts, ASR error correction, and LLM training schemes for LLM-based emotion recognition. Our study aims to refine the use of LLMs in emotion recognition and related domains.", "sections": [{"title": "I. INTRODUCTION", "content": "Recent studies have suggested that Large Language Models (LLMs) have the ability to reason about emotional content [1]. This finding has encouraged researchers to further explore the \"emotional intelligence\" (e.g., emotion recognition, interpretation, and understanding) of LLMs. For example, [2] developed a psychometric assessment focusing on emotion understanding to compare the emotional intelligence of LLMs and humans. They found that most LLMs achieved above-average Emotional Quotient (EQ) scores, with GPT-4 surpassing 89% of human participants with an EQ of 117.\nTherefore, the use of LLMs in text-based emotion recognition has emerged as a resource-efficient and effort-saving alternative to human annotators and traditional emotion classifiers for two main reasons: 1) Emotion recognition requires substantial human effort. Typically, multiple annotators are needed for each sample to reach a majority vote, ensuring accurate assessment. Although platforms like Amazon Mechanical Turk provide a relatively efficient solution, concerns persist regarding privacy leaks, subjective bias, and the reliability of annotations [3]. 2) Despite the advancements of state-of-the-art deep learning technologies, training an emotion classifier involves multiple steps, including feature extraction and model building, which require careful consideration of which features, models, and algorithms to use.\nTo this end, researchers have recently started exploring and utilizing LLMs for emotion annotation and recognition. Their work includes various approaches, such as using multiple-step prompting with LLMs [4], examining prompt sensitivity [5], integrating outputs from multiple LLMs [3], and incorporating acoustic information [6]. Despite these efforts, understanding of the usage, efficacy, and reliability of LLM-based approaches remains limited, especially on Automatic Speech Recognition (ASR) transcription. Therefore, building upon existing literature, we conduct various experiments on LLM-based emotion recognition to investigate effective prompting practices. Our major contributions are:\n\u2022 We propose novel prompts for LLM-based emotion recognition, integrating emotion-specific knowledge from acoustics, linguistics, and psychology.\n\u2022 We propose the REVISE-REASON-RECOGNIZE (R3) prompt for emotion recognition on imperfect text, addressing the limitations of prior methods on ground-truth text.\n\u2022 We experiment on LLM training schemes, evaluating the efficacy of context-aware learning, in-context learning, and instruction tuning for LLM-based emotion recognition, and investigate the sensitivity of LLMs to minor prompt variations."}, {"title": "II. RELATED WORK", "content": "Interest in LLM-based emotion recognition has surged recently, with the availability of pre-trained models. Studies in this area have explored a variety of approaches. [7] inferred emotion labels using three different prompting approaches: text generation, mask filling, and textual entailment, employing a fine-grained emotion taxonomy. [3] proposed an ensemble approach that integrates outputs from multiple LLMs, leveraging a Mixture of Experts (MoE) reasoning model. They trained emotion classifiers using MoE-generated emotion labels from both ground-truth and ASR transcriptions, and tested these classifiers on ground-truth labels, demonstrating comparable performance in emotion classification. [4] employed a multi-step prompting technique with few training samples for text emotion recognition. [6] and [8] incorporated textual acoustic feature descriptors into prompts. [9] investigated several approaches,including in-context learning, few-shot learning, accuracy, generalization, and explanation. [5] examined various prompting techniques, including chain-of-thought, role-play, and their variations.\nDespite these advancements, we argue that each approach has its limitations, leaving several concerns unaddressed. For example, [9] did not study prompting, [4] only proposed a multi-step prompting without further exploration. The prompting techniques tested by [5] were not specifically designed for emotion. [6] and [8] only considered basic acoustic features, without incorporating more emotion-related properties. Furthermore, both [3] and [7] used ASR transcriptions generated by Whisper, whose output has been shown to be robust in emotion recognition even with ASR errors [10]. However, this setting is not ideal for LLMs handling challenging ASR transcriptions in real-world emotion applications."}, {"title": "III. METHODOLOGY", "content": "To address the issues above, we 1) Develop prompts that incorporate emotion-specific knowledge; 2) Incorporate ASR Error Correction (AEC) to refine transcriptions for robust emotion recognition; and 3) Explore LLM training schemes to further improve the performance.\nA. Prompting with Emotion-Specific Knowledge\nIn light of the relationship between emotion and relevant disciplines, we extract useful knowledge from acoustics, linguistics, and psychology, to develop emotion-specific prompts for emotion recognition. Acoustic information plays a crucial role in distinguishing speech emotions. Features like energy, pitch, and speaking rate have proven useful when been incorporated into prompts as textual descriptors [6]. Similarly, gender information, which is highly correlated with pitch, has also been shown to be useful [8], [11]. However, these features are insufficient to fully describe fine-grained differences in emotions beyond the Big Four: angry, happy, neutral, and sad. Hence, we hypothesize that additional acoustic features can enhance LLMs' emotion recognition ability. We propose including pitch range, jitter, and shimmer to incorporate mid-level prosody (between frame-level and utterance-level) and voice quality.\nLinguistic structure is essential for understanding emotion in text. For example, [12] investigated the impact of part-of-speech, affective score, and utterance length on emotion. However, to our knowledge, only one work [13] has utilized linguistics via identifying emotion triggers (i.e., words that elicit the emotion) when prompting LLMs for emotion prediction. Thus, we hypothesize that LLM-based emotion recognition can benefit from more linguistic knowledge as LLM processing is inherently text-based. We propose including ASR-emotion relationships among emotion category, Word Error Rate (WER), and utterance length as outlined in [12].\nPsychological theories, such as self-monitoring, social cognitive theory, and cognitive emotion regulation have proven effective in improved LLMs' performance across various tasks [14], [15]. Therefore, we hypothesize that LLMs'emotion recognition ability can resonate with their emotional intelligence and thus be enhanced. We propose incorporating positive and negative stimuli from [14], [15], as well as create our novel competitive stimuli.\nB. Emotion Recognition with ASR Error Correction\nTraditional emotion recognition often struggles with imperfect text [10]. We argue that it is more challenging to prompt LLMs for emotion recognition on ASR transcription compared to human transcription, due to the presence of word errors. Therefore, we propose the R3 prompting pipeline to perform emotion recognition with AEC and reasoning on ASR transcriptions. The R3 pipeline involves three steps: Revise, where ASR errors are corrected based on N-best hypotheses; Reason, where the LLMs self-explain based on the corrected transcriptions and emotion-specific knowledge; and Recognize, where the emotion is recognized. To incorporate AEC into our prompts, we follow an AEC-specific Alpaca prompt [16], which uses the \u201cYou are an ASR error corrector\u201d instruction, guiding the LLMs to perform error correction. As LLMs have proven their ability in both AEC and emotion recognition [17], this format is expected to facilitate seamless integration with our emotion prompting, instructing the LLMs to function simultaneously as both an ASR error corrector and an emotion recognizer.\nC. Exploring LLM Training Schemes\nTo understand how LLM training schemes contribute to emotion recognition, we explore context-aware learning, in-context learning, and instruction tuning. For context-aware learning, we organize the sentences in the conversation order and compare different context windows (i.e., the number of sentences preceding the sentence to be recognized). For in-context learning, we test and compare several few-shot cases."}, {"title": "IV. EXPERIMENTS", "content": "A. Datasets and Models\nFor the datasets, we use IEMOCAP [19] and the Test1 set of MSP-Podcast [20]. We combine excited with happy and use the Big Four classes for IEMOCAP. For the ASR models, we adopt ten popular ones from [10] to generate diverse transcripts to form 10-best ASR hypotheses. For the LLMS, we utilize Llama-2 (7b-chat-hf & 13b-chat-hf) and Falcon (7b-instruct). Temperature and max token are set as 1e-4 and 100. Due to limited space, we mainly present the results on IEMOCAP using Llama-2 and omit the full prompting message, presenting only the core text following the literature in Sec. II. Results of using the other model and dataset are presented in necessary experiments.\nB. Results and Discussions\nWe present the results and discussions based on the following exploration tasks. We replace responses that fall outside the emotion classes with neutral. Unweighted Accuracy (UA) is used to measure the results.\n1. Do WERs have an impact on LLM prompting?\nIn this task, we use the baseline no reasoning prompt: Predict the emotion from {the emotion classes}. Do not show your explanation. From Table I, we see that WERS do impact LLM prompting. Even the best-performing ASR transcription (i.e., from Whisper large) shows more than a 4% loss compared to ground-truth text. This finding contradicts a previous claim that LLM-based emotion recognition is robust to ASR errors [3]. We believe this discrepancy arises from their (i) use of Whisper large, which provides relatively accurate transcriptions, and (ii) introduction of a fifth emotion class, 'other', to filter out unconfident labels. However, our setup is more inline with real-world scenarios where emotion recognition is more challenging due to various speaking styles and unconfident labels cannot be filtered. Furthermore, LLM-based performance remains relatively stable within certain WER ranges. The accuracy decrease does not linearly correlate with the WER increase, as seen in traditional deep learning model-based emotion recognition [12]. Finally, LLMs benefit from more parameters as the 13b model consistently outperforms the 7b model.\n2. Does emotion-specific knowledge help?\nIn this task, we use each of the emotion-specific prompts and their combinations for emotion recognition and compare their effectiveness on both ground-truth and ASR transcriptions. For brevity, we use one ASR transcription, whose WER ranked in the middle, as the representative (i.e., HuBERT large). Results are presented in Table. II.\nWe can see that: 1) All emotion-specific prompts improve the performance, demonstrating the efficacy of our proposed approach by incorporating emotion-specific knowledge. However, the improvement is less pronounced on ASR transcription, highlighting the necessity for AEC. 2) Our proposed paralinguistic information improves on [6], verifying our hypothesis that additional paralinguistic features are beneficial. Furthermore, the improvement in 8-class is more significant, confirming that these additional features help in distinguishing finer-grained emotions (see Table III). 3) Linguistic knowledge generally contributes the most, even on ASR transcription. This means that LLMs benefit from identifying emotional trigger words and understanding the ASR-emotion relationship. This ASR-emotion does apply to ground-truth text, as it is specifically developed for ASR transcription. 4) The steady improvement from psychological knowledge confirms our hypothesis that LLMs' emotion recognition ability can be affected by psychological setting. Interestingly, among the psychological prompts, stimuli with negative affect perform the best. 5) Surprisingly, the baseline reasoning prompt does not improve performance. By investigating the responses, however, we found this is likely due to the LLM hallucinations, where they often described the (acoustic) tone despite having only text input. 6) Majority voting underperforms most single prompts, aligning with the finding of [6]. Finally, identifying the best prompt combination for both ground-truth and ASR transcriptions, we see that linguistics contributes the most to the latter by having both trigger words and ASR relationships.\n3. Does the proposed R3 prompt work?\nIn this task, we use the R3 prompt: You are an ASR error corrector and emotion recognizer. Generate the most likely transcript from {the 10-best ASR hypotheses} and predict the emotion from {the emotion classes} with reasoning based on the provided knowledge. For comparison, we conduct an ablation study, removing AEC or reasoning. We use 4+5+6+8 as the emotion knowledge since it has proven the best.\nAs shown in Table IV, both AEC and reasoning contribute to the effectiveness of our R3 prompt. Moreover, when incorporating our proposed emotion-specific knowledge, reasoning improves the performance, in contrast to the decrease observed when emotion-specific knowledge was not provided (see Table II). This suggests that emotion recognition is particularly challenging for LLMs to reason without relevant information. The examples in Fig. 2 illustrate how the R3 prompt helps LLMs in reasoning with emotion-specific knowledge, regardless of whether the recognition is correct.\n4. Do LLM training schemes help?\nIn this task, we apply the R3 prompt with context-aware learning (windows of 5 and 25), in-context learning (5- and 10-shot), and instruction tuning. For instruction tuning, we perform cross-validation by applying PEFT on every four sessions, testing on the remaining session, and then averaging. We do not compare performance across these three approaches due to their different settings."}, {"title": "V. CONCLUSION", "content": "In this work, we propose emotion-specific prompts by incorporating relevant knowledge from acoustics, linguistics, and psychology. We also compare LLM-based emotion recognition on both ground-truth and ASR transcriptions, confirming the necessity of AEC. Consequently, we develop the REVISE-REASON-RECOGNIZE prompting pipeline that integrates AEC, reasoning, and emotion recognition, which proves effective. Additionally, by investigating several LLM training schemes, we confirm the value of longer context windows, more few-shot samples, and instruction tuning. Finally, we uncover the sensitivity of LLMs to minor prompt variations. This research is expected to bridge the gap between existing studies on LLMs and emotion recognition."}]}