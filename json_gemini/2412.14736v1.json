{"title": "Advances in Artificial Intelligence for Diabetes Prediction: Insights from a Systematic Literature Review", "authors": ["Pir Bakhsh Khokhar", "Carmine Gravino", "Fabio Palomba"], "abstract": "Diabetes mellitus, a prevalent metabolic disorder, has significant global health implications. The advent of machine learning (ML) has revolutionized the ability to forecast and manage diabetes early on, offering new avenues to mitigate its impact. This systematic review examines 53 articles on ML applications for predicting diabetes, focusing on datasets, algorithms, training methods, and evaluation metrics. Various datasets, such as the Singapore National Diabetic Retinopathy Screening Program, REPLACE-BG, National Health and Nutrition Examination Survey (NHANES), Pima Indians Diabetes Database (PIDD), are explored, highlighting their unique features and challenges like class imbalance. The review assesses the performance of various ML algorithms such as Convolutional Neural Networks (CNN), Support Vector Machines (SVM), Logistic Regression, and XGBoost for the prediction of diabetes outcomes from multiple data datasets. Techniques such as cross-validation, data augmentation, and feature selection are discussed in terms of their influence on the versatility and robustness of the model. Some of the evaluation techniques involve k-fold cross-validation, external validation, and performance indicators such as accuracy, Area Under Curve, sensitivity, and specificity are presented. The findings highlight the usefulness of ML in addressing the challenges of diabetes prediction, the value of sourcing for different data types, the need to make models explainable, and the need to keep models clinically relevant. The study highlights significant implications for healthcare professionals, policymakers, technology developers, patients, and researchers, advocating for interdisciplinary collaboration and ethical considerations when implementing ML-based diabetes prediction models. By consolidating existing knowledge, this SLR outlines future research directions aimed at improving diagnostic accuracy, patient care, and healthcare efficiency through advanced ML applications. This comprehensive review contributes to the ongoing efforts to utilize AI technology for better diabetes prediction, ultimately aiming to reduce the global burden of this widespread disease.", "sections": [{"title": "1. Introduction", "content": "Diabetes mellitus is a metabolic disorder characterized by elevated blood glucose levels due to either insufficient insulin production by the pancreas or improper insulin uti-\nlization by the body. Insulin, a crucial hormone secreted by\nthe pancreas, facilitates the movement of glucose from the\nblood into the cells, where it is converted into energy. It\nis also essential for the metabolism of proteins and lipids.\nWhen the body does not produce enough insulin or the cells\ndo not respond to it properly, glucose accumulates in the\nblood, leading to diabetes.\nThis condition can result in severe complications such as\nheart disease, kidney failure, and nerve damage. According\nto the International Diabetes Federation, the number of\npeople with diabetes worldwide is projected to reach 700\nmillion by 2045 1. This alarming prediction underscores\nthe urgent need for innovative methods and treatments for\ndiabetes.\nTraditional diabetes treatments focus on monitoring\nblood glucose and HbA1c levels, which are reactive ap-\nproaches that detect the disease at an advanced stage. Thus,\nthe need to develop better models for early prediction to\nimprove the quality of life of a patient cannot be overem-\nphasized. Studies have also shown the revolution that has\nbeen brought in the healthcare industry by AI, especially in\nML and DL [24]. These technologies are particularly good\nat capturing large amounts of data, as well as recognizing\npatterns and even making predictions that were inconceiv-\nable before the use of such statistical tools. Since the interest\nin applying the ML for predicting diabetes has been on the\nrise, research in this field has received a boost. The accuracy\nof developed ML models to predict diabetes relies greatly\non the ML model and type and amount of data used, such\nas Electronic Helath Recors (EHR), laboratory data, age,\ngender and other aspects of lifestyle [31]. The integration of\nContinuous Glucose Monitoring (CGM) data with EHRs has\nbeen more useful, especially in predicting health outcomes,\nthan the use of CGM data alone [51]. Also the integration of\ngenetic information and biomarkers brings more information\nabout the probability of the person to develop diabetes [25].\nTraining of the ML models for the prediction of diabetes\nincludes different procedures and optimizations. Logistic\nregression, SVM and random forest are some of the widely\nused algorithms in supervised learning because of their inter-\npretability and stability [34]. Other deep learning models, in-\ncluding CNNs and RNNs, have also been used in the analysis"}, {"title": "2. Background and Related Work", "content": "The main objective of this section is to equip us with\nbackground knowledge of the problem so that we can pro-\nceed with our research. This section is devoted to the data\nmethods, prediction models, and metrics used for diabetes\nprediction and to systematic literature reviews conducted in\nthe past regarding diabetes prediction.\n2.1. Anatomy of Diabetes Mellitus\nDiabetes mellitus (DM) is a metabolic disorder in which\nthe body is unable to regulate levels of sugar or glucose in the\nbloodstream either due to inadequate insulin secretion by the\npancreas (type 1) or due to insulin resistance (type 2). There\nare two main types of diabetes: Type 1 Diabetes Mellitus\n(T1DM) and Type 2 Diabetes Mellitus (T2DM), with Type\n2 diabetes comprising nearly 90% of all diabetes cases and\nwith a global prevalence of 537 million [17]. Diabetes is\na community health problem that has shown an alarming\nincrease in the last 20 years in many parts of the world. DM is\na multiorgan disease with numerous diabetic microvascular\ncomplications involving the retina, heart, brain, kidney, and\nnerves.\nIt can be clearly stated that the role of medical personnel\nin preventing, treating, and managing diabetes mellitus and\nits complications is well established [5]. Exercise prescrip-\ntion and education for rehabilitation management are effec-\ntive for participation and maintaining physical well-being,\nimproving situation of patient and health-related quality of\nlife [9]. Diabetes itself is not a high-mortality cause, but it\nis a significant risk for other causes of death and has a high\ndisability burden. Diabetes is also a significant risk factor\nfor cardiovascular disease, kidney disease, and blindness\n[12]. DM is categorized into three types according to their\netiology and clinical manifestation: type 1 diabetes, type 2\ndiabetes, and gestational diabetes [29].\nDiabetes Mellitus primarily involves the islets of Langer-\nhans in the pancreas, from which glucose is secreted from\nthe alpha cells and insulin from the beta cells. Glucagon\nincreases blood glucose levels, and insulin reduces them.\nT1DM (Insulin-Dependent) is a chronic metabolic disorder\nthat causes 5% to 10% of diabetes mellitus [26]. It is charac-\nterized by the autoimmune destruction of insulin-producing\nbeta cells in the islets of the pancreas, and the loss of function\nof the beta cells leads to absolute insulin deficiency. T1DM\nis most commonly seen in children and adolescents but can\naffect anyone at any age."}, {"title": "2.2. Related Work", "content": "In previous years, as evidence shows, several systematic\nliterature reviews emphasize the diagnosis of predicting type\n2 diabetes and studies concerning those predictions. Many of\nthe articles from those journals and conferences are centered\naround Machine Learning and Deep Learning techniques,\nwhich are among the most relevant topics today. They aim\nto investigate similar data sets and conclude through the data\nsets analysis that the amount of data used in those studies is\nunstable.\nThe research conducted by Bidwai, P. et al. [11] has\nsuggested a new review that aimed to eliminate the gaps left\nby current reviews and helped other researchers in selecting\nthe current results from the studies that they can use in pre-\ndicting ML-based risk of Diabetic Retinopathy progression\nand related diseases by synthesizing the current results from\nthese studies and put in place the research challenges, limita-\ntions, and gaps for the selection of efficient machine learning\ntechniques in the establishment of my model of prediction.\nFurthermore, they pointed out the six AI-related technical\ndiscussions and the approaches as these two crucial points\nfor the adopted strategy. As for the SLR, data collection was\nused to obtain suitable studies. They searched IEEE Xplore,\nPubMed, Springer Link, Google Scholar, and Science Direct\nelectronic databases for literature reviews published between\nJanuary 2017 and 30th April 2023. Thirteen (13) studies ap-\npearing from the broad discussion were subsequently short-\nlisted based on their relevance to the reviewing questions and\nthe filters applied. While the literature review exposed some\nsignificant research gaps to be considered in future research\nthat will improve the performance of Diabetic Retinopathy\n(DR) progression risk prediction models, issues like the\ncomparability and inclusion of the diverse DR populations\nwere inattentive.\nThey also discussed different approaches to the problem\nof diabetes prediction in general, and about the problem of\nselecting and integrating necessary research articles for ML-\nbased diabetic prediction models. They talked about how\nthe medical data is nonlinear, non-normal and correlation\nstructured and about how beneficial machine learning is in\nhealthcare especially in the medical imaging. While their\nreview was not comprehensive in some of the areas of\ninterest especially in early diagnosis and risk stratification,\nit provided the researchers with a source of reference. How-\never, the current systematic literature review (SLR) follows\nthe PRISMA guidelines much more closely to ensure more\nexhaustive and objective approach to analysis and provide\nthe discussion of the practical recommendations for further\nresearch that would consider the intricacies of medical data\nfor diabetes prediction.\nIt may preclude older basic studies because the ML-\nbased risk prediction of DR progression [74] is limited to\npapers published between January 2017 and April 2023.\nUsing only 13 research and a few databases may not identify\nall the relevant materials, which can lead to selection bias.\nThe authors did not extensively discuss the comparability\nand inclusion of the different DR populations, which would\ninfluence the generalizability of the findings. Our SLR al-\nleviates these limitations by focusing on a more extended\nperiod (2014-2023), covering more first-hand papers (53),\nand incorporating more criteria such as algorithms, datasets,\nand validation methods. This methodological approach in-\ncreases the likelihood of identifying relevant and inclusive\nstudies. It thus provides a more comprehensive synthesis of\nthe literature as a foundation for future research on blood\nglucose prediction and DR progression.\nThe systematic literature review performed by Wadghiri,\nM.Z et al. [76] aimed to review state of the art in predict-\ning blood glucose using ensemble methods regarding eight\ncriteria: types of algorithms, year of publication, journal,\ndatabase, types of ensembles, learners, combination meth-\nods, performance measures, validation methods, overall per-\nformance, and accuracy. This systematic literature review\nhas been performed to compare primary studies between\ndigital libraries from 2000-2020. Among the 32 primary\npapers they have reviewed, eight review questions were\nchosen for this study. The results indicated an increase in the\nuse of ensembles in recent years; overall, they were better\nthan the rest of the single models. However, the process of\nformation of the groups and the performance criteria are not\nentirely flawless. Here, some suggestions have been provided\nabout the design of compelling ensembles for blood glucose\nlevel prediction.\nDigital libraries may have missed crucial studies. The\nexclusion of some research and a short number of evaluated\nprimary papers may affect the selection process compre-\nhensiveness and biases. The study approach of measuring\nensemble formation and performance has limitations. This\ndiscovery is particular to blood glucose prediction and may\nnot apply to other contexts. Datasets and validation methods\nalso affect dependability. Finally, the pace of technological\nprogress may render certain conclusions outmoded and less\nrelevant. This article addresses these concerns well, focusing\non significant database research and publication years. We\nuse various methods besides ensemble learning.\nThe review by Eijoseno, M.R et al. [77] was designed\nto present diabetes in general, its prevalence, complications,"}, {"title": "3. Research Approach", "content": "The predominant goal of this SLR is to achieve critical\nsystematic integration and summary of the latest published\nscientific literature on the application of machine learning in\npredicting and managing diabetes. This review will outline,\nanalyze, and summarize emerging trends, known gaps, and\nkey takeaways of the technology landscape that is dynamic\nand fast-moving. This review aims to examine the predictive\nmodels; additionally, it will outline the used approaches,\nboth the strengths and the weaknesses, used datasets, train-\ning and validation strategies, categorize the effectiveness\nof the current hypothesis, give the critique, and consider\nthe areas to advance further research. To achieve this, the\nreview process must be thoroughly arranged according to\nthe PRISMA framework [59]. With its solemnity and complex-\nity of procedure, PRISMA is considered a reference to con-\nducting systemic reviews, supporting hearings, and ensuring\nclarity in the appraisal of scientific literature. It provides a\nsystematic technique that is evaluative regarding literature\nselection, literature assessments, and literature syntheses.\nThis makes it a proper analysis tool that condenses vast\nresearch findings into coherent conclusions.\n3.1. Research Objectives and Research Questions\nThe research questions designed for the systematic lit-\nerature review aim to answer how machine learning and\nartificial intelligence are used for diabetes prediction and\nestablish the framework for the current state of the art in\nthe field. These goals are not only to sum up and analyze\nthe previous studies but also to identify the areas of gaps\nwhere more technological innovations and new methods can\nbe used. The main objective is a systematic review of all"}, {"title": "3.2. Search Databases and Search Queries", "content": "When conducting a systematic literature review, particu-\nlarly in fields involving advanced technologies such as ML in\nhealthcare, selecting suitable databases to search is crucial.\nIn the context of systematic literature reviews, a research\nquery definition specifies the exact terms, scope, and param-\neters for a search strategy used to gather relevant literature\non a given topic. This definition is crucial as it directly\ninfluences the quality, relevance, and comprehensiveness\nof the literature collected. Defining a research query helps\nensure the review is systematic, reproducible, and closely\naligned with the research objectives. Keeping in mind that\ndefinition, we set the following strategy:\n\u2022 Specific words and phrases were used in the database\nsearch. Those were usually derived from the main\ntopics of the research questions and are critical in\nretrieving relevant literature. Keywords are carefully\nselected to capture the various aspects of the investi-\ngated topic.\n\u2022 For all those keywords, we searched for synonyms,\nalternative spellings, and other names for the disease.\n\u2022 We incorporated Boolean operators (AND, OR) to\nformulate search queries.\nHere is a description of critical databases with their\nsearch queries that were used for such research, highlighting\ntheir specific relevance and benefits:\nPubMed is the premier database for anyone researching\nmedical and healthcare topics. Managed by the National\nInstitutes of Health, PubMed provides access to more than\nthirty million citations for biomedical literature from MED-\nLINE, life science journals, and online books. It is especially\nuseful for finding peer-reviewed articles on medical studies,\nclinical trials, and epidemiology."}, {"title": "3.3. Exclusion and Inclusion Criteria", "content": "Exclusion and inclusion criteria can facilitate the selec-\ntion of resources that address the research questions in a\nsystematic literature review. Within the framework of our\ninvestigation, we determined and implemented the \"Inclu-\nsion/Exclusion\" criteria that should be followed. For the\nExclusion Criteria during our research, we eliminated the\nresources that were able to satisfy the following constraints:\n\u2022 Articles written in languages other than English.\n\u2022 Short papers are defined as papers that consist of fewer\nthan seven pages.\n\u2022 Workshop papers\n\u2022 Papers that are duplicated.\n\u2022 The full text of the papers that were not available for\nreading.\n\u2022 In subsequent years, conference papers were pub-\nlished in journals.\nFor the Inclusion Criteria, all the articles that applied\nmachine learning methods to predict diabetes were included\nin our study."}, {"title": "3.4. Execution of Search Queries", "content": "Once we had the general framework for the SLR in\nhand, we designed a thorough search strategy to cover all\nthe databases and widen the scope of our search.\nA. The search yielded many relevant articles from three\nmajor databases. Consequently, the data for research were\ncollected from 321 articles from IEEE Xplore, 728 papers\nfrom PubMed, and 807 articles from Science Direct. These\ndiversified sources were useful in building up a good pool\nfor the review which will be useful in the development of\nthe database. The first search brought up a total of 1,856\narticles in all the databases searched for. On the records that\nwere collected, the process of de-duplication was also done\nto avoid having the same record entered twice. Finally, after\nexcluding duplicate articles 336, there were 1520 articles\nthat went through the screening process.\nB. Each manuscript was then proceeded to the exclusion\ncriteria in a step wise manner. In this phase, all records\nidentified by the search process amounted to 1,520, and all\nthe records were screened by title and abstract to decide their\nsuitability for the study. Out of this process, 1468 records\nwere screened out because they were not relevant to the\nresearch questions or did not meet the inclusion criteria.\nOut of them, 53 were potentially relevant and hence were\nretrieved for full-text review based on the title and abstract.\nC. The first author of the study systematically went through\nthe 53 manuscripts and strictly obeyed the rules of the inclu-\nsion criteria. Thus, 37 studies were included in the analysis\nafter the full-text review of the articles and according to the\ndata quality, the relevance of the studies, and the purpose of\nthis study. Out of the total 37 studies, a total of 16 studies\nwere removed at this step; 11 studies were not related to the\nresearch questions and for 5 studies, the required information\nwas missing. The other 37 studies were considered to be of\nhigh quality and more related to the systematic review.\nD. To make the process of identifying relevant articles\neven more rigorous, the snowballing technique was used.\nRegarding the citation searching method, it means the use\nof references or citation from the previous studies that have\nbeen included in the current study and help in identifying\nmore related studies that may have been retrieved from\nthe database search. There are two types of snowballing:\nforward snowballing that entails identifying papers that have\ncited the included papers and backward snowballing that\ninvolves identifying papers cited in the included papers. To\nensure the systematic review of the reference lists of the\n37 studies, backward snowballing was applied. By using\nthis snowballing method, other 16 related studies were also\nfound, and all of them were included in the final review.\nThese works greatly expanded the range of the literature\nand greatly reduced the likelihood of missing any pertinent\nresearch.\nE. The last process was the process of incorporating studies.\nBy the end of the study, a total of 53 papers were analyzed in\nthe systematic review after the eligibility step and the snow-\nballing technique were done; this was after getting 37 papers\nfrom the eligibility step and an additional 16 papers from the\nsnowballing technique. This approach ensured a consistent\nand systematical method of selecting the studies as shown\nwhich makes a solid ground for answering the\nresearch questions and yielding useful knowledge.\nF. We progressed to the data extraction stage, which is\ncrucial for answering our study questions by identifying\nthe exact datasets with characteristics, training strategies,\nevaluation approaches, metrics and ML algorithms used in\nthe studies. The data collection process was easy, enabling\nthe primary author to handle the extraction independently.\nYet, assessing the possible constraints of the investigations\nwas more difficult. This analysis required a thorough and\nconcentrated discussion, collaboratively carried out by all\nauthors of our work. They carefully analyzed sections of the\npublications that addressed potential constraints and threats\nto validity. They examined the features and qualities of each\nML technique employed to pinpoint any further constraints.\nAll authors are experienced in artificial intelligence and\nmachine learning, with years of expertise and engagement\nin teaching academic courses. This significantly improved\nthe thoroughness and depth of their analysis in this phase of\nour systematic literature evaluation."}, {"title": "3.5. Quality assessment", "content": "Before moving further with the process of extracting\nthe material necessary to answer our research questions,\nwe evaluated the quality and comprehensiveness of the\ncollected resources. We discarded the papers that did not\nprovide sufficient details to be utilized in our investigation.\nRegarding this matter, we devised a checklist that contained\nthe following queries:\nQ-1: Are there datasets used related to diabetes predic-\ntion?"}, {"title": "4.1. RQ1: On the Datasets and Their\nCharacteristics", "content": "When it comes to diabetes prediction research, the selec-\ntion of datasets is rather crucial [37]. Data or datasets are the\nkey input to the development of any predictive model and the\nquality of the data defines the efficacy of the resulting model.\nAdvanced datasets include people of different demography,\ndiseases, and geography; that provide extensive informa-\ntion for diabetes control and prognosis. From the different\ndatasets, one can see that the way diabetes is researched and\ncombated is quite varied in terms of methods and strate-\ngies. In response to the RQ1, the current studies revealed\nthat the employed data embraces different populations, and\ngeographic areas, which offered a comprehensive view of\ndiabetes research from different perspectives. Both datasets\nrequire different features, which represent the richness and\ncomplexity of diabetes management and prediction. Differ-\nent distribution of datasets used in the studies is shown in\nLongitudinal Studies: The Japanese study of Aizawa Hos-\npital from Matsumoto investigated 2,105 cases of adults\nwith prediabetes follow-up data with an average observation\nperiod of 4. 7 years [79]. It also shows that the monitoring\nprocess is a vital aspect for one be able to notice the transi-\ntion from prediabetes to diabetes. This way, the researchers\nwould be able to determine potential early indicators and\ncontributing factors to the development of diabetes, which\ncould be of significant help in the development of primary\nprevention and early detection programs. The studies carried\nout at the Almazov National Medical Research Center cover\npatients with endocrine disorders, including gestational dia-\nbetes mellitus (GDM) [6, 78]. This study is important since\nit deals with the specifics of diabetes and the challenges\nthat it has on pregnancy in particular. Thus, analyzing the\nclinical information of this population, the study intends to\nadvance the management approaches and performances in\nthis field for both the mothers and their babies, stressing the\nimportance of focusing on endocrine disorders and develop-\ning more specific care for women.\nLarge Population-Based Studies: The Australian Dia-\nbetes, Obesity, and Lifestyle AusDiab study is a large, cross-\nsectional study that is ideal for assessing the performance\nof risk models for diabetes complications using real data\nof patients [66]. Researchers themselves should have this\ndataset based on which they could work out and check good\nmodels for prognosis of the further evolution of diabetes in\npatients. The extensive follow-up and the frequent collection\nof data offer a vast source of information on the relation of\nsuch factors as obesity and diabetes. The eight-year follow-\nup of the BARICAN cohort deals with impact of RYGB\non diabetes in 175 patients with T2D. This study gathered\ndata before surgery and at various intervals up to the 5-\nyear follow-up post-surgery to analyze the impact of surgi-\ncal procedures on diabetes remission and other metabolic\noutcomes. This research also presents the probability of\nthe utilization of bariatric surgery as a solution for type 2\ndiabetes.\nSpecific Health Condition Datasets: The Diabetes Predic-\ntion Data Set (DPDS) contains data of 520 patients and is\nused for classification problem, namely, to diagnose a patient\nas a diabetic or a non-diabetic based on the age, gender, BMI,\nand lab test results of patient [7]. This dataset is very vital in\nthe development of machine learning models for diagnosis\nof diabetes; this explains the usefulness of data mining in\ndiagnosis of some diseases. The richness of attributes in the\nDPDS allows for such a detailed picture of the determinants\nof diabetes to be painted.\nImaging-Based Studies: The Diabetes Prediction Data Set\nDPDS is a database consists of 520 records of patients that"}, {"title": "4.2. RQ2: On the Configurations of ML\nAlgorithms in Diabetes Prediction", "content": "The application of ML techniques has enhanced the\nprediction of diabetes and the reliability of predictions. Due\nto the exposure to different datasets, ML systems can handle\nlarge amounts of data, discover complex and sophisticated\npatterns, and enhance the accuracy of the outcomes. These\nalgorithms entail independent variables and training strate-\ngies. Training processes allow for tweaking and verifying the\nML models, while other factors that are outside the training\nprocess, such as the demographic data of the patients and\nthe medical statistics, provide input data. Diabetes can also\nbe predicted with the help of machine learning algorithms\nto analyze big data sets and patterns that are unnoticed by\nstatistical means. The common ML algorithms used for pre-\ndiction/classification purposes are Decision Tree Classifier,\nNaive Bayes, Linear Regression, Logistic Regression, K-\nNearest Neighbor,CNN, SVM, and XGBoost are suitable\nfor organizing various sorts of data and providing accurate\npredictions or classifications [48]. These algorithms employ\ncomplex inputs of data such as medical images, or physio-\nlogical readings to enhance diabetes diagnosis and care.\nSince the diabetes prediction models require indepen-\ndent variables as the inputs for the algorithm training, some\nof these variables include age, gender, blood glucose levels\nand the retinal images. The accuracy of predicting diabetes is\ninfluenced by independent variables [14]. Choosing appro-\npriate and full variables is useful for the creation of predic-\ntions by the ML algorithms. Training methods are essential\nwhen it comes to the enhancement of the ML model. Cross-\nvalidation, data augmentation, hyper parameter tuning and\nselection of features improve models and avoid overfitting.\nCross-validation is used to validate the model on different\ndata subsets to make it more reliable. The augmentation\nof data enhances the generalization of the model since the\ntraining data contains variation in the new data set. Feature\nselection helps in removing the irrelevant features hence\nreducing the noise and improving the models.\n4.2.1. The Role of Independent Variables and\nTraining Techniques in Diabetic Prediction\nUsing ML Algorithms\nOf the studies, some aimed at the diagnosis of diseases\nsuch as diabetic retinopathy, possibly glaucoma, and AMD,\nwhere the retinal image was the main independent factor.\nThe type of ML algorithm that has been employed mainly\nfor these tasks is the CNN which is used for image anal-\nysis and classification. The training plan relies on giving\nnumerous retinal images to the deep learning system. For\ninstance, the research based on the Singapore National Dia-\nbetic Retinopathy Screening Program as well as other multi-\nethnic population-based studies further optimized their clas-\nsifiers with large databases of retinal images to achieve high\nlevels of classification accuracy for such diseases [73, 79, 22,\n66].\nIn REPLACE-BG studies, the principal independent\nvariables were the various glycemic indices such as mean\nblood glucose level and time in range. Classification was\noften performed by SVM because this was efficient for small\nsample sizes and avoiding the problem of over-learning.\nThe training strategy included data partitioning into the\ntraining and test sets and the features selection by recursive\nfeature elimination. This method allowed for the appropriate\nutilization of features that enhanced the model performance\nA wide range of demographic and health-related predic-\ntors were included in the present studies, and data came from\nthe NHANES dataset; most statistical tests applied were lo-\ngistic regression. In the classification, emphasis was made on\nbiomarkers that would help distinguish between prediabetes\nand DM. Training strategies employed comprised five-fold\ncross validation so as to prevent overtraining of the models;\nlarge demographic and health data could then be used to\naccurately predict diabetes risk [75, 36].\nThe dataset concerning the Itabuna Diabetes Campaign\ninvolved determining the DR severity from fundus images\nusing deep CNNs like PhelcomNet. The process of training\nalso involved some augmentation where the images were\nrotated and brightness was changed in order to get the best\nresults. These works were expected to enhance the CNN\ndiagnostic abilities on a large dataset of fundus images\n[12, 68].\nThe features that were detected when working with stud-\nies that employed the Optum\u00ae EHR Dataset; XGBoost was\ncommonly utilized because of its capacity to accommodate\nbig data. Training activities included selecting the features\nand hyperparameter tuning with the help of five fold cross\nvalidation. This approach helped to deal with the large EHR\ndata that resulted in the prediction of diabetes and related\ndiseases [50, 60, 64, 71, 10, 7].\nThe EyePACS was mainly consisted of fundus images\nand CNN was used for diagnosing and categorizing DR.\nTraining practices included data augmentation and cross-\nvalidation that allowed the model to recognize the different\nDR stages across the population [13].\nThe studies based on data of ELSA-Brasil used random\nforest algorithms because they are designed to work with\nhigh dimensions and also give the probability of variable\nimportance. The training included parameter optimization\nand selecting the most appropriate variables with the help\nof the wrapper methods, demographic, and clinical factors\nto predict diabetes risk [18]."}, {"title": "4.2.2. Classification Types and Corresponding ML\nAlgorithms for Diabetes Prediction", "content": "CNNs were mainly applied for image analysis in exper-\niments, and the most common type of images used were the\nretinal ones for diagnosing diabetic retinopathy, suspected\nglaucoma, and AMD. Training was done using a large num-\nber of retinal images and this gave high accuracy models\n[73, 79, 22, 66].\nIn analyzing glycemic metrics, Support Vector Machines\n(SVMs) were used to analyze the small data points with\nan added advantage of avoiding overfitting. Filtering was\nthe most used technique for adjusting the feature list and\nextracting the best set of features to be applied in the model\n[39].\nThe motivation for applying logistic regression to the\nNHANES dataset is based on previous application of the\nmethod in research on factors such as BMI percentiles and\nfamily history of diabetes and hypertension. The process of\nfive-fold cross-validation was a common training methodol-\nogy to obtain high model stability [75, 36].\nDeep CNNs were applied in the Itabuna Diabetes Cam-\npaign dataset to classify the DR severity, training strategies\nwere Data augmentation to increase the transferability of\nmodel [52, 13].\nSpecifically, XGBoost was often adopted in research\nworks with the Optum\u00ae EHR dataset, which is characterized\nby high performance and data compatibility. The training\nmethods used were feature selection preprocessing and five\nfold cross validation [50, 60, 64, 71, 10, 7, 4].\nIn the studies that employed the ELSA-Brasil data, ran-\ndom forest algorithms were incorporated. These algorithms\nwere selected based on their capacity to work with large\nnumber of predictors and give the quantitative evaluation of\nthe importance of variables [18].\nIn the Botnia Prospective Study, Least Squares Regres-\nsion analysis was used in the determination of type 2 diabetes\nrisks related to metabolomic profiles. Training methodolo-\ngies employed were multivariate logistic regression, and\nrepeated nested cross-validation [49, 72, 7].\nAs for the HRV signals obtained from ECG, CNN-\nLSTM-SVM Hybrid Models were utilized in the research,\nsince component algorithms complement each other, im-\nproving the predictive potential. [63, 68, 70, 23, 55, 47, 42,\n35, 28, 18, 8, 69, 56, 61].\nThe deep learning model Inception-V3 was used, which\nis ideal for image data, was applied in a study that involved\nthe analysis of OCT measurements of diabetic patients [27].\nDemographic, clinical characteristics and lifestyle fac-\ntors were used and employed with Bayesian networks, as this\napproach is suitable for representing probabilistic dependen-\ncies between variables [58, 6, 3, 72, 53, 43, 41, 30, 20, 80,\n32, 57]."}, {"title": "4.3. RQ3: On the Evaluation Techniques and\nMetrics", "content": "The evaluation setups are important especially in diag-\nnostics of diabetes through ML algorithms. It is important\nto have evaluation sets to make sure the models are correct\nand practical in real life situations. They provide the robust\napproach to compare the ML models and thus it is easier\nto identify the most appropriate techniques and increase the\nreliability and efficiency of models. The primary finding\nof this study is that the configurations of ML model eval-\nuations affect the reliability and robustness of the models.\nOverfitting, check whether the model runs properly on other\ndata, and describe advantages and limitations of the model.\nScholars can determine which diabetes prediction models to\nselect based on the available evaluation methods.\nAs it is seen in the diabetes prediction literature, there\nare different approaches for measuring the performance.\nOne such method is the cross validation which is helpful in\nenhancing the assessment of the model by checking for its\nperformance on different partitions of data. This approach\nmakes the model more reliable and accurate when tested\non different datasets hence giving more reliable evaluations\nValidation tests the model on a data other than training\ndata. It is also important in the validation process to see the\ngeneralization of the model on new data. In the Optum\u00ae\nEHR dataset research, the model was externally validated\nby comparing the prediction with the scores of new images\nfrom the screening program as well as ten other datasets\nwith different populations [45"}]}