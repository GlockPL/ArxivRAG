{"title": "The erasure of intensive livestock farming in text-to-image generative AI", "authors": ["Kehan Sheng", "Frank A.M. Tuyttens", "Marina A.G. von Keyserlingk"], "abstract": "Generative AI (e.g., ChatGPT) is increasingly integrated into people's daily lives. While it is known that AI perpetuates biases against marginalized human groups, their impact on non-human animals remains understudied. We found that ChatGPT's text-to-image model (DALL-E 3) introduces a strong bias toward romanticizing livestock farming as dairy cows on pasture and pigs rooting in mud. This bias remained when we requested realistic depictions and was only mitigated when the automatic prompt revision was inhibited. Most farmed animal in industrialized countries are reared indoors with limited space per animal, which fail to resonate with societal values. Inhibiting prompt revision resulted in images that more closely reflected modern farming practices; for example, cows housed indoors accessing feed through metal headlocks, and pigs behind metal railings on concrete floors in indoor facilities. While OpenAI introduced prompt revision to mitigate bias, in the case of farmed animal production systems, it paradoxically introduces a strong bias towards unrealistic farming practices.", "sections": [{"title": "1 Introduction", "content": "Since ChatGPT's launch in November 2022, generative artificial intelligence (AI) has seen unprecedented growth, with ChatGPT now having over 180 million monthly active users [30]. Generative AI refers to models that can create new text, images, and other media by learning patterns from existing data, typically guided by text prompts [33]. Evidence suggests that given its ease of use and efficiency, the general public is increasingly relying on ChatGPT over traditional search engines [64]. However, Al ethics research has shown that these AI models inherited human biases through the use"}, {"title": "1.1 Cows? Pigs? Why do they matter?", "content": "Driven by a growing demand for abundant, low-cost food supply, farming practices shifted from extensive systems (e.g., cows grazing on pasture, pigs foraging outdoors) toward intensive systems emphasizing productivity after the Great Depression [38]. Intensive livestock farming is characterized by housing large numbers of animals per unit area [50] including indoor confinement in cages or in pens with concrete floors, and severely restricting movement [50, 55, 58]. While the increases in intensification are often justified as necessary to feed a projected global human population of 9.8 billion by 2050 [18], many practices have faced mounting public scrutiny [9].\nExtensive scholarship has shown that intensive livestock farming contributes greatly to antimicrobial resistance [42, 53], increased spread of zoonotic diseases (pathogen transmissible between animals and humans, such as highly pathogenic avian influenza) [29], biodiversity loss [27], climate change [49], posing direct or indirect risks to human health [23]. Public concern over farmed animal welfare emerged in the mid-to-late 20th century, highlighting that many common livestock farming practices failed to resonate with societal values, such as the permanent separation of dairy calves from the dam within hours of birth [45], early slaughter of male chicks and dairy calves [9], lack of pasture access for dairy cows [46] and housing systems that severely restrict animals' movement (i.e., pig gestation stalls [39]; tie-stall housing in dairy [6].\nIt is increasingly argued that the long term sustainability of food production systems depends not only on economic viability and environmental sustainability but also on social sustainability [51, 57]. More recently some have also argued that sustainability frameworks should include a fourth pillar - 'animals' - that would require recognition that animals used for food are sentient beings whose welfare matters independently of public perception [17].\nGiven that images shape public opinion, images of farmed animals accessible by the public will play a key role in shaping public perception of the lives led by farmed animals [39, 54]. Most public image datasets commonly depict clean and healthy farmed animals roaming outdoors, but these pastoral scenes drastically deviate from the modern livestock farming reality, where most animals are housed indoors at high animal densities; systems that require some painful procedures to help mitigate animals injuring each other (e.g., removing horn buds from cattle and tail-docking in pigs to reduce tail biting) [20]. While concealing the reality of livestock farming may temporarily shield the industry from scrutiny, greater trust backlash could occur when citizens discover the truth, thereby threatening the industry's social license to operate [9].\nGenerative AI like text-to-image models are developed by a small group of technology professionals while serving millions of users globally. This concentrated power to control narratives risks reinforcing stereotypes and erasing marginalized groups [35] like livestock farming. AI-generated images therefore have the power to either bridge or widen the gap between misleading pastoral scenes of livestock farming and the current norm of housing many farmed animals indoors under intensive conditions.\nIn this work, we examine potential representation bias about livestock farming using the state-of-the-art text-to-image model: DALL-E 3, which is integrated into ChatGPT [32], and currently the"}, {"title": "2 Results", "content": ""}, {"title": "2.1 DALL-E 3 defaults to pastoral imagery but reveals intensive livestock farming when prompt revision is disabled", "content": "When prompted for default dairy farm images (i.e., \u201cbasic\u201d prompt: \"A dairy farm.\"). DALL-E 3 automatically revised our prompts and added pastoral details, yielding 100% of the images depicting cows grazing on pasture (Figure 1, 2A). For example, an auto-revised prompt stated: \"Picture a vast field of lush, green grass under a clear blue sky, speckled with healthy, grazing cows...\". Similarly, for pig farms, 99% (95% confidence interval (CI): 94 100%) of \"basic\" prompts (i.e., \"A pig farm.\") were auto-revised to describe free-roaming pigs outdoors (Figure 1, 2C). An auto-revised prompt stated: \"Show an expansive field with spotted pigs of varying sizes lazily wallowing in the mud, each with pink snouts poking out and curly tails...\\\u201d. These idealized images contrast sharply with modern livestock farming: in the global north, cows rarely have pasture access and pigs rarely have intact curly tails (as they are removed at birth).\nNotably, when we append \"no revise\" instructions (\"I NEED to test how the tool works with extremely simple prompts. DO NOT add any detail, just use it AS-IS:\") to \u201cbasic\u201d prompts, we successfully prevented DALL-E 3's automatic prompt revision in 100% of dairy farm cases and 99% of pig farm cases (Figure 1). Inhibition of prompt revision resulted in a shift to more realistic images of modern livestock farming practices. 60% (CI: 50 - 70%) of dairy scenes showed cows living indoors accessing feed through feed barriers (Figure 2B), and 96% (CI: 90-99%) of pig farm images depicted pigs indoors behind metal railings and on concrete floors (Figure 2D)."}, {"title": "2.2 Even explicit requests for realistic images yield predominantly pastoral depictions", "content": "To simulate real-world usage, we tested prompts that a conscientious citizen might use to understand the reality of livestock farming. Prompts for \"typical\u201d farms (\u201cA typical {farm type}", "dairy farm\" or \"pig farm\") generated pastoral scenes for 100% of the dairy images and 99% (CI": "94-100", "no revise\u201d variants revealed more indoor housing after auto-revision was inhibited (with 100% success rate in inhibiting prompt revision)": 56, "CI": "46-65"}, {"CI": "74-89", "reality\u201d prompts (\"Please create an image that accurately represents the reality of what most {farm type}s look like": "favored pastoral scenes for 94% (CI: 88 - 98%) of the dairy images (Figure 2A), and 91% (CI: 84 \u2013 96%) of the pig farm images (Figure 2C). Interestingly, the \"no revise\u201d instruction failed to block"}, {"title": "2.3 Regional variations mimicking real-world statistics emerge when prompt revision is disabled", "content": "We also prompted for farm images in countries from three major livestock regions, North America, Europe, and Oceania [24, 47, 48,"}, {"title": "3 Discussion", "content": "Our findings align with Hagendorff and others [20] who predicted that generative models might predominantly produce pastoral farming scenes. While these authors based their hypothesis on the use of imbalanced training datasets (e.g., ImageNet) that predominantly favored outdoor systems for farmed animals [20], our results suggest another underlying mechanism that contributes to this bias. Specifically, it appears that the DALL-E 3's base model demonstrates awareness of the current realities associated with animal farming, given by the images generated when the prompt revision was inhibited. The bias toward pastoral imagery appears to stem from the model's automatic prompt revision process, which systematically adds pastoral details to user prompts, conveying disinformation (i.e., the deliberate dissemination of false information) that farmed animals are raised extensively."}, {"title": "3.1 The biases in GPT-4 enabled prompt revision", "content": "DALL-E 3's prompt revision was originally designed to mitigate bias [8]. The process involves using GPT-4 to \"upsample\" short user prompts into detailed, descriptive prompts. OpenAI has disclosed a system prompt they used to instruct GPT-4 to rewrite user prompts (see Appendix C in Betker et al. [8]) but the full guidelines governing prompt revision-particularly those concerning the removal of public figures and branded items, as well as protocols for animal depiction-are not publicly available.\nAlthough DALL-E 3's training data sources are also not disclosed, the evaluation dataset testing DALL-E 3's prompt following ability is publicly available. Among the 8000 evaluation prompts extracted from MSCOCO [8], 93 prompts involve cows/cattle, 58 depicted pastoral scenes such as cows on pasture with calves outdoors, while only 6 described housing a few cows indoors in pens. The remaining 29 prompts portrayed atypical scenarios like cows walking on streets and pigs only appeared in one prompt (in a cooking context). While OpenAI states they did not specifically use MSCOCO for training or optimization, they do acknowledge potential data leakage in the training process [8]. The model's ability to accurately depict the reality of intensive livestock farming was not evaluated.\nMore importantly, while this automatic prompt revision process is documented in API system cards available for programmers, the general public who mostly access these models through Chat-GPT's website or app interfaces are kept ignorant of this, raising transparency concerns. Without specialized prompt engineering techniques, typical ChatGPT users are unlikely to generate realistic representations of modal livestock farming. We recommend that ChatGPT transparently inform its website and app users about the prompt revision process, and provide more representative depictions of modern livestock farming, especially when it is explicitly requested to do so. It is important in the ongoing discussions between society and the animal industries that transparency exists regarding current farming practices, as failure to do so increases the risk of disconnect between producers and the consumers who purchase their products."}, {"title": "3.2 Who shapes AI, and who gets left out?", "content": "The pastoral bias is a form of \"coded gaze\" from those who trained DALL-E 3. Contrary to the common misconception that algorithmic systems are objective [28], \"coded gaze\" illuminates how those with the power to shape technology can encode discrimination and erasure into Al systems, potentially propagating harm, even if unintentional [11]. This framework echoes with the concept of \"male gaze\": a term describing how societal priorities and values are shaped through a masculine lens in patriarchal societies [11]. The theory of \"regimes of representation\" from media studies also warns how dominant groups could shape the narrative and public understanding of marginalized social groups [21]. In some cases, an already marginalized group could be systematically erased from the dominant media [35].\nAl companies like OpenAI have made extensive efforts to include domain experts from diverse disciplines to participate in red teaming (i.e., systematic testing for flaws and vulnerability in the model by adopting an attacker's mindset) [32]. Nevertheless, the choice of which domain experts to include, which data to filter, and even what biases to evaluate inevitably encodes new biases in models [31, 32]. Red teaming practices primarily address anthropocentric concerns, animal-related concerns are limited to preventing explicit depictions of animal cruelty [31, 36]. Without direct access to OpenAI's prompt revision guidelines, we can only speculate why intensive livestock farming systems are being systematically erased. While some routine intensive farming practices such as tail docking in pigs might be flagged during red teaming as potential forms of animal harm, it is also possible that programmers judge these routine practices to be too disturbing for the general public (see Figure A.19, A.20 for examples of ChatGPT refusing to generate images because it classifies common intensive farming practices as sensitive content). However, when Al is programmed to idealize and conceal these routine management practices, it prevents the public from engaging with important concerns inherent to the systems producing the milk they drink and the meat they purchase. To our knowledge, no research has examined whether the public prefers Al to generate realistic depictions of livestock farming or pastoral scenes that in turn shield them from the modern realities of food animal production."}, {"title": "3.3 The self-perpetuating cycle of pastoral bias through synthetic data", "content": "As internet-scraped data becomes exhausted for AI training, developers are turning to synthetic data \u2013 data generated by AI models themselves as the path forward [52, 62]. As of 2024, synthetic data already constitute about 60% of AI training data [62]. This shift introduces a new risk referred to as \"synthetic data spill\" [63], similar to oil spills that pollute oceans, synthetic data can \"pollute\" online data ecosystems [7]. For example, some AI-generated images of baby peacocks, visually appealing yet drastically different from real peachicks, have proliferated across the internet and now dominate Google image search results [63]. This pollution has compromised online searches for people seeking to learn about real baby peacocks, as the top search results now predominantly feature AI-generated peachick images [40]. There is great risk that"}, {"title": "3.4 Limitation", "content": "One limitation of our study is that our binary classification (indoor versus outdoor) overlooks some variations within each category. Indoor images do not always depict severe restriction of movement, as some images show animals roaming loosely in mud housed in buildings. Outdoor images also do not always depict freedom of movement, as some images show restriction of space, depicting densely packed animals on pasture. Second, even when depicting indoor housing systems, the images consistently portrayed clean and healthy animals without physical alterations (e.g., pigs with curly tails), and arguably did not fully represent the range of real-world conditions in intensive farming operations. Our study focused specifically on bias in the depiction of housing conditions, and we did not investigate other forms of potential misrepresentation, such as the physical appearance of animals.\nFurthermore, our analysis is constrained by its western-centric perspective. Intensive livestock farming practices are less prevalent in developing countries (except China), suggesting that representation biases of livestock farming might manifest differently in these contexts. Recent scholarship has emphasized the importance of non-western frameworks in evaluating generative AI bias [35]."}, {"title": "4 Ethical and societal impact", "content": "Our work systematically reveals the representation bias in text-to-image generative model about livestock farming. We demonstrated that while DALL-E 3 has knowledge about modern livestock farming practices, its prompt revision erases the reality that most farmed animals are raised indoors under intensive conditions. This misrepresentation compounds existing transparency issues in livestock farming. Evidence suggests that the general public considers pasture-based systems as \"natural\", \"healthy\u201d, and \u201ccaring\u201d, while associating indoor housing systems with negative connotations like \"unhealthy\", \"unnatural\" and even \u201canimal cruelty"}, {"title": "5 Methods", "content": "During the preparation of this work, the first author used Anthropic Claude to rephrase portions of the manuscript. After using this tool/service, all authors reviewed and edited the content as needed. Collectively all authors take full responsibility for the content of the publication."}, {"title": "5.1 Related work", "content": "The ethical discussions about Al have been mainly anthropocentric, often neglecting the impact of these technologies on non-human animals [13, 44, 68]. However, recent work has begun to address this gap. Previous research has revealed systematic biases in computer vision training datasets (e.g., ImageNet), which predominantly depict livestock freely roaming on pasture rather than in modern farming environments indoors [20]. Their analysis of five prominent computer vision models (e.g., InceptionV3 and VGG16) demonstrated significantly lower accuracy in classifying animals in indoor housing systems compared to outdoor settings, indicating poor out-of-distribution generalization capabilities. The authors hypothesized that future generative models trained on these dataset will further generate images that misrepresent livestock farming, such as images showing animals freely roaming outdoors.\nPrevious research on Al's impact on non-human animals has mainly focused on philosophical investigations of speciesism bias in Al systems [10, 44]. Philosophers who oppose speciesism believe that any being capable of suffering deserves equal consideration of interests, and raising livestock in factory farms for human consumption violates their interests [43]. Many philosophers noted that Al systems are normalizing speciesism practices, such as livestock farming, killing, and eating animals [19, 44, 68]. Analysis of word embeddings from models like GloVe revealed that terms referring to farmed animals are more strongly associated with negative attributes (e.g., \"ugly\", \"primitive\") than positive qualities (e.g.,"}, {"title": "5.2 Model selection", "content": "We examined dairy and pig farm depictions in a leading text-to-image generative model: DALL-E 3 [32]. We focused on DALL-E 3 because of its integration with ChatGPT, which has become the primary Al platform that people use to access information and create content. While other advanced text-to-image models like Stable Diffusion and Midjourney exist, they are primarily used by the open-source community and art creation rather than the general public in their everyday activities. We did conduct a pilot test using Stable Diffusion 3.5-large (480 images; 10 per prompt). However, Stable Diffusion primarily generated close-up images of 1-3 animals rather than detailed farm scenes, we included the results in Figure A.9- A.18. We did not evaluate Midjourney due to our inability to obtain their API access for automated bulk image generation."}, {"title": "5.3 Prompts design", "content": "We created 3 major prompt categories of increasing specificity for both pig and dairy farms to test the models' image generation capabilities. Beginning with a \u201cbasic\" prompt (\"A {farm type}", "typical\u201d representations (\"A typical {farm type}": "and finally explicit", "Please create an image that accurately represents the reality of what most {farm type}s look like\"). The \\\"basic\" prompt was designed to test the model's default farm depictions, and the latter two categories were designed to elicit realistic depictions of modern dairy and pig farming practices. Within each of the 3 major categories, we also asked the models to generate images of pig and dairy farms in major livestock farming countries across North America, Europe, and Oceania: United States, Germany, and New Zealand for dairy farms; United States, Spain, and Australia for pig farms (Table A.1).\nAccording to OpenAI's system card, DALL-E 3 automatically revises user prompts to enhance image quality with more details and ensure compliance with OpenAI guidelines and safety protocols (e.g., removing branding and public figure names, depicting people in diverse skin tones) [32]. While OpenAI's API documentation notes that automatic prompt revision cannot be reliably prevented, they suggest adding this specific sentence to the prompt - \\\"I NEED to test how the tool works with extremely simple prompts. DO NOT add any detail, just use it AS-IS:\\\" \u2013 may help limit prompt revision.\nAiming to test how the image depiction changes when prompt revision is disabled, we created \u201cno revise": "ariants by appending this text to each prompt explained above. As this method does not always successfully prevent prompt revision, we documented the revised prompts that the model used for image generation."}, {"title": "5.4 Image generation", "content": "Given the probabilistic nature of Al image generation, we generated 100 images per prompt using standard quality settings at 1024x1024 pixel resolution, yielding a total of 4,800 images. Each image was generated through a separate API call to ensure independence between generations. API calls are stateless - meaning each prompt is processed independently without retaining information from previous conversations. This approach eliminates potential cross-contamination between multiple image generation requests. All API requests and subsequent data analysis were performed using Python 3.11.10."}, {"title": "5.5 Image clustering", "content": "In our exploratory analysis we manually went through each of the generated images, and identified two predominant themes: (1) \"pasture/mud outdoor\" showing cows on pasture or pigs in mud, and (2) \"exclusively indoor\" showing animals confined indoors. Images that did not clearly fit these categories, including those with ambiguous backgrounds or irrelevant scenes, were classified as (3) \"other\" and excluded from the main analysis.\nWe analyzed 4,800 images using a mixed-methods approach that combines manual review [2, 35] with automated tools [59]. This approach was chosen for several reasons. First, the generated images exhibit substantial variation and complexity even within thematic categories, making purely automated classification challenging. Second, as a first study investigating potential representational biases in livestock farming imagery, our goal was to identify broad patterns in how animals are depicted (outdoor versus indoor settings) rather than develop sophisticated image classifiers. Third, the absence of existing benchmarks or classifiers specifically designed for livestock housing conditions necessitates a more flexible analytical framework.\nFor the analysis, we first prompted OpenAI's GPT-40 model (version 2024-08-06) to automatically categorize each image into 3 categories and provide brief reasoning . As AI could hallucinate, the first author then manually reviewed all images and their auto-assigned categories, finding that only 4.8% of images required correction. Of the corrected images, 41.7% were initially classified as \"exclusively indoor\", and were corrected as \"other\" because they showed animals in metal pens but housed outdoors. Another 23.8% of corrections involved images with backgrounds too ambiguous to categorize as indoor or outdoor, leading to their reclassification as \"other\". The final distribution after these corrections showed 66.0% of images in the \"pasture/mud outdoor\" category, 25.6% in \"exclusively indoor\" and 8.4% in \"other\".\nWe calculated the percentage of images depicting outdoor (\"pasture/mud outdoor\u201d) versus indoor (\u201cexclusively indoor\") housing for each unique prompt. 95% confidence intervals were derived from 10,000 rounds of bootstrap simulations for each prompt. While\""}, {"title": "5.6 Image description analysis and visualization", "content": "While the categorical analysis provided a high-level understanding of livestock housing systems depicted in the images, we conducted a more granular analysis to capture subtle patterns and thematic nuances within each category. To systematically analyze the visual content of all 4,800 images, we employed the GPT-40 model to generate detailed text descriptions for each image (prompt: \"Describe the image in detail\"). We set the temperature at 0.2 out of 2 to ensure deterministic model outputs (higher temperature would give more random output), and used high-quality image settings to preserve image details. We employed a bag-of-words approach to examine both the revised prompts and GPT-40-generated image descriptions. We analyzed bigram terms as they provide more context than unigram terms would (e.g., \"green pasture\" is more interpretable than \"green\u201d), excluding common English stop words and terms present in fewer than 20 images across our 4,800 image dataset. We removed terms from original prompts and generic descriptive phrases (e.g., \"image depicts\") to focus on meaningful differences between descriptions (full list of terms removed in Table A.3). Each term was coded as binary for presence (0 for absent, 1 for present), regardless of frequency of occurrence within individual texts.\nTo visualize patterns, we created word clouds using bigram terms. For each unique prompt, we generated a word cloud for auto-revised prompts, and another for GPT-40's image descriptions. We created grid plots to display the original prompts, revised prompt word cloud, a randomly selected generated image, and the corresponding GPT-40 description word cloud (Figure 1, A.1 \u2013 \u0391.8)"}, {"title": "6 Data availability", "content": "Images and data generated in this project are available at: https://doi.org/10.5683/SP3/EAWR6D."}, {"title": "7 Code availability", "content": "All source code for this research can be accessed at: https://github.com/skysheng7/AI_bias_in_farming.git. Our repository includes a custom Docker container along with GNU make scripts that automate the complete data analysis workflow, ensuring full computational reproducibility of our findings."}, {"title": "8 Funding", "content": "This research was supported by a Social Sciences and Humanities Research Council (SSHRC) Insight Grant (435-2022-0315) awarded to M.v.K. K.S also received funding from Hugo E Meilicke Memorial Fellowship (Vancouver, BC, Canada), Pei-Huang Tung and Tan-Wen"}, {"title": "9 Author contributions", "content": "All authors had access to the complete dataset and shared responsibility for data integrity and analytical accuracy. K.S., F.T., and M.v.K. conceptualized and designed the study. K.S. generated images and performed data analyses under the guidance of F.T. and M.v.K. K.S. prepared the first draft, with F.T. and M.v.K. providing substantial intellectual input throughout the manuscript development and revision process. M.v.K. secured funding and served as the principal supervisor for the overall project."}, {"title": "10 Ethics declarations", "content": "K.S.: I am a female PhD candidate at UBC, specializing in the intersection of animal welfare science and data science. I grew up in urban China and I consume animal products as part of my daily diet. My first direct exposure to livestock farming came during my studies at the University of Wisconsin-Madison, where I was trained in both animal science and computer science. My doctoral training in the Animal Welfare Program at the University of British Columbia, along with continued work in data science, inspired me to envision new possibilities for the industry's future. My research focuses on advancing automated methods for monitoring animal behavior and health, examining algorithmic bias in Generative AI and its impact on animal welfare. I believe in compassionate farming practices that align with societal values and prioritize animal wellbeing during their lifespan.\nF.T.: I am a male visiting professor at UGent and head of the Farm Animal Welfare & Behaviour research group at the ILVO Animal Sciences Unit. I have been vegan for about 8 years which aligns with my growing concern about the animal welfare and environmental footprint of animal agriculture. During recent years I have witnessed an exponential increase in the use of generative AI in academia and research, including my own scientific discipline (farmed animal welfare and behavior). This evolution provides numerous opportunities, but also threats. The social license for animal agriculture ought to be based on accurate and realistic views of current livestock conditions. As generative AI is believed to increasingly shape people's perceptions, the concern of how animal agriculture is represented in generative AI models prompted my interest in this study.\nM.v.K.: I am a female Professor at UBC where I have co-led the Animal Welfare Program since 2002. I grew up on a beef cattle ranch in British Columbia, Canada, and worked in the agribusiness sector for 7 years before joining the university as a professor in 2002. Together with my students I have published extensively in both the natural and social sciences on a broad range of topics in animal welfare. I have worked closely with livestock farmers and attempt to develop solutions that address the needs of the animals but also work for the farmers and align with public values. Some of my work has focused on the use of technology, such as sensors to monitor different behaviors but also now mentor students using AI. I believe that all animals under human care deserve a good life and practices that resonate with societal values will be more sustainable in the long run."}, {"title": "11 Competing interests", "content": "Authors declare that they have no competing interests."}]}