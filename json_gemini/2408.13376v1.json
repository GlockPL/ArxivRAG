{"title": "Reduce, Reuse, Recycle:\nCategories for Compositional Reinforcement Learning", "authors": ["Georgios Bakirtzis", "Michail Savvas", "Ruihan Zhao", "Sandeep Chinchali", "Ufuk Topcu"], "abstract": "In reinforcement learning, conducting task composition\nby forming cohesive, executable sequences from multiple tasks re-\nmains challenging. However, the ability to (de)compose tasks is a\nlinchpin in developing robotic systems capable of learning complex\nbehaviors. Yet, compositional reinforcement learning is beset with\ndifficulties, including the high dimensionality of the problem space,\nscarcity of rewards, and absence of system robustness after task com-\nposition. To surmount these challenges, we view task composition\nthrough the prism of category theory-a mathematical discipline ex-\nploring structures and their compositional relationships. The cate-\ngorical properties of Markov decision processes untangle complex\ntasks into manageable sub-tasks, allowing for strategical reduction\nof dimensionality, facilitating more tractable reward structures, and\nbolstering system robustness. Experimental results support the cate-\ngorical theory of reinforcement learning by enabling skill reduction,\nreuse, and recycling when learning complex robotic arm tasks.", "sections": [{"title": "1 Introduction", "content": "Reinforcement learning (RL) is a powerful tool for sequential\ndecision-making, which is crucial in training robots to execute\ncomplex tasks. Nevertheless, the challenge of composing multiple\ntasks a prerequisite for creating adaptable, interpretable, and ver-\nsatile robotic systems-persists. Central to this challenge are issues\nsuch as high dimensionality problem spaces and task complexity.\nThese issues manifest in several ways: sparse rewards [17], where\npositive feedback is infrequent, making learning slower and more\ncomplex; a lack of robustness [37], making systems susceptible to\nvariations in the environment or task; and complexities in sequencing\nand coordinating sub-tasks [41], particularly when tasks have inter-\ndependencies or must perform in a specific order.\nA compositional perspective alleviates these challenges inherent\nin multi-task RL by decomposing complex tasks into simpler sub-\ntasks [26]. First, principled decomposition reduces the dimension-\nality of the problem space. Each sub-task can be learned and op-\ntimized separately, resulting in more manageable reward structures\nand quicker learning times. For instance, sparse rewards become less\nproblematic as each sub-task can be associated with its reward struc-\nture, providing more frequent feedback to the learning algorithm.\nSecond, by segregating tasks, failures or variations in one compo-\nnent have a lesser chance of disrupting the entire system, improv-\ning overall stability and robustness. If a particular sub-task is per-\nforming poorly due to environmental variations, it can be isolated,\nanalyzed, and improved without affecting the performance of other\ntasks. Third, when tasks are modular, the interactions and dependen-\ncies between different tasks can be systematically mapped and man-\naged, simplifying coordinating and sequencing sub-tasks.\nDespite progress in compositional RL, the challenge of modular\ntask composition remains a barrier to creating versatile robotic\nsystems. Deciding how to break down a complex task into manage-\nable subtasks relies on domain-specific knowledge. The categorical\ninterpretation of RL problem formulations offers an abstraction that\nsystematically captures tasks' interdependencies and compositional\nstructures, leading to a principled way of discovering optimal task\ndecompositions. Additionally, combining policies from different\nmodules to form a coherent overall policy can lead to conflicts\nor inefficiencies, especially if the components were developed\nindependently [30]. The categorical semantics of RL specifies how\npolicies are combined, ensuring consistency and coherence in the re-\nsulting composite policy and enhancing the robustness of integrated\npolicies. Additionally, proof of the existence of categorical structures\nequips compositional RL with a symbolic knowledge representation\nfor interfacing and gluing sub-task constructions. In this paper, we\nvalidate our theoretical results [8] through computational evidence\nusing increasingly complex robotic tasks."}, {"title": "Merits of category-theoretic RL:", "content": "Reduce: By representing the dynamics between tasks, such as\npicking up an object and placing it in a box, the categorical for-\nmalism streamlines coordination and sequencing, improving the\nability to learn increasingly complex tasks through reduction.\nReuse: Through abstraction within the categorical framework, the\nrobot can learn a task, like \"picking up an object,\" and then reuse\nthis knowledge across related tasks modularly.\nRecycle: The categorical formalism extends this reusability fur-\nther, allowing for the recycling of learned skills across different\ncontexts. For example, a skill developed for lifting a block can be\nfined-tuned to lift a soda can."}, {"title": "Conventions", "content": "Subscripts for Markov decision process (MDP) ele-\nments refer to a particular definition instantiation; that is, SN refers\nto the state space of the MDP N."}, {"title": "2 Preliminaries", "content": "Here we give informal definitions of the category-theoretic struc-\ntures we use. Consult Lawvere and Schanuel [24], Leinster [25],\nor Mac Lane [27] for an in-depth treatment of category theory.\nDefinition 1 (Category). A category C consists of the following data\nobjects a collection of objects, denoted obj C\nmorphisms for each pair of objects A, B, a collection of mor-\nphisms from A to B, denoted $\\text{Hom}_{c}[A, B]$\nidentity for each object A, a morphism $A \\xrightarrow{\\text{id}_A} A$\ncomposition for each A, B, C objects, a composition operation\n$\\circ_{A,B,C}: \\text{Hom}_c[B, C] \\times \\text{Hom}_c[A, B] \\rightarrow \\text{Hom}_c[A, C]$.\nTo represent a category this data has to also respect the following\nrelations for each $A \\xrightarrow{f} B$, $B \\xrightarrow{g} C$, and $C \\xrightarrow{h} D$:\n$\\text{id}_B \\circ f = f$\n$f \\circ \\text{id}_A = f$\n$(h \\circ g) \\circ f = h \\circ (g \\circ f)$,\nmeaning that composing with the identity morphism either from the\nleft or the right recovers the morphism itself (unitality) and the order\nof operations when composing morphisms does not matter as long as\nthe order of operands is unchanged (associativity).\nWe will work within Set, the category whose objects are sets and\nmorphisms are functions between them. For each set A, $\\text{id}_A$ is the\nidentity function from A to itself, and composition is function com-\nposition. Rather than treating sets as collections of items, the cate-\ngorical interpretation emphasizes the relationships between sets.\nDefinition 2 (Commutative diagrams). A standard diagrammatic\nway to express composites is $X \\xrightarrow{f} Y \\xrightarrow{g} Z$ and equations via com-\nmutative diagrams of the following form\nwhich stands for $g \\circ f = h$.\nA commutative square is, instead,\nwhich stands for $g' \\circ f = f' \\circ g$.\nA diagram commutes when the result of a composition is the same\nregardless of the path we take from one object to another.\nDefinition 3 (Pushout). A pushout for morphisms $f: C \\rightarrow A$ and\n$g: C \\rightarrow B$ is an object W together with morphisms $a: A \\rightarrow W$\nand $b: B \\rightarrow W$ such that the square\ncommutes, where the morphisms a, b are thought of as \"inclusions,\"\nsuch that $a \\circ f = b \\circ g$, and is universal: for any object $W_0$ with\nmorphisms $a_0: A \\rightarrow W_0$ and $b_0: B \\rightarrow W_0$ such that $a \\circ f = b_0 \\circ g$,"}, {"title": "3 Compositional Reinforcement Learning\nvia Morphisms and Subprocesses", "content": "In this section, we restate some definitions and results from our the-\noretical work for completeness [8]. Task interactivity often relies on\nthe Markov decision process (MDP) structure [32]. We start by de-\nveloping a definition for MDPs that is congruent with the traditional\nMDP representation while containing some subtle generalizations,\nsuch as added flexibility of action spaces. Our definition is designed\nto accommodate uniform action spaces across the entire state space.\nHowever, we also cater to applications where varying action spaces\nin different state space regions are more appropriate, each with dis-\ntinct semantic meanings.\nFor instance, the environment remains relatively stable in a robotic\narm example. Conversely, consider a drone maintaining a safe al-\ntitude; the action space dynamically adjusts when entering an area\nwhere this altitude threshold changes. Traditionally, the literature fo-\ncuses on surjective morphisms on state and action spaces, aiming to\nreduce these spaces for efficient learning. Our approach seamlessly\nincorporates this aspect. However, to emphasize the compositionality\nfeature, it is required also to allow for the expansion of state spaces to\nencompass task components and incorporate morphisms with mixed\ncharacteristics (neither purely injective nor surjective).\nDefinition 4 (MDP). An MDP $M = (S, A, \\psi, T, R)$ consists of:\nThe state space S, a measurable space with a fixed $\\sigma$-algebra.\nThe state-action space A, the total set of actions available at all\ndifferent states, i.e. elements of S.\nA function $\\psi: A \\rightarrow S$ that maps an action $a \\in A$ to its associated\nstate $s \\in S$. Every action in the action space $a \\in A$ can be taken\nat a specific state $s \\in S$, and $\\psi$ maps the action to that state so\nthat $\\psi(a) = s$. Equivalently, the set of actions available at s is the\npre-image $\\psi^{-1}(s) \\subset A$.\nThe information of the transition probabilities is given as a func-\ntion $T: A \\rightarrow P_S$, where $P_S$ denotes the space of probability\nmeasures on S.\nThe reward function R: A $\\rightarrow$ R.\nDefinition 5 (Category of MDPs). MDPs form a category (def-\nnition 1) MDP whose morphisms are as follows. Let $M_i =\n(S_i, A_i, \\psi_i, T_i, R_i)$, with $i = 1,2$, be two MDPs.\nA morphism $m = (f,g): M_1 \\rightarrow M_2$ is the data of a measurable\nfunction $f: S_1 \\rightarrow S_2$ and a function $g: A_1 \\rightarrow A_2$ satisfying the\nfollowing compatibility conditions:\n1. The diagram\nis commutative (definition 2).\n2. The diagram\nis commutative, where $f_*$ maps a probability measure $\\mu_1 \\in P_{S_1}$\nto its pushforward, meaning $\\mu_2 = f_* \\mu_1 \\in P_{S_2}$ under f.\n3. $R_1 = R_2 \\circ g: A_1 \\rightarrow \\mathbb{R}$.\nThe constant MDP pt is the MDP pt whose state space and action\nspaces are the one-point set. Every MDP M admits a unique, natural\nmorphism M $\\rightarrow$ pt and pt is the terminal object in MDP.\nThe two commutative diagrams above show us when two MDPS\nare compatible in that their interfaces agree. Namely, diagram (1)\nguarantees that if an action $a_1$ in MDP $M_1$ is associated to a state\n$s_1 \\in S_1$, then its image action $a_2 = g(a_1)$ under m is associated to\nthe image state $s_2 = f(s_1)$. Similarly, diagram (2) ensures that the\ntransition probability from any state $s_1$ to another state $s_1' \\in f^{-1}(s_2)$\nunder taking action $a_1$ in $M_1$ is equal to the transition probability\nfrom the state $s_2 = f(s_1)$ to $s_2' = f(s_1')$ under action $a_2 = g(a_1)$\nin $M_2$. The third compatibility condition accounts for the reward in\nour categorical formulation.\nIntuitively, the category of MDPs represents a way to relate differ-\nent MDPs to each other through morphisms. A morphism between\ntwo MDPs is a pair of functions that consistently map states and\nactions from one MDP to another. The two commutative diagrams\npresented above define what it means for these mappings to be con-\nsistent. The first diagram ensures that if an action is associated with a\nspecific state in the first MDP, the action in the second MDP must be\nrelated to the corresponding state. The second diagram ensures that\ntransition probabilities between states are preserved under the map-\nping. In other words, how actions transition from one state to another\nin the first MDP must correspond to how actions transition between\nthe mapped states in the second MDP. When augmented with the re-\nward function, two MDPs must preserve the relationships between\nstates and actions and the rewards associated with those actions.\nSubprocesses The definition of morphism correctly captures the\nnotion of a subprocess of an MDP.\nDefinition 6 (Subprocess of MDP). We say that $M_1$ is a subprocess\nof the MDP $M_2$ if there exists a morphism (f, g): $M_1 \\rightarrow M_2$ such\nthat f and g are injective. We say that $M_1$ is a full subprocess if\ndiagram (1) is cartesian.\nSince f is injective, we may consider the state space $S_1$ as a subset\nof $S_2$. Moreover, the condition that diagram (1) is cartesian means\nthat the only available actions on $S_1$ come from MDP $M_1$. Thus,\n$M_1$ being a full subprocess of $M_2$ implies that an agent following\nthe MDP $M_2$ who finds themself at a state $s_1 \\in S_1$ will remain\nwithin $S_1$ no matter which action $a_1 \\in A_1$ they elect to apply.\nConversely, for an MDP $M_2$ and any subset $S_1 \\subset S_2$ there is a\ncanonical subprocess $M_1$ with state space $S_1$, whose action space\n$A_1$ is defined by\nIn fact, $M_1$ is uniquely characterized as the maximal such subpro-\ncess.\nProposition 1. Any subprocess $M_1 \\rightarrow M_2$ with state space $S_1$\nfactors uniquely through the subprocess $M_1 \\rightarrow M_2$.\nThis concept of factoring reflects the idea that certain morphisms\nor relationships break down into simpler or more fundamental parts,\nand uniqueness ensures that this breakdown is done in one specific\nway. In particular, for MDPs, the above proposition establishes a\nunique intermediate structure or relationship that connects subpro-\ncesses.\nPushouts: a gluing construction The categorical notion of\npushout models the gluing of two objects along a third object with\nmorphisms to each. Interesting categorical properties usually are\nuniversal. Universal properties represent specific ideals of behavior\nwithin a defined category [38, 2]. A pushout's universal property is\ndetermined by its being minimal in an appropriate, universal sense.\nAs mentioned above, the simplest example is given in the category\nof sets by the disjoint union $S_1 \\coprod S_2$, which can be viewed as the\npushout of the two morphisms $\\emptyset \\rightarrow S_1$ and $\\emptyset \\rightarrow S_2$.\nSuppose that we have two MDPS $M_1$ and $M_2$ together with a\nthird $M_3$, which is expressed as a component of both through mor-\nphisms $m_1: M_3 \\rightarrow M_1$ and $m_2: M_3 \\rightarrow M_2$. The existence of a\npushout operation in the category MDP allows us to model the com-\nposite task obtained by putting together $M_1$ and $M_2$ and capture\nthe internal behavior of their common component in a maximally\nefficient way without introducing extra cost in resources or dimen-\nsionality or sacrificing accuracy of the representation. The universal\nproperty of pushouts guarantees this as minimal gluings along an\noverlap. Moreover, if $M_3$ is a subprocess, then both $M_1$ and $M_2$\nform subprocesses of the composite M, as desired.\nTheorem 1. There exists an MDP $M = M_1 \\coprod_{M_3} M_2$ which is the"}, {"title": "4 Compositional Task Completion", "content": "We illustrate the implications of the constructions above in the con-\ntext of compositional task completion, but this is one possible appli-\ncation. In particular, we derive a denotational language for composi-\ntional RL based on the properties of subprocess and pushout.\nWe employ denotational semantics to provide a rigorous mathe-\nmatical foundation for modeling RL tasks. Denotational semantics\nprecisely define the meanings of constructs without ambiguity, using\nmathematical objects. This approach is crucial in RL as it allows us\nto define the components of learning tasks such as states, actions,\nrewards, and transitions in a clear, consistent, and universally appli-\ncable way across different scenarios. By using denotational seman-\ntics, we ensure that each component of an RL task is described in\nterms of its effects and interactions, which facilitates an interpretable\ncomposition of complex behaviors. This method contrasts with more\noperational approaches focusing on the computation process itself.\nThe benefit of denotational semantics in our context is its ability to\nabstract and generalize problem-solving strategies, making it poten-\ntially more manageable to apply them to various tasks. This abstrac-\ntion is advantageous when dealing with complex decision-making\nenvironments, where clarity and consistency in task formulation are\ncrucial to developing robust and scalable solutions."}, {"title": "4.1 Zig-zag Diagrams", "content": "In this subsection, we restate results from our theoretical work [8].\nFor designing compositional tasks, we desire to operationalize us-\ning the categorical semantics of RL, which involve accomplishing\ntasks sequentially. In a general setting, we consider the setup given\nby, what we term a zig-zag diagram of MDPs\nwhere for each i = 0, . . ., n \u2212 1, $N_i$ is a subprocess of $M_i$ (defini-\ntion 6).\nThe composite MDP associated with the above diagram is the\nMDP $C_n$ defined by the inductive rule\nEach subprocess $N_i \\rightarrow M_i$ models the completion of a task in the\nsense that an agent's goal is to find themselves at a state of $N_i$ eventu-\nally. Once the i-th goal is accomplished inside the environment given\nby $M_i$, we allow for the possibility of a changing environment and\nmore options for states and actions to achieve the next goal modeled\nby the subprocess $N_{i+1} \\rightarrow M_{i+1}$.\nThe composite MDP $C_n$ is a single environment capturing all the\ntasks simultaneously.\n(?) Suppose an agent learned an optimal policy for each MDP\n$M_i$ given the reward function $R_i$ for achieving the i-th goal\nfor each i = 0,...,n. Under what conditions do these opti-\nmal policies determine optimality for the joint reward on the\ncomposite MDP $C_n$?\nOne scenario in which optimality is preserved is when the zig-zag\ndiagram is forward-moving, meaning that $N_i$ is a full subprocess of\n$M_i$ and the optimal value function $v_i(s)$ for any state s in the state\nspace of a component $M_i$, considered as a state of $C_n$, is mono-\ntonic for subsequent subprocesses $M_{i+1},..., M_n$. Monotonicity\nhere means that the expressions\nare maximized by the same action $a \\in (A_i)_s$. Here $C[i,n]$ denotes the\ncomposite MDP of the truncated zig-zag diagram\nMonotonicity is a strong assumption that helps make a formal ar-\ngument but can be relaxed. It is related to the notion that myopic\nsolutions to the above maximization problems are globally optimal.\nThe experiments considered in this section satisfy monotonicity. For\na non-example, one can consider a moving agent on a grid having to\ncome within a certain distance of two locations, which are an equal\ndistance away from the agent's starting point.\nIn practice, a zig-zag diagram can always be made forward\nmoving by removing the actions of $N_i$ that can potentially move the\nagent off $N_i$ back into $M_i$. This can be formalized as puncturing\n$M_i$ along the complement of $N_i$ and intersecting the result with $N_i$.\nThe details are of general interest but not immediately relevant to the\npresent paper, so we skip a further discussion.\nTheorem 2. Suppose that the zig-zag diagram (4) is forward-moving\nand the optimal value function of $C_n$ is monotonic. Then, following\nthe individually calculated policies $\\pi_i$ on each component $M_i$ gives\nan optimal policy on the composite MDP $C_n$."}, {"title": "4.2 Experiments", "content": "To support the categorical formalism through experiments, we tasked\nRL agents with four distinct manipulation challenges (figure 1) using\nrobosuite [48, 4].\nTask 1 Lift a block The robot lifts a single block:\nThe experiments within the robosuite simulator demonstrate a com-\npositional approach to RL by integrating category theory. This inte-\ngration emphasizes the use of zig-zag diagrams as an efficient deno-\ntational tool. The resulting compositional RL technique provides a\ndirect method for sequential decision-making and introduces modu-\nlarity in robotic tasks, adding precision to learning.\nThe practical strengths of mapping computational tasks to mathe-\nmatical objects manifest in the following properties.\nCompositionality: When tasks break down into sub-tasks, the se-\nmantics guarantee that the entirety's meaning is an aggregation of\nits components, streamlining the synthesis of intricate tasks from\nfoundational ones.\nScalability: Scaling up and integrating new computational tasks\nbecomes unambiguous.\nInteroperability: Employing a common mathematical framework\nensures consistent and modular understanding across varied sys-\ntem compositions."}, {"title": "4.2.1 Zig-zag Task Composition and Reward Structure", "content": "In the context of the zig-zag diagrams and the categorical formalism,\neach manipulation task corresponds to an environment $M_i$, and its\nseries of sub-tasks align with the subprocesses $N_i$. We have a de-\nfined dense reward signal $r_{\\text{dense}}$ and a set success criterion for every\nsuch sub-task. Meeting this success criterion implies the agent has\nreached a state within the subprocess $N_i$ and receives a task reward\n$r_{\\text{task}}$. However, if the agent meets the failure criterion, it signifies a\ndeviation from the intended subprocess path, resetting the agent to\nthe beginning of the task or environment $M_0$.\nEach sub-task within an environment $M_i$ is associated with a sub-\nprocess $N_i$, and we dedicate an individual RL agent to each such\nsubprocess. During training, the agent corresponding to the active\nsubprocess or sub-task samples an action records the subsequent ex-\nperience, and refines its policy. From the perspective of the categori-\ncal structure, this approach resembles traversing through the zig-zag\ndiagrams sequentially. Initially, with all agents set to random poli-\ncies, the training effectively starts with the environment $M_0$ and its\nassociated subprocess $N_0$. Only after achieving success in this ini-\ntial sub-task does the robot begin accumulating experiences in the\nsubsequent subprocesses or sub-tasks, moving through the diagram.\nHere are the settings for each sub-task MDP mapping to the zig-\nzag diagrams above."}, {"title": "4.2.2 Performance Evaluation of Subprocess Composition", "content": "Decomposing complex, long-horizon manipulation tasks into smaller\nsubprocesses enhances learning performance, as evidenced by suc-\ncess rate and convergence speed improvements. This improvement\nis captured through the formalism of zig-zag diagrams, which pro-\nvide a structured approach to understanding the relationship between\nsub-tasks within the larger task. In this framework, the zig-zag di-\nagrams represent the sub-tasks composition, connecting states and\ntransitions within the MDP. By systematically breaking down com-\nplex tasks, we enable more efficient learning and synthesis of solu-\ntions, leading to observed performance improvements.\nWe designed a robosuite environment wrapper using categorical\nconstructs to oversee and transition between sub-tasks. This wrapper\nfilters state vectors at each step, modifies actions per the defined sub-\ntask MDPs, and allocates dense rewards $r'^{\\text{dense}}$. Completing a sub-task\ntriggers a $r^{\\text{task}} = 10$ reward and transitions to the subsequent sub-\ntask. Upon task completion or environment termination, it reverts to\nthe initial sub-task. This approach of breaking a long-horizon control\ntask into shorter segments facilitates training individual RL agents\nfor each segment. For comparison, we train using a direct robosuite\nenvironment with a similarly constructed dense reward. Both meth-\nods use soft actor-critic [18], an advanced model-free RL algorithm.\nWe conduct experiments using 5 random seeds for each setting.\nThe category-theoretic compositional RL performs well in training\nsample efficiency and final model performance (figure 2). In the\nblock-lifting task, our method converges to a 100% success rate af-\nter 150k training steps, whereas the baseline method converges at\naround 225k steps. In a more challenging task like block-stacking,\nour method converges to over 90% success rate while the baseline\nmethod struggles to reach even a 50% success rate. The trend con-\ntinues to the nut-assembly and can-moving tasks where our method\nconsistently learns a better policy with fewer training steps.\nTask composition enables the reuse or recycling of existing trained\nsub-task policies. Because all four robosuite tasks involve the reach\nand lift sub-tasks, repetitive training can be avoided after training the\nblock-lifting task. Aside from direct reuse, where the trained poli-\ncies are directly used in the sub-task of a different environment, re-\ncycling could prove beneficial: the interactions and reward signals\nfrom the new sub-task are used to fine-tune the policy parameters.\nReusing the reach and lift skills allows our method to start training\ndirectly from the place sub-task, significantly improving sample effi-\nciency (figure 3). However, the final performance is lower than when\ncompositional RL is trained from scratch. When a second block is\npresent, the policies trained to lift a single block occasionally fail\ndue to the robot hand getting stuck on the other block. When further\nfine-tuning is performed, the lifting policies initially trained on the"}, {"title": "4.2.3 Limitations", "content": "A comprehensive compositional generalization benchmark is still\nlacking [28, 17]. This absence hinders the ability to systematically\nevaluate and compare the performance of different compositional RL\nalgorithms across a standardized set of tasks. If such benchmarks ex-\nisted, it would be straightforward to determine which algorithms are\nmore effective at generalizing from their training environments to\nunseen scenarios. Furthermore, the need for standardized evaluation\nmetrics for compositional generalization in RL adds another layer of\ncomplexity. Metrics that can accurately reflect the ability of an algo-\nrithm to leverage compositional structures in learning and decision-\nmaking processes are essential for advancing the field. This method-ological gap means that current algorithm comparisons rely on in-\nconsistent criteria or non-comparable tasks. We attempted to provide\na common baseline that does not compare sparse reward structures\nwith unfair dense reward structures. Future directions will attempt to\nderive a fair benchmark for compositional RL algorithms and com-\npare compositional RL algorithms with our proposal based on cate-\ngorical structures."}, {"title": "5 Related Work", "content": "Our work builds upon and extends a rich tradition in RL that explores\nthe structure and abstraction in decision processes [23, 35, 36] and\nrecent developments in applied category theory [1, 5, 6, 7, 11, 19, 20,\n45, 46, 47]. Seminal contributions on minimalization have laid foun-\ndational concepts for understanding state and action abstractions in\nMDPs [16]. Similarly, the work on factored and propositional rep-\nresentations has been pivotal in advancing structured solution tech-\nniques and symbolic dynamic programming [9, 10]. Additionally,\nwork on the theoretical underpinnings of structured solution tech-\nniques in RL provides a way to synthesize behaviors [43].\nIn hierarchical reinforcement learning (HRL), significant formal\nmodels have been developed that go beyond the heuristic layering\nof policies. These models provide structured approaches to defining\nsubtasks and subgoals, facilitating multi-task learning and systematic\nproblem decomposition [33, 13, 34, 31]. Our categorical approach\naims to integrate these hierarchical structures within a unified math-\nematical framework, offering a complementary perspective on task\ncomposition and policy integration.\nBuilding on foundational principles, compositionality in RL has\ntraditionally focused on temporal and state abstractions to execute\ncomplex behaviors and enhance learning efficiency through mech-\nanisms such as skill chaining [40, 42, 22, 21, 28]. In contrast, our\ncategorical formalism introduces a shift towards functional compo-\nsition in RL. This approach leverages the denotational nature of cat-\negory theory to decompose tasks into distinct behavioral functions,\nproviding a more structured and mathematically rigorous framework\nfor task decomposition than previously available.\nThis functional approach offers granularity and aligns with con-\ntemporary efforts in robotics and policy modularization. For in-\nstance, it complements methods used in robotics tasks [12], where\ndecomposing complex behaviors into simpler, manageable units is\ncrucial. Similarly, it supports the development of modular neural ar-\nchitectures for policy learning [29], where each module can be under-\nstood and optimized independently. Our framework enriches these\nefforts by providing a formal language of zig-zag diagrams, which\naids in the systematic composition and decomposition of tasks and\npolicies. This diagrammatic language not only enhances the inter-\npretability of complex decision-making structures but also ensures\nthat these structures can be rigorously analyzed and validated within\na coherent theoretical framework.\nOur categorical formalism addresses the need for a unified and rig-\norous mathematical framework that can encapsulate and generalize\nthe concepts of MDP homomorphisms and task composition. Unlike\nprevious works, our approach leverages the semantics of category\ntheory to provide a systematic structure for decomposing and recom-\nposing tasks and policies. This is achieved through the introduction\nof categorical operations such as pushouts, which we prove exist for\nMDPs and serve as a novel method for task integration.\nWe extend the work on probabilistic representations in category\ntheory, moving beyond the stochastic process descriptions [15, 44]\nand recent categorical treatments of MDPs [3, 14]. Our framework\nnot only models the dynamics of decision processes but also provides\na compositional toolset for functional decomposition in RL, which\nhas been less explored in the existing literature.\nIn this paper, we examine how the categorical approach can en-\nhance RL systems' modularity, scalability, and interoperability. By\nproviding a rigorous mathematical structure for task and policy com-\nposition, our approach offers potential improvements in learning ef-\nficiency and adaptability in complex environments. However, we\nalso acknowledge the challenges and limitations of applying abstract\nmathematical frameworks in practical RL scenarios."}, {"title": "6 Conclusion", "content": "In this work, we introduce an abstraction theory for compositional\nRL, underpinned by the formal construct of categorical pushouts\nin the context of MDPs. Our adoption of zig-zag diagrams is a\nstructured way to visualize and analyze the complex interdepen-\ndencies between tasks and subprocesses within RL systems. Zig-\nzag diagrams are but one way to describe and synthesize sequential\ndecision-making problems.\nThe categorical formalism we propose offers a denotational lan-\nguage that aids in precisely modeling decision-making scenarios in\ngeneral, robotic tasks being only one of the application domains. The\nempirical results from our experiments indicate that this approach\ncan lead to improvements in learning precision and sample efficiency.\nHowever, it is essential to mention that these findings are contextual\nand derived from specific task settings in controlled environments.\nAs we look to the future, the application of category theory in RL\npresents a promising avenue for research with the potential to address\nseveral open problems in compositional RL: task synthesis, general-\nization, and interpretability, to name a few. However, its broader im-\npact and utility remain to be fully explored. We anticipate that further\nstudies will be necessary to validate the scalability of this approach\nacross diverse and more complex scenarios. Our ongoing research\nwill refine this framework's theoretical tools and constructs to en-\nhance their robustness and applicability."}]}