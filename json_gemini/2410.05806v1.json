{"title": "A Parameter Update Balancing Algorithm for Multi-task Ranking Models in Recommendation Systems", "authors": ["Jun Yuan", "Guohao Cai", "Zhenghua Dong"], "abstract": "Multi-task ranking models have become essential for modern real-world recommendation systems. While most recommendation researches focus on designing sophisticated models for specific scenarios, achieving performance improvement for multi-task ranking models across various scenarios still remains a significant challenge. Training all tasks na\u00efvely can result in inconsistent learning, highlighting the need for the development of multi-task optimization (MTO) methods to tackle this challenge. Conventional methods assume that the optimal joint gradient on shared parameters leads to optimal parameter updates. However, the actual update on model parameters may deviates significantly from gradients when using momentum based optimizers such as Adam, and we design and execute statistical experiments to support the observation. In this paper, we propose a novel Parameter Update Balancing algorithm for multi-task optimization, denoted as PUB. In contrast to traditional MTO method which are based on gradient level tasks fusion or loss level tasks fusion, PUB is the first work to optimize multiple tasks through parameter update balancing. Comprehensive experiments on benchmark multi-task ranking datasets demonstrate that PUB consistently improves several multi-task backbones and achieves state-of-the-art performance. Additionally, experiments on benchmark computer vision datasets show the great potential of PUB in various multi-task learning scenarios. Furthermore, we deployed our method for an industrial evaluation on the real-world commercial platform, HUAWEI AppGallery, where PUB significantly enhances the online multi-task ranking model, efficiently managing the primary traffic of a crucial channel.", "sections": [{"title": "I. INTRODUCTION", "content": "Multi-task learning (MTL) is a powerful technique widely applied to various recommendation systems [1]\u2013[6], including e-commerce, social media, news/video feeds, and online advertising. For instance, in e-commerce, a ranking model can be trained on multiple related tasks, such as predicting user ratings, click-through rate, and purchase likelihood. This model learns shared representations of users and items, which can be used to make personalized recommendations. Similarly, in social media, an MTL model can be trained on tasks such as predicting user engagement with posts, comments, and likes.\nMTL has demonstrated significant potential for enhancing the accuracy of recommendation systems and user experience.\nCurrent multi-task models often share some parameters across all tasks to learn shared representations and then use task-specific parameters to predict multiple labels. However, the intricate and competing correlations among tasks may result in inequitable learning if all tasks are naively trained together. This problem is also known as the seesaw problem [7], where improving performance in one task comes at the expense of other tasks. A major reason behind this issue is conflicting gradients [8], meaning the gradients of different task are not well aligned. As a result, following the average gradient direction can be detrimental to the performance of specific tasks. To address this issue, many multi-"}, {"title": "II. RELATED WORK", "content": "MTL simultaneously learns the tasks by minimizing their empirical losses together. It is common for some specific tasks to be learned well while others are overlooked, i.e, the seesaw problem. A main symptom of the seesaw problem is poor overall performance. In this section, we briefly discuss two main categories of MTL methods.\nMulti-task optimization (MTO) tries to find task weights that are multiplied by the raw losses for model optimization. Generally, MTO methods can be divided into two categories [15], Gradient Balancing and Loss Balancing.\nGradient Balancing Method (GBM) attempts to alleviate mutual competition among tasks by combining the per-task gradients of shared parameters into a joint update direction using a particular heuristic. Existing methods typically search for task weights based on a mathematical theory, such as Pareto optimality, which theoretically implies the potential for great generalization of these methodologies [16]. MGDA [9] casts multi-task learning as multi-object optimization and finds the minimum-norm point in the convex hull composed by the gradients of multiple tasks. MGDA-UB [17] proposes an approximation of the original optimization problem of MGDA to improve efficiency. PCGrad [18] avoids interference between tasks by projecting the gradient of one task onto the normal plane of the other. CAGrad [8] optimizes for the average loss while explicitly controlling the minimum decrease rate across tasks. GBMs can evenly learn task-shared parameters while ignoring task-specific ones, making them perform poorly when the loss scale of tasks is huge [14]. IMTL [13] and NashMTL [12] are loss scale-free GBM. IMTL-G makes the aggregated gradient have equal projections onto individual tasks, and IMTL-L scales all task-specific loss to be same. NashMTL uses the Nash bargaining solution to make tasks negotiate and reach an agreement on a joint direction of parameter update in the ball of fixed radius centered around zero. The strict restrictions of above two methods make them unable to consistently improve the MTL model.\nLoss Balancing Method (LBM) uses a delicate heuristic to integrate losses of various tasks based on certain assumptions. Uncertainty weighting [19] models the loss weights as data-agnostic task-dependent homoscedastic uncertainty. Then loss weighting is derived from maximum likelihood estimation. GradNorm [20] learns the loss weights to enforce the norm of the scaled gradient for each task to be close. BanditMTL [21] adds the variance of task losses to regularize optimization, but it focuses on the task with a large loss scale. To balance the loss scale, it needs to adopt some tricks. LBMs often have higher efficiency than GBM, and some LBMs, such as GradNorm, can prevent MTL from being biased in favor of tasks with large loss scales. FAMO [22] is a fast adaptive multi-task optimization method, using a dynamic weighting method that decreases task losses in a balanced way using O(1) space and time. We also compare PUB with several SOTA loss balancing baselines in our experiments.\nUpdate manipulation method (UMM) Besides the MTO methods, there are another type methods called update manipulation method. They limit the updates computed by gradient to prevent issues such as instability, over-fitting in multi-task learning by some heuristics. Popular methods that incorporate UMM include gradient clipping [23], [24], learning rate warmup [25], [26], and layer normalization [27]. AdaTask [28] utilizes task-specific accumulative gradients when adjusting the learning rate of each parameter, which can alleviate the dominance problem during training. Clippy [6] tries to mitigate instability by using L\u221e norm on updates instead of gradient, which has been adopted on YouTube multi-task ranking model. Theoretically, PUB is flexible and can integrate UMMs easily."}, {"title": "III. STATISTIC ANALYSIS", "content": "In this section, we try to identify the reason why existing MTO methods could not mitigate seesaw problem in some multi-task ranking datasets. We further design statistical experiments to verify our observation of several GBMs in benchmark CTR and CTCVR ranking datasets."}, {"title": "A. Root Cause and Evidence", "content": "We aim to answer the following research question: (RQ) Does the joint gradient obtained by conventional GBMs leads to the optimal parameter update in multi-task ranking models?\nPresumption. We hypothesis that the relationship between gradient and update is relatively optimal when considering only the impact of a single task gradient, such as the relationship within task-specific parameters. Thus, we can compare the relationships between shared parameters and task-specific parameters to determine whether updates on shared parameters are as effective as updates on task-specific parameters.\nExperiment setting. We conducted extensive experiments using four different methods and three different MTL models in four country AliExpress datasets (US, NL, ES and FR), which contain two tasks: CTR and CTCVR prediction.\n\u2022\n\u2022\nMTO methods: Linear scalarization (LS,\u2211ili), MGDA, IMTL-G and NashMTL\nMTL model: Shared bottom, MMOE and PLE\n\u2022\nOptimizer: Adam\nWe systematically explored all combinations, and tested each setting three times with different random seeds. As a result, 144 experiments are conducted in total. During each experiment, we collected gradient and update of all parameters at every training step from the first step to the end of epoch which get the best overall result in validation dataset.\nA common used metric (called Diff in this paper) is adopted to measure difference between the relationship on task-specific and shared parameters.\n$Diff = \\frac{2 |Sim_{task} - Sim_{share}|}{|Sim_{task} + Sim_{share}|}$"}, {"title": "IV. PRELIMINARY", "content": "In this section, some important concepts and notations are introduced for clearly understanding. Below, we summarize some important concepts for Multi-task learning. Additionally, we display some important notations in Table II."}, {"title": "Pareto Optimal and Pareto front", "content": "Pareto optimality is a situation where no action or allocation is available that makes one individual better off without making another worse off\u00b9. A solution x dominates x' if it is better on one or more objectives and not worse on any other objectives. A solution that is not dominated by any other is called Pareto optimal, and the set of all such solutions is called the Pareto front. How to identify Pareto front is called Pareto optimal problem."}, {"title": "V. METHOD", "content": "Based on Section III, we know that without gradients of other tasks, update obtained by task gradient (i.e.\u2206\u03b8\u2081 =\nf(g)) is sufficient for the multi-task ranking. In this section, we detailed describe PUB an efficient method to obtain optimal update. In this section, we first describe PUB algorithm in general to give a overall picture. Then we formalize the update balancing problem as a convex optimization problem. Lastly, we describe the method to efficient approximate the convex optimization problem."}, {"title": "A. PUB Algorithm", "content": "Utility Definition. We define the utility function for each task as $u_i(\u03b8) = \\langle \\Delta \u03b8_i, \\Delta \u03b8 \\rangle, \\forall i, u_i \\in \\mathbb{R}$. Intuitively speaking, higher utility $u_i(\u03b8)$ of task i means better optimization for the task at current training step. Thus, each task desires to"}, {"title": "B. Formalizing PUB as Convex Problem", "content": "Next, we formalize parameter update balancing as a convex problem. We provide the proof for our claim that the solution of update combination step is same as $D^T D \u03b1 = 1/\u03b1$. Given shared parameters \u03b8 of a MTL model, we aim to find an update vector \u2206\u03b8(t) at training step t within the ball of radius \u2208 $B_\\epsilon$ (omitting superscript t in the following). We presume that if \u03b8 is not Pareto stationary then the task updates are linearly independent [12]. Therefore, if \u03b8 is not on the Pareto front, the unique solution has the following form:\nClaim 1. Let D be the d x n matrix whose columns are the task parameter updates \u2206\u03b8i, where d is shared parameters number and n is task number. The solution to argmax\u2206\u03b8\u2208B\u03b5 \u03a3i log(\u2206\u03b8T\u2206\u03b8i) is the solution to $D^T D \u03b1 = 1/\u03b1$ where \u03b1 \u2208 R and 1/\u03b1 is the element-wise reciprocal.\nOur proof assume that: 1) without gradient of other tasks, update obtained by task gradient (i.e.\u2206\u03b8i = f(gi) where f is the optimizer) is optimal for the task. 2) if \u03b8 is not Pareto stationary then the gradients are linearly independent [12]. It should be noted that when computing \u2206\u03b8i the moments of optimizer are constants, making \u2206\u03b8i independent as well.\nProof. The derivative of this objective is \u03a3T1 \u2206\u03b8T \u2206\u03b8i. For all vector \u2206\u03b8 such that \u2200i : \u2206\u03b8T \u2206\u03b8i > 0 the utilities are monotonically increasing with the norm of \u2206\u03b8. Thus, the optimal solution has to be on the boundary of B\u03b5. From this we see that the update at the optimal point \u03a3T1 1/ai \u2206\u03b8T \u2206\u03b8i must be in the radial direction, i.e. \u03a3T1 1/ai \u2206\u03b8T \u2206\u03b8i = \u03bb\u2206\u03b8. Since we have \u2206\u03b8 = \u03a3i \u03b1i \u2206\u03b8i, and the updates of different tasks"}, {"title": "C. Efficient approximate method", "content": "Thirdly, we design a method through a sequence of convex optimization problems to efficiently approximate the optimal solution for $D^T D \u03b1 = 1/\u03b1$.\nTo begin, we define \u03b2i(\u03b1) = \u2206\u03b8Ti D\u03b1. Ideally, if we get optimal solution \u03b1, we can obtain \u03b2i for all i by \u03b2i = 1/ai. Equivalently, we can express log(ai) + log(\u03b2i) = 0. Therefore, we introduce the following function, and our objective is to find a non-negative \u03b1 such that \u03c6i(\u03b1)\n$\\varphi_i(\u03b1) = log(a_i) + log(\u03b2_i)$\nTo get optimal solution \u03b1, we consider the following optimization problem:\n$min_{\\alpha} \\sum_i \\varphi_i(\u03b1)$\ns.t. \\alpha_{i,} - \\varphi_i(a) \\leq 0$\n$\\alpha_i > 0$\nNext, we employ an iterative first-order optimization algorithm to tackle the aforementioned optimization problem more efficiently. Specifically, we replace the concave term \u03c6i(\u03b1) with its first-order approximation\n$\\varphi_i(\u03b1^{(\u03c4)}) = \\varphi_i(\u03b1^{(\u03c4)}) + \\nabla \\varphi_i(\u03b1^{(\u03c4)})(\u03b1 - \u03b1^{(\u03c4)})$\nwhere \u03b1(\u03c4) is the solution at iteration \u03c4. It is worth noting that we only modify \u03c6 to in the objective function, while keeping the constraint on \u03c6, resulting in an optimized problem can be rewritten as follows:\n$min_{\\alpha} \\sum_i \\varphi_i(\u03b1)$\ns.t. \\alpha_{i,} - \\varphi_i(a) \\leq 0$\n$\\alpha_i > 0$\nThis sequential optimization approach is a variant of the concave-convex procedure (CCP) [31], [32], so we can leverage existing tools, such as CVXPY [33], to get the critical points of \u03b1(\u03c4) for every step \u03c4. Furthermore, since we do not modify the constraint, \u03b1(+) always satisfies the constraint of original problem for any given step \u03c4.\nComplexity Analysis. According to the page 48 of [34], we would like to report the complexity of PUB as follows: If we compute the value of parameter \u03b1 in every training step, there will be O((n + \u03c4)d + \u03c42) additional computation, where n is the number of tasks, \u03c4 is the iteration steps with the maximum 200 in our experiments, d is the number of shared parameters. In practice, we compute the value of parameter \u03b1 in every s \u2208 {10,100} training steps to accelerate training, and the total training time cost is lower than the compared methods."}, {"title": "VI. EXPERIMENTS", "content": "We conducted experiments in two publicly benchmark datasets and deployed our PUB algorithm in a commercial platform. The public datasets contains both CTR&CTCVR prediction and scene understanding."}, {"title": "1) Public Datasets", "content": "For CTR&CTCVR prediction, we experiment in the AliExpress Dataset\u00b2. This dataset collects user logs from the real-world traffic in the AliExpress e-commercial platform. We use data from four countries: the Netherlands, Spain, France and the USA. It contains two binary classification tasks: Click Through Rate (CTR) prediction and post-click conversion rate (CTCVR) prediction. For scene understanding, we follow the protocol of [12], [35] in the NYUv2 dataset [36]. It is an indoor scene dataset that consists of 1449 RGBD images, each with dense per-pixel labeling and 13 classes. It contains three tasks, semantic segmentation, depth estimation, and surface normal prediction. We use the dataset as a three tasks learning benchmark dataset."}, {"title": "2) MTL architecture", "content": "(1) MMOE [37] extends MOE to utilize different gates for each task to obtain different fusing weights in MTL. (2) PLE [7] develops both shared experts and task-specific experts, together with a progressive routing mechanism to further improve learning efficiency. In our experiments, all experts are single layer perceptron with same shape. MMOE backbone has two moe layers which both contain 8 experts. PLE has two moe layers too, and each moe layer contains 8 shared experts and 8 task-specific expert for every tasks. (3) Task Attention Network (MTAN) [35] is the architecture in scene understanding experiment. It adds an attention mechanism on top of the SegNet architecture [38]."}, {"title": "3) Implementation Details and Evaluation Metrics", "content": "For ranking datasets AliExpress, we trained two popular multi-task recommendation backbones, i.e. MMOE [37] and PLE [7] in all datasets using two independent tower with the multi-expert layer. The MMOE model contain eight shared single layer fully-connected network as expert networks, while the PLE model contains four shared expert networks and four task-specific expert networks for each task. We re-implemented Uncertainty, MGDA, NashMTL, BanditMTL, IMTL, CAGrad, PCGrad and FAMO, based on the open-source code\u00b3 of [22]. The learning rate was set to 1e-3 and weight decay to le-6, with a batch size of 4096. We adopt AUC [39] as the evaluation metrics, which is commonly used in CTR and CTCVR prediction. AUC measures the probability of a positive sample being ranked higher than a randomly chosen negative one. We also report average AUC of CTR and CTCVR as the overall performance."}, {"title": "Two tasks experiments in Recommendation Ranking", "content": "We first report results in the ranking datasets, which are shown in Table III. We report the result with best average AUC, and all results are averages over 5 times training with different random seeds. AUC improvement on the third decimal place can be considered as significant improvement for offline CTR or CTCVR prediction. We can draw several insightful conclusions:\n1) PUB significantly improves average AUC with both MMOE and PLE backbones in all 4 datasets, while only 2 out of 80 average AUC of baselines outperform MTL backbones. These results demonstrate that PUB largely alleviates seesaw problem [7] in ranking datasets.\n2) Besides, PUB outperforms SOTA baselines at all task metrics. These findings demonstrate the generality and effectiveness of our proposed method. In the Table III, we observe that some MTL backbones achieve the similar results at certain task metrics, but this actually presents the seesaw problem. Consequently, these backbones exhibit poor overall performance.\n3) PUB exhibits better robustness against unbalanced loss compared to other baselines. Although, on average, the loss of CTR is approximately 23 times larger than CTCVR, our method still reliably boosts backbones. Conversely, scale-free methods such as NashMTL and IMTL-G, are unable to consistently improve backbones.\nIn real-world applications, there may be some specific requirements besides alleviating the seesaw problem, such as improving CTCVR more for online advertising platforms. UMMs are commonly used methods to satisfy such special requirements. Fortunately, PUB is flexible and can integrate UMMs easily to accommodate such real-word special requirements. We will assess its capability in the upcoming experiment. It should be noted that conventional MTO methods are unable to integrate UMMs, since they are all based on gradient level tasks fusion or loss level tasks fusion.\nPUB with UMMs. To demonstrate flexibility of our proposed method, we evaluate PUB with two SOTA update manipulation methods, Clippy [6] and AdaTask [28]. We reimplement Clippy using Adam according to its paper based on the source code of Fairseq [40]. It should be noted that current UMMs are based on certain assumptions, so they may be ineffective in some datasets which do not meet the assumptions. Besides, these methods often require significant"}, {"title": "Experiment on Time Comsuming", "content": "To investigate the complexity of PUB, the average one epoch training time is shown on Table V. AliExpress_ES dataset contains 22326719 training samples. We searched task weights every 10 steps and batch size is 4096."}, {"title": "D. Industrial Evaluation", "content": "We further deployed PUB on a real-world commercial platform HUAWEI AppGallery, with hundreds of millions of active users every month, to investigate its effectiveness in a practical setting. The compared baseline is denoted as Mbase, which is a highly-optimized multi-tasks ranking model over years. Mbase adopts Adam optimizer to update trainable parameters. We equip it with PUB algorithm and denote it as Mpub. For online A/B testing on a key channel, 5% of the traffic are randomly selected as the control group and receive results from Mbase, while another 5% of the traffic are in the experimental group and receive results from Mpub. With continuous improvement, the proportion of Mpub traffic is gradually increased to 20%, 50% and eventually 100%. The North Star metric is effective cost per mille (eCPM), which is the result of dividing the ad revenue per banner or campaign by the number of thousand ad impressions. From Table VI, we observe that with the equipment of PUB algorithm, the Mpub model outperform the baseline method on both eCPM and CTR metircs, which increase revenue for the platform and enhance the experience for the users."}, {"title": "E. Three tasks experiments in scene understanding", "content": "To investigate the generalization of PUB, we also conducted experiments in scene understanding dataset. We should notice that every influential multi-task optimization approach conducts experiments on scene understanding. The experimental results for the three tasks in the scene understanding experiment are presented in Table VII. We re-implement our method and all baselines. All methods are trained three times with different random seeds by using the same protocol as [12].\nFrom Table VII, we can draw the following conclusions:\n1) PUB achieves a significant improvement at overall performance metric \u2206m% compared to SOTA. Although MGDA and FAMO outperform other baselines at surface normal, it still experiences seesaw problem. They focus"}, {"title": "VII. CONCLUSION AND FUTURE WORK", "content": "In this paper, we focus on multi-task optimization in ranking models with shared parameters. Our goal is not only to identify the causes behind the challenges posed by conventional multi-task optimization methods in addressing the seesaw problem in multi-task ranking, but also to propose an effective solution that efficiently alleviates this issue.\nFirstly, we thoroughly investigate the problem to understand why conventional methods fail to mitigate the seesaw problem. Our paper highlights a fundamental flaw in these methods: they assume that optimal joint gradients consistently result in optimal parameter updates with diverse optimizers. We substantiate this with statistical experiments in CTR and CTCVR ranking datasets, revealing significant discrepancies between actual updates and gradients on shared parameters when using Adam optimizer. Secondly, based on our understanding of the limitations of conventional methods in multi-task ranking, we propose PUB, a Parameter Update Balancing method designed to overcome these limitations. PUB is the first work to optimize multiple tasks through parameter update balancing in field of multi-task optimization. Lastly, our extensive experiments demonstrate the effectiveness of our method on both public ranking datasets and real-world commercial online recommendation system.\nFuture work. While the initial target of PUB is addressing problems in multi-task ranking, our proposed method shows great potential in other multi-task learning tasks, as it outperforms state-of-the-art general MTO baselines on both ranking and scene understanding datasets. Subsequently, we aim to evaluate the effectiveness of PUB across a wide range of multi-task learning tasks and establish theoretical guarantees for convergence. Lastly, we will conduct more exploration in theory to deeply understand our proposed method, such as converge analysis and updating the moment vectors."}]}