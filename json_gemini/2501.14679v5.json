{"title": "Surface Vision Mamba: Leveraging Bidirectional State Space Model for Efficient Spherical Manifold Representation", "authors": ["Rongzhao He", "Weihao Zheng", "Leilei Zhao", "Ying Wang", "Dalin Zhu", "Dan Wu", "Bin Hu"], "abstract": "Attention-based methods have demonstrated exceptional performance in modelling long-range dependencies on spherical cortical surfaces, surpassing traditional Geometric Deep Learning (GDL) models. However, their extensive inference time and high memory demands pose challenges for application to large datasets with limited computing resources. Inspired by the state space model in computer vision, we introduce the attention-free Vision Mamba (Vim) to spherical surfaces, presenting a domain-agnostic architecture for analyzing data on spherical manifolds. Our method achieves surface patching by representing spherical data as a sequence of triangular patches derived from a subdivided icosphere. The proposed Surface Vision Mamba (SiM) is evaluated on multiple neurodevelopmental phenotype regression tasks using cortical surface metrics from neonatal brains. Experimental results demonstrate that SiM outperforms both attention- and GDL-based methods, delivering 4.8 times faster inference and achieving 91.7% lower memory consumption compared to the Surface Vision Transformer (SiT) under the Ico-4 grid partitioning. Sensitivity analysis further underscores the potential of SiM to identify subtle cognitive developmental patterns. The code is available at https://github.com/Rongzhao-He/surface-vision-mamba.", "sections": [{"title": "1 Introduction", "content": "Many methods have been developed for traditional Euclidean space data, such as Convolution Neural Networks (CNNs) and attention-based [Dahan et al., 2022; Zhao et al., 2024] approaches. CNNs use a regular convolutional kernel to slide over the input data, calculating the weighted sum at each location, while attention-based methods treat the data as a sequence of patches. However, few models exist for non-Euclidean data consist of graph, manifold and hyperbolic space data which have more complex geometries and distance"}, {"title": "2 Related Work", "content": "Non-Euclidean data, particularly spherical cortical surface data, is characterized by high resolution, rich features, and intricate geometric shapes, as the cortical surface is inherently a high-dimensional manifold. While these data provide valuable insights into neurodevelopment, their effective representation poses a formidable challenge, often requiring a balance between performance and computational efficiency. Inspired by the efficiency of Vim, we extend its application to cerebral cortex analysis\u2014an important yet underexplored area\u2014by proposing Surface Vision Mamba (SiM). To adapt SiM to the unique characteristics of cortical surface data, we adjusted the input sequence length using various surface patching methods, as illustrated in Figure 1.\nThe main contributions of this study can be summarized as follows:\n1. We introduce SiM, an adaptation of Vim, as a generic backbone network for analyzing data mapped onto genus-zero surfaces.\n2. Leveraging the suitability of Mamba for tasks with long-sequence and autoregressive characteristics [Yu and Wang, 2024], we explore the impact of varying input sequence length on surface data in non-Euclidean space. We further implement autoregressive pretraining to validate the effectiveness of this approach.\n3. Extensive experiments on three neurodevelopmental phenotype regression tasks, including the prediction of postmenstrual age (PMA) and long-term language and motor outcomes, demonstrate that our proposed SiM achieves promising performance compared to attention- and GDL-based models and is 4.8\u00d7 faster than SiT and saves 91.7% GPU memory when performing batch inference under the Ico-4 grid partitioning."}, {"title": "2.1 Geometric Deep Learning", "content": "Geometric Deep Learning (GDL) has emerged as a powerful tool for analyzing irregular geometries. While traditional CNNs specialize in processing Euclidean data, such as images, they are less effective for irregular data (e.g., cortical surfaces). GDL models extend CNNs to non-Euclidean domains, enabling the capture of intricate topological and geometric properties of the cortex. While these models excel in capturing local features, they often face challenges in learning long-range dependencies due to high computational costs or inherent architectural limitations, limiting their ability to model more complex relationships. Systematic comparisons of various GDL methods, such as MoNet [Monti et al., 2017], and Spherical UNet [Zhao et al., 2019], in brain phenotype prediction tasks have stressed these challenges."}, {"title": "2.2 Attention-based Methods", "content": "The self-attention mechanism, introduced in the Transformer [Vaswani, 2017], has revolutionized natural language processing (NLP) by capturing long-range dependencies. This architecture become the foundation for models like BERT [Devlin, 2018] and GPT [Floridi and Chiriatti, 2020]. Researchers extended self-attention to visual representation learning by splitting image into patches, known as the Vision Transformer (ViT) [Dosovitskiy, 2020]. The Swin Transformer [Liu et al., 2021] proposed hierarchical image merging via shifted windows, significantly improving efficiency and scalability for tasks like object detection and image segmentation. In medical image tasks, Surface Vision Transformer (SiT) [Dahan et al., 2022] was proposed to address irregular geometries, such as the cerebral cortex. Motivated by the asymmetric development of brain structure, the hemispheric relation inference network (HRINet) [Zhao et al., 2024] was designed to extract potential covariation relationships between bilateral hemispheres. However, the attention-based models not only struggle with quadratic time complexity relative to the sequence length, leading to significant computational costs in modeling dense, long sequences in NLP and high-resolution images in computer vision, but are also limited by quadratic space complexity owing to store all key-value pairs from previous sequences as its memory. To address these issues, numerous works have focused on reducing both quadratic time complexity and memory cost, as demonstrated in [Wang et al., 2020; Qiu et al., 2019; Han et al., 2023; Beltagy et al., 2020; Dao et al., 2022; Dao, 2023; Shah et al., 2024; Han et al., 2025; Han et al., 2024] by changing the operation of attention calculation, but cause a drop in performance."}, {"title": "2.3 State Space Models (SSMs)", "content": "The SSMs have recently been proposed to address key limitations of Recurrent Neural Networks (RNNs) [Medsker et al., 2001], particularly the challenges of non-parallelizable training and the tendency to forget earlier information as sequence length increases. The structured state space for sequence (S4) [Gu et al., 2021] employs the zero-order hold technique for discretization and High-order Polynomial Projection Operators (HiPPO) [Gu et al., 2020] to compress context into a smaller state. However, S4 is constrained by Linear Time Invariance (LTI), leading to limited ability to perform adaptive inference based on different inputs. In addition, S4 fails to prioritize and attend to the most critical parts owing to treat each segment equally. Mamba [Gu and Dao, 2023] incorporates a selective scanning mechanism, allowing the model to selectively extract relevant information depending on the inputs. Vim [Zhu et al., 2024] extended capabilities of Mamba to the computer vision domain, designing a generic vision backbone based on bidirectional SSM to address direction-sensitive problem, analogous to the ViT. Additionally, the Visual State Space Model (VMamba) [Liu et al., 2024] proposed a cross-scan module to bridge the difference between 1D array scanning and 2D plane traversal, enabling the adaptation of Mamba for visual data while preserving the size of the receptive fields."}, {"title": "3 Materials and Methods", "content": "The imaging data used in this work are from the publicly available Developing Human Connectome Project (dHCP) and the Gansu Provincial Maternity and Child-care Hospital (GPMCH). We used T1-weighted (T1w) and T2-weighted (T2w) images to calculate morphometric metrics of cerebral cortex.\nThe dHCP is approved by the United Kingdom Health Research Ethics Authority (reference number: 14/LO/1169). Additionally, we collected T1w and T2w images of 10 infants from the GPMCH (2020-GSFY-05). These images were acquired in the resolution of 0.8\u00d70.8\u00d71.6 mm\u00b3 with 0.8 mm overlap, and were reconstructed to 0.5 mm isotropic resolution.\nConcerning the data from dHCP, a total of 526 infants covering preterm- and term-born neonates ranging from 24 to 45 weeks postmenstrual age (PMA) are enrolled in our study. The neurodevelopmental assessments for these infants, conducted at 18 months of age using the Bayley-III Scales of Infant Development, can also be obtained. We used the following exclusion criteria: For PMA prediction, (i) we excluded the later scans of participants who were scanned twice to avoid the influence of extrauterine environmental factors; (ii) term-born neonates with focal abnormalities (radiology score > 2) were excluded to build a normative model for normal brain development assessment. The remaining infants were then split into two subsets: Subset 1: 408 participants who were born and scanned between 34 and 45 PMA; Subset 2: 16 preterm infants who were born before 34 PMA and scanned at term-equivalent age (> 37 PMA) for the evaluation of premature effects on brain development. For scaled language and motor scores prediction, we retained the scans closest to 40 weeks for neonates scanned twice identified as Subset 3: 410 infants born between 23 and 43 gestational weeks (GA). We further utilized data from GPMCH as a Replication dataset, consisting of 10 neonates born and scanned between 34 and 40 PMA, to evaluate the generalization ability of the models."}, {"title": "3.2 Preliminaries", "content": "SSMs are generally considered LTI systems that map an input stimulation u(t) \u2208 R^{N} to an output response y(t) \u2208R^{N} through a hidden state h(t) \u2208 R^{N}. The evolution of the hidden state over time is governed by parameter matrices A\u2208 R^{N \\times N}, B\u2208 R^{N \\times 1}, and C\u2208 R^{1 \\times N}. The system is mathematically described using a linear ordinary differential equation (ODEs) as follows:\n\\begin{equation}\n\\begin{cases}\nh'(t) = Ah(t) + Bu(t) \\\\\ny(t) = Ch(t)\n\\end{cases}\n\\label{eq:ssm}\n\\end{equation}\nwhere A is the state matrix to control the latent state h, B denotes the control matrix, and C is the output matrix. Equation (1) aims to predict the state of the system based on observed data. Since the input is generally continuous, the primary use of SSMs is in continuous-time representation. However, since computers struggle with processing continuous signals and the real data we used is typically discrete, the standard procedure is to discretize Equation (1) using the Zero-order hold (ZOH) method which assumes that the input signal remains constant between sampling intervals, formulated as:\n\\begin{equation}\n\\begin{cases}\nh_{t} = \\bar{A}h_{t-1} + \\bar{B}u_{t} \\\\\ny_{t} = Ch_{t}\n\\end{cases}\n\\label{eq:zoh}\n\\end{equation}\nwhere $\\bar{A}$ = exp($\\Delta A$) and $\\bar{B}$ = ($\\Delta A$)^{-1}exp($\\Delta A$ \u2013 I) \u00b7$\\Delta B$ are the discretized parameter matrices and $\\Delta$ is the discretization step size. The output y is then calculated using a global convolution kernel K\u2208 R^{L}, L is the input sequence length. The kernel is defined as:\n\\begin{equation}\n\\begin{cases}\nK = (CB, C\\bar{A}B, ..., C\\bar{A}^{k}B,...)\\\\\ny = u* K\n\\end{cases}\n\\label{eq:kernel}\n\\end{equation}\nwhere k \u2208 [0, L) indicates the sequence index."}, {"title": "3.3 Surface Vision Mamba", "content": "Given the interconnected nature of the brain, alterations within one region will inevitably influence others. To capture these long-range dependencies, we proposed the SiM model, as shown in Figure 2. Specifically, the input domain is divided into 2N patches, represented as $\\mathcal{X} = \\{L, R|L \\in R^{N \\times V \\times C}, R \\in R^{N \\times V \\times C'}\\}$, that V is the number of vertices in a patch, and C denotes the number of feature channels. This is then flattened to $\\mathcal{X} = \\{L, R|L \\in R^{N \\times (VC)}, R \\in R^{N \\times (VC')}\\}$. Next, we projected X into D-dimensional vectors using a trainable fully connected layer. Following the design of ViT and BERT, a learnable class token $X_{cls}$ is concatenated between the left and right hemispheres to represent the patch sequence. To retain positional information, standard 1D position embeddings $E_{pos}$ are added to the patch features.\nS_{0} = [\\{X_{L}^{1}\\}W;...;\\{X_{L}^{N}\\}W; X_{cls}; \\{X_{R}^{1}\\}W;...;\\{X_{R}^{N}\\}W]+E_{pos}  (4)\nwhere W\u2208 R^{(VC)\u00d7D}, $E_{pos}$ \u2208 R^{(2N+1)\u00d7D}, $S_{0}$ \u2208R^{(2N+1)\u00d7D} is the initial input of SiM, $X_{L}^{1}$ and $X_{R}^{N}$ represent the first patches of the left and right hemispheres, respectively. The implementation of SiM follows the same structure as Vim. Specifically, for a given layer l, the input from the previous layer $S_{l-1}$ is processed as follows:\n\\begin{equation}\n\\begin{aligned}\nS_{N} &= SiM(S_{l-1}) + S_{l-1}\\\\\nT &= LayerNorm(S_{N})\n\\\\\np &= MLP(T)\n\\end{aligned}\n\\label{eq:block}\n\\end{equation}"}, {"title": "3.4 Surface Patching Methods", "content": "The choice of surface patching methods can significantly affect model performance. In most Surface-based visual tasks, each face of a second-order icosphere (Ico-2) is commonly used as a patch, with all data points in the face treated as vertices. This approach splits the surface into 320 non-overlapping patches, each containing 153 vertices, with patches sharing only common edges. As Mamba has been indicated to perform well on tasks involving long-sequences, we extend the sequence length by progressively subdividing the icosahedron into finer discrete levels and evaluate different surface patching methods, including first- to third-order icosphere, as summarized in Table 2. The icosphere subdivision process involves three steps: (i) new vertices are inserted at the midpoints of edges from the previous subdivision level; (ii) new edges are generated between adjacent new vertices within the same face; and (iii) the newly added vertices are projected onto the circumsphere of the icosahedron. The different surface patching methods are visually represented in Figure 1. To evaluate the impact of patching methods, we use the Mean Absolute Error (MAE) as a performance metric"}, {"title": "3.5 Training Methods", "content": "Medical imaging datasets are often smaller than natural imaging datasets due to ethical, privacy, and legal restrictions on image acquisition, the variability in imaging equipment and parameter settings, and the challenges of annotating large datasets. To overcome these limitations, pretraining methods are essential for learning robust features, enhancing performance on downstream tasks. In this study, we explore three training strategies: (i) training models from scratch; (ii) fine-tuning pretrained weights from ImageNet (as released in Vision Mamba); and (iii) self-supervised pretraining for visual representation learning. Given the suitability of the Mamba architecture for autoregressive modeling [Ren et al., 2024], we adopt autoregressive approach for self-supervised pretraining, where the model predicts the next token based on preceding information. The performance of all three training strategies is evaluated using mean squared error (MSE) as the loss function."}, {"title": "4 Results and Discussion", "content": ""}, {"title": "4.1 Model Variants", "content": "The proposed SiM configurations are built upon three variants of Vim: Vim-Tiny, Vim-Small, and Vim-Base. Table 3 summarizes the architectural details of SiM. Concise notation is employed for model size and icosphere input size, e.g., SiM-B/3 represents the \"Base\" variant with an input size of 2560\u00d7180, using an Ico-3 grid on the sphere. With the constant resolution of Ico-6, higher-order icospheres yield finer-grained patches, enabling more precise analysis. This capability is peculiarly valuable in the medical imaging domain, where finer-grained insights are critical for capturing subtle variations related to diseases."}, {"title": "4.2 Infant Brain Age Prediction", "content": "As shown in Table 4, the comparison results of SiM against benchmark GDL methods [Fawaz et al., 2021; Vosylius et al., 2020] and attention-based models [Dahan et al., 2022; Zhao et al., 2024] on PMA prediction of Subset 1 on the three training strategies (see section 3.5). Notably, when fine-tuning with ImageNet pretraining weights, three variants of SiM outperform all the GDL methods using an Ico-3"}, {"title": "4.3 Long Sequence and Efficiency Analysis", "content": "Figure 3 illustrates the performance and efficiency of the tiny-sized SiM model across different surface patching methods. In terms of MAE, SiM slightly outperforms SiT across all other patching methods except when using an Ico-2 grid, and both models exhibit decreasing MAE as the icosphere order increases (Figure 3a). Regarding FPS (Frames Per Second), SiM is slightly slower than SiT when the icophere order is below 3 but surpasses it as the order increases (Figure 3b). For GPU memory usage, SiM exhibits better efficiency with SiT when icosphere orders raises. Notably, when using an Ico-4 as grid, SiM is 4.8 times faster and consumes 91.7% less GPU memory compared to SiT (Figure 3c). All experiments on efficiency analysis are conducted on a 40G A100 device. These results highlight the suitability of SiM for finer-grained tasks and its potential for practical clinical applications."}, {"title": "4.4 Cortical Regions with Significant Contributions to Age Prediction", "content": "We perform a sensitive analysis [Saltelli, 2002] on the test dataset of Subset 1 to evaluate the contribution of individual vertex on cortical surface to brain age prediction, as illustrated in Figure 4. For each vertex on the brain surface, we assessed four morphometric features (i.e., curvature, sulcal depth, cortical thickness, and myelination). \u201cAll\u201d nullifies all features, while other results nullify one feature at a time per vertex. Contributions were quantified by measuring performance changes before and after nullification, with larger shifts indicating greater impact.\nThe mean performance change for each vertex/feature was computed, normalized using Z-score, and visualized on the cortical surface (Figure 4). The intensity of the hot color signifies the influences of each vertex/feature. In the right hemisphere, key regions include the temporal lobe, precentral gyrus, and prefrontal and paracentral cortices. The left hemisphere shows a similar focus on the prefrontal cortex, sensory cortex, language areas, and parietal cortex when all features or only curvature are masked. Sulcal depth complements these findings by emphasizing the temporal lobe, central sulcus regions, and superior frontal and parietal areas. Cortical thickness and myelination highlight frontal regions, particularly the anterior insula, rostral middle frontal gyrus, and orbitofrontal cortex."}, {"title": "5 Conclusion", "content": "In this study, we introduced Surface Vision Mamba (SiM), a novel vision backbone with sub-quadratic time complexity, tailored for genus-zero surfaces. We validated SiM as a more robust and efficient alternative to SiT in the challenging task of neurodevelopmental phenotype prediction from cortical surface data. Leveraging the strengths of Mamba in handling long-sequence and autoregressive modeling, we extended sequence lengths using various surface patching methods and conducted autoregressive pretraining. While SiM demonstrated sensitivity to sequence length, the benefits of autoregressive pretraining were limited, likely due to constraints of small samples. The use of longer sequences facilitated finer-grained partitioning, enhancing the ability to identify potential pathological features critical in clinical applications. Furthermore, SiM offers faster inference speeds and lower GPU memory consumption, making it both efficient and practical. Sensitivity analysis also emphasized the interpretability of SiM, highlighting its potential utility in medical research and applications."}, {"title": "Ethical Statement", "content": "There are no ethical issues."}, {"title": "Appendix A. Implementation Details", "content": "All the experiments are implemented with Python 3.10.13 and PyTorch library and conducted on 4 NVIDIA A100 GPUs with batch size of 32. The Vim-Tiny\u2020, Vim-Small and Vim-Base weights are adapted to initialize our model that Vim-Tiny and Vim-Small are fine-tuned under long sequence but no open-source Vim-Base\u00b9 to use. The autoregressive pretraining for all model variants is performed using an Ico-3 grid and fine-tuned on the sequence obtained from other partitioning methods."}, {"title": "A.1. PMA Prediction Experiments", "content": "We assess the performance of our models in PMA prediction using the Subset 1 which is described in Table 1. For all the model variants and surface patching methods, all training details were presented explicitly in Table 5."}, {"title": "A.2. Scaled Language Score Prediction Experiments", "content": "Predicting long-term language scores is a challenging task, directly applying the PMA recipe does not work. We find that it is no need for a long schedule and provide our configuration in Table 6."}, {"title": "A.3. Scaled Motor Score Prediction Experiments", "content": "The training setting is in Table 7 and we observe that this to be akin to language score prediction. It is worth noting that a large warmup epoch can improve performance in some cases."}, {"title": "Appendix B. Additional Results", "content": ""}, {"title": "B.1. Decoder Design", "content": "We use SiM-T/3 for decoder architectures ablation experiments on subset 1, the fine-tuning MAE and MSE are summarized in Table 8. We first vary the decoder depth, and find that deeper decoders decreased performance. Further increase the decoder width, we find that performance improved when the dimension increased to 256, and then decreased."}, {"title": "B.2. Brain Development Analysis of Preterm Infant", "content": "To explore whether preterm birth affects brain development, we applied the SiM-S/3 (fine-tuned with ImageNet pretraining weights) to the Subset 2. The paired samples t-test was utilized to assess the difference between predicted brain age and chronological brain age. The result showed that predicted brain age in preterm infants was significantly lower"}]}