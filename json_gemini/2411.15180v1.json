{"title": "Multi-layer matrix factorization for cancer subtyping using full and partial multi-omics dataset", "authors": ["Yingxuan Ren", "Fengtao Ren", "Bo Yang"], "abstract": "Cancer, with its inherent heterogeneity, is commonly categorized into distinct subtypes based on unique traits, cellular origins, and molecular markers specific to each type. However, current studies primarily rely on complete multi-omics datasets for predicting cancer subtypes, often overlooking predictive performance in cases where some omics data may be missing and neglecting implicit relationships across multiple layers of omics data integration. This paper introduces Multi-Layer Matrix Factorization (MLMF), a novel approach for cancer subtyping that employs multi-omics data clustering. MLMF initially processes multi-omics feature matrices by performing multi-layer linear or nonlinear factorization, decomposing the original data into latent feature representations unique to each omics type. These latent representations are subsequently fused into a consensus form, on which spectral clustering is performed to determine subtypes. Additionally, MLMF incorporates a class indicator matrix to handle missing omics data, creating a unified framework that can manage both complete and incomplete multi-omics data. Extensive experiments conducted on 10 multi-omics cancer datasets, both complete and with missing values, demonstrate that MLMF achieves results that are comparable to or surpass the performance of several state-of-the-art approaches.", "sections": [{"title": "Introduction", "content": "Cancer is one of the major global health threats, with its high incidence and mortality rates making it a focal point of current medical research and public health efforts. Its occurrence and development are a biological change with a complex mechanism. Different subtypes of the same cancer may differ in histopathology and clinical features, but the heterogeneity of cancer mainly stems from its intrinsic molecular characteristics (Reis-Filho and Pusztai, 2011). Therefore, making full use of the intrinsic molecular characteristics of cancer to identify cancer subtypes will help achieve precision medicine for cancer.\nIn precision medicine, the molecular profile of a patient contains multiple molecules that belong to different omics (such as genomics, proteomics, metabolomics, etc.). These omics data reflects different biological processes, such as gene expression, protein function, metabolic pathways, etc. Early studies usually conducted statistics and research on one single omics data (Sotiriou et al., 2003). However, one single omics data can only reflect the cancer characteristics of a certain level of biological process (Etcheverry et al., 2010), and using different single omics data to address the same question may produce different results. For example, using mRNA expression data and Copy Number Variation (CNV) data to identify the subtype of breast cancer samples, the identification results are significantly different (Burgun and Bodenreider, 2008). Incompatible subtype classifications cannot have a positive effect on clinical treatment. For a heterogeneous disease like cancer, its occurrence and development are affected by different gene combinations and various factors, so only using single omics data cannot fully describe the complete information of cancer (Cai and Wang, 2024). Different omics data are combined to describe the patient's biological information, which is called \"multi-omics data\" (Subramanian et al., 2020). Currently, common multi-omics data includes CNV, mRNA expression, miRNA expression, DNA methylation, etc. (Shahrajabian and Sun, 2023). Multi-omics data can reflects the various biological processes in cancer. Effective mining and integration of multi-omics data can effectively make up for the shortcomings of single-omics data, thereby comprehensively understanding the occurrence and development of cancer (Kumar et al., 2024).\nCurrently, cancer subtype identification based on multi-omics data is mainly achieved through the integrated analysis of cancer sample data (Yang et al., 2022b). With the widespread application of machine learning, such as multi-view learning and deep learning, the current methods can be roughly divided into three categories: early integration, mid-term"}, {"title": "Method", "content": "MLMF mainly includes two modules, i.e. matrix factorization and optimizing consensus. Cancer subtyping is carried out on the consensus representation via spectral clustering algorithm. Each module and step will be detailed in the following sections."}, {"title": "Notation", "content": "Let $X = \\{X^{(1)}, X^{(2)}, ..., X^{(V)}\\}$ represents multi-omics dataset where V is the number of omics. $X^{(\\upsilon)} = \\{x_{1}^{(\\upsilon)}, x_{2}^{(\\upsilon)},..., x_{N_{\\upsilon}}^{(\\upsilon)}\\} \\in R^{D_{\\upsilon} \\times N_{\\upsilon}}$ is a collection of $N_{\\upsilon}$ data samples with dimension $D_{\\upsilon}$ in vth omics measurements, where $\\upsilon = 1, 2,..., V$. The consensus representation is $H = \\{h_{1}, h_{2}, ..., h_{N}\\} ^T \\in R^{N \\times d}$, where d is the ultimate dimension of consensus embedding space and N (N\u2265 Nv) is the sample size of total data. $||\\cdot||_F$ is the Frobenius norm.\nSince data may be missing, the sample index matrix $G^{(\\upsilon)}$ on each omics data is constructed as follows:\n$G_{ij}^{(v)} = \\begin{cases}1, & \\text{if } i\\text{th sample in } X^{(v)} \\text{ is the } j\\text{th sample in intact data} \\\\ 0, & \\text{otherwise} \\end{cases}$"}, {"title": "The framework of MLMF", "content": "As shown in Figure 1, MLMF mainly contains two modules. First, the deep semi-non-negative matrix factorization algorithm is used to perform multi-layer factorization of each omics data to obtain a deep low-dimensional representation. According to the mapping way, it can be formulated two strategies: linear mapping and nonlinear mapping. Then in the consensus representation module, indicator matrix is used to represent the missing status of some samples in the omics, and then fuses these representations into a consensus representation. The consensus representation retains as much original information as possible through the minimum reconstruction loss. Finally, cancer subtype is identified on consensus representation via spectral clustering."}, {"title": "Deep semi-non-negative matrix factorization", "content": "Non-negative matrix factorization (NMF) (Han et al., 2015) is a classic matrix factorization algorithm that adds non-negative"}, {"title": "Linear MLMF", "content": "The optimization objective function solved by Deep Semi-NMF can be extended from single-view data to multi-omics data. The optimization objectives are as follows:\n$\\min_{Z^{(v)}, H^{(v)}} \\sum_{v=1}^{V} ||X^{(v)} - Z_{1}^{(v)} Z_{2}^{(v)} ... Z_{m}^{(v)} H^{(v)}||_{F}^{2} + \\lambda_1 \\sum_{i=1}^{m} ||H_{i}^{(v)}||_{1}$\ns.t.$H^{(v)} \\ge 0$\n(5)\nAmong them, $H^{(v)}$ represents the m layer implicit of the v omics data, and the $\\sum_{i=1}^{m}||H_{i}^{(v)}||_{1}$ module is used to control the sparsity of $H^{(v)}$, and the specific formula is as follows:\n$\\sum_{i=1}^{m} ||H_{i}^{(v)}||_{1} = Tr[(H_{m}^{(v)})^T (H_{m}^{(v)}) E]$\n(6)\nE is a matrix with all elements equal to 1, and Tr() represents the trace operation of the matrix. Different from the common feature fusion method, the method proposed here first randomly initializes a consensus representation H, and then represents the feature data of each perspective based on the consensus representation. The mathematical expression is as follows:\n$H_{m}^{(v)} = H G^{(v)}$\n(7)\nAmong them, $G^{(v)}$ is the index matrix that records the missing data. By minimizing the reconstruction error, the purpose of optimizing the consensus representation H and the deep feature matrix $H_{m}^{(v)}$ of each omics data can be achieved. So the optimization goal of the reconstruction stage is defined as follows:\n$\\min_{H^{(v)}, H} \\sum_{v=1}^{V} ||H_{m}^{(v)} - H G^{(v)}||_{F}^{2}$\n(8)"}, {"title": "Algorithm 1 Algorithm of Linear MLMF", "content": "Input: multi-omics data X, trade-off coefficients $\\lambda_1, \\lambda_2$\nOutput: consensus representation H\n1: Construct an indicator matrix $G^{(v)}$ via Eq. (1)\n2: Initialize each matrix\n3: Update $Z_{i}^{(v)}$ according to Eq. (10)\n4: Update $H_{m}^{(v)}$ according to Eq. (11)\n5: Update $H_{i}^{(v)}$ (i < m) according to Eq. (12)\n6: Update H according to Eq. (13)\n7: Repeat steps 3-6 until convergence\n8: Return H\nTo sum up, the overall optimization object of linear MLMF can be written as:\n$\\min_{Z_{i}^{(v)}, H_{m}^{(v)}, H} \\sum_{v=1}^{V} ||X^{(v)} - Z_{1}^{(v)} Z_{2}^{(v)} ... Z_{m}^{(v)} H_{m}^{(v)}||_{F}^{2} + \\lambda_1 \\sum_{i=1}^{m} ||H_{i}^{(v)}||_{1} + \\lambda_2||H_{m}^{(v)} - H G^{(v)}||_{F}^{2}$\ns.t. $H_{i}^{(v)} \\ge 0$\n(9)\nAmong them, $\\lambda_1$ and $\\lambda_2$ are penalty trade-off coefficients. The problem is solved using the gradient descent method, which iteratively updates the variables to minimize the optimization objective function of MLMF. In each iteration, the parameter value is adjusted in the negative gradient direction according to the gradient information of the objective function relative to the parameter, and the step size is determined by the learning rate. This process continues until it converges to a local minimum or meets the stopping condition. The detailed solution process for each variable is shown in the Supplementary Note 1.\nFor $Z_{i}^{(v)}$ (1 \u2264 i \u2264 m), it is updated as follows:\n$Z_{i}^{(v)} = X^{(v)} \\Psi^T (\\Psi \\Psi^T)^{-1} \n(10)\nwhere $\\Psi = Z_{1}^{(v)} Z_{2}^{(v)} ... Z_{i}^{(v)}...Z_{m}^{(v)} H_{m}^{(v)}$, and $H_{i}^{(v)} = Z_{1}^{(v)}...Z_{i}^{(v)}...Z_{m}^{(v)} H_{m}^{(v)}$.\nFor $H_{m}^{(v)}$, it is updated as follows: For $Z_{i}^{(v)}$ (1 \u2264 i \u2264 m), it is updated as follows:\nA_{ik} = \\frac{A_{ik} \\sqrt{A_{ik} ^2}}{B_{ik} + (C - A)_{ik} \\sqrt{A_{ik} ^2} B_{ik} + (C + A)_{ik}}$\n(11)\nwhere A = $(H_{m}^{(v)})^T$, and I is the unit matrix. $B = \\Psi^T X^{(v)} + \\lambda_2 HG^{(v)}$, $C = \\Psi \\Psi^T + \\lambda_1 E + \\lambda_2 I$.\nFor $H_{i}^{(v)}$ (i < m), it is updated as follows:\nH_{ik}^{(v)} = H_{ik}^{(v)} \\frac{(\\Psi^T X^{(v)})_{ik} + ((\\Psi \\Psi^T) H_{m}^{(v)})_{ik}}{\\Lambda_{ik} ((\\Psi^T X^{(v)})_{ik} + ((\\Psi \\Psi^T) H_{m}^{(v)})_{ik})$\n(12)\nwhere $\\Psi = Z_{i}^{(v)} (Z_{i+1}^{(v)})... Z_{m}^{(v)}$.\nFor H, it is updated as follows:\nH = (\\sum_{v=1}^{V} H_{m}^{(v)} G^{(v) T}) (\\sum_{v=1}^{V} G^{(v)} G^{(v) T})^{-1}\n(13)\nSummarizing the above steps, the optimization process of the Linear MLMF is shown in Algorithm 1."}, {"title": "Nonlinear MLMF", "content": "By linearly decomposing the initial data distribution, it may not be possible to effectively describe the nonlinear relationship between the potential attributes of the model. Introducing nonlinear functions between layers can extract features for each potential attribute of the model, and the nonlinear functions are nonlinearly separable in the initial input space. After constructing the optimization target, the gradient descent method is used to solve it.\nFirst, construct the loss function. Compared with linear factorization, nonlinear factorization uses nonlinear mapping in all factorizations except the first layer. Nonlinear factorization decomposes the given data matrix X into m + 1 factors in a nonlinear way, as $X \\approx Z_{1} f(Z_{2} f(...f(Z_{m} H_{m})))$. $H_{m}$ is the m-level implicit representation of the data, which can be given by the following factorization:\n$H_{m-1} \\approx f(Z_{m} H_{m})$\n(14)\nThe optimization goal of the deep matrix nonlinear factorization model is as follows:\n$L = \\min_{Z_{i}^{(v)}, H_{m}^{(v)}, H} \\sum_{v=1}^{V} ||X^{(v)} - Z_{1}^{(v)} f(Z_{2}^{(v)} f (...f(Z_{m}^{(v)} H_{m}^{(v)}))))||_{F}^{2} + \\lambda_1 \\sum_{i=1}^{m} ||H_{i}^{(v)}||_{1} + \\lambda_2||H_{m}^{(v)} - H G^{(v)}||_{F}^{2}$\ns.t. $H_{i}^{(v)} \\ge 0$\n(15)\nThe problem is solved using the gradient descent method, which iteratively updates the variables to minimize the optimization objective function of MLMF. In each iteration, the parameter value is adjusted in the negative gradient direction according to the gradient information of the objective function relative to the parameter, and the step size is determined by the learning rate. This process cess continues until it converges to a local minimum or meets the stopping condition. The detailed solution process for each variable is shown in the Supplementary Note 2.\nFor $H_{i}^{(v)}$ (1 \u2264 i \u2264 m), it is updated as follows:\nH_{ik}^{(v)} = H_{ik}^{(v)} - \\alpha \\frac{\\partial L}{\\partial H_{i}^{(v)}}\n(16)\nwhere $H_{m}^{(v)} = H Z_{i}^{(v)}$.\nFor $Z_{i}^{(v)}$ (1 \u2264 i \u2264 m), it is updated as follows:\nZ_{ik}^{(v)} = Z_{ik}^{(v)} - \\alpha \\frac{\\partial L}{\\partial Z_{i}^{(v)}}\n(17)\nFor H, it is updated as follows:\nH = H - \\alpha \\frac{\\partial L}{\\partial H}\n(18)\nTo summarize the above steps, each variable is regarded as the only variable of the objective function, and its partial derivative is taken as the gradient. The variable is updated using the gradient descent method. The optimal solution is obtained by alternately updating the variables. The optimization process of the deep matrix nonlinear factorization algorithm is shown in Algorithm 2."}, {"title": "Spectral clustering", "content": "The consensus representation H is clustered using the spectral clustering method ((Von Luxburg, 2007)). First, a similarity"}, {"title": "Algorithm 2 Algorithm of Nonlinear MLMF", "content": "Input: multi-omics data X, trade-off coefficient $\\lambda_1, \\lambda_2$, step length \u03b1.\nOutput: consensus representation H\n1: Construct an indicator matrix $G^{(v)}$ via Eq. (1)\n2: Initialize each matrix\n3: Update $H_{i}^{(v)}$ (i < m) according to Eq. (16)\n4: Update $Z_{i}^{(v)}$ (i < m) according to Eq. (17)\n5: Update H according to Eq. (18)\n6: Repeat steps 3-8 until convergence\n7: Return H\nmatrix is constructed. This paper uses the k-nearest neighbor method to build the similarity matrix, expressed as follows:\nW_{ij} = \\begin{cases}0, & h_{i} \\notin nei(h_{j}) \\text{ and } h_{j} \\notin nei(h_{i}) \\\\ exp(-\\frac{||h_{i} - h_{j}||^2}{2\\sigma^2}), & h_{i} \\in nei(h_{j}) \\text{ or } h_{j} \\in nei(h_{i}) \\end{cases}\n(19)\nwhere \u03c3 is a tuning parameter to scale the similarity measure. The standardized Laplace matrix can be obtained as follows:\nL = D^{- \\frac{1}{2}} W D^{- \\frac{1}{2}}\n(20)\namong them, D is the diagonal matrix of W, calculated as $D_{ii} = \\sum_{j} W_{ij}$.\nThe third step is to to optimize the following objective function based on the Laplacian matrix L:\n$\\min_{B} Tr(B^T L B)$\ns.t. $B^T B = I$\n(21)\nwhere B is the indicator matrix, defined as $B = Y (Y^T Y)$. Among them, $Y = [Y_1, Y_2, ..., Y_k]^T$, $Y_i = [Y_{i1}, Y_{i2}, \u2026, Y_{ik}]$ is the clustering result, $Y_{ik} = 1$ means that the i-th sample belongs to the k-th class. I is the identity matrix, and the constraint $B^T B = I$ is to control each sample to belong to only one category. So the optimization problem is transformed into finding the eigenvectors corresponding to the first k smallest eigenvalues of the graph Laplacian matrix L. Then, the matrix B = $[b_1, b_2,..., b_k]$ is treated as a new data set with k-dimensional features and n samples for K-Means clustering, and the category to which each sample belongs can be obtained."}, {"title": "Results", "content": "Full muti-omics datasets\nSeveral computational experiments evaluate the effectiveness of cancer subtypes with multi-omics data. This paper conducts experiments on 10 cancer data sets of AML, BIC, COAD, GBM, KIRC, LIHC, LUSC, OV, SKCM and SARC of TCGA (Cancer Genome Atlas Research Network, 2008). Each data set includes mRNA expression, DNA methylation and miRNA expression data. The feature data after dimensionality reduction is standardized using z-score.\nThis article compares MLMF with ten algorithms are selected as comparisons methods on complete multi-omics data sets, including K-means and spectral clustering algorithms, as well as eight integration methods such as LRAcluster (Wu et al., 2015), PINS ((Nguyen et al., 2017), MCCA (Witten and Tibshirani, 2009), iCluster Bayes (Mo et al., 2018), SNF (Wang et al., 2014), SNFCC (Xu et al., 2017), NEMO (Rappoport"}, {"title": "Partial multi-omics datasets", "content": "To evaluate the performance of the method on some multi-omics datasets, this paper still selected the ten TCGA datasets analyzed above and simulated some patient loss omics measurements. Specifically, this paper maintains the complete expression of DNA methylation and miRNA, and randomly extracts samples from a part of patients to remove their mRNA expression, with missing rates of 0.1, 0.3, 0.5, and 0.7. Enrichment analysis and survival analysis are still used to evaluate the performance of the method.\nFrom Supplementary Table 1 and Supplementary Fig S3, MLMF_Linear and MLMF_Nonlinear performed better than NEMO and MCCA in survival and enrichment analysis at all missing rates. Under the same missing rate, the average performance of the nonlinear decomposition algorithm is better than that of the linear decomposition. These results indicate that MLMF can be well applied to situations where part of the omics is missing. In general, cancer subtyping by MLMF resulted in statistically significant survival spectrum differences and significant clinical enrichment. In addition, MLMF can effectively solve the challenge of missing parts of the omics.\nIn order to evaluate the efficiency of the MLMF algorithm, we compared the average running time of the MLMF_Linear algorithm and the MLMF_Nonlinear algorithm on the BIC dataset with ten algorithms, namely K-means, spectral clustering algorithms, LRAcluster, PINS, MCCA, iCluster Bayes, SNF, SNFCC, NEMO. As can be seen from Supplementary Fig S4, the fastest algorithm is spectral clustering and the slowest algorithm is iCluster Bayes. In general, the running time of the MLMF algorithm saves more time than the training model of the deep neural network, and the results are better than those of the ordinary clustering algorithm."}, {"title": "Conclusion", "content": "Predicting cancer subtypes using multi-omics data enables researchers and clinicians to adopt a more comprehensive and precise approach to patient treatment. Data from various omics offer distinct insights into biological processes, and by integrating these multi-omics datasets, researchers can uncover unique patterns and molecular features associated with different cancer subtypes. In this paper, we introduce MLMF, a multi-layer matrix decomposition method designed for cancer subtyping through the clustering of multi-omics data. For the first time, MLMF unifies the processing pipelines for complete and missing multi-omics data within a common framework. It performs multi-layer linear or nonlinear decomposition on the multi-omics feature matrix, breaking down the original data representation into respective latent feature representations. These representations are then fused to create a consensus representation. The identification of cancer subtypes is achieved through spectral clustering of this consensus representation. Experimental results from 10 TCGA multi-omics datasets demonstrate that MLMF outperforms other related methods. While our study focused on two to three histological levels, MLMF provides a versatile framework that can be easily adapted to scenarios involving additional omics data. We believe that MLMF holds significant promise for advancing precision oncology and enhancing patient outcomes."}]}