{"title": "CE-SDWV: Effective and Efficient Concept Erasure for Text-to-Image Diffusion Models via a Semantic-Driven Word Vocabulary", "authors": ["Jiahang Tu", "Qian Feng", "Chufan Chen", "Jiahua Dong", "Hanbin Zhao", "Chao Zhang", "Hui Qian"], "abstract": "Large-scale text-to-image (T21) diffusion models have achieved remarkable generative performance about various concepts. With the limitation of privacy and safety in practice, the generative capability concerning NSFW (Not Safe For Work) concepts is undesirable, e.g., producing sexually explicit photos, and licensed images. The concept erasure task for T21 diffusion models has attracted considerable attention and requires an effective and efficient method. To achieve this goal, we propose a CE-SDWV framework, which removes the target concepts (e.g., NSFW concepts) of T21 diffusion models in the text semantic space by only adjusting the text condition tokens and does not need to re-train the original T2I diffusion model's weights. Specifically, our framework first builds a target concept-related", "sections": [{"title": "1. Introduction", "content": "In recent year, large-scale text-to-image (T2I) models [39, 45, 47, 53, 69] have remarkable generative capabilities to synthesize realistic images. Unfortunately, the internet-sourced datasets used in training are often not rigorously filtered and frequently contain NSFW (Not Save For Work) concepts [26], and copyrighted materials [50]. Due to the limitation of privacy and safety in practice, these samples can cause models to learn and produce harmful content that could breach social norms.\nTo make generative models reasonably applicable, researchers have introduced the concept erasure task for T2I models, which prevents generated images from containing undesired concepts (i.e., target concepts [29, 34]). Typically, An optimal concept erasure method should balance the effectiveness [29, 34] and efficiency [31, 66]. Regarding effectiveness, the generated visual content must ensure target concepts suppression and irrelevant concepts preservation. In terms of efficiency, erasure methods should minimize both storage overhead and computational time. However, most model-based tuning methods [9, 11, 14-16, 18, 22, 24, 29, 35, 37, 57, 59, 63, 65] involve modifying model parameters and usually require additional parameter storage and training overhead. The recent text-based suppression method aims at suppressing information of target concepts in text embeddings, but predefining suppressed words hinders its effectiveness in special sentences (e.g., cases in Figure 1(a)). Our work focuses on the text-based suppression method, as it adjusts text conditions without modifying T2I models, thereby achieving high efficiency.\nTo suppress target concepts, the primary concerns are the accurate representation and precise removal of these concepts. Existing methods [29, 34, 59, 63] typically assume a link between target concepts and specific words (i.e., target words). These target words are encoded into target tokens and input into the generative models. For instance, to erase the sexual concept, researchers have constructed text conditions containing words like \"naked\" as study cases. However, such word-based concept representation presents two issues: 1) fails to accurately represent target concepts in biased [48] or memorized [29, 31] words; 2) fails to effec-"}, {"title": "2. Related Work", "content": "Existing research in T2I diffusion models can be broadly divided into four categories: training from scratch with curated datasets [36, 44], model-based tuning [9, 11, 14-16, 18, 22, 24, 29, 34, 35, 37, 57, 59, 63, 65], inference guidance [2, 48], and text-based suppression [31]. Retraining with curated datasets is impractical due to the substantial financial resources and significant time investment required. Model-based tuning involves modifying model parameters and usually requires additional parameter storage and training overhead. The inference guidance method adjusts conditional estimated noise during the sampling process but often fails in specific cases [34] within the I2P dataset [48]. In text-based methods, SEOT [31] constructs a matrix that includes both the text tokens to be erased and the EOT tokens, applying a soft-weighted regularization on the primary singular values to suppress the target concept information. However, this approach relies on prior knowledge of the specific words that need to be suppressed, making it ineffective when dealing with sentences that do not explicitly contain words related to target concepts. Our method can adaptively erase target concepts in text conditions without predefining words to be erased, facilitating the flexibility in diverse sentences."}, {"title": "2.1. Text-to-Image Synthesis", "content": "Text-to-image synthesis has evolved significantly over the years. Beginning with Generative Adversarial Networks (GANs)[13, 25, 43], these models can effectively generate faces and categorical objects but struggle to create complex scenes that align with textual conditions. Subsequent research explores the use of transformers [6, 13, 54] and diffusion models [3, 4, 10, 21, 36, 55], with their corresponding large-scale models demonstrating outstanding capabilities in generating high-fidelity images from textual descriptions. DALL-E [41] is trained on a large dataset of text-image pairs, utilizing autoregressive transformers to generate high-quality images from textual descriptions. SD v1 [45] employs conditional diffusion models to achieve superior generation capabilities on the LAION-2B [49] dataset. Moreover, SD v2 [45] is trained on a subset of LAION-2B, with data filtered by an NSFW detector. However, studies [34, 48] point out that SD v2 still learns NSFW concepts from the dataset and generate inappropriate and harmful content. In this context, our method aims to mitigate such issues by effectively removing undesired concepts from generative models, ensuring safer and more controlled image generation."}, {"title": "2.2. Concept Erasure in T2I Diffusion Models", "content": "Existing research in T2I diffusion models can be broadly divided into four categories: training from scratch with curated datasets [36, 44], model-based tuning [9, 11, 14-16, 18, 22, 24, 29, 34, 35, 37, 57, 59, 63, 65], inference guidance [2, 48], and text-based suppression [31]. Retraining with curated datasets is impractical due to the substantial financial resources and significant time investment required. Model-based tuning involves modifying model pa-"}, {"title": "2.3. Adversarial Prompt Attack", "content": "The adversarial prompt attack is a technique used to manipulate text prompts to deceive the model into generating content that bypasses its built-in constraints or safety filters. Adversarial attacks have been extensively studied in language models, with typical modifications including additions, deletions, and substitutions at the word level [23, 33, 61]. Recent research extends adversarial attack techniques to T2I diffusion models. CCE [38] leverages textual inversion [12] to learn specialized input word embeddings that bypass concept erasure methods. P4D [7] constructs adversarial prompts by optimizing prompt embeddings within a dual-model framework, aligning the outputs of an erased diffusion model with those of an unconstrained model to generate similar inappropriate content. UnlearnDiffAtk [67] utilizes the inherent classification abilities of diffusion models to generate adversarial prompts without requiring auxiliary models. Building on these approaches, subsequent studies [16, 27, 65] propose new frameworks that employ adversarial prompts to improve the erasure of target concepts by further training models. Our work effectively defends against adversarial prompt attacks without requiring multi-round training, achieving a good trade-off between effectiveness and efficiency."}, {"title": "3. Method", "content": "We propose CE-SDWV, a novel framework for concept erasure in T2I diffusion models that prioritizes both effectiveness and efficiency. Our approach aims to accurately suppress target concepts while preserving irrelevant ones, achieving high-quality generation with minimal overhead. Figure 3 presents an overview of our framework."}, {"title": "3.1. Semantic-Driven Concept Representation", "content": "The premise of the concept erasure task is the accurate representation of target concepts. Inaccurate concept representation can lead to unintended results during the erasure process, such as over-erasing irrelevant concepts or under-erasing target concepts. We assume that vocabulary serves as a concrete representation of concepts, and the embeddings of words processed by the text encoder contain certain components related to their associated concepts.\nWe employ a LLM to generate words associated with a specific target concept. Based on these initial words, we further request the model to generate corresponding synonyms to expand the vocabulary $V$. Using this expanded vocabulary, the LLM generates a sequence of sentences ${P}_{i=1}^{n}$.  Each sentence is encoded by a text encoder to obtain text token embeddings $c = \\{c_{SOT}, c_{nt}, c_{nt},..., c_{nt}, c_{T}, c_{T},..., c_{EOT}, c_{EOT},...\\}$, where $c_{nt}$ represents the irrelevant concept token and $c_{T}$ represents the target concept token. From these embeddings, we extract EOT [31] tokens \\{$c_{EOT}^{i}\\}_{i=1}^{n}$ and relevant text tokens\\{$c_{T}^{i}\\}_{i=1}^{n}$, building a token matrix $R_{t} \\in R^{N \\times d_{e}}$ related with the target concept, where $N$ is the token number and $d_{e}$ is the dimension of embeddings. However, due to the attention mechanism in the text encoder, each token in this matrix contains information from irrelevant concept tokens.\nTo obtain a more precise representation of the target concept, we perform singular value decomposition (SVD) on the matrix $R_{t}=U_{t} \\Sigma_{t} V_{t}^{T}$, extracting the top-k principal components in $E_{t}$, where $\\Sigma_{t} = diag(\\sigma_{0}, \\sigma_{1},..., \\sigma_{n_{1}})$, and the singular values satisfy $\\sigma_{0} \\geq ... \\geq \\sigma_{n_{1}}$. We hypothesize that these top-k components can effectively represent the target concept. Since each token in the matrix contains"}, {"title": "3.2. Adaptive Component Suppression", "content": "In this section, we focus on modifying the text embeddings to ablate the target concept. Compared to model-based tuning methods, this efficient approach does not require additional model training or parameter storage. However, precisely identifying which text tokens should be suppressed can be challenging, especially when attempting to remove specific sentences that lack explicit words related to the target concepts, as illustrated in Figure 1(a).\nTo this end, we propose erasing all tokens in the text conditions and introducing an adaptive component suppression method. For text condition tokens $\\hat{c} = \\{\\hat{c}_{0}, \\hat{c}_{1}, \u2026, \\hat{c}_{EOT}\\}$, we concatenate each text token $\\hat{c}_{i}$ with the semantic matrix $R_{t}$ to obtain the matrix $R$ and apply the SVD on $R$ to suppress the top-k components. Since the introduction of a single token $\\hat{c}_{i}$ has a negligible impact on the principal components of the matrix $R_{t}$, the information represented by the components of matrix $R_{t}$ and $R$ is essentially consistent. Thus, we set the principal components to zero and reconstruct the token embedding $\\hat{c}'$, which can effectively remove the concept represented by the semantic matrix $R_{t}$."}, {"title": "3.3. Gradient-Orthogonal Token Optimization", "content": "By accurately representing the target concept and effectively removing related information from each text token, the diffusion model can avoid generating content associated with the target concept. However, suppressing text tokens do not adapt well to the original image semantic space, resulting in low-quality detail generation for irrelevant concepts. Notably, the detail generation in diffusion models is closely linked to the sampling steps [68]. For example, when generating an image of a naked person, the initial sampling trajectory tends to align with the human manifold, forming a rough outline of the body. At the end of the sampling phase close to the generated data [8, 30, 42], specific details, such as facial features and sexual organs, start to be generated.\nTo maintain the quality of image generation while preserving the erasure effect, we propose an end-to-end gradient-orthogonal token optimization to refine the suppressed text tokens on the specific sampling steps. Specifically, for each text condition, we input both the text tokens before and after semantic suppression into the diffusion model, obtaining two predicted noises, denoted as $\\hat{\\epsilon}$ and $\\epsilon_{t}$. Here, $\\hat{\\epsilon}$ represents the original noise adapted to the original image space, with the target concept and irrelevant concepts included, whereas $\\epsilon_{t}$ is the noise after removing the target concept. Following the equation below, we aim to adjust the predicted noise $\\epsilon_{t}$ during the sampling time interval from $t_{e}$ to $T$ to adapt to the original image semantic space, thereby improving the detail generation with the conditions after suppression.\n$L_{noise-guide} = E_{t \\sim [t_{e}, T]} || \\hat{\\epsilon} - \\epsilon_{t} ||^{2}$  \nHowever, directly applying $L_{noise-guide}$ would inevitably undermine the effectiveness of the target concept erasure. Inspired by [60] reducing the mutual influence of different tasks in multi-task learning and [46] mitigating the forgetting of old tasks in continual learning, we propose adjusting the gradients of text conditions with the semantic space $S_{t}$ defined in Section 3.1. The reason behind this adjustment is that the gradient of the token embedding is a linear transformation of the embedding itself. [46]. If the embedding exists within a specific space $A$ (e.g., text space), the gradient must also lie within that space. Since the gradients of the loss function $L_{noise-guide}$ on text tokens represent the optimization direction towards the original noise, which contains information about both irrelevant concepts and the target concept, we utilize the semantic space $S_{t}$ to modify the gradients, retaining only the projection onto the complement space of the subspace. Thus, the suppressed tokens will only be optimized towards irrelevant concepts within the original image space. This adjustment is formally provided as follows:\n$g^{+} = g - Proj_{S_{t}}(g)$, \n$Proj_{S_{t}}(g) = gB_{t}(B_{t}^{T})$,  \nwhere $g = \\nabla_{\\hat{c}}L_{noise-guide}$ and $B_{t}$ is the bases of space $S_{t}$.\nUltimately, by applying orthogonal adjustments to the gradients of $L_{noise-guide}$, we refine the suppressed text tokens to better align with the image semantic space and enhance the detail generation for irrelevant concepts while preserving the erasure effect of the target concept."}, {"title": "4. Experiments", "content": "In this section, we conduct a comprehensive evaluation of our proposed method, benchmarking it against existing approaches on the I2P [48] and UnlearnCanvas [66] datasets to verify its effectiveness in concept erasure and the preservation of unrelated concept generation. Additionally, we employ UnlearnDiffAtk [67] to construct adversarial prompts, further assessing the robustness of our method."}, {"title": "4.1. Implementation Details", "content": "All experiments are conducted on the SD v1.4, with the DDIM sampler [51] set to 50 sampling steps. To ensure the fairness and reproducibility of the experimental results, we strictly adhered to the predetermined random seeds in the dataset. The optimal hyperparameters settings are discussed in detail in Section 4.6. Further details are provided in Appendix B."}, {"title": "4.2. Sexual Concept Erasure", "content": "Evaluation setup. This section focuses on erasing the sexual concept in T2I models. We apply a similar assessment to MACE [34], generating images for all 4703 sentences provided in the I2P [48] dataset. The NudeNet [5] is utilized to detect body parts related to sexual concept in these images, with a threshold set at 0.6. Additionally, we sample 30,000 captions from the MS-COCO validation set [32] to generate images and calculate the FID [19] and CLIP score [40], assessing the model's capability to generate regular concepts.\nAnalysis. Table 1 compares our method with baseline approaches in erasing sexual concepts. Our method detects the least amount of sexual content in the generated images, indicating its effectiveness. The I2P dataset contains numerous sentences that, while appearing unrelated to the target concept, still generate harmful content, such as \u201cassassin striking its victim by bouguereau\u201d in Figure 1. Methods like AC, FMN, MACE, and SA, which transforms unsafe words to anchor words, often struggle with the aforementioned sentences. Similarly, SEOT has difficulty accurately identifying which words to erase, resulting in incomplete removal of the target concept. We also observe"}, {"title": "4.3. Object Erasure", "content": "Evaluation setup. In this section, we mitigate the generation of specific objects in T2I models. Following [66], we conduct experiments using the fine-tuned SD v1.4 provided by UnlearnCanvas, forgetting each of the 20 object categories in the dataset. When a specific object is forgotten, the remaining object concepts are treated as in-domain, while style concepts are considered cross-domain. We generate five sets of images using the sentence \"an image of {object} in {artistic style} style.\u201d with different seeds. The generated images are classified using pre-trained object and style classifiers, and we calculate UA (Unlearning Accuracy), IRA (In-domain Retain Accuracy) and IRA (Cross-domain Retain Accuracy) metrics. UA indicates the proportion of images generated from sentences related to the target concept that are incorrectly classified into the corresponding category. IRA represents the classification accuracy for images generated from sentences related to the remaining concepts within the same domain. CRA represents the classification accuracy for images generated from sentences related to concepts across different domains. Additionally, we evaluate the efficiency of the erasure method from three aspects: time overhead, memory usage, and stor-"}, {"title": "4.4. Style Erasure", "content": "Evaluation setup. This section aims to address the erasure of artistic style concepts in T2I models. We use the same T2I model, pre-trained classifiers, and evaluation metrics as in Section 4.3. For the case of erasing a specific artistic style, the remaining style concepts are considered in-domain, while object concepts are treated as cross-domain.\nAnalysis. Table 2 compares different erasure methods in removing style concepts. Our method achieves an IRA of 98.62% for style concept erasure, which is the highest among all compared methods. This indicates that our approach is most effective at retaining integrity of other styles within the same domain when erasing a specific style concept. While ESD and UCE exhibit slightly stronger erasure capabilities than our method, their significant impact on generation capability for in-domain concepts reveals a major limitation. This trend is similarly observed in the"}, {"title": "4.5. Adversarial Attack", "content": "Evaluation setup. In this section, we explore the effectiveness of our method in fully removing the target concept from the model. We employ the advanced adversarial attack method, UnlearnDiffAtk [67], to generate adversarial prompts and assess the erasure performance. Following [67], we select 142 prompts from the I2P dataset with"}, {"title": "4.6. Ablation Study", "content": "In this section, we present a comprehensive ablation study on the I2P dataset to evaluate the effects of various components and configurations on our method's ability. More ablation studies are provided in Appendix C.\nTop-k principal components. We first study the effect of various principal components for selectively removing undesirable elements from generated images while maintaining overall image quality. In Figure 5, as we increase the number of principal components removed (from k = 1 to k = 9), there is a noticeable reduction in the presence of unwanted sexual content. Specifically, by k = 5, the sexual elements are effectively removed. We also observe that there is a slight degree of degradation in image quality, particularly at k = 7 and k = 9. Therefore, our findings suggest that an optimal balance must be struck, ideally around k = 5, where the target content is sufficiently suppressed"}, {"title": "5. Limitations and Conclusion", "content": "In this work, we propose CE-SDWV, an effective and efficient method for concept erasure in T2I diffusion models by modifying the text condition tokens. Extensive experiments indicate that CE-SDWV achieves an optimal balance between suppressing target concepts and preserving irrelevant concepts, while minimizing training time and storage requirements. However, despite effectively removing the visual content related to the target concept, there remain slight inconsistencies in the generated images before and after erasure, such as Figure 5 row one. Furthermore, extending our method to simultaneously erase multiple target concepts is a promising direction for future research."}]}