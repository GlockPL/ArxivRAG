{"title": "Generalization Ability Analysis of Through-the-Wall Radar Human Activity Recognition", "authors": ["Weicheng Gao", "Xiaodong Qu", "Xiaopeng Yang"], "abstract": "Through-the-Wall radar (TWR) human activity recognition (HAR) is a technology that uses low-frequency ultra-wideband (UWB) signal to detect and analyze indoor human motion. However, the high dependence of existing end-to-end recognition models on the distribution of TWR training data makes it difficult to achieve good generalization across different indoor testers. In this regard, the generalization ability of TWR HAR is analyzed in this paper. In detail, an end-to-end linear neural network method for TWR HAR and its generalization error bound are first discussed. Second, a micro-Doppler corner representation method and the change of the generalization error before and after dimension reduction are presented. The appropriateness of the theoretical generalization errors is proved through numerical simulations and experiments. The results demonstrate that feature dimension reduction is effective in allowing recognition models to generalize across different indoor testers.", "sections": [{"title": "I. INTRODUCTION", "content": "THROUGH-THE-WALL radar (TWR), especially its applications on indoor human activity recognition (HAR), is mainly used in disaster rescue, anti-terrorism, and health monitoring, which attracts many teams to take effort mining cutting-edge algorithm designs [1]. The micro-Doppler signature generated in the echoes can be used to achieve accurate motion feature extraction and activity recognition [2].\nRecent research results in the field of TWR HAR focused on the use of micro-Doppler signature to classify human activities, modeling different body parts of people behind walls, distinguishing, and predicting their intentions [1]. These methods ranged from heuristic models [3] to more sophisticated statistical learning techniques [4], [5], including principal component analysis (PCA), independent component analysis (ICA), empirical modal decomposition (EMD), and Hilbert-Huang transform (HHT). Frontier research had focused on the use of deep convolutional neural networks (CNN) for single-stage feature extraction and activity recognition through large-scale data training [6]. However, to solve the problem of high-precision extraction of fuzzy features from TWR imaging, the CNN-based recognition methods were improved by widening or deepening strategies, leading to a significant increase in spatial and temporal costs. Therefore, many lightweighting works were investigated [7], [8].\nAlthough existing methods address the issues of accuracy and resource cost, the models were highly dependent on the distribution of training data and difficult to generalize across various indoor testers. In our previous works, a series of generalized indoor HAR methods based on the downscaling of micro-Doppler corner feature were proposed [9], [10]. However, none of them presented a rigorous discussion on how much feature dimension reduction could actually optimize the model generalization error in theory. Therefore, the generalization ability analysis of TWR HAR is presented in this paper. In detail, an end-to-end neural network approach for TWR HAR is proposed, and its micro-Doppler corner representation improvement is presented. In addition, the analysis of the generalization error bounds of both methods are given, respectively, and the enhancement of model generalization ability by dimension reduction is theoretically demonstrated. Moreover, the reasonableness of the theoretical analysis is verified through numerical simulations and experiments."}, {"title": "II. FEATURE REDUCTION BASED ON MICRO-DOPPLER CORNER REPRESENTATION", "content": "As shown in Fig. 1, the generalization ability of TWR HAR is compared between two different features. The first is the TWR range and Doppler profiles directly generated by the signal and data processing modules. The second feature is the micro-Doppler corner representation, which is obtained by generating TWR range and Doppler profiles using the same signal and data processing modules and extracting the key points' coordinates on them using corner detection algorithm. Both features are fed into linear neural networks for recognition, and the generalization performance of them is compared by the training effect.\nIn signal processing module, the raw TWR echo in the frequency domain is first captured. Time-domain raw echo is then generated using the inverse Fourier transform (IFFT). Then, the extraction of the baseband time-domain echo signal is achieved by local oscillation mixing and low-pass filtering. The baseband echoes over a slow period of time are concatenated into a matrix, which is called range-time map (RTM).\nThe RTM is summed along the range axis and the short-time"}, {"title": "III. GENERALIZATION PERFORMANCE ANALYSIS", "content": "As shown in Fig. 2, assuming the concatenated input dataset to the model is x. Then the true loss to the model is:\n\\begin{equation}\nL_{true}(f) = E_{z\\sim P_T}[L(f, z)],\n\\end{equation}\nwhere $P_T$ is the distribution of data $x$. $L$ denotes the loss of model $f$ on a single data $z$ satisfying distribution $P_T$, where:\n\\begin{equation}\nf(W; x) = \\sigma_3 (W_3(\\sigma_2 W_2(\\sigma_1(W_1 x)))) \\stackrel{Def}{=} \\sigma W(x),\n\\end{equation}\nis the transfer function of the model. $W_i, i = 1,2,3$ are the weights and $\\sigma_i, i = 1,2,3$ are the activation functions in each layer. Similarly, the training loss of the model is:\n\\begin{equation}\nL_{train} (f; S) = \\frac{1}{|S|}\\sum_{z_i\\in S} L(f, z_i),\n\\end{equation}\nwhere $z_i$ is the $i$th sample in training data $S$. The generalization error of the model is defined as the difference between the true loss and the training loss [11]:\n\\begin{equation}\nGE = L_{true}(f) - L_{train} (f; S).\n\\end{equation}\nIn order to be able to quantify the bounds on the generalization error, the activation function in the model can all be assumed as Lipschitz continuous with the constant of $C$, and the loss function $L$ is assumed as Lipschitz continuous with the constant of $L'$. Define the maximum eigenvalue of $W_i$ as $\\lambda_i$. According to the triangular inequality, for any real vector $x, y$ with the same rows of $W_i$:\n\\begin{equation}\n||W_i(x) - W_i(y)||_2 = ||W_i(x - y)|| \\leq ||\\lambda_i(x - y)||_2 = \\lambda_i ||x - y||_2\n\\end{equation}\nThus, define $y = x+dx$ in the equation above, the sensitivity of the model to the data can be measured as:\n\\begin{equation}\n||f(W; x + dx) - f(W; x)||_2\\\\\n= ||\\sigma_3 W_3\\sigma_2 W_2\\sigma_1 W_1(x+dx) - \\sigma_3 W_3\\sigma_2 W_2\\sigma_1 W_1(x)||_2 \\\\\n< C\\lambda_3 ||\\sigma_2 W_2\\sigma_1 W_1(x + \\delta x) - \\sigma_2 W_2\\sigma_1 W_1(x)||_2 \\\\\n< C^2\\lambda_3\\lambda_2 ||\\sigma_1 W_1(x + \\delta x) - \\sigma_1 W_1(x)||_2\\\\\n< C^3\\lambda_3\\lambda_2\\lambda_1 || x + dx - x||_2 \\leq C^3 \\prod_{i=1}^3 \\lambda_i ||dx||_2\n\\end{equation}\nAccording to [11], the sensitivity of the model is:\n\\begin{equation}\n||f(W + dW;x) - f(W;x)||_2\\\\\n< \\frac{\\beta}{\\alpha} \\left(\\frac{2\\omega\\kappa^2}{||W||_F} \\right)^3 \\left(\\left(1 + \\frac{||dW||}{||W||_F}\\right)^{-1} - 1\\right) ||f(W;x)||_2\n\\end{equation}\nwhere $\\omega$ is the maximum width of the network, $\\kappa$ is the condition number bound of $W_i$. $||.||_F$ denotes the Frobenius norm. $\\alpha, \\beta$ are the lower and upper Lipschitz bounds of the activations. Because the data used is not simply Gaussian distributed, here the condition number is assumed as finite.\nIn the finite hypothesis space of the HAR task, the mathematical model of the generalization error bound for the training model can be established as the following inequality:\n\\begin{equation}\nE_S[|L(f_S, z_i) - L(f_{S/z_i}, z_i)]] \\leq \\beta\n\\end{equation}\nwhere $z_i \\in S, i = 1, 2, ..., M, M \\in Z^+$ is the dataset. $S/z_i$ denotes the remaining dataset without $z_i$, $S/z_i \\cup z_i = S$. The model obtained at the end of training is $f_S$. Define the model obtained at the end of training with $S/z_i$ is $f_{S/z_i}$. Thus:\n\\begin{equation}\nL(f_S, S) - L(f_{S/z_i}, S/z_i)\\\\\n< L'|f_S(S) - f_{S/z_i}(S/z_i)| \\\\\n= L'|f(W + dW;x + dx) - f(W; x)\\\\\n= L'|f(W + dW; x + dx) - f(W + dW; x) + f(W + dW;x) - f(W;x)| \\\\\n< L'(\\left|f(W + dW; x + dx) - f(W + dW;x)\\right| + \\left|f(W+dW;x) - f(W; x)\\right|)\n\\end{equation}\nAccording to [11], the sensitivity on both data and weights of the model can be denoted as:\n\\begin{equation}\n|f(W + dW; x + dx) - f(W + dW; x)|\\\\\n\\leq \\sqrt{h} C^3 \\prod_{i=1}^3 \\lambda_i ||dx||_2\n\\end{equation}"}, {"title": "IV. NUMERICAL SIMULATIONS AND EXPERIMENTS", "content": "In this paper, the generalization performance of the theoretically analyzed TWR HAR models is verified using both simulated and measured datasets. The simulated dataset is achieved using UWB signal transmitting in the frequency range of 0.5 ~ 2.5 GHz. The wall parameters are set to be 12 cm thick with a relative dielectric constant of 6. Human motion information is implemented by an open source motion capture dataset from University College London (UCL) [12].\nThe radar and wall environment used for the measured dataset is consistent with the simulation scenario. The captured data is fed into the signal and data processing module to generate R2TM, D2TM, and PC \u2013 RD, all with 3200 sets for training (\"Training\": 1.8 m height human), 800 sets for validation (\"Validation\u201d: 1.8 m height human), and 400 sets for each tester (\"Testing 1\": 1.7 m height and \"Testing 2\": 1.6 m height human). Activity labels include: Empty; Punching; Kicking; Grabbing; Sitting Down; Standing Up; Rotating; Walking; Sitting to Walking; Walking to Sitting; Falling to Walking; Walking to Falling. Both network models pass 20 epochs of training with a batch size of 32 and a validation and testing frequency of 10 batches at a time. Initial learning rate is 0.00147. Parameters R and D in Fig. 2 are both 4096.\nAs shown in Fig. 3, the models corresponding to both methods converge after no more than 20 epochs of training. Comparing the four plots in the first line, which denote the results of simulated dataset under traditional method, the end-epoch accuracy of validation and testing is decreased compared to the end-epoch accuracy of training. The differences in accuracy between the validation set and the test sets are 6.00% and 16.50%. The end-epoch loss of validation and testing is increased compared to the end-epoch loss of training. Comparing the four plots in the second line, which denote the results of simulated dataset under feature reduction based on micro-Doppler corner representation, the differences in accuracy between the validation set and the testing sets are both reduced to 2.13% and 8.63%, respectively. Comparing the four plots in the third line, which denote the results of measured dataset under traditional method, the differences in accuracy between the validation set and the testing sets are 6.13% and 18.88%, respectively. Comparing the four plots in the fourth line, which denote the results of measured dataset under feature reduction based on micro-Doppler corner representation, the differences in accuracy between the validation set and the testing sets are reduced to 3.25% and 9.00%, respectively. Comparison of the convergence effects of the loss functions in Fig. 4 leads to exactly the same patterns. The above results prove that the generalization ability of the model is improved after the micro-Doppler corner representation based feature reduction. The enhancement level is also close to the theoretically derived generalization error results."}, {"title": "V. CONCLUSION", "content": "In order to address the problem that existing TWR HAR models have not generalized well across different indoor human testers, this paper has provided a theoretical analysis of TWR HAR's generalization performance. In detail, the generalization error bound of an end-to-end linear neural network technique has been calculated for TWR HAR. Also, the generalization error improvement before and after micro-Doppler corner representation based dimension reduction has been analyzed. Numerical simulated and measured experiments have been carried out to prove that the generalization ability analysis is valid. The results have shown that feature dimension reduction has worked well to enable recognition models to generalize across different indoor testers."}]}