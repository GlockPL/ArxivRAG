{"title": "A Theoretical Framework for Data Efficient Multi-Source Transfer Learning Based on Cram\u00e9r-Rao Bound", "authors": ["Qingyue Zhang", "Haohao Fu", "Guanbo Huang", "Yaoyuan Liang", "Chang Chu", "Tianren Peng", "Yanru Wu", "Qi Li", "Yang Li", "Shao-Lun Huang"], "abstract": "Multi-source transfer learning provides an effective solution to data scarcity in real-world supervised learning scenarios by leveraging multiple source tasks. In this field, existing works typically use all available samples from sources in training, which constrains their training efficiency and may lead to suboptimal results. To address this, we propose a theoretical framework that answers the question: what is the optimal quantity of source samples needed from each source task to jointly train the target model? Specifically, we introduce a generalization error measure that aligns with cross-entropy loss, and minimize it based on the Cram\u00e9r-Rao Bound to determine the optimal transfer quantity for each source task. Additionally, we develop an architecture-agnostic and data-efficient algorithm OTQMS to implement our theoretical results for training deep multi-source transfer learning models. Experimental studies on diverse architectures and two real-world benchmark datasets show that our proposed algorithm significantly outperforms state-of-the-art approaches in both accuracy and data efficiency. The code and supplementary materials are available in https://anonymous.4open.science/r/Materials.", "sections": [{"title": "1. Introduction", "content": "Nowadays, various machine learning algorithms have achieved remarkable success by leveraging large-scale labeled training data. However, in many practical scenarios, the limited availability of labeled data presents a significant challenge, where transfer learning emerges as an effective solution (Zhao et al., 2020). Transfer learning aims to leverage knowledge from tasks with abundant data or being well-trained, known as the source tasks, to improve the performance of a new learning task, known as the target task. Given its numerous applications, transfer learning has gained wide popularity and seen success in a variety of fields, such as computer vision (Wang & Deng, 2018), natural language processing (Sung et al., 2022), recommendation system (Fu et al., 2024) and anomaly detection (Vincent et al., 2020). Traditionally, transfer learning has focused on the transfer between a single source task and a target task. However, there is a growing emphasis on multi-source transfer learning, which leverages multiple source tasks to enhance the training of the target task (Sun et al., 2015).\nIn multi-source transfer learning, traditional methods usually jointly train the target model using all available samples from sources without selection (Zhang et al., 2024; Shui et al., 2021; Li et al., 2021b). This evidently poses a severe limitation to training efficiency, considering the vast number of available samples from various potential source tasks in real-world scenarios (Peng et al., 2019). Moreover, directly assuming the use of all available samples seriously constrains their solution space, which possibly leads to suboptimal results as illustrated in Figure 1. Therefore, it is critical to establish a theoretical framework to answer the question: what is the optimal transfer quantity of source"}, {"title": "2. Related Work", "content": ""}, {"title": "2.1. Transfer Learning Theory", "content": "Existing theoretical works can be categorized into two groups. The first group focuses on proposing measures to quantify the similarity between the target and source tasks. Within this group, some measures have been introduced, including 12-distance (Long et al., 2014), optimal transport cost (Courty et al., 2016), LEEP (Nguyen et al., 2020), Wasserstein distance (Shui et al., 2021), and maximal correlations (Lee et al., 2019). This work belongs to the second group focusing on developing new generalization error measures. Within this group, the measures having been introduced include f-divergence (Harremo\u00ebs & Vajda, 2011), mutual information (Bu et al., 2020), \\(\\chi^2\\)-divergence (Tong et al., 2021), H-score (Bao et al., 2019; Wu et al., 2024). However, the potential of K-L divergence as a generalization error measure has not been sufficiently explored."}, {"title": "2.2. Multi-source Transfer Learning", "content": "Classified by the object of transfer, existing multi-source transfer learning methods mainly focus on two types: model transfer vs sample transfer (Zhuang et al., 2020). Model transfer assumes there is one or more pre-trained models on the source tasks and transfers their parameters to the target task via fine-tuning (Wan et al., 2022). This work focuses on the latter, which is based on joint training of the source task samples with those of the target task (Zhang"}, {"title": "3. Problem Formulation", "content": "Consider the transfer learning setting with one target task T, and K source tasks \\({S_1, . . ., S_K}\\). The target task T is not restricted to a specific downstream task category. Generally, we formulate it as a parameter estimation problem under a distribution model \\(P_{X;\\theta}\\). For example, when T is a supervised classification task, \\(P_{X;\\theta}\\) corresponds to the joint distribution model of input features Z and output labels Y, i.e., \\(X = (Z,Y)\\). Our objective is to estimate the true value of \\(\\theta\\), which corresponds to optimizing the neural network parameters for target task T. Here, \\(\\theta\\) denotes 1-dimensional parameter, and \\(\\Theta\\) denotes high dimensional parameter.\nFurthermore, we assume that the source tasks and the target task follow the same parametric model and share the same input space X. Without loss of generality, we assume X to be discrete, though our results can be readily extended to continuous spaces. The target task T has \\(N_0\\) training samples \\(X_{N_0} = \\{x_1,..., x_{N_0}\\}\\) i.i.d. generated from some underlying joint distribution \\(P_{X;\\theta_0}\\), where the parameter \\(\\theta_0 \\in \\mathbb{R}^d\\). Similarly, the source task \\(S_k\\) has \\(N_k\\) training samples \\(X_{N_k} = \\{x_1^k,...,x_{N_k}^k\\}\\) i.i.d. generated from some underlying joint distribution \\(P_{X;\\theta_k}\\), where \\(k \\in [1, K]\\), and the parameter \\(\\theta_k \\in \\mathbb{R}^d\\). In this work, we use the Maximum Likelihood Estimator (MLE) to estimate the true target task parameter \\(\\theta_0\\). Moreover, the following lemma demonstrates that, for large sample size, the MLE can achieve the theoretical lower bound of the Mean Squared Error (MSE) asymptotically, known as the Cram\u00e9r-Rao Bound.\nLet \\(\\hat{\\theta}\\) be an unbiased estimator of \\(\\theta\\) based on n i.i.d. samples. Then, the MSE matrix of \\(\\hat{\\theta}\\) satisfies the following lower bound:\n\\[MSE(\\hat{\\Theta})_{d \\times d} \\geq \\mathbb{E} [(\\hat{\\Theta} - \\Theta)(\\hat{\\Theta} - \\Theta)^T] \\geq \\frac{1}{n} J(\\Theta)^{-1},\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad(1)\\]\nwhere \\((\\hat{\\Theta} - \\Theta)\\) is d - dimensional vector, and the matrix"}, {"title": "4. Theoretical Analysis and Algorithm", "content": "In this section, we will first introduce a new K-L divergence measure for the optimization problem in (5). Then, we will analyze it based on the Cram\u00e9r-Rao bound to derive the optimal transfer quantities for both single-source and multi-source scenarios. Finally, we will develop a practical algorithm based on the theoretical framework.\nDefinition 4.1. The K-L divergence measures the difference between two probability distributions P(X) and Q(X) over the same probability space. It is defined as:\n\\[D (P||Q) = \\sum_{x} p(x) \\log \\frac{p(x)}{q(x)}\\]"}, {"title": "4.1. Single-Source Transfer Learning", "content": "The direct computation of the proposed K-L divergence measure is challenging. Fortunately, we can prove that the proposed K-L measure directly depends on the MSE in the asymptotic case. Moreover, the MSE has a widely used Cram\u00e9r-Rao bound introduced in Lemma 3.1, which provides a bound on the estimator's error, and is asymptotically tight. As our goal is to find a correspondence between transfer quantity and generalization error, for the rest of the paper, we mainly analyze the K-L measure based on the Cram\u00e9r-Rao bound (3). To begin, we consider the setting with a target task T with \\(N_0\\) samples generated from a model with 1-dimensional parameter.\nGiven a target task T with \\(N_0\\) i.i.d. samples generated from 1-dimensional underlying model \\(P_{X;\\theta_0}\\), where \\(\\theta_0 \\in \\mathbb{R}\\), and denoting \\(\\hat{\\theta}\\) as the MLE (4) based on the \\(N_0\\) samples, then the K-L measure (6) can be expressed as:\n\\[\\mathbb{E} [D (P_{X;\\hat{\\theta}_0}||P_{X;\\theta_0})] = \\frac{1}{2 N_0} + o(\\frac{1}{N_0}),\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad(7)\\]\nThe result of Lemma 4.2 demonstrates that when there is only a target task, our K-L measure is inversely proportional to the number of training samples. Next, we consider the transfer learning scenario in which we have one target task T with \\(N_0\\) training samples and one source task \\(S_1\\) with \\(N_1\\) training samples. In this case, We aim to determine the optimal transfer quantity \\(n \\in [1, N_1]\\). To facilitate our mathematical derivations, we assume \\(N_0\\) and \\(N_1\\) are asymptotically comparable, and the distance between the parameters of target task and source task is sufficiently small (i.e., \\(|\\theta_0 - \\theta_1| = O(\\sqrt{\\epsilon})\\)). Considering the similarity of low-level features among tasks of the same type, this assumption is made without loss of generality. Furthermore, as demonstrated in subsequent analysis, our conclusions remain valid even in extreme cases where the distance between parameters is large."}, {"title": "4.2. Multi-Source Transfer Learning", "content": "Consider the multi-source transfer learning scenario with K source task \\({S_1, ..., S_K}\\) and one target task T. We aim to derive the optimal transfer quantity \\(n_k\\) of each source.\nGiven a target task T with \\(N_0\\) i.i.d. samples generated from underlying model \\(P_{X;\\theta}\\), and K source tasks \\(S_1, . . ., S_K\\) with \\(N_1,..., N_k\\) i.i.d. samples generated from underlying model \\(P_{X;\\theta_1},..., P_{X;\\theta_K}\\), where \\(\\theta_0,\\theta_1,\u2026\u2026\u2026,\\theta_K \\in \\mathbb{R}^d\\). \\(\\hat{\\theta}\\) is denoted as the MLE (4) based on the \\(N_0\\) samples from T and \\(n_1,...,n_k\\) samples from \\(S_1, ..., S_K\\), where \\(n_i \\in [0, N_i]\\). Denoting \\(s = \\sum_{i=1}^{K} n_i\\) as the total transfer quantity, and \\(\\alpha_i = \\frac{n_i}{s}\\) as the proportion of different source tasks, then the K-L measure (6) can be expressed as:\n\\[\\frac{d}{2} \\left(\\frac{1}{N_0 + s} + \\frac{s^2}{(N_0 + s)^2}t + o(\\frac{1}{N_0 + s})\\right).\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad(14)\\]\nIn (14), t is a scalar denoted as\n\\[t= \\frac{\\alpha^T\\Theta^T J(\\theta_0)\\Theta \\alpha}{d}\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad(15)\\]\nwhere \\(\\alpha = [\\alpha_1,..., \\alpha_K]^T\\) is a K-dimensional vector, and \\(\\Theta_{d \\times K} = [\\theta_1 - \\theta_0,\u2026\u2026\u2026, \\theta_K - \\theta_0]\\).\nAccording to Theorem 4.6, we can derive the optimal transfer quantities \\(n_1^*, ..., n_k^*\\) by minimizing (14). Equivalently, we need to find the optimal total transfer quantity \\(s^*\\) and the optimal proportion vector \\(\\alpha^*\\) which minimize (14). The analytical solutions of \\(s^*\\) and \\(\\alpha^*\\) are difficult to acquire, and we provide a method to get their numerical solutions in Appendix D. Eventually, we can get the optimal transfer quantity of each source through \\(n_i^* = s^* \\alpha_i^*\\)."}, {"title": "4.3. Practical Algorithm", "content": "Along with our theoretical framework, we propose a practical algorithm, OTQMS, which is applicable to all supervised target tasks, as presented in Algorithm 1. It mainly involves two stages: (1) initializing the source task parameters \\(\\theta_1, ..., \\theta_K\\) to compute the optimal transfer quantities and (2) jointly training the target model using a resampled dataset whose sample quantity of each source corresponds to the optimal transfer quantity derived from our theory."}, {"title": "5. Experiments", "content": ""}, {"title": "5.1. Experiments Settings", "content": "Benchmark Datasets. DomainNet contains 586,575 samples of 345 classes from 6 domains (i.e., C: Clipart, I: Infograph, P: Painting, Q: Quickdraw, R: Real and S: Sketch). Office-Home benchmark contains 15588 samples of 65 classes, with 12 adaptation scenarios constructed from 4 domains: Art, Clipart, Product and Real World (abbr. Ar, Cl, Pr and Rw). Digits contains four-digit sub-datasets: MNIST(mt), Synthetic(sy), SVHN(sv) and USPS(up), with each sub-dataset containing samples of numbers ranging from 0 to 9.\nImplementation Details. We employ the ViT-Small model (Wightman, 2019), pre-trained on ImageNet-21k (Deng et al., 2009), as the backbone for all datasets. The Adam optimizer is employed with a learning rate of 1e-5. We allocate 20% of the dataset as the test set, and report the highest accuracies within 5 epoch early stops in all experiments. Following the standard few-shot learning protocol, the training data for k-shot consists of k randomly selected samples per class from the target task. All experiments are conducted on Nvidia A800 GPUs.\nBaselines. For a general performance evaluation, we take SOTA works under similar settings as baselines. The scope of compared methods includes: 1) Unsupervised Methods: MSFDA (Shen et al., 2023), DATE (Han et al., 2023), M3SDA (Peng et al., 2019). 2) Few-Shot Methods Based on Model(Parameter)-Weighting: H-ensemble (Wu et al., 2024), MCW (Lee et al., 2019). 3) Few-Shot Methods Based on Sample: MADA (Zhang et al., 2024), WADN (Shui"}, {"title": "5.2. Main Result", "content": "We evaluated our algorithm, OTQMS, alongside baseline methods on the multi-source transfer learning tasks using the DomainNet and Office-Home datasets. The quantitative results are summarized in Table 2. Since the unsupervised baselines are not designed for the supervised few-shot setting, we report their original results from the respective papers for reference. We make the following observations:\nOverall Performance. In general, compared to baseline methods, OTQMS achieves the best performance on almost all the transfer scenarios on the two datasets. Specifically, OTQMS outperforms the state-of-the-art (AllSources U Target) by an average of 1.5% on DomainNet and 1.0% on Office-Home.\nData Speaks Louder Than Model Weighting. It is worth noting that on both datasets, samples-based methods utilizing both target and source samples to jointly train the model, such as WADN, MADA and OTQMS, generally outperform model(parameter)-weighting approaches which construct the target model by weighting source models, such as H-ensemble and MCW. This observation suggests that sample-based approaches offer greater advantages over model-based methods, because they can fully leverage the relevant information from the source data for the target task.\nTake, But Only as Much as You Need. Comparing results in Table 2 among Target-only, AllSources U Target, and OTQMS, we observe that OTQMS achieves the best performance in both datasets by leveraging only a subset of data selected from all available sources based on model preference. This result validates our theory and highlights the benefits of identifying the optimal balance in the bias-variance trade-off. By choosing the right quantities of samples from the source tasks, we could train the target model more accurately. Furthermore, Figure 5 shows that OTQMS also significantly reduces the training time and sample usage, which validates its superiority in terms of data efficiency.\nFew-Shot Labels, Big Gains. We make a comparison of the results of unsupervised and supervised methods. While other conditions remain the same, Table 2 demonstrates"}, {"title": "5.3. Static vs. Dynamic Transfer Quantity", "content": "In our proposed Algorithm 1, we employ a \"Dynamic\" strategy that dynamically determines the optimal transfer quantities and updates the resampled dataset during the joint training of target task. To validate the effectiveness of this strategy, we conducted comparative experiments using the \"Static-*\" methods. \"Static-*\" methods first simulate the distribution of target on target dataset only, and different types of Static such as \"Under, Exact and Over\" stands for different fitting levels. In \"Static-*\" methods, we only compute the optimal transfer quantity once to make the resampled dataset, and evaluated on it until target model converges. The results on Table 3 demonstrate OTQMS using dynamic transfer quantity achieved the best performance."}, {"title": "5.4. Generality across Different Shot Settings", "content": "As discussed in the theoretical analysis of Theorem 4.3, our theoretical framework is applicable to any quantity of target samples. Therefore, OTQMS exhibits shot generality, enabling it to avoid negative transfer across different shot settings. To validate this, we increase the number of shots from 5 to 100 across methods including AllSources U Target, Target-Only, and OTQMS. As shown in Figure 4, experimental results demonstrate that OTQMS consistently outperforms other approaches across all shot settings. This highlights the generality and scalability of OTQMS in terms of data utilization."}, {"title": "5.5. Data Efficiency Test", "content": "In this section, we demonstrate the advantage of OTQMS in terms of data efficiency. Specifically, we conduct experiments with MADA, AllSources U Target, and OTQMS across different shot settings, and for each shot setting, we"}, {"title": "5.6. Compatibility to Parameter-Efficient Training", "content": "To evaluate the applicability with parameter-efficient training, we used a ViT-Base model (Dosovitskiy et al., 2021) integrated with the LoRA framework (Hu et al., 2021) as the backbone. This approach significantly reduces the number of trainable parameters for downstream tasks while ensuring model quality and improving training efficiency. In the experiments, we consider the trainable low-rank matrices and the classification head as the parametric model in our theoretical framework, while treating the remaining parameters as constants. Other experimental settings are the same as de"}, {"title": "5.7. Analysis on Domain-specific Transfer Quantity", "content": "To understand the domain preference of OTQMS, we visualize the proportion of each source in the selected samples for each target domain. As shown in Figure 6(b), when the target domain is Clipart, OTQMS primarily leverages samples from Real, Painting, and Sketch. In addition, Quickdraw contributes minimally to any target domain. These observations align with the findings in (Peng et al., 2019). To further clarify the selection process of OTQMS during training, we visualize it in Figure 6(a). We observe that in the Office-Home dataset, Clipart initially selects all source domains but later focuses on Art and Real World. In the DomainNet dataset, Sketch predominantly selects Clipart, Painting, and Real throughout the training process."}, {"title": "6. Conclusion", "content": "In this work, we propose a theoretical framework to determine the optimal transfer quantities in multi-source transfer learning. Our framework reveals that by optimizing the transfer quantity of each source task, we can improve target task training while reducing the total transfer quantity. Based on this theoretical framework, we develop an architecture-agnostic and data-efficient practical algorithm OTQMS for jointly training the target model. We evaluated the proposed algorithm through extensive experiments and demonstrated its superior accuracy and enhanced data efficiency."}]}