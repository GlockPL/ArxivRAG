{"title": "DYNAMIC SPARSE TRAINING VERSUS DENSE TRAINING: THE UNEXPECTED WINNER IN IMAGE CORRUPTION ROBUSTNESS", "authors": ["Boqian Wu", "Qiao Xiao", "Shunxin Wang", "Nicola Strisciuglio", "Mykola Pechenizkiy", "Maurice van Keulen", "Decebal Constantin Mocanu", "Elena Mocanu"], "abstract": "It is generally perceived that Dynamic Sparse Training opens the door to a new era\nof scalability and efficiency for artificial neural networks at, perhaps, some costs in\naccuracy performance for the classification task. At the same time, Dense Train-\ning is widely accepted as being the \"de facto\" approach to train artificial neural\nnetworks if one would like to maximize their robustness against image corrup-\ntion. In this paper, we question this general practice. Consequently, we claim that,\ncontrary to what is commonly thought, the Dynamic Sparse Training methods can\nconsistently outperform Dense Training in terms of robustness accuracy, partic-\nularly if the efficiency aspect is not considered as a main objective (i.e., sparsity\nlevels between 10% and up to 50%), without adding (or even reducing) resource\ncost. We validate our claim on two types of data, images and videos, using several\ntraditional and modern deep learning architectures for computer vision and three\nwidely studied Dynamic Sparse Training algorithms. Our findings reveal a new\nyet-unknown benefit of Dynamic Sparse Training and open new possibilities in\nimproving deep learning robustness beyond the current state of the art.", "sections": [{"title": "INTRODUCTION", "content": "If one would like to maximize as much as possible the robustness of a deep learning model on noisy\nmore realistic data (e.g., image corruption, out of distribution), what would be the typical approach?\nWould one train directly a dense neural network (referred further as Dense Training) or a sparse neu-\nral network (referred further as Sparse Training)? Of course, there are many techniques to enhance\nthe model robustness, but still they would be applied on top of a basic optimization process which\nusually requires training an artificial neural network. In order to give an answer to the previously\nposed question, we would need to quantify the research and practitioner community perception,\nwhich is a hard problem in itself. Yet, given the large body of literature on the topic, it is safely\nto assume that the usual answer would be \"Yes, Dense Training is the typical solution to maximize\nthe model robustness.\". Nevertheless, the reader can answer to this question by themselves, while\nfurther in this manuscript we would like to bring more clarity and some new perspectives on this\ntopic.\nWith respect to Dense Training, recent studies have demonstrated that over-parameterized neural\nnetworks, can achieve impressive generalizability on test data even without explicit regularizers\nZhang et al. (2021). This phenomenon is partly explained by the implicit regularization induced by\nthe optimization algorithm used during training, such as stochastic gradient descent (SGD) Zhang\net al. (2021); Keskar et al. (2017); Li & Liang (2018). Despite ongoing efforts to understand the"}, {"title": "RELATED WORK", "content": "Deep neural networks (DNNs) are susceptible to unseen changes in their inputs, a scenario com-\nmonly encountered in practical applications, such as common corruptions like Gaussian noise, defo-\ncus blur, etc Hendrycks & Dietterich (2019). To enhance robustness against these common corrup-\ntions, many methods have been developed, primarily focusing on data augmentation, for example,\nAugMix Hendrycks* et al. (2020), AugMax Wang et al. (2021), PRIME Modas et al. (2022). These\napproaches aim to reduce the distribution gap between the training and testing datasets. Alterna-\ntively, other strategies to enhance corruption robustness concentrate on developing resilient learning\napproaches, such as contrastive learning Chen et al. (2020), or on designing specialized network\ncomponents, like the push-pull layer Strisciuglio et al. (2020). Recent research has revealed that\nLTH-based sparse models can provide enhanced robustness to common corruptions compared to\ntheir denser counterparts Diffenderfer et al. (2021); Chen et al. (2022a). Additionally, Bair et al.\n(2024) introduces an adaptive sharpness-aware pruning method, which regularizes the model to-\nwards flatter regions, thereby improving robustness against image corruption. However, these meth-\nods are typically built on dense models either at the start or throughout training, often overlooking\nthe aspect of resource-aware training."}, {"title": "DYNAMIC SPARSE TRAINING", "content": "Dynamic Sparse Training (DST) Mocanu et al. (2018); Bellec et al. (2018); Mostafa & Wang (2019);\nEvci et al. (2020); Chen et al. (2021); Yuan et al. (2021); Liu et al. (2021a), as a sparse-to-sparse\ntraining paradigm, starts from scratch and maintains partial parameters throughout training, pro-\nviding a promising approach to significantly improve training and inference efficiency while still\npreserving accuracy. Recent research has focused on deciphering the mechanisms of DST Liu et al.\n(2021c); Evci et al. (2022; 2019), and has broadened its application in various domains, such as con-\ntinuous learning Sokar et al. (2023), reinforcement learning Graesser et al. (2022); Tan et al. (2023),\nfeature selection Sokar et al. (2022); Atashgahi et al. (2022), time series classification Xiao et al.\n(2022), network architecture design Liu et al. (2023), and vision transformers Chen et al. (2021).\nMoreover, recent studies have concentrated on developing improved DST algorithms Dettmers &\nZettlemoyer (2019); Mostafa & Wang (2019); Yuan et al. (2021); Jayakumar et al. (2020); Liu et al.\n(2021b). For instance, Dettmers & Zettlemoyer (2019) introduced a technique to regrow weights\nbased on the momentum of existing weights, while Yuan et al. (2021) proposed a method that utilizes\nboth weight and gradient information for pruning. More recently, it has been demonstrated that DST\ncan enhance the performance of DNNs on biased data Zhao et al. (2023) and adversarial samples\nChen et al. (2022b). However, the majority of DST research relies on pristine benchmark datasets,\nleaving the robustness of DST models against image corruption relatively unexplored. This paper\naims to systematically investigate the robustness behavior of DST when exposed to various image\ncorruptions."}, {"title": "PRELIMINARIES", "content": "Given the i.i.d. training samples {(x,y)}_{i=1}^{N_{tr}} from a training distribution \\(P_{tr}(x, y)\\), our goal is\nto predict the labels \u0177 of test examples {(x,y)}_{i=1}^{N_{te}} drawn from a test distribution \\(p_{te} (x, y)\\).\nWe decompose \\(P_{tr}(x, y)\\) and \\(P_{te} (x, y)\\) into the marginal distribution and the conditional probability\ndistribution, that is:\n\\(P_{tr}(x, y) = P_{tr}(X)P_{tr}(y | X),\\)"}, {"title": "CAN DST IMPROVE ROBUSTNESS AGAINST IMAGE CORRUPTION?", "content": "In this section, we aim to carry out extensive experiments to verify the DSCR Hypothesis across a\nwide variety of DST methods, models and data. To this end, we conduct a comprehensive set of\nexperiments to evaluate the robustness accuracy of DST models with different sparsity ratios in the\npresence of image corruption.\nTo comprehensively validate the DSCR Hypothesis, our study embarks on an extensive analysis\nevaluating the robustness behavior of sparsely trained models. We train using several representative\nDST algorithms, including SET, Rigging the Lottery (RigL) Evci et al. (2020), Memory-Economic\nSparse Training (MEST) Yuan et al. (2021), and Gradual Pruning with zero-cost Neuroregeneration\n(GraNet) Liu et al. (2021a), across a wide range of model architectures (i.e., VGG Simonyan &\nZisserman (2015), 2D/3D ResNet He et al. (2016), EfficientNet Tan & Le (2019), DeiT Touvron\net al. (2021) and Two-Stream Inflated 3D ConvNet (I3D) Carreira & Zisserman (2017)).\nOur analysis spans a range of image corruption benchmarks\u2014CIFAR10-C Hendrycks & Dietterich\n(2019), CIFAR100-C Hendrycks & Dietterich (2019), TinyImageNet-C Hendrycks & Dietterich\n(2019), ImageNet-C Hendrycks & Dietterich (2019), ImageNet-C Mintun et al. (2021), ImageNet-\n3DCC Kar et al. (2022) and corrupted UCF101 Soomro et al. (2012) \u2014covering 19 types of im-\nage corruptions for CIFAR10/100-C, 15 types for TinyImageNet-C and ImageNet-C, 10 types for\nImageNet-C and 11 types for ImageNet-3DCC, with each corruption tested across five severity lev-\nels. The corrupted UCF101 dataset includes 16 corruption types with four severity levels. This anal-\nysis provides a comprehensive perspective on the robustness evaluation of sparsely trained models.\nDetailed dataset descriptions and implementation setup can be found in Appendix A.1 and A.3.1."}, {"title": "OVERALL PERFORMANCE", "content": "Figure 2 showcases the average robust accuracy across various types of corruption, with severity\nlevels ranging from 1 to 5, on the CIFAR10/100-C and TinyImageNet-C datasets. We can find that\nDST models outperform their Dense training counterparts (as indicated by the blue line in Figure 2)\nin terms of robustness accuracy across multiple sparsity ratios. This trend is evident in both the\nrandom regrow and gradient-based regrow strategies. Specifically,\nfor CIFAR100-C and TinyImageNet- C, DST models with sparsity ratios ranging from 0.3 to 0.7\ngenerally show encouraging improvements in robustness. For CIFAR10-C, at certain sparsity ratios,\nsuch as 0.4, the overall DST methods achieve decent robust performance against image corruptions.\nMoreover, based on our experimental setup, at least 40% of both training computational and memory\ncosts can be saved while simultaneously enhancing corruption robustness. Details on FLOPs and\nparameter counts are available in the Appendix A.3.2. This finding substantiates our DSCR Hypoth-\nesis across different DST methods, varying sparsity ratios, and architectures (i.e., VGG, ResNet, and\nEfficientNet)."}, {"title": "PERFORMANCE ON CORRUPTION TYPES", "content": "We further evaluate the DST methods across various corruption types with different severities. Fig-\nure 3 provides detailed relative robustness gains for each type of corruption in ImageNet-C and"}, {"title": "ROBUSTNESS OF DST MODELS: IS TRUE FOR OTHER DATASETS, TASKS, AND ARCHITECTURES?", "content": "Herein, we evaluate the robustness of DST models using a more realistic corruption dataset (e.g.,\nImageNet-3DCC Kar et al. (2022)), and across different tasks (e.g., video classification), with mod-\nern architectures (transformer-based, e.g., DeiT-base Touvron et al. (2021))."}, {"title": "WHAT IS BEHIND THE CORRUPTION ROBUSTNESS GAIN IN DST?", "content": "Building on the previous empirical results, where DST showed improved robustness against com-\nmon corruptions, we are motivated to explore the inner reasons for the robustness of DST models.\nOur focus is on analyzing how DST and Dense Training models utilize their parameters in the spatial\ndomain and process the input in the spectral domain."}, {"title": "ANALYSIS THROUGH SPATIAL DOMAIN", "content": "Traditionally, the constraints on weight values, such as \\(L_2\\) regularization, during dense training have\nbeen an effective method to mitigate the problem of overfitting. In contrast, DST imposes sparsity\nconstraints, enabling the selective removal of parameters. In this section, we aim to intuitively\ninvestigate how DST affects the location of non-zero weights. To achieve this, we performed a\nvisualization analysis to pinpoint the locations of sparse parameters for DST models. Figure 5\nshowcases the non-zero weight counts and the sum of weight magnitudes (i.e., absolute values) for\neach kernel in a specific layer."}, {"title": "ANALYSIS FROM SPECTRAL DOMAIN", "content": "Motivated by previous work Yin et al. (2019), which examines ImageNet accuracy after low-pass\nand high-pass filtering to understand how neural networks utilize frequency information for image\nrecognition, and building on the observations and assumptions from the previous section, we will\nfurther explore dynamic sparse models from a spectral perspective.\nIn this section, we explore how the test accuracy of both DST and Dense Training models is affected\nby the removal of high and low-frequency components from the test data after training. In detail,\nthe test images are first transformed into the Fourier spectrum, followed by a frequency attenuation"}, {"title": "FURTHER ANALYSIS AND DISCUSSION", "content": "In this paper, we primarily investi-\ngate the robustness of fundamental\nDST models initialized from random\nsparse networks with the basic re-\nmoval and regrowth criteria, to vali-"}, {"title": "DSCR HYPOTHESIS IN RECENT DST ALGORITHMS", "content": "date our DSCR hypothesis in commonly used settings. With the emergence of other recent and\npromising DST methods, we also include an initial exploration to further validate our hypothesis\non these methods, such as Cannistraci-Hebb soft training (CHTs) Zhang et al. (2024b;a), which\nemploy more complex growth criteria and topology initialization. We compare dense training with\nCHTs using Correlated Sparse Topological Initialization (CHTs+CSTI) and bipartite small-world\nnetworks (CHTs+BSW) on robustness accuracy, using the Fashion-MNIST corrupted dataset with\nan MLP model, as shown in Table 2. The results indicate that the recent DST method (i.e., CHTs)\nachieves even more inspiring robustness performance, further validating our DSCR hypothesis on\nthe robustness of DST."}, {"title": "DISCUSSION AND LIMITATION", "content": "Our study questions the conventional approach of using \"de facto\" dense training for model robust-\nness in favor of sparse training. Due to the page constraint, we also analyze the complementarity\nbetween DST and data augmentation (e.g., Mixup Zhang et al. (2018)) in Appendix A.6, and further\nexplore DST's robustness with Out-Of-Domain (OOD) data and Grad-CAM Selvaraju et al. (2017)\nin Appendix A.7 and A.8, respectively. In the future, it is worth moving beyond the basic fact\nrevealed in this paper, i.e., vanilla DST outperforms vanilla Dense Training for model robustness,\nand to devise new DST methods for model robustness especially in the high sparsity regime, and\nto replace Dense Training with DST in the current state-of-the-art techniques for model robustness.\nAdditionally, while we empirically analyze robustness behaviors between dense and sparse train-\ning and provide insights from both spatial and frequency domains, further work on the theoretical\nunderstanding of this phenomenon, along with a fine-grained exploration of different components\nof DST (e.g., topology initialization, regrowth methods and regrowth weight initialization), could\nprovide deeper insights for the development of more robust and efficient networks. This would be a\npromising direction for future research."}, {"title": "CONCLUSION", "content": "This paper questioned the typical ap-\nproach of using \"de facto\" Dense\nTraining to maximize model robust-\nness in deep learning, and revealed\nan unexpected finding. That is: \"Dy-\nnamic Sparse Training at low spar-\nsity levels can train more robust mod-\nels against image corruption than\nDense Training.\". This finding has\nbeen confined formally in the DSCR\nHypothesis and rigorously validated\non nine scenarios (as summarized in\nTable 3 where a striking observation\ncan be made all DST algorithms"}, {"title": "APPENDIX", "content": null}, {"title": "DATASET INTRODUCTION", "content": null}, {"title": "CORRUPTION DATASET", "content": "Image corruptions refer to visible distortions in images that lead to data distribution shifts from that\nof the original data. They are common in practical applications when models are deployed in the real\nworld. Typical corruptions include Gaussian noise, impulse noise, defocus blur, etc. In Figure 8, we\ndisplay the common image corruptions on the CIFAR-10 dataset."}, {"title": "RELATED BENCHMARKS", "content": "\u2022 CIFAR-10/100-C Hendrycks & Dietterich (2019) is synthetically generated on top of the\ntest set of CIFAR-10/100 dataset. It includes 19 sub-datasets, each corrupted with a type\nof image corruption (Gaussian noise, impulse noise, shot noise, speckle noise, defocus\nblur, Gaussian blur, glass blur, motion blur, zoom blur, brightness, fog, frost, snow, spatter,\ncontrast, elastic transform, JPEG compression, pixelate, saturate). Each corruption dataset\ncontains five subsets, which have images corrupted with five severity levels. The higher the\nseverity, the more influence the corruption has on the test images.\n\u2022 Tiny-ImageNet-C Hendrycks & Dietterich (2019) consists of 15 types of common image\ncorruptions, and is synthetically generated from Tiny-ImageNet dataset as well. The types\nof corruption are Gaussian noise, impulse noise, shot noise, defocus blur, glass blur, motion"}, {"title": "EXPERIMENT SETUP", "content": "For CIFAR10, CIFAR100, and TinyImageNet, the codes were implemented in Python using PyTorch\nand executed on a single NVIDIA A100 GPU. Each was run three times using three fixed random\nseeds. The ImageNet experiments were run using distributed computing on four NVIDIA A100\nGPUs. A batch size of 64 was utilized for each task, resulting in a combined total batch size of 256."}, {"title": "THE COMPUTATIONAL AND MEMORY CONSUMPTION", "content": "In this section, we present the computational cost in terms of Floating-Point Operations (FLOPs)\nfor training and inference, as well as the memory cost in terms of the number of parameters, for\ndifferent models across different sparsity ratios.\nCIFAR-10: For the CIFAR10 dataset, we train VGG16 for 160 epochs. The soft memory bound\nfor MEST is set to 10% of the target density. For example, if the sparse network's density is 0.3,\nthen the soft memory bound is 0.03, resulting in an initial model density of 0.33. This soft memory"}, {"title": "THE ROBUSTNESS ACCURACY\nFOR DIFFERENT CORRUPTION TYPES AND SERVERITIES", "content": "Figure 10, 11, 12, 13 14 and 15 showcase the relative gains in\nrobustness at each of these severity levels. We observe that dy-\nnamic sparse models exhibit a more pronounced advantage in\nrobustness over dense models, particularly under high severity\nlevels of high-frequency corruption."}, {"title": "ANALYSIS THROUGH THE LENS OF FILTER", "content": "Figure 16 and 17 showcases the non-zero weight counts and the sum of weight magnitudes (i.e.,\nabsolute values) for each kernel in a specific layer of dynamic sparse VGG16 and ResNet34 trained\non CIFAR10 and CIFAR100, respectively."}, {"title": "HOW DATA AUGMENTATION INTERACTS WITH DST?", "content": "We extend our analysis to explore how data augmentation (e.g.,\nMixup Zhang et al. (2018)) interacts with dynamic sparse train-\ning in comparison to dense training. From Table 10, we observe: In general, data augmentation helps improve model generalization\nby providing increased input variability. For DST, combining data\naugmentation with dynamic sparse training can lead to even greater"}, {"title": "THE PERFORMANCE OF DST ON OUT-OF-DOMAIN (OOD) TEST DATA", "content": "ImageNet-R Hendrycks et al. with 30,000 images of art, cartoons, and other 14 renditions from 200 ImageNet classes, presents a no-\ntable domain shift from the original dataset. We report the average\ntest accuracy on ImageNet-R for dense and DST models trained on\nthe original ImageNet."}, {"title": "GRAD-CAM", "content": "Grad-CAM (Gradient-weighted Class Activa-\ntion Mapping) Selvaraju et al. (2017) gener-\nates a heatmap highlighting important regions\nby weighting the feature maps based on the gra-\ndient values. It provides practitioners with a vi-\nsual indication of the areas on which the net-\nwork focuses when making predictions. We vi-\nsualize and compare the Grad-CAM outputs of"}, {"title": "IMPACT STATEMENT", "content": "In an era dominated by over-parameterized models and the pervasive presence of image corruption,\nthe design of resource-aware and robust AI models is of increasing importance. Gaining insight\ninto the robust behavior of dynamic sparse models against image corruption paves the way for em-\nbracing these environmentally friendly models in challenging environments. This holds significant\nimplications across various domains, including medical diagnosis, robotics, autonomous vehicles,\nand other AI applications. Furthermore, our insights into the inner workings of sparse models help\nus understand the reasoning behind their robust decisions. Overall, we advance our fundamental\nunderstanding of dynamic sparse training and provide future perspectives for scalable, efficient, and\ntrustworthy AI. We do not anticipate any negative societal impacts resulting from this research."}]}