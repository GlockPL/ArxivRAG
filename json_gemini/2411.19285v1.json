{"title": "BPQP: A Differentiable Convex Optimization Framework for Efficient End-to-End Learning", "authors": ["Jianming Pan", "Zeqi Ye", "Xiao Yang", "Xu Yang", "Weiqing Liu", "Lewen Wang", "Jiang Bian"], "abstract": "Data-driven decision-making processes increasingly utilize end-to-end learnable deep neural networks to render final decisions. Sometimes, the output of the forward functions in certain layers is determined by the solutions to mathematical optimization problems, leading to the emergence of differentiable optimization layers that permit gradient back-propagation. However, real-world scenarios often involve large-scale datasets and numerous constraints, presenting significant challenges. Current methods for differentiating optimization problems typically rely on implicit differentiation, which necessitates costly computations on the Jacobian matrices, resulting in low efficiency. In this paper, we introduce BPQP, a differentiable convex optimization framework designed for efficient end-to-end learning. To enhance efficiency, we reformulate the backward pass as a simplified and decoupled quadratic programming problem by leveraging the structural properties of the Karush\u2013Kuhn-Tucker (KKT) matrix. This reformulation enables the use of first-order optimization algorithms in calculating the backward pass gradients, allowing our framework to potentially utilize any state-of-the-art solver. As solver technologies evolve, BPQP can continuously adapt and improve its efficiency. Extensive experiments on both simulated and real-world datasets demonstrate that BPQP achieves a significant improvement in efficiency-typically an order of magnitude faster in overall execution time compared to other differentiable optimization layers. Our results not only highlight the efficiency gains of BPQP but also underscore its superiority over differential optimization layer baselines.", "sections": [{"title": "1 Introduction", "content": "In recent years, deep neural networks have increasingly been used to address data-driven decision-making problems and to generate final decisions for end-to-end learning tasks. Beyond explicit forward functions, some layers of the network may be characterized by behaviors of implicit outputs, such as the solutions to mathematical optimization problems, which can be described as differentiable optimization layers [1]. These can be treated as implicit functions where inputs are mapped to optimal solutions. In this manner, the network can incorporate useful inductive biases, including domain-specific knowledge, physical structures, and priors, thereby enabling more accurate and reliable decision-making. This approach has been integrated into deep declarative networks [2] for end-to-end learning and has proven effective in various applications, such as energy minimization [3, 4] and predict-then-optimize [5, 6] problems. Here, we focus on convex optimization due to"}, {"title": "2 Related works", "content": "Optimization problems typically lack a general closed-form solution; therefore, calculating gradients for relevant parameters requires more sophisticated methods. These methods can be categorized based on whether an explicit computational graph is constructed, namely into explicit unrolling and implicit methods. Explicit methods [4, 10\u201312] involve unrolling the iterations of the optimization process, which incurs additional computational costs. Conversely, implicit methods leverage the Implicit Function Theorem [13] to derive gradients. Some of these methods [14, 1, 15] are tailored for specific problems, thus restricting the options for forward optimization and reducing efficiency. Alternatively, other approaches [2, 10] offer more general solutions for deriving gradients but face inefficiencies during the backward pass. There remains substantial potential for enhancing efficiency in these methodologies.\nTo enable rapid, tractable differentiation within convex optimization layers and further enhance the capabilities of the end-to-end learning paradigm, we propose a general, first-order differentiable convex optimization framework, which we refer to as the Backward Pass as a Quadratic Programming (BPQP). Specifically, BPQP simplify the backward pass for the parameters of the optimization layer, by reformulating first-order condition matrix into a simpler Quadratic Programming (QP) problem. This decouples the forward and backward passes and creates a framework that can leverage existing efficient solvers (with the first-order algorithm, Alternating Direction Method of Multipliers (ADMM) [16], as the default) that do not require differentiability in both passes. Simplifying and decoupling the backward pass significantly reduces the computational costs in both the forward and backward passes."}, {"title": "3 Background", "content": "We will now provide some background information for the differentiable convex optimization layers.\nSuppose the differentiable convex optimization layer has its input $y \\in \\mathbb{R}^p$, output $z^* \\in \\mathbb{R}^d$, we define the layer with the standard form of a convex optimization problem parameterized by $y$.\nGiven the input $y \\in \\mathbb{R}^p$, output $z^* \\in \\mathbb{R}^d$, a differentiable convex optimization layer is defined as\n$z^*(y) = \\arg \\min_{z \\in \\mathbb{R}^d} f_y(z)$\ns.t. $h_y(z) = 0,$\n$g_y(z) \\leq 0,$\nwhere $y$ is the parameter vector of the objective functions and the constraints, $z$ is the optimization variable, $z^*$ is the optimal solution to the problem; The functions $f : \\mathbb{R}^p \\rightarrow \\mathbb{R}$ and $g : \\mathbb{R}^n \\rightarrow \\mathbb{R}$"}, {"title": "3.2 Differentiating Through KKT Conditions", "content": "To differentiate KKT conditions more efficiently, CvxpyLayer [19] has adopted the LSQR technique to accelerate implicit differentiation for sparse optimization problems. However, this method may not be efficient for more general cases, which might not exhibit sparsity. Although OptNet [14] employs a primal-dual interior point method in the forward pass, making its backward pass relatively straightforward, it is suitable only for quadratic optimization problems.\nIn this paper, our main target is to develop a new method that can increase the computational speed of the differentiation procedure especially for general large-scale convex optimization problems.\nWe consider a general convex problem as defined in Definition 1. To compute the derivative of the solution $z^*$ to parameter $y$, we follow the procedure of [14] to differentiate the KKT conditions using techniques from matrix differential calculus. Following this method, the Lagrangian is given by (omitting $y$),\n$L(z, v, \\lambda) = f(z) + v^\\top h(z) + \\lambda^\\top g(z),$\nwhere $v \\in \\mathbb{R}^m$ and $\\lambda \\in \\mathbb{R}^n$, $\\lambda \\geq 0$ respectively denotes the dual variables on the equality and inequality constraints. The sufficient and necessary conditions for optimality of the convex optimization problem are KKT conditions. Applying the IFT (Lemma 1) to the KKT conditions and let $P(z^*, v^*, \\lambda^*) = \\nabla^2 f(z^*) + \\nabla^2 h(z^*)v^* + \\nabla^2 g(z^*)\\lambda^*$, $A(z^*) = \\nabla h(z^*)$ and $G(z^*) = \\nabla g(z^*)$.\nLet $q(z^*, v^*, \\lambda^*) = \\partial(\\nabla f(z^*) + \\nabla h(z^*)v^* + \\nabla g(z^*)\\lambda^*)/\\partial y$, $b(z^*) = \\partial h(z^*)/\\partial y$ and $c(z^*, \\lambda^*) = (D(\\lambda^*)(\\partial g(z^*)/\\partial y))$. Then the matrix form of the linear system can be written as:\n$\\begin{bmatrix}\nP(z^*,v^*,\\lambda^*) & G(z^*)^\\top & A(z^*)^\\top \\\\\nD(\\lambda^*)G(z^*) & D(g(z^*)) & 0 \\\\\nA(z^*) & 0 & 0\n\\end{bmatrix}\\begin{bmatrix} \\frac{\\partial z^*}{\\partial y} \\\\ \\frac{\\partial \\lambda}{\\partial y} \\\\ \\frac{\\partial v}{\\partial y} \\end{bmatrix} = \\begin{bmatrix} q(z^*, v^*, \\lambda^*) \\\\ c(z^*, \\lambda^*) \\\\ b(z^*) \\end{bmatrix},$", "subsections": []}, {"title": "4 Methodology", "content": "Our approach solves Eq. (3) using reformulation. Consider a general class of QPs that have $d$ decision variables, $m$ equality constraints and $n$ inequality constraints:\n$\\min_{z} \\frac{1}{2} z^\\top P'z + q'^\\top z \\quad s.t. A'z = b', G'z \\leq c',$\nwhere $P' \\in \\mathbb{S}^d_+$, $q' \\in \\mathbb{R}^d$, $A' \\in \\mathbb{R}^{m \\times d}$, $b' \\in \\mathbb{R}^m$, $G' \\in \\mathbb{R}^{n \\times d}$ and $c' \\in \\mathbb{R}^n$. KKT conditions write down in matrix form:\n$\\begin{bmatrix}\nP' & G'^\\top D(\\lambda) & A'^\\top \\\\\nD(\\lambda)G' & D(G'z - c) & 0 \\\\\nA' & 0 & 0\n\\end{bmatrix} \\begin{bmatrix}\nz \\\\ \\lambda \\\\ v\\end{bmatrix} = \\begin{bmatrix}\n-q' \\\\ 0 \\\\ b'\\end{bmatrix}.$", "subsections": [{"title": "4.1 Backward Pass as QPs", "content": ""}]}, {"title": "4.2 Efficiently Solve Backward Pass Problem with OSQP", "content": "The solver we referenced is OSQP [16], which incorporates the sparse matrix method and uses a first-order ADMM method to solve QPs, which we summarize below. On each iteration, it refines a solution from an initialization point for vectors $z^{(0)} \\in \\mathbb{R}^d$, $\\lambda^{(0)} \\in \\mathbb{R}^m$, and $v^{(0)} \\in \\mathbb{R}^n$. And then iteratively computes the values for the $k+1$th iterates by solving the following linear system:\n$\\begin{bmatrix}\nP + \\sigma I & A^\\top & G^\\top \\\\\nA & diag(\\rho)^{-1} & 0\n\\end{bmatrix} \\begin{bmatrix}\nz^{(k+1)} \\\\ v^{(k+1)} \\end{bmatrix} = \\begin{bmatrix}\n\\sigma \\lambda^{(k)} - q \\\\ diag(\\rho)^{-1}b_l^{(k)}\n\\end{bmatrix},$\nAnd then performing the following updates:\n$\\lambda^{(k+1)} = \\lambda^{(k)} + diag(\\rho)^{-1} (v^{(k+1)} - z^{(k)})$\n$x^{(k+1)} = \\Pi \\big(x^{(k+1)} + diag(\\rho)^{-1} x^{(k)} \\big)$\n$\\mu^{(k+1)} = \\mu^{(k)} + diag(\\rho) (x^{(k+1)} - x^{(k+1)})$\nwhere $\\sigma \\in \\mathbb{R}_+$ and $\\rho \\in \\mathbb{R}$ are the step-size parameters, and $\\Pi : \\mathbb{R}^m \\rightarrow \\mathbb{R}^m$ denotes the Euclidean projection onto constraints set. When the primal and dual residual vectors are small enough in norm after kth iterations, $z^{(k+1)}$, $x^{(k+1)}$ and $\\mu^{(k+1)}$ converges to exact solution $z^*$, $x^*$ and $v^*$.\nIn particular, given a backward pass problem Eq. (6) with known active constraints, as stated in OSQP, we form a KKT matrix below\u00b2:\n$\\begin{bmatrix}\nP + \\delta I & G_+\\top & A^\\top \\\\\nG_+ & -\\delta I & 0 \\\\\nA & 0 & -\\delta I\n\\end{bmatrix} \\begin{bmatrix}\nz \\\\ \\lambda \\\\ v \\end{bmatrix}= \\begin{bmatrix} -q \\\\ 0 \\\\ 0\n\\end{bmatrix}$\nAs the original KKT matrix is not always inveritible, e.g., if it has one or more redundant constraints, we modify it to be more robust for QPs of all kinds by adding a small regularization parameter $D(P + \\delta I, -\\delta I, -\\delta I)$ (in Eq. (10)) as default $\\delta \\approx 10^{-6}$. We could then solve it with the aforementioned ADMM procedure to obtain a candidate solution, denoted as $\\hat{t}$ and recover the exact solution $t$ from the perturbed KKT conditions $(K + \\Delta K)\\hat{t} = g$ by iteratively solving:\n$(K + \\Delta K)\\Delta \\hat{t}^k = g - K\\hat{t}^k$.\nwhere $\\hat{t}^{k+1} = \\hat{t}^k + \\Delta \\hat{t}^k$ and it converges to $t$ quickly in practice [16] for only one backward and one forward solve, which helps BPQP solve backward pass problems in a general but efficient way.\nWe have implemented BPQP with some of the use cases and have released it in the open-source library Qlib[24] (https://github.com/microsoft/qlib)."}, {"title": "4.3 Examples: Differentiable QP and SOCP", "content": "Below we provide examples for differentiable QP and SOCP oracles (i.e. solutions) using BPQP.\nThe general procedure is to first write down KKT matrix of the original decision making problem. And then apply Theorem 1. Assuming the optimal solution $z^*$ is already obtained in forward pass.\nDifferentiable QP With a slight abuse of notation, given the standard QP problem with parameters P, q, A, b, G, c as in Eq. (4). The result is exactly the same as OptNet [14] since both approaches are for accurate gradients. But BPQP is capable of efficiently solving large-scale QP forward-backward pass via ADMM [16], as shown in Section 5.1.\n$\\nabla_q L = \\frac{1}{2}(zz^{*T} + z^* z^T) \\nabla_q L = \\hat z$ \n$\\nabla_b L = - \\hat v$\n$\\nabla_A L = iz^{*T} + \\hat v^T$\n$\\nabla_{G_+} L = D(\\lambda^*)\\hat \\lambda z^{*T} + 1^* \\hat \\lambda ^T\\nabla_{c_+} L = -D(\\lambda)\\hat \\lambda$\nAnd $[\\hat z, \\hat v, \\hat \\lambda]$ solves\n$ \\min_{z} \\frac{1}{2} z \\hat Pz + \\frac{\\partial L}{ \\partial z} z\\quad s.t. \\hat Az = 0, \\hat Gz=0.$\nDifferentiable SOCP The second-order cone programming (SOCP) of our interest is the problem of robust linear program [25]:\n$ \\min_{z} q^T z \\quad s.t. a_i^T z + ||z||_2 \\leq b_i  \\forall i \\=1,2,...,m,$\nwhere $q \\in \\mathbb{R}^d$, $a_i \\in \\mathbb{R}^d$, and $b_i \\in \\mathbb{R}$. With m inequality constraints in L2 norm, we give the gradients w.r.t. above parameters.\n$ \\nabla_{a_i + L = \\hat \\lambda_i \\forall i = 1,2,...,m.$\\nabla_q L = \\hat z \\nabla_{a_i + L = \\hat \\lambda_i \\forall i = 1,2,...,m.$\nAnd $[\\hat z, \\hat v, \\hat \\lambda]$ are given by ($t_1 = \\Sigma_i \\hat \\lambda_i a_i$ and $t_0 = ||\\hat \\lambda||_2$)\n$ \\min_{z}  \\frac{1}{2}( \\frac {t_1} {t_0}z^T  z^* \\hat z s.t. (  {a_i + \\hat \\lambda_i  \\frac {1} {2} z^T}) z \\= 0 i  \\forall i  \\=1,2,...,m.$"}, {"title": "5 Experiments", "content": "In this section, we present several experimental results that highlight the capabilities of the BPQP. To be precise, we evaluate for (i) large-scale computational efficiency over existing solvers on random-generated constrained optimization problems including QP, LP, and SOCP, and (ii) performance on real-world end-to-end portfolio optimization task that is challenging for existing end-to-end learning approaches."}, {"title": "5.1 Simulated Large-scale Constrained Optimization", "content": "We randomly generate three datasets (e.g. simulated constrained optimization) for QPs, LPs, and SOCPs respectively. The datasets cover diverse scales of problems. The problem scale includes 10 \u00d7 5, 50 \u00d7 10, 100 \u00d7 20, 500 \u00d7 100 (e.g., 10 \u00d7 5 represents the scale of 10 variables, 5 equality constraints, and 5 inequality constraints). Please refer to more experiment details in Appendix A.5.\nQPs Dataset The format of generated QPs follows Eq. (6) to which the notations in the following descriptions align. We take $q$ as the learnable parameter to be differentiated and $L = 1^Tz^*$ in Eq. (3). To generate a positive semi-definite matrix P, $P'^T P' + \\delta I$ is assigned to P where $P' \\in \\mathbb{R}^{d \\times d}$ is a randomly generated dense matrix, $\\delta I$ is a small regularization matrix, and $\\delta = 10^{-6}$. Potentially, we set $c = Gz', G \\in \\mathbb{R}^{m \\times n}, z' \\in \\mathbb{R}^n$ to avoid large slackness values that lead to inaccurate results. All other random variables are drawn i.i.d. from standard normal distribution $N(0, 1)$.\nLPs Dataset The LP problems are generated in the format below\n$\\min_o^z + e||z||_2^3 \\quad s.t. Az = b, Gz \\leq h.$\nwhere $\\theta \\in \\mathbb{R}^d$ is the learnable parameter to be differentiated, $z \\in \\mathbb{R}^d$, $A \\in \\mathbb{R}^{n \\times d}$, $b \\in \\mathbb{R}^n$, $G \\in \\mathbb{R}^{m \\times d}$, $h \\in \\mathbb{R}^m$ and $e \\in \\mathbb{R}_+$. All random variables are drawn from the same distribution as the QPs dataset."}, {"title": "5.2 Real-world End-to-End Portfolio Optimization", "content": "Portfolio optimization is a fundamental problem for asset allocation in finance. It involves constructing and balancing the investment portfolio periodically to maximize profit and minimize risk. The problem is an important use case of end-to-end learning and can also be solved utilizing differentiable convex optimization layers [26]. We now show how to apply BPQP to the problem of end-to-end portfolio optimization (more experiment details in Appendix A.6).\nMean-Variance Optimization (MVO) [27] is a basic portfolio optimization model that maximizes risk adjusted returns and requires long only and budget constraints.\n$\\max_w \\mu^T w - \\frac{\\gamma}{2} w^T \\Sigma w \\quad subject to \\quad 1^T w = 1, w \\geq 0,$\nwhere variables $w \\in \\mathbb{R}^d$ represent the portfolio weight, $\\gamma \\in \\mathbb{R}_+$ is the risk aversion coefficient, and $\\mu \\in \\mathbb{R}^d$ the expected returns are the parameters to be predicted (under our setting, the input to the optimization layer) of the convex optimization problem. The covariance matrix, $\\Sigma$, of all assets can be learned end-to-end by BPQP. However, it preserves a more stable characteristic than returns in time-series [28]. Therefore, we set it as a constant.\nBenchmarks We evaluate BPQP based on the most widely used predictive baseline neural network, MLP. For the learning approach, we compared the separately two-stage(Two-Stage) and differentiable convex optimization layer approaches(qpth/OptNet). The optimization problem in the experiment has a variable scale of 500, which cannot be handled by other layers based on CVXPY and JAXOpt. We found the tolerance level for truncation in Alt-Diff hard to satisfy the 500 inequality constraints and yield a relatively longer training time (588 minutes per training epoch) than the above benchmarks. Our implementation substantially lowers the barrier to using convex optimization layers."}, {"title": "6 Further discussion", "content": "In this section, we discuss the potential for BPQP to be applied in non-convex problems.\nWhen addressing non-convex problems, we may encounter two challenges. Firstly, the solution is only a local minimum. Secondly, the solution represents only a proximate solution near a local minimum. If an effective non-convex method (e.g. Improved SVRG [29]) is employed in the forward pass, BPQP is still equipped to reformulate the backward pass as a QP. This is because our derivations and theoretical analysis are equally applicable to non-convex scenarios.\nBPQP allows for the derivation of gradients that preserve the KKT norm, as elaborated in Section 4.1 under \"General Gradients.\", which means that when KKT norm is small, BPQP can derive a high quality gradient. Therefore, when a non-convex solver used in the forward pass successfully achieves a solution that is close to or even reaches a local or global minimum, BPQP can still compute well-behaved gradients effectively. This capability underscores the robustness of BPQP and adaptability in handling the complexities associated with non-convex optimization problems.\nAdditionally, many non-convex problems can be transformed into convex problems, making our approach applicable in a broader range of scenarios.\nWhile its hard to perform experiments on non-convex problem due to the lack of baselines, we hope that future work can employ BPQP to do further analysis."}, {"title": "7 Conclusion", "content": "We have introduced a differentiable convex optimization framework for efficient end-to-end learning. Prior work in this area can be divided into explicit and implicit methods, based on the construction of an explicit computational graph.Explicit methods unroll the iterations of the optimization process, incurring additional costs. Conversely, implicit methods often struggle to achieve overall efficiency in both computing the optimal decision variable during the forward pass and solving the linear system involving KKT matrix during the backward pass. Our approach, BPQP, is grounded in implicit methods and simplify the backward pass by reformulating it into a simpler decoupled QP problem, which greatly reduces the computational cost in both the forward and backward passes. Extensive experiments on both simulated and real-world datasets have been conducted, demonstrating a considerable improvement in terms of efficiency."}, {"title": "A Appendix", "content": "In this section, we discuss additional related works which focus on scenarios that regard optimization problem as terminal objectives. When optimization solutions solely constitute the terminal output of an end-to-end learning process rather than intermediates within a neural network architecture-additional methodologies emerge."}, {"title": "A.2 Proof of Theorem 1", "content": "In this section, we'll demonstrate the proof of Theorem 1.\nProof. After the forward pass, the active sets of the original set are known. Thus, the original optimization problem in can be reformulated as\n$z^* = arg min f(z) \\quad subject to h(z) = 0, g_+(z) = 0,$\nWhere y is omitted for simplifying notations, $g_+$ has the same row of the active set as the original inequality constraints $g_\\hat y$.\nAccordingly, the matrix form of the KKT conditions, as shown in 2, can be rewritten as follows:\n$\\begin{bmatrix}\nP_+(z^*,v^*,\\lambda^*) & G_+(z^*) & A(z^*)^\\top \\\\\nG_+(z^*) & 0 & 0 \\\\\nA(z^*) & 0 & 0\n\\end{bmatrix} \\begin{bmatrix}\n\\frac{\\partial z^*}{\\partial y} \\\\ \\lambda \\\\ v\\end{bmatrix} = \\begin{bmatrix}\nq_+(z^*,v^*,\\lambda^*) \\\\ C(z^*)\\\\ b(z^*)\n\\end{bmatrix},$", "subsections": []}, {"title": "A.3 Differentiate Through KKT Conditions Using the Implicit Function Theorem", "content": "In this section, we give a detailed discussion on Eq. (3). The sufficient and necessary conditions for optimality for are KKT conditions:\n$\\bigtriangledown f(z^*) + \\bigtriangledown h(z^*)v^* + \\bigtriangledown g(z^*)\\lambda^* = 0$\n$h(z^*) = 0$\n$D(\\lambda^*) (g(z^*)) = 0$\n$\\lambda^* \\geq 0,$\nApplying the Implicit Function Theorem to the KKT conditions and let $P(z^*,v^*,\\lambda^*) = \\bigtriangledown^2 f(z^*) + \\bigtriangledown^2 h(z^*)v^* + \\bigtriangledown^2 g(z^*)\\lambda^*$, $A(z^*) = \\bigtriangledown h(z^*)$ and $G(z^*) = \\bigtriangledown g(z^*)$ yields to Eq. (2). We can then backpropagate losses by solving the linear system. In practice, however, explicitly computing the actual Jacobian matrices is not desirable due to space complexity; instead, we product some previous pass gradient vectors $\\frac{\\partial L}{\\partial z^*}$ \\in \\mathbb{R}^d, to reform it by noting that:\n$\\bigtriangledown_y L = [ \\frac{\\partial L}{\\partial z^*} \\frac{\\partial z^*}{\\partial y},\\frac{\\partial \\lambda}{\\partial y}, \\frac{\\partial v}{\\partial y} ],$\nThe first term of left hand side is the transposed solution of Eq. (2) and above can be reformulated as\n$\\triangledown_y L = [q,c, b][ P(z^*,v^*,\\lambda^*) D(\\lambda^*) G(z^*) A(z^*)-\\frac{\\partial L}{\\partial z^*}]$,", "subsections": []}, {"title": "A.4 Preserve KKT Norm Gradients", "content": "In a typical optimization algorithm, each stage of the iteration gives primal-dual conditions $r^{(k)}$, we follow the procedures of BPQP and solve the corresponding QP problem $Q^{(k)}$ to define general gradients $\\bigtriangledown_yL^{(k)}$. The key difference here is that instead of using the optimal solution to derive BPQP, we plug in the intermediate points. By IFT,\n$\\frac{\\partial r^{(k)}}{\\partial } = K^{(k)}[dz, dd, dv]^\\top + \\frac {\\bigtriangledown \\gamma^{(k)}} {\\bigtriangledown y}dy = 0.$"}, {"title": "A.5 Simulation Experiment", "content": "In Section 5.1, we randomly generate simulated constrained optimization datasets with uniform distributions and varying scales. We use these datasets to evaluate the efficiency and accuracy of state-of-the-art differentiable convex optimizers as well as BPQP. The methods of comparison briefly introduced previously are now detailed below:\n is a universal differentiable convex solver [19, 15, 1]. SCS [42, 43] solver is employed to accelerate the gradients calculation process.\nqpth is a GPU-based differentiable optimizer, OptNet [14] is a differentiable neural network layer that wraps qpth as the internal optimizer.\nBPQP is our proposed method. Its forward and backward passes are implemented in a decoupled way. It adopts the OSQP [16] as the forward pass solver. In the backward pass, it reformulates the backward pass as an equivalent simplified equality-constrained QP. OSQP is also adopted in the backward pass to solve the QP.\nExact uses the same forward pass solver as BPQP. The optimization algorithm used for the forward pass is the OSQP [16], which is a first-order optimization algorithm that does not share differential structure information. In the backward pass, without using reformulation via BPQP, the Eq. (3) are solved using the matrix inversion method like [2]. As a result, this approach fails to achieve overall efficiency.\n[10] is an open-sourced optimization package that supports hardware accelerated, catchable training and differentiable backward pass. Optimization problem solutions can be differentiated with respect to their inputs either implicitly or via autodiff of unrolled algorithm iterations.\nAlt-Diff [12] adopts ADMM in specializing in solving QP problems with exact solutions as well as gradients w.r.t. parameters."}, {"title": "A.6 Portfolio Optimization Experiment", "content": "Statistical Risk Model (SRM) is used to generate the covariance matrix of MVO in Section 5.2. It takes the first 10 components with the largest eigenvalues by applying PCA on stock returns in the last 240 trading days. SRM shows the best performance of the traditional data-driven approach for learning latent risk factors.\nThis section provides a more detailed introduction to the datasets and metrics used in the experiments described in Section 5.2. The dataset is from Qlib [24] and consists of 158 sequences, each containing OHLC-based time-series technical features [44] from 2008 to 2020 in daily frequency. Our experiment is conducted on CSI 500 universe which contains at most 500 different stocks each day."}]}