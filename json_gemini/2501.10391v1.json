{"title": "Developing an Ontology for Al Act Fundamental Rights Impact Assessments", "authors": ["Tytti Rintam\u00e4ki", "Harshvardhan J. Pandit"], "abstract": "The recently published EU Artificial Intelligence Act (AI Act) is a landmark regulation that regulates the use of AI technologies. One of its novel requirements is the obligation to conduct a Fundamental Rights Impact Assessment (FRIA), where organisations in the role of deployers must assess the risks of their AI system regarding health, safety, and fundamental rights. Another novelty in the AI Act is the requirement to create a questionnaire and an automated tool to support organisations in their FRIA obligations. Such automated tools will require a machine-readable form of information involved within the FRIA process, and additionally also require machine-readable documentation to enable further compliance tools to be created. In this article, we present our novel representation of the FRIA as an ontology based on semantic web standards. Our work builds upon the existing state of the art, notably the Data Privacy Vocabulary (DPV), where similar works have been established to create tools for GDPR's Data Protection Impact Assessments (DPIA) and other obligations. Through our ontology, we enable the creation and management of FRIA, and the use of automated tool in its various steps.", "sections": [{"title": "1. Introduction", "content": "The European Union's recently published Artificial Intelligence Act (AI Act) [1] is the first of its kind regulation that governs AI systems with a particular focus on harms to health, safety, and fundamental rights. A key and novel requirement established in AI Act Article 27 is the Fundamental Rights Impact Assessment (FRIA) which requires deployers of AI systems to assess the risks and impacts of their AI systems on fundamental human rights. The FRIA is a structured process following existing procedures for impact assessments, and was developed based on the similar procedure under the General Data Protection Regulation (GDPR) [2] for Data Protection Impact Assessments (DPIA). As development of AI technologies has progressed rapidly within the last decade, and the AI Act itself is a new legal framework, conducting and using a FRIA poses significant challenges not only regarding legal compliance, but also from the perspectives of data governance to identify and maintain relevant information and information systems to develop tools that can support and enhance these processes.\nThe current conventional method for implementing FRIA is to identify obligations linked to specific clauses in the AI Act and find the steps needed to complete them. For organisations, such tasks are primarily human-oriented activities that utilise word processor software (e.g. MS Word) and document formats (e.g. PDF) that contain unstructured information and are not suitable for developing automated procedures and tooling. Further, organisations commonly have several departments or organisational units that can contain different technologies and practices, making a combined legal assessment of the organisation as a whole a challenging and complicated affair. The AI Act in Article 27-5 foresees such challenges and requires the AI Office, the EU body responsible for the implementation of the AI Act, to create a 'questionnaire' to support organisations in meeting the obligations for a FRIA. The AI Act, in the same article, also states that such a questionnaire should be provided with an automated tool - though it does not clarify what automation or support mean in this context."}, {"title": "2. Rationale", "content": "To develop the ontology, we follow the Linked Open Terms (LOT) ontology engineering methodology [4] which has been used successfully in several projects, and is based on the NeOn ontology engineering methodology which has been used in the creation of similar legally relevant ontologies including for GDPR's DPIA [3]. The first step in LOT is the development of an ontology requirements specification that outlines \"why the ontology is being built and to identify and define the requirements the ontology should fulfil\". For this, LOT recommends the use of competency questions which are a well established practice in the ontology engineering community. We reused the template provided by LOT to generate the ontology requirements specification, which is presented in Table 1."}, {"title": "3. State of the Art", "content": "Within ontology engineering methodologies based on semantic web, including LOT, the reuse of existing ontologies is heavily recommended. Therefore, following the requirements specification, we explore the state of the art to identify relevant resources and assess the extent to which they can be reused to"}, {"title": "3.1. Existing Ontologies for FRIA and Al Act", "content": "Given the recency of the AI Act in terms of development and finalisation, few approaches have emerged that provide ontologies modelling it. Golpayegani et al. were one of the first approaches to model the requirements of the AI Act as an ontology through the AI Risk Ontology (AIRO) [5] - an OWL2 ontology based on an early draft version of the AI Act. AIRO provides a risk management ontology based on the requirements of the AI Act and ISO standards, and acts as the upper ontology for Vocabulary of AI Risks (VAIR) [6]. Golpayegani et al. have demonstrated the use of AIRO and VAIR to model the high-risk use-cases defined in AI Act Annex III as a logical group of semantic concepts and showed that logical reasoning or validation approaches such as SHACL can be used to determine whether the use-case is high-risk under the AI Act [6]. Golpayegani et al. have also developed the AI Card [7] as a visual approach for documenting the AI system through the use of AIRO and VAIR as its machine-readable representation. AIRO and VAIR provide concepts required in the AI Act such as stakeholders, AI processes, and risk management, but do not contain a modelling of the FRIA.\nHernandez et al. developed the Trustworthy AI Requirements Ontology (TAIR) [8] which models the clauses of the AI Act and of relevant ISO standards as a series of requirements and compares them to identify where such standards would be useful for compliance with the AI Act. This work addresses the requirement for using 'Harmonised Standards' in the AI Act, and includes concepts regarding impact assessments and risk management, albeit these are based on a draft version of the AI Act.\nThough not providing an ontology or directly addressing the final AI Act requirements, these works provide an exploration of the FRIA requirements by identifying information involved in conducting a FRIA: the FRIA template produced in the ALIGNER H2020 project [9], an analysis of the FRIA requirements in AI Act by Mantelero [10], the rights impact assessments for algorithmic systems by Gerards et. al [11], the algorithmic impact assessment published by the Govt. of Canada [12], a quantified risk score for impact on fundamental rights by Inverardi et. al. [13], a method for assessing the severity of impacts on fundamental rights by Malgieri and Santos [14], and an interpretation of the draft AI Act's FRIA requirements by Janssen et. al [15]"}, {"title": "3.2. Existing Ontologies for DPIA, GDPR, and Impact Assessments", "content": "In comparison to the AI Act, the GDPR has been in effect for 6 years, and has been addressed through several surveys on compliance approaches and developed ontologies [16, 17, 18]. Notable approaches in these include the ontology of privacy requirements by Gharib et al. [19], The core ontology for privacy requirements (CoPri), [20] which provides a framework for modelling legal processes and requirements, Privacy Ontology for Legal Reasoning (PrOnto) [21] which provides concepts with the aim of modelling legal norms and assessing them through deontic reasoning, and the Data Privacy Vocabulary (DPV) [22] which is an output of the W3C Data Privacy Vocabularies and Controls Community Group (DPVCG), and provides an extensible collection of vocabularies for modelling legal concepts associated with data and technologies.\nOf these, only the DPV has the community and infrastructure supporting the continuos development and refinement of the resource, and is also the only resource that had modelled GDPR which has been expanded to also model the AI Act using the same core concepts [22]. The DPV is also the only resource we know of that provides rich taxonomies to represent real-world concepts associated with the ontological concepts e.g. for purposes and data categories. The DPV features a TECH extension which provides concepts for modelling the technology lifecycle, stakeholders, and documentation, the RISK extension for modelling risk assessments, and the AI extension which extends these to provide Al-specific concepts. In DPV, the legal concepts derived from specific regulations are provided in a"}, {"title": "4. FRIA Ontology", "content": "Our objective is to develop an ontology to model the FRIA as defined in the AI Act Article 27 as an information process through which stakeholders such as deployers and authorities can create automated technological tools to support the compliance activities. For ensuring our ontology is interoperable and extensible, we utilise semantic web standards such as RDF to represent it, SKOS to create a vocabulary or thesauri, and RDFS and OWL2 for knowledge representation. We follow the Linked Open Terms (LOT) [4] as the methodology for ontology engineering, which strongly recommends reusing existing ontologies where relevant. For this, from Section 3, we identified AIRO [5] and VAIR [6] as the most relevant ontologies for the AI Act, and the DPV [22] as a useful resource for practical use of legal concepts. Since AIRO and VAIR are being integrated for the upcoming DPV version 2.1, we aim to support this integration by identifying the concepts not present in these existing ontologies.\nDPV is provided with RDFS+SKOS semantics as the 'default serialisation', with a separate namespace used for OWL2 semantics to support the use of concepts beyond the strict requirements of logical constraints when using OWL2. Following this, we provide the concepts necessary to model the FRIA in this article which can then be expanded as more information is available to represent real-world constraints and logical assertions using OWL2 or another method.\nThe concept for Fundamental Rights Impact Assessments (FRIA) already exists within the main DPV as dpv: FRIA, and is extended as eu-aiact:FRIA in AI Act extension to represent the FRIA as defined within the AI Act. This concept represents the FRIA as both an activity and as an artefact (e.g. a document). Therefore, in our FRIA ontology, we create separate explicit concepts for modelling the information and steps involved in the DPIA process by expanding this central concept.\nBased on the interpretation of the FRIA in AI Act Article 27, and by using existing work interpreting the DPIA in GDPR as a series of steps that are represented through an ontology [3], we identified the following groups of concepts for our ontology:\n1. FRIA Metadata: concepts representing relevant metadata regarding the FRIA such as when it was conducted, by whom, for which AI systems, etc.;\n2. FRIA Necessity: concepts representing the step where a necessity for conducting a FRIA is identified as per AI Act Article 27-1;\n3. FRIA Inputs: concepts representing the inputs required in a FRIA as per AI Act Article 27-1, and the reuse of a DPIA as per AI Act Article 27-4;\n4. FRIA Outcomes: concepts representing the outcomes identified from conducting a FRIA as per AI Act Article 27-1;\n5. FRIA Notifications: concepts representing the step where a FRIA to be communicated to an authority as per AI Act Article 27-3;\n6. FRIA Automated Tools: the use of questionnaire and/or automated tools as per AI Act Article 27-5.\nWe use the following namespaces and prefixes in describing our proposed ontology:\n\u2022\tOur proposed ontology: https://example.com/FRIA# with prefix fria:.\n\u2022\tDCMI Metadata Terms: http://purl.org/dc/terms/ with prefix dct:.\n\u2022\tDPV: https://w3id.org/dpv# with prefix dpv : .\n\u2022\tDPV TECH extension: https://w3id.org/dpv/tech# with prefix tech:.\n\u2022\tDPV RISK extension: https://w3id.org/dpv/risk# with prefix risk:.\n\u2022\tDPV AI extension: https://w3id.org/dpv/ai# with prefix ai :.\n\u2022\tDPV EU AI Act extension: https://w3id.org/dpv/legal/eu/aiact# with prefix eu-aiact:."}, {"title": "4.1. Metadata for FRIA", "content": "A FRIA, as a documentation requirement under the AI Act, is expected to be regularly updated as per Article 27-2 \u201cthe deployer shall take the necessary steps to update the information\". There-fore it is necessary to indicate temporal information and provenance associated with the FRIA. For these, we reuse prior work establishing the reuse of DCMI terms for GDPR's DPIA [3] regarding temporal information (dct : created, dct :modified, dct:dateSubmitted, dct : dateAccepted, dct:temporal, dct : valid), conformance e.g. codes of conduct (dct: conformsTo), descriptions (dct:title, dct:description), identifier or version (dct : identifier, dct:isVersionof), and subject or scope (dct: subject, and dct : coverage).\nTo record provenance, we suggest reusing dct:publisher to record the organisation responsi-ble for conducting the FRIA, dct : contributor to denote the personnel and entities involved, and dct: provenance to refere to a log of changes. Additionally, dct : creator can record the specific entity or tool used to 'create' the resource which is relevant as the AI Act Article 27-5 explicitly provides for the use of automated tools in the FRIA process."}, {"title": "4.2. Concepts to represent necessity of FRIA", "content": "AI Act Article 27-1 describes the conditions under which a FRIA is necessary. An organisation therefore has the obligation to first assess whether it must conduct a FRIA. We represent this process through the concept fria:FRIANecessityAssessment which extends the existing eu-aiact:FRIA concept and can be associated with a FRIA using the relation dpv : hasAssessment. To represent the specific outputs of this process, we create the concepts fria:FRIANecessityStatus which is associated with the assessment using the relation dpv : hasStatus. To represent specific outcomes, we create the instances fria:FRIARequired and fria:FRIANotRequired."}, {"title": "4.3. Concepts to represent inputs of FRIA", "content": "We represent the process of carrying out the FRIA as the concept fria:FRIAProcedure which extends the existing eu-aiact : FRIA concept and can be associated with a FRIA using the relation dpv:hasAssessment. AI Act Article 27-1 describes the information which must be included when conducting a FRIA, which we interpret as follows:\n1. Article 27-1a description of the deployer's processes: represented by extending dpv : Process as the concept fria:AIProcess, and associated using the relation dpv: hasProcess. This follows the DPV's modelling of similar processes for GDPR where a dpv : Process provides a way to combine other concepts such as purposes, data, technologies, and entities in specific roles.\n2. Article 27-1a intended purpose: represented by the existing eu-aiact:IntendedPurpose whose parent is dpv:Purpose, and is assocaited using the relation dpv: hasPurpose. Note that the AI Act's intended purpose is a broad concept that goes beyond DPV's modelling of purpose as referring to the objective or goal, whereas intended purpose includes details such as the AI technique and data involved. Therefore, we suggest also modelling eu-aiact:IntendedPurpose as the subclass of dpv: Process.\n3. Article 27-1b period of time: represented using dpv:Duration and associated using the relation dpv:hasDuration. DPV provides enumerated concepts for different durations such as endless, fixed, temporal, until event, and until time.\n4. Article 27-1b frequency: represented using dpv:Frequency and associated using the relation dpv:hasFrequency. DPV provides enumerated concepts for different frequencies such as continous, often, singular, and sporadic.\n5. Article 27-1b intended to be used: represented as fria:IntendedUse, where we interpret this concept to be different from aiact:IntendedPurpose as the 'purpose' is a declaration of why the AI system is needed or to be used, and 'use' is the contextual application of that purpose in specific scenarios or 'deployments'. The same AI system with one intended purpose can thus have different intended uses in separate scenarios e.g. through variance in input and output data (including decisions"}, {"title": "4.4. Concepts to represent outcomes of FRIA", "content": "AI Act's Article 27-1 states the FRIA's objective is to produce an \u201cassessment of the impact on fundamental rights that the use of (AI) system may produce\u201d, which in the simplest interpretation implies a boolean categorisation as to whether there is or isn't an impact on fundamental rights. We therefore represent the process of determining the outcome of a FRIA process as the concept fria:FRIAOutcome, which extends the existing eu-aiact: FRIA concept and can be associated with a FRIA using the relation dpv:hasAssessment. And to represent the outcomes, we model these as statuses through the concept fria:FRIAOutcomeStatus which can be associated by using the relation dpv:hasStatus. We also create instances to represent the specific outcomes possible as per Article 27:\n1.\tfria:FRIAOutcomeUnacceptableRisk: FRIA outcome status indicating that there is an un-acceptable risk to fundamental rights, implying the AI system should not be used.\n2.\tfria:FRIAOutcomeHighResidualRisk: FRIA outcome status indicating high residual risk to fundamental rights which are not acceptable for continuation.\n3.\tfria:FRIAOutcomeRisksAcceptable: FRIA outcome status indicating residual risks to fun-damental rights remain and are acceptable for continuation.\n4.\tfria:FRIAOutcomeRisksMitigated: FRIA outcome status indicating (all) risks to fundamen-tal rights have been mitigated and it is safe for continuation.\nAs part of the FRIA procedure and the outcome process, it is essential to identify the relevant fundamental rights which might be impacted. Therefore, we reuse the DPV's extension modelling the EU Charter of Fundamental Rights and Freedoms where each article within the charter is rep-resented as an instance of dpv: Right. To represent which right is impacted, we reuse the concept risk:ImpactToRights along with the relevant instance of fundamental right, and associate it by using the relation dpv:has Impact.\nTo enable the granular investigation of impact on rights as required in the FRIA process, we identify the need to to create impact concepts for each right in a manner that allows directly stating that right has been impacted e.g. Impact on Right of Non-Discrimination. We also argue that it would be useful to further represent such impacts at an even more granular level by creating concepts representing impacts on specific requirements within the right e.g. to state there has been an impact on this right due to discrimination based on a specific category such as sex, race, gender, etc. as mentioned in Article 21 of the Charter. We propose such concepts be added to the DPV's extension modelling fundamental rights so that they can be readily used with the rest of DPV's risk and impact assessment concepts."}, {"title": "4.5. Concepts to represent notification of FRIA", "content": "AI Act Article 27-3 states that upon completion of a FRIA, a deployer \"shall notify the market surveillance authority of its results\u201d. We represent this step as the concept fria:FRIANotificationAssessment, which extends the existing eu-aiact:FRIA concept and can be associated with a FRIA using the relation dpv: hasAssessment. This steps requires an assessment of whether the notification is required to be sent, or if there is an exception as Article 27-3 also states \u201cIn the case referred to in Article 46(1), deployers may be exempt from that obligation to notify\u201d.\nTo represent whether a notification is needed and has been communicated, or is exempt, we create the concept fria:FRIANotificationStatus which extends dpv: Status and its instances:\n1.\tfria:FRIANotificationNeeded for when a notification has been identified as being needed, and requires further assessment for whether it is required to be sent or is exempt;\n2.\tfria:FRIANotificationNotSent for when a FRIA notification is identified as being required but it not sent yet;\n3.\tfria: FRIANotificationSent for when the notification is sent; and\n4.\tfria:FRIANotificationExempt for which the obligation to notify is exempt as per Article 46-1. As each market surveillance authority will have the ability to create exemptions, we also note the possibility to expand this concept for different jurisdictions based on the DPV's modular legal framework."}, {"title": "4.6. FRIA Questionnaire and Automated Tool", "content": "AI Act Article 27-5 states the existence of a questionnaire based on a template that the deployers can use to complete the FRIA obligations, such as in Article 27-3 for communicating the FRIA to market surveillance authorities by submitting the filled out questionnaire template. The AI Act Article 27-5 further states that the questionnaire, \u201cincluding through an automated tool\", is intended \"to facilitate deployers in complying with their obligations under this Article\u201d - which means that the FRIA questionnaire and documentation in some part can be based on automated tools.\nTo represent these processes, we find two interpretations based on the word 'template' having two meanings. First interpretation consists of three artefacts a template questionnaire used to create a questionnaire, which is then used by deployers to create a filled out questionnaire. The second interpretation consists of two artefacts a questionnaire is used by the deployer to create a filled out questionnaire. We follow it is the second interpretation, and represent it through the concepts fria:FRIAQuestionnaire to represent the template questionnaire that is given to be filled out by the deployer, and extend it as aiact:FRIACompletedQuestionnaire to represent the filled out questionnaire which the deployer can send in their notice to the market surveillance authority.\nTo represent the involvement of tools as per Article 27-5, we create the conecpt aiact:FRIATool which extends dpv: Technology. This enables the reuse of DPV TECH extension concepts regarding the modality (e.g. service, product), stakeholders (e.g. developer, user), and other relevant data to be modelled using existing concepts. The tool can be represented as being used in relevant steps of the FRIA by associating it with the dpv: is ImplementedUsingTechnology relation.\nWe do not think it is necessary to explicitly define the tool as being automated given the purpose of the ontology is to create information systems which by definition use automation in some form. That being said, automated here can be interpreted to have different meanings within the context of \"to facilitate deployers in complying with their obligations under this Article in a simplified manner\u201d. The tool can be used to determine necessity, to assist in collecting and organising input information, to determine - manually or through reasoning - whether there is an impact on rights, and to support notification to authority aiact:FRIANotificationProcedure.\""}, {"title": "5. Conclusion & Future Work", "content": "Our work represents the first ontology for modelling the Fundamental Rights Impact Assessments (FRIA) under the AI Act in terms of the information involved as well as the procedure for conducting FRIA itself. As we utilised well-established standards in the legal domain - namely the semantic web standards our ontology enables the use of machine-readable information that is interoperable, extensible, and well-structured by default. Through this, we enable the creation of automated tools to assist with the FRIA processes that can use our ontology to structure and use information in a consistent manner across use-cases. By being a semantic web ontology, our approach permits using existing standards for information retrieval such as SPARQL, and for SHACL for validation. It also facilitates use of logical semantic reasoning to infer additional information - such as specific risks and impacts, and to ensure completeness and correctness of information.\nWe developed our ontology by utilising and extending the Data Privacy Vocabulary (DPV), which is a state of the art resource that is continuously developed, and provides a modular approach to representing legal concepts across jurisdictions. This enables the development of practical tools that not only address the FRIA, but are also compatible with the existing and potential uses of DPV in legal processes associated with compliance, documentation, and communication. Our future work therefore"}]}