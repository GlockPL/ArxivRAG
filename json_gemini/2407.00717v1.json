{"title": "Learning System Dynamics without Forgetting", "authors": ["Xikun Zhang", "Dongjin Song", "Yushan Jiang", "Yixin Chen", "Dacheng Tao"], "abstract": "Predicting the trajectories of systems with unknown dynamics (i.e. the governing\nrules) is crucial in various research fields, including physics and biology. This\nchallenge has gathered significant attention from diverse communities. Most ex-\nisting works focus on learning fixed system dynamics within one single system.\nHowever, real-world applications often involve multiple systems with different\ntypes of dynamics or evolving systems with non-stationary dynamics (dynamics\nshifts). When data from those systems are continuously collected and sequentially\nfed to machine learning models for training, these models tend to be biased toward\nthe most recently learned dynamics, leading to catastrophic forgetting of previ-\nously observed/learned system dynamics. To this end, we aim to learn system\ndynamics via continual learning. Specifically, we present a novel framework of\nMode-switching Graph ODE (MS-GODE), which can continually learn varying\ndynamics and encode the system-specific dynamics into binary masks over the\nmodel parameters. During the inference stage, the model can select the most confi-\ndent mask based on the observational data to identify the system and predict future\ntrajectories accordingly. Empirically, we systematically investigate the task con-\nfigurations and compare the proposed MS-GODE with state-of-the-art techniques.\nMore importantly, we construct a novel benchmark of biological dynamic systems,\nfeaturing diverse systems with disparate dynamics and significantly enriching the\nresearch field of machine learning for dynamic systems.", "sections": [{"title": "1 Introduction", "content": "Scientific research often involves systems composed of interacting objects, such as multi-body\nsystems in physics and cellular systems in biology, with their evolution governed by underlying\ndynamic rules. However, due to potentially unknown or incomplete dynamic rules or incomplete\nobservations, deriving explicit equations to simulate system evolution can be extremely challenging.\nAs a result, data-driven approaches based on machine learning have emerged as a promising solution\nfor predicting the future trajectories of system states purely from observational data. For instance,"}, {"title": "2 Related Works", "content": ""}, {"title": "2.1 Learning based dynamic System Prediction", "content": "In recent years, neural networks, espe-\ncially graph neural networks (GNNs),\nhave been proved to be promising in\npredicting the complex evolution of\nsystems consisting of interacting ob-\njects [2, 3, 4, 5, 6]. This was firstly\ndemonstrated by [2] with Interaction\nNetwork (IN), which iteratively infers\nthe effects of the pair-wise interac-\ntions within a system and predicts the\nchanges of the system states. Follow-\ning IN, [3] proposed neural relational\ninference (NRI) to predict systems\nconsisting of objects with unknown\nrelationship. [16] proposed Hierarchi-\ncal Relation Network (HRN) that ex-\ntends the predictions to systems con-\nsisting of deformable objects. [4] pro-\nposed Hamiltonian ODE graph net-\nwork (HOGN), which injects Hamiltonian mechanics into the model as a physically informed\ninductive bias. Later, to better consider the intrinsic symmetry of the target systems, GNNs with\ndifferent invariance and equivariane are proposed [17, 5, 18, 19, 20, 6].\nConsidering that the observation of real-world systems may be incomplete and irregularly samples, [7]\nproposed LG-ODE, which is capable of generating continuous system dynamics based on the latent\nordinary differential equations. Following LG-ODE, [8] proposed Coupled Graph ODE (CG-ODE)\nto further extend the continuous dynamics prediction to systems with unknown relationship. Similar\nideas are also adopted in other time series research [21]. Our work is closely related to the ODE\nbased models [21, 7, 8], and we also encode the system dynamics within the irregularly and partially\nobserved data via spatial-temporal GNN structures [7, 8]. Although these above mentioned methods\nhave made significant contributions to dynamic system prediction from different perspectives, they\nhave been restricted to learning a single system with fixed dynamics."}, {"title": "2.2 Continual Learning & Masked Networks", "content": "Existing continual learning methods can be briefly categorized into three types [22, 23, 24, 25].\nRegularization based methods slow down the adaption of important model parameters via regular-\nization terms, so that the forgetting problem is alleviated [26, 27]. For example, Elastic Weight\nConsolidation (EWC) [28] and Memory Aware Synapses (MAS) [29] estimate the importance of\nthe model parameters to the learned tasks, and add penalty terms to slow down the update rate of\nthe parameters that are important to the previously learned tasks. Second, experience replay based\nmethods replay the representative data stored from previous tasks to the model when learning new\ntasks to prevent forgetting [30, 31, 32, 33]. For example, Gradient Episodic Memory (GEM) [34]\nleverages the gradients computed based on the buffered data to modify the gradients for learning the\ncurrent task and avoid the negative interference between learning different tasks. Finally, parameter\nisolation based methods gradually introduce new parameters to the model for new tasks to prevent the\nparameters that are important to previous tasks [35, 36]. For example, Progressive Neural Network\n(PNN) [37] allocate new network branches for new tasks, such that the learning on new tasks does not\nmodify the parameters encoding knowledge of the old tasks. Our proposed MS-GODE also belongs to\nthe parameter-isolation based methods, and is related to Supermasks in Superposition (SupSup) [12]\nand the edge-popup algorithm [11]. SupSup studies continual learning for classification tasks with\nan output entropy based mask selection, which is not applicable to our task. Edge-popup algorithm\nprovides a simple yet efficient strategy to select a sub-network from the original network, and is\nadopted by us to optimize the binary masks over the model parameters. As far as we are concerned,"}, {"title": "3 Learning System Dynamics without Forgetting", "content": ""}, {"title": "3.1 Preliminaries", "content": "In our work, the model is required to sequentially learn on multiple systems with different dynamics.\nEach system is composed of multiple interacting objects, therefore is naturally represented as a graph\nG = {V, E}. {V is the node set denoting the objects of the systems, and E is the edge set containing\nthe information of the relation and interaction between the objects. Based on the edge set E, the spatial\nneighborhood of a node is defined as \\( N_{\\Omega}(v) = \\{u|e_{u,v} \\in E\\} \\). Each object node v is accompanied\nwith observational data containing the observed states at certain time steps \\( X_v = \\{x_t | t \\in T_v\\} \\). With\nthe system structured as a graph, the observation of the system evolution trajectory is naturally a\nspatial temporal graph, of which each node is an observed state \\( x_t \\). In the multi-body system example,\nthe observation is the trajectories of the particles over time. In the following, we will refer to \\( x^{(t)}_v\\)\nas a 'state' for convenience. The set \\( T_v\\) contains the time steps (real numbers) when the states of\n\\( v\\) are observed and can vary across different objects. For the prediction task, the observations lie\nwithin a certain period, i.e. \\( \\cup_{v \\in V} T_v \\in [t_0, t_1]\\), and the task is to predict the system states at future\ntime steps beyond \\( t_1\\). We denote the future time steps to predict for an object \\( v\\) as \\( T_v^{future}\\). In our\ncontinual dynamics learning setting, the training stage requires a model to sequentially learn on\nmultiple systems with different dynamics and potentially different objects (i.e. V)."}, {"title": "3.2 Framework Overview", "content": "In this subsection, we provide a high-level introduction on the workflow of MS-GODE (Figure 3),\nwhile the details of each component are provided in the following subsections.\nOverall, MS-GODE consists of three core components: 1) An encoder network \\( Enc(\\cdot; \\theta_E) \\) parameter-\nized by the parameters \\( \\theta_E\\) for encoding the observational data into the latent space; 2) A ODE-based\ngenerator \\( Gen(\\cdot; \\theta_G) \\) parameterized by \\( \\theta_G\\) for predicting the future states of the system within the\nlatent space; 3) A decoder network \\( Dec(\\cdot; \\theta_D) \\) parameterized by \\( \\theta_D\\) for transforming the predicted\nlatent states back into the data space. Within a standard learning scheme, the model will be trained and\noptimized by updating the parameters \\( \\{\\theta_E, \\theta_G, \\theta_D\\} \\). However, as introduced above, when continually\ntraining the model on multiple systems with different dynamics, this learning scheme will bias the\nmodel towards the most recently observed system, causing the catastrophic forgetting problem. In\nthis work, inspired by the recent advances in sub-network learning [11], we propose to avoid directly\noptimizing the parameters \\( \\{\\theta_E, \\theta_G, \\theta_D\\} \\). Instead, we train the model by optimizing the connection\ntopology of the backbone model and encode the dynamics of each system into a sub-network. This\nis equivalent to encoding each system-specific dynamics pattern into a binary mask overlaying the\nshared parameters with fixed values. In this way, the interference between learning on different\nsystems with different dynamics, i.e. the cause of the forgetting problem, can be avoided. Moreover,\nthis approach is also memory efficient since the space for storing the binary masks is negligible. With\nthe system-specific masks, the three model components are formulated as:\n\\[\nEnc(\\cdot; \\theta_E \\odot M_E^s); \\quad Gen(\\cdot; \\theta_G \\odot M_G^s); \\quad Dec(\\cdot; \\theta_D \\odot M_D^s),\n\\]\nwhere the superscript s is the system index. The details of the binary mask optimization during\ntraining and mask selection during testing are provided in Section 3.5. In the following subsections,\nall parameters are subsets of \\( \\theta_E, \\theta_G\\), or \\( \\theta_D\\) and are controlled by the corresponding masks. For\nexample, \\( W_{msg}\\) in Section 3.3 is part of the encoder parameters \\( \\theta_E\\) and is under the control of \\( M_E^s\\)."}, {"title": "3.3 Masked Encoder Network", "content": "As the first component of the model, the masked encoder network serves to encode the dynamic\npattern in the observational data into the latent space. As introduced in Section 3.1, the observation of\nthe system is a spatial temporal graph. Therefore, we adopt the attention-based spatial temporal graph\nneural network framework (ST-GNN) [38, 7, 8, 39] to encode the observational data. Originally,\nthe graph attention network (GAT) [40] is designed to aggregate information over the spatially\nneighboring nodes. On spatial temporal graphs, the information aggregation is extended to both\nspatial and temporal neighboring nodes. Such a spatial temporal neighborhood of a state \\( x_t^v\\) is defined\nas the states of the spatially connected nodes within a specified temporal window \\( d_{window}\\),\n\\[\nN_{st}(x_t^v):= \\{x_q^u | e_{u,v} \\in E \\quad and \\quad |t - q| < d_{window} \\}.\n\\]\nThen, the information aggregation is conducted over the spatial temporal neighborhood to iteratively\nupdate the representation of each state. Formally, the update of the hidden representation of a state\n\\( x_t^v\\) at the l-the layer of the ST-GNN is formulated as,\n\\[\nh_{v,t}^{l} = h_{v,t}^{l-1} + \\sum_{x_{u,q}\\in N_{st}(x_t^v)} \\alpha(h_{v,t}^{l-1}, h_{u,q}^{l-1})\\cdot W_{msg}\\cdot msg(h_{u,q}^{l-1}, q - t),\n\\]\nwhere \\( \\alpha(\\cdot, \\cdot)\\) calculates the attention score between a pair of states, and \\( msg(\\cdot, \\cdot)\\) is the message\nfunction commonly adopted in graph neural networks [41]. However, different from the message\nfunction in typical graph neural networks, the temporal relationship between the states is a crucial\npart to understand the system dynamics in our task. Therefore, we follow the strategy in LG-ODE\n[7] to incorporate the temporal distance between the states in the message function and attention\nfunction,\n\\[\nmsg(h_{u,q}^{l-1}, q - t) := \\sigma(W_{tmp} \\cdot concat(h_{u,q}^{l-1}, i_t, q - t)) + TE(q - t),\n\\]\n\\[\n\\alpha(h_{v,t}^{l-1}, h_{u,q}^{l-1}, q - t) := \\frac{exp(msg(h_{u,q}^{l-1}, q - t) \\cdot h_{v,t}^{l-1})}{\\sum_{x_{w,p}\\in N_{st}(x_t^v)} exp(msg(h_{w,p}^{l-1}, p - t) \\cdot h_{v,t}^{l-1})},\n\\]\nwhere \\( TE(\\cdot)\\) is a temporal position encoding developed based on the position encoding in Transformer\n[42] for incorporating the temporal information into the representation. Finally, for the subsequent"}, {"title": "3.4 Masked ODE-based Generator", "content": "For practical consideration, we develop the masked ODE-based generator based on the latent ODE\nframework [43, 7, 21], such that the model can handle observation with irregular temporal intervals\nand predict future states at any time denoted by real numbers. Specifically, the trajectory prediction\nproblem is formulated as as solving an ODE initial value problem (IVP), where the initial values\nof the objects \\( \\{z_{t_1}^v|v \\in V\\} \\) are generated from the final representation of the observational data\n\\( \\{h_{final}^v|v \\in V\\} \\), Section 3.3). Mathematically, the procedure of predicting the future trajectory of a\nsystem s is formulated as,\n\\[\nz_{t_1}^v \\sim p(z_{t_1}^v|{X_v}), v \\in V\n\\]\n\\[\n\\{z_{\\tau}^v|v\\in V, \\tau\\in T_{pred}\\}= Gen(\\{z_{t_1}^v|v \\in V\\}, \\{T_{pred}|v \\in V\\}; \\theta_G \\odot M_G^s)\n\\]\nTo estimate the posterior distribution \\( q(\\{z_{t_1}^v|v \\in V\\}|\\{X_v|v \\in V\\}) \\) based on the observation (i.e.\n\\( \\{X_v\\}_{v\\in V}\\)), the distribution is assumed to be Gaussian. Then the mean \\( \\mu_v\\) and standard deviation\n\\( \\sigma_v\\) are generated from \\( \\{h_{final}^v\\}_{v \\in V}\\) with a multi-layer perceptron (MLP),\n\\[\nq(z_{t_1}^v|\\{X_v|v \\in V\\}) = N(\\mu_v, \\sigma_v) = N(mlp(h_{final}^v; \\theta_G \\odot M_G^s)), v \\in V.\n\\]\nAs noted at the end of Section 3.2, the parameters of \\( mlp(\\cdot)\\) and \\( F_{int}(\\cdot)\\) are part of \\( \\theta_G\\) and controlled\nby \\( M_G^s\\).\nBased on the approximate posterior distribution \\( q(\\{z_{t_1}^v|v \\in V\\}|\\{X_v|v \\in V\\}), we sample an initial\nstate for each object, upon which the ODE solver will be applied for generating the predicted states\nin the latent space. The dynamics of each object in the system is governed by its interaction with\nall the other objects. Therefore, the core part of the ODE-based generator is a trainable interaction\nnetwork that encodes the dynamics in the form of the derivative of each \\( z_v\\),\n\\[\n\\frac{dz_v}{dt}|_{t=t'} = F_{int}(\\{z_u \\in N_\\Omega(v)\\}; \\theta_G \\odot M_G^s),\n\\]\nwhere the function \\( F_{int}(\\cdot)\\) parameterized by \\( \\theta_I\\) predicts the dynamics (derivative) of each object v\nbased on all the other objects interacting with v (i.e. \\( N_\\Omega(v)\\) defined in Section 3.1), and \\( t'\\) denotes\nany possible future time. Note that \\( N_\\Omega(v)\\) only contains the spatial neighbors and is different from\n\\( N_{st}()\\). Because the object-wise interaction at a certain time \\( t'\\) is not dependent on system states\nat other times. For example, in a charged particle system governed by electrostatic force, the force\nbetween each pair of particle at \\( t'\\) is solely determined by the relative positions (i.e. the states) of\nthe particles (Figure 2) at \\( t'\\). In our work, we adopt the Neural Relational Inference (NRI) [3] as the\nfunction \\( F_{int}()\\). Based on \\( F_{int}(\\cdot)\\), the future state of the system at an arbitrary future time \\( t_2\\) can be\nobtained via an integration\n\\[\nz_v^{t_2} = z_v^{t_1} + \\int_{t_1}^{t_2} \\frac{dz_v}{dt} dt = z_v^{t_1} + \\int_{t_1}^{t_2} F_{int}(\\{z_u \\in N_\\Omega(v)\\}; \\theta_G \\odot M_G^s)dt,\n\\]\nwhich can be solved numerically by mature ODE solvers, e.g. Runge-Kutta method. After obtaining\nthe latent representations of the states at the future time steps \\( \\{z_{\\tau}^v|t \\in T_{future}, v \\in V\\} \\), the\npredictions are generated via a masked decoder network that projects the latent representations back\ninto the data space\n\\[\ny_v^t = Dec(z_{\\tau}^v; \\theta_D \\odot M_D^s), t \\in T_{future}, v \\in V.\n\\]\nIn our work, \\( Dec(\\cdot; \\theta_D)\\) is instantiated as a multi-layer perceptron (MLP)."}, {"title": "3.5 Mask Optimization & Selection", "content": "MS-GODE is trained by maximizing the Evidence Lower Bound (ELBO). Denoting the concatenation\nof all the initial latent states (\\( \\{z_{t_1}^v|v \\in V\\} \\)) as Z, the ELBO is formulated as\n\\[\nELBO(M^s) = E_{Z_1\\sim q(Z_{t_1}|\\{x_t^v\\}_{v \\in V})} [log(p(\\{x_t|t \\in T_{future}, v \\in V\\}))]\n\\]\n\\[\n-KL[q(Z_{t_1}|\\{X_v\\}_{v\\in V}))||p(Z_{t_1})].\n\\]\nwhere \\( p(Z_{t_1}) \\) denotes the prior distribution of \\( Z_{t_1}\\), which is typically chosen as standard Gaus-\nsian. \\( M^s\\) denotes the union of all masks over different modules of the framework (i.e. \\( M^s =\\{\nM_E^s, M_G^s, M_D^s\\} \\)). In our model, the parameters \\( (\\theta_E, \\theta_G, and \\theta_D)\\) will be fixed, and the ELBO will\nbe maximized by optimizing the binary masks \\( M^s\\) overlaying the parameters via the Edge-popup\nalgorithm [11]. After learning each system, the obtained mask is added into a mask pool M to be\nused in testing. During testing, MS-GODE will automatically select the most appropriate mask based\non the confidence of reconstructing part of the given observations. Specifically, a given observations\nfrom \\( [t_0,t_1]\\) is first split it into two periods \\( [t_0, \\frac{t_0+t_1}{2}] \\) and \\( [\\frac{t_0+t_1}{2}, t_1]\\). Then, the first half is fed into\nthe model and the correct mask can be chosen by selecting the one that can reconstruct the second\nhalf with the lowest error."}, {"title": "4 Experiments", "content": "In this section, we aim to answer the following questions. 1. How to properly configure MS-GODE\nfor optimal performance. 2. How would the configuration of the system sequence influence the\nperformance? 3. How is the performance of the existing CL techniques? 4. Can MS-GODE\noutperform the baselines?"}, {"title": "4.1 Experimental Systems", "content": "In experiments, we adopt physics and biological cellular systems. The detailed introduction on the\nsystem sequence construction is provided in Appendix A.1.\nSimulated physics systems are commonly adopted to evaluate the machine learning models in the\ntask of learning system dynamics [6, 2, 7]. The physics systems adopted in this work include spring\nconnected particles and charged particles (Figure 2). We carefully adjust the system configuration\nand construct 3 system sequences with different level of dynamics shift (Appendix A.1).\nBiological cellular systems are innovatively introduced in this work based on Virtual Cell plat-\nform [13, 14, 15]. In experiments, we adopt two models: EGFR receptor interaction model and Ran\nprotein based translocation model. We adjust the coefficients of the models to construct a sequence\ncontaining 2 EGFR and 2 Ran systems interleaved with each other (EGFR1 \\( \\rightarrow\\) Ran1 \\( \\rightarrow\\) EGFR2 \\( \\rightarrow\\)\nRan2). Full details are provided in Appendix A.1.2."}, {"title": "4.2 Experimental Setups & Evaluation", "content": "Model evaluation under the continual learning setting. Different from standard learning setting,\nthe models in this paper learns sequentially on multiple systems under the continual learning and\nevaluation are significantly different. After learning each new task, the model is tested on all learned\ntasks and the results form a performance matrix \\( M^P \\in \\mathbb{R}^{N \\times N}\\), where \\( M_{i,j}\\) denotes the performance\non the j-system after learning from the 1-st to the i-th system, and N is the number of systems in\nthe sequence. In our experiments, each entry of \\( M^P\\) is a mean square error (MSE) evaluating the\nperformance on a single system. To evaluate the performance over all systems, average performance\n(AM) can be calculated. For example, \\( A_{N,1} \\equiv \\frac{\\sum_{j=1}^N M_{N,j}}{N} \\) is the average performance after learning the entire\nsequence with N tasks. Similarly, average forgetting (AF) can be calculated as \\( AF \\equiv \\frac{\\sum_{j=1}^{N-1} M_{j,j} - M_{N,j}}{N-1} \\).\nMore details on model evaluation can be found in Appendix A.4. All experiments are repeated 5\ntimes on a Nvidia Titan Xp GPU. The results are reported with average and standard deviations.\nBaselines & model settings. We adopt state-of-the-arts baselines including the performance upper\n(joint training) and lower bounds (fine-tune) in experiments. The state-of-the-arts baselines adopted\nin this work include Elastic Weight Consolidation (EWC) [28] based on regularization, Learning\nwithout Forgetting (LwF) [44] based on knowledge distillation, Gradient Episodic Memory (GEM)\n[34] based on both memory replay and regularization, Bias-Correction [45] based Memory Replay"}, {"title": "4.3 Model Configuration and Performance (RQ1)", "content": "When optimizing the system-specific masks\nusing the edge-popup algorithm [11] (Ap-\npendix A.2), each entry of the mask is as-\nsigned with a continuous value for gradient\ndescent after backpropagation. During infer-\nence, different strategies can be adopted to\ntransform the continuous scores into binary\nvalues. In our experiments, we tested both\n'fast selection' and 'top-k selection' with dif-\nferent thresholds. 'Fast selection' set all en-\ntries with positive score values into '1's and\nthe other entries into '0's. 'Top-k selection' first ranks the score values and set a specified ratio of\nentries with the largest values into '1's. In Figure 4, we show the performance of different strategies.\nOverall, 'top-k selection' is inferior to 'fast selection'. This is potentially because that 'fast selection'\ndoes not limit the number of selected entries, therefore allowing more flexibility for optimization.\nWe also observe that the performance of 'top-k' selection is more sensitive on the cellular systems\ncompared to the physics systems, indicating that the cellular systems have higher optimization\ndifficulty for sub-network (binary mask) learning over system sequences.\nSecond, sub-network learning will deactivate some neurons in the model, which resembles the\ndropout mechanism widely adopted in machine learning models and may cause the model to be over\nsparsified. Therefore, we investigate the influence of dropout rate in MS-GODE. From Figure 5, we\ncould see that smaller dropout rate results in lower error (better performance). This corroborates our\nhypothesis that the mask selection mechanism and dropout are complementing each other, and the\ndropout rate should be decreased when the masking strategy is adopted."}, {"title": "4.4 Sequence Configuration and Performance (RQ2)", "content": "In this subsection, we investigate the influence of system sequence configuration on the learning\ndifficulty and model performance. Specifically, we construct 3 physics system sequences with\nincreasing level of dynamics shift (Details are provided in Appendix A.1.1). Sequence 1 (low-level\ndynamics shift) consists of 8 spring connected particle systems, in which consecutive systems are\nonly different in one system coefficient. Sequence 2 (mid-level dynamics shift) is constructed to have\nhigher level of dynamics shift by simultaneously varying 2 system coefficients. Finally, sequence\n3 (high-level dynamics shift) is constructed by interleaving spring connected particle systems and\ncharged particle systems with disparate dynamics. As shown in Table 1, in terms of both AP and"}, {"title": "4.5 Comparisons with State-of-the-Arts (RQ3,4)", "content": "In this subsection, we compare MS-GODE with\nmultiple state-of-the-arts methods including the\njoint training, which is typically regarded as\nthe upper bound on the performance in contin-\nual learning research. The experiments are con-\nducted on both physics systems 1 and cellular\nsystems 2, which demonstrate that MS-GODE\noutperforms the baselines in both cellular sys-\ntems and physics systems with different con-\nfigurations. Besides, by comparing the results\nacross different sequences in the two tables, we\ncould find that the sequences with gradual dy-\nnamics shift (Sequence 1,2 of physics systems)\nare more difficult to learn than the sequences\nwith abrupt dynamics shift (Sequence 3 of the\nphysics systems and the cellular system)."}, {"title": "4.6 In-depth Investigation on the Learning Dynamics (RQ3,4)", "content": "Table 1 and 2 provide the overall performance, which is convenient to compare different methods.\nHowever, as introduced in Section 4.2, to obtain an in-depth understanding of the performance of\ndifferent methods, we have to seek help from the most through metric, i.e. the performance matrix.\nIn Figure 6, we visualize the performance marices of different methods after learning different\nsystem sequences. The i-th column demonstrates the performance of the i-th task when learning\nsequentially over the systems. Comparing MS-GODE ((a) and (e)) and the other methods, we find\nthat MS-GODE could maintain a much more stable performance of each system when learning\nover the sequence. EWC ((c) and (f)) also maintains a relatively stable performance of each system\nbased on its regularization strategy. However, compared to MS-GODE, the model becomes less and\nless adaptive to new systems (the columns become increasingly darker from left to right). This is\nbecause the regularization is applied to more parameters when proceeding to each new task. Fine-tune\n((b) and (g)) is not limited by regularization, therefore is more adaptive on new systems but less\ncapable in preserving the performance on previous systems compared to EWC. LwF (d), although\nbased on knowledge distillation, does not directly limit the adaptation of the parameters like EWC.\nFinally, based on memory and gradient modification, GEM (h) maintains the performance better than\nfine-tune (g), and is more adaptive to new tasks than EWC (f). More details on the performance\nmatrices is provided in Appendix A.5."}, {"title": "5 Conclusion", "content": "In this paper, we systematically study the problem of continually learning varying system dynamics,\nand propose an effective method MS-GODE for this task. Moreover, we also construct a novel\nbenchmark consisting of biological cellular systems for the field of machine learning on system\ndynamics. Finally, we conduct comprehensive experiments on both physics and cellular system\nsequences, which not only demonstrate the effectiveness of MS-GODE, but also provide insights into\nthe problem of machine learning over system sequences with dynamics shift. Although MS-GODE\noutperforms the baselines significantly, there is still a gap between MS-GODE and the performance\nupper bound (joint training) especially in the biological cellular systems. In our future work, we aim\nto develop improved strategies for sub-network learning to further boost the performance in both\nindividual systems and system sequences."}, {"title": "A Appendix / supplemental material", "content": ""}, {"title": "A.1 System Sequence Configuration", "content": ""}, {"title": "A.1.1 Physics System Sequence", "content": "Simulated physics systems are commonly adopted to evaluate the machine learning models in the\ntask of learning system dynamics [6, 2, 7]. The physics systems adopted in this work include spring\nconnected particles and charged particles (Figure 2) with disparate dynamics, therefore are ideal\nfor constructing system sequences to evaluate a model's continual learning capability under severe\nsignificant dynamics shift. Besides, the configuration of each system type is also adjustable. For the\nspring connected particles, the number of particles, strength of the springs, and the size of the box\ncontaining the particles are adjustable. For the charged particles, the number of particles, charge sign,\nand the size of box are adjustable. In our experiments, we constructed multiple systems with different\nconfigurations, which are aligned into sequences for the model to learn.\nThe physics system sequences are constructed to have different types of dynamics changes. System\nsequence 1 is composed of 8 spring connected particle systems. Each system contains 5 particles,\nand some pairs of particles are connected by springs. An illustration is given in Figure 2. For\neach system, besides the number of particles, the size of the box containing the particles and the\nstrength of spring are adjustable. In Sequence 1, the first 4 systems have constant spring strength\nand decreasing box size. From the 5-th system, the box size is fixed, and the spring strength is\ngradually increased. Sequence 2 also contains 8 systems of spring connected particles and is designed\nto posses more severe dynamics shift. Specifically, both the box size and spring strength vary from\nthe first to the last system, and the values are randomly aligned instead of monotonically increasing\nor decreasing. Sequence 3 is designed to posses more significant dynamics shift than Sequence 2\nby incorporating the charged particle systems in the sequence. Specifically, Sequence 3 contains 4\nspring connected particle systems and 4 charged particle systems, which are aligned alternatively.\nThe box size gradually decreases and the interaction strength (spring strength or amount of charge\non the particles) gradually increases. In a charged particle system, the particles could carry either\npositive or negative charge, and the system dynamics is governed by electrostatic force, which is\nsignificantly different from the spring connected particle system.\nSpecifically, we list the configurations of the systems in Table 3 and 4. Then the three sequences can\nbe precisely represented as:\n1. Sequence 1: \\( S_1 \\rightarrow S_2 \\rightarrow S_3 \\rightarrow S_4 \\rightarrow S_5 \\rightarrow S_6 \\rightarrow S_7 \\rightarrow S_8 \\)\n2. Sequence 2: \\( S_1 \\rightarrow S_8 \\rightarrow S_2 \\rightarrow S_7 \\rightarrow S_3 \\rightarrow S_6 \\rightarrow S_5 \\rightarrow S_5 \\)\n3. Sequence 3: \\( S_1 \\rightarrow C_1 \\rightarrow S_9 \\rightarrow C_2 \\rightarrow S_{10} \\rightarrow C_3 \\rightarrow S_8 \\rightarrow C_4 \\)\nFor each system, the simulation runs for 6,000 steps, and the observation is sampled every 100 steps,\nresulting in a 60-step series. During training, the first 60% part of the trajectory of each system is\nfed to the model to generate prediction for the remaining 40%. For each system sequence, 1,000\nsequences are used for training, and another 1,000 sequences are used for testing."}, {"title": "A.1.2 Biological Cellular System", "content": "In this paper, we build a novel benchmark containing biological cellular dynamic systems\nbased on Virtual Cell [13, 14, 15] with different system configurations and variable selection.\nCurrently, the benchmark is built based on two types of cellular models. The first one is rule-based"}, {"title": "A.1.3 Additional Details of Experimental Settings", "content": "For the encoder network, the number of layers is 2, and the hidden dimension is 64. 1 head is used for\nthe attention mechanism. The interaction network of the generator is configured as 1-layer network,\nand the number of hidden dimensions is 128. Finally, the decoder network is a fully-connected layer.\nThe model is trained for 20 epochs over each system in the given sequence. We adopt the AdamW\noptimizer [47] and set the learning rate as 0.0005."}, {"title": "A.2 Edge-popup Algorithm", "content": "In this work, we adopt the edge-popup algorithm [11] for optimizing the binary masks. The main\nidea is to optimize a continuous score value for each entry of the mask during the backpropagation,\nand binarize the values into discrete binary values during forward propagation (Appendix A.2).\nAccordingly, the strategy for binarizing the mask entry values is a crucial factor influencing the\nperformance. For convenience of the readers, we provide the details about this algorithm in this\nsubsection.\nGiven a fully connected layer, the input to a neuron v in the l-th layer can be formulated as a weighted\nsummation of the output of the neurons in the previous later,\n\\[\nI_v = \\sum_{u \\in V^{l-1}} W_{uv}z_u\n\\]\nwhere \\( V^{l-1}\\) denotes the nodes in the previous layer and \\( z_u\\) refers to the output of neuron u.\nWith the edge-popup strategy, the output is reformulated as\n\\[\nI_v = \\sum_{u \\in V^{l-1}} W_{uv}z_uh(S_{uv}),\n\\]"}, {"title": "A.3 Baselines", "content": "1. Fine-tune denotes using the backbone model without any continual learning technique.\n2. Elastic Weight Consolidation (EWC) [28] applies a quadratic penalty over the parameters\nof a model based on their importance to maintain its performance on previous tasks.\n3. Gradient Episodic Memory (GEM) [34] selects and stores representative data in an\nepisodic memory buffer. During training, GEM will modify the gradients calculated based\non the current task with the gradient calculated based on the stored data to avoid updating\nthe model into a direction that is detrimental to the performance on previous tasks.\n4. Learning without Forgetting (LwF) [44] is a knowledge distillation based method, which\nminimizes the discrepancy between the the old model output and the new model output to\npreserve the knowledge learned from the old tasks.\n5. Bias Correction based Memory Replay (BCMR) [45]. This baseline is constructed by\nintegrating the navie memory replay with the data sampling bias correction strategy [45].\nIn other words, the method does not train the data immediately after observing the data.\nInstead, it stores the observed data into a memory buffer. Whenever testing is required, the\nmodel will be trained over all buffered data.\n6. Scheduled Data Prior (SDP) [46] considers that the importance of new and old data is\ndependent on the specific characteristics of the given data, therefore balance the contribution\nof new and old data based on a data-driven approach.\n7. Joint Training (Joint) jointly trains a given model on all data instead of following the\nsequential continual learning setting."}, {"title": "A.4 Model Evaluation", "content": "Different from standard learning setting with only one task to learn and evaluate, in our setting,\nthe model will continually learn on a sequence of systems, therefore the setting and evaluation are\nsignificantly different. In the model training stage, the model is trained over a system sequence.\nIn the testing stage, the model will be tested on all learned tasks. Therefore the model will have\nmultiple performance corresponding to different tasks, and the most thorough evaluation metric is the\nperformance matrix \\( M^P \\in \\mathbb{R}^{N \\times N}\\), where \\( M_{i,j}\\) denotes the performance on the j-system after learning\nfrom the 1-st to the i-th system, and N is the number of systems in the sequence. In our experiments,\neach entry of \\( M^P\\) is a mean square error (MSE) value. To evaluate the overall performance on a\nsequence, the average performance (AM) over all learnt tasks after learning multiple tasks could\nbe calculated. For example, i.e., \\( A_{N,1} \\equiv \\frac{\\sum_{j=1}^N M_{N,j}}{N} \\) corresponds to the average model performance after\nlearning the entire sequence with N tasks. Similarly, average forgetting (AF) after N tasks\ncan be formulated as \\( AF \\equiv \\frac{\\sum_{j=1}^{N-1} M_{j,j} - M_{N,j}}{N-1} \\).\nThese metrics are widely adopted in continual learning\nworks [48, 34, 49, 50, 51], although the names are different in different works.\nFor convenience, the performance matrix can be visualized as a color map (Figure 6). For example,\nthey are named as Average Accuracy (ACC) and Backwarde Transfer (BWT) in [48, 34], Average\nPerformance (AP) and Average Forgetting (AF) in [49], Accuracy Mean (AM) and Forgetting Mean\n(FM) in [50], and performance mean (PM) and forgetting mean (FM) in [51]."}, {"title": "A.5 Performance Matrix Analysis", "content": "Given a visualized performance matrix, we should approach it from two different dimensions. First,\nthe i-th row of the matrix denotes the performance on each previously learned system after the\nmodel has learned from the 1-st system to the i-th system. Second, to check the performance of a\nspecific system over the entire learning process, we check the corresponding column. For example, in\nFigure 6 (e), each column maintains a stable color from the top to the bottom. This indicates that the\nperformance of each system is perfectly maintained with little forgetting. But if the color becomes\ndarker and darker from top to bottom (increasing MSE), it indicates that the corresponding method is\nexhibiting obvious forgetting problem."}]}