{"title": "Federated Data-Driven Kalman Filtering for State Estimation", "authors": ["Nikos Piperigkos", "Alexandros Gkillas", "Christos Anagnostopoulos", "Aris S. Lalos"], "abstract": "This paper proposes a novel localization framework based on collaborative training or federated learning paradigm, for highly accurate localization of autonomous vehicles. More specifically, we build on the standard approach of KalmanNet, a recurrent neural network aiming to estimate the underlying system uncertainty of traditional Extended Kalman Filtering, and reformulate it by the adapt-then-combine concept to FedKalman-Net. The latter is trained in a distributed manner by a group of vehicles (or clients), with local training datasets consisting of vehicular location and velocity measurements, through a global server aggregation operation. The FedKalmanNet is then used by each vehicle to localize itself, by estimating the associated system uncertainty matrices (i.e, Kalman gain). Our aim is to actually demonstrate the benefits of collaborative training for state estimation in autonomous driving, over collaborative decision-making which requires rich V2X communication resources for measurement exchange and sensor fusion under real-time constraints. An extensive experimental and evaluation study conducted in CARLA autonomous driving simulator highlights the superior performance of FedKalmanNet over state-of-the-art collaborative decision-making approaches, in localizing vehicles without the need of real-time V2X communication.", "sections": [{"title": "I. INTRODUCTION", "content": "Autonomous vehicles employ a variety of sensors such as cameras, LiDAR, GNSS (global navigation satellite systems), and IMUs (inertial measurement units) to perceive and interpret their environment. These vehicles are expected to be a fundamental component of future Intelligent Transportation Systems [1]. Moreover, vehicles enhance their perception capabilities beyond the individual sensor range through Vehicle-to-Vehicle (V2X) communication and 5G, allowing them to share crucial traffic information. Achieving precise 3D location awareness over time is essential for optimizing autonomous driving performance. A promising approach for enhancing location or situational awareness is to exploit collaboration among vehicles, either during training or the decision-making phase, relying on V2X information exchange [2], [3]. This approach becomes even more effective when the uncertainty of sensor measurements can be estimated using data-driven or deep learning techniques [4]. KalmanNet [5], a recurrent neural network (RNN) designed to estimate the uncertainty for a single agent through the principles of the Extended Kalman filter (EKF), will be used as a key module, exactly due to its interpretability and efficiency in capturing unknown system dynamics. This work will explore the potential of avoiding raw data exchange between vehicles, while still leveraging the information among connected agents. Specifically, we will investigate transitioning from collaboration during the decision-making phase to collaboration during the training phase, and the potential benefits of it. To be more concise, instead of exchanging raw information, the data collected by a group of vehicles can facilitate a continual learning paradigm in order to estimate sensor measurements uncertainty, thereby enhancing the accuracy of localization over time.\nCollaboration during training usually refers to a distributed scenario where clients jointly train models used for localization applications, using their own local models. In this federated learning (FL) scenario, a global server aggregates the local models and sends back to the clients the global model after some communication rounds [6], [7]. FedLoc [8], [9] is a very popular generic framework, focusing mainly on indoor localization scenarios of edge devices. However, despite its benefits, it requires extensive trainable parameters and large datasets, even for simple sequences, lacking the explainability of KalmanNet. Indoor localization based on WiFi measurements is also the focus of related FL works [10], [11]. Collaboration during the decision-making phase, usually refers to cooperative localization (CL) based on traditional optimization techniques. Understanding the statistics of measurement noise is crucial for enhancing location estimation accuracy [2]. Centralized methods, such as those using multi-dimensional scaling [12] or quadratically constrained quadratic problems [13], often either assume the noise covariance is known in advance or set it equal to the identity matrix. More practical distributed approaches, which utilize the concept of covariance intersection [14], [15], typically assume the true covariance matrices are known, without addressing how they can be estimated in practice. However, in all cases CL requires raw data exchange in order to localize vehicles, thus resulting in high communication costs and privacy issues. Thus, the challenge addressed in this paper is to design an explainable data-driven localization architecture that utilize the collaborative nature of FL in order to enhance autonomous vehicles localization.\nTo address that challenge, this study combines FL with the inherent interpretable KalmanNet architecture. This novel integration promises high performance, due to diverse data shared by cooperating agents, as well as low computational complexity due to the explainable nature of KalmanNet. Moreover, motivated by distributed parameter estimation approaches [16], our method employs the adapt-then-combine (ATC) strategy. During the adaptation step, each vehicle utilizes its private dataset to train a local KalmanNet model. This model estimates the uncertainty of the specific vehicle's measurements, which is then incorporated into the Kalman filter (KF) solution. In the combination step, we aim to develop a robust global KalmanNet model that integrates information across various vehicles operating in diverse environments, effectively learning the underlying system's dynamics. Furthermore, our approach only requires sharing the weights of the local KalmanNet models. By exchanging and fusing the local models during training, we will achieve better performance than CL approaches.\nTherefore, the main contributions of this study can be summarized as follows:\n\u2022 Exploiting the ATC strategy, we reformulate standard KalmanNet to its FedKalmanNet counterpart, enabling the formulation of a highly efficient distributed learning framework for data-driven localization, limiting the need for data sharing and ensuring privacy protection.\n\u2022 The newly proposed collaborative training paradigm for autonomous vehicle localization is shown to outperform traditional optimization based CL approaches that require exchanging and fusing raw data in real-time V2X conditions.\n\u2022 Extensive numerical evaluations carried out in the renowned CARLA simulator [17] demonstrate the competitive advantages of the proposed federated data-driven localization approach, in terms of absolute pose error.\nOutline: Section II introduces the preliminaries; Section III presents the proposed federated data-driven localization framework; Section IV is dedicated to experimental setup and results, while Section V concludes this work."}, {"title": "II. PRELIMINARIES", "content": "Vehicle i at time instant t, needs to autonomously navigate using its own sensor capabilities. Its state is characterized by the 3D position, i.e, $x_i^{(t)} = [x_i^{(t)} y_i^{(t)} z_i^{(t)}]^T \\in \\mathbb{R}^3$. Utilizing a suite of visual, satellite, and mechanical sensors, the vehicle can gather both self and relative multi-modal observations or measurements concerning its own state and that of a nearby vehicle j. More specifically, we can define the state transition and self-positioning models using data from IMU and GNSS sensors. These models, which are assumed to be degraded by Gaussian noise, denoted as $\\mathcal{G}(\\mu, \\Sigma)$, can be expressed as follows [2]:\n\u2022 State transition model:\n$x_i^{(t)} = f(x_i^{(t-1)}, u_i^{(t)}) + e_i^{(t)}$, (1)\nwhere $e_i^{(t)} \\sim \\mathcal{G}(0, R_i^{(t)})$. Function f(.) employs a constant velocity motion model: $f = Ax_i^{(t-1)} + Bu_i^{(t)}$. Here, $A = I_{3} + B_{3*3}$, $B = diag(\\Delta t, \\Delta t, \\Delta t)$. Control input vector $u_i^{(t)} = [u_{x,i}^{(t)} \\, u_{y,i}^{(t)} \\, u_{z,i}^{(t)}]^T \\in \\mathbb{R}^3$ consists of 3D velocity as recorded by the IMU sensor.\n\u2022 Self positioning measurement model:\n$z_i^{(t)} = x_i^{(t)} + \\eta_p, \\,  \\eta_p \\sim \\mathcal{G}(0, \\Sigma_p)$ (2)\nCollaborative decision-making approaches [18], [19] based on traditional optimization, exploit the V2X connectivity links among nearby vehicles by fusing self and relative vehicular measurements, in order to localize ego vehicle and its neighbors. Relative measurements or observations include distance, azimuth and inclincation angles with respect to nearby vehicles, extracted by visual sensors like camera or LiDAR. Instead of real-time measurement transmission and fusion between vehicles in challenging environments, the proposed collaborative learning scheme in the context of FedKalmanNet will perform offline local models aggregation using only self measurements. Afterwards, the trained FedKalmanNet will be exploited by each individual vehicle in order to localize itself highly accurate and much more efficient than a collaborative decision-making approach."}, {"title": "B. Data-Driven Kalman Filtering for state estimation", "content": "Before we proceed with the presentation of our framework, we will revisit the fundamental equations of the EKF, used for state or location estimation in autonomous driving. This review will help illustrate how standard KalmanNet enhances ego vehicle localization through two key features: the representation of non-linear system dynamics and the estimation of covariance matrices for state and measurement noise using an explainable deep learning approach. Therefore, the steps for estimating state $\\hat{x}_i^{(t)} \\in \\mathbb{R}^3$ and its covariance matrix $\\hat{S}_i^{(t)} \\in \\mathbb{R}^{3\\times 3}$ using the EKF can be described as follows:\n$\\hat{x}_i^{(t)} = A\\hat{x}_i^{(t-1)} + Bu_i^{(t)}$ (3)\n$S_i^{(t)} = AS_i^{(t-1)}A^T + R_i^{(t)}$ (4)\n$K_i^{(t)} = S_i^{(t)}H^T (HS_i^{(t)}H^T + Q_i^{(t)})^{-1}$ (5)\n$\\hat{x}_i^{(t)} = \\hat{x}_i^{(t)} + K_i^{(t)}(z_i^{(t)} - g(\\hat{x}_i^{(t)}))$ (6)\n$\\hat{S}_i^{(t)} = (I-K_i^{(t)}H)S_i^{(t)}$, (7)\nwhere $R_i^{(t)} \\in \\mathbb{R}^{3\\times 3}$ is the state transition covariance matrix, and $Q_i^{(t)} \\in \\mathbb{R}^{3\\times 3}$ denotes the measurement covariance matrix and $z_i^{(t)} \\in \\mathbb{R}^3$ represents the measurement vector required to estimate the state or location of i. Additionally, $H_i^{(t)} \\in \\mathbb{R}^{3\\times 3}$ corresponds to the jacobian matrix of some generic function $g(\\cdot)$ with respect to $\\hat{x}_i^{(t)}$. In case where $z_i^{(t)}$ contains the GNSS position, i.e., direct measurement of i's state, then $g(\\hat{x}_i^{(t)}) = \\hat{x}_i^{(t)}$ and $H_i^{(t)} = I_3$. As such, EKF turns to Kalman filter (KF), i.e, its linear counterpart."}, {"title": "III. FEDERATED DATA-DRIVEN LOCALIZATION: FEDKALMANNET", "content": "In this Section, the proposed FedKalmanNet methodology will be presented. Based on the distributed learning theory [16], the proposed FL scheme can be realized by an ATC strategy, motivated by the fact that each vehicle employs a local KF algorithm utilizing the corresponding KalmanNet, and subsequently the local KalmanNet models are fused at the server side in order to derive a more robust and accurate global KalmanNet. Initially, we will formulate the general approach of FedKalmanNet and then present the proposed adaptation and combination steps of this methodology."}, {"title": "A. Federated KalmanNet", "content": "To establish the FL framework, we consider a network of N vehicles. In this distributed learning framework, each vehicle i participating in the proposed collaborative learning process, utilizes its local dataset $\\mathcal{D}_i = \\{Z_{1:T_i}, X_{1:T_i}\\}$, containing an input trajectory as measured over time by its own sensors (GNSS, IMU, etc.), as well as the corresponding ground truth (or target) trajectory. More specifically, $T_i$ is the length of training trajectories, input $Z_{1:T_i} = [z_i^{(1)} \\, z_i^{(2)} \\, ..., z_i^{(T_i)}] \\in \\mathbb{R}^{6\\times T_i}$ contains the noisy 3D positions and velocities for the corresponding training trajectory, while target $X_{1:T_i} = [x_i^{(1)} \\, x_i^{(2)} \\, ..., x_i^{(T_i)}] \\in \\mathbb{R}^{3\\times T_i}$ contains the corresponding ground truth 3D trajectory. Note that in order to generate input $Z_{1:T_i}$, we add white Gaussian noise to ground truth position and velocity of the training dataset following (1) and (2). For simplicity, we assume that each local dataset consists of a single pair of input and ground truth trajectories.\nEach vehicle employs a local KF algorithm and trains its corresponding KalmanNet model using its private dataset, following equations (8)-(10). The fact that each agent employs only its local dataset to train a local model may lead to limitations in the model's ability to generalize across various environmental conditions. The local KalmanNet model (KalmanNet$\\Theta,i(\\cdot)$) might only capture the uncertainties in sensor measurements specific to the local environment, hence failing to capture the system dynamics across different scenarios (e.g., weather conditions, trajectories in rural or urban areas). To address this limitation, we propose the FedKalmanNet framework. This approach enables agents to collaborate under the coordination of a central server. Through this collaboration, vehicles can learn a more robust KalmanNet model that demonstrates enhanced generalization capabilities across diverse environmental conditions."}, {"title": "B. Federated Data-driven Localization: Adaptation Step", "content": "During the adaptation step, each vehicle i employs a local KF which utilizes a local KalmanNet KalmanNet$\\Theta,i(\\cdot)$ to estimate the Kalman gain:\n$K_i^{(t)} = $ KalmanNet$\\Theta,i(\\cdot)$ (11)\n$\\hat{x}_i^{(t)} = \\hat{x}_i^{(t)} + K_i^{(t)} (z_i^{(t)} - \\hat{x}_i^{(t)})$ (12)\nIn the proposed framework, the local KalmanNet can be trained end-to-end using the local dataset. In more detail, let $\\theta_i$ denote the trainable parameters of the local KalmanNet, and $\\gamma_i$ be a regularization coefficient. Each agent employs an $\\ell_2$-regularized mean-squared error (MSE) loss to optimize its local model, defined as follows:\n$\\ell_i (\\theta_i) = \\frac{1}{T_i} \\sum_{t=1}^{T_i} ||\\hat{x}_i^{(t)}(z_i^{(t)}; \\theta_i) - x_i^{(t)}||^2 + \\gamma_i ||\\theta_i||^2$ (13)\nwhere $\\hat{x}_i^{(t)}(z_i^{(t)}; \\theta_i)$ is the output of the local KF parametrized by $z_i^{(t)}$ and $\\Theta_i$. The fact that the KalmanNet model is optimized using only the local dataset of each agent may lead to limitations in the model's ability to generalize across various environmental conditions. Hence, after all participating vehicles $i \\in N$ have updated their local KalmanNet using equation (13), the next step is the combination phase."}, {"title": "C. Federated Data-driven Localization: Combination Step", "content": "The goal of this step is to develop a model that captures underlying system dynamics and accurately estimates covariance matrices for state and measurement noise using local data from the vehicles. Given the structure of KFs, agents upload to the central server only KalmanNet$\\Theta,i(\\cdot)$, as defined in equation (8). The server then aggregates the local KalmanNets using a fusion rule:\n$KalmanNet_{\\Theta, *} (\\cdot) = \\sum_{i=1}^{N} a_i KalmanNet_{\\Theta, i} (\\cdot)$ (14)\nwhere KalmanNet$\\Theta, *(\\cdot)$ denotes the global KalmanNet and $a_i$ are the combination weights. Afterwards, the server broadcasts the global KalmanNet model back to all clients. Each vehicle then initializes its local KalmanNet model (equation (8)) with the received global model. This iterative process is repeated for M communication rounds, enabling the global model to continuously improve, incorporating diverse data as well as ensuring the privacy of local training datasets.\nThus, the FedKalmanNet method can be realized by a twofold process: adaptation, i.e., training the local KalmanNet using KF concept and the local private dataset, and combination, i.e., aggregating the local models at the server side and broadcasting the global model back to the agents:\n$K_i^{(t)} = KalmanNet_{\\Theta,i}(\\cdot)$ (15)\n$\\hat{x}_i^{(t)} = \\hat{x}_i^{(t)} + K_i^{(t)} (z_i^{(t)} - \\hat{x}_i^{(t)})$ (16)\n$KalmanNet_{\\Theta, *}(\\cdot) = \\sum_{i=1}^{N} a_i KalmanNet_{\\Theta, i} (\\cdot)$ (17)\n$KalmanNet_{\\Theta,i}(\\cdot) = KalmanNet_{\\Theta,*}(\\cdot)$ (18)\nThe proposed FedKalmanNet approach is demonstrated in Figure 1. Moreover, Algorithm 1 summarizes the main steps of the proposed framework."}, {"title": "IV. NUMERICAL RESULTS", "content": "The simulations were carried out using dataset 1 which contains the trajectories of 60 vehicles moving in CARLA simulator's environment [20]. The dataset contains ground truth 3D position, linear velocity, acceleration, etc. For the testing evaluation, we have chosen vehicle with index O as the ego vehicle over the simulation horizon of T = 900 time instances and sampling interval $\\Delta t = 0.1$ sec. The evaluation study will consider two scenarios in order to assess the proposed FL approach: i) comparing FedKalmanNet with the traditional KalmanNet when all the training data are available to the global server, as well as when only the dataset from an individual agent is used during training, ii) how the collaborative training paradigm presented in this work can outperform traditional optimization based CL approaches, which require much larger amount of information from nearby vehicles to localize ego vehicle. Baseline methods, apart from standalone GNSS, include MSMV [18] and LKF-SA [19], which set the covariance matrix of sensor measurements equal to identity. The error metrics include Root Mean Square Localization Error over Time, i.e., RT-LE, in order to evaluate ego vehicle i's ability to localize itself. Additionally, the cumulative distribution function (CDF) of instantaneous localization errors demonstrates the probability of location error to be lower or equal than a specific threshold. For the training of networks, we have exploited four vehicles/clients with trajectories from TownMap10 of CARLA, and varying lengths (T = 1550, 4600, 1450, 1420), which are shown in Fig. 2. Although they seem similar, vehicles actually move with different velocities. For example, the minimum and maximum velocity of agents 1 and 2 are between 8.9-10.8 m/sec and 9.2 \u2013 10.9 m/sec, respectively, while those of 3 and 4 are between 0.7 \u2013 10.7 m/sec and 3.6 \u2013 10.7 m/sec, respectively. The input to the network is the ground truth 3D trajectory degraded by additive white Gaussian noise of zero mean and standard deviation $\\Sigma_p = diag(1.5m, 1.5m, 1.5m)$. Furthermore, additive white Gaussian noise is used for the 3D velocity inputs in order to realistically capture state transition noise. The standard deviation of velocity noise is set to 10% of the ground truth velocity of the specific vehicle, as stated in [21]. Each trajectory is splitted in subtrajectories of length equal to 100, while 80% and 20% out of them are used for training and cross validation. For the centralized training, all four datasets are used to train CentrKalmanNet for 1500 epochs. For the individual training, we exploit the trajectories only from agent 0 and train the network for 500 epochs. For the FL implementation, we adopt the FedAvg [22] implementation, and use 20 communication rounds. Batch size is equal to 1, while learning rate and weight decay are set to 0.3."}, {"title": "B. Evaluation study", "content": "1) Impact of federated learning vs centralized and individual training: In this testing scenario, we will evaluate the performance of the proposed data-driven FL framework with respect to centralized and individual implementation of KalmanNet's training. More specifically, Fig. 3 demonstrates the convergence of FedKalmanNet to CentrKalmanNet after 20 communication rounds. To be more detailed, after each round both FedKalmanNet and CentrKalmanNet are evaluated in terms of RT \u2013 LE with the GNSS based trajectory of ego vehicle as input, which has been generated by adding white Gaussian noise of zero mean and standard deviation $\\Sigma_p = diag(1.8m, 1.8m, 1.8m)$, as well as a bias drawn from uniform distribution U[0.5, 1] to the ground truth. In that way, we will show that the performance of networks is still high enough, regardless of the fact that we have conducted training with input trajectory degraded by Gaussian noise. Furthermore, the standard deviation of velocity noise is set to 15% of the ground truth velocity. Clearly, centralized training achieves superior performance in terms of RT \u2013 LE due to the availability of all training data. However, the distributed framework of FedKalmanNet reduces RT \u2013 LE after each round, as it is expected from the relevant theory, reaching RT-LE at round 20 lower than 1.5m, with respect to 1.43m of CentrKalmanNet. Additionally, Fig. 4 highlights the CDF of ego vehicle localization error using FedKalmanNet (after 20 rounds of training), CentrKalmanNet, IndKalmanNet, a traditional KF taking as input the GNSS and without any knowledge of system uncertainty, and, finally, GNSS. For each one of the curves, we indicate the maximum error attained by each approach. For example, we see that the simple KF reduces GNSS error by almost 3m, while the IndKalmanNet reduces it by 5m, clearly showing the benefits of estimating the underlying uncertainty. Most importantly, the proposed FedKalmanNet reduced maximum GNSS error by 6.3m, reaching the same accuracy with that of CentrKalmanNet. As such, we conclude that the proposed data-driven FL framework efficiently converges to the centralized model's accuracy, significantly improving at the same time the localization accuracy of ego vehicle.\n2) Impact of collaborative training vs collaborative decision-making for ego vehicle localization: In the second testing scenario, we will investigate the performance of Fed-KalmanNet versus CL techniques LKF-SA and MSMV. Our goal is to demonstrate that federated data driven localization which exploits only self measurements of ego vehicle, is capable of outperforming collaborative decision-making solutions which require to fuse information coming from nearby vehicles. As such, by estimating the underlying uncertainty through the proposed collaborative training scheme, we will accurately and cost-efficiently localize ego vehicle. Results are summarized in Fig. 5. To simulate relative and self measurements that have to be fused by the ego vehicle, we set standard deviation of distance, azimuth and inclination angle measurement noise equal to $ \\sigma_{\\rho} = 1 m$, $\\sigma_{\\alpha z} = \\sigma_{\\epsilon} = 4^{\\circ}$, respectively, as well as $\\Sigma_p = diag(3.5, 3.5, 3.5)$. Furthermore, each vehicle establishes a connected neighborhood with its nearby vehicles within a range of 30m, consisting of a maximum number of vehicles (based on shortest distance). In Fig. 5, we demonstrate RT \u2013 LE of each technique with respect to maximum number of connected neighbors. Clearly, GNSS experiences the lowest accuracy, while both FedKalmanNet and GNSS are actually independent of the number of neighbors. LKF-SA improves its accuracy as the size of neighborhood grows larger, reaching RT \u2013 LE equal to 1.62m, requiring at the same time richer V2X communication resources in order to perform the fusion. MSMV performs more or less the same in all cases (2.1m of RT \u2013 LE). We see in all cases that FedKalmanNet significantly outperforms the other solutions, reaching 1.5m of accuracy, exploiting only the self measurements (GNSS and velocity) of ego vehicle. On the other hand, LKF-SA has to exploit larger neighborhoods in order to enhance the localization performance."}, {"title": "V. CONCLUSION", "content": "This paper has introduced FedKalmanNet, the FL counterpart of KalmanNet, in order to enable a collaborative training paradigm among a group of vehicles, aiming to enhcance vehicle localization through self measurments' uncertainty estimation. The distributed learning scenario among a group of vehicles has been formulated through the ATC strategy, where each vehicle exploits initially its local private dataset to train a local KalmanNet, which is then updated by a global aggregation operation at the server side. Evaluation results in CARLA simulator demonstrate that the FL model features almost similar performance with its centralized counterpart, while significantly outperforms the model trained with the data coming from an individual vehicle. Most importantly, we have shown that the proposed FL data-driven localization framework exploiting only self measurements, performs much more efficient than collaborative decision-making schemes, which fuse data from large neighborhoods of connected vehicles in order to localize ego vehicle. As a future study, we will investigate how different aggregation rules at the server side influence the FL model accuracy."}]}