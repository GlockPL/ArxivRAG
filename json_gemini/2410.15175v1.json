{"title": "Implicit neural representation for free-breathing MR fingerprinting (INR-MRF): co-registered 3D whole-liver water T1, water T2, proton density fat fraction, and R2* mapping", "authors": ["Chao Li", "Jiahao Li", "Jinwei Zhang", "Eddy Solomon", "Alexey V. Dimov", "Pascal Spincemaille", "Thanh D. Nguyen", "Martin R. Prince", "Yi Wang"], "abstract": "To develop an MRI technique for free-breathing 3D whole-liver quantification of water\nT1, water T2, proton density fat fraction (PDFF), R2*.\nAn Eight-echo spoiled gradient echo pulse sequence with spiral readout was\ndeveloped by interleaving inversion recovery and T2 magnetization preparation. We propose a\nneural network based on a 4D and a 3D implicit neural representation (INR) which\nsimultaneously learns the motion deformation fields and the static reference frame MRI\nsubspace images respectively. Water and fat singular images were separated during network\ntraining, with no need of performing retrospective water-fat separation. T1, T2, R2* and proton\ndensity fat fraction (PDFF) produced by the proposed method were validated in vivo on 10\nhealthy subjects, using quantitative maps generated from conventional scans as reference.\nOur results showed minimal bias and narrow 95% limits of agreement on T1, T2, R2* and\nPDFF values in the liver compared to conventional breath-holding scans.\nINR-MRF enabled co-registered 3D whole liver T1, T2, R2* and PDFF mapping in a\nsingle free-breathing scan.", "sections": [{"title": "Introduction", "content": "Chronic liver disease affects 1.5 billion people globally, resulting in two million deaths each year.\n(1, 2) The leading cause is nonalcoholic fatty liver disease (NAFLD).(3) The progressive form of\nNAFLD, known as nonalcoholic steatohepatitis (NASH), is often accompanied by liver\ninflammation and fibrosis.(3) Liver fibrosis can progress to cirrhosis, an end-stage condition that\nis fatal.(4, 5) In chronic liver disease, fibrosis, iron, and fat are interrelated and iron may be both\na cause(6) and consequence of liver disease.(7-9)\nProton density fat fraction (PDFF) is a widely used MRI marker for measuring fat content in\ntissues, (10-12) while R2* is used to assess liver iron levels.(13, 14) Although liver biopsy remains\nthe gold standard for diagnosing liver fibrosis, it's invasive, not suitable for regular monitoring,\nprone to variability between observers, and has the risk of complications. Lately, more attention\nhas been given to the potential of T1 and T2 measurements in assessing liver fibrosis and\ninflammation. Previous studies have shown that T1 relaxation time is significantly increased,\nand T2 relaxation time is notably reduced in fibrotic and cirrhotic livers, (13, 15-18) suggesting\nthat these measurements could serve as non-invasive biomarkers for diagnosing liver disease\nand monitoring it over time.\nHowever, there are still technical challenges that limit the use of MRI for liver diseases. While\nPDFF and R2* can be measured together in a single 3D scan, T1 and T2 usually require multiple\n2D scans. The most common sequences for these measurements, 2D MOLLI for T1(19) and 2D\nmulti-echo spin echo (MESE) for T2(20), require multiple breath-holds to capture different\nslices. This leads to longer scan times, discomfort for patients, and misregistration between\nslices.\nIn recent years, magnetic resonance fingerprinting (MRF)(21) has gained attention as a method\nfor simultaneous multi-parametric mapping.(22, 23) By continuously sampling the\nmagnetization during scanning, MRF can encode several parameters at once, generating co-\nregistered, multi-parametric maps from a single scan. However, the k-space data for these\nsignals is highly under-sampled, which can cause errors in the parametric maps.(24) This issue\nbecomes more complex in free-breathing scans, where motion can introduce artifacts if not\ncarefully addressed. Significant efforts have been made to develop algorithms that improve the\nreconstruction of under-sampled k-space data, including model-based iterative methods and\nlearning-based approaches. For example, HD-PROST reconstructs multi-contrast MR images by\nusing redundant information at both local and non-local levels and exploiting the correlations\nbetween different contrasts.(25) Recently, a deep learning framework was developed to\ngenerate high-resolution, co-registered T1, T2, R2*, and QSM maps for the brain by leveraging a\nnetwork-designed k-space sampling pattern.(26) For free-breathing liver scans, MR-multitasking\nwas introduced to create 3D T1, R2*, and PDFF maps, (27) and HD-PROST with motion\ncompensation was used to generate 3D T1 and T2 maps.(22)\nRecently, a new machine learning technique called implicit neural representation (INR) has\nshown potential in medical image reconstruction, registration, and analysis. (28-32) In INR, a\nneural network maps spatial coordinates to desired physical values, such as MRI signal\nintensities at specific voxels, by implicitly learning the geometry of the physical subjects.(33, 34)\nThis method has recently been applied to dynamic image reconstruction using a deformation-\ndriven technique.(31) However, to fully eliminate motion artifacts, this approach typically\nrequires principal components of motion deformation fields, which are usually calculated offline\nfrom an external dataset. Using motion fields obtained with the data itself can lead to artifacts,\nas non-deformation intensity changes between the reference image and images from other\nmotion states can be caused by aliasing or motion artifacts.(31)\nIn this paper, we demonstrate the feasibility of using INR to simultaneously learn motion\ndeformation fields and reference frame images from scratch and in zero-shot, without any prior\nknowledge of the motion deformation fields. We show that this approach is effective in MRF,\nwhere navigator signals and images are acquired in transient states. In summary, we propose a\npulse sequence and INR-based reconstruction method to create 3D whole-liver co-registered\nT1, T2, R2*, and PDFF maps simultaneously in a free-breathing scan."}, {"title": "Methods", "content": null}, {"title": "Pulse sequence", "content": "The multi-contrast pulse sequence proposed, illustrated in Figure 1(a), draws inspiration from\nmcLARO(26) and MR multi-tasking (27)designs. It consists of a module that begins with a non-\nselective inversion pulse which is used to sensitize T1 relaxation, followed by 6 segments each\nconsisting of a navigator pulse followed by 15 spiral multi-echo gradient-echo spiral readouts for\nT2* measurement. The navigator pulse, a central k-space line in the Sl direction (kx = ky = 0), is\nplayed to capture the respiratory motion. In each segment, the readout pulses have the same\nangle with kz reordering sampled from a Gaussian distribution. The spiral leaves rotate at a\ngolden angle between each segment, as shown in figure 1(b). Another module including a\nT2prep pulse (41,42) followed by the same 6 navigator-readout segments was used for T2\nrelaxation measurement, leading to a total of 12 readout segments in each repetition."}, {"title": "Motion signal as input of the neural network", "content": "Because the magnetization is in transient state within each repetition, motion-binning using\nprincipal component-based method(35) designed for steady state imaging led to problem. Here\nwe propose a simple envelope detection method that bins the respiratory motion for navigator\nsignals in transient states. A main coil located near the diaphragm was manually selected, the\nnavigator signal intensity from this coil was normalized, as shown in figure 2.a, and the local\nmaxima are then detected to locate the position of the liver-lung boundary which provides the\ninformation of respiratory state (red curve in figure 2.a).\nThe motion signal ($m_n$ in figure 3) as the input of the 4D INR was constructed as follows: The\nposition of local maxima of the navigator signal described previously were normalized to 0 and\n1(figure 2.b), where 0 and 1 denote the end-of expiration and end-of-inspiration respectively.\nThe points in this normalized navigator signal curve were classified into 12 groups based on\nwhich segment they belong to in their corresponding repetition (figure 2.c). For example, as\nshown in figure 2.c, circles denote the navigator signals in the first acquisition segment in the\npulse sequence, and right triangles indicate the navigator signals in the last segment.\nNavigator signals were sorted in ascending order within each of the 12 groups, and a sliding\nwindow was applied to each group. This window always encloses r navigator signals. It slides\nfrom end-of expiration and end-of-inspiration as from 0 to 1. Every time the window moves up,\nit skips j navigator signals (j<r), leading to r-j shared views between window n and n+1 (figure\n2.c). If the whole scan contains R repetition of the pulse sequence, then there are a total of\n$[\\frac{R-r+j}{j}]$ possible window positions, n = 1,2,...$[\\frac{R-r+j}{j}]$. In this work, we chose the jump size j to\nbe 1 and window size r to be 24. Assume the average navigator signal in window n for segment i\nwas calculated to be $\\overline{m_{n,i}}$. Motion representation $m_n$ was obtained by further average $\\overline{m_{n,i}}$ over\nall segments (i=1..12):\n$m_n = \\frac{1}{N}\\sum_{i=1}^{N} \\overline{m_{n,i}}.$ (1)\nwhere N = 12 is the number of acquisition segments for our pulse sequence design. This\nnumber, as a representation of the respiratory state, will be used as the input of the neural\nnetwork.\nWhen training the network, a random window index n was chosen from 1,2,...$[\\frac{R-r+j}{j}]$ for each\niteration, and only the k-space readouts associated with the navigators bound by sliding window\nn in the 12 segments were fed into the network in this iteration. The readouts in one segment\nhave similar contrasts, and thus our segment-selective (or contrast-selective) motion binning\nstrategy ensures that there are same number of readouts in each contrasts being seen by the\nnetwork in one iteration."}, {"title": "Image reconstruction", "content": null}, {"title": "Optimization problem", "content": "Given the transient state image-series at reference-frame, the signal at echo i can be written\nas(23)\n$S_i(r) = U e^{-R_2 t_i}e^{-i2\\pi f t_i}(W' + F'e^{-i2\\pi v_f t_i})$ (2)\nfor a single-peak fat model. In this equation, the terms W' and F' represent the singular images\nof water and fat, $v_F$ denotes the difference in precession frequency between water and fat. The\nvariable $t_i$ represents the echo time i, and f stands for the total field. In our experiment, we\nspecify the number of singular images used to be 4 as they together account for >99% of the\nenergy of the simulated dictionary. Therefore, $W' = \\begin{bmatrix} W'_1\\\\ W'_2\\\\ W'_3\\\\ W'_4 \\end{bmatrix}$ and $F' = \\begin{bmatrix} F'_1\\\\ F'_2\\\\ F'_3\\\\ F'_4 \\end{bmatrix}$.\nRecalling the strategy that we proposed to represent the motion states by a single number $m_n$\nusing sliding window-based method discussed in section 2.2 and shown in figure 2. The image\nseries for motion state $m_n$ can be written as $S_{in} = UD_n e^{-R_2 t_i}e^{-i2\\pi f t_i}(W' + F'e^{-i2\\pi v_f t_i})$,\nwhere $D_n$ is the motion deformation field for this state with respect to the reference-frame\nimages. Then a NUFFT acting on $S_{in}$ should give the k-space data that matches the acquired k-\nspace data associated with $m_n$. With this data consistency, reconstruction of the reference\nimages and motion deformation field can be formulated as optimization problem:\n$(W', F', R_2, f, \\{D_n\\}) =\nargmin\\sum_{n,i}|K_{n,i} \u2013 NUFFT(SU D_n e^{-R_2 t_i}e^{-i2\\pi f t_i}(W' + F'e^{-i2\\pi v_f t_i}))|+\\lambda||VD_n||_2^2$ (3)"}, {"title": "Network structure", "content": "Our network consists of two INRs, which were built using multilayer perceptrons (MLPs). Figure\n3 outlines the workflow of the network. The INRs for the reference-frame image of MRI\nmodalities and motion displacement field are depicted in the lower and upper branch of the\nnetwork respectively. The INR for the MRI modalities ($f, R_2, W', F'$) mapped 3D voxel\ncoordinates to their corresponding image intensities. The input coordinates were pre-processed\nthrough a learning-based position encoding, $h_l$, before being fed into the MLPs to enhance the\nlearning of high-frequency features. In this position encoding technique, feature vectors were\nassociated with vertices of the grids of different resolutions and were trainable parameters.(34)\nThey were encoded by a hash function and stored in a hash table. An input coordinate queries\nthe feature of the image at a voxel by interpolating the feature vectors associated with adjacent\ngrid vertices from multi-resolutions and combining these features vectors using concatenation,\nand thus the length of the queried feature depends on the number of resolution levels. In multi-\nparametric MRI, MRI modalities of the reference-frame images, $f, R_2, W', F'$, share the same\nanatomy. Therefore, the learned multi-resolution feature vector by hash-encoding $h_l$ can be\nshared among the MLPs used to reconstruct these modalities:\n$f, R_2,W', F' = MLP(h_l(x, y, z))$ (4)\nThe number of resolution levels we chose for the hash-table for $f, R_2, W', F'$ reconstruction is\n16, and the feature dimension of each level is 2, leading to a feature of size of 32 as the input of\nthe MLPs.\nAs W', F' are complex images, there are two MLPs for the real and imaginary components for\neach of them. $R_2$ and $f$ are real images and thus are outputted by single MLPs. Each MLP\nconsisted of an input layer, 4 hidden layers, and an output layer. The feature size for the input\nlayer and hidden layers for all the above-mentioned MLPs are 32 and 64 respectively. As 4\nsingular images were used for the subspace recon, the feature size of the output layer of the\nMLPs for W', F' was 4, and the size of output layer of the MLPs for $R_2$ and $f$ was 1.\nThe upper branch of the network, for the estimation of the motion deformation field, takes the\n3D voxel coordinate with a motion representation value, $m_n$ (equation 1), as input. The hash-\nencoding in this branch, denoted as $h_D$, outputs the feature of the motion deformation\nassociated with $m_n$."}, {"title": "Training details", "content": "$D_n = MLP(h_D(x, y, z, m_n))$ (5)\nWe only use 5 levels of resolution for $h_D$, which helps the training convergence. The following\nMLP had an input layer, 3 hidden layers, and an output layer, and the sizes of these layers are\n10, 32 and 3 respectively, as the final layer outputs the x,y,z components of the displacement\nfield.\nFor each iteration, a random sliding window index n was chosen by the data loader, which gives\na groups of k-space readouts with motion state represented by $m_n$ bound by the sliding\nwindows, calculated using equation (1). $m_n$ together with the 3D voxel-coordinate were the\ninput of the network, and the above k-space data were used to calculate the data consistency\nloss (3) to update the network weights. One epoch traverses all the sliding window indices. With\nthe help of the motion representation value $m_n$, the INR learns a smooth representation of the\nmotion displacement field from end-of-expiration to end-of-inspiration.\nDue to GPU memory limitation, 8-echo image volumes were not able to fit into the GPU all\ntogether. To resolve this issue, the training was divided into two phases: In phase one, only the\nfirst 4 echoes of the mGRE k-space are used for training. In phase two, echo 1 and 3 other\nechoes randomly selected from echo 2-8 were used to update the neural network. In this way,\nthe network was trained for a total of 6 epochs; phase one contains the first two epochs, and\nphase two involves the rest 4 epochs. The network was implemented in pytorch using ADAM\noptimizer (initial learning rate being 0.01) on a NVIDIA A6000 GPU. TorchKbNUFFT, a pytorch\nbased non-uniform library was used in this work.(36)The training time for one subject was\napproximately 3 hours."}, {"title": "Results", "content": "Reference frame water and fat singular images, R2* and BO field, as outputs of the neural\nnetwork, were shown in figure 4, revealing sharp image quality with abundant details for liver\ntissues and veins. The reference frame images registered to the end-of-inspiration and end-of-\nexpiration state of the liver (figure 5.a) using deformation fields learned by the network were\nillustrated, demonstrating the ability of INR-MRF to resolve respiratory motions. Singular images\ngenerated by INR-MRF were compared with zero-filled reconstruction in figure 6 where\nsubstantial blurring, aliasing and motion artifacts were reduced. T1, T2, R2* and PDFF maps\ngenerated using INR-MRF for a representative subject were compared with the conventional\nmethods in figure 7, showing good consistency across the liver.\nFigure 8 shows Bland-Altman plots of average liver T1, T2, R2* and PDFF values obtained from\nthe 10 subjects, demonstrating small bias and narrow 95% limits of agreement. The T1 value of\nthe liver measured using MOLLI was 921.7 \u00b1 28.8 ms, and that measured by INR-MRF was\n884.6 \u00b1 41.9 ms. Liver T2 values measured by MESE and INR-MRF were 37.9 \u00b1 2.8 ms and\n35.8 \u00b1 4.5 ms respectively. R2* and PDFF evaluated using Cartesian mGRE sequence were\n47.9 \u00b1 7.9 Hz and 4.5 \u00b1 1.2 % respectively, and R2* and PDFF evaluated using INR-MRF were\n49.2 \u00b1 9.8 Hz and 4.9 \u00b1 1.8 % respectively."}, {"title": "Discussion", "content": "In this study, we introduced INR-MRF, an unsupervised learning framework that jointly learns\nthe reference frame MRI images and motion deformation fields in zero-shot. INR-MRF utilizes a\n3D and a 4D INR, along with a registration module to produce dynamic MR images with\nenhanced image quality. In addition, the network simultaneously separates water and fat\nimages in the training process, eliminating the need of performing any retrospective water-fat\nseparation.\nWe proposed a contrast-selective sliding window-based motion binning pipeline. Using the\nmotion representation value extracted from the binned navigator signals and 3D Cartesian\ncoordinate as input, the network learns the water and fat singular images, R2* map, BO field,\nand motion deformation fields throughout the respiratory cycle. T1 and T2 maps can be\ngenerated using dictionary matching. Our in-vivo experiment showed comparable quantitative\nvalues of INR-MRF in liver with respect to the reference scans.\nOur method poses several limitations. First, in our model, the BO field being subject to the same\nmotion deformation fields as the magnitude images is an approximation. BO field consists of\ntissue local field and background field, which are convolution of a magnetic dipole kernel with\ntissue local susceptibility sources and susceptibility sources from the background (e.g. air)\nrespectively. The component that deforms in the way described by the learned motion\ndeformation fields was the local field, or more precisely, the local susceptibility sources. As\ntissue susceptibility contains rich information about the pathological conditions of the livers,\ne.g. quantitative susceptibility mapping (QSM)(40, 41) has been used to diagnose liver iron\ndeposition and evaluate fibrosis, (42-44) the BO field obtained in our method might not be very\nuseful to reconstruct an accurate susceptibility map. To get more comprehensive information of\nthe liver including the susceptibility map, a network that better models the physical process\nneeds to be established.\nThe pulse sequence design was also preliminary, as there was only one inversion recovery pulse\nand one T2 preparation pulse included. The T2 prep echo time, 37.5 ms, used in our pulse\nsequence was designed for the liver, which might be too short for other abdominal organs with\nlonger T2. Luckily, it was found that a T2 prep echo time ~85ms was enough to capture a large\nrange of T2 from 50ms to 150ms with negligible errors compared with the ground truth.(26)\nOur sequence can be easily extended to measure the whole abdomen quantitative maps with a\nsimply increasing the T2 prep echo time. On the other hand, more IR and T2 prepared\nacquisition blocks can be added to the pulse sequence as proposed by (22, 23). As long as the\nprincipal components compressed from the corresponding dictionary are calculated, our deep\nlearning reconstruction framework can be used on any pulse sequence designs."}, {"title": "Conclusion", "content": "In this work, we demonstrated the feasibility of acquiring 3D co-registered whole liver T1, T2,\nR2* and PDFF maps in vivo in a free-running scan. Our proposed deep learning frame utilizes\nimplicit neural representation to jointly learns the reference frame MRI images and motion\ndeformation fields in zero-shot."}, {"title": "Data acquisition and post processing", "content": "The experiments were conducted on 10 clinically healthy subjects (5 females; age 28 \u00b1 3.5\nyears) with no history of liver disease. This experiment received approval from the local\ninstitutional review board, and all subjects gave written informed consent prior to scanning. The\nexperiments were performed using a 3T scanner (GE Healthcare, Waukesha, WI, USA),\nemploying a 16-channel array coil. For reference, a 4-echo Cartesian multi-echo gradient-echo\nsequence was used to produce the water, fat and R2*images in a breath-hold at end-expiration\nwith the following parameters: FOV = 480 \u00d7 480 mm\u00b2, reconstruction matrix size = 256 \u00d7 256 x\n20, \u03a4\u0395 = 2.8/6.1/9.4/12.7 ms, TR = 15.82 ms, and slice thickness = 5 mm. 2D MOLLI and 2D\nmulti-echo spin echo (MESE) were acquired during breath-hold at end-expiration for 1 slice,\ntaken from the middle of the liver. The parameters for MOLLI were: FOV = 380 mm\u00b2, matrix =\n256x256, and slice thickness = 5 mm, TE = 1.29, TR = 2.97, and the parameters for MESE were:\nFOV = 380 mm\u00b2, matrix = 256x256, and slice thickness = 5 mm, TR = 350 ms, TE =\n6.25/12.50/18.75/25/31.25/37.50/43.75/50 ms. The proposed INR-MRF sequence was\nexecuted, covering the entire liver with parameters: FOV = 480 \u00d7 480 mm\u00b2, matrix = 256 \u00d7 256\nmm\u00b2, TE = 0.54/1.70/2.87/4.03/5.19/6.36/7.52/8.68ms, TR = 14.2 ms, slice thickness = 5 mm,\nand number of slices = 40. For more information about the pulse sequences, please refer to\nTable S1.\nT1 and T2 maps for INR-MRF were determined using a dictionary matching approach. A\ndictionary of transverse magnetization for the INR-MRF sequence was created via a numerical"}, {"title": "Analysis", "content": "ROIs for T1 and T2 map generated by our method were manually drawn on the slice\ncorresponding to the slice of MOLLI image and MESE image, and ROIs for R2* and PDFF were\ndrawn on the 3D volume corresponding to the 3D Cartesian mGRE images, including as much\nliver tissue as possible while avoiding blood vessels and edges. The mean values of T1, T2, R2*\nand PDFF in the liver ROIs for INR-MRF and conventional scans were compared. The\nrepeatability of the measurements was assessed using Bland-Altman plots."}]}