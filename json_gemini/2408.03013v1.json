{"title": "NeurDB: On the Design and Implementation of an Al-powered Autonomous Database", "authors": ["Zhanhao Zhao", "Shaofeng Cai", "Haotian Gao", "Hexiang Pan", "Siqi Xiang", "Naili Xing", "Gang Chen", "Beng Chin Ooi", "Yanyan Shen", "Yuncheng Wu", "Meihui Zhang"], "abstract": "Databases are increasingly embracing AI to provide autonomous system optimization and intelligent in-database analytics, aiming to relieve end-user burdens across various industry sectors. Nonetheless, most existing approaches fail to account for the dynamic nature of databases, which renders them ineffective for real-world applications characterized by evolving data and workloads. This paper introduces NeurDB, an AI-powered autonomous database that deepens the fusion of AI and databases with adaptability to data and workload drift. NeurDB establishes a new in-database AI ecosystem that seamlessly integrates Al workflows within the database. This integration enables efficient and effective in-database AI analytics and fast-adaptive learned system components. Empirical evaluations demonstrate that NeurDB substantially outperforms existing solutions in managing AI analytics tasks, with the proposed learned components more effectively handling environmental dynamism than state-of-the-art approaches.", "sections": [{"title": "1 INTRODUCTION", "content": "Database management systems (DBMSs) are becoming more automated and intelligent by embracing artificial intelligence (AI). Al empowers these systems to achieve autonomous optimization [12, 22, 33] and support complex analytics [11, 20, 30] with minimal human intervention, thereby catering to advanced data- and Al-centric applications.\nThe aspiration of integrating DBMSs with AI was first expressed forty years ago [5], which has been periodically revisited with evolving technology [7, 24, 28]. With the advancements in both AI and DBMSs, considerable progress has been made in deepening their fusion. Unfortunately, a huge gap remains between the potential of this integration and its current state of usability, largely due to the inherent differences in their paradigms. The dynamic nature of databases, characterized by constantly changing data and workloads due to transactional updates, and user interactions, poses a fundamental challenge. For example, an e-commerce database might experience a sharp increase in workloads during flash sales compared to normal periods, caused by huge volumes of updates from sales transactions and processing. In contrast, AI models typically derive intelligence from static datasets and thus can become outdated quickly in the face of database dynamism. For example, models for learned query optimization often acquire knowledge by training on specific system environments including workload patterns and data distributions. However, when these environments drift, e.g., due to data updates from user interactions, models relying on past knowledge may lead to ineffective query optimizations since they are not updated to reflect new conditions.\nThe discrepancy in dynamicity between AI and DBMSs poses a great challenge to the effective adoption of AI-enhanced DBMSs. First, traditional Al-driven system optimization, including knob tuning [22], intelligent advisors [16, 33], and learned system components [12] such as query optimizers [19, 32], indexes [13], and concurrency control [27], often overlook the dynamicity of data distributions and workloads. Second, another important facet of AI and DBMS integration, namely in-database AI analytics for complex tasks such as disease progression predictions and user purchase recommendations, has gained traction but faces similar adaptability issues. Existing systems generally focus on static model inference [21, 25], model serving [26], and others [31], without considering necessary model adaptations to evolving data and workload patterns. Consequently, they require frequent manual updates and retraining to remain effective, which complicates the analytics workflow. Recent works [14, 15, 17, 29] aim to address these challenges but are typically more effective in controlled scenarios, such as data distribution changes following certain rules or query optimization under read-only workloads. These methods have not been designed to generalize across more dynamic and practical workloads involving continuous read and write operations.\nWe envision a deep integration of AI and DBMSs for adaptability to both data and workload drift. Unlike existing approaches that merely overlay AI onto DBMSs or selectively enhance certain system components, we aim for a comprehensive fusion of AI with DBMSs that enables continuous adaptation to drift. However, achieving this level of integration presents significant challenges. First, the integration necessitates a fundamental redesign of the entire Al workflow, including training, inference, and fine-tuning, within the database architecture. Second, models for learned database components and AI analytics must swiftly adapt to drifting data workloads without losing effectiveness and efficiency. Therefore, developing such a system requires both a system foundation that seamlessly supports model adaptation and Al models that are inherently adaptive in structure.\nIn this paper, we present NeurDB\u2020, an AI-powered autonomous DBMS that provides efficient and effective in-database AI analytics to seamlessly support modern Al-powered applications, and fully embraces Al techniques in each major system component to offer self-driving capabilities. At the core of NeurDB is an in-database AI ecosystem that achieves deep integration of the AI workflow into the database. In this ecosystem, we develop multiple in-database AI operations, such as model training, inference, and fine-tuning, along"}, {"title": "2 PRELIMINARIES", "content": "In this section, we outline the design goals of NeurDB and present the SQL syntax enhanced for AI-powered Analytics.\n2.1 Design Goals\nDBMSs are dynamic as data distributions and workloads evolve over time, and therefore, the system must be designed for adaptability while also guaranteeing reliability and scalability. Building upon this understanding, we define three essential properties for NeurDB.\nAdaptability is the capability of a DBMS to evolve autonomously in response to drifting data and workloads. With optimal adaptability, DBMS can respond to drift in real time.\nReliability depicts the ability of a DBMS to consistently meet performance and accuracy standards, even during phases of adaptation and evolution. With optimal reliability, the system can operate at peak performance and maintain high accuracy consistently.\nScalability refers to the system's capacity to maintain or enhance performance as the workload increases by introducing more resources, such as threads or nodes.\nInformally, the design goal of NeurDB is to ensure the system can uphold reliability as quickly as possible when the system or its components adapt or evolve due to data and workload drift, while ensuring good scalability.\n2.2 SQL Syntax for AI Analytics\nNeurDB incorporates enhanced SQL, which extends from the standard SQL to support AI analytics. As illustrated in Listing 1 and Listing 2, NeurDB introduces a new PREDICT keyword to handle two typical ML tasks: classification with the CLASS OF clause and regression with the VALUE OF clause. Inspired by the original principle of introducing SQL that allows an application developer to write a query with SELECT, and then let the DBMS find the most efficient way to store and retrieve data, we ensure that a developer can submit an Al analytic task simply with PREDICT. All the following operations, such as retrieving training data and invoking Al models, are handled automatically by the database. We also plan to expose more enhanced SQL for AI model management and other AI analytics functionalities. Due to space constraints, we mainly focus on the PREDICT query in this paper.\nWe now present two real-world analytic scenarios that can be directly supported by NeurDB using PREDICT.\nClassification. The disease progression prediction in healthcare can be handed by the SQL shown in Listing 1. By specifying the"}, {"title": "3 SYSTEM OVERVIEW", "content": "We now describe the system architecture of NeurDB as shown in Figure 1, where we achieve the deep fusion of AI and databases by establishing an in-database AI ecosystem. To achieve this, we first holistically redesign each existing database component, such as the query optimizer, transaction manager, and index manager, to support in-database AI analytics and function as learned components for improved performance. In particular, we enhance the SQL parser and the query optimizer to produce a customized query plan for PREDICT queries. Beyond traditional operators for fetching and processing data, e.g., scan and join, the query executor in NeurDB includes in-database AI operators for model training, inference, and fine-tuning. With these AI operators, we effectively align the Al workflow with the database query processing. We are developing additional AI operators, such as model selection, to provide more comprehensive AI services. For example, a query may call the model selection operator (denoted as MSelection) to automatically select the best-suited model for a given prediction task [30], thereby enhancing accuracy and efficiency. We then introduce a new component, called the Al engine, into NeurDB. It handles the AI-related processing requests from AI operators and learned components and creates AI tasks on their behalf, where the task manager dispatches them to the CPU/GPU runtime for execution. Specifically, we propose a data streaming protocol to"}, {"title": "4 THE DESIGN OF NeurDB", "content": "In this section, we present two key subsystems of NeurDB, namely an in-database Al ecosystem and learned system components.\n4.1 In-database AI Ecosystem\nAI Engine. The AI engine of NeurDB, pivotal to all AI-related activities for tasks from both user and internal learned components, operates on a distributed and event-driven architecture to optimize efficiency and throughput. Figure 2 shows the main components and the communicative flow with connected external nodes serving distributed AI tasks. In the Al engine, the task manager is the main component that coordinates and schedules the tasks and resources. It handles and parses the incoming AI tasks, and creates a dispatcher for each task. A dispatcher connects to multiple AI runtimes at external nodes. It also loads and caches the necessary data required by the corresponding AI tasks, performs data pipelines on it for preprocessing, feature engineering, etc, and pushes the prepared data and model weights to the remote AI runtime to trigger AI activities. Notably, the data is transferred in a streaming and pipelining manner to minimize the delay in the data preparation steps.\nData Streaming Protocol. During an AI task, the Al runtime receives data continuously from the database. NeurDB's AI engine optimizes this process with a dedicated data streaming protocol to reduce the time and memory overheads. Specifically, the AI runtime establishes a TCP socket connection with the dispatcher. When a task is assigned to the dispatcher, it first schedules the Al runtimes and performs handshakes with them to negotiate (1) model parameters, such as model structure, model arguments, the training batch size, etc, and (2) streaming parameters, e.g., the initial size for send and receive buffers and the number of batches per transmission. Then, it starts the data and model transfer through the connection. Notably, to support adaptable control and scheduling over resources, these parameters can be dynamically updated for an ongoing AI task through a data-driven dispatcher. This makes the Al engine a self-driving component, thereby controlling and optimizing its operations autonomously.\nModel Manager. Given the dynamic nature of DBMSs, a typical Al lifecycle extends beyond a single model. As new data is introduced, incremental updates and retraining are required to address data and workload drifts that degrade predictive performance. This process results in multiple evolving model versions, creating significant management difficulties and storage overheads. To address this challenge, NeurDB leverages the capabilities of databases to efficiently manage AI models and handle drift by design. Specifically, it introduces a dedicated model manager in its Al engine, enabling fine-grained model management with efficient updates. The model manager provides high-level interfaces for handling Al operations, such as training, inference, and fine-tuning, executed via model views. Similar to data views in DBMSs, model views serve as logical abstractions of AI models tailored for specific tasks, with physical representations maintained in model storage. Formally, a model M is uniquely defined by its Model ID (MID) i and the timestamp of creation t, i.e., $M_{i,t}$. A model $M_{i,t}$, created by either users or internal components, comprises a series of layers L, each identified by a Layer ID (LID) j and its training timestamp. To generate outputs for data X, the layers are executed sequentially: $M_{i,t}(X) = L^{(n)}(L^{(n-1)}(...(L^{(1)}(X)))$. This layered model storage approach aligns with the structure of deep neural networks (DNNs), ensuring fast and efficient AI model accessibility. Notably, this model formulation can also be generalized to non-linear DNN architectures that are represented as directed acyclic graphs, which can be achieved by executing layers based on the topological order.\nModel Incremental Update. Leveraging its layered model storage, NeurDB enables linear versioning for a specific model and supports incremental model updates through fine-tuning. In particular, to adapt the current model to drifting data distributions, the AI engine selectively fine-tunes the final layers using the updated data stored in the designated database relation and freezes the preceding layers. Subsequently, only the updated layers remain persistent in the model storage, from where they can be extracted and merged with the previously frozen layers to create a new model version.\nFigure 3 illustrates how the model manager supports incremental updates for AI models. Whenever an inference or fine-tuning task is initiated, the system retrieves all layers up to the most recent version to construct the model, i.e., for a model $M_{i,t}$ with k layers, $M_{i,t}(X) = L_{i,t_k}^{(k)}(L_{i,t_{k-1}}^{(k-1)}(...(L_{i,t_1}^{(1)}(X)))) s.t. \\forall p, q e {1, ..., k}, L_{i,t_p}^{(p)} \\rightarrow t_p \\geq t_q \\wedge t_p \\leq t$. Let us consider the example shown in Figure 3. Supposing the model $M_1$ requires fine-tuning the last layer $L_n$, $M_{1,2}$, namely the second version of $M_1$, can then be"}, {"title": "4.2 Fast-adaptive Learned Components", "content": "In this section, we introduce two key learned system components, including learned concurrency control and learned query optimizer, which can achieve fast adaptation to data and workload drift. To achieve this, we fundamentally rely on the underlying Al ecosystem. We non-intrusively monitor the system conditions such as transaction throughput and data distributions, which can be used to detect data and workload drift in real time. Based on these metrics, NeurDB automatically triggers model fine-tuning to adapt to continuously evolving data and workloads, and continually generates valid input for model pre-training, allowing the model for learned system components to gain global knowledge of most drifts.\nLearned Concurrency Control. We design an efficient learned concurrency control algorithm that can continually adapt to changing workloads, as shown in Figure 4. Given a transaction T with multiple operations, our algorithm incorporates a decision-making model F to assign each operation op the optimal concurrency control action 8 based on the current system condition represented as x, i.e., d = F(x). Unlike the state-of-the-art approach [27] that simply adjusts actions based on predefined transaction or operation patterns (e.g., transaction type), our approach learns the optimal action based on the contention state, which includes both conflict information (such as dependency) of transactions and contextual information (such as the transaction length). For instance, when a write is performed on high-contention data records, we may immediately abort the transaction to avoid unnecessary costs, as the transaction is likely to be aborted eventually. In contrast, we may execute a read on low-contention records with optimistic concurrency control without locking to avoid extra conflict detection overhead, and a long transaction that is supposed to run for a long time should have high priority. By using a modelling paradigm based on the contention state, our model is more likely to generalize to drifting workloads with varying levels of contention. However, since transactions can be completed in milliseconds, the model must be efficient so as not to become a bottleneck. To achieve this, we first develop a fast encoding technique to significantly reduce the dimension of contention state representation, and then compress the model with a flattened layer to improve inference efficiency.\nAs the model is compressed to trade generalizability for performance, the representation of the contention state may gradually become inaccurate over time due to workload drift. Consequently, when we detect workload drift through their impact on transaction performance, we introduce a fine-tuning process for F to adapt it into Fnext. With the leaner architecture of the model, the"}, {"title": "5 EVALUATION", "content": "In this section, we present our preliminary evaluation results. We first introduce the experimental setup, and then evaluate the in-database AI ecosystem under real-world AI analytics scenarios, and the learned system components with data and workload drifts.\n5.1 Experimental Setup\nWe conduct experiments on a server equipped with an Intel(R) Xeon(R) W-2133 CPU@3.60GHz (12 cores, 24 threads), 64 GB memory, and 3 NVIDIA GeForce RTX 2080 Ti GPUs. All experiments are executed within Docker containers based on the official Ubuntu 22.04 image with CUDA 11.8.0, leveraging the host's GPU resources.\n5.1.1 Benchmarks. We construct two real-world applications that require Al analytics."}, {"title": "5.2 In-database AI Analytics", "content": "We evaluate the in-database AI analytics in terms of end-to-end latency, training throughput, and loss variation with data drift.\nEfficiency and Scalability. We study the efficiency of NeurDB on AI analytics workloads by comparing it with PostgreSQL+P. As observed in Figure 6(a), NeurDB achieves up to 41.3% and 48.6% lower end-to-end latency, and 1.96\u00d7 and 2.92\u00d7 higher training throughput"}, {"title": "5.3 Learned System Components", "content": "We now investigate the performance of our proposed learned system components.\nLearned Concurrency Control. To evaluate the proposed concurrency control algorithm, we compare NeurDB with PostgreSQL using the micro-benchmark with varying thread counts. The results, shown in Figure 7(a), demonstrate that NeurDB achieves up to 1.44x higher transaction throughput than PostgreSQL. We attribute this performance gain to the proposed algorithm's ability to schedule transactions more effectively than serializable snapshot-isolation [23], a static concurrency control algorithm employed in PostgreSQL. We further evaluate the adaptability of our proposed algorithm against Polyjuice [27], the state-of-the-art learned algorithm. Due to the limitation of constraining the transaction execution workflow, implementing Polyjuice on the codebase of NeurDB would be cumbersome. We therefore opt to implement our algorithm, named NeurDB(CC), into the Polyjuice codebase to facilitate a fair comparison. We set up a drift workload based on TPCC [9] by varying the number of warehouses and threads. As shown in Figure 7(b), NeurDB(CC) adapts quickly to workload drifts and outperforms Polyjuice by up to 2.05\u00d7. The superior performance of NeurDB(CC) mainly stems from its design that encapsulates a fast yet accurate model to find the best concurrency control action, while facilitating the fine-tuning process with the two-phase adaptation algorithm."}, {"title": "6 RELATED WORK", "content": "Our work relates to a broad spectrum of efforts on the fusion of AI and databases. The initial concepts [5, 10] can be traced back to the 1980s. At that time, the fusion was far from reality due to limited development in both realms. With advancements in both fields over the years, numerous attempts by academia [12, 22] and industry [11, 16] have been made. However, many problems remain open, and it is important to consider database dynamicity in the fusion of Al with databases. Further, the system architecture may require a re-design to support AI-powered operations. NeurDB has been designed along this direction by seamlessly integrating AI into the database architecture, enabling continuous adaptation to data and workload drift."}, {"title": "7 CONCLUSIONS", "content": "This paper presents NeurDB, a novel AI-powered autonomous DBMS that is adaptable to data and workload drift. NeurDB, with its fast-adaptive learned system components and in-database AI ecosystem, facilitates efficient and effective in-database AI analytics. Empirical evaluations demonstrate the superiority of NeurDB, highlighting its potential to realize a seamless fusion of AI and databases."}]}