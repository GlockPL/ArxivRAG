{"title": "TourLLM: Enhancing LLMs with Tourism Knowledge", "authors": ["Qikai Wei", "Mingzhi Yang", "Jinqiang Wang", "Wenwei Mao", "Jiabo Xu", "Huansheng Ning"], "abstract": "Recently, large language models (LLMs) have demonstrated their effectiveness in various natural language processing (NLP) tasks. However, the lack of tourism knowledge limits the performance of LLMs in tourist attraction presentations and travel planning. To address this challenge, we constructed a supervised fine-tuning dataset for the culture and tourism domain, named Cultour. This dataset consists of three parts: tourism knowledge base QA data, travelogues data, and tourism diversity QA data. Additionally, we propose TourLLM, a Qwen-based model supervised fine-tuned with Cultour, to improve the quality of the information provided about attractions and travel planning. To evaluate the performance of TourLLM, we employed both automatic and human evaluation, and we proposed a human evaluation criterion named CRA (Consistency, Readability, Availability). The experimental results demonstrate the effectiveness of the responses generated by the TourLLM. Our proposed Cultour is accessible at https://github.com/mrweiqk/Cultour.", "sections": [{"title": "1. Introduction", "content": "Large language models (LLMs) such as ChatGPT[1] and Llama[2] have proven their effectiveness in various natural language processing (NLP) downstream tasks with their excellent performance[3]. These models generate natural and fluent language expressions in diverse contexts by capturing linguistic patterns from vast amounts of textual data, significantly advancing NLP technology[4].\nHowever, with the increasing public demand for various travel needs, there is a noticeable imbalance between the supply of tourism services and the growing demand. The applications of LLMs in the tourism domain are evident, such as personalized recommendations, language translation, and chatbots[5]. However, the lack of tourism domain knowledge limits the performance of LLMs in attraction recommendations and travel plans. This limitation restricts the application of LLMs in tourism[6]. Additionally, while LLMs perform exceptionally well in English environments, their performance in Chinese environments is relatively limited. This discrepancy is mainly due to the complexity and uniqueness of the Chinese and the differences in data distribution between Chinese and English. These factors can create barriers for non-English speakers and limit the public's access to travel advice.\nTo address these limitations, researchers have explored a range of vertical domain fine-tuning methods to alleviate the lack of corpus in the domain such as Parameter-Efficient Fine-Tuning(PEFT)[7], Low-Rank Adaptation of Large Language Models(LoRA)[8], and Quantized LoRa(QLoRA)[9]. For instance, researchers have constructed domain-specific datasets in the medicine and law domain and employed techniques like continued pre-training, vertical domain fine-tuning, and learning from human feedback[10] to enhance model performance. This has driven the development of LLMs in specific domains resulting in more specialized outcomes such as HuaTuo for Chinese medical knowledge[11] and Lawyer LLaMA for legal knowledge[12].To enhance the accuracy of LLMs in providing travel advice and improving user experience in the tourism domain, it is crucial to develop LLMs tailored to the tourism domain.\nIn this paper, we construct a Chinese Supervised Fine-Tuning(SFT) dataset for the culture and tourism domain, named Cultour, which consists of three"}, {"title": "2. Related Work", "content": "The emergence of general LLMs like ChatGPT 3.5 opens up a new way of life for people and reduces the cost of living[13]. However, in specific application domains, the performance of general large models is still limited[12]. Therefore, researchers are considering combining domain-specific data with general-domain large models to train a vertical-domain large model to serve specific domains. Huang et al. [12] used 50k legal domain-related data to continue pre-train the model, enabling it to possess more relevant knowledge in the legal domain. In the process of answering questions, the model's responses are more knowledgeable. Yang et al.[14] implemented a complete LLMs training process involving pre-training, Supervised Fine-Tuning (SFT), and Reinforcement Learning from Human Feedback (RLHF) to enhance the"}, {"title": "3. Our Approach", "content": "In this section, we provide a detailed overview of our proposed method for constructing the Cultour dataset and the PEFT method for fine-tuning TourLLM. The overall training process is shown in Fig. 1."}, {"title": "3.1. Dataset construction", "content": "People appreciate local attractions in tourism and show a strong interest in cultural heritage and intangible cultural assets. However, the training data for general LLMs in the cultural and tourism domain is relatively limited, resulting in suboptimal performance. To address this challenge, we constructed Cultour dataset to enrich the culture and tourism domain data. This dataset includes tourism knowledge base QA data, travelogues data, and diverse QA data in the tourism domain. The specific data statistics are shown in Table 1."}, {"title": "3.1.1. Tourism knowledge base QA data", "content": "It is worth noting that there is a large amount of tourism-related data on the internet, which includes misinformation, advertisements, and useless text.\nTo utilize tourism resources more accurately, we collected common questions and answers about attractions, food, and intangible cultural heritage from official websites. To ensure the accuracy of the answers, we manually verified each one, ultimately constructing a comprehensive tourism knowledge base. Some examples from the Culture dataset are shown in Table 2.\nInspired by previous research[25], we design a specialized prompt template for generating SFT data based on the structured data in Table 2. The prompt template is shown in Table 3. Utilizing the powerful capabilities"}, {"title": "3.1.2. Travelogues data", "content": "Travelogues data is open-ended, unlike knowledge base QA data. We selected data from travel planning provided by some travel agencies and travelogues on tourism platforms. We performed manual cleaning, secondary design, and annotation to ensure the data input and output format is consistent with human reading habits. Ultimately, we generated 1,792 travelogue"}, {"title": "3.1.3. Diversity QA data", "content": "To improve the performance of LLMs in the tourism domain and enhance their understanding of human questions, we expanded the data to meet the versatility of TourLLM when facing diverse data. It involves many aspects, including eating, living, traveling, touring, shopping, and entertaining. We use ChatGPT to automatically ask questions to collect possible questions and answers, aiming to simulate real user needs, thereby making LLM more accurate and appropriate when answering actual questions. Finally, we collected 2,027 QA pairs of SFT data."}, {"title": "3.2. Parameter-Efficient Tuning", "content": "To enable the LLMs to understand people's questions, inspired by previous work[27], fine-tuning the entire model based on the given domain-specific SFT data requires substantial computational resources. We prepare 51K general domain data [28], combine Cultour as all training corpus, and use parameter-efficient fine-tuning methods to train LLMs. This approach allowed us to fine-tune the model with fewer computational resources. Among these methods, we used LoRA[8] as the fine-tuning method for TourLLM. Specifically, the Lora method freezes the parameters of LLMs and introduces an additional trainable low-rank decomposition matrix in each transformer layer, as shown in Fig. 2. The blue part in Fig. 2 represents the pre-trained weights of frozen LLMs, and only the parameters in the red part are trained. In y = Wx, W denotes the pretrained nk parameter matrix. We compute y by introducing low-rank matrices A(Rnr) and B(Rrk).\n$$y = (W)x + (AW)x = Wx + BAx$$\nIn Eq. (1), r denotes the rank of A and B, and r is much smaller than min(n, k). Only parameters A and B participate in the training of the model, so we can complete the training of model parameters at a smaller cost and improve model performance."}, {"title": "4. Experimental", "content": "To validate the performance of the TourLLM model, we evaluate it against common LLMs and conduct a detailed analysis of the results. Additionally, we introduce CRA, a human evaluation standard specifically for LLMs in the tourism domain, which assesses the model's performance based on Consistency, Readability, and Availability."}, {"title": "4.1. Baseline", "content": "To evaluate the effectiveness of our method, we compare TourLLM with ChatGPT[29], ChatGLM3[30], Alpaca[31], Qwen1.5[32].\nChatGPT3.5[29] is an NLP model designed by OpenAI, which uses manually annotated data for training and reinforcement learning to enhance the model's capabilities.\nChatGLM3[30] is an open-source model in the ChatGLM series, characterized by its low deployment barrier. Additionally, it demonstrates strong performance across various datasets in semantics, mathematics, reasoning, code, knowledge, and other domains.\nAlpaca[31], derived from LLAMA and continued pretrained with Chinese textual data, exhibits robust proficiency in Chinese comprehension. Furthermore, it uses Chinese instruction data for fine-tuning to enhance the ability of the model to understand the ability of human instructions.\nQwen1.5[32], an encoder-only Transformer model, accommodates prompt with maximum length of 32K tokens and is compatible with multiple languages, including English, Chinese, French, and Spanish. Additionally, it has been made open-source in various sizes, including 0.5B, 1.8B, 4B, 7B, 14B, and 72B."}, {"title": "4.2. Experimental settings", "content": "In this section, we introduce the parameters involved in the fine-tuning TourLLM process. We set the maximum length of the input sequence to 1024 and 3 epochs. We set the learning rate (Lr) to 5e-4 and employ learning rate warm-up with a setting of 100[33]. In Lora, The rank r is set to 8, the constant a is set to 16, and the dropout is set to 0.1. We utilize the Adam[34] optimizer to update the Lora parameters. All experiments are conducted on 2 Nvidia GeForce RTX 3090 GPUs."}, {"title": "4.3. Evaluation Metrics", "content": "We evaluate the performance of TourLLM through three metrics: BLEU [35], Rouge[36], and Meteor[37].\nBilingual Evaluation Understudy(BLEU)[35] is an evaluation metric used to measure the accuracy of models with multiple correct output results. It compares the overlap of n-grams between candidate translations and reference translations. It is commonly used for evaluating machine translation quality.\nRecall-Oriented Understudy for Gisting Evaluation(ROUGE)[36] is a set of metrics used to evaluate automatic summarization and machine translation. It measures the \u201csimilarity\u201d between an automatically generated abstract or translation and a set of manually generated reference abstracts by calculating the corresponding score.\nMetric for Evaluation of Translation with Explicit ORdering(Meteor)[37] is a metric used to evaluate the quality of machine-translation output. Compared to BLEU, METEOR considers more factors such as synonym matching, stem matching, and word order, making it generally considered a more comprehensive evaluation metric."}, {"title": "5. Result", "content": "In this section, we use automatic and human evaluation methods to evaluate the performance of TourLLM."}, {"title": "5.1. Automatic evaluation", "content": "To evaluate the performance of LLMs, we design 60 questions based on the aspects of eating, living, traveling, traveling, shopping, and entertaining, and collect all the responses without any prompt templates from LLMs. For\nResponses, we use BLEU-1 (B-1), BLEU-2 (B-2), ROUGE-1 (R-1), ROUGE-2 (R-2), ROUGE-L (R-L), and Meteor as the metrics to evaluate LLMs, the result is shown in Table 5.\nIn Table 5, the TourLLM model achieved optimal performance on most metrics. On the BLEU-related metric, the performance of TourLLM is much higher than other models. On the Rouge-L metric, TourLLM achieved the second-best performance. On the meteor metric, TourLLM achieved optimal performance compared with other models. This proves the TourLLM model can improve QA effects in the culture and tourism domains."}, {"title": "5.2. Human evaluation", "content": "Inspired by the previous literature [38], we conduct the human evaluation to assess the acceptability of the results generated by LLMs. We design sixty questions for LLMs and collect responses from ChatGLM3, Qwen1.5, Llama-Chinese, TourLLM, and ChatGPT3.5. To facilitate a fair evaluation,"}, {"title": "5.3. The impact of data volumes", "content": "We investigate the effect of varying the amount of SFT data on model performance. Specifically, we use 1K, 5K, 10K, 30K, and 60K data to train Qwen 1.5 and utilize BLEU-1, Rouge-L, and Meteor to evaluate performance, the results are shown in Fig. 3. With the improvement of the number of SFT data, the model's performance will improve. Interestingly, when the amount of data is 30K, the model's performance has decreased significantly. One possible reason for this inconsistency is that the data is imbalanced. The model may tend to favor predicting the more frequent categories, leading to a decrease in prediction performance for the less frequent categories."}, {"title": "6. Conclusion", "content": "In this paper, we present Cultour, a high-quality Chinese tourism SFT dataset, which is specifically fine-tuned for LLM. It includes 12,823 data items such as eating, living, traveling, traveling, shopping, and entertaining. Based on this dataset, we fine-tuned an LLM, TourLLM, for the cultural and tourism domain to gain deeper insights into people's needs. To better evaluate the performance of TourLLM, we propose human evaluation CRA metrics tailored for LLMs, incorporating consistency, readability, and availability. We use both automated and manual evaluation methods to assess model performance. Experimental results demonstrate the effectiveness of TourLLM.\nIn future work, we will utilize TourLLM and external documents to enhance retrieval capabilities through a retrieval augmentation generation (RAG) approach to make responses more reliable."}]}