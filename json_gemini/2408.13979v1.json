{"title": "NEMESIS: NORMALIZING THE SOFT-PROMPT VECTORS OF VISION-LANGUAGE MODELS", "authors": ["Shuai Fu", "Xiequn Wang", "Qiushi Huang", "Yu Zhang"], "abstract": "With the prevalence of large-scale pretrained vision-language models (VLMs), such as CLIP, soft-prompt tuning has become a popular method for adapting these models to various downstream tasks. However, few works delve into the inherent properties of learnable soft-prompt vectors, specifically the impact of their norms to the performance of VLMs. This motivates us to pose an unexplored research question: \"Do we need to normalize the soft prompts in VLMs?\" To fill this research gap, we first uncover a phenomenon, called the Low-Norm Effect by performing extensive corruption experiments, suggesting that reducing the norms of certain learned prompts occasionally enhances the performance of VLMs, while increasing them often degrades it. To harness this effect, we propose a novel method named Normalizing the soft-prompt vectors of vision-language models (Nemesis) to normalize soft-prompt vectors in VLMs. To the best of our knowledge, our work is the first to systematically investigate the role of norms of soft-prompt vector in VLMs, offering valuable insights for future research in soft-prompt tuning. The code is available at https://github.com/ShyFoo/Nemesis.", "sections": [{"title": "INTRODUCTION", "content": "In the age of large-scale pretrained vision-language models (VLMs), such as CLIP (Radford et al., 2021), Flamingo (Alayrac et al., 2022), and BLIP (Li et al., 2022), soft-prompt-based methods, also known as prompt-tuning, have emerged as a dominant approach for adapting these models to a wide range of downstream tasks. For instance, Zhou et al. (2022b) propose a Context Optimization (CoOp) method to learn soft prompts in a continuous space of CLIP for image classification tasks. Additionally, Rao et al. (2022) and Du et al. (2022) also employ prompt-tuning to address dense prediction and open-vocabulary object detection tasks, respectively.\nRecent research in the field of VLMs has been primarily focused on enhancing model performance through the alignment of visual and textual features. For instance, in (Lu et al., 2022), the weight distribution of output embeddings is estimated, while Zang et al. (2022) propose a joint optimization approach for prompts across multiple modalities. Additionally, Chen et al. (2023) employs optimal transport techniques. To interpret learned soft-prompt vectors, Zhou et al. (2022b) and Chen et al. (2023) map them to the nearest words within the embedding space. More recently, Oymak et al. (2023) delves into the role of attention mechanisms in prompt-tuning, specifically within the context of a one-layer attention network.\nWhile considerable advancements have been made in soft-prompt-based techniques for VLMs, scant attention has been paid to their intrinsic properties, specifically the norms of learnable soft-prompt vectors. We argue that the norms of soft prompts are a crucial but overlooked attribute that significantly influences the performance of VLMs. This paper addresses an overlooked aspect and presents a research question \u201cDo we need to normalize the soft prompts in VLMs?\" To the best of our knowledge, there is no work to study this question."}, {"title": "2 Low-NORM EFFECT", "content": "In this section, we examine how the norms of learned prompt vectors influence the performance of VLMs and identify the Low-Norm Effect. To achieve that, we conduct extensive corruption"}, {"title": "3 METHODOLOGY", "content": "In this section, we introduce the proposed Nemesis method. We begin with a review of the CoOp method (Zhou et al., 2022b) and subsequently introduce two key corruption operations, REPLACE and RESCALE. Finally, we present the entire method."}, {"title": "3.1 A REVISIT OF PROMPT-TUNING VISION-LANGUAGE MODELS", "content": "Over the years, pretrained VLMs have demonstrated impressive generalization performance in zero-shot open-world visual recognition, wherein the model can perform a task without undergoing explicit training. One typical paradigm is CLIP (Radford et al., 2021), which consists of an image encoder and a text encoder. CLIP is trained on approximately 400 million image-text pairs, contributing to its remarkable performance. Nevertheless, effectively fine-tuning these VLMs for downstream tasks remains a challenge, particularly when dealing with few-shot data, due to their massive param-eters. The CoOp method addresses this issue by setting the templated context prompts (e.g. This\nis a photo of {class-name}.) as learnable vectors, which only requires fine-tuning these\nlearnable vectors while keeping the pretrained VLMs frozen. For a downstream visual recogni-tion task consisting of C categories, the classification weights of one image can be defined by the\nsimilarity between the visual feature and the text features of all categories.\nFormally, the image encoder and text encoder can be denoted by f and g, respectively. Given an image x along with its classification label y, the visual feature can be formulated as f = f(x), while the textual prompt of i-th class can be formulated as \\(t_i = \\{v_1, v_2, v_j, ..., v_L, c_i \\}\\), where \\(v_j\\) and \\(c_i\\) denote the j-th soft-prompt vector and the word embedding of the class name, respectively. Then the i-th class textual feature can be denoted as \\(g_i = g(t_i)\\). Given few-shot data, CoOp can learn the soft prompts \\(V^{L \\times D} = \\{v_1, v_2, ..., v_L \\}\\), where L and D denote the length of soft prompts and the dimension of prompt vectors, respectively, by minimizing the negative log-likelihood between the image feature f and its ground-truth textual feature \\(g_y\\) as\n\\[L_{CE} =  \\sum_{x \\in X} - \\log \\frac{\\exp(sim(f, g_y) / \\lambda)}{\\sum_{i=1}^{C} \\exp(sim(f, g_i) / \\lambda)},\\]\nwhere \\(\\lambda\\) is a temperature parameter and sim(,) denotes the cosine similarity function. After the training process, the text encoder g encodes both the learned prompts V and the class embeddings to produce textual features for all classes."}, {"title": "3.2 CORRUPTION OPERATIONS", "content": "In this section, we introduce two corruption operations: REPLACE and RESCALE, which can be employed to corrupt the learned soft-prompt vectors.\nFor the REPLACE operation, we replace learned prompt vectors at a single position with a zero-mean Gaussian-distributed vector with fixed variance. Then, we can obtain a set of corrupted soft"}, {"title": "3.3 THE NEMESIS METHOD", "content": "To handle the Low-Norm Effect during prompt-tuning VLMs, we propose two losses for normal-izing the norms of soft prompts: Position-Uniform Normalization (PUN) loss and Position-Aware Normalization (PAN) loss. In the experiments, they are separated as an individual regularization item, which is added to the standard soft-prompt tuning process.\nGenerally, given a set of soft prompts \\(V^{L \\times D} = \\{v_1, v_2, ..., v_L \\}\\), we can calculate their norms as\n\\[\\frac{1}{M} \\sum_{j=1}^{L} a_j ||v_j||_p,\\]\nwhere M denotes the number of non-zero zero values in the set \\(\\{a_1, a_2,..., a_L \\}\\) and \\(|| \\cdot ||_p\\) denotes the \\(l_p\\)-norm of a vector. Unless otherwise specified, we use the \\(l_2\\) norm by default.\nFor the PUN loss, all elements of the set \\(\\{a_1, a_2, . . ., a_L \\}\\) are set to the same value, imposing an equal weight on the norms of soft prompts at all positions. Hence, this loss can be formulated as\n\\[L_{PUN} = \\frac{w}{M} \\sum_{j=1}^{L} ||v_j||_2,\\]\nwhere \\(a_j = w\\) for \\(j = 1,..., L\\). Here w is a scaling coefficient that controls the normalization strength. However, normalizing prompt vectors at positions unaffected by the Low-Norm Effect may not yield performance improvement. This is because it could potentially restrict the weight updates of soft prompts at these positions. Hence, it is necessary to tackle the Low-Norm Effect at each prompting position and dynamically adjust \\(a_j\\) during training.\nOn the other hand, if the Low-Norm Effect can be explicitly recognized during the training process, we can effectively address this issue and enhance the efficacy of soft-prompt learning. To achieve this, we incorporate an additional inference process prior to each batch training iteration to identify the prompting positions that induce the Low-Norm Effect.\nSimilar to corruption experiments, we initially set a rescaling factor, denoted by \\(\\tau\\), to induce the Low-Norm Effect, where \\(\\tau\\) is a positive real number less than 1. Then we apply the RESCALE operation on a normal soft prompt V to generate N sets of corrupted prompts at distinct prompting posi-tions \\(\\{V^{l_1}, V^{l_2}, . . ., V^{l_N}, ..., V^{l_N} \\}\\), where \\(l_n\\) denote corrupted positions. Note that for each training batch, we randomly select N distinct positions from the set of L positions \\(L = \\{1, 2, . . ., L \\}\\). Formally, the conditions \\(1 < l_1 \\neq l_2 ... \\neq l_n ... \\neq l_N \\leq L\\) and \\(N < L\\) ensure that the positions of rescaled prompt vectors for each set of corrupted prompts are distinct from each other.\nBy having a set of images X with a batch size of B as well as their ground-truth labels \\(Y = \\{y_1, ..., y_B \\}\\), and a hybrid prompt set \\(V^{(N+1)\\times L \\times D} = \\{V, V^{l_1}, V^{l_2}, \u2026\u2026, V^{l_N} \\}\\), where V is the orig-inal prompt and others are corrupted prompts, we can obtain a set of label predictions \\(\\hat{Y}^{(N+1)\\times B}\\)"}, {"title": "4 EXPERIMENTS", "content": "In this section, extensive experiments are conducted to evaluate the proposed Nemesis method, including comparison with CoOp (Zhou et al., 2022b) on few-shot image classification tasks and domain generalization tasks, comparison with CoCoOp (Zhou et al., 2022a) in the base-to-new generalization setting. Additionally, we conduct an in-depth impact analysis on VLM performance due to the norms of soft prompts, explore the method's extensibility to other soft-prompt tuning approaches, and assess the computational efficiency."}, {"title": "4.1 DATASETS", "content": "For few-shot image classification experiments and base-to-new generalization tasks, we follow the experimental setting of CoOp and CoCoOp, respectively, and conduct experiments on 11 visual classification datasets, including Caltech101 (Fei-Fei et al., 2004) and ImageNet (Deng et al., 2009) for object recognition, EuroSAT (Helber et al., 2019) for satellite image recognition, DTD (Cimpoi et al., 2014) for texture recognition, UCF101 (Soomro et al., 2012) for action recognition, SUN397 (Xiao et al., 2010) for scene recognition, OxfordPets (Parkhi et al., 2012), FGVCAircraft (Maji et al., 2013), Food101 (Bossard et al., 2014), Flowers102 (Nilsback & Zisserman, 2008), and StanfordCars (Krause et al., 2013) for fine-grained recognition. Besides, ImageNet (Deng et al., 2009) and its variants, including ImageNet-A (Hendrycks et al., 2021b), ImageNet-R (Hendrycks et al., 2021a), ImageNetV2 (Recht et al., 2019), and ImageNet-Sketch (Wang et al., 2019), are used for the evaluation of domain generalization. Detailed descriptions of each dataset can be found in Appendix A.2.1."}, {"title": "4.2 IMPLEMENTATION DETAILS", "content": "For few-shot image classification experiments and domain generalization tasks, we compare our method with the baseline method CoOp, while CoCoOp is chosen as our baseline model in base-to-new generalization tasks. Following the few-shot evaluation protocol used in CoOp, we use a fixed number of training samples from each category (i.e. 1, 2, 4, 8, 16 shots per class). Besides, we follow the same training configurations as these baseline models, including training epochs, learning rate, and batch size, etc. All reported results are based on the average of five different seed runs. Bold denotes the best performance on each comparison setting. More implementation details and hyper-parameter settings can be found in Section A.2.2."}, {"title": "4.3 FEW-SHOT IMAGE RECOGNITION RESULTS", "content": "The experimental results of few-shot recognition are summarised in Figure 2. The blue, orange, and green lines represent CoOp, CoOp+Nemesis with the PUN loss, and CoOp+Nemesis with the PAN loss, respectively. In terms of average performance, both Nemesis methods outperform CoOp. Particularly, they achieved a large improvement over CoOp on the ImageNet, OxfordPets, Food101, and SUN397 datasets. This indicates that normalizing the soft prompts in VLMs can lead to bet-ter performance on these datasets that exhibit a more pronounced Low-Norm Effect. Taking the ImageNet dataset as an example, Nemesis with the PUN loss gains 2.06%, 3.84%, 2.6%, 1.16%, 0.38% performance boost over CoOp at 1, 2, 4, 8, 16 shots. Similarly, Nemesis with the PUN loss also shows performance improvements of 0.46%, 1.56%, 1.74%, 0.80%, and 0.44%. Moreover, it is evident that CoOp+Nemesis demonstrates enhanced robustness and superior performance on the Food101 and OxfordPets, compared with CoOp. Additionally, comparing Nemesis with the PUN loss, Nemesis with the PAN loss shows more robust performance at larger shot settings. All these performance comparisons demonstrate normalizing the soft prompts in VLMs can facilitate the ef-fective learning of soft prompts for few-shot recognition. More detailed data and analysis of training process can be found in Appendix A.2.6."}, {"title": "4.4 EVALUATION OF GENERALIZATION PERFORMANCE", "content": "In this subsection, we conduct experiments to assess the generalization performance of the proposed method. All methods are trained on the ImageNet dataset with 16 shots per class and tested on four different ImageNet-based datasets. Table 1 reports the results of CoOp, CoOp+Nemesis (PUN), and CoOp+Nemesis (PAN). It is clear that CoOp+Nemesis outperforms CoOp consistently on both source and target domains, whether adopting the PUN loss or PAN loss, which suggests that Nemesis can improve CoOp's domain generalization abilities by normalizing the soft prompts in VLMs. Furthermore, we can observe that Nemesis using larger w can achieve better transfer performance, implying that a stronger normalization of soft prompts could enhance the robustness of soft prompts to domain shifts. Comparing Nemesis using the PUN loss and Nemesis using the PAN loss, despite that the latter achieves better performance on the source domain, its performance on target domains is inferior to the former. We argue that this may arise due to the PAN loss excessively prioritizing to identify and address the Low-Norm Effect within intra-domain data, which could compromise its generalization capability. The results of base-to-new experiments can be found in Appendix A.2.4."}, {"title": "4.5 IN-DEPTH STUDIES ON THE LOW-NORM EFFECT IN VLMS", "content": "In this section, we aim to provide plausible explanations for the occurrence of the Low-Norm Effect and the effectiveness of the proposed method Nemesis.\nFrom Figure 3(a), it is apparent that the norms of soft prompts in CoOp first increase and then level off, while test accuracy falls into degradation as norms slowly flatten out. By performing corruption operations that decrease the norms of prompt vectors, the last green circle may be pushed away from the degradation area and get closer to those small green circles that demonstrate superior performance. This could be regarded as a plausible explanation for the occurrence of the Low-Norm Effect: those corrupted soft prompts that demonstrate superior performance than their original counterparts may be precisely one of those small circles. Moreover, this figure may unveil a potential correlation between the time when prompt learning starts to degrade and the time when the norm of soft prompts begins to stabilize. We leave this to future research.\nFrom Figure 3(b), different from the observed norm variation pattern in CoOp, CoOp+Nemesis (ours) exhibits a distinct trend where norms initially increase, followed by a subsequent decrease, and eventually stabilize. Furthermore, the test accuracy exhibits a consistent upward trend before reaching a plateau, whereas a declining trend is observed in CoOp. This implies that our method can delay the time point where soft prompts tend to plateau during the learning process, thereby reducing the probability of learning degradation."}, {"title": "4.6 EXTENDIBILITY ANALYSIS", "content": "To analyze the extensibility of the proposed approach Nemesis, we apply the proposed method Nemesis to other soft prompt-tuning methods on few-shot recognition experiments. PLOT (Chen"}, {"title": "6 CONCLUSION", "content": "In this paper, we are the first to examine the impact of soft prompts' norms on the performance of VLMs. We conduct extensive corruption experiments using two specially designed operations and discover the Low-Norm Effect. To harness this phenomenon, we introduce Nemesis, a method for normalizing soft prompts during soft-prompt tuning. In general, Nemesis can be incorporated into any soft-prompt-based methods, even other PEFT methods, such as prefix-tuning, and P-tuning. We hope our findings and proposed method can provide new insights and facilitate future research on these fields."}]}