{"title": "Problem Solving Through Human-Al Preference-Based Co-operation", "authors": ["Subhabrata Dutta", "Timo Kaufman", "Goran Glava\u0161", "Ivan Habernal", "Kristian Kersting", "Frauke Kreuter", "Mira Mezini", "Iryna Gurevych", "Eyke H\u00fcllermeier", "Hinrich Schuetze"], "abstract": "While there is a widespread belief that artificial general intelligence (AGI) \u2013 or even super- human AI is imminent, complex problems in expert domains are far from being solved. We argue that such problems require human-AI cooperation and that the current state of the art in generative AI is unable to play the role of a reliable partner due to a multitude of shortcomings, including inability to keep track of a complex solution artifact (e.g., a software program), limited support for versatile human preference expression and lack of adapting to human preference in an interactive setting. To address these challenges, we propose HAI-Co\u00b2, a novel human-AI co-construction framework. We formalize HAI-Co2 and discuss the difficult open research problems that it faces. Finally, we present a case study of HAI-Co2 and demonstrate its efficacy compared to monolithic generative AI models.", "sections": [{"title": "1 Introduction", "content": "Despite the impressive achievements of generative AI spearheaded by Large Language Models (LLMs), Vision Language Models and code models (Lozhkov et al., 2024; Wang et al., 2021), multiple recent investigations have pointed out their lack of competence in dealing with complex generation problems that require intricate planning (Kambhampati et al., 2024) or task adherence while keeping track of multiple constraints (Xie et al., 2024). A broad class of such complex problems requires active human participation. Therefore, although the recent focus in generative AI has mostly been on complete automation, we believe that human-AI cooperation is a more promising approach for complex problems of this kind.\nTo effectively support human-AI cooperation, we draw inspiration from how humans collectively address complex problems to devise solutions: Humans often solve complex problems by iteratively co-constructing a solution step by step, revising and refining draft solutions while transitioning between different levels of abstraction, and exchanging information about preferences and potential improvements in natural lan- guage (Dam\u015fa, 2013). Our position is that this type of human-human cooperation is a promising template for the cooperation of humans and AI agents. On this basis, we propose Human-AI Co-Construction (HAI-Co2), a novel framework for human-AI cooperative problem-solving that builds on preference-based learning and search methodology and relies on natural language to facilitate interaction. The problem-solving process is conceived as a process of systematic search in a construction space X of candidate solutions, i.e., as a co- constructive process, in which candidate solutions are modified step by step until a sufficiently good solution has been found.\nWhat are co-construction problems? The broad class of problems that we seek to address in this paper is primarily centered around domain-specific expert applications where the task is to construct a solution that meets specific requirements, e.g., a computer program in software engineering or a machine learning pipeline in automated machine learning (AutoML). We choose the term co-construction because of the necessity for the AI agent to work closely with human experts. First, current AI systems' capabilities are limited and cannot fully replace human expertise in these tasks, e.g., due to insufficient knowledge and"}, {"title": "2 Related work", "content": "We group relevant prior work into five major strands: reinforcement learning from human feedback, RLHF search- and evolution-driven construction, assistance games, LLM agents for complex problem solving and persistent solution spaces for iterative construction. We now discuss how they attempt to address expert-AI co-construction. However, as we will see in Section 4, they fail to comprehensively tackle its challenges.\nReinforcement Learning from Human Feedback. RLHF focuses on learning a policy preferred by humans, most commonly relying on comparisons between candidate solutions (Kaufmann et al., 2024). The goal is to learn a policy that maximizes a reward or utility function that is consistent with the human feedback. Originating in classical reinforcement learning domains such as games and continuous control (Christiano et al., 2017), RLHF has been extended to a variety of domains, most notably fine-tuning genera- tive models such as LLMs (Stiennon et al., 2020; Ouyang et al., 2022), eventually leading to the development of AI models that can generate human-preferred responses in natural language such as ChatGPT.\nRLHF for generative AI is typically employed in a single-turn setting, where the agent generates an immediate response to a query, evaluated by a human expert. This contrasts with expert-AI co-construction, which involves multi-turn interactions where agent and expert collaboratively construct a solution. Multi-turn interactions introduce challenges such as extended time horizons and large action spaces. Extensions to RLHF have been proposed that address these issues (Zhou et al., 2024).\nEven multi-turn RLHF, however, is not well suited to expert-AI co-construction without further extension: It does not maintain an explicit representation of the solution space, which is crucial for systematic solution construction. In principle, RLHF could be used to learn the AI agent's policy in HAI-Co2, but it is challenging to do so interactively as required in HAI-Co2.\nSearch- and Evolution-Driven Construction. Our framework emphasizes iterative search within the construction space, a process akin to evolutionary optimization, which iteratively generates and evaluates candidate solutions (B\u00e4ck, 1996). This evolution can be viewed as a form of search-based construction. Interactive evolutionary computation, a preference-based extension, is particularly relevant to our work as it involves human evaluation of candidate solutions (Takagi, 2001; Wang & Pei, 2024). For example, these methods have been applied to search-based procedural content generation in video games (Togelius et al., 2011). Our approach differs in the core approach to the search process: Traditional evolutionary methods maintain a population of candidate solutions and generate new ones through mutation and recombination. In contrast, in our framework, each iteration ends with a single candidate solution that is then the basis for the next iteration. In addition, we leverage the extensive prior knowledge of pretrained language models to guide the search and use natural language communication to facilitate cooperation between the AI agent and the human expert.\nAssistance Games. Hadfield-Menell et al. (2016) introduce the framework of cooperative inverse rein- forcement learning, later called assistance games (Shah et al., 2021; Laidlaw et al., 2024), for cooperative decision-making between an AI agent and a human expert. They model human-AI interaction as a two player game betwen human expert and AI agent. The AI agent aims to maximize the expert's utility func- tion without explicit knowledge of it. The AI agent learns this function by observing the expert's actions and receiving feedback on its own actions. Our setting is similar in that AI and human collaborate to construct a solution that only the human expert can evaluate. It differs in that we focus on search-based co-construction of solutions rather than decision-making in a cooperative setting. When viewing solution construction as a sequential decision-making problem, our framework can be seen as a search-based approach to assistance games where the AI agent's actions are the steps taken to construct the solution. Despite the nice theoretical properties of the assistance games framework (Shah et al., 2021), it has not yet been widely applied to real- world problems, likely due to the complexity of the human-AI interaction and the difficulty of interactively"}, {"title": "3 HAI-Co\u00b2: Human-Al co-construction through preference-based search", "content": "In this section, we propose HAI-Co2, a framework for cooperative problem solving. Broadly speaking, HAI-Co2 is meant to formalize an interactive problem-solving scenario, in which a human expert seeks to (co-)construct a candidate solution \u2013 such as a computer program with the help of an AI agent. The problem-solving process is conceived as a process of systematic search in a space X of candidate solutions, i.e., as a (co- )constructive process, in which candidate solutions are modified or extended step by step until a (sufficiently) good solution has been found. Therefore, we also refer to the search space X as the construction space. The construction space, its hierarchical organization and its topology (or neighborhood structure) are depicted in Figure 2.\nActions taken by the AI agent during the search (e.g., adapting a candidate solution or asking the expert a question regarding where to move next) depend on its informational state I, which comprises its experience so far, e.g., about the expert's preferences, any relevant information about the current context, the solutions considered so far and the best solution constructed so far. Formally, the behavior of the AI agent can be determined by a policy \\( \\pi \\) that maps informational states to actions.\n3.1 Construction space and abstraction hierarchy\nThe construction space will typically be large, most often even (countably) infinite. For example, the construction space may consist of all computer programs in a specific programming language. Spaces of this kind cannot be specified in an explicit way. Instead, they will be defined implicitly and may even be adapted or designed on-the-fly in the course of the problem-solving process. In this regard, the formal representation of candidate solutions is of major importance and will strongly influence the efficacy and efficiency of the problem-solving process. Moreover, it is also clear that the representation of solutions will not be universal but rather specific to the expert domain. For example, a computer program will not be represented in the same way as a machine learning pipeline or data science workflow. It should be noted that we do not make any assumption of completeness for candidate solutions: at any stage of the search, a candidate solution \\( x \\in X \\) can be partial or incomplete (i.e., an incomplete codebase, an incomplete ML pipeline, etc.).\nDuring problem solving, it is often useful to look at (candidate) solutions on multiple levels of abstraction. In many cases, for example, a rough draft of the solution is found in a first phase of the process, and this draft is then worked out in more detail in a second phase. More generally, one can imagine a search process that switches back and forth between different levels of abstraction whenever appropriate. Therefore, we assume the construction space X is equipped with a hierarchy of abstraction levels. Formally, this can be modeled by a sequence \\( X_0, X_1, ..., X_j \\) of spaces, where \\( X_j \\) is a refinement of \\( X_{j-1} \\) - or, vice versa, \\( X_{j-1} \\) an abstraction of \\( X_j \\).\nWe describe the abstraction process from \\( X_j \\) to \\( X_{j-1} \\) as a surjection \\( f_j : X_j \\rightarrow X_{j-1} \\) such that \\( x' = f_j(x) \\in X_{j-1} \\); that is, \\( x' \\) is the abstraction of \\( x \\) on the abstraction level modeled by \\( X_{j-1} \\). We denote by \\( f_j^{(-1)}(x') = \\{x \\in X_j | f_j(x) = x'\\} \\) the set of all refinements of \\( x' \\in X_{j-1} \\) on abstraction level \\( X_j \\). Note that refinements are not unique, which is why a transition from \\( X_{j-1} \\) to \\( X_j \\) may come with a certain arbitrariness. In our case study, we work with three levels of abstraction, considering a Python program as a refinement of a UML diagram, which in turn is a refinement of a natural language description.\n3.2 Latent utility\nWe assume that the construction space is equipped with a latent utility function reflecting the preferences of the expert, i.e., the quality of solutions as perceived by the expert. In general, \"quality\" may refer to various dimensions or criteria, and different objectives might be pursued at the same time; we formalize this with a multi-dimensional utility function \\( u(x) = (u_1(x), ..., u_k(x))^\\top \\) comprised of local utility functions \\( u_i \\). For example, a computer program could be rated by average runtime or memory consumption. The local utility functions can be combined into a scalar utility function \\( U : X \\rightarrow \\mathbb{R} \\) via a suitable aggregation operator.\nVarious factors influencing the quality of candidate solutions can be distinguished, notably hard and soft constraints. Hard constraints refer to (functional) properties that qualify a candidate as a valid solution."}, {"title": "4 Challenges and practical issues", "content": "Our characterization of HAI-Co\u00b2 implies multiple challenges that need to be addressed to realize co- construction effectively. In the following, we briefly describe these challenges with reference to the current state of research.\nSpecification of abstraction hierarchy. Wwo core components of HAI-Co2 are (i) the abstraction hier- archy of the construction space and (ii) the neighborhood structure that facilitates preference-based search. A synergistic implementation of (i) and (ii) poses a non-trivial research challenge. In the domain of code generation, Le et al. (2024) propose a modular code generation approach to circumvent this challenge: they generate a chain-of-thought style intermediate description of the subtasks followed by modular codes im- plementing each of them. Such a hierarchical generation approach can be extended to generalized solution co-construction. However, relying on purely natural language-based intermediate representations limits the utility of the hierarchy. The choice of abstraction representation is domain-specific: UML descriptions are a suitable abstraction for code generation, but not for an AI scientific assistant. The abstraction specification must adhere to the neighborhood structure on all levels of abstraction; e.g., if two points are neighbors, their abstractions must also be neighbors. This poses additional constraints on the choice of abstraction, the choice of neighborhood structure, and the choice of refinements between two given levels of abstraction. Ideally, all levels of abstraction must be suitable for human preference expression: an \"unnatural\" choice of abstraction can render the co-construction tiresome for the human expert, negatively affecting productivity.\nSpecification of informational state. HAI-Co2 utilizes an informational state to keep track of relevant information in the interaction history. Given that the search policy is conditioned on it, an efficient represen- tation of the informational state is a core challenge of HAI-Co2. Typically such interactive co-constructions are expected to span a long sequence context. While we have observed a significant surge in the context-size of present-day generative AI (e.g., GPT-4 Turbo can handle up to 128K tokens in the input prompt), recent research has questioned the effective usability of such very long context information (Liu et al., 2024). The representation of the informational state needs to be compatible with the abstraction specification of the construction space as well as well as the choice of how preference signals from the human expert are encoded. This is particularly important as the reflection of any preference signal upon the candidate solution is man- ifested via the informational state an unreliable update of the informational state subsequently worsens the solution quality and may result in a divergent search.\nCommunication in natural language. When humans co-construct a solution, communication in natural language plays an important role. Natural language is a powerful and at the same time succinct medium for conveying information. Given the expressivity of natural language, human and AI agent can easily communicate different options of how to improve the current solution, both at a detailed level and in more abstract terms. Similarly, preference learning is facilitated by natural language since many preferences are easily specified in natural language. The challenge here is that the language capabilities of LLMs have advanced to an impressive level for the general domain, but this does not apply to complex expert domains (Magesh et al., 2024; Hager et al., 2024; Anand et al., 2024).\nMultimodal human-AI interaction. Natural language-based interaction is not the ideal channel for all types of preference. Categorical preference can be communicated more simply by pointing towards the better solution. Thus, we would like to incorporate multiple types of preference into HAI-Co\u00b2. This poses the challenge of aligning these multiple modes of feedback with each other. For example, the human expert may express the need for a security feature in a software engineering problem explicitly, or they can express"}, {"title": "5 An exemplary implementation of HAI-Co2", "content": "In this section, we provide a case study of HAI-Co2, tailored to code generation as a co-construction problem. This case study does not claim scientific rigor on its own; instead, we use it to demonstrate what prior findings (see Section 1 and Section 2) already establish.\nThe initial problem description is underspecified. During the cooperation, the user can introduce new re- quirements, ask for modifications to the already generated code, and so on. We approximate different aspects of HAI-Co2 (the surjective mappings between different abstraction hierarchies of the construction space, policy and heuristic search strategy and the multi-dimensional utility function) using baseline im- plementation strategies for ease of demonstration. Future research endeavors should be directed to more in-depth implementation of these features.\nProblem. The user wants to develop a modular Python codebase for simulating a double pendulum. Modules should include components such as I/O interface, visualization and physics engine.\nIn this example, the construction space X consists of the set of all Python programs. Three distinct levels of abstraction are implemented: a specification of the simulation software in natural language (Xo), a UML description of the software (X1), and finally, the Python program (X2) itself. The abstraction refinements f(\u22121) 1 and f(\u22121) 2 (as introduced in Section 3) are implemented using suitably prompted instances of GPT- 4 Turbo that we denote as UML generation module and Code generation module, respectively; while the former produces a (stochastic) set of refinements in UML given a natural language specification, the latter generates Python implementations of a given UML description. The informational state I is realized at different levels of abstraction within the contexts of these LLMs. We do not implement a concrete realization of the policy \\( \\pi \\); instead, we rely on the limited abilities of LLM instances to explore and implement policy iterations (Krishnamurthy et al., 2024; Brooks et al., 2023).\nThe implementation, as depicted in Figure 3, instantiates HAI-Co2 as follows. The co-construction starts with the user providing an underspecified description of the task (in this example, building a simulation software in Python). The specification module (\u2460 in Figure 3) generates the natural language abstraction of the candidate solution as a list of possible components of the software along with their functionalities 2. This serves as a transparent interface in natural language that provides a layout of the construction. The user can directly edit the specification if they have specific requirements in mind (preemptive reviewer), or choose to continue with the workflow and decide on the specifics upon observing the final program (lazy reviewer).\nNext, the UML generation module generates a set of stochastic refinements of the natural language specifi- cation into UML descriptions (\u2461 in Figure 3). The UML description of the software forces the subsequent code generation module to generate a final program that consists of multiple, independent components (in this case, Python classes) and well-defined dependencies among such components. Micro-level changes to the code (e.g., changing the design of the GUI, choice of numerical algorithms in the simulator, etc.) can be facilitated now without changing the complete codebase a desirable property of our implementation that is closer to real-life software engineering. This addresses the challenge monolithic code LLMs face in scenarios in which persistent editing is required.\nTo facilitate exploration of the candidate solution space, we generate multiple UML descriptions from a given specification by setting a high decoding temperature in the UML generation module and sampling multiple responses 3. Intuitively, we seek to exploit earlier findings that a highly stochastic generation regime facilitates better novelty (Wang et al., 2023a). However, generating the Python programs from all such candidate UMLs and verifying them one by one is both computationally expensive and infeasible for the human user.\nTo facilitate partial automation of searching through the candidate UMLs, we simulate human preference using GPT-4 Turbo in the preference learning module (\u2462 in Figure 3). Specifically, the task of the preference learning module is to provide judgment on the relative quality of a given pair of UML candidates along with"}, {"title": "6 Conclusion", "content": "This paper presents a novel research perspective towards complex problem solving via human-AI co- construction. Our position is that existing generative AI agents require active human participation to successfully construct solutions to complex problems, but cannot effectively serve as reliable partners in human-AI cooperation due to their current limitations. We find evidence for this position in multiple prior research areas across a broad set of domains. Our case study focuses on software generation using GPT-4 Turbo, a strong proprietary LLM, and exemplifies the major drawbacks of current LLMs such as inability to follow human preference, unreliable refinement of complex solution artifacts and limitations to facilitate active human participation. We observed that although day-to-day usage of generative AI tends to adopt a type of human-AI co-construction paradigm in an uninformed manner, the challenges that LLMs face confine such interactions to a much weaker form. As a remedy, we introduce HAI-Co2, a framework that is motivated by the effectiveness of collective human problem solving. HAI-Co2 facilitates a solution construction space with multiple levels of abstractions in which human and AI iteratively refine the candidate solution through search guided by human preference. HAI-Co2 allows active human participation along with versatility in preference expression. After presenting a formalization of HAI-Co2, we discussed the research challenges for this new approach as well as possible future directions for addressing them. Finally, we presented a case study for the application of code generation and noted clear improvements compared to monolithic LLMs."}]}