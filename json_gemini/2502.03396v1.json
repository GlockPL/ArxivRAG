{"title": "Accurate AI-Driven Emergency Vehicle Location Tracking in Healthcare ITS Digital Twin", "authors": ["Sarah Al-Shareeda", "Yasar Celik", "Bilge Bilgili", "Ahmed Al-Dubai", "Berk Canberk"], "abstract": "Creating a Digital Twin (DT) for Healthcare Intelligent Transportation Systems (HITS) is a hot research trend focusing on enhancing HITS management, particularly in emergencies where ambulance vehicles must arrive at the crash scene on time and track their real-time location is crucial to the medical authorities. Despite the claim of real-time representation, a temporal misalignment persists between the physical and virtual domains, leading to discrepancies in the ambulance's location representation. This study proposes integrating AI predictive models, specifically Support Vector Regression (SVR) and Deep Neural Networks (DNN), within a constructed mock DT data pipeline framework to anticipate the medical vehicle's next location in the virtual world. These models align virtual representations with their physical counterparts, i.e., metaphorically offsetting the synchronization delay between the two worlds. Trained meticulously on a historical geospatial dataset, SVR and DNN exhibit exceptional prediction accuracy in MATLAB and Python environments. Through various testing scenarios, we visually demonstrate the efficacy of our methodology, showcasing SVR and DNN's key role in significantly reducing the witnessed gap within the HITS's DT. This transformative approach enhances real-time synchronization in emergency HITS by approximately 88% to 93%.", "sections": [{"title": "I. PROBLEM IN FOCUS", "content": "In contemporary transportation management, Intelligent Healthcare Transportation Systems (HITS) are fundamental to facilitating collaborative information exchange among medical vehicles and infrastructure, especially in the case of emergencies and accidents, and incorporating Digital Twins (DTs) into HITS promises significant advantages, including real-time data integration, improved traffic management, and democratizing data-driven decision making. DT deployment within HITS can take various forms, including cloud-based, edge-based, or hybrid-based approaches [1]\u2013[5]. However, achieving real-time synchronization between the physical and virtual facets of HITS remains elusive, resulting in an enduring temporal gap that hinders the attainment of a real-time representation of the physical system. For example, in edge-based deployment, this delay originates from the process by which the physical HITS transmits information to the edge server that hosts the constructed DT. Moreover, this temporal discrepancy is observed across the DT's data, virtual, and service layers. Ultimately, when final decisions and responses are transmitted to the physical system, the system's state may have changed before receiving these responses, underscoring the challenge of achieving true real-time synchronization. This temporal misalignment is exemplified in Fig. 1, where the physical HITS records data at time (say To\u00b9), while the DT lags significantly at delayed timestamp To+++. Consequently, the response is returned at a very late timestamp T+++++. This discrepancy between real-time data acquisition and DT response generation requires a dire solution. This research problem underscores the critical need to bridge the synchronization gap between physical HITS and their DTs, thus advancing the quest for real-time representation of healthcare transportation systems. Numerous studies have addressed the issue of synchronization from various angles [6], [7]. An emerging notable approach involves using AI-based predictive models within the DT plane, allowing predicting medical vehicle locations and behaviors ahead of time, effectively mitigating synchronization delays. A detailed literature review reveals a multitude of endeavors addressing the general challenge of location prediction [8]\u2013[11]. These works collectively showcase the use of AI for vehicle location prediction, each contributing innovative techniques and models to improve prediction accuracy, efficiency, and adaptability. However, few of these works utilize the concept of DT, that is, making location prediction in the DT domain; Maheswaran et al. [12] improve autonomous driving systems by continuously updating the locations of autonomous and human-piloted vehicles on road segments. To mitigate communication delays, they incorporate a forecaster algorithm in the twin capable of predicting future vehicle locations. Along the same lines, our present study aims to bridge the gap by contributing to the field of HITS in the following key ways:\nA. Main Contributions\n1) We address the challenge of the temporal gap in HITS DT using AI prediction techniques, ensuring a seamless alignment between virtual and actual medical vehicle locations.\n2) We introduce Support Vector Regression (SVR) as our Machine Learning (ML) model and Deep Neural Networks (DNN) as the Deep Learning (DL) model. This approach"}, {"title": "II. PROPOSED SOLUTION: PREDICTING THE NEXT LOCATION OF THE AMBULANCE IN HITS DT TO OFFSET THE OBSERVED DELAY", "content": "Our HITS comprises a fleet of n emergency service vehicles, as depicted in Fig. 1, each identified by the index Vi, i = {1, ...n}. These vehicles are equipped with real-time location tracking systems that provide coordinates $(x_i^v,y_i^v)$ at time T. Communication of status occurs through vehicle-to-vehicle (V2V) and vehicle-to-structure (V2I) channels, with real-time situational information transmitted to the Road Side Unit (RSU). Despite adjusting for factors such as congestion and contention in the physical network, an unavoidable communication delay \u2206T is observed from the perspective of the RSU. Deploying a virtual twin of the HITS at the RSU's edge server exacerbates the temporal gap and asynchronization with the physical system. The DT of each vehicle consistently lags by \u2206\u03c4 seconds behind its real-world counterpart. Our primary goal is to mitigate this observed \u0394\u03c4. \u03a4\u03bf address this, we integrate AI models to predict future vehicle locations within the DT framework, aligning the virtual representation with physical reality. Two AI models, SVR as an ML model and DNN as a DL model, operate within the DT layers. The schematic representation of the prediction model is displayed in Fig. 2 with its three involved steps detailed below.\nA. Input Dataset and Preprocessing\nOur dataset comprises a historical geospatial GPS trajectory dataset sourced from a fleet of n = 221 regular vehicles, which operated during the first two days of each month throughout 2019. This GPS dataset includes the following feature set: unique vehicle identifiers Vi, i = {1, ..., n}, timestamp, speed (km / h), distance traveled (m), duration of stay at a specific location (second), latitude and longitude coordinates of the current location, that is, $(x_i^v,y_i^v)$ and the corresponding next location coordinates $(x_i^{v_T+}, y_i^{v_T+})$. In particular, this data set comprises 1,048,576 timestamps per month; however, to ensure data quality and minimize computational resource utilization, we apply rigorous data filtering and restrict our study to a subset of N = 43, 856 time instances. Subsequently, this filtered data set is divided into a training subset, which constitutes 80% of the data, and a validation subset, reserving the remaining 20%. Data preprocessing forms a foundational corner of our model development, adhering to rigorous technical standards. In this critical process, a meticulous transformation of our features set centers the data around a mean of 0 and scales it to show a standard deviation of 1. This standardization significantly improves the convergence rate during model training, providing Al models with a notable understanding of the intricate spatio-temporal dynamics of our dataset. This centering will also affect the bias of the SVR model b, as explained in a later note. The next stage involves feeding the data into our selected prediction models, enabling us to anticipate vehicle movements accurately. In this context, we choose the SVR and DNN models, as SVR makes precise predictions. At the same time, DNNs can discern intricate spatio-temporal patterns, resulting in highly accurate and dependable forecasts of future vehicle locations. We dive into a detailed exploration of these two models in the following.\nB. Utilized AI Prediction Models Description\n1) SVR ML Predictive Model: In the context of our dataset, the main objective of regression is to uncover how the changes in the six input features relate to the changes in the next location coordinates $(x_i^{v_T+}, y_i^{v_T+})$ of the vehicle. SVR is our dataset's regression method of choice as it can effectively model the sought nonlinear relationship. SVR is an extension of the Support Vector Machine (SVM) algorithm that can capture complex relationships and patterns within the data by finding the \"hyperplane\" that best fits the data points within error \u03b5-tube region. In our case, this hyperplane is a mathematical representation of the relationships between the input features and the target x-coordinate $x_i^{v_T+}$ and y-coordinate $y_i^{v_T+}$. We employ dual SVR models: one dedicated to predicting the x-coordinate and the other to predict the y-coordinate. For simplicity, our description refers to either coordinates as \u0177 or f(x) where \u00ee = [x1, x2, ..., X, ..., \u00ceN] represents the input dataset that has N = 43,856 instances of 6-dimension values. The main steps of formulating our SVR, exhibited in Fig. 3, involve:\ni. In the input space, we identify the support vectors and the data points closest to the hyperplane to focus on the most critical data points when creating the prediction model:\n$f(x) = \\sum_{i=1}^N (w_i \\cdot x_i) + b \\pm \\varepsilon$,\nii. To make the features of the input linearly separable, a mapping function (\u03c8(x)) is used instead of each 2.\niii. In such transformed feature space of \u03c8(x), the optimal hyperplane f(x) can be found by minimizing the following Lagrange Loss primal problem:\n$L(\\hat{y}, f(x)) = \\frac{||w||^2}{2} + C \\sum_{i=1}^N (\\xi_i + \\xi_i^*)$,\nsuch that C controls the generalization capabilities of the predictor, $y - f(x) \\le \\varepsilon + \\xi_i$, $f(x) - y \\le \\varepsilon + \\xi_i^*$, and $\\xi_i, \\xi_i^* \\ge 0$ for i = {1, ..., N}. As this problem (2) is hard to solve in this primal space of w, the solution is to transform the problem to a dual space of \u03b1, \u03b1\u2217, Lagrange multipliers by letting:\nw = (\u03b1i \u2212 \u03b1i\u2217)\u03c8(xi), i = {1, ..., N}.\niv. In the dual feature space, the hyperplane is exhibited as:\n$f(x) = \\sum_{i=1}^N (\\alpha_i - \\alpha_i^*) \\cdot (\\psi(x_i) \\cdot \\psi(x_i))$,\nwhere (\u03c8(xi)\u00b7\u03c8(xi)) is the dot product between the two mapping functions. It turns out that the calculation of such a dot product can be avoided by using the kernel trick concept such that:\n$(\\psi(x) \\cdot \\psi(x)) = K(x_i, x_j), \u00ce = {1, ..., N}$.\nv. In the kernel space, from (5), the kernel trick can di- rectly calculate the similarity between input features by transforming them into a higher-dimensional space. As the choice of the kernel function influences the flexibility and performance of the SVR model and as our dataset is a mix of linear and nonlinear features, we leverage the Gaussian Radial Basis Function (RBF) kernel to simplify capturing the nonlinear relationships for prediction. The formula for the RBF kernel in our SVR is $K(x, x_j) = exp(-\\frac{||x-x_j||^2}{2 \\sigma^2})$, where || ||2 is the squared Eu- clidean distance and \u03c3 is the width of the kernel's bell- shaped curve. A smaller \u03c3 makes the kernel more lo- calized, while a larger \u03c3 makes it more spread out with potentially fewer support vectors; selecting an appropriate \u03c3 requires cross-validation to find the optimal value for our specific dataset. As \u00ee has N samples, we would calculate the kernel value for every x_i. This results in a N \u00d7 N dimension kernel Gram matrix. From such a kernel matrix, we create a correlation matrix by subtracting the mean of each row and column from the matrix, ensuring that the kernel matrix has a zero mean. Next, we divide each element of the centered kernel matrix by the product of the square root of the corresponding diagonal elements. The correlation matrix provides insights into the relationships between data points in the higher-dimensional space as captured by the kernel function. Elements close to 1 indicate high similarity, values close to -1 indicate anti-correlation, and values close to 0 indicate low or no correlation.\nvi. Finally, in the dual space using the kernel trick, the La- grange Loss function can be easily solved with Quadratic Programming to maximize:\n$L(y, f(x)) = \\sum_{i,j}^{N,N} ((\\alpha_i - \\alpha_i^*)(\\alpha_j - \\alpha_j^*))K(x_i, x_j) - \\varepsilon \\sum_{i=1}^N (\\alpha_i + \\alpha_i^*) + \\sum_{i=1}^N y_i(\\alpha_i - \\alpha_i^*)$,\nsuch that $\\sum_{i=1}^N (\\alpha_i - \\alpha_i^*) = 0$.\n2) DNN DL Predictive Model: The adopted DNN model is carefully designed to apprehend intricate spatiotemporal patterns inherent in our \u00ee dataset. The input layer of our model consists of six neurons to receive each N 6-dimensional training and validation sample. We opt for a model of two hidden layers with 64 neurons and a Rectified Linear Unit (ReLU) activation function. The final layer has two neurons, each assigned to forecasting the x-coordinate and y-coordinate of an ambulance's next location. This architectural arrangement equips the DNN to learn and generalize the training data effectively. The model undergoes 1000 training iterations with a batch size of 32 out of the N sample; 20% of the training data serves as a validation subset. These settings balance model complexity and generalization, determined by empirical exploration. Once the model is finely tuned and trained, real-time data, including current vehicle location, is fed into the input layer. The model aims to precisely predict the future coordinates of the vehicle $(x_i^{v_T+}, y_i^{v_T+})$. This prediction is an invaluable tool for alleviating the observed delay \u2206\u0442 and improving the overall efficiency of DT-HITS, as discussed in Section III."}, {"title": "III. PREDICTION EFFECT AND DT EXHIBITION: ANALYSIS AND DISCUSSION", "content": "In this section, our objective is to evaluate the performance of our SVR and DNN prediction models, providing a detailed account of their accuracy. We begin with an analysis of model evaluation metrics, shedding light on the precision and reliabil- ity of our models. Next, we showcase the models' proficiency in capturing underlying patterns in the testing geospatial data through accurately predicted values aligning with actual testing data. We then exhibit the mock DT implementation, showing the original and predicted locations in real time. Furthermore, we explore how our predictions offset the observed delay \u0394\u03c4, drawing comparisons between the observed improvement. We implemented our models and conducted our analysis and simulations in Python and MATLAB R2022b environments on a computer with a 2.8GHz Core i7 processor and 16GB memory.\nA. Predictive Models Validation Accuracy\nMeasuring the accuracy and error of our two prediction mod- els is crucial to assessing their effectiveness. In our analysis, we use the following three metrics for the assessment.\n\u2022\nMean Absolute Error (MAE) calculates the average abso- lute differences between actual and predicted next location coordinates as:\n$MAE = \\frac{1}{N} \\sum_{i=1}^N [|(x_i^{v_T+}) - (\\hat{x_i^{v_T+}})| + |(y_i^{v_T+}) - (\\hat{y_i^{v_T+}})|]$\n\u2022\nMean Squared Error (MSE) squares the differences, plac- ing more weight on larger errors.\n$MSE = \\frac{1}{N} \\sum_{i=1}^N [((x_i^{v_T+}) - (\\hat{x_i^{v_T+}}))^2 + ((y_i^{v_T+}) - (\\hat{y_i^{v_T+}}))^2]$\n\u2022\nR-squared (R2) measures how well our model's predic- tions explain the variability in the actual data. A value of 1 indicates a perfect fit, while a value of 0 indicates that the model does not explain any variability:\n$R^2 = 1- \\frac{\\sum_{i=1}^N((x_i^{v_T+}) - (\\hat{x_i^{v_T+}}))^2 + ((y_i^{v_T+}) - (\\hat{y_i^{v_T+}}}))^2}{\\sum_{i=1}^N((x_i^v) - \\bar{x})^2 + ((y_i^v) - \\bar{y})^2}$\nIn the context of the evaluation metrics described, Table I offers a comprehensive analysis of the accuracy performance for our SVR and DNN models in two distinct computational environments. MATLAB and Python. Within the MATLAB environment, the SVR RBF model exhibits a moderately high MAE of 83.424 and MSE of 15527.804, suggesting a moderate level of predictive accuracy. However, R\u00b2 stands impressively high at 0.99911, indicating a robust correlation between predicted and actual values. In contrast, the DNN model in MATLAB outperforms the SVR RBF, achieving a significantly lower MAE of 9.179 but with a higher MSE of 17261.584. Despite a slightly less perfect R2 value of 0.99901, this underscores the superior predictive accuracy of the SVR RBF model and its ability to capture intricate patterns within the validation dataset. SVR RBF and DNN models demonstrate remarkable accuracy when transitioning to the Python environment. The SVR RBF achieves an MAE of 0.0712 and an MSE of 0.0265, with a highly recommended value of R\u00b2 of 0.97345, indicating a precise alignment with the validation data. The DNN model in Python excels further, achieving a value of R2 of 0.99995, accompanied by negligible MAE (0.0105) and moderate MSE (0.0002), highlighting its exceptional predictive accuracy and its ability to capture the underlying patterns within the validation data set accurately. Consistently across both environments, the DNN model outperforms the SVM RBF, with Python implementations yielding superior results. The consistently high values R2 across all models affirm their reliability and suitability for predictive tasks in MATLAB and Python environments.\nB. Prediction Testing Scenarios Results\nIn evaluating the generalization of the models to unseen data, two datasets denoted \u00ee are used with 40,128 samples (Scenario 1) and 19,252 samples (Scenario 2), each with six-dimensional input features. Testing is carried out in MATLAB and Python environments to ensure cross-platform consistency. MATLAB-visualized results, Fig. 4, reveal that for the larger dataset of Scenario 1, the predicted latitude and longitude responses are closely aligned with the true responses, though there are occasional outliers. However, the test results for the smaller dataset in Scenario 2, Fig. 5, indicate a higher error. This discrepancy suggests potential challenges in the models' ability to generalize effectively to datasets with fewer samples, offering valuable insights into their performance across varying data sizes.\nThe Python results exhibit a more favorable performance in predicting location than the actual location of the emergency vehicle for both test datasets, as shown in Fig. 6. These visual- izations suggest a higher accuracy in the Python environment, showcasing a closer alignment between the predicted and true responses for the ambulance's next location. The implication is that, in contrast to the MATLAB results discussed earlier, the Python implementation of the models shows superior per- formance in predicting the ambulance's location, highlighting the programming environment's importance in influencing the models' effectiveness.\nC. Showcasing The Prediction in The DT\nA mock DT environment has been developed on the host machine\u00b2 to emulate the original and predicted ambulance locations. Using the open-source Docker platform for con- tainerization, the DT application and its associated components and dependencies are encapsulated within virtual containers; a Docker container is constructed using a Docker package/image [13]. The orchestration of these containers is adeptly managed by Docker-compose, which is crucial for the cohesive operation of the DT system. The resultant integrated DT system is contained within the Docker-compose framework, as illustrated in Fig. 7. Three main images are used. For data streaming, Apache Kafka, renowned for its scalability and fault tolerance capabilities, is set by the \"confluentinc/cp-kafka:latest\" image [14]. Apache Zookeeper is used through the \"confluentinc/cp- zookeeper:latest\" image to coordinate and synchronize the Kafka streaming nodes (brokers) to ensure consistent manage- ment of system coordination [16]. Lastly, the Grafana visualiza- tion, represented by the \"grafana/grafana:latest\" image, builds a connection agent to integrate Kafka with the visualization, i.e., to send Kafka metrics to the Grafana Cloud instance. The data pipeline in our DT starts with reading the input data. We used a CSV file with timestamp, latitude, and longitude coordinates of the current location $(x_i^v,y_i^v)$, the predicted coordinates of the next corresponding location $(x_i^{v_T+}, y_i^{v_T+})$ using SVR and DNN for an ambulance of the 221 vehicles in\nD. Witnessed Delay Offset\nTo assess the impact of prediction on mitigating the observed delay (AT) between the digital and physical domains, our simulation-based analysis initially examines the communication delay observed from the perspective of the Road Side Unit (RSU) in the physical network. With an RSU coverage of 1 km that accommodates around n = 40 vehicles, the RSU uses V2I communication through a cellular network with a data transfer rate of 100 Mbps. Furthermore, V2V communication employs WiFi at 6Mbps, featuring a control channel duration of 46 msec. Specifically, for a safety application that transmits 310 bytes of data, a vehicle beacon rate of 100 msec, and an application processing time of 2.23 msec, Table II illustrates a noticeable correlation between the increase in the number of vehicles n and the increase in delay in the physical HITS realm. Upon deploying virtual twin prediction models for this HITS at the RSU's edge server, improvements in the observed temporal gap (AT) between the DT and the physical system are evident, as depicted in Table II, including the average testing prediction delays of 0.0883 sec for the DNN model and 0.0037 sec for the SVR model. The results in Table II show the efficacy of using predictive models to bridge the temporal gap in HITS, especially as the number of vehicles increases. The DNN and SVR models contribute to substantial \u2206\u03c4 reductions, reflecting improved synchronization between the digital and physical realms."}, {"title": "IV. CONCLUSION AND KEY EXTENSIONS", "content": "Despite the prevalent claim of real-time representation, the digital counterpart of HITS must always catch up with its physical world due to synchronization delays \u0394\u03c4. Our approach leveraged AI models to forecast the next-ambulance locations in the virtual world and align the virtual positions with their physical twin locations. We built a mock DT environment using Docker and Kafka to support a real-time data pipeline of actual and predicted locations; our DT enabled accurate visualization through Grafana, enhancing synchronization in HITS operations. In this DT, both the SVR and DNN models showcased high prediction accuracy in various testing scenarios and visually underscored the effectiveness of our methodology. In particular, DNN was the superior model, outperforming SVR in multiple instances. Significantly, both models played a transformative role by substantially reducing observed delays from 1.65 sec in the case of n=2 vehicles to only 0.196 sec and from 33 sec in the case of n=40 vehicles to only 2.1 sec. These results highlighted the efficacy of our proposed approach and emphasized the pivotal role of advanced AI predictive models in addressing such critical challenges. Future work could focus on ensemble modeling, combining SVR and DNN for improved predictions, and exploring hybrid solutions like edge-cloud DT integration for enhanced real-time processing efficiency."}]}