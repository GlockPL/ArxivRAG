{"title": "TalkMosaic: Interactive PhotoMosaic with Multi-modal LLM Q&A Interactions", "authors": ["Kevin Li", "Fulu Li"], "abstract": "We use images of cars of a wide range of varieties to compose an image of an animal such as a bird or a lion for the theme of environmental protection to maximize the information about cars in a single composed image and to raise the awareness about environmental challenges.\nWe present a novel way of image interaction with an artistically-composed photomosaic image, in which a simple operation of \u201cclick and display\u201d is used to demonstrate the interactive switch between a tile image in a photomosaic image and the corresponding original car image, which will be automatically saved on the Desktop. We build a multimodal custom GPT named TalkMosaic by incorporating car images information and the related knowledge to ChatGPT. By uploading the original car image to TalkMosaic, we can ask questions about the given car image and get the corresponding answers efficiently and effectively such as where to buy the tire in the car image that satisfies high environmental standards. We give an in-depth analysis on how to speed up the inference of multimodal LLM using sparse attention and quantization techniques with presented probabilistic FlashAttention (PrFlashAttention) and Staircase Adaptive Quantization (SAQ) methods. The implemented prototype demonstrates the feasibility and effectiveness of the presented approach.", "sections": [{"title": "1. Introduction", "content": "Currently, we have faced quite a long list of endangered species on Earth due to various pollutions for our environment. According to a report by CNN [4], almost 6.1 million metric tons of car tire dust end up in our atmosphere and waterways every year and the microplastics from those car tire dust contribute to dangerous PM2.5 pollution for our environment as well as endangered species on Earth. Recent advancement of AI, in particular multi-modal ChatGPT (generative pre-trained transformer) gives rise to great potential for convenient Q&A (questions & answers) interactions with images. The problem is how can we use AI, more specifically the multi-modal LLM (large language model) [9,11,17,19-20,22] platform to raise the awareness of endangered species and environment protection? For example, finding an appropriate car part for replacing or repairing for one's car such as car tires that meets with high environmental protection standards can be complicated.\nAccording to a report in [15], in the first quarter of 2023, there were almost 286 million vehicles operating on roads throughout the United States. There are essentially millions of car images and the images of endangered species.\nThe challenge is that can we provide an innovative and interactive UI (user interface) with those images that can help to raise the awareness of endangered species by composing the image of an endangered species with a number of car images such as interactive image mosaic? Further, can we use a Chatbots such as a custom GPT, named TalkMosaic, to answer the user's questions such as where to buy the car parts that meet with high environmental standards immediately and conveniently by just uploading the corresponding car image to the Chatbots with multi-modal LLM? Essentially, we are exploring efficient ways to use Al to protect our environment.\nOur work is partly inspired by Albert Einstein's assessment on the development of Western Science [7] more than 70 years ago as well as the sensational work on causal attention computation in Transformer model by Vaswani et al in 2017 [16]. According to Einstein [7], the development of Western Science is based on two great achievements: the invention of the formal logical system (in Euclidean geometry) by Greek philosophers, and the discovery of the possibility to find out causal relationships by systematic experiment (Renaissance). Nearly 70 years later, the state of the art of AIGC (AI generated content) is the discovery of the possibility to find out causal attention using Transformer model [16] by massive data sets and massive parallel computation with GPUs (graphics processing unit) or TPUs (tensor processing unit).\nIn this paper, we tend to explore the computation of causal attention in two different settings. In the first scenario, the computation of causal attention for the composing a mosaic image of an endangered species with a data set of multiple car images is at the pixel level based on some statistical properties of the pixel values in different image channels, i.e., RGB channels for color image or one channel for grayscale images. In the second scenario, the computation of causal attention for multi-modal LLM is at the language token level, i.e., the scaled dot product attention as described in [16]. In the case of composing mosaic"}, {"title": "2. Related Work", "content": "The term of photomosaic is first coined by Silvers in [13] and the work on composing photomosaic images using clustering based evolutionary programming can be found in [8]. Our work differs from [8,13] in that we provide \u201cclick and display\u201d interactions for tile images in the photomosaic for further Q&A interactions with a multi-modal custom GPT while the photomosaic images in [8,13] are static images without \u201cclick and display\u201d interactions.\nThe seminal work in [5,6] on FlashAttention has been widely adopted for attention computation in Transformer models [16], in particular as a default attention computation approach in PyTorch."}, {"title": "3. A Unified Framework", "content": "The common thread among the construction of interactive, i.e., \u201cclick and display\u201d, photomosaic and the eventual TalkMosaic for Q&A applications with a multimodal custom ChatGPT is the computation of attention scores in different settings. We discuss more details in the following sections."}, {"title": "3.1. PhotoMosaic with \u201cClick and Display\" Interactions", "content": "Let N stand for the number of input images, which are candidates for the grid tile images of the photomosaic image. Let (wi,hi) stand for the size dimension information for the ith input image, where wi is the width information and hi is the height information of the ith input image. Let Ni,c stand for the type information for the ith input image, which is the number of channel information for the ith input image. Let (m,n) stand for the dimension information of the grid for the photomosaic image, where m denotes the number of rows of the tiles in the grid and n is the number of columns of the tiles in the grid. Without loss of generality, we assume that each grid tile image is a square of"}, {"title": "3.2. Multi-modal LLM with a Custom GPT", "content": "We build a multimodal custom ChatGPT [1] named TalkMosaic by incorporating car images and related knowledge information such as where to buy a car tire in the image that satisfies high environment standards to ChatGPT. We give an in-depth analysis on how to speed up the inference with sparse attention and quantization techniques in the following sections."}, {"title": "3.3. Analysis On Speeding Up the Inference with Sparse Attention and Quantization Techniques", "content": "There are generally two ways to speed up the inference with multi-modal LLM by means of sparse attention computation as well as quantization techniques for KV (key, value) cache during attention computation. In the following, we present Probabilistic FlashAttention (PrFlashAttention) based on block distance (the number of blocks in-between) and Staircase Adaptive Quantization (SAQ) for KV cache based on token arrival distance (the number of tokens in-between)."}, {"title": "3.3.1. Probabilistic FlashAttention", "content": "FlashAttention [5,6] for exact attention computation in Transformer model for LLM by Hazy Research at Stanford has been widely adopted, in particular as a default attention computation approach for Transformer model in PyTorch. As discussed in [13], fast causal attention computation for sparse FlashAttention can be more efficient. We considers attention computation in Transformer model for LLM in a probabilistic way. The presented probability density function (PDF) with respect to the block/tile distance in the matrix follows a constrained harmonic deduction philosophy. The presented PrFlashAttention dynamically and probabilistically skips less-related rows/columns in Query/Key (Q/K) matrix along a tensor dimension, say the number of Head dimension of H, in the tensor shape of (Batch, Head, Context Length, Head Dimension) during attention computation while supporting causal masks for auto-regressive models by reshaping the tensors.\nIn the following, we discuss the probabilistic model for the presented approach of PrFlashAttention and how the masks for each row in the query matrix of Q and each column in the key matrix of K are calculated.\nThe presented probabilistic model for PrFlashAttention is defined as follows: For a block distance, say, n, within a given range, say, k, the probability is set as one, otherwise, it follows a harmonic deduction series.\n\n\\(f(n) = \\begin{cases} 1, & \\text{if } 0 \\leq n \\leq k; \\\\ \\frac{1}{(n-k)(n-k + 1)}, & \\text{if } n > k; \\end{cases}\\)\n\nNotably, for the second part, when n > k, we have the sum of probability series as:\n\\( \\frac{1}{\\max([N\\div Br], [N \\div Bc]) - k} \\),\nwhere N is the context length, Br and Bc are block sizes for matrix Q and matrix K respectively.\nLet nq stand for the number of blocks in each row of matrix Q, the normalized probability for each row can be defined as:\n\n\\(Pr(rq) = \\frac{\\sum_{i=1}^{nq} Pr(i)}{nq}\\)\n\nwhere Pr(i) is the probability of the ith block in the qth row of rq"}, {"title": "3.3.2 Staircase Adaptive Quantization for KV Cache", "content": "We present Staircase Adaptive Quantization (SAQ) for KV cache to further alleviate the problem of KV cache based on the framework in [10] by means of gradual quantization degradation. For a B-bit integer, the quantization and de-quantization process can be expressed as follows[10]:\n\n\\(Q(X) = [\\frac{SX}{2B-1} ]\\)\n\n\\(X' = Q(X). sx + zx\\)\n\nwhere Q(X) indicates the quantized tensor of X, X' is the de-quantized tensor of Q(X), zx = min X is the zero-point and sx = (max X \u2013 min X)/(2B \u2013 1) is the scaling factor and the symbol of [.]is the rounding operation.\nNotably, key and value cache of newly generated tokens arrive sequentially in time. Following similar settings in [10], during the pre-fill phase, exact (full precision) key and value tensors are passed to the next layers, even though only the quantized KV cache is retained in memory to reduce the memory footprint and to prevent some re-computations in the decoding phase.\nWe assume that we have lprompt number of key tokens and lprompt number of value tokens in the pre-fill stage. We also assume that a full precision is expressed as 16-bit quantization such as fp16 (float point 16) that is commonly used in the implementation of tensors, so we can have lower quantization choices such as 8-bit quantization, 4-bit quantization, 2-bit"}, {"title": "5. Conclusion and Future Directions", "content": "Recent advancement of AI, in particular multi-modal ChatGPT gives rise to great potential for Q&A interactions with images. By using a custom ChatGPT with car images and related knowledge materials, questions can be answered on where to buy a car part to meet a certain level of environmental standards conveniently and efficiently. By using an artistically-composed photomosaic image of an endangered species such as a bird or a lion with a large collection of car images, the theme of environmental protection is further embodied. The magic is that with a few layers of mosaic images, we can essentially accommodate billions of car images. With simple \u201cclick and display\u201d interaction of photomosaic image, the original car image of the tile image in the photomosaic image will pop up and be automatically saved on the Desktop. By uploading the corresponding car image to a multimodal custom GPT, people can get their answers quickly and conveniently on where to buy a car tire in the image that satisfies high environmental standards. We also present efficient ways to speed up inference with multi-modal LLM using probabilistic FlashAttention (PrFlashAttention) and Staircase Adaptive Quantization (SAQ) of KV cache techniques."}]}