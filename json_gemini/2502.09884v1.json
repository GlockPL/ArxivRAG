{"title": "Nonasymptotic CLT and Error Bounds for Two-Time-Scale Stochastic Approximation", "authors": ["Seo Taek Kong", "Sihan Zeng", "Thinh T. Doan", "R. Srikant"], "abstract": "We consider linear two-time-scale stochastic approximation algorithms driven by martingale noise. Recent applications in machine learning motivate the need to understand finite-time error rates, but conventional stochastic approximation analysis focus on either asymptotic convergence in distribution or finite-time bounds that are far from optimal. Prior work on asymptotic central limit theorems (CLTs) suggest that two-time-scale algorithms may be able to achieve 1/\u221an error in expectation, with a constant given by the expected norm of the limiting Gaussian vector. However, the best known finite-time rates are much slower. We derive the first non-asymptotic central limit theorem with respect to the Wasserstein-1 distance for two-time-scale stochastic approximation with Polyak-Ruppert averaging. As a corollary, we show that expected error achieved by Polyak-Ruppert averaging decays at rate 1/\u221an, which significantly improves on the rates of convergence in prior works.", "sections": [{"title": "1. Introduction", "content": "Stochastic approximation (SA), introduced by (Robbins and Monro, 1951), is an iterative sample- based approach to find the root (or fixed point) x* of some unknown operator F. In particular, SA iteratively updates x, an estimate of x*, by moving along the direction of the sample F(x; \u00a7) scaled by some step size, where \u00a7 is a random variable representing sampling noise. The simplicity of its implementation has enabled broad applications in many areas including stochastic optimization, machine learning, and reinforcement learning (Sutton and Barto, 2018; Lan, 2020). The convergence properties of SA are well-studied, where the error rate achieved by SA with Polyak-Ruppert (PR) averaging is known to decay faster than that of SA without PR averaging (Polyak and Juditsky, 1992).\nIn this paper, we study the finite-time error rates of the linear two-time-scale SA (TSA) algorithm, a generalized variant of SA, for solving a system of two coupled linear equations, i.e., we seek to find a pair (x*, y*) that solves\n$\\begin{aligned} \\mathbb{E}_W[A_{ff}x^* + A_{fs}y^* - W] &= 0, \\\\\n\\mathbb{E}_V[A_{sf}x^* + A_{ss}y^* \u2013 V] &= 0,\n\\end{aligned}$"}, {"title": "where W, V are random vectors with unknown distributions and Aff, Afs, Asf, Ass are the system parameters. In this setting, TSA iteratively updates (x, y) as follows:", "content": "$\\begin{aligned} x_{t+1} &= x_t - \\alpha_t (A_{ff}x_t + A_{fs}y_t - W_t) \\\\\ny_{t+1} &= y_t - \\gamma_t (A_{sf}x_t + A_{ss}y_t \u2013 V_t),\n\\end{aligned}$ \nwhere {(Wt, Vt)} is a martingale difference sequence representing the sampling noise. Here, \u03b1t \u00bb \u03b3t are two different step sizes. The variable x is often referred to as the fast-time-scale variable (using larger step sizes) while y is called the slow-time-scale variable (using smaller step sizes).\nTSA has received a great amount of interest due to its application in many areas where the classic SA is not applicable. Prominent examples include gradient temporal-difference learning (Sutton et al., 2008, 2009; Xu et al., 2019), actor-critic methods in reinforcement learning (Konda and Borkar, 1999; Bhatnagar et al., 2012; Gupta et al., 2019; Wu et al., 2020; Zeng and Doan, 2024b), and gradient descent-ascent methods in min-max optimization for zero-sum games (Zeng et al., 2022). These methods require one iterate being updated using a smaller step size than the other to guarantee convergence.\nUnlike the literature on SA where convergence properties are well understood, theoretical results for TSA are not complete. While the benefit of using PR averaging has been established for SA (Polyak and Juditsky, 1992), its benefit has only been demonstrated with respect to asymptotic convergence in distribution for TSA (Mokkadem and Pelletier, 2006). In this paper, we focus on understanding the finite-time error rates at which the PR average of the iterates generated by TSA converge to the desired solution. We use TSA to refer to the sequence {(xt, yt)} in Eq. (2) without Polyak-Ruppert averaging, to distinguish from TSA-PR which is used to refer to the averages (In, Yn). Our contributions are summarized below."}, {"title": "1.  We establish in Theorem 3 a finite-time bound on the Wasserstein-1 distance between the scaled deviations \u221an(In \u2013 x*) and \u221an(\u0177n \u2013 y*) generated by TSA-PR and their Gaussian limits. This is the first non-asymptotic central limit theorem (CLT) in the context of two-time- scale algorithms, complementing the asymptotic CLT established in (Mokkadem and Pelletier, 2006).", "content": "2.  Our bound on the Wasserstein-1 distance implies that the expected error achieved by TSA-PR decays at rate n-1/2 (Corollary 4), where error is defined to be the norms ||In - x*|| and || \u0177n \u2013 y* ||. This rate significantly improves the rate achieved by TSA without PR averaging, as explained in Section 1.1.1 and Remark 5.\n3.  In proving these results, we also establish in Theorem 2 lower and upper bounds on the expected square error (MSE) achieved by TSA (i.e., without PR averaging). When compared to similar bounds in prior works, our result provides a more convenient representation to establish our main results above while using a much simpler proof technique."}, {"title": "1.1. Related Work", "content": "In this section, we highlight the differences between our results and prior work. References in the following discussion may assume a model with conditions that differ from ours (Assumptions 1\u20133), but nonetheless we refer to their results when they are comparable. The norms (||xn-x* ||, ||Yn-y* ||) and (||In - x* ||, ||\u1ef3n \u2013 y* ||) are referred to as the errors achieved by TSA and TSA-PR, respectively."}, {"title": "1.1.1. POLYAK-RUPPERT AVERAGING IN TWO-TIME-SCALE ALGORITHMS", "content": "Understanding the optimal rates that can be achieved by a class of algorithms is important for algorithm design. The study of optimal rates in stochastic approximation has been a central focus since (Robbins and Monro, 1951). In the context of single-time-scale algorithms, the question of whether the optimal rate could be achieved was resolved by Polyak and Juditsky (1992), using the PR averaging scheme as proposed by Ruppert (1988); Polyak (1991). Moreover, it was shown that the minimum asymptotic covariance is obtained. The PR averaging scheme was extended to two-time-scale algorithms by Mokkadem and Pelletier (2006), where the authors established asymptotic normality of TSA-PR.\nAll the above results are asymptotic. The widespread application of stochastic approximation algorithms has spurred interest in understanding finite-time bounds. For single-time-scale algorithms, finite-time bounds on the averaged iterates are known when the step size is constant (Srikant and Ying, 2019; Mou et al., 2020; Durmus et al., 2024). These bounds involve correction terms because constant step sizes are not asymptotically optimal. Finite-time bounds for decaying step sizes was established in (Srikant and Ying, 2019; Chen et al., 2022; Srikant, 2024). Less is known for the more general case of two-time-scale algorithms. Existing finite-time bounds are known only for the TSA without the averaging in Eq. (2); see (Dalal et al., 2018; Kaledin et al., 2020; Haque et al., 2023). Here, we establish the first finite-time bound for the averaged iterates (TSA-PR) generated by two-time-scale algorithms with decreasing step sizes. The rates shown to be achieved by TSA-PR significantly improves that achieved by TSA, akin to the single-time-scale case."}, {"title": "1.1.2. LIMIT THEOREMS AND QUANTITATIVE BOUNDS", "content": "Central limit theorems have been established for both SA and TSA algorithms (Polyak and Juditsky, 1992; Mokkadem and Pelletier, 2006; Hu et al., 2024). But these results are asymptotic, and therefore cannot be applied to rigorously test the significance of repeated trials that halt after a finite number of iterations. Non-asymptotic CLTs were established in (Anastasiou et al., 2019; Samsonov et al., 2024; Srikant, 2024), which capture the normality behavior of single-time-scale algorithms. In this paper (Theorem 3), we establish a finite-time bound on the Wasserstein-1 metric for TSA-PR using the martingale CLT in (Srikant, 2024). The reason for considering the Wasserstein-1 distance as in (Srikant, 2024) is that weaker notions of distance considered in (Anastasiou et al., 2019; Samsonov et al., 2024) are not strong enough to deduce explicit bounds such as the expected error. In Corollary 4, we show that convergence in the Wasserstein-1 distance can be used to establish both a lower and upper bound on the expected error, capturing its correct magnitude up to exact constants."}, {"title": "2. Model and Preliminaries", "content": "In this paper, we consider two time-scale stochastic approximation algorithms of the form\n$\\begin{aligned} x_{t+1} &= x_t - \\alpha_t (A_{ff}x_t + A_{fs}y_t \u2013 W_t), \\\\\ny_{t+1} &= y_t - \\gamma_t (A_{sf}x_t + A_{ss}y_t \u2013 V_t) .\n\\end{aligned}$\nWhile we do not consider the so-called ODE approach here to analyze the system, the assumptions on the system matrices in Eq. (3) are easy to explain by relating the above to a singularly perturbed differential equation (ODE); see (Borkar, 2008):\n$\\begin{aligned} \\dot{x_t} &= -(A_{ff}x_t + A_{fs}y_t), \\\\\n\\dot{y_t} &= -\\frac{\\gamma}{\\alpha} (A_{sf}x_t + A_{ss}y_t).\n\\end{aligned}$"}, {"title": "In the limit \u03b3\u03b9\u03b1 \u2192 0, xt evolves much faster than yt. When the system governing it is stable, the slow-time-scale yt is analyzed assuming a stationary solution xx(y) = -A++Afsy:", "content": "$\\dot{y_t} = (A_{sf}x_x(y_t) + A_{ss}y_t) = -(A_{ss} - A_{sf}A_{ff}^{-1}A_{fs})y_t.$ \nTo ensure that both xt and yt converge to their respective limits, it is therefore assumed that - Aff and -\u2206 = -(Ass - Asf AF Afs) are both H\u00fcrwitz stable, i.e., the eigenvalues lie in the left-half of the complex plane. The rates at which the discretized system in Eq. (3) approach their limits are studied under the same setting, which we now state formally.\nAssumption 1 (System Parameters) The matrix Aff and its Schur complement \u2206 = Ass - Asf AF Afs are real and satisfy\n$A_{ff} + A_{ff}^T > 0, \\quad \\Delta + \\Delta^T > 0.$\nWhen a matrix \u2013 A is H\u00fcrwitz stable, we use \u03bc\u0104, VA to denote the smallest and largest eigenvalues of A + AT, respectively.\nAssumption 2 (Noise) Let {N+} := {(Wt, Vt)}t_1 be a martingale difference sequence drawn independently of the iterates xt and yt. We assume that for every t \u2265 1, E||N+||2+\u03b2 < \u221e for some \u03b2 \u2208 (1/2, 1) and that\n$\\mathbb{E}[W_t W_t^T|\\mathcal{H}_{t-1}] = \\Gamma_{ff}, \\quad \\mathbb{E}[V_t V_t^T|\\mathcal{H}_{t-1}] = \\Gamma_{ss}, \\quad \\mathbb{E}[W_t V_t^T|\\mathcal{H}_{t-1}] = \\Gamma_{fs},$\nwhere Ht = {x1, Y1, W1, V1,\uff65\uff65\uff65,Wt, Vt} and \u0393 is covariance matrix of (Wt, Vt) conditioned on the history.\nOur last assumption is a guidance on how to choose the step sizes.\nAssumption 3 (Step Size) The step sizes are chosen to be at = a\u2081t\u00af\u00aa, Yt = \u00a51t\u2212b for 1/2 < a < b < 1 and any a1, Y1 > 0.\nRemark 1 Both xn and yn converge even when b = 1. This parameter is crucial when deducing the n\u00af\u00b9 rate for the second moment of the slow-time-scale iterate. As we will show that the Polyak- Ruppert averaging scheme achieves this fast rate for both fast- and slow-time-scale variables without having to set b = 1, we assume b < 1 which introduces minor technical conditions on the requirement for Y1.\nHere we allow arbitrary 01, Y1 > 0, but clarify a few technical conditions. Define (\u00b5ff, vff) and (\u03bc\u25b3, \u03bd\u25b3) such that puff I < Aff + Aff \u2264 vffI and \u00b5\u25b3I < \u25b3 + \u2206T < v\u25b3I. Because at, Yt \u2192 0 and Yt/at \u2192 0, there exists a time to and problem-dependent constants K1, K2, K3 such that the following holds for all t \u2265 to:\n$\\gamma_t < \\frac{K_1}{\\nu_{ff}}, \\quad \\frac{\\gamma_t}{\\alpha_t} < K_2 \\min\\{\\frac{\\mu_{\\Delta}}{\\nu_{ff}}, \\frac{\\mu_{ff}}{\\nu_{\\Delta}} \\}, \\quad \\frac{\\alpha_t}{\\gamma_t} < K_3.$\nSince this condition will be satisfied at some finite time to, the analysis in this paper holds for all t\u2265 to. We set to = 1 for simplicity of exposition."}, {"title": "3. Main Results", "content": "In this section, we state a finite-time bound on the Wasserstein-1 distance between TSA-PR, scaled appropriately, and its Gaussian limit. We highlight the practical significance of this result by proving lower- and upper-bounds on the expected error. To this end, we first prove that the second moments of TSA error converge to zero at rates determined by the choice of step sizes.\nRecall the notations \u00cen = Xn X*, \u0177n = Yn y* to denote the deviation of TSA (Xn, Yn) from the solution (x*, y*).\nTheorem 2 Assume 1\u20133. Let \u2211 be the asymptotic covariance of (xt \u2013 x*, Yt y*), evaluated as\n$\\begin{aligned} A_{ff}\\Sigma_{ff} + \\Sigma_{ff}A_{ff}^T &= \\Gamma_{ff}, \\\\\nA_{ff} \\Sigma_{fs} + \\Sigma_{ff}A_{ff}^T &= \\Gamma_{fs}, \\\\\n\\Delta \\Sigma_{ss} + \\Sigma_{ss}\\Delta^T + A_{sf}\\Sigma_{fs} + \\Sigma_{sf}A_{fs}^T &= \\Gamma_{ss}.\n\\end{aligned}$\nFor some problem-dependent constants Mf, Ms > 0 and every n \u2265 1, it holds that\n$\\begin{aligned} ||\\mathbb{E} \\widehat{x}_{n+1} \\widehat{x}_{n+1}^T - \\alpha_{n+1} \\Sigma_{ff} || &\\leq \\Big[\\prod_{t=1}^n (1 - \\alpha_t \\frac{\\mu_{ff}}{4})\\Big] ||\\mathbb{E} \\widehat{x}_{1} \\widehat{x}_{1}^T - \\alpha_{1} \\Sigma_{ff} || + M_f \\mathcal{V}_n,\\\\\n||\\mathbb{E} \\widehat{y}_{n+1} \\widehat{y}_{n+1}^T - \\gamma_{n+1} \\Sigma_{ss} || &\\leq \\Big[\\prod_{t=1}^n (1 - \\gamma_t \\frac{\\mu_{\\Delta}}{4})\\Big] ||\\mathbb{E} \\widehat{y}_{1} \\widehat{y}_{1}^T - \\gamma_{1} \\Sigma_{ss} || + M_s \\mathcal{W}_n,\n\\end{aligned}$\nA proof is provided in Sections B.1\u2013B.3. The finite-time bounds in Theorem 2 are needed to derive our next result in Theorem 3. Specifically, it is implied that\n$\\lim_{n \\to \\infty} || \\mathbb{E} \\widehat{x}_{n+1} \\widehat{x}_{n+1}^T - \\alpha_{n+1} \\Sigma_{ff} || = 0, \\quad \\lim_{n \\to \\infty} || \\mathbb{E} \\widehat{y}_{n+1} \\widehat{y}_{n+1}^T - \\gamma_{n+1} \\Sigma_{ss} || = 0.$\nNote that the nature of Theorem 2 is similar to Theorem 4.1 in (Haque et al., 2023). However, the latter is not directly applicable to our setting. Our presentation provides a more convenient step to establish the convergence rates in Theorem 3. In addition, we develop a simple proof technique for Theorem 2 compared to existing proofs for finite-time mean square error rates.\nNext, we present a non-asymptotic CLT for TSA-PR. To our knowledge, Mokkadem and Pelletier (2006) are the only authors who analyzed TSA-PR in the context of two-time-scale SA, where the authors prove its asymptotic behavior. Utilizing the error bounds in Theorem 2 for TSA, we establish a non-asymptotic CLT on the deviation \u221an(\u017en \u2013 z*) from a Gaussian variable 1/2Z by obtaining a finite-time bound on the Wasserstein-1 distance\n$d_1 (\\sqrt{n}(z_n - z^*), \\Sigma^{1/2}Z) := \\sup_{h \\in Lip_1} \\Big|\\mathbb{E} [h (\\sqrt{n}(z_n-z^*))] - \\mathbb{E} [h (\\Sigma^{1/2}Z)]\\Big|.\n The limiting distribution of TSA-PR involves the Schur complement G = Aff \u2013 AfsA551 Ass of Ass, as well as the Schur complement A defined in Section 2.\nTheorem 3 Let zn := (In, Yn) be the Ruppert-Polyak average of (xt, yt) generated by (3). Define the asymptotic covariance of \u221an(In \u2013 x*) and \u221an(\u0177n \u2013 y*) as\n$\\Sigma_{ff} = \\lim_{n \\to \\infty} n \\mathbb{E}(\\bar{x}_n - x^*)(\\bar{x}_n - x^*)^T, \\quad \\Sigma_{ss} = \\lim_{n \\to \\infty} n \\mathbb{E}(\\bar{y}_n - y^*)(\\bar{y}_n - y^*)^T.$"}, {"title": "Under Assumptions 1\u20133, the above limits exist, and the rate of convergence in the Wasserstein-1 distance is given by:", "content": "$\\begin{aligned}\nd_1 (\\sqrt{n}G(\\bar{x}_n - x^*), (G\\Sigma_{ff}G^T)^{1/2}Z_1) &= O\\Big(\\frac{1}{\\sqrt{n}} \\left(n^{a/2} + n^{a-b/2} + n^{b/2} \\right)\\Big), \\\\\nd_1 (\\sqrt{n}\\Delta(\\bar{y}_n - y^*), (\\Delta \\Sigma_{ss}\\Delta^T)^{1/2}Z_2) &= O\\Big(\\frac{1}{\\sqrt{n}} \\left(n^{a/2} + n^{a-b/2} + n^{b/2} \\right)\\Big),\n\\end{aligned}$\nwhere Z1 and Z2 are standard Gaussian vectors of appropriate dimensions.\nThe asymptotic covariances \u2211ff and \u221155 satisfy\n$\\begin{aligned}\nG\\Sigma_{ff}G^T &= \\Gamma_{ff} + A_{fs}A_{ss}^{-1}\\Sigma_{ss}(A_{fs}A_{ss}^{-1})^T - (\\Gamma_{fs}(A_{fs}A_{ss}^{-1})^T + A_{fs}A_{ss}^{-1}\\Gamma_{sf})\\\\ \n\\Delta\\Sigma_{ss}\\Delta^T &= \\Gamma_{ss} + A_{sf}A_{ff}^{-1}\\Sigma_{ff}(A_{sf}A_{ff}^{-1})^T - (\\Gamma_{sf}(A_{sf}A_{ff}^{-1})^T + A_{sf}A_{ff}^{-1}\\Gamma_{fs}),\n\\end{aligned}$\n$\\mathbb{E}||G(\\bar{x}_n - x^*)|| - \\frac{1}{\\sqrt{n}} \\mathbb{E}||(G\\Sigma_{ff}G^T)^{1/2}Z_1||\\Big| = o(n^{-1/2}) \\\\\n\\Big|\\mathbb{E}||\\Delta(\\bar{y}_n - y^*)|| - \\frac{1}{\\sqrt{n}} \\mathbb{E}||(\\Delta \\Sigma_{ss}\\Delta^T)^{1/2}Z_2||\\Big| = o(n^{-1/2})$\nThe bounds on the expected error is tight, in the sense that the expected error is bounded above by rate n-1/2, and similar to Eq. (10), both E||In - x*|| and E||\u1ef3n - y* || are lower bounded by the expected norm of the limiting Gaussian vector times the rate n-1/2. Replacing the norm of the Gaussian vector with the trace of its covariance would yield O(n-1/2) instead of the o(n-1/2) above. Theorem 3 shows that the step sizes determine the quality of a Gaussian approximation of Zn - z* at any n \u2265 1, whereas Corollary 4 shows that the expected error decays at rate n\u22121/2, with the step sizes 1/2 < a < b < 1 determining only the transient behavior.\nRemark 5 As mentioned in Section 1.1, a finite-time performance guarantee on TSA-PR has not been established in literature. Second moment bounds, which are common metrics of interest in the analysis of stochastic approximation algorithms, are inevitably tied to the trace of an algorithm's asymptotic covariance. We emphasize that such bounds only provide a conservative estimate of n-1/2\u221aTr\u2211 on the expected error."}, {"title": "3.1. Discussion", "content": "To understand the significance of the Wasserstein-1 distance error bounds achieved by TSA-PR, it is useful to compare with an oracle algorithm that has access to the system parameters A. Such an algorithm has been considered as a baseline in prior work (Polyak and Juditsky, 1992; Konda and Tsitsiklis, 2004; Mokkadem and Pelletier, 2006).\nConsider a modification of TSA in (2), where the algorithm is allowed to design two gain matrices Qff, Qss and estimate the solution (x*, y*) with the sequence {(x, y)} updated as\n$\\begin{aligned}\nx_{t+1}^* &= x_t^* - \\alpha_t Q_{ff} (A_{ff}x_t^* + A_{ss}y_t^* - W_t) \\\\\ny_{t+1}^* &= y_t^* - \\gamma_t Q_{ss} (A_{sf}x_t^* + A_{ss}y_t^* - V_t).\n\\end{aligned}$"}, {"title": "A constraint is imposed on Qff and Qss so that the modified system with the gain matrix is asymptotically stable. It was shown in (Mokkadem and Pelletier, 2006) that if the step sizes are chosen as at = O(t\u00af\u00aa) and Yt = O(t\u2212b) with a \u2208 (1/2, 1), the slow-time-scale {y}}=1 converges in distribution to the solution y*:", "content": "$\\sqrt{n}(y_n^* - y^*) \\to N(0, \\Sigma_{ss}(Q)),$\nwhere Ess(Qss) is the solution to the Lyapunov equation\n$\\begin{aligned}\nQ_{ss} &= \\frac{1}{2} \\Big(Q_{ss}^{-1} \\Delta + \\Delta^T Q_{ss}^{-1}\\Big)^{-1} \\Big(\\Gamma_{ss} + A_{sf} A_{ff}^{-1} (A_{sf} A_{ff}^{-1})^T - \\big(\\Gamma_{fs} (A_{sf} A_{ff}^{-1})^T + (A_{sf} A_{ff}^{-1})^T \\Gamma_{sf} \\big)\\Big) Q_{ss}. \n\\end{aligned}$\nA similar result holds for x when it is updated as the slow-time-scale variable (reversing the step size decay rates), where the other Schur complement G appears in place of \u2206 in the above equation. The minimum mean square error and the corresponding asymptotic covariance matrix is obtained by solving\n$\\min_{Q_{ff}} Tr \\Sigma_{ff}(Q_{ff}) =: Tr \\Sigma_{ff}^*, \\quad \\min_{Q_{ss}} Tr \\Sigma_{ss}(Q_{ss}) =: Tr \\Sigma_{ss}^*,$ \nwhich can be shown to satisfy\n$\\begin{aligned}\nG\\Sigma_{ff} G^T &= \\Gamma_{ff} + A_{fs} A_{ss}^{-1} \\Sigma_{ss}(A_{fs} A_{ss}^{-1})^T - (\\Gamma_{fs}(A_{fs}A_{ss}^{-1})^T + A_{fs} A_{ss}^{-1}\\Gamma_{sf}) \\\\\n\\Delta \\Sigma_{ss} \\Delta^T &= \\Gamma_{ss} + A_{sf} A_{ff}^{-1} \\Gamma_{ff}(A_{sf}A_{ff}^{-1})^T - (\\Gamma_{sf}(A_{sf}A_{ff}^{-1})^T + A_{sf} A_{ff}^{-1} \\Gamma_{fs})\n\\end{aligned}$\nThis matches the asymptotic covariance achieved by TSA-PR. But in this case, the above covariances are not obtained simultaneously because one variable has to be updated at a faster time scale. This is in contrast to TSA-PR, which achieves the minimum asymptotic mean square errors for both time scales simultaneously and at the same rate. Next, we explain a gap in literature in the context of achievable rates.\nImproved Rates via TSA-PR: Konda and Tsitsiklis (2004) proved that TSA converges asymp- totically in m.s., where it was shown that\n$\\lim_{n \\to \\infty} \\alpha_n^{-1} \\mathbb{E}(x_n - x^*)(x_n - x^*)^T = \\Sigma_{ff}, \\quad \\lim_{n \\to \\infty} \\gamma_n^{-1} \\mathbb{E}(y_n - y^*)(y_n \u2013 y^*)^T = \\Sigma_{ss},$\nwith Eff, Ess defined in Eq. (8). Finite-time counterparts to the above asymptotic convergence were established by Dalal et al. (2018); Kaledin et al. (2020); Haque et al. (2023), where it was shown that\n$\\mathbb{E}(x_n - x^*)(x_n - x^*)^T = O (\\alpha_n) \\Sigma_{ff}, \\quad \\mathbb{E}(y_n - y^*)(y_n \u2013 y^*)^T = O (\\gamma_n) \\Sigma_{ss}.$\nThe MSE rates, obtained by taking the trace of the above, demonstrate that the asymptotic rates in Eq. (18) are achievable. Our upper bound on the norm of the difference in Theorem 2 is stronger than Eq. (19) in that it also proves a lower bound, namely that the mean square errors decay no faster than an and Yn. These bounds suggest that the expected error rate achieved by TSA is of order O(n-a/2) and O(n-b/2), where a, b satisfy Assumption 3."}, {"title": "The scaling factor of \u221an in In - x* and Yn - y* in Theorem 3 suggests that TSA-PR enjoys faster rates of convergence than TSA. Moreover, its asymptotic covariance cannot be improved upon even when the model parameters are known, as seen for (xh, yn). Therefore, we conclude that the n-1/2 rate in Corollary 4 cannot be improved upon without a trade-off in covariance or other modes of convergences.", "content": "Next, we describe the tightness of the bound in Corollary 4. First, note that the result conveys both an upper and lower bound on E||In \u2013 x*|| and E||\u1ef3n \u2013 y*||, indicating that the guarantee is asymptotically tight. Knowing that the limit of \u221an(In \u2013 x*, \u0177n \u2013 y*) is the Gaussian vector \u22111/2Z, the best possible bound on the second moment is of the form\n$\\mathbb{E}||\\bar{x}_n - x^*||^2 = \\frac{1}{n}Tr \\Sigma_{ff} + o(n^{-1}), \\quad \\mathbb{E}||\\bar{y}_n - y^*||^2 = \\frac{1}{n}Tr \\Sigma_{ss} + o(n^{-1}).$\nWithout additional information, the expected error can be deduced using Jensen's inequality to obtain\n$\\mathbb{E}||\\bar{x}_n - x^*|| = \\frac{1}{\\sqrt{n}} \\sqrt{Tr \\Sigma_{ff}} + o(n^{-1/2}), \\quad \\mathbb{E}||\\bar{y}_n - y^*|| = \\frac{1}{\\sqrt{n}} \\sqrt{Tr \\Sigma_{ss}} + o(n^{-1/2}).$\nBut Corollary 4 establishes E||In - x*|| = \u0398(n-1/2E||\u2211ffZ1||) and a similar improvement for E||\u1ef3n \u2013 y*||. Therefore, it is interesting to see that the use of the Wassertein-1 distance in our CLT captures the expected error precisely up to exact constants."}, {"title": "4. Experiments", "content": "In this section, we complement our theoretical results with simulations that demonstrate the numerical observation of the finite-time bounds and CLT behaviors as predicted by our theories.\nSynthetic System of Equations. Our first set of experiments uses randomly generated system parameters Aff, Afs, Asf, Ass \u2208 R5\u00d75 subject to the constraints in Assumption 1. The noise {(Wt, Vt)} is sampled i.i.d. from the Gaussian distribution N(0, \u0393) with \u0393fs = 0 and \u0393ff, \u0393ss chosen to satisfy \u2211ss = I according to Eq. (17)."}, {"title": "We implement TSA and TSA-PR with the step sizes an = 0.5/(n + 1000)0.5, \n= 0.5/(n + 1000)0.6. By Corollary 4, the errors ||In \u2013 x* ||, ||In \u2013 y*|| achieved by TSA-PR are expected to decay with rate 1/\u221an, whereas Theorem 2 suggests that the errors ||xn - x*||, ||Yn \u2013 y*|| achieved by TSA depend on the choice of step sizes and decay slower than 1/\u221an. This is indeed observed in Figure 1, which plots the empirical errors scaled by \u221an, averaged over 100 trials. The TSA-PR curves for fast- and slow-time-scale variables exhibit downward movement, suggesting that ||In -x*|| and || Yn - y*|| both decay with rate O(1/\u221an). In comparison, the TSA curves move upward over iterations, which indicates that the iterates of TSA do not converge at an 1/\u221an rate.", "content": "According to Theorems 2 and 3, the scaled deviation \u221an(xn \u2013 x*, Yn \u2013 y*) of TSA exhibits increasing variance as n grows, whereas the scaled deviation \u221an(In \u2013 x*, Yn \u2013 y*) of TSA-PR converges to a Gaussian distribution. We visualize the deviations in Figure 2 using a smoothed kernel density plot at three checkpoints (different values of n). For simplicity of illustration, we only plot the first coordinates of the slow variables \u221an(yn \u2013 y*) and \u221an(\u0177n \u2013 y*). The figure reveals that \u221an(\u0177n \u2013 y*) indeed converges to a Gaussian distribution with standard deviation 1, which is the asymptotic covariance predicted by Theorem 3. The distribution of \u221an(yn \u2013 y*) exhibits an increasing standard deviation over time, again matching the results in Theorem 2."}, {"title": "Gradient-Based Policy Evaluation. Temporal difference learning with gradient correction (TDC) is a gradient-based policy evaluation algorithm in RL which works stably with function approximation", "content": "and off-policy sampling (Sutton et al., 2009). The algorithm seeks to solve the system of equations\n$\\begin{aligned}\n\\mathbb{E}_\\pi[\\phi(s)\\phi(s)^T x - r(s, a) - \\gamma \\phi(s')^T y | \\phi(s) + \\phi(s)^T y \\rbrack &= 0, \\\\\n\\mathbb{E}_\\pi[\\phi(s)\\phi(s)^T x - r(s, a) - \\gamma \\phi(s')y(s) + \\phi(s)y(s) \\rbrack &= 0.\n\\end{aligned}$\nHere x, y \u2208 Rd are the (fast- and slow-time-scale) variables, s, a, s' denote the state, action, and next state, and \u03c6(s) \u2208 Rd is the feature vector associated with state s. Details on how TDC can be expressed in the form Eq. (2) can be found in (Xu et al., 2019; Zeng and Doan, 2024a).\nWe employ TSA (equivalent to the standard TDC method in this case) and TSA-PR to evaluate the cumulative reward of a random policy under linear function approximation and off-policy samples collected by a uniform behavior policy. The reward function, transition kernel, and feature vectors are all randomly generated, with d = 10. Figure 3 compares the (scaled) errors of TSA and TSA-PR under the step sizes an = 0.5"}]}