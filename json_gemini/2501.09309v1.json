{"title": "Understanding Mental Health Content on Social Media and It's Effect Towards Suicidal Ideation", "authors": ["Mohaiminul Islam Bhuiyan", "Nur Shazwani Kamarudin", "Nur Hafieza Ismail"], "abstract": "The study \"Understanding Mental Health Content on Social Media and Its Effect Towards Suicidal Ideation\" aims to detail the recognition of suicidal intent through social media, with a focus on the improvement and part of the machine learning (ML), deep learning (DL), and natural language processing (NLP). This review underscores the critical need for effective strategies to identify and support individuals with suicidal ideation, exploiting technological innovations in ML and DL to further suicide prevention efforts. The study details the application of these technologies in analyzing vast amounts of unstructured social media data to detect linguistic patterns, keywords, phrases, tones, and contextual cues associated with suicidal thoughts. It explores various ML and DL models like SVMS, CNNS, LSTM, neural networks, and their effectiveness in interpreting complex data patterns and emotional nuances within text data. The review discusses the potential of these technologies to serve as a life-saving tool by identifying at-risk individuals through their digital traces. Furthermore, it evaluates the real-world effectiveness, limitations, and ethical considerations of employing these technologies for suicide prevention, stressing the importance of responsible development and usage. The study aims to fill critical knowledge gaps by analyzing recent studies, methodologies, tools, and techniques in this field. It highlights the importance of synthesizing current literature to inform practical tools and suicide prevention efforts, guiding innovation in reliable, ethical systems for early intervention. This research synthesis evaluates the intersection of technology and mental health, advocating for the ethical and responsible application of ML, DL, and NLP to offer life-saving potential worldwide while addressing challenges like generalizability, biases, privacy, and the need for further research to ensure these technologies do not exacerbate existing inequities and harms.", "sections": [{"title": "I. INTRODUCTION", "content": "As digital technologies permeate and reshape society, social media has emerged as a massive window into the psychological landscape of users. Individual expressions within these platforms can serve as a mirror, presenting critical insights into the mental well-being of the global population. Although revealing various pathologies, a stark reality is reflected that demands urgent attention - suicidal ideation. This affliction continues to take an unconscionable toll, with the World Health Organization (WHO) reporting nearly 800,000 people dying by suicide annually [1]. Shockingly, it is the second leading cause of death for those aged 15-29 years [2]. Many suicides relate to mental health issues like depression, substance abuse, and psychosis. But the causes are complex. Those struggling deserve support [1]. These alarming statistics underscore the human loss and suffering that suicidal behaviors induce worldwide. Clearly, there is a pressing need to earnestly seek more effective strategies for identifying those with suicidal ideation to provide life-saving prediction, prevention and intervention.\nFortunately, advancements in Machine Learning (ML) and Deep Learning (DL) are illuminating a promising path forward, offering technological innovations that could drastically further suicide prevention efforts [3], [4]. The potential of machine learning for suicide prevention is significant, but practical application faces hurdles regarding transparency, ethics, and data quality for which further research is needed [5]. At the core is the ongoing amassment of vast digital traces as we communicate, browse, share, and express ourselves through online conduct. Analyses of resulting \"big data\" repositories using sophisticated analytical techniques promise to usher impactful progress in decoding and responding to human behaviors and states of mind [6]. Specifically, by applying ML and DL tools to mine social media communications, the recognition of linguistic patterns and semantic complexities associated with suicidal ideation can be realized to an unprecedented degree [7], [8]. Essential human expressions conveyed through unstructured text data can now be computationally elucidated to discern what once remained invisible. This paper aims to comprehensively review the detection of suicidal ideation on social media, focusing on the roles and advancements of machine learning (ML), deep learning (DL), and natural language processing (NLP).\nMachine learning, deep learning, and natural language processing are being applied to detect signs of suicidal ideation in social media posts. These technologies can analyze large volumes of unstructured text data to identify linguistic patterns, keywords, phrases, tones, and contextual cues associated with suicidal thoughts. While traditional ML techniques like SVMs and Random Forests can learn predictive rules, they are limited in understanding nuanced semantics and emotions. However, deep learning methods like CNNs and LSTM neural networks, which model complex data patterns, show promise for interpreting broader concepts and context to represent the intricacies of human experience [9], [10], [11]. Though still imperfect, deep learning's ability to comprehend subtext and vulnerability in language offers hope for identifying cries for help and risk factors in a more meaningful way. Advanced NLP and deep learning may enable breakthroughs in computationally decoding the complexities of human expression to uncover suicidal warning signs in text."}, {"title": "II. PREVIOUS WORKS", "content": "The detection and analysis of suicidal ideation through social media have gained increasing attention in the field of mental health research. This section provides an overview of the existing literature, outlining the evolution of methodologies and the various approaches used in the detection of suicidal ideation.\nIn embarking on an analysis of recent studies focused on the detection of suicidal ideation through social media using machine learning (ML), deep learning (DL) and Natural Language Processing (NLP) techniques, we delve into a domain of computational psychiatry that has shown both promising advancements and encountered significant challenges. This analysis will synthesize key findings from various research efforts, evaluating their methodologies, effectiveness, and broader implications within the public health context.\nThe growing prevalence of mental health issues, particularly suicidal ideation, and its manifestation on social media platforms, presents an urgent need for innovative monitoring and intervention strategies. Studies such as those conducted by Samer Muthana et al. [30], Arunima Roy et al. [31], and Swati Jain et al. [32], have explored the utilization of platforms like Twitter, employing techniques ranging from sentiment analysis to complex neural network architectures.\nThese studies highlight the potential of ML and DL in deciphering the nuanced language of distress and suicidal thoughts expressed in social media posts."}, {"title": "III. EARLY STYLES AND EVOLUTION", "content": "Initial research in the field of suicidal ideation detection was primarily focused on traditional psychological assessments and face-to-face interactions. However, the emergence of social media as a pervasive communication medium opened a new avenue for mental health research. Early studies in this domain utilized basic text analysis techniques, relying on keyword searches and simple statistical methods to identify posts indicative of suicidal thoughts. These methods, though pioneering, were limited in their ability to understand the complexities of human language and context."}, {"title": "A. Advancement in Machine Learning (ML)", "content": "The introduction of machine learning algorithms marked a significant advancement in this field. Machine learning, particularly supervised learning techniques, began to be used to identify patterns and features in social media posts that were indicative of suicidal ideation. These approaches involved training models on annotated datasets where posts were labeled as showing signs of suicidal ideation or not. Commonly used machine learning algorithms in this context included Support Vector Machines (SVM), Decision Trees, and Naive Bayes classifiers.\nOne of the key challenges in applying machine learning was the need for large, annotated datasets. The creation of such datasets involved manually labeling social media posts, a process that was both time-consuming and subject to human error and bias. Despite these challenges, machine learning algorithms proved to be significantly more effective than earlier methods, as they could capture a wider range of linguistic and semantic features."}, {"title": "B. The Role of Natural Language Processing (NLP)", "content": "Natural language processing (NLP) emerged as a critical tool in enhancing the effectiveness of machine learning models. NLP techniques allowed for more sophisticated analysis of text data, enabling the extraction of features such as sentiment, thematic elements, and linguistic structures. The use of NLP in conjunction with machine learning algorithms led to more nuanced and accurate detection of suicidal ideation. Techniques such as tokenization, stemming, and lemmatization were employed to preprocess the data, making it more amenable for machine learning models. Sentiment analysis, a subset of NLP, was particularly useful in identifying the emotional tone of posts, which is a crucial aspect in detecting suicidal ideation."}, {"title": "C. The New Frontier of Deep Learning (DL)", "content": "The advent of deep learning brought about a paradigm shift in the detection of suicidal ideation on social media. Deep learning models, particularly neural networks, were capable of modeling complex patterns in large datasets. Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs), including their variants like Long Short-Term Memory (LSTM) networks, started being used extensively. These models excelled at understanding the contextual nuances and varied expressions of language, making them particularly effective for this task.\nDeep learning models were trained on vast amounts of unstructured social media data, learning to identify subtle patterns and linguistic cues associated with suicidal ideation. These models outperformed traditional machine learning algorithms in many aspects, particularly in their ability to understand the context and semantic meaning of text. The application of deep learning, however, required substantial computational resources and large, well-annotated datasets."}, {"title": "D. Integration of ML, DL and NLP", "content": "The integration of machine learning, deep learning, and NLP represents the current state-of-the-art in suicidal ideation detection on social media. This integrated approach leverages the strengths of each of these technologies, offering a more robust and accurate detection mechanism. Machine learning algorithms provide the basis for pattern recognition, deep learning models add an understanding of contextual and semantic nuances, and NLP techniques enable the effective processing and analysis of textual data."}, {"title": "E. Challenges and Ethical Considerations", "content": "Despite the advancements in technology, there are significant challenges in this field. The ethical considerations of privacy and consent are paramount. The use of social media data for mental health research raises questions about the privacy of individuals and the potential for misuse of sensitive information. Ensuring that research in this area is conducted with strict ethical guidelines is crucial.\nAnother challenge is the accuracy and generalizability of these models. Suicidal ideation is a complex and deeply personal phenomenon, and its expression can vary greatly among individuals. Models trained on specific datasets may not generalize well to broader populations. Additionally, the risk of false positives and false negatives in detection is a concern, as it can have serious implications for the individuals involved.\nThe literature in the field of suicidal ideation detection on social media using machine learning, deep learning, and NLP indicates a rapidly evolving landscape. From basic text analysis to sophisticated deep learning models, the methodologies have advanced significantly. The integration of these technologies offers promising avenues for early detection and intervention in mental health crises. However, the challenges of data privacy, ethical considerations, and the need for accurate, generalizable models remain areas that require ongoing research and attention."}, {"title": "F. Commonly Followed Methods", "content": "This section outlines the methodologies and techniques employed in the detection of suicidal ideation on social media, focusing on dataset collection, preprocessing, feature extraction, and the application of machine learning, deep learning, and NLP models.\nFollowing taxonomy represents various approaches and tools used in the studies. Each method or technique is nested within its broader category, illustrating the hierarchical relationship between them:"}, {"title": "1) Dataset collection", "content": "One of the initial steps in studying suicidal ideation using social media data is the collection of relevant datasets. This process involves selecting social media platforms (such as Twitter, Facebook, Reddit, etc.) and extracting posts that potentially indicate suicidal thoughts or behaviors. The selection criteria for these posts often involve keyword searches, using terms commonly associated with suicidal ideation.\nThe complexity of dataset collection is amplified by ethical considerations, such as the privacy and consent of social media users. Researchers must navigate these challenges while ensuring that the data is representative and unbiased. Additionally, the dynamic nature of social media, where content is continually created and modified, poses a challenge in creating stable and reliable datasets."}, {"title": "2) Preprocessing", "content": "Once the datasets are collected, the next crucial step is preprocessing. This stage involves cleaning and preparing the data for analysis, which is pivotal in NLP and machine learning applications."}, {"title": "3) Some Common Techniques for Suicidal Ideation Detection", "content": ""}, {"title": "a) Lexicon based emotion analysis", "content": "i) NRC Affect Intensity Lexicon: The NRC Affect Intensity Lexicon is a lexicon that provides real-valued scores of affect intensity for a large set of English words. It's an extension of the NRC Emotion Lexicon and was developed by Saif M. Mohammad, a senior research officer at the National Research Council Canada [46]. The lexicon aims to quantify the intensity of the affect (emotion) evoked by a word. Each word in the lexicon is associated with an affect intensity score for each of eight basic emotions: anger, fear, anticipation, trust, surprise, sadness, joy, and disgust. The score ranges from 0 (no association with the emotion) to 1 (strong association).\nii) SentiStrength: SentiStrength is a sentiment analysis tool designed to decipher the sentiment strength of texts, particularly short informal text found on social media platforms. It is based on a lexicon approach, which means it relies on a dictionary of sentiment-related words, each tagged with sentiment strength scores [48]. SentiStrength can be fine-tuned for specific domains (e.g., software engineering) [49] by adjusting its dictionary to include jargon and terminologies unique to those fields. It can also be adapted to different contexts and languages, recognizing that sentiment expression varies greatly across cultural and linguistic landscapes. It is used to gauge public sentiment on various topics by analysing social media posts on platforms like Twitter and YouTube. Governments and organizations use it to understand public opinion on policies, products, or events. SentiStrength struggles with posts that contain images [50], as its lexical approach does not account for visual sentiment indicators. Like many sentiment analysis tools, SentiStrength may not accurately interpret sarcasm and irony, which are prevalent in social media text. The rapid evolution of online language can outpace the tool's dictionary updates, potentially leading to inaccurate sentiment scores.\nSentiStrength stands out for its ability to decipher sentiment in informal, web-based text, making it a valuable tool for researchers and organizations looking to tap into public sentiment.\nThe heart of suicidal ideation detection lies in the application of machine learning and deep learning models. These models are trained on preprocessed and feature-extracted data to classify social media posts as indicative of suicidal ideation or not."}, {"title": "b) Supervised machine learning models", "content": "i) Support Vector Machines (SVM): Support Vector Machine (SVM) is a robust and versatile supervised machine learning algorithm widely used for classification and regression tasks [51], but primarily known for its applications in classification. The core idea behind SVM is to find the optimal hyperplane that maximizes the margin between different classes in the feature space. For a linear SVM (the simplest form) [52], the decision boundary is a hyperplane, and the goal is to find the hyperplane that leaves the maximum margin from the nearest points of all classes, which are known as support vectors. Mathematically, this can be represented by the equation of the hyperplane:\n$w.x - b = 0$   (1)\nwhere w is the weight vector perpendicular to the hyperplane, x represents the input features, and b is the bias term. In more complex scenarios, where classes are not linearly separable, SVM uses kernel functions to transform the input space into a higher-dimensional space [53] where a hyperplane can effectively segregate the classes. This is known as the Kernel trick, allowing SVM to perform non-linear classification.\nSVM's strength lies in its versatility and efficiency, particularly in high-dimensional spaces. It's relatively memory efficient as it uses a subset of training points in the decision function (the support vectors), making it both powerful and efficient. The optimization of SVM involves finding the right balance between increasing the margin size and minimizing classification error, controlled by a regularization parameter. Support Vector Machine (SVM) is adept at detecting suicidal ideation from social media data, largely due to its proficiency in managing high-dimensional spaces [53]. By employing techniques like TF-IDF for feature extraction, SVM transforms complex and nuanced social media text into a structured format. It then identifies an optimal hyperplane to differentiate between posts that indicate suicidal ideation and those that don't, maximizing the margin between these categories using key data points, known as support vectors. This approach is particularly effective due to the subtle linguistic cues and contextual nuances present in social media content, though its success is contingent on precise data preprocessing and feature selection to capture the complexities of emotional expressions online.\nii) Decision tree: A Decision Tree is a widely used non- parametric supervised learning algorithm used for classification and regression tasks [54]. It models decisions and their possible consequences as a tree-like structure, where each internal node represents a \"test\" on an attribute, each branch represents the outcome of the test, and each leaf node represents a class label (decision taken after computing all attributes). The paths from root to leaf represent classification rules. In building the decision tree, algorithms like ID3, C4.5, or CART [54] are used to determine how to split the data and construct the tree. These algorithms typically employ measures such as Gini impurity or entropy to choose which feature to split at each step. The Gini impurity for a set is given by:\nGini Impurity = $1 \u2013 \u03a3_{i=1}^{k} Pi^{2}$   (2)\nWhere p\u2081 is the probability of an object being classified to a particular class. Alternatively, entropy, a measure of disorder or impurity, is given by:\nEntropy = $\u03a3_{i=1}^{k} Pi log2(Pi)$   (3)\nIn the context of detecting suicidal ideation from social media text data, a Decision Tree algorithm works by learning from the features extracted from the text (such as specific keywords, phrases, sentiment scores, or linguistic patterns) and creating a model that can classify new texts based on these learned patterns [38]. Each node in the tree represents a feature, and the branches represent the decision rules leading to the final classification in the leaf nodes. This approach is particularly suitable for such tasks due to its interpretability; the tree structure allows for easy understanding and tracing of the decision path and reasoning [19]. This transparency is crucial in sensitive applications like mental health monitoring, where understanding the rationale behind a classification (such as why a particular post is flagged as indicative of suicidal ideation) is as important as the classification itself.\niii) Random forest: Random Forest is a machine learning technique for classification, regression, and other tasks that operates by constructing a multitude of decision trees at training time and outputting the mode of the classes or mean prediction of the individual trees [55]. It builds upon the concept of bagging, an approach that improves the stability and accuracy of machine learning algorithms by combining multiple models to 'vote' on the final output [56]. Each tree in a Random Forest makes a class prediction, and the class with the most votes becomes the model's overall prediction. The algorithm injects randomness into the model building process, which not only helps in reducing the variance of the model but also prevents overfitting. This is done by randomly selecting subsets of the training data set (with replacement) and subsets of the features used for splitting nodes. The decision tree equation typically involves measures like Gini impurity or entropy [57] to find the best split at each node:\nGini Impurity = $1 \u2212 \u2211(pi)\u00b2$   (4)\nEntropy = - $\u2211pilog2(pi)$   (5)\nWhere pi is the proportion of samples that belong to a certain class in a given node.\nIn the context of suicidal ideation detection from social media text data, Random Forest can be highly effective [7]. It starts with preprocessing and transforming textual data into a numerical format, typically using vectorization methods such as TF-IDF or word embeddings. Each decision tree in the Random Forest then learns from a random subset of these features, creating a diverse set of perspectives for interpreting the data. When new data is inputted, each tree makes a prediction based on its learned patterns, and the final output is decided by a majority vote across all trees. This methodology is particularly suitable for analyzing social media content, as it accommodates the high variability and noise often found in this type of data. The ensemble nature of Random Forest also helps in capturing a wide array of linguistic and contextual indicators associated with suicidal ideation, making it a robust tool for mental health monitoring in digital platforms [16], [17].\niv) Logistic regression: Logistic Regression is a statistical method used for binary classification problems, which models the probability of a binary response based on one or more predictor variables [58]. It operates under the principle that the log odds of the probability of an event occurring versus it not occurring is linearly related to the independent variables [59]. This relationship is expressed through the logistic function:\nlog$\\frac{p}{(1-p)}$  =  $\\beta_0 + \\beta_1X_1 + \\beta_2X_2 + \\dots + \\beta_nX_n$   (6)\nHere, p is the probability of the dependent event occurring, Bo is the intercept, B1, B2, ..., \u1e9en) are the regression coefficients, and X1, X2, ..., Xn are the independent variables. The output is then transformed using the logistic function (or sigmoid function), ensuring that the output always lies between 0 and 1, making it interpretable as a probability:\np = $\\frac{1}{1+e^{-(Bo+B1X1+B2X2+\\dots+\\beta_nXn)}}$  (7)\nIn utilizing Logistic Regression for identifying suicidal ideation within social media text, a nuanced approach is adopted to process and analyze the content [32]. Initially, the textual data undergoes preprocessing to extract meaningful attributes, which might include the frequency of emotive words, the structure of sentences, or the usage of certain language patterns associated with mental health indicators. Logistic Regression then applies its algorithm to these extracted features, determining the likelihood of a post reflecting suicidal thoughts. The output, given as a probability, offers a graded scale of risk assessment rather than a binary classification, providing a more refined analysis. This method stands out for its straightforward interpretability, essential for mental health monitoring, where understanding the reasoning behind a prediction is crucial. However, the model's effectiveness hinges on the relevance and quality of the features selected, necessitating careful curation to avoid biases or misinterpretations [15], [32]. Such an approach allows Logistic Regression to be a potent tool in the sensitive area of mental health surveillance on digital platforms.\nv) KNN: K-Nearest Neighbors (KNN) is a simple, yet versatile supervised learning algorithm used for both classification and regression tasks, but it's most utilized for classification [60]. KNN operates on the principle that similar things exist in proximity; in other words, it assumes that similar data points are near to each other. The algorithm doesn't explicitly learn a model; instead, it classifies a new data point based on the majority vote of its 'K' nearest neighbors. The number of neighbors, K, is a critical user-defined parameter, and the distance between data points is calculated using metrics like Euclidean distance, Manhattan distance, or Hamming distance [61]. The Euclidean distance between two points in a plane is given by [62]:\nd(p,q) = $\\sqrt{(q_1-p_1)^2 + (q_2 - P_2)^2 + \\dots + (q_n - p_n)^2}$   (8)\nIn suicidal ideation detection from social media text using K-Nearest Neighbors (KNN), the algorithm classifies new posts based on linguistic and emotional similarities with existing posts [18]. After transforming text data into numerical features, KNN identifies the 'K' closest posts in this feature space, determining the new post's category based on the prevalence of categories (indicative of suicidal ideation or not) among these nearest neighbors. This method effectively captures subtle patterns in personal expression [41], with the choice of 'K' and the nature of features used being crucial for accuracy. The model's reliance on direct comparisons with known cases makes it uniquely suited for discerning nuanced expressions of mental states in social media, provided the training data is diverse and representative.\nvi) Na\u00efve bayes classifiers: Na\u00efve Bayes is a probabilistic machine learning model based on applying Bayes' Theorem with the assumption of independence among predictors [63]. It's particularly popular for text classification tasks due to its simplicity and effectiveness, even with high-dimensional data. The fundamental equation is Bayes' Theorem [64]:\nP(A/B) = $\\frac{P(B/A)P(A)}{P(B)}$  (9)\nIn this context, A and B represent different events, where P(A/B) is the probability of A given B, P(B/A) is the probability of B given A, P(A) and P(B) are the probabilities of observing A and B independently of each other.\nFor suicidal ideation detection in social media texts, Naive Bayes works by first transforming text data into a feature vector (often using techniques like bag-of-words or TF-IDF). Each word or phrase in the text contributes independently to the probability that the message reflects suicidal ideation. The model then uses these probabilities, derived from the training data, to predict whether new texts suggest suicidal thoughts [15], [20]. This method's efficiency in handling large volumes of text and its ability to quickly classify new data make it suitable for real-time monitoring of social media platforms. However, the assumption of independence among words can sometimes oversimplify the linguistic complexities of human communication, particularly in the nuanced context of mental health discussions. Despite this, Naive Bayes remains a popular choice due to its ease of implementation and its proficiency in processing and classifying large datasets efficiently."}, {"title": "c) Unsupervised machine learning models", "content": "i) K-Means Clustering: K-Means Clustering is an unsupervised learning algorithm that partitions a dataset into k clusters by minimizing the intra-cluster variance [65]. It does so by iteratively assigning data points to the nearest cluster centroid and updating the centroid to the mean of the points in the cluster. The algorithm's objective is to minimize the sum of squared distances between points and their respective cluster centroids, expressed as:\nJ = $\\sum_{j=1}^{k} \\sum_{i=1}^{n^{(j)}}||x_i \u2212 c_j ||^2$  (10)\nHere,  ||x\u2081) \u2013 cj||\u00b2is the Euclidean distance between a data point x and the cluster centroid cj, n is the number of data points in cluster j, and k is the number of clusters.\nFor suicidal ideation detection in social media text, K- Means can group posts into clusters based on textual similarities, using features like TF-IDF vectors. These clusters can then be analyzed to identify common themes or expressions indicative of suicidal thoughts [19]. This clustering approach helps in organizing large, unlabeled datasets into meaningful categories, facilitating the identification of mental health concerns. However, the effectiveness of K-Means in this context heavily relies on the choice of k and the initial centroid selection, alongside robust preprocessing of the text data.\nii) Latent Dirichlet Allocation (LDA): Latent Dirichlet Allocation (LDA) is a popular unsupervised learning algorithm in natural language processing, primarily used for topic modeling [66]. It assumes that documents are mixtures of topics and that topics are mixtures of words. This generative model allows it to discover hidden thematic structures in large collections of text documents. LDA represents each document as a distribution over topics and each topic as a distribution over words.\nFor detecting suicidal ideation in social media texts, LDA helps identify topics that may signify mental distress. It processes text data to extract latent topics, potentially flagging those aligned with suicidal thoughts. This method is valuable for exploratory analysis, identifying linguistic patterns related to mental health [19], [43]. However, the effectiveness of LDA depends on accurate text preprocessing and parameter tuning, requiring careful interpretation in the sensitive context of mental health monitoring."}, {"title": "d) Deep learning models", "content": "i) Artificial Neural Networks (ANN): Artificial Neural Networks (ANNs) are computational models inspired by the human brain's structure and function, particularly effective in pattern recognition and predictive modeling [67]. An ANN consists of layers of interconnected nodes or neurons, each node in one layer connected to several others in the next layer. The basic operation in a neuron involves weighted input summation and a non-linear activation function [68]. Mathematically, the output y of a neuron can be described by the equation,\ny = $f(\\sum_{i=1} WiXi + b)$  (11)\nwhere xi are the inputs, w\u2081 are the weights, b is the bias, and f is the activation function, like a sigmoid or ReLU function. The network learns to model complex relationships by adjusting these weights and biases based on the input data.\nFor suicidal ideation detection from social media text, ANNs can be employed to analyze and classify text data [23]. The process involves preprocessing the text (like tokenization, stemming, and vectorization) to transform it into a format suitable for the ANN. The network then processes this data through its layers, learning to identify patterns and linguistic cues that are indicative of suicidal ideation. This might include specific keywords, phrases, or the overall sentiment of the text. The final layer of the network, typically a SoftMax layer, classifies the text based on the learned patterns, indicating whether it likely contains suicidal ideation. The performance of ANNs in this application largely depends on the network's depth and complexity, the quality of the training data, and the model's capacity to capture subtle nuances in the language that may suggest suicidal thoughts or tendencies.\nii) Convolutional Neural Networks (CNN): CNN, or Convolutional Neural Networks, are a class of deep neural networks commonly used in image processing [69] but also effective in text classification [70], particularly for feature extraction [71]. CNNs are particularly effective due to their ability to learn spatial hierarchies of features through the use of convolutional layers. A basic CNN structure includes an input layer, convolutional layers, pooling layers, fully connected layers, and an output layer [72]. The convolutional layers apply a convolution operation to the input, passing the result to the next layer. This can be represented by the equation:\nOutput = Activation(Weights.Input + Bias) (12)\nwhere Activation is a non-linear function like ReLU. Pooling layers reduce the spatial size of the convolved features to decrease the computational power required. Finally, fully connected layers combine these features to classify the input into various categories.\nFor suicidal ideation detection from social media text, CNNs can be utilized to analyze and classify textual data [27]. The process begins with the collection and preprocessing of social media texts, which involves cleaning, normalization, and tokenization to convert text into a form that can be fed into a CNN. CNN then learns to identify patterns and features in the text indicative of suicidal ideation, such as specific keywords, phrases, or linguistic patterns. This involves multiple layers of convolution and pooling to extract and condense the relevant features from the text data. The fully connected layers at the end of the CNN then interpret these features to classify the text, often outputting a probability score indicating the likelihood of suicidal ideation present in the text. The effectiveness of this approach relies on the quality and diversity of the training data, as well as the complexity and depth of the CNN model used.\niii) Recurrent Neural Networks (RNN): Recurrent Neural Networks (RNNs) are a type of neural network particularly suited for processing sequential data, such as time series or text [73]. Unlike traditional neural networks, RNNs have a unique feature: they maintain a form of memory by using their output as input for the subsequent step. This is achieved through loops within the network [74]. In mathematical terms, the hidden state ht at time t in a simple RNN is calculated as\nht = activation(Whhht-1 + Wxhxt + bh)  (13)\nwhere Whh and Wxh are weight matrices, xt is the input at time t, ht-1 is the previous hidden state, and by is the bias. The output yt is then a function of the current hidden state: yt = activation(Whyht + by with Why being the output layer weights and by the output bias.\nFor suicidal ideation detection in social media text, RNNS are particularly effective due to their ability to process and learn from the sequential nature of language. The process starts with preprocessing the text data, including tokenization and possibly embedding the words into a vector space [8]. The RNN then processes this sequential data, with each word (or token) being input sequentially. The RNN's hidden state updates with each word, effectively allowing the network to remember and utilize the context from previous words. This context understanding is crucial for identifying patterns or linguistic cues indicative of suicidal ideation, such as expressions of despair, hopelessness, or direct mentions of self- harm. The final output layer of the RNN can classify the text based on the learned patterns, potentially indicating whether the text suggests suicidal ideation. The performance of RNNS in this application hinges on the depth of the network, the quality of the training data, and the network's ability to capture and utilize long-term dependencies in the text.\niv) Long Short-Term Memory (LSTM) and Bidirectional LSTM (BiLSTM): Long Short-Term Memory (LSTM) networks are an advanced type of Recurrent Neural Network (RNN) designed to better capture long-range dependencies and address the vanishing gradient problem common in standard RNNs [75]. The key to LSTM's effectiveness is its unique cell structure comprising three gates: the input gate it, the forget gate ft, and the output gate ot. These gates collectively decide what information to retain or discard as the network processes data sequentially. The LSTM cell updates are governed by the following equations:\nft = \u03c3(Wf. [ht-1,xt] + bf), (Forget Gate  (14)\nit = \u03c3(Wi. [ht\u22121, xt] + bi), (Input Gate)  (15)\nCt = tanh(Wc. [ht\u22121, xt] + bc), (Cell State Candidate)  (16)\nCt = ft * Ct-1 + it * Ct, (Cell State Update)  (17)\nOt = \u03c3(Wo. [ht\u22121, xt] + bo), (Output Gate)  (18)\nht = ot * tanh(Ct), (Hidden State)  (19)\nA Bidirectional LSTM (BiLSTM) extends the standard LSTM by introducing a second layer that processes data in the reverse order [76]. While a regular LSTM processes data from past to future (left to right in a sequence), a BiLSTM also processes data from future to past (right to left), effectively capturing information from both directions. This dual processing makes BiLSTMs particularly effective in applications where the context of the entire sequence is crucial for understanding each part of it.\nIn the context of suicidal ideation detection from social media text, LSTMs excel due to their ability to capture and remember pertinent information across long text sequences [8], [28], which is crucial in understanding the context and nuances of language. By processing sequential data, LSTMs can identify patterns or phrases indicative of suicidal thoughts, such as expressions of hopelessness or mentions of self-harm. In suicidal ideation detection, a BiLSTM would analyze the text from both directions [45], offering a more comprehensive understanding of the context and sentiment expressed, thus potentially improving the accuracy of detecting signs of suicidal ideation.\nv) Transformer models: Transformer-based models have revolutionized natural language processing by offering a more efficient and effective means of handling sequential data compared to traditional RNNs or LSTMs. The core concept of Transformers is the self-attention mechanism, which computes the output of a layer by attending to all positions within the same layer [77]. The basic equation for self-attention can be written as:\nAttention(Q, K, V) = softmax $(\\frac{QK}{\\sqrt{d_k}})$V  (20)\nwhere Q, K, and V are queries, keys, and values matrices, respectively, and dk is the dimensionality of the keys. This mechanism allows the model to weigh the importance of different parts of the input sequence differently, making it highly effective for tasks involving contextual understanding.\nDifferent transformer-based models have emerged, each with unique characteristics [78]:"}, {"title": "IV. CONCLUSION", "content": "Social media has become a valuable data source for detecting mental health conditions, such as suicidal ideation. This review synthesizes current research utilizing machine learning, deep learning, and NLP techniques to identify warning signs in social media posts. The study highlights the advancement of AI in suicide prevention, showcasing models that leverage deep neural networks and transfer learning to decipher complex linguistic patterns indicative of suicidal thoughts. Key findings demonstrate precision rates of 82-97% and recall rates of 71-94% using models such as SVMs, Random Forests, and neural networks. Despite promising results, model robustness must be improved for real-world application.\nChallenges include limited, non-representative datasets that hinder generalizability and may introduce demographic biases. Most models were developed using English data from American users, lacking validation across cultures, languages, and demographics. Achieving a balance between accuracy, complexity, and interpretability remains difficult, with simpler models underperforming and complex models being opaque. Future work should focus on testing across age groups and integrating additional risk indicators, alongside addressing privacy concerns and ensuring ethical data use.\nDifferentiating genuine suicidal intent from rhetorical expressions is an ongoing challenge, as individuals communicate distress uniquely, influenced by personal and cultural factors. Addressing these nuances requires further qualitative research and interdisciplinary collaboration for"}]}