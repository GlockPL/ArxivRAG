{"title": "Harnessing Large Vision and Language Models in Agriculture: A Review", "authors": ["Hongyan Zhu", "Shuai Qin", "Min Su", "Chengzhi Lin", "Anjie Li", "Junfeng Gao"], "abstract": "Large models can play important roles in many domains. Agriculture is another key factor affecting the lives of people around the world. It provides food, fabric, and coal for humanity. However, facing many challenges such as pests and diseases, soil degradation, global warming, and food security, how to steadily increase the yield in the agricultural sector is a problem that humans still need to solve. Large models can help farmers improve production efficiency and harvest by detecting a series of agricultural production tasks such as pests and diseases, soil quality, and seed quality. It can also help farmers make wise decisions through a variety of information, such as images, text, etc. Herein, we delve into the potential applications of large models in agriculture, from large language model (LLM) and large vision model (LVM) to large vision-language models (LVLM). After gaining a deeper understanding of multimodal large language models (MLLM), it can be recognized that problems such as agricultural image processing, agricultural question answering systems, and agricultural machine automation can all be solved by large models. Large models have great potential in the field of agriculture. We outline the current applications of agricultural large models, and aims to emphasize the importance of large models in the domain of agriculture. In the end, we envisage a future in which famers use MLLM to accomplish many tasks in agriculture, which can greatly improve agricultural production efficiency and yield.", "sections": [{"title": "1. Introduction", "content": ""}, {"title": "1.1. The challenges facing the agricultural domain", "content": "The significance of agriculture in the global economy is increasing steadily, and there is growing awareness regarding its sustainability. Ahirwar et al. believe that it is necessary to increase global agricultural food production by a minimum of 70% to meet the needs of the increasing world population [1]. Unfortunately, there are many factors in agriculture that make it difficult to steadily increase grain production, including 1) crop diseases caused by pathogens such as bacteria, fungi, and viruses; 2) unscreened low-quality seeds lead to unhealthy crop growth, decreased yield, and susceptibility to crop diseases; 3) many agricultural tasks are inefficient, including weeding, planting, watering, and harvesting crops. Agricultural production is facing enormous economic and production losses. For crop diseases, traditional detection methods like polymerase chain reactions on the basis of unique deoxyribonucleic acid sequences of pathogens, enzyme-linked immunosorbent assays on the basis of pathogens proteins and hyperspectral"}, {"title": null, "content": "imaging, are constrained by their operational complexity and the requirement for bulky instruments [2]. For selecting high-quality seeds, quality assurance programs employ various ways to attest seed quality attributes, including germination and vigour tests [3]. But these methods have limitations in terms of time overhead, subjectivity, and the destructive nature of assessing seed quality [4]. For a general tasks in agriculture, the use of pesticides for weed control may have negative impacts on the environment, and Phytotoxicity reactions can lead to diminished crop quality and reduced yields [5]. And the traditional solutions to these tasks are also inefficient due to these manned implements are dreadfully slow. Therefore, it is necessary to develop a method that is fast, simple, and easy for people engaged in agricultural work to use address the problems of the traditional methods mentioned above.\nOn the other hand, driven by growing health consciousness, the public has long been worried about the safety and quality of food, which is linked to agricultural products. Reducing food losses and improving food safety rely significantly on the continuous monitoring of crop quality, especially the inspection of diseases during crop growth stage [6]. As an efficient analytical means, large model, has found extensive application in the agricultural sector [7] [8] [9]. Large model has shown excellent performance in analysing agricultural data, pest and disease management, precision agriculture, and more. However, it still faces many problems such as difficulty in obtaining agricultural data [10], low model training efficiency, distribution shift[11], and plant blindness [12].\nWe aim to offer a comprehensive analysis of large model, starting with a systematic summary of the history of large model (LLM and LVM), large model in other fields, the importance of large model for agriculture. Subsequently, introduce many applications of large model in agriculture. Moreover, due to the fact that large models are a relatively new technological"}, {"title": null, "content": "means, we outline some solutions from their ethical and responsibility aspects. Finally, summarize the current challenges and future directions of large models, and draw conclusions on the effectiveness of its implementation in the agricultural domain."}, {"title": "1.2. The history of LLM and LVM", "content": "Artificial intelligence (AI), whose main purpose is to establish systems that learn and think like human [13], just like human language and visual abilities. At present, research on large models is also focused on the natural language processing (NLP) and computer vision (CV). Next, LLMs and LVMs will be introduced in detail. LLM is a model based on NLP, and we can divide the development of it into four stages:\n\u2022 Statistical language models (SLM). SLMs use traditional statistical techniques such as n-gram and some language rules to learn the probability distribution associated with words. It is generally believed that the amount of data, and the ability of a given estimation algorithm to accommodate large number of training are very significant in providing a solution that competes successfully with the entrenched n-gram language models [14]. SLMs are currently widely used in the field of NLP, such as Raychev et al. designed a simple and scalable static analysis that uses SLMs to complete incorrect code [15]. However, n-gram models have three drawbacks. Firstly, as n increases, the more parameters need to be calculated and counted, and the more memory space it occupies. Markov assumption can be used to limit the size of n [16]. Secondly, n-grams models cannot share information from vocabulary or prefixes with the same semantics. Word embedding can be used to shift character representation to vector representation [17]. Thirdly, data sparsity. Data smoothing, backoff [18] and interpolation can be used to solve this problem. In addition, neural network models can better handle the problem of data sparsity."}, {"title": null, "content": "\u2022 Neural language models (NLM). NLMs [19] [20] [21] use different types of neural networks to model language, and compared to SLMs, NLMs are more effective. To solve the problem of data sparsity in n-gram models, feedforward neural networks and recurrent neural networks (RNN) were used in continuous space language modelling, which can enable the model to automatically learn features and continuous representations. The first feedforward neural network language model (FFNNLM) was proposed by Bengio et al. in 2003, which overcomes the curse of dimensionality by learning distributed representations of a word [19]. Subsequently, Mikolov et al. suggested the RNN language model (RNNLM), which can make predictions using limited context [20]. However, during the training process of RNNLM, the gradient of parameters may disappear or explode, leading to slower training speed or infinite parameter values, making it difficult for the model to achieve long-term dependence. Sundermeyer et al. applied long short-term memory recurrent neural networks to language models in 2012 and proposed LSTM-RNNLM [21]. Three gate structures (including input, output, and forget gates) had been added to the LSTM memory unit to control information flow, which solved the problem of long-term dependence in language models learning.\n\u2022 Pre-trained language models (PLM). PLMs can be divided into two paradigms: feature-based and fine-tuning. Feature-based treats pre-training as a feature extraction process, trains model parameters on large-scale corpora, and encodes them as fixed features to downstream models for collective tasks. A typical example is ElMo, a pre-training bidirectional LSTM (BiLSTM) proposed by Peters et al. [22]. Due to LSTM modelling sentences, it can solely consider the contextual information preceding the current sentence and fails to capture subsequent contextual information. And BiLSTM uses reverse networks, which can concurrently consider contextual information before and after, thus better processing sequential data. Fine-tuning"}, {"title": null, "content": "transfers the parameters of the entire model to downstream tasks, which is the current mainstream paradigm and has better flexibility compared to feature-based. The representative models of fine-tuning are bidirectional encoder representations from transformers (BERT) [23] and generative pre-trained transformer (GPT). In 2017, Google's research team proposed Transformer [24], a model that uses self-attention mechanism, while OpenAI proposed GPT based on the architecture of Transformer. GPT achieved almost perfect training results by pre-training on large-scale text datasets and fine-tuning parameters. BERT was proposed by pre-training bidirectional language models with especially designed pre-training tasks on vast unlabelled corpora. These pre-trained context-aware word representations demonstrate high efficacy as general-purpose semantic features, significantly enhancing the performance of NLP tasks [25]. Furthermore, due to the significant acceleration of model training by Transformer, it has gradually become the fundamental architecture for LLMs.\n\u2022 Large language models (LLM). LLM is a language models that contains billions (or more) of parameters. Large models possess abilities that small models do not possess, which is known as the emergence abilities of LLMs [26]. This is also one of the most obvious distinguishing features between LLMs and PLMs. OpenAI researchers discovered that larger models will continue to exhibit better, and will also be much more sample efficient than before [27]. Many current studies have trained large-sized PLMs and found that compared to smaller PLMs, large-sized PLMs exhibit different behaviours and exhibit astonishing abilities in solving a range of complex tasks [25]. This is the emergence abilities of LLMs, as mentioned earlier. For instance, the context learning ability of GPT-3 can generate the expectant output of test examples by completing word sequences of input text, without the need for extra training or"}, {"title": null, "content": "gradient updates, which GPT-2 cannot achieve. Therefore, the research community refers to these large-sized PLMs with additional capabilities as LLMs [28] [29] [30].\nLVM is a model associated with CV. The research on vision models initially focused on shallow image feature extraction algorithms, including scale-invariant feature transform, histogram of oriented gradient, and other methods, but had significant limitations. In 2012, AlexNet [31] achieved a breakthrough success in ImageNet large scale visual recognition challenge, sparking a wave of convolutional neural networks (CNN) for vision models. With the development of deep learning, deep residual networks including VGGNet [32], GoogLeNet [33], and ResNet [34] were successively proposed, which improved the performance of image classification, object detection, semantic segmentation, etc. The boom of the Internet also enabled large-scale image datasets to be used for training vision models. Faster R-CNN [35], YOLO [36], Mask R-CNN [37] emerged one after another. In recent years, Transformer has been applied in the domain of LVM, and vision transformer (ViT) [38] and DALL-E [39] have appeared in front of the public. These models use self-attention mechanism, combined with generative adversarial network, to demonstrate strong capabilities in image classification and generation tasks.\nIn addition to the LLM and LVM introduced above, multimodal large language models (MLLM) are also a research focus in the domain of AI. LLMs perform well in text-based tasks, but they are hard to understand and handle other data types. LVMs perform well in the field of CV, but there is limited information on the analysis results, which has certain limitations for users. MLLMs [40] integrate multiple data types, such as images, text, language, audio, and more. It not only possesses the advantages of LLMs and LVMs, but also address the limitations of LLMs and LVMs by integrating multiple modalities, enabling a more comprehensive understanding of"}, {"title": null, "content": "various data. It can be said that the developments in MLLMs have set up new avenues for AI, which make binary machines to understand and then process various data types [40]."}, {"title": "1.3. The current developed large models", "content": "Currently, many industry professionals have found that large models can bring breakthroughs to their industries. In order to create a large model that is suitable for the industry and can complete some professional tasks (Table 1), different industries have begun to consider invested manpower, material resources, and financial resources in succession."}, {"title": "1.4. The current large models in other domains", "content": "As shown in Table 1, the current large models are mainly LLMs and MLLMs, with LVMs accounting for a minority. Many LLMs are designed to develop chatbots (BLOOM [41], PaLM2 [42], ERNIE Bot) or complete NLP tasks, including text classification, machine translation, and sentiment analysis (OPT [43]). Some researchers are not satisfied with NLP tasks, so they have added visual ability to enable the model to answer questions based on images (Minipt-4 [44]), this type of model can be called large vision-language model (LVLM).\nAlthough LVLM satisfies some functions and takes large models a big step towards artificial general intelligence (AGI), it is not enough to achieve the goal that machines can emulate human thinking and carry out a wide range of general tasks through transfer learning and diverse other modalities without achieving the multimodality of the model [45]. Some large models have implemented multimodality, enabling them to analyze different types of information (GPT-4 [46], LLaMA [47], Gemini [48], ImageBind [49]) and interact with users."}, {"title": "1.5. The importance of large models in the agricultural domain", "content": "In the past few decades, the advancement of agricultural technology has significantly improved global agricultural production efficiency. According to the forecast released by the food and agriculture organization (FAO) of the United Nations, the global grain production in 2023 was 2.84 billion tons, nearly twice that of the early 20th century. Although global agricultural production efficiency is high, the world population is also constantly growing. Continuously"}, {"title": null, "content": "improving agricultural production efficiency is the lifeline of economic development and the foundation for ensuring human food, clothing, and survival needs. Hence, how to make agricultural practices advance is a crucial issue. Currently, many challenges faced by agriculture can be addressed using large models:\n\u2022 Crop pests and diseases are one of the major problems in agricultural production. Most farmers blindly spray pesticides to control the occurrence of diseases and pests, which has caused many problems including environmental pollution and food safety [65]. The traditional identification of crop pests and diseases primarily relies on the expertise and experience of farmers and agricultural experts. Although these experiences are reliable, it is inevitable that misjudgements may occur. Moreover, some large plantations have more crops, requiring more manpower and time, making it easy to miss the appropriate time to rescue diseased crops. The use of large models can lower the threshold for detecting pests and diseases, and greatly improve the efficiency of identification. For example, farmers can use a large model targeting diseases and pests, take photos of crops suspected of having diseases, and upload them to the large model, which will analyse the results of pests and diseases.\n\u2022 Weeding issues. Weeds are analogous in colour to crops, and their growth also needs sunlight and water. This leads to weeds and crops competing for survival space and nutrients. Excessive weed density in the field can significantly impact the yield and quality of crops. Hence, weeding is an inevitable and vital link in agricultural yield. Farmers can use agricultural robots embedded in large models to identify and trim weeds [51].\n\u2022 The quality of seeds determines the survival rate and yield of crops. When high vitality seeds are planted in the field, due to their strong stress resistance, they have a high germination rate, fast and neat emergence, and can produce high-yield and high-quality crops. Seeds with low"}, {"title": null, "content": "\u2022 vitality exhibit weak stress resistance and are prone to rot and die, ultimately leading to a decrease in crop yield. Using large models to accurately identify high vitality seeds can greatly improve crop yield and quality.\nIn addition to identifying seed quality, grading mature crops is also important. It involves strict screening of crops before entering the market, removing decaying crops, and classifying them based on their quality. Large models can detect crop photos and efficiently grade crops, greatly reducing the time required for crops to enter the market stage."}, {"title": "2. Large Language Models in Agricultural Applications", "content": "Numerous agricultural tasks require intricate reasoning. For example, when presented with an image of a soybean field, agricultural scientists or farmers rely on large models to undertake several key steps. Firstly, the large model must identify any abnormal symptoms evident in the soybean leaves, such as water stains. Subsequently, it must ascertain the name of the specific problem that troubles plants, such as bacterial wilt disease. Next, the model needs to determine the underlying cause of the disease, such as pseudorabies. Finally, it must develop an appropriate treatment strategy, such as applying a bactericide spray.\nMany question answering (QA) and dialogue systems are designed to address this type of reasoning problem [66] [67] [68]. For instance, a chatbot based on a RNN is specifically designed to handle questions related to soil testing, plant protection, and nutrient management [66]. Although, these QA and dialogue systems and chatbots are capable of answering most inquiries without the need for human interaction and with excellent accuracy, they have limited capabilities for complex problems by reason of their small model size as well as of inadequate training data. Therefore, the agricultural domain requires large models to promote the development of QA and dialogue systems and chatbots."}, {"title": "2.1. The role of LLM in processing and generating agricultural data, providing insights and decision-making support", "content": "LLM can play many roles in the agricultural domain, such as processing and generating agricultural data, providing insights into agricultural production work, and supporting agricultural decision-making for farmers."}, {"title": "2.1.1. LLMs processing and generating agricultural data", "content": "Information extraction. LLMs can extract structured information from unstructured agricultural text data. First, the text is divided into individual tokens and LLMs represent each token as a numerical vector called a word embedding. Then, LLMs analyse the surrounding context of each token to understand its meaning within the sentence or document, and identify and categorize named entities within the text, like names of individuals, locations, organizations, or specific agricultural terms. Finally, LLMs employ techniques like information extraction to identify and extract structured information from unstructured text (Involve identifying relationships between entities, extracting key facts, or populating knowledge graphs). LLMs extract information from data using a process known as NLP. Peng et al. used LLM (Not related to the agricultural domain) to automatically extract entities and attributes from unlabelled agricultural data and transform them into structured data [69]. Information extraction is beneficial for LLM to better understand the overall meaning of the text.\nAgricultural data generation. Generative Al models are actually a multimodal LLMs (This content will be detailed in 4.1). An obstacle encountered when applying specialized CV algorithms to agricultural vision data is the insufficient availability of training data and labels [70] [37]. In addition, collecting data that encompasses the wide range of variations caused by season and weather changes is exceedingly challenging. Acquiring high-quality data requires a lot of time, and labelling them is even more costly [71]. To address these challenges, one approach is to fine-"}, {"title": null, "content": "tune multimodal generative LLMs on the target agricultural data domain. This allows the models to generate massive training data and labels, thereby constructing an augmented training set that closely resembles the distribution of the original data [72]. Besides, text-based generation models can generate images [73] and videos [74] of specific scenes based on text descriptions, thereby supplementing training datasets that may lack certain visual content. These models can also be employed to generate diverse variations of the initial data for some characteristics: multimodal generative LLMs can transform the time of the image from daytime to nighttime [75] or alter the weather conditions from rainy to sunny. This helps in expanding the training data and improving the performance of downstream models."}, {"title": "2.1.2. LLMs provide insights", "content": "LLMs possess the capability to analyse textual data and uncover trends in agricultural practices, market conditions, consumer preferences, and policy developments. Through analysis of agricultural text data from sources such as news articles, reports, and social media, these models can offer valuable insights into market dynamics and pricing trends [76]. This provides support for farmers to understand domains outside of agriculture. Many researchers believe that the integration of LLMs into different stages of designment and development for agricultural applications is also experiencing a noticeable rise [8] [77]. In [8] study, Stella et al. incorporated LLM into the design phase of robotic systems. They specifically focused on designing an optimized robotic gripper for tomato picking and outlined the step-by-step process. In the initial ideation phase, they leveraged LLMs like ChatGPT [46] to gain insights into the possible challenges and opportunities associated with the task. Building upon this knowledge, they identified the most promising and captivating pathways, engaging in ongoing discussions with the LLM to refine and narrow down the design possibilities. Throughout this process, the human"}, {"title": null, "content": "collaborator harnesses the expansive knowledge of the LLM to tap into insights transcend their individual expertise. In the following stage of the design process, which emphasizes technical aspects, the broad directions derived from the collaboration need to be transformed into a real, completely functional robot. Although LLMs do not provide comprehensive technical support, they can offer their own insights on whether the technology is feasible, helping researchers reduce the risk of failure.\nPresently, LLMs lack the ability to generate comprehensive CAD models, evaluate code, or independently fabricate robots. Nevertheless, advancements in LLM research suggest that these algorithms can offer significant assistance in executing software [78], mathematical reasoning [79], and even in the generation of shapes [80]. Lu et al. specifically focused on the utilization of LLMs for organizing unstructured metadata, facilitating the conversion of metadata between different formats, and discovering potential errors in the data collection process [77]. They also envisioned the next generation of LLMs as remarkably potent tools for data visualization [46], and anticipated that these advanced models will provide invaluable support to researchers, enabling them to extract meaningful insights from extensive volumes of phenotypic data.\nAlthough LLMs provide insights can indirectly help farmers solve a small number of agricultural tasks, it's important to note that their insights should be used in conjunction with human judgment and domain expertise. That is to say, the insights provided by LLMs cannot be separated from human experience."}, {"title": "2.1.3. LLMs provide decision-making support for farmers", "content": "According to a recent study, ChatGPT demonstrates the ability to comprehend natural language requests, extract valuable textual and visual information, select appropriate language and vision tasks, and effectively communicate the results to humans [81]. Shen et al. proposed a system"}, {"title": null, "content": "LLMs have the potential to function as controllers, overseeing and managing the operations of existing Al models to address complex AI tasks. As shown in Fig 2, A farmer with a low level of education used audio to consult the system and sent an image. When receiving a task request, LLM first divides the total task into subtasks and selects the appropriate Al model based on the needs of each subtask. For example, converting farmers' audio into text requires the use of an audio to text model (Amazon transcribe, Whisper [82]); It is also necessary to recognize the sent image and integrate the text obtained from the audio conversion in the previous step to obtain a text-response (vit-gpt2); Considering that the farmer is illiterate, it is necessary to further convert text-response into audio and ultimately obtain the audio-response (Fastspeech [83] [84]). Although LLM does not play a role in solving problems throughout the entire system, as a \"conductor\", it can coordinate various AI models to complete subtasks, thereby gradually solving complex tasks and playing a core role in decision-making support."}, {"title": "2.2. Few-shot learning of LLM in the agricultural domain", "content": "In the previous section, it was mentioned that LLM plays a significant role in processing and generating agricultural data, providing insights and decision support. But in the case of fully-supervised learning, this often requires a large number of labelled samples to train in order to obtain a good model. Unlike many current models, human beings possess the remarkable capacity to derive new knowledge even in situations where they have limited or zero experiences. To narrow the gap between human beings and large models, researchers have proposed the concept of few-shot learning (FSL) [85]. FSL only requires meta knowledge (Prior knowledge) to infer new knowledge, that is, in the case of insufficient samples, FSL can also obtain remarkable generalization ability based on limited samples. It is very useful for agricultural domain where data collection and labelling are difficult and expensive."}, {"title": null, "content": "FSL has already shown superior performance in the NLP domain [86] [87] [88], it can be categorized into three distinct types: few-shot, one-shot, and zero-shot. Few-shot applies to 2 to 5 samples per class, one-shot applies to one sample per class, and zero-shot classifies invisible classes without samples. In a study conducted by Tom B. Brown et al., GPT-3 was trained and evaluated in few-shot setting. The results indicated that GPT-3 demonstrates strong performance in diverse NLP tasks, such as translation, QA, and cloze [89].\nAlthough FSL performs well in image classification, object detection, and object tracking, its generalizability is very limited compared to fully-supervised learning. Consider two examples of classifying fruits in an image and detecting fruits in an image. While both tasks involve recognizing fruits, they cannot be directly converted into one another. Consequently, each task necessitates a dedicated model specifically trained for that particular objective, which greatly reduces the generalizability of the model. The main problem with training models in the agricultural domain is the lack of labelled data, which leads to poor generalization of models trained by fully supervised learning. For this reason, researchers are trying to use FSL to reduce the demand for particular crop data. Surprisingly, LLMs not only has excellent performance in generalizability, but also demonstrate an innate talent for few-shot learning [89].\nLLMs have demonstrated remarkable abilities across diverse domains, exhibiting the capability of zero-shot generalization without the requirement for fine-tuning specific to each task [90] [91]. Even so, these models are primarily limited to processing text-based data. MLLMs may be able to overcome these limitations. It is worth noting that many current research directions for large models still only focus on image, neglecting audio, video, and other aspects. As the most advanced large model of OpenAI, GPT-4 only supports input of text, audio and images [46] [92]. Large models with visual ability show their versatility in different domains [55]. Because the"}, {"title": null, "content": "images used in training models are from the Internet, these images have a large gap with the real agricultural images, which leads to these models cannot be well applied to the agricultural domain. As a consequence, agriculture researchers can only rely on FSL to train a large model suitable for agriculture, unless there are suitable agricultural images to train large vision-language models (LVLM)."}, {"title": "3. Large Vision Models in Agricultural Applications", "content": "The public often confuse LVLM and LVM. LVLM refers to LLM with visual ability. LVM is a purely visual large model that does not making use of any linguistic data, and only uses image data for training and inference [93]. The goal of LVM is to learn universal visual knowledge and adapt to different visual tasks and scenes.\nThe current use of large models in agriculture is mainly focused on CV. Using models to analyze diseases, pests, weeds, seeds, mature crops, and other aspects involves the use of LVMs, among which the main problem is still the problem of diseases and pests. The traditional methods for detecting crop pests and diseases mainly rely on special methods such as serology and molecular biology-based technical means, in addition to artificial visual evaluation. Although these methods can accurately determine pests and diseases to a certain extent, they often require a lot of time and money. And some methods of sampling crops often lead to crop damage, which goes against the original intention of diagnosing diseases and pests to protect crops. Therefore, image processing and analysis is an important task for large models in the field of agriculture, and another important task is to embed LVMs into robots to solve some agricultural problems (Weeding, pruning branches, harvesting, etc.) and achieve automated agriculture."}, {"title": "3.1. Image processing and analysis", "content": "Using a LVM to judge crop related information can not only greatly improve the time required for judgment, but also indirectly reduce the damage caused to crops. Moreover, after crops are invaded by pests and diseases, their color, texture, spectral characteristics will undergo certain changes, all of which are related to CV.\nAt present, there are four types of methods for obtaining crop image information: 1) ordinary channels, taking photos to obtain images; 2) obtaining remote sensing images through agricultural machinery near the ground; 3) obtaining remote sensing images through aircraft monitoring platforms [94]; 4) obtaining remote sensing images through satellites [95]. Remote sensing can provide large-scale land use and land cover information. By analyzing satellite images or high-altitude images, various surface information can be identified, such as surface conditions, soil moisture, vegetation coverage, and crop growth status [96]. Classifying and segmenting from limited examples obtained from remote sensing is a significant challenge. Regarding this, Wu et al. put forward GenCo (a generator-based two-stage approach) for few-shot classification and segmentation on remote sensing and earth observation data [97]. Their approach presents an alternative solution for addressing the labeling challenges encountered in the domains of remote sensing and agriculture. Spectral data can provide rich insights into the composition of observed objects and materials, especially in remote sensing applications. The challenges faced in processing spectral data in agriculture include: 1) effectively processing and utilizing vast amounts of remote sensing spectral big data derived from various sources; 2) deriving significant knowledge representations from intricate spatial-spectral mixed information; 3) addressing the spectral degradation in the modeling of neighboring spectral relevance. Hong et al.'s SpectralGPT empowers intelligent processing of spectral remote sensing big data, and this LVM has also demonstrated its excellent spectral reconstruction capabilities in agriculture [98]. Due to"}, {"title": null, "content": "multispectral imaging (MSI) and hyperspectral imaging (HSI) make it possible to monitor crop health in the field. The integration of remotely sensed multisource data, such as HSI and LiDAR (Light detection and ranging), enables the monitoring of changes occurring in different parts of a plant [99]. By using a large visual model to analyze these spectral data, the obtained crop health information can help farmers quickly and accurately identify diseases and treat them, reducing the loss of crop yield.\nThe use of LVMs for image recognition and predictive analysis of crop information is often more effective than traditional machine learning algorithms. When farmers need to obtain crop information, four types of image acquisition methods can be used to obtain crop image information (Fig 3). Then, the image information is processed through image recognition (Divided into four tasks: image classification, object detection, semantic segmentation, instance segmentation), and the identified results need to be further predictive analytics by the model (LVLM) to obtain crop information that farmers can understand."}, {"title": null, "content": "In addition to obtaining information by analyzing the phenotypic characteristics of crops, Feng et al. developed an organelle segmentation network (OrgSegNet) [100]. OrgSegNet is capable of accurately capturing the actual sizes of chloroplasts, mitochondria, nuclei, and vacuoles within plant cell, further inspecting plant phenotypic at the subcellular level. They have tested two applications: 1) A thermo-sensitive rice albino leaf mutant was cultivated at cold temperature conditions. In the transmission electron microscope images (TEMs), the albinotic leaves lacked typical chloroplasts, and OrgSegNet failed to identify any chloroplast structures; 2) Young leaf chlorosis 1 (Ylc1). Young leaves of the ylc1 mutant showed lower levels of chlorophyll and lutein compared to corresponding wild type, and its TEM analysis further revealed a noticeable loose arrangement of the thylakoid lamellar structures. It can be imagined that if a large model is used to replace deep learning algorithms, the recognition of subcellular cells may perform better, and the recognition results can be further predictive analytics to obtain information that non plant experts can also understand."}, {"title": "3.2. Automation and robotics", "content": "A conventional agricultural robot system consists of perception, decision-making, and actuation modules [101]. Their perception module utilizes CV and deep learning to accurately identify crops, soil conditions, and other relevant information [102]. The module of decision-making utilizes this data to automatically provide suitable agricultural management strategies based on factors such as crop growth status and soil quality [103]. The actuator module is responsible for executing specific tasks as determined by the decision-making module [104].\nNevertheless, traditional agricultural robot systems have limitations in processing large volumes of offline data. They lack high-performance data processing and high-quality actual-time control capabilities. This is due to the potential network communication and computing burdens associated"}, {"title": null, "content": "with big data processing, causing decreased system performance and heightened costs [105]. Furthermore, they were usually designed for specific crops based on crop type and application requirements. The drawbacks of traditional systems were evident in their inflexible control logic and the absence of intelligence, including automatic decision-making and motion generation [106].\nIn response to these challenges, it is necessary to use large models to help lift the intellectual features of agricultural robots.\nCurrent LVMs can be used in drones to monitor crops and obtain information on their growth, disease, yield, and other factors [107] [108] [109]. In addition to the above functions, ground machines that used LVMs can also be used for harvesting and classifying crops, as well as detecting pests up close. In [9], a LVM, segment anything model (SAM) [110], uses infrared thermal images for chicken segmentation tasks in a zero-shot means. SAM can be used in agriculture to segment immature fruits on a fruit tree and quickly achieve yield prediction. Yang et al. subsequently proposed the Track Anything Model (TAM) by combining SAM and video [111]. Unfortunately, TAM places more emphasis on maintaining short-term memory rather than long-term memory. Nevertheless, TAM still has great potential in the agricultural field. If its long-term memory ability can be improved, it can monitor early changes in crop diseases and provide early warning to farmers. Embedding LVMs such as SAM and TAM into robots can not only achieve automation in agriculture, but these LVMs themselves can help achieve automation in agricultural robot design. As mentioned in section 2.1.2, Stella et al. used ChatGPT and other LLMs to assist in designing an optimized robotic gripper for tomato picking [8]. It is worth mentioning that the ChatGPT they used at the time was the GPT-3 version, which only supported text input at this time. At present, ChatGPT has been updated to GPT-4 version and has the"}, {"title": null, "content": "function of LVLM. Designers of agricultural robots can input text descriptions and sketches into ChatGPT to achieve partial automation of design robots.\nOverall, due to the real-time requirements of agricultural robots, the scale of traditional vision models is small, and the recognition results of agricultural images are often unsatisfactory. The emergence of LVM has broken this deadlock, as pre-trained recognition results using large-scale datasets often outperform traditional vision models. Its disadvantage is that it usually requires more computing resources and time to complete the inference and prediction process, resulting in poor real-time performance. However, by optimizing the model architecture, using efficient inference algorithms, and utilizing hardware acceleration techniques, the real-time performance of LVMs can be improved to a certain extent [112]."}, {"title": "3.3. LVLM compared to LVM"}]}