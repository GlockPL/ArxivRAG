{"title": "Harnessing Large Vision and Language Models in Agriculture: A Review", "authors": ["Hongyan Zhu", "Shuai Qin", "Min Su", "Chengzhi Lin", "Anjie Li", "Junfeng Gao"], "abstract": "Large models can play important roles in many domains. Agriculture is another key factor\naffecting the lives of people around the world. It provides food, fabric, and coal for humanity.\nHowever, facing many challenges such as pests and diseases, soil degradation, global warming,\nand food security, how to steadily increase the yield in the agricultural sector is a problem that\nhumans still need to solve. Large models can help farmers improve production efficiency and\nharvest by detecting a series of agricultural production tasks such as pests and diseases, soil quality,\nand seed quality. It can also help farmers make wise decisions through a variety of information,\nsuch as images, text, etc. Herein, we delve into the potential applications of large models in\nagriculture, from large language model (LLM) and large vision model (LVM) to large vision-\nlanguage models (LVLM). After gaining a deeper understanding of multimodal large language", "sections": [{"title": "1. Introduction", "content": ""}, {"title": "1.1. The challenges facing the agricultural domain", "content": "The significance of agriculture in the global economy is increasing steadily, and there is\ngrowing awareness regarding its sustainability. Ahirwar et al. believe that it is necessary to\nincrease global agricultural food production by a minimum of 70% to meet the needs of the\nincreasing world population [1]. Unfortunately, there are many factors in agriculture that make it\ndifficult to steadily increase grain production, including 1) crop diseases caused by pathogens such\nas bacteria, fungi, and viruses; 2) unscreened low-quality seeds lead to unhealthy crop growth,\ndecreased yield, and susceptibility to crop diseases; 3) many agricultural tasks are inefficient,\nincluding weeding, planting, watering, and harvesting crops. Agricultural production is facing\nenormous economic and production losses. For crop diseases, traditional detection methods like\npolymerase chain reactions on the basis of unique deoxyribonucleic acid sequences of pathogens,\nenzyme-linked immunosorbent assays on the basis of pathogens proteins and hyperspectral"}, {"title": "1.2. The history of LLM and LVM", "content": "Artificial intelligence (AI), whose main purpose is to establish systems that learn and think\nlike human [13], just like human language and visual abilities. At present, research on large models\nis also focused on the natural language processing (NLP) and computer vision (CV). Next, LLMs\nand LVMs will be introduced in detail. LLM is a model based on NLP, and we can divide the\ndevelopment of it into four stages:\n\u2022\nStatistical language models (SLM). SLMs use traditional statistical techniques such as n-gram\nand some language rules to learn the probability distribution associated with words. It is\ngenerally believed that the amount of data, and the ability of a given estimation algorithm to\naccommodate large number of training are very significant in providing a solution that\ncompetes successfully with the entrenched n-gram language models [14]. SLMs are currently\nwidely used in the field of NLP, such as Raychev et al. designed a simple and scalable static\nanalysis that uses SLMs to complete incorrect code [15]. However, n-gram models have three\ndrawbacks. Firstly, as n increases, the more parameters need to be calculated and counted,\nand the more memory space it occupies. Markov assumption can be used to limit the size of\nn [16]. Secondly, n-grams models cannot share information from vocabulary or prefixes with\nthe same semantics. Word embedding can be used to shift character representation to vector\nrepresentation [17]. Thirdly, data sparsity. Data smoothing, backoff [18] and interpolation can\nbe used to solve this problem. In addition, neural network models can better handle the\nproblem of data sparsity.\n\u2022\n\u2022\nNeural language models (NLM). NLMs [19] [20] [21] use different types of neural networks\nto model language, and compared to SLMs, NLMs are more effective. To solve the problem\nof data sparsity in n-gram models, feedforward neural networks and recurrent neural networks\n(RNN) were used in continuous space language modelling, which can enable the model to\nautomatically learn features and continuous representations. The first feedforward neural\nnetwork language model (FFNNLM) was proposed by Bengio et al. in 2003, which overcomes\nthe curse of dimensionality by learning distributed representations of a word [19].\nSubsequently, Mikolov et al. suggested the RNN language model (RNNLM), which can make\npredictions using limited context [20]. However, during the training process of RNNLM, the\ngradient of parameters may disappear or explode, leading to slower training speed or infinite\nparameter values, making it difficult for the model to achieve long-term dependence.\nSundermeyer et al. applied long short-term memory recurrent neural networks to language\nmodels in 2012 and proposed LSTM-RNNLM [21]. Three gate structures (including input,\noutput, and forget gates) had been added to the LSTM memory unit to control information\nflow, which solved the problem of long-term dependence in language models learning.\nPre-trained language models (PLM). PLMs can be divided into two paradigms: feature-based\nand fine-tuning. Feature-based treats pre-training as a feature extraction process, trains model\nparameters on large-scale corpora, and encodes them as fixed features to downstream models\nfor collective tasks. A typical example is ElMo, a pre-training bidirectional LSTM (BiLSTM)\nproposed by Peters et al. [22]. Due to LSTM modelling sentences, it can solely consider the\ncontextual information preceding the current sentence and fails to capture subsequent\ncontextual information. And BiLSTM uses reverse networks, which can concurrently consider\ncontextual information before and after, thus better processing sequential data. Fine-tuning"}, {"title": "2. Large Language Models in Agricultural Applications", "content": "Numerous agricultural tasks require intricate reasoning. For example, when presented with\nan image of a soybean field, agricultural scientists or farmers rely on large models to undertake\nseveral key steps. Firstly, the large model must identify any abnormal symptoms evident in the\nsoybean leaves, such as water stains. Subsequently, it must ascertain the name of the specific\nproblem that troubles plants, such as bacterial wilt disease. Next, the model needs to determine the\nunderlying cause of the disease, such as pseudorabies. Finally, it must develop an appropriate\ntreatment strategy, such as applying a bactericide spray.\nMany question answering (QA) and dialogue systems are designed to address this type of\nreasoning problem [66] [67] [68]. For instance, a chatbot based on a RNN is specifically designed\nto handle questions related to soil testing, plant protection, and nutrient management [66].\nAlthough, these QA and dialogue systems and chatbots are capable of answering most inquiries\nwithout the need for human interaction and with excellent accuracy, they have limited capabilities\nfor complex problems by reason of their small model size as well as of inadequate training data.\nTherefore, the agricultural domain requires large models to promote the development of QA and\ndialogue systems and chatbots."}, {"title": "2.1. The role of LLM in processing and generating agricultural data, providing insights and\ndecision-making support", "content": "LLM can play many roles in the agricultural domain, such as processing and generating\nagricultural data, providing insights into agricultural production work, and supporting agricultural\ndecision-making for farmers.\n2.1.1. LLMs processing and generating agricultural data\nInformation extraction. LLMs can extract structured information from unstructured\nagricultural text data. First, the text is divided into individual tokens and LLMs represent each\ntoken as a numerical vector called a word embedding. Then, LLMs analyse the surrounding\ncontext of each token to understand its meaning within the sentence or document, and identify and\ncategorize named entities within the text, like names of individuals, locations, organizations, or\nspecific agricultural terms. Finally, LLMs employ techniques like information extraction to\nidentify and extract structured information from unstructured text (Involve identifying\nrelationships between entities, extracting key facts, or populating knowledge graphs). LLMs\nextract information from data using a process known as NLP. Peng et al. used LLM (Not related\nto the agricultural domain) to automatically extract entities and attributes from unlabelled\nagricultural data and transform them into structured data [69]. Information extraction is beneficial\nfor LLM to better understand the overall meaning of the text.\nAgricultural data generation. Generative Al models are actually a multimodal LLMs\n(This content will be detailed in 4.1). An obstacle encountered when applying specialized CV\nalgorithms to agricultural vision data is the insufficient availability of training data and labels [70]\n[37]. In addition, collecting data that encompasses the wide range of variations caused by season\nand weather changes is exceedingly challenging. Acquiring high-quality data requires a lot of time,\nand labelling them is even more costly [71]. To address these challenges, one approach is to fine-"}, {"title": "2.1.2. LLMs provide insights", "content": "LLMs possess the capability to analyse textual data and uncover trends in agricultural\npractices, market conditions, consumer preferences, and policy developments. Through analysis\nof agricultural text data from sources such as news articles, reports, and social media, these models\ncan offer valuable insights into market dynamics and pricing trends [76]. This provides support\nfor farmers to understand domains outside of agriculture. Many researchers believe that the\nintegration of LLMs into different stages of designment and development for agricultural\napplications is also experiencing a noticeable rise [8] [77]. In [8] study, Stella et al. incorporated\nLLM into the design phase of robotic systems. They specifically focused on designing an\noptimized robotic gripper for tomato picking and outlined the step-by-step process. In the initial\nideation phase, they leveraged LLMs like ChatGPT [46] to gain insights into the possible\nchallenges and opportunities associated with the task. Building upon this knowledge, they\nidentified the most promising and captivating pathways, engaging in ongoing discussions with the\nLLM to refine and narrow down the design possibilities. Throughout this process, the human"}, {"title": "2.1.3. LLMs provide decision-making support for farmers", "content": "According to a recent study, ChatGPT demonstrates the ability to comprehend natural\nlanguage requests, extract valuable textual and visual information, select appropriate language and\nvision tasks, and effectively communicate the results to humans [81]. Shen et al. proposed a system"}, {"title": "2.2. Few-shot learning of LLM in the agricultural domain", "content": "In the previous section, it was mentioned that LLM plays a significant role in processing\nand generating agricultural data, providing insights and decision support. But in the case of fully-\nsupervised learning, this often requires a large number of labelled samples to train in order to\nobtain a good model. Unlike many current models, human beings possess the remarkable capacity\nto derive new knowledge even in situations where they have limited or zero experiences. To narrow\nthe gap between human beings and large models, researchers have proposed the concept of few-\nshot learning (FSL) [85]. FSL only requires meta knowledge (Prior knowledge) to infer new\nknowledge, that is, in the case of insufficient samples, FSL can also obtain remarkable\ngeneralization ability based on limited samples. It is very useful for agricultural domain where\ndata collection and labelling are difficult and expensive."}, {"title": "3. Large Vision Models in Agricultural Applications", "content": "The public often confuse LVLM and LVM. LVLM refers to LLM with visual ability. LVM\nis a purely visual large model that does not making use of any linguistic data, and only uses image\ndata for training and inference [93]. The goal of LVM is to learn universal visual knowledge and\nadapt to different visual tasks and scenes.\nThe current use of large models in agriculture is mainly focused on CV. Using models to\nanalyze diseases, pests, weeds, seeds, mature crops, and other aspects involves the use of LVMs,\namong which the main problem is still the problem of diseases and pests. The traditional methods\nfor detecting crop pests and diseases mainly rely on special methods such as serology and\nmolecular biology-based technical means, in addition to artificial visual evaluation. Although these\nmethods can accurately determine pests and diseases to a certain extent, they often require a lot of\ntime and money. And some methods of sampling crops often lead to crop damage, which goes\nagainst the original intention of diagnosing diseases and pests to protect crops. Therefore, image\nprocessing and analysis is an important task for large models in the field of agriculture, and another\nimportant task is to embed LVMs into robots to solve some agricultural problems (Weeding,\npruning branches, harvesting, etc.) and achieve automated agriculture."}, {"title": "3.1. Image processing and analysis", "content": "Using a LVM to judge crop related information can not only greatly improve the time\nrequired for judgment, but also indirectly reduce the damage caused to crops. Moreover, after\ncrops are invaded by pests and diseases, their color, texture, spectral characteristics will undergo\ncertain changes, all of which are related to CV.\nAt present, there are four types of methods for obtaining crop image information: 1)\nordinary channels, taking photos to obtain images; 2) obtaining remote sensing images through\nagricultural machinery near the ground; 3) obtaining remote sensing images through aircraft\nmonitoring platforms [94]; 4) obtaining remote sensing images through satellites [95]. Remote\nsensing can provide large-scale land use and land cover information. By analyzing satellite images\nor high-altitude images, various surface information can be identified, such as surface conditions,\nsoil moisture, vegetation coverage, and crop growth status [96]. Classifying and segmenting from\nlimited examples obtained from remote sensing is a significant challenge. Regarding this, Wu et\nal. put forward GenCo (a generator-based two-stage approach) for few-shot classification and\nsegmentation on remote sensing and earth observation data [97]. Their approach presents an\nalternative solution for addressing the labeling challenges encountered in the domains of remote\nsensing and agriculture. Spectral data can provide rich insights into the composition of observed\nobjects and materials, especially in remote sensing applications. The challenges faced in\nprocessing spectral data in agriculture include: 1) effectively processing and utilizing vast amounts\nof remote sensing spectral big data derived from various sources; 2) deriving significant\nknowledge representations from intricate spatial-spectral mixed information; 3) addressing the\nspectral degradation in the modeling of neighboring spectral relevance. Hong et al.'s SpectralGPT\nempowers intelligent processing of spectral remote sensing big data, and this LVM has also\ndemonstrated its excellent spectral reconstruction capabilities in agriculture [98]. Due to"}, {"title": "3.2. Automation and robotics", "content": "A conventional agricultural robot system consists of perception, decision-making, and\nactuation modules [101]. Their perception module utilizes CV and deep learning to accurately\nidentify crops, soil conditions, and other relevant information [102]. The module of decision-\nmaking utilizes this data to automatically provide suitable agricultural management strategies\nbased on factors such as crop growth status and soil quality [103]. The actuator module is\nresponsible for executing specific tasks as determined by the decision-making module [104].\nNevertheless, traditional agricultural robot systems have limitations in processing large volumes\nof offline data. They lack high-performance data processing and high-quality actual-time control\ncapabilities. This is due to the potential network communication and computing burdens associated"}, {"title": "3.3. LVLM compared to LVM", "content": "As mentioned at the beginning of this chapter, LVLM and LVM cannot be confused, but\nLVLM can be considered as an LVM with NLP capabilities. LVLM is a model that combines both\nvisual and textual information to comprehend and generate captions, respond to questions about\nimages, and tackle tasks that necessitate a comprehensive understanding of both vision and\nlanguage.\nLike LVM, research on LVLM is also very early. Mori et al. conducted research on\nenhancing content-based image retrieval by training a model to forecast nouns and adjectives in\ntext associated with images as early as 1999 [113]. In 2007, Quattoni et al. showcased the potential\nof learning more data efficient image representations through manifold learning in the weight\nspace of categorizer trained to predict words in image captions [114]. Over a decade ago,\nSrivastava and Salakhutdinov delved into the domain of deep representation learning by training\nmultimodal Deep Boltzmann Machines using low-level image and text tag features as a foundation"}, {"title": "4. Multimodal Large Language Model and Model Assessment", "content": ""}, {"title": "4.1. Integration of multimodal models", "content": "MLLM recently has emerged as a prominent research hotspot, which uses powerful LLMs\nas a core to tackle multimodal tasks [118]. The most common MLLM (Supporting both images\nand text) is LVLM (Fig 4). In recent years, many researchers have utilized and merged diverse\ntypes of data inputs, such as text, images, audio, video [119], sensor data [51], depth information,\npoint cloud [120], and more.\nThe agricultural community has started exploring the realm of multimodal learning in\nagricultural applications. By incorporating multimodal learning techniques, the agricultural\ncommunity seeks to unlock new opportunities for optimizing various agricultural processes and\nachieving improved outcomes. As an example, Bender et al. have released an open-source\nmultimodal dataset specifically curated for agricultural robotics [121]. This dataset was collected\nfrom cauliflower and broccoli fields and aims to foster research endeavours in robotics and\nmachine learning within the agricultural domain. It encompasses a diverse range of data types,"}, {"title": "4.2. Results and impact assessment", "content": "For the evaluation of a large model, questions can be asked and the answer results of the\nmodel can be tested. According to ethics and timeliness (Fig 5), it can be divided into A: the results\nhave timeliness and do not violate ethics; B: the results have timeliness but violate ethics; C:\noutdated results that do not violate ethics; D: outdated results that violate ethics. As time passes,\nA will gradually become C, but it does not mean that the C is useless. Also affected by time, B\nwill gradually become D, and D is the worst-case evaluation, both unethical and outdated. There\nare individual differences in the evaluation of A and B, and different questioners have different\nopinions on whether the same answer violates ethics. Therefore, judgments should be made based\non the questioner's own religious beliefs, race, and other reasons. In summary, from a priority\nperspective, A>C>B>D."}, {"title": "5. Ethical issues and responsible use of large vision and language models in\nAgriculture", "content": "The performance of large models in agriculture demonstrates their superiority, and the\npotential of large models becomes evident when employed to enable predictive understanding of\nintricate systems. However, there are often ethical and responsibility issues in the development\nand deployment process of AI today. The digital gap between those who have the resources to\ndevelop and utilize large models and those who cannot afford to do so creates an inequality in\naccessing large models, resulting in an unfair distribution of risks and benefits [126]. Not only that,"}, {"title": "5.1. Ethical issue of large language models to guide farming", "content": "Predicting and solving ethics problems of large models in agriculture is a critical scientific\nand societal challenge. Although large models point the way for the future of smart agriculture,\ndue to their characteristic of being influenced by close association, large models often learn some\nbad knowledge in addition to useful knowledge. Ethical issues have always been an indispensable\ntopic of discussion in the process of technological progress (Such as the ethical issues discussed\nby Holmes et al. in the field of education regarding educational AI [129]), and we also need to pay\nattention to ethics issues when using large models in the agricultural direction. As mentioned\nbelow, many relevant institutions and personnel have put forward their own ideas on ethical issues\nrelated to large models."}, {"title": "5.2. Responsible use in agriculture", "content": "With the expanding development and utilization of large models, there is undoubtedly a\ngrowing need for agile and effective regulatory oversight. To address this issue, it may be\nnecessary to use AI technology to assist in overseeing the development and deployment of large\nmodels. Regarding this aspect, the AI Act, which has been jointly agreed upon by the European\nParliament and the Council of Europe, represents the first comprehensive set of harmonized rules\non a global scale. It promotes responsible large model designment and development by regulating\nlarge model across various applications and contexts based on a risk-based framework. Within the\nframework, careful consideration must be given to the level of risk involved and how to evaluate\ndifferent large models as risk-free or low-risk.\nTo evaluate the risk level of a large model, we focus on four aspects: transparency, privacy,\nequality, and beneficence. On the other hand, in addition to developing and adhere to a strong\nregulatory framework that guides the development, deployment, and use of large models,\nregulatory methods also need to be considered. Consider the potential societal impact, potential\nharms, and long-term implications of the technology. Firstly, due to the wide applicability of large\nmodels, we cannot make a one size fits all approach. Regulation must adapt to specific issues in\ndifferent domains. The United States' food and drug administration (FDA) has tailored potential\nregulatory methods for AI and machine learning technologies used in medical devices,\ncategorizing them into three major categories based on risk levels: Class I (Low risk), Class II\n(Moderate risk), and Class III (High risk). Large models in agriculture can also be regulated\naccording to the FDA's approach, dividing them into several types of models ranging from low"}, {"title": "6. Challenges and Future Directions", "content": "Although large models can play a powerful role in the field of agriculture, they still face\nchallenges in many aspects.\n6.1. Technical and practical challenges\n1) Difficulty in obtaining agricultural data\nDeveloping a large model suitable for agriculture requires a lot of relevant agricultural data,\nand there are many difficulties in the process of collecting these data. Due to factors such as crop\ntypes, growth stages, soil conditions, weather patterns, and agricultural practices, the complexity\nand high diversity of datasets make its collection and standardization a challenging task [10]. First\nof all, the collection of these data must be comprehensive and accurate, otherwise it cannot be\nguaranteed that the trained model will have good performance. Obtaining high-quality data is time-\nconsuming, labour-intensive, and costly, particularly considering the requirement for ground truth\nlabelling in supervised learning [139]. Secondly, as mentioned in Chapter 5, private data can pose\nrisks to the use of large models. But to ensure the accuracy of the large model, some private data\nis necessary. However, as farmland is typically privately owned, farmers may exhibit hesitancy in\nsharing data due to concerns over privacy or latent mercantile exploitation. Thirdly, crops have a\ngrowth cycle, their growth process changes with the passage of time, influenced by daily\nfluctuations, seasonal changes, or annual variations. This requires the collection of time-series data,\nwhich introduces the other layer of complexity for data collection [140].\n2) Low training efficiency\nTraining large models for agriculture applications presents significant challenges,\nespecially when it comes to lengthy training times and significant costs, such as thousands of GPU\nhours and millions of training data are required [140]. Large models typically have a significantly\nhigher number of parameters, which increases the computational demand during training. The\ncomputations involved in forward and backward passes through the layers of the model become\nmore complex and time-consuming. Collecting, preprocessing, and loading massive data is time-\nconsuming and resource-intensive.\n3) Distribution shift\nThe problem of distribution shift is a major challenge when using large models in\nagriculture. When the data encountered by the model during deployment is obviously different\nfrom the data used in its training phase, a distribution shift will occur. The environmental\nconditions for collecting data may vary greatly in different regions and climates. These changes\nmay include differences in crop types, soil conditions, weather patterns, and agricultural practices,\nall of which can lead to significant changes in data distribution [141]. The distribution shift will\nresult in the trained large model not having strong applicability and may not achieve good results\nin some agricultural tasks. For example, it has been proven that applying large models directly to\nleaf segmentation tasks in a zero-shot means led to unsatisfactory performance, which can be\nattributed to possible distribution shifts [11].\n4) The lag of data\nAfter the trained large model is put into use, the data used for training has a certain\ntimeliness for a long period of time. But after a long time, some data lags in time, and the results\nobtained by using a large model may deviate from the current facts (Fig 7)."}, {"title": "6.2. Future trends in the integration of agricultural and food sectors and large models", "content": "In the future, there will undoubtedly be agricultural large models with better performance\nand higher applicability. And the large models in agriculture should not be limited to text and\nimage inputs. We believe that future multimodal agricultural models can support multimodal\ninformation such as videos (Analysing crops in videos) and audio (Tapping watermelons, and\njudging maturity through the sound emitted). On the other hand, agriculture is closely related to\nfood, and the development of large models in agriculture is likely to promote the development of\nlarge models in the food domain. Trust is indispensable for agriculture and food system\ntechnologies given food's universality and importance to people [143]. Researchers need to\nnavigate complicated social, political, economic, and environmental landscapes to develop\nappropriate large models in the food industry. In the future food industry, researchers will strive\nto establish trust with governmental agencies and funders, as well as with food system partners, to\nprovide food and products that the public trusts [144]."}, {"title": "7. Conclusion", "content": "In summary, this study investigated the application status of large models in the agricultural\nfield. The current large models research in agricultural domain can bring great changes to\nagriculture, not only greatly improving the efficiency of agricultural production, but also further\nmoving agriculture towards \"smart agriculture\" and \"unmanned agriculture\". However, there are\nstill some unresolved issues in the development and deployment of agricultural large models.\nAlthough some studies have proposed solutions to these issues, further research is needed to ensure\nthe applicability and reliability of large models in the field of agriculture. The food field is closely\nrelated to the agricultural field, and in the process of developing the agricultural large models, the\nfood large models will also be further developed. These two different fields of large models will\ninteract with each other, forming positive feedback. In the future, research on agricultural large\nmodels still needs to be further improved in terms of applicability and reliability, to prevent\nerroneous information from misleading farmers and causing damage to farmland, as well as\nfarmers' distrust of new technologies. We hope this paper can serve as a support and cornerstone\nfor the development of future agricultural models."}]}