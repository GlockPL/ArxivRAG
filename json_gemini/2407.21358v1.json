{"title": "Tree-of-Traversals: A Zero-Shot Reasoning Algorithm for Augmenting Black-box Language Models with Knowledge Graphs", "authors": ["Elan Markowitz", "Anil Ramakrishna", "Jwala Dhamala", "Ninareh Mehrabi", "Charith Peris", "Rahul Gupta", "Kai-Wei Chang", "Aram Galstyan"], "abstract": "Knowledge graphs (KGs) complement Large Language Models (LLMs) by providing reliable, structured, domain-specific, and up-to-date external knowledge. However, KGs and LLMs are often developed separately and must be integrated after training. We introduce Tree-of-Traversals, a novel zero-shot reasoning algorithm that enables augmentation of black-box LLMs with one or more KGs. The algorithm equips a LLM with actions for interfacing a KG and enables the LLM to perform tree search over possible thoughts and actions to find high confidence reasoning paths. We evaluate on two popular benchmark datasets. Our results show that Tree-of-Traversals significantly improves performance on question answering and KG question answering tasks. Code is available at https://github.com/amazon-science/tree-of-traversals", "sections": [{"title": "1 Introduction", "content": "Large language models (LLMs) are used for a range of knowledge-intensive tasks such as information retrieval (Zhu et al., 2023b), summarization (Zhang et al., 2023), and question answering (Tan et al., 2023). Trained on large amounts of textual data, these models learn a wide breadth of information. However, LLMs suffer from several limitations they produce hallucinated information (Ji et al., 2022; Bang et al., 2023), lack deep domain-specific knowledge (Pan et al., 2023b), and have a static knowledge cutoff when training ends.\nKnowledge graphs (KGs) naturally complement LLM weaknesses. KGs contain up-to-date information covering general (Vrande\u010di\u0107 and Kr\u00f6tzsch, 2014; Lehmann et al., 2015) and/or domain-specific topics (Abu-Salih, 2020; Liu et al., 2019; Zhu et al., 2017; Choi and Lee, 2019; Farazi et al., 2020) in highly structured and interpretable format. Augmenting an LLM's ability to reason and respond in natural language with an external KG's up-to-date knowledge presents a path toward a reliable and factual LLM.\nThe rise of powerful LLMs with new capabilities has renewed interest in combining LLMs with KGS. Numerous survey and position papers have recently emphasized their combined potential (Pan et al., 2023a; Zhu et al., 2023a; Yang et al., 2023; Pan et al., 2023b). Existing works augmented LLMs with KGs in multiple ways, such as integration into pretraining (Yasunaga et al., 2022), fine-tuning (Zhang et al., 2022), or later adaptation with subsequently trained components (Lin et al., 2019; Hu et al., 2022). All of these carry some limitations. In particular, training or fine-tuning a large scale LLMs is computationally expensive. In some cases, model weights are unavailable publicly. Finally, the largest KGs require their own servers and cannot be integrated in-memory with LLMs. Additionally, previous works do not consider the case of augmenting with multiple KGs.\nAn algorithm that allows the augmentation of a powerful black-box LLM with any number of internal or external KGs without training from scratch or fine-tuning the model is valuable. Such a zero-shot algorithm would enable several innovative use cases such as (1) customers using a black-box LLM API in conjunction with an internal domain-specific KG, (2) integration of personalized KGs into an LLM without the risks associated with training a model with such personal data, (3) integration of deep domain knowledge via an array of API accessible KGs (e.g., IMDb\u00b9, MusicBrainz\u00b2).\nWe introduce Tree-of-Traversals, a novel algorithm that addresses the above issues by allowing the augmentation of any powerful LLM with arbitrary number of KGs in a zero-shot fashion. It re-"}, {"title": "2 Tree-of-Traversals", "content": "The Tree-of-Traversals algorithm maintains a local KG subgraph that is repeatedly expanded until it contains all the information required by an LLM to answer the given query. At the start, a local KG subgraph is initialized to contain the entities present in the original query. It is then expanded using a tree search algorithm to choose actions and thoughts generated by an LLM in order to obtain relevant knowledge from the KG using a KG interface. The algorithm halts when the LLM is able to answer the original query using the local KG subgraph as context. Tree-of-Traversals consists of three major components. (1) A knowledge graph interface implemented to interact with one or more required KGs. (2) An action state machine (ASM) which is a finite state machine that defines the feasible space of actions, states, and prompt templates when the LLM interacts with a KG to expand the local KG subgraph. (3) A tree search algorithm which defines the overall LLM search trajectory such as best first search, backtrack upon making a mistake, and termination condition when an answer is found."}, {"title": "2.1 Knowledge Graph Interface", "content": "The knowledge graph interface allows Tree-of-Traversals to interact with one or multiple KGs. Let K = (E,R, T) be a single KG. E is the set of entities in which each entity consists of an identifier, a label, and an optional description (e.g., Q35332, \u2018Christopher Nolan', \u2018British-American filmmaker'). R is the set of relation types, each consisting of an identifier, a label, and an optional inverse label (P57, \u2018director', 'is director of'). T"}, {"title": "2.2 Action State Machine (ASM)", "content": "One of the challenges with developing a zero-shot LLM algorithm that works with arbitrary KGs is that the LLM does not know what relations are available in the graph or what relations are valid for a given entity. Few-shot or in-context learning approaches can only cover a handful of the possible relation types (e.g., Wikidata has over 11,000 relation types) (Brown et al., 2020).\nTo overcome these issues we break the task of expanding a local KG subgraph into multiple subtasks. We use a finite state machine with the following actions: Think, Answer, ExpandKG, Select_Entities, and Select_Relation, and states: default, selecting-entities, selecting-relation, and done as shown in Figure 2. This is named as Action State Machine (ASM) throughout the paper.\nFrom the default state, Tree-of-Traversals can either Think, Answer, or choose to ExpandKG. After Tree-of-Traversals chooses to ExpandKG, it first is prompted to Select_Entities about which it needs more information (e.g., 'Inception' in Figure 1). It is then prompted to Select_Relation from a list of candidate relations provided by the KG interface's get_relations method. After selecting a relation (e.g., 'cast member' in Figure 1), all edges containing one of the selected entities as the source and the selected relation as the relation are added to the local KG subgraph. Tree-of-Traversals is then able to Answer, Think, or ExpandKG again.\nEach state in the ASM other than the 'done' state is associated with a unique prompt template. Prompt templates are filled with information from the local KG subgraph and the KG interface before presenting them to the LLM. A customized prompt for each state allows us to present precise and relevant information along with specific instructions for each state to the LLM simplifying the LLM's task. For instance, the prompt for 'selecting-entities' presents the available options of entities to choose from that are in the local KG subgraph (see Figure 3). Prompt templates for all the states are in the Appendix F.1-F.3.\nLocal KG subgraph is represented using a a token efficient YAML format that minimizes repetition for multiple edges on the same entity.\nOutside of initialization, there are two times in which the ASM needs to invoke the KG interface: (1) When constructing the selecting-relation prompt, the algorithm calls get_relations(Eselected) to gather available choices of relations. (2) When executing the transition from selecting-relation to default after having selected a relation type r, the algorithm calls get_edges(Eselected, r) so that it can add the new edges and entities to the local subgraph."}, {"title": "2.3 Tree Search Algorithm", "content": "Our approach draws inspiration from the Tree-of-Thoughts approach (Yao et al., 2023) in which an LLM is given increased reasoning power by allowing generation of multiple thoughts at a time and"}, {"title": "Algorithm 1 Tree-of-Traversals", "content": "Input: q query, k \u2190 branching factor,\nT\u2190 answer threshold, P \u2190 LLM,\nF\u2190 ASM\nOutput: Answer to q\n1: procedure TOACTIONS(q)\n2: T\u2190 \u03a6 \u25b7 Empty tree\n3: Y\u2190 \u2205 \u25b7 Empty answer set\n4: s0 \u2190 initialize(q)\n5: T.add(s0)\n6: while ! finished do\n7: s \u2190 choose_node(T)\n8: \u25b7 Sample k actions from P using the action\n9: state and associated prompt of s from F(s)\n10: a \u2190 sample_actions(s,k, F, P)\n11: for a \u2208 a do\n12: \u25b7 Apply action a to state s according to F\n13: s' \u2190 transition(s, a, F)\n14: \u25b7 Evaluate the resulting state s' using P\n15: s'.value \u2190 evaluate(s', P)\n16: T.add(s')\n17: if s'.action_state = done then\n18: Y.add(s')\n19: if s'.value > \u315c then\n20: \u25b7 When answer exceeds threshold, stop search\n21: finished \u2190 True\n22: return argmaxy\u2208Y y.value\nTree-of-Traversals computes the value of a node to determine its utility. This value is created by the LLM using evaluation prompts (step evaluate in Algorithm 1). The value can be between 0 to 1 where 1 indicates highest utility. We use two types of evaluation prompts: one for intermediate states and one for answer states. The prompts include the original query, the local KG subgraph, the trajectory of previous actions, followed by instructions for evaluating the node (see Appendix F.4 and F.5). These values are then used to guide the exploration of the action space. Specifically, choose_node returns the unexplored node with the highest value (Best First). If there are nodes with the same value, Depth First Search is used.\nIn some cases we can find the answer to a query with a single sequence of thoughts and actions using the ASM and KG interface. This is equivalent to Tree-of-Traversals with a branching factor of k = 1. We refer to this as Chain-of-Traversals. While useful for compari-"}, {"title": "2.4 Tree-of-Traversals with Multiple KGS", "content": "Augmenting an LLM with more than one KG mainly involves building KG interfaces for each of the added KGs. There are a few other changes to the algorithm. (1) The entities extracted in initialize(q) are matched with each KG interface. (2) When presenting the options of relations during selecting-relation, get_relations(Eselected) is called on each KG interface. (3) When adding a new entity to the local KG subgraph we call an entity linking function for the other KG interfaces. We allow for the entity linking function to be a separate function in the KG interface or to fallback on initialize(o) where o is the text label of the entity that has just been added. This makes allows the use of explicit links between common KGs if available while still functioning without."}, {"title": "3 Experiments", "content": "We evaluate Tree-of-Traversals using three different models available on Amazon Bedrock\u00b3: Claude-Instant (claude-instant-v1), Llama2 70b (llama2-70b-chat-v1), and Llama2 13b (llama2-13b-chat-v1). AWS Bedrock provides on-demand access through a single API to various Foundation Models, including both open source and black box ones. This is precisely a use case Tree-of-Traversals is designed for."}, {"title": "3.1 Tasks and Datasets.", "content": "We first evaluate the Tree-of-Traversals algorithm on two common tasks used for evaluating an LLM's knowledge: 2WikiMultiHop and QALD-10. To allow testing on complex questions requiring knowledge from multiple KGs we create a new dataset that requires knowledge from multiple KGs.\nDataset (Ho et al., 2020) was constructed by extracting multi-hop templates from HotPotQA (Yang et al., 2018), combining templates to get complex reasoning questions, generating candidate questions with Wikidata, and then confirming that the entity mentions for each edge appear in the Wikipedia paragraphs. Answers to these questions can be derived from both Wikipedia and Wikidata (Vrande\u010di\u0107 and Kr\u00f6tzsch, 2014). We"}, {"title": "4 Results and Discussion", "content": "Table 1 presents the results of our experiments on 2WikiMultiHop and QALD-10. For all the models, Tree-of-Traversals outperforms the baselines on 2WikiMultiHop, setting state-of-the-art results for these tasks in the zero-shot setting. We hypothesize that much of this gain is due to Tree-of-Traversals' access to the knowledge base via proposed KG interface and its thought-action procedure guided by the ASM. This is evident, as even Chain-of-Traversals, which does not perform a tree traversal (including multiple thoughts/actions, backtracking, and node value computation), significantly outperforms ReAct's knowledge grounding: 8.7% higher accuracy than ReAct\u2192 CoT on 2WikiMultiHop when averaged over all models. Compared to Chain-of-Traversals, Tree-of-Traversals further improves performance. It gives on average a 12.8% absolute accuracy increase for 2WikiMultiHop and 4.3% absolute improvement for QALD-10. We note that the better performing the model is, the more it stands to gain from Tree-of-Traversals as noted by the difference between Llama-70b and Llama-13b.\nOn MusicBrainz-x-Wikidata (Table 2), which contains challenging reasoning questions requiring access to two KGs, there is an average of 37.4% relative improvement from Tree-of-Traversals over Chain-of-Traversals as shown in Table 2. Both Chain-of-traversals and Tree-of-Traversals outperform Chain-of-Thoughts on this dataset. We only"}, {"title": "4.1 Effect of the Value Function.", "content": "Tree-of-Traversals relies on signal from the value function to pick the final tree trajectory. If the values were arbitrary, then Tree-of-Traversals would not do any better than Chain-of-Traversals. Figure 5 shows that there is a meaningful signal from the value function for all models. There is an average performance difference of 31.0% between the accuracy for answers valued at 1.0 vs 0.0. This represents an average relative improvement of 83.2% when selecting answers valued at 1.0 over those valued at 0.0. See Appendix C for individual profiles of each model's value function."}, {"title": "4.2 Effect of Backtracking.", "content": "To determine the effect of backtracking in Tree-of-Traversals, we ask the counter-factual of how would the model perform if it could not backtrack (Figure 6). We limit the analysis to 2WikiMultiHop questions in which Tree-of-Traversals generates answers on a subtree, and the model eventually backtracks on that subtree (i.e., the cases where we have a counter-factual). As a result, these questions are generally more challenging than the overall distribution of questions. In these cases, we compare the result if the highest-valued answer was taken from the first searched subtree compared to the ultimate answer after backtracking. We find that the ability to backtrack gives Tree-of-Traversals a significant accuracy increase ranging from 4.1% to 12.3%."}, {"title": "4.3 Performance on MusicBrainz-x-Wikidata.", "content": "For MusicBrainz-x-Wikidata dataset, we only compare against Chain-of-Thought since the implementations for other baseline algorithms do not have access to similar music-specific knowledge bases. Despite this, we observed some interesting results. Chain-of-Thought does far worse on MusicBrainz-x-Wikidata than on the more general datasets based exclusively on Wikipedia/Wikidata (10.1%-13.8% vs. 25.2%-47.4%). This could be because LLMs are trained on vast amount of general knowledge such as that found in Wikipedia, but they are not trained with as much data from specific domains such as music. Besides the presence of KG interface and ASM with Tree-of-Traversals, this could be an additional reason why Tree-of-Traversals does 2.2 times as well as Chain-of-Thought on MusicBrainz-x-Wikidata. This demonstrates the importance of augmenting LLMs with domain-specific KGs and/or multiple KGs which the proposed Tree-of-Traversals is capable of."}, {"title": "4.4 Analysis of Baselines.", "content": "ReAct underperforms Chain-of-Thought in most cases. This phenomenon was seen in the original ReAct paper which noted that their approach significantly reduced hallucinations despite lower accuracy (Yao et al., 2022). Therefore, falling back on Chain-of-Thought results in an accuracy improvements for for Llama2-70b and Claude-Instant. We note that claude-instant vastly underperforms Llama2-70b on ReAct. The primary reason for this is claude-instant refuses to \"search\" people and apologizes after performing invalid actions. Despite this, ReAct\u2192CoT still improves over CoT on both 2WikiMultiHop and QALD-10. FLARE improves model performance on 2WikiMultiHop but not on QALD-10. This may be due to better overlap between the text knowledge base for 2WikiMultiHop."}, {"title": "5 Related Works", "content": "There is a large history of work that has looked into answering questions using a knowledge graph (Wu et al., 2019; Lan et al., 2021). The approaches can broadly be broken into those that attempt to parse the question into a logical form (Berant and Liang, 2014; Luo et al., 2018; Zhu et al., 2022), and information retrieval approaches (Bordes et al., 2015; Chen et al., 2019)\nEnhancement. Recently, researchers have looked into enhancing pretrained language models and LLMs using knowledge graphs. Many works have focused on incorporating knowledge graph data into LLMs through training, often with architectural changes to the model (Zhang et al., 2019; Wang et al., 2019; Peters et al., 2019; Yamada et al., 2020; He et al., 2021). Some of these have found success using specialized graph encoder layers (Yasunaga et al., 2021; Sun et al., 2021). Some have sought to mix this process with pretraining of the language model (Yasunaga et al., 2022). The limitations of including KGs during LLM training are: the models are incapable of incorporating KG updates without retraining, are not able to change KG source (e.g., a domain-specific one), and may have low explainability resulting from learning knowledge in model weights rather than explicit retrieval. In addition, these methods add complexity to the training process, increase cost, and do not work with LLM without access to model weights. As a result, scaling these methods has often been seen as too risky.\nOther methods treat a KG as a more complete source of truth and use the LLM to generate structured queries for the KG. Tianle et al. (2023) and Choudhary and Reddy (2023) teach the LLM to generate a logical KG query which then returns matching entities from the KG. These methods share similarities with the semantic parsing based"}, {"title": "6 Conclusion", "content": "Tree-of-Traversals is a powerful algorithm that enables LLMs to utilize KG reasoning with zero examples, no schema dependency, and no training. We demonstrate its efficacy experimentally on multiple LLMs and datasets. We hope Tree-of-Traversals continues to be developed and see value in studying integration with personalized user KGs"}, {"title": "7 Limitations", "content": "Tree-of-Traversals is slower than simpler retrieval alternatives. Improving the value function would reduce the number of LLM and KG API calls by avoiding incorrect paths along the tree to explore. Other engineering solutions, such as hosting graph servers, could be implemented to accelerate LLM and KG access. In terms of the token cost, the KG text representation is token efficient compared to many retrieval methods using unstructured knowledge bases as the latter tend to maximize usage of the LLM context window. However, compared to non-retrieval baselines, there is significant increase in token usage cost.\nThe types of KG questions that can be answered are limited by the context window, search depth, and LLM's reasoning ability. For instance, a very large aggregation (\u2018How many mountains have elevation above 3500 meters?') would require more entities than what fits in the LLM context. Future work could look at adding other actions to the ASM, such as aggregations, that could distill the local KG into more relevant information.\nEM-in is also an imperfect metric. False negatives can arise from discrepancies in date and number formatting, text formatting, and aliasing. False positives can arise in cases in which the model does not definitively answer but includes the correct answer in its response."}, {"title": "8 Ethical Impact", "content": "We do not anticipate Tree-of-Traversals to introduce new areas of risk but it may have unstudied effects on existing risks of LLMs or KGs. We highlight the following areas. (i) Tree-of-Traversals gives new capabilities to LLMs after training. While positive in terms of accuracy, we have not evaluated its effect on wider safety metrics. (ii) Our evaluation is limited to only English versions of KGs and datasets. Tree-of-Traversals should be evaluated in other languages to ensure consistent and fair experience. (iii) We have not performed analysis under misleading or deceptive knowledge graphs. Using a publicly modifiable knowledge graph does come with the risk that information could be deceptively changed.\nIn terms of positive ethical impact, making this research public democratizes access to knowledge-augmented LLMs as this method does not require"}, {"title": "B.1 Diversity Oversampling.", "content": "One problem with Tree-of-Thoughts is that when there are constrained options to choose from, the LLM becomes repetitive and fails to produce diverse outputs (Yao et al., 2023). Their solution used a \"propose prompt\" with additional instructions for proposing multiple distinct thoughts. However, this"}]}