{"title": "Uncertainty Quantification of Large Language Models through Multi-Dimensional Responses", "authors": ["Tiejin Chen", "Xiaoou Liu", "Longchao Da", "Jia Chen", "Vagelis Papalexakis", "Hua Wei"], "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities across various tasks due to large training datasets and powerful transformer architecture. However, the reliability of responses from LLMs remains a question. Uncertainty quantification (UQ) of LLMs is crucial for ensuring their reliability, especially in areas such as healthcare, finance, and decision-making. Existing UQ methods primarily focus on semantic similarity, overlooking the deeper knowledge dimensions embedded in responses. We introduce a multi-dimensional UQ framework that integrates semantic and knowledge-aware similarity analysis. By generating multiple responses and leveraging auxiliary LLMs to extract implicit knowledge, we construct separate similarity matrices and apply tensor decomposition to derive a comprehensive uncertainty representation. This approach disentangles overlapping information from both semantic and knowledge dimensions, capturing both semantic variations and factual consistency, leading to more accurate UQ. Our empirical evaluations demonstrate that our method outperforms existing techniques in identifying uncertain responses, offering a more robust framework for enhancing LLM reliability in high-stakes applications.", "sections": [{"title": "1 Introduction", "content": "Large Language Models (LLMs) have demonstrated exceptional capabilities in tasks ranging from code generation to clinical decision support [7, 13]. However, their deployment in high-stakes domains requires rigorous reliability verification, as studies reveal persistent hallucination and overconfidence issues [20, 43]. This challenge intensifies with commercial LLMs like GPT-4, Claude, and Gemini [2, 5, 34], where black-box access to architectures and parameters prevents internal confidence measurement.\nWhile uncertainty quantification (UQ) methods form the foundation of reliable AI systems [40], existing approaches face fundamental limitations in natural language generation (NLG). Traditional UQ techniques for classification [15] or regression [44] fail to address NLG's unique challenges: semantic equivalence despite lexical variation [26], and knowledge coherence beyond surface patterns [9]. Current LLM UQ methods exacerbate these issues by focusing on single uncertainty dimensions-either semantic entropy requiring white-box access [26] or knowledge-augmented approaches that propagate redundancy [10]."}, {"title": "2 Preliminaries", "content": "Modern uncertainty quantification (UQ) for black-box LLMs operates through two sequential stages: similarity measurement between responses and uncertainty estimation from these similarities. Let M denote a black-box LLM generating n responses {A\u00b9, ..., A\u207f} to input Q. The UQ task estimates confidence U through:\n$\\displaystyle U = f(S), S\\in \\mathbb{R}^{n \\times n}$ (1)\nwhere S is the similarity matrix with the (i, j)-th entry capturing the proximity of responses A\u2071 and A\u02b2, and f represents the estimation strategy. This formulation enables UQ without accessing internal model probabilities."}, {"title": "2.1 Problem Formulation", "content": "The foundation of reliable UQ lies in effective similarity measurement. We analyze two complementary approaches capturing different aspects of response quality."}, {"title": "2.2 Measuring Response Similarities", "content": "Semantic similarity focuses on surface-level consistency between responses. The Jaccard index [29] offers simple lexical comparison:\n$\\displaystyle S_{ij} = \\frac{A^i \\cap A^j}{A^i \\cup A^j}$ (2)\nWhile computationally efficient, Jaccard ignores word order and semantics. For deeper analysis, there is another common way to compute the semantic similarity, which uses DeBERTa's NLI capabilities [18]:\n$\\displaystyle S_{ij} = = (P_{\\text{entail}}(A^i, A^j) + P_{\\text{entail}}(A^j, A^i))$ (3)\nWhere Pentail (A\u2071, A\u02e1) the probability of A\u2071 entails A\u02b2 that is output from the NLI model.\nCompared with the Jaccard index, NLI-based scoring better captures semantic equivalence but remains sensitive to syntactic variation. For instance, paraphrased factual statements may receive low scores despite equivalent meaning. To the question How many students became heroes, The response These three became heroes and the response Andrew Willis, Chris Willis, Reece Galea share the factual knowledge that three students became heroes while their similarity from NLI models will be low as 0.015. Therefore, relying solely on responses from the semantic dimension may result in information loss."}, {"title": "2.2.1 Semantic Dimension", "content": "The knowledge dimension operates through a structured pipeline that transforms raw responses into factual representations. Given a question Q and its original response A\u2071, a knowledge representation K\u2071 could be generated through a knowledge mapping process by extracting explicit claims: K\u2071 = Maux (Q, A\u2071) and augmenting the response, where Maux denotes"}, {"title": "2.2.2 Knowledge Dimension", "content": "With similarity matrices constructed, existing UQ methods employ two principal ways to estimate uncertainty, each offering unique advantages and limitations."}, {"title": "2.3 Estimating Uncertainty", "content": "Proposed by Kuhn et al. [26], this method groups responses into equivalence classes using bidirectional entailment checks from an NLI model. Formally, responses A\u2071 and A\u02b2 are merged into the same semantic set if:\n$\\displaystyle P_{\\text{entail}}(A^i, A^j) > P_{\\text{contra}}(A^i, A^j) \\text{ and } P_{\\text{entail}}(A^j, A^i) > P_{\\text{contra}}(A^j, A^i)$ (4)\nThe uncertainty measure UNumSet equals the number of resulting semantic sets. This approach aligns with spectral graph theory. Because when using binary adjacency matrices (Wij \u2208 0, 1), the number of zero eigenvalues in the graph Laplacian corresponds to the number of connected components [38]. While this method discretizes continuous semantic relationships, it fails to capture partial meaning overlaps."}, {"title": "2.3.1 Number of Semantic Sets (UNumSet)", "content": "Building on spectral graph principles [3, 29], this method quantifies uncertainty through the eigenvalues \u03bb\u03ba of the normalized graph Laplacian L = I \u2013 D\u207b\u00b9/\u00b2WD\u207b\u00b9/\u00b2:\n$\\displaystyle U_{\\text{EigV}} = \\sum_{k=1} max(0, 1 - \\lambda_k).$ (5)\nHere, eigenvalues \u03bbk encode connectivity. fragmented graphs (low consistency in responses and thus high uncertainty) have more small eigenvalues. Compared with UNumSet, this method is able to capture possible overlapping semantic relationships."}, {"title": "2.3.2 Graph Laplacian", "content": "Now, we compare the difference between similarity matrices from knowledge and semantic dimensions. In detail, we use the NLI model to obtain the similarity matrix. In Table 1, we present the mean values and the proportion of similarity scores greater than 0.55 in the similarity matrices. The results show that similarity matrices in the knowledge dimension have more large value as well as a larger mean value. This reveals the knowledge dimensions' superior consistency. These results highlight the importance of multi-dimensional analysis since semantic features capture response variability, while knowledge features track factual consistency hidden"}, {"title": "2.4 Dimensional Analysis", "content": "In this section, we introduce our methods: Multi-Dimensional Uncertainty Quantification (MD-UQ)."}, {"title": "3 Methodology", "content": "While our methodological framework generalizes to multiple response dimensions, this work focuses on two well-established and complementary dimensions: the semantic dimension capturing surface-level linguistic patterns, and the knowledge dimension encoding factual consistency [9, 10, 37]. The semantic similarity matrix S is computed using established natural language inference techniques [18], while SK leverages auxiliary LLM-generated claim comparisons as detailed in Section 2.2.2. By jointly analyzing these dimensions through tensor operations, our framework addresses the limitations of single-axis approaches documented in Section 2, particularly the inability to distinguish lexical variation from factual inconsistency. As illustrated in Fig. 3, our approach integrates these dimensions through three key phases:\n(1) Tensor Representation (Section 3.2): Construct a multi-dimensional similarity tensor S \u2208 \u211d\u207f\u02e3\u207f\u02e3\u00b2 by concatenating semantic (S) and knowledge (SK) similarity matrices derived from n responses\n(2) Tensor Decomposition (Section 3.3): Apply orthogonal tensor decomposition to isolate dimension-specific features and suppress redundant information\n(3) Ensemble Scoring (Section 3.4): Combine decomposition residuals across dimensions to compute the final uncertainty measure Ufinal"}, {"title": "3.1 Overview", "content": "After obtaining the similarity matrices S and SK, the next question will be how to fully utilize two similarity matrices to represent the information from multiple dimensions. There are many methods such as concatenating two similarity matrices within 2D dimensions:\n$\\displaystyle S_{\\text{concat}} = \\begin{bmatrix} S\\\\ S_K \\end{bmatrix} \\in \\mathbb{R}^{n \\times (n+n)}$ (6)"}, {"title": "3.2 Tensor Representation", "content": "In our work, we utilize two prominent tensor decomposition methods, the Tucker decomposition and the Canonical Polyadic (CP) decomposition, to extract information contained in S and calculate the final uncertainty measures. CP decomposition represents the tensor as a sum of rank-one components, offering a more interpretable model. Its simplicity is advantageous in many scenarios, but it can be too rigid when the data exhibits rich interactions that a rank-one approximation fails to capture-potentially resulting in suboptimal solutions. On the other hand, although Tucker decomposition excels at capturing high-order interactions, Tucker decomposition may converge to a local optimum due to its sensitivity to initialization and cause an unstable result. Therefore, in our paper, we use two tensor decomposition methods. We briefly introduce them below."}, {"title": "3.3 Tensor Decomposition", "content": "The Tucker decomposition is a higher-order generalization of the singular value decomposition (SVD) and represents a tensor as a core tensor multiplied by factor matrices along each dimension [11]. Formally, for a Nth-order tensor X \u2208 \u211d\u1d35\u00b9\u02e3\u1d35\u00b2\u02e3\u2026\u02e3\u1d35\u1d3a, the Tucker decomposition is expressed as:\n$\\displaystyle X \\approx G \\times_1 U^{(1)} \\times_2 U^{(2)} ... \\times_N U^{(N)},$ (8)\nwhere G\u2208 \u211d\u1d3f\u00b9\u02e3\u1d3f\u00b2\u02e3\u2026\u02e3\u1d3f\u1d3a is the core tensor that captures the interactions among the dimensions and U\u207d\u2071\u207e \u2208 \u211d\u1d35\u2071\u02e3\u1d3f\u2071 for i = 1,..., N are the factor matrices associated with each dimension. Without loss of generality, we can assume that the Tucker factor matrices U\u207d\u2071\u207e are orthogonal and jointly form subspace bases of the different dimensions in the tensor. In that sense, Tucker decomposition jointly models the dimensions of the tensor while allowing the individual to model the subspaces of each dimension. Based on this feature, Tucker decomposition offers flexibility in choosing the ranks (R1, R2, ..., RN) for different dimensions and each dimension n can have a different rank Rn. A common way to compute the Tucker decomposition is via the Higher-Order Singular Value Decomposition (HOSVD) [11].\nDifferent from Tucker Decomposition, which might be sensitive to the noise in the tensor due to its high parameter complexity, CP decomposition offers a more robust alternative by representing the tensor as a sum of rank-one components. Specifically, for an Nth-order tensor X, the CP decomposition is expressed as:\n$\\displaystyle X \\sim \\sum_{r=1}^R \\lambda_r a_r^{(1)} \\circ a_r^{(2)} \\circ ... \\circ a_r^{(N)},$ (9)\nwhere R is the CP rank, \u03bbr are scalar weights, a\u1d63\u207d\u207f\u207e \u2208 \u211d\u1d35\u207f are the factor vectors associated with the n-th mode, and \u2218 denotes the outer product. CP decomposition can be computed using the Alternating Least Squares algorithm [25]. Similar to the Tucker decomposition, the CP rank R can be chosen flexibly.\nAfter we apply different tensor decomposition to S, we can obtain the reconstructed tensor with different rank. For example, if we apply CP decomposition to S with rank R, we have:\n$\\displaystyle S \\approx S_{CP} = \\sum_{r=1}^R \\lambda_r a_r^{(1)} \\circ a_r^{(2)} .... a_r^{(N)}$ (10)\nThen we could compute the reconstruction error, which measures how much information could be captured with rank R:"}, {"title": "Uncertainty", "content": "$\\displaystyle E_R^{CP} = \\frac{\\vert\\vert S - S_{CP} \\vert\\vert_F}{\\vert\\vert S \\vert\\vert_F}$ (11)\nwhere || ||F is the Frobenius norm. Similarly, we could have a reconstruction tensor and error for Tucker decomposition with rank [R, R, 2]:\n$\\displaystyle E_R^{\\text{tucker}} = \\frac{\\vert\\vert S - S_{\\text{tucker}} \\vert\\vert_F}{\\vert\\vert S \\vert\\vert_F}$ (12)\nHere, we always use the last mode uncompressed because we hope our method can analyze the two dimensions of responses separately. We also show an experiment that uses tucker with the last rank 1 in Section 4.3.\nIf the responses are more consistent, then S has an easier structure and thus it is easier to use a low-rank structure to capture the information. Therefore, the reconstruction error is expected to become lower when the responses are more consistent, i.e. the model is more confident. Therefore, we could directly use $E_R^{CP}$ or $E_R^{\\text{tucker}}$ as the uncertainty measure. To empirically prove this, we draw a figure to observe the relationship between different accuracy and reconstruction errors. We define the accuracy of a question to the mean accuracy of its n responses. We present the results in Fig. 4, which shows a higher accuracy sample indeed intends to have a lower reconstruction error."}, {"title": "Ensemble Uncertainty", "content": "Though it is possible for us to directly use $E_R^{CP}$ or $E_R^{\\text{tucker}}$ as the uncertainty measure, we further enhance the uncertainty measures by ensemble methods. Firstly, the choice of rank R might influence the quality of $E_R^{CP}$ or $E_R^{\\text{tucker}}$. Therefore, our method ensemble all the ER from R = 1 to R = n. In detail, we have an uncertainty ensemble from all rank R for CP decomposition:\n$\\displaystyle U_{CP} = \\frac{\\sum_{r=1}^R E_R^{CP}}{n}$ (13)\nSimilarly, we compute the uncertainty ensemble from all rank R for Tucker decomposition:\n$\\displaystyle U_{\\text{tucker}} = \\frac{\\sum_{r=1}^{\\text{R}} E_R^{\\text{tucker}}}{\\text{n}}$ (14)\nFinally, to ensure robust and accurate uncertainty estimation, we ensemble the uncertainty from both decomposition methods to obtain the final uncertainty. With two uncertainties from two tensor decomposition methods, we could have multiple meaningful ways to ensemble the results in an unsupervised way. We introduce two different methods with different intuitions.\nA simple yet effective ensemble is the summation. The summation means that we assign an equal weight to the uncertainty results obtained from each rank and from both decomposition methods. This approach is based on the intuition that each decomposition method captures the different aspects of information and by adding two uncertainties up, we ensure that every method's contribution is treated evenly and thus obtain a more comprehensive information in the final uncertainty. In detail, we have:\n$\\displaystyle U = U_{\\text{Tucker}} + U_{CP}.$ (15)\nAs mentioned above, a lower U indicates a higher consistency between responses and thus a lower uncertainty.\nThe second ensemble strategy is based on the minimum operator. The intuition behind this approach is that if one of the tensor decomposition methods produces a low uncertainty estimate for a given sample, then the overall uncertainty should also be considered low. In other words, we rely on the most confident (i.e., smallest uncertainty) prediction provided by either method. Thus, we define the final uncertainty as:\n$\\displaystyle U = \\min (U_{\\text{Tucker}}, U_{CP}).$ (16)\nThis Min strategy can be particularly beneficial when one of the decomposition methods is prone to overestimating uncertainty. By selecting the minimum, we effectively mitigate the impact of any overly pessimistic estimates, while still preserving the robust information provided by the other method."}, {"title": "3.4", "content": "We conduct comprehensive experiments across multiple datasets and model architectures to validate our method's ability to decouple explanation robustness from classification robustness. Our evaluation addresses three key research questions:"}, {"title": "4 Experiments", "content": "As mentioned in Section 2, following prior works [28], we focus on open-form question-answering (QA) tasks in this paper. We adopt 4 different classic QA datasets. Coqa [32] is a conversational question-answering dataset that contains dialogues with free-form answers grounded in diverse passages, which is the easiest dataset among all datasets. HotpotQA [42] is a multi-hop QA dataset that demands reasoning over multiple Wikipedia paragraphs to derive correct answers. NQ-Open [27] consists of real-world queries from Google Search, requiring models to retrieve and answer ques-tions without explicit context, which is the hardest dataset."}, {"title": "4.1 Experimental Setup", "content": "We evaluate MD-UQ on Llama family [36], which is the one of the most popular LLMs. In detail, we use Llama-2-13b and Llama-2-7B to demonstrate the effectiveness of MD-UQ with different model sizes and use Llama-3.1-8B [14] to that MD-UQ could also work on the different version of Llama. To further demonstrate the generalization ability for other architectures, we also use Phi4 [1] and Deepseek-R1-distill-7B [17] in our paper."}, {"title": "4.1.1 Datasets", "content": "Effective uncertainty measures should accurately represent the reliability of LLM responses, with higher uncertainty more likely leading to incorrect generations and vice versa [26, 29]. Following prior works [10, 29], we mainly use UQ values to predict whether an answer is correct or not. Following prior works [10, 29], we will use Area Under Receiver Operating Characteristic (AUROC) and Area Under Accuracy Rejection Curve (AUARC) as evaluation metrics, where a higher AUROC or AUARC demonstrates better uncertainty measures. To compute AUROC and AUARC, the accuracy of each original response is required. Following previous works [10, 29], we use another LLM to provide correctness from 0-100 to each response. If the correctness is greater than 70, we label the response as correct. In this paper, we use Qwen-34B [6] to evaluate the correctness."}, {"title": "4.1.2 Models to Evaluate", "content": "In this paper, we mainly use llama-2-13b [36] as the auxiliary models to extract the knowledge dimension of responses. To demonstrate the robustness of MD-UQ with different knowledge-extracted models, we also contain the results for different LLMs as knowledge-extracted models."}, {"title": "4.1.3 Evaluation Metrics", "content": "In this paper, we compared MD-UQ with baselines that use semantic dimension response and knowledge dimension response. For semantic dimension, we mainly compared with methods that come from Lin et al. [29]. In detail, we incorporate six distinct methods from Lin et al. [29], which differ based on the operations applied after computing similarity and whether they utilize agreement (entailment) probabilities or disagreement (contradiction) logits to construct the similarity matrix. For knowledge dimension, we use D-UE [10] and p(true) [23] as the baselines. Note that we use p(true) on the knowledge dimension of response. We show the detailed explanations of all baselines in Table 3"}, {"title": "4.1.4 Knowledge Extracted Models", "content": "In this section, we explore whether MD-UQ has better uncertainties compared with state-of-the-art uncertainty quantification methods. In Table 2, we compare MD-UQ with 8 baselines across three different datasets and five different models as introduced in Section 4.1 In detail, we have the following observations:\n\u2022 Compared with all baseline methods, MD-UQ achieves the best performance overall. Especially when we consider AUROC. For AUARC, MD-UQ achieves the best performance for NQ_Open while MD-UQ also achieves the comparable performance for CoQA in most scenarios. These results demonstrate that MD-UQ has better quantify uncertainties overall.\n\u2022 Among all datasets, MD-UQ achieves the highest performance improvement on NQ_Open, which is the most difficult dataset among all datasets and may lose to baselines for an easier dataset like CoQA. This indicates MD-UQ could perform even better when the"}, {"title": "4.1.5 Baselines", "content": "In this section, we use more experiments to prove the necessity of using information from both semantic and knowledge dimensions as well as using tensor decomposition. In detail, we consider the following methods: 1) MD-UQ with only semantic responses, 2) MD-UQ with only knowledge responses and 3) Concatenating similarity matrices from semantic and knowledge dimensions into a 2D matrix and applying SVD, 4) only using one tensor decomposition. In Fig. 5, we show the comparison between MD-UQ and other methods. The results show that MD-UQ consistently outperforms its variants and SVD method that repeated information will dominate the features, showing the effectiveness of our framework."}, {"title": "4.2 Does MD-UQ have better quantify\nuncertainties? (RQ1)", "content": "Knowledge extracted models influence the claim extraction in MD-UQ as stated in Section 2.2.2. Therefore, in this section, We test the robustness of MD-UQ on various knowledge extracted models. unlike using llama2-13b in Section 4.2 and Section 4.3, we conduct experiments on CoQA and NQ_open using llama2-7b and llama3.1 as the knowledge extracted models, We show the results in Fig. 6. From the figure, we can see that using Phi4 could even achieve a better result, indicating MD-UQ has more potential with the development of LLMs."}, {"title": "4.3 How do different ensemble methods and\ninformation from both dimensions help?\n(RQ2)", "content": "Different accuracy thresholds lead to different accuracy and influence the evaluation of uncertainties. In the previous experiments, we all set the accuracy threshold to 70 as mentioned in Section 4.1. To test the robustness of MD-UQ under different accuracy thresholds, we choose an extra dataset TriviaQA [22], which is considered the easiest dataset, and NQ_Open, which is the most challenging dataset in our paper to conduct experiments. We show the results with accuracy thresholds of 70 and 90 in Table 4. From the results, we can see that increasing the accuracy threshold decreases the performance of all baselines while the performance of MD-UQ could even increase for datasets with different difficulties, showing the robustness of MD-UQ in different settings."}, {"title": "4.4 Is MD-UQ robust to different settings? (RQ3)", "content": "Finally, different similarity metrics lead to different similarity matrices. Therefore, to test whether MD-UQ also has a good performance for different similarities, we"}, {"title": "4.4.1 Different Knowledge Extracted Models", "content": "Uncertainty quantification for traditional machine learning problems such as regression or classification has been well studied [4, 31,"}, {"title": "4.4.2 Different Accuracy Thresholds", "content": "In conclusion, this study introduces a novel multi-dimensional uncertainty quantification framework, MD-UQ, for large language"}, {"title": "4.4.3 Different Similarity Metrics", "content": "models, addressing the limitations of conventional uncertainty estimation approaches. By leveraging both semantic similarity and knowledge coherence dimensions, our method disentangles and integrates complementary information to achieve a more robust uncertainty representation. Through the application of tensor decomposition techniques, MD-UQ effectively reduces redundant information and enhances the reliability of uncertainty assessments. Experimental results across multiple datasets and models demonstrate the superiority of our framework in distinguishing uncertain responses, particularly in complex and high-stakes environments."}, {"title": "5 Related Works", "content": "Most previous works on uncertainty quantification for nature language processing (NLP) consider text classifiers [12, 21, 24] or text regressors [16, 41]. To transfer NLP tasks into a classification task, previous work may consider using multi-choice question answering datasets or transferring questions into multi-choice form [24].\nHowever, considering NLP tasks as simple classification tasks overlooks the generation nature of the LLMs [26]. To overcome this disadvantage, recent works focus on open-ended generation tasks. The first branch of research is inducing the LLMs to output their uncertainty along with the response to solve UQ for open-ended generation tasks [23, 30, 35]. Lin et al. [28] even fine-tuned LLMs so that LLMs can output better uncertainty. This is a straightforward solution. However, fine-tuning the LLMs to obtain a better uncertainty measure requires white-box access to the models and may cost computation resources. Kuhn et al. [26] first propose semantic entropy, which calculates entropy considering semantic information. However, such an approach still requires the token-related probability values as input.\nTo compute uncertainty for black-box MLLMs, previous works take a step further compared with semantic entropy and utilize the similarity and consistency between different generated answers from the same query to the LLMs. Lin et al. [29] uses NLI models to obtain the similarity. Then they treat the similarity matrix as from a weight connected graph and compute uncertainty using the structure of the graph such as using eigenvalues from the graph Laplacian. Chen and Mueller [8] identify unreliable or speculative answers by computing a confidence score. However, both works only consider semantic similarity, lacking an analysis of the deep meaning of the output. Da et al. [10] contains a claim level response augmentation. However, augmented responses share much common information with original responses, and such common information is not considered by Da et al. [10], causing a potential performance downgrade. Therefore, in our paper, we do not only generate implicit knowledge behind the original answers but also use tensor decomposition to fully utilize the additional information."}, {"title": "6 Conclusion", "content": "33, 44].\nTo transfer NLP tasks into a classifica-tion task, previous work may consider using multi-choice ques-tion answering datasets or transferring questions into multi-choiceform [24].However, considering NLP tasks as simple classification tasks overlooks the generation nature of the LLMs [26]. To overcome thisdisadvantage, recent works focus on open-ended generation tasks.The first branch of research is inducing the LLMs to output theiruncertainty along with the response to solve UQ for open-endedgeneration tasks [23, 30, 35]. Lin et al. [28] even fine-tuned LLMs sothat LLMs can output better uncertainty. This is a straightforward solution. However, fine-tuning the LLMs to obtain a better uncer-tainty measure requires white-box access to the models and maycost computation resources. Kuhn et al. [26] first propose semanticentropy, which calculates entropy considering semantic informa-tion. However, such an approach still requires the token-relatedprobability values as input.To compute uncertainty for black-box MLLMs, previous workstake a step further compared with semantic entropy and utilize thesimilarity and consistency between different generated answersfrom the same query to the LLMs. Lin et al. [29] uses NLI modelsto obtain the similarity. Then they treat the similarity matrix asfrom a weight connected graph and compute uncertainty using thestructure of the graph such as using eigenvalues from the graphLaplacian. Chen and Mueller [8] identify unreliable or speculative answers by computing a confidence score. However, both works only consider semantic similarity, lacking an analysis of the deep meaning of the output. Da et al. [10] contains a claim level re-sponse augmentation. However, augmented responses share muchcommon information with original responses, and such common information is not considered by Da et al. [10], causing a potential performance downgrade. Therefore, in our paper, we do not only generate implicit knowledge behind the original answers but also use tensor decomposition to fully utilize the additional information."}]}