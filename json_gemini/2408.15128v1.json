{"title": "Evaluating the Energy Consumption of Machine Learning: Systematic Literature Review and Experiments", "authors": ["Charlotte Rodriguez", "Laura Degioanni", "Laetitia Kameni", "Richard Vidal", "Giovanni Neglia"], "abstract": "Monitoring, understanding, and optimizing the energy consumption of Machine Learning (ML) are various reasons why it is necessary to evaluate the energy usage of ML. However, there exists no uni-versal tool that can answer this question for all use cases, and there may even be disagreement on how to evaluate energy consumption for a specific use case. Tools and methods are based on different ap-proaches, each with their own advantages and drawbacks, and they need to be mapped out and explained in order to select the most suitable one for a given situation. We address this challenge through two approaches. First, we conduct a systematic literature review of all tools and methods that permit to eval-uate the energy consumption of ML (both at training and at inference), irrespective of whether they were originally designed for machine learning or general software. Second, we develop and use an experi-mental protocol to compare a selection of these tools and methods. The comparison is both qualitative and quantitative on a range of ML tasks of different nature (vision, language) and computational com-plexity. The systematic literature review serves as a comprehensive guide for understanding the array of tools and methods used in evaluating energy consumption of ML, for various use cases going from basic energy monitoring to consumption optimization. Two open-source repositories are provided for further exploration. The first one contains tools that can be used to replicate this work or extend the current review. The second repository houses the experimental protocol, allowing users to augment the protocol with new ML computing tasks and additional energy evaluation tools.", "sections": [{"title": "1 Introduction", "content": "Reducing the energy consumption of Machine Learning (ML) and Software in general has many motiva-tions. Besides the environmental impact of computing, other factors include the actual cost of energy [24], and the energy limitations of battery powered systems such as embedded or mobile devices [27, 114, 44]. Most of the studies reviewed here express concern about the current and future growth of the Information and Communication Technology (ICT) energy consumption and carbon footprint, with data centers being the fastest growing source of emissions in the ICT sector [41]. Regarding Artificial Intelligence (AI) and ML, the study [130] examined the environmental impact of Natural Language Processing (NLP) tasks, such as Bert, Transformer, and GPT-2 training, or Neural Architecture Search (NAS), and attracted considerable attention in 2019. The authors find that training BERT-base (one of the the smaller versions of BERT) produced about 652 kg of carbon dioxide equivalents (CO2eq), which is equivalent to the emissions of a round-trip flight between New York and San Francisco per passenger [130, 14]. They also estimate that the neural architecture search and training of the Transformer T2T has an impact equivalent to five times that of a car life time (including fuel).\nThe increasing attention to the energy impact of ICT let researchers addressing the energy efficiency of ICT to shift the focus from maximizing performance based on physical capabilities to minimizing energy and carbon costs while maintaining the same level of performance, giving rise to the concept of \u201cGreen ICT\u201d [55]. Similar considerations have also emerged in AI, with the notion of \u201cGreen AI\u201d being introduced as an alternative to \u201cRed AI\u201d (although both are considered important). The latter aims to develop machine learning models with the highest accuracy, at the expense of massive computational power and energy con-sumption, whereas the former seeks to create models with lower computational power and fewer carbon emissions [122]. Examples of approaches to improve energy efficiency of software may be found in [94] and [124, Appendix B]. The latter study notably stresses how essential accurate evaluation of energy con-sumption of an application execution is in order to minimize this consumption. In the field of machine learning, many studies ask that energy (and carbon) cost of ML is reported in addition to accuracy metrics, notably to increase awareness and incentivise energy efficient ML algorithms [60]. Some machine con-ferences, such as ICML or NeurIPS, now ask contributions to declare the amount of compute and type of resources used (e.g., type of GPUs, type of platform) needed for their experiments. Studies also stress the need to render more available the reporting of energy and carbon metrics to the machine learning commu-nity [43, 42, 60], by easing the process of collecting these metrics and familiarising the community with the available approaches.\nOur objective is to explore the different ways of evaluating the energy consumption of ML computing tasks, across all application domains. As we have seen above, tracking energy consumption is also a concern for computing tasks in general, this is why we also study ways of evaluating the energy consumption of software in general, thus also using terms such as \u201csoftware\u201d or \u201capplication.\u201d Note that when assessing the total environmental impact of computing tasks, one should also take into account the impact of production and disposal of hardware (routers, computers, servers, for instance) [10]. However, the latter impact is not in the scope of this work."}, {"title": "1.1 Background", "content": "To evaluate the energy consumption (and carbon footprint) of a computing task, various methods and tools have been developed. Some are tailored for machine learning, while others can be used for general comput-ing tasks. One can find several literature reviews and/or experimental comparison of such tools and methods. Among them the following four are particularly relevant for our interests: [42, 10, 66, 37]. Specifically, [42] provides a comprehensive review of a broad set of energy consumption evaluation methods deemed ap-"}, {"title": "1.2 Research Question and Contributions", "content": "The following research question is at the origin of this work:\nWhat tools and methods currently permit to evaluate the energy consumption of machine learning computing tasks?\nHere, \"method\" entails that it is not yet implemented as a tool. Furthermore, the term \u201cevaluation\" includes both \"measuring\u201d and \u201cestimating,\u201d with or without the need to run the computing task. More precisely, for each discovered tool or method, we look to cover the following aspects of the research question:\n[Approach] What approach does this tool or method rely on?\n[Context] For what purpose, in what context has this tool or method been designed?\n[Constraints] What are the constraints and limits of this tool or method?\nOur contributions are the following ones.\nContribution 1. Our first contribution is that this work is the broadest review in terms of scope and number of studies reviewed, see Figure 1. This is due to the following three choices. Firstly, we propose a Systematic Literature Review (SLR), meaning that the search, selection, and analysis of studies are based on an a priori defined protocol, that we describe in detail in Section 2. This is in contrast with the four works presented in Section 1.1 and additional surveys found during our review process, apart from [10, 111] that however have a narrower research scope. Secondly, the scope of our review includes all types of energy consumption evaluation approaches, and all application domains in the sense that we consider tools and methods developed not just for ML, but also for software in general (for monitoring, optimization, etc.). Thirdly, concerning ML application, we do not restrain ourselves to a specific subset of ML applications.\nContribution 2. Our second contribution is an experimental comparison of evaluation tools and methods based on different approaches, on different ML computing tasks. For example, some tools and methods are based on direct measurements at the power outlet, others on vendor-specific sensors, and yet others on analytical estimation models (more detail on the different approaches will be provided in Section 4.1), enabling us to observe the influence of the underlying approach on the result of the tool. The selected computing tasks include training tasks of different nature (vision, language) and with different computational complexities, permitting us to evaluate the behaviour of the tested tools and methods in different settings."}, {"title": "1.3 Paper Overview and Outline", "content": "This article is organized as follows. In Section 2 we define the protocol of the SLR, including how studies are collected (Section 2.1) and selected (Section 2.2), and how studies are classified and data is extracted from them (Section 2.3). Section 3 details the actual execution of the protocol, notably the timeline and the number of papers identified during the search (and selection) steps. Then, in Section 4, we present the se-lected results, first introducing a taxonomy of the identified papers (Section 4.1), then presenting the selected primary and secondary studies in Sections 4.2 and 4.3, respectively. Finally, we provide experimental results where a selection of tools is tested on different ML training tasks in Section 5, and give our conclusions in Section 6."}, {"title": "2 Protocol of the Review", "content": "In this section, we present the research protocol of this SLR, which is mainly based on the guidelines provided in [71]. The protocol permits to built a pool of items (scientific articles, reports, etc.) from which data is then extracted. We may divide the protocol in three main steps:\n1. collection of a pool of items,\n2. selection of the items,\n3. classification the selected items and data extraction.\nAs we see in more detail in the following sections, we target items in which the authors have developed a specific method or tool, whether or not they have been specifically designed for ML applications, and we also target items in which the authors have tested methods and tools built by others."}, {"title": "2.1 Collection of a Pool of Items", "content": "To cover publications in the domains of Computer Science and Software Engineering, we use 3 data sources. On the one hand, we use the following two digital databases: ACM Digital Library, an academic database for computer science, and IEEE Xplore Digital Library, which covers journals and conference papers, tech-nical standards, as well as some books, on electrical engineering, computer science, and electronics. We complement these data sources by the Google Scholar search engine (GS). Indeed, GS covers a larger por-tion of the literature than most data sources, as well as much unpublished work across all scientific fields and in particular those of interest here, i.e., machine learning, computing, and energy.\nEach of these data sources has its own specificity. The data source presenting most constraints for the systematic search process is GS. First, a search query may contain at most 256 characters. Second, for a given query, GS provides at most 1000 results even if the actual number of results associated to this query (which is displayed by GS) is greater. Finally, the GS official interface only permits the user to save results to the user's Google Scholar Library by selecting the star icon, and then exporting said library. GS tends to block any behavior deviating from this usage mode. However SerpAPI permits to circumvent this issue (see https://serpapi.com/). ACM permits to export results page by page (in BibTeX, EndNot or ACM Ref format), and the maximum number of results displayed on a single page is 50. IEEE permits to export all results at once (in csv format), though only the 2000 first results will be exported."}, {"title": "2.1.2 Initial Pool", "content": "The construction of our systematic review protocol notably builds upon an initial pool identified through some less structured search on the internet (whose results have been verified by a person) and on the basis of suggestions from experts in the domain.\nThis initial pool contains 13 items describing the development of a tool: Carbon-Tracker [8], Code-Carbon, previously developed under the name Energy-Usage [83], Deep-Neural-Network-Estimation-Tool [146], Eco2AI [14], ESAVE [106], Experiment-Impact-Tracker [60], PowerJoular and JoularJX [101], Green Al-gorithms [75], LIKWID-powermeter [135], ML-CO2-Impact [73], PMT [24], PowerAPI [13], Cumulator [134]. The initial pool also contains 7 studies describing methods: [117, 115] (SyNERGY), [123], [124], [127], [130], [112] (for federated learning), and [29]. It contains as well 5 secondary studies (reviews): [10], [43], [37], [102], and [66].\nWe are also aware of four tools without any associated scientific study: Energy-Scopium, PyJoules, Perf, Scaphandre. References to such \u201cseparate-tools\" that do not have any corresponding scientific study, are\""}, {"title": "2.1.3 Keywords", "content": "To search for items, we look for results containing, in the title field, at least one word from each of the three following lists of keywords:\n(i) machine learning, deep learning, computing, information and communications technology, ICT, ar-tificial intelligence, AI, natural language processing, NLP, neural network, neural networks, CNN, DNN, computation, computations, software, process-level, server, virtual machine, federated learn-ing, distributed learning;\n(ii) measure, measuring, estimate, estimation, consumed, consumption, predict, prediction, predicting, track, tracking, report, reports, reporting, account, quantify, quantifying, monitor, monitoring, evalu-ate, evaluating;\n(iii) energy, power, environmental impact, carbon footprint, carbon emissions, carbon impact.\nThe first category of keywords initially also contained the words \u201cprocess\u201d and \u201cprocesses.\u201d The latter have finally been removed because they induced too many irrelevant results pertaining to industrial processes. As explained in Section 2.1.1, GS comes with a number of constraints. Mainly in view of reducing the number of results provided by GS, we simultaneously exclude all results containing any of the following keywords:\n(iv) wind, building, buildings, vehicles, homes, ships, solar, photovoltaic, vehicle.\nHere \u201cCNN\u201d, \u201cNLP\u201d and \u201cDNN\u201d correspond to Convolutional Neural Network, Natural Language Process-ing and Deep Neural Network, respectively.\nIn the case of IEEE, we use an additional filter based on metadata. We select only the papers for which the \"Publication Topics\" contains at least one of the following values: \u201cpower consumption,\u201d \u201cenergy consump-tion,"}, {"title": "2.1.4 Building Queries", "content": "Each of the selected data sources allows for the use of the operators AND, OR, NOT, parenthesis and quo-tation to search for a specific phrase. In the first step, search by keywords, we use these operators and the keywords presented in Section 2.1.3, to build appropriate queries for each of the data sources. The syntax of the queries differs slightly for the different data sources (see Appendix A.2). In the case of GS, the original query is actually divided into a total of 103 sub-queries in order to meet the constraints of the data source (see Section 2.1.1). The results of these sub-queries are then merged together, removing the duplicates."}, {"title": "2.2 Selection of the Items", "content": "We consider different dimensions for each item (relevance, type of literature, accessibility, language) and we include items which satisfy at least one inclusion criterion for each aspect. The inclusion criteria are as follows:\n\u2022 Relevance to research question:"}, {"title": "2.2.1 Selection Criteria", "content": "include items where the authors develop tools or methods (not shaped into tools) that can mea-sure, estimate or predict the energy consumption (or power profile) of machine learning (training and/or inference); if the tool/method has not been specifically designed for machine learning, but rather for a broader range of computing tasks, the item should still be included;\ninclude items where tools or methods are being used for measuring/estimating the energy con-sumed by machine learning, even though not developed by the authors;\n\u2022 Literature type:\ninclude \"articles\u201d: peer-reviewed scientific articles (journals, conferences, workshops), or parts of books;\ninclude \"preprints\u201d: non-peer reviewed scientific articles, which may for instance be found on arXiv, Reasearch Gate, Hal, as well as on the author's personal website;\ninclude other materials and research produced outside of the traditional commercial or academic publishing and distribution channels, such as technical reports, thesis, white papers, etc.;\n\u2022 Accessibility: only include items for which the full text is available;\n\u2022 Language: only include items written in English."}, {"title": "2.2.2 Semi-Automatic Selection", "content": "Our first selection step is a semi-automated selection phase. This phase is based on the results' titles and on the relevance to the research question only. It consists in identifying words (among all words contained in the results' titles) that rule a title containing any of these words, as off-topic. Indeed, our query captures studies on energy efficiency in the domain of renewable energies, manufacturing, construction, etc. However, many of these studies' titles contain common words that permit to easily identify them as off-topic with respect to our research question. The list of words and pairs of words to exclude from the titles is provided in Appendix A.3."}, {"title": "2.2.3 Selection by Hand", "content": "The second part of the selection process is based on assessors reading the results' titles, abstracts and full text if necessary. Three assessors share this task. Doubts on a result's selection are resolved through discussion with another assessor. We divide the selection by hand in two parts. The first part is solely based on the selection criteria described in the Section 2.2.1.\nThe second part is based on additional selection criteria that have been added during the protocol application. The aim of this second part of the selection by hand, is to reduce the size pool of selected items, by excluding items least relevant to our research question. Here, we additionally exclude items for which both:\n\u2022 the authors have not created a method or tool, but rather used one created by others,\n\u2022 the authors have not tested this method or tool on ML applications, but rather on other computing tasks."}, {"title": "2.3 Classification of the Selected Items and Data Extraction", "content": "In the fourth step, we classify the results selected in the third step according to two criteria:\n1. First, is the result a primary study or a survey? Then, if the result is a primary study, has a tool or method been created by the authors or not? (The latter case implies a tool or method is used by the authors.) We provide one of the three following values: \u201cYes \u2013 creation,\u201d \u201cNo no creation,\" \"Survey.\""}, {"title": "2.3.2 Data Extraction Forms", "content": "We prepare data extraction forms for all five groups of items described in 2.3: YY, NY, YN, SN, and SY. The results of these extractions are presented in Section 4. Lets us start with primary studies.\nGroup yy. For items with tool creation and applications to ML we ask questions belonging to six cate-gories that we call \u201cstudy,\u201d \u201cdetail,\u201d \u201ctarget task,\u201d \u201cconstraints,\u201d \u201cavailable,\u201d and \u201ccites.\u201d The questions are the following.\n\u2022 Study:\nProvide the name of the tool or method, or \u201cName Unspecified\u201d (NU) for tools and methods that are unnamed.\nProvide the reference of the item.\nProvide the publication or appearance year of the item.\n\u2022 Detail:\nWhat is the approach behind the method or tool developed by the authors (e.g., estimation model, sensors, measurements, etc.)? If it is an estimation model, provide detail on the type of model and inputs to the models.\nWhat part of the computing task is accounted for/targeted by the method or tool (e.g., data movement, computations)?\nDoes the method or tool account for the energy consumption of specific hardware? If yes, which hardware?\n\u2022 Target Task: What resources are accessible to us in connection with this tool or method (such as code, models, APIs)?\n\u2022 Constraints: If any, what are the hardware or software constraints for using this method or tool?\n\u2022 Available: What is available to us related to this tool or method (code, model, API, etc.)?\n\u2022 Cites: How many citations does the item have according to Google Scholar?\nGroup NY. For items without tool creation and with applications to ML we ask questions belonging to four categories that we call \u201cstudy,\u201d \u201cdetail,\u201d \u201cML task,\u201d and \u201csetup\u201d. The questions are the following."}, {"title": "3 Execution of the Protocol", "content": "Let us now describe the execution of the protocol (see Figure 4 for the associated timeline) and the proportion of results across each search step. The initial search through the IEEE Digital Library, ACM Digital Library, and Google Scholar yielded 597, 193, and 5822 results, respectively. We thus obtained an initial set of 6612 results. Proceeding with the semi-automatic selection phase described in Section 2.2.2 with a total of 688 \"excluding words,\u201d we discarded a first set of 3465 results, obtaining a smaller set of 3147 results: 421 from IEEE, 137 from ACM and 2589 from GS. We then merged these three groups and removed all duplicates, obtaining a total of 2607 results. Finally, the first part of the selection by hand yielded 146 selected results"}, {"title": "4 Overview and Summary of the Selected Items", "content": "We may now describe the 118 selected results. We describe each of the five groups separately (YY, NY, YN, SY, SN), starting with the secondary studies in Section 4.3, before going to the primary studies in Section 4.2. For the latter, we also compare studies in terms of the approach used by the method/tool to evaluate energy consumption. In view of this we have chosen the taxonomy described in the following Section."}, {"title": "4.1 Taxonomy", "content": "We count four different categories of approaches (techniques) to evaluate energy consumption of ML tasks or general computing tasks (see Figure 5): measurement, data-based estimation model, analytical estimation model, and on-chip sensors:\n\u2022 Measurement: External Power Meter (EPM) or sensor measure power, current intensity and/or volt-age, for the whole computer or specific hardware components.\n\u2022 Estimation model: an estimation model takes indirect evidences, such as activity factors (in other words, useful features, hardware or software provided metrics) or characteristics of the target applica-tion (e.g. a neural network's architecture) and matches them to an energy consumption or power draw output. We differentiate between two kinds of models:\nData-based model: the model learns patterns and relationships directly from a data set through algorithms such as a ML model or a statistical model.\nAnalytical model: explicit equations or formula describe relationships between variables.\n\u2022 On-chip sensors based approaches: on-chip sensors, such as Running Average Power Limit (RAPL) and Nvidia Management Library (NVML), are sensors embedded in some vendors' processors with associated libraries to access their data. Although such approaches may overlap with the measurement and estimation groups (see Section 4.1.5 for detail), we consider them as a separate group, as they are based on vendor specific tools.\nSome approaches may target a single hardware component, such as the CPU or the GPU. Others may ag-gregate the energy consumption of multiple hardware components, intrinsically, as is the case of an external power meter placed at the power outlet level, or artificially, by summing, for instance, the consumption provided (by one or several of the above approaches) for several hardware components. A simple sum-mation may be replaced by a modelling approach itself. Indeed, the aggregation may be done by means of an analytical modelling (such as a simple weighted sum with predetermined coefficients) or by means of a data-based model (for instance learning from data the coefficients representing the contribution of the different hardware components to the total energy consumption of the system).\nSome of the studies reviewed here belong to several of the four categories. This is particularly common for approaches aggregating the consumption of multiple hardware components. First, the aggregation method can involve using analytical (and even sometimes data-based) modelling to some degree. Second, some techniques may combine different approaches for different components, for instance an analytical estimation model for the CPU with an on-chip sensor approach for the GPU. Furthermore, even an approach targeting a single hardware component may be a combination of several of the four categories."}, {"title": "4.1.1 Measurement", "content": "As already mentioned above, the measurement category refers to actual measurements of current, power, voltage. These measurements can be done at different places, ranging from a wall outlet to measurements at the motherboard ([94] notably reviews several measurement approaches), thus requiring additional or spe-cialised hardware such as a multi-meter or a specialized circuit integrated into the motherboard [102, 104]. This approach is considered to be the baseline (ground truth) for energy consumption evaluation. However, at large-scale, utilizing EPMs becomes costly [6]. Moreover, a drawback of this approach that is recurrently pointed out [37, 102, 124], is its inability to furnish fine-grained decomposition of the energy consumption. An EPM placed at the power outlet cannot provide information of where the power is consumed in the computer and even specialized integrated circuits with power sensors cannot monitor the consumption of a specific software (and even less, its classes and methods' usage) [102, 104, 124, 94]. In order to circum-vent this issue and use EPM as a baseline for more fine-grained energy evaluation methods and tools, some studies, such as [55], [37] and [124] have proposed specific experimental settings. For example in [55] all the variables that can impact variation in energy consumption (e.g., fans) are fixed so as to target a specific software performing a function. Similarly, in [124] the authors ensure that the value of dynamic energy is only due to the CPU and RAM. Furthermore, in [66] the authors compare Energy Scopium, Scaphandre, Perf (see Table 20) and PowerAPI [13], a series of fine-grained energy evaluation methods that provide power profiles (power evolution through time), with EPM and Baseboard Management Controllers (mea-surement equipment placed inside computing nodes), in terms of correlations. Overall, they observe similar and strongly correlated power profiles, and some differences are analyzed and discussed in detail by the authors."}, {"title": "4.1.2 Inputs of the Estimation Models", "content": "The analytical and data-based estimation models' inputs (or predictor variables) can range from Performance Monitoring Counters (PMCs), and hardware utilization rates, to hardware specifications, and software char-acteristics such as the architecture of the Neural Network (NN) to be trained/executed, or Parallel Thread Execution (PTX) code (an intermediate compilation of CUDA code generated at compile time).\nPMCs are registers provided in the processor to store the counts of software and hardware activities [37, 123]. This information, collected during programs' execution, sheds light on the behavior of these programs. PMCs are thus metrics directly provided by the hardware, as opposed to OS provided metrics (i.e., computed by the OS) such as the utilization level of a system (e.g., the CPU utilization indicator) [94]. PMC are also referred to as \"hardware performance counters\" [121], \"power monitoring units\" [51], \"performance events\u201d [41] in the literature reviewed here.\nIn addition to aforementioned inputs, other types of inputs observed in the reviewed studies include:\n\u2022 characteristics of NN layers such as their shape, number of non-zero values and bitwidths (i.e., bits used to represent each value in a numerical data type);\n\u2022 hardware specifications (constant parameters associated to a specific hardware and generally provided by the manufacturer) such as the Thermal Design Power (TDP) of the CPU or GPU, which is the maximum heat flow generated by a CPU or GPU that its cooling system is designed to dissipate; the TDP can be seen as an indication of the maximum power the component can draw;\n\u2022 execution and memory access traces obtained by means of simulators,\n\u2022 static features of sources code (obtained without executing the program), compiled binary;\n\u2022 Floating Point Operations (FLOPs) or Multiply-Accumulate (MAC) count;\n\u2022 task duration."}, {"title": "4.1.3 Data-Based Estimation Models", "content": "As explained in [94], data-based estimation models (referred to as \u201cpower estimation models", "steps": "first, the selection of the model's inputs (see Section 4.1.2), and second, the identification of a tool to train and test the model. The latter may be a benchmark, that the authors define as \u201csoftware programs specifically designed to stress some of the subsystems of a server in a comprehensible and repeatable manner.\u201d According to [37], a model is typically trained using a large suite of diverse benchmarks and validated against a subset of the benchmark suite and some real-life applications. The estimation error is then the difference between the estimated power consumption and the actual power consumption, also called baseline, ground truth or reference. The way to quantify the baseline varies across studies, some of them, e.g. [41], use on-chip sensors (see Section 4.1.5), and others, e.g. [84], use actual measurements. As reported by [94], the estimation error is significantly influenced by the choice of 1) the model input parameters, 2) the model training techniques, 3) the benchmarks/applications for training and evaluation purposes, and 4) the power baseline to which the estimated power is compared. Several studies agree that the most common approach used to build a data-based estimation model for energy consumption is linear regression [94, 37, 124, 123, 52]. Some also state that models inputs are generally PMCs recorded at the target hardware components during a program's execution. Often, one model is built for each component and the consumption of each component is then summed [37]. In [52] estimation models based on PMCS are notably reviewed.\nWhile the PMCs and other activity factors are typically recorded during an application run, one can also use simulators (emulating a specific hardware platform and integrating monitoring tools into the code whose execution is simulated on that platform) to obtain these counters and thus bypass the need to execute an application [6]. In [43], the authors look at both approaches that simulate hardware, and approaches that"}, {"title": "4.1.4 Analytical Estimation Models", "content": "A typical example of analytical estimation model is for instance computing the energy consumption of the CPU (or GPU) by the product of its TDP and the total execution time of the target computing task [73]. This assumes that the CPU (or GPU) is utilized at 100%, or in any case at some known constant average utilization level as in [75]. The authors in [100] also propose a variation of this model, in which the CPU TDP is first multiplied by 0.7 to account for the fact that the actual power draw of the CPU is generally less than the amount of heat the component generates, that is stipulated by the TDP. Other models have been proposed that involve for instance FLOP or MAC count, characteristics of the application (such as the architecture of a NN in the context of a ML computing task), static features of source code, and PMCs, see for instance [29], [76], [82], and [108], respectively."}, {"title": "4.1.5 On-Chip Sensors", "content": "Approaches based on on-chip sensors, also called internal interfaces [66], rely on 1) sensors embedded in mainstream processors such as Intel and AMD Multicore CPUs, Nvidia GPUs, and Intel Xeon Phis and 2) associated vendor specific libraries that give access to power data from these sensors. Well known examples include Running Average Power Limit (RAPL) for Intel CPUs, and Nvidia Management Library (NVML) for Nvidia GPUs and Intel System Management Controller chip (SMC) for Intel Xeon Phi [124] (see Tables"}, {"title": "4.2 Summary of the Selected Methods and Tools", "content": "We will now summarize, by means of tables, the 108 selected primary studies, presenting successively each of the groups YY, NY and YN in Sections 4.2.1, 4.2.2 and 4.2.3, respectively. In each section, we group studies according to the taxonomy described in Section 4.1. The column \u201cstudy\u201d contains the reference of the article, year of publication and name of the tool or method created by the authors (for the groups YY and YN).\nIn what follows, we use the subsequent abbreviations: \u201cNN", "NU\" for Name Unspecified (for tools and methods that are unnamed). Whenever code or trained models have been made available by the authors, we provide the corresponding link directly in the tables, and one can also refer to Appendix A.4 for the list of URLs.\"\n    },\n    {\n      \"title\": \"4.2.1 Studies with Tool Creation and Applied to ML (YY group)\",\n      \"content\": null\n    },\n    {\n      \"title\": \"4.2.1.1 YY studies in the group \\\"analytical estimation model\\\"\",\n      \"content\": null\n    },\n    {\n      \"title\": \"4.2.1.2 YY studies in the group \u201cdata-based estimation model\\\"\",\n      \"content\": null\n    },\n    {\n      \"title\": \"4.2.1.3 YY studies in the group \u201con-chip sensors\\\"\",\n      \"content\": null\n    },\n    {\n      \"title\": \"4.2.1.4 YY studies in the group \\\"analytical and data-based estimation model\\\"\",\n      \"content\": null\n    },\n    {\n      \"title\": \"4.2.1.5 YY studies in the group \\\"analytical estimation model and on-chip sensors\\\"\",\n      \"content\": null\n    },\n    {\n      \"title\": \"4.2.1.6 YY studies without group\",\n      \"content\": null\n    },\n    {\n      \"title\": \"4.2.2 Studies with Tool Usage and for ML (NY group)\",\n      \"content\": null\n    },\n    {\n      \"title\": \"4.2.2.1 NY studies in the group \u201cmeasurement\\\"\",\n      \"content\": null\n    },\n    {\n      \"title\": \"4.2.2.2 NY studies in the group \u201canalytical estimation model\\\"\",\n      \"content\": null\n    },\n    {\n      \"title\": \"4.2.2.3 NY studies in the group \\\"on-chip sensors\\\"\",\n      \"content\": null\n    },\n    {\n      \"title\": \"4.2.2.4 NY studies in the group \u201cdata-based estimation model\\\"\",\n      \"content\": null\n    },\n    {\n      \"title\": \"4.2.2.5 NY studies without group\",\n      \"content\": null\n    },\n    {\n      \"title\": \"4.2.3 Studies with Tool Creation and not Applied to ML (YN group)\",\n      \"content\": null\n    },\n    {\n      \"title\": \"4.2.3.1 YN studies in the group \\\"measurement\\\"\",\n      \"content\": null\n    },\n    {\n      \"title\": \"4.2.3.2 YN studies in the group \\\"analytical estimation model\\\"\",\n      \"content\": null\n    },\n    {\n      \"title\": \"4.2.3.3 YN studies in the group \u201cdata-based estimation model\\\"\",\n      \"content\"": null}, {"title": "4.2.3.4 YN studies in the group \"on-chip sensors\"", "content": null}, {"title": "4.2.3.5 YN studies in a mixed group", "content": null}, {"title": "4."}]}