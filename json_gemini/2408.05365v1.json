{"title": "FiST-Financial Style Transfer with Hallucination and Creativity Control Framework", "authors": ["Sohini Roychowdhury", "Marko Krema", "Brian Moore", "Xingjian Lai", "Dike Effedua", "Bharat Jethwani"], "abstract": "Financial report generation using general purpose large language models pose two major challenges, including the lack of compound sentences and hallucinations. Advanced prompt engineering and retrieval augmented generation (RAG) techniques are incapable of curing the writing style discrepancies. In this work we propose a novel two-stage fine-tuning process wherein public domain financial reports are processed into prompt-completions and augmented using simple LLM prompts to then enable sectional financial report generation using minimal instructions and tabular data inputs. Our proposed fine-tuning framework results doubles the number of correct questions answers and reduces hallucinations by over 50%. Additionally, the two-stage fine tuned models have lower perplexity, improved ROUGE, TER and BLEU scores, higher creativity and knowledge density with lower uncertainty and cross entropy.", "sections": [{"title": "I. INTRODUCTION", "content": "Large language models (LLMs) have powered several question answering chat-bots and automation processes as major use cases in the recent past. For the financial domain, several significant developments have been made [1]. Major financial tasks that can now be fulfilled with LLMs include automated financial statement analysis, personalized narrative generation for financial reports, automated tagging and labelling of financial data and reports, financial forecasting and prediction, risk management and compliance and audit processes [2]. The major notable contributions for LLMs in the domain of finance include the BloombergGPT [3] that is capable of sentiment analysis, named entity recognition, and question answering when applied to financial text; and FinancialGPT [1] that incorporates various financial data formats, including news, filings, social media, and company announcements into the training phase to enable creation of financial products and services and supports informed investment and risk management strategies.\nWhile training a financial-domain specific LLM poses challenges with regards to training data quality and hardware resources needed for large scale training epochs, most of these well-established financial use-cases rely on web-search approaches combined with knowledge graphs (KGs) to ensure \"recency\" in the data quality and standards of responses/outputs [2]. The process of retrieving updated financial information and serving the analysis in domain-representative jargon, also known as the agentic retrieval approach, comprises of two steps. First, a web-search is orchestrated for the user-query; second from the retrieved web link texts, paragraphs that contain relevant information are identified using the KGs. KGs are a structured representation of data or textual information. It consists of nodes (entities) and edges (relationships) that connect them. For example, a node might represent an entity such as an organization, place, or person, while an edge could represent a relationship like \"resulted in\u201d, \u201crisen/fallen\" etc. The most appropriate paragraphs/KGs from the web links are then used to serve the information in a personalized and structured manner to create accurate and reliable Generative AI systems that are capable of fact-checking, improved Understanding, enhanced domain-specific reasoning [4].\nAlthough agentic retrieval augmented generation (RAG) processes have benefited certain financial use cases such as question answering and fact checking, these approaches do not scale to financial report generation tasks where the intention is to transfer the domain-specific writing style. As an experiment, we used as tabular data and english language instructions describing the persona of a financial analyst and specific instructions to GPT4o model to generate multiple paragraphs of financial reporting text. The sample output is shown in where unwanted text is struck out by our financial domain experts. This experiment was further fine tuned with the following observations.\n\u2022 Inspite of detailed persona descriptions and advanced instructions to prevent the use of words such as {successively, landscape of growth} and general wordiness, the output did not signifincatly change.\n\u2022 Controlling for LLM parameters like temperature, top_p and max tokens did not improve the quality of generated text.\n\u2022 increased instructions to generate multiple sentences from tabular data reduced the overall performance of text generation.\n\u2022 Complex sentences that are atypical for the financial domain, such as contrasting sentiments regarding the same entity cannot be generated with reproducibility using the RAG approaches.\nHowever, the knowledge graph significantly impacts the nature of language generated by the LLM, as shown in"}, {"title": "II. RELATED WORK", "content": "Domain-specific generative AI led automation tasks such as a financial chatbot or financial news writer, have seen specific improvements in overall knowledge retrieval tasks by using search engine and search engine along with knowledge graph capabilities as shown in Fig. 5 [5]. The major reason for improved answering capabilities with web searches and KG isolation of text is that the LLMs follow a unique knowledge distribution, with a head, body/torso and tail [6]. Knowledge from the LLM head (commonly occurring and rarely changing facts) are easily retrievable with minimal hallucinations. Contrastingly, knowledge from the LLM tail (rapidly changing facts, such as share prices etc.) can lead to stale data in the responses or inaccuracies or \u201ci dont know\" responses from LLMs. The knowledge from the body/torso of LLMs can result in either accurate responses or hallucinations. Thus, it is imperative to teach the LLM to work with latest data, but reasonably modify the text generation style to ensure lowered hallucinations and unknown responses as shown in [6].\nSo far, LLMs have provided advanced capabilities for insights, trends, and assessments in the financial domain. Notable models like FINBERT [7], introduced in 2022, demonstrate the adaptation of LLMs to financial domains. Innovations continue with Bloomberg GPT [3], boasts an impressive 50 billion parameters trained on extensive financial domain data, making it one of the largest and most powerful financial-specific LLMs to date. Looking forward, developments in multi-modal LLMs [8] and specialized agents [9] provide added capability in financial sentiment analysis and market predictions, underscoring the significant role of LLMs in shaping the future of financial analytics. Financial report data is characterized by a mix of structured (tables, charts) and unstructured (narrative text) information. Techniques like Named Entity Recognition (NER) are used to extract key financial metrics from these texts. Reports are often lengthy and complex, with hidden data labels that require careful analysis to assess model performance. Additionally, financial reports contain important sentiment and tone information, crucial for financial analysis and transparency. Research in Writing style transfer has seen significant development in recent years. Initial efforts focused on creating datasets and methodologies for formality style transfer [15], with advancements leading to more sophisticated techniques for maintaining semantic integrity while altering style. By 2023, models like ChatGPT demonstrated improved capabilities in evaluating and editing text for style transfer [16]. Recent research explored multidimensional evaluations and integrated new approaches for enhancing style adaptation. However, there is still a lack of work specifically analyzing effective style transfer in the financial domain, which this paper aims to address."}, {"title": "III. METHODS AND DATA", "content": "LLMs typically perform two distinct tasks of natural language understanding (NLU), wherein the user data and query is converted to machine translation entities or tokens followed by natural language generation (NLG), wherein a sequence of words/tokens are generated based on the probabilities of the prior generated words. In this work, we focus on the NLG aspect of an LLM and the ability to transfer domain specific jargon, such as compound sentence generation and creative language generation. Evaluation of LLM responses is performed by analyzing the user-query (Q), contextual data (D) and the LLM responses (R) together.\nOne major challenge with NLG from LLMs is detecting instances of \"hallucinations\" or fake responses [23]. While hallucinations characterize factually false information/sentences that are confidently rendered as LLM responses, they are different from creativity or sentences that are factually accurate extrapolations of the facts/concepts. For example, consider the following context, user query and responses:\n\u2022 D: \"The company ACL had targeted 30% profits but it finished Q2 at 28.8% profits.\"\n\u2022 Q: \"How was ACL's performance in Q2?\".\n\u2022 R1:\"ACL met its target of 30% profit in the Q2 quarter.\"\n\u2022 R2: \"ACL missed the planned target of 30% by 1.2% by the close of Q2.\"\nIn this situation R\u2081 is a hallucination while R\u2082 is a creative response. In this work, we assess the quality of generated sentences after domain-specific fine tuning to isolate the log-probabilities at sentence level for creative versus hallucinated sentences. Additionally, the entities (nouns, locations, currencies etc.) in the generated text ($e_k$) and their relationships ($p_k$) can be extracted using standard libraries such as nltk and spacy to asses the density of knowledge per sentence.\nIn this work we assess the importance of two-stage fine tuning on OpenAI GPT3.5 model using DPO mechanism that impacts the LLM weights and biases directly as opposed to modifying the LLM reward model [24]. Our training data is several public domain financial reports are are pre-processed into the \"prompt-completion\" format as shown in section."}, {"title": "A. Metrics and Notation", "content": "The goal of this work is to generate domain-friendly natural language text from a minimal prompt that contains basic instructions and financial data in a tabular format. For a sequence of words/tokens, the i'th generated token $x_i$ and the log probability associated with the token is $p_i$. It is noteworthy that each sequential token is generated as a function (F) of the prior tokens and the token with highest probability across the top contenders for each sequential position as shown in equation (1). The log probability of top 5 contenders for each sequential position is collected as $P_i$ from the output of OpenAI's GPT3.5 to assess overall quality of the generated text and to detect hallucinations and creativity.\n$x_i = F(x_{i-1}, x_{i-2}..., arg max(P_i)), \\forall P_i = {P_{i,1}, P_{i,2}...P_{i,5}}$ (1)\nFor example, each response word shown in Table IV is selected across 5 top contenders as the one with lowest log probability (or highest probability). Further, we assess the quality of fine tuned generated text using the sequential log-probabilities per token and the following metrics.\n$P = exp(\\frac{1}{t}\\sum_{i=1}^{t} ln(x_i|x_{i-1}...))$ (2)\n$ASLS = \\frac{1}{t}\\sum_{i=1}^{t}\\sum_{j=1}^{5} P_{i,j}$ (3)\n$CE = \\sum_{i=1}^{t}-max(P_{i,j})_{j=1}^{5},$ (4)\n$KDPS = \\frac{1}{S}\\sum_{k=1}^{S}(e_k + p_k)$ (5)\n\u2022 Perplexity (P): A lower value determines how confidently each sequential token is generated following the fine-tuning process and defined in equation (2).\n\u2022 BLUE (Bilingual Evaluation Understudy) score [25]: A high value represents high similarity between the generated text to the reference context, thereby representing accuracy of the generated text.\n\u2022 TER (Translation Edit Rate) [25]: A lower value indicates fewer edits required to transform the generated text to the reference context.\n\u2022 ROUGE (Recall-Oriented Understudy for Gisting Evaluation) score [25]: A higher value determines similarity between generated text and reference context.\n\u2022 chrF++ (character level F score) [25]: A high value operates at a character level to denote accuracy of generation in terms of similarity with reference context.\n\u2022 Averaged sequential log-loss per sentence (ASLS): A high value represents highly discernible tokens per sentence (t) such that the probability distribution per token $P_i$ is highly non-uniform as shown in equation (2). This novel sentence-level metric evaluates how confident the LLM is to generate each subsequent token. For instance, if top 5 log probabilities per sequential tokens are equally likely, that would result in a low ASLS, which can indicate under-confident or hallucinated or creative text generation. ASLS is an extension from cross entropy loss (CE in equation (2)), where a lower value indicates higher confidence of token/word selection.\n\u2022 Knowledge density per sentence (KDPS): A high value represents dense information in terms of entities and their relationships per sentence. This is a domain-specific metric and is representative of compound sentences at paragraph level as shown in (2).\nThe impact of the well-known language evaluation metrics perplexity, BLUE, TER, ROUGE and chrF++ on LLM generated responses varying in certainty is illustrated by the"}, {"title": "B. Hallucination vs. Creativity", "content": "While fine-tuning LLMs for niche domain-writing styles such as finance, sales, medical reporting etc. are necessary, most LLM fine-tuning techniques do not focus on hallucinations introduced by un-prepared data sources. A recent work in [26] presents the mathematical framework to define LLM hallucinations using probability and information theoretic approaches. This work demonstrates that LLM hallucinations are characterized by low log likelihood of sequential tokens. Also, it illustrates that hallucinations arise from self-supervised learning where the training process typically relies on metrics such as ROUGE, TER, BLEU etc. that focus on ensuring the response stay similar to the context, even if a well formed answer exists. Also, hallucinations are implausible based on the context and can be considered as inference-level anomalies that cannot be replicated owing to low token probabilities. Also, this work demonstrates that minimizing hallucinations can minimize creativity of an LLM outcome. In this work, we expand on this fact and utilize ASLS and CE metrics to control for likelihood of sequential token generation across training epochs. Also, we demonstrate that by controlling for hallucinations and adequate data preparation, we enhance creative compound sentence generation that is required for the financial domain.\nAnother recent work in [27] demonstrates the two phases of LLM hallucinations, where in the first divergent phase hallucination induced creativity can be controlled by advanced prompt engineering, and fine-tuning to promote creativity. The second convergent phase involves standard RAG approaches [28] including intention recognition and hallucination detection and RAG-based control mechanisms. In this work, we expand on the divergent phase to pre-process the data preparation phase followed by hallucination control mechanisms to promote creativity and compound sentences but to reduce hallucinations in the fine tuned LLM."}, {"title": "C. Data Preparation", "content": "Our goal is to fine-tune an off the shelf LLM to generate a financial report using minimal instructions and tabular data to mimic the creation of a financial analyst. Thus, the goal is to format the prompt-response pairs in a similar format. The first step here is to generate sample data tables that can serve as inputs. We started by creating tabular data that was extrapolated from 150 public domain financial reports. The tabular data is further augmented by small variations to the numbers and schema that can be generated using minimal LLM prompts. This resulted in 950 samples of tabular data and reports that were the source for these reports. Our next task is model fine-tuning/training.\nThe next step is to create prompts instructing the LLM to generate sections of the financial reports. Since various sections such as introduction, conclusion, discussion sections require specific verbiage, prompt-completions for each section require specific instructions. The prompt aspects that remained unchanged across all the prompt-completion samples was the style transfer attributes like tone, assertiveness, and persona. The prompt-completions are also generated using minimal LLM (Open AI GPT4o) prompts. At the end of the two steps, we obtain an augmented set of data tables and prompt-completions that can then be sent to the LLM to automatically generate required reports. This process requires minimal manual supervision and prompt engineering to ensure quality standards in the augmented prompt-completions as shown in Fig. 6."}, {"title": "IV. EXPERIMENTS AND RESULTS", "content": "For validation, two 10-page detailed financial reports are manually annotated for verbiage and quality and we assess the average perplexity per section for these manually annotated reports using vanlillaGPT3.5 model, single stage fine-tuned model, and two-stage fine tuned model with hallucination control."}, {"title": "A. Validation and Test Prompts", "content": "First, we assess the perplexity scores for the two-stage fine-tuned model on the two validation reports in Table V. Here we observe that the fine tuned perplexities are consistently lower and hence better per section of the financial reports. Additionally, the average scaled KDPS for Untrained and trained model on both reports were 0.75 and 0.8 respectively. This demonstrates compound sentences and increase number of entity relations per sentence in the fine tuned model.\nNext, we assess the report generation performances for the following 3 prompts shown in Fig. 7 and Fig. 8."}, {"title": "B. Quantitative Analysis of Two-stage LLM Fine-tuning", "content": "To ensure style transfer and hallucination control, we first fine-tune the GPT3.5 model for style using 1000 prompt-completions generated using the method explained in section III-C over 100 epochs. Next, we query 112 questions to the fine-tuned model and check the performance for hallucinations. Following this, we create another set of 1000 prompt-completions that are manually curated to eliminate hallucinations. We then fine-tune the LLM a second time on the hallucination-free data for 100 epochs. The resulting fine-tuned model ensure transferred domain-specific style and low hallucinations. The quality of responses to the 112 user queries can be categorized as {Correct, Hallucinations, Incomplete}. The quality of the untrained LLM, one stage and two-stage fine tuned LLMs in terms of response quality is shown in Fig. 9. The quality of generated text is further shown in terms of scaled metrics in Fig. 10."}, {"title": "C. Qualitative Analysis: Hallucination and creativity monitoring", "content": "In the previous subsection, we observe the value in two-stage fine tuning to control for hallucinations. However, since creative and hallucinated words/tokens have similar probabilistic nature, we qualitatively assess the reports generated from the prompts shown in Fig. 7 and 8 for hallucinations and creativity. Fig. 13 demonstrates sample reports generated from untrained, one-stage fine tuned and two-stage fine-tuned models. In Fig. 11 we observe that the cross-entropy of the generated text significantly reduces after each stage of fine tuning leading to less hallucinations and more certain text generation. Finally, in Fig. 12, we observe the ASLS metric at sentence level for the untrained, one-stage and two-stage fine tuned models, respectively. We observe that for the untrained and one-stage trained models, the last two lines have the lowest log-loss, or low certainty for text generation. These sentences have a higher tendency to contain hallucinations or creativity. However, for the two-stage tuned model, the hallucinations significantly reduce, thereby leading to more certain and higher quality of text generation."}, {"title": "V. CONCLUSIONS AND DISCUSSION", "content": "Our analysis on a variety if versions of fine tuned LLM models on financial reports reveal the following nature of generated text.\n\u2022 Closed-ended questions generally have lower perplexity, higher ROUGE and lower TER scores indicating that they are easier for the model to predict based on the reference context.\n\u2022 Open-ended questions tend to have lower BLEU, higher TER and perplexity suggesting more uncertainty in the generated text.\nAdditionally, we observe that for the labeled validation reports, the fine-tuned models generally outperform the untrained model with higher average coherence and correctness, while the relevance of data remains fairly unchanged. For question answering from minimal prompts, the fine-tuned models excel in depth and creativity, although creativity is not a desired trait for financial reports. However, the untrained model demonstrated slightly better conciseness. Thus, without the need for creativity, the fine-tuned model's superior performance in coherence and correctness, combined with appropriate depth, makes it the preferred choice for sectional financial report generation. Additionally, manual verification revealed that the untrained model tends to over-explain (low ASLS), leading to unnecessary depth, which is not suitable for our concise reporting needs. This makes the fine-tuned models the better choice for generating accurate, coherent, and appropriately detailed financial reports for our use case.\nFuture works will be directed towards further controlling for hallucinations and creativity by monitoring weights and biases of additional final layers of the LLMs."}]}