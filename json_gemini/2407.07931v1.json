{"title": "Search, Examine and Early-Termination: Fake News Detection with Annotation-Free Evidences", "authors": ["Yuzhou Yang", "Yangming Zhou", "Qichao Ying", "Zhenxing Qian", "Xinpeng Zhang"], "abstract": "Pioneer researches recognize evidences as crucial elements in fake news detection apart from patterns. Existing evidence-aware methods either require laborious pre-processing procedures to assure relevant and high-quality evidence data, or incorporate the entire spectrum of available evidences in all news cases, regardless of the quality and quantity of the retrieved data. In this paper, we propose an approach named SEE that retrieves useful information from web-searched annotation-free evidences with an early-termination mechanism. The proposed SEE is constructed by three main phases: Searching online materials using the news as a query and directly using their titles as evidences without any annotating or filtering procedure, sequentially Examining the news alongside with each piece of evidence via attention mechanisms to produce new hidden states with retrieved information, and allowing Early-termination within the examining loop by assessing whether there is adequate confidence for producing a correct prediction. We have conducted extensive experiments on datasets with unprocessed evidences, i.e., Weibo21, GossipCop, and pre-processed evidences, namely Snopes and PolitiFact. The experimental results demonstrate that the proposed method outperforms state-of-the-art approaches.", "sections": [{"title": "1 Introduction", "content": "The ubiquitous availability and accessibility of the Internet have reshaped the way people obtain and engage with information. Yet, it has concurrently paved the way for the rapid propagation of fake news, which can swiftly amass momentum on social media and various online platforms. The propagation of false information has the potential to yield ill-informed perspectives, with serious implications including public opinion manipulation, concealing the truth, and the incitement of crimes.\nFake News Detection (FND) involves analyzing the probability of news containing misconducting information. Early methods mainly utilize low-level coarse statistical analyses of news content to estimate the veracity of news, e.g., punctuation, lexical statistics [9] or grammar [16]. With the evolution of machine learning techniques, hand-crafted pattern analyzers have been largely supplanted by deep networks. The prevailing methodology is to prepare thousands of real and fake news samples, extracting features from each sample, and constructing a classifier to establish a binary classification boundary. The literature has had success stories from either mining linguistic features, e.g., pragmatic pattern [10], writing style [85], sentiment [87], or visual features, e.g., image quality [26], forgery ar-"}, {"title": "2 Related Works", "content": "Numerous studies have been conducted to develop automatic methods that detect fake news without considering external evidence. BiGRU [35] and TextCNN [88] respectively use a bidirectional GRU and a 1-D CNN module for feature extraction from the text. BERT [29] is also frequently utilized as FND baselines where the parameters are kept tunable and the classifier works on the CLS token. Ajao et al. [2] propose to analyze the sentimental characteristics of fake news, benefiting some latter works [87]. M\u00b3FEND [91] uses a memory bank to enrich domain information of the news to assist with detection. Also, there are a list of multimodal FND methods that further consider the joint distribution of image and text. Chen et al. [11] use VAEs to compress the images and texts and learn to minimize the Kullback-Leibler (KL) divergence for correctly matched image-text pairs contrastively. Ying et al. [84] extract features from multiple views and design a scoring mechanism to adaptively adjust the weight of each view in the final decision. Zhou et al. [90, 89] design multi-modal fusion mechanisms with pre-trained models. Nevertheless, these methods mainly rely on pattern analysis of static news, neglecting the possible evolvement of characteristics of fake news."}, {"title": "2.2 Evidence-aware Fake News Detection", "content": "Many high-quality fake news datasets with evidences are proposed. Snopes [46] and PolitiFact [53] contains retrieved evidence articles for each claim by issuing each claim as a query to the Microsoft Bing API, articles are processed by filtering out those related to Snopes and PolitiFact websites and calculating relevance scores to decide on their usage. Similar datasets are FEVER [66], Emergent [17], etc. In contrast, other famous datasets such as Weibo21 and GossipCop do not provide evidences and therefore have only been applied for pattern-based, rather than evidence-aware, FND. Besides, many tailored detection networks are proposed on top of these datasets. De-ClarE [47] averages signals from external evidence articles and concatenates them with the language of the articles and the trustworthiness of the sources. Vo et al. [72] proposes to use hierarchical multi-head attention network to combine word attention and evidence attention. CCN [1] leverages both the image caption and text for online evidences, and detects the consistency of the claim-evidence (text-text and image-image), in addition to the image-caption pairing. Xu et al. [82] introduces GET that applies a Graph Neural Network (GNN) to capture long-distance semantic dependency among the news and evidence articles. However, previous methods either require laborious pre-processing operations towards the evidences, or utilize all evidences for news cases regardless of the quality and quantity. We propose a new FND approach with annotation-free evidences and early-termination."}, {"title": "3 Proposed Approach", "content": "Fig. 2 depicts the pipeline of the proposed SEE approach. It consists of three stages, namely, 1) Searching online materials using the news as query and directly using their titles as the retrieved evidences without any annotating or filtering procedure, 2) sequentially Examining"}, {"title": "3.1 Search: Evidence Preparation", "content": "Let the input news be $\\mathcal{N} \\triangleq [c, \\mathcal{E}] \\in \\mathcal{D}$, where $c, \\mathcal{E}, \\mathcal{D}$ are the text of the news, a queue of the corresponding retrieved evidences and the news dataset, respectively. $\\mathcal{E} = [e_1, e_2, ...]$ can be either provided by the dataset along with $c$, e.g., PolitiFact and Snopes, or prepared by the users via online searching, e.g., Weibo21 and GossipCop. The searching step can be optional if the evidences can be prepared in advance, otherwise, we prevail the circumvention of laborious annotating or other pre-processing operations on $\\mathcal{E}$ for quality control. For evidence retrieval, our preliminary is that users trust a certain credibility control of the applied searching engine for collecting evidence through the corresponding API. Here, we apply the popular Microsoft Bing to collect evidences. To benchmark \"annotation-free\" evidence retrieval, we purposefully exclude any pre-processing operations other than pasting the news content into the search box & clicking \"Search\" for all datasets. We turn each piece of the retrieved material into evidence via recording its title, in accordance with Snopes and PolitiFact, and store in order at most $N$ evidences in each $\\mathcal{E}$, where $N$ is a tunable hyper-parameter. Exampled $N$ for Weibo21 and GossipCop are provided in the experiments\u00b9. Next, we adopt the BERT model [29] as the preliminary feature extractor for both news and the evidences. The representations of the news and evidences are respectively denoted as $C = \\text{BERT}(c) \\in \\mathbb{R}^{L \\times d}, P_i = \\text{BERT}(e_i) \\in \\mathbb{R}^{L \\times d}, i \\in [1, N]$, and $d$ denotes the feature dimension."}, {"title": "3.2 Examine: Attention-based News-evidence Fusion", "content": "We prepare a cascade of $N$ independent transformer decoders [29] with joint self- and cross-attention to sequentially examine the news alongside with each piece of evidence and produce new hidden states with richer information. Each decoder is responsible for feature fusion for a typical time-step. The first block takes $C$ and the leading evidence $P_1$ as inputs, and outputs $R_1$, which we call hidden state of the first time-step. The following blocks take the hidden state by the previous block and the initial embedding of the upcoming evidence to iteratively produce a list of hidden states. We use the attention mechanism and feed-forward layer operation in typical transformers [29], denoted with $\\text{Attn}(\u00b7)$ and $\\text{FFN}(\u00b7)$. Specifically, the attention operation has:\n$$\\text{Attn}(Q, K, V) = \\text{softmax}(\\frac{QK^T}{\\sqrt{d}})V,$$\nwhere $Q, K, V$ denotes the query, key, and value matrix.\nIn the decoders, we combine both self-attention and cross-attention in the examining step for news-evidence interaction. Each decoder consists of three layers: a self-attention block, a cross-attention block, and a feed-forward network. Each layer has a residual connection to the previous layer and is attached to a layer normalization. For simplicity in equations, we use overlines to denote the Layer Normalization operations (LN) [4]. The examination process of a decoder block is:\n$$\\begin{aligned}\nL_1 &= \\begin{cases}\nC + \\text{Attn}(C, C, C), & \\text{if } k = 1 \\\\\nR_{k-1} + \\text{Attn}(R_{k-1}, R_{k-1}, R_{k-1}) & \\text{otherwise}\n\\end{cases}\\\\\nL_2 &= L_1 + \\text{Attn}(L_1, P_k, P_k),\\\\\nR_k &= L_2 + \\text{FFN}(L_2).\n\\end{aligned}$$\nNote that each decoder is independent and receives evidence from a specific index in the queue, where the inherent relationship between each index and its statistical relevance of the evidence to the news can be implicitly learned. One can also alternatively employs a shared"}, {"title": "3.3 Early-termination: Exit When \u201cConfident\"", "content": "Consider that examining all evidences as supplements to the news regardless of the quality and quantity might be sub-optimal, as the existence of low-quality or less-relevant evidences could impact the model performance. We introduce the early-termination step that enables the model to cease further examining more pieces of evidence and proceed to prediction if a confidence threshold is surpassed within each time-step.\nIn detail, the confidence assessor visits every hidden state $R_k$, $k \\in [1, N]$ and reduces them into confidence scores $s_k$. We set a hyper-parameter $\\tau$ as a threshold. $\\tau$ is set to decide whether to continue the examining step by sending $R_k$ and the next, if exists, evidence into the next decoder, or to terminate and make the prediction, denoted as $\\hat{y}$, by sending $R_k$ into the classifier. $\\tau$ is another hyper-parameter, which has a non-negligible effect on both the overall ratio of early-termination and detection performance. We give a detailed analysis of $\\tau$ in Section 4.2.\nDuring the iterative examining and confidence assessment, we record the hidden state with the highest confidence score, denoted as $R'$. If the last evidence is reached, we resort to using $R'$ with the highest score to make the prediction $\\hat{y}$. The classifier is a three-layer perceptron and a sigmoid function. Therefore, we denote the calculation procedure of $\\hat{y}$ as follows.\n$$\\hat{y} = \\begin{cases}\n\\sigma(\\text{MLP}(R_k)), & \\text{if } s_k > \\tau \\\\\n\\sigma(\\text{MLP}(R')), & \\text{otherwise}\n\\end{cases}$$\nFor the confidence assessor, given a hidden state $R_k$ at time-step $k$, we first reduce the token dimension using average pooling over all tokens and use a fully-connected layer $f(\u00b7)$ to reduce it into a logit, which is further mapped within [0, 1] as the confidence score by a sigmoid function $\\sigma(\u00b7)$.\n$$\\begin{aligned}\n\\hat{R}_k &= \\text{AvgPool}(R_k),\\\\\ns_k &= \\sigma(f(\\hat{R}_k)).\n\\end{aligned}$$"}, {"title": "3.4 Two-staged Training Mechanism", "content": "There is no external label for the confidence assessment process. We propose a two-staged training mechanism where we first solely emphasize on feature extraction from evidences, and then train an assessor to determine when to exit with fixed feature extractors. Soft"}, {"title": "4 Experiments", "content": ""}, {"title": "4.1 Experimental Setups", "content": "Implementation Details. We use bert-base-chinese and bert-base-uncased pre-trained models for processing Chinese dataset and English datasets, respectively. The hidden size of word embeddings is 768 (d = 768). We unify the length of input news and evidence to a specific length by padding or truncating (L = 100). For samples with fewer than N evidence, the missing evidences are treated as blank and filled with [PAD] tokens. To save computation, the representations can be pre-computed, stored on disk and loaded upon training. Our model is trained using a single NVIDIA GeForce RTX 4090 GPU. We use Adam optimizer [31] with default parameters. The batch size is 12. We use a learning rate of $6 \\times 10^{-6}$ for the feature extractors, i.e., fine-tuned BERT and the decoders, and $5 \\times 10^{-5}$ for the rest of the model.\nData Preparation. We use four famous datasets, namely Weibo21 [42], GossipCop [61], Snopes [46], and PolitiFact [47] for our experiments. Weibo21 is a Chinese fake news detection dataset collected from Sina Weibo. News content of GossipCop, Snopes, and PolitiFact are collected from fact-checking websites. Weibo21 and GossipCop do not contain official evidences, so we collect evidence articles for them by the method mentioned in Section 3.1. We conduct train-val-test split in the ratio of 6:2:2 in accordance with previous methods. Table 1 summarizes these datasets."}, {"title": "4.2 Performance Analysis", "content": "Before conducting extensive comparisons with previous state-of-the-arts, we first study the impact of different implementation settings"}, {"title": "4.3 Comparisons", "content": "The compared benchmark methods are listed in Table 3. Since our testing datasets might not have been used by some of the baseline methods, we carefully re-implemented them by providing all available required data, e.g., publisher information, propagation graph, etc. In contrast, SEE refrains from using the related additional information other than annotation-free evidences.\nImplementation of Baselines. DeClarE [47] and GET [82] also require publisher information and other propagation-based information. As such, we do not directly borrow the experimental results from their papers and instead collect related information and carefully retrain the models on the testing datasets. GET involves generating graphs by segmenting words and using pre-trained embeddings, and we implement this on Weibo21 by using jieba 2 and Chinese word vectors pre-trained on weibo [32]. Domain information of news is mandatory for M\u00b3FEND, which is not available in GossipCop, Snopes, and PolitiFact. We remove visual modality parts of the CCN [1] and report the results using Sentence-BERT [54] and pre-trained BERT with LSTM versions of it, denoted respectively as CCN-sent and CCN-lstm."}, {"title": "4.4 Ablation Studies", "content": "Enabling Different Amount of Evidences. In Table 4, we vary the maximum quantities of evidences for testing. The performances drop evidently compared to the default setting. It suggests that the training stage is impacted altogether by the quantity of evidences, even though some of which might show less relation with the news. The same performance drop happens to results on Snopes and PolitiFact, suggesting this does not depend on evidence quality. As stage one considers evidences sequentially, and produces detection outcomes solely at the final decoder, an excessive input-to-output span thus damages the training. The input of front decoders may be overshadowed as the data propagates deeper. Therefore, limiting the number of input evidence, which equals limiting the depth of SEE, benefits the performance.\nShared or Independent Decoders. In Table 4, we investigate the utilization of a shared decoder informed by time-step information"}, {"title": "5 Conclusions and Future Works", "content": "We introduce SEE, a FND method with Search, Examine and Early-termination based on annotation-free evidences. Our approach incorporates confidence assessment trained on annotation-free evidences for early-termination within examination loops without the effort of human-intervened evidence labelling. Through the method, we are motivated by two key insights, which are then verified by experiments: 1) it is not always necessary to utilize as much evidences as possible to make correct FND prediction, and 2) training models upon well-crafted useful information might mistakenly delude it to highlight the order of all evidences as well as the role played by the most relevant one. Our extensive results underscore the superiority of SEE over state-of-the-art methods, validating its robustness across diverse scenarios. We conclude that SEE excels in distinct evidences utilization and detection capabilities, suggesting that guiding models to assess annotation-free evidences aids in evidence-aware FND.\nWhile we made progress in directly utilizing web-searched raw evidences, the in-depth mechanism of evidence examination as well as that of the early-exiting remains implicit to us. It would be beneficial to further improve the interpretability of FND methods by perhaps utilizing large language models which have zero-shot reasoning abilities for a Q&A."}]}