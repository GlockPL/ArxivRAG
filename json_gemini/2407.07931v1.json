{"title": "Search, Examine and Early-Termination: Fake News Detection with Annotation-Free Evidences", "authors": ["Yuzhou Yang", "Yangming Zhou", "Qichao Ying", "Zhenxing Qian", "Xinpeng Zhang"], "abstract": "Pioneer researches recognize evidences as crucial elements in fake news detection apart from patterns. Existing evidence-aware methods either require laborious pre-processing procedures to assure relevant and high-quality evidence data, or incorporate the entire spectrum of available evidences in all news cases, regardless of the quality and quantity of the retrieved data. In this paper, we propose an approach named SEE that retrieves useful information from web-searched annotation-free evidences with an early-termination mechanism. The proposed SEE is constructed by three main phases: Searching online materials using the news as a query and directly using their titles as evidences without any annotating or filtering procedure, sequentially Examining the news alongside with each piece of evidence via attention mechanisms to produce new hidden states with retrieved information, and allowing Early-termination within the examining loop by assessing whether there is adequate confidence for producing a correct prediction. We have conducted extensive experiments on datasets with unprocessed evidences, i.e., Weibo21, GossipCop, and pre-processed evidences, namely Snopes and PolitiFact. The experimental results demonstrate that the proposed method outperforms state-of-the-art approaches.", "sections": [{"title": "1 Introduction", "content": "The ubiquitous availability and accessibility of the Internet have reshaped the way people obtain and engage with information. Yet, it has concurrently paved the way for the rapid propagation of fake news, which can swiftly amass momentum on social media and various online platforms. The propagation of false information has the potential to yield ill-informed perspectives, with serious implications including public opinion manipulation, concealing the truth, and the incitement of crimes.\nFake News Detection (FND) involves analyzing the probability of news containing misconducting information. Early methods mainly utilize low-level coarse statistical analyses of news content to estimate the veracity of news, e.g., punctuation, lexical statistics [9] or grammar [16]. With the evolution of machine learning techniques, hand-crafted pattern analyzers have been largely supplanted by deep networks. The prevailing methodology is to prepare thousands of real and fake news samples, extracting features from each sample, and constructing a classifier to establish a binary classification boundary. The literature has had success stories from either mining linguistic features, e.g., pragmatic pattern [10], writing style [85], sentiment [87], or visual features, e.g., image quality [26], forgery ar-\ntifacts [8], joint spatial-temporal features [49]. Nevertheless, these methods still rely exclusively on pattern analysis of static news, where the learned abnormal patterns may merely capture the traits of news forgeries within specific datasets or limited temporal windows, neglecting the evolution of attributes of fake news. Besides, attackers could circumvent the pattern analyzers by mimicking the style of real news.\nRecent works [58, 70, 86, 38, 22] have prominently recognized evidence as a premier element in fake news detection apart from patterns. This recognition stems from the observation that individuals tend to search for related news as references during the decision-making process. Researchers have developed many evidence-based FND schemes, where the underlying methodology can be categorized into two types. The first is high-quality dataset contribution, which provides cleaned news-evidence pairs and the label of the news is determined by whether the majority of conclusions from the evidences match that of the news. Famous examples of such datasets include PolitiFact [53], Snopes [46], etc. The second is tailored network design, which explores enhanced strategies for the news-evidence joint learning [38, 72, 78, 80]. These methods usually refine and fuse the representations of all evidence articles together with that of the news [47, 72], somehow resemble learning a boundary from the joint distribution of the news and evidences based on the aforementioned datasets.\nDespite the efforts made in evidence-aware FND, these methods either require laborious pre-processing operations to secure relevant and high-quality evidences during both the training and inference stage, or often utilize all evidences as supplement to the news, regardless of their quality and quantity. In real-world applications, the Internet is capable of providing an exploding amount of similar yet unfiltered materials as evidences for a given news. It presents challenges in calculating similarity or manually scrutinizing each piece of evidence for quality assurance. Furthermore, is it beneficial to examine as many pieces of evidences as possible? Not always. When individuals observe the retrieved queue of evidences, a tendency is to scrutinize it sequentially and decisively: first focusing on the content of the evidences starting from the leading ones, next relating each to the news with comparing and reasoning, and finally quitting reading further when they are confident to make a decision. It motivates us to study ways of more efficient utilization of evidences that devoid of annotating, and ensure resilience to low-quality or less-related retrieved evidences.\nWe propose a new fake news detection approach with annotation-free evidences and early-termination. Our method, SEE, mainly innovates the inference procedure, which includes three main steps. The first is Search, where we search for online materials using the news as query and directly using their titles as evidences without any annotating or filtering procedure. The second is Examine, where we encode news and evidences into representations, and employ separate transformer-based decoders [68] with joint self- and cross-attention for sequential news-evidence information fusion. The third is Early-Termination, where we equip the model with a shared confidence assessor that in each time-step, i.e., index of the evidence in the queue, determines either to continue examining more evidences or to provide a prediction with adequate confidence. Fig. 1 depicts the mechanism of our method, in comparison with the previous paradigm of direct joint news-evidence learning. We design a two-stage training mechanism, where we first train the decoders (or feature extractors) and the ultimate binary classifier for useful representation mining from each time-step. Then we fix these networks to train the confidence assessors where the target is one minus the distance between the predicted result in each time-step and the label of the news.\nTo verify the proposed method, we collect evidences via the Microsoft Bing API [40] for the news in two famous FND datasets, namely, Weibo21 [42] and GossipCop [61], and refrain from making any additional quality control to the retrieved evidences. We apply many state-of-the-art methods on the datasets with the same evidences and experiments show that our method provides the highest average accuracy. Besides, we verify the robustness of our SEE approach by alternation, shuffling, removal, or void insertion of evidences, which show little impact on the overall FND performance. Moreover, we conduct experiments on two more datasets already with processed evidences, namely, Snopes [46] and PolitiFact [47], which also show leading results.\nThe contribution of this paper is three-folded:\n\u2022 We propose a fake news detection approach that is capable of retrieving useful information from annotation-free online retrieved materials, which saves laborious annotating or other pre-processing procedures for quality control over utilized evidences.\n\u2022 We sequentially feed the evidences and devise an early-termination mechanism to use the evidences more efficiently. The assessor gives a confidence score in each time-step and determines when to quit reading further evidences and move on to giving a prediction.\n\u2022 Experiments on datasets without pre-processed evidences, i.e.,"}, {"title": "2 Related Works", "content": "Numerous studies have been conducted to develop automatic methods that detect fake news without considering external evidence. BiGRU [35] and TextCNN [88] respectively use a bidirectional GRU and a 1-D CNN module for feature extraction from the text. BERT [29] is also frequently utilized as FND baselines where the parameters are kept tunable and the classifier works on the CLS token. Ajao et al. [2] propose to analyze the sentimental characteristics of fake news, benefiting some latter works [87]. M\u00b3FEND [91] uses a memory bank to enrich domain information of the news to assist with detection. Also, there are a list of multimodal FND methods that further consider the joint distribution of image and text. Chen et al. [11] use VAEs to compress the images and texts and learn to minimize the Kullback-Leibler (KL) divergence for correctly matched image-text pairs contrastively. Ying et al. [84] extract features from multiple views and design a scoring mechanism to adaptively adjust the weight of each view in the final decision. Zhou et al. [90, 89] design multi-modal fusion mechanisms with pre-trained models. Nevertheless, these methods mainly rely on pattern analysis of static news, neglecting the possible evolvement of characteristics of fake news.\nMany high-quality fake news datasets with evidences are proposed. Snopes [46] and PolitiFact [53] contains retrieved evidence articles for each claim by issuing each claim as a query to the Microsoft Bing API, articles are processed by filtering out those related to Snopes and PolitiFact websites and calculating relevance scores to decide on their usage. Similar datasets are FEVER [66], Emergent [17], etc. In contrast, other famous datasets such as Weibo21 and GossipCop do not provide evidences and therefore have only been applied for pattern-based, rather than evidence-aware, FND. Besides, many tailored detection networks are proposed on top of these datasets. DeClarE [47] averages signals from external evidence articles and concatenates them with the language of the articles and the trustworthiness of the sources. Vo et al. [72] proposes to use hierarchical multi-head attention network to combine word attention and evidence attention. CCN [1] leverages both the image caption and text for online evidences, and detects the consistency of the claim-evidence (text-text and image-image), in addition to the image-caption pairing. Xu et al. [82] introduces GET that applies a Graph Neural Network (GNN) to capture long-distance semantic dependency among the news and evidence articles. However, previous methods either require laborious pre-processing operations towards the evidences, or utilize all evidences for news cases regardless of the quality and quantity. We propose a new FND approach with annotation-free evidences and early-termination."}, {"title": "3 Proposed Approach", "content": "Fig. 2 depicts the pipeline of the proposed SEE approach. It consists of three stages, namely, 1) Searching online materials using the news as query and directly using their titles as the retrieved evidences without any annotating or filtering procedure, 2) sequentially Examining the news alongside with attention mechanisms, which produce new hidden states with richer information, and 3) using Early-termination within the examination loop by assessing whether sufficient confidence for a correct FND prediction exists."}, {"title": "3.1 Search: Evidence Preparation", "content": "Let the input news be N [c, E] \u2208 D, where c, E, D are the text of the news, a queue of the corresponding retrieved evidences and the news dataset, respectively. E = [e1, e2, ...] can be either provided by the dataset along with c, e.g., PolitiFact and Snopes, or prepared by the users via online searching, e.g., Weibo21 and GossipCop. The searching step can be optional if the evidences can be prepared in advance, otherwise, we prevail the circumvention of laborious annotating or other pre-processing operations on E for quality control. For evidence retrieval, our preliminary is that users trust a certain credibility control of the applied searching engine for collecting evidence through the corresponding API. Here, we apply the popular Microsoft Bing to collect evidences. To benchmark \"annotation-free\" evidence retrieval, we purposefully exclude any pre-processing operations other than pasting the news content into the search box & clicking \"Search\" for all datasets. We turn each piece of the retrieved material into evidence via recording its title, in accordance with Snopes and PolitiFact, and store in order at most N evidences in each &, where N is a tunable hyper-parameter. Exampled N for Weibo21 and GossipCop are provided in the experiments. Next, we adopt the BERT model [29] as the preliminary feature extractor for both news and the evidences. The representations of the news and evidences are respectively denoted as C = BERT(c) \u2208 RL\u00d7d, Pi = BERT(ei) \u2208 RLxd, i \u2208 [1, N], and d denotes the feature dimension."}, {"title": "3.2 Examine: Attention-based News-evidence Fusion", "content": "We prepare a cascade of N independent transformer decoders [29] with joint self- and cross-attention to sequentially examine the news alongside with each piece of evidence and produce new hidden states with richer information. Each decoder is responsible for feature fusion for a typical time-step. The first block takes C and the leading evidence P1 as inputs, and outputs R1, which we call hidden state of the first time-step. The following blocks take the hidden state by the previous block and the initial embedding of the upcoming evidence to iteratively produce a list of hidden states. We use the attention mechanism and feed-forward layer operation in typical transformers [29], denoted with Attn(\u00b7) and FFN(\u00b7). Specifically, the attention operation has:\nAttn(Q, K, V) = softmax( QKT\u221adk\n)V, (1)\nwhere Q, K, V denotes the query, key, and value matrix.\nIn the decoders, we combine both self-attention and cross-attention in the examining step for news-evidence interaction. Each decoder consists of three layers: a self-attention block, a cross-attention block, and a feed-forward network. Each layer has a residual connection to the previous layer and is attached to a layer normalization. For simplicity in equations, we use overlines to denote the Layer Normalization operations (LN) [4]. The examination process of a decoder block is:\nL1 =\n{\nC + Attn(C, C, C), if k = 1\nRk\u22121 + Attn(Rk\u22121, Rk\u22121, Rk\u22121) otherwise,\nL2 = L1 + Attn(L1, Pk, Pk),\nRk = L2 + FFN(L2).\n(2)\nNote that each decoder is independent and receives evidence from a specific index in the queue, where the inherent relationship between each index and its statistical relevance of the evidence to the news can be implicitly learned. One can also alternatively employs a shared"}, {"title": "3.3 Early-termination: Exit When \u201cConfident\u201d", "content": "Consider that examining all evidences as supplements to the news regardless of the quality and quantity might be sub-optimal, as the existence of low-quality or less-relevant evidences could impact the model performance. We introduce the early-termination step that enables the model to cease further examining more pieces of evidence and proceed to prediction if a confidence threshold is surpassed within each time-step.\nIn detail, the confidence assessor visits every hidden state Rk, k \u2208 [1, N] and reduces them into confidence scores sk. We set a hyper-parameter \u03c4 as a threshold. \u03c4 is set to decide whether to continue the examining step by sending Rk and the next, if exists, evidence into the next decoder, or to terminate and make the prediction, denoted as \u0177, by sending Rk into the classifier. T is another hyper-parameter, which has a non-negligible effect on both the overall ratio of early-termination and detection performance. We give a detailed analysis of \u03c4 in Section 4.2.\nDuring the iterative examining and confidence assessment, we record the hidden state with the highest confidence score, denoted as R'. If the last evidence is reached, we resort to using R' with the highest score to make the prediction \u0177. The classifier is a three-layer perceptron and a sigmoid function. Therefore, we denote the calculation procedure of \u0177 as follows.\n\u0177 =\n{\n\u03c3(MLP(Rk)), if sk > \u03c4\n\u03c3(MLP(R\u2032)) otherwise,\n} (3)\nFor the confidence assessor, given a hidden state Rk at time-step k, we first reduce the token dimension using average pooling over all tokens and use a fully-connected layer f(\u00b7) to reduce it into a logit, which is further mapped within [0, 1] as the confidence score by a sigmoid function \u03c3(\u00b7).\n\nRk = AvgPool(Rk),\nsk = \u03c3(f(Rk)).\n(4)"}, {"title": "3.4 Two-staged Training Mechanism", "content": "There is no external label for the confidence assessment process. We propose a two-staged training mechanism where we first solely emphasize on feature extraction from evidences, and then train an assessor to determine when to exit with fixed feature extractors. Soft labels are automatically assigned in each time-step by comparing the current predicted result with the ground-truth FND hard label.\nStage One: Training Feature Extractors and Classifier. The initial phase involves training the feature extractors, i.e. the tunable BERT and decoders, and the classifier. The confidence assessor remains uninvolved during this stage. Specifically, we iteratively feed all N evidences without early-termination, and every decoder generates a unique hidden state in each time-step. The goal is to enable the decoders to extract useful features from the provided news and evidences at different time-steps. The hidden state of the last decoder RN is then fed to the classifier, which produces \u0177N. We update the networks using the classification loss Lcls, where\nLcls = \u2212y log(\u0177N) + (1 \u2212 y) + (1 \u2212 y) log(1 \u2212 \u0177N). (5)\nThe classifier is also jointly trained in the settings where all N evidences are provided. The purpose of this stage is to provide the classifier with adequate information for decision-making as well as en-"}, {"title": "4 Experiments", "content": "We use bert-base-chinese and bert-base-uncased pre-trained models for processing Chinese dataset and English datasets, respectively. The hidden size of word embeddings is 768 (d = 768). We unify the length of input news and evidence to a specific length by padding or truncating (L = 100). For samples with fewer than N evidence, the missing evidences are treated as blank and filled with [PAD] tokens. To save computation, the representations can be pre-computed, stored on disk and loaded upon training. Our model is trained using a single NVIDIA GeForce RTX 4090 GPU. We use Adam optimizer [31] with default parameters. The batch size is 12. We use a learning rate of 6 \u00d7 10\u22126 for the feature extractors, i.e., fine-tuned BERT and the decoders, and 5 \u00d7 10\u22125 for the rest of the model.\nWe use four famous datasets, namely Weibo21 [42], GossipCop [61], Snopes [46], and PolitiFact [47] for our experiments. Weibo21 is a Chinese fake news detection dataset collected from Sina Weibo. News content of GossipCop, Snopes, and PolitiFact are collected from fact-checking websites. Weibo21 and GossipCop do not contain official evidences, so we collect evidence articles for them by the method mentioned in Section 3.1. We conduct train-val-test split in the ratio of 6:2:2 in accordance with previous methods. Table 1 summarizes these datasets."}, {"title": "4.2 Performance Analysis", "content": "Before conducting extensive comparisons with previous state-of-the-arts, we first study the impact of different implementation settings additionally considering the trade-off between accuracy and efficiency. According to Fig. 4, \u03c4 = 0.745 and \u03c4 = 0.660 respectively yield the best accuracy on the validation set of Weibo21 and GossipCop. Besides, the optimal threshold for Snopes is T = 0.715, and that for PolitiFact T = 0.690. In practical scenarios, since the four applied datasets are representative and popular, users can select a proper \u03c4 ranging from 0.715 to 0.745 for Chinese news, or 0.660 to 0.690 for English news. Moreover, the experiments indicate that even when the threshold is roughly set within an acceptable small range, the caused variation in accuracy is within 2% of the peak value for both datasets.\nImpact of the Retrieved Results. Provided with the same query, the searching engine might also retrieval different combinations of materials over time, potentially changing the prediction results of fact-checking based FND methods. Therefore, after the selection of proper \u03c4, we also study the impact of the retrieved results from the view of quality, quantity, and order. The settings are: 1) Most Related Swapped presents the leading three (usually most related) materials in the retrieved queue in an arbitrary order, while keeping intact the remaining materials. 2) All Evidences Shuffled simulates a more challenging scenario where all materials are in an arbitrary order. 3) Reverse the Sequence simulates a scenario in which less relevant evidence is examined first, which is an even more challenging scenario compared to All Evidences Shuffled. 3) Most Related Void simulates that the first (primary) evidence conveys no valuable information, e.g., due to advertisement or failed retrieval. In this case the first evidence is replaced with a random irrelevant article. 4) Most Related Missing simulates the absence of the primary evidence. In this case the first evidence is simply polled out from the queue. 5) Limited Evidences (n) simulates that the searching queue only contains a maximum of n evidence. On doing the experiments, we first train our model using the default content and order of evidences in each dataset, and then test them using the above-mentioned settings.\nThe results are reported in Table 2. Among all adjustments, providing limited evidences (1 or 3) decreases performance most evidently, which suggests that considering more evidence is necessary for detection. Adjustments on the order of evidences or the content of the most related evidences result in different performance drop trend on different datasets. For datasets without pre-processed evidences, i.e., Weibo21 and GossipCop, we see that the performance drop is trivial, i.e., usually less than 1%. In contrast, the drop is more noticeable on datasets with pre-processed evidences, i.e., Snopes and PolitiFact, even if only the leading materials are swapped. The finding suggest that the pre-filtering stage might has the ability to indeliberately mislead the model to over-highlight the order of the evidences as well as the role played by the most related evidence. In comparison, using annotation-free evidences suggest a more robust and consistent result less affected by the quality of the first evidence and the order."}, {"title": "4.3 Comparisons", "content": "The compared benchmark methods are listed in Table 3. Since our testing datasets might not have been used by some of the baseline methods, we carefully re-implemented them by providing all available required data, e.g., publisher information, propagation graph, etc. In contrast, SEE refrains from using the related additional information other than annotation-free evidences.\nImplementation of Baselines. DeClare [47] and GET [82] also require publisher information and other propagation-based information. As such, we do not directly borrow the experimental results from their papers and instead collect related information and carefully retrain the models on the testing datasets. GET involves generating graphs by segmenting words and using pre-trained embeddings, and we implement this on Weibo21 by using jieba 2 and Chinese word vectors pre-trained on weibo [32]. Domain information of news is mandatory for M\u00b3FEND, which is not available in GossipCop, Snopes, and PolitiFact. We remove visual modality parts of the CCN [1] and report the results using Sentence-BERT [54] and pre-trained BERT with LSTM versions of it, denoted respectively as CCN-sent and CCN-lstm."}, {"title": "4.4 Ablation Studies", "content": "In Table 4, we vary the maximum quantities of evidences for testing. The performances drop evidently compared to the default setting. It suggests that the training stage is impacted altogether by the quantity of evidences, even though some of which might show less relation with the news. The same performance drop happens to results on Snopes and PolitiFact, suggesting this does not depend on evidence quality. As stage one considers evidences sequentially, and produces detection outcomes solely at the final decoder, an excessive input-to-output span thus damages the training. The input of front decoders may be overshadowed as the data propagates deeper. Therefore, limiting the number of input evidence, which equals limiting the depth of SEE, benefits the performance.\nIn Table 4, we investigate the utilization of a shared decoder informed by time-step information through positional encodings. The resulting accuracy witnesses declines of 4.9% and 1.7%, 4.4%, and 4.2%, on four datasets respectively, suggesting that assigning a single decoder to capture universal features across evidences sequential locations compromises the examination proficiency of the proposed SEE.\nWe test the necessity of the two-staged training by altering it with training the model in one go, in which we jointly train all components. During training, the hidden state at each time-step is directed into the assessor. In instances where termination is deemed appropriate, the remaining evidences are disregarded, leaving subsequent decoders untrained. The proposed approach suffers from performance drops under this alternative approach on all datasets. According to our observation of details, a substantial number of samples tend to terminate right after the first decoder block, indicating that the confidence assessment holds limited validity. We conclude that jointly training all components damages both the examination and termination abilities of SEE.\nPrevious methods mainly utilize concatenation to fuse representations of examined evidences. We exclude the confidence assessment during inference by concating the hidden states at all time-steps, which produces a hidden representation of size L \u00d7 Nd. This setting underperforms baseline settings, which demonstrates the effectiveness of sequential examination of evidence."}, {"title": "5 Conclusions and Future Works", "content": "We introduce SEE, a FND method with Search, Examine and Early-termination based on annotation-free evidences. Our approach incorporates confidence assessment trained on annotation-free evidences for early-termination within examination loops without the effort of human-intervened evidence labelling. Through the method, we are motivated by two key insights, which are then verified by experiments: 1) it is not always necessary to utilize as much evidences as possible to make correct FND prediction, and 2) training models upon well-crafted useful information might mistakenly delude it to highlight the order of all evidences as well as the role played by the most relevant one. Our extensive results underscore the superiority of SEE over state-of-the-art methods, validating its robustness across diverse scenarios. We conclude that SEE excels in distinct evidences utilization and detection capabilities, suggesting that guiding models to assess annotation-free evidences aids in evidence-aware FND.\nWhile we made progress in directly utilizing web-searched raw evidences, the in-depth mechanism of evidence examination as well as that of the early-exiting remains implicit to us. It would be beneficial to further improve the interpretability of FND methods by perhaps utilizing large language models which have zero-shot reasoning abilities for a Q&A."}]}