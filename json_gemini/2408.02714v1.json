{"title": "MDM: Advancing Multi-Domain Distribution Matching for Automatic Modulation Recognition Dataset Synthesis", "authors": ["Dongwei Xu", "Jiajun Chen", "Yao Lu", "Tianhao Xia", "Qi Xuan", "Wei Wang", "Yun Lin", "Xiaoniu Yang"], "abstract": "Recently, deep learning technology has been successfully introduced into Automatic Modulation Recognition (AMR) tasks. However, the success of deep learning is all attributed to the training on large-scale datasets. Such a large amount of data brings huge pressure on storage, transmission and model training. In order to solve the problem of large amount of data, some researchers put forward the method of data distillation, which aims to compress large training data into smaller synthetic datasets to maintain its performance. While numerous data distillation techniques have been developed within the realm of image processing, the unique characteristics of signals set them apart. Signals exhibit distinct features across various domains, necessitating specialized approaches for their analysis and processing. To this end, a novel dataset distillation method-Multi-domain Distribution Matching (MDM) is proposed. MDM employs the Discrete Fourier Transform (DFT) to translate time-domain signals into the frequency domain, and then uses a model to compute distribution matching losses between the synthetic and real datasets, considering both the time and frequency domains. Ultimately, these two losses are integrated to update the synthetic dataset. We conduct extensive experiments on three AMR datasets. Experimental results show that, compared with baseline methods, our method achieves better performance under the same compression ratio. Furthermore, we conduct cross-architecture generalization experiments on several models, and the experimental results show that our synthetic datasets can generalize well on other unseen models.", "sections": [{"title": "I. INTRODUCTION", "content": "In recent years, deep learning techniques have been gradually introduced into AMR tasks [1]\u2013[5] and have achieved great success. The success of deep learning is due to training on large datasets, but such a large amount of data poses a huge challenge for storage and transmission, and brings a significant amount of time and computing resource overhead for model training. In order to solve this problem, some researchers have proposed a promising direction named dataset distillation (DD), which aims to use limited data to train the model in a more efficient way, thereby reducing the training cost and improving the model performance.\nDD was firstly proposed by Wang et al. [6] in 2018, which viewed model parameters as a function about the synthetic dataset and updated the synthetic dataset by minimizing the training loss of the original training data with respect to the synthetic data. Subsequently, Zhao et al. [7] proposed a method named Dataset Condensation (DC). This method updated the synthetic dataset by matching the gradient between the real training set and the synthetic dataset. Zhao et al. [8] proposed Differentiable Siamese Augmentation (DSA), which brought data augmentation technique to DC and achieved better performance. Zhao et al. [9] proposed a method based on Distributed Matching (DM), which used a model to extract high-dimensional features of the synthetic dataset and the original training set, and updated the synthetic dataset by matching the distance between the two high-dimensional features. Lu et al. [10] introduced two plug-and-play loss terms, CLoM and CCloM, which provide stable guidance for optimizing synthetic datasets. Although many data distillation techniques have been developed for image processing, signals have unique attributes like temporal dynamics and frequency characteristics that set them apart. These differences mean that conventional image processing techniques may not be effective for signals, requiring specialized methods tailored to the specific nature of signals for AMR tasks.\nTo this end, this paper combines the time domain and frequency domain of the signal to achieve the complementary gain of the information in the two domains. The time domain signal is first mapped to the frequency domain using the DFT [11], and the DM loss between the real training set and the synthetic dataset is then computed in both time and frequency domains. The two losses are combined as the final objective function. By minimizing the objective function, the optimal synthetic dataset is achieved. Experiments are conducted on three modulated signal datasets: RML2016.10a-high, RML2016.10a [12] and Sig2019-12-high [1]. Additionally, cross-architecture generalization experiments are carried out on the AlexNet [13] and VGG16 [14] models. Random selection, Forgetting [15], DC [7] and DM [9] are taken"}, {"title": "II. MULTI-DOMAIN DISTRIBUTION MATCHING", "content": "A. Dataset Condensation Problem\nA large-scale training dataset and a small synthetic dataset can be expressed as follow:\n$T = \\{(x_1^T, y_1^T), ..., (x_{|T|}^T, y_{|T|}^T)\\}$\n$x^T = [I^T (n), Q^T (n)], n = 0, 1, ..., N -1$\n$S = \\{(x_1^S, y_1^S), ..., (x_{|S|}^S, y_{|S|}^S)\\}$\n$x^S = [I^S (n), Q^S(n)], n = 0, 1, ..., N \u2013 1$\nwhere $|T|$ indicates that the training dataset $T$ contains $|T|$ signals and labels; $x^T$ represents the signal in the training dataset; each signal $x^T$ is represented by an $I$ channel and a $Q$ channel; each channel has $N$ sampling points; $|S|$ indicates that the synthetic dataset $S$ contains $|S|$ signals and labels; $x^S$ denotes the signal of the synthetic dataset, and $|T| > |S|$.\nB. Distribution Matching in Time Domain\nFirst, a neural network model $\\psi_\\theta$ is randomly initialized, which is used to obtain low-dimensional embeddings of real signal $x$ and synthetic signal $x^S$. Then the maximum mean discrepancy (MMD) [16] is used to estimate the distance between the real data distribution and the synthetic data distribution. Finally, this distance is taken as a loss function in the time domain, which can be expressed as:\n$L^{TD} = E_{\\theta \\sim P_{\\theta}} ||\\frac{1}{|T|} \\sum_{j=1}^{|T|} \\psi_{\\theta}(x_j^T) - \\frac{1}{|S|} \\sum_{m=1}^{|S|} \\psi_{\\theta}(x_m^S) ||^2$\nwhere $P_{\\theta}$ represents the distribution of network parameters; TD indicates Time Domain."}, {"title": "C. Discrete Fourier Transform", "content": "DFT is a basic method in signal analysis that transforms a discrete time series signal from the time domain to the frequency domain.\nIn order to align with the time domain signal, DFT is performed on $I^T (n)$ and $Q^T(n)$ of signal $x$ in the training dataset, and they are then spliced together. The frequency domain signals of the two channels are also obtained, which can be expressed as follows:\n$I^T (k) = | \\sum_{n=0}^{N-1} I^T (n)e^{-j2\\pi kn/N}|, k = 0,1, ..., N \u2013 1$,\n$Q^T (k) = | \\sum_{n=0}^{N-1} Q^T (n)e^{-j2\\pi kn/N}|$,\n$X^T = [I^T (k), Q^T (k)]$,\nwhere $X^T$ represents the frequency domain representation of each signal in the training dataset; each signal $X^T$ has two channels: $I^T(k)$ and $Q^T(k)$; each channel has $N$ sampling points (the input of the DFT is $N$ discrete points and the output of the DFT is $N$ discrete points). The same operation is performed on the synthetic dataset, which can be expressed as:\n$X^S = [I^S (k), Q^S (k)]$\nwhere $X^S$ denotes the frequency domain representation of each signal in the synthetic dataset; $I^S(k)$ is the output of $I^S(n)$ after DFT, and $Q^S(k)$ is the output of $Q^S(n)$ after DFT.\n D. Distribution Matching in Fequency Domain\nThen, the low-dimensional embeddings of real signal $X^T$ and synthetic signal $X^S$ from the frequency domain are obtained by using $\\psi_\\theta$. MMD is used to estimate the distance between the real data distribution and the synthetic data distribution in the frequency domain. The distance is used as a loss function in the frequency domain, which can be expressed as:\n$L^{FD} = E_{\\theta \\sim P_{\\theta}} ||\\frac{1}{|T|} \\sum_{j=1}^{|T|} \\psi_{\\theta}(X_j^T) - \\frac{1}{|S|} \\sum_{m=1}^{|S|} \\psi_{\\theta}(X_m^S) ||^2$\nwhere FD means Frequency Domain. The framework of MDM is shown in the Fig. 1."}, {"title": "E. Combination of Time Domain and Frequency Domain", "content": "Inspired by [17], we believe that combining the time and frequency domain information of the signal is better than using only a single signal domain information.\nTherefore, we combine the distribution matching loss in the time domain and frequency domain as the total loss:\n$L = L^{TD} + \\alpha L^{FD}$\nwhere $\\alpha$ is a tunable hyeprparameter. The value of $\\alpha$ in the experiment depends on the dataset. The overall pipeline is summarized in Algorithm 1."}, {"title": "III. EXPERIMENTS", "content": "A. Dataset\nTo evaluate the effectiveness of our method, we conducted experiments on three signal modulation classification datasets RML2016.10a, RML2016.10a-high, and Sig2019-12-high.\nRML2016.10a uses GNU radio to synthesize electromagnetic signals containing I and Q channels. There are a total of 11 modulation signal categories in the dataset, QPSK, 8PSK, BPSK, BFSK, 16QAM, 64QAM, CPFSK, PAM4, AM-SSB, WB-FM and AM-DSB, the first 8 types are digital modulation types, and the last 3 types are analog modulation types. The dataset uses an electromagnetic signal with a signal-to-noise ratio (SNR) range from -20db to 18dB and a signal length of 128. We divide the dataset into a training set and a test set with a ratio of 4:1.\nRML2016.10a-high is the part of RML2016.10a dataset with SNRs ranging from 10 dB to 18 dB. We also divide the dataset into the training set and the test set with a ratio of 4:1.\nSig2019-12-high is a subset of Sig2019-12, which is a self-generated dataset by Chen et al. [1]. Sig2019-12 contains 12 modulation types, namely OPSK, 8PSK, BPSK, 4PAM, 8PAM, OQPSK, 16QAM, 32QAM, 64QAM, 2FSK, 4FSK and 8FSK. The signal-to-noise ratio of the dataset ranges from -20db to 30db. [18], we select signals above 10dB, comprising a training set of 120,000 signal samples and a test set with 60,000 signal samples.\nB. Model Architecture\nIn our experiments, an AlexNet model is used to learn synthetic dataset. For the evaluation phase, 5 AlexNet models are randomly initialized and trained from scratch using the"}, {"title": "D. Results and Analysis", "content": "Our method is compared with several baseline methods: Random Selection, Forgetting, DC, and DM. These baselines are briefly summarized as follows:\n\u2022 Random Selection: This algorithm randomly selects a certain number of training samples from each class of training samples as synthetic samples.\n\u2022 Forgetting: This method counts how many times a train-ing sample is learned and then forgotten during network training. The samples that are less forgetful can be dropped.\n\u2022 DC: This method synthesizes a small but informative dataset by matching the loss gradients with respect to the training and synthetic datasets.\n\u2022 DM: This method aims to minimize the MMD between the synthetic dataset and the real dataset.\nComparison to coreset selection methods. Our method is first compared with the coreset selection baselines. As shown in Table I, only when the dataset is RML2016.10a-high, SPC=100, Forgetting method has better results than MDM. In other cases, MDM is superior to Random Selection method and Forgetting method. This indicates that MDM generally surpasses coreset selection methods in most cases.\nComparison to DC and DM. As can be seen from Table I, MDM is superior to the DC and DM in all cases. In most cases, our method is more than 1% better than DM. These results illustrate that MDM, by incorporating frequency"}, {"title": "E. Cross-Architecture Generalization.", "content": "Cross-architecture generalization experiments are also conducted. Specifically, for the RML2016.10a-high dataset, 50 condensed signals per class are synthesized using two distinct models: AlexNet and VGG16. These synthesized signals are then evaluated across multiple architectures, including AlexNet, 1D-ResNet, 2D-CNN, VGG16, and MCLDNN. In Table II, the synthetic dataset is learned with one architecture (C) and then evaluated on another architecture (T) by training a model from scratch and testing on real testing data. The experimental results show that the synthetic dataset trained on AlexNet and VGG16 performs best on AlexNet, with strong performance on VGG16 as well. It also achieves promising results on 1D-ResNet, 2D-CNN, and MCLDNN, indicating strong cross-model generalization."}, {"title": "F. Visualization", "content": "The training set and synthetic dataset are visualized in Fig. 2, showing time and frequency domain diagrams for each signal type when SPC=50 on the RML2016.10a-high dataset. The top rows display the training set diagrams, while the bottom rows show the synthetic dataset. The characteristics of the synthetic samples closely resemble those of the training set."}, {"title": "IV. CONCLUSION", "content": "In this paper, we propose a novel dataset distillation method named MDM. MDM maps the time domain signal to the frequency domain by DFT, and combines the time domain and frequency domain characteristics of the signal to distill the data, which makes up the gap of the dataset distillation method in the task of signal modulation recognition. Experiments reveal that the proposed method outperforms existing baselines and can generalize well on other unseen models."}]}