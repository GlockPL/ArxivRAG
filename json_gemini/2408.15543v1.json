{"title": "An Investigation of Warning Erroneous Chat Translations in Cross-lingual Communication", "authors": ["Yunmeng Li", "Jun Suzuki", "Makoto Morishita", "Kaori Abe", "Kentaro Inui"], "abstract": "Machine translation models are still inappropriate for translating chats, despite the popularity of translation software and plug-in applications. The complexity of dialogues poses significant challenges and can hinder cross-lingual communication. Instead of pursuing a flawless translation system, a more practical approach would be to issue warning messages about potential mistranslations to reduce confusion. However, it is still unclear how individuals perceive these warning messages and whether they benefit the crowd. This paper tackles to investigate this question and demonstrates the warning messages' contribution to making chat translation systems effective.", "sections": [{"title": "1 Introduction", "content": "Globalization has led to the popularity of neural machine translation (Bahdanau et al., 2014; Vaswani et al., 2017; Gehring et al., 2017). Applications like Google Translate\u00b9 and DeepL2 have become essential tools in people's lives (Medvedev, 2016; Patil and Davies, 2014). Chat software such as WeChat and LINE also integrates built-in translation features to facilitate cross-lingual communication. Plug-in translating applications like UD Talk\u00b3 and Hi Translate\u2074 have become popular as well with the rise of online communication.\nHowever, while machine translation technologies have demonstrated sound performance in translating documents (Barrault et al., 2019, 2020; Nakazawa et al., 2019; Ma et al., 2020; Maruf and Haffari, 2018), current methods are not always suitable for translating conversations (Uthus and Aha, 2013), especially colloquial dialogues such as chats (L\u00e4ubli et al., 2018; Toral et al., 2018; Farajian et al., 2020; Liang et al., 2021a). When a translation system generates erroneous translations, people unable to read the other language may not recognize such errors, leading to confusion.\nAchieving a perfect error-free chat translation system is challenging due to the unique characteristics of chat (Tiedemann and Scherrer, 2017; Maruf et al., 2018; Liang et al., 2021a,b), making it impractical to aim for perfection. Instead, a viable alternative approach is to enhance translation software by providing warnings about possible mistranslations to reduce confusion. However, the perception and effects of such warning messages remain unclear. To investigate this, we proposed to provide a warning message for erroneous translations during the cross-lingual chat and conducted a survey to explore how such warnings help people communicate. The survey design is shown in Figure 1. Participants engage in a simulated cross-lingual chat scenario, where they have to select the most reasonable response from three options. Whenever a translation error occurs, a warning message is displayed. At the end of the chat, participants answer corresponding questions regarding their perceptions of the warning messages.\nWe conducted the survey and collected responses through crowdsourcing. The results indicate that warning messages (1) are helpful in cross-lingual chats and (2) potentially encourage users to change their chat behavior. Moreover, the survey reveals the crowd's desired features for the warning messages. This is the first study of its kind to explore the impacts of warning users about erroneous translations in cross-lingual chat. The findings are valuable for developing an assistant function that detects and warns users of erroneous chat translations."}, {"title": "2 Related Work", "content": "Previous studies have pointed out the potential benefits of incorporating machine translation in chat, despite its imperfections (Uthus and Aha, 2013)."}, {"title": "3 Survey Design", "content": "We propose an alternative strategy to improve translation software's performance by integrating cautionary alerts for potential mistranslations to reduce confusion. We designed a warning message and executed a survey to evaluate its effectiveness. Figure 1 illustrates the survey process, including two simulated chat rounds: one devoid of warning messages and the other incorporating them."}, {"title": "3.1 Simulated Cross-lingual Chat Scenarios", "content": "Since dynamic real-time chats are relatively uncontrollable and high-cost, we simulated a chat scenario with a foreign partner based on chat data from Persona-chat (Zhang et al., 2018). In the simulation, participants are presented with three initial chat turns as historical chat logs at the beginning.Participants choose the most contextually fitting response from the three provided options each time their scripted partners respond iteratively. To explore the cognitive processes of individuals lacking proficiency in a foreign language, we operated under the assumption that participants would receive translated messages generated by the machine translation system from their partners. Hence, all texts within the survey are presented to participants in their native language."}, {"title": "3.2 Chat Data", "content": "We prepared the simulated scenarios with the Persona-chat dataset, containing multi-turn chat data about various personality traits with assumed personas in English. To ensure the quality of the data, we eliminated incoherent and unnatural chat data from Persona-chat through crowdsourcing at Amazon Mechanical Turk 5. We defined \"inco-"}, {"title": "3.3 Erroneous Translations", "content": "To provide the chat data that were supposed to be erroneous translations, we translated the prepared chat data with a low-quality machine translation model that achieved a considerably low BLEU score (Papineni et al., 2002) of 4.9 on the English-Japanese chat translation evaluation dataset BPersona-chat (Li et al., 2022a). Consequently, we transformed the low-quality translations twenty times through Google Translate into different languages and finally translated them back to the source language of the survey. To ensure the final translations could serve as erroneous translations, we manually confirmed that the texts included significant syntax issues, incorrect emotional expressions, incoherence, or other errors that led to confusion. We designed that at least one of the three turns of the simulated chat would include erroneous translations. We required proficient English speakers to continue the chat based on the erroneous translations to prepare the extended chat."}, {"title": "3.4 Warning Messages", "content": "We designed the warning message to notify participants of erroneous translations in the chat. When the current text is assumed to be the erroneous translation, participants are presented with a warning message alerting them of the mistranslation, as shown in Figure 1. We structured the warning messages into two types since receiving and sending are both essential in a conversation. One type alerts participants of erroneous translations in the messages they received, while the other type indicates potential errors in the last message they sent."}, {"title": "3.5 Corresponding Questions", "content": "After the chat, participants are asked to answer if they notice erroneous translations without hints. If participants answer yes, they rate their experience on two Likert Scale questions (Joshi et al., 2015; Nemoto and Beglar, 2014). The first question assesses the extent to which the errors prevented them from continuing the chat, while the second question asks to what extent they could grasp exactly where the erroneous translations were in the message. Participants will use 1-5 to score their perceptions, with higher numbers indicating a greater awareness or understanding of the errors.\nParticipants must also rate on a Likert Scale question the extent to which they think the warning helped them continue the chat. Further, they check the plural options of additional features they find helpful if added to the warnings. Selectable features include: indicating the correctness rate of the translation, providing alternative translation suggestions, showing specific errors in the translation, and suggesting the emotion of their partner."}, {"title": "4 Crowdsourcing Experiments", "content": "We prepared the survey in English, Chinese, and Japanese to observe the possible difference between languages. Professional translators translated the data from English to Chinese and Japanese to ensure quality. We prepared three sets of chat data for each type of warning message and two types of warnings; hence, we provided six sets of chat and collected the responses through crowdsourcing. We provided instructions for participants on how the chat would be presented and what they should do to attend the chat at the beginning of the task. Participants would be acknowledged that (1) their partner would speak to them in a language other than their native language, (2) the system would translate their partners' messages and the chat would only be presented in their language, (3) they would read the chat log and choose the most reasonable of the three options, (4) the message sent to them would be displayed on the odd-numbered lines, and their answer would be displayed on the even-numbered lines.\nTo minimize any possible influence of showing warnings first or later, we provided each chat in two orders. Participants answer either without warning messages first or with warning messages first. At the round of warning messages, we would explain the role of warning messages to participants and inform them that they could refer to the warnings"}, {"title": "5 Results and Analysis", "content": "Under the different policies of crowdsourcing platforms, we finally gathered 604 English, 635 Chinese, and 621 Japanese responses. Figure 2 displays the overall summaries. Around 70% of participants across three languages rated the warning messages as \u201c4 - helpful\u201d or above in the chat. Most participants view the warning messages as helpful in cross-lingual chats, aligned with Likert Scale analysis (Amidei et al., 2019).\nWith or without warning messages The results of \"Without hints, do you think there were erroneous translations in the chat\" based on the order in which participants answered the survey are listed in Table 1. The percentages of noticing erroneous translations without hints remain consistent, regardless of participants answering with warning messages first or after. Hence, we conclude that the impact of answering orders on the crowds appears minimal. Moreover, considering a score greater or equal to 4 suggests the positivity of a Likert\nImpact of warning messages on modifying user's chat behavior We analyzed participants' choices in relation to warning messages, categorizing them into three cases: (1) entered the same scenario in both the round with warnings and the round without warnings and did not change their choices, (2) entered the same scenario in both rounds and changed their choices, and (3) did not change their choices due to entering other branches in advance. We believe that the first case demonstrates that participants were not influenced by warnings, while the second case shows that they were influenced. In the third case, although it is impossible to compare whether participants changed their choices in the same scenario since they changed earlier, we still view it as an indirect influence due to the equiv-\nalence between having no warning messages and having no erroneous translations. Indeed, 103 participants stated they changed their choices as they ensured there were no erroneous translations.\nSurvey results shown in Figure 3 indicate that approximately 25% participants remained unchanged, while about 75% changed their choices, either directly or indirectly, due to the warning messages. We confirm that the participants were genuinely influenced by warning messages and participated in the subsequent feedback.\nWarnings on the received messages or the sent messages The collected responses of different types of warning messages are summarized in Fig-"}, {"title": "6 Conclusions", "content": "We conducted a survey to investigate the effectiveness of warning about possible mistranslations in chat as an alternative approach to enhance the experience of cross-lingual communication. Through crowdsourcing, we collected responses and concluded that such warning messages are helpful. By comparing the participants' choices with and without warning messages, we found that the warning messages did encourage participants to change their behaviors. We also found the crowd expects the warning message to (1) show the specific error in the translation, (2) indicate the correctness rate of the translation, and (3) provide alternative translation suggestions.\nThis survey is the first to explore the effects of warning about erroneous translations in cross-lingual chat, providing valuable insights for developing an assistant function that detects and warns people of erroneous chat translations."}, {"title": "Limitations", "content": "During the survey design phase, diligent measures were taken to minimize potential leading effects on the participants' judgment by randomly switching the order and neutralizing the questioning style. Despite the conscientious efforts, we must acknowledge the inherent challenges in completely eliminating all influences on the people who participated in the survey. With this realization, we recognize the need for further optimization to guarantee the fairness and validity of the responses. Refinement is warranted to minimize the biases further."}, {"title": "Ethics", "content": "The crowdsourcing survey employed in this study adheres to stringent ethical guidelines to ensure participant privacy and data protection. The survey design deliberately avoids collecting any personally identifiable information from the participants. No restrictions or enforcement of work hours were imposed upon participants, thereby eliminating undue influence or coercion. Given the absence of personal data collection and voluntary participation, the data is not subject to ethics review at the organization. Consequently, the survey design and data collection procedures adhere to the ethical standards and regulations governing research practices."}]}