{"title": "An Investigation of Warning Erroneous Chat Translations\nin Cross-lingual Communication", "authors": ["Yunmeng Li", "Jun Suzuki", "Makoto Morishita", "Kaori Abe", "Kentaro Inui"], "abstract": "Machine translation models are still inappro- priate for translating chats, despite the popu- larity of translation software and plug-in appli- cations. The complexity of dialogues poses significant challenges and can hinder cross- lingual communication. Instead of pursuing a flawless translation system, a more practical approach would be to issue warning messages about potential mistranslations to reduce con- fusion. However, it is still unclear how indi- viduals perceive these warning messages and whether they benefit the crowd. This paper tackles to investigate this question and demon- strates the warning messages' contribution to making chat translation systems effective.", "sections": [{"title": "1 Introduction", "content": "Globalization has led to the popularity of neural ma- chine translation (Bahdanau et al., 2014; Vaswani et al., 2017; Gehring et al., 2017). Applications like Google Translate\u00b9 and DeepL2 have become essential tools in people's lives (Medvedev, 2016; Patil and Davies, 2014). Chat software such as WeChat and LINE also integrates built-in transla- tion features to facilitate cross-lingual communi- cation. Plug-in translating applications like UD Talk\u00b3 and Hi Translate\u2074 have become popular as well with the rise of online communication. However, while machine translation technolo- gies have demonstrated sound performance in trans- lating documents (Barrault et al., 2019, 2020; Nakazawa et al., 2019; Ma et al., 2020; Maruf and Haffari, 2018), current methods are not always suitable for translating conversations (Uthus and Aha, 2013), especially colloquial dialogues such as chats (L\u00e4ubli et al., 2018; Toral et al., 2018; Farajian et al., 2020; Liang et al., 2021a). When a translation system generates erroneous translations, people unable to read the other language may not recognize such errors, leading to confusion. Achieving a perfect error-free chat translation system is challenging due to the unique charac- teristics of chat (Tiedemann and Scherrer, 2017; Maruf et al., 2018; Liang et al., 2021a,b), mak- ing it impractical to aim for perfection. Instead, a viable alternative approach is to enhance transla- tion software by providing warnings about possible mistranslations to reduce confusion. However, the perception and effects of such warning messages remain unclear. To investigate this, we proposed to provide a warning message for erroneous transla- tions during the cross-lingual chat and conducted a survey to explore how such warnings help peo- ple communicate. The survey design is shown in Figure 1. Participants engage in a simulated cross- lingual chat scenario, where they have to select the most reasonable response from three options. Whenever a translation error occurs, a warning mes- sage is displayed. At the end of the chat, partic- ipants answer corresponding questions regarding their perceptions of the warning messages. We conducted the survey and collected responses through crowdsourcing. The results indicate that warning messages (1) are helpful in cross-lingual chats and (2) potentially encourage users to change their chat behavior. Moreover, the survey reveals the crowd's desired features for the warning mes- sages. This is the first study of its kind to explore the impacts of warning users about erroneous trans- lations in cross-lingual chat. The findings are valu- able for developing an assistant function that de- tects and warns users of erroneous chat translations."}, {"title": "2 Related Work", "content": "Previous studies have pointed out the potential ben- efits of incorporating machine translation in chat, despite its imperfections (Uthus and Aha, 2013)."}, {"title": "3 Survey Design", "content": "We propose an alternative strategy to improve trans- lation software's performance by integrating cau- tionary alerts for potential mistranslations to reduce confusion. We designed a warning message and executed a survey to evaluate its effectiveness. Figure 1 illustrates the survey process, including two simulated chat rounds: one devoid of warning mes- sages and the other incorporating them."}, {"title": "3.1 Simulated Cross-lingual Chat Scenarios", "content": "Since dynamic real-time chats are relatively un- controllable and high-cost, we simulated a chat scenario with a foreign partner based on chat data from Persona-chat (Zhang et al., 2018). In the simulation, participants are presented with three initial chat turns as historical chat logs at the be- ginning.Participants choose the most contextually fitting response from the three provided options each time their scripted partners respond iteratively. To explore the cognitive processes of individuals lacking proficiency in a foreign language, we oper- ated under the assumption that participants would receive translated messages generated by the ma- chine translation system from their partners. Hence, all texts within the survey are presented to partici- pants in their native language."}, {"title": "3.2 Chat Data", "content": "We prepared the simulated scenarios with the Persona-chat dataset, containing multi-turn chat data about various personality traits with assumed personas in English. To ensure the quality of the data, we eliminated incoherent and unnatural chat data from Persona-chat through crowdsourcing at Amazon Mechanical Turk 5. We defined \"inco-"}, {"title": "3.3 Erroneous Translations", "content": "To provide the chat data that were supposed to be erroneous translations, we translated the pre- pared chat data with a low-quality machine trans- lation model that achieved a considerably low BLEU score (Papineni et al., 2002) of 4.9 on the English-Japanese chat translation evaluation dataset BPersona-chat (Li et al., 2022a). Conse- quently, we transformed the low-quality transla- tions twenty times through Google Translate into different languages and finally translated them back to the source language of the survey. To ensure the final translations could serve as erroneous trans- lations, we manually confirmed that the texts in- cluded significant syntax issues, incorrect emo- tional expressions, incoherence, or other errors that led to confusion. We designed that at least one of the three turns of the simulated chat would include erroneous translations. We required proficient En- glish speakers to continue the chat based on the erroneous translations to prepare the extended chat."}, {"title": "3.4 Warning Messages", "content": "We designed the warning message to notify partici- pants of erroneous translations in the chat. When the current text is assumed to be the erroneous translation, participants are presented with a warn- ing message alerting them of the mistranslation, as shown in Figure 1. We structured the warning mes- sages into two types since receiving and sending are both essential in a conversation. One type alerts participants of erroneous translations in the mes- sages they received, while the other type indicates potential errors in the last message they sent."}, {"title": "3.5 Corresponding Questions", "content": "After the chat, participants are asked to answer if they notice erroneous translations without hints. If participants answer yes, they rate their experience on two Likert Scale questions (Joshi et al., 2015; Nemoto and Beglar, 2014). The first question as- sesses the extent to which the errors prevented them from continuing the chat, while the second ques- tion asks to what extent they could grasp exactly where the erroneous translations were in the mes- sage. Participants will use 1-5 to score their per- ceptions, with higher numbers indicating a greater awareness or understanding of the errors. Participants must also rate on a Likert Scale ques- tion the extent to which they think the warning helped them continue the chat. Further, they check the plural options of additional features they find helpful if added to the warnings. Selectable fea- tures include: indicating the correctness rate of the translation, providing alternative translation sug- gestions, showing specific errors in the translation, and suggesting the emotion of their partner."}, {"title": "4 Crowdsourcing Experiments", "content": "We prepared the survey in English, Chinese, and Japanese to observe the possible difference be- tween languages. Professional translators trans- lated the data from English to Chinese and Japanese to ensure quality. We prepared three sets of chat data for each type of warning message and two types of warnings; hence, we provided six sets of chat and collected the responses through crowd- sourcing. We provided instructions for participants on how the chat would be presented and what they should do to attend the chat at the beginning of the task. Participants would be acknowledged that (1) their partner would speak to them in a language other than their native language, (2) the system would translate their partners' messages and the chat would only be presented in their language, (3) they would read the chat log and choose the most reasonable of the three options, (4) the mes- sage sent to them would be displayed on the odd- numbered lines, and their answer would be dis- played on the even-numbered lines. To minimize any possible influence of showing warnings first or later, we provided each chat in two orders. Participants answer either without warning messages first or with warning messages first. At the round of warning messages, we would explain the role of warning messages to participants and inform them that they could refer to the warnings"}, {"title": "5 Results and Analysis", "content": "Under the different policies of crowdsourcing plat- forms, we finally gathered 604 English, 635 Chi- nese, and 621 Japanese responses. Figure 2 dis- plays the overall summaries. Around 70% of par- ticipants across three languages rated the warning messages as \u201c4 - helpful\u201d or above in the chat. Most participants view the warning messages as helpful in cross-lingual chats, aligned with Likert Scale analysis (Amidei et al., 2019).\nWith or without warning messages The results of \"Without hints, do you think there were erro- neous translations in the chat\" based on the or- der in which participants answered the survey are listed in Table 1. The percentages of noticing erro- neous translations without hints remain consistent, regardless of participants answering with warning messages first or after. Hence, we conclude that the impact of answering orders on the crowds appears minimal. Moreover, considering a score greater or equal to 4 suggests the positivity of a Likert\nalence between having no warning messages and having no erroneous translations. Indeed, 103 par- ticipants stated they changed their choices as they ensured there were no erroneous translations. Survey results shown in Figure 3 indicate that ap- proximately 25% participants remained unchanged, while about 75% changed their choices, either di- rectly or indirectly, due to the warning messages. We confirm that the participants were genuinely influenced by warning messages and participated in the subsequent feedback.\nWarnings on the received messages or the sent messages The collected responses of different types of warning messages are summarized in Fig-"}, {"title": "6 Conclusions", "content": "We conducted a survey to investigate the effective- ness of warning about possible mistranslations in chat as an alternative approach to enhance the ex- perience of cross-lingual communication. Through crowdsourcing, we collected responses and con- cluded that such warning messages are helpful. By comparing the participants' choices with and with- out warning messages, we found that the warn- ing messages did encourage participants to change their behaviors. We also found the crowd expects the warning message to (1) show the specific er- ror in the translation, (2) indicate the correctness rate of the translation, and (3) provide alternative translation suggestions.\nThis survey is the first to explore the effects of warning about erroneous translations in cross- lingual chat, providing valuable insights for devel- oping an assistant function that detects and warns people of erroneous chat translations."}, {"title": "Limitations", "content": "During the survey design phase, diligent measures were taken to minimize potential leading effects on the participants' judgment by randomly switch- ing the order and neutralizing the questioning style. Despite the conscientious efforts, we must acknowl- edge the inherent challenges in completely elimi- nating all influences on the people who participated in the survey. With this realization, we recognize the need for further optimization to guarantee the fairness and validity of the responses. Refinement is warranted to minimize the biases further."}, {"title": "Ethics", "content": "The crowdsourcing survey employed in this study adheres to stringent ethical guidelines to ensure participant privacy and data protection. The survey design deliberately avoids collecting any person- ally identifiable information from the participants. No restrictions or enforcement of work hours were imposed upon participants, thereby eliminating un- due influence or coercion. Given the absence of personal data collection and voluntary participa- tion, the data is not subject to ethics review at the organization. Consequently, the survey design and data collection procedures adhere to the ethical standards and regulations governing research prac- tices."}]}