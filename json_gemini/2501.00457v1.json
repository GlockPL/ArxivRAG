{"title": "Differentiable Prompt Learning for Vision Language Models", "authors": ["Zhenhan Huang", "Tejaswini Pedapati", "Pin-Yu Chen", "Jianxi Gao"], "abstract": "Prompt learning is an effective way to exploit\nthe potential of large-scale pre-trained foundational\nmodels. Continuous prompts parameterize con-\ntext tokens in prompts by turning them into dif-\nferentiable vectors. Deep continuous prompts in-\nsert prompts not only in the input but also in the\nintermediate hidden representations. Manually de-\nsigned deep continuous prompts exhibit a remark-\nable improvement compared to the zero-shot pre-\ntrained model on downstream tasks. How to au-\ntomate the continuous prompt design is an under-\nexplored area, and a fundamental question arises,\nis manually designed deep prompt strategy opti-\nmal? To answer this question, we propose a method\ndubbed differentiable prompt learning (DPL). The\nDPL method is formulated as an optimization prob-\nlem to automatically determine the optimal con-\ntext length of the prompt to be added to each\nlayer, where the objective is to maximize the per-\nformance. We test the DPL method on the pre-\ntrained CLIP. We empirically find that by using\nonly limited data, our DPL method can find deep\ncontinuous prompt configuration with high confi-\ndence. The performance on the downstream tasks\nexhibits the superiority of the automatic design: our\nmethod boosts the average test accuracy by 2.60\n% on 11 datasets compared to baseline methods.\nBesides, our method focuses only on the prompt\nconfiguration (i.e. context length for each layer),\nwhich means that our method is compatible with\nthe baseline methods that have sophisticated de-\nsigns to boost the performance. The DPL method\ncan be deployed to large language models or com-\nputer vision models at no cost.", "sections": [{"title": "1 Introduction", "content": "Parameter-Efficient fine-tuning (PEFT) offers a paradigm to\nadapt pretrained model to downstream tasks using a small\nset of trainable parameters. Among the PEFT methods, the\nprompt learning can perform few-shot learning or even zero-\nshot learning to adapt the pre-trained models to new scenar-\nios. Using appropriate prompts, both text prompts [Brown\net al., 2020; Lester et al., 2021; Schick and Sch\u00fctze, 2020b;\nShin et al., 2020; Gao et al., 2020] and visual prompts [Bar\net al., 2022; Shtedritski et al., 2023; Chen et al., 2023;\nTsai et al., 2024], to query foundational models have shown\ngreat potential. At the same time, the selection of context\ntokens in prompts has a pronounced effect on the perfor-\nmance of the prompt learning methods [Zhou et al., 2022b;\nSchick and Sch\u00fctze, 2021; Schick and Sch\u00fctze, 2020a; Ha-\nviv et al., 2021]. Continuous prompts use differentiable vec-\ntors that are in the embedding space of the foundation model.\nContinuous prompts use trainable parameters that are learned\nduring the fine-tuning process. It avoids the time-consuming\ntrial-and-error process using discrete context tokens. Besides,\nthe continuous prompts are not constrained to be the embed-\ndings of word tokens in the vocabulary. The selection for the\nembeddings of context tokens becomes continuous.\nDeep continuous prompts add prompts to multiple lay-\ners. This method has shown superior performance compared\nto only adding continuous prompts to the input in both vi-\nsion [Jia et al., 2022; Zhu et al., 2023b; Zhu et al., 2023b;\nYoo et al., 2023] and language fields [Lester et al., 2021;\nLi and Liang, 2021; Liu et al., 2021; Liu et al., 2023]. There\nare two hyperparameters: the context length of continuous\nprompts $C_p$ and prompt depth $l_p$. Let the hidden dimension\nbe $d$, continuous prompts $E \\in \\mathbb{R}^{C_p \\times d}$ are inserted to the input\nto the neural network layers up to $l_p$ layers. Since $E$ are auto-\nmatically determined during the fine-tuning process, a natural\nquestion is: can we automatically determine $C_p$ and $l_p$? Re-\ncently, it has been found that training merely part of deep neu-\nral network layers can achieve a performance comparable to\nor even better than training all layers. This line of work indi-\ncates that there is a subset of layers in the pre-trained model,\ndepending on the distribution shift between the pre-training\ndataset and fine-tuning dataset, whose parameters might be\nclose to a minima for downstream tasks [Lee et al., 2022;\nLodha et al., 2023; Panigrahi et al., 2023; Vettoruzzo et al.,\n2024].\nIn the prompt learning, we postulate that there might be\nsome layers that do not need deep continuous prompts or only\nneed continuous prompts with shorter context length com-\npared to rest of layers. In the existing prompt learning works,\nhowever, a fixed number cp is used for each layer. To examine\nour postulation, we design our method to insert continuous\nprompts with different context lengths. The context lengths of"}, {"title": "2 Background and Related Work", "content": "Prompt Learning Prompt learning offers an efficient way\nto adapt pre-trained foundational models to downstream\ntasks. This technique is of great interest in both vision [Wang\net al., 2022b; Wang et al., 2022a] and natural language [Jiang\net al., 2020; Shin et al., 2020]. CoOp [Zhou et al., 2022b] in-\nserts continuous prompts to the input of the vision-language\nmodel. The visual prompt tuning [Jia et al., 2022] proposes\nthe deep continuous prompts to vision transformer [Dosovit-\nskiy et al., 2020]. MaPLe [Khattak et al., 2023] combines\nthe ideas from these two works by using deep continuous\nprompts in both the text branch and the image branch. Simi-\nlar to CoOp, CoCoOp, PLOT and ProGrad insert continuous\nprompts only in the input. CoCoOp [Zhou et al., 2022a] in-\nserts the continuous prompts conditioning on the input im-\nages. PLOT [Chen et al., 2022] uses the computationally\ncostly iterative algorithm to compute the transport plan for\naligning word tokens and image patches. ProGrad [Zhu et\nal., 2023a] uses the gradient-aligned knowledge distillation\nto avoid the overfitting problem. All of the above-mentioned\nmethods use fixed context length as opposed to our proposed\nDPL method which adapts the context length for each layer\ndynamically based on the dataset.\nNeural Architecture Search Neural architecture search\n(NAS) automatically determines the architecture by minimiz-\ning the objective function. One-shot NAS is an efficient\nway to search neural architectures. In the one-shot NAS, a"}, {"title": "2.1 Revisiting Differentiable NAS", "content": "Differentiable NAS [Liu et al., 2018; Xu et al., 2019;\nDong and Yang, 2019; Liang et al., 2019; Zela et al., 2019;\nChu et al., 2020; Yan et al., 2021] uses a cell-based search\nspace. A cell is represented by a directed acyclic graph\n(DAG) G(V,E). Each node is a hidden representation and\neach directed edge is an operation transforming the hidden\nrepresentation. The supernet incorporates all the operations.\nLet O be a set of candidate operations. The categorical choice\nof a particular operation is relaxed by the softmax over all\npossible operations:\n$\\overline{o}^{(i,j)}(x) = \\sum_{o \\in O} \\frac{\\exp(\\alpha_o^{(i,j)})}{\\sum_{o' \\in O} \\exp(\\alpha_{o'}^{(i,j)})} o(x),$ (1)\nwhere $\\alpha_o^{(i,j)}$ are trainable parameters that determine the\nsearched operation between the latent representation $i$ and $j$.\nThe goal of the search process is to replace $\\overline{o}^{(i,j)}$ with the\nmost likely operation. The optimal neural architecture is ob-\ntained after the search process.\nInspired by differentiable NAS methods, we relax the\ncategorical selection on the context lengths of continuous\nprompts to make the search space continuous. We use the\nsearch space to determine the optimal prompt configuration.\nThe continuous prompts are trained from scratch. Exist-\ning vision-language prompt learning methods use the deep\nprompt method [Jia et al., 2022] where continuous prompts\nare added to transformer blocks and removed after the self-\nattention [Vaswani et al., 2017]:\n$[x^{(l)}, E^{(l)}] = f^{(l)}([x^{(l-1)}, E^{(l-1)}]).$ (2)\nHere we denote l-th transformer block as $f^{(l)}$. Different op-\ntions for adding continuous prompts cannot be mixed as the\ndimension of the input $[x^{(l-1)}, E^{(l-1)}]$ is different due to dif-\nferent context lengths. We solve this problem by using cross-\nattention. Details are reported in the following section."}, {"title": "3 Differentiable Prompt Learning", "content": "We use the pre-trained CLIP model [Radford et al., 2021] in\nour experiments. The CLIP model is pre-trained on over 400\nmillion image-text pairs. The DPL method has two stages:\nthe searching stage and the training stage. The goal of the\nsearching stage is to determine the context length of the con-\ntinuous prompt to be added to each transformer block of the\nCLIP model. The best prompt configuration is used in the\ntraining stage. Figure 1 shows the proposed method."}, {"title": "3.1 Searching Stage", "content": "We prepend continuous prompts ${E^{(l)}}$ to inputs to trans-\nformer blocks ${x^{(l)}}$ in the text branch and image branch,\nwhere $1 < l < L, l \\in \\mathbb{N}^{+}$. The concatenated inputs are fed"}, {"title": "3.2 Training Stage", "content": "We denote $A^{txt}$ for the $\\alpha$ matrix of the text branch and $A^{img}$\nfor that of the image branch. The column index of the max-\nimum value in each row of $\\alpha$ matrix determines the con-\ntext length of the inserted continuous prompts, i.e. $A =$\nmaxm Aim. After the context length of continuous prompts\nis determined, we fine-tune the model on various downstream\ndatasets. Figure 1 (c) shows the training stage. The fine-tuning process is the same as the conventional prompt learn-\ning method: model parameters are frozen and only continu-\nous prompts are differentiable.\nIn the image branch, the input $x \\in \\mathbb{R}^{C\\times H\\times W}$ is patchified\nand projected to produce patch token embeddings [Dosovit-\nskiy et al., 2020]. A learnable classification token embed-\nding $u_{cls} \\in \\mathbb{R}^{1\\times d_{txt}}$ is added to the patch token embedding\n$X_{img} = [u_{cls}, U_1,..., u_{n_{img}}]$. In the text branch, a text tem-\nplate such as a photo of a [class] is tokenized and\nembedded to generate text token embeddings that are formu-\nlated as $x_{txt} = [v_{SOS}, v_1,..., v_{n_{txt}}, v_k, v_{EOS}]$, where $v_{SOS}$\nis the start token embedding, $v_{EOS}$ is the end token embed-\nding, and $v_k$ is the embedding corresponding for the class\nname. $x_{txt}$ and $x_{img}$ are combined with continuous prompts\nand fed to transformer blocks in the text branch and image\nbranch for obtaining text embedding $\\overline{g}$ and image embedding\n$\\overline{f}$, respective. Within each transformer block, we use the cross\nattention mechanism as shown in Equation 4 and 5. The out-\nput logits are based on the similarity between $\\overline{g}$ and $\\overline{f}$:\n$\\hat{y} = \\frac{\\exp(sim(\\overline{f}, \\overline{g})/\\tau)}{\\sum_{c \\in C} \\exp(sim(\\overline{f}, \\overline{g_c})/\\tau)}$ (10)\nwhere $\\tau$ is the temperature parameter. The loss $\\mathcal{L}_{de}$ computes\nthe deviation of the prediction from the ground truth labels:\n$\\mathcal{L}_{de} = \\mathbb{E}_{(x,y)\\sim D} F(\\hat{y}, y),$ (11)\nwhere F() is the loss function. We use the cross entropy\nloss for calculating $\\mathcal{L}_{de}$. Continuous prompts are updated by\ndescending the training loss $\\nabla_{E}\\mathcal{L}_{train} (E)$.\nIn addition to the vanilla DPL, we add knowledge distil-\nlation in the training stage. Specifically, we use Kullback-\nLeibler (KL) divergence [Hinton et al., 2015] between the\nmodel prediction $\\hat{y} = p(x)$ and the zero-shot pre-trained\nmodel prediction $p_{zs}(x)$:\n$\\mathcal{L}_{kl} = \\sum_{x \\in X} p_{zs}(x) \\log( \\frac{p(x)}{p_{zs}(x)} ).$ (12)\nThe total loss $\\mathcal{L}_{total}$ is computed by:\n$\\mathcal{L}_{total} = \\mathcal{L}_{de} + \\lambda \\mathcal{L}_{kl},$ (13)\nwhere $\\lambda$ is a hypereparameter. The gradient descent of con-\ntinuous prompts uses $\\mathcal{L}_{total}$ to update parameters."}, {"title": "4 Experiments", "content": "4.1 Datasets and Experiment Setup\nDatasets We evaluate the DPL method on 11 datasets:\nCaltech101 [Fei-Fei et al., 2004] and ImageNet [Deng et\nal., 2009] for the generic object classification, Describable-\nTectures [Cimpoi et al., 2014] for the texture classifica-\ntion, EuroSAT [Helber et al., 2019] for the satellite image\nclassification, FGVCAircraft [Maji et al., 2013], Food101\n[Bossard et al., 2014], OxfordFlowers [Nilsback and Zisser-\nman, 2008], OxfordPets [Parkhi et al., 2012], and Stanford-\nCars [Krause et al., 2013] for the fine-grained image recogni-\ntion, UCF101 [Soomro et al., 2012] for the action classifica-\ntion, and SUN397 [Xiao et al., 2010] for the scene recogni-\ntion.\nBaselines We compare the proposed method with CoCoOp\n[Zhou et al., 2022a], PLOT [Chen et al., 2022], MaPLe\n[Khattak et al., 2023] and ProGrad [Zhu et al., 2023a]. The\noriginal implementation of PLOT uses ResNet [He et al.,\n2016] as the backbone model. For a fair comparison, we\nreplace the backbone model of ResNet with the transformer\nmodel. In addition to the prompt learning methods, we ex-\namine the performance of the zero-shot CLIP (ZS CLIP) and\nthat of training a linear classifier given image and text repre-\nsentations by CLIP (Linear probe) [Radford et al., 2021].\nExperiment Details We use the pretrained ViT-B/16 CLIP\nmodel [Radford et al., 2021] in the few-shot learning. In both\ntraining stage and searching stage, we use the same hyper-\nparameters except for the number of epochs. The number of\nepochs in the searching stage is 60 while that for the train-\ning stage is 40. The batch size is 4 and we use stochastic\ngradient descent (SGD) to optimize continuous prompts. In\nthe searching stage, two $\\alpha$ matrices are optimized using SGD\nstrategy. Learning rate is 3.5 \u00d7 10-3. Experiments are con-\nducted using a single NVIDIA A40 GPU."}, {"title": "4.2 Determining Context Lengths of Continuous\nPrompts", "content": "We use the few-shot learning setting in the searching stage.\nThe number of shots is the same for the searching and train-\ning stages. The number of shots is 16. The results of using\n8/4/2/1 shots are shown in Appendix A.5. The evolution of\n$\\alpha$ matrices is visualized to examine the convergence process.\nThe evolution of $\\alpha$ matrices using 11 different datasets is re-\nported in the Appendix A.1. We define special $\\alpha$ matrices\nformally:\nDefinition 4.1 (single-dominant). An $\\alpha$ matrix $A^o \\in \\mathbb{R}^{l \\times t}$ is\nsingle-dominant if $\\forall i \\in \\mathbb{N}^{+},1 < i < l, \\exists j \\in \\mathbb{N}^{+}, 1 \\leq j \\leq t$\ns.t. $A_{ij} > A_{ik}$, where $k \\in \\mathbb{N}^{+}, 1 \\leq k \\leq t, k \\neq j$.\nThe single-dominant $\\alpha$ matrix means that the searching al-\ngorithm has a high confidence in the searched subprompts.\nThis is beneficial to the training stage as the determined $\\alpha$\nmatrix is robust against the fluctuation of the matrix in the\nupdating process. We use the alpha value at each row with"}, {"title": "4.3 Prompt Learning Based on Alpha Matrix", "content": "After determining the context length of added continuous\nprompts, we add them to the pre-trained CLIP model and\nconduct the prompt learning in a supervised fashion. We\nuse the few-shot learning and the number of shots is 16.\nThe $\\alpha$ matrix in the text branch might be different from\nthat in the image branch as shown in Appendix Figure 4,\nand there is no coupling function [Khattak et al., 2023;\nZang et al., 2022] between added continuous prompts in the\ntwo branches. Note that the direct comparison of\nzero-sho CLIP with other methods is not fair as it does not\nrequire any training.\nOur proposed method shows a pronounced advantage com-\npared to baseline methods. It boosts the average accuracy\nby 2.60% test accuracy. The proposed method shows unfa-\nvorable performance on the Food101 dataset. When compar-\ning the zero-shot CLIP method with the linear probe method\nwhich adds a linear classifier on top of pre-trained CLIP\nmodel, there is a remarkable performance drop (77.30% \u2192\n70.13%). We postulate that the reason might be related to\nthe forgetting issue [Chen et al., 2019; Boschini et al., 2022;\nJung et al., 2016] in the fine-tuning process. ProGrad is de-\nsigned to avoid the forgetting issue by aligning the gradient\ndescent direction of matching predictions and ground-truth\nlabels to that of knowledge distillation when there is a con-\nflict. ProGrad exhibits a good performance on that dataset.\nWe find that the performance difference between the DPL\nmethod and baseline methods is largest on the EuroSAT\nand Aircraft datasets. There is a large distribution shift\non EuroSAT and Aircraft datasets compared to the pre-train\ndatasets of the CLIP model. On the generic dataset such as\nCaltech101, the distribution shift is small. Hence, the differ-\nence between the DPL method and baseline methods is mini-\nmal."}, {"title": "4.4 Ablation Studies", "content": "We examine the performance of the shallow prompt learning\nmethod: continuous prompts with a context length of 16 are\nadded to the inputs of the text branch and the image branch"}, {"title": "5 Discussion", "content": "By using bi-level optimization, the DPL method is able to\nautomatically determine the context length of the continu-\nous prompt for each layer. It seems to indicate that the op-\ntimal prompt configuration might be dataset-dependent. The\ndeep neural networks are found to be brittle to even small\ndistribution shits between the pre-training and fine-tuning\ndatasets [Recht et al., 2019; Hendrycks and Dietterich, 2019;\nKoh et al., 2021]. A dataset-dependent training scheme pro-\nvides the flexibility to the level of distribution shift. Our re-\nsults show that the few-shot learning with DPL can boost the\ndownstream accuracy.\nExisting deep prompt learning works hardly consider a\ngranular level of adding continuous prompts: each layer has\nthe same context length and a hyperarameter of prompt depth\nis empirically determined. A prompt depth $l_p$ smaller than\nthe model depth $l$ indicates that the last few layers of the\npre-trained model might be close to a minima for the down-\nstream dataset. In the transfer learning, not all layer pa-\nrameters are responsible for the distribution shift. There\nare numerous researches on training different layers dif-\nferently to mitigate the forgetting issue [Niu et al., 2022;\nToneva et al., 2018; Davari et al., 2022] caused by the\ndistribution shift: fine-tuning on the target domain using\ngradual unfreezing [Howard and Ruder, 2018; Mukherjee\nand Awadallah, 2019; Romero et al., 2020], using differ-\nent learning rate for different layers [Ro and Choi, 2021;\nShen et al., 2021], and training part of layers [Lee et al., 2022;\nVettoruzzo et al., 2024].\nIf some layer parameters are close to optimal in down-\nstream datasets, we believe there is no need to add continu-\nous prompts to those layers. The deep prompt methods using\n$l_p < l$ avoid adding prompts to layers that are close to the\noptimal. If we refine this strategy, a natural question is do"}, {"title": "6 Limitation", "content": "The searching stage of the DPL method, similar to NAS, is\ncomputationally costly due to the introduction of the sup-\nprompt. The computational cost is determined by the size\nof the search space. At each depth, DPL searches con-\ntext lengths of {0,2,4,6}. The size of the search space is\n2.81\u00d71015. Using differentiable approach greatly accelerates\nthe searching process compared to exhaustive search. The\ntraining stage of the DPL method is lightweight as it relies\ncompletely on prompt configuration without advanced tech-\nnologies such as coupling functions. Details regarding to the\ncomputational costs are discussed in Appendix A.3."}, {"title": "7 Conclusion", "content": "In this work, we automate the prompt learning design by re-\nlaxing the categorical selection of context lengths to obtain a\ncontinuous search space. Using limited data, our method is\nable to find a prompt learning setting that is better than the\nexisting manually designed prompt learning methods. The\nmethod is simple yet effective: it only focuses on determine\ncontext lengths of continuous prompts. We empirically find\nthat our searching algorithm has a higher confidence in the\ntext branch compared to that in the image branch, and that\nthe prompt configuration shows a data-dependent behavior.\nThe data-dependent behavior and the asymmetric prompt in-\nsertion in two branches demonstrate the strength of the au-\ntomatic prompt learning design. In summary, our work pro-\nposes a new paradigm of adding continuous prompts that re-\nmoves the restriction of the manually designed context length\nfixed prompt learning method."}, {"title": "A Appendix", "content": "A.1 Alpha Matrix Evolution\nWe examine the evolution of a matrix on the Caltech101, De-\nscribableTextures, EuroSAT, FGVCAircraft, Food101, Ox-\nfordFlowers, OxfordPets, StanfordCars, UCF101, SUN397\nand ImageNet datasets. The result is shown in Figure 4. Over-\nall, the searching algorithm has a higher confidence in the\ntext branch compared to the image branch. Even though us-\ning only 16 shots learning, the searching algorithm can find\nsubprompts with reasonable confidence on all 11 datasets.\nWe note that the $\\alpha$ matrix at the last epoch varies for the\ndifferent datasets. It indicates the dataset-dependent behavior\nof the deep continuous prompt method."}, {"title": "A.2 Terminology", "content": "We summarize the terminology in Table 3. Supprompt is\nanalogous to Supernet while Subprompt is analogous to Sub-\nprompt in differentiable NAS [Liu et al., 2018; Xu et al.,\n2019; Dong and Yang, 2019; Liang et al., 2019; Zela et al.,\n2019; Chu et al., 2020; Yan et al., 2021]. Similarly, we use\nsearch space to group prompt configurations in the search-\ning process. The computational cost of the searching stage is\nrelated to the size of the search space.\nPrompt configuration determines context lengths at differ-\nent depths. Manually designed prompts generally have a ho-\nmogeneous prompt configuration while the DPL method in-\ntentionally introduces heterogeneity in the prompt configura-"}]}