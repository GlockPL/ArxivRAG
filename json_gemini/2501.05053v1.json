{"title": "TAPFed: Threshold Secure Aggregation for Privacy-Preserving Federated Learning", "authors": ["Runhua Xu", "Bo Li", "Chao Li", "James Joshi", "Shuai Ma", "Jianxin Li"], "abstract": "Federated learning is a computing paradigm that enhances privacy by enabling multiple parties to collaboratively train a machine learning model without revealing personal data. However, current research indicates that traditional federated learning platforms are unable to ensure privacy due to privacy leaks caused by the interchange of gradients. To achieve privacy-preserving federated learning, integrating secure aggregation mechanisms is essential. Unfortunately, existing solutions are vulnerable to recently demonstrated inference attacks such as the disaggregation attack. This paper proposes TAPFed, an approach for achieving privacy-preserving federated learning in the context of multiple decentralized aggregators with malicious actors. TAPFed uses a proposed threshold functional encryption scheme and allows for a certain number of malicious aggregators while maintaining security and privacy. We provide formal security and privacy analyses of TAPFed and compare it to various baselines through experimental evaluation. Our results show that TAPFed offers equivalent performance in terms of model quality compared to state-of-the-art approaches while reducing transmission overhead by 29%-45% across different model training scenarios. Most importantly, TAPFed can defend against recently demonstrated inference attacks caused by curious aggregators, which the majority of existing approaches are susceptible to.", "sections": [{"title": "INTRODUCTION", "content": "Federated learning (FL) [1], [2] is incredibly promising for collaborative model training amongst several parties orchestrated by an aggregator - without requiring them to provide any of their raw training data, and thus appears to have an elementary privacy guarantee, as it shares only model updates such as model weights or gradients, as opposed to the raw private data. Recent studies, however, have shown that private information can still be inferred by exploiting the final ML model, such as through data extraction, membership inference, model inversion, and property inference attacks [3]\u2013[6], or by exploiting the exchanged model update during the learning phase [7]\u2013[9]. The second category of attack is more FL-specific because it exploits information that is shared during the FL training process, in contrast to the first type of attack, which can be applicable to any ML system and is not just limited to FL systems. The increasing demand for privacy-preserving FL (PPFL) solutions has resulted in a variety of methods being offered in recent research [10]\u2013[18]. The privacy-preserving aggregation procedure is essential in those PPFL solutions because it can ensure input privacy by securing each party's local input model updates and disclosing only the global aggregated model during FL training, thereby effectively preventing or mitigating the second type of attack [19].\nTo achieve privacy-preserving aggregation, various approaches have been proposed, including privacy-enhancing aggregation and secure aggregation. Through the use of differential privacy mechanisms, the privacy-enhancing aggregation approaches focus on perturbing model updates with differential privacy (DP) noise [16], [20], whereas the secure aggregation approaches prevent private information leakage through the use of secure multi-party computation (MPC), pairwise mask technique, and other cryptographic schemes [10], [11], [13]\u2013[15], [17], [21]. In contrast to DP-based privacy-enhancing approaches, secure aggregation techniques ensure the protection of the local model without compromising the aggregated model's accuracy.\nTable TABLE 1 illustrates our examination of the architectures and assumptions of existing secure aggregation techniques, highlighting their potential limitations.\nTo begin with, the majority of known secure aggregation approaches rely on a single centralized aggregator and the assumption of an honest-but-curious (HbC) aggregation, leaving the system vulnerable to a variety of attacks. For instance, approaches based on threshold homomorphic encryption (THE), multi-input or multi-client functional encryption (MIFE/MCFE), and pairwise masking techniques retain some vulnerability to gradient inference attacks [7]\u2013[9]. This is because, even though the aggregation cannot learn each party's input, it can still access the intermediate aggregated model in plaintext during multiple rounds of FL training. On the other hand, while homomorphic encryption (HE) based approaches prevent the curious aggregator from learning the intermediate aggregated models, they leave the aggregator vulnerable to replay attack and isolation attacks"}, {"title": "RELATED WORK", "content": "The concept of federated learning (FL), initially presented in [1], [2], is a distributed machine learning framework that aims to collaboratively train a machine learning model through exchanging model updates such as weights or gradients, rather than sharing personal data. While the FL paradigm appears to offer privacy assurances at first glance, the exchange of model updates still poses potential risks. Curious aggregators could potentially extract private information from the shared model updates, as demonstrated in [3], [4], [8], rendering the privacy guarantees insufficient. To prevent leakage of private information from parties' output, secure aggregation plays a crucial role in FL to ensure that the central aggregator only obtains the fused model updates without learning any input model updates from parties.\nNote that it's important to distinguish between pri-vacy issues and security issues in the context of federated learning. This paper won't discuss attacks like poisoning, backdoor or robustness-related issues, as summarized in [33], [34], which aim to disrupt the functionality or integrity of the federated learning system. In the context of privacy protection in federated learning, from the perspective of aggregator settings, secure aggregation can be divided into two categories: single honest-but-curious aggregator and multi-aggregator settings."}, {"title": "Secure Aggregation in Single Honest-but-Curious Aggregator Setting", "content": "In the single honest-but-curious aggregator setting, the aggregator is assumed to be honest-but-curious, which means that it will follow the protocol but may attempt to learn pri-vate information from the obtained intermediate aggregated model updates. The majority of existing secure aggregation approaches are based on this setting, where the secure aggregation solutions employ a variety of techniques:(i) approaches based on secure multi-party computation protocols using garbled circuits [35]\u2013[37]; (ii) approaches based on anonymous communication using mix-nets [38] or DC-nets [39]; (iii) approaches based on cryptosystems such as partially/fully HE or FE [10], [11], [17]; (iv) approaches based on pairwise masking [13], [23]\u2013[27], [29], [30].\nThe methods described in [35]\u2013[37] rely on secure multi-party computing protocols that use garbled circuit tech-niques. However, these approaches have a significant draw-back in that they require the exchange of large garbled tables for each circuit gate, leading to a communication overhead. Alternatively, anonymous communication techniques like DC-nets [39] or mix-nets [38] offer a different approach by shielding the connections between the privacy-sensitive data and the parties, instead of solely preventing the disclo-sure of private information.\nMost of the emerging and promising secure aggrega-tion approaches in the single honest-but-curious aggregator setting rely on advanced cryptographic systems, such as partially or fully homomorphic encryption (HE) and multi-input or multi-client functional encryption (FE) [10], [11], [17], TEE-based approach [33], and lightweight crypto-graphic primitives such as pairwise masking [13], [23]\u2013[28].\nPairwise masking-based methods can accommodate a large number of parties with consideration for dropouts, but their design requires multiple rounds of communication between the central aggregator and parties for a sin-gle round of secure aggregation. Trust execution environ-ment (TEE) based approaches, also known as confidential computing-based approaches, rely on specialized hardware that allows for secure enclaves, such as Intel SGX, AMD PSP, and ARM TrustZone. However, these secure enclave hardware are not widely available and still have limited memory space for secure processing. Rather than following the path of pairwise masking, which may result in increased communication overhead, this paper concentrates on the use of advanced cryptographic techniques, which represent a viable emerging trend for resolving secure aggregation problems in a simple communication topology without the need for special hardware support.\nInstead of relying on fully homomorphic encryption (HE) based solutions that have computational limitations resulting in not practical for large-scale secure aggrega-tion of model updates and suffer from potential isola-tion or replay attacks, alternative solutions such as multi-input functional encryption (MIFE) or multi-client func-tional encryption (MCFE) demonstrate promise in terms of both computation and communication efficiency [10], [40]. However, MIFE/MCFE-based solutions still suffer from re-cently demonstrated model disaggregation attacks that are launched by the central curious aggregator by exploiting the information of aggregated model and fusion weights from multiple FL training rounds."}, {"title": "Secure Aggregation in Multi-Aggregator Setting", "content": "To address potential privacy breaches from an honest-but-curious aggregator, a simple solution is to distribute trust among several decentralized aggregators rather than relying on one centralized source. This prevents any single aggregator from learning intermediate aggregated models, thereby eliminating the possibility of inference attacks.\nExisting secure aggregation approaches in multi-aggregator setting lies in two categories: (i) approaches based on secure multi-party computation protocols using secret sharing primitives [21] and (ii) secure enclave [31], [32].\nThe approaches based on secure multi-party computa-tion protocols using secret sharing primitives [21] are de-signed for the two-server setting, which requires a peer-to-peer connection to exchange shared information, resulting in a complex communication topology. The same limitation also occurs at the approaches based on secure enclave-based secret sharing approaches [31], [32]. Moreover, the two-server setting is vulnerable to a single point of failure, as well as the feasibility and likelihood of collusion among aggregators.\nTo address the above-mentioned secure aggregation challenges, we focus on the path of MCFE techniques to take advantage of computation and communication efficiency and solve the disaggregation problem with the setting of untrusted multiple aggregators by proposing a threat vari-ant of functional encryption primitives to achieve the threat model in the FL environment.\nNote that our study, which follows a similar methodol-ogy as described in [10], [11], is also compatible with differ-ential privacy mechanisms. These are another fundamental technique to achieve privacy-preserving federated learning by adding noise to perturb the model and provide an output privacy guarantee for the final trained model [41]."}, {"title": "THRESHOLD FUNCTIONAL ENCRYPTION", "content": "As we've previously discussed, TAPFed is constructed on a multi-aggregator architecture to ward off potential inference attacks. To address the issues of single-point failure and scalability, a new secure aggregator protocol should be developed based on an innovative cryptographic primitive. This differs from existing secret sharing-based multi-party computation primitives as it doesn't necessitate any peer-to-peer communication between aggregators.\nTo accomplish this, we propose a groundbreaking threshold functional encryption (TFE) scheme. This allows for secure aggregation with independent and decentralized aggregators without any fully connected peer-to-peer com-munication, while tolerating a limited number of malicious ones.\nGiven that threshold functional encryption aligns with computational cryptographic primitives, it's reasonable to question why we wouldn't leverage existing Homomorphic Encryption (HE), threshold HE, or Functional Encryption (FE) schemes. After all, these are viable alternatives and promising strategies in the field of secure aggregation [42]. We do not employ these alternative techniques directly for the following reasons: (i) HE- or FE-based techniques rely on centralized aggregator settings, resulting in isolation and disaggregation attacks, as demonstrated in recent literature [18]; (ii) As the most relevant work, threshold HE (e.g., threshold Paillier cryptosystem) is inefficient for handling complex applications over encrypted data, and it also suffers from the same disaggregation problem as FE-based tech-niques.\nRecent multi-input FE (MIFE) or multi-client FE (MCFE) systems [43]\u2013[45] have shown the applicability of the computation-efficient DDH assumption in FE cryptosys-tems, making it more suitable for IoT devices than pairing and garbled circuit-based alternatives. Considering their promising use in the creation of practical PPML applications [10], [12], [46], [47], we propose a new threshold MCFE scheme based on the DDH assumption that supports se-cure aggregation in decentralized aggregators settings and handling issues as previously analyzed.\nIn short, TAPFed leverages TFE cryptographic primitive for its dual benefits: it uses a multi-aggregator structure that naturally wards off recently demonstrated inference attacks that require to access intermediate global model update and employs a simple communication topology free from bur-densome peer-to-peer exchanges among nodes. Crucially, our secure aggregation protocol, based on threshold func-tional encryption, can withstand collusion from a limited number of malicious aggregators a feature not offered by existing multi-aggregator solutions. This advantage is ensured by the design of the underlying cryptographic primitive's threshold functionality."}, {"title": "Preliminaries: Functional Encryption Definitions", "content": "Functional encryption (FE) is a group of cryptosystems that allow functions to be computed over encrypted data, with the resulting function value being in plaintext. Following the initial definition from [48] and [43], we present the no-tion of functionality, functional encryption scheme, security assumption and security definition.\nDefinition 1 (Functionality [48]). A functionality $F$ defined over $(\\mathcal{K}, \\mathcal{X})$ is a function $F : \\mathcal{K} \\times \\mathcal{X} \\rightarrow \\Sigma \\cup \\{ \\perp \\}$ where $\\mathcal{K}$ is the key space, $\\mathcal{X}$ is the message space and $\\Sigma$ is the output space and $\\perp$ is a special string not contained in $\\Sigma$.\nDefinition 2 (Functional Encryption Scheme [48]). A func-tional encryption (FE) scheme for functionality $F$ is a tuple $\\text{EFE} = (\\text{Setup}, \\text{KeyDerive}, \\text{Encrypt}, \\text{Decrypt})$ of four algorithms:\n$\\cdot$ Setup$(1^\\lambda)$ outputs public and master secret keys $(\\text{pkm}, \\text{skm})$ for security parameter $\\lambda$;\n$\\cdot$ KeyDerive $(\\text{skm}, k)$ outputs secret key $\\text{sk}_k$ given an input a master secret key, $\\text{skm}$, and a key, $k \\in \\mathcal{K}$;\n$\\cdot$ Encrypt$(\\text{pkm}, x)$ outputs ciphertext $\\text{ct}$ given an input a public key, $\\text{pkm}$, and a message, $x \\in \\mathcal{X}$;\n$\\cdot$ Decrypt$(\\text{pkm}, \\text{ct}, \\text{sk}_k)$ outputs $z \\in \\Sigma \\cup \\{ \\perp \\}$.\nIn addition, the correctness of $\\text{EFE}$ is described as $(\\text{pkm}, \\text{skm}) \\leftarrow \\text{Setup}(1^\\lambda)$, $\\forall k \\in \\mathcal{K}, x \\in \\mathcal{X}$, for $\\text{sk}_k \\leftarrow \\text{KeyDerive}(\\text{skm}, k)$ and $\\text{ct} \\leftarrow \\text{Encrypt}(\\text{pkm}, x)$, we have $\\text{Decrypt}(\\text{pkm}, \\text{ct}, \\text{sk}_k) = F(x, k)$ whenever $F(x, k) \\neq \\perp$, except with negligible probability.\nDefinition 3 (Selective Simulation-based Secure FE [43]). A functional encryption EFE for functionality Fis selec-tive simulation-based secure (SEL-SIM-secure) if there exist PPT simulator algorithms ESIM=(SetupSIM, KeyDeriveSIM, Encrypt SIM, DecryptSIM) such that for every stateful PPT adversary A and $\\lambda \\in \\mathbb{N}$, the following two distributions are computationally indistinguishable:\n$\\begin{array}{ll} \\text { Exp }_\\text { REAL }_A^{\\text {SE}}(1^\\lambda, \\mathcal{A}) & \\text { Exp }_\\text { IDEAL }_A^{\\text {SE}}(1^\\lambda, \\mathcal{A}) \\\\\\ \\left\\{x_i\\right\\}_{i \\in[n]} \\leftarrow \\mathcal{A}(1^\\lambda, F) & \\left\\{x_i\\right\\}_{i \\in[n]} \\leftarrow \\mathcal{A}(1^\\lambda, F) \\\\\\ (\\text{pkm}, \\text{skm}) \\leftarrow \\text { Setup }(1^\\lambda, F) & (\\text{pkSIM}, \\text{skSIM}) \\leftarrow \\text { SetupSIM }(1^\\lambda, F) \\\\\\ \\forall i \\in[n], \\text{ct}_i \\leftarrow \\text { Encpk }(i, x_i) & \\forall i \\in[n], \\text{ct}_i \\leftarrow \\text { EncpkSIM }(i) \\\\\\ \\alpha \\leftarrow \\mathcal{A}^{\\mathcal{O}}(\\text{pkm},\\left\\{\\text{ct}_i\\right\\}_{i \\in[n]}) & \\alpha \\leftarrow \\mathcal{A}^{\\mathcal{O}}(\\text{pkSIM},\\left\\{\\text{ct}_i\\right\\}_{i \\in[n]}) \\\\\\ \\text { Output: } a & \\text { Output: } a \\\\\\ \\\\\\ \\end{array}$\nThe oracle $\\mathcal{O}(\\cdot)$ in the ideal experiment above is given access to another oracle that, given $f \\in F$, returns $f(x_1, ..., x_n)$, and then $\\mathcal{O}(\\cdot)$ returns KeyDeriveSIM ($\\text{sk\u0218IM}, f, f (x_1, ..., x_n)$).\nits\n1]\n=\nNote that for every stateful adversary A, we define advantage as $Adv_{A, F}^{sel-sim}(\\lambda) = | Pr[REAL_{A, F}^{SE} (1^\\lambda) = 1] - Pr[IDEAL_{A, F}^{SE} (1^\\lambda) = 1] |$ and we require that for every"}, {"title": "Definition of Threshold Functional Encryption", "content": "Notation. As a brief notational introduction to the following threshold FE (TFE) presentation, let GroupGen$(1^\\lambda)$ be a probabilistic polynomial-time algorithm that takes as input a security parameter $1^\\lambda$, and outputs a triplet $(\\mathbb{G}, p, g)$, where $\\mathbb{G}$ is a group of order $p$ that is generated by $g \\in \\mathbb{G}$, and $p$ is a $\\lambda$-bit prime number. Furthermore, let $r \\stackrel{\\$}{\\leftarrow} \\mathbb{Z}_p$ denote the assignment to $r$ an element chosen uniformly at random from integer group $\\mathbb{Z}_p$. We use $[x]$ to denote encrypted $x$. A lowercase bold variable such as $\\mathbf{a}^{1 \\times n}$ represents a vector with length, $\\eta$. A capital bold variable such as $\\mathbf{W}^{n \\times \\eta}$ denotes a matrix with $n$ rows and $\\eta$ columns.\nWe define threshold functional encryption (TFE) for func-tionality F scheme as follows.\nDefinition 4 (Threshold Functional Encryption Scheme (TFE)). A t-of-s threshold functional encryption for functionality F is a tuple of following six algorithms:\nSetup() outputs public parameter and master secret key, (pp, msk), based on security parameter, \u03bb.\nSKDistribute(pp, msk, eidx) distributes secret key, skidx, for encryption entity eidx on input master keys (pkm, skm).\nDKGenerate (pp, msk, K, didx, L) generate functional decryp-tion key, dkidx, for a decryption entity, didx on input master keys, (pkm, skm), and a label L, and a vector from K.\nEncrypt(skidx, X, L) outputs ciphertext of [X] on input vec-tor from X, secret key skidx and a label L.\nShareDecrypt(pp, ct, K, dkidx, L, S) outputs a partially de-crypted ciphertext, [X]', on input a ciphertext, ct, a public parameter, pp, a vector from K, a label L, and a functional private key, dkidx, a selected sub-set of decryption parties S.\nCombineDecrypt(pp, ct', L) outputs functionality result on input public parameter, pp, a label L, and partially decrypted ciphertext, [X]'."}, {"title": "Proposed Threshold Multi-Client FE Scheme", "content": "Functionality of FMCIP. In this paper, we mainly focus on the inner-product functionality over the integers. Let $F_{\\mathcal{I}p}$ be a family of inner-product functionality with message space $\\mathcal{X}$ and key space $\\mathcal{K}$ both consisting of vectors in $\\mathbb{Z}_p^\\eta$ of norm bounded by $p$ of length $\\eta$. Here, we focus on multiple clients inner-product $F_{MIIP}$, defined as follows:\n$f_{MCIP}(\\{(x_i, l_x)\\}, \\{y, l_y\\}) = \\sum_{i\\in[n]} \\sum_{j\\in[n_i]} (x_{ij}y_{k+j})$\ns.t. |x_i| = n_i, |y| = \\sum i, \\forall i \\in [1, ..., n] : l_{x_i} = l_y\nwhere $f_{MCIP} \\in F_{\\mathcal{I}p}, x_i \\in \\mathcal{X}, y \\in \\mathcal{K}$, and $I \\in L$. Also, the total length of $x_i$ should be equal to the length of vector $y$.\nConstruction. Beginning with the multi-client FE (MCFE) scheme, our threshold MCFE (tMCFE) scheme for FMCIP is constructed as follows:\n$\\cdot$ Setup$(\\lambda, \\eta, t, s, n)$: The algorithm first generates a triplet from the integer group, as $(\\mathbb{G}, p, g) \\stackrel{\\$}{\\leftarrow}$ GroupGen$(1^\\lambda)$, on given security parameter $\\lambda$ as input and defines a full-domain hash function $H$ onto $\\mathbb{G}$. Then, it randomizes a matrix of 1 \u00d7 $\\eta$ samples and two matrix samples with size n \u00d7 $\\eta$, represented as: $\\mathbf{a}^{1 \\times \\eta} \\stackrel{\\$}{\\leftarrow} \\mathbb{Z}_p^{\\eta}, \\mathbf{W}^{n \\times \\eta} \\stackrel{\\$}{\\leftarrow} \\mathbb{Z}_p^{n}, \\mathbf{U}^{n \\times \\eta} \\stackrel{\\$}{\\leftarrow} \\mathbb{Z}_p^{\\eta}$. The public parameter pp and master private key msk are defined as follows: $\\text{pp} = (\\mathbb{G}, p, g, t, s, n, H)$, $\\text{msk} = (\\mathbf{W}^{n \\times \\eta}, \\mathbf{U}^{n \\times \\eta},g^\\mathbf{a}, \\{g^{\\mathbf{a*W}_i}\\}_{i\\in\\{1,...,n\\}})$.\n$\\cdot$ SKDistribute(pp, msk, ei): Given master keys, for en-cryption entity @idx \u2208 {1, ..., n}, the algorithm distributes the secret keys as $sk_{@idx} = (pp, g^\\mathbf{a}, g^{\\mathbf{aW}_{eidx}}, U_{eidx})$.\n$\\cdot$ DKGenerate (pp, msk, y, didx, l): The algorithm takes mas-ter keys, functionality-related vector $y = (y_1, y_2, ..., y_n)$, and distributes functional decryption key for correspond-ing decryption entity didx and label l. The algorithm first defines a set of polynomial functions (f(0)(x) = \\sum_{k=0}^{t-1} a_kx^k, \\{f^{(i)} (x) = \\sum_{k=0}^{t-1} b_{i,k}x^k\\}_{i\\in\\{1,...,n\\}}), where $a_k \\stackrel{\\$}{\\leftarrow} \\mathbb{Z}_p, b_{i,k} \\stackrel{\\$}{\\leftarrow} \\mathbb{Z}_p, a_0 = H(1) \\sum_{i=1}^{n} (y_i, U_i)$, and $b_{i,0} = (y_i, W_i)$. The algorithm then generates a set of functional decryption keys $dk = \\{v_{j,0}, v_{j,1}\\}_{j\\in\\{1,...,s\\}}$, where $v_{j,0} = f^{(0)} (j), v_{j,1} = \\{f^{(i)}(j)\\}_{i\\in\\{1,...,n\\}}$. For the partial decryp-tion entity didx \u2208 {1, ..., s}, the algorithm distributes the functional private key $dk_{didx} = (pp, V_{didx,0}, V_{didx,1})$.\n$\\cdot$ Encrypt (sk, xi, l): For the encryption entity Cidx \u2208 \\{1,..., n\\}, the algorithm takes as input sk; and i with specified label l, and returns ciphertext $[x_i]$. It first chooses a random element $r_i \\stackrel{\\$}{\\leftarrow} \\mathbb{Z}_p$ and computes the ciphertext $[x_i] = (ct_{i,0}, ct_{i,1})$ as follows:\n$ct_{i,0} = g^{x_i+H(l)U_i} o (g^{\\mathbf{a}+\\mathbf{W}_i}r_i), ct_{i,1} = g^{a^{\\mathbf{a}}r_i}.$\nNote that the symbol o denotes the element-wise mul-tiplication. For instance, $x^{1 \\times \\eta} o \\mathbf{Y}^{n \\times \\eta} \\rightarrow \\mathbb{Z}_p^{n \\times \\eta}$ denotes the element-wise multiplication of elements at the corre-sponding position in x and each row of Y.\n$\\cdot$ ShareDecrypt(pp, \\{[x_i]\\}_{i\\in\\{1,...,n\\}}, y, dk_j, \\mathcal{S})$: The algo-rithm takes the_ciphertext \\{[x_i]\\}_{i\\in\\{1,...,n\\}}, the public parameter pp and vector $y = \\{y_i\\}_{i\\in\\{1,...,n\\}}$ associated decryption key dk; from an authorized sub-set $\\mathcal{S}$, where $|\\mathcal{S}| \\geq t$. For the sharing decryption entity $d_j \\in \\mathcal{S}$ with $dk_j$, it outputs the partially decrypted ciphertext $[ct]' = (ct_{j,0}, ct_{j,1}, ct_{j,2})$ as follows:\n$\\begin{aligned} &ct_{j,0} = \\prod_{i\\in\\{1,...,n\\}} ct_{i,0}^{y_i} \\\\ &ct_{j,1} = \\{(ct_{i,1})}^{v_{j,1}L_j(j)}\\}_{i\\in\\{1,...,n\\}}, \\\\ &ct_{j,2} = g^{v_{j,0} L_j(j)}, \\end{aligned}$\nwhere $L_j (j)$ is the Lagrange basis polynomials defined as $\\prod_{j'\\in S, j'\\neq j} \\frac{(j')}{(j-j')}$. Note that $X^{(n\\times m)}oy^{(1\\times m)} \\rightarrow \\mathbb{Z}_p^{(n\\times m)}$ represents element-wise exponentiation of elements at the corresponding position in X and y.\n$\\cdot$ CombineDecrypt(pp, \\{[ct]'\\}_\\{j\\in\\{1,..,s'\\}\\})$: The algorithm takes all received_ciphertext \\{[ct]'\\}_\\{j\\in\\{1,..,s'\\}\\} and re-turns the inner-product \\{\\{x_i\\}_\\{i\\in\\{1,...,n\\}\\}, y\\}. $\\forall ct_{j,0} \\in \\{[ct]'\\}_\\{j\\in\\{1,..,s'\\}\\}$, the algorithm verifies they are all equal. If the verification is not passed, it returns the stop symbol;"}, {"title": "Correctness and Security", "content": "Given the public parameter pp, collected partially decrypted ciphertext \\{[ct]'\\}_\\{j\\in\\{1,..,s'\\}\\}, we have that\n$\\begin{aligned} D & = \\frac{\\prod_{i} c t_{i, 0}^{y_i}}{\\prod_{i} \\prod_{j} c t_{i, j, 1} \\cdot \\prod_{j} (c t_{j, 2})^{2}} \\\\ & = \\frac{\\prod \\left(g^{x_i+H(l)U_i} o \\left(g^{\\mathbf{a*W}_i} r_i\\right)\\right)^{y_i}}{\\prod_i \\prod_j \\left(g^{ar_i} \\right)^{f^{(i)}(0)} \\cdot \\prod_i g^{2 f^{(0)}(0)}} \\\\ & = \\frac{g^{2H(l) \\sum_{i=1}^{n}y_i U_i}}{\\prod_i (g^{r_i a})^{f(i)(0)} \\cdot g^{2 f^{(0)}(0)}} \\\\ & = \\frac{g^{2 \\sum_{i=1}^{n}(x_{ii}y_i)} \\cdot g^{2H(l) \\sum_{i=1}^{n} (y_iU_i)}}{g^{2H(l) \\sum_{i=1}^{n}(y_iU_i)}} \\\\ & = g^{2fMCFE(\\{x\\},Y)} \\end{aligned}$\nFor the proof of security of the threshold MCFE scheme for FMCIP, as stated in Theorem 1, we employ the same security definition as in [43], namely, selective simulation-based security (SEL-SIM security). We present the theorem and its proof in Section 5."}, {"title": "TAPFed FRAMEWORK", "content": "How does TAPFed work? Fig. 2 depicts a summary of the threshold secure aggregation procedure and illustrates the operation of the TAPFed FL system, which consists of a set of parties, decentralized aggregators (allowing a limited number of malicious aggregators), and a crypto infrastructure. TAPFed adopts threshold MCFE to achieve privacy-preserving FL coupled with a decentralized multi-aggregator setting to the secure aggregation process.\nTAPFed initiates threshold secure aggregation prior to the start of training by initializing crypto infrastructure, configuring cryptographic keys for each entity, and deter-mining the agreed-upon fusion weight and training label for each FL training round. To avoid redundancy, the following presentation begins with the threshold secure aggregation mechanism in iter-avg fusion method, where iter-avg fusion means that the aggregated model is the average of each party's model for each training round, and then discusses in Section 4.3 how our proposed mechanism supports other commonly used fusion methods in the FL system.\nAt each train round, each party trains a local model, and encrypts the model update using the threshold MCFE cryptosystem that has been proposed in Section 3 with the current training round as the cryptographic label, and trans-mits it to each aggregator. Next, each aggregator performs the secure aggregation over the received encrypted model updates and returns the aggregated model update to each party. Notably, unlike existing MIFE-based FL solutions [10], [18], which exposes the aggregated model update to the aggregator, here the aggregated model update cannot be learned by aggregators because it is still in the ciphertext. After receiving a set of aggregated model updates with a size greater than the specified threshold, each party is able to recover the aggregated model update in plaintext and start another training round until the maximum number of training rounds has been reached.\nImportantly, in contrast to other innovative decentral-ized aggregator designs, TAPFed eliminates the need for secure enclave hardware support while offering excellent scalability as a result of the design's elimination of ad-ditional communication beyond that between parties and aggregators. This design, which avoids peer-to-peer aggre-gator communication, is consistent with the FL paradigm's primary setting as shown in Fig 2. Moreover, TAPFed di-rectly supports both average and weighted fusion methods, whereas the vast majority of secure aggregation methods only support the former. This is discussed in Section 4.3.\nNote that TAPFed primarily focuses on cross-silo fed-erated learning, aligning with existing secure aggregation research based on computational cryptographic solutions [10], [17]."}, {"title": "Threat Model and Assumption", "content": "The following threat model is considered in TAPFed framework:\n$\\cdot$ Unlike most existing PPFL solutions [21], [25]\u2013[27], [31], [32] that assume aggregator(s) are honest-but-curious and don't collude with other aggregators in a two-server setting, TAPFed eases this assumption. It allows for a limited number of adversarial aggregators enrolled in collusion, which isn't supported by many current privacy-preserving federated learning solutions. These aggrega-tors may also sporadically or intentionally drop out dur-ing the FL training.\n$\\cdot$ Similarly to existing crypto-based PPFL solutions that either rely on a trusted dealer to synchronize keys among parties or on a trusted authority to provide key services to all entities in the FL framework, TAPFed is also built on a trusted crypto infrastructure that is responsible for configuring the underlying cryptosystem and delivering keys to all entities in the framework.\nWe assume all communications take place over secure channels, effectively thwarting eavesdropping attacks. Un-like secure federated learning solutions that address security threats like model backdoor, poisoning, and stealing at-tacks, this work solely concentrates on privacy leakage risks posed by honest-but-curious or even adversarial aggrega-tors. This approach aligns with existing privacy-preserving"}, {"title": "Privacy-Preserving FL Training Process", "content": "First", "functions": "TDSA-Protect and TDSA-Recover, which are executed by parties; and TDSA-Aggregate, which is carried out by aggregators.\nIn TDSA-Protect function, each party employs threshold MCFE to encrypt local model update with its secret key ski. Similar to the setting in [10"}]}