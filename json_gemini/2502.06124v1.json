{"title": "FOUNDATION MODEL OF ELECTRONIC MEDICAL RECORDS FOR ADAPTIVE RISK ESTIMATION", "authors": ["Pawel Renc", "Michal K. Grzeszczyk", "Nassim Oufattole", "Deirdre Goode", "Yugang Jia", "Szymon Bieganski", "Matthew B. A. McDermott", "Jaroslaw Was", "Anthony E. Samir", "Jonathan W. Cunningham", "David W. Bates", "Arkadiusz Sitek"], "abstract": "Background: The U.S. allocates nearly 18% of its GDP to healthcare but has lower life expectancy and higher preventable death rates than other high-income nations. Hospitals struggle to predict critical outcomes such as mortality, ICU admission, and prolonged hospital stays. Traditional early warning systems, like the National Early Warning Score (NEWS) and Modified Early Warning Score (MEWS), rely on static variables and predefined thresholds, limiting their adaptability, accuracy, and level of personalization. Machine learning models are similarly constrained, missing valuable longitudinal EHR patterns.\nMethods: We developed the Enhanced Transformer for Health Outcome Simulation (ETHOS), an AI model that tokenizes patient health timelines (PHTs) from EHRs. ETHOS predicts future PHTs using transformer-based architectures. The Adaptive Risk Estimation System (ARES) employs ETHOS to compute dynamic and personalized risk probabilities for clinician-defined critical events. ARES incorporates a personalized explainability module that identifies key clinical factors influencing risk estimates for individual patients. ARES was evaluated on the MIMIC-IV v2.2 dataset in emergency department (ED) settings, benchmarking its performance against traditional early warning systems and machine learning models.\nResults: We processed 299,721 unique patients from MIMIC-IV into 285,622 PHTs, with 60% including hospital admissions. The dataset contained over 357 million tokens. ETHOS outperformed benchmark models in predicting hospital admissions, ICU admissions, and prolonged hospital stays, achieving superior AUC scores. ETHOS-based risk estimates demonstrated robustness across demographic subgroups with strong model reliability, confirmed via calibration curves. The personalized explainability module provides insights into patient-specific factors contributing to risk.\nConclusion: ARES, powered by ETHOS, advances predictive healthcare AI by providing dynamic, real-time, and personalized risk estimation with patient-specific explainability to enhance clinician trust. Its adaptability and superior accuracy position it as a transformative tool for clinical decision-making, potentially improving patient outcomes and resource allocation in emergency and inpatient settings. We release the full code at github.com/ipolharvard/ethos-ares\u00b9 to facilitate future research.", "sections": [{"title": "1 Introduction", "content": "The United States allocates nearly 18 percent of its GDP to healthcare, yet Americans have shorter lifespans and poorer health than residents of other high-income nations. Among these countries, the U.S. not only has the lowest life expectancy but also the highest rates of preventable deaths [1]. Hospitals face mounting challenges managing patient influx and identifying individuals at risk for critical outcomes, including mortality, intensive care unit (ICU) admission, or prolonged hospital stays [2]. Accurate prediction of critical clinical events is essential for enhancing patient care and optimizing the timely allocation of limited healthcare resources [3]. Early identification of at-risk patients enables clinicians to prioritize interventions, anticipate potential escalations in care, and improve outcomes while simultaneously reducing costs [4, 5]. However, current methodologies often fail to fully utilize the vast and complex data available in electronic health records (EHRs), a limitation that becomes particularly evident in emergency settings where time-sensitive decisions are critical [6, 7, 8, 9, 10]. Traditional scoring systems, such as the National Early Warning Score (NEWS) [11] and the Modified Early Warning Score (MEWS) [12], rely on static variables and predefined thresholds, constraining their ability to adapt to dynamic and multifaceted patient data. Similarly, conventional machine learning models depend on preselected predictors of patient deterioration, requiring the inclusion of only a limited number of variables. These approaches are further hindered by their reliance on specific cutoff points for data inclusion (e.g., triage, 24-hour windows), which can overlook valuable longitudinal patterns.\nRecent advances in generative machine learning, particularly in transformer architectures [13, 14, 15, 16], which underpin the success of Large Language Models (LLMs) [17, 18], have unlocked unprecedented capabilities for processing high-dimensional, heterogeneous, time-stamped, and episodic health data derived from electronic health records (EHRs) [14, 19, 20, 21, 22, 23]. In this work, we build on our previous development, the Enhanced Transformer for Health Outcome Simulation (ETHOS) [14]. While our approach shares some similarities with the works of [20] or [19] it differs in how EHR data are encoded and processed by the transformer model. ETHOS is designed to provide zero-shot predictions; once the model is trained, no additional fine-tuning is required to make inferences. The model operates on Patient Health Timelines (PHTs), which are tokenized sequences of events extracted from EHRs, including demographics, medical history, medications, and more (the full list is provided in Table S7). Using known PHTs up to a given point in time, ETHOS predicts future PHTs (Figure 1). ETHOS enables dynamic, real-time risk assessment by computing a range of possible Patient Health Timelines (PHTs) for a defined outcome, such as ICU admission. If the probability of an adverse event exceeds a critical threshold, appropriate interventions can be initiated to mitigate risk. This continuous probability estimation functions as an early warning system, similar to an experienced physician's intuition in identifying high-risk patients. Unlike traditional models that require predefined inference tasks, ETHOS operates as a single, unified model, allowing for the simultaneous assessment of multiple positive and negative outcomes without retraining. Probabilities for various clinical events are dynamically updated as new patient data becomes available, ensuring adaptability throughout the care process. We refer to this flexible and scalable risk prediction framework as the Adaptive Risk Estimation System (ARES), as illustrated in Figure 2.\nIn this paper, we present the development of ARES and introduce a novel explainability framework that delivers fully personalized insights, allowing clinicians to understand the specific factors influencing the system's risk predictions for individual patients. We benchmark the performance of ARES against state-of-the-art methods across multiple clinically relevant tasks, demonstrating its superior predictive accuracy. Using Emergency Department (ED) datasets from MIMIC-IV-ED [24, 25, 26], we validate its effectiveness and provide the accompanying code for the full reproduction of all the experiments by other researchers."}, {"title": "2 Methods", "content": null}, {"title": "2.1 Data", "content": "In this study, we used the Medical Information Mart for Intensive Care (MIMIC-IV) version 2.2 database [24, 25], including its ED extension. MIMIC-IV, developed by the Massachusetts Institute of Technology and Beth Israel Deaconess Medical Center contains de-identified health records for almost 300,000 patients either admitted to the ED and/or hospital at BIDMC from 2008 to 2019. Detailed patient demographics are presented in Table S2. We extracted relevant data from the MIMIC-IV tables as detailed in Table S7. Laboratory tests and medications were standardized using ATC codes, and all diagnostic and procedural codes were mapped to ICD-10 when necessary, as described in detail [14]. Additional tables requiring advanced processing, such as clinical notes, were not included in the current implementation of ETHOS."}, {"title": "2.2 Tokenization, PHT Construction, model training", "content": "The core of ETHOS lies in constructing PHTs from electronic medical records (EMRs) using a tokenization strategy that captures diverse clinical events. A PHT represents a patient's medical history as a sequence of tokens, each encoding specific health-related information organized chronologically. This structured representation enables comprehensive modeling of patient journeys and more accurate clinical predictions. To build PHTs we used the MEDS-DEV [27] extraction pipeline that converts EHR data to an intermediate format called MEDS [28] to facilitate further data transformations. Advanced transformation operations were subsequently applied, breaking down each event into 1 to 7 tokens based on its complexity. Simpler events required fewer tokens, while intricate ones, such as multi-component lab results, were represented with more tokens to encapsulate their detailed information.\nFor example, lab test results were encoded using quantile-based tokens to represent clinical significance. Time-interval tokens were added to mark the elapsed time between successive events, with intervals shorter than 5 minutes omitted and longer gaps tokenized into 19 distinct interval tokens. Continuous numerical values, such as lab test results, were similarly quantile-encoded using ten quantiles, balancing clinical interpretability and predictive precision. Diagnostic and procedural codes, including ICD-10-CM, ICD-10-PCS, and ATC drug codes, were encoded hierarchically, which leveraged their inherent structure to enhance the transformer model's attention mechanisms. For more details, refer to [14].\nStatic patient attributes such as gender, marital status, race, and body mass index (BMI) were encoded using a single token depending on the value. For age, tokens of quantiles were reused, allowing age representation from 0 to 99. For instance, a 46-year-old patient would be coded as Q5 and Q7. Attributes with potential variability were represented using their most recently known value at the start of the timeline. By incorporating these elements, ETHOS ensured a richer and more adaptable representation of patient timelines.\nThe dataset was split into two disjoint groups: training/validation (90%) and testing (10%). During the training phase, 6 million tokens (1.8% of the entire dataset) were used for validation to balance model optimization and computational efficiency. The detailed statistics about the tokenized dataset are available in Table S6 and S9, and information about the model is in S1."}, {"title": "2.3 Probabilistic inference", "content": "The ETHOS model generates probabilities of future clinical events by leveraging tokenized PHTs and employing a transformer-based generative model. During inference, ETHOS autoregressively generates tokens, each representing a potential future event, until predefined stopping conditions are met, such as the appearance of a token of interest or meeting the simulation time limit. By simulating multiple future PHTs (fPHTs) for each patient, ETHOS accounts for inherent uncertainties and produces robust probabilistic predictions. For example, if N simulated fPHTs are generated and M indicates inpatient mortality, the estimated probability of mortality is calculated as $M/N$ (Section S1). This"}, {"title": "2.4 Explainability", "content": "As illustrated in Figure 3, stochastic simulations can be initiated not only from the most recent token representing current information but also from any preceding token in the patient's history. This allows risk estimates to be visualized as a time series, highlighting how specific medical events affect risk over time. This approach provides intuitive visualizations, offering clinicians clear insights into the factors contributing to current risk values."}, {"title": "2.5 Methods used for benchmarking", "content": "We followed benchmarking tasks for emergency department models presented in the Emergency Department MIMIC- IV-ED benchmark paper [29]. Three tasks were defined: prediction of the hospital admission at triage, prediction of the critical outcome (death or transfer to ICU within 12 hours) at triage, and ED re-presentation within 72 hours after discharge from ED. We applied machine learning methods (logistic regression, random forest, gradient boosting), scoring systems MEWS [12], NEWS [11, 30, 31], Rapid Emergency Medicine Scores (REMS) [32], Cardiac Arrest Risk Triage (CART) [33], five-level triage system Emergency Severity Index (ESI) [34] and neural networks-based models including multilayer perceptron, Med2Vec [35] and Long Short-Term Memory (LSTM) [36].\nTo compare tasks used for early warning scores, we compared the MEDS-Tab library [37] which was used to establish a baseline. MEDS-Tab converts time-series EHR data into a tabular format by aggregating features across multiple time"}, {"title": "2.6 Statistical Methods", "content": "The performance of predictive models was evaluated using Receiver Operating Characteristic (ROC) curves and corresponding Area Under the Curve (AUC) values. Bootstrapping techniques were employed to estimate 95% confidence intervals (CIs) for AUCs. Model predicted probabilities were compared with observed event frequencies using calibration curves to evaluate ETHOS's reliability and alignment with real-world clinical outcomes. All statistical analyses were conducted using Python-based libraries, including scipy and scikit-learn [39, 40]. Data visualization, including ROC curves, calibration plots, and other statistical figures, was performed using matplotlib, seaborn and altair."}, {"title": "3 Results", "content": "Following the tokenization process, the data of 299,721 unique patients from the MIMIC-IV dataset was converted into 285,622 PHTs, which were subsequently used for training and testing. The discrepancy arises from some patients lacking associated data after tokenization. Of the total PHTs, approximately 60% (180,733) contained hospital admissions records. The tokenized dataset comprised over 357 million tokens in total. Detailed information regarding the MIMIC-IV data used, patient demographics, characteristics of the PHTs and tokens, and descriptive statistics are provided in supplementary data (Table S2,S7,S6,S9). The model was trained and validated on 90% of the PHTs, with the remaining 10% reserved for testing. During inference, at least 100 fPHTs were generated for each investigated task.\nThe predictive performance of ETHOS and MEDS-Tab was evaluated for four critical clinical outcomes: hospital mortality, ICU admission, prolonged hospital stay, and a composite risk score (HM+IA+PS). Prolonged stay was defined as a stay longer than 90th percentile of all stays. All predictions were performed at patient admission. As"}, {"title": "4 Discussion", "content": "The ARES framework introduces an innovative approach to building predictive models by leveraging cutting-edge artificial intelligence technology. Several aspects of this approach distinguish it from traditional models. First, ARES enables dynamic risk estimation at any time during a patient's stay, from admission to discharge. Powered by ETHOS [14], ARES utilizes PHTs and incorporates all available clinical information at the time of risk estimation. Unlike traditional models, which rely on static data points such as information collected within 24 hours after admission"}, {"title": "S1 Monte Carlo Justification for Probability Estimation", "content": "Let p(x) denote the probability distribution over fPHTs as modeled by ETHOS where by x we indicate an fPHT. Suppose we want to estimate the probability of some event A regarding the future timeline. For instance, A could be the event \"the patient death when admitted\u201d or \u201cthe patient admitted to ICU.\u201d Formally,\n$Pr(A) = \\sum_{X \\in A} p(x)$,\nwhere the sum is over all sequences x for which the event A holds (i.e., x \u2208 \u0410).\n\nA. Monte Carlo Estimator\n\nA straightforward Monte Carlo approach to approximate Pr(A) is as follows:\n\n1.  Draw N i.i.d. samples {x(1), x(2), . . ., x(N) } from the model p(x).\n2.  Define an indicator function I(x(i) \u2208 A), which is 1 if the sample x(i) lies in A, and 0 otherwise.\n3.  Estimate Pr(A) by the ratio\n$\nPr(A) = \\frac{1}{N} \\sum_{i=1}^{N} I(x^{(i)} \\in A).\n$\n\nIn other words, Pr(A) is simply the fraction of samples whose corresponding timelines satisfy event A indicated as M/N in the text.\n\nB. Unbiasedness\n\nIf the samples x(i) are drawn exactly from p(x), then for each sample,\n\n$E[I(x^{(i)} \\in A)] = Pr(x^{(i)} \\in A) = Pr(A)$.\n\nHence,\n\n$\nE[Pr(A)] = E[\\frac{1}{N} \\sum_{i=1}^{N} I(x^{(i)} \\in A)] = Pr(A),\n$\n\nshowing that Pr(A) is an unbiased estimator of Pr(A).\n\nC. Convergence by the Law of Large Numbers\n\nBy the Law of Large Numbers (LLN), as N \u2192 \u221e,\n\n$\\overline{Pr(A)} \\xrightarrow{a.s.} Pr(A)$,\n\nmeaning the simple ratio of \"successes\u201d (i.e., samples satisfying A) to total draws converges almost surely to the true probability."}]}