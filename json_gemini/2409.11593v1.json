{"title": "Self-Contrastive Forward-Forward Algorithm", "authors": ["Xing Chen", "Dongshu Liu", "J\u00e9r\u00e9mie Laydevant", "Julie Grollier"], "abstract": "The Forward-Forward (FF) algorithm is a recent, purely forward-mode learning method, that updates weights locally and layer-wise and supports supervised as well as unsupervised learning. These features make it ideal for applications such as brain-inspired learning, low-power hardware neural networks, and distributed learning in large models. However, while FF has shown promise on written digit recognition tasks, its performance on natural images and time-series remains a challenge. A key limitation is the need to generate high-quality negative examples for contrastive learning, especially in unsupervised tasks, where versatile solutions are currently lacking. To address this, we introduce the Self-Contrastive Forward-Forward (SCFF) method, inspired by self-supervised contrastive learning. SCFF generates positive and negative examples applicable across different datasets, surpassing existing local forward algorithms for unsupervised classification accuracy on MNIST (MLP: 98.7%), CIFAR-10 (CNN: 80.75%), and STL-10 (CNN: 77.3%). Additionally, SCFF is the first to enable FF training of recurrent neural networks, opening the door to more complex tasks and continuous-time video and text processing.", "sections": [{"title": "Introduction", "content": "Purely-forward and local algorithms propagate signals from inputs to outputs, without any backward pass, and employ a learning rule that is local in space, using signals only from pre- and post- neurons to update a weight. These algorithms, which include well-known Hebbian learning methods [1], have long been studied to model the brain, as their features align with biological processes, contrarily to error backpropagation [2]. They are also ideal for on-chip learning of low-power embedded hardware. The purely forward architecture addresses the challenge of implementing backpropagation on neuromorphic chips, a key obstacle that has been limiting the development of on-chip training for these systems [3]. The local learning rule allows synaptic devices to be directly updated by signals from neuron devices, eliminating the need to store neural activations for gradient computation, thus significantly reducing memory usage, power consumption as well as training times [4].\nThe practical application of these algorithms was historically limited by low accuracy on deep learning image recognition benchmarks, such as CIFAR-10 (labeled) and STL-10 (unlabeled). However, in recent years, accuracy has significantly improved thanks to their integration with automatic differentiation tools and activation functions, combined with the use of standardization and pruning techniques [5-14]. As a result, these algorithms have become relevant not only for brain modeling and energy-efficient training of neuromorphic chips, but also for distributed learning of large-scale models across multiple devices [15-18].\nThese advances have motivated the recent development of novel purely forward and local algorithms aimed at improving accuracy and simplifying implementation for various applications. The Forward-Forward (FF) algorithm is a key example of this new breed of algorithms [19]. Its main advantages are its simplicity and versatility, allowing it in principle to handle both unsupervised and supervised learning, and to process time-series as well as static inputs while many other purely forward and local algorithms are limited to a single category. As a result, the FF algorithm has attracted significant interest since its introduction [7, 20-27], inspiring variants with improved accuracy and architectures and addressing tasks such as image recognition, temporal sequence classification, and reinforcement learning [14, 28-39]. Early demonstrations of FF in silico already cover a wide range of hardware platforms, including microcontrollers [40], in-memory computing systems utilizing Vertical NAND Flash Memory as synapses [41], and physical implementations where neurons are replaced by acoustic, optical, or microwave technologies [42, 43].\nAs illustrated, the accuracy of FF supervised training has significantly improved from below 60% [19] to 88.2% recently [44], progressively catching up with the best supervised, purely local, and forward algorithm [5]. In unsupervised learning, where FF's greatest potential for on-chip training may lie, it has only achieved high accuracy on the MNIST task [19, 45], with limited [38] or no success on more challenging datasets such as CIFAR-10 [46] or STL-10 [47]."}, {"title": "Introduction", "content": "Inspired by the noise contrastive estimation (NCE) method [48], the Forward-Forward (FF) algorithm presents positive and negative examples sequentially to the network inputs. Once trained, the network is expected to produce distinctly different neural responses across all layers for these examples. The key challenge is generating \"negative\" examples that closely resemble the training data but still provide enough contrast for the network to learn meaningful representations.\nSupervised learning methods applicable to any dataset have been developed, solving tasks like MNIST and CIFAR-10 [19, 32]. However, for unsupervised FF learning, there is no universal method to generate positive and negative examples for all databases, hindering FF's application to more complex unsupervised tasks beyond MNIST. This limitation is evident in the few FF points, where only Hebbian and activation learning algorithms have successfully solved CIFAR-10 and STL-10 by combining a local rule with a purely forward architecture.\nMoreover, the FF algorithm currently lacks the ability to handle time-varying sequential data, limiting its applicability in neuromorphic systems which often deal with dynamic inputs from the real world. While the original FF paper [19] includes a multi-layer recurrent neural network, its purpose is to model top-down effects, using a static MNIST image repeated over time frames as input. Another implementation demonstrates a limited form of sequence learning with a fully connected network,"}, {"title": "Introduction", "content": "but this architecture could not handle real-time sequential data due to the absence of recurrence. As a result, FF has yet to be extended to effectively handle recurrent network scenarios for time-varying inputs.\nIn this work, we introduce the Self-Contrastive Forward-Forward (SCFF) method, where each data sample is contrasted within itself to enable efficient learning. This method is inspired by self-supervised learning to provide a simple and effective way to generate positive and negative examples for any dataset. In SCFF, a positive example is created by concatenating an input with itself, while a negative example is formed by concatenating the input with a randomly selected example from the training set. This simple method  not only extends the capabilities of FF to unsupervised tasks but also surpasses the state-of-the-art accuracy of similar algorithms on the MNIST, CIFAR-10, and STL-10 image datasets. It also opens the path to solving sequential tasks by contrasting inputs with FF. More specifically, our contributions are:\n\u2022 We propose an approach called SCFF that takes inspiration from self-supervised learning to generate positive and negative examples and train neural networks with the Forward-Forward algorithm in an unsupervised way, applicable to a wide range of databases.\n\u2022 We show that SCFF significantly outperforms existing unsupervised purely-Forward and local learning algorithms in image classification tasks. With a multilayer perceptron (MLP), we achieved a test accuracy of 98.7% on MNIST. With a convolutional neural network (CNN), we reached 80.75% on CIFAR-10 and 77.3% STL-10 (which includes a small number of labeled examples alongside a much larger set of unlabeled data).\n\u2022 We present the first demonstration of the FF approach being successfully applied to sequential data. Our findings show that the proposed SCFF method effectively learns representations from time-varying sequential data using a recurrent neural network. In the Free Spoken Digit Dataset (FSDD), SCFF training results in an accuracy improvement of over 10 percentage points compared to scenarios where hidden connections remain untrained (random).\n\u2022 We conduct a theoretical and illustrative analysis of the distribution of negative examples generated with our method in comparison to positive examples within the data space. The analysis reveals that negative data points consistently position themselves between distinct clusters of positive examples. This positioning suggests that negative examples play a crucial role in pushing apart and further separating adjacent positive clusters, thereby enhancing the efficiency of classification.\nOur results demonstrate the potential of Self-Contrastive Forward-Forward (SCFF) methods for efficient and flexible layer-wise learning of useful representations in a local and purely forward unsupervised manner. In section 2.1 and 2.2, we will introduce the two foundational methods that SCFF builds upon: the original Forward-Forward algorithm and Contrastive Self-Supervised learning, highlighting their differences and similarities. Next, in section 3, we will present our Contrastive Forward-Forward algorithm and discuss our findings. Finally, we will explore the relationship of SCFF to other purely forward and/or local learning methods in the discussion of section 4."}, {"title": "Background", "content": null}, {"title": "The original Forward-Forward algorithm", "content": "The original Forward-Forward algorithm is depicted in Fig 2b. For an input example xi, each layer's output is assigned a \u2018goodness' score G(l), where l is the layer index. This score is calculated as the mean of the squared activities of the output neurons at layer l: $G^{(l)} = \\frac{1}{M^{(l)}} \\sum_{m} y_{im}^2$, where $M^{(l)}$ is the number of neurons at layer l and m represents the neuron index.\nPredefined positive and negative examples are successively presented to the network's input. The possibility of a positive example xi being recognized as positive and a negative example xj being recognized as negative by the network are defined as $P_{pos}(x_i) = \\sigma (G^{(l)} - \\Theta_{pos})$ and $P_{neg}(x_j) = \\sigma (\\Theta_{neg} - G^{(l)})$ respectively. The sigmoid function $\\sigma(x) = \\frac{1}{1 + e^{-x}}$ evaluates the effectiveness of the separation, where $\\Theta_{pos}$ and $\\Theta_{neg}$ are fixed values that serve as hyperparameters of the network."}, {"title": "Constrastive self-supervised learning", "content": "Inspired by Noise-Contrastive Estimation [48], which aims to distinguish positive examples from noisy examples, the objective of FF learning is to increase the goodness score for positive input examples so that it significantly exceeds the threshold ($P_{pos}(x_i) \\rightarrow 1$) and to decrease the goodness score for negative input examples so that it falls well below the threshold ($p_{neg}(x_j) \\rightarrow 1$). Weight updates are performed locally by combining the gradients derived from both positive and negative examples:\n$L_{FF} = -\\sum_{x_i \\sim pos}log p_{pos}(x_i) - \\sum_{x_j \\sim neg}log p_{neg}(x_j)$\n$= -E_{i, pos}[log\\sigma(G_{i,pos}^{(l)} - \\Theta_{pos})] - E_{j,neg}[log\\sigma(\\Theta_{neg} - G_{j,neg}^{(l)})]$                (1)\nwhere $G_{i, pos}^{(l)}$ and $G_{j,neg}^{(l)}$ respectively correspond to the goodness for the positive and negative examples input at layer l. The final loss is computed over all N examples in the batch.\nHinton [19] proposed that FF can be used for self-supervised representation learning by using real data vectors as the positive examples and engineered data vectors as the negative examples. The negative examples should be carefully designed, rather than relying on random corruption methods of the training data like noise injection or occlusion. The negative data needs to be sufficiently challenging to ensure the network learns useful information. To make FF focus on the long-range correlations in images that characterize shapes, the negative data should have very different long-range correlations while maintaining similar short-range correlations. For the MNIST dataset, this can be achieved by creating a mask with large regions of ones and zeros. As proposed in the original framework [19], negative data is then generated by com-bining one digit image multiplied by the mask with a different digit image multiplied by the inverse of the mask, as illustrated in Fig 2a. Although this method performs well for MNIST (as shown in the Unsupervised panel in Fig 1), it does not easily translate to more complex image databases like CIFAR-10 and STL-10, resulting in limited accuracy on these benchmarks.\nIn this article, we draw inspiration from contrastive self-supervised learning methods to construct positive and negative examples for FF, applicable to any image database and beyond. Contrastive learning, illustrated in Fig 2c, is a self-supervised technique designed to learn representations by contrasting positive pairs against negative pairs. This approach relies heavily on data augmentation, where a positive pair consists of two different augmented views of the same data sample, and negative pairs are constructed from different samples. While FF shares strong similarities with contrastive learning, it also has key differences.\nBoth methods utilize the concept of contrasting positive and negative examples to guide the learning process. They also both aim to learn meaningful data representations without labeled data in the first phase, allowing to extract information from the hidden layers in the second phase by training a linear classifier."}, {"title": "Self-Constrastive Forward-Forward algorithm and results", "content": null}, {"title": "Creating the negative and positive examples", "content": "Instead of contrasting the representations in the feature space as in contrastive self-supervised learning (Fig 2c), SCFF directly takes pairs of positive and negative images as inputs to the neural network (Fig 2d). More specifically, given a batch of N training examples, and for a randomly selected example $x_k (k \\in \\{1, N\\})$ in the batch, the positive example $x_{i,pos}^{(0)}$ (the number 0 is the layer index) is the concatenation of two repeated $x_k$, i.e., $x_{i,pos}^{(0)} = [x_k, x_k]^T$. The negative example $x_{j,neg}^{(0)}$ is obtained by con-catenating $x_k$ with another example $x_n (n \\neq k)$ in the batch, i.e., $x_{j,neg}^{(0)} = [x_k, x_n]^T$ (or $[x_n, x_k]^T$). Fig 3a shows some instances of generated positive and negative examples from the original training batch for the STL-10 dataset.\nConsidering the case of a fully connected network, the concatenated pair of images (positive or negative examples) are sent as inputs to the network. The outputs for the positive and negative examples from the first layer can be written respectively as $y_{i,pos}^{(0)} = f(W_1x_k + W_2x_k)$, $y_{j,neg}^{(0)} = f(W_1x_k + W_2x_n)$, where f is the ReLU activation function. The weight matrices $W_1$ and $W_2$ correspond to the connections to the two images. In practice, we set $W_1 = W_2$ because the gradient of the loss function with respect to $W_1$ and $W_2$ converges to the same value. Setting $W_1 = W_2$ accelerates the training speed and improves the performance. Intuitively, this can be understood by recognizing that swapping the positions of $x_k$ and $x_n$ in the concatenated image should not affect the output neural activities. For a rigorous mathematical proof, see Appendix A."}, {"title": "Training procedure", "content": "The concept of SCFF can be understood through the lens of Noise Contrastive Estimation (NCE). In NCE, a key insight is that \"the noise distribution should be close to the data distribution, because otherwise, the classification problem might be too easy and would not require the system to learn much about the structure of the data\" [48]. Our method of generating the positive and negative examples aligns with this principle if we treat the negative examples as \"noise data\". We assume that the data samples for each class follow a multivariate Gaussian distribution with a shared covariance matrix \u2211 and that each class is statistically independent of the oth-ers assumptions commonly employed in various statistical models [50]. Furthermore, noting that the input weight matrices W\u2081 and W2 are identical, i.e. W = W\u2081 = W2, the concatenated inputs processed by the network are simplified as follows: the positive example becomes $y_{i,pos}^{(0)} = f(W_1x_k + W_2x_k) = f(W(2x_k))$, and the negative example is $y_{j,neg}^{(0)} = f(W_1x_k + W_2x_n) = f(W(x_k + x_n))$. This is equivalent to treating the pos-itive examples as $x_{i,pos}^{(0)} = 2x_k$ and negative examples as $x_{j,neg}^{(0)} = x_k + x_n$. Therefore, the distributions of positive examples $x_{i,pos}^{(0)}$ and negative examples $x_{j,neg}^{(0)}$ follow :\n$x_{i,pos}^{(0)} \\sim N(2\\mu_1, 2\\Sigma)$\n$x_{j,neg}^{(0)} \\sim N(\\mu_1 + \\mu_2, 2\\Sigma)$                                                                 (2)\nwhere $\u03bc_1$ and $\u03bc_2$ are means of two different classes respectively. Theoretically, the negative examples always lie somewhere between two different clusters of positive examples in the sample space, as illustrated in Fig. 4a for the one-dimensional case. For practical analysis with a real-world dataset, we visualized the distributions of positive and negative examples from the IRIS dataset [51] using 2D linear discriminant analysis (LDA), which distinguishes between three different types of irises, as shown in Fig.4b. This visualization shows that the negative examples are positioned between different clusters of positive examples, suggesting that they contribute to pushing apart and further separating adjacent positive examples as they are mapped into higher-dimensional space during training. Additionally, negative examples are formed by combining two examples from different classes, enriching the diversity of negative examples and leading to more robust training. For a detailed analysis of how the LDA components evolve during training as the input data is mapped into the feature space and more theoretical results, please refer to Appendix B.\nWe evaluate SCFF on different image datasets including MNIST [45], CIFAR-10 [46] and STL-10 [47] and (results, as well as an audio dataset Free Spoken\nDigit Dataset (FSDD) [52].\nEach layer of the network was fully trained and frozen before training the next one. After unsupervised training with SCFF, we froze the network and trained a linear downstream classifier [9, 53] with the back-propagation method on representations created by the network using the labeled data. The linear classifier was optimized using cross-entropy loss. The accuracy of this classification serves as a measure of the quality"}, {"title": "Fully connected network: MNIST", "content": "On the MNIST dataset, when trained on a two-layer fully connected network with 2000 hidden neurons each, SCFF achieves a test precision of 98.7%, which is comparable to the performance achieved by backpropagation [19]. This surpasses previously published benchmarks on other biologically inspired algorithms, such as 97.9% in [9], 98.42% in [8] (supervised training), and 96.6% in [7]. The full comparison is shown in the right column of the green frame in Fig 1."}, {"title": "Convolutional neural networks: CIFAR-10 and STL-10", "content": "The convolutional neural network processes three-dimensional color images. The original images are concatenated along the channel dimension to form positive or negative inputs (see Fig 3). The output of each convolutional layer is represented as a three-dimensional vector $y_{i,pos}^{(l)}$ (or $y_{i,neg}^{(l)}$) $\\in$ $R^{C\\times H \\times W}$. The Loss function at layer l is then defined as:\n$L_{SCFF}^{(l)} = -E_{pos} [\\frac{1}{H \\times W}  \\sum_{h}\\sum_{w} log \\sigma (G_{i,h,w,pos}^{(l)} - \\Theta_{pos})]-\nE_{neg} [\\frac{1}{H \\times W}  \\sum_{h}\\sum_{w} log \\sigma (\\Theta_{neg} - G_{i,h,w,neg}^{(l)})]$                                                (3)\nwhere the goodness of neural activities is calculated over the channels as $G_{i,h,w,pos}^{(l)} = \\sum_{c} y_{i,c,h,w,pos}^{2(l)}$ (or $G_{i,h,w,neg}^{(l)} = \\sum_{c} y_{i,c,h,w,neg}^{2(l)}$).\nFor the CIFAR-10 and STL-10 datasets, we employed convolutional neural networks with architectures identical to those in [9] to extract features. SCFF achieves a test accuracy of 80.75% with a three-layer convolutional architecture (number of filters each layer: 96-384-1536) on CIFAR-10 and 77.3% with a four-layer convolutional architecture (number of filters each layer: 96-384-1536-6144) on STL-10. These results surpass the previous state-of-the-art accuracies for purely-forward unsupervised learning, of 80.3% on CIFAR-10 and 76.2% on STL-10 achieved using the SoftHebb algorithm [9]. This demonstrates the significant potential of the SCFF method to scale effectively to more complex datasets and architectures. The full comparison is shown in the left column of the green frame in Fig. 1.\nWe also compared the test accuracies at each layer using SCFF and Backpropa-gation (BP) methods on CIFAR-10 and STL-10. Notably, for STL-10, SCFF achieved a final layer performance of 77.3% higher than the one of BP: 77.02% (Fig. 5b). This is because the STL-10 dataset contains a large amount of unlabeled images, which limits the effectiveness of supervised BP training. By fine-tuning SCFF with end-to-end BP on the few labelled STL-10 examples, SCFF's accuracy further improves to 80.13%. This demonstrates that SCFF is highly suitable for unsupervised pretraining followed by supervised BP training, making it ideal for semi-supervised learning approaches.\nUnlike other unsupervised learning methods, where the result is obtained solely from the final layer's output, SCFF integrates neuron information with the linear clas-sifier from intermediate layers, leading to more comprehensive feature extraction [19]. For CIFAR-10 (Fig. 5 a), the test accuracy for the two-layer and three-layer models was obtained by combining the outputs of all previous layers (pooled information for dimensionality reduction) before feeding them into the final lin-ear classifier. However, because the STL-10 dataset consists of high-quality images, the number of output neurons in each layer is much larger than that in CIFAR-10. Therefore, for the STL-10 dataset, we did not combine outputs from previous layers for training the linear classifier, with the exception of the fourth layer. In this case, we combined the outputs from both the third and fourth layers for the final classifi-cation, resulting in a 1% improvement in accuracy compared to using only the fourth layer's outputs as input to the linear classifier.\nBy visualizing and investigating the class activation map, which highlights the importance of each region of a feature map in relation to the model's output, we"}, {"title": "Recurrent neural network: FSDD audio dataset", "content": "The original FF paper [19] introduces a specialized recurrent neural network (RNN) that models top-down effects using repeated static images as input for each time frame. In contrast, our work focuses on training an RNN that processes time-varying inputs. We employ the Free Spoken Digit Dataset (FSDD), a standard benchmark task for evaluating RNN training performance [55-57]. The FSDD is a collection of audio recordings where speakers pronounce digits (0-9) in English. We follow the standard procedure consisting in extracting frequency domain information at different time intervals, here through Mel-Frequency Cepstral Coefficient (MFCC) features (39 channels) [58]. Plots of the evolution of MFCC feature with time are shown in Fig. 6 for the digits 3 and 8. The SCFF method forms positive and negative examples by concate-nating the same input for positive examples, and different ones for negative examples. Fig. 6a presents a negative example which is generated by concatenating MFCC fea-tures from two different digits. The goal of the task is to recognize the digit after feeding in the full sequence, from the output of the network at the last time step.\nWe train a Bi-directional Recurrent Neural Network (Bi-RNN) in an unsupervised way using the SCFF method to classify the digits. The procedure that we use for this purpose is illustrated in Fig. 6a. Unlike conventional uni-directional RNNs, where sequential input is processed step by step in a single direction, resulting in a sequence of hidden states from Ho to HT, the Bi-RNN comprises two RNNs that process the input in parallel in both forward and backward directions. This results in hidden states evolving from Ho to Hy in the forward RNN and from H to Ho in the backward RNN*, the figure. The red regions in the figure highlight the features at different time steps. This bidirectional structure is particularly advantageous for tasks where context from both preceding and succeeding audio frames is critical, such as speech recognition, enhancing model performance compared to conventional uni-directional RNNs [59].\nThe output of each directional RNN for a positive or negative input example is a two-dimentional vector $h_i \\in R^{M \\times T}$, where T represents the number of time steps and M denotes the number of hidden neurons. The loss function at layer l is then defined as:\n$L_{SCFF} = \\sum_{t}[E_{i, pos}^{(l)}log\\sigma(G_{i,t,pos}^{(l)} - \\Theta_{pos})]-\n[E_{j,neg}^{(l)}log\\sigma(\\Theta_{neg} - G_{j,t,neg}^{(l)})]$                                               (4)"}, {"title": "Discussion", "content": null}, {"title": "Comparison to the original FF algorithm", "content": "In addressing the limitations of the original FF algorithm, our method introduces sev-eral key improvements. Firstly, we have developed an approach for generating negative examples that can be applied to any database. This approach is also biologically plau-sible, since it operates by aggregating two similar or different images at the input, very much like our eyes do. This innovation directly addresses the criticisms highlighted in[8], which pointed out the biological implausibility of the negative examples used in the original FF algorithm.\nFurthermore, we have expanded the applicability of FF to complex unsupervised tasks beyond the MNIST dataset. The SCFF method achieves state-of-the-art (SOTA) accuracy for local methods on challenging datasets such as CIFAR-10 and STL-10,"}, {"title": "Comparison to SOTA self-supervised learning (SSL)", "content": "Our SCFF method draws significant inspiration from self-supervised contrastive learn-ing techniques [49, 68]. While the accuracy of SCFF may be lower compared to these methods, primarily due to its layer-wise learning in a purely local manner, it offers unique advantages. Unlike global self-supervised methods, SCFF operates without requiring auxiliary heads (multi-layer nonlinear projector) or complex regulariza-tion techniques, which simplifies its implementation and makes it more suitable for neuromorphic computing applications.\nRecent developments in local versions of contrastive self-supervised learning have shown promising results [62, 63]. For instance, Laydevant et al. [62] empirically demon-strated that layer-wise SSL objectives can be optimized rather than a single global one, achieving performance comparable to global optimization on datasets such as MNIST and CIFAR-10. However, the layer-wise training methods involving multi-layer MLP as projector heads might offer better performance in certain tasks, but at the cost of increased computational complexity. Illing et al. [64] have shown that local plasticity rules, when applied through the CLAPP model, can successfully build deep hierarchical representations without the need for backpropagation. How-ever, this method introduces additional processing along the time axis, which may add complexity when dealing with data that lacks temporal dynamics."}, {"title": "Comparison to other forward-only methods including non-Hebbian and Hebbian based", "content": "Recently, other purely forward learning techniques have been developed, driven by their potential for biologically plausible and neuromorphic computing applications [7, 8]. Similar to Forward-Forward (FF), Pepita [8] processes data samples in two for-ward passes. The first pass is identical to FF, while the input of the second pass is modulated by incorporating information about the error from the first forward pass through top-down feedback. Activation Learning [7] builds on Hebb's well-known pro-posal, discovering unsupervised features through local competitions among neurons. However, these methods do not yet scale to more complex tasks, limiting their potential applications.\nRecent advances in Hebbian deep learning have also shown remarkable progress , These methods are purely local in space and can be applied purely"}, {"title": "Comparison to energy-based learning methods", "content": "locally in time, offering a biologically plausible approach to learning. Miconi [11] demonstrated that Hebbian learning in hierarchical convolutional neural networks can be implemented with modern deep learning frameworks by using specific losses whose gradients produce the desired Hebbian updates. However, adding layers has not resulted in significant performance improvements on standard benchmarks [11, 12] (see Table 1). Journe et al. [9] proposed using a simple softmax to implement a soft Winner-Takes-All (WTA) and derived a Hebbian-like plasticity rule (SoftHebb). With techniques like triangle activation and adjustable rectified polynomial units, Soft-Hebb achieves increased efficiency and biological compatibility, enhancing accuracy compared to state-of-the-art biologically plausible learning methods.\nOur SCFF method brings the FF approach to accuracy levels comparable to Soft-Hebb, effectively bridging the gap between these learning paradigms. A key advantage of Hebbian learning is its ability to learn without contrast, much like non-contrastive self-supervised learning techniques, operating purely in an unsupervised manner. Con-versely, FF is flexible regarding labels, akin to contrastive self-supervised learning techniques, supporting both unsupervised learning as we demonstrate here with SCFF and supervised learning. This versatility allows FF to be applied across a broader range of tasks and datasets, enhancing its applicability and effectiveness in diverse scenarios.\nEnergy-based learning methods, such as Equilibrium Propagation (EP), Dual Prop-agation (DP) and Latent Equilibrium (LE) [66, 70, 71], also offer locality in space and time. These methods have a significant advantage over SCFF due to their strong mathematical foundations, closely approximating gradients from BP and backpropa-gation through time (BPTT). This theoretical rigor allows them to be applied to a wide range of physical systems, making them particularly appealing for neuromorphic computing applications. EP, for instance, can operate in an unsupervised manner, while recent advancements in Genralized Latent Equilibrium (GLE) [72] have extended these models to handle sequential data effectively.\nHowever, the implementation of energy-based methods poses certain challenges. Specifically, the backward pass in these methods requires either bidirectional neural networks or dedicated backward circuits [73, 74]. These requirements can be complex to design and build in a manner that is both energy-efficient and compact. In contrast, the simplicity and versatility of SCFF in supporting both supervised and unsuper-vised learning, without the need for complex backward circuitry, make it a practical alternative for many applications [3]. This balance of accuracy, ease of implementa-tion, and versatility underscores the potential of SCFF in advancing neuromorphic computing and biologically inspired learning systems."}, {"title": "Conclusion", "content": "In conclusion, the Forward-Forward (FF) algorithm has sparked significant advance-ments in both biologically-inspired deep learning and hardware-efficient computation. However, its original form faced challenges in handling complex datasets and time-varying sequential data. Our method, Self Contrastive Forward-Forward (SCFF),"}, {"title": "Methods", "content": "SCFF learns representations by maximizing agreement (increasing activations/-goodness) between concatenated pairs of identical data examples while minimizing agreement (reducing activations/goodness) between concatenated pairs of different data examples using a cross-entropy-like loss function at each layer. The network is trained layer by layer, with each layer's weights being frozen before moving on to the next. Unlike the original FF framework, this approach incorporates several key components that contribute to achieving high accuracy across various tasks."}, {"title": "Normalization and Standardization", "content": "For vision tasks, the data is typically normalized by subtracting the mean and dividing by the standard deviation for each channel. These mean and standard deviation values are computed across the entire training dataset, separately for each of the three color channels. This dataset-wide normalization centers the data, ensuring that each channel has a mean of 0 and is on a comparable scale.\nIn addition to dataset-wide normalization, we also applied per-image stan-dardization, which plays an important role in unsupervised feature learning [75]. Standardizing the images involves scaling the pixel values of each image such that the resultant pixel values of the image have a mean of 0 and a standard deviation of 1. This is done before each layer during processing , ensuring that each sample is centered, which improves learning stability and helps the network handle varying illumination or contrast between images."}, {"title": "Concatenation", "content": "The positive and negative examples  are generated by concate-nating two identical images for the positive examples and two different images for the negative examples. After being processed by the first layer, the output vectors $y_{i,pos}^{(0)}$ and $y_{j,neg}^{(0)}$ are obtained. There are two approaches for generating the inputs to the next layer. The first approach is to directly use the first layer's output of the positive example $y_{i,pos}^{(0)}$ as the positive input $x_{i,pos}^{(1)}$, and the first layer output of the negative example $y_{j,neg}^{(0)}$ as the negative input $x_{i,neg}^{(1)}$ for the next layer. The second approach involves re-concatenating to form new positive and negative inputs for the next layer. This is done by treating the first layer's positive outputs as a new dataset and recreating"}, {"title": "Triangle method of transmitting the information", "content": "\"Triangle\" method was firstly introduced to compute the activa-tions of the learned features by K-means clustering. This method was later found to be effective in other Hebbian-based algorithms  for transmitting the informa-tion from one layer to the next. The method involves subtracting the mean activation from each channel, and then rec-tifying any negative values to zero before the pooling layer. This approach to feature mapping can be viewed as a simple form of \"competition\" between features while also promoting sparsity.\nImportantly, the \"Triangle\" activation only determines the responses passed to the next layer; it does not influence the plasticity. The output used for plasticity at each position is given by $y_{i,pos}^{(l)} = f^{(l)}(x_{i,pos})$, and $y_{j,neg}^{(l)} = f^{(l)}(x_{j,neg})$, where $f^{(l)}$ refers to the convolutional operations followed by ReLU activation at layer l."}, {"title": "Penalty term", "content": "Training with the FF loss can lead to excessively high output activations for posi-tive examples, which significantly drives positive gradients and encourages unchecked growth in their activation. To mitigate this, we introduce a small penalty term-the Frobenius Norm of the Goodness vector-into the training loss function. For outputs from a CNN layer, the goodness vector Gi,h,w,pos is a two-dimensional matrix where each element represents the goodness calculated over the channel outputs processed by all filters under the same receptive field. In the case of Bi-RNN outputs, the good-ness vector  is a one-dimensional matrix, with each"}]}