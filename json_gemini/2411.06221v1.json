{"title": "Smart-LLaMA: Two-Stage Post-Training of Large Language Models for Smart Contract Vulnerability Detection and Explanation", "authors": ["Lei Yu", "Shiqi Cheng", "Hang Yuan", "Peng Wang", "Zhirong Huang", "Jingyuan Zhang", "Chenjie Shen", "Fengjun Zhang", "Li Yang", "Jiajia Ma"], "abstract": "With the rapid development of blockchain technology, smart contract security has become a critical challenge. However, existing smart contract vulnerability detection methods face three main issues: (1) Insufficient quality and comprehensiveness of datasets, due to the lack of detailed explanations and precise vulnerability locations in current datasets. (2) Limited adaptability of large language models (LLMs) to the smart contract domain, because most LLMs are typically pre-trained on vast amounts of general text data but very little smart contract-specific data. (3) Lack of high-quality explanations for detected vulnerabilities, as most existing methods focus solely on detection without providing clear explanations for their results. These limitations significantly hinder detection performance and make it harder for developers to understand and fix vulnerabilities quickly, potentially leading to severe financial losses. To address these problems, we propose Smart-LLaMA, an advanced detection method based on the LLaMA language model. First, we construct a comprehensive dataset covering four vulnerability types with labels, detailed explanations, and precise vulnerability locations. Second, we introduce Smart Contract-Specific Continual Pre-Training, using raw smart contract data to enable the LLM to learn smart contract syntax and semantics, thereby enhancing their adaptability to the smart contract domain. Furthermore, we propose Explanation-Guided Fine-Tuning, a novel approach that fine-tunes the LLM using paired vulnerable code and explanations, enabling it to both detect vulnerabilities and provide reasoned explanations for its results. To evaluate the quality of generated explanations, we employ both LLM evaluation and human evaluation, focusing on three key aspects: Correctness, Completeness, and Conciseness. Experimental results show that Smart-LLaMA outperforms state-of-the-art baselines, with average improvements of 6.49% in F1 score and 3.78% in accuracy, while providing reliable explanations. We have made all models, datasets, and code available.", "sections": [{"title": "I. INTRODUCTION", "content": "The advent of blockchain technology has seen rapid adoption across various sectors, driven by its decentralized architecture [1]. This innovative technology enables the creation of secure, distributed digital ledgers for recording transactions [2]. Utilizing advanced cryptographic methods, blockchain ensures the integrity and verification of each transaction, establishing itself as a highly reliable technological framework [3], [4]. Within this ecosystem, smart contracts function as self-executing programs on the blockchain, automating the management of digital assets such as cryptocurrencies. These contracts activate when specific conditions are met and, once deployed, become permanent fixtures on the blockchain [5]. However, the immutable nature and inherent complexity of smart contracts present significant security challenges [5]. The well-documented DAO incident [6], [7] serves as a cautionary tale, illustrating the potential severity of such vulnerabilities. This security breach resulted in the unauthorized diversion of Ethereum valued at $60 million, causing widespread disruption within the blockchain community [8], [9]. This event underscores the critical importance of enhancing smart contract security to prevent similar devastating outcomes in the future.\nResearchers have developed various techniques to identify vulnerabilities in smart contracts, each addressing different aspects of the challenge but also facing limitations. Symbolic execution tools like Oyente [10], Mythril [11], Osiris [12], and Manticore [13], as well as static analysis tools such as Slither [14] and SmartCheck [15], rely on predefined patterns to detect vulnerabilities. However, these methods often struggle with complex scenarios and lack generalizability. We conducted a detailed survey of existing smart contract vulnerability datasets as shown in I, evaluating multiple datasets including A [16], B [17], C [18], and D [19], and found significant limitations. These datasets typically provide only basic vulnerability labels, lacking detailed explanations and precise location information. They cover a limited range of vulnerability types, usually only 1 to 3, failing to represent the diverse potential security risks in smart contracts. This simplified labeling approach severely constrains models' ability to comprehensively understand and detect complex vulnerability patterns. These limitations directly affect the learning effectiveness of detection models, potentially leading to questionable accuracy and reliability in detection results.\nSome more advanced methods have attempted to address these limitations. Clear [20] employs a Contrastive Learning (CL) model to capture complex inter-contract relationships, while Zhuang et al. [17] and Luo et al. [21] introduce graph neural network-based approaches to represent smart contracts."}, {"title": "II. BACKGROUND AND MOTIVATION", "content": "In this section, we analyze three key motivations behind our research on improving smart contract vulnerability detection. We use real-world examples and existing datasets to illustrate the limitations of current approaches. These motivations highlight the importance of high-quality datasets, domain-specific model adaptation, and explainable detection results in smart contract vulnerability detection."}, {"title": "A. Problem Statement", "content": "We propose an automated approach to detect vulnerabilities in smart contracts. Our method assigns a label \u0177 to each independent smart contract, where \u0177 = 1 indicates the presence of a vulnerability and \u0177 = 0 denotes security. Notably, our approach not only automatically identifies vulnerabilities but also provides detailed explanations for each detected vulnerability, including its type, location, and potential impact. We focus on four key vulnerability types: Reentrancy, Timestamp Dependency, Integer Overflow/Underflow, and Delegatecall.\nReentrancy vulnerability occurs when a contract calls an external contract or sends Ether before completing all necessary internal state changes. An attacker can exploit this vulnerability by repeatedly calling the vulnerable function before the original call is completed, potentially leading to unexpected behavior such as multiple withdrawals of funds.\nTimestamp dependence vulnerability occurs when smart contracts rely on block timestamps for critical operations. Miners can manipulate these timestamps, potentially compromising contract integrity and leading to financial losses. This vulnerability often affects contracts using timestamps for random number generation or key decision-making processes.\nInteger Overflow/Underflow occurs when the result of an arithmetic operation exceeds the storage range of the variable. In an overflow, the value \"wraps around\" to the minimum value for that type, while in an underflow, it \"wraps around\" to the maximum value. This can lead to unexpected contract behavior such as incorrect balances or out-of-control loops.\nDelegatecall is a low-level function call that allows a contract to dynamically load code from another contract. While this provides powerful upgradeability, it can lead to severe security vulnerabilities if used improperly. The main risk is that the called contract executes in the context of the calling contract and can thus modify the calling contract's storage.\nWe primarily focus on these four vulnerabilities for the following reasons: (i) Empirical evidence shows that approximately 70% of financial losses in Ethereum smart contract attacks are attributed to these vulnerabilities [25]. (ii) Existing works [25]\u2013[27] demonstrate that these vulnerabilities occur with higher frequency in Ethereum smart contracts compared to others. (iii) These vulnerabilities have significant impacts on contract security and functionality, potentially leading to severe economic losses. (iv) Despite being well-known, these vulnerabilities are still often overlooked or misunderstood due to the complexity and immutability of smart contracts."}, {"title": "B. Motivations", "content": "In this section, we analyze three key motivations behind our research on improving smart contract vulnerability detection. We use real-world examples and existing datasets to illustrate the limitations of current approaches. These motivations highlight the importance of high-quality datasets, domain-specific model adaptation, and explainable detection results in smart contract vulnerability detection."}, {"title": "III. APPROACH", "content": "The overall workflow of Smart-LLaMA is shown in Figure 3. The Smart-LLaMA framework consists of four key modules: Open-source Smart Contract Vulnerability Data Collection, Smart Contract Vulnerability Explanation Annotation, Two Stage Post-training for Smart Contract Vulnerability Detection Task, and Evaluation of Explanation generated by LLM."}, {"title": "A. Open-source Smart Contract Vulnerability Data Collection", "content": "Our Smart Contract-Specific Continual Pre-training dataset is derived from the work presented in [28]. This dataset underwent rigorous filtering and quality validation processes. Specifically, Google BigQuery was utilized to select all smart contract addresses on the Ethereum blockchain with at least one transaction. Subsequently, the researchers queried Etherscan, the largest verified smart contract provider, to obtain the source code of these addresses.\nTo ensure uniqueness, the researchers employed the computationally efficient token-based similarity algorithm, Jaccard Index [29]. The downloaded smart contracts contained numerous duplicate library codes. To mitigate this, each contract file was decomposed into its original representative files. Library code, along with other imported contract files, was separated into individual contract records. The resulting smart contracts were then grouped by filename and filtered for uniqueness using a Jaccard Index [29] similarity threshold of 0.9, meaning that all smart contracts sharing over 90% of tokens were discarded.\nOur labeled dataset for Explanation-Guided Fine-Tuning is based on datasets from [30] and [18], encompassing various types of SC vulnerabilities. The authors of [30] manually verified the generated vulnerabilities to ensure their correctness. [18] is the renowned SmartBugs dataset [31], on which [16] annotated reentrancy vulnerabilities.\nWe extracted 1,634 smart contracts containing call.value from [18], and further isolated 379 contracts containing delegatecall, which we manually annotated. To augment our dataset, we crawled verified contracts from Etherscan. The final SFT dataset comprises 3,382 instances of reentrancy vulnerabilities, 1,165 timestamp dependency vulnerabilities, 1,005 integer overflow/underflow vulnerabilities, and 697 delegatecall vulnerabilities."}, {"title": "B. Smart Contract Vulnerability Explanation Annotation", "content": "We utilized the LLMs Qwen2-72B-Instruct and Mistral-Large-Instruct-2407-123B to generate detailed explanations of smart contract vulnerabilities. These LLMs were chosen primarily because they are open-source, powerful language models that excel in natural language processing and code comprehension, comparable to GPT-4 but at a lower cost.\nTo ensure the relevance and accuracy of the generated content, we designed specialized prompts for each vulnerability type, implementing label-guided analysis. These prompts cover common vulnerability types such as reentrancy, timestamp dependence, delegatecall, and integer overflow/underflow. Our prompt design not only guides the models to explain the vulnerabilities but also instructs them to pinpoint the exact locations of these vulnerabilities within the smart contract code, providing specific line numbers and code blocks where the issues occur. For reentrancy vulnerabilities, the prompts guide the models to focus on the use of call.value(), operation order, external calls, access control, and internal function implementation. When analyzing timestamp dependence vulnerabilities, the models are directed to examine the use of block.timestamp or now, time constraints in critical operations, potential for miner manipulation, and the precision of time measurements and their impact on contract logic. For delegatecall vulnerabilities, the prompts require the models to evaluate the use of delegatecall(), context preservation, state variable manipulation, access control, and internal function implementation. Lastly, for integer overflow/underflow vulnerabilities, the models are instructed to check arithmetic operations (especially on uint variables), the use of SafeMath library or Solidity 0.8.x built-in overflow/underflow checks, the use of the 'unchecked' keyword (Solidity 0.8.x or higher), arithmetic operations in critical operations, and type conversion and large number handling. Through this comprehensive and detailed prompt design, we ensure that the generated explanations cover the core elements of each vulnerability type.\nTo further improve the quality of explanations, we introduce Llama-3.1-70B-Instruct as an evaluation model. This LLM assesses the explanations generated by Qwen2 and Mistral, with evaluation criteria including correctness, completeness, and conciseness, each scored on a scale of 1 to 10. During the scoring process, Llama-3.1-70B-Instruct provides detailed scoring rationales and improvement suggestions. We then select the highest-scoring explanations based on this evaluation for further human review.\nIn the human expert review stage, we selected 8 PhD students specializing in smart contract vulnerability detection. These experts were divided into 4 groups of 2, with each group responsible for reviewing one specific type of vulnerability. The selected high-scoring explanations from the LLM evaluation undergo careful review by these experts to verify accuracy. If errors, omissions, or unclear points are found, the experts make necessary modifications and additions to further improve the quality of the explanations."}, {"title": "C. Two Stage Post-training for Smart Contract Vulnerability Detection Task", "content": "We propose an innovative two-stage post-training strategy aimed at enhancing the model's understanding of smart contracts, improving vulnerability detection accuracy, and increasing the quality of explanations. In the Smart Contract-Specific Continual Pre-training stage, the model learns to understand the basic structure, syntax, and semantics of smart contracts by minimizing a context-based language model loss function:\n$\\Ladapt = \\sumlog P(xi|context)$ (1)\nwhere xi represents each token in the input sequence, context represents the surrounding context tokens of xi, and P(xi|context) is the conditional probability of the model predicting xi. In the case of smart contract analysis, this formula takes on specific meanings: xi represents each Solidity token in the smart contract code (e.g., 'function', 'uint256', 'require'). The context typically includes function definitions, state variable declarations, and control structures specific to Solidity. P(xi|context) then becomes the probability of the model correctly predicting Solidity-specific tokens given their surrounding code context. By minimizing this loss, the model learns: (a) Solidity-specific syntax, including contract declarations and function modifiers (e.g., 'payable', 'view'); (b) common smart contract patterns, such as the 'Checks-Effects-Interactions' pattern for preventing reentrancy attacks; (c) EVM-specific operations, including gas considerations and storage vs. memory usage; (d) security-critical Solidity functions, such as 'transfer', 'send', and 'call.value()'. (e) contextual relevance, such as identifying potential security flaws in contract logic, analyzing inter-contract dependencies and interactions, assessing the impact of external calls, and evaluating the correct implementation of access control mechanisms; To maintain the model's general capabilities and prevent catastrophic forgetting, we integrated a substantial amount of general data into the training dataset, including content from mathematics, coding, and linguistics. This approach not only helps the model maintain its understanding of a wide range of knowledge domains but also enhances its generalization ability and robustness in smart contract tasks, reduces the risk of overfitting, and improves the model's performance when dealing with novel or rare contract patterns.\nIn the Explanation-Guided fine-tuning stage, the model focuses on learning to identify specific types of vulnerabilities and generate corresponding explanations. We adopted a balanced loss function:\n$\\LSFT = - \\sum [log P(yg|x;0) + log P(ya|x; 0)]/2$ (2)\nwhere x represents the input smart contract code, yg and yd represent target outputs for the generation task (explanations) and detection task (labels), respectively, and 0 represents all trainable parameters of the model, including attention weights, feedforward layer weights, and embeddings. This loss function ensures that the model is adequately trained on both vulnerability detection and explanation generation tasks. The domain-specific knowledge acquired during the Smart Contract-Specific Continual Pre-training stage lays the foundation for the fine-tuning stage, enabling the model to understand the context and nuances of smart contracts while learning to detect vulnerabilities.\nThrough this two-stage strategy, our model first gains a deep understanding of the specific language and structure of the smart contract domain while maintaining diversity in general knowledge. It then focuses on improving the accuracy of vulnerability detection and the quality of explanations."}, {"title": "D. Evaluation of Explanations", "content": "To comprehensively assess the quality of smart contract vulnerability explanations generated by Smart-LLaMA, we follow [32] and designed an evaluation framework based on three key dimensions: correctness, completeness, and conciseness. Each dimension is scored on a 4-point Likert scale [24].\nOur evaluation is based on three key dimensions: Correctness, Completeness, and Conciseness, Correctness. This criterion evaluates the accuracy of the explanation in terms of reasoning logic and vulnerability localization.\n1 - Disagree: Major errors in logic and localization. 2 - Somewhat disagree: Some errors, misses major vulnerabilities. 3 - Somewhat agree: Minor omissions, locates major vulnerabilities. 4 - Agree: Correct logic, accurate identification and localization.\nCompleteness. This criterion assesses whether the explanation comprehensively covers all potential vulnerability points. 1 - Disagree: Omits multiple key vulnerabilities, superficial explanations. 2 - Somewhat disagree: Identifies some, misses major issues, lacks depth. 3 - Somewhat agree: Covers major vulnerabilities, may miss minor ones. 4 - Agree: Comprehensive identification, detailed explanations for all.\nConciseness. This criterion evaluates whether the explanation is concise and easy to understand and apply quickly. 1 - Disagree: Verbose, key points obscured, difficult to apply. 2 - Somewhat disagree: Somewhat verbose, key info present but unclear. 3 - Somewhat agree: Generally concise, some parts slightly verbose. 4 - Agree: Precise, clear, directly applicable, no redundancy.\nWe utilized the advanced LLM Llama-3.1-70B-Instruct for automated evaluation. We carefully designed a set of prompts containing detailed scoring criteria, example scores, and scoring rationales to guide the LLM in evaluating smart contract vulnerability explanations. The LLM scored each explanation generated by Smart-LLaMA on correctness, completeness, and conciseness using a 4-point Likert scale [24]. In addition to providing specific scores, the LLM also offered detailed rationales for each dimension's score. We then developed automated scripts to calculate the distribution of scores for each vulnerability category in each dimension as the final evaluation result.\nTo further validate the evaluation results, we invited four experienced smart contract security experts for additional expert evaluation. Each expert spent 8 hours evaluating explanations for one evaluation category, totaling 32 hours of in-depth analysis. The experts used the same 4-point Likert scale [24] as the LLM, scoring each explanation on correctness, completeness, and conciseness. They also provided detailed scoring rationales, improvement suggestions, and overall quality assessments. To ensure consistency, we arranged for 20% overlapping evaluation samples, allowing different experts to score the same explanation. If the evaluation difference exceeded 1 point on the Likert scale, we discussed and re-evaluated together to reach a consensus. Finally, similar to the LLM-based evaluation, we calculated the distribution of scores for each category in each dimension as the final evaluation result."}, {"title": "IV. EXPERIMENTS", "content": "To evaluate our proposed Smart-LLaMA approach, we conduct experiments to answer the following research questions:\nRQ1: How does Smart-LLaMA perform in detecting smart contract vulnerabilities compared to state-of-the-art methods?\nRQ2: What is the impact of different components in Smart-LLaMA on its overall performance?\nRQ3: How effective are the explanations generated by Smart-LLaMA in terms of correctness, completeness, and conciseness?\nRQ4: What insights can be gained from detailed analysis of specific cases in smart contract vulnerability detection using Smart-LLaMA?"}, {"title": "B. Dataset", "content": "Smart Contract-Specific Continual Pre-training: we employ a dataset derived from the work of Storhaug et al. [28]. This dataset comprises 186,397 unique smart contract instances from the Ethereum blockchain, totalling 501.62M tokens. We also augment this dataset with an additional 100,000 instances from various domains, including general code, mathematics, English, and Chinese text, totalling 118.94M tokens. This results in a comprehensive dataset of 286,397 instances, totaling 620.56M tokens.\nExplanation-Guided Fine-Tuning: Our Explanation-Guided Fine-Tuning dataset is curated from multiple sources, primarily drawing from Liu et al. [30] and Yu et al. [18]. We incorporate manually verified vulnerabilities from [30] and the SmartBugs dataset [31] with reentrancy vulnerabilities annotated by Wu et al. [16]. To enrich the dataset, we extracted and manually annotated additional contracts from [18] and Etherscan. The final dataset comprises 3,382 reentrancy, 1,165 timestamp dependency, 1,005 integer overflow/underflow, and 697 delegatecall vulnerability instances, totalling 7.87M tokens.\nEvaluation: We utilize the evaluation dataset from [19]. This challenging dataset encompasses four major vulnerability types: reentrancy, timestamp dependency, integer overflow/underflow, and delegatecall. The complexity of this dataset is primarily reflected in three aspects: First, for reentrancy vulnerabilities, while most samples contain call.value function calls, not all contracts with this function are vulnerable, requiring models to understand complex access control and execution sequences; Second, identifying timestamp dependency and delegatecall vulnerabilities demands deep contextual understanding, as most contracts contain blockstamp and delegatecall, but the mere presence of these keywords is insufficient to determine the existence of vulnerabilities; Lastly, the integer overflow type includes both overflow and underflow scenarios, increasing the diversity of vulnerability patterns. We removed the unreasonable labels in the original evaluation dataset [19]."}, {"title": "C. Baselines", "content": "Our evaluation includes a range of baselines for Smart Contract Vulnerability Detection, representing state-of-the-art approaches in four categories: rule-based, neural network-based, pre-trained model-based, and LLM-based techniques.\nBaseline methods, categorized as rule-based techniques, employ predefined heuristics to detect vulnerabilities in smart contracts. This category includes tools such as Mythril [11], Osiris [12], Oyente [10], Slither [14], and Smartcheck [15].\nIn contrast, neural network-based techniques harness the power of deep learning algorithms to detect vulnerabilities in smart contracts. We consider several cutting-edge methods in this category: GCN [33], TMP [17], AME [34], SMS [19] and DMT [19]. It should be noted that we faced challenges in reproducing some baselines, and in other cases, our reproduced results differed significantly from the originally reported values. For fairness, we used the higher of our reproduced results and the originally reported figures for each baseline in our comparisons.\nPre-trained models-based techniques, rely on pre-trained models like CodeT5 [35], CodeBERT [36], GraphCodeBERT [37] and fine-tuning techniques to identify smart contract vulnerabilities, including Peculiar [16] and PSCVFinder [18].\nLLM-based techniques, rely on large language models to identify smart contract vulnerabilities, including LLaMA-3.1-8B-Instruct [38], LLaMA-3.1-70B-Instruct [38], Qwen2-7B-Instruct [39], and Qwen2-72B-Instruct [39]."}, {"title": "D. Metrics", "content": "To evaluate our proposed model and baseline approaches in vulnerability identification, we employ four widely accepted metrics: Precision, Recall, F1-score, and Accuracy. Precision measures the ratio of correctly identified vulnerabilities to all predicted positives, while Recall calculates the proportion of detected vulnerabilities among all actual vulnerabilities. The F1-score provides a balanced measure by computing the harmonic mean of Precision and Recall. Accuracy assesses overall correctness by calculating the ratio of correct predictions to total cases. These metrics collectively offer a comprehensive assessment of our Smart-LLaMA.\nFor assessing the quality of vulnerability explanations generated by Smart-LLaMA and baseline models, we utilize three key metrics as discussed in Section III-D1: Correctness, Completeness, and Conciseness."}, {"title": "E. Implementation Details", "content": "We perform Smart Contract-Specific Continual Pre-training and Explanation-Guided Fine-Tuning using LlamaFactory [40] and DeepSpeed [41] with fp16 enabled. We calculate loss with cross-entropy and optimize parameters using AdamW [42] with \u03b2=(0.9, 0.99) and e=1e-8. For all our models, we employ full parameter fine-tuning and continual pre-training. During Smart Contract-Specific Continual Pre-training, we set the batch size to 64 per device, gradient accumulation steps to 16, epochs to 2, learning rate to le-5 with cosine decay, warmup steps to 0, cutoff length to 2048, and save steps to 500. During Explanation-Guided Fine-Tuning, we set the batch size to 8 per device, gradient accumulation steps to 8, epochs to 3, learning rate to le-5 with cosine decay, warmup steps to 0, cutoff length to 2048, and save steps to 50. All models were trained on a server equipped with 8 NVIDIA GeForce RTX H800 GPUs, each with 80GB memory. For evaluating our Smart-LLaMA, we use greedy decoding with do_sample set to false. Peculiar [16] originally only detects reentrancy vulnerabilities, while PSCVFinder [18] detects reentrancy and timestamp dependency vulnerabilities. We extended both tools to detect two additional vulnerability types using the same code."}, {"title": "F. Experimental Results", "content": "In this section we present experimental results to answer the research question.\nRQ1: To answer this question, we compared Smart-LLaMA's performance against 16 baseline methods across four different vulnerability types: Reentrancy, Timestamp Dependency, Overflow/Underflow, and Delegatecall. The results are presented in Table II.\nSmart-LLaMA demonstrated superior performance across all vulnerability types, consistently outperforming state-of-the-art (SOTA) methods. For Reentrancy vulnerabilities, Smart-LLaMA achieved the highest scores with an F1-score of 88.37% and accuracy of 93.12%, surpassing the previous best performer DMT by 7.35% in F1-score and 4.14% in accuracy. In detecting Timestamp Dependency vulnerabilities, Smart-LLaMA again led with the highest F1-score of 96.15% and accuracy of 95.17%, outperforming DMT by 1.24% in F1-score and 0.62% in accuracy. For Overflow/Underflow vulnerabilities, Smart-LLaMA maintained its lead with the highest F1-score of 85.71% and accuracy of 89.78%, surpassing DMT by 7.82% in F1-score and 4.83% in accuracy. Finally, for Delegatecall vulnerabilities, Smart-LLaMA showed strong performance with the highest F1-score of 89.36% and accuracy of 94.51%, exceeding the previous best performer PSCVFinder by 9.55% in F1-score and 5.53% in accuracy. Notably, Smart-LLaMA consistently outperformed other popular methods such as Mythril, Oyente, Securify, and Slither across all vulnerability types, and showed significant improvements over more recent LLM-based approaches like LLaMA-3.1-8B and Qwen2-7B in most metrics.\nThe superior performance of Smart-LLaMA can be attributed to three key factors. Our comprehensive dataset provided rich learning resources, covering various vulnerability types and complex scenarios. The Smart Contract-Specific Continual Pre-training and Explanation-Guided Fine-Tuning enabled the model to deeply understand smart contract structures and the detection process, significantly enhancing its detection capabilities.\n[RQ1]: Smart-LLaMA consistently outperformed 16 state-of-the-art baseline methods across all four types of vulnerabilities (reentrancy, timestamp dependency, integer overflow/underflow, and delegatecall).\nRQ2: Our ablation study elucidated the crucial roles of Explanation-Guided Fine-Tuning (EGFT) and Smart Contract-Specific Continual Pre-Training (SCPT) in the Smart-LLaMA architecture. The base model represents Smart-LLaMA's full performance. \"w/o EGFT\" indicates the model trained only with labeled data for Supervised Fine-Tuning, without the vulnerability explanations. \"w/o SCPT\u201d represents the model without Smart Contract-Specific Continual Pre-Training, and \"w/o Both\" shows the performance without both components.\nFor reentrancy vulnerabilities, the complete Smart-LLaMA achieved 93.12% accuracy and 88.37% F1 score. Removing EGFT significantly reduced performance (71.10% Acc, 5.97% F1), while eliminating SCPT has a lesser impact (84.86% Acc, 68.57% F1). The drastic drop in F1 score without EGFT (from 88.37% to 5.97%) indicated that the detailed reasoning process in Explanation-Guided Fine-Tuning is particularly important for the LLM to understand and identify the complex logic of reentrancy vulnerabilities.\nIn detecting timestamp dependency vulnerabilities, Smart-LLaMA achieved an impressive 95.17% accuracy and 96.15% F1 score. Removing EGFT severely impacts performance (54.59% Acc, 48.91% F1), while omitting SCPT has a milder effect (83.09% Acc, 87.46% F1). Notably, excluding both components led to a dramatic performance decline (39.13% Acc, 16.00% F1), highlighting their synergistic importance.\nFor integer overflow vulnerabilities, the complete model attained 89.78% accuracy and 85.71% F1 score. EGFT's removal caused a substantial drop (59.85% Acc, 45.00% F1), while SCPT's absence had a moderate impact (79.93% Acc, 57.36% F1). Similarly, for delegate call vulnerabilities, Smart-LLaMA achieved 94.51% accuracy and 89.36% F1 score. Again, removing EGFT resulted in a more significant decline (67.58% Acc, 35.16% F1) compared to removing SCPT (86.26% Acc, 67.53% F1).\nWe can summarize the following general patterns: (1) The complete model performs best across all vulnerability types, demonstrating the importance of both modules in Smart-LLaMA; (2) The impact of EGFT is generally more significant than that of SCPT, indicating that detailed reasoning processes are particularly important for understanding and identifying complex vulnerability logic; (3) While SCPT has a relatively smaller impact, it still positively contributes to the performance by providing broad domain knowledge to support the model's contextual understanding and reasoning depth when analyzing smart contracts.\n[RQ2]: Explanation-Guided Fine-Tuning (EGFT) and Smart Contract-Specific Continual Pre-Training (SCPT) both significantly enhance Smart-LLaMA's performance. EGFT shows a more substantial impact, especially on F1 scores.\nRQ3: Table IV presents the quality assessment results of explanations generated by the Smart-LLaMA method for smart contract vulnerability detection tasks. The evaluation comprises two parts: LLM evaluation and human evaluation, each assessing three dimensions: Correctness, Completeness, and Conciseness.\nIn both LLM and human evaluations, Smart-LLaMA significantly outperformed the baseline (LLaMA-3.1-8B-Instruct). In the LLM evaluation for correctness, Smart-LLaMA achieved a score of 4 (agree) in 89.4% of cases and 3 (somewhat agree) in 2.8%, compared to the baseline's 61.9% and 9.8%. For completeness, Smart-LLaMA scored 4 in 77.8% of cases and 3 in 15.0%, substantially higher than the baseline's 51.3% and 25.1%. In terms of conciseness, Smart-LLaMA excelled with 65.5% scoring 4 and 33.3% scoring 3, versus the baseline's 25.8% and 53.8%. evaluation results further corroborated Smart-LLaMA's advantages. For correctness, Smart-LLaMA received a score of 4 in 69.5% of cases and 3 in 19.8%, notably higher than the baseline's 33.3% and 35.2%. In completeness, Smart-LLaMA achieved a score of 4 in 57.1% of cases and 3 in 30.6%, compared to the baseline's 22.4% and 51.0%. Regarding conciseness, Smart-LLaMA again demonstrated superior performance, with 65.6% scoring 4 and 32.7% scoring 3, while the baseline achieved 17.5% and 64.6% respectively.\nThese results clearly indicated that the Smart-LLaMA method generates more accurate, comprehensive, and concise explanations for smart contract vulnerability detection.\nNotably, human evaluation scores were consistently lower than those from LLM evaluation, highlighting a potential gap between automatically generated explanations and human expert expectations. This observation suggested a direction for future research: further optimization of generative models to produce explanations that better align with human.\n[RQ3]: Smart-LLaMA has demonstrated its capability to generate explanations for smart contract vulnerability that are correct, complete, and concise, as validated by both LLM evaluation and human evaluation.\nRQ4: We demonstrated the superiority of Smart-LLaMA in smart contract vulnerability detection through a specific case study. As illustrated in Figure 4, we compared Smart-LLaMA with other methods such as Slither, PSCVFinder, and Peculiar.\nThis case study highlighted the advantages of our two-stage post-training method. Slither, PSCVFinder, and Peculiar all incorrectly identified a reentrancy vulnerability, failing to accurately assess the contract's security. These tools overlooked crucial security features, particularly the role of the onlyOwner modifier. In contrast, Smart-LLaMA successfully provided the only correct assessment. It accurately recognized that the contract is secure against reentrancy attacks and offered an in-depth analysis. Smart-LLaMA's smart contract-specific pre-training enabled it to deeply understand the contract structure, especially in accurately identifying the critical role of the onlyOwner modifier in protecting the refund function.\nSmart-LLaMA's explanation-guided fine-tuning further enhanced its analytical capabilities. Although it noted that the balance update occurs after the external call (which typically could lead to reentrancy issues), Smart-LLaMA accurately assessed that in this specific case, the owner restriction (onlyOwner) effectively eliminates the reentrancy risk. This nuanced analysis demonstrates Smart-LLaMA's ability to consider multiple security factors and context.\n[RQ4]: Compared to other methods, Smart-LLaMA not only accurately identifies the contract's security features but also provides in-depth contextual analysis, thus demonstrating clear advantages in complex smart contract security evaluations."}, {"title": "V. RELATED WORK", "content": "Smart contract vulnerability detection research has evolved significantly", "techniques": "Oyente [10", "11": "and SmartCheck [15", "43": "utilized formal verification with custom-designed compliance and violation patterns. Others", "12": "and Manticore [13", "44": "introduced a bidirectional LSTM with an attention mechanism for reentrancy vulnerability detection. SmartEmbed [45", "information": "works by Zhuang et al. [17", "34": "utilized GNNs to represent contract semantics, with Liu et al. combining GNNs with expert patterns. Recent advancements include pre-training models like Peculiar [16", "46": "which utilized a graph"}]}