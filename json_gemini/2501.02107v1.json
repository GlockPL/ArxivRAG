{"title": "Online Detection of Water Contamination Under Concept Drift", "authors": ["Jin Li", "Kleanthis Malialis", "Stelios G. Vrachimis", "Marios M. Polycarpou"], "abstract": "Water Distribution Networks (WDNs) are vital infrastructures, and contamination poses serious public health risks. Harmful substances can interact with disinfectants like chlorine, making chlorine monitoring essential for detecting contaminants. However, chlorine sensors often become unreliable and require frequent calibration. This study introduces the Dual-Threshold Anomaly and Drift Detection (AD&DD) method, an unsupervised approach combining a dual-threshold drift detection mechanism with an LSTM-based Variational Autoencoder (LSTM-VAE) for real-time contamination detection. Tested on two realistic WDNS, AD&DD effectively identifies anomalies with sensor offsets as concept drift, and outperforms other methods. A proposed decentralized architecture enables accurate contamination detection and localization by deploying AD&DD on selected nodes.", "sections": [{"title": "I. INTRODUCTION", "content": "Water Distribution Networks (WDNs) are crucial for community well-being and economic growth, requiring robust monitoring to address challenges like contamination detection. For instance, Milwaukee, USA, experienced one of the largest U.S. waterborne outbreaks when Cryptosporidium contaminated the water supply, affecting over 400,000 residents [1]. Timely detection is essential to protect public health, ensure safe drinking water, and mitigate risks.\nChlorine is injected into WDNs for disinfection, with concentrations maintained within specific bounds for effective water quality management [2]. Accurate monitoring is crucial under varying conditions, as chlorine levels fluctuate due to factors like chemical reactions or malicious attacks, serving as potential contamination indicators [3]. Manual sampling methods are ineffective during contamination events due to delays, while online monitoring ensures prompt threat detection and response.\nWith advancements in environmental sensing networks, data-driven analytics are increasingly used to study and predict water quality [4]. However, real-world data often exhibits non-stationary behavior, or concept drift, due to factors like measurement offsets, power failures, and hydraulic changes. Distinguishing concept drift from continuous anomalies, such as persistent changes in chlorine concentration, becomes challenging when both occur simultaneously.\nThis study addresses contamination detection and localization in non-stationary WDN environments. We propose the Dual-Threshold Anomaly and Drift Detection (AD&DD) method and a decentralized architecture for localization. The key contributions are:\n1) We evaluate two realistic water networks with strategically placed sensors, classifying arsenite contamination as anomalies and sensor offsets as concept drift. In the decentralized architecture, each sensor uses AD&DD for local anomaly detection, enabling fault localization with initial flow direction knowledge.\n2) AD&DD employs an LSTM-VAE-based online learning algorithm with a dual-threshold mechanism for detecting both concept drift and anomalies without supervision. Drift detection occurs in the latent space. Comparative analysis shows that our method outperforms several state-of-the-art techniques.\nThe paper is organized as follows: Section II reviews related work. Section III details the proposed detection method and architecture. Sections IV and V cover the experimental setup and results. Finally, Section VI concludes with a summary and future work."}, {"title": "II. RELATED WORK", "content": "A. Concept drift adaptation\nData nonstationarity, often due to concept drift (a change in the underlying probability distribution), is a challenge in streaming applications. Methods to address drift are classified as passive or active [5]. Passive methods adapt incrementally without full re-training [6]\u2013[9]. Active methods detect changes in the data distribution to trigger adaptation. Hybrid methods combine the strengths of both approaches [10].\nRequiring fully labeled data can be unrealistic in some real-world scenarios. To address this issue, the research community has explored alternative learning paradigms. In active learning [11], strategies are employed to intelligently determine when to query a human expert for ground truth information, such as class labels, for selected examples. Unsupervised learning, where no labeled data is required, autoencoders have emerged as effective drift detectors. For instance, [12] introduces an autoencoder-based approach that monitors two distinct cost functions-cross-entropy and reconstruction error-to detect concept drift. The variation in these cost functions serves as an indicator for concept drift detection. Another work [13] also employs autoencoder and leverages the advantages of both incremental learning and drift detection based on Mann-Whitney U Test. In this paper, we focus on unsupervised learning methods and AEs.\nB. Contamination diagnosis\n1) Contamination detection: Machine learning techniques classify water quality time series as normal or anomalous, as reviewed in [4]. Deep Belief Networks (DBNs), an unsupervised learning method, effectively reconstruct inputs probabilistically. In [14], DBNs are used to analyze and predict water chemical features, showing superior accuracy over traditional supervised learning methods. Threshold methods, like Isolation Forest (iForest) [15], set upper and lower limits to classify data. Among density-based algorithms, the Local Outlier Factor (LOF) [16] uses reachability distance to detect outliers, while iForest detects anomalies by analyzing path lengths in an ensemble of trees. VAE4AS [17] introduces dual concept drift detection, distinguishing between abnormal sequences and drift, making it suitable for contamination detection under concept drift.\n2) Contamination localization: Several approaches focus on contamination localization. [18] combines Artificial Neural Networks (ANNs) for pollution classification and Random Forests for regression analysis, using Monte Carlo simulations to identify contamination sources, though it remains offline in stationary environments. [19] proposes a method for locating contamination sources in DWDS, but it assumes known flow directions and does not address concept drift. In [20], an inline mobile sensor localizes contamination based on Bayesian updates of intrusion probabilities.\nThese methods highlight a research gap in real-time online contamination localization under concept drift. To address this, we propose a cost-effective approach using fixed sensors, capable of detecting anomalies and localizing contamination in real-time with only initial flow direction data."}, {"title": "III. ONLINE WATER CONTAMINATION DETECTION AND LOCALIZATION", "content": "A. Overview\nProblem formulation. A WDN is defined as a network, with nodes representing junctions and edges denoting pipes. The task is to identify any harmful substance which might have been injected accidentally (e.g., during a leakage) or maliciously. We identify it at points where it reacts with chlorine, which is already in the water for disinfection purposes. The concept drift considered here is the measurement offset of sensors. The chlorine sensors are installed on the nodes to measure the concentration level. These sensors are represented as $S_1, S_2, ..., S_K$. At each time t, the univariate time series of $S_i$ is $x_t \\in \\mathbb{R}$, where $i \\in (1, 2, ..., K)$.\nSensor placement. In practice, sensor installation is optimized by selecting a subset of nodes from feasible locations to minimize objectives like risk, considering impact metrics such as the number of people infected [21]. This study uses the strategy from [22] with a multi-objective evolutionary algorithm to minimize infected populations. Additional methods are discussed in [23].\nProposed Architecture. This study proposes a decentralized architecture where each sensor hosts a detector, sending results to a monitoring center for real-time contamination localization. Fig. 1 illustrates the architecture, with green dashed lines for sensor measurements, blue dashed lines for AD&DD predictions, and the orange section highlighting contamination localization. A detailed technical description follows.\nProposed algorithm. The unsupervised AD&DD algorithm detects anomalies and localizes them. As shown in Fig. 2, the system observes the value at time t, denoted as $x_t$. In the decentralized architecture, the observation is $x_t \\in \\mathbb{R}$ from sensor $s_i$. The output $\\hat{y}_t \\in \\{0,1\\}$ indicates anomaly (1) or normal conditions (0).\nAutoencoders detect anomalies by reconstructing normal data with minimal error. To capture temporal dependencies, we integrate a Variational Autoencoder (VAE) with Long Short-Term Memory (LSTM), addressing the vanishing gradient problem. The VAE learns a distribution $q(z|x)$ with a multivariate Gaussian assumption, and regularization is applied via Kullback-Leibler (KL) divergence. The total VAE loss combines reconstruction loss and KL divergence, with $\\beta \\ge 0$ adjusting KL's weight. Our algorithm also includes a drift detection component to adapt IVAE.\n$l_{VAE}(x,\\hat{x}) = l_{AE}(x,\\hat{x}) + \\beta * l_{KL}(x)$ (1)"}, {"title": "B. Detailed Description", "content": "Deployment. In the decentralized architecture, each sensor has its own AD&DD mechanism for localized monitoring. Let $\\hat{y}_1, \\hat{y}_2,..., \\hat{y}_K$ represent anomaly detection results at sensors $S_1, S_2,..., S_K$ at time t, where $\\hat{y}_i \\in \\{0,1\\}$. This enables localized anomaly detection, aiding fault localization when combined with flow direction. A central monitoring center can analyze real-time results for network-wide fault localization.\nMemory. Each AD&DD has three windows: $ref_n$, $mov_{all}$ and $mov_{retrain}$. Therefore, the number of windows is $3*K$. $ref_n$ stores the encodings of normal instances and $mov_{all}$ stores the encodings of the most recent instances. Both $ref_n$ and $mov_{all}$ have the same size as $W_{drift}$. $mov_{retrain}$ stores the instances of size $W_{retrain}$ once drift alarm is raised.\nThe following descriptions are for individual AD&DD.\nAD (Anomaly Detection). An adaptive threshold $\\theta_t$ is set based on the maximum training loss, with anomalies detected when the cumulative loss exceeds this threshold. The initial threshold is calculated using offline data. At retraining time t, the loss for all elements in the window $mov_{retrain}$ is calculated: $L_t = \\{l_{VAE}(x^{t'}, \\hat{x}^{t'})\\}_{t'=t-W_{retrain}+1}^t$. The threshold at training time t is set to avoid false drift alarms:\n$\\theta_t = max(L_t) + std(L_t)$ (2)\nDD (Drift Detection). Drift is detected by calculating the Euclidean distance between the reference window $ref_n$ and the most recent data window $mov_{all}$, as shown in Eq. (3). Dual distance thresholds help distinguish between minor sensor drifts and significant deviations indicating contamination, as shown in Eq. (4). If a drift is detected, the model is retrained, and the reference window is updated with data in $mov_{retrain}$.\n$Dis(ref_n, mov_{all}) = \\sqrt{\\sum_{i=1}^n \\sum_{j=1}^m (ref_{n_{ij}} - mov_{all_{ij}})^2}$ (3)\n$alarm = True \\; if \\; thre_{upp} > Dis(ref_n, mov_{all}) > thre_{low}$ (4)\nLocalisation. The fault is assumed to lie in the intersection of the upstream region of the sensors that detect an anomaly at time t (i.e., $\\hat{y}_i = 1$) and the downstream region of the sensors that do not detect an anomaly. Specifically, define $S_1 = \\{S_i \\; | \\; \\hat{y}_i = 1\\}$ as the set of sensors that detect an anomaly at time t, and $S_0 = \\{S_i \\; | \\; \\hat{y}_i = 0\\}$ as the set of sensors that do not detect an anomaly at time t. The contamination region is the intersection of the upstream of $S_1$ and the downstream of $S_0$:\n$Contamination \\; Region = Upstream(S_1) \\cap Downstream(S_0)$ (5)"}, {"title": "IV. EXPERIMENTAL SETUP", "content": "A. Data Generation\nHanoi and ZJ networks. The Hanoi network has 32 nodes, 34 pipes, and a reservoir [24]. The Zhi Jiang (ZJ) network features 164 pipes, 113 demand nodes, and 50 primary loops, with a fixed head reservoir [25]. Fig. 3 shows both networks, including flow directions and sensor placements.\nScenarios generation. We use EPyT-Flow [26] to model scenarios in WDNs, creating three scenarios each for the Hanoi and ZJ networks based on demand patterns from [27]. Chlorine (0.7 mg/L) is continuously injected for disinfection, with arsenite (0.8-1 mg/L) introduced in fault scenarios. Sensor offsets are set to 0.98 of the true value. Six months of historical normal data are used for pretraining, followed by six months with faults and drifts for online training. STL [28] is applied to adjust data, removing trend and residual components, with a one-week period. Anomaly periods are 960-1440 and 5760-6240, as shown in Table I.\nB. Compared methods\niForest++ [15]: An advanced tree-based method for anomaly detection (Sec. II-B), adapted to concept drift using incremental learning ('++').\nLOF++ [16]: Similar to iForest++, we use LOF as the classifier, combined with incremental learning for drift adaptation. The description can be found in Sec. II-B.\nVAE4AS [17]: As detailed in Sec. II-B, VAE parameters align with AD&DD, and for drift detection, we use the same statistical test parameters and threshold from original paper.\nAD&DD: The proposed method as described in Sec. III.\nC. Performance metrics and evaluation method\nTo evaluate experiment results, we use the geometric mean (G-mean) as the performance metric for anomaly detection effectiveness at each node. G-mean is robust to class imbalance [29] and is defined as G-mean = $\\sqrt{R^+ \\times R^-}$, where $R^+ = TP/P$ is the positive class recall, and $R^- = TN/N$ is the negative class recall. TP, P, TN, and N represent true positives, total positives, true negatives, and total negatives, respectively. G-mean is insensitive to class imbalance and achieves high values when all recalls are high and their differences are minimal. Prequential evaluation with a 0.99 fading factor converges to the Bayes error on stationary data without a holdout set [30]. We plot the prequential G-mean at each time step, averaged over 10 repetitions with standard error bars."}, {"title": "V. EXPERIMENTAL RESULTS", "content": "In the following experiments, the hyper-parameters for LSTM-VAE are as follows: learning rate =0.0001, mini-batch size = 64, weight initializer = He Normal; Optimizer = Adam, Hidden activation = Leaky ReLu, Num. of epochs = 100, $\\beta$ = 1.0, time step = 10, output activation = Sigmoid, Loss function = Square error, Hidden layers = [2]. $mov_{retrain}$, is set to 500 and $W_{drift}$ = 200. Optimal thresholds $thre_{low}$ and $thre_{upp}$ for each scenario are determined through experimentation, and the specific values will be provided in the code.\nIn the following, we will first analyze the localization capability of the decentralized architecture, and then evaluate AD&DD's detection performance by comparing it with other approaches.\nA. Contamination localization\nIn this experiment, four scenarios are used, with two for each network. Localization accuracy, as summarized in Table II, shows that up to 5 nodes, including the contamination source, are localized despite limited sensors. While false negatives are low, false positives are relatively high, likely due to concept drift.\nB. Contamination detection performance comparison\nIn this section, we compare the detection performance of iForest++, LOF++, VAE4AS, and AD&DD across four scenarios: N7 in Hanoi Sce.1, N18 in Hanoi Sce.2, N6 in ZJ Sce.1, and N26 in ZJ Sce.3. Contamination periods are highlighted in red, drift periods in yellow dashed lines, and retraining times are marked with red (AD&DD) and green (VAE4AS) dashed lines.\nAs shown in Fig. 4, VAE4AS performs similarly to AD&DD in the Hanoi network scenarios but poorly in others, showing limited robustness. While both methods include drift detection, VAE4AS raises false alarms except in Hanoi Sce.2, while AD&DD accurately detects drift across all cases. iForest++ maintains an average G-mean above 0.7 but does not match AD&DD's performance. LOF++ shows significant variability, performing well in some scenarios like Hanoi Sce.2 but poorly in others. These results suggest the other methods have limited fault detection potential, so comparative experiments for contamination localization were not conducted with these methods."}, {"title": "VI. CONCLUSIONS", "content": "Contamination in WDNs poses risks to public health, and monitoring chlorine levels helps detect these events as contamination reacts with chlorine. This study simulates arsenite contamination and sensor measurement offsets using two realistic WDNs, proposing AD&DD, a method combining LSTM-VAE for anomaly detection with a dual-threshold drift detection, requiring no labeled data. Experiments show that AD&DD outperforms current methods. Future work will explore more complex contamination scenarios."}]}