{"title": "GPT-4 Emulates Average-Human Emotional Cognition from a Third-Person Perspective", "authors": ["Ala N. Tak", "Jonathan Gratch"], "abstract": "This paper extends recent investigations on the emotional reasoning abilities of Large Language Models (LLMs). Current research on LLMs has not directly evaluated the distinction between how LLMs predict the self-attribution of emotions and the perception of others' emotions. We first look at carefully crafted emotion-evoking stimuli, originally designed to find patterns of brain neural activity representing fine-grained inferred emotional attributions of others. We show that GPT-4 is especially accurate in reasoning about such stimuli. This suggests LLMs agree with humans' attributions of others' emotions in stereotypical scenarios remarkably more than self-attributions of emotions in idiosyncratic situations. To further explore this, our second study utilizes a dataset containing annotations from both the author and a third-person perspective. We find that GPT-4's interpretations align more closely with human judgments about the emotions of others than with self-assessments. Notably, conventional computational models of emotion primarily rely on self-reported ground truth as the gold standard. However, an average observer's standpoint, which LLMs appear to have adopted, might be more relevant for many downstream appli-cations, at least in the absence of individual information and adequate safety considerations.", "sections": [{"title": "I. INTRODUCTION", "content": "The exploration of large language models (LLMs) in un-derstanding and modeling human emotions has received sig-nificant attention in the last two years. These studies haveprobed the capabilities of models such as the GPT familyof LLMs and others in tasks related to causal reasoning [1],emotional decision-making and appraisal theory [2], emotionclassification [3]\u2013[5], emotional intelligence [6], emotionaldialogue understanding [7], generation of emotional text [8],and more. A consistent method across these studies is thezero-shot approach (i.e., in-context learning) with promptengineering, emphasizing the LLMs' ability to perform taskswithout explicit training.\nWhile the field of affective computing often concentrateson inferring emotions from expressions, typically overlook-ing the triggering circumstances [9], computational emotionmodels aim to understand the situational context, includinghow specific aspects may evoke particular emotions and influ-ence future decisions, behaviors, and beliefs [10], [11]. Thefoundation of most computational emotion models is appraisaltheory [12], [13], actually a cluster of theories that share theprinciple that emotions arise from an evaluation of how currentcircumstances impact the individual. This evaluation, based oncriteria known as appraisal variables, assesses the relevanceof a situation to one's goals, its alignment with these goals,and its predictability, among other factors. The specific patternof these assessments gives rise to particular emotions. Forinstance, anger is triggered by goal-incongruent events whenthe person perceives control, whereas sadness emerges froma sense of powerlessness. The intensity of these emotionsis further shaped by factors such as the importance of thethreatened goal or the unexpectedness of the threat, leading tostronger emotional responses [14].\nIn this paper, we seek to address a persistent controversyinvolving appraisal theory as to whether it reflects the actualmechanisms involved in human emotion elicitation [15], orwhether it serves as a folk psychological theory that observersuse to interpret the emotions of others [16], [17], or if bothperspectives are equally valid (echoing similar controversiesas to whether emotion recognition methods are best seen asrecognizing felt or perceived emotion). If the former, LLM-based models would be well-suited to emotion recognition.If the latter, they may be better suited to predicting socialperceptions.\nCurrent evaluations of LLM abilities have not directly eval-uated the distinction between production and perception. Forexample, Tak and Gratch [2], [18] showcased the advantageof using appraisal theory as a lens to shed light on similaritiesand differences in how humans and LLMs attribute emotionsto situations. Though the work only considered self-reportedemotions from descriptions of autobiographical memories, anddid not contrast the accuracy of these predictions against thoseof outside observers reading the same descriptions. This studywas also limited by the small size of the corpus they used.\nWe address these limitations with two studies. We first lookat carefully crafted, artificial emotion-evoking stimuli withratings on a large set of appraisal and emotion dimensions. Thestimuli were originally designed to find patterns of brain neuralactivity representing fine-grained inferred emotional attribu-tions of others. We show that GPT-4 [19], arguably the mostcapable LLM currently available, is more accurate in reasoningabout such stimuli than free-form self-report vignettes. Theperformance might also be derived from the differences inperspective. In other words, GPT-4 might view situations asan observer and capture the third-person perspective of theaverage human. This hypothesis motivates the second study, inwhich we examine whether GPT-4 processes emotions throughan average observer's lens. To this end, we employ a corpusthat includes both author and reader annotations of appraisalsand emotions. In both studies, we follow the current practiceof assessing LLMs' zero-shot in-context learning abilities(temperature set to 0) employing OpenAI's API resources.\nOur work builds upon recent efforts to unravel the under-lying mechanisms and inner workings of LLMs and AI morebroadly. Emotional inference plays a pivotal role across a spec-trum of real-world social contexts, including courtroom judg-ments, therapeutic environments, negotiations, and personalrelationships. Given its significance, the emotional cognitivecapabilities of LLMs and AI at large can pose substantialrisks or confer critical benefits. The perspective LLMs adoptin emotional inference is a fundamental component of theircognitive capacity, especially influencing their applicabilityin various domains. Depending on their intended use, anLLM might be optimally deployed either to recognize theemotions people are actually experiencing or to gauge socialperceptions. For instance, a storytelling model should steerclear of endorsing any particular understanding of emotionalexperiences in the absence of a universal consensus, aiminginstead to align with general social perceptions. Conversely,a model designed for personal therapy must closely alignwith an individual's authentic emotional state. The subsequentsections explore different components of LLM's emotionalreasoning with discussions on LLM performance in relationto the nature of inputs (stereotypically crafted stimuli versusspontaneous, free-form scenarios) and the model's perspective(first-person/experiencer versus third-person/observer)."}, {"title": "II. STUDY 1: CRAFTED EMOTION-EVOKING STIMULI", "content": "Skerry and Saxe [20] hypothesized that brain representationsinvolved in inferring others' emotions based on short textualnarratives are better captured by appraisal variables thanby combinations of basic emotional dimensions. Instead ofstudying emotions as directly experienced by individuals, i.e.,the authentic and subjective/first-person experience of emo-tions, Skerry and Saxe [20] explored how people intuitivelyunderstand and theorize about the causes of emotions. In otherwords, they aimed to explore folk psychological theories [21]about emotions (i.e., how emotions are caused). Regardless ofwhether these ideas are directly tied to immediate emotionalexperiences, such folk psychological theories (e.g., appraisaltheory) hold value as they often capture real causal regularitiesin the world.\nIn their study, subjects read 200 stimuli describing situationsthat would elicit a particular emotion. The reliability of theconstructed stimuli was tested by a group of subjects on MTurkwho classified the stimuli with 65% accuracy (chance = 5%).The constructed verbal stimuli (2-3 sentences each; M(SEM)=\n50.68(0.28) words) describe a character in an emotion-elicitingevent who experiences one of 20 different emotions withoutany mention of the character's reaction. Participants (1521total responses) are asked to rate the situation on high-dimensional appraisal space (38 variables drawn from differenttheories, particularly Scherer and colleagues [22], [24]) andeight basic emotion dimensions (six basic emotions plusvalence and arousal).\nAiming to replicate and extend the approach in [2] on theextensive set of carefully crafted stimuli described above, weprompt GPT-4 to rate the scenarios using the same scales andwordings given to Skerry and Saxe's participants. We repeatedeach prompt eight times, yielding 1600 data points, enablingus to analyze variability in responses. An example promptis illustrated in Fig. 1, which includes the narrative eachtime generated with a random female name and a minimumadditional text to help the model provide standardized output.Skerry and Saxe used random names to avoid bias thatmight arise from a particular name (like them, we did notexamine any effects of name choice). In particular, we aim toexamine how accurate GPT-4 would be at predicting people'sassessment of others' appraisals (i.e., third-person appraisalderivation), people's attributions of others' emotion (i.e., third-person affect derivation), and would it be consistent withappraisal theory in explaining appraisal-emotion mapping?"}, {"title": "A. Reduced appraisal space", "content": "Following Skerry and Saxe [20], we apply sequential featureselection to reduce appraisals to a smaller feature spaceas several of the 38 appraisals are highly correlated. Thereduced appraisal space eliminates redundant features, helpingto capture unique variance across stimuli.\nUtilizing an ensemble classifier, we evaluate the contributionof each feature towards accurately classifying the 20 distinctemotion labels and incrementally add features that improveclassification accuracy. A model trained on ten appraisal vari-ables classifies the scenarios with 45.8% accuracy compared to56.6% observed with the full appraisal space (thus, suggestingthe reduced space achieves reasonable performance). Below isthe list of selected features:\n\u2022 Pleasantness: Did the situation involve a hedonicallypositive or pleasant experience for (name)?\n\u2022 Expectedness: Did (name) expect this situation to occur?\n\u2022 Agent-cause: Was this situation caused by a person orsome other external force (e.g., randomness)?\n\u2022 Self-cause: Was this situation caused by (name) herselfor by someone/something else?\n\u2022 Already-occurred: Was (name)'s emotion based onsomething that had already occurred?\n\u2022 Close-others: Did people other than (name) know aboutthe situation that occurred?\n\u2022 Pressure: Was (name) under a lot of pressure in thissituation?\n\u2022 Consequences: Was (name)'s situation an isolated inci-dent, or did it have long-term consequences?\n\u2022 Safety: Did this situation involve risks for (name) orothers?\n\u2022 Self-esteem: Did this situation affect (name)'s self-esteem or opinion of herself?\nStrikingly, using the same ensemble approach with GPT-4 rated appraisals (i.e., using GPT-4 rather than humans topredict appraisal values) achieved 94.5% accuracy with thesame reduced set, compared to 99.7% accuracy using the full39 appraisals. Fig. 2 illustrates the performance of GPT-4 theclassify stimuli following their intended labels (i.e., True labels"}, {"title": "B. Appraisal derivation", "content": "To examine how well GPT-4 predicts how a person wouldappraise a situation (i.e., appraisal derivation), we computePearson correlations between the ten appraisal variables ratedby human participants and the corresponding variables pre-dicted by GPT-4. To this end, we first averaged the scoresover each stimulus for humans and GPT-4 to have a meanstimuli score. We observe very high correlations across theten variables, suggesting the GPT-4 mean responses closelymatch human mean appraisal scores. GPT-4 seems\nto struggle to predict if a situation has already occurred (using"}, {"title": "C. Basic emotion recognition", "content": "Both participants and GPT-4 rated the stimuli on the eightbasic emotion dimensions. Table II demonstrates the results ofPearson correlation analysis. Similar to the appraisal derivationstep findings, very significant correspondence is observed."}, {"title": "D. Appraisal to emotion mapping", "content": "Finally, we investigate if GPT-4 reports a theoreticallyplausible relationship between appraisal variables and emo-tions. Recall that appraisal theories state that emotions arisefrom specific patterns of appraisals. Here, we examine andcompare the pattern underlying human participants and GPT-4 responses. To this end, we conducted multiple linear re-gression (with backward elimination) to see if/how appraisalspredict emotion dimensions. Additionally, for instances wherer"}]}