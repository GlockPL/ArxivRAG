{"title": "From Flexibility to Manipulation: The Slippery Slope of XA\u0399 Evaluation", "authors": ["Kristoffer Wickstr\u00f8m", "Marina H\u00f6hne", "Anna Hedstr\u00f6m"], "abstract": "The lack of ground truth explanation labels is a fundamental challenge for quantitative evaluation in explainable artificial intelligence (XAI). This challenge becomes especially problematic when evaluation methods have numerous hyperparameters that must be specified by the user, as there is no ground truth to determine an optimal hyperparameter selection. It is typically not feasible to do an exhaustive search of hyperparameters so researchers typically make a normative choice based on similar studies in the literature, which provides great flexibility for the user. In this work, we illustrate how this flexibility can be exploited to manipulate the evaluation outcome. We frame this manipulation as an adversarial attack on the evaluation where seemingly innocent changes in hyperparameter setting significantly influence the evaluation outcome. We demonstrate the effectiveness of our manipulation across several datasets with large changes in evaluation outcomes across several explanation methods and models. Lastly, we propose a mitigation strategy based on ranking across hyperparameters that aims to provide robustness towards such manipulation. This work highlights the difficulty of conducting reliable XAI evaluation and emphasizes the importance of a holistic and transparent approach to evaluation in XAI.", "sections": [{"title": "1 Introduction", "content": "Explainable artificial intelligence (XAI) is a crucial research area to ensure trustworthiness in computer vision [44], which contains a wide range of methods that provide explanations for the output of a predictive model [7,38,53]. To determine which XAI method is suitable for a given problem setting, quantitative evaluation analysis is necessary to provide an objective measurement for comparison. Such"}, {"title": "2 Related Work", "content": "Metric-based Quality Estimation Quantitative analysis of XAI explanation has improved considerably in recent years, and researchers now have a vast amount of evaluation metrics at their disposal [2,26]. Due to the lack of ground truth explanations, researchers try to quantify the quality of an explanation by measuring desirable properties, which can be categorized into 6 families of properties [26]; faithfulness [10], robustness [3], localisation [51], complexity [16], randomisation [1], and axiomatic [30]. Within each family, a variety of metrics exists.\nPrior Studies on Hyperparameter Sensitivity in XAI Increasing attention has been given to the influence and potential confounding effects of hyperparameters in XAI evaluations [24]. These studies vary in defining dependent versus independent variables and the hyperparameter space of intervention, be it model, explanation, or evaluation space. Studies have examined the sensitivity of attribution methods to explanation hyperparameters like random seed and number of samples [8], and the impact of baseline choices in methods like Integrated Gradients on explanation outcomes [46, 49]. Additionally, the sensitivity of explanation outcomes concerning model performance variables such as optimizer,"}, {"title": "3 Preliminaries", "content": "For clarity, we present the core concepts and notation used in the work.\nLocal explanations Let the input to a black-box classifier \u0192 be denoted as $x \\in \\mathbb{R}^d$ and the output of the classifier as f(x) = \u0177. Local explanation methods [7, 15, 45,50] interpret the decision of f by attributing an importance score to each component of x. We denote the explanation of f for a given class y as $e \\in \\mathbb{R}^d$.\nEvaluating Explanations Here, we present a generalized formulation of quantitative XAI evaluation to illustrate the static input parameters and adjustable hyperparameters. We assuming an evaluation function F\u2192 R on the form:\n$F(f, x, e, a, b, c) = s.$"}, {"title": "4 Manipulating \u03a7\u0391\u0399 Evaluation", "content": "Here, we introduce our manipulation strategies for changing the evaluation outcome of XAI evaluation with only small hyperparameter alterations. The motivation for this approach is that there often exists several agreed-upon hyperparameters for a given XAI evaluation method. For instance, when conducting a"}, {"title": "Intra-manipulation", "content": "We propose two ways to manipulate XAI evaluation methods. First, we propose to focus on manipulating the evaluation outcome for a single XAI method, which we refer to as intra-manipulation and is defined as:\nDefinition 1 (Intra-Manipulation). Given an evaluation function F, an input sample x, an explanation e, hyperparameters a, b, and c, and a feasible set of hyperparameters A for the hyperparameter a, the intra-manipulation method solves the following optimization problem to determine the hyperparameter a, which maximizes the evaluation score of F:\n$\\begin{array}{c}\\text { maximize } F(f, x, e, a, b, c) \\\\ \\text { subject to } a \\in \\mathbb{A} .\\end{array}$ \nDefinition 1 defines an optimization problem where the goal is to find hyperparameters that maximize the evaluation outcome, but are constrained to lie within a feasible set of values (A in this case) for the hyperparameters in questions. Determining this feasible set requires a researcher's judgment and a good understanding of the particular XAI evaluation method that the user wants to manipulate. But more deeply, it fundamentally depends on the model: i.e. the feasible set is and should be dependent on the learned functional response of the model. In Sec. 5, we further explain how to determine the feasible set. If the feasible set is large, Definition 1 can be solved through suitable optimization techniques. If the feasible set if small, an exhaustive search can be performed. Also note that Definition 1 can be extended to optimize across several hyperparameters, e.g. maximizing both a and b."}, {"title": "Inter-manipulation", "content": "Definition 1 allows for improving the evaluation outcome of a single XAI method. But in many cases it could be desirable to alter the outcome of the evaluation of several XAI methods. Our second manipulation approach is to take a holistic view and manipulate the evaluation of several XAI methods jointly. We refer to this approach as inter-manipulation and define it as:\nDefinition 2 (Inter-Manipulation). Given an evaluation function F, an input sample x, a set of explanations {e1,\u2026\u2026\u2026, \u0435\u043c } from M different XAI methods, hyperparameters a, b, and c, and a feasible set of hyperparameters A for the"}, {"title": "5 Manipulating Faithfulness Evaluation", "content": "Some types of XAI evaluation methods are more susceptible to manipulation than others. For instance, localization metrics, which aims to measure if an explanation is within a region-of-interest, usually only have 1 or even 0 hyperparameters to select [5,51] and are therefore harder to manipulate. On the other hand, faithfulness metrics [3,10,39] have at least 3 hyperparameters that must be determined, and often more. This is one of the most popular evaluation methods in XAI [4, 7, 9, 17, 40, 43] and is therefore an important evaluation category to study. Therefore, we will focus on manipulating faithfulness metrics. The following section provides an overview of the fundamental components in faithfulness evaluation.\nThe fundamental components of faithfulness Faithfulness measures to what extent explanations follow the predictive behavior of the model by iteratively perturbing the input and monitoring the corresponding change in the output of the model. Our focus will be on the task of classification, since this is the most common setting in the context of explainability and vision. This section presents the mathematical formulation of the general components of most faithfulness metrics. Let S denote the set of indices {1,\u2026\u2026,d} for each element in the input sample $x \\in \\mathbb{R}^d$. Partition S into K sets S1,\u2026, Sk of equal cardinality C and arranged such that:\n$\\Sigma\\_{i \\in S\\_1} e\\_i \\geq \\ldots \\geq \\Sigma\\_{i \\in S\\_K} e\\_i$ \nFor convenient notation, we define the sum of attributions for one partition as:"}, {"title": "6 Towards More Reliable Quantitative Evaluation with Mean Resilience Rank", "content": "Due to the lack of ground truth explanations, we cannot determine what setting of hyperparameters constitutes the \"correct\" choice. However, we do know that it is desirable to perform well across all hyperparameter settings. Therefore, if an XAI method consistently appears among the highest-ranked methods across numerous hyperparameters, it provides an indication of high quality with less sensitivity to hyperparameters. Thus, to provide robustness towards hyperparameter manipulation, we propose to rank each XAI method for each hyperparameter setting in the feasible set, and average the ranking across the entire set. We will refer to this ranking-approach as Mean Resilience Rank (MRR).\nHere, we describe mathematically how to perform this ranking. First, assume we want to evaluate M explanation methods, and that we only have a single hyperparameter a with a feasible set of values At that can be altered. We denote one element of A as ai, such that the evaluation outcome for all M XAI methods can be collected in the set:\n$S\\_F(a\\_i) = \\{F(f, x, e\\_1, a\\_i, b, c), \\ldots, F(f, x, e\\_M, a\\_i, b, c) \\}.$ \nThen, we define a function R(\u00b7) that takes in a set of scores and outputs a vector with integer elements, where 0 indicates the lowest score within the set and M-1 indicates the highest score within the set. Finally, we define the outpout of the MMR as the following ranking vector:\n$r=\\frac{1}{\\vert A\\vert}\\Sigma\\_{a\\_i \\in A}\\frac{R\\lbrack S\\_F(a\\_i)\\rbrack}{M}$ \nFor clarity, we have focused on a single hyperparameter, but Eq. (5) can easily be extended to several hyperparameters. For evaluation methods where a high value is desirable, a high ranking indicates good performance, and vice versa for evaluation methods where a low value is desirable."}, {"title": "7 Experimental Setup", "content": "We evaluate our manipulation strategy across numerous datasets, models, and XAI methods, which are described below. We also define the feasible sets used in our manipulation methods."}, {"title": "Defining the Feasible Set of Hyperparameters for Faithfulness", "content": "A critical aspect of the manipulation methods outlined in Sec. 4 is to determine the feasible set of hyperparameters. This requires in-depth knowledge of the family of quantitative metrics that we aim to manipulate. In this work, we focus on the faithfulness family of evaluation metrics and the critical hyperparamters outlines in Sec. 5.1. We focus on a subset of hyperparameters to provide a clear and understandable evaluation of our manipulation strategies. The feasible set of hyperparameters considered in this work are shown in Tab. 2. This selection is based on common choices in the literature for partition size [7, 15, 24, 26, 53], perturbation function [3, 40, 46], and normalization function [10, 11, 24]. We consider the aggregation function fixed as AUC aggregation, which means that a lower faithfulness score is better. Specifically, we compute the AUC of the faithfulness curve from the set of perturbed model outputs {\u00dbS1,\u2026\u2026,\u00dbSK}."}, {"title": "8 Results", "content": "Here we present the results of performing our proposed inter-manipulation and intra-manipulation. In both cases, we survey the literature and create what"}, {"title": "Intra-Manipulation Results", "content": "Tab. 3 shows the results of performing the intra-manipulation proposed in Definition 1, where base is the score obtained with the selected set of hyperparameters described above and manipulated is the score obtained after manipulation. These results demonstrate that there is much room for changing the evaluation outcome for a single XAI method, in some cases as much as a 130 % improvement from the base to the manipulated evaluation outcome. Note that the manipulated scores are not directly comparable, since the manipulation is performed method-wise and the hyperparameters can be different. Therefore, the inter-manipulation shown in the next section must be used to alter the outcome of an evaluation across methods."}, {"title": "Inter-Manipulation Results", "content": "Tab. 4, Tab. 5, and Tab. 6 show the results of performing the inter-manipulation proposed in Definition 2, where the scores are manipulated towards LRP, Saliency, and KernelSHAP, respectively. For some tasks, the evaluation outcome can be manipulated such that most of the three methods achieves the best performance. This is particularly apparent for PneumoniaMNIST, where all XAI methods can achieve the best performance after manipulation. For some datasets there is less room for manipulation. This is most clear from the ImageNet results. That said, the evaluation difference between explanation methods can still be reduced and thus make the XAI evaluation findings less conclusive (see e.g. Imagenet results in Tab. 6). In Appendix A, we provide a summary of the amount of times each hyperparameter occurs in the manipulated set."}, {"title": "Towards More Robust Faithfulness Evaluation", "content": "The results in Tab. 3, Tab. 4, Tab. 5, and Tab. 6, demonstrate that the evaluation outcome can be manipulated and can not be trusted, which reduces the trustworthiness of the quantitative evaluation. Here, we display the results of using MRR described in Sec. 6 towards mitigating the potential for manipulation.\nTab. 7 displays the results of this ranking procedure, which shows that the top-performing XAI methods change between datasets. However, if we average the ranking across all datasets, LRP comes out as the top-performing method closely followed by KernelSHAP, while Saliency seems to be consistently ranked lower. But note that there is notable variation in the scores, which we further illuminate in Fig. 2. The benefit of this ranking approach is that there is little room for manipulation since the top-performing methods will have to perform well across numerous hyperparameters and datasets. The downside of this ranking approach is that it requires a significant amount of computation to calculate the scores for all methods across all hyperparameters and datasets. Also, while averaging across datasets can provide robustness, it can also obfuscate important insights from a particular dataset. Therefore, it is important to include the dataset-wise ranking such that readers can get an overview of the evaluation."}, {"title": "9 Discussion and Limitations", "content": "The hyperparameters described in Sec. 7.1 could be extended to include other important choices such as the order of perturbation, i.e., descending or ascending [43] and the type of normalization function applied [11]. Also, in all our experiments we repeatedly perturb the input until the entire image is perturbed, which is the standard approach in faithfulness analysis. However, when the majority of pixels are removed there is danger of OOD effects (see e.g. Fig. 1), which can influence the evaluation outcome [22]. An alternative approach would be to only perturb parts of an image to avoid such OOD effects. One example is to perturb until the prediction changes and then stop [7]. But this introduces yet another hyperparamter, which further increases the scope for manipulation.\nOur proposed MRR is a simple approach to combat the problem of manipulation, but it also has drawbacks. Most prominently, the computational cost rises quickly when more methods and hyperparameters are considered. Also, MMR requires domain expertise to determine the feasible set of hyperparameters. If the selection of the feasible set is done incorrectly, it might exacerbate the problem of manipulation since it can increase the amount of hyperparameters to choose from. MRR is also a ranking-based approach, where the scores depend on the set of explanation methods used in the analysis, including the cardinality of that set. Since the rankings are relative, they do not allow for meaningful comparisons across different tasks. To address this, we propose creating an open-source database, leveraging tools like Quantus [26] and OpenXAI [2], to efficiently store and standardise benchmarking results, thereby supporting researchers with the development and XAI evaluation. For future work, we further aim to expand the parameter sensitivity analysis to other families of quantitative measures such as randomisation [1,25] and robustness [3, 17,55] which rely on parameters such as segmentation masks and noise perturbation methods, respectively."}, {"title": "10 Conclusion", "content": "We have presented two general-purpose methods for manipulating the quantitative evaluation of explanation methods. Intra-manipulation which increases the performance of a single method and inter-manipulation which manipulates a comparative analysis of XAI methods. The motivation for these methods is based on the lack of ground truth explanations, which makes the selection of hyperparameters in quantitative evaluation for XAI challenging. We demonstrate the effectiveness of our manipulation strategies across numerous vision datasets and XAI methods for faithfulness metrics, with results indicating that there is significant room for manipulation of the evaluation outcome. This has potentially big implications for the XAI community, as it shows that evaluation outcomes cannot always be \"taken at face value\" and therefore, trusted. Lastly, we present a new ranking-based procedure that aims to improve the reliability of quantitative evaluation of XAI. We believe that this work highlights the difficulty of conducting reliable XAI evaluation and emphasizes the importance of a holistic and transparent approach to evaluation in XAI."}]}