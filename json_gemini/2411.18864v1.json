{"title": "Redesigning the ensemble Kalman filter\nwith a dedicated model of epistemic uncertainty", "authors": ["Chatchuea Kimchaiwong", "Jeremie Houssineau", "Adam M. Johansen"], "abstract": "The problem of incorporating information from observations received serially in time is widespread\nin the field of uncertainty quantification. Within a probabilistic framework, such problems can be ad-\ndressed using standard filtering techniques. However, in many real-world problems, some (or all) of the\nuncertainty is epistemic, arising from a lack of knowledge, and is difficult to model probabilistically.\nThis paper introduces a possibilistic ensemble Kalman filter designed for this setting and characterizes\nsome of its properties. Using possibility theory to describe epistemic uncertainty is appealing from a\nphilosophical perspective, and it is easy to justify certain heuristics often employed in standard ensemble\nKalman filters as principled approaches to capturing uncertainty within it. The possibilistic approach\nmotivates a robust mechanism for characterizing uncertainty which shows good performance with small\nsample sizes, and can outperform standard ensemble Kalman filters at given sample size, even when\ndealing with genuinely aleatoric uncertainty.", "sections": [{"title": "1 Introduction", "content": "Dynamical real-world systems are typically represented as a hidden process in some state space, indirectly\nobserved via a measurement process. The usual approach to characterizing the unknown state and uncer-\ntainty about it is to combine the observed information with given prior information in an approach known\nas filtering, or sometimes data assimilation [29]. However, this is non-trivial due not only to imprecise\nmeasurements, but also to model misspecification [31].\nPerhaps the best-known data-assimilation algorithm is the Kalman filter (KF) [22], which is the optimal\nfilter for the linear Gaussian state-space model, as detailed, e.g., in [31]. However, its application is limited\nby its high computational costs when dealing with large state spaces, and by the fact that it cannot be\napplied directly to nonlinear models [28]. Several modifications of the KF have been developed to extend its\nscope. The extended Kalman Filter can deal with a mild level of nonlinearity by approximating the model\nwith a first order Taylor series expansion, as described, e.g., in [34]. The unscented Kalman Filter (UKF)\napproximates the distribution with Gaussian distribution using a set of sigma points and their weights,\noften giving better accuracy for highly nonlinear models [37]. Still, the accuracy of the UKF depends upon\nthe tuning of certain algorithmic parameters which determine the locations of the sigma points. Moreover,\nthe number of sigma points (and hence the computational cost and accuracy) is fixed. Another widely\nused algorithm is the ensemble Kalman filter (EnKF) [5, 35], which uses an ensemble to approximate the\ndistributions of interest. The strengths of the EnKF are that it does not require the calculation of the\nvariance (avoiding costly matrix inversions in high-dimensional problems) and can be used with a nonlinear\nmodel without approximating it with its linear tangent model [28] as one simply needs to be able to sample"}, {"title": "2 Background", "content": "We first briefly review the standard EnKF and the underlying filtering problem in Section 2.1 before intro-\nducing, in Section 2.2, the framework based on which the proposed method will be derived."}, {"title": "2.1 State estimation problem and filtering technique", "content": "The standard, probabilistic Gaussian state-space model describes the evolution of a hidden state process,\n(Xk)k>0, and its associated observation process, (Yk)k>0, via\nXk = Fk(Xk-1) + \u20ack\nYk = Hk(Xk) + \u025bk\nwhere \u20ack ~ N(0, Uk)\nwhere \u025bk ~ N(0, Vk),\n(1a)\n(1b)\nwith Uk and Ve positive definite matrices and with \u039d(\u03bc, \u03a3) denoting a Gaussian distribution of mean \u03bc and\ncovariance \u03a3.\nWe consider the setting in which a stream of observations Y1, Y2,... arrives sequentially in time, and we\nwant to obtain estimates of the hidden states as they arrive. Thus, in the Bayesian context, we characterise\nour knowledge of the state Xk at time step k > 0 given the realisations Y1:k = (Y1, Y2,...,Yk) of the\nobservations Y1:k via the filtering density p(xk|Y1:k) which can be computed recursively, see, e.g., [31], as\np(xk|Y1:k-1) = \u222bp(xk|xk-1)p(xk-1|Y1:k-1)dxk-1\np(xk|Y1:k) = p(yk|xk)p(xk|Y1:k\u22121)/\u222bp(yk|xk)p(xk|Y1:k\u22121)dxk\u02d9\n(prediction)\n(update)\nThe Kalman Filter (KF) provides a closed-form recursion for the prediction and update steps for linear\nGaussian state-space models (see, e.g., [31]). However, many models in this world are nonlinear, meaning\nthat the KF is not directly applicable and, unfortunately, there are few other settings in which analytic\nrecursions are available. This motivates the development of numerous alternatives, including the UKF and\nthe EnKF.\nWhile the UKF can provide good performance for moderately nonlinear models, which depends upon\ncareful choice of several algorithmic tuning parameters, and, as the number of sigma points is fixed, there is\nlittle scope for adjusting computational cost or accuracy. The EnKF algorithm takes a different approach; it\ncan be viewed as an approximation to the KF which employs an ensemble of samples {X}\u2081 to approximate\nthe parameters of the Gaussian distribution at time k. In particular, the ensemble's mean and variance are\nused to approximate those of the filtering distribution. The EnKF algorithm then proceeds recursively via the\nprediction and update steps. The prediction step mirrors that of the KF but uses an ensemble approximation,\nwhich means that Fk need not be linear as long as it can be evaluated pointwise as in Algorithm 1 [5, 35]."}, {"title": "2.2 Review of possibility theory", "content": "Possibility theory aims to directly capture epistemic uncertainty about a fixed but unknown element \u03b8* in a\nset \u0398, by focusing on the possibility of an event related to \u03b8* rather than on its probability. A possibility of 1\ncorresponds to the absence of evidence against the event taking place not evidence that the event took place\nalmost surely. If there is no evidence against an event, say E, then there cannot be any evidence against (E\nor E'), with E' any other event, so that the possibility of (E or E') is also equal to 1. This behaviour shows\nthe notion of possibility does not give an additive measure of uncertainty, and the simplest operation that\ncorresponds to the possibility of a union of events is the maximum of their individual possibilities.\nThe analogue of a probability density is a so-called possibility function, f : \u2192 [0,1] which must have\nsupremum 1. Just as probabilities are best described by measures, possibilities are naturally cast as outer\nmeasures, P and just as one may obtain a probability from a density one can obtain a possibility from a\npossibility function by taking its supremum, that is, for any A \u2286 \u04e8, P(A) = supoea f(0). If it holds that\nf(0) = 1 for some \u03b8\u2208 A, then we will indeed have P(A) = P(AUB) = 1 for any B \u2286 \u04e8, as required.\nf(0 | y) = p(y|0) f (0)/supe'\u2208\u04e9 P(y | 0') f (0'), \u03b8\u0395\u0398.\n(2)\nWe borrow from the Bayesian nomenclature and simply refer to f and f(. | y) as the prior and the posterior.\nSince we can always start from the uninformative prior f = 1, it is easy to find posterior possibility functions\nby inserting different likelihoods; for instance, if = R\" and if the likelihood is a multivariate Gaussian\ndistribution with mean 0 and known variance \u03a3, i.e., p(y | \u03b8) = N(y; \u03b8, \u03a3), then\nf(0 | y) = exp(-1/2 (0-y)T \u03a3-1 (0-y)) = N(0; y, \u03a3').\nSuch a Gaussian possibility function is a conjugate prior for the Gaussian likelihood as in the probabilistic\ncase, and shares many of the properties of its probabilistic analogue. It can be advantageous to parameterise\na Gaussian possibility function, say N(\u03b8; \u03bc, \u03a3), by the precision matrix A = \u03a3\u00af\u00b9; indeed, the precision matrix\ndoes not need to be positive definite for the Gaussian possibility function to be well defined, with positive\nsemi-definiteness being sufficient. In particular, this means that setting A to the 0 matrix is possible, with\nthe Gaussian possibility function being equal to 1 in this case. A simple way to quantify the amount of\nepistemic uncertainty in a possibility function is to consider the integral \u222b f(0)de as in [6], when defined.\nThis notion of uncertainty is consistent with the partial order on possibility functions: if g is less informative\nthan f then the integral of g will obviously be larger then that of f. In particular, the uncertainty of a\nGaussian possibility function is \u221a|2\u03c0\u03a3|, with |\u00b7| denoting the determinant; a quantity often used to quantify\nhow informative a given Gaussian distribution is.\nIf and are two uncertain variables, respectively on sets and \u03a8, jointly described by a possibility\nfunction f on \u00d7 \u03a8, then Bayes' rule can also be expressed via a more standard notion of conditioning as\nf(0 | \u03c8) = f(0, \u03c8)/supo' \u2208\u04e9 \u0192 (0', \u03c8),\n[8]\nwhere supere f (\u03b8', \u03c8) is the marginal possibility function describing \u03c8. The conditional possibility function\nf(0 | 4) allows independence to be defined simply: if f(0 | 4) is equal to the marginal f(0) = sup\u03c8' \u03b5\u03c8 f(0, \u03c8')\nfor any \u03b8\u2208 \u0398, then \u03b8 is said to be independent from & under f. As with most concepts in possibility theory,\nthe notion of independence depends on the choice of possibility function; if 0 and are not independent\nunder f, we could find another possibility function g such that g\u2265 f and such that is independent of\nunder g. This will be key later on for simplifying high-dimensional Gaussian possibility functions in a\nprincipled way. When there is no ambiguity about the underlying possibility function, we will simply say\nthat is independent of 4.\nAlthough the parameters \u03bc and \u2211 of the Gaussian possibility functions are reminiscent of the probabilistic\nnotions of expected value and variance, these notions have to be redefined in the context of possibility\ntheory. Asymptotic considerations [20] lead to a notion of expected value E*(\u00b7) based on the mode, that\nis E*(0) = arg max\u0259\u2208\u04e9 f(0), for any uncertain variable e described by f, and to a local notion of variance\nbased on the curvature of f at E* (0), assuming that the latter is a singleton, an assumption that we\nwill make throughout this work. These quantities correspond to the approximation often referred to as\nLaplace/Gaussian approximation, and make sense in the context of epistemic uncertainty: without a notion\nof variability, we simply look at our best guess E* (0) for the unknown 0* and at how confident we are in that\nguess, i.e., how fast the possibility decreases around it. Although the expected value and variance associated\nwith the Gaussian possibility function \u00d1(\u03bc, \u03a3) are indeed \u03bc and \u2211, they will differ in general from their\nprobabilistic counterparts.\nIn order to make inference for dynamical systems simpler, we introduce a Markovian structure as follows:\nWe consider a sequence of uncertain variables x0,x1,... in a set X and assume that ak is described by a\npossibility function fk for some given k \u2265 0. Following the standard approach, we assume that xk+1 is\nconditionally independent of Xk\u22128 given \u00e6k, for any \u03b4 > 0. The available information about xk+1 given a\nvalue Tk of ak can then be modelled by a conditional possibility function fk+1|k(\u00b7 | xk), and prediction can\nbe performed via\nfk+1(xk+1) = sup_fk+1|k(Xk+1 |Xk)fk(Xk), xk+1 \u20ac \u03a7.\nXkEX\nWe will focus in particular on the case where an analogue of (la) holds, that is\nXk = Fk(Xk-1) + \u0438\u043a,\nwith uk an uncertain variable described by N(0, Uk). In this case, the term uk cannot be interpreted as\nnoise and models instead deviations between the model and the true dynamics: the true states x and x-1\nare related via x = F(x-1) with Fk potentially different from Fr; the true value u of interest is therefore\nequal to the difference Fk(x-1) - Fk (x-1) between the model and the true dynamics.\nIn the case where the prediction is deterministic, that is xk+1 = Fk(xk) for some possibly non-linear\nmapping Fk, we can use the change of variable formula [3] to characterise the possibility function fk+1 as\nfk+1(xk+1) = sup {fk(xk) : xk \u2208 FF1(xk+1)},\n(3)\nwhere Fr\u00b9(xk+1) is the (possibly set-valued) pre-image of xk+1 via Fk, and sup\u00d8 = 0 by convention.\nA result that is specific to possibility theory is that the expected values of xk+1 and xk are related via\nE*(xk+1) = Fk (E*(xk)) without assumptions on Fk. This result will be key in our approach since it allows\nto compute the expected value at time step k + 1 with a single application of Fk, rather than averaging\nensembles as in the EnKF. This result does not hold for the mode of probability densities because the\ncorresponding change of variable formula include the Jacobian of the transformation, which shifts the mode\nin non-trivial ways."}, {"title": "3 Possibilistic EnKF", "content": "It is has been shown in [19] that an analogue of the Kalman filter can be derived in the context of possibility\ntheory, and that the corresponding expected value and variance are the same as in the probabilistic case.\nHowever, as with the probabilistic KF, its applicability is limited to linear models so it is natural to develop\nextensions that accommodate nonlinearity. Since the probabilistic EnKF is flexible in computational cost\nand can be effectively applied to nonlinear models, we explore the use of EnKF-like ideas in the possibilistic\nsetting. Here, we present a novel possibilistic EnKF (p-EnKF) and show that analogues of inflation and\nlocalisation arise naturally in the context of possibility theory rather than being imposed as heuristics to\nimprove performance as in the standard setting.\nFor the p-EnKF, we use an ensemble of weighted particles to characterise the possibility function and\nfollow a similar path to the standard EnKF by assuming that the underlying possibility function is Gaussian\nin order to proceed with a KF-like update. For this purpose, we need to define two operations: 1) how to\napproximate a given possibility function by weighted particles? This will be necessary for initialisation at\ntime step k = 0, and 2) how to define a Gaussian possibility function based on weighted particles? This will\nbe necessary to carry out the Kalman-like update. We start by answering the latter question in Section 3.2,\nbefore moving to the former in Section 3.3. Based on this, we detail the prediction and update mechanism\nof the p-EnKF in Sections 3.4 and 3.5 respectively, and consider some extensions in Section 3.6."}, {"title": "3.1 Ensemble approximation", "content": "We consider the problem of defining a set {(wi, xi)}1 of N weighted particles in R\", which will allow the\napproximate solution of optimisation problems of the form maxx\u2208Rn f(x) f(x), for some bounded function\n\u03c6 on R\" and for a given possibility function on R\". Although our approach could be easily formulated\non more general spaces than R\", Euclidean spaces are sufficient for our purpose in this work and help to\nsimplify the presentation. As is common in Monte Carlo approaches, we do not want the particles or weights\nto depend on 4, so as to allow us to solve this problem for many different such functions using a single\nsample, we therefore focus on directly approximating f: placing particles in locations which allow a good\ncharacterization of f allows us to approximate the optimization for a broad class of regular 4. Following the\nprinciples of Monte Carlo optimization [30, Chapter 5], and assuming that f f(x)dx < +\u221e, we can sample\nfrom the probability distribution proportional to f to obtain the particles {x}\u2081 and then weight these\nparticles with w\u2081 = f(xi), for any i \u2208 {1, ..., N}. We then obtain the approximation\nmax \u03c6(x) f(x) \u2248 max Wi\u03c6(xi).\nxERn i\u2208{1,...,N}\nThis approximation can be proved to converge when N \u2192 \u221e under mild regularity conditions on as long\nas the supports of and f are not disjoint. This is a simple default choice for the methods developed below,\nalthough more sophisticated approaches are possible."}, {"title": "3.2 Best-fitting Gaussian possibility function", "content": "We consider the situation in which the epistemic uncertainty is captured by a set {(Wi, xi)}0 of N + 1\nweighted particles in Rn, with wi\u2081 = 1 if and only if i = 0. We denote by f the \u201cempirical\u201d possibility function\ndefined based on the ensemble as f(x) = maxi\u2208{0,...,N} Wi1x\u2081(x), with 1x, the indicator of the point xi. The\nstandard approach would be to simply compute the (weighted) mean and variance of the ensemble, but these\nnotions do not apply directly to possibility functions, and the curvature-based possibilistic notion of variance\nis not defined for an empirical possibility function like f. Instead, we aim to fit a Gaussian possibility function\n\u039d(\u03bc, \u03a3) to this (weighted) ensemble and the considered variance will simply be the second parameter \u2211 of\nthis fitted Gaussian.\nTo fit the Gaussian \u00d1(\u03bc, \u03a3) to the ensemble, we need a notion of best fit. Based on the partial order\nbetween possibility functions described in Section 2.2, we can easily ensure that N(\u03bc, \u03a3) does not introduce\nartificial information at least at locations {x}o - by requiring that \u00d1(\u03bc, \u03a3) \u2265 f. Since f(x) = 0 when\nx # {x}p, we can simplify this condition to: \u00d1(xi;\u03bc, \u03a3) > w\u017c for all i \u2208 {0,...,N}. The inequality\n\u039d(\u03bc, \u03a3) \u2265 f forces the expected values of N(\u03bc, \u03a3) and f to coincide, from which we can deduce that \u03bc = xo.\nFor the variance, we aim to minimise the uncertainty in the possibility function \u00d1(\u03bc, \u03a3), i.e., minimising\n\u222b\u00d1(x; \u03bc, \u03a3)dx \u00d7 \u221a\u03a3, which is equivalent to maximising log |A| with A = \u03a3\u2212\u00b9 the precision matrix, thanks\nto the properties of the determinant. The precision matrix is then most naturally defined as the one solving\nthe constrained optimisation problem\nmax log |\u039b|\nsubject to N(xi; \u03bc, \u03a3) \u2265 Wi, 1 \u2264 i \u2264 N,\n(4)\nwhere S is the cone of positive semi-definite d\u00d7d matrices. Since \u03bc = xo, the corresponding constraint\n\u039d(\u03a7\u03bf; \u03bc, \u03a3) > wo is automatically satisfied and we only need to ensure our Gaussian possibility function\nupper bounds the ensemble at the other xi's. Using the invariance of the trace to cyclic permutations allows\nthese constraints to be rewritten as\n(xi \u2013 \u03bc)\u03a4 \u039b(\u03a7\u03af \u2013 \u03bc) = Tr (C\u00bfA) \u2264 \u22122log wi, 1 \u2264 i \u2264 N,\n(5)\nwhere Ci = (xi \u2212 \u03bc)(xi \u2212 \u03bc)\u0f0b; this is more convenient for numerical optimization because Tr(C\u00bfA) is linear\nin A.\nmin -2 log wi/\u03c3\u00b2 < \u03c4\u03b5{1,...,\u039d} (\u03a7\u03af \u2013 \u03bc)2\u00b7\n(6)"}, {"title": "3.3 Initialisation", "content": "We consider a sequence of uncertain variables x0,x1,..., with k representing the state of the system at time\nstep k. We assume that there is prior knowledge about xo, encoded into a possibility function \u039d(\u03bc\u03bf, \u03a3\u03bf).\nThis possibility function is approximated by an ensemble {(w\u00b2, \u00ee)}\\o of N + 1 weighted particles, defined\nas in Section 3.1. The time index, 0 in this case, is omitted for the weights as these will in fact remain\nconstant throughout the algorithm, which relies exclusively on transports of the associated particles. The\ninitialisation step is detailed in Algorithm 3."}, {"title": "3.4 Prediction step", "content": "In the probabilistic framework, the standard way of obtaining the predictive ensemble at time step k is\nto i) apply the transition model Fk to each particle, and ii) add a realisation of the transition noise. The\nfirst part of this process can be used as is, with some advantageous properties: a key result is the fact\nthat E*(Fk(xk\u22121)) = Fk(E*(xk-1)) with no assumption on either Fk or xk-1. This allows to perform the\nprediction without recomputing the expected value, therefore stabilising the estimation through non-linear\ndynamics. In practice, this means that the particle with index 0 will always correspond to the expected\nvalue, hence its special treatment. In practice, given the ensemble (w\u00b2, -1)}0 at time step k 1, we\ncan simply compute the image x = Fk (1) of each particle to capture the information at time k in the\nabsence of perturbations.\nHowever, the second part of the standard approach is not appropriate in the possibilistic setting since we\naim to model epistemic uncertainty which, in this context, corresponds to deviations between the model and\nthe actual dynamics rather than real perturbations. Deterministic methods can however be adapted and we"}, {"title": "3.5 Update step", "content": "We first need to specify how the observation equation (1b) will be adapted to the considered context. Since\nperturbations in sensors are often stochastic in nature, we continue to model the error in the observation\nwith a random variable, that is\nYk = Hk(xk) + \u025bk,\nwith \u03b5\u03ba ~ N(0, Vk) as before. The mechanism to update the information on ak accordingly is provided by\n(2). In some situations, the main source of uncertainty in the observation will be of an epistemic nature,\nyet, if the corresponding model errors are described by N(0, Vk), then the posterior possibility function will\nbe the same; this follows from the likelihood principle since the two associated likelihoods will only differ by\na multiplicative constant.\nThere are several variants of the probabilistic EnKF update step. Here, we follow the principles of the\nSqrtEnKF as it is well suited to the non-random setting of interest. In fact, we will show that our ensemble\ncan be updated exactly in the same way as in the SqrtEnKF.\nFrom the prediction step, we know that the best fitting Gaussian possibility function for the predicted\nsample is N(\u03bc\u03ba, \u03a3\u03ba). As is standard, we consider the deviations e = x\u00b2 - \u03bc\u03b5 and we verify that the correct\nupdating formulas for the expected value and deviations are\n\u03bc\u03ba =\u03bc\u03ba + Kk(Yk \u2013 Hkpk), and e =e - KkHkek,\nwhere Kk and Kk are as defined in the Kalman filter and SqrtEnKF, respectively. The updated particles\nobtained by adding the posterior expected value and deviations together are\nX = Mk(x) = (In - KkHk)x\u00b2 + (KkHkpk + Kkyk - \u039ak\u0397\u03ba\u03bc\u03ba),\nwhich is a linear transformation of x. Defining \u00e6k as an uncertain variable described by \u00d1(\u03bc\u03ba, \u03a3k) and\nusing Proposition 3, it follows that Mk(k) is described by\nfk = N ((In \u2013 KkHk)\u03bc\u03ba + (KkHkpk + KkYk - KkHkMk), (In \u2013 KkHk) \u03a3k (In \u2013 KkHk))\n= \u039d (\u03bc\u03ba + Kk(yk \u2013 Hkpk), (In \u2212 KkHk)\u03a3\u03ba),\nwhich matches the update mechanism of the KF, as required. The map Mk is therefore moving the particles\nin such a way that the best fitting Gaussian for {(w\u00b2, Mk(x)))} is the posterior of the KF with \u00d1(\u03bc\u03ba, \u03a3k) as\na predicted possibility function. Thus, the update step of the p-EnKF is formally the same as that of the\nstandard SqrtEnKF, as detailed in Algorithm 2, albeit with a difference in interpretation."}, {"title": "3.6 Extensions", "content": "We finish this section by collecting together some extensions to the p-EnKF, demonstrating its applicability\nin the context of nonlinear measurement models and providing a number of ways to improve computational\nefficiency."}, {"title": "3.6.1 Nonlinear observation models", "content": "In the previous section, we have detailed the p-EnKF with a linear observation model. We now establish\nthat, similarly to the EnKF [14, 33], the p-EnKF could be adapted to nonlinear observation models. There\nare, in fact, two main approaches to dealing with nonlinearity in the observation model, which we consider\nin turn.\nModel linearisation The simplest way to handle a nonlinear observation model is to linearise it, i.e., to\nTaylor expand the observation model around the predictive expected value at time k as Hk (xk) \u2248 Hk(\u03bc\u03ba) +\nJHk (\u03bc\u03ba)(Xk \u2013 \u03bc\u03ba), with JHk(\u03bc\u03ba) the Jacobian matrix of Hk at \u03bc\u03ba. Then, a new observation model can\nbe defined based on the observation matrix JH\u2081(\u00b5k) and on a non-zero mean Hk(\u00b5k) \u2013 JHk(\u03bc\u03ba)\u03bc\u03ba for\nthe observation noise \u03b5\u03ba. After that, we can follow Algorithm 2 for the update, except that the term\n\u0423\u043a\nHkuk is replaced by yk + JHk(\u03bc\u03ba)\u03bc\u03ba in step 4. Since linearisation does not depend on the chosen\nrepresentation of uncertainty, it is equally applicable to the p-EnKF as it is to standard versions of the\nEnKF. The linearisation method can usually be improved by replacing the term Hk\u03a3\u0397 by the predictive\nvariance of the observation based on the ensemble [33], which is also applicable to the p-EnKF. The term\n\u03a3\u03ba\u0397 can usually also be replaced by a ensemble-based approximation, yet, this is not straightforward in the\np-EnKF since the precision matrix does not have the same properties as the covariance matrix: to compute\nthe covariance matrix Ex, H(x) between the uncertain variables x and Hk(x), one must first compute the\nprecision matrix for (x, Hk(x)), invert it, and then extract the block corresponding to \u03a3\u03b1,\u0397(x). Such an\nextension of the state is however usual, as described next.\nExtending the state space Another way to deal with a nonlinear observation model is by extend-\ning/augmenting the original state with a the corresponding predicted observation, which is then observed\nlinearly. In this case, the state becomes zk = (xk, Hk(xk)) and the extended observation matrix is\nHk = [0mxn Im], with Omxn the 0 matrix of size m \u00d7 n. Algorithm 2 can be used as usual once a\nGaussian is fitted to this extended state. The posterior ensemble can then be extracted by choosing the first\nn elements of the extended state for every particle. Care must be taken in practice as the precision matrix of\nthe extended state can be close to singularity due to a strong correlation between the elements. For instance,\nif one of the components of the state that is observed independently becomes sufficiently well estimated at\na given time step, then it might be that the nonlinear observation function is approximately linear from\nthe viewpoint of the ensemble. Yet, this corresponds to cases where linearisation would be appropriate. It\ntherefore appears that a hybrid technique would be the most suitable, with components of the observations\nbeing either linearised or included in the state depending on their observed degree of nonlinearity."}, {"title": "3.6.2 Techniques to improve computational efficiency", "content": "As with any ensemble-based technique, the accuracy of the p-EnKF depends on ensemble size. As it is\ntypically of interest to use small ensembles for computational reasons, it can be challenging to represent\nthe state of interest adequately. An important aspect is that the p-EnKF requires a minimum sample size\nequal to the state's dimension plus one due to the computation of the variance; a sample size matching\nthe dimension plus one is sufficient to ensure that the resulting covariance matrix is of full rank providing\nonly that the collection of displacements from the expected value to each of the sample points are linearly\nindependent whereas a smaller sample will lead to a rank-deficient covariance matrix. That a sample size\nequal to the dimension plus one suffices follows from the fact that a quadratic form bounded away from zero\nat a number of points separated from the centroid by linearly-independent vectors cannot vanish anywhere.\nConditional Independence For the p-EnKF, variance is computed via an optimisation problem. Thus,\nthe number of variables in the precision matrix of the state x \u2208 Rn will be n(n + 1)/2. However, for many\nproblems, there is a natural structure in the state variable, such as a conditional-independence structure,\nwhich can be exploited to reduce this number. Indeed, for sparsely dependent models, it is straightforward\nto reduce the number of nonzero variables in the precision matrix A using conditional independence as\nfollows: The off-diagonal elements Aij that i \u2260 j are set to 0 if the variable x, and xj are to be modelled as\nconditionally independent. By setting some of the off-diagonal elements in the precision matrix to 0 during\nthe computation of this matrix by optimisation, the other terms in the precision matrix will automatically\nadjust to these constraints, offering a systemic way to perform inflation that is tailored to the strength of\nthe dependence being assumed away. However, exploiting this structure to gain in computational efficiency\nwould require optimisation algorithms that are specifically tailored to sparse/band diagonal positive-definite\nmatrices. The design of such algorithms is left for future work.\nNodal Numbering Scheme Apart from reducing the number of variables, the calculation and storage\ncan be done more efficiently by reordering the variables to minimise the bandwidth of nonzero entries in\nthe covariance matrix. One of the methods to achieve that is proposed in the literature is called the nodal\nnumbering scheme [7]. This method uses the graph to reorder the state's element so that the nonzero elements\nwill be close to the diagonal element. Moreover, the nodal numbering scheme ensures that the permuted\nmatrix will have a bandwidth no greater than the original matrix, making the computation involved with\nthe precision matrix more efficient, see [7] and [25] for more details."}, {"title": "4 Numerical Experiments", "content": "Here we show the performance of the p-EnKF using simulated data from two different models: a simple\nlinear model and a modified Lorenz 96 model.\nData Generation One convenient feature of standard probabilistic modelling is that simulation can be\nperformed exactly according to the model: the variability of scenarios, necessary for a thorough performance\nassessment, can be obtained directly by sampling from the assumed probability distributions. This is no\nlonger the case with possibility theory since embracing epistemic uncertainty means that sampling is no\nlonger a natural operation. The ideal solution would be to obtain a sufficiently large collection of real\ndatasets for which the ground truth is known, this is however not generally achievable for problems like data\nassimilation. Instead, we generate our simulated scenarios by sampling from the probability distributions\nassumed by the probabilistic baselines and align our possibilistic model with these."}, {"title": "4.1 Linear model", "content": "We first consider a linear model since the performance can be clearly compared with the optimal filter, which\ncan be computed in this instance via the KF. A simple linear model is considered so as to generalise easily\nto arbitrary dimensions. In particular, we consider that the i-th component at time k, i \u2208 {2, ..., n}, only\ndepends on the i-th and (i-1)-th components at time k\u22121. This means that conditional independence can be\nimposed to reduce the computational cost of obtaining the precision matrix with a limited information loss.\nThe model can be written as a state-space model (1), for k\u2208 {1, ..., 100}, with the following components:\n1. The initial state Xo is sampled from N(On, 10In).\n2. The dynamic model is linear: Fk(Xk\u22121) = FkXk-1 with\n\u300c10\n01 \u03bb\n01\n0\nFk = ... 0 0 1\n0\n: : :\n000\n1\n\u300d,\nwhere \u5165 0.1 and the covariance matrix of the dynamical noise ek is Uk = 0.01In.\n3. The observation model is also linear, Hk(Xk) = HkXk, with Hk = [Im 0m\u00d7(n-m)] and the covariance\nmatrix of the observation noise \u025bk is Vk = 0.1Im.\nBased on all the shared properties between the Gaussian possibility function and the Gaussian distribu-\ntion, the best way to align our possibilistic model with the assumed probabilistic one is to simply keep the\nexpected value and variance parameters in our possibility functions. In particular, we assume that the initial\nstate x is described by the Gaussian possibility function N(0n, 10In) and that the errors in the dynamical\nmodel are described by N(0n, Uk).\nThe parameters of the considered methods are as follows: Unless otherwise stated, the parameter N is\nset to twice the state's dimension, i.e., N 2n. For a given value of N, the actual number of samples for\nall methods is N + 1. The parameters of the UKF chosen in this paper are given by a = 0.25, \u043a = 130, \u03bb =\na\u00b2(n + \u043a) \u2013 n and \u1e9e = 2."}, {"title": "4.1.1 Performance assessment for various sample sizes and dimensions", "content": "Since the p-EnKF is an ensemble-based method, it is natural for us to investigate the performance based\non different sample sizes and dimensions first. Figure 2 shows the performance of the p-EnKF with no\nlocalisation when the state is fully observed (n = m), comparing it to the SqrtEnKF and the UKF. The\nperformance is measured in terms of average RMSE over 1000 realisations, except for n = 64 where we only\nconsider 50 realisations due to a large computational time (more than 30 minutes per run). We"}]}