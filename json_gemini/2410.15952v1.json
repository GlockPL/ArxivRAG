{"title": "User-centric evaluation of explainability of AI with and for humans: a\ncomprehensive empirical study", "authors": ["Szymon Bobek", "Paloma Koryci\u0144ska", "Monika Krakowska", "Maciej Mozolewski", "Dorota Rak", "Magdalena Zych", "Magdalena W\u00f3jcik", "Grzegorz J. Nalepa"], "abstract": "This study is located in the Human-Centered Artificial Intelligence (HCAI) and focuses on the results of a user-centered\nassessment of commonly used eXplainable Artificial Intelligence (XAI) algorithms, specifically investigating how humans un-\nderstand and interact with the explanations provided by these algorithms. To achieve this, we employed a multi-disciplinary\napproach that included state-of-the-art research methods from social sciences to measure the comprehensibility of explanations\ngenerated by a state-of-the-art lachine learning model, specifically the Gradient Boosting Classifier (XGBClassifier). We con-\nducted an extensive empirical user study involving interviews with 39 participants from three different groups, each with varying\nexpertise in data science, data visualization, and domain-specific knowledge related to the dataset used for training the machine\nlearning model. Participants were asked a series of questions to assess their understanding of the model's explanations. To ensure\nreplicability, we built the model using a publicly available dataset from the UC Irvine Machine Learning Repository, focusing on\nedible and non-edible mushrooms. Our findings reveal limitations in existing XAI methods and confirm the need for new design\nprinciples and evaluation techniques that address the specific information needs and user perspectives of different classes of AI\nstakeholders. We believe that the results of our research and the cross-disciplinary methodology we developed can be successfully\nadapted to various data types and user profiles, thus promoting dialogue and address opportunities in HCAI research. To support\nthis, we are making the data resulting from our study publicly available.", "sections": [{"title": "1 Introduction", "content": "Human-Centered Artificial Intelligence (HCAI) is a new multi- and cross-disciplinary field of AI that shifts the focus from purely\nengineering intelligent systems to developing and applying AI technologies aimed at broadly enhancing human capabilities. On\nthe other hand these new design principles should be inline with the methods of Explainable Artificial Intelligence (XAI) thus\nensuring that intelligent systems are transparent, equitable, trustworthy, meeting human needs, values, and finally, remain under\nhuman control. HCAI approaches aim at involving a possibly broad scope of stakeholders, including researchers, developers,\npolicymakers, and end-users. This assures consideration of multiple perspectives in the creation, design and implementation of\nAl systems, and also includes comprehensive assessment of multifaceted impacts from a user-centric viewpoint.\nAs explanations are crucial for HCAI, Explainable Artificial Intelligence (XAI) has been one of the most extensively de-\nveloped and researched areas of AI. It has originally emerged after the Defense Advanced Research Projects Agency (DARPA)\nreleased a challenge [1], which constituted the requirements for every automated decision-making algorithm to allow human\nunderstanding of its operations. Shortly after the DARPA challenge, the European Union (EU) has made explainability a require-\nment for all Al systems through such regulations as GDPR [2], or the more recent EU AI ACT [3]. One of the major postulates of\nthese initiatives was to \"Enable human users to understand, appropriately trust, and effectively manage the emerging generation\nof artificially intelligent partners\" [1].\nTherefore, one of the main challenges in achieving adequate measure of success of explanations is to include the subjective\nperspective of the main beneficiary of this act, who is the explanation addressee \u2013 the human. Even technically correct expla-\nnation, with high values of all available quality criteria, will be not useful in case when it is not comprehended by the user or\nstakeholder they are designed for. In fact, one of the fundamental pitfalls of the current XAI techniques is that they are designed\nfrom a perspective of data scientists who are creators of the subjects they try to explain. This creates a bias that can influence the\nfinal form and quality of explanations."}, {"title": "2 Results", "content": "The study focused on evaluating comprehensibility of explanations generated by XAI algorithms for a ML model for mushroom\nclassification to distinguish edible and poisonous ones. The selection of the dataset followed two requirements we formulated: 1)\nan access to experts in the dataset domain, 2) research reproducibility. To this goal we decided to use a dataset originating from\nthe UC Irvine Machine Learning Repository\u00b2. The ability to differentiate between edible and poisonous mushrooms which are\ntraditionally and culturally harvested in large quantities for food and commercial purposes in Poland, was deliberately selected as\nthe domain. Not only this is a well understood domain by a larger audience, but also, using our research and community channels\nwe had access to high quality experts in mycology.\nUsing the selected dataset we trained a Gradient Boosting Classifier (XGBoost) model achieving an accuracy rate of 99.97\nFor this model we generated explanations with some most commonly used XAI algorithms and shown to the participants of\nthe study. To cover the largest possible spectrum of the XAI methods and not overwhelm participants with their variety, we se-\nlected following representative types of explanations: 1) statistical descriptions and visualization of data, such as table presenting\ndescriptive statistics (mean, median, standard deviation, quartiles), information on missing data for each variable and plots illus-\ntrating frequencies of various features 2) feature importance attribution-based explanations such as SHAP and LIME [14, 15],\n3) rule-based explanations such as Anchor [16], and finally 4) counterfactual explanations such as DICE [17]. Additionally both"}, {"title": "2.1 Thematic analysis with think-aloud protocol", "content": "The results of thematic analysis should be interpreted in the context of a double metacognitive filter, as is standard practice in\nqualitative research [21, 22, 23]. Furthermore, the intensity of this relevance can be indicated by aggregating and comparing\nthe co-occurrence of codes in segments (units of thematic analysis) within individual observations (within the analysis of the\nempirical material produced during the study of a given user). The first metacognitive filter, which was included in the study,\npertains to the verbalisation of thoughts constructed by the user. In contrast, the second metacognitive filter, which was also\nincluded in the study, refers to the coding of empirical material by the researcher. In the context of the application of this dual"}, {"title": "2.2 Reception of the presentation of XAI algorithms", "content": "The findings discussed in this section derive from a comprehensive synthesis of the thematic analysis, the review of modified\npresentations, and the Kano and UX questionnaires [24, 25]. Based on the results of the thematic analysis, the majority of\nrecommendations for the preparation of supplementary materials were related to box plots and histograms, in the context of\nunderstanding of annotations, legends and feature significance, among others. Conversely, requests for changes of visualisation\nscheme were mainly related to descriptive statistics and bee swarm plot. The study revealed students' preferences regarding the\nconstruction of visual narratives and improving the reception of presentations by the audience."}, {"title": "3 Discussion", "content": "Referring to the research hypothesis we formulated at the beginning, we can observe that explanations generated by XAI algo-\nrithms being treated as a heuristic aid helped users to get cognitive access to the content generated by the AI model.\nHowever, the evidence we have collected via our multidisciplinary and mixed method research revealed that for students\nwho declare little knowledge of macrofungi (low self-assessed level of macrofungi literacy), generated explanations proved to\nprovide sole, yet insufficient access to AI model's output. On the contrary, for mycologists and mycophiles, explanations refer\ndirectly to the primary dataset and are used as a handy tool for assessing its quality comprehended as the adequacy of data with\nbotanic reality of macrofungi. Moreover, in the group, there were students who express a high level of trust towards AI, even\ndeclaring abandonment of their own proclaimed extensive knowledge of mushrooms in favour of AI, or are uncertain about the\noutcomes and effectiveness of AI. Within this group, there were students who express a high level of confidence in the accuracy\nof the dataset. Some participants in this group express a priori belief that it was compiled with consultation from competent\nexperts in the field. There were even those who assumed that the data were artificially generated by ChatGPT and thus may not\nnecessarily be true. This statement should be tempered by possible cognitive and hierarchical biases (the study was notoriously\nconducted by teachers on students). Mycologist and mycophiles manifest a purely pragmatic and utilitarian approach to the\nprovided explanation as well as to the AI model itself and, consequently, they are, in the first place, prone to assess the dataset\nquality, and point out its shortcomings.\nDeeper analysis of the results revealed that for students, the explanations generated by XAI algoritms were insufficient,\nbecause strictly limited to superficial visual level of explanations. The presented infographics did not allow them to reach\nbeyond to the primary dataset and seek coherence between displayed data and botanic reality. With this caveat in mind, the\nresearch with illiterate students delivered nevertheless a plethora of practical tips for further improving visual and textual XA\u0399\nexplanations. These students' suggestions, both explicit and implicit, concerned indeed every single aspect of visual aesthetics\nand textual content of XAI explanations as well as of the research tool in the form of slideshow presentation used to guide the TAP\nprocedure and dataset quality. Despite the lack of mushroom expertise, some students, although few in number, made an effort\nto evaluate the credibility of the dataset on which the ML model was trained, as well as the safety of using the clues embedded\nin the explanations for real macrofungi recognition. This cognitive attitude should be retained as an indicator of high intellectual\nmaturity and high information literacy level. Interestingly enough, the overall level of skills in reading infographics had no\nsignificant incidence on the results of interpreting XAI explanations, Insofar as, for students (with rare exceptions), explanations\nmainly refer to themselves, we may postulate that, for macrofungi illiterate recipients, infographics generated by the given AI\nmodel are confined to an autotelic function.\nFor the group of domain experts participants, explanation and its informative potential are secondary and subaltern to the\ncompleteness and botanic relevance of the dataset on which the AI model has operated. When they detect a discrepancy between\nthe content of an infographic and their mycological know-how, they simply abandon any further evaluation of the infographic\nitself, For mycologists and mycophiles, explanations have a proper mediation function, in the sense that they are perceived as a\ngateway giving insight to the dataset and AI model's operation rules; the autotelic aspect of explanation is absent.\nWe approached the analysis of comprehensibility of XAI output by adapting the semiotic triangle that originally was proposed\nas a model that explains how linguistic symbols relate to the objects they represent. This account, originally conceived by C.\nS. Peirce, provides a valuable framework for understanding signs and their meanings through the triadic relationship of the\nfollowing components: symbols (representamens), objects and interpretants as depicted in Fig. 3. In this work, we adapt this\napproach to XAI area to investigate the interplay between model outputs, input data, and human understanding [26].\nIn the context of explanations provided by XAI methods, the symbol represents the model output or the prediction made by\nan Al system. It could be a classification label, a regression value, or any other form of output generated by the model. The\nsymbol (representamen) is the observable result produced by the AI system, which may be correct or incorrect. The object from\nthe perspective of XAI corresponds to the real-world phenomenon or the data instance that the AI system is supposed to predict.\nIt could be an image, a text document, a medical diagnosis, or any other input data. The object is what the AI system aims\nto represent or interpret through its predictions. The interpretant refers to the meaning or understanding that arises from the\ninteraction between the symbol and the object. In XAI, this involves human interpretation, i.e. how users (such as data scientists,\ndomain experts, or end-users) understand and make sense of the model's output and explanation methods, i.e. techniques that\ngenerate explanations to bridge the gap between the sign (model output) and the object (input data).\nThis fundamental framework was used by us to analyze and conclude results of our study. With regard to the XAI techniques\nunder examination, we define comprehensibility as the property that enables users to complete a full semiotic circle, moving back\nand forth between the following three stages: (1) perceiving and deciphering a symbol (explicit XAI content), (2) identifying\nthe chain of objects underlying this symbol (ML algorithm operation mode <= input data <= specimens of macrofungi), and (3)\nembracing and integrating both of the later into a mental representation Accordingly, comprehensibility is impaired when at least\none of these steps is not completed by the user.\nFollowing the basic concept of Peirce's semiotic triangle introduced above, we can conclude that the semiotic triangle is\nincomplete for all of the participants groups. Mycologists and mycophiles bypassed the interpretant and, by a semiotic shortcut,\nused the representamen to reach directly to the object/referent, i.e. real macrofungi taxonomy. They skip the interpretant and,\nsubsequently, do not even try to reach comprehension of how the AI model engendered the displayed results.\nStudent, regardless of the visual reading skills, were stuck in the relation between representamen and interpretant, failing to\nobtain both full understanding of the AI model operating mode and the congruency between the dataset and biological evidence"}, {"title": "4 Methods", "content": "4.1 Dataset, AI model and XAI algorithms\nThe dataset we used comprises data on 61,069 specimens from 173 mushroom species, categorized as edible or inedible/poi-\nsonous. Specimens with unknown edibility were classified as inedible/poisonous. The dataset exclusively contains cap-and-stalk\nmushrooms with gill hymenophores. It includes both real observations and hypothetical data, the latter being artificially generated\nfrom a smaller set of real-world mushroom observations.\nRegarding class distribution, 33,888 instances are inedible or poisonous, and 27,181 are edible, making the dataset fairly\nbalanced with approximately 55.49 This balance is essential for accurate model training and performance evaluation, avoiding\nbiases towards the majority class.\nThe ML model which was later elucidated to the study participants is the Gradient Boosting Classifier (XGBClassifier). To\nhandle categorical variables, a one-hot encoder was used, and missing data were addressed through imputation. Additionally,\nnumerical variables were scaled to ensure uniformity in data handling. This preprocessing involved imputing missing values\nin numeric features with the median and scaling these features, while categorical variables were imputed with a placeholder\nvalue '_NA_'. This resulted in the model operating on 82 features derived from the original 20 input variables. Renowned for\nits efficiency in classification tasks, the model exhibited an accuracy rate of 99.97 Study participants were informed about the\nmodel's limitations, emphasizing that while the model is data-driven and highly accurate, it does not encompass all possible\nfactors affecting mushroom edibility and thus should be used as a supportive tool rather than a sole determinant in the identifi-"}, {"title": "4.2 Participants", "content": "The participants selected for the interviews were recruited based on the initial survey. The survey comprised 18 questions, 12\nof which pertained directly to self-assessing knowledge and skills in mushrooming and data visualisation, as well as acquiring\ninformation about their origin and experience. The survey included a question about the field of study to ensure appropriate\nrepresentation of students pursuing humanities, social sciences, and computer science. Five questions in the questionnaire directly\nrelated to giving consent for data use and participation in further research, as well as confirming familiarity with the GDPR\nclause. The questionnaire aimed to gather information and assess the knowledge, qualifications, experience, and competences\nof the participants. It consisted of six open-ended questions and six closed questions. The latter included an 'other' option,\nallowing participants to provide their own answer. In total 143 respondents completed the questionnaire, including 79 students\nwho provided consent for further participation in the study. Three respondents did not receive invitations as they did not meet the\nqualification criteria due to being from different academic disciplines, possessing varying levels of education, etc.\nThe experimental group was formed of different types of participants. From the perspective of expertise in the domain\nof macrofungi, we could distinguish two groups: 1) mycologists and mycophiles (called hereafter \u201cdomain experts\") and 2)\nnon-specialists in mycology. Both groups exhibited various levels of literacy in data analysis.\nThe group of domain experts included: a couple of entrepreneurs owing a laboratory-based medicinal and exotic macro-\nfungi mycelium production plant (offering mother cultures on Petri dish, mother spawn on grain or sawdust, plug spawns and\ngrowkits), one academic scholar in chemistry, specialized in mycology, one doctoral student in mycology, two professional cer-\ntified phytologists-mycologists involved in natural sciences education and macrofungi knowledge vulgarisation, four amateur\nmycologists, among whom one doctoral student in medical science, co-administering or moderating two of the most influen-\ntial and well-reputed social media groups devoted to macrofungi identification, two amateur mycophiles holding, each of them,\na popular fungal thematic channel on general-public webstreaming platforms, ans one amateur mycologist collaborating with\nacademic mycologists in identifying and describing new fungal taxa (preparation of dried specimens for scholars). The ma-\njority of respondents are also certified macrofungi identifiers accredited by competent Polish Regional Office of Sanitary and\nEpidemiological Vigilance (SANEPID). This group brings together representatives of various professions with unequal levels of\ninfographic reading competences.\nThe group of non-specialists in mycology included students from Jagiellonian University representing various fields of sci-\nence, social sciences, humanities, and computer science, with varying levels of information literacy skills, including different\nabilities in reading infographics. Students participating in the study also reported various levels of knowledge about macrofungi\nand experiences in their identification and assessment of edibility, ranging from decidedly low, low, moderate, to high. Despite\ndeclarations of very high competencies in fungal knowledge, as well as communicated extensive experience in identifying ed-\nible, inedible, and poisonous mushrooms, we assumed that none of the recruited students possessed certified competencies in\nrecognizing macrofungi and assessing their edibility."}, {"title": "4.3 Research tools", "content": "To carry out the user study, we developed the following research tools: (1) an online survey questionnaire through which we\ncollected, among other things: basic information about our users, especially about their experience in data analysis and visual-\nization, as well as their domain knowledge about mushrooms, which was connected with the dataset we chose; (2) a presentation,\nwith slides showing selected XAI techniques, to which we asked respondents questions and which respondents modified in terms\nof their subjective assessment of the usefulness of the individual slides and their components (similar to the well-known UX card\nsorting technique); (3) a set of questions and tasks used during the TAP; (4) a study scenario and other supporting materials,\nincluding an audio file with a recording of a sample verbalisation in the TAP and a test presentation to explain the procedure to\nrespondents; (5) a simple UX questionnaire with which users could determine on a five-point scale their overall feelings related\nto the use of the viewed explanations in terms of their level of difficulty, aesthetic, comprehensibility and stimulation of the\nuser's attention. Additionally, users were asked to indicate data visualizations that were easier and more difficult than those seen\nduring the study, which was inspired by the Kano technique derived from market research aimed at showing the tested product\nin relation to selected aspects often by comparing it to other, similar ones; (6) consent forms and information for respondents."}, {"title": "4.3.1 Think-aloud protocol (TAP)", "content": "Think-aloud protocol (TAP) is a data collection technique that has its roots in psychology and is based on the verbalisation of the\nsubject's thoughts, feelings and impressions [27]. This technique allows us to capture both the pragmatic values of UX (such as\nusability and functionality) as well as the subjective emotional and aesthetic impressions that accompany the user's interaction\nwith an information product [28], e.g. a website, a database or, in our case, a presentation with XAI techniques. TAP has three\nvariants: concurrent (verbalisation occurs at the same time as the activity under investigation), retrospective (verbalisation occurs\nonly after the activity has taken place, for example in the form of commenting on a recording of an activity previously performed\nby the participant) and constructive interaction (another name: co-discovery learning) based on a conversation between two\npeople [29, 30]. In the study of XAI techniques, we used a concurrent variant of TAP, which does not overload the participants'\nmemory mechanism and does not further prolong the study procedure.\nIn general, the advantages of TAP include: its versatility (it is suitable for examining different elements of UX, can be used\nat different phases in the product development cycle, and can be applied in a quantitative, qualitative and mixed approach),\nmobility (TAP typically does not require specialised equipment, so it can be used in a variety of environmental conditions that\nare compatible with the scenario and purpose of the study in question), and low cost (which results from not needing specialised\ntechnical equipment or software). In addition, properly conducted TAP provides information on the actual impressions of users,\nthus providing convincing data. With the right attitude on the part of the researcher (i.e. controlling his or her own behaviour so\nas not to impose his or her own opinions on the respondents and creating an atmosphere that encourages verbalisation), it is also\na technique that is easy to use and learn."}, {"title": "4.3.2 Thematic analysis in MAXQDA", "content": "In the conducted study, based on a qualitative methodology employing a think-aloud protocol, a thematic content analysis was\nalso employed utilising inductive forms of reflexive analysis [31, 32]. In the conducted study, based on a qualitative method-\nology employing a think-aloud protocol, a thematic content analysis was also employed utilising inductive forms of reflexive\nanalysis [31, 32].\nThe thematic analysis comprised stages such as: a) an exploratory phase, involving data reconnaissance and familiarization, b)\ninductive, independent generation of codes by two individuals, followed by c) possible deductive referencing to the main research\ngoals of evaluation of explanations and recommendations, as well as potential theoretical references to quality information\nassessment criteria and their connections to XAI evaluation metrics (footnote), then d) creation and verification of themes,\nduring which the first and subsequent codebooks were developed, and e) results compilation [31]. A comprehensive list of codes\nused for thematic analysis was provided in the form of a codebook in the supplementary materials."}, {"title": "4.3.3 Analysis of the user experience", "content": "The analysis of user experience was conducted by us with two independent approaches: 1) through analysis of the modifications\nthat the users requested for the visualizations of XAI output, 2) through UX questionnaire and questions inspired by Kano\napproach.\nThe analysis of modifications proposed by non-domain experts in the baseline presentation was based on a model of data\npresentation, combining data visualization and data storytelling [33]. While both approaches serve to communicate data, they\ndiffer in their objectives. Data visualization primarily focuses on enhancing data perception, whereas data storytelling aims to\ntransform data perception into data cognition by incorporating narrative elements [33].\nThe study of modification of visualization was complemented by the UX questionnaire which is a popular technique for\ncollecting information about a user's overall experience using the tested system, long described in the subject literature on UX\nresearch [25] and vigorously developed in relation to various situations and user groups [34, 35]."}, {"title": "5 Data availability", "content": "Additional data, such as summary of MAXQDA analysis and presentation slides that the participants were interacting with\nthat we were referring throughout the text were provided in supplementary materials. The source code used to reproduce the\nML model and explanations is available in GitHub repository. Finally, we have prepared the whole dataset resulting from the\nexperiment to be publicly available in the Zenodo platform [36]."}]}