{"title": "Generalizable Sensor-Based Activity Recognition via Categorical Concept\nInvariant Learning", "authors": ["Di Xiong", "Shuoyuan Wang", "Lei Zhang", "Wenbo Huang", "Chaolei Han"], "abstract": "Human Activity Recognition (HAR) aims to recognize activ-\nities by training models on massive sensor data. In real-world\ndeployment, a crucial aspect of HAR that has been largely\noverlooked is that the test sets may have different distribu-\ntions from training sets due to inter-subject variability in-\ncluding age, gender, behavioral habits, etc., which leads to\npoor generalization performance. One promising solution is\nto learn domain-invariant representations to enable a model to\ngeneralize on an unseen distribution. However, most existing\nmethods only consider the feature-invariance of the penulti-\nmate layer for domain-invariant learning, which leads to sub-\noptimal results. In this paper, we propose a Categorical Con-\ncept Invariant Learning (CCIL) framework for generalizable\nactivity recognition, which introduces a concept matrix to\nregularize the model in the training stage by simultaneously\nconcentrating on feature-invariance and logit-invariance. Our\nkey idea is that the concept matrix for samples belonging\nto the same activity category should be similar. Extensive\nexperiments on four public HAR benchmarks demonstrate\nthat our CCIL substantially outperforms the state-of-the-art\napproaches under cross-person, cross-dataset, cross-position,\nand one-person-to-another settings.", "sections": [{"title": "Introduction", "content": "Sensor-based human activity recognition (HAR) aims to\ntrain models using massive data collected from wearable\nsensors such as accelerometers and magnetometers. HAR\nhas wide applications in many areas, including personal fit-\nness, elderly-care, human-machine interaction, sports track-\ning, etc (Huang et al. 2022). Despite significant progress,\ncurrent HAR study still faces critical challenges that pre-\nvent practical deployment while rendering the performance\nsuboptimal on never-seen-before data (Qian, Pan, and Miao\n2021). As shown in Figure 1, the distribution of sensor sig-\nnals is typically influenced by various factors such as age,\ngender, and deployment locations. For instance, due to inter-\nsubject variability, a model that recognizes the activities of\nan adult does not generalize well on new unseen data from\nan elderly person, because they may have different behav-\nioral patterns that make their data distributions highly di-\nverse. Therefore, simply generalizing a model trained on ex-\nisting data to new unseen data may not work due to such dis-\ntribution shift problem in sensor signals.\nIn practice, the real-world sensor samples are typically\nrestricted to access during training. Taking elderly fall de-\ntection as an example, it is rather unrealistic to aggregate\ntraining data from the elderly people based on safety con-\ncerns. However, it is feasible to collect training data from\nyoung subjects while ensuring enough safe conditions. We\nhave to expect a model trained on the data collected from\nyoung subjects to be readily extensible to elderly users with\nno need of training data collected from them. To mitigate\nthis issue, DG has been a popular technique to reduce the\ndistribution discrepancy between the source and target do-\nmains with no need of direct access to never-seen-before\ntarget data during training. Though many research efforts\nhave been devoted to computer vision applications, they may\nbe incompatible with time series data. Until now, there has\nbeen limited research attention targeted at wearable sensor\ndata including feature disentanglement (Qian, Pan, and Miao\n2021), data augmentation (Zhang et al. 2018), gradient op-\neration (Huang et al. 2020), and domain-invariant represen-\ntation learning (Lu et al. 2024; Du et al. 2021), which fo-\ncus on explicitly or implicitly regularizing the models based\non the analysis of features. Despite notable achievements in\nDG, it still remains a major challenge that is far from being\nsolved on sensor data. A recent study (Gulrajani and Lopez-\nPaz 2021) have empirically shown that most current state-of-\nthe-art approaches are even inferior to the baseline empirical\nrisk minimization (ERM) algorithm. These findings clearly"}, {"title": "Related Work", "content": "Human activity recognition (HAR) mainly attempts to rec-\nognize activities of daily living that are performed by differ-ent persons. Based on data type, it can be roughly grouped\ninto two categories: vision-based HAR and sensor-based\nHAR (Dang et al. 2020): The former collects activity data\nby cameras or other optical devices, which would often en-\ncounter severe privacy leaking problems (Sun et al. 2022).\nFor example, sensitive personal data like facial information\nwill be accidentally released on cameras. Moreover, cam-\neras may not work in HAR when a person is beyond their\ncoverage range (Kong and Fu 2022); The latter collects ac-\ntivity data through ambient sensors deployed in smart en-\nvironment or wearable sensors attached to different body\nparts (Gu et al. 2021). Due to small size and low price, there\nhas been the wide popularity of inertial sensors embedded in\nwearable devices like smart phones and watches, that makes\nthem convenient and practical to record activity data for of-\nfering smart user services (Chen et al. 2021). In contrast to\nvideo-based action recognition, there is relative limited re-\nsearch attention on HAR using wearable sensor data. Thus,\nthis paper mainly concentrates on wearable sensor-based\nHAR problem. To resolve sensor-based HAR, deep learning\nmodels have recently been widely applied to automatically\nextract features from raw sensor signals for activity recogni-\ntion (Qian, Pan, and Miao 2021; Hammerla, Halloran, and\nPl\u00f6tz 2016; Qian et al. 2019; Wang et al. 2024). Despite\nremarkable progress, these activity recognition models are\ntypically trained based on the assumption that the training\nand testing data have independently identical distributions,\nignoring the fact the sensor data collected from different per-\nsons may follow different distributions due to their unique\ncharacteristics in body shapes, behavior patterns, or other\nbiological factors.\nTo address distribution-shift problem, domain adaptation\n(DA) has offered a popular solution to bridge domain gaps\n(Kouw and Loog 2019; Wang et al. 2018; Yu and Lin 2023).\nHowever, DA has a notable limitation in that it more or less\nrequires to access target domain data during training, which\nrenders DA infeasible in many real-world HAR situations\n(Qian, Pan, and Miao 2021). Moreover, while there are mul-\ntiple target domains, the model has to be re-trained on every\ntarget domain (Lu et al. 2021), which is time-consuming and\ninefficient. DG has been recently proposed to handle such\nchallenging situations (Wang et al. 2018). It aims to learn\na robust and generalizable model from one or more differ-\nent but related source domains, that can perform well on the\nnever-seen-before target domains. In computer vision com-\nmunity, existing DG-related literatures may be coarsely cat-\negorized into three research streams (Zhou et al. 2022; Wang\net al. 2022): Learning strategy (Huang et al. 2020; Sagawa\net al. 2019), Data manipulation (Zhang et al. 2018; Zhou\net al. 2021), Representation learning (Parascandolo et al.\n2020; Du et al. 2021; Qian, Pan, and Miao 2021; Lu et al.\n2024; Chen et al. 2023; Sun and Saenko 2016). Though the\npast five years have witnessed its remarkable success in the\ncomputer vision community, there has been very limited re-\nsearch attention for human activity recognition using wear-\nable sensor data. To the best of our knowledge, the latest\nwork to solve such DG problem for HAR is DIVERSITY"}, {"title": "Domain-Invariant Learning for Generalization"}, {"title": "Methodology", "content": "Given a set of source domains utilized as the training dataset\nDtr = {D1, D2, ..., DS}, for the i-th source domain Di we\nuse Pi (x, y) on X \u00d7 Y to represent the joint distribution,\nwhere x \u2208 X denotes the sensor input obtained by slid-\ning window, y \u2208 Y = {1, ..., C'} denotes the label space\nwith total C activity categories. We perform training from\nthe source domain Dtr dataset to obtain the cross-domain\nactivity recognition model h : X \u2192 Y, which can general-\nize well on the never-seen-before target domain Dte dataset.\nIt is important to note that the target domain Dte can only be\naccessed at inference. Although the source and target do-\nmains have the same input and output spaces, the source\nand target domains have different distributions Pte, i.e.,\nP\u00b2(x,y) \u2260 P(x,y),\u2200i, j \u2208 {1, 2, ..., S, te}. In a word,\nwe hope that the model h trained on the source domain Dtr\ncan minimize the average prediction error et on the target\ndomain Dte:\n\u20act = E(x,y)~Pte(x,y)L(h(x), y).\nIn this section, we answer the potential motivation behind\nthe proposed CCIL and provide in-depth insights into our"}, {"title": "Problem Formulation"}, {"title": "Motivation Based on Feature v.s. Logit", "content": "algorithm design. To learn domain-invariant representations\nfor sensor-based activity recognition, a well-generalized\nmodel should be stable under cross-domain scenarios. Most\nexisting DG-based works concentrate on implicitly or ex-\nplicitly regularizing the model based on the notation of\nfeature-invariance (Lu et al. 2024; Du et al. 2021; Cha et al.\n2022). However, such feature-invariance leaning strategy\nstill poses a serious limitation. To be specific, while only\nfocusing on the feature-invariance, it fails to take into full\nconsideration the classifier weights, which are in charge of\ndetermining the importance of different feature elements,\nthereby resulting in a biased estimate for feature importance.\nFor example, while a feature element has a big value, it\nmight correspond to a small value in the classifier, lead-\ning to a lower effect on final activity classification results.\nSolely considering the feature-invariance would be biased\nor misleading, thus undermining the generalization ability of\nthe model. Therefore, the influence of the classifier weights\nshould be fully considered so as to avoid such biased esti-\nmation of feature importance.\nTo mitigate this issue in cross-domain situation, instead of\nonly concentrating on the feature-invariance, the logit may\nimplicitly take into account the effect of classifier weights\nto a certain extent. However, the logit is only able to pro-\nvide a coarse value, that lacks a fine-grained perspective to\ninterpret the rationale behind generalizable cross-domain ac-\ntivity recognition process. As a consequence, focusing only\non logit-invariance may lead to ineffectiveness in generating\nrobust feature representations, which will be verified in later\nvisualizing analysis. Our concept matrix aims to overcome\nthe two drawbacks by simultaneously concentrating on both\nfeature-invariance or logit-invariance, which learn domain-\ninvariant representations from a more fine-grained perspec-\ntive while taking into account the influence of classifier\nweights. A new regularization loss term is introduced based\non the concept matrix to capture both feature-invariance\nand logit-invariance representations for generalizable cross-\ndomain activity recognition."}, {"title": "Framework Overview", "content": "This section presents a comprehensive description of our\nnewly proposed DG approach. As illustrated in Figure 2,\nwe propose Categorical Concept Invariant Learning abbre-\nviated as CCIL to learn both feature-invariance and logit-\ninvariance for generalizable cross-domain activity recogni-\ntion. CCIL takes inputs from multiple different but related\nsource domains for model training, while the target domain\ndata is only utilized for model test. Subsequently, after go-\ning through a common feature extractor, the output features\nare multiplied with the classifier weights, which can then\nbe used to form the concept matrix. While the same activ-\nity performed by different persons (domains) tend to have\nsimilar activity semantics, we may leverage the invariance\nacross domains to regularize the model to facilitate domain\ngeneralization. To ensure robust results, the concept matrix\nof samples belonging to the same activity class should align\nwith their corresponding mean value, which is very reason-\nable such the causal factors for invariance-learning are usu-\nally stable patterns to persist across domains (Lu et al. 2024;\nChen et al. 2023). On this basis, we introduce a new regu-\nlarization loss term that allows the model to explore more\ninvariance.\nIn most existing HAR models, the back-\nbone architecture h is typically comprised of a feature ex-\ntractor and an activity classifier. The feature z \u2208 RD can\nbe produced through a feature extractor f (i.e., z = f (x))\nparameterized by 0, which contains two convolution layers\nand one pooling layer (Lu et al. 2024). Assuming that there\nare total C activity classes in Y after applying the classifier g\ncomprised of one fully-connected layer on z, we can obtain\nthe final logits o = W\u00afz\u2208 RC (i.e., o = g (z)), where\nW \u2208 RD\u00d7C is the weights of the classifier g. For simplicity,\nwe omit the bias in the classifier. On this basis, the concept\nmatrix can be constructed based on the output feature z and\nclassifier weights W. In practice, every logit value is equiv-\nalent to the summation of element-wise multiplications be-\ntween the feature elements and the corresponding weights\nin the classifier. Without loss of generality, oc (i.e., the c-th\ndimension of o) can be formulated as follows:\nOc = \\sum_{j=1}^{D} W{j,c}Zj,\nwhere the logit value on the c-th activity class is a simple\naddition of all W{j,c}Zj. Intuitively, it can be seen as an\nelement-wise contribution to oc. Therefore, we are able to\naggregate all W{j,c} zj to form the concept matrix, that may\nbe mathematically denoted as follows:\nM = [\\begin{smallmatrix}\nW{1,1}z_1 & W{1,2}z_1 & \\dots & W{1,C}z_1 \\\\\nW{2,1}z_2 & W{2,2}z_2 & \\dots & W{2,C}z_2 \\\\\n\\vdots & \\vdots & \\vdots & \\vdots \\\\\nW{D,1}z_D & W{D,2}z_D & \\dots & W{D,C}z_D\n\\end{smallmatrix}]\nSince the Softmax function is implemented on all the logits\nto produce the final posterior probability. It is important to\nnote that the concept matrix M should be constructed from\nall classes. That is to say, the final posterior probability will\nbe affected by the logits from all activity classes."}, {"title": "Concept Matrix"}, {"title": "Categorical Concept Invariant Learning", "content": "Our key idea\nis that the concept matrix for activity samples of the same\ncategory should align with their corresponding mean value,\nimplying that the concept matrix for the same activity cat-\negory should be similar regardless of domains. To achieve\nthis goal, we introduce a regularization term based on the\nconcept matrix similarity (abbreviated as CMS) in training\nphase. Such regularization term may be formulated as:\nLCMS = \\frac{1}{N_b}\\sum_{c}^{C}\\sum_{{i|y_i=c}} || M_i \u2013 M_c||\u00b2,\nwhere No is the number of samples in one mini-batch, M\u2081\ndenotes the concept matrix of the i-th sample, M\u025b denotes\nthe mean matrix of the concept matrix corresponding to the\nc-th class, and ||\u00b7 || is 12 norm. The M\u025b in the above equa-\ntion requires averaging the activity samples in all domains,\nwhich is impractical and computationally expensive. Since\nit is unrealistic to directly calculate the concept matrix of all\nsensor samples, we perform a dynamic momentum update\nto adapt the concept matrix during each training iteration,\nwhich can greatly ease the computational burden. To be spe-\ncific, inspired by previous work (He et al. 2020; Chen et al.\n2023) we can utilize momentum updating for Me online:\nM_c^t = (1 \u2212 \\lambda) \u00d7 M_c^{t-1} + \\lambda \\sum_{y_i = C}^{} M_i,\nwhere X is the positive momentum value, t is the iteration\nindex, yi = c| denotes the sample corresponding to the c-th\nclass of activity identification, and Me is initialized from the\nfirst iteration to compute the processed concept matrix.\nThe overall learning objective can be\nwritten as follows:\nL = LCE + \u03b1LCMS,\nwhere LCE denotes the standard cross-entropy loss, LCMS\nis the loss of CCIL, and a is a positive weight coefficient.\nAs can be seen in Eq. 6, our CCIL is very simple, that only\nrequires adding only a few lines of code upon the vanialla\nERM training pipeline."}, {"title": "Learning Objective"}, {"title": "Experiments", "content": "The widely-employed\nsliding window strategy is first used to segment time series\ndata, while maintaining the same window length and over-\nlap rate as in previous works (Ord\u00f3\u00f1ez and Roggen 2016;\nAnguita et al. 2013; Wang et al. 2019). We directly follow\nthe model architecture in (Lu et al. 2024) to conduct the ex-\nperiments. The backbone architecture consists of two mod-\nules: the feature extractor and activity classifier. The fea-\nture extractor includes two convolutional layers followed by\nmax-pooling operation for feature extraction, while the clas-\nsifier contains a fully connected layer for final predictions.\nWe evaluate our method on four public sensor-based HAR\nbenchmark: DSADS (Altun, Barshan, and Tun\u00e7el 2010),\nPAMAP2 (Reiss and Stricker 2012), USC-HAD (Zhang and\nSawchuk 2012) and UCI-HAR (Anguita et al. 2013)."}, {"title": "Cross-Domain Settings", "content": "Cross-domain Settings are di-\nvided into the following four categories. Cross-person set-\nting. In the DSADS dataset, there are a total of 8 sub-\njects. We divide the 8 subjects into 4 domains, each of which\ncontains two subjects. We use the sliding window technique\nwith a window size of 125 and an overlap rate of 50%. The\nfinal processed sample size is (45, 1, 125), where 45 repre-\nsents sensors from 5 positions, with each position having 3\ndifferent sensors, and each sensor being 3-axis. In the USC-\nHAD dataset, there are a total of 14 subjects. We roughly\ndivide them into four domains, where three of four domains\nwith each containing four subjects are used as source do-\nmain, while the rest domain containing two subjects is uti-\nlized as target domain. We use the sliding window technique\nwith a window size of 200 and an overlap rate of 50%. The\nfinal processed sample size is (6, 1, 200), where 6 represents\nsensors from one position, with this position having 2 differ-\nent sensors, and each sensor being 3-axis. In the PAMAP2\ndataset, there are a total of 9 subjects with subject IDs 0-8.\nWe divide them into four domains: domains: (2, 3, 8), (1, 5),\n(0, 7), (4, 6). We use the sliding window technique with a\nwindow size of 200 and an overlap rate of 50%. The final\nprocessed sample size is (27, 1, 200), where 27 represents"}, {"title": "Comparative Methods"}, {"title": "Experimental Results", "content": "The classification results of our method for HAR under\ncross-person, cross-dataset, cross-position, and one-person-\nto-another generalization settings are presented in Tables 1-\n4. We draw some conclusions from these results: (1) As\nlisted in Table 1, in the term of average accuracy, we note\nthat the na\u00efve ERM baseline achieves favorable performance\nagainst compared arts. Most existing strategies cannot con-\nsistently improve ERM while evaluated under the rigorous\nsettings, and some DG methods perform even worse than\nERM on certain tasks, which are in well line with previous\nobservations in (Gulrajani and Lopez-Paz 2021). This may\nbe due to the inability of these methods to reduce the distri-\nbution discrepancy in time series sensor data. Therefore, it\nis crucial to explore domain-invariant knowledge that can\neffectively reduce distribution discrepancy in sensor data\nfor HAR; (2) Overall, our proposed approach consistently\ndemonstrates superior performance against other state-of-\nthe-art baselines under cross-person setting, where ours is\nranked first place on all three benchmarks. Specifically, in\nterms of average accuracy, our CCIL significantly surpass\nthe baseline ERM by large margins of 10.4%, 7.3%, and\n7.4% on DSADS, USC-HAD, and PAMAP respectively. In\nfact, domain generalization is a challenging task, and it is\noften difficult to achieve an improvement over 1%. As can\nbe seen in Table 1, the second-best baseline only has a slight\nimprovement compared to the third one. In contrast to the\nbest baseline DIVERSIFY, our approach still achieves fur-\nther improvements of 2.5%, 3.0%, and 3.7% on all three\nbenchmarks. The observations validate the effectiveness of\nour approach compared against existing baselines; (3) As\naforementioned, other methods, such as CORAL, Group-"}, {"title": "Ablation Study", "content": "In addition to the baseline ERM method, we com-\npare our suggested approach with the following vari-\nants to access their independent impact of each com-\nponent: (1) The feature-invariance constraint abbreviated\nas 'W/fea', where Eq. 4 is replaced as: LCMS =\n\\frac{1}{N_o}\\sum_{c}^{C}\\sum_{{i|y_i=c}} || Z_i \u2013 2_c||\u00b2; (2) The logit-invariance con-\nstraint abbreviated as 'W/log', where Eq. 4 is replaced as:\nLCMS = \\frac{1}{N_o}\\sum_{c}^{C}\\sum_{{i|y_i=c}} || o_i - \u00d4_c||\u00b2; (3) Ours with x = 0\n(i.e., \u2018W/X = 0'), where M equals the mean value dynam-\nical calculated from current batch; (4) Ours with \u5165 = 1\n(i.e., \u2018W/X = 1'), where M is kept fixed from the initial\npretrained model. We observe that either feature-invariance\nconstraint or logit-invariance constraint can substantially\nbeat the baseline ERM method. In contrast to them, our ap-"}, {"title": "T-SNE Visualization", "content": "To better understanding our invariance regularization, we\nprovide a t-SNE visualization illustration on DSADS\ndataset, as plotted in Figure 3. In contrast to the other three\nstrategies, it can be seen the clusters from our proposed in-\nvariance regularization are more distinctly separated, indi-\ncating its effectiveness while generalizing on an unseen dis-\ntribution. This is in well line with the results reported in\nTable 5. Meanwhile, we observe that the logit-invariance\nconstraint alone performs only slightly better than the base-"}, {"title": "Categorical Concept Invariant Learning", "content": "Our key idea\nis that the concept matrix for activity samples of the same\ncategory should align with their corresponding mean value,\nimplying that the concept matrix for the same activity cat-\negory should be similar regardless of domains. To achieve\nthis goal, we introduce a regularization term based on the\nconcept matrix similarity (abbreviated as CMS) in training\nphase. Such regularization term may be formulated as:\nLCMS = \\frac{1}{N_b}\\sum_{c}^{C}\\sum_{{i|y_i=c}} || M_i \u2013 M_c||\u00b2,\nwhere No is the number of samples in one mini-batch, M\u2081\ndenotes the concept matrix of the i-th sample, M\u025b denotes\nthe mean matrix of the concept matrix corresponding to the\nc-th class, and ||\u00b7 || is 12 norm. The M\u025b in the above equa-\ntion requires averaging the activity samples in all domains,\nwhich is impractical and computationally expensive. Since\nit is unrealistic to directly calculate the concept matrix of all\nsensor samples, we perform a dynamic momentum update\nto adapt the concept matrix during each training iteration,\nwhich can greatly ease the computational burden. To be spe-\ncific, inspired by previous work (He et al. 2020; Chen et al.\n2023) we can utilize momentum updating for Me online:\nM_c^t = (1 \u2212 \\lambda) \u00d7 M_c^{t-1} + \\lambda \\sum_{y_i = C}^{} M_i,\nwhere X is the positive momentum value, t is the iteration\nindex, yi = c| denotes the sample corresponding to the c-th\nclass of activity identification, and Me is initialized from the\nfirst iteration to compute the processed concept matrix.\nThe overall learning objective can be\nwritten as follows:\nL = LCE + \u03b1LCMS,\nwhere LCE denotes the standard cross-entropy loss, LCMS\nis the loss of CCIL, and a is a positive weight coefficient.\nAs can be seen in Eq. 6, our CCIL is very simple, that only\nrequires adding only a few lines of code upon the vanialla\nERM training pipeline."}, {"title": "Conclusion", "content": "In this paper, we propose CCIL, a new regularization ap-\nproach for sensor-based cross-domain activity recognition.\nWhile there exist diverse distributions in time series activity\ndata across domains, e.g., different persons, CCIL addresses\nthis problem by learning domain-invariant knowledge. To\nensure robust outputs, the key idea of our algorithm is to\ncapture domain-invariant knowledge by enforcing similar-ity between the concept matrix of samples from the same\nactivity category and their corresponding mean value. Dif-\nferent from prior most works, our approach takes a different\npath by taking into full consideration the classifier weights\n(i.e., the logit-invariance), rather than only concentrating on\nfeature-invariance. Experiments on multiple public datasets\ndemonstrate the superiority of our CCIL approach across\nvarious cross-domain settings."}, {"title": "Supplementary Materials", "content": "In the Supplementary Material, all experiments were con-\nducted under the CNN architecture (except for the extensi-\nbility section) and we provide:\n\u2022 Different invariance regularizations.\n\u2022 Implementation details.\n\u2022 Extensibility.\n\u2022 Additional visualization study.\n\u2022 Pseudo-code."}, {"title": "Different Invariance Regularizations"}, {"title": "Implementation Details", "content": "The following provides a detailed description of four pub-\nlicly available HAR benchmark datasets. The UCI Daily and\nSports Dataset (DSADS) (Altun, Barshan, and Tun\u00e7el 2010)\nconsists of 19 activities collected from 8 subjects wearing\nbody-worn sensors on 5 body parts. The subjects were aged\nbetween 20 and 30 years. The USC-SIPI Human Activity\nDataset (USC-HAD) (Zhang and Sawchuk 2012) is com-\nposed of 14 subjects (7 male, 7 female, aged 21 to 49) exe-\ncuting 12 activities with a sensor tied to the front right hip.\nThe UCI-HAR (Anguita et al. 2013) dataset was collected\nfrom 30 subjects performing 6 daily living activities with a\nwaist-mounted smartphone. The subjects were aged between\n20 and 30 years. The PAMAP dataset (Reiss and Stricker\n2012) contains data on 18 activities, performed by 9 sub-\njects wearing 3 sensors. The subjects were aged between 20\nand 30 years. Additional information is provided in Table 6."}, {"title": "Network Architecture and Training Details"}, {"title": "Compared Methods", "content": "The following provides a detailed description of various\ncomparison methods. ERM (Vapnik 1991) is a popular DG-\nbased method that focuses on minimizing the sum of errors\nover source domains. DANN (Ganin et al. 2016) is a method\nthat utilizes the adversarial training to force the discrimina-\ntor unable to classify domains for better domain-invariant\nfeatures. It requires domain labels and splits data in advance\nwhile ours is a universal method. CORAL (Sun and Saenko\n2016) is a method that utilizes the covariance alignment in\nfeature layers for better domain-invariant features. It also\nrequires domain labels and splits data in advance. Mixup\n(Zhang et al. 2018) is a method that utilizes interpolation\nto generate more data for better generalization. Ours mainly\nfocuses on generalized representation learning. GroupDRO\n(Sagawa et al. 2019) is a method that seeks a global distri-\nbution with the worst performance within a range of the raw\ndistribution for better generalization. Ours study the inter-\nnal distribution shift instead of seeking a global distribution\nclose to the original one. RSC (Huang et al. 2020) is a self-"}, {"title": "Extensibility", "content": "We explore using Transformer as the backbone for compar-\nison. Transformers often exhibit better generalization abil-\nity compared to CNNs, making further improvement with\nTransformers more challenging. As shown in Table 8, each\nmethod with a Transformer backbone shows significant im-\nprovement on DSADS. While DANN shows little improve-\nment over ERM, our method still achieves further enhance-\nments and delivers the best performance. Overall, across all\narchitectures, our method consistently achieves superior per-\nformance."}, {"title": "Additional Visualization Study"}, {"title": "Algorithm 1: CCIL for DG-based HAR", "content": "Input: The training domain Dtr, hyperparameter & and\nthe momentum \u5165\nOutput: The parameters @ of feature extractor f and the\nweights W of activity classifier g.\n1: Randomly initialize 0 and W;\n2: while not converge do\nSample a mini-batch B \u2190 {B1, B2, ..., Bn } from\neach source domain, and concat them as Xtr;\nExtract output features z \u2190 f(xtr) by feature\nextractor f;\nObtain the classification loss LCE for activity\nclassifier g;\nUsing output features z and classifier weight W to\ncalculate the mean values M;\nUpdating the Concept matrix M through dynamic\nMomentum Update Strategy with momentum value\n\u03bb, i.e., Eq. (5).\nCalculate the loss of CMS\n(LCMS \u2190 \u03a3\u03a3{i|yi=c} ||Mi \u2013 Mc||\u00b2);\nCalculate the final loss of CCIL\n(LLCE + ALCMS);\nUpdate @ and W using Adam;\n11: end while\n5:\n6:\n7:\n8:\n9:\n10:"}, {"title": "Inference:"}, {"title": "Contribution Statement", "content": "\u2022 Di Xiong (Nanjing Normal University, China):\nProposing the idea, implementing code, conducting ex-\nperiments, data collection, figure drawing, table organiz-\ning, and completing original manuscript.\n\u2022 Shuoyuan Wang (Southern University of Science and\nTechnology, China): Writing polish, idea improvement,\nand rebuttal assistance.\n\u2022 Lei Zhang (Nanjing Normal University, China): Pro-\nviding experimental platform, supervision, idea improve-\nment, writing polish, rebuttal assistance, and funding ac-\nquisition.\n\u2022 Wenbo Huang (Southeast University, China): Figure\ndrawing, table organizing, supervision, and rebuttal as-\nsistance.\n\u2022 Chaolei Han (Southeast University, China): Table or-\nganizing."}, {"title": "Acknowledgements"}]}