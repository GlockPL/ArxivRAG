{"title": "PACE: PHYSICS INFORMED UNCERTAINTY AWARE CLIMATE EMULATOR", "authors": ["Hira Saleem", "Flora D. Salim", "Cormac Purcell"], "abstract": "Climate models serve as critical tools for evaluating the effects of climate change and projecting future climate scenarios. However, the reliance on numerical simulations of physical equations renders them computationally intensive and inefficient. While deep learning methodologies have made significant progress in weather forecasting, they are still unstable for climate emulation tasks. Here, we propose PACE, a lightweight 684K parameter Physics Informed Uncertainty Aware Climate Emulator. PACE emulates temperature and precipitation stably for 86 years while only being trained on greenhouse gas emissions data. We incorporate a fundamental physical law of advection-diffusion in PACE accounting for boundary conditions and empirically estimating the diffusion co-efficient and flow velocities from emissions data. PACE has been trained on 15 climate models provided by ClimateSet outperforming baselines across most of the climate models and advancing a new state of the art in a climate diagnostic task.", "sections": [{"title": "1 INTRODUCTION", "content": "The past decade has seen superior performing data-driven weather forecasting models Kochkov et al. (2024); Lam et al. (2023); Nguyen et al. (2023b) as compared to numerical weather prediction models (ECMWF, 2023). However, the medium range forecasting ability makes them unstable for climate modelling several years into the future (Chattopadhyay & Hassanzadeh, 2023).\nClimate models are governed by temporal partial differential equations (PDEs) to describe complex physical processes Gupta & Brandstetter (2022), enabling simulations of climate behavior under various forcing scenarios, such as fluctuating greenhouse gas (GHG) emissions. The computational expense associated with solving these PDEs involves, executing these climate model simulations typically for several months (Balaji et al., 2017).\nIn order to faithfully emulate the reference climate model, a Machine Learning (ML) based climate emulator should follow the fundamental physical laws that govern the dynamics of the atmosphere (Watt-Meyer et al., 2023). Additionally, accurately capturing the influence of GHG and aerosols is essential for simulating realistic climate responses to different emission scenarios (Bloch-Johnson et al., 2024).\nThe few existing climate emulators that incorporate GHG concentrations typically rely on auto-regressive training regimes. These models predict climate variables at future time steps based on past states, but often fail to account for the projected emissions at those future times. This limitation leads to significant inaccuracies in predicting future climate states, especially under varying anthropogenic emission scenarios, highlighting a critical gap in current climate modeling approaches.\nTo address this gap, we propose PACE, which treats climate emulation as a diagnostic-type prediction and integrate emissions data directly into the model's training framework, to predict climate variables from a given parallel time-series of climate forcer emission maps (GHG and aerosols) allowing for more accurate simulation of future climate states under varying concentration scenarios.\nFurthermore, we focus on two key phenomenon observed by our climate system i.e. advection and diffusion. In climate modeling, the advection-diffusion equation is fundamental for simulating"}, {"title": "2 RELATED WORK", "content": ""}, {"title": "2.1 MACHINE LEARNING (ML) AND PHYSICS BASED CLIMATE EMULATORS", "content": "Recently, ML based and Physics Informed climate emulators have been successful in emulating several climate variables. Watt-Meyer et al. (2023) proposed ACE (AI2 Climate Emulator) based on Spherical Neural Operator (SFNO) architecture for effective physics informed emulation. Guan et al. (2024) proposed LUCIE, also based on SFNO to account for the computational complexity of ACE. Choi et al. (2023) proposed climate modelling using Graph Neural Network (GNN) and Neural ODE, but do not account for GHG emissions or show any long term stability. Additionally, there are several climate emulators which are trained on only one climate model unknown for their generalizability across different climate models (Scher, 2018; Mansfield et al., 2020; Beusch et al., 2020; Cachay et al., 2021; Watson-Parris et al., 2022). Bassetti et al. (2024) use diffusion models for climate emulation, however their primary goal is temporal downscaling. Nguyen et al. (2023a) accounts for multi-model training, however it is limited to medium range forecasting."}, {"title": "2.2 MODELLING PHYSICAL SYSTEMS USING NEURAL NETWORKS", "content": "The neural ordinary differential equation(ODE) model proposed by Chen et al. (2018) has demonstrated significant potential for solving partial differential equations (PDEs) that govern the complex physical systems, opening up numerous new research avenues in the field (Mattheakis et al., 2022; Dandekar et al., 2020; Finzi et al., 2020; Lutter et al., 2019). Further, physics-informed neural networks (PINNs) were used to to solve the advection-dispersion equation using discretization-free and reduced-order methods (Vadyala et al., 2022; He & Tartakovsky, 2021). Neural Networks (NN) have also been used as surrogate models for obtaining PDE solutions in fluid dynamics and forecasting (Lu et al., 2021; Li et al., 2020; Brandstetter et al., 2022; S\u00f8nderby et al., 2020; Keisler, 2022)."}, {"title": "3 MODELLING CLIMATE VARIABILITY THROUGH NEURAL\nADVECTION-DIFFUSION PROCESS", "content": ""}, {"title": "3.1 PROBLEM FORMULATION", "content": "We model climate emulation as a continuous sequence to sequence (seq-to-seq) task where the goal is to predict mapping of climate variables from a given time-series of climate forcer emission maps.\nConsidering that climate system evolves according to a 2D advection-diffusion process, described by the following partial differential equation (PDE):\n\n$\\frac{\\partial u}{\\partial t}$ + v \u2022 Vu = DV\u00b2u\n\nwhere u(x, y, t) represents the climate variables (temperature and precipitation) at time t and spatial coordinates (x, y), v is the velocity field representing advection and D is the diffusion coefficient.\nFormally, let F(t) \u2208 Rxxy represent the input fields of greenhouse gas concentrations at time t and x and y denote the latitude-longitude spatial grid \u2208 \u03a9 = [-90\u00b0,90\u00b0] \u00d7 [-180\u00b0, 180\u00b0] CR\u00b2. The output U(t) \u2208 Rxxy corresponds to the predicted climate variables at the parallel time step. The neural network is trained to solve the following mapping:\n\nU(t) = M(F(t); 0)\n\nwhere M is the neural network model parameterized by 0, which approximates the solution to the advection-diffusion equation given the input emissions F. The model is designed to learn the spatiotemporal patterns of our climate system dictated by the underlying physical processes modeled by the PDE."}, {"title": "3.2 ADVECTION DIFFUSION PROCESS", "content": "We model climate emulation as a continuous spatio-temporal process which captures two fundamental physical processes: advection and diffusion, which together dictate how substances are transported and spread out throughout the climate system. The general form of the advection-diffusion equation in a climate system is defined in equation 1.\nTo faithfully emulate the climate's chaotic nature, it is essential to determine the path and rate at which the physical quantities are transported given by v Vu where v is the velocity vector of the fluid (e.g., wind velocity) and \u2207u is the gradient of the quantity being transported (e.g., temperature or concentration). On the other hand, diffusion models the distribution of physical quantities such as heat, moisture, and other properties within the atmosphere DV\u00b2u where D is the diffusion coefficient, indicating how the scalar field spreads out due to molecular diffusion.\nWe employ Neural ODE presented by Chen et al. (2018) to solve the 2D advection diffusion equation 3 by discretizing the spatial domain using Finite Difference Method (FDM) Fiadeiro & Veronis (1977) considering the earth is divided into spatially uniform grid points in x and y directions (longitude x latitude). FDM employ spatial discretization to approximate derivatives using the values at grid points. We explain the spatail discretization and show it's effect visually in section 4.\n\n$\\frac{\\partial u}{\\partial t}$ + Vx $\\frac{\\partial u}{\\partial x}$+ Vy $\\frac{\\partial u}{\\partial y}$ = D($\\frac{\\partial^2 u}{\\partial x^2}$ + $\\frac{\\partial^2 u}{\\partial y^2}$)"}, {"title": "3.2.1 ESTIMATING DIFFUSION COEFFICIENT AND VELOCITY FIELD OF CLIMATE FORCER\nEMISSIONS", "content": "We initialize the model with the empirical estimation of diffusion coefficient D from green house gas emissions data. We calculate the spatial variance across the latitude and longitude dimensions to analyze how greenhouse gas concentrations spread from regions of high emissions over time. The diffusion co-efficient is calculated as equation 8.\n\nDestimate = $\\frac{1}{M}$ $\\sum_{i=1}^{M}$ Var(Ci)\n\nwhere M is the number of gas types and Var(C) = spatial variance calculated as:\n\nVar(C) = $\\frac{1}{N_x N_y}$ $\\sum_{x=1}^{N_x}$ $\\sum_{y=1}^{N_y}$ (C(t,x,y) \u2013 \u0108(t))2\n\nwhere C(t, x, y) is the concentration at time t at point (x, y), C(t) is the mean concentration across the spatial domain and Nx, Ny are the number of grid points in the longitude and latitude dimensions.\nWe empirically estimate the initial velocity from GHG concentration fields. The velocity fields Vx and vy are inferred using spatial gradients of the concentration field as shown in equation 10. These gradients indicate the direction and rate of concentration change, allowing the model to simulate advection accurately. Estimating velocity this way integrates spatial transport dynamics into the advection-diffusion solver, crucial for realistic climate modeling.\n\nUx ~ $\\frac{\\partial C}{\\partial x}$\n\nVy \u2248 $\\frac{\\partial C}{\\partial y}$\n\n$\\frac{C(x + \u2206x, y, t) \u2013 C(x \u2013 \u2206x, y, t)}{2\u2206x}$\n\n$\\frac{C(x, y + \u2206y, t) \u2013 C(x, y \u2013 \u2206y, t)}{2\u2206y}$"}, {"title": "3.2.2 UNCERTAINTY ESTIMATION", "content": "To account for uncertainty in our climate model, we integrate a stochastic term into the advection-diffusion as show in equation 13. Here, the stochasticity refers to a noise term which represents random fluctuations or uncertainties.\n\n$\\frac{\\partial u}{\\partial t}$ + v \u2022 \u2207u = D\u2207\u00b2u + an(x, y, t)"}, {"title": "3.2.3 PERIODIC BOUNDARY CONDITIONS AND HARMONICS SPATIO-TEMPORAL\nEMBEDDINGS", "content": "We implement periodic boundary condition (PBC) to simulate the entire planet. Considering Earth as roughly spherical, PBC ensure that the boundary at one edge of the domain connects seamlessly to the opposite edge, avoiding artificial edge effects and ensuring continuity. Mathematically, if f(x, y) is the state variable, periodic conditions imply f(x,y) = f(x + Lx,y) = f(x,y + Ly) where Lx and Ly are the domain lengths in the x and y directions, respectively.\nWe implement harmonic embeddings to learn seasonal variations and cyclical changes in climate data. By employing a series of sine and cosine functions of varying frequencies, these embeddings introduce features that help the model learn and represent periodic behaviors in the data effectively.\n\nembedding(t) = [sin(2\u00b2 \u00b7 t), cos(2\u00b2 \u00b7 t), ........., sin(2n-1 . t), cos(2n-1 . t)]\n\nwhere n is the number of bands and 22 is the frequency factor for each band, where i ranges from 0 to n 1 (determined by maximum frequency)."}, {"title": "3.3 CONVOLUTION BLOCK ATTENTION MODULE (C\u0412\u0410\u041c)", "content": "We implement a CBAM to handle the global spatial dependencies, as a parameterized network equation 16. The Neural ODE models the advection diffusion dynamics and extract features that are then fed into the CBAM which applies both Channel Attention Module (CAM) equation 17 and Spatial Attention Module (SAM) equation 18.\n\nfo(u(x,y)) = Mc(F) + M\u2084(F)\n\nMc(F) = \u03c3(MLP(AvgPool(F)) + MLP(MaxPool(F)))\n\nwhere Mc(F) is the channel attention map, ois the sigmoid function, and MLP denotes the multi-layer perceptron.\n\nM\u2084(F) = \u03c3(f7\u00d77([AvgPool(F); MaxPool(F)]))\n\nwhere Mg(F) is the spatial attention map, and f7\u00d77is the convolutional layer with a 7x7 filter."}, {"title": "4 EXPERIMENTS AND RESULTS", "content": ""}, {"title": "4.1 TASK", "content": "The goal of PACE is to emulate surface air temperature (TAS) and precipitation (PR) from climate forcer emission maps (CO2, CH4, SO2, BC) for a parallel time series of 2015-2100. We simulate the output of each climate model as single and super emulator, and also validate the generalisation of our methodology using zero-shot learning. We compare PACE against all baselines provided by ClimateSet under the same hyperparameter settings. We also compare against ACE (Watt-Meyer et al., 2023) and LUCIE Guan et al. (2024), two recent climate emulators. Since, they both are developed for different emulation task, we adopt their base architecture SFNO Bonev et al. (2023) and train it for the same task as ours. The details for adaptation of SFNO are given in Appendix A.2."}, {"title": "4.2 DATASET", "content": "We train PACE on a total of 15 climate models provided by ClimateSet Kaltenborn et al. (2023). ClimateSet compiles climate data from the Coupled Model Intercomparison Project Phase 6 (CMIP6) (Eyring et al., 2016), incorporating climate model outputs from ScenarioMIP (O'Neill et al., 2016) and future emission trajectories of climate forcing agents from Input Datasets for Model Intercomparison Projects (Input4MIPs) (Durack et al., 2017). Each climate model has been standardized to a spatial resolution of 250km i.e. 96 \u00d7 144 grid points (latitude \u00d7 longitude) with a monthly temporal resolution. Both input and output datasets consist of 86-year time-series data spanning four SSP scenarios (SSP1-2.6, SSP2-4.5, SSP3-7.0, SSP5-8.5) from 2015 to 2100. We use three scenarios namely SSP1-2.6, SSP3-7.0, SSP5-8.5 for training with a validation split of 0.1 and SSP2-4.5 for testing."}, {"title": "4.3 EVALUATION METRICS", "content": "We evaluate PACE and all benchmarks using latitude-weighted Root Mean Square Error (RMSE) given in equation 19.\n\nRMSE = $\\sqrt{\\frac{1}{N} \\sum_t^{N} \\frac{1}{HW} \\sum_{h}^{H} \\sum_{w}^{W} L(i) (Y_{thw} - pred_{thw})}$\n\nwhere L(i) accounts for latitude weights.\n\nL(i) = $\\frac{cos(lat(i))}{\\frac{1}{H} \\sum_{i'=1}^{H} cos(lat(i'))}$\n\nwhere lat(i) represents the latitude of the i-th row within the grid. The latitude weighting factor is introduced to address the uneven distribution of areas when mapping the spherical Earth's surface onto a regular grid."}, {"title": "4.4 SINGLE EMULATOR", "content": "For single emulator experiments, we trained all models for 25 epochs. We report RMSE for UNet, ConvLSTM, ClimaX, ClimaX_Frozen and SFNO. The training hyperparameters are all kept similar to those used in the original paper. PACE outperforms all models for emulating temperature across"}, {"title": "4.5 SUPER EMULATOR", "content": "Here, the term super emulator is used to train a single ML model on all of 15 climate models. This leads to the rich feature learning resulting in better generalization capabilities across different climate models. We use the same multihead decoder proposed in ClimateSet to train all ML models including PACE. We train all ML models for 100 epochs to keep the training regime computationally efficient with 2 convolutional layers and and 32 units decoder head. For super-emulator experiments we use a batch size of 1 for all models due to computational constraints.\nFor super emulation PACE outperforms all ML models on 13 climate models while ConvLSTM performs best for emulating EC-Earth3-Veg-LR and TaiESM1. The authors of ClimateSet Kaltenborn et al. (2023) suggest that during super emulation, smaller models demonstrate superior learning efficiency compared to larger models. This is because smaller models converge faster, allowing the model to learn patterns and relationships in the data more rapidly. We believe PACE being physically consistent and compute-efficient is able to learn complex climate features and outperform computationally intensive climate emulators."}, {"title": "4.6 GENERALIZATION CAPABILITIES OF PACE AS A SINGLE EMULATOR", "content": "We perform generalization experiments to test the generalization capabilities of ML models on three climate models: AWI-CM-1-1-MR, MPI-ESM1-2-HR and FGOALS-f3-L. The RMSE results are shown in Tables 3, 4 and 5 for TAS (surface air temperature) and PR (precipitation) pre-trained on different climate models and tested on these three climate models. The metric for best performing model is emboldened. The pretrained climate model column shows which dataset the model was initially trained on before being tested on the either of the three climate models. Overall we observe that PACE, SFNO and ClimaX performs well for generalizing over different climate models with PACE outperforming on majority of the models. Here ClimaX does gain benefit from being pre-trained on a range of climate models initially. In future, we will test ClimaX generalization without using the pre-trained checkpoint to see how it compares against the smaller models such as unet and convlstm."}, {"title": "5 NUMERICAL DISCRETIZATION AND GRID REPRESENTATION: IMPACT OF\nFINITE DIFFERENCE METHODS (FDM) ON EARTH'S SPATIAL GRIDDING\nIN CLIMATE MODELS", "content": "We utilize FDM for spatial discretization in PACE which divides the the physical space (in this case Earth atmosphere) into a grid of discrete points. Each grid point represents a specific location, and the value of the physical quantity (e.g., temperature) is computed at each point. The gridding at a lower resolution does induce additional errors. In future, we aim to test FVM and FEM to test if they results in smoother outputs and reduce errors."}, {"title": "6 ABLATION STUDIES", "content": "To understand the importance of each component of PACE, we perform ablation studies across four climate models namely AWI-CM-1-1-MR, TaiESM1, EC-Earth3 and NorESM2-MM.\nAdvection-Only: For this study, we remove the empirical estimated diffusion term from PACE and only model the advection process using Neural ODE. The resulting RMSE for surface air temperature and precipitation increases deteriorating the model's overall performance. The results show that missing approximation of diffusion has a greater effect on temperature as compared to precipitation, therefore determining that diffusion is critical in accurately simulating the transport of physical quantities like heat, moisture, and momentum.\nDiffusion-Only: In order to understand the importance of advection process, we initialised the model with constant velocities i.e. (Vx = 1.0, vy = 1.0) rather than estimating their values from GHG emissions. This resulted in a much greater impact on emulating precipitation as compared to the previous study.\nNeural ODE: For this study, we remove the advection diffusion process and only parameterize the Convolution Attention Module using Neural ODE. Our results demonstrate that accurately capturing advection-diffusion process is essential to simulate how energy and moisture are distributed, which directly impacts predictions of temperature, precipitation, and long-term climate changes, highlighting the critical contribution of each element to optimizing the model's emulating performance."}, {"title": "7 CONCLUSION AND FUTURE WORK", "content": "In this work, we present PACE, a physics and uncertainty aware climate emulator which accounts for Earth's atmospheric advection-diffusion phenomenon. We incorporate a key physical law in PACE by solving a time-dependent partial different equation (PDE) using Neural ODE. Additionally, we encode periodic boundary conditions to avoid artificial edge effects that arise from rigid boundaries."}, {"title": "ETHICAL STATEMENT", "content": "Our research aims to emulate temperature and precipitation for multiple climate models by solving an atmospheric advection-diffusion equation using ML based approach while being computationally efficient. The findings demonstrate that data-driven approaches can substantially enhance forecast accuracy while utilizing computational resources more efficiently. The environmental impact of optimizing computational efficiency in forecasting is notable, as it reduces the carbon footprint associated with large-scale computational processes, aligning with global initiatives to mitigate climate change. By combining machine learning (ML) techniques to both improve predictive accuracy and reduce computational overhead, we propose a sustainable and scalable solution for climate emulation that can better serve the global population."}]}