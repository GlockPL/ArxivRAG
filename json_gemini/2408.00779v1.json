{"title": "Learning Structurally Stabilized Representations for Multi-modal Lossless DNA Storage", "authors": ["Ben Cao", "Tiantian He", "Xue Li", "Bin Wang", "Xiaohu Wu", "Qiang Zhang", "Yew-Soon Ong"], "abstract": "In this paper, we present Reed-Solomon coded single-stranded representation learning (RSRL), a novel end-to-end model for learning representations for multi-modal lossless DNA storage. In contrast to existing learning-based methods, the proposed RSRL is inspired by both error-correction codec and structural biology. Specifically, RSRL first learns the representations for the subsequent storage from the binary data transformed by the Reed-Solomon codec. Then, the representations are masked by an RS-code-informed mask to focus on correcting the burst errors occurring in the learning process. With the decoded representations with error corrections, a novel biologically stabilized loss is formulated to regularize the data representations to possess stable single-stranded structures. By incorporating these novel strategies, the proposed RSRL can learn highly durable, dense, and lossless representations for the subsequent storage tasks into DNA sequences. The proposed RSRL has been compared with a number of strong baselines in real-world tasks of multi-modal data storage. The experimental results obtained demonstrate that RSRL can store diverse types of data with much higher information density and durability but much lower error rates.", "sections": [{"title": "1 Introduction", "content": "DNA storage has become one of the most promising technical solutions for coping with data explosion [8, 9,21]. Compared with conventional storage techniques, DNA storage utilizes DNA molecules as a storage medium to read and write data. By integrating advanced bio-technologies, such as DNA coding, synthesis, sequencing, recovery, and decoding, it achieves desirable characteristics of high-density [7], high-durability [19], and ultra-long-time storage [29]. Although benefiting from the emergence of modern information and biotechnology [6], DNA storage still suffers from the critical bottlenecks of cost and latency compared with electromagnetic storage media.\nRecently, leveraging computational approaches to break through the cost and latency bottlenecks of existing DNA storage has drawn much attention from AI and machine learning communities. Several models for DNA coding and decoding have been developed to learn compact data representations that can improve the base utilization [33] while reducing latency issues [22]. These approaches can be categorized into two classes, i.e., coding-theory-based and learning-based approaches. Methods based on coding theory [1,11,12, 19] are designed to strictly follow certain coding systems. Thus, they have high storage capacity ratios. However, these approaches are computationally demanding when dealing with large-scale data. In contrast, learning-based approaches adopt heuristic searching algorithms [18] or deep neural networks [10, 16, 30] to acquire an optimized coder/decoder that can write or read data stored in the DNA sequences. Though effective to some extent, these learning-based approaches always suffer from limited base utilization. Besides, they lack sufficient biological constraints during training, which can compromise data integrity. Thus, they are applicable only to data types that can tolerate information loss, such as images and videos.\nIn this paper, we hypothesize that the coalescence of contemporary learning models and stable traits of biomolecular structures in DNA can overcome the previously mentioned challenges confronted by existing learning-based approaches for DNA storage. To this end, we present Reed-Solomon coded single-stranded representation learning (RSRL), a novel model for learning representations for lossless DNA storage of multi-modal data. To develop RSRL, we make the following two technical contributions. Firstly, inspired by the Reed-Solomon codec, we propose a novel data preprocessing and mask strategy for representation learning for DNA storage. Specifically, the representations are learned from binary data coded based on the Reed-Solomon codec. Then, the representations are masked by an RS-code-informed Mask to focus on correcting the burst errors occurring in the learning process. Secondly, with the decoded data representations with error corrections, we propose a novel biologically stabilized loss that regularizes the data representations to possess stable single-stranded structures. With the mentioned techniques incorporated into the training process, the data representations learned for the subsequent writing to DNA are highly durable, dense, and lossless. In our experiments, the proposed RSRL has been compared with several strong baselines in real-world tasks of multi-modal data storage. The results demonstrate that RSRL achieves a notable reduction in learning complexity, with an 18% increase in net information density and an 11% improvement in thermodynamic performance. Additionally, our approach reduces coding and decoding delays by more than two orders of magnitude, representing a significant advancement in the field of DNA storage technology. The main contributions of this paper are summarized as follows:\n\u2022 We have verified that the consideration of stable traits of biomolecular structures and error-correction codec can significantly improve the representation learning for DNA storage.\n\u2022 To the best of our knowledge, we initialize the first attempt to formulate the loss function that can guide the proposed RSRL to learn representations for the subsequent DNA storage tasks that possess stable single-stranded structures. Such formulated loss enables RSRL to learn representations for durable, dense, and lossless DNA storage.\n\u2022 The proposed RSRL has been compared with strong baselines in real-world storage tasks of multi-modal data. Experimental results show that RSRL can overcome the shortcomings of existing learning-based approaches, indicating that it is an effective and promising method for real-world DNA storage tasks."}, {"title": "2 Related work", "content": "Conventional DNA storage and coding Due to intrinsically bearing life information as a natural storage medium, DNA has become the most competitive alternative to silicon-based storage [17]. DNA storage can be divided into three main phases, including data writing [3, 12, 23], preservation, and reading [3, 5, 20]. Conventionally, utilizing DNA molecules for data storage primarily includes two methods, i.e., sequence base representation and structure representation. Most approaches are designed to capture the distribution of bases to convert abiotic information into DNA sequences through DNA coding. Efficient and robust coding schemes not only improve coding efficiency but also ensure data integrity. However, due to the uncontrollability of biomolecules [34] and the inherent errors during DNA synthesis and sequencing, the coding rate was still some distance from the"}, {"title": "3 The proposed method", "content": "In this section, we introduce RSRL, a novel end-to-end model for learning representations for multi-modal lossless DNA storage. Fig. 1 illustrates the brief architecture of RSRL. RS codec is firstly used to process multi-modal data into a redundant binary data stream to correct errors during the learning process. This data stream is then fed into a Transformer network [27] to learn representations. Based on the RS codec, we design a Mask-MSE loss that can correct the burst errors widely existing in DNA sequences for storage. We further design a hairpin loss to ensure that the DNA codewords carrying non-biological information (i.e., the learned data representations) possess the stable single-strand structures possessed by DNA in the biont. It is noted that the one-stranded structure is considered in RSRL due to the complementary pairing structure of DNA double helices. The low-dimensional data representations are transcoded into DNA sequences and then automatically paired to form double-helix structures for data storage."}, {"title": "3.1 Representation learning and codec", "content": "For any file of size, W to be stored, it is first converted to a binary matrix $M * 48$, $M = W/48$, and this matrix is RS(64, 48) encoded by rows to obtain a binary data stream ($M * 64$) with error-correction redundancy. After reshaping the data stream into $N * 32 * 64$, $N = M/32$, a transformer with a compression layer [27] is employed to extract low-dimensional data representations, which are encoded as DNA sequences for data storage after optimization by a loss function."}, {"title": "3.2 Biologically stabilized loss functions", "content": "Existing loss functions fail to guide a learning model to achieve lossless DNA storage as they do not consider factors of biological stability. Inspired by the single-stranded structure in RNA and RS codec, we propose to formulate biologically stabilized loss functions that can guide the learned representations to possess the stable structures like bio-molecules have, thus achieving highly durable, information-dense, and lossless storage in DNA."}, {"title": "3.2.1 Synergizing RS codes with MASK-MSE loss", "content": "The primary purpose of data storage is to ensure the consistency of data reading and writing. Naturally, mean squared error (MSE) is a widely accepted loss function that quantifies the average deviation between the reconstructed binary data stream and the original data. However, conventional MSE cannot fully address the errors caused by information loss during representation learning. Moreover, to ensure data integrity, RSRL incorporates RS codes as an error-correction measure that is good at handling burst errors (a series of adjacent errors). In contrast, random errors (random single-bit errors) generally exist in DNA storage channels. Therefore, to fully utilize the error-correction capability of the RS codec, random errors in DNA storage have to be transformed into burst errors. To address these two issues, we introduce an additional mask operation to MSE loss, and thus propose MASK-MSE loss based on RS codes, which guides the reduction of learning efficiency for a specific integer block of the current tensor during the learning process, concentrating errors within this block.\nLet Z denote the ground truth data tensor, 2 represents the predicted tensor (i.e., the output representation learned from Y), M and N denote the mask tensor and the total number of elements in the tensor, i and j are the indices of the elements in the tensors. $M_{ij}$ is the mask value at position(i, j). If $M_{i,j} = 1$, the loss is computed at corresponding position. Otherwise, the loss regarding $Z_{i,j}$ is"}, {"title": "3.2.2 Learning single-stranded representations", "content": "It is known that DNA and RNA with stable structures can generally carry genetic information with minimized errors in transcription and translation [14]. In this paper, we introduce single-stranded loss functions to endow the learned representations with the previously mentioned properties of stable structures. Here, we formulate a single-stranded loss by mainly considering GC content and hairpin structure. The proposed single-stranded loss will be computed based on the DNA sequences that are transcoded from the learned representations according to Table 7 in the Appendix (i.e., sequence l is \u017d\u012b in 2 after transcoding). Let G(l) and H(l) denote the GC content and hairpin structure of the sequence l, $G^*$ and $H^*$ denote the target values of G(l) and H(l), which are 50% and 0, respectively. Therefore, our goal is to formulate a loss that can minimize the difference between G(l) and $G^*$, and that between H(1) and $H^*$.\nSince there are more hydrogen bonds between bases G&C than between A&T and keeping the bases evenly distributed is beneficial to the stability of the DNA sequence [21], we use the GC content as one of the learning objectives. The GC content of each DNA sequence transcoded from the corresponding representation is computed as the following:\n$G(l) = \\frac{G + C}{|G| + |C| + |A| + |T|} \u00d7 100%$,\nwhere | | is defined as the sum of the number of bases in each DNA sequence.\nA hairpin structure forms a hairpin-like shape in which two base pairs are bonded together by hydrogen bonds to form a loop (Fig. 3), which increases the error rate in reading and replicating DNA storage data [15]. Therefore, we aim to form a loss that can minimize the hairpin structure in learned representations. Hairpin structures have two important parameters, i.e., the minimum stem region $S_{min}$ and the minimum ring region $R_{min}$. In calculating the probability of forming a hairpin structure of different sizes at each position of the sequence, the first consideration is the result of forming a hairpin at position i with R ring and S stem region. A hairpin structure is considered to be formed if more than half of $l_{i\u2212s}\u00b7\u00b7\u00b7l_{i}$ and $l_{i+r}\u00b7\u00b7\u00b7l_{i+r+s}$ are hybridized. For each sequence transcoded from the learned representation, the number of existing hairpin structures can be computed as follows:\n$H(l) = \\frac{1}{2} \\sum_{s=S_{min}}^{(L-R_{min})/2} \\sum_{r=R_{min}}^{L-2s}  \\sum_{i=1}^{L-2s-r} \\sum_{j=1}^{s} T(bp(l_{s+i-j},l_{s+i+r+j-1}),\\frac{s}{2})$,\nwhere s is the stem length, $S_{min}$is the set minimum stem length. r is the ring length, $R_{min}$ is the set minimum ring length, and L denotes the length of the DNA sequence. $T(\u00b7)$ is the threshold function."}, {"title": "4 Experimental evaluation", "content": "In this section, we validate the effectiveness of the proposed RSRL by comparing it with strong baselines on real-world tasks of multi-modal data storage. Besides, the unique properties of the proposed approach are also revealed by ablation studies."}, {"title": "4.1 Compared baselines", "content": "We compare RSRL with nine strong baseline approaches, which can be divided into two categories according to the used coding methods. Church [8], Goldman [11], Grass [12], Blawat [2], DNA Fountain [9], Yin-Yang [21], and HL-DNA [16] are coding theory-based DNA storage methods. DJSCC [30] and DNA-QLC [35] are learning-based DNA storage approaches. More details of the used baselines for comparison have been illustrated in Appendix B."}, {"title": "4.2 Tasks of DNA storage and experimental settings", "content": "DNA storage tasks Due to the cost of DNA storage, current baselines are often experimented at KB/MB data volume levels [9, 21]. Following the data volume settings of previous studies, we evaluate the storage performance of all approaches using five files of diverse modalities, including images, PDFs, and text files. For fair comparisons, all the experiments are conducted at the binary data level. Thus, the file type has basically no effect on the performance, except in the case of lossless reading and writing. In the main content of this paper, we report the results regarding DNA storage for PDF files. More results showing the proposed RSRL performs similarly to the PDF storage tasks have been reported in Appendix D.\nExperimental settings To fulfill the task of multi-modal DNA storage, the proposed RSRL performs RS(64, 48) to pre-coding in the GF(28) field. The input dimension of the RS encoder is M * 48. The input files are first converted to matrix form, and the output dimension is M * 64 after being coded by RS. After reshaping the dimension of the file matrix to N * 32 * 64 vector, it serves as input to a Transformer with two layers and four heads, which will learn representations for the subsequent DNA storage tasks. The learned representations are then encoded as DNA sequences according to Table 7. Hyperparameters a and \u1e9e in biologically stabilized loss functions are set to 16.67 and 0.058, respectively, determined through cross-validation. As for the settings of compared baselines, we use the ones recommended in previous studies. In Appendix B, we provide the settings of all baselines."}, {"title": "4.3 Evaluation metrics", "content": "The performance of DNA storage mainly involves data consistency and efficiency during read/write process, and stability of the encoded DNA sequences. In our experiments, data consistency can be directly evaluated by checking whether the learning and DNA encoding process is lossless. Data read/write efficiency is evaluated by encoding methods, net information density, error rates, and coding speed. As for the metrics of stability, we use minimum free energy (MFE) and melting temperature (Tm) to evaluate all approaches in our experiment. These evaluation metrics can comprehensively reveal the performances of all approaches. We provide the detailed definitions of these used metrics in Appendix E."}, {"title": "4.4 Comprehensive analysis of DNA storage performance", "content": "We compare the overall performance of DNA storage obtained by the proposed RSRL and other advanced approaches. The corresponding results have been listed in Table 1. As the table shows, RSRL demonstrates a significant advantage in net information density compared to lossless coding theory-based methods. Compared to Goldman, RSRL achieved an 18% improvement in Net information density. Although learning-based approaches like DNA-QLC may obtain a higher net information density, they are not applicable for multi-modal data storage as their representation learning is not lossless. Besides, DNA-QLC and DJSCC are computationally demanding as they stack many CNN layers for learning data representations. The proposed RSRL is the only learning-based model that can efficiently learn lossless representations with desirable net information density. And RSRL is the only learning-based model applicable for storing multi-modal data in DNA.\nRegarding data loss, both DJSCC and DNA-QLC use convolution to compress the input image. It is known that this processing introduces loss, which we quantify using the Structural Similarity Index (SSIM). In the best-case scenario, the SSIM values for images stored by DJSCC and DNA-QLC are 0.841 and 0.926, respectively, both falling short of 1. In contrast, the proposed RSRL achieves lossless storage of multimodal data, as shown in Table 1. Obtaining such results is mainly because"}, {"title": "4.5 Thermodynamic comparisons of coding", "content": "Thermodynamic changes can better reflect the essence of biochemical reactions, consistently inter-weaving with biochemical reactions, thus more directly manifesting the stability and performance of DNA sequences. In DNA storage tasks, DNA sequences can be evaluated based on thermodynamic properties such as free energy, melting temperature, and GC content. In our experiments, we compare RSRL with other baseline methods in terms of minimum Gibbs free energy, melting temperature, GC content, and local GC content. The results are presented in Figs. 5-8."}, {"title": "4.6 Ablation study", "content": "In this subsection, we conduct ablation studies to show the effect of each module in the proposed RSRL on DNA storage tasks. Specifically, we systematically analyze the effects of MASK-MSE and biologically stabilized loss functions on the performance of RSRL. The results have been listed in Table 2. We first compare RSRL without MASK-MSE (RSRL-No-MASK) and RSRL. Results indicate that RSRL-No-MASK fails to achieve lossless data reconstruction, losing approximately 9.6% of data blocks. Also, there is an evident performance gap regarding MFEave and GCave when comparing RSRL-No-MASK with RSRL. We then evaluate the performance of RSRL without biologically stabilized functions (RSRL-No GC&pair). Despite the combined effect of Mask and RS codes, this version of RSRL successfully recovered data but exhibits a noticeable decline in thermodynamic results. Compared to RSRL, the MFEave of RSRL-No GC&pair is increased by almost 50%, indicating insufficient stability in DNA sequence double-strand binding, which may lead to errors during DNA storage. At last, we evaluate the performance of the variant only adopting the conventional MSE loss (RSRL-No GC&pair&mask). Although it surpasses RSRL-No MASK in terms of reconstruction rate, it still fails to reconstruct the data completely. Due to the use of"}, {"title": "5 Conclusion", "content": "In this paper, we have proposed Reed-Solomon coded single-stranded representation learning (RSRL), a novel end-to-end model for learning represnetations for DNA storage. Unlike existing learning-based approaches to DNA storage, RSRL incorporates an error-correction codec and stable biological structures into the process of learning representations for data storage. Representations learned by RSRL possess remarkable structural properties like biomolecules in biont and are, therefore, highly durable, dense, and lossless for subsequent storage tasks. The proposed RSRL has been compared with both coding theory and learning-based methods for DNA storage. The obtained experimental results demonstrate that RSRL can outperform prevalent approaches in the tasks of representation learning for multi-modal data. In the future, we will further improve the proposed RSRL by identifying more efficient strategies to incorporate error-correction codes into neural networks and formulating more efficient biologically informed loss functions for model training."}, {"title": "A More details on DNA data storage", "content": "The International Data Corporation (IDC) predicts that the capacity of the global data circle will increase to 175 zettabytes by 2025. Current storage systems are faced with high cost and huge energy consumption. In contrast, DNA is a highly parallel, low-cost storage medium with great storage potential. Different from traditional storing medium that are replaced every few years, DNA is very stable in decades or centuries, and can be easily replicated and stored based on methods of molecular biology.\nThere are five steps in DNA data storage, including encoding information into DNA codewords (encoding), synthesizing DNA from the sequence (writing), storage, DNA sequencing (reading), and decoding. For encoding, fountain, rotation, and Huffman code are commonly used methods. Methods that are based on modern AI techniques have also been proposed for encoding purposes. Popular techniques for DNA synthesis can then be used to synthesize the sequences storing real-world data in DNA. After that, DNA molecules of real-world data can be stored in test tubes or in the form of dry powder for a very long period. To read the data from DNA, prevalent sequencing methods, e.g., Illumina sequencing and nanopore sequencing can be used. After processing the sequenced DNA with clustering and assembly techniques, the original data can finally be recovered by decoding, which is completed inversely by the previously used encoding method.\nCurrently, the main bottlenecks existing in DNA storage are cost and read/write latency. DNA storage is costly due to DNA synthesis and sequencing. Issues of read/write latency in DNA storage are mainly due to codec and corresponding biotechnologies. It is seen that efficient and robust codec algorithms can reduce not only the cost by improving the encoding rate but also the read-write latency by reducing errors in DNA storage. In this paper, we propose a novel learning-based model that can significantly reduce the read and write delay from the codec stage. Besides, the proposed model provides an economical solution to DNA storage by reducing the error rate and improving the encoding rate."}, {"title": "B More details on the baselines", "content": "Based on the coding method, the baselines can generally divided into two categories, i.e., coding theory based on learning based approaches. Methods based on coding theory have the advantage of predictable results and complete proof of theory.\n\u2022 Church [8]: This method proposes encoding one binary bit per base (A or C for 0, G or T for 1) to encode bitstreams directly into DNA sequences.\n\u2022 Goldman [11]: This approach uses the Huffman trinomial tree to analyze binary files to be transcoded based on the frequency of occurrence of individual bytes. The binary sequences (0/1) are converted to the corresponding ternary sequences (0/1/2), which are subsequently mapped to the corresponding DNA sequences according to the ternary mapping model.\n\u2022 Grass [12]: This approach combines the Galois field with the DNA codon wheel style base mapping rules to propose a coding algorithm that avoids the length of a single base being greater than three.\n\u2022 Blawat [2]: This method uses the byte as the basic unit of base conversion and maps eight bits of information into five nucleotides. The first six bits are fixed conversion portions mapped to nucleotides A, C, G, and T. The last two bits are optional conversion portions. This design limits the maximum length of the homopolymer to three.\n\u2022 DNA Fountain [9]: This approach preprocesses binary information into a series of non-overlapping fragments, randomly selects a variable number of sequence fragments for heterogeneous operation based on Luby Transform, and appends a fixed-length seed to form a droplet.\n\u2022 Yin-Yang [21] : This method provides a dynamic combinatorial coding scheme that combines two independent coding rules (called \"yin\" and \"yang\") into a single binary sequence, thus compressing two bits into a single nucleotide.\n\u2022 HL-DNA [16]: This approach proposes a hybrid lossy and lossless image storage scheme implemented by quaternary mapping. HL-DNA uses about 300 nt as the length of DNA strands and four extra nucleotides, and it is a hybrid lossy/lossless encoding scheme."}, {"title": "C More analysis and discussions on the performance of DNA storage", "content": "Here, we further analyze the results in Table 1. Since higher biological stability of DNA sequences can reduce the probability of errors occurring during the storage process, this section mainly analyzes the GC content, homopolymers, and hairpin structure of the encoding results.\nGC content and homopolymers Most storage schemes can meet the GC content constraint. However, the fluctuations (large deviations) of GC content obtained by Grass and Blawat are evident. Previous studies have shown that deviations of GC content have a significant effect on the melting temperature [24]. Thus, the PCR yield and sequencing accuracy of these two approaches are reduced. In contrast, RSRL, DNA-QLC, and HL-DNA perform robustly when evaluated by GC content (50%), demonstrating that these approaches may cause fewer errors during DNA sequencing. Homopolymers during synthesis can cause difficulties, while during sequencing, they may result in gaps such as AAAA being misread as AAA, affecting data consistency. However, overly strict homopolymers could impact base utilization since the total number of base combinations is fixed. RSRL limited homopolymers to around three, achieving a good balance between base utilization and data consistency in reading and writing.\nHairpin structure A hairpin structure is a distinctive secondary structure in DNA, where two base pairs are held together by hydrogen bonds [15]. The hairpin structure can increase the error rate when reading and replicating in DNA storage, thus influencing the performance. It can be seen from Table 1 that RSRL is one of the few approaches to DNA storage, considering the impact of hairpin structures. Although DJSCC can satisfy GC content and homopolymer constraints through learning, its deviations of GC content and homopolymer limitations are higher than those of RSRL. DNA-QLC attempts to force the learned representations to satisfy the biological constraints by post-processing. Thus, it is not an end-to-end learning approach. Moreover, existing learning approaches like DJSCC and DNA-QLC, can only store multimedia data, e.g., image data, due to the information loss during model training. Compared with existing learning-based approaches, the proposed RSRL is the first end-to-end model that considers stable properties of biological structures. Thus, RSRL performs much better than existing learning-based methods regarding diverse metrics of DNA storage."}, {"title": "D Additional results of multimodal data encoding", "content": "Although any data type is binary at input to the model, RSRL has no bias to the data type, that is, the data type has minimal influence on the encoding result. However, in order to further illustrate the applicability of RSRL to multi-modal data, we also verified this point through experiments, as shown in Tables 3-5. The evaluation metrics are the same as the main text, and the results show that RSRL is unbiased in terms of data types. In particular, the unit of encoding and decoding time is bits/s."}, {"title": "E Details on the metrics of DNA thermodynamics", "content": ""}, {"title": "E.1 Minimum free energy", "content": "The Gibbs Free Energy contains two important thermodynamic parameters, entropy change and enthalpy change: $\u2206G = \u0394\u0397 \u2013 T\u2206S$, where T is the temperature. The minimum Gibbs free energy is the minimum value of the standard free energy of all possible secondary structures in the DNA sequence. Secondary structures with lower Gibbs free energy are more stable. Therefore, the minimum free energy (MFE) could be used to assess the quality of DNA sequences. Let $\u2206G(s, s')$ denote the Gibbs free energy value of DNA sequence s, where s' is its complementary strand, which could be calculated using the PairFold method [25]:\n$MFE = min{AG(u, v), \u2206G(u, v'), \u2206G(u', v')}$,\nwhere AG(u, v), $\u2206G(u, v')$, and $\u2206G(u', v')$ are the Gibbs free energy between u and v, and that between their complements, respectively. Given the the number of sequences and their lengths, the average MFE (MFEave) can be computed as the following:\n$MEF_{ave} = \\frac{1}{n} \\sum_{i=1}^{n} \\frac{MFE_i}{L_i}$,\nwhere n is the number of DNA sequences, and $L_i$ is the length of DNA sequence i. Accordingly, we are able to obtain the standard deviation of MFE of each approach (MFEstd)."}, {"title": "E.2 Melting temperature", "content": "In this paper, the melting temperature (Tm) is calculated as the following:\n$T_m = \u0394\u0397\u00b0/(AS\u00b0 + Rln C_T) \u2013 273.15$,\nwhere R is the gas constant (1.987 cal/K\u00b7mol), $C_T$ is the total oligonucleotide strand concentration, \u0394\u0397\u00b0 and AS\u00b0 can be obtained by search the Unified oligonucleotide table [26]. The Tm represented the temperature required for a DNA sequence to transition from a double-stranded structure to a single-stranded structure. When Tm falls within the range of (85-95), we should pay more attention to the standard deviation of Tm (Tmstd), as stable Tm values indicate orderly progression of assembly and PCR processes. Then, A smoother data reading and writing process in DNA storage can be achieved."}, {"title": "F Network structure of RSRL and other learning-based approaches", "content": "In this section, we compare the network structure of the proposed RSRL with other learning-based approaches, including DJSCC [30] and DNA-QLC [35]. Regarding computational complexity, we mainly consider Total Madd and Total Flops, which represent the number of multiply-accumulate and"}, {"title": "G End-to-end training", "content": "In this section, we provide more details on building the proposed RSRL. In the encoding phase, a file is first processed into a binary data stream. Since the domain of RS codes is characters, the binary data stream is grouped and converted into hexadecimal characters. RS codes are performed on the hexadecimal characters in the Galois domain of 28. The encoding result is then reshaped as 32*32*64 as an input to the Transformer, which has a 2-layer encoder with four multi-head attention. The Transformer can learn a 32*32*56 low-dimensional representation for each file, which is normalized to 0 or 1 by a liner layer. The last 8 bits of the representation (an 8-bit binary could be transcoded into 1-bit hexadecimal characters) are masked for the subsequent error correction. Then, the normalized representation is transcoded to a DNA sequence by Table 7.\nFor the decoder, the input is a DNA sequence, inverted to a binary matrix by Table 7. The structure of the decoder is similar to that of the encoder, except that a masking mechanism and encoder-decoder attention are used to make the decoder pay more attention to the different parts of the input sequence. The raw tensor vector output from the Transformer decoder is converted into hexadecimal characters and fed into the RS decoder for decoding. Due to the Mask operation at the time of encoding, the errors are concentrated in the last 8 bits of the tensor so that RS codes can correct all errors in the last 8 bits. Finally, the RS decoded hexadecimal characters are converted to a binary stream to complete the reconstruction of the original file."}]}