{"title": "TIPS: Threat Actor Informed Prioritization of Applications using SecEncoder", "authors": ["Muhammed Fatih Bulut", "Acar Tamersoy", "Naveed Ahmad", "Yingqi Liu", "Lloyd Greenwald"], "abstract": "This paper introduces TIPS: Threat Actor Informed Prioritization using SecEncoder, a specialized language model for security. TIPS combines the strengths of both encoder and decoder language models to detect and prioritize compromised applications. By integrating threat actor intelligence, TIPS enhances the accuracy and relevance of its detections. Extensive experiments with a real-world benchmark dataset of applications demonstrate TIPS's high efficacy, achieving an F-1 score of 0.90 in identifying malicious applications. Additionally, in real-world scenarios, TIPS significantly reduces the backlog of investigations for security analysts by 87%, thereby streamlining the threat response process and improving overall security posture.", "sections": [{"title": "1 Introduction", "content": "Since the introduction of transformers [47], foundational models have become pivotal, significantly influencing various facets of our lives. Prominent examples include encoder-only models like BERT and DeBERTa [13,24], as well as decoder-only models such as GPT, Gemini, and Llama [15, 38, 46]. These models leverage extensive datasets and possess the capability to reason across diverse tasks, transforming fields such as natural language processing, computer vision, and more.\nSecurity has always been at the forefront of adopting machine learning-based solutions, addressing tasks such as anomaly detection, phishing detection, intrusion detection, and various other critical functions. With the general availability of large language models (LLMs), we have already begun to see their integration into everyday security tasks, including incident enrichment, summarization, vulnerability detection, and log analysis [7, 10\u201312, 17, 23,33,35].\nDespite the notable progress, security presents unique challenges when adopting language models. Universal challenges include hallucinations, context length limits, and the reasoning capabilities of language models. Additionally, security-specific challenges arise, such as dealing with logs and telemetry data, which often differ from natural language texts and are massive in volume.\nMoreover, malicious threat actors (TAs) continuously exploit vulnerabilities to compromise systems and applications, aiming to harm or steal intellectual property. These actors vary in their motivations, with some driven by financial gain (e.g., ransomware groups) and others by political motives (e.g., state-sponsored actors). Their techniques also vary, ranging from complex social engineering to exploiting existing weaponized vulnerabilities.\nThis paper introduces TIPS, a novel approach for threat actor-informed prioritization of applications using SecEncoder, a security-specific language model [10]\u00b9. Enterprise applications serve as crucial gateways for accessing vital resources within a company through mechanisms known as service accounts or principals. These principals theoretically have access to numerous resources necessary for the application's operation, such as Key Vault, Emails, or Storage. Threat actors (TAs) often exploit this mechanism to compromise the service principal of an application, enabling lateral movement to other resources or information theft.\nWhenever an action is performed on a resource, an event is logged in the resource's databases, providing crucial breadcrumbs for monitoring and auditing suspicious activities. For service principals, sign-in logs are particularly important as they offer a gateway for accessing resources, providing critical context for identifying compromises. TIPS focuses on sign-in logs as the primary telemetry, while also utilizing other log types as necessary. Although the primary focus is on application investigation and risk-based prioritization using service principals, the concepts and methodologies are also applicable to other entities such as users or devices.\nTo achieve this objective, TIPS employs an encoder-only small security specific language model (SecEncoder) alongside a decoder-only Large Language Model (GPT-4 Turbo) to analyze raw logs related to applications. This dual-model"}, {"title": "2 Related Work", "content": "Our work finds similarities to multiple lines of research. We discuss them below, highlighting the main differences between this and prior work, and the gaps we aim to fill.\nSince TIPS essentially prioritizes applications for investigation, we first review existing cybersecurity risk assessment methods, reflecting on the frameworks and approaches used. We categorize these approaches into subjective, impact-focused, vulnerability-focused, and adversary-focused.\nSubjective approaches rely on the assessor's expertise, often using frameworks like NIST SP 800-30, combined with interviews and questionnaires [31,43,44]. However, these can be limited by the assessor's knowledge. Impact-focused approaches prioritize critical assets and their potential impacts, using frameworks like ISO 27005 [4, 22]. These methods may not fully account for threat likelihood or actor behavior, but some studies aim to address these gaps (such as [29]). Vulnerability-focused approaches, such as [18], [9] and [1], use metrics like CVSS and vulnerability scanners to assess risks, but tend to lack threat intelligence data.\nMost relevant to our work is adversary-focused approaches, which focus on understanding threat actors, using frameworks like NIST SP800-30 [21, 27, 28]. Some studies incorporate threat metrics and cyber kill chain concepts [16,25], but do not fully integrate threat actor attributes. Prior work considered the MITRE ATT&CK framework as a valuable resource for modeling cybersecurity threats [19], but its integration into risk assessment is often incomplete. We argue that, while there is significant research on cyber risk assessment, there is a need for more comprehensive approaches that consider behavioral metrics of threat actors and integrate frameworks like MITRE ATT&CK more thoroughly.\nThreat intelligence is also related to the problem studied in this paper. Research has highlighted issues with the coverage, timeliness, and accuracy of (open) threat intelligence (TI), including abuse feeds and blocklists [34, 45]. Efforts to formalize and measure the quality of TI have introduced metrics for coverage, accuracy, timeliness, relevance, overlap, latency, and volume [20, 30, 41], with studies on how to present TI quality to analysts [42]. The use of high-quality TI is also critical, with organizations facing challenges in interpreting TI, managing large volumes of information, and addressing false positives [39]. Despite the operational issues similar to those of blacklists, TI offers high-level contextual information that could address these problems [6]. Nevertheless, a SANS survey in 2019 revealed that security operations analysts tend to value low-level indicators of compromise over high-level tactics, techniques, and procedures (TTPs), likely due to their focus on enriching alerts with technical details [8]. Our work takes advantage of both approaches, by enriching alerts with TTPs relevant to a treat actor.\nRecent research has highlighted the potential of Large Language Models (LLMs) in addressing various cybersecurity challenges. LLMs have been effectively used in software security to detect vulnerabilities from descriptions and source code, and to create security patches and exploits, showing high accuracy in these tasks [11, 12, 17]. They have also been applied to higher-level security tasks, such as analyzing security and privacy policies to classify documents and identify potential policy violations [23,35]. In network security, LLMs have proven capable of detecting and classifying different types of cyberattacks from network traffic data, including DDoS, port scanning, and botnet activities [2,3,37]. For malware analysis, LLMs are being used to classify malware families and detect malicious domains and URLs through textual and behavioral analysis [7,33]. Additionally, LLMs are aiding in social engineering defense by identifying phishing attempts via email content analysis [26, 40]. Overall, LLMs are becoming an integral part of cybersecurity, offering the ability to process vast amounts of data and learn from it. We extend prior work by leveraging LLMs for threat actor informed application prioritization."}, {"title": "3 Threat Model for Compromising an Application", "content": "In this section, we outline a potential threat model for compromising an application in Azure. While this model is specific to Azure, it is generally applicable to any cloud provider, such as AWS or Google Cloud, as they all support similar paradigms.\nFigure 1 illustrates a potential path through which an application can be compromised in Azure. Identity and access management (IAM) for a typical application in Azure is handled through Microsoft Entra [36], which serves as a gateway for authentication and authorization. The application itself may have an identity, known as a service principal, in addition to the users accessing the application. For the application to function properly, this service principal typically needs access to various resources such as Azure Key Vault, Azure Storage, or Microsoft Graph APIs. These accesses can be configured through the service principal with various levels of privileges.\nA threat actor usually monitors public resources to seek vulnerabilities that can be exploited to gain access to an application (Reconnaissance). A forgotten credential on GitHub may provide such an opportunity for the actor to access the application. An expired credential may also leave traces in the form of certain error messages. Once the malicious actor gains access to the application via stolen or forgotten credentials, they may seek to escalate privileges by exploiting managed identities with overly permissive roles. If the application is configured with extensive privileges, this can potentially be abused to access additional resources and allow the threat actor to move laterally within the system. The threat actor can potentially create additional users and establish persistence for a longer presence. This presence would allow the malicious actor to exfiltrate data and sensitive information.\nOn the defensive side, when a user or service principal accesses the application, they must go through IAM, in this case, Entra, and leave a trace of activities that can be analyzed offline. Similarly, each resource, such as Key Vault, Storage, and Microsoft Graph, also maintains logs to track the activities of users and service principals. These logs are invaluable for detecting malicious activities and hunting for potential abuses. TIPS leverages these trails to identify threats and prioritize them for security analysts."}, {"title": "4 System Design", "content": "TIPS is designed with a modular architecture, consisting of five main components as shown in Figure 2: Language Models, Data Retriever, Data Reducer, Data Reasoner, and Reviewer. The following sections explain each component in detail."}, {"title": "4.1 Language Models", "content": "TIPS relies on two state-of-the-art language models: the decoder-only GPT-4 Turbo model and the encoder-only SecEncoder model [10]\u00b9. GPT-4 Turbo is an enhanced version of the GPT-4 model, featuring several significant improvements. One of the most notable enhancements is its larger context window, which can handle up to 128,000 tokens, allowing it to process and retain more information in a single interaction. Additionally, GPT-4 Turbo is more cost-effective compared to its predecessor. These improvements make GPT-4 Turbo an excellent choice for working with logs and telemetries, as it can efficiently manage large volumes of data while maintaining high performance and cost efficiency.\nSecEncoder is a specialized small language model designed to address the unique challenges of cybersecurity. Unlike general-purpose language models, SecEncoder is pretrained exclusively on a large corpus of security logs, capturing various events and activities related to security incidents and operations. This domain-specific pretraining enables SecEncoder to outperform traditional language models, such as BERT and OpenAI's embedding model (text-embedding-ada-002), in tasks related to security log analysis [10].\nSecEncoder employs an encoder-only architecture based on the DeBERTa-v2 model, which enhances BERT by incorporating a disentangled attention mechanism and an improved mask decoder. The model is pretrained using a customized masked language modeling (MLM) loss that focuses on learning the content of security logs. The training dataset comprises a diverse set of logs from both public and private"}, {"title": "4.2 Data Retriever", "content": "This component is responsible for retrieving relevant telemetry and details about the application. The data resides in Kusto clusters, and Kusto Query Language (KQL) queries are used to fetch this data. The data retrieval process works in multiple steps.\nIn the first step, the component pulls the sign-in logs, which serve as the primary entry point for any subsequent activities. Next, it checks for access to other resources such as Microsoft Graph (MSGraph) or Azure Key Vault. If access to these resources is detected, relevant telemetry from those resources is also fetched, even if they reside in different clusters.\nThe observed IP addresses from these resources are then extracted, combined, and enriched with various details, including city, ISP, and proxy information. Additionally, other application-related data is retrieved, particularly the application's permission details, such as which resources it has access to, and credential details, including creation, rotation, and expiration dates. Relevant alerts and incidents from other detectors, if they exist, are also gathered.\nAll of this data is used by downstream components to analyze the application for potential malicious activities. This comprehensive approach ensures that any suspicious behavior is detected and addressed promptly, enhancing the overall security posture of the application."}, {"title": "4.3 Data Reducer", "content": "This component addresses the critical need to reduce data volume. Some applications generate an excessive amount of logs that cannot be accommodated within the LLM prompt, rendering them unusable directly. To overcome this challenge, TIPS employs two novel approaches from SecEncoder: LogSubsampling and LogPatternDetection [10]."}, {"title": "4.3.1 LogSubsampling", "content": "Logs are a rich source of security data, providing valuable insights into system activities and potential threats. However, security analysts face significant challenges when investigating large quantities of raw logs and transforming them into actionable insights and recommendations. Generative models like GPT can assist in this transformation by turning raw data into meaningful insights and recommendations. However, due to size limitations, language models cannot effectively process vast amounts of raw logs in their entirety.\nWhile generic methods exist for breaking large datasets into smaller chunks and combining results, these methods often fail to account for the varying importance of different data chunks. This is where LogSubsampling, powered by SecEncoder embeddings, comes into play. LogSubsampling effectively selects chunks of data that retain the critical information needed for an investigation, while pruning away redundant and uninformative data. This ensures that the most relevant and diverse set of logs is chosen for analysis."}, {"title": "4.3.2 LogPatternDetection", "content": "LogPatternDetection is a tool designed to identify anomalies in log data. It employs an unsupervised implementation of the IsolationForest algorithm, utilizing SecEncoder embeddings as a featurizer.\nThe IsolationForest algorithm operates by creating a random subsample of the dataset, which is then used to construct an isolation tree. Each tree is built using SecEncoder embedding as a feature, with split values selected randomly. The resulting binary tree is analyzed to identify isolated points, which are expected to have fewer splits, indicating potential anomalies. This method is effective for anomaly detection in logs because it does not require labeled data and can handle high-dimensional datasets efficiently."}, {"title": "4.4 Data Reasoner", "content": "This component utilizes condensed data from the Data Reducer, along with other application-specific details, to analyze activities and determine a triage priority level. It relies on a specified Threat Actor (TA) profile, which can range from generic MITRE ATT&CK techniques to detailed subtechniques. The Data Reasoner uses this profile to match against the observed activities. Appendix A provides an example of a TA profile defined in YAML format.\nThe primary reasoning engine for TIPS is a Large Language Model (LLM), specifically GPT-4 Turbo, which features an extensive context window of 128,000 tokens. This capability is crucial for processing raw logs and other extensive data inputs."}, {"title": "4.5 Reviewer", "content": "Large Language Models (LLMs) are generally effective in analyzing given data and arriving at conclusions. However, it has been observed that as the context provided to an LLM increases, its effectiveness can diminish, leading to overlooked details. This is a known limitation of state-of-the-art LLMs [32].\nTo mitigate this limitation, TIPS employs a secondary step to ensure that no critical details are missed. This is achieved through a reviewer component, which utilizes natural language-defined checks and codes to verify the output of the Data Reasoner.\nChecks include guidelines such as double-checking whether certain IP addresses are correctly classified as benign based on specific criteria. These checks ensure that the initial analysis by the LLM is accurate and comprehensive.\nCodes involve the use of regular expressions and other programming constructs to validate and verify the report. For instance, regular expressions can be used to ensure that the report highlights high-priority sensitive resources. These codes act as an additional layer of scrutiny to catch any details that might have been missed by the LLM.\nThe Reviewer component ensures that the final output is robust and reliable. By incorporating both checks and codes, it validates the findings of the Data Reasoner, ensuring that the report is thorough and can be confidently used in the downstream triage process.\nThis two-step approach enhances the reliability of TIPS's analysis by addressing the inherent limitations of LLMs when dealing with large contexts, ensuring that critical details are not overlooked."}, {"title": "5 Evaluation", "content": "This section provides a comprehensive discussion on the data, detailing the methodology used for evaluation and the experiments conducted."}, {"title": "5.1 Dataset", "content": "We have curated 93 applications, 32 of them are malicious and 61 are benign apps. We further divide the benign apps into two categories: benign-nonsuspicious 16 apps and benign-suspicious 45 apps. Definitions of the different categories are described in Table 1."}, {"title": "5.2 Methodology", "content": "TIPS assigns a priority score for each application based on a comprehensive list of criteria. These criteria are detailed in Table 2 and Table 3, which reflect two distinct sets of criteria, differing in both breadth and scope. The first set (TIPSGeneral) constitutes our baseline, which encompasses a wide range of MITRE ATT&CK tactics, providing an extensive evaluation framework. In contrast, the second set (TIPS Focused) is more concise and specifically tailored to the activities of the Threat Actor (TA), focusing on targeted aspects of their behavior.\nThese criteria have been meticulously defined based on the extensive experience and domain knowledge of security"}, {"title": "5.3 Experiments", "content": "We evaluate TIPS across multiple dimensions. In Section 5.3.1, we discuss the overall performance of TIPS and provide a comparative analysis between versions TIPSGeneral and TIPS Focused. Section 5.3.2 delves into the performance specifics for malicious applications, highlighting key metrics and observations. Section 5.3.3 focuses on benign applications, with an emphasis on precision and recall metrics. Further, Section 5.3.4 explores the performance metrics in greater detail for various benign categories, as outlined in Table 1."}, {"title": "5.3.1 Overall Performance", "content": "Figure 4 illustrates the overall performance of TIPS using the F1-score metric. Each bar group on the x-axis represents the count of sign-in logs greater than the specified number. For instance, the group labeled \"<5\" indicates performance for applications with at least 5 or more sign-in log counts. Each bar, distinguished by different colors, represents various minimum thresholds of priority scores used for predicting whether an application is malicious or benign.\nFrom Figure 4, it is evident that there is a slight increase in performance as the required number of log counts rises from 0 to at least 5. This trend is expected, as a higher number of logs provides more context for the application, enabling TIPS to make more informed decisions. When considering a minimum of 5 logs for an application and averaging the performance for priority scores of 3, 4, and 5 or above as malicious, TIPS Focused achieves an F1-score of 0.90, whereas TIPSGeneral achieves an F1-score of 0.78.\nWe attribute this difference to the fact that TIPS Focused employs a more targeted and straightforward priority calculation list compared to TIPSGeneral. However, this advantage comes with a trade-off: TIPSFocused requires more prior knowledge, which may not be suitable for more complex investigations. Despite this, the higher F1-score of TIPSFocused indicates its effectiveness in scenarios where sufficient prior knowledge is available."}, {"title": "5.3.2 Malicious Applications Performance Details", "content": "Figures 5 and 6 illustrate the precision and recall metrics for identifying malicious applications for TIPSGeneral and TIPS Focused. By averaging the priority scores of 3, 4, and 5, with a minimum of 5 logs, we achieve a precision of 0.74 and a recall of 1.00 for TIPS Focused, and a precision of 0.58 and a recall of 0.94 for TIPSGeneral. Lowering the priority level threshold consistently introduces more false positives in both versions.\nIn both versions, TIPS consistently achieves high recall, demonstrating its strength in not missing actual malicious applications. As discussed in the previous section, the shorter and more targeted priority criteria of TIPS Focused outperformed the longer and broader priority criteria of TIPSGeneral. This indicates that a more focused approach is more effective in accurately identifying malicious applications while maintaining a high recall rate."}, {"title": "5.3.3 Benign Application Performance Details", "content": "Figures 7 and 8 illustrate the precision and recall metrics for benign applications using TIPSGeneral and TIPS Focused. By averaging the priority scores of 3, 4, and 5, with a minimum of 5 logs, TIPS Focused achieves a precision of 1.0 and a recall of 0.85. In comparison, version TIPSGeneral achieves a precision of 0.97 and a recall of 0.69.\nThe near-perfect precision of TIPS allows security analysts to confidently ignore applications classified as benign, significantly reducing their workload. This efficiency is further demonstrated in an internal real-world study, where 412 suspicious applications were analyzed by TIPS. Randomly selected applications classified as benign by TIPS were picked and verified for accuracy by security analysts. All of the randomly selected applications were indeed benign, resulting in an approximately 87% reduction in the number of applications that analysts needed to investigate. This substantial decrease in the analysts' queue translates to a more streamlined and efficient security process, enabling analysts to focus on more critical tasks."}, {"title": "5.3.4 Different Categories of Benign Applications", "content": "In this section, we investigate whether different types of benign applications pose any challenges for TIPS. Our goal is to determine if the diversity in benign application types affects the performance and accuracy of TIPS in classifying them correctly. By analyzing various categories of benign applications, we aim to identify any potential difficulties or inconsistencies that may arise. This analysis will help us understand the robustness of TIPS and its ability to maintain high recall across a wide range of benign application types.\nSince this analysis is purely focusing on benign apps, we use recall as a metric to compare performances.\nBenign-Nonsuspicious Apps: Figure 9 illustrates the recall performance for TIPSGeneral and TIPS Focused. By averaging the priority scores of 3, 4, and 5, with a minimum threshold of 5 logs, TIPSFocused achieves a recall of 0.86. This indicates"}, {"title": "6 Discussion, Limitations and Future Work", "content": "In this section, we provide a comprehensive analysis of the limitations associated with TIPS, exploring the various challenges and constraints that may impact its effectiveness and usability.\nWhile LLMs provide parameters, such as the temperature setting, to mitigate this inconsistency, even setting the temperature to 0 does not entirely eliminate variability in outputs. This issue is exacerbated when dealing with large context windows, which is often the case when working with extensive logs. Research has shown that LLMs tend to struggle as the input size increases [32]."}, {"title": "6.1 LLM inconsistencies", "content": "TIPS leverages Large Language Models (LLMs), specifically GPT-4 Turbo, for its analytical processes. It is a well-known phenomenon that LLMs can exhibit inconsistent behaviors.\nTo address these inconsistencies, TIPS performs multiple analyses per application. By running these analyses several times, TIPS achieves more robust results. To determine the priority level after multiple runs, TIPS employs a majority voting system. Our observations indicate that, in most cases,"}, {"title": "6.2 LLM hallucination", "content": "Hallucination is a more challenging problem than inconsistency, as it is also hard to detect. Since we are grounding LLMs with actual data, we have observed only a limited number of hallucinations, albeit an interesting one. When the LLM is provided with sign-in logs, one of the columns is the error code, and in one instance, the code is \"ForkingIgnored.\" \nMultiple instances of the error ForkingIgnored from the IP address block fd00::b918:xxxx:xxxx:xx:xx.\nAs shown in the quote, the LLM detects this ForkingIgnored error and further interprets it as a sign of malicious behavior.\nThis is more of an engineering issue than a security concern; however, the LLM exhibits significant hallucination in this case.\nTo alleviate this issue and similar ones, TIPS relies as much on grounding as possible. TIPS includes error codes and their explanations to avoid such behaviors from LLMs."}, {"title": "6.3 LLM token size", "content": "TIPS uses GPT-4 Turbo, which has a 128K token limit (input + output). However, we have observed that this limitation causes some issues, both in terms of fitting logs into the prompt and in reasoning as the size gets larger. With all the other grounding information that TIPS passes to the prompt, we are able to fit only 500 to 1000 rows of logs into the prompt. To be safe, we cap that limit to even lower since content can vary in size based on the application.\nAnother problem that we partially attribute to the token size limitation is the LLM's reasoning capabilities. Even though the model we use is GPT-4 Turbo, which has a 128K token limit, we observe that the more we provide, the more the LLM misses out. Specifically for application analysis, one attribute that we look for in IP addresses is whether that IP has ever been used by a known, verified entity within the vicinity of the same time period. We observe that as the context gets larger, GPT has a hard time checking for these among many other things that we are asking.\nTo alleviate this and similar issues, TIPS adopts a multi-step review-based analysis, which involves making multiple LLM calls in sequence to reduce the number of reasoning tasks we want the LLM to perform. This approach has proven to be useful as we observe that subsequent calls usually correct mistakes caused by the first LLM call, albeit with an increased monetary cost.\nBy implementing this multi-step analysis, TIPS ensures more accurate and reliable results. Each step in the sequence allows the LLM to focus on a smaller subset of tasks, thereby improving its performance and reducing the likelihood of errors. This method also helps in managing the token limit more effectively, ensuring that critical information is not omitted due to space constraints."}, {"title": "6.4 Scalability and cost", "content": "TIPS relies on two foundational models: SecEncoder and GPT-4 Turbo. These models are integral to its functionality, with SecEncoder handling data reduction and GPT-4 Turbo focusing on reasoning tasks. Both models require GPUs to operate efficiently.\nSecEncoder is a small language model, consisting of 700 million parameters and based on the DeBERTa-v2 architecture. It can run on V100 NVIDIA GPUs, which are well-suited for its computational needs. On the other hand, GPT-4 Turbo is a more demanding model, necessitating the use of at least NVIDIA A100 GPUs to function optimally.\nTIPS leverages parallelization to efficiently process multiple applications simultaneously. This capability ensures that TIPS can scale effectively to handle a large number of applications, maintaining high performance and reliability even as the workload increases.\nThe costs associated with these GPUs and models are thoroughly documented in the Azure website [5], providing transparency and detailed information for budgeting and planning purposes."}, {"title": "6.5 Limitations and future improvements", "content": "TIPS was initially designed to analyze applications. However, its modular design allows for expansion to analyze various entities, including but not limited to devices, users, or any other service principals. While TIPS's results are promising, we acknowledge that the number of applications used in our experiments is limited and needs to be expanded. For further improvements, we will focus on three key areas:\nReasoning with Graphs: The initial design of TIPS relies on typical Retrieval Augmented Generation (RAG) techniques, which bring context to the prompt. To enhance TIPS's reasoning capabilities, we plan to explore the use of GraphRAG [14], which utilizes a knowledge graph derived from the underlying data to help answer questions. Various aspects will be considered, such as logs, threat intelligence (e.g., TA profiles), and the overall architecture of TIPS. This includes examining how the outputs of different components of TIPS can be integrated into GraphRAG for improved reasoning.\nReasoning with Multiple Agents: The initial design of TIPS includes multiple steps that pulls relevant data, reduce the size, reasons on it and review. LLM-based agents have proven useful in correcting mistakes and achieving better outcomes. We will explore the use of multiple agents to reduce false positives and enhance the performance of TIPS.\nData Reduction: One of the main challenges of working with logs and LLMs is the large volume of data. TIPS currently relies on subsampling and anomaly detection to focus on the data that matters. We will work to improve and optimize these aspects, which is also crucial for the system's scalability."}, {"title": "7 Conclusion", "content": "This paper introduces TIPS, detailing its design, experiments, limitations, and future work. TIPS achieves high precision and recall in detecting malicious applications by leveraging language models. In our experiments, TIPS achieved an impressive F-1 score of 0.90 in detecting malicious applications, significantly reducing the case load for security analysts by 87% in a real-world use case.\nFor future versions of TIPS, we plan to focus on enhancing its reasoning capabilities and scalability. This will involve improving its ability to understand and interpret complex patterns in data, as well as ensuring it can handle larger datasets and more diverse types of malicious applications. By addressing these areas, we aim to make TIPS an even more powerful tool for cybersecurity professionals."}]}