{"title": "TeVAE: A Variational Autoencoder Approach for Discrete Online Anomaly Detection in Variable-state Multivariate Time-series Data", "authors": ["Lucas Correia", "Jan-Christoph Goos", "Philipp Klein", "Thomas B\u00e4ck", "Anna V. Kononova"], "abstract": "As attention to recorded data grows in the realm of automotive testing and manual evaluation reaches its limits, there is a growing need for automatic online anomaly detection. This real-world data is complex in many ways and requires the modelling of testee behaviour. To address this, we propose a temporal variational autoencoder (TeVAE) that can detect anomalies with minimal false positives when trained on unlabelled data. Our approach also avoids the bypass phenomenon and introduces a new method to remap individual windows to a continuous time series. Furthermore, we propose metrics to evaluate the detection delay and root-cause capability of our approach and present results from experiments on a real-world industrial data set. When properly configured, TeVAE flags anomalies only 6% of the time wrongly and detects 65% of anomalies present. It also has the potential to perform well with a smaller training and validation subset but requires a more sophisticated threshold estimation method.", "sections": [{"title": "Introduction", "content": "Anomaly detection in time-series data has emerged as a common problem with a variety of real-world applications, from the medical field [16] to high-performance computing [24]. Findings from the field of anomaly detection are also of particular interest to the modern automotive industry. This industry is very diverse, including, for example, manufacturing, prototyping and testing. Furthermore, a car is a complex structure that can be segmented into different subsystems, one of them being the powertrain, which includes all components required for longitudinal dynamics. The powertrain is an important subsystem, as it is something a customer interacts with when driving or being driven. Therefore, testing the powertrain is an an integral part of the wider automotive powertrain development and is undertaken at different stages of development. Each of these stages is composed of many integration levels. These integration levels range from powertrain sub-component testing, such as the electric drive unit (EDU) controller or high-voltage battery (HVB) management system, to whole vehicle powertrain testing. For each integration level there is a special type of controlled environment, called a test bench. The use-case in this paper is on an endurance powertrain test bench, where the EDU and HVB on their own are tested under different conditions and loads for longer periods to simulate wear over time. Given the costly maintenance and upkeep costs of such test benches, it is desirable to keep downtime at a minimum and to avoid faulty records. Also, it is desirable to detect problems early to prevent damage to the testee. Online time-series anomaly detection is especially relevant, as it can provide timely insights into potentially harming behaviour that deviates from the norm.\nApplying anomaly detection to this real-world use case is especially challenging due to its complexity and highly dynamic setup. During powertrain testing several sensors record signals over time, leading to data in the form of multivariate time series. These signals not only have correlations within themselves over time but also between each other. In addition to that, some of the signals recorded also feature variable-state behaviour, meaning the same test done at different times will yield slightly different data. This is due to certain channels like the battery signals presenting slightly different behaviour depending on how warm or charged the battery is. All these characteristics exclude the use of simpler statistical models as they are not compatible with all of the mentioned data properties.\nGiven that evaluation is currently done manually by inspection, it is not feasible to analyse every single test, also evaluation tends to be delayed, only being undertaken days after the test is recorded, hence there is a clear need for automatic, fast and unsupervised evaluation methodology which can flag anomalous behaviour before the next testing procedure is started.\nTo achieve this, we propose a temporal multi-head attention-based variational autoencoder (TeVAE). TeVAE consists of a bidirectional long short-term memory (BiLSTM) variational autoencoder architecture that maps a time-series window into a temporal latent distribution [17] [24]. Also, a multi-head attention (MA) mechanism is added to further enhance the sampled latent matrix before it is passed on to the decoder. As shown in the ablation study, this approach avoids the so-called bypassed phenomenon [3], which is the first contribution. Furthermore, this paper offers a unique methodology for the reverse-window process. It is used for remapping the fixed-length windows the model is trained on to continuous variable-length sequences, i.e. time series. Moreover, we propose a set of metrics apt to online time-series anomaly detection that is not only interpretable and simple but is also compatible with discrete time-series anomaly detection. Lastly, the root-cause capability of TeVAE is investigated, for which a new metric, the root-cause precision, is also proposed.\nThis paper is structured as follows: First, a short background is provided in Section 2 on the powertrain testing methodology specific to this use case, as well as the theory behind VAEs and MA mechanisms. Then, related work in variational autoencoder-based time-series anomaly detection is presented in Section 3, followed by an in-depth introduction of the real-world data set and the approach we propose in Section 4. Then, several experiments testing different aspects of the proposed method are conducted and discussed in Section 5, along with the final results. Finally, conclusions from this work are drawn and an outlook into future work is provided in Section 6. The source code for the data pre-processing, model training as well as evaluation can be found under https://github.com/lcs-crr/TeVAE."}, {"title": "Background", "content": "2.1 Real-world Application: Automotive Powertrain Testing\nDuring endurance testing a portfolio of different drive cycles is run, where a drive cycle is a standardised driving pattern characterised by the vehicle speed, which enables repeatability. For this type of testing, the portfolio consists exclusively of proprietary drive cycles, which differ from the public drive cycles used, for example, for vehicle fuel/energy consumption certification. The reason why proprietary drive cycles are used for endurance runs is that they allow for more extensive loading of the powertrain.\nGiven the presence of a battery in the testee, some time has to be dedicated to battery soaking (sitting idle) and charging. These procedures are also standardised using soaking and charging cycles, respectively, although, for the intents and purposes of this paper, they are omitted. What is left in the portfolio are eight dynamic drive cycles representing short, long, fast, slow and dynamic trips ranging from 5 to 30 minutes. Modelling the testee behaviour is further complicated through variable-state behaviour. This means that two measurements of the same drive cycle done one after another will look different, depending on initial states. A measurement is defined as an instance of a drive cycle and is in the form of a multivariate time series or sequence. Variable-state behaviour can be categorised into short-term reversible and long-term irreversible. On the one hand, there are channels like the battery temperature or state of charge (SoC) that contribute to the short-term reversible kind since the battery heats up and discharges as it is used. On the other hand, processes like battery ageing, also known as the state of health (SoH), contribute to long-term irreversible behaviour, which is not considered and modelled in this use-case.\nOn powertrain test benches, there are several control methods to ensure the testee maintains the given drive cycle, i.e. the vehicle speed profile. In this particular test bench, the regulation is done by the acceleration pedal position and the EDU revolutions per minute (rpm).\n2.2 Data Set\nTo enable the development of anomaly detection methodology that can deal with the above-mentioned challenges, a data set is created using the data for one of the testees. This real-world data set D consists of thousands measurement files, each of variable length and containing hundreds of (many redundant or empty) channels. The training subset Dtrain consists of M = 2785 unlabelled time series such that Dtrain = [S1, ..., Sm, ..., SM]. Note that each time series in Dtrain has variable length Tm and dimensionality dp, such that Sm \u2208 RTm\u00d7dD. For this work, a list of representative dp = 13 channels is hand-picked in consultation with the test bench engineers. The chosen features along with their indices are as shown\nin Table 1.\nThe testing subset Dtest consists of N labelled time series such that Dtest = [S1, ..., Sn, ..., SN], where each time series in Dtest has variable length Tn and dimensionality dp, such that Sn \u2208 RTnxdD. The labelled anomaly-free portion of the testing subset Dtest accounts for Naf = 698 measurements, where a measurement is considered anomaly-free when the testee behaviour conforms to the norm.\nDue to the absence of labelled anomalies in the dataset, realistic anomalous events are intentionally simulated and recorded following the advice of test bench engineers. To this end, four anomaly types are recorded. Every anomaly type is recorded for every drive cycle at least once, leading to Na = 47 anomalous measurements that are all used as the labelled anomalous portion of the testing subset Dtest. Hence Dtest is made up of N = 745 measurements, representing an anomaly ratio of around Na/N = 6.3%, however in reality this value is estimated to be much lower. This amount of anomalous data in relation to anomaly-free data is used as it approximately matches the anomaly ratio in public data sets [15, 1, 11, 24] and because the data set is not large enough to create a larger anomaly-free test subset.\nIn the first type, the virtual wheel diameter is changed, such that the resulting vehicle speed deviates from the norm. The wheel diameter is a parameter as resistances are connected to the shafts rather than actual wheels. This accounts for 16 time-series anomalies and the only channel that demonstrates anomalous behaviour is the vehicle speed, since:\n\\(U_{vehicle} = r \\cdot w\\) (1)\nwhere r is the wheel radius and w the angular velocity of the drive shaft. Logically, the anomalous behaviour is most visible at higher speeds."}, {"title": "Related Work", "content": "TeVAE belongs to the so-called generative model class, which encompasses both variational autoen- coders, as well as generative adversarial networks. This section focuses solely on the work on VAE proposed in the context of time-series anomaly detection.\nIn time-series anomaly detection literature, the only other model that uses the combination of a VAE and an attention mechanism is by [18]. For the purpose of our paper, it is referred to as variational self-attention VAE (VS-VAE). Their approach consists of a BiLSTM encoder and decoder, where, for an input window of length w, the t = w encoder hidden states of each direction are passed on to the variational self-self-attention (VS) mechanism [3]. The resulting context vector is then concatenated with the sampled latent vector and then passed on to the decoder. The author claims that applying VS to the VAE model solves the bypass phenomenon, however, no evidence for this claim is provided.\nThe first published time-series anomaly detection approach based on VAE is LSTM-VAE [17]. One of the contributions is its use of a dynamic prior, i.e. N(\u03bcp, 1), rather than a static one, i.e. N(0, 1). In addition to that, they introduce a state-based threshold estimation method consisting of a support-vector regressor (SVR), which maps the latent distribution parameters (\u03bc\u03b1, \u03c3\u03c4) to the resulting anomaly score using the validation data. Hence, the dynamic threshold can be obtained\nthrough Equation 10.\n\\(Nt = SVR(\u03bcz,t, oz,t) + C\\) (10)\nwhere c is a pre-defined constant to control sensitivity.\nOmniAnomaly [24] attempts to create a temporal connection between latent distributions by applying a linear Gaussian state space model to them. For the purpose of this paper, it is abbreviated to OmniA. Also, it concatenates the last gated recurrent unit (GRU) hidden state with the latent vector sampled in the previous time step. In addition to that, it uses planar normalising flow [20] by applying K transformations to the latent vector in order to approximate a non-Gaussian posterior, as shown in Equation 11.\n\\(fk (z-1) = utanh(wz-1) + b\\) (11)\nwhere u, w and b are trainable parameters.\nA simplified VAE architecture [19] based on BiLSTM layers is also proposed. For the purpose of our paper, it is called Wasserstein VAE (W-VAE). Unlike its predecessor [18], it drops the attention"}, {"title": "Proposed Approach", "content": "4.1 Overview\nTo detect anomalies in multivariate time-series data, we propose a variational autoencoder architecture consisting of BiLSTM layers. The model architecture is illustrated in Figure 3. During training, the encoder q, parameterised by \u00f3, maps input window X to a temporal distribution with parameters \u03bc\u03b1 and log oz in the forward pass, Equation 13.\n\\((\\mu_z, \\log \\sigma^2_z) = q_\\phi(X)\\) (13)\nGiven the latent distribution parameters \u03bcz and log oz, the latent matrix is sampled from the resulting distribution, as shown in Equation 14. Note that the covariance is not modelled, hence oz only contains the diagonal of the covariance matrix.\n\\(Z \\sim N (\\mu_z, diag(\\sigma_z))\\) (14)\nThen, the input window X is linearly transformed to obtain the query matrices Qi and key matrices\nKi for each head i. Likewise, the sampled latent matrix Z is also transformed to the value matrix Vi, as shown in Equation 15.\n\\(Q_i = XW^Q_i\\) \\(K_i = XW^K_i\\) \\(V_i = ZW^V_i\\) (15)\nTo output the context matrix Ci for each head i, the softmax of the through \u221adk normalised query and key product is multiplied with the value matrix, Equation 16.\n\\(C_i = \\text{Softmax} (\\frac{QK^T}{\\sqrt{d_k}}) V_i\\) (16)\nThe final context matrix C is the result of the linearly-transformed concatenation of each head-specific context matrix Ci, as expressed in Equation 17.\n\\(C = [C_1, ..., C_h] W^O\\) (17)\nThe decoder pe, parameterised by 0, then maps the context matrix C to \u03bc\u03c7 and log \u03c3\u03c7, as shown in\nEquation 18. These can then be used to parametrise output distribution N(\u03bc\u03c7, diag(\u03c3\u03c7)).\n\\((\\mu_X, \\log \\sigma^2_X) = p_\\theta(C)\\) (18)\nMapping the output to a distribution rather than a deterministic vector allows TeVAE to model uncertainty, which is assumed to be normally distributed.\n4.2 Inference Mode\nDespite the generative capabilities of VAEs, TeVAE does not leverage generation for anomaly detection. Rather than sampling a latent matrix as shown in Equation 14 during inference, sampling is disabled and only uz is taken as the input for the multi-head attention mechanism, like in [22].\nEquation 14, therefore, is replaced by Equation 19 for the forward pass.\n\\(Z = \\mu_z\\) (19)\nThis not only accelerates inference by eliminating the sampling process but is also empirically found to be a good approximation of an averaged latent matrix if it were sampled several times like in [18].\nThe TeVAE layout during inference is shown in Figure 3, where the traced arrow designates the information flow from the encoder to the MA mechanism.\n4.3 Threshold Estimation Method\nAnomalies are by definition very rare events, hence an ideal anomaly detector only flags measurements very rarely but accurately. In the powertrain test bench scenario an algorithm is preferred that only flags a sequence it is sure is an anomaly, in other words, an algorithm that outputs very few to no false positives. A high false positive count would lead to a lot of stoppages and therefore lost testing time and additional cost. Of course, the vast majority of measurements evaluated will be anomaly-free hence it is paramount to classify them correctly, naturally leading to a high precision value. Also, there is no automatic evaluation methodology currently running at test benches, other than rudimentary rule-based methods, therefore a solution that plugs into the existing system that automatically detects some or most anomalies undetectable by rules-based approaches can already lead to time and cost savings. To achieve this, the threshold 7 is set as the maximum negative log-likelihood observed when the model is fed with unlabelled validation data."}, {"title": "Bypass Phenomenon", "content": "VAE, when combined with an attention mechanism, can exhibit a behaviour called the bypass phenomenon [3]. When the bypass phenomenon happens the latent path between encoder and decoder is bypassed and information flow occurs mostly or exclusively through the attention mechanism, as it has deterministic access to the encoder hidden states and therefore avoids regularisation through the\nDKL term. In an attempt to avoid this, [3] propose variational attention, which, like the VAE, maps the input to a distribution rather than a deterministic vector. Applied to natural language processing,\n[3] demonstrate that this leads to a diversified generated portfolio of sentences, indicating alleviation of the bypassing phenomenon. As previously mentioned, only [18] applies this insight in the anomaly detection domain, however, they do not present any evidence that it alleviates the bypass phenomenon in their work. TeVAE on the other hand, cannot suffer from the bypass phenomenon in the sense that information flow ignores the latent variational path between encoder and decoder since the MA mechanism requires the value matrix V from the encoder to output the context matrix. Assuming the bypass phenomenon also applies to a case where information flow ignores the attention mechanism, one could claim that TeVAE is not immune. To disprove this claim, the attention mechanism is removed from the model in an ablation study to see if anomaly detection performance remains the same. In this case, V = Z is instead directly input into the decoder. If it drops, it is evidence of the contribution of the attention mechanism to the model performance and hence is not bypassed. The results for this ablation study are shown and discussed in Section 5."}, {"title": "Reverse-window Process", "content": "Since the model is trained to reconstruct fixed-length windows, the same applies during inference. However, to decide whether a given measurement sequence Sn \u2208 RTnxdD is anomalous, a continuous reconstruction of the measurement is required. A trivial way to do so would be to window the input measurement Sn using a shift of 1, input the windows into the model and chain the last time step from each output window to obtain a continuous sequence [5]. Considering the BiLSTM nature of the encoder and decoder, the first and last time steps of a window can only be computed given the states from one direction, making these values, in theory, less accurate, however. To overcome this, we propose averaging matching time steps in overlapping windows, which is called mean-type reverse-window method. This is done by pre-allocating an array with NaN values, filling it, and taking the mean for each time step while ignoring the NaN values, as depicted in Figure 4. This process and the general anomaly detection process are described in Algorithm 1. The input for this process is the output distribution parameters (\u03bcx, log o\u3121), so it essentially averages the distributions and hence can only be applied to the mean and variance parameters. Consider the distributions\nN(\u03bc\u03b1, \u03c32) and N (\u03bcy, 02), both assumed to be independant and normally distributed. The sum of both distributions results in normal distribution N (\u03bcx+y, 2+y), obtained as shown in Equation 20\n\\(\u03bc_{x+y} = \u03bc_x + \u03bc_y\\) \\(\u03c3^2_{x+y} = \u03c3^2_x + \u03c3^2_y\\) (20)\nTherefore, the standard deviation of the resulting distribution \u03c3x+y is characterised by Equation 21.\n\\(\\sigma_{x+y} = \\sqrt{\u03c3^2_x + \u03c3^2_y}\\) (21)\nThe theoretical delay theory associated with each of the reverse-window processes can be discussed ahead of Section 5, however. theory is defined as the intrinsic delay introduced by each reverse- windowing method. To illustrate the theoretical delay theory, it is plotted against time t to demonstrate the delay for each of the reverse-window processes, shown in Figure 5. For the last-type reverse- window method during 0 < t < w, no time steps can be evaluated until a full window can be formed, streamed and evaluated, introducing a theoretical delay theory = w. This property is intrinsic to approaches based on fixed-length windows rather than variable-length sequences. At time step t = w, however, all time steps 0 < t < w are evaluated and output at the same time. For w < t < T, however, the last time step of each window corresponds the current real-world time step, i.e. theory = 0 for w < t <T. As mentioned above, the lack of evaluation until t = w is natural to any window-based approach and hence the first-type and mean-type reverse-window methods show the same behaviour.\nIn contrast to last-type reverse-windowing, however, these methods only output the first value of each window i.e. evaluation is theory = w time steps behind for 0 < t < T - w. At t = T, though, the time steps T \u2013 w < t < T are all output at the same time, meaning that theory = 0 and no extra time is needed for evaluation after streaming ends. It should be noted, however, that in online time-series anomaly detection the last-type reverse-window method is in theory faster than the other two types. Consider a sub-sequence anomaly starting at time step w + 2, designated by the red line in Figure\n5. Apart from the time required for inference, the last-type reverse-window method can detect the anomaly without a theoretical delay theory, during w < t < T, whereas the other two methods can only detect the anomaly theory = w time steps later. For 0 < t <T w, a theoretical delay of theory = w time steps is, therefore, the absolute best that first-type and mean-type reverse-windowing can achieve, however, while the best delay the first-type can achieve is theory = 0, it will be higher in reality, perhaps higher than w time steps."}, {"title": "Root-cause Analysis", "content": "Once a measurement is predicted to be anomalous it is of great benefit if context is provided, like what channel had the biggest impact on the prediction. Depending on what subsystem within the system the anomaly originates, it may affect a different number of channels, in some cases even all. Some attempts to provide root-cause functionality are made in literature.\nThe first known to the authors is proposed by [28]. The approach does not use time series but instead, the resulting correlation matrices and the anomaly score is given as the difference between the input and reconstructed correlation matrices. Hence, as a mean of providing root-cause information they rank each channel by the number of high anomaly scores for every other channel. Root-cause identification is then quantified by the recall for the top k channels, in this case three, although little information on how exactly this is calculated is provided. Another issue with this metric is that is not parameter-free, since k needs to be set manually. Furthermore, the method used is specific to approaches using the same type of correlation matrices, which is rare in literature.\nApproaches using the negative log-likelihood as the anomaly score obtain it from a multivariate output distribution with a diagonal covariance. While the resulting anomaly score is a univariate time series, it is referred to as multivariate anomaly score for now due to its origin in a multivariate output distribution. [24] propose decomposing the anomaly score into anomaly scores for each channel, by splitting the multivariate output distribution into do univariate output distributions. The resulting anomaly scores for each of the dp channels are referred to as univariate anomaly scores due to their origin in dp univariate output distributions. To find the channel that contributed most to a detection, the highest univariate anomaly score is assumed to be the root cause.\nIn this work, the methodology proposed by [24] is used to find the channels that contribute most to a detection. To this end, the method is slightly adapted, given the online premise of the use case. Rather than considering the univariate anomaly scores as time series for root cause analysis, the first time step of the multivariate anomaly score above the threshold is used. Then, for that time step, the highest univariate anomaly score is assumed as the contributing channel."}, {"title": "Results", "content": "5.1 Setup\nThe encoder and decoder both consist of two BiLSTM layers, with the outer ones having 512 hidden- and cell-state sizes and the inner ones 256. All other parameters are left as the default in the TensorFlow API.\nDuring training only, input windows are corrupted using Gaussian noise using 0.01 standard deviation to increase robustness [26].\nKey factors that are investigated in Section 5 are given a default value which applies to all experiments unless otherwise specified. These factors are training and validation subset size, which is set to 512h, reverse-window method, where the mean-type is used, the latent dimension size, which is set to dz = 64, the MA mechanism, which is set up as proposed in [25] with a head count of h = 8 and a\nkey dimension size dk = [dp/h] = 1.\nThe optimiser used is the AMSGrad optimiser with the default parameters in the TensorFlow API. Cyclical DKL annealing is applied to the training of TeVAE, to avoid the DKL vanishing problem [9]. The DKL vanishing problem occurs when regularisation is too strong at the beginning of training, i.e. the Kullback-Leibler divergence term has a larger magnitude in relation to the reconstruction term.\nCyclical DKL annealing allows the model to weigh the Kullback-Leibler divergence lower than the reconstruction term in a cyclical manner through a weight \u03b2. This callback is configured with a grace period of 25 epochs, where \u1e9e is linearly increased from 0 to 10-8. After the grace period, \u1e9e is set to 10-8 and is gradually increased linearly to 10-2 throughout the following 25 epochs, representing one loss cycle. This loss cycle is repeated until the training stops.\nAll priors in this work are set as standard Gaussian distributions, i.e. p = N(0, 1).\nTo prevent overfitting, early stopping is implemented. It works by monitoring the negative log- likelihood component of the validation loss during training and stopping if it does not improve for\n250 epochs. Logically, the model weights at the lowest validation negative log-likelihood are saved. Given the stochastic nature of the VAEs, the chosen seed can impact the anomaly detection perfor- mance as it can lead to a different local minimum during training, hence all tests are done with three different seeds and are shown in form of the standard deviation after every performance metric.\nTraining is done on a workstation configured with an NVIDIA RTX A6000 GPU. The library used for model training is TensorFlow 2.10.1 on Python 3.10 on Windows 10 Enterprise LTSC version 21H2.\n5.2 Online Evaluation Metrics\nThe results provided are given in the form of the calibrated and uncalibrated anomaly detection performance, i.e. with and without consideration of threshold T, respectively. Recall that the threshold used is the maximum negative log-likelihood obtained from the validation set. The basis for all metrics are the number of true positives Ntp, number of false negatives Nfn and number of false positives Nfp.\nAs discussed in Section 1, a testing subset in discrete time-series anomaly detection problem has three types of time series: entirely normal, time-series anomalies and sub-sequence anomalies. Since anomalies are considered rare events, the number of anomaly-free time series Naf within Dtest is much larger than the number of time-series anomalies Nts and sub-sequence anomalies Nss, such that\nNaf >> Nts + Nss = Na and N = Naf + Nts + Nss. In the case of anomaly-free time series and time-series anomalies, traditional labels can easily be applied. An anomaly-free time series can be labelled as true negative or false positive and a time-series anomaly can be labelled as true positive or false negative. For partially anomalous time series, i.e. where the anomalous behaviour occupies a contiguous subset of time steps within the time series, it can be labelled as a true positive or a false negative, but also as a false positive, which occurs when an algorithm flags a time step early. Formally, this is the case when the first flagged time step is far enough ahead of the first ground-truth time step that the model cannot have had access to it. As is evident, the proposed metrics can only be applied to discrete time-series data sets where anomalous time series have at most one contiguous ground-truth anomalous sub-sequence of any length. Also, ensuring each time series contains at most one contiguous anomaly avoids ambiguity on how multiple sub-sequence anomalies within a time series should be detected and counted [27]. In addition to that, there can also be at most one contiguous ground-truth anomaly-free sub-sequence of any length within a sub-sequence anomalous time series, since systems that can dynamically return to anomaly-free behaviour (especially in a short amount of time) reap less benefit from automated anomaly detection than those which require human attention. Given that a predicted anomaly likely requests human attention and potentially a stoppage of the system, the adaptation of the metrics proposed above only takes into account the first predicted anomalous time step. For cases where the process may continue, there can be multiple contiguous predicted anomalous sub-sequences, hence the metrics cannot be applied.\nCalibrated metrics are the precision, recall and F\u2081 score. Precision P represents the ratio between the number of correctly identified anomalies (true positives) and the number of all positives (true and false), shown in Equation 22, recall R represents the ratio between the number of true positives and the number of all anomalies, shown in Equation 22, and F\u2081 score represents the harmonic mean of the precision and recall, shown in Equation 22.\n\\(P = \\frac{N_{tp}}{N_{tp} + N_{fp}}\\) \\(R = \\frac{N_{tp}}{N_{tp} + N_{fn}}\\) \\(F_1 = 2 \\cdot \\frac{PR}{P+R}\\) (22)\nThe theoretical maximum F\u2081 score, F1,best, is also provided to aid discussion. This represents the best possible score achievable by the approach if the ideal threshold were known, i.e. the point on the precision-recall curve that comes closest to the P = R = 1 point, though, in reality, this value is not observable and hence cannot be obtained in an unsupervised manner. The precision and recall corresponding to the F1,best score are also provided.\nThe uncalibrated anomaly detection performance, i.e. the performance for a range of thresholds is represented by the area under the continuous precision-recall curve Apont, Equation 23.\n\\(A^{cont}_{PR} = \\int^1_0 P dR\\) (23)\nAs the integral cannot be computed for the continuous function, the area under the discrete precision- recall curve A disc is used which is done using the trapezoidal rule, Equation 24.\n\\(A^{disc}_{PR} = \\sum^{K-1}_{k=1} \\frac{P_{k-1}+P_{k}}{2} \\Delta R_k\\) (24)\nwhere K is the number of discrete points along the precision-recall curve, k the index of discrete points along the precision-recall curve and ARk the sub-interval length between indices k and k 1.\nWhile the above metrics quantify binary anomaly detection performance, they do not provide information on the delay of detections, which plays a crucial role in online time-series anomaly detection. Therefore, we propose an additional metric, the detection delay \u03b4, which represents the absolute delay between the first ground-truth anomalous time step t = tgt and the first predicted anomalous time step t = tp. The detection delay 8 is only calculated for anomalous time series since\nin anomaly-free time series there is no first ground-truth time step t = tgt, therefore it is calculated as\nshown in Equation 25.\n\\delta = |t_p - t_{gt}| (25)\nwhere, in case of a false negative, tp is equal to the last time step of the anomalous time series. This formula not only reflects the detection delay for true positives but also punishes false negatives by applying the maximum delay possible, i.e. d = T, as well as false positives by applying the \"negative\"\ndelay between the first early predicted time step t tp and the first ground-truth time step t = tgt. For each anomalous test time series the detection delay is calculated and subsequently averaged to yield the average detection delay 8, shown in equation 26.\n\\(\\bar{\\delta} = \\frac{1}{N_{ts} + N_{ss}} \\sum^{N_{ts} + N_{ss}}_{i=1} \\delta_i\\) (26)\nIn order to evaluate TeVAE's root-cause analysis performance we propose a corresponding metric. Recall that according to the method of counting labels, anomaly-free sequences can be labelled as true negatives or false positives and time-series anomalies can be labelled as true positives or\nfalse negatives. Sub-sequence anomalies can be labelled as true positives, false negatives or false\npositives, where the latter occurs when an anomaly is detected before it actually occurs. To quantify\nwhether the most relevant channel has been flagged in the case of a predicted anomalous sequence, the\nroot-cause true positive count Ntp and root-cause false positive count Nfpre are introduced. Clearly, the root-cause channel can only be obtained for predicted anomalous sequences, hence why there is no root-cause true negative count tnrc or root-cause false negative count Nfnre. The root-cause true\npositive count Ntp\u2081e represents the number of sequences labelled as true positives and the predicted root-cause channel is a subset of the list of ground-truth root-cause channels for a given anomaly type. Likewise, root-cause false positive count Nfpre represents the sum of three cases. The first case is an anomaly-free sequence labelled as a false positive, for which there are no ground-truth root-cause channels. The second case is a ground-truth time-series or sub-sequence anomaly that is labelled as a true positive, but the predicted root-cause channel is not a subset of the list of ground-truth root-cause\nchannels for the relevant anomaly type. The third case is a ground-truth sub-sequence anomaly that is labelled as a false positive, due to a premature detection, for which there are no ground-truth root-cause channels. To aid the understanding of this concept, a diagram depicting what types of sequences can be labelled as what is shown in Table 2. As is evident, Ntp + Nfp = Ntprc + Nfpre. To summarise the Ntpre and Nfpre figures, we propose a new metric called the root-cause precision Prc, shown in Equation 27.\n\\(P_{rc} = \\frac{N_{tprc}}{N_{tp} + N_{fp}}\\) (27)\nPre denotes the number of correctly identified root-cause channels relative to the number of total\ndetections, true or false."}, {"title": "Ablation Study", "content": "TeVAE is tested without the MA mechanism and with a direct connection from the encoder to the decoder to observe whether the absence of the MA impacts results. The anomaly detection performance of TeVAE and its counterpart without MA, henceforth referred to as NoMA model, are shown in Table 3.\nWhile the precision value of the NoMA model is slightly higher than the TeVAE, the recall value on the other hand is much lower. Overall, TeVAE has a significantly higher F\u2081 score, as well as a higher theoretical maximum F\u2081 score and higher uncalibrated anomaly detection performance, denoted by the Apr figure. Furthermore, TeVAE features a much lower average detection delay which is especially relevant for online time-series anomaly detection. In contrast to that, NoMA offers marginally higher root-cause precision. The results hence point towards an improvement brought about by the addition of the MA mechanism and therefore the bypass phenomenon can be ruled out."}, {"title": "Data Set Size Requirements", "content": "To evaluate how much data is required to train TeVAE to a point of adequate anomaly detection performance, it has been trained with 1h, 8h, 64h, and 512h of dynamic testing time.\nOn the one hand, as the training and validation subset increases in size, the precision value improves but on the other hand recall value decreases as the subset grows, though at a smaller scale compared to the increase in precision. This can be attributed to the fact that smaller subset sizes lead to a small validation set and therefore less data to obtain a threshold from. With a limited amount of data the validation set distribution is very different to the"}]}