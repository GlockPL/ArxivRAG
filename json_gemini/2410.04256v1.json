{"title": "Implicit to Explicit Entropy Regularization: Benchmarking ViT Fine-tuning under Noisy Labels", "authors": ["Maria Marrium", "Arif Mahmood", "Mohammed Bennamoun"], "abstract": "Automatic annotation of large-scale datasets can introduce noisy training data labels, which adversely affect the learning process of deep neural networks (DNNs). Consequently, Noisy Labels Learning (NLL) has become a critical research field for Convolutional Neural Networks (CNNs), though it remains less explored for Vision Transformers (ViTs). In this study, we evaluate the vulnerability of ViT fine-tuning to noisy labels and compare its robustness with CNNs. We also investigate whether NLL methods developed for CNNs are equally effective for ViTs. Using linear probing and MLP-K fine-tuning, we benchmark two ViT backbones (ViT-B/16 and ViT-L/16) using three commonly used classification losses: Cross Entropy (CE), Focal Loss (FL), and Mean Absolute Error (MAE), alongside six robust NLL methods: GCE, SCE, NLNL, APL, NCE+AGCE, and ANL-CE. The evaluation is conducted across six datasets including MNIST, CIFAR-10/100, WebVision, Clothing1M, and Food-101N. Furthermore, we explore whether implicit prediction entropy minimization contributes to ViT robustness against noisy labels, noting a general trend of prediction entropy reduction across most NLL methods. Building on this observation, we examine whether explicit entropy minimization could enhance ViT resilience to noisy labels. Our findings indicate that incorporating entropy regularization enhances the performance of established loss functions such as CE and FL, as well as the robustness of the six studied NLL methods across both ViT backbones.", "sections": [{"title": "I. INTRODUCTION", "content": "Deep Neural Networks (DNNs) have transformed a variety of machine learning tasks, driven by the availability of large, high-quality annotated datasets [14], [39], [51], [52]. Large-scale datasets can be collected from the web via search engines or social media [7]. Acquiring and manually annotating these datasets is both costly and time-intensive. To mitigate this, cheaper alternatives have been developed. One method involves crowdsourcing the labeling process through platforms like Amazon Mechanical Turk and Crowdflower, significantly reducing labeling costs. Another method employs automated systems for labeling data using deep learning techniques [22], [62], retrieval-based methods [60], [72], and graph-based semi-supervised learning methods [24], [61]. However, these approaches often lead to the introduction of noisy labels, which can adversely affect the learning outcomes of DNNs [37], [66]. Moreover, label noise can also stem from human annotators who may lack the necessary experience, or from data that is too complex to be accurately labeled even by experts [1], [5]. This widespread issue underscores the need for developing robust algorithms capable of managing noisy labels effectively [3], [4].\nLarge-scale real-world datasets inevitably contain a significant portion of mislabeled training samples. Previous research has shown that these samples can disrupt the learning process of DNNs, impairing their effectiveness [40], [66], [71]. Consequently, developing strategies to learn in the presence of noisy labels has become a crucial area of research. Existing research on robust noisy label learning (NLL) can be categorized into four main approaches: 1) Label correction methods aimed at detecting and correcting incorrect labels [2], [6], [35], [57], [66]. 2) Loss correction methods that adjust the loss function based on an estimated noise transition matrix [18], [45], [49], [54]. 3) Refined training strategies designed to better accommodate incorrect labels [19], [26], [28], [43], [55], [63], [65]. 4) Robust loss functions inherently designed to withstand the impact of noisy labels [16], [42], [64], [67], [74]. The first three categories often suffer from inaccurate noise estimations and involve complex training procedures, whereas robust loss functions offer a simpler and more effective solution.\nGiven the success of Vision Transformers (ViTs) [15] across various computer vision tasks [30], [47], [53], [69], ViTs have established themselves as the de facto standard in the"}, {"title": "II. RELATED WORK", "content": "Deep learning methods for Noisy Label Learning (NLL) are typically divided into four distinct categories:\nLabel Cleaning Methods: These methods aim to identify and correct mislabeled data [35], [57], [59], [66], [68], [75]. Xiao"}, {"title": "B. ViT Fine-tuning Techniques", "content": "The development of large-scale deep learning models has led to a shift towards a pre-training and fine-tuning paradigm, prominently used in fields like computer vision [15], [20] and natural language processing [48], [58]. Recent works have used large ViT models [15] trained on extensive datasets such as ImageNet-21K [14], which have shown significant performance improvements and exceptional generalizability. These models provide pre-trained weights that are versatile across various downstream tasks [20], [47]. As pre-trained models become more complex, the focus of research has shifted to devising efficient fine-tuning methods that optimize performance for specific tasks, resulting in several parameter-efficient fine-tuning strategies [27], [36], [44], [56], [70], [73], [77]. Full Fine-Tuning (Full-FT) involves adjusting all parameters of a pre-trained model for a downstream task, which consumes substantial computational resources. Alternatively, techniques like linear probing, where only the final linear layer is adjusted, or MLP-K, which only fine-tunes the MLP classification head, are computationally economical due to fewer tunable parameters. Visual Prompt Tuning (VPT) [25] and AdaptFormer [13] introduced an adapter module for task-specific fine-tuning while keeping the core transformer structure largely unchanged. AdaptFormer [13] introduced an adapter module for task specific fine-tuning while keeping the core transformer structure largely unchanged. Both VPT and AdaptFormer are computationally expensive and incur significantly larger memory overhead compared to LP/MLP-K based fine-tuning. A visual illustration of these techniques is shown in Figure 2."}, {"title": "III. PROPOSED METHODOLOGY", "content": "Let  D = {(x_i, y_i)}^n_{i=1} represent the dataset where x_i \u2208 XC Rd  is a sample and  y_i \u2208 Y = {1,...,kc} denotes its annotated labels from  kc  classes (which may include noise). The distribution over different labels for sample  x_i is represented as  q(k|x_i) with \u2211_{k=1}^{kc} q(k|x_i) = 1.  In this paper, we focus on the common scenario where there is a single label for each  x_i,  i.e.,  q(k = yi|x_i) = 1 and q(k \u2260 yi|x_i) = 0. In this case, q is simply the one-hot encoding of the label. For the classification task, the goal is to learn a function f(\u00b7) : X \u2192 Y  that maps the input space to the label space. In this work, we model f(\u00b7)  using a Vision Transformer (ViT) backbone, followed by one or more dense layers with a softmax applied at the output layer. For a sample  x_i,  we denote the probability output of classifier f(x_i)  as  p(k|x_i) = e^{z_k} / \u2211_{j=1}^{kc} e^{z_j} where  z_i represents the output from last layer before the softmax. Training the classifier  f(\u00b7) involves finding an optimal classifier f*(\u00b7)  that minimizes the empirical risk defined by a loss function:  f*(\u00b7) = argmin_@\u2211_{i=1}^{n}L(f(x_i, y_i)),  where  @  represents the trainable parameters of  f(.)."}, {"title": "B. Label Noise Generation.", "content": "To systematically evaluate the robustness of various methods to noisy labels different noise levels are introduced into clean datasets [42], [64], [67], [78]. There are two common"}, {"title": "C. Entropy Regularization as a Robust Loss Function", "content": "2) Explicit Entropy Regularization: Entropy measures the uncertainty or randomness of a probability distribution [50]. In machine learning, it is often used to quantify the uncertainty in a decision. The entropy H(X) for all samples is defined as:\nH(X) = 1/n \u2211_{i=1}^{n} \u2211_{k=1}^{kc} P(k|x_i) log P(k|x_i) (1)\nwhere,  p_l(kx\u2081) represents the softmax probability of the classifier for the k-th class in l-th iteration, while \u2211_{k=1}^{kc} Pl(k|x_i) = 1,  and  ke  is the number of classes. Entropy reduction  \u0394\u0397_(l,l+\u0394\u03b9)(X) is defined as:\n\u0394\u0397_(l,l+\u0394\u03b9)(X) = H_l(X) - H_(l+\u0394\u03b9)(X) (2)\nwhere, Hl(X) and H_(l+\u2206\u03b9)(X) are the mean entropies at l-th and (l + Al)-th epochs, respectively.\nThe investigation in the previous section showed that robust loss functions implicitly minimize prediction entropy, leading to a more significant reduction in entropy when dealing with"}, {"title": "IV. EXPERIMENTS AND RESULTS", "content": "Datasets. We use six benchmark datasets, including MNIST, CIFAR-10/100, as well as real-world noisy datasets such as WebVision [34], Clothing1M [66], and Food-101N [32], to assess and compare the performance of various NLL methods.\nBaselines. We consider three commonly used classification losses: CE, FL, and MAE alongside six state-of-the-art (SOTA)NLL methods, including GCE [74], SCE [64], NLNL [28], APL: NCE+RCE [42], NCE+AGCE [78], ANL: ANL-CE [67].\nLabel Noise Generation. Noisy labels for the MNIST and CIFAR-10/100 datasets are generated using standard approaches from previous works [28], [42], [64], [67], [74], [78]. For symmetric noise, labels within each class are randomly flipped to incorrect labels of other classes. For asymmetric noise, label flipping occurs within a specified set of classes. Specifically, for MNIST, the label flips are as follows: 7 \u2192 1, 2 7, 5 6, and 3 8 [42], [67]. For CIFAR-10, the flips are TRUCK \u2192 AUTOMOBILE, BIRD \u2192AIRPLANE, DEER\u2192 HORSE, and CAT \u2194 DOG"}]}