{"title": "Correction: Harnessing Federated Generative Learning for Green and Sustainable Internet of Things", "authors": ["Yuanhang Qi", "M. Shamim Hossain"], "abstract": "The rapid proliferation of devices in the Internet of Things (IoT) has ushered in a transformative era of data-driven connectivity across various domains. However, this exponential growth has raised pressing concerns about environmental sustainability and data privacy. In response to these challenges, this paper introduces One-shot Federated Learning (OSFL), an innovative paradigm that harmonizes sustainability and machine learning within IoT ecosystems. OSFL revolutionizes the traditional Federated Learning (FL) workflow by condensing multiple iterative communication rounds into a single operation, thus significantly reducing energy consumption, communication overhead, and latency. This breakthrough is coupled with the strategic integration of generative learning techniques, ensuring robust data privacy while promoting efficient knowledge sharing among IoT devices. By curtailing resource utilization, OSFL aligns seamlessly with the vision of green and sustainable IoT, effectively extending device lifespans and mitigating their environmental footprint. Our research underscores the transformative potential of OSFL, poised to reshape the landscape of IoT applications across domains such as energy-efficient smart cities and groundbreaking healthcare solutions. This contribution marks a pivotal step towards a more responsible, sustainable, and technologically advanced future.", "sections": [{"title": "1. Introduction", "content": "The advent of the Internet of Things (IoT) [46, 55, 4] has ushered in a new era of connectivity and data-driven decision-making across various domains [32, 33, 35, 14]. IoT devices have permeated our daily lives, enabling a wide range of applications, from smart homes and cities to industrial automation and healthcare. However, the proliferation of these devices has raised concerns about their environmental impact, especially with regard to energy consumption and data privacy. In this context, Federated Learning (FL) [36] has emerged as a promising paradigm to address these challenges by enabling collaborative machine learning on decentralized IoT devices, while also respecting user privacy [26, 49, 41].\nFederated learning is a decentralized machine learning approach that enables multiple devices to collaboratively train a global model while keeping their data localized and private [30]. The workflow begins with the initialization of a global model, followed by device participation, where decentralized clients perform local training on their data, compute model updates, and securely aggregate them on a central server [7, 19]. This iterative process refines the global model over multiple rounds, monitored by evaluation metrics until the desired performance is achieved. FL\u2019s privacy-preserving and distributed nature makes it suitable for applications like green and sustainable IoT, healthcare, and federated edge computing, addressing data privacy concerns while enabling machine learning in diverse and resource-constrained environments [60, 1, 20, 37, 40].\nTraditional FL approaches often require numerous communication rounds between the central server and participating devices, which can result in significant energy consumption, latency, and communication overhead [25, 24]. Inspired by previous work [56, 44, 21, 58], this paper introduces a novel approach known as \u201cOne-shot Federated Learning(OSFL),\u201d aimed at minimizing resource utilization while maximizing the sustainability of IoT networks. Leveraging the power of generative learning [58], this approach allows IoT devices to learn and share knowledge efficiently in a single communication round, reducing the need for constant connectivity and data transmission. This approach not only promotes green and sustainable IoT but also enhances the scalability and practicality of FL in resource-constrained environments.\nThe need for sustainable IoT solutions has become increasingly pressing as the world grapples with the challenges of climate change and resource depletion [3]. IoT devices are projected to proliferate exponentially in the coming years, making it imperative to design and adopt technologies that can mitigate their environmental impact [43]. By incorporating generative learning techniques into the FL framework, this paper presents a promising avenue for reducing energy consumption and prolonging the lifespan of IoT devices, thereby contributing to the broader goal of sustainable technology development [47].\nPrivacy concerns also loom large in the IoT landscape, as the data generated by these devices often contains sensitive information [1]. Traditional FL methods inherently preserve user privacy by keeping data localized, but they still involve multiple interactions that raise potential security risks [50, 31]. OSFL enhances privacy further by minimizing data exposure and limiting communication, making it an attractive choice for applications where privacy is paramount. This paper explores how this approach can strike a delicate balance between data utility, model performance, and user privacy in green and sustainable IoT environments. To this end, we summarize the challenges we face as follows:\n\u2022 (C1.) Difficult to Converge: Since OSFL only communicates once, this brings severe challenges to global model convergence. Unlike traditional FL, OSFL cannot iteratively update the model and perform multiple rounds of communication [58].\n\u2022 (C2.) New Privacy Concerns: Although OSFL only conducts one-shot communication to mitigate privacy risks to a certain extent, adversaries still have the opportunity to threaten OSFL\u2019s privacy. The main reason is that the knowledge uploaded by OSFL is not protected by privacy protection measures.\nTo tackle the aforementioned challenges, this paper utilizes the concept of OSFL as a novel and environmentally friendly approach to machine learning within the realm of the IoT. Specifically, we present an innovative framework termed Federated Generative Learning (FGL) which was proposed by Zhang et al. [58]. FGL harnesses the robust capabilities of generative models, including Stable Diffusion and GPT-4V, to generate high-fidelity surrogate training data directly on the server. This process is guided by prompts provided by individual clients. In a concrete sense, our method streamlines the workflow by having each client upload only their respective prompts, linked to their local training data. Once all prompts are gathered from the clients, the server orchestrates prompt aggregation and subsequently synthesizes a premium-quality surrogate training dataset. This dataset can then be employed to train a global model. By leveraging generative learning techniques and minimizing communication rounds, this approach aims to address the challenges of energy efficiency, scalability, and privacy in IoT networks. The subsequent sections of this paper will delve into the technical details, experiments, and practical implementations of OSFL, illustrating its potential to usher in a greener and more sustainable era for IoT applications. This paper's primary contributions are as follows:\n\u2022 We customize a new one-shot federated generative learning system for green and sustainable IoT, which can effectively alleviate data privacy and communication overhead issues.\n\u2022 We propose two new local prompt generation strategies, which aim to extract fine-grained feature information of local data to enhance the model's generalization ability.\n\u2022 We develop a one-shot FL method with generative learning as the core, which is organically combined with generation to improve the overall performance of FL. In particular, the one-shot FL method based on generative learning significantly improves the problem of expensive communication in IoT.\n\u2022 We conduct comprehensive validation and evaluation on three benchmark datasets, and the experimental results demonstrate the effectiveness of the proposed method.\nThe paper's structure is organized as follows: In Section 2, we provide a comprehensive overview of the background and concepts related to FL and the IoT. This section highlights the existing challenges and open problems within this context. Section 3 delves into the foundational aspects of federated learning and text-to-image models, offering a clear understanding of these crucial components. Furthermore, we explore the practical application scenarios of text-to-image models and delve into the core challenges currently faced in this field. In Section 4, we introduce our innovative One-shot FGL system, detailing its architecture and mechanisms. We then proceed to Section 5, where we present a series of case studies conducted on three real-world datasets. In these case studies, we thoroughly analyze the experimental results, providing valuable insights and observations. Lastly, in Section 6, we draw our conclusions, summarizing the key findings and contributions of our work in the context of OSFL for green and sustainable IoT. We summarize the notation descriptions used in this paper in Table 1."}, {"title": "2. Related Work", "content": "In the pursuit of advancing green and sustainable IoT through the lens of FL, this section provides an overview of existing research in four key subsections:"}, {"title": "2.1. Federated Learning in IoT", "content": "The integration of FL in the IoT has garnered substantial attention, primarily for its ability to harmonize the divergent requirements of data-driven intelligence and sustainability in resource-constrained environments. Prior research in this domain has delved into diverse FL strategies, encompassing federated optimization techniques, communication-efficient algorithms, and privacy-preserving methods. Notable contributions include the works of McMahan et al. [36] on federated averaging, which laid the foundation for distributed model training, and Bonawitz et al. [8] on secure aggregation, addressing privacy concerns in FL. Moreover, recent research by Wei et al. [50] introduced the concept of \"Federated Learning with Differential Privacy,\" further enhancing privacy guarantees in IoT applications. We build upon these foundations and extend them by introducing One-shot Federated Learning, which minimizes communication rounds and maximizes sustainability through generative learning.\nEfforts to minimize communication between IoT devices and the central server have been pivotal in the context of FL for green IoT [45]. Various federated optimization [30, 39, 48] techniques have been proposed to reduce the amount of information exchanged during each communication round. Notable works include the FedPAQ algorithm introduced by [42], which enables IoT devices to send only model updates to the central server rather than transmitting raw data. This approach significantly reduces communication bandwidth, making it an essential step towards greener and more sustainable IoT practices.\nQuantization and compression techniques have emerged as effective means to further enhance communication efficiency in FL for IoT [9, 36]. Researchers have explored methods to quantize model updates into compact representations, thereby reducing the data transfer requirements between clients and the central server. Chen et al. [9] proposed a quantization approach, Q-FFL, which compresses model updates to a fraction of their original size, alleviating the communication burden on IoT devices. Such techniques align with the green IoT agenda by conserving energy and reducing the carbon footprint associated with data transmission."}, {"title": "2.2. Sustainability in IoT", "content": "Promoting environmental sustainability in IoT has become a critical research area, given the ever-growing number of IoT devices and their potential ecological impact [5, 2]. Previous studies have examined energy-efficient communication protocols, low-power hardware design, and green data center technologies. Additionally, researchers have proposed solutions to optimize IoT device lifespans and reduce their carbon footprint. The work of Xue et al. [53] on energy-efficient IoT communication protocols and Zhang et al. [59] on sustainable IoT design are notable examples.\nAdditionally, advancements in green data center technologies and eco-friendly IoT infrastructure have contributed to reducing the overall carbon footprint of IoT deployments. These research endeavors underscore the importance of mitigating environmental impact, a key objective that aligns closely with the vision of our proposed One-shot Federated Learning approach, which seeks to enhance sustainability in IoT by optimizing machine learning while minimizing energy consumption and communication overhead. Our paper contributes to this body of knowledge by presenting One-shot Federated Learning as a novel approach that minimizes energy consumption during model updates and enhances the sustainability of IoT networks."}, {"title": "2.3. One-shot Learning in FL", "content": "The hallmark of OSFL [56, 44, 10, 58] is its ability to streamline the FL process into a single communication round, minimizing the energy expended on data transmission and device connectivity. Traditional FL workflows require multiple rounds of communication to exchange model updates and converge towards a global model [36]. In contrast, OSFL condenses this multi-round process into a one-shot operation, reducing the overall energy footprint of IoT devices. This reduction in energy consumption is of paramount importance in green and sustainable IoT, where power-efficient operations are essential to mitigate environmental impact and prolong the lifespan of battery-operated devices.\nThe introduction of OSFL underscores the importance of striking a balance between sustainability and model performance in IoT applications. While reducing energy consumption and communication overhead are critical sustainability objectives, it is equally crucial to ensure that model quality and learning performance are not compromised. OSFL addresses this challenge by optimizing generative learning processes to create high-quality synthetic updates that faithfully represent the knowledge of participating devices [23]. Through this balance, OSFL presents a compelling solution for green and sustainable IoT, enabling energy-efficient machine learning while maintaining or even improving the quality of learned models. Recent research has further pushed the boundaries of FL efficiency by exploring one-shot learning techniques. Li et al. [29] demonstrated the feasibility of one-shot learning, enabling models to generalize from limited data instances. While these advancements primarily targeted traditional FL, they underscored the potential for a more streamlined and efficient FL workflow. Our work bridges the gap between communication-efficient FL and one-shot learning, introducing OSFL as a novel approach that synergizes these concepts to maximize sustainability in IoT while minimizing the environmental footprint of machine learning operations."}, {"title": "2.4. Generative Learning in FL", "content": "Generative learning has emerged as a powerful technique in machine learning, enabling models to generate data samples that capture underlying data distributions [11]. In the context of FL, generative learning has been applied to enhance data privacy, as seen in the work of Nasr et al. [38] and Zhang et al. [58] on generative models, e.g., generated adversarial networks (GANs) and Stable Diffusion, for privacy-preserving data sharing. Furthermore, recent research by Zhang et al. [58] demonstrated the feasibility of generative models for one-shot learning tasks.\nGenerative Learning has also played a role in data augmentation for FL. Techniques such as federated data generation, as proposed by Xin et al. [52], leverage generative models to create synthetic data samples that help balance class distribution and improve model robustness in FL scenarios with imbalanced data. Furthermore, the application of generative models in one-shot learning tasks has demonstrated significant promise. Zhang et al. [57] explored the use of generative models for efficient adaptation to new tasks, enabling FL models to learn from a single example. This concept has implications for resource-efficient machine learning and can be integrated into the FL framework to optimize knowledge transfer with minimal communication.\nIn the context of our paper, we leverage the capabilities of generative learning within the FL workflow to introduce OSFL, a novel approach that combines generative learning and FL to maximize sustainability in IoT while minimizing communication overhead and energy consumption. This integration represents a pivotal advancement in the field, addressing the pressing need for eco-friendly and efficient machine learning operations in IoT environments. Building upon these foundations, our paper leverages generative learning to optimize the FL workflow, reducing communication overhead and fostering sustainable IoT by achieving learning objectives with minimal data transfer and device energy consumption."}, {"title": "3. Preliminaries", "content": ""}, {"title": "3.1. Federated Learning", "content": "FL empowers decentralized participants to engage in collaborative machine learning model training without the need to share their private data with one another, as highlighted in [36]. In a conventional supervised FL framework, the structure typically comprises a server denoted as S and a set of K clients. Each client maintains a comprehensive labeled dataset represented as D, while the server itself does not possess any data. This architecture ensures data privacy and security during the collaborative training process. Specifically, a widely used FL training strategy (i.e. FedAvg [36]) is described as follows.\nAt the beginning of FL, the server initializes an ML model parameter \\(\\omega\\) and broadcasts it to a subset of clients (i.e., \\(K_o\\), and \\(K_o \\subseteq K\\)) for local training. Afterward, for each communication round t, the clients in the selected subset \\(K_t\\) train the received global model \\(\\omega_t\\) on the local dataset. For instance, the minimization objective function for the k-th client training a local model \\(\\omega_k\\) (i.e., \\(\\omega_k \\leftarrow \\omega_t\\)) on dataset \\(D_k = \\{(x_1, y_1), \u2026, (x_{n_k}, y_{n_k})\\}\\) can be formulated as follows.\n\\[\\mathcal{L}_k = \\frac{1}{n_k} \\sum_{i=1}^{n_k} l_i(\\textbf{y}_i, p(f(\\textbf{x}_i; \\omega_k^t))).\\]\nIn this context, we define the variables as follows: \\(n_k\\) represents the number of training samples held by client k, \\(l_i\\) represents the loss function applied to the i-th training sample, \\(\\textbf{y}_i\\) denotes the ground-truth corresponding to \\(\\textbf{x}_i\\), and \\(p(\\textbf{y}|\\textbf{x}_i; \\omega_k^t)\\) signifies the probability vector predicted by model \\(\\omega_k^t\\) for the i-th training sample. Concurrently, model \\(\\omega_k^t\\) undergoes continuous updates until the completion of the local training process by client k.\n\\[\\omega_k^{t+1} = \\omega_k^t - \\eta \\nabla \\mathcal{L}_k(D_k; \\omega_k^t).\\]\nIn this context, \\(\\eta\\) represents the learning rate, governing the magnitude of each model update step. Subsequently, within the subset \\(K_t\\), each client uploads their locally trained model to the server for aggregation, with the aggregation formula outlined as follows.\n\\[\\omega^{t+1} = \\sum_{k \\in K_t} p_k \\omega_k^{t+1},\\]\nwhere \\(p_k = \\frac{n_k}{\\sum_{k \\in K_t} n_k}\\) represents the contribution rate of the k-th client to the current global model. Again, the server selects a subset of clients for the next communication round to send down the global model \\(\\omega^{t+1}\\) until the termination condition is reached."}, {"title": "3.2. Text-to-Image Generative Models", "content": "Text-to-Image Generative Models (T2IGMs) [13, 32, 6] signify a groundbreaking advancement at the convergence of natural language processing and computer vision. These models are specifically engineered to produce visually coherent and contextually relevant images based on textual descriptions, effectively closing the traditional gap between linguistic and visual comprehension. In recent years, T2IGMs have witnessed notable advancements, emerging as a formidable tool with applications ranging from content creation to augmenting the capabilities of IoT systems [12, 16]. This section provides a comprehensive background and definition of T2IGMs, tracing their evolution and elucidating their profound impact across diverse domains.\nT2IGMs typically consist of two primary components: an encoder-decoder architecture and a generative model [13]. The encoder processes the textual input, converting it into a latent representation that captures the semantics of the text. The decoder, on the other hand, takes this latent representation and generates a corresponding image. Often, the generative model incorporates GAN-based techniques to ensure the generated images are both visually convincing and semantically faithful to the input text [18, 17]. The synergy between these components enables T2IGMs to understand and translate textual descriptions into high-quality images. The training of a T2IGM involves a GAN-like setup with a discriminator and generator [34]. The discriminator tries to distinguish between real images and images generated from text, while the generator aims to generate images that fool the discriminator. The loss function typically involves both a generator loss \\(\\mathcal{L}_{gen}\\) and a discriminator loss \\(\\mathcal{L}_{disc}\\):\n\\[\\begin{aligned}\n\\mathcal{L}_{gen} &= -log(D(\\text{Generated Image })) \\\\\n\\mathcal{L}_{disc} &= log(D(\\text{ Real Image })) \u2013 log(1 \u2013 D(\\text{ Generated Image }))\n\\end{aligned}\\]\nwhere D represents the discriminator network. The overall training objective is to find the parameters of the generator network that minimize the generator loss while simultaneously minimizing the discriminator loss. This is often represented as a min-max optimization problem:\n\\[\\underset{f_{generator}}{\\text{min}} \\hspace{0.1cm} \\underset{f_{discriminator}}{\\text{max}} \\hspace{0.1cm} [\\mathcal{L}_{gen} - \\alpha \\mathcal{L}_{disc}],\\]\nwhere \\(\\alpha\\) is a hyperparameter that controls the trade-off between the generator and discriminator losses.\nThe versatility of T2IGMs has led to their adoption across a wide spectrum of domains. In the realm of art and design, T2IGMs serve as creative assistants, turning textual prompts into stunning visual artworks. In e-commerce, they facilitate the automatic generation of product images from textual descriptions, streamlining the process of catalog creation [15, 54]. For accessibility, T2IGMs have been utilized to provide visually impaired individuals with rich, textual descriptions converted into tactile and comprehensible images. Additionally, T2IGMs have enabled advancements in data augmentation for computer vision tasks, allowing the generation of synthetic training data for improved model performance."}, {"title": "4. Methodology", "content": ""}, {"title": "4.1. Overview of Federated Generative Learning Framework", "content": "FGL, as shown in Figure 1, is an innovative and emerging area of research that combines two powerful domains: FL and generative learning. FGL seeks to harness the potential of generative models to create synthetic data while preserving data privacy and decentralization principles in a federated environment. Here's an overview of the key components and concepts within Federated Generative Learning:\n\u2022 Generative Models for Privacy-Preserving Data Synthesis: FGL employs a generative model to create synthetic data samples on the server. This model uses generation prompts sent by each client to create synthetic data samples without centralizing them, preserving data privacy.\n\u2022 Edge Device Collaboration: In contrast to conventional federated learning approaches, which typically involve the transmission of features, parameters, or gradients, our method transmits prompts that correlate with the private data stored on clients to the central server. This novel approach enhances privacy preservation and communication efficiency.\n\u2022 Server-Side Aggregation: The central server aggregates the prompts from edge devices, enhancing the global generative model. This one-shot aggregation might involve techniques to balance the contributions from each device and maintain model quality.\n\u2022 Synthetic Data Generation: Once a robust global generative model is established, it can be employed to generate synthetic data samples that closely resemble the data distribution present on edge devices.\nFGL offers numerous advantages, including enhanced data privacy, reduced communication overhead, and the ability to create synthetic data for data augmentation. It has applications in various fields, especially IoT, to create synthetic IoT sensor data for model training while protecting device privacy. It is worth noting that our method does not require multiple communications and only requires one-shot communication to complete model training, which greatly promotes the realization of green and sustainable IoT."}, {"title": "4.2. Local Prompt Generation", "content": "In this paper, we follow [58], and introduce Local prompt generation, as shown in Figure 2, which serves as a fundamental pillar in the groundbreaking paradigm of FGL. FGL seamlessly merges the principles of FL and generative learning, offering a privacy-preserving and communication-efficient approach to data-driven tasks. At the heart of this innovative approach lies the concept of Local prompt generation, which empowers individual edge devices within a federated network to contribute their private data without compromising data privacy or centralized control.\nIn this context, we utilize two distinct local prompt generation strategies [58], both of which are visually depicted in Figure 2. The first strategy is designed to characterize classes within the local data, while the second focuses on characterizing individual entities present in the local datasets. These two prompt generation strategies share a common objective: to extract essential features from the local training data, facilitating the server-side generation model's ability to effectively collaborate in data synthesis. Importantly, it is essential to emphasize that these strategies do not entail the transmission of model updates or gradients. This unique characteristic substantially mitigates communication overhead, aligning with the core principles of efficient and privacy-preserving FGL."}, {"title": "4.3. Training Data Synthesis", "content": "Training data synthesis constitutes a pivotal phase within the innovative paradigm of FGL. FGL seamlessly integrates the principles of FL and generative learning, with the overarching goal of revolutionizing the execution of data-driven tasks while upholding data privacy and decentralized control. In the FGL framework, training data synthesis assumes a transformative role, enabling individual edge devices to actively contribute to the development of a global generative model without exposing sensitive data.\nTraining data synthesis in FGL commences with the generation of descriptive prompts by edge devices. These prompts encapsulate the essence of the local data they hold, serving as abstract yet informative representations. The prompts are designed to convey crucial insights about the data, such as class characteristics or entity attributes, without divulging raw data details. This synthesis of prompts aligns with the privacy-centric ethos of FL, as no actual data is shared during this process.\nUpon receiving all the prompts contributed by the edge devices, the central server embarks on the pivotal phase of data synthesis. This process involves the generation of every training sample, denoted as \\(\\textbf{t}_i\\), by prompting the pre-trained generative models, e.g., Stable Diffusion model, with each prompt \\(\\textbf{p}_i\\). We follow [58], the sequence of actions can be summarized as follows:\n\\[\\textbf{t}_i = G (\\textbf{z}_i, \\textbf{p}_i) = \\sqrt{\\beta} \\sum_{t=1}^T \\frac{1}{\\sqrt{T}} \\sqrt{1 - \\beta}^{T-t} G_{\\theta_t} (\\textbf{z}_i, t).\\]\nIn this process, \\(\\textbf{z}_t\\) represents a randomly generated noise vector, \\(\\textbf{p}_i\\) signifies the prompt generated by edge devices, and \\(G_{\\theta_t}(...)\\) stands for the denoising network, which is parameterized with \\(\\theta\\) at the specific time step t. The hyperparameter \\(\\beta\\) plays a pivotal role in balancing image quality against diversity, while T dictates the number of diffusion steps to be taken. This inference process follows an iterative pattern wherein the generated image undergoes denoising at each step before ultimately yielding the finalized synthetic training image. Subsequently, the central server orchestrates the generation of the synthetic training dataset, denoted as S, comprising pairs of training samples and corresponding labels, represented as \\(S = \\{(\\textbf{s}_i, y_i)\\}_{i=1}^N\\).\nCrucially, training data synthesis in FGL operates without the exchange of model updates or gradients, a distinctive departure from traditional FL. Instead, it empowers edge devices to participate actively in the generative learning process without relinquishing control over their data. This approach not only enhances privacy preservation but also minimizes communication overhead, a critical consideration in resource-constrained environments like IoT."}, {"title": "4.4. One-shot Learning", "content": "One-shot learning streamlines the knowledge transfer process within FGL. In traditional FL, multiple rounds of model updates are exchanged between edge devices and the central server, often leading to substantial communication overhead. In contrast, one-shot learning condenses this into a singular communication round, dramatically reducing the amount of data transferred. The core objective of one-shot updating is to enrich the global generative model with collective insights from edge devices. These insights are encapsulated in the prompts generated by edge devices, which offer descriptive information about their local datasets. The central server leverages this valuable input to enhance the capabilities of the generative model. Following the acquisition of the synthetic training set denoted as \\(S = \\{(\\textbf{s}_i, y_i)\\}_{i=1}^N\\), our subsequent step involves the joint training of the model on the central server. Specifically, we employ the AlexNet architecture as the model of choice and utilize the cross-entropy loss function.\n\\[\\mathcal{L} = -\\frac{1}{N} \\sum_{i=1}^N y_i \\log (\\hat{y}_i) + (1 - y_i) \\log (1 \u2013 \\hat{y}_i)\\]\nThe efficiency of one-shot updating contributes to the robustness and sustainability of FGL. It allows for the seamless integration of generative learning techniques into IoT and other data-sensitive domains, where resource-efficient machine learning is essential. Therefore, one-shot updating in FGL embodies the essence of efficient and privacy-conscious knowledge transfer. It empowers edge devices to contribute effectively to the generative learning process while preserving data privacy and minimizing communication overhead."}, {"title": "4.5. Complexity Analysis", "content": "Here, we focus on analyzing the algorithm complexity on the client side. It can be seen from the above algorithm that on the client side, the client needs to generate local prompts and upload the generated prompts. For the sake of simplicity, we let the complexity of generating a prompt be C (depending on the specific generation algorithm), then the algorithm complexity of clients performing local prompt generation operations is O(KCN). In addition, considering that the upload operation can be completed in one go, the complexity is O(N)."}, {"title": "5. Experomental Results", "content": ""}, {"title": "5.1. Experiment Setup", "content": "The experiments are conducted within a uniform computing environment, comprising Linux Ubuntu 10.04, an Intel i5-4210M CPU, 32GB RAM, and a 1024GB SSD. The implementation is facilitated through the utilization of the Pytorch and Foundation Model libraries."}, {"title": "5.3. Discussion", "content": "Privacy has been a paramount concern in IoT ecosystems, and our One-shot FGL approach offers a pragmatic solution. By allowing edge devices to share abstract prompts instead of raw data, we strike a balance between data utility and privacy preservation. This design mitigates the risk of data breaches and unauthorized access while enabling the collaborative generation of synthetic data. The localization of data aggregation further fortifies privacy, as prompts, not individual data samples, are aggregated. The privacy-centric nature of FGL aligns with the ethical use of data and user expectations for data confidentiality in the IoT era.\nSustainability is at the core of our approach. By reducing the need for extensive data transmission and centralization, FGL contributes to the ecological sustainability of IoT systems. The conservation of energy and bandwidth resources not only supports environmental goals but also enhances the operational longevity of IoT devices. FGL's ability to generate high-quality synthetic data from decentralized sources promotes sustainable practices by minimizing the environmental footprint of data transfer and storage. This integration of sustainability and privacy-consciousness positions FGL as a pioneering approach in building responsible and eco-friendly IoT ecosystems.\nWhile our approach shows promise, several challenges and future directions warrant consideration. One key challenge is optimizing the generative model's performance while working with decentralized and diverse data sources. Developing advanced generative techniques that can adapt to various data distributions across edge devices is essential. Additionally, research in federated learning orchestration and model aggregation techniques needs further exploration to maximize the utility of FGL.\nFinally, it is crucial to highlight that the proposed framework exhibits flexibility and can be readily extended to various tasks. The adaptability stems from the ability to employ different generation models for prompt generation corresponding to diverse task data. For instance, the VisualGLM model can be employed to generate prompts and subsequently facilitate learning from video data. The scalability of the framework across different tasks is confirmed, underscoring the importance of task scalability in a learning framework."}, {"title": "6. Conclusions", "content": "In this paper, we have introduced and delved into the concept of OSFL as an innovative approach aimed at addressing the dual imperatives of sustainability and privacy within the realm of the IoT. OSFL, characterized by its reduction of communication rounds and optimization for energy efficiency through generative learning, holds significant promise for reshaping the landscape of machine learning in IoT ecosystems. Our research has successfully demonstrated the feasibility and effectiveness of OSFL in achieving sustainable IoT operations. By condensing the traditional federated learning process into a single communication round, OSFL substantially mitigates energy consumption, communication overhead, and latency. Moreover, the integration of generative learning techniques ensures the preservation of data privacy, even as knowledge is efficiently shared among IoT devices. OSFL stands as a novel and environmentally conscious paradigm that aligns with the global imperative to reduce the environmental footprint of technology while facilitating advanced machine learning capabilities.\nLooking ahead, the potential applications of OSFL in green and sustainable IoT are expansive. From optimizing energy consumption in smart cities to enhancing environmental monitoring in remote regions, OSFL can empower IoT devices to learn and collaborate effectively while minimizing their environmental impact. Furthermore, OSFL\u2019s ability to balance sustainability and model performance opens doors to new opportunities in domains such as healthcare, agriculture, and industrial automation, where resource-efficient machine learning is crucial. In conclusion, OSFL not only underscores our commitment to responsible and sustainable technology development but also offers a transformative pathway to a greener and more intelligent IoT ecosystem."}]}