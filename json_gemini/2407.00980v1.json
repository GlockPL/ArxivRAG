{"title": "Acceleration method for generating perception\nfailure scenarios based on editing Markov process", "authors": ["Canjie Cai"], "abstract": "With the rapid advancement of autonomous driving\ntechnology, self-driving cars have become a central focus in the\ndevelopment of future transportation systems. Scenario gener-\nation technology has emerged as a crucial tool for testing and\nverifying the safety performance of autonomous driving systems.\nCurrent research in scenario generation primarily focuses on\nopen roads such as highways, with relatively limited studies on\nunderground parking garages. The unique structural constraints,\ninsufficient lighting, and high-density obstacles in underground\nparking garages impose greater demands on the perception\nsystems, which are critical to autonomous driving technology.\nThis study proposes an accelerated generation method for\nperception failure scenarios tailored to the underground parking\ngarage environment, aimed at testing and improving the safety\nperformance of autonomous vehicle (AV) perception algorithms\nin such settings. The method presented in this paper generates\nan intelligent testing environment with a high density of per-\nception failure scenarios by learning the interactions between\nbackground vehicles (BVs) and autonomous vehicles (AVs) within\nperception failure scenarios. Furthermore, this method edits the\nMarkov process within the perception failure scenario data to\nincrease the density of critical information in the training data,\nthereby optimizing the learning and generation of perception\nfailure scenarios. A simulation environment for an underground\nparking garage was developed using the Carla and Vissim\nplatforms, with Bevfusion employed as the perception algorithm\nfor testing. The study demonstrates that this method can gen-\nerate an intelligent testing environment with a high density of\nperception failure scenarios and enhance the safety performance\nof perception algorithms within this experimental setup.", "sections": [{"title": "I. INTRODUCTION", "content": "As autonomous driving technology rapidly advances, self-\ndriving cars have become a focal point in future transporta-\ntion systems. One of the biggest challenges in autonomous\ndriving research today is verifying the safety performance of\nautonomous vehicles. Existing testing methods include virtual\nsimulation and real-world road tests in natural driving environ-\nments [1]. Natural driving scenarios are characterized by high\nparameter dimensions, large parameter ranges, and massive\ncombinations, with dangerous scenarios only constituting a\nsmall fraction, exhibiting a \"long tail effect.\" According to\nthe findings in [2], demonstrating with 95% confidence that\nautonomous vehicles can achieve a 20% reduction in accident\nrates compared to human-driven vehicles necessitates at least\n14.2 billion kilometers of testing in naturalistic road environ-\nments. Due to this severe inefficiency, autonomous vehicle\ndevelopers face significant economic and time costs, which\nseverely hinder the market entry process for autonomous\nvehicles.\nCurrently, scenario generation technology has become key\nto enhancing and ensuring the safety performance of au-\ntonomous driving systems. This technology primarily involves\nefficiently generating and simulating various driving scenarios\nto verify and improve the safety performance of autonomous\ndriving systems, such as simulating traffic accidents, sudden\nweather conditions, and extreme traffic behaviors on open\nroads. Scenario generation technology also ensures that au-\ntonomous driving algorithms are tested under safe conditions,\nreducing the cost of testing these algorithms.\nScenario generation studies mainly focus on open roads\nsuch as highways, with relatively limited studies on under-\nground parking garages. Underground parking garages, with\ntheir structural constraints, insufficient lighting, and high-\ndensity obstacles, pose higher demands on the critical percep-\ntion systems of autonomous driving technology. The percep-\ntion systems of autonomous vehicles face greater challenges\nin environments like underground parking garages, where any\nfailure could lead to severe safety consequences.\nThis study proposes an accelerated generation method for\nperception failure scenarios tailored to underground parking\ngarage environments, aimed at testing and improving the safety\nperformance of perception algorithms in autonomous vehicles\nunder such conditions. The method presented in this paper\ngenerates an intelligent testing environment with a high density\nof perception failure scenarios by learning the interactions\nbetween background vehicles (BVs) and autonomous vehicles\n(AVs) within perception failure scenarios. Furthermore, this\nmethod edits the Markov process within the perception failure\nscenario data to increase the density of critical information\nin the training data, thereby optimizing the learning and\ngeneration of perception failure scenarios.\nThe main contributions of this method can be summarized\nas follows:\n1) Unlike previous methods for generating perception failure\nscenarios [3], [4], this method generates perception fail-\nure scenarios by learning from the interactions between\nbackground vehicles (BVs) and autonomous vehicles\n(AVs).\n2) It incorporates the editing Markov process from [5],\ndemonstrating its effectiveness in generating perception\nfailure scenarios.\n3) It provides a scenario generation scheme that enhances\nthe safety performance of perception algorithms in un-\nderground parking garage environments."}, {"title": "II. RELATED WORK", "content": "Scenario generation technology has become a key tool\nfor validating and improving the safety performance of au-\ntonomous driving systems. This technology primarily involves\nthe efficient generation and simulation of various driving\nscenarios to validate and improve the safety performance\nof autonomous systems, such as simulating traffic accidents,\nsudden weather conditions, and extreme traffic behaviors on\nopen roads. According to [6], [7], current scenario generation\nmethods can be broadly categorized into three types: data-\ndriven, adversarial generation-based, and knowledge-based\nscenario generation methods.\nData-driven scenario generation methods [8], [9], [10], [11]\nmainly rely on replaying or learning from real-world driving\ndata to generate scenarios. These methods produce scenarios\nwith higher realism but lack controllability and efficiency\nwhen generating dangerous or other specific scenarios. Ad-\nversarial generation-based scenario generation methods [3],\n[4], [12] primarily produce scenarios by targeting the percep-\ntion, decision-making, and control algorithms of autonomous\nsystems, creating scenarios that these algorithms struggle to\nhandle. These methods are more efficient in generating dan-\ngerous or specific scenarios, but the realism of the scenarios\nis lower. Knowledge-based scenario generation methods [13],\n[14], [15], [16] typically use expert knowledge and predefined\nrules to generate scenarios that meet specific standards. These\nmethods offer higher controllability but lack realism in the\ngenerated scenarios. Each method has unique characteristics\nand can be flexibly chosen or combined based on specific\napplication requirements.\nCurrent perception failure scenario generation methods [3],\n[4] are primarily based on adversarial generation techniques,\nattacking perception algorithms through the generation of\nadversarial images or point clouds to create perception failure\nscenarios. [3] proposed a method using differentiable render-\ning to generate images that induce errors in object detection\n[17], [18] or misclassification by classification algorithms [19],\n[20]. [4] developed a method to generate universal 3D ad-\nversarial objects that deceive LIDAR detectors, causing point\ncloud-based object detection algorithms to malfunction. The\nlimitations of these methods can be summarized as follows:\n1) The generated scenarios are primarily static, based on\npoint clouds or images.\n2) They mainly rely on adversarial generation techniques,\nmaking it difficult to ensure the realism of the scenarios.\n3) There is a lack of generalizability, making it difficult to\nadapt to different types of perception algorithms."}, {"title": "III. METHODOLOGY", "content": "This section primarily introduces the problem description\nfor accelerated generation of perception failure scenarios based\non interactions between background vehicles (BVs) and au-\ntonomous vehicles (AVs). In this study, the entire scenario\nis denoted as x, where x consists of the initial states of\nthe AV and BVs and all the maneuvers across the time\nsteps. Specifically, Sk represents the state of all vehicles\nat time step k (including position, velocity, etc.), and Uk\ndenotes the maneuvers of all BVs at the same time step.\nFor individual vehicles, skj and ukj respectively indicate the\nstate and maneuver of the j-th BV at time step k. Notably,\nS0 represents the state of the AV at time step k. The entire\nscenario can be expressed as x = [S0,U0,U1, \u2026\u2026\u2026,UT],\nwhere each Sk and Uk are the sets of vehicle states and\nmaneuvers, respectively.\nAt each time step k, assuming P\u2081 represents the maneuver\ndistribution for a single BV and that the maneuvers of different\nBVs are independent, the conditional probability of the set of\nall BV maneuvers Uk, given the states of all BVs and the AV\nat time step Sk, can be expressed as:\n$$P(Uk | Sk) = \\prod_{j=1}^{M} Pq (Ukj | Sk)$$\nUtilizing the Markov property, the probability distribution\nof the entire scenario can be represented as a product over the\ntime steps:\n$$P(x) = P(S_0) \\times \\prod_{k=0}^{T} P(Uk | Sk)$$\nThe probability of a perception failure event A can be esti-\nmated using the Monte Carlo method, assuming a total number\nof sampled scenarios N, with the following approximation:\n$$P(A) = E_{x \\sim P(x)} [P(A\\vert x)] \\approx \\sum_{i=1}^{N} P (A\\vert x_i) P(x_i)$$\nExpanding P(xi) yields:\n$$P(A) \\approx \\sum_{i=1}^{N}P (A \\vert x_i) P (Si0) \\prod_{k=0}^{T}\\prod_{j=1}^{M} Pq (Uikj | Sik)$$\nThus, optimizing the maneuver behavior distribution Pq\nof BVs to maximize P(A) can increase the likelihood of\noccurrence of perception failure scenarios:\n$$\\max_{Pq} P(A) \\approx \\max_{Pq} \\sum_{i=1}^{N}P (A\\vert x_i) \\prod_{k=0}^{T}\\prod_{j=1}^{M} Pq (Uikj | Sik)$$"}, {"title": "B. Editing Markov Process", "content": "In autonomous driving data, non-safety-critical states pre-\ndominate, with safety-critical states constituting only a small\nfraction. This distribution makes it challenging for traditional\ndeep learning models to effectively learn from data cluttered\nwith a majority of non-safety-critical states [21]. To address\nthis issue, [5] introduced the concept of editing Markov pro-\ncess. By removing non-safety-critical states from the Markov\nprocess, training the model exclusively with data from safety-\ncritical states significantly enhances the model's ability to learn\nfrom complex scenarios.\nFor complex environments like underground parking\ngarages, this paper also applies the method of editing Markov\nprocess to optimize the scenario generation process. Non-\ncritical states, defined as states that minimally contribute to\nthe final generation of hazardous scenarios, are excluded from\nthe state set xc. Thus, it can be assumed that:\n$$P(A\\vert xc) \\approx P(A \\vert x)$$\nLet Sc represent the critical states, and use ISikEsc as the\nindicator function for critical states. The original optimization\nproblem can be approximated as:\n$$\\max_{Pq} P(A) \\approx \\max_{Pq} \\sum_{i=1}^{N} P (A\\vert XCi) \\prod_{k=0}^{T} \\prod_{j=1}^{M} Pq (Uikj | Sik) ISik\\in SC$$"}, {"title": "C. Transforming the Deep Learning Problem", "content": "This study employs deep learning methods to optimize\nthe maneuver distribution Pq of background vehicles (BVs)\nto maximize the probability of perception failure scenarios,\nP(A). Based on Equation 7, this paper sets the loss function\nas shown in Equation 8:\n$$L = - \\sum_{i=1}^{N}P(A\\vert ci) \\prod_{k=0}^{T}\\prod_{j=1}^{M} Pq (Uikj | Sik) ISikESC$$\nTo further simplify, this paper uses the indicator function\nfor perception failure events, IA(x), as an approximation for\nP(Axci), and transforms Equation 8 into:\n$$L = - \\sum_{i=1}^{N}IA(x) \\prod_{k=0}^{T}\\prod_{j=1}^{M} Pq (Uikj | Sik) ISik\\in SC$$\nSince the product operation might lead to issues with\nnumerical stability during training, this paper ultimately ap-\nproximates Equation 9 as:\n$$L = - \\sum_{i=1}^{N}IA(x)\\sum_{k=0}^{T}\\sum_{j=1}^{M}\\log Pq (Uikj | Sik) ISik\\in Sc$$"}, {"title": "D. Generating an Intelligent Testing Environment", "content": "This section explains how the trained maneuver distribution\nmodel of background vehicles (BVs) is used to generate an\nintelligent testing environment with an increased number of\nperception failure scenarios. The method for generating the\nintelligent testing environment primarily modifies the calcula-\ntion of the BVs' maneuver distributions based on the original\nenvironment. The specific process for computing the BVs'\nmaneuvers in the intelligent testing environment is detailed\nin the pseudocode shown in algorithm 1."}, {"title": "IV. EXPERIMENTS", "content": "Static Simulation Environment. This study constructs\na static simulation environment of an underground parking\ngarage using Carla [22]. The model utilized is sourced from\nthe OpenAVP project and is based on a 1:1 simulation of the\nactual structure and environmental features of the underground\nparking garage at the Southern University of Science and\nTechnology of Engineering. It perfectly replicates the details\nof the real environment\nTraffic Flow Generation. This research employs PTV\nVissim [23] to develop the road network within the static\nsimulation environment of the underground parking garage,\nsubsequently generating the vehicle traffic. Specifically, de-\ncision points are added at all junctions within the network,\nallowing the study to influence vehicle routing decisions at\nthese junctions by adjusting the decision points [24]. The\nfinal configuration of the Vissim underground parking garage\nnetwork.\nCoupled Simulation. This research generates the final\nunderground parking garage simulation environment through a\ncoupled simulation using Carla and PTV Vissim. The specific\nprocess of the Carla and Vissim coupled simulation is depicted\n, including the following technical aspects:\n1) Using Vissim's COM interface to read vehicle position\ndata.\n2) Constructing a Bridge module to translate vehicle posi-\ntion data from the Vissim coordinate system to the Carla\ncoordinate system.\n3) Synchronizing Vissim traffic within Carla.\nSimulation Environment Configuration. In this study,\nthe autonomous vehicle (AV) navigates a fixed route within\nthe underground parking garage simulation environment\nDeployment of Perception Algorithm\nSelection of Perception Algorithm. This study employs\nBevfusion [25] as the perception algorithm for subsequent\nexperimental testing. Bevfusion is a multimodal 3D object"}, {"title": "C. Experimental Setup", "content": "Validation of the Effectiveness of Accelerated Genera-\ntion of Perception Failure Scenarios. This experiment aims\nto validate the proposed method's effectiveness for accelerat-\ning the generation of perception failure scenarios. The main\nsteps and settings of this experiment are as follows:\n1) Collect driving scenario data from the simulation envi-\nronment. This experiment collected 17 hours of driving\nscenario data at a frequency of 2Hz, totaling 122,400\nframes, with each frame's data details shown in Table VI.\n2) Select perception failure scenario data. This experiment\nuses the data frames from the 10 seconds prior to each\nperception failure frame as a perception failure scenario\ndataset.\n3) Identify critical states within the perception failure sce-\nnario data. In this experiment, visible BVs within a 20-\nmeter radius of the AV in the perception failure frame are\nconsidered critical BVs. All states of critical BVs within\n7.5 seconds before the failure are set as critical states.\n4) Train the BV maneuver distribution model using only\ncritical states versus using all data. The input to the BV\nmaneuver distribution model includes the states of the\nAV and BVs, and the output is the BV's maneuvers, with\nspecific input-output details referring to Table VI. The\nTraining parameters for the BV maneuver distribution\nmodel\n5) Compare the proportion of perception failure frames\nwithin 0.5 hours in the generated intelligent testing envi-\nronment.\nValidation of Enhanced Safety Performance of the Per-\nception Algorithm. The purpose of this experiment is to\nvalidate that the intelligent testing environment generated by\nthe proposed method can enhance the safety performance of\nthe perception algorithm. The main steps and settings of this\nexperiment are:\n1) Collect a dataset in the intelligent testing environment\ngenerated by the proposed method for retraining Bev-\nfusion, keeping the dataset specifics consistent with Ta-\nble III.\n2) Retrain Bevfusion using the dataset collected in the\nintelligent testing environment. The hardware configura-\ntion and training parameters for training Bevfusion are\nconsistent with Table IV and Table V.\n3) Compare the proportion of perception failure frames\nwithin 0.5 hours between the original simulation envi-\nronment and the intelligent testing environment using the\ntrained Bevfusion.\nIt is noteworthy that to verify the generalizability of the\nproposed method, this study conducted repeated experiments\nusing different definitions of perception failures. The relation-\nship between experiment numbers and definitions of percep-\ntion failures"}, {"title": "V. RESULTS", "content": "Validation of the Effectiveness of Accelerated Genera-\ntion of Perception Failure Scenarios. Based on Table IX,\nit can be observed that the number of critical states in\nperception failure scenario data is significantly lower than\nthe total number of states. From Figure 7, it is evident\nthat training the BV maneuver distribution model using only\ncritical states from perception failure scenarios results in a\nfaster decrease in validation set loss. As shown in Table X,\nthe proportion of perception failure frames in intelligent testing\nenvironment a is similar to that in the original simulation\nenvironment, whereas environment b shows a much higher\nproportion of failure frames. These results validate that the\nproposed method can generate an intelligent testing environ-\nment enriched with high-density perception failure scenarios\nand confirm the effectiveness of the editing Markov process in\noptimizing the learning and generation of these\nscenarios. Notably, Figure 7 reveals noticeable overfitting in\nall experiments except for experiment a, which has a higher\nvolume of data as seen in Table IX. Therefore, the overfitting\nobserved in Figure 7 is hypothesized to be due to insufficient\ndata volume.\nValidation of Enhanced Safety Performance of the Per-\nception Algorithm. According to Table XI, it is observed\nthat datasets collected in the intelligent testing environment\nsignificantly reduce the proportion of perception failure frames\nof Bevfusion in the original simulation environment compared\nto those collected under normal conditions [31]. Some visual\ncomparison results are shown\nIt is speculated that the increased proportion of perception\nfailure frames in the intelligent testing environment enables\nBevfusion to handle these scenarios more effectively. Overall,\nthese results validate that the proposed method can enhance the\nsafety performance of the perception algorithm in the original\nsimulation environment."}, {"title": "VI. DISCUSSION", "content": "The results of this study validate the proposed method's\nability to accelerate the generation of perception failure sce-\nnarios and enhance the safety performance of perception algo-\nrithms. Compared to the perception failure scenario generation\nmethods mentioned in section II, the proposed method exhibits\nthe following characteristics:\n1) It is data-driven and can extend from simulated to real-\nworld scene data, enhancing the realism of the generated\nscenarios.\n2) The method is not designed for a specific perception\nalgorithm, allowing for better scalability across different\nperception technologies.\n3) It generates scenarios through interactions between BVs\nand AVs, rather than directly producing point clouds and\nimages, which facilitates further research into the impact\nof vehicle interactions on the generation of perception\nfailure scenarios."}, {"title": "A. Limitations", "content": "The method proposed in this paper has the following\nlimitations:\n1) Poor controllability of scenario generation. It is unable to\ngenerate specific types of perception failure scenarios in\na controlled manner.\n2) The method for selecting critical states in perception\nfailure scenarios significantly impacts the performance of\nthe proposed method.\n3) It requires a large dataset of perception failure scenarios."}, {"title": "VII. CONCLUSIONS", "content": "The results of this study confirm that the proposed method\ncan generate an intelligent testing environment with high-\ndensity perception failure scenarios based on the original\nsimulation environment, thereby enhancing the safety per-\nformance of perception algorithms within that environment.\nFurthermore, the results also validate the effectiveness of\nthe editing Markov process in optimizing the learning and\ngeneration of perception failure scenarios."}]}