{"title": "Measuring Human Contribution in Al-Assisted\nContent Generation", "authors": ["Yueqi Xie", "Tao Qi", "Jingwei Yi", "Ryan Whalen", "Junming Huang", "Qian Ding", "Yu Xie", "Xing Xie", "Fangzhao Wu"], "abstract": "With the growing prevalence of generative artificial intelligence (AI), an increasing amount of content is no longer exclusively\ngenerated by humans but by generative Al models with human guidance. This shift presents notable challenges for the\ndelineation of originality due to the varying degrees of human contribution in Al-assisted works. This study raises the research\nquestion of measuring human contribution in Al-assisted content generation and introduces a framework to address this\nquestion that is grounded in information theory. By calculating mutual information between human input and Al-assisted\noutput relative to self-information of Al-assisted output, we quantify the proportional information contribution of humans in\ncontent generation. Our experimental results demonstrate that the proposed measure effectively discriminates between varying\ndegrees of human contribution across multiple creative domains. We hope that this work lays a foundation for measuring\nhuman contributions in Al-assisted content generation in the era of generative Al.", "sections": [{"title": "Results", "content": "Recent advances in large language models (LLMs)1\u20135 have impacted our personal and working lives in significant ways,\nmost notably by changing the process of content generation.6,7 Artificial intelligence (AI) \u201ccopilots\u201d have emerged as a new\nand powerful content production tool across a variety of domains8\u201310, such as lyrics creation11, office work9,10, academic\nwriting, etc. Consequently, an increasing amount of new content being generated is no longer solely created by humans but is\nrather the result of AI-assisted creation12\u201314. In this new creative modality, humans contribute by providing prompts to AI\nmodels, resulting in the generation of \u201cAI-assisted output\u201d, as illustrated in Figure 1a.\nThis development has raised debates about determining the originality and corresponding regulation of content generated\nwith AI assistance12,15. The varying degrees of human contribution in AI-assisted generation complicate the attribution of\nintellectual contribution to AI-assisted outputs. This issue is particularly pertinent in fields that prioritize originality, such\nas education16, academic research17\u201319, and creative work20. For example, universities face a dilemma in whether to ban or\nembrace AI. Administrators and instructors are concerned that students might use AI to create materials for evaluation with\nvarying levels of originality, potentially compromising educational fairness and effectiveness21,22. Similarly, there is a growing\ndebate, underscored by notable incidents23,24, concerning the copyright eligibility of AI-assisted works20, 25, 26.\nAt the two extreme ends of the human-AI contribution spectrum, the attribution of originality is relatively clear. If a human\nauthor simply uses AI to polish their document, it should be considered the result of the author's own work. Conversely, if\na human uses a short, less-informative prompt to generate a large amount of text, it will not reflect much of the human's\nintellectual conception. However, there remains a substantial grey area between these two extremes, in which determining\noriginality requires insight into the degree of human contribution during the AI-assisted generation process. Hence, there is an\nurgent need for a credible measure by which to evaluate human contribution in AI-assisted content generation.\nIn this paper, we address the quantification of human contribution in AI-assisted content generation. We begin with the\nrecognition that a major obstacle is the lack of a well-defined perspective, or medium, by which to ascertain the extent to\nwhich content output can be attributed to humans rather than the AI tools they have used. Towards this goal, we introduce a\nnew general framework within which we provide a preliminary attempt to quantify human contribution in AI-assisted content\ngeneration. Our framework hinges on the concept of information content as a modeling medium. Utilizing principles from\ninformation theory27, as depicted in Figure 1b, our approach centers on the quantification of the proportion of the information"}, {"title": "Results", "content": "content in the AI-assisted output that can be attributed to human input. Specifically, it is a ratio of two quantities. The\ndenominator is the total/unconditional information content (surprisal) in AI-assisted output, calculated as the negative logarithm\nof the probability of generating the AI-assisted generated content, which we refer to as self-information, I(y). The numerator,\nI(x;y), is the portion of self-information I(y) that is shared with the total information content from human input, I(x), which\nwe define as mutual information. The difference between the two is the conditional self-information in AI-assisted output given\nuser input, I(yx), calculated as the negative logarithm of the probability of generating the AI-assisted output conditional on\nhuman input.\nWe systematically validate the proposed method as a reliable measure of human contribution by evaluating its effectiveness,\ndomain adaptivity, and model adaptivity. To achieve this, we construct a comprehensive dataset of AI-assisted content\ngeneration, encompassing various levels of human contribution, multiple creative domains, and outputs from different LLMs.\nFor instance, Figure 1c illustrates the distribution of the outcomes of our proposed measure for AI-assisted poem generation,\nacross three varying levels of human contribution, ranging from high to low, using the LLM Llama-3. Our proposed measure\neffectively discriminates between varying degrees of contribution, generally producing lower values for content with less human\ncontribution. Additionally, we investigate the impact of content length, resilience to adaptive attacks, and generalization of\nour method in evaluation. We further apply our measure to real-world human-AI co-creation data, demonstrating its practical\napplicability. In brief, this paper poses a novel research question on quantitatively evaluating human contribution in AI-assisted\ngeneration and presents a simple yet effective information-based measure as a potential solution."}, {"title": "Dataset Construction", "content": "To verify the reliability of the proposed measure of human contribution, we construct a dataset of AI-assisted generation data\nwith known varying levels of human contribution. Note that there is no absolute ground truth for assessing human contribution.\nTherefore, by design, our dataset spans a very large range of human contribution in AI-assisted output with distinct levels that\nare hardly controversial. For a comprehensive evaluation, we further vary three factors, beyond the level of human contribution:\n(1) domains, focusing on those where originality protection is crucial; (2) different LLMs; and (3) different random generation\nruns. Building this dataset primarily involves two steps: raw information collection and processing and Al-assisted content\ngeneration.\nRaw Information Collection and Processing: First, we collect and process multi-level information in various domains.\nSpecifically, we sample raw data from public datasets across the following domains: academic paper abstracts, news articles,\npatent abstracts, and poems. We sample 2,000 entries for each domain. For paper abstracts, each raw data entry includes\ncontent, title, and subject; for the other three domains, each raw entry includes content and title. Details of the original dataset\nand sampling process are provided in Supplemental Materials Section 1.1. We further process the data into a uniform structure\nwith decreasing levels of information: content, summary, title, and subject (except poems, because of short titles), with missing\nparts of the raw data supplemented using GPT-3.52. The corresponding statistics are presented in Table 1.\nAI-Assisted Content Generation: Next, we generate new content using LLMs with varying levels of human input\nconstructed from the earlier process, categorized as follows: polishing, generation with summary, generation with title,\ngeneration with subject (where applicable). These inputs use information corresponding to content, summary, title, and subject,\nrespectively. The detailed prompt constructions are shown in Supplementary Materials Section 1.2. These human inputs\nrepresent varying levels of human contribution, from high to low, based on the amount of information provided. To support a\ncomprehensive analysis, we apply different LLMs, including the state-of-the-art open-source LLMs Llama-3\u00b9 and Mixtral28\nand the chatbot GPT-3.52. We generate 5 times for a human input with the temperature set as 0.7 for diverse outputs."}, {"title": "Human Contribution Evaluation", "content": "We evaluate the effectiveness of the proposed measure using the constructed dataset. This section focuses on the original\nscenario where both the AI-assisted output y and human input x are known, and the AI model Me's output probability is"}, {"title": "Impact of Content Length", "content": "In addition to the varying levels of human contribution present in our constructed dataset, we further validate our method\nby varying the length of the AI-assisted content that is generated. This helps us determine whether our method adequately\nevaluates the proportion of human contribution in AI-assisted generated content when the same human input information yields\nAI-assisted outputs of different lengths. Intuitively, when human informational input remains constant, the longer the generated\ncontent, the smaller the measured human contribution should be. To verify this, we use Llama-3 to generate AI-assisted outputs\nof varying lengths from titles by specifying the length of the AI-assisted output in the prompt.\nFigure 3 shows the results for paper and patent abstracts with different lengths. The results for news and poems are included\nin Supplementary Materials Section 2.1. The results align with our initial expectation: as we require AI-assisted output to be\nlonger, human informational contribution relative to total informational content decreases, as does our measurement of human\ncontribution."}, {"title": "Resilience to Adaptive Attacks", "content": "We further investigate whether adaptive attacks could be employed in real-world applications to artificially inflate measured\nhuman contribution. To this end, we design two adaptive attacks: we separately append two instructions to the original input\nthat do not provide additional information but do guide the AI's generation process to potentially increase the measured human\ncontribution. These instructions are to 1) always choose words you rarely use and 2) mimic human writing. The first instruction"}, {"title": "Generalization of Our Method", "content": "In real-world applications, the AI model's generative probability $p_\\theta$ may not be available. For instance, generative applications\nlike ChatGPT do release generative probabilities to users. This section demonstrates whether a surrogate model with generative\nprobability $p_{\\theta'}$ can be employed for our assessment when the AI model's generative probability $p_\\theta$ is unknown. Specifically,\nin this experiment, we use Llama-3 and Mistral as the surrogate models and use their generative probability $p_{\\theta'}$ to assess the\ncontent generated by various LLMs (Llama-3, Mistral, and ChatGPT) in the constructed dataset.\nFigure 5 illustrates the effectiveness of our approach in the news domain for various combinations of surrogate model (rows)\nand generation model (columns). Results for other domains are presented in Supplementary Materials Section 2.3. We observe\nthat even without using the original AI model for evaluation, our proposed measure captures the expected trend in human\ncontribution across various surrogate and generative model combinations. This validates the applicability of our measure when\ngeneration model information is unavailable. This effectiveness may be attributed to the similar generative distributions across\nLLMs, stemming from the universal knowledge they share during training. The gradient in human contribution across varying\nlevels of human input is far more pronounced than the differences between the distributions themselves, indicating that our\nmethod is a robust assessment tool."}, {"title": "Applications to Real-World Al-Assisted Generation", "content": "The aforementioned experiments were conducted on a synthetic dataset with known varying levels of human contribution,\nallowing us to verify the reliability of our measurement method. To test its real-world applicability, we apply our method to\nreal-world scenarios involving user interactions with LLMs. Specifically, we sample cases from the WildChat-1M dataset29\nand classify them using a prompt classification tool30. We then sample data from two prompt classes related to AI-assisted\ngeneration: \"assisting or creative writing\" (2,000 entries) and \"editing or rewriting\" (500 entries), according to their counts in\nthe dataset. The evaluation surrogate model is Llama-3, while the contents were generated with ChatGPT.\nFigure 6a demonstrates the overall distribution of measured human contributions across the two classes. We expect that\nthe \"editing or rewriting\" class will involve more human contribution than \"assisting or creative writing.\" Consistent with this,\nthe measured human contributions are generally higher for \"editing or rewriting.\" We present two specific cases in Figure 6b,\nwith additional cases detailed in Supplementary Materials Section 2.4. Overall, the measured human contributions align with\nour expectations. For instance, the \u201cediting or rewriting\" case is measured as having 92.86% human contribution, while the\n\"assisting or creative writing\" case is measured at 16.14%. These distribution and case study results further support the validity\nof our method in measuring human contribution in real-world AI-assisted generation contexts."}, {"title": "Discussion", "content": "Technological advancements in generative AI have significantly altered the content production process, resulting in the\ngeneration of a vast amount of AI-assisted content 8,10,11. This proliferation of AI-assisted generated content poses challenges\nto the delineation of originality of these works, sparking intense debates regarding the application of AI in areas that prioritize\noriginality, such as education, academic research, and copyright23\u201325,31\u201333. It has been increasingly recognized that defining\nthe intellectual originality of AI-assisted generated content cannot be approached with a one-size-fits-all solution; instead, it\nrequires consideration of the extent of human contribution to the work20,22,32. Consequently, to facilitate the generative AI era,\ndecision makers will need credible methods to measure human contribution in AI-assisted generation across various contexts.\nThis study frames this challenge and presents a method to measure human contribution to AI-assisted generation that\nis grounded in information theory. We propose using information content to quantify the percentage of information in the\nAI-assisted output that is attributable to human input. By measuring the ratio of mutual information between human input and\nAI-assisted output to the self-information of AI-assisted output, we quantify the human contribution in AI-assisted generation.\nOur measure is validated through experiments conducted on multi-domain AI-assisted generation datasets using multiple LLMs.\nIn raising this research question and proposing a new framework, we seek to measure human contribution quantitatively, inspire\nfurther research, and help advance the refinement of relevant originality delineation and content regulation in the future."}, {"title": "Ethical and Societal Impact", "content": "The objective of this study is to pose a research question and propose a framework for measuring human contribution in\nAI-assisted content generation. This question and framework aim to facilitate originality delineation in the era of creation\nwith the assistance of AI. Simultaneously, this work seeks to inspire more research on technical methods that can support the\nenhancement of relevant regulations in the context of widespread AI utilization in various scenarios. A potential risk is that in\nreal-world applications of the proposed framework, there might be targeted adaptive attacks aimed at manipulating the results to\nartificially elevate the assessed level of human contribution. Although this paper examines two adaptive attacks and verifies the\nrobustness of the proposed measure against them, more sophisticated and advanced attacks may arise in real-world scenarios.\nWe hope to further understand and mitigate such risks in future work.\nThe authors of this paper introduce a mere method to technically measure the human contribution in AI-assist content\ngeneration which can be potentially used in various scenarios. However, the paper does not intend to discuss the complex\ncopyright legal and policy issues related to \"originality\" or \"eligibility,\u201d nor it reflect any of Microsoft's legal and policy\npositions on the copyright issues."}, {"title": "Methods", "content": "The research problem most closely related to evaluating human contribution is the detection of content generated by LLMs34\u201336.\nAs the performance of LLMs continues to improve, the risk of being unable to distinguish between content generated by\nLLMs and humans becomes increasingly apparent, with attendant threats in security, fraud prevention37,38, and academic\nintegrity39, among other fields34,40,41. Consequently, researchers are increasingly directing their efforts towards the detection\nof LLM-generated content, specifically ascertaining whether a given text is primarily the product of AI. These research efforts\nentail training detection models42\u201344, employing features for zero-shot detection36,45,46, or incorporating specific watermarks\nduring content generation35,47,48.\nWhile the current body of research predominantly focuses on identifying content substantially generated by AI, thus\noptimized for binary detection, real-world AI-assisted generation often involves varying degrees of human contribution. In\nmany practical application scenarios, it is not sufficient to merely detect content primarily generated by AI, rather it is crucial to\ndiscern the extent of human contribution. Therefore, distinct from the detection of AI-generated content, our emphasis is on\nreliably quantifying human contribution within AI-assisted generation from an informational perspective."}, {"title": "Defining Human Contribution in Al-Assisted Generation", "content": "In contrast to a binary classifier determining whether content is primarily generated by AI, our aim is to derive a quantitative\nmeasurement indicating the extent of human contribution in AI-assisted content generation. This is a novel and previously\nunexplored issue. Our core idea revolves around utilizing information content as a medium for gauging the contributions of\nhumans and AI. Particularly, we define human contribution in AI-assisted generation as the ratio of mutual information between\nhuman input and AI-assisted output relative to the total self-information of the AI-assisted output, as illustrated in Figure 1b.\nIn this section, we first introduce related concepts derived from information theory27; we then provide our definition of\nhuman contribution. In the following definition, we consider an AI model Me, its generative distribution $p_\\theta$, human input\nx, and AI-assisted output y. First, we quantify the information content within the generated output y through the concept of\nself-information. Self-information measures the level of surprisal associated with the outcome of a random variable, which is\nrelated to the probability of that outcome occurring. In this context, content that is less probable in its generation is deemed"}, {"title": null, "content": "more informative. We represent the self-information of the generated output y as follows:\n$I(y) = -log(p_\\theta(y)),$                                                            (1)\nwhere $p_\\theta (y)$ is the probability that the content y is generated without any condition.\nOn the other hand, when conditioned on human input x, the information content within the generated output y transforms\ninto conditional self-information. Conditional self-information quantifies the information contained in an outcome of a random\nvariable, given the occurrence of another event. Here, we represent the conditional self-information of the generated output y\ngiven the human input x as follows:\n$I(y|x) = -log(p_\\theta(y|x)),$                                                                  (2)\nwhere $p_\\theta (y)$ is the probability that the content y is generated conditioned on human input x.\nBased on these two information concepts, we define the mutual information between the generated content y and the human\ninput x as the information gain during generation when the human input is known. This signifies the reduction in surprisal\nwhen human input x is for generating content y is provided, defined as follows:\n$I(x;y) = I(y) - I(y|x).$                                                                      (3)\nBuilding upon the aforementioned definition of information within the AI-assisted generation process, we proceed to\nestablishing the definition of human contribution in AI-assisted generation."}, {"title": null, "content": "Definition 1 (Human contribution in AI-assisted generation). Given an AI model $M_\\theta$ and human input x, where y represents the\nAI-assisted generated content, the human contribution $\u00f8$ is defined as the ratio of mutual information $I(x,y)$ to self-information\n$I(y)$.\nThis definition of human contribution pertains to the proportion of the information content within the generated output that\ncan be attributed to human input, relative to the total information content of the generated output."}, {"title": "Data Availability", "content": "The Arxiv dataset is available at https://huggingface.co/datasets/gfissore/arxiv-abstracts-2021.\nThe News Articles dataset is available at https://dataverse.harvard.edu/dataset.xhtml?persistentId=\ndoi:10.7910/DVN/GMFCTR. The HUPD dataset is available at https://huggingface.co/datasets/HUPD/\nhupd/blob/main/data/2018.tar.gz. The Poetry Foundation dataet is availbale at https://www.kaggle.com/\ndatasets/tgdivy/poetry-foundation-poems. The WildChat-1M dataset is available at https://huggingface.\nco/datasets/allenai/WildChat-1M."}, {"title": "Code Availability", "content": "The code applied in the experiments is publicly available at https://github.com/xyq7/Human-Contribution-Measurement."}]}