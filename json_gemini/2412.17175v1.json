{"title": "DCC: Differentiable Cardinality Constraints for Partial Index Tracking", "authors": ["Wooyeon Jo", "Hyunsouk Cho"], "abstract": "Index tracking is a popular passive investment strategy aimed\nat optimizing portfolios, but fully replicating an index can\nlead to high transaction costs. To address this, partial repli-\ncation have been proposed. However, the cardinality con-\nstraint renders the problem non-convex, non-differentiable,\nand often NP-hard, leading to the use of heuristic or neu-\nral network-based methods, which can be non-interpretable\nor have NP-hard complexity. To overcome these limitations,\nWe propose a Differentiable Cardinality Constraint (DCC)\nfor index tracking and introduce a floating-point precision-\naware method (DCCfpp) to address implementation issues.\nWe theoretically prove our methods calculate cardinality ac-\ncurately and enforce actual cardinality with polynomial time\ncomplexity. We propose the range of the hyperparameter a\nensures that DCCfpp has no error in real implementations,\nbased on theoretical proof and experiment. Our method ap-\nplied to mathematical method outperforms baseline methods\nacross various datasets, demonstrating the effectiveness of\nthe identified hyperparameter a.", "sections": [{"title": "Introduction", "content": "Index tracking, particularly through full replication, is one\nof the most widely used strategies in portfolio optimization.\nThis approach constructs a portfolio that mimics a specific\nmarket index by including all constituent stocks with corre-\nsponding weights. Full replication can be effectively solved\nas a basic regression problem using mathematical optimiza-\ntion techniques, enabling the efficient and precise portfo-\nlio construction. However, this method assigns continuous\nweights to all stocks in the portfolio, leading to significant\ntransaction costs a critical challenge in real-world invest-\nment scenarios. To mitigate these costs, partial replication\nhas been proposed (Meade and Salkin 1989), (Ertenlice and\nKalayci 2018), where only a subset of stocks is assigned\nweights, reducing the overall number of transactions. Partial\nreplication extends full replication by incorporating a cardi-\nnality constraint to limit the number of stocks.\nCardinality constraints, integral to partial replication, ex-\nhibit several notable technical challenges (Chang et al. 2000;\nPandey and Banerjee 2024): i) Discreteness: Cardinality\nconstraints enforce a limit on the number of selected stocks,\nresulting in a discrete solution space, unlike the continuous\none encountered in full replication. ii) Combinatorial Com-\nplexity: These constraints give rise to a combinatorial op-\ntimization problem, where all possible combinations must\nbe considered. Their independent and non-continuous na-\nture complicates to reformulate the problem into a form\nthat can be solved using traditional mathematical optimiza-\ntion techniques, such as those requiring linearity, convexity,\nor differentiability. iii) Computational Complexity: Finding\na solution that satisfies the cardinality constraint is classi-\nfied as an NP-hard problem, characterized by high compu-\ntational complexity, making it difficult to identify efficient\nsolutions. Due to these inherent characteristics, traditional\nmathematical optimization approaches, which were effec-\ntive for solving full replication problems, struggle with par-\ntial replication. Consequently, heuristic methods (Beasley,\nMeade, and Chang 2003; Wu, Kwon, and Costa 2017; Erwin\nand Engelbrecht 2023; Kabbani 2022; Zheng et al. 2020)\nhave been proposed to address partial replication. However,\nthese heuristic approaches have significant drawbacks, in-\ncluding the non-interpretability of some solution processes\nand the persistence of high complexity.\nTo overcome these limitations, it would be advanta-\ngeous to transform cardinality constraints into a form that\ncan be tackled using mathematical optimization techniques.\nThus, we propose the Differentiable Cardinality Constraint\n(DCC), which is not only adaptable to mathematical opti-\nmization techniques but also ensures the enforcement of ac-\ntual cardinality constraints. In summary, our contributions\nare as follows:\n1. We propose DCC, applicable to any optimization algo-\nrithm handling differentiable constraints, particularly us-\ning the Lagrangian multiplier method for partial replica-\ntion.\n2. To address implementation challenges, we introduce a\nfloating-point precision-aware variant, DCCfpp, ensur-\ning accurate enforcement of cardinality constraints.\n3. We establish conditions for the constant a in DCCfpp,\nproviding accurate cardinality calculations and constraint\nenforcement.\n4. We validate DCC fpp's performance in partial replication\nusing the SLSQP method, demonstrating improved re-"}, {"title": "Related Works", "content": "Full replication is a passive investment strategy in portfo-\nlio optimization, where objective is to minimize the tracking\nerror between a target index and the portfolio index, which\ncan be formulated as a constrained regression problem. This\nproblem can be efficiently solved using mathematical op-\ntimization techniques. Specifically, the constraints in full\nreplication include the sum-to-one constraint, where the sum\nof portfolio weights equals one, and the non-negativity con-\nstraint, ensuring that each weight is non-negative. Both con-\nstraints are linear, making Quadratic Programming (QP) an\neffective method for efficiently solving full replication prob-\nlems, as demonstrated in various studies (Jobson and Ko-\nrkie 1980; Fabozzi, Markowitz, and Gupta 2011; Boyd and\nVandenberghe 2004). Furthermore, since these constraints\ncan also be expressed in differentiable forms, full replication\ncan be solved using Lagrangian multipliers (Shaw, Liu, and\nKopman 2008; Bertsekas 2014). These mathematical opti-\nmization techniques are easily implemented using libraries\nsuch as CVXPY (Diamond and Boyd 2016) or SciPy (Vir-\ntanen et al. 2020), which efficiently find precise solutions.\nSince these methods follow well-established mathemati-\ncal procedures, the resulting portfolio solutions are inter-\npretable, as the clear objective functions and explicit con-\nstraints make it easy to understand how each decision im-\npacts the final outcome. However, the cardinality constraint\nis neither linear nor differentiable, making it challenging to\nsolve using mathematical optimization methods.\nTo address this problem, heuristic approaches have been\nemployed to address partial replication problems. Heuristic\nmethods such as search algorithms (Kabbani 2022), which\niteratively explore different combinations of stocks to iden-\ntify those that optimize the portfolio, and meta-heuristic\napproaches, including evolutionary algorithms (Beasley,\nMeade, and Chang 2003; Erwin and Engelbrecht 2023),\nhave been used. Additionally, clustering methods (Wu,\nKwon, and Costa 2017) have also been employed to select\noptimal subsets of stocks, effectively reducing the portfo-\nlio size while attempting to maintain tracking accuracy. De-\nspite the practical utility of these heuristic methods, they\ncome with inherent limitations. The approximate nature of\nheuristic solutions means they may find suboptimal solu-\ntion, and the large search space involved in these problems\nintroduces significant computational complexity. Thus, re-\ncently, (Zheng et al. 2020) have proposed the use of neu-\nral network-based approaches for partial replication, em-\nploying reparameterization techniques to transform uncon-\nstrained parameters into forms that satisfy the cardinality\nconstraint. However, these neural network approaches often\nfunction as black-box models, obscuring the interpretability\nof the solutions and the intermediate steps involved.\nThe limitations of heuristic and neural network ap-\nproaches underscore the need for a mathematical optimiza-\ntion approach to solve the partial replication problem effi-\nciently. Traditional methods of handling the cardinality con-\nstraint, such as iteratively applying full replication and se-"}, {"title": "Preliminaries", "content": "Before introducing our Differentiable Cardinality Con-\nstraint (DCC), it is essential to formally define the index\ntracking and the cardinality constraint associated with it."}, {"title": "Full Replication", "content": "Traditional index tracking (full replication) involves con-\nstructing a portfolio to minimize the difference between\nthe market index and the portfolio index, i.e. tracking er-\nror. Minimizing the tracking error is a straightforward re-\ngression problem when dealing with N stocks over a dura-\ntion D. The objective function is min || Xw-y||\u00b2 where\nX \u2208 RDXN is the daily return of stocks and w \u2208 [0,1]\nsuch that w = [w\u2081W\u2082 ... wN]T is a weight vector of portfo-\nlio. wi is the weight of i-th stock and y \u2208 RD is the daily\ntarget index.\nMoreover, the portfolio must satisfy straightforward con-\nstraints: each stock should have a non-negative weight, and\nthe sum of all weights must equal one. Then, we can define\nthe full replication problem as:\nmin ||Xw-y||\u00b2\nW\nN\nsubject to: wi \u2265 0 \u2200i, \u2211 wi = 1\ni=1"}, {"title": "Partial Replication", "content": "The partial replication ensures that the portfolio's cardinal-\nity, calculated through a specific function, does not exceed\na given value K. To enforce this constraint, we first define\nthe function that calculates the portfolio's cardinality. Let\nwi represent the weight of the i-th stock in the portfolio.\nThen cardinality function is defined using a binary function,\nb(wi), that assigns a value of 0 if a portfolio weight is zero,\nand 1 if the weight is greater than zero. By summing the\nbinary function values across all weights in the portfolio,\nwe can calculate the portfolio's cardinality. Partial replica-"}, {"title": "Differentiable Cardinality Constraint", "content": "Defining the cardinality constraint requires a function that\ncalculates the portfolio's cardinality, C(w). This function\ncan be expressed as the summation of a binary function\nb. However, as illustrated in Figure 1 (a) (red), this binary\nfunction is discontinuous and non-differentiable, rendering\nC(w), and cardinality constraints are non-differentiable as\nwell. To address this, we approximate the binary function\nwith a differentiable alternative, allowing C(w) and the car-\ndinality constraint to be expressed in a differentiable form\nunder two properties in Preliminaries (Will be discussed in"}, {"title": "Rational Function Approach", "content": "Section 4.2). We utilize the following rational function to\napproximate the binary function:\nb(wi) = 1 -\n1\na * wi + 1\na: constant\nThe graph of the b(w\u2081) function is shown in Figure 1 (a).\nThis rational function b(wi) is differentiable for all weight in\n[0, 1], and it passes through the origin and approaches b = 1\nas an asymptote, so that it takes the value of 0 when w\u2081 is\n0 and approaches 1 for w\u2081 greater than 0. Here, the con-\nstant a can be arbitrarily chosen, and increasing the value of\na allows b(wi) to approximate binary function b(wi) more\nclosely (See Figure 1 (a) (green lines)). Therefore, select-\ning a very large value for a is advantageous. Furthermore,\nthe value of a in the approximation function remains inde-\npendent of the portfolio weight or the number of stocks, thus\nincurring no additional computational cost or execution time\nas a increases.\nUsing b(wi), the function for calculating cardinality of a\nportfolio can be approximated. Since C(w) is composed of\ndifferentiable functions of each variable wi, it is also a dif-\nferentiable Nth-order function. Therefore, we can get the\nDifferentiable Cardinality Constraint (DCC) using C(w):\nN\nC(w) = \u2211 b(wi) =\ni=1\nN\n\u03a3 (1-\ni=1\n1\na * wi + 1\n) < K\nHowever, when selecting stocks, portfolio typically sets a\nweight cutoff threshold. This means that instead of strictly\ncounting weights as 0 when they are exactly zero, the binary\nfunction should count a weight as 0 if it is below the cut-\noff threshold, and as 1 if it is above the threshold. This ad-\njustment accounts for floating-point precision and requires a\nnew binary function that incorporates the cutoff threshold."}, {"title": "Sigmoid Function Approach (DCC fpp)", "content": "Cardinality Constraint with Cutoff Threshold Consider-\nation As discussed, due to the floating-point precision is-\nsues from cutoff threshold, we redefine the cardinality con-\nstraint considering the cutoff threshold of portfolio weights\nlike this:\nN\nCfpp(W) = \u2211 bfpp(Wi) \u2264 K,\ni=1\n10, if 0 \u2264 wi < \u2208\nwhere bfpp (Wi) =\n1, if wi\u2265 e\nThe graph of the redefined binary function is shown in Fig-\nure 1 (b) (red). Here, e represents a small cutoff threshold of\nportfolio weights. Therefore, the redefined cardinality func-\ntion means that if a weight is less than e, it is counted as\nzero, and if it is greater than e, it is counted as one. The re-\ndefined binary function bfpp from the Cfpp remains a non-\ndifferentiability. We approximate this again to make it dif-\nferentiable. However, we can no longer approximate the bi-"}, {"title": "", "content": "ferentiable. Instead,\nwe transform the sigmoid function to preserve the meaning\nof the bfpp(Wi) and make it differentiable as follows:\nbfpp(Wi) =\n1\n1+ e-a(wi-e)\na: constant\nSee Figure 1 (b) (blue lines). As shown in the graph, a larger\nvalue of a results in a closer approximation to bfpp(Wi).\nSince a is a simple constant (for the same reasons as be-\nfore), choosing a large a does not affect the problem's com-\nplexity or execution time. This approximated binary func-\ntion is differentiable and has an inflection point at w\u2081 = \u20ac.\nAdditionally, when a is set sufficiently large, the function\nhas an asymptote at bfpp = 1 for weights greater than e and\nan asymptote at bfpp = 0 for weights less than e. Although\nbfpp(Wi) is 0.5 when w\u2081 = 6, the floating-point precision is-\nsue means that weights are rarely exactly e. Even if they are,\nthe cardinality constraint is still ensured. This will be dis-\ncussed further in the next section. To summarize, if a weight\nis greater than e, bfpp(Wi) is close to 1; if it is less than e,\nbfpp(wi) is close to 0.\nSimilarly, the approximated cardinality function can be\ndefined using the approximated binary function. Since\nCfpp(w) is an N-th degree function composed of differen-\ntiable terms with respect to each variable wi, the approxi-\nmated cardinality function is also differentiable. Thus Dif-\nferentiable Cardinality Constraint for floating-point preci-\nsion (DCC fpp) can be written as follows:\nN\nCfpp (w) = \u2211 bfpp (Wi) = \u2211\ni=1\ni=1\n1\n1+e-a(wi-e)\n<K\nConditions for Accurate Cardinality Calculation In the\nPreliminaries, one of the key properties that the DCC fpp\nmust satisfy is the accurate calculation of the portfolio's\ncardinality. Achieving this accurate calculation relies on the\nproper definition of the cardinality function, which, in turn,\ndepends on the binary function used within it. The ability\nof the cardinality function to accurately reflect the true car-\ndinality is heavily influenced by the value of the constant a\nused in defining the binary function. Therefore, we estab-\nlish conditions for the constant a that ensure the cardinality\nfunction correctly computes the portfolio's cardinality.\nIf the value of a is too small, it may count values much\nlarger than zero even when the weight is zero, or conversely,\nit may fail to count exactly 1 when the weight is 1. In the\nfirst case, this could lead to a situation where cardinality is\ncalculated for all weights, regardless of whether they actu-\nally contribute to the portfolio. Therefore, to ensure accurate\ncardinality calculation, the value of a must at least be set\nsuch that it counts 0 when the weight is zero and confidently\ncounts 1 when the weight is 1. However, since the bfpp does\nnot exactly take the values of 0 and 1 but instead approaches\nb = 0 and b = 1 asymptotically, we consider a bounded\ncondition using the same cutoff threshold value e as men-\ntioned in Section 4.2. We establish the following minimum\nconditions:\nN\n\u2022 Co : w\u2081 = 0 \u2200i \u2208 {1,\u2026, N} \u21d2 \u2211 i \u2264 \u03b5\ni=1\nN\n\u2022 C\u2081 : w\u2081 = 1 \u2200i \u2208 {1,\u2026,N} \u21d2 \u2211i=1 Wi \u2265 \u039d - \u20ac"}, {"title": "", "content": "Conditions for Assurance of the DCCfpp Similarly, we\nmust ensure the second property of DCCfpp, Assurance.\nThis can be confirmed by verifying that satisfying DCC fpp\nalways guarantees the actual cardinality constraints. To\nprove that our DCCfpp ensures the actual cardinality con-\nstraint, we need to show the following:\nN\nN\nIf bfpp(Wi) \u2264 K, then \u2211 bfpp(Wi) \u2264 K\ni=1\ni=1\nThen we present the following theorem:\nTheorem 1. The Assurance of the cardinality constraint\nN\nIf N.err < 1 and \u2211 bfpp(Wi) \u2264 K,\ni=1\nN\nthen \u2211 bfpp (Wi) \u2264 K\ni=1\nN is the number of stocks, e is constant in Lemma 1, and K\nis integer such that K < N.\nProof.\nSuppose that N\u22c5\u03f5< 1 and \u2211 bfpp(Wi) \u2264 K.\ni=1\nN\nBy Lemma 2, \u2211 bfpp(Wi) - \u2211 bfpp(Wi) | \u2264 N \u2022 e.\ni=1\ni=1\nN\n\u03a3bfpp (Wi) - Ne\u2264 \u2211bfpp(Wi)\ni=1\nN\ni=1\n<\u2211bfpp(Wi) + N.e\ni=1\nN\n\u2211bfpp(Wi) \u2264 \u2211bfpp(Wi) + N. e \u2264 K + N \u2022 e.\ni=1\ni=1\nBy assumption, K+Ne < K + 1.\nN\nThus, \u03a3bfpp(Wi) < K + 1.\ni=1\nN\nBy Lemma 3, \u2211 bfpp(Wi) \u2264 K.\ni=1\nSince N is fixed value and e is dependent on the con-\nstant a in Eq. 6, if we choose a such that e <, then\nour DCC fpp will always ensure the cardinality constraint.\nThrough Theorem 4.2, we have proven that our DCCfpp\nguarantees the cardinality constraint. In other words, our\nproposed DCC fpp can effectively solve cardinality problem\nby applying to some optimization algorithms without calcu-"}, {"title": "Experiments", "content": "In this section, we validate the proposed DCCfpp with\nvarious dataset in three aspects: 1) We compare index track-\ning errors to assess the performance of partial replication. 2)\nWe measure the performance of the generated portfolio us-\ning commonly used metrics, 3) we compare the runtime of\nmethods to highlight their efficiency."}, {"title": "Experimental Settings", "content": "Data We conduct experiments using the following three\nmarket indices:"}, {"title": "Index Tracking with Cardinality Constraint", "content": "We measure the error between target index and tracking in-\ndex of partial replication. To evaluate the performance of\nindex tracking. We first fit the portfolio weights on each re-\nbalancing day (3-month) and calculate the tracking index\nby taking the weighted sum of the returns of each stock.\nWe then plot this tracking index alongside the target index\nvalues to visually assess how well each method tracks the\nS&P 100 index. As illustrated in Figure 2 and summarized\nin Table 1, our DCCfpp outperforms the baselines by accu-\nrately adhering to the cardinality constraint through a rigor-\nous mathematical procedure.\nOur SLSQP with DCCfpp outperforms the baselines in\ntracking performance by precisely adhering to the cardinal-\nity constraint. Forward and backward selection methods per-\nform poorly because they separate portfolio fitting from as-\nset selection, often leading to suboptimal solutions regard-\nless of the value of K. In contrast, SNN and our method in-\ntegrate selection and fitting simultaneously, resulting in su-\nperior tracking performance. As K decreases, our method\neffectively reduces the number of selected assets, maintain-\ning strong performance while naturally achieving a slight in-\ncrease in error, which is expected in scenarios with fewer\nassets.\nTo assess the effectiveness of the portfolios generated\nthrough partial replication using our method, we evalu-\nate them using commonly used metrics: cumulative return,\nvolatility, Sharpe ratio, and maximum drawdown (MDD).\nThese four evaluation metrics are aggregated as the aver-\nges of the values obtained from all portfolios during the\nbacktesting period. Our method demonstrates performance\ncomparable to that of the full replication (See Figure 3). De-\nspite the cardinality constraints, our portfolio consistently\nmaintains a sharpe-ratio above 1, indicating that it provides\nfavorable returns relative to its risk. Actually, the cumula-\ntive return is comparable to full replication, and the volatility\nshows minimal difference.\nTo evaluate the robustness of the methods, we also con-"}, {"title": "Efficiency", "content": "To illustrate the efficiency of our approach, we compare the\nruntimes taken for index tracking with a cardinality constraint\nusing forward selection and backward selection. The origi-\nnal cardinality constraint is known as an NP-hard problem.\nIncorporating a cardinality constraint into mathematical op-\ntimization algorithms typically results in exponential com-\nplexity for the index tracking solution. By applying our pro-\nposed DCC fpp, we can find an exact solution that satisfies\nthe existing cardinality constraint within polynomial time."}, {"title": "Hyperparameter Analysis", "content": "We also explored the hyperparameter a which determines\nthe satisfiability of the two essential properties (accuracy\nand assurance) in DCCfpp. To identify the appropriate a\nvalue satisfying all three conditions (Co, C\u2081 and C2), we\nanalyzed the status of each condition based on the value of\na. As shown in Figure 6, when a \u2264 14, none of the condi-\ntions are met. For a \u2265 14, Co is satisfied, C2 is satisfied for\na \u2265 70, and finally, C\u2081 is met when a \u2265 138, 157. a should\nbe set to at least 138,157 to satisfy all conditions in Python's\n64-bit floating-point precision, ensuring that our DCC fpp an\naccurately calculates the portfolio's cardinality and guaran-\ntees the enforcement of the cardinality constraint, regardless\nof the dataset."}, {"title": "Conclusion", "content": "In this work, we introduced the Differentiable Cardinality\nConstraint (DCC) and its precision-aware variant (DCC fpp)\nto address the NP-hard problem of partial replication in in-\ndex tracking. Our method converts the problem into a differ-\nentiable form, enabling efficient solutions using mathemati-\ncal optimization within polynomial time. Experiments show\nthat DCC fpp achieves comparable performance to full repli-\ncation while adhering to cardinality constraints, outperform-\ning state-of-the-art heuristic methods in both accuracy and\nefficiency. The robustness and reduced computational com-\nplexity of our approach make it highly applicable in real-\nworld portfolio optimization."}, {"title": "A Differentiable Cardinality Constraint for floating-point precision DCC fpp", "content": "To demonstrate that our proposed Differential cardinal-ity Constraint for floating-point precision (DCCfpp) can ensure the actual cardinality constraint, we present some theo-rems and prove a theorem along with the conditions on theconstant a used in the approximated binary function. Beforeproving this, we define a few necessary Lemmas.\nLemma 1. (Binary function error boundedness)\nThe error in the approximated binary function value for eachweight is bounded by a constant value.\n\u2200i \u2208 {1,\u2026, N},\n|bfpp(Wi) - bfpp(Wi)| \u2264\n1\n0\n|bfpp(Wi) - bfpp(Wi)|dwiwhere w\u2081 \u2208 [0, 1].\nProof. Trivial. Each weight error is smaller than the sumof possible errors. The sum of possible errors is a con-stant, because the definite integral of function (the differ-ence between bfpp(Wi) and bfpp(Wi)) is the same regardlessof i.\nWe defined\n1\n0\n \bfpp(Wi) \u2013 bfpp(wi)|dwi as e.\nLemma 2. (Cardinality function error boundedness)\nThe error in the approximated cardinality function value forsome weight vectors is bounded by a constant value.\nN\n\u2211bfpp (Wi) - \u2211bfpp(Wi)| \u2264 N.e\ni=1\ni=1\nN is the number of stocks, e is the constant in Lemma 1.\nProof. By several obvious mathematical properties andLemma 1,\n \u2211 bfpp (Wi) - \u2211bfpp(Wi)|\ni=1\ni=1\n\u03a3(bfpp(Wi) - bfpp(Wi))|\ni=1\nN\n01 (bfpp(Wi)\ni=1\nN\n< \u2211 0 bfpp(Wi)i=1"}, {"title": "Complex Analysis", "content": "When applying our proposed DCCfpp to the mathemati-cal optimization method, we analyze the time complexityof partial replication using Lagrange multipliers to showthat the complexity of the optimization algorithm remainspolynomial time. To analyze the time complexity from acomputational implementation perspective, we applied theDCCfpp to Sequential Least Squares Quadratic Program-ming (SLSQP), a mathematical optimization technique us-ing the Lagrangian multiplier method. First, the algorithmfor solving partial replication using the SLSQP, which is de-tailed in Algorithm 1 (see Appendix), serves as the founda-tion for the subsequent complexity analysis.\n1. Initializing a variable of order N is O(N).\n2. Defining the Lagrangian function is just for understand-ing next step. Thus, actually, this step is not executed.\n3. To calculate the  we have to calculate RTR and RTy.\nThese are O(DN\u00b2) and O(DN), respectively.\n4. Setting the Karush-Kuhn-Tucker (KKT) conditions andsolving these are just O(1).\n5. To solve the system of equations of 3 and 4, we uti-lize SLSQP solver. SLSQP solver commonly performsmatrix operations internally, with a time complexity of\u039f(\u039d\u00b3).\nThe combined time complexity for each step of the algo-rithm is as follows:\n\u2022 O(N)+O(DN\u00b2)+O(DN)+O(1)+O(N\u00b3) = O(N\u00b3)\nTherefore, we can conclude that adding DCCfpp to SLSQPallows us to solve the problem in polynomial time."}, {"title": "Approximation Error of Partial Replication", "content": "The approximation error of partial replication compared tofull replication can be bounded as follows:"}]}