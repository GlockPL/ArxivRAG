{"title": "SRE-CNN: A Spatiotemporal Rotation-Equivariant CNN for Cardiac Cine MR Imaging", "authors": ["Yuliang Zhu", "Jing Cheng", "Zhuo-Xu Cui", "Jianfeng Ren", "Chengbo Wang", "Dong Liang"], "abstract": "Dynamic MR images possess various transformation symmetries, including the rotation symmetry of local features within the image and along the temporal dimension. Utilizing these symmetries as prior knowledge can facilitate dynamic MR imaging with high spatiotemporal resolution. Equivariant CNN is an effective tool to leverage the symmetry priors. However, current equivariant CNN methods fail to fully exploit these symmetry priors in dynamic MR imaging. In this work, we propose a novel framework of Spatiotemporal Rotation-Equivariant CNN (SRE-CNN), spanning from the underlying high-precision filter design to the construction of the temporal-equivariant convolutional module and imaging model, to fully harness the rotation symmetries inherent in dynamic MR images. The temporal-equivariant convolutional module enables exploitation the rotation symmetries in both spatial and temporal dimensions, while the high-precision convolutional filter, based on parametrization strategy, enhances the utilization of rotation symmetry of local features to improve the reconstruction of detailed anatomical structures. Experiments conducted on highly undersampled dynamic cardiac cine data (up to 20X) have demonstrated the superior performance of our proposed approach, both quantitatively and qualitatively.", "sections": [{"title": "1 Introduction", "content": "Cardiac cine magnetic resonance imaging (MRI) plays a vital role in evidence-based diagnostic of cardiovascular disease and is widely regarded as the gold-standard for assessment of heart morphology and function [16,26]. Dynamic cardiac cine imaging with high spatiotemporal resolution is highly demanded for\nY. Zhu and J. Cheng\u2013Contributed equally to this work."}, {"title": "2 Method", "content": "In our proposed approach, the accelerated MRI reconstruction model is based on an unrolled neural network, which unrolls the existing iterative reconstruction algorithms to deep networks [5]. The regularized reconstruction can be formulated as a nonlinear inverse problem of the form:\n$x = \\underset{X}{argmin} ||Ax \u2013 y||2 + \\lambda R (x)$\nwhere y is the k-space measurement, x is the image to reconstructed, A is the forward operator during acquisition, and the regularization term R is associated with regularization strength A. We employ the Proximal Gradient Descent (PGD) method to iteratively solve the optimization problem presented\nin Equation (1) by alternating between two updates: a data consistency update $z^{(k)} = x^{(k)} - \\eta A^{*}(Ax^{(k)} \u2013 y)$, where \u03b7 is the PGD step size, which is followed by a proximal update $x^{(k+1)} = prox_{R}(z^{(k)})$ at iteration k, where $prox_{R}(\u00b7)$ is the proximal operator of \u03bbR [11]. In a deep-learning-based data-driven reconstruction, the proximal operator is replaced by a deep neural network: $x^{(k+1)} = N_{\\theta_{k}}(z^{(k)})$, where N is a CNN whose parameters $\\Theta_k$ are learned uniquely for each iteration. The architecture of the unrolled reconstruction model is illustrated in Fig. 2(a). The data consistency and update steps are based on DL-ESPIRIT [17]. The network takes a zero-filled reconstruction of a cardiac cine slice with its corresponding ESPIRIT maps as the input and is trained to reconstruct images which are close to fully sampled images."}, {"title": "2.2 Spatiotemporal Rotation-Equivariant CNN Design", "content": "Equivariance can be formulated as follows [24]. Let f be a convolution mapping, G is a group of transformations. f is equivariant w.r.t. the action of G, if for any g\u2208G,\n$f (\\pi_{g}(x)) = \\pi_{g}'(f(x)), g \u2208 G, x \u2208 X$\nwhere x can be any input feature map, and $\u03c0_g(\u00b7)$ denotes a group action in the respective space, X and Y represent the input and output feature spaces. In this paper, we focus on the rotation equivariance in CNN, since rotation symmetry is prevalent in dynamic MR data. It has been demonstrated that the equivariance of the entire unrolled MRI reconstruction model can be achieved as long as the proximal operator satisfies rotation equivariance. [3]. Therefore, it is desirable to model the proximal operator defined in section 2.1 with rotation-equivariant CNN. In most advanced dynamic MRI reconstruction CNNs, the 3D convolutions are replaced with (2+1)D convolutions consisting of 2D spatial and 1D temporal components [17,20]. However, current equivariant CNNs can only be applied to 2D or spatial 3D convolutions [24,25], which have not been explored for 2D+t data. Directly applying 2D equivariant convolution methods to (2+1)D CNNs is unable to achieve equivariance, since the 1D temporal convolution layer will destroy the equivariance between 2D equivariant convolution layers, consequently destroying the global equivariance of the network.\nTo preserve the equivariance of the network, a temporal-equivariant convolution layer is designed and applied to construct the SRE-CNN. The input, output and intermediate equivariant convolution layers have been well defined in previous works [6,24], so we only give a brief description. We define a rotation transformation group S with s elements. The rotation operators A and B are group elements of S, which are used to rotate the filters. In input equivariant layer, the 2D filters learn spatial patterns in different frames of input 2D+t data. Each set of adjacent filters share a same weight and rotated by the action in group S to ensure the feature robustness to input image rotation. Thus, similar features with different orientations can be responded. \u03a8 denotes the discrete convolution filters, * is regular discrete 2D convolution, * is group convolution [6]. For any A \u2208 S, the convolution in input equivariant layer\ncan be expressed as:\n$\\Psi^{A}(I+1) = \\Psi_{A} * I$\nThe feature maps after the input equivariant layer denote $F_A^{(1)}$. Each color of the feature map in $F_A^{(1)}$ is corresponding to a different rotation element A in group S.\nThe proposed temporal-equivariant layer can be formulated as:\n$(\\Upsilon * F)^{(j)} = \\sum_{A \\in S} \\Upsilon_{T, T-1}^{A} * F_{A}^{(1)}$\nwhere \u03a5 denotes the filters. As shown in Fig. 2(b), the channels of each 1D filter are extended to match the additional channels in $F^{(1)}_A$. Specifically, the channel CA1 of the filter should be convolved with the feature map $F^{(1)}_A$. To preserve the equivariance, the channel orders of the filters in a same group are cyclically shifted to match each rotation element in group A. The same color of channels in each filter represents the same weighting. As 1D Temporal convolution is not required to rotate in x x y spatial dimension, T are not rotation actions but still have s elements to match A and B.\nIn a intermediate equivariant layer, I denotes the convolution for intermediate layer. For any B\u2208S, the convolutions in this layer can be expressed as:\n$(\\Psi*F)^{B} = \\sum_{T \\in M} \\Psi_{I B,T} * F_{BT}$. The channels of the filters still need to be cyclically shifted. Due to it is a 2D convolution layer, the spatial dimension of filter"}, {"title": "2.3 Filter Parametrization", "content": "2D Filter parametrization technique has been widely used in equivariant CNNs to achieve an arbitrary angular resolution w.r.t. the sampled filter orientations without suffering interpolation artifacts from filter rotation [18]. However, the current filter parametrization methods still remain the problem of low representation accuracy, which is not sufficient for reconstruction of image details.[19,23]. To address this issue, we present a high-precision filter parametrization method based on 1D and 2D Fourier series expansion, since Fourier series expansion is equivariant to inverse discrete Fourier transform, which is with zero representation error [25]. Specifically, we define the filters as the linear combination of a set of basis functions and learn the combination coefficients. For 1D temporal-equivariant convolutions, we adopt 1D Fourier series expansion as the basis functions to construct filters, which can be expressed as:\n$\\delta (x) = \\sum_{k=1}^{p-1} (a_{k}\\varphi_{k}(x) + b_{k}\\varphi_{k}'(x))$\nwhere is the filter, are basis functions, i.e. 1D Fourier series expansion, p denotes the filter size, a and b are learned coefficients. Nonetheless, the aliasing effect in 2D Fourier series expansion for the rotated cases is significant. Followed by Xie's work [25], we replace high-frequency bases with the mirror functions of low-frequency bases to alleviate this problem and apply it to construct filter in 2D equivariant convolutions, which can be expressed as:\n$\\varphi_k (x) = cos\\left(\\frac{2\\pi}{ph}(\\frac{x_1}{2} - \\frac{p}{4})\\right)cos\\left(\\frac{2\\pi}{ph}(\\frac{x_2}{2} - \\frac{p}{4})\\right)$\nh is the mesh size of images. With the help of such high-accuracy filter parametrization, SRE-CNN can effectively leverage the rotation symmetry of local features."}, {"title": "3 Data and Experiments", "content": "We use a set of dynamic cardiac cine data to evaluate our approach. Informed consent was obtained from the imaging subjects in compliance with the Institutional Review Board (IRB) policy. The fully sampled cardiac cine data were collected from 29 healthy volunteers on a 3T scanner (MAGNETOM Trio, Siemens Healthcare) with 20-channel receiver coil arrays. For each subject, 10 to 13 short-axis slices were imaged with the retrospective electrocardiogram (ECG)-gated\nsegmented bSSFP sequence during breath-hold. The following sequence parameters were used: FOV = 330\u00d7330mm, acquisition matrix = 256\u00d7256, slice thickness = 6 mm, TE/TR = 1.5/3.0 ms. The acquired temporal resolution was 40.0 ms and each data has 25 phases that cover the entire cardiac cycle. We randomly selected 25 volunteers for training and the rest for testing. Data augmentation using rigid transformation-shearing was applied. Finally, 800 2D-t multi-coil cardiac MR data of size 192\u00d7192\u00d718 (x \u00d7 y \u00d7 t) are used for training, 30 for validation, and 118 for testing.\nThe number of unrolled iterations is set to be 10 empirically, four layers with the filter number of 46-46-46-2 in each iteration are used. The ADAM optimizer was employed, and the learning rate was set to 0.001 with an exponential decay rate of 0.95. The loss function is constructed as 11 differences in pixel-wise sense. The training and testing were on a workstation equipped with a Nvidia Tesla V100 Graphics Processing Unit (GPU). The fully sampled data were retrospectively under-sampled with VISTA [2] of R=12, 16 and 20 acceleration to generate the pair of training samples.\nWe compared our proposed approach with SOTA dynamic MR reconstruction methods, including a compressed sensing (CS) method L+S [15], a DL-based method dynamic MoDL [1] and DL-ESPIRIT (named as R2plus1D) [17]. All the DL methods were designed with a parameter size of around 330k to give fair comparisons. Peak signal to noise ratio (PSNR) and structural similarity index (SSIM) [22] were employed to evaluate the reconstruction."}, {"title": "4 Results and Discussion", "content": "The quantitative results  show consistent superior performance of the proposed method across every single undersampling factor compared to all other baseline methods. At extremely high acceleration factors (16X, 20X), the proposed SRE-CNN still gives superior reconstructions by a large margin (~ 2dB in PSNR). DL methods could achieve much faster reconstruction than CS methods since only one forward process is required in the test mode. The proposed SRE-CNN achieves better performance in higher accelerated factor, which indicates the prior knowledge of rotation symmetry is useful in highly undersampled MRI reconstruction. Although the proposed SRE-CNN has a little longer reconstruction time than other DL methods due to the equivariant convolutions, its reconstruction time is still less than 1s, which is acceptable.\nThe qualitative comparisons are shown in Fig. 3, where the reconstructed images in the spatial domain and temporal domain, as well as the corresponding error maps, were provided. From the figure, the proposed SRE-CNN can faithfully reconstruct the images with smaller errors and clearer anatomical details. Importantly, the edge of myocardium in reconstructed images, i.e. the regions with more rotated variants of the similar anatomical structure were evidently better reconstructed. It indicates that SRE-CNN can effectively exploit the rotation symmetry present in images and significantly improve the quality of details reconstruction. From x-t results, it can be observed that our proposed approach can still recover the dynamic information very well from extremely high undersampled data (R = 20), where the conventional CS approaches fail and the competing deep learning approaches cannot remove artifacts well.\nIt is noted that all of our proposed modules can be universally adopted by most CNN-based model. Our filter parametrization method can be applied to improve the representation accuracy of any parameterized filter in 1D and 2D convolutions. The SRE-CNN module with the designed temporal-equivariant"}, {"title": "5 Conclusion", "content": "In this study, we have proposed a Spatiotemporal Rotation-Equivariant CNN (SRE-CNN) with a high-accuracy filter parametrization strategy to take full advantage of the rotation symmetry in dynamic MRI reconstruction. The improved reconstruction performance has demonstrated that our method can effectively utilize the rotation symmetry along the temporal dimension and the rotation symmetry of local features within image frames to enhance the reconstruction of detailed features in image. In our future work, we will further extend the employed rotation temporal equivariant CNN to a larger group of transformations, such as the composition of scale and rotation.\nconvolution layer can be used in most CNNs to effectively exploit the rotation symmetry in (2D+t) data, such as video tasks."}]}