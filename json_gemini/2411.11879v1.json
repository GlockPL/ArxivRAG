{"title": "CSP-Net: Common Spatial Pattern Empowered Neural Networks for EEG-Based Motor Imagery Classification", "authors": ["Xue Jiang", "Lubin Meng", "Xinru Chen", "Yifan Xu", "Dongrui Wu"], "abstract": "Electroencephalogram-based motor imagery (MI) classification is an important paradigm of non-invasive brain-computer interfaces. Common spatial pattern (CSP), which exploits different energy distributions on the scalp while performing different MI tasks, is very popular in MI classification. Convolutional neural networks (CNNs) have also achieved great success, due to their powerful learning capabilities. This paper proposes two CSP-empowered neural networks (CSP-Nets), which integrate knowledge-driven CSP filters with data-driven CNNs to enhance the performance in MI classification. CSP-Net-1 directly adds a CSP layer before a CNN to improve the input discriminability. CSP-Net-2 replaces a convolutional layer in CNN with a CSP layer. The CSP layer parameters in both CSP-Nets are initialized with CSP filters designed from the training data. During training, they can either be kept fixed or optimized using gradient descent. Experiments on four public MI datasets demonstrated that the two CSP-Nets consistently improved over their CNN backbones, in both within-subject and cross-subject classifications. They are particularly useful when the number of training samples is very small. Our work demonstrates the advantage of integrating knowledge-driven traditional machine learning with data-driven deep learning in EEG-based brain-computer interfaces.", "sections": [{"title": "1. Introduction", "content": "A brain-computer interface (BCI) establishes a direct communication pathway that enables the human brain to interact with external devices [1]. Electroencephalogram (EEG), which records the electrical activities on the scalp of the brain, is the most widely used input signal in non-invasive BCIs due to its affordability and convenience [2]. EEG-based BCIs have been used in controlling robots [3], decoding speech [4], enhancing computer gaming experience [5], and so on.\nMotor imagery (MI) [6] is a classical paradigm of EEG-based BCIs, where a subject imagines the movement of a body part, e.g., right hand, left hand, right foot, left foot, both feet, and/or tongue, without actually executing it. An MI induces changes in the sensory-motor rhythms (SMR) of corresponding areas of the cerebral cortex, which primarily involve modulations of the u rhythm (8-12Hz) and the \u1e9e rhythm (14-30Hz) [7]. Specifically, when an MI starts, these rhythmic activities decrease, resulting in event-related desynchronization (ERD); at the end of an MI, these rhythmic activities increase, resulting in event-related synchronization (ERS) [8, 9]. Therefore, the detection of SMR patterns within specific areas of the cerebral cortex can be used to identify which body part the subject is imagining moving.\nMany algorithms have been proposed for EEG-based MI classification. Common spatial pattern (CSP) [10, 11] is one of the most widely used and effective approaches, which converts the raw multi-channel EEG signals into more discriminative spatial patterns. It was initially proposed for binary classification, by designing spatial filters that maximize the variance ratio of the filtered signals of different classes [10]. Dornhege et al. [12] extended it to multi-class classification using a one-versus-the-rest strategy. Ang et al. [13] proposed filter bank CSP (FBCSP), which bandpass filters EEG signals into multiple frequency bands, extracts CSP features from each band, and then selects the most useful features for classification. Lotte et al. [14] introduced regularized CSP to enhance the robustness of CSP.\nRecent years have witnessed significant increase in using deep learning for EEG signal decoding [15], which integrates feature extraction and classification into a single end-to-end network. Among various deep architectures, convolutional neural networks (CNNs) are the most prevalent for MI classification [16, 17]. For example, Schirrmeister et al. [18] proposed ShallowCNN and DeepCNN for raw EEG classification. ShallowCNN is inspired by FBCSP and includes components such as temporal convolution, spatial convolution, log-variance calculation and a classifier, each corresponding to a specific step in FBCSP. DeepCNN is similar but includes more convolutional and pooling layers. Lawhern et al. [19] introduced a compact EEGNet, which has demonstrated promising performance across various BCI tasks, including MI classification. Inspired also by FBCSP, EEGNet uses a two-step sequence of temporal convolution followed by depthwise convolution. Recently, FBCNet [20] extends the FBCSP approach by utilizing a hierarchical architecture that enhances feature extraction through multi-dimensional filtering, allowing it to capture richer spatial and temporal patterns in EEG data. EEGConformer [21] adopts a transformer-like architecture, combining self-attention mechanisms with convolutional layers, which enables the model to learn long-range dependencies in EEG signals effectively.\nThough these data-driven deep models have achieved promising performance in MI classification, they usually require a large amount of labeled training data, which may not be always available in practice. This highlights the need to incorporate prior knowledge into EEG networks, as it can help reduce the reliance on extensive labeled datasets. By integrating prior knowledge, models can leverage existing insights about EEG signal characteristics, enhancing their generalization capabilities and performance even in data-scarce environments. This paper proposes CSP empowered neural networks (CSP-Net), which more effectively integrate CSP and CNNs. More specifically, we propose two CSP-Nets, by embedding CSP into different layers of the CNN models. The first, CSP-Net-1, places a CSP layer before a CNN to filter the EEG signals for enhancing their discriminability. The second, CSP-Net-2, replaces a CNN's convolutional layer with a CSP layer to provide task-specific prior knowledge initialization. The parameters in the CSP layer of both CSP-Nets are initialized from CSP filters designed on the training data. They can be fixed or optimized by gradient descent during training. In summary, CSP-Nets integrate the strengths of traditional CSP feature extraction with deep learning by embedding CSP layers in CNN architectures. This approach enhances the model's ability to capture relevant features from EEG signals, making it a more effective solution for MI classification. Our main contributions are:\n\u2022 Integration of CSP and CNNs: We propose a novel framework that combines CSP with CNNs for MI classification, enhancing EEG feature extraction and improving classification performance.\n\u2022 Two CSP-Net Variants: We introduce two architectures, CSP-Net-1, which incorporates a CSP layer before the CNN, and CSP-Net-2, which replaces a convolutional layer with a CSP layer for task-specific prior knowledge initialization. Both variants allow CSP layer parameters to be fixed or further optimized.\n\u2022 Performance on Multiple EEG Datasets: CSP-Nets demonstrate strong performance across various scenarios, including within-subject and cross-subject classifications, as well as in small sample settings. The models demonstrate generalization across different backbone architectures, validated on four public MI datasets.\nThe rest of this paper is structured as follows. Section 2 introduces the classical CSP and proposes two CSP-Nets. Section 3 presents the experimental settings and experimental results. Finally, Section 4 draws conclusions."}, {"title": "2. Methods", "content": "This section introduces the CSP algorithm, five CNN models for MI classification, and our proposed two CSP-Nets to integrate CSP and CNNs."}, {"title": "2.1. CSP", "content": "CSP was first proposed by Koles et al. [22] to extract discriminative features from EEG signals of two human populations. M\u00fceller-Gerking et al. [23] later extended it to MI classification. Since then, it has become one of the most popular and effective algorithms in MI-based BCIs [10, 11].\nFor binary classification, CSP aims to learn spatial filters that maximize the variance of EEG signals from one class while simultaneously minimizing the variance from the other class. Let $X_i \\in \\mathbb{R}^{c \\times t}$ be an EEG trial of MI task $i$, where $i \\in \\{1,2\\}$ is the class index, $c$ the number of channels, and $t$ the number of time domain samples. CSP generates a spatial filtering matrix $W \\in \\mathbb{R}^{c \\times f}$ ($f < c$) that projects the original EEG trials into a lower-dimensional space with higher discriminability. $W$ is obtained by maximizing (or minimizing):\n$J(W) = \\frac{W^T \\bar{X_1} \\bar{X_1}^T W}{W^T \\bar{X_2} \\bar{X_2}^T W} = \\frac{W^T \\hat{C_1} W}{W^T \\hat{C_2} W},$ where $\\bar{X_i} \\in \\mathbb{R}^{c \\times t}$ is the averaged EEG trial from class $i$, and $\\hat{C_i} \\in \\mathbb{R}^{c \\times c}$ the mean spatial covariance matrix of all EEG trials in class $i$.\nSince $J(W) = J(kW)$ for any arbitrary real constant $k$, maximizing $J(W)$ is equivalent to maximizing $W^T \\hat{C_1} W$, subject to the constraint $W^T \\hat{C_2} W = I_f$. This optimization problem can be solved using the Lagrange multiplier method [14], whose Lagrange function is\n$F(W, \\lambda) = W^T \\hat{C_1} W - \\lambda (W^T \\hat{C_2} W - I_f).$\nSetting the derivative of $F(W, \\lambda)$ with respect to $W$ to 0, we have"}, {"title": "2.2. CNNs for MI Classification", "content": "Five popular CNN models are considered in this paper: EEGNet [19], DeepCNN [18], ShallowCNN [18], FBCNet [20], and EEGConformer [21]. Their architectures are detailed in Ta- bles 1-5, respectively.\n\u2022 EEGNet [19], which consists of three convolutional blocks and a classifier block. The first convolutional block performs temporal filtering for capturing frequency information. The second spatial filter block uses depthwise convolution with size (c, 1) to learn spatial filters. The third separable convolutional block is used to reduce the number of parameters and decouple the relationships within and across feature maps.\n\u2022 DeepCNN [18], compared with EEGNet, it is deeper and hence has much more parameters. It mainly includes a temporal convolutional block, a spatial filter block, two standard convolutional blocks and a classifier block. The first temporal and spatial convolutional blocks are specially designed to handle EEG inputs and the other two are standard ones.\n\u2022 ShallowCNN [18], which is a shallow version of Deep- CNN, inspired by FBCSP. Its first two blocks are similar to the temporal and spatial convolutional blocks of DeepCNN, but with a larger kernel, a different activation function, and a different pooling approach.\n\u2022 FBCNet [20], which is a simple yet effective CNN architecture. It begins by applying multiple fixed-parameter band-pass filters to decompose the EEG into various frequency bands as multi-view inputs. Spatial filter block is then used to extract spatially discriminative patterns from each frequency band. Finally, a classifier block is designed for classification.\n\u2022 EEGConformer [21], which is a compact convolutional transformer model. The convolution module also includes a temporal convolutional block and a spatial filter block for learning the low-level local features. The multiple self- attention modules are used to extract the global correlation within the local features."}, {"title": "2.3. CSP-Net-1", "content": "Our proposed CSP-Net-1 simply performs CSP before a CNN.\nAs illustrated in Fig. 2(a), all training EEG samples are used in CSP, resulting in $f$ spatial filters $W_i \\in \\mathbb{R}^{c \\times 1}, i = 1,..., f$. Then, as shown in Fig. 2(b), CSP-Net-1 uses these filters to spatially filter the raw EEG signals, before passing them to a CNN backbone.\nThere could be two different training approaches: 1) Fix the CSP layer and train the CNN backbone only (CSP-Net-1-fix); and, 2) update the CSP layer and the CNN backbone simultaneously (CSP-Net-1-upd). Their effectiveness will be discussed in Section 3.3.\nCSP-Net-1 applies CSP filtering as a pre-processing step, enabling the model to work with more discriminative input signals. This explicit inclusion of the CSP filter provides a more structured way to embed expert knowledge into the network, thereby improving the model's capacity to capture task-relevant spatial features.\nAlgorithm 1 gives the pseudo-code of CSP-Net-1."}, {"title": "2.4. CSP-Net-2", "content": "Many CNN models have been proposed for MI classification, which typically consist of multiple convolution-pooling layers for feature extraction and some fully connected layers for classification. Although they differ in architecture, they usually include a spatial filter layer with spatial convolutional kernels specifically designed for EEG signals.\nCSP-Net-2 replaces their spatial filter layer with a CSP layer. Fig. 2(c) uses EEGNet as the CNN backbone to illustrate the architecture of CSP-Net-2. For clarity, we primarily depict the connection of the convolutional kernel between inputs and outputs. The depthwise spatial filter block aims to learn spatial patterns in EEG data. CSP-Net-2 replaces the convolutional kernels in this block with the CSP filters, and keeps other parts unchanged.\nMore specifically, CSP-Net-2 uses the CSP layer to replace the DepthwiseConv2D layer in the spatial filter block of EEG- Net (8 kernels), the Conv2D layer in the spatial filter block of DeepCNN (25 kernels), the Conv2D layer in the spatial filter block of ShallowCNN (40 kernels), the DepthwiseConv2D layer in the spatial filter block of FBCNet (48 kernels), and the Conv2D layer in the spatial filter block of EEGConformer (40 kernels).\nSimilar to CSP-Net-1, the CSP filter layer in CSP-Net-2 can either be fixed (CSP-Net-2-fix) or updated (CSP-Net-2-upd). Furthermore, this replacement is significant as it allows CSP-Net-2 to explicitly incorporate prior knowledge about spatial filtering, enhancing the model's ability to capture discriminative features from the EEG signals. The flexibility of using either fixed or updated CSP filters also provides a balance between stability and adaptability during training, which we discussed in detail in Section 3.3.\nAlgorithm 2 gives the pseudo-code of CSP-Net 2."}, {"title": "3. Experiments and Results", "content": "This section presents the experimental results to validate the effectiveness of our proposed CSP-Nets."}, {"title": "3.1. Datasets", "content": "Four public MI datasets from BNCI-Horizon 1, summarized in Table 6, were used in our experiments:\n1. MI4C and MI2C: They were from the 001-2014 dataset. The EEG signals were sampled at 250Hz. MI2C includes only left-hand and right-hand trials. MI4C includes all classes.\n2. MI14S: This was from the 002-2014 dataset. The EEG signals were sampled at 512Hz.\n3. MI9S: This was the 001-2015 dataset. The EEG signals were recorded at 512Hz. The last three subjects were discarded due to their poor performance [25, 26].\nThey were downloaded and pre-processed using the MOABB framework [27]. All datasets were pre-processed with an 8-32Hz bandpass filter."}, {"title": "3.2. Implementation Details", "content": "We evaluated the performance of CSP-Nets in both within-subject and cross-subject classifications:\n1. Within-subject classification: For each individual subject, 80% trials were used for training, and the remaining 20% for testing.\n2. Cross-subject classification: Leave-one-subject-out cross- validation was performed, i.e., one subject was used as the test set and all remaining ones as the training set.\nAll experiments were repeated 5 times, and the average accuracies are reported.\nWe used Adam optimizer with batch size 128 and initial learning rate 0.01, and cross-entropy loss with weight decay 0.0005. The maximum number of training epochs was 200.\nThe CSP layer used by default $f = 8$ spatial filters (Section 3.6 presents sensitivity analysis). For CSP-Net-2, the number of convolutional kernels in the original spatial filter layer of the CNN models may be larger than 8. We expanded the CSP filters to address this mismatch: when the number of convolutional kernels exceeds the number of CSP filters, we replicate the CSP filters to match the number of required kernels. Specifically, we duplicated the 8 CSP filters 5 times to match the 40 kernels in the spatial filter block of ShallowCNN and EEGConformer (8 x 5 = 40), duplicated the 8 CSP filters 6 times to match the 48 kernels in the spatial filter block of FBCNet (8 \u00d7 6 = 48), and duplicated the 8 CSP filters 3 times and randomly selected one more to match the 25 kernels in the spatial filter block of DeepCNN (8 x 3 + 1 = 25)."}, {"title": "3.3. Experimental Results", "content": "Table 7 shows the classification accuracies for the individual subjects on MI4C, where CSP-LR used logistic regression as the classifier. Tables 8-10 show the average classification results across all subjects on the other three datasets, due to page limit. We performed paired t-tests on the results, calculated p-values between the standard backbone models and the CSP-Nets, and adjusted them using Benjamini Hochberg False Discovery Rate correction. Observe that:\n1. Both CSP-Nets were generally highly effective on all datasets and backbones. Embedding CSP knowledge in CNN backbones resulted in significant performance improvements. For example, in within-subject classification on MI4C, CSP-Net-2-fix increased the average accuracy on all subjects from 63.50% to 71.91% after integrating CSP information into EEGNet as CSP-Net-2-fix. The average accuracies across all five backbones also exhibited significant improvements, from an initial accuracy of 61.32% to as high as 67.33%.\n2. CSP-Nets with fixed CSP layer parameters generally performed better. Particularly, CSP-Net-2-fix achieved substantial improvements over EEGNet, DeepCNN, and EEGConformer. This validated that the incorporation of CSP prior knowledge can enhance the generalization of CNN models. High number and proportion of parameters of spatial convolutional kernels in ShallowCNN and FBC- Net may overshadow the benefits offered by CSP filters.\n3. CSP-Nets had larger performance improvements in within-subject classification than cross-subject classification. This might be because: 1) within-subject classification had much fewer training samples than cross-subject classification, and hence prior knowledge in CSP is more helpful to the generalization performance; and, 2) cross-subject classification is intrinsically more challenging, as there are large individual differences among different subjects. The impact of training data quantity on CSP-Nets is discussed in Section 3.5.\n4. CSP-Nets achieved better performance on most subjects. However, for some subjects where CSP did not perform well, CSP-Nets also struggled, e.g., Subject 1, 2, 5 and 6 in cross-subject classification on MI4C."}, {"title": "3.4. Comparative Performance Analysis", "content": "We further compared our approaches with nine other approaches, including the state-of-the-art traditional approaches and deep learning approaches: CSP [10], FBCSP [13], MDRM [28], DeepCNN [18], LMDA-Net [29], ShallowCNN [18], EEGConformer [21], EEGNet [19], and FBC- Net [20]. Table 11 presents the classification accuracies of CSP- Net-1 and CSP-Net-2 compared to these baselines. In CSP-Net- 1 and CSP-Net-2, the EEGNet was used as the backbone archi- tecture, and the fixed CSP layer was applied. The same training and test data were used for all models.\nBoth CSP-Net-1 and CSP-Net-2 demonstrated superior performance compared to traditional approaches like CSP and FBCSP, as well as more recent models like FBCNet and EEG-Conformer. These results highlight their effectiveness for EEG signal classification tasks."}, {"title": "3.5. Small Sample Setting", "content": "Deep CNN models may easily overfit when the training dataset is small. Figs. 3-6 show the accuracy improvements compared with the backbone at different training data ratios (the number of training samples used to train the model divided by the total number training samples) on the four datasets, respectively.\nObserve that:\n1. Consistent with previous findings, CSP-Net-fix generally outperformed CSP-Net-upd, with CSP-Net-2-fix particularly competitive on EEGNet and DeepCNN. For example, in within-subject classification, CSP-Net-2-fix achieved a remarkable accuracy improvement of more than 20% over the DeepCNN backbone, when trained with only 50% of the training data on MI4C.\n2. Overall, the performance improvements of CSP-Nets were more obvious when the training data size was small. This may be because the embedding of prior knowledge greatly reduces the overfitting issue of CNN backbones in small sample scenarios."}, {"title": "3.6. Influence of the Number of CSP Filters", "content": "We further investigated the influence of the number of CSP filters (f) on the performance of CSP-Nets with three backbones on MI4C. The dataset includes 22-channel EEG signals, so we considered $f \\in \\{4, 8, 12, 16, 22\\}$. Fig. 7 shows the corresponding accuracies of the two CSP-Nets (fixed CSP layer). As the number of filters increased, the accuracy first increased and then decreases, which is intuitive. Generally, $f = 8$ seems to be a good choice to balance the performance and computational cost."}, {"title": "3.7. Ablation Studies", "content": "An ablation study was performed to verify that the performance improvement of CSP-Net-1 was not due to an increase in the number of network parameters.\nSpecifically, we trained CSP-Net-1-rad, which replaced the CSP layer of CSP-Net-1 with a randomly initialized layer of the same size. The results on the four MI datasets in within-subject classification are shown in Table 12. Generally, CSP-Net-1- rad performed similarly to the standard backbone, suggesting that the performance improvement of CSP-Net-1 was due to its incorporation of knowledge from CSP, instead of more parameters."}, {"title": "3.8. Training Process Visualization", "content": "Fig. 8 shows the average cross-subject training and test accuracy curves of CSP-Nets (fixed CSP layer) and their corresponding backbones (EEGNet) on the four datasets. For all the backbones, there was a large gap between the training and test curves, indicating overfitting. Our proposed CSP-Nets effectively leveraged the knowledge from the CSP filters for better initialization, reducing the gap and achieving better test performance."}, {"title": "3.9. Visualization of the CSP Filters", "content": "We further visualized the spatial convolutional kernel weights from the CSP-Net-2 and the counterparts from standard backbone. In Fig. 9, we present the eight spatial filters in the EEGNet model and the CSP filters in the CSP-Net-2-fix model for within-subject classification on Subject 1 of MI2C (binary classification on the left hand and right hand). We can observe that the CSP filters in CSP-Net-2-fix exhibited a more focused and obvious left-right distribution concentrated on a specific sensorimotor area, which aligned well with the spatial characteristics of MI. In contrast, the standard EEGNet struggled to learn effective spatial information due to the absence of prior knowledge provided by CSP. This alignment suggests that CSP filters effectively capture the relevant spatial patterns inherent in the EEG data, enhancing the interpretability of the model."}, {"title": "4. Conclusions", "content": "Spatial information, which can be well captured by CSP filters, is critical in EEG-based MI classification. This paper has introduced two CSP-Nets, which integrate the knowledge-driven CSP filters with data-driven CNN models. CSP-Net-1 directly adds a CSP layer before a CNN, utilizing CSP-filtered signals as input to enhance the discriminability. CSP-Net-2 replaces a convolutional layer in CNN with a CSP layer. Experiments on four public MI datasets demonstrated that the two CSP-Nets consistently improved over their CNN backbones, in both within-subject and cross-subject classifications. They are particularly useful when the number of training samples is very small. Remarkably, CSP-Net-1-fix, whose CSP layer uses fixed weights calculated using the traditional CSP algorithm, is the simplest yet demonstrates overall best performance.\nOur work demonstrates the advantage of integrating knowledge-driven CSP filters with data-driven CNNs, or traditional machine learning with deep learning, in EEG-based BCIS."}]}