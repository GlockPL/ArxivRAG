{"title": "TIMERAG: BOOSTING LLM TIME SERIES FORECASTING VIA RETRIEVAL-AUGMENTED GENERATION", "authors": ["Silin Yang", "Dong Wang", "Haoqi Zheng", "Ruochun Jin"], "abstract": "Although the rise of large language models (LLMs) has introduced new opportunities for time series forecasting, existing LLM-based solutions require excessive training and exhibit limited transferability. In view of these challenges, we propose TimeRAG, a framework that incorporates Retrieval-Augmented Generation (RAG) into time series forecasting LLMs, which constructs a time series knowledge base from historical sequences, retrieves reference sequences from the knowledge base that exhibit similar patterns to the query sequence measured by Dynamic Time Warping (DTW), and combines these reference sequences and the prediction query as a textual prompt to the time series forecasting LLM. Experiments on datasets from various domains show that the integration of RAG improved the prediction accuracy of the original model by 2.97% on average.", "sections": [{"title": "I. INTRODUCTION", "content": "Time series forecasting is critical in data science and machine learning research, covering wide applications including financial market analysis, demand forecasting, weather prediction, etc. Although deep-model-based forecasting methods such as LSTM [1], Reformer [2] and Informer [3] have achieved satisfactory performance on classical benchmarks [4], they can hardly capture the hidden complex patterns and dependencies in large-scale sequential data with staggering complexity and diversity [5]. In view of this challenge, researchers have explored the possibility of applying large language models (LLMs) to time series analysis and prediction across various domains [6], [7], since LLMs have demonstrated remarkable achievements in natural language processing. However, existing time series forecasting LLMs cannot easily adapt to different domains, as the training of LLMs is computationally costly and typically optimized for a specific domain [8]. Moreover, due to the \u201challucination\u201d of LLMs [9], LLMs may generate inaccurate predictions, outliers, or fabricated patterns when performing time series forecasting, that do not align with the data, with no interpretability.\nIn order to resolve these issues, we propose to boost time series forecasting LLMs via Retrieval-Augmented Generation (RAG) [10]. Specifically, we first establish a time series knowledge base by collecting representative sequential data from the training set via K-means clustering. Then given the time series forecasting query as input, we employ Dynamic Time Warping (DTW) [11] as the distance metric to retrieve sequences, that share similar waveforms and trends with the query, from the time series knowledge base as referential sequences, since DTW is tolerant to temporal distortions. Finally, the input query and the referential sequences are rewritten as a natural language prompt and fed into the LLMs for prediction. We have experimentally verified our method on M4 datasets, a collection of varying-frequencies time series from different domains [12], where significant improvements of up to 13.12% have been observed.\nDifferent from existing time series LLMs that require massive training costs [13], [14] and previous RAG solutions [10], [15], to the best of our knowledge, we are the first to propose a RAG framework specifically designed for time series data prediction without modifying the foundational parameters of the underlying LLM. Experimental results confirm that our method exhibits strong competitiveness when compared to both similar LLMs and baseline models.\nThe key contributions of our work are as follows:\n\u2022 To the best of our knowledge, we are the first to boost time series forecasting LLMs by Retrieval-Augmented Generation, which significantly improves prediction accuracy.\n\u2022 We employ K-means clustering and Dynamic Time Warping to efficiently construct a time series knowledge base, which facilitates the LLM to easily adapt to different domains of time series.\n\u2022 We experimentally verify that RAG contributes to an average improvement of 2.97% in the accuracy of sequence forecasting."}, {"title": "II. METHOD", "content": "As shown in Fig. 1, in order to enhance the performance of LLMs in time-series forecasting tasks, we propose a retrieval-augmented framework, named TimeRAG, that consists of two main components: a Time Series Knowledge Base (KB) (II-B) and an LLM-based time series forecasting model(II-C). Specifically, TimeRAG first sequentially slices the original sequence into segments and establishes a time series knowledge base by extracting representative segments from the training set using K-means clustering. Then input the time series forecasting query, we apply Dynamic Time Warping (DTW) as the distance metric to retrieve sequences from the time series knowledge base that exhibit similar waveforms and trends to the query, leveraging DTW's ability to handle temporal distortions. The input query and the retrieved sequences are then reformulated into a natural language prompt, which is subsequently input into the LLMs for prediction."}, {"title": "II-B. Time-Series Knowledge Base", "content": "In order to establish the Time-Series Knowledge Base, TimeRAG first performs sequential slicing on the original sequence through a sliding window, and employs clustering to select representative segments for storage. Instead of storing and retrieving complete raw sequences, our sequence-segmentation approach preserves the local information of the sequence, avoids long sequences where LLMs tend to miss key information [16], and improves the retrieval efficiency. Specifically, given a sequence $X = (x_t,...x_{t+n}), X \\in R^n$ of time-varying values from time t to t + n, TimeRAG first adopts a sliding window approach with a step size of S and a window length of L to slice X into several sub-sequences $X_L$, where $X_L \\in R^L$. Secondly, K-means clustering is applied to these fragments for capturing representative sequences. Given a set of N sequence fragments $Q_L = {X_{L_i}}, i \\in [1, N]$, K-means first initializes a set of cluster centroids $C = {X_{c_1}, ..., X_{c_k} }, X_{c_i} \\in Q_L, i \\in [1,k]$ and assign each $X_{L_i}$ to the closest centroid, where the distances between each sequence fragment $X_{L_i}$ and all centroids are measured by the Euclidean distance as Eq.1:\n$d = ||X_L - X_{c_i}||_2$ (1)\nwhere $X_L \\neq X_{c_i}$. After this initialization, K-means iteratively updates each centroid as the mean of sequences within each cluster and reassigns each sequence to the cluster whose centroid is the closest to the sequence, which gradually minimizes the total sum of distances between all points and their corresponding cluster centroids. Finally, TimeRAG constructs the Time-series Knowledge Base by collecting the sequence that is the closest to its centroid from each cluster."}, {"title": "II-C. Retrieval-Augmented LLM-based Time-series Forecasting", "content": "Although LLMs have demonstrated remarkable performance in time series forecasting [17], their prediction accuracy deteriorates when processing sequences that have not been previously trained. Moreover, LLMs show general performance degradation due to their tendency to forget [16], which may adversely affect the accuracy of time series forecasting. In view of these challenges, we introduce the retrieval-augmented LLM-based time-series forecasting that consists of the following two stages: (1) retrieval of similar sequences based on DTW [18], and (2) prediction by LLM"}, {"title": "ICASSP2025 Accepted", "content": "where both the original sequence and the retrieved similar sequences are combined to enhance forecast accuracy.\nIn the retrieval stage, given the prediction query and the Time-Series Knowledge Base, TimeRAG employs DTW to retrieve top-K sequences that are most similar to the query from the knowledge base. Specifically, given the input query sequence $X_{input}, X_{input} \\in R^n$ for prediction, DTW first constructs an n \u00d7 L matrix for each sequence $X_L$ in the knowledge base, where the element (i, j) of the matrix represents the distance d(i, j) between the $X_{input_i}$ and $X_{L_j}$, which represent the i-th point of $X_{input}$ and the j-th point of $X_L$ respectively. The distance d(i,j) is computed as following formula:\n$d(i, j) = (X_{input_i}, X_{L_j})^2$ (2)\nWe refer to the path W from matrix element (1, 1) to (n, L), consisting of several adjacent and non-repeating matrix elements, as the warping path, where the m-th element of W is defined as $w_m = d(m_i, m_j)$, which is computed by Eq. 2. Thus, W can be given by:\n$W = w_1,...w_m,...w_M$ (3)\nwhere max(n, L) < M < n + L and $w_M = d(n, L)$.\nThe algorithm then employs dynamic programming to obtain the shortest warping path, which can be utilized to measure the similarity between $X_{input}$ and $X_L$ as Eq.4:\n$Simi(X_{input}, X_L) = min_W \\frac{\\sum_{m=1}^M w_m}{M}$ (4)\nwhere $Simi(X_{input}, X_L)$ denotes the similarity between the $X_{input}$ and $X_L$. Finally, TimeRAG selects the top K sequences that are most similar to the query sequence as the retrieval results, measured by Simi.\nIn the model prediction stage, TimeRAG follows Time-LLM [13] that adopts a reprogramming layer to align the sequence modality with the natural language modality. As shown in Fig. 1, the input query sequence $X_{input}$ and the retrieved sequences are transformed through the reprogramming layer and concatenated as one prompt, which enhances the prediction performance of the LLM."}, {"title": "III. EXPERIMENTS", "content": "Datasets. We evaluate TimeRAG on the M4 benchmark, a widely used dataset for time series forecasting that contains data from diverse domains, including finance, demographics, marketing, etc., with different sequential sampling frequencies: yearly, quarterly, monthly, weekly, daily, and hourly. Each frequency corresponds to specific prediction horizons and input lengths, which supports the comprehensive evaluation of forecasting models. More details of the dataset are provided in Tab. I.\nEvaluation Metric. As introduced in [13], we adopt the following three widely accepted metrics for performance evaluation: (1) Symmetric Mean Absolute Percentage Error (SMAPE): as a widely recognized measure in time series forecasting, SMAPE quantifies forecast accuracy relative to actuals by computing the percentage error. (2) Mean Absolute Scaled Error (MASE): this metric evaluates a model's predictive accuracy relative to a naive forecast strategy, offering scale independence and robustness across a series of varying magnitudes. (3) Overall Weighted Average (OWA): drawing from the methodology in N-BEATS [19], OWA integrates SMAPE and MASE to provide a holistic assessment of model performance. The smaller values of prediction results measured by SMAPE, MASE, and OWA, the higher prediction accuracy the model achieves.\nBaselines. We compare TimeRAG with state-of-the-art time series models, including Transformer-based methods: iTransformer [20], FEDformer [21], Pyraformer [22], Autoformer [23], Informer [3], and Reformer [2]; as well as other competitive models: Time-LLM [13], DLinear [24], TSMixer [25], MICN [26], FiLM [27] and LightTS [28].\nTraining Settings. Inspired by [13], TimeRAG employs the reprogramming technique where the input time series are reprogrammed with text prototypes before fed into a frozen LLM to align the two modalities. In order to obtain a well-trained reprogramming layer, we trained TimeRAG based on Llama3 with a maximum of 50 training epochs, using 8 A100 GPUs, Adam optimizer, and SMAPE as the loss function. To mitigate over-fitting, we employ dynamic learning rate adjustment and an early stopping strategy, with the maximum learning rate set as 0.01.\nKnowledge Base Implementation. As sequential data shows distinct waveform characteristics at different time frequencies, we built separate knowledge bases for each frequency in the M4 dataset and split the remaining data into training, validation, and test sets. Tab. I shows statistics of the knowledge bases for the M4 dataset at different frequencies. Once the knowledge bases were constructed, TimeRAG enhanced the test samples by retrieving the top-five most relevant entries, measured by DTW, from the corresponding knowledge base for each test case, which"}, {"title": "III-B. Main Results", "content": "Tab. II presents a comprehensive comparison of forecasting accuracy across various models on the M4 dataset. The table is meticulously organized to display the performance metrics for different temporal granularities, including yearly, quarterly, monthly, weekly, daily, and hourly. The efficacy of each model is quantified by these three metrics: SMAPE, MASE and OWA.\nTimeRAG is superior to the time series prediction LLM without RAG (Time-LLM). In our comparative analysis, our model outperforms Time-LLM, achieving an average reduction of 1.13% in SMAPE, 4.78% in MASE, and a notable 3.00% decrease in OWA. Moreover, an overall improvement of 2.97% has been observed, highlighting the model's enhanced predictive capabilities. Under optimal conditions, TimeRAG notably reduces SMAPE by 0.74 at the \"Weekly\" frequency and demonstrates the most significant enhancement of 13.12% in MASE at the same interval.\nThese improvements across the board can be credited to the augmented knowledge base that our model incorporates. This supplementary data acts as a catalyst for the model's knowledge enhancement, effectively bolstering its predictive accuracy without modifying the foundational parameters of the underlying LLM.\nTimeRAG also stands out among the current SOTA time series forecasting models, achieving the best values for both MASE and OWA metrics under the current training paradigm. On average, TimeRAG achieves a MASE score of 2.72, which is the lowest among all evaluated models, underscoring its superior forecasting accuracy. FEDformer follows as the second, while DLinear ranks the third. Likewise, TimeRAG performs exceptionally well in the OWA metric, achieving an OWA score of 1.03. It secures the leading position among all evaluated models, followed by FEDformer in second place and Time-LLM in third.\nThe empirical evidence garnered from our analysis substantiates the efficacy of integrating large models with RAG techniques for the execution of time series tasks. This amalgamation has significantly improved predictive accuracy and model responsiveness to temporal data patterns.\nTimeRAG exhibits a consistent performance across all metrics and all temporal frequencies. In all 18 comparative analyses, our model secures the top-three positions more frequently than any other, with a total of 14 instances, consistently ranking within the top-three in terms of average performance. Time-LLM follows in second place, with DLinear coming in third. Our model's ability to sustain such a high level of performance across various analytical dimensions underscores its robustness and reliability in the domain of time series forecasting.\nThe superior performance of TimeRAG can be attributed to its highly effective alignment with the knowledge base. TimeRAG meticulously matches each time series with pertinent samples from the knowledge base, enabling the model to draw insights beyond the parameters established through training. This approach allows the LLMs to learn from a more authentic and reliable dataset, thereby minimizing randomness and improving the model's consistency."}, {"title": "IV. CONCLUSION", "content": "After integrating Retrieval-Augmented Generation that consists of clustering-based Time-Series Knowledge Base construction, Dynamic-Time-Warping-based similar reference sequence retrieval, and natural-language-alignment-based prompt rewriting, our TimeRAG framework significantly enhances the prediction accuracy of time series forecasting LLMs, achieving an average accuracy improvement of 2.97% over baseline models across diverse domains. Our work demonstrates the potential of RAG in amplifying LLM performance in time series forecasting, which offers a promising approach for future research in knowledge-enhanced sequential data management."}]}