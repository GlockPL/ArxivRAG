{"title": "Streamlining the review process: AI-generated annotations in research manuscripts", "authors": ["Oscar D\u00edaz", "Xabier Garmendia", "Juanan Pereira"], "abstract": "The increasing volume of research paper submissions poses a significant challenge to the traditional academic peer-review system, leading to an overwhelming workload for reviewers. This study explores the potential of integrating Large Language Models (LLMs) into the peer-review process to enhance efficiency without compromising effectiveness. We focus on manuscript annotations, particularly excerpt highlights, as a potential area for AI-human collaboration. While LLMs excel in certain tasks like aspect coverage and informativeness, they often lack high-level analysis and critical thinking, making them unsuitable for replacing human reviewers entirely. Our approach involves using LLMs to assist with specific aspects of the review process. This paper introduces AnnotateGPT, a platform that utilizes GPT-4 for manuscript review, aiming to improve reviewers' comprehension and focus. We evaluate AnnotateGPT using a Technology Acceptance Model (TAM) questionnaire with nine participants and generalize the findings. Our work highlights annotation as a viable middle ground for AI-human collaboration in academic review, offering insights into integrating LLMs into the review process and tuning traditional annotation tools for LLM incorporation.", "sections": [{"title": "Introduction", "content": "The growing number of research papers being submitted to academic journals presents a substantial challenge to conventional peer-review system [16]. This trend contributes to a significant rise in the workload for peer review: over 15 million hours are dedicated to reviewing manuscripts [2], while academics are handling an average of 14 manuscript reviews each year, with each review requiring about 5 hours [21]. This burden frequently leads to reviewing being undertaken 'without sufficient care' [17]. This calls for assistance in reconciling efficiency and effectiveness in peer review.\nRecent advancements in generative AI, especially Large Language Models (LLMs), hold some promise for alleviating the review load [18,6,11]. However, there are notable issues with the standalone AI-generated reports [23]. Firstly, these reports often lack high-level analysis, failing to provide a comprehensive and insightful evaluation. Secondly, the style adopted by the generated reports tends to imitate rather than demonstrate critical thinking and independent judgment. Finally, a prominent shortcoming is the absence of questioning and probing, which are crucial for fostering rigorous scholarly"}, {"title": "Related work", "content": "AI interventions in peer reviewing can be framed along two dimensions. The first dimension is the targeted stakeholder: the editor, the reviewer, or the author. The second dimension is the role played by the AI: AI for automation (i.e., AI systems that replace human work) and AI for augmentation (i.e., AI systems that integrate with human expertise to improve decisions) [8]. This section is structured along with these dimensions.\nThe editor as the stakeholder Goshal et al. target editors by proposing a sentiment analyzer to automatically validate a research manuscript based on both the manuscript and the reviews from reviewers to predict the acceptance decision. They claim their system outperforms existing baselines, offering an enhanced level of confidence for editors, particularly in cases where reviewers are unresponsive [9]. In contrast, Checco et al. introduce a regular neural network model trained with 3300 manuscripts, which"}, {"title": "RQ1: How could the task of LLM-authored annotations be integrated into the review process?", "content": "Peer review is not solely focused on determining whether a manuscript should be accepted or rejected. It also serves the purpose of enhancing the quality of the published paper by offering valuable feedback. Approximately 90% of researchers believe that the primary benefit of peer review lies in its capacity to provide constructive criticism, thereby improving the final version of the paper [22,23]. This places peer-review as a feedback practice.\nFeedback provision is being extensively investigated in education. Feedback on student assignments is pedagogical, and aimed at enhancing learning, understanding, and skill development. Alternatively, peer review in research manuscripts is evaluative, intended to uphold and improve the quality and integrity of scholarly work before publication. That said, both practices aim to provide constructive criticism to help the author(s) improve their work, whether it be a student's essay or a researcher's manuscript. Good practice in both involves providing specific and actionable advice, pointing out not just what is lacking but also how to improve it. Nicol provides ten recommendations for constructive feedback for textual assignments [12]. We focus on three of these recommendations related to the substance of feedback rather than to its linguistic aspects (e.g., understandability or politeness). These include ensuring that feedback is contextualized, specific, and timely. The rest of this section delves into each of these aspects. Bold font is used for cues for later functional requirement.\nContextualized feedback refers to feedback being framed about the learning outcomes [12]. This implies the existence of a review framework that guides the reviewer through the reviewing process. However, reviewing is a diverse practice [19], with communities and research areas requiring different aspects to be assessed. While student feedback is often more directive, with specific suggestions for improvement and learning, peer review is more critical, with an emphasis on identifying gaps, questioning methodology, and ensuring the validity of the findings. This calls for making explicit the review criteria. Additionally, contextualized feedback might not be limited to the review criteria but also include the sentiment of the feedback, i.e., positive remarks versus negative remarks, on the pursuit of balanced feedback that helps to motivate rather than discourage.\nSpecific feedback refers to avoiding general comments and instead being more accurate about the excerpts in the manuscript where the feedback applies [12]. This is commonly achieved by annotating the manuscript while reading, and then, quoting when writing the review. Similar to \u201cgrammatical typos\", specific feedback should include the excerpts where the \u201cargumental typos\u201d or \u201cmethodological typos\" apply.\nTimely feedback highlights the fact that feedback given close to the time of action reinforces either the correctness of the action or the need for change [5]. This issue might be better captured by the term \"performant feedback\" as a cause previous"}, {"title": "RQ2: How could traditional annotation tools be tuned for LLM-assisted academic review?", "content": "A review platform is a dedicated interface for manuscript reviewing. We consider the platform to be \"AI-powered\u201d if it incorporates an LLM into the process. This pertains to the way in which the LLM prompts are composed, invoked, sequenced, and integrated into the platform's interface. For example, ChatGPT primarily engages users through a question-answer format [13]. Alternatively, we take a different approach by using annotations as the main form of interaction between reviewers and the LLM. This shift from a linear dialogue to an annotation-based approach allows for a more layered and nuanced interaction with the manuscript. Therefore, the main contribution of this work lies not so much in the prompting (which follows traditional practices, as discussed later), but in the proposed interaction model for LLM-human collaboration\u00b9 . This section presents a proof-of-concept: AnnotateGPT."}, {"title": "Annotation", "content": "Create. Annotations are created by prompting GPT-4 through the annotate prompt. We utilize the \"Reverse Prompt Engineering\" technique as our core design strategy [1]. This technique involves presenting the language model with desired outputs, along with examples, and instructing it to generate corresponding prompts iteratively. The output is JSON formatted, as described later on. The \u201cannotate\u201d prompt has a single parameter: the review criterion. Besides the criterion, the prompt includes a request for (1) three excerpts that provide the evidence that sustains the criterion in the paper and (2) the analysis of the sentiment to determine whether each excerpt meets the criterion.5.\nThe annotate function belongs to the criterionReview class. This class has a highlighter bar as its GUI counterpart (see later). Fig. 2 outlines the interaction sequence. First, the reviewer should click on the highlighter criterion to display a contextual menu. By selecting Annotate (A), a prompt will be generated and sent to GPT-4. GPT-4 should be instructed to format the answer in JSON. The returned JSON should then be rendered, with excerpts located and color-coded highlighting (B), and sentiments reflected through smileys (C).\nUpdate. If annotations are created through prompting, it seems reasonable to assume that updates might also be prompt-driven. Specifically, AnnotateGPT accounts for requesting additional evidence to fact-check the text in the annotation, address social concerns, or ask open-ended questions to clarify doubts about the annotation content."}, {"title": "Criterion Review", "content": "Annotation-powered tools like NVivo, Annotate, or PDF Annotator result in color-coded highlighting. This means that different colors are used to highlight text, data, or other information based on specific criteria or categories. AnnotateGPT builds on this familiarity, where colors now represent review criteria. Fig. 2 illustrates the case for Contribution, Originality, Relevance and Rigor. Review criteria can be introduced manually or through an XML file for easy sharing. Each criterion includes a name (to be displayed in the sidebar), as well as a description and, optionally, actionable recommendations to assess the criteria. These concerns are incorporated into the prompt counterpart.\nCriterionReview instances are initially empty, and gradually enriched by adding Annotation components. Besides spotting relevant excerpts (Annotate), GPT can also help in summarizing the evaluation so far for the criterion at hand (Compile) or asking for alternative viewpoints (Provide viewpoints). Fig. 4 shows the case for Provide viewpoints."}, {"title": "Full Review", "content": "A Review is composed of multiple CriterionReview components. AnnotateGPT enables the creation of an editable review report using the Compilations from the CriterionReview, which are in turn derived from the Excerpts and Comments in the assembled Annotations. This final review can be structured along with either the review criterion or the sentiment. Functionalities reviewByCriteria and reviewBySentiment help to deliver these reports. As an example, in this URL7 you can download the review report generated for this manuscript."}, {"title": "Evaluation", "content": "This evaluation does not test the accuracy of GPT-4 in highlighting the right paragraphs. Assessing the quality of the annotations produced by GPT-4 is outside the scope of this work which takes as a premise the increasing accuracy that LLMs exhibit in this task. Rather, this work's main contribution should be sought in the interaction model for AI-human collaboration, and its realization in AnnotateGPT. It is then a question of technology acceptance, i.e., the extent reviewers perceive this model as ease of use and useful. We then resort to the Technology Acceptance Model (TAM) [7].\nGoal. Assessing the ease of use and usefulness of AnnotateGPT with respect to peer review from the point of view of human reviewers in the context of criteria-based academic manuscript reviewing."}, {"title": "Threats to validity", "content": "The results demonstrated strong construct validity with Cronbach's \u03b1 values of 0.8 and 0.83 for usefulness and ease of use, respectively. It is important to note that the assessment of 'usefulness' may be influenced by the GPT's ability to accurately identify the relevant excerpts. Although we made it clear beforehand, some participants might perceive the effectiveness of GPT as the determining factor, rather than solely considering the tool's usefulness in interacting with the LLM, regardless of the accuracy of the annotations. Regarding internal validity, we consider the subject's reviewing expertise and the manuscript's research topic to be confounding variables. Further evaluation is"}, {"title": "Formalization of Learning", "content": "This section elaborates on the extent the insights of this project can be generalized. It specifically examines two facets: firstly, the generalization of the solution instance, i.e.,"}, {"title": "Generalization of the Solution Instance", "content": "AnnotateGPT employs LLMs akin to content-based recommender systems. These recommendations, however, are subject to potential inaccuracies, including false positives (i.e., highlighting an excerpt not related to the criterion at hand) and false negatives (i.e., failing to spot an excerpt that relates to the criterion at hand). In the case of manuscript reviewing, the impact of false negatives is limited to cause some unnecessary fatigue in the reviewer's attention by highlighting unnecessary paragraphs. However, false negatives have a more significant impact as they could lead to overlooking relevant paragraphs. Therefore, AnnotateGPT is limited by the precision of current LLMs. In order to mimic the advancements in recommender systems, AnnotateGPT could provide assistance in various ways, specifically:\nleveraging user feedback. This can be achieved by allowing reviewers to provide feedback on the recommended paragraphs' relevance. By collecting this feedback, the system can iteratively refine its recommendations and adapt to each reviewer's preferences. This interactive feedback loop can lead to a personalized and fine-tuned paragraph recommendation system, further improving precision,\nimproving the interpretability, i.e., generating explanations for the model's recommendations. These explanations can provide insights into why specific paragraphs were selected, helping reviewers understand and trust the system's recommendations. This aligns with the recent initiative for self-explained LLM models [10].\nThe aforementioned limitations pertain to the LLM side. From a front-end perspective, AnnotateGPT also has certain limitations due to its interaction metaphor. When reviewers engage with annotated manuscripts, they may become overly reliant on the highlighted excerpts and fail to engage with the full text, potentially missing important context or content that was not annotated. To address this issue, AnnotateGPT offers the ability to toggle annotations on and off."}, {"title": "Generalization of the Problem Instance", "content": "AnnotateGPT focuses on the reviewer as the stakeholder. However, manuscript feedback might also be 'a problem' for both conference endowments and manuscript authors.\nConference organizers can benefit from using LLM to normalize and maintain the quality standards of their conferences. AnnotateGPT offers a variety of pre-set prompts for evaluating review criteria. These prompts can be customized to align with the specific requirements of the conference profile. These customized review platforms can be readily installed as browser plugins adjusting the current tool and distributed across PCs. This might help a more consistent review, ultimately enhancing the overall quality and prestige of the conference.\nFurthermore, conference endowments are in a favorable position to utilize the abundance of reviews from past editions. As long as confidentiality issues are addressed with reviewers and authors, these reviews can be used for fine-tuning LLMs8. This involves transforming general-purpose LLMs like GPT-4 into specialized tools that are specifically tuned for annotation-based reviews.\nManuscript authors can benefit from a preliminary assessment. Systems like ChatGPT might be used to generate the title, the abstract, a structured introduction that sets the context, or the keywords of the manuscript [4]. However, our content here is not about writing but about giving feedback. Regardless of how the manuscript is written (with the assistance of ChatGPT or not), LLMs can also be used to assist in the delicate task of giving feedback. The AnnotateGPT's contribution is not in generating content (\"provide me with an introduction\") but in assessing content (\u201cdoes this introduction capture this manuscript's essence?\u201d). Here, the LLM does not provide content but assess human-provided content. By highlighting what the LLM considers relevant excerpts, authors are encouraged to self-reflect on their narratives and identify both weaknesses (to be addressed or explicitly acknowledged in the manuscript) and strengths (to be further developed in the manuscript). If authors use spell-check on their manuscripts before submitting them for review, why not use tools like AnnotateGPT to help authors check in advance how well their drafts meet the review criteria set by the publication venue? So we did for this very manuscript. It is not difficult to imagine that in the near future, authors will conduct a preliminary review to determine the extent to which they meet the venue's criteria. Reviewers are likely to appreciate this effort."}, {"title": "Conclusions", "content": "To keep up with authors empowered by AI, reviewers should also have access to similar tools. We have researched the use of AI as a supportive tool and propose a nuanced approach where AI aids reviewers in identifying important sections of the manuscript. To accomplish this, we recommend using \"annotation\" as a means to enhance collaboration between the Al agent and the reviewer. This vision is realized in AnnotateGPT, a web-based PDF visualizer that combines criterion-driven prompts with language models like GPT-4.\nWe have different follow-ons in mind. In terms of rigor, we need larger quantitative evaluations (involving more subjects) and qualitative evaluations (involving conference endowment). In terms of relevance, our goal is to assess the effectiveness of open-source LLMs in pursuing reducing expenses (although AnnotateGPT is free, GPT-4 is not), while also exploring the fine-tuning of these models to enhance their effectiveness in review."}]}