{"title": "Deep Learning for Spectrum Prediction in Cognitive Radio Networks: State-of-the-Art, New Opportunities, and Challenges", "authors": ["Guangliang Pan", "David K. Y. Yau", "Bo Zhou", "Qihui Wu"], "abstract": "Spectrum prediction is considered to be a promising technology that enhances spectrum efficiency by assisting dynamic spectrum access (DSA) in cognitive radio networks (CRN). Nonetheless, the highly nonlinear nature of spectrum data across time, frequency, and space domains, coupled with the intricate spectrum usage patterns, poses challenges for accurate spectrum prediction. Deep learning (DL), recognized for its capacity to extract nonlinear features, has been applied to solve these challenges. This paper first shows the advantages of applying DL by comparing with traditional prediction methods. Then, the current state-of-the-art DL-based spectrum prediction techniques are reviewed and summarized in terms of intra-band and cross-band prediction. Notably, this paper uses a real-world spectrum dataset to prove the advancements of DL-based methods. Then, this paper proposes a novel intra-band spatiotemporal spectrum prediction framework named ViTransLSTM. This framework integrates visual self-attention and long short-term memory to capture both local and global long-term spatiotemporal dependencies of spectrum usage patterns. Similarly, the effectiveness of the proposed framework is validated on the aforementioned real-world dataset. Finally, the paper presents new related challenges and potential opportunities for future research.", "sections": [{"title": "I. INTRODUCTION", "content": "THE wide application of 5G mobile communication and Internet of Things (IoT) network technology has made the number of wireless devices grow by hundreds of millions every year, which puts a huge load on the already scarce radio spectrum resources. The International Telecommunication Union (ITU) allocates spectrum resources to these wireless devices in a static manner, restricting their communication to licensed frequency bands. Consequently, licensed bands experiencing an inundation of wireless devices face congestion issues and degradation in the quality of service [1]. In contrast, other licensed bands, such as those designated for broadcasting TVs or analogue cellular telephony, possess abundant available spectrum that is regrettably underutilized.\nTo address these problems, cognitive radio network (CRN)-based dynamic spectrum access (DSA) is considered an effective solution. It enables wireless devices, referred to as secondary users (SUs), to opportunistically access the unused licensed spectrum as long as harmful interference to primary users (PUs) is limited. This access method can achieve better spectrum efficiency and higher system capacity, thereby alleviating the shortage of spectrum resources. The key step in DSA is to accurately obtain the spectrum state by spectrum sensing in cognitive radio (CR). Spectrum sensing techniques in various frequency bands include energy detection, matched filtering (< 1 GHz), feature detection (sub-6 GHz), compressed sensing, and machine learning (millimeter wave and terahertz) techniques. However, practical hardware constraints limit spectrum sensing, including factors such as limited time delay, energy constraints, and sensing scopes. Fortunately, spectrum prediction can obtain unknown spectrum occupancy information in advance by capturing potential correlation patterns in the measured spectrum data to help CUs quickly access idle bands [2]. Herein, spectrum prediction focuses on providing future spectrum state, while spectrum sensing emphasizes obtaining the current state. Therefore, spectrum prediction has emerged as a research hotspot.\nHowever, spectrum prediction has some tricky challenges. This paper divides the existing work into intra-band prediction and cross-band prediction. In intra-band prediction, spectrum measurement is highly nonlinear due to diverse wireless devices, varied spectrum services, and influences from both the external environment and internal device interference. This nonlinearity spans time, frequency, and space, making learning multidimensional nonlinear features challenging. Cross-band prediction is the prediction of the future spectrum of the target band by using a few spectrum measurements in the target band (typically caused by spectrum security, device deployment, and hardware damage, etc) and abundant spectrum measurements in relevant bands. Effectively leveraging the substantial data from relevant bands and the limited data from the target band to achieve cross-band prediction poses a formidable challenge.\nRecently, inspired by the stunning breakthroughs that deep learning (DL) has achieved in computer vision and natural language processing, DL has also been harnessed in spectrum prediction [3]-[5]. DL can directly extract nonlinear usage patterns from spectrum measurements and integrate various types of networks such as convolutional neural networks (CNN) and recurrent neural networks (RNN) to capture multi-"}, {"title": "II. WHY DL FOR SPECTRUM PREDICTION?", "content": "As shown in Fig. 1, we consider a CRN consisting of several PUs and SUs. The spectrum sensors (SSs), which are sparsely distributed in the region of interest (RoI), transmit the received signal strength (RSS) over the Internet to the data storage center (DSC). Referencing the upper left corner of Fig. 1, spectrum measurement can be divided into time, frequency, and space domains. DL enables spectrum prediction by learning the underlying temporal/spectral/spatial correlations in historical spectrum measurement. Below, we give the reasons for using DL by comparing it with traditional methods.\nAR Model-Based Methods. Influenced by user behavior and radio equipment activity, latent time patterns exist in the time dimension of spectrum, encompassing periodicity and trends. To explore these patterns, AR and moving average (MA) models use parameter estimation to analyze the influence of past spectrum series on the current moment, aiming to better capture temporal patterns for predicting future spectrum states [2]. The ARMA model, which combines AR and MA, is then used to further enhance analytical capabilities. Subsequently, a more advanced AR integrated MA (ARIMA) model is proposed to eliminate trends or seasonal effects by introducing differential operations [2]. However, these models assume that the relationship between the past and future values of the spectrum series is linear. In real-world scenarios, many spectrum series exhibit nonlinear behavior, and these models may struggle to capture such patterns. In contrast, DL does not require any prior assumptions and can automatically extract complex nonlinear patterns, thereby achieving accurate spectrum prediction.\nTraditional Machine Learning (ML)-Based Methods. Traditional ML methods, including support vector machine (SVM), hidden Markov model (HMM), and Bayesian inference have been utilized for spectrum prediction [2]. Authors of [2] introduce that SVM predicts spectrum mobility based on design features, HMM predicts spectrum occupancy with state transition matrices, and Bayesian inference estimates channel quality using a posterior distribution. However, SVM usually requires manual selection and crafting of features. HMM comes with limitations in terms of context modeling, relying solely on previous observations and struggling to capture long-term dependencies. Bayesian methods face constraints due to their reliance on specific probabilistic distributions, limited access to prior knowledge, and sensitivity to the selection of prior distributions. Moreover, these models are only used to capture features in the temporal dimension of the spectrum, ignoring the frequency and spatial dimensions. In contrast, DL takes an end-to-end approach, eliminating the need for manual feature engineering. DL-models are highly flexible and can adapt to a wide range of tasks without substantial modifications. Moreover, DL-models can capture long-term spectrum patterns to support accurate prediction."}, {"title": "III. LEARNING NONLINEARITIES FOR INTRA-BAND SPECTRUM PREDICTION", "content": "A. Time-Frequency Spectrum Prediction\nVarious frequency bands are allocated for diverse spectrum services, encompassing applications such as broadcasting TV, GSM900 (both uplink and downlink), ISM, GSM1800 (both uplink and downlink), and similar services. The interplay of factors such as the number of spectrum devices, user mobility, and patterns of usage imparts unique temporal and spectral correlations to each spectrum service. The intricacies of this multifaceted time-frequency correlation are notably nonlinear, presenting a challenge for conventional methodologies. To overcome this challenge, the application of DL-models becomes pertinent. These models prove effective in capturing the nuanced time-frequency correlations by directly assimilating spectrum correlations from measurements across distinct frequency bands, subsequently encapsulating this information in a parameterized format within the neural network architecture.\nAs an attempt, LSTM was employed to learn the temporal correlations of multiple spectrum channels. Gao et al. [3] utilized LSTM and attention mechanisms to design a sequence-to-sequence model for achieving multi-channel, multi-step spectrum prediction. Supervised learning is adopted for the model optimization. Once the model is adequately trained, supervised learning transitions to the prediction phase. In this stage, only a specific length of historical spectrum data is input into the prediction model to predict the future spectrum state without any prior information. To further improve predictive performance, Yu et al. [4] combined CNN and gated recurrent unit (GRU) (a variant of the LSTM) networks to design a model called DCG for spectrum availability prediction. Recognizing the local correlations among different channels within the same time slot and regional correlations across multiple time slots, Yu et al. employed one-dimensional convolution to delve into the occupancy patterns of local channels and two-dimensional convolution to explore the occupancy patterns of regional channels. Subsequently, GRU was leveraged to encapsulate both short-term and long-term temporal dependencies within the data processed by the dual CNN.\nGiven the extensive range of frequency bands utilized by wireless devices, the amalgamation of vast spectrum data inherently results in high-dimensional data. Simultaneously, there is a heightened demand for the model's proficiency in extracting features. To tackle this challenge, Pan et al. [5] initially employed stacked autoencoders (SAE) to diminish the dimensionality of the high-dimensional spectrum data while automatically extracting features without disrupting its internal temporal and frequency relationships. The extracted features were then fed into a CNN and bidirectional LSTM (Bi-LSTM) fusion network to grasp the frequency and time dependencies. However, due to the constraints of the Bi-LSTM gating structure, it demonstrated excellent short-term predictive performance but relatively weaker long-term predictive performance. To surmount this limitation, Pan et al. [6], drawing inspiration from the Transformer architecture, devised a long-term spectrum prediction method named Autoformer-CSA. Autoformer-CSA employs a self-attention mechanism, integrating series spatial and channel attention modules with autocorrelation mechanisms. This enables the model to allocate varying degrees of attention to different positions in the spectrum sequence, effectively capturing the long-term trends and seasonal characteristics of spectrum data.\nB. Time-Frequency-Space Spectrum Prediction\nUnlike traditional time-frequency prediction, DL-based spatiotemporal spectrum prediction faces two key challenges: reconstructing spectrum map data for large RoIs and capturing heterogeneous time-frequency-space correlations.\nTo overcome these challenges, Li et al. [7] initially delved into historical data collected from a network of sparsely distributed spectrum sensors. They employed an inverse-distance spatial interpolation method to extrapolate the spectrum map across the entire RoI. They utilized predictive recurrent neural network (PredRNN) to discern the spatial-temporal correlations embedded in the spectrum map. Employing three identical PredRNN components, they modeled the temporal proximity, daily cycle, and weekly trend of the spectrum image. Ultimately, Li et al. used parameter matrices to integrate the features extracted from these three components. This refined approach to feature extraction has proven effective in significantly enhancing the model's predictive performance.\nAccording to the path loss model in [8], it's clear that wireless signals follow exponential decay with distance. As the average received power at nearby locations tends to be similar, there's a higher spatial correlation. In simpler terms, only sensors close to the unsensed area can provide signal power information that has a certain correlation with the data in the unsensed area. Therefore, Ren et al. [8] went a step further and employed a neighboring spatial interpolation method to estimate the spectrum map for the entire RoI. This method is compared with a tensor completion, and the proposed approach achieves the minimum error rate at a low sparsity level. Note that in addition to the above methods there are Kriging, kernel-based, and improved tensor completion methods. Ren et al. proposed a spatiotemporal spectrum prediction method combining CNN and ResNet to capture spectrum matrix spatiotemporal features, using skip connections to improve performance and prevent gradient vanishing."}, {"title": "IV. LEARNING ENHANCEMENT FOR CROSS-BAND SPECTRUM PREDICTION", "content": "In real-world spectrum services, certain frequency bands, like those used for cellular mobile communication, can gather a substantial amount of spectrum data. Conversely, other bands, such as military bands, may have only limited available spectrum data. For frequency bands with abundant labeled data, we can directly employ DL-models for training and prediction. However, in scenarios where data is scarce, training DL-models becomes challenging, resulting in less-than-optimal predictive performance. To tackle this challenge, there are currently two methods: one involves increasing the amount of trainable data for the target band to support model training, while the other involves transferring knowledge from related bands with ample available data to the target prediction network. Below, we detail how DL drives both methods.\nA. DGAN for Cross-Band Spectrum Prediction\nA deep GAN (DGAN) consists of a generator and a discriminator. The GAN's aim is to train the generator network to produce realistic data, while the discriminator network distinguishes between generated and real data. These two networks engage in mutual adversarial training, propelling the learning and improvement of the model. Consequently, GAN can be employed to boost the quantity of trainable data for the target band.\nPeng et al. [9] introduced a spectrum data conversion GAN to generate realistic data for the target band. Initially, they used Fr\u00e9chet inception distance (FID) to measure differences between the target band and other bands, pinpointing the source band with the least difference from the target predictive band. Peng et al. then crafted a generator using a blend of CNN and LSTM to transform data from the source band to the target predictive band. Subsequently, the prediction model utilized both the transformed data and the original data from the target band for training and prediction.\nIt's essential to note that this method doesn't directly generate the target prediction data but leverages highly similar data from other bands. This is because traditional GANs have specific requirements for the quantity of target samples, and insufficient target samples can lead to GAN instability. Additionally, this approach reduces the dependency of the GAN on existing data from the target band. Lin et al. [10] similarly utilized FID to identify a source band with high similarity to the target band. They then devised a deep convolutional GAN (DCGAN) for pre-training using the source band. Subsequently, transfer learning was employed to fine-tune the pre-trained model onto the target band, generating data with minimal differences. Finally, the generated data for the target band, along with the original data, was used for training and prediction in a residual prediction model.\nB. DTL for Cross-Band Spectrum Prediction\nTransfer learning (TL) aims to distill knowledge from one or multiple source tasks and apply that knowledge to related but different target tasks. Building upon this TL concept, deep transfer learning (DTL) has emerged as a secondary approach to tackle this challenge. DTL efficiently achieves cross-band spectrum prediction by transferring pre-trained models from the source band to the target task.\nLin et al. [11] implemented cross-band prediction through a naive TL approach by transferring a prediction model comprised of LSTM units. To ensure positive TL, Lin et al. analyzed the similarity between source and target bands and used dynamic time warping to measure the similarity of each frequency point between source and target bands. Subsequently, Lin et al. employed a transfer component analysis method, utilizing maximum mean discrepancy as the distance measurement, based on the marginal distribution of features to obtain features with strong transferability.\nFor an additional performance enhancement, Li et al. proposed a transfer time-frequency fusion attention network (T-TF2AN) to achieve cross-band spectrum prediction. The primary challenge in applying TL for TF2AN stems from the gaps between source and target bands, resulting from variations in spatial, temporal, or spectral domains. Li et al. addressed these challenges through weighted TL, adaptively discovering and transferring shared knowledge while mitigating the negative impact of specific domain patterns from the source spectrum. The core components of the designed weighted TL are the shared pattern learner and the loss with adaptive weights. The shared pattern learner assigns higher weights to source spectrum data similar to the target spectrum, incorporating more shared patterns. Adaptive weights are determined by appropriately weighting the loss from the source domain, diminishing the risk of negative transfer and effectively enhancing the model's performance on the target domain dataset. It's noteworthy that the T-TF2AN model not only considers cross-band prediction but also takes into account spatial and temporal transferability."}, {"title": "V. A VITRANSLSTM SPATIOTEMPORAL SPECTRUM PREDICTION FRAMEWORK", "content": "A. Problem Description\nAssuming that there are S sparsely distributed spectrum sensors in a RoI divided into M(rows) \u00d7 N(columns) grids to measure the radio signal power in the area. Considering the hardware cost, it is not feasible to deploy sensors at every location. Therefore, we adopt the commonly used inverse-distance spatial interpolation method to fill in the missing signal power at unmeasured locations. These measurements at any given time step t can be represented as a tensor $X_t \\in \\mathbb{R}^{C \\times M \\times N}$, where the measurements are mapped to three channels (C = 3) using a common Jet colormap. The spatiotemporal spectrum prediction problem involves predicting a spectrum sequence of the most probable length-K time steps in the future based on a spectrum sequence of historical length-J time steps, including measurements at the current time step, represented as\n$X_{t+1},..., X_{t+K} = \\underset{X_{t+1},..., X_{t+K}}{\\arg \\max} p(X_{t+1},... , X_{t+K}|X_{t-J+1}, \\dots, X_{t}).$ (1)\nB. ViTransLSTM Framework\nIn spatiotemporal spectrum prediction, most works adopt convolutional structures to capture spatial correlations, such as PredRNN used in [7]. However, due to the limitations of convolutional kernel size, convolutional structures may struggle to capture global information. The fixed parameter-sharing mechanism in convolution operations makes it challenging for the model to handle spatiotemporal correlations at different locations. Compared to convolutional structures, vision Transformers (ViTs) excel at capturing spatial correlations due to their self-attention-based global learning patterns. Inspired by this, we integrate ViT and PredRNN to propose an extended spatiotemporal spectrum prediction framework called ViTransLSTM. The innovation of this framework lies in replacing the core component ST-LSTM in PredRNN with our designed ViT-LSTM component. The overall structure of the ViT-LSTM component is shown on the left of Fig. 3.\nAs a variant of ST-LSTM, spatiotemporal ViT-LSTM consists of two sets of gate structures: a standard temporal ViTransMemory and a spatiotemporal ViTransMemory. In the standard temporal ViTransMemory, all the inputs $X_{t-J+1},\\dots, X_t$, hidden states $H_{t-J+1}, \\dots, H_t$, cell outputs $C_{t-J+1},\\dots, C_t$, and gates, i.e., input ViTransGate $i_{t}^{vit}$, int, input-modulation ViTransGate $g_{t}^{vit}$, forget ViTransGate $f_{t}^{vit}$ are 3D tensors in $\\mathbb{R}^{C \\times M \\times N}$. In the spatiotemporal ViTransMemory, all the inputs $X_{t-1+1}, ..., X_t$, hidden states $M_{t-J+1},..., M_{t-1}$, cell outputs $M_{t-J+1},\\dots, M_{t}$, and gates $i'_{t}^{vit}, g'_{t}^{vit}, f'_{t}^{vit}, o'_{t}^{vit}$ are also 3D tensors in $\\mathbb{R}^{C \\times M \\times N}$. The equations of ViT-LSTM in the l-th layer are shown as follows:\n$g_{t}^{vit} = tanh(vit(X_t) + vit(H_{t-1}) + b_g)$\n$i_{t}^{vit} = \\sigma(vit(X_t) + vit(H_{t-1}) + b_i)$\n$f_{t}^{vit} = \\sigma(vit(X_t) + vit(H_{t-1}) + b_f)$\n$C_t = f_{t}^{vit} * C_{t-1} + i_{t}^{vit} g_{t}^{vit}$\n$g'_{t}^{vit} = tanh(vit(X_t) + vit(M_{t-1})+b_g)$\n$i'_{t}^{vit} = \\sigma(vit(X_t) + vit(M_{t-1})+b_i)$\n$f'_{t}^{vit} = \\sigma(vit(X_t) + vit(M_{t-1})+b_f)$\n$M_t = f'_{t} M_{t-1} + i'_{t} g'_{t}$\n$o_{t}^{vit} = \\sigma(vit(X_t) + vit(H_{t-1}) + vit(C_t) + vit(M_t) + b_o)$\n$H_t = o_{t}^{vit} tanh(linear([C_t, M_t]))$, (2)\nwhere $\\sigma$ is the sigmoid activation function, * is the convolution operator, $\\odot$ is the Hadamard product, [,] is the operation of concatenating two tensors, and vit(\u00b7) is two consecutive Swin Transformer [13] blocks (see Fig. 3, right), which includes a standard multi-head self-attention module with non-overlapping window (W-MSA), a MSA module with non-overlapping shifted window (SW-MSA), and a feed-forward network (FFN, is a 2-layer multilayer perceptron (MLP), with Gaussian error linear unit (GELU) non-linearity in between) following each MSA module. Layer normalization (LN) is applied before each MSA module and FFN, and a residual connection is applied after each module.\nAs shown in (2), unlike ST-LSTM, ViT-LSTM introduces two new designs: ViTransGate and ViTransMemory. Specifically, 1) ViTransGate: This design replaces the convolutional networks in all gate structures of the original ST-LSTM with ViT (i.e., Swin Transformer). Taking the input ViTransGate $i_{t}^{vit}$ (see Fig. 3, right) as an example, it is obtained by feeding $X_t$ and $H_{t-1}$ into the vit(\u00b7) module, followed by the activation function. 2) ViTransMemory: From (2), this design feeds the tamporal memory unit $C_t$ and the spatiotemporal memory unit $M_t$ separately into the vit(\u00b7).\nCompared to the original ST-LSTM, the advantages of ViT-LSTM include: 1) The ViTransGates in ViT-LSTM capture local and global spectral pattern features of the spectrum map by computing self-attention within the standard window and the shifted window, respectively. In contrast, the original ST-LSTM can only capture local features through convolution operations, which may lead to the loss of critical spatial spectrum pattern features. 2) The ViTransMemory also employs the self-attention mechanism to integrate spectral information from different positions, capturing more diverse feature representations to enhance memory. Additionally, it works in conjunction with LSTM to store long-range spatiotemporal spectrum dependencies. In contrast, convolution operations may exhibit biases toward local patterns, potentially leading to the loss of specific memory features.\nC. Experimental Results\nTo validate the effectiveness of the proposed ViTransLSTM, we use spectrum data collected by four sensors via the Elec-"}, {"title": "VI. RESEARCH CHALLENGES AND OPPORTUNITIES", "content": "Although DL has achieved beneficial performance gains in spectrum prediction, there are still numerous open challenges for further study, as summarized in Fig. 5 at a glance.\nOwing to interference from spectrum measuring equipment, signal propagation environments, and other variables, spectrum measurements may contain missing and abnormal data. This compromise in data quality amplifies the complexity of modeling. In an initial exploration, tensor completion is used to address this challenge. However, tensor completion algorithms struggle to estimate nonlinear missing data accurately. Fortunately, the diffusion model uses a stepwise de-noising approach to grasp the distribution of nonlinear spectrum data, resulting in the generation of high-quality spectrum data that is robust to deletions and anomalies.\nB. Multi-Modal Integration Assisted Spectrum Prediction\nDespite achieving impressive accuracy, existing DL-based spectrum prediction methods rely only on uni-modal data, highlighting the need for a robust DL-based multi-modal fusion framework to integrate features from each modality (such as spectrum occupancy series and spectrogram). To the best of our knowledge, deep multi-modal learning has yet to be applied in the field of spectrum prediction, despite its successful implementation in other domains such as weather and traffic predictions. However, a significant challenge involves the necessity to assign relative weights to different modalities. A viable approach could use a multi-objective optimization algorithm to balance the optimal weight of each modal by treating each weight as an optimization objective.\nC. High Complexity with Multi-Tasking Spectrum Prediction\nMulti-tasking spectrum prediction is often considered to meet the customization needs of massive spectrum users. However, when various DL-based spectrum prediction models are deployed in multiple spectrum prediction tasks, the intrinsic complexity of the models often necessitates substantial computational resources for training. To address this issue, it is recommended to customize lightweight DL models for spectrum prediction to achieve a flexible balance between performance and complexity through pruning and knowledge distillation techniques. Further, the lightweight model uses distributed learning [15] for each task node to improve computing efficiency.\nD. Cross-RoI Spatiotemporal Spectrum Prediction\nUnlike cross-band spectrum prediction, cross-region spatiotemporal spectrum prediction extends into the time-frequency-space dimension. TL addresses this challenge, with cross-region TL going beyond time-frequency knowledge to include spatial information. This introduces complexity, leading to a challenge known as knowledge drift. As more knowledge transfers, the problem of knowledge drift becomes more severe. Enhancing transfer learning efficiency and spectrum prediction accuracy in the target region is a significant challenge. To address this, importance weight TL reweights source domain knowledge to improve model performance. Furthermore, cross-region cross-band spectrum prediction based on DTL presents an even more formidable problem. The relevance of the target domain to the source domain is lower compared to the previous challenge, intensifying the knowledge drift problem in transfer learning. Refinement TL emerges as a solution, involving the classification of transfer knowledge to improve transfer efficiency.\nE. Spectrum Prediction for Multi-Domain Information Fusion\nThe electromagnetic spectrum is evolving, integrating space, air, and ground communication modes like vehicle-to-vehicle (V2V), unmanned aerial vehicle (UAV)-assisted, air-to-ground, and satellite communication. These modes create complex spectrum usage patterns. Joint spectrum prediction for space, air, and ground is challenging due to multi-domain information fusion, addressed by spectrum information semanticization. Additionally, traditional-DL struggles in dynamic wireless systems, requiring frequent retraining for changing data distributions, consuming time and memory. Deep reinforcement learning offers a solution by training intelligent agents to perform tasks and derive optimal strategies from experience. In highly dynamic wireless systems, where the environment constantly changes, the agent receives feedback through a reward mechanism and makes rational decisions."}, {"title": "VII. CONCLUSION", "content": "We have commenced by elaborating on the motivation of applying DL in spectrum prediction. Firstly, DL is eminently suitable for extracting the complex nonlinear features encountered. Secondly, the adaptive fitting capability of DL enables parameter knowledge fine-tuning required by the predicted band change. Based on these motivations, DL is proposed for extracting both the intrinsic nonlinear time-frequency-and time-frequency-space-domain features, thereby inspiring short/long-term spectrum predictions. Further, DL was employed for data enhancement of target prediction bands and knowledge transfer of source bands to achieve cross-band spectrum prediction. Then, a framework combining visual self-attention and LSTM, named ViTransLSTM, is proposed to achieve high-precision spatiotemporal spectrum prediction. We have validated the effectiveness of the proposed framework on a real-world spectrum dataset. Finally, we have provided the future associated challenges and potential opportunities of applying DL to spectrum prediction."}]}