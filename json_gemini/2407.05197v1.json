{"title": "A Generalized Transformer-based Radio Link\nFailure Prediction Framework in 5G RANS", "authors": ["Kazi Hasan", "Thomas Trappenberg", "Israat Haque"], "abstract": "Radio link failure (RLF) prediction system in Ra-\ndio Access Networks (RANs) is critical for ensuring seamless\ncommunication and meeting the stringent requirements of high\ndata rates, low latency, and improved reliability in 5G networks.\nHowever, weather conditions such as precipitation, humidity, tem-\nperature, and wind impact these communication links. Usually,\nhistorical radio link Key Performance Indicators (KPIs) and their\nsurrounding weather station observations are utilized for building\nlearning-based RLF prediction models. However, such models\nmust be capable of learning the spatial weather context in a\ndynamic RAN and effectively encoding time series KPIs with\nthe weather observation data. Existing works fail to incorporate\nboth of these essential design aspects of the prediction models.\nThis paper fills the gap by proposing GenTrap, a novel RLF\nprediction framework that introduces a graph neural network\n(GNN)-based learnable weather effect aggregation module and\nemploys state-of-the-art time series transformer as the temporal\nfeature extractor for radio link failure prediction. The proposed\naggregation method of GenTrap can be integrated into any\nexisting prediction model to achieve better performance and\ngeneralizability. We evaluate GenTrap on two real-world datasets\n(rural and urban) with 2.6 million KPI data points and show that\nGenTrap offers a significantly higher F1-score (0.93 for rural and\n0.79 for urban) compared to its counterparts while possessing\ngeneralization capability.", "sections": [{"title": "I. INTRODUCTION", "content": "The emergence of modern networking applications such as\nIndustry 4.0, intelligent transportation systems, health infor-\nmatics, and augmented/virtual reality (AR/VR) necessitates\nhigh network bandwidth, robust reliability, and fast commu-\nnication speeds [1]. Fifth-generation (5G) cellular networks\naspire to accommodate these applications by satisfying various\nservice level objectives (SLOs) through the use of millimetre-\nwave (mmWave) spectrums (24GHz to 100GHz). For instance,\nteleoperated driving systems can schedule human takeover\nif SLOs are not satisfied [2]. However, a 5G radio access\nnetwork (RAN) requires deploying a denser array of base\nstations to communicate over mmWave radio as it traverses\nshort distances. Moreover, these links suffer from distortion\nand attenuation due to weather phenomena like precipitation,\nhumidity, temperature, and wind [3], [4]. Thus, mobile oper-\nators must have predictive maintenance of RANs connections\nto support the above real-time applications.\nA group of works investigated this correlation of mmWave\nradio and weather conditions using operator-provided real data\n[5], [6], [7]. Our initial investigation on the same dataset [6]\nreveals the same findings and motivates us to revisit the current\nreliable 5G RAN systems. These works developed learning-\nbased failure prediction schemes due to the availability of\nradio key performance indicators (KPIs) from radio stations\nand respective weather attributes. The automated systems also\nreduce human intervention, CAPEX, and OPEX. Semih et\nal. propose a branched LSTM architecture to process both\ntemporal and spatial features and offer better performance\ncompared to models considering only temporal data processing\n[6]. Islam et al. introduce a comprehensive data preprocessing\npipeline and use an LSTM-autoencoder model to predict link\nfailures based on the reconstruction loss [7]. Finally, Agarwal\net al. deploy decision trees and random forest classifiers to\npredict upcoming five-day radio link failures [5].\nThese works demonstrate the influence of weather attributes\non radio communication and incorporate them into their\ndeveloped models. However, the solutions suffer from few\ncritical limitations. Specifically, these models cannot capture\nlong-term dependencies due to vanishing gradients issue of\nLSTM [8]. Also, they do not weigh the importance of dif-\nferent elements in a sequence during predictions [9]. Another\ncritical design aspect is correctly associating each link to the\nsurrounding weather stations that affect the link. However,\nthe existing approaches deploy heuristics to associate radio\nsites with weather stations. For instance, [5], [6], and [7] use\nthe closest weather station, the aggregated k nearest stations,\nand the maximum of minimum distances between radio and\nweather sites, respectively. Also, these heuristic-based solu-\ntions cannot generalize well on a dynamic topology, which\nmay occur if providers selectively turn on/off radio stations\nfor efficient resource utilization [10]. Overall, existing LSTM-\nbased solutions suffer from learnability and generalizability\ncritical for predictive RAN maintenance.\nThis work fills the above gaps and proposes GenTrap,\na novel radio link failure prediction framework capable of\nefficiently learning both the spatial (radio and weather stations\nassociation) and temporal (time-series features) context of\nRAN and surrounding weather stations. Specifically, GenTrap\nleverages a Graph Neural Network (GNN) to dynamically\nlearn the effect of weather attributes from surrounding stations\non radio links and realize a generalized model for unseen radio\nlinks. This GNN module can be incorporated into existing\narchitectures for better performance and generalizability. In\naddition, the time series Transformer can encode complex\ntemporal dependencies by learning which time point in the\npast to focus on for predicting future link failures [11]. Thus,\nthe novelty of GenTrap includes developing a learnable archi-\ntecture for capturing weather effects and applying transformers"}, {"title": "II. BACKGROUND AND MOTIVATION", "content": "This section offers the necessary background to understand\nthe propose work and associates that knowledge to motivate\nthe need for developing GenTrap.\n5G RAN. 5G has gained popularity due to its support\nfor emerging applications that require high bandwidth, high\nreliability, and low latency [14]. It uses mmWaves to achieve\nthese breakthroughs at the cost of coverage size and higher\npenetration loss [15]. 5G deployment takes advantage of small\ncells that collect user traffic and communicate it to radio\nsites/stations (RS) to mitigate these drawbacks. The radio sites\nuse 5G radio links (RL) to communicate with each other\nand the core network, which connects users to the Internet\n[16]. These links are usually surrounded by numerous weather\nstations (WS) that can provide weather context at the radio\nlinks [6]. An overview of this type of deployment is depicted\nin Fig. 1. We use radio site KPIs along with the weather\nstation data to predict radio link failures for the upcoming\nday. Thus, providers can take the necessary precautions for\ncritical services.\nImbalance dataset. The percentage of radio link failures,\nhowever, is less compared to the normally operating ones,\nwhich creates imbalanced data to be processed. For instance,\nthe Turkcell dataset [6] that we use has 0.3% and 0.06%\nfailures in rural and urban deployments, respectively [6]. Thus,\ndeep learning models trained on such a highly imbalanced\ndataset leads to good performance only on the majority class\n[17]. Typical approaches for handling such datasets are to use\nrandom undersampling of the majority class [6] and SMOTE\noversampling of the minority class [7]. Undersampling bal-\nances class distributions by randomly removing majority class\ninstances, which may remove informative data points [18].\nOn the other hand, SMOTE oversampling takes each minority\nclass sample and generates synthetic examples along the line\nsegments by joining k nearest neighbours [19]. However, some\nof the limitations of SMOTE include generating noisy samples\nand introducing bias due to sub-optimal neighbours selection\n[20].\nWe use the weighted cross entropy loss function to over-\ncome the limitations of undersampling and oversampling as\ndata points are neither sampled nor generated [21], [22], [23].\nIt deals with the imbalanced data by incorporating prior prob-\nabilities into a cost-sensitive cross-entropy error function [22].\nThe regular cross-entropy function is symmetrical. Also, the\nerror reduction for both classes occurs at the same logarithmic\nrate. Thus, in the case of imbalanced data, the majority class\nwill have a larger influence on the total loss as the overall\nerror is minimized regardless of class. We use the following\nweighted cross entropy loss function to mitigate the effects of\nclass imbalance in the dataset.\n$J(\\Theta) = \\frac{1}{m} \\sum_{i=1}^{m} -y^{(i)} log(\\hat{y}^{(i)}) \\lambda - ( 1 - y^{(i)}) log(1 - \\hat{y}^{(i)}) \\lambda$ (1)\nHere, $J(\\Theta)$ and m are the total loss and number of samples,\nrespectively. y is the ground truth (y = 1 for failure) and $\\hat{y}$ is\nthe model prediction.\nGraph Neural Network (GNN) aggregation. We can\ndeploy a learning-based failure prediction scheme on the\nbalanced data by incorporating weather impact on radio links.\nFor instance, existing works incorporate surrounding weather\nstation information - by using derived features, optimal dis-\ntance, and closest station data to capture their spatial context\n[6], [7], [5]. However, the optimal number of closest weather\nstations can vary across links even in the same deployment;"}, {"title": "III. RELATED WORK", "content": "This section presents two groups of related works for\nGenTrap: learning-based failure prediction approaches in 5G\nand GNN-based aggregation methods that capture spatial\ncorrelations.\nLearning-based failure prediction. Khunteta et al. [29]\nand Boutiba et al. [30] introduced the LSTM network to\ncapture temporal feature correlations to predict link failures,\nbut they do not consider weather effects. Other works filled the\ngap and utilized both historical radio link KPIs and weather\nobservation data - similar to the dataset used in our approach.\nFor example, Agarwal et al. [5] combined individual link\nfeatures with the closest weather station measurements and\nproposed Random Forest as the classifier. Aktas et al. [6]\nutilized a branched architecture with LSTM and feed-forward\nnetwork to capture temporal and categorical feature depen-\ndencies, respectively. Islam et al. [7] exploited the advantage\nof the reconstruction capabilities of LSTM-autoencoder by\ntraining their model on normal operational data and flagging\ndata points with high reconstruction error as a failure during\ntesting. These approaches rely on LSTM's ability to extract\nuseful information. Still, they cannot weigh the importance of\nelements in a time series sequence. They fail to capture all\npossible influences among time series variables [9]. Recently,\ntransformer models have demonstrated promising results in\ntime series forecasting [28], as they can capture long-range\ndependencies, focus on important elements in a sequence and\nlearn from all possible dependencies [11]. We take advantage\nof the time-series transformer model and propose a branched\narchitecture that performs graph aggregation over each link's\nsurrounding weather stations to achieve the best performance."}, {"title": "IV. DATASET DESCRIPTION", "content": "The performance of GenTrap is evaluated over two sets\nof real-world open-source data from a renowned telecommu-\nnication provider, Turkcell [6]. The dataset comprises radio\nlink configuration and key performance indicator (KPIs) data,\ncoupled with time-aligned weather station observations of two\ndistinct deployments, urban and rural, where the time range\nis between January 2019 to December 2020 and January\n2019 to December 2019, respectively. Because of privacy\nconcerns, some configuration parameters and performance data\n(e.g., equipment name, link IDs, etc.) of the radio links are\nanonymized without loss of information. Also, the actual\nGPS location of these stations is not provided; instead, there\nare pairwise relative distances among these sites. A detailed\ndescription of the data tables is provided below.\nrl-sites. This data contains radio site identifiers and site-\nspecific parameters such as height and clutter class - surround-\ning environment at the site, e.g., open urban, open land, dense\ntree area, etc. The same radio site can have multiple radio\nlinks as each uses different links to communicate with different\nsites.\nrl-kpis. Presents daily radio link KPIs, where important\nones include severally error second, error second, unavailable\nsecond, block bit error, etc. and link-specific configuration\nparameters such as card type, modulation, frequency band, etc.\nEach link is uniquely identified with a pair of radio site-id and\nmini link-id.\nmet-stations. This data encompasses unique weather station\nnumbers and station-specific parameters such as height and"}, {"title": "V. GENTRAP ARCHITECTURE", "content": "This section first presents the GenTrap architecture. Then,\nwe illustrate the integration of GNN-based spatial context\ncapturing in existing LSTM+ and LSTM-Autoencoder models.\nA. GenTrap\nFig. 4 presents the GenTrap architecture, which maps time-\nseries sequences to a probability vector. Specifically, the\nprediction system takes the radio link KPIs and surrounding"}, {"title": "VI. RADIO LINK FAILURE PREDICTION", "content": "This section presents the link failure prediction workflow\n(Fig. 9) deploying the above learning models. The process\nconsists of three components: data preprocessing, model train-\ning and validation, and model testing. In brief, the data\npreprocessing step consists of cleaning raw data, correlating\nlinks with weather stations, handling missing values, encod-\ning categorical features, and performing a time series split.\nThen, the next part focuses on training and validating the\nexisting LSTM+ and LSTM-autoencoder models along with\nthe proposed GenTrap. Lastly, we test the performance of\nthese approaches on unseen real-world link KPIs and weather\nobservations, which is presented in Section VII.\nA. Data Preprocessing\nThe data preprocessing consists of the following steps.\nData preparation. The effectiveness, precision, and intri-\ncacy of machine learning tasks are significantly influenced\nby calibrating the training data [35]. Our initial investigation\nrevealed that there are inconsistent values in weather station\nand radio link data (e.g., unexpected string values both in radio\nand weather data). These inconsistencies lead to erroneous or\nimpossible data transformation for the subsequent steps, e.g.,\ncasting features to proper data types. Thus, we first tackle\nthese inconsistencies, e.g., by removing the data samples\nif a numerical feature contained unexpected string values.\nAfter handling inconsistent values, we cast all numerical and\ncategorical features to the floating and the string data type,\nrespectively. In this problem, we consider daily data for both\nradio links and weather stations.\nReal weather data alignment. Our dataset has data from\ndifferent entities (e.g., weather stations and their observations,\nradio sites and their link performance data). In order to merge\nweather observations with radio link KPIs, their temporal\nfrequencies need to be maintained. Radio site KPIs and real\nweather realizations are collected in the chosen dataset over\ndaily and hourly time intervals, respectively. We use the\nstandard mean aggregation [6] to transform hourly realizations\ninto daily weather data to align historical weather realizations\nwith radio link KPIs.\nData imputation. The majority of statistical and machine\nlearning algorithms lack robustness in handling missing val-\nues, thereby being susceptible to the impact of incomplete\ndata [36]. We calculate the percentage of missing values for\neach feature in our dataset. Some features from historical\nradio link KPIs and real weather station data have a high\npercentage of missing values. We use a simple heuristic of\ndropping features with missing values of 20% or higher. Also,\nsome numerical features suffer from missing segments over\ntime, but the data can be reliably interpolated if the percentage\nof missing values is under 15% [37]. Thus, we deploy time\nseries linear interpolation to impute missing numerical KPIs\nand historical weather observations [38].\nData Merging. We need to use historical KPIs and weather\ndata to predict following-day link failure. Thus, we append a\nlabel column in the KPIs table, representing the next-day link\nstatus. Also, each radio site can have multiple links, so we\nmerge the KPI features with the corresponding site features by\nmatching the site id. Weather station features are also merged\nwith weather observation data similarly.\nTackling data imbalance. We use the weighted cross-\nentropy loss function to tackle the data imbalance, which\nincorporates prior probabilities into a cost-sensitive cross-\nentropy error function. Unlike traditional cross-entropy, this\nweighted approach accounts for the imbalanced nature of the\ndata, giving a larger influence to the majority class while\nminimizing overall error. The loss function puts the prior\nminority to majority class ratio $\\lambda$ (0.003 for rural and 0.0006\nfor urban) into the regular cross entropy (Eq. 1). In rural\ndeployment, this ensures that both classes have an equal\ninfluence because when y = 0 for a non-failure instance,\nthe remaining term (1 \u2013 y\u00b2) log(1 \u2013 \u0177\u00b2) only contributes\n$\\lambda$ = 0.3 percent to the loss. Similarly, when y = 1 for a\nfailure instance, the remaining term -y\u00b2 log(y) contributes\n(1 \u2212 ) = 99.7 percent to the loss.\nTime series split. Cross-validation (CV), a widely adopted\nmethod for assessing algorithm generalizability in classifi-\ncation and regression, has been extensively studied by re-\nsearchers [39]. Our dataset contains time series numerical"}, {"title": "VII. EVALUATION OVER REAL-WORLD DATA", "content": "This section presents the evaluation results of GenTrap over\ntwo real-world datasets: urban and rural. We also implement\nand evaluate the existing LSTM+ and LSTM-autoencoder\nmodels on the same datasets for a fair comparison. Next, we\nillustrate the benefits of integrating the learnable GNN aggre-\ngation module into existing models to boost their performance.\nFinally, we evaluate the generalization capability of GenTrap.\nA. Performance Metrics and Evaluation Setup\nWe evaluate the performance of different approaches using\nthree metrics: precision, recall, and F1-score. For each ap-\nproach, we first calculate true positives (TP), true negatives\n(TN), false positives (FP), and false negatives (FN) cases for\nboth failure and non-failure events. True positives are those\nfailures in the test dataset that are correctly predicted as"}, {"title": "D. Generalization performance of GenTrap", "content": "This last evaluation focuses on GenTrap's generalization\nability to show its application in modern 5G RAN. Usually,\nproviders selectively turn off radio stations for resource (e.g.,\nenergy) savings as the traffic demand across base stations\ncan vary according to their locations (urban vs. rural) and\ntime of the day (working vs. after working hours) [41][42].\nThus, a prediction model must be generalized, i.e., capable of\nadapting with dynamically changing links. Another benefit of\nsuch generalization is saving computational resources to train\nthe model with a subset of links instead of the entire set.\nIn this evaluation, we train GenTrap and LSTM+ models\non different fractions of the links of the given topology while\ntesting the entire topology to understand how well the models\ngeneralize on unseen links. This gives us a measure of how\ngood the chosen models are in learning from a topology with\nfewer links and generalizing over a bigger topology with new\nlinks. Table III presents the comparison of GenTrap with"}, {"title": "E. Discussion", "content": "This section discusses how GenTrap can be extended in\nfuture.\nEnhancing GenTrap model. This work demonstrated how\na GNN aggregation and Transformer-based spatiotemporal\ncontext capture could lead to increased performance and\ngeneralization of a radio link failure prediction scheme.\nHowever, the proposed model can further be improved by\nincorporating recent advancements in pre-training transform-\ners and transformer GNN. Following an unsupervised pre-\ntraining scheme similar to [11], [43], GenTrap can benefit from\nperformance enhancement over the current fully supervised\nlearning. Similarly, the GNN aggregation module in GenTrap\ncan be extended with a transformer encoder like [44], [45] to\ndirectly learn the aggregation function instead of using the max\naggregation. We can also utilize the GNN aggregation to cap-\nture inter-base station effects such as interference. The same\narchitecture principle can be applied to purely unsupervised\napproaches where the input consists of a variable number of\nweather stations for each radio link. We plan to explore these\noptions in future.\nImproving data quality. Our datasets have a meagre\nminority-to-majority class ratio. Because of that, a small\nvolume of data (minority class) can penalize the model per-"}, {"title": "VIII. CONCLUSION", "content": "5G RAN radio links can fail due to changes in weather\nconditions. A proactive RLF prediction system can improve\nuser experience and save network operators' time, cost, and\nresources. Thus, we investigated the shortcomings of existing\nlink failure prediction models and proposed a novel GNN ag-\ngregation and time-series transformer-based framework called\nGenTrap. It deploys GNN aggregation over a variable number\nof surrounding weather stations to capture spatial context\nwhile incorporating the transformer for temporal context. The\nevaluation of GenTrap over two real-world datasets confirmed\nits superiority over existing LSTM-based models. We also\ndemonstrated that integrating the GNN aggregation into exist-\ning models could improve performance. Finally, we presented\nthe generalization capability of GenTrap in the presence of\nunseen links. Thus, service providers can deploy GenTrap for\npredictive maintenance to support emerging IoT applications."}]}