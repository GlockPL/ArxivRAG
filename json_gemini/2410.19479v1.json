{"title": "Peter Parker or Spiderman?\nDisambiguating Multiple Class Labels", "authors": ["Nuthan Mummani", "Simran Ketha", "Venkatakrishnan Ramaswamy"], "abstract": "In the supervised classification setting, during inference, deep networks typically\nmake multiple predictions. For a pair of such predictions (that are in the top-k\npredictions), two distinct possibilities might occur. On the one hand, each of the\ntwo predictions might be primarily driven by two distinct sets of entities in the\ninput. On the other hand, it is possible that there is a single entity or set of entities\nthat is driving the prediction for both the classes in question. This latter case, in\neffect, corresponds to the network making two separate guesses about the identity\nof a single entity type. Clearly, both the guesses cannot be true, i.e. both the\nlabels cannot be present in the input. Current techniques in interpretability research\ndo not readily disambiguate these two cases, since they typically consider input\nattributions for one class label at a time. Here, we present a framework and method\nto do so, leveraging modern segmentation and input attribution techniques. Notably,\nour framework also provides a simple counterfactual \u201cproof\u201d of each case, which\ncan be verified for the input on the model (i.e. without running the method again).\nWe demonstrate that the method performs well for a number of samples from the\nImageNet validation set and on multiple models.", "sections": [{"title": "1 Introduction", "content": "Supervised deep learning models performing classification are being widely deployed in many\nsettings. An important and active direction of research is on interpretability of the predictions of\nthese models. In the multiclass classification setting, typically, each training datapoint comes with\none or few labels Deng et al. (2009), Lin et al. (2014); however models usually output softmax\nprediction \"probabilities\" for every class label present in the dataset. Generally, either the top one or\ntop k softmax values are considered as predictions for classification. Since contemporary datasets\nhave large numbers of labels, many of the labels in the top k predictions are likely those that aren't\npresent in the input in question. Indeed, for a given pair of such predicted labels, these prediction\nprobabilities have two distinct interpretations. The first interpretation is that the probabilities represent\nthe possibility of the presence of distinct entities that correspond to each of the class labels. The\nsecond interpretation is that the pair of probabilities represent two distinct predictions about a single\ntype of entity present in the image. Both these interpretations could simultaneously be true for\ndifferent pairs of predicted class labels for a single input that is run through a model. The second\ninterpretation being true for a given pair of labels might detract from our confidence that both the\nlabels are indeed correct predictions; this would indicate the need to verify these predictions via\nother means e.g. using a different more capable model or a human. Most contemporary models do"}, {"title": "2 Related work", "content": "Attribution techniques have been studied in multiple directions. Perturbations are the simplest among\nthe them. Zeiler (2014) implements them by masking the part of the picture with gray square and\nobserving the output. They also implemented a process where outputs at each layer are projected\nback to the layer's input dimension with minimum loss in the data but also capturing what caused\nthe final activation and termed it as deconvolution. Springenberg et al. (2014) proposed Guided\nbackpropagation, as a modification to deconvolution.\nGradient-based methods, such as gradient descent and backpropagation, form the foundation for\nmany feature attribution techniques. These methods compute the gradient of the model's output with\nrespect to the input features. The magnitude of the gradient indicates the sensitivity of the model's\noutput towards changes in the input features. Gradient Simonyan et al. (2014) itself along with\nintegrated gradients Sundararajan et al. (2017), deepLift Shrikumar et al. (2017), GradCAM Selvaraju\net al. (2017), layer wise relevance propagation Bach et al. (2015) are few notable techniques.\nBy closely inspecting the visualizations of these gradients, Sundararajan et al. (2017) proved that\ngradients do not work properly. XRAI Kapishnikov et al. (2019) showcases the ability to attribute to\nparticular segments of image with the help of Integrated gradients and segmentation algorithms like\nFelzenswalb's graph based algorithm Felzenszwalb and Huttenlocher (2004).\nLIME Ribeiro et al. (2016) and SHAP Lundberg and Lee (2017) have different approaches. LIME\ntried to generate interpretable explanations local to the input in question which are understandable to\nhumans. SHAP on the other hand tries to explains how important the feature is in the given prediction\nbased on a concept of Shapley values from Game Theory. While all these methods calculate/explain\nthe importance of each feature for the given generated output, we would like to expand on the role of\nthese features when we consider multiple outputs.\nRelatedly, the issue of popular contemporary datasets such as ImageNet having one label per image\nhas also received attention. For example, Beyer et al. (2020) point out that even though images in\nImageNet training set often contain multiple objects, only one of them is recognized in the label."}, {"title": "3 Definitions and Preliminaries", "content": "We now present some definitions and preliminaries that will be used in the remainder of the paper.\nWhile we apply the framework to the image classification setting here, these definitions could, in\nprinciple, also be applied to other types of supervised learning models.\nFor our purposes here, we define a deep network model as a function that maps input points in\nn-dimensional space to a vector of softmax \u201cprobabilities\u201d corresponding to m class labels."}, {"title": "Definition 1.", "content": "A deep network model is a function $f : R^n \\rightarrow [0,1]^m$, which maps an input in\nn-dimensional space to a vector of softmax values corresponding to m class labels."}, {"title": "Definition 2 (S-redaction).", "content": "Given an input $I \\in R^n$ and a set $S \\subseteq {1, ..., n}$ of indices, an $S$-\nredaction of $I$ to $v$, is defined as the input $I_S$ obtained by replacing the values corresponding to the\nindices in $S$ to the value $v$.\nUnless otherwise specified, when we mention an $S$-redaction here, we mean an $S$-redaction to zero. If\nthe input is an image, an $S$-redaction of it would correspond to the image generated by \"blackening\"\nout the subset of the pixels corresponding to $S$. Also, if each pixel has multiple channels (e.g. R,G,B),\nan $S$-redaction will zero out values in all channels, for every pixel present in $S$.\nInformally, an input attribution for a specific class label is typically understood to correspond to the\ninput dimensions that are \"responsible\" for the prediction of that class label by the deep network\nmodel. Here, we will define an attribution to simply be a subset of input dimensions (i.e. without\nassigning relative weights to every dimension in the subset). We now define a natural counterfactual\nnotion of input attributions that precisely quantifies the same in a verifiable manner."}, {"title": "Definition 3 (8-attribution).", "content": "For a deep network $f : R^n \\rightarrow [0,1]^m$, input $I \\in R^n$, labell with\nprediction $p$, $\\delta \\in [0, 1]$, and $S \\subseteq {1, ..., n}$, if the $S$-redaction of $I$ causes the prediction of $l$ to be\nat most $\\delta p$, then $S$ is said to be a $\\delta$-attribution for label $l$ corresponding to input $I$, with respect to $f$.\nHere, the intent is to have $\\delta$ be a small value (e.g. $\\delta = 0.2$)\nThis definition of a $\\delta$-attribution naturally leads to a verification method. The idea is that one can\naccompany a claimed $\\delta$-attribution with a counterfactual proof or certificate, which in this case would\nsimply be the $\\delta$-attribution $S$. This allows a verifier to easily verify a claimed $\\delta$-attribution without\nneeding to re-run the method that determined it or indeed even having knowledge of the method."}, {"title": "Definition 4 (8-disjoint label predictions).", "content": "For $\\delta\\in [0,0.5]$, suppose we have a deep network\n$f : R^n \\rightarrow [0,1]^m$ which, on input $I$, has predictions $p_1$ and $p_2$ for class labels $l_1$ and $l_2$ respectively.\nThe class labels $l_1$ and $l_2$ are said to be $\\delta$-disjoint, if there exist disjoint sets $S_1$ and $S_2$ such that\n1.  The $S_1$-redaction of $I$ causes a $\\delta$-attribution to exist for class label $l_1$, while causing the\nprediction for class $l_2$ to be at least $(1 - \\delta)p_2$.\n2.  The $S_2$-redaction of $I$ causes a $\\delta$-attribution to exist for class label $l_2$, while causing the\nprediction for class $l_1$ to be at least $(1 - \\delta)p_1$.\nHere, again, for two labels $l_1$ and $l_2$, claimed $\\delta$-disjoint label predictions will be accompanied by a\ncertificate, which would simply be the $\\delta$-attributions $S_1$ and $S_2$ that satisfy the above definition."}, {"title": "Definition 5 (\u03b4-overlapping label predictions).", "content": "For a deep network $f : R^n \\rightarrow [0, 1]^m$ with an input\n$I$, two class labels $l_1$ and $l_2$ are said to be $\\delta$-overlapping, if $l_1$ and $l_2$ are not $\\delta$-disjoint and if there\nexists a set $S$ such that an $S$-redaction causes a $\\delta$-attribution to exist for class labels $l_1$ as well as $l_2$.\nHere, again, the certificate would be the $\\delta$-attribution $S$; however it is unclear if a tractable verification\nalgorithm exists, since one might need to check all partitions of $S$ \u2013 of which there are exponentially\nmany \u2013 to check if they correspond to $\\delta$-disjoint label predictions. In Section A.2.2, we describe a\nheuristic verification algorithm that is tractable and demonstrate that it works well."}, {"title": "4 Methodology", "content": "Leveraging modern input attribution and segmentation techniques, we build algorithms to determine\nif a given pair of labels is $\\delta$-disjoint or $\\delta$-overlapping. These algorithms also return the corresponding\ncertificates. We deploy and test these algorithms on image classification models VGG-16 Simonyan\nand Zisserman (2014), Inception-v3 Szegedy et al. (2016), and ResNet-50 He et al. (2016) which are\npretrained on the ImageNet dataset Deng et al. (2009). We use images from the ImageNet validation\ndataset in our test, unless otherwise mentioned.\nFor a label available in the top k predictions of an input image, we calculate pixel-wise attribution\nusing integrated gradients Sundararajan et al. (2017) and parallelly, we segment the image using Seg-\nment Anything Model (SAM) Kirillov et al. (2023). We then performed segment-wise accumulation\nof attribution values to rank the segments from highest attribution to lowest attribution, along the\nlines of XRAI Kapishnikov et al. (2019). These segment-wise rankings are used in the later part of\nthe paper and can be visualized using heatmaps (Figure 1)."}, {"title": "4.1 Effectiveness of Redactions", "content": "Here, we demonstrate that redactions to zero are an effective counterfactual proof, in practice.\nRedacted images are constructed by picking up segments one-by-one based on segment-wise attribu-\ntion rankings and replacing segmented areas with black pixels in the original preprocessed image."}, {"title": "5 Distinct labels pointing to distinct entities", "content": "To determine if two labels from the top-k predictions are driven by distinct entities in an image,\nwe need $S_1$ and $S_2$ redactions, if available, that satisfy Definition 4. One method to obtain such\nredactions is discussed below & two other methods are presented in the Appendix A.2.\nGiven a list of segment attribution values for one label, for each segment, we determine the proportion\nof the segment's attribution value with respect to the highest segment attribution value, which we\ncall its normalized segment attribution. We do so for the other label as well. Now we segregate the\nsegments into two disjoint sets corresponding to the two labels. For any segment, if the normalized\nsegment attribution for label $l_1$ is higher than that for label $l_2$, then that segment is categorized within\nthe set of label $l_1$ and vice-versa. In case of a tie, we use the data of surrounding segments for\ncategorization. Now that we have two disjoint sets of segments, one for each label, we pick each\nsegment from label $l_1$'s set based on their rank and redact by sequentially accumulating them to form\nan $S_1$-redaction until the prediction of corresponding class label $l_1$ goes down to at most $\\delta p_1$ while\nthe $l_2$ prediction stays above $(1-\\delta)p_2$ where $p_1$ and $p_2$ are the softmax probability of original image"}, {"title": "6 Distinct labels pointing to single entity", "content": "To determine if two labels from the top-k predicted labels are \"pointing\" to a single entity in an\nimage, we do the following. We pick each segment based on their absolute\u00b2 rank for label $l_1$ and\nredact by sequentially accumulating them to form an $S_1$ redaction until the prediction of both the\nlabels go down simultaneously to at most $\\delta p_1$ and $\\delta p_2$ respectively. This process is likewise repeated\nwith segments ranked based on $l_2$ to obtain a $S_2$ redaction. If $l_1$ and $l_2$ are indeed pointing to single\nentity, then $S_1$ and $S_2$ redactions present themselves with a significant intersection and $S_1 \\cap S_2$,\non satisfying Definition 5, is used as a $\\delta$-attribution.The $\\delta$-attribution for $S_1 \\cap S_2$, as illustrated in\nFigure 3, acts as a certificate which can be used to verify that the two labels indeed \"point\" to a single\nentity in the image."}, {"title": "7 Discussion", "content": "In this paper, we consider the problem of disambiguating the input attributions of a given pair of\nclass labels. Specifically, we ask if the two label predictions arise from the same percept or from\ndifferent percepts present in the input. We build a method and framework to do so, by leveraging\nmodern attribution and segmentation techniques and demonstrate favorable performance on a number\nof contemporary image classification models.\nThis work comes with some limitations. Firstly, we use existing attribution and segmentation algo-\nrithms and, as such, depend on their performance; this also has the positive effect that improvements\nin such techniques will likely improve our method. Another limitation is that, for cases wherein the\nobject corresponding to a label isn't present, our method does not specifically identify that this is\nso; see Section A.2.3. Finally, we find, empirically, that for labels whose softmax values are very\nsmall, the method often does not perform well. Indeed, this may be because for such small prediction\nvalues the model does not tangibly use a coherent set of segments for such predictions.\nA conceptual departure from typical attribution methods is our stipulation that a claimed answer ought\nto be accompanied by a certificate that can be objectively verified, i.e. without appeal to the method\nthat created it. Often, different attribution methods offer differing attributions and it is difficult to\nobjectively and automatically ascertain the quality of these attributions without human scoring. We\ntherefore suggest that this type of framework will also have value in such settings."}, {"title": "A.1 Illustration of rank-based redaction for ResNet-50 and Inception-v3", "content": null}, {"title": "A.2 Two additional algorithms for finding 8-disjoint attributions", "content": null}, {"title": "A.2.1 Algorithm 2", "content": "As we perform the steps mentioned in Section 4, for labels $l_1$ and $l_2$, we obtain two identical sets of\nsegments that are ranked within their set based on segment-wise attribution method Kapishnikov et al.\n(2019). Now that we have two sets of segments, we pick each segment from label $l_1$'s set based on\ntheir rank and redact by sequentially accumulating them to form an $S_1$-redaction until the prediction\nof corresponding class label $l_1$ goes down to at most $\\delta p_1$ while the $l_2$ prediction stays above $(1-\\delta)p_2$\nwhere $p_1$ and $p_2$ are the softmax probability of original image of labels $l_1$ and $l_2$ respectively. This\nstep is repeated on $l_2$'s set to obtain $S_2$ redaction. Redacting based on their rank in corresponding\nsets allows us to get the $S_1$ and $S_2$ redactions with small number of segments. These two redactions\nmight not satisfy Definition 4 as they may not be disjoint. We then discard the intersection segments\nor reassign them one-by-one to either $S_1$ or $S_2$ redactions based on their importance to the respective\nlabels. This step makes the $S_1$ and $S_2$ redactions disjoint and satisfies Definition 4."}, {"title": "A.2.2 Algorithm 3 (which also serves as a heuristic verifier for Definition 5)", "content": "Given a set of segments $E$ that are obtained after segmentation, we would like to curate two disjoint\nsets of segments that are $\\delta$ attributions for each label and can generate $S$-redactions that satisfy\nDefinition 4. To generate $\\delta$ attribution set of segments for label $l_1$, we start with an empty set $A$ and\nexecute the following algorithm.\n1.  Select the most important segment $s_i$ and pop it out of $E$ and push it into $A$.\n2.  Generate $D$ with the set of segments that are adjacent to any segment in $A$.\n3.  Pop out next most important segment from $D$ and push it into $A$.\n4.  Repeat the process from Step2 until we end up with no important segment in $D$.\n5.  Repeat from Step1 and start with a different segment until we are left with no important\nsegments for label $l_1$. This process is repeated to generate $\\delta$ attribution set of segments for\nlabel $l_2$.\nHow do we choose most important segment? To calculate the importance score of segment $s_i$ we\nredact the segment $s_i$ from A-redacted image(image with all segments from $A$ redacted) and check\nthe percentage drop in $l_1$ and $l_2$ prediction values from A-redaction to $A \\cup \\{s_i\\}$ redaction. The\ndifference between $l_1$ percentage drop and $l_2$ percentage drop is the importance score for the segment\n$s_i$ during that step.\nWe end up with $S_1$ and $S_2$ redactions that are not disjoint, and discarding the intersection gives us\ntwo disjoint redactions. These redactions are then verified to check if they satisfy Definition 4 and\ncorresponding $\\delta$ attributions are used as certificates to validate the image later.\nThe limitation of this algorithm is that, unlike attribution based algorithms from Sections 5 & A.2.1, it\ndoes not provide the redactions with a small number of segments, since it does not pick the segments\nbased on the ranks generated by the attribution algorithms.\nThis algorithm also acts as a heuristic verifier for Definition 5. Provided with set of segments\n$S = S_1 \\cup S_2$ as $\\delta$ overlapping attribution certificate from Section 6, if the image and labels correspond\nto $\\delta$ disjoint from Section 5, this algorithm segregates the segments into $S_1$ and $S_2$ sets that correspond\nto each labels satisfying Definition 4. These $S_1$ and $S_2$ sets invalidate the $\\delta$ attribution certificate.\nUsage of this algorithm can remove the overhead of attribution. User performing the verification\nneed not have the knowledge of algorithm that generated the certificate."}, {"title": "A.2.3 Additional examples on VGG-16, ResNet-50 and Inception-v3", "content": "Illustrations of $\\delta$-disjoint and $\\delta$-overlapping attributions and their corresponding redactions performed\non various images are shown in Figures 6, 7, and 8. Note that the label pairs chosen in these figures\nare picked from top-5 rather than top-2.\nWe mention an example in Figure 6 (VGG-16, example 1), wherein the method flags it as a $\\delta$-\ndisjoint attribution, even though a human inspection shows that no object corresponding to the class\nmoving_van is present. This is a limitation, as previously mentioned, even though the method shows\nthat differing segments cause the $\\delta$ attributions for the two classes.\nFigure 7 and 8 demonstrate our method on a challenging example, which contains both a spider and a\nbee. In a pair of classes that correspond to a spider and a bee, it is classified as a $\\delta$-disjoint attribution;\nhowever with two spider class labels, it is classified as a $\\delta$-overlapping attribution. Specifically, in\nFigure 7, it is observed that for Inception-v3, the image is categorized into $\\delta$-disjoint attribution for\npair of labels (garden_spider, bee) and (bee, black_and_gold_garden_spider), whereas the\nsame image for labels (garden_spider, barn_spider) is categorized into $\\delta$-overlapping attribution\nas shown in Figure 8."}, {"title": "A.3 Running time estimates for our methods", "content": "All our experiments were run on an Apple Macbook Pro with M1 Pro chip, 16GB RAM, running\nmacOS 12.1, and the running time estimates below correspond to this hardware.\nSAM segmentation algorithm: 127 seconds per image.\nPixel-wise attribution and Segment-wise attribution: 64 seconds for a pair of chosen labels.\nAlgorithm mentioned in Section 5: 15 seconds for a pair of chosen labels.\nAlgorithm mentioned in Section 6: 16 seconds for a pair of chosen labels.\nAlgorithm mentioned in Section A.2.1: 16 seconds for a pair of chosen labels.\nAlgorithm mentioned in Section A.2.2: 900 seconds for a pair of chosen labels."}]}