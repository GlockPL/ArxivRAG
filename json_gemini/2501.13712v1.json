{"title": "Formally Verified Neurosymbolic Trajectory Learning via Tensor-based Linear Temporal Logic on Finite Traces", "authors": ["Mark Chevallier", "Filip Smola", "Richard Schmoetten", "Jacques D. Fleuriot"], "abstract": "We present a novel formalisation of tensor semantics for linear temporal logic on finite traces (LTLf), with formal proofs of correctness carried out in the theorem prover Isabelle/HOL. We demonstrate that this formalisation can be integrated into a neurosymbolic learning process by defining and verifying a differentiable loss function for the LTLf constraints, and automatically generating an implementation that integrates with PyTorch. We show that, by using this loss, the process learns to satisfy pre-specified logical constraints. Our approach offers a fully rigorous framework for constrained training, eliminating many of the inherent risks of ad-hoc, manual implementations of logical aspects directly in an \"unsafe\" programming language such as Python, while retaining efficiency in implementation.", "sections": [{"title": "1. Introduction", "content": "Neurosymbolic learning is an active and growing field of interest in artificial intelligence (Garcez & Lamb, 2023) that aims to combine the benefits of deep learning and symbolic reasoning. Of particular interest is the possibility to assist neural learning using symbolically encoded domain knowledge. This can be a complicated task and is prone to human errors in the translation process. In this work, we eliminate this risk by formally verifying the logic that implements the symbolic reasoning and automatically generating code that we then integrate into a neural network. We thus bring a high level of mathematical certainty to our implementation.\nWe use the proof assistant Isabelle/HOL (Nipkow, Paulson, & Wenzel, 2002) to formally specify and verify both the syntax and semantics of our logical language. Our approach is over tensors, the objects used for calculations in most deep learning frameworks. We also use Isabelle to generate executable code directly from our formalisation, guaranteeing that the implementation retains the formally verified correctness properties of the specification.\nMore concretely, we build a pipeline that integrates linear temporal logic over finite traces (LTLf) (De Giacomo & Vardi, 2013) formalised in Isabelle and deep learning in PyTorch (Paszke, Gross, Massa, Lerer, Bradbury, Chanan, Killeen, Lin, Gimelshein, Antiga, et al., 2019) via a novel interpretation of the LTLf semantics over tensors. This allows us to automatically synthesise code for a loss function suitable to the application of any LTLf logical constraint to the learning environment. While our solution is general and can be applied to any domain over which discrete temporal reasoning is appropriate, in this paper we demonstrate our pipeline with a set of motion-planning experiments. In these, we train a"}, {"title": "1.1 Organisation of paper and contributions", "content": "In the next section we discuss the background to our work, and briefly introduce LTLf, tensors and the Isabelle/HOL theorem prover. Then, in Section 3 we present a formal specification of LTLf and some of its expected properties. We go on to specify a loss function $L$ and its derivative $dL$ that work over tensors representing finite traces of real-valued states varying in discrete time. We give an oveview of our formal proof that $L$ is sound with respect to the semantics of LTLf, and that $dL$ formalises its derivative with respect to any variation in the input trace. We also describe our setup for the automatic generation of code for $L$ and $dL$ from their specifications using Isabelle's rigorous code extraction mechanism (Haftmann & Bulwahn, 2021). In Section 4, we illustrate an application of our general approach by considering a set of motion planning experiments. Lastly, in Section 5, we discuss the significance of our work and potential future developments.\nThe main contributions of this paper can be summarised as follows:\n\u2022 Formalised semantics of LTLf over tensors.\n\u2022 A formally-specified, differentiable loss function $L$ over tensors that is sound with respect to the LTLf semantics.\n\u2022 A formally verified, tensor-based derivative $dL$ of the loss function.\n\u2022 Automatically generated, reusable (OCaml) code for constrained, neural learning processes using LTLf.\n\u2022 Trajectory planning experiments demonstrating the practical applicability of our work.\n\u2022 An empirical demonstration that the LTLf constraint specification is domain-dependent, using a double loop path finding experiment.\nNext, we briefly review the general background to our work before focusing on some of its more specific technical foundations."}, {"title": "2. Background", "content": "The standard semantics for a logical syntax is a way of evaluating statements written in the language. This evaluation typically is either true or false, and takes place in a context where any variables used in the statements have values assigned to them. In our work, a context is the trace over which our logic is evaluated (discussed further in Section 3.2). In what follows, let $[\\phi]_{L,i}$ denote the evaluation of a formula $\\phi$ of a logical language $L$ under the standard semantics for $L$ in some context $i$.\nA smooth semantics over the same language $L$ can be considered a way of evaluating statements, also in some context, such that the evaluation is differentiable. Typically, the evaluation will give a real number that relates to the standard semantics. For some smooth semantics, e.g. in fuzzy logic, this value may represent a confidence in the truth of the"}, {"title": "2.1 Learning using smooth semantics", "content": "Fischer et al. (2019) have shown that it is possible to use a differentiable propositional logic to train a neural network. They use a simple logic to demonstrate that a loss function which is sound with respect to its semantics allows one to train a neural network to learn logical constraints. Our formalisation of atomic constraints is closely related to their work, although our treatment of other logical operators is different (see Section 3.2).\nInnes and Ramamoorthy (2020) extend Fischer et al.'s approach to use LTL and demonstrate that a path-planning neural network is able to learn to satisfy a subset of LTL constraints. However, the treatment of LTL in their paper does not make clear that they are working over finite traces in their task, which requires the different semantics of LTLf. In particular, the treatment of LTLf differs from LTL when it comes to the termination of a trace, as discussed in Section 2.3 \u2013 for example, the semantics for the Next operator is different from that in LTL. This means that the semantics they discuss in the paper cannot fully work over finite traces. Partly for this reason, the code supporting their work is incomplete and differs from the mathematical treatment discussed in the paper. Our work addresses these limitations (see Section 3.2).\nThis issue about the actual version of LTL being used, and the variance between the mathematical specification and its implementation motivated some of our earlier work on formally verifying the use of a LTLf-based loss function to train neural networks (Chevallier, Whyte, & Fleuriot, 2022). However, while rigorous, this previous work was not based on tensors, leading to inefficiencies in the generated code and the approach not scaling beyond simple examples. The current paper fully overhauls and extends this earlier effort.\nOn the theorem proving side, Bentkamp et al. (2019) formalised tensors in Isabelle/HOL as part of their work on proving the fundamental theorem of network capacity. As their formalisation was solely concerned with the mathematical proof of this theorem, it is impractical for generating efficient code. However, it did motivate our own approach to representing and formally reasoning about tensors (see Section 3.1).\nOther researchers have examined the semantics of different logics over tensors. How a subset of signal temporal logic (STL), a continuous time analogue to linear temporal logic, might be evaluated over tensor structures was examined by Leung et al. (2023). Their work describes the semantics with an algorithmic method rather than a simple loss function such as we detail in Section 3.2.2, and is not formally verified. They were able to demonstrate their approach experimentally.\nA smooth semantics for a variant of LTL (called Differentiable Temporal Logic or DTL) was adopted to learn task planning techniques by Xu et al. (2022). DTL is defined over a subset of a variant of LTL, and is differentiable and applicable to neural learning. The constants True and False are interpreted as positive and negative infinity, which may not be useful in a learning process. Similarly to the work by Innes and Ramamoorthy, it is"}, {"title": "2.2 Properties of smooth semantics", "content": "Given the above, there are several important properties that we might want smooth semantics to possess:\n1.  Compositionality: the smooth semantics should preserve structure of the standard semantics. Usually this is taken to mean that conjunction in the smooth semantics should be associative, commutative and idempotent.\n2.  Soundness: $[\\phi]_{L',i}$ should output a value corresponding to truth if and only if $[\\phi]_{L,i}$ evaluates to true.\n3.  Shadow-lifting (Varnai & Dimarogonas, 2020): The value of a conjunction should reflect improvements in either of its conjuncts. In particular, if all conjuncts have comparable value, then an improvement in any of them should induce a similar improvement in the value of the conjunction. More formally, all partial derivatives should be positive:\n$\\forall n. \\frac{[\\phi_1 \\land \\phi_2]_{L',i}}{[\\phi_n]_{L',i}} > 0 \\quad \\text{if } [\\phi_1]_{L',i} = [\\phi_2]_{L',i} = c$\nThis means one can learn from partial improvements, even if not all conjuncts are improving simultaneously.\n4.  Monotonicity: for all constraints $\\phi_1$ and $\\phi_2$, if $\\phi_1$ entails $\\phi_2$, then, if both are false under the standard semantics, $[\\phi_1]_{L',i}$ should be no closer to the nearest value representing true than $[\\phi_2]_{L',i}$. So, if the smooth semantics returns a value representing a loss, the weaker constraint produces a smaller loss than the stronger one\u00b9."}, {"title": "2.3 Linear temporal logic over finite traces", "content": "Linear temporal logic (LTL) allows the specification of constraints that can be evaluated over traces of states in discrete time (Pnueli, 1977). In this context, a state is a set of measurements in a particular domain, and a trace is an ordered sequence of states, encoding how these change as time progresses.\nLinear temporal logic constraints are either satisfied (true) or unsatisfied (false) at a specific moment within such a trace. Whether a constraint is satisfied may depend on how the trace changes in the future. LTLf is a version of LTL where constraints are evaluated over traces that terminate at some finite point (De Giacomo & Vardi, 2013). In particular, this influences how the temporal operators work at the end of a trace. We assume that any constraint evaluated over an empty trace cannot be satisfied and must be interpreted as false.\nThe trace that an LTLf constraint is evaluated over can be thought of as a finite matrix, as illustrated in Figure 1. Consider columns as corresponding to a progression through time, and rows as corresponding to values that may change over time as the trace progresses. In our work, the elements of this matrix are always real numbers representing measurements of interest, such as the x or y coordinate of a time parameterised trajectory at a given moment. Indexing into the matrix extracts the value of a single measurement at a single point in time."}, {"title": "2.4 On Tensors", "content": "Although tensors are fundamental to modern deep learning systems, their high-level representation and operations are usually taken for granted. In our case, though, these need to be made explicit to enable formal reasoning about their basic properties and more advanced notions based on them e.g. our loss function $L$. For this reason, we next give a brief overview of some of the aspects that are relevant to our current work, and delve a bit more deeply into their mathematical formalisation in Section 3.1.\nTensors are essentially multi-dimensional arrays of data that can be understood as a generalisation of vectors and matrices to arbitrary dimensions. In deep learning, tensors can be used to represent the input, intermediate computations, the weights of a neural network, and any output (Lim, 2013). Like a matrix, we can index into a tensor to obtain individual elements. Unlike a matrix, which has two indices, a tensor may take between zero and arbitrarily many indices. Following the terminology of Kolda and Bader (2009), the number of indices corresponds to the order of the tensor while the number of different values each index can take is the dimension (of that index).\nIn our work, tensors are used to represent a trace over which we might evaluate some constraint in LTLf. For example, an order 3 tensor $T$ could be used to represent a batch of four traces of the x and y coordinates of a robot over five discrete time steps. So, if $T$"}, {"title": "2.5 Isabelle/HOL", "content": "For our work, the proof assistant Isabelle (Nipkow et al., 2002) provides the symbolic framework for formal specification, verification, and code generation. It is widely used for the formalisation of mathematics, especially real analysis and associated domains (Fleuriot, 2000; H\u00f6lzl & Heller, 2011; Immler & H\u00f6lzl, 2012), the verification of programs (Strecker, 2002; Bulwahn, 2012; Mari\u0107, 2010), hardware (Tverdyshev, 2005), and even software architecture (Marmsoler, 2018).\nTheories in Isabelle are collections of formal mathematical definitions (about e.g. types, algebraic objects, functions, or other objects), and theorems about their mathematical properties. Theorems and their proofs can be written in the pen-and-paper like, structured proof language Isar (Wenzel, 1999). We use higher order logic (Gordon, 1988) in Isabelle, Isabelle/HOL, to formalise our work.\nAll theorems proven in Isabelle/HOL can be guaranteed to be valid. Informally, this is because Isabelle belongs to the LCF family of theorem provers (Milner, 1979) which represent theorems as a type that must be built using a set of inference rules, starting from a small kernel of trusted axioms in our case, those of higher order logic. Moreover, Isabelle/HOL adheres to the so-called HOL methodology. This involves introducing new concepts via definitions rather than axiomatically; i.e. new theories are conservative extensions of existing ones (Pitts, 1993; Kun\u010dar & Popescu, 2017).\nIsabelle/HOL can generate code from formally specified functions, using a thin rewriting layer, into PolyML, OCaml, Haskell and Scala (Haftmann & Bulwahn, 2021). This ability provides a link between Isabelle/HOL's formal concepts, such as our $L$ and $dL$ functions, and their code-generated versions. As discussed further in Section 3.3, this provides various guarantees that the generated code respects the formally proven properties of its specification."}, {"title": "3. Formalisation in Isabelle/HOL", "content": "We now discuss the details of our formalisation and proofs in three main sections: first we cover relevant parts of our tensor formalisation, then discuss our LTLf work, and lastly, we briefly review code generation and how our formalisation feeds into it. Throughout, we use mathematical notation (rather than Isabelle syntax) to illustrate our specification and its properties."}, {"title": "3.1 Tensors", "content": "As previously mentioned, the use of tensors in a deep learning framework such as PyTorch is usually taken for granted. In our work, however, we need to give careful consideration to how these can be represented in formal mathematics and then used for code generation."}, {"title": "3.2 LTLf syntax and semantic formalisation", "content": "Here, we discuss the formalisation of LTLf in Isabelle/HOL. We formalise the syntax of LTLf following our definitions in Section 2.3. In the rest of this section we will detail our novel formalisation of the semantics of LTLf over tensors, both the truth value of an LTLf constraint and its smooth semantics."}, {"title": "3.2.1 TENSOR-BASED SEMANTICS FOR LTL f", "content": "A constraint has meaning under LTLf: it is either true or false, given a time period to be evaluated over. In order for our formalisation to capture this, we define a function EVAL that can evaluate a LTLf formula over a trace this effectively formalises the standard semantics of LTLf over tensors.\nEVAL takes three parameters: an LTLf constraint $\\rho$, an order $n$ real tensor $T$ (with $n \\geq 2$), and a time parameter $t$, indicating the time step within each trace that $\\rho$ should be evaluated from. $T$ contains the traces to be evaluated over, with dimensions beyond the first two representing the batching, and is indexable using $(i_0, i_1, ..., i_{n-1})$. EVAL returns a boolean tensor (a member of Tensor$\\mathbb{B}$) of order $(n - 2)$, where the element at dimensional index $(i_2, i_3, ..., i_{n-1})$ is the truth value of $\\rho$ when evaluated over the trace found at that element of the batch. Using the notation established in Section 2.2, EVAL($\\rho$, $T$, 0) gives a tensor of results corresponding to $[\\rho]_{LTLf,T}$.\nIn the rest of this section we examine EVAL by its cases, starting with the base case. If $t$ exceeds the maximum temporal index of the traces within $T$ then EVAL always evaluates to False, as we are evaluating $\\rho$ over an empty trace. This is the first case, and overrides any"}, {"title": "3.2.2 SMOOTH TENSOR-BASED SEMANTICS FOR LTLf", "content": "We next formalise the smooth semantics for LTLf by defining the loss function $L$ and its derivative $dL$ over our tensors. $L$ returns a real tensor (a member of Tensor$\\mathbb{R}$) of the same order as EVAL.\n$L$ takes four parameters: the LTLf constraint $\\rho$, the tensor $T$, a temporal position $t$ we are to evaluate from, and a smoothing factor $\\gamma$ used for differentiation (discussed in more"}, {"title": "3.3 Code generation in Isabelle/HOL", "content": "We obtain code from our formalisation using Isabelle/HOL's code generation facilities (Haftmann & Bulwahn, 2021). This is a formal program synthesis method that passes our mathematical specifications through a thin translation layer to a target programming language, in our case OCaml. The translation layer of the code generator, analogous to the kernel of the theorem prover, uses a small number of trusted code translations to build types and function definitions.\nAs already mentioned, this ensures that the generated code retains the mathematical properties that we have proven for our formal specification. This principle is fundamental to our pipeline.\nFor several of our functions, we expand on the formal specifications using code equations. Consider some function $F$ defined in Isabelle/HOL, with a set of properties proven against it. The definition of $F$ used for these proofs may be ideally suited for theorem proving purposes, but may be inefficient when translated using code generation. A code equation for $F$ is then a formally proven equivalent, alternative definition for $F$. This alternative definition is designed to generate more efficient code. As an example, consider SUBT, which"}, {"title": "3.4 Integration with PyTorch", "content": "In our experiments, the generated OCaml code is integrated into PyTorch using its autograd engine. The $L$ function is used in the forward pass of an optimiser, and the $dL$ function in the backward pass"}, {"title": "4. Experiments", "content": "To show that our pipeline produces usable learning outcomes, we give a demonstration of our LTLf loss function being used to directly optimise trajectories in Section 4.1, and then look at its use in a deep learning setting involving dynamic movement primitives in Section 4.2."}, {"title": "4.1 Direct optimisation of trajectories", "content": "The setting of these introductory demonstrations is that of finding a two-dimensional trajectory that satisfies some constraint expressed in LTLf. In our first example, a trajectory is represented as a vector in $(\\mathbb{R} \\times \\mathbb{R})^N$, where $N$ is the number of discrete timesteps. This vector acts as the trace our LTLf constraints are evaluated over. The initial trajectory is a straight line (with a small random component to avoid poor learning due to symmetry) from (0,0) to (1,1), with constant velocity, and $N = 50$ (the time interval between timesteps is $dt = 1$). We optimise $N - 2$ points on this trajectory, excepting the first and last timesteps (to fix the endpoints of the trajectory), using PyTorch."}, {"title": "4.2 Neural optimisation of trajectories using Dynamic Movement Primitives", "content": "The environment within which each of the following experiments takes place is a plane. A feed-forward neural network learns the parameters for a Dynamic Movement Primitive (DMP) (Schaal, Peters, Nakanishi, & Ijspeert, 2005) across this plane.\nDMPs span a wide class of smooth trajectories that approach a goal state from arbitrary initial conditions. A trajectory $y(t)$ approaching a goal $y_{final}$ is modelled as a damped spring with a forcing term $f$, can be summarised as the following equation adapted from Ijspeert et al. (2013):\n$\\ddot{y} = \\alpha(y_{final} - y) \u2013 \\beta \\dot{y} + f$\nfor constants $\\alpha$ and $\\beta$. The forcing term $f$ is a function of the initial conditions of the trajectory, learned from data as discussed in Innes & Ramamoorthy (2020). Once the forcing term and parameters are fitted to data, a set of states along the trajectory can be produced by evolving the above equation from an initial state in discrete time.\nDMPs are frequently used to represent complex movements, and present many advantages over the simpler model of Section 4.1. They represent a trajectory abstractly: as such, the learned trajectory is used to generate a set of samples for any list of time stamps. For point-set trajectories, the model and the sample are equal, and the timestamps are considered fixed across the entire problem. More importantly, the learnable parameters of the DMP are variables in a dynamical system, rather than just an independent set of positions (and perhaps velocities). Thus gradient descent influences the dynamics of the entire trajectory, while for point-set trajectories any dynamical meaning must be added manually (e.g. through the dynamical constraint in Section 4.1).\nOnce the initial, unconstrained, DMP has been learned we repeat the learning process, injecting our loss function $L$ for an LTLf constraint into the learning process, and observe how the resulting trajectory seeks to satisfy the constraint as we would expect. The constraint is evaluated against the trajectory produced by the DMP, not the DMP itself directly. However, as the trajectory is differentiable with respect to the DMP's parameters, the loss function can still be used to adjust the neural network's weights using backpropagation.\nThe training data follow a trajectory from which we extract $N = 100$ sequenced points in the plane describing a curve with small random perturbations, simulating a demonstrator in a supervised learning process following a trajectory from the origin to a destination in the plane. The DMP learns this trajectory, which we subsequently alter using LTLf constraints."}, {"title": "4.2.1 UNCONSTRAINED TRAINING", "content": "Let $D$ be the trajectory of the demonstrator along the curve and let $Q$ be the trajectory produced by the neural network, with both trajectories expressed using paired x and y coordinates. $Q$ and $D$ are $N \\times 2$ matrices. Let $Q_i$ be the row vector at index $i$ of $Q$ (similarly for $D_i$ and $D$). The per-sample imitation loss, $L_d$, for this sample pair is given by:\n$L_d(Q, D) = \\frac{1}{N} \\sum_{i=0}^{N-1} ||Q_i - D_i||^2$"}, {"title": "4.2.2 CONSTRAINED TRAINING WITH LTLf", "content": "Recall that $Q$, the trajectory of the DMP, encodes the $x$ and $y$ coordinates at each time-step. Let $P$ be the trace used to evaluate an LTLf constraint, which may additionally encode derived values about the trajectory, such as velocity or distance from a certain point, as well as any constants used for comparison.\nTo use $L$ in the learning process, we define a differentiable function $g$ that maps $Q$ to the trace $P$, an LTLf constraint $\\rho$ over that trace, and a smoothing factor $\\gamma > 0$. We use the function $g$ to transform the $x$ and $y$ coordinates of $Q$ to the values we are constraining e.g. the distance from a particular point, as discussed in Section 4.2.3. We then use this constraint in the learning process by changing the per-sample loss function to:\n$L_{full} = L_d(Q, D) + \\eta \\cdot L(\\rho, g(Q), \\gamma)$\nwhere $\\eta$ is a positive real number representing the weighting of the constraint violation loss against the imitation loss. This weighting is adjustable, allowing us to change the priority of satisfying the constraints relative to the imitation data. The loss function $L$ is implemented by the generated code from Isabelle/HOL.\nWe now repeat the same training procedure as for the unconstrained case, but with this augmented loss function $L_{full}$. We use $\\eta = 1.0$, the default weighting. For $\\gamma$, we proceeded empirically by by testing our most complicated scenario, involving the Compound constraint (see below for the full description), with different $\\gamma$ values from 0.5 to 0.001. The lowest value to produce stable results was $\\gamma = 0.005$."}, {"title": "4.2.3 DESCRIPTION OF EXPERIMENTS", "content": "We lay out 5 different problems:"}, {"title": "4.3 Constraint relaxation", "content": "Calculating losses for the constraints describing complicated trajectories can become time consuming. This is especially true if we have multiple nested temporal operators. However, it is sometimes possible to simplify the logical constraint by choosing an appropriate representation of the problem.\nWe demonstrate the above by extending the loop experiment previously described in Section 4.2.3 to one that loops twice, once towards the top left of the demonstrated trajectory, and once to the bottom right. This requires an increase in the number of nested temporal operators to capture the new loop constraint. The obvious extension for the con-"}, {"title": "5. Conclusion", "content": "We conclude this paper by giving an overview of current and potential further work, and provide some final reflections on our research contribution."}, {"title": "5.1 Future work", "content": "We have discussed a formal, tensor-based formulation of LTLf that can be used for neurosymbolic learning. However, there are further logics that we might wish to work with, that allow for a broader range of constraints. For example, we are currently working on formalising signal temporal logic (Donz\u00e9, 2013) and integrating it into our neurosymbolic framework. More generally, our work indicates that the approach could be successfully and practically applied to arbitrary logics, defining smooth semantics and proving them sound with respect to the logic's standard one.\nIt would be interesting to further study the loss landscape generated by our smooth semantics, through properties such as the shadow-lifting property (see Section 2.2). Any proofs of properties of the smooth semantics, be it regarding exploration or soundness, directly describe the behaviour of optimisation problems. One could then explore ideas"}, {"title": "5.2 Final Observations", "content": "We have presented a fully formal tensor-based formulation of LTLf and discussed how this can be used to specify a loss function and its derivative, and to generate code that is integrated into PyTorch for logic-based optimisation and neural learning.\nOur experimental results show that these constraints can successfully change the training process to match the desired behaviour. In contrast to ad-hoc, manual implementation in Python, our formally verified approach provides strong guarantees of correctness through a combination of proof and faithful code generation.\nThroughout, the decisions we have taken have been informed by the requirement to accurately model LTLf, but additionally by the (sometimes competing) requirements of formal proof and efficient code generation. Formal proof is greatly assisted by a logical structure that allows for easy induction over both constraints and tensors.\nWe have also seen how the choice of domain representation can impact on the applicability of constraints to achieve a goal. In our application to path modelling, a sophisticated trajectory model based on DMPs allows us to simplify constraints in a way that a na\u00efve coordinate-based approach does not.\nOur research emphasises several important lessons:\n1.  The soundness of the smooth semantics is important, but it is not the only property that should be satisfied.\n2.  Other properties such as compositionality and shadow-lifting (discussed in Section 2.1) are important, but need not be perfectly met for the logic and its loss function to be useful for effective learning."}]}