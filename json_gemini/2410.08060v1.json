{"title": "OPTIMAL TRANSPORTATION BY ORTHOGONAL COUPLING DYNAMICS", "authors": ["Mohsen Sadr", "Peyman Mohajerin Esfehani", "Hossein Gorji"], "abstract": "Many numerical algorithms and learning tasks rest on solution of the Monge-Kantorovich problem and corresponding Wasserstein distances. While the natural approach is to treat the problem as an infinite-dimensional linear programming, such a methodology severely limits the computational performance due to the polynomial scaling with respect to the sample size along with intensive memory requirements. We propose a novel alternative framework to address the Monge-Kantorovich problem based on a projection type gradient descent scheme. The micro-dynamics is built on the notion of the conditional expectation, where the connection with the opinion dynamics is explored and leveraged to build compact numerical schemes. We demonstrate that the devised dynamics recovers random maps with favourable computational performance. Along with the theoretical insight, the provided dynamics paves the way for innovative approaches to construct numerical schemes for computing optimal transport maps as well as Wasserstein distances.", "sections": [{"title": "1. INTRODUCTION", "content": "Background. The importance of the optimal transport lies in its widespread application at different fronts of computational studies, along with its unique theoretical properties. It plays an essential role in machine-learning by offering relevant metrics for comparing different distributions [5, 39, 26]. It has led to a significant progress in the theory of partial differential equations by its by-product, Wasserstein gradient flows [2, 35, 57]. At the same time, existing algorithms to compute such distances and corresponding maps remain expensive and complex. Given the versatile role of optimal transport in different branches of machine-learning [34, 1, 5], analysis [63, 35, 56], density functional theory [18, 24], optimization [43], and inference [32], among others, several numerical approaches have been pursued for its efficient computations. Classical methods were developed based on linear programming [13], gradient descent [19], dynamic flow formulation [10, 62], or elliptic solvers [58]. For efficient computation and improved performance-scaling with respect to the dimension, entropy regularization [25, 51] and its stochastic treatment [7] have been pursued. Approximate approaches using moment formulation [45, 55] of Monge-Kantorovich problem have been proposed, as well.\nDespite these progresses, to the best of our knowledge, there is no concise Ordinary Differential Equation (ODE) model, in the sense of particle/agent based models, which leads to the solution of the"}, {"title": "2. ORTHOGONAL COUPLING", "content": "(un-regularized) Monge-Kantorovich problem. Such a model would be particularly valuable, beyond theoretical and conceptual contributions, for its potential to further enable efficient optimal transport computations. In the opening chapter of Villani's seminal book [63], a list of coupling dynamics, of ODE or Stochastic Differential Equation (SDE) forms, are reviewed with the intention of creating correlations between two given random variables. While interesting results can be obtained e.g. by the Knoth-Rosenblatt rearrangement [28] or Moser's coupling [17], such schemes remain limited; e.g. due to coordinate dependency of the Knoth-Rosenblatt rearrangement, or the constraint of small deviation between the marginals for Moser's coupling.\nIn principle, finding the optimal transport between two probability spaces is a global optimiza-tion in a sense of linear programming on an infinite dimensional space. We are confronted with the question whether there exist local dynamic rules that can lead to the optimal transportation between two sample spaces? An interesting class of dynamic processes is given by orthogonal dynamics. They naturally arise in projecting Hamiltonian systems onto a sub-space, e.g. by the use of conditional expectation [21, 31]. These processes have an interesting feature that the remainder/unresolved portion remains orthogonal to the current state of the resolved variable.\nRecent study of Conforti et al. [23] leverages the projection method in the context of Langevin dynamics. Their proposed stochastic dynamics leads to the coupling which converges to the Sinkhorn regularization of the optimal transport problem [25]. Such a stochastic dynamics, which is closely linked to the Schr\u00f6dinger Bridge [30, 40, 20], gives rise to the Fokker-Planck equation, evolving the joint distribution. It remains to be addressed what happens to the introduced projected Langevin dynamics when the contribution of Brownian motion vanishes, relevant for the (un-regularized) Monge-Kantorovich problem.\nThe simplest form of the orthogonal dynamics can be constructed by projection of the gradient descent (with respect to the Monge-Kantorovich cost) onto a sub-space where marginals are preserved. In the absence of entropy regularization, this dynamics becomes a good candidate to create optimal transport between two measure spaces. At the level of distribution, one expects such a dynamics gives rise to the Vlasov equation for the evolution of the joint. Despite the theoretical appeal of the coupling through projection, numerical treatment of the conditional expectation can become prohibitive. In general, conditional expectation is solution of the Bayesian regression [46]. On the other hand, interpreting the conditional expectation through distinct data clusters, e.g. in an analogy with opinion dynamics [41], offers non-parametric numerical approach to deal with such coupling dynamics. With these observations in hand and leveraging the recent study [23], we pursue a projected dynamic approach as a concise solution algorithm of the Monge-Kantorovich problem.\nMain Contributions. We present the orthogonal coupling dynamics for the Monge-Kantorovich problem. More specifically:"}, {"title": "2.1. Main Dynamics", "content": "Starting with independent samples of X0 ~ \u03bcand Yo ~ \u03bd, we would like to construct a micro-dynamics in the sense of an ODE on Xt and Yt, which converges to the solution of (1). In other words, we look for a velocity vector v which updates Xt and Yt in a way that the minimum cost c(Xt, Yt), in the"}, {"title": "2. General Structural Properties", "content": "2.2. General Structural Properties\nThe OCD dynamics (13) leads to a certain favourable theoretical features. These are rooted in the fact that the conditional expectation is a projection operator in L\u00b2 with self-adjoint and contraction characteristics. We leverage these characteristics to derive theoretical properties of the OCD. While the detailed justifications are deferred to Supplementary Information, we provide an overview of the main theoretical results below, where the proofs are provided in Supplementary Information.\n(1) Marginal Preservation. Since the velocities $v_1^{ocd}, v_2^{ocd}$, introduced in Eq. (13), are orthogonal with respect to the functions of Xt and Yt, respectively, a direct computation shows that the distributions of Xt and Yt remain unchanged. More precisely we have the following result.\nProposition 2.1. Consider (Xt, Yt) to be the solution of the ODE system\n$Xt = v_1$ and $Yt = v_2$ \nwith velocities v = (v1, v2) \u2208 Tanpt,2\u03a0(\u03bc,\u03bd), and the initial condition (Xo, Yo) ~ \u03c0, where \u03c0\u2208 \u03a0(\u03bc,\u03bd) and pt is their joint law. Therefore pt \u2208 \u03a0(\u03bc,\u03bd).\n(2) Descent in Cost. As a result of the conditional expectation contraction property, the OCD leads to a monotone decay in the cost. More specifically, we have the following result.\nProposition 2.2. Consider (Xt, Yt) to be the solution of OCD (13) with the initial condition (Xo, Yo) ~ \u03c0, from an arbitrary coupling \u03c0\u2208 \u03a0(\u03bc,\u03bd), where \u03bc,\u03bd\u2208Pr(R", "nu)": {}}, {"title": "2.3. Key Features in L2 Monge-Kantorovich", "content": "at some T > 0. The coupling p\u03c4 is unstable in the sense that if the law is perturbed by\n$p_T^{\\epsilon} = (1 - \\epsilon) \\rho_T + \\epsilon \\pi_{\\mu,\\nu}^{opt}$,\nwhere 0 < \u0454 < 1, the solution (Xt, Yt) would not have the measure p\u03c4 for any time later.\n(4) McKean-Vlasov System. The OCD (13) can be equivalently interpreted as a probability flow in the sense of Eq. (5). Due to the absence of Brownian motion, this probability flow is in the form of the Vlasov equation. The latter arises in the mean field limit of interacting particles, e.g. see [33, 49]. By exploiting the projection operator S, the corresponding probability density evolution takes the concise form\n$\\partial_t p_t +\\nabla_x \\cdot (p_t S_{p_t,x}[\\nabla_x c]) + \\nabla_y \\cdot (p_t S_{p_t,y}[\\nabla_y c]) = 0$,\nwhere\n$S_{p_t,x}[\\nabla_x c] = \\nabla_x c(x, y) - E_{(X_t, Y_t)\\sim p_t} [\\nabla_x c(X_t, Y_t) | X_t = x]$ and $S_{p_t,y} [\\nabla_y c] = \\nabla_y c(x, y) - E_{(X_t, Y_t)\\sim p_t} [\\nabla_y c(X_t, Y_t) | Y_t = y]$.\nTheorem 2.4. Consider (Xt, Yt) to be the solution of the ODE system (13) with the initial condition (Xo, Yo) ~ \u3160, from an arbitrary coupling \u03c0\u2208 \u03a0(\u03bc,\u03bd), where \u03bc,\u03bd \u2208 Pr(Rn). Suppose pt is the joint law of (Xt, Yt) with the density pt. Therefore pt is weak solution of the Vlasov-type equation Eq. (20).\nWe expect that the Vlasov equation (20) admits a variational formulation in terms of Otto calculus [35, 3, 57, 9], if appropriate set of couplings is considered (those that can be generated by Tanpt,2\u03a0(\u03bc,\u03bd)). However, we leave this interesting question to a separate work. Instead, we will present a variational formulation of OCD in the probability space for the L2 Monge-Kantorovich cost.\nSo far, we discussed that OCD (13) brings a given joint distribution closer to the solution of the Monge-Kantorovich problem. In other words, the dynamics decreases the cost E[c(Xt, Yt)]. In this section, we present a finer result on the decay of the quadratic cost $c(x, y) = ||x - y||^2$, resulted from OCD, i.e. for the ODE system\n$Xt = Yt - E_{p_t} [Y_t | X_t]$ and $Yt = Xt - E_{p_t}[X_t|Y_t]$.\nIn this scenario, the optimal transport problem is equivalent to maximizing correlation between Xt and Yt, see [52, 54]. Focusing on (22), we show the following results.\n(1) Symmetric Positive Semi-Definite Correlation. Consider $S_n^+$ to be the set of symmetric positive semi-definite matrices\n$S_n^+ := \\{ A \\in \\mathbb{R}^{n\\times n} | A = A^T, A \\ge 0 \\}$.\nLet us define the cross-correlation matrix\n$J_t := E[X_t' Y_t']$\nwith $X'_t := X_t - E[X_t]$ and $Y'_t := Y_t \u2013 E[Y_t]$. We have the following result."}, {"title": "3. SPECIAL EXAMPLES FOR L2-MONGE-KANTOROVICH", "content": "Proposition 2.5. Consider (Xt, Yt) to be the solution of the ODE system (13) with the initial condition (Xo, Yo) ~ \u03bc\u2297 \u03bd, where \u03bc,\u03bd\u2208 Pr(Rn). Therefore\n$J_t \\in S^+$.\nIn other words the L2-OCD (22) ensures that the cross-correlation created between Xt and Yt remains in the space of symmetric positive semi-definite matrices.\n(2) Sharp Descent and Variational Formulation. The L2-OCD (22) gives rise to a sharp decay in the cost E[c(Xt, Yt)]. More precisely, if we restrict the set of velocities to the tangent space $(L^2(\\mu, \\mathbb{R}^n) \\otimes L^2(\\nu, \\mathbb{R}^n))^\\perp$, the OCD gives fastest decay in the cost E[c(Xt, Yt)].\nTheorem 2.6. Consider (Xt, Yt) to be the solution of the ODE system (15) and the initial condition (Xo, Yo) \u2208 \u03c0, where \u03c0\u2208 \u03a0(\u03bc,\u03bd). Let\n$V(p_t) := \\int_{\\mathbb{R}^{2n}} ||x - y|| p_t (dx, dy)$\nbe the L2 transport cost and\n$L_{p_t} (v) := \\frac{d}{dt} V(p_t) + \\frac{1}{2} \\int_{\\mathbb{R}^{2n}} ||v||^2 p_t (dx, dy)$,\nits decay rate penalized by the L2 norm of the velocities. Define optimal velocities\n$v^{opt}_{p_t} := \\arg \\min_{v \\in (L^2(\\mu,\\mathbb{R}^n) \\otimes L^2(\\nu,\\mathbb{R}^n))^\\perp} L_{p_t}(v)$.\nTherefore\nvpt,1(Xt, Yt) = Yt - Ept [YtXt] and vpt,2(Xt, Yt) = Xt - Ept [XtYt].\nThis result can be employed as variational formulation of L2-OCD. The velocities vid admit the variational formulation\n$v_{1,2}^{ocd} \\underset{\\nu \\in (L^2(\\mu,\\mathbb{R}^n) \\otimes L^2(\\nu,\\mathbb{R}^n))^\\perp}{=} \\arg \\min_{\\mathbb{R}^{2n}} \\frac{d}{dt} \\int_{\\mathbb{R}^{2n}} \\vert \\vert x - y \\vert \\vert p_t (dx, dy) + \\int_{\\mathbb{R}^{2n}} ||v|| p_t (dx, dy)$.\nWe present two scenarios for which the solution of OCD can be analyzed with respect to the analytical solution of L2-Monge-Kantorovich problem."}, {"title": "3.1. Linear Maps", "content": "After initializing (Xo, Yo) ~ \u03bc\u2297 v, suppose L2-OCD (22) converges to a stationary solution (Xs, Ys) which is represented by an affine map\n$Y_s = T(X_s) = \\Sigma X_s + m$,\nwith \u03a3\u2208 Rn\u00d7n and m\u2208 Rn. We argue that the map T() is the Monge (optimal) map from \u00b5 to \u03bd. Due to Proposition 2.5, \u03a3\u2208 S, i.e. it has to be symmetric positive semi-definite. Therefore the linear map can be cast as the gradient\n$T(X_s) = \\nabla \\varphi(X_s)$"}, {"title": "3.2. Elliptic Distributions", "content": "of a convex\n$\\varphi(x) := \\frac{1}{2} x^T \\Sigma x + m x$\nIt follows from Brenier's theorem [16, 2, 56] that a map is solution of L2-Monge-Kantorovich problem if (and only if) it is gradient of a convex. Therefore T is the Monge map.\nA special case is when both \u03bcand vare Gaussian measures. Let \u00b5 and v be centered Gaussian measures with covariance matrices \u03a3\u03bc and \u03a3\u03bd. The dynamics of correlation matrix Jt = E[Xt & Yt], following L2-OCD (13), reads\n$\\partial_t J_t = \\Sigma_\\mu + \\Sigma_\\nu - J_t \\Sigma^{-1} J_t - J_t \\Sigma_{\\nu}^{-1} J_t$,\ndue to the identities\n$E_{p_t} [Y_t|X_t] = J_t \\Sigma_{\\mu}^{-1} X_t$ and $E_{p_t} [X_t|Y_t] = J_t \\Sigma_{\\nu}^{-1} Y_t$,\nwhich results from pt being Gaussian, see [23]. The matrix-Riccati equation (35) admits many stationary solutions, since any bijection between \u03bcand vis a stationary solution of (13), as discussed in [23]. However, as we justified in Proposition 2.2, starting with independent samples, i.e. E[XoYo] = 0, Jt remains symmetric positive semi-definite and its trace increases monotonically. This restricts the stationary solution to the one associated with the optimal transport. More precisely, we have\n$X_t = Y_t - J_t \\Sigma_{\\mu}^{-1} X_t$ and $Y_t = X_t - J_t \\Sigma_{\\nu}^{-1} Y_t$\nwith the fixed point\nY_s = J_s \\Sigma_{\\mu}^{-1} X_s and X_s = J_s \\Sigma_{\\nu}^{-1} Y_s$.\nGiven that Js is symmetric positive semi-definite (Proposition 2.2), each of Xs or Ys can be expressed as gradient of a convex function of the other (similar to Eq. (34)). For the one-dimensional case, Eq. (35) takes a simpler form. Let n = 1 and suppose the variances are $\u03c3_{\\mu}^2$ and $\u03c3_{\\nu}^2$. Define the correlation coefficient $k_t := J_t / (\u03c3_{\\mu} \u03c3_{\\nu})$. Therefore, the Riccati equation (35) reduces to\n$\\partial_t k_t = \\frac{(\u03c3_{\\mu} + \u03c3_{\\nu}) (\u03c3_{\\mu} - \u03c3_{\\nu})}{\u03c3_{\\mu} \u03c3_{\\nu}} (1 - k_t^2)$.\nStarting from independent samples, this nonlinear ODE gives a monotone increase of kt from zero to the stationary solution kt \u2192 1 as t \u2192 \u221e, which is consistent with the solution of the optimal transport problem (note that here the Monge map is given by $T(X) = \u03c3_{\\nu} / \u03c3_{\\mu} X$ leading to unity correlation coefficient)."}, {"title": "4. NUMERICAL ALGORITHM THROUGH OPINION DYNAMICS", "content": "Opinion dynamics at its core tries to answer how different agents shape their opinions in contact with each-other [37]. While seemingly unrelated to the Monge-Kantorovich problem, in this section, we leverage analogy between opinion dynamics and OCD to provide a novel, yet simple, numerical algorithm for the latter. The main idea is to first, split the data points into a certain number of"}, {"title": "4.1. Analogy with Opinion Dynamics", "content": "Consider a population of agents indexed by i \u2208 {1,...,N}. Suppose each person i has certain two-dimensional position Pi(t) \u2208 R\u00b2 as their opinion in time t. In the standard form of consensus dynamics, e.g. see [44], these positions relax towards a global consensus via\n$P_i' = \\sum_{i\\neq j} a_{ij} (P_j(t) \u2013 P_i(t))$,\nwhere aij \u2265 0 captures the influence of other agents positions. We can decompose it as aij = $(rij)aij where rij = ||Pi \u2013 Pj||2 is the Euclidean distance between the positions of two persons i and j, and a a constant matrix. Based on a, we can intuitively consider two idealized regimes:\n(1) The positions are completely independent from each-other and a becomes the identity matrix.\n(2) The positions are perfectly tied to each-other and a becomes the exchange matrix J.\nThe first one degenerates the system into independent positions. More interestingly, let us focus on the latter and denote P = [Px, Py]T, therefore the dynamics takes the form\n$P_{x,i}' = \\sum_{i \\neq j} \\phi(r_{ij}) (P_{y,i}(t) - P_{y,j}(t))$ and $P_{y,i}' = \\sum_{i \\neq j} \\phi(r_{ij}) (P_{x,i}(t) \u2013 P_{x,j}(t))$.\nIf we assume $( ) is simply a step function i.e. it is one if r < e and zero otherwise (for \u0454 > 0), we can further simplify the dynamics to\n$P_{x,i}' = \\frac{1}{N_{\\mathcal{I}^X_{i,\\epsilon}}} \\sum_{j \\in \\mathcal{I}^X_{i,\\epsilon}} (P_{y,i}(t) - P_{y,j}(t))$ and $P_{y,i}' = \\frac{1}{N_{\\mathcal{I}^Y_{i,\\epsilon}}} \\sum_{j \\in \\mathcal{I}^Y_{i,\\epsilon}} (P_{x,i}(t) \u2013 P_{x,j}(t))$,\nwhere $I^X_{i,e}$ and $I^Y_{i,e}$ are the set of all agents with $||P_{x,i} - P_{x,j}||^2 < \\epsilon^2$ and $||P_{y,i} - P_{y,j}||^2 < \\epsilon^2$, respectively, with the corresponding number of elements $N_{I^X_{i,e}}$ and $N_{I^Y_{i,e}}$. In the limit of N \u2192 \u221e and \u20ac \u2192 0, it is suggestive to express the above dynamics in the statistical form. Treating Px,i(t) and Py,i(t) as samples of random variables Xt \u2208 H and Yt \u2208 H, respectively, the dynamics takes the form\n$Xt = Yt - E[Yt|Xt]$ and $Yt = Xt \u2013 E[Xt|Yt]$,\nwhich is OCD (13) for L\u00b2-cost. From technical point of view, the discrete version is justified due to the approximation of conditional expectation by a discrete kernel [46]. Through the lens of opinion dynamics, the OCD describes a dynamics which is local in a sense that each agent is only influenced by agents in its vicinity, yet as discussed before, it is closely linked to the global optimization problem (1)."}, {"title": "4.2. Non-parametric Monte-Carlo Algorithm", "content": "The analogy with opinion dynamics hints a numerical recipe for OCD. Conceptually, the parameter e gives rise to formation of clusters in the cloud of (Xt, Yt) points. We consider two numerical schemes:\n(1) OCD-piecewise constant. In each cluster, Xt and Yt relax towards their locally averaged values, i.e. the conditional expectation is estimated to be constant in the cluster."}, {"title": "5. REPRESENTATIVE RESULTS FOR L2-MONGE-KANTOROVICH", "content": "(2) OCD-piecewise linear. In each cluster, the conditional expectation is estimated using linear regression, i.e. the joint distribution of each cluster is estimated by a Gaussian.\nStarting with Np i.i.d. samples Xi,to ~ \u00b5 and Yi,to ~ v, we update the state of each sample according to discretized form of OCD. It is important to note that here we are focusing on an approximate solution of the optimization problem (1) over atom-less distributions \u03bc and \u03bd. An alternative interpretation, where the distributions are assumed to be sum of diracs (assignment problem) is not pursued here (see [62]). Therefore throughout what follows, we assume that there exists an underlying continuous map between the two measure spaces. Three hyper-parameters control the discretization error: number of samples Np, time step size \u2206t, and cluster cut-off e. Once these values are fixed, relying on Euler's scheme (see Runge-Kutta's scheme in Sec.7.2 of Supplementary Information), each sample is updated according to\n$X_i^{n+1} = X_i^n + \\nabla_x c(X_i^n, Y_i^n) \\Delta t - K_X \\Delta t$\nand $Y_i^{n+1} = Y_i^n + \\nabla_y c(X_i^n, Y_i^n) \\Delta t - K_Y \\Delta t$,\nwhere superscript n and n + 1 denote the approximations at tn and tn + \u2206t, respectively. The functionals $K_{X,Y}(.)$ estimate conditional expectations with respect to X and Y, respectively, and they are found depending on the following estimators.\n(1) OCD-piecewise constant. The estimator is constant in each cluster (equivalent to using square kernel in the estimation of the conditional expectation). The expressions for Kx,y(.) are given in Eqs. (76)-(77) in Supplementary Information.\n(2) OCD-piecewise linear. The estimator follows linear regression (accounts for using Gaussian kernel in the estimation of the conditional expectation). In other words here we look for L2 projection of \u2207x,yc onto the span of linear functions [36]. The final expressions are given in Eqs. (85)-(86) in Supplementary Information.\nOur focus remains on basic structural properties of the dynamics along with its computational implications."}, {"title": "6. DISCUSSION", "content": "Conceptually, what makes the OCD approach particularly appealing is that it is at cross-road of different topics:\n(1) The original problem of Monge-Kantorovich optimization, constrained on a set of couplings, is reduced to a dynamics whose evolution is controlled by the conditional expectation. The latter is solution of the regression problem, and thereby, the OCD provides a direct link between Bayesian regression and the optimal transportation.\n(2) Using basic interaction rules, the dynamics gives a particle-type relaxation of independent samples, seeking their optimal coupling. The notion of clustering, which arises from this coupling, resonates with models of opinion dynamics and offers a method for obtaining sparse representations of complex, high-dimensional datasets.\n(3) The OCD framework has potential applications as the foundation for generative models. When combined with supervised learning, the learned maps could be employed to generate new datasets.\n(4) Finally, the dynamics of OCD can be interpreted as a form of projected gradient descent, providing a novel approach through which optimization techniques constrained on a set of distributional coupling can be constructed."}]}