{"title": "A Complete Characterization of Learnability for Stochastic Noisy Bandits", "authors": ["Steve Hanneke", "Kun Wang"], "abstract": "We study the stochastic noisy bandit problem with an unknown reward function f* in a known\nfunction class F. Formally, a model M maps arms \u03c0 to a probability distribution \u039c(\u03c0) of reward.\nA model class M is a collection of models. For each model M, define its mean reward function\nfM(\u03c0) = Er~M(\u03c0)[r]. In the bandit learning problem, we proceed in rounds, pulling one arm \u03c0\neach round and observing a reward sampled from M(\u03c0). With knowledge of M, supposing that\nthe true model M \u2208 M, the objective is to identify an arm \u0175 of near-maximal mean reward fM (\u5143)\nwith high probability in a bounded number of rounds. If this is possible, then the model class is\nsaid to be learnable.\nImportantly, a result of Hanneke and Yang (2023) shows there exist model classes for which\nlearnability is undecidable. However, the model class they consider features deterministic rewards,\nand they raise the question of whether learnability is decidable for classes containing sufficiently\nnoisy models. More formally, for any function class F of mean reward functions, we denote by\nMF the set of all models M such that fM \u2208 F. In other words, MF admits arbitrary zero-mean\nnoise. Hanneke and Yang (2023) ask the question: Can one give a simple complete characterization\nof which function classes F satisfy that MF is learnable?\nFor the first time, we answer this question in the positive by giving a complete characterization\nof learnability for model classes MF. In addition to that, we also describe the full spectrum of pos-\nsible optimal query complexities. Further, we prove adaptivity is sometimes necessary to achieve\nthe optimal query complexity. Last, we revisit an important complexity measure for interactive de-\ncision making, the Decision-Estimation-Coefficient (Foster et al., 2021, 2023), and propose a new\nvariant of the DEC which also characterizes learnability in this setting.\nKeywords: Bandits, Structured Bandits, Learning Theory, Query Complexity", "sections": [{"title": "1. Introduction", "content": "The multi-armed bandit problem (Robbins, 1952; Auer et al., 2002a,b; Lattimore and Szepesv\u00e1ri,\n2020) is a problem in which a learner performs an action and gains a reward round by round,\nwith the intention of identifying actions with the highest rewards. The multi-armed bandit problem\noccurs in many contexts. For instance, imagine one situation where a restaurant customer wants to\nfigure out which item on the menu is the most delicious. By strategically choosing his order each\ntime he visits the restaurant, he can eventually identify which item is the most delicious. Many\nother examples in practice include recommendation systems, clinical trials, and financial portfolio\ndesign (Yue and Joachims, 2009; Combes et al., 2015; Li et al., 2016, 2010; Slivkins, 2011). The"}, {"title": "2. Characterization of Learnability", "content": "In this section, we introduce our main learnability results. Theorem 2 and Theorem 3 give suffi-\ncient and necessary conditions of learnability and corresponding query complexities, respectively.\nCombining Theorem 2 and Theorem 3 gives our characterization of learnability (Theorem 1).\nTheorem 2 (Upper bound) $\\Upsilon_{F,\\alpha} > 0 \\forall \\alpha \\in (0,1)$ is a sufficient condition for learnability of F\nwith arbitrary noise. In addition, $QC(F, \\alpha, \\delta) = O (\\frac{1}{\\Upsilon_{F,\\alpha/2}^2} log \\frac{1}{\\delta} log(\\frac{1}{\\Upsilon_{F,\\alpha/2}} log \\frac{1}{\\delta}))$"}, {"title": "3. Optimal Query Complexity of Learnability", "content": "Further in this section, we explore some properties of optimal query complexity. Theorem 4 shows\nevery query complexity between $(\\log \\frac{1}{\\Upsilon_{F,\\alpha}})$ and $(\\frac{1}{\\Upsilon_{F,\\alpha}})$ is achievable. Theorem 5 shows adap-\ntivity is sometimes necessary for achieving optimal query complexity.\nTheorem 4 $\\forall \\alpha, \\delta\\in (0, 1), \\forall \\gamma \\in {\\frac{1}{2^i} : i \\in N}, \\forall f(\\gamma) \\in [log \\frac{1}{\\gamma}, \\frac{1}{\\gamma}]$, there exists a function class F\nsuch that $\\Upsilon_{F,\\alpha} = \\gamma$ and $QC(F, \\alpha, \\delta) = \\tilde{O}(f(\\Upsilon_{F,\\alpha}))$."}, {"title": "4. Extension to Unbounded and Gaussian Noise", "content": "In this section, we extend our existing results to some general and well-known scenarios. First,\nconsider the model M such that for each arm \u03c0, its reward r(\u03c0) sampled from M(\u03c0) is unbounded\nbut with variance \u03c3\u00b2. Let M\u03c32F denote a set of all such models such that f \u2208 F. With the\nknowledge of F, suppose the true model M\u2208 M\u03c32F, if there exists an algorithm that is able to\nidentify an arm such that fM(\u03c0) \u2265 sup\u03c0* fM(\u03c0*) \u2212 \u03b1 with probability at least 1 \u2013 \u03b4 in a bounded\nnumber of rounds \u2200\u03b1, \u03b4 \u2208 (0, 1) and \u2200M \u2208 M\u03c32F, then we say function class F is learnable\nwith unbounded noise. Theorem 6 shows Algorithm 2 can identify a near-optimal arm in a finite\nnumber of rounds for M\u03c32F. Briefly speaking, Algorithm 2 changes the direct mean estimation\nto the median of means method, which provides a better accuracy guarantee when the reward is\nunbounded."}, {"title": "5. The Variant of Decision-Estimation-Coefficient", "content": "In this section, we give a new variant of Decision-Estimation-Coefficient that can also characterize\nthe learnability of stochastic noisy bandits. Given \u03b1 \u2208 (0, 1), let\n$dec_{\\epsilon, \\alpha}(F, f) = \\inf_{P,q \\in \\Delta(\\Pi)} \\sup_{f \\in F}  \\sup_{\\pi^*} Pr_{\\pi \\sim p}( \\sup_{\\pi^*} f(\\pi^*) - f(\\pi) > \\alpha  | E_{\\pi \\sim q}[(f(\\pi) - \\bar{f}(\\pi))^2] < \\epsilon^2 )$\nFurther, define\n$dec_{\\epsilon, \\alpha}(F) = \\sup_{f \\in co(F)} dec(F, f)$\nDefinition 9 (Online regression oracle for F) At each time t \u2208 [T], an online regression oracle\nReg for F returns, given\n$H^{t-1} = (\\pi^1, r_1), ..., (\\pi^{t-1}, r_{t-1})$\nwith rt ~ M\u2217(\u03c0t) and \u03c0t ~ \u03c1t, an estimator ft \u2208 co(F) such that whenever f\u2217 \u2208 F (Equivalently,\nM\u2217 \u2208 MF),\n$EST(T) := \\sum_{t=1}^{T} E_{\\pi \\sim \\rho^t}[(f^* (\\pi^*) \u2013 f^t (\\pi^t))^2] \\leq EST(T, \\delta) $\nwith probability at least 1 \u2013 \u03b4, where EST(T, \u03b4) is a known upper bound.\nNext, we will describe another characterization of learnability for stochastic bandits with ar-\nbitrary noise based on our variant of the Decision Estimation Coefficient. Let T \u2208 N, define\n$EST := EST(\\frac{2T}{\\delta}, \\frac{T}{\\lfloor log 4/\\delta \\rfloor+1})$ and set $\\epsilon(T) := 8 \\sqrt{\\frac{1}{\\lfloor log 4/\\delta \\rfloor+1} EST}$. Then we have:\nTheorem 10 F is learnable with arbitrary noise if and only if there exists T \u2208 N, $dec_{\\epsilon(T), \\alpha}(F) <\n1  \\forall \\alpha \\in (0, 1)$.\nTheorem 11 (Upper Bound)\n$\\exists T \\in N, \\forall \\alpha \\in (0, 1), dec_{\\epsilon(T), \\alpha}(F) < 1$\nis a sufficient condition for learnability of function class F with arbitrary noise. In addition,\n$QC(F, \\alpha, \\delta) = O(T + \\frac{1}{(1- dec_{\\epsilon(T)/2, \\alpha/2}(F))^2} log \\frac{8}{\\delta} log(\\frac{1}{(1- dec_{\\epsilon(T)/2, \\alpha/2}(F))} log \\frac{8}{\\delta}))$"}]}