{"title": "Is Contrasting All You Need? Contrastive Learning for the Detection and Attribution of AI-generated Text", "authors": ["Lucio La Cava", "Davide Costa", "Andrea Tagarelli"], "abstract": "The significant progress in the development of Large Language Models has contributed to blurring the distinction between human and AI-generated text. The increasing pervasiveness of AI-generated text and the difficulty in detecting it poses new challenges for our society. In this paper, we tackle the problem of detecting and attributing AI-generated text by proposing WhosAI, a triplet-network contrastive learning framework designed to predict whether a given input text has been generated by humans or AI and to unveil the authorship of the text. Unlike most existing approaches, our proposed framework is conceived to learn semantic similarity representations from multiple generators at once, thus equally handling both detection and attribution tasks. Furthermore, WhosAI is model-agnostic and scalable to the release of new AI text-generation models by incorporating their generated instances into the embedding space learned by our framework. Experimental results on the TuringBench benchmark of 200K news articles show that our proposed framework achieves outstanding results in both the Turing Test and Authorship Attribution tasks, outperforming all the methods listed in the Turing-Bench benchmark leaderboards.", "sections": [{"title": "Introduction", "content": "In recent years, advancements in artificial intelligence (AI) have revolutionized various domains, including natural language processing (NLP), leading to the emergence of sophisticated text generation models. These AI-powered systems are capable of generating human-like text, ranging from simple sentences to complex narratives, with remarkable fluency and coherence [20]. Such advancements have attracted attention from the research community as well as industry and society at large, offering opportunities for enhancing communication, creativity, and productivity [7].\nHowever, a pressing challenge comes alongside these advancements: distinguishing between AI-generated text and human-written text. As AI text generation models continue to improve in sophistication and realism, the ability to differentiate between AI-generated and human-generated content becomes increasingly crucial [37]. The implications of failing to discern between these two sources of text are profound and multifaceted, spanning various aspects of society, such as the preservation of truth, authenticity, and trustworthiness in online communication. With the proliferation of AI-generated content on social media, news platforms, and other digital channels, there is a growing risk of misinformation, manipulation, and deception [51, 9]. Without effective means of distinguishing between AI-generated and human-generated text, users may unwittingly consume and propagate false or misleading information, undermining the integrity of public discourse and decision-making processes.\nFurthermore, the rise of AI text generation brings ethical and societal concerns about authorship, intellectual property rights, and accountability. As AI systems become increasingly proficient at mimicking human language and creativity [8], questions arise regarding the ownership and attribution of AI-generated content. Without clear guidelines and mechanisms for identifying the origin of text, issues might also arise about plagiarism, copyright infringement, and legal responsibility, posing challenges to established norms in intellectual property law and digital content creation.2\nRelated work. The remarkable boost in human-like text generation performances achieved by Large Language Models (LLMs) in recent years has determined a rising challenge in detecting whether and to what extent texts have been generated by humans or machines [21, 49, 39]. In this context, the \"watermarking\" paradigm rapidly gained attention [25, 53, 28, 50], as it allows embedding specific signals into generated texts that remain invisible to humans but are algorithmically detectable. Statistical learning methods also offer advanced solutions for detecting the authorship of texts. These include probabilistic models [31, 1, 47, 14], log rank information [38], perplexity [44], discourse motifs [24], and other statistical approaches [16, 40, 45]\nMore recently, we have witnessed the emergence of deep learning to detect or attribute AI-generated content, which stands as a promising body of research. Researchers have been exploiting LLMs to detect generated text [18, 46], using ChatGPT itself as a detector [2], or combining LLMs with topological aspects [43].\nA very recent trend involves leveraging contrastive learning to handle textual information. Indeed, despite its origins in the computer vision domain, contrastive representation learning has been proven particularly effective in NLP contexts to improve research on semantic similarity related problems, such as text classification [33, 10], spotting hate-speech [23], unveiling intents [55], and eventually detecting AI-generated text through domain adaptation [3] or domain adversarial training [4].\nDespite the advancements in research on detection of AI text generation, each of the above mentioned approaches faces significant challenges. Watermarking approaches are conditioned by the con-\n2 Can one really spot if the text in the Introduction was written by a human or an AI text-generation model?"}, {"title": "Problem Statement", "content": "We are given a set of discrete labels (categories) \\(C = \\{C_k\\}_{k=1}^M\\), with \\(M \\geq 2\\), and a collection of text data objects \\(D = \\{D_i\\}_{i=1}^N\\), such that each text object in D is assigned to one of the categories in C. The semantics of such categories refer to information on the originator of a written text, which is assumed to be either a human or a machine, i.e., an AI model for text generation; hence, in this setting, the authorships of the texts in D are a priori known.\nThe problem we are interested in is generally to learn a model, supervisedly trained on (D, C), that can predict the category from C for any given text data whose authorship is unknown. Specifically, we address two supervised learning problems: (i) A binary classification task, known as Turing Test (TT), which requires to predict whether the author of a text is a human or an AI text-generator, and (ii) A multi-class classification task, known as Authorship Attribution (AA), which requires to predict exactly who is the author of a text, choosing between a human or an AI text-generator.\nIn line with the related literature, our setting does not differentiate between human authors in either task (i.e., 'human' always corresponds to one class in C), whereas the identity of a particular AI text-generator must be unveiled for the Authorship Attribution task only, therefore M-1 categories are available that correspond to either any AI text-generator (for Turing Test) or a specific AI text-generator (for Authorship Attribution).\nIt is worth emphasizing that these tasks, particularly the Authorship Attribution, pose in principle two challenges:\n\u2022 First, the available AI text-generator categories might not necessarily be regarded as classes of document representations that unlikely share their linguistic feature subspaces; roughly speaking, two texts generated by different AI models, or even the same model with different parametrization, could be hardly distinguishable form each other. This particularly holds in our setting since the AI text generation is assumed to be open-ended.\n\u2022 Second, and more importantly, it is supposed that the number of AI text-generators will keep growing, however a classification model trained to recognize the authorship of a text would have to be retrained every time a new AI text-generator is added to the document database.\nThe above challenges can be faced if the problem under study is switched to a similarity learning problem as a core component for the ultimate goal of binary/multi-class prediction."}, {"title": "Background", "content": "Transformer-based Pre-trained Language Models (PLMs) are the well-established NLP tools to build deeply contextualized text-representation learning models. Given a text data \\(D_i \\in D\\), a token sequence \\(T_i = [T_{i,1},..., T_{i,|T_i|}]\\) is produced as initial representation of \\(D_i\\) through a tokenization process typically associated with a PLM. Each token sequence is deeply contextualized by mapping it onto a dense, relatively low dimensional space of size f, based on the PLM. The resulting output is the token embeddings of \\(D_i\\), denoted as \\(\\text{PLM}(T_i) \\in R^{f \\times |T_i|}\\). Eventually, a pooling function pooling(\u00b7) is applied to the token embeddings of each object \\(D_i\\) to yield a single embedding vector \\(h_i\\) of size f:\n\\[h_i = \\text{pooling}(\\text{PLM}(T_i)) \\in R^f.\\]\nTypically, this pooled output is an average embedding over all token embeddings of a data object. The embeddings \\(h_i\\) are commonly referred to as sentence embeddings.\nSimilarity Learning. The deeply contextualized representations produced by a PLM lend themselves particularly suited to enable semantic comparisons between the input text objects. In this respect, we want to explicitly model and leverage the similarity space induced from the sentence embeddings. Similarity learning aims to train a model to distinguish between similar and dissimilar pairs of objects. More specifically, if we consider objects whose relative similarity follows a predefined order \u2013 i.e., for any triplet of objects, the first object is assumed to be more similar to the second object than to the third object - the goal becomes to learn a contrastive loss function, so that it favors small distances between pairs of objects labeled as similar, and large distances for pairs labeled as dissimilar. This is"}, {"title": "The WhosAl Framework", "content": "Overview. We propose WhosAl, a deep learning framework for the detection and attribution of open-ended texts generated by AI models vs. human-written texts. Figure 1 shows a schematic illustration of the main components and data flows of WhosAl.\nWhosAl is conceived to be trained on text data with associated labels expressing authorship as either human or an AI text-generation model. The framework is comprised of three key elements: (i) a PLM, which is charge of learning deeply contextualized representations (embeddings) of the text data, in an unsupervised fashion, (ii) a Triplet Network architecture, which is designed to perform contrastive learning to induce a similarity space of the PLM embeddings, and (iii) a nearest centroid classification model, which is in charge of predicting the authorship category for any query text.\nDuring the training phase, WhosAl builds a deep semantic representation space whereby different regions correspond to features of human-written texts as well as distinct AI text-generators. The contrastive learning strategy allows for capturing the underlying similarity structure and relations within the data objects, such that the deeply contextualized embeddings produced by a PLM encoder will be grouped together when they correspond to the same author and will be kept separated when they correspond to different authors. Moreover, as a byproduct, the similarity learned space facilitates the learning of the decision boundary for our classification objective of determining the class of previously unseen texts; in this setting, our choice of a nearest centroid classifier turns out to be a highly efficient yet effective way to perform authorship prediction.\nWhosAl is designed to be versatile and modular. Versatility mainly refers to the possibility of choosing alternative PLMs as core component of the Triplet Network, variants of the Triplet Network architecture, and alternative (instance-based) classification models. Moreover, WhosAl is modular in that enhanced methods are considered to improve specific aspects of the framework. In particular, these enhancements include (i) improving the efficiency and generalization capabilities of the contrastive learning component, (ii) refining the separation between classes corresponding to different text-creators in the learned space, and (iii) enhancing the robustness of the framework by corrupting the input textual data.\nTraining. Our training process starts with mining triplets \\((D^{(a)}, D^{(p)}, D^{(n)})\\) of text data objects from D to be fed into our triplet network. Such triplets are formed in such a way that, for a given anchor \\(D^{(a)}\\), \\(D^{(p)}\\) and \\(D^{(n)}\\) are selected as positive and negative sample, respectively, i.e., such that \\(c(a) = c(p)\\) and \\(c(a) \\neq c(n)\\), where symbols c() are here used to denote the category associated with an anchor, positive or negative object.\nThe embeddings \\(h^{(a)}, h^{(p)}, h^{(n)}\\) of the anchor, positive and negative objects, respectively, are next computed according to Eq. 1. It should be noted that the text annotations, i.e., their associated categories, are not required when computing the embeddings, since the PLM is an unsupervised learner.\nGiven a triplet, the Triplet Network computes the distance between the embedding of the anchor object and the embedding of the positive object (positive pair), and the distance between the embedding of the anchor object and the embedding of the negative object (negative pair). The triplet loss minimizes the distance between an anchor and a positive, both having the same category, and maximizes the distance between the anchor and a negative of a different category:\n\\[\\mathcal{L} = \\sum_{(D^{(a)}, D^{(p)}, D^{(n)})} \\max(d(h^{(a)}, h^{(p)})-d(h^{(a)}, h^{(n)})+\\lambda,0)\\]\nwhere d(, ) is a distance function and \\(\\lambda \\in \\mathbb{R}^+\\) is a margin between positive and negative pairs. This loss defines the triplet constraint as the requirement that the distance of negative pairs should be larger than the distance of positive pairs.\nInference. At inference time, WhosAl exploits an off-line step that consists in precomputing the centroids in D for each category \\(c_k \\in C\\), defined as \\(c_k = (1/|D_k|) \\sum_{D_i\\in D_k} h_i\\), where \\(D_k\\) denotes the subset of D containing data objects of category \\(c_k\\).\nGiven a previously unseen data object D, WhosAl computes its embedding h (Eq. 1), which is then compared to each of the centroids in such a way that D is assigned to the category \\(c_{k^*}\\) that corresponds to the least distant centroid:\n\\[k^* = \\arg \\min_{k=1..M} d(h, c_k).\\]"}, {"title": "Optimizations", "content": "We discuss here a set optimization techniques as enhancements of key components in WhosAl, namely improved triplet mining, dynamic margin scheduling, and data corruption."}, {"title": "Experimental Methodology", "content": "We used the publicly available benchmark dataset TuringBench [42, 41], which contains 200K news articles, where 10K are human-written and the other ones are machine-generated news articles equally distributed over 19 different AI text-generation models. From the human-written articles, originally collected from sources like CNN and with typical length of 200-400 words, the titles were used to prompt the 19 AI text-generators to generate 10K articles each. Table 1 summarizes the main characteristics of the dataset, providing details for the various subsets of data associated with the human category and each of the AI text-generator categories. It should be noted that TuringBench comes with a pre-defined split into train, validation and test sets. We will follow this setting, so as to fully compare with previous and future evaluation studies on TuringBench."}, {"title": "Assessment Criteria and Model Settings", "content": "To validate the performance of WhosAl in detecting and attributing AI-generated text, we resort to standard statistics based on the confusion matrices derived from testing WhosAl predictions w.r.t. the"}, {"title": "Turing Test", "content": "We start with evaluating WhosAl on the binary classification task, i.e., TT, aimed at recognizing whether a given piece of text originates from a human or any AI text-generator. As reported in Figure 3, the official TuringBench leaderboard presents the F\u2081-scores for the TT under a One-vs-One approach, whereby one side of the comparison denotes \u201chuman\u201d and the other one corresponds to each of the available AI-generators in TuringBench. It can be noticed that some generators are more easily detectable than others, resulting in substantial disparities in terms of average weighted F\u2081-scores.\nBy contrast, WhosAl is able to learn a deep semantic space for the whole set of generators at once. As a major result, WhosAl achieves an impressive F1-score of 0.999 on the whole TT test set supplied by the TuringBench benchmark, setting a new best performance on the Turing Test. Our remarkable F\u2081-score is further corroborated by a qualitative analysis based on the visualization provided in Figure 4:5 while at the beginning of the training the semantic representation directly induced by the PLM does not adequate separate the human and"}, {"title": "Authorship Attribution", "content": "We discuss our evaluation of WhosAl on the Author Attribution (AA) task, aimed at deciding the authorship of a text, being a human or one of the AI text-generators in TuringBench.\nOur first remarkable finding derives from a comparison between WhosAl results against those reported on the TuringBench leaderboard for the AA task, whose top-5 best-performing models are shown in Table 2. ROBERTa [29] with a multi-class classification setting turns out to be the best model in the leaderboard for the AA task, with a F1 score of 0.811, followed by other BERT-based approaches, as well as the official OpenAI detector and machine learning-based models. The winner method from the leaderboard is however outperformed by WhosAl, which achieves a striking average weighted F\u2081 score, precision and recall of 0.990, thus demonstrating almost perfect capabilities of authorship prediction.\nTable 3 offers insights into the prediction performance of WhosAl w.r.t. each of the generator categories corresponding to the largest-size versions of the AI models. Results show extremely robustness of WhosAl, as it achieves F\u2081 score at least 0.960, and above 0.99 in 7 out of 10 cases. It should also be noticed that precision and recall are always comparable or very close to each other, thus indicating an equal capability of avoiding both types of statistical errors.\nAs previously found for the Turing Test task, the striking F\u2081 scores achieved by WhosAl couple with an evidence of highest cohesiveness and separation of the subspaces associated with the various text authorships, as visually shown in Fig. 5 (left); quantitatively, this corresponds to an average pairwise similarity between embeddings of objects sharing the same category, resp. belonging to different categories, of 0.938, resp. -0.012 (cf. Table 5).\nIt is worth noting that the outstanding performance by WhosAl in the AA task is not paired by a state-of-the-art sentence-embedding method for semantic-similarity-related tasks like SBERT [36], based on a Siamese network using BERT at its core: indeed, as shown in Fig. 5 (right), the intra-class cohesiveness and inter-class separation of the semantic space learned by SBERT are clearly worse than those achieved by WhosAl."}, {"title": "Sensitivity Analysis", "content": "Turing Test. Table 4 reports the results achieved by WhosAl on the TT task by varying the framework settings according to the various optimizations discussed in Section 4.1.\nAt first glance, we notice that WhosAl can solve the TT task almost perfectly - with P, R, F\u2081 always above 0.996 \u2013 regardless of specific optimizations. This remarkable finding, coupled with the visual evidence of the semantic space representation displayed in Figure 4, indicate that WhosAl excels in distinguishing between human authors and AI text-generators, even when equipped with the simplest configuration.\nWhile the classification performance criteria have indeed only slight fluctuations by varying the framework settings, different behaviors of WhosAl appear to be more evident in terms of compactness (intra) and, especially, separation (inter), with the former consistently above 0.846 and the latter that can vary from 0.35 to -0.81. In particular, applying data corruption techniques can affect the distance-based criteria: in fact, by using either token deletion and span cropping, we notice a worse (i.e., higher) similarity between embeddings of objects pertaining to different categories, whereas the similarity between embeddings of objects from the same category remains coherent. This suggests that corrupting the data in input to the TT predictor might impact particularly on some of the tokens that are discriminative of the text-generators, being human or AI models.\nMore importantly for our TT evaluation, we assessed the effect on the WhosAl performance due to the presence of texts that were generated by the same AI architecture yet with different parameter sizes (cf. Table 1). To this aim, we focused on comparing the performance of WhosAl when keeping all instances generated by the same AI text-generation architecture, and only the subsets corresponding to either the largest model or the smallest model of that AI architecture available in TuringBench.\nAs reported in Table 4, the variation of the model subset mainly impacts on the separation between embeddings of objects pertaining to different classes: keeping all instances from differently sized models from the same architecture can bring additional discriminative information helping WhosAl better separate the human-generated texts from the ones generated by all AI models. Conversely, maintaining only either the largest-model or smallest-model subsets might lead to slightly improved intra-class cohesiveness, hinting at a reduced noise affecting characterizing tokens.\nAuthorship Attribution. Analogously to the previous analysis, Table 5 summarizes the results achieved by WhosAl on the AA task based on different settings. We notice that WhosAl obtains an F1 score above 0.980, also with remarkable distance-based scores, in 6 out of 9 configurations, which correspond to testing on texts from a particular model-size variant of an AI text generator, rather than testing on all texts from the different variants of a model.\nThis prompted us to investigate the similarity between the centroids of the subsets corresponding to the various categories (i.e., model instances), as reported in Fig. 6 (left). Notably, looking at the diagonal blocks in the heatmap, WhosAl consistently learns identical centroids (i.e., cosine similarity equal to 1) for the different instances of the same AI generation architecture, regardless of the parameter size. While this suggests that a single instance of a given architecture may be enough in a contrastive setting to characterize a whole family of AI generators, it introduces lots of noise when distinguishing between two or more instances of the same architecture.\nIf we focus on the largest-model variants of the AI generators, which should make our AA task more challenging as it is supposed that more parameters enable the model to capture more knowledge providing it with better generation capabilities, we still find in Fig. 6 (right) low values of inter-class similarity. Analogous results (not shown) are achieved for the smallest model instances, which may be preferable in resource-constrained scenarios.\nFurthermore, considering the impact of the different optimizations, the triplet mining and the dynamic margin scheduling lead to performance improvements, while the data corruption methods appear to worsen the separation of the learned embedding subspaces by affecting tokens crucial for discriminating text-generators."}, {"title": "Conclusions and Future Work", "content": "We tackled the challenge of detecting and attributing AI-generated text through WhosAl, a novel PLM-based framework that leverages contrastive learning to induce a semantic similarity space texts written by humans or AI text-generation models. This similarity space is efficiently exploited at inference time by means of a nearest centroid classifier to predict the authorship of unlabeled texts. Extensive experimentation on the well-known TuringBench dataset has revealed state-of-the-art performances of WhosAl on both TT and AA tasks. Furthermore, WhosAl comes with several key advantages: (i) it can be applied straightforwardly without altering texts or accessing models' internals, (ii) it can be adapted to a number of AI text-generators without needing model-specific adjustments, and (iii) it is model-agnostic and scalable for easy integration of novel AI text-generators. Remarkably, such empirical evidence of outstanding performance of WhosAl holds despite our choice of PLM in the experimental evaluation refers to the baseline BERT model.\nThere are important directions to explore. Particularly, we will evaluate WhosAl on other types of written texts than those available in TuringBench. We aim to compare WhosAl with advanced yet commercially licensed AI detection tools (e.g., GPTZero). Also, we will investigate explainability aspects of WhosAl in order to unveil which features are determinant to characterize and which to discriminate text originators.\nRemarks on the carbon footprint of WhosAl. As a supplementary analysis, we investigated the environmental impact of WhosAl. Based on our selected reference PLM, which has 109.48M parameters, we estimate an inference cost of 290.17 GFLOPS for a single-element batch with a sequence length of 512, and a training cost of 835.8 PFLOPS assuming 32 batch size, 512 sequence length, and 30K training steps. With an average training time for all WhosAl configurations of ~8 hours on a 350W Nvidia GeForce RTX 3090 GPU, we estimate an energy consumption of 2.8 kWh per training run. With an average carbon efficiency factor of 0.432 kg/kWh, a single training run is associated with 1.21 kg of CO2 emissions, which extends to 50.4 kWh of consumed energy and 21.78 kg of CO2 equivalent emissions for running all of our experiments.6"}]}