{"title": "AgentInstruct:\nToward Generative Teaching with Agentic\nFlows", "authors": ["Arindam Mitra", "Luciano Del Corro", "Guoqing Zheng", "Shweti Mahajan", "Dany Rouhana", "Andres Codas", "Yadong Lu", "Wei-ge Chen", "Olga Vrousgos", "Corby Rosset", "Fillipe Silva", "Hamed Khanpour", "Yash Lara", "Ahmed Awadallah"], "abstract": "Synthetic data is becoming increasingly important for accelerating the development of\nlanguage models, both large and small. Despite several successful use cases, researchers\nalso raised concerns around model collapse and drawbacks of imitating other models. This\ndiscrepancy can be attributed to the fact that synthetic data varies in quality and diversity.\nEffective use of synthetic data usually requires significant human effort in curating the data.\nWe focus on using synthetic data for post-training, specifically creating data by powerful\nmodels to teach a new skill or behavior to another model, we refer to this setting as Generative\nTeaching. We introduce AgentInstruct, an extensible agentic framework for automatically\ncreating large amounts of diverse and high-quality synthetic data. AgentInstruct can create\nboth the prompts and responses, using only raw data sources like text documents and code\nfiles as seeds. We demonstrate the utility of AgentInstruct by creating a post training dataset\nof 25M pairs to teach language models different skills, such as text editing, creative writing,\ntool usage, coding, reading comprehension, etc. The dataset can be used for instruction\ntuning of any base model. We post-train Mistral-7b with the data. When comparing\nthe resulting model (Orca-3) to Mistral-7b-Instruct (which uses the same base model), we\nobserve significant improvements across many benchmarks. For example, 40% improvement\non AGIEval, 19% improvement on MMLU, 54% improvement on GSM8K, 38% improvement\non BBH and 45% improvement on AlpacaEval. Additionally, it consistently outperforms\nother models such as LLAMA-8B-instruct and GPT-3.5-turbo.", "sections": [{"title": "Introduction", "content": "Synthetic data accelerated the development of LLMS: The rise of synthetic data in\nthe training of Large Language Models (LLMs) has been a significant development of the\nlast year. Synthetic data was used to significantly accelerate the progress of model training\n(especially SLMs) in all stages of training from pre-training (e.g., [1]), to instruction-tuning\n(e.g., [21, 36]) and RLHF(e.g., [12, 28]).\nGenerating high quality synthetic data is hard: On the other hand, research has also\nshown that pre-training models on synthetic data generated by other models can lead to\nmodel collapse [29], leading to models gradually degenerating as a result. Similar arguments\nhave been made against using synthetic data for pos-training, which could amount to an\nimitation process that could teach the trained model to pick only stylistic characteristics\nand not real capabilities [8]. This discrepancy could be explained by the observation that\ncreating high-quality and diverse synthetic data is hard [17]. Successful use of synthetic data\ninvolved significant human effort in curating and filtering the data to ensure high quality. If\nwe focus on post-training synthetic data, we will see the most widely used approach includes\nstarting with a set of prompts and using a powerful model such as GPT-4 [22] to generate\nresponses to these prompts [24] or of an expanded set of the prompts [36]. This recipe\nwas further improved by eliciting explanations or step-by-step instructions from the teacher\nmodel [20] or using more complex prompting techniques to elicit higher quality answers [18].\nSynthetic data meets Agents: Another major development we witnessed last year is the\nrise of Agentic (especially multiagent) workflows [33, 13]. Agentic workflows can generate\nhigh quality data, that surpasses the capabilities of the underlying LLMs, by using flows\nwith reflection and iteration, where agents can look back at solutions, generate critiques and\nimprove solutions. They can also use tools (e.g. search apis, calculator, code interpreters)\naddressing limitations of LLMs. Multi-agent workflows bring in additional benefits such\nas simulating scenarios where we can generate both new prompts and the corresponding\nresponses. They also enable automation of the data generation workflows reducing or\neliminating need for human intervention on some tasks.\nGenerative Teaching & Orca AgentInstruct: Generating synthetic data for post-\ntraining often relies on an existing prompt set that is used as is or used as seeds for\ngenerating more instructions. In this work, we generalize the problem settings to a broader\nobjective of generating abundant amounts of diverse, challenging and high-quality data to\nteach a particular skill to an AI model, we refer to this setting as Generative Teaching.\nAgentInstruct is an agentic solution for Generative Teaching. AgentInstruct focuses on\ncreating demonstration and feedback data and requires only raw documents as input. When\ngeneric data is used as seeds, AgentInstruct can be used to teach an LLM a general capability\n(e.g. Math, Reasoning, RAG, etc.). Domain specific data (e.g. gaming, finance) can also be\nused as seeds to improve the model in a certain specialization. AgentInstruct can create:\n1. High-quality data: using powerful models like GPT-4, coupled with tools like search\nand code interpreters.\n2. Diverse data: AgentInstruct generates both prompts and responses. It uses a large\nnumber of agents (equipped with powerful LLMs, tools and reflection flows) and a\ntaxonomy (of over 100 subcategories) to create diverse and high quality prompts\nand responses,\n3. Large quantities of data: AgentInstruct can run autonomously and can apply flows\nfor verification and data filtering. It does not require seed prompts and uses raw\ndocuments for seeding.\nUsing raw data (unstructured text documents or source code) as seeds has two benefits.\nFirst, this data is available in abundance enabling the use of AgentInstruct to create large\namounts of diverse data. Additionally, using raw data as seeds, and hence, avoiding using\nexisting prompts, as is or after paraphrasing, can promote learning more general capabilities\nas opposed to benchmark-specific ones.\nWe demonstrate the utility of AgentInstruct by creating a comprehensive synthetic post-\ntraining dataset of 25 million prompt and response pairs. The dataset covers a wide array"}, {"title": "Generative Teaching: AgentInstruct", "content": "Creating synthetic datasets for supervised fine-tuning and instruction-tuning has seen\nsignificant progress over the last year. The quality of these datasets has been steadily\nimproving. High quality can be achieved by using powerful frontier models (or agenetic flows\nbased on these models) to generate responses. However, when creating synthetic data, in\naddition to quality, we also need to consider several other fundamental questions:\n1. How can we create a vast amount of data?\n2. How can we ensure that the generated data is diverse?\n3. How can we generate complex or nuanced data points?\nIn the AgentInstruct methodology, we outline a structured approach to tackle these challenges\nas follows:\nWe use agentic flows to automate the generation process and leverage raw articles as seeds to\nfoster diversity and ensure that problems generated in different iterations (line 2 in Figure 1)\nare distinct and of broad coverage. This enables us to create data at scale (benefiting from\nautomation of agentic flows), with high diversity (based on the broad and diverse seeds) and\nof varying complexity (benefiting from the iterative and refinement patterns supported by\nagentic flows). AgentInstruct defines three different flows:\nContent Transformation Flow converts the raw seed into an intermediate representation\nthat simplifies the creation of instructions tailored to specific objectives. It comprises of"}, {"title": "AgentInstruct Flow for Reading Comprehension", "content": "Reading comprehension is a critical skill involving processing and understanding text, which\nis necessary for learning and encompasses decoding, fluency, and vocabulary knowledge.\nReading comprehension questions range from asking for explicit information (literal com-\nprehension) to requiring inferences, understanding vocabulary in context, analyzing text\nstructure and argumentation, critically evaluating the content, and synthesizing informa-\ntion from different parts of or multiple texts. Reading comprehension is a very important\ncapability and can enable scenarios like question answering, search, grounded reasoning, etc.\nContent Transformation Flow Web crawls encompass an extensive collection of human-\ngenerated text, which holds potential for generating reading comprehension materials.\nHowever, these sources are not inherently structured to facilitate the teaching of read-\ning comprehension skills. Consequently, they do not support the consistent generation of\ndiverse question types required for comprehensive reading comprehension evaluation. For\ninstance, the LSAT Logical Reasoning test features specialized question categories, including\nassumption, strengthening/weakening, flaw, and inference questions. Crafting such questions\nnecessitates passages with a particular stylistic and logical framework. The objective of\nContent Transformation Flow is to transform arbitrary articles into well-crafted pieces that\nare conducive to the formulation of a wide array of reading comprehension question types.\nOur current flow for Reading Comprehension encompasses a suite of nine content transfor-\nmation agents for generating argument passages, debates and conversations, long passages,\nmeeting transcripts, poems, satarical content, etc. Detailed description is provided in Ap-\npendix A. Given a seed article, the flow will randomly pick one of the Content Transformation\nAgents to assess the seed article and attempt to generate the text passages. The following\nprovides an example for the Argument Passage Generator."}, {"title": "EXAMPLE: Content Transformation Flow", "content": "Random Seed\nUric acid is a substance produced naturally by the breakdown of purine (a type of dietary\nprotein). When it is in excess in the body, crystals composed of these substances are formed.\nThese crystals are deposited in various parts of the body, mainly in the joints and kidneys,\ncausing pain and other aggravations. The lack or excess of uric acid in the body is caused by\nsome diseases (such as leukemia, obesity, kidney diseases, and anemia) and factors related\nto lifestyle (consumption of alcohol and processed foods, for example).\nContents\n\u2022\n\u2022\nWhere does purine come from?\n\u2022\nWhere is uric acid found?\n\u2022\nWhat is high uric acid?\nWhat can high uric acid cause?\n\u2022\nWhat is low uric acid?\n\u2022\nTests: how to know uric acid levels?\nWhere does purine come from?\nPurine is produced and released into the bloodstream when an amino acid is broken down\nby digestion. Therefore, it is produced naturally in the body. (Truncated)"}, {"title": "Transformed Seed (Argument Passage Generator)", "content": "Recent studies have indicated that high levels of uric acid in the blood, known as hyper-\nuricemia, may increase the risk of cardiovascular disease. Uric acid is a byproduct of purine\nmetabolism, and while it is naturally produced in the body, excessive amounts can lead to\nhealth complications. Hyperuricemia is typically defined as levels above 6 mg/dL in women\nand 7 mg/dL in men. This condition can result from increased production of uric acid or\ninsufficient elimination through urine. Factors contributing to high uric acid include a diet\nrich in purines, found in red meat and seafood, as well as lifestyle choices such as alcohol\nconsumption and physical inactivity. Conversely, low levels of uric acid, or hypouricemia,\nare less common and usually do not present symptoms. Nonetheless, they can be indicative\nof underlying kidney or liver issues. Diagnosing either condition requires laboratory blood\nand urine tests. It is important to note that while high uric acid levels are associated with\nan increased risk of cardiovascular disease, the causal relationship remains to be conclusively\nestablished."}, {"title": "Seed Instruction Generation Flow", "content": "We have currently compiled a collection of 43\nreading comprehension questions types. The list includes literal comprehension questions,\ncritical comprehension questions, evaluative comprehension questions, reasoning, identifying\nassumptions, identifying information that strengthens/weakens an argument, ordering events,\netc.\nA list some of these types is in Appendix A.\nWe have defined multiple Agents targeting these categories. Each of these agent receives as\ninput a piece of text and generates a list of questions based on a predefined question type.\nThe orchestration process will engage a subset of these agents, determined by the content\ntransformation agent in the preceding step. Upon completion of this phase, we will obtain a\ncollection of (passage, question) pairs that will constitute the input for the subsequent stage.\nThe following figure provides an example of Strengthen type question that is generated from\nthe running example."}, {"title": "EXAMPLE: Seed Instruction", "content": "Which one of the following, if true, most strengthens the argument that high lev-\nels of uric acid increase the risk of cardiovascular disease?\n(A) Some individuals with hyperuricemia do not develop cardiovascular disease.\n(B) Physical activity has been found to have no significant impact on uric acid levels in the\nblood.\n(C) Dietary supplements have been shown to reduce uric acid levels in the blood.\n(D) A significant number of patients with cardiovascular disease have been found to have\nuric acid levels above the defined thresholds for hyperuricemia.\n(E) Individuals with a family history of cardiovascular disease are more likely to have high\nuric acid levels."}, {"title": "Instruction Refinement Flow", "content": "The refinement flow contains multiple suggester-editor\nagents that will go through each of the (passage, question) pairs and create more such pairs\nwith the following goals: (1) Modify the passage to make the question unanswerable, (2)\nModify the passage to alter the answer, if possible, in opposite direction, or (3) Modify the\nquestions or answer choices (if applicable) to make them complex.\nHere is an example where the suggester agent that tries to add a difficult distractor to\nconfuse the test taker."}, {"title": "EXAMPLE: Refinement Flow", "content": "SUGGESTER\n\u2022 Suggestion 1 Introduce a hypothetical study or finding that could potentially\nstrengthen the argument, requiring the test-taker to infer its impact on the rela-\ntionship between uric acid levels and cardiovascular disease.\n\u2022 Suggestion 2 Add a layer of complexity by suggesting a genetic predisposition\nto hyperuricemia and its correlation with increased cardiovascular events, which\nwould require the test-taker to consider both genetic and physiological factors.\n\u2022 Suggestion 3 Include a distractor option that seems to strengthen the argument\nbut upon closer examination, it does not directly relate to the causal relationship\nbetween uric acid levels and cardiovascular disease, thus testing the test-taker's\nability to discern relevant from irrelevant information.\nEDITOR\n\u2022 Modification 1,2 (omitted for brevity)\n\u2022 Modification 3 Which one of the following, if true, most strengthens the argument\nthat high levels of uric acid increase the risk of cardiovascular disease?\n(A) Some individuals with hyperuricemia do not develop cardiovascular disease.\n(B) Physical activity has been found to have no significant impact on uric acid\nlevels in the blood.\n(C) A placebo-controlled trial shows that individuals taking uric acid-lowering\nmedication do not exhibit a reduced incidence of cardiovascular disease compared\nto the placebo group.\n(D) A significant number of patients with cardiovascular disease have been found\nto have uric acid levels above the defined thresholds for hyperuricemia.\n(E) A cross-sectional study finds that high uric acid levels are associated with other\nrisk factors for cardiovascular disease, such as hypertension and diabetes, but does\nnot establish a direct causal link."}, {"title": "AgentInstruct Flow for Text Modification", "content": "Text modification is the process of editing and refining written content to enhance its quality\nand effectiveness or alter its attributes. This involves correcting spelling and grammar,\nclarifying ideas, reorganizing content for better flow, adjusting tone, ensuring style consistency,\nfact-checking, removing redundancies, formatting, developing content, and adapting to specific\naudiences. It is a useful skill for LLMs that help in content writing. While several content\ntransformation agents can be introduced to intentionally modify the text as described earlier,\nwe focus here on showing the how the instructions are created and refined.\nSeed Instruction Generation Flow We have currently compiled a collection of 18 types\nof text modification tasks including paraphrasing, expansion, simplification, redacting or\nremoving content, styling, code switching, etc. The full list is in Appendix A.\nWe define an Agent for each of the task type. Each agent takes as input a piece of text and\ncreates several text modification tasks of the associated type. Here we provide an example\ninput and a task created by the Paraphrasing Agent."}, {"title": "EXAMPLE: Seed Instruction", "content": "Random Seed\nApril 6-8, 2017, University of Iowa, Iowa City, USA. Abstracts due December 1, 2016.\nFinance is hard to escape. In recent years, the increasing social impact and interconnection\nof financial discourses, markets, actors, and institutions have been understood under the\nbroad concept of financialization. Natascha van der Zwan identifies three distinct research\nstreams that have approached financialization as 1) a regime of accumulation, 2) the influence\nof financial markets and instruments on non-financial corporations as well as the banking\nand finance industry, and 3) a discourse of risk-taking, self-management and self-fulfillment\nthat is transforming people into investing subjects. Some anthropological skeptics, however,\nargue that finance has a far longer genealogy than the financialization literature has to date\nrecognized. For example, in the context of a lengthy human history of creating hierarchy,\nfinancialization may simply be a new technology serving an old purpose.\n(omitted for brevity)... The supply chains of financial products connect different places\nand political projects across the globe. How do such financial instruments transform social\nlife?\nAbstract deadline is December 1, 2016.\n1. Go to americananthro.org and log in. If you don't have a login id and password, create\none (you do not need to join the American Anthropological Association).\n2. Once you are logged in, look to the left hand column, click on Meeting registration.\n3. Click on register under the SEA 2017 Annual Meeting then follow online prompts to\nregister for the meeting (if we do not accept your abstract and you decide not to attend,\nyou may request that your registration fee be refunded and we would be happy to do so).\n4. Once you are registered, AAA will automatically send you an email inviting you to submit\nan abstract. Click the link and follow the instructions.\nTask:\nRewrite the event details (date, location, abstract deadline) in a more casual tone.\nGiven a random seed, the seed instruction creation flow randomly picks one of the 18 agents\nand uses that to obtain a seed (text, text modification instruction) pair."}, {"title": "Instruction Refinement Flow", "content": "The refinement flow consists of only one Suggester-Editor\npair. The Suggester-Editor duo increase the complexity of the generated instructions while\ntaking as input the text and the task modification instruction as input. Here we show three\nsuggestions and edits as proposed by the suggester-editor pair."}, {"title": "EXAMPLE: IRefinement Flow", "content": "Suggestions\nSuggestion 1: Incorporate a fictional narrative. Use a conversational style with colloquial\nlanguage and include a humorous element.\nSuggestion 2: Translate the event details into a poetic format. Maintain accurate infor-\nmation while using rhyming couplets and ensure the tone remains light and\nengaging.\nSuggestion 3: Frame the event details as a social media post. Use internet slang and\nemojis. Keep the message within 280 characters.\nModified Instructions\nInstruction 1: Rewrite the event details (date, location, abstract deadline) as if you're\ntelling a funny story to a friend using casual and colloquial language,\nwhile incorporating a fictional narrative that still conveys the necessary\ninformation.\nInstruction 2: Transform the event details (date, location, abstract deadline) into a light-\nhearted poem with rhyming couplets, ensuring that the essential information\nis accurately conveyed in a poetic format.\nInstruction 3: Craft a social media post that includes the event details (date, location,\nabstract deadline) using internet slang, emojis, and a casual tone, while\nkeeping the message concise and within 280 characters."}, {"title": "AgentInstruct Flow for Tool Use", "content": "The task of tool use or API use for LLMs involves enabling models to interact with external\ntools or services; via APIs. This capability allows AI systems to extend their functionality,\naccess external data, and perform actions beyond their native capabilities.\nContent Transformation Flow We use source code snippets or an API description [26] as\nthe random seed. If source code snippets has been used as the seed, a content transformation\nagent is used to synthesize an API description from the code snippet. The goal of the\nContent Transformation Flow is to synthesize list of APIs from the random seed. API lists\nare created by either: (1) using an API retrieval agent that iteratively searches for similar\ncode to expand the API list or (2) the agent uses the LLM to hypothesize other APIs present\nin the library.\nThe following figure provides an example of the library reconstruction scenario."}, {"title": "EXAMPLE: Content Transformation Flow [Library Reconstruction]", "content": "Seed\n{\n\"name\": \"View All Food Items\",\n\"description\": \"The request enables clients to obtain a detailed list of food items,\ncomplete with nutritional profiles such as calorie count, protein, fat, ...\",\n\"parameters\": {\n\"type\": \"object\",\n\"properties\": {\n\"limit\": {\n\"type\": \"NUMBER\",\n\"description\": \"limit the length of response\"\n}\n},\n\"required\": []\n}\n}\n[\n{\nReconstructed Remaining APIs from the Library\n\"name\": \"Search Food Items\",\n\"description\": \"Allows clients to search for food items by name and retrieve a list of\nmatching items ...\",\n\"parameters\": {\n\"type\": \"object\",\n\"properties\": {\n\"query\": {\n\"type\": \"string\",\n\"description\": \"The name or partial name of the food item to search for.\"\n},\n\"limit\": {\n\"type\": \"number\",\n\"description\": \"Optional parameter to limit the number of search results\nreturned.\"\n}\n},\n\"required\": [\n\"query\"\n]\n}\n},\n}\n]\nSeed Instruction Creation Flow The seed instruction creation flow, consume the list of\nAPIs and employs variety of agents to create several tasks of the following types:\n1. Tasks that require the use of a single API:"}, {"title": "(a) Tasks where the input supplies all necessary parameters.", "content": "(b) Tasks where the input includes superfluous parameters.\n(c) Tasks where the input is missing some required parameters.\n2. Tasks that necessitate the use of multiple APIs:\n(a) Tasks where the input provides all necessary parameters.\n(b) Tasks where the input is missing some required parameters.\n3. Tasks that require a single API which is not listed among the available APIs.\n4. Tasks that require multiple APIs but lack some of the essential APIs in the provided\nlist.\nRefinement Flow The goal of the Refinement flow is to increase the complexity, for e.g.,\nlooking at the task and the conversation and to suggest refinements to increase the number\nof steps required to solve the task.\nThe following figure provides an example of a multi-turn conversation created by the Agent-\nInstruct flow."}, {"title": "EXAMPLE: Instruction Data Created by AgentInstruct]", "content": "System Message\nAs an AI assistant, your role is to assist users in achieving their desired outcomes. You have\nthe capability to utilize a variety of APIs, and at each step of the process, you are required\nto produce a markdown output.\nAt any given moment, you have two choices to proceed:\nChoice 1: Initiate an API Call If you choose to call an API, you must generate a makdown\nincluding the \"name\" of the API and the necessary \"parameters\" for the call. After creating\nthe response, you must wait for the system to execute the API with the provided parameters\nand return the results to you. The markdown you output should follow this structure:\nACTION_TYPE : API_CALL\nACTION: name(parameter_name=value, another_parameter_name=value, ....)\nChoice 2: Conclude the Process There are times when you may decide to end the process,\neither because a) you have successfully obtained the answer\nb) you have determined that the appropriate APIs are not available.\nc) you discovered that user did not provide values for some required parameter\nIn case you successfully obtained the answer use FINAL_ANSWER as the action name\nwith only one parameter being the final answer. In case you decided to stop due to other\nreasons, use FAILED as the action with one parameter describing the reason you decided to\nstop. Overall you should follow this structure:\nACTION_TYPE : STOP\nACTION: [ACTION_NAME] ([VALUE])\nBelow is a list of APIs that you have access to:\n]\n[\nAPIs from the Library construction example both the seed and the\ngenerated ones\nUSER:\nI want to start a new diet plan for the next week. My goal is to consume around 1500\ncalories per day, and I prefer vegetarian meals. I'll be eating three meals a day. Can you\ncreate a meal plan for me? Also, I'd like to track what I eat every day and get some new\nfood recommendations. At the end of the week, I want to see my nutritional summary. Oh,\nand I found this great recipe for a Quinoa Salad that I want to add to your database. I also\nnoticed that the calorie count for 'Chana Masala' seems off; it should be lower. And please\nremove 'Butter Chicken' from my list; I've stopped eating it."}, {"title": "ASSISTANT:", "content": "To assist you with your request, I will perform the following actions:\n1. Create a meal plan based on your dietary preferences (vegetarian) and caloric goal (1500\ncalories per day) for three meals a day.\n2. Provide you with a way to track your daily meals.\n3. Offer you new food recommendations.\n4. Generate a nutritional summary at the end of the week. 5. Add the Quinoa Salad recipe\nto the database.\n6. Update the nutritional information for 'Chana Masala'.\n7. Remove 'Butter Chicken' from the database.\nLet's start by creating a vegetarian meal plan for you with a caloric goal of 1500 calories\nper day and three meals a day.\n'''markdown\nACTION TYPE: API CALL\nACTION: Create Meal Plan(dietary_preferences=[\"vegetarian\"],\ncaloric_goal=1500, num_meals=3)\n\u2019\u2019\u2019\nUSER:\n{\n\"status\": \"success\",\n\"meal_plan\": {\n\"day_1\": {\n\"breakfast\": {\n\"food_items\": [\"Oatmeal with Fruits\", \"Almond Milk\"],\n\"total calories\": 350\n},\n\"lunch\": {\n\"food_items\": [\"Chickpea Salad\", \"Whole Wheat Bread\"],\n\"total calories\": 500\n},\n\"dinner\": {\n\"food_items\": [\"Mixed Vegetable Stir Fry\", \"Brown Rice\"],\n\"total calories\": 650\n}\n},\n\"day_2\": {\n},\n}\n}\nASSISTANT:\nYour meal plan for the next week has been successfully created. Here's a brief overview:\n**Day 1**: Oatmeal with fruits and almond milk for breakfast, chickpea salad with whole\nwheat bread for lunch, and mixed vegetable stir fry with brown rice for dinner.\n**Day 2**:\nNext, let's proceed to add the Quinoa Salad recipe to the database. Please provide the\nnutritional information for the Quinoa Salad so I can proceed with the addition.\nAs for updating the 'Chana Masala' and removing 'Butter Chicken', I will need\ntheir unique identifiers (food_id) to make those changes. If you have those identi-\nfiers, please provide them. If not, I can search for these items in the database to find\nthe correct identifiers. Would you like me to search for 'Chana Masala' and 'Butter Chicken'?\nUSER:\n...(truncated)"}, {"title": "Orca-3", "content": "We implemented an AgentInstruct Flow for 17 different capabilities as described in Table 1.\nWe created a collection of approximately 22 million instructions aimed at teaching the\naforementioned skills. We have used unstructured text and code files sampled from\nKnowledge Pile [7], AutoMathText [38], a subset of openstax and a subset of apache-2.0\nlicensed source code files from [4]. The dataset covers variety of skills, as detailed in Table 1.\nUsing unstructured content as seeds for instruction data generation has several benefits.\nFirst, there is abundance of such data enabling the generation of large-scale and diverse\ninstruction data. Additionally, it enables us to avoid using any benchmark-specific data as\nseeds and hence focus on optimizing for a capability, not for a specific benchmark.\nIn addition to the 22 million instructions, we have incorporated approximately 3.8 million\npaired instructions sourced from Orca-1[21], Orca-2[18], Orca-Math[19] and samples from\nother publicly available sources such as [5, 37, 10, 30]. We refer to this data as Orca-2.5-\ndataset.\nThe culmination of these datasets results in approximately 25.8 million paired instructions,\nall of which are incorporated into the training of Orca-3. Furthermore, we have trained a\nseparate model, referred to as Orca-2.5, using the 3.8 million instructions (Orca-2.5-dataset).\nThe purpose of this is to compare and evaluate the impact of the 22 million instructions\ncurated through AgentInstruct."}, {"title": "Training Details", "content": "We use the 25.8 million paired instructions described earlier to finetune Mistral-7b-v0.1.\nWe choose this model because the it makes the weights publicly available for the base\n(no-instruction-tuned) version, with a permissive license allowing easy redistribution. We\nrefer to the finetuned model (Mistral-7b-v0.1 finetuned on AgentInstruct dataset) as Orca-3.\nEach pair in the dataset undergoes a tokenization process using the Mistral tokenizer,\nensuring a maximum sequence length of 8192 with packing. To guarantee that the training\nloss is calculated based only on the response conditioned on the prompt, label masking is\napplied. Weight decay was set at 0.1\nThe finetuneing used 19 NVIDIA A100 nodes, or 152 NVIDIA A100 GPUs, each with a\nbatch size of 10. We used AdamW optimizer with an initial learning rate of 8e-6 and a a\ncosine learning rate schedule. We also used a linear learning rate warm-up during the initial\n500 steps. The model was trained for three epochs and the training process concluded after\napproximately 200 hours."}, {"title": "Evaluation Results", "content": "The Orca-Bench dataset serves as a held-out test set, consisting of 100 samples from each of\nthe 17 skills for which data was curated using AgentInstruct, except for the Open Domain\nQuestion Answering (ODQA) category, where we created two test sets. The first subset,\nreferred to as ODQA, consists of 100 questions originated from the initial seed instruction\nphase. The second subset, termed Complex ODQA, includes more intricate questions\ndeveloped during the refinement phase.\nWe evaluated the performance of all baselines using the Orca-Bench dataset. These were\nscored relative to GPT-4 on a scale ranging from 0 to 10. It is worth noting that some of\nthe entries within Orca-Bench involve multiple exchanges. To illustrate, let a multi-turn\ninteraction in Orca-Bench be denoted by the sequence (system message, user1, assistant,\nuser2, assistant, ...), where each turn is crafted by GPT4 (teacher). For every user; input, we\ngenerate a corresponding student response, which is conditioned on the preceding conversation\nhistory as established by the teacher. We then evaluate the student's generated response"}, {"title": "OrcaBench Performance Comparison", "content": "multiple agents and is often instrumental in the generation of high-quality data and serve as\nan additional means to introduce diversity.\nSeed Instruction Generation Flow comprising of multiple agents takes as input the\ntransformed seed from the Content Transformation Flow and generates a set of diverse\ninstructions. The only goal of the Seed Instruction Flow is to introduce diversity for which\nit often relies on a pre-defined, but extensible, taxonomy.\nInstruction Refinement Flow takes as input the instructions from the Seed Instruction\nFlow and iteratively enhances their complexity and quality. Towards this we use the concept\nof Suggester-Editor Agents[19]. Suggester agents initially propose various approaches to\nincrease the intricacy of the initial instructions (making them more complex, unsolvable,\nor tricky), after which the Editor agents modify the instructions in accordance with these\nsuggestions.\nEach flow consists of a number of agents. We use a generic definition of an agent, where an\nagent is powered by an LLM and can optionally have the ability to use tools such as search\nAPIs, code interpreter or a calculator. Each agent has a specific role and set of instructions\nspecified as part of the underlying LLM system message.\nWe implemented these flows for 17 different skills, each having multiple subcategories.\nThe skills include reading comprehension, question answering, coding, retrieval augmented\ngeneration, creative writing, tool/API use and Web control. The full list is provided in\nTable 1\nWe explain how the workflows work with case studies of generating data for the following\nthree skills:\nReading Comprehension: The ability to understand, process, and interpret written text.\nText Modification: The process of altering text to suit different purposes.\nTool Use: The employment of functions or APIs to perform tasks or solve problems."}, {"title": "Benchmark Results", "content": "We evaluate Orca-3 against 5 baseline models including Orca-2.5", "benchmarks": "n\u2022 AGIEval: AGIEval [39", "MMLU": "Massive Multitask Language Understanding (MMLU) [9", "ARC": "The AI2 Reasoning Challenge (ARC) [2", "sets": "Easy (2376"}]}