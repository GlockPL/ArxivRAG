{"title": "Low-distortion and GPU-compatible Tree Embeddings in Hyperbolic Space", "authors": ["Max van Spengler", "Pascal Mettes"], "abstract": "Embedding tree-like data, from hierarchies to ontologies and taxonomies, forms a well-studied problem for representing knowledge across many domains. Hyperbolic geometry provides a natural solution for embedding trees, with vastly superior performance over Euclidean embeddings. Recent literature has shown that hyperbolic tree embeddings can even be placed on top of neural networks for hierarchical knowledge integration in deep learning settings. For all applications, a faithful embedding of trees is needed, with combinatorial constructions emerging as the most effective direction. This paper identifies and solves two key limitations of existing works. First, the combinatorial construction hinges on finding highly separated points on a hypersphere, a notoriously difficult problem. Current approaches achieve poor separation, degrading the quality of the corresponding hyperbolic embedding. We propose highly separated Delaunay tree embeddings (HS-DTE), which integrates angular separation in a generalized formulation of Delaunay embeddings, leading to lower embedding distortion. Second, low-distortion requires additional precision. The current approach for increasing precision is to use multiple precision arithmetic, which renders the embeddings useless on GPUs in deep learning settings. We reformulate the combinatorial construction using floating point expansion arithmetic, leading to superior embedding quality while retaining utility on accelerated hardware.", "sections": [{"title": "1. Introduction", "content": "Tree-like structures such as hierarchies are key for knowledge representation, from biological taxonomies (Padial et al., 2010) and phylogenetics (Kapli et al., 2020) to natural language (Miller, 1995; Tifrea et al., 2018; Yang et al., 2016), social networks (Freeman, 2004), visual understanding (Desai et al., 2023) and more. To obtain faithful embeddings, Euclidean space is ill-equiped; even simple trees lead to high distortion (Sonthalia & Gilbert, 2020). On the other hand, the exponential nature of hyperbolic space makes it a natural geometry for embedding trees (Nickel & Kiela, 2018). This insight has led to rapid advances in hyperbolic learning, with superior embedding (Sala et al., 2018) and clustering (Chami et al., 2020) of tree-like data.\nRecent literature has shown that hyperbolic tree embeddings are not only useful on their own, they also form powerful target embeddings on top of deep networks to unlock hierarchical representation learning (Peng et al., 2021; Mettes et al., 2024). Deep learning with hyperbolic tree embeddings has made it possible to effectively perform action recognition (Long et al., 2020), knowledge graph completion (Kolyvakis et al., 2020), hypernymy detection (Tifrea et al., 2018) and many other tasks in hyperbolic space. These early adoptions of hyperbolic embeddings have shown a glimpse of the powerful improvements that hierarchically aligned representations can bring to deep learning.\nThe rapid advances in hyperbolic deep learning underline the need for hyperbolic tree embeddings compatible with GPU accelerated software. Current tree embedding algorithms can roughly be divided in two categories; optimization-based and constructive methods. The optimization-based methods, e.g. Poincar\u00e9 embeddings (Nickel & Kiela, 2017), hyperbolic entailment cones (Ganea et al., 2018), and distortion optimization (Yu et al., 2022b), train embeddings using some objective function based on the tree. While these approaches are flexible due to minimal assumptions, the optimization can be unstable, slow and result in heavily distorted embeddings. Conversely, constructive methods traverse a tree once, placing the children of each node on a hypersphere around the node's embedding (Sarkar, 2011; Sala et al., 2018). These methods are fast, require no hyperparameter tuning and have great error guarantees. However, they rely on hyperspherical separation, a notoriously difficult problem (Saff & Kuijlaars, 1997), and on multiple precision floating point arithmetic, which is incompatible with GPUs and other accelerated hardware.\nOur goal is to embed trees in hyperbolic space with minimal distortion yet with the ability to operate on accelerated GPU hardware even when using higher precision. We do so in"}, {"title": "2. Preliminaries and related work", "content": "To help explain existing constructive hyperbolic embedding algorithms and our proposed approach, we outline the most important hyperbolic functions here. For a more thorough overview, we refer to (Cannon et al., 1997; Anderson, 2005). Akin to (Nickel & Kiela, 2017; Ganea et al., 2018; Sala et al., 2018), we focus on the Poincar\u00e9 ball model of hyperbolic space. For n-dimensional hyperbolic space, the Poincar\u00e9 ball model is defined as the Riemannian manifold $(D^n, g^n)$, where the manifold and Riemannian metric are defined as\n$D^n = \\{x \\in \\mathbb{R}^n : ||x||^2 < 1\\},\\qquad g^n_x = \\frac{4}{(1- ||x||^2)^2}I_n,$\\nUsing this model of hyperbolic space, we can compute distances between x, y \u2208 $D^n$ either as\n$d_D(x, y) = \\cosh^{-1}\\left(1+2\\frac{||x - y||^2}{(1- ||x||^2)(1- ||y||^2)}\\right),$\\nor as\n$d(x, y) = 2 \\tanh^{-1} (|| \u2212 x + y||),$\nwhere\n$x + y = \\frac{(1+2\\langle x, y \\rangle + ||y||^2)x + (1 \u2212 ||x||^2)y}{1+2\\langle x, y \\rangle + ||x||^2||y||^2},$\nis the M\u00f6bius addition operation. These formulations are theoretically equivalent, but suffer from different numerical errors. This distance represents the length of the straight line or geodesic between x and y with respect to the Riemannian metric $g^n$. Geodesics of the Poincar\u00e9 ball are\nEuclidean straight lines through the origin and circular arcs perpendicular to the boundary of the ball. We will use some isometries of hyperbolic space. More specifically, we will use reflections in geodesic hyperplanes. A geodesic hyperplane is an (n - 1)-dimensional manifold consisting of all geodesics through some point x \u2208 $D^n$ which are orthogonal to a normal geodesic through x or, equivalenty, orthogonal to some normal tangent vector v \u2208 $T_xD^n$. For the Poincar\u00e9 ball these are the Euclidean hyperplanes through the origin and the (n - 1)-dimensional hyperspherical caps which are perpendicular to the boundary of the ball. We will denote a geodesic hyperplane by $H_{x,v}$. Reflection in a geodesic hyperplane $H_{0,v}$ through the origin can be defined as in Euclidean space, so as a Householder transformation\n$R_{H_{0,v}}(y) = (I_n \u2013 2vv^T)y,$\\nwhere ||v|| = 1. Reflection in the other type of geodesic hyperplane is a spherical inversion:\n$R_{H_{x,v}}(y) = m+\\frac{r^2}{||y - m||^2} (y \u2013 m),$\\nwith m \u2208 $\\mathbb{R}^n$, r > 0 the center and radius of the hypersphere containing the geodesic hyperplane. We will denote a reflection mapping some point x \u2208 $D^n$ to another point y \u2208 $D^n$ by $R_{x\u2192y}$. The specific formulations and derivations of the reflections that we use are in Appendix A."}, {"title": "2.2. Related work", "content": "Existing embedding methods can be divided into two categories: optimization-based methods and constructive methods. The optimization methods typically use the tree to define some loss function and use a stochastic optimization method such as SGD to directly optimize the embedding of each node, e.g. Poincar\u00e9 embeddings (Nickel & Kiela, 2017), hyperbolic entailment cones (Ganea et al., 2018) and distortion optimization (Sala et al., 2018; Yu et al., 2022b). Poincar\u00e9 embeddings use a contrastive loss where related nodes are pulled together and unrelated nodes are pushed apart. Hyperbolic entailment cones attach an outwards radiating cone to each node embedding and define a loss that forces children of nodes into the cone of their parent. Distortion optimization directly optimizes for a distortion loss to embed node pairs. Such approaches are flexible, but do not lead to arbitrarily low distortion and optimization is slow. Constructive methods are either combinatorial methods (Sarkar, 2011; Sala et al., 2018) or eigendecomposition methods (Sala et al., 2018). Combinatorial methods first place the root of a tree at the origin of the hyperbolic space and then traverse down the tree, iteratively placing nodes as uniformly as possible on a hypersphere around their parent. (Sarkar, 2011) proposes a 2-dimensional approach, where the points have to be separated on a circle; a trivial task. For higher dimensions,"}, {"title": "3. HS-DTE", "content": "We are given a (possibly weighted) tree T = (V, E), where the nodes in V contain the concepts of our hierarchy and the edges in E represent parent-child connections. The goal is to find an embedding \u03a6 : V \u2192 $D^n$ that accurately captures the semantics of the tree T, so where T can be accurately reconstructed from \u03a6(V). An embedding \u03a6 is evaluated by first defining the graph metric $d_T(u, v)$ on the tree as the length of the shortest path between the nodes u and v and then checking how much \u03a6 distorts this metric. More specifically, for evaluation we use the average relative distortion (Sala et al., 2018), the worst-case distortion (Sarkar, 2011) and the mean average precision (Nickel & Kiela, 2017). Further details on these metrics can be found in Appendix B.\nThe starting point of our method is the Poincar\u00e9 ball implementation of Sarkar's combinatorial construction (Sarkar, 2011) as outlined by (Sala et al., 2018). A generalized formulation of this approach is outlined in Algorithm 1. The scaling factor \u03c4 > 0 is used to scale the tree metric $d_T$. A larger \u03c4 allows for a better use of the curvature of hyperbolic space, theoretically making it easier to find strong embeddings. Lower values can help avoid numerical issues that arise near the boundary of the Poincar\u00e9 ball. When the dimension of the embedding space satisfies $n \\leq \\log(\\text{deg}_{\\text{max}}) + 1$ and the scaling factor is set to\n$\\tau = \\frac{1+ \\epsilon}{\\epsilon} \\log (4 \\text{deg}_{\\text{max}}),\\qquad$\nwith $\\text{deg}_{\\text{max}}$ the maximal degree of T, then the construction leads to a worst-case distortion bounded by 1 + $\\epsilon$, given that the points on the hypersphere are sufficiently uniformly distributed (Sala et al., 2018). When the dimension is $n > \\log(\\text{deg}_{\\text{max}})+1$, the scaling factor should be \u03c4 = \u03a9(1), so it can no longer be reduced by choosing a higher dimensional embedding space (Sala et al., 2018). The number of bits required for the construction is O(log(degmax)) when $n \\leq \\log(\\text{deg}_{\\text{max}})+1$ and O(1) when $n > \\log(\\text{deg}_{\\text{max}})+1$, where l is the longest path in the tree."}, {"title": "The difficulty of distributing points on a hypersphere", "content": "The construction in Algorithm 1 provides a nice way of constructing embeddings in n-dimensional hyperbolic space with arbitrarily low distortion. However, the bound on the distortion for the \u03c4 in Equation 7 is dependent on our ability to generate uniformly distributed points on the n-dimensional hypersphere. More specifically, given generated points $x_1,...,x_{\\text{deg}_{\\text{max}}}$, the error bound relies on the assumption that\n$\\min_{i \\neq j} \\sin \\angle(x_i, x_j) > \\text{deg}_{\\text{max}}^{-1}.$"}, {"title": "4. HypFPE: High-precision GPU-compatible hyperbolic embeddings", "content": "While hyperbolic space enjoys numerous potential benefits, it is prone to numerical error when using floating point arithmetic. Especially as points move away from the origin, floating point arithmetic struggles to accurately represent or perform computations with these points. For larger values of \u03c4 or maximal path lengths l, the embeddings generated by the construction often end up in this problematic region of the Poincar\u00e9 ball. As such, the precision required for hyperbolic embeddings is often larger than the precision provided by the floating point formats supported on GPUs. Increased precision can be attained by switching to arbitrary precision arithmetic. However, this makes the result incompatible with existing deep learning libraries.\nHere, we propose HypFPE, a method to increase the precision of constructive hyperbolic approaches through floating point expansion (FPE) arithmetic. In this framework, numbers are represented as unevaluated sums of floating point numbers, typically of a fixed number of bits b. In other words, a number \u0192 \u2208 R is represented by a floating point expansion $f$ as\n$f \\approx \\hat f = \\sum_{i=1}^{t} f_i,$\\nwhere the $f_i$ are floating point numbers with a fixed number of bits and where t is the number of terms that the floating point expansion $f$ consists of. Each term $f_i$ is in the form of a GPU supported float format, such as float16, float32 or float64. Moreover, to ensure that this representation is unique and uses bits efficiently, it is constrained to be ulp-nonoverlapping (Popescu, 2017).\nDefinition 4.1. A floating point expansion $f = f_1 + ... + f_t$ is ulp-nonoverlapping if for all 2 < i < t, $|f_i| < ulp(f_{i-1})$, where ulp($f_{i\u22121}$) is the unit in the last place of $f_{i\u22121}$.\nA ulp-nonoverlapping FPE consisting of t terms each with b bits precision has at worst t(b \u2212 1) + 1 bits of precision, since exactly t \u2212 1 overlapping bits can occur. The corre-"}, {"title": "4.1. The inverse hyperbolic cosine formulation", "content": "For Equation 2, normal floating point arithmetic may cause the denominator inside the argument of cosh\u22121 to become 0 due to rounding. To solve this, we can use FPE arithmetic to compute the argument of cosh\u22121 and then approximate the distance by applying cosh-1 to the largest magnitude term of the FPE. This allows accurate computation of distances even for points near the boundary of the Poincar\u00e9 ball, as shown by Theorem 4.2 and Proposition 4.3.\nTheorem 4.2. Given x, y \u2208 $D^n$ with ||x|| < 1 \u2212 $\u03f5^{t\u22121}$ and ||y|| < 1 \u2212 $\u03f5^{t\u22121}$, an approximation $d$ to equation 2 can be"}, {"title": "4.2. The inverse hyperbolic tangent formulation", "content": "For Equation 3, the difficulty lies in the computation of tanh\u22121. With normal floating point arithmetic, due to rounding errors, this function can only be evaluated on [\u22121 + \u03f5, 1 \u2013 \u03f5], where \u03f5 is the machine precision. This severely limits the range of values, i.e., distances, that we can compute. Therefore, we need to be able to compute the inverse hyperbolic tangent with FPEs. Inspired by (Felker & musl Contributors, 2024), we propose a new routine for this computation, given in Algorithm 13 of Appendix N. Here, we approximate the logarithm in steps 7 and 9 as $\\log(f) \\approx \\log(f_1)$, which is accurate enough for our purposes. This algorithm can be used to accurately approximate tanh\u22121 while extending the range linearly in the number of terms t as shown by Theorem 4.4 and Proposition 4.5."}, {"title": "5. Experiments", "content": "To test how well the proposed methods for hyperspherical separation perform, we generate points $W_1,..., W_k$ on an 8-dimensional hypersphere for various numbers of points k and compute the minimal pairwise angle $min_{i \\neq j} \\angle(w_i, w_j)$. We compare to the Hadamard generation method from (Sala et al., 2018) and the method that is used in their implementation, which precomputes 1000 points using the method from (Lovisolo & Da Silva, 2001) and samples from these precomputed points. Note that a power of 2 is chosen for the dimension to be able to make a fair comparison to the Hadamard construction, since this method cannot be used otherwise. The results are shown in Figure 1a. These results show that our MAM indeed leads to high separation in terms of the minimal pairwise angle, that the precomputed approach leads to poor separation and that the Hadamard method only performs moderately well when the number of points required is close to the dimension of the space."}, {"title": "5.1. Ablations", "content": "To verify that this minimal pairwise angle is important for the quality of the construction, we perform the construction on a binary tree with a depth of 8 edges using each of the hypersphere generation methods. The construction is performed in 10 dimensions except for the Hadamard method, since this cannot generate 10 dimensional points. Additional results for dimensions 4, 7 and 20 are shown in Appendix I. Each method is applied using float32 representations and a scaling factor of \u03c4 = 1.33. The results are shown in Table 1. These findings support our hypothesis that the minimal pairwise angle is important for generating high quality embeddings and that the MAM is an excellent objective function for performing the separation."}, {"title": "5.2. Embedding complete m-ary trees", "content": "To demonstrate the strong performance of the combinatorial constructions compared to other methods, we perform embeddings on several complete m-ary trees with a max path length of l = 8 and branching factors m = 3,5,7. Due to the small l, each experiment can be performed with normal floating point arithmetic using float64 representations. We compare our method with Poincar\u00e9 embeddings"}, {"title": "5.3. Embedding phylogenetic trees", "content": "Lastly, we compare hyperbolic embeddings on phylogenetic trees. Moreover, we show how adding HypFPE to our method and the other combinatorial methods increases the embedding quality when requiring GPU-compatibility. The phylogenetic trees describe mosses (Hofbauer et al., 2016), weevils (Marvaldi et al., 2002), the European carnivora (Roquet et al., 2014), and lichen (Zhao et al., 2016), obtained from (McTavish et al., 2015). The latter two trees are weighted trees which can be embedded by adjusting the scaling in step 8 of Algorithm 1. Each of the embeddings is performed in 10-dimensional space. Other dimensions are given in Appendix K. The h-MDS method and the combinatorial constructions are performed with the largest \u03c4 that can be used with the given precision. The results are shown in Table 3. When using float64, HS-DTE outperforms each of the optimization-based methods and the other combinatorial approaches from (Sala et al., 2018). While h-MDS obtains high average distortion, it collapses entire subtrees, leading to massive local distortion. Therefore, the HS-DTE embeddings are of the highest quality. When adding HypFPE on"}, {"title": "6. Conclusion", "content": "In this paper we introduce HS-DTE, a novel way of constructively embedding trees in hyperbolic space, which uses an optimization approach to effectively separate points on a hypersphere. Empirically, we show that HS-DTE outperforms existing methods, while maintaining the computational efficiency of the combinatorial approaches. We also introduce HypFPE, a framework for floating point expansion arithmetic on tensors, which is adapted to extend the effective radius of the Poincar\u00e9 ball. This framework can be used to increase the precision of computations, while benefiting from hardware acceleration, paving the way for highly accurate hyperbolic neural networks. It can be added on top of any of the combinatorial methods, leading to low-distortion and GPU-compatible hyperbolic tree embeddings."}, {"title": "L. Statistics of the trees used in the experiments", "content": "Some statistics of the trees that are used in the experiments are shown in Table 11. Most notably, these statistics show that the true number of optimizations that has to be performed is significantly lower than the worst-case number of optimizations given by Theorem 3.1. To see this, note that an optimization step using MAM has to be performed each time a node is encountered with a degree that did not appear before. The result of this optimization step can then be cached and used for each node with the same degree."}, {"title": "M. Graph and tree-like graph embedding results", "content": "The graphs that we test our method on are a graph detailing relations between diseases (Goh et al., 2007) and a graph describing PhD advisor-advisee relations (De Nooy et al., 2018). In order to embed graphs with the combinatorial constructions, the graphs need to be embedded into trees first. Following (Sala et al., 2018), we use (Abraham et al., 2007) for the graph-to-tree embedding. The results of the subsequent tree embeddings are shown in Table 12. These distortions are with respect to the tree metric of the embedded tree instead of with respect to the original graph. This is to avoid mixing the influence of the tree-to-hyperbolic space embedding method with that of the graph-to-tree embedding."}, {"title": "N. FPE arithmetic", "content": ""}]}