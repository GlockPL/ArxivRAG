{"title": "Dehallucinating Parallel Context Extension for Retrieval-Augmented Generation", "authors": ["Zexiong Ma", "Shengnan An", "Zeqi Lin", "Yanzhen Zou", "Jian-Guang Lou", "Bing Xie"], "abstract": "Large language models (LLMs) are susceptible to generating hallucinated information, despite the integration of retrieval-augmented generation (RAG). Parallel context extension (PCE) is a line of research attempting to effectively integrating parallel (unordered) contexts, while it still suffers from in-context hallucinations when adapted to RAG scenarios. In this paper, we propose DePaC (Dehallucinating Parallel Context Extension), which alleviates the in-context hallucination problem with context-aware negative training and information-calibrated aggregation. DePaC is designed to alleviate two types of in-context hallucination: fact fabrication (i.e., LLMs present claims that are not supported by the contexts) and fact omission (i.e., LLMs fail to present claims that can be supported by the contexts). Specifically, (1) for fact fabrication, we apply the context-aware negative training that fine-tunes the LLMs with negative supervisions, thus explicitly guiding the LLMs to refuse to answer when contexts are not related to questions; (2) for fact omission, we propose the information-calibrated aggregation which prioritizes context windows with higher information increment from their contexts. The experimental results on nine RAG tasks demonstrate that DePaC significantly alleviates the two types of in-context hallucination and consistently achieves better performances on these tasks.", "sections": [{"title": "Introduction", "content": "Retrieval-augmented generation (RAG) (Lewis et al., 2020; Gao et al., 2023) is nowadays a prevalent paradigm for incorporating large language models (LLMs) (OpenAI, 2023; Touvron et al., 2023; Jiang et al., 2023a) with outside knowledge. RAG employs a retriever to fetch documents that are semantically closest to the question, and incorporates them into LLM's prompt. Parallel Context Extension (PCE) (Hao et al., 2022; Ratner et al., 2023; Su et al., 2024) is a line of research attempting to effectively integrating parallel contexts through an aggregation function. PCE is highly compatible with RAG scenarios, as the candidate retrieved documents of RAG are independ of each other.\nHowever, existing PCE approaches still face two types of in-context hallucination issues (Ji et al., 2023; Rawte et al., 2023; Yang et al., 2023): fact fabrication and fact omission. (1) fact fabrication occurs when the model presents fabricated claims that are inconsistent with the contextual facts. As shown in Figure 2a, LLM confidently produces a fabricated answer for the window with Doc2, caused PCE to fabricate the wrong answer. (2) fact omission refers to windows lacking useful information may disproportionately affect the aggregation function, leading it to omit critical information present in other windows. This will make LLMs fail to present claims that can be supported by the contexts. As shown in Figure 2b, Doc3 does not contain required information, makes LLM confidently generate \"Unknown\" for the window with Doc3, further leading to the wrong final answer.\nIn this paper, we propose DePaC to alleviate the hallucination issue of parallel context extension on RAG. DePaC contains two parts: NegTrain (Context-aware Negative Training) to address fact fabrication issue and ICA (Information-Calibrated Aggregation) to address fact omission issue. (1) NegTrain guids the LLMs to refuse to answer when contexts are not related to the question. Neg-Train consists of two parts of training data: one part comprises useful documents and questions as input, with corresponding answers as output. While the other part treats irrelevant documents and questions as input, with a rejection token as output. (2) ICA prioritizes context windows with higher information increment from their contexts. Specifically, we utilize Kullback-Leibler (Kullback and Leibler, 1951) divergence to measure the information increment of with-document compared to non-document. This approach enhances DePaC's capability to identify useful information within parallel windows. Moreover, DePaC has lower computational complexity than vanilla inference approach. The inference time of DePaC increases linearly with the number of documents, while inference time of vanilla approach increases squarely.\nWe conduct experiments on various RAG tasks, demonstrate that DePaC significantly alleviates the two types of hallucination and consistently achieves promising performances. Then we analyze the proportion of hallucination produced by different approaches, demonstrating that DePaC can effectively mitigate the two types of hallucination (Figure 1). We also conducte ablation study to identify that information-calibrated aggregation and context-aware negative training are both essential for DePaC performance.\nThe main contents of this paper are organized as follows. Section 2 introduces the formalization of PCE and two existing aggregation methods for PCE. Section 3 introduces the methodology and implementation details of DePaC. Section 4 introduces the complexity analysis of DePaC. Section 5 introduces our experimental results on information seeking and DocQA. Section 6 discusses the related work. Finally, section 7 provides a conclusion regarding our work."}, {"title": "Background: Parallel Context Extension (PCE)", "content": "The core idea of PCE involves aggregating information from multiple context windows into a unified representation space. Such a representation aggregation can be formalized on either the probability distributions of output tokens (Su et al., 2024), or the internal hidden states in attention layers (Hao et al., 2022; Ratner et al., 2023). Su et al. (2024) claimed the above two formalizations have similar practical performances. In this work, we adopt the formalization in (Su et al., 2024) that takes the aggregation of output distributions.\nGiven an question Q, a set of retrieved documents $D = \\{d_1, d_2, ..., d_n \\}$, and a language model with parameters $\\theta$, PCE first computes the output distribution of each context window,\n$P_{i,j} = p_{\\theta}( \\cdot | d_j \\oplus Q \\oplus A_{1:i-1}),$ (1)"}, {"title": "Dehallucinating Parallel Context Extension (DePaC)", "content": "As shown in Figure 3, we propose two methods to alleviate the fact fabrication and fact omission hallucinations of PCE for RAG scenarios. First, we introduce Context-aware Negative Training to enable the model to refuse to answer questions when the relevant information is missing in the context, thereby mitigating fact fabrication. Then, we propose Information-Calibrated Aggregation to measure the information increment given by the document, preventing the model from fact omission.\nWe introduce context-aware negative training to alleviate fact fabrication, which explicitly train the backbone model to determine whether a question is answerable based on the provided document. If not, we hope the model to refuse to answer the question rather than generating hallucinations.\nGiven an RAG example with a question Q, a ground-truth answer A, and a retrieved document $d_j$, we fine-tune the backbone model $\\theta$ according to the following loss function,\n$Loss(Q, A_{1:m}, d_j) =\\begin{cases}CE[p_{\\theta}( \\cdot | d_j \\oplus Q \\oplus A_{1:i}), t_d], & \\text{Q unrelated to } d_j,\\\\CE[p_{\\theta}( \\cdot | d_j \\oplus Q), A_{1:m}], & \\text{Q related to } d_j,\\end{cases}$ (8)\nwhere CE[] represents the cross-entropy loss, $t_d$ is a pre-defined rejection token, m refers to the sequence length of the ground-truth answer, $A_{1:m}$ refers to the complete ground-truth answer with all tokens, $A_{1:i}$ refers to the partial ground-truth answer the first tokens. As shown in Figure 3(1), to prevent DePaC from generating rejection token only at the beginning of the answer, we also include the positive answer clauses as input. After context-aware negative training, we use $t_d$ to explicitly judge the usefulness of each context window. We set $t_d$ as the UNK token to minimize interference with normal tokens during training.\nAs discussed in Section 2, merely measuring the uncertainty of the final output distribution can be heavily influenced by fact omission hallucination. We propose to measure the changes of uncertainty from the non-document output distribution to the with-document output distribution, reflecting the information increment provided by the retrieved document.\nSpecifically, we apply the Kullback-Leibler (KL) divergence to measure the information increment,\n$\\Delta_A(p_{i,j}, p_{i,c}) = D_{KL}(p_{i,j} || p_{i,c}),$ (9)"}, {"title": "Complexity Analysis", "content": "Considering that RAG scenarios have high expectations for execution efficiency and previous PCE-style work lacked analysis of the execution efficiency, we present the inference complexity of DePaC compared with vanilla inference approach. Figure 4 shows the attention pattern and execution time comparison between DePaC and vanilla inference. As the length of the question is much smaller than the length of the document, the complexity of processing the question is ignored. Given a LLM with m layers, we assume that the context consists of k documents, each with n tokens.\nVanilla complexity. Vanilla inference directly concatenates the k documents as the input to LLM, with a sequence length of kn. The attention of each layer is calculated by Attention(Q, K, V) = $softmax (\\frac{Q K^T}{\\sqrt{d}} )V$, where $Q, K, V \\in \\mathbb{R}^{(kn)\\times d}$ is the query, key and value matrix. The complexity of $Q K^T$ is $O((kn)^2 \\cdot d)$. The complexity of applying softmax to the matrix is $O((kn)^2)$.\nAfter applying softmax, the complexity of multiplying with V is $O((kn)^2 \\cdot d)$. So the complexity of Attention(Q, K, V) for m layers is $O(k^2 \\cdot n^2 \\cdot d \\cdot m)$.\nDePaC complexity. In DePaC, k documents are inputted to LLM in parallel, the sequence length for each input is n. This is akin to k times Attention(Q, K, V) computions, but with smaller $Q, K, V \\in \\mathbb{R}^{n\\times d}$, so the complexity of Attention(Q, K, V) for m layers is $O(k\\cdot n^2 \\cdot d \\cdot m)$. The complexity of calculating KL divergence for k documents is O(kn). Hence, the complexity of Attention compution for DePaC inference is $O(k \\cdot n^2 \\cdot d\\cdot m)$.\nThe complexity of Vanilla increases quadratically with k, while DePaC's complexity grows linearly. Figure 4 shows the average execution time of DePaC and vanilla inference approach with different context length, DePaC has faster inference speed than vanilla approach. Moreover, DePaC can place all documents in a single batch for parallel processing, further enhancing DePaC's inference speed."}, {"title": "Experiments", "content": "We conduct experiments on various tasks to assess DePaC's performance on RAG and alleviate the two types of in-context hallucination."}, {"title": "Tasks", "content": "We conduct evaluations on nine RAG tasks, including six information seeking tasks and three document-based question-answering tasks.\nThe information seeking tasks serve to explicitly probe the information awareness of DePaC. Each test case in these tasks contains an information query question and a large amount of contexts.\nBased on the given question, the model is required to seek for some textual pieces within the contexts. The information seeking tasks include:\n\u2022 Function name retrieve (FuncNR) (An et al., 2024). The contexts in FuncNR contain a large number of Python functions, all of which are sampled from the training data of Starcoder (Li et al., 2023). The questions in FuncNR ask for retrieving the function names based on the given code snippets. We extend the original context length in An et al. (2024) from 32K to 128K.\n\u2022 Entity label retrieve (EntLR) (An et al., 2024). The contexts in EntLR contain a large number of entities, all of which are sampled from Wikidata. Each entity is a triplet in the form of (id, label, description). The questions in EntLR ask for retrieving the labels corresponding to the given entity ids from the contexts. We extend the original context length in An et al. (2024) from 32K to 128K.\nNeedle-in-a-Haystack (MVIH) (Hsieh et al., 2024). The contexts in MVIH contain multiple values for a certain key, along with other unrelated text pieces. The questions in MVIH require the model to seek for all the associated values for the given key.\n\u2022 APIBench (Patil et al., 2023). The contexts in APIBench consist of many real-world APIs, each of which includes an API name, an API call and an API description. The questions in APIBench require to retrieve the API calls based on the given development requirements. Due to the ambiguity in the requirements, APIBench serves as the most challenging evaluation task for information seeking. We take three sub-tasks from"}, {"title": "Results and Analysis", "content": "DePaC consistently achieves promising performances across nine tasks. As shown in Table 3 and Table 1, DePaC achieves better performance than baselines across six information seeking tasks and three DocQA tasks. It is worth noting that although YaRN can process more documents, it performs worse than Vanilla on some tasks. This indicates that long-context extension approach may potentially impair the information seeking capabilities of LLM.\nDePaC maintains promising performance with candidate documents number increases. On DocQA tasks, as the number of documents increases, more redundant information in the context, DePaC still achieves promising performance. DePaC's performance with k=20 even surpasses NBCE with k=5 (23.9 vs. 19.5), further demonstrating DePaC's capability to identify key information from redundant context.\nDePaC significantly alleviates fact fabrication and fact omission hallucinations. We analyze the proportion of hallucinations produced by different approaches on three information seeking tasks (FuncNR, EntLR and MVIH). As shown in Figure 5, DePaC significantly reduces the occurrence of both types of hallucinations. DePaC even completely avoids fact omission on EntLR and fact fabrication on MVIH. The detailed hallucination evaluation setup is shown in Appendix G.\nBoth information-calibrated aggregation and context-aware negative training are essential for DePaC performance. We compare DePaC with two ablation setting: (1) DePaC w/o NegTrain. We reconstruct a Positive Training (Pos-Train) dataset composed solely of positive samples, with the sample size as NegTrain dataset, and finetune Mistral-7B with PosTrain dataset. (2) DePaC w/o ICA. We only replace the information-calibrated aggregation function of DePaC with lowest-uncertainty aggregation. We conducte ablation study on the six information seeking datasets. As shown in Figure 6, the ablation results indicate that both parts of DePaC are essential for its performance.\nDePaC also achieves promising performance on different LLMs. We also evaluate DePaC on another advanced LLM, Llama3-8B\u00b9. Table 2 shows the different PCE performance with Llama3-8B on the three QA datasets, DePaC also achieves promising performance with Llama3-8B model. It is worth mentioning that, while the performance of vanilla inference with Llama3-8B is significantly lower than with Mistral-7B (7.7 vs. 21.6), DePaC with Llama3-8B achieves comparable performance to Mistral-7B (24.2 vs. 24.8). This further confirms our finding that DePaC can effectively leverage the short-context processing capabilities of LLMs to extract useful information from long-context."}, {"title": "Related Work", "content": "To address hallucination issue of LLM, Retrieval-augmented generation (Lewis et al., 2020; Gao et al., 2023; Cheng et al., 2024; Asai et al., 2023) has been applied in many fields, including question answering (Zhang et al., 2024), code generation (Zhou et al., 2022; Ma et al., 2024) and recommendation (Zeng et al., 2024). The performance of RAG is limited by the effectiveness of retriever and the information utilization capability of LLM. Some work focus on enhancing the retriever's capabilities (Wang et al., 2023; Lewis et al., 2020). Shi et al. (2024) compresses the retrieved information for LLM. Some work proposes iterative RAG (Jiang et al., 2023b; Shao et al., 2023; Cheng et al., 2024) to help the model progressively utilize document information. Some work (Asai et al., 2023; Dhuliawala et al., 2023; Feng et al., 2024) utilizes prompt engineer to aggregate information from multiple documents to generate a final answer. These methods often lead to information omission during the aggregation process. In this work, we utilize PCE to directly aggregate information from multiple documents when predicting the next token, enhance the accuracy and efficiency of information utilization.\nRecent research has proposed some PCE approaches to aggregate multiple context windows into a unified representation space, extending context length of LLM. Some research (Hao et al., 2022; Ratner et al., 2023; Li et al., 2024) aggregates by average aggregation mechanisms. Su et al. (2024) proposes NBCE to aggregates by lowest-uncertainty aggregation mechanisms. Previous PCE work primarily focuses on increasing in-context learning examples, and faces hallucination issues when applied for RAG (Yang et al., 2023). Beyond parallel context extension for existing LLM, Yen et al. (2024) also proposes encoder-decoder architecture to implement parallel context. In this work, we propose DePaC to alleviate the hallucination issues of PCE for RAG scenarios. To the best of our knowledge, we are the first work to apply PCE to RAG scenarios."}, {"title": "Conclusion", "content": "In this paper, we propose DePaC to address two types of in-context hallucination issues of parallel context extension on RAG. DePaC consists of two key components: (1) a context-aware negative training technique to mitigate fact fabrication, and (2) an information-calibrated aggregation method to address fact omission issue. Both experiments on information seeking and DocQA tasks show the effectiveness of DePaC."}, {"title": "Limitations", "content": "We rely on GPT-4-Turbo to generate our training data, which cost around 90$ for API calling. Future work should attempt to generate data using cheaper models without compromising data quality.\nOur training process consumes some computational resources, but it's a one-time effort. Given the advantages of our method in terms of inference efficiency and accuracy, we believe these offline costs are justified."}, {"title": "More Formula Details", "content": "The Kullback-Leibler (KL) divergence for discrete probability distributions P\u2081 and P2 is defined as:\n$D_{KL} (P_1 || P_2) = \\sum_i P_1 (i) \\log \\frac{P_1(i)}{P_2(i)}$ (13)\nThe cross-entropy loss function is defined as:\n$CE[p_{\\theta}( \\cdot | d_j \\oplus Q), A] =\\sum_{i=1}^{n}log p_{\\theta}(A_i | d_j + Q \\oplus A_{1:i-1})$ (14)\nwhere A is the i-th token in g round-truth answers, n is the sequence length of ground-truth. $p_{\\theta}(A_i|d_j \\oplus Q+ A_{1:i-1})$ is the probability of generating $A_i$ given the input $d_j \\oplus Q \\oplus A_{1:i-1}$."}, {"title": "DePaC Simplified Form", "content": "Notice that one implicate constraint in Equation 11 is $\\gamma \\gg C(P_{i,j}, P_{i,c})$ as we hope to directly filter out irrelevant context windows. To simplify this constraint for implementation, we rewrite Equation 11 as the product of two terms and modify Equation 12 to make sure $\\hat{C}(P_{i,j}, P_{i,c}) \\geq 0$,\n$P_i = arg max \\hat{C} (P_{i,j}, P_{i,c}) \\cdot \\mathbb{I}(arg max p_{i,j}^k = t_a),$ (15)\n$k$\n$\\hat{C}(P_{i,j}, P_{i,c}) = max p_{ij}^k +\\beta \\cdot \\Delta(p_{i,j}, P_{i,c}),$(16)\n$k$\nwhere we use $max_k p_{ij}^k$ to estimate the output certainty, and $\\beta > 0$ is hyper-parameter. For the output of deep learning models, a higher $max_k p_{ij}^k$ always indicates a higher certainty in practice (Ghoshal and Tucker, 2022). We set $\\beta = 0.2$ by default and analyze the choice of $\\beta$ in Appendix C."}, {"title": "Hyperparameter Settings", "content": "We conducted $\\beta$ ablation study on the EntLR dataset. The result in Figure 7 indicates that $\\beta\\in [0.2,0.3]$ achieves better trade-off between information entropy and KL divergence. We set $\\beta$ = 0.2 in our experiments."}, {"title": "Analysis on NegTrain", "content": "Context-aware Negative training can improve the ability of refusing to answer questions with unrelated documents. We constructed an additional 4.4K positive samples (PosEval) and negative samples (NegEval), using the same data construction method as NegTrain, but with different seed documents. PosEval represents the situation that documents are related to the question, while NegEval represents the opposite. We compare the rejection token $t_d$ prediction loss on PosEval and NegEval datasets with different NegTrain steps. Figure 8 shows that NegTrain can increase the probability difference between refusing to answer questions with unrelated document and related document."}, {"title": "More Evaluation Results", "content": "We also compare DePaC with previous aggregation approaches specific to RAG (Asai et al., 2023) or can be applied to RAG (Dhuliawala et al., 2023; Feng et al., 2024), the results in Table 4 show that DePaC outperforms other aggregation approaches on different datasets (Kwiatkowski et al., 2019; Joshi et al., 2017; Chen et al., 2024).\nWe evaluate on 2WikimQA and HotPotQA datasets using Mistral-7B and Llama2-13B as base-models. The results in Table 5 show that DePaC with different models still maintains its performance advantage on multi-hop QA datasets. We make the prompt for multi-hop QA datasets end with \"Let's think step by step, \", this helps DePaC first seeks useful information across different contexts before generate the final answer."}, {"title": "Case Study", "content": "Some questions require synthesizing information from multiple documents, which demands DePaC to switch between different context windows during the generation process. As shown in Table 3, results on the MVIH dataset indicate that DePaC can achieve better performance on such tasks. As shown in Figure 9, DePaC can find all magic numbers located in different documents."}, {"title": "Hallucination Definition and Evaluation Setup", "content": "Previous work (Weng, 2024) categorizes hallucination into two types: (1) extrinsic hallucination, where the output of LLM is not grounded by the pre-training dataset or external world knowledge. (2) in-context hallucination, where the output of the model is inconsistent with the source content in context. In this work we focus on two types of in-context hallucination: (1) fact fabrication, where LLMs present claims that are not supported by the contexts. (2) fact omission, where LLMs fail to present claims that are supported by the contexts.\nWe done in-context hallucination evaluation on three information seeking tasks (FuncNR, EntLR and MVIH), as they are evaluated by exact-match score, makes them easier to analyze than QA tasks. Since these tasks have clear answers in the docu-"}, {"title": "Window Number Analysis", "content": "To analyze DePaC's performance with different numbers of windows, we conduct experiments on the FuncNR dataset, keeping the total number of candidate functions constant while varying the number of windows into which the context is divided. The results in Figure 11 show that as the number of windows increases (form 4 to 128), De-PaC's information-seeking ability improves; however, when the number of windows becomes too large (larger than 256), there may be a slight performance decline. All DePaC with split-window outperforms the single-window, further validating the effectiveness of DePaC with parallel context windows."}, {"title": "Broader Impacts", "content": "This work used GPT-4-Turbo to generate training data. Therefore, our fine-tuned model may inherit the potential risks of GPT-4-Turbo in terms of ethical and safety issues."}]}