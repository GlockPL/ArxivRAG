{"title": "Al Explainability for Power Electronics: From a Lipschitz Continuity Perspective", "authors": ["Xinze Li", "Fanfan Lin", "Homer Alan Mantooth", "Juan J. Rodr\u00edguez-Andina"], "abstract": "Lifecycle management of power converters continues to thrive with emerging artificial intelligence (Al) solutions, yet Al mathematical explainability remains unexplored in power electronics (PE) community. The lack of theoretical rigor challenges adoption in mission-critical applications. Therefore, this letter proposes a generic framework to evaluate mathematical explainability, highlighting inference stability and training convergence from a Lipschitz continuity perspective. Inference stability governs consistent outputs under input perturbations, essential for robust real-time control and fault diagnosis. Training convergence guarantees stable learning dynamics, facilitating accurate modeling in PE contexts. Additionally, a Lipschitz-aware learning rate selection strategy is introduced to accelerate convergence while mitigating overshoots and oscillations. The feasibility of the proposed Lipschitz-oriented framework is demonstrated by validating the mathematical explainability of a state-of-the-art physics-in-architecture neural network, and substantiated through empirical case studies on dual-active-bridge converters. This letter serves as a clarion call for the PE community to embrace mathematical explainability, heralding a transformative era of trustworthy and explainable Al solutions that potentially redefine the future of power electronics.", "sections": [{"title": "I. INTRODUCTION", "content": "ARTIFICIAL INTELLIGENCE (AI) is increasingly permeating the lifecycle of power converters, credited to its capability in identifying complex patterns from data, automating decision-making, adapting to evolving environments, etc. Whereas black-box AI solutions are prevalent in power electronics (PE), their lack of explainability poses significant challenges to trust and adoption [1]. Explainable AI (XAI) has thus served as a cornerstone to confidently deploy AI in PE domains, supporting diversified applications like renewable energy integration [2], transportation electrification [3], smart cities, etc.\nEmerging as the next generation of AI for engineering, physics-informed machine learning steers the AI learning process through integrating physical principles to safeguard AI explainability [4]. A noteworthy advancement in physics-informed machine learning for PE is the physics-in-architecture neural network (PANN), featuring a physically inspired recurrent neural architecture crafted from discretized state-space equations [5], providing physical explainability with enriched PE circuit insights whilst being light and flexible in nature [6], [7].\nDespite its promise in offering PE-specific physical explainability, the mathematical explainability of PANN remains unexplored in the current literature. More broadly, the PE community lacks the awareness of prioritizing the mathematical foundation of AI-based solutions, impeding their widespread adoption in mission-critical applications, including but not limited to more electric aircrafts, submarines, and healthcare appliances. Consequently, this letter strives to establish standards and tools for evaluating the mathematical explainability of AI in PE, demonstrated through the validation of PANN's model stability and convergence under rigorous mathematical settings.\nOverall, the mathematical explainability of PANN is justified from two critical aspects: inference stability and training convergence. Firstly, inference stability evaluates the consistency of model outputs in response to inputs and neural parameters, preventing abrupt reactions like exploding outputs to minor input variations. In real-time control and fault diagnosis of power converters, inference instability can lead to oscillations, overshoots, or false alarms caused by minor sensor fluctuations, compromising energy conversion reliability [8]. Secondly, training convergence ensures stable learning dynamics, such as a smoothly decreasing loss function during gradient descent. Divergent training can lead to suboptimal control or inaccurate diagnosis. In system-level applications like dynamic energy scheduling, a lack of training convergence may result in unrealistic dispatch, risking grid integrity [9]. These two metrics are universal indicators for assessing the mathematical explainability of data-driven AI models.\nCentering on the proof of mathematical explainability, Lipschitz continuity is instrumental in validating both inference stability and training convergence. This property ensures that output or loss variations of data-driven Al models are proportionally bounded by input or neural parameter changes, with the associated Lipschitz constant quantifying the maximal gradient value, which effectively functions as gradient clipping to enforce training convergence.\nTo address the need for a rigorous theoretical foundation in Al models for the PE community, this letter emphasizes mathematical explainability from the perspective of Lipschitz continuity, and establishes a generic and comprehensive evaluation framework for mathematical explainability, including:\n\u25a0 Inference stability: Demonstrating the Lipschitz continuity of model outputs concerning inputs to ensure inference stability.\n\u25a0 Training convergence: Validating the Lipschitz continuity of loss functions with respect to neural parameters to justify training convergence.\n\u25a0 Lipschitz-aware learning rates: Proposing a strategy for selecting learning rates based on Lipschitz constants to accelerate convergence while mitigating overshoots and oscillations.\nThis letter calls upon the PE community to prioritize mathematical rigor in the development and evaluation of AI solutions, fostering trust and reliability in their deployment across PE applications."}, {"title": "II. MATHEMATICAL EXPLAINABILITY OF AI MODELS IN POWER ELECTRONICS AND LIPSCHITZ CONTINUITY", "content": ""}, {"title": "A. Definitions of Lipschitz Continuity and Lipschitz Constant", "content": "Definition 1. A function $f: R^n\\rightarrow R^m$ is Lipschitz continuous if there exists a constant $L_1$ (the Lipschitz constant) such that [10]:\n$\\vert\\vert f(x_1) - f(x_2) \\vert\\vert \\leq L_1\\vert\\vert x_1 - x_2 \\vert\\vert, \\forall x_1, x_2 \\in R^n$.\nwhere $\\vert\\vert \\cdot \\vert\\vert$ denotes a consistent norm, and $L_1$ quantifies the maximum rate of variation off w.r.t. x and serves as an upper bound for its magnitude. Lipschitz continuity in (1) is consistently used to prove inference stability and training convergence."}, {"title": "a) Generic Proof of Inference Stability", "content": "Theorem 1. An Al model satisfies inference stability if the gradient of model outputs f(z) w.r.t. model inputs z, namely its Jacobian matrix $\\nabla_zf(z)$, is bounded, as formulated in (2) [11].\n$\\vert\\vert \\nabla_zf(z) \\vert\\vert \\leq L_{1z} \\rightarrow \\vert\\vert f(z_1) - f(z_2) \\vert\\vert \\leq L_{1z}\\vert\\vert z_1 - z_2 \\vert\\vert$\nyield\n$L_{1z}$ is the Lipschitz constant that captures the upper bound of the Jacobian matrix norm $\\vert\\vert\\nabla_zf (z) \\vert\\vert$, safeguarding against over-amplified model responses to input variations for smoother behaviors. Inference stability enhances the robustness of AI models to input perturbations, which is vital in noisy environments and under risks of adversarial attacks. For instance, in real-world power converter control, sensor signals like output voltages are subjected to ambient noise and fluctuations [8], which could cause sharp changes in the duty cycle, leading to voltage oscillations, overshoots, and even control instability for an Al-based online controller without inference stability, jeopardizing mission success."}, {"title": "b) Generic Proof of Training Convergence", "content": "Definition 2. Training convergence is established [11] if the limit of the averaged regret approaches zero as the number of training epochs $T\\rightarrow \\infty$, as given in (3), where the regret is defined in (4).\n$\\lim\\limits_{T\\rightarrow \\infty} \\frac{Regret(T)}{T} = \\lim\\limits_{T\\rightarrow \\infty} \\frac{1}{T}\\sum\\limits_{t=1}^T f_t(\\theta_t) - f_t(\\theta^*) = 0$\n$Regret(T) = \\sum\\limits_{t=1}^T [f_t(\\theta_t) \u2212 f_t(\\theta^*)]$,\nwhere $\\theta^* = \\argmin_{\\theta} \\sum_{\\theta} f_t(\\theta)$.\nThe training convergence proof depends on the choice of optimizers. Here, the Adam optimizer is considered for analysis.\nTheorem 2. Convergence of Al models trained with the Adam optimizer is achieved if the conditions in (5) hold [12], [13]:\n$\\vert\\vert\\nabla_{\\theta}f_t(\\theta)\\vert\\vert_2 \\leq G, \\vert\\vert\\nabla_{\\theta}f_t(\\theta)\\vert\\vert_{\\infty} \\leq G_{\\infty}$\n$\\vert\\vert\\theta_n - \\theta_m\\vert\\vert_2 \\leq D, \\vert\\vert\\theta_n \u2212 \\theta_m\\vert\\vert_{\\infty} \\leq D_{\\infty}$,\nwhere, G and $G_{\\infty}$ are upper bounds on the 2-norm and infinity-norm of the gradient matrix of the loss function w.r.t. neural parameters 0. D and $D_{\\infty}$ bound the parameter updates. Small bounds can mitigate divergence, overshoots, and oscillations during training with a restricted search space.\nThe conditions in (5) imply that the gradient norm $\\vert\\vert\\nabla_{\\theta}f_t(\\theta)\\vert\\vert$ is bounded across all epochs, equivalent to the proof of Lipschitz continuity of loss functions, as indicated in (6).\nyield\n$\\vert\\vert\\nabla_\\thetaf(\\theta)\\vert\\vert \\leq L_{1\\theta} \\rightarrow \\vert\\vert f(\\theta_1) \u2013 f(\\theta_2)\\vert\\vert \\leq L_{1\\theta}\\vert\\vert\\theta_1 - \\theta_2\\vert\\vert $\nTraining convergence guarantees that Al models can accurately recognize informative and generalizable patterns from data. For example, for a reinforcement learning algorithm that is trained in real time, training convergence is crucial for reliable control performance for constantly varying conditions [14]. Similarly, in an Al-driven thermal management case, stable training ensures accurate thermal predictions [15], facilitating precise cooling and energy-efficient operation."}, {"title": "B. Fundamentals of PANN: Formulation and Structure", "content": "Without loss of generality, this letter focuses on the proof of Al mathematical explainability in the context of the latest PANN models, which provide theoretical foundations complementary to PANN's physical explainability.\nPANN, proposed by Li et al. in 2024 [5], integrates the general large-signal form of circuit state-space equations of power converters in (7) into its recurrent neural architecture through the discretization of numerical methods. In (7), x(t) and u(t) are time-dependent state and input variables, respectively, with associated circuit parameter-dependent matrices denoted as A and B. Notably, the trainable neural parameters of PANN correspond to the circuit parameters $\\theta$. The formulation of PANN with the implicit Euler algorithm is expressed as (8), which underpins the recurrent neural structure shown in Fig. 1, where $\\Delta_t$ is the time interval. Notations defined in (9) are used throughout this letter, and their shapes are indicated in (10), where $D_x$, $D_u$, and $D_{\\theta}$ are the dimensions of states, inputs, and circuit parameters, respectively.\n$\\frac{dx(t)}{dt} = A(\\theta)x(t) + B(\\theta)u(t)$\n$x[t+1] = [(1 \u2212 A\\Delta_t)^{-1} (1 \u2212 \\Delta_t)^{-1}BAt]\\begin{bmatrix}x[t]\\\\u[t+1]\\end{bmatrix}$\nX\u2208 $R^{D_x\u00d71}$, u \u2208 $R^{D_u\u00d71}$, z \u2208 $R^{(D_x+D_u)\u00d71}$,\nW\u2208$R^{D_x\u00d7(D_x+D_u)}$, $\\theta$ \u2208 $R^{D_\\theta\u00d71}$\nx = W ($\\theta$)z"}, {"title": "C. Proof of Inference Stability of PANN", "content": "Building on Theorem 1, the inference stability of PANN models can be established by proving that the norm of the Jacobian matrix $\\vert\\vert\\nabla_z x(z)\\vert\\vert$ is bounded, as stated in (11). Lemmas 1.1 and 1.2 are utilized to support the proof of (11).\n$\\vert\\vert\\nabla_zx(z)\\vert\\vert = \\vert\\vert W(\\theta)\\vert\\vert \\leq L_{1z}$\nLemma 1.1 For stable power converters, the norms of the state and input matrices in (7), $\\vert\\vert A\\vert\\vert$ and $\\vert\\vert B\\vert\\vert$, are bounded due to the physical constraints of circuit parameters and stability condition."}, {"title": "D. Proof of Training Convergence of PANN", "content": "Theorem 3. If the conditions in Theorem 2 are satisfied, the regret over T epochs, Regret(T), for PANN models trained with Adam is bounded as expressed in (12) [12]. The average regret, Regret(T)/T, decreases at a rate of $0(1/\\sqrt{T})$, indicating that the accuracy of PANN improves with training epochs, although the rate of improvement diminishes as T increases.\n$Regret(T) \\leq \\frac{dD^2G}{\\sqrt{1 - \\beta_2}}\\frac{\\sqrt{T}}{2\\alpha(1 \u2013 \\beta_1)(1 \u2013 \\lambda)^2} + \\frac{dD^2G}{\\sqrt{1 - \\beta_2}}\\frac{\\sqrt{T}}{2\\alpha(1 \u2013 \\beta_1)} + \\frac{\\alpha(1 + \\beta_1)dG^2}{(1 \u2212 \\beta_1)\\sqrt{1 - \\beta_2(1 \u2212 \\gamma)^2}}\\sqrt{T} = 0(\\sqrt{T})$\nBased on Theorem 3, the training of PANN models achieves convergence by justifying the boundedness of the gradient norm $\\vert\\vert\\nabla_{\\theta}ft(\\theta)\\vert\\vert$ and the parameter updates $\\vert\\vert\\theta_n \u2013 \\theta_m\\vert\\vert$. Since PANN is designed to characterize the time-domain behaviors of power converters, the root mean square error (RMSE) defined in (13) is commonly used, where $x^*$ is the target states. The gradient of the RMSE loss w.r.t. neural parameters o is derived in (14). Using the Cauchy-Schwarz inequality [11], the gradient norm is shown to be bounded by (15).\n$f(\\theta) = 0.5(x \u2013 x^*)^T (x \u2212 x^*)$\n$f(x) = (x - x^*)$\n$\\nabla_{\\theta}f (\\theta) = \\frac{\\partial f}{\\partial W} \\frac{\\partial W}{\\partial \\theta} = (z \\frac{\\partial W}{\\partial \\theta})^T(x-x^*)$\n$\\vert\\vert\\nabla_{\\theta}f(\\theta)\\vert\\vert \\leq \\vert\\vert W \u2013 W^*\\vert\\vert \\vert\\vert z\\vert\\vert^2 \\vert\\vert \\frac{\\partial W}{\\partial \\theta} \\vert\\vert = L_{1\\theta}$\nPrior to proving the training convergence of PANN using Theorem 2, Lemma 2 and Assumption 1 are introduced.\nLemma 2 The neural parameters O of PANN, which correspond to the circuit parameters of power converters, are physically bounded, implying that $\\vert\\vert\\theta_n \u2013 \\theta_m \\vert\\vert$ is bounded.\nAssumption 1 The norms of the derivative of the Jacobian matrix w.r.t. $\\theta$, $\\vert\\vert\\partial W/\\partial\\theta\\vert\\vert$, are bounded. This is a standard assumption for power converters with robust stability.\n$\\vert\\vert\\nabla_zx(\\theta)\\vert\\vert$ provides the bounds for the first term in (15), and the second term $\\vert\\vert z\\vert\\vert$ is also bounded due to its physical interpretation. Along with Lemma 2 and Assumption 1, the conditions in (5) are satisfied, proving the training convergence of PANN. Since the training of PANN corresponds to identifying unknown circuit parameters, its convergence implies an asymptotically stable system identification. Moreover, smaller Lipschitz constants $L_{1\\theta}$ in (15) result in smoother training dynamics, such that during the transient phase of identification, the estimates of circuit parameters 0 are free from oscillations and overshoots."}, {"title": "E. Lipschitz-Aware Selection of Learning Rates for PANN", "content": "In pursuit of optimal training performance for PANN, a Lipschitz-aware strategy to select learning rates is proposed in (16), where a\u2081 is the individual learning rate for the ith parameter $\\theta_i$, with $\\theta_{i,min}$ and $\\theta_{i,max}$ being the lower and upper limits of $\\theta_i$. The second-order Lipschitz constant, $L_{20}$, which captures the upper bound of the Hessian matrix norm $\\vert\\vert\\nabla^2f(\\theta)\\vert\\vert$, is defined in (17) and (18).\n$a_i = 0(G_{\\infty} \\cdot (\\theta_{i,max} \u2014 \u03b8_{i,min})/L_{20})$\n$\\nabla_\\theta^2f(\\theta) = z(\\frac{\\partial^2W}{\\partial \u03b8^2} \\cdot z^T) + (x-x^*)(\\frac{\\partial W}{\\partial \u03b8})^T +(x-x^*)\\frac{\\partial W}{\\partial \u03b8} = L_{20}$\n$\\vert\\vert f(\\theta)\\vert\\vert \\leq \\vert\\vert z\\vert\\vert^2_2 \\vert\\vert W-W^*\\vert\\vert\\vert\\vert \\frac{\\partial^2W}{\\partial \u03b8^2} \\vert\\vert + \\vert\\vert W-W^*\\vert\\vert \\vert\\vert z\\vert\\vert^2. \nThis Lipschitz-aware heuristic strategy ensures stable and efficient training convergence for PANN, as highlighted below:\nFirstly, the second-order gradient is bounded by $L_{20}$, which is incorporated into the denominator of ai, preventing oscillations in large-curvature regions and stabilizing training [17]. Secondly, the first-order Lipschitz constant $G_{\\infty}$ in the numerator accounts for the gradient scale, enabling effective updates of 0. Thirdly, to cater for major differences in parameter magnitudes, ai is scaled proportionally to the range of the ith parameter to explore the parameter space effectively."}, {"title": "III. CASE STUDY: DUAL-ACTIVE-BRIDGE CONVERTERS", "content": ""}, {"title": "A. PANN Model for Dual-Active-Bridge (DAB) Converters", "content": "This section analyzes the mathematical explainability of a PANN model for DAB converters, widely applied in solid state transformers [18], energy storage systems, etc. The state-space equation is given in (19), where $i_L$ is the key state variable, $v_p$ and $v_s$ are input variables, and the circuit parameters $\\Theta_{dab}$ include $L_k$, $R_L$, and n. Using (8), the discretized state-space equation is derived in (20), and the recurrent PANN model for the DAB converter, customized in Fig. 2, is detailed in Table I.\n$\\frac{di_L(t)}{dt} = \\frac{R_L}{L_k}i_L(t)+\\frac{v_p(t) \u2013 nv_s(t)}{L_k}$\n$x_{dab} = i_L[t_{k+1}]\\begin{bmatrix}v_p[t_{k+1}]\\\\v_s[t_{k+1}]\\end{bmatrix} = W_{dab} (\\theta_{dab})z_{dab}$"}, {"title": "B. Inference Stability of the PANN for DAB Converters", "content": "As derived in (20), the boundedness of the Jacobian matrix norm $\\vert\\vert\\nabla_{z_{dab}}x_{dab}(z_{dab})\\vert\\vert$, $W_{dab}$, is validated, with its upper"}, {"title": "C. Training Convergence of the PANN for DAB Converters", "content": "According to Theorems 2 and 3, training convergence of the PANN model is ensured if the norms of the Jacobian matrix derivatives, $\\vert\\vert W_{dab}/d\\theta_{dab} \\vert\\vert$, are bounded. As derived in (21), these matrix entries depend on the circuit parameters $\\theta_{dab}$, so physical constraints are naturally imposed to bound their norms. The upper bound of $\\vert\\vert\u2202W_{dab}/d\\theta_{dab} \\vert\\vert$ is primarily influenced by the derivatives w.r.t. $L_k$, as indicated by the entries in the first column of (21).\n$\\frac{dW_{dab}}{d\\theta_{dab}} =\\begin{bmatrix}At / (L_k + R_L\u2206t)^2 & -RL \u2206t / (L_k + R_L\u2206t) & -n\u2206t / (L_k + R_L\u2206t) \\\\& & \\\\0 & 0 & 0 \\end{bmatrix}$\nSimilarly, MC simulations have been conducted to validate the theoretical Lipschitz constant of the RMSE loss w.r.t. neural parameters 0, $L_{10}$ or $G_{\\infty}$, as shown in Fig. 3. The empirically validated boundedness of $L_{10}$ further justifies training convergence. Besides, to illustrate training convergence, Fig. 4 presents the training performance for various learning rates. The training dynamics, including regrets, losses, and parameter estimates under Strategies 1, 3, and 5, are shown in Fig. 5. Low learning rates (Strategy 1) imply slow convergence, whereas high rates (Strategy 5) exhibit undesired overshoots and oscillations due to regions of high loss curvature. In comparison, the proposed Lipschitz-aware Strategy 3 is free of such concerns, whilst attaining the fastest convergence and high modeling accuracy. In addition, an ablation study (Strategy 6) demonstrates the effectiveness of scaling individual a\u2081 to the parameter range, without which, convergence slows down, and overshoots and oscillations occur."}, {"title": "IV. CONCLUSION", "content": "This letter is the first attempt to systematically address the mathematical explainability of Al models in power electronics, focusing on inference stability and training convergence from the perspective of Lipschitz continuity. The proposed generic framework emphasizes two aspects. First, the sufficient"}]}