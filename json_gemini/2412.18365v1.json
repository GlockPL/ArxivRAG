{"title": "Hypergraph Attacks via Injecting Homogeneous Nodes into Elite Hyperedges", "authors": ["Meixia He", "Peican Zhu", "Keke Tang", "Yangming Guo"], "abstract": "Recent studies have shown that Hypergraph Neural Networks (HGNNs) are vulnerable to adversarial attacks. Existing approaches focus on hypergraph modification attacks guided by gradients, overlooking node spanning in the hypergraph and the group identity of hyperedges, thereby resulting in limited attack performance and detectable attacks. In this manuscript, we present a novel framework, i.e., Hypergraph Attacks via Injecting Homogeneous Nodes into Elite Hyperedges (IE-Attack), to tackle these challenges. Initially, utilizing the node spanning in the hypergraph, we propose the elite hyperedges sampler to identify hyperedges to be injected. Subsequently, a node generator utilizing Kernel Density Estimation (KDE) is proposed to generate the homogeneous node with the group identity of hyperedges. Finally, by injecting the homogeneous node into elite hyperedges, IE-Attack improves the attack performance and enhances the imperceptibility of attacks. Extensive experiments are conducted on five authentic datasets to validate the effectiveness of IE-Attack and the corresponding superiority to state-of-the-art methods.", "sections": [{"title": "Introduction", "content": "Graph Neural Networks (GNNs) (Kipf and Welling 2017; Veli\u010dkovi\u0107 et al. 2017; Cheng et al. 2024a; Liu et al. 2023; Dong et al. 2023; Wang et al. 2023; Cheng et al. 2024b) capture intricate relationships and patterns within graph data, facilitating tasks like node classification, recommendation systems and source detection, etc. Nevertheless, with the increasing complexity and diversity of real-world networks, attention has shifted towards higher-order networks like hypergraphs and simplicial complexes (Benson, Gleich, and Leskovec 2016; Battiston et al. 2021; Wang et al. 2024). Subsequently, Hypergraph Neural Networks (HGNNs) (Feng et al. 2019; Bai, Zhang, and Torr 2021) are proposed to extract higher-order features from hypergraphs, significantly improving the efficiency of downstream graph-related tasks. Despite its success, GNNs and HGNNs have been shown to be vulnerable to adversarial attacks (Z\u00fcgner, Akbarnejad, and G\u00fcnnemann 2018; Bojchevski and G\u00fcnnemann 2019), which has attracted increasing research interest.\nAdversarial attacks on GNNs are divided into modification attack and injection attack according to attack techniques (Wei et al. 2020; Sun et al. 2022). In modification attack (Chang et al. 2020; Jin et al. 2023), attackers aim to affect the performance of GNNs by modifying the attributes or connections of nodes and edges. Conversely, due to the high authority required by modification attack, the injection attack has received more attention. For instance, in social networks, injection attacks involve create new fake accounts without the need to compromise existing accounts, thus requiring relatively low permissions. Injection attacks (Sun et al. 2019; Zou et al. 2021; Zhu et al. 2024c) inject new nodes or edges into the graph, introducing malicious information to degrade the performance of GNNs. Nevertheless, researches on adversarial attacks against HGNNs are limited to the hypergraph modification attack, including Hyper-Attack (Hu et al. 2023) and MGHGA (Chen et al. 2023). These methods do not further consider the phenomenon of node spanning in the hypergraph and the group identity of hyperedges, resulting in poor attack performance and easily detectable attacks, as illustrated in Figure 1.\nBy modeling higher-order relationships in the network, hypergraphs exhibit richer graph structural features, leading to more limitations on hypergraph attacks. First, modifying hypergraphs requires high authority, limiting the applicability of hypergraph modification attacks. Second, the existence of node spanning in hypergraphs (Battiston et al. 2021) implies that when the same node appears in multiple hyperedges, hyperedges with substantial influence can be discerned by the frequency of node occurrences across various hyperedges. For instance, in social networks, when a user presents in multiple chat groups, it suggests that the user can extensively disseminate information through these groups within the network. However, current methods select modified hyperedges by calculating gradients, which cannot maximize the destruction of the feature aggregation of HGNNs, resulting in poor attack performance. Moreover, hyperedges are viewed as groups and exhibit group identity according to social psychology research (Spears 2021). Current hypergraph modification attacks do not consider the group identity of hyperedges when adding or removing known nodes in hyperedges, making the attacks easily detectable.\nTo address these challenges, we propose the Hypergraph Attacks via Injecting Homogeneous Nodes into Elite Hyperedges (IE-Attack). Firstly, due to the high authority required by hypergraph modification, we present the node injection attacks on hypergraphs. Secondly, inspired by the elite group in social psychology (Shayegh et al. 2022; Howard 2000), we propose an elite hyperedges sampler to identify elite hyperedges with significant influence by utilizing the node spanning phenomenon in the hypergraph. Additionally, we develop a node generator based on Kernel Density Estimation (KDE) to generate the homogeneous node, so that the elite hyperedges injected into the homogeneous node still exhibit group identity. By injecting the homogeneous node into elite hyperedges, IE-Attack maximizes malicious information propagation to obtain excellent attack results and enhances the imperceptibility of attacks. We validate the effectiveness of our approach on five publicly available datasets. Extensive experimental results demonstrate that IE-Attack exhibits excellent attack performance on HGNNs, outperforming state-of-the-art node injection attack methods.\nOverall, our contributions are summarized as:\n\u2022 We are the first to analyze the problem of node injection attack in hypergraphs and to propose a methodology to address this challenge.\n\u2022 We propose a novel attack method against HGNNS for the Hypergraph Attacks via Injecting Homogeneous Nodes into Elite Hyperedges.\n\u2022 We demonstrate the effectiveness of our proposed method over baseline approaches through extensive experimental validation."}, {"title": "Related Works", "content": "Graph Injection Attack Deep neural networks (Tang et al. 2022a) are known to be vulnerable to adversarial attacks, and this susceptibility has been extensively studied across various domains, including images (Zhu et al. 2024a; Li et al. 2023), point clouds (Tang et al. 2022b), and graphs (Wei et al. 2020). In this paper, we focus on graph injection attacks. NIPA (Sun et al. 2019) introduced a novel node injection approach to poison the graph structure, which was based on reinforcement learning. Likewise, AFGSM (Wang et al. 2020) addressed a more practical attack scenario, allowing adversaries to inject malicious nodes into the graph without manipulating the existing graph structure. Conversely, both NIPA and AFGSM were developed in a poisoning environment, requiring retraining of the defense models after each attack. TDGIA (Zou et al. 2021) followed the evasion attack setting of KDDCUP 2020, where different attacks were evaluated based on the same set of models and weights. In contrast to previous attacks in a white-box setting, G2A2C (Ju et al. 2023) and (Zhu et al. 2024b) proposed node injection attacks in a black-box setting. Subsequently, considering that previous studies involved injecting multiple nodes for attacks, G-NIA (Tao et al. 2021) introduced the extreme scenario of single node injection. G-NIA_CANA (Tao et al. 2023) incorporated a generator-discriminator structure to enhance the imperceptibility of attacks based on G-NIA.\nDifferent from node injection attack in ordinary graphs, hyperedges involve higher-order relationships among multiple nodes in hypergraphs, rendering graph injection attack methods unsuitable for hypergraph structures.\nHypergraph Neural Networks To encapsulate more intricate higher-order interaction details within graph datasets, advanced structures like hypergraphs, represented as G = (V, E), have been identified and developed (Jin et al. 2019; Antelmi et al. 2023). Subsequently, HGNNs (Feng et al. 2019) were introduced, where the feature aggregation process involved node-hyperedge-node interactions. This enabled HGNNs to extract more comprehensive feature information compared to GNNs. Approaches such as hypergraph convolution and hypergraph attention (Bai, Zhang, and Torr 2021; Yadati et al. 2019; Zhang, Zou, and Ma 2019) delved into refining the feature aggregation mechanism within hypergraphs, demonstrating notable effectiveness across graph-related tasks like node classification and link prediction. Additionally, a range of related HGNNs provided varied perspectives and find applications in fields such as recommendation systems and biological information networks (Zeng et al. 2023; Wang et al. 2018; Yu et al. 2023).\nWhile the security of HGNNs warrants significant attention, current attacks on HGNNs are solely focused on hypergraph modifications attacks (Hu et al. 2023; Chen et al. 2023), overlooking the node spanning phenomenon in the hypergraph and the group identity within hyperedge."}, {"title": "Preliminary and Problem Statement", "content": "Graph Neural Networks The graph G = (V, E), where V represents the set of nodes and E represents pairwise edges. The node features are denoted by $X \\in \\mathbb{R}^{|V|\\times|F|}$, where F signifies the feature dimension of X. The adjacency matrix is represented as $A \\in \\mathbb{R}^{|V|\\times|V|}$, with $A_{ij}$ being 1 if there exists a connection between node $v_i$ and $v_j$, and 0 otherwise. The GNNs involve a graph convolution process, where the feature aggregation is expressed as:\n$X^{l+1} = \\sigma(D^{-\\frac{1}{2}}(A + I)D^{-\\frac{1}{2}}X^{l}W^{l}),$ (1)\nwhere D denotes the degree matrix, I stands for the identity matrix, and $W^{l}$ represents the weight matrix of the l-th layer in GNNs. The symbol o signifies the activation function."}, {"title": "Methodology", "content": "Elite Hyperedges Sampler The phenomenon of node spanning in the hypergraph indicates varying abilities of nodes to propagate information within hyperedges, providing us with insights into selecting hyperedges for node injection. Initially, we analyze the feature aggregation process of HGNNs, $X^{l+1} = \\sigma(D_HWD_HD X^{l} \\theta^l)$.\nThe purpose of $D_V$ and $D_E$ is to normalize the matrix H, further simplified to $X^{l+1} = HWH^T X^l \\theta^l$. Considering the W as the identity matrix, $X^{l+1} = H H^T X^l \\theta^l$ is obtained. Subsequently, the feature aggregation process can be simplified and represented as follows:\n$X^{l+1} = H \\cdot H^T \\cdot X^l \\cdot$ (4)\nDuring node feature updates, we first aggregate hyperedge features using $H^T \\cdot X^l$, followed by updating node features using $H \\cdot H^T \\cdot X^l$. The $H \\cdot H^T$ signifies the weight adjustments post feature updates, reflecting the frequency of shared hyperedges between pairs of nodes. Consequently, a higher correlation coefficient arises from the increased frequency of shared hyperedges between two nodes, resulting in more enriched features during the aggregation process. Given that nodes exist across multiple hyperedges, does this suggest that these nodes offer substantial feature information during the aggregation process?\nExamining the cyclic structure of the network tackles this challenge and introduces the notion of \"cycle ratio\" quantifying a node's involvement in the shortest cycles of other nodes (Fan et al. 2021). Inspired by this, if we consider hyperedge as cycles, then $H_{cycle} = H \\cdot H^T$ symbolizes the \"cyclenumber matrix\" within the hypergraph. The sum of the participation rates of node $v_i$ in the hyperedge involving itself and other nodes is the \"cycle ratio\", which is:\n$P_{v_i} = \\frac{\\sum_{j=1}^{\\mu_E} H^{cycle}_{ij}}{\\sum_{j=1}^{|V|} H^{cycle}_{jj}},$ (5)\nwhere $H^{cycle}_{ij}$ denotes the count of hyperedges in which both nodes $v_i$ and $v_j$ are participants, while $H^{cycle}_{jj}$ represents the number of hyperedges involving node $v_j$. $\\mu_E$ denotes the number of hyperedges. $p_{v_i}$ reflects the importance of node $v_i$ within the hypergraph. This novel idea suggests that the more involved an individual is within a community (sharing hyperedges with neighbors) and the wider range of social roles they assume (including hyperedges they are associated with), the more significant their role becomes. Subsequently, we calculate the \"cycle ratio\" of all nodes in the hypergraph through Eq. (5) and sorting them, the most important elite node $v_{elite}$ is obtained. The hyperedge that includes elite node $v_{elite}$ is recognized as elite hyperedges $E_{elite}$.\nHomogeneous Node Generator To generate homogeneous nodes with features resembling the elite node, we employ Kernel Density Estimation function $f_{kde} (x)$ (Wkeglarczyk 2018), defined as:\n$f_{Kde} (x) = \\frac{1}{F} \\sum_{i=1}^{F} Kde (x - x_i).$ (6)\nHere, F denotes the sample size, which is equivalent to the dimensionality of the features. $x_i$ represents i-th data point of features vector x. Kde refers to the kernel function, utilized to assess the density contribution in the vicinity of data points. By placing kernel functions around data points and blending them with weights, a smoothed density estimation is achieved over the entire spatial domain.\nInitially, we utilize the KDE function $f_{kde} (x)$ to fit features of the elite node $v_{elite}$. The fitting process is as follows:\n$P_{elite} = f_{Kde} (z_{elite}),$ (7)\nwhere $z_{elite}$ denotes the feature of $v_{elite}$. $P_{elite}$ is the probability density function obtained by fitting the features $z_{elite}$. Introducing an excessive number of homogeneous nodes elevate the dimensionality of the H and escalate the computational complexity of the HGNNs. Consequently, $P_{elite}$ are sampled to obtain preliminary features $z_m$ of single homogeneous node $v_{mal}$ with a similar distribution of features as the elite node $v_{elite}$. The dimension F of $z_m$ is the same as features of $v_{elite}$. This process can be formalized as:\n$z_m = P_{elite}.sample(1 \\times F).$ (8)\nWhile the $v_{mal}$ exhibits group identity of the elite hyperedge similarity to $v_{elite}$, features of nodes other than $v_{elite}$ within the hyperedge are also essential. Given that $v_{elite}$ exists in multiple elite hyperedges, selecting all elite hyperedges will increase complexity. Therefore, we randomly select an elite hyperedge $e_{elite} = {v_1, ..., v_t }$ and further optimize the generation of $z_m$ using the feature information from other nodes in hyperedge $e_{elite}$, represented as follows:\n$z_{ms} = ((((z_m \\otimes v_1) \\otimes \\theta^2) \\cdot\\cdot\\cdot \\otimes \\theta^l),$ (9)\n$z_{msd} = relite \\cdot mean \\frac{1}{t} \\sum_{i=1}^t v_i,$ (10)\n$z_{mal} = NN(z_{msd}).$ (11)\nHerein, $mean {v_1+...+v_t}, {v_1,...,v_t}$ denote the node embedding acquired for nodes ${v_1,...,v_t}$ via the surrogate model HGNNS. $relite$ is node embedding of $v_{elite}$ in $e_{elite}$. t signifies the size of the elite hyperedge $C_{elite}$. ${\\theta^1, \\theta^2, ..., \\theta^l }$ represent the inter-layer weight parameters trained within the surrogate model HGNNs. The $\\otimes$ denotes the element-wise multiplication operation between vectors, while signifies the concatenation operation between vectors. $z_{ms}$ denotes the homogeneous feature vector further computed using the trained weights in HGNNs. Subsequently, the homogeneous feature vector $z_{msd}$ undergoes training through a linear neural network layer NN, where NN is expressed as $Y = W_{NN}z_{msd}+b_{offset}$. Here, $W_{NN}$ denotes the weight parameters of NN, and $b_{offset}$ represents the bias term. Consequently, we obtain the homogeneous node $v_{mal}$ with homogeneous feature $z_{mal}$.\nInjection Attack for HGNNs To achieve excellent attack performance with a lower attack cost, we inject single homogeneous node $v_{mal}$ into $E_{elite}$. The generated homogeneous node $v_{mal}$ serves as an attacker injected into elite hyperedges $E_{elite}$, thereby propagating malicious information during feature aggregation of HGNNs and increasing the imperceptibility of attacks.\nGiven the hyperedge incidence matrix of the original hypergraph G as $H_{\\mu_V\\times\\mu_E}$, where $\\mu_V$ is the number of nodes and $\\mu_E$ is the number of hyperedges. The single homogeneous node $v_{mal}$ is injected into elite hyperedges $E_{elite}$, resulting in the attacked hypergraph $\\hat{G}$. The hyperedge incidence matrix of $\\hat{G}$is updated to $\\hat{H}_{(\\mu_V+1)\\times\\mu_E}$.\nFor instance, if $E_{elite} = {e_{elite_1},..., e_{elite_j}}$ and $e_{elite_j} = {v_1, v_5, v_i}$, injecting the homogeneous node $v_{mal}$ into $e_{elite_j}$, results in the attacked hyperedge $\\hat{e}_{elite_j} = {v_1, v_5, v_i, v_{mal}}$. Consequently, the value at the corresponding position {(\\mu_V + 1), j} in the $\\hat{H}_{(\\mu_V+1)\\times\\mu_E}$ matrix is set to 1. ($\\mu_V$ + 1) is the position of $v_{mal}$ in the node set V. j denotes the j-th hyperedge of the elite hyperedge $e_{elite_j}$ in the hyperedges set E.\nThe attacked H resulting from injecting the homogeneous node $v_{mal}$ into elite hyperedges $E_{elite}$ is described as:\n$\\hat{H} = $\n$H_{ij} = 1, if v_i \\in e_j,$\n$H_{ij} = 0, if v_i \\notin e_j,$\n$H_{(\\mu_V+1)j} = 1, if v_{mal} \\in e_{elite_j}.(12)\nIt is evident that the node dimension of H has increased by one, while the hyperedge dimension remains unchanged. Additionally, the feature matrix X has been augmented with the injected homogeneous node feature $z_{mal}$. Therefore, we obtain the input data for adversarial attacks on HGNNs, comprising the attacked incidence matrix $\\hat{H}$ and the perturbed feature attributes $X = {X, z_{mal}}$.\nHGNNs aggregate the malicious feature information in the attacked hypergraph, leading to a degradation in HGNNs. Z is the output of HGNNs after being attacked:\n$\\hat{Z} = \\sigma(D^{-\\frac{1}{2}}_H \\hat{H}W \\hat{D}_H \\hat{H}^T D^{-\\frac{1}{2}}_H \\hat{H}) \\hat{X}^l \\hat{H}) \\hat{\\theta}).(13)\nOptimization Finally, we aim to enhance the attack effectiveness by training the IE-Attack, thereby improving the Misclassification rate of HGNNs. Consequently, the objective of model training is to minimize the discrepancy between predicted scores of correct labels and the predicted scores of the targeted incorrect labels, being depicted as:\n$\\min L_{atk} = \\sum_{q \\in V_{train}} \\sum_{z \\neq Y_q} max(0, \\hat{Z}_{q,Y_q} - \\hat{Z}_{q,z})+ \\frac{\\lambda}{Z_{elite}}||z_{mal} - z_{elite}||, (14)\nwhere q denotes the index of training samples in the training set $V_{train}$, $Y_q$ indicates the label of sample q, $\\hat{Z}$ represents the classification prediction results of HGNNs on the attacked hypergraph $\\hat{G}$, and z is the label of sample q obtained by the surrogate model HGNNs. The ReLU function max(0,) is employed to ensure the non-negativity of the loss function. The term $||z_{mal} - z_{elite}||$ represents the distance between the embeddings of the elite node $v_{elite}$ and the generated homogeneous node $v_{mal}$. The purpose is to make the generated homogeneous node $v_{mal}$ closer to the elite node $v_{elite}$ with the group identity of the elite hyperedges, thereby improving the imperceptibility of attacks. The training process of the IE-Attack is guided by the attack loss $L_{atk}$, optimizing iteratively with the gradient descent method until convergence."}, {"title": "Experiments", "content": "Experimental Setting\nDatasets To validate the superiority of our method, five datasets (Cora, Citeseer, Pubmed, Chameleon, Lastfm) (Maurya, Liu, and Murata 2021) are adopted. Following the hypergraph generation methods in the HGNNs, we apply the Hyper-KNN and Hyper-L1 methods for hypergraph generation (Gao et al. 2022). Furthermore, we introduce a novel approach for constructing hypergraphs by considering higher-order neighbors of nodes (Hyper-HOR). Three distinct hypergraph generation strategies are employed to verify the efficacy and robustness of the proposed IE-Attack. According to the datasets partitioning strategy for node classification in Graph Convolutional Networks (GCNs) (Kipf and Welling 2017), datasets are divided into training/validation/test sets.\nParameter Setting In this study, we set the elite hyperedge perturbation budget \u03b7, which involves selecting \u03b7 \u00d7 w hyperedges within elite hyperedge Eelite. The value of n ranges from 0.1 to 1 and w is the number of Eelite. Regarding the value of K in the Hyper-KNN hypergraph construction method, we set it to 10. The order in Hyper-HOR is set to 1-order and y in Hyper-L1 is set to 0.1.\nEvaluating Metrics This paper utilizes the Misclassification rate as an evaluation metric for the performance of IE-Attack. The Misclassification rate indicates the success rate of misclassifications by HGNNs, where a higher Misclassification rate signifies a more effective attack.\nBaselines IE-Attack is the node injection attack against HGNNs. Hence, we modify node injection methods from GNNs to align with the strategy proposed for hypergraphs in this study. We set up six baseline methods, including random methods (GIA-Random (GIA-R), DICE (Waniek et al. 2018)), gradient methods (FGA (Chen et al. 2018), IGA (Wu et al. 2019)), and adversarial generation (G-NIA (Tao et al. 2021), G-NIA_CANA (G-NIA*) (Tao et al. 2023)). These baseline methods adapt graph attacks to hypergraphs, making them comparable to proposed IE-Attack. Moreover, IE-Attack and baselines attack HGNNs in evasion attack scenarios. All experiments are conducted on a workstation equipped with four NVIDIA RTX 3090 GPUs, which are conducted under the same parameter settings. Except for Table 1, the random seed for other experiments is set 2024."}, {"title": "Model Performance and Parameter Analysis", "content": "Performance Comparison with State-of-the-art Methods\nIn contrast, G-NIA introduces injected nodes into hyperedges generated by a generator after multiple training iterations, leading to improved attack performance. G-NIA* incorporates a discriminator to enhance the imperceptibility of attacks. Nonetheless, IE-Attack achieves the highest Misclassification rate across all datasets and hypergraph generation models. These findings show attack effectiveness on HGNNs by injecting the homogeneous node into elite hyperedges. Moreover, the Cora hypergraph generated by the Hyper-HOR shows higher susceptibility to attacks, indicating weaker robustness. Conversely, the Citeseer hypergraph generated by Hyper-KNN and Hyper-L1 is more vulnerable to such attacks. These differences arise from how models capture graph structural information and node features."}, {"title": "Ablation Study and Analysis", "content": "To evaluate the effectiveness of the proposed algorithm, we conduct ablation experiments by systematically removing the \"Elite Hyperedges (R1)\", \u201cKDE (R2)\u201d and \u201cNode Generator (R3)\". Table 4 shows that excluding three strategies lead to a decrease in the model's attack performance, resulting in lower Misclassification rate. Particularly, the absence of the \"Elite Hyperedges\" and \"Node Generator\" have a more significant impact on the model's performance. Leveraging the elite hyperedge to maximize the malicious influence of the homogeneous node and utilizing the \"Node Generator\" to generate the homogeneous node, IE-Attack enhances its attack performance and improves the imperceptibility of attacks. Ablation experiments confirm the remarkable effectiveness of the proposed IE-Attack on HGNNs."}, {"title": "Conclusion", "content": "This paper explores the phenomenon of node spanning in the hypergraph and the group identity of hyperedges, introducing the node injection attack framework IE-Attack for HGNNs. The key idea lies in injecting the homogeneous node into elite hyperedges, IE-Attack maximizes the spread of malicious information in feature aggregation of HGNNs and enhances the imperceptibility of attacks. Extensive experiments demonstrate IE-Attack's superior performance over other attack models. Future research will explore attack techniques for different HGNNs variants and varying levels of knowledge, including black-box attacks."}]}