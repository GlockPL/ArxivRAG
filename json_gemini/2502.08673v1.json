{"title": "High-Throughput SAT Sampling", "authors": ["Arash Ardakani", "Minwoo Kang", "Kevin He", "Qijing Huang", "John Wawrzynek"], "abstract": "In this work, we present a novel technique for GPU-accelerated Boolean satisfiability (SAT) sampling. Unlike conventional sampling algorithms that directly operate on conjunctive normal form (CNF), our method transforms the logical constraints of SAT problems by factoring their CNF representations into simplified multi-level, multi-output Boolean functions. It then leverages gradient-based optimization to guide the search for a diverse set of valid solutions. Our method operates directly on the circuit structure of refactored SAT instances, reinterpreting the SAT problem as a supervised multi-output regression task. This differentiable technique enables independent bit-wise operations on each tensor element, allowing parallel execution of learning processes. As a result, we achieve GPU-accelerated sampling with significant runtime improvements ranging from 33.6\u00d7 to 523.6\u00d7 over state-of-the-art heuristic samplers. We demonstrate the superior performance of our sampling method through an extensive evaluation on 60 instances from a public domain benchmark suite utilized in previous studies.", "sections": [{"title": "I. INTRODUCTION", "content": "High-throughput SAT samplers play a crucial role in advancing the state of the art in software and hardware verification methodologies [1]. Generating a set of random solutions to logical constraints is critical in the verification, testing, and synthesis. In software verification, SAT samplers enable efficient exploration of diverse execution paths, addressing the scalability challenges inherent in symbolic execution [2]-[17]. In hardware verification, they support the generation of varied input patterns, ensuring a rigorous and effective verification process [18]-[21].\n\nThe SAT sampling process begins by formulating the logical constraints of the target application into conjunctive normal form (CNF) [22]. CNF is the specific format required by most SAT samplers, where the logical formula is expressed as a conjunction of clauses, with each clause being a disjunction of literals. The complexity of the logical constraints in the target application can result in a CNF that is not always concise. Nevertheless, CNF remains the preferred format due to the strong performance of SAT samplers and solvers. The complexity of the CNF can, however, affect the efficiency of these solvers.\n\nSAT solvers employ various strategies to find a satisfying assignment for the variables in the CNF. Modern SAT solvers [23]-[25] often use the conflict-driven clause learning (CDCL) algorithm [26], [27], that relies heavily on heuristics such as conflict-driven backtracking and clause learning. These heuristics effectively guide the CDCL algorithm in finding a satisfying assignment. Due to the sequential nature of these heuristics, that involve branching and backtracking, the latest SAT solvers are typically executed on CPUs. Consequently, state-of-the-art SAT samplers, which incorporate SAT solvers within their algorithms, also rely on a sequential process and are optimized for CPU execution."}, {"title": "II. PRELIMINARIES", "content": "SAT sampling involves drawing solutions from the solution space defined by a set of logical constraints expressed in CNF. In SAT sampling applications, Boolean expressions are typically represented in higher-level logical formats before being converted into CNF [22], [29]. These formats include propositional logic with operators like AND, OR, NOT, implications, and equivalences, as well as more complex structures such as if-then-else conditions, arithmetic expressions, and bit-level operations. In hardware verification, Boolean expressions can take the form of circuit representations, such as And-Inverter Graphs (AIGs) or Binary Decision Diagrams (BDDs). In cryptographic contexts, Algebraic Normal Form (ANF) is sometimes used. These representations are transformed into CNF through logical simplifications, flattening complex structures, and applying techniques like Tseitin transformation [30]. This transformation preserves the satisfiability of the original formula while introducing auxiliary variables when needed. The conversion to CNF provides SAT solvers with a standardized problem representation that retains the essential constraints of the original problem.\n\nA CNF consists of a conjunction of clauses (i.e., an AND of multiple clauses), where each clause consists of a disjunction of literals (i.e., an OR of literals). Literals refer to Boolean variables or their negations. In SAT solving, the goal is to determine if there exists an assignment of binary values to the variables in a given CNF, representing a Boolean expression, such that all clauses evaluate to 1. SAT sampling adds a probabilistic layer to this process. Instead of seeking just one solution for satisfiable instances, the aim is to produce multiple solutions or samples from the complete set of possible solutions. Generating samples from SAT instances plays a crucial role in design verification, testing, and synthesis, with significant applications in constrained-random verification (CRV) [18].\n\nA common method for SAT sampling involves using SAT solvers with built-in sampling functionality. These solvers are designed not only to determine the satisfiability of a Boolean formula but also to extract solutions from the solution space. Efficient SAT solving techniques include backtracking algorithms like the Davis-Putnam-Logemann-Loveland (DPLL) algorithm [31], stochastic local search methods such as WalkSAT [32], and CDCL algorithms [26], [27]. In recent years, several approaches have been developed for SAT sampling, including randomized algorithms, Markov chain Monte Carlo (MCMC) techniques, and heuristic-based sampling methods [1], [33]\u2013[36]. These methods typically explore the solution space iteratively, selecting candidate solutions based on predefined criteria and stochastically deciding whether to accept or reject them.\n\nSAT solvers and samplers have been optimized over decades to efficiently handle problems in CNF. CNF is well-suited for SAT-solving algorithms like DPLL and CDCL. These algorithms take advantage of CNF's structure to systematically explore possible truth assignments, detect conflicts early, and prune the search space efficiently. By focusing on individual clauses, which define specific constraints on solutions, the use of CNF enables solvers to address highly complex problems in a manageable way."}, {"title": "A. SAT Sampling", "content": "SAT sampling involves drawing solutions from the solution space defined by a set of logical constraints expressed in CNF. In SAT sampling applications, Boolean expressions are typically represented in higher-level logical formats before being converted into CNF [22], [29]. These formats include propositional logic with operators like AND, OR, NOT, implications, and equivalences, as well as more complex structures such as if-then-else conditions, arithmetic expressions, and bit-level operations. In hardware verification, Boolean expressions can take the form of circuit representations, such as And-Inverter Graphs (AIGs) or Binary Decision Diagrams (BDDs). In cryptographic contexts, Algebraic Normal Form (ANF) is sometimes used. These representations are transformed into CNF through logical simplifications, flattening complex structures, and applying techniques like Tseitin transformation [30]. This transformation preserves the satisfiability of the original formula while introducing auxiliary variables when needed. The conversion to CNF provides SAT solvers with a standardized problem representation that retains the essential constraints of the original problem.\n\nA CNF consists of a conjunction of clauses (i.e., an AND of multiple clauses), where each clause consists of a disjunction of literals (i.e., an OR of literals). Literals refer to Boolean variables or their negations. In SAT solving, the goal is to determine if there exists an assignment of binary values to the variables in a given CNF, representing a Boolean expression, such that all clauses evaluate to 1. SAT sampling adds a probabilistic layer to this process. Instead of seeking just one solution for"}, {"title": "B. Multi-Output Regression Task", "content": "A multi-output regression task, in the context of example generation, refers to the process of creating data points (or \"examples\") that serve as input-output pairs for a given model [37]. The main goal is to generate inputs such that they satisfy multiple specific output constraints simultaneously. Various methods, such as linear regression, neural networks or probabilistic representations of the relationships between inputs and outputs, can be used to construct such a model. The inputs to the model are adjusted in an iterative manner to minimize the difference between the predicted and actual output values. One common way to measure this difference is by using metrics like mean squared error (MSE) or l2 loss."}, {"title": "III. METHODOLOGY", "content": "In this section, we present a transformation algorithm paired with an optimization method to generate valid and diverse solutions to SAT problems. Our algorithm transforms a CNF from its flat, two-level structure into a more streamlined, multi-level, multi-output Boolean function, reducing both operations and logical constraints. We then apply gradient-based optimization to efficiently learn valid solutions using the simplified multi-level, multi-output function.\n\nAs discussed in Section II-A, Boolean expressions are typically represented in more abstract logical formats before being converted to CNF. In other words, the sub-expressions (i.e., sub-clauses) in a CNF often result from the transformation of single logical operators or the combination of multiple operators. This transformation increases the size of the CNF. Therefore, a sampler that could operate directly on the logical operators represented by the sub-expressions in a CNF would be advantageous. Motivated by this, we introduce our transformation algorithm, which converts CNF into an equisatisfiable multi-level, multi-output Boolean function, and demonstrate how this function can be used to generate various valid and distinct solutions using gradient-based optimization."}, {"title": "A. Transformation Algorithm", "content": "Let us first review the clauses, known as the CNF signature [38], which represent primary logical operators as a result of the Tseitin transformation. The CNF structure of an inverter with the input x and the output f, i.e., $f(x) = \\overline{x}$, is given by\n\n$(\\neg f \\vee x) \\wedge (f \\vee \\neg x)$,\n(1)\n\nwhere $\\vee$ and $\\wedge$ denote logical OR and AND operators, respectively. The clauses representing the logical OR operator with n inputs and an output f, i.e., $f(x_1, x_2, ..., x_n) = \\bigvee_{i=1}^{n} x_i$, can be expressed as\n\n$\\bigwedge_{i=1}^{n}(\\neg f \\vee x_i) \\wedge (f \\vee \\bigvee_{i=1}^{n} \\neg x_i)$,\n(2)\n\nThe clauses representing the logical AND operator with n inputs and an output f, i.e., $f(x_1, x_2,...,x_n) = \\bigwedge_{i=1}^{n} X_i$, are similar to those of the logical OR operator with its input and output variables inverted, i.e.,\n\n$(\\neg f \\vee \\bigwedge_{i=1}^{n} \\neg x_i) \\wedge (f \\vee \\bigvee_{i=1}^{n} x_i)$,\n(3)\n\nThe CNF structure of the logical NAND and NOR operators can be derived in a similar manner by inverting the output variable in the clauses associated with the logical AND and OR operators, respectively. The CNF signature of the logical XOR operator with n inputs and an output f is is given by\n\n$(\\neg f \\vee XOR(x_1,...,x_n)) \\wedge (f \\vee \\neg XOR(x_1,...,x_n)) = \\neg XOR(x_1,..., x_n, f) = XNOR(x_1,...,x_n, f)$.\n(4)\n\nSimilarly, the CNF structure for the logical XNOR operation can be described as $XOR(x_1,..., x_n, f)$.\n\nWhile deriving logical operators from the CNF signatures described above is straightforward through pattern matching, this method is limited to identifying clauses linked to primary logical operators. It does not handle sub-expressions that may involve more complex Boolean expressions constructed from these operators. For example, the clauses\n\n$(\\neg x_4 \\vee \\neg x_{107} \\vee x_5) \\wedge (\\neg x_4 \\vee x_{107} \\vee \\neg x_5) \\wedge (x_4 \\vee \\neg x_{108} \\vee x_5) \\wedge (x_4 \\vee x_{108} \\vee \\neg x_5)$\n(5)\n\nfrom the '75-10-1-q' CNF instance correspond to the function $x_5(x_4, x_{107}, x_{108}) = (x_{107} \\wedge x_4) \\vee (x_{108} \\wedge \\neg x_4)$, which cannot be identified using pattern matching alone, as it is impractical to store all possible Boolean patterns. This underscores the need for a general transformation algorithm capable of identifying the Boolean sub-expressions and constraints represented by the clauses.\n\nBefore introducing our algorithm, let us establish some key definitions. The primary objective of the algorithm is to transform a given CNF into an acyclic combinational structure while preserving all logical constraints in the original CNF. Variables that correspond to the inputs and outputs of this circuit are referred to as primary input variables and primary output variables, respectively. Variables representing the intermediate signals within the circuit are called intermediate variables. With these definitions in place, once a variable is identified as a"}, {"title": "III. EXPERIMENTAL RESULTS", "content": "In this section, we demonstrate the effectiveness of our sampling technique. To accomplish this, we developed a prototype of our approach using PyTorch, an open-source machine learning library that integrates Torch's powerful GPU-optimized backend with a Python-friendly interface. For a thorough assessment, we evaluated 60 problem instances of varying sizes from a public domain benchmark suite. The experiments were performed on a system featuring an Intel Xeon E5-2698 processor running at 2.2 GHz and 8 NVIDIA V100 GPUs, each with 32 GB of memory. We present the runtime performance of our method in terms of throughput, defined as the number of unique and valid solutions generated per second, using a single NVIDIA V100 GPU. GD was employed as the optimizer during the training phase, with the learning rate set to 10 and the number of iterations to 5. We varied the batch size between 100 and 1,000,000, based on the specific instances tested.\n\nWe compare the performance of our sampling method with leading SAT sampling methods, specifically UNIGEN3 [35],"}, {"title": "A. Runtime Performance", "content": "Table II presents the sampling performance of our method in terms of throughput for a representative subset of 14 instances from the sampling benchmark. Throughput is defined as the number of unique solutions generated per second. Each sampler is required to produce at least 1,000 solutions within a maximum runtime of 2 hours. The table shows the best throughput results obtained from each sampler. Our method consistently outperforms state-of-the-art samplers in unique solution throughput, achieving speedups ranging from 33.6\u00d7"}, {"title": "B. Learning Dynamics", "content": "We analyze the learning dynamics of our sampling method, focusing on hyper-parameters such as iterations and batch size. Fig. 3 shows the progress in generating unique solutions over 10 iterations, where the number of unique solutions increases with more iterations. Increasing the batch size improves runtime performance by leveraging GPU parallelism, but at the cost of higher memory usage. The GPU memory demand, as shown in Fig. 3, grows with both the complexity of the Boolean function derived from the CNF transformation and the batch size. In scenarios requiring a high number of unique samples with limited GPU memory, the practical solutions are to either run more iterations, reducing throughput, or use GPUs with larger memory."}, {"title": "C. Ablation Study", "content": "In this section, we analyze the extent of GPU acceleration by comparing the runtime performance of our sampler between the GPU and CPU, as presented in Fig. 4. The data shows that GPU execution results in an average speedup of 6.8\u00d7 over CPU execution. Additionally, we provide the rate of reduction in the number of bit-wise operations due to the transformation, measured as the number of operations in the CNF divided by"}, {"title": "IV. RELATED WORK", "content": "Numerous SAT formula sampling methods have been explored in prior research. For example, UNIGEN3 provides approximate uniformity guarantees [45], while both CMSGEN and QUICKSAMPLER [1] emphasize sampling efficiency. Other studies have also examined the use of data-parallel hardware for SAT solving, primarily focusing on parallelizing CDCL and various heuristic-based algorithms [46], [47]. Some recent efforts, such as MATSAT [48] and NEUROSAT [49], have attempted to frame SAT instances as constrained numerical optimization problems. However, these methods have struggled to demonstrate the effectiveness of GPU-accelerated formula sampling on large and diverse standard benchmarks, typically focusing on small, random instances. Recently, a new differentiable sampling technique called DIFFSAMPLER was proposed in [37], enabling GPU-accelerated SAT sampling on standard benchmarks and achieving competitive runtime performance compared to UNIGEN3 and CMSGEN. DEMOTIC is another GPU-accelerated, differentiable sampler specifically designed for CircuitSAT problems in CRV. It operates directly on circuit structures described in hardware description languages such as Verilog [50].\n\nThere have been only a few attempts in the literature that focus solely on extracting circuit structure from CNF descriptions [38], [51], primarily to recover information lost during the Tseitin transformation. These approaches typically rely on pattern matching based on predefined gate structures. In contrast, our transformation method is more general, capable of restoring any combination of logical gates from CNF, and, more importantly, it enables high-throughput SAT sampling using GPUs."}, {"title": "VI. CONCLUSION", "content": "In this paper, we have introduced a novel GPU-accelerated approach for SAT sampling that significantly outperforms traditional methods. By transforming CNF representations into simplified multi-level, multi-output Boolean functions and employing gradient-based optimization, our method reinterprets SAT as a supervised multi-output regression task. This enables parallel, bit-wise operations across tensor elements, leading to substantial runtime improvements. With speedups ranging from 33.6x to 523.6\u00d7 compared to existing heuristic samplers, our extensive evaluation on 60 benchmark instances demonstrates the effectiveness and efficiency of this new technique for SAT sampling. This performance gain is primarily attributed to the GPU's acceleration over CPU execution and the reduction in the number of logic operations resulting from our transformation."}]}