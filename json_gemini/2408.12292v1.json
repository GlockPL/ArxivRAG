{"title": "Towards Deconfounded Image-Text Matching with Causal Inference", "authors": ["Wenhui Li", "Xinqi Su", "Dan Song", "Lanjun Wang", "Kun Zhang", "An-An Liu"], "abstract": "Prior image-text matching methods have shown remarkable performance on many benchmark datasets, but most of them overlook the bias in the dataset, which exists in intra-modal and inter-modal, and tend to learn the spurious correlations that extremely degrade the generalization ability of the model. Furthermore, these methods often incorporate biased external knowledge from large-scale datasets as prior knowledge into image-text matching model, which is inevitable to force model further learn biased associations. To address above limitations, this paper firstly utilizes Structural Causal Models (SCMs) to illustrate how intra- and inter-modal confounders damage the image-text matching. Then, we employ backdoor adjustment to propose an innovative Deconfounded Causal Inference Network (DCIN) for image-text matching task. DCIN (1) decomposes the intra- and inter-modal confounders and incorporates them into the encoding stage of visual and textual features, effectively eliminating the spurious correlations during image-text matching, and (2) uses causal inference to mitigate biases of external knowledge. Consequently, the model can learn causality instead of spurious correlations caused by dataset bias. Extensive experiments on two well-known benchmark datasets, i.e., Flickr30K and MSCOCO, demonstrate the superiority of our proposed method.", "sections": [{"title": "1 INTRODUCTION", "content": "Image-text matching is a crucial task that devotes to bridging the semantic gap between computer vision and natural language processing. It aims to align the semantics of image-text pairs, and matches images with their semantically consistent texts, or matches texts with their corresponding images. Recent studies have achieved impressive performance on image-text matching by focusing on two key aspects: (i) precise measurement of semantic similarity between the features of image-text pairs, and (ii) introducing external knowledge to enhance the capabilities of cross-modal representation and semantic matching.\nIn the first aspect, the existing methods can be broadly categorized as global-level matching and local-level matching [48]. The former projects holistic features of image and text into a common space to compute their semantic similarity [3, 21, 42, 45], while the latter considers the semantic correspondence between specific visual and textual elements, such as region or word [17, 20]. The attention-based local-level matching approach was proposed and quickly became the most popular framework for image-text matching by utilizing the attention mechanism to align the common semantics of"}, {"title": "2 RELATED WORK", "content": "2.1 Image-text Matching\nImage-text matching methods can be broadly classified into two major categories: global-level matching and local-level matching. The former measures overall semantic alignment, while the latter focuses on fine-grained alignment between local segments of image-text pairs. Karpathy et al. [16] were the first to attempt fine-grained semantic reasoning for images and texts. Subsequently, Lee et al. [20] employed the Stacked Cross Attention Network (SCAN) to establish correspondences between regions and words, enabling each region to attend to multiple words and vice versa. SCAN's success led to attention-based local-level matching methods becoming the"}, {"title": "2.2 Causal Inference", "content": "In recent years, researchers have integrated causal inference into computer vision and natural language processing [1, 28, 46], enabling DNNs to learn causal effects and significantly improving performance in some areas such as image classification [28, 51], visual question answering [29, 30], and image captioning [25, 43].\nCausal inference methods can be categorized into front-door and backdoor adjustment [13, 31, 43]. Backdoor adjustment stratifies confounders into different levels to deconfound. Wang et al. [39] proposed Visual Commonsense Region-based Convolutional Neural Network, which employed backdoor adjustment to improve visual feature representation learning. Zhang et al. [50] utilized backdoor adjustment to mitigate high likelihood of co-occurrence between visual and textual tokens, showing that reducing dataset bias can enhance generalization. Liu et al. [25] used backdoor adjustment to disentangle region visual features and deconfound visual and linguistic pseudo-correlations in image captioning. Front-door adjustment aims to construct an additional mediator between cause and effect relationship to transmit knowledge. Yang et al. [43] used the front-door adjustment to deconfound in image captioning. Yang et al. [44] improved the attention mechanism with the front-door adjustment to remove spurious correlations.\nIn image-text matching task, confounders exist in both inter- and intra-modal aspects. Due to bi-directional retrieval, the features of image-text pairs can be easily interfered by these confounders, thus deconfounding is more challenging than other tasks."}, {"title": "3 METHODOLOGY", "content": "In this section, we first construct a structure causal model for image-text matching and explain how confounder can lead to spurious correlations in Sec. 3.1, and then describe how to use the backdoor"}, {"title": "3.1 SCM for Image-text matching", "content": "Structure causal model(SCM) is formulated to analyze the causal relationship where a variable is defined as a confounder when it exerts an influence on two or more other variables simultaneously [5, 43]. To simplify, we denote V as the input image or image feature and T as the input text or text feature. In Fig. 2, we present a SCM constructed for image-text matching, depicting the relationships among image feature V, text feature T, visual confounder $D\u2081$, and linguistic confounder $D\u2082$, where the direction of an edge indicates causality, e.g., $D\u2081 \u2192 V$ means that $D\u2081$ causes V. Next, we will introduce the structure causal model in detail.\n$V \u2192 T,T\u2192 V$: The causal effect $V \u2192 T$ indicates that the visual features contribute to matching their corresponding texts, and $T\u2192 V$ indicates that the text features contribute to matching their corresponding images.\n$D\u2081 \u2192 V, D\u2081 \u2192 T, D2 \u2192 V, D2 \u2192 T$: The confounder can negatively affect the attended features. We denote the causal effect of $D1$ on V as $D\u2081 \u2192 V$ because the frequently appearing visual contexts can severely affect the attended visual features during training (intra-modal). $D\u2081 \u2192 T$ means that the visual contexts can affect the frequency of textual words (inter-modal) [25]. Similarly, $D2 \u2192 V$ implies that the frequently appearing linguistic contexts can directly affect the frequency of visual regions (inter-modal), and $D2 \u2192 T$ indicates that the linguistic contexts can strongly impact the attended textual features by co-occurring (intra-modal).\n$V\u2190 D\u2081 \u2192 T, VD2\u2192T, T\u2190 D\u2081 \u2192 V, T \u2190 D2 \u2192 V$ (backdoor path) : The backdoor path between V and T is defined as any path from V to T with an arrow pointing towards V. The existence of confounders $D\u2081$ and $D2$ create multiple backdoor paths between V and T, which result in taking the observational likelihood P(T | V) or P(V | T) as the training target and generating spurious correlations between V and T, decreasing the network's generalization.\nTo illustrate how backdoor paths in image-text matching can lead to the spurious correlations between image and text features,"}, {"title": "3.2 Intervention with Backdoor Adjustment", "content": "We propose using backdoor adjustment in causal inference to eliminate dataset bias. We employ backdoor adjustment to block the backdoor path, as shown in Fig.2 (right). The model's implicit training target is set as P(T | do(V)) and P(V | do(T)), instead of the regular target for image-text matching. Specifically, we intervene on variable V and utilize backdoor adjustment to achieve P(T | do(V)) as follows:\nP(T | do(V)) = \u2211 P (d2) \u00b7\n                                d2\n\u2211P (T | V, d1, d2) P (d1),\n                               d1"}, {"title": "3.3 DCIN", "content": "Our proposed DCIN is depicted in Fig.3. First, we extract image and text global features in the \"Visual and Textual Global Embedding\". Then, we create visual and linguistic confounder dictionaries and incorporate debiased external knowledge based on causal probability estimation P(Y | do(X)) in the \"Confounder dictionary Embedding\" and \"Debiased Knowledge Embedding\" modules. Finally, we eliminate the spurious correlations between visual and textual features in the \"Visual Deconfound\" and \"Textual Deconfound\" modules before computing these matching probability.\n3.3.1 Visual and Textual Global Embedding. For an input image, we follow the approaches of [3, 48] to extract salient regions using Faster R-CNN [36], which pre-trained on the Visual Genome [19], by selecting the top-n (n = 36) regions with the highest confidences. Then, we encode region-level image features F = {f1,..., fi,..., fn} from these regions using ResNet101 [14] pre-trained on ImageNet [7]. Finally, we employ a fully connected layer to map these features to a D-dimensional space to obtain image features V = {01, . . ., Ui, . . ., Un }. In order to acquire global embedding V, we apply generalized pooling operator (GPO) [3] on features V."}, {"title": "3.3.2 Confounder dictionary Embedding", "content": "To construct the necessary confounders for backdoor adjustment, we create approximate visual confounder dictionary $D\u2081$ and linguistic confounder dictionary $D2$. Due to the impracticality of focusing on all concepts in the training set and identifying all confounders, we extract the top-k semantic concepts in text and visual domains and remove non-informative words such as \"is\" and \"a\". We select the dictionary containing object, gender, property, action concepts to address their corresponding biases.\nTo construct the linguistic dictionary, we use pre-trained Glove [33] word embedding to represent the selected text semantic concepts and create the linguistic matrix $g_{t} \u2208 R^{k\u00d7d\u0131}$. As for the visual dictionary, we adopt the approach from previous work [11] and represent each visual concept as a region-level average ROI feature of the same image, constructing the visual matrix $g_{v} \u2208 R^{k\u00d7dv}$.\n$g_{i} = \\frac{1}{h_{i}} \\sum_{j=1}^{h_{i}} \\frac{1}{1-\\mid R_{j} \\mid} \\sum_{r=1}^{\\mid R_{j} \\mid} v_{j,r}$,\nwhere $h_{i}$ denotes the number of images containing the i-th concept, and $v_{j,r}$ denotes the feature of the r th region of the j \u2013 th image. Next, we utilize two linear projections, $W^{v} \u2208 R^{do\u00d7d}$ and $W^{g} \u2208 R^{do\u00d7d}$, to map $V_{r}$ and $g_{v}$ to $D\u2081$ and $D2$, respectively. i.e., $D\u2081 = W^{v}g^{v}$, $D2 = W^{9}g^{t}$."}, {"title": "3.3.3 Debias Knowledge Embedding", "content": "Existing methods often leverage external knowledge from large-scale datasets to enhance the reasoning ability of image-text matching models at higher levels. They tend to capture the relationships between concepts X and Y using their co-occurrence probabilities P(Y | X). However, these approaches often introduce dataset bias, leading to spurious correlations between different concepts [13]. We conduct a toy experiment to illustrate the impact of bias on the relationship between semantic concepts. Surprisingly, we find that given the concept \"plate,\" the probability of \"fork\" being present is high, i.e., P(fork | plate) = 8.94%, even though it does not have a strong relationship with the concept \"fork\". Fig.4 (left) illustrates a SCM used to introduce external knowledge, where P(Y | X) can be represented as:\nP(Y | X) = \u2211 P(Y | X, z)P(z | X) =\n     Z\nP(Y,X)\nP(X)\n     ,\nwhere Z denotes the confounder. When Z is observed, we usually observe both X (Z \u2192 X) and Y (Z \u2192 Y). However, when only X is observed, Y rarely appears, indicating that Z is the confounders between X and Y (X \u2190 Z \u2192 Y). To address this problem, we use the backdoor adjustment to control the confounder effect of Z and mitigate the spurious correlation between X and Y. The adjusted formula is as follows:\nP(Y | do(X)) =\n\nP(Y | X, z)P(z) = \\sum_\\limits\n    Z\nP(Y, X, z)P(z)\nP(X, z)\n     ,\nwhere Z is the visual (linguistic) confounder if X, Y are visual (textual) concepts, and Z is the visual and linguistic confounders if X, Y are concepts of different modalities. To prevent data leakage in the test set, we select image-text pairs from the Visual Genome dataset [19] that are also present in either the MSCOCO [24] or Flickr 30K [34] training sets as external knowledge, we utilize multiple stacked graph convolutional networks (GCNs) to model the interdependencies among the concepts in the confounder dictionary. Firstly, we construct the concept relationship matrix E, where $E_{ij}$ = P ($Y_{j}$ | do ($X_{i}$)). Then, we concatenate the visual dictionary $D\u2081$ and linguistic dictionary $D2$, and reason the relationship between them. The process is illustrated below:\n$H^{(0)} = [D_{1}, D_{2}]$\n$H^{(l+1)} = \u03c3 (\\tilde{A}H^{(l)}W^{(l)}) + H^{(0)}$,\nwhere $A = \\tilde{D}^{-\\frac{1}{2}}E\\tilde{D}^{-\\frac{1}{2}}$ denotes normalized symmetric matrix, $W^{(l)}$ is learnable weight matrix, and \u03c3 is LeakyReLU activation function. We can obtain the final confounder dictionary D from the output of the last layer of the GCN."}, {"title": "3.3.4 Visual-Textual Feature Deconfound", "content": "Our goal is to transform the hidden probabilities P(T | V) and P(V | T) into P(T | do(V)) and P(V | do(T)) during the model learning process. We can compute Eq.(2) as follows:\nP(T | do(V)) = ED\u2081, ED\u2082 [P (T|V, d1,d2)].\nIt can be observed that it is the expected value of $P_{TV, d1, d2}$ according to the $D\u2081$ and $D2$, and following the previous works [38, 44], we can represent P(T | do(V)) as a network, where $P_{TV, d1, d2}$ can be implemented as:\nP (T | V, d1, d2) = 9 (V,T, d1, d2),\nwhere g() is a linear model to compute the match probability of the image-text pair, e.g., 9 (V, T, d1, d2) = ($Q_{1}V + Q_{2}d_{1} + Q_{3}d_{2}$)\u00d7T, where $Q_{1}$, $Q_{2}$, $Q_{3} \u2208 R^{dxd}$ denote the learnable weights. However, this approach also presents a challenge that in order to compute P(T | do(V)), we need to sample a large number of outputs from the network. To address this issue, we absorb the expectations into the linear model g(.) because the linear projection of the expectation"}, {"title": "3.3.5 Objective Function", "content": "To optimize the whole model, we utilize a hinge-based bidirectional triple loss [10] to enforce the matching probability of aligned image-text pairs to be a certain magnitude higher than that of unaligned pairs. The loss function is formulated as follows:\n$L = [\u03b1 \u2013 S(V, T) + S(V, \\hat{T})]_{+} + [\u03b1 \u2013 S(V, T) + S(\\hat{V}, T)]_{+}$,\nwhere \u03b1 represents the margin factor, $[x]_{+} = max(x, 0)$. V and $T\u0302$ represent the hardest negatives samples in a mini-batch."}, {"title": "4 EXPERIMENTS", "content": "4.1 Datasets and Implementation Details.\nDatasets. To evaluate the effectiveness of our proposed method, we conducted extensive experiments on two commonly benchmark datasets. Flickr30K [34] comprises 310,000 images and 155,000 sen- tences, and we follow the uniform data protocol as previous works"}, {"title": "4.2 Comparison Results and Analysis", "content": "We compare our DCIN model with the existing methods on two benchmark datasets. The results are shown in Table. 1 and Table. 2, respectively. DCIN represents the use of causal inference alone, and DCIN-ek indicates the introduction of debiased external knowledge on DCIN. To ensure fairness in the experiments, we average two models' similarities to report the ensemble results, denoted by"}, {"title": "4.3 Ablation Study", "content": "In this section, we perform several ablation studies on the Flickr30K dataset to evaluate the effectiveness of each module in our model, the influence of dictionary size as well as the different parameter settings.\n4.3.1 The effectiveness of model component. In Table. 3, we examine the validity of each module. Base: We denote the GPO model as base model and compare it with the following variations. (1) DCIN: We incorporate causal inference into the base model. The experiments demonstrate that using the backdoor adjustment to eliminate bias in the dataset substantially enhances model performance, highlighting the effectiveness of confront visual and linguistic confounders to improve model generalization. (2) DCIN-ek: We introduce biased external knowledge to reason visual and linguistic dictionaries"}, {"title": "4.3.2 The effectiveness of confounder dictionary", "content": "In Table. 5, we perform exhaustive ablation studies to confirm the utility of the confounder dictionary. DCIN w/o init: We randomly initialize visual and linguistic confounder dictionaries with the size of 300. DCIN w/o VD#K: We only use the linguistic confounder dictionary of size K. DCIN w/o LD#K: We only use the visual confounder dictionary of size K. DCIN+D#K: We define the size of the visual and linguistic confounder dictionaries as K. From the results we can find that even with random initialization of the dictionary, DCIN still outperforms the base model, indicating that random initialization of the dictionary can also reduce dataset bias [44]. Additionally, we find that a larger dictionary leads to better performance. Furthermore, we find that both visual and linguistic confounders introduce bias to the model, and removing either of them from the confounder dictionary will result in a degradation of model performance."}, {"title": "4.3.3 The analysis of confidence level \u03bb", "content": "In Figure. 5, we evaluate the impact of approximate sampling of visual and linguistic confounder dictionaries on image-text matching. We vary the confidence \u03bb from 0 to 0.15 with increments of 0.025 to balance the effect of approximation error on causal inference. The results show that the performance improves with increasing \u03bb until it reaches an optimal point. After that, there is a slight drop in performance, which demonstrates that this approximate visual and linguistic confounder dictionaries within suitable confidence levels can indeed enhance the model's ability of inferring image-text causality."}, {"title": "4.4 Qualitative results", "content": "Figure. 6 visualizes the image-to-text results retrieved by our model and the GPO. Intuitively, our model matches the texts that are less"}, {"title": "5 CONCLUSION", "content": "In this paper, we provide an in-depth analysis of why image-text matching models are prone to learning spurious correlations from a causal perspective and propose a novel method called the De-confounded Causal Inference Network for image-text matching. It utilizes layered interventions with two structural causal models in image-text matching and introduces external knowledge to mitigate spurious correlations. This strategy effectively addresses the issue of overestimating feature similarity between concepts and enhances the model's matching ability when introducing debiased external knowledge. It enables the model to learn causal knowledge from both the training and external databases simultaneously. Experimental results on two prominent datasets validate the superiority of our proposed method."}]}