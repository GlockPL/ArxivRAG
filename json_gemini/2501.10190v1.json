{"title": "Temporal Causal Reasoning with (Non-Recursive) Structural Equation Models*", "authors": ["Maksim Gladyshev", "Natasha Alechina", "Mehdi Dastani", "Dragan Doder", "Brian Logan"], "abstract": "Structural Equation Models (SEM) are the standard approach to representing causal dependencies between variables in causal models. In this paper we propose a new interpretation of SEMs when reasoning about Actual Causality, in which SEMs are viewed as mechanisms transforming the dynamics of exogenous variables into the dynamics of endogenous variables. This allows us to combine counterfactual causal reasoning with existing temporal logic formalisms, and to introduce a temporal logic, CPLTL, for causal reasoning about such structures. We show that the standard restriction to so-called recursive models (with no cycles in the dependency graph) is not necessary in our approach, allowing us to reason about mutually dependent processes and feedback loops. Finally, we introduce new notions of model equivalence for temporal causal models, and show that CPLTL has an efficient model-checking procedure.", "sections": [{"title": "Introduction", "content": "There has recently been increased interest in causal reasoning from Al researchers and philosophers. The standard framework for reasoning about causal dependencies in both stochastic and deterministic settings is Structural Equation Modelling (SEM) (Pearl 2000; Spirtes, Glymour, and Scheines 2001). Both types of reasoning are crucial for the field of AI: in stochastic domains it is often used in Causal Machine Learning (Peters, Janzing, and Sch\u00f6lkopf 2017) and Causal Discovery, while in deterministic domains it forms the basis for work on Actual Causality (Halpern 2016).\nHowever, reasoning about many real-world phenomena and their dynamics requires reasoning about time and temporal properties. As a result, temporal reasoning in, for example, Linear-time Temporal Logic (LTL) (Pnueli 1977), has become an important technique for reasoning about the dynamics of AI systems. Progress in this field has resulted in many theoretical results in areas such as formal verification and synthesis (Demri, Goranko, and Lange 2016).\nWhile structural equation models are the main tool for analysing cause-effect relations and have been applied in a range of disciplines, e.g., medicine, economics, computer science and industrial engineering, they are not specifically designed for representing the temporal behaviour of a system, which play important role for causality claims in many domains. For example, the effect of some treatment may (causally) depend not only on whether the treatment was given to a patient or not, but also on temporal properties (i.e, dynamics) of this treatment, such as timing, duration and repetition of the treatment. Combining SEM models with temporal reasoning is therefore key in many applications.\nPrevious work on combining SEM models with temporal reasoning has focused on causal discovery, and several methods for analysing time-series data with SEMs have been developed, e.g., (Assaad, Devijver, and Gaussier 2022; Hyv\u00e4rinen, Khemakhem, and Monti 2023). In this paper, we propose an approach to temporal reasoning with SEMs for reasoning about actual causality. While a causal model is usually understood as a static representation of causal dependencies transforming values of exogenous variables into the values of endogenous variables, we show it can also be interpreted as a causal mechanism transforming the dynamics of exogenous changes into the dynamics of endogenous ones. In our framework, we assume that input to a causal model is a (time) series of values assigned to the exogenous variables, which we call the 'temporal context'. We give a procedure that, given a causal model as input, processes a temporal context and transforms it into a (time) series of assignments to endogenous variables. We then show how the framework of actual causality can be combined with the temporal logic LTL to give the logic CPLTL, allowing us to express statements about future and past of the system, e.g., \"a fact \\varphi was always true\", \"a fact \\psi will be true until another fact \\& is true\", etc.\nOur framework has several interesting features. Firstly, interventions (necessary for counterfactual reasoning) become \u2018time-sensitive': in temporal settings it is necessary to specify not only which intervention happens, but also when it happens. Secondly, most existing works on actual causality only deal with recursive causal models (models with acyclic dependency graphs). In our approach cycles in the dependency graph have a natural temporal interpretation, so they do not create technical difficulties, but instead provide useful modelling tools. Following Beckers (2021), we introduce new notions of (temporal) equivalence for causal models, which also covers non-recursive cases. Finally, we show that our framework has an efficient model-checking procedure."}, {"title": "Formal Background", "content": "In this section we introduce the formal apparatus we use in the rest of the paper: Structural Equation Models (SEM's), also called Causal Models, used for modelling causal dependencies between events, and Linear-time Temporal Logic (LTL) designed for temporal reasoning.\n\nThe presentation below essentially follows (Halpern 2016). Let U and V be the finite sets of exogenous and endogenous variables respectively. We say that S = (U, V, R) is a signature, where $R : U \\cup V \\rightarrow 2^\\Re$ associates with every variable $Y\\in U \\cup V$ a non-empty finite set R(Y) of possible values, also called range of Y.\n\nCausal Model (or SEM) over S is a tuple M = (S,F), where F associates with every endogenous variable $X \\in V$ a function\n\n$F_x: \\prod_{Z \\in (U\\cup V)} R(Z) \\rightarrow R(X)$\n\nwhich defines the structural equation describing how the value of X depends on the values of U UV.\nInformally, in causal models different events are represented by the assignment of different values to abstract variables. Values of endogenous variables depend on the values of other variables, while values of exogenous variables are determined outside of the model. A complete assignment $(U_1 = u_1,..., U_k = u_k)$ of U is called a context and denoted \u1ee7. A pair (M, \u1ee7) is called causal setting.\nExample 1 (Rocks). Suzy and Billy both pick up rocks and throw them at a bottle (encoded as ST=1 and BT=1 respectively). Both throws are perfectly accurate, so the bottle shatters (BS=1) whenever ST=1 or BT=1.\nBecause all the variables are binary here, for simplicity we write ST and \u00acST instead of ST=1 and ST=0 respectively. It is assumed that exogenous variables UST and UBT determine values of ST and BT: ST := UST, BT := UB\u0442. The structural equation for BS is BS := ST v BT. It is often convenient to represent the structure of the model as a dependency graph. Nodes in the graph represent variables, and directed edges represent (direct) dependencies among variables.\n\nA model M is recursive if there exists a partial order < on V, such that unless X2 \u2264 X1, X\u2081 is independent of X2 (Halpern 2016). As a result, a dependency graph of a recursive model is a directed acyclic graph. Recursiveness also guarantees that given \u0169, the set of structural equations has a unique solution, i.e., a unique assignment of V. For this reason, many papers on actual causality consider recursive causal models only (e.g., (Halpern and Pearl 2005; Beckers and Vennekens 2018)). As we show later, this restriction recursive models is not necessary in our approach.\nThe last ingredient we need for reasoning about actual and counterfactual courses of events are interventions. An intervention $[X \\leftarrow x^*] \\varphi$, meaning \u201cafter fixing the values of $X \\subseteq V$ to $x^*$, holds\", results in a new casual model denoted $M_{X \\leftarrow x^*}$, which is the model M where functions Fx for any $X \\in X$ are replaced with a constant function F'x, which always returns $x^*$, where X = x* \u2208 X \u2190 7 and the remaining functions remain unchanged.\nNote that X abbreviates {X1,...,Xk}; X = 2 abbreviates {X1 = x1,...,Xk = xk}; X \u2190 2 abbreviates {X1 \u2190X1,..., Xk \u2190 xk}. Sometimes we slightly abuse this notation and write X = x \u2208 X \u2190 7 instead of X \u2212 x \u2208 X \u2190 7.\nIn our example in a context \u1ee7 = (UsT = 1,U\u0432\u0442 = 1), where both Suzy and Billy throw their rocks, formulas ST = 1, BT = 1, BS = 1 are true. At the same time, interventions allow us to formulate statements, such that [ST \u2190 0]BS = 1, meaning", "shatters": "r [ST \u2190 0, BT \u2190 0]\u00ac(BS = 1), meaning \u201cif neither Suzy nor Billy throw the rock, then the bottle is not shattered\". Thus, interventions provide us all the necessary machinery for counterfactual reasoning about SEM's.\nDefinition 2 (Syntax). The grammar of the basic causal language is defined as follows:\n$\\varphi ::= [\\vec{Y} \\leftarrow \\vec{y}]\\psi | \\neg \\varphi|\\varphi\\rightarrow \\varphi$\n$\\psi ::= (X = x) | \\neg\\psi | \\psi \\land \\psi,$\nwhere X \u2208 U UV, x \u2208 R(X), \u0176 \u2286 V and \u1ef9 \u2208 R(\u00dd). Note that \u1ef6 \u2190 \u1ef9 may be empty, so we write o instead of []4.\nThe truth relation (M,\u016b) |= 6, meaning that a causal formula is true in a causal setting (M, \u1ee7), is defined inductively as follows:\n(M, \u00fb) F (X = x) iff (X = x) \u2208 Sol(\u016b)\u00b9;\n(M, \u1ee7) \u25ba \u00ac iff (M, \u1ee7) 14 6;\n(M,\u00fb) it (y^4) iff (M, \u00fb) - 6 and (M, \u00fb) F \u03c8;\n(M,\u00fb) \u00a6\u00a6 [\u00dd \u2190 \u1ef9] iff (M\u1ef9\u2190\u1ef9, \u016b) IF \u03c6."}, {"title": "Linear-time Temporal Logic", "content": "Now we introduce some basics of Linear-time Temporal Logic (LTL), for an extensive overview see (Demri, Goranko, and Lange 2016). In this paper we use both future and past LTL operators, so we call it PLTL, and it contains four basic modalities: O\u03c6 meaning \u201cy will be true in the next moment\", XU\u03c8 meaning \" will be true until \u03c8\", \u0398\u03c6 meaning \u201co was true in the previous moment\u201d and \u03c8S\u03c8 meaning \" is true since \u03c8\". The only difference of our approach from the standard PLTL definitions is that we use atomic expressions (X = x) generated by a given signature S instead of atomic propositions Prop = {p,q, . . . }.\nDefinition 3 (PLTL syntax). Given a signature S, PLTL syntax is defined as:\n$\\varphi ::= (X = x) | \\neg \\varphi | \\varphi\\land \\varphi | O\\varphi | \\varphi\\bigcup\\varphi | \\Theta\\varphi | \\varphi\\S y,$\nwhere X \u2208 V, x \u2208 R(X).\nHere, Sol(u) denotes the unique solution of the equations in M in context \u0169 (existing by the recursiveness of M)."}, {"title": "Temporal Interpretation of Causal Models", "content": "In order to proceed we need to modify some of the definitions presented already. Firstly, we need to adjust the idea of contexts. Note that normally, the context \u1ee7 is understood as an assignment of all exogenous variables (Halpern 2016). But in our setting, we want to consider contexts as a (time) series of such assignments describing how the values of exogenous variables evolve over time.\nDefinition 7 (Temporal context). A temporal context u is an infinite sequence of complete assignments of U:\n$\\vec{u}: N \\rightarrow \\prod_{U \\in U} R(U).$\nWe denote a particular time instance of u as u(n).\nWe also need to adjust the definition of interventions. In our framework it is essential to specify not only which interventions take place, but also when. We extend the notation to make interventions time sensitive and, instead of Y \u2190 \u0443, we use Y(n) \u2190 y, where n \u2208 N, which means that we intervene on Y with value y at time step n. For multiple interventions, we use the notation $\\vec{Y}(\\vec{n}) \\leftarrow \\vec{y} = (Y_1(n_1) \\leftarrow y_1,..., Y_k (n_m) \\leftarrow y_k)$. Note that we allow the same variable Y' to occur in \u1ef8(n) \u2190 \u0177 multiple times, meaning that we can intervene on the same variable at multiple time moments.\nGiven M describing causal dependencies between the variables, and u describing how the values of exogenous variables evolve over time, we want to understand how the values of endogenous variables evolve over time. We represent this evolution as an (infinite) sequence C = (\u014d, 01,...) called a computation. First we define a call to F. Let u' and v be complete assignments of U and V respectively. We say that a call to F with (u,v) takes (u,v) and returns $\\vec{v}\" = \\prod_{X \\in V} Fx(u', v')$. A computation C starts with a default assignment v of V (representing \u2018initial' configuration of endogenous values)\u00b2 and evolves as a process of iterative calls to F, using values of U U V from the previous step 3.\nDefinition 8 (Computation). Given a tuple (M,u,v), a computation Cover (M, u,v) is a function mapping N to the complete assignments $\\prod_{V \\in V} R(V)$ of endogenous variables, such that C(M, u, v)(0) := v and for all i > 0,\n\n$\\ C(M,u,v) (i) := \\prod_{X \\in V} Fx(u(i-1),C(M, u, v)(i - 1))$"}, {"title": "Non-Recursiveness", "content": "The temporal approach to SEM's proposed above not only allows to deal with non-recursive models without additional technical adjustments, but also often provides more elegant ways to describe the desired temporal behaviour of the system.\nConsider Example 2 again. To model this scenario, we want our model M to contain V = {T, R} (for Treatment and Recovery), such that (1) R = 1 once the treatment is given twice in a row, and (2) once R = 1, it remains so. Let variable U (R(U) = {0, 1}) represent whether the treatment is given in a given moment. And let R(T) = {0, 1}, R(R) = {0,,1}, where T=1 means the treatment is given. We want to define our structural equations in such a way that R=0 if the treatment is not given on the previous step, R= if the treatment was given once, and R=1 if the treatment was given twice in a row. Additionally, we require that if the patient is recovered, he must remain so.\n\nThe desired behaviour of the system may be achieved if we define FR as follows. R := 0 if (T = 0 ^ R \u2260 1); R := 2 if (T = 1 ^ R = 0); R := 1 if (T = 1 ^ R = \u00bd) v R = 1.\nThis model is clearly non-recursive, because FR depends of R. However, note that under temporal interpretation every edge in the dependency graph takes (at least) 1 time interval to proceed. It is a feature of computation C, which performs consecutive calls to F, where values of V at any step i depend on values of (UUV) on the previous step. So, R := 1 if ((T = 1 ^ R = \u00bd) \u2228 R = 1) means that \u201cR=1 is true now if on the previous step both T=1 and R= were true, or R=1 was true.\nGiven a temporal context, e.g. u\u2081 = (0,1,0,1,1,0...) and a default assignment \u0e1b\u0e35 = 00 (we write 00 instead of (T=0,R=0)), (M,u,v) generates a computation C = (00,00,10,0,10,1,01,01,...), in which u\u2081(1)=1 triggers (T=1 at t=2), which triggers (R=\u00bd at t=3). But since \u2081(2)=0, T=0 becomes true at t=3, leading to (R=0 at t=4). Later, at step 4, T=1 happens again, triggering (R=\u00bd at t=5). Since both T=1 and R= are true at t=5, R=1 triggers at t=6. From this moment, R=1 remains true at any t=i, because R=1 holds at i-1. This corresponds to the temporal be-"}, {"title": "Modelling Assumptions", "content": "Here we list our modelling assumptions. First of all, in our settings the time is discrete. This is a standard assumption for LTL-style temporal logics. We also assume that the temporal context u represents a time series of exogenous changes given to us as an input. In this time series equal intervals between indexes correspond to equal time intervals. And similarly, equal time intervals correspond to equally spaced indices of the computation C.\nGiven u time series, we want our model to return the correct time series of V values that (temporally) correspond to the behaviour of the phenomena of our interest. So, our framework requires causal models to contain correct temporal information, which affects the way we design them.\nTo illustrate this, let us revisit Example 1. Assume we know that Suzy's throws are consistently faster that Billy's. Let us say it takes n time steps (e.g. seconds) for Suzy's rock to reach the bottle, and k for Billy's, where n < k. So, whenever Suzy decides to throw the rock at time ts and Billy at tB, the Suzy's rock will reach the bottle (if it is still there) at time ts + n and Billy's at time tp + k. We want our model to predict when the bottle will be shattered, given a temporal context u. So, our model must contain the information about 'delays' between the Suzy's (or Billy's) throw and the bottle shattering. One way to achieve this, is to add 'chains' of hidden (i.e. dummy) variables in the model.\nFirstly, we assume that if BS=1 at some step, then it should remain so, because once the bottle is shattered it obviously remains so. This creates a reflexive arrow in the dependency graph. If they throw simultaneously at step i, then the bottle shatters at step (i + n), because n < k. But now we can model situations when they decide to throw a rock at different time. So, if Suzy decides to throw at ts and Billy at te, then the bottle will be shattered at t* := min((ts + n), (tp + k)), i.e. for u = (00,00,...), (M, u, v), 0 |= [ST(ts) \u2190 1, BT(tb) \u2190 1]\u25cbt* (BS = 1).\nSuch a representation is not compact, and non-recursive models provide us a better way to represent this example. Instead of adding a long chain of dependencies to capture time intervals between events and their effects, we can add a single variable to abbreviate each chain. Note, however, that it is not enough to specify the range of these new variables, X and Y, as R(X) = {0,...,n - 1} and R(Y) = {0,..., k \u2212 1}, where each value \u2018emulates' position of the rock on the original chain. This is because nothing prevents multiple variables in the corresponding chains X1... Xn-1 and Y\u2081 ... Yk\u22121 to have value 1 at the same time moment. This situation can be interpreted as multiple rocks thrown at different moments. To properly encode the temporal behaviour of the original model using a 'chain-free' model, the range of X and Y must contain all binary strings of the length n \u2013 1 and k \u2212 1 respectively. In other words, the new values must represent not only in which position the rock is at a given time moment, but also how many rocks there are. The equations then can be defined straightforwardly, and we omit the formal description due to lack of space. This construction provides a more compact graphical representation of the model, by reducing long chains of dependencies. It is easy to verify that as long as we are interested only in the variables {ST, BT, BS}, these two models behave identically wrt any context and time moment. We discuss the notion of temporal equivalence in detail in the next section.\nOur models must adequately represent temporal behaviour of a system. This, in turn, requires a clear temporal semantics of each 'tick' of the model. To illustrate the problem, we present our final example."}, {"title": "Temporal Equivalence for Causal Models", "content": "When dealing with structural equation modelling, we usually have many alternative causal models that describe the same underlying process. These models may have different sets of variables and describe causal dependencies in different ways. Moreover, at some point we may expand the set of variables in a model or reconsider some dependencies due to new discoveries. The only requirement ensuring that different models talk about the same process is that the models share some set of common variables. In such settings, it is crucial to have an adequate notion of equivalence between models to guarantee that different models correctly represent causal (and temporal) properties of some process with respect to the variables of interest (Beckers 2021). Since previous work has focused on static interpretation of SEMs (and so usually applicable only to recursive models), in this section we discuss how model equivalence can be treated in our framework.\nFollowing (Beckers 2021), we assume that, two models M1 and M2 share the same exogenous variables (U\u2081 = U2) and a set of observable variables O\u2286 (V\u2081 \u2229 V2). So, we can only observe the values of and perform interventions on O.\nDefinition 12 (Equivalent Computations). Consider two computations C1 and C2 sharing some set of variables O. We call C1 and C2 temporally equivalent wrt O if\n$\\forall X \\in O, \\forall i > 0 : (X = x) \\in C_1 (i) \\iff (X = x) \\in C_2(i).$\nIn other words, at any step equivalent computations agree on the values of all variables in O.\nDefinition 13 (Model Equivalence). Two models M\u2081 and M2 are temporally equivalent wrt O if for any intervention \u1ef6(n) \u2190 \u1ef9, where \u1ef6 \u2286 O and for any (u,v) there exists v2, such that computations for $(M_1^{\\vec{Y}(\\vec{n}) \\leftarrow \\vec{y}}, \\vec{u},\\vec{v}_1)$ and $(M_2^{\\vec{Y}(\\vec{n}) \\leftarrow \\vec{y}}, \\vec{u},\\vec{v}_2)$ are equivalent, and vice versa.\nTemporal equivalence of causal models guarantees that no matter what intervention $\\vec{Y}(\\vec{n}) \\leftarrow \\vec{y}$ we use, there is no difference in $C_1^{\\vec{Y}(\\vec{n}) \\leftarrow \\vec{y}}$ and $C_2^{\\vec{Y}(\\vec{n}) \\leftarrow \\vec{y}}$ in how the endogenous changes in O proceed with exogenous changes u.\nObservation 1. Models Ma and M\u2081 in Figure 3 are temporally equivalent for O = {ST, BT, BS}.\nIt is easy to check, that whatever the context u, default assignment \u2081 and an intervention $\\vec{Y}(\\vec{n}) \\leftarrow \\vec{y}$ for YO are, there exists a default assignment 2, such that $(M_1^{\\vec{Y}(\\vec{n}) \\leftarrow \\vec{y}}, \\vec{u}, \\vec{v}_1)$ and $(M_2^{\\vec{Y}(\\vec{n}) \\leftarrow \\vec{y}}, \\vec{u}, \\vec{v}_2)$ generate O-equivalent computations. However, this notion of equivalence is too strong to capture the similarities in Example 3.\nObservation 2. Models Ma and M\u266d from Example 3 are not temporally equivalent wrt O = {Start, Pass}.\nWe therefore need a more general notion of equivalence. Note that the models in Example 3 describe identical processes, but on a different time scale. To capture this aspect, we introduce the notion of rescalable equivalence.\nDefinition 14 (Rescalably Equivalent Computations). C2 is rescalably equivalent to C\u2081 wrt O (with a coefficient k \u2208 N) if $\\forall X \\in O, \\forall i > 0 : (X = x) \\in C_1 (i) \\iff (X = x) \\in C_2(i\\cdot k)$.\nInformally, k demonstrates how many ticks of M2 are needed to emulate one tick of M\u2081. Given an intervention \u0178 (n) \u2190 \u1ef9 and a coefficient k, \u0178(\u00f1k) \u2190 \u0177 denotes an intervention, in which all indexes from \u00f1 are multiplied by k.\nDefinition 15 (Rescalably Equivalent Models). A model M2 is rescalably equivalent (with a coefficient k) to M1 wrt O if for any intervention \u0178(n) \u2190 \u1ef9 (\u0178 \u2286 O) and for any (u, v) there exists v2, such the computation for $(M_2^{\\vec{Y}(\\vec{n}k) \\leftarrow \\vec{y}}, \\vec{u}, \\vec{v}_2)$ is rescalably equivalent (with a coefficient k) to the computation for $(M_1^{\\vec{Y}(\\vec{n}) \\leftarrow \\vec{y}}, \\vec{u}, \\vec{v}_1)$.\nObservation 3. Model Mb in Example 3 is rescalably equivalent to Ma wrt O = {Start, Pass} with k = 60.\nWe disagree with Beckers (2021) that it is impossible to come up with a useful notion of equivalence that takes into account 'numerical' properties. We believe that we have proposed such a notion, and it is useful because in temporal settings it is essential to consider not only what happened, but also how much time it took to happen."}, {"title": "Model-Checking", "content": "In this section, we study the model-checking complexity of CPLTL.\nDefinition 16 (Model-checking). The CPLTL model-checking problem is, given (M, u, v,t) and a CPLTL formula 4, to decide whether (M, u,v), t |= p.\nNote that the input to the problem is not necessarily finite or finitely presentable, since only M, and t are finite objects. To ensure that u is finitely presentable, analogously to Definition 6, we require that u is ultimately periodic of type (n, m), i.e. there exist n, m > 0 such that u (k) = u(k+m)"}, {"title": "Related Work", "content": "The computational complexity of verifying actual causation in SEMs have been studied by many researchers, for example, Halpern (2015), Gladyshev et al. (2023) and de Lima and Lorini (2024).\nAlthough Beckers and Vennekens (2018) argued that accounting for temporal information is crucial for actual causation judgments, to the best of our knowledge the framework proposed in this paper is the first attempt to integrate LTL-style temporal reasoning into actual causality settings. Previous work on combining SEM models with temporal reasoning has focused on causal discovery, and several methods for analysing time-series data with SEMs have been developed, e.g., (Assaad, Devijver, and Gaussier 2022; Hyv\u00e4rinen, Khemakhem, and Monti 2023). These methods typically use Full Time Causal Graphs to represent and reason about time-series using SEMs. Full Time Causal Graphs use time-indexed variables (Peters, Janzing, and Sch\u00f6lkopf 2017, Ch. 10) and thus potentially require specifying infinitely many structural equations. However, if all the causal relations remain constant over time, a Full Time Causal Graph can be abbreviated with a (finite) Window Causal Graph or a (finite) Summary Causal Graph (Assaad, Devijver, and Gaussier 2022). Though the dependency graphs of our models resemble both Window and Summary graphs in the way they interpret cyclic dependencies, there are important differences. Firstly, conventional models of time-series allow contemporaneous dependencies, i.e., a (time-indexed) variable Xt may depend on the value of another variable Yt at the same time step t. This modelling choice is usually driven by the observational limitations in the field of causal discovery, e.g., the sampling frequency of the time series may not be able to separate causes and effects. In the field of actual causality, in contrast, we assume that a given causal model provides a complete representation of reality, and thus we assume that the unit interval is sufficiently small to separate causes and subsequent effects. So, contemporaneous relations do not occur in our framework. Secondly, both Full Time and Window graphs allow arbitrary \u2018lagged' dependencies, i.e., a variable X at time t may (directly) depend on another variable Y at time t-n for arbitrary n. In our models we interpret all the direct dependencies as 1-step lagged. We conjecture that for any arbitrary lagged model there exists an equivalent (Definition 13) 1-step lagged model.\nIn contrast to causal discovery, where cyclic causal models are sometimes used, e.g. (Bongers et al. 2021), current research in actual causality is mostly focused on acyclic (recursive) models. To the best of our knowledge, there has been relatively little work which considers non-recursive models, e.g., Halpern (2000) studies axiomatizations for different classes of SEM's, in particularly non-recursive ones, and Halpern (2016, Ch. 2.7) discusses the definition of an actual cause in such models. Finally, Halpern and Peters (2022) introduce so-called Generalized SEMS (GSEM) and axiomatize different classes of GSEMs, including non-recursive ones. Note that in GSEMs structural equations F are replaced with F mapping contexts and interventions to sets of outcomes. We argue that, by staying closer to original formalism, our temporal framework accommodates non-recursive models without significant adjustments.\nDefining the equivalence of causal models is another well-recognized problem both in causal discovery and actual causality. We have already mentioned the work of Beckers (2021), but the problem was recognized already by Verma and Pearl (1990). A similar notion of causal consistency has also been studied in (Rubenstein et al. 2017).\nSimilarly to equivalence, causal consistency, intuitively guarantees that two models agree in their predictions of the effects of interventions. Rubenstein et al. (2017) introduced the notion of exact transformations between SEMs preserving causal consistency, and Willig et al. (2023) proposed another type of transformations, called consolidating mechanisms, to transform large-scale SEMs into smaller, computationally efficient ones. Both of these approaches to consistency-preserving transformations are applicable to time-series models. We believe studying our models as transformations of existing time-series models based on (Rubenstein et al. 2017; Willig et al. 2023) is an interesting direction for future work."}, {"title": "Discussion", "content": "We have proposed a novel conceptual interpretation of existing formalisms in the field of actual causality. While causal models have been developed as a useful tool for representing static dependencies between the variables, we demonstrate that this formalism (with minor modifications) can be treated as a mechanism able to transform a time series of exogenous values into a time series of endogenous ones. Though our approach does not allow us to extract temporal information from existing static models which were not designed with this purpose, it provides new insights and techniques for (temporal) structural equation modelling.\nWe make a number of technical contributions. We introduced the core concept of a computation, which treats structural equations as 'time-lagged' and allows us to 'unwind' a causal scenario (M, u, v) into a time series C of the assignments to V. In addition, we proposed the logic CPLTL, which combines the temporal logic LTL with causal time-sensitive interventions. Finally, we introduced new notions of temporal equivalence for causal models and showed that the model-checking problem for CPLTL is in P.\nWe believe there are a number of interesting directions for future work. First, in this paper we discussed only finite models, however the extension of our framework to models with infinitely many variables (and potentially infinite range) seems to be straightforward. Secondly, the problems of defining a (bi)simulation relation between temporal causal models (which would imply their temporal equivalence) as well as defining weaker notions of temporal equivalence are left open. Finally, another promising direction for future work is adaptation of our framework to probabilistic settings, when we have a probability distribution on temporal contexts or non-deterministic structural equations as recently proposed by Beckers (2024)."}]}