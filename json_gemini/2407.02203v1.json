{"title": "Automatic Adaptation Rule Optimization via Large Language Models", "authors": ["Yusei Ishimizu", "Jialong Li*", "Jinglue Xu", "Jinyu Cai", "Hitoshi Iba", "Kenji Tei"], "abstract": "Rule-based adaptation is a foundational approach to self-adaptation, characterized by its human readability and rapid response. However, building high-performance and robust adaptation rules is often a challenge because it essentially involves searching the optimal design in a complex (variables) space. In response, this paper attempt to employ large language models (LLMs) as a optimizer to construct and optimize adaptation rules, leveraging the common sense and reasoning capabilities inherent in LLMs. Preliminary experiments conducted in SWIM have validated the effectiveness and limitation of our method.", "sections": [{"title": "I. INTRODUCTION", "content": "Self-adaptive systems are engineered to achieve system goals under dynamic conditions and changing environments. Rule-based adaptation, which is a fundamental approach where the adaptation logic is predefined through rules, offers two sig-nificant advantages. Firstly, the human-readable rules enhances the explainability of adaptation. Secondly, since reasoning and planning are not required at runtime, rule-based adaptation is suitable for scenarios that require quick responses.\nHowever, designing high-performance and robust adaptation rules is often challenging. Essentially, it is an optimization problem within a complex design space. The development of adaptation rules typically involves two crucial steps. The initial step is the selection of variables, which includes both observed input variables and control variables, essentially designing the dimensions of the search space. The subsequent step focuses on the searching and optimization of rules, essentially finding the optimal solution within the given search space, for instance, [1] employs reinforcement learning.\nRecently, large language models (LLMs) have emerged as significant tools across various research fields. [2] utilizes LLMs for automatic feature engineering, identifying seman-tically relevant variables from extensive datasets. Meanwhile, [3] explores the potential of LLM-based optimization in trav-eling salesman problem. Given the capabilities demonstrated in these studies, we believe LLMs have strong potential for automatically constructing and optimizing adaptive rules.\nIn this paper, we preliminarily explore the application of LLMs to develop and optimize adaptation rules. Drawing from the established MAPE-K reference architecture, we design a series of prompts tailored for the continuous iteration and optimization of these rules. The effectiveness of this method is initially validated in SWIM (Simulator for Web Infrastructure and Management) [4]."}, {"title": "II. PROPOSAL", "content": "Overview. We consider the optimization of adaptation rules as processes of automatic computing\u00b9, and use the MAPE-K loop to outline our method, as shown in Fig. 1. In this process, the monitor captures system and environment contexts from the interactions between the application system and its (simu-lated) environment, and incorporates them into the knowledge base. Following this, the analyzer and the planner generate the updated adaptation rule, and the executor applies the new rules to the application system. In the subsequent part of this section, we will focus primarily on the knowledge, analyzer, and planner components, as our method predominantly involves these three elements.\nKnowledge base. When utilizing LLMs, it is essential to provide comprehensive context to support their reasoning. In knowledge base, we prepare four types of information crucial for rule construction. First, we include an introduction to the application domain, e.g., the operational logic of the application. Second, we define the adaptation goals, clarifying the objectives that the system aims to achieve. Third, we also describe the variables within the application, detailing both observable variables and those the system can control, i.e., defining the system's observable and controllable spaces. Note that in rule construction, LLMs may only use some of these variables or even define new variables using existing ones."}, {"title": "III. PRELIMINARY EVALUATION", "content": "The evaluation addresses the following research questions: What is the performance level of the adaptation rules designed and optimized by LLMs? How does the performance trend change with iterations of the adaptation rules?\nTarget scenario. We utilize SWIM as the platform to simulate multi-tier web applications, where a load balancer supports multiple servers. Key variables include request arrival rate, server number (adjustable on demand) and the optional content dimmer. The adaptation goal is to maximize a utility function primarily composed of revenue utility minus cost utility. We utilize Clarknet-105m-170 scenario, which is a more challenging setting due to significant fluctuations in request arrivals per unit time. We omit detailed explaination due to space constraints; interested readers can refer to [4].\nLLM and prompt settings. For the experiment, we employ advanced GPT-4 and excellent performance-cost DeepSeek-Coder-V2 (hereafter DS-Coder). Due to the uncertainty in LLMs' outputs, we conduct ten experiments for each LLM, and each experiment include ten iterations. Furthermore, the adaptation rules are asked to be outputed in C++ language code format, allowing for direct execution within SWIM."}, {"title": "IV. CONCLUSION AND FUTURE WORK", "content": "In this paper, we utilize LLMs to automatically design and optimize adaptation rules. Preliminary experiments conducted in the SWIM environment have shown the effectiveness of our method. Future research will primarily focus on two areas. First, we aim to integrate existing optimization algorithms with LLMs to enhance the efficiency. Second, we plan to extend our method to the runtime phase, to allow the automatic evolution of adaptation rules under unforeseen conditions."}]}