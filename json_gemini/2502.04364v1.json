{"title": "Lost in Edits? A \u5165-Compass for AIGC Provenance", "authors": ["Wenhao You", "Bryan Hooi", "Yiwei Wang", "Euijin Choo", "Ming-Hsuan Yang", "Junsong Yuan", "Zi Huang", "Yujun Cai"], "abstract": "Recent advancements in diffusion models have driven the growth of text-guided image editing tools, enabling precise and iterative modifications of synthesized content. However, as these tools become increasingly accessible, they also introduce significant risks of misuse, emphasizing the critical need for robust attribution methods to ensure content authenticity and traceability. Despite the creative potential of such tools, they pose significant challenges for attribution, particularly in adversarial settings where edits can be layered to obscure an image's origins. We propose LAMBDATRACER, a novel latent-space attribution method that robustly identifies and differentiates authentic outputs from manipulated ones without requiring any modifications to generative or editing pipelines. By adaptively calibrating reconstruction losses, LAMBDATRACER remains effective across diverse iterative editing processes, whether automated through text-guided editing tools such as InstructPix2Pix and ControlNet or performed manually with editing software such as Adobe Photoshop. Extensive experiments reveal that our method consistently outperforms baseline approaches in distinguishing maliciously edited images, providing a practical solution to safeguard ownership, creativity, and credibility in the open, fast-evolving AI ecosystems.", "sections": [{"title": "1. Introduction", "content": "Recent advancements in diffusion models, such as Stable Diffusion (Rombach et al., 2022), have significantly propelled the field of image generation. Concurrently, text-guided image editing models like InstructPix2Pix (Brooks et al., 2023) and ControlNet (Zhang et al., 2023; Zhao et al., 2024; Li et al., 2025) have emerged, enabling modifications based on user instructions. Commercial services, including DALL-E 3 (Betker et al., 2023) from OpenAI, Anytext (Tuo et al., 2023) from Alibaba, and Photoshop from Adobe, further democratize access through user-friendly APIs and tools. While these advancements empower creative applications by lowering the barriers to image creation and editing, they simultaneously introduce opportunities for misuse by malicious actors (Verge, 2024a;b; Ke et al., 2025). Specifically, malicious individuals may falsely claim AI-edited photographs or artworks as their original creations, posing significant intellectual property rights and authenticity verification challenges. Moreover, judicial rulings in several countries have recognized that model-generated images meeting originality criteria are eligible for copyright protection(He, 2024), sparking widespread debate (Ren et al., 2024; Ducru et al., 2024; Gaffar & Albarashdi, 2024). These challenges underscore the critical importance of addressing copyright issues associated with synthesized content and highlight the urgent need for methods to detect and trace the origin of images, identify the underlying generation models, and determine whether someone has edited the images.\nExisting methods for detecting the source of generated images can be broadly categorized into two approaches. The first, embedding-based detection methods, involve injecting fingerprint information during training (Tancik et al., 2020;"}, {"title": "A \u5165-Compass for AIGC Provenance", "content": "Yu et al., 2021) or modifying model architectures to embed detectable fingerprints into generated images (Yu et al., 2020; Jeong et al., 2022; Sinitsa & Fried, 2024). However, embedding-based methods are often impractical in open environments due to the infeasibility of universally enforcing watermark embedding during training or generation. The second approach, latent space reverse-engineering detection methods, attempts to trace the origin of an image by working backward. Specifically, these methods evaluate whether an image can be accurately recreated by feeding it back into the model and finding a representation in the model's internal latent space that closely matches the original image (Asnani et al., 2023; Wang et al., 2023b; 2024b;c). This tests whether an image aligns with a model's internal structure, enabling direct source attribution. However, they fail against more sophisticated adversaries who iteratively manipulate images via text-guided editing models, leading to provenance inconsistencies (Figure 1). In contrast, our method, LAMBDATRACER, effectively traces both original and edited images.\nIn this paper, we address these challenges by proposing LAMBDATRACER, a novel origin attribution method specifically designed to tackle the complexities introduced by text-guided image editing models. Our key contributions are:\nRobust and versatile origin attribution: We propose LAMBDATRACER, an alteration-free, inversion-based framework that effectively handles challenges from text-guided models (e.g., InstructPix2Pix (Brooks et al., 2023), ControlNet (Zhang et al., 2023; Zhao et al., 2024; Li et al., 2025)) and image editing tools (e.g., Adobe Photoshop), ensuring reliability in open and adversarial settings. First systematic study on text-guided editing in attribution tasks: We present the first comprehensive analysis of the impact of text-guided editing methods on image attribution, particularly for artistic content. By considering the potential misuse by adversaries, we provide a research context that closely reflects real-world challenges. Flexible loss transformation: We introduce a flexible loss transformation approach based on an improved Box-Cox Transformation (Box & Cox, 1964). This method significantly enhances the separability of overlapping distributions, improving attribution accuracy across diverse scenarios. State-of-the-art performance: Our method outperforms baselines in adversarial settings, achieving the best attribution accuracy across both generated and edited images."}, {"title": "2. Related Work", "content": "Stable Diffusion Generative Models. Stable Diffusion (Rombach et al., 2022) has emerged as a major advancement in generative models, surpassing traditional models such as GANs (Goodfellow et al., 2014; Radford, 2015; Karras et al., 2019) and VAEs (Kingma, 2013; Tolstikhin et al., 2017) in terms of computational efficiency, scalability, and output quality. Stable Diffusion employs a denoising diffusion process within a low-dimensional latent space, enhancing robustness and significantly reducing memory and computational requirements compared to pixel-space methods (Ho et al., 2020; Song et al., 2020) while maintaining high-quality image generation. Across different versions, Stable Diffusion has introduced key improvements in model architecture, training datasets, and noise-handling techniques, resulting in higher resolution outputs and improved alignment with textual prompts (Rombach et al., 2022). These advancements have transformed creative applications, enabling breakthroughs in art generation, design prototyping, and visual storytelling (Han & Cai, 2023; Wu et al., 2023; Wang et al., 2024a).\nText-guided Image Editing Methods. Text-guided image editing methods (Li et al., 2020; Choi et al., 2023; Wang et al., 2023a; Ravi et al., 2023) have seen significant progress with the advent of conditional diffusion models (Nichol & Dhariwal, 2021; Dhariwal & Nichol, 2021), which enhance controllability and flexibility in generating or editing images. InstructPix2Pix (Brooks et al., 2023) is a conditional diffusion model designed explicitly for text-guided image editing tasks. It takes an input image and a natural language instruction as conditions, enabling precise edits to the image. By fine-tuning instruction-image pairs, it excels in tasks like style transfer and scene adjustments. Similarly, ControlNet (Zhang et al., 2023; Zhao et al., 2024; Li et al., 2025) extends the framework of conditional diffusion models by incorporating structural guidance inputs such as edge maps, pose data or segmentation maps. ControlNet preserves spatial coherence and structural integrity while enabling high-fidelity edits based on textual and structural conditions. While these models represent state-of-the-art advancements in text-guided image editing, they also introduce challenges for origin attribution. Specifically, iterative use of these models can produce images with complex modification histories, complicating efforts to trace the source or the sequence of edits. Addressing these challenges is critical for ensuring content traceability and accountability.\nGenerative Content Provenance Methods. Current methods for tracing the origins of generated images can be broadly divided into two main approaches: Embedding-based detection and latent space reverse-engineering. Embedding-based detection methods (Tancik et al., 2020; Yu et al., 2021; 2020; Jeong et al., 2022; Sinitsa & Fried, 2024), often referred to as fingerprinting or watermarking techniques, embed unique identifiers into models during training to trace the origin of model-generated images. These identifiers can later be detected in generated outputs to verify image provenance. While effective, they require training modifications, making them impractical for pre-trained or open-source models, and are vulnerable to adversarial removal or forgery (Xu et al., 2020; Sun et al., 2021). Ad-"}, {"title": "A \u5165-Compass for AIGC Provenance", "content": "ditionally, embedding increases complexity and frequently affects image quality.\nLatent space reverse-engineering methods (Creswell & Bharath, 2018; Wang et al., 2023b; 2024b;c) trace the origin of generated images by optimizing latent vectors to minimize reconstruction loss, thereby avoiding model modifications. However, these methods are limited to original model-generated images and fail against cumulative perturbations from iterative text-guided editing models (Brooks et al., 2023; Zhang et al., 2023; Zhao et al., 2024; Li et al., 2025), limiting effectiveness in open environments. To address this gap, we propose LAMBDATRACER, a more robust latent space reverse-engineering approach that can both attribute origins and detect iterative modifications, substantially expanding the scope of provenance tracing in real-world scenarios."}, {"title": "3. Latent Distribution Analysis", "content": "As discussed in \u00a7 2, embedding-based methods fail in open-source contexts due to their reliance on model modifications. In contrast, latent space reverse-engineering methods are compromised by the cumulative distortions from iterative editing. Among these, threshold-based classification (Wang et al., 2023b) is the most effective. However, this approach struggles in scenarios involving perturbed or edited images due to significant overlap in the reconstruction loss distributions between different categories, such as pristine model-generated images and modified outputs. To illustrate how repeated modifications blur the line between generated and edited outputs, we analyze the distribution of reconstruction losses in this section, providing both empirical and theoretical insights into this overlap."}, {"title": "3.1. Quantitative Analysis of Distribution", "content": "We examine the reconstructed Mean Squared Error (MSE) loss distributions across different image categories by calculating the overlap between their probability density functions (PDF), estimated using Gaussian Kernel Density Estimation (KDE) (Davis et al., 2011). Equation 1 illustrates the KDE formulation, which provides smooth estimates of the PDFs for the given data points. Once the PDFs, f1 and f2, are estimated, Equation 2 illustrates the overlap calculation, where higher overlap values indicate reduced separability between the distributions.\n$f(x) = \\frac{1}{nh\\sqrt{2\\pi}} \\sum_{i=1}^{n} exp(-\\frac{(x - x_i)^2}{2h^2})$\n$O(x) = \\int_{-\\infty}^{\\infty} min(f_1(x), f_2(x))dx$\nwhere n is the number of data points, h is the bandwidth, and xi represents each data point."}, {"title": "3.2. Theoretical Analysis of Distribution", "content": "We can formalize the accumulation of editing perturbations in Equation 3.\n$z_n = z_0 + \\sum_{i=1}^{n} f(z_{i-1}, \\theta_i),$"}, {"title": "A \u5165-Compass for AIGC Provenance", "content": "where z0 represents the initial latent vector and f (zi\u22121, \u03b8i) denotes the nonlinear transformation included by the editing model at the i-th step, parameterized by \u03b8i.\nThe equation follows from an iterative formulation, where each editing step applies a transformation conditioned on the previous latent state, modelling the accumulated modifications in a structured way. Each edit perturbs the latent representation non-linearly, leading to a gradual distributional drift. The term \u2211n=1 f(zi\u22121,\u03b8i) directly captures how small perturbations accumulate over multiple edits, leading to progressive drift. Over multiple editing steps, this drift may push zn away from the original data manifold, causing it to overlap with the distributions of other categories. This phenomenon explains why distinguishing between original and edited content becomes increasingly difficult: as modifications accumulate, the latent space regions that initially correspond to distinct classes blur together. From a discriminative perspective, this drift directly impacts classification tasks. If zn deviates significantly from the original distribution but aligns with other categories, a classifier trained on the original data distribution may struggle to differentiate manipulated content. This provides intuitive reasoning for why standard reconstruction loss comparison is insufficient: reconstruction losses typically measure pixel-wise or feature-level similarity without explicitly accounting for how edits influence class separability in the latent space."}, {"title": "3.3. Key Insights and Motivation", "content": "These quantitative and theoretical analyses reveal two key insights. First, iterative editing introduces cumulative distortions that significantly alter the distribution of reconstruction losses, with overlap rates increasing by up to 86% after multiple edits (as shown in Fig. 2). Second, the non-linear nature of these distortions suggests that conventional linear approaches would be insufficient for reliable attribution. These findings highlight the need for an adaptive approach that can effectively handle varying degrees of distribution overlap while preserving discriminative features."}, {"title": "4. Methodology", "content": "As advanced generative models and easily accessible editing tools amplify threats to content authenticity and intellectual property, a robust attribution framework for real-world scenarios involving iterative text-guided editing is critically needed. We first provide a formal definition of our attribution task (\u00a7 4.1). Next, we provide an overview of our proposed LAMBDATRACER system (\u00a7 4.2), followed by a detailed explanation of the transformation design (\u00a7 4.3) and a dynamic parameter selection strategy (\u00a7 4.4). We describe our lightweight supervised classification mechanism (\u00a7 4.5)."}, {"title": "4.1. Problem Formulation", "content": "Attribution Task. Our goal is to attribute a target image It, which is directly generated by a generative model (Mg) or modified by an editing model (Me). This involves distinguishing between images directly generated by a base generative model (e.g., Stable Diffusion (Rombach et al., 2022)) and those modified iteratively using text-guided editing tools such as InstructPix2Pix (Brooks et al., 2023) or ControlNet (Zhang et al., 2023). Formally, this task can be framed as a binary classification problem, where the objective is to design a mapping function F that takes as input the target image It and outputs a label y \u2208 {1,2}. The mapping function can be expressed as F : It \u2194 y."}, {"title": "4.2. Overview of LAMBDATRACER", "content": "We propose LAMBDATRACER, a robust attribution approach tailored to scenarios where an image may have undergone multiple text-guided edits or other manipulations. By combining a carefully chosen loss transformation with dynamic parameter selection, our method aims to reduce the overlap of reconstruction-error distributions for generated and iteratively edited images and maintain consistent performance even under adversarial manipulations. The framework operates without embedding watermarks or modifying source models, making it viable in real-world, open environments. Fig. 3 illustrates the general process of LAMBDATRACER."}, {"title": "4.3. Transformation Design", "content": "To handle varying degrees of distribution overlap, it is important to choose a proper transformation.\nComparison of Transformations. We evaluate several transformations, including Z-score standardization, logarithmic transformation, exponential transformation, and power transformation (see Appendix B for more details). We find that Z-score standardization, while effective for normalizing data scales, fails to address the non-linear distortions introduced by iterative edits. Logarithmic transformation compresses the right tail of skewed distributions but offers limited flexibility in capturing subtle differences across diverse editing intensities. Although theoretically capable of amplifying differences, exponential transformation tends to exaggerate outliers and noise. Power transformation provides greater flexibility through its power parameter but lacks the adaptability to handle varying editing intensities effectively.\nThese approaches suffer from a fundamental limitation: they apply a fixed transformation regardless of the underlying distribution characteristics. This inflexibility makes them inadequate for handling the complex distortions introduced by repeated edits, often degrading key attribution features. To address these limitations, we propose using the Box-Cox transformation (Box & Cox, 1964), which offers adaptive"}, {"title": "A \u5165-Compass for AIGC Provenance", "content": "flexibility through its tunable parameter \u03bb.\nBox-Cox Transformation. We argue that Box-Cox transformation (Box & Cox, 1964) is the most suitable choice for our task for the following reasons. First, it addresses skewness in the loss distributions by compressing heavily skewed tails and pushing the data toward a more symmetric shape. This property is particularly crucial for iterative edits, where repeated modifications introduce cumulative distortions. Second, its tunable parameter A provides flexible control over the transformation intensity, allowing adaptation to diverse editing patterns. Finally, the transformation preserves the monotonic ordering of the data, ensuring that critical distinctions in reconstruction errors are not obscured. Equation 4 presents the general form of the Box-Cox transformation, where A governs the form and strength of the power-based adjustment. Applying Box-Cox to the reconstructed loss values substantially improved the separability of generated versus edited images, particularly in highly adversarial settings.\n$T_\\lambda(y_i) = \\begin{cases} \\frac{y_i^\\lambda - 1}{\\lambda}, & \\text{if } \\lambda \\neq 0, \\\\ \\ln(y_i), & \\text{if } \\lambda = 0, \\end{cases}$"}, {"title": "4.4. A Selection Strategies", "content": "One of the key challenges in applying the Box-Cox transformation is selecting the optimal value of X. An effective strategy must balance adaptability to various data distributions and computational efficiency. To address this, we propose three approaches: Maximum Likelihood Estimation (MLE),"}, {"title": "A \u5165-Compass for AIGC Provenance", "content": "Strategies of A Selection. Askew is arg minx |Skew (Tx (data))|. Equation 5 illustrates the skewness of the transformed data.\nKurt is arg min\u5165 |Kurtosis (Tx (data)) \u2013 c, where c is the constant to adjust the kurtosis. Equation 6 illustrates the kurtosis of the transformed data.\n$Skew (T_\\lambda(data)) = \\frac{\\frac{1}{n} \\sum_{i=1}^{n} (\\frac{T_\\lambda(x_i) - \\mu_\\lambda}{\\sigma_\\lambda})^3}{\\sigma_\\lambda^3},$\nwhere Tx (xi) denotes the value of the data point xi after applying the Box-Cox transformation with current temporary A (i.e. Equation 4), \u03bc\u03bb denotes the mean of the transformed data Tx (data), \u03c3\u2081 denotes the standard deviation of the transformed data Tx (data), and n is the total number of data points.\n$Kurtosis (T_\\lambda(data)) = \\frac{\\frac{1}{n} \\sum_{i=1}^{n} (\\frac{T_\\lambda(x_i) - \\mu_\\lambda}{\\sigma_\\lambda})^4}{\\sigma_\\lambda^4} - 3,$"}, {"title": "A X-Compass for AIGC Provenance", "content": "B. Methodology: Additional Transformations\nZ-score Standardization is a widely used linear transformation that scales data to have a mean of zero and a standard deviation of one, ensuring uniformity and computational efficiency (Vapnik et al., 1996; Cervantes et al., 2020). However, its linear nature is insufficient for distinguishing overlapping distributions with subtle nonlinear variations, as it fails to capture complex patterns in the data. This limitation highlights the need for nonlinear transformations to enhance separability in such scenarios.\nLogarithmic Transformation is adequate for handling right-skewed data by compressing large values and stabilizing variance, reducing the influence of outliers. However, their fixed transformation intensity limits their ability to amplify minor differences in overlapping regions, making them less suitable for complex distributions requiring adaptive separability enhancements.\nExponential Transformation effectively reduces left-skewness by amplifying smaller values, enhancing separability in specific cases. However, they are unsuitable for our right-skewed data, as they exacerbate skewness and distort the intrinsic structure, compromising essential distinguishing features.\nPower Transformation generalizes logarithmic and exponential methods by applying flexible powers to data, effectively reducing skewness and stabilizing variance across diverse distributions. While they retain essential data characteristics, their fixed parameters limit adaptability to varying distributions, leading to suboptimal separability in complex, overlapping datasets."}, {"title": "5. Experiment", "content": "This section comprehensively evaluates LAMBDATRACER. We outline the experimental settings, including model choices, prompt design, dataset composition, baseline selection, and metrics definition (\u00a7 5.1). Next, we compare LAMBDATRACER against the baseline (Wang et al., 2024c) in detecting various manipulated images (\u00a7 5.2). We present an ablation study (\u00a7 5.3) to examine the contribution of each component in LAMBDATRACER in achieving high performance. Then, we demonstrate the scalability and adaptability of our A-selection mechanism (\u00a7 5.4). Together, these analyses underscore the effectiveness and robustness of our approach in dynamic, open-environment scenarios."}, {"title": "5.1. Experiment Setup", "content": "Models. The experiments utilize several state-of-the-art generative and editing models, including Stable Diffusions (v1-5, v2-base, XL-1.0-base) (Rombach et al., 2022), Kandinsky (Liu et al., 2024), Anytext (Tuo et al., 2023), ControlNet (Zhang et al., 2023; Zhao et al., 2024; Li et al., 2025), and InstructPix2Pix (Brooks et al., 2023).\nPrompts. For generative models, we select the first 20 prompts from LATENTTRACER (Wang et al., 2024c) to ensure consistency and comparability. Additionally, we designed 20 corresponding prompts specifically for text-guided editing methods (Brooks et al., 2023; Zhang et al., 2023; Zhao et al., 2024; Li et al., 2025), systematically evaluating the effects of iterative editing while focusing on diverse artistic themes and attributes.\nDatasets. We extend the datasets by applying modifications through Adobe Photoshop and iterative text-guided editing methods using InstructPix2Pix (Brooks et al., 2023) and ControlNet (Zhang et al., 2023; Zhao et al., 2024; Li et al., 2025), ensuring a broader and more diverse dataset for experimentation. Specifically, the Adversarial Editing Dataset (AE-Dataset) includes 18 categories: 5 for generative models, 2 for manual background modification using Adobe Photoshop, and 11 for iterative text-guided editing. For iterative processing, the same text-guided editing method is applied repeatedly on a single generated image for 1 to 5 iterations, simulating progressive modifications. Each category contains 20 samples per model, with 20 random seeds per sample, resulting in 400 images per category. In total, our AE-Dataset comprises 7200 images.\nBaseline. We choose LATENTTRACER (Wang et al., 2024c) as the baseline for comparison. Unlike embedding-based methods (e.g., watermarking and model fingerprinting) that require additional steps during the training or generation phases, LATENTTRACER is the method capable of achieving alteration-free origin attribution. Moreover, LATENTTRACER has been shown to outperform its predecessor, RONAN (Wang et al., 2024b), making it a more suitable and robust benchmark for evaluating our proposed approach.\nEvaluation Metrics. We focus on Precision, Recall, and F1-score specifically for modified images. Precision mea-"}, {"title": "A X-Compass for AIGC Provenance", "content": "sures how many flagged images are modified, while Recall measures how many modifications are correctly detected. The F1-score balances both, providing a comprehensive assessment of detection performance. By measuring these metrics, we show that our approach enhances the robustness of manipulation detection, ensuring more reliable differentiation between original and altered content. Formulas can be found in Appendix D."}, {"title": "5.2. Detection Performance on Manipulated Images", "content": "To evaluate the effectiveness of our proposed method in distinguishing manipulated images, we conducted a series of experiments comparing it against the baseline LATENT-TRACER(Wang et al., 2024c) using AE-Dataset. Precision, Recall, and F1-Score were measured across five iterative editing steps and Photoshop-modified images, with aggregated results reported to provide an overall assessment.\nTable 1 illustrates that our LAMBDATRACER consistently outperforms the baseline in both Recall and F1-Score across all manipulations. Specifically, the Recall scores demonstrate that LAMBDATRACER is more effective in detecting actual modifications, which is crucial for identifying malicious users attempting to manipulate content. The F1-Scores further confirm the balanced improvement in precision and recall, underscoring the robustness of LAMBDATRACER in maintaining high attribution accuracy. Notably, our ablation study underscores the Box-Cox transformation's role in enhancing latent space separability, leading to improved detection performance.\nThese results highlight the superiority of LAMBDATRACER in accurately distinguishing various types of modified content, thereby enhancing the reliability of attribution tasks. Its ability to maintain high performance across multiple editing iterations and manual Photoshop modifications demonstrates LAMBDATRACER's adaptability and effectiveness in real-world open environments, where content manipulation"}, {"title": "A X-Compass for AIGC Provenance", "content": "may occur repeatedly or involve diverse techniques."}, {"title": "5.3. Analysis of Ablation Studies", "content": "Effectiveness of Box-Cox Transformation. To validate the effectiveness of the proposed Box-Cox transformation, we conducted experiments by removing the Box-Cox transformation and using only a simplified supervised learning version of LAMBDATRACER. As shown in Table 2, the F1-Score dropped from 0.7581 to 0.6453 without the Box-Cox transformation.\nComparison with Alternative Transformations. To further assess the effectiveness of Box-Cox compared to other transformations, we replaced it with four widely used alternatives: logarithmic, power, exponential, and z-score transformations. As shown in Table 2, LAMBDATRACER with Box-Cox significantly outperformed other variants. These findings underscore the unique ability of the Box-Cox transformation to optimize the separability of generated and"}, {"title": "5.4. Adaptive X-Selection for Generalized Performance", "content": "To accommodate the rapid emergence of new generative models, we redefined the composition of the positive class in this study. Specifically, we form seven positive groups to evaluate how different combinations of generative models influence detection performance (detailed in Appendix F). This redesign aims to enhance the generalizability of the proposed method across diverse generative sources. Figure 4 compares the performance of the baseline (Wang et al., 2024c) and our LAMBDATRACER across seven positive groups. LAMBDATRACER consistently outperforms the baseline in all three metrics, demonstrating its robustness in accurately distinguishing manipulated content.\nTable 3 further reports the binary classification accuracy of both methods. Across all seven positive groups, LAMBDATRACER achieves higher accuracy, showcasing the effectiveness of its adaptive A-selection mechanism in handling variations across multiple generative models and manipulation types. These findings affirm that LAMBDATRACER not only excels in detecting manipulated images but also maintains strong scalability and generalization, making it well-suited for future open-environment scenarios with continuously evolving generative technologies."}, {"title": "6. Conclusion", "content": "In this paper, we introduced LAMBDATRACER, a novel inversion-based origin attribution method designed to predict whether an image is a forged original in open and adversarial environments. By employing a newly designed Box-Cox transformation to optimize the loss function, LAMBDATRACER enhances the model's ability to classify images accurately, distinguishing genuine originals from those modified by advanced text-guided editing models. Experimental results demonstrate that LAMBDATRACER outperforms existing methods, achieving high accuracy in detecting forged images even after iterative editing. Specifically, it effectively identifies images modified by sophisticated editing tools such as InstructPix2Pix and ControlNet, providing reliable provenance tracing for model-generated content. This work offers a robust solution for copyright protection and the responsible commercialization of diffusion models. Future work includes enhancing the interpretability of LAMBDATRACER through visualization techniques that provide intuitive insights into its classification decisions."}, {"title": "Impact Statement", "content": "The primary purpose of this work is to combat copyright infringement and unauthorized modifications of model-generated content by providing robust origin attribution capabilities. LAMBDATRACER is designed to ensure the responsible use of generative models, particularly in creative domains, by tracing and identifying misuse. This technology is not intended for use by adversarial actors or those seeking to exploit generative models for unlawful purposes. We encourage its application within ethical and legal frameworks to safeguard intellectual property while promoting responsible artificial intelligence practices."}]}