{"title": "LinkThief: Combining Generalized Structure Knowledge with Node Similarity for Link Stealing Attack against GNN", "authors": ["Yuxing Zhang", "Siyuan Meng", "Chunchun Chen", "Mengyao Peng", "Hongyan Gu", "Xinli Huang"], "abstract": "Graph neural networks (GNNs) have a wide range of applications in multimedia. Recent studies have shown that Graph neural networks (GNNs) are vulnerable to link stealing attacks, which infers the existence of edges in the target GNN's training graph. Existing attacks are usually based on the assumption that links exist between two nodes that share similar posteriors; however, they fail to focus on links that do not hold under this assumption. To this end, we propose LinkThief, an improved link stealing attack that combines generalized structure knowledge with node similarity, in a scenario where the attackers' background knowledge contains partially leaked target graph and shadow graph. Specifically, to equip the attack model with insights into the link structure spanning both the shadow graph and the target graph, we introduce the idea of creating a Shadow-Target Bridge Graph and extracting edge subgraph structure features from it. Through theoretical analysis from the perspective of privacy theft, we first explore how to implement the aforementioned ideas. Building upon the findings, we design the Bridge Graph Generator to construct the Shadow-Target Bridge Graph. Then, the subgraph around the link is sampled by the Edge Subgraph Preparation Module. Finally, the Edge Structure Feature Extractor is designed to obtain generalized structure knowledge, which is combined with node similarity to form the features provided to the attack model. Extensive experiments validate the correctness of theoretical analysis and demonstrate that LinkThief still effectively steals links without extra assumptions. Our code is available here", "sections": [{"title": "1 Introduction", "content": "In recent years, Graph Neural Networks (GNNs) have experienced significant development. Despite their excellent performance in various multimedia applications [9, 26, 34, 38, 40, 45], recent studies have shown that graph neural networks are vulnerable to privacy attacks such as model extraction attacks [25, 47], property inference attacks [33, 46], and membership inference attacks [6, 16, 23]. In this paper, we focus on link stealing attack, which is a link-level membership inference attack aimed at inferring whether a specific link exists in the training graph of the target GNN model.\nGNNs obtain the context of nodes through a message passing mechanism [11, 18]. This process results in neighbors having similar posteriors, which, in turn, reveals private relationships between nodes. After the model owner has deployed and published the GNN online model, attackers can launch the link stealing attack by querying the target GNNs (i.e., a black-box setting) to obtain the nodes' posteriors, which poses a risk of link privacy leakage. For example, in a GNN-based physician recommendation system [3, 22], the patient and the heart specialist are represented as two nodes in the graph. The attackers hijack the representations of two nodes and input them into the attack model to infer the existence of a link between the two nodes and then infer whether the patient has a heart disease. This triggers a trust crisis in GNN systems.\nAll existing link stealing attacks [15, 35, 41] utilize the similarity between the posteriors of two nodes as features to train the attack model. However, this may not be applicable to all links. For example, in a task of predicting the gender of a user in a social network, users of different genders have different posteriors, indicating that there may be no connection between users of different genders. Yet, in real-world social networks, it is common for users of opposite genders to follow each other. Therefore, we need additional information to guide the attack model to steal this type of link."}, {"title": "2 PRELIMINARIES", "content": null}, {"title": "2.1 Victim GNNs Model", "content": "GNNs leverage graph structures and node features to learn low-dimensional representations for each node. Mainstream GNNs [13, 18, 30, 39] currently follow the message passing mechanism. For example, in node classification tasks, GNNs aggregate rich information from higher-order neighbors by stacking multiple graph convolutional layers, and finally output node classification results in the form of probability distributions over a set of labels, which are commonly referred to as posterior probabilities. Due to the message passing mechanism, neighbors have similar posteriors, which, in turn, reveal private relationships between nodes."}, {"title": "2.2 Threat Model", "content": "Link Stealing Attack (LSA) aims to infer the existence of links in the training data of the target model. The vanilla LSA assumes three adversary's background knowledge: target dataset's nodes' features, target dataset's partially leaked graph, shadow dataset. Whether the attackers possess each of these three items is a binary choice. Therefore, the attacker has eight different types of background knowledge, corresponding to eight different link stealing attacks. In this paper, we assume that the background knowledge includes the target dataset's partially leaked graph and shadow dataset, which corresponds to LSA-4 in [15]. These two background knowledge are easily accessible in real-world settings. For instance, in a scenario where some user relationships of a social networking company have been disclosed, a rival company may use them as a partial target graph and leverage its own user social network as a shadow dataset to train a link stealing model aimed at trade secrets.\nThe attack pipeline is shown in Fig.1. Consider a target GNN model that can be queried by any user through black-box access. The output for a given node is a posterior vector, where the i-th probability represents the likelihood that the node belongs to the i-th class. During the preparation phase, attackers train a shadow GNN model to mimic the target GNN using the shadow dataset. After obtaining the partially leaked target graph, target model, and shadow model, attackers query them to obtain the posteriors of nodes in both the shadow graph and the partial target graph. Relying on the principle that similar nodes are more likely to be connected, attackers compute 12 posterior similarity metrics proposed in [15] for pairs of nodes. These 12 metrics constitute the attack features that are input into an attack model to predict the existence of links. During the attack phase, attackers query the posteriors of two nodes to be targeted using the target GNN model. The rest of the attack flow is the same as the preparation phase."}, {"title": "3 EXPLORATORY ANALYSIS", "content": null}, {"title": "3.1 Notations", "content": "Let us denote a graph with N nodes as $G = (V,E,X)$, where V = {01,..., UN} is the node set and $& is the edge set with |8| edges. $A = {a_{ij}}_{N\u00d7N}$ is an adjacency matrix corresponding to & ($a_{ij}=1$ means the link between node i and j exists and 0 otherwise). $X \u2208 R^{N\u00d7F}$ and $Z \u2208 R^{N\u00d7D}$ denote the node feature and embedding matrices, respectively, where F and D are the dimensions of the node feature and embedding, respectively. $x_i$ and $z_i$ denote the i-th row of X and Z, respectively. It is noteworthy that X are equal to the queried posteriors, not the initial node features or attributes used in training for either the target or shadow GNN. This is because the attacker can only query the posteriors of nodes but cannot obtain their initial features. We use $G^S = (V^S, E^S, X^S)$ to denote the shadow graph and $G^t = (V^t,&^t, X^t)$ to denote the target graph. Correspondingly, the adjacency matrix of $G^s$ and $G^t$ are denoted as $A^s$ and $A^t$, respectively. We refer to the partial target graph that the attacker is aware of as $G_{t\\_leak} = (V^t,&_{t\\_leak}, X^t)$, while those unknown to the attacker are termed $G_{t\\_safe} = (V^t,&_{t\\_safe}, x^t)$, where $\\&^t = \\&_{t\\_leak} \u222a \\&_{t\\_safe}$. Similarly, $A^t = A_{t\\_leak} + A_{t\\_safe}$. We use $G_{i,j}^r = (V_{i,j}^r, \\&_{i,j}^r, X_{i,j}^r)$ to denote the edge subgraph (i.e., the subgraph around the link) of $(v_i, v_j)$ within r hops."}, {"title": "3.2 Bottlenecks of Using Nodes Similarity as Attack Feature", "content": "Previous link stealing attacks [15, 35, 41] exploit similarities as attack features to train attack models under the assumption of homogeneity, which has a high probability of success for most link stealing attacks. However, for some links, the posteriors of two nodes may not be similar, which leads to the failure of similarity-based attack methods. For a pair of nodes $(v_i, v_j)$, the attacker aims to make a choice between the following two hypotheses:\n\u2022 Null hypothesis $H_0$: In the graph G, there exists a link between nodes $v_i$ and $v_j$, that is, $e_{ij} = (v_i, v_j) \u2208 E$.\n\u2022 Alternative hypothesis $H_1$: In the graph G, there exists no link between nodes $v_i$ and $v_j$, that is, $e_{ij} = (v_i, v_j) \u2209 E$.\nGiven these two hypotheses $H_0$ and $H_1$, we use $\u0124_0$ and $\u0124_1$ to denote the attacker's predictions, where $\u0124_0$ represents the attacker accepts the null hypothesis, while $\u0124_1$ signifies the attacker accepts the alternative hypothesis. We categorize all links into four classes: True Positive(TP, truth is $H_1$ and attacker accepts $\u0124_1$), False Negative(FN, truth is $H_1$ yet attacker accepts $\u0124_0$), True Negative(TN, truth is $H_0$ and attacker accepts $\u0124_0$), False Positive(FP, truth is $H_0$ but attacker accepts $\u0124_1$). To further illustrate the bottleneck of relying solely on similarities as attack features, we visualize the attack features of these four types of links using a scatter plot generated by the t-SNE algorithm. Fig. 2 (a)(b) are from Twitch and Facebook, two social networks from the real world, respectively. We observe that most links are successfully stolen, belonging to TP and TN, but there are still a small number of links that failed to be stolen, belonging to FN and FP. Edges classified as FN(FP) show considerable discrepancies in their attack features compared to those classified as TP(TN). This indicates that relying solely on similarity as the criterion for edge existence is insufficient for edges belonging to FN and FP."}, {"title": "3.3 Shadow-Target Bridge Graph", "content": "Given the bottleneck of attack models that depend solely on node similarities, we need additional link knowledge. The local enclosing subgraph around each link contains rich neighborhood structural information [42, 51]. Therefore, we can extract structural features from the edge subgraph as link knowledge, which serves as a supplement to attack features based on node similarity.\nIn practical scenarios, the number of leaked links is significantly fewer than those that remain safe in the target graph, i.e., $|\\&_{t\\_leak}| \u00ab |\\&_{t\\_safe} |$. This results in a small attack training dataset, making it challenging to capture comprehensive structure-aware edge subgraph representations in the target graph. To acquire universal and generalizable edge structural features, we introduce the shadow graph [23] that provides supplementary structural knowledge to the attack model. However, the shadow graph is inherently different from the target graph, which inevitably leads to structure shift and covariate shift between the two graphs [19, 37]. Furthermore, the edges within the shadow and target graphs exhibit different neighbor structures, implying that the edge subgraph structure features may be distinct [28, 50]. Inspired by [4, 5], we try to build a bridge between the shadow graph and partial target graph to form the Shadow-Target Bridge Graph. The following is the definition:\nDefinition 3.1 (Shadow-Target Bridge Graph). Given the partial target graph $G_{t\\_leak}$ and the shadow graph $G^\u00ba$, the Shadow-Target Bridge Graph is represented as $G_{st} = (V_{st}, E_{st},x_{st})$, where $V_{st} = V^S\u016aV^t$ is the nodes set, $E_{st} = E^s U\\&_{t\\_leak} \u222a\\&_{bridge}$ is the edges set where $\\&_{bridge}$ serves as intermediaries connecting two graphs, and $X_{st}$ is the concatenated feature matrix of $X^s$ and $X^t$.\nThe Shadow-Target Bridge Graph defines the scope of knowledge transfer and distribution alignment under distribution shift between nodes, thereby forming a global perspective of the attack model. We can extract the edge subgraph around the link on the Shadow-Target Bridge Graph, and input them into the edge structure feature extractor, which comprises GNN encoders, to derive link structure features. This approach treats the structure features as generalized knowledge across the shadow graph and target graph."}, {"title": "3.4 Theoretical Analysis of Privacy Theft", "content": "Although we proposed above to tackle the acquisition of generalizable link structure knowledge by sampling edge subgraphs on the Shadow-Target Bridge Graph, we still encounter two problems:\nRQ1: How can the shadow graph be effectively connected to the partial target graph to construct the bridge graph?"}, {"title": "3.4.1 Problem Setup", "content": "Since edge subgraph sampled from the bridge graph contains nodes from both partial target graph and shadow graph, we start with a formal definition of target nodes density:\nDefinition 3.2 (Density of target nodes in the edge subgraph).\n$D = \\frac{|{u|u \u2208 N}|}{|V_{i,j}^r|} \\space  \\frac{\\{N_a > n|n}\\} + \\{N_a > n|n}\\}$ \n(1)\nwhere $V_{i,j}^r$ is the nodes set of the edge subgraph $G_{i,j}^r$. $N_a$ is the neighbor set of node v that belong to partial target graph, and $N_b$ is the neighbor set of node v that belong to shadow graph. D ranges from 0 to 1, with a larger D indicating a higher proportion of nodes from partial target graph in the edge subgraph.\nDifferent from [48], which uses the distribution distance of two different sensitive groups to measure the privacy leakage of message passing, we define the privacy theft of edge subgraph structure feature extraction as follows:\nDefinition 3.3 (Measurement of privacy theft for edge subgraph structure feature extraction). Given the link and its corresponding edge subgraph, the nodes' features and representations after edge subgraph structure feature extraction follow the distributions P and Q, respectively. Privacy theft for edge subgraph structure feature extraction is measured by the distance between P and Q.\nFor the convenience of subsequent analysis, we employ the Wasserstein distance to measure the distance between two multivariate normal distributions $P ~ N(\u00b5_p, \u03a3_p)$ and $Q ~ N(\u00b5_q, \u03a3_q)$:\n$W[P,Q] = \\sqrt{(\u03bc_\u03c1-\u03bc_q)^T(\u03bc_\u03c1-\u03bc_q)+Tr(\u03a3_p)+Tr(\u03a3_q)-2Tr((\u03a3_\u03c1\u03a3_q)^{\\frac{1}{2}})} $ \n(2)\nIntuitively, privacy theft in structure feature extraction can be understood as the extent to which nodes extract features from their neighbors. When the distributions between features and learned representations are farther apart, it means that each node in the edge subgraph extracts more context from its neighbors. The sum of these extractions represents the privacy theft of the edge subgraph structure feature extraction. Larger privacy theft means that the attacker obtains more structural information about the link. Therefore, it is easier to infer the existence of a connection."}, {"title": "3.4.2 Theoretical Analysis", "content": "Contextual Stochastic Block Model (CS BM) [8, 21] is a random graph model that adeptly combines graph structure with node features, enabling the effective simulation of graphs with community structures. Since the edge subgraph includes nodes from both the partial target graph and shadow graph, we employ CSBM for our analysis, treating the edge subgraph with n nodes as a random graph $G_{i,j}^r ~ (n, p, q, \u00b5, k\u00b5, d)$. Each node is associated with a community label: Vt represent the target nodes and Vs represent the shadow nodes. We construct edges based on two types of probabilities: if a node is linked to $V^t$, an edge between them is generated with a probability of p; otherwise, if it is linked to $V^s$, the probability is q. Based on community labels, d-dimensional feature matrix X are sampled differently: we denote feature matrix of $V^t$ as $X^t$, each dimension of $X^t$ follows $N(\u03bc, 1)$, whereas those of $V^s$ as $X^s$, each dimension of $X^s$ follows $N(k\u03bc, 1)$. Thus, $X^t$ follow the normal distribution $N(\u03bc_{xt}, \u03a3_{xt})$ and $X^s$ follow the normal distribution $N(\u03bc_{xs}, \u03a3_{xs})$, where\n$\u03bc_{xt} [i] = \u03bc, \u03bc_{\u03c7s} [i] = k\u00b5, \u03a3_{xt} [i, i] = \u03a3_{xs} [i, i] = 1 (0 \u2264 i < d)$.\n(3)\nWe will analyze privacy theft in the process of extracting edge subgraph structure features from two different scenarios.\nBest-case scenario. The ideal edge subgraph of an edge consists exclusively of nodes $V^t$. Considering a 1-layer GCN model without nonlinearity, a standard message passing $Z = AX$ where A is the normalized adjacency matrix with self-loop, the representation of node a after propagation can be written as:\n$\u0396_\u03b1 = \\frac{1}{\\sqrt{N_a}} X_a + \\sum_{b\u2208N \\sqrt{N_aN_b}} X_b, $ \n(4)\nwhere $N_a$ denotes the neighbor set of node a. Consider the generation process of the synthetic edge subgraph that only includes nodes $V^t$, which means $N_a = N$. For each node, the approximate size of its neighbor set can be expressed as np. Thus, representations of nodes follow distributions $Z ~ N(\u00b5_z, \u03a3_z)$, where\n$\u00b5_z [i] = \\frac{1 + np}{np + 1} \u03bc, \u03a3[i, i] = \\frac{1 + np}{n^2p^2}(0 \u2264 i < d).$\n(5)\nUsing Eq.2 and Def.3.3, in the optimal case where the edge graph only includes Vt, privacy theft (PT) of edge subgraph structure feature extraction can be quantified as:\n$PT^{opt} = d\u03bc^2(1 - \\frac{k + 1}{n^2 (1 + pq) - 2 \\sqrt{np(pq + 1)} })\n(6)\nGeneral-case scenario. Under general circumstances, the edge subgraph of edge is composed of nodes $V^t$ and $V^s$. This inevitably introduces noise into $V^t$ in the form of node features and structures originating from Vs, thereby leading to covariate shift and structure shift within the edge graph. After one layer of graph convolution, the representation of node a can be written as:\n$Za = \\frac{1}{\\sqrt{N_a}} X_a + \\sum_{b\u2208N \\sqrt{N_aN_b}} X_b + \\sum_{b\u2208N \\sqrt{N_aN_b}} X_b, $ \n(7)\nwhere $N_a$ denotes the neighbor set of node a. Each node's neighbors consist of both nodes $V^t$ and $V^s$, hence $N_a = N\u222aN$. The size of the neighbor set can be approximately represented as n(p+q). A percentage of $p/(p + q)$ of its neighbors are $V^t$, whereas a percentage of $q/(p + q)$ of its neighbors are Vs. The representations Zt of nodes $V^t$ follow $N(\u00b5_{zt}, \u03a3_{zt})$, while Zs of nodes Vs follow $\u039d(\u00b5_{zs}, \u03a3_{zs})$. \u03a4\u03bf facilitate analysis, we combine $Z^t$ and $Z^s$, such that the representations Z of all nodes in the edge subgraph approximately follow $N(\u00b5_z, \u03a3_z) = N((\u00b5_{zt} + \u03bc_{zs})/2, (\u03a3_{zt} + \u03a3_{zs})/2)$. Correspondingly, initial feature matrix X approximately follow $\u039d(\u03bc\u03c7, \u03a3\u03c7) = N((\u03bc_{xt} + \u03bc_{xs})/2, (\u03a3_{xt} + \u03a3_{xs})/2)$, where\n$\u00b5_z [i] = \\frac{1}{np + 1 - 2 \\sqrt{np}} (k + 1)np \u00b5, \u03a3[i, i] = \\frac{n^2 p^2 - (1 + 2k)np + k^2}{2},$\n(8)\nUsing Eq.2 and Def.3.3, in the general case where the edge subgraph contains both $V^t$ and Vs, privacy theft of edge subgraph"}, {"title": "4 THE PROPOSED METHOD", "content": "In this section, we detail the design of the proposed link stealing attack framework - Link Thief, which combines generalized link structure knowledge with node similarity."}, {"title": "4.1 Overview", "content": "We have partially leaked target graph (containing only the leaked links) and complete shadow graph. The target model is a black box model (i.e., the adversary can only access the node posterior/embedding without knowing the model's parameters), while the shadow model is a white box model that we have trained using the shadow graph. We query the posteriors of target nodes and shadow nodes from the target model and shadow model, and use them as new features $X^t$ and $X^s$, respectively. In the training phase, According to Prop.3.4, we design Bridge Graph Generator (BGG) for RQ1 and Edge Subgraph Preparation Module (ESPM) for RQ2, to construct the Shadow-Target Bridge Graph and sample edge subgraphs on it, respectively. On this basis, Edge Structure Feature Extractor (ESFE) is proposed to learn generalized edge subgraph structure feature across these two graphs. As defined in [15], a set of 12 distance metrics quantifying the similarity between two features constitutes the node similarity features. Finally, we concatenate the edge subgraph structure features with node similarity features to form the attack features. These features are then input into an attack model consisting of Multi-Layer Perceptron (MLP) to derive"}, {"title": "4.2 Bridge Graph Generator (BGG)", "content": "Considering the shadow graph with M nodes and the target graph with N nodes, bridges refer to a collection of inter-graph links connecting the nodes between two graphs. The bridge learner consists of a parametric matrix $W = {\u03c9_{ij}}_{M\u00d7N}$. For node $u_m$ in the shadow graph, we sample S edges from the multinomial distribution $M_m$, which give S nonzero entries in the m-th row of $A_{bridge}$. The probability of N outcomes in $M_m$, and the probability of adding an edge between $u_m$ and $u_n$ from target graph are as follows:\n$M_m~ (\u03c9_{m1},..., \u03c9_{mN}), \u03c9_{mn} = \\frac{exp(\u03c9_{mn})}{\\sum_{\u03c0'=1} exp(\u03c9_{mn'}) }$\n(11)\nWe use $\\&_{bridge}$ corresponding to $A_{bridge}$ to merge $\\&^s$ and $\\&_{t\\_leak}$ to obtain $\\&_{st}$, and concatenate $X^t$ and $X^s$ to obtain $X_{st}$. Finally, they are fed into the GNN encoder with parameters d, which yields the representations $Z_{st}$. $Z_{st}$ contains the target node representing $Z_t$ and the shadow node representing $Z_s$.\nRegarding RQ1, the Prop.3.4(1) presents a criterion to evaluate the effectiveness of bridges. Namely, the closer between $Z_t$ and $Z_s$, the more bridges facilitate subsequent privacy theft. Moreover, since our original intention is to serve the shadow graph as a supplement to target graph, we aim to ensure that $Z_{st}$ cannot deviate too far from the feature $X_t$. We define the above two distances as $L_{inner}$ and $L_{outer}$ respectively, which can be expressed as:\n$L_{inner} = W(Z_S, Z_t), L_{outer} = W(X_t, Z_{st}).$ \n(12)\nW is the Wasserstein-1 distance [2, 12], which we use to measure the distribution distance similar to the theoretical analysis:\n$W (P, Q) = inf E(zz')~y [z - z'||],$ \n(13)\nwhere z and z' are two random variables sampled from two different distributions P and Q separately. Due to the high computational complexity of the original Wasserstein distance, we use the Sinkhorn algorithm [7] to efficiently approximate it through an iterative normalization procedure.\nThe optimization for parametric matrix W is difficult because the edge sampling process is non-differentiable and hinders backpropagation. To handle it, we use policy gradient method REINFORCE [1, 37, 49], treating edge generation as a decision process and edge adding as actions. Specifically, we use \u2013Linner as the reward function R(Abridge), i.e. the smaller the distance between Zs and Zt, the greater the reward. The bridge learner's w and GNN's \u03c6 are updated with learning rates \u03b71 and \u03b72 as follows:\n$\u03c9 \u2190 \u03c9 + \u03b7_1\u2207_\u03c9 log p_\u03c9(A_{bridge})R(A_{bridge}),$ \n(14)\n$\u00a2 \u2190 \u00a2 \u2013 \u03b7_2\u2207_\u00a2(L_{inner} + L_{outer}),$ \n(15)\nwhere $po (A_{ (A_{bridge}) = \u03a0\u039c\u03a0=1wij is the sampling policy."}, {"title": "4.3 Edge Subgraph Preparation Module (ESPM)", "content": "Regarding RQ2, the Prop.3.4(2) suggests that the higher the density of target nodes in edge subgraph, the more conducive it is for privacy theft. Therefore, in the edge subgraph sampler, the sampling methods for target links and shadow links differ. Specifically, when sampling the edge subgraph in the Shadow-Target Bridge Graph, for target links, we select neighbors only from the target graph. In contrast, for shadow links, we choose neighbors not only from the shadow graph but also from the target graph. This method helps align the structure distribution of the shadow links with that of the target links. Inspired by [42, 44], in order to mark nodes with different roles, we use Double-Radius Node Labeling(DRNL) method to assign structure labels to each node in the edge subgraph. The node label NL of vx in the edge subgraph is denoted by\n$NL(x) = 1 + min (di, dj) + (dij/2) [(dij/2) + (dijmod2) \u2013 1],$\n(16)\nwhere d denotes the shortest path distance between two nodes, $di = d(v_i,v_x), dj = d(v_j,v_x), dij = di + dj$. After getting structure labels, we concatenate their one-hot vectors with $X_{st}$ to construct new node features $\\hat{X}_{st}$ of the edge subgraph."}, {"title": "4.4 Edge Structure Feature Extractor (ESFE)", "content": "Further, we construct the k-NN graph [10] to capture latent relationships in the feature space, named the similarity-preserving subgraph. To ensure that each node in the edge subgraph contains implicit node similarity knowledge, we conduct cross-view contrastive learning between the raw and similarity-preserving subgraph [14, 27]. In practice, we utilize the GNN encoder with parameter 0 to map the new node features $X_{st}$ obtained from ESPM into node representations for two views, denoted as $Z_{raw}$ and $Z_{sim}$. To extract the edge subgraph features, we use sort pooling [43] as the readout to obtain subgraph-level representations $S_{raw}$ and $S_{sim}$ of $Z_{raw}$ and $Z_{sim}$, respectively. To ensure that $Z_{raw}$ effectively captures the implicit node similarities, while $Z_{sim}$ retains the raw structure information, we maximize the mutual information (MI) between them. MI [17, 31] is widely used to measure the dependence between two distributions, which can be defined as:\n$I (Z, S) = \\frac{1}{2N} \\sum_{i=1}^N (\\sum_1 log T_y (Z_i, S) + \\sum_1 log[1 \u2013 T_y  (\\tilde{Z}i, (\\tilde{Z}i, S)]),$ \n(17)\nwhere N is the number of nodes in the subgraph, $T_p$ denotes an MI estimator composed of the Bilinear layer that provides probability scores for sampled pairs, Z represents perturbed node embeddings as negative samples. Thus, our contrastive loss is defined as:\n$L_{MI} = I (Z_{raw}, s_{sim}) + I (Z_{sim}, s_{raw}).$\n(18)\nGNN's @ and MI estimator's y are updated with \u03b73 and \u03b74 as follows:\n$\u03c8 \u2190 \u03c8 + \u03b7_3\u2207_\u03c8\\pounds_{MI}, \u03b8 \u2190 0 + \u03b7_4\u2207_@\\pounds_{MI}\u00b7 $\n(19)"}, {"title": "5 EXPERIMENT", "content": "In this section, we first evaluate the effectiveness of Link Thief. Then, we explore the role of the three modules proposed by LinkThif. Finally, we empirically verify how Prop.3.4 affects the privacy theft of edge subgraph structure feature extraction."}, {"title": "5.1 Experimental Setup", "content": "Datasets. We use four real datasets from different multimedia domains including sixteen graphs for evaluation. The Twitch dataset [24] contains social networks from five regions (ENGB, ES, TW, RU, PTBR). The Facebook dataset [29] contains social networks from five US universities (Caltech, Haverford, Reed, Simmons, Swarthmore). The ArnetMiner dataset [32] contains citation networks from three academic databases (DBLPv7, Citationv1, and ACMv9). The Airport dataset [36] contains airport networks from three countries or regions (Brazil, USA, and Europe). The statistics of the datasets are given in the Appendix."}, {"title": "5.2 Main Experiments", "content": "We conduct the main experiment in a setting with 10 bridges connecting a shadow node to a target node. As shown in Table 1 and 2, LSA-3 and LSA-4 exhibit poor performance on the Twitch dataset and Facebook dataset, with ASR and AUC scores ranging between"}, {"title": "5.3 Ablation Study", "content": "We conduct the ablation study to show the effectiveness of each component in our LinkThief as shown in Table 5. We design three Link Thief variants for analysis: (1)w/o BGG: A variant without the Bridge Graph Generator. (2)w/o ESPM: A variant without the Edge Subgraph Preparation Module. (3)w/o ESFE: A variant without the Edge Structure Feature Extractor.\nImpact of Bridge Graph Generator: We find that without BGG, Link Thief decreases AUC scores by 1% to 2% on Citation dataset, 0.2% to 1% on airport dataset, and even 3% in some cases. This suggests that constructing the bridge graph benefits the attack model by providing a perspective that spans the shadow and target graphs to the link.\nImpact of Edge Subgraph Preparation Module: We observe that without ESPM, LinkThief degrades the AUC score by about 3% on Citation dataset and by about 0.5% on airport dataset. This suggests that utilizing distinct subgraph sampling strategies for the target and shadow links benefits the attack model.\nImpact of Edge Structure Feature Extractor: We find that without ESFE, LinkThief's AUC scores are reduced by about 2.5% on Citation dataset, about 3% on airport dataset, and even 20% in some cases. This indicates that the attack model benefits from using edge subgraph structure features as a complement to attack features."}, {"title": "5.4 Empirical verification of Prop.3.4", "content": "Empirical study of Prop.3.4(1): Prop.3.4 (1) suggests that the more similar the features of the shadow nodes and the target nodes in the edge subgraph, the more conducive to privacy theft. We use the bridge construction method that randomly adds edges to compare with the bridge construction method based on minimizing the distribution distance between the shadow node and the target node. As shown in Fig.4, compared with the former, the bridge graph constructed based on Prop.3.4 (1) has a higher AUC score in the former attacks. This proves the effectiveness of Prop.3.4 (1)."}, {"title": "6 CONCLUSION", "content": "In this paper, we investigate the link stealing attack against links that are insensitive to similarity-based attacks and propose an improved attack method called LinkThief. We first empirically demonstrate the bottleneck of relying solely on node similarity as attack features, and then suggest that structural features of the subgraph around links can be used as a complement to attack features. To obtain the edge subgraph structure features that span the target and shadow graphs, we introduce the concept of bridge graphs to connect the two graphs. Through theoretical analysis, we summarize the criteria to measure the impact of the bridge and how to sample the subgraph around the target link and the shadow link, respectively. Based on the above findings, we design three modules for LinkThief to obtain edge subgraph structure features: Bridge Graph Generator (BGG), Edge Subgraph Preparation Module (ESPM), and Edge Structure Feature Extractor (ESFE). Finally, we input the attack features obtained by concatenating the structural features and similarity features into the attack model to obtain the link stealing results. Extensive experiments verify the theoretical analysis and demonstrate the effectiveness of LinkThief."}]}