{"title": "Multi-label Scandinavian Language Identification (SLIDE)", "authors": ["Mariia Fedorova", "Jonas Sebulon Frydenberg", "Victoria Handford", "Victoria Ovedie Chruickshank Lang\u00f8", "Solveig Helene Willoch", "Marthe L\u00f8ken Midtgaard", "Yves Scherrer", "Petter M\u00e6hlum", "David Samuel"], "abstract": "Identifying closely related languages at sentence level is difficult, in particular because it is often impossible to assign a sentence to a single language. In this paper, we focus on multi-label sentence-level Scandinavian language identification (LID) for Danish, Norwegian Bokm\u00e5l, Norwegian Nynorsk, and Swedish. We present the Scandinavian Language Identification and Evaluation, SLIDE, a manually curated multi-label evaluation dataset and a suite of LID models with varying speed-accuracy trade-offs.\nWe demonstrate that the ability to identify multiple languages simultaneously is necessary for any accurate LID method, and present a novel approach to training such multi-label LID models.", "sections": [{"title": "Introduction", "content": "Correctly identifying the language of a short piece of text might seem like a simple (and possibly already solved) task. While differentiating between two distant languages might be straightforward, we show that, when focusing on a group of closely related languages, this task becomes substantially more challenging. This is especially true when we consider the fact that language identification (LID) tools have to be fast and efficient, as they are often used for preprocessing large quantities of texts."}, {"title": "Related work", "content": "Language identification The task of identifying the language of a text is an \u201cold\u201d NLP task dating back to the 1960s. Simple but relatively powerful tools have been available since the 1990s (Jauhiainen et al., 2019).\nIn recent years, the main focus of NLP research has shifted towards large language models, and especially towards extending their coverage to an increasing number of languages. As training data for underrepresented languages is mostly found in web crawls, reliable LID systems covering a large number of languages are more important than ever. While the earliest LID systems were restricted to a dozen languages, recent systems cover hundreds (Joulin et al., 2017; Grave et al., 2018; Burchell et al., 2023; Jauhiainen et al., 2022a) and even thousands (Kargaran et al., 2023) of languages.\nIn terms of methods, simple linear classifiers with character-level and word-level features have often outperformed more sophisticated neural models (Jauhiainen et al., 2019). Most currently available large-coverage LID models are based on the FastText architecture (Joulin et al., 2017), a multinomial logistic regression classifier with character n-gram embeddings as input features. These include FastText-176 (Joulin et al., 2017; Grave et al., 2018), NLLB-218 (NLLB Team et al., 2022), OpenLID (Burchell et al., 2023) and GlotLID (Kargaran et al., 2023). Different approaches are used by HeLI-OTS (Jauhiainen et al., 2022b), which bases its decisions on a combination of character n-gram and word unigram language models, and gpt2-lang-ident, which is a fine-tuned decoder-only model (Radford et al., 2019).\nIn practice, LID is most often applied to individual sentences, even though the tools can work with longer or shorter segments of text.\nLID for closely related and Nordic languages To our knowledge, the only publication focusing specifically on LID for Nordic languages is Haas and Derczynski (2021). They compile a dataset for the six languages (including both Norwegian standards) from Wikipedia and evaluate a range of LID models on it. They find that the languages mostly cluster into three groups: Danish\u2013Bokm\u00e5l\u2013Nynorsk, Swedish, and Icelandic\u2013Faroese. Their models were not available online as of writing this paper. Besides this, de la Rosa and Kummervold (2022) present two FastText-based LID models: one containing only the 12 most common languages of the Nordic countries (including several S\u00e1mi languages, Finnish, and English), and one with an extended coverage of 159 languages.\nFuthermore, the previously mentioned off-the-shelf LID systems (NLLB-218, OpenLID, GlotLID, HeLI-OTS) cover all six Nordic languages, with the exception of FastText-176, which does not include Faroese.\nMulti-label language identification Most existing LID training and evaluation corpora are not manually labeled. Instead, they are based on the assumption that the language is determined by the source it is retrieved from. If a sentence is retrieved from a Danish newspaper, it is assumed to be only Danish. But when dealing with closely related languages, it is often the case that an instance cannot be unambiguously assigned to a single language (Goutte et al., 2016; Keleg and Magdy, 2023).\nRecent proposals address this issue by framing LID between similar languages as a multi-label task (e.g., Chifu et al., 2024; Abdul-Mageed et al., 2024) and by manually annotating the evaluation data (e.g., Zampieri et al., 2024; Mileti\u0107 and Mileti\u0107, 2024). However, these works do not include studies of Scandinavian languages."}, {"title": "Data", "content": "One of the main contributions of this paper is the release of manually and automatically annotated multi-label datasets. In Section 3.1, we introduce the sources from which we compile our datasets. We then present our manually annotated multi-label evaluation dataset (Section 3.2). Next, we describe a way to obtain multi-label annotations automatically for the larger training set in Section 3.3. Lastly, we outline different approaches to data augmentation in Section 3.4.\nData sources\nAs a starting point, we use the Universal Dependencies 2.14 treebanks (UD; Nivre et al., 2016, 2020), keeping their train/dev/test splits intact. For each of the four languages, we associate each sentence in the treebank with the language tag corresponding to that treebank's language. This results in a foundational single-label dataset with the following language tags: Danish (DA), Norwegian Bokm\u00e5l (NB), Norwegian Nynorsk (NN), and Swedish (sv). We further incorporate examples labeled as other, drawing random samples from other UD treebanks to represent other languages.\nAs the UD treebanks are manually annotated, we assume that the texts accurately reflect their corresponding languages. Additionally, the treebanks cover multiple genres, improving the robustness of the models to different text varieties. However, while the resulting dataset is clean, it is not disambiguated. For example, a sentence labeled as Nynorsk is almost guaranteed to be in Nynorsk, but it could also be a valid Bokm\u00e5l sentence.\nSLIDE dataset: manually multi-labeled evaluation data\nManual inspection To identify multi-label instances in the validation and test splits, we performed a combination of automatic filtering and manual annotation. Automatic filtration was done by removing frequent words that unambiguously define a language (e.g. 'ikkje' is only valid in Nynorsk; the full list is to be found in our Github repository).\nAfter filtering, we split the remaining instances among a group of annotators to manually check for cases of multilingual acceptability. All annotators were native or near-native Norwegian speakers. Annotation tasks were delegated depending on the speakers' knowledge and exposure to Swedish and Danish (all native speakers have received education in or about other Scandinavian languages through the public curriculum or university classes).\nUnclear instances Most cases of multilingual acceptability involved short sentences with proper names, numbers, or words that are acceptable in"}, {"title": "SLIDE training methodology", "content": "In this section, we present our approach to training the SLIDE models. We explore two main directions: transformer-based models that achieve high accuracy but require more computational resources, and a fast model based on static word embeddings that trades accuracy for faster inference times.\nTransformer models (SLIDE x-small, small and base)\nFine-tuned masked language models are nowadays the most popular sequence classification solution for problems that require accurate solutions and reasonable inference time (Devlin et al., 2019).\nSelection of BERT family We assessed massively multilingual, Scandinavian, and Norwegian BERT-like models with comparable number of parameters in order to choose a model to focus on for further optimizations.\nWe test two massively multilingual models: XLM-ROBERTa-base (Conneau et al., 2020), which is trained on a corpus containing 100 languages (including the Scandinavian languages) and has a total of 278M parameters, as well as DistilBERT-multilingual-base (Sanh et al., 2019), which is a distilled version of the multilingual BERT base model trained on Wikipedia data from 104 languages (including all the Scandinavian languages) with 135M parameters. The Scandinavian model we use is called ScandiBERT (Sn\u00e6bjarnarson et al., 2023); it is a BERT-like model with 125M parameters trained on Icelandic, Danish, Norwegian, Swedish and Faroese data. Finally, NorBERT3-base (Samuel et al., 2023) is a masked language model trained mostly on Norwegian data.\nPreliminary experiments showed that the NorBERT3 models performed the best on our dataset\nTraining details Fine-tuning is done using the transformers library (Wolf et al., 2020) and the PyTorch framework (Ansel et al., 2024). We use binary cross-entropy as the loss function to train the model for multi-label classification.\nStatic-word-embedding model\n(SLIDE-fast)\nSince our dataset is smaller than that used to train baseline FastText models, we train a tiny multi-label model instead of concentrating efforts on pre-training a model on our dataset. The model is based on GlotLID sentence embeddings and has 20.9k parameters, not counting the input embeddings. It uses a feed forward network with 1 hidden linear layer of size 64 and a ReLU activation function between it and the output linear layer, and is trained with a regular binary cross-entropy loss. We selected the 0.5 sigmoid threshold to accept a class based on the validation data split. The other class is selected only if all other classes are below the threshold. Reducing number of classes from 2,102 to 4 explains faster inference (Table 4) than that of original GlotLID.\nAdditional Scandinavian data Since a SLIDE-fast model trained on the same training dataset as the larger model does not correctly discriminate Bokm\u00e5l from Nynorsk and Danish sentences, we enhance the training dataset with additional Bokm\u00e5l, Nynorsk, Danish and Swedish sentences from the Tatoeba evaluation dataset (automatically labeled in the same way as the UD-based training dataset). NER, punctuation augmentation and regular expression normalization are not applied to the resulting training split."}, {"title": "Experiments", "content": "We evaluate our SLIDE models against several established LID baselines, comparing both prediction accuracy and speed. Our evaluation focuses on two key aspects: performance on our manually annotated multi-label test set, and generalization to out-of-domain data. We first describe the baseline models used for comparison, then present our main results and the results of our out-of-domain experiments.\nBaselines\nWe compare against LID models available at the time of writing that support the four Scandinavian languages: FastText-176 (Joulin et al., 2017), NLLB-218 (Grave et al., 2018), NB-Nordic-LID (de la Rosa and Kummervold, 2022), OpenLID (Burchell et al., 2023), GlotLID (Kargaran et al., 2023); Heliport, a faster version of HeLI-OTS (Jauhiainen et al., 2022b), and gpt2-lang-ident.\nMain results\nTable 4 presents the main results of our experiments on the manually-annotated SLIDE test set. We report loose accuracy and exact-match accuracy as overall metrics, along with per-language exact-match F1 scores for each of the four languages and the 'other' category. Additionally, we measure inference speed in milliseconds per sentence, averaged over three runs\nOut-of-domain test set\nHaas and Derczynski (2021) provide two test sets with single-label annotations, extracted from Wikipedia. In order to evaluate our models on an out-of-domain dataset and compare them with previous work, we use their two test splits containing 3 000 and 14 960 samples respectively and map Icelandic and Faroese to the 'other' label. We present the results on these test sets in Table 5."}, {"title": "Discussion", "content": "Performance of baseline models The baseline models exhibit varying levels of performance, see Table 4 for detailed metrics. These results demonstrate that, while most FastText-based models offer speed advantages, they fall short in accuracy for closely related languages such as Norwegian Bokm\u00e5l and Norwegian Nynorsk. GlotLID, though slower (0.51 ms/sentence), provides the best performance among the baseline models, with Heliport being a close contender while being significantly faster (0.02 ms/sentence). gpt2-lang-ident, originally pretrained as a monolingual English model, fails to tell Danish and two Norwegian languages from each other, while being able to detect Swedish and 'other', which again highlights the importance of a dataset focused on Scandinavian languages.\nPerformance of SLIDE models Our three BERT-based LID models SLIDE-xs, SLIDE-small and SLIDE-base perform the best on our test set, with the base version reaching an exact-match accuracy of 96.4%, while the small and xs both reach 95.7%. This comes at the cost of significantly longer runtimes compared to the static embedding models. These models are suitable when high accuracy is of most importance. However, it is worth noting that we measured inference speed solely on a CPU, one sentence at a time, to ensure a fair comparison with the faster baseline models intended\nError analysis Common error sources are proper names (half of \u2018other' instances misclassified as Scandinavian contains proper names (e.g. \u2018kruvi: Karl Marx'), instances in English (30% of 'other' instances misclassified as Scandinavian), and loan-words ('- Ta avisa Kommersant.', \u2018Server med pastasalat med bakte gr\u00f8nsaker og tsatsiki til', 'Men Anne Linnet - oh la la.') Bokm\u00e5l and Nynorsk are confused most often. If a sentence valid both in Bokm\u00e5l and Nynorsk contains irregular Bokm\u00e5l spelling like \u2018h\u00f8g' instead of 'h\u00f8y', and 'tjuvfiske' instead of 'tyvfiske', it is likely to be misclassified as Nynorsk only. Some errors imply that particular tokens influence the prediction more than a sentence representation as a whole: 'h\u00f8yre' is a valid word both in Nynorsk (\u2018hear') and Bokm\u00e5l ('right'), but the sentence \u2018I alle \u00e5r har vi f\u00e5tt h\u00f8yre at med dagens forbruk er det olje nok for mange ti\u00e5r.', which is Nynorsk because of 'h\u00f8yre' used as a verb, is misclassified as Bokm\u00e5l, while a both Bokm\u00e5l and Nynorsk sentence 'I den nye designen er h\u00f8gre og venstre spalte p\u00e5 framsida til nettavisa fjerna.' is misclassified as only Nynorsk because of the spelling. Additionally, some \u2018other' instances containing subwords matching those in Scandinavian are misclassified, although the whole sentence semantics does not make any sense: 'Va shiaulteyr er ny skeabey harrish boayrd.' (Manx).\nOut-of-domain evaluation In order to ensure that we do not overfit to the UD data, we evaluate"}, {"title": "Conclusion", "content": "We release a novel multi-label LID dataset for Danish, Norwegian Bokm\u00e5l, Norwegian Nynorsk and Swedish with manually annotated validation and test splits. Using machine translation for creating a silver multi-label training dataset from a single-label one has proved to be efficient.\nAlthough fine-tuning models for a specific data source may be helpful to obtain high performance on a selected test set, such models (especially the FastText-based ones) may be not robust towards the test dataset change. Also, excessive training data preprocessing may lead to performance degradation on data from unknown domains compared with training without any preprocessing."}, {"title": "Limitations", "content": "We limit ourselves to the larger Scandinavian languages, and include neither the other closely related Nordic languages Faroese and Icelandic (also known as Insular Scandinavian), nor the smaller Scandinavian varieties with a limited written tradition, such as Scanian, Elfdalian and Bornholmsk.\nWe also do not look at other sources of variation, e.g., dialectal, diachronic or otherwise different varieties found in literature or social media.\nAnother limitation is that while all Norwegians generally understand Swedish and Danish well, as these languages are a compulsory part of the public curriculum, and also teaching languages of Norwegian universities, their productive capabilities are much lower, and there might be cases of mislabeling."}]}