{"title": "Data selection method for assessment of autonomous vehicles", "authors": ["Linh Trinh", "Ali Anwar", "Siegfried Mercelis"], "abstract": "As the popularity of autonomous vehicles has grown, many standards and regulators, such as ISO, NHTSA, and Euro NCAP, require safety validation to ensure a sufficient level of safety before deploying them in the real world. Manufacturers gather a large amount of public road data for this purpose. However, the majority of these validation activities are done manually by humans. Furthermore, the data used to validate each driving feature may differ. As a result, it is essential to have an efficient data selection method that can be used flexibly and dynamically for verification and validation while also accelerating the validation process. In this paper, we present a data selection method that is practical, flexible, and efficient for assessment of autonomous vehicles. Our idea is to optimize the similarity between the metadata distribution of the selected data and a predefined metadata distribution that is expected for validation. Our experiments on the large dataset BDD100K show that our method can perform data selection tasks efficiently. These results demonstrate that our methods are highly reliable and can be used to select appropriate data for the validation of various safety functions.", "sections": [{"title": "I. INTRODUCTION", "content": "Autonomous vehicles today are not only confined to the re- search labs but they are becoming more prevalent in the real- world. Recently, many automotive Original Equipment Man- ufacturers (OEMs) launched their commercial autonomous vehicles, such as Tesla, Alphabet, Waymo, and so on. To standardize autonomous vehicles worldwide, self- driving is usually divided into 6 levels, from 0 (zero self- driving) to 5 (full self-driving) where each level consists of a set of Advanced Driver-Assistance System (ADAS) or Automated Driving System (ADS) features such as Adap- tive Cruise Control (ACC), Lane Keeping Assist (LKA), Highway Pilot (HWP), and others. Following many standards such as ISO 26262, 21448, ANSI/UL 4600 , ISO 15622 , ISO 17361 , ISO 11270 , ISO 19237 , ISO 22839 and national regulators such as the USA NHTSA, EURO NCAP , ASEAN NCAP autonomous vehicles must pass certain test cases and scenarios on the public road before being granted the permission to drive in the real world. Data is crucial in the functioning of autonomous vehicles as they heavily depend on vast quantities of it for validation purpose and to successfully implement autonomous vehicles in real-world scenarios. Since self-driving is a safety-critical application, validation requires a diverse set of testing scenarios that are representative of driving. Many OEMs, such as Alphabet, Tesla, and Audi, etc., have collected a large amount of public road data for validating safety of their high- level autonomous vehicles. But collecting data on the public road can generate a huge amount of data on a daily basis. Processing all this data for validation purposes is an extremely exhausting and impractical effort. Hence it is more important to query a subset of the data which is smaller than the original dataset to accelerate validation process. The Society of Automotive Engineers (SAE) has established the Operational Design Domain (ODD) as a framework for determining the scope of validation test cases and scenarios conducted on public roads. ODD then becomes a funda- mental condition when validating an ADAS/ADS system of autonomous vehicles. Several recent works attempted to define scenario identification in terms of corre- sponding ODD to pass validation, such as [2], [1]. However, because public road validation is highly manual, it is heavily reliant on human effort . Moreover, the large amount of data presents a significant challenge for self-driving system validation. Hence, locating and selecting a smaller set that covers the expected ODD is an effective way to reduce human effort while increasing productivity and efficiency. Furthermore, data selection logically implies data reduction. To save storage space, data may need to be discarded after collection or application completion. However, because data collection on public roads is prohibitively expensive, the data should be separated into useful information that can be used later. Mining these examples can be based on a variety of criteria, including unseen conditions, objects or scenes, or examples where self-driving systems underperformed. Hence, a flexible and dynamic data selection approach is required for validation of ADAS/ADS features of au- tonomous vehicle. However, to the best of our knowledge, there is a lack of research or algorithm development pertain- ing to the aforementioned objectives. Recently, several com- mercial services, such as ADaaS, Scale Nucleus, dSPACE IVS, and many others provide data curation services on data collected on the road. These services, on the other hand, primarily facilitate data querying based on user-defined filters which are relevant to ODD list. However, these commercial services are disclosed, with no explicit method or algorithm described. In this paper, we propose a data selection method for selecting subset of the data to validate multiple self- driving features. Our main idea is to perform the selection using the dataset's metadata. In more detail, we optimize the similarity of selected data's metadata distribution to the"}, {"title": "II. RELATED WORKS", "content": "In reality, self-driving systems are required to validate not only the correctness of their system, but also their safety. Many standards such as ISO 26262, 21448, ANSI/UL 4600 [6], [7], [8], [9], ISO 15622 [10], ISO 17361 [11], ISO 11270 [12], ISO 19237 [13], ISO 22839 [14] or national regulators such as NHTSA [5], Euro NCAP [15], [3], ASEAN NCAP [16] require ADAS/ADS system of autonomous vehicles to pass the validation on the public road for any SAE self- driving levels [4]. These standards and regulations provide the specification of test cases for autonomous vehicle safety validation, which typically consists of certain stages: data collection, event extraction (e.g. scenario, tagging, etc.), data selection for each test case, and verification or validation. In recent years, many OEMs have focused on collecting public road data for validation. For example, Waymo has accu- mulated 5 million miles since 2018, Cruise collected over 770,000 miles in 2020 , BMW has been collecting more than 230 PB data from more than 100 vehicles since 2019 . As stated by SAE [4], the ODD refers to the specific set of operating conditions that a particular driving automation system or its feature is designed to function within. This includes various factors such as environmental conditions, geographical limitations, time-of-day restrictions, and specific traffic or roadway characteristics. In simplicity, ODD comprises of a collection of high-level domains as well as details on static tags and dynamic events known as scenarios. Many prior works concentrated on building algorithms for extracting scenarios from captured data, such as clustering-based scenario extraction [20], corner-cases scenario finding , traffic scenario extraction , tags extraction [23]. In addition to these techniques, self-driving fleets can perform scenarios manually by triggering specified events during test driving [17]. In the following stage, data for each scenario needs to be curated for validation or verification. Data curation is typically accomplished using metadata tags or scenarios that have already been retrieved and saved alongside the acquired data, as defined by ODD [17]. There are two types of data selection: frame-level and scenario-level. The majority of selection processes are performed manually by humans, which is related with the manual validation process [17]. Due to the enormous volume of collected data and the limited availability of validation resources, the output of data selection is typically smaller than the original dataset. Furthermore, with a high number of test cases, the selection operation must run often. A few works describe methods for selecting scenarios for a specific test case, such as [24], [25]. Sadat et al. [26] describe a dataset selection approach that uses infrastructure, traffic participants, and driving maneuvers to measure the level of interest in traffic scenes. The goal of this method is to improve the performance of deep learning models used in self-driving perception tasks. Bogdoll et al. [27] proposed an algorithm for selecting corner case scenarios. Unfortunately, to the best our knowledge, there is a lack of scientific study on data selection to support the validation of autonomous vehicles. Several commercial services, such as the above- mentioned ADaaS, Scale Nucleus, dSPACE IVS, and so on, provide data curation services on data collected on the road for fleet testing or holomogation. These services, on the other hand, primarily facilitate data querying based on user-defined filters such as ODD condition filtering. Moreover, these methods do not provide an explicit algorithm or methodology inside. We then propose a method to better support flexible and dynamic selection for validating autonomous vehicles in the next section."}, {"title": "III. METHOD", "content": "This section describes the details of our method. Our primary idea for scenario selection for autonomous vehicle verification and validation is to use the dataset's metadata. Metadata can be broadly defined as the compilation of information from multiple sources in a dataset. For example, the dataset includes environmental data like weather and road types, as well as dynamic traffic participants like cars, buses, trucks, and pedestrians. Similar to ODD, we consider metadata to be constructed from domains, each of which might contain a set of distinct categories (or tags). Several domains of metadata can coexist independently. For example, data collected on public roads may include weather informa- tion in addition to road information; the weather domain is divided into four categories: wet, sunny, foggy, and cloudy. Similarly, there are five domain object categories: vehicle, bus, truck, pedestrian, and motorcycle. We assume that in the early stages of any data-driven validation task, experts have an expectation of a metadata distribution of interest. For instance, when choosing a subset of data to verify a lane assistant keeping feature, the priority is given to selecting roads with lanes rather than dirt or gravel roads. Therefore, the goal is to ensure that the selected data contains lane- roads. The predetermined expectation of metadata distribu- tion is denoted as E, which $E \\in R^{D \\times C}$ where D, and C denote the number of distinct domains, and the number of categories inside each domain, respectively. Table I shows an illustrative instance of expectation, featuring two domains and their corresponding categories.\nDenote the original dataset $D = \\{x_i\\}_{i=1}^{N}$ with N data points, and $\\mid D \\mid$ represents the dataset size. Each data point $x_i$ can be a scenario data, which may include a sequence of frames, GPS data, CAN signal, etc. The goal is to find a subset dataset $U \\subset D$ that is smaller than D. We select a smaller dataset with a given ratio $\\rho = \\frac{|U|}{|D|}$, where \u03c1 is the keep ratio and 0 < p < 1. Our main idea is to maximize the distribution of metadata for the selected data U so that it matches the expected metadata distribution E. Let A denote the metadata distribution of the selected data U, where $A \\in R^{D \\times C}$. We define two metrics which are category- based metric $S_c$ and domain based metric $S_d$, referred to as equation 1 and equation 2, to measure the similarity between two metadata distributions.\n$S_c(A,E) = 1 - \\frac{||A - E||}{D}$ (1)\n$S_d(A,E) = 1 - \\sum_{i=1}^{D} \\frac{\\mid A_{d_i} - E_{d_i} \\mid}{A}$ (2)\nwhere $d_i$ is defined as in the equation 3.\n$d_i = (\\frac{||A_{d_i} - E_{d_i}||}{E})$ (3)\nwith $\\min(1, a)$ for simplicity. While the domain- based metric indicates how good the selection method is when compared to the average of domains, the category- based metric indicates how good the selection method is when compared to the average of categories. These metrics can be used to measure the quality of selection directly when the selection was done. If both of these metrics are higher then it indicates a better match with expected E.\nThe framework in Figure 1 illustrated the workflow of our data selection. The metadata can be obtained by using the metadata extraction module F, which can be a set of functions such as map API to obtain geographic information, car information (e.g. acceleration, velocity, throttle info) from CAN, weather information query, and so on. The output of metadata extraction F for each sample $x_i$ is the series of metadata $m_i \\in M_D$ associated with this sample $x_i$, where $M_D$ denotes all extracted metadata of the entire data D. Each $m_i$ contains M interested metadata tags, $m_1, m_2, ..., m_M$. Metadata $m_i$ can be a series of metadata tag by time, with the value associated with each metadata tag $m_j$ set to 1 if it occurred and 0 otherwise. Each extracted metadata tag $m_j$ by F can be represented as a series in time, for example, a highway tag of data occurred every 5 seconds. To summarize the extracted metadata $m_i$ of each sample $x_i$, we use a transformation function $\\Phi$ to transform metadata to a ratio list. The ratio of each metadata tag $m_j$ can be the duration of this metadata tag over the duration of the data sample $x_i$. All metadata distribution $\\{\\Phi(m_i)|i = 1,.., N\\}$ will be inputed into a scoring model G($\\theta_i$) for calculating the important score of data $x_i$, which is later used for selection decision, where \u03b8 is the parameter of model G. The calculated score will be used by a selection function $\\Psi_{\\rho}$, which seeks to keep a rate p of data. To simplify, we use the function \u03a8, as the selection function, which selects the top p items from the ranking of D. The ranking can be used to determine the level of significance or interest, as well as diversity and complexity. Thus, we select \u03a8 as the descending rank in the scoring function G. For example, when comparing two data points, $x_1$ and $x_2$, the data point with the higher score is more likely to be retained. Generally, if G($\\theta, \\Phi(m_p)$) > G($\\theta, \\Phi(m_k)$), then $x_p$ is more likely to be retained than $x_k$."}, {"title": "IV. EXPERIMENT", "content": "In this section, we run extensive experiments to assess the effectiveness of our proposed method.\nDataset. We use BDD100K video, a very large open self-driving dataset which provided GPS signal for extracting metadata. This dataset contains 100,000 videos collected across the United States of America in the more than 300 days. Each video is about 40 seconds long and 30 frames per second. In this experiment, our goal is to select a subset of videos from the entire video dataset. The videos also include GPS and IMU data captured by cell phones. As the metadata query from OpenStreet map service via GPS, we implement the metadata extraction function FM. We extract the 8 domains and their categories using GPS, as shown in Table II. Because some GPS positions from cell phones cannot be queried in Openstreet map, therefore out of 100,000 videos, 72,197 videos with metadata totaling 2,861,030 seconds were successfully extracted. The extracted metadata are publicly available. The ratio between the duration of all the videos in the category with the total duration represented in all the categories is represented as the Original column in the Table II.\nOur method. For model training, we use a G model with two layers of 128 hidden layers each. The batch size K is set at 1024. We train our model with the Adam optimizer and a learning rate of 0.01. The model was trained for T = 120 epochs. We set the initialized to 0.9 and = 0.85. We set the selection ratio p in a wide range in several experiments. Due to lack of scientific methods and studies on selecting data for validating autonomous vehicles, we chose the work of selecting a diversity and complexity data set based on geographical information DC.\nWe run first experiment to observe performance of our method compare against DC [33]. Here we select data with rate \u03c1\u2208 {0.2,0.4, 0.6, 0.8}. With each selection rate p, we define an expected distribution E. The Table II describes the performance of our selection method in detail, with each representative scenario for each selection ratio, as well as the domain-based and category-based evaluation metrics. The expected distribution varies, and it is entirely determined by human expertise based on application demand. The first purpose of data selection is to select a subset of data that meets an expectation. With DC [33] method, the selection may attempt to select samples with the most diversity and complexity while disregarding the minor appearance cate- gory. The results show that our method is better than DC [33] in most categories, selection ratio, and evaluation metrics.\nSelection for ADAS/ADS validation. We select data for validation on some ADAS level 2 and 3 features, such as Lane Departure Warning (LDW), Adaptive Cruise Control (ACC), Autonomous Emergency Braking (AEB), Automated High Beam (AHB), Rear Collision Warning (RCW), Forward Collision Warning (FCW), Lane Chang- ing Assist (LCA), Highway Pilot (HWP), and Intelli- gent Speed Alerting (ISA). Each of these ADAS fea- tures has a set of ODD conditions that require safety validation, as described by NHTSA [5], ISO 15622 [10], ISO 17361 [11], ISO 11270 [12], ISO 19237 [13], ISO 22839 [14]. We setup the selected ratio p as the following values: {0.01, 0.05, 0.1, 0.3, 0.5, 0.67, 0.75, 0.9, 0.95, 0.99}. The metadata tag extracted of BDD100K video which are in the list ODD involved of each feature will be kept to assess our method. With each above ADAS feature, we define an expected distribution E on each selection ratio p. Finally, we calculate the average score, percentile 70%, percentile 30%, and up variance and down variance of Sc and Sd as in chart in Figure 2 for each selected ratio p. The figure shows that as p increases, the value of both of two metrics increase. This indicates that a low keep ratio makes it more difficult to ensure that the selected data follows the expected distributions. Furthermore, the results show that the variance to score in lower keep ratio pincreases. It demonstrates that when we aim to select a larger amount of dataset, our selection method is more stable with a variety of expected distributions, including both hard and easy expected distributions. (The hard expected distribution can be considered when there is less data in the entire dataset, but we define the expected ratio to select this data, which is impossible. For example, if we define that the expected ratio of tunnel is 0.5 in the selected dataset with a keep ratio of 0.7, then even if we keep all tunnel data, the actual ratio in the selected data is still much lower than that expected ratio.)\nImpact of similarity filtering. We analyze the impact of similarity filtering on the selection data. We conducted exper- iments with different values of p\u2208 {0.1,0.3, 0.5, 0.7, 0.9}. In the selection function \u03a8, we use both similarity filtering and no filtering. After selecting data, we calculate the mean"}, {"title": "V. CONCLUSIONS", "content": "In this paper, we present our proposed data selection method for validation of variety of ADAS/ADS features in autonomous vehicles. We introduced our framework for data selection based on the metadata of data set. Furthermore, we proposed an algorithm to train a model which is used to optimize the similarity of metadata distribution of selected data and a predefined metadata distribution that is expected for a validation task. Additionally, we provide two metrics which can be used to evaluate the quality of data selection, and guide the data selection algorithm. In experiment, we used a large self-driving dataset BDD100K which consists of near thousands hours driving. Experiment results of data selection compared with other methods indicates that our method is efficient, highly reliable and can be used for validation of a variety of self-driving safety functions."}]}