{"title": "AutoGeo: Automating Geometric Image Dataset Creation for Enhanced Geometry Understanding", "authors": ["Zihan Huang", "Tao Wu", "Wang Lin", "Shengyu Zhang", "Jingyuan Chen", "Fei Wu"], "abstract": "With the rapid advancement of large language models, there has been a growing interest in their capabilities in mathematical reasoning. However, existing research has primarily focused on text-based algebra problems, neglecting the study of geometry due to the lack of high-quality geometric datasets. To address this gap, this paper introduces AutoGeo, a novel approach for automatically generating mathematical geometric images to fulfill the demand for large-scale and diverse geometric datasets. AutoGeo facilitates the creation of AutoGeo-100k, an extensive repository comprising 100k high-quality geometry image-text pairs. By leveraging precisely defined geometric clauses, AutoGeo-100k contains a wide variety of geometric shapes, including lines, polygons, circles, and complex spatial relationships, etc. Furthermore, this paper demonstrates the efficacy of AutoGeo-100k in enhancing the performance of multimodal large language models through fine-tuning. Experimental results indicate significant improvements in the model's ability in handling geometric images, as evidenced by enhanced accuracy in tasks such as geometric captioning and mathematical reasoning. This research not only fills a critical gap in the availability of geometric datasets but also paves the way for the advancement of sophisticated AI-driven tools in education and research.", "sections": [{"title": "1 Introduction", "content": "Mathematical reasoning is a critical component of human intelligence and a key objective of artificial intelligence (AI). The advancement of Multimodal Large Language Models (MLLMs), such as GPT-4 [1] and LLaMa [2], has demonstrated remarkable abilities in comprehension [3], computation [4], and reasoning [5]. Despite these advancements, the full utilization of MLLMs in mathematics, particularly in the area of geometric reasoning, has yet to be fully realized.\nUnlike algebra, which has been extensively studied [6] and benefits from rich datasets [7, 8], geometry has received relatively little attention due to the lack of high-quality large-scale geometry datasets. Existing geometry datasets [9, 10, 11, 12, 13, 14, 15] are primarily derived manually from examination papers or textbooks. As shown in Table 1, these datasets constrain MLLMs' understanding of geometry due to their limited size and lack of detailed geometric descriptions. This limitation hinders the development of AI tools that can effectively understand geometric concepts and aid in personalized learning. Therefore, there is a clear need for the automatic creation of geometry datasets.\nOne potential approach to create the dataset is by utilizing diffusion models [16]. Although diffusion models have shown great potential for natural image synthesis and have addressed data shortage"}, {"title": "2 Related Work", "content": "2.1 Geometric Image Datasets\nMost existing datasets of geometry understanding and reasoning are constructed manually. They use image-text pairs in a Q&A format to train and evaluate the geometric understanding and reasoning capabilities of multi-modal models. The GEOS [10] dataset is one of the earliest efforts to systematize data in the field of geometry Q&A, including 186 plane geometry problems that encompass images, questions, and answers. The GEOS+ [11] dataset expands on GEOS by increasing the number of geometry problems to 1,406. Geometry3K [9] collects more than 3,000 SAT-style geometry problems from high school textbooks, covering a wider variety of geometries and problem types. GeoQA [12] and GeoQA+ [13] further expand the data volumes by adding annotations related to problem solving. PGDP5K [14] contains more complex geometric elements and inter-element relationships. The largest geometric dataset is UniGeo [21], which further expands the data size to 9k and includes a more concise symbolic proof analysis process. PGPS9K [15] includes more detailed diagram annotations and more solutions. The most recent dataset is Mathverse [22], which contains 2, 612 problem samples and is labeled with detailed descriptions of image contents.\nThe proposed AutoGeo framework overcomes the labor-intensive nature of previous efforts by introducing an automated, cost-effective pipeline for generating geometric images. This not only expands the current geometric image dataset but also addresses the issue of insufficient dataset size."}, {"title": "2.2 Geometric Image Understanding and Reasoning", "content": "Before the widespread adoption of MLLMs, earlier approaches [23, 14] have explored solutions for geometric problems. However, these approaches are limited by parameter constraints and lack robust reasoning abilities. For example, Inter-GPS [23] and PGDP [14] employ symbolic methods, manually crafting geometric reasoning rules and symbol definitions for representing geometric objects. These models translate geometric images into symbols through techniques like instance segmentation [24], subsequently applying theorem search algorithms to derive solutions based on predefined rules. Recently, the advent of large language models has replaced manual theorem proving with powerful, data-driven reasoning. Projects such as GeoDRL [25], G-Llava [26], and SCA-GPS [27] align geometric visual features with language model spaces, leveraging the inherent reasoning capabilities of these models instead of rule-based approaches. Additionally, approaches like Alphageometry [28] combine both symbolic and language model reasoning for geometric theorem proving.\nGiven the challenges in obtaining geometric image data, existing work based on MLLMs primarily focus on enhancing the reasoning capabilities of language modules. Techniques such as chain-of-thought (CoT [5]) are utilized to improve the model's reasoning ability on geometry. Mathverse [22] reveals that current MLLMs still heavily rely on textual information for reasoning, with visual modules showing limited effectiveness. In contrast, our work focuses on enhancing model comprehension and reasoning for multimodal geometric problems by automating the synthesis of geometric images and descriptions, thereby improving the extraction and utilization of visual geometric information."}, {"title": "3 AutoGeo: Automated Pipeline for Geometry Image Generation", "content": "AutoGeo serves two essential needs for geometric image generation. First, it enables the generation of well-structured geometries by sampling from a predefined system of geometric clauses. Second, it allows for the cost-effective creation of a wide range of images with a high level of diversity. In this section we first present the performance of existing image generation baselines for generating geometries based on our trial-and-error experience. Then we describe AutoGeo's generation process. And finally, we show the static analysis of our dataset."}, {"title": "3.1 Background: Diffusion Model or Python for Geometry Image Generation", "content": "Diffusion model.\nDiffusion models [16] have emerged as a powerful approach in the field of image generation, offering a novel and effective method for creating high-quality synthetic images. The fundamental idea behind diffusion models is to model the distribution of data as a sequence of denoising steps. Starting from a noise vector, the model gradually refines the image by removing noise and enhancing details in each step. However, when it comes to generating high-quality geometric images, diffusion models fall short. As illustrated in Figure 2(a), the model struggles to produce precise geometric images and even fails to draw straight lines. This limitation likely stems from the inherent differences between image types. Bitmap graphics, such as natural images, are composed of pixels arranged in a grid, making them suitable for the gradual refinement process of diffusion models. In contrast, vector graphics, like geometric images, are defined by mathematical equations, requiring a more logical and rigorous generation process that diffusion models currently cannot provide.\nMatplotlib. Python Matplotlib package [20] is a tool specialized in creating static, animated, and interactive visualizations. With correct point coordination and Python code, Matplotlib can generate accurate geometric images. Manual coding, however, is labor-intensive, thus we resort to large language models to automate the code-writing process. As shown in Figure 2(b), we prompt GPT-4 with a natural language description of the image to generate the corresponding Python code. However, the resulting image often fails to match the original image and text description, indicating significant logical errors in the generated code. Additionally, basic syntax errors may exist in the code and further impede image generation. This reveals the current large language models' insufficient proficiency in generating code for geometric image generation.\nBased on our explorations, we find that an effective automatic geometric image generation pipeline needs two key components: 1) A comprehensive geometric definition system that includes basic geometric objects capable of constructing complex shapes, along with the formal geometric properties these points and lines must meet; and 2) An accurate tool for drawing these geometric objects."}, {"title": "3.2 AutoGeo Pipeline", "content": "In this section we introduce AutoGeo, a novel pipeline designed to automatically generate large-scale geometric datasets. As shown in Figure 3, AutoGeo contains an augmented geometry clause system (Section 3.2.1), a rule-based clause selector (Section 3.2.2) and a sample generator (Section 3.2.3)."}, {"title": "3.2.1 Augmented Geometry Clause System", "content": "As introduced in Section 3.1, an effective automatic geometric image generation pipeline should contain a comprehensive geometric definition system. Inspired by [28], we reference its visualization system with geometric clauses as the foundation of our generation pipeline. A geometric clause is a formalized description of basic geometric objects, their properties or geometric transformations, which constitutes the fundamental units of complex geometric figures. As illustrated in Figure 4, each geometric clause contains several vital attributes:\n\u2022 Prerequisite points are existing points necessary for constructing the geometric object. Please note that some geometric clauses do not require prerequisite points; we refer to these as \u201cIndependent Clauses\", like clause (a) in Figure 4. Conversely, clauses that do require prerequisite points are termed \"Dependent Clauses\", such as clause (b) and (c) in Figure 4.\n\u2022 Inter-dependencies are geometric properties inherent in the geometric definitions, serving as essential conditions when generating geometric images based on the clauses.\nHowever, current geometry clause system still has some drawbacks. Firstly, it lacks geometry clauses that use numbers as input parameters. In geometric images, numerical annotations, such as segment lengths and angle sizes, are crucial for understanding the relationships between geometric objects and for further reasoning. Secondly, the system does not provide a clear complexity classification for each clause, which would aid in controlling the complexity of generated images.\nTo address these issues, we propose two enhancements to the current clause system. First, we investigate common geometric scenarios with numerical annotations and summarize 26 geometric clauses with numerical inputs. Training on geometric images with numerical annotations is expected to enhance the model's optical character recognition (OCR) capabilities and improve the reasoning performance. Second, we categorize the geometric clauses into three levels of difficulty: easy, medium, and hard. This classification will facilitate the complexity control of generated images in the rule-based clause selector. The final augmented geometry clause system comprises 77 clauses in total, categorized into 17 easy, 40 medium and 20 hard ones.\""}, {"title": "3.2.2 Rule-based Clause Selector", "content": "Based on the augmented geometry clause system, we introduce a rule-based clause selector. This selector uses predefined rules to automatically choose a series of mutually compatible geometric clauses that meet the target complexity.\nTo create a geometric dataset with clear levels of difficulty, it is essential to control the number of geometric clauses in each sample. Thus initially, we determine the number of selected clauses $N$ based on the corresponding complexity. As the complexity of geometric images increases, the number of selected clauses grows accordingly. Next, we utilize the classification system in the augmented geometric clause system to facilitate the selection of clauses with appropriate difficulty. Generally, we avoid highly difficult clauses in geometric images of low complexity. Detailed rules of clause number and difficulty control are demonstrated in Table 2."}, {"title": "3.2.3 Sample Generator", "content": "The sample generator transforms selected clause groups into data samples. It consists of two sub-modules: image generation and text generation.\nImage generation. We design a sketch function for each clause to efficiently convert it into geometric images. The sketch function is a piece of Python code, which first determines the coordinates of each new point defined in the clause. For dependent clauses (defined in Section 3.2.1), the coordinates are easily derived from the prerequisite points and their inter-dependencies. For independent clauses, we first create coordinates that satisfy the inter-dependency conditions. Then we apply geometric transformations, such as zooming and rotating, which preserve these inter-dependencies, to increase the diversity of the generated images.\nOnce the coordinates of each points are decided, the sketch function determines whether two points in the image should be connected, whether the connection should be a straight line or a curve, and whether it should be solid or dashed. This ensures the accuracy of the generated geometric images. Additionally, we apply two augmentations on the generated image to increase the task difficulty:\n\u2022 We assign different colors on each line and the background to enhance the diversity of the dataset;\n\u2022 We randomly mask small sections of the images as the absence of these small sections should not impact the model's comprehension of geometric images. Instead, the model should have the ability to reconstruct the missing parts based on the remaining geometric objects.\nText generation. We design 20 descriptive templates for each clause. For each clause in the selected group, we randomly choose and fill in a template, then request ChatGPT to combine and refine them. This process provides a diversified description for each image, serving as the ground truth response to the task instruction, \u201cRender a clear and concise description of an image about geometric shapes.\""}, {"title": "3.3 AutoGeo-100k: Dataset Statistics and Characteristics", "content": "Based on the proposed AutoGeo pipeline, we construct a large-scale geometric dataset, AutoGeo-100k. AutoGeo-100k contains 100k samples in total, encompassing 20k easy, 40k medium, and 40k hard ones. Figure 5 shows the frequency of each clause in data samples of different complexity levels and the average length of textual annotations corresponding to each clause. Detailed statistics are provided in Supplementary. AutoGeo-100k has three main characteristics:\n\u2022 Large-scale. We use the AutoGeo pipeline to create a dataset of 100k geometric image-text pairs, surpassing the size of existing geometric datasets. Additionally, our clause-combination generation method theoretically allows for an unlimited number and complexity of samples.\n\u2022 Low-cost. AutoGeo is fully automatic and takes just 7.5 hours to generate a 100k-level dataset. This approach significantly reduces construction costs compared to human-annotation methods.\n\u2022 Data validity. AutoGeo pipeline employs a rigorously defined geometric clause system and an accurate visualization tool (i.e., Matplotlib), ensuring a precise one-to-one correspondence among clauses, geometric images and text annotations. This guarantees the validity of the data."}, {"title": "4 Experiments", "content": "We evaluate mainstream multimodal large language models (MLLMs) on AutoGeo-100k. Experiments on geometric captioning and geometric question-and-answer (Q&A) tasks demonstrate the limitations of existing MLLMs in geometric understanding and the effectiveness of AutoGeo-100k."}, {"title": "4.1 Experiment Setup", "content": "Implementation details. For dataset generation, we utilize an Intel(R) Xeon(R) Gold 6240 CPU with 10 threads parallelism. In fine-tuning for captioning, we maintain the model's language module while adjusting the geometric semantic alignment through fine-tuning the model's projector layer and the LoRa layer [29] in the vision module. To further finetune the model for geometric Q&A task, we maintain the LoRa layer in the vision module and finetune the model's projector layer and Lora layer in language module on the augmented Geometry3K [26]. Our experiments are conducted on 8 A800s for 2 epochs, with a learning rate of 6e-5 and a batch size of 64.\nBaselines and metrics. We conduct experiments on three MLLMs: LLaVA [30], InstructBLIP [31], and MiniGPT4-v2 [32]. Additionally, we explore baseline models with varying sizes (LLaVA-7B and LLaVA-13B). For the geometry captioning task, we utilize Bleu [33], ROUGE-L [34], and CIDEr [35] for evaluation. For the geometry Q&A task, we utilize the average accuracy for evaluation."}, {"title": "4.2 Experimental Results", "content": "We experiment with fine-tuning various MLLMs on AutoGeo-100k to confirm that our dataset enhances geometric comprehension across models with diverse architectures and parameter sizes.\nComparing different baselines on geometric captioning. Table 3 presents the zero-shot and fine-tuning (highlighted in grey) results of MLLMs on geometric captioning. As can be seen, prior to fine-tuning, these MLLMs generally struggle with captioning geometric images, particularly underperforming on the CIDEr metric. Specifically, the models tend to generate overgeneralized representations and produce verbose captions. LLaVA-7B exhibits better performance on the Bleu and ROUGE-L metrics, whereas the MiniGPT4-v2 model excells in the CIDEr metric. After fine-tuning, the models generate more concise and precise captions, exhibiting significant improvement across all captioning metrics. This indicates the effectiveness of our AutoGeo-100k dataset in enhancing the models' ability to understand and describe geometric images.\nComparing different baselines on geometric Q&A. After fine-tuning MLLMs on AutoGeo-100k, we further fine-tune them using geometric Q&A dataset, Geometry3K [26]. We evaluate the geometric Q&A performance of these finetuned models on GeoQA [12] test set and compare their performance with task-specific models and general MLLM baselines. The results in the first part of Table 4 indicate that general MLLMs' zero-shot performance on Q&A task is lower than task-specific models. After fine-tuning on both captioning and QA data, MLLMs have notably improved performance on geometric QA and LLaVA-7B even surpasses the baselines specialized in geometric Q&A."}, {"title": "4.3 Ablation Study", "content": "We conduct ablation studies on data volumes, data difficulties, and training components.\nAblation on data volumes. We conduct experiments to assess the impact of the training dataset volumes on model's performance. Specifically, we fine-tune LLaVA-7B with different data volumes ranging from 10k to 100k. The result is in Figure 6, demonstrating that model's performance on both geometric captioning and Q&A improves continuously as the data volume grows. Even when the data volume reaches 100k, the performance still increases steadily. This trend suggests that even larger datasets will likely yield further performance improvements, revealing the necessity of AutoGeo's ability in efficiently generating large volumes of geometric training data. Detailed results are provided in Supplementary.\nAblation on data difficulties. The AutoGeo-100k dataset includes 20k easy, 40k medium, and 40k hard samples. To assess the impact of each subset, we systematically remove one subset and replace it with an equal number of samples from the other difficulty levels, maintaining consistent training data volumes. The results, shown in Table 5, indicate that the absence of any difficulty level leads to a performance drop, highlighting the importance of diverse training data in complexity.\nAblation on fine-tuning strategies. We perform ablation studies to evaluate the impact of various fine-tuning strategies on geometric comprehension. The results in Table 6 demonstrate that fine-tuning both the vision and projection modules significantly enhances the model's performance on captioning tasks. Omitting fine-tuning the vision module (illustrated in Figure 7(a)) leads the model to overlook geometric concepts within the image, focusing instead on low-level visual pixels like the \"purple line\". Omitting fine-tuning the projector module damages the model's descriptive capabilities, often resulting in imprecise and simplistic responses. As depicted in Figure 7(a), the model incorrectly describes the geometry containing the points ABCD as a rectangular ABCD. As shown in Figure 7(b), ablating either the vision module or the projector module diminishes the model's geometric Q&A proficiency, leading to misunderstandings of the midpoint and generating incorrect answers."}, {"title": "5 Conclusion", "content": "AutoGeo is featured as an automated pipeline that efficiently generates a diverse and large-scale dataset with minimal cost. This approach addresses the previously limited availability of high-quality geometric datasets and provides a foundation for research and application in AI-driven educational tools and beyond. Based on AutoGeo, we construct AutoGeo-100k with a collection of 100k high-quality geometry image-text pairs. AutoGeo-100k provides massive data for training and evaluating multimodal large language models (MLLMs). Our experiments demonstrate that fine-tuning MLLMs on AutoGeo-100k substantially enhances their performance on tasks such as geometric captioning and question-and-answering, highlighting the dataset's ability to improve models' understanding of geometric concepts. Looking forward, the AutoGeo pipeline and the AutoGeo-100k dataset will facilitate further exploration and development in geometric reasoning. We hope that the dataset will inspire innovations in multimodal understanding and contribute to the advancement of AI systems capable of mathematical reasoning."}]}