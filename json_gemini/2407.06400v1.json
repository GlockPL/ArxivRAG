{"title": "Interactively Diagnosing Errors in a Semantic Parser", "authors": ["Constantine Nakos", "Kenneth D. Forbus"], "abstract": "Hand-curated natural language systems provide an inspectable, correctable alternative to language systems based on machine learning, but maintaining them requires considerable effort and expertise. Interactive Natural Language Debugging (INLD) aims to lessen this burden by casting debugging as a reasoning problem, asking the user a series of questions to diagnose and correct errors in the system's knowledge. In this paper, we present work in progress on an interactive error diagnosis system for the CNLU semantic parser. We show how the first two stages of the INLD pipeline (symptom identification and error localization) can be cast as a model-based diagnosis problem, demonstrate our system's ability to diagnose semantic errors on synthetic examples, and discuss design challenges and frontiers for future work.", "sections": [{"title": "1. Introduction", "content": "Hand-curated natural language systems\u00b9 provide an inspectable, correctable, and incremental alternative to systems based on machine learning (ML). Where ML models are opaque and provide limited opportunities for debugging or incremental extension, hand-curated language systems can be improved by editing their linguistic knowledge. Such changes are typically local, do not require retraining, and can be verified by both testing and direct inspection.\nThe downside of hand-curated language systems is that they are difficult to maintain. Their knowledge spans the breadth of language itself, at least in principle, while it is stored in a variety of specialized formats, such as grammar rules or lexicon entries. Traces of a language system's behavior are complicated and can stump even experts. More generally, the burden of decision-making falls on the maintainer, rather than the system, making maintenance costly. Even when parts of the system's knowledge are learned automatically, the maintainer is responsible for the design, representation decisions, and knowledge curation that keep the system running.\nInteractive Natural Language Debugging (INLD; Nakos, Kuthalam, & Forbus, 2022) aims to lessen this burden. INLD is a framework for debugging hand-curated language systems by asking the user questions in natural language and reasoning about the answers. With the right questions, the system can determine where its behavior deviates from the user's expectations, locate the error in its knowledge that caused the discrepancy, and repair it with the user's assistance.\nIn this paper, we present an implementation of the first two stages of the INLD pipeline: symptom identification and error localization. Our interactive error diagnosis system uses"}, {"title": "2. Companions Natural Language Understanding", "content": "CNLU (Tomai & Forbus, 2009) is the language understanding component for the Companion cognitive architecture (Forbus & Hinrichs, 2017). It parses text to produce a set of parse trees and semantic interpretations, the latter of which are grounded in the NextKB ontology.\u00b2 The parsing algorithm is based on Allen's (1994) bottom-up chart parser and has been extended to build up semantic as well as syntactic structure.\nThe primary function of CNLU is to supply semantic interpretations for downstream planning and reasoning tasks. It has been instrumental in allowing Companions to learn norms (Olson & Forbus, 2021), games (Hinrichs & Forbus, 2014), commonsense knowledge (Ribeiro & Forbus, 2021), and qualitative knowledge (Crouse, 2021), and it serves as the backbone for a question-answering information kiosk located in Northwestern's CS department (Wilson et al., 2019).\nThere are four types of knowledge used by CNLU, corresponding to the lexicon, grammar, semantics, and ontology:"}, {"title": "2.1 Error Taxonomy", "content": "shows a taxonomy of error types found in CNLU's knowledge, along with the symptoms that can be used to diagnose them. Some symptoms can be identified automatically by the parser (e.g., a fragmented parse), while others require user judgments to discern (e.g., a missing word"}, {"title": "3. Interactive Natural Language Debugging", "content": "Interactive Natural Language Debugging (INLD) is a framework for debugging hand-curated language systems by asking the user a series of questions in natural language. The answers allow"}, {"title": "4. Interactive Error Diagnosis", "content": "While there are a number of ways to implement the identification and localization stages of the INLD pipeline, we select a model-based diagnosis framework. Model-based diagnosis compares the behavior of an artifact with the predictions of a model, using the discrepancies to determine where the artifact is malfunctioning (taking the model as ground truth) or where the model fails to capture its behavior (taking the artifact as ground truth). The artifact can be physical, like a printer, or conceptual, like a student's reasoning on a homework problem.\nFor the purposes of INLD, the artifact is the user's understanding of a sentence, and the model is a trace of the parser's behavior as it tries to interpret the same sentence. The user's"}, {"title": "4.1 GDE & CATMS", "content": "The backbone of our diagnosis system is the General Diagnostic Engine (GDE; de Kleer & Williams, 1987). GDE is a model-based diagnosis algorithm that eschews domain-specific diagnosis strategies in favor of a general approach. Given a model and the set of observations made so far, GDE computes the measurement to take that will best distinguish between the current minimal diagnoses, minimal sets of faults that explain the observed discrepancies between the artifact and the model. The algorithm terminates when only one minimal diagnosis remains or when no more measurements are possible.\nGDE uses an assumption-based truth maintenance system (ATMS; de Kleer, 1986) to keep track of its hypotheses. An ATMS maintains a set of nodes, corresponding to assertions, whose labels compactly encode the logical environments in which they are true. Each environment consists of a set of assumptions, nodes assumed to be true in any environment they appear in. Justifications connect their antecedents to a consequent, combining the antecedents' labels to determine when the consequent is true. Some nodes are marked as contradictions. Environments that entail a contradiction are marked nogood and removed from further consideration. These building blocks allow an ATMS to reason about all combinations of assumptions at once, letting it track large sets of hypotheses at the risk of exponential blow-up in the size of its labels.\nTo keep the size of the ATMS tractable, we use a CATMS (DeCoste & Collins, 1991), which compresses its labels by blocking propagation when an assumption is reached. The label of an assumption will only ever contain the singleton environment corresponding to itself, so just one environment is passed to downstream nodes, rather than the exponential number of environments needed to list all the ways the assumption could be entailed. The tradeoff is that the CATMS has to do more work at runtime, recomputing some of the environment comparisons that an ordinary ATMS caches in its (uncompressed) labels. Even so, the runtime benefits of smaller labels typically outweigh the extra work needed to unpack them.\nIn practical terms, this means we can prevent the combinatorial blow-up of labels by turning select nodes into assumptions. Effectively, we are carving the problem into separable pieces that use assumptions to isolate the complexity of one part of the model from the rest of it. As we will show, our INLD formulation lends itself to this technique, with natural groupings of nodes whose internal behavior can be summarized with a single assumption. We have found that the efficiency gains provided by a CATMS are crucial to having our system run in real time."}, {"title": "4.2 Problem Formulation", "content": ""}, {"title": "4.2.1 The Algorithm", "content": "With our implementation of GDE in place and a CATMS to keep label sizes tractable, we turn our attention to the diagnosis problem itself. We divide our algorithm into an inner loop and an outer loop, as shown in 4. The inner loop is our implementation of the GDE algorithm, asking the user a series of questions to diagnose faults in the model. Once the inner loop has found a likely fault, the outer loop decomposes the model, reformulating the problem to drill down on the fault and refine the diagnosis.\nFor example, a missing sense for a word might cause the algorithm to look for senses of that word that were (perhaps erroneously) ruled out during parsing and add them to the model for consideration. The inner loop then takes over to ask further questions, in this case to determine if any of the recovered senses is the right one and, if so, why it was ruled out. Depending on the fault that the algorithm finds, another round of decomposition may be necessary to locate the error (e.g., an overly restrictive type constraint). The cycle continues until the algorithm finds a diagnosis that cannot be decomposed, corresponding to underlying errors in CNLU's knowledge.\nThere are three reasons to structure our algorithm this way. The first is tractability. While the CATMS helps keep the runtime of the algorithm manageable, the size of the problem is still a significant concern. Having to instantiate the parse trace in its entirety is wasted effort when the problem can be decomposed into smaller pieces.\nThe second reason is control. The outer loop allows us to control when structure is added to the model and how it is explored. We can carve off manageable pieces of massive search spaces (e.g., the set of rules that did not fire during the parse), backtrack when a decomposition strategy does not pan out, and instantiate structure dynamically to support flexible debugging strategies (e.g., differential diagnosis; Nakos et al., 2022).\nThe final reason for the structure of our algorithm is modularity. Decomposition strategies are an organic way to handle different types of errors and different techniques for localizing them. New strategies can be added to the library as they are formulated, allowing us to incrementally extend the capabilities of our algorithm. As stated in Section 3., INLD is not an all-or-nothing proposition, and nowhere is that more evident than in decomposition.\nNext, we turn to the model itself and the key concepts that will help us transform a parse trace into a model our diagnosis algorithm can use."}, {"title": "4.2.2 Completeness Assumptions", "content": "The challenge before us is to formulate our model in such a way that fault diagnosis in the model leads to error diagnosis for CNLU. We must capture enough of the logical dependencies between different elements of the parse that the measurements our algorithm takes the user's answers to its questions will eventually localize the error. Faults in the model should either correspond to CNLU errors directly or represent elements of the parse that may contain errors.\nThe crux of the problem is deciding what to use as defaults: assumptions that are presumed to be true unless there is evidence that they are not. GDE computes the set of diagnoses by querying the ATMS for all consistent, maximal combinations of defaults. The defaults that are excluded from a combination are the ones that are inconsistent with it, indicating faults."}, {"title": "4.2.3 Acceptability Judgments", "content": "To put our completeness assumptions to work, we must next define what it means for a parse element to be \"right\". This is complicated by two issues. First, sentences may be ambiguous, in which case there is no single \u201cright\u201d interpretation to find. For example, \"Bob threw the wedge\" is ambiguous as to the type of wedge, so it has more than one valid interpretation. Second, a piece of knowledge may be correct even if it does not apply to the current sentence. For example, we would not delete the golf club sense of the word \"wedge\u201d just because it is the wrong sense for \"Bob ate the wedge.\""}, {"title": "4.2.4 Factored Interpretations", "content": "The last piece of the puzzle is to arrange the parse elements in a way that reflects the logic of the parse. Our goal is to have a root element that is acceptable if at least one acceptable interpretation of the sentence exists and unacceptable otherwise.\nOne na\u00efve way to accomplish this would be to have a separate element for each interpretation (i.e., each consistent combination of CNLU choices) and connect them all to the root. This would get the job done the label of the root would capture the full set of scenarios where an acceptable interpretation existed but only at the cost of a combinatorially prohibitive number of nodes.\nAnother na\u00efve approach would be to have a parse element for each choice set and connect them all jointly to the root. Each choice set would be acceptable when at least one of its choices was acceptable, and the root would be acceptable when all of the choice sets were. While this is a much more compact setup, it ignores the dependencies between choices. For example, if the only acceptable parse tree has \u201cwedge\u201d as a verb and the only acceptable sense of \"wedge\u201d requires it to be a noun, both choice sets would be satisfied even though no consistent interpretation exists.\nInstead of either of these approaches, we use factored interpretations to correctly capture the space of possible interpretations by taking advantage of the dependencies between choices. The enablesChoice relation, which determines when choices should be considered, is purely local. Choices are enabled as long as none of the choices that directly enable them have been ruled out,"}, {"title": "4.3 Problem Decomposition", "content": "As discussed above, decomposition allows our algorithm to reformulate the model in response to an initial diagnosis. Decomposition triggers when the inner loop finds a diagnosis that contains a decomposable fault, namely one that has an associated decomposition strategy. The outer loop"}, {"title": "4.3.1 No Known Semtrans for Word", "content": "This is the simplest decomposition strategy. It triggers automatically when one of the words in the sentence has no known semtranses, as when the system encounters a new word. The only decomposition necessary is to install a completeness assumption for the word's semtranses so it can be faulted. Because all the information the system needs to localize this error is captured in the parse trace, the error can be diagnosed with no user input."}, {"title": "4.3.2 No Acceptable Semtrans for Word", "content": "Another decomposition strategy handles the case where a word has semtranses, but none of them are applicable to the current sentence. When the completeness assumption for a semantic choice set is faulted, the system walks back over the parse trace, following the choices for the word back to their origins to ensure that no other word senses were ruled out along the way. If this is the case, the system can conclude that a semtrans for the word is missing."}, {"title": "4.3.3 Missing Valence Pattern for Acceptable Semtrans", "content": "In some cases, CNLU rules out the right semtrans because it is missing a valence pattern. When a grammar rule binds a grammatical role such as the subject or object of a clause, any semtrans that has no way to handle the role (i.e., a valence pattern with an open role of the appropriate type) will be ruled out. This allows us to make a more specific diagnosis than just saying a semtrans is missing. If one of the dropped semtranses would have otherwise applied to the sentence, we can pinpoint the error to a missing valence pattern with the observed grammatical roles.\nBecause these semtranses were dropped, they do not appear in the model by default. Only when the system has reason to believe a semtrans might have been dropped does it go looking for one, then it installs the necessary structure in the ATMS. The model only contains what it needs."}, {"title": "5. Examples", "content": "To demonstrate our system's ability to diagnose semantic errors, we applied it to a set of three synthetic errors based on the sentence \u201cJoe ate the apple,\" which CNLU interprets correctly. For each of the error types our system supports, we ablated a piece of knowledge to induce that error in the sentence. 2 shows the examples and the decomposition strategies used for diagnosis."}, {"title": "6. Related Work", "content": "While we are unaware of any existing work that attempts to interactively debug a semantic parser, we draw inspiration from several clusters of related work. The first is past work on model-based diagnosis. de Kleer & Williams (1987) present GDE and demonstrate its use for diagnosing faults in digital circuits. de Koning et al. (2000) diagnose student errors by comparing their responses to a model reasoning trace, using hierarchical decomposition to compactly represent a large search space. Collins (1994) extends traditional model-based diagnosis with fault models generated by a process-centered domain theory, allowing the system to handle novel faults not enumerated by the designer.\nMore germane to language, error mining (de Kok & van Noord, 2017) locates errors in a syntactic parser by running the parser over a corpus and tracking the n-grams associated with broken parses. Goodman & Bond (2009) take a similar approach, tracking the combinations of rules that are associated with round-trip parsing and generation failures. These techniques complement INLD nicely, focusing on breadth rather than depth, and future work should explore this synergy.\nInteractive Task Learning (ITL; Laird et al., 2017) deals with systems that learn tasks through explicit instruction. INLD shares the goal of learning via user interaction, but it attempts to repair or supplement existing linguistic knowledge, rather than teach new tasks. However, ITL systems such as Rosie (Kirk & Laird, 2014) and PUMICE (Li et al., 2019) can learn new vocabulary terms to support their task learning. One can imagine a future system that unifies INLD, ITL, and other forms of interactive learning under the same framework.\nFinally, two knowledge-based systems have some intriguing overlap with INLD. KRAKEN (Matthews et al., 2004) and its interactive dialogue component (Witbrock et al., 2003) provide an interface for subject-matter experts to browse, expand, and add entities to the Cyc ontology. The"}, {"title": "7. Conclusion", "content": "INLD shows promise for making hand-curated language systems more maintainable. In this paper, we have presented a partial implementation of the INLD pipeline for the CNLU semantic parser: an interactive, model-based diagnosis system that locates semantic errors in CNLU's knowledge with the help of the user. We have explained the design of the algorithm, shown how a CNLU parse trace can be converted into a model for diagnosis, and demonstrated our system's ability to diagnose a sample set of synthetic errors.\nNotably, our diagnosis system does not require the user to have any expertise aside from a basic knowledge of English. This paves the way for non-experts to help maintain and extend CNLU, which is vital for both longevity of the parser and its use in lifelong learning scenarios (Chen & Liu, 2018).\nWhile the model we have presented here is specific to CNLU, the algorithm can apply to any language system that relies on hand-curated linguistic resources, such as the NLU component of OntoAgent (McShane & Nirenburg, 2021) or the English Slot Grammar parser in Watson (McCord, Murdock, & Boguraev, 2012). Formulating a model for a new system is non-trivial, but the basic pattern of completeness assumptions, acceptability judgments, and decomposition strategies should hold for a wide range of systems."}, {"title": "8. Future Work", "content": "While the system described in this paper constitutes a baseline interactive diagnosis module for CNLU, much work remains to be done, both for NL diagnosis and for INLD as a whole. For the purposes of this paper, we have circumscribed the task of diagnosis, focusing on the classes of errors that are most amenable to INLD. Future work will explore other categories of errors, more sophisticated debugging strategies, and the remaining two stages of the pipeline.\nWe observe that the current limiting factor on our system is its ability to generate English paraphrases of NextKB concepts. While the canned strings and generation templates stored in NextKB have broad coverage, they are incomplete. Furthermore, they have never been tested in a scenario as strenuous as this. Paraphrases that are perfectly fine in isolation may be confusing when used to disambiguate related concepts. Further work is needed to both expand coverage for generation and explore strategies for clarifying paraphrases. This will enable us to test how well our diagnosis strategies work on wild text.\nOne major diagnosis strategy discussed in Nakos et al. (2022) but omitted here is differential diagnosis, the strategy of rephrasing a sentence to localize the error. By rephrasing a sentence, parsing it, and comparing the user's acceptability judgments for the two sentences, INLD can localize the error to either the part of the sentence that changed or the part that stayed the same. In this way, it can drill down on errors that might not be revealed by other localization strategies and break up complex sentences into manageable parts. Implementing this strategy will require"}]}