{"title": "Adaptive Digital Twin and Communication-Efficient Federated Learning Network Slicing for 5G-enabled Internet of Things", "authors": ["Daniel Ayepah-Mensah", "Yu Pang", "Guolin Sun", "Wei Jiang"], "abstract": "Network slicing enables industrial Internet of Things (IIoT) networks with multiservice and differentiated resource requirements to meet increasing demands through efficient use and management of network resources. Typically, the network slice orchestrator relies on demand forecasts for each slice to make informed decisions and maximize resource utilization. The new generation of Industry 4.0 has introduced digital twins to map physical systems to digital models for accurate decision-making. In our approach, we first use graph-attention networks to build a digital twin environment for network slices, enabling real-time traffic analysis, monitoring, and demand forecasting. Based on these predictions, we formulate the resource allocation problem as a federated multi-agent reinforcement learning problem and employ a deep deterministic policy gradient to determine the resource allocation policy while preserving the privacy of the slices. Our results demonstrate that the proposed approaches can improve the accuracy of demand prediction for network slices and reduce the communication overhead of dynamic network slicing.", "sections": [{"title": "I. INTRODUCTION", "content": "The explosive growth of the Internet of Things (IoT) poses significant hurdles for network operators. As a result of the rapid development of communication and sensor technologies paving the way to realize the IoT, it has become more challenging to support urgent and reliable communications with their quality of service (QoS) requirements [1]. As a core component of the 5G architecture, Network Slicing supports various application scenarios and customized services. The physical infrastructure can be divided into logical network instances, called slices [2]. However, IoT networks are char- acterized by considerable differences between service types [3]. Hence, the dynamic module for resource allocation should meet individual user requirements. Dynamic network slicing algorithms developed in recent years take advantage of the large amounts of data flowing through the network, which contain information relevant to resource allocation decisions.\nUsing the data generated by the network, the network slices can predict and exploit the upcoming behavior of a system with many different actors. This will enable slices to allocate resources accurately to their users. To this end, accurately predicting the demand for a given network slice is critical to increasing the utilization of network slices.\nSome works study the impact of demand forecasting for network slicing and dynamic resource allocation for IoT 5G services, while others analyze slicing as a radio access network (RAN) sharing issue. In [4], a framework is proposed to implement a capacity prediction algorithm that considers guar- anteed and best-effort traffic. The authors in [5] proposed an AutoRegressive Integrated Moving Average (ARIMA)-based traffic analysis to prevent slice-level agreement violation. In addition, various Deep Q-Network (DQN) algorithms are used to address the problem of demand-based resource allocation, where an agent learns how to perform optimal actions in an environment by observing state transitions and providing feedback [6]. As a result of the increasing number of IoT devices and slices within the network, the network cannot handle the workload associated with large networks resulting in scalability issues. Furthermore, for dynamic network slicing to be successful, resource-sharing strategies must be collab- orative and autonomous. There is also a need for network slices to share information with the infrastructure providers (InP). This includes user numbers, resource requirements, and any other sensitive information. However, network slices may not want to share because of privacy concerns. Data such as"}, {"title": "II. SYSTEM MODEL", "content": "This section describes the RAN slicing system model for 5G enabled IoT networks. As shown in Fig. 1, the wireless spectrum resources provided by InP are abstracted to constitute a shared resource pool that consists of a certain number of available resource blocks (RBs). These resources can be leased and shared between different network slices. To meet the expected service requirements, the a controller in the cloud is assumed to manage the shared resource pool and allocates resources to slices according to their characteristics [1].\nA. Network Model\nWe consider an orthogonal frequency division multiplexing (OFDM) system in which a single BS b is assumed to be shared by M = {1, 2, 3, 4 . . . M} network slices in a downlink setup. Each slice has a set of IoT devices, denoted by U, and can be represented by U = {1,2,3,4 . . . Um}. In our network model, time is divided into slots denoted by t. Each slice is characterized by a demand $d_m = \\{r_u, r_u,..., r_u\\} (u \\in \\{1,2,...U\\})$, which is the determinant factor for allocating resources $w_m$ to slices. In this paper, Shannon theory is used to define the transmission rate for IoT devies, i.e.,\n$r_u = w_m \\log_2(1 + \\frac{P_{u,t}h_{u,t}}{N_o})$\nwhere $w_m^t$ is the amount of resources assigned to user u and $P_{u,t}$ is the transmit power on the base station at the t-th TTI. $h_{u,t}$ is the channel coefficient, which contains path loss, shadowing effect $O_u$ and Rayleigh fast fading $g_u$, between IoT device u and the base station. We define as $h_{u,t} = 10^{-PL*(u)/20} \\sqrt{d_u, \\Theta_u, g_u}$, where (PL) is the Path Loss and is defined as (dB) = $20log_{10}(d) + 20 log_{10}(f)- 27.55$ where f (in MHz) and d (in meters) representing IoT device to base station channel frequency and distance respectively [8]. Moreover, $N_o$ is the power of additive white Gaussian noise (AWGN). The average delay $T_u$ experienced by the IoT device u in the slice m is $T_u = \\frac{\\lambda_u}{W_m}$, where $\u03bb_u$ is the packet arrival rate. Based on IoT device requirements, different slices can be created to serve different types of IoT device traffic. A summary of commonly used notations is provided in Table I.\nB. Utility Model\nWe introduce a utility function to quantify the QoS needs of IoT devices in a slice [8]. We define QoS utility as the satisfaction of user u on either data rate or delay. The utility function of a slice represents the user preference in the network"}, {"title": "C. Federated Learing Model", "content": "Each slice m has a set of data samples and trains its local model using stochastic gradient descent (SGD) [9]. We formulate a learning problem for dynamic slicing where each slice has the task of optimizing the global loss function F(0) by minimizing the weighted average of the local loss function $F_m(0)$ as\n$\\min \\{F(0) = \\sum_{m \\in M} \\frac{|D_m|}{|D|} F_m (0)\\}$\nTaking our proposed slicing model into account, we propose that the centralized cloud, i.e. the InP, only performs the aggregation of the model and network slices autonomously perform dynamic network slicing.\nD. Problem Formulation\nIn our proposed dynamic slicing framework, our goal is to optimize the resource utilization of a slice and ensure the the QoS requirement of the IoT devices in the slice are met. We formulate the optimization problem as maxizing the QoS utility of the slice as:\n$\\arg \\max_{w_m} \\{\\Omega_m + U_m\\}$\ns.t. $W_m \\leq K$, $W_m > 0$\nwhere \u043a is the maximum amount that can be allocated to a slice. $w_m < K$ indicates that the amount of resources allocated to the slice should not exceed the total resources available at the base station, and $w_m > 0$ are the constraints that ensure that at least one slice always has resources. In dynamic network slicing, not only the current service demand needs to be considered, but the future demands of the slice also need"}, {"title": "III. ADAPTIVE DT BASED DEMAND FORECAST FOR RAN SLICES", "content": "In this section, we design a dynamic graph-based DT to capture the dynamics and spatial dependency of traffic in a slice. During the resource allocation stage of a slice, the graph- based DT is composed of four steps: i: Feature Extraction: a CNN-based feature extraction net is used to convert the raw spatial-temporal data into the feature matrix representations. ii: Graph Construction: We adopt a direct optimization approach to learn dynamic graph structures, which generate a graph adjacency matrix that represents the DT. iii: Interaction Modeling: Captures the dynamic interaction of UEs and the structural information within the nodes (UEs and gNodeB) of the slice. iv: Prediction Model: integrates each node's individual sequential information to predict the slice's traffic demands. The network topology of the slice at each time interval can be represented as a sequence of graph snapshots G = {G1,\u2026, GT}, where T is the number of time steps. To construct the DT, the network topology of the IoT devices in the slice is represented as a graph. The graph can be defined as G = {V,E} with N nodes, where V and E are the set of nodes and edges, respectively. The network traffic data generated by the slice is defined as $d \u2208 R^{Z\u00d7T\u00d7V}$ where Z is the input channels and T time intervals and V are the spatial data associated with the channel [10]. The task of traffic forecasting is to learn a mapping function h(\u00b7), which takes historical traffic data d and graph G as inputs to forecast future time intervals traffic data:\n$d_m = h(d_m,G,\u03c8)$,\nwhere & is the learnable parameters. However, the Slice traffic data is defined as multivariate and temporal data and no nodes. Therefore, the proposed DT is used to build a graph that comprehensively models the interaction between IoT devices in a slice.\nA. Graph construction.\nThe first stage of the proposed slice DT is a graph learning layer that learns a graph adjacency matrix adaptively to capture the hidden relationships among time series data for the slice. The adjacency matrix can be seen as DT, representing the topology and spatial behavior of the IoT devices in a slice. Firstly, CNN-based feature extraction is used to convert the raw spatial-temporal data into the feature matrix representation $B^m$. Based on the feature matrix, a unique graph structure is generated for the slice, consistent with the dynamic property of the traffic data generated by BS. Inspired by [11], the underlying adjacency matrix A is dynamically generated with:\n$A = ReLU (tanh (\u03b2 (M_1M^T \u2013 M_2M^T)))$\nwhere \u1e9e is a hyper-parameter which is a saturation rate of the activation function and $M_1 = M_2 = tanh (\u03b2 (E_mB^m)$ is a dynamic filter with $B^m$ as its input."}, {"title": "B. Interaction Modeling for slices with GAT", "content": "The GAT layer can model the relationships between nodes and frequencies [12]. The GAT generates the attention weight that reflects the channel quality of traffic generated by IoT devices in a slice. The input to the graph layer is a set of node features $\\{x_1...,x_N\\}$ embedded in the adjacency matrix A and the output is a new set of node features $\\{x_1,...,x_N\\}, x \u2208 R^H$, where H is the number of features for each node. We compute the attention coefficient of node z \u2208 N\u2082 to node v as follows [12]:\n$\u03b1_{zv} = \\frac{\\exp (LeakyReLU (q^T [W^zx_z||W^zx_v]))}{\\sum_{u\u2208N_z} \\exp (LeakyReLU (q^T [W^zx_u||W^zx_v]))}$\nwhere N is the set of immediate neighbors and $W\u02dc \u2208 R^{F\u00d7D}$ is the weight matrix of the graph. $q \u2208 R^{2D}$ is a weight vector of each node on the graph. Note that $A_{zv}$ is the weight of the link (u, v) in the current snapshot G. $\u03b1_{zv}$ indicates the importance of node features in traffic data. The attention coefficients are then used to compute the final output features for every node:\n$x'_z = \u03c3(\\sum_{u\u2208N_z} \u03b1_{zv} Wx_\u03c5)$\nwhere \u03c3(\u00b7) is applied component-wise. The GAT layer is able to dynamically learn the relationships between different chan- nels and timestamps and abstract more meaningful information from the traffic channel of the slice.\nC. Prediction Model\nFinally, a two-layer fully connected neural network is used to obtain the final traffic prediction as follows:\n$d_m = softmax (x' + b)$\nwhere is a learnable matrix and b is the bais. We define a cross-entropy loss to train the model as:\n$LoSS_{forecasting} (t) = \\frac{1}{T} \\sum_{t=1}^T |d_m^t - \\hat{d_m^t}|$\nwhere $d_m^t$ and $\\hat{d_m^t}$ are the actual demand and the predicted demand of the slice m at timestamp T."}, {"title": "IV. MULTI-AGENT FEDERATED LEARNING DYNAMIC NETWORK SLICING", "content": "The limited communication capability of wireless networks makes DQN solutions unsuitable for large networks. We propose a multi-agent federated dynamic slicing algorithm to ensure privacy and scalability. The proposed algorithm can determine the near-optimal slicing policy that meets the QoS satisfaction requirements. According to the result of the prediction of the DT forecast, the dynamic slicing algorithm aims to maximize the average resource utilization of each slice and user satisfaction. Specifically, we model FL with multiple slices as an MDP and design a multi-agent federated reinforcement learning algorithm to explore the optimization solution for IoT slices."}, {"title": "A. Problem Transformation", "content": "To maximize the long-term return for the provider while accounting for the real-time arrivals of IoT network slices, we transform the problem into a Markov decision process (MDP) [6]. An MDP is defined by a tuple (t, S, A, R) where t is an decision epoch, S is the system's state space, A is the action space and R is the reward function. The state, action, and reward can be defined as follows.\na) State: At the beginning of each time interval, the state of each slice is defined as $s_m(t) = [d_m(t), \\hat{d_m} (t-1)]$, where $d_m$ and $\\hat{d_m}$ are the actual demand and the predicted demand of the slice m.\nb) Actions: The action taken by the slice m at time t is represented by $a_m = \\{w_m\\}$, where $w_m$ represents the increase in the percentage of bandwidth for the m-th slice. When $w_m > 0$, $w_m$ percentage of bandwidth will be added to the rsource of the slice and when $a_m < 0$, $a_m$ percentage bandwidth of the slice will be reduced.\nc) Reward: After the state transition, each slice would gain rewards w.r.t. current state sm and actions am. The reward function of the of the slice is defined as:\n$R_m(s, a) = {\u039b\u00b7 \u03a9_m(s, a) + \u03bc\u00b7 U_m(s,a)}$\nwhere \u039b and u are the importance of the algorithm places on the resource utilization and utility, respectively [8]. The ultimate objective of the agent in the multi-agant FL system is to find the optimal slicing strategy (policy) \u03c0*.\nB. MAFL Network slicing\nNetwork slices collaborate to find the optimal resource allocation in a decentralized manner. The role of the slice orchestrator is to coordinate all slices to achieve a global optimal resource allocation. In this allocation process, network slices do not need to share or exchange their proprietary infor- mation, including resource availability and traffic dynamics, with each other or with the slice orchestrator. the MAFL Network slicing, consist of 1) Local Policy Iteration 2) Global Policy Aggregation. The local policy iteration is performed by the slices and the central InP controller performs the for global policy aggregation. The aggregation period for the global model is called \u0442.\n1) Local Policy Iteration: Taking advantage of Deep De- terministic Policy Gradient (DDPG) [6], an actor's network guides the update of policy parameters \u03b8t of the network slcing policy $\u03c0_{\u03b8_t}$ based on the evaluated values from the critic's network. The policy gradient is defined as follows:\n$\\nabla_{\u03b8\u03c0} = \\frac{1}{N} \\sum \\nabla_a Q(s_m, a | \u03b8^Q) \\nabla_{\u03b8\u03c0} \u03c0 (s_m | \u03b8^*)$.\nWe update the critic by minimizing the loss:\n$L (\u03b8^Q) = \\frac{1}{n} \\sum (y_m - Q (s_m, a_m | \u03b8^Q))^2$\nwhere $y_m = R_m + \u03b3Q' (S_{i+1}, \u03c0' (S_{i+1} | \u03b8'))$. The target parameters in both actor and critic networks are updated as follows:\n$\u03b8 \u2190 \u03bd\u03b8 + (1 \u2212 \u03bd)\u03b8'$\n$\u03b8' \u2190 \u03bd\u03b8 + (1 \u2212 \u03bd)\u03b8'$\nIn the t-th iteration, each slice agent performs model update via the stochastic gradient descent (SGD) algorithm based on its local data with the following expression:\n$\u03b8_t^{(m)} \u2190 \u03b8_{t-1}^{(m)} - \u03b7 \u2207 f_m (\u03b8_{t-1}^{(m)})$\nwhere \u03b7 is the learning rate and where $f_m (\u03b8) = \\frac{1}{|D_m|} L_{D_m} (\u03b8^m)$ is the loss function of the agent m, $\u03b8_{t-1}^{(m)}$ is the local model of the slice at the start of the t-th iteration. The local model update $\u03b8_t^{(m)}$ is uploaded to the slice orchestrator for global model aggregation.\n2) Global Policy Aggregation: The slice orchestrator up- dates the global network slicing model by aggregating all local model updates from IoT slices as follows:\n$\\theta = \\frac{\\sum_{m \\in M} D_m \u03b8_t^{(m)}}{|D|}$\nwhere @ denotes the aggregated model at the cloud server. Af- ter that, @ is broadcasted to the slices, which can be expressed"}, {"title": "VI. CONCLUSION", "content": "This paper presents a comprehensive approach to opti- mize IoT network slice management through advanced traffic analysis and resource allocation. We introduced a novel DT architecture leveraging GAT for real-time traffic monitoring and demand forecasting within network slices. Building upon these predictions, we developed a federated multi-agent rein- forcement learning framework for dynamic network slicing, enabling inter-slice collaboration while preserving individual slice privacy. Our extensive simulations demonstrate the ef- ficacy of the proposed methods in significantly enhancing demand prediction accuracy for network slices and substan- tially reducing the communication overhead associated with dynamic network slicing. These improvements translate to more efficient resource utilization, improved QoS, and en- hanced scalability of IoT networks. Future work includes exploring the integration of policy distillation methods, where knowledge from multiple specialized policies can be consol- idated to improve collaboration and address Non-IID (Non- Independent and Identically Distributed) challenges in network slicing due to diverse requirements for slices. This approach could potentially further optimize the learning process and improve the adaptability of our system to diverse network conditions. By leveraging policy distillation, we aim to create more robust and generalizable policies that can effectively handle the heterogeneous nature of network slices, leading to more efficient resource allocation and improved overall network performance."}]}