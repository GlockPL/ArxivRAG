{"title": "Adaptive Digital Twin and Communication-Efficient Federated Learning Network Slicing for 5G-enabled Internet of Things", "authors": ["Daniel Ayepah-Mensah", "Yu Pang", "Guolin Sun", "Wei Jiang"], "abstract": "Network slicing enables industrial Internet of Things (IIoT) networks with multiservice and differentiated resource requirements to meet increasing demands through efficient use and management of network resources. Typically, the network slice orchestrator relies on demand forecasts for each slice to make informed decisions and maximize resource utilization. The new generation of Industry 4.0 has introduced digital twins to map physical systems to digital models for accurate decision-making. In our approach, we first use graph-attention networks to build a digital twin environment for network slices, enabling real-time traffic analysis, monitoring, and demand forecasting. Based on these predictions, we formulate the resource allocation problem as a federated multi-agent reinforcement learning problem and employ a deep deterministic policy gradient to determine the resource allocation policy while preserving the privacy of the slices. Our results demonstrate that the proposed approaches can improve the accuracy of demand prediction for network slices and reduce the communication overhead of dynamic network slicing.", "sections": [{"title": "I. INTRODUCTION", "content": "The explosive growth of the Internet of Things (IoT) poses significant hurdles for network operators. As a result of the rapid development of communication and sensor technologies paving the way to realize the IoT, it has become more challenging to support urgent and reliable communications with their quality of service (QoS) requirements [1]. As a core component of the 5G architecture, Network Slicing supports various application scenarios and customized services. The physical infrastructure can be divided into logical network instances, called slices [2]. However, IoT networks are characterized by considerable differences between service types [3]. Hence, the dynamic module for resource allocation should meet individual user requirements. Dynamic network slicing algorithms developed in recent years take advantage of the large amounts of data flowing through the network, which contain information relevant to resource allocation decisions.\nUsing the data generated by the network, the network slices can predict and exploit the upcoming behavior of a system with many different actors. This will enable slices to allocate resources accurately to their users. To this end, accurately predicting the demand for a given network slice is critical to increasing the utilization of network slices.\nSome works study the impact of demand forecasting for network slicing and dynamic resource allocation for IoT 5G services, while others analyze slicing as a radio access network (RAN) sharing issue. In [4], a framework is proposed to implement a capacity prediction algorithm that considers guar- anteed and best-effort traffic. The authors in [5] proposed an AutoRegressive Integrated Moving Average (ARIMA)-based traffic analysis to prevent slice-level agreement violation. In addition, various Deep Q-Network (DQN) algorithms are used to address the problem of demand-based resource allocation, where an agent learns how to perform optimal actions in an environment by observing state transitions and providing feedback [6]. As a result of the increasing number of IoT devices and slices within the network, the network cannot handle the workload associated with large networks resulting in scalability issues. Furthermore, for dynamic network slicing to be successful, resource-sharing strategies must be collab- orative and autonomous. There is also a need for network slices to share information with the infrastructure providers (InP). This includes user numbers, resource requirements, and any other sensitive information. However, network slices may not want to share because of privacy concerns. Data such as these are stored in a centralized database. Accessing them from the centralized InP would be computationally prohibitive due to the amount of processing and optimization required, as well as privacy issues associated with a centralized data store. Finally, many works have examined demand forecasting for network slices but primarily focused on modeling a single sequence. This is constrained to only account for the time series dependence on traffic networks and ignores the un- derlying spatiotemporal topological traffic information of the IoT devices in the slice. Therefore, the forecasting model for network slicing should be able to capture the spatial-temporal evolution of traffic generated by the slices.\nThis paper proposes an intelligent digital twin (DT) frame- work as a scalable solution for real-time data-driven moni- toring and accurate prediction of IoT demand in 5G-based IoT network slices to address the above issues. As an emerg- ing digitization method, DT provides a viable alternative to capture the dynamic and complex network environment [7]. It creates a virtual environment in digital space through software definition. By utilizing a graph learning model algorithm, we can construct DTs, i.e., virtual representations of IoT devices with similar structural properties to the physical network. We propose a Graph-Attention-Network (GAT) based DT that can capture the temporal characteristics and accurately monitor and predict the traffic demand of each slice. Based on the demand predictions, we formulate the resource allocation problem as a decentralized multi-agent reinforcement learning (RL) problem to find the optimal resource allocation policy under slice service demand uncertainty. Furthermore, we rely on federated learning (FL), a decentralized machine learning technique, to train deep learning models without compromis- ing privacy. The outcome is a digital twin multiagent federated learning (DT-MAFL) network slicing. The remainder of this article is organized as follows: In Section II, we describe the system model and propose the dynamic resource allocation problem. Section III describes the construction of the DT for each slice. Section IV presents the design of a federated multiagent learning system for dynamic slicing. Section V provides a detailed simulation to validate our proposed slicing framework. Section VI concludes the paper."}, {"title": "II. SYSTEM MODEL", "content": "This section describes the RAN slicing system model for 5G enabled IoT networks. As shown in Fig. 1, the wireless spectrum resources provided by InP are abstracted to constitute a shared resource pool that consists of a certain number of available resource blocks (RBs). These resources can be leased and shared between different network slices. To meet the expected service requirements, the a controller in the cloud is assumed to manage the shared resource pool and allocates resources to slices according to their characteristics [1].\nWe consider an orthogonal frequency division multiplexing (OFDM) system in which a single BS b is assumed to be shared by M = {1, 2, 3, 4 . . . M} network slices in a downlink setup. Each slice has a set of IoT devices, denoted by U, and can be represented by U = {1,2,3,4 . . . Um}. In our network model, time is divided into slots denoted by t. Each slice is characterized by a demand $d_m = \\{r_u,r_u,...,r_u\\}$ (u \u2208 {1,2,...U}), which is the determinant factor for allocating resources $w_m$ to slices. In this paper, Shannon theory is used to define the transmission rate for IoT devies, i.e.,\n$r_u = w_m log_2 (1+ \\frac{P_{u,t}h_{u,t}^2}{N_o})$\nwhere $w_m$ is the amount of resources assigned to user u and $P_{u,t}$ is the transmit power on the base station at the t-th TTI. $h_{u,t}$ is the channel coefficient, which contains path loss, shadowing effect $O_u$ and Rayleigh fast fading $g_u$, between IoT device u and the base station. We define as $h_{u,t} = 10^{-PL*(u,)/20} \\sqrt{d_u,}O_u g_u$, where (PL) is the Path Loss and is defined as (dB) = 20log10(d) + 20 log10(f)- 27.55 where f (in MHz) and d (in meters) representing IoT device to base station channel frequency and distance respectively [8]. Moreover, $N_o$ is the power of additive white Gaussian noise (AWGN). The average delay $T_u$ experienced by the IoT device u in the slice m is $T_u = \\frac{1}{\u03bb\u0304_u}$ where $\u03bb\u0304_u$ is the packet arrival rate. Based on IoT device requirements, different slices can be created to serve different types of IoT device traffic. A summary of commonly used notations is provided in Table I."}, {"title": "B. Utility Model", "content": "We introduce a utility function to quantify the QoS needs of IoT devices in a slice [8]. We define QoS utility as the satisfaction of user u on either data rate or delay. The utility function of a slice represents the user preference in the network by mapping the achievable rate and maximum delay with the level of UE satisfaction. Here, we use a sigmoid function to express users' satisfaction in terms of rate and delay. In this article, we adopt a framework for satisfaction function U(.) that can meet different optimization goals for both delay and rate constraint as U (Tu) and U (ru), respectively. Therefore, we propose a unified utility function for both delay and rate constraint users.\nRate-constrained slice: For the slice m, the average QoS satisfaction of a rate-constrained user is defined as;\n$U_u (r_u) = \\frac{1}{1+ e^{-\\frac{(r_u-r_{min})}{\u03b6}}}$\nwhere $r_{min}$ denotes the minimum rate requirement of the user in slice m, and $\u03b6$ specifies the steepness of the satisfactory curve.Delay-constrained slice: The average satisfaction on delay in slice m is defined as\n$U_u (T_u) = \\frac{1}{1 + \u0435^{-\u0444(\u03c4^{max}\u2212T_u)}}$\nwhere the maximum tolerance delay is indicated as $\u03c4^{max}$, which is required to satisfy the upper bound delay for the IoT device u. Essentially, a slice utility $U_m$ can be defined as a summation of individual utilities of the users who make up that slice. The slice utility is defined as:\n$U_m = \\sum_{UEU_n} U_u (.)$\nFurthermore, the average utilization of a slice is defined as\n$\u03a9_m = \\frac{W_m}{Y_m}$\nwhere $w_m = \\sum_{u\u2208U_m} w_{u,t}$ is the amount of RBs occupied by slice m and $\u03a9_m$ is the number of RBs needed by slice m which is the demand of the slice."}, {"title": "C. Federated Learing Model", "content": "Each slice m has a set of data samples and trains its local model using stochastic gradient descent (SGD) [9]. We formulate a learning problem for dynamic slicing where each slice has the task of optimizing the global loss function F(0) by minimizing the weighted average of the local loss function Fm (0) as\n$min \\{F(\u03b8) = \\sum_{MEM} \\frac{|D_m|}{|D|} F_m (\u03b8)\\}$\nTaking our proposed slicing model into account, we propose that the centralized cloud, i.e. the InP, only performs the aggregation of the model and network slices autonomously perform dynamic network slicing."}, {"title": "D. Problem Formulation", "content": "In our proposed dynamic slicing framework, our goal is to optimize the resource utilization of a slice and ensure the the QoS requirement of the IoT devices in the slice are met. We formulate the optimization problem as maxizing the QoS utility of the slice as:\narg max {$\u03a9_m + U_m$}\n$s.t. W_m \u2264 \u03ba,$\n$W_m > 0$\nwhere \u03ba is the maximum amount that can be allocated to a slice. $w_m < \u03ba$ indicates that the amount of resources allocated to the slice should not exceed the total resources available at the base station, and $w_m > 0$ are the constraints that ensure that at least one slice always has resources. In dynamic network slicing, not only the current service demand needs to be considered, but the future demands of the slice also need to be considered. Hence, we proposed a DT model which monitors the real-time behavior and accurately predicts each slice's demand."}, {"title": "III. ADAPTIVE DT BASED DEMAND FORECAST FOR RAN SLICES", "content": "In this section, we design a dynamic graph-based DT to capture the dynamics and spatial dependency of traffic in a slice. During the resource allocation stage of a slice, the graph- based DT is composed of four steps: i: Feature Extraction: a CNN-based feature extraction net is used to convert the raw spatial-temporal data into the feature matrix representations. ii: Graph Construction: We adopt a direct optimization approach to learn dynamic graph structures, which generate a graph adjacency matrix that represents the DT. iii: Interaction Modeling: Captures the dynamic interaction of UEs and the structural information within the nodes (UEs and gNodeB) of the slice. iv: Prediction Model: integrates each node's individual sequential information to predict the slice's traffic demands. The network topology of the slice at each time interval can be represented as a sequence of graph snapshots $G = \\{G_1,\u2026, G_T\\}$, where T is the number of time steps. To construct the DT, the network topology of the IoT devices in the slice is represented as a graph. The graph can be defined as $G = \\{V,E\\}$ with N nodes, where V and E are the set of nodes and edges, respectively. The network traffic data generated by the slice is defined as $d\u2208 R^{Z\u00d7T\u00d7V}$ where Z is the input channels and T time intervals and V are the spatial data associated with the channel [10]. The task of traffic forecasting is to learn a mapping function h(\u00b7), which takes historical traffic data d and graph G as inputs to forecast future time intervals traffic data:\n$d_m = h(d_m,G,\u03c8)$,\nwhere \u03c8 is the learnable parameters. However, the Slice traffic data is defined as multivariate and temporal data and no nodes. Therefore, the proposed DT is used to build a graph that comprehensively models the interaction between IoT devices in a slice."}, {"title": "A. Graph construction.", "content": "The first stage of the proposed slice DT is a graph learning layer that learns a graph adjacency matrix adaptively to capture the hidden relationships among time series data for the slice. The adjacency matrix can be seen as DT, representing the topology and spatial behavior of the IoT devices in a slice. Firstly, CNN-based feature extraction is used to convert the raw spatial-temporal data into the feature matrix representation $B^m$. Based on the feature matrix, a unique graph structure is generated for the slice, consistent with the dynamic property of the traffic data generated by BS. Inspired by [11], the underlying adjacency matrix A is dynamically generated with:\n$A = ReLU (tanh (\u03b2 (M_1 M_1^T \u2013 M_2 M_2^T)))$,\nwhere \u03b2 is a hyper-parameter which is a saturation rate of the activation function and $M_1 = M_2 = tanh (\u03b2 (E_m B_m))$ is a dynamic filter with $B^m$ as its input."}, {"title": "B. Interaction Modeling for slices with GAT", "content": "The GAT layer can model the relationships between nodes and frequencies [12]. The GAT generates the attention weight that reflects the channel quality of traffic generated by IoT devices in a slice. The input to the graph layer is a set of node features $\\{x_1...,x_N\\}$ embedded in the adjacency matrix A and the output is a new set of node features $\\{x'_1,...,x'_N\\}$,$x \u2208 R^H$, where H is the number of features for each node. We compute the attention coefficient of node z \u2208 N\u2082 to node v as follows [12]:\n$\u03b1_{zv} = \\frac{exp (LeakyReLU (q^T [W^z x_z||W^z x_v]))}{\u03a3_{\u03c9\u2208N_v} exp (LeakyReLU (q^T [W^z x_u||W^z x_v]))}$\nwhere $N_v$ is the set of immediate neighbors and W\u02dc \u2208 $R^{F\u00d7D}$ is the weight matrix of the graph. q \u2208 $R^{2D}$ is a weight vector of each node on the graph. Note that $A_{zv}$ is the weight of the link (u, v) in the current snapshot G. $\u03b1_{zv}$ indicates the importance of node features in traffic data. The attention coefficients are then used to compute the final output features for every node:\n$x'_z = \u03c3(\\sum_{u\u2208N_v} \u03b1_{zv} Wx_\u03c5)$,\nwhere \u03c3(\u00b7) is applied component-wise. The GAT layer is able to dynamically learn the relationships between different chan- nels and timestamps and abstract more meaningful information from the traffic channel of the slice."}, {"title": "C. Prediction Model", "content": "Finally, a two-layer fully connected neural network is used to obtain the final traffic prediction as follows:\n$d_m = softmax (x + b)$\nwhere \u03b8 is a learnable matrix and b is the bais. We define a cross-entropy loss to train the model as:\n$LoSS_{forecasting} (t) = \\frac{1}{T} \\sum_{t=1}^T (d^{d^{id}}_t) \\cdot \u03b1_t^{id}$"}, {"title": "IV. MULTI-AGENT FEDERATED LEARNING DYNAMIC NETWORK SLICING", "content": "The limited communication capability of wireless networks makes DQN solutions unsuitable for large networks. We propose a multi-agent federated dynamic slicing algorithm to ensure privacy and scalability. The proposed algorithm can determine the near-optimal slicing policy that meets the QoS satisfaction requirements. According to the result of the prediction of the DT forecast, the dynamic slicing algorithm aims to maximize the average resource utilization of each slice and user satisfaction. Specifically, we model FL with multiple slices as an MDP and design a multi-agent federated reinforcement learning algorithm to explore the optimization solution for IoT slices."}, {"title": "A. Problem Transformation", "content": "To maximize the long-term return for the provider while accounting for the real-time arrivals of IoT network slices, we transform the problem into a Markov decision process (MDP) [6]. An MDP is defined by a tuple (t, S, A, R) where t is an decision epoch, S is the system's state space, A is the action space and R is the reward function. The state, action, and reward can be defined as follows.\na) State: At the beginning of each time interval, the state of each slice is defined as $s_m(t) = [d_m(t), \\hat{d_m} (t-1)]$, where $d_m$ and $\\hat{d_m}$ are the actual demand and the predicted demand of the slice m.\nb) Actions: The action taken by the slice m at time t is represented by $a = \\{w_m\\}$, where $w_m$ represents the increase in the percentage of bandwidth for the m-th slice. When $w_m > 0$, $w_m$ percentage of bandwidth will be added to the rsource of the slice and when $a_m < 0$, $a_m$ percentage bandwidth of the slice will be reduced.\nc) Reward: After the state transition, each slice would gain rewards w.r.t. current state sm and actions am. The reward function of the of the slice is defined as:\n$R_m(s, a) = {\u039b\u00b7 Nm(s, a) + \u03bc\u00b7 Um(s,a)}$\nwhere \u039b and \u00b5 are the importance of the algorithm places on the resource utilization and utility, respectively [8]. The ultimate objective of the agent in the multi-agant FL system is to find the optimal slicing strategy (policy) \u03c0*."}, {"title": "B. MAFL Network slicing", "content": "Network slices collaborate to find the optimal resource allocation in a decentralized manner. The role of the slice orchestrator is to coordinate all slices to achieve a global optimal resource allocation. In this allocation process, network slices do not need to share or exchange their proprietary infor- mation, including resource availability and traffic dynamics, with each other or with the slice orchestrator. the MAFL Network slicing, consist of 1) Local Policy Iteration 2) Global Policy Aggregation. The local policy iteration is performed by the slices and the central InP controller performs the for global policy aggregation. The aggregation period for the global model is called \u03c4.\nLocal Policy Iteration: Taking advantage of Deep De- terministic Policy Gradient (DDPG) [6], an actor's network guides the update of policy parameters \u03b8t of the network slcing policy $\u03c0_{\u03b8_t}$ based on the evaluated values from the critic's network. The policy gradient is defined as follows:\n$\\nabla_{\u03b8_t}\u03c0 = \\frac{1}{N} \\sum_i \\nabla_{a_i}Q(s_m, a | \u03b8^Q) \\nabla_{\u03b8_t}\u03c0 (s_m | \u03b8^*)$.\nWe update the critic by minimizing the loss:\n$L (\u03b8^Q) = \\frac{1}{n} \\sum_{i=1}^n (y_m - Q (s_m, a_m | \u03b8^Q))^2$\nwhere $y_m = R_m + \u03b3 Q' (S_{i+1}, \u03c0' (S_{i+1} | \u03b8'))$. The target parameters in both actor and critic networks are updated as follows:\n$\u03b8 \u2190 \u03bd\u03b8 + (1 \u2212 1)\u03b8$\n$\u03b8' \u2190 \u03bd\u03b8 + (1 \u2212 1)\u03b8$\nIn the t-th iteration, each slice agent performs model update via the stochastic gradient descent (SGD) algorithm based on its local data with the following expression:\n$\u03b8_{t}^{m} \u2190 \u03b8_{t-1}^{m} - \u03b7 \u2207f_m (\u03b8_{t-1}^{m})$\nwhere \u03b7 is the learning rate and where $f_m (\u03b8) = \\frac{1}{|D_m|} L_m (\u03b8^m)$ is the loss function of the agent m, $\u03b8_{t-1}^{m}$ is the local model of the slice at the start of the t-th iteration. The local model update (m) is uploaded to the slice orchestrator for global model aggregation.\nGlobal Policy Aggregation: The slice orchestrator up- dates the global network slicing model by aggregating all local model updates from IoT slices as follows:\n$\\theta \\leftarrow \\sum_{MEM} \\frac{|D_m|}{|D|} \\theta_{t-1}^{m}$\nwhere \u03b8 denotes the aggregated model at the cloud server. After that, \u03b8 is broadcasted to the slices, which can be expressed"}, {"title": "V. NUMERICAL EVALUATIONS", "content": "The system consists of a base station with a coverage radius of 500 meters and a carrier frequency of 2 GHz. The average number of IoT devices connected to a slice is 100, which are uniformly distributed. We set the number of slices M to 6. We set the bandwidth at 10 MHz and divide it into 50 RBs. The power spectral density of additive white Gaussian noise (AWGN) and interference thresholds are -174 dBm/Hz and -101.2 dBm, respectively. The Path Loss (PL) is defined as PL (dB) = 20 log10(d) + 20 log10(f)- 27.55 where f (in MHz) and d (in meters) represent IoT device to base station channel frequency and distance respectively [13]. Our DQN model consists of 6 hidden layers with 64 neurons in each hidden layer. We set the discount factor for both the actor and critic neural networks at 0.95 and the learning rate at 0.1. The replay buffer size is 1000, and the minibatch size for sampling is 64. Furthermore, we adopt Adamoptimizer to optimize the loss function [14]. TensorFlow 2.0 is used to implement DQN and FL [15]. We compare our proposed DT with two different prediction models, i.e., a vanilla Long short-term memory (LSTM) model [16] and ARIMA model [5]. Furthermore, our proposed dynamic slicing, i.e., DT-MAFL slicing, is com- pared with the following benchmarks: (1) Federated Learning-based slicing (FL), which performs resource allocation and sends updates to the slice orchestrator. (2) Multi-agent DQN (MADQN), which models the resource allocation problem as a distributed problem and deploys DQN agents on each slice to allocate resources independently [6] and (3) Netshare, which is a centralized controller with a global network view and performs resource allocation decisions for all slices [2]. The summary of the simulation parameters used can be found in Table II."}, {"title": "B. Forecasting Performance", "content": "In Fig. 2, we show the qualitative comparison of the prediction in terms of the average traffic load (Mbs) of each slice in the BS over a period of time. The results show that the DT models can follow the wave of traffic relatively well. The LSTM and ARIMA models cannot follow it, and the ARIMA model has the worst pattern. The GAT network in our proposed DT model encodes spatial features in graph learning, which can track the spatial correlations in the 5G traffic data generated by the IoT devices in a slice. The ARIMA model increases linearly and leads to overfitting of the data set as the number of data increases. In Fig. 2b, the Root Mean Square Error (RMSE) measures the performance of the predictive models. It is helpful to estimate which model carries the largest error point based on RMSE because it magnifies the relative difference between the errors. As a measure of accuracy, the RMSE is a good indicator. Our DT model methods achieve low error rates, highlighting the importance of modeling spatial correlations in traffic forecasting."}, {"title": "C. Convergence Performance", "content": "Fig. 3 illustrates the reward and loss results of our proposed dynamic slicing system. The reward is numerical feedback that evaluates the allocation of resources of the proposed framework in Equation (14). Fig. 3a shows that our proposed DT-MAFL slicing framework has the highest reward and achieves stability quickly. The FL model can achieve relatively good performance, but the resource allocation is unstable without an accurate prediction model. The MADQN converges slower than FL and DT-MAFL due to the communication overhead. At the same time, the optimal model cannot adapt to the dynamic conditions of the IoT devices in the slice. The loss curve further proves the convergence performance of the proposed scheme in Fig. 3b. The proposed DT-MAFL has the lowest loss, indicating stable convergence."}, {"title": "D. Performance on Slice Satisfaction and Resource Utilization", "content": "This section analyzes the system's performance regarding resource utilization and QoS satisfaction. In Fig. 4a, we compare the resource utilization of the algorithms with the increasing number of users in each slice. From Fig. 4a, it can be seen that the proposed DT-MAFL achieves a higher allocation of resources than FL, MADQN and Netshare. With DT-MAFL, the prediction model can accurately predict the traffic load for the next time. Therefore, it can adapt to the dynamic changes in slice requests in a 5G network and increase resource utilization. As a result, the QoS requirements of the IoT devices in the slices are satisfied, as shown in Fig. 4b. Netshare is the most inefficient due to its lack of learning ability. This is because the QoS satisfaction values do not reach the threshold when the number of users in the slice increases. In Fig. 4b, we can also see that the QoS satisfaction of FL and MADQN decreases rapidly as the number of network users increases. The QoS satisfaction of MADQN in high load scenarios also does not reach the QoS threshold of the slices."}, {"title": "VI. CONCLUSION", "content": "This paper presents a comprehensive approach to opti- mize IoT network slice management through advanced traffic analysis and resource allocation. We introduced a novel DT architecture leveraging GAT for real-time traffic monitoring and demand forecasting within network slices. Building upon these predictions, we developed a federated multi-agent rein- forcement learning framework for dynamic network slicing, enabling inter-slice collaboration while preserving individual slice privacy. Our extensive simulations demonstrate the ef- ficacy of the proposed methods in significantly enhancing demand prediction accuracy for network slices and substan- tially reducing the communication overhead associated with dynamic network slicing. These improvements translate to more efficient resource utilization, improved QoS, and en- hanced scalability of IoT networks. Future work includes exploring the integration of policy distillation methods, where knowledge from multiple specialized policies can be consol- idated to improve collaboration and address Non-IID (Non- Independent and Identically Distributed) challenges in network slicing due to diverse requirements for slices. This approach could potentially further optimize the learning process and improve the adaptability of our system to diverse network conditions. By leveraging policy distillation, we aim to create more robust and generalizable policies that can effectively handle the heterogeneous nature of network slices, leading to more efficient resource allocation and improved overall network performance."}]}