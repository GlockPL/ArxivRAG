{"title": "Cancer Vaccine Adjuvant Name Recognition from Biomedical Literature using Large Language Models", "authors": ["Hasin Rehana", "Jie Zheng", "Leo Yeh", "Benu Bansal", "Nur Bengisu \u00c7am", "Christianah Jemiyo", "Brett McGregor", "Arzucan \u00d6zg\u00fcr", "Yongqun He", "Junguk Hur"], "abstract": "Motivation: An adjuvant is a chemical incorporated into vaccines that enhances their efficacy by improving the immune response. Identifying adjuvant names from cancer vaccine studies is essential for furthering research and enhancing immunotherapies. However, the manual curation from the constantly expanding biomedical literature poses significant challenges. This study explores the automated recognition of vaccine adjuvant names using state-of-the-art Large Language Models (LLMs), specifically Generative Pretrained Transformers (GPT) and Large Language Model Meta Al (Llama).\nMethods: We utilized two datasets: 97 clinical trial records from AdjuvareDB and 290 PubMed abstracts annotated with the Vaccine Adjuvant Compendium (VAC). Two LLMS, GPT-40 and Llama 3.2 were employed in zero-shot and few-shot learning paradigms with up to four examples per prompt. Prompts explicitly targeted adjuvant names, testing the impact of contextual information such as substances or interventions. Outputs underwent automated and manual validation for accuracy and consistency.\nResults: GPT-40 consistently attained 100% Precision across all situations, while also exhibiting notable enhancements in Recall and F1-scores, particularly with the incorporation of interventions. On the VAC dataset, GPT-40 achieved a maximum F1-score of 77.32% with interventions, surpassing Llama-3.2-3B by approximately 2%. On the AdjuvareDB dataset, GPT-40 reached an F1-score of 81.67% for three-shot prompting with interventions, surpassing Llama-3.2-3B's maximum F1-score of 65.62%. These results highlight the critical role of contextual information in enhancing model performance, with GPT-40 demonstrating a superior ability to leverage this enrichment.\nConclusion: Our findings demonstrate that LLMs excel at accurately identifying adjuvant names, including rare and novel variations of naming representation. This study emphasizes the capability of LLMs to enhance cancer vaccine development by efficiently extracting insights from clinical trial data. Future work aims to broaden the framework to encompass a wider array of biomedical literature and enhance model generalizability across various vaccines and adjuvants.", "sections": [{"title": "1. Introduction", "content": "Vaccine represents one of the most significant advancements in medical history, providing effective prevention and control of infectious diseases. Cancer immunotherapy has leveraged vaccine technologies to stimulate the immune system to recognize and destroy tumor cells. Vaccines have markedly diminished the effects of infectious diseases, with a historical trajectory commencing 500 years ago and culminating in the eradication of smallpox in 1980. The swift advancement of COVID-19 vaccines has emphasized the significance of vaccine innovation, showcasing improvements in laboratory methodologies that persist in saving millions of lives and providing critical insights for future pandemic preparedness (Saleh et al., 2021).\nExtending these successes to non-viral tumors and improving overall cancer prevention strategies are necessary next steps in cancer vaccine development, which has made significant achievements in preventing virus-related cancers, especially with successful vaccines. However, there are still obstacles to overcome, such as identifying target antigens in at-risk individuals and inducing long-lasting immune responses (Ruzzi et al., 2025). These vaccines frequently incorporate adjuvants-substances that enhance the immunogenicity of antigens to improve their efficacy. Identifying and characterizing potent adjuvants remains critical for advancing cancer vaccine development, as these components directly influence the magnitude and quality of immune responses.\nCancer vaccine development has undergone significant evolution over the past decades, with advancements in molecular biology, immunology, and bioinformatics contributing to novel approaches in vaccine design. A crucial aspect of cancer vaccines is the inclusion of adjuvants, which are pivotal in enhancing the immune response against weakly immunogenic tumor antigens. Traditional adjuvants, such as aluminum salts and oil-in-water emulsions, have been widely studied and utilized in prophylactic vaccines. However, the unique immunosuppressive microenvironment of tumors necessitates the development of more potent and specialized adjuvants tailored for therapeutic cancer vaccines. Finding the best combinations of well-known or currently available adjuvants could aid in developing new ones for cancer immunotherapy. This superiority of immunostimulatory or immunomodulatory adjuvant combinations over individual use has been well-demonstrated (Temizoz et al., 2016).\nUnderstanding vaccine adjuvants and their processes to boost T cell responses and improve clinical outcomes for cancer patients is crucial, especially as cancer vaccines are considered potential partners with immunotherapies such as T cell checkpoint inhibition (Khong and Overwijk, 2016). Artificial Intelligence (AI) is transforming the expensive and time-consuming drug development process by improving patient selection and streamlining target discovery, especially in oncology. Although obstacles exist, such as limited data accessibility and a lack of trained staff, AI can enhance cancer vaccination effectiveness through noveladjuvantdesign and by improving customized therapy (Zhanget al., 2024).\nIn recent years, computational approaches have emerged as powerfultools foradvancingcancer vaccine research. Machine learning (ML) techniques have been applied to predict immunogenic epitopes, analyze clinical trial outcomes, and identify novel antigens. Kumar et al. highlight how advancements in AI, particularly ML and computational modeling, have enabled the precise prediction and optimization of neoantigens, improved vaccine design, and facilitated the creation of personalized cancer vaccines (Kumar et al., 2024).\nStudies have demonstrated the efficacy of models like Generative Pretrained Transformers (GPT) and Large Language Model Meta AI (Llama) in tasks such as named entity recognition and relation extraction, which are critical for understanding the interplay between vaccine components and their immunological outcomes (Palepu et al., 2024). A novel annotation schema for oncology information was created and evaluated using large language Models (LLMs), demonstrating that although GPT-4 exhibited superior performance in extracting comprehensive oncological histories from clinical notes, substantial enhancements are still required for dependable use in clinical research and patient care documentation (Sushil et al., 2024).\nFor instance, Ferber et al. illustrates that localized fine-tuning of Llama models via the QLoRA algorithm can proficiently produce physician letters in radiation oncology, achieving significant therapeutic advantages and efficiency with minimalcomputational resources (Ferber et al., 2024). Using LLMs, authors developed an automated pipeline that accurately matches cancer patients to clinical trials, identifying 93.3% of relevant trials and achieving matches in 92.7% of cases. This improves the process of matching patients to trials and may be better than qualified medical professionals (Hou et al., 2024).\nAlthough research leveraging LLMs for cancer vaccine adjuvant recognition is still nascent, a few pioneering studies underscore its potential. For instance, VaxLLM fine-tuned a large LLM to annotate vaccine components, including adjuvants, in Brucella vaccines (Li et al., 2024). Similar methodologies could be adapted to cancer vaccine research, focusing on extracting adjuvant-specific entities from clinical trial data. Studies on oncology guidelines and personalized oncology have also explored LLMs for tasks like zero-shot learning, achieving notable accuracy improvements through few-shot training (Benary et al., 2023).\nWhile these applications are not directly centered on cancer vaccine adjuvants, they highlight the broader utility of LLMs in biomedical research and their promise to advance this niche area. This manuscript investigates the application of LLMs for recognizing cancer vaccine adjuvant names from clinical trial data. By harnessing the advanced NLP capabilities of LLMs, this study proposes a systematic framework for extracting adjuvants referenced in cancer vaccine trials. This approach not only facilitates a more comprehensive understanding of the role of adjuvants in cancer immunotherapy but also underscores the potential of LLMs to advance biomedical research through data-driven insights."}, {"title": "2. Adjuvant Databases and Resources", "content": "The discovery and development of vaccine adjuvants rely heavily on curated databases and resources that compile critical information on adjuvant properties, usage, and safety. Several prominent databases have emerged as invaluable tools to support researchers in accessing and analyzing adjuvant-related data:\nAdjuvareDB: AdjuvareDB is a comprehensive web-based database that compiles information on candidate adjuvants in clinical use (Ren et al., 2024). It provides detailed records of adjuvant composition, function, and other attributes, serving as a valuable resource for understanding their applications in immunotherapy.\nVaxjo: Vaxjo is a centralized web-based database and analysis platform designed to curate, store, and analyze vaccine adjuvants and their roles in vaccine development (Sayers et al., 2012). The database includes detailed information such as adjuvants names, components, structure, appearance, storage conditions, preparation methods, function, safety, and associations with specific vaccines. This robust database facilitates the exploration of adjuvant characteristics and their applications across diverse vaccine platforms.\nVaccine Adjuvant Compendium (VAC): The VAC database (https://vac.niaid.nih.gov/) focuses on providing comprehensive records foreach adjuvant, includingpoints of contact for intellectual property (IP) holders. Each entry in VAC encompasses information such as the Vaccine Ontology ID, detailed properties of the adjuvant, preclinical and clinical usage data, associated publications, product grade, and available formulations. By offering these comprehensive insights, VAC aids researchers in identifying and leveraging adjuvants for vaccine development.\nBy centralizing and standardizing critical information on adjuvants, these databases are advancing vaccine research. They enable researchers to make informed decisions when selecting adjuvants for experimental and clinical applications, thus accelerating the development of next-generation vaccines."}, {"title": "3. Large Language Model (LLM)", "content": "LLMs are machine learning models designed to process and generate human-like text by learning patterns and relationships within vast textual datasets (Thirunavukarasu et al. 2023). These models, such as Generative Pretrained Transformers (GPT) and Llama, utilize transformer-based architectures, enabling them to handle complex linguistic tasks with high accuracy. Their capabilities extend across a broad spectrum of natural language processing (NLP) applications, including named entity recognition (NER), text summarization, translation, and contextual understanding.\nIn the biomedicaldomain, LLMs have demonstrated immense potential in addressing challenges posed by unstructured data. Tasks such as extracting meaningful information from scientific literature, annotating clinical data, and identifying relationships between entities have greatly benefited from LLM-driven automation. Their ability to contextualize and synthesize information makes them particularly valuable in fields requiring the analysis of large and complex datasets, such as cancer vaccine development.\nOne of the notable applications of LLMs is in named entity recognition, where these models are fine-tuned to identify and categorize specific entities, such as genes, proteins, or adjuvants, from text. For instance, studies leveraging fine-tuned LLMs, like VaxLLM, have shown the effectiveness of such approaches in annotating vaccine-related components, paving the way for similar applications in cancer vaccine research. Moreover, few-shot and zero-shot learning capabilities further enhance the utility of LLMs, enabling them to generalize to new tasks with minimal labeled data (Li et al., 2024).\nThe evaluation of models such as GPT and BERT for protein-protein interaction identification (Rehana et al., 2024b) and nested named entity recognition using multilayer BERT-based architectures (Rehana et al., 2024a) further showcases the adaptability of LLMs for nuanced and complex biomedical tasks. These advancements underline the transformative potential of LLMs in automating and scaling research efforts, especially in specialized domains like cancer vaccine adjuvant discovery."}, {"title": "4. Methods", "content": "We have employed two LLMs, namely Llama and GPT, in this research. Figure 1 illustrates the overall structure of our methodology."}, {"title": "4.1 Llama", "content": "The Llama is a family of open-source large-scale language models developed by Meta AI, designed to achieve cutting-edge performance across various benchmarks (Touvron et al., 2023). The initiative prioritizes openness and efficiency, allowing the academic community to use high-performing models without relying on proprietary datasets. Key contributions include efficient scaling, which challenges the concept that only the largest models get the best results.\nLlama takes advantage of publicly available datasets such as Common Crawl, Wikipedia, and GitHub repositories, which makes the models powerful and compatible with open-source platforms. Llama models are available in various configurations, including lightweight versions. The lightweight models (e.g. Llama 3.2 1B, Llama 3.2 3B) are optimized for devices with constrained resources without significantly compromising accuracy. However, the 1B Llama model struggles to follow the instruction to provide consistently structured output format in our study (data not shown). Llama models demonstrate competitive performance across tasks, including common sense reasoning, question answering, and reading comprehension. They also have impressive zero-shot and few-shot learning skills. Furthermore, Llama models are trained to utilize energy-efficient techniques by prioritizing memory optimization and minimizing activation recomputation. This technique is consistent with the ideas of sustainable AI, lowering computational resource demands while maintaining good performance.\nOur research utilized the Llama 3.2 3B model. The temperature parameter was set to 0.0001 to balance creativity and coherence in responses. The maximum token limit was set to 100 to ensure concise output. The model was configured to perform in both zero-shot and few-shot learning setups, using zero to four-shot examples for task adaptation. The transformer-based design of Llama, with multi-head self-attention mechanisms, enables adequate contextual understanding across input text, regardless of positional relationships."}, {"title": "4.2 GPT", "content": "GPT models represent a groundbreaking class of LLMs designed to process and generate natural language text (Radford, 2018). Developed by OpenAI, GPT models, such as GPT-3 and GPT-4, have set a new standard for natural language processing (NLP) tasks, owing to their remarkable ability to understand context, generate coherent responses, and perform complex linguistic reasoning. Early studies demonstrate GPT models' potentialin successfully addressing complex biomedical challenges, such as drug discovery optimization and protein-protein interaction identification, with high accuracy and efficiency. Their transformer-based architecture allows them to process large volumes of unstructured data, making them invaluable for applications like literature mining and clinical data analysis.\nOur study employed GPT-40 (Hurst et al., 2024) for cancer vaccine adjuvant identification with a temperature value of 0.0001 to generate precise and controlled outputs. The model was utilized in a zero-shot and few-shot learning paradigm, incorporating zero to four-shot examples when necessary to enhance task-specific performance. One key strength of GPT models is their ability to perform few-shot and zero-shot learning, a technique in which the model can learn new tasks with minimal or no prior exposure to labeled data.\nDespite challenges such as the potential risk of generating hallucinated information and the necessity for rigorous output validation, GPT models' scalability, versatility, and seamless integration with computationaltools position them as crucial assets in accelerating advancements in cancer vaccine development, drug discovery, and other critical areas of biomedical research."}, {"title": "4.3 Data Preprocessing", "content": "This study utilized datasets for cancer vaccine adjuvant name recognition from two primary sources: gold standard annotated clinical trial records from the AdjuvareDB website (http://tmliang.cn/adjuvaredb/) and PubMed abstracts annotated in the Vaccine Adjuvant Compendium (VAC) database (https://vac.niaid.nih.gov/). The AdjuvareDB dataset included 97 trials manually annotated by the AdjuvareDB team. The VAC dataset comprised 290 abstracts from clinical and preclinical studies collected from PubMed.\nThe yearly distribution of the 290 abstracts from the VAC dataset illustrated in Figure 2 illustrates a significant increase in cancer vaccine adjuvant-related studies in recent years. This trend underscores the growing complexity and scale of curating cancer vaccine-related information manually.\nTo meet the urgent need for scalable solutions in cancervaccine research, this study automated the identification of adjuvant names using advanced LLMs. A detailed breakdown of the datasets, including annotation sources, is presented in Table 1. These two datasets have formed a robust foundation for our research to develop and evaluate automated adjuvant name recognition methods."}, {"title": "4.4 Prompt Engineering", "content": "We designed a series of carefully crafted prompts tailored for each input type to extract target cancer vaccine adjuvant names effectively from PubMed abstracts and clinical trial datasets. The prompts explicitly defined the goal as identifying and extracting specific vaccine adjuvant names mentioned in the input text.\nThe significant parts of the prompt are task specification, key instructions, output format, and task input. Each query was designed to process one article or trial dataset at a time to avoid data mixing. Input data contained the unique identifier (PMID/NCT Number), title, article/trial data, and, optionally, substances/interventions.\nTo evaluate the impact of additional context, for PubMed abstracts, prompts were tested with and without the inclusion of substances to determine their role in enhancing extraction accuracy. Similarly, for clinical trials, prompts were evaluated with and without the list of interventions to assess their influence on identifying relevant adjuvant names. The zero-shot prompts for both datasets are detailed in Figures 3 and 4, which illustrate the basic structure and configuration for each setting."}, {"title": "4.5 Postprocessing", "content": "We have employed a systematic postprocessing approach to extract the meaningful response from the LLM models. The process involved data cleaning, removing duplicates, formatting standardization and ensuring the response was complete. We have removed any details other than the tab-delimited table and duplicate rows to avoid unnecessary redundancy. We have ensured outputs adhered to the specified tab-separated values (TSV) format, including the unique identifier (PMID for PubMed and NCT ID for clinical trials) and corresponding adjuvant names. We have checked for a \"Done\" markerin the output to signal the end of processing for each input. This organized step afterresponse extraction ensured that the data met high standards of accuracy and consistency. This made it possible to use the data reliably in later analyses and helped reach the goal of automatically finding cancer vaccine adjuvants in biomedical literature."}, {"title": "4.6 Performance Evaluation", "content": "The study evaluated a model's performance using Precision, Recall, and F1 scores. Precision measures the accuracy of true positive outputs, by assessing how well the model minimized nonspecific or spurious results. A higher Precision score indicates that the model minimized nonspecific outputs and focuses on relevant results. Recall measures the model's ability to identify all relevant instances, including missed potential positives. A higher Recall score indicates that the model captures a larger proportion of true positive instances, even with nonspecific outputs. The F1 score, the harmonic mean of Precision and Recall, offers a balanced performance measure. A higher F1 score indicates a model that effectively balances Precision and Recall, ensuring output accuracy and comprehensiveness. The equations for these metrics in this research are,\nPrecision = $\\frac{True Positive}{True Positive+Nonspecific Output}$ (1)\nRecall = $\\frac{True Positive}{Total Identification+Missed Instances}$ (2)\nF1 Score = $\\frac{2 \\times Precision \\times Recall}{Precision + Recall}$ (3)\nThese metrics collectively provide a robust framework for evaluating the model's accuracy, comprehensiveness, and balance in its outputs. By analyzing these metrics, the study identified areas for targeted improvement, ensuring alignment with the intended objectives.\nThe evaluation process employed a combination of automated and manual validation methods to ensure the accuracy and reliability of the evaluation scores. Automated validation served as the initial step in the pipeline, applying an exact-match (case insensitive) criterion to compare the model's outputs against a curated dictionary of predefined mappings. The dictionary, meticulously compiled and validated in advance, acted as the reference for determining correctness. Automated validation was efficient in quickly identifying outputs that matched the expected results. However, its limitations in handling ambiguous, context-dependent, or nuanced cases, necessitated further scrutiny through manual validation.\nMismatched cases identified during the automated process were subjected to manual validation to address the limitations. A team of six domain experts thoroughly reviewed each mismatched output to determine its correctness. At least two validators reviewed each case independently, ensuring that each instance was examined from multiple perspectives, reducing the likelihood of oversight or bias. In cases where the two initial validators disagree, the instance was forwarded to a third validator. The third validator reviewed the case independently and provided the final decision, resolving discrepancies and ensuring a fair and accurate validation. Findings are carefully documented throughout the manual validation process, including the reasons for disagreements and their resolution."}, {"title": "5. Results and Discussion", "content": "A few examples of GPT-40 and LlaMA-3.2 outputs are listed in Table 2."}, {"title": "6. Future Direction", "content": "In the future, our research will extend beyond cancer vaccine adjuvants to include those targeting infectious diseases, addressing broader public health challenges. We plan to explore larger variants of Llama models (e.g. Llama-3.3 70B) as well as other open-access LLMs to enhance the flexibility and efficiency of our methodologies. Additionally, we aim to integrate vaccine ontology into our data preprocessing and fine-tuning pipelines, ensuring improved semantic accuracy and a deeper contextual understanding of adjuvants. By refining model generalizability and expanding datasets, we aim to create robust framework that contribute to advancing vaccine research and innovation on a global scale."}]}