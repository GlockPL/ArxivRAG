{"title": "EEG-ReMinD: Enhancing Neurodegenerative EEG Decoding through Self-Supervised State Reconstruction-Primed Riemannian Dynamics", "authors": ["Zirui Wang", "Zhenxi Song", "Yi Guo", "Yuxin Liu", "Guoyang Xu", "Min Zhang", "Zhiguo Zhang"], "abstract": "The development of EEG decoding algorithms confronts challenges such as data sparsity, subject variability, and the need for precise annotations, all of which are vital for advancing brain-computer interfaces and enhancing the diagnosis of diseases. To address these issues, we propose a novel two-stage approach named Self-Supervised State Reconstruction-Primed Riemannian Dynamics (EEG-ReMinD), which mitigates reliance on supervised learning and integrates inherent geometric features. This approach efficiently handles EEG data corruptions and reduces the dependency on labels. EEG-ReMinD utilizes self-supervised and geometric learning techniques, along with an attention mechanism, to analyze the temporal dynamics of EEG features within the framework of Riemannian geometry, referred to as Riemannian dynamics. Comparative analyses on both intact and corrupted datasets from two different neurodegenerative disorders underscore the enhanced performance of EEG-ReMinD.", "sections": [{"title": "I. INTRODUCTION", "content": "Developing robust, generalizable, and interpretable EEG decoding algorithms is crucial for enhancing brain-computer interfaces and improving disease diagnosis. Neurodegenerative diseases such as Parkinson's Disease (PD) and Mild Cognitive Impairment (MCI) exemplify the challenges in this area, characterized by the subtle and varied manifestations in resting-state EEG data [1]\u2013[4]. While EEG holds significant potential for diagnostic applications [5]\u2013[8], the variability between subjects and data sparsity complicates the development of effective models. These challenges underscore the need to explore suitable low-dimensional feature spaces for robust representation and to develop self-supervised learning (SSL) strategies that reduce reliance on clinical labels.\nGiven the decline in synchronous neural activity in neurodegenerative diseases, we explore EEG's low-dimensional space through graph mapping and geometric learning to develop robust representations. Research in Euclidean space utilizes Graph Neural Networks (GNN) to map spatial relationships between EEG channels, effectively capturing structural features through graph constructions [9], [10]. Transitioning to Riemannian space, the adaptations leverage the manifold's capacity to adapt to EEG's inherent non-Euclidean structure [11]. Utilizing the distinct geometric properties of Riemannian manifolds, these models harness invariant metrics to enhance robustness against the inherent non-stationarity and noise in EEG signals, thereby improving generalization across complex EEG data [12]\u2013[16]. Recent innovations in this domain include the deployment of a manifold-Euclidean combined model that specifically addresses the representation of spatio-temporal features of EEG data [17], and the employment of attention mechanisms to analyze sequences of functional brain networks in Riemannian space [18]. Consequently, these advancements inspire us to integrate functional networks with geometric representation learning to enhance model interpretability.\nHowever, these methods rely on supervised learning, which requires extensive labeled data. This is particularly challenging for neurodegenerative diseases, where subtle and variable EEG characteristics make accurate labeling difficult. Additionally, EEG data are prone to corruption, such as continuous segment and channel disruptions. Thus, developing self-supervised learning strategies is crucial to reduce label dependency and enhance model robustness by learning intrinsic representations that effectively handle EEG data corruptions. Reconstruction learning captures temporal and frequency features [19], [20]. Contrastive learning enhances feature extraction by maximizing similarity between different samples [21], [22].\nDespite these advances, current approaches have not fully leveraged graph construction and geometric representation learning to develop self-supervised algorithms. Therefore, this paper introduces a novel two-stage EEG decoding approach, termed Self Supervised State Reconstruction-Primed RieMnnian Dynamics (EEG-ReMinD) to overcome existing limitations. The main contributions of this paper can be summarized as follows: 1) We developed a two-stage EEG-ReMinD training strategy that primes robust representations via SSL, validated on MCI and PD datasets. 2) Our SSL framework is based on model internal state reconstruction, uniquely identifying states within time-varying geometric maps in Riemannian manifold spaces. 3) We facilitate state reconstruction from a Riemannian dynamics perspective by incorporating spatio-temporal filters, learnable positional encodings, and attention-based analysis of time-varying geometric maps."}, {"title": "II. METHODS", "content": "The proposed EEG-ReMinD model is illustrated in Fig.1 and consists of an unsupervised pre-training stage followed by a fine-tuning stage that utilizes limited labeled data. The initial stage of the framework employs SSL devoid of labels, utilizing Riemannian manifold geometric representations. This phase comprises the systematic construction and subsequent reconstruction of Riemannian geometric features, which serve as the internal state within the trainable model (refer to Sections A and B). The second stage capitalizes on the pre-trained model to facilitate brain state recognition, utilizing only a sparse amount of labeled data (refer to Section C).\nLet the multi-channel EEG signals be denoted by a matrix $X \\in \\mathbb{R}^{C\\times T}$, where C represents the number of channels and T corresponds to the number of time points. To capture inter-channel relationships over time and intra-channel temporal dynamics, we utilized spatiotemporal filters comprising two convolutional layers to extract generalized representations across multiple channels and periods, enhancing robustness against noise and artifacts. The output of these filters yields a feature matrix, denoted as $X' \\in \\mathbb{R}^{C'\\times T'}$. This enables the subsequent construction of the Riemannian geometric state, effectively incorporating local channel correlations and temporal factors.\nTraditional positional encoding focuses on incorporating sequence order information. Nevertheless, considering that the subsequent Riemannian geometric states should effectively capture the geometric relationships between electrodes, we introduce 3D-Geometric position encoding to integrate geometric positional information:\n$\\text{Enc}(m_s, i) =\\begin{cases}\\sin \\left(\\frac{m_s}{\\Phi_i}\\right) & i = 2k, k \\in \\mathbb{N}, \\\\\\cos \\left(\\frac{m_s}{\\Phi_i}\\right) & i = 2k + 1, k \\in \\mathbb{N}.\\end{cases}$ (1)\n$\\text{GPE}(x_s, y_s, z_s, i) = \\text{cat} \\left[\\text{Enc}(x_s, i), \\text{Enc}(y_s, i), \\text{Enc}(z_s, i)\\right].$ (2)\nHere, $(X_s, Y_s, 2_s)$ represents the 3D coordinates of the electrodes, where s denotes the s-th sensor. The variable i represents the index of the feature dimension, and I is a constant. The final encoding GPE, is generated by concatenating the encodings of $x_t$, $y_t$, and $z_t$. By incorporating this learnable 3-D geometric position encoding of the electrodes into the EEG features extracted by the CNN, the subsequent construction of the Riemannian geometric states can gain accurate positional information, thereby enhancing its robustness.\nAfter incorporating 3-D geometric position encoding, the data is segmented into n sequence segments, denoted as ${X_1, X_2,..., X_{n-1}, X_n}$. For each of these segments, considering the correlation characteristics of the EEG signal between electrodes, we constructed the internal geometric states sequence (functional brain networks) to capture the functional connectivity between electrodes. As a result, the segments ${X_1,X_2,..., X_{n-1}, X_n}$ are transformed into the internal geometric states sequence ${G_1, G_2, ..., G_{n-1},G_n}$, where each internal geometric state $G_{mi,j}$ is defined as follows:\n$G_{mi,j} = \\frac{\\text{xcovar}(X_{mi}, X_{mj})}{\\|X_{mi}\\|\\|X_{mj}\\|}, \\quad 1 \\leq i, j \\leq C$ (3)\nwhere xcovar(\u00b7,\u00b7) denotes covariance function, m presents the mth sequence. $X_{m_i}$ presents the mth sequence's ith channel. $G_{mi_j}$ presents the mth sequence's ith row jth column value. The internal geometric states sequence ${G_1, G_2, ..., G_n}$ is projected from Euclidean space onto a Riemannian manifold via positive-definite mapping, forming the Riemannian geometric states sequence ${G_1, G_2,..., G_{n-1}, G_n}$.\nTo capture the temporal dependencies within the Riemannian geometric states sequence, we introduce an attention-based computation strategy based on Riemannian manifold, where QKV and the corresponding attention computations are performed within the framework of Riemannian Dynamics."}, {"title": "B. Reconstruction of Internal States", "content": "In this framework, we focus on time-varying behavior and evolution of the EEG data's Riemannian geometric representation, using Riemannian metrics to compute geometric properties such as distances in a non-Euclidean space. The advantage of using Riemannian Dynamics lies in their metric invariance properties, which enable the model to generalize well to complex EEG signals while also being robust to the non-stationarity and noise inherent in EEG signals.\nWe calculate the Q, K, V of the brain network through bilinear mapping, as follows:\n$Q_i = W_q G W_i, K_i = W_k G W_i, V_i = W_v G W_i^T$ (4)\nHere, $W_q, W_k$, and $W_v$ are the weight matrices of the linear mappings. Through the above bilinear mapping, $Q, K, V$ are constrained to be Symmetric Positive Definite(SPD) matrices on the manifold. The standard attention mechanism based on Euclidean distance cannot directly compute similarity in Riemannian space. To address this, we utilize the Log-Euclidean metric method [13] which effectively calculates the center on the SPD manifold and uses Log-Euclidean distance as a similarity measure in Riemannian space, the geodesic distance from $Q_i$ to $K_j$ is given by:\n$\\text{LE-distance}(Q_i, K_j) = ||\\text{Log}(Q_i) - \\text{Log}(K_j)||_F$ (5)\nThe similarity calculation is as follows:\n$S_{ij} = \\text{Sim}(Q_i, K_j) = \\frac{1}{1 + \\text{log}(1 + \\text{LE-distance}(Q_i, K_j))}$ (6)\nThen the sub-matrix is normalized with the Softmax function to perform normalization along each row:\n$S' = \\text{Softmax}(S) = \\text{Softmax} ([S_{ij}]_{n \\times n}) = [S'_{ij}]_{n \\times n}$ (7)\nwhere $S'_{ij} = \\frac{\\text{exp}(S_{ij})}{\\sum_{k=1}^n \\text{exp}(S_{ik})}, \\forall i, j \\in \\{1, ..., n\\}$. Furthermore, The weighted Log-Euclidean mean [23] can be defined as:\n$\\text{G}(W_1,..., W_n, P_1,..., P_n) = \\text{exp} \\left(\\sum_{i=1}^n W_i \\text{log}(P_i)\\right)$ (8)\nwhere the weight of each SPD matrice${X_i}_{i=1}^n$ is defined as ${\\omega_i}_{i=1}^n$, ${\\omega_i}_{i=1}^n$ satisfies the convexity constraint definition. By utilizing the weighted Log-Euclidean mean,we combine $V_1,..., V_k$ and the attention-score matrix to get the final the Riemannian geometric representation sequence ${V_1, V_2,..., V_m}$:\n$V_i = \\text{G}(S_{i1},..., S_{in}, V_1,..., V_n) = \\text{exp} \\left(\\sum_{j=1}^n S_{ij} \\text{log}(V_j)\\right)$ (9)\nTo ensure that the Riemannian geometric representation effectively captures temporal and structural relationships as well as EEG time-varying behavior, we use a simple MLP layer to reconstruct the Riemannian geometric states sequence, ${G_1, G_2,..., G_{n-1}, G_n}$. The reconstruction yields the sequence ${\\hat{G_1}, \\hat{G_2},..., \\hat{G_{n-1}}, \\hat{G_n}}$ and then optimize the model by minimizing the Mean Squared Error (MSE) loss between the reconstructed sequence and the target sequence.\n${\\{\\hat{G_1}^{(r)}, \\hat{G_2}^{(r)},..., \\hat{G_{n-1}}^{(r)}, \\hat{G_n}^{(r)}\\}} = MLP(V_1, V_2, ..., V_n)$ (10)\n$\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^n \\| \\hat{G_i} - G_i \\|^2$ (11)\nBy reconstructing Riemannian geometric states sequence, the model retains the core structure of the EEG data at multiple levels, allowing it to recover crucial information even in the presence of poor data quality. This enhances the model's robustness to incomplete data, enabling it to remain resilient in the face of noise or anomalies in the input data."}, {"title": "C. Limited Labeled Data Fine-tuning Stage", "content": "By minimizing the reconstruction loss of Riemannian geometric representations during the pre-training phase, we develop a Riemannian geometric encoder with enhanced representative capabilities. Then, the pre-trained encoder can process the new EEG data and generate the Riemannian representations for classification. This stage requires only 10% labels of training data for supervised fine-tuning, and tests on the remaining fold to obtain the cross-validation results."}, {"title": "III. MATERIALS AND RESULTS", "content": "The dataset from the University of New Mexico (UMN) [24], comprises EEG recordings of 27 PD patients and 27 healthy subjects. The dataset was acquired using 64-channel Ag/AgCl electrodes with the Brain Vision system at a sampling rate (frequency) of 500 Hz.\nThe dataset from a hospital in city A, includes 46 MCI patients and 43 healthy subjects. The dataset was acquired using 62 Ag/AgCl electrodes with the Brain Vision system at a sampling rate (frequency) of 5000 Hz.\nOur computational environment is set up with PyTorch 2.0.1 and Python 3.10.1, using an NVIDIA RTX 3090 for training. For the PD dataset, segments are defined with 500 sampling points, and we use 3-fold cross-validation. For the MCI dataset, segments are defined with 2000 sampling points each, and we employ 4-fold cross-validation for the experiments. For both datasets, we predict the label for each segment and then aggregate these predictions for the corresponding subject to assess the individual's disease status.\nTo validate the effectiveness of our experimental model, we compared it with various feature engineering methods, supervised and semi-supervised learning approaches, including correlation-based [25] and SPD-based [26] functional connectivity features, Tensor-CSPNet [27], MAtt [17], COMET [28], CTW [29], and BNMTrans [18]. We pre-trained our model using the N-1 Folds unlabeled training set and fine-tuned it with only a small amount of labeled data (10% of labeled data in N-1 Folds). As shown in TABLE I, the results demonstrated that our proposed EEG-ReMinD achieved state-of-the-art (SOTA) performance, thereby validating the effectiveness of our SSL-based two-stage methods from the perspective of Riemannian dynamics in decoding neurodegenerative EEG signals.\nTo test the robustness of the proposed EEG-ReMinD against corrupted data, we compared it with BNMTrans and COMET. In the experiments, the training data was intact while the test data was corrupted in three ways: Continuous Segment Corruption, where data was corrupted in random and continuous T/2 time segments; Channel Corruption, where the first and second channels were corrupted; and Non-Continuous Random Corruption, where 50% of sampling points in both channels and time were randomly corrupted in each sample. For our model, during the pre-training phase, we first compute the Riemannian geometric states sequence for the intact EEG signals. Then, we implement data masking to the original EEG signals and train the framework using these masked EEG signals. The model then reconstructs the Riemannian geometric states from the masked data. Finally, we calculate the MSE loss by comparing the reconstructed Riemannian geometric states with the original states obtained from the complete EEG signals. Reconstructing the Riemannian geometric states sequence helps the model maintain robustness against noise or anomalies in the input data. By preserving the core structure of the data across multiple layers, the model can recover essential information even with poor data quality, enhancing its adaptability to incomplete data. TABLE II have demonstrated that our framework exhibits strong resistance to corrupted data, maintaining robust performance even under data degradation.\nTo evaluate the effectiveness of ReMinD's key components, we conducted ablation experiments in a top-down manner, including modifying our Manifold-Euclidean integrated state reconstruction algorithm using either pure manifold or Euclidean transformer-based SSL (ManiSSL/EucliSSL), removing the SSL pre-training stage (w/o SSL), removing the 3D geometric positional encodings (w/o 3D-Pos), and removing the spatiotemporal convolutional filters (w/o Filter).\nThe experiments were performed on PD and MCI datasets, as summarized in Table III. We demonstrate the superior performance of our two-stage learning approach, the innovative nature of our state reconstruction method, and the essential role of the incorporated positional and filtering modules."}, {"title": "IV. CONCLUSION", "content": "In this study, we propose a novel two-stage EEG decoding framework named EEG-ReMinD, which is initially pre-trained using self-supervised internal state reconstruction that incorporates 3-D geometric position information and Riemannian dynamic analysis. Three experiments validated on two different neurodegenerative EEG datasets demonstrate the efficacy of EEG-ReMinD in learning from limited labels and addressing data corruption. Our proposed method offers new insights into semi-supervised EEG decoding strategies."}]}