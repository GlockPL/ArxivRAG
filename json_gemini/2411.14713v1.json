{"title": "LIBER: Lifelong User Behavior Modeling Based on Large Language Models", "authors": ["Chenxu Zhu", "Jianghao Lin", "Xiangyang Li", "Shigang Quan", "Xiaoling Cai", "Yunjia Xi", "Ruiming Tang", "Bo Chen", "Hong Zhu", "Weinan Zhang"], "abstract": "Click-Through Rate (CTR) prediction plays a vital role in recommender systems. Recently, large language models (LLMs) have been applied in recommender systems due to their emergence abilities. While leveraging semantic information from LLMs has shown some improvements in the performance of recommender systems, two notable limitations persist in these studies. First, LLM-enhanced recommender systems encounter challenges in extracting valuable information from lifelong user behavior sequences within textual contexts for recommendation tasks. Second, the inherent variability in human behaviors leads to a constant stream of new behaviors and irregularly fluctuating user interests. This characteristic imposes two significant challenges on existing models. On the one hand, it presents difficulties for LLMs in effectively capturing the dynamic shifts in user interests within these sequences, and on the other hand, there exists the issue of substantial computational overhead if the LLMs necessitate recurrent calls upon each update to the user sequences. In this work, we propose Lifelong User Behavior Modeling (LIBER) based on large language models, which includes three modules: (1) User Behavior Streaming Partition (UBSP), (2) User Interest Learning (UIL), and (3) User Interest Fusion (UIF). Initially, UBSP is employed to condense lengthy user behavior sequences into shorter partitions in an incremental paradigm, facilitating more efficient processing. Subsequently, UIL leverages LLMs in a cascading way to infer insights from these partitions. Finally, UIF integrates the textual outputs generated by the aforementioned processes to construct a comprehensive representation and then this representation can be incorporated by any recommendation model to enhance the performance. LIBER has been deployed on Huawei's music recommendation service and achieved substantial improvements in users' play count and play time by 3.01% and 7.69%, respectively.", "sections": [{"title": "1 INTRODUCTION", "content": "Click-Through Rate (CTR) prediction [11, 44, 45, 50, 51], which aims to predict the probability of the user clicking on the recommended items (e.g., music, advertisement), plays a core role in recommender systems. Recently, large language models (LLMs) [8, 30, 39, 40] have achieved remarkable breakthroughs and shown amazing emergence capabilities, thus giving a mushroom growth to the promising research direction of LLM-enhanced recommender systems [1, 10, 21, 22, 24, 43, 47] for performance enhancements.\nUser behavior sequence modeling is especially important for CTR prediction due to the rich user interest information contained in the behaviors [50, 51]. However, traditional methods for user behavior sequence modeling [25, 31, 32] only consider the information from their own datasets, ignoring other valuable external knowledge. To overcome this problem, researcher [24, 47] introduces LLMs to assist user behavior sequence modeling, because LLMs have accumulated a great amount of factual knowledge from the web and possess strong reasoning capabilities to better analyze users' interests. Specifically, KAR [47] employs LLMs to summarize the user sequences while Rella [24] retrievals the most relevant behaviors and directly makes the predictions by LLMs.\nHowever, there exist two significant limitations in the existing LLM-enhanced CTR prediction works: (1) LLMs fail to extract textual context information of lifelong user behavior sequences for recommendation tasks [24], which we refer to as the lifelong user behavior incomprehension problem. This problem is shown in Figure 1, where DIEN [50] is a traditional recommendation model while DIEN+Llama2 is a LLM-enhanced model. DIEN+Llama2 first utilizes Llama2 [40] (a popular open-source LLM with a context window of 4096 tokens) to exploit the textual information of user behavior sequences and then employs it as an additional feature for DIEN. As we can observe, DIEN enjoys performance gains as the length of involved user behavior sequence K grows. However, the performance of DIEN+Llama2 has an obvious drop with a larger K value. Even though the number of involved tokens (around 2000 tokens when K = 100) is far less than the context window limitation (4096 tokens), LLMs struggle in effectively capturing the highlights [24, 27] when K grows to a certain extent. Besides, the user behavior sequence required for industrial environments is generally longer, resulting in the possibility of using tokens that exceed the context window limitation of LLMs (i.e., more than 20000 tokens when K >= 1000). (2) The existing methods do not account for the inherent variability in behaviors, which results in a constant stream of new behaviors and irregularly fluctuating user interests. This leads to two serious challenges. First, since the current LLM-enhanced works tend to treat each item in user behavior sequences equally without considering its obsolescence, it is difficult for LLMs to understand the dynamic variations of user interests. Second, LLMs need to be re-executed whenever the user behavior sequence is updated, which brings huge computational costs.\nTo solve the aforementioned problems, we propose a simple yet effective framework called Lifelong User Behavior Modeling (LIBER) based on large language models. Inspired by the computer data storage technique [36], we divide the lifelong sequence of user behaviors into short-term behavior cache and long-term behavior memory in LIBER. Long-term behavior memory is conducted in partitions, with new partitions being increased gradually only if certain conditions are met. LIBER performs LLM enhancement only for each partition in long-term behavior memory while using the traditional sequence modeling method to deal with short-term behavior cache. Since the past partitions for each user are fixed, each partition only needs to perform LLMs once. Therefore, the efficiency is improved greatly. Besides, LIBER restricts the user behaviors in each partition to a suitable length to deal with the lifelong user behavior incomprehension problem. Furthermore, LIBER introduces a cascading paradigm that considers the association of different partitions to learn the evolution of user interests.\nSpecifically, LIBER consists of three modules: (1) User Behavior Streaming Partition (UBSP), (2) User Interest Learning (UIL), and (3) User Interest Fusion (UIF). Whenever a new user behavior is received, it is first allocated to the short-term behavior cache in UBSP. When the specific partition condition is reached, these behaviors in the cache are employed to construct a new partition in the long-term behavior memory. Each partition is processed by UIL to generate an intra-block user interest summary and an inter-block user interest shift in a cascading way. The user interest summary and the user interest shift are passed to a knowledge encoder and fused by an attention layer in UIF. Finally, this fusion representation, which implies long-term user interest, can be incorporated by any recommendation model to enhance the performance.\nIn conclusion, our contributions can be summarized as follows:\n\u2022 To handle the lifelong user behavior incomprehension problem, we present a novel incremental framework called LIBER to model the lifelong user behavior sequences with large language models, simultaneously improving the effectiveness and efficiency.\n\u2022 The proposed LIBER with three core stages (namely, User Behavior Streaming Partition, User Interest Learning, and User Interest Fusion) automatically explores the user interest summary and user interest shift in a cascading paradigm to assist the recommendation.\n\u2022 Offline experiments on two public datasets and one industrial dataset demonstrate the superior performance of LIBER. Besides, an online A/B test further confirms the effectiveness and applicability of LIBER."}, {"title": "2 RELATED WORK", "content": "CTR prediction task is to predict the probability of clicking the target item based on input context information [11, 12, 44, 51]. The main methods of CTR prediction can be divided into two types: feature interaction models [20, 44, 45, 52] and user behavior sequence models [3, 50, 51]. The feature interaction models aim to cross features through different operations (such as factorization machine [35], cross-net [44, 45], attention [37], and so on). DeepFM [11] and xDeepFM [20] are DNN-based factorization models to learn both low-order and high-order feature interactions. DCN [44] and DCNV2 [45] propose the cross network to enable feature interactions and use stacked layers to learn feature interactions of different orders. AutoInt [37] and FiBiNet [17] adopt the attention-based mechanism to explicitly construct feature interactions, which provide explainable attention weights. Another line is to extract information from user behavior sequences. The user behavior sequences are usually sequential ID features, so different structures (attention [18, 51], GRU [50], CNN [38], and so on) are designed to model these features. Among these methods, DIN [51] utilizes an attention mechanism to represent the relation between the target item and historical items. DIEN [50] models interest evolving through attention-based GRU. Nevertheless, all these models neglect the powerful abilities of large language models, thus leading to limited performances."}, {"title": "2.2 Language Models for Recommendation", "content": "As suggested in previous work [6, 9, 28, 46], the adaption of large language models to the field of recommender systems can achieve strong abilities. Specifically, LLMs for recommendation can be classified as follows: LLM itself serves as a recommendation model [4, 10, 42] or LLM as a component for the recommendation model [14, 16, 47]. LLMs can process complex natural language tasks, so one basic idea is to directly apply LLMs for recommendation tasks [1, 2, 4, 53]. For instance, P5 [10] utilizes the T5 [34] as a universal pre-trained model and unifies all recommendation tasks in the shared framework. M6-Rec [4] extends the foundation model M6 [23] and supports open-ended domains and tasks in the industrial recommender system. TALLRec [1] fine-tunes LLaMA-7B with the LORA [15] parameter efficient strategy and aligns it with recommendation. ReLLa [24] further adopts retrieval-enhanced instruction tuning by adopting SUBR as a data augmentation technique for training samples and achieves better performance. But all the above methods suffer from inferring latency, so another direction is to combine LLMs and recommendation models [19, 47, 48]. For example, U-BERT [33] utilizes BERT as a generator of user representations. UnisRec [14] and VQRec [13] feed BERT with descriptive texts and these output representations can be applied in cross domains. KAR [47] adopts the GPT-3.5 to extract and reason knowledge from descriptive texts of users and items.\nAlthough these models achieve higher performances by large language models, they suffer from two limitations: lifelong user behavior incomprehension problem, and the computational overhead due to the excessive executions of LLMs. Our proposed LIBER improves these methods by successfully solving such two limitations."}, {"title": "3 METHODOLOGY", "content": "To utilize LLMs to assist the user behavior modeling, we design LIBER, as shown in Figure 2. The framework is model-agnostic and consists of the following three modules:\nUser Behavior Streaming Partition Module constructs a strategy to automatically divide the lifelong sequences of user behaviors into short-term behavior cache and long-term behavior memory, where the behaviors in the short-term behavior cache are only utilized by traditional recommendation method while the behaviors in the long-term behavior memory are employed by LLMs to assist the model. Besides, long-term behavior memory is conducted in fixed partitions, with new partitions being increased gradually only if certain partition conditions are met. The user behavior length in each partition is limited to an appropriate length for LLMs. In this way, both the lifelong user behavior incomprehension problem and the efficiency problem are well mitigated.\nUser Interest Learning Module extracts recommendation-relevant knowledge from LLMs for user behavior sequences. Each partition is processed to generate an intra-block user interest summary and an inter-block user interest shift in a cascading way. In this way, we can not only obtain the external knowledge to help the model understand the behaviors better in user sequences but also leverage powerful reasoning capability from LLMs to analyze how user interests evolve.\nUser Interest Fusion Module converts textual knowledge from LLMs into compact representations and fuses them properly to help the CTR prediction task. First, the knowledge obtained from LLMs is encoded into dense representations. Then, we design an attention fuse layer to integrate the user interests from different partitions. Finally, this long-term user interest fusion representation can be incorporated into the prediction by any recommendation model to improve the performance."}, {"title": "3.2 User Behavior Streaming Partition", "content": "Since the user behavior sequences are not only extremely lengthy but also frequently dynamically varied, as reported in section 1, directly using LLMs to model the user behavior sequences suffers two serious problems: (1) Lifelong user behavior incomprehension problems; (2) The huge computational overhead due to the excessive executions of LLMs. Therefore, inspired by the computer data storage technique [36], we divide the lifelong user behavior sequences into short-term behavior cache and long-term behavior memory and only perform LLM enhancement for long-term behavior memory."}, {"title": "3.3 User Interest Learning", "content": "LLMs have accumulated a great amount of factual knowledge from the web and possess strong reasoning abilities to analyze users' interests. Therefore, we can first employ LLMs to summarize and reason for user sequences. Different from traditional recommendation models that only memorize ID-based features through collaborative signals, LLMs can infer user interests from various perspectives through external semantic information based on user sequences."}, {"title": "3.3.1 User Interest Summary", "content": "We design an instruction template prompts for user interest summary (shown in Figure 3). prompts is constructed with the user's profile description, behavior history and dataset-specific factors (i.e., genre, director, period for movie dataset), where the user profile description and behavior history provide LLMs with the necessary context and user-specific information to understand the user's preferences while dataset-specific factors can instruct LLMs to analyze user preference from proper perspectives according to the specific dataset and allow LLMs to recall the relevant knowledge more comprehensively.\nSpecifically, when a new partition Pj is generated, we utilize LLMs to yield user interest summary knowledge \\( klg \\) as:\n\\( klg_j = LLM (prompts, P_j). \\)"}, {"title": "3.3.2 User Interest Shift", "content": "Although the difficulty for LLMs to understand the user sequences is reduced when we employ the partition strategy, it still exists another serious challenge: hard to understanding the dynamic variations of user interests for LLMs, which is even exacerbated by the fact that partitioning cuts off the connection within the user sequences. To solve this problem, we propose a cascaded paradigm, trying to learn how user interests evolve.\nHere we design a user interest shift instruction template promptc. As shown in Figure 3, prompte consists of three parts - user previous interest summary, user current interest summary, and dataset-specific factors. This prompt can guide LLMs to pay more attention to users' new interests and eliminate the obsolescent interests, to better explore and understand the changes in user interests.\nSpecifically, for the new partition Pj, after the user interest summary knowledge \\( klg \\) is got, we can employ LLMs to get user interest shift knowledge klg as:\n\\( klg'_j = LLM(prompt_c, klg_j, klg_{j-1}) \\)."}, {"title": "3.4 User Interest Fusion", "content": "The knowledge generated by LLMs brings new challenges when used to assist recommendation models: (1) The knowledge generated by LLMs is usually in textual form, which cannot be directly utilized by traditional recommender systems. (2) Our partition approach yields multiple partitions of knowledge, and how to combine the knowledge from different partitions becomes a new challenge.\nTo address these challenges, we devise the user interest fusion module with three components: a knowledge encoder, a attention fuse layer, and a combination layer."}, {"title": "3.4.1 Knowledge Encoder", "content": "To utilize the semantic information generated by LLMs, we propose a knowledge encoder to encode these texts outputted by LLMs. The knowledge encoder is a smaller language model that has fewer parameters than LLMs, so it is suitable to vectorize the text quickly. We can obtain the dense representation \\( r_j \\) for partition Pj as:\n\\( r_j = Encoder(klg_j, klg'_j), \\)\nwhere \\( klg \\) and \\( klg' \\) denote the user interest summary knowledge and user interest shift knowledge generated by LLMs for j-th partition. Encoder is a low-parameterized language model, in practice, we primarily use BERT [7]. Note that the output dimension for BERT is too large (768 for each token), which does not match the traditional recommender system, here we additionally apply a pre-trained PCA [29] to do the dimensionality reduction."}, {"title": "3.4.2 Attention Fuse Layer", "content": "To fuse the representations from different partitions to assist the recommendation, we utilize the self-attention pooling [41] to fuse these representations. Suppose the user long-term behavior memory contains j partitions \\( \\{P_1, \u2026, P_j\\} \\), the fusion representations rj can be computed as:\n\\( r_j = SelfAttn(r_1, ..., r_j) = SelfAttn(R_j), \\)\nwhere Rj is the concatenation of \\( \\{r_1, ..., r_j\\} \\) and the SelfAttn calculates the weights of different partitions and obtains a unified weighted representation. The detailed process can be defined as:\n\\( SelfAttn(R) = Aggr (Softmax(\\frac{RW_Q (RW_K)^T}{\\sqrt{d}} )RW_V), \\)\nwhere \\( W^Q, W^K, W^V \\) denote the weights of query, key and d is the output dimension of SelfAttn(R)."}, {"title": "3.4.3 Combination Layer", "content": "Once we obtain the LLM-enhanced user interest representation, we can incorporate it into the traditional recommendation model. Specifically, we put it as an additional feature in the recommendation. Generally, it can be formulated as:\n\\( \\hat{y} = f(x, h, r; \\theta), \\)\nwhere x is the general user and item feature, h is the user history feature and \\( r \\) is the long-term user interest representation. Importantly, although \\( r \\) may ignore some short-term behaviors since they have not been added to the long-term behavior memory and are still present in the short-term behavior cache, these behaviors are modeled in the traditional way using h to capture the short-term user interest, resulting in a better balance between effectiveness and efficiency. Besides, LIBER only modifies the input of the recommendation model, thus it is a model-agnostic framework with various backbone recommendation model designs."}, {"title": "3.5 Discussion of Efficiency", "content": "Compared with the methods directly using LLMs to enhance the user sequence modeling [24, 47], LIBER can reduce the time cost of executing LLMs, which accounts for the majority of offline time. Suppose the sample number in the dataset is N and the time complexity of executing LLMs once is O(M), the other LLM-enhanced works for user sequence modeling need to employ LLMs once for each sample and therefore need cost O(N\u00d7M) for LLMs execution. However, for LIBER, we design the short-term behavior cache and long-term behavior memory in an incremental paradigm. Therefore, different samples from the same user can share the output of LLMs. Suppose the average length for partition is K, then the time complexity of LIBER to executing LLMs is O(N\u00d7M/B), which mitigates the computational overhead problem greatly.\nFor latency requirements in online scenarios, LIBER can pre-store the representations in a database. Consequently, we only need to retrieve the representations from the database for the inference process, which makes the inference time of LIBER acceptable."}, {"title": "4 EXPERIMENTS", "content": "To gain more insights into LIBER, we tend to address the following research questions (RQs) in this section.\n\u2022 RQ1: How does LIBER perform compared with current LLM-enhanced and traditional recommendation models?\n\u2022 RQ2: Does LIBER gain performance improvements for different backbone recommendation models and large language models?\n\u2022 RQ3: Can LIBER improve the performance of existing models in a live recommender system?\n\u2022 RQ4: What are the influences of different components in LIBER?\n\u2022 RQ5: How about the time complexity of LIBER?"}, {"title": "4.1 Experimental Settings", "content": "Experiments are conducted for the following two public datasets and one industrial dataset:\n\u2022 MovieLens-100K.\n\u2022 Amazon-Books."}, {"title": "4.2 Performance Comparison (RQ1)", "content": "In this section, we compare the performance of LIBER with the baseline models. Table 1 summarizes the performance on MovieLens-100K and Amazon-books datasets. We can observe:\n\u2022 User behaviors sequence modeling can significantly improve performance. For instance, DIN and DIEN, achieve better performances than other traditional models in terms of AUC and Log Loss, which validates the importance of modeling user behavior sequences for CTR prediction.\n\u2022 Leveraging large language models (LLMs) brings benefit to model performance. TALLRec and KAR, utilizing LLaMa2-13B, achieve the best performances among all the baseline models. However, the models using language models (LMs) with parameters less than one billion, such as UnisRec, VQRec, PTab, and P5, tend to exhibit poorer performances, even worse than the traditional CTR models. These results demonstrate the large ability gap between the LMs and LLMs.\n\u2022 The superior performance of LIBER. We can observe from Table 1 that LIBER consistently yields the best performance on all datasets. Concretely, LIBER beats the best baseline by 1.90% and 4.56% on MovieLens-100K dataset in terms of AUC and Log Loss (0.62% and 1.04% on Amazon-books dataset). This suggests that modeling lifelong user behavior sequences by large language models can greatly improve CTR prediction performance."}, {"title": "4.3 Compatibility Analysis (RQ2)", "content": "To investigate LIBER's compatibility for different backbone recommendation models, we implement our proposed LIBER upon representative CTR models for MovieLens-100K and Amazon-books datasets. The results are presented in Table 2, from which the following observations can be made:\n\u2022 As a model-agnostic framework, LIBER can achieve performance improvements for different backbone recommendation models. With the help of LIBER, the selected representative CTR models on two datasets both achieve a significant AUC improvement, indicating the compatibility of LIBER.\n\u2022 For feature interaction models and user behavior models, the relative improvements by LIBER are similar. This may be because LIBER mostly considers the semantic information whereas the user behavior models account for the collaborative information, so there is only little information overlap between LIBER and user behavior models. Therefore, the enhancements to feature interaction models and user behavior models are similar."}, {"title": "4.3.2 The Compatibility for Large Language Models", "content": "To demonstrate the compatibility of LIBER for different large language models, we implement our proposed LIBER upon three representative LLMs [8, 39, 40] on the MovieLens-100K dataset. As shown in Table 3, we can get several conclusions:\n\u2022 By all three large language models, employing LIBER can improve the performance, which validates that LIBER has a strong compatibility for different LLMs.\n\u2022 The large language models with more parameters enable LIBER to achieve better performance. It may be attributed to the larger LLMs having better comprehension and reasoning capabilities, beneficial for understanding the user interest from the lifelong behavior sequences."}, {"title": "4.4 Industrial Experiments (RQ3)", "content": "We also test our approach on an offline industrial dataset collected and sampled from a music recommendation scenario, where hundreds of millions of samples are generated. We split them into training/test sets with a ratio of 9 : 1 by timestamp. We utilize around 100 feature fields, including user features (e.g., user's behavior history), music features (e.g., artist, category), and context features. Note for this industrial dataset, we do not compare the user behavior model (DIN), because we have applied the attention mechanism on sequential features to each baseline model, which is the core of DIN."}, {"title": "4.4.2 Online Industrial A/B Test", "content": "To validate the effectiveness of our approach in the real environment, we deploy LIBER on Huawei's music recommendation service and conduct a one-week online A/B test. Specifically, 10% of users are randomly selected into the experimental group, and another 10% are in the control group. For the control group, the users are served by a highly optimized deep model. For the experimental group, the users are served by the same base model with LIBER, utilizing Huawei's own LLM Pangu [49] to generate lifelong user preference. It is worth noticing that LIBER is updated in a streaming paradigm, where the new user behavior is firstly saved to a short-term behavior cache. When the size of this cache exceeds 20, we take out these behaviors to construct a new partition in long-term behavior memory and then make use of LLM to extract user interest summary and shift. In this way, the number of LLM calls is greatly reduced and can be acceptable for our online scenario. We compare the performances in terms of user play count and play time, which are also widely used in industrial music services products [5, 47]."}, {"title": "4.5 Ablation Study (RQ4)", "content": "To investigate the effectiveness of each component in our proposed LIBER framework, we design the following model variants:\n\u2022 LIBER (Ours) is the complete version of our proposed method with three key components: User Behavior Streaming Partition, User Interest Learning, and User Interest Fusion.\n\u2022 LIBER (w/o Part.) removes the user behavior streaming partition module and takes the original long historical sequence as inputs for LLMs to enhance the user preference modeling for backbone models.\n\u2022 LIBER (w/o I.S.) removes the user interest shift part in the user interest learning module, which is designed to address the ever-evolving user dynamic interest via a cascaded merging paradigm among user behavior partitions.\n\u2022 LIBER (w/o A.F.) replaces the attention fuse layer in the user interest fusion module with a simple mean pooling layer."}, {"title": "4.6 Efficiency Study (RQ5)", "content": "In this section, we study the efficiency of LIBER in both the training phase and inference phase on the MovieLens-100K dataset, with DIEN [50] as the backbone recommendation model."}, {"title": "4.6.1 Training Efficiency", "content": "For the training phase, the major bottleneck lies in the involvement of LLMs. Hence, in Table 6, we report the AUC performance, the number of averaged LLM calls per user (#Calls/User), the number of averaged tokens per prompt (#Tokens/Prompt), and the averaged LLM processing time per user (Time/User) for the four model variants:\n\u2022 LIBER (Ours) is the complete version of our proposed model, which involves both the user interest summary prompt and the user interest shift prompt.\n\u2022 LIBER (w/o I.S.) removes the user interest shift prompt and only maintains the user interest summary prompt for each individual memory partition.\n\u2022 LLM (length=100) further removes the partition-wise user interest summary prompt and employs LLMs to infer the user preference at each time step of updating the behavior sequence. We truncate the maximum length of the user sequence to 100, which is the same as LIBER.\n\u2022 LLM (length=20) is similar to LLM (length=100), while we truncate the maximum sequence length to 20."}, {"title": "4.6.2 Inference Efficiency", "content": "For the inference phase, we report the inference time per 1000 samples of TALLRec [1], DIEN [50], KAR [47], and our proposed LIBER in Table 7. We can observe that TALLRec generally suffers from an unacceptable inference latency since it directly employs LLMs to estimate the user preference toward each target item. Similar to KAR [47], LIBER can pre-calculate and cache the knowledge representations for long-term user interests, and therefore avoid LLM calls during the inference phase. Consequently, LIBER is able to achieve superior performance over baselines like DIN and KAR, and meanwhile satisfy the strict latency constraint in real-world applications."}, {"title": "5 CONCLUSION", "content": "In this work, we propose Lifelong User Behavior Modeling (LIBER) based on large language models (LLMs). LIBER aims to solve two main challenges: (1) Lifelong user behavior incomprehension problem; and (2) Huge computational overhead of LLMs. LIBER mainly consists of three stages: User Behavior Streaming Partition (UBSP), User Interest Learning (UIL), and User Interest Fusion (UIF). UBSP condenses lengthy user behavior sequences into shorter partitions in an incremental paradigm. UIL leverages LLMs in a cascading way to infer insights from each partition. UIF integrates the textual outputs generated by LLMs to construct a unified representation and then incorporates this representation into the recommendation models. The significant improvements in offline evaluations and an online A/B test have demonstrated the superiority of our model."}]}