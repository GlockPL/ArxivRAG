{"title": "Timing Matters: Enhancing User Experience through Temporal Prediction in Smart Homes", "authors": ["Shrey Ganatra", "Spandan Anaokar", "Pushpak Bhattacharyya"], "abstract": "Have you ever considered the sheer volume of actions we perform using IoT (Internet of Things) devices within our homes, offices, and daily environments? From the mundane act of flicking a light switch to the precise adjustment of room temperatures, we are surrounded by a wealth of data, each representing a glimpse into user behaviour. While existing research has sought to decipher user behaviours from these interactions and their timestamps, a critical dimension still needs to be explored: the timing of these actions. Despite extensive efforts to understand and forecast user behaviours, the temporal dimension of these interactions has received scant attention. However, the timing of actions holds profound implications for user experience, efficiency, and overall satisfaction with intelligent systems. In our paper, we venture into the less-explored realm of human-centric AI by endeavoring to predict user actions and their timing. To achieve this, we contribute a meticulously synthesized dataset comprising 11k sequences of actions paired with their respective date and time stamps. Building upon this dataset, we propose our model, which employs advanced machine learning techniques for k-class classification over time intervals within a day. To the best of our knowledge, this is the first attempt at time prediction for smart homes. We achieve a 40% (96-class) accuracy across all datasets and an 80% (8-class) accuracy on the dataset containing exact timestamps, showcasing the efficacy of our approach in predicting the temporal dynamics of user actions within smart environments.", "sections": [{"title": "Introduction", "content": "In the era of technological advancement, the rapid growth of Internet of Things (IoT) solutions has resulted in a increase of smart devices within households, which is likely to almost double from 15.1 billion in 2020 to more than 29 billion IoT devices in 2030 (Lionel 2023). This has changed the way we interact with technology in our daily lives. From smart thermostats to voice-activated assistants, these devices have seamlessly integrated into our homes, workplaces, and public spaces, providing convenience, efficiency, and connectivity like never before.\nBeyond task automation and real-time data provision, smart devices also have the potential to impact how machines understand and respond to human behaviour. By continuously collecting data on user interactions, preferences, and habits, these devices offer insights into our routines, lifestyle choices, and even our cognitive processes. Leveraging this data can lead to the development of more intuitive and personalized technologies that anticipate the time of our needs and preferences, ultimately enhancing our overall quality of life.\nA crucial yet often overlooked aspect of user behavior prediction is the timing of actions. While existing research primarily focuses on predicting the next user action, little attention has been given to forecasting when these actions will occur. Understanding and predicting the timing of user actions is as important as predicting the actions themselves, as it significantly enhances the responsiveness and effectiveness of smart systems.\nConsider a smart home system designed to assist with daily routines. If the system can predict that a user will typically start making breakfast at 7:30 AM, it can preheat the oven or prepare the coffee machine just in time, thereby providing a seamless and proactive user experience. Without such temporal predictions, the system remains reactive, merely responding to user commands rather than anticipating needs.\nTemporal predictions are integral to the functionality of autonomous systems. Whether developing assistive robots for home use or automating smart home systems, accurate time prediction is crucial for active user assistance. Without temporal prediction, applications remain passive, lacking the capability to proactively support users. By addressing this novel task, our research takes the first steps towards creating automated assistive AI systems capable of significantly improving the user experience in smart homes."}, {"title": "Contributions", "content": "1. A Synthesized Dataset, which consists of information about 16 devices and 121 device controls. This new dataset has ~ 12000 instances each consisting of a sequence of 10 consecutive actions and the exact timestamps. (Section 5.1)\n2. A novel approach Timing-Matters for predicting the time of action on open source and our dataset. (Section 4)\n3. A extensive study of modeling classification problem with the choice of the length of the context window and the window duration. (Section 6)"}, {"title": "Related Work", "content": "The primary focus of research on user behaviour prediction in smart homes is on learning-based techniques, specifically deep learning and conventional machine learning techniques. Traditional methods like Hidden Markov Models (HMMs) (Lin, Zheng, and Xiang 2018; Sikder et al. 2019) have been used to extract the user's behaviour pattern and detect anamolies. However, HMM will fail due to the independence assumption (Eddy 1996) of HMM which makes it unable to consider context information. (Alaghbari et al. 2022; Du, Lim, and Tan 2019; Farayez, Reaz, and Arsad 2018; Tax 2018; Zou et al. 2023) exploit Long Short-Term Memory Networks (LSTM) to predict user behaviour in smart home scenarios. However, LSTM can only model long-term sequential influence (Graves 2012), but misses out on the complex heterogeneous transitions and periodic sequential patterns caused by users' routines and intents. SmartSense (Jeon et al. 2022) adopts knowledge transfer to exploit user intent and employs a two-stage encoder to mine contextual information. However, it does not classify the routines before inputting the sequence into the encoder. Second, the complex heterogeneous transitions are not modeled. Third, it does not take into account multi-level periodicity due to a lack of consideration of historical sequences. DeepUDI (Xiao et al. 2023a) employs the attention mechanism to consider the periodicity of human behaviour and intent-aware encoder to consider intents. SmartUDI (Xiao et al. 2023b) considers routines, intent, and multi-level periodicity at the same time. However, none of the techniques try to predict the time when the user will perform the action."}, {"title": "Sequential User Behaviour Prediction", "content": "Sequential user behaviour prediction methods can be categorized as follows. Traditional methods include Factorizing Personalized Markov Chains (FPMC) (Rendle, Freudenthaler, and Schmidt-Thieme 2010) factorize the users-locations matrix to generate user general preferences to complete the next location prediction. However, the location independence assumption prevents FPMC from capturing complicated sequential information (Rendle, Freudenthaler, and Schmidt-Thieme 2010). CNN-based methods like Caser (Tang and Wang 2018) employs CNN in both the time-axis and feature-axis to capture temporal dynamics in sequential recommendation. However, due to the limited receptive field of CNN, it cannot fully model long-term contextual information (Kim and Kim 2017). RNN-based methods like CARNN (Liu et al. 2016) and SIAR (Rakkappan and Rajan 2019) incorporate contextual information into the RNN for sequential recommendation. However, CARNN and SIAR can not model multi-level periodicity because they only mine contextual information in a single sequence (Liu et al. 2016; Rakkappan and Rajan 2019). Although DeepMove (Feng et al. 2018) uses attention-based RNN to model the correlation between the current sequence and historical sequences, it leads to suboptimal performance and long prediction time since it ambiguously considers all history sequences. SRGNN (Wu et al. 2019; Xu et al. 2019) applies gated GNN to capture complex transition patterns among nodes for a session-based recommendation. However, SRGNN ignores the heterogeneity of the transition patterns caused by users' intents. SASRec (Kang and McAuley 2018) utilizes unidirectional transformers to capture sequential patterns in sequences while considering the importance of correlations between behaviours. However, SASRec only captures the sequential patterns in single sequences, which prevents it from considering multi-level periodicity."}, {"title": "Problem Statement", "content": "This project aims to predict the next time of action given the history of $n - 1$ actions taken by the user. Each action comprises the device and the temporal context, like the day of the week, time of day, device, and corresponding action. The goal is to develop a model that takes these input sets and predicts the specific time of action, providing valuable insights into user behaviour. For example, Fig. 1, shows a user sequence of 5 actions and the task of the model is to predict the time of 6th action."}, {"title": "TIME OF ACTION PREDICTION", "content": "For each instance u, we are given\nInput A Sequence of history $S_u = [X_{u,1},..., X_{u,(n-1)}]$, where $X_{u,i} = (d_{u,i}^{(1)}, d_{u,i}^{(2)}, c_{u,i}^{(1)}, c_{u,i}^{(2)})$ is a quadruplet of indices of device, device control, day, and time, respectively, of the $i$th action in the sequence. The entire sequence contains n elements.\nOutput The time interval $\\hat{y}_u$ of the day that the next action will be performed. In our approach, we mainly work with dividing the day into 96 15-minute intervals."}, {"title": "Methodology", "content": "Time2Vec Embedding This is a widely used representation of time and ensures that both the sequential and cyclic patterns of time are captured (Kazemi et al. 2019). This representation can be likened to a form of Fourier Transform. Except for the linear element, the rest of the elements split the time into different frequencies. This extracts the cyclic patterns present in the temporal information. For a given scalar time $\u03c4$, the k sized time representation t2v is given by:\n$t2v(\u03c4)[i] = \\begin{cases} w_it + V_i & \\text{if } i = 0 \\\\ F(w_it + V_i) & \\text{if } 1 \\leq i \\leq k - 1 \\end{cases}$\nHere, t2v(t)[i] denotes the ith element of vector t2v(t), F is a periodic activation function with sine being the most common, and $w_i$ and $V_i$ are learnable parameters.\nRadial Basis Functional Embedding While Time2Vec incorporates the periodic properties of time, Radial Basis Functions (RBF) measure the similarity between a given scalar time and an agreed reference point. Taking inspiration from (Lewinson 2022), we propose a new type of embedding in which each element of the vector representation denotes the Gaussian-like distance between the scalar time and a trainable reference point, For a given scalar time $\u03c4$, the k-sized time representation is given by:\n$rbf(\u03c4) [i] = e^{\\frac{\\tau-\\mu_i}{\\sigma_i}} \t  0<i<k-1$\nwhere both $\u03bc_i$ and $\u03c3_i$ are trainable parameters.\nThus we have utlized two different methods of embedding scalar time. The RBF method is dependent upon the exponential distance between the time and a certain set of trainable points in space. On the other hand Time2Vec is a representation where the cyclic properties and emphasized. Together these two methods give complete information about the temporal properties of a sequence."}, {"title": "Our Model", "content": "The model takes in a N \u00d7 10 \u00d7 4 tensor as input and gives the predicted probabilities for all time intervals of a day. Currently, for each action, we have the time $c_{u,i}^{(1)}$, date $c_{u,i}^{(2)}$ device $d_{u,i}^{(1)}$ and device control $d_{u,i}^{(2)}$. Using this we first derive a new feature that contains the time difference between consecutive actions $c_{u,i}^{(3)}$ which denotes the time difference between ith and $(i \u2013 1)$th action in a sequence.\nEmbedding Next, we rely on our embedding to convert the scalar values for different quantities into vectors. We rely on the linear embedding for the device and device control $e_{u,i}^{(1)}$ and $e_{u,i}^{(2)}$. For the temporal values, we utilize both the Time2Vec and Radial Basis Function approach to get a periodic embedding and a radial embedding respectively for the time and the date the action happened at giving us $z_{u,i}^{(1,1)}$, $z_{u,i}^{(1,2)}$, $z_{u,i}^{(2,1)}$ $z_{u,i}^{(2,2)}$. The time difference, however, is converted to an embedding using Time2Vec after multiplying it by a trainable factor as we are interested in the periodic properties itself giving us $z_{u,i}^{(3)}$\nAction Encoder We make use of the famous Transformer Encoder Architecture (Vaswani et al. 2017) to encode all contextual information into a single vector. This includes the device, device control, and the two temporal embeddings of the day of action.\n$X = concat(e_{u,i}^{(1)}, e_{u,i}^{(2)}, z_{u,i}^{(1,1)}, z_{u,i}^{(1,2)})$\n$Z = Trans(X)$\nHere we further flatten the transformer encoder output,\n$Z' = flatten(Z)$\n$H = ZW$\nwhere $X \u2208 R^{4\u00d7d}$, $Z' \u2208 R^{4d}$, $H \u2208 R^{d}$ and weight $W \u2208 R^{4d\u00d7d}$\nTime Encoder For each instance, we have $z_{u,i}^{(3)}$. First of all, we append a zero vector at the start, denoted as $z_{u,1}^{(3)}$ ensuring the sequence length is the same as that of the action encoder output. Now we pass this through a Temporal Convolution Network (Lea et al. 2017) to get $u_{i}^{(3)}$ which contains the temporal information at the neighbourhood of each element of the sequence.\nThus, we combine the periodic information, the radial distance, and temporal neighbourhood information which are the vectors $z_{u,i}^{(1,1)}$ $z_{u,i}^{(1,2)}$ and $u_{i}^{(3)}$ and concatenate them along with a Batch Normalization thereby producing a sequence of vectors in which all the temporal information for a given instance has been encoded into.\nFurther on, we thus concatenate to this the Action embedding getting a sequential encoding $\u015d_{u,i}$ of the entire sequence of action, with both the contextual and temporal elements.\nSequence Encoder The goal of the Sequence Encoder is to finally calculate the predicted probabilities \u0177 from the final sequence $\u015d_{u,i}$. To do this, the encoder relies on a two-step process."}, {"title": "Dataset and Experimental Setup", "content": "We introduce our experimental setup: datasets, baselines, evaluation metrics, experimental process, and hyperparameters."}, {"title": "Dataset", "content": "SmartSense Dataset The dataset (Jeon et al. 2022) contains real-world SmartThings data collected from various regions to evaluate performance. It comprises four log datasets and three routine datasets. The log datasets document device control histories executed by users of Bixby, serving as sequential instances for a general sequential recommendation.\nThe provided datasets are collected from SmartThings, a worldwide Internet of Things (IoT) platform with 62 million users. The log datasets are gathered over a month from four different countries: Korea (KR), USA (US), Spain (SP), and France (FR). Additionally, dictionaries mapping names to ids for various categories, such as day of weeks, hours, devices, controls, and device controls, are provided. The data is segregated by country into repositories, each corresponding to Korea, USA, Spain, and France, respectively. For the log dataset, each instance is represented as a tensor of size [N \u00d7 10 \u00d7 5], where N denotes the number of instances. Each instance comprises ten consecutive actions performed by a Bixby service user, with each action represented as a vector of length 5, indicating the day of week, hour, device, control, and device control in order. The hour in a context is one of the 8-time ranges of 3 hours length: 0-3, 3-6, 6-9, 9-12, 12-15, 15-18, 18-21, and 21-24. The day, on the other hand, is an integer from 0 to 6.\nAnonymous (AN) Dataset This dataset contains synthesized raw data to mark all the daily actions a person takes in his/her smart house. It is in the form of device logs, where we have information about the action performed using a device and its timestamp.\nThis dataset is more detailed than the Smartsense Datasets as the AN dataset contains the entire time and date information for each action. The data is represented as a tensor of size [N \u00d7 10 \u00d7 5], where N denotes the number of instances. Each instance consists of a sequence of 10 consecutive actions performed, and each action consists of a vector of length 5, indicating the day of the year, time of day, device, user id and device control. In this context, the time is an integer denoting the number of seconds the action was performed after the start of the day. Here the date refers to an integer denoting the day of the year a particular action was conducted on.\nThe user id is a novel component in our dataset whereby instead of randomly generating sequences from a multitude of users as was done in the SmartSense datasets, we make sure each generated sequence is marked by which user executes the sequence. We have 39 different users each of whom follow a different pattern when it comes to utilization of smart devices."}, {"title": "Baselines", "content": "We compare our model with the following existing methods commonly used in sequential prediction:\n\u2022 MLP MultiLayer Perceptron is a simple neural network that just flattens all input and utilizes the following 3 hidden layers of size 1024, 128, and finally num_classes.\n\u2022 LSTM Long short-term memory consists of stacking together the vectors of each action and using LSTM with hidden layer size 40 and 2 layers to make predictions.\n\u2022 TCN Refers to a simple Temporal Convolution Network structure (See Section 4.2) where we utilize a two-layer TCN with a kernel size of 2 in both the encoder and decoder layers followed by a Linear layer.\n\u2022 Trans + TCN: Utilizing two encoders, where Trans is a Transformer Encoder with two heads stacked using two layers followed by a linear layer to encode information about an action into a single vector. This sequence of action vectors is then passed through a Temporal Convolution Network of 2 layers in both the encoder and decoder with a kernel size of 2 followed by a final Linear layer."}, {"title": "Evaluation Metrics", "content": "In our problem, time prediction is a classification problem where we have to make our predictions regarding what time interval the next action is likely to be taken. Hence, our final output is the list of probability values for all classes. We rely on two evaluation metrics, 96-class Accuracy and 8-class Accuracy which, if we divide a day into some k number of classes, denote the fraction where our prediction and true values belong to the same class. In our cases, we rely on k = 96 and 8 which correspond to classes of time intervals of 15 min and 3 hrs respectively."}, {"title": "Experimental Process", "content": "We first split our data into a training set, a validation set, and a test set in the ratio of 7:12. For each instance in the dataset, we have 10 continuous actions. The first nine actions constitute our input, while the time of the 10th action is our output to be predicted."}, {"title": "HyperParameters", "content": "The dimension of the vector embedding is 50. All Transformer Encoders used contain multi-head structures with 2 heads and 2 layers of encoders stacked together. The feedforward network hidden layer size is 200. The Temporal Convolution Networks consist of an encoder and a decoder, where both of them contain two stacked 1D convolution units with a kernel size of 2 and a stride of 1. The first linear layer at the end of the Sequence Encoder contains a hidden layer of size 100. For training we rely on a batch size of 64 with a learning rate of 0.0001 and 12reg 0.0001."}, {"title": "Results", "content": "Frequency of Actions in sequence We used the SmartSense Dataset where each element is a sequence of 10 actions. Similarly in constructing the AN dataset we also create sequences of 10 actions. In such cases, we need to understand the distribution of the actions in a given sequence and more importantly what devices they refer to. Taking a look at the distribution of the counts of the two most frequent devices in the sequence (4) we observe that our synthetically generated dataset's actions in a sequence very closely match with that of the SmartSense Dataset."}, {"title": "Time Difference between Consecutive Actions", "content": "For the smart home dataset, unlike traditional time series datasets, each action does not occur at specific time intervals. In such cases the consecutive time differences actually can be taken to be a time series where the kth element denotes the time between kth action and (k + 1)th. We analyze this distribution of time difference between consecutive actions. On comparing (5) we find that SmartSense dataset is more discrete while our AN dataset provides a more continous spectrum."}, {"title": "Regression vs Classification", "content": "Time is a continuous variable and hence time prediction is considered to be a regression problem. However in our case it has been seen that regression is not the optimal solution. Instead we divide the day into 96 intervals and predict which interval the time of next action would lie in. Also for the regression, the metric Precision(96) means whether the prediction is within a 15 minute range from true value. As seen in Table 4, both for the Precision(96) and Test RMSE the classification method yields much better results compared to regression. Even though for the AN dataset, Precision(08) is much better, Precision(96) which gives accuracy upto 15 minutes is more better."}, {"title": "Accuracy of Model", "content": "We measure the accuracy of the model and the baselines using four SmartSense Datasets and 1 Anonymous dataset. We show both the results in terms of 96 classes and 8 class classifications. Note that the SmartSense datasets have both 96-class and 8-class results, as the datasets themselves contain time information only up to a precision of 3-hour intervals. Table 2 shows that our model outperforms nearly all datasets."}, {"title": "Ablation Study", "content": "We take a look at the components of the model and check which ones play an important role in giving us our results (Table 3). We first replace the Radial Basis Functional Embedding with the Time2Vec Embedding to get Timing-Matters - RBF. This ensures we only take into account periodic variations and not radial distance information. Similarly, by replacing the Time Encoder with an Identity function, we end up with Timing-Matters - Time Encoder. Instead of having information about the neighbourhood at each Time Difference element, we have just the element itself.\nAs the most crucial link, by using Timing-Matters - Sequence Encoder, we replace the Transformer Encoder with an Identity function, thereby ensuring that no correlation is achieved between each action. We compare all 3 of these variants with the original and find out that Timing-Matters gives the highest results, showing that all of the parts are necessary for our model."}, {"title": "Context Window", "content": "A larger number of historical sequences allows the model to consider more historical information. However, too much historical information may introduce more uncertainty and not contribute to performance improvement. Table 5 shows that 20 historical sequences enables us to achieve the optimal performance. However due to limitations of the SmartSense dataset, we have demonstrated our model performance for 10 historical sequences."}, {"title": "Conclusions and Future Work", "content": "In this paper, we approach a completely new problem related to User Behaviour in Smart Homes where we learn to predict the time at which the user will perform the next action. This is of extreme importance because whenever you want to model a user behaviour, the temporal context plays a very important role. Our model gives the state-of-the-art results on multiple datasets. It learns the temporal patterns very well thereby increasing its accuracy upto 9.3% as compared to its competitors. We also show that how each component of the model is an essential part of its working through Ablation Study.\nIncluding external factors in the model such as weather, holidays, and user calendar events can help in making more accurate predictions.\nDeveloping real-time systems that continuously learn and adapt to user behavior can ensure that predictions remain accurate and relevant. By focusing on both the type and timing of user actions, smart home systems can become more intuitive and responsive, significantly enhancing the user experience."}]}