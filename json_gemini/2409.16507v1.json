{"title": "Center-fixing of tropical cyclones using uncertainty-aware deep learning\napplied to high-temporal-resolution geostationary satellite imagery", "authors": ["Ryan Lagerquist", "Galina Chirokova", "Robert DeMaria", "Mark DeMaria", "Imme Ebert-Uphoff"], "abstract": "ABSTRACT: Determining the location of a tropical cyclone's (TC) surface circulation center\n\u201ccenter-fixing\u201d is a critical first step in the TC-forecasting process, affecting current and\nfuture estimates of track, intensity, and structure. Despite a recent increase in the number of\nautomated center-fixing methods, only one such method (ARCHER-2) is operational, and its best\nperformance is achieved when using microwave or scatterometer data, which are not available at\nevery forecast cycle. We develop a deep-learning algorithm called GeoCenter; it relies only on\ngeostationary IR satellite imagery, which is available for all TC basins at high frequency (10-15\nmin) and low latency (< 10 min) during both day and night. GeoCenter ingests an animation\n(time series) of IR images, including 10 channels at lag times up to 3 hours. The animation is\ncentered at a \u201cfirst guess\u201d location, offset from the true TC-center location by 48 km on average and\nsometimes > 100 km; GeoCenter is tasked with correcting this offset. On an independent testing\ndataset, GeoCenter achieves a mean/median/RMS (root mean square) error of 26.9/23.3/32.0 km\nfor all systems, 25.7/22.3/30.5 km for tropical systems, and 15.7/13.6/18.6 km for category-2-5\nhurricanes. These values are similar to ARCHER-2 errors when microwave or scatterometer data\nare available, and better than ARCHER-2 errors when only IR data are available. GeoCenter also\nperforms skillful uncertainty quantification (UQ), producing a well calibrated ensemble of 200\nTC-center locations. Furthermore, all predictors used by GeoCenter are available in real time,\nwhich would make GeoCenter easy to implement operationally every 10-15 min.", "sections": [{"title": "1. Introduction", "content": "Determining the location of a tropical cyclone's (TC) surface circulation center is a critical\nfirst step in the forecasting process. Even small errors in the center fix can lead to large errors\nin downstream products, including the current intensity estimate (Olander and Velden 2019) an\nestimates of future TC track/intensity/structure, including rapid-intensification forecasts (Kieper\nand Jiang 2012; Rozoff et al. 2015). Accurate center-fixing is also important for post-season\nanalysis and research applications (Mayers and Ruf 2019) and initializing numerical weather\nprediction (NWP) models (Leslie and Holland 1995; Trabing and Bell 2020).\nThe best data sources for center-fixing are aircraft reconnaissance and radar. However, aircraft\nreconnaissance is limited to storms in the North Atlantic and eastern North Pacific approaching\nlandfall, while radar is limited to storms near land-based radar sites. Most TCs occur in the open\nocean away from land, which makes satellite imagery the main data source for center-fixing.\nOver the last half-century, many subjective and objective methods have been developed for\ncenter-fixing. However, center-fixing remains a challenge, especially for weak systems and those\nundergoing extratropical transition. Currently, the only automated (objective) center-fixing method\nused operationally is Automated Rotational Center Hurricane Eye Retrieval (ARCHER-2; Wim-\nmers and Velden 2016). ARCHER-2 has known limitations, including [1] large errors for weak\nor extratropical systems and [2] its reliance on microwave and scatterometer data, which are often\nunavailable, for best performance. For subjective center-fixing, operational forecasters rely primar-\nily on the Dvorak (1975) technique, whose inputs are visible and IR satellite data. IR data from\ngeostationary (GEO) satellites are the only satellite data available during both day and night, for"}, {"title": "a. Approaches based primarily on Dvorak technique", "content": "The subjective Dvorak (1975) technique is often used by operational TC-forecasting centres,\nincluding the National Hurricane Center (NHC), Central Pacific Hurricane Center (CPHC), and\nJoint Typhoon Warning Center (JTWC). The main purpose of the Dvorak technique is to estimate\nthe current TC intensity, which requires center-fixing as a first step. To perform center-fixing, the\nDvorak technique categorizes the dominant cloud pattern in the TC (e.g., curved band, central\ndense overcast, shear, etc.) and then fits a category-dependent cloud template to the satellite image.\nThe Dvorak technique uses a single visible/IR image, rather than a time series (animation).\nSeveral studies have taken steps to automate (i.e., make objective) the Dvorak technique, leading\nto the objective Dvorak technique (ODT; Velden et al. 1998), advanced ODT (AODT; Olander et al.\n2002), and advanced Dvorak technique (ADT; Olander and Velden 2007), which is now operational\nat NOAA NESDIS (Olander and Velden 2019). The ADT uses ARCHER-2 for center-fixing, which\nincorporates parallax correction, spiral-fitting to curved cloud bands, ellipse-fitting to the inner\neyewall (if present), thresholding of microwave imagery (if available), and fitting of ambiguity\nvectors from scatterometer retrievals (if available).\nOther efforts to automate center-fixing are described below; note that none of these methods has\nbeen operationalized."}, {"title": "b. Approaches based solely on fitting specific features", "content": "Several methods focus on either spiral-fitting of curved cloud bands or ellipse-fitting of smaller\nfeatures such as the inner eyewall or central dense overcast (CDO). In the spiral-fitting literature,\nJaiswal and Kishtawal (2010) used image segmentation to isolate TC clouds from other systems,\nfollowed by image-processing techniques to reduce noise (e.g., smoothing and filtering), and\nfinally fitting a logarithmic spiral band to the denoised IR image. Lu et al. (2019) followed a\nsimilar approach with visible and IR imagery, while Shin et al. (2022) followed a similar approach\nwith two IR channels (the longwave IR window and water vapour), averaging center locations\nestimated from the two channels into an ensemble.\nIn the ellipse-fitting literature, Chaurasia et al. (2010) fit contours to the five coldest brightness\ntemperatures ($T_b$) in the CDO region \u2013 starting with the minimum $T_b$ and incrementing by 2 K for\neach contour \u2014 then computed the center of each contour and took the mean of the five centers"}, {"title": "c. Approaches using cloud-derived or measured wind", "content": "Methods based on cloud-derived wind include Zheng et al. (2019), who used atmospheric motion\nvectors (AMV) for center-fixing. Specifically, they computed AMVs from IR imagery provided\nby the Gaofen-4 satellite1, converted the AMVs to a field called magnitude of the mean of the\ndirection vectors (MMDV), and then took the minimum of this field as the center of concentric\nmotion \u2013 i.e., the TC center. However, the computation of high-quality AMVs was made possible\nby the extremely high spatial and temporal resolution of the Gaofen-4 satellite. It is unclear how\nwell the approach of Zheng et al. (2019) would generalize to typical GEO satellites, which have\nmuch coarser resolution (10 min and 0.5-2.0 km).\nMethods based on measured wind include Lin et al. (2013), who used scatterometer mea-\nsurements, and Mayers and Ruf (2019), who used Cyclone Global Navigation Satellite System\n(CYGNSS) measurements. Scatterometer-based methods are often used for center-fixing of weak\nsystems without well defined structure, but accuracy is negatively impacted by the directional am-\nbiguity of scatterometers for weak wind (Lin et al. 2013). The MTrack system developed by Mayers\nand Ruf (2019) was shown to reduce uncertainty in the best-track TC center (dataset described in\nSection 2a), but it is unclear how well this system works for asymmetric storms. Thus, center-fixing"}, {"title": "d. Deep-learning approaches", "content": "The foregoing automated methods are considered expert systems (Reiss and Hofmann 1988;\nKumar et al. 1994), i.e., algorithms with preset rules defined by humans. While human expertise\nis crucial, expert systems are often outperformed by statistical models that can learn autonomously\nfrom large datasets, in particular deep learning (Goodfellow et al. 2016). In the last few years, deep\nlearning, especially convolutional neural networks (CNN), have become popular tools for center-\nfixing. Unlike traditional NNs and other statistical models, CNNs can directly ingest image data,\nincluding animations and multispectral imagery (e.g., multiple satellite channels). For example,\nWang et al. (2019) trained a CNN on 4-channel IR imagery, with the image center deviating from\nthe true TC center in both the x- and y-directions, and tasked the CNN with finding the true TC\ncenter. Yang et al. (2019) used a more complex architecture, based on the U-net (Ronneberger et al.\n2015), to perform semantic segmentation, producing a probability-of-TC-center-presence at every\npixel in the satellite image. Wang and Li (2023) applied a ResNet (He et al. 2016) architecture\nwith transfer learning2 to 3-channel imagery, with the image center deviating from the true TC\ncenter in only one direction. Smith and Tuomi (2021) trained three CNNs \u2013 each on animations\nfrom one IR channel, containing lag times of 0-5 hours \u2013 with the image center being the true TC\ncenter from 5 hours ago. They averaged center locations estimated from the three CNNs into an\nensemble."}, {"title": "e. Our deep-learning approach", "content": "To overcome the limitations of existing center-fixing methods, particularly those that hinder\noperational deployment, we present GeoCenter: a deep-learning method powered by an ensemble\nof CNNs. Below, we highlight the key features of GeoCenter that enhance its suitability for\noperational use.\n1. All input data \u2013 including IR satellite images and nine scalars from the Automated Tropical\nCyclone Forecasting System (Sampson and Schrader 2000) are available in real time."}, {"title": "2. Input data", "content": "This section discusses the labels and predictors used to train CNNs. Labels (or \u201cground truth\")\nare the correct answers used to evaluate CNNs."}, {"title": "a. Labels", "content": "The Automated Tropical Cyclone Forecasting System (ATCF) is an operational software package\nand database with information on multiple TC properties, including the intensity, structure, and\ncenter location. This information includes current analyses, official forecasts from several agencies,\nand forecasts from several models. The ATCF is also used as a comprehensive database for historical\nTCs. After every hurricane season, operational centres use this database to generate \u201cbest track\"\ndata, containing the best estimates for 6-hourly center locations (Landsea and Franklin 2013)."}, {"title": "b. Predictors: IR satellite data", "content": "Our first source of predictor data is IR imagery from geostationary sensors: the GOES-16\nAdvanced Baseline Imager (ABI) for the AL basin, GOES-17/18 ABI for the EP basin, and\nHimawari-8/9 Advanced Himawari Imager (AHI) for the WP basin. We use a CIRA satellite\narchive to generate TC-centered images at 30-min time steps; although geostationary data are\navailable every 10-15 min, we subsample due to computing limitations. We generate images\nthroughout the full lifetime of every TC in the AL from 2017-2021, in the EP from 2018-2022,\nand in the WP from 2016-2021. For every TC sample (definition: one TC at one time step), we\nreproject imagery from the CIRA database to a 2500-by-2500-km grid with 2-km spacing centered\non the FBT center fix, using the plate carr\u00e9e projection. The reprojected imagery contains all ten\nIR channels available on the GOES ABI and Himawari AHI; see Figure 2 and Table 2. Although\nthe ABI and AHI channels differ slightly in wavelength, we train GeoCenter with data from both"}, {"title": "c. Predictors: ATCF scalars", "content": "Our second source of predictor data is scalar TC properties from the ATCF. We use the CARQ\n(combined automated response to query) line in the A-deck file, which provides real-time estimates\nof TC properties. Specifically, for every TC sample, we extract the nine scalars listed in Table 3\nfrom the most recent synoptic time step. Thus, all GeoCenter predictors \u2013 both IR satellite images\nand ATCF scalars \u2013 include only data available in real-time operations."}, {"title": "d. Pre-processing: Splitting and normalization", "content": "Following common practice, we split our data into three subsets: training, validation, and testing.\nThe training data are used to optimize CNN parameters (weights and biases); the validation data, to\noptimize hyperparameters (settings that remain static during training, like number of neurons/layers,\nlearning rate, etc.); and the testing data, to evaluate the selected CNN model on independent data.\nWe split the data by basin-year, as shown in Table 4.\nAfter splitting, we normalize the predictor variables. Specifically, for each predictor variable\n(each of the ten IR channels and all ATCF scalars except the binary flags) and each TC sample, we\napply the following.\n1. Quantile normalization. Convert the variable x to its quantile over the distribution of x in the\ntraining data. Let the result be x', ranging from [0,1].\n2. z-score normalization. Convert x' to a z-score, using the inverse cumulative distribution\nfunction (CDF) for the standard normal distribution. Let the result be x\", which ranges from\n[-4.75,+4.75].5"}, {"title": "3. Methods", "content": "Figure 3 provides an overview of the challenges involved in machine learning (ML)-based center-\nfixing and how we overcome those challenges. For discussions involving hardware, note that each\nCNN is trained with eight Tesla P100 graphics-processing units (GPU) and 16 GB of memory per\nGPU."}, {"title": "Challenge 1: Small sample size", "content": "Description: Our training dataset has a nominal sample size of 62 740, but these samples come from 234 unique TCs\n(see Table 3). Temporal autocorrelation within each TC makes the effective sample size << 62 740.\nFurthermore, the original images are already TC-centered, leaving nothing for the NN to do.\nSolution: data augmentation (DA; Section 3b). For each original image, use random translations (\"jittering\") to\ncreate many new images.\nEach new image contains a different error (offset between image center and true TC center) to be corrected by the NN.\nThis allows the NN to learn to correct different kinds of errors.\nDA increases the nominal sample size more than the effective sample size, because all images created by translating one\noriginal image are closely related. Nonetheless, DA increases effective sample size by a little."}, {"title": "Challenge 2: High dimensionality", "content": "Description: One TC sample has dimensions of 1250 (rows) x 1250 (columns) x 10 (IR channels).\nIf we also train the NN with a video containing K lag times, dimensions grow to 1250 x 1250 x 10 x K for one data sample.\nA priori, we do not know what information in this hypercube is most relevant. How much spatial context (grid\nsize) is needed for accurate center-fixing? How much temporal context (lag times)? How much spectral info (channels)?\nFurthermore, using all available data leads to slow training and out-of-memory errors.\nSolution: We perform a hyperparameter experiment (Sections 3e, 4) to determine what information is most relevant."}, {"title": "Challenge 3: Features at many scales are important", "content": "Description: Features used for operational center-fixing range from 10s of km (inner eyewall, convective cells) to 100s of\nkm (spiral rain bands).\nThus, the NN must \"look at\" both very small and very large areas. In ML jargon: convolutional filters need receptive fields\nof many different sizes.\nNNs have small rec. fields by default; large rec. fields require a \u201cwide\u201d or \u201cdeep\u201d architecture (Nguyen et al. 2020).\n1. Wide NN: large filters (9 x 9 pixels, 11 x 11, or even greater)\n2. Deep NN: small filters (3 x 3) but many pooling layers, which serially coarsen image resolution so that for the\ndeepest convolutional layers, a 3-by-3-pixel filter covers a large physical area\nSolution: We opt for the deep architecture (Section 3a), which is less memory-intensive."}, {"title": "Challenge 4: Ensemble adds complexity", "content": "Description: We provide an ensemble of TC-center locations, not a single estimate. Evaluating an ensemble or any\nprediction that includes uncertainty quantification (UQ) - requires additional evaluation tools.\nSolution: We use the continuous ranked probability score (CRPS), spread-skill plot & associated metrics, discard test &\nassoc. metrics, rank histogram & assoc. metrics. See Section 3f."}, {"title": "a. CNN architectures", "content": "Our CNN architecture is similar to the temporal U-net introduced by Chiu et al. (2020), which\nis specially designed for predicting a future image based on an animation (time series) of images\nfrom the recent past. An example is shown in Figure 4. Our architecture is narrow and deep,\nwhich is a common choice in the ML literature (Nguyen et al. 2020). \u201cNarrow\u201d means that we\nuse small convolutional filters (here, 3 \u00d7 3 pixels); \u201cdeep\u201d means that we use many pooling layers\nto detect features at many spatial resolutions (here, doubling successively from the original 2-km\ngrid spacing to 128 km). Thus, for the shallowest convolutional layers (left column of figure), the\nphysical size of the receptive field is 6 \u00d7 6 km \u2013 while for the deepest convolutional layers (right\ncolumn), the receptive field is 384 \u00d7 384 km. This allows the CNN to detect important features at\nmany scales, ranging from the inner eyewall and convective cells (10s of km) to spiral rain bands\n(100s of km)."}, {"title": "b. CNN-training with data augmentation", "content": "During pre-processing, we center all IR images on the TC center from FBT, which is our best\nrepresentation of the truth. Thus, in image-center-relative coordinates, the true TC center is always\nat x = y = 0 km. However, in real time the FBT data do not exist yet. Instead, we have access to a\nforecast, which could be an official NHC/CPHC/JTWC forecast or an extrapolated track from the\nprevious forecast cycle. For this study, we call such a forecast or any center fix not produced by\na CNN \u2013 the \"first guess\". To mimic the operational setting during CNN-training, we randomly\ntranslate each IR image \u2013 creating an offset between the image center (first guess) and true center\n\u2014 and task the CNN with correcting this offset. In the ML literature, applying such random\nperturbations to the input data is often called data augmentation (Section 5.2.5 of Chollet 2018).\nOur specific procedure is as follows:\n1. Draw the translation vector from a random distribution. Specifically, draw the length from\n$\\max{0 \text{ km}, N(48 \text{ km}, 24 \text{ km})}$ \u2014 which is a zero-truncated Gaussian distribution with mean\nof 48 km and standard deviation of 24 km \u2014 and the direction from $U(0,2\\pi)$, which is a\nuniform distribution over the unit circle.\n2. The distribution of translation vectors is shown in Figure 5a. If the translation were not\ncorrected by a CNN \u2013 i.e., if the translated image centers were taken as estimated TC centers\n\u2014 this would be the error distribution.\n3. Convert the translation vector to Cartesian coordinates (\u0394x and \u0394y in km), then to row-column\ncoordinates (\u0394r and \u0394c in number of pixels). Since the IR imagery has 2-km grid spacing,\nwe use the equations \u0394r = g($\\frac{\\Delta x}{2 km}$) and \u0394c = g($\\frac{\\Delta y}{2 km}$), where g() rounds to the nearest integer.\n4. Translate the IR image by the given \u0394r and \u0394c, avoiding edge effects. For example, if the\ndomain size used by the CNN is 300 \u00d7 300, the pre-translation image must be larger than 300\n\u00d7300. Otherwise, the post-translation image will have an obvious border, which the CNN\ncan easily use to \u201ccheat\u201d. For example, if the border is 30 rows thick on the south edge of the\nimage and 40 columns thick on the east edge (Figures 5b-c), the CNN can trivially determine\nthat \u0394r = +30 and \u0394c = -40.\n5. The CNN is tasked with estimating \u0394r and \u0394c, providing a 50-member ensemble for each\ncoordinate (Figure 4)."}, {"title": "c. Uncertainty quantification", "content": "Uncertainty can be decomposed into two parts: epistemic uncertainty, arising from deficiencies\nof the ML model itself, and aleatory uncertainty, arising from deficiencies of the training data.\nMost methods for machine-learned uncertainty quantification (ML-UQ) resolve only one type of\nuncertainty, so we combine two methods. To resolve aleatory uncertainty, we use the continuous\nranked probability score (CRPS) method, where the CNN is trained to produce a 50-member"}, {"title": "4. Results of hyperparameter experiment", "content": "This section evaluates the CNNs on all systems (both tropical and non-tropical) in the validation\ndata, with the aim of selecting the best CNN. The validation data contain 1160 original TC samples;\nwe randomly translate each sample 8 times (following the procedure in Section 3b), yielding a final\nsample size of 9280. Results for two evaluation metrics (mean Euclidean distance and SSRAT) are\nshown in Figure 6; other evaluation metrics are shown in Supplemental Section 6. We summarize\nthe results below:\n1. For most evaluation metrics (all except REL, SSREL, and SSRAT), the worst results occur\nwith the largest domain size (1200 \u00d7 1200 km). Domain size is the main control on the\nnumber of CNN weights, and CNNs with more weights are harder to fit.\n2. For most metrics (all except median Euclidean distance, CRPS, and SSRAT), the best value\noccurs with an intermediate domain size, not the smallest. This suggests that the smallest\ndomain (600 \u00d7 600 km) is not quite large enough to achieve the best accuracy. In other words,\na wider spatial context is important for accurate center-fixing.\n3. For half of all metrics (the three Euclidean metrics, bias, and CRPS), the worst animation\nlength is one. This suggests that the temporal evolution of the TC's satellite presentation\nnot just a single image \u2013 is important.\n4. For some metrics (bias, REL, SSREL, and RHD), the longest animation length (7 lag times)\nleads to a clear minimum in performance. This suggests that, like the largest domain size, the\nlongest animation length might lead to overly complex CNNs that are hard to fit.\n5. For more than half of all metrics (the three Euclidean metrics, bias, REL, and CRPS), results\nare overall better with a main pooling factor of 2 instead of 3. This suggests that retaining the\nfinest spatial resolution possible at every level in the CNN is beneficial.\nBased on all ten metrics, we select the CNN with a 1000-by-1000-km domain size, animation\nlength of 7 lag times (back to 180 min ago), and main pooling factor of 2 \u2013 marked by circles in\nFigure 6. The exact scores achieved by this model are listed in Table 8."}, {"title": "5. Evaluation of final ensemble", "content": "Here we evaluate the final ensemble of center-fixing models, henceforth \u201cGeoCenter\". The\nensemble consists of four CNNs \u2013 all using IR imagery with a domain size of 1000 \u00d7 1000 km,\nan IR animation with 7 lag times, and a main pooling factor of 2 \u2013 but each using a different\nset of IR channels (Table 5). The first subsection evaluates GeoCenter objectively, based on all\ntropical systems in the testing dataset (for which the \u201ctropical flag\" defined in Table 3 is 1). For\nanalogous results on the complete testing set and on non-tropical systems in the testing set, see\nSupplemental Sections 7a-b. The second subsection presents case studies for a deeper but more\nsubjective understanding of GeoCenter."}, {"title": "a. Objective evaluation", "content": "Tropical systems in the testing data comprise 906 original samples; we randomly translate each\nsample 8 times, yielding a final sample size of 7248.\nFigure 7 evaluates the GeoCenter ensemble mean. The attributes diagram for the x-coordinate\n(Figure 7a) shows that, while intermediate predictions are nearly unbiased, extreme predictions are\nnot extreme enough. Specifically, predictions \u2264 -60 km are too high (not negative enough). In other\nwords, when GeoCenter makes an extreme correction to the west, it should correct even more to the\nwest. Similarly, the attributes diagram for the y-coordinate (Figure 7b) shows that predictions \u2265 +60\nkm are not positive enough. In other words, when GeoCenter makes an extreme correction to the\nnorth, it should correct even more to the north. The attributes diagram for total correction distance"}, {"title": "b. Case studies", "content": "Here we investigate four case studies from the testing data. To save space, the figures show\nIR predictors at all 10 channels but only one lag time (the most recent; 0 min). The first case\nstudy (Figure 11) is a low-intensity TC (Dujuan; WP012021) at low latitude, identified in Figure\n9 as a trouble area for GeoCenter. Dujuan contains several areas of deep convection with no\nobvious circulation center; also, the true TC center (green star in Figure 11) is in a region of\nsmall brightness-temperature gradients. The GeoCenter ensemble (green contours) places the TC\ncenter southeast of the image center (red square), but it is actually well northeast of the image\ncenter. The Euclidean distance error is 72.9 km, and the true TC center lies on the second-to-\noutermost probability contour, indicating that GeoCenter assigns a very small probability to the"}, {"title": "6. Summary and future work", "content": "Center-fixing is a critical first step in the TC-forecasting process, with current and future estimates\nof TC properties being highly sensitive to this initial location estimate. However, operational centres\noften rely on the subjective Dvorak technique, with ARCHER-2 being the only objective method\nused in operations. ARCHER-2's best-case performance is achieved when using microwave or\nscatterometer data, which are available twice a day or less in the tropics. ARCHER-2 performs\nmuch worse when using routinely available IR data \u2013 collected by geostationary satellites during\nboth day and night, at 10\u201315-min resolution and < 10-min latency, across all TC basins. Preliminary\nresults show that GeoCenter (the algorithm developed herein), which uses only routinely available\nIR data, performs similarly to the best-case ARCHER-2 (with microwave/scatterometer data) and\ngreatly outperforms the worst-case ARCHER-2 (with IR data).\nGeoCenter is a deep-learning algorithm, specifically an ensemble of CNNs, trained with multi-\nspectral animations of IR data. Our hyperparameter experiment shows that CNNs perform better\nwhen trained with an animation (time series) than a single image. The predictors include ten IR\nchannels at seven lag times ..., 0, 30, ..., 180 minutes before the valid time to centered at a\nfirst-guess location which is randomly offset from the true TC center at to. GeoCenter's task is to\ncorrect this random offset, which averages 48 km and can exceed 100 km, and find the true center.\nGeoCenter is trained on data from three ocean basins \u2013 the AL, EP, and WP \u2013 representing the vast\nmajority of northern-hemisphere TCs. GeoCenter is also trained with data across the full lifetime\nof every TC, which includes post-/sub-/extra-tropical systems. These properties \u2013 combined with\nGeoCenter being trained on routinely available IR data \u2013 make GeoCenter a potentially operational\ntool with wide applicability. Furthermore, GeoCenter performs skillful uncertainty quantification,\nproviding a well calibrated ensemble of 200 possible TC centers.\nThe objective evaluation of GeoCenter \u2014 on an independent testing set \u2014 focuses mainly on\ntropical systems, which comprise the majority (84.4%) of the dataset. GeoCenter achieves a small\nbias \u2014 0.6 km to the west and 0.5 km to the south \u2013 with mean/median/RMS Euclidean errors of\n25.7/22.3/30.5 km. Errors vary strongly with TC intensity, reaching a maximum of 29.0/25.9/33.7"}]}