{"title": "DIFFUSION ATTRIBUTION SCORE:\nEVALUATING TRAINING DATA INFLUENCE IN DIFFUSION MODEL", "authors": ["Jinxu Lin", "Linwei Tao", "Minjing Dong", "Chang Xu"], "abstract": "As diffusion models become increasingly popular, the misuse of copyrighted and\nprivate images has emerged as a major concern. One promising solution to miti-\ngate this issue is identifying the contribution of specific training samples in gener-\native models, a process known as data attribution. Existing data attribution meth-\nods for diffusion models typically quantify the contribution of a training sample\nby evaluating the change in diffusion loss when the sample is included or excluded\nfrom the training process. However, we argue that the direct usage of diffusion loss\ncannot represent such a contribution accurately due to the calculation of diffusion\nloss. Specifically, these approaches measure the divergence between predicted\nand ground truth distributions, which leads to an indirect comparison between the\npredicted distributions and cannot represent the variances between model behav-\niors. To address these issues, we aim to measure the direct comparison between\npredicted distributions with an attribution score to analyse the training sample im-\nportance, which is achieved by Diffusion Attribution Score (DAS). Underpinned\nby rigorous theoretical analysis, we elucidate the effectiveness of DAS. Addition-\nally, we explore strategies to accelerate DAS calculations, facilitating its appli-\ncation to large-scale diffusion models. Our extensive experiments across various\ndatasets and diffusion models demonstrate that DAS significantly surpasses pre-\nvious benchmarks in terms of the linear data-modelling score, establishing new\nstate-of-the-art performance.", "sections": [{"title": "INTRODUCTION", "content": "Diffusion models, highlighted in key studies (Ho et al., 2020; Song et al., 2021b), are advancing\nsignificantly in generative machine learning with broad applications from image generation to artis-\ntic creation (Saharia et al., 2022; Hertz et al., 2023; Li et al., 2022; Ho et al., 2022). As these\nmodels, exemplified by projects like Stable Diffusion (Rombach et al., 2022), become increasingly\ncapable of producing high-quality, varied outputs, the misuse of copyrighted and private images has\nbecome a significant concern. A key strategy to address this issue is identifying the contributions of\ntraining samples in generative models by evaluating their influence on the generated images, a task\nknown as data attribution. Data attribution in machine learning is essential for tracing model out-\nputs back to influential training examples and understanding how specific data points affect model\nbehavior. In practical applications, data attribution spans various domains, including explaining\npredictions (Koh & Liang, 2017; Yeh et al., 2018; Ilyas et al., 2022), curating datasets (Khanna\net al., 2019; Jia et al., 2021; Liu et al., 2021), and dissecting the mechanisms of generative models\nlike GANs and VAEs (Kong & Chaudhuri, 2021; Terashita et al., 2021), serving to enhance model\ntransparency and explore the effect of training data on model behaviors."}, {"title": "", "content": "Data attribution methods generally fall into two categories. The first, based on sampling (Shap-\nley et al., 1953; Ghorbani & Zou, 2019; Ilyas et al., 2022), involves retraining models to assess how\noutputs change with the deletion of specific data. While effective, this method requires training thou-\nsands of models\u2014a formidable challenge given today's large-scale models. The second approach\nuses approximations to assess the change in output for efficiency (Koh & Liang, 2017; Feldman &\nZhang, 2020; Pruthi et al., 2020), which may compromise precision. Recent advancements have\nled to innovative estimators like TRAK (Park et al., 2023), which linearizes model behavior us-\ning a kernel matrix analogous to the Fisher Information Matrix. Additionally, Zheng et al. (2024)\nproposed D-TRAK, which adapts TRAK to diffusion models by setting the output function as the\ndiffusion loss. However, this setting conducts an indirect comparison between the predicted distri-\nbutions since the diffusion loss is equivalent to the divergence between predicted and ground truth\ndistributions (Ho et al., 2020). They also reported counterintuitive findings that the diffusion loss\ncan be replaced with other output functions without modifying the form of the attribution score, and\nthe results of these empirical designs surpass diffusion loss with theoretical designs, highlighting\nthe need for a deeper understanding of diffusion models in data attribution."}, {"title": "", "content": "In this paper, we first present a theoretical analysis to address the challenges associated with directly\napplying TRAK to diffusion models, which also explain the counter-intuitive observations noted in\nD-TRAK. Further, we propose a novel attribution method termed Diffusion Attribution Score (DAS),\nspecifically designed for diffusion models to quantitatively assess the impact of training samples on\nmodel outputs by measuring the divergence between predicted distributions when the sample is\nincluded or excluded from the training set, which includes a self-contained derivation. Additionally,\nwe explore several techniques to expedite the computation of DAS, such as compressing models\nor datasets, enabling its application to large-scale diffusion models and significantly enhancing the\npracticability of our approach. The primary contributions of our work are summarized as follows:"}, {"title": "", "content": "1. We offer a comprehensive analysis of the limitations when directly applying TRAK to\ndiffusion tasks. This theoretical examination sheds light on the empirical success of D-\nTRAK and fosters the development of more effective attribution methods.\n2. We introduce DAS, a theoretically solid metric designed to directly quantify discrepancies\nin model outputs, supported by detailed derivations. We also discuss various techniques,\nsuch as compressing models or datasets, to accelerate the computation of DAS, facilitating\nits efficient implementation.\n3. DAS demonstrates state-of-the-art performance across multiple benchmarks, notably ex-\nelling in linear datamodeling scores."}, {"title": "2 PRELIMINARIES", "content": ""}, {"title": "2.1 DIFFUSION MODELS", "content": "Our study concentrates on discrete-time diffusion models, specifically Denoising Diffusion Proba-\nbilistic Models (DDPMs) (Ho et al., 2020) and Latent Diffusion Models (LDMs) which are foun-\ndational to Stable Diffusion (Rombach et al., 2022). This paper grounds all theoretical derivations\nrelated to diffusion models within the framework of unconditional generation using DDPMs. Below,\nwe detail the notation employed in DDPMs that underpins all further theoretical discussions.\nConsider a training set S = {z(1), ..., z(n)} where each training sample z(i) := (x(i), y(i)) ~ Z\nis an input-label pair\u00b9. Given an input data distribution q(x), DDPMs aim to model a distri-\nbution po(x) to approximate q(x). The learning process is divided into forward and reverse\nprocess, conducted over a series of timesteps in the latent variable space, with xo denoting\nthe initial image and at the latent variables at timestep t \u2208 [1,T]. In the forward process,\nDDPMs sample an observation 20 from S and progressively add noise on it across T timesteps:\nq(xt|xt\u22121) := N(xt; \u221a\u221a1 \u2013 \u1e9etxt\u22121, \u1e9et I), where \u1e9e1, ..., \u1e9e\u0442 constitute a variance schedule. As in-\ndicated in DDPMs, the latent variable \u00e6t can be express as a linear combination of x0:\nxt = \u221aatxo + \u221a1 \u2013 \u0101te, \t(1)"}, {"title": "", "content": "where at := 1 \u2212 \u03b2t,\u0101t := \u03a0=1&s and \u0454 ~ N(0, I). In the reward process, DDPMs model a\ndistribution po(xt-1|xt) by minimizing the KL-divergence from q(xt-1|Xt, x0) at each timestep t:\nDKL [Po(Xt-1|Xt)||9(Xt-1|Xt, xo)] = EE~N(0,1) [\\frac{\\beta}{2\\alpha+(1-\\bar{\\alpha}_t)} ||\\epsilon - \\epsilon_\\theta (x_t, t)||^2], \t(2)\nwhere e is a function implemented by trainable models @ which can be seen as a noise predictor. A\nsimplified version of objective function for a data point x used to train DDPMs is:\nLSimple(x, 0) = Ee,t[||Eo(xt, t) \u2013 \u20ac||2].\t(3)"}, {"title": "2.2 DATA ATTRIBUTION", "content": "Given a DDPM trained on dataset S, our objective is to trace the influence of the training data on\nan output generated for a particular sample z. This task is commonly referred to as data attribution.\nA common approach to data attribution involves addressing a counterfactual question: if a training\nsample z(2) is removed from S and a model 0\u00bf is retrained on the remaining subset S\\i, the influence\nof z(2) on the sample z can be assessed by the change in the model output, computed as f(z, 0)\nf(z, 0). The function f(z, 0), which represents the model output, has a variety of choices, such\nas the direct output of the model or its loss function."}, {"title": "", "content": "To circumvent the high computational costs associated with retraining models, some data attribution\nmethods compute a scoring function \u315c(z, S) : Z \u00d7 Zn \u2192 Rn, which assigns scores reflecting the\nimportance of each training sample in S for the sample z under consideration. For clarity, \u315c(z, S) (i)\ndenotes the attribution score assigned to the influence of the individual training sample z(i) on z.\nTRAK (Park et al., 2023) stands out as a representative data attribution method designed for large-\nscale models focused on discriminative tasks. TRAK defines the model output function as:\nfTRAK (z, 0) = log[p(x, 0)/(1 \u2013 p(x, 0))], \t(4)\nwhere p(x, 0) represents the probability of the corresponding class y for the sample z. TRAK\nintroduces an attribution function TTRAK (z, S)(i) designed to approximate the change in fTRAK (z, 0)\nfollowing the deletion of a data point. This is expressed as:\nTTRAK(Z, S)(i) := $(z) (\u03a6\u03a4\u03a6)\u2212\u00b9\u00a2(z(i))r(i) \u2248 fTRAK (z, 0) \u2013 fTRAK(z, 0\\i), \t(5)\nwhere r(i) = 1 \u2212 p(x(i), (\u03b8) denotes the residual for sample z(i). Here, $(z) := P\u00af\u2207efTRAK(z, 0)\nand \u03a6 := [(z(1)), ..., $(z(n))] represents the matrix of stacked gradients from S. P ~ N(0, 1)d\u00d7k\nis a random projection matrix (Johnson & Lindenstrauss, 1984) employed to reduce the dimension\nof the gradient Veftrak(z; 0) \u2208 Rd to k. This function computes a score indicating the influence\nof a training sample zi on the sample of interest z in a discriminative model setting."}, {"title": "", "content": "To adapt TRAK in diffusion models, D-TRAK (Zheng et al., 2024) modifies the output function to\nalign with the objective function described in Eq. 3: fD-TRAK(z, 0) = LSimple (x, 0), and simplifies the\nresidual term to an identity matrix I. The attribution function in D-TRAK is defined as follows:\nTD-TRAK (Z, S)(i) = $(z)(\u03a6\u03a4\u03a6)\u00af\u00b9\u00a2(z(i)) I \u2248 fD-TRAK (z, 0) \u2013 fD-TRAK(z, 0\\i), \t(6)\nwhere (z) := P\u00af\u2207efd-Trak(z,0) mirrors the gradient term used in TRAK. Interestingly, D-\nTRAK has observed that substituting the function fD-TRAK with other functions can yield supe-\nrior attribution performance. Examples of these include Lsquare (z, 0) = Et,e [||Eo(xt,t)||2] and\nLAverage(z, 0) = Et,e [Avg(\u20ac0(xt, t))], both of which have enhanced attribution capabilities."}, {"title": "3 METHODOLOGY", "content": "In this section, we propose a novel data attribution method tailored for diffusion models to assess the\nimpact of training samples on the generative process. Revisiting our objective, we aim to evaluate\nhow training samples influence the generation within a diffusion model. Previous work D-TRAK,\nhas applied TRAK designed for discriminative tasks to generative tasks, utilizing the Simple Loss\nas the output function. In Section 3.1, we critically analyze the shortcomings of employing a loss\nfunction as the output function in diffusion models and propose a more suitable output function."}, {"title": "", "content": "Additionally, the attribution score is contingent upon the task setting and the selected output func-\ntion. Alterations in the settings, such as the loss function and output function, significantly affect\nthe derivation of the attribution score. Consequently, we introduce a new attribution metric called\nDiffusion Attribution Score (DAS), specifically developed for generative tasks in diffusion models,\ndetailed in Section 3.2. In section 3.3, we explore methodologies for applying DAS to large-scale\ndiffusion model and discuss strategies to expedite the computation process."}, {"title": "3.1 RETHINKING THE DESIGN OF MODEL OUTPUT FUNCTION", "content": "Reviewing the goal of data attribution within diffusion models, suppose we have a set of training\ndata S and wish to measure the influence of a specific training sample z(i) on a generated sample\nzgen. This task can be approached by addressing the counterfactual question: How would the model\noutput change for zgen if we removed z(2) from S and retrained the model on the subset S\\\u00bf? D-\nTRAK proposes using TD-TRAK to approximate this difference based on the Simple Loss:\nTD-TRAK (zgen, S) (i) \u2248 fD-TRAK(zgen, 0) \u2013 fD-TRAK (zgen, i)\n= Eet [||\u20ac (x, t) \u2013 \u20ac||\u00b2] \u2013 Ee,t [||\u20ac0\u2081\u2081 (x, t) \u2013 \u20ac||2], \t(7)\nwhere 60 denotes the noise predictor trained on S\\\u00bf. However, from a distribution perspective, this\napproach involves an indirect comparison of KL-divergences between the model distributions and\nthe data distribution to indicate the distances between model distributions:\nTD-TRAK(zgen, S)(i) \u2248 DKL[Pe(xgen)||q(xgen)] \u2013 DKL[Po\\; (xgen)||q(xgen)]. \t(8)"}, {"title": "", "content": "This indirect comparison may introduce errors when evaluating the differences between po (xgen) and\nPe (xgen). For instance, both distributions might approach the data distribution q(\u00e6gen) from dif-\nferent directions, yet exhibit similar distances. To enable a more direct comparison, we propose the\nDiffusion Attribution Score (DAS) to assess the KL-divergence between the predicted distributions:\nTDAS (zgen, S) (i) \u2248 DKL[Po(xgen)||Pe\\; (xgen)]\n\u2248 E\u20ac,t[||\u20ac (x, t) - \u20ac0 (x,t)||2]. \t(9)\nThe output function in DAS is defined as fpas (z, 0) = (x, t), which is able to directly reflect\nthe differences between the noise predictors of the original and the retrained models. Eq. 9 also\nvalidates the effectiveness of employing Lsquare as the output function, which is formulated as:\nTSquare (zgen, S) (i) \u2248 Ee,t[||\u22080(x, t)||2] \u2013 Ee,t[||\u20ac0\u2081\u2081 (x, t)||2]. \t(10)\nThis approach also mitigates the influence of indirect comparisons. However, the subtraction used\nhere does not constitute any recognized type of distance metric. Furthermore, the matrices ee and\n\u20ac0, which retain the same high dimensionality as the input images \u00e6gen, should not be represented\nmerely by scalar values, whether by average or L2 norm, as this leads to a loss of dimensional\ninformation. For instance, these matrices might exhibit identical differences across various dimen-\nsions, an aspect that scalar representations fail to capture. This dimensional consistency is crucial\nfor understanding the full impact of training data alterations on model outputs."}, {"title": "3.2 DIFFUSION ATTRIBUTION SCORE", "content": "In diffusion models, the generative process involves a series of generative steps, and the model\nproduces outputs at T different timesteps. In this section, we explore methods to approximate Eq. 9\nat a specific timestep t without the necessity for retraining the model, which aims to evaluate the\ninfluence of training data on the model's generation."}, {"title": "", "content": "Linearing Output Function. Computing the output of the retrained model ee(x, t) is compu-\ntationally expensive. To enhance computational efficiency, we propose linearizing the model output\nfunction using its Taylor expansion centered around the final model parameters 0*, simplifying the\ncalculation as follows:\nfDAS(Zt, 0) \u2248 \u20ac0* (Xt, t) + \u22070\u00a30*(xt, t) (0 \u2013 0*). \t(11)\nBy substituting Eq. 11 into Eq. 9, we derive:\nTDAS (zgen, S) (2) ~ E\u2208 [|| \u22070\u20ac*(x, t) (,t)(0* \u2013 0*)||2]. \t(12)"}, {"title": "", "content": "The subscript t indicates the attribution score for the model output at timestep t. Consequently,\nthe influence of removing a sample from subset S\\\u00bf on the model output can now be quantitatively\nevaluated through the changes in model parameters, which can be measured by the leave-one-out\nmethod, thereby significantly reducing the computational overhead."}, {"title": "", "content": "Estimating the model parameter. Consider using the leave-one-out method, the variation of the\ndiffusion model parameters can be assessed by Newton's Method (Pregibon, 1981). By removing\na training sample z(2), the counterfactual parameters * can be approximated by taking a single\nNewton step from the optimal parameters 0*:\n\u0398* \u2212 \u0398*\t(i)\t= \u2212 [\u2207\u03b8\u03b5\u03c1* (St, t)\t\u2207\u03b8\u03b5\u03c1* (St, t)]\t\u22121\u2207\u03b8\u03b5\u03c1* (St, t) \tRt, \t(13)\nwhere 60* (St, t) := [\u20ac* (x1), t), ..., \u20ac* (x(n), t)] represents the stacked output matrix for the set S\nat timestep t, and Rt := diag[\u20ac(x2), t) \u2013 e] is a diagonal matrix describing the residuals among S.\nA detailed proof of Eq. 13 is provided in Appendix B."}, {"title": "", "content": "Let gt(x(i)) = \u221a9\u20ac (x2), t) and G+(S) = Vo\u20ac9* (St,t). The inverse term in Eq. 13 can be\nreformulated as:\nG+(Si) G+(Si) = G+(S)TG+(S) \u2013 gt(x(i))Tgt(x(i)). \t(14)\nApplying the Sherman-Morrison formula to Eq. 14 simplifies Eq. 13 as follows:\n0*-0*\\t(i) =\\t\\frac{[G+(S)TG+(S)]^{-1}g_t(x^{(i)})r^{(i)}_t}{1-g_t(x^{(i)})^T[(G+(S)TG+(S)]^{-1}g_t(x^{(i)})}, \t(15)\nwhere r \u2022(2) is the i-th element of Rt. A detailed proof of Eq 15 in provided in Appendix C.\nDiffusion Attribution Score. By substituting Eq.15 into Eq.12, we derive the formula for comput-\ning the DAS at timestep t:\nTDAS (zgen, \", S)(i) = Ee [||\\frac{g_t(x_{gen})^T [G_t(S)^TG_t(S)]^{-1}g_t(x^{(i)})r^{(i)}_t}{1-g_t(x^{(i)})^T[(G_t(S)^TG_t(S)]^{-1}g_t(x^{(i)})}\t||^2]. \t(16)\nThis equation estimates the impact of training samples at a specific timestep t. The overall influence\nof a training sample z(i) on the target sample zgen throughout the entire generation process can be\ncomputed as an expectation over timestep t. However, directly calculating these expectations is\nextremely costly. In the next section, we discuss methods to expedite this computation.\""}, {"title": "3.3 EXTEND DAS TO LARGE-SCALE DIFFUSION MODEL", "content": "Reducing Calculation of Expectations Computing t times the equation specified in Eq. 16 is highly\nresource-intensive due to the necessity of calculating inverse terms. To simplify this process, we\nconsider using the average gradient g(x) and average residual r, which allows for a singular com-\nputation of Eq. 16 to evaluate the overall influence. However, during averaging, these terms may\nexhibit varying magnitudes across different timesteps, potentially leading to the loss of significant\ninformation. To address this, we normalize the gradients and residuals over the entire generative\nprocess before averaging:\ng(x(i)) = \\frac{g_t(x^{(i)})}{\\sqrt{\\sum_t g_t(x^{(i)})^2}}\t, r^{(i)}_t = \\frac{r^{(i)}_t}{\\sqrt{\\sum_t {r^{(i)}_t}^2}}\t(17)\nThus, to attribute the influence of a training sample z(i) on a generated sample zgen throughout the\nentire generation process, we redefine Eq. 16 as follows:\nTDAS (ze, S)(i) = ||\\frac{g(x_{gen})^T [G(S)^TG(S)]^{-1}g(x^{(i)})r^{(i)}}{1-g(x^{(i)})^T [G(S)^TG(S)]^{-1}g(x^{(i)})}\t||^2. \t(18)"}, {"title": "", "content": "Reducing the amount of timesteps The computation of Eq. 17 requires performing back propa-\ngation T times to calculate the gradients, which is highly resource-intensive. The need to calculate"}, {"title": "", "content": "gradients at multiple timesteps can be effectively reduced by sampling fewer timesteps. This method\nleverages statistical sampling techniques to estimate gradient behaviors across the generative process\nwhile significantly reducing computational overhead."}, {"title": "", "content": "Reduce Dimension of Gradients The dimension of gt (x(i)) is as large as that of the diffusion model\nitself, which poses a challenge in calculating the inverse term due to its substantial size. There are\nstrategies to simplify this calculation by reducing the dimensionality of the gradient.\nOne effective method is to apply the Johnson and Lindenstrauss Projection (Johnson & Linden-\nstrauss, 1984). This technique involves multiplying the gradient vector gt(x(i)) \u2208 Rp by a random\nmatrix P ~ N(0,1) \u2208 Rp\u00d7k(k \u00ab\u226a p), which can preserve inner product with high probability while\nsignificantly reducing the dimension of the gradient. This projection method has been validated in\nprevious studies (Malladi et al., 2023; Jacot et al., 2018; Park et al., 2023), demonstrating its efficacy\nin maintaining the integrity of the gradients while easing computational demands. With the above\nspeed up techniques, we summarize our algorithms in Algorithm 1."}, {"title": "", "content": "In addition to projection methods, other techniques can be employed to reduce the dimension of\ngradients in diffusion models. For instance, as noted by Ma et al. (2024), the up-block of the U-\nNet architecture in diffusion models plays a pivotal role in the generation process. Therefore, we\ncan focus solely on the gradients of the up-block for dimension reduction purposes, optimizing\ncomputational efficiency."}, {"title": "", "content": "Furthermore, when applying large-scale diffusion models to downstream tasks, various strategies\nhave been proposed to fine-tune these models efficiently. One such approach is LoRA (Hu et al.,\n2022), which involves freezing the pre-trained model weights while utilizing trainable rank de-\ncomposition matrices. This significantly reduces the number of trainable parameters required for\nfine-tuning. Consequently, when attributing the influence of training samples in a fine-tuned dataset,\nwe can selectively use the gradients of these trainable parameters to compute the DAS."}, {"title": "", "content": "Reducing Candidate Training Sample The necessity to traverse the entire training set when com-\nputing the DAS poses a significant challenge. To alleviate this, a practical approach involves con-\nducting a preliminary screening to identify the most influential training samples. Techniques such\nas CLIP (Radford et al., 2021) or cosine similarity can be effectively employed to locate samples\nthat are similar to the target. By using these methods, we can form a preliminary candidate set and\nconcentrate DAS computations on this subset, rather than on the entire training dataset."}, {"title": "4 EXPERIMENTS", "content": "In this section, we conducted comparative analyses of our method, Diffusion Attribution Score\n(DAS), against existing data attribution methods under various experimental settings. The primary\nmetric used for assessing attribution performance is the Linear Datamodeling Score (LDS) (Ilyas\net al., 2022). Additionally, we evaluated the effectiveness of the speed-up techniques discussed in\nSection 3.3. Our findings indicate that DAS significantly outperforms other methods in terms of\nattribution performance, confirming its capability to accurately identify influential training samples."}, {"title": "4.1 DATASETS AND MODELS", "content": "This subsection provides an overview of datasets and diffusion models utilized in our experiments.\nA detailed description of each dataset and model configuration is available in the Appendix F.1.\nCIFAR10 (32\u00d732). The CIFAR-10 dataset (Krizhevsky, 2009) consists of 50,000 training sam-\nples distributed across 10 classes. We conducted experiments using the entire CIFAR-10 dataset to\nevaluate the DAS. For computational efficiency and to facilitate ablation studies, we also created\na subset called CIFAR-2 from CIFAR-10, which includes 5,000 samples randomly selected from\nthe \"automobile\" and \"horse\" categories. We employed a DDPM model as described by Ho et al.\n(2020), which includes 35.7M parameters. Image generation during inference was performed using\na 50-step Denoising Diffusion Implicit Models (DDIM) solver (Song et al., 2021a).\nCelebA (64\u00d764). From original CelebA dataset training and test sets (Liu et al., 2015), we extracted\n5,000 training samples. Following preprocessing steps outlined by Song et al. (2021b), images were"}, {"title": "4.2 EVALUATION METHOD FOR DATA ATTRIBUTION", "content": "Various methods are available for evaluating data attribution techniques, including the leave-one-\nout influence method (Koh & Liang, 2017; Basu et al., 2021) and Shapley values (Lundberg &\nLee, 2017). These methods, however, present significant computational challenges in large-scale"}, {"title": "4.3 EVALUATION FOR SPEED UP TECHNIQUES", "content": "In this section, we detail the experiments conducted to evaluate the effectiveness of the speed-up\ntechniques applied in computing the DAS. The diffusion models used in our experiments vary sig-\nnificantly in complexity, with parameter counts of 35.7M, 118.8M, and 25.5M respectively. These\nlarge dimensions pose considerable challenges in calculating the attribution score efficiently. To\naddress this, we implemented speed-up techniques as discussed in Section 3.3."}, {"title": "", "content": "Normalization. The first technique we evaluated is the normalization of gradients and residuals, as\nproposed in Eq. 17. Given that the data attribution method in Eq. 16 targets model output at a spe-\ncific timestep, we advocated for the normalization of gradients and residuals across all generation\nprocesses before averaging. This approach is intended to stabilize the variability in gradient magni-\ntudes across timesteps, thereby enhancing computational efficiency and accuracy. The specifics of\nthis normalization process are detailed in Eq. 17."}, {"title": "", "content": "Due to space constraints, the results of these evaluations in this section are reported in the Ap-\npendix F.4. As shown in Table 4, the implementation of normalization improved the performance of\nboth DAS and D-TRAK."}, {"title": "", "content": "Number of timesteps. When computing the DAS as defined in Eq. 18, obtaining gradients at more\ntimesteps can potentially improve performance due to more comprehensive averaging, but it also\nnecessitates more back-propagation steps. Consequently, there is a notable trade-off between effec-\ntiveness and computational efficiency. To explore this, we considered the extreme case of computing\ngradients for all 1000 timesteps-a scenario that is computationally intensive, especially for large\nprojection dimensions and extensive datasets. We conducted an experiment using the CIFAR-2\ndataset with a projection dimension k = 4096. The results, presented in Table 5, demonstrate that\nincreasing the number of timesteps correlates with improved LDS outcomes. Notably, our findings\nalso indicate that setting the number of timesteps to 100, or even 10, can achieve performance com-\nparable to that of 1000 timesteps, but with significantly reduced computational demands. Based on"}, {"title": "4.4 MAIN EXPERIMENT", "content": "In this section, we evaluate the performance of the Diffusion Attribution Score (DAS) against exist-\ning attribution baselines that can be applied in our experimental settings, following methodologies\nsimilar to those described by Zheng et al. (2024). We limit the use of techniques to projection only,\nomitting others like normalization to ensure fair comparisons across different attribution methods.\nOur primary focus is on post-hoc data attribution methods, which are applied after the model's\ntraining is complete. These methods are categorized into similarity-based, gradient-based (with-\nout kernel), and gradient-based (with kernel) approaches, with detailed explanations provided in\nAppendix F.3. The outcomes are documented in Tables 1, 2, and 3, where DAS consistently outper-\nforms existing methods across all datasets."}, {"title": "5 CONCLUSION", "content": "In this paper, we introduce the Diffusion Attribution Score (DAS) to address the existing gap in data\nattribution methodologies for generative models. We conducted a comprehensive theoretical anal-\nsis to elucidate the inherent challenges in applying TRAK to diffusion models. Subsequently, we\nderived DAS theoretically based on the properties of diffusion models for attributing data throughout\nthe entire generation process. We also discuss strategies to accelerate computations to extend DAS\nto large-scale diffusion models. Our extensive experimental evaluations on datasets such as CIFAR,\nCelebA, and ArtBench demonstrate that DAS consistently surpasses existing baselines in terms of"}, {"title": "A RELATED WORKS", "content": ""}, {"title": "A.1 DATA ATTRIBUTION", "content": "The training data exerts a significant influence on the behavior of machine learning models. Data\nattribution aims to accurately assess the importance of each piece of training data in relation to the\ndesired model outputs. However, methods of data attribution often face the challenge of balancing\ncomputational efficiency with accuracy. Sampling-based approaches, such as empirical influence\nfunctions (Feldman & Zhang, 2020), Shapley value estimators (Ghorbani & Zou, 2019; Jia et al.,\n2019), and datamodels (Ilyas et al., 2022), are able to precisely attribute influences to training data\nbut typically necessitate the training of thousands of models to yield dependable results. On the\nother hand, methods like influence approximation (Koh & Liang, 2017; Schioppa et al., 2022) and\ngradient agreement scoring (Pruthi et al., 2020) provide computational benefits but may falter in\nterms of reliability in non-convex settings (Basu et al., 2021; Ilyas et al., 2022; Akyurek et al.,\n2022)."}, {"title": "A.2 DATA ATTRIBUTION IN GENERATIVE MODELS", "content": "The discussed methods address counterfactual questions within the context of discriminative models,\nfocusing primarily on accuracy and model predictions. Extending these methodologies to genera-\ntive models presents complexities due to the lack of clear labels or definitive ground truth. Re-\nsearch in this area includes efforts to compute influence within Generative Adversarial Networks\n(GANs) (Terashita et al., 2021) and Variational Autoencoders (VAEs) (Kong & Chaudhuri, 2021).\nRecently, Park et al. (2023) developed TRAK, a new attribution method that is both effective and\ncomputationally feasible for large-scale models. In the realm of diffusion models, earlier research\nhas explored influence computation by employing ensembles that necessitate training multiple mod-\nels on varied subsets of training data a method less suited for traditionally trained models (Dai &\nGifford, 2023). Journey TRAK (Georgiev et al., 2023) extends TRAK to diffusion models by at-\ntributing influence across individual denoising timesteps. Moreover, D-TRAK (Zheng et al., 2024)\nh"}]}