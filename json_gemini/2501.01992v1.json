{"title": "Disagree and Commit: Degrees of Argumentation-based Agreements", "authors": ["Timotheus Kampik", "Juan Carlos Nieves"], "abstract": "In cooperative human decision-making, agreements are often not total; a partial degree of agreement is sufficient to commit to a decision and move on, as long as one is somewhat confident that the involved parties are likely to stand by their commitment in the future, given no drastic unexpected changes. In this paper, we introduce the notion of agreement scenarios that allow artificial autonomous agents to reach such agreements, using formal models of argumentation, in particular abstract argumentation and value-based argumentation. We introduce the notions of degrees of satisfaction and (minimum, mean, and median) agreement, as well as a measure of the impact a value in a value-based argumentation framework has on these notions. We then analyze how degrees of agreement are affected when agreement scenarios are expanded with new information, to shed light on the reliability of partial agreements in dynamic scenarios. An implementation of the introduced concepts is provided as part of an argumentation-based reasoning software library.", "sections": [{"title": "1 Introduction", "content": "In Artificial Intelligence (AI) research, devising formal models and algorithms that specify how autonomous agents can reach agreements is an important research direction [2]. In this context, the symbolic AI community considers formal argumentation approaches [3, 4] as particularly promising. Recently, such approaches have, for example, been proposed to align the moral values of different stakeholders in decision automation scenarios [5] and to resolve rule conflicts in medical decision-support systems [6]. From a more generic perspective, recent research has introduced a formal approach to determining degrees of agreement in formal argumentation dialogues, in which agents add arguments on a specific topic to a knowledge base [7]. The intuition behind this notion is that for practical purposes, it is often not necessary (or possible) to reach a complete agreement; instead, agents may decide that a certain degree of agreement on a given topic is sufficient to commit to roughly aligned decisions and move on. In management practice, this approach is sometimes referred to as \"disagree and commit\" [8], emphasizing that while discourse is vital, at some point stakeholders will have to align in order to lay the prerequisites for successful execution. In this paper, we introduce this notion to formal argumentation, in particular to abstract and value-based argumentation, and work towards answering the following research questions about multi-agent agreements in abstract and value-based argumentation:\n1. How can a set of agents determine to what degree they are agreeing on a topic (set of arguments)?\n2. How do an agent's subjective value preferences impact the degree of agreement on a topic?\n3. How are degrees of agreement affected when agreement scenarios are expanded with new information?\nTo answer Question 1 and 2, we introduce a formal framework for agreement scenarios and degrees of satisfaction and agreement to abstract argumentation [9], as well as to value-based argumentation [10]. To answer Question 3, we apply and extend formal properties that are systematic relaxations of monotony of entailment and conduct a basic empirical analysis using synthetic data.\nLet us introduce examples to illustrate the contribution this paper makes to the research questions. First, we take a step back, introducing a simple choice-based agreement scenario.\nExample 1 (Degrees of Agreement in Simple Choice Scenarios). We have three agents (A0, A1, A2), who are C-level managers and discuss which strategic initiatives among a, b, and c are the most important ones. Considering the complex socio-professional nature of the problem, reaching full consensus on all questions is intractable. As long as everyone roughly agrees on the importance, the managers will be content and assume that their objectives are aligned to a sufficient degree. Table 1 shows ranks and degrees of satisfaction of the managers given the different choice options, assuming the agents have established a total preorder of preferences on the powerset of the set of all options\u00b9. Here, we assume that the option of Rank 1 in Table 1 is an agent's most preferred option and the ranks of all other options are inferred from this option. Table 1 assumes that the agents care about agreement with respect to the inclusion as well as exclusion of options: here, we may assume that the ranking is based on a similarity measure between the most preferred and other options. For example, we may measure similarity between {b,c} and {b} by computing the number of joint options in plus the number of joint options out, divided by the total number of options, i.e. $\\frac{|\\{b,c\\}^{b}|+|\\{a\\}^{a,c}|}{|\\{a,b,c\\}|}$, and between {b,c} and {a,c} by computing $\\frac{|\\{b,c\\}^{a,c}|+|\\{a\\}^{b}|}{|\\{a,b,c\\}|}$. Hence, given the most preferred option {b,c}, A\u2081 ranks {b} higher than {a,c}."}, {"title": "3 Degrees of Agreements in Abstract Argumentation", "content": "Let us formalize the intuitions introduced in Section 1, starting with the notion of an argumentation-based agreement scenario.\nDefinition 5 (Argumentation-based Agreement Scenario (AAS)). An argumentation-based agreement scenario is a tuple AAS = (AF,T, SIG), where AF = (AR,AT) is an argumentation framework, T C AR and SIG = \u27e8\u03c3\u2080, ..., \u03c3\u2099\u27e9, such that each \u03c3\u1d62, 0 \u2264 i \u2264 n is an argumentation semantics. We say that T denotes the topic of AAS.\nIntuitively, an agreement scenario contains the argumentation framework that (typically several) agents, each represented by the argumentation semantics, infer extensions from; the topic is the subset of arguments in the argumentation that the agents want to agree on. Arguments that are not in the topic play, in contrast, a merely auxiliary role in that they may have an impact on which topic arguments are inferred. Let us recall the motivating example.\nExample 7. In Example 1 (see Figure 1 for the argumentation framework), we have the agreement scenario (({a, b, c, d, e}, {(b, e), (c, e), (d, a), (d, d), (e, b), (e, c), (e, e) }), {a,b,c}, \u27e8\u03c3st, \u03c3pr, \u03c3gr\u27e9): our three agents apply stable, preferred, and grounded semantics, respectively, and are interested in the topic arguments a, b, and c.\nWe now introduce a measure of the degree of satisfaction given an argumentation semantics w.r.t. an argumentation framework, and two subsets of the argumentation framework's arguments (a topic set and a conclusion set, the latter of which is typically an extension inferred by applying an argumentation semantics). First, we introduce the degree of satisfaction as an abstract measure.\nDefinition 6 (Abstract Degree of Satisfaction). Let \u03c3 be an argumentation semantics, let AF = (AR,AT) be an argumentation framework, and let T,S \u2286 AR. The degree of satisfaction of \u03c3 w.r.t. AF, T, and S, denoted by \u03c3\u209b\u1d62\u2098(AF,T,S), is determined as follows:\n\u03c3\u209b\u1d62\u2098(AF,T,S) = max({sim(E,S,T)|E\u2208 \u03c3(AF)}),\nwhere sim : 2\u1d2c\u1d3f \u00d7 2\u1d2c\u1d3f \u00d7 2\u1d2c\u1d3f \u2192 [0,1]. We call sim the similarity function of \u03c3\u209b\u1d62\u2098.\nWe then define several specific measures of the degree of satisfaction, using a measure that is based on the well-known Hamming distance measure [22] (which is also used in related research on merging argumentation frameworks [23]), as well as simpler intersection-based measures."}, {"title": "Definition 7 (Degree of Satisfaction, Similarity Measures).", "content": "Given the sets of arguments T,E,S\u22082\u1d2c\u1d3f, as well as the set differences (relative complements) E' :=T\\E and S' :=T\\S, we define the following similarity functions of extensions E and S with respect to the topic \u0422.\nIntersection-based similarity (i-similarity):\ni(E,S,T) = \\{\n    1 & if |T\u2229 (EUS)| = 0;\\\\\n    \\frac{|T\u0e01E\u0e01S|}{|T\u2229(EUS)|} & otherwise.\n\\}\nComplement-based similarity (c-similarity):\nc(E,S,T) = \\{\n    1 & if |T\u2229 (E' US')| = 0;\\\\\n    \\frac{|T\u0e01E'OS'|}{|T\u2229(E'US')|} & otherwise.\n\\}\nHamming-based similarity (h-similarity):\nh(E,S,T) = \\{\n    1 & if T = 0;\\\\\n    \\frac{|T\u2229E\u2229S|+|(E')\u2229(S')|}{|T|} & otherwise.\n\\}\nHere, the intersection-based (i-similarity) and complement-based similarity (c-similarity) serve as mere building blocks for the Hamming similarity-like measure; we merely use both i-similarity and h-similarity in Example 8 to highlight the nuanced, yet important, difference.\nLet us note that the measures could potentially be extended to account for weights that model the importance of arguments; intuitively, the current measures consider all arguments in the topic as equally important, whereas all arguments that are not in the topic are considered as entirely irrelevant.\nNow, we can introduce the two-agent degree of satisfaction for AAS, as a means to provide a starting point for the n-agent degrees that follow later.\nDefinition 8 (Two-Agent Degree of Satisfaction). Let AF = (AR,AT) be an argumentation framework, let T \u2286 AR, let \u03c3 and \u03c3' be argumentation semantics, and let sim be a similarity function. The degree of satisfaction between \u03c3 and \u03c3' w.r.t. AF and T, denoted by sat\u209b\u1d62\u2098(AF,T, \u03c3, \u03c3'), is determined as follows:\nsat\u209b\u1d62\u2098(AF,T, \u03c3, \u03c3') = max({\u03c3\u209b\u1d62\u2098(AF,T,E)|E \u2208 \u03c3'(AF)}).\nIntuitively, the two-agent degree of satisfaction measures the distance between the maximally similar extensions (considering only the topic arguments of the extensions) that the agents' semantics can infer from the given argumentation framework. Let us introduce an example for illustration purposes."}, {"title": "4 Expanding Argumentation-based Agreement Scenarios", "content": "In our study, we are interested in how degrees of agreement change in dynamic environments, in which agents have a dialogue by exchanging arguments. In our case, the dynamism is modeled by a normally expanding argumentation framework, i.e., new arguments are added to an initial argumentation framework, as well as attacks involving these new arguments as source or targets, whereas the attack relationships between initially existing arguments remain unchanged. In order to model how agreement scenarios change in the face of new information that becomes available, let us define normal expansions in the context of AAS.\nDefinition 10 (AAS Normal Expansions). Let AAS = (AF,T,SIG) and AAS' = (AF',T',SIG') be argumentation-based agreement scenarios, with AF = (AR,AT). AAS' is a normal expansion of AAS, denoted by AAS \u227c\u1d3a AAS', iff it holds true that AF \u227c\u1d3a AF', T\u2286 T', (T' \\T)\u2229AR = {} and SIG = SIG'.\nThe idea behind an AAS normal expansion is that agents engage in an argumentation-based dialogue that starts with a topic set (a subset of the arguments of the AAS' argumentation framework). The agents argue by adding new arguments to the argumentation framework, and may also expand the topic set to include some of these new arguments; in contrast, the topic cannot be expanded using arguments from the initial argumentation framework. Also, the agents cannot \u201cremove\u201d arguments (neither from the argumentation framework nor from the topic set), nor \"change\" the attack relations between existing arguments or add existing arguments to the topic set.\nLet us illustrate the notion of an AAS normal expansion by introducing an example.\nExample 10. Let us revisit the argumentation frameworks depicted in Figure 3:\n*   AF\u2080 = ({a,b,c}, {(a, b), (b, c)});\n*   AF\u2081 = ({a, b, c,d}, {(a,b), (b,a), (b, c), (d,a)});\n*   AF\u2082 = ({a, b, c,d}, {(a,b), (b, c), (d,a)}).\nHere, AF\u2080 is the argumentation framework in our initial agreement scenario, whereas AF\u2081 and AF\u2082 are then used in potential expansions. We utilize these argumentation frameworks in the following AAS:\n*   AAS\u2080 = (AF\u2080, {a,b}, (\u03c3\u2080, \u03c3\u2081));\n*   AAS\u2081 = (AF\u2081, {a,b}, (\u03c3\u2080, \u03c3\u2081));\n*   AAS\u2082 = (AF\u2082, {a, b,d}, (\u03c3\u2080, \u03c3\u2081));\n*   AAS\u2082 = (AF\u2082, {a, b, c}, (\u03c3\u2080, \u03c3\u2081));\n*   AAS\"\u2082 = (AF\u2082, {a,b}, (\u03c3\u2080, \u03c3\u2081, \u03c3\u2082)).\nHere, we do not care about the specifics of the argumentation semantics \u03c3\u2080, \u03c3\u2081, and \u03c3\u2082. Now, we can observe the following:\n*   AAS\u2080 \u227c\u1d3a AAS\u2081 does not hold: the expansion from AF\u2080 to AF\u2081 \"adds\u201d an attack between arguments in the initial argumentation framework;\n*   AAS\u2080 \u227c\u1d3a AAS\u2082 holds: AF\u2080 \u227c\u1d3a AF\u2082 holds, the topic is expanded by adding a \u201cnew\u201d argument, and the sequence of semantics remains the same;"}, {"title": "Definition 11 (Relaxed Monotony Principle).", "content": "An argumentation semantics \u03c3 satisfies the relaxed monotony principle RMP\u209a iff for every two argumentation frameworks AF = (AR,AT), AF' = (AR',AT') such that AF \u227c\u1d3a AF', the following statement holds true:\n\u2200E \u2208 \u03c3(AF),\nif p(AF,AF',\u0395, \u03c3) holds true\nthen \u2203\u0395' \u2208 \u03c3(AF') s.t. E \u2286 E',\nwhere p (the principle's p-function) is a Boolean function p: F \u00d7 F \u00d7 2\u1d2c\u1d3f \u00d7 S \u2192 {true, false}, i.e., AF,AF' \u2208 F, E \u2208 2\u1d2c\u1d3f (also: E \u2286 AR), and \u03c3 \u2208 S.\nWe may call the p-function of a relaxed monotony principle the principle's monotony condition; given an argumentation semantics that satisfies a relaxed monotony principle RMP\u209a, we may say that \u03c3 satisfies p-relaxed monotony. Now, we can characterize weak cautions monotony (Definition 4) as a relaxed monotony principle.\nProposition 4.1. An argumentation semantics \u03c3 satisfies weak cautious monotony iff \u03c3 satisfies the relaxed monotony principle RMPcm, where the p-function is characterized by the following function:\ncm(AF,AF', \u0395, \u03c3) = \\{\ntrue, & if S\u2217 = \u2205;\\\\\nfalse, & otherwise,\\\\\n\\}\nAF = (AR,AT),AF' = (AR',AT'), and S\u2217 = {(a,b)|(a, b) \u2208 AT', a \u2208 AR' \\AR,b\u2208 E}.\nFor the sake of increasing the stability of the agreements that agents reach, we may want to introduce stricter relaxed monotony principles to then enforce that agents adhere to them in the context of our agreement scenarios. Let us, for this purpose, introduce a principle that (roughly speaking) stipulates that we can only relax monotony if the expansion of our initial argumentation framework implies that an argument that attacks our initially inferred extension cannot be rejected. For this, let us first introduce the notion of a strong attacker in the context of argumentation framework expansions."}, {"title": "5 Degrees of Agreements in Value-based Argumentation", "content": "We extend the formal framework from the previous sections by defining satisfaction and agreement degrees for value-based argumentation. Value-based argumentation allows us to model subjective value preferences for different agents instead of assuming differences between the agents' semantics. Let us first introduce the notion of a value-based AAS (VAAS).\nDefinition 15 (Value-based AAS (VAAS)). A value-based agreement scenario is a tuple (VAF,T,\u03c3), where VAF is a value-based argumentation framework VAF = (AR,AT,V, val, P), T \u2286 AR is the topic, and \u03c3 is an argumentation semantics.\nLet us again highlight that in a VAAS, differences between the agents' inference processes are managed via the value preferences that are modeled as part of the VAF. Hence, we do not need to model different argumentation semantics. We introduce a function that maps value-based AAS to argumentation-based agreement scenarios, so that we can build upon the definitions introduced in the previous section. In the mapping definition, we make use of the notion of a subjective argumentation framework, as introduced in Section 2 as part of the preliminaries for value-based argumentation.\nDefinition 16 (AAS-to-Value-based AAS-Mapping). vaas is a function that takes a value-based AAS, VAAS = ((AR,AT,V,val, P),\u03a4, \u03c3), and returns an argumentation-based agreement scenario AAS = ((AR,AT),T,SIG) s.t. SIG = \u27e8\u03c3\u2080, ..., \u03c3\u2099\u27e9 and each \u03c3\u1d62, 0 \u2264 i \u2264 n is an argumentation semantics and the equality \u03c3\u1d62(AF) = \u03c3(AF\u209a\u1d62) holds true.\nThe vaas function allows us to determine degrees of satisfaction and agreement in the same way we do it for AAS.\nDefinition 17 (Degrees of Satisfaction and Agreement in Value-based Argumentation). Let VAAS = (VAF,T,\u03c3) be a value-based AAS, VAF = (AR,AT,V,val, P), with P = (P\u2080,..., P\u2099). Let AAS = (AF,T,SIG) be the argumentation-based agreement scenario s.t. AAS = vaas(VAAS), AAS = ((AR,AT),T,SIG),SIG = (\u03c3\u2080, ..., \u03c3\u2099), and let sim be a similarity function. We define:\n*   the degree of minimal agreement of VAAS, denoted by vdeg\u209b\u1d62\u2098(VAAS), as deg\u209b\u1d62\u2098(AAS);\n*   the degree of mean agreement of VAAS, denoted by vdeg\u209b\u1d62\u2098\u2098\u2091\u2090\u2099(VAAS), as deg\u209b\u1d62\u2098\u2098\u2091\u2090\u2099(AAS);\n*   the degree of median agreement of VAAS, denoted by vdeg\u209b\u1d62\u2098med(VAAS), as deg\u209b\u1d62\u2098med(AAS).\nFor P\u1d62 and P\u2c7c with 0 \u2264 i \u2264 n, 0 \u2264 j \u2264 n, we define the two-agent degree of satisfaction between P\u1d62 and P\u2c7c w.r.t. VAF, T denoted by vsat\u209b\u1d62\u2098(AF,T,P\u1d62,P\u2c7c), as sat\u209b\u1d62\u2098(AF,T, \u03c3\u2c7c,\u03c3\u2c7c).\nLet us introduce an example of a value-based AAS and its degrees of satisfaction and agreement.\nWe continue our previous example to illustrate this notion."}, {"title": "6 Expanding Value-Based AAS", "content": "As the final formal part of this paper, let us extend our notion of AAS expansions, as well as the analysis of how reliable agreements are in the face of expansions, to the case of value-based AAS. Before we proceed to the formal analysis, we define VAF expansions and normal expansions.\nDefinition 19 (VAF (Normal) Expansions). Let VAF = (AR,AT,V,val,P) and VAF' = (AR',AT',V',val', P') be value-based argumentation frameworks, such that P = (P\u2080, ...,P\u2099) and P' = (P'\u2080,...,P'\u2098).\n*   VAF' is an expansion of VAF (denoted by VAF \u227c\u1d31 VAF') iff it holds true that (AR,AT) \u227c\u1d31 (AR',AT'), V \u2286 V', \u2200a \u2208 AR, val(a) = val'(a), |P| = |P'| and for every P\u1d62, P'\u1d62, 0 \u2264 i \u2264 n, P\u1d62\u2286 P'\u1d62.\n*   VAF' is a normal expansion of VAF (denoted by VAF \u227c\u1d3a VAF') iff it holds true that VAF \u227c\u1d31 VAF', (AR,AT) \u227c\u207f (AR',AT'), \u2200a \u2208 AR, val'(a) = val(a), and for every P\u1d62, P'\u1d62, 0 \u2264 i \u2264 n, for every (v,v') \u2208 P it holds that if v,v' \u2208 V then (v, v') \u2208 P\u1d62.\nThis allows us to define VAAS normal expansions.\nDefinition 20 (VAAS Normal Expansions). Let VAAS = (VAF,T,\u03c3) and VAAS' = (VAF', \u03a4', \u03c3') be value-based AAS. VAAS' is a normal expansion of VAAS, denoted by VAAS \u227c\u1d3a VAAS' iff VAF \u227c\u1d3a VAF', T\u2286 T', (T' \\T) \u2229AR = {} and \u03c3 = \u03c3'."}, {"title": "7 Implementation and Experiments", "content": "As an initial step towards an empirical perspective on our formal approach to degrees of agreement in argumentation dialogues, we provide a software implementation that supports the specification of argumentation-based agreement scenarios (value-based or not) and the computation of degrees of satisfaction and agreement, as well as of the impact values have on degrees of agreement. The implementation is an extension of the Diarg argumentation-based dialogue reasoner [19], which in turn is based on Tweety, a well-known library for argumentation and defeasible reasoning [27]. Like Tweety, our implementation is provided in Java, a mainstream high-level programming language. A tutorial on how to work with our implementation is provided at http://s.cs.umu.se/mhfrcp, alongside the source code and additional documentation and tests.\nUsing our implementation, we can conduct initial experiments based on synthetically generated argumentation frameworks to obtain some empirically informed intuitions. Below, we do exactly this, focusing on value-based AAS and the following two questions:\n1. Given a value-based AAS and a normal expansion of it, how large is the delta between initial and final degrees of (minimal, median, and median) agreement, and how is this delta affected by the size of the expansion (in terms of number of new arguments)?\n2. Given a value-based AAS, how large is the impact a value has on the degrees of (minimal, median, and mean) agreement, and how does the size of the argumentation framework (in terms of number of arguments) affect the impact?\nWe focus on value-based AAS and do not cover \"ordinary\u201d AAS because the former explicitly model subjective differences in agent preferences that affect the extensions inferred by the agents, whereas in the latter case, the degrees of agreement are affected solely by differences in how semantics treat topological properties (arguably: often nuances) of argumentation frameworks. Hence, we consider an empirical study of value-based AAS more interesting for gauging future application potential. In contrast, a study of AAS could, if conducted thoroughly, produce empirical insights regarding the nature of differences between argumentation semantics, but is considered out-of-scope in the context of our paper.\nIn order to shed light on Question 1, we first generate an initial value-based AAS and determine the degrees of agreement (Step 1). Then, we expand the value-based AAS and again determine the degrees of agreement and their delta to the previously computed degrees (Step 2), as described in more detail below:\n1. Each argument has up to three attack targets, and each of the three attacks (to any random argument) is generated with a probability of 50%. Self-attacks are excluded. Each argument is mapped to a value (we can then say that we have single-argument values and hence our VAFs are, intuitively, multi-agent preference-based argumentation frameworks). A topic is generated that includes any of the arguments with 50% probability. We then generate five value preferences for each of the three agents, in a pseudo-random manner, considering the following constraints: i) each value preference runs contrary to the direction of an attack between two arguments that are mapped to the corresponding values, in order to ensure the value preference can have an actual impact on the inferences that are drawn; ii) an agent's value preferences must be transitive. Then, we instantiate the initial value-based AAS and determine its degrees of (minimal, mean, and median) agreement.\n2. We then expand the (value-based) argumentation framework by adding one or several arguments (see below) and attacks from these arguments to any other arguments, but not vice versa7. We also generate a new value for each of the new arguments and add new value preferences for each agent, approximately one for each new argument, again in a pseudo-random manner considering the constraints above (preferences running contrary to attacks and transitive preferences per agent). Then, we generate a new value-based AAS with the expanded value-based argumentation framework and again determine the new degrees of agreement, which we then use to compute the (absolute) delta between then initial and new degrees (minimal, median, and mean). When generating the new value-based AAS, we run experiments for two configurations: i) in one configuration, we keep the topic fixed, i.e., no new arguments are added to the topic; ii) in the other configuration, we expand the topic by adding each \u201cnew\u201d argument to the topic with a probability of 50%."}, {"title": "8 Related Research", "content": "The research presented in this paper takes the idea of degrees of agreement, first developed for a specific variant of structured argumentation [7], and lifts them to the abstract level; the two approaches are not directly comparable, as they assume fundamentally different underlying formal models. Let us argue that the approach taken in this paper is appealing because it takes abstract argumentation as a starting point, which is a very simple model of reasoning in face of conflicts that is well-studied and widely understood within the broader symbolic AI community.\nThe issue our theoretical framework and its software implementation tackle is of a different nature than the problems investigated in works on merging knowledge bases in general [28] and argumentation frameworks in particular [23] in that we focus on the result of an inference process and not on the input knowledge base. In contrast to works on argumentation and judgment aggregation (see [29] for a survey), our work does not primarily address the problem of determining a joint judgment, but rather of assessing to what extent diverging judgments are aligned and may stay aligned in a dynamic environment; thereby, we provide a novel bridge between multi-agent argumentation and argumentation dynamics (see [30] for a survey). In contrast to other works on argumentation dynamics such as [31, 32] that formalize change operations (for adding and removing an argument, respectively), we instead model change as the normal expansion of an argumentation framework. This means we focus only on the addition of new arguments. Let us claim that this is a well-motivated constraint: after all, the removal of arguments can be modeled by introducing dummy annihilator arguments"}]}