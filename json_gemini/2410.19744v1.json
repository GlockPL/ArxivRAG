{"title": "Towards Next-Generation LLM-based Recommender Systems: A Survey and Beyond", "authors": ["QI WANG", "JINDONG LI", "SHIQI WANG", "QIANLI XING", "RUNLIANG NIU", "HE KONG", "RUI LI", "GUODONG LONG", "YI CHANG", "CHENGQI ZHANG"], "abstract": "Large language models (LLMs) have not only revolutionized the field of natural language processing (NLP) but also have the potential to bring a paradigm shift in many other fields due to their remarkable abilities of language understanding, as well as impressive generalization capabilities and reasoning skills. As a result, recent studies have actively attempted to harness the power of LLMs to improve recommender systems, and it is imperative to thoroughly review the recent advances and challenges of LLM-based recommender systems. Unlike existing work, this survey does not merely analyze the classifications of LLM-based recommendation systems according to the technical framework of LLMs. Instead, it investigates how LLMs can better serve recommendation tasks from the perspective of the recommender system community, thus enhancing the integration of large language models into the research of recommender system and its practical application. In addition, the long-standing gap between academic research and industrial applications related to recommender systems has not been well discussed, especially in the era of large language models. In this review, we introduce a novel taxonomy that originates from the intrinsic essence of recommendation, delving into the application of large language model-based recommendation systems and their industrial implementation. Specifically, we propose a three-tier structure that more accurately reflects the developmental progression of recommendation systems from research to practical implementation, including representing and understanding, scheming and utilizing, and industrial deployment. Furthermore, we discuss critical challenges and opportunities in this emerging field.", "sections": [{"title": "1 INTRODUCTION", "content": "Recommender systems have become integral to our digital lives. By curating personalized content, products, and services [4], these systems facilitate user decision-making processes, enhance user experience, and contribute to the economic success of industries. Recently, large language models (LLMs) have become a cornerstone in enhancing recommender systems due to their powerful generalization capabilities and reasoning skills, which has led to a shift in the realm of recommendation paradigm [157]. More importantly, the emergence of large language models has brought new opportunities to bridge the substantial gap between research and practical deployment, enabling the authentic translation of recommendation algorithms into real-world applications [154]. Such advances promise to revolutionize conventional recommendation frameworks and set the stage for a new era of recommendation.\nWith increasing efforts to explore large language model (LLM) methods for recommender systems [28, 112, 160, 179], several critical issues merit further investigation. Firstly, current deep learning methods focus on obtaining the embedding features of users and items via user/item ID to perform"}, {"title": "2 OVERVIEW", "content": "2.1 A Brief History of Recommender Systems\nThe history of recommender systems is a rich narrative that spans several decades, reflecting the evolution of machine learning techniques. The journey began with simple heuristics in the early days, where recommendations were often based on the most popular items or those with the highest ratings. These methods were limited in their ability to provide personalized recommendations.\nAs data collection became more robust, collaborative filtering [33, 73] emerged as a dominant approach. This method exploited the collective preferences of the users to make predictions, either by comparing the similarity between users (user-based collaborative filtering) or between items (item-based collaborative filtering). However, collaborative filtering faced challenges such as the \"cold start\" problem, where new users or items lacked sufficient data for accurate recommendations."}, {"title": "2.2 Notations and Definitions", "content": "To formally define the process flow of LLM-based recommender systems, in this subsection, we formalize the notations and definitions used for LLM-based Recommender Systems as follows.\nUsers and items in a recommender system can be represented by feature vectors $x_u \\in \\mathbb{R}^d$ and $y_i \\in \\mathbb{R}^d$, respectively, where d denotes the feature dimension. These vectors are designed to encapsulate essential characteristics of both users and items. For users, the feature vector x\u016b might include demographic information, behavioral data (e.g., past interactions with items), or inferred preferences. Similarly, the item feature vector yi could encompass attributes such as genre, price, brand, or content descriptors. The dimensionality d represents the number of features considered, which can be determined based on the specific application or data availability. These vectors serve as the basis for calculating similarity measures or making predictions in various recommendation algorithms."}, {"title": "2.2.2 Definitions", "content": "DEFINITION 1. Recommender Systems. Recommender systems aim to predict the utility of items for users by leveraging historical interactions. Let $U = {U_1, U_2, ..., U_m}$ denote the set of users and $I = {i_1, i_2, ..., i_n}$ the set of items. The interaction between user u and item i can be represented by\na matrix $R \\in \\mathbb{R}^{m\\times n}$, where each entry $r_{ui}$ indicates the interaction level, such as as a rating or binary indicator.\nPrediction Function: The recommender system learns a function $f(u, i|\\theta)$ that predicts the interaction $r_{ui}$ based on parameters \u03b8. The objective is to minimize the prediction error across all observed interactions:\n$\\min_{\\theta} \\sum_{(u,i) \\in D} (r_{ui} - f(u, i|\\theta))^2$\nwhere D is the set of observed interactions.\nRecommendation: Given the learned function $f(u, i|\\theta)$, the system generates a ranked list of items $i \\in I$ for each user $u \\in U$, typically by sorting items based on the predicted scores $f(u, i|\\theta)$.\nDEFINITION 2. LLM-based Recommender Systems. LLM-based Recommender Systems leverage Large Language Models (LLMs) to enhance or refine recommendation processes. In summary, LLM-based Recommender Systems are defined by their capability to utilize the deep contextual and semantic understanding of LLMs to enhance recommendation tasks. They transform input feature vectors $x_i$ into predictive outputs $\u0177_i$ by leveraging the extensive knowledge encoded in the LLM, thereby improving the overall recommendation quality and user experience. The integration of LLMs into recommender systems involves the following components:\nLarge Language Model (LLM): Denoted as LLM(\u00b7), this model is trained on extensive text data and possesses advanced contextual understanding. The LLM is used to process input features and predict recommendations based on deep learning and contextual analysis.\nRefined Predictive Function f(\u00b7): The LLM generates or refines the predictive function. Given the domain D = {X,P(X)} and task T = {Y, f(\u00b7)}, the LLM produces a refined predictive function f(.) that maps feature vectors $x_i$ to recommended labels $\u0177_i$.\nThe formal representation of the LLM-based recommendation process is:\n$f(x) = LLM(X, Y, \\theta)$\nwhere f(x) is the refined predictive function output by the LLM, X is the feature space containing user-item interaction vectors, y is the label space representing possible recommendations, and \u03b8 represents the model parameters of the LLM. It includes weights and biases learned during training.\n3 REPRESENTING AND UNDERSTANDING\nWith the advent of large language models (LLMs), recommender systems are experiencing a paradigm shift from traditional, closed methodologies to more open and dynamic frameworks. These models bring expansive world knowledge and advanced reasoning capabilities, enhancing the ability of recommender systems to not only generate accurate suggestions but also to improve intermediate processes such as user and item representation. In this evolving landscape, representing and understanding have become pivotal. Representing involves creating nuanced, semantic representations of users and items, categorized into uni-modality and multi-modality approaches.\n3.1 Representing\nIn modern recommender systems, the representation of user-item interactions forms the foundation for generating accurate and personalized recommendations. This representation involves the fusion and processing of multimodal data, including text, image, audio, video, metadata, etc., to capture the full spectrum of user preferences and item characteristics. Let $X_r, X_{txt},X_{img},X_{aud}, X_{vid}, X_{seq}, X_{time}$ denote the extracted features of different modalities including user-item interaction, text data, image data, audio data, video data, sequence data, and timestamp data. These features are then fused into a unified representation as:\n$X_{multi} = Fusion(X_r, X_{txt}, X_{img}, X_{aud}, X_{vid}, X_{seq}, X_{time})$\nAs recommender systems evolve to meet the diverse needs of users, it becomes crucial to consider both the variety of the data and the complexity of the relationships it captures. This leads us to explore two distinct yet complementary approaches: Uni-Modality and Multi-Modality recommendations. Uni-Modality recommendations focus on leveraging user-item interactions, utilizing graph data to model these interactions and occasionally supplementing it with textual information to refine the understanding of user preferences and item attributes. In contrast, Multi-Modality approaches extend beyond the boundaries of uni-modality by integrating data from multiple sources or modalities, such as text, image, and video. This expansion leverages the availability of diverse data sources to provide a richer understanding of user preferences and item attributes, offering a more comprehensive and flexible recommendation strategy.\n3.1.1 Uni-Modality\nIn uni-modality recommendations, the primary approach involves leveraging graph-based methods to model user-item interactions. These methods emphasize the structural relationships between entities, capturing patterns within the data to predict user preferences. To enhance the effectiveness of the recommender system, textual information is occasionally integrated into the graph structure, adding semantic context that enriches the understanding of\nDEFINITION 3. Uni-Modality Recommendation. Uni-Modality refers to recommender systems that leverage data from a single modality. In this approach, user-item interactions R are represented primarily through one type of data, such as user ratings or interaction histories, without incorporating other data sources like image, audio, or video. However, in some cases, textual information $T_{txt}$ is integrated to enhance the representation within this single modality.\n3.1.2 Multi-Modality\nIn multi-modality recommendations, leveraging various types of data-such as text, images, audio, video, and metadata-enhances the recommender system's capability to provide more relevant suggestions. Techniques like graph augmentation and textual information integration are crucial in this context. By enriching user-item interactions and incorporating diverse attributes, these methods tackle issues like sparse feedback and low-quality side information. The use of multimodal large language models (MLLMs) further supports the integration of complex, real-time data sources, such as screenshots of user activities. This approach emphasizes interpretability, robustness, and adaptability across different domains and modalities, ultimately improving the effectiveness of recommender systems.\nDEFINITION 4. Multi-Modality Recommendation. Multi-Modality refers to recommender systems that integrate data from multiple modalities, represented as $D = \\{(R,T_{txt}, I, A, V_{vid}, S,T)\\}$, to provide a richer and more comprehensive representation of both users and items. By combining information from text, image, audio, video, sequence, and timestamp, the system is able to capture diverse aspects of user preferences and item characteristics, leading to more robust and nuanced recommendations.\n3.2 Understanding\nRecommender systems based on large language models leverage external world knowledge and advanced reasoning capabilities. These models can incorporate external knowledge, particularly information specific to users and items like user preferences, item attributes, and behavioral patterns. Furthermore, due to their strong reasoning abilities, LLMs can offer deep insights into user motivations, as well as relationships between users, items, and their broader social context. Consequently, they enable a more profound understanding of the underlying rationale behind recommendations.\n3.2.1 Pre-Recommendation Explanations\nDEFINITION 5. Pre-Recommendation Explanations. This paradigm emphasizes generating explanations for items prior to the recommendation process, offering a clear rationale for why each item is being considered before the final decision is made. It includes (i) utilizing reasoning graphs, (ii) leveraging known relationships between nodes (such as user-item interactions, item similarities, and social connections), (iii) utilizing LLM generates transparent and interpretable intermediate insights through multi-source information extraction and reasoning integration to justify why certain items are considered for recommendation. Let $h_u$ denote the latent representation of user u, and $h_i$the latent representation of item i. Based on this, the system computes a score $s(u, i) = f(h_u, h_i, \\varepsilon_i)$ that incorporates the explanation into the recommendation process:\n$\\varepsilon_i = Explain(h_u, h_i)$\nThe function Explain(\u00b7) generates the explanation before ranking the items, providing insights into why an item is likely a good match.\nIn this context, $f(h_u, h_i, \\varepsilon_i)$ is a function that computes a relevance score by combining the user's latent representation, the item's latent representation, and the explanation $ \\varepsilon_i$, which justifies why a particular item is being considered for recommendation.\n3.2.2 Post-Recommendation Explanations\nDEFINITION 6. Post-Recommendation Explanations. In this paradigm, explanations are provided after the recommendation is made, allowing users to understand why certain items were suggested. Given a set of recommended items $I' = \\{i_1', i_2', ..., i_k'\\}$, the system generates a corresponding set of explanations $E = \\{\\varepsilon_{i_1}, \\varepsilon_{i_2}, ..., \\varepsilon_{i_k} \\}$. Here, $ \\varepsilon_i$ represents the explanation for why item i was included in the recommendations for user u. The challenge lies in ensuring that these explanations are both informative and personalized, aligning with the user's preferences and the specific context of the recommendation. Let s(u, i) denote the relevance score between user u and item i, which reflects how well the item fits the user's preferences. Mathematically, the problem can be expressed as:\n$E = Explain(s(u, i), h_u, h_i)$\n4 SCHEMING AND UTILIZING\nThe emergence of LLMs has introduced a new paradigm in recommender systems, sparking extensive research into how to effectively integrate LLMs into recommendation frameworks. The research in this area can be categorized into Non-Generative LLM-based and Generative LLM-based Approaches, depending on whether the framework requires calculating rating scores for each candidate to determine recommendations.\nDEFINITION 7. Non-Generative LLM-based Recommendation. Non-Generative LLM-based Recommendation is a paradigm that utilizes large language models to enhance traditional recommendation tasks by incorporating the LLMs' understanding of natural language into the recommendation process. Unlike generative approaches, non-generative LLM-based methods do not generate recommendations directly as natural language outputs. Instead, they employ LLMs to improve the accuracy and relevance of the recommendation models, such as by leveraging the semantic understanding embedded in pre-trained language models to enhance ranking, scoring, or feature extraction.\nDEFINITION 8. Generative LLM-based Recommendation. Generative LLM-based Recommendation is a paradigm that leverages large language models to perform recommendation tasks by transforming them into natural language tasks.\nDEFINITION 9. LLM Retraining. LLM Retraining refers to the process of modifying the parameters LLM of a pre-trained large language model to adapt it to a specific recommendation task. This can involve techniques such as fine-tuning, where the LLM's knowledge is aligned with the particular characteristics and data of the recommender system. The goal of retraining is to enhance the personalization, accuracy, and effectiveness of the recommendations by tailoring the LLM's capabilities to the domain-specific requirements of the task. This can be mathematically represented as optimizing a loss function $L(LLM_\\theta; D_{task})$, where $D_{task}$ denotes the dataset specific to the recommendation task.\nDEFINITION 10. LLM Reusing. LLM Reusing involves utilizing a pre-trained large language model without or with only minimal modifications to its parameters. This strategy capitalizes on the LLM's pre-existing capabilities and knowledge, focusing on optimizing how the model is employed within the recommender system. Methods under this category typically involve adapting how the inputs X, outputs \u0177, or intermediate processing stages are handled, without altering the LLM's core parameters $LLM_\\theta$.\n4.1 Non-Generative LLM-based Approaches\nNon-generative approaches typically require calculating the ranking score for each candidate individually to determine the recommendation results. We categorize these non-generative methods into LLM retraining and LLM reusing. LLM retraining involves modifying the parameters of the LLM, whereas LLM reusing requires no or only minimal parameter changes.\nNon-Generative Modeling Process. Formally, the Non-Generative approach can be expressed as:\n$Y = R_{\\phi} (X, Z) = argmax_{z\\in Z} P(z | X)$\n4.1.1 LLM Retraining\nNaive Fine-Tuning.\nInstruction Tuning.\nLow-Rank Adaptation (LoRA).\n4.1.2 LLM Reusing\nDirect Utilizing.\nPrompt Tuning.\nIn-Context Learning (ICL).\n4.2 Generative LLM-based Approaches\nThe Generative approach involves using LLMs to generate new content or recommendations based on the input data. This method is particularly useful in scenarios where novel user interactions or items are required. Formally, let $X = \\{x_1, x_2, ..., x_n \\}$ represent the input data, and let $Y = \\{Y_1, Y_2, ..., Y_m \\}$ represent the generated recommendations. The goal of the Generative approach is to learn a mapping function $G_{\\theta}(\\cdot)$ parameterized by \u03b8, such that:\n$Y = G_{\\theta}(X) = \\{g_{\\theta}(x_1), g_{\\theta}(x_2), ...,g_{\\theta}(x_n) \\}$\nGenerative Modeling Process. Given an input sequence X, the Generative approach can be described as follows:\n$Y = G_{\\theta}(X) = P(y_1, y_2, ..., y_m | x_1, x_2, ..., x_n)$\n4.2.1 LLM Retraining\nNaive Fine-Tuning.\nInstruction Tuning.\nLoRA (Low-Rank Adaptation).\n4.2.2 LLM Reusing\nDirect Utilizing.\nPrompt Tuning.\n4.2.3 Components or Strategies for Generative Recommendation\n5 INDUSTRIAL DEPLOYING\nDeploying LLM-based recommender systems in large-scale industrial settings involves several crucial aspects.\n5.1 Large-Scale Industrial Scenarios\n5.2 Acceleration\n5.3 Cold Start\n5.4 Dynamic Update\n5.5 Business Customization Requirements\n6 CHALLENGES AND OPPORTUNITIES\nThe integration of large language models (LLMs) into recommender systems offer the potential to revolutionize how recommendations are generated, leveraging vast amounts of data and complex contextual understanding to provide users with highly tailored suggestions. However, this evolution comes with its own set of challenges that need careful consideration."}, {"title": "6.1 Calibration", "content": "In LLM-based Generative Recommender Systems, recommendations are generated directly based on user input or context, but the strength of user preferences can vary significantly. For example, one user might have a top 10 list with high preference scores (e.g., 0.9, 0.89), while another's might have much lower scores (e.g., 0.6, 0.2). Although both users receive recommendations they like, the inconsistency in preference strength poses challenges, especially in business scenarios like ad placements or engagement predictions, where precise preference understanding is crucial."}, {"title": "6.2 Temporal Dynamics", "content": "Temporal dynamics enable LLM-based recommender systems to adapt to changing user preferences and behaviors. As interests shift with trends and events, advanced temporal modeling is necessary. Recommendations should balance recent interactions with historical data, employing weighting and decay strategies. Seasonal variations also require contextual adaptation. Strategies like time-aware embeddings, temporal attention mechanisms, and real-time data processing enhance personalization and deliver timely, relevant recommendations, boosting user satisfaction and engagement."}, {"title": "6.3 Scalability", "content": "Scalability in LLM-based recommender systems enables efficient handling of increasing data volumes and user interactions. Horizontal scalability expands capacity through additional servers and load balancing (e.g., Apache Spark, Kubernetes), while vertical scalability enhances server performance. Architectural scalability employs modular designs and containerization (e.g., Docker) for flexible deployment. Data scalability utilizes NoSQL databases and distributed file systems (e.g., Apache Hadoop) to manage large datasets."}, {"title": "6.4 Efficiency", "content": "Efficiency in LLM-based recommender systems involves optimizing performance while managing computational resources and costs. Computational Efficiency focuses on reducing latency and improving responsiveness by optimizing model architectures and using hardware accelerators such as GPUs or TPUs. Operational Efficiency involves resource and cost management through strategies such as workload distribution and cost-effective infrastructure (e.g., cloud computing). Energy Efficiency addresses the environmental impact by employing techniques such as model compression and quantization."}, {"title": "6.5 Multimodal Recommendation Scenarios", "content": "LLM-based multimodal recommender systems enhance personalization by integrating diverse data types, such as text, images, audio, and video. By leveraging LLMs, these systems achieve a comprehensive understanding of user preferences, improving the relevance and accuracy of recommendations. For example, in e-commerce, combining product descriptions, images, and"}, {"title": "6.6 User Privacy and Data Security", "content": "LLM-based recommender systems require extensive user data for personalization, necessitating strong security measures. Compliance with data protection regulations involves transparent practices, explicit user consent, and user control over personal data. Techniques like anonymization and encryption safeguard personally identifiable information (PII) during storage and transmission."}, {"title": "6.7 Interactivity and Feedback Loop", "content": "Interactivity and feedback loops enhance user engagement in LLM-based recommender systems. Users can actively adjust settings and customize preferences, tailoring their experiences. Feedback loops capture user input to refine algorithms and adapt recommendations to changing preferences, fostering trust. Key strategies include customizable settings, intuitive interfaces, real-time personalization, structured feedback integration, and engagement incentives."}, {"title": "6.8 Ethics", "content": "Ethics in LLM-based recommender systems ensure fair, transparent, and responsible operation. Transparency through explainable AI (XAI) helps users understand recommendations. Compliance with standards like GDPR protects privacy and data security. Fairness involves auditing biases and using diverse datasets to prevent discrimination."}, {"title": "6.9 Fairness", "content": "Fairness in LLM-based recommender systems ensures equal treatment across user groups and addresses biases related to race, gender, and age. LLMs must provide equitable recommendations by analyzing and mitigating biases. Systems should avoid favoring popular content to prevent biased exposure."}, {"title": "7 CONCLUSION", "content": "This paper presents a comprehensive review that not only delineates recent advances in the field, but also discusses the challenges faced by LLM-based recommender systems. Specifically, a novel taxonomy is introduced, which provides a structured approach to understanding the integration of LLMs in recommender systems and their deployment in industry. This taxonomy is organized into a three-tier framework that encapsulates the progression from theoretical research to practical application."}]}