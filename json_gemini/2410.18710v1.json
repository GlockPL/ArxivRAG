{"title": "Uncovering the Genetic Basis of Glioblastoma Heterogeneity through Multimodal Analysis of Whole Slide Images and RNA Sequencing Data", "authors": ["Ahmad Berjaoui", "Eduardo Hugo Sanchez", "Louis Roussel", "Elizabeth Cohen-Jonathan Moyal"], "abstract": "Glioblastoma is a highly aggressive form of brain cancer characterized by rapid progression and poor prognosis. Despite advances in treatment, the underlying genetic mechanisms driving this aggressiveness remain poorly understood. In this study, we employed multimodal deep learning approaches to investigate glioblastoma heterogeneity using joint image/RNA-seq analysis. Our results reveal novel genes associated with glioblastoma. By leveraging a combination of whole-slide images and RNA-seq, as well as introducing novel methods to encode RNA-seq data, we identified specific genetic profiles that may explain different patterns of glioblastoma progression. These findings provide new insights into the genetic mechanisms underlying glioblastoma heterogeneity and highlight potential targets for therapeutic intervention.", "sections": [{"title": "1. Introduction", "content": "Glioblastoma (GB) is the most aggressive primary brain tumor and is not curable [1] despite of treatment associating surgery when possible followed by radio-chemotherapy [2] and more recently Tumor treating Fields [3] leading to a median overall survival (OS) of 20.9 months and a progression free survival (PFS) around 7 months. Despite being a minor population of cancer cells, the cancer stem cells that are identified in glioblastoma (GSCs) are thought to be the major driving force behind glioblastoma biological heterogeneity and are likely to explain the high rates of glioblastoma recurrence. In the STEMRI clinical trial aiming to study GB heterogeneity and the enrichment of GSC in certain areas defined by multimodal MRI (NCT01872221) [4] different GSC sub-populations extracted from tumor samples obtained by multimodal MRI guided surgery were xenografted into mice brain to study their invasion patterns as well as their aggressiveness. RNA-seq on each tumor bulk samples was also performed. The observed differences in mice survival according to the GSC implanted confirm the heterogeneous nature of tumor cells lineage.\nIn this study, we set out to determine potential genetic markers associated with glioblastoma aggressiveness using multimodal deep learning. Our results reveal genetic targets already identified in medical literature but also highlight new potential targets. We leverage the extensive recent developments in multimodal data analysis, namely image and text, and adapt these techniques to whole slide images (WSI) and RNA-seq data. Training uses public data from The Cancer Genome Atlas (TCGA) [5] but also WSI and RNA-seq data from the STEMRI trial. Furthermore, we introduce a new RNA-seq encoding technique where genes are grouped based on biological pathways prior to encoding and show better performance in comparison to mere position based grouping.\nOverall, our results can be used to test new GB treatment strategies. Our main contributions can be summarized as follows:\ni Identify genetic profiles leading to unique GB patterns.\nii Novel method to encode RNA-seq data for use in deep learning models.\niii Novel method to combine WSI and RNA-seq data for use in deep learning models.\nThis paper is structured as follows. Section 2 details the developed algorithms, the datasets and training strategies. Section 3 showcases our experimental results followed by our main findings."}, {"title": "2. Material and methods", "content": ""}, {"title": "2.1. Datasets", "content": "Two datasets are used to train our models. The TCGA public dataset is used to pre-train RNA-seq encoders. This dataset contains around 10k RNA-Seq gene expression samples from multiple sites (breast, brain, prostate, bladder, etc.).\n51 RNA-seq samples from the STEMRI trial complete this data. These correspond to 16 patients and bulk tumor RNA from metabolically heterogeneous regions identified by spectral MRI, as explained in [4]. This corresponds to 51 different tumor cell lineages. To insure data homogeneity, only genes common to both STEMRI and TCGA were kept. Genes expressions with relatively low variance were also removed and all data was then normalized. Tumor cells from these 51 different lineages were xenografted onto mice brains. Cells from the same lineage were used onto more than one mouse whenever possible, as culture was not always successful. This led to a total of 116 mice. Whole slide images of mice brain slices were used at x10 magnification factor (fig.2) after each mouse's death. These images are in average composed of 16k x 21k RGB pixels and human tumor cells are highlighted using specific coloration.\nObservation data contains patient OS and PFS and mouse survival time in days."}, {"title": "2.2. RNA-seq encoding", "content": "RNA-seq data is a vector representing protein expressions for roughly 19K protein coding genes. Moreover, attention-based encoders are currently state-of-the-art for vision [6] and language [7]. Combining these two observations, we leveraged the Protein-to-Protein interaction (PPI) graph [8] to regroup protein scores before computing attention scores. The PPI graph is a directed graph and [9] propose a clustering algorithm that considers the directed nature of PPI.\nThe reader can refer to [9] for more detail about the directed Louvain algorithm but in brief, the aim is to maximize modularity [10] $Q_d$ which in the case of a directed graph, can be defined by:\n$Q_d = \\frac{1}{m}\\sum_{i,j}[A_{ij} - \\frac{d^{out}_i d^{in}_j}{m}]\\delta(c_i, c_j)$"}, {"title": "2.3. WSI encoding", "content": "All images are split into sequential, non-overlapping patches of 256x256 RGB pixels, which results in roughly 5K patches per image and a total of 100K patches for the whole dataset. All patches are converted to hue, saturation, luminance, space (HSL). HSL conversion makes it easier to distinguish non-tumor and tumor cells (colored in brown). Patches with a majority of tumor cells can hence be easily extracted by computing an overall pixel score, by counting pixels that respect a given hue interval, regardless of lighting conditions. Patches can then be sorted based on that score, which correlates with their tumor cells content. Only those with a brown colored pixel ratio exceeding 20% are kept for training.\nTraining a masked autoencoder for tumor patches would require a very high computational cost due to the size of the WSI dataset. We therefore rely solely on contrastive learning as our experiments have proved that it was enough to achieve very good performance. A 256x256 patch is split into smaller 16x16 sub-patches and we use a ViT [6] transformer encoder to obtain a global representation of the patch, using the cls token. This representation serves then as an anchor in a triplet loss[13]: the anchor (zi) is matched with"}, {"title": "2.4. Multimodal training", "content": "Both the RNA and the WSI encoders are pre-trained using eq.5 and eq.6. In order to consider both modalities, we draw inspiration from ALBEF[14].\nA multimodal contrastive loss LMM is used to align the modalities' representations before a cross-attention encoder. For a given RNA vector and a 256x256 WSI patch, let uk and u be the cls representations at the output of their respective encoders, after linear projection to a common embedding size. Order is irrelevant as the following equations treat ur and u symmetrically. We use a similar pairwise loss as in eq.4, considering a pair of RNA/WSI representations uk and u, a temperature \u03c4\u060e and batch size N:\n$l_k = -y(k, k') \\log \\frac{exp(u_k u'_k/\\tau_c)}{\\sum_{j=1}^N exp(u_k u'_j/\\tau_c)}$"}, {"title": "2.5. Evaluation", "content": "Training the multimodal model leads to aligned WSI and RNA-seq representations. Given a WSI patch not used during training, it becomes possible to retrieve the closest RNA-seq vector amongst all the 51 RNA-seq vectors by measuring its cosine similarity, as shown in fig.4\nThe main evaluation criteria is therefore matching accuracy, computed over a subset of WSI patches (from a total of 100K patches) not used during training but that are drawn evenly amongst corresponding cell lineages and patients. Let I = {1..51} be the set of all the 51 RNA-seq samples, zwsi be the output of the image encoder for a given WSI patch, and ui be the output"}, {"title": "3. Experiments", "content": "RNA-encoding. After pre-training the RNA-seq encoder depicted in \u00a72.2 using TCGA data, we plotted the t-SNE two dimensional projections for both TCGA data and STEMRI data (fig.5). Nearly all STEMRI data points lie very close to TCGA data points corresponding to brain tumors.\nRNA retrieval. Table.1 lists RNA-seq retrieval accuracy considering tumor cell lineage and patient of origin. The best results are obtained using pathway based clustering as explained in \u00a72.2, and using only a matching loss (without a RNA decoder and a reconstruction loss). Results show a near perfect accuracy for both patient and cell lineage matching tasks. This indicates that our model has learned unique genetic features that can be matched against unique cellular microscopic patterns."}, {"title": "Genetic analysis", "content": "Grad-CAM [15] is a common technique to analyse deep neural networks\u2019response. We used grad-CAM to determine genetic positions that have the greatest contribution in the WSI/RNA-seq matching process. For each WSI in the validation set, we sort gene expressions according to their importance as computed using grad-CAM. Keeping the 15 most occurring gene expressions leads to the results in table.2. The highlighted genes have already been identified in literature as playing an important role in the occurrence or development of glioblastoma [16, 17, 18, 19, 20] (most of them playing a role in metabolism, micro-environment and invasion), other brain cancer types [21] and cancer in general [22, 23, 24, 25, 26, 27, 28]."}, {"title": "4. Conclusion", "content": "In conclusion, our study demonstrates the effectiveness of multimodal deep learning approaches in identifying genetic profiles that explain different glioblastoma patterns. By leveraging joint image/RNA-seq analysis and introducing novel methods to encode RNA-seq data, we have shed new light on the heterogeneous nature of this aggressive brain tumor. Our findings not only confirm existing medical literature but also highlight new potential targets for therapeutic intervention. These results have significant implications for the development of personalized medicine strategies for glioblastoma patients and underscore the importance of continued research into the application of AI algorithms in cancer biology."}]}