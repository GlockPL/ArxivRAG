{"title": "Towards Robust ESG Analysis Against Greenwashing Risks:\nAspect-Action Analysis with Cross-Category Generalization", "authors": ["Keane Ong", "Rui Mao", "Deeksha Varshney", "Erik Cambria", "Gianmarco Mengaldo"], "abstract": "Sustainability reports are key for evaluating\ncompanies' environmental, social and gover-\nnance (ESG) performance, but their content is\nincreasingly obscured by greenwashing - sus-\ntainability claims that are misleading, exag-\ngerated, and fabricated. Yet, existing NLP\napproaches for ESG analysis lack robustness\nagainst greenwashing risks, often extracting in-\nsights that reflect misleading or exaggerated\nsustainability claims rather than objective ESG\nperformance. To bridge this gap, we introduce\nA3CG - Aspect-Action Analysis with Cross-\nCategory Generalization, as a novel dataset to\nimprove the robustness of ESG analysis amid\nthe prevalence of greenwashing. By explic-\nitly linking sustainability aspects with their\nassociated actions, A3CG facilitates a more\nfine-grained and transparent evaluation of sus-\ntainability claims, ensuring that insights are\ngrounded in verifiable actions rather than vague\nor misleading rhetoric. Additionally, A3CG\nemphasizes cross-category generalization. This\nensures robust model performance in aspect-\naction analysis even when companies change\ntheir reports to selectively favor certain sustain-\nability areas. Through experiments on A3CG,\nwe analyze state-of-the-art supervised models\nand LLMs, uncovering their limitations and\noutlining key directions for future research.", "sections": [{"title": "1 Introduction", "content": "Sustainability reports have become an important\nmechanism for evaluating a company's environ-\nmental, social, and governance (ESG) perfor-\nmance (Nguyen, 2020). However, the rise of green-\nwashing - the practice of providing misleading, ex-\naggerated, and fabricated sustainability claims\nhas undermined the credibility of sustainability re-\nports (Ong et al., 2024). By obscuring the eval-\nuation of a company's ESG performance, green-\nwashing hinders meaningful progress toward sus-\ntainability goals (Rajesh, 2020).\n*Correspondence to: mpegim@nus.edu.sgYet, existing NLP methods for ESG analysis\n- i.e. topic analysis (Ong et al., 2025), retrieval-\naugmented generation (RAG) (Zou et al., 2025),\nfail to account for greenwashing risks. These ap-\nproaches aim to provide actionable insights from\nsustainability reports, but fail to account for the\ncredibility of the claims within them. Therefore,\nthe insights extracted by these NLP methods can of-\nten reflect vague and misleading rhetoric instead of\ngenuine sustainability initiatives (Ong et al., 2024).\nTo tackle this, we propose A3CG\nAspect-Action Analysis with Cross-Category\nGeneralization, a novel dataset for robust ESG\nanalysis amid the prevalence of greenwashing.\nA3CG provides a foundation for systematically\nextracting two interconnected components from\nsustainability texts: i) Aspect: The sustainability-\nrelated entity, goal, or activity discussed (i.e.\n\u201ccarbon emissions reduction\u201d). ii) Action: The\ntype of engagement related to the aspect, \"imple-\nmented\", \"planning\u201d, or \u201cindeterminate\u201d. While\n\"implemented\u201d and \u201cplanning\u201d indicate concrete\nsteps taken or planned toward the sustainability\naspect, \"indeterminate\u201d highlights vague, evasive\nor non-attributable claims which may be linked\nwith greenwashing (Siano et al., 2017). By\nenabling the identification of sustainability aspects\nand their action assessments, A3CG allows models"}, {"title": "2 Related Work", "content": "to clarify genuine sustainability initiatives from\nambiguous or misleading rhetoric. While A3CG is\nnot designed for definitive greenwashing detection,\nit facilitates clear and transparent ESG analysis\nthat is less susceptible to greenwashing risks.\nTo further enhance the robustness of ESG anal-\nysis, A3CG extends aspect-action analysis to a\ncross-category generalization setting. This en-\nsures that aspect-action analysis remains effective\neven when companies change their report con-\ntent to selectively favor certain sustainability ar-\neas (Darnall et al., 2022). By emphasizing the\nextraction of aspect-action pairs from sustainability\ncategories beyond those seen in training, A3CG\nfacilitates aspect-action analysis on new, previ-\nously unencountered sustainability themes. As a\nresult, aspect-action analysis remains robust in dis-\ntinguishing genuine sustainability initiatives from\nrhetoric, even with changes in report content.\nNLP Methods in Sustainability Analysis. To au-\ntomate the extraction of insights from sustainability\nreports, popular NLP approaches include analyz-\ning topic occurrence (Ong et al., 2025), sentiment\nanalysis (Song et al., 2018), and RAG (Zou et al.,\n2025). Yet, these traditional NLP approaches do\nnot consider how greenwashing might distort ex-\ntracted insights (Ong et al., 2024). To promote the\ntransparency of sustainability claims, Stammbach\net al. (2022) studied environmental claim detection,"}, {"title": "3 Dataset Construction", "content": "and Ni et al. (2023) assessed report conformance\nto TCFD guidelines. However, these works do\nnot explicitly address building robust ESG analysis\nagainst greenwashing risks.\nAspect-Based Sentiment Analysis. Aspect-Based\nSentiment Analysis (ABSA) has become a popu-\nlar NLP problem over the past decade (Du et al.,\n2023; Ong et al., 2023). Yet, ABSA has focused on\nreviews and opinion mining (He et al., 2023), de-\nspite calls for aspect-level analysis to be extended\nto other contexts (Chebolu et al., 2023). Our study\npresents the first adaptation of aspect-level analy-\nsis to the aspect-action classification task. While\nwe focus on sustainability, aspect-action analysis\ncould potentially be adapted for other applications\n- i.e. government policy analysis (Howlett, 2015).\nCross-Generalization Studies. Cross-domain gen-\neralization has become an increasingly important\nchallenge in NLP (Wang et al., 2022). However,\nthere has been limited investigation on how mod-\nels perform on unseen categories within the same\ndomain - i.e. cross-category generalization. Yet,\nthis deserves attention because intra-domain data\nshifts are distinct from cross-domain shifts, and\ncan significantly degrade model performance (Sub-\nbaswamy et al., 2021). Moreover, data annotation\nfor unseen categories is expensive and impractical,\nas these categories often arise unexpectedly from\nevolving text content (Bai et al., 2024).\nLLMs Biases in Sustainability Analysis. Given\nLLMs' reasoning capabilities (Wei et al., 2022a),\nthey have increasingly been utilized for tasks within\nsustainability analysis, such as knowledge base\nconstruction (Ong et al., 2025), RAG (Zou et al.,\n2025), among others. However, their performance\non domain-specific tasks can be impacted by pre-\ntraining biases (Dai et al., 2024; Yang et al., 2024b),\nand the impact of these biases on sustainability\nanalysis tasks remains under-explored.\nThis section describes A3CG's\u00b9 construction."}, {"title": "3.1 Data Collection & Quality Control", "content": "We collect sustainability statements from 1679 sus-\ntainability reports\u00b9 of Singapore Exchange (SGX)\ncompanies, from 2017-2022 inclusive. The reports\nFor full reproducibility, the dataset and all experimental\ncodes will be released after the review process. Company\nnames and the corresponding years of sustainability reports\nwill also be available. Using this information, these public\nreports can be searched and accessed online."}, {"title": "3.2 Annotation Scheme", "content": "are public and can be found online via company\nwebsites. For quality control, we eliminate: (1)\nIncomplete statements (2) Incoherent statements\nwith misspelled words (3) Non-English statements.\nPairs of (aspect, action) are annotated for each sus-\ntainability statement. In a pair, the action charac-\nterizes the company's engagement with the aspect.\nNotably, the aspect's sustainability category is also\nannotated. However, similar to other generalization\nstudies (Xu et al., 2023a), the aspect category is not\na prediction target. Instead, it is utilized to split the\ndataset for cross-category testing. We summarize\nthe aspect and action definitions below:\nAspect: A sustainability aspect is defined as a sig-\nnificant entity, goal, sub-area, activity of a sus-\ntainability category, providing a focal point for an\naction to address or engage with. We focus on as-\npects that belong to the sustainability categories\nin Table 5, and are explicitly found within a state-\nment.\nAction: The type of action taken toward the as-\npect. i) Planning: Indicates that an action has\nbeen planned or a commitment has been made by\na company to address or engage with the aspect to\nadvance its sustainability efforts. ii) Implemented:\nIndicates that an action has already been taken to\naddress or engage with the aspect to advance its\nsustainability efforts. iii) Indeterminate: Indicates\nthat it is unclear from the statement if the company\nintends to address or engage with the aspect to ad-\nvance its sustainability efforts, or how it intends to\ndo so.\nFor i) and ii), \u201caddressing\u201d or \u201cengaging with\" \nan aspect involves incorporating the aspect within\ncompany operations if it is a sustainability activity\nor entity, or advancing the aspect if it is a sus-\ntainability goal or sub-area. On the other hand,\niii) characterizes vague, non-committal and non-\nattributable language. These action labels differ-\nentiate planned commitments from implemented\nactions, while separating them from ambiguous,\nnon-committal claims.\""}, {"title": "3.3 Annotation Process", "content": "The annotation process involves 5 annotators2 and\n3 verifiers\u00b2, all actively engaged in doctoral or post-\ndoctoral research in sustainability. (1) Train &\nTrial: Annotators and verifiers undergo rounds of\n2Detailed annotation instructions, guidelines, definitions,\nsamples, and annotator details can be found in appendix A"}, {"title": "3.4 Dataset Statistics", "content": "trial annotation, with each round comprising 50\nrandom samples. After each round, annotations are\nscrutinized for accuracy and conformance to the\nguidelines, and feedback is provided. The trials oc-\ncur until each person attains a proficiency of at least\n95% correctly labeled samples. (2) Daily Annota-\ntion: After the trials, annotators label the data daily,\nand are instructed to flag samples with uncertain\nannotation. (3) Resolving Disagreements: Every 3\ndays, uncertain annotations are discussed among\nall annotators to reach a decision. In cases where\ncomplete agreement cannot be reached, majority\nvoting is taken. (4) Validation: Every 3 days, 20%\nof annotated data for each annotator (comprising\nsamples that are not flagged with uncertain anno-\ntation) are scrutinized by the verifiers for accuracy\nand conformance to guidelines. When incorrectly\nannotated statements exceed 5%, annotations for\nthe 3-day period are redone.\nA3CG comprises 2004 statements (samples), com-\nparable to standard aspect-level analysis datasets\nRest15 (Pontiki et al., 2015). Table 1 summarizes\nthe dataset. Moreover, A3CG follows standard\naspect-level analysis datasets - Lapt14, Rest14, 15,\n16 (Pontiki et al., 2014, 2015, 2016), by having\na similar proportion of samples (33.2%) without\naspect-action pairs. This adds the challenge of dis-"}, {"title": "4 Experiments", "content": "tinguishing sustainability statements that contain\naspect-action pairs from those that do not, simulat-\ning real-world statements where relevant aspects\nare not always mentioned (Khan et al., 2016).\nFull Dataset\u00b3. As a preliminary step to verify\ndataset stability before evaluating cross-category\ngeneralization, we split the entire dataset into train,\nvalidation, and test sets while keeping a balanced\nratio of aspect categories.\nCross-Category Generalization\u00b3. Different from\nleave-one-domain-out setups in cross-domain gen-\neralization (Xu et al., 2023b), cross-category gener-\nalization requires a distinct approach. Real-world\nsustainability statements are complex (Smeuninx\net al., 2020), and aspects from different categories\ntend to co-occur within the same statement, mak-\ning a leave-one-category-out strategy unrealistic.\nTherefore, we split the dataset into three equal folds.\nIn each fold, samples are assigned to the training,\nvalidation, or test set based on the aspect categories\nthey contain. 3-4 categories are excluded from the\ntraining and validation sets, forming the unseen\n(US) test set. Models are evaluated on the US test\nset to analyze their capacity for cross-category gen-\neralization. A control seen (S) test set is also con-\nstructed, comprising categories that overlap with\nthose in the training set, but with entirely different\nsamples. To ensure proper evaluation, no training\nor validation sample appears in any test set. The set\nof excluded categories for each fold is chosen con-\nsidering their tendency to co-occur in a statement\nand varies across folds with no overlap, enabling\nbalanced evaluation on different unseen categories."}, {"title": "4.1 Experimental Setups", "content": "Vanilla Models\u00b3: Popular models for aspect analy-\nsis are utilized, encompassing generative - T5 (Raf-\nfel et al., 2023), and sequence tagging - BERT\nSequence Tagging, BERT-ST (Mao and Li, 2021).\nVanilla + Learning Paradigm\u00b3: Contrastive learn-\ning (CL) and adversarial learning (AL) are applied\nto vanilla models - T5+CL, T5+AL, BERT-ST+CL,\nBERT-ST+AL. CL uses the supervised contrastive\nloss for pre-training (Li et al., 2021): $L^{UP} =$\\n$\\sum_{i\\in I}[\\frac{1}{\\mid P(i)\\mid}\\sum_{p\\in P(i)} -log \\frac{exp(z_i \\cdot z_p/T)}{\\sum_{a \\in N(i)} exp(z_i\\cdot z_a/T)} ]$. In\nbatch I, index i represents the anchor sample.\n\u00b3Appendix C details all experimental setups and model\nimplementations, including hyperparameter study for AL."}, {"title": "4.2 Models", "content": "$P(i) = {p \\in I : p \\neq i}$ is the set of indices\nof all positives distinct from i (samples with the\nsame category label as the anchor; a sample's cat-\negory label is determined by the categories of its\ncontained aspect(s)). $N(i) = {n \\in I : n \\notin P(i)}$\nis the set of indices of all negatives (samples not\nsharing any category label with the anchor). Fol-\nlowing Ganin and Lempitsky (2015), AL focuses\non learning category-invariant features. A category\ndiscriminator is added to the encoder to predict\nthe categories of a sample, with a gradient reversal\nlayer to reverse the discriminator loss gradients.\nSOTA-ABSA\u00b3: We adapt SOTA-ABSA models for\nA3CG. InstructABSA (Scaria et al., 2023), IT-RER-\nABSA (Zheng et al., 2024), GRACE (Luo et al.,\n2020), CONTRASTE (Mukherjee et al., 2023).\nLarge Language Models\u00b3: The latest LLMs\n(zero-shot and few-shot) are evaluated. GPT-\n40 (OpenAI, 2024), Claude 3.5 Sonnet (Huang\net al., 2024b), Llama 3 (70B) (AI@Meta, 2024),\nDeepSeek V3 (Liu et al., 2024)."}, {"title": "5 Results & Discussion", "content": "From Table 2, model evaluation on the full dataset\nindicates the dataset's stability, with supervised\nmodels (T5, T5+CL, CONTRASTE) achieving\nover 70% F1. In the following, we focus on\nA3CG's core objective: aspect-action analysis\n(AAA) - the extraction of aspect-action pairs in\na cross-category generalization setup. Therefore,\nwe primarily discuss performance on unseen (US)\ncategories. Performance on sub-tasks of AAA is\nalso analyzed: aspect term extraction (ATE) for\nidentifying aspects, and action classification (AC)\nfor classifying action labels after correctly identify-\ning aspects (AC excludes no-aspect cases)."}, {"title": "5.1 Comparison of Model Types", "content": "Supervised models can perform better than\nLLMs on unseen categories, with GRACE achiev-\ning the highest average F1 score on unseen cate-\ngories (US Avg 47.51) compared to LLMs, from\nTable 2. As shown in Figure 3, supervised models\ngenerally outperform LLMs in AAA on unseen cat-\negories, except for T5, BERT-ST, BERT-ST+CL,\nBERT-ST+AL. This suggests that while LLMs per-\nform well on a broad range of tasks, supervised\nfine-tuning is generally better at capturing task-\nspecific patterns within A3CG. Thus, supervised\nfine-tuning remains essential for optimal perfor-\nmance on A3CG."}, {"title": "5.2 A3CG Challenges for Supervised Models", "content": "While supervised models have higher absolute\nperformance than LLMs, they show significant\ninefficiency at transferring performance from\nseen to unseen categories. For supervised models,\nthe difference between average F1 scores on seen\nand unseen categories, \u2206, is significant - greater\nthan 14% in magnitude except BERT-ST+AL (\u2206=-\n6.95%), from Table 2. This represents a substantial\ndrop in performance when transferring learned pat-\nterns from seen to unseen categories, underscoring\nthe weak generalization efficiency of learned fea-\ntures. Consequently, supervised models must im-\nprove the generalizability efficiency of their learned\nfeatures, to enhance cross-category generalization.\nSpecific LLMs can still perform competitively\non unseen categories. Despite being generally out-\nperformed by supervised models, specific LLMs\nachieve competitive average F1 scores on unseen\ncategories, narrowing the performance gap. From\nFigure 3, Claude 3.5 Sonnet+FS (42.03) outper-\nforms several supervised models - T5 (41.12),\nBERT-ST (26.06), BERT-ST+CL (37.93), BERT-\nST+AL (26.24), while lagging behind IT-RER-\nABSA (43.26), T5+AL (42.82) by less than 1.5%.\nTherefore, while supervised learning provides op-\ntimal performance, its superiority is not absolute -\nspecific LLMs can still present viable alternatives\nto full-scale supervised fine-tuning, particularly in\nlow-resource scenarios.\nAction classification is more challenging than\naspect term extraction for all methods. From\nFigure 3, AC F1 scores are markedly lower than"}, {"title": "5.3 Comparison of Learning Paradigms for\nSupervised Models", "content": "ATE on unseen categories across all methods. This\nis potentially because while both subtasks involve\nsemantic, syntactic and pragmatic reasoning, AC\nplaces greater emphasis on interpreting complex\nsyntax and pragmatics an issue explored later.\nHence, AC is particularly challenging for super-\nvised and LLM approaches. Therefore, given the\nconsiderable difficulty and lower performance, tar-\ngeted model improvements for AC could drive sig-\nnificant gains in the overall performance of AAA.\nPopular methods for cross-domain generalization,\nadversarial learning (AL) and contrastive learning\n(CL), are evaluated on cross-category generaliza-\ntion within A3CG. From Figure 4(a), compared to\nvanilla T5 and BERT-ST baselines, although AL\nstill enhances generalization performance (+1.70\nfor T5+AL; +0.18 for BERT+AL), CL yields rel-\natively higher F1 improvements on unseen cate-\ngories (+2.87 for T5+CL; +11.87 for BERT+CL),\naveraged across all folds.\nThe generalization effectiveness of CL could\nbe attributed to the models' ability to learn robust\nsemantic features (category distinctions) that are\ntransferable across categories (Khosla et al., 2020).\nIn a case study, the feature embeddings of samples\nfrom different unseen categories exhibit more dis-\ntinct clustering for Figure 4(c) T5+CL, compared\nto 4(b) T5 Vanilla, which shows greater overlap.\nThis suggests that CL allows the model to capture\nsemantic distinctions between unseen categories,\nreducing category overlap and ambiguity. There-\nfore, instead of spurious correlations, the model\nrelies more on robust semantic features unique to\neach category, improving unseen category general-\nization (Izmailov et al., 2022).\nIn contrast, AL focuses on learning category-\ninvariant features induced by feature collapse to\npromote generalization (Tang and Jia, 2020). From\nFigure 6(d) T5+AL, features from samples of un-\nseen categories appear less discriminable and more\nentangled, particularly along the y-axis, compared"}, {"title": "5.4 Comparison of LLM performance", "content": "to 6(b) T5 Vanilla. However, by collapsing fea-\ntures for invariance, AL may inadvertently suppress\ndomain-specific feature attributes that are relevant\nfor identifying aspects of unseen categories. Hence,\nthough AL increases generalization performance,\nit yields lower improvements than CL.\nThis presents a key consideration for supervised\ntraining techniques in A3CG: although AL is still\nbeneficial, CL can be a more effective strategy for\nunseen category generalization.\nLLMs with higher reasoning capabilities per-\nform better on A3CG. From Table 2, Claude 3.5\nSonnet+FS and DeepSeek V3 yield the highest av-\nerage F1 on unseen categories among LLMs (US\nAvg 42.03 & 41.08 respectively). This aligns with\ntheir superior performance over the other LLMs\nGPT-40 and Llama 3 (70B) on general reason-\ning benchmarks (Liu et al., 2024; Dubey et al.,\n2024). This suggests that A3CG goes beyond naive\ntext classification to require structured reasoning.\nTherefore, selecting LLMs with higher reasoning\ncapabilities can optimize performance on A3CG.\nFew-shot improves performance on nearly all\nLLMs except DeepSeek V3. From Figure 3, the\naddition of few-shot examples to LLMs generally\nimproves their F1 performance on AAA for un-\nseen categories. This suggests that LLMs tend to\ngeneralize better to unseen categories through in-\ncontext learning (Dong et al., 2024). Yet, including\nfew-shot examples for DeepSeek V3 unexpectedly\ndegrades model performance. Preliminary stud-\nies on a related model - DeepSeek R1 (Guo et al.,\n2025) highlight its over-reliance and failure to gen-\neralize from examples (Parmar and Govindarajulu,\n2025). Yet, these studies may only have limited\napplicability to DeepSeek V3, warranting further"}, {"title": "5.5 A3CG Challenges for LLMs", "content": "investigation. Therefore, to optimize performance\non A3CG, few-shot examples can be provided for\nLLMs such as GPT-40, Claude 3.5 Sonnet, Llama 3\n(70B). In contrast, DeepSeek V3 unexpectedly per-\nforms better in zero-shot, underscoring the need\nfor further studies into its few-shot capabilities.\nLLMs generally exhibit higher recall toward as-\npects of environmental categories, potentially\ndue to pre-training biases. Figure 5 shows that\nATE recall on all environmental categories (re-\nsource optimization, emissions control, ecological\nconservation) tend to exceed the median ATE re-\ncall of non-environmental categories, frequently\nsurpassing their upper quartile. This suggests that\nLLMs capture environmental aspects more effec-\ntively than non-environmental ones, potentially due\nto popularity biases in their pre-training (Dai et al.,\n2024). Since LLMs are pre-trained on large-scale\nuser-generated data, their learned distributions are\noften influenced by the popularity of specific top-\nics - in this case, the prominent association of\nsustainability with environmental protection over\nnon-environmental areas (i.e. social and gover-\nnance) (Ruggerio, 2021). Consequently, LLMs\nmay end up disproportionately favoring environ-\nmental aspects for ATE while under-representing\nnon-environmental sustainability aspects. However,\nwhile our findings highlight this possibility, further\nresearch is needed to assess how much these bi-\nases contribute to the recall skew. Therefore, to\nmitigate this imbalance for improved performance,\nmethods such as bias-aware re-ranking (Carraro\nand Bridge, 2024) can be employed to balance the\nselection of non-environmental aspects, although\ndeeper investigation into the causes of the recall\nskew could enhance mitigation strategies."}, {"title": "6 Conclusion", "content": "In this study, we proposed the A3CG dataset, and\nevaluated SOTA supervised models and LLMs to\nhighlight key directions for research. We invite\nresearchers to unlock AI's potential for robust ESG\nanalysis, by developing models tailored to A3CG."}, {"title": "Limitations", "content": "The A3CG dataset focuses on sustainability state-\nments and reports that are solely in the English\nlanguage. However, we acknowledge that corpo-\nrate sustainability is a global responsibility that\ncan encompass many different countries and re-\ngions. Therefore, for greater inclusivity, future\nwork will focus on extending A3CG to non-English\nlanguages."}, {"title": "Ethical Considerations", "content": "Procedures for data collection were approved by\nan internal ethics review board within our research\ngroup. Additionally, we adhere to ethical princi-\nples by ensuring that all data collection and pro-\ncessing are performed with respect for privacy and\nconfidentiality. We use publicly available sustain-\nability disclosures from respective company web-\nsites. Considering that these disclosures may con-\ntain company and personal names, we make efforts\nto anonymize sensitive and personal information\nin the A3CG dataset, focusing solely on the sus-\ntainability content relevant to our research. Addi-\ntionally, the models utilized are publicly available,\nfound from published research papers. Our usage\nof all data, packages and models adheres to the\ncopyright guidelines provided by the respective\ncopyright holders. Human annotators follow strict\nguidelines to maintain objectivity and reduce bias.\nWe also ensure transparency in our methodology\nand provide clear attribution for our sources, aim-\ning to support ethical practices in data usage and\ndissemination. The dataset and experimental code\nused in this study will be made publicly available\nupon acceptance, for the sole purpose of facilitating\nresearch, accompanied by appropriate copyright\nprovisions."}, {"title": "C.4 Ablation Study for Adversarial Setups", "content": "${\\bigtriangledown}_\\theta L =  L_{task} - \\alpha L_{adv}$ (1)\nIn this study, the implementation of adversarial\nlearning methods (T5+AL, BERT-ST+AL) follows\nfrom (Ganin and Lempitsky, 2015), where the ob-\njective is for the encoder to learn category-invariant\nfeatures. First, a category discriminator is added\nto the encoder to predict the categories present in\na given sample. Then, a gradient reversal layer is\nadded to reverse the gradients resultant from the dis-\ncriminator loss. We summarize this in equation (1)\nwhere $L_{adv}$ represents the discriminator loss, and\n\u03b1 represents the gradient scaling factor which con-\ntrols the strength of the adversarial signal. The total\nloss L combines the task loss $L_{task}$ with a scaled\n$L_{adv}$, to ensure that the encoder learns category-\ninvariant representations while balancing the learn-\ning of the primary task. Following from (Ganin and\nLempitsky, 2015), \u03b1 controls the trade-off between\nthe primary task objective and the adversarial ob-\njective (learning category-invariant features).\nSince the main results of this study focus on\nthe performance on unseen categories, tuning \u03b1\non the validation set (comprising seen categories)\nwould not necessarily optimize performance on\nthe unseen test set (comprising unseen categories).\nTherefore, we selected a default \u03b1 value of 0.3 for\nall adversarial setups (T5+AL, BERT-ST+AL). \u03a4\u03bf\nvalidate the robustness of this choice, we observe\nhow varying \u03b1 impacts F1 for BERT-ST and T5 on\nthe unseen test set. We examine \u03b1 \u2208 {0.01, 0.05,"}, {"title": "C.5 Error Analysis Examples", "content": "All error examples discussed in the main text are\noutlined in tables 12 and 13"}, {"title": "C.6 Results Breakdown", "content": "The detailed results breakdown for all methods\ncorresponding to each subtask of A3CG is found\nin Table 14."}]}