{"title": "Beyond Yes or No: Predictive Compliance Monitoring Approaches for Quantifying the Magnitude of Compliance Violations", "authors": ["Qian Chen", "Stefanie Rinderle-Ma", "Lijie Wen"], "abstract": "Most existing process compliance monitoring approaches detect compliance violations in an ex post manner. Only predicate prediction focuses on predicting them. However, predicate prediction provides a binary yes/no notion of compliance, lacking the ability to measure to which extent an ongoing process instance deviates from the desired state as specified in constraints. Here, being able to quantify the magnitude of violation would provide organizations with deeper insights into their operational performance, enabling informed decision making to reduce or mitigate the risk of non-compliance. Thus, we propose two predictive compliance monitoring approaches to close this research gap. The first approach reformulates the binary classification problem as a hybrid task that considers both classification and regression, while the second employs a multi-task learning method to explicitly predict the compliance status and the magnitude of violation for deviant cases simultaneously. In this work, we focus on temporal constraints as they are significant in almost any application domain, e.g., health care. The evaluation on synthetic and real-world event logs demonstrates that our approaches are capable of quantifying the magnitude of violations while maintaining comparable performance for compliance predictions achieved by state-of-the-art approaches.", "sections": [{"title": "1 Introduction", "content": "Process compliance is a pivotal component in information systems research [1] and focuses on ensuring that processes adhere to compliance constraints that are imposed on them. Compliance constraints may stem from legislative and regulatory documents, standards and codes of practice, and business rules or contracts [10], might change frequently (e.g., financial regulations change every 12 minutes\u00b3), and non-compliance might result in the risk of reputational and financial loss and even criminal penalties [7].\nSeveral surveys on challenges in compliance management in (process-aware) information systems exist, e.g., [1,15,16,21]. A first dimension of challenges arises from the process life cycle phase when compliance verification is supposed to take place, i.e., design time, runtime and ex post. Compliance by design [25] verifies the compliance of a process model with the set of compliance constraints. During runtime, ongoing process instances which are generated from the process model are monitored to detect or even predict compliance violations (i.e., compliance monitoring) [15]. Afterwards, the set of executed traces (an event log) are compared to a relevant process model to assess their conformity (i.e., conformance checking) [4]. Despite the importance of design and ex post compliance checking, (predictive) compliance monitoring enables business organizations to proactively detect and manage possible compliance violations during process execution [15]. However, only few existing approaches target the prediction of violations. Hence, in this work, we focus on the sub-field of compliance monitoring, i.e., predictive compliance monitoring (PCM) [21].\nAnother challenge is the lack of sufficient ability to quantify the degree of compliance defined as a compliance monitoring functionality (CMF10) in [15]. To predict compliance violations at runtime, most approaches [9, 17, 27] offer binary yes/no notions of compliance. Outcome-oriented predictive process monitoring [24] and predicate prediction [17] aim to classify each running case based on a predefined set of categorical outcomes, e.g., will an order be delivered on time (desired outcome) or not (undesired outcome)? However, these approaches lack the ability to quantify the extent to which an ongoing process case will deviate from the desired state. The ability to quantify the magnitude of violation is crucial, particularly for prescriptive process monitoring techniques. These techniques aim to recommend or prescribe actions to prevent undesired outcomes by minimizing a cost function of interventions. Such cost function considers factors like the probability of an undesired outcome occurring, the cost of executing interventions, and the timing of those interventions (i.e., their mitigation effectiveness) [8]. Including the magnitude of violation as a key factor in the cost function is essential, as severe deviations may require more substantial and costly interventions compared to mild ones. In addition, quantifying the magnitude of violation supports process participants in making risk-informed decisions to reduce the likelihood or severity of process faults [6]. For instance, severe violations can be prioritized for intervention to mitigate their impact, while cases with mild extent of violation may be addressed first, as they are often easier and less costly to resolve compared to severe ones.\nTo address these challenges, we propose two PCM approaches which extend existing predicate prediction methods with the ability to quantify the magnitude of violations. Here, the magnitude of violation corresponds to the degree of compliance [15] as utilized in literature. The hybrid approach reformulates the binary classification problem into a regression task, implicitly preserving the nature of"}, {"title": "2 Problem Statement", "content": "We illustrate the problem based on an Order-to-Cash (O2C) process (cf. Fig. 1) as the running example. The process is triggered when a purchase order (PO) is received. An associated temporal constraint t is introduced into the process model that imposes a maximum temporal distance of 24 hours between tasks ship goods and confirm order.\nTo predict compliance states of running cases w.r.t. the associated temporal constraint Ot, existing predicate prediction approaches [9, 17, 27] classify them either into satisfaction or violation via a binary classifier. Consider the event log that has been derived from the running example in Fig. 2. Predicate prediction approaches [17] or outcome-oriented predictive process monitoring (outcome-oriented PPM) [24] first assign a boolean outcome to every case in the log according to t, i.e., positive if the case violated ot or negative if it satisfied with t. The binary classifier is then trained based on the labeled event log and applied to evolving event streams, aiming to predict which of the running case will and will not violate t."}, {"title": "3 Approach", "content": "Existing predicate prediction approaches [9,17,24, 27] focus on predicting compliance violations in a binary yes/no notion of compliance. Hence, they lack the capability to quantify the magnitudes of violations for deviant cases. By contrast, simply framing the problem as a regression task to predict the extent of deviation which can be either positive or negative signaling satisfied or violated cases cannot emphasize violation predictions. To address this research gap we combine the prediction of the occurrence of compliance violations (classification) with predicting their magnitude (regression) for ongoing cases. To this end, we propose hybrid and multi-task learning (MTL) approaches. We first introduce the pipeline of existing predicate prediction approaches to describe the procedure for compliance predictions. The proposed approaches are presented afterwards."}, {"title": "3.1 Predicate Prediction Pipeline", "content": "Figure 3 shows the pipeline of the state-of-the-art methods for compliance prediction. The first step is to label each case in the event log based on the associate constraint, and prefixes are generated and filtered based on the different requirements, e.g, only include prefixes up to a maximum length. Next, all retained prefixes can be divided into several buckets based on the length of prefixes or various clustering algorithms, and different classifiers are then trained for each such buckets. If all prefixes are considered into the same bucket, then a single classifier is trained based on all prefixes. For prefixes in each bucket, we apply different encoding techniques for attributes of the event within the trace. The most common approach is to one-hot encode categorical variables and apply normalization to numerical attributes. Finally, the predictive model is trained based on the encoded feature vectors and applied to an ongoing case to determine whether it's compliant or not. In the following, we focus on the most critical steps-case labeling and model training-as highlighted in Fig. 3, since these steps represent the key distinctions between conventional predicate prediction approaches and our proposed methods.\nCase Labeling is conducted for each case in the event log based on the corresponding temporal compliance constraint. An event log L := {01,...,\u03c3\u03ba} comprises a set of completed traces oi where oi := (C1, C2, ..., Cen) is defined as a sequence of events ej. The prefix hdk(oi) := (e1, 2, ..., ek) is defined as a partial trace of \u03c3\u2081 where k \u2264 |oi|. An event ej, in turn, is defined as a tuple (a, c, t, d1, ..., dm) where a is an activity type, c is the case id, t is the timestamp of execution, and d\u2081,.., dm are other attributes of this event. A temporal constraint t specifies both the control-flow and temporal requirements each process execution must comply with. The control-flow patterns specify the occurrences or ordering of activities, such as existence and eventually follows relations. Time patterns, on the other hand, impose restrictions on the (e.g., minimum or maximum) temporal distance between the execution of activities.\nThe labeling function for each case w.r.t. the associated constraint Ot is defined as follows:\n$Y_{binary} (\u03c3)=\\begin{cases} deviant \\rightarrow 1 & \\text{if} \\tau \\text{violated in } \\sigma \\\\normal \\rightarrow 0 & \\text{otherwise} \\end{cases}$\nSpecifically, for a given temporal constraint Ot, a case is labeled as deviant (encoded as 1) if it violates the constraint; otherwise, it is labeled as normal (encoded as 0). Consider the running example as introduced in Sect. 2 with 6t:"}, {"title": "3.2 Hybrid Approach", "content": "In order to predict the compliance of running cases and to further assess the degree of such violations, a pure classification or regression method is not capable of achieving both goals. Thus, we present a hybrid approach which is inspired by [11] in grid distribution networks. It targets at predicting the occurrence of grid constraint violations as well as the amplitude of such violation, aiming to identify and prevent grid constraint violations for the stable and efficient operation of systems.\nCase Labeling in this approach is different from the conventional predicate prediction methods as introduced in Sect. 3.1. We follow up on the idea from [11] to assign the magnitude of violation for each case in the log, extending the binary classification problem by incorporating regression to capture the degree of violations. In particular, the hybrid approach assigns a positive value to deviant cases to reflect the magnitude of violation, while normal cases are consistently"}, {"title": "3.3 Multi-task Learning", "content": "The multi-task learning (MTL) approach is particularly suited to our problem as it allows the model to jointly learn compliance prediction (binary classification) and magnitude quantification (regression). Both tasks are closely related: the classification task identifies whether a case is compliant or deviant, while the regression task quantifies the magnitude of violation for deviant cases. By sharing knowledge across tasks, MTL exploits their interdependence, enabling the model to learn richer feature representations that improve both tasks. By doing so, this framework provides both a high-level understanding of compliance and detailed insights into the magnitude of violations, enhancing overall predictive performance. Thus, the MTL approach incorporates both the predicate prediction approach (cf. Sect. 3.1) and the hybrid technique (cf. Sect. 3. 2) to predict compliance states and the magnitude of violation simultaneously.\nCase Labeling for MTL approach combines labeling functions from predicate prediction (ybinary) and hybrid approach (yhybrid) to assign labels and the magnitude of violations for each case, resulting in a labeled event log with both label and magnitude columns as shown in Fig. 4. Thus, the integrated labeling"}, {"title": "4 Evaluation", "content": "In this section, we demonstrate the efficacy of our proposed approaches by comparing them with the conventional binary predicate prediction approach (baseline). We employ the XGBoost classifier as one of the predictive models, as it has been shown to outperform other traditional machine learning models in the benchmark study of outcome-oriented PPM approaches [24]. Additionally, we incorporate a deep learning based predictive model the Attention-based Bidi-rectional LSTM Neural Network (Att-Bi-LSTM) as the second baseline due to"}, {"title": "4.1 Experimental Setup", "content": "All experiments are conducted on a synthetic data set and two real-life event logs with temporal constraints involved.\nDatasets. The synthetic data set o2c is generated from the Order-to-Cash process (cf. Fig. 1) using the Cloud Process Execution Engine (CPEE) [18]. For real-life event logs, the sepsis event log 5 records patient pathways in a hospital for sepsis treatment, and bpic2012w 6 deals with a sub-process (work item) within a loan application procedure.\nTable 1 presents the characteristics of all datasets, and the corresponding temporal constraints are presented as follows:\no2c_1: \"Goods must be shipped no later than 24 hours after order confirmation.\"\nsepsis_1: \"Patients should be administered antibiotics within one hour after ER Sepsis Triage\"\nsepsis_2: \"Lactic Acid measurements should be performed within three hours from ER Sepsis Triage.\"\nbpic2012w_1: \"A scheduled validation should start within 2 days.\"\nbpic2012w_2: \"The validation must be done in at most 20 minutes.\"\nMetrics. For the binary compliance prediction task, we choose area under the ROC curve (AUC) instead of the most commonly used metric accuracy, because it remains unbiased even on imbalanced datasets and is threshold-independent"}, {"title": "4.2 Data Preprocessing and Model Adaptation", "content": "All event logs are first labeled based on the corresponding labeling function as introduced in Sect. 3. For each dataset, we remove incomplete cases and include all attributes available in the event log as input features. In addition, time-related features, such as month, weekday and hour, are extracted based on the timestamp attribute as we also target at quantifying the magnitude of temporal violations. All traces are cut before the relevant events derived from the temporal constraint happen to allow early predictions, i.e., cut traces exactly before the corresponding class labels are known and irreversible. In this work, we do not consider the multiple occurrences of constraint-related events, thus, traces cutting can be applied even to cases with eventually follows relation involved. We keep the 80%-20% train-test-split ratio for model training and evaluation. Prefixes are extracted from the labeled event log and filtered based on a predefined maximum prefix length. For each dataset, the maximum prefix length is determined as the case length corresponding to the 90th percentile of positive cases as adopted in [24]. For our experiments, we train the predictive model based on all retained prefixes, namely prefixes are not divided into several buckets.\nFor data preprocessing, the main difference between XGBoost and Att-Bi-LSTM lies in how events are encoded. For XGBoost, the optimal encoding technique is aggregation: categorical attributes are represented by their frequency of occurrences, while numerical attributes are denoted with the mean and standard deviation [24]. By contrast, Att-Bi-LSTM uses one-hot encoding for categorical features and applies normalization to numerical values [26].\nModel Adaptation. Traditional machine learning models do not support model adaptation. Therefore, for XGBoost, we modify only the loss function as described in Sect. 3, based on the corresponding approach. As for deep learning"}, {"title": "4.3 Results", "content": "We report experimental results with XGBoost (cf. Tab. 2) and Att-Bi-LSTM (cf. Tab. 3) to assess the performance of compliance prediction (AUC) and magnitude quantification (MAE in days).\nXGBoost. For traditional machine learning models, such as XGBoost (cf. Tab. 2) in this study, our proposed approaches outperform the baseline in predict-"}, {"title": "5 Related Work", "content": "In this section, we analyze related work on predicting compliance states of ongoing process instances and quantifying the degree of compliance w.r.t. a given set of compliance constraints.\nCompliance Prediction. [19] classify predictive process monitoring (PPM) approaches into process-aware and non-process-aware approaches, both employing regression and classification methods to predict attributes in the future, such as next activity, next time, or the outcome of the case. As part of PPM, outcome-oriented PPM [23,24] and predicate prediction [9, 17] focus on compliance predictions of ongoing instances regarding a given set of constraints; the binary yes or no answer w.r.t. compliance is not sufficient for compliance management and requires the ability to quantify the degree of compliance.\nCompliance Degree. [14] calculate a compliance distance to indicate the degree of match between the process model and the set of control rules at design time. They define control rules into four distinct classes according to the ideal semantics: ideal, sub-ideal, non-compliant and irrelevant states. [13] classify cases into full-, partial- and non-compliance and formulate a framework to detect and evaluate the degree of violations after process executions. However, the user-defined piece-wise mapping function cannot distinguish the extent of violations in a fine-grained manner. In [20], a compliance scale model is created to measure the degree of compliance of completed process instances. Still, the mechanisms of c-semirings to classify process instances into < Good, Bad > or < 0, .5,1 > are not accurate enough. [22] define a set of key performance indicators (KPIs) for each compliance rule and map the evaluation values of them to a compliance level from -100 to 100 taking into account values of target, threshold and worst. However, existing approaches provide various metrics for compliance degrees in different phases of process life cycle, but none of them target compliance prediction."}, {"title": "6 Conclusion", "content": "This work proposes two predictive compliance monitoring approaches that extend state-of-the-art binary predicate prediction methods by enabling the quantification of violation magnitudes for ongoing process executions. The hybrid approach reformulates the binary classification problem into a regression task, focusing on quantifying violations in deviant cases, which implicitly aligns with the binary classification objective. By contrast, the multi-task learning (MTL) approach explicitly incorporates both compliance prediction and magnitude quantification tasks. This design is reasonable because these two tasks are closely related, and learning them together allows for feature sharing between tasks.\nThe evaluation demonstrates that our approaches\u2014particularly the multi-task learning method-outperform existing predicate prediction methods in magnitude quantification while maintaining comparable performance in compliance prediction. The performance of both tasks improves when MTL leverages deep learning models, owing to the flexibility in adapting model architectures to better capture task-specific features. The ability to quantify the magnitude of violations is crucial in compliance monitoring, as it provides organizations with deeper insights into their operational performance and enables informed decision-makings to reduce or mitigate the risks of non-compliance.\nHowever, our approaches have limitations. The performance of the hybrid approach is highly sensitive to data distribution, i.e., performing poorly on skewed datasets. This limitation is primarily due to the case labeling function applied to deviant cases, where the relevant event may not even occur. In future work, we aim to investigate methods for assigning the magnitudes of violation to deviant cases that breach temporal constraints in the control-flow dimension. Additionally, we plan to explore techniques to adapt the multi-task model architecture further, such as dynamically weighting each task's loss [12], to improve overall performance."}]}