{"title": "REVISITING NETWORK PERTURBATION FOR SEMI-SUPERVISED\nSEMANTIC SEGMENTATION", "authors": ["Sien Li", "Ruizhe Hu", "Tao Wang", "Wenxi Liu"], "abstract": "In semi-supervised semantic segmentation (SSS), weak-to-strong consistency regularization tech-\nniques are widely utilized in recent works, typically combined with input-level and feature-level\nperturbations. However, the integration between weak-to-strong consistency regularization and\nnetwork perturbation has been relatively rare. We note several problems with existing network\nperturbations in SSS that may contribute to this phenomenon. By revisiting network perturbations, we\nintroduce a new approach for network perturbation to expand the existing weak-to-strong consistency\nregularization for unlabeled data. Additionally, we present a volatile learning process for labeled\ndata, which is uncommon in existing research. Building upon previous work that includes input-level\nand feature-level perturbations, we present MLPMatch (Multi-Level-Perturbation Match), an easy-to-\nimplement and efficient framework for semi-supervised semantic segmentation. MLPMatch has been\nvalidated on the Pascal VOC and Cityscapes datasets, achieving state-of-the-art performance.", "sections": [{"title": "Introduction", "content": "Semantic segmentation has been a long-standing and fundamental problem in computer vision, and recent years\nwitnessed significant performance improvements because of the impressive ability of deep neural networks to capture\nlong-range and high-order interactions among local features [19, 33, 2, 28]. One of the key challenges in semantic\nsegmentation, however, is that the task requires a laborious and time-consuming manual labeling process on large\ndatasets for models to learn well. Unlike image annotation, image acquisition is comparatively easier, prompting\nthe rise of Semi-supervised Semantic Segmentation (SSS). This method aims to train segmentation models using\nlimited labeled data and a large pool of unlabeled data, garnering considerable interest in recent times. In terms of\nthe paradigms proposed for SSS, mainstream methods have evolved from GAN-based adversarial training [23] to\nself-training-based [32, 27] and the widely-adopted consistency regularization framework [21, 7, 3, 37]. In particular,\nweak-to-strong consistency regularization expects a model to make consistent predictions on strongly perturbed and"}, {"title": "Related Work", "content": ""}, {"title": "Semi-supervised Semantic Segmentation", "content": "In recent years, semi-supervised semantic segmentation has made remarkable progress, with a variety of new methods\nemerging, such as: semi-supervised contrastive learning methods [29], segmentation prediction based on prototypes [36],\ntraining methods based on heterogeneous frameworks like CNN and ViT [11], and so on. In particular, most mainstream\napproaches currently utilize a combination of pseudo-labeling techniques and consistency regularization in training,\nand their presence can be found in the methods mentioned above. In terms of pseudo-labeling techniques, the family of\nmethods based on confidence threshold filtering proposed in FixMatch [22] and its variants is widely embraced for\nits simplicity and effectiveness. In terms of consistency regularization, weak perturbations at the input level such as\nflipping and resizing, as well as strong perturbations like blurring and grayscale adjustments, are commonly used in\nSSS training [32, 35, 34, 31, 24, 27, 26]. Moreover, perturbations at the feature level, such as random channel dropout,\nare also extensively utilized.\nMany recent works have delved deeper into this domain. For instance, iMas [34] considers the instance's difficulty for\nvarying degrees of perturbation at the input level, while AugSeg [35] expands the repertoire of input-level perturbations\nand proposes intensity-based variations. Furthermore, UniMatch [31] integrates both input-level and feature-level\nperturbations. In contrast, this work primarily explores network perturbations that are less conventional in SSS."}, {"title": "Network Perturbation", "content": "In terms of existing SSS methods with network perturbation, CPS [4] exemplifies network perturbation by training two\nnetworks with differing initializations to enforce consistency between their predictions. CPS primarily benefits from\nusing predictions of another dissimilar subnet as supervisory signals, enhancing its ability to mitigate inherent cognitive\nbiases. However, unlike input and feature-level perturbations, these methods may struggle to extract diverse features\nfrom the same image due to the inherent homogeneity of the two networks, which is crucial for enforcing consistency\nconstraints. To address this issue, our work focuses on exploring network perturbations tailored for integration with\nconsistency regularization, aiming to unlock their potential in SSS."}, {"title": "Our Approach", "content": "In this section, we describe the proposed MLPMatch framework in detail. Specifically, we first present a brief\nintroduction to the semi-supervised semantic segmentation (SSS) task. This is followed by detailed descriptions of our\napproach for both unlabeled and labeled images."}, {"title": "Preliminaries", "content": "In semi-supervised semantic segmentation, we are given a small set of labeled images $D_x = \\{(x_i, y_i)\\}_{i=1}^{M_x}$, where\n$x_i \\in X$ and $y_i \\in Y$ are the i-th image and the corresponding pixelwise ground-truth label, and $M_x$ is the number\nof images in the set of labeled images. In addition, we have a large set of unlabeled images $D_u = \\{(u_i)\\}_{i=1}^{M_u}$, where\n$u_i \\in X$ is the i-th unlabeled image, and $M_u$ is the number of images in the set of unlabeled images. Our goal is to train\na segmentation model $R$ that maps any input image to the label space, i.e., $R : X \\rightarrow Y$. In our work, $X = \\mathbb{R}^{H \\times W \\times 3}$\nindicates that both labeled images and unlabeled images have a spatial dimension of $H \\times W$ and 3 channels. And\n$Y = C^{H \\times W}$ are the spatial dimension of both ground-truth labels and pseudo-labels, where $C = \\{1 . . . C\\}$ is the set of\n$C$ classes.\nTypically, $R$ includes an encoder $F(\\cdot)$ to obtain a latent feature representation $z_i \\in \\mathbb{R}^{\\hat{H} \\times \\hat{W} \\times D}$ from $x_i$ or $u_i$, and a\ndecoder $G(\\cdot)$ to further convert $z_i$ into $p_i \\in \\mathbb{R}^{H \\times W \\times C}$.\nGiven a labeled image $x_i$ and its corresponding ground-truth $y_i$, the cross-entropy loss $L_x$ is calculated between the\nprediction under the weakly perturbed input view $A_w(x_i)$ and $y_i$. Loss $L_x$ can be written as:\n$L_x = \\frac{1}{M_x} \\sum_{i=1}^{M_x} \\frac{1}{H \\times W} \\sum_{j=1}^{H \\times W} L_{ce} (p_{ij}(A_w(x_i)), y_{ij}) \\tag{1}$\nwhere $p_{ij}(\\cdot)$ and $y_{ij}$ refer to the prediction and the ground-truth label of the i-th image at the j-th site, respectively. For\nunlabeled images $u_i$, the predictions from $A_w(u_i)$ will be used as pseudo-labels $y^\\prime$ through an argmax operation and a\nhigh-confidence threshold filtering for predictions with strong perturbations. The consistency regularization at the input\nlevel is applied between predictions of unlabeled images with weak input-level perturbations and unlabeled images with\nstrong input-level perturbations. Additionally, our baseline method applies two random strong input-level perturbations,\n$A_{s1}$ and $A_{s2}$, to the unlabeled data and calculates $L_{s1}$ and $L_{s2}$. For brevity, we combine them into $L_s$ as:\n$L = \\frac{1}{2M_u} \\sum_{i=1}^{M_u} \\frac{1}{H \\times W} \\sum_{j=1}^{H \\times W} L_{ce} (p_{ij}(A_{s1/s2}(u_i)), y^\\prime_{uij} )\\cdot M_i \\tag{2}$\nwhere $M_i$ is a binary mask that is set to 1 when $p_{ij}(A_w (u_i)) > \\tau$, and 0 otherwise.\nBesides, our baseline method performs consistency regularization with feature-level perturbation $A_{fp}$. Specifically,\nchannel-wise dropout is applied to $F(A_w(u_i))$ with $y^\\prime$ as the supervision. So the corresponding loss term $L_{fp}$ is\nwritten as:\n$C_{fp} = \\frac{1}{M_u} \\sum_{i=1}^{M_u} \\frac{1}{H \\times W} \\sum_{j=1}^{H \\times W} L_{ce} (p_{ij}(A_{FP}(u_i)), y^\\prime_{uij} ) \\cdot M_i \\tag{3}$"}, {"title": "Weak-to-strong consistency based on network perturbation", "content": "As already discussed, recent work [35, 31, 34, 22] uses the weak-to-strong consistency to force the decision boundary\nof a model to be located in areas with low sample density. However, most works are limited to the input-level and\nfeature-level perturbations. In this paper, we introduce Network Perturbation (NP) to form a weak version of the encoder\n$A$ from the original $F$. More specifically, the convolutional forward of bottlenecks will be deactivated randomly to\nform $A$ from $F$, as shown in Fig. 3.\nBased on the idea that over-strong perturbations negatively impact model performance [31], we limit only one bottleneck\nlayer in the entire $A$ to execute NP. Though $A$ and $F$, we can obtain diverse feature representations from the same\nimage. We then perform weak-to-strong consistency between $G(A(u_i))$ and $G(F(u_i))$. Specifically, the weak-to-strong\nconsistency loss can be written as:\n$C_{np} = \\frac{1}{M_u} \\sum_{i=1}^{M_u} \\frac{1}{H \\times W} \\sum_{j=1}^{H \\times W} L_{ce} (p_{ij}(A (u_i)), y^\\prime_{ij} ) \\cdot M_i \\tag{4}$\nHere, $p_{ij}$ represents the prediction of $u_{ij}$ using the encoder $A$."}, {"title": "A volatile learning process for labeled data", "content": "Recent work [22] has introduced a high-confidence threshold (e.g., 0.95) to filter noise in pseudo-labels. This implies\nthat in the early stages of training, when few pseudo-labels pass the filtering process, the model relies primarily on\nlabeled data. In the scenario of semi-supervised training, the limited labeled data cannot cover the diversity in data\ndistribution within different classes. As a result, this means that we risk fitting the labeled data to a much greater extent\nthan fitting the unlabeled data. Additionally, the over-confidence phenomenon further results in incorrect pseudo-labels\npassing through the filtering process and contributing to training. To address this issue, we propose a strategy of\nperturbing supervised learning data, which is uncommon in previous work. We refer to this practice as volatile learning\nand expect that this \"volatility\" can alleviate the impact of fitting labeled data far ahead of fitting unlabeled data.\nSpecifically, we utilize both $A$ and $F$ to fit labeled data, instead of using $F$ alone. And the loss of volatile learning $C_{np}$\ncan be written as:\n$C_{np} = \\frac{1}{M_x} \\sum_{i=1}^{M_x} \\frac{1}{H \\times W} \\sum_{j=1}^{H \\times W} L_{ce} (p_{ij}(A (x_i)), y_{ij} ) \\tag{5}$\nIn addition, the difference in fitting progress between labeled and unlabeled data mentioned above intensifies as training\nprogresses, so we set the relative weight of this loss term to a simple linear growth to reflect this trend."}, {"title": "Our Holistic Framework: MLPMatch", "content": "In summary, we utilize network perturbations on both labeled data and unlabeled data to enhance model performance.\nFrom Fig. 2, we can clearly see the comparisons between our baseline methods and MLPMatch. The total loss of\nMLPMatch can be written as:\n$L_{total} = (\\lambda_x - \\lambda^{np})L_x + \\lambda^{np} C^{np} + \\lambda L + \\lambda_l^{fp} C^{fp} + \\lambda_l C^{np} \\tag{6}$\nFollowing our baseline, $\\lambda_x$ is set to 0.5, and we set $\\lambda_l^{fp}$ and $\\lambda_l$ to 0.25 to maintain consistent loss weights between\nlabeled and unlabeled data. $\\lambda^{np}$ is a linear increasing value starting from 0. In addition, we conduct experiments with\ndifferent $\\lambda^{np}$ in the experiments section."}, {"title": "Experiments", "content": "In this section, we first introduce our experimental settings. Next, we compare our method with recent state-of-the-art\n(SOTA) methods in SSS. In particular, it should be noted that our method did not introduce any modifications during\nmodel inference, as compared to the baseline methods."}, {"title": "Experimental Setup", "content": "Datasets. We conduct experiments on two widely used datasets, Pascal VOC 2012 [6] and Cityscapes [5], to demonstrate\nthe efficacy of MLPMatch. Pascal VOC provides a semantic segmentation task with 21 classes including the background\nclass. This dataset contains 1464 high-quality annotated images and 1449 validation images. Following [4, 32, 25],\n9118 additional coarsely-labeled images from the SBD dataset [8] have been added to the dataset. Ultimately, this\nresulted in a training set comprising 10582 images. Cityscapes [5] is an urban-oriented dataset consisting of 19 classes,\nwith 2975 finely annotated training images and 500 validation images.\nTraining. To compare fairly with previous works, extensive comparative experiments and ablation studies were\nconducted on the two datasets based on the DeeplabV3+ [2] model with ResNet-50 [9] or ResNet-101 backbone."}, {"title": "Comparison with SOTAS", "content": "Pascal VOC 2012. In Tab. 1 and Tab. 2, we compare MLPMatch with recent SOTAs. It is evident that our approach\nsignificantly outperforms other methods when the quantity of labeled data is small (e.g., 92, 183, 366 partition protocols).\nTab. 3 provides a detailed demonstration of the performance improvements brought by our method under different\npartition protocols.\nCityscapes. In Tab. 4, we evaluate our method on the more challenging Cityscapes dataset, using ResNet-50 as the\nencoder. Compared to recent SOTA methods including UniMatch, iMas, and AugSeg, MLPMatch outperforms all\nmethods under the 1/30 and 1/16 partition protocols. In particular, MLPMatch surpasses our baseline UniMatch by\n2.0% under the 1/32 partition protocol."}, {"title": "Ablations studies", "content": "In this section, we perform a series of ablation studies on the Pascal VOC dataset.\nEffectiveness of each component. From Tab. 3, we can observe the efficacy of each component of MLPMatch.\nSpecifically, the sequential addition of $L_{vp}$ and $C^{np}$ gradually improves model performance, with our complete method\nproviding the best mIoU."}, {"title": "Conclusion", "content": "In this paper, we present MLPMatch, an easy-to-implement and efficient framework for SSS. A key advantage of our\nmethod is its effectiveness and strong generalization. Compared to existing network perturbation methods in SSS, our\napproach can be seamlessly integrated with other weak-to-strong consistency regularization approaches to enhance\nmodel generalization. Additionally, we introduce perturbations in the learning process of labeled data, a strategy that\nhas been relatively rare in previous research. MLPMatch achieves state-of-the-art performance on Pascal VOC and\nCityscapes datasets. Furthermore, we validate its generalization and effectiveness in the remote sensing domain."}]}