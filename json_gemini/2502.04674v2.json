{"title": "ADPARAPHRASE: Paraphrase Dataset for Analyzing Linguistic Features toward Generating Attractive Ad Texts", "authors": ["Soichiro Murakami", "Peinan Zhang", "Hidetaka Kamigaito", "Hiroya Takamura", "Manabu Okumura"], "abstract": "Effective linguistic choices that attract potential customers play crucial roles in advertising success. This study aims to explore the linguistic features of ad texts that influence human preferences. Although the creation of attractive ad texts is an active area of research, progress in understanding the specific linguistic features that affect attractiveness is hindered by several obstacles. First, human preferences are complex and influenced by multiple factors, including their content, such as brand names, and their linguistic styles, making analysis challenging. Second, publicly available ad text datasets that include human preferences are lacking, such as ad performance metrics and human feedback, which reflect people's interests. To address these problems, we present ADPARAPHRASE, a paraphrase dataset that contains human preferences for pairs of ad texts that are semantically equivalent but differ in terms of wording and style. This dataset allows for preference analysis that focuses on the differences in linguistic features. Our analysis revealed that ad texts preferred by human judges have higher fluency, longer length, more nouns, and use of bracket symbols. Furthermore, we demonstrate that an ad text-generation model that considers these findings significantly improves the attractiveness of a given text. The dataset is publicly available at: https://github.com/CyberAgentAILab/AdParaphrase.", "sections": [{"title": "1 Introduction", "content": "Online advertising plays a significant role in digital marketing. Advertising aims to attract attention, spark interest, and encourage clicks and purchases for profit. To achieve this, writing an ad text relevant to user interests is essential; however, this alone is not sufficient. Simultaneously, the way an ad text is written, that is, the linguistic expression of the ad text to attract attention, is crucial for the success of advertisements. Effective linguistic choices in ad texts can influence the ease of understanding and appeal to people, potentially leading to successful outcomes, such as improved click-through rates (CTR).\nIn this study, we aim to explore the linguistic features of an ad text that influences human preferences with the goal of maximizing the potential success of advertisements. Many studies have been conducted on the methods for generating attractive ad texts (Hughes et al., 2019; Kamigaito et al., 2021; Wei et al., 2022). However, progress in understanding the linguistic features that affect attractiveness, that is, human preferences, has been hindered by several obstacles. First, human preferences are complex and are influenced by various factors, including linguistic expressions and semantic content (Pryzant et al., 2018; Hu et al., 2023). For instance, when analyzing human preferences for two ad texts with different content and writing styles, such as ad texts (a) and (c) in Figure 1, it is difficult to determine the factors influencing preferences. They can be motivated by content such as place names (e.g., Atami) or writing styles such as uppercase text (e.g., BOOK NOW!). Second, publicly available ad text datasets containing human preference data are lacking (Murakami et al., 2023). Previous studies that analyzed attractive ad texts relied on log data, such as clicks and views, that reflect human preferences (Pryzant et al., 2018; Murakami et al., 2022). However, the datasets they used were proprietary to companies for confidential- ity reasons and were not publicly available. This restricts potential researchers to those with access to such data, hindering research on what makes ads attractive.\nTo explore the linguistic features that affect attractiveness by overcoming the aforementioned obstacles, we present ADPARAPHRASE, a novel paraphrase dataset that contains human preferences for pairs of ad texts that are semantically equivalent but differ in wording and style. We carefully constructed the dataset by collecting semantically similar ad texts, performing paraphrase identification with five judges per pair, and collecting human preference judgments with ten judges per pair, as shown in Figure 1. The dataset allows us to focus on differences in linguistic features between individual ad texts while minimizing the impact of differences in semantic content. Thus, we can analyze human preferences centered on these features.\nThrough a statistical analysis of the human preferences collected in our dataset, we found that an ad text that is more fluent, longer in length, contains more nouns, and uses bracket symbols tends to be preferred by most human judges. Based on the findings of this analysis, we explored various methods for generating more attractive ad texts in terms of their linguistic styles. In the experiments, we found that more attractive ad texts could be generated by considering our findings and preference judgments as few-shot examples; however, room for improvement still exists. We believe that our dataset will advance the understanding of linguistic features that influence human preferences in advertisements."}, {"title": "2 Construction of ADPARAPHRASE", "content": "We constructed ADPARAPHRASE, a paraphrase dataset of ad texts, to examine the influence of linguistic variations on human preferences. This dataset allowed us to collect and analyze human preferences by focusing on the linguistic differences between ad texts. Our two-step dataset construction process involves the collection of paraphrase candidates (\u00a72.1) and manual annotation for paraphrase identification (\u00a72.2)."}, {"title": "2.1 Collecting Paraphrase Candidates", "content": "ADPARAPHRASE was constructed based on two publicly available Japanese ad text datasets, Ad Similarity (Zhang et al., 2024) and CAMERA (Mita et al., 2024). We employed different strategies, as outlined below, to collect paraphrase candidates from the datasets based on their distinct formats. Table 1 summarizes the breakdown of the paraphrase candidates. We obtained a total of 1,238 candidates.\nAd Similarity Ad Similarity is a dataset that includes 6,332 pairs of ad texts rated on a five-point scale by three human evaluators. Higher scores indicate greater similarity between pairs, and vice versa. To collect the candidates, we set a threshold of four for the similarity score and extracted 1,088 pairs. However, we found that several extracted pairs contained different named entities such as date and price. To address this issue, we applied regular expression rules, removed 382 pairs, and finally obtained 706 candidate pairs.\nCAMERA CAMERA is a benchmark dataset for ad text generation (ATG) tasks, in which an ad text is generated from user queries and source documents. Unlike with Ad Similarity, we created paraphrases from scratch using ad texts in the dataset as the source text. We asked two professional ad writers from an advertising agency to create a paraphrased text from a given source text. We provided two instructions: first, to rephrase its wording and style to enhance attractiveness without adding or deleting any information; and second, to limit the ad text to 15 full-width characters, which is the length limit for advertising delivery platforms such as Google Ads. Owing to time constraints, we requested approximately 100 paraphrases from human experts, resulting in 133 paraphrases. In addition, we used large language models (LLMs) that have shown remarkable paraphrasing capabilities (Cegin et al., 2023) to generate paraphrase"}, {"title": "2.2 Manual Annotation", "content": "For the paraphrase candidates, we conducted a manual annotation for paraphrase identification, which is a binary classification task, to determine whether each pair of ad texts is semantically equivalent (i.e., paraphrase or non-paraphrase). We defined the paraphrasing criteria at the sentence level rather than at the word or phrase level to assess whether the two sentences conveyed the same meaning. Annotation was performed by five workers with extensive experience in in-house advertising production. The gold label was determined by majority votes. For details of paraphrase identification, including quality control measures and the instructions presented to workers, please refer to Appendix B."}, {"title": "2.3 Data Analysis", "content": "The annotation results of the paraphrase identification are summarized in Table 1. Of the 1,238 candidates, 725 were paraphrases, and 513 were non-paraphrases. Ad Similarity yielded 335 paraphrases, whereas human experts and LLMs produced 390 paraphrases. The average length of the ad texts is 7.1 words. The Fleiss' kappa metric among the five workers was 0.462, indicating moderate agreement (Fleiss et al., 1971; Landis and Koch, 1977). Table 2 lists examples of paraphrases and non-paraphrases. Several cases determined to be non-paraphrases were caused by differences in named entities, such as product names.\nTo better understand ADPARAPHRASE, we calculated the Jaccard similarity to measure the lexical overlap between ad text pairs. Figure 2 illustrates the distributions of the metrics for the paraphrases and non-paraphrases. These results confirm that ADPARAPHRASE includes many paraphrases that are lexically different but semantically equivalent."}, {"title": "3 Collection of Human Preferences", "content": "We collected human preferences through human evaluations of the attractiveness of ad texts rather than relying on log data, such as CTR, for two reasons. First, human evaluations of attractiveness are widely used to measure the quality of ad texts in the ATG field (Murakami et al., 2023). Second, previous studies have shown that human attractiveness ratings and their predicted CTR (pCTR) are reasonably consistent, supporting the validity of using human evaluations as a proxy (Mita et al., 2024). Therefore, we expect this approach to serve as an alternative to not releasing such data publicly."}, {"title": "3.1 Evaluation Method", "content": "We used the 725 paraphrase pairs in Table 1 as the evaluation set and performed pairwise comparisons to determine the ad text that was more attractive in each pair. Each pair was evaluated by ten human judges, who are native Japanese speakers, recruited from a crowdsourcing platform. A skip option was provided for judges to use when they found the ad texts equally attractive. Appendix C provides details of the attractiveness evaluation, including the workers and interface of the evaluation tool."}, {"title": "3.2 Quality Control", "content": "Several strategies were introduced to ensure annotation quality. (1) To mitigate position bias in pairwise comparisons, we randomized the order of ad text pairs before presenting them to the judges. (2) Given the subjective nature of attractiveness, we provided clear evaluation criteria based on the"}, {"title": "3.3 Evaluation Results", "content": "Figure 3 shows a histogram of attractiveness evaluations from ten judges for ad text pairs. The x-axis indicates the maximum number of judges who selected the same ad text in a pair. For instance, a value of six indicates that six judges preferred the same ad text, whereas zero indicates that all judges skipped it, suggesting equal attractiveness of the ad text pair. The distribution shows many cases in which five to six judges selected the same ad text, suggesting inconsistent preferences for paraphrased ad texts. The inter-rater agreement measured by Fleiss' kappa was 0.161, indicating a slight agreement.\nNevertheless, it should be noted that in 316 cases, seven or more judges agreed on their preference. In these cases, the inter-rater agreement was 0.307, indicating fair agreement. These findings suggest that linguistic differences between paraphrased ad texts influence the preferences of human judges to a certain extent."}, {"title": "4 Experiments", "content": "According to \u00a73.3, the human preference judgments showed fair agreement in 316 evaluation cases. This raises the following question: What linguistic differences between ad text pairs affect hu-"}, {"title": "4.1 Analyzing Linguistic Features that Influence Human Preferences", "content": ""}, {"title": "4.1.1 Linguistic Features", "content": "An ideal ad text is designed to capture attention and generate interest. Therefore, readability, visibility, and informativeness are key factors in improving the attractiveness of ad texts (Wang and Pomplun, 2012; Murakami et al., 2023). We analyzed various linguistic features from the surface-level, such as text length, to deeper factors, such as lexical choice and emotion. Our feature set consists of four groups: raw text, lexical, syntactic, and stylistic features, including the 24 types listed in Table 3. For the detailed definitions of these features, see Appendix D.\nRaw text features Raw text features, such as text length, are the most basic features of ad text that affect readability and informativeness. We measured word and character counts.\nLexical features Lexical features include word-level features such as the number of content words, lexical choice, and character types. We hypothesized that ad texts with more content words would be more informative and attractive. Regarding lexical choices, we posit that ad texts using common words would be more readable and preferable. To measure this, we calculated the average word frequency of each ad text using the Balanced Corpus of Contemporary Written Japanese (Maekawa et al., 2010) and counted the common and proper nouns. Because ADPARAPHRASE comprises Japanese ad texts, we also included character-type features, such as hiragana counts, which are known to affect readability by helping readers distinguish words more clearly (Sato et al., 2008).\nSyntactic features Syntactic features relate to the structure of the entire ad text or its parts, such as phrases, including the depth of the dependency tree, length of the dependency links, number of noun phrases, and perplexity (PPL).\nStylistic features Stylistic features comprise features related to the wording and style of ad texts, including high-level linguistic features such as emotions (e.g., joy and anticipation) and the specificity of the ad text. We hypothesized that more positive or specific ad texts would be preferred. To determine these features, we used separate classification models for emotion and specificity, which we had constructed (see Appendix D for details). In addition, we used the presence or absence of bracket symbols such as ) or \u300c\u300d as a unique linguistic feature in Japanese ad texts because these brackets are often used to highlight important information for visibility. For instance, in the ad text \u3010Official Site\u3011 ABC Insurance, the brackets highlight the key information."}, {"title": "4.1.2 Analysis Method", "content": "We used the chi-square test of independence to analyze the relationship between the linguistic features and human preferences. This statistical method tests the independence of two categorical variables. In our study, these variables were (1) the ad text selected by the majority of human judges and (2) the ad text scoring value (higher or lower) for each linguistic feature. For example, when examining the impact of PPL on human preferences, we investigated whether ad texts with lower PPL tended to be selected by the majority of the judges.\nTo ensure the reliability of our analysis, we used the 316 (out of 725) pairs of ad texts, in which the choices of more than seven human judges for attractiveness were consistent, as this indicated fair agreement by Fleiss' kappa (Landis and Koch, 1977)."}, {"title": "4.1.3 Results", "content": "Table 3 lists the chi-square test results. Our analysis focused on the differences in features between the two ad texts, considering only the cases in which each feature differed within the pair. Consequently, the number of cases varied for each feature type. For example, the character counts differed in 248 pairs.\nIn Table 3, linguistic features with high chi-square values and low p-values indicate a strong correlation with human preferences. Therefore, the results demonstrate that the ad texts preferred by the majority of human judges exhibit significantly lower PPL, longer character counts, higher frequencies of nouns, more noun phrases, and greater use of bracket symbols (p < 0.01). These findings suggest that to create attractive ad texts, it is crucial to focus on these specific linguistic features.\nHowever, we observed no statistically significant differences in other linguistic features. Several factors may explain these results. We speculated that the complexity of the dependency trees had little impact because of the short length of the ad texts. The quality of emotion labels may be limited by a domain mismatch because the emotion classification model was trained on social media texts, which differ from ad texts. Concerning specificity, because we used paraphrase pairs for attractiveness evaluation, the specificity of the pair differed in a few cases and we could not obtain a sufficient number of cases for analysis. However, a promising result was obtained, in that 10 out of the 11 cases with high specificity were preferred by the majority of human judges."}, {"title": "4.2 Generating Attractive Ad Texts", "content": "To demonstrate the practical application of these findings, we conducted an experiment using ATG. Specifically, we explored methods for generating attractive ad texts based on the findings of our analysis."}, {"title": "4.2.1 Ad Text Generation Methods", "content": "In this experiment, we focused on ad text refinement (Youngmann et al., 2020; Mishra et al., 2020). The goal was to generate more attractive ad text by rephrasing its wording and style without adding or deleting information from the input ad text.\nInspired by the success of integrating human preferences into LLMs, we explored methods for generating attractive ad texts using LLMs. Various methods have emerged for integrating human preferences into LLMs, including reinforcement learning, supervised fine-tuning, and in-context learning (ICL) (Ouyang et al., 2022; Fernandes et al., 2023; Kirk et al., 2023). Owing to limited preference data, we focused on ICL, which is a learning paradigm in which an LLM learns a new task from context, including instructions and input-output demonstrations, and is known for its effectiveness in few-shot settings (Brown et al., 2020).\nWe explored methods for generating more attractive ad texts by learning human preferences using ICL. For instructions, we incorporated the findings of the linguistic features into the prompt. For the demonstrations, we created two types of input-output pairs using the results of attractiveness evaluations: those in which attractiveness improved and those in which it did not. For the former, we selected cases in which the preferences of at least seven out of ten human judges matched, using the less-preferred text as the input and the more-preferred text as the output. For the latter, we selected cases in which no consensus was reached among the judges. These were referred to as positive and negative examples, respectively. Full experimental details, including prompts, are provided in Appendices E and F."}, {"title": "4.2.2 Evaluation Method", "content": "We conducted a human evaluation based on two aspects: paraphrase identification and attractiveness. Specifically, we assessed whether the generated ad texts were semantically equivalent to the input ad texts and which were more attractive, following the same procedures in \u00a72.2 and \u00a73.1."}, {"title": "4.2.3 Results and Discussion", "content": "Table 4 summarizes the results. The success rate for each evaluation task was calculated. For paraphrase identification, the success rate represents the proportion of generated texts labeled as paraphrases by the majority of human judges. For attractiveness, we defined the success rate as the proportion of paraphrased texts found to be more attractive by at least seven out of ten judges. We also calculated the overall success rates for both tasks. The following can be observed from Table 4.\nFindings significantly improved performance Explicitly, incorporating the findings into the instructions (e.g., GPT-4-zeroshot-findings) significantly improved both evaluation tasks compared to the baselines (e.g., GPT-4-zeroshot). We found that directly incorporating these findings into the instructions was straightforward and effective. Further improvements would be possible by identifying other factors that influence preferences.\nNegative examples are also useful Introducing only positive examples as few-shot examples improves the paraphrase identification performance. However, contrary to our expectations, this yielded little improvement in attractiveness. Interestingly, when we introduced negative examples as well, the attractiveness evaluation performance improved significantly. One possible explanation is that negative examples consist of minor edits between the input and output texts compared to positive examples. For example, the average Jaccard similarity between the input and output were 0.560 and 0.602 for the positive and negative examples, respectively. This discrepancy may have influenced the generation model to actively perform editing operations"}, {"title": "5 Analysis", "content": "Through experiments, we explored the linguistic features that influence human preferences and the methods for generating attractive ad texts. Because the primary goal of advertising is to capture users' attention, it is crucial to examine how attractively paraphrasing ad text affects ad performance, such as clicks. To this end, we analyzed the relationship between human preference and pCTR. In addition, we conducted an online evaluation of paraphrased ads in real-world ad-delivery scenarios."}, {"title": "5.1 Relationship between Human Preferences and pCTR", "content": "Table 7 lists the number of cases in which human preferences align with pCTR in the evaluation set. Following Hughes et al. (2019), we used an in-house CTR prediction model. We identified ad texts that were both preferred and had a higher pCTR. Only 355 of the 725 ad texts exhibited this alignment, suggesting a weak correlation between human preference and pCTR. For a detailed analysis, we divided the evaluation data into two groups based on the level of agreement. The high-agreement group, in which more than seven judges preferred the same ad, showed a 54.7% alignment, while the low-agreement group, which included all other cases, showed a 44.5% alignment. This suggests that the ad texts preferred by many judges tend to align with pCTR. Therefore, attractive rephrasing can positively affect pCTR, although to a limited extent."}, {"title": "5.2 Ad Performance via Online Evaluation", "content": "We conducted an online evaluation to verify the extent to which the paraphrasing method (\u00a74.2) affected the ad performance. Specifically, we performed an A/B test to compare the performance of the original ads as a baseline with that of the paraphrased ads. See the link for the glossary of advertising terms. We used Google Ads' search ads as the evaluation platform. For the evaluation data, we used three ad groups from two companies in the human resources (HR) and education industries. Each ad group consists of a maximum of 15"}, {"title": "6 Discussion for Practical Application", "content": "As a potential practical application of this study, the development of a writing assistant tool based on our paraphrasing method could be considered to enhance the attractiveness of input ad texts. In advertising production, there are situations where the advertised content is fixed due to campaign requirements, and only the expression of the ad text needs to be refined. In fact, many tools already exist with the aim of supporting ad production in various ways. Such a writing assistant tool could further improve the wording and style of ad texts, making them more appealing."}, {"title": "7 Related Work", "content": ""}, {"title": "7.1 Generating Attractive Ad Text", "content": "With the increasing demand for online advertising, the manual creation of ad text has reached its capacity limits. Therefore, researchers have focused on ATG (Murakami et al., 2023). The goal of advertising is to attract interest in a product or service and motivate users to take action such as clicking and purchasing. Therefore, generating attractive ads is critical to the success of online advertising.\nVarious methods have been developed to generate attractive ad texts, ranging from template-based approaches (Bartz et al., 2008; Thomaidou et al.,"}, {"title": "7.2 Understanding Attractive Ad Text", "content": "Understanding the factors that affect the attractiveness of ad text is crucial to the success of the ad creation process. Various efforts have been made to analyze the factors influencing the attractiveness of ad texts, such as advertising appeal (Murakami et al., 2022), persuasive tactics (Yuan et al., 2023), and emotions (Youngmann et al., 2020). This study investigates the linguistic features of ad texts that affect their attractiveness.\nA common approach for studying the factors influencing human preferences is to use log data, which measures attractiveness based on clicks and views. However, these log data are often proprietary and not publicly available, hindering research replication and knowledge advancement. Therefore, we collected human preferences through manual evaluations to make the data publicly available.\nIn a study closely related to our work, Pryzant et al. (2018) examined the impact of writing style on ad performance, while controlling for potential confounding variables. However, this study only considered the influence of the brand names and neglected other content-related factors. In our study, we constructed a paraphrase dataset varying in writing style to focus on the linguistic differences between ad texts while mitigating content variations, thereby enabling the analysis of human preferences centered on these linguistic features."}, {"title": "8 Conclusion", "content": "In this paper, we proposed a dataset called ADPARAPHRASE, which comprises semantically equivalent ad pairs, to analyze the linguistic features that influence human preferences. We collected data on human preferences for these ad pairs and demonstrated that factors such as fluency, number of characters, and use of brackets significantly affected the attractiveness of the ad text. In addition, we conducted experiments on ATG, showing that considering human preferences can lead to the generation of attractive ad texts. In future work, we plan to expand our dataset to analyze other attractiveness factors and explore ATG methods."}, {"title": "9 Limitations", "content": "This study had several limitations that should be addressed in future studies.\nDataset size ADPARAPHRASE consists of 1,238 pairs of ad text, including 725 paraphrases. Although the limited size of the dataset has affected the robustness and generalizability of our findings, we ensured reliable results. Unlike many existing studies that use three human judges per pair to evaluate attractiveness, we asked ten human judges per pair to collect more comprehensive preference data. This approach helped mitigate the limitations of dataset size. In future work, we plan to expand the dataset to include a broader range of linguistic features in ad texts, thus further enhancing the depth and applicability of our research.\nLinguistic features In this study, we analyzed a variety of linguistic features, including deep linguistic features that extend beyond surface-level features such as lexical choice and textual specificity. However, other unexplored features such as discourse intent were not considered. Therefore, future studies should consider these additional linguistic features to provide a more comprehensive understanding of the factors that influence human preferences.\nGeneralizability to other languages ADPARAPHRASE consists of Japanese ad texts, and all linguistic features and preference analyses are based on Japanese ad texts. Therefore, please note that some features, such as character types, are unique to the Japanese language, and we do not intend that our analysis results be applicable to all languages. However, we believe that other languages such as English and Chinese also have their unique linguistic features. Multilingualization of a dataset is an important future direction for revealing linguistic features that can be applied to a wide range of languages. In this study, we focused on Japanese ad texts, but we hope that this will pave the way for the"}, {"title": "D Details of Linguistic Features", "content": "This study analyzed a wide range of linguistic features, from surface-level features to deeper factors, including lexical choice and textual specificity. Our feature set consists of four groups: raw text, lexical, syntactic, and stylistic features, including the 24 types of linguistic features listed in Table 3. In the following sections, we explain the definitions and extraction methods for each feature.\nD.1 Raw text features\nText length We calculated the number of words and characters as a measure of text length. We used Sudachi (Takaoka et al., 2018), a Japanese morphological analyzer, to split Japanese texts into words.\nD.2 Lexical features\nContent words We hypothesized that ad texts with more content words would be more informative and attractive. We defined content words as nouns, verbs, adjectives, adjectival nouns, and adverbs and counted their occurrences in each ad text. For morphological analysis of Japanese ad texts, we used Sudachi (Takaoka et al., 2018).\nLexical choice For word frequency, we hypothesized that ad texts containing more common words would be preferred; therefore, we calculated the frequency of words in each ad text. Specifically, we calculated the average frequency of occurrence per million words for each word in the ad text using the Balanced Corpus of Contemporary Written Japanese (Maekawa et al., 2010). Furthermore, to verify whether ad texts containing common or proper nouns were preferred, we used Sudachi to extract these nouns and counted their occurrences.\nCharacter type We counted the numbers of hiragana, katakana, kanji, symbols, and numerals in each Japanese ad text.\nD.3 Syntactic features\nDependency tree We used spaCy with GiNZA to perform the dependency parsing of ad texts. The depth of the dependency tree refers to the longest path from the roots to leaves in the dependency tree. The length of the dependency link refers to the number of words between the syntactic head and its dependent.\nNoun phrases We used spaCy with GiNZA to extract the noun phrases and counted their occurrences.\nPerplexity We calculated the perplexity using GPT-2 (Radford et al., 2019) trained on a web-crawled corpus and the Wikipedia dataset."}, {"title": "D.4 Stylistic features", "content": "Emotion To label the emotion of ad texts, we used the LUKE model (Yamada et al., 2020) trained on WRIME (Kajiwara et al., 2021), which is a Japanese emotion analysis dataset based on social media text. This model is an 8-class classifier that determines the most appropriate emotions from the following eight categories: joy, sadness, anticipation, surprise, anger, fear, disgust, and trust. When we applied the classifier to the ad texts, the majority of cases were labeled as either \u201cjoy\" or \"anticipation,\" so we used only these two labels in our analysis. The accuracy of the classifier was 68.6%.\nTextual specificity Owing to the lack of datasets or existing models for measuring the specificity of Japanese sentences, we created our own specificity classifier using GPT-4 with a few-shot setting. We defined this as a three-class classification problem and constructed a model that compares two ad pairs and judges with higher specificity. If the specificity of both is equivalent, it outputs a label of \"equal.\" To evaluate the performance of the model, we randomly sampled 100 predictions and conducted a manual evaluation, achieving an accuracy of 88.0%.\nBrackets We created a binary label indicating whether the ad text contains bracket symbols \u3010\u3011 or\u300c\u300d."}, {"title": "E Details of Ad Text Generation Experiment", "content": "Figure 9 shows an example of the prompts used in the ATG experiment. Specifically, this prompt was used for GPT-4-fewshot-findings-both in Table 4. In this prompt, we include few-shot examples and the findings revealed from the analysis of linguistic features that influence human preferences. For the few-shot examples, we created two types of examples, where attractiveness improved and where it did not, from the results of the attractiveness evaluation and used 20 examples for each type. We report the results of a single experiment."}, {"title": "F Implementation Details", "content": "Models We used GPT-3.5, GPT-4, and Llama2 to perform the paraphrase candidate generation (\u00a72.1) and an experiment using ATG (\u00a74.2). For GPT-3.5 and GPT-4, we used the Azure OpenAI API service with version 2024-03-01-preview and a default temperature parameter of 1.0. In the case of Llama2, we used the ELYZA-japanese-Llama-2-7b model available via Hugging Face, which enhances Japanese-language capabilities through additional pre-training based on Llama2. See link for the detailed parameters of the Llama2 model.\nTokenizer We used Sudachi (Takaoka et al., 2018), a Japanese morphological analyzer, to tokenize Japanese text into words. Sudachi offers three splitting modes to provide tokens of different granularities for each application purpose: short, medium, and named entities. In this study, we used the named entity mode."}]}