{"title": "GeFL: Model-Agnostic Federated Learning with Generative Models", "authors": ["Honggu Kang", "Seohyeon Cha", "Joonhyuk Kang"], "abstract": "Federated learning (FL) is a promising paradigm in distributed learning while preserving the privacy of users. However, the increasing size of recent models makes it unaffordable for a few users to encompass the model. It leads the users to adopt heterogeneous models based on their diverse computing capabilities and network bandwidth. Correspondingly, FL with heterogeneous models should be addressed, given that FL typically involves training a single global model. In this paper, we propose Generative Model-Aided Federated Learning (GEFL), incorporating a generative model that aggregates global knowledge across users of heterogeneous models. Our experiments on various classification tasks demonstrate notable performance improvements of GEFL compared to baselines, as well as limitations in terms of privacy and scalability. To tackle these concerns, we introduce a novel framework, GEFL-F. It trains target networks aided by feature-generative models. We empirically demonstrate the consistent performance gains of GEFL-F, while demonstrating better privacy preservation and robustness to a large number of clients.", "sections": [{"title": "I. INTRODUCTION", "content": "Deep learning has demonstrated remarkable success across various domains, due to the availability of abundant training data. However, with the proliferation of edge devices like mobile and Internet-of-Things (IoT) devices, which generate substantial amounts of decentralized data, there arises a challenge in effectively aggregating distributed information and collaboratively training neural networks. Federated learning (FL) is a promising solution, facilitating collaborative model training by leveraging data from multiple clients while preserving privacy without sharing client's raw data. In FL, the server collects knowledge (e.g., model weights) from clients and subsequently aggregates it to make clients share the global knowledge [2]. Many recent studies have explored such potential of FL in many practical applications. Simultaneously, the increasing growth rate of model size [5]\u2013[7] and the growing heterogeneity of edge devices [8] pose additional challenges in FL. Edge devices exhibit diverse capabilities, encompassing factors such as computing power, memory, and communication environment. Given the limitations of edge devices to accommodate large models beyond their capabilities, the necessity arises for these devices to adopt personalized and optimized heterogeneous model architectures.\nHowever, many FL algorithms aim to train a single global model [2], [9], creating a challenge for devices with personalized model architectures when collaboratively training their models with others having different architectures. Hence, there needs a solution to aggregate knowledge from edge devices, even when clients have heterogeneous models. While there have been studies on training multiple models in FL [3], [10], [11], previous approaches typically involve scaling down a global model into smaller submodels. Consequently, a client with a model that is not a subset of the global model cannot be trained within the same FL framework. Different lines of work have proposed the incorporation of additional public data through assembly to address model heterogeneity [12]\u2013[15]. However, these approaches necessitate access to a well-curated public dataset in either clients or the server.\nIn this paper, we introduce Generative model-aided Federated Learning (GEFL), a framework that addresses the challenge of training multiple models with diverse architectures tailored to the heterogeneous requirements of individual clients (e.g., memory, computing, and bandwidth dynamics). GEFL incorporates a federated generative model\u00b9 trained in a federated manner on clients' local data. This generative model augments local training data by generating synthetic samples for the training of heterogeneous models [16]. However, training a generative model in a distributed manner poses challenges, especially when dealing with a large number of clients, leading to issues such as mode collapse, blurry, and low-quality generated images [17]\u2013[19]. Moreover, the trained generative model may conflict with the privacy-preserving benefits of FL. Therefore, we propose GEFL-F, which employs generative models that produce features, which are the output of a common feature extractor within heterogeneous models. Our proposed algorithm effectively aggregates global knowledge from feature-generative models under model-heterogeneity, while mitigating related to generative model training and privacy concerns."}, {"title": "II. RELATED WORKS", "content": "FL trains models while data is distributed across multiple clients. Most approaches involve training a single global model [2], [9], [20] and the foundational algorithm, FedAvg [2] gathers global knowledge at the server by aggregating the model parameters from clients and averaging them. Another line of work integrates knowledge distillation (KD) [21] into FL to transfer knowledge from client models to the server model [12], [22]\u2013[24]. For example, FedKD [23] shares a small student model while keeping a local teacher model at each client to reduce communication costs. FedDKD [24] addresses data heterogeneity across clients by averaging the knowledge of clients by KD. However, none of these works specifically aim to address model heterogeneity.\nTo address model heterogeneity in FL, several approaches have proposed scaling a global model into submodels in widthwise [10], [25], in depthwise [11], and both widthwise and depthwise [3]. However, these methods scale the model into a subset of the global model, requiring all clients to share the same model architecture. Our proposed method allows for the training of heterogeneous models with different architectures across clients.\nAnother approach tackles model heterogeneous FL by leveraging the concept of ensembling various models. AvgKD [4] requires a client to receive all other models from other clients and compute an averaged logit of all logits from local samples of these models. However, this can be computationally infeasible with a large number of clients and less effective when models across clients have significant architectural differences. In addition to the above techniques, some studies introduce architectural conditions such as training a common extractor [26] or sharing additional model [27].\nRecent studies have proposed to incorporate additional public data to enhance ensembling methods for addressing model heterogeneity [12]\u2013[15]. For instance, FedDF [12] conducts ensemble distillation between the client and global models, utilizing synthetic data from a pre-trained generator or unlabeled public data. FCCL [13] incorporates unlabeled datasets by introducing a loss term defined on logits of unlabeled public data and the averaged logit across clients. FedMD [14] leverages labeled public data for transfer learning through knowledge distillation. pFedHR [28] has the flexibility to leverage either labeled or unlabeled public data. However, these algorithms often require access to a well-curated public dataset in either clients or the server, which does not exist in practical for real-world training. Instead, our framework employs existing local data in each client.\nSeveral works have delved into FL by incorporating generative models, such as VAE [29] and GAN [30]. FedGAN [31] investigates the federated training of GANs, while other studies involve training a generator supervised by a well-trained model to address statistical heterogeneity when training a single model [32], [33]. In previous studies, generative models could not be effectively trained when client models were heterogeneous, limiting their applicability. In contrast, our approach enables generative models to be trained collaboratively, even in the presence of heterogeneous client models. Furthermore, existing methods often fail to significantly enhance generalization, as the generator tends to produce samples that only reinforce the existing capabilities of well-trained models. While FedCG [34] adopts a similar technique by employing a conditional GAN to generate intermediate features, it does not"}, {"title": "III. GENERATIVE MODEL-AIDED MODEL HETEROGENEOUS FL", "content": "To address the model heterogeneity in FL, GEFL incorporates a conditional generative model trained in a federated manner using local clients' data, as illustrated in Figure 1. GEFL consists of two main processes: (i) federated generative model (FedGen) training for global knowledge aggregation and (ii) target network training augmented by generative models (see Algorithm 1 for details).\nIn the generative knowledge aggregation stage, generative models are trained to capture the representation of real samples. Each client $k \\in C$ trains a generative model G with parameters wk using its local data. The server then aggregates the generative model parameters as $w_g \\leftarrow \\sum_{k\\in C} w_k$ and sends them back to each client for the next round.\nThe trained generative model effectively gathers global knowledge from every client, enabling the training of target networks despite the different model architectures among clients. Specifically, we assume that each client has a model architecture with an index $m \\in \\{1,\\dots, M\\}$ for their target network, where there exist M candidate heterogeneous architectures (e.g., different CNNs or the combination of ResNet [35], EfficientNet [36], and MobileNet [37]).\nThen, during target network training and refinement, target networks are updated by forwarding synthetic samples and real samples separately. In each round of target network training, each client k trains its target network $\\Theta_{k,m}$ using samples generated by FedGen $G(\\cdot|y_i, w_g)$ conditioned on random label $Y_i \\sim p(y)$, treating them as augmented training samples for multiple local epochs as\n$\\min_{\\Theta_{k,m}} \\mathbb{E}_{z_i,y_i \\sim \\mathcal{N}(0,I),p(y)}[CE(p(\\Theta_{k,m}(G(z_i|Y_i, w_g)))), Y_i)]$,\nwhere p is the softmax function and CE is the cross-entropy function. After training target networks on generated samples from G, the target networks are trained on real data samples subsequently. In our algorithm, trained FedGens offer diverse training synthetic samples, contributing to overcoming model heterogeneity in FL. The learning rates are \u03b1 for the generative model G and \u1e9e for the target networks."}, {"title": "IV. FEATURE GENERATIVE MODEL-AIDED FL", "content": "In this section, we introduce GEFL-F, a novel framework designed to address the challenges posed in GEFL, including privacy preservation, scalability, and communication efficiency. This leverages feature-generative models to tackle these issues effectively. We use the suffix -F to indicate the feature-generative models (e.g., FedDCGAN-F, FedCVAE-F).\nOur primary motivation is to design a lightweight federated generative model that preserves privacy on training data of individual clients while simultaneously aggregating global knowledge to benefit the training of heterogeneous networks. To achieve this, we incorporate feature-generative models that are trained on features, which represent the output of a common feature extractor comprising a few layers of the target network. Given the lower resolution of features compared to the original images, sharing feature-generative models offers a potential to mitigate privacy concerns [51], [59], [60], and further reduces the required size of generative models to learn a global knowledge [61]. As information passes through the successive layers of a convolutional layers, the focus shifts from fine-grained pixel-level details to more abstract, high-level features. This process results in a trade-off: while high-level semantic content is preserved and enhanced, detailed pixel information is progressively discarded or generalized [51], [62]. These findings motivate the inherent design of feature extract to prioritize semantic understanding, which is advantageous for preserving privacy.\nAn overview of GEFL-F is provided in Figure 3. Each client has its target network from M candidate models, each consist-"}, {"title": "V. INSIGHTS AND FINDINGS", "content": "Recent studies suggest that a lower guidance score in diffusion models often enhances downstream task performance by improving sample diversity, albeit at the expense of reduced sample quality. In Table II, our experminets on MNIST, FMNIST and CIFAR10 exhibited the consistent results where GEFL with DDPM of lower guidance score outperforms GEFL with DDPM of higher guidance score. DDPM with low guidance (w = 0) does not achieve considerable image quality, despite demonstrating better sample diversity [70]. We also provide t-SNE visualization results in Figure 9. We used pre-trained ResNet18 for CIFAR10 to see the ability of well-trained model learning features from real and synthetic images. The orange dots represent synthetic samples while blue dots represent real samples. The results demonstrate that synthetic samples of lower guidance score are more diverse than samples of higher guidance score. Compared to the samples of lower guidance score, the samples of higher guidance score are concentrated near the real samples.."}, {"title": "VI. CONCLUSION", "content": "In this paper, we proposed GEFL, a straightforward yet effective framework designed to address the challenges of model heterogeneity in FL. Our approach leverages federated generative models to efficiently aggregate knowledge from heterogeneous clients, achieving superior performance compared to baseline methods. To further enhance scalability, reduce communication and computation costs, and address privacy concerns, we introduced GEFL-F, an extension utilizing feature-generative models trained on lower-resolution features. Experimental results demonstrated the advantages of GEFL-F, including improved robustness to increasing client numbers, a significant reduction in parameters and sampling costs, and enhanced privacy preservation."}, {"title": "APPENDIX A\nEXPERIMENTAL DETAILS", "content": "All hyperparameter settings for GEFL and GEFL-F are summarized in Table IX and Table X. Table IX outlines the hyperparameter configurations for training target networks in GEFL and GEFL-F. Notably, $T_{FE}$ is exclusive to training the feature extractor in GEFL-F.\nTable X presents the hyperparameter settings for training federated generative models (FedGens) in GEFL and GEFL-F. The latent dimensions, denoted as $d_g$ and $d_d$, correspond to parameters of FedDCGAN and FedDCGAN-F, respectively. Similarly, the latent size l is used for FedCVAE and FedCVAE-F, while $n_{feat}$ pertains to FedDDPM and FedDDPM-F. Details on these parameters are provided in Appendix B-A.\nThe number of FL communication rounds for training generative models, $T_{KA}$, in Table X indicates the total rounds used to update the FedGens (e.g., FedDCGANs) during the training process in both GEFL and GEFL-F. For instance, under the update setting discussed in Section V-B, FedDCGAN is updated for half of the rounds ($T_{KA}$/2) during global knowledge aggregation stages and subsequently updated for the remaining half during target network training. Conversely, in the freeze setting, FedDCGAN is updated for the full $T_{KA}$ rounds exclusively during the global knowledge aggregation stages.\nThe results presented in Table 8 and Table 7 were obtained based on the configurations outlined in Table XI. Detailed model architectures used to generate feature outputs are provided in Appendix B.\nFor baseline evaluation, we applied a proximal term with a scaling factor of 1 \u00d7 10\u207b\u00b2 for FedProx [9]. For AvgKD [4], pseudo labels were aggregated from the outputs of 10 heterogeneous models. In the case of FedDF [12], we used SVHN as the public dataset for MNIST, and CIFAR10 as the public dataset for FMNIST. For LG-FedAvg [26], the first convolutional layer was averaged across all heterogeneous models, while subsequent layers were averaged within their respective submodels.\nFor evaluating baselines, we used le-2 multiplied to proximal term for FedProx [9]. Pseudo labels are aggregated from the outputs of 10 heterogeneous models for AvgKD [4]. For FedDF [12], we used SVHN as the public dataset for MNIST, CIFAR10 as the public dataset for FMNIST, and CIFAR100 as the public dataset for CIFAR10. For LG-FedAvg [26] the first conv layer was employed as averaging over all the heterogeneous models while the other layers are averaged across submodels.\nTo evaluate the FID and IS scores, we generated 1,000 conditional images uniformly distributed across classes, with 100 images per class."}, {"title": "APPENDIX B\nMODEL ARCHITECTURE", "content": "GAN introduces a generator with parameters $ \\theta_g $, $G (z;\\theta_g)$, to learn the distribution over training data where $z$ denotes input noise variables that are mapped to data space. A discriminator $D (x; \\theta_d )$ that outputs a single scalar is also introduced. $D(x)$ represents the probability that $x$ came from the data rather than from $G$. $D$ is trained to correctly classify whether the input is from training data or samples from $G$. $G$ is simultaneously trained to minimize $log(1 \u2013 D(G(z))))$ to fake $D$. In other words, $D$ and $G$ play the following two-player minimax game: $ \\min_G \\max_D E_{x \\sim p(x)} [log D(x)] + E_{z \\sim p_z(z)} [log(1 \u2013 D(G(z)))].$\\nOur implementation for FedDCGAN and FedDCGAN-F consist of generator and discriminator. Referring to Table XIIa and Table XIIIa, for the generator, 100 dimensional uniform distribution latent input is projected to step 1 and 2 while conditional label is projected to step 3 and 4. Two projected outputs are then concatenated and projected to following steps. Referring to Table XIIb and Table XIIIb, for the discriminator, image is projected to step 1 and label is projected to step 2. Two projected outputs are then concatenated and projected to following steps. We used ($d_g, d_d$, c) = (128, 128, 1) for MNIST and FMNIST, (256, 64, 3) for CIFAR10 and (128, 128, 3) for CelebA and SVHN.\nVAE is trained by maximum likelihood so that the model is likely to produce training set samples. Therefore, VAE aims to maximize the probability of each $x$ in the training set according to $max P(x) = \u222b P(x|z;\u03b8)P(z)dz $. VAE consists of encoding $x$ into $z$ and decoding $z$ into $x$. The decoder maps latent variable $z$ to data space where z is drawn from $N(0, I)$. However, $P(x|z)$ is nearly zero for most $z$ that the encoder sample $z$'s that are likely to have produced $x$. A new function $Q(z|x)$ is introduced to take a value of $x$ and give a distribution over $z$'s that are likely to produce $x. \u03c3N (0, I) + \u03bc$. Then, the loss function is written as follows: $log P(x) \u2013 D[Q(z|x)||P(z|x)] = E_{z\u223cQ}[log P(x|z)] \u2013 D[Q(z|x)||P(z)],$ where D"}, {"title": "APPENDIX C\nADDITIONAL EXPERIMENT RESULTS", "content": "For the CIFAR10 dataset, we employed a diverse set of 10 heterogeneous target networks, comprising eight models with EfficientNet backbones (EfficientNet-B1 through EfficientNet-B7 [36]) and two models with ResNet backbones (ResNet18 and ResNet32 [35]). The hyperparameter settings for training the federated generative models are consistent with those outlined in Table X. As observed in Table XIX, similar to the results in Table IV, GEFL consistently outperforms the baseline methods. The performance degradation observed in both the baselines and GEFL can be attributed to the increased training demands, requiring more communication rounds and larger volumes of data to effectively train the target networks, particularly for larger models such as EfficientNet and ResNet.\nWe measure privacy in our framework, GEFL and GEFL-F, in terms of memorization. In GEFL, where the target networks are not shared, privacy leakage is solely due to the memorization of shared generative models. Memorization occurs when there is an increased probability of generating a sample closely resembling the training data [53]. This is particularly concerning in scenarios involving sensitive data like medical images or images containing private information. A typical way to evaluate memorization is to compare the generated samples to their nearest neighbors in the training set [54], [79].\nWe elaborated on how we assess memorization in GEFL using the mean nearest neighbor distance (MND) ratio, as detailed in Section III-C. The MND ratio for each training sample is computed as the ratio between the distance to the nearest synthetic sample and the nearest validation sample. While any metric can be employed as a distance [53], we use the perceptual metric LPIPS, which captures image similarity as human perception, in contrast to traditional metrics like Euclidean distance. The memorization of federated generative models of GEFL is evaluated as Figure 11, illustrating the distribution of the nearest neighbor distance ratio over the training set of MNIST.\nIn GEFL-F, a common feature extractor and feature-generative model are shared between the server and clients in the FL pipeline. A promising way that attacker can take using trained feature extractor and feature-generative model is to generated"}, {"title": "APPENDIX D\nEXAMPLE OF GENERATED SAMPLES AND FEATURES", "content": "synthetic features from generative model and apply model inversion using feature extractor. To evaluate the vulnerability of GEFL-F in such scenario, we assume a white-box feature extractor and apply model inversion [51] using generated features to get reconstructed images as Figure 5. Subsequently, we compare the original real images with the reconstructed ones by measuring the MND ratio, as we did in GEFL. In Figure 11, it is observed that incorporating feature-generative models mitigates privacy preservation compared to GEFL, even though it shares a common feature extractor.\nWe present additional results analyzing the impact of the guidance score on performance, with a particular focus on its correlation with time steps T. By varying the time steps for DDPM, we observed that under sufficient time steps, lower guidance scores (w = 0) yielded superior performance compared to higher guidance scores (w = 2), as shown in Table XX. Within our framework, while lower guidance scores enhance sample diversity, using fewer time steps results in degraded image quality, leading to better performance with higher guidance scores under such conditions."}]}