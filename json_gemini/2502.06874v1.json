{"title": "Group Reasoning Emission Estimation Networks", "authors": ["Yanming Guo", "Qian Xiao", "Kevin Credit", "Jin Ma"], "abstract": "Accurate greenhouse gas (GHG) emission reporting is critical for governments, businesses, and investors. However, adoption remains limited-particularly among small and medium enterprises due to high implementation costs, fragmented emission factor databases, and a lack of robust sector classification methods. To address these challenges, we introduce Group Reasoning Emission Estimation Networks (GREEN), an AI-driven carbon accounting framework that standardizes enterprise-level emission estimation, constructs a large-scale benchmark dataset, and leverages a novel reasoning approach with large language models (LLMs). Specifically, we compile textual descriptions for 20,850 companies with validated North American Industry Classification System (NAICS) labels and align these with an economic model of carbon intensity factors. By reframing sector classification as an information retrieval task, we fine-tune Sentence-BERT models using a contrastive learning loss. To overcome the limitations of single-stage models in handling thousands of hierarchical categories, we propose a Group Reasoning method that ensembles LLM classifiers based on the natural NAICS ontology, decomposing the task into multiple sub-classification steps. We theoretically prove that this approach reduces classification uncertainty and computational complexity. Experiments on 1,114 NAICS categories yield state-of-the-art performance (83.68% Top-1, 91.47% Top-10 accuracy), and case studies on 20 companies report a mean absolute percentage error (MAPE) of 45.88%. Our experimental results achieve state-of-the-art performance on 1,114 NAICS categories, attaining 83.68% Top-1 accuracy and 91.47% Top-10 accuracy. Additionally, case studies on 20 companies yield a mean absolute percentage error (MAPE) of 45.88% in predicted emissions relative to self-disclosed GHG data. The project is available at: https://huggingface.co/datasets/Yvnminc/ExioNAICS.", "sections": [{"title": "1 Introduction", "content": "Accurate greenhouse gas (GHG) emission reporting has become increasingly critical for governments, businesses, and investors striving to mitigate the impacts of climate change [1, 2]. In recent years, various jurisdictions worldwide have instituted mandatory disclosure frameworks that oblige enterprises to publicly report their emissions, spurring both transparency and accountability in corporate climate action [3, 4]. For instance, the European Union Emissions Trading System (EU ETS) imposes stringent reporting and trading requirements on power and industrial sectors, contributing to notable emission reductions since its inception [5]. Australia, through the National Greenhouse and Energy Reporting (NGER) Act 2007, similarly enforces comprehensive disclosure obligations designed to capture reliable emissions data from large facilities [6]. Beyond regulatory obligations,"}, {"title": "2 Related Work", "content": "investors and other stakeholders increasingly demand granular, verifiable carbon accounting as part of environmental, social, and governance (ESG) assessments [7, 8, 9].\nThese regulations are based on the GHG Protocol Corporate Standard, which defines emissions across three scopes: Scope 1 direct emissions, Scope 2 indirect emissions from electricity consumption, and Scope 3 all other indirect emissions across the value chain [10]. Among these, more than 75% GHG emission reported are Scope 3 emissions [11, 12]. However, they are particularly challenging to estimate, as they involve emissions from upstream and downstream activities such as purchased goods, transportation, and waste disposal. Making it necessary to investigate the enterprise value chain and accurately identify company sector categories [13, 14, 15]. Moreover, over 70% of enterprises' emission reporting relies on Scope 3 emission factors, which are expensive to access and require domain expertise to determine carbon intensity [16, 17]. This complexity hinders broader adoption, especially among small and medium enterprises (SMEs), and is exacerbated by a dearth of large-scale benchmark datasets that automate sector classification and carbon factor assignment [18]. The absence of such resources creates a major barrier, limiting GHG reporting largely to organizations with sufficient capital and expertise.\nTo address these challenges, we introduce Group Reasoning Emission Estimation Networks (GREEN), the first LLM-driven enterprise emission estimation framework in an end-to-end manner. The predicted emission is the multiplication of an enterprise's annual revenue and a carbon intensity factor, determined by classifying the enterprise into a sector. We fine-tune Sentence-BERT models via self-supervised contrastive learning and apply a Group Reasoning hierarchical search with LLMs. Trained on a large-scale benchmark dataset constructed from scratch, named ExioNAICS, it covers over 20,850 enterprises, each mapped to validated North American Industry Classification System (NAICS) codes [19]. The Scope 3 emission factors are obtained from the ExioML economic dataset [16] over 166 sectors. We formulate and standardize the automated emission estimation pipeline as an Information Retrieval (IR) problem and demonstrate the potential of Natural Language Processing (NLP) techniques in streamlining carbon accounting. We achieve 83.68% Top-1 accuracy and 91.47% Top-10 accuracy in the challenging industry classification with 1,114 categories. The predicted enterprise emissions are evaluated with self-disclosed emissions found through sustainability reports, showing a moderate percentage error of 45.88% on average.\nThis study contributes in three key ways:\n1. It provides a standardized emission estimation pipeline that helps bridge machine learning research with climate science, thereby making carbon accounting more accessible to SMEs.\n2. It introduces a novel, publicly available benchmark dataset for enterprise-level GHG estimation with a unifying NAICS and emission factor database, and applies state-of-the-art NLP models to automate sector classification.\n3. It proposes high-performance fine-tuning via self-supervised contrastive learning and Group Reasoning search."}, {"title": "2.1 Machine Learning in Sector Classification", "content": "Machine Learning (ML) methods have been extensively explored for automating sector classification, a task traditionally reliant on expert-based taxonomies (e.g., GICS, NAICS). In a typical setup, each sample xi (e.g., firm-level features, textual descriptions, or both) is mapped to a label y from a predefined category set Y. One seeks a classifier\n\\(f_{\\theta}: X \\rightarrow y,\\)\nparameterized by \u03b8. Minimizing a suitable loss, such as\n\\(\n\\hat{\\theta} = \\underset{\\theta}{\\operatorname{argmin}} \\frac{1}{N} \\sum_{i=1}^{N} l(f_{\\theta}(x_i), y_i) + \\lambda \\Omega(\\theta),\n\\)\nlies at the core of traditional supervised learning. However, purely human-assigned labels face key obstacles: inconsistent coding across experts [20], limited coverage of new or cross-sector activities,"}, {"title": "2.2 Self-Supervised Contrastive Learning Framework", "content": "Self-supervised learning (SSL) has emerged as a powerful representation learning paradigm that does not require large labeled datasets. Instead, the model learns from inherent data structures, creating positive and negative instances by various transformations or pairing strategies. SSL shifts away from cross-entropy on labeled samples {(xi, Yi)} and instead uses contrastive losses to align similar views of the same data point while separating different samples.\nInitial advances in SSL stemmed from the image domain, with frameworks like SimCLR [33] and MoCo [34] leveraging an InfoNCE loss to bring positive pairs (augmented views of the same image) closer in latent space relative to a set of negatives. Later works like BYOL [35] and SimSiam [36] showed negative-free designs. In NLP, models such as SBERT [37] and SimCSE [38] adapted contrastive principles to sentence embeddings, enabling robust similarity measures with minimal or no labeled data. Contrastive methods have thus evolved into a general framework for embedding diverse data types (images, text, multimodal) into semantically meaningful spaces."}, {"title": "2.3 GHG Emission Estimation by Ecological Economic Framework", "content": "Over 70% of enterprises estimate their carbon footprints using sector-based carbon intensity factors, representing GHG emissions produced per unit of economic output in a given sector and region [17]. The Environmentally Extended Multi-Regional Input-Output (EE-MRIO) framework provides a structured way to derive these intensities by integrating economic transactions and regional environmental data [39, 40]. The carbon intensity factor is defined as the ratio of a sector's total emissions to its economic output. While the EE-MRIO framework offers a comprehensive view of inter-sector linkages, its deployment in real industrial applications is hindered by expensive data and domain expertise requirements [41, 42]."}, {"title": "3 Method", "content": "3.1 Open-Source Large-Scale NLP Benchmark Dataset: ExioNAICS\nDespite recent advancements in LLMs, sector classification and emission estimation still lack publicly available, large-scale datasets. Existing work often uses closed-source repositories or small label spaces. We therefore introduce ExioNAICS, the first open-source dataset targeting both sector classification and emission estimation. It integrates:\n\u2022 NAICS Codes and Descriptions. We adopt the North American Industry Classification System (NAICS). Validated NAICS codes are retrieved from the official NAICS Associa-tion, mitigating label noise."}, {"title": "3.2 Sentence-BERT with Contrastive Fine-Tuning", "content": "We cast sector classification as an Information Retrieval (IR) problem: for a given enterprise description q, retrieve the most relevant NAICS document c \u2208 Cl. This approach naturally scales to large or evolving taxonomies, unlike standard classification with a rigid label space.\nWe adopt the Sentence-BERT (SBERT) framework [37], which uses a siamese encoder to produce fixed-dimensional sentence embeddings. Let \\(f_{\\theta} : X \\rightarrow R^d\\) be the shared encoder. For each query q and NAICS document c, the embeddings are:\n\\(Q = f_{\\theta}(q), C = f_{\\theta}(c).\\)\nTheir similarity is measured by cosine similarity\n\\(s(q, c) = \\frac{Q \\cdot C}{||Q|| ||C||}.\\)\nHence, the most relevant NAICS class is found by Maximum Inner Product Search (MIPS):\n\\(\\pi(q) = \\underset{c \\in C}{\\operatorname{argmax}} s(q, c).\\)\nRather than a standard cross-entropy, we fine-tune SBERT using a contrastive Multiple Negative Ranking (MNR) loss [44]:\n\\(\nL = - \\frac{1}{n} \\sum_{i=1}^{n} \\log(\\frac{\\exp(\\cos(Q_i, D_i))}{\\sum_{j=1}^{n} \\exp(\\cos(Q_i, D_j))}),\n\\)\nwhere Qi = f\u03b8(qi) and Di = f\u03b8(di) are positive query-document pairs, while all other documents in the same batch serve as negatives. This encourages alignment of relevant pairs and separation from non-relevant pairs."}, {"title": "3.3 Large-Scale Sector Classification via Hierarchical Group Reasoning", "content": "NAICS codes have a coarse-to-fine hierarchy: 20 categories at level 2, 95 at level 3, and 1,114 at level 6. Classifying queries directly among 1,114 labels is complex, and single-stage classifiers often suffer from higher uncertainty and heavier computation. We introduce a Hierarchical Group Reasoning method, which ensembles multiple LLM-based classifiers and domain-specific heuristics at each level. This approach:\n1. Decomposes the large classification task into smaller, level-wise subproblems.\n2. Traverses the NAICS tree from root to leaves, pruning irrelevant branches early.\n3. Reduces model uncertainty (entropy) and lowers time complexity from exponential (bd) to linear in the depth (b. d).\nAlgorithm 1 details the procedure. A top-k parameter controls how many child nodes at each level are selected for expansion, trading off accuracy and speed. Theoretical proofs show that hierarchical decomposition lowers Shannon entropy compared to a single massive classifier and cuts computational overhead (\u00a73.4)."}, {"title": "3.4 Theoretical Performance Analysis", "content": "Theorem 1 (Hierarchical Classification Entropy) Let there be a hierarchical classification tree of depth d with uniform branching b. Let each level i have accuracy pi. The hierarchical approach has strictly lower Shannon entropy than a single-stage classifier with bd classes and accuracy  \u03a0di=1 pi Formally, HD(Y) \u2265 HG(Y).\nTheorem 2 (Complexity) A single-stage approach over bd classes has O(bd) time, whereas hierarchical classification has O(b\u00b7d)."}, {"title": "4 Experiments & Results", "content": "4.1 Experimental Setup\nWe evaluate on NAICS levels 2 (20 classes), 3 (95 classes), and 6 (1,114 classes). Data splits are 80% train, 10% validation, 10% test. Models are trained for 100 epochs with a learning rate 2\u00d710-5 on an NVIDIA T4 GPU. The primary metric is Top-k accuracy (Acc@k):\nAcc@k=\\frac{TP}{TP + FP + FN},\nwhere a prediction is correct if any ground-truth label is among the top-k predictions. We examine the effects of different SBERT backbones, data augmentation, hierarchical hyperparameters, and ensemble strategies."}, {"title": "4.2 Comparison of Pre-trained SBERT Backbones", "content": "Table 2 compares multiple Sentence-Transformer (SBERT) backbones on levels 2, 3, and 6. These differ in model size (60 MB to 420 MB) and pre-training corpora (Paraphrase, Multi-QA, All).\nMpnetbase achieves the highest accuracy at all levels, but it is quite large (420 MB) and slow. Smaller MiniLM variants remain competitive, e.g., MiniLML12 is only 120 MB with near state-of-the-art performance. Hence, practitioners can balance performance against computational constraints."}, {"title": "4.3 Data Augmentation Analysis", "content": "We test paraphrase-based augmentations (e.g., word replacement) at random probabilities for MiniLML3 on NAICS-6. Table 3 shows minimal gains or slight performance drops, consistent with findings that large pre-trained models are robust to naive text augmentations."}, {"title": "4.4 Group Reasoning Hyperparameter k", "content": "Table 4 shows that increasing k (the beam width in hierarchical search) yields higher accuracy but linearly increases running time. For k = 90, Acc@1 rises from 77.51% to 80.29% with a total runtime of 16 minutes, still faster than naive MIPS over 1,114 classes."}, {"title": "4.5 Model Ensembles in Group Reasoning", "content": "We can ensemble smaller and larger MiniLM backbones at different levels. For instance, use L3 at levels 2 and 3, then L12 at level 6. Table 5 shows that mixing smaller models for early levels and bigger ones for deeper levels can achieve high accuracy with moderate size."}, {"title": "4.6 Ablation Study", "content": "Table 6 shows incremental ablations for NAICS-6 with MiniLML3. Zero-shot SBERT yields only 20.12% Acc@1. Cross-entropy slightly improves to 21.49%, but contrastive MNR drastically jumps to 76.85%. NLTK preprocessing, Group Reasoning, and the multi-level ensemble lead to the final GREEN model with 83.68%."}, {"title": "5 Enterprise Emission Inference", "content": "We estimate corporate GHG emissions by multiplying predicted carbon intensity from NAICS classification with annual revenue. Due to limited public data, we sample 20 companies with self-disclosed emissions, compare with GREEN estimates, and compute Mean Absolute Percentage Error (MAPE):\nMAPE = \\frac{1}{N} \\sum_{i=1}^{N} \\frac{|R_i - E_i|}{R_i},"}, {"title": "6 Conclusion", "content": "We propose GREEN as the first end-to-end LLM-driven framework for enterprise-level GHG emission estimation. The core pipeline: (1) maps textual descriptions to NAICS sectors via contrastive SBERT classification, (2) derives carbon intensity factors from ExioML, and (3) computes emissions as revenue \u00d7 intensity. We introduce ExioNAICS, a large-scale public benchmark unifying 20,850 enterprises across 1,114 NAICS categories with emission-factor data, and propose a novel Group Reasoning method to handle large-scale hierarchical classification efficiently. Extensive experiments show Acc@1 = 83.68% on NAICS-6, surpassing prior methods, and a moderate MAPE of 45.88% when validated against self-disclosed corporate emissions."}]}