{"title": "An Axiomatic Study of the Evaluation of Enthymeme Decoding in Weighted Structured Argumentation", "authors": ["Jonathan Ben-Naim", "Victor David", "Anthony Hunter"], "abstract": "An argument can be seen as a pair consisting of a set of premises and a claim supported by them. Arguments used by humans are often enthymemes, i.e., some premises are implicit. To better understand, evaluate, and compare en- thymemes, it is essential to decode them, i.e., to find the miss- ing premisses. Many enthymeme decodings are possible. We need to distinguish between reasonable decodings and unrea- sonable ones. However, there is currently no research in the literature on \"How to evaluate decodings?\". To pave the way and achieve this goal, we introduce seven criteria related to decoding, based on different research areas. Then, we intro- duce the notion of criterion measure, the objective of which is to evaluate a decoding with regard to a certain criterion. Since such measures need to be validated, we introduce several de- sirable properties for them, called axioms. Another main con- tribution of the paper is the construction of certain criterion measures that are validated by our axioms. Such measures can be used to identify the best enthymemes decodings.", "sections": [{"title": "Introduction", "content": "In the literature on logic-based argumentation, a deductive argument is usually defined as a premise-claim pair where the claim is inferred (according to a logic) from the premises. However, when studying human debates (i.e. real world argumentation), it is common to find incomplete ar- guments, called enthymemes, for which the premises are in- sufficient for implying the claim. The reason for this incom- pleteness is varied, for example it may result from impreci- sion or error, e.g. a human may argue without knowing all the necessary information, or it may be intentional, e.g. one may presuppose that some information is commonly known and therefore does not need to be stated, or the employment of enthymemes is an instrument well known since Aristo- tle (Faure 2010) as one of the most effective in rhetoric and persuasion when it comes to interacting with an audience.\nThere are studies in the literature on understanding en- thymemes in argumentation, using natural language process- ing (Habernal et al. 2017; Singh et al. 2022; Wei et al. 2022), but these do not identify logic-based arguments. There are also symbolic approaches for decoding enthymemes in structured argumentation including (Hunter 2007; Dupin de Saint-Cyr 2011; Black and Hunter 2012; Hosseini, Modgil,"}, {"title": "Weighted Logics", "content": "In the present section, we introduce the logic in which we represent enthymeme. Let us begin with the language. We chose a weighted one, because weights play an important role in enthymeme decodings as we will see it in the section devoted to the axioms.\nDefinition 1. A weighted language is a set W such that:"}, {"title": "Normalization Methods", "content": "Later in the paper, we count the number of elements in a set of formulae \u0393. Thus, we need first to normalize the syntactic form of \u0393. To achieve this goal, we propose the notion of normalization method.\nDefinition 6. Let W be a weighted language. A normal- ization method on W is a function N that normalizes the syntactic form of the formulae, i.e., N is a function from $2^W$ to $2^W$.\nThe rest of the present section is devoted to the construc- tion of a specific normalization method on wLog that will be used in examples.\nOur proposal is an alternative to the notion of compilation introduced in (Amgoud and David 2021) for propositional logic-based arguments.\nFor this, we need to capture classical interpretation with formula.\nDefinition 7. We assume an enumeration (without repeti- tion) $Ena = (a_1, a_2,..., a_n)$ of A, as well as an enumera- tion $Eni = (I_1, I_2, ..., I_m)$ of the classical interpretations of Lan.\nNext, let $i \\in {1,2,...,m}$. We denote by $f_i$ the formula representing the interpretation $I_i$, i.e., $f_i$ is the conjunction of literals $l_1 \\land l_2\\land...\\land l_n$ of Lan such that $n = |A|$ and $\\forall j\\in {1, ..., n}$, the following holds: $l_j = a_j$, if $a_j$ is true in $I_i$; $l_j = \\neg a_j$, otherwise.\nWe are ready to normalize the syntactic form of a propo- sitional formula in a standard way.\nDefinition 8. Let $f \\in Lan$. We denote by $Dnf(f)$ the canon- ical disjunctive normal form of $f$, i.e.,\n$Dnf(f) = \\bigvee_{{i:I_i \\text{ is a model of } f}} f_i$.\nNext, we denote by $Cnf(f)$ the canonical conjunctive normal form of $f$, i.e., $Cnf(f)$ is obtained from $\\neg Dnf(\\neg f)$ by, first, applying the De Morgan laws and double negation until we get a formula in CNF, and second iteratively apply- ing the following three points:\n1. identify any two clauses $c = l_1 \\lor l_2 \\lor ... \\lor l_n$ and $c' = l_1 \\lor l_2 \\lor ... \\lor l'_m$ such that $n = m$ and, for some $i\\in {1, ..., n}$, for some $j \\in {1, ..., n}$, we have that $(l_i = \\neg l'_j \\text{ or } l'_j = \\neg l_i)$ and $(l_1,..., l_{i-1},l_{i+1},..., l_n)$ is a permutation of $(l_1, ..., l'_{j - 1}, l'_{j+1}, ..., l'_m)$;\n2. remove $c'$ (unless $c'$ is a literal);\n3. remove $l_i$ from $c$ (unless $c$ is a literal).\nLet us illustrate syntactic normalization."}, {"title": "Weighted Structured Argumentation", "content": "An argument can be seen as a pair consisting of a set of premises and a claim supported by them. Some constraints on the premises and claim are usually considered (Besnard and Hunter 2001). The goal of this section is to extend the notion of argument to a weighted logic.\nDefinition 10. Let L = (W,$\\sim$, t) be a weighted logic. A weighted argument on L is a pair $A = (\\Gamma, \\alpha)$ such that \u0393 is a finite subset of W and $\\alpha \\in W$, \u0393 is consistent, $\\Gamma \\sim \\alpha$, $\\forall\\Gamma' \\subset \\Gamma, \\Gamma' \\not\\sim \\alpha$. Let $Arg_L$ be the set of all weighted ar- guments on L. We omit subscripts like L whenever they are clear from the context.\nHowever, such ideal arguments, whether weighted or not, are rarely seen. In general, humans use enthymemes, i.e., incomplete arguments in which part of the premises is miss- ing, to logically infer the claim. The task of handling en- thymemes is investigated in e.g. (Hunter 2007, 2022).\nIn what follows, we introduce the notion of an approxi- mate weighted argument, which is subject to no constraints other than the structure of its premises/claims. Thus, an en- thymeme is a special case of this type of argument, where it is guaranteed that the inference between the premises and the claim does not logically hold.\nDefinition 11. Let L = (W,$\\sim$, t) be a weighted logic. An approximate weighted argument on L is a pair $A = (\\Gamma, \\alpha)$ such that I is a finite subset of W and $\\alpha \\in W$. We denote by $aArg_L$ the set of all approximate weighted arguments on L. An enthymeme on L is an element $E = (\\Gamma, \\alpha) \\in aArg_L$ such that $\\Gamma \\not\\sim \\alpha$. We denote by Enth the set of all enthymemes on L."}, {"title": "Criterion Measures and Axioms", "content": "Obviously, certain enthymeme decodings are not reasonable. By reasonable, we mean that there are a range possible fea- tures we would expect to see satisfied in an acceptable en- thymeme decoding. In order to distinguish between the rea- sonable ones and the others, we introduce seven criteria, as well as the notion of criterion measure.\nDefinition 13. Let L = (W,$\\sim$, t) be a weighted logic. A criterion measure on L is a measure of the success of an enthymeme decoding with regard to one criterion, i.e., it is a function $M : Enth \\times aArg \\rightarrow [0, 1]$.\nWe propose 7 criteria for evaluating enthymeme decod- ings: the inference of the claim from the premises, the co- herence of the premises, their minimality, the preservation of the enthymeme premises, the similarity between the en- thymeme premises and the decoded ones, the granularity of the decoded premises, and the stability of the weights.\nAll these criteria except stability (which is specific to our framework), are inspired by criteria defined in argumenta- tion (Simari and Loui 1992), or informally discussed in ex- plainable AI (XAI) (Sokol and Flach 2020) or in philosophy (Grice 1975), as elucidated in Figure 1. It is useful also to recall that the notions of argument and explanation are close (Hahn and Te\u0161i\u0107 2023), and that XAI's informal properties"}, {"title": "Construction of Criterion Measures", "content": "In the present section, we will construct criterion measures for each of the seven aforementionned criterion.\nCriterion measures of coherence. We assume here the strong condition that no inconsistency is acceptable in a good decoding. Moreover, the binary nature of our measures is in line with the binary nature of the consistency threshold of a weighted logic (Definition 2).\nDefinition 22. Let L = (W,$\\sim$,t) be a weighted logic, $\\forall E = (\\Gamma, \\alpha) \\in Enth, \\forall D = (\\Delta, \\beta) \\in aArg, we define\n$Nb\\_SInc(E, D) = |{\\Phi \\subseteq \\Delta : \\Phi\\in Inc, \\exists \\Psi \\subset \\Phi \\text{ s.t. } \\Psi \\in Inc}|$, and\n$Nb\\_WInc(E, D) = |{\\Phi \\subseteq \\Delta\\cup\\Gamma: \\Phi\\in Inc, \\exists \\Psi \\subset \\Phi \\text{ s.t. } \\Psi \\in Inc}|$.\nWe denote first by $M_{SC}$ the criterion measure on L called Divided Strong Coherence, and second by $M_{WC}$ the crite- rion measure on L called Divided Weak Coherence:\n$M_{SC}(E, D) = \\frac{1}{1+ Nb\\_SInc(E, D)}$\n$M_{WC}(E, D) = \\frac{1}{1 + Nb\\_WInc(E, D)}$\nSimilarly, let p \u2208 (0, 1] be a penalty score, we denote first by $M_{PSC}^p$ the criterion measure on L called p-Penalty Strong Coherence, and second by $M_{PWC}^p$ the criterion measure on L called p-Penalty Weak Coherence:\n$M_{PSC}(E, D) = Max \\bigg(0,1 - p \\times Nb\\_SInc(E, D)\\bigg)$\n$M_{PWC}(E, D) = Max\\bigg(0,1 - p \\times Nb\\_WInc(E, D)\\bigg)$\nLet us illustrate the criterion measure."}, {"title": "Criterion measures of inference", "content": "To evaluate the infer- ence criterion, we propose two parametric measures based on a threshold defining the acceptable error in relation to the weight. We assume here that for any weighted logic, its weighted consequence operator can be defined as a com- bination of a flat consequence operator (such that the flat support infers the flat claim), and a weight aggregator (such that the aggregated weight of the support equals the claim's weight).\nGiven that inference strongly depends on language and its consequence operator, we will propose measures specific to propositional weighted logic, in order to give a concrete example. To reason finitely on a set of formulae, we bor- row and modify from Definition 41 in (David 2021) the def- inition of dependent finite Cn. Note that even if the mea- sures for inference proposed here are specific to this (propo- sitional) logic, it is nevertheless possible to generalise these measures to any logic by adapting the finite inference func- tion (here flat finite Cn).\nDefinition 23. Let \u0394 \u2286 wLan, N a normalization method on wLan, the flat finite Cn is defined by $fCn_N (\\Delta) =$\n${\\lbrace f: Flat(\\Delta) \\vdash f \\text{ s.t. } f \\in Flat(N(wLan))\\text{ and } Lit(f) \\subseteq Lit(Flat(\\Gamma)) \\text{ where }\\Gamma \\subseteq \\Delta \\text{ s.t. } Flat(\\Gamma) \\vdash f \\text{ and }\\nexists\\Gamma' \\subset\\Gamma\\text{ s.t. } Flat(\\Gamma') \\vdash f\\rbrace}$.\nExample 5. Let N = Dn, and\n$\\Delta = {\\langle r, 0.7\\rangle, \\langle\\neg r \\lor h, 0.8\\rangle} \\subseteq wLan$;\n$\\alpha = \\langle h, 0.7\\rangle \\in wLan$;\n$\\beta = \\langle r\\land h\\land x, 0.7\\rangle \\in wLan$.\nHence, we have:\n$fCn(\\Delta) = {r, \\neg r \\lor h, h, r \\lor h}$;\n$fCn(\\alpha) = {h}$;\n$fCn(\\beta) = {r, h, x, r\\lor h, r\\lor x, h\\lor x, r\\lor h\\lor x}$.\nIt is interesting to note that the use of inferences based solely on the literals present initially avoids the explosion of clauses inferable from all possible literals (and which are not relevant here), however we have a variation of clauses for all acceptable combinations of literals; e.g., with r and h we will also have r\\lor h. This combination can be seen as a redun- dancy. One option would be to use implicate primes, which has been studied in the literature for compilation problems (Darwiche and Marquis 2002), however if we compare the implicate primes of {r, h} with those of {r \\lor h}, we see no overlap although there is an inference relationship between these two set of formulae. For this reason we have defined the finite flat Cn operator, and we consider that semantic overlap between clause combinations is the price to pay for a fine-grained and comparable semantic representation.\nMoreover, to check for common semantic information between the premises and the claim, we also considered us- ing models. Unfortunately, if the premises are inconsistent, the models do not allow for detecting common inferences. For example, between the premises {r, \\neg r, h} and the claim {h}, there is no common interpretation.\nNext, we present two families of measures for calculating how well the premises of a decoding infers its claim.\nDefinition 24. Let L = (W,$\\sim$, t) be a weighted logic, N a normalization method on W, a \u2208 [0,1] be an acceptable error, and V be the weight aggregator used in L. We denote"}, {"title": "Criterion measures of minimality", "content": "For the minimality cri- terion, we propose two strategies: one based on the number of minimal subsets, and another based on the number of un- necessary formulae."}, {"title": "Quality Measure", "content": "Criterion measures look at different aspects of the quality of a decoding of an enthymeme. In order to get a better under- standing of the quality of a decoding, we will use multiple criterion measures, each giving a value, and then we com- bine those values to give a single quality measure.\nAn aggregation function is a function $F : [0,1]^n \\rightarrow [0, 1]$, where $n \\in N$, which aggregates a sequence of val- ues into a single one.\nDefinition 32. Let L = (W,$\\sim$, t) be a weighted logic, C = ($M_1,..., M_k$) a sequence of criterion measures on L, and F an aggregation function. We denote by $Q_F$ the quality measure based on C and F, i.e., the function on $Enth\\times aArg$ such that, $\\forall E \\in Enth, \\forall D \\in aArg$, the following holds:\n$Q_F(E, D) = F(v_1, ..., v_k)$, where\n$M_1(E, D) = v_1, . . ., M_k(E, D) = v_k$.\nLet see some specific examples of aggregation function.\nDefinition 33. Let a sequence T = ($v_1, ..., v_k$) where each $v_i \\in [0,1]$. The following aggregation functions $F_{av}$, and $F_{Pr}$ are defined as follows:\nif |T| = 0, then $F_{av}(T) = 0$, else $F_{av} (T) = \\frac{\\Sigma_{T}}{|T|}$\nif |T| = 0, then $F_{Pr}(T) = 0$, else $F_{Pr} (T) = \\prod_{T} T[i]$"}, {"title": "Conclusion", "content": "Enthymemes are an omnipresent phenomenon, and to build systems that can understand them, we need methods to mea- sure the quality of decodings, and thereby optimize the choice of decodings. This paper introduces an unexplored research question on the evaluation of enthymeme decoding."}]}