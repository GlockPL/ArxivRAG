{"title": "A Baseline Method for Removing Invisible Image Watermarks using Deep Image Prior", "authors": ["Hengyue Liang", "Taihui Li", "Ju Sun"], "abstract": "Image watermarks have been considered a promising technique to help detect AI-generated content, which can be used to protect copyright or prevent fake image abuse. In this work, we present a black-box method for removing invisible image watermarks, without the need of any dataset of watermarked images or any knowledge about the watermark system. Our approach is simple to implement: given a single watermarked image, we regress it by deep image prior (DIP). We show that from the intermediate steps of DIP one can reliably find an evasion image that can remove invisible watermarks while preserving high image quality. Due to its unique working mechanism and practical effectiveness, we advocate including DIP as a baseline invasion method for benchmarking the robustness of watermarking systems. Finally, by showing the limited ability of DIP and other existing black-box methods in evading training-based visible watermarks, we discuss the positive implications on the practical use of training-based visible watermarks to prevent misinformation abuse. Our code is publicly available at https://github.com/HengyueL/DIP_Watermark_Evasion.", "sections": [{"title": "Introduction", "content": "In this prosperous era of generative AI, the traceability of AI-generated content (e.g., language, images, and videos) to its source has been frequently mentioned as a promising solution to promote the responsible use of generative AI (Fan et al., 2023), e.g., to protect copyright or to curb misinformation. In particular, the traceability of AI-generated images has become increasingly urgent, as many AI products, such as DALL-E (Ramesh et al., 2022) and Stable Diffusion (Rombach et al., 2022), can create highly photorealistic and artistic images that are hard to distinguish from natural photos or human drawings. Unsurprisingly, some AI-generated images have caused false beliefs on social media (Wendling). Thus, major tech companies such as Google, OpenAI (Bartz & Hu) have recently opted to incorporate watermarks into their image generation products to improve traceability and promote responsible use.\nManually designed vs. training-based watermarks Watermarking methods can be generally divided into two categories: (i) non-blind methods (Cox et al., 1997; Hsieh et al., 2001; Pereira & Pun, 1999) and (ii) blind methods (Bi et al., 2007), which are divided by whether access to original clean images is required to correctly decode the watermarked images (Zhao et al., 2024). In what follows, we focus only on blind methods (and refer to them as watermarks), as they do not require access to clean images and fit better in large-scale application scenarios, such as tracing AI-generated content. Watermarks are typically embedded"}, {"title": "Background and related work", "content": "(Blind) image steganography refers to the technique of hiding secret but retrievable messages in an image with minimal change to the image (Zhu et al., 2018). Given an arbitrary natural image $I \\in I$, where $I$ denotes the set of natural images, and an arbitrary n-bit message $w \\in \\{0,1\\}^n$, an image steganography system typically consists of an encoder $E$-which takes any image $I$ and any message $w$ and produces an encoded image, a decoder $D$-which takes any image and produces an informative message, and its system goal: (o means function composition)\n\n$(D o E)(I, w) = w, \\forall I\\in I, w \\in \\{0,1\\}^n, $(correctly encode and decode w)\n$D(I) = 0, \\forall I \\in I,$(no useful message decoded from a clean image)\n$E(I, w) \\approx I,\\forall I\\in I, \\forall w \\in \\{0,1\\}^n. $(minimal encoding distortion to the image)\n\nExisting steganography methods differ by whether the encoder and decoder are manually designed or learned from data. Manually designed encoder-decoder pairs rely on ideas such as manipulating the least significant bit (LSB) (Tirkel et al., 1993), template matching in the Fourier domain (Pereira & Pun, 2000), discrete wavelet transform (DWT), discrete cosine transform (DCT), and singular value decomposition (SVD) (Bi et al., 2007; Pereira & Pun, 2000; Navas et al., 2008). In contrast, training-based methods often learn DNN-based encoder-decoder pairs from data, based on variants of a model formulation derived from the goal stated in Eq. (1):\n\n$\\min_{\\Phi,\\theta} E_{w,I} l_m[w, (D_{\\theta} o E_{\\Phi})(I, w)] $(to ensure Eq. (1a))\ns. t. l_q(I, E_{\\Phi}(I, w)) \\leq \\delta, \\forall I \\in I, \\forall w \\in \\{0,1\\}^n, $(to ensure Eq. (1c))\n\nwhere $\\Phi$ and $\\theta$ are learnable weights of the DNNs in $E$ and $D$, respectively; $l_m$ and $l_q$ are two losses measuring the error of message recovery and the quality distortion to the image, respectively; and $\\delta$ is the maximally allowed perturbation to the image caused by watermarking embedding. Representative training-based methods include HIDDEN and its variants (Zhu et al., 2018; Wen & Aydore, 2019; Luo et al., 2020), SteganoGAN (Zhang et al., 2019a), Stable Signature (Fernandez et al., 2023), rivaGAN (Zhang et al., 2019b), StegaStamp (Tancik et al., 2020), Mbrs (Jia et al., 2021) and TrustMark (Bui et al., 2023a). These methods typically also incorporate regularization terms to encourage the distribution of the encoded images to be close to that of the original images based on generative adversarial networks (GAN) (Goodfellow et al., 2014a). SSL (Fernandez et al., 2022) and RoSteALS (Bui et al., 2023b) are similar in spirit but perform learning in different spaces. In theory, solving Eq. (2) with a reasonably small $\\delta$ can always produce distortion patterns that are invisible to human eyes. However, existing methods typically work with heuristic penalty or regularization forms of"}, {"title": "(Blind) image watermarking", "content": "Based on steganography, a natural way to trace AI-generated images is to assign a fixed message $w$ as the signature of the content owner (e.g., a company) and apply steganography to generate images containing the signature, i.e., watermarked images, to achieve (Jiang et al., 2023):\n\n$D(E(I, w)) = w, \\forall I \\in I,$ (w is a fixed message representing the signature)\n$D(I) \\neq w, \\forall I \\in I,$ (messages decoded from unwatermarked images should not be w)\n$E(I, w) \\approx I, \\forall I \\in I.$ (minimal encoding distortion to the image)\n\nIn practice, whether an image $I$ is watermarked by $w$ can be detected by comparing the decoded message with $w$:\n\n$1[B A(D(I), w) > \\gamma],$\n\nwhere $B A$ denotes the bitwise accuracy and $\\gamma$ is a preset task-dependent threshold (Jiang et al., 2023; Fernandez et al., 2023; Yu et al., 2021). Due to the similarity between Eq. (3) and Eq. (1), most existing work considers image watermarking as a special application of steganography, e.g., Zhu et al. (2018); Tancik et al. (2020); An et al. (2024); Zhao et al. (2024). As a result, the learning formulation in Eq. (2) is also widely adopted in works that only focus on watermarking systems, e.g., Zhang et al. (2019b); Fernandez et al. (2023).\nThe above watermark methods are post-processing in nature, as the watermark is embedded on any given image $I$ that is already generated. There is an emerging line of in-processing watermark methods that directly modify the image generation process (Zhao et al., 2024; An et al., 2024), including TreeRing watermark (Wen"}, {"title": "Robustness of watermarking systems", "content": "Robustness of an image watermarking system refers to the extent of the watermark to remain detectable by the decoder $D$ when the watermarked image is manipulated (also called \"evaded\" if such manipulation is a deliberate attack). Thus, robustness is typically associated with the potential of a watermarking system to be applied to copyright protection and misinformation detection. To stress test the robustness of watermark systems, various watermark evasion techniques have been proposed. These techniques are broadly classified into white-box and black-box evasions, depending on whether any component of the watermark system is known to the evader (An et al., 2024). In this paper, we focus on black-box evasions where nothing about the watermark system is known, as in practice, companies tend to keep their watermark system private. Existing black-box evasions can be classified into two groups: Corruption methods try to distort watermarked images so that watermarks become corrupted and undetectable. Classical digital editing (e.g., applying Gaussian noise, Gaussian blur, JPEG compression, etc. (Voyatzis & Pitas, 1999)), the query-based adversarial attack (WevadeBQ) in Jiang et al. (2023) and the surrogate attack in Saberi et al. (2023) belong to this group; Purification methods treat embedded watermark patterns as noise signals and attempt to remove them using denoising and regeneration techniques, such as BM3D (Dabov et al., 2007), diffusion models (Saberi et al., 2023; Zhao et al., 2023) and VAE (Zhao et al., 2023). The rationale behind the purification methods is rooted in Eq. (3), where the original image, if recovered successfully, is always an evasion. In addition, the original image will be the ultimate threat to any watermarking system\u2014the watermark is evaded by an image without any loss of quality."}, {"title": "Our method: DIP for black-box watermark evasion", "content": null}, {"title": "Watermark evasion via DIP-based blind denoising", "content": "Deep Image Prior (DIP) refers to the technique of using untrained DNN as an implicit prior for natural images in solving image recovery problems, without training on massive data: for any natural image $I$, DIP parametrizes it as $I = G_{\\theta}(z)$, where $G_{\\theta}$ is typically a trainable convolutional neural network (CNN) and $z$ is a fixed input (typically randomly drawn). Now consider the canonical optimization-based formulation for image recovery problems:\n\n$\\min_{I} l(y, f(I)) + \\lambda R(I),$\n\nwhere $y \\approx f(I)$ is the observation model, $l(y, f(I))$ measures the recovery error, and $R(\\cdot)$ denotes regularization on $I$. DIP transforms the formulation into\n\n$\\min_{\\theta} l(y, f(G_{\\theta}(z))) + \\lambda R(G_{\\theta}(z)).$"}, {"title": "Watermark evasion via DIP-based blind denoising", "content": "Now, consider an arbitrary watermarked image $I_\\omega = E(I, w)$, where we do not know $E$ or $w$. Since $I_\\omega \\approx I$ as required in Eq. (3) and $I$ is clearly a successful invasion, it is sensible to try to \u201cpurify\u201d or \u201cdenoise\u201d $I_\\omega$ toward $I$-the intuition behind all purification methods for black-box evasion (Dabov et al., 2007; Saberi et al., 2023; Zhao et al., 2023).\nDIP has proven effective in single-image denoising, e.g., with Gaussian, impulse, shot noise, etc., when combined with appropriate early stopping strategies (Mataev et al., 2019; Jo et al., 2021; Li et al., 2021; Wang et al., 2021; Li et al., 2023a;b; 2024). In particular, when the noise level is low-which is true for typical watermarking systems as $I$ is supposed to be very close to $I$, a simple formulation with the standard mean-squared-error (MSE) loss and the additive noise model can perform \u201cblind\u201d simultaneous denoising for multiple types of noise Li et al. (2021); Wang et al. (2021). Inspired by this, we propose a simple DIP-based blind watermark-evasion formulation\n\n$\\min_{\\theta} ||I_\\omega - G_{\\theta}(z) ||_2^2,$(DIP-based watermark evasion)\n\nfor any given watermarked image $I_\\omega$. Unlike DIP-based blind denoising which requires appropriate early stopping strategies to find optimal denoising, we only need to check the evasion success of all iterates when iteratively solving Eq. (7) by querying the watermark decoder. Our whole algorithm pipeline is summarized in Algorithm 1. While we do not invent DIP-based blind denoising, we are the first to explore it for blind evasion of invisible watermarks. Rishik also performs DIP-based watermark removal, but solves it as image inpainting which requires known watermark patterns and locations."}, {"title": "Why including DIP-based evasion as a baseline method?", "content": "The primary obstacle for purification methods is that the \"noise\" patterns induced by watermark methods, especially those training-based ones, may not follow any simple noise model. Consequently, classical denoising methods that target specific noise types, such as BM3D, may struggle to remove the watermark. The recent regeneration techniques via diffusion models or VAE effectively perform learned denoising. However, a priori, it is unclear they can generalize well to novel watermark patterns. In contrast, our DIP-based evasion operates on a different principle: it leverages the different rates at which different frequency components are captured during DIP learning through Eq. (7), which has been consistently observed in prior DIP literature (Ulyanov et al., 2018; Shi et al., 2022a; Li et al., 2021; Wang et al., 2021). Specifically, the $G_{\\theta}(z)$ term in Eq. (7) picks up the low-frequency components\u2014which dominate natural images, much faster than picking up the high-frequency components\u2014which tend to be noise-induced, likely watermark-induced for our case."}, {"title": "Remarks on improving the query efficiency", "content": "Algorithm 1 often takes up to ~ 1000 iterative steps to solve Eq. (7). Querying the decoder using all intermediate iterates, as described in Algorithm 1, may be costly, and the decoder server may also limit query frequency for individual users to ensure safety and fairness. To reduce the number of queries and"}, {"title": "Qualitative and quantitative evaluation", "content": "Experiment setup (1) Datasets: We use images from two large-scale datasets: (i) MS-COCO (Lin et al., 2014) composed of 328K real images and (ii) DiffusionDB (Wang et al., 2022) composed of 14 million high-quality AI-generated images. We randomly sample 2000 images from each dataset the typical scale for the robustness evaluation of watermark systems (An et al., 2024), resize them to 512 \u00d7 512, and generate images with different watermarks, respectively; (2) Watermark methods: We focus on 6 representative and publicly available post-processing watermark methods: DwtDctSVD, rivaGAN, SSL, TrustMark, RoSteALS, and StegaStamp, whose watermark patterns vary in the visibility level and Fourier spectrum; see Figs. 3 and 6 and Table 1 for visual and quantitative comparisons, respectively. We also evaluate on the SOTA in-processing TreeRing watermark, where 2000 watermarked images are generated using Gustavosta stable diffusion prompts from HuggingFace (Santana); (3) Evasion methods: In addition to our DIP-based evasion method described in Algorithm 1, we also consider the following classical digital editing methods: (i) brightness, (ii) contrast, (iii) Gaussian noise, (iv) JPEG compression, (v) bm3d denoising, and recent SOTA purification methods: (vi) DiffPure (Saberi et al., 2023), (vii) Diffuser and (viii) VAE regeneration (Jiang et al., 2023).\nEvaluation protocol As we argue in Section 1 (see also An et al. (2024)), evasion success and image quality are two essential dimensions of watermarking systems. Therefore, we report the best image quality each evasion method can achieve while failing watermark detection. To find the \u201coptimal\u201d tradeoff image, we perform an exhaustive search over the allowable ranges of the hyperparameters for each evasion method and look for images with (i) watermark undetected and (ii) the highest PSNR value with respect to the watermarked image $I_w$; see Section 3.3 for justification on why $I_w$ is used and Appendix B for details about all hyperparameters. Finally, to quantify the quality of such images, we use three metrics: (i) PSNR, (ii) Structural Similarity Index Measure (SSIM) (Hore & Ziou, 2010) and (iii) 90% quantile of pixel-wise difference, all with respect to the clean image $I$. The quantile metric mainly serves as a supplement, as PSNR and SSIM focus on the average difference while it reflects the difference on the tail-watermark-induced distortion to an image may be highly localized and hence spatially sparse, which might not be captured by averaging metrics; see Fig. 3 and Table 1 for a sense of the visual and quantitative distortions caused by different watermark methods. Since the TreeRing watermark lacks a notion of clean image, we use $I_w$ as the reference in all evaluation experiments related to TreeRing watermark."}, {"title": "Conclusion and discussion", "content": "With the results and the analysis above, we can conclude that there is no universal best evasion methods for existing watermarking systems. In general, our DIP-based evasion is most effective in evading invisible watermarks that induce high-frequency distortions (e.g., DwtDctSVD, rivaGAN and SSL), and is partially successful in evading in-processing watermarks such as TreeRing. Its limited performance for RoSteALS and"}]}