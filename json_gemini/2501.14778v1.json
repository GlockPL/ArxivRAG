{"title": "ADVANCING TRUSTWORTHY AI FOR SUSTAINABLE DEVELOPMENT: RECOMMENDATIONS FOR STANDARDISING AI INCIDENT REPORTING", "authors": ["Avinash, Agarwal\u00b9", "Manisha, Nene\u00b2"], "abstract": "The increasing use of AI technologies has led to increasing Al incidents, posing risks and causing harm to individuals, organizations, and society. This study recognizes and addresses the lack of standardized protocols for reliably and comprehensively gathering such incident data crucial for preventing future incidents and developing mitigating strategies. Specifically, this study analyses existing open-access Al-incident databases through a systematic methodology and identifies nine gaps in current AI incident reporting practices. Further, it proposes nine actionable recommendations to enhance standardization efforts to address these gaps. Ensuring the trustworthiness of enabling technologies such as Al is necessary for sustainable digital transformation. Our research promotes the development of standards to prevent future Al incidents and promote trustworthy AI, thus facilitating achieving the UN sustainable development goals. Through international cooperation, stakeholders can unlock the transformative potential of AI, enabling a sustainable and inclusive future for all.", "sections": [{"title": "1. INTRODUCTION", "content": "The proliferation of AI technologies across diverse domains has led to rapidly increasing AI incidents ranging from algorithmic biases and deepfakes to system failures and unintended consequences. These incidents pose risks to individuals, organizations, and society, thus undermining overall trust and confidence in AI technologies. Recognizing the importance of addressing these risks, stakeholders are increasingly focusing on identifying, analyzing, and mitigating AI-related risks and harms.\nSustainable digital transformation, driven by innovative technologies such as AI, can accelerate progress towards the United Nations' Sustainable Development Goals (SDGs), for example by enhancing access to quality healthcare (SDG 3) [1], education (SDG 4) [2], managing water crisis and sanitation (SDG 6) [3], and climate change adaptation (SDG 13) [4], among other benefits. However, realizing this potential requires a concerted effort to ensure that AI technologies are deployed responsibly and ethically, with due consideration for their societal and environmental impacts.\nSeveral studies highlight that if not deployed responsibly and ethically, AI could impede the achievement of the UN SDGS [5, 6]. For instance, algorithmic biases in hiring processes could exacerbate inequalities in employment opportunities, thereby impeding progress toward SDG 8 (Decent Work and Economic Growth) and SDG 10 (Reduced Inequalities) [7].\nPrinciples of Responsible AI, such as those proposed by Organization for Economic Co-operation and Development (OECD), emphasize inclusive growth, sustainability, fairness, transparency, robustness, and accountability of AI systems [8]. Compliance with these principles can ensure that AI systems aid and do not hamper the achievement of UN SDGs. Standards, benchmarks, and standardized assessment procedures are needed to ensure that AI systems meet the responsible AI principles [9, 10]. Comprehensive data collected through different AI lifecycle stages and deployments in diverse scenarios drives the assessment of compliance with these responsible AI principles.\nLearning from past AI incidents is a crucial way to avoid repeat incidents. The aviation industry has well-established protocols for collecting aviation incident-related data. Systematically collecting and analyzing details of aviation incidents have resulted in continuous product improvement and mitigation strategies, leading to a drastic reduction in aviation accidents [11, 12]. Similarly, cybersecurity incident reporting is well-established and supported by regulations in many countries [13].\nTransparent disclosure of incidents, comprehensive compilation of AI incident data, and their systematic analysis can provide crucial data for developing mitigation strategies and promoting the deployment of trustworthy AI [14]. Against the backdrop of the UN SDGs, which seek to address pressing global challenges and promote sustainable development, the need for standardized AI incident reporting becomes even more pronounced. This paper identifies and addresses the critical gap in the availability of standards and protocols for systematic AI incident reporting and data sharing.\nIn light of these considerations, this paper explores the intersection of AI incident reporting, sustainable digital transformation, and the UN SDGs. By analyzing the current state of AI incident reporting, identifying gaps and challenges, and proposing recommendations for improvement, this"}, {"title": "2. LITERATURE REVIEW", "content": "The review shows that multiple definitions of \"AI incident\" are available.\nOECD [15] defines an \"AI incident\" as, \"an event where the development or use of an Al system: (i) caused harm to person(s), property, or the environment; or (ii) infringed upon human rights, including privacy and non-discrimination\".\nAccording to the AI Incident Database (AIID), an \"AI incident\" is \"an alleged harm or near harm event to people, property, or the environment where an Al system is implicated\" [16].\n'AI, Algorithmic, and Automation Incidents and Controversies' (AIAAIC) considers an \"incident\" in the context of AI as \u201ca sudden known or unknown event (or 'trigger') that becomes public and which takes the form of a disruption, loss, emergency, or crisis\u201d [17].\nThe review reveals the gap related to a lack of standard terms, definitions, and taxonomies.\nRecording AI incidents is crucial for understanding their impact on people, infrastructure, and technology, allowing the development of flexible regulations that evolve with new information and ensure the safe and effective use of AI technologies [18]. Sharing AI incidents improves the verifiability of claims in Al development, highlights overlooked risks, and enhances the effectiveness of external scrutiny by increasing common knowledge of potential AI system behaviors [19]. AI community is starting to recognize incident sharing as vital to prevent vulnerabilities, biases, and privacy concerns in AI systems, ensuring their trustworthiness and enhancing user experience [20]. Public databases cataloging global AI incidents promote awareness of potential AI harms among policymakers, researchers, and the public, essential for developing safe AI systems [21]. Collecting real-world failures in incident databases, such as those in mature industrial sectors like aviation, is crucial for informing safety improvements and preventing repeated mistakes in designing and deploying intelligent systems [22]. The collected AI incident data highlights unethical AI use, with top-ranking applications including language and computer vision models, intelligent robots, and autonomous driving, revealing issues like misuse, racism, and bias [23]."}, {"title": "2.1 AI incident definitions"}, {"title": "2.2 The need for AI incident reporting", "content": "Recording AI incidents is crucial for understanding their impact on people, infrastructure, and technology, allowing the development of flexible regulations that evolve with new information and ensure the safe and effective use of AI technologies [18]. Sharing AI incidents improves the verifiability of claims in Al development, highlights overlooked risks, and enhances the effectiveness of external scrutiny by increasing common knowledge of potential AI system behaviors [19]. AI community is starting to recognize incident sharing as vital to prevent vulnerabilities, biases, and privacy concerns in AI systems, ensuring their trustworthiness and enhancing user experience [20]. Public databases cataloging global AI incidents promote awareness of potential AI harms among policymakers, researchers, and the public, essential for developing safe AI systems [21]. Collecting real-world failures in incident databases, such as those in mature industrial sectors like aviation, is crucial for informing safety improvements and preventing repeated mistakes in designing and deploying intelligent systems [22]. The collected AI incident data highlights unethical AI use, with top-ranking applications including language and computer vision models, intelligent robots, and autonomous driving, revealing issues like misuse, racism, and bias [23]."}, {"title": "2.3 AI incident repositories", "content": "The AI Incident Database (AIID) [16] is among the earliest initiatives solely focused on documenting AI incidents. It compiles real-world harms or near harms caused by AI systems. Inspired by similar databases in aviation and cybersecurity, AIID aims to draw insights from past incidents to prevent or minimize future adverse outcomes. Another notable repository is the AIAAIC Repository [17], which compiles incidents and controversies driven by and relating to AI, algorithms, and automation. The AI Vulnerability Database (AVID) [24] is an open-source repository that aims to catalog failure modes for AI models, datasets, and systems. Its objectives include constructing a comprehensive taxonomy of potential AI harms spanning security, ethics, and performance dimensions and storing detailed information on evaluation use cases and mitigation techniques for each harm category. Another database, the AI Litigation Database (AILD) [25] compiles ongoing and completed legal cases concerning artificial intelligence, machine learning, and related fields, offering comprehensive coverage from complaints to verdicts. Further, the OECD.AI expert group is developing the AI Incidents Monitor (AIM) [26] to track real-time AI incidents for informing policy discussions. Unlike AIID and AIAAIC, AIM currently does not accept open submissions.\nExisting AI incident repositories rely on media coverage and voluntary public submissions, lacking robust mechanisms for technical input [18]. Taxonomies prioritize policy and ethics over technical details, while definitions of AI incidents remain inconsistent [21]. Moreover, there is a notable absence of federally operated databases, leaving incident reporting reliant on public sources and lacking mandatory legal disclosure and validation processes [21, 27]."}, {"title": "3. METHODOLOGY", "content": "The study adopted the following methodology:\n1. Executed an exhaustive search and literature review to discover AI incident repositories.\n2. Isolated four potential repositories: AIAAIC, AIID, AILD, and AVID. Given that AILD focuses on AI related legal aspects and AVID emphasizes identifying AI system vulnerabilities, shortlisted the two open-access repositories, AIID and AIAAIC, for further scrutiny.\n3. Examined the policies, scope, reporting procedures, and review mechanisms of the AIID and AIAAIC databases to comprehend their operational frameworks.\n4. Submitted an incident to each database to discern their reporting protocols and procedural intricacies.\n5. Retrieved and scrutinized publicly available data from both databases to evaluate their content and structure.\n6. Investigated the repositories to pinpoint gaps in standardization across various dimensions, including: incident reporting protocols, quality control, data interoperability, comprehensiveness of data, contributor and source diversity, sector-specific coverage, geographical coverage, and data sharing protocols.\n7. Tabulated observations and inferred key insights based on the conducted analysis.\n8. Formulated recommendations for standardization activities to address identified gaps and enhance the effectiveness of AI incident reporting practices."}, {"title": "4. RESULTS", "content": "This section presents the observations and results of the study. The next section analyses and draws inferences from them."}, {"title": "4.1 Incident reporting", "content": "Table 1 provides the basics of incident reporting in AIAAIC and AIID. Both have similar processes for incident reporting, though their scopes are slightly different."}, {"title": "4.2 AI-Incident snapshot", "content": "Sample incidents reported in AIAAIC, shortlisted for analysis, are listed in Table 2. These were extracted for analysis by filtering on the criteria \"Occurred\" = \"2024\" and \"Country(ies)\" = \u201cGlobal\u201d."}, {"title": "4.3 Interoperability and data sharing", "content": "Table 3 compares the data fields available in the two databases. They have different data structures."}, {"title": "4.4 Contributors to the Databases", "content": "Table 4 lists the top seven submitters of the published incidents in AIID. They reported more than 70% of all the incidents in AIID. AIAAIC does not have data fields to capture this data."}, {"title": "4.5 Sources of the reports submitted to the databases", "content": "Table 5 provides details of the top seven source domains of the reports submitted to AIID. AIAAIC does not have data fields to capture this data."}, {"title": "4.6 Sector Coverage", "content": "Table 6 details the top seven sectors of the incidents reported in AIAAIC. While AIID does not have data fields to capture this data, Table 7 provides details of the top seven deployers of the AI systems with incidents reported in AIID."}, {"title": "4.7 Geographical coverage", "content": "Table 8 lists the top seven countries related to the geographic origin and/or primary extent of the incidents reported in"}, {"title": "4.8 Data sharing", "content": "Table 9 outlines the formats available for downloading incident data from the two databases and the limitations on accessible data."}, {"title": "5. GAP ANALYSIS AND RECOMMENDATIONS", "content": "This section analyses the results to identify gaps in existing AI-incident reporting mechanisms and recommends areas for standardization and policy initiatives. These recommendations aim to address observed gaps, enabling meticulous AI-incident reporting and contributing to the achievement of the UN SDGs."}, {"title": "5.1 Lack of definitions and taxonomies", "content": "Observation: There is a lack of consistency in qualifying the reported events as incidents. The AIAAIC incidents with ids AIAAIC1449 [28] and AIAAIC1439 [29] cited in Table 2 relate to ethical practices and possible copyright infringement, but qualifying them as AI-incidents will depend on the definition of AI-incident. Similarly, incident id AIAAIC1395 [31] at s.no. 4 in Table (2) relates to the ethics of the authors and the screening processes followed by the journals and does not meet the AI-incident definition provided by OECD [15]. Also, it is challenging to determine the severity of the incidents based on the information available in both databases.\nInference: One significant gap is the absence of standardized definitions and taxonomies related to AI incidents and AI harms. It becomes challenging to compare and analyze incidents across different domains and jurisdictions without consistent guidelines for categorizing incidents, their harms, and severity levels.\nRecommendation 1:Standardise AI-incident and AI-harms taxonomies: Develop standard taxonomies for AI-incidents and AI-harms based on domain, severity, root causes, and impact on SDGs to enable consistent classification and analysis of AI-incidents across different sectors and jurisdictions, facilitating benchmarking and trend analysis."}, {"title": "5.2 Bias, inconsistencies, and misclassification", "content": "Observation: As mentioned in the previous paragraph, three of the incidents cited in Table 2 [28], [29], and [31] may not qualify as AI incidents depending on the definition considered. The reporting of incidents, their review, classification as incidents, and assessing their harm quotients being manual are prone to biases and capabilities of the individuals involved. Biases and inconsistencies in incident reporting can skew perceptions of AI-related risks and hinder efforts to develop inclusive and equitable solutions.\nInference: The AI-incident databases may suffer from the biases of the submitters or the reviewers related to attributes such as their political leanings, gender, minority groups, countries, and so on. Further, different individuals classify the incidents and their harms in distinct ways, depending on their exposure, capabilities, and understanding, which may lead to inconsistencies and misclassification.\nRecommendation 2: Define guidelines for AI-incident database quality audits: Formulate procedures to regularly audit the AI-incident databases for consistency, checking for misreporting, misclassification, reported incidents meeting the defined criteria, and so on."}, {"title": "5.3 Insufficient and incompatible data fields", "content": "Observation: Table 3 compares the columns available in the two databases, showing that only six fields are compatible between the two datasets, while the remaining are incompatible. Secondly, these databases do not have enough detailed data fields needed for thorough analysis, like identifying the causes, context, and impact of reported incidents. AIID does not have fields to capture impacted sectors (Table 6), impacted countries (Table 8), and so on. On the other hand, AIAAIC does not capture details of the harmed (or nearly harmed) parties the way AIID does, such as Facebook users, minority groups, patients, and so on.\nInference: Different and incompatible structures of AI incident databases make aggregating data from multiple databases difficult, limit interoperability, and restrict data exchange. Secondly, the captured data is generally insufficient for assessing the severity and proper categorization of the incidents.\nRecommendation 3: Standardise Al-incident database structures: Standardising the fields of AI-incident databases will ensure that the collected data has sufficient granularity required for analysis. It will also facilitate interoperability, data exchange, and ease of aggregating data from multiple databases."}, {"title": "5.4 Inadequate motive to report incidents", "content": "Observation: As indicated in Table 1, incident reporting in both databases is voluntary and lacks incentives. Without legal mandates or rewards, reporting relies on reporters' discretion and motivation, potentially resulting in underreporting.\nInference: Fears of data privacy breaches may discourage reporting, leading to incomplete or underreported AI incidents. Without transparent and privacy-protective reporting mechanisms, stakeholders may hesitate to disclose incidents, hampering the effectiveness of incident databases. Additionally, fragmentation among databases complicates data collection and analysis, impeding comprehensive risk understanding and response.\nRecommendation 4: Develop regulatory and policy frameworks for Al-incident reporting: Make sector-specific legal provisions to mandate or encourage AI-incident reporting. Global standards organizations such as ITU should develop standardized regulatory and policy frameworks for AI-incident reporting to enable consistency across nations."}, {"title": "5.5 Narrow base of the incidents reported", "content": "Observation: Though the incident reporting is open to the public, only a few individuals report the incidents. Table 4 indicates that just four individuals, excluding the anonymous ones, have reported half of the incidents in AIID. Further, the top sources of the reports submitted to AIID are from American or European newspapers, as detailed in Table 5.\nInference: Technological interventions and process reforms are required to widen the base of incident reporting.\nRecommendation 5: Develop standards for automated incident reporting: Develop standards to enable automated AI-incident reporting through the AI applications to supplement manual reporting."}, {"title": "5.6 Inadequate data-sharing protocols", "content": "Observation: As indicated in Table 9, the two databases allow downloading data in different formats, and both do not provide APIs for accessing data. Further, there is inconsistency related to the information accessible from the two databases (Table 9). The submitter names are accessible in AIID but not in AIAAIC. Similarly, AIID provides access to the details of the harmed parties, but in AIAAIC, harm data is only accessible to Premium Members.\nInference: Therefore, standardized mechanisms for sharing incident data among stakeholders, including government agencies, industry partners, researchers, and the public, are lacking. It impedes collaborative efforts to address emerging trends, root causes, and mitigation strategies for AI incidents.\nRecommendation 6: Standardise data sharing mechanisms: Define protocols for data sharing, access controls, and privacy protection to ensure the confidentiality and security of incident data. Establish mechanisms for sharing incident data among stakeholders, including government agencies, industry partners, research institutions, and civil society organizations."}, {"title": "5.7 Sectoral underrepresentation:", "content": "Observation: Existing AI-incident databases have skewed representations of application sectors. \"Media/entertainment/sports/art\" sector has the highest number of incidents reported in AIAAIC, followed by automotive and politics sectors, as illustrated in Table 6. Table 7 indicates that the maximum incidents reported in AIID relate to self-driving cars (Tesla, Cruise), social media (Facebook), search engines (Google), online shopping (Amazon), and advanced AI models (OpenAI).\nInference: While these databases predominantly report consumer-oriented sectors, they underrepresent critical infrastructure sectors such as telecom and electricity supply. The AI incidents in such sectors may not be as frequent as in the consumer-oriented sectors; however, it is still vital to maintain a repository of their incidents.\nRecommendation 7: Sector-specific AI-incident databases: Develop sector-specific AI-incident databases to supplement the general purpose AI-incident databases."}, {"title": "5.8 Demographic underrepresentation:", "content": "Observation: Table 8 shows that just three countries account for 60% of the incidents reported in AIAAIC. Similarly, the incidents reported in AIID predominantly relate to AI systems developed by American companies, as evident from Table 7. Further, the top sources of the reports submitted to AIID are from American or European newspapers, as detailed in Table 5.\nInference: Existing AI-incident databases particularly lack representation from developing and underdeveloped countries. Capturing AI incidents prevalent in these underrepresented regions is crucial for developing mitigation strategies. It is also essential in advancing the UN SDGs.\nRecommendation 8: ITU-led inclusive AI incident reporting: Encourage international collaboration facilitated by UN organizations, such as ITU, to establish standardized protocols for Al-incident reporting, prioritizing inclusivity from developing countries. This promotes comprehensive understanding and mitigation aligned with UN SDGs."}, {"title": "5.9 Lack of awareness:", "content": "Observation: As mentioned in the previous paragraphs and observed through Tables 4 and 5, the base of AI incident reporting is narrow.\nInference: The key stakeholders, including industry, academia, civil society, the general public, and policymakers, are largely unaware of AI-incident databases. Without active involvement from diverse perspectives, databases will fail to capture the full spectrum of AI-related risks and opportunities.\nRecommendation 9: Awareness programs: Hold regular campaigns to enhance stakeholders' awareness and understanding of AI incident reporting standards and best practices.\nThese standardization actions can enhance the effectiveness, transparency, and accountability of AI-incident reporting processes, thereby contributing to the achievement of the UN SDGs.\nIt is further recommended to include incident reporting as an integral part of the AI lifecycle so that it gets appropriate focus in the future. Figure 1 illustrates the conceptualized AI lifecycle stages to collect data for developing incident mitigation strategies."}, {"title": "6. CONCLUSION", "content": "In conclusion, this study highlights the critical need for standardized AI-incident reporting to enable data gathering, research, and development of mitigation strategies for preventing future incidents. Through an analysis of existing open-access AI-incident databases, it presents the key observations and gaps in standardization, underscoring the importance of policy and standardization initiatives in this domain. Table 10 summarises the gaps observed and the recommendations to overcome them."}]}