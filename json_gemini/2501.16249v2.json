{"title": "Lightweight Weighted Average Ensemble Model\nfor Pneumonia Detection in Chest X-Ray\nImages", "authors": ["Suresh Babu Nettur", "Shanthi Karpurapu", "Unnati Nettur", "Likhit Sagar Gajja", "Sravanthy Myneni", "Akhil Dusi", "Lalithya Posham"], "abstract": "Pneumonia is a leading cause of illness and death in children, underscoring the need for early\nand accurate detection. In this study, we propose a novel lightweight ensemble model for detecting pneumonia\nin children using chest X-ray images. Our proposed ensemble model integrates two pre-trained convolutional\nneural networks (CNNs), MobileNetV2 and NASNetMobile, selected for their balance of computational\nefficiency and accuracy. These models were fine-tuned on a pediatric chest X-ray dataset and combined to\nenhance classification performance. Our proposed ensemble model achieved a classification accuracy of\n98.63%, significantly outperforming individual models such as MobileNetV2 (97.10%) and\nNASNetMobile(96.25%) in terms of accuracy, precision, recall, and F1 score. Moreover, the ensemble model\noutperformed state-of-the-art architectures, including ResNet50, InceptionV3, and DenseNet201, while\nmaintaining computational efficiency. The proposed lightweight ensemble model presents a highly effective\nand resource-efficient solution for pneumonia detection, making it particularly suitable for deployment in\nresource-constrained settings.", "sections": [{"title": "I. INTRODUCTION", "content": "Pneumonia remains a critical global health concern,\naccounting for 14% of all deaths of children under five years\nold and claiming the lives of approximately 740,180 children\nin 2019 [1]. This burden is disproportionately high in\ndeveloping nations, where medical resources are scarce, and\nenergy poverty exacerbates health risks. In 2020, household\nair pollution is responsible for approximately 3.2 million\npremature deaths annually. Among these, 21% are due to\nlower respiratory infections (LRIs). Exposure to household air\npollution nearly doubles the risk of childhood LRIs and is\nresponsible for 44% of all pneumonia deaths in children under\nfive years old [2]. In such regions, the challenge is further\ncompounded by limited access to healthcare infrastructure and\nsevere shortages of medical personnel. For instance, there are\n57 countries that face a shortfall of 2.3 million doctors and\nnurses [3] [4].\nThe accurate and timely diagnosis of pneumonia is essential to\nimproving outcomes, especially in resource-constrained areas"}, {"title": "II. RELATED WORKS", "content": "In recent studies, various approaches have been explored to\nimprove pneumonia detection using deep learning\ntechniques, with the Kermany dataset [14] [15], a collection\nof children's chest X-ray images, being commonly utilized in\nthis research. In this section, we discuss the various research\nefforts conducted in this field, highlighting different\nmethodologies and models applied to the Kermany dataset."}, {"title": "A. PRE-TRAINED MODEL WITH TRANSFER LEARNING", "content": "Ayan et al. conducted a comparative study using this dataset,\nallocating 80% for training, 10% for validation, and 10% for\ntesting [16]. They fine-tuned VGG16 and Xception models,\nachieving accuracies of 87% and 82%, respectively [16].\nSimilarly, Thakur et al. employed the Kermany dataset with\n80% for training, 10% validation, and 10% testing and\nfocused on fine-tuning VGG16, which resulted in an improved\naccuracy of 90.54% [17]. Jain et al. also used the Kermany\ndataset but with a 90% training and 10% testing split [18].\nThey developed six models, including two custom models and\nfour pre-trained models (VGG16, VGG19, ResNet50, and\nInceptionV3). The custom models achieved validation\naccuracies of 85.26% and 92.31%, while the pre-trained\nmodels achieved accuracies of 87.28% (VGG16), 88.46%\n(VGG19), 77.56% (ResNet50), and 70.99% (InceptionV3)\n[18]. Chhikara et al. proposed a modified InceptionV3 model\nwith pre-processing techniques such as gamma correction,\nJPEG compression, median filtering, and CLAHE [19]. Using\nthe same dataset split (80% training, 10% validation, and 10%\ntesting), they demonstrated the effectiveness of their approach\nfor pneumonia diagnosis [19].\nIn contrast, Sara et al. employed InceptionV3 to extract\nfeatures from chest X-ray images and trained three\nclassification algorithms (K-Nearest Neighbor, Neural\nNetwork, and Support Vector Machines) on a Kaggle dataset\n[20]. Their Support Vector Machines model achieved the\nhighest AUC score of 93.1% [20]. El et al. extended their study\nby combining the Kermany dataset (5,856 images) with an\nadditional dataset of 231 COVID-related images [21]. They\nallocated 60% of the combined data for training and 40% for\nvalidation. Their work involved various pre-trained models,\nincluding InceptionV3, DenseNet201, VGG19, Xception,\nVGG16, InceptionResNetV2, MobileNetV2, a customized\nCNN, and ResNet50. Using data augmentation, MobileNetV2\nand InceptionResNetV2 achieved accuracies of approximately\n96% [21]. Knock et al. adopted a transfer learning approach\nusing VGG16, splitting the dataset into 90% for training and\n10% for testing. Their model achieved an accuracy of 94%\n[22]."}, {"title": "B. CUSTOM DEEP LEARNING TECHNIQUES", "content": "Liang et al. designed a novel network architecture with\nresidual structures to learn the effective texture\ncharacteristics of lung tissue [23]. The network consists of\n49 convolutional layers with ReLU activation, followed by a\nsingle global average pooling layer and two dense layers.\nUsing 90% of the data for training and validation and 10%\nfor testing, their model achieved an accuracy of 90.5% [23].\nStephen et al. proposed a CNN with four convolutional\nlayers, using 63.5% of the data for training and 36.5% for\nvalidation, achieving an accuracy of 93.7% [24]. Raheel et\nal. developed an 18-layer Deep Convolutional Neural\nNetwork, allocating 89.7% of the data for training, 0.3% for\nvalidation, and 10% for testing [25]. Their model achieved\nan accuracy of 94.3%, with sensitivity and specificity of"}, {"title": "C. ENSEMBLE TECHNIQUE", "content": "To\u011fa\u00e7ar et al. utilized existing CNN models such as\nAlexNet, VGG-16, and VGG-19 as feature extractors,\nspecifically using the last fully connected layer of each\nmodel [31]. These extracted features were then fed into\nmachine learning models, including Decision Trees (DT), k-\nnearest Neighbors (kNN), Linear Discriminant Analysis\n(LDA), Logistic Regression (LR), and Support Vector\nMachines (SVM). Feature selection was performed using the\nmRMR method, and the best results were achieved by\ncombining all features from mRMR, with an accuracy of\n99.41% using the Kermany dataset (70% training, 30%\ntesting) [31]. Chouhan et al. proposed an ensemble model\nthat combined the outputs from several pre-trained models,\nsurpassing the performance of individual models [32]. This\nensemble, which included Inception V3, ResNet, AlexNet,\nGoogleNet, and DenseNet121, achieved state-of-the-art\nresults with an accuracy of 96.4% and a recall of 99.62% on\nthe Kermany dataset, using a 90% training and 10% testing\nsplit [32].\nHashmi et al. introduced a novel weighted classifier\napproach that optimally combined predictions from several\nstate-of-the-art deep learning models, including ResNet18,\nXception, InceptionV3, DenseNet121, and MobileNetV3\n[33]. The weighted classifier model achieved a test accuracy\nof 98.43% and an AUC score of 99.76% on the Kermany\ndataset, with 88.05% training and 11.95% testing [33]. El\nAsnaoui et al. focused on ensemble models fine-tuned from\nInceptionResNetV2, ResNet50, and MobileNetV2 [34]. In\ntheir experiments, they used two datasets: the first containing\n5856 images from the Kermany dataset and the second\ncontaining only 231 images. They found that\nInceptionResNetV2 performed best as a single model, with"}, {"title": "III. METHODOLOGY", "content": "The proposed lightweight ensemble model for pneumonia\ndetection is illustrated in Figure 1. The preprocessing of the\npneumonia dataset is carried out first, ensuring the input\nimages are ready for transfer learning. Three lightweight pre-\ntrained CNN models, namely NASNetMobile, MobileNetV2,\nand EfficientNetB0, were selected for this study. These pre-\ntrained models are enhanced by freezing initial layers and\napplying modifications such as GlobalAveragePooling2D,\nDropout, and BatchNormalization, with Dense layers and a\nSigmoid activation for classification. Next, these models are\nfine-tuned and evaluated on the dataset. Then, the top two\nperforming models were selected to implement the weighted\nensemble approach. The individual predictions, P1 and P2,\nfrom these models are then combined, with each prediction\nbeing assigned a weight (W1 and W2, respectively) to\noptimize the overall accuracy of the ensemble. Finally, the\nweighted ensemble model is developed using the optimal\nweights and comprehensively evaluated, effectively\ncombining the strengths of the two selected CNN architectures\nfor accurate pneumonia detection. In this section, we will\ndiscuss the key components of the methodology."}, {"title": "A. DATASET", "content": "Kermany et al. developed the dataset by collecting chest X-\nray images of patients under 5 years of age at Guangzhou\nWomen and Children's Medical Center [14] [15]. The\ndataset comprises 5856 images with varying resolutions\nranging from 400p to 2000p. It includes 4273 images of\npneumonia cases and 1583 images of normal cases. The\ndataset is utilized for training, and the performance of\nvarious transfer learning models is evaluated. Some of these\nimages are shown in Figure 2. For effective model training\nand evaluation, the dataset was divided into two parts: 90%\nof the images were allocated for training, while the\nremaining 10% were allocated for testing. As the next step,\nimage pre-processing techniques and augmentation\nstrategies were applied to enhance the quality and variability\nof the dataset, ensuring it was well-suited for effective model\ntraining and evaluation."}, {"title": "B. IMAGE PRE-PROCESSING AND AUGMENTATION", "content": "In computer vision tasks, image pre-processing plays a vital\nrole in preparing data for model training. Pre-processing\ntechniques enhance model performance by addressing key\nfactors such as noise reduction, image normalization, and\nresizing. These steps are especially critical for CNNs, which\ndepend on consistent input dimensions and appropriately\nscaled pixel values. In our work, pixel intensity normalization\nwas applied to scale the pixel values to the range [0, 1]. This\nstep is essential for stabilizing the training process and\nfacilitating efficient model convergence, allowing the model\nto learn patterns effectively without being affected by\nvariations in image brightness or contrast.\nFurthermore, the images were resized to ensure compatibility\nwith the input dimensions required by the network. This\nresizing step is crucial for maintaining consistency across the\ndataset, particularly when utilizing pre-trained models that\nmandate fixed input sizes. The choice of 224x224 pixels aligns\nwith widely adopted practices in computer vision, as these\ndimensions are used in models such as MobileNetV2,\nNASNetMobile, and EfficientNetB0. This ensures not only\ncompatibility but also efficient training and inference.\nTo enhance dataset diversity and simulate real-world\nvariations, we applied image augmentation, a critical step for\nbuilding a more resilient model and minimizing overfitting.\nOur approach involved implementing a range of\ntransformations, including rotation, width and height shifts,\nshear, zoom, and brightness adjustments. For example, slight\nrotations and positional shifts enabled the model to identify\nfeatures from varying perspectives, while brightness and zoom\nmodifications allowed the model to generalize across different\nlighting conditions and scales. These augmentations ensure\nthat the model learns more robust and adaptable features,"}, {"title": "C. TRANSFER LEARNING", "content": "We employed a transfer learning approach to fine-tune pre-\ntrained CNN models, MobileNetV2, EfficientNetB0, and\nNASNetMobile, for Pneumonia detection. These models were\noriginally trained on ImageNet, a large-scale dataset\nconsisting of 1.28 million natural images across 1,000\ncategories. Utilizing the feature representations learned from\nextensive datasets like ImageNet reduces the reliance on large\namounts of labeled data, which is often limited during\npandemics. It also enabled quick adaptation to the specific task\nwhile improving diagnostic accuracy. Choosing transfer\nlearning offers a scalable and cost-effective solution for\nenhancing Pneumonia detection, effectively addressing\nchallenges related to data scarcity and limited resources. In\nthis study, we applied transfer learning to specifically include\nlightweight CNN models, which are specifically designed to\nmeet the unique needs of mobile and edge devices."}, {"title": "D. TRANSFER LEARNING WITH LIGHTWEIGHT\nMODELS", "content": "Lightweight CNN models have a significantly reduced\nnumber of parameters, with smaller model sizes, faster\ndetection speeds, and lower memory usage. They are\nparticularly effective in medical image analysis, such as\ndetecting lung pathologies, tumors, and heart conditions,\nwhere accurate and fast diagnoses are crucial [35]\n[36][37][38]. Their ability to operate efficiently in low-cost,"}, {"title": "E. MOBILENETV2", "content": "MobileNetV2, introduced by Sandler et al. (2018) [39], is a\nCNN architecture specifically designed for mobile and\nembedded vision applications. It employs an inverted residual\nstructure with shortcut connections between compact\nbottleneck layers, which effectively reduces the number of\nparameters while enhancing computational efficiency. The\narchitecture begins with a 32-filter convolutional layer,\nfollowed by 19 bottleneck layers that enable the construction\nof deeper networks without significantly increasing the size of\nintermediate layers. MobileNetV2 is particularly well-suited\nfor tasks demanding efficient performance, such as image\nsegmentation, object detection, and real-time inference on\nmobile and edge devices [40] [41] [42] [43] [44] [45]."}, {"title": "F. EFFICIENTNETBO", "content": "EfficientNet is a convolutional neural network (CNN)\narchitecture that introduces compound scaling, which\noptimally balances the width, depth, and resolution of the\nnetwork to improve performance while maintaining efficiency\n[46]. EfficientNet is particularly well-suited for tasks requiring\na balance of high accuracy and computational efficiency, such\nas image classification, object detection, and transfer learning,\nmaking it ideal for deployment on both resource-constrained\ndevices and high-performance systems [47] [48] [49] [50] [51]\n[52] [53] [54] [55]. Width scaling applies a feature map to each\nlayer, depth scaling increases the number of layers in the\nnetwork, and resolution scaling enhances the input image\nresolution [56]. The EfficientNet family comprises eight\nvariants, ranging from EfficientNet-B0 to EfficientNet-B7.\nThe architecture we chose for this study is EfficientNet-B0,\nwhich incorporates the (Mobile Inverted Bottleneck"}, {"title": "G. NASNETMOBILE", "content": "The NAS (Neural Architecture Search) [57] framework,\ndeveloped by Google, is a scalable CNN architecture designed\nusing reinforcement learning to configure its fundamental\nbuilding blocks. Each cell comprises a small set of operations,\nsuch as convolutions and pooling, which are replicated\nmultiple times to meet the required network capacity. Its\nlightweight variant, NasNetMobile, features 12 cells\ncontaining 5.3 million parameters and 564 multiply-\naccumulate operations, making it highly efficient for mobile\nand resource-constrained environments. NasNetMobile is\nparticularly well-suited for tasks requiring efficient\nperformance, including image classification, object detection,\nand real-time inference on mobile and edge devices [58] [59]\n[60] [61] [62]."}, {"title": "H. FINE-TUNING PRE-TRAINED MODELS", "content": "After selecting lightweight pre-trained CNN architectures, we\nfine-tuned them for the Pneumonia detection task. By\nleveraging pre-trained CNN architectures, we retained several\nof their initial layers, which were frozen to preserve the\ngeneral features learned from ImageNet. Freezing these layers\nensured that their weights were not updated during training on\nthe new dataset. This prevented the model from overwriting\nessential, general-purpose feature representations such as\nedges, textures, and basic shapes learned from the diverse\nImageNet dataset. The final classification layer was replaced\nwith new layers tailored specifically for Pneumonia detection.\nOnly these newly added layers were left unfrozen, allowing\ntheir weights to be updated during training. This targeted fine-\ntuning strategy improved task-specific performance for\nPneumonia detection while maintaining computational\nefficiency. The fine-tuning approach we implemented is\ndepicted in Figure 3.\nAs illustrated in Figure 3, the custom layers we added include\na global average pooling layer to summarize the learned\nfeatures. This layer reduces the spatial dimensions of the\nfeature maps, improving computational efficiency and helping\nprevent overfitting by generating compact feature\nrepresentations [63]. A dropout layer is also incorporated to\nmitigate overfitting by randomly omitting a portion of the\nunits during training. Dropout serves as a regularizer, forcing\nthe network to rely on a subset of neurons, which has been\nshown to enhance generalization by simulating a bagged\nensemble of neural networks [64]. Additionally, a batch\nnormalization layer is used to improve training stability and\nspeed by normalizing the output of each layer, ensuring zero\nmean and unit variance [65]. This technique helps accelerate\nconvergence and stabilize the learning process. To introduce\nnon-linearity, the ReLU (Rectified Linear Unit) activation"}, {"title": "I. ENSEMBLE LEARNING", "content": "Ensemble learning has proven to be an effective approach for\nimage classification, as it combines the predictions of multiple\nclassifiers to achieve superior performance compared to\nindividual classifiers. These models take advantage of the\nunique strengths of each classifier, enhancing accuracy and\nrobustness by capturing different features of the data while\ncompensating for their individual strengths and weaknesses.\nBagging, boosting, and stacking methods are commonly used\nto build ensemble classifiers. Bagging, or Bootstrap\nAggregating, creates diverse models by training each classifier\non a bootstrapped subset of the training dataset. Boosting, on\nthe other hand, iteratively improves weak learners by focusing\nmore on misclassified examples, thereby boosting their\nperformance over successive iterations. Stacking uses a meta-\nclassifier that combines the predictions of base classifiers,\nutilizing these outputs as inputs to produce a higher-level\nrepresentation of the data. By integrating multiple classifiers,\nensemble learning provides a promising way to advance image\nclassification, effectively improving performance. Ensemble\nmethods are resistant to noise and overfitting, making them\neffective for complex, noisy image datasets. As a result,\nensemble learning has become increasingly popular in various\ncomputer vision tasks, including medical image analysis and\nobject recognition. However, it is important to note that\nensemble learning may incur higher computational costs and\nresource demands due to the need for training and combining\nmultiple models. To address these challenges, we selected\nlightweight models, which are more computationally efficient\nyet capable of yielding superior ensemble performance."}, {"title": "J. WEIGHTED AVERAGE ENSEMBLE MODEL", "content": "In this study, we employed a weighted ensemble technique to\nenhance the classification performance for pneumonia. In\norder to implement this, we initiated a comprehensive model\nselection and training process. After training the three\nlightweight pre-trained deep learning models, namely\nEfficientNetB0, MobileNetV2, and NASNetMobile, their\nperformance is evaluated. Based on individual model\nperformance, we selected the top two models, MobileNetV2\nand NASNetMobile, which demonstrated better prediction\naccuracies compared to the other models. Therefore, these two\nmodels were chosen as foundational models and combined to\nimplement a weighted average ensemble (WAE) model. The\nWAE approach was chosen to leverage the strengths of\nindividual models and to enhance the overall predictive\ncapability. The weights for each base classifier's prediction\nwere determined to maximize the WAE model accuracy.\nThe calculation of the WAE model predictions is shown in\nEquation 2. The WAE model prediction is represented as"}, {"title": "1) Evaluation", "content": "We evaluated the performance of our proposed WAE model\nin comparison to the fine-tuned models, assessing their\neffectiveness in pneumonia detection using key metrics,\nincluding accuracy, recall, precision, F1 score, the area under\nthe ROC curve, and the confusion matrix. These metrics\nprovide a comprehensive evaluation of each model's ability to\ndistinguish between pneumonia-positive and normal cases,\noffering insights into class-specific performance and overall\nclassification effectiveness. This thorough evaluation enabled\na clear comparison between the fine-tuned models and our\nproposed WAE model.\nAccuracy:\nAccuracy is an evaluation metric that measures the ratio of\ncorrect predictions (both true positives and true negatives) to\nthe total number of predictions. It provides an overall\nassessment of each model's performance, as shown in\nEquation 4. Accuracy is calculated using the following\ncomponents: TP (True Positives), TN (True Negatives), FP\n(False Positives), and FN (False Negatives)."}, {"title": "IV. RESULTS", "content": "We conducted the experiments using Google Colab, utilizing\nCPU resources, 51 GB of RAM, and 225.8 GB of disk space.\nPython 3 and relevant libraries, including Scikit-Learn, Keras,\nand TensorFlow, were used to implement the proposed\nweighted average ensemble model. The pre-trained\nlightweight models, specifically MobileNetV2,\nEfficientNetB0, and NASNetMobile, were loaded from Keras,\neach initialized with ImageNet weights, and the top two\nperforming models were incorporated into the WAE model for\nenhanced performance. We trained the three pre-trained\nlearning CNN models using 5,270 normal and pneumonia\npatient X-ray images.\nFor model compilation, we used the Adam optimizer with a\nlearning rate of 1e-4, combined with a binary cross-entropy\nloss function, which is suitable for binary classification tasks.\nTo improve the training process, we incorporated several\ncallbacks. Early stopping was applied to prevent overfitting by\nmonitoring the validation loss and restoring the best weights if\nno improvement was observed after five epochs. We also\nimplemented a learning rate reduction strategy, which adjusts\nthe learning rate by a factor of 0.5 when a plateau in validation\nloss is detected, with a minimum learning rate of le-6.\nAdditionally, model checkpointing was used to save the best-\nperforming model based on validation loss, ensuring the\nretention of the most effective model after training. The\ntraining process was carried out on the augmented data for 20\nepochs with a batch size of 16, utilizing the specified callbacks\nto optimize both performance and training efficiency. We\ncompared the performance of the fine-tuned CNN model with\nour proposed WAE using 586 images, consisting of 423\nPneumonia-infected and 163 non-infected images. The\nmodels were evaluated based on various metrics outlined in\nthe methodology section.\nBefore implementing the ensemble model, we evaluated the\nthree lightweight fine-tuned CNN models to select the top two\nmodels with the highest accuracy. The accuracies of the\nmodels are presented in Table 3."}, {"title": "V. Discussions", "content": "The superior performance of our proposed weighted average\nensemble (WAE) model, combining MobileNetV2 and\nNASNetMobile, can be attributed to the complementary\nstrengths of these architectures and the benefits of the\nensemble approach. MobileNetV2, with its lightweight\narchitecture, achieves efficient feature extraction using\ndepthwise separable convolutions and inverted residuals. This\ndesign enables MobileNetV2 to capture fine-grained features\nwhile maintaining low computational overhead, making it\nparticularly effective for scenarios requiring precision and\nefficiency. Conversely, NASNetMobile, developed through\nNeural Architecture Search (NAS), specializes in identifying\ntask-specific optimal architectures, enabling it to analyze\nintricate patterns such as fine-grained anomalies and texture\nvariations in medical imaging datasets.\nAs demonstrated by the results, the WAE approach leverages\nthe strengths of these models through a weighted combination\nof predictions, optimizing accuracy and robustness. The use of\nweighted averaging, with weights determined based on\nvalidation performance, ensures a balanced contribution from\neach model, addressing their individual limitations. This\nensemble is particularly valuable in medical imaging\napplications, where diverse feature extraction is critical for\naccurate classification. Our WAE approach reduces the risk of\noverfitting by combining the diverse learning patterns of\nMobileNetV2 and NASNetMobile, each excelling in distinct\nfeature representations. By integrating these architectures, the\nWAE model avoids over-reliance on dataset-specific features,\nthereby enhancing its ability to generalize to unseen data. This\nimproved robustness is reflected in the WAE model's superior\nevaluation metrics, underscoring its capability to provide\naccurate and reliable predictions.\nOne notable advantage of the WAE model, as demonstrated\nby our results, is its ability to address the challenges posed by\nclass imbalance. The WAE model achieves substantial\nimprovements in precision, recall, and F1-score for the\nunderrepresented NORMAL class compared to individual\nmodels. This balanced performance across both classes\nhighlights the ensemble's capability to leverage the\ncomplementary strengths of MobileNetV2 and\nNASNetMobile.\nDespite the promising results, our study has limitations that\nwarrant further exploration in future work. The model was\ntrained and evaluated on a single dataset, the Kermany dataset,\nwhich was chosen for its high-quality, well-curated, and\nwidely recognized collection of chest X-ray images. While the\ndataset is an excellent foundation for our current study, it may\nnot fully capture the diversity of image conditions,\ndemographic variations, and disease patterns seen in real-\nworld clinical settings. Variations in imaging equipment,\npatient populations, and environmental factors could impact\nthe model's performance when applied to different healthcare\nenvironments. In the future, we plan to prioritize evaluating\nthe model's adaptability and robustness across larger and more\ndiverse datasets to ensure broader applicability.\nFurthermore, while our study focuses on binary classification\n(pneumonia vs. normal), extending the model to multi-class\nclassification tasks, such as distinguishing between different\ntypes or severities of pneumonia, could significantly enhance\nits clinical relevance. Real-time testing and collaboration with\nhealthcare professionals are also crucial to evaluate the\nmodel's practical utility and usability in diagnostic workflows.\nAlthough our study meets its primary objectives of improving\npneumonia detection, future work should investigate the\nperformance of the proposed weighted average ensemble\napproach on larger, more diverse datasets to assess its"}, {"title": "VI. CONCLUSION", "content": "In this study, we proposed a novel weighted average\nensemble (WAE) model for pneumonia detection in X-ray\nimages, which combines the complementary strengths of two\nlightweight pre-trained models, MobileNetV2 and\nNASNetMobile. By leveraging these models, we achieved\nsignificant performance improvements over individual\nmodels, with an accuracy of 98.63% and precision, recall,\nand F1-score of 98.66%, 98.63%, and 98.64%, respectively.\nOur proposed ensemble model outperformed several pre-\ntrained complex architectures, demonstrating its potential for\nreal-time, resource-efficient applications in medical\nimaging. We highlighted the ensemble approach's\neffectiveness in balancing model strengths and weaknesses,\nproviding superior performance while maintaining lower\ncomputational requirements compared to more complex\nmodels. The weighted averaging mechanism further\noptimized prediction accuracy, enhancing the overall\nperformance of the model. In future work, we plan to explore\nadvanced optimization techniques, expand the model's\napplicability to larger and more diverse datasets, and\ninvestigate its potential across different healthcare domains."}]}