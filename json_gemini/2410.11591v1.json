{"title": "PASTE: IMPROVING THE EFFICIENCY OF VISUAL ANOMALY DETECTION AT THE EDGE", "authors": ["Manuel Barusco", "Francesco Borsatti", "Davide Dalle Pezze", "Francesco Paissan", "Elisabetta Farella", "Gian Antonio Susto"], "abstract": "Visual Anomaly Detection (VAD) has gained significant research attention for its ability to identify anomalous images and pinpoint the specific areas responsible for the anomaly. A key advantage of VAD is its unsupervised nature, which eliminates the need for costly and time-consuming labeled data collection. However, despite its potential for real-world applications, the literature has given limited focus to resource-efficient VAD, particularly for deployment on edge devices. This work addresses this gap by leveraging lightweight neural networks to reduce memory and computation requirements, enabling VAD deployment on resource-constrained edge devices. We benchmark the major VAD algorithms within this framework and demonstrate the feasibility of edge-based VAD using the well-known MVTec dataset. Furthermore, we introduce a novel algorithm, Partially Shared Teacher-student (PaSTe), designed to address the high resource demands of the existing Student Teacher Feature Pyramid Matching (STFPM) approach. Our results show that PaSTe decreases the inference time by 25%, while reducing the training time by 33% and peak RAM usage during training by 76%. These improvements make the VAD process significantly more efficient, laying a solid foundation for real-world deployment on edge devices.", "sections": [{"title": "1 Introduction", "content": "Visual Anomaly Detection (VAD) is a computer vision task that aims to identify images containing anomalies and pinpoint the specific pixels within the image responsible for the anomaly (see examples in Fig. 2). This is performed using the unsupervised learning paradigm, avoiding the costly label collection phase necessary for pixel-level anomaly tagging.\nVAD has many applications in various fields, such as manufacturing, medicine, and autonomous vehicles [1-3]. However, its relevance is limited by the constraint of its deployment in real-world environments. Most of the current literature focuses on VAD performance as the only important metric, excluding other practical considerations regarding memory, inference time, and processing power. However, in most real-world application scenarios, it is not unusual that VAD algorithms run on edge devices with limited resources, making it challenging to deploy complex deep learning models typically used in VAD, such as WideResNet50 [4]."}, {"title": "2 Related Work", "content": "In this work, we provide a benchmark for resource-efficient VAD (also known as tinyAD) by testing the most well-known VAD methods in the literature, considering relevant metrics for edge deployment. This is crucial for real-time applications and deployments in environments where resources are limited. To perform this study, we consider lightweight networks that enable the implementation of VAD on edge devices (see Fig. 3), these networks are often constrained in terms of processing power, memory, and energy consumption.\nMoreover, we address the method's weaknesses by proposing a new algorithm called Partially Shared Teacher-student (PaSTe). This new algorithm is based on the Student-Teacher Feature Pyramid (STFPM) [5] approach and is intended for edge deployment. It aims to run on tiny devices by reducing the required computational resources. With our approach, applied to four different resource-efficient backbones, we achieve up to 87% reduction in training memory and 50% reduction in computation compared to the original STFPM. The trade-off is a slight decrease in performance on some backbones, while others remain unaffected or even improve. We prove the feasibility of deploying AD methods on the edge and the superiority of PaSTe over STFPM by evaluating with the MVTEC dataset, the most well-known VAD dataset, which consists of ten objects and five textures.\nOur contributions can be summarized as follows:\n\u2022 We test several edge architectures in the context of VAD;\n\u2022 We propose a novel AD algorithm specifically designed for the edge, called PaSTe;\n\u2022 We compare several edge architectures and VAD methods, providing a benchmark for resource-efficient VAD by evaluating using the well-known MVTec dataset.\nThe outline of the paper is as follows. In Section 2, we describe the VAD algorithms present in the literature and the relevant developments in edge-oriented neural networks. In Section 3, we introduce the proposed framework for tinyAD and the specific method, PaSTe, proposed to reduce resource consumption on the edge of STFPM. In Section 4, we describe the experimental setup for all the AD methods and tiny backbones considered. Finally, in Section 5, we present our findings before concluding in Section 6."}, {"title": "2.1 Visual Anomaly Detection", "content": "AD approaches find many applications in Computer Vision (CV) where safety is crucial, encompassing manufacturing, the medical domain, autonomous vehicles, security systems, and more [1-3]. In fact, identifying anomalous samples helps users in their decision-making process. In addition, recent approaches focused on providing interpretability."}, {"title": "2.2 Deep Learning for the Edge", "content": "Designing and deploying edge neural networks has been a topic that recently attracted significant attention [17-19]. Common strategies differ on the basis of their trade-off and design principles. Neural network designs based on Neural Architecture Search (NAS) [20, 21] achieve a good performance-complexity trade-off but require extensive search-space exploration. In NAS-based techniques, models are trained with varying hyperparameter configurations and evaluated on a held-out validation set [22]. This operation is very costly, as it requires sequential network training. Faster alternatives that concurrently train multiple networks include super-networks [23, 24] and strategies based on the lottery-ticket hypothesis [25]. These methods are more computationally efficient. However, they are difficult to adapt to advanced training strategies (e.g., using the network's latent representation during training).\nOn the other hand, efficient neural architecture designs do not require ad hoc training and pruning strategies but rely on provably efficient operations (e.g., convolution micro-factorizations). These designs are usually parametric, and their hyper-parameters scale the computational budgets according to design-specific patterns. In this paper, we explore efficient designs based on various optimizations. MobileNetV2 [26], MCUNet [27], PhiNet [28] leverage the inverted residual block sequence of pointwise, depthwise, and pointwise convolutions to reduce the memory footprint of the model. Despite these designs being based on the same computational block, their scaling strategies differ, resulting in diverse performance-complexity trade-offs. MobileNetV2 scales the number of input and output channels of the"}, {"title": "3 Methodology", "content": "In this section, we present the methodology proposed in this manuscript. Specifically, Sec. 3.1 presents the general approach to bringing AD methods into real-world applications on tiny devices by changing the feature extractor from a heavy architecture to a lightweight neural network. Then, in Sec. 3.2, we describe our resource-efficient AD algorithm based on the STFPM approach."}, {"title": "3.1 General Approach", "content": "In the AD literature, current state-of-the-art approaches are feature-based methods, which exploit the representations produced by a pre-trained model. Although the proposed AD methods differ significantly from each other, a common component of all these approaches is that they are based on a feature extractor (see Fig. 3a).\nAD approaches are developed and tested using large models such as WideResNet50 [4], thus without considering the challenging scenario of deploying AD for edge inference.\nTherefore, to make it more feasible to deploy the AD algorithms on edge, we propose replacing the heavy feature extractor used in the AD methods with a light feature extractor (see Fig. 3). Our first goal is to analyze the features"}, {"title": "3.2 Partially Shared Teacher Student (PaSTe)", "content": "Changing the feature extractor used in each AD method allows significant reductions in the required resources, helping them to be deployed on tiny devices. However, modifying each algorithm with specific considerations could help bring such methods to even smaller devices. Specifically, in this work, we propose a modified version of STFPM, called Partially Shared Teacher-student (PaSTe), which significantly reduces the required resources such as memory and computation.\nThe STFPM approach passes the input image through a Teacher network and a Student network. The Teacher network is typically pre-trained, while the Student network is trained to mimic the teacher's output. During the process, the features extracted at various levels from the Teacher and Student are compared (denoted as \\(F_t\\) for the teacher and \\(F_s\\) for the student) across different layers. The comparison aims to identify discrepancies between the Teacher and Student representations, which could indicate anomalies (see Fig. 4a for an overview). However, one of the major drawbacks of STFPM is that it requires storing two full architectures in memory and performing backpropagation across both. This significantly increases memory usage and computational complexity."}, {"title": "4 Experimental Setting", "content": "This work introduces a benchmark to evaluate visual tiny anomaly detection in real-world environments, specifically focusing on resource-constrained devices (Edge computing). Therefore, Sec. 4.1 provides information on all edge models tested, while Sec. 4.2 give implementation details of all the AD methods that use such backbones. Then Sec. 4.3 describes the dataset used to evaluate AD algorithms and Sec. 4.4 describes all the metrics considered to compare the AD methods. Finally, Sec. 4.5 describes how the layers used for the feature extractor were chosen for each backbone.\nTo evaluate the performance of the AD methods with different feature extractor backbones, we need to make sure that the pre-trained models have all been trained on the same dataset. Specifically, we used the available weights of the models trained on ImageNet for the classification task. Moreover, every feature extractor backbone is trimmed to the last considered layer to save resources."}, {"title": "4.1 Deep Learning models for Edge", "content": "MobileNetV2: available in PyTorch, we used the version pre-trained on ImageNet [31] available in TorchVision.\nMCUNet: PyTorch based implementation of the MCUNet-in3 network pre-trained on ImageNet available on the official GitHub repository [32].\nPhiNet: PyTorch-based implementation trained on ImageNet, the source code is available in the MicroMind repository [33]. Specifically, the hyperparameters of the considered PhiNet are: num_layers=7, alpha = 1.2, beta = 0.5, t0 = 6.\nMicroNet: PyTorch-based implementation of the MicroNet-m1 network pre-trained on ImageNet. The network weights are available on the official GitHub repository [34]; the architecture code has been refactored by ourselves. Among all the available versions of the MicroNet, PhiNet, and MCUNet models, we chose the version with the same input size and similar MACs as the MobileNetV2 model."}, {"title": "4.2 AD methods", "content": "PatchCore: tested by considering the default training and evaluation parameters [35]. The memory bank size is the default one, and the random projection applied to the feature vectors is performed with the same parameters.\nCFA: tested by adapting the components of the method to the different feature extractor backbones. Specifically, the Patch-Descriptor network has been dynamically adapted to the dimensions of the feature vectors extracted by the considered backbones. The other training parameters, such as batch size, optimizers, and so on, are the same as the original implementation [36]\nPadim: tested by considering the default training and evaluation parameters [10]. The memory bank size is the default one, and the random projection applied to the feature vectors is also performed with the same parameters.\nSTFPM: all hyper-parameters are the same as the original [37], except when using the MicroNet-m1 backbone, where the learning rate of SGD optimizer had to be lowered to 1/10 the original one due to training instability, and to compensate for that the number of epochs was multiplied by 10."}, {"title": "4.3 Dataset", "content": "The MVTec Anomaly Detection (AD) dataset is a real-world dataset and is the most well-known dataset in literature to evaluate VAD algorithms [1]. This dataset encompasses ten objects and five textures, making it suitable for assessing various AD techniques' robustness and generalization capabilities. Specifically, the MVTec AD dataset contains over 5,000 images, encompassing 15 different object categories, such as bottles, cables, capsules, and wood (see some examples in Fig. 2)."}, {"title": "4.4 Evaluation metrics", "content": "Various evaluation metrics are commonly employed to assess the performance of AD techniques. In general, the evaluation metrics can be image-level or pixel-level. Image-level metrics determine if the whole image is anomalous, while pixel-level metrics assess how well the model could identify the anomalous parts of the image. For both image and pixel levels, ROC AUC and F1 metrics are usually considered. As the main metric for assessing the anomaly segmentation performance, we decided to choose the F1 pixel level metric, which is a robust metric when there is an imbalance in pixel classes: the typical scenario in Visual Anomaly Detection where a lot of pixels are normal and only a small portion of them is anomalous. Furthermore, the F1 pixel level score is the strictest metric, so a high score on this metric guarantees a high score on the other metrics as well.\nThis work introduces a benchmark to evaluate visual tiny anomaly detection in real-world environments, specifically focusing on resource-constrained devices (Edge computing). Therefore, we move beyond the AD performance, and report other important metrics for edge such as the AD Model memory footprint and the inference MACs (multiply-accumulate operations). Specifically, the memory footprint represents the memory occupied by the feature extractor but also by additional components used by the AD method, such as the memory bank for PatchCore, Padim, and CFA, as well as additional architectures like the Student for STFPM and the PatchDescriptor for the CFA."}, {"title": "4.5 Feature Extraction Layers Selection", "content": "Depending on the chosen layers to perform feature extraction, different performances and levels of granularity can be obtained. For example, the first layers of every CNN extract very low-level features but with the highest granularity. In contrast, the last layers extract high-level features that are more related to the dataset where the CNN is trained, but they also have worse granularity. Therefore, we will evaluate the different architectures by performing a grid search on the layer groups used for feature extraction by considering both low-level and high-level layers.\nFor every feature extractor, we have defined groups of layers with a low, middle, high depth. The choice of the layers for every group has been defined based on the total number of layers and by considering a minimum \"distance\u201d between the layers to vary their receptive fields starting from the \"center\" backbone layer. For example, for MobileNetV2, which has a total of 18 layers, we defined the mid-level group of layers by considering the center layer (more or less layer with index 10), and by considering an offset of 3 layers, we considered the others: 7 and 13. The low-level and high-level layers are [4,7,10] and [10,13,16], respectively, by applying the same offset and criteria to the left and right. All the combinations of feature extractor layers considered in the experiments are reported in Tab. 1.\nWideResNet50, which is commonly used in AD methods, examines the features produced by three different layers, each at different depths and granularities. Intuitively, this is a good strategy, since the anomalies vary in size. Therefore, considering features extracted from different layers simultaneously is essential to evaluate anomalies by exploiting different receptive fields. Therefore, in our analysis, we defined an equivalent feature layers group, which"}, {"title": "5 Results", "content": "Sec. 5.1 shows the results of our benchmark, where we use lightweight neural networks to allow AD methods to be deployed on the edge. Then, Sec. 5.2 investigates deeply how the chosen layers of the feature extractor affect the final performance. Eventually, Sec. 5.3 discusses how our novel algorithm, PaSTe, reduces the resources required by the STFPM approach."}, {"title": "5.1 Lightweight Neural Networks vs Standard AD Methods", "content": "As discussed in Sec. 2, the current AD methods reached optimal results in the field. However, there is a lack of consideration of how these methods behave in devices with constrained resources, such as edge devices. Therefore, our first contribution is to evaluate how the main AD methods behave when considering limited resources. To achieve this, we change the backbone used in feature-based methods, moving from a large backbone like WideResNet50, commonly used in the literature, to lightweight neural networks like MobileNetV2.\nIn Tab. 3, a comparison is provided in terms of performance and required resources between AD methods when using the WideResNet50 as feature extractor or a MobileNetV2 with equivalent layers (a comparison table with all edge backbones is provided in the Supplementary Material \u00b9). It is fundamental to consider that each AD method has its peculiarities that cause some methods to be more memory-consuming or computing-consuming compared to others. Therefore, the optimal AD method will be decided based not only on the AD performance but also on the resources available on the target edge device.\nIn general, we can see that all AD methods perform well on edge, with similar AD performance compared to the corresponding methods with WideResNet50. For example, PatchCore obtains 0.57 and 0.53 for WideResNet50 and MobileNetV2 respectively. However, other AD methods receive even less impact by changing the underlying backbone. For instance, STFPM achieves the same WideResNet50 performance using MobileNetV2.\nFurthermore, the same or similar performance obtained with WideResNet50 is achieved with a significant reduction in resources (model memory footprint and inference MACs) when using MobileNetV2. For example, when considering memory, MobileNetV2 reduces the PatchCore memory footprint significantly from 300MB of WideResNet50 to 31MB. However, this value could still be too demanding for many tiny devices, so other methods like CFA and STFPM could be preferred with, respectively, 6.2MB and 5.3MB. However, while CFA and STFPM appear to be the lightest among the studied approaches and with similar memory usage, when considering the inference time, the STFPM is around six times smaller, making the optimal choice for real-time applications.\nIn general, we provide a benchmark by evaluating several edge backbones such as MobileNetV2 MCUNet, MicroNet, and PhiNet on state-of-the-art AD methods such as PatchCore, Padim, CFA, and STFPM. In Fig. 1 for each Backbone and method, the results are shown, with the y-axis representing the F1 pixel level performance, the x-axis the memory (log scale), and the size of each point representing the MACs. As is notable in the figure, all the lightweight neural networks show similar performance, though each one requires a different level of resources. The only exception is the MicroNet architecture, which shows low results. This is because such a network, even if considered in its biggest version, is much smaller than the other edge models tested. Therefore, while edge architectures proved to be fitted to be used to deploy AD methods on edge, a careful selection needs to be considered, since a too small network could not be able to produce enough rich representations for the AD algorithms. Moreover, based on the resources available, some methods could be preferred to others.\nIn conclusion, adopting edge architectures leads to substantial memory and inference reductions. For example, STFPM achieves a 35-fold decrease in memory usage and a 4-fold reduction in inference requirements. Even more impressive is CFA, which lowers inference operations from 36.89 GMACs to 2.8 GMACs, a 13-fold reduction, and decreases memory usage by a factor of 23. Similarly, PatchCore reduces memory consumption by 9.6 times and inference demands by 4.4 times. Most notably, Padim delivers the most significant improvements, slashing memory usage from 3.72 GB to just 31.1 MB, representing a 75.4-fold reduction. However, even more significant is the inference reduction factor of x224. This is due to the fact that the Mahanabolois distance has cubic complexity with respect to the"}, {"title": "5.2 How the chosen layers affect the performance", "content": "After demonstrating that AD methods on edge devices can achieve performance comparable to their counterparts with heavy backbones, we investigate deeply how the layers chosen for feature extraction affect performance. Specifically, we defined groups of layers as low, middle, and high based on their depth. The first layers have the advantage of being the ones with more granularity, but they are also the ones with very generic features. In contrast, the last layers extract high-level features that are more related to the dataset where the CNN is trained, but they also have worse granularity. Furthermore, we consider an equivalent group of layers, which attempts to select layers from the lightweight backbone in the same proportion of MACs as considered in WideResNet50 by the original AD methods. This group of layers actually considers a wide range of layers, covering low, middle, and high depths. Fig. 5 shows the results for each backbone and group of layers. Each row represents a backbone with the groups of low, middle, high, and equivalent layers considered (highlighted with symbols L, M, H, and E), and in the column, the results for each category are shown (by averaging the AD methods), while the color represents the variance in performance with respect to the AD methods considered. In particular, the categories shown on the x-axis are ordered from those with the smaller anomaly sizes to those with the larger ones. For example, the screw object contains anomalies of sizes around 50 times smaller than the metal nut object.\nFrom an initial analysis, observing the last column, all, gives us an idea of the performance in all categories, where similar performance is achieved for each backbone and layer, except for MicroNet, which is too limited, as discussed in the previous section. However, a difference emerges when examining the categories individually. The first observation is that, in general, for all the backbones, categories with larger anomalies have better performance, while the smaller ones perform worse.\nIn particular, while objects with bigger anomalies don't have notable differences among backbones and layers, this does not hold for smaller anomalies, like for screw and grid items. In fact, in this case, we can observe that the WideResNet50 has the best overall performance, demonstrating that when considering very small anomalies, larger backbones still have an advantage over edge backbones. Furthermore, for detecting small anomalies, the low-level layers play a crucial role because they have a very small field of view and because of the low-level features (such as angles, lines, and so on) that are extracted from them. Among the low, middle, and high groups, the low group of layers is better than the other groups for every tiny backbone, as shown in Fig. 5.\nHowever, the best results for small anomalies are usually observed when the analysis is considered the equivalent layer group as in the case of MobileNetV2 and MCUNet backbones. This suggests that the additional information of middle-level and high-level layers can improve the detection, though considering low layers remains fundamental. Therefore, in general, a good solution to identify both small and large anomalies seems to involve selecting a group of feature extraction layers that contains a combination of low-, middle- and high-depth layers, as originally considered for WideResNet50."}, {"title": "5.3 PaSTe", "content": "For this reason, in this work, we propose an efficient version of STFPM called PaSTe. PaSTe works by reusing the same weights of the first layers of the teacher for the student architecture to bypass computation on these since we can copy the features extracted by the teacher and paste it as the input of the student network. The first layers are usually the ones with the fewest weights and the most expensive in terms of backward-pass computing and RAM during training. As is visible from Tab. 2, where we compare STFPM with PaSTe using MobileNetV2 as the backbone, the inference time is reduced by 24.9% compared to STFPM, from the original 454.4MMAC to the 341.2MMAC of PaSTe. Instead, the memory footprint of the model does not see great improvement and is reduced by 3.9%, from the original 5.32MB to 5.11MB.\nMoreover, during training, the computation is reduced from the original 297.5MMAC of STFPM to 198.4MMAC of PaSTe, with a reduction of more than 33%. In addition, when considering the RAM usage required by training, our method requires only 22.9MB compared to 96.15MB of STFPM, with a reduction of 76.2%. Therefore, our method can significantly reduce the required resources, making it more viable for deployment at the edge compared to STFPM.\nSimilar improvements are achieved for the MobileNetV2, PhiNet, and MCUNet backbones. Fig. 6 shows a clear improvement in terms of computing and RAM memory resources, while having almost no negative impact on performance, which actually improves in some backbones.\nInstead, MicroNet shows limited gains. The first reason is due to the results on the MicroNet backbone, which are not comparable to the other backbones, where its extremely compact size already sits ad its resource-efficiency limits. This is because its original layer configuration of [2, 3, 5] translates to [3, 4, 5] when adapted to PaSTe, resulting in the freezing of few layers. Consequently, the potential for improvement is minimal with such limited layer adjustments.\nThese advantages are achieved while achieving similar performance or, in the case of some backbones like MobileNetV2, even better performance. Indeed, with MobileNetV2, STFPM achieves 0.52 f1 pixel-level compared to 0.53 of PaSTe. Furthermore, the performance for small anomalies appears to be slightly improved with PaSTe (see the results of the PaSTe approach for each category and the backbone in the Supplementary Material 2). This is justified by the fact that the first layers are important, but choosing layers too close to the input could be damaging, further motivating the freezing of such layers in PaSTe."}, {"title": "6 Conclusion", "content": "Visual Anomaly Detection is an important field that aims to identify anomalous images and the specific parts inside the image that are abnormal. This is performed with an unsupervised paradigm, avoiding the costly label collection phase, especially for the pixel-level granularity. This work provides a benchmark for TinyAD, where visual anomaly detection is studied for resource-constrained devices. This work impacts many domains, such as manufacturing, medicine, and autonomous vehicles. However, edge devices often have limited resources, making it challenging to deploy complex deep learning models typically used in VAD. The benchmark uses lightweight neural networks, such as MobileNetV2 and PhiNet, and explores various anomaly detection approaches, including PatchCore, CFA, Padim, and STFPM, analyzing their suitability for edge devices. Specifically, several edge architectures are implemented,"}, {"title": "6 Conclusion", "content": "proving their ability to significantly reduce memory and computation constraints, making AD algorithms more feasible for deployment on the edge in small devices.\nIn addition, we introduce a novel algorithm called PaSTe, which addresses the memory and computational limitations of the traditional STFPM method, making it more scalable and efficient for edge deployment. The idea is that initial layers are not so fundamental in the final performance. Therefore, these weights are frozen and used for both the teacher and the student architecture. PaSTe can reduce more than half the training time and more than four times the RAM for training while obtaining the same performance and reducing the inference time by 30%. Evaluating all the methods and architectures on the well-known MVTec AD Dataset proves the feasibility of AD algorithms for edge and the superiority of memory-efficient STFPM to STFPM.\nWhile this work proved the feasibility of AD approaches on the edge, there are several promising research directions. For example, while this work significantly reduced the memory and processing power usually considered for Visual Anomaly Detection, further work is necessary to reduce the resources consumed to run AD algorithms on tiny devices even further. Moreover, a further insight from this work is that these methods, in the context of tiny AD, struggle when considering objects with very small anomalies, such as screws. Therefore, an interesting research direction will be to improve the performance of these objects. Furthermore, we don't know how edge architectures behave in modified scenarios compared to larger architectures. For instance, we do not know how they can behave in noisy settings or when in the presence of a data stream."}]}