{"title": "Detecting Emotional Incongruity of Sarcasm by Commonsense Reasoning", "authors": ["Ziqi Qiu", "Jianxing Yu", "Yufeng Zhang", "Hanjiang Lai", "Yanghui Rao", "Qinliang Su", "Jian Yin"], "abstract": "This paper focuses on sarcasm detection, which aims to identify whether given statements convey criticism, mockery, or other negative sentiment opposite to the literal meaning. To detect sarcasm, humans often require a comprehensive understanding of the semantics in the statement and even resort to external commonsense to infer the fine-grained incongruity. However, existing methods lack commonsense inferential ability when they face complex real-world scenarios, leading to unsatisfactory performance. To address this problem, we propose a novel framework for sarcasm detection, which conducts incongruity reasoning based on commonsense augmentation, called EICR. Concretely, we first employ retrieval-augmented large language models to supplement the missing but indispensable commonsense background knowledge. To capture complex contextual associations, we construct a dependency graph and obtain the optimized topology via graph refinement. We further introduce an adaptive reasoning skeleton that integrates prior rules to extract sentiment-inconsistent subgraphs explicitly. To eliminate the possible spurious relations between words and labels, we employ adversarial contrastive learning to enhance the robustness of the detector. Experiments conducted on five datasets demonstrate the effectiveness of EICR.", "sections": [{"title": "Introduction", "content": "Sarcasm detection aims to endow machines with the ability to identify the emotional reversal between the literal word and its true intention about the given statement. This task holds significant potential to benefit various real-world applications, such as sentiment analysis (Chen et al., 2024b), social opinion analysis (Okawa and Iwata, 2022), and political intent identification (B\u00fclow and Johann, 2023). According to Joshi et al. (2017), the key to sarcasm detection is to discern subtle incongruity in the statement. The simple cases of sarcasm typically involve only the shallow meaning of the text. For example, an obvious sarcastic statement like \u201cI am so happy that the car broke down\" uses the word 'happy', but the author is unhappy because the car 'breakdown'. However, sarcasm on social platforms often arises from complex real-world scenarios, making it less manifest and more difficult to detect (Oprea and Magdy, 2020). It involves complex background knowledge and social relationships, where simple word matching is insufficient to grasp the full semantic meaning (Li et al., 2021). As shown in Figure 1, Trump's sarcastic intentions need to be deduced from multiple relevant clues in the contexts, i.e., implicit commonsense knowledge \"Trump aborted PA\u201d and \u201cTrump and Biden are hostile\". Here, commonsense knowledge refers to the well-established fact and emotional causality that people are familiar with. Although they do not appear in the statement, it is hard to find the incongruity without them due to the incomplete context. Detecting such complex sarcasm requires a comprehensive understanding of the semantics in the statement and even resorting to external commonsense to make inferences. However, research"}, {"title": "Methodology", "content": "We first give the problem definition of sarcasm detection. Suppose we have a set of training samples, where each sample consists of a given statement S and its corresponding label y. Specifically, y = 1 if the statement is sarcastic, and y = 0 represents non-sarcastic. To enhance S with relevant context, we utilize a retrieval-augmented GPT-40 to provide the commonsense knowledge C. We aim to train a novel sarcasm detection model F that can precisely identify incongruity across texts as follows,\n\u0177 = F(S,C|\u03b8),\nwhere \u03b8 denotes all the trainable parameters of F and \u0177 is the probability distribution. Subsequently, we present the commonsense reasoning model for detecting emotional incongruity, as depicted in Figure 2. This model integrates RAG-based commonsense augmentation, graph-based incongruity reasoning, and adversarial contrastive learning."}, {"title": "RAG-based Commonsense Augmentation", "content": "To supplement the indispensable commonsense required for sarcasm detection, we resort to retrieval-augmented LLMs, which has demonstrated the capability to generate reliable knowledge. In particular, we first employ NLTK to extract the entities Es = {e1,2,..., en} from the given statement S, where Ne denotes the number of entities. We then employ the general web search engine Bing to retrieve entity-related content and select the Top-N relevant passages P = {P1,P2,...,pn} as candidate corpus for LLMs. However, the retrieved passages might inevitably introduce noise harmful to LLMs. To alleviate this problem, inspired by Zhang et al. (2023), we devise a hybrid noise filter to improve the quality of generated commonsense knowledge. We employ the BERT-BM25 Hybrid method to calculate the BM25 keyword matching score fbm25 and the BERT-based semantic similarity score fbert between each passage and statement S. The final score is obtained by weighted computation of the two scores as follows,\nfbebm = \u03b1/(1+ e-fbm25)+(1-a) fbert,\nwhere a is a hyper-parameter and passages will be filtered if the fbebm is less than the predefined threshold \u20ac. After that, remained passages Pf will be fed into the BART Encoder (Lewis et al., 2019) incorporating an additional multi-head pooling layer to get the representation of passages Rp. To ensure the efficiency of training, we freeze the parameters in LLMs and adopt prompt-tuning (Radford et al., 2021) to generate statement-related commonsense knowledge C. Thereby, based on Rp, we employ a prompt builder which consists of a cross-attention network and a feed-forward network to create the retrieval-augmented prompt as follows,\nPra = MHA(DMq; RpMk; RpMv),\nPra = LN(Pra' + FFN(Pra)),\nWhere D is a trainable length controller with a fixed length ID, each M represents a projection matrix, MHA denotes multi-head attention, and LN stands for layer normalization. The LLMs take as input the concatenation of the retrieval-augmented prompt Pra, the task-specific prompt Pts, and the entities embedding PE, collectively denoted as Pim = [Pra||Pts||PE]. The task-specific prompt Pts is a predefined instruction: \u201cPlease provide reliable commonsense knowledge related to this statement and its relevant passages.\" To control irrelevant noise, the maximum number of generated commonsense C is constrained to Nc, a hyper-parameter. Since lacking corresponding labels, we manually review commonsense quality and analyze the effectiveness of commonsense in section 3.3."}, {"title": "Graph-based Incongruity Reasoning", "content": "To capture the complex correlations across multiple texts, we employ graph structures, which are well-suited for modelling long-range dependencies. However, existing methods fail to find fine-grained incongruity due to the incomplete graph topology and poor inferential ability. To address this problem, we introduce a graph refinement strategy to capture robust associations and utilize an inference module to retrieve the incongruity subgraphs. We further supplement the overall context features to prevent over-reliance on the inference skeleton.\nGraph Construction. To capture the syntactic dependency relations between the statement and commonsense, we first transform each piece of text into an undirected graph using Spacy, denoted as Gi = {Vi, Ei} (Lou et al., 2021). Here, Vi represents the meaningful concepts in the text, while Ei denotes the set of syntactic dependency edges. We then construct a commonsense-augmented graph G through the off-the-shelf technique by (Zhu et al., 2021) for effectively aligning the concepts. To better learn the topology, we define Ad\u2081 = 1 if there is an edge between nodes vi and vj, where Ad is the dependency adjacency matrix. Additionally, each node includes a self-loop, denoted as A = 1.\nGraph Enrichment. To augment the semantic associations in the dependency graph, inspired by Zhao et al. (2021), we design a graph enrichment mechanism by employing the metric learning to obtain the semantic matrix Ase. This promotes interactions among sparsely connected long-tail nodes, which enhances the capabilities of EICR to discover subtle incongruities. The learning rule is formulated as Eq.(4),\nAijse = {\u03c8se(hi, hj),\u03c8se(hi, hj) \u2265 \u03b4,0 Use (hi, hj) < d,\nwhere hi is the node embedding encoded by Bi-LSTM, 8 is a threshold to control sparsity and se(.) is the B-head weighted cosine similarity as follows,\n\u03c8se(hi, hj) =1/\u03b2\u03a3i=1\u03b2cos(wsehi, wsehj),\nwhere denotes Hadamard product and wse is a trainable parameter. The message propagation matrix is computed as Ap = Ase Ad. The semantic-enriched matrix A is then formed by combining Ap and Ad, represented as \u0100 = Ap \u2295 Ad.\nGraph Pruning. To learn the task-optimal graph topology, we adopt a meta-path-based edge pruning strategy, which efficiently removes noisy edges. An optimal graph topology should retain the relevant edges and be conducive to achieving effective sarcasm detection. Thus, we focus on sampling Top-L meta-path neighbors based on the enriched graph, subject to certain constraints. In particular, we first define the edge weight coefficient w of node j to the center node v, as follows,\n\u03c9\u03c5\u03c4\u03ae =exp(\u03c3(Mw[hv||hj]))\u03a3j\u03b5\u03bd exp(\u03c3(\u039c\u03c9[hv||hj]))'\u03a6\nwhere N denotes the nodes connected with v through meta-path \u03a6 and Mw is the learnable matrix. Then we employ a linear programming strategy to perform the sampling process, formulated as argmaxo\u2208c (O\u00b7 ML). Here O is the one-hot sampling pointers, M\u00b2 is the weight matrix constructed by L interactions of computation. To ensure the one-hot property and sorting reasonableness of Top-L, the constraint C is denoted as Eq.(7),\nC = {\u03a3j Oj = 1, \u2200j \u2264 L,Oi(j+1) \u2265 O, \u2200i < D,\nwhere D represents the number of meta-path neighbors. Subsequently, we merge the sampling pointers from each \u03a6 to form the pruned matrix \u00c2. Due to the non-differentiability of one-hot and Top-L operations, the perturbed maximum strategy (Berthet et al., 2020) is employed during the training stage, as Eq.(8). This strategy allows for gradient-based optimization by introducing controlled randomness, enabling effective learning in scenarios where traditional backpropagation would fail.\nOv = Eu[argmaxo\u2208c<O, M\u00b2 + VU)],\nwhere & controls the proportion of injected Gaussian Noise U. Finally, we incorporate Of into \u00c2 to get the matrix Aopt, which represents the task-optimal graph topology of the refined graph G.\nIncongruity Reasoning. To grasp the fine-grained incongruity in the refined graph G, we propose a novel reasoning skeleton, which incorporates inference rules as prior knowledge. These inference rules come from multiple disciplines such as psychology (Michel et al., 2022) and sociology (Klomberg et al., 2024), helping the model better understand the diverse sarcasm patterns. Nevertheless, these rules are not scalable and are difficult to integrate into EICR. To address this problem, we leverage these rules to fine-tune the entailment checker based on pre-trained RoBERTa-large (Liu et al., 2019). In the skeleton, we first separate multiple paths between the same node pair with special tokens  to a single input sequence. We then input them into the entailment checker as conditions and conclusions, respectively, to generate predicted logits for each group of paths. Here, the logits correspond to three results: contradiction, neutral, and entailment. We sample the node pairs with the contradiction logit as the suspicious incongruity subgraphs Gs. Relying solely on extracted subgraphs may lose some important context. Thus G and Gs are fed into hierarchical graph attention(HGAs) (Wang et al., 2019) simultaneously to learn multi-grained incongruity features as follows,\nIe = Mmpl(M'sem (Mnod(Il-1, GS, N\u00ae\u00ae))),\nIc = Mmpl(M'sem (Mnod(Il\u2212\u00b9, \u011e, N))),\nwhere Mhod and M sem represent the hierarchical attention mechanisms in the l-th layer of HGAs, while Mmpl and Ns denote max-pooling and the meta-path neighbor sets in G\u00ba, respectively. To balance multi-grained features, a gating strategy combines global context and local incongruity into the final feature If, formulated as If = yIc+(1\u2212y)Ie, where y is a hyper-parameter. This enables robust performance by integrating both perspectives. The feature If is then fed into a single-layer MLP to predict its probability distribution \u0177 as \u0177 = Softmax(MLP(If)). Finally, cross-entropy loss Lsd is used for classification as Eq.(10),\nLsd = -(y log(\u0177) + (1 \u2212 y) log(1 \u2013 \u0177))."}, {"title": "Adversarial Contrastive Learning", "content": "To learn robust representations, we employ supervised contrastive learning (Kim et al., 2020), which aims to pull together samples with the same label and push apart those with different labels. Further, to mitigate the spurious correlation and reduce sensitivity to local knowledge, we introduce adversarial gradient perturbations in the feature space to construct augment instances in the feature space. The perturbation process is applied to the commonsense node embeddings He as Eq.(11),\nHcLsd = Hc + HcVu||HcVLsd||,\nwhere V is the derivation operator, u is a validation controller and He is perturbed commonsense. Compared with direct delete or substitute words, the gradient-based perturbation can maintain the original semantics of commonsense. Thereafter, H' along with statement representations are fed into the Graph-based Incongruity Reasoning Network to get the perturbed incongruity feature I'. So far, the sarcastic set As contains If and I'f in the same batch. The same is true in the non-sarcastic set An. Finally, the supervised contrastive learning loss (Khosla et al., 2020) is computed as Eq.(12),\nLcl = -1\u03a3\u03b9\u03b5\u03bb log(exp(sim(If,I+)/T)\u03a3\u03c4jel\u03b7exp(sim(If,IF)/T)),\nwhere It is the sarcastic samples and I\u012b is the non-sarcastic samples. T is a temperature parameter to adjust the smoothness of the shrinkage distribution and sim() denotes the cosine similarity function. The learning objective is to train the framework by jointly minimizing the two losses derived from sarcasm detection and adversarial supervised contrastive learning. The overall loss is written as,\nL = Lsd + \u03bb\u00a3cl,\nwhere X is a hyper-parameter to control the weight of contrastive learning in the overall loss function."}, {"title": "Evaluations", "content": "We conducted experiments with qualitative and quantitative analyses to evaluate our approach."}, {"title": "Data and Implementation Details", "content": "We conducted our experiments on five benchmark datasets, including Ghosh (Ghosh and Veale, 2017) which was collect from Twitter and annotated automatically, Reddit (Khodak et al., 2018) that only contained political content, IAC-V2 (Oraby et al., 2017) which was obtained from Internet Argument Corpus and designed for analyzing sarcastic remarks, iSarcasm (Oprea and Magdy, 2020) that encompassed tweets which were written by online users and SemEval2018 (Van Hee et al., 2018) collected using hashtags from SemEval 2018 Task 3. The statistics of datasets are shown in Table 1. Our experiments were conducted using Pytorch and ran on four NVIDIA GeForce 3090 GPUs. For the passages filtering, we utilized the embedding from the BERT-based model and set the balanced hyper-parameter a to 0.4 and the threshold e to 0.95. To learn the semantic relationships, we set the sparse-controlled hyper-parameter 8 to 0.95. The number of \u03b2-head in Eq.(5) was set to 3. For the adversarial contrastive loss, the temperature parameter 7 was set to 0.07. The training batch size was fixed at 8, and we took Adam as the optimizer with a learning rate of 0.001."}, {"title": "Model Comparison", "content": "We compared our method against eight mainstream models, including (1) MIARN (Tay et al., 2018) and SAWS (Pan et al., 2020), which were representative attention-based methods and identified sarcasm based on the input text features; (2) ROBERTa (Liu et al., 2019), which served as a strong baseline by capturing nuanced contextual and linguistic features; (3) SarDeCK (Li et al., 2021), a competitive BERT-based method that utilized COMET to supplement commonsense knowledge and enriched context via attention networks; (4) ADGCN (Lou et al., 2021), a GCN-based model that fused features from the dependency graph and sentiment graph to discern incongruity; (5) DC-Net (Liu et al., 2022), which modeled literal and implied sentiments separately to recognize sentiment conflict; (6) SD-APRR (Min et al., 2023), an incongruity reasoning model that employed a denoising module based on a commonsense-augmented dependency graph; (7) SensoryT5 (Zhao et al., 2025), which integrated sensory knowledge into the T5 framework's attention mechanism to facilitate sensory-emotional interactions; (8) SarcasmCue (Yao et al., 2024), which introduced a prompting framework that elicited LLMs to detect sarcasm by considering sequential and non-sequential prompting methods. Our approach was evaluated against the baseline methods illustrated in Table 2. We observed that (1) EICR achieved state-of-the-art performance across five public benchmarks in most settings, demonstrating its effectiveness in sarcasm detection; (2) Baseline methods exhibited relatively low Ma-F1 scores on the iSarcasm dataset, likely due to the imbalanced label distribution. In contrast, EICR demonstrated strong robustness in handling such imbalances; (3) Compared with RoBERTa and SarDeCK, our proposed commonsense reasoning perspective fully captured the sentiment incongruity across contexts; (4) The performance gains observed over SarcasmCue suggested that solely prompting LLMs led to hallucinations. Our retrieval-augmented strategy effectively mitigated this issue, as further confirmed by the superior results compared to SensoryT5, which highlighted the combined impact of noise filtering; (5) When compared to ADGCN, EICR highlighted the supplementation of comprehensive commonsense and the ability for commonsense inference instead of directly representing the entire graph for detection; (6) As opposed to DC-Net and SD-APRR, the novel"}, {"title": "Ablation Studies", "content": "We performed extensive ablation studies to verify the effectiveness of our proposed key modules, including (1) RetA that omitted retrieval-augment strategy and solely relied on the GPT-4o; (2) ComA that removed the entire commonsense-augmented module and only based on the statement; (3) RefG that dropped the graph refinement strategy; (4) ReaS that discarded the reasoning skeleton and depended on the features extracted by GCNs; (5) AdCL threw away the adversarial contrastive loss. As depicted in Figure 3, the ablation studies provided meaningful insights into the effectiveness of various components in EICR, including (1) RetA performed worse than EICR. This indicated solely LLMs may be influenced by hallucinations, which will generate noise and make reasoning difficult; (2) ComA caused the terrible performance underscored the critical role of external commonsense. Without external knowledge to contextualize and facilitate reasoning, the model struggled to detect sarcasm; (3) RefG led to the noticeable degradation demonstrated that the optimized graph topology was conducive to our model discovery of implicit emotional incongruity in the graph; (4) EICR outperformed the ReaS proving the necessity of reasoning about fine-grained incongruity, which improved the robustness and generalization of incongruity features; (5) AdCL had a suboptimal performance confirmed adversarial contrastive learning helped us mitigate biases and learn robust representations."}, {"title": "Model Analysis", "content": "Hyper-parameter Sensitivity Analysis. We conducted a detailed analysis of the trade-off parameters employed in our proposed model, including the score balance parameter a in Eq.(2) when threshold \u20ac = 0.95 and the contrastive learning coefficient \u00e0 in Eq.(13). Specifically, we adjusted a within [0, 1], while \u00c0 varied within [0, 0.3]. To better observe the tendency, we employed 0.1 and 0.05 as intervals for a and \u5165, respectively. Figure 4a showed that performance initially improved as a increased but subsequently declined. The best results were achieved when a = 0.5. This indicated that an inappropriate value could lead to an imbalance in the filtering process, which may introduce irrelevant noise and perturb the quality of the retrieval-augmented prompt. In Figure 4b, as \u5165 increased, the curve showed an upward trend followed by a decline. This suggested that too small A prevented the model from mitigating the biases and learning robust representations, while a larger A diverted attention away from sarcasm detection.\nEvaluations on Language Models. To assess the performance of our method across different large language models, we conducted experiments on BLOOM 3B, Qwen 2 7B, Llama 3 8B, T5 11B, and GPT-40. As presented in Table 3, the results exhibited only minor fluctuations and were still better than the baselines. This demonstrated that our method was largely insensitive to the parameter scale of the LLMs, which was attributed to the proposed retrieval-augmented strategy. That effectively supplemented the models with relevant external commonsense, and the carefully designed prompts used this external knowledge and the parameterized knowledge embedded within the LLMs to generate the emotional commonsense required for this task. This highlighted the strong generalization ability of our model across different LLMs.\nRobustness under Low-resource Scenario. To further evaluate the effectiveness of EICR in low-resource scenarios (Liu et al., 2023), we implemented experiments using various proportions of training samples-10%, 20%, and 50%-from four benchmarks. Since the iSarcasm contained a small number of sarcastic instances, it was difficult for the model to capture the true incongruous features in low-resource scenarios. The experimental results were too random to discuss. For a fair comparison, we selected the best results from various prompting sub-methods in the GPT-4o-based Sarcasm-Cue (Yao et al., 2024) as the baseline. The observed improvements shown in Figure 5 can be attributed to the integration of reliable external commonsense, which enriched the contextual content. Moreover, explicit reasoning about fine-grained incongruities between the knowledge and the given statements further enhanced the performance of the sarcasm detector. These findings validated the robustness of EICR in addressing distributional incongruities between training and testing samples, demonstrating its effectiveness in low-resource settings."}, {"title": "Case Study", "content": "To gain deeper insights into EICR, we conducted case studies focusing on complex sarcastic statements. As illustrated in Figure 6, EICR identified the sarcastic intent in Hillary's statement, as shown in the first case example. EICR effectively retrieved relevant knowledge, including the well-established fact \"political opponents\" and sentiment-related cues \"rarely praise each other publicly.\u201d This underscored the value of the retrieval-augmented strategy in grounding sarcasm detection with commonsense knowledge. Further, the extracted subgraphs precisely captured the emotional incongruity without introducing extraneous information. In addition, EICR exhibited strong generalization capabilities across various domains, adapting to diverse sarcastic contexts. These findings demonstrated the outstanding commonsense reasoning ability of EICR neglected by traditional methods."}, {"title": "Related Work", "content": "Sarcasm Detection (SD) has attracted extensive attention in recent years. Early efforts were mainly based on formulated rules (Riloff et al., 2013). For instance, (Maynard and Greenwood, 2014) considered that hashtags might contain sarcastic features. Bamman and Smith (2015) found that the incongruity between positive verbs and negative situations indicated sarcasm. With the advancement of neural networks, co-attention tricks (Pan et al., 2020) and BERT (Babanejad et al., 2020) were applied to capture incongruity patterns. Recent methods employed knowledge graphs like SenticNet (Liu et al., 2022) or COMET (Li et al., 2021) (Yu et al., 2023b) to introduce external commonsense knowledge for daily sarcastic instances. To capture the intricate relations between multi-source knowledge and the statement, Lou et al. (2021) injected emotional commonsense into the dependency graph for SD. Additionally, Min et al. (2023) augmented potential results and reactions from COMET to mimic the way humans judge sarcasm. Liu et al. (2023) and Yao et al. (2024) both employed the LLMs with a prompting framework in SD. Besides, other works focused on behavior-level (Zhou et al., 2024) and deep text representation and learning (Gedela et al., 2024). However, these methods lack commonsense inferential ability when they face complex real-world scenarios, which might lead to unsatisfactory performance.\nCommonsense reasoning has become a prominent focus in natural language processing (Guo et al., 2023) and computer vision (Liu et al., 2024). Many knowledge-intensive tasks usually require associating with commonsense knowledge, such as question answering (Zhang et al., 2024), question generation (Yu et al., 2021), and sarcasm detection (Yue et al., 2023). Effective commonsense reasoning often requires external knowledge resources, including KGs such as SenticNet(Cambria et al., 2020) and ConceptNet(Speer et al., 2017) and PLMs like COMET(Hwang et al., 2021) and GPT-4(Achiam et al., 2023). While KGs typically aggregate knowledge through structured matching processes (Ye et al., 2022), PLMs generate knowledge dynamically via prompting (Radford et al., 2021). Commonsense reasoning for detecting incongruity features generally follows two paradigms (Chen et al., 2024a). The first leverages neural networks to encode contextual clues (Tay et al., 2018), yet these methods often struggle with capturing complex relations (Lou et al., 2021). The second approach involves constructing graphs and incorporating commonsense knowledge directly into the graph structures (Qiao et al., 2023). However, existing GNN-based methods are limited in their ability to explain the reasoning process, focusing primarily on the final detection outcomes (Yu et al., 2023a). In contrast, our proposed reasoning skeleton integrates prior rules creating a more interpretable and effective framework for sarcasm detection."}, {"title": "Conclusion", "content": "This paper tackled the challenges of supplementing commonsense knowledge and inferring fine-grained incongruity when facing complex instances in sarcasm detection. To address these issues, we proposed a novel commonsense reasoning framework for sarcasm detection named EICR. Concretely, we first devised retrieval-augmented LLMs to provide the essential commonsense knowledge. To capture sophisticated contextual associations, we constructed a dependency graph and obtained the optimized topology through graph refinement. We further introduced an adaptive reasoning skeleton that integrated prior rules to extract emotional-incongruity subgraphs explicitly. To eliminate the possible spurious relations between words and labels, we employed adversarial contrastive learning to enhance the robustness of the detector. Experiments conducted on five popular datasets demonstrate the effectiveness of our proposed method."}]}