{"title": "Resource Allocation for Stable LLM Training in Mobile Edge Computing", "authors": ["Chang Liu", "Jun Zhao"], "abstract": "As mobile devices increasingly become focal points for advanced applications, edge computing presents a viable solution to their inherent computational limitations, particularly in deploying large language models (LLMs). However, despite the advancements in edge computing, significant challenges remain in efficient training and deploying LLMs due to the computational demands and data privacy concerns associated with these models. This paper explores a collaborative training framework that integrates mobile users with edge servers to optimize resource allocation, thereby enhancing both performance and efficiency. Our approach leverages parameter-efficient fine-tuning (PEFT) methods, allowing mobile users to adjust the initial layers of the LLM while edge servers handle the more demanding latter layers. Specifically, we formulate a multi-objective optimization problem to minimize the total energy consumption and delay during training. We also address the common issue of instability in model performance by incorporating stability enhancements into our objective function. Through novel fractional programming technique, we achieve a stationary point for the formulated problem. Simulations demonstrate that our method reduces the energy consumption as well as the latency, and increases the reliability of LLMs across various mobile settings.", "sections": [{"title": "1 INTRODUCTION", "content": "The advent of large language models (LLMs) marks a significant milestone in the advancement of artificial intelligence and offers unparalleled capabilities in natural language processing, generation, and understanding. The desire for ubiquitous access to Artificial intelligence (AI) capabilities has driven a significant trend and demand toward the deployment and even training of these computationally intensive models directly on mobile devices [2, 18, 30]. Users seek real-time, personalized experiences and decision-making support across a diverse array of applications, from healthcare to customer service, which only such advanced models can provide. Additionally, there is a growing emphasis on decentralization in computing to enhance privacy and data security by processing sensitive information locally on the device, rather than transmitting it to distant data centers. However, this aspiration faces a tough challenge: the substantial computational resources required by LLMs. These models necessitate sophisticated hardware configurations that far exceed the capabilities of standard mobile devices [19].\nMobile edge computing (MEC) emerges as a transformative solution to this challenge by bringing computational resources closer to the data source [26]. MEC enables data processing at the network's edge, utilizing distributed computing resources geographically proximate to where the data originates and is consumed. Augmented with LLMs, mobile edge servers can process and understand complex queries locally, minimizing the need for constant communication with centralized cloud infrastructure. This not only improves response times but also enhances privacy and data security by processing sensitive information closer to its source.\nHowever, we still face challenges in how LLMs can be optimized in real-time mobile applications to achieve the best possible performance. The challenges involve tailoring these models in resource-constrained environments. One solution is in-context learning. It provides the LLM with a few examples of the desired task within the input prompt, allowing the model to adapt its behavior based on these examples without changing its parameters. But the effectiveness of in-context learning is constrained by the model's context window size, and it doesn't lead to persistent improvements in the model's capabilities. Moreover, recent studies have shown that in-context learning may struggle with reliability and hallucination [13]. Alternatively, many studies propose parameter-efficient fine-tuning (PEFT) methods [5, 12, 17]. These methods have been demonstrated to yield state-of-the-art performance in model training and optimization, significantly reducing the computational overhead traditionally associated with such processes. Inspired by this body of work, we propose a novel scenario for collaboratively training LLMs, harnessing the combined capabilities"}, {"title": "2 RELATED WORK", "content": "In this section, we review the existing literature related to our work.\nResource allocation in mobile edge computing. In [20], the authors propose a Lyapunov optimization-based dynamic computation offloading algorithm to optimize the execution delay and the task-dropping cost in MEC system. When addressing the offloading decision problem, they apply an exhaustive search strategy, assessing the objective values across three discrete options to determine the optimal solution. Dinh et al. [6] propose to minimize the execution latency and the user devices' energy consumption in MEC. They use an exhaustive search approach and a semidefinite relaxation (SDR)-based approach to optimize the CPU frequency. However, the exhaustive search approach is not practical in implementation due to its high complexity, and the SDR-based approach has no global or local optimality guarantee. In [3], Chen et al. optimize the computation resource allocated to each task to minimize the computation and communication delay. To handle the multiplication of two decision variables (i.e., the computation resource allocation and the offloading decision), they adopt alternative optimization (AO) techniques. Xu et al. [31] formulate a cooperative resource optimization problem to optimize the offloading decision and resource allocation in vehicular edge computing. Yet, they decouple the resource allocation variables from the offloading decision variable, and then use a deep reinforcement learning-based approach to solve it. Zhan et al. [32] optimize the computation offloading scheduling and resource allocation in unmanned aerial vehicle (UAV)-enabled MEC system. They propose a two-stage alternating optimization algorithm to optimize the offloading scheduling, resource allocation and time duration alternatively.\nIn contrast, Wang et al. [29] obtain the optimal solution in a semi-closed form for offloading decisions and resource allocation in MEC with wireless power transfer. However, their study exclusively focuses on minimizing the total energy consumption without integrating delay considerations into the objective function. Consequently, while it facilitates the determination of the optimal CPU frequency, it inherently simplifies the selection process to the minimal processing unit frequency that meets the latency requirements. Nonetheless, in this paper, we incorporate delay considerations into the objective function, thereby introducing a higher level of complexity to the solution process for resource allocation. As a result, the optimal solution to our problem cannot be directly ascertained.\nPEFT vs. In-Context Learning (ICL). Recent studies have demonstrated the superiority of PEFT methods over ICL in various scenarios. Mosbach et al. [22] conduct a fair comparison of ICL and fine-tuning approaches across different tasks and model sizes. They find that fine-tuning outperforms in-context learning across different performance metrics. Liu et al. [16] also rigorously demonstrate that PEFT surpasses ICL in both accuracy and computational efficiency.\nThe model stability of fine-tuned large language models. Extensive efforts have focused on developing algorithms aimed at improving the stability of the fine-tuning process. Based on the idea of dropout, Lee et al. [14] present \"Mixout\" regularization technique to selectively combine the parameters of two pre-trained"}, {"title": "3 SYSTEM MODEL", "content": "In this section, we first present the system model, including local computation model, edge computation model and LLM stability. After that, we formulate the multi-objective optimization problem.\nWe consider an MEC system consisting of N users and M edge servers, as described in Figure 1. Assume all the users in the system train LLMs with the same architecture. Let Y be the total number of transformer layers in the LLM. User n fine-tunes the first \u03b1n layers locally, after which the intermediate results are sent to a certain edge server to complete the remaining training process. Let dn denote the length of input tokens of user n for training. For the energy and delay calculation for training LLMs, we follow the setting in [15]. Let \u03c8(dn) be the FLOPs per token required to train one transformer layer, \u03c8(dn) = 72Bdnh\u00b2 + 12Bdh where B is the batch size and h is the dimensionality of the hidden states.\n3.1 Local Computation Model\nWhen user n is training one transformer layer locally, the delay for computation can be given by:\n$T_{n}^{emp} = \\frac{\\psi(d_n)}{f_nC_UD_U}$\n(1)\nwhere fn is the GPU frequency of user n, CU is the number of cores of the GPU at user n and Du is the number of FLOPs per cycle per core of the GPU. The relationship between the GPU's power consumption and its clock speed is cubic, i.e., power = k1f\u00b3\nHere, k1 is the coefficient reflecting the power usage per cubic cycle per second ([in Watt/(cycle/s)\u00b3]), dependent on the specific GPU architecture. Hence, when training one transformer layer, the energy expenditure for local computations is established as follows:\n$E_{n}^{emp} = K_1 \\times T_{n}^{emp} = \\frac{K_1 \\psi(d_n)}{f_nC_UD_U}$\n(2)\nUpon completing local computations, users transmit the intermediate results to edge servers for further processing. The association between users and edge servers is represented by Xn,m with Xn,m = 1 signifying that user n has selected edge server m for further computations, and Xn,m = 0 indicating no such association. In this context, we adopt Frequency-Division Multiple Access (FDMA) such that communications between users and edge servers are free from mutual interference. The power used for transmission by user n is denoted as pn. Following the principles of the Shannon-Hartley theorem [4], the transmission rate between user n and edge server m can be formulated as rn,m = bn,m log2(1 + \\frac{gn,mpn}{\u03c3\u00b2}), where \u03c3\u00b2 represents the power of the noise, bn,m denotes the bandwidth that edge server m assigned to user n, pn is the transmission power of user n, and gn,m is the channel gain between user n and edge server m. Let s(dn) be the size of the intermediate results for user n. Therefore, the energy consumption of wireless transmission for user n is:\n$E_n^{com} = \\sum_{m \\in M} X_{n,m} \\frac{s(d_n)p_n}{r_{n,m}}$\n(3)\nWhen user n is training the first \u03b1n layers locally, the computation of both time and energy expenditure is:\n$Cost_n^{local} = \\alpha_n \\cdot (w_t T_n^{emp} + w_e E_n^{emp}) + w_e E_n^{com}$\n(4)\nHere, wt serves as the weighting and normalization factor, reflecting the priority given to minimizing delay, while we represents the"}, {"title": "3.2 Edge Computation Model", "content": "When edge server m trains one transformer layer for user n, the time taken for the computation can be expressed as follows:\n$T_{n,m}^{edge} = \\frac{\\psi(d_n)}{f_{n,m}C_mD_e}$\n(5)\nwhere fn,m denotes the GPU frequency of edge server m assigned to user n, and Cm represents the total core count of the GPU within edge server m, and De signifies the computational capability of each core, measured in floating point operations per cycle, for the GPU located at edge server m. Thus, the energy required by edge server m to train one transformer layer for user n can be quantified as follows:\n$E_{n,m}^{edge} = \\frac{K_2f_{n,m}^3 \\psi(d_n)}{C_mD_e}$\n(6)\nwhere k2 is a coefficient that varies based on the architecture of the chip. The energy used for downlink transmission from the edge servers to the users is not considered in this calculation, due to the substantially higher power capacities of the edge servers compared to the users. Furthermore, in comparison to the energy requirements for training the LLM, the energy expended on transmission by the edge servers is considered negligible.\nSince there are Y transformer layers in total, (Y-\u03b1n) layers are processed at the corresponding edge server. As a result, the incurred cost for conducting the training tasks for users at edge server m is calculated by integrating both the time delays and energy expenditures into a weighted sum:\n$Cost_m^{edge} = \\sum_{n \\in N} X_{n,m}(Y - \\alpha_n) \\cdot (w_t T_{n,m}^{edge} + w_e E_{n,m}^{edge})$\n(7)"}, {"title": "3.3 LLM Stability", "content": "In this paper, we use the Average-replace-one Stability (AS) proposed by [25] to measure the mode stability. AS is a measure of how much an individual prediction is affected by small changes in the training dataset. It serves as a crucial metric for ensuring that our fine-tuned language model remains consistent and reliable, despite the variability in local data from user to user. Next, we give the definition of the average-replace-one stability.\nDEFINITION 1 (AVERAGE-REPLACE-ONE STABILITY). Given a loss function l and training dataset S = {z1, ..., zk}, an algorithm A demonstrates the average-replace-one stability (AS) with a bound \u03b2 if the following condition is met: Vi \u2208 {1, ..., k},\n$\\mathbb{E}_S [|l(A(S), z_i) - l(A(S^i), z_i)|] \\leq \\beta,$\n(8)\nwhere A(S) denotes the model obtained after the algorithm A has been trained on the dataset S, and l(A(S), zi) is the loss function evaluated at a particular data point zi using the model given by A(S). Si represents the training dataset with the i-th sample replaced with zi, i.e., Si = {z1, . . ., zi\u2212 1, z', ..., zk }.\nThis definition implies that for every individual element zi in a dataset of size k, the expected disparity in the loss computed by algorithm A when trained with the complete dataset versus the dataset lacking that specific sample is bounded by \u03b2."}, {"title": "3.4 Problem Formulation", "content": "With the computation and communication model above, we then formulate the joint optimization problem that aims to minimize the system's cost while minimizing the Average-replace-one Stability (AS) of the LLMs, by optimizing the following variables: the number of transformer layers that execute locally: \u03b1 := [\u03b1n]n\u2208N],\nthe user-to-edge server association: X := [Xn,m|n\u2208N,m\u2208M], the transmission power of the users: p := [pn|n\u2208N], the bandwidth allocation: b := [bn,m[n\u2208N,m\u2208M], the users' GPU frequency: fU := [fn|n\u2208N] and the edge servers' GPU frequency allocation: fE := [fn,m[n\u2208N,m\u2208M]. Similar to delay and energy, we also give a weighting and normalization parameter \u03c9\u03c2 to the AS. The joint optimization problem is formulated as follows:\n$Problem P_1: \\underset{\\alpha, X, p, b, f_U, f_E}{min} \\sum_{n \\in N} Cost_n^{local} + \\sum_{m \\in M} Cost_m^{edge} + w_s AS,$\ns.t. \u03b1n \u2208 {1,2,..., Y}, \u2200n \u2208 N,\n(9)\n(9a)\nXn,m \u2208 {0,1}, \u2200n \u2208 N, me M,\n(9b)\n$\\sum_{m \\in M} X_{n,m} = 1, \\forall n \\in N,$\n(9c)\npn \u2264 pmax, \u2200n\u2208 N,\n(9d)\n$\\sum_{n \\in N} X_{n,m} b_{n,m} = b^{max}, \\forall m \\in M,$\n(9e)\nfn \u2264 fmax, \u2200n \u2208 N,\n(9f)\n$\\sum_{n \\in N} X_{n,m} f_{n,m} = f^{max}, \\forall m \\in M.$\n(9g)\nGiven the inherent challenges in quantifying the average-replace-one stability, we commence by presenting the following theorem to facilitate addressing the optimization problem. We assume the loss function l() is L-Lipschitz and strong convex. These two assumptions are widely employed in the analysis of the behavior of neural networks [23, 24].\nTHEOREM 1. If a user fine-tunes a proportion \u03b1 of the parameters, the expectation of the loss has an AS bounded by $\\frac{2L^2}{k(1-\\alpha)}$. I.e., Vi e {1, ..., k},\n$\\mathbb{E}_S [|l(A(S), z_i) - l(A(S'), z_i)|] \\leq \\frac{2L^2}{k(1-\\alpha)}$\n(10)\nPROOF. The proof can be found in Appendix A.\nTheorem 1 provides a quantifiable measure of model stability and bridges the concept of \u201cmodel stability\u201d with a measurable quantity. Since the \"model stability\" term is not quantitative in problem P1, we re-formulate problem P1 into the following P2 by replacing the sum of AS with the sum of the AS's upper bound of all the users:\n$Problem P_2: \\underset{\\alpha, X, p, b, f_U, f_E}{min} \\sum_{n \\in N} Cost_n^{local} + \\sum_{m \\in M} Cost_m^{edge} + w_s \\sum_{n \\in N} \\frac{2L^2}{k_nY \\cdot (1-\\alpha_n)},$\ns.t. (9a) - (9g).\n(11)\nWhile the optimal solutions to problem P\u2081 and P2 may not be strictly equivalent in a mathematical sense, P2 serves as a practical approximation of P1. By using the upper bound from Theorem 1, we are optimizing for the worst-case scenario of model instability. Problem P2 falls into the category of Mixed Integer Nonlinear Programming (MINLP) problem. This classification arises due to the inclusion of both integer-valued decision variables and nonlinear terms involving products of variables, a combination that inherently induces non-convexity in the problem space. The non-convex nature of this problem makes it especially challenging to solve because it cannot be addressed using standard optimization methods, which typically rely on the problem being convex. In order to tackle the non-convex problem, we optimize \u03b1, p, b, fU, fE and x iteratively. Specifically, in the first step, we fix x and utilize a novel fractional programming technique motivated by Zhao et al. [33] to optimize \u03b1, p, b, fU, fE by transforming the non-convex problem into a series of parametric convex problems. In the second step, given \u03b1, p, b, fU, fE, the method of CCCP is adopted to facilitate the solution to x by solving a sequence of convex problems."}, {"title": "4 PROPOSED ALGORITHM", "content": "In this section, we provide a detailed solution to the optimization problem.\n4.1 Optimizing \u03b1, p, b, fU, fE given x\nThe discrete variable \u03b1n is difficult to handle. Thus, we first relax \u03b1n to continuous variables, which will be rounded back to the nearest integer later. For problem P2, to optimize \u03b1, p, b, fU, fE given x means to solve the following optimization problem:\n$Problem P_3(x): \\underset{\\alpha, p, b, f_U, f_E}{min} H(\\alpha, p, b, f_U, f_E) = \\sum_{n \\in N} Cost_n^{local} + \\sum_{m \\in M} Cost_m^{edge} + w_s \\sum_{n \\in N} \\frac{2L^2}{k_nY \\cdot (1-\\alpha_n)}$\ns.t. 1 \u2264 \u03b1n \u2264 Y, \u2200n \u2208 N,\n(12)\n(9d)-(9g).\n(12a)\nProblem P3 involves fraction term and multiplication terms, which makes it difficult to solve using standard optimization algorithms. Motivated by the novel fractional programming technique proposed in [33], we next transform problem P3 into a series of P4:\n$Problem P_4(x, z, v, q): \\underset{\\alpha, p, b, f_U, f_E}{min} K(\\alpha, p, b, f_U, f_E, z, v, q) = \\sum_{n \\in N} (w_t \\frac{\\psi(d_n)}{f_nC_UD_U} z_n + w_e \\frac{K_1f_n^2 \\psi(d_n)}{C_UD_U} z_n) + w_e \\sum_{n \\in N} \\sum_{m \\in M} X_{n,m} (\\frac{s(d_n) p_n^2}{\\frac{r_{n,m}}{2ln(2)g_{n,m} + \\sigma^2} } v_{n,m}) + \\sum_{n \\in N} \\sum_{m \\in M} X_{n,m} (\\frac{K_2f_{n,m}^2 \\psi^2(d_n)}{C_e^2D_e^2} q_{n,m}) + w_s \\sum_{n \\in N} \\frac{2L^2}{k_nY \\cdot (1-\\alpha_n)} \\text{ s.t. } \\text{ (12a), (9d)-(9g), }$\n(13)\nwhere the auxiliary variables z := [z1, z2, ..., zn] with zn > 0, v := [v1,1, v1,2,..., v1,m, ..., vn,m] with vn,m > 0 and q := [q1,1, q1,2,..., q1,m,..., qn,m] with qn,m > 0.\nProblem P3 involves non-convex terms and is difficult to handle. Therefore, we formulate the above problem P4. Next, we introduce an AO algorithm for problem P4. After that, we propose Proposition 1 to explain how we can tackle problem P3 through a series of convex problem P4 instances.\nFirst, we introduce the AO algorithm for problem P4. Overall, we alternatively optimize \u03b1, p, b, fU, fE and z, v, q. Specifically, we begin with an initial feasible [\u03b1 (0), p(0), b(0), fu (0), fE (0)]. Next, we denote A(fn) and B(fn,m) as:\n$A(f_n) = w_t \\frac{\\psi(d_n)}{f_nC_UD_U} + w_e \\frac{K_1f_n^2 \\psi(d_n)}{C_UD_U}$\n(14)\n$B(f_{n,m}) = w_t \\frac{\\psi(d_n)}{f_{n,m}C_mD_e} + w_e \\frac{K_2f_{n,m}^2 \\psi(d_n)}{C_eD_e}$\n(15)\nWe assign $z_n^{(0)}$ to be $\\frac{A(f_n)}{2\\alpha_n}$, which is the optimal value of zn when optimizing \u03b1nz\u00b2n + \\frac{A\u00b2(f_n)}{4z_n} with respect to zn, while keeping \u03b1n, fn fixed at $\u03b1_n^{(0)}, f_n^{(0)}$; we assign $v_{n,m}^{(0)}$ to be $\\frac{p_n d_n}{2 \\rho_n,m}$, which is the optimal value of vn,m when optimizing $(\\frac{p_nd_n}{2ln(2)g_{n,m} + \\sigma^2}) v_{n,m} + \\frac{\\rho_{n,m}}{4v_{n,m}}$ with respect to vn,m, while keeping pn, dn fixed at $p_n^{(0)}, d_n^{(0)}$; we assign $q_{n,m}^{(0)}$ to be $\\frac{B(f_{n,m})}{2(Y-\\alpha_n)}$, which is the"}, {"title": "4.2 Optimizing x given a, p, b, fu, fE", "content": "Firstly, to reduce the computational complexity, we convert discrete variables into continuous ones. Without loss of equivalence, constraint (9b) can be reformulated as:\nXn,m \u2208 [0, 1], \u2200n \u2208 N, m\u2208 M,\n(46)\n$\\sum_{n \\in N} \\sum_{m \\in M} X_{n,m} \\cdot (1 - X_{n,m}) \\leq 0.$\n(47)\nBy replacing constraint (9b) with constraints (46) and (47), the discrete variables are transformed into continuous ones, thereby reducing the computation complexity of the problem.\nWith fixed \u03b1, p, b, fU, fE, solving problem P\u2081 is equivalent to solving the following problem:\n$Problem P_5 (\\alpha, p, b, f_U, f_E) : \\underset{X}{min} \\sum_{n \\in N} Cost_n^{local} + \\sum_{m \\in M} Cost_m^{edge}$ \ns.t. (9c), (9e), (9g), (46), (47).\n(48)\nHowever, constraint (47) remains a non-convex constraint. Thus, further measures are required to efficiently tackle this challenge. Next, we convert problem P5 into an equivalent problem that has linear constraints, which we then address using the CCCP method. To this end, we introduce the following lemma:\nLEMMA 1. Let G(Xn,m) = $\\sum_{n \\in N} Cost_n^{local} + \\sum_{m \\in M} Cost_m^{edge}$. With any xn,m satisfying (9c), (9e), (9g), and (46), for all \u03c1 > \u03c1\u2080 where\n$\\rho_0 = \\frac{G(X_{n,m}) - min\\{G(X_{n,m}): (9c), (9e), (9g), (46)\\} }{min\\{\\sum_{n \\in N} \\sum_{m \\in M} X_{n,m}(1-X_{n,m}): (9c), (9e), (9g), (46)\\}}$,\n(49)\nproblem P5 has the same optimal solution with problem P6, which is defined as follows:\n$Problem P_6(\\alpha, p, b, f_U, f_E) : \\underset{X}{min} \\sum_{n \\in N} Cost_n^{local} + \\sum_{m \\in M} Cost_m^{edge} + \\rho \\sum_{n \\in N} \\sum_{m \\in M} X_{n,m}(1 - X_{n,m}),$\ns.t. (9c), (9e), (9g), (46).\n(50)\nIt is worth noting that problem P6 is derived from problem P5 by integrating the concave constraint (47) into the objective function as a penalization term.\nPROOF. The proof can be directly derived from Theorem 1 in [1].\nProblem P6 involves subtracting a quadratic convex function from a linear function, while its constraints are linear in nature. According to [27], problem P6 falls under the category of indefinite quadratic problem, which is a subset of the broader class of problems known as the difference of convex problems. With the objective function of problem P6 being differentiable, we can effectively address problem P6 using the CCCP method, which involves employing a first-order Taylor series approximation [10] to refine"}, {"title": "5 SIMULATIONS", "content": "In this section, we present the performance of the proposed approach through simulations. The simulated MEC network has 50 mobile users and 10 edge servers by default. Assume the users and edge servers collaboratively train Meta's open-source large language model Meta-AI (LLaMA-7B) which consists of 32 transformer layers [28]. The path loss is modeled as 128.1 + 37.6 log(distance) and Gaussian noise power is \u03c3\u00b2 = \u2212134dBm. The maximum transmission power pmax for the users is set in the range of 1 to 2 W. The maximum GPU frequency fmax for users and fmax for edge servers are chosen from [0.5,1] and [1,3] respectively. The total bandwidth bmax for each edge server is 20 MHz.\nFor LLM training, the batch size B is set to 512 and the dimensionality of the hidden states h is set to 1024. The lengths of input tokens for each user are randomly generated from 512 to 1024. We assume the mobile users are equipped with mobile devices with GPU such as Apple A15, whose GPU has 4 to 6 cores. Thus, the number of cores of the GPU at the user side Ch is chosen between 4 to 6. The number of FLOPs per cycle per core D is all set to 1. The edge servers are presumed to be equipped with advanced GPUs such as NVIDIA Tesla T4 and NVIDIA Tesla V100, therefore the number of cores of the GPU C is randomly assigned values from the interval [2560, 5120]. The number of FLOPs per cycle per core D is chosen between 1 and 2.\n5.1 The performance of the proposed collaborative training method\nIn Figure 2, we present an analysis of system performance across three computing approaches: the proposed collaborative training method, edge server training method and local training method. Figure 2 (a) illustrates the energy consumption associated with each approach, where the proposed collaborative method demonstrates a balanced reduction in energy usage compared to the edge server training and local training methods. Figure 2 (b) depicts the delay experienced under each approach, showing that the proposed method effectively minimizes delay, achieving a performance closer"}, {"title": "5.2 The performance of proposed algorithms under weighting factors", "content": "Next, we compare the performance of the proposed method when the weighting factors for energy, delay and model stability vary. The default weighting factors after normalization are all set to 1 for energy, delay and model stability. A larger weighting factor denotes enhanced prioritization of system attributes such as energy efficiency, latency, or model stability. The three additional methodologies employed for comparative analysis with our proposed method are listed as follows:\n\u2022 Alternating optimization: This method is the most commonly employed strategy in the related literature as discussed in Section 2. It systematically alternates between optimizing offloading decisions and the allocation of computational or communication resources.\n\u2022 Optimize \u03b1 only: This approach solely focuses on optimizing the offloading decision \u03b1, while implementing a random strategy for resource allocation.\n\u2022 Optimize resource only: This method concentrates exclusively on the optimization of resource allocation, while employing a random approach to the offloading decision \u03b1.\nIn Figure 3, we adjust the weighting factors for energy, delay and model stability from 1 to 10, respectively. For each setting where one attribute's weighting factor varied from 1 to 10, the weighting factors for the other two attributes are held constant at 1. In Figure 3 (a), the proposed methodology consistently attains the lowest energy consumption among the methods evaluated. The alternating optimization approach secures the second-best performance. Conversely, the method that solely optimizes \u03b1 exhibits the poorest results. This suboptimal performance can be attributed to the fact that the \u03b1-only optimization method neglects resource allocation considerations, which are crucial in minimizing energy consumption. Furthermore, as the weighting factor for energy is incrementally increased, the reductions in optimal energy consumption diminish progressively, eventually converging. Figure 3 (b) depicts the average delay experienced under various weighting factors for delay. Consistently, the proposed approach yields"}, {"title": "5.3 The impact of the number of users and the number of edge servers", "content": "In this part, we assess the influence of both the user population and the number of edge servers on the effectiveness of the proposed approach to addressing the user-to-edge association challenge. We employ a comparative methodology as outlined below:\n\u2022 Baseline: The baseline approach we choose is a greedy-based strategy. Under this strategy, each user opts for the edge server offering the highest available transmission rate, subject to bandwidth limitations.\n\u2022 Random: The random user-to-edge server association method distributes users among edge servers in a stochastic manner, also adhering to bandwidth constraints.\nIn Figure 5 (a), we present the total energy consumption when there are different numbers of users. It can be observed that the proposed method always outperforms the two alternative strategies. The baseline strategy selects the edge server with the highest available transmission rate for each user; however, this approach may inadvertently overload servers that possess lower computational efficiency, thereby causing a marginal increase in energy consumption relative to our method. The random strategy invariably results in the highest energy expenditure. Subsequently, we analyze the average delay contingent on varying user quantities, as depicted in Figure 5 (b). It is evident that the proposed methodology consistently surpasses the two alternative strategies. Specifically, the random strategy yields the least favorable outcomes due to its arbitrary selection of edge servers for user allocation. While the baseline strategy may attain minimal communication delays, it tends to allocate an excessive number of users to a single edge server, thereby exacerbating the computational delays.\nIn Figure 4, the convergence performance of the algorithm is analyzed for the user-to-edge server association problem across varying quantities of edge servers. For each scenario considered, the user count remains constant at 100. The analysis reveals that the algorithm attains a stationary point as evidenced by the stabilization of the objective value. It is worth noticing that configurations with a smaller number of edge servers exhibit faster convergence rates. This enhanced speed of convergence can be attributed to the diminished complexity of the optimization challenge: a reduced number of servers correlates with fewer constraints and a lower number"}, {"title": "6 CONCLUSION", "content": "In this study, we present a collaborative LLM training framework that merges the efforts of mobile users and edge servers. Here, mobile users are tasked with training the preliminary layers of the LLM, while the computationally intensive later layers are managed by the edge servers. We develop a multi-objective optimization strategy aimed at reducing overall energy usage and latency experienced by users, while also improving the stability of LLMs. Through analytical analysis, we establish an upper bound for the average-replace-one stability. The proposed algorithm leverages fractional programming and the CCCP method to derive solutions. Simulation results indicate that our approach effectively reduces energy usage and delay, and enhances the stability of LLMs in the mobile edge computing environments."}, {"title": "A PROOF OF THEOREM 1", "content": "Denote w as the parameters of a language model", "problem": "n$min L_S(w)", "to": "n$min max L_S (w) + \\lambda || (I \u2013 M) (w \u2013 w\u00b0) ||\u00b2", "by": "n$min L'_S(w) = L_S (w) + \\lambda || (I \u2013 M) (w \u2013 w\u00b0) ||^2.$\n(A.4)\nIt indicates that minimizing initial loss function Ls(w)", "get": "n$\\mathbb{E}_M(L'_"}]}