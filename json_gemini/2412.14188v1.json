{"title": "CogSimulator: A Model for Simulating User Cognition & Behavior with Minimal Data for Tailored Cognitive Enhancement", "authors": ["Weizhen Bian", "Yubo Zhou", "Yuanhang Luo", "Ming Mo", "Siyan Liu", "YiKai Gong", "Renjie Wan", "Ziyuan Luo", "Aobo Wang"], "abstract": "The interplay between cognition and gaming, notably through educational games enhancing cognitive skills, has garnered significant attention in recent years. This research introduces the CogSimulator, a novel algorithm for simulating user cognition in small-group settings with minimal data, as the educational game Wordle exemplifies. The CogSimulator employs Wasserstein-1 distance and coordinates search optimization for hyperparameter tuning, enabling precise few-shot predictions in new game scenarios. Comparative experiments with the Wordle dataset illustrate that our model surpasses most conventional machine learning models in mean Wasserstein-1 dis-tance, mean squared error, and mean accuracy, showcasing its efficacy in cognitive enhancement through tailored game de-sign.", "sections": [{"title": "Introduction", "content": "In recent years, the application of artificial intelligence has expanded across various fields such as music (Bian et al., 2023), gaming (Yin et al., 2023), and healthcare (Shaheen, 2021), demonstrating its broad impact and potential. Con-currently, the relationship between cognition and games has become a hot topic, particularly in research focused on using games to assess cognitive abilities and explore whether games can enhance cognitive skills (Boot, 2015). At the same time, the relationship between cognitive level and education is also the focus of attention, where cognitive ability is considered a crucial predictor of education and socioeconomic achievement, especially regarding strategies and methods in student learning, individual differences, etc (Yen et al., 2004; Van Hove et al., 2019).\nIn terms of using games to help measure cognitive ability, games can test different aspects of cognitive function, including aspects such as memory and attention, which can assist in diagnosing disease (Wiley et al., 2021). At the same time, games are thought to be more effective in assessing cognitive abilities, even in improving fairness and user experience (Leutner et al., 2023). Therefore, games are closely linked to cognitive ability, and in the framework of the importance of cognitive ability in education, the better use of games to contribute to the development of cognitive ability is a significant agenda. However, given the hetero-geneous attributes of participants, a fixed game algorithm may not enhance the cognitive abilities of all individuals consistently (Manzano-Le\u00f3n et al., 2021). Conventional approaches, encompassing behavior trees (Hecker, 2011) and data-driven methodologies (Kim & Ruip\u00e9rez-Valiente, 2020), attempt to tailor game modes to diverse cognitive profiles of users yet necessitate substantial data acquisition. Tech-nologies related to artificial intelligence, including Transfer Learning and Convolutional Neural Networks (CNN), are also challenged by over-fitting issues, consequently diminishing the precision in predicting user cognitive patterns (Zhao, 2017).\nThis work developed the CogSimulator model, which intends to capture and simulate the user's cognitive level based on a small amount of data. Further, using less data to simulate user groups, the game can implement a more targeted educational game for specific users. This paper uses the game \u201cWordle\u201d, a word game, to demonstrate how to evaluate and improve cognitive ability with a limited number of users, making the game a more acceptable form for teenagers in learning (Amory, 2010). It is important to highlight that due to the CogSimulator's efficient use of data, encompassing common word frequency metrics pervasive across numerous word-based games, it is well-suited for application to newly developed games or those aimed at niche user groups. By simulating individual player behaviors, the model offers game designers a valuable tool for tailoring game difficulty to match specific cognitive profiles."}, {"title": "Related Work", "content": "Cognition includes the mental processes of acquiring knowl-edge and understanding through thought, experience, and the senses and plays a fundamental role in human development and interaction with the environment (Sommerville, 2020). This area, crucial for critical thinking, problem-solving skills, and the effective processing and interpretation of information, has attracted increasing attention in contemporary research, particularly at the intersection of cognition and play (Majuri et al., 2018; Sailer & Homner, 2020). Human research on educational games dates back to 1981 when Malone investi-gated in his seminal paper how to use the captivating effects of computer games to make learning fun and interesting (Malone, 1981). In the mid-1980s, research examined the link between video game play and cognitive performance, and this correlation was gradually confirmed (Dale et al., 2020). However, even using AI-based game-based educational technologies, such as AI applications for learning new skills or knowledge, may only improve learners' cognition if they motivate long-term use (Laine & Lindberg, 2020). Therefore, the challenge is producing a game design that suits the needs and preferences of the players to ensure the gamers' cognitive enhancement.\nMany academic studies have shown that positive motiva-tion is crucial in enhancing human engagement, which in turn helps promote cognitive improvement (Teixeira et al., 2012; Ryan & Deci, 2000; Dweck, 2006). In this context, it can be broken down participation motivation into two categories: intrinsic participation motivation (stemming from the game's intrinsic design elements) and extrinsic participation motivation (stemming from the game's reward and punishment system) (Laine & Lindberg, 2020). Although the persistence of intrinsically motivated engagement is remarkable, intrinsic motivation depends on various factors, including player type, specific educational needs, and personal interests (Manzano-Le\u00f3n et al., 2021). Therefore, if the game mode cannot change with different individuals, the degree of cognitive enhancement may vary widely between individuals. This variability poses a significant challenge to developing fixed game mechanics that can universally meet the diverse needs of all players (Manzano-Le\u00f3n et al., 2021).\nTraditional approaches to creating adaptive and responsive gaming environments, designed to cater to players' individual needs, have primarily relied on rule-based systems such as finite state machines and behavior trees (Park et al., 2023). These systems provide an easy way to build simple agents that provide different feedback based on user actions (Hecker, 2011). However, while this approach effectively creates a baseline interactive experience, it cannot dynamically adapt to individual players' subtle and changing preferences or capabilities. An alternative solution lies in data-driven approaches (Kim & Ruip\u00e9rez-Valiente, 2020). This approach entails collecting extensive gameplay data, such as average completion times, to assess game difficulty and subsequently recommend games of varying difficulty levels to different players. However, this approach relies on substantial data accumulation for accurate predictions, making it challenging to apply effectively in scenarios requiring rapid adaptation to new tasks. As for artificial intelligence technology, most of the gamification research that appeared in the past decade from 2010 to 2020 failed to provide a structured overview of game elements such as NPCs working with artificial intelligence (Funk et al., 2020). Until 2023, Generative Agents realized the simulation of human behavior based on large language models (LLMs), even in zero-shot scenarios (Park et al., 2023). However, the need for extensive resources poses a significant obstacle, especially for small educational games in their embryonic stages (Jozefowicz et al., 2016). For these emerging games, the high threshold of data and computing requirements makes it challenging to fully exploit the potential of AI-driven interactive elements. In contrast, models such as CNN may cause overfitting problems due to insufficient data volume. Therefore, while advances in artificial intelligence technology offer promising avenues for enhancing the realism and engagement of game environments, their applicability still needs to be improved in resource-constrained settings.\nThis work will elucidate and test the model using Wordle as an illustrative case. Wordle is a word-guessing game that epitomizes its players' diverse needs and individual charac-teristics, reflecting the unique responses and strategies each person brings to the game. The goal of Wordle is to guess a five-letter word within six attempts. After each guess, the color gives feedbacks as: Green (the correct letter in the right spot), Yellow (The correct letter but in the wrong position) or Grey (the letter outside the word) (Match, 2022). Unaided players guess words mainly through word recall, largely limited by their vocabulary. Consequently, the CogSimu-lator was developed to emulate user cognition utilizing a limited dataset of game records, thereby facilitating the de-sign of game difficulties optimized for cognitive enhancement."}, {"title": "CogSimulator Model", "content": "We analyze that traditional machine learning models often face severe overfitting due to insufficient sample sizes, limiting their effectiveness. In contrast, our model excels in explaining word difficulty and result distribution, offering a more robust solution as detailed in Table 1. Attributes such as word frequency, prevalent across various word-based games, provide a solid foundation for applying our model to different gaming scenarios. To address these challenges, we have developed a novel sampling simulator that better reflects the gameplay dynamics of the broader population, as illustrated in Figure 1.\nThe Cogsimulator operates through a process analogous to Markov Chain Monte Carlo (MCMC) as described by Geyer (Geyer, 2011), where parameters progressively converge to a steady state distribution and achieve detailed balance. The model incorporates hyperparameters that capture players' cognitive processes at each stage of their guessing attempts, alongside the stochastic variations ob-served in each trial. Unlike traditional optimization methods that require derivatives of the cost function, our approach uses Coordinate Search Optimization (Frandi & Papini, 2014), which optimizes parameters coordinate-wise within the hyperparameter space in each iteration, allowing the model"}, {"title": "Algorithm 1: Choose A Word algorithm CW", "content": "Data: Dictionary $D \u01dd {A_i}^N$ with word frequency ${p(A_i)}^N$\nGiven hyper-parameters: $K,T$ ;\nInitialise: Probability list of length N:\nPL = $[0,0,...,0]$;\nwhile $i \u2264 N$ do\nupdate $PL[i] \u2190 max(0, p(A_i)\u00d7T)$ ;\nDelete words from D according to Wordle clue rule (colored clue);\nupdate $PL[i] \u2190 normalise(PL)$ ;\nupdate Chosenword \u2190 randomly choose a word from D with probability PL;\nend\nReturn Chosenword\nIn simulating Wordle player choices, the CogSimulator posits that players are more inclined to guess words they en-counter more frequently. However, the human capacity to recall words is finite, and the probability of recalling a spe-cific word is not strictly proportional to its word frequency."}, {"title": "Algorithm 2: Single word Trial Simulation Algorithm", "content": "Data: Any target word A*, dictionary $D\u220b {A_i}^N$ with word frequency ${p(A_i)}^N$\nGiven hyper-parameters: K,T ;\nInitialise: Count of steps: cnt = 1;\nSet:Chosenword = CW(D*, ${p(A_i)}^N$,K,T);\nwhile Chosenword \u2260 A do\nupdate D* - Delete words from D according to Wordle clue rule (colored clue);\nupdate Chosenword = C(D, ${p(A_i)}^N$,K,T);\ncnt = cnt+1;\nend\nReturn cnt"}, {"title": "Wasserstein Metric", "content": "To test the difficulty of a word for a particular cognitive group, we first obtain the distribution of word guessing times for this cognitive group's best record in past games. Then, by comparing the distance between the distribution of new input words and the distribution of the best record, the difficulty of the word for this cognitive group is judged. For this pur-pose, we propose using the Wasserstein-1 distance to evalu-ate the discrepancy between two trial distributions. Let p,q be two probability distributions on compact spaces. Denote \u03a0(p,q) as the set of all distributions \u03c0(\u03c9, \u03c9') on XXX' such that the marginals are p(x) and q(y) respectively. Then the"}, {"title": "Wasserstein-1 distance between p and q is", "content": "$W_1(p,q) = \\inf_{\\pi \\in \\Pi(p,q)} E_{(\\omega,\\omega') \\sim \\pi} [|\\omega - \\omega' ||]$ \nwhen 1 applies to discrete sample spaces, let us assume X = ${w_i}_{i=1}^m$ and X' = ${w_i'}_{i=1}^{m'}$. p and q are trial distributions of words A and A*, respectively. The distance between p and q can be obtained by solving the following linear programming problem"}, {"title": "Coordinate Search Optimization", "content": "To obtain parameters to simulate the cognition of the target population, we used Coordinate Search Optimization. The algorithm is as follows:"}, {"title": "Experiment", "content": "The model employed in this study utilized Wordle results sourced from Wordle Stats over the full year from January 7, 2022, to December 31, 2022. This one year was chosen to capture longitudinal data, reflecting genuine player interac-tions throughout different seasons and stages of player devel-opment, thereby minimizing pre-selection bias and providing a comprehensive basis for understanding group behavior in word-guessing activities. The results include the distribution of the number of trials it took players to succeed, a criti-cal measure of the game's difficulty, and player engagement. Additionally, to construct a robust model, we integrated a dic-tionary database comprising five-word English terms from the Google Books Ngram Corpus from 1970 to 2019. This cor-pus provided the foundational data for calculating each word's usage frequency, a key determinant of user selection within our predictive framework. We define word frequency as the relative occurrence of a word in the corpus, which is a direct measure of its commonality and presumed familiarity to play-ers, reflecting the likely cognitive effort required for players to guess the word correctly (Solovyev et al., 2019)."}, {"title": "Model Evaluation", "content": "Wasserstein Metric This algorithm uses Wasserstein-1 dis-tance to evaluate the difference between two trial distributions. Here, the attempt distribution refers to the attempts the user requires to complete the task in the Wordle game. This model aims to determine the difficulty of the word A relative to the word A* in the Wordle game. This is done by calculating the Wasserstein-1 distance of word A relative to the overall attempt distribution. Figure 2 shows the difficulty distribution of 355 ground truth words. It shows that the proposed met-ric is sufficiently consistent, representative of the difficulty realized by records, and mediates between other quantifiers. Clearly, 'easier' target words exhibit a trial distribution shifted towards the left on the x-axis, and 'harder' target words (yel-low colored) have a right-shifted trail distribution.\nCoordinate Search Optimization To assess the efficacy of the Coordinate Search Optimization algorithm, it is essential to consider the broader statistical profile rather than just a single winning result. This algorithm's utility lies in its ability to iteratively explore and optimize a multi-dimensional space by adjusting one coordinate at a time. It is particularly suited for problems with a complex objective function or lack an analytical gradient. The evaluation of this optimization technique is predicated on its capacity to train generators that output a discrete target trial distribution accurately. We plan to invoke the same number of generative realizations for a robust evaluation as in fixed-length accurate data batches. This approach ensures a fair comparison between the model's output and the empirical ground truth. Consistency with the ground truth is then assessed by visualizing the distribution of densities using the same projection of functional PCA (Shang, 2014), as depicted in Figure 3 (a). Further, we solidify our statistical analysis by constructing an empirical 95% confidence interval for the optimization outcomes, with the results presented in Figure 3 (b) indicating that the sampling algorithm is robust, as evidenced by the slight variance observed. The predictions and summaries derived from this approach are systematically tabulated for further scrutiny.\nSimulator The model is benchmarked with several other machine learning algorithms that comprehensively estimate trial distributions. Note that we are using the attributes to feed as the input; in regression-type benchmarks, the machine learning algorithms output a 7 dimensional vector filled with floating number loadings, whereas in classification tasks, benchmarks output a category. We train these machine learning algorithms under the canonical parameter settings. Representative methods, namely, linear regression, decision tree regression, random forest regression, and Multiple layer perceptron regressor, are selected for the experiments, and the actual performance of the algorithms is compared by studying the training and validating performance among these algorithms. For the sake of fairness, hyperparameters and settings for each method are set by default.\nThe simulator has proven a successful method for predicting the difficulty and distribution of words in the simulator game. The model achieves an accuracy of 87%, outperforming other machine learning algorithms we have tried. The results demonstrate that the simulator is effective in predicting the distribution of future reports and the difficulty and distribution of specific words in Wordle."}, {"title": "Conclusion and Future Work", "content": "This study introduces the CogSimulator, designed to simulate cognitive distributions in contexts with limited sample sizes, exemplified by its application to Wordle. The model com-petes against machine learning metrics such as Wasserstein-1 distance, mean squared error, and mean accuracy. Leveraging the universal relevance of word frequency attributes, the CogSimulator shows promising generalization across word-based games, suggesting significant potential impacts on cognitive game development for niche user groups. Despite its strengths, the model tends to represent an \u201caverage\u201d player, which may not reflect the diversity in player strategies and cognitive processes, particularly where data distributions are multimodal.\nFuture work will enhance this model by integrating clus-tering algorithms to detect and model unique player profiles, thereby better capturing the diversity of players. Plans also in-clude integrating player feedback as a dynamic reward mech-anism and developing an advanced parameter optimization method for dynamic loss functions to suit simulation tasks better and extend applicability to a broader range of educa-tional games."}]}