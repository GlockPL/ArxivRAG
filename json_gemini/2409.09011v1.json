{"title": "VAE EXPLAINER: Supplement Learning Variational Autoencoders with Interactive Visualization", "authors": ["Donald Bertucci", "Alex Endert"], "abstract": "Variational Autoencoders are widespread in Machine Learning, but are typically explained with dense math notation or static code examples. This paper presents VAE EXPLAINER, an interactive Variational Autoencoder running in the browser to supplement existing static documentation (e.g., Keras Code Examples). VAE EXPLAINER adds interactions to the VAE summary with interactive model inputs, latent space, and output. VAE EXPLAINER connects the high-level understanding with the implementation: annotated code and a live computational graph. The VAE EXPLAINER interactive visualization is live at ://xnought.github.io/vae-explainer and the code is open source at https://github.com/xnought/vae-explainer.", "sections": [{"title": "Introduction", "content": "Variational Autoencoders (VAE) [11] compress data effectively and produce a latent space that can be nicely interpolated through. However, VAEs are conceptually more difficult than regular Autoencoders (i.e., Reparameterization) and are described with dense mathematical notation [11]. Furthermore, documentation or notebooks on VAEs include code, but no live interactive exploration to show off key pieces of the VAE [2, 5, 9, 12, 16, 18].\nVAE EXPLAINER doesn't aim to replace existing examples, but to supplement them with interactive visualization. VAE EXPLAINER specifically builds off of the demonstrated educational effectiveness of interactive explainers like CNN Explainer [17], Diffusion Explainer [14], and Transformer Explainer [3] but to explain VAEs.\nWith VAE EXPLAINER, we don't display low-level details first. We hide the math notation and provide an interactive high-level overview (see Figure 1). For example, a user can hand-draw the input and view how the encoded distribution and reconstruction changes. When a user is ready, they can display low-level implementation details such as the Log-Var Trick [15] and Reparameterization Trick [11] (see Figure 2). For simplicity and familiarity, we use the MNIST Digit dataset [19] to align with existing documentation on VAEs [2, 5]."}, {"title": "System", "content": "This section describes the entire VAE EXPLAINER tool in two subsections: the High-Level Summary View (Section 2.1) and the Low-Level Graph View (Section 2.2)."}, {"title": "High-Level Summary View", "content": "To explain the main ideas from static documentation on VAES, VAE EXPLAINER distills the main point of a VAE as encoding a probability distribution of the input data, which we then sample and reconstruct (see Figure 1).\nThe encoder takes a hand-written digit input and encodes the data as a two-dimensional isotropic normal distribution. We chose 2D so the latent space could be easily visualized by humans. The distribution itself is displayed directly on the latent space in gradually increasing and diffuse purple circles (see middle of Figure 1). Since the distribution has no covariance, it'll always be stretched in the vertical or horizontal direction. When you change the input data, you'll see that the distribution changes location and shape to other places in the latent space. For example on the left side in Figure 3, as we draw the digit \"0\" as the input, the latent space gradually interpolates through \"9\" and \"2\" regions before finding itself in the \"0\" region.\nThe latent space itself has many colored points in the background. These points are training data with labels from the MNIST dataset [19]. When a user hovers over the latent space, they"}, {"title": "Low-Level Graph View", "content": "Once the user has a grasp of the overview, they can view the computations involved with the VAE by revealing the VAE computational graph as shown in Figure 2. This section connects the static documentation to the interactive pieces.\nFirst, the Keras [4, 5] Python code is displayed and colored so the notation is easier to understand [6]. The code can be visualized as a computational graph as shown in Figure 4. We show the mean vector $\\mu$ and the log of the variances vector $\\log(\\sigma^2)$ with the real numbers on the graph. The encoder doesn't directly output the standard deviation $\\sigma$ since the standard deviation must be greater than 0. Here we show the Log-Var Trick [15] where we recover the $\\sigma$ by applying\n$\\sigma = \\sqrt{e^{\\log(\\sigma^2)}}$\n$= e^{\\frac{1}{2}\\log(\\sigma^2)}$\n$= \\sigma$\nwhich forces the standard deviation $\\sigma$ to be positive [15]. The Log-Var trick is represented on the graph as mapping the encoding ($\\log(\\sigma^2)$) through the exponential function node to produce the output ($\\sigma$) vector (see Figure 4).\nThe parameters $\\mu$ and $\\sigma$ specify the normal distribution $z \\sim N(\\mu, \\sigma^2)$ we sample from. The Reparameterization Trick [11] samples $N(\\mu, \\sigma^2)$ by sampling a standard normal distribution"}, {"title": "Implementation", "content": "To make VAE EXPLAINER, we trained an existing implementation of a VAE directly copied from the Keras Variational Autoencoder Example [5] with some modifications for presentation. The training can be found in a Colab Notebook.\nJust to summarize from [5], the model consists of a Convolutional Neural Network [13] as the encoder and the opposite as the decoder (Convolution Transposes). The model was trained with the Adam optimizer [10] over 30 epochs of the 60,000 MNIST Digits train set [19].\nAfter training the model, we converted the Keras model to a TensorFlow graph and exported the graph to a TensorFlowJS format so it could be run in the browser [1, 4, 7]. We specifically exported the encoder and decoder as separate models so that the middle computation could be computed and visualized in the browser easily. Additionally, we computed the encodings for the first 10,000 MNIST Digit train set [19] images to better map out the latent space in the browser.\nWe used JavaScript, TensorflowJS [7], and Svelte [8] for the interactive frontend. The visualizations are primarily SVG and Canvas elements. The frontend code can be found at the open source repository https://github.com/xnought/vae-explainer and the live site can be found at https://xnought.github.io/vae-explainer."}, {"title": "Conclusion", "content": "VAE EXPLAINER adds live interaction to static explanation. First a user can summarize what a VAE does, then they can view the real code and computational graph for how a VAE works.\nTo improve this work, more explanation on the VAE loss function would further help someone understand how the encoded normal distributions are regularized to standard normal. Additionally, extending to Vector Quantized Variational Autoencoders (VQ-VAE) would cover the latest and greatest for Autoencoders."}]}