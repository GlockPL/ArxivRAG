{"title": "Standardised schema and taxonomy for AI incident databases in critical digital infrastructure", "authors": ["Avinash Agarwal", "Manisha J. Nene"], "abstract": "The rapid deployment of Artificial Intelligence (AI) in critical digital infrastructure introduces significant risks, necessitating a robust framework for systematically collecting AI incident data to prevent future incidents. Existing databases lack the granularity as well as the standardized structure required for consistent data collection and analysis, impeding effective incident management. This work proposes a stan- dardized schema and taxonomy for AI incident databases, addressing these challenges by enabling detailed and structured documentation of AI incidents across sectors. Key contributions include developing a unified schema, introducing new fields such as incident severity, causes, and harms caused, and proposing a taxonomy for classifying AI incidents in critical digital infrastructure. The proposed solution facilitates more effective incident data collection and analysis, thus supporting evidence-based policymaking, enhancing industry safety measures, and promoting transparency. This work lays the foundation for a coordinated global response to AI incidents, ensuring trust, safety, and accountability in using AI across regions.", "sections": [{"title": "I. INTRODUCTION", "content": "Increasing integration of AI systems into critical digital in- frastructure offers both transformative benefits and significant risks. The potential for AI-driven failures or unforeseen con- sequences necessitates the establishment of robust incident reporting mechanisms. A standardized AI incident reporting mechanism would allow for the systematic collection and detailed analysis of incident data, helping to uncover trends, identify vulnerabilities, and prevent future incidents by learn- ing from past incidents [1]. Such knowledge is essential for devising effective mitigation strategies, developing safety protocols, evolving considered best practices, and informing regulatory frameworks that govern the use of AI in these sensitive domains [2]. Recent regulatory developments further underscore the need for such a framework. These include the EU AI Act, which mandates reporting of serious incidents involving high-risk AI systems, including those in critical infrastructure [3]. To quote the EU AI Act, serious incident means an incident or malfunctioning of an Al system that directly or indirectly leads to any of the following: (a) the death of a person, or serious harm to a person's health; (b) a serious and irreversible disruption of the management or operation of critical infrastructure. (c) the infringement of obligations under Union law intended to protect fundamental rights; (d) serious harm to property or the environment. Despite the pressing need, a standardized approach for documenting and analyzing AI incidents in these sectors is currently lacking [4]. The effectiveness of current AI incident databases, such as the Artificial Intelligence In- cident Database (AIID) [5] and the AI, Algorithmic, and Autonomous Incident Classification (AIAAIC) Repository [6], is hampered by several key issues. These databases vary significantly in their structure and the granularity of the data they capture [2], making it complicated to aggregate and analyze information across different sectors and regions. For instance, while some databases focus on high-level incident descriptions, others lack detailed fields necessary for thorough analysis. Additionally, the absence of a unified taxonomy for categorizing incidents further complicates ef- forts to draw actionable insights from the data [7]. These inconsistencies highlight the need for a more standardized approach to AI incident reporting that can ensure compre- hensive, comparable, and actionable data [8]. This study addresses these challenges by developing a standardized schema and taxonomy for AI incident databases. The objective is to create a unified framework that can be adopted across various sectors, enabling consistent and detailed documentation of AI incidents. By standardizing the AI incident reporting and categorization methodology, this research aims to enhance the quality and utility of AI incident data, providing a stronger foundation for analyzing risks, developing mitigation strategies, and informing policy decisions. This paper makes two significant contributions. First, it establishes a standardized schema for AI incident reporting, which enhances the granularity and consistency of data collection across various databases. Second, it introduces a taxonomy for classifying AI incidents in critical digital infrastructure, improving the comprehensiveness and clarity of incident data. The structure of this paper is as follows: Section II analyses"}, {"title": "II. ANALYSIS OF EXISTING AI INCIDENT DATABASES", "content": "This section reviews existing AI incident databases world- wide, highlighting their limitations in systematically collect- ing and categorizing incident data."}, {"title": "A. AIAAIC Repository", "content": "The AIAAIC Repository [6], which stands for 'AI, Al- gorithmic, and Automation Incidents and Controversies', is an evolving open resource that documents incidents and controversies related to artificial intelligence, algorithms, and automation. It collects and classifies these occurrences, shedding light on the ethical, social, and technical dimensions that drive them. AIAAIC emphasizes broader impacts such as job displacements, environmental damage, and misleading marketing. The repository covers a wide array of issues, with 1009 incidents and 411 issues reported as of September 2024. This resource is publicly accessible, aiming to serve as a tool for researchers, policymakers, educators, and the general public to understand and navigate the complexities of AI and automation."}, {"title": "B. AI Incident Database (AIID)", "content": "The AIID [9] is another resource dedicated to documenting AI-related incidents. Inspired by similar incident databases in aviation and computer security, AIID seeks to record past AI incidents. It compiles real-world harms or near harms caused by Al systems across various domains, making it a non- domain-specific resource. As of September 2024, AIID has recorded 759 incidents and over 3,500 reports. Managed by an industrial/non-profit cooperative, the database is an open resource accessible to the public, with incident submissions reviewed before being added. It also encourages community participation, recognizing that collective input is crucial for improving AI safety and accountability [1]."}, {"title": "C. Other Al incident repositories", "content": "In addition to these two AI incident databases, there are a few other repositories for documenting AI-related incidents. The AI Vulnerability Database (AVID) [10] catalogs about 40 AI system vulnerabilities, including general failure modes and specific reports of these failures. AVID uses a detailed taxonomy to categorize issues, such as security, ethics, and performance, providing AI developers and auditors with valuable evaluation methods. The AI Incidents Monitor (AIM) is a developing initiative by the OECD.AI expert group designed to track real-time AI incidents [11]. AIM aims to provide an evidence base to inform AI incident reporting frameworks and related policy discussions. Unlike AIID and AIAAIC, AIM does not currently allow open submissions. Another repository, 'Where in the World is AI?' presents AI incidents on an interactive global map, highlighting re- sponsible or unethical uses of AI globally. It emphasizes the geographical context, labeling incidents as either harmful or helpful. However, the map has not been updated since 2021, and its database is currently inaccessible. In addition to these, there are informal lists on platforms like Twitter and GitHub that chronicle problematic AI sys- tems. These lists lack formal taxonomies and reporting struc- tures but still represent early efforts to document irresponsible AI use. Lastly, various government databases, such as those in the European Union, Amsterdam, Helsinki, and Chile, provide transparency by cataloging Al systems used in the public sector. These registers offer detailed information about the designs, contexts, and impacts of various AI systems, serving as useful tools for public awareness and governance."}, {"title": "D. Database Schema Discrepancies", "content": "Table I presents the data fields of the two databases, highlighting their vastly different and incompatible structures. Additionally, both databases lack fields required for capturing detailed structured information necessary for a thorough analysis of incidents, such as the causes, context, and impacts. For illustration, AIAAIC does not have fields for the affected parties and incident summaries. On the other hand, AIID does not have fields for the concerned application name, its technology and purpose, impacted sectors, and so on."}, {"title": "E. Inconsistent definitions and taxonomies", "content": "Another challenge is the lack of standardized definitions and taxonomies for classifying AI incidents. Each database uses its own criteria, which may not align with regulatory def- initions. For example, AIAAIC incident with id AIAAIC1724 [12] pertains to smog caused by gas turbines of a data center of xAI company. This incident is not an outcome of any AI application, and recording it as an AI incident is not accurate. The same is the case with incident id AIAAIC1695 [13], related to industrial waste dumped by Microsoft's Mekaguda data center, which also should not be listed as an Al incident. Similarly, incident id AIAAIC1561 [14] relates to a lawsuit filed against OpenAI and Microsoft for alleged copyright infringements while training their AI models, which may not fit into the OECD's definition of an AI incident [15]. The absence of a consistent framework further compli- cates the evaluation of incident severity. Both databases do not provide detailed classifications for types of harm, their severity, and their root causes. They also lack specific infor- mation on AI applications, such as version numbers. Without standardized definitions and taxonomies, it is challenging to categorize incidents effectively, identify commonalities, and analyze patterns across different databases. In conclusion, there are only a few AI incident databases available globally. Further, they suffer from several significant shortcomings. These include insufficient data fields, incom- patible schemas, and a lack of standardized taxonomies. Also, it is challenging to classify incidents for systematic analysis due to varying definitions of an AI incident and a lack of detailed data. Additionally, these databases are often general- purpose, with limited attention to specific sectors, such as critical digital infrastructure, where more detailed and sector- specific information is crucial. These limitations hinder the effectiveness of these databases in providing comprehensive insights into AI-related incidents. This work addresses these gaps by proposing a standardized schema and taxonomy."}, {"title": "III. RESULTS", "content": "The results section presents two key outcomes: the devel- oped standardized schema and the proposed taxonomy for AI incident databases for critical digital infrastructure."}, {"title": "A. Proposed standardized schema", "content": "In developing a standardized schema for AI incident re- porting, existing fields from the AIID, AIAAIC, and other repositories were carefully reviewed and incorporated. Fur- ther, additional fields were introduced to enhance the com- prehensiveness and utility of the database. These additions, such as incident causes, incident severity, and distinct types of harm, enable a deeper understanding of the root causes and diverse impacts of AI incidents. Table II presents the proposed standardized fields of an AI incident database. The fields are selected to ensure clarity, consistency, and comprehensiveness, facilitating the accurate collection and analysis of AI incident data across diverse contexts. The description of each field is as follows:\n1) Incident ID: A unique identifier assigned to each inci- dent.\n2) Incident Title: A concise title that encapsulates the incident.\n3) Incident Summary: A detailed overview of the incident, up to 250 words.\n4) Incident Date: The exact date (and time, if applicable) when the incident occurred.\n5) Incident Location(s): The geographical area(s) where the incident occurred.\n6) Affected Party(ies): The individuals, organizations, or entities impacted by the incident.\n7) Sector(s) Impacted: The industry or sector affected by the incident.\n8) Incident Issue(s): The specific concerns related to the system, governance, technology, or third-party actions.\n9) AI Application Name(s): The name of the AI system or application involved in the incident.\n10) Application Version: The specific version of the AI application in use.\n11) Application Technology(ies): The technologies em- ployed within the AI application/system.\n12) Application Purpose(s): The intended function or goal of the AI application.\n13) Application Deployer: The organization or entity re- sponsible for deploying the AI system.\n14) Application Developer: The organization or entity that created the AI system.\n15) Application Transparency: The clarity, accessibility, and accountability of the Al system to users and stakeholders, including the ability to challenge it.\n16) Incident severity: The level of impact or seriousness of the incident.\n17) Incident Cause(s): The root causes or contributing factors leading to the AI incident.\n18) Physical Harm: Any form of injury, damage, or adverse impact on the physical well-being of an individual or a group.\n19) Environmental Harm: Any adverse impact or damage on the environment affecting ecosystems, wildlife, air, water, or soil.\n20) Property Harm: Damaging or destroying property of an individual, group, or organization.\n21) Psychological Harm: Damage to mental health and well-being of an individual or a group.\n22) Reputational Harm: Damage to the reputation of an individual, group, or organization.\n23) Economic Harm: Impairment of financial assets of an individual, group, or organization.\n24) Legal/Regulatory Harm: Any legal or regulatory con- sequences arising from the incident.\n25) Human Rights Harm: Damage to fundamental rights or human rights to an individual or a group.\n26) Link to the incident description/news article: A URL directing to external sources for detailed information or news coverage of the incident.\n27) Name of submitter: The full name of the individual or organization submitting the incident report.\n28) Email of submitter: The contact email address of the submitter for follow-up and verification purposes.\n29) Incident news source(s): The sources, such as news articles or reports, from which information about the incident was obtained.\n30) Extra information shared by the submitter: Additional details or context provided by the submitter that may enhance the understanding of the incident.\nNote: Serial numbers 27 to 30 are redacted fields as they pertain to details of the submitter."}, {"title": "B. Proposed taxonomy", "content": "Table III presents the proposed taxonomy for AI incidents in critical digital infrastructure. It is designed to address the unique challenges and impacts of AI failures in areas like telecommunications and energy. A general-purpose taxonomy may not be able to capture the specific nuances and critical aspects of Al incidents in essential sectors. It categorizes incidents by type, affected systems, severity, cause of failure, and harm, providing subcategories and examples such as network disruptions and IoT component failures. This tar- geted approach ensures that the taxonomy reflects the distinct complexities of critical digital infrastructure, offering detailed insights and actionable data that broader frameworks might overlook. The structured and specialized framework proposed in this work enhances incident analysis and management, contributing to improved resilience and compliance in these crucial sectors."}, {"title": "IV. DISCUSSION", "content": "This study aims to address significant gaps in AI incident reporting by introducing a unified schema and taxonomy cus- tomized for critical digital infrastructure. Existing databases, such as AIID and AIAAIC, are beset by inconsistent data formats and insufficient granularity, hindering effective in- cident analysis and integration. Further, they, being general-purpose, lack the specific details required to analyze incidents in specialized sectors, such as critical digital infrastructure. Our standardized schema directly tackles these issues by incorporating specific fields like incident causes, incident severity, and types of harm. For instance, a general system failure previously reported in AIID is now captured with precise details, such as sectors affected, incident locations, incident issues, etc., allowing for a clearer assessment of impact and contributing factors. This level of detail enhances the ability to analyze and understand the specific nature of each incident, leading to more effective responses and mitigation strategies. Similarly, AIAAIC's previous reporting often lacked suf- ficient context, making it difficult to gauge the causes and implications of incidents. Our schema addresses this by in- cluding detailed fields. For example, to understand the cause of the incident, the proposed schema includes fields that are not available in AIAAIC, such as incident summary, incident causes, and application version. Similarly, to gauge the impact of an incident, fields missing in AIAAIC have been included to document comprehensive information, such as incident severity, property harm, psychological harm, human rights harm, etc., enabling more targeted and actionable insights. The proposed taxonomy categorizes incidents by type (e.g., network disruption, security breach), affected systems (e.g., core network, IoT components), severity (e.g., critical, high), causes of failure (e.g., AI misconfiguration, predictive maintenance error), and types of harms (physical, envi- ronmental, property, psychological, reputational, economic, legal/regulatory, and human rights harms). This structure facilitates more effective pattern recognition and predictive analysis. For example, incidents involving IoT components are now specifically identified, allowing for the detection of trends and vulnerabilities that were previously hidden under broad classifications. By standardizing the reporting schema and taxonomy, this work consolidates data from disparate sources into a coherent format, enhancing data clarity and supporting thorough anal- ysis. The improved granularity and detailed categorization not only facilitate better-informed decision-making and policy development but also strengthen resilience and compliance in critical digital infrastructure sectors. Overall, this unified schema and taxonomy represents a significant advancement in addressing the deficiencies of existing reporting systems, providing a robust framework for systematic documentation, analysis, and management of AI incidents."}, {"title": "V. CONCLUSION AND FUTURE WORK", "content": "The increasing deployment of AI systems in critical digital infrastructure presents significant potential risks that could lead to system failures or unpredictable operations. The lack of a standardized framework for reporting AI incidents has hindered efforts to collect incident data, systematically analyze them, and develop mitigation strategies. This study addresses this issue by proposing a standardized schema and taxonomy for AI incident databases, enabling more consistent and comprehensive documentation of incidents across various sectors. One of the primary contributions of this work is the development of a unified schema that enables detailed and structured collection of AI incident data, overcoming previous challenges of integrating disparate databases with incompat- ible structures. This schema addresses the shortcomings of existing repositories that lacked data fields with the required granularity for a meaningful analysis. Further, incorporating new fields, such as incident severity, causes, and types of harm, facilitates a comprehensive analysis of root causes and diverse impacts. Additionally, the proposed taxonomy enables the systematic classification of AI incidents for further re- search and policymaking. This work is crucial as it establishes a foundation for a more unified global response to AI incidents and enables the effective application of lessons learned from one sector or region to others. This work provides significant value across various sectors. For academia and researchers, the standardized schema and taxonomy lay a strong foundation for systematic studies and future research on AI incidents by identifying patterns, predicting incidents, and refining mitigation strategies. Industry can leverage these tools to enhance the safety and reliability of AI systems. For poli- cymakers, the standardized framework serves as a basis for regulatory efforts to ensure the safe and ethical deployment of AI in critical digital infrastructure. By categorizing harms and incident severity, the taxonomy enables regulators to prioritize areas of concern and develop targeted interventions. The detailed, standardized data captured using the proposed schema supports evidence-based policymaking, addressing gaps in existing regulations and frameworks. Lastly, the pub- lic benefits from increased transparency and accountability promoted by this standardized approach. As AI continues to evolve, the standardized schema and taxonomy proposed here will be instrumental in ensuring that AI incidents are systematically documented, analyzed, and addressed in a manner that promotes trust, safety, and accountability in Al systems. Future work: Future efforts should focus on adopting this standardized schema across different sectors and geographies. Additionally, ongoing refinement of the schema, informed by new incidents and emerging technologies, will be crucial. Expanding AI incident reporting and integrating it with auto- mated reporting tools are also key areas for further research."}]}