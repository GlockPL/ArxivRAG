{"title": "DUET: Optimizing Training Data Mixtures via Feedback from Unseen Evaluation Tasks", "authors": ["Zhiliang Chen", "Gregory Kang Ruey Lau", "Chuan Sheng Foo", "Bryan Kian Hsiang Low"], "abstract": "The performance of a machine learning (ML) model depends heavily on the relevance of its training data to the domain of the downstream evaluation task. However, in practice, the data involved in an unseen evaluation task is often not known to us (e.g., conversations between an LLM and a user are end-to-end encrypted). So, it is not obvious what data would be relevant for training/fine-tuning the ML model to maximize its task performance. Instead, one can only deploy the ML model in the unseen evaluation task to gather multiple rounds of coarse feedback on how well the model has performed. This paper presents a novel global-to-local algorithm called DUET that can exploit the feedback loop by interleaving a data selection method with Bayesian optimization. As a result, DUET can efficiently refine the training data mixture from a pool of data domains to maximize the model's performance on the unseen evaluation task and its convergence to the optimal data mixture can be theoretically guaranteed by analyzing its cumulative regret. Empirical evaluation on image and LLM evaluation tasks shows that DUET finds better training data mixtures than conventional baselines.", "sections": [{"title": "1. Introduction", "content": "The performance of an ML model depends heavily on the composition of training data domains (Chen et al., 2024a; Xie et al., 2023) and the downstream evaluation task (Hoffmann et al., 2022; Long et al., 2017). For instance, if users of an LLM are interested in asking layman science questions, then fine-tuning the LLM with more Wikipedia data allows it to converse better with the users. Hence, knowing the evaluation task is important as it informs us on the relevant training data to be selected from an existing pool of data domains to produce a better-performing ML model.\nHowever, in practice, the data (e.g., its domain, distribution, or labels) involved in a downstream unseen evaluation task is often not known to us. So, it is not obvious what data would be relevant for training or fine-tuning the ML model. Instead, one can only deploy the ML model a few times in the unseen evaluation task to gather multiple rounds of feedback on how well our ML model has performed, thereby creating a feedback loop. Furthermore, each round of feedback incurs significant time or monetary costs. Hence, the key challenge lies in how to achieve efficiency in the number of feedback rounds to refine the training data and improve the task performance of the ML model. This problem setting has become increasingly important recently: Any LLM owner would be interested in fine-tuning its LLM to converse better with the users but due to privacy concerns (Li et al., 2024), conversations between their deployed LLM and users are end-to-end encrypted (openai.com/enterprise-privacy). So, the LLM owner does not know the conversation domain or data seen by the deployed LLM. Rather, the LLM owner can only receive coarse feedback on how well its LLM has performed in the conversation (e.g., ratings from human users indicating their satisfaction with the LLM) and gather multiple rounds of feedback from the users.\nThis paper presents a novel algorithm called DUET that can exploit the feedback loop to optimize the training Data mixture for the Unseen Evaluation Task. DUET is a global-to-local algorithm that interleaves influence function (IF) (Koh & Liang, 2017) as a data selection method (Albalak et al., 2024; Ting & Brochu, 2017) with Bayesian"}, {"title": "2. Preliminaries", "content": "We first provide an outline of how BO can be used to optimize a generic black-box objective function. We will provide details later on how BO is used in DUET (Sec. 3.3). We consider a black-box objective function $f: \\mathbb{R}^n \\rightarrow \\mathbb{R}$ over the space of inputs $r\\in \\mathbb{R}^n$. The goal is to find $r^* = \\text{argmin}_{r} f(r)$ which minimizes the objective function. BO is an active algorithm that strategically selects input points to query the black-box objective function, conditioned on previous function observations. At each iteration $t = 1, 2, ..., T$ of BO, we query the black-box function with a selected input $r_t$ to obtain a noisy observation $\\tilde{y}_t = f(r_t)+\\epsilon_t$ with a sub-Gaussian noise $\\epsilon_t$ (e.g., Gaussian or bounded noise) to form the sample $(r_t, \\tilde{y}_t)$. Consistent with the work of Chowdhury & Gopalan (2017), we model the unknown function $f$ as a realization of a Gaussian process (GP) (Williams & Rasmussen, 2006) that is fully specified by its prior mean $\\mu(r)$ and covariance $\\kappa(r, r')$ for all $r,r' \\in \\mathbb{R}^n$ where $\\kappa$ is a kernel function chosen to characterize the correlation of the observations between any two inputs r and r'; a common choice is the squared exponen-"}, {"title": "2.1. Bayesian optimization", "content": "We first provide an outline of how BO can be used to optimize a generic black-box objective function. We will provide details later on how BO is used in DUET (Sec. 3.3). We consider a black-box objective function $f: \\mathbb{R}^n \\rightarrow \\mathbb{R}$ over the space of inputs $r\\in \\mathbb{R}^n$. The goal is to find $r^* = \\text{argmin}_{r} f(r)$ which minimizes the objective function. BO is an active algorithm that strategically selects input points to query the black-box objective function, conditioned on previous function observations. At each iteration $t = 1, 2, ..., T$ of BO, we query the black-box function with a selected input $r_t$ to obtain a noisy observation $\\tilde{y}_t = f(r_t)+\\epsilon_t$ with a sub-Gaussian noise $\\epsilon_t$ (e.g., Gaussian or bounded noise) to form the sample $(r_t, \\tilde{y}_t)$. Consistent with the work of Chowdhury & Gopalan (2017), we model the unknown function $f$ as a realization of a Gaussian process (GP) (Williams & Rasmussen, 2006) that is fully specified by its prior mean $\\mu(r)$ and covariance $\\kappa(r, r')$ for all $r,r' \\in \\mathbb{R}^n$ where $\\kappa$ is a kernel function chosen to characterize the correlation of the observations between any two inputs r and r'; a common choice is the squared exponen-"}, {"title": "2.2. Problem setting: Optimizing data mixtures", "content": "In this subsection, we formally describe our problem setting. Suppose that we have N training datasets $D\\equiv \\{D_1, D_2, ..., D_N\\}$ from N different domains (e.g., Wikipedia, ArXiv for language tasks). Hence, D is the union of training datasets from each domain. Let $L_{eval}(\\theta)$ be the unseen evaluation task loss w.r.t. an ML model parameterized by $\\theta$. This loss can only be observed as a coarse feedback from the unseen evaluation task and does not have a closed, mathematical form. Our goal is to find an optimal data mixture $X^* \\in D$ (a set of training data points) and learn model parameters $\\theta_{X^*}$ such that the unseen evaluation task loss $L_{eval}$ is minimized:\n$\\begin{aligned}\n& \\min_{X \\in D} L_{eval}(\\theta_{X})\n& \\text{s.t.} \\ \\ \\ |X| = M,\n\\end{aligned}$        (2)\nwhere $\\theta_X \\equiv \\text{argmin}_{\\theta} L_{train}(X, \\theta)$ is the model parameters learnt in a standard supervised learning manner (e.g., gradient descent) from a chosen data mixture X and $L_{train}$ is a standard model training loss (e.g., cross-entropy loss for LLM prediction). M is a practical constraint that can be decided beforehand (Mirzasoleiman et al., 2020) and is used to"}, {"title": "3. Optimizing Training Data Mixtures using DUET", "content": "Unfortunately, solving problem (2) is challenging because the unseen evaluation task loss $L_{eval}$ does not have a closed, mathematical form and finding the optimal data mixture $X^*$ directly is a high-dimensional discrete optimization problem if the size of each dataset in D large. To alleviate this, DUET adopts a global-to-local approach to optimize the training data mixture. At a global level, DUET exploits feedback $L_{eval}$ from the unseen evaluation task to iteratively refine the mixing ratio of data domains in D. At a local level, DUET uses IF as a data selection method to remove low-quality data points from the data mixture at each iteration."}, {"title": "3.1. Reparameterization of the optimization problem", "content": "To perform DUET effectively, we first reparameterize the objective function of problem (2) into a bilevel optimization problem that, at the outer level, depends on the mixing ratio $r\\in \\mathbb{R}^N$ of training data domains (entries in r sum to 1). This reparameterized problem has a unique structure that can be solved by interleaving data selection methods with BO, which we cover in Sec. 3.2 & 3.3.\n$\\boxed{X^* \\text{, the optimal set of data points from } D, \\text{ is the solution of the original problem (2) iff } r^* = \\text{ratio}(X^*) \\text{ is the optimal mixing ratio solution of the reparameterized problem:}}$\n$\\begin{aligned}\n&\\min_{r\\in \\mathbb{R}^N} \\min_{X \\in S_r} L_{eval}(\\theta_X),\n\\end{aligned}$        (3)\nwhere $S_r\\equiv \\{X : X \\in D, \\text{ratio}(X) = r,|X| = M\\}$ and $\\text{ratio}(X) = r$ means that the data points in X satisfies the given ratio $r \\in \\mathbb{R}^N$ from N data domains and $||r||_2 = 1$.\nThe proof can be found in App. B.1, where we show that $X^*$, the solution data mixture of original problem (2), satisfies a mixing ratio $r^*$ that is also the solution of the reparameterized problem (3). Notice that this reparameterized problem consists of an outer and inner optimization problem, and the outer problem requires us to find the optimal mixing ratio $r^*$. DUET aims to solve problem (3) in an iterative manner. At the outer optimization level (global), DUET uses BO to exploit feedback from the evaluation task to propose a promising mixing ratio $r_t$ at each iteration t. At the inner optimization level (local), we introduce a sampling strategy that uses the IF values of each data point w.r.t. its local domain to retrieve a high-quality subset of data points that satisfies the proposed mixing ratio $r_t$ and approximately solves the inner problem. By repeating the process iteratively, our approach theoretically converges (theorem. 4.1)"}, {"title": "3.2. Using data selection methods for inner problem", "content": "The inner optimization problem seeks to find the best-performing data mixture that satisfies the given mixing ratio r from the outer level. In this section, we propose an IF-driven estimator that relies on sampling to approximately solve the inner problem given a data ratio r:\n$\\begin{aligned}\n&X^* \\triangleq \\mathop{\\text{argmin}}\\limits_{X \\in S_r} L_{eval}(\\theta_{X}),\n\\end{aligned}$         (4)\nwhere $S_r\\triangleq \\{X : \\text{ratio}(X) = r,|X| = M\\}$. To solve the inner problem, we need to find a subset of data $X^*$ that yields the lowest evaluation task loss $y^* = L_{eval}(\\theta_{X^*})$ while still constrained to the proposed mixing ratio r.\nA simple approach, based on prior works on estimating distribution extrema (de Haan, 1981; Lee & Miller, 2022), is to randomly sample k different data mixtures from $S_r$. This yields k samples of training data mixtures $\\{X_1,...,X_k\\}$ (each satisfying the mixing ratio r), in which a uniform random estimator for y can be obtained by checking the evaluation task loss of the ML model trained on each data mixture sample and taking the minimum: $\\tilde{y} = \\min_{X_i} \\{L_{eval}(\\theta_{X_1}),..., L_{eval}(\\theta_{X_k})\\}$ and $X^* = \\text{argmin}_{X_i} \\{L_{eval}(\\theta_{X_1}), ..., L_{eval}(\\theta_{X_k})\\}$ as the solution estimate of inner problem (4). The estimator $\\tilde{y}$ is the 1st-order statistic (Arnold et al., 2008) and a random variable. While consistent (i.e., as we increase the sampling size k, we can estimate the solution of Eq. 4 more accurately), the uniform random estimator $\\tilde{y}$ has high variance (we provide empirical evidence in Fig. 6) because from k uniformly random data mixture samples, it is unlikely we can select the optimal data mixture.\nWe aim to improve the quality of estimator $\\tilde{y}$ by using data selection methods (Sim et al., 2022; Wang et al., 2024a) in our sampling process to improve the chance of selecting a data mixture that results in a smaller evaluation task loss. Specifically, we want to reduce the estimator's variance or bias (w.r.t. a fixed sampling size k) by increasing the chance of sampling high-quality data points (conversely, reduce the chance of sampling low-quality data points) from each data domain, before using it to train an ML model. To do so, we incorporate Influence function (Koh & Liang, 2017) (IF), a popular data selection method that identifies high-quality data points (Saunshi et al., 2023) into our estimator $\\tilde{y}$, and show empirically that doing so improves our estimation of the inner problem solution by reducing our estimator's bias and variance. In App. A.4, we also explore and discuss the use of other data selection methods, such as coresets (Mirzasoleiman et al., 2020) and diversity-driven subset selection (Wang et al., 2024b). In general, we found the use of IF the most practical due to its ease of implementation and efficiency.\n$\\text{IF-driven estimator.}$ We construct the IF-driven estimator in the following manner: first, for each dataset $D_i \\in D$ from the training domains, we train or fine-tune a local model on that dataset (e.g., train a model from Wikipedia data, a model from ArXiv etc.). This produces N different ML models. Second, we derive the IF value of every training data point w.r.t. the trained ML model for its respective domain (this can be computed and stored beforehand; more details in App. A.3). Lastly, given a mixing ratio r proposed at each iteration, we perform weighted sampling from each domain based on each data point's IF value within the domain dataset (instead of uniform sampling as mentioned previously) until we satisfy the mixing ratio r. From hereon, we refer to this sampling process as IF-weighted sampling. Hence, for each data domain, there is a higher chance to sample a data point with a higher IF value. This yields a single sample of data mixture $X^{IF}$. By performing IF-weighted sampling k times, we obtain k samples of IF-weighted data mixtures $\\{X^{IF}_1, . . ., X^{IF}_k\\}$, in which we obtain a new IF-driven estimator:\n$\\begin{aligned}\n&\\tilde{y}^* = \\min_{X_i} \\{L_{eval}(\\theta_{X^{IF}_1}),..., L_{eval}(\\theta_{X^{IF}_k})\\},\n\\end{aligned}$   (5)\nwhich we use to estimate the solution of inner optimization problem (4). The key difference between the IF-driven estimator and the uniform random estimator is that the IF-driven estimator places higher emphasis on selecting data with high IF values, and prior works (Saunshi et al., 2023) have regarded data points with higher IF values as of higher quality. Next, we provide empirical evidence into why the IF-driven estimator performs better than the uniform random estimator in finding better data mixtures."}, {"title": "3.3. Using Bayesian optimization for outer problem", "content": "With the IF-driven estimator introduced to estimate the inner optimization problem solution, we shift our focus to solving the outer optimization problem of problem (3), which aims to find the optimal data mixing ratio $r^*$ for the unseen evaluation task. Since the solution of the inner problem $\\tilde{y} = \\min_{X \\in S_r} L_{eval}(\\theta_{X})$ depends only on the mixing ratio r, we can succinctly define a function $f(r) \\triangleq \\tilde{y} = \\min_{X \\in S_r} L_{eval}(\\theta_{X})$, where for a given mixing ratio r, we use the IF-driven estimator to estimate a solution for the inner problem, producing f(r). As such, the outer optimization problem of problem (3) can be rewritten into:\n$\\begin{aligned}\n&\\min_{r} f(r).\n\\end{aligned}$         (6)\nwhere $r \\in \\mathbb{R}^N$ is the mixing ratio over the N training domains and the sum of entries in r is constrained to 1 (since it is a ratio). DUET uses BO with constraints of $||r||_2 = 1$ (Sec. 2.1) to find the optimal data mixture ratio $r^*$ to solve outer problem (6). BO is suitable for solving this problem for a few reasons. First, evaluating f requires us to use the IF-driven estimator to estimate the inner optimization problem solution and thus f is a black-box function with no closed, mathematical form; BO is a principled and popular framework to optimize such black-box functions (Garnett, 2023; Pyzer-Knapp, 2018). Second, we can only estimate the inner problem solution (Theorem 3.2) using our IF-driven estimator introduced in the previous section. Hence, this implies we can only obtain noisy observations $f(r) + \\epsilon$, where $\\epsilon$ is a random noise variable with the same distribution as that in theorem 3.2; fortunately, BO handles noisy function observations gracefully (Srinivas et al., 2010; Chowdhury & Gopalan, 2017) during the optimization pro-cess, allowing us to find the optimal mixing ratio eventually (theoretical results shown in Sec. 4)."}, {"title": "3.4. Interleaving the IF-driven estimator and BO", "content": "DUET uses BO at the outer level and IF-driven estimator at the inner level to iteratively optimize the data mixture, solving problem (3). We describe DUET in Algorithm. 1.\nAlgorithm 1 DUET: Optimizing Data Mixtures for Unseen Evaluation Task\n1: Input: N training datasets from N domains $\\{D_1,...,D_N\\}$. Computed IF values of each data point (App. A.3) w.r.t. its domain dataset and locally trained model. Initial observation of data mixture ratio and evaluation task performance: $D_0 \\equiv \\{(r_0, \\tilde{y}_0)\\}$, SE kernel $K$, sampling size k, parameter $\\beta_t$ for acquisition step and total number of BO iterations T.\n2: for t = 1,..., T do\n3:      $r_t = \\text{argmin}_r \\mu_t(r) - \\beta_t \\sigma_t(r)$ (BO acquisition step)\n4:      IF-weighted sampling to obtain k samples of data mixtures $\\{X^{IF}_1, ..., X^{IF}_k\\}$ (Sec. 3.2).\n5:      $\text{IF-driven estimator at iteration t:}$ $\\tilde{y}^* = \\min_{X_i} \\{L_{eval}(\\theta_{X^{IF}_1}),..., L_{eval}(\\theta_{X^{IF}_k})\\}$.\n6:      Keep track of best performing data mixture $X^* = \\text{argmin}_{X_i} \\{L_{eval}(\\theta_{X^{IF}_1}),..., L_{eval}(\\theta_{X^{IF}_k})\\}$.\n7:      $D_t = D_{t-1} \\cup \\{(r_t, \\tilde{y})\\}$\n8:      Update the GP posterior and $K$ with updated observations $D_{t+1}$ (Sec. 2.1).\n9: end for\n10: Output $X^* = \\text{argmin}_{X^*\\in \\{X^*_1,..,X^*_T\\}} L_{eval}(\\theta_{X^*})$\nAt iteration t, DUET uses the LCB acquisition function (Srinivas et al., 2010) on the GP posterior to propose a candidate mixing ratio $r_t$ for our data domains (Line 3). Using the proposed mixing ratio $r_t$, we use IF values of each data point to compute the IF-driven estimator $\\tilde{y}$ and keep track of the best performing data mixture $X^*$ at current iteration t (Line 4, 5 and 6). Note that the data mixture $X^*$ at each iteration t satisfies the proposed mixing ratio $r_t$. Next, we include $(r_{t+1}, \\tilde{y})$ into our historical observations $D_{t+1}$ (Line 7) and update our GP posterior (Line 8). After which, we repeat the entire process, until the budget of T BO iterations is exhausted. In the end, we recover the best performing data mixture $X^*$ (Line 10).\nDUET can be implemented easily by LLM practitioners. Once a data mixture is sampled using the IF-driven estimator to fine-tune the LLM at each BO iteration, the trained LLM can be deployed for a small period of time (e.g., one day on a small subset of users) to gather feedback (e.g., user rating) from conversations with human users. Then, DUET proposes a new data mixing ratio to refine the training data mixture. As seen from our experiments (Sec. 5), the model performance on the unseen evaluation task improves as DUET progressively optimizes the data mixture to be more relevant to the task."}, {"title": "4. Theoretical Analysis", "content": "We analyze the convergence rate of DUET using the growth of attained cumulative regret (Chen et al., 2024b) $R_T = \\sum_{t=1}^T \\tilde{y_t} - f(x^*) = \\sum_{t=1}^T |f(r^*) + \\epsilon_t - f(r_t)|$ for T BO iterations. The attained cumulative regret consists of two terms, where $|f(r^*) - f(r_t)|$ indicates the quality of mixing ratio $r_t$ proposed at each iteration while $\\epsilon_t$ indicates how well we can estimate the inner problem solution at every iteration. By analyzing the attained average regret $R_T/T$ with $T\\rightarrow\\infty$, the following theorem helps us understand how close our algorithm converges (Berkenkamp et al., 2019) to the optimal evaluation task loss with increasing number of BO iterations T."}, {"title": "4.1. Convergence analysis using cumulative regret", "content": "We analyze the convergence rate of DUET using the growth of attained cumulative regret (Chen et al., 2024b) $R_T = \\sum_{t=1}^T \\tilde{y_t} - f(x^*) = \\sum_{t=1}^T |f(r^*) + \\epsilon_t - f(r_t)|$ for T BO iterations. The attained cumulative regret consists of two terms, where $|f(r^*) - f(r_t)|$ indicates the quality of mixing ratio $r_t$ proposed at each iteration while $\\epsilon_t$ indicates how well we can estimate the inner problem solution at every iteration. By analyzing the attained average regret $R_T/T$ with $T\\rightarrow\\infty$, the following theorem helps us understand how close our algorithm converges (Berkenkamp et al., 2019) to the optimal evaluation task loss with increasing number of BO iterations T.\nLet f be the outer problem objective defined in Eq. 6 with bounded RKHS norm: $||f||_\\kappa = \\sqrt{(f, f)_\\kappa}$. Also, let our IF-driven estimator for the inner problem solution be governed by the error distribution introduced in Theorem 3.2 with constant c and $\\lambda$ = 1. Let $A_{c,k} \\triangleq \\frac{c^2(1-e^{-\\lambda c})^{-(k-1)}}{(1-e^{-\\lambda c})^k}$, where k is a fixed predecided sampling size. Then, running DUET over f using the LCB acquisition function found in (Chowdhury & Gopalan, 2017) at each BO iteration t = 1, ..., T yields the following attained average regret upper bound with probability at least 1 \u2013 \u03b4:\n$\\begin{aligned}\n&\\lim_{T \\rightarrow \\infty} \\frac{R_T}{T} \\leqslant \\frac{\\delta \\kappa}{\\sqrt{T}} + \\frac{6(\\beta + \\sqrt{k})}{\\sqrt{k}} +2A_{c,k} + \\sqrt{\\frac{2A_{c,k}}{\\delta}}\n\\end{aligned}$\nThe proof is provided in App. B.3 and bounds $|f(r^*) - f(r_t)|$ and $\\epsilon_t$ independently using BO regret analysis (Chen et al., 2024b; Chowdhury & Gopalan, 2017) and the error distribution defined in Theorem. 3.2. Our theorem's average regret indicates how close our algorithm converges to the optimal evaluation task loss with increasing BO iteration T and different choices of sampling size k. Notice that because c characterizes the error of our estimator in Theorem. 3.2, a larger c would decrease $A_{c,k}$ and our average regret. In addition, a larger sampling size k reduces the estimation error of the inner problem (Theorem. 3.2), decreasing $A_{c,k}$ and also reduces our regret bound, allowing us to achieve a better-performing data mixture.\nIn practice, using a large k is computationally expensive because we need to use our IF-driven estimator to sample data mixtures and train our ML models k times at each iteration (selecting one that attains the smallest $L_{eval}$). Fortunately, our experiments (Sec. 5.2) show that setting k = 1 is sufficient to achieve better results than other baselines. If computational resource is not an issue, we can also consider setting an adaptive sampling size (Chen et al., 2024b) that increases w.r.t. each iteration t."}, {"title": "5. Experiments and Discussion", "content": "In this section, we conduct extensive experiments to showcase the effectiveness of DUET compared to other baselines. Our experimental evaluation pipeline is constructed as follows: first, we select data mixtures from different data domains with DUET or other baselines. Second, we train or fine-tune an ML model according to the selected data mixture. Third, we deploy the ML model on the unseen evaluation task to evaluate how well the model has performed. In the next subsection, we provide more details next on how our experiment is setup with varying training and evaluation data domains to showcase DUET's effectiveness even in traditionally difficult out-of-domain scenarios. Our code is in the supplementary material folder."}, {"title": "5.1. Experimental setup", "content": "Our experiments are carried out on two broad classes of evaluation tasks. The first consists of image classification tasks by a VGG-16 model (Simonyan & Zisserman, 2015) over different object domains (Russakovsky et al., 2015; Xiao et al., 2017). The second consists of LLM evaluation tasks by a Llama-8b-Instruct model (Touvron et al., 2023) across different knowledge domains. The image training data consist of binary classification of 4 different clothing types (Shirt, Boots, Sandals, Bags) from the FashionMNIST dataset (Xiao et al., 2017) and cat/dog classification from the Dog & Cat dataset (Elson et al., 2007) (abbreviated as Dog in our plots). The training data domains for LLM evaluation consists of 9 topics: Wikitext (Merity et al., 2016), gsm8k (Cobbe et al., 2021), PubmedQA (Jin et al., 2019), HeadQA (Vilares & G\u00f3mez-Rodr\u00edguez, 2019) , SciQ (Welbl et al., 2017), TriviaQA (Joshi et al., 2017), TruthfulQA (Lin et al., 2022), Hellaswag (Zellers et al., 2019), and CommonsenseQA (Talmor et al., 2019). These domains are chosen specifically for their diversity to mimic topics seen by user-facing LLMs. In our experiments, we vary the difficulty of the unseen evaluation task by adjusting the training and evaluation data domains (see captions of Fig. 3 & 4 for more information).\nWe compare our algorithm with several other baselines: DoReMi is a DRO-driven approach which optimizes the data mixture so that the trained ML model performs well for any evaluation task domain distributions (the original algorithm is used for pre-training, but in our LLM setting we fine-tune our LLM instead). The Uniform weights baseline samples from the training data domains uniformly to produce a data mixture of uniform ratio across different domains. We use DUET with a few different data selection methods: DUET-IF is our main method that uses our IF-driven estimator (Eq. 5) to select data mixtures at each BO iteration; DUET-UR, introduced in Sec. 3.2, uses the uniform random estimator and randomly selects data mixtures"}, {"title": "5.2. Main result", "content": "DUET finds better data mixtures. Our result (Fig. 3 & 4) shows that in different evaluation tasks, DUET finds data mixtures that produce better-performing ML models within a few iterations of feedback loops. The first column in Fig. 3 and 4 (for both image classification and LLM) consists of a relatively easier task where the evaluation task domain is found in the training task domains. In this case, DUET (green plot) uses feedback from the evaluation task to find the optimal data mixture with more emphasis on the relevant training data domain. On the other hand, DoReMi (orange dotted line) cannot adapt to the evaluation task and hence produces worse data mixtures. In the 2nd, 3rd and 4th columns, we increased the difficulty of our evaluation task by removing the evaluation task domain from our training domains (so, the task is out-of-domain). Surprisingly, even for these cases, DUET can still use the unseen evaluation task feedback to automatically improve the quality of the data mixture, achieving better model performance. This is because data from certain training domains could still be useful for the out-of-domain evaluation task (e.g., Wikitext data can still be helpful for mathematical questions in gsm8k). Hence, DUET uses feedback from the unseen evaluation task to place higher weights on more relevant training data domains. In App. C.2, we provide more experimental results for different combinations of evaluation tasks to showcase the effectiveness of DUET.\nIF is an effective data selection method. Our result also shows that DUET-IF, which uses the IF-driven estimator (Eq. 5) to place more sampling emphasis on data points with high IF values, performs better than DUET-UR and DUET-RH. This showcases the effectiveness of using IF values for DUET to work effectively, as compared to other data selection methods."}, {"title": "5.3. Ablation study on different components of DUET", "content": "Next, we perform ablation studies to qualitatively analyze the influence of BO and different data selection methods on DUET's convergence to the optimal evaluation task performance. For clarity purpose, we only use the results for one evaluation task for our analysis. Fig. 5 shows that by naively using a uniform data mixture and training an ML model, we can only achieve an evaluation task performance given by the red dotted line. With only BO, DUET automat-"}, {"title": "6. Conclusion", "content": "Our paper proposes DUET, a novel algorithm that exploits multiple rounds of feedback from a downstream unseen evaluation task to automatically optimize training data mixture. We provide theoretical guarantees of DUET and show that it finds better data mixtures in a variety of image and LLM evaluation tasks as compared to other conventional baselines. In light of the growing importance of our problem setting where we do not know the data in an unseen evaluation task is not known, we hope our work inspires future research to use coarse feedback from the evaluation task to refine the training data mixture for ML models."}, {"title": "A. Additional Discussions", "content": "In our problem setting, (a) there is no direct access to the data (e.g., its domain, distribution, or labels) involved in the unseen evaluation task but (b) multiple rounds of coarse feedback (details covered in Sec. 2.2) can be gathered from the task using a trained ML model. Here, we provide several real-world examples in which such a setting occurs."}, {"title": "A.1. Real-world examples of our problem setting", "content": "In our problem setting, (a) there is no direct access to the data (e.g., its domain, distribution, or labels) involved in the unseen evaluation task but (b) multiple rounds of coarse feedback (details covered in Sec. 2.2) can be gathered from the task using a trained ML model. Here, we provide several real-world examples in which such a setting occurs.\nEnd-to-end encrypted conversations between LLM and users. This setting is specific to the conversational setting between a trained LLM and human users. LLM owners are interested in fine-tuning an LLM to converse well with some human-user demographics but due to real-world privacy concerns (Li et al., 2024), conversations between a deployed LLM and users are end-to-end encrypted during test-time (openai.com/enterprise-privacy). So, an LLM owner does not have any knowledge of the conversation domain or the (unlabeled or labeled) data seen during test-time. Instead, they only receive a feedback on how well the LLM has performed in the conversation (e.g., ratings from the human user, how long each user stays on the applicaton). The LLM owner can collect multiple rounds of feedback over a period of time. Hence, they can exploit this feedback to iteratively refine the training data for the ML model. Many chat-driven applications (e.g., whatsapp, telegram) nowadays use end-to-end encrypted chats, so our problem setting is relevant here.\nModel marketplace. In addition, there are other scenarios in which a model owner needs to improve an ML model without having access to the data involved in the unseen evaluation task. For instance, an ML model owner might rent or sell an image"}]}