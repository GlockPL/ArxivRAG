{"title": "Superior Computer Chess with Model Predictive Control, Reinforcement Learning, and Rollout", "authors": ["Atharva Gundawar", "Yuchao Li", "Dimitri Bertsekas"], "abstract": "In this paper we apply model predictive control (MPC), rollout, and reinforcement learning (RL) methodologies to computer chess. We introduce a new architecture for move selection, within which available chess engines are used as components. One engine is used to provide position evaluations in an approximation in value space MPC/RL scheme, while a second engine is used as nominal opponent, to emulate or approximate the moves of the true opponent player.\nWe show that our architecture improves substantially the performance of the position evaluation engine. In other words our architecture provides an additional layer of intelligence, on top of the intelligence of the engines on which it is based. This is true for any engine, regardless of its strength: top engines such as Stockfish and Komodo Dragon (of varying strengths), as well as weaker engines.\nStructurally, our basic architecture selects moves by a one-move lookahead search, with an intermediate move generated by a nominal opponent engine, and followed by a position evaluation by another chess engine. Simpler schemes that forego the use of the nominal opponent, also perform better than the position evaluator, but not quite by as much. More complex schemes, involving multistep lookahead, may also be used and generally tend to perform better as the length of the lookahead increases.", "sections": [{"title": "1 Introduction", "content": "The fundamental paper on which computer chess programs are based was written in 1950 by one of the most illustrious modern-day applied mathematicians, C. Shannon [Sha50]. It was argued by Shannon that whether the starting chess position is a win, loss, or draw is a question that can be answered in principle through exact minimax search that extends up to game termination with a win by one of the players or a draw.\u00b9 However, the answer will probably never be known because this would require extraordinarily long computation. As an alternative, Shannon proposed a limited lookahead of a few moves and evaluating the end positions by means of some scoring function. This is the principle on which all current major computer chess programs are based: they involve a search through a tree, which is rooted at the current position and extends to a certain depth. The positions at the leaves of the tree are evaluated using the scoring function, and the move chosen at the root of the tree is the one with best backed-up score.\nThe tree may be pruned selectively to save computation time and to extend the length of the search within the given time constraint: this was called a type B strategy by Shannon, to differentiate it from what he called type A strategy that does not resort to any kind of pruning (except to enhance computational efficiency in executing an exact minimax strategy, as in alpha-beta pruning [KnM75]). Chess-playing computer programs typically use a combination of Shannon's type A and type B strategies, but over the years the balance has"}, {"title": "MPC-MC (Model Predictive Control-Meta Chess).", "content": "From a theoretical point of view, MPC-MC allows a synergism of off-line training of the position evaluation function and the on-line search process that is couched on the algorithmic framework of Newton's method. This theoretical view is discussed at length in the recent books by Bertsekas [Ber20], [Ber22a], [Ber23], and the related survey papers [Ber22b] and [Ber24], and will not be explained at any depth in this paper. However, it is fundamentally responsible for the results that we are reporting here. These results suggest that by incorporating any chess engine into our MPC framework, we can improve the performance of that engine, and often dramatically so. As an example, MPC-MC based on Stockfish engines defeats the Stockfish engines on which it is based by overwhelming margins for fast time limits, and by lesser margins for longer time limits (at which the Stockfish play is nearly optimal).\nFinally, we note that the structure and characteristics of our architecture apply not only to chess, but also to any two-person zero-sum game, not involving stochastic uncertainty, such as Shogi, Xiangqi, Checkers, Go, Reversi, etc. It is likely that similar results to the ones reported here can be obtained in the context of these games.\nThe paper is organized as follows. In the next section we describe our MPC-MC architecture in its one-step lookahead form. In Section 3, we introduce the two main variants of MPC-MC, which apply to the cases of a deterministic/known and a stochastic/unknown opponent. We also discuss a so-called fortified variant, which is motivated by experience with rollout algorithms, and is effective against very strong, world champion-caliber opponent engines. In Section 4, we provide detailed experimentation results, which support the theoretical development of Section 3. Moreover, we discuss experiments with another variant of MPC-MC, which uses a \"half-step\" lookahead and does not involve a nominal opponent (only a position evaluation for each legal move at the current position, see Section 4.2). Consistent with theoretical predictions, this variant of MPC-MC improves the performance of the position evaluation engine, but not by as much as the one-step lookahead variants. In Section 5, we discuss multistep lookahead versions of MPC-MC, which achieve somewhat better results that their one-step lookahead variants, at the expense of more intensive computation."}, {"title": "2 The MPC-MC Architecture", "content": "Given a chess position x, a typical chess engine will select a move on the basis of some calculations that involve multistep minimax search (likely approximate, because of pruning of the lookahead tree).\u2074 In particular, it will produce a numerical evaluation Q(x, u) of the position resulting from x after each of the legal moves u, and it will play a move \u0169 that produces the best evaluation.\u2075 Thus, for the purposes of this paper, a chess engine can be viewed as a function \u03bc, which when faced with a position x, plays the move \u03bc(x) = \u0169, where\n\u0169 \u2208 arg min Q(x, u),\nu\u2208L(x)\nwith L(x) denoting the set of legal moves at x. The function\nE(x) = min Q(x, u).\nu\u2208L(x)\nwill be called the evaluation function of the engine; it provides a numerical evaluation of any given position x (castling and record keeping to detect a drawn chess position, such as a three-move repetition, are incorporated as part of the position).\u2076 In this paper, we assume that an engine is memoryless, so that Q(x, u) depends only on the pair (x, u) and not on the earlier game calculations.\u2077\nTo play against an opponent, our MPC-MC architecture also selects a move in response to a given position. However, to compute this move it uses two engines, such as Stockfish (SK for short), Komodo Dragon (KD for short), Leela Chess Zero (LCO for short), etc.\n(a) The position evaluator. This is a chess engine, which produces a numerical evaluation of any given position.\n(b) The nominal opponent. This is either an exact replica or an approximation"}, {"title": "", "content": "to the true opponent (engine or human), whom we intend to play against. It outputs deterministically a move to play at any given chess position. In the absence of knowledge of the true opponent, a reasonable choice is to use a competent chess engine as nominal opponent, such as for example the one used to provide position evaluations.\u2078\nThe nominal opponent and the position evaluator engines may be different. Moreover, the nominal opponent engine may be changed from game to game to adapt to the true opponent at hand. Note that stored knowledge of the evaluator and nominal opponent engines, such as an opening book or an endgame database, are indirectly incorporated into the MPC-MC player.\nTo describe mathematically the move selection of MPC-MC at a position x\u2096, and to make the connection with the optimal control and MPC/RL framework, we use the following notation:\n\u2022 x\u2096 is the chess position at time/move k.\n\u2022 u\u2096 is a legal move at time k in response to position x\u2096.\n\u2022 w\u2096 is the move choice of the nominal opponent at time k in response to position x\u2096 followed by move u\u2096.\nThe resulting position at time k + 1 is given by\nx\u2096\u208a\u2081 = f(x\u2096, u\u2096, w\u2096),\nwhere f is a known function. This corresponds to a dynamic system in the standard MPC framework, where x\u2096 is viewed as the state, u\u2096 is viewed as the control, and w\u2096 is viewed as a known or unknown (possibly random) disturbance.\nThe structure of the MPC-MC architecture with one-step lookahead is shown in Fig. 1. Here is the sequence of calculations by which it selects a move u\u2096 at a given position x\u2096:\n(1) We generate all legal moves u\u2096 at x\u2096.\n(2) For each pair (x\u2096, u\u2096), we use the nominal opponent engine to evaluate the position (x\u2096, u\u2096) and to generate the corresponding best move v(x\u2096, u\u2096), where v is a given function."}, {"title": "3 Deterministic and Stochastic Variants of MPC-MC", "content": "We will now discuss two basic variants of our MPC-MC architecture. In the first variant, called deterministic, we can predict exactly the response of the true opponent, and use this prediction as the nominal opponent move. This variant can be viewed as a special case of a standard MPC architecture. In the second variant, called stochastic, we can generate only an approximate prediction. This variant can be viewed as an approximation to an MPC architecture.\nDeterministic MPC-MC\nIn the deterministic variant of MPC-MC, we are able to predict exactly the move of the true opponent in response to a position x\u2096 and legal move u\u2096, and use the prediction as the nominal opponent move. We thus assume that the nominal opponent engine replicates the play of the true opponent. In this case, if v(x, u) denotes the nominal opponent move in response to x followed by u, the sequence of positions generated during the actual game evolves according to\nx\u2096\u208a\u2081 = F(x\u2096, u\u2096),\nwhere\nF(x\u2096, u\u2096) = f(x\u2096, u\u2096, v(x\u2096, u\u2096)).\nHere v(x\u2096, u\u2096) is the move generated by both nominal and true opponent engines in response to position x\u2096 and MPC-MC moves u\u2096.\nIn optimal control terms, Eqs. (1)-(2) represent a chess game as the evolution of a deterministic controlled system with state x and control u. Regarding the cost function, a nonzero cost is incurred only at the terminal positions where"}, {"title": "", "content": "one of the opponents wins the game. The optimal cost function J*(x) is the solution of the Bellman equation, the fundamental equation of exact DP:\nJ*(x) = min J*(F(x, u)),\nu\u2208L(x)\nwith\nJ*(x) \u2260 0\nfor all positions x where one of the players can win, regardless of the play of the other player, and with\nJ*(x) = 0\nfor all other positions x, which are theoretical draws.\nOf course the optimal cost function J* is unknown at the starting chess position (and most other positions),\u00b9\u2070 and is unlikely to be calculated in the near future, in view of the complexity of the chess game. In the approximation in value space approach of RL, which is very similar to the MPC methodology, we approximate the unknown function J* with an approximation. Accordingly, in the MPC-MC architecture, J* is approximated by the evaluation function E of the position evaluator engine. In particular, at position x, the MPC-MC player selects the move\n\u0169 \u2208 arg min E(F(x, u)),\nu\u2208L(x)\nwhere the needed values of F are calculated by using the nominal opponent engine (also true opponent), and the needed values of E are calculated by the position evaluator engine.\nAn important fact is that the performance of the MPC-MC player is better than the performance of the position evaluator engine, provided the evaluator engine's play is relatively close to optimal. This follows from a theoretical frame-work, which applies more broadly than chess, and explains the performance of MPC and RL schemes that are based on approximation in value space. The development, justification, and visualization of this framework is the focal point of the books [Ber20], [Ber22a], [Ber23], and the survey papers [Ber22b] and [Ber24], which were noted earlier. The performance improvement property also"}, {"title": "", "content": "relates to Newton's method applied to the Bellman Eq. (3).\nIn this paper, we will not discuss further the theoretical backdrop just sketched, but instead we will demonstrate experimentally in Section 4 how the performance of the MPC-MC player is superior to the performance of its position evaluator engine. This performance improvement is generally significant, but tends to diminish in absolute terms as the position evaluator engine approaches optimality; after all if the position evaluator engine plays perfect/optimal chess, its performance cannot be improved. However, in theory, the performance improvement of the MPC-MC player increases in relative terms as the position evaluator engine approaches optimality. In particular, we have\nJ\u016b(x) \u2013 J*(x) / J(x) - J*(x) \u2192 0, as J \u2192 J*,\nwhere \u0169 represents the move selection policy of the MPC-MC player, J\u016b(x) is its performance starting from any position x, and J(x) is the position evaluation, as given by the position evaluator engine.\u00b9\u00b9 This is a superlinear performance improvement relation that is typical of Newton's method; see the sources cited earlier. Our experimental results are consistent with this relation.\nWe finally note that the use of the position evaluator engine to approximate the optimal cost function is reminiscent of the rollout algorithm from DP/RL, whereby the optimal cost function is approximated by the cost function of some policy known as the base policy; see the sources cited earlier for an extensive account of rollout algorithms, and for many references to their remarkable effectiveness. In our case, the base policy is the move selection policy of the position evaluator engine, and its cost function is approximated by the corresponding engine evaluations.\nStochastic MPC-MC\nIn the stochastic variant of MPC-MC, we cannot predict exactly the move of the true opponent in response to (x\u2096, u\u2096), and we use instead the move generated by a nominal opponent engine that approximates the play of the true opponent. Again, if v(x, u) is the nominal opponent move in response to x followed by u,"}, {"title": "", "content": "the MPC-MC player calculates its move according to\n\u0169 \u2208 arg min E(F(x, u)),\nu\u2208L(x)\ncf. Eq. (4), where\nF(x, u) = f(x, u, v(x, u)).\nHowever, the positions generated during the actual game will occasionally deviate from the positions generated by the equation\nx\u2096\u208a\u2081 = F(x\u2096, u\u2096),\nbecause the play of the true opponent can deviate from the play of the nominal opponent.\nWhile the performance improvement property of Eq. (5) cannot be estab-lished for the stochastic MPC-MC player, it evidently holds approximately, provided that the nominal opponent is a strong player. In fact our experiments indicate that the nominal opponent engine should play at least as well or better than the true opponent. As an explanation of why we need a strong nominal opponent, we note that the MPC-MC architecture may select a poor and even catastrophic move u\u2096 because the nominal opponent produces a poor response v(x\u2096, u\u2096), leading to x\u2096\u208a\u2081 which is favorably judged by the position evaluator engine. It is thus essential that the nominal opponent does not underestimate the true opponent.\nFortified Move Generation\nWhile the MPC-MC architecture has worked well in our computational experiments, it may make occasional errors, even when it uses very strong nominal opponent and position evaluator engines. In particular, we have observed rare mistakes, which seem to be due to the approximation of minimax play of the opponent with the moves produced by the nominal opponent. This type of situation is common in truncated rollout algorithms for general approximate DP/RL settings, where the search with a base policy is extended to only a limited depth of lookahead. A useful supplement to truncated rollout algorithms is fortification, whereby we follow the base policy at states where the rollout policy appears to be ineffective (we refer to sources given earlier, such as the books [Ber19] and [Ber20], for a detailed discussion)."}, {"title": "", "content": "We have thus considered an MPC-MC fortification strategy, which works as follows. For a given position x\u2096, once a move \u016b\u2096 is computed by using the MPC-MC policy of Eq. (4) or Eq. (6), it is compared with the move suggested by the position evaluator at x\u2096, call it \u00fb\u2096. The MPC-MC fortification strategy then is to play \u00fb\u2096 if its evaluation Q(x\u2096, \u00fb\u2096) is better than the one of \u016b\u2096, and to play \u016b\u2096 otherwise.\nAs the preceding discussion suggests, the fortification strategy is conservative, but provides some safeguards against overambitious play by the (unfortified) MPC-MC architecture. Our computational experiments, given in the next section, indicate that fortification is effective against very strong opponents, such as powerful SK engines, which can exploit even small errors by MPC-MC. On the other hand, fortification may lead to a relatively small performance degradation against weak opponents, against which MPC-MC has an overwhelming advantage."}, {"title": "4 Computational Results", "content": "In this section, we will present our computational results for the MPC-MC architecture applied to two different types of chess engines. We will first use SK and/or KD chess engines of varying strengths as the nominal opponent and the position evaluator.12 These engines are specially designed for playing chess, and they are incorporated into the MPC-MC architecture without modification. The strongest versions of these engines have won prominent computer chess competitions in recent years. Still, our results show that MPC-MC with one-step lookahead can improve their performance. Moreover, our results indicate that fortification in MPC-MC is beneficial against very strong opponents.\nWe have also used the chess engines developed by Ruoss et al [RDM24] (at Google DeepMind) within the MPC-MC architecture. These are engines that rely exclusively on (off-line trained) transformer neural networks to provide po-sition evaluations without further search. At the current position and for each legal move, they calculate a Q-factor and then they choose the move with best Q-factor. These engines attain a strong grandmaster-level performance against human opponents, but are generally weaker than the SK and KD engines. Still, in a limited set of experiments, we have verified that MPC-MC can provide"}, {"title": "", "content": "a significant performance improvement, consistently with our experience with the SK and KD engines.13 Note that the transformers that we used in these experiments have similar structure with versatile large language models, which can be used in a broad range of applications. This suggests that we can expect offline-trained transformers to be well-suited for use within our MPC-based ar-chitecture in a variety of settings, which involve minimax sequential decision making (including two-person zero-sum games other than chess). Further re-search in this direction appears to be promising."}, {"title": "4.1 MPC-MC with Stockfish and Komodo Dragon Chess Engines", "content": "We will first provide some computational details of the MPC-MC architec-ture with one-step lookahead, when the specialized chess engine Stockfish (SK) and/or the freely available version of Komodo Dragon (KD) are used as nominal opponent and/or position evaluator. We will not repeat the generic procedures of MPC-MC introduced in Section 3. Instead, we will focus on describing how the engines can be incorporated into MPC-MC, to play against themselves or against each other. We will then describe the setup of our computational studies, where we test both the deterministic and the stochastic MPC-MC architectures, and evaluate the effect of fortification.\nGiven the chess position x\u2096 at time k and a legal move u\u2096, both the SK and KD engines select a move v(x\u2096, u\u2096) via some built-in function. In addition, these engines can be used to provide scalar evaluations E(x\u2096\u208a\u2081) of any chess position x\u2096\u208a\u2081 with some additional calculation. Both the quality of move selection and the position evaluation can be affected by a variety of factors. In our tests, we have relied solely on the computational time limit to affect the performance of these engines. In particular, given two engines of the same type (be it SK or KD), we view the one with higher time limit as \u201cstronger.\u201d\nWe have tested both the deterministic and stochastic MPC-MC architecture, where the engines' time limits are set to 0.5, 2, and 5 seconds (at 5 secs, the play of KD is very strong, while the play of SK is nearly perfect). To eliminate the effect of stored hash tables on the performance, only engines without stored"}, {"title": "4.2 Comparison with a Half-Step Lookahead Version of MPC-MC", "content": "Let us also consider a simpler version of MPC-MC, which does not use a nominal opponent engine, only a position evaluator. We call this the half-step lookahead version, and we illustrate it in Fig. 2. Here the evaluator engine considers all legal moves at the current position, and evaluates them from the point of view of the opponent. The half-step version of MPC-MC then selects the legal move that results in the position that is worst from the opponent's point of view.\nTheoretically, this version also has a Newton step interpretation, but the Newton step is somewhat less reliable. The reason has to do with the lack of concavity of the minimax form of the Bellman operator (see [Ber22a], Section 3.9, [Ber22c], Chapter 5). We will not go into further details, but we will instead discuss briefly our computational results. These results are favorable but not as favorable as the ones we presented earlier for MPC-MC with one-step lookahead against the SK engine. In particular, half-step MPC-MC (using the SK evaluator at 0.5 sec) vs SK won a ten-game match by 6.5-3.5, while for one-step MPC-MC, the corresponding result was 8-2. Against SK at 2 sec, half-step MPC-MC drew a ten-game match (5-5), while for one-step MPC-MC, the result was 5.5-4.5; see the left side of Table 3.\nSimilar results have been obtained when using the chess engines developed"}, {"title": "5 MPC-MC with Multistep Lookahead", "content": "We next consider the structure of the MPC-MC scheme with two-step lookahead (the case of lookahead longer than two is similar); see Fig. 3:\n(1) At the current position x\u2096, we generate all legal moves u\u2096 (say m in number).\n(2) For each pair (x\u2096, u\u2096), we use the nominal opponent to generate a single best move w\u2096, resulting in the position\nx\u2096\u208a\u2081 = f(x\u2096, u\u2096, w\u2096).\n(3) For each of the resulting positions x\u2096\u208a\u2081, we generate all legal moves u\u2096\u208a\u2081.\n(4) For each pair (x\u2096\u208a\u2081, u\u2096\u208a\u2081), we use the nominal opponent to generate a single best move w\u2096\u208a\u2081, resulting in the position\nx\u2096\u208a\u2082 = f(x\u2096\u208a\u2081, u\u2096\u208a\u2081, w\u2096\u208a\u2081).\n(5) We evaluate each of the possible positions x\u2096\u208a\u2082 by using the position evaluator engine, and select as next move u\u2096 the one that leads to the"}, {"title": "", "content": "position x\u2096\u208a\u2082 with best evaluation.\nThus, there are roughly a total of at most m\u00b2 position evaluations and m\u00b2+m nominal opponent move generations, where m is representative of the number of possible legal moves at the positions that may result from the two-step lookahead process. These calculations can be expedited by using parallel computation, but they can also be expedited by pruning the tree that corresponds to the second level of lookahead. One way to do this is to consider the evaluations of the positions x\u2096\u208a\u2081 following the first layer of nominal opponent moves w\u2096. Then prune some of the less promising positions x\u2096\u208a\u2081, i.e., those x\u2096\u208a\u2081 that have relatively low evaluation, as provided by the local opponent engine. This is consistent with MPC theory, which suggests that it is important to execute"}, {"title": "6 Concluding Remarks", "content": "The ideas of this paper were motivated by theoretical insights from the MPC, RL, approximation in value space, and rollout methodologies. These ideas center around Newton's method for solving Bellman's equation associated with an underlying DP problem, and apply very generally to discrete and continuous spaces sequential decision problems (see the books and papers noted earlier). They apply to computer chess in particular, after its minimax two-player structure is changed to a one-player sequential decision structure through the use of the nominal opponent engine. Consistent with the theoretical insights, we have verified that the MPC-MC architecture provides a boost in the performance of existing chess engines, including engines that play near perfect chess, like Stockfish at a 5 secs per move time limit.\nWe distinguished between a deterministic architecture, where the nominal opponent replicates exactly the actual opponent, and a stochastic architecture, where it does not. An interesting observation from our experiments is that the performance difference between the deterministic and stochastic versions of MPC-MC is relatively small, as long as the nominal opponent does not significantly underestimate the strength of the actual opponent. We believe that multistep lookahead will provide an additional boost in performance, but this remains to be confirmed with additional testing.\nWhile each move of MPC-MC requires many position evaluations with the"}]}