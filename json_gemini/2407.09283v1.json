{"title": "DAHRS: Divergence-Aware Hallucination-Remediated SRL Projection", "authors": ["Sangpil Youm", "Brodie Mather", "Chathuri Jayaweera", "Juliana Prada", "Bonnie Dorr"], "abstract": "Semantic role labeling (SRL) enriches many downstream applications, e.g., machine translation, question answering, summarization, and stance/belief detection. However, building multilingual SRL models is challenging due to the scarcity of semantically annotated corpora for multiple languages. Moreover, state-of-the-art SRL projection (XSRL) based on large language models (LLMs) yields output that is riddled with spurious role labels. Remediation of such hallucinations is not straightforward due to the lack of explainability of LLMs. We show that hallucinated role labels are related to naturally occurring divergence types that interfere with initial alignments. We implement Divergence-Aware Hallucination-Remediated SRL projection (DAHRS), leveraging linguistically-informed alignment remediation followed by greedy First-Come First-Assign (FCFA) SRL projection. DAHRS improves the accuracy of SRL projection without additional transformer-based machinery, beating XSRL in both human and automatic comparisons, and advancing beyond headwords to accommodate phrase-level SRL projection (e.g., EN-FR, EN-ES). Using CoNLL-2009 as our ground truth, we achieve a higher word-level F1 over XSRL: 87.6% vs. 77.3% (EN-FR) and 89.0% vs. 82.7% (EN-ES). Human phrase-level assessments yield 89.1% (EN-FR) and 91.0% (EN-ES). We also define a divergence metric to adapt our approach to other language pairs (e.g., English-Tagalog).", "sections": [{"title": "1 Introduction", "content": "The natural language processing (NLP) task of semantic role labeling (SRL) captures \"who did what to whom\" for many downstream applications, e.g., machine translation, question answering, and summarization [21,14]. Semantic roles are central to inferring unstated information (e.g., stances [26,25] and emotional cues [3]) that are absent from the output of NLP tools such as dependency parsing. Disappointingly, SRL has been studied primarily in English due to highly available English-specific SRL annotated datasets [12]. The scarcity of multilingual SRL-annotated corpora motivates the need for cross-language approaches that project semantic roles from English to other languages.\nMany studies have explored pre-trained SRL models [28,34] and generative AI approaches for semantic tasks that include SRL [36]. These LLM-centric studies tend to focus exclusively on English. The associated LLMs thus introduce hallucinations without obvious recourse due to an inherent lack of explainability.\nOur approach, \"Divergence-Aware Hallucination-Remediated SRL Projection\" (DAHRS) adopts a generalized characterization of divergence types [9,23] and corrects alignnments, remediating hallucinated semantic-role transfer from source to target languages (e.g., English-French and English-Spanish). We introduce a greedy \"First-Come First-Assign\" (FCFA) algorithm within DAHRS that projects roles from corrected initial alignments. FCFA also remediates the hallucinated lack of semantic role projections emerging from corrected initial alignments.\nThe key insight here is that leveraging linguistic knowledge overcomes deficiencies in current transformer-based alignment-projection approaches. Transformer-based alignment treats target words as a bag-of-words, frequently aligning source-language terms to hallucinated target-language terms. By contrast, DAHRS injects an awareness of naturally occurring language divergences, e.g., one-to-many/many-to-one translations or word/phrase order distinctions, into alignment. Straightforward correction of alignments that would otherwise lead to hallucinated incorrect roles supports effective and explainable transfer of semantic roles from the source language to the target language.\nState-of-the-art XSRL [6] addresses a subset of language divergences explored in this paper: nominalizations and separable verb prefixes. In cases where the initial alignment is correct, XSRL fails to project valid roles in the context of other types of divergences, often hallucinating a lack of semantic role projections on the right-hand side. DAHRS is designed to address two types of hallucinations simultaneously: alignment and projection. The performance of DAHRS is compared to that of XSRL using data processed by both methods (see section 5).\nHallucination remediation in DAHRS starts with token-level and phrase-level corrections to an initial transformer-based mBERT [11] alignment. Following this, additional hallucination remediation takes place during projection. Fig. 1 illustrates two representative cases of divergences that have triggered hallucinations in prior work: Light Verb and Structural.3 Square brackets '[]' indicate SRL projections, with unaligned words indicated by \u20ac. The output shown at each stage explainably pin-points which sub-components fail or succeed (alignment or projection, or both).\n(a) Light Verb Divergence. The single verb fell maps to a combination of a \"light\" verb (a) and content word \"fallen\" (chut\u00e9). Despite the correct initial mBERT alignment, XSRL is unable to \"see past\" this divergence to project"}, {"title": "2 Related Work", "content": "Early applications for annotation-projection include: dependency parsing [19]; part-of-speech taggers [38]; machine translation [39,33]; divergence-inspired alignment [10]; and creation of syntactic-dependency datasets for multiple languages [27]. We borrow the notion of annotation projection to produce explainable, cross-language SRL that advances the state of the art.\nA contrasting SRL annotation projection approach is one where a source-language model is modified for direct applicability to a new language, using cross-lingually shared representations [20]. Such \"model transferring\" approaches do not align datasets across languages, but instead induce a separate dataset. By contrast, annotation projection approaches (including our own) propagate available information from one language to another via alignment.\nTranslation-based models provide an alternative approach for transferring SRL annotations. These have demonstrated promising performance due to recent improvements in neural machine translation (NMT) [12,13,17]. Translation-based projection involves tree-to-tree mappings to build cross-lingual SRL-annotated corpora [31], based on tree/graph-based representations [33]. By contrast, our approach aims to accommodate divergences for SRL projection via word-to-word mapping without relying on additional structure (e.g., trees or graphs).\nPrior studies have demonstrated the benefits of embedding models in cross-language SRL projection. For example, Polyglot SRL [29] employs word vectors and is trained on the union of annotations between two languages. A cross-lingual encoder-decoder model is applied to simultaneously translate and apply SRL for resource-poor languages [5]. Adding a syntactic information layer to the embedding models demonstrates plausibility of transferring semantic roles [15]. By contrast, our approach enables improved SRL projection without additional vector-based machinery. Instead, we factor out syntactic variations, as these are not central to the transfer of semantic roles, and introduce a greedy SRL projection algorithm that is both accurate and efficient.\nTranslation divergences and associated alignment errors lead to considerable noise, often resulting in the implementation of intricate techniques. For example, projection probability distributions and gold-standard annotated data have been employed to improve alignment performance [1]. XSRL uses translations produced by DeepL [7], more than 10% of which are human-judged as improperly translated and removed. An mBERT [8] aligner is applied, followed"}, {"title": "3 Divergence-Aware Hallucination-Remediated SRL Projection (DAHRS)", "content": "DAHRS's key contribution is its ability to compensate for potential semantic role errors emerging from hallucinated alignments that coincide with naturally occurring cross-language divergences. Leveraging source-language knowledge (e.g., English is head initial) coupled with a greedy FCFA algorithm, DAHRS transfers semantic roles to the target language.\nFig. 2 illustrates the DAHRS step-wise pipeline with an English-to-French example. DAHRS's input is an initial mBERT-style alignment, as in XSRL, but prior to SRL projection it corrects hallucinated alignments and transfers semantic roles without additional transformer-based processing.\nFig. 3 shows three key steps in DAHRS: divergence identification (see Section 3.1), alignment correction (DAHRS\u2081 and DAHRS2, see Section 3.2), and FCFA projection (DAHRS3, also in Section 3.2). When divergence identification uncovers a divergence, DAHRS modifies the alignment prior to SRL projection. Otherwise it directly projects semantic roles through FCFA projection."}, {"title": "3.1 Divergence Identification", "content": "For divergence identification, DAHRS relies on a sub-categorization of divergences into three types, as shown in Fig. 4. For example, with regard to the divergences illustrated in Section 1, Light Verb divergences are associated with (a) one-to-many and (b) many-to-one sub-categories, and Structural divergences are associated with (c) the ordering sub-category.\nThe identification of these divergence sub-categories for a given source-target input pair relies on position-value pairs. These pairs indicate the tokens and phrases that are mapped singularly or repeatedly across the source and target inputs. Divergence types are identified across tokenized source and target sentences, where each token is assigned a position value starting from 0.\nConsider the French sentence fragment ordinateurs portable (laptops) in Fig. 4(a). This string is associated with position values of 17 in English and 23,24 in French. Source and target word mappings are denoted by a hyphenated position-value pair. For example, 17-23 and 17-24 indicate the 17th English word (laptops) aligns with the 23rd and 24th word French words (ordinateurs portable). This case is identified as a one-to-many divergence, i.e., a single source token aligns with multiple target tokens. Analogously, a many-to-one divergence is identified when multiple source tokens align with a single target token, as in Fig. 4(b), where fell(4) and apart(5) align with effondr\u00e9e(6).\nAn ordering divergence is detected when a single source token is mBERT-aligned with multiple target tokens (one-to-many) while one of those same target tokens aligns with a different source token (many-to-one). Returning to our earlier example, October 1987 crash (translated in French as crash of October 1987), as shown in Fig. 4(c): october(9) aligns with \u00e9crasement(7) and octobre (9), while one of target tokens, \u00e9crasement(7) also aligns with crash(11).\nAlthough state-of-the-art (mBERT-based) word-to-word alignment establishes a reasonable source-to-target baseline, ordering divergences are not adequately handled, due to mBERT's bag-of-words design. These lead to incorrect alignments that must be remediated in order to avoid hallucinated SRL projections. We note that ordering distinctions have been a focus in statistical machine translation (SMT) for quite some time [32], but these have heretofore not been remediated for projection.\nSubsequent to identifying divergence types, as described below, our approach remediates hallucinations due to divergences and projects semantic roles through FCFA SRL projection."}, {"title": "3.2 DAHRS Algorithms", "content": "DAHRS's three key steps each correspond to a component-level algorithm: alignment correction at the token level (Algorithm 1) and phrase level (Algorithm 2) to remediate hallucinated incorrect role projections, followed by FCFA SRL projection (Algorithm 3) which remediates hallucinated lack of role projections.\nDAHRS1: Token-Level Hallucination Remediation. We remediate alignment hallucinations at the token level, using DAHRS1 (see Algorithm 1). Such hallucinations are discerned from input pairs for one-to-one (tLevelOneToOne), one-to-many (tLevelOneToMany), many-to-one (tLevelManyToOne) alignments."}, {"title": "DAHRS2: Phrase-Level Hallucination Remediation", "content": "DAHRS2 shown in Algorithm 2 advances beyond the token-level processing of state-of-the-art (XSRL) in that it includes handling of phrases for SRL projection.\nPhrase-level processing is similar to what is described above, but phrase identification is employed: BIO (Begin-Inside-Outside) tags are assigned to the source-language side via SRL-BERT [34].4 These BIO-delineated phrasal units are brought together with alignment corrections for more robust alignment hallucination remediation. A phrase range is determined by arranging the source words in the order they appear within the sentence and employing BIO tags to identify phrases on the English side.5\nPhrase information (start to end indices), encoded as a source phrase range (srcPhRange) and target phrase range (tgtPhRange), acts as phrase-level hallucination remediation input. Other inputs are lists of phrase-level alignment pairs: one-to-one (pLevelOneToOne), one-to-many (pLevelOneToMany), many-to-one (pLevelManyToOne).\nTo support remediation, a list of function words (funcWordIdx) and a head-initial flag (headInitialFlag) are also introduced. This algorithm returns lists of remediated mappings (remOneToOne).\nFirst, DAHRS2 examines whether the mBERT-aligned input is indicative of a one-to-many or many-to-one divergence within a given phrase (a BIO-tagged pair). If no such divergence is present, all the tokens in the phrase are returned as output (remOneToOne) without correction (lines 2-4)."}, {"title": "DAHRS3: First-Come First-Assign (FCFA) SRL Projection", "content": "DAHRS3 is a new greedy FCFA SRL projection that transfers semantic roles using the remediated alignments (one-to-one mappings, remOneToOne), as shown in Algorithm 3. Alignments are provided as an input along with corresponding role labels transferred from English (srcSRLSet).\nSource side semantic roles are assigned to the remediated aligned target token (lines 3-9). Projection yields two outputs: a human interpretable alignment representation and a JSON formatted SRL representation. For example, in Fig. 6 (a), token-level FCFA projects label (\"O\") to octobre and \u00e9crasement from october and crash (ordering). In addition, the source label from laptops is projected to both ordinateurs and portables, leveraging the correct (one-to-many) alignment. Advancing beyond state-of-the-art (XSRL), many-to-one handling results in the retention of V for effondr\u00e9e and the elimination of the hallucinated ARG4 for apart.\nPhrase-level projection operates similarly. In Fig. 6 (b), october aligns with octobre and \"ARGM-TMP\" transfers to octobre (one-to-many). Due to the correct alignment of crash with \u00e9crasement, \"ARGM-TMP\" is transferred to \u00e9crasement (many-to-one). Furthermore, phrase-level projection considers whether the source language is head-initial or head-final. For example, [B-V-closed], [B-ARGM-MNR-down] close, B-V-ferm\u00e9, DAHRS projects \"V\" from closed, rather than \"ARGM-MNR\" from down."}, {"title": "3.3 Explainability and Visualization", "content": "In contrast to blackbox LLMs, which do not elucidate the decisions behind language alignment and SRL projections, DAHRS builds readily visualized representations that explain how it arrives at its output. Whereas prior work [18] has proposed metrics such as \u2018goodness', \u2018user satisfaction', and \u2018understandability' as proxies for explainability, DAHRS integrates human-interpretable representations directly into alignment and projection.\nTwo visualized products of our implementation (with French, Spanish as our test case) are: (a) a set of linguistically annotated alignment representations (one for each predicate indicated as \u201cV\u201d) that provides a window into why/how the system produces its output while elucidating errors that can be readily remedied, as depicted in Fig. 5; (b) a JSON formatted representation that specifies all semantic role-labeled tokens for each sentence, as depicted in Fig. 2 (French semantic role-labeled sentence). These examples showcase our handling of hallucination remediation in the face of divergences and highlight the assignment of predicates and corresponding semantic roles on the target side."}, {"title": "3.4 Model as a Diagnostic Tool", "content": "DAHRS employs a direct alignment-based source-to-target transfer mechanism, without requiring a filter or BERT Score (as implemented in XSRL). Moreover, the model based on this algorithm is an effective tool for assessing the accuracy of predicate and semantic role projection in longstanding community standard datasets. To illustrate this point, we explore a human-tagged English evaluation dataset from CoNLL-2009 [16], which has also been translated to French and Spanish data as part of XSRL's research [6].\nPreliminary tests using these datasets for SRL projection yield a much lower precision for DAHRS than that of XSRL: DAHRS: 65.9 (FR), 66.3 (ES), XSRL: 80.7 (FR), 85.4 (ES). Further investigation reveals that these data sets include a very large number of spurious V tags for non-predicates: 8341 (DAHRS) vs."}, {"title": "4 Data and Experimental Setup", "content": "We use our updated English CoNLL-2009 data for projecting semantic roles to French and Spanish datasets. Human-validated FR/ES datasets, parallel to the EN-CONLL, are provided by XSRL. The original CoNLL-2009 data incorporates semantic roles for headwords only. In our headword-level experiment, semantic roles from English headwords are projected to the headwords of the FR/ES datasets. Since phrase-level test datasets are unavailable, we employ AllenNLP's SRL-BERT to assign phrase-level semantic roles to the English corpora, which are then projected onto FR/ES corpora.\nPhrasal-level semantic role assignment further enhances the accuracy of SRL, ensuring phrasal coverage a significant advance over the head-word labeling in the original resource. For instance, without our phrase-level enrichment, the word The is considered a headword during SRL assignment in The Dow Jones industrials closed at 2569.26. The result is a single, inappropriate semantic role assignment of ARG1 to the word The. However, with our enrichment, an appropriate phrasal-level semantic role assignment is made possible: [ARG1- The Dow Jones industrials] [V-closed] [ARGM-EXT at 2569.26]. This corrected output yields a more thorough, accurate representation, which is crucial for downstream tools such as those enumerated in Section 1.\nFrench and Spanish corpora, including their semantic roles, are projected from 2046 English sentences using XSRL (see details in section 2) and DAHRS. Subsequently, we evaluate these against both the community standard ground truth CoNLL-2009 (headword) from XSRL and the human judgment (phrasal)."}, {"title": "5 Results and Analyses", "content": "We explore the performance of two projection-based models: DAHRS and XSRL. DAHRS achieves higher F1 scores in comparison to XSRL on our test data in both word-level and phrasal-level (see Table 1). Performance improvements are obtained as well as explanability.\nTo evaluate the correctness of the French and Spanish projection outputs, we employ the ground truth data from CONLL-2009 for the headword dataset. Linguistically trained human taggers proficient in French and Spanish evaluate the phrasal output. Both evaluations use precision (P), recall (R), and F1 scores. Thus, we have achieved explainable transferability of semantic roles more efficiently and with more accurate outputs (P, R, F1).\nWe evaluate DAHRS against a human-validated CoNLL-2009 that assigns semantic roles only to headwords, per the original XSRL algorithm. We compare XSRL and a variant of DAHRS that produces only headword assignments against this same ground truth. In Table 1, DAHRS projection to headwords outperforms XSRL, with an F1 of 77.3 vs. 87.6 (FR), 82.7 vs. 89.0 (ES).\nFurthermore, we conduct a post-analysis and evaluation of our phrasal-rich output against human judgment by French and Spanish proficient evaluators with linguistic training who evaluated 549 total labels (FR), and 582 total labels (ES). This analysis yields a F1 score (FR-89.1%, ES-91.0%, see Table 1). To our knowledge, this is the highest score achieved for this task, surpassing performance (accuracy) of single headword assignments without the overhead of human-labeled source data for French and Spanish."}, {"title": "6 Discussion: Beyond EN-FR / FR-ES", "content": "We explore hallucinations associated with linguistic divergences by considering language pairs beyond EN-FR / EN-ES. We consider Tagalog, a low-resource language notably influenced by Spanish at the word level [2], yet divergent from Spanish (and English) in that its subject follows the verb (VSO). Although our current study focuses on English as the source language, our future research focuses on Tagalog with both Spanish and English as source languages, further enriching our divergence exploration. This investigation aims to verify whether the pairs exhibit the divergent properties assumed by DAHRS and to provide a framework for testing longstanding hypotheses about cross-language divergences in the context of alignment.\nWe introduce divergence metrics that count the number of misalignments on both the source and target sides. When the target language demonstrates a higher number of misalignments, this typically indicates a one-to-many divergence case. Conversely, when the source side yields more misalignment, this typically corresponds to a many-to-one case. DAHRS effectively transfers semantic roles to the"}, {"title": "7 Conclusions and Future Work", "content": "We present a model for cross-language semantic role projection. Our work enhances semantically informed language processing with minimal overhead via a two-step process that rapidly identifies divergence cases and produces explainable, visualizable SRL output. We demonstrate performance improvements in accuracy without requiring a human-labeled French/Spanish corpus. Our evaluation relies on a community standard ground truth with SRL-tagged headwords (CoNNL-2009). Notable improvements are demonstrated when considering entire phrases, as evidenced by human judgments.\nFuture work will focus on expanding to other languages (Tagalog is underway) where hand-annotated labels are scarce. Although French and Spanish are investigated above, divergence-causing hallucinations, remediated by acknowledging the syntactic property of languages during DAHRS have been noted across many other languages, e.g., Spanish (categorial; [9]), Korean (structural; [23]), or German (light verb; [24]). As such, it is expected that DAHRS applies multilingually, both for mid-resource language pairs (e.g., English-Spanish/French) and for those that are low-resource language pairs (e.g., English-Tagalog).\nFinally, our experiments reveal that a new model, DAHRS, improves the multilingual SRL projection task. We provide French and Spanish corpora, including SRL information per predicates. Additionally, we utilize DAHRS as a diagnostic tool to verify the accuracy of ground truth. Through this diagnostic tool, we identify errors in the data, enabling us to update and reproduce data for the language community. These data resources are not only beneficial for the SRL task but also may be leveraged for other tasks."}]}