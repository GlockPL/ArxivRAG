{"title": "Amortizing Pragmatic Program Synthesis with Rankings", "authors": ["Yewen Pu", "Saujas Vaduguru", "Priyan Vaithilingam", "Elena Glassman", "Daniel Fried"], "abstract": "The usage of Rational Speech Acts (RSA) framework has been successful in building pragmatic program synthesizers that return programs which, in addition to being logically consistent with user-generated examples, account for the fact that a user chooses their examples informatively. We present a general method of amortizing the slow, exact RSA synthesizer. Our method first query the exact RSA synthesizer to compile a communication dataset. The dataset contains a number of example-dependent rankings of subsets of programs. It then distills a single global ranking of all programs as an approximation to every ranking in the dataset. This global ranking is then used at inference time to rank multiple logically consistent candidate programs generated from a fast, non-pragmatic synthesizer. Experiments on two program synthesis domains using our ranking method resulted in orders of magnitudes of speed ups compared to the exact RSA synthesizer, while being more accurate than a non-pragmatic synthesizer when communicating with humans. Finally, we prove that in the special case of synthesis from a single example, this approximation is exact.", "sections": [{"title": "1. Introduction", "content": "For intelligent systems to be accessible to end users, it is important that they can infer the user's intent under ambiguity. Imagine a person asking an AI assistant to generate a regular expression that matches the string 123-7890. It would be unhelpful if the AI assistant simply returned the regular expression \u2211* \u2013 the expression that matches all strings \u2013 although it is technically correct. The rational speech acts model (RSA) of pragmatics (Frank & Goodman, 2012) gives an algorithm for resolving ambiguities by modeling the user as a speaker that chooses informative examples for the system, via recursive Bayesian reasoning. Given several competing responses, for instance regex\u2081 = \\d{3}-\\d{4} and regex2 = \u2211*, RSA would reason that it is more likely that an informative user would use the example 123-7890 to describe regex\u2081 over regex2, allowing it to prefer the intended regex. Recent works (Pu et al., 2020; Vaithilingam et al., 2023) have leveraged the RSA algorithm to build pragmatic program synthesizers \u2013 interactive systems that take in user given examples (e.g. strings) and return programs (e.g. regexes) that are both logically consistent and take into account the informativity of the chosen examples. Their algorithm, which we refer to as RSA, is applicable to any program synthesis domain where programs can be efficiently enumerated (Feser et al., 2015; Solar-Lezama, 2008; Gulwani, 2011), and produces a pragmatic synthesizer which interacts well with humans, while requiring no labeled human data.\nThe RSA algorithm marginalizes across all possible examples (e.g. all strings) and programs (e.g. all regexes) multiple times. This makes it difficult to scale RSA to large domains, where users expect the system to complete its inference in real-time. Prior works in scaling up RSA computation (Monroe et al., 2017; Andreas & Klein, 2016) have largely focused on sampling and re-ranking, curbing RSA's computation to a small subset of programs and examples. In this work, we show a simple yet effective way of amortizing RSA via a single global ranking of all programs. Rather than using RSA directly at inference time, our method uses it to generate training data in the form example-dependent rankings of subsets of programs. We then distill a global ranking from the training data, amortizing the computation of RSA (Figure 1). At inference time, a fast, non-pragmatic synthesizer is used to propose multiple logically consistent programs, and the global ranking is used to quickly rank them,\u00b9 resulting in a pragmatic yet efficient synthesizer.\nThis work makes the following contributions. (1) We describe a general method of amortizing the RSA algorithm (considered in Cohn-Gordon et al. (2018b); Pu et al. (2020); Vaithilingam et al. (2023)) applicable to any pragmatic program synthesis domains. (2) Using global ranking, we scale the model proposed by Vaithilingam et al. (2023) to a larger domain while still allowing for real-time interaction. We conduct a small user study validating that end-users are more accurate communicating with a ranking based program synthesizer compared to a non-pragmatic one (+27%, +41% relative). (3) We conduct simulated user studies by replaying the human interactive synthesis data collected from Pu et al. (2020) and Vaithilingam et al. (2023). We confirm that our ranking-based synthesizer retains the communicative accuracy of RSA (55%, 92% respectively), while running orders of magnitudes(over 100 times) faster. (4) We prove that in the special case of synthesis from just a single example, RSA_single, a setting studied in the original RSA literature (Goodman & Frank, 2016; Vogel et al., 2013; Monroe & Potts, 2015; Smith et al., 2013), the approximation using a global ranking is exact."}, {"title": "2. Background on Pragmatic Synthesis", "content": "In this section, we provide background on a reference game framework of program synthesis, which affords building a pragmatic synthesizer that can infer a user's intended program from few examples (Pu et al., 2020). We illustrate this framework using a toy example from a small version of the regular expression domain of this work."}, {"title": "2.1. Synthesis as a Reference Game", "content": "Consider the problem where a user gives example strings to a synthesis system, and asks it to find a matching regular expression. This process can be modeled as a reference game\nIn our example, the regex \u03a3* would be ranked lower than other consistent programs."}, {"title": "2.2. A Literal Program Synthesizer", "content": "How might we build a system that takes an utterance (say 01) and produces the intended hypothesis 0+1{1}? As 01 is consistent with multiple hypotheses (0+1{1} and 0+1*), a naive strategy is to treat all consistent hypotheses as equally likely, scaled by a prior distribution of hypotheses P(w):\n\\[L_o(w|u) \\propto P(w)M[u, w] \\tag{1}\\]\n\\[ = P(w) \\frac{M[u, w]}{\\sum_{w'} M[u, w']} \\tag{2}\\]\nA synthesizer built this way is a literal listener Lo (Bergen et al., 2016). Assuming the prior P(w) is uniform over programs, we can construct it by normalizing the rows of the matrix M, resulting in a probability distribution over hypotheses W given utterances u (Figure 2). As we can see, given the utterance 01, this listener predicts an equal probability of 0+1{1} and 0+1* being the intended program."}, {"title": "2.3. A Pragmatic Synthesizer from a Single Example", "content": "A key insight to improving on the literal synthesizer is to consider that a user is cooperatively choosing an utterance to be informative about the intended program to the synthesizer. The Rational Speech Acts (RSA) framework models this"}, {"title": "2.4. A Pragmatic Synthesizer from Multiple Examples", "content": "RSA_single is capable of producing a program synthesis algorithm from a single example. However, the users will typically have to clarify their intent interactively, by giving a sequence of multiple utterances u = u\u2081, u\u2082,..., u\u2099. The synthesizer must infer the intended program after every turn. With each new utterance, the meaning matrix M becomes smaller, as hypotheses inconsistent with the new utterance are ruled out (Figure 3). This is an instance of incremental RSA (Cohn-Gordon et al., 2018b), which models the informative speaker S\u2081 generating utterances auto-regressively:\n\\[S_1(u|w) = S_1(u_1, u_2, ..., u_n | w)\\]\n\\[ = \\prod_{i=1}^{n} S_1(u_i | w, u_1, ..., u_{i-1})\\]\n\\[ = \\prod_{i=1}^{n} \\frac{L_0(w | u_1, ..., u_i)}{\\sum_{w'} L_0(w' | u_1, ..., u_i)}\\]\n\nIn essense, the S\u2081 is the product of multiple single-utterance S1 computed on separate meaning matrixes (like those in Figure 3). The synthesizer L\u2081(w|u) is defined recursively on top of S1, L\u2081(w|u) \u221d S\u2081(u|w).\nPu et al. (2020) builds on top of the incremental RSA algorithm with additional memoization strategies. In this work, we shall call their algorithm RSA. Similar to RSA_single, this algorithm is applicable to enumerative program synthesis domains such as Feser et al. (2015); Solar-Lezama (2008); Gulwani (2011)."}, {"title": "2.5. Exact RSA is Slow", "content": "In practice, it is infeasible to explicitly store the matrices M, Lo, S1, L1. Instead, computing L\u2081 using RSA requires O(|W|) calls to S1. Each call to compute S\u2081 requires O(|U|) calls to Lo, which in turn requires O(|W|) operations to determine a set of consistent programs. In practice, the pragmatic synthesizer L\u2081 runs in O(|W|\u00b2|U|) time. In the incremental RSA setting with multiple (say l) utterances, the runtime of L\u2081 is O(|W|\u00b2|U|l). As the number of hypotheses and utterances becomes large in a program synthesis domain, it becomes infeasible to compute L\u2081 at a speed required for end-user interactions."}, {"title": "3. Amortizing RSA with Rankings", "content": "We explain how the pragmatic listener L\u2081, derived from the RSA algorithm can be amortized using a single global ranking of programs.\nFinding Consistent Programs Finding correct programs given a sequence of examples u = u\u2081, u\u2082,..., is the primary challenge of program synthesis, with solutions ranging from enumeration (Feser et al., 2015), constraint solving (Solar-Lezama et al., 2006), neuro-symbolic (Polosukhin & Skidanov, 2018; Balog et al., 2016), and using large language models for code (Li et al., 2022). In this work, we assume the a set of k consistent programs w\u2081, w\u2082,..., w\u2096 can be found using any of these techniques.\nRanking Consistent Programs with a Prior A global ranking \u03c3 is an un-normalized prior (a score) over all programs. The global ranking is example-agnostic: given two programs w\u2090 and w\u044c, either \u03c3[w\u2090] > \u03c3[w\u044c] or \u03c3[w\u2090] < \u03c3[w\u044c], irrespective of the given examples u.\n\\[L_o(w|u) \\propto \\sigma[w] M[u, w]\\]\nAs we can see, ranking the consistent programs under \u03c3[w] can be very efficient. In practice, efficient synthesis algorithms are built using either domain-specific heuristics for rankings (Singh & Gulwani, 2015; Polozov & Gulwani, 2015), or a learned prior from a code corpus (Li et al., 2022).\nRanking with L\u2081 Rather than relying on heuristics or learning from a large corpus, RSA automatically derives a ranked synthesizer L\u2081(w|u):\n\\[L_1(w|u) \\propto S_1(u|w)M[u, w]\\]\nTo rank the consistent programs, L\u2081 uses S\u2081(u|w), an example-dependent ranking function, that ranks the satisfying programs differently depending on the sequences of examples u given. In this setting with multiple examples, there could be cycles where a pair of satisfying programs w\u2090 and w\u044c, which is ranked S\u2081(u\u2081|w\u2090) > S\u2081(u\u2081|w\u044c) under some examples u\u2081 and ranked S\u2081(u\u2082|w\u2090) < S\u2081(u\u2082|w\u044c) given different examples u\u2082. In this work, we assume that S\u2081 can be tractably computed at non-interactive speed.\nAmortizing L\u2081 with a Ranking In this work, we explore whether the example-dependent ranking of S\u2081(u|w) can be approximated to have similar top-k responses with an example-agnostic ranking function \u03c3[w]. Note that due to the existence of cycles, it may be impossible to find a global ranking that is consistent with all example-dependent rankings. Our key findings are as follows:\nKey Finding 1: One can distill a pragmatic ranking \u03c3L\u2081 from L\u2081. While this is an approximation, it nonetheless retains much of the L\u2081's communicative accuracy when interacting with end-users, and running orders of magnetudes faster.\nKey Finding 2: In the special case where only a single example is used, RSA_single, the approximation can be made exact: There exists a global ranking \u03c3* that perfectly matches the top-k responses of L1 over any example u."}, {"title": "4. Distilling L\u2081 of RSA to a Global Ranking", "content": "Distilling the example-dependent L\u2081 rankings into a global ranking has two stages. First, we generate a dataset of D = {(w, u, \u00f5u), . . . }, where w is a program, u is a specification (sequence of examples) used to describe w, and \u00d5u = [w\u2081, w\u2082,..., w\u2096] are the k example-dependent rankings of consistent programs given u.\u00b3 Then, we distill a global ranking that aggregates the example-dependent rankings in D."}, {"title": "4.1. Dataset Generation via Simulated Communications", "content": "The pragmatic listener L\u2081 can generate a partial ranking of consistent programs for any sequences of examples u. As arbitrary examples u are unlikely to reflect what a user might give at inference time, we use the informative speaker S\u2081 as a \"stand-in\". Specifically, we generate D in a form of simulated interactions between the pragmatic speaker S1 and the pragmatic listener L\u2081. We enumerate over the set of programs w \u2208 W, then use the pragmatic speaker to sample the most likely specifications (sequence of examples) u ~top-1 S1(w) of length 1 to length N. For each specification, we query L\u2081 for a partial ranking \u1ee1u of consistent programs, and add it to the dataset D (Algorithm 1)."}, {"title": "4.2. Distillation via Annealing", "content": "The most straight-forward representation of a ranking is as an explicit list of programs &global = [w\u2081, w\u2082,..., w\u2099]. We describe a process of finding an approximate global ranking using annealing. We repeatedly sample example-dependent rankings \u00f5u from D, and update the global ranking &global to match \u1ee1u for a single pair of programs sampled from \u00f5u. Since cycles exist in example-dependent rankings, we terminate the annealing procedure once the number of swaps in a sliding window has stabilized (Algorithm 2). The resulting Oglobal is then used at inference time."}, {"title": "4.3. Distillation via Learning a Score Function", "content": "An alternative method to distill D is to train a score function Se: w\u2192 R that determines a score for a program w that is independent of the specifications u. We can optimize \u03b8 to minimize disagreement with the generated dataset of example-dependent rankings, by minimizing the loss\n\\[\\mathcal{L}(\\theta) = \\mathbb{E}\n_{\\tilde{u} \\sim D}\n[\\log(\\text{sig}(s_{\\theta}(w_1) - s_{\\theta}(w_2)))]\\]\nwhere sig is the sigmoid function. This follows estimating a score function from a set of pairwise preferences (Bradley & Terry, 1952; Christiano et al., 2017). We parametrize se as a small neural network that scores programs. To reduce variance, we fit an ensemble of score functions and use their average to rank the consistent programs at inference time (Christiano et al., 2017). Details of the neural models are in Appendix E."}, {"title": "5. Experiments", "content": "To validate the accuracy and run-time of an approximate ranking listener, we perform two sets of experiments. First, we conduct a small (n = 8) human experiment by building a ranking-based synthesizer in a regular expression synthesis domain where it is infeasible to run the RSA algorithm L1 at interaction time. Second, we conduct two replay studies by simulating virtual users giving examples one after another using human interaction data collected from prior works. We seek to answer the following questions: (Q1) Can ranking based synthesizers accurately infer programs from humans (both in live interaction and in simulated replays)? (Q2) Are ranking-based synthesizers fast to run when compared to Lo and L\u2081?\nMetrics In our experiments, the users (real or simulated) will be given a target program, and attempt to communicate it to the synthesizers using examples. The synthesizers will be measured on their communication accuracy whether the synthesizers can infer the target program from the examples given. A synthesizer is better than another if it can recover the target program using fewer examples."}, {"title": "5.1. Interactive User Study", "content": "We conduct a user study where people interacted with both the ranking-based synthesizer distilled with annealing Lanneal and the literal synthesizer Lo on the domain of regular expression synthesis.\nThe Regex Domain The regex domain is a scaled up version of Vaithilingam et al. (2023), which has a total of 350 regular expressions from their grammar (Figure 4. For this study, we expanded the space of programs to 3500 regular expressions from the same grammar a setting that would make live interaction infeasible running L\u2081 with RSA."}, {"title": "5.2. Simulated User Studies Using Replays", "content": "We evaluate the ranking-based synthesizers by replaying the interaction data collected from Vaithilingam et al. (2023) and Pu et al. (2020) \u2013 small pragmatic program synthesis domains where it is feasible to run L\u2081 with RSA.\nReplay Data In the human studies by Vaithilingam et al. (2023) and Pu et al. (2020), a human H is given a target program w, and attempt to get the synthesizer (Lo or L\u2081) to infer the target using a sequence of examples u = u\u2081, u\u2082,. Thus, two sets of data are generated, one where the human is interacting with the literal synthesizer Lo, which we term Ho, and one where the human is interacting with the pragmatic synthesizer L1, which we term H\u2081. Specifically, from each domain we extract the following dataset {(w, u)|w \u2208 Ws, j\u2208 P, i \u2208 {0, 1}}. Here, W\u300f are the set of programs used for the human study (the stimuli), P is the set of participants, and i indicates if the participant is communicating with Lo or L1.\nExperiment Setup We can simulate an user interaction by using the replay data. Given a datapoint w, u, we create a simulated user that iteratively gives the examples u\u2081, u\u2082,... in multiple turns to communicate a given target program w. At every turn, the synthesizer returns the top-1 responses, Ltop-1(u1), Ltop-1 (u1,u2), . . ., and we can check if any of them matches the target program w. If they do, we mark the communication as successful and stop early. Otherwise, we keep adding examples until the u runs out, and we mark the communication as unsuccessful. Note that our evaluation cannot account for a user adapting their choice of examples to L, as the simulated user can only give scripted examples according to the replay data."}, {"title": "6. RSA_single Can Be Distilled Completely", "content": "In this section, we prove a strong approximation result for a special case of RSA, RSA_single, where only a single example u is used to communicate. In accordance with the terminologies of Goodman & Frank (2016); Vogel et al. (2013); Monroe & Potts (2015); Smith et al. (2013) and Franke & Degen (2016), we'll use the term \u201chypothesis\" instead of \"program\". We prove that a global pragmatic ranking of hypotheses must exist for any listeners Lo, L1,... resulting from the RSA_single algorithm.\u2074 In other words, the rankings over consistent hypotheses in these listeners are example-agnostic.\nTheorem: For a sequence of listeners in the RSA algorithm Lo, L1,... over a boolean-valued lexicon M, there exists a sequence of global pragmatic rankings Lo, OL\u2081,\u06f0\u06f0\u06f0 such that:\n\\\\[\\forall w, w', u. \\text{ if } L_i(w|u) > 0 \\land L_i(w'|u) > 0.\\\\\\]\n\\\\[ \\text{then } L_i(w|u) > L_i(w'|u) \\Leftrightarrow \\sigma_{L_i}[w] > \\sigma_{L_i}[w'] \\tag{4}\\]\nThis means the partial rankings produced by any Li over consistent hypotheses are example-agnostic, where a global ranking preferring certain hypotheses unconditionally over others (e.g. a convention) is sufficient to explain the relative rankings of Li resulting from RSA_single.\nProof: Let M be a boolean lexicon of size m rows and n columns. Let ro = r\u2080...r\u2098 be the row-normalizing vector such that r\u2070 = (\u2211M[j, :])\u207b\u00b9, which is to say, each element r\u2080 is the normalization term for row j of Lo. Let *\u2191 denotes row-wise multiplication:\n\\[L_0 = M*\\uparrow r_0\\]\nWhich is to say, starting from M, Lo can be obtained by scaling each row j by their respective normalization constant ro. Let c\u2081 = c\u2081 ... c\u2099 be the col-normalizing vector such that c\u2081 = (\u2211 Lo[:, j])\u207b\u00b9, which is to say, each element c\u2081 is the normalization term for column j of S\u2081. Similarly, let *\u2194 denotes column-wise multiplication\n\\[S_1 = L_0*\\leftrightarrow c_1 = M*\\uparrow r_0 *\\leftrightarrow c_1\\]\nComputing Li under RSA amounts to applying row and column normalization alternatively multiple times:\n\\[L_i = M *\\uparrow r_0 *\\leftrightarrow c_1 ... *\\leftrightarrow c_{i-1}*\\uparrow r_i\\]\nLet * be element-wise multiplication, let \u2297 be outer-product, we can rearrange the terms:\n\\[L_i = M * ((r_0 ... r_i) \\otimes (c_1 *...* c_{i-1})) \\tag{5}\\]"}, {"title": "7. Related Works", "content": "Scaling RSA without Global Ranking Prior work such as that by Monroe et al. (2017) and Andreas & Klein (2016) has largely focused on sample and re-rank as a way of scaling RSA, making the example-dependent ranking function S\u2081(u|w) more efficient at a cost of accuracy. Recent work by Key et al. (2022) and Vaduguru et al. (2024) apply the sample and re-rank approach to program synthesis, resulting in neural program synthesizers that also rank programs in an example-dependent way. Our work enables a different kind of synthesis algorithm altogether that of a distilled pragmatic ranking that rank consistent programs agnostic to examples given. We view these works as complementary, able to efficiently produce a simulated communication dataset D which our approach can distill from.\nScaling RSA with Human Data RSA has been applied to improve the performance of language interfaces in a variety of other domains, such as image description (Andreas & Klein, 2016; Cohn-Gordon et al., 2018a;b), instruction generation and interpretation (Fried et al., 2018a;b), and grounded interaction (Fried et al., 2021; Lin et al., 2022). These works all use speaker models trained on labeled data from people. Our approach requires no human-produced data, and can be run entirely from the lexicon M of the synthesis problem. On the other hand, we can easily integrate human data within our approach by training similar speaker models on the collected interactive data.\nRanking Functions in Synthesis Prior works on resolving ambiguity in program synthesis have relied on example-agnostic ranking functions. Works such as Singh & Gulwani (2015); Polozov & Gulwani (2015) use scoring functions to penalize certain properties of programs (e.g. discouraging the use of constants), effectively inducing a global ranking over all programs; Ellis & Gulwani (2017) uses a set of hand-crafted features to learn a naturalistic ranking from data. Synthesis algorithms that use a large neural code model to sample a large number of programs (Chen et al., 2021; Li et al., 2022) implicitly rank the programs based on their naturalistic distributions in its training data. Our work is unique in that (1) the learned ranking is rooted in efficient communication rather than hand-crafted features and (2) our approach does not require human annotated data.\nOther Theoretical Works on Ranking Recent work by Muggleton FREng (2023) shows that in the case of single-example, the MAP estimate of the learner can be completely ranked by s\u03bb(H) + lng(H) an example-agnostic global ranking. Our work can be viewed as a strict generalization in the following sense: They consider the chain of recursive bayesian reasoners of the form M \u2192 So\u2192 L1, whereas our result applies to any alternating chains speakers and listeners of arbitrary depth. Their notion of \u201cspecificity\u201d and \"program length\" also has direct analogies to the normalization terms in Equation (5), except these analogies do not carry over to deeper recursive depths."}, {"title": "8. Conclusion", "content": "We present a way of amortizing the expensive RSA algorithm by an example-agnostic global ranking. We have shown this amortization interacts well with humans when applied to two program synthesis domains. We have further proved this amortization is exact in the case of communication with a single example. In addition of being a practical method for scaling up RSA, these findings may provide an alternative account for pragmatic behaviour in humans one rooted in relative rankings of hypotheses (e.g. a pragmatic prior), perhaps distilled from the expensive RSA computation over time."}, {"title": "8.1. Limitation and Future Directions", "content": "The limitation of our approach is two-fold: First, whether an optimal global ranking exists for the multi-example PBE setting; Second, whether our distillation algorithm can find this optimal ranking.\nExistence of an effective global ranking The effectiveness of a global ranking is upper-bounded by the amount of cycles that exists in the communicative dataset of example-dependent rankings of subsets of programs. A cycle exists if under one ranking we have wa > wb, and under a different one we have w\u044c > wa, which no single ranking can approximate exactly. Forecasting the number of cycles from the meaning matrix M is an exciting future work.\nEffectiveness of distilling an effective global ranking Our experiments have shown that given a communicative dataset, both the annealing (in the case of a small dataset) and neural scoring (in the case of a larger dataset) have their merits in deriving a ranking. Thus, running the slow RSA in the dataset generation itself is the likely bottleneck. We believe recent works by Key et al. (2022) and Vaduguru et al. (2024) using sample-and-rerank may be used in generating the communicative dataset instead of the exact RSA algorithm."}, {"title": "Impact Statement", "content": "This work builds a system where end-users may use examples to generate programs. While the proposed method is more intuitive to use by humans, it is possible that for some interactions, it may generate unexpected programs. Therefore, it could be of potential danger when humans do not manually verify the generated program, as it may have unintended outcomes when executed."}, {"title": "B.1. Ranking Always Exists", "content": "We empirically validate that in the case of single utterances, a ranking can always be found. See simulation/single_utter/exp_exists_orders.py"}, {"title": "B.2. Stability of Ranks Across RSA Iterations", "content": "We've shown that for every Lo, L1,..., there exists a corresponding global, utterance agnostic ranking \u03c3\u03c4\u03bf, L1,.... We now explore the relationship between these rankings as a function of the RSA iteration i. Specifically, how stable is the relative ranks of w and w' once it is formed?\nStable Order A pair-wise order between w and w' is stable from iteration i onward if:\n\\[stable(i, w > w') \\triangleq \\bigwedge_{j\\in{i,i+1,...,\\infty}} \\sigma_{L_j} [w] > \\sigma_{L_j}[w']\\]\nWhich means the relative ranking of \u03c3\u03c4\u2081 [w] > \u03c3\u03c4\u2081 [w'] holds true for every subsequent iterations until OL\u221e. Let the minimal-index of a stable pair-wise ordering be the first iteration i such that w > w' becomes stable:\n\\[i_{min}(w > w') = argmin_{j} stable(j, w > w')\\tag{6}\\]\nAs OL\u2081 is the first time any ranking can exist (Lo is a uniform distribution over valid hypotheses, i.e. no rankings), we explore the following: For a lexicon M, what fraction of stable orderings have a minimal-index of 1?\n\\[frac-stable_{L_1}(M) = \\frac{|{w > w' | i_{min} (w > w') = 1}|}{|{w > w' | \\exists i. stable(i, w > w')}|}\\tag{7}\\]\nSimulation We measure stableL\u2081 (M) on a population of sampled random boolean lexicons. We sample square lexicons of size lexicon_size \u2208 2 \u00d7 2 . . . 100 \u00d7 100. Each lexicon is sampled with Ptrue \u2208 {0.1, 0.2, 0.5}, where larger value of Ptrue makes the lexicon have more 1s. We make sure each sampled lexicon is valid in the following sense: (1) all rows are unique \u2013 every utterance must communicate a unique subset of valid hypotheses (2) all columns are unique \u2013 every hypothesis has a unique set of utterances that can refer to it. For every combination of (Ptrue, lexicon_size) we randomly sample 100 lexicons. As it is infeasible to run RSA until iteration \u221e, we run RSA for 100 iterations for each lexicon (i.e. L100 \u2248 L\u221e). We measure stable, for each sampled lexicon. The result is shown in 9. As we can see, of all the stable pair-wise orderings, a large fraction (> 0.8) are formed during OL\u2081, this is increasingly true as we (1) increase Ptrue, making the boolean lexicons having more number of 1s \u2013 i.e. the lexicon is more ambiguous for a literal speaker and listener and (2) increase lexicon_size. We suspect this is due to faster \u201cmixing time\u201d of the RSA algorithm under these conditions, but this is just a guess.\nTakeaway This study may provide an alternative explanation as to why humans do not perform RSA for more than few iterations (Franke & Degen, 2016). In addition to it being computationally expensive, it is also not necessary as the majority of top-k orderings becomes available at OL\u2081, and remains stable for all subsequent iterations of the RSA algorithm. In another word, Ltop-k Ltop-k. Code in simulation/single_utter"}, {"title": "C. Animals domain", "content": "In the Animals domain, a program is a pattern on a grid formed from a set of objects. These objects may be a colourless pebble, or a chicken or pig that may be red, green or blue. An utterance reveals one square on the grid, and the speaker has to communicate the pattern by choosing which square to reveal. The pattern is formed according to rules specified in the domain-specific language in Figure 10. Examples of programs shown in Figure 11. The description of the domain-specific language and the examples are due to Vaduguru et al. (2022)."}, {"title": "D. Human study interface", "content": "The interface for the human study on regular expression programs is shown in Figure 12."}, {"title": "E. Neural model", "content": "The neural scoring model maps from the program to a real number. The program is input as vector encoding the productions of the grammar that produce the program. That is, we construct a vector of the index of the production that is used to expand each non-terminal in the DSL grammar. We then convert this vector to a one-hot matrix. There are 12 rules, with any single rule having at most 7 possible expansions resulting in an input vector of dimension 12 \u00d7 7 = 84. The input is then passed through 3 hidden layers of size 128, each of which has as ReLU activation, and then mapped to a scalar output with a linear layer.\nThe model is trained on a dataset of rankings of the form D = (w, u, \u00f5u). For each program w, we sample a pair of programs from the inferred ranking \u00f5u and use this pair to compute the loss function for this sample. We train the model for a maximum of 20 epochs, where one epoch of training corresponds to presenting the model with every element in D once. We train with a batch size of 32 using the Adam optimizer. We use a validation set generated similarly to D (on a disjoint set of programs) to perform validation, choosing the model that results in the highest synthesis accuracy on this validation dataset with synthetically produced examples (from the S\u2081 speaker model).\nWe train an ensemble of 10 models. For each model, we normalize the scores to be of zero mean and unit variance based on the empirical mean and standard deviation computed on the validation set. We then average the scores for the 10 models at inference time."}]}