{"title": "Simple Augmentations of Logical Rules for Neuro-Symbolic Knowledge Graph Completion", "authors": ["Ananjan Nandi", "Navdeep Kaur", "Parag Singla", "Mausam"], "abstract": "High-quality and high-coverage rule sets are imperative to the success of Neuro-Symbolic Knowledge Graph Completion (NS-KGC) models, because they form the basis of all symbolic inferences. Recent literature builds neural models for generating rule sets, however, preliminary experiments show that they struggle with maintaining high coverage. In this work, we suggest three simple augmentations to existing rule sets: (1) transforming rules to their abductive forms, (2) generating equivalent rules that use inverse forms of constituent relations and (3) random walks that propose new rules. Finally, we prune potentially low quality rules. Experiments over four datasets and five ruleset-baseline settings suggest that these simple augmentations consistently improve results, and obtain up to 7.1 pt MRR and 8.5 pt Hits @ 1 gains over using rules without augmentations.", "sections": [{"title": "Introduction", "content": "Knowledge Graphs (KGs) comprise important world knowledge facts, but are typically incomplete, due to their ever-increasing size. KG embeddings (Wang et al., 2017) has been the dominant methodology for knowledge graph completion (KGC). A KG embedding approach represents entities and relations as learnable dense vectors and computes a score for an unseen fact as a function over them. These generally have state-of-the-art performance, especially for large KGs.\nRecently, neuro-symbolic (NS-KGC) approaches for the task have been proposed, where KG embeddings are enhanced by inferences over an explicit first-order logic rule set (Zhang et al., 2020; Qu et al., 2021). The resulting models bring together best of both worlds generalizability and interpretability of explicit logical rules, and the scalability and representation power of embeddings. Unfortunately, a key roadblock for success of NS-KGC is the availability of a high-coverage rule set.\nEarly NS-KGC methods, such as NeuralLP (Yang et al., 2017) and DRUM (Sadeghian et al., 2019), learn rules as part of a single model, but do not have performance competitive with embedding models such as RotatE (Sun et al., 2019). A recent NS-KGC model, RNNLogic (Qu et al., 2021), matches empirical performance with embedding approaches. It has a separate neural component that outputs a set of rules, which is then used to train inference parameters, in an EM-based approach. Preliminary experiments on RNNLogic suggest that its ruleset has limited coverage, due to which symbolic inferences do not fire for many queries, and the model gets limited to using its embedding part only. The goal of this work is to strengthen the symbolic inferences in NS-KGC models for better overall performance.\nIn this work, we propose simple augmentations that take an existing ruleset (such as one output by RNNLogic) and proposes additional (related) rules to improve coverage and quality. We propose three augmentations. First, we convert each deductive rule into its abductive counterparts. Second, we supplement each rule via an equivalent rule that uses inverses for all constituent relations. Third, we generate additional high-quality rules independently by local random walks and subsequent PCA filtering (Gal\u00e1rraga et al., 2013). These increase size of ruleset drastically; we balance runtimes by additionally pruning rules from existing set using our filtering approach. Overall, this results in a comparable number of high-quality and high-coverage rules, for use in NS-KGC.\nOn four KGC datasets, over three NS-KGC models, we find that our augmentations consistently improve KGC performance, outperforming no augmentation baselines by up to 7.1 MRR and 8.5 Hits@1 pts. We believe our augmentations should become standard practice over any ruleset for NS-KGC. We release our code 1 and rulesets."}, {"title": "Background and Related Work", "content": "We are given an incomplete KG K = (E,R,T) consisting of entities E, relation set R and set T = {(h, r, t)} of triples. Our goal is to predict the validity of any triple not present in T.\nRelated Work: Existing work on NS-KGC can roughly be characterized into four types. One approach is to use attention over relations to learn end-to-end differentiable models (Yang et al., 2017; Sadeghian et al., 2019). A second approach, which includes Minerva (Das et al., 2018) and Deep-Path (Xiong et al., 2017), uses RL to train an agent to find reasoning paths for KG completion. These approaches are not yet competitive to KG embedding models for large datasets. Thirdly, models like ExpressGNN (Zhang et al., 2020) and RNN-Logic use variational inference to assess plausibility of a given triple. We experiment with both these models in this paper. The final type includes UNIKER (Cheng et al., 2021) and RUGE (Guo et al., 2018), which integrate embeddings alongside traditional rules learnt via ILP models. We believe that our augmented rules can benefit these works too. Since our experiments are based on RNN-Logic, ExpressGNN and we utilize PCA scores for filtering, we describe these in some detail next.\nRNNLogic+: As a pre-processing step, for every r \u2208 R, RNNLogic adds a relation r\u00af\u00b9 to R, and corresponding facts using inverse relations to T. RNNLogic first produces a set of first order rules (L) using an LSTM which are used by the RNN-Logic+ predictor to compute the score of a given triple. Given a query (h, r, ?), the candidate answer o is scored by RNNLogic+ as:\nscor(o) = MLP (PNA({v1| #(h, r, o)}1\u2208\u00a3)) (1)\nwhere the learnable embedding v\u2081 of a given rule 1 \u2208 L is weighted by the number of groundings (#) that triple (h, r, o) satisfies in the rule 1's body. The resulting weighted embeddings of all rules are aggregated by employing PNA aggregator (Corso et al., 2020) and this aggregated embedding is passed through an MLP to obtain a final score. The authors designed another scoring function that incorporates RotatE (Sun et al., 2019) into the scoring function, scor(o), in equation (1) where the goal is to exploit the knowledge encoded in the KG embeddings. The resulting scoring function is:\nscoreKGE(O) = scor(o)+\u03b7 Rotate (h, r, o) (2)\nwhere RotatE (h, r, o) is the score of the triple obtained from RotatE, and \u03b7 is a hyper-parameter.\nRotate (h, r, o) is the negation of the value obtained by rotating the embedding for h by the rotation transformation defined by the embedding of r in complex space and computing the distance from the embedding of t. Please refer to Appendix B for further details.\nExpressGNN: It is a novel model that integrates Markov Logic Networks (MLN) (Richardson and Domingos, 2006) and Graph Neural Networks (GNN) (Kipf and Welling, 2017) to exploit their complementary strengths. An open-world paradigm is adopted in which a fact that is unknown in KG is assumed to be hidden (not false). The joint distribution of the observed and hidden triples of the KG in the MLN is optimized by employing a variational EM framework where the variational posterior distribution of the hidden variables is encoded as a GNN. Please refer to (Zhang et al., 2020) for further details about the model.\nPCA Score: It is a symbolic rule confidence metric proposed in AMIE (2013) see Appendix M for details. Broadly, it is the number of positive examples satisfied by a rule, divided by the total number of tails reached by the rule from heads occurring in the training dataset. Its performance in the context of AMIE was not as good due to its purely symbolic approach, and we are likely the first to show its utility in the context of NS-KGC."}, {"title": "Rule Augmentation in NS-KGC Models", "content": "With the aim of maximal utilization of a given rule 1 \u2208 L, we first propose two rule augmentation techniques: abduction and rule inversion. The other two techniques prune low-quality rules from L, and independently add new rules to increase coverage. All augmentations are generic and can be integrated with any existing ruleset, and NS-KGC model.\nAbduction: The goal of abductive reasoning (or abduction) is to find the best explanation from a given set of observations (Pierce, 1935). It has seen limited use in the context of KBs (Yoshikawa et al., 2019). In our approach, for every rule in L, we introduce several abductive rules with one of the antecedants, appearing as a consequent. As an example, consider the rule:\nR1(X, Y) ^ R2(Y, Z) ^ R3(Z, W) \u21d2 RH(X, W)\nOur augmentation will generate abductive rules, one for each relation in the body, as:"}, {"title": "", "content": "R2(Y, Z) ^ R3(Z, W) ^ RH\u00af\u00b9(W, X) \u21d2 R1\u00af\u00b9(Y, X)\nR3(Z, W) ^ RH\u00af\u00b9(W, X) ^ R1(X, Y) \u21d2 R2\u00af\u00b9(Z, Y)\nRH\u00af\u00b9(W, X) ^ R1(X, Y) ^ R2(Y, Z) \u21d2 R3\u00af\u00b9(W, Z)\nAs an example, let's say a learned rule is BornIn(X, U) A PlaceInCountry(U,Y) \u21d2Nationality(X, Y). If in the KG, we know that Oprah has nationality U.S., and that she is born in Mississippi, then abduction allows the model to hypothesize that Mississippi might be in U.S. Of course, not all abductions are accurate, for instance, just because Alabama is known to be in U.S., does not mean that Oprah was born in Alabama. Abductive rules increase rule coverage at the cost of precision. We expect the predictor scorer to automatically handle which (abductive) rules can and cannot be trusted.\nBornIn\nRule Inversion: Our second rule augmentation takes an existing rule and rewrites it by referring to inverses of all relations. As an example, if a rule uses the path\nPlaceInCountry\nOprah \u2192 Mississippi \u2192 US,\nthen it could also use the equivalent path\nPlaceInCountry-1\n\u2192 Mississippi\nOprah. Formally, for every original rule:\nUS\nBornIn-1\n\u2190\nR1(X, Y) ^ R2(Y, Z) ^ R3(Z, W) \u21d2 RH(X, W)\nwe add to the ruleset the following inverted rule:\nR3-1(W, Z) ^ R2-1(Z, Y) ^ R1-1(Y, X) \u21d2 RH-1(W, X)\nRule Filtering: Augmentations increase the size of the ruleset. In order to reduce the number of parameters and the training/test times of the NS-KGC model, we prune seemingly low-quality rules from the augmented rulebase. For this, we compute the PCA score for each original and augmented rule and prune all the rules that have score less than a threshold (set at 0.01 in experiments) and have less than 10 groundings. So, all low-coverage rules with seemingly low quality are pruned out. As experiments show, this results in up to 70% reduction in the number of rules, while preserving KGC performance.\nRandom Walk Augmentation: Motivated by the empirical success of PCA scores for finding good rules in the previous step, we further augment our ruleset with new, high scoring rules generated independently via local random walks. Starting at each entity in the KG, we perform a number of random walks of fixed length. Each such random walk constitutes the body of the rule and the relation connecting the end entities in the KG form the head of the discovered rule. We score these rules by the PCA score and retain all such rules that have PCA score above the threshold (of 0.1)."}, {"title": "Experiments", "content": "Datasets: We use four datasets for evaluation: WN18RR (Dettmers et al., 2018), FB15K-237 (Toutanova and Chen, 2015), Kinship and UMLS (Kok and Domingos, 2007). For each triple in test set, we answer queries (h, r,?) and (t, r\u00af\u00b9,?) with answers t and h. We report the Mean Reciprocal Rank (MRR) and Hit@k (H@1, H@10) under the filtered measures (Bordes et al., 2013). Details and data stats are in Appendix A.\nBaselines: We first experiment with two base models: RNNLogic+ ([RNN] in tables), and RNNLogic+ with RotatE ([RNN+RotE]) (Eqn 2). We have reproduced the numbers published by the original authors for these models (details in Appendix D). We run these models with two rulesets: (1) Orig, rules generated by RNNLogic (around 300 rules per relation for WN18RR and FB15k-237, and 1000 rules per relation for Kinship and UMLS), and (2) RW, only the rules discovered by our random walks. This second setting can only evaluate the value of abduction, inversion, and pruning since random walks are anyways used in generating rules. More details in Appendix C, F and G.\nIn order to assess the generality of our augmentations, we also experiment with ExpressGNN (Zhang et al., 2020). We choose top five rules for each relation from RNNLogic's Orig ruleset according to PCA confidence and provide them as input ruleset to ExpressGNN ([ExpGNN] in tables). ExpressGNN does not scale up to the augmented ruleset for FB15K-237, hence we test it for the other three datasets. Refer to Appendix E for more details. We use AUG to denote the performance of rule augmentations for all baselines.\nWe also tried rulesets from NeuralLP (2017), but they are too small to be useful with RNN-Logic+. The only other NS-KGC model that has reported performance similar to RNNLogic+ is RLogic (2022). Unfortunately, their code is not publicly available.2"}, {"title": "Analysis of Augmented Rules", "content": "We perform five further analyses to answer the following questions. Q1. Are the rules created by abduction and rule inversion of high quality? Q2. What is the individual effect of each type of augmentation on the performance? Q3. How do the rule augmentations affect the training time of a model? Q4. Can we get the same performance as augmentation by generating more rules from the LSTM in RNNLogic? Q5. Are the augmented rules interpretable by a human?\nQuality of New Rules: To answer Q1, we employ two metrics to assess quality of rules, (PCA-metric and FOIL-metric) before and after abduction and rule inversion. The rules obtained from random walks have high scores by construction since they are filtered based on PCA score. Therefore, they are of high quality as per our definition. (Details in Appendix M and N)\nAblation: To answer Q2, we perform an ablation"}, {"title": "Conclusion and Future Work", "content": "We present simple rule augmentation techniques in the context of Neuro-Symbolic Knowledge Graph models and obtain substantial increase in performance over strong base models. We believe our augmentations can become standard for all subsequent NS-KGC models. We release code and rulesets for further research. Future work includes using our augmentation technique during the iterative learning of rules in algorithms such as RNNLogic, potentially further improving their performance."}, {"title": "Limitations", "content": "Since rule abduction and inversion utilize the same groundings as the original rules, Neuro-Symbolic KGC models that are based on grounding the entire rule will not benefit from these augmentations. Abduction and inversion also require the model to be trained on a knowledge graph that contains the inverse relations r\u00af\u00b9 for each relation r. Finally, since RNNLogic+ has a separate rule embedding for each rule, performing rule augmentation increases the number of parameters in the model and leads to longer training times and larger GPU memory consumption."}, {"title": "Ethics Statement", "content": "We anticipate no substantial ethical issues arising due to our work on rule augmentation for Neuro-Symbolic KGC. Our work relies on a set of rules generated from another source to perform augmentation. This may result in the augmented rule set exaggerating the effect of malicious or biased rules in the original rule set."}]}