{"title": "Hardware-Aware DNN Compression for Homogeneous Edge Devices", "authors": ["Kunlong Zhang", "Guiying Li", "Ning Lu", "Peng Yang", "Ke Tang"], "abstract": "Deploying deep neural networks (DNNs) across homogeneous edge devices (the devices with the same SKU labeled by the manufacturer) often assumes identical performance among them. However, once a device model is widely deployed, the performance of each device becomes different after a period of running. This is caused by the differences in user configurations, environmental conditions, manufacturing variances, battery degradation, etc. Existing DNN compression methods have not taken this scenario into consideration and can not guarantee good compression results in all homogeneous edge devices. To address this, we propose Homogeneous-Device Aware Pruning (HDAP), a hardware-aware DNN compression framework explicitly designed for homogeneous edge devices, aiming to achieve optimal average performance of the compressed model across all devices. To deal with the difficulty of time-consuming hardware-aware evaluations for thousands or millions of homogeneous edge devices, HDAP partitions all the devices into several device clusters, which can dramatically reduce the number of devices to evaluate and use the surrogate-based evaluation instead of hardware evaluation in real-time. Experiments on ResNet50 and MobileNetV1 with the ImageNet dataset show that HDAP consistently achieves lower average inference latency compared with state-of-the-art methods, with substantial speedup gains (e.g., 2.86 \u00d7 speedup at 1.0G FLOPs for ResNet50) on the homogeneous device clusters. HDAP offers an effective solution for scalable, high-performance DNN deployment methods for homogeneous edge devices.", "sections": [{"title": "1. Introduction", "content": "Recently, the development of Artificial Intelligence & Internet of Things (AIoT) has raised an increasing demand for deploying AI models on edge devices [7]. As the dominant AI models in lots of tasks like computer vision [4] and natural language processing (NLP) [13], Deep Neural Networks (DNNs) are highly required to run on the edge [46]. However, as models become more powerful, their size, computational requirements, and latency grow proportionally. Modern neural networks, with millions or even billions of parameters (e.g., GPT-3 [6]), encounter increasing challenges in widespread deployment, especially due to stringent energy and latency constraints [7, 46]. In scenarios such as autonomous driving, failing to meet latency constraints not only diminishes user experience but also raises serious safety risks. In practice, such DNNs should be carefully compressed for edge deployment, and many researchers are continually working on the issue [9, 32, 38, 43].\nHardware-aware DNN compression [17, 19, 42] offers an effective solution to reduce model size for edge devices. \"Hardware-aware\" here indicates evaluating the compressed models on edge devices for their real performances, which is different from traditional DNN compression methods where proxy metrics (like parameter numbers and FLOPs) are adopted as the edge performances of compressed models. The actual feedback from edge devices makes hardware-aware DNN compression the best suitable for AIoT scenarios [36, 41, 47, 50].\nDespite the effectiveness, existing hardware-aware DNN compression methods are not yet practical for large-scale deployment. First, most existing methods are designed for one edge device [17, 19, 36, 42, 47, 49, 50, 52], whereas the real-world target is a homogeneous edge cluster. In the large-scale AIoT deployment scenario, a trained DNN generated in the data center is deployed on numerous devices with identical architecture (the devices with the same SKU labeled by the manufacturer), which referred to as a homogeneous edge cluster. For example, updating an AI camera model on millions of replicas of iPhone 16. Based on previous research [1, 14, 45], these replicas appear to have different performances due to the different user configurations, environmental conditions, or manufacturing variances. See Fig. 1 for an illustration. This makes existing hardware-ware DNN compression methods impractical because they are only designed for one device. Second, hardware-aware evaluation is costly and impractical for hundreds or thousands of homogenous edge devices. Each hardware-aware evaluation requires running the candidate compressed model on an edge device tens of hundreds of times to obtain an average performance. This is highly time-consuming due to the limited computational power of edge devices [28].\nIn this paper, a new hardware-aware DNN compression method called Homogeneous-Device Aware Pruning (HDAP) is proposed, which can deal with all the problems mentioned above. In HDAP, the DNN compression task for homogeneous devices is formulated as a constrained single-objective optimization problem, which requires minimizing the average latency of the compressed model on all the devices and subjected to the model's accuracy loss. The DNN compression technique used in HDAP is DNN pruning [9, 16], which directly drops the redundant components of the trained DNN. Once the proposed optimization problem is solved, the best-compressed model for all the devices can be automatically found. Two major difficulties lay on the way to solving the optimization problem: the first is the suitable optimization algorithm, and the second is the time-consuming hardware-aware evaluation process. HDAP first adopts a powerful derivative-free optimization algorithm, negatively correlative search (NCS) [39], to solve the non-trivial optimization problem. To accelerate the evaluation process for compressed models, HDAP creates a surrogate-based evaluation process instead of evaluating models on the hardware in real-time.\nOur main contributions can be summarized as follows:\n\u2022 We first introduce the task of hardware-aware DNN compression on the homogeneous edge devices, which is based on the practical scenario of AIoT. Existing hardware-aware DNN compression methods can not solve this task.\n\u2022 We propose HDAP to compress DNN models for homogeneous edge devices. The compression technique used in HDAP is DNN pruning, but other techniques like DNN quantization [22, 32] can also be used instead.\n\u2022 We validate our approach through extensive experiments on the ImageNet dataset with ResNet50 and MobilNetV1, demonstrating that HDAP effectively improves efficiency and consistency across homogeneous edge devices.\nThe remainder of this paper is organized as follows. In Sec. 2, we review related work on hardware-aware DNN compression. Sec. 3 details our proposed HDAP framework. Experimental results and analyses are presented in Sec. 4, demonstrating the effectiveness of our approach. Finally, we conclude the paper in Sec. 5."}, {"title": "2. Related Work", "content": ""}, {"title": "2.1. Hardware-Aware DNN Compression", "content": "Hardware-aware DNN compression methods aim to optimize DNN models not only for accuracy but also for performance on specific hardware devices. These methods integrate hardware performance metrics, such as inference latency [29, 36, 42, 47, 50, 52], memory usage [17, 19], and energy consumption [42, 49], directly into the compression or optimization process to produce compressed models that are suited for deployment on the target hardware. However, these methods are designed for one edge device, assuming consistent performance across homogeneous edge devices-a condition that often does not hold in practice [1, 14]. Although some research in hardware-aware compression addresses multi-device scenarios, it primarily focuses on different types of devices (e.g., GPUs, embedded systems, mobile phones), where \"multi-device\" refers to device diversity [41]. In contrast, this work focuses on homogeneous edge devices."}, {"title": "2.2. DNN Pruning", "content": "DNN compression has been widely studied to deploy complex models on resource-constrained devices. Common methods include pruning [9, 16], quantization [22, 32], knowledge distillation [24, 43, 54], and low-rank decomposition [38, 44, 48]. Pruning is particularly effective, as it reduces model size and computational costs while preserving accuracy. Pruning techniques fall into unstructured and structured categories. Unstructured pruning [3, 11, 23, 34] removes individual weights, creating sparse matrices that may limit hardware efficiency [30]. Structured pruning [10, 18, 51], by contrast, removes filters or neurons, resulting in models with regular structures that are more hardware-friendly [8]. This approach enhances hardware acceleration compatibility and is often more feasible for deploying DNNs on limited-resource devices."}, {"title": "2.3. Performance Prediction Methods", "content": "Evaluating DNN models directly on edge devices is time-consuming, which is the bottleneck in hardware-aware DNN compressions. Some previous work speeds up the evaluation by performance prediction methods. Performance prediction methods are algorithms to predict the performance values of running DNNs on devices. There are three primary approaches:\nMathematical Models [29]: These use detailed hardware and DNN computational characteristics to simulate performance, modeling the execution pipeline, memory access, and operations. While potentially accurate, developing these models requires in-depth hardware and DNN knowledge.\nLookup Table (LUT) [36, 50, 52]: LUT-based methods split the DNN architecture into different operational units and evaluate the performances of these units on devices. Then, a performance lookup table indexed by operational units and devices is built. Once a DNN model needs to be evaluated, the LUT-based methods will sum the operational units' performance of the model based on the lookup table.\nData-Driven Models [47, 49]: This approach is designed for the given range of DNN architectures. It first samples DNN models under the given architecture (e.g., VGG or ResNet). Then, the sampled models are run on devices to determine their performance (inference latency or power consumption). Based on the sampled data, a machine learning model can be trained to predict the performance of an unseen DNN model if it fits the given architecture."}, {"title": "2.4. Homogeneous Edge Devices", "content": "Homogeneous edge devices are devices with the same model, which widely exists in AIoT, like the distributed replicas of mobile phones labeled as the same SKU. Existing hardware-aware DNN compression methods always assume that those devices have exactly the same ability, which is not true in reality. Prior study [1, 14, 45] indicates that running the same DNN model on homogeneous edge devices will lead to substantial variability in performance, where power consumption can vary by 10% to 40%, and runtime differences ranging from 6% to 20% [1]. This means the existing hardware-aware DNN compression can get misleading feedback from the edge and can not guarantee a good compressed model. In this paper, HDAP proposes a new way to identify the differences among homogeneous devices by clustering and can effectively compress DNN model in the scenario."}, {"title": "3. Methodology", "content": "In this section, we present our HDAP method, designed for DNN deployment on homogeneous edge devices. In HDAP, We first formalize the task of DNN compression on homogeneous devices as an optimization problem, and then we use a population-based algorithm to solve the problem for the best pruned DNN model. To reduce the number of devices to evaluate, HDAP proposes the idea of clustering devices into several types where the number of types is much smaller. To accelerate the hardware-aware evaluation on devices, HDAP uses a data-driven approach to build surrogate models for evaluation instead of direct hardware evaluation in real-time."}, {"title": "3.1. Problem Formulation", "content": "In the environment of homogeneous edge devices, the abilities of devices appear significantly different due to user configurations, environmental conditions, or manufacturing variances. These differences pose a substantial challenge for deploying DNN models consistently across all devices. Our objective is to find a compressed DNN model M* that minimizes the average inference latency across all devices while satisfying an accuracy constraint.\nGiven a pre-trained DNN model M with L + 1 layers, we apply a structured pruning operator P to obtain a compressed DNN model $M' = P(M, X)$, where $X = [x_1,...,x_l,...,x_L]$ with $x_l \\in [0, 1)$ represents the pruning rates for all the DNN weights. The structured pruning operator P(\u00b7) prunes the model according to the pruning vector X, removing filters or neurons based on their importance quantified by the $L_2$ norm. Let $C = \\{1, ..., N\\}$ denote the set of homogeneous edge devices. The average inference latency across all devices can be formulated as:\n$\\overline{f(M')} = \\frac{1}{N}\\sum_{i=1}^{N}f_i(M'),$ (1)\nwhere $f_i(M')$ denotes the inference latency of M' on device i.\nHowever, the calculation of Eq. (1) is impractical when N is very large. Because it requires all the devices to run all the candidate compressed DNN models sequentially, which is technically very difficult for edge devices with poor network and computational resources. Specifically, edge devices are distributed everywhere, and no stable network connections can be guaranteed, so it is hard to get the value of $f_i(\u00b7)$ from device i in time. Except the communication issue, edge devices with limited computational resources may not execute the candidate DNN models in a reasonable time, which means the whole evaluation time may be infeasible for users.\nIn Eq. (1), the latency values of the compressed model M' is derived by each edge device, as shown in Fig. 2a. As mentioned above, it is challenging to implement for homogeneous edge devices. The commonly used approach by existing hardware-aware DNN compression is using a unified latency evaluation, as shown in Fig. 2b, which ignores the differences among homogeneous devices. Obviously, this approach introduces significant noise since the performances of M' oscillate in the homogeneous scenario, making it difficult to ensure that the compressed model performs well on all devices."}, {"title": "3.2. Method Overview", "content": "To address the optimization problem in Eq. (6), we propose HDAP, a method designed for efficient DNN compression in homogeneous edge devices. As illustrated in Fig. 3, HDAP comprises two main components: (1) iterative pruning and fine-tuning, and (2) surrogate-based evaluation."}, {"title": "3.3. Surrogate-based Evaluation", "content": "Unsupervised Device Clustering. Given a set of homogeneous edge devices C, HDAP applies a clustering algorithm to partition C into K device clusters, as shown in Eq. (2). To achieve this, HDAP first deploys the pre-trained DNN model M on each device i, obtaining the latency $f_i(M)$ for each device. This yields N latency values across all devices, which serve as input features for the clustering algorithm, which is DBSCAN [35] in the implementation of HDAP. By clustering devices with similar performance, HDAP significantly reduces the number of evaluations required.\nSupervised Learning for Surrogates. For each device cluster $C_k$, we construct a surrogate model $g_k(\u00b7; \u03b8)$ to predict the inference latency $g_k(M')$ of the pruned model $M'$ within that cluster. To gather training data, we first sample various pruning vectors concerning the value range of X and apply them to the original model M, generating a series of pruned models, e.g., $M' = P(M, X)$. Next, each pruned model M' is deployed on all devices within the cluster $C_k$, where we evaluate the inference latency $f_i(M')$ for each device $i \u2208 C_k$. The latency $g_k(M')$ of M' on cluster $C_k$ is then computed as the average latency across all devices in the cluster, as follows:\n$g_k(M') = \\frac{1}{|C_k|}\\sum_{i \\in C_k}f_i(M').$ (7)\nThis latency, $g_k(M')$, serves as the prediction target for supervised learning. To map the pruning vector X to the latency $g_k(M')$, we train a Gradient Boosting Regression Tree (GBRT) [12] model $g(\u00b7; \u03b8)$ for each cluster $C_k$, using the objective function in Eq. (4). By targeting the average latency in each cluster, the surrogate model effectively captures the typical performance of devices in that cluster."}, {"title": "3.4. Iterative Pruning and Fine-tuning", "content": "HDAP employs an iterative process for the final pruned model, as illustrated in Fig. 3. In iteration $t \u2208 \\{1, ..., T\\}$, We utilize a population-based pruning strategy guided by the NCS [39] to solve Eq. (6) for the best-pruned model. Then, the best-pruned model will fine-tuned by retraining. The implementation details can be found in Appendix A.\nIn population-based pruning, the reference model M is first encoded as a vector of pruning rates equal to 0, which is $X_1 = \\{0,...,0\\}$. Based on $X_1$, the adopted evolutionary strategy will generate new individuals $X_2, ..., X_n$ by search operators like mutation or crossover. Here, each vector of $X_i, i \u2208 \\{1, ..., n\\}$ represents a candidate pruned DNN model with respect to the pruning operator P. The fitness of each candidate model M' is evaluated based on its latency and accuracy. Specifically, the fitness function is defined as:\n$\\begin{cases} f(M'), & \\text{if } Acc(M') > \\alpha Acc(M), \\\\ f(M') + \\frac{1 - \\frac{Acc(M')}{Acc(M)}}{1-\\alpha}, & \\text{if } Acc(M') < \\alpha Acc(M), \\end{cases}$ (8)\nwhere $f(M')$ is defined in Eq. (6), Acc(M') is the accuracy of the pruned model on a validation set, and \u03b1 is the acceptable accuracy threshold. This fitness function prioritizes candidates that meet the accuracy requirement, penalizing those that do not. Once the fitness values of $X_i$ are calculated, the adopted evolutionary strategy will generate a set of new candidates as the new set of candidate $X_1, ..., X_n$. The loop will continue for a given number of generations, and the individual with the best fitness value will selected as X in iteration t. By applying the pruning operator P, we can get the best-pruned model $M'^* = P(M, X)$. As DNN pruning hurts the model accuracy, $M_t^*$ is then retrained on the training set for a while, and the retrained model is treated as the new reference model M to be pruned in iteration t + 1."}, {"title": "4. Experiment", "content": "In this section, we demonstrate the effectiveness of the proposed HDAP through extensive experiments. We first present results on ImageNet using ResNet50 and MobileNetV1 to demonstrate HDAP's performance, compared with the state-of-the-art methods. We then study three surrogate model construction methods, highlighting the superiority of our clustering-based approach. An ablation study on CIFAR-10 with ResNet56 and VGG16 examines the impact of surrogate-based evaluation versus hardware-aware evaluation on compression results. Finally, we verify the acceleration benefits of surrogate-based evaluation. We introduce the details of experimental setup in Appendix B."}, {"title": "4.1. Setup", "content": "Datasets and DNN models. We use ResNet50 [15] and MobileNetV1 [20] on the ImageNet dataset [33] for large-scale compression evaluations. For the ablation study, we use ResNet56 [15] and VGG16 [37] trained on CIFAR-10 dataset [21].\nHomogeneous Edge Devices. We use 10 NVIDIA Jetson Xavier NX devices, each configured with the same software environment.\nEvaluation Metrics. We report the Top-1 accuracy, FLOPs, and average inference latency, along with the latency speedup across device clusters. Latency speedup is calculated as the ratio of the baseline DNN model's latency to that of the compressed model. The measurements are averaged over 10 runs using a batch size of 16. Surrogate accuracy is evaluated using Mean Absolute Percentage Error (MAPE) [5].\nHDAP Settings. For HDAP, we set T = 20 and an accuracy ratio of \u03b1 = 0.5 across all experiments. During fine-tuning, we use the SGD optimizer with a momentum of 0.9, training for 90 epochs with an initial learning rate of 0.01, reduced by a factor of 10 every 30 epochs. The weight decay is $1 \u00d7 10^{-4}$ for ImageNet and $5 \u00d7 10^{-4}$ for CIFAR-10."}, {"title": "4.2. ResNet50 Compression", "content": "We evaluate HDAP on ResNet50 with the ImageNet dataset, demonstrating its effectiveness across three FLOPs constraints. As shown in Tab. 1, HDAP consistently achieves the lowest average inference latency across all device clusters, outperforming other methods at each computational budget (3.0G, 2.0G, and especially 1.0G FLOPs). Notably, at 3.0G FLOPs, HDAP achieves a significant 1.24\u00d7 speedup; at 2.0G FLOPs, it achieves a 1.69\u00d7 speedup; and at 1.0G FLOPs, it delivers an impressive 2.86\u00d7 speedup, making it especially valuable for latency-sensitive applications. Furthermore, HDAP maintains competitive accuracy, achieving an optimal balance between latency reduction and the model's accuracy. The latency distributions across device clusters, shown in Fig. 4, indicate that HDAP achieves the lowest maximum and minimum latencies among all methods. This result highlights HDAP's effectiveness in delivering consistently low latency across devices, addressing the performance difference among homogeneous edge devices, and optimizing the inference latency. These qualities make HDAP particularly well-suited for DNN deployment across homogeneous edge devices."}, {"title": "4.3. MobileNetV1 Compression", "content": "To further validate HDAP's effectiveness on lightweight models, we apply our method to MobileNetV1 using the ImageNet dataset. The results, summarized in Tab. 2, demonstrate HDAP's consistent performance in reducing latency across all device clusters. Specifically, HDAP achieves an average inference latency of 42.54 ms, yielding a speedup of 1.67\u00d7 over the unpruned baseline, which surpasses both MetaPruning (1.49\u00d7) and AMC (1.48\u00d7). This substantial latency reduction underscores HDAP's superiority in optimizing inference latency for DNN deployment across homogeneous edge devices. While the Top-1 accuracy of HDAP (70.22%) is slightly lower than MetaPruning (70.90%) and AMC (70.50%), the trade-off remains favorable for latency-sensitive applications where consistent performance across devices is essential."}, {"title": "4.4. Surrogate Model Evaluation", "content": "We evaluate our clustering-based approach against two surrogate model construction methods illustrated in Fig. 2. The evaluation spans four network DNN models (MobileNetV1, ResNet50, ResNet56, and VGG16), using mean absolute percentage error (MAPE) between predicted and actual inference latency as the performance metric. Fig. 5 illustrates the comparison of the surrogate model's accuracy for the different construction methods on the four DNN Models. The results show that our clustering-based method achieves prediction accuracy close to the Per-device method, while significantly outperforming the Unified method across four DNN Models. In particular, the clustering-based method consistently surpasses the Unified method. By grouping devices based on their performance, it more effectively captures performance differences in homogeneous edge devices, which the Unified method overlooks. While the Per-device method offers the lowest prediction error, it requires evaluating latency on each device, which is impractical as mentioned in Sec. 3.1. In contrast, our clustering-based method only requires one device per cluster to have a stable network connection for latency evaluation, making this approach well-suited for edge scenarios. This makes it a practical choice for real-world applications."}, {"title": "4.5. Ablation Study", "content": "We conduct an ablation study on CIFAR-10 with ResNet56 and VGG16, using grid search with the real hardware devices (\"Hardware\") and the surrogate models (\"Surrogate\") to evaluate candidate pruning vectors, as shown in Tab. 3. For ResNet56, the baseline model achieves 93.5% accuracy with 125.75M FLOPs and a latency of 19.93 ms. Using hardware evaluations, the compressed model achieves 91.66% accuracy, 44.54M FLOPs, and a latency of 18.37 ms, resulting in a speedup of 1.08\u00d7. Surrogate-based evaluation yields similar results, with 91.42% accuracy, 44.12M FLOPs, and 18.57 ms latency, demonstrating the effectiveness of surrogate models in guiding pruning with minimal deviation from hardware-based results. For VGG16, surrogate-based evaluation not only preserves comparable latency improvements but also achieves a higher accuracy (90.65%) than hardware evaluation (88.76%) at a similar speedup (6.38\u00d7 vs. 6.63\u00d7). These results validate that surrogate-based evaluation can substitute time-consuming hardware evaluation, effectively guiding the pruning process with only a slight compromise in the quality of the compressed model."}, {"title": "4.6. Acceleration of Surrogate-based Evaluation", "content": "The results in Tab. 4 highlight the significant acceleration achieved by surrogate-based evaluation compared to the hardware-aware evaluation across four target models. Specifically, for ResNet56, the surrogate-based evaluation achieves a remarkable acceleration of $1.28 \u00d7 10^4$ over hardware-aware evaluation, with even higher accelerations observed for VGG16 ($3.14 \u00d7 10^6$), MobileNetV1 ($2.65 \u00d7 10^7$), and ResNet50 ($1.36 \u00d7 10^7$). These results underscore the efficiency of surrogate-based evaluation, especially for more complex models like MobileNetV1 and ResNet50, where evaluating latency directly on hardware is time-consuming. The acceleration from surrogate-based evaluation enables rapid pruning and tuning in large-scale DNN model searches, making it an effective tool for optimizing performance across homogeneous edge devices."}, {"title": "5. Conclusion", "content": "We introduce HDAP, a hardware-aware DNN compression framework designed to address performance differences across homogeneous edge devices. By clustering devices with similar performance and utilizing surrogate-based evaluation, HDAP significantly accelerates the evaluation process. The effectiveness of HDAP is further demonstrated through experimental results on ResNet50 and MobileNetV1, where it consistently outperforms state-of-the-art methods in terms of average latency across homogeneous edge devices while maintaining competitive accuracy. These results highlight HDAP as a highly effective solution for DNN deployment on homogeneous edge devices, showcasing its practicality for real-world, latency-sensitive applications."}]}