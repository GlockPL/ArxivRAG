{"title": "MCTS-SQL: An Effective Framework for Text-to-SQL with Monte Carlo Tree Search", "authors": ["Shuozhi Yuan", "Liming Chen", "Miaomiao Yuan", "Jin Zhao", "Haoran Peng", "Wenming Guo"], "abstract": "Text-to-SQL is a fundamental and longstanding problem in the NLP area, aiming at converting natural language queries into SQL, enabling non-expert users to operate databases. Recent advances in LLM have greatly improved text-to-SQL performance. However, challenges persist, especially when dealing with complex user queries. Current approaches (e.g., COT prompting and multi-agent frameworks) rely on the ability of models to plan and generate SQL autonomously, but controlling performance remains difficult. In addition, LLMs are still prone to hallucinations. To alleviate these challenges, we designed a novel MCTS-SQL to guide SQL generation iteratively. The approach generates SQL queries through Monte Carlo Tree Search (MCTS) and a heuristic self-refinement mechanism are used to enhance accuracy and reliability. Key components include a schema selector for extracting relevant information and an MCTS-based generator for iterative query refinement. Experimental results from the SPIDER and BIRD benchmarks show that MCTS-SQL achieves state-of-the-art performance. Specifically, on the BIRD development dataset, MCTS-SQL achieves an Execution (EX) accuracy of 69.40% using GPT-40 as the base model and a significant improvement when dealing with challenging tasks, with an EX of 51.48%, which is 3.41% higher than the existing method.", "sections": [{"title": "1 Introduction", "content": "Text-to-SQL aims at converting natural language queries to SQL, which plays a critical role in data analytics and supports a wide range of applications (e.g., business intelligence and automated reporting). Recent advances in LLM have significantly improved the accuracy and stability of text-to-s SQL systems.\nHowever, real-world Text-to-SQL applications face with significant challenges, mainly due to user queries' random, often ambiguous nature (as seen in Figure 1). Text-to-SQL is challenging for three main reasons. First, natural language has ambiguous expressions and rich semantics, making it hard to map them to specific database tables and fields. Second, extracting meaningful information from natural language requires strong understanding capabilities. Lastly, generating accurate SQL queries that meet often vague requirements demands both semantic understanding and syntactic precision.\nTo tackle these challenges, existing algorithms have employed various strategies, typically falling into categories such as rule-based methods[Kang et al., 2012; Hammami et al., 2021], sequence-to-sequence models[Zhong et al., 2017; Katsogiannis-Meimarakis and Koutrika, 2021], and pre-trained language models[Katsogiannis-Meimarakis and Koutrika, 2023; Guo and Gao, 2019]. Early Text-to-SQL systems relied on rule-based approaches, which employed handcrafted grammar rules and heuristics. Subsequently, sequence-to-sequence models and pre-trained language models were introduced, enabling more accurate and flexible SQL generation. In the past three years, the advent of LLMs has significantly advanced Text-to-SQL, particularly in zero-shot and few-shot settings where models can generate SQL without extensive training examples.Despite these advancements,"}, {"title": "2 Related Work", "content": "In this section, we provide an overview of related work on Text-to-SQL and Monte Carlo Tree Search, highlighting their relevance and main differences to our proposed research."}, {"title": "2.1 Text-to-SQL", "content": "Text-to-SQL aims to bridge natural language queries and structured database queries. Due to its complexity, numerous approaches are proposed to address its challenges. Early systems, such as LUNAR[Kang et al., 2012] and NaLIX[Hammami et al., 2021], employed rule-based methods that manually crafted grammar rules and heuristics. However, these approaches are highly domain-specific, and generalization performance across different tasks or databases is difficult to guarantee.\nThe deep learning marked a turning point for Text-to-SQL. End-to-end models like Seq2SQL[Zhong et al., 2017] and SQLNet[Katsogiannis-Meimarakis and Koutrika, 2021] directly mapped natural language to SQL but struggled with complex queries, especially those involving nested structures or intricate reasoning. Pre-trained Language Models (PLMs), such as TaBERT[Katsogiannis-Meimarakis and Koutrika, 2023] and BERT-SQL[Guo and Gao, 2019], enhance cross-domain generalization and improve the accuracy of SQL generation. However, handling complex user queries and achieving powerful cross-domain performance remain significant challenges.\nRecently, Large Language Models (LLMs) such as GPT-4[Achiam et al., 2023], Palm-2[Anil et al., 2023], and LLAMA [Touvron et al., 2023] have revolutionized Text-to-SQL tasks. These models excel in zero-shot and few-shot settings due to extensive pretraining and advanced reasoning capabilities. [Lee et al., 2024; Talaei et al., 2024; Alp Cafero\u011flu and Ulusoy, 2024] Techniques like DAIL-SQL[Gao et al., 2023] optimized prompt ngineering, focusing on question representation, prompt structure, and example selection to enhance SQL accuracy with minimal supervision. Frameworks like C3-SQL[Dong et al., 2023], DIN-SQL [Pourreza and Rafiei, 2024], and StructGPT[Jiang et al., 2023] further advanced the field by addressing complex queries through database simplification, query decomposition, and structured data access. Additionally, MAC-SQL[Wang et al., 2024] introduced a collaborative framework integrating decomposer, auxiliary selector, and refiner modules for iterative SQL refinement.\nFrom the analysis of existing methods, it is evident that advancing Text-to-SQL hinges on improving models' ability to reason through complex scenarios. Current approaches often rely on basic COT strategies or multi agent framework to autonomously plan, yet they suffer from hallucination issues. To address this, our work integrates Monte Carlo Tree Search to enhance models' comprehension of ambiguous table structures and queries, significantly improving SQL generation accuracy."}, {"title": "2.2 Monte Carlo Tree Search", "content": "MCTS is a widely used tool for planning complex problems, and a large number of downstream experiments have demonstrated its effectiveness. For example, [Pitanov et al., 2023]"}, {"title": "3 Preliminaries", "content": "This section provides the necessary preliminaries and notations for understanding the proposed framework. We start with a concise overview of the Text-to-SQL task, highlighting its relevance to our approach, and then introduce the fundamental concepts of Monte Carlo Tree Search."}, {"title": "3.1 Definition of Text-to-SQL", "content": "Let X = (Q, S, K) represent the input to the Text-to-SQL task, where Q is a natural language question, S is the database schema, and K optionally incorporates external knowledge to enhance contextual understanding. The database schema S consists of a set of tables T = T1, T2, \u2026\u2026\u2026,T|T and their associated columns C = C1, C2, ..., C|c|. Each column Ci is defined within a specific table Tj, providing structural and semantic information crucial for SQL generation. The goal of the Text-to-SQL task is to generate an SQL query Y that precisely captures the semantic intent of the natural language questionQ while adhering to the structural constraints of the schema S."}, {"title": "3.2 Review of MCTS", "content": "Monte Carlo Tree Search is a fundamental tool widely used in game AI and complex planning making. It builds search trees, estimates action values through simulation, and solves complex problems step-by-step through continuous exploration. The algorithm relies on the Upper Confidence bounds for Trees(UCT) to optimize decision efficiency and consists of four key phases: selection, expansion, simulation, and back-propagation.\nIn the selection phase, the algorithm starts at the root and iteratively selects child nodes based on the UCT until reaching a leaf node. During expansion, if the leaf node is non-terminal, one or more child nodes are added to explore potential future actions. The simulation phase evaluates the newly added nodes by performing stochastic simulations to a terminal state. Finally, in backpropagation, the simulation results results are propagated back through the tree, updating the values of visited nodes and improving future decision-making."}, {"title": "4 MCTS-SQL Framework", "content": "As shown in Figure 2, the MCTS-SQL framework consists of three key components: the Selector, Direct Generator, and MCTS-Refiner. The Selector identifies relevant tables and schema elements based on the user query, while the Direct Generator quickly produces an initial SQL query. Queries that fail or yield errors are refined by the MCTS-Refiner through iterative tree search. A detailed explanation of each component is provided in the subsequent section.\nThe collaboration process of our MCTS-SQL is presented in Algorithm 1:"}, {"title": "4.1 Schema", "content": "Combining the database schema information in the prompt is essential for enabling the LLM to comprehend the database structure accurately and generate precise queries. This paper presents a novel method that illustrates the hierarchical relationships between databases, tables, and columns using a semi-structured format.\nTo be specific, we provide the table name and corresponding description for each table(which can be omitted if not necessary). The table information is converted into a list where each entry is a tuple containing a column of details. Each column includes the name, data type, description, and example values, thus providing a comprehensive view of its contents. In addition, foreign keys must be included to represent the relationships between tables accurately. Understanding hierarchical relationships is critical for query generation. An example of proposed schema format is shown in Figure 3."}, {"title": "4.2 Selector", "content": "The role of the Selector can be formally described as follows. Given an input triplet X = (Q, S, K), where Q is the query, S = T,C is the database schema consisting of tables (T) and columns (C), and K denotes the knowledge provided. The Selector aims to identify a minimal subset of tables and columns, denoted as S' = T', C', which are necessary to answer the query Q. The behavior of the Selector is formally defined as follows:\n$S' = f_{Selector}(Q, S, K | M)$\nWhere $f_{Selector}( | M)$ represents the Selector's function, implemented via prompt engineering powered by a large language model M.\nThe design of the Selector is motivated by two key considerations: (i) Including unnecessary schema elements in the prompt increases the risk of irrelevant or extraneous items being incorporated into the generated SQL, which can degrade output quality; (ii) Directly utilizing the entire database schema may result in excessively long prompts, which could lead to higher computational costs and potentially exceed the input length limitations of the language model."}, {"title": "4.3 Generator", "content": "To balance accuracy and efficiency in Text-to-SQL, we introduce a fast-slow thinking mechanism consisting of a Direct Generator and an MCTS-Refiner. Initially, the user's input is processed by the Direct Generator, which leverages COT in one prompt to generate SQL queries rapidly. If the executor successfully executes the SQL and the LLM confirms it meets the user's intent, the result is immediately returned. If an error occurs or the LLM thinks the output is insufficient, the MCTS-Refiner iterative optimization is based on the error feedback and self-criticism. Once reaching the maximum of iterations, the SQL with the highest evaluation value is selected and provided."}, {"title": "A. Direct Generator", "content": "The purpose of the Direct Generator is to generate SQL queries directly within a single step through an end-to-end process. It can be described as follows, where R represents the generated SQL query.\n$R = f_{Direct Generator}(Q, S', K | M)$\nAfter the SQL is generated, it follows two steps of evaluation. First, an executor checks its syntactic correctness and successful execution. Then, an LLM verifies if the SQL meets the user's requirements. The LLM-based verifier can be formalized as:\n$V = f_{verifier}(R, Q, S', K | M)$\nSpecifically, the Direct Generator employs chain-of-thought (COT) prompting, which is proven effective during SQL generation. The Selector provides a selected subset of tables and columns to minimize confusing information during the generation. And the user's query is added to the same prompt. The LLM processes this input to generate SQL queries, accompanied by a detailed rationale.\nAdditionally, we employ a few-shot learning strategy, using several in-context examples to improve the LLM's understanding of task-specific instructions and enhance its generalization capabilities."}, {"title": "B. MCTS-Refiner", "content": "The MCTS-Refiner aims to refine SQL queries using execution errors, and the self-critique mechanism is adopted to optimize the query iteratively. The main workflow of the proposed method consists of several stages, detailed as follows:\nInitialization: The root node is initialized with the suboptimal SQL generated by the Direct Generator as a reference for step-by-step optimization to reduce the complexity of the search process.\nSelection: Following the existing practices, we define a function P to rank all generated SQL queries that are not fully expanded. The node with the highest value is selected for further refinement. The function P of a node a can be defined as follows, where ra represents the set of results associated with node a.\n$P(a) = \\frac{1}{2}(min r_a + \\frac{1}{|r_a|} \\sum_{i=1}^{|r_a|} r_i)$\nSelf-Refine: The SQL query a is initially executed by the executor to get the error information Ea, which is then used to refine the query through the self-refine framework. In this process, the LLM generates a critique c, serving as the guidance for refining the query and producing an improved SQL query a'. Specifically, Ea represents the error details related to the initial SQL query a, and I denotes the prompt used in the Direct Generator, which includes the input query Q, the database schema S', and relevant knowledge K. The details can be formally described as follows:\n$c = f_{Critiquer}(a, E_a, I | M)$\n$a' = f_{Refiner}(a, c, E_a, I | M)$\nThe Self-refine module designed a refinement mechanism using error feedback and critique generation to enhance the accuracy and robustness of SQL queries.\nSelf-Evaluation: The refined SQL query is evaluated to obtain a reward value, denoted as r, and its corresponding P-value is computed. To be specific, we proposed a model-based self-reward feedback mechanism, with the reward value constrained within the range of -95 to 95. To ensure the reliability and fairness, the highest scores are deliberately suppressed. The reward r is formally defined as:\n$r_a = f_{evaluater}(a', E_a', I | M)$\nBackpropagation: The value r of the refined SQL query is backpropagated through the search tree, updating the value information of the parent node and other relevant nodes. If the P-value of any child node is changed, the corresponding P-value of its parent node is recalculated accordingly. The process can be described as follows:\n$P'(a) = \\frac{1}{2} (P(a) + max_{i \\in Children(a)} P(i))$\nUCT update: After updating the P values for all nodes, we choose the UCT function to measure the combined value of each node, which is used as an important basis for expansion in the next selection stage. The UCT value of a node a is formally defined as:\n$UCT_a = P(a) + c_1 \\sqrt{\\frac{ln N(Father(a)) + 1}{N(a) + \\epsilon}}$\nIn this formulation, N(.) denotes the total number of visits to a given node, and c is a constant that balances the trade-off between P-value and visit times. The term e is a small constant to prevent division by zero.\nThe algorithm proceeds through all these steps iteratively until the maximum rollout numbers are reached. And the SQL querie with the highest score r is chosen as the final output."}, {"title": "5 Experiments", "content": "To evaluate the performance of our MCTS-SQL, we present the implementation details, explain the experiments performed, and offer a thorough analysis of the results."}, {"title": "5.1 Datasets", "content": "We evaluate our MCTS-SQL framework using two NL2SQL benchmarks: Spider and BIRD. The Spider contains 7000 training question-query pairs and 1038 development pairs, which are from 200 different databases across 138 domains. In this study, we only concentrate on the development set. In contrast, BIRD includes 95 large-scale databases with high-quality Text-to-SQL pairs, covering 37 specialized domains. Unlike Spider, BIRD focuses on real-world database content and provides external knowledge reasoning to bridge natural language queries and database contextual information."}, {"title": "5.2 Evaluation Metrics", "content": "To evaluate our proposed method's performance, we use two metrics: Execution Accuracy(EX) and Valid Efficiency Score(VES). The Execution Accuracy(EX) calculates the percentage of queries where the predicted SQL queries match the correct SQL queries when executed. Valid Efficiency Score(VES) measures the percentage of predicted SQL queries that output sets consisting of the results from the ground-truth SQL queries."}, {"title": "5.3 Base Models", "content": "In this paper, we utilized the latest models, GPT-40-mini and GPt-40, as the base models for our conducted experiments. Most of our ablation studies experiments are carried out with GPT-40-mini, which offers a nearly 30% cost reduction compared to GPT-40. Despite this, GPT-40-mini proved to be more effective, offering a powerful balance between performance and cost. In future works, we will explore other models and fine-tune an open-source LLM."}, {"title": "5.4 Hyper-parameters", "content": "In order to ensure the stability of our experiment results, we standardized the hyper-parameters as follows. The temperature is fixed at 0.0, the top-p parameter is set to 1.0, and the max-token length is 32168. As for the hyper-parameters in the MCTS-Refiners, the child nodes of a node are set to 2, and the max-rollout numbers are 5."}, {"title": "5.5 Results", "content": "A. BIRD Results\nIn Table 1, we present the comparison of our method's performance on the BIRD against existing approaches. Our proposed MCTS-SQL achieves the highest performance with 69.40% for dev EX and 66.24% for dev VES, demonstrating its superiority over other methods. Even when using the more cost-effective model GPT-40-mini, our method still performs well, with scores of 63.15% and 60.78%. This highlights the effectiveness of our approach, which can achieve competitive results even with a lighter model.\nThe detailed performance of different complexity levels is shown in Table 2. The results show a notable improvement. Based on the GPT-40, the EX of the simple subset is 74.32%, the moderate subset is 65.17%, and a challenging subset is 51.48%. Analyzing the results, we can find a great outperforming of challenging sets, mainly due to the MCTS-based refiner, which is an important aspect of handling real-world applications."}, {"title": "B. Spider Results", "content": "Table 3 shows the performance comparison on the Spider dataset. Our MCTS-SQL achieves excellent results with 88.71% on the development set and 86.63% on the test set. We can see that existing work has achieved outstanding performance; even in this situation, our work still performs remarkably well."}, {"title": "5.6 Ablation study", "content": "We conducted an ablation study to analyze the impact of three of our proposed components-Schema, Selector, and MCTS-Refiner. The results, shown in Table 4, highlight the importance of each module in the MCTS-SQL. To reduce costs, we use GPT-40-mini as the base model. Specifically, removing the carefully designed Schema and using a normal DDL slightly reduces performance. The Selector is more important, especially on both moderate and challenging subsets. The most significant decrease occurs when the MCTS-Refiner is removed, demonstrating its critical role in solving challenging conditions. All these tricks boost the system's effectiveness in the NL2SQL task and can be transferred to other relevant problems.\nIn this paper, we use the Monte Carlo Tree Search to enhance the model's performance, and the number of child nodes and max-rollouts are two hyper-parameters."}, {"title": "6 Discussion", "content": "Figure 5 shows an example of normal COT and MCTS-SQL to solve the same user's query. Through the error analysis, we can find that the syntax and structure generated by the COT are generally correct, but due to the hallucination of LLM, it struggles with detailed information and complex constraints. The feedback and iterative optimization mechanism of MCTS helps reduce errors caused by these details, thus improving the performance of SQL generation."}, {"title": "7 Conclusion", "content": "In conclusion, this paper introduces MCTS-SQL, a novel framework that utilizes the Monte Carlo Tree Search to enhance the LLMs to address challenges in Text-to-SQL tasks. Experimental results from the Spider and BIRD demonstrate the significant advantages of our method, achieving state-of-the-art performance, especially in challenging queries. Specifically, we achieve an EX 69.40% on the BIRD with 51.48% on the challenging set, outperforming existing method by 3.41%. These results show the potential of MCTS-SQL for real-world database applications. However, the MCTS uses multiple iterations which inevitable increases token consumption and time. In the future work, we will explore some methods to solve the constrain."}]}