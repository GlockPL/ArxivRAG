{"title": "AutoPETIII: The Tracer Frontier\nWhat frontier ?", "authors": ["Zacharia Mesbah", "Leo Mottay", "Romain Modzelewski", "Pierre Decazes", "S\u00e9bastien Hapdey", "Su Ruan", "Sebastien Thureau"], "abstract": "For the last three years, the AutoPET competition gathered\nthe medical imaging community around a hot topic: lesion segmentation\non Positron Emitting Tomography (PET) scans. Each year a different\naspect of the problem is presented; in 2024 the multiplicity of existing\nand used tracers was at the core of the challenge. Specifically, this year's\nedition aims to develop a fully automatic algorithm capable of performing\nlesion segmentation on a PET/CT scan, without knowing the tracer,\nwhich can either be a FDG or PSMA-based tracer. In this paper we\ndescribe how we used the nnUNetv2[1] framework to train two sets of\n6 fold ensembles of models to perform fully automatic PET/CT lesion\nsegmentation as well as a MIP-CNN to choose which set of models to\nuse for segmentation.", "sections": [{"title": "Introduction", "content": "For cancer detection and diagnosis, Positron Emission Tomography (PET) imag-\ning is extremely valuable. It allows to explore specific functions in the body,\nwhich is especially fit for cancer detection since cancer cells are cells exhibiting\nabnormal behavior. PET consists in injecting a radioactive tracer in the patient's\nbody and observing its distribution using the gamma rays it emits.\nTracers are designed to target a specific function of the body. The most com-\nmon, 18F-FluoroDesoxyGlucose (18FDG) is a sugar, which accumulates (i.e. up-\ntakes) in the parts of the body that consume energy (i.e. high-function). The can-\ncer cells, in their uncontrolled reproductive frenzy, need a lot of energy. They're\nusually very visible on PET scans, which makes this imaging modality the key-\nstone of cancer detection and cancer treatment protocols.\nIt is always accompanied by a Computed Tomography (CT) scan, which\nserves for attenuation correction of the PET scan. However, the images from this\nmodality also provide a different, useful information. They show the mapping"}, {"title": "Competition", "content": "This year's edition, AutoPET III challenge aims, just as its predecessors did,\nto build an algorithm capable of delineating cancerous lesions in PET/XCT\nscans. However this year's novelty is the appearance of not only FDG but also\nPSMA PET scans. The catch is that no prior knowledge is given (at test time)\nabout the tracer.\nTo achieve this, participants are given 1014 FDG PET/CT scans and 597\nPSMA PET/CT scans, gathered from two German medical centers:\nUniversity Hospital of T\u00fcbingen (FDG data)\nUniversity Hospital of the LMU in Munich (PSMA data)\nFor each of these studies, two modalities are available, in NifTi format:\nThe Computed Tomography, resampled towards the PET spacing\nThe PET, for which voxel values have been converted to Standardized Up-\ntake Value.\nStudies selected were from patients with lung cancer, lymphoma, melanoma\nor healthy patients for FDG and prostate cancer patients for PSMA."}, {"title": "Our Method", "content": "Windowing We used a CT and PET windowing method. Instead of using a 2\nchannels input to our network, we use 4 channels. The first two channels remain\nthe CT and PET volumes, but the third and fourth channels are clipped versions\nof the CT and PET scans. Precisely:\nThe PET scan is clipped between 0 and 20 SUV\nThe CT scan is clipped between -300 and 400 HU\nThis windowing's goal is to deal with two problems caused by input data\nnormalization:\nBy normalizing between min and max, the values are squashed, which means\nthat slow variations in the image are represented with very similar values\nwhich can in turn make differentiation harder for the network. We normalize\nover a smaller range of values to limit this effect\nFor each patient the maximum value can be different (especially in PETs).\nThis lowers the meaningfulness of the normalized voxel values inputted in the\nnetwork, as it is also dependant on the volume's maximum value. Windowing\nalso reduces this effect by making sure we are in a specific range of values\nSupplementary labels We re-used a method from last year's AutoPET II\ncompetition. The winning team had drastically reduced the amount of false\npositives by adding other anatomical contours to the segmentation. We defined\na list of organs that were interesting for PET segmentation:\nthe brain, heart and aorta: high FDG uptake\nliver, kidneys, urinary bladder: waste clearing activity\nspleen: sometimes very active\ndigestive system, prostate: high PSMA uptake\nskeleton,\nlungs, pancreas: added localization for the remaining organs\nWe used TotalSegmentator [3] to perform segmentation for all of these organs\nusing the CT scans. We had to group some organs together to form broader\nclasses (bones, digestive system, lungs etc...) in order to reduce the computa-\ntional overhead. On top of these organs we added the lesion back with maximum\npriority.\nThis method's goal is to help the network figuring out malignant uptake from\nbenign uptake."}, {"title": "Tracer Discriminator", "content": "Our approach consists in using tracer-specific neural\nnetworks for tumor delineation. However, since the injected radio-tracer is not\ndisclosed alongside volumes, a tracer detection strategy is required. To address\nthis, we use a neural network for tracer discrimination. Its architecture consists\nof six consecutive 2D convolutions layers, followed by five fully connected layers,\nall with ReLU activation and a final sigmoid activation. Initially, the volumes\nare resampled (3x3x3 spacing) and their maximum intensity projection (MIP) is\ncomputed in the coronal plane. Next, a zero-padded 224x224 window is extracted\naround the center of the MIP and fed to our neural network. During training,\nthe model's outputs (predicted tracer types) are compared against ground truth\nusing Binary Cross-Entropy (BCE) as the loss function. Optimization is per-\nformed using AdamW, with an initial learning rate of le-4, over 100 epochs\nwith early stopping to reduce over-fitting. Inference times on the entire dataset,\ntested on an Intel i7-11850H CPU, averages to 2.18 seconds per patient and\n5-folds cross-validation yielded 99.64% accuracy."}, {"title": "Segmentation Networks", "content": "As described earlier, we use two tracer-specific seg-\nmentation networks. Both are trained using the nnUNet framework, with mostly\nunchanged parameters/hyper-parameters. The only change occurred in the set-\nting for the FDG model. Indeed, nnUNet is using the median spacing as a\ntarget spacing for all training data. However, the median (3mmx2mmx2mm)\nspacing for FDG data implied too much inference time as this was limited to\n5 minutes per patient. We chose to replace it by an isotropic larger spacing\n(3.3mmx3.3mmx3.3mm), which allowed us to run a 6 folds ensembling with\nTest-Time Augmentation (TTA) for most patients 5.\nWe then trained the regular 5 folds ensemble with no post-processing for\nboth tracers."}, {"title": "Results", "content": "Our model obtained results that situated us middle of the pack on the prelimi-\nnary test set, which does give us an idea of what our final result will be."}, {"title": "Conclusion", "content": "The key takeaway from our participation in this challenge is that a dataset of\nsuch dimensions makes the training of highly reliable PET lesions segmentation\ndeep learning based tools accessible to researchers in cancer research centers. We\nwill conduct future work, as well as review the others participants' methods to\nattempt developing a robust PET segmentation model.\nSuch a model would alleviate the burden of PET segmentation off the shoul-\nders of physicians, in turn freeing their time to conduct more impactful work."}]}