{"title": "Clinically-Inspired Hierarchical Multi-Label Classification of Chest X-rays with a Penalty-Based Loss Function", "authors": ["Mehrdad Asadi", "Komi Sodok\u00e9", "lan J. Gerard", "Marta Kersten-Oertel"], "abstract": "In this work, we present a novel approach to multi-label chest X-ray (CXR) image classification that enhances clinical interpretability while maintaining a streamlined, single-model, single-run training pipeline. Leveraging the CheXpert dataset and VisualCheXbert-derived labels, we incorporate hierarchical label groupings to capture clinically meaningful relationships between diagnoses. To achieve this, we designed a custom hierarchical binary cross-entropy (HBCE) loss function that enforces label dependencies using either fixed or data-driven penalty types. Our model achieved a mean area under the receiver operating characteristic curve (AUROC) of 0.903 on the test set. Additionally, we provide visual explanations and uncertainty estimations to further enhance model interpretability. All code, model configurations, and experiment details are made available.", "sections": [{"title": "I. INTRODUCTION", "content": "In the field of medical imaging, multi-label classification is important for diagnosing a wide range of conditions from an image set, especially in 2D radiographic modalities like chest X-rays (CXR). CXR analysis poses unique challenges due to the complex and overlapping nature of thoracic diseases, where capturing clinically meaningful label dependencies is important to improve diagnostic reliability and efficiently rule in or out diagnoses that may require urgent intervention.\nLung pathologies remain one of the leading causes of morbidity and mortality worldwide [1], highlighting the significant role of accurate and timely radiographic interpretation. However, diagnostic variability persists due to differences in radiologists' experience and expertise, leading to inconsistent interpretations, particularly in subtle or complex cases. In addition, long working hours can impair concentration, increasing the likelihood of diagnostic errors [2]. The increasing demand for imaging studies, coupled with a global shortage of trained radiologists, particularly in low-resource settings, has significantly increased radiology workloads [3]. This strain often results in delays in diagnosis, where heavy workloads and resource constraints compromise timely interpretation, negatively impacting clinical outcomes. Despite the advancement of Deep Learning (DL) techniques, many current approaches struggle to incorporate clinical hierarchies effectively. This limitation is particularly evident in hierarchical classification models that do not sufficiently leverage clinical insights through penalties or relationships between parent and child labels, thus limiting both interpretability and performance.\nTo address these challenges, we introduce a hierarchical multi-label classification framework for CXRs, which organizes clinically related labels into parent-child relationships. In this framework, we propose a novel hierarchical binary cross-entropy (HBCE) loss function that applies penalties when child labels are predicted as positive without corresponding positive predictions for their parent labels. To optimize the effectiveness of this loss function, we explore two key penalty strategies: a fixed penalty approach and a data-driven penalty method. The data-driven method adjusts the penalty based on the likelihood of parent-child label dependencies, with a range of scale factors to fine-tune the impact of the penalty according to the strength of these relationships.\nThe primary objective of this work is to improve the clinical interpretability of CXR classifications by using hierarchical groupings that mirror clinical decision-making processes: often, the most dangerous and/or life-threatening diagnoses that require immediate and urgent intervention must be ruled out before further workup for less severe diagnoses is performed. While a CXR provides less information than three-dimensional tomographic imaging, they are a fundamental tool used in many inpatient hospital settings due to the portability of imaging units. Many severely ill and unstable patients often undergo a CXR in their hospital bed before more complex imaging is performed to minimize the risk of unnecessary manipulation that could decompensate their fragile health status. These CXRs are often reviewed by non-radiology trained medical professionals and can be challenging to interpret. By introducing a custom hierarchical loss function we aim to improve the model performance and explainability for transparency on diagnosis determination. By systematically evaluating the hierarchy and penalty types, we comprehensively analyze their effects on predictive performance. We demonstrate the practical benefits of leveraging clinical insights for accurate and interpretable multi-label classification.\nThe proposed framework achieved a weighted AUROC of 0.9034 on the CheXpert dataset using a single-model, single-run pipeline, showing the efficacy of the hierarchical structure and the custom HBCE loss function. Data-driven penalties showed the potential to improve predictive accuracy, while visual explanations and uncertainty estimations enhanced model interpretability and transparency.\nTo promote transparency and reproducibility, all code, model configurations, and experiment details have been made available in a public Git repository: CIHMLC."}, {"title": "II. RELATED WORK", "content": "Multi-label classification plays an important role in analyzing CXRs, particularly when handling a diverse range of pathologies that overlap or present concurrently. Prior studies have focused on improving the performance of such models. For example, Wang et al. [9] introduced CXR\u00d7MLAGCPL, a multi-label classification model for CXRs that leverages both local label correlations and global co-occurrence patterns for improved disease prediction. The model captures nuanced inter-pathological patterns by combining a Local Awareness Module (LAM) for image-specific label dependencies and a Global Co-occurrence Priori Learning (GCPL) module for dataset-wide label relationships. Evaluated on large datasets, CXR\u00d7MLAGCPL achieved a good performance on most labels (mean AUROC of 0.805 and 0.810 on all 14 and common 5 classes of the CheXpert [4] dataset respectively), highlighting the benefit of jointly considering local and global dependencies in multi-label medical image classification.\nA similar study by Zhang et al. [10], proposed the Label Correlation Guided Discriminative Label Feature Learning (LCFL) model for CXR classification which uses a self-attention-based Label Correlation Learning (LCL) module to capture global label correlations and a Discriminative Label Feature Learning (DLFL) module for feature enhancement through label-level contrastive learning. This framework allows the model to learn distinctive label-specific features, yielding a mean AUROC score of 0.764 on the CheXpert dataset and U-zeros setting, utilizing both global and local label correlations to guide discriminative feature learning.\nCvTGNet by Lu et al. [11] integrated convolutional and transformer architectures alongside graph-based co-occurrence modeling to enhance the multi-label classification of CXRs. By combining the strengths of Convolutional Vision Transformers for spatial detail extraction and Graph Convolutional Networks for pathological relationship learning, the model effectively captures both image-specific and inter-label dependencies, achieving an overall AUROC score of 0.840 across all 14 CheXpert pathologies."}, {"title": "B. Hierarchical Learning in Medical Imaging", "content": "The use of hierarchical networks has introduced a significant advancement, particularly with the introduction of Hierarchical Multi-Label Classification Networks (HMCN). This architecture represents one of the first attempts to explicitly incorporate hierarchical structures within deep neural network frameworks for multi-label classification [17]. Compared to traditional flat multi-label approaches, HMCNs integrate hierarchical relationships directly into the learning process, leading to accurate predictions that align with the structure of the label space. This is particularly relevant in domains where hierarchical dependencies are naturally present, such as medical imaging, where disease categories often share anatomical or pathological relationships.\nIn work by Chen et al. [18] a two-stage Hierarchical Multi-Label Classification (HMLC) approach is introduced for CXR analysis. It utilizes clinically relevant taxonomies to enhance interpretability and manage incomplete labeling common in medical datasets. The method first trains the model to predict conditional probabilities within the label hierarchy, focusing on sibling categories, before fine-tuning with a numerically stable cross-entropy loss function to derive unconditional probabilities, thereby improving classification stability and performance. Evaluated on the PLCO [21] and PadChest [22] datasets, the approach outperformed traditional flat classifiers and other hierarchical models, achieving the highest AU-ROC (0.887) reported on PLCO and showing resilience to missing labels. This study demonstrates HMLC's utility in producing clinically aligned, interpretable predictions, offering a significant advancement for CXR computer-aided diagnosis (CAD) and suggesting broader applications across hierarchical classification tasks in medical imaging.\nSimilarly, the study by Pham et al. [19] presents a deep learning-based framework for multi-label CXR classification that integrates hierarchical disease dependencies and addresses label uncertainty, advancing upon previous work in the field. By using a conditional training process based on a predefined disease hierarchy, the model learns relationships among parent and child disease labels, allowing it to make clinically consistent predictions. To manage uncertain labels, the authors apply Label Smoothing Regularization (LSR), reducing model overconfidence in cases of label ambiguity. Trained on the CheXpert dataset, their combined Conditional Training (CT) and LSR in the U-zeros setting achieved an AUROC score of 0.884 on the five CheXpert labels. In addition, they evaluated an ensemble of six CNN architectures and achieved an AUROC of 0.940, outperforming prior methods and even surpassing most radiologists on the validation set. Their method highlights the value of incorporating hierarchical relationships and uncertainty handling in improving the interpretability and accuracy of automated CXR analysis.\nHierarchical Multi-Label Classification Networks (HMCNs) and related approaches represent significant advancements by incorporating hierarchical label structures directly into the learning process, leading to clinically interpretable and accurate predictions. Table III presents the results of these studies evaluated on the CheXpert dataset compared to ours."}, {"title": "III. METHODOLOGY", "content": "The proposed method emphasizes enhancing the clinical interpretability and explainability of model predictions while maintaining strong performance on the CheXpert dataset. This highlights a new approach for integrating domain knowledge with DL in a clinically meaningful way. We developed a penalty-based loss function that enforces consistency between child and parent labels, addressing clinically implausible predictions, a feature not commonly seen in traditional dependency models (e.g., those using label co-occurrence or graph convolutional networks). Moreover, while hierarchical models use multi-stage training to refine parent and child label relationships, this study opts for a single-run pipeline, simplifying the process and reducing computational complexity but potentially limiting nuanced adjustments for hierarchical learning."}, {"title": "B. Dataset and Labeling Strategy", "content": "We used the CheXpert dataset, one of the largest publicly available CXR datasets, which consists of over 224,000 CXRs from more than 65,000 patients. CheXpert has become a standard benchmark for multi-label classification in medical imaging due to its diverse range of labeled thoracic pathologies, including atelectasis, cardiomegaly, pulmonary consolidation, pulmonary edema, and pneumonia, among others. This dataset provides annotations derived from radiologist reports using rule-based labelers, specifically VisualCheXbert [5], compared to the CheXpert and CheXbert [6] labelers.\nHowever, directly using these labels poses limitations due to the complex interdependence between the thoracic pathologies. To address this, we introduced hierarchical label groupings where individual pathologies are grouped under newly defined parent categories based on clinical insights. For instance, labels such as Pleural Effusion and Pneumonia, Edema, and Consolidation were grouped under the parent label \u201cFluid Accumulation,\u201d capturing clinical dependencies in the underlying pathologies [27]\u2013[30]. Furthermore, we labeled all instances with neither positive findings nor \"No Finding\" as \u201cUncertain,\u201d which allowed us to capture a broader spectrum of clinical uncertainty in the dataset.\nThis hierarchical grouping, informed by previous works [18], [31] and feedback from a clinician, ensures that the model leverages clinical knowledge and reflects real-world diagnostic relationships, thereby potentially improving the predictive performance and, more importantly, clinical interpretability of the model."}, {"title": "1) Clinical Relevance of the Groupings", "content": "The hierarchy's structure in Fig 1 reflects the relationships between different conditions, making it possible for the model to capture clinical dependencies and associations more effectively. The structure aligns with clinical reasoning as follows:\nGrouping Related Conditions: By categorizing labels into clinically meaningful groups, the hierarchy better relates different diagnoses based on visual features of the CXR. For example, the appearance of an enlarged cardiac silhouette or altered contours in the mediastinum is often a suggestion of a primary cardiac diagnosis. In contrast, gravity-dependent pulmonary opacifications often suggest fluid infiltration and may include a spectrum of pathologies. These are frequently described as hazy or opaque regions and could indicate pleural effusions, pulmonary edema, or fluid within the parenchymal spaces depending on their geometric distribution within the CXR.\nParent-Child Dependencies: In clinical practice, some conditions naturally lead to others, i.e., consolidations could precede pneumonia [30]. By structuring the hierarchy this way, the model can potentially better understand and reflect these dependencies in its predictions."}, {"title": "C. Model Architecture", "content": "We used DenseNet121 [7] as the base architecture due to its widespread use in medical image analysis and its dense connectivity pattern, which mitigates the vanishing gradient problem, promotes feature reuse, and enables efficient parameter utilization. To adapt DenseNet121 for a multi-label classification task, we extended the architecture with several additional layers:\nA Conv2D layer with 512 filters was added after the DenseNet121 backbone to enhance feature extraction from CXR images, specifically targeting finer details related to the hierarchical structure of pathologies.\nBatch Normalization was applied to stabilize and accelerate the training process.\nA Global Average Pooling (GAP) layer was used instead of a fully connected layer to reduce overfitting while maintaining the critical spatial features in the images.\nA fully connected dense layer with 128 neurons and a ReLU activation function is applied to introduce non-linearity and enable the model to capture complex interactions between the high-level features extracted from the GAP layer.\nDropout layers were used to prevent over-fitting by randomly dropping connections during training with a dropout rate of 0.5.\nFinally, a Dense layer with a sigmoid activation function was used to output the probability scores for each label, enabling multi-label predictions.\nThe model was initialized with random weights and trained from scratch, as the domain-specific nature of CXR images often benefits from task-specific training [23]."}, {"title": "D. Clinically-Inspired Hierarchical Loss Function", "content": "We developed a loss function that aims to reflect clinically meaningful dependencies between labels. In multi-label classification tasks such as CXR analysis, individual labels are not independent of one another. For instance, the presence of a specific pathology (e.g., Pleural Effusion) can increase the likelihood of another pathology (e.g., Pneumonia). To capture these dependencies, our hierarchical loss function incorporates penalties when the model predicts child labels inconsistently with their corresponding parent labels."}, {"title": "1) Binary Cross-Entropy", "content": "At the core of our loss function is the Binary Cross-Entropy (BCE) Loss, which is traditionally used in multi-label classification. BCE measures the difference between the predicted probabilities Ypred and the true binary labels Ytrue for each label. For L labels and a batch size of B, the BCE loss is given by:\n$L_{BCE}(Y_{true}, Y_{pred}) = -\\frac{1}{BL} \\sum_{b=1}^{B} \\sum_{l=1}^{L} (y_{true}^{(b,l)} \\cdot log(y_{pred}^{(b,l)}) + (1 - y_{true}^{(b,l)}) \\cdot log(1 - y_{pred}^{(b,l)}))$\nWhile effective for independent labels, this loss function fails to capture the hierarchical dependencies that are clinically relevant in CXR analysis."}, {"title": "2) Hierarchical Penalty for Parent-Child Relationships", "content": "Incorporating a hierarchical structure requires addressing parent-child dependencies in label predictions. For example, if a parent label (e.g., \u201cFluid Accumulation\u201d) is predicted as negative, it is inconsistent for a child label (e.g., \u201cPleural Effusion\") to be predicted as positive. To enforce such consistency, a penalty term was added to the standard BCE loss. This penalty is designed to increase the loss by a factor to discourage clinically implausible predictions.\nLet Pp,c represent the penalty applied between a parent label p and its child label c. The hierarchical penalty for each pair of parent and child labels is computed as:\n$P_{p,c} = Penalty (p, c) \\cdot 1\\{y_{pred,p} < 0.5 \\text{ and } Y_{pred,c} > 0.5\\}$ (2)\nwhere:\n$Y_{pred,p}$ is the predicted probability for the parent label,\n$Y_{pred,c}$ is the predicted probability for the child label,\n$1\\{\u00b7\\}$ is an indicator function that triggers the penalty when the condition holds."}, {"title": "3) Fixed vs. Data-Driven Penalties", "content": "The hierarchical loss function operates in two modes depending on the source of the penalties:\nFixed Penalty: A constant penalty value is assigned to all parent-child inconsistencies. This penalty mode is straightforward and computationally efficient, but it lacks adaptability to data:\n$Penalty (p, c) = \\beta$ (3)\nData-Driven Penalty: The penalties are dynamically computed based on the empirical likelihood of child labels given the parent labels in the training dataset. This approach introduces a degree of adaptiveness and should better reflect the relationships between labels.\nIn the data-driven approach, the penalty $Penalty(p, c)$ is calculated as:\n$Penalty (p, c) = \\frac{N_{parent=0,child_c=1} + \\epsilon}{N_{parent=0} + 2\\epsilon}$ (4)\nwhere:\n$N_{parent=0,child_c=1}$ is the count of instances where the parent label p is negative and the child label c is positive,\n$N_{parent=0}$ is the total count of instances where the parent label p is negative,\n$\\epsilon$ is a small Laplace smoothing factor to avoid division by zero.\nThe total hierarchical penalty is scaled by a scale factor $\u03bb$, which controls the strength of the hierarchical penalty relative to the BCE loss. The final total HBCE loss is expressed as:\n$L_{HBCE} = L_{BCE} + \\lambda \\sum_{p,c} P_{p,c}$ (5)"}, {"title": "E. Training Strategy", "content": "The model was trained using the Adam optimizer, with an initial learning rate of 0.0001. Following a learning rate reduction-on-plateau strategy, this learning rate decreased by a factor of 0.9 after the validation loss plateaued. Early stopping was used to prevent overfitting and halting training if the validation loss did not decrease for three consecutive epochs. To ensure robust model performance, we used checkpointing, saving the model when either the validation loss decreased or the AUROC increased.\nAdditionally, we increased the input image size to 320x320 to capture higher-resolution features. Given the increased input size and memory limitations, the batch size was set to 16, balancing computational constraints with performance needs and increasing generalizability [24]. The data splits are as follows: Train: 223, 414, Validation: 234, and Test: 668. Each subset is mutually exclusive, without overlapping data points, ensuring that the model performance metrics are unbiased and accurately reflect its generalization capabilities.\nWe also incorporated random image augmentations using TensorFlow's image processing library. The augmentations included horizontal and vertical flips, random brightness adjustments with a delta of 0.1, and random contrast variations with lower and upper bounds of 0.9 and 1.1, respectively. Notably, while the seed for random number generation was fixed to ensure reproducibility across batches, the augmentations were allowed to vary, thus enhancing the model's generalization capabilities.\nThe training was performed on an Ubuntu 20.04.2 LTS (Focal Fossa) with an NVIDIA GeForce RTX 2080 Ti GPU and an Intel Core i9-9900K CPU @ 3.60GHz. Tensorflow and Keras versions were 2.16.1 and 3.0.5, respectively."}, {"title": "F. Monte Carlo Uncertainty Estimation", "content": "To enhance the transparency and interpretability of the model, we used Monte Carlo dropout during inference, a technique that enables uncertainty estimation by making multiple forward passes through the model with active dropout layers. This yields a distribution of predictions, from which we can compute the mean and standard deviation for each label, quantifying the confidence of the model in its predictions. These statistics provide a measure of the uncertainty associated with each prediction, providing clinicians with information on the reliability of the model results."}, {"title": "G. Class Activation Maps", "content": "To further facilitate interpretability and explainability, we derived Class Activation Maps (CAM) using the Grad-CAM method [8]. This technique generates heatmaps indicating the regions of the input image that most strongly influence the model's predictions. By backpropagating the gradients of the target class for the final convolutional layer, we obtained visual explanations that highlight the relevant areas of the CXR contributing to each predicted label. Such visualizations are important for enhancing the model's clinical applicability, as they allow practitioners to verify whether the model's attention aligns with the expected regions of interest or abnormalities seen during physical exam i.e. auscultation of the lungs and/or heart."}, {"title": "IV. RESULTS", "content": "The experiments were initiated by training two baseline models with and without the \"Uncertain\" label to assess the effect of its inclusion. Table I provides the AUROC results across various training strategies on five common pathologies from the CheXpert dataset, along with the influence of the \"Uncertain\" label. It examines two primary setups: flat training with and without the \"Uncertain\" label, and hierarchical training with data-driven and fixed penalties at varying scale factors. Given that the correlation between parent and child labels ranges from 0.814 to 0.999, a fixed penalty value of 1 was selected to ensure a fair comparison of different penalty strategies. It is worth noting the flat training with the Uncertain label achieves the highest mean AUROC (0.899), with superior performance in several pathologies such as Atelectasis (0.883), Cardiomegaly (0.861), Consolidation (0.903), and Edema (0.905). In addition, flat training shows significantly better performance on Cardiomegaly, Consolidation, and Pleural Effusion, Pneumonia, and marginally better on the five pathologies mean (p = 0.0484, 0.027, 0.0473, 0.0308, 0.0057, respectively)."}, {"title": "A. Uncertain Label", "content": "To evaluate the significance of including the \"Uncertain\" label on model performance, a paired t-test was conducted comparing AUROC scores with and without this label included. The scores for the model with 14 original labels (without \"Uncertain\") and 15 labels (with \"Uncertain\") showed minor variations, with mean AUROC values of 0.890 and 0.892 on all 14 pathology labels, respectively. The test suggests that the \"Uncertain\" label does not have a significant impact on the overall performance (five labels: p = 0.0976, 14 labels: p = 0.2076) of the model. However, the results indicate that adding this label leads to marginally better AUROCs, which may hold clinical importance when handling ambiguous cases."}, {"title": "B. Penalty", "content": "To assess the impact of hierarchical label grouping and penalty strategies, we conducted experiments with one primary hierarchy in Fig 1 and two types of penalties, fixed and data-driven, across a range of scale factors. The fixed penalty imposed a constant penalty for parent-child inconsistencies, while the data-driven penalty was based on the conditional probability of child labels given parent labels. Table II presents the AUROC values across different hierarchical training strategies focused on high-level pathological categories, showcasing the impact of the two penalty types at various scale factors. The primary goal of this analysis is to examine how penalty types and scale factors influence classification performance across parent categories. Data-driven paradigm showed significantly better results for Missing Lung Tissue and Opacity in high-level (p = 0.0351, 0.0003, respectively), and Atelectasis, Edema, and Lung Opacity in low-level labels (p = 0.0038, 0.0225, 0.0001, respectively). However, no significant difference was found in other pathologies and mean AUROCs. Based on these results, we followed the study with the data-driven penalty approach at a scale factor of 0.5 that achieved the highest mean of AUROC (0.903), suggesting a favorable balance of penalties for boosting classifier performance on the high-level categories compared to other configurations. Additionally, it attains the highest AUROC values for Abnormal (0.942), Fluid Accumulation (0.922), and Other (0.903), indicating its strength in enhancing the model's recognition of these specific classes."}, {"title": "C. Overall Model Performance", "content": "Overall, our model achieves a mean AUROC of 0.903, 0.904 (see table II), and 0.892 (see table III) on all the hierarchy, the high-level, and the five common CheXpert labels, respectively. As depicted in Fig 2, the AUROC curves show the model's overall efficacy in accurately distinguishing between pathologies and its ability to generalize well across diverse CXR features, supporting its applicability in clinical settings where accurate multi-label classification is essential. High AUROC values for high-level classes suggest the model's capacity to accurately identify broader pathologies, an important requirement in clinical applications. In contrast, it highlights the challenges in detecting specific pathologies that may have overlapping visual characteristics or subtle manifestations on CXRs."}, {"title": "D. Visualization", "content": "Fig 3 depicts generated CAMs, where each sub-image corresponds to a specific label, showing the model's activation regions overlaid on the original CXR. In these CAMs, the calculated activations from the gradients are clipped after normalization, with a 0.5 threshold to retain only the most prominent regions. This technique effectively filters out lower activation values, focusing the visualization on the areas of highest relevance to each pathology. Additionally, the discretized colormap segments the color spectrum to enhance the clarity of localized focus. The color bar in the Figure indicates the activation intensity, with values close to 1 (black) representing areas of high model attention and values near O (white) showing minimal focus. This segmentation provides a more distinct contrast between high and low activation areas, allowing for better interpretability and enabling clearer identification of regions the model attributes greater attention."}, {"title": "V. DISCUSSION", "content": "The goal of this work was to create a highly accurate model to classify CXR diagnoses for clinical decision support. The hierarchical structure of the model is a key strength that enhances interpretability by aligning label dependencies with medical expertise and categorization. This aims to improve prediction accuracy, especially in complex, multi-label settings like CXR analysis. Additionally, the custom hierarchical loss function, which applies penalties for inconsistent parent-child predictions, ensures logical consistency between predictions.\nA strength of the method is the single-run training pipeline, which simplifies deployment and reduces computational overhead, making the approach practical for real-world clinical applications. The integration of CAMs and Monte Carlo uncertainty estimates also enhances transparency, providing both interpretability and confidence measures for clinicians.\nIn comparison to previous works (see Table III), our proposed hierarchical model achieves competitive performance across all pathologies, recording the highest AUROC for Atelectasis (0.879) and Pleural Effusion (0.945), while maintaining a mean AUROC (0.892) similar to other state-of-the-art studies. Our method performed marginally better than Zhang et al. [10] (p = 0.0598), however, no significant difference was found between all these methods.\nIn terms of limitations, the batch size affects the model performance by balancing generalization, convergence, and label representation. Smaller batches improve generalization but introduce noisy gradients, while larger batches stabilize training at the cost of higher computational demands and potential overfitting. Moreover, the model's reliance on a specific label structure reduces its generalizability across datasets."}, {"title": "VI. CONCLUSION", "content": "This study aimed to enhance the interpretability and clinical relevance of multi-label classification for CXR analysis by introducing a hierarchical label structure and a custom loss function. We organized the pathologies into clinically meaningful categories that reflect real-world clinical decision-making, enabling the model to capture the relationships and dependencies between various conditions more effectively. Additionally, by providing visual heatmaps of the activation areas driving our model's diagnostic decisions, we enable clinicians to correlate clinical and radiographic findings with the AI model for consistency.\nWe implemented the HBCE loss function that incorporates penalties for inconsistencies between parent and child predictions. This approach allowed for flexible experimentation with both fixed and data-driven penalty schemes, revealing their impact on model performance. The results demonstrated that using data-driven penalties potentially improves the model's AUROC, indicating the benefit of penalizing clinically inconsistent predictions.\nOur proposed hierarchical classification framework was evaluated across the hierarchy and multiple penalty configurations, showing that a single model with a single-run training pipeline could achieve a weighted AUROC of 0.9034 on the CheXpert dataset. The framework's interpretability was further enhanced using CAM visualizations and Monte Carlo uncertainty estimation, which provided insights into the model's decision-making process and its confidence in predictions.\nOverall, the findings underline the value of integrating clinically inspired hierarchical structures and customized loss functions in medical image analysis. This work contributes to bridging the gap between automated classification and clinical application by promoting more interpretable and clinically aligned predictions.\nFuture work could explore extending this study to use adaptive batch size strategies to combine the benefits of small-batch generalization and large-batch stability, as well as incorporating a domain adaptation approach that dynamically aligns the hierarchy structure to the target dataset. The model's impact should also be evaluated in simulated clinical scenarios, such as Objective Structured Clinical Examinations (OSCEs), to validate its effectiveness as a clinical decision-support tool in real-world workflows."}]}