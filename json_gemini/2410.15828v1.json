{"title": "LLM4GRN: DISCOVERING CAUSAL GENE REGULATORY NETWORKS WITH LLMS \u2013 EVALUATION THROUGH SYNTHETIC DATA GENERATION", "authors": ["Tejumade Afonja", "Ivaxi Sheth", "Ruta Binkyte", "Waqar Hanif", "Thomas Ulas", "Matthias Becker", "Mario Fritz"], "abstract": "Gene regulatory networks (GRNs) represent the causal relationships between tran-scription factors (TFs) and target genes in single-cell RNA sequencing (scRNA-seq) data. Understanding these networks is crucial for uncovering disease mechanisms and identifying therapeutic targets. In this work, we investigate the potential of large language models (LLMs) for GRN discovery, leveraging their learned biolog-ical knowledge alone or in combination with traditional statistical methods. We develop a task-based evaluation strategy to address the challenge of unavailable ground truth causal graphs. Specifically, we use the GRNs suggested by LLMs to guide causal synthetic data generation and compare the resulting data against the original dataset. Our statistical and biological assessments show that LLMs can support statistical modeling and data synthesis for biological research.", "sections": [{"title": "1 INTRODUCTION", "content": "Single-cell RNA sequencing (scRNA-seq) is a cutting-edge technology that enables the collection of gene expression data from individual cells. This approach opens up new avenues for a wide range of scientific and clinical applications. One crucial application of scRNA-seq data is the reconstruction and analysis of gene regulatory networks (GRNs), which represent the interactions between genes. GRN analysis can deepen our understanding of disease mechanisms, identify key regulatory pathways, and provide a foundation for the development of interventional gene therapies and targeted drug discovery.\nStatistical causal discovery algorithms (Scheines et al., 1998; Zheng et al., 2018; Mercatelli et al., 2020; Brouillard et al., 2020; Lippe et al., 2021; Yu & Welch, 2022; Roohani et al., 2024) can reveal potential causal links between TFs and their target gene. However, they often lack robustness and are prone to detecting spurious correlations, especially in high-dimensional, noisy single-cell data. Furthermore, many of these approaches rely heavily on prior knowledge from curated databases (e.g., TRANSFAC (Wingender et al., 1996), RegNetwork (Liu et al., 2015), ENCODE (de Souza, 2012), BioGRID (de Souza, 2012), and AnimalTFDB (Hu et al., 2019)), which frequently lack essential contextual information such as specific cell types or conditions, leading to inaccuracies in the inferred regulatory relationships (Zinati et al., 2024).\nThe recent advancements in and success of large language models (LLMs) have opened up new possibilities for their use in scientific discovery (Sheth et al., 2024; Lu et al., 2024; AI4Science & Quantum, 2023), including causal discovery (K\u0131c\u0131man et al., 2023; Kasetty et al., 2024; Vashishtha et al., 2023; AI4Science & Quantum, 2023; Abdulaal et al., 2023; Khatibi et al., 2024). Most of the above methods involve the refinement of the statistically inferred causal graph by LLM. However, LLMs excel at synthesizing vast amounts of heterogeneous knowledge, making them well-suited for tasks that require the integration of diverse datasets, such as constructing full causal graphs based on"}, {"title": "2 RELATED WORKS", "content": "LLMs and Causality. Gene regulatory network inference from scRNA-seq data traditionally relies on statistical causal discovery methods (Pratapa et al., 2020; Huynh-Thu et al., 2010; Moerman et al., 2019). However, causal discovery often requires external knowledge in the form of inter-ventions (Brouillard et al., 2020), expert input (Kleinegesse et al., 2022), or priors from curated databases (Zinati et al., 2024). Recent advances in large language models (LLMs) offer a promising solution, as LLMs excel at integrating diverse knowledge and providing contextual information (Wan et al., 2024; Ma, 2024). Many of the recent works leverage LLMs for causal discovery by utilizing metadata, such as variable names, to infer causal relationships (K\u0131c\u0131man et al., 2023; Ban et al., 2023b; Vashishtha et al., 2023; Ban et al., 2023a). Further optimizations, including more advanced prompting strategies beyond pairwise variable comparisons, have been developed to enhance causal discovery (Vashishtha et al., 2023; Jiralerspong et al., 2024). Subsequently, (Sheth et al., 2024) explored the effectiveness of completing a partial causal graph across diverse domains. This work, however, considers LLM as an oracle to discover causal graphs for GRN inference.\nLLMs and Biology. Models based on transformer architecture and trained on DNA or RNA genomic sequences are effective at prediction and generation tasks (Zhang et al., 2024). However, the availability of generative Gene-LLMs is limited, they lack rich contextual information and are focused on specific tasks (Zhang et al., 2024). To overcome these limitations, foundation models are tailored for the genomic tasks (Wang et al., 2024a; Cui et al., 2024). However, models trained on the genetic data do not achieve the wide context of LLMs like GPT4 that inject information from the scientific literature and freely available genomic databases. LLMs have been used for the tasks such as gene perturbation (M\u00e4rtens et al., 2024), protein interaction prediction (Jin et al., 2024), gene selection (Toufiq et al., 2023), analyzing biomarkers (Elsborg & Salvatore, 2023) and cell"}, {"title": "3 PRELIMINARIES", "content": ""}, {"title": "3.1 CAUSAL GRAPH", "content": "A directed acyclic graph (DAG) G = (V,E) is composed of a set of variables/vertices V and a set of (directed) edges & between them such that no cycle is formed. Let P be the probability distribution over the same set of variables V. G and P satisfy the Markov condition if every variable is conditionally independent of its non-descendants given its parents. Assuming the Markov condition, the joint distribution of variables V1, V2, . . . \u2208 V can be factorized as:\n$P[V_1, V_2, ..., V_a] = \\prod_i P[V_i|Pa(V_i)]$.\nwhere Pa(Vi) denotes the set of parents of Vi.\nA bipartite acyclic graph G = (U, V, E) is an instance of a DAG whose vertices are divided into two subsets U and V. Each edge E\u00bf connects only two vertices from U and V."}, {"title": "3.1.1 GENE REGULATORY NETWORK (GRN)", "content": "A gene regulatory network (GRN) is a collection of molecular regulators that interact with each other and with other substances in the cell to control the gene expression levels of mRNA and proteins. GRNs describe the relationships between genes, transcription factors (TFs), RNA molecules, and other regulatory elements within a biological system, illustrating how genes are turned on or off and how their expression is modulated over time and in different conditions. GRN can be expressed as a directed acyclic graph (DAG) 3.1. In this work we are considering a bipartite DAG consisting of TFs and target genes."}, {"title": "3.2 GENERATIVE ADVERSARIAL NETWORK (GAN)", "content": "A Generative Adversarial Network (GAN) consists of two neural networks, the generator G and the discriminator D, which are trained simultaneously in a zero-sum game. The generator G maps a random noise vector z sampled from a prior distribution pz(z) (typically Gaussian) to the data space, producing a synthetic sample G(z). The discriminator D maps an input x to a scalar value D(x) \u2208 [0, 1], representing the probability that x is a real sample.\nThe training objective for GANs is formulated as a minimax game defined by the following function:\n$\\min_G \\max_D V(D, G) = E_{x\\sim p_{data}(x)} [log D(x)] + E_{z\\sim p_z(z)} [log(1 \u2013 D(G(z)))]$\nwhere $p_{data}(x)$ is the distribution of real data, and $p_g(x)$ is the distribution induced by G. The discriminator tries to maximize the probability of distinguishing real data from G's samples, while G aims to minimize log(1 \u2013 D(G(z))) to generate realistic data. At equilibrium, the optimal generator replicates the true data distribution, making $p_g(x) = p_{data}(x)$."}, {"title": "3.2.1 GROUNDGAN", "content": "Causal GAN (CGAN) proposed by Kocaoglu et al. (2018) is a variant of GAN that incorporates a causal directed acyclic graph (DAG) into the data generation process. GRouNdGAN (Zinati et al.,"}, {"title": "4 LLM4GRN", "content": "In this work, we propose a novel approach integrating Large Language Models (LLMs) for GRN inference. The overall goal is to leverage the potential of LLMs in capturing complex biological interactions and to assess their utility. Given the lack of ground-truth data, we consider causal synthetic data generation as a downstream task to perform biological (causal) and statistical evaluations. Our methodology involves two distinct experimental settings that leverage different knowledge about the potential transcription factors (TFs) to guide gene regulatory network (GRN)-informed data generation. In each setting, we introduce LLMs into the pipeline motivated by their ability to incorporate extensive contextual information.\n\u2022 In the first setting (Figure 1a, Setting 1.A), we use LLM to infer the GRN graph by providing the LLM with a potential list of TF candidates sourced from a human-curated database.\n\u2022 In the second setting (Figure 1b, Setting 2.A), we utilize the LLM as the knowledge base, incorporating it earlier in the pipeline to infer potential TFs and to deduce the GRN graph.\nWe compare with Setting 1.B and 2.B where the Human knowledge base and LLM knowledge base is used by a statistical causal inference approach, GRNBoost2, respectively."}, {"title": "4.1 GRN GRAPH", "content": "To model the regulatory relationships between transcription factors and target genes. In this frame-work, we maintain a knowledge base (KB) that contains comprehensive information regarding the"}, {"title": "4.2 SETTING 1: HUMAN KNOWLEDGE BASE", "content": "Given the ability of large language models (LLMs) to generate causal graphs from metadata (such as variable names) (Abdulaal et al., 2023), we establish the foundational components of gene regulatory networks (GRNs) using a human knowledge base, denoted as KBH. Let TH represent the set of transcription factors identified through the human-curated database, and let RH denote the set of target genes regulated by these factors. Total set of genes are defined by G. The directed edges in the graph are represented as E, where an edge $(T_i^H, R_j^H) \\in E$ signifies that transcription factor $T_i^H$ regulates target gene $R_j^H$.\nIn Setting 1A, (Figure 1a), the LLM is employed to establish causal relationships between TFs and target genes, utilizing a list of TFs transcription factor candidates sourced from a human-curated database. We model the LLM as a function FLLM that, given a set of metadata M, produces a bipartite graph G = (T, R, E), expressed as:\n$F_{LLM}(M, T^H, R^H) = G$\nThe input metadata M encompasses gene names, transcription factors (TFs), single-cell RNA sequencing (scRNA-seq) data, and relevant biological context (such as species or experimental conditions) sourced from relevant literatures about the dataset.\nIt is important to highlight that, unlike traditional inference methods like GRNBoost2, the LLM-based GRN inference approach in this work does not rely on observational data, ensuring that individuals' privacy in the dataset remains uncompromised. By integrating metadata from scRNA-seq datasets, the LLM can construct GRNs that are tailored specifically for the biological context of the data, potentially capturing nuances that statistical methods cannot. Detailed descriptions of the various prompting strategies employed can be found in the Appendix A.2."}, {"title": "4.3 SETTING 2: LLM KNOWLEDGE BASE", "content": "In Setting 2A, ( Figure 1b), we utilize LLM knowledge base, denoted as KBLLM, to establish partition between transcription factors and target genes. In this context, the LLM is tasked with extracting relevant information directly from its knowledge base, which includes extensive biological data and relationships derived from various sources.\n$F_{LLM}(M) = (T^{LLM}, R^{LLM})$\nHere, TLLM denotes the set of transcription factors identified from the LLM knowledge base, and RLLM represents the corresponding target genes. The input metadata M includes gene names, transcription factors (TFs), and relevant biological context, leveraging the extensive knowledge embedded in the LLM."}, {"title": "4.4 GRN-INDUCED CAUSAL SYNTHETIC DATA GENERATION", "content": "We use the GRNs obtained by either of the settings, to perform synthetic causal data generation. These GRNs are fed into a causal GAN algorithm, specifically GRouNdGAN (Zinati et al., 2024), which uses them to generate synthetic datasets that correspond to each GRN structure in a two-stage approach."}, {"title": "5 RESULTS", "content": "We evaluate and compare the resulting synthetic datasets based on a range of statistical and biological metrics, allowing us to assess the quality and biological relevance of the data produced in each setting. Additionally, we analyze the TFs list generated by the LLM to gain insights, comparing them to priors from human curated database.\nExperimental Setup. We generated synthetic data using datasets and protocols from (Zinati et al., 2024). Our preprocessing focused on creating train, test, and validation sets while maintaining 1,000 genes across all datasets (see AppendixA.1 for details). For each setting, we construct three different GRNs: one derived directly from the LLM, one generated by a causal discovery algorithm that incorporates the prior information (the dataset), and a third, randomly generated graph (based on TF list extracted from KBH or KBLLM). For the GRN inference of LLM, we prompted with contextual knowledge. We used the state-of-art pretrained GPT-4 model (Achiam et al., 2023). Given GPT-4 strong performance for causal discovery (Abdulaal et al., 2023) across different domains including genomics, we prompted (see Appendix A.2) in zero-shot fashion. We also compare open-source model, Llama-3.1-70B (Dubey et al., 2024).\nEvaluation. We employed four statistical metrics: Cosine and Euclidean distances to measure the differences between centroids, maximum mean discrepancy (MMD) to assess the proximity of high-dimensional distributions without centroid creation, and Random Forest Area Under the Receiver Operating Characteristic (RF-AUROC) to determine the distinguishability of real and synthetic cells. We evaluate the biological plausibility of the datasets by conducting single-cell RNA sequencing analysis using the Scanpy Python library. The cell annotations from the original dataset were utilized to annotate the synthetic datasets. Our analysis included log1p normalization and scaling to 10,000, focusing on 1,000 highly variable features. We performed dimensionality reduction using PCA with 50 principal components, followed by Uniform Manifold Approximation and Projection (UMAP). Cell type proportion analysis was conducted with custom code, while gene expression profiling for the top markers of each cell type was visualized using dot plots. For more details, refer to Appendices A and B.\nDatasets. For the direct comparison of the different settings, we focus on the dataset and genomic database information by (Zinati et al., 2024). Specifically, PBMC-All, PBMC-CTL and Bone Marrow data sets (details in Appendix A.1.1). Our objective is to assess the performance of large language models (LLMs) in gene regulatory network (GRN) inference. To evaluate the utility of the inferred GRNs, we employ causal synthetic data generation as a downstream task in scenarios where a reliable ground truth graph is unavailable."}, {"title": "5.1 COMPARISION AGAINST BASELINE", "content": "Evaluation of GPT-4 graphs. For Setting 1, in the absence of ground truth for the GRN, we compare the overlap between the graph proposed by GRNBoost2, a statistical method, and the graph hypothesized by the GPT-4 . While GRNBoost2 is not the definitive ground truth, it serves as a useful reference point. Analyzing this overlap allows us to assess how the hypothesized connections align with established statistical methods and examine how these differences impact downstream synthetic data generation metrics. As a baseline, we also compared against a randomly generated causal graph. Additionally, we test the consistency of the LLM's performance across different random seeds by measuring the overlap between graphs produced from multiple seeds. This helps us evaluate the robustness and stability of the GPT-4 -generated hypotheses. We plot the overlaps for all of the datasets in Figure 2. Our two main observations are that (1) the LLM-derived GRN demonstrates greater robustness compared to the GRNBoost2 (GRNB) GRN, particularly in terms of higher certainty; and (2) the overlap between the GPT-4 -generated GRN and the random GRN is smaller than between GPT-4 GRN and GRNBoost2 GRN, suggesting, that the GPT-4 could be generating meaningful graphs.\nEvaluation of KBGPT4. In Setting 2, we introduced the LLM to filter TF and target genes from a list of genes. Similar to calculating overlaps in GRN evaluation, we also compute the overlap of TF produced by both approaches. From Table 6 (Appendix C), we observe there exists around just about half an overlap between the two knowledge bases. Interestingly we observe less than 50% overlap"}, {"title": "5.2 STATISTICAL EVALUATION OF GRN INFERENCE METHODS ON SYNTHETIC DATA", "content": "In Table 1, we present the statistical metrics results for the three datasets. Metrics are computed between a synthetic dataset of 1000 cells and a held-out test set of 1000 real cells for PBMC-ALL and PBMC-CTL. For BoneMarrow, 500 samples were used for synthetic and held-out test set. In GRouNdGAN's imposed GRN, each gene is regulated by 10 transcription factors (TFs). Lower values (4) indicate better performance for all metrics, with the first two metrics representing the distance between the centroids of the real and synthetic cells. The \u201ccontrol\" metrics are based on the real training dataset. The best performance values (excluding control and Stagel which is a non-causal baseline) are highlighted in bold. Evaluations were carried out on 4 synthetic datasets, with experiments repeated using 2 cross-validation seeds.\nSetting 1 Comparison. The Setting 1 (using KBH, Table 1) result shows the GPT-4-inferred GRN achieves the best performance across all metrics for PBMC-ALL. The LLM model shows the lowest Cosine distance of 0.00024 and Euclidean distance of 89, indicating that the synthetic data generated is most similar to the real data in terms of overall structure. Its lower MMD of 0.0072 compared to the GRNBoost2 model suggests it effectively captures subtle gene expression distributions. Additionally, the LLM model performs well on the Random Forest metric of 0.63, which measures binary classification accuracy in distinguishing real from synthetic data. Unsurprisingly, the Random Graph method performs the worst across all metrics, particularly with a high MMD of 0.0166 and the largest Euclidean distance of 121, highlighting the importance of informed GRN inference methods. In contrast, for the PBMC-CTL and BoneMarrow, the GRNBoost2 graph outperform the GPT-4 in this setting.\nSetting 2 Comparison. In Setting 2 (Table 1), where we incorporated the GPT-4 knowledge base (KBGPT4), the GRNBoost2 method\u2500combining GPT-4-proposed transcription factor (TF) lists with GRN inference\u2500outperforms the fully GPT-4-based GRN approach (i.e., where the LLM proposes both the TF list and the connections between TFs and genes) across all datasets. GRNBoost2 also achieves the best overall performance for all datasets. For instance, in the PBMC-ALL dataset, it achieves a Euclidean distance of 83, improving from 121 in Setting 1, and an RF AUROC of 0.59, compared to 0.73 in Setting 1. Overall, GRNBoost2 shows improvement over its performance in Setting 1, delivering better results across all metrics for both PBMC-ALL and PBMC-CTL. Notably, it surpasses the top results from Setting 1. These findings suggest that integrating LLM-derived priors with GRNBoost2's statistical inference yields a more accurate and robust representation of gene regulatory networks (GRNs). In contrast, BoneMarrow performed best in Setting 1 but remains competitive in Setting 2 when the KBGPT4 is combined with GRNBoost2."}, {"title": "5.3 BIOLOGICAL PLAUSIBILITY OF CAUSAL SYNTHETIC DATA", "content": "We conduct cell type annotation based on the original dataset, gene expression analysis to identify top markers for each cell type and cell-type proportion analysis on the most statistically robust datasets. Full analysis can be found in Appendix D (subsection C.4)."}, {"title": "5.3.1 GENE EXPRESSION PROFILING PER CELL TYPE", "content": "General Performance of KBLlama GRNBoost2 in Cell-Specific Expression Profiles. The KBLlama GRNBoost2 model shows that specific cell types, such as CD8+/CD45R+ naive cytotoxic T cells and CD4+ T helper cells, exhibit significantly higher mean expression levels for the same markers across multiple cells, while maintaining similar cell fraction of expression. Additionally, the KBLlama GRNBoost2 model demonstrates superior performance in elucidating expression patterns in certain cases, such as with dendritic cells. Although KBLlama GRNBoost2 synthetic data Figure 3a introduces some noise, it generally improves cell-specific expression profiles, which could be further optimized for even cleaner cell type differentiation. A key observation was that when mean expression was higher in specific cell types, it tended to be lower in others, with fewer than 30% of cells displaying similar expression fractions. In contrast, when expression was noisy across multiple cell types, both mean expression and cell fraction tended to be similar across these groups.\nKBGPT4 GRNBoost2 Dataset Performance and Noise Patterns. The KBGPT4 GRNBoost2 model identifies top marker genes, revealing notable differences in expression profiles. While expression levels among some markers are noisy and indistinguishable, this model effectively highlights markers that are more discriminative for certain cell types. The KBGPT4 GRNBoost2 dataset Figure 3b exhibited more noise than the KBLlama dataset Figure 3a, with multiple markers expressed across various cell types at comparable mean expression levels and with higher cell fractions. For the"}, {"title": "5.3.2 DIFFERENTIAL CELL TYPE PROPORTION ANALYSIS", "content": "Variations in Cell Type Proportions Across Datasets. A notable observation is that the cell type proportions in each generated dataset differ significantly from those in the original dataset, indicating a noisy overall expression profile that can alter the distribution of cell types. In the KBLlama GRNBoost2 dataset (Figure 4b), CD8+/CD45RA+ naive cytotoxic T cells were the most abundant at 34.1%, followed closely by CD56+ NK cells, CD8+ Cytotoxic T cells, and CD4+/CD25+ T regulatory cells. This trend was similarly observed KBGPT4 GRNBoost2 ( Figure 4a) and other datasets, albeit with slightly varying percentages.\nOverall Performance of KBLlama GRNBoost2. We observe that CD4+/CD45RA+/CD25\u2013 naive T cells and CD8+/CD45RA+ naive cytotoxic T cells exhibited noisy expression patterns consistently across all datasets. The original dataset performed better for CD8+/CD45RA+ cytotoxic T Cells, showing lower noise in their expression compared to the KBLlama GRNBoost2 ( Figure 4b) dataset. Among the various models, the KBLlama GRNBoost2 model emerged as the best performer, providing clearer segregation of cell types and reduced noise, particularly for CD4+/CD45RA+/CD25\u2013 naive T Cells and dendritic cells. In contrast, the KBGPT4 GRNBoost2 ( Figure 4a) model exhibited more noise than KBLlama GRNBoost2, with similar markers expressed across various cell types at comparable mean expression levels."}, {"title": "5.4 DISCUSSION AND LIMITATIONS", "content": "We observe promising results in using LLM for GRN discovery, especially on the PBMC dataset. The hybrid approach incorporating TFs suggested by LLM (KBLLM) and GRNBoost2 causal discovery yield the best overall performance (for PBMC-ALL and PBMC-CTL data sets). Surprisingly, a smaller open-source model Llama has shown the best result in this setting. One possible explanation could be the number of TFs proposed in Setting 2. The number of TFs in KBLlama is higher than those in KBH or KBGPT4. Our additional experiments (subsection C.2) indicate that the number of transcription factors (TFs) may be significant, as it provides a broader set of variables for the GRNBoost2 algorithm to evaluate during causal discovery. Nevertheless, although further evaluation is needed, new Llama models might perform as good or better than state-of-the-art GPT for specific tasks Valero-Lara et al. (2023). However, Llama performs worse on the more challenging, GRN construction task. The lower performance of LLMs on CTL and BoneMarrow data sets is not surprising. Recent studies suggest that genomic LLMs under-perform on cell-specific data (Tang & Koo, 2023). In addition, human transcription factors outnumber mice transcriptomic information in the databases (Members & Partners, 2024) making the information on mice genes scarcer in the LLMs training data.\nBiological plausibility analysis reveals that the Setting 2, KBLlama dataset significantly improves cell type differentiation and reduces noise compared to other generated datasets, particularly for CD4+/CD45RA+/CD25\u2013 naive T cells and dendritic cells, which indicates better performance of the model due to its ability to handle large contexts (Xiong et al., 2023).\nIn contrast, while the Setting 2, KBGPT4 model exhibited higher noise and less specificity, the Setting 1, KBH, GRNBoost2 model also showed noisy patterns, especially in naive T and cytotoxic T cells, emphasizing the need for models that clearly delineate cell type-specific expression. Notably, discrepancies in cell type proportions across generated datasets, particularly the inflated presence of CD8+/CD45RA+ naive cytotoxic T cells, raise concerns about the biological relevance of these models. As reported previously, large-scale single-cell studies tend to be more noisy which can lead to sub-optimal biological inferences (Kavran & Clauset, 2021). Therefore, further refinements are essential across all approaches to enhance specificity and reliability in representing true cellular compositions, which is crucial for accurate downstream biological analyses and interpretations. Finally, the KBH GPT-4 model exhibited highly noisy or non-specific expression profiles, particularly for CD4+/CD45A+/CD25\u2013 naive T cells, CD8+/CD45RA+ naive cytotoxic T cells, CD4+ T helper cells, CD4+/CD25+ T regulatory cells, and CD4+/CD45RO+ memory cells. For other cell types, the model either failed to express most top markers or showed high cell fractions with reduced mean expression across different cell types.\nOne of the limitations of the study is the unifying constraints that are imposed on the GRN discovery due to the parametric requirements of GRouNdGan (Zinati et al., 2024). Namely, all GRN graphs are set to be bipartite graphs with the same number of TFs and same number of target genes for each TF. These constraints restrict the diversity of the generated graphs, resulting in fairly similar performance metrics among different GRN discovery approaches. In addition, multi-layer graphs with transcription factors, cofactors, and target genes are more realistic and can better reflect biological complexity (Karlebach & Shamir, 2008).\nDespite the promising results, we note, that LLMs should be used cautiously in any high-stakes decision-making. The models are prone to reporting false information with confidence (Ji et al., 2023; Farquhar et al., 2024). In addition, they are susceptible to biases in the training data. One of the most common sources of bias in machine learning is the under-representation of minority populations in the training data. Transcription factor databases and literature often lack balanced representation across ethnicity, ancestry, gender, and age groups. The vast majority of genetic data and studies are based on individuals of European ancestry (Sirugo et al., 2019; Bentley et al., 2017). The underrepresentation of non-European ancestry populations in genomic databases can obscure gene-disease associations that are rare in European groups, leading to treatments that may not be effective for these communities (Landry et al., 2018; Tawfik et al., 2023; Barral-Arca et al., 2019). Age groups, specifically children and elderly, females, low-income populations and individuals from remote rural areas are also underrepresented in clinical trials and data, making them less likely to benefit from the achievements of precision medicine (Mosenifar, 2007; Davis et al., 2019; Steinberg et al., 2021). LLMs are shown to exacerbate some existing health disparities (Pfohl et al., 2024), and are likely to be influenced by the under-representation bias in the genomic data."}, {"title": "6 CONCLUSION", "content": "In conclusion, our analysis highlights the potential of using Large Language Models (LLMs) for gene regulatory network (GRN) inference, as supported by both statistical and biological performance metrics. Notably, the best performing approach combines LLM-derived TF priors with GRNBoost2 for statistical inference. In addition, we see good potential for using open-source models such as Llama for GRNs, and we aim to explore their utility further, either directly or with fine-tuning. Our biological results suggest that additional refinement is needed. For this we foresee developing GRNs tailored to individual cell types, as evidence indicates that GRNs are often cell-type-specific."}, {"title": "A EXPERIMENTAL SETUP", "content": ""}, {"title": "A.1 DATA PREPARATION AND MODIFICATIONS", "content": "In synthetic data generation, we use the same data sets and follow the protocol described by Zinati et al. Zinati et al. (2024).\nWe downloaded the three datasets using the link provided at https://emad-combine-lab. github.io/GRouNdGAN/tutorial.html#demo-datasets.\nTo ensure consistent results across different runs, we modified the code in two key ways: (1) we seeded the randomness in the \u2018main.py' file. While the GRNBoost2 algorithm is already seeded by default, ensuring consistent output, the rest of the code was not. Given that we are testing different GRN graphs, it was critical to control for randomness to prevent it from influencing our results. (2) We addressed additional bugs to ensure smooth execution, such as handling sparse data loading and ensuring that the code was properly assigned to the correct device for training. All modifications have been incorporated into our forked version of the repository, available upon publication. Some of the bugs we identified were also reported and fixed by the original authors.\nAfter downloading the raw data, we preprocessed it to create separate train, test, and validation files. Following the paper's recommendations, we used a test set of 1,000 samples for the PBMC and CTL datasets, and 500 samples for the BoneMarrow dataset. For validation, we set aside 1,000 samples each for PBMC and CTL, and 500 for Bone Marrow. The subsets were disjoint. We refer to these preprocessed datasets as \"Real Data\" throughout the paper. The preprocessed data will be made available upon publication.\nDuring preprocessing, we observed that the BoneMarrow dataset had two genes absent in the training data, as they were not expressed in any cells. This issue did not occur in the full dataset, where genes expressed in fewer than three cells and cells expressing fewer than 10 genes had been filtered out. However, after splitting the data into train, test, and validation sets, some genes in specific splits were not expressed at all.\nTo address this, we modified the code to filter out genes expressed in fewer than one cell for each data split. This reduced the number of genes in the BoneMarrow dataset from 1,000 to 910. In the PBMC dataset, we found that 493 genes were not expressed in the test set, requiring extensive filtering.\nTo resolve this, we revised our approach. Instead of applying the original threshold, which discarded genes expressed in fewer than three cells, we increased this threshold to 680 cells for the PBMC dataset, equivalent to 0.01% of the full dataset. This change allowed us to retain the full 1,000 highly variable genes. However, the resulting set of 1,000 genes may differ slightly from those identified with the initial criteria, given that the full PBMC dataset contains over 32,738 genes, while BoneMarrow contains 3,451 genes.\nThis revised strategy allowed us to retain the full 1,000 genes for the PBMC and CTL datasets but not for BoneMarrow. To address this, we further adjusted the strategy by filtering out genes expressed in fewer than the number of cells in the test set for each dataset (1,000 for PBMC and CTL, and 500 for BoneMarrow). This approach successfully retained 1,000 genes across all datasets.\nAfter preprocessing, we followed the rest of the process as detailed in the tutorial provided by the authors."}, {"title": "A.1.1 DATA SETS", "content": "\u2022 Human peripheral blood mononuclear cell (PBMC-Al). 68579 samples corresponding to 11 cell types\n\u2022 Human peripheral blood mononuclear CD8+ Cytotoxic T-cells (PBMC-CTL). 20773 samples from the most common cell type in PBMC-All\n\u2022 Mouse bone marrow Hematopoietic stem cells lineage differentiation (BoneMarrow). 2730 cells."}, {"title": "A.2 LLM PROMPTING STRATEGIES", "content": "In this study, we utilize prompting techniques to guide the behavior of a Large Language Model (LLM) for gene regulatory network (GRN) inference and other downstream analyses. The model employed is based on a pretrained large language model, specifically GPT-4, which has not been fine-tuned for this task. Instead, we rely on advanced prompting strategies, including Chain of Thought (CoT) reasoning and context provision, to enhance the performance of the LLM in generating biologically plausible results."}, {"title": "A.2.1 CHAIN OF THOUGHT (COT) PROMPTING", "content": "Chain of Thought (Co"}]}