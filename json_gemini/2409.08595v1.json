{"title": "Automatic Generation of Fast and Accurate Performance Models for Deep Neural Network Accelerators", "authors": ["KONSTANTIN L\u00dcBECK", "ALEXANDER LOUIS-FERDINAND JUNG", "FELIX WEDLICH", "MIKA MARKUS M\u00dcLLER", "FEDERICO NICOL\u00c1S PECCIA", "FELIX THOMMES", "JANNIK STEINMETZ", "VALENTIN BIERMAIER", "ADRIAN FRISCHKNECHT", "PAUL PALOMERO BERNARDO", "OLIVER BRINGMANN"], "abstract": "Implementing Deep Neural Networks (DNNs) on resource-constrained edge devices is a challenging task that\nrequires tailored hardware accelerator architectures and a clear understanding of their performance charac-\nteristics when executing the intended AI workload. To facilitate this, we present an automated generation\napproach for fast performance models to accurately estimate the latency of a DNN mapped onto systemati-\ncally modeled and concisely described accelerator architectures.\nUsing our accelerator architecture description method, we modeled representative DNN accelerators such\nas Gemmini, UltraTrail, Plasticine-derived, and a parameterizable systolic array. Together with DNN map-\npings for those modeled architectures, we perform a combined DNN/hardware dependency graph analysis,\nwhich enables us, in the best case, to evaluate only 154 loop kernel iterations to estimate the performance\nfor 4.19 billion instructions achieving a significant speedup. We outperform regression and analytical mod-\nels in terms of mean absolute percentage error (MAPE) compared to simulation results, while being several\nmagnitudes faster than an RTL simulation.", "sections": [{"title": "1 INTRODUCTION", "content": "Edge devices provide lower bandwidth demands, lower response times, higher autonomy, better\nprivacy, less cost, and higher energy efficiency than data centers when processing data-intensive\ntasks such as Deep Neural Networks. Therefore, more and more hardware vendors enter the mar-\nket for edge devices tailored explicitly for the execution of DNNs, offering a large variety of param-\neterizable accelerator architectures. However, selecting the most suitable accelerator architecture\nfor a given application is arduous since reliable performance metrics can often only be gathered\nusing time-consuming simulators or data sheets that provide peak $OPS/s$ for only a few selected\nDNNs so that these numbers are hardly transferrable to other DNN architectures, using spread-\nsheet calculations, due to their vast hyperparameter space.\nAdditionally, during the early design phase of an accelerator, it is crucial to compare different\nvariants with each other quickly. On the hardware side, these variants range from changes in the\nnumber of available multiply-accumulate units to entirely different data paths. On the software\nside, hardware-aware Network Architecture Search (NAS) can explore different hyperparameters\nand data reuse strategies for mapping DNNs onto an accelerator. Building accurate performance\nmodels for all those variants and combinations is only feasible with a fast and automated approach."}, {"title": "2 RELATED WORK", "content": "Several studies have been carried out to estimate the performance of DNNs executed on accelera-\ntor architectures. Those studies can be divided into analytical and machine learning models with\nvarying accuracy and estimation speeds.\nBouzidi et al. [5] compare five different machine learning models for performance estimation of\nDNNs mapped onto edge GPUs. They executed different DNN architectures with varying hyper-\nparameters, measured their end-to-end latency and gathered at least 200 000 samples per platform\nto train different estimators. The MAPE for the best regression models ranges between 14.73% and\n7.67%.\nIn PreVIous [26], a specially designed DNN composed of different layers with varying param-\neters is executed on the CPUs of single-board computers. During the execution of this DNN, the\nend-to-end latency and energy consumption for each layer are measured. The measurements are\nused together with the layer parameters to train linear regression models for execution time and\nenergy consumption estimation. In terms of execution time, PreVIous achieves a MAPE between\n3.25% and 7.92%. However, collecting the data is time-consuming and requires the hardware for\nwhich the estimation should be made.\nANNETTE [28] uses micro-kernel benchmarks and multi-layer benchmarks of DNNs executed\non an FPGA and an ASIC accelerator to characterize the performance of those platforms. Similar\nto PreVIous special DNNs are used to measure the execution time of several different layers in\none benchmark run. The layer execution time measurements are combined with refined roofline\nmodels, incorporating utilization efficiency, for each layer which are used when no measurements\nfor a layer exist to estimate the execution time of a whole DNN executed on one of the selected\naccelerators reaching a MAPE between 3.47% and 7.44%.\nTimeloop [21] proposes an analytical modeling framework for execution time and energy con-\nsumption based on coarse textual descriptions of accelerator architectures and the mapping of\nconvolutional and fully-connected layers. Compared to three real-world accelerators, an average\naccuracy in terms of execution time of 95% is achieved. Timeloop does not consider pipeline stalls,\nresource conflicts and instruction-level parallelism, which can lead to an accuracy as low as 78%."}, {"title": "3 PROPOSED APPROACH", "content": "Fig. 1 shows our proposed automatic DNN accelerator performance model generation approach.\nThe foundation of our performance model generation is the Abstract Computer Architecture\nDescription Language (ACADL) introduced in section 4. ACADL allows us to model various pa-\nrameterizable accelerator architectures and capture how data and instructions propagate through\nthem on different abstraction levels.\nA TVM-assisted Deep Neural Network mapping presented in section 5 for a given DNN\naccelerator architecture described in ACADL generates loop kernel instructions together with the\nnumber of iterations for each DNN layer.\nEach loop kernel instruction is propagated through the ACADL object diagram to construct an\nArchitectural Instruction Dependency Graph (AIDG) in the Architectural Instruction Depen-\ndency Graph Construction phase described in section 6.1. This directed acyclic graph captures\nthe structural and data dependencies between instructions occupying hardware modules, which\nrepresents the performance model for a DNN/hardware mapping.\nThe Architectural Instruction Dependency Graph Evaluation in section 6.2 uses the gen-\nerated AIDG and the calculated loop kernel iterations. Depending on the loop kernel instructions,\nthe loop must be executed only a few times to estimate the end-to-end latency of a whole DNN\nlayer. Since in consecutively executed iterations, only the memory addresses change, it is only\nnecessary to analyze the first few iterations until a stable end-to-end latency of a single iteration\nis established. This stable end-to-end latency is then multiplied by the amount of loop kernel itera-\ntions minus the loop kernels that have already been analyzed, resulting in the end-to-end latency"}, {"title": "4 ABSTRACT COMPUTER ARCHITECTURE DESCRIPTION LANGUAGE", "content": "Computer architectures are almost exclusively communicated using block diagrams. Each block\nin a block diagram describes the function of the computer architecture module it represents, while\narrows are used to depict how data is exchanged between different modules. However, modeling\ncomputer architectures on the system level is mainly done using hardware description languages\nlike VHDL and Verilog or electronic system-level languages such as SystemC.\nEspecially in the early design phase of new computer architectures, it is crucial to evaluate\nthe performance of different design alternatives. However, using the aforementioned hardware\ndescription languages requires a lot of expert knowledge and time to produce working design\nalternatives, leading to low productivity. Therefore, we use the Abstract Computer Architecture\nDescription Language (ACADL) [18] that does not require extensive hardware design knowledge.\nACADL is an object-oriented language that defines twelve classes and one interface that de-\nscribe the basic building blocks of computer architectures. The dependencies and relations of those\nclasses are depicted in Fig. 2 using the Unified Modeling Language (UML) [11] notation standard\nfor class diagrams. Computer architectures modeled with ACADL are instruction-centric, meaning\nthat any architectural state change is triggered by an instruction. All instructions originate in an\ninstruction memory and are forwarded to a functional unit supporting the instruction's operation\nand register and memory accesses. The time in clock cycles from loading an instruction from the\ninstruction memory until it reaches a functional unit that carries out its operation is accumulated.\nThis accumulated time is the end-to-end latency of a single instruction. Several instructions can\nbe loaded, issued, forwarded, and executed simultaneously, allowing for modeling multiple issue\nand parallel computer architectures with ACADL."}, {"title": "4.1 Types and Classes", "content": "The ACADL class diagram in Fig. 2 shows the dependencies between all classes. An association\ndescribes that a class calls the method of another class. Inheritance describes that a derived class\ninherits all attributes and methods from its base class. A derived class can add its own unique\nattributes and methods. In Fig. 2 we only list the attributes and methods in the base class and only\nlist the added attributes in methods in the derived class. The composition expresses that a class\ncontains instances of other classes as attributes.\n`bool`, `int`, `str`, `List`, `Set`, `Union`, `Tuple`, `Any`, `Callable`, are the data types of ACADL based\non the Python 3.10 typing system [25].\nAssociation describes the relation between two or more instantiated objects of classes that\nallows one object (caller) to cause another one to perform an action (callee), while `:call()` signifies\nthe callee's function that is called by the caller.\nInheritance allows a class to base its implementation and attributes upon another base class.\nComposition defines a relationship between instantiated objects of classes that implies that\none or more objects are part of a single composite object.\nlatency describes a time delta in clock cycles. It can be specified as an integer value or a string\ncontaining a function that is evaluated during the performance estimation.\nACADLObject is the virtual base class for every computer architecture module modeled in\nACADL. It only has the attribute name, the unique identifier for each object."}, {"title": "4.2 General Modeling Workflow", "content": "Creating an ACADL object diagram for an accelerator architecture is the foundation of our pro-\nposed performance evaluation approach. In this section, we introduce two methods for obtaining\nan ACADL object diagram.\nThe first method is the top-down modeling of an accelerator. This modeling method is to be\nused when exploring the design of a new architecture. Using the envisioned accelerator capabili-\nties supported operations are formulated. Together with structural information of the accelerator\nhardware a high-level ACADL object diagram can be created. Mapping DNNs onto the ACADL ob-\nject diagram together with the proposed performance evaluation allows to validate the high-level\ndesign. This validated ACADL object diagram can than be decomposed into smaller modules and\nvalidated again. By iterative refinement and validation, a detailed ACADL object diagram for an\naccelerator is obtained.\nThe second method is modeling accelerator architectures bottom-up which is to be used for ob-\ntaining an ACADL object diagram for an existing accelerator. This method requires some knowl-\nedge of the hardware that implements the accelerator. An input for the bottom-up modeling is an\narchitectural block diagram together with timing information on different operations running on\nthe accelerator. The timing information can be obtained from the accelerator datasheet or through\nmicrobenchmarks. The architectural block diagram can often be translated into an ACADL object\ndiagram without major adaptations. Section 4.3 provides two detailed examples for obtaining an\nACADL object diagram from architectural block diagrams on two abstraction levels. Additionally,\nin section 7.2 the ACADL object diagram for the Gemmini accelerator is presented which was also\nobtained from the architectural block diagram of the Gemmini accelerator.\nThe UML-based representation of the ACADL class diagram enables developers to use a graph-\nical UML editor to create accelerator architecture object diagrams. A suitable export plugin would\nbe required to automatically generate an analyzable ACADL model from such an object diagram.\nAdditionally, [18] provides a detailed description on how to use ACADL to model AI hardware\naccelerators."}, {"title": "4.3 Modeling Examples", "content": "In this section, we present two different example accelerator architectures, to show how these can\nbe modeled as an ACADL object diagram using their architectural block diagrams. While the first\narchitecture is modeled in ACADL using scalar instructions, the second architecture is modeled\nusing fused tensor instructions and thus addressing different abstraction levels.\nThe block diagram in Fig. 3 depicts a 2\u00d72 systolic array. Each processing element (PE) consists\nof an ALU and an internal register file. PEs are able to move data from their internal register file\ninto the register file of adjacent PEs at the bottom and the right-hand side. The PEs at the top row\nand leftmost column are connected to load units that read data from the data memory. The PEs in\nthe bottom row are connected to store units that are able to write data back into the data memory.\nThe instructions presented on the right-hand side of Fig. 3 show two consecutive iterations of an\nelement-wise multiplication of vectors A and B accumulated into vector C.\nFig. 4 shows additional classes and the ACADL object diagram for 2\u00d72 systolic array. The block\ndiagram's load units, store units, and PEs are represented by the classes MemoryLoadUnit, Memo-\nryStoreUnit, and ProcessingElement. Introducing those three classes, composed of ACADL classes,"}, {"title": "4.4 Extendability and Limitations", "content": "The ACADL class diagram presented in Fig. 2 is easily extendable by adding new classes and in-\nheriting from existing ones. Fig. 7 depicts how a new class for a dynamic random access memory\n(DRAM) model that inherits from Memory can be added to the ACADL class diagram. the Dynamic-\nRandomAccessMemory has additional attributes for different access latencies for DRAM ($t_RCD$,\n$t_CAC$, $t_RP$, and $t_RAS$, $t_RC$) and redefines `read_latency` and `write_latency` with stateful\nlatency functions. The object-oriented paradigm facilitates the extendability of ACADL. Addition-\nally, ACADL models could be generated from other languages such as Bluespec [20], Chisel [3], or\nCoreDSL [12]."}, {"title": "5 DEEP NEURAL NETWORK MAPPING", "content": "In the previous section, we have seen how we can model accelerator architectures on different\nabstraction levels using ACADL. To estimate the performance of an accelerator architecture, we\nalso need to represent the DNN layers to be executed.\nGenerally speaking, all accelerator architectures exploit some kind of data reuse during the com-\nputation of DNN layers to reduce memory accesses, as those are typically the most time-consuming\noperations. For example, the UltraTrail architecture, presented in Fig. 5, unrolls the output chan-\nnels K in one dimension and the input channels C in the other [4]. A similar reuse pattern is used\nfor the systolic array shown in Fig. 3.\nThe relevant difference is that the UltraTrail accelerator operates with tensor-level `conv_ext`\ninstructions, while the systolic array executes scalar instructions like `load` and `mac`. Therefore,\nthe granularity of the representation of the DNN layer needs to match the abstraction level of the\nACADL model.\nIn the case of the aforementioned systolic array, we use TVM's [8] TIR intermediate represen-\ntation to partially unroll the output channel dimension K and input channel dimension C such\nthat the generated instructions can be executed in parallel on the given architecture resulting in a\nweight stationary dataflow. By unrolling different dimensions of a DNN layer, different dataflows,\nand data reuse strategies can be explored. However, this is beyond the scope of this paper. The\nunrolling factors for K and C depend on hardware parameters such as the dimensions of a systolic\narray instance and the memory port width, which are extracted from the ACADL object diagram.\nFor a complete computation of a convolutional layer, this loop kernel needs to be executed k it-\neration times with different memory addresses. This k is obtained from the loop variables of the\nunrolled TIR computation.\nMoving to more abstract hardware models, the instructions to be executed also become more\nabstract. For example, some accelerator architectures only support tiled matrix-matrix multiplica-\ntions (GEMM) with sometimes fused pooling and activation operations. Therefore, the instructions\nfor an end-to-end latency estimation of a DNN layer need to be generated accordingly. Firstly, by\nconverting the convolutional or fully-connected layer to a GEMM computation using an im2col\ntransformation and, secondly, by tiling the resulting matrix-matrix multiplication to fit the sup-\nported tile size of the accelerator.\nOverall, to create a valid DNN layer mapping for an architecture modeled in ACADL, one needs\nto consider the operations that can be executed on the given hardware and then partition the DNN\nlayers according to these operations. For low-level models, this could be `load` and `mac` instructions,\nfor intermediate-level models `gemm` instructions, and for high-level models `conv_ext` instructions.\nLastly, layer fusion, pruning, and quantization are considered differently on the different ab-\nstraction levels. For low-level instructions, a tool like TVM can provide an already optimized com-\nputation graph where e.g. the activation function is fused into a preceding convolutional layer and\nunimportant weights and computations have been removed. The unrolling would then be done on\nthe optimized layer. On a higher abstraction level, layer fusion, pruning, and quantization depends\non the architecture's capability. In the case of UltraTrail, the quantized and fused `conv_ext` layer\ncomputes the convolution, pooling, and activation using its MAC-array and output processing unit\n(OPU). For the systolic array a pruned layer would contain less instructions which could lead to an"}, {"title": "6 ARCHITECTURAL INSTRUCTION DEPENDENCY GRAPH", "content": "To accurately estimate the performance of DNNs mapped onto an accelerator architecture with-\nout using a simulator, we propose the Architectural Instruction Dependency Graph (AIDG) [17],\ncapturing when an instruction occupies a hardware module (ACADL object), in which order an\ninstruction propagates through an accelerator (forward), resource conflicts (structural dependen-\ncies), data dependencies, and buffer fill levels, extending the Execution Graph proposed by Li et al.\n[16].\nAn AIDG = (N, E) is a directed acyclic graph. Nodes in N = {`(i, o) : (i, o) \u2208 I \u00d7 O` } of an AIDG\nrepresent that an instruction $i \u2208 I$ occupies an ACADL object $o \u2208 O$. There are four different\ndependency types $D \u2208 `{f, s, d,b` }$ an edge $e \u2208 E = {`(x, y)_s : (x, y)_s \u2208 N \u00d7 N \u00d7 D`}$ can represent:\nforward f, structural dependency s, data dependency d, and a buffer fill level dependency b."}, {"title": "6.1 Construction", "content": "To construct an AIDG from a given set of instructions $I$ and an ACADL object diagram $O$ each in-\nstruction $i \u2208 I$ is propagated in order through the ACADL object diagram $O$, which returns the or-\nder $o(i)$ of ACADL objects $i$ passes through. If an instruction reads from memory, an ACADL object\nnamed `writeBack` is added to the order $o(i)$, which is later used as data dependency for nodes ac-\ncessing the write register of the read operation. For each $o \u2208 \\tilde{o}(i)$, a node $(i, o)$ is created. The nodes\ncontaining $i$ and $o_0, . . ., o_n \u2208 \\tilde{o}(i)$ are connected according to the order in $o(i)$ with forward edges\n$((i, o_j), (i, o_{j+1}))_f$. Nodes containing the InstructionFetchStage object of consecutive instructions\nare connected through a buffer fill level dependency edge $((i_j, InstructionFetchStage), (i_{j+1}, InstructionFetchSt$\nwhich is used to track the fill level of the issue buffer to facilitate issuing multiple instructions at\nonce. Except for the node containing the `writeBack` object, each node is connected with a struc-\ntural dependency edge to the node that has previously contained the current ACADL object $o$,\nwhich is the last structure user $s_u(o) \u2208 N$, afterward the last structure user is set to the target\nof the added structural edge. If a FunctionalUnit $o$ has sibling FunctionalUnits $F_s \u2282 O$, these are\nFunctionalUnits contained by the same ExecuteStage, the last structure user for all $f_s \u2208 F_s$ is set\nto $o$, which restricts ExecuteStages from processing multiple instructions at the same time using\ndifferent FunctionalUnits. For the node $(i, o)$ where o is a FunctionalUnit, data dependency edges\nfor all read and write registers of $i$ are added, coming from the last node that accessed those regis-\nters. Afterward, $(i, o)$ is set as the last register reader and writer for the read and write registers of\n$i$. If o of $(i, o)$ is a Memory, data dependency edges for read and write addresses are added coming\nfrom the last node accessing those addresses. The node containing the Memory $o$ is set as the last\nreader and writer for the addresses. The node containing the `writeBack` object is then set as the\nlast register writer for all write registers of $i$, as mentioned above. The last step of the AIDG con-\nstruction algorithm is to merge the nodes of consecutive instruction blocks of size `port_width` of\nthe instruction Memory. All consecutive `port_width` nodes containing the `InstructionMemory`-\n`AccessUnit` and instruction Memory are merged along their respective structural dependency and\nbuffer fill level edges into a single node. The construction of an AIDG is in $O(|I| \\cdot o_{max})$ where $o_{max}$\nis the longest path an instruction can take through an ACADL object diagram."}, {"title": "6.2 Evaluation", "content": "To determine the end-to-end latency of an AIDG, the nodes are sorted in their topological order.\nThis is done by following the out-going forward edges of each node and, in the instruction order,\nfollowing the structural dependency edges. Because each node, structural dependency edge, and\nforward edge is only visited once, computing this topological order is in $O(|N| + |E_{f,s}|)$. For given set of instructions,I the topological order\n is denoted in the bottom right of each node. For each node, the in-going\nand out-going edges are evaluated and depending on the different dependency types, $t_{enter}$ and"}, {"title": "6.3 End-to-end Latency of a Deep Neural Network Layer", "content": "When executing consecutive iterations in a pipeline, the end-to-end latency of a single iteration\ncannot be multiplied to get the execution time of the whole loop. This is because successive iter-\nations overlap each other in a pipeline. Moreover, loop-carried dependencies can lead to different\nend-to-end latencies in consecutive iterations. However, this difference in end-to-end latencies is\nonly present in the first few iterations, while the end-to-end latencies of all following iterations\nonly vary by a negligible amount.\nFig. 9 shows the overlap of consecutive iterations in a pipeline with different end-to-end laten-\ncies of successive iterations of the same loop kernel caused by loop-carried dependencies. While\niteration 0 has an execution time of 8 cycles, because there are no dependencies from previous\niterations, all following iterations have an end-to-end latency of $\\Delta t_{iteration} = 9$. Multiplying the ex-\necuting time of the first iteration by the number of iterations $(k = 4)$ results in 32 cycles, while the\nactual end-to-end latency for the whole loop is 29. After iteration 1, the end-to-end latency of the\niterations becomes stable. We call the iterations before the execution times of successive iterations\nstabilize prolog $(k_{prolog} = 2, \\Delta t_{prolog} = 15)$. The overlap between two successive iterations after\nthe prolog is $\\Delta t_{overlap} = 2$. Considering the prolog and overlap results in the following equation\ndescribing the end-to-end latency of a whole loop:\n$\\Delta t = \\Delta t_{prolog} + (k - k_{prolog}) \\cdot (\\Delta t_{iteration} - \\Delta t_{overlap})$.\n(2)\nDue to the dataflow-driven nature of DNNs, the loop kernel of a DNN layer does not contain any\ncontrol-flow instructions. This means each iteration executes the same instructions with different\nmemory addresses. We assume the memory latency of consecutive iterations does not change since\naccelerators heavily rely on SRAM or standard cell memory for their on-chip memory [2, 4, 7, 9, 22]\nand because the memory access patterns are always the same. Under this assumption, we can use\nan AIDG containing at least $k_{prolog}$ iterations to determine $\\Delta t_{prolog}, \\Delta t_{iteration}, \\Delta t_{overlap}$, and $\\Delta t$.\nTo determine $k_{prolog}$, we use a fixed point computation as proposed in [16] to find the number\nof iterations until $\\Delta t_{iterations}$ becomes stable. Firstly, we calculate the minimal number of iterations"}, {"title": "7.1 Ultra Trail", "content": "For the UltraTrail accelerator, we created an ACADL model on the tensor operations level, as in-\ntroduced in section 4.3, and performed an AIDG evaluation. Moreover, we built a refined roofline\nmodel for UltraTrail. Table 1 compares different latency estimators with the cycle-accurate Ca-\ndence Xcelium RTL simulator when mapping TC-ResNet8 onto UltraTrail. Since UltraTrail only\nsupports one-dimensional data processing and convolutional layers [4] the DNNs EfficientNet and\nAlexNet can not run on this accelerator architecture because they rely heavily on two-dimensional\nconvolutional layers. Therefore, we only report results for the TC-ResNet8, which consists of one-\ndimensional convolutional and fully-connected layers. Our AIDG-based end-to-end latency esti-\nmation outperforms the refined roofline model, and the literature-reported regression model re-\ngarding PE and MAPE matching the ground truth almost precisely. Additionally, the estimation\nruntime of our approach on this abstraction level is comparable to analytical models and allows for\nfast and accurate performance estimations. The peak memory usage for estimating the end-to-end\nlatency of all layers of the TC-ResNet8 using the AIDG evaluation is 146 MiB."}, {"title": "7.2 Gemmini", "content": "Gemmini [13] is a parameterizable accelerator generator developed by UC Berkeley and is part of\nthe Chipyard [1] ecosystem. At its core, Gemmini is composed of a systolic array of DIM\u00d7DIM\nMAC units. The accelerator is complemented by a scratchpad of banked SRAMs, used to store the\nmatrix-matrix multiplication (GEMM) inputs A, B, D, and another one equipped with adder units\nknown as the accumulator, used to store the output matrix C of the computation $C = A \\cdot B + D$.\nAdditionally, Gemmini can be configured to apply activation and pooling functions to outputs\nof GEMM operations and thereby supporting on device layer fusion. A DMA engine is used to\nexchange data between the accelerator's SRAMs and the SoC's L2 cache. Gemmini works in a\ntightly-coupled manner with a RISC-V CPU by receiving custom instructions through a Rocket\nChip Co-processor (RoCC) interface. Internally, Gemmini uses a decoupled access-execute archi-\ntecture, which allows for accessing data and processing it in parallel. A reorder buffer detects\nhazards between Gemmini instructions and issues them to their respective controller in the cor-\nrect order. For our performance model comparisons, we instantiated a Gemmini accelerator with\na DIM size of 16."}, {"title": "7.3 Parameterizable Systolic Array", "content": "To validate that our ACADL-based accelerator modeling and AIDG fixed point evaluation also\nwork for parameterizable architectures, we mapped the DNNs TC-ResNet8, AlexNet, and Efficient-\nNet onto different sizes of the systolic array introduced in section 4.3.\nWe instantiated the systolic array in different sizes, which refers to the number of processing\nelements. First, we ran an AIDG whole graph evaluation, meaning all iterations were evaluated for\neach DNN/systolic array pairing. The estimated cycles from this AIDG whole graph evaluation are\nused as a ground truth for comparison (measured cycles). Second, we performed our AIDG fixed\npoint evaluation and built a refined roofline model for the parameterizable systolic array."}, {"title": "7.4 Plasticine-derived Accelerator Design Space Exploration", "content": "Plasticine [22] is a parameterizable and reconfigurable architecture for parallel patterns devel-\noped at Stanford University. Plasticine comprises Pattern Compute Units (PCUs) and Pattern Mem-\nory Units (PMUs) arranged in a checkerboard pattern. PCUs and PMUs communicate via a switch\nbox (S) interconnect, which can transfer data between units on a multi-word level. Fig. 14 shows\na block diagram of the Plasticine-derived architecture. Inside each PCU resides a SIMD pipeline\nwhich can be configured to process parallel patterns such as Map, Fold, etc. PMUs have a scratchpad\nand a reconfigurable datapath that supports different access patterns. We opted to model a param-\neterizable Plasticine-derived architecture in ACADL on the matrix operation level. Each PCU is\nrepresented by an ExecuteStage, two RegisterFiles for input and output data, and a FunctionalUnit\nthat supports tiled matrix-matrix multiplications (GEMM) and additions with fused activation and\npooling operations. The PMUs are modeled using an ACADL Memory, an ExecuteStage, and Mem-\noryAccessUnit, which supports instructions for read and write access to the Memory. The switch"}, {"title": "8 CONCLUSION", "content": "This paper presented a fast and automatic approach for the generation of accurate performance\nmodels for DNN accelerator architectures based on the Abstract Computer Architecture Descrip-\ntion Language (ACADL). Together with DNN layer mappings we construct and evaluate an Archi-\ntectural Instruction Dependency Graph (AIDG) that allows us to evaluate, in the best case, only 154\nloop kernel iterations to estimate the performance for 4.19 billion instructions. We evaluated our\napproach using four different accelerator architectures including UltraTrail, Gemmini, parameter-\nizable systolic array, and Plasticine-derived. Those architectures are modeled on different abstrac-\ntion levels going from fine-grained scalar operations up to fused tensor operations. We achieve\nbetter MAPE results than the state-of-the-art analytical latency estimators refined roofline and\nTimeloop and regression-based latency estimators without the need for creating a large training\ndataset.\nWe are confident that a fast and parameterizable modeling and performance estimation of DNN\naccelerator architectures is crucial for selecting a tailored hardware for the intended edge Al work-\nload."}, {"title": "A.1 Parameter Determination of AIDG Evaluation Fallback Heuristic", "content": "To determine the percentage of iterations that are evaluated in the case of an oscillating $\\Delta t_{iteration}$,\nwe mapped the DNNs TC-ResNet8, AlexNet, and EfficientNet onto the systolic array, introduced\nin section 4.3, of different sizes (2\u00d72, 4\u00d74, 6\u00d76, 8\u00d78, and 16\u00d716). For each mapping of each DNN\nlayer, we conducted an AIDG evaluation with a fixed point computation with different percentages\nof all iterations k for the fallback heuristic. As percentages of k, we set 0.1%, 1%, and 5% and\ncompared the estimated end-to-end latency for all layers mappings which did not satisfy the fixed\npoint criterion in equation (5) against the AIDG whole graph evaluation of those layers using\nthe MAPE. Additionally, we measured the runtime of the AIDG evaluation of each DNN layer\nmapping for the different percentages of k."}, {"title": "A.2 Effects of Oscillating $\\Delta t_{iteration}$ and $\\Delta t_{overlap}$ on the Estimation Accuracy", "content": "To determine the effects of an oscillating $\\Delta t_{iteration}$ and $\\Delta t_{overlap}$ on the estimation accuracy of the\nAIDG fixed point evaluation we mapped the DNNs TC-ResNet8, AlexNet, and EfficientNet onto\nthe systolic array of different sizes (2\u00d72, 4\u00d74, 6\u00d76, 8\u00d78, and 16\u00d716) using the same configurations\nas presented in Table 5. For each mapping, we recorded all $\\Delta t_{iteration}$ and $\\Delta t_{overlap}$ and did not stop\nthe AIDG evaluation when equation (5) was satisfied or 1% of all iterations k have been evaluated.\nFig. 17 presents the recorded $\\Delta t_{iteration}$ and $\\Delta t_{overlap}$ for different DNN layer types and configu-\nrations (1D convolution, clip, add, and fully-connected) of TC-ResNet8 mapped onto the systolic\narray of size 2\u00d72 and 4\u00d74. Each row of plots in Fig. 17 corresponds to the same layer type and\nconfiguration of TC-ResNet8. The first two columns show the recorded $\\Delta t_{iteration}$ and $\\Delta t_{overlap}$ for\nthe systolic array of size 2\u00d72, columns three and four show the recorded $\\Delta t_{iteration}$ and $\\Delta t_{overlap}$ for\nthe systolic array of size 4\u00d74. The vertical red line marks the iteration $k_{stop}$ at which the AIDG\nfixed point evaluation would have stopped because either equation (5) was satisfied or 1% of all\niterations k have been evaluated, according to the results presented in Table 5.\nFor the 1D convolutional and fully-connected layers in the first and second row of Fig. 17 the\nnumber of iterations needed to process the layers on the systolic array of size 4\u00d74 is quartered\ncompared to the number of iterations needed on the systolic array of size 2\u00d72. This is because 1D\nconvolutional and fully-connected layers have high data reuse and the input channel dimensions\nof those layer configurations are divisible by 2 and 4 which allows for an optimal utilization of pro-\ncessing elements. The number of iterations of the clip layer presented in the third row of Fig. 17\nis halved when increasing the systolic array size from 2\u00d72 to 4\u00d74 because the input channel di-\nmension is divisible by 2 and 4. Moreover, the clip layer is applied element-wise and does not have\nany data reuse. Therefore, only the first row of processing elements of the systolic array is utilized,\nwhich corresponds to a linear decrease in the number of iterations when increasing the systolic\narray size. The input channel dimensions of the add layers in the fourth and fifth row of Fig. 17 are\nnot divisible"}]}