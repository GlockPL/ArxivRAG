{"title": "Connective Viewpoints of Signal-to-Noise Diffusion Models", "authors": ["Khanh Doan", "Quyen Tran", "Long Tung Vuong", "Thanh-Toan Do", "Tuan Nguyen", "Dinh Phung", "Anh Tuan Bui", "Trung Le"], "abstract": "Diffusion models (DM) have become fundamental components of generative models, excelling across\nvarious domains such as image creation, audio generation, and complex data interpolation. Signal-to-\nNoise diffusion models constitute a diverse family covering most state-of-the-art diffusion models. While\nthere have been several attempts to study Signal-to-Noise (S2N) diffusion models from various perspec-\ntives, there remains a need for a comprehensive study connecting different viewpoints and exploring new\nperspectives. In this study, we offer a comprehensive perspective on noise schedulers, examining their role\nthrough the lens of the signal-to-noise ratio (SNR) and its connections to information theory. Building\nupon this framework, we have developed a generalized backward equation to enhance the performance\nof the inference process.", "sections": [{"title": "Introduction", "content": "Diffusion models (DM) have become a fundamental part of generative models, which excel in various domains,\nincluding creating images, generating audio, and interpolating complex data. The foundational framework\nfor these models was introduced by Sohl-Dickstein et al. (2015), and Ho et al. (2020) further refined it\nwith Denoising Diffusion Probabilistic Models (DDPMs). DDPMs add noise to data iteratively and learn to\nreverse this process, allowing them to model data distributions effectively.\nSignal-to-Noise (S2N) diffusion models Kingma and Gao (2024); Kingma et al. (2021) constitute an\nextensive class of diffusion models encompassing various other models such as variance-preserving (VP) and\nvariance-exploding (VE) DM Song et al. (2020b), iDDPM Nichol and Dhariwal (2021), DDPM Ho et al.\n(2020), EDM Karras et al. (2022), and continuous variation models Kingma and Gao (2024); Kingma et al.\n(2021). Numerous efforts have been made to study Signal-to-Noise diffusion models from various perspectives.\nNotably, Kingma et al. (2021) began with a discrete S2N diffusion model, developed its variational-based\nbackward inference, and finally examined the asymptotic behavior as the number of time steps approaches\ninfinity, resulting in a continuous variational DM. Building on the development of continuous variational DM,\nKingma and Gao (2024) further investigated S2N diffusion models in the signal-to-noise space, identifying\nconnections between diffusion objectives with different weighting formulas and simple data augmentation\ntechniques. Additionally, Kong et al. (2023) developed an information-theoretic viewpoint for S2N diffusion\nmodels in the signal-to-noise space. However, this development is limited to very specific and simple S2N\ndiffusion models in the signal-to-noise space.\nMoreover, Zhang and Chen (2022) devised a general backward SDE from a forward S2N SDE and explored\nthe deterministic backward SDE flow to propose a fast sampling approach based on exponential integrators.\nInterestingly, it can be proven that DDIM Song et al. (2020b) falls within the spectrum of this devised\nfamily. However, there has been no development for the stochastic case, which is well-known to enhance the\ndiversity of generated images. Furthermore, to summarize, there is currently no unified study connecting\nMarkovian continuous variational DM, non-Markovian continuous variational DM, backward/forward SDE,\nand the information-theoretic viewpoint of S2N diffusion models.\nIn this work, we propose connective viewpoints of S2N diffusion models. Specifically, our contribution\ncan be summarized as follows:"}, {"title": "Related Work", "content": "Diffusion models have rapidly become a cornerstone in the landscape of generative models, demonstrating\nexceptional capabilities across a variety of domains, including image synthesis, audio generation, and complex\ndata interpolation. The foundational framework of diffusion probabilistic models was first introduced by\nSohl-Dickstein et al. (2015), and this framework underwent significant refinement with Ho et al. (2020), who\ndeveloped Denoising Diffusion Probabilistic Models (DDPMs). DDPMs iteratively add noise to data and\nlearn to reverse this process, effectively modeling the data distribution through a sophisticated generative\nprocedure.\nBuilding on this foundation, subsequent research has introduced various enhancements aimed at improv-\ning the efficiency and quality of sample generation. A key development in these variants is the introduction of\nadaptive noise control mechanisms, often termed noise scheduling. This control is crucial as it determines the\nreverse diffusion trajectory, directly influencing the fidelity and diversity of the generated samples. Among\nthese innovations, the Score-Based Generative Model (SGM) introduced by Song and Ermon (2019); Song\net al. (2020b) represents a significant advancement. SGMs utilize score-based methods, as formalized by\nHyv\u00e4rinen Hyv\u00e4rinen and Dayan (2005), to guide the reverse diffusion. These methods leverage gradients\nof the data distribution to adaptively refine the generative process, producing samples that more closely\nresemble the original distribution. This approach has proven particularly effective in enhancing the visual\nand auditory quality of the generated outputs.\nAnother influential perspective is the treatment of diffusion as Continuous Normalizing Flows (CNFs),\nproposed by Lipman et al. (2022); Tong et al. (2023). This view interprets the diffusion process as a series\nof invertible transformations, facilitating smoother and more controlled transitions from noise back to data.\nThis methodology is essential for maintaining the structural integrity of complex datasets and supports a\nmore nuanced manipulation of the generative process.\nAdditionally, the precise control of noise levels, conceptualized through the Signal-to-Noise Ratio (S2N),\nhas been the focus of several studies Karras et al. (2022); Kingma and Gao (2024); Kingma et al. (2021);\nNichol and Dhariwal (2021); Song et al. (2020a). The optimization of SNR is crucial, as it impacts the\nclarity and sharpness of the generated samples. By carefully tuning the SNR during the diffusion process,\nthe model's ability to produce high-quality outputs can be significantly improved, thus avoiding common\nissues such as over-smoothing or excessive residual noise, which can degrade the performance of generative"}, {"title": "Theory Development", "content": ""}, {"title": "Problem Setting", "content": "We consider the following diffusion forward process\n$z_t = \\alpha (t) x + \\sigma (t) \\epsilon,$\nwhere $\\epsilon \\sim \\mathcal{N} (0, I)$, $x$ is generated from a data distribution, and $\\alpha, \\sigma : [0, T] \\rightarrow \\mathbb{R}_+$ are two functions\nrepresenting signal and noise of the forward process with $\\alpha (0) = 1$ and $\\lim_{t \\rightarrow T} \\frac{\\alpha(t)}{\\sigma(t)} = 0.$\nWe define $\\Lambda (t) = \\log \\frac{\\alpha(t)^2}{\\sigma(t)^2}$ specifying the log of the signal-to-noise ratio with $\\lim_{t \\rightarrow T} \\Lambda (t) = -\\infty$ or very\nlow. The above signal-to-noise (S2N) forward process can be rewritten\n$z_t = \\alpha (t) x + \\alpha (t) \\exp \\{-\\Lambda (t) / 2\\} \\epsilon,$\nwhere $\\Lambda (t)$ is a monotonic decreasing function from $\\Lambda_{\\text{max}} = \\Lambda (0)$ and $\\Lambda_{\\text{min}} = \\Lambda(T)$.\nAdditionally, S2N diffusion models constitute a highly diverse family of diffusion models that have\nachieved state-of-the-art performance in practice, as summarized in Table 1."}, {"title": "The Connective Viewpoints", "content": "SDE Viewpoint. From the definition of the forward process, we know that $q (z_t | z_0) = \\mathcal{N} (\\alpha (t) z_0, \\sigma^2 (t) I)$.\nTo realize the general transition distribution $q (z_t | z_s)$ where $0 < s < t <T$, we aim to find the SDE of the\nabove forward process. Let us consider the general form of SDE\n$dz_t = f (t) z_t dt + g (t) dw_t,$\nwhere $\\{w_t : t \\in [0; T]\\}$ is the Brownian motion, and $f (t), g (t) \\in \\mathbb{R}$.\nDenote $\\Psi (\\tau, t)$ as the transition function satisfying (i) $\\frac{d\\Psi (\\tau, t)}{dt} = -\\Psi (\\tau, t) f (t) I$, (ii) $\\frac{d\\Psi (\\tau, t)}{d\\tau} = \\Psi (\\tau, t) f (\\tau) I$,\nand (iii) $\\Psi (\\tau, \\tau) = I$. It is obvious that $\\Psi (\\tau, t) = \\exp \\{-\\int_{\\tau}^{t} f(s) ds\\} I$ satisfies (i), (ii), and (iii). The\ndistribution $q (z_t | z_s) = \\mathcal{N} (m_{t|s}, \\Sigma_{t|s})$ is a Gaussian distribution with $m_{t|s} = \\Psi (t, s) z_s$ and $\\Sigma_{t|s} =$\n$\\int_s^t \\Psi (t, \\tau)^2 g^2 (\\tau) d\\tau$. Theorem 1 whose proof can be found in Appendix A.1.1 characterizes the SDE of\nthe forward process of S2N diffusion models."}, {"title": "Experiments", "content": "Inspired by the theoretical results in Section 3, we conduct experiments to test the effectiveness of hyperpa-\nrameters participating in the backward process built based on our Corollary 1. Our experiment settings are\norganized based on work and checkpoints in EDM Karras et al. (2022)."}, {"title": "Deterministic sampling", "content": "Corollary 1 becomes deterministic when $\\rho = 0$, then the sampling process is defined as follow:\n$z_s = \\frac{\\alpha (s)}{\\alpha (t)} z_t - \\frac{1 + \\gamma^2}{1 + \\gamma} \\frac{\\gamma \\lambda' (t)}{2} \\left[ \\exp\\{\\frac{\\Lambda (t)}{2}\\} - \\exp\\{\\frac{\\Lambda (s)}{2}\\} \\right] \\exp \\{\\frac{\\lambda (t)}{2} \\} \\epsilon_\\theta (z_t, s)$\nThe traditional Euler solver method corresponds to our specific case when $\\gamma = 0$. As shown in Figure 4,\nwith the same number of NFEs, more negative $\\gamma$ makes the outcome images blurrier, while images become"}, {"title": "Stochastic sampling", "content": "We observe synthetic image quality in stochastic sampling ($\\rho = 1$) for numerous values of $\\gamma$ and $\\delta$. As\nmentioned before, setting $\\gamma = 1$ and $\\delta = 1$ allows Corollary 1 to correspond to the traditional inference\nformula 8. Similarly to deterministic sampling 4.1, different choices of $\\gamma$ and $\\delta$ can improve results when\nevaluating model performance. Figure 3 presents the FID for an unconditional CIFAR-10 (32 \u00d7 32) model\nfrom a grid search over $\\gamma$ and $\\delta$. Among the pool of candidates, the choice of ($\\gamma = 1.25, \\delta = 0.95$) yields the\nbest value for this metric and improves model performance beyond ($\\gamma = 1, \\delta = 1$), not only in this CIFAR-10\nsetting but also in an ImageNet (64 \u00d7 64) setting, as shown in Figure 2."}, {"title": "Conclusion", "content": "Diffusion models (DMs) have emerged as essential elements within generative models, demonstrating pro-\nficiency across diverse domains such as image synthesis, audio generation, and intricate data interpolation.\nSignal-to-Noise diffusion models encompass a versatile family that includes most cutting-edge diffusion mod-\nels. While various efforts have been made to analyze Signal-to-Noise (S2N) diffusion models from different\nangles, there is still a need for a comprehensive investigation that connects disparate perspectives and ex-\nplores novel viewpoints. In this work, we present an extensive examination of noise schedulers, probing their\nsignificance through the prism of the signal-to-noise ratio (SNR) and its links to information theory. Expand-\ning upon this framework, we have devised a generalized backward equation aimed at enhancing the efficacy\nof the inference process. Our experimental results show that by choosing the correct hyperparameters, our\ngeneralized equation improves model performance compared to traditional ones."}]}