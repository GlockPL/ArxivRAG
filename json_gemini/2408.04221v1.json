{"title": "Connective Viewpoints of Signal-to-Noise Diffusion Models", "authors": ["Khanh Doan", "Quyen Tran", "Long Tung Vuong", "Thanh-Toan Do", "Tuan Nguyen", "Dinh Phung", "Anh Tuan Bui", "Trung Le"], "abstract": "Diffusion models (DM) have become fundamental components of generative models, excelling across various domains such as image creation, audio generation, and complex data interpolation. Signal-to-Noise diffusion models constitute a diverse family covering most state-of-the-art diffusion models. While there have been several attempts to study Signal-to-Noise (S2N) diffusion models from various perspectives, there remains a need for a comprehensive study connecting different viewpoints and exploring new perspectives. In this study, we offer a comprehensive perspective on noise schedulers, examining their role through the lens of the signal-to-noise ratio (SNR) and its connections to information theory. Building upon this framework, we have developed a generalized backward equation to enhance the performance of the inference process.", "sections": [{"title": "Introduction", "content": "Diffusion models (DM) have become a fundamental part of generative models, which excel in various domains, including creating images, generating audio, and interpolating complex data. The foundational framework for these models was introduced by Sohl-Dickstein et al. (2015), and Ho et al. (2020) further refined it with Denoising Diffusion Probabilistic Models (DDPMs). DDPMs add noise to data iteratively and learn to reverse this process, allowing them to model data distributions effectively.\nSignal-to-Noise (S2N) diffusion models Kingma and Gao (2024); Kingma et al. (2021) constitute an extensive class of diffusion models encompassing various other models such as variance-preserving (VP) and variance-exploding (VE) DM Song et al. (2020b), iDDPM Nichol and Dhariwal (2021), DDPM Ho et al. (2020), EDM Karras et al. (2022), and continuous variation models Kingma and Gao (2024); Kingma et al. (2021). Numerous efforts have been made to study Signal-to-Noise diffusion models from various perspectives. Notably, Kingma et al. (2021) began with a discrete S2N diffusion model, developed its variational-based backward inference, and finally examined the asymptotic behavior as the number of time steps approaches infinity, resulting in a continuous variational DM. Building on the development of continuous variational DM, Kingma and Gao (2024) further investigated S2N diffusion models in the signal-to-noise space, identifying connections between diffusion objectives with different weighting formulas and simple data augmentation techniques. Additionally, Kong et al. (2023) developed an information-theoretic viewpoint for S2N diffusion models in the signal-to-noise space. However, this development is limited to very specific and simple S2N diffusion models in the signal-to-noise space.\nMoreover, Zhang and Chen (2022) devised a general backward SDE from a forward S2N SDE and explored the deterministic backward SDE flow to propose a fast sampling approach based on exponential integrators. Interestingly, it can be proven that DDIM Song et al. (2020b) falls within the spectrum of this devised family. However, there has been no development for the stochastic case, which is well-known to enhance the diversity of generated images. Furthermore, to summarize, there is currently no unified study connecting Markovian continuous variational DM, non-Markovian continuous variational DM, backward/forward SDE, and the information-theoretic viewpoint of S2N diffusion models.\nIn this work, we propose connective viewpoints of S2N diffusion models. Specifically, our contribution can be summarized as follows:"}, {"title": "Related Work", "content": "Diffusion models have rapidly become a cornerstone in the landscape of generative models, demonstrating exceptional capabilities across a variety of domains, including image synthesis, audio generation, and complex data interpolation. The foundational framework of diffusion probabilistic models was first introduced by Sohl-Dickstein et al. (2015), and this framework underwent significant refinement with Ho et al. (2020), who developed Denoising Diffusion Probabilistic Models (DDPMs). DDPMs iteratively add noise to data and learn to reverse this process, effectively modeling the data distribution through a sophisticated generative procedure.\nBuilding on this foundation, subsequent research has introduced various enhancements aimed at improving the efficiency and quality of sample generation. A key development in these variants is the introduction of adaptive noise control mechanisms, often termed noise scheduling. This control is crucial as it determines the reverse diffusion trajectory, directly influencing the fidelity and diversity of the generated samples. Among these innovations, the Score-Based Generative Model (SGM) introduced by Song and Ermon (2019); Song et al. (2020b) represents a significant advancement. SGMs utilize score-based methods, as formalized by Hyv\u00c3\u20acrinen Hyv\u00e4rinen and Dayan (2005), to guide the reverse diffusion. These methods leverage gradients of the data distribution to adaptively refine the generative process, producing samples that more closely resemble the original distribution. This approach has proven particularly effective in enhancing the visual and auditory quality of the generated outputs.\nAnother influential perspective is the treatment of diffusion as Continuous Normalizing Flows (CNFs), proposed by Lipman et al. (2022); Tong et al. (2023). This view interprets the diffusion process as a series of invertible transformations, facilitating smoother and more controlled transitions from noise back to data. This methodology is essential for maintaining the structural integrity of complex datasets and supports a more nuanced manipulation of the generative process.\nAdditionally, the precise control of noise levels, conceptualized through the Signal-to-Noise Ratio (S2N), has been the focus of several studies Karras et al. (2022); Kingma and Gao (2024); Kingma et al. (2021); Nichol and Dhariwal (2021); Song et al. (2020a). The optimization of SNR is crucial, as it impacts the clarity and sharpness of the generated samples. By carefully tuning the SNR during the diffusion process, the model's ability to produce high-quality outputs can be significantly improved, thus avoiding common issues such as over-smoothing or excessive residual noise, which can degrade the performance of generative"}, {"title": "Theory Development", "content": ""}, {"title": "Problem Setting", "content": "We consider the following diffusion forward process\n$z_t = \\alpha (t) x + \\sigma (t) \\epsilon,$\nwhere $\\epsilon \\sim \\mathcal{N} (0,1)$, x is generated from a data distribution, and $\\alpha,\\sigma : [0,T] \\rightarrow \\mathbb{R}_+$ are two functions representing signal and noise of the forward process with $\\alpha (0) = 1$ and $\\lim_{t \\rightarrow T} \\frac{\\alpha(t)}{\\sigma(t)} = 0$.\nWe define $\\Lambda (t) = \\log \\frac{\\alpha(t)^2}{\\sigma(t)^2}$ specifying the log of the signal-to-noise ratio with $\\lim_{t\\rightarrow T} \\Lambda (t) = -\\infty$ or very low. The above signal-to-noise (S2N) forward process can be rewritten\n$z_t = \\alpha (t) x + \\alpha (t) \\exp \\{-\\Lambda (t) /2\\} \\epsilon,$\nwhere $\\Lambda (t)$ is a monotonic decreasing function from $\\Lambda_{\\max} = \\Lambda (0)$ and $\\Lambda_{\\min} = \\Lambda(T)$.\nAdditionally, S2N diffusion models constitute a highly diverse family of diffusion models that have achieved state-of-the-art performance in practice, as summarized in Table 1."}, {"title": "The Connective Viewpoints", "content": "SDE Viewpoint. From the definition of the forward process, we know that $q (z_t | z_0) = \\mathcal{N} (\\alpha (t) z_0, \\sigma^2 (t) I)$. To realize the general transition distribution $q (z_t | z_s)$ where $0 < s < t <T$, we aim to find the SDE of the above forward process. Let us consider the general form of SDE\n$dz_t = f (t) z_t dt + g (t) dw_t,$\nwhere $\\{w_t : t \\in [0; T]\\}$ is the Brownian motion, and $f (t), g (t) \\in \\mathbb{R}$.\nDenote $\\Psi (\\tau, t)$ as the transition function satisfying (i) $\\frac{d\\Psi(\\tau, t)}{dt} = - \\Psi(\\tau, t) f (t) I$, (ii) $\\frac{d\\Psi(\\tau, t)}{d\\tau} = \\Psi(\\tau, t) f (\\tau) I$, and (iii) $\\Psi (\\tau, \\tau) = I$. It is obvious that $\\Psi (\\tau, t) = \\exp \\{-\\int_{\\tau}^t f(s) ds\\} I$ satisfies (i), (ii), and (iii). The distribution $q (z_t | z_s) = \\mathcal{N} (m_{t|s}, \\Sigma_{t|s})$ is a Gaussian distribution with $m_{t|s} = \\Psi (t,s) z_s$ and $\\Sigma_{t|s} = \\int_s^t \\Psi (t, \\tau)^2 g^2 (\\tau) d\\tau$. Theorem 1 whose proof can be found in Appendix A.1.1 characterizes the SDE of the forward process of S2N diffusion models."}, {"title": "Transforming S2N Diffusion Models to Signal-to-Noise Space and Information Theory Viewpoint", "content": "We denote $\\tilde{\\alpha} (\\Lambda (t)) = \\alpha(t)$ (i.e., $\\tilde{\\alpha} = \\alpha \\circ \\Lambda^{-1}$), $\\tilde{\\sigma} (\\Lambda (t)) = \\sigma(t)$ (i.e., $\\tilde{\\sigma} = \\sigma \\circ \\Lambda^{-1}$), and $\\tilde{z}_{\\Lambda(t)} = z_t$ where $\\Lambda(t) = \\log \\frac{\\alpha(t)^2}{\\sigma(t)^2}$. We have the following forward process in the signal-to-noise space\n$\\tilde{z}_{\\Lambda(t)} = \\tilde{\\alpha} (\\Lambda(t)) x + \\tilde{\\sigma} (\\Lambda (t)) \\epsilon = \\tilde{\\alpha} (\\Lambda(t)) x + \\frac{\\tilde{\\alpha} (\\Lambda (t))}{\\exp {\\Lambda (t)/2\\}} \\epsilon$\nor equivalently\n$\\tilde{z}_{\\lambda} = \\tilde{\\alpha} (\\lambda) x + \\frac{\\tilde{\\alpha} (\\lambda)}{\\exp {\\lambda/2\\}} \\epsilon,$\nwhere $\\lambda \\in [\\Lambda_{\\min}, \\Lambda_{\\max}]$ with $\\Lambda_{\\min} = \\Lambda (T)$ and $\\Lambda_{\\max} = \\Lambda (0)$.\nIn the following theorem, we answer the question which pair of $(\\alpha(t),\\sigma (t))$ induces the same forward process in the signal-to-noise space.\nInformation-Theoretic viewpoint of S2N DM in the signal-to-noise space. Information theoretic viewpoint was studied in Kong et al. (2023) for a very simple diffusion process: $\\tilde{z}_{\\lambda} = \\sqrt{\\lambda} x + \\epsilon$. In what follows, we present the information-theoretic results for the general S2N diffusion model in the signal-to-noise space (11).\nGiven x, we define the Minimum Mean Square Error (MMSE) for recovering x in the noisy channel\n$\\operatorname{mmse} (\\lambda) := \\min_{\\hat{x} (\\tilde{z}_{\\lambda}, \\lambda)} \\mathbb{E}_{p(\\tilde{z}_{\\lambda}, x)}[||x - \\hat{x} (\\tilde{z}_{\\lambda}, \\lambda) ||^2],$\nwhere $\\hat{x} (\\tilde{z}_{\\lambda}, \\lambda)$ is referred to as a denoising function. The optimal denoising function $\\hat{x}^*$ corresponds to the conditional expectation, which can be seen using variational calculus or from the fact that the squared error is a Bregman divergence\n$\\hat{x}^* (\\tilde{z}_{\\lambda}, \\lambda) = \\operatorname{argmin}_{\\hat{x} (\\tilde{z}_{\\lambda}, \\lambda)} \\mathbb{E}_{p(\\tilde{z}_{\\lambda}, x)}[||x - \\hat{x} (\\tilde{z}_{\\lambda}, \\lambda) ||^2] = \\mathbb{E}_{x \\sim p(x|\\tilde{z}_{\\lambda})} [x].$\nMoreover, the point-wise MMSE is defined as follows:\n$\\operatorname{mmse} (x, \\lambda) := \\mathbb{E}_{p(\\tilde{z}_{\\lambda}, x)} [||x - \\hat{x}^* (\\tilde{z}_{\\lambda}, \\lambda) ||^2] .$\nThe mutual information $I (x, \\tilde{z}_{\\lambda})$ can be characterized in the following theorem."}, {"title": "Experiments", "content": "Inspired by the theoretical results in Section 3, we conduct experiments to test the effectiveness of hyperparameters participating in the backward process built based on our Corollary 1. Our experiment settings are organized based on work and checkpoints in EDM Karras et al. (2022)."}, {"title": "Deterministic sampling", "content": "Corollary 1 becomes deterministic when $\\rho=0$, then the sampling process is defined as follow:\n$z_s = \\frac{\\alpha (s)}{\\alpha (t)} \\frac{1}{1 + \\gamma^2} z_t + \\frac{\\gamma \\lambda (t)}{2} \\sqrt{[\\exp {-\\lambda(t)} - \\exp {-\\lambda(s)}]} \\exp {\\frac{x(t)}{2} }\\epsilon_\\theta (z_t,t)$"}, {"title": "Stochastic sampling", "content": "We observe synthetic image quality in stochastic sampling ($\\rho=1$) for numerous values of $\\gamma$ and $\\delta$. A\u03c2 mentioned before, setting $\\gamma=1$ and $\\delta=1$ allows Corollary 1 to correspond to the traditional inference formula 8. Similarly to deterministic sampling 4.1, different choices of $\\gamma$ and $\\delta$ can improve results when evaluating model performance."}, {"title": "Conclusion", "content": "Diffusion models (DMs) have emerged as essential elements within generative models, demonstrating proficiency across diverse domains such as image synthesis, audio generation, and intricate data interpolation. Signal-to-Noise diffusion models encompass a versatile family that includes most cutting-edge diffusion models. While various efforts have been made to analyze Signal-to-Noise (S2N) diffusion models from different angles, there is still a need for a comprehensive investigation that connects disparate perspectives and explores novel viewpoints. In this work, we present an extensive examination of noise schedulers, probing their significance through the prism of the signal-to-noise ratio (SNR) and its links to information theory. Expanding upon this framework, we have devised a generalized backward equation aimed at enhancing the efficacy of the inference process. Our experimental results show that by choosing the correct hyperparameters, our generalized equation improves model performance compared to traditional ones."}]}