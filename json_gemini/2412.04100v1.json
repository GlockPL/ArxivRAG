{"title": "Missing Melodies: Al Music Generation and its \"Nearly\" Complete Omission of the Global South", "authors": ["ATHARVA MEHTA", "SHIVAM CHAUHAN", "MONOJIT CHOUDHURY"], "abstract": "Recent advances in generative AI have sparked renewed interest and expanded possibilities for music genera- tion. However, the performance and versatility of these systems across musical genres are heavily influenced by the availability of training data. We conducted an extensive analysis of over one million hours of audio datasets used in AI music generation research and manually reviewed more than 200 papers from eleven prominent AI and music conferences and organizations (AAAI, ACM, EUSIPCO, EURASIP, ICASSP, ICML, IJCAI, ISMIR, NeurIPS, NIME, SMC) to identify a critical gap in the fair representation and inclusion of the musical genres of the Global South in AI research.\nOur findings reveal a stark imbalance: approximately 86% of the total dataset hours and over 93% of researchers focus primarily on music from the Global North. However, around 40% of these datasets include some form of non-Western music, genres from the Global South account for only 14.6% of the data. Furthermore, approximately 51% of the papers surveyed concentrate on symbolic music generation, a method that often fails to capture the cultural nuances inherent in music from regions such as South Asia, the Middle East, and Africa. As AI increasingly shapes the creation and dissemination of music, the significant underrepresentation of music genres in datasets and research presents a serious threat to global musical diversity. We also propose some important steps to mitigate these risks and foster a more inclusive future for AI-driven music generation.", "sections": [{"title": "1 Introduction", "content": "Music has always been a crucial element in representing the traditions of different communities worldwide [29]. With recent developments in AI, particularly through the use of deep learning models [2, 10, 26, 30], there has been a dramatic improvement in generating music automatically.\nThese advancements have led to the creation of various AI-driven music platforms, such as Jukebox [12], Suno, Udio, etc, giving users the ability to create music based on their preferences. Dysart [14] noted, \"AI-generated music could easily surpass the amount of music that has ever been recorded, due to how quickly it can be produced.\" This is largely because AI systems are capable of producing music around the clock without the limitations faced by human composers, such as time constraints. Several studies [33, 35] reveal that biases persist in AI music generation, including popularity, evaluation, and training data biases, particularly against Global South genres. Models like Copet et al. [10], Melechovsky et al. [26] often default to Western tonal structures when generating non-Western music such as Indian classical or traditional Middle Eastern genres, let alone lesser-known styles and genres such as the Baul, and instruments such as the Gonje(see Appendix A.4). As a result, a generated piece intended to mimic an Indian raga may sound like a Western pop melody played on a sitar. Similarly, SunoAI, when attempting to generate Maqam, (definition in Appendix A.4), may round off the microtones to the nearest Western equivalent, resulting in a piece that lacks the distinctive sound of Arabic music. As generative models continue to gain traction in the field of music generation, the misrepresentation and under-representation of the musical genres of the \u201cglobal majority\" poses a significant threat to the inclusion of musical genres from around the world. The skewed distribution in datasets, reflected in model outputs, can lead to several issues, including cultural homogenization, reinforcement of Western culture dominance [11], misrepresentation of musical styles, and most importantly gradual decline leading to the disappearance of many musical genres [25, 32, 34]. Drawing inspiration from studies such as Joshi et al. [19] and Bender and Friedman [4] which systematically analyze the under-representation"}, {"title": "2 Research Methods and Materials", "content": "To collect our initial pool of papers, we implemented an automated, keyword-based approach using the Scholarly package [6], which retrieved approximately 5000 papers. Queries included terms like \"music,\" \"music generation,\" and \"symbolic music.\" This method allowed us to efficiently focus on relevant research while avoiding manual errors. We refined the pool to 800 papers from eleven major conferences and organizations such as AAAI, ACM, ICASSP, NeurIPS, and ISMIR, chosen for their relevance and reputation.\nFrom this refined pool, 152 papers proposing datasets were identified through title and abstract reviews. These datasets, collectively containing over one million hours of music, were annotated for region, genres, total hours, and additional metadata such as instruments or styles. However, 7.9% of the datasets (totaling 5,772 hours) were excluded due to insufficient details on genre or region. For large datasets with over 10,000 hours of audio, we analyzed sound file metadata to extract this information where available.\nTo identify generative AI papers, we applied a second round of keyword filtering (e.g., \"generative AI,\" \"transformers\") on titles and abstracts, resulting in 244 papers. These were annotated for genres and regions, with regional classification based on the first author's institutional affiliation. For example, a paper authored by someone at a French institution was labeled as European. This classification highlighted where research on AI-driven music generation is being conducted.\nWe selected PANN-CNN14 [18] and VGGish as backbone models for evaluation, both of which convert music samples into fixed representations for metrics like Fr\u00e9chet Audio Distance (FAD) [21] and KL divergence [22].\nPANN-CNN14 was trained on the AudioSet dataset [17], which has a uniform clip length of 10 seconds. We analyzed the genre and region distribution based on the AudioSet Ontology metadata, which mirrors the sample count due to consistent clip duration.\nVGGish was trained on YouTube-8M [1], where we focused on the \"Art & Entertainment\" category to map genres and regions. With 6.1 million instances varying in length (120\u2013500 seconds), the distribution was analyzed by the number of instances, as metadata lacked total hours per class. To evaluate the models' capability in representing diverse instruments, we compared global instruments (e.g., guitar, piano, drums) and regional instruments (e.g., sitar, tabla, bagpipes) in their training datasets."}, {"title": "3 Findings", "content": "As shown in Figure 1, Pop music has the highest (20.7%) representation followed by Rock (17%) and Classical (13.5%) genres. Country, hip-hop, blues and jazz have a moderate (more than 5%) representation in the collection. Folk and experimental music contribute to only 2.1% of the collection. The other genres receive minimal attention (\u2264 1%) which includes music for Children, Indie-music, and region-specific genres. We can see from the table in Appendix A.2 that Pop music forms 200K+ hours of the collection while Folk music constitutes only 20K hours of the collection.\nFigure 1 presents a striking heatmap illustrating the imbalance in dataset representation, with the Global South marked in blue and the Global North in red. Our analysis reveals that more than 6,000 hours of music in the research dataset belong to European music, whereas only 28 hours represent African music, as detailed in Appendix A.3. Music from the Global North is well represented, constituting 85.9% of the collection. In contrast, music from South Asia and the Middle East is underrepresented, each contributing approximately 5%. Furthermore, music from Central Asia and Africa each accounts for less than 1% of the entire collection, effectively rendering them unrepresented in the dataset.\nUpon analyzing the datasets used to train backbone models for evaluating music generation, we observed a strong emphasis on global instruments such as guitar, drums, and piano compared to regional instruments. From table in Appendix A.1 we can infer that guitar, piano, and drums \u2013commonly used in music from the Global North constitute 52.33% and 67.54% of the collection in the VGGish and PANN models respectively. In contrast, instruments like sitar, tabla, clarinet, bagpipes, accordion, and bassoon each have less than 2% and 3% representation in the collection. This imbalance favours globally prevalent instruments over regional ones, leading to skewed evaluations and inaccurate vector spaces that misrepresent regional instruments and diverse musical styles.\nFigure 2 shows that Classical music is the most prominent genre in research, accounting for 36.5% of the total papers across various conferences in our collection. Electronic music, with a substantial 14.9%, and Pop, at 13.3%, follow as the next most studied genres. These genres likely benefit from a high volume of accessible data and established digital formats, making them more conducive for research. Conferences such as ICASSP and ISMIR have a strong representation of Classical, Pop, and Electronic genres while NIME and AAAI showcase a diverse genre distribution, including Avant-garde & Experimental genres, indicating these venues' some openness to exploring other genres also. Genres like Jazz (6.7%), Rock (3.5%), and Folk (2.7%) receive moderate attention, suggesting a valuable exploration of these genres in AI music. Country and Easy Listening are notably underrepresented in research, as seen by their minimal paper counts in most conferences.\nFigure 1 highlights significant disparities in affiliations of researchers, underscoring the under-representation of the Global South. Approximately 88% of research papers originate from researchers affiliated with institutions in the Global North, in contrast, only about 12% of the research papers feature contributions from researchers affiliated with institutions in the Global South. The table in Appendix A.3 shows that regions leading in terms of researcher affiliations are East Asia (84 papers), Europe (70 papers), and America (75 papers),"}, {"title": "4 Why Does it Matter?", "content": "The under-representation of Global South music genres in AI-driven music generation poses a serious threat to cultural diversity. As AI becomes integral to the music industry, the rich and vibrant traditions of the Global Majority risk being eroded or extinct [31], leading to a homogenized global music landscape. This section explores the implications of this marginalization and offers actionable recommendations to mitigate potential risks.\nColonization and technological progress have historically favored those who create and propagate the technology, often at the expense of marginalized groups and their cultures [9]. Lund [25] critiques Western dominance in global pop narratives, showing how local genres in regions like Turkey, Brazil, and Peru gain recognition only through Western attention, reshaping their value domestically. Similarly, Collins and Grierson [8] warns that AI in music could reinforce this dynamic, monopolizing musical history and promoting select genres, metaphorically \"rewriting\" all music with \"Taylor's Versions.\" Our analysis shows that genres from the Global South are underrepresented in training datasets, limiting models' ability to capture their richness and diversity.\nThe exclusion of Global South music genres from AI training datasets limits the potential for these genres to evolve and adapt in the digital age. By not being part of the AI-driven creative process, these genres may miss out on opportunities to innovate and reach new audiences, potentially stagnating while other genres continue to develop in exciting new directions.\nFocus on Global North music in AI-generated content could further worsen the economic disparities within the music industry. Musicians from the Global South [27] may find it even more challenging to gain recognition if their genres are not adequately represented, further increasing the economic divide between the Global North and South [16].\nBy focusing primarily on Global North music datasets [34], AI models may inadvertently reinforce existing cultural biases, perpetuating a cycle where Global South music is viewed as less important or less valuable. For instance, Longoria [24] claims that the people of the Global South encounter barriers such as lack of representation in the music they study and in organizational leadership, alongside systemic bias. AI could further marginalize musicians and composers from non-Western backgrounds.\nGenres like Hindustani folk, traditional Arabic Maqam, and others, are repositories of centuries-old traditions, philosophies, and artistic expressions. If AI systems continue to prioritize Western music, these rich traditions could fade from the public mind, leading to cultural erosion."}, {"title": "4.2 Recommendations", "content": "The global musical landscape evolves through economic, technological, and social forces, alongside efforts to amplify diversity and decolonize music studies Tan [32]. In AI-generated music, fostering inclusivity requires intentional actions. While egalitarian approach to genres is challenging [7], the research community can adopt strategies to better include diverse musical traditions:\nMusic generation papers should explicitly state the genres used for training and evaluation, akin to the Bender Rule in NLP [4], to ensure clarity and prevent misinterpretations. Additionally, they should acknowledge model limitations, such as symbolic music's inability to capture microtonal variations (e.g., Shrutis, Appendix A.4), encouraging improvements and highlighting underrepresented genres.\nEven the most inclusive models may struggle with under-represented or unrepresented genres. It is essential to issue warnings for the former and avoid generating samples for the latter to ensure users understand potential inaccuracies and prevent distortions in the digital music space. Table 1 outlines the associated issues, risks, and recommendations.\nThe Masakhane Project [28] highlights the impact of community-driven efforts in building diverse, regional datasets. A similar approach in music data collection could address the underrepresentation of Global South genres. While genres like Hip-Hop are digitally prominent, they are underrepresented in research [5], emphasizing the need for diverse regional and genre coverage. Initiatives like Google's Inclusive Images Competition [3] demonstrate how AI models can be designed to generalize across cultural and geographic diversity, a principle applicable to music generation.\nSimilar to language research, where transfer learning aids low-resource languages [20, 23, 38], music research should explore sample-efficient cross-genre transfer for styles, instruments, and melodic structures [13].\nFor most genres, model performance remains unclear due to insufficient genre-specific evaluations or reporting. Studies like Xiong et al. [36] and Yang and Lerch [37] emphasize the limitations of formative assessments and the need for subjective evaluation in AI-generated music. Additionally, as noted in Section 3.1.3, backbone models require fine-tuning on diverse music styles to avoid misrepresenting different styles."}, {"title": "5 Conclusion", "content": "This article highlights an important gap in AI-driven music generation: the noticeable lack of representation of music genres from the Global South. While AI tools have made incredible progress in generating music, they overwhelmingly focus on genres from the Global North, leaving out many unique and culturally rich styles from regions like Africa, Latin America, South Asia, and the Middle East. This imbalance not only risks the erasure of many under-represented (in AI space) musical genres of the world but also limits the potential of AI to serve as a truly global creative tool.\nWe also provided several recommendations that the AI-music research community could follow to mitigate these risks. While many of the recommendations, such as transparency about genres and avoidance of generation when not confident, can be implemented by individuals and groups in their research, several others will need community-level cooperation. This article is a call for such large-scale community-level initiatives that can make a significant positive impact on the diversity and inclusion of Al music research."}, {"title": "A Tabular Data and Definitions", "content": "(1) The Bauls are mystic minstrels from the Bengal region spread across India and Bangladesh, blending Sufism and Vaishnavism in songs about the love between the human soul and a personal god within.\n(2) The Gonje is a one-stringed West African fiddle, often made with a snakeskin-covered gourd and horsehair string, played solo or in ensembles with other traditional instruments.\n(3) Maqam, in traditional Arabic music, is a melodic mode system defining pitches, patterns, and improvisation, central to Arabian art music, with 72 heptatonic scales.\n(4) The Shruti, in Indian Classical, is the smallest interval of pitch that the human ear can detect and a singer or musical instrument can produce."}]}