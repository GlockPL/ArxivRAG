{"title": "Gendered Words and Grant Rates: A Textual Analysis of Disparate Outcomes\nin the Patent System", "authors": ["Deborah Gerhardt", "Miriam Marcowitz-Bitton", "W. Michael Schuster", "Avshalom Elmalech", "Omri Suissa", "Moshe Mash"], "abstract": "This study examines gender disparities in patent law by analyzing the textual content of\npatent applications. While prior research has primarily focused on the study of metadata (i.e., filing\nyear or technological class), we employ machine learning and natural language processing\ntechniques to derive latent information from patent texts. In particular, these methods are used to\npredict inventor gender based on textual characteristics. We find that gender can be identified with\nnotable accuracy\u2014even without knowing the inventor's name. This ability to discern gender\nthrough text suggests that anonymized patent examination\u2014often proposed as a solution to\nmitigate disparities in patent grant rate may not fully address gender-specific outcomes in\nsecuring a patent.\n\nOur analysis additionally identifies gendered differences in textual choices within patent\ndocuments and the fields in which inventors choose to work. These findings highlight the complex\ninteraction between textual choices, gender, and success in securing a patent. As discussed herein,\nthis raises critical questions about the efficacy of current proposals aimed at achieving gender\\parity and efficiency in the patent system.", "sections": [{"title": "Background", "content": "Every year, the United States Patent and Trademark Office (USPTO) receives over 600,000\npatent applications. The vast majority are filed and prosecuted by a patent agent or an attorney.\nAfter filing, the USPTO assigns a patent examiner with subject matter expertise to evaluate\nwhether the claimed invention is patentable. If multiple statutory requirements are satisfied, a\npatent will be granted.\n\nAlthough women constitute more than half of the U.S. population, they represented only\n12.8% of inventors who were granted a patent in 2019. In this study, we aim to leverage machine\nlearning techniques to gain latent insights into the factors contributing to such disparities.\n\nBeyond simple inventor counters, gendered differences in patenting outcomes have been\nresearched in several studies. Jenson, Kov\u00e1cs and Sorenson analyzed 2.7 million US patent\napplications and concluded that women applicants succeeded in securing patents less frequently\nthan men. Schuster, Davis, Schley, and Ravenscraft examined 3.9 million applications and\nreached similar conclusions. Both studies found evidence that the ability to identify an inventor's\ngender from their name contributed to gender-disparate outcomes.\n\nTaking these findings as a starting point, we embark on the task of addressing whether\nvariables beyond gender-specific names contribute to this gap. To explore that question, we\nanalyze not only the metadata of patent applications (e.g., filing year, subject matter, inventor\nattributes, etc.) but the written text contained of patent applications."}, {"title": "Data", "content": "To test our expectations regarding gender and textual choices in patent law, we amassed a\ndataset of approximately 270,000 published applications filed between 2013 and 2020, inclusive. Each of these entries included the application number, the abstract, the filing year, and dummy\nvariables for men inventors, women inventors, and applicants claiming \"small entity\" status. We\nsorted the applications by technological field using the assigned USPC (United States Patent\nClassification) class and by allocating applications into one of 8 technological fields associated\nwith the art unit it was assigned to at the USPTO. Using USPTO data, we coded the outcome of\neach application as patented, abandoned, or pending as of June 22, 2022.\n\nThe scope of our study was intentionally limited to remove potential noise that could\nmuddy our efforts to identify trends associated with the inventor's gender. To focus on direct links\nbetween gender, patent attributes, and outcomes, we identified applications naming a single United\nStates inventor. This allowed us to draw a direct link between inventor gender and relevant patent\nattributes and outcomes. By limiting the data to single inventor applications, we did not have to\nquestion whether one inventor might have caused a particular outcome or behavior-especially in\nmixed-gender teams. We recognize that limiting our dataset to single inventor teams may present\ncertain biases (e.g., if single inventors tend to invent in certain areas or hire patent attorneys of a\ncertain quality). However, we accepted this limitation to assure we were analyzing direct links\nbetween inventor gender and patent outcomes.\n\nWe also limited our applications to U.S.-based inventors because due to cultural\ndifferences, foreign inventor behaviors may vary in a manner that is dissimilar to U.S. inventors.\nThese possibilities might have introduced noise into the associations we intend to study-namely\npatenting behaviors or outcomes that are disproportionately associated with inventors of a\nparticular gender.\n\nOur dataset includes only utility patent applications that did not claim priority through an\nearlier filing, except for priority claims to national stage entries or provisional applications. The\nchoice to study only utility applications excluded design patents, plant patents, provisionals,"}, {"title": "Data Cleaning and Pre-Processing", "content": "To improve the quality and reliability of our analysis, we conducted additional cleaning of\nthe data. First, we removed duplicate abstracts. While we attempted to remove repeated abstracts\nby excluding applications making priority claims (other than claims to foreign filings or\nprovisionals), we found a small percentage (2,489 of our 272,401 applications amounting to .91%)\nof repeated abstracts. Due to the low percentage of data represented by these repeated entries, we\nremoved them to avoid double-counting.\n\nNext, we sorted the applications into USPC classes. During the exploratory data analysis\n(EDA) process, we discovered that the column representing patent classes from the PatEx dataset\ncontains 839 distinct values. According to the USPC website, there should be approximately 400"}, {"title": "Descriptive Statistics", "content": "The applications in our data were filed between 2013 and 2020. After cleaning and pre-\nprocessing, the dataset contained 255,728 records with 37 columns. We divided the applications\ninto 8 broader subject-matter categories by the USPTO-assigned examination group. The most\ndominant categories are Transportation (26.02%) and Mechanical Engineering (25.16%), which\ncompose 51.18% of the data. The remaining categories are: Semiconductors (13.78%),\nCommunications (8.27%), Chemical and Material Engineering (7.99%), Computer Networking\n(6.81%), Computer Architecture (6.12%), and Biotechnology (5.83%).\n\nAs noted above, the gender representation is highly imbalanced. Within our dataset, the\nMan:Woman ratio remained at 8.76:1 after cleaning. The ratio varied across each of our eight\ntechnological categories. As shown in Figure 1, Mechanical Engineering constituted the largest\npercentage of applications from women inventors; Transportation was the highest percentage for\nmale inventors. Biotechnology is a dominant category for female applications (when comparing\nthe percent of applications by gender by field), while Semiconductors is a dominant category for\nmale applications. These trends are consistent with prior research."}, {"title": "Hypotheses and Research Methods", "content": "After creating our dataset and conducting descriptive analysis, we began testing the data to\ndetermine whether textual analysis can teach us more about the gender disparity in patent\napplications. To advance this goal, we tested three hypotheses. Due to the low absolute number of\napplications filed by women in several categories, we tested our hypotheses on the Transportation\nand Mechanical Engineering categories, which compose 51.18% of the data and have a sufficient\nnumber of applications filed by women to reflect statistically reliable results.\n\nHypothesis 1: It is possible to predict the gender of the inventor based on the content of\nthe patent abstract.\n\nThis hypothesis is based on an analysis of dominant word usage within our abstracts by\ngender. To explore this question, we used unigrams and bigrams. A unigram is a single token (e.g.,\na word) and a bigram is a set of two words in a particular order. On a macro level, an Ngram is\na particular string of terms (in a particular order) consisting of N words. The table below describes\nparticular Ngrams that only appear in the top 50 Ngrams for one gender (and not the other). Thus,\nan Ngram that appears in the top 50 for applications from men and women inventors will not\nappear on either list.\n\nHypothesis 2: It is possible to predict the outcome of a patent application based on text\ncharacteristics and topics."}, {"title": "Data Analysis", "content": "We begin with Hypothesis 1 to see if inventor gender can be predicted from the abstract's\ncontent. Using two distinct text classification models, we were able to predict the inventor's gender\ncorrectly 57-68% of the time.\n\nWe employed a machine learning model to classify textual aspects of abstracts to determine\nif the model can predict whether the inventor is a woman or a man. To prepare our \u201cclean abstracts\u201d\nfor analysis, we eliminated stop words and normalized different versions of the same word (e.g.,\nsingular and plural).\n\nOur first model used a Logistic Regression Classifier. This approach is commonly\nemployed for binary classifications\u2014such as the current prediction of an inventor's gender. We\nused a TFIDF Matrix (\u201cTerm Frequency-Inverse Document Frequency\u201d) to convert the text data\ninto a numerical format that a machine learning model can process.\n\nThe TFIDF matrix takes each input (e.g., an abstract) and transforms it into a vector of\nnumbers representing the importance of all terms appearing in the dataset (i.e., the body of text).\nFrom there, logistic regression uses these vectors to learn patterns that may be used to classify text\ninto categories (e.g., male or female inventor) based on their textual content.\n\nOur second classification model is based on DeBERTa (\u201cDecoding-enhanced BERT with\nDisentangled Attention\u201d). DeBERTa is a transformer-based model that may be used to analyze\ncomplex language by capturing nuanced relationships within the text. Its advanced approach to\nnatural language processing leverages self-attention mechanisms (i.e., understanding the\ndependencies and relationships between words in the text) to better understand the context and\nsemantics of an abstract's content.\n\nWe fed our abstracts into the DeBERTa model, which processes the text through multiple\nlayers of self-attention and feed-forward neural networks to generate contextual embeddings.\nThese embeddings encapsulate the meaning and context of each word in relation to the entire\nabstract, providing a richer representation for classification.\n\nTo train our classifiers, we coded the target variable (i.e., inventor gender) into numeric\nvalues: 0 representing \u201cMale\u201d and 1 representing \u201cFemale.\u201d Considering the highly imbalanced\nnature of the dataset (about 9 male inventors for every female inventor), an under-sampling\napproach was adopted. The classifiers were run nine times, each time using a different random"}, {"title": "Hypothesis 2 \u2013 Predicting Patent Grant", "content": "In this part, we investigate Hypothesis 2, which proposes that a classifier can predict\nwhether a patent application will be granted or denied. As discussed below, our evidence supports\nthis hypothesis. Moreover, we identified traits of patent applications that help predict whether a\npate"}]}