{"title": "MOST: MR reconstruction Optimization for multiple downStream Tasks via continual learning", "authors": ["Hwihun Jeong", "Se Young Chun", "Jongho Lee"], "abstract": "Deep learning-based Magnetic Resonance (MR) reconstruction methods have focused on generating high-quality images but they often overlook the impact on downstream tasks (e.g., segmentation) that utilize the reconstructed images. Cascading separately trained reconstruction network and downstream task network has been shown to introduce performance degradation due to error propagation and domain gaps between training datasets. To mitigate this issue, downstream task-oriented reconstruction optimization has been proposed for a single downstream task. Expanding this optimization to multi-task scenarios is not straightforward. In this work, we extended this optimization to sequentially introduced multiple downstream tasks and demonstrated that a single MR reconstruction network can be optimized for multiple downstream tasks by deploying continual learning (MOST). MOST integrated techniques from replay-based continual learning and image-guided loss to overcome catastrophic forgetting. Comparative experiments demonstrated that MOST outperformed a reconstruction network without finetuning, a reconstruction network with na\u00efve finetuning, and conventional continual learning methods. This advancement empowers the application of a single MR reconstruction network for multiple downstream tasks. The source code is available at: https://github.com/SNU-LIST/MOST", "sections": [{"title": "I. INTRODUCTION", "content": "MAGNETIC Resonance Imaging (MRI) has gained considerable prominence in clinical practice due to its inherent advantages including soft tissue sensitivity, non-invasiveness, and no radiation exposure. The advent of deep learning-based techniques has ushered in a new era of innovation in MRI such as disease classification [1-4], tumors or lesions segmentation [5, 6], acquisition [7], and image processing [8, 9]. In particular, the scan time reduction has been a target of innovation and various reconstruction neural networks have been proposed, yielding high-quality images even from highly undersampled k-space data [10-12]. When evaluating reconstructed images, the gold-standard is the assessment by radiologists, which is often impractical due to high expense. Consequently, many studies rely on quantitative metrics such as the Structural Similarity Index (SSIM) and Peak Signal-to-Noise Ratio (PSNR) [12, 13]. Despite the utility, such metrics have limitations in reflecting the evaluation of radiologists. More importantly, when the reconstruction network is connected to a downstream task network (e.g., segmentation network), optimizing these metrics in the reconstruction network has been shown to deliver suboptimal outcomes in the downstream task [14, 15]. As a result, efforts have been made to design a \"downstream-oriented\" reconstruction network, optimizing it based on the performance of downstream tasks [16-19]. So far, however, these methods are designed for a single downstream task (Fig. 1a). Hence, when multiple downstream tasks exist, the current solution is to develop multiple reconstruction networks each of which is optimized for individual tasks, which may not be practical.\nIn this study, we propose an approach that one can optimize a reconstruction network for multiple downstream tasks. Simple expansion from single-task to multi-task optimization is not straightforward [20]. Therefore, we consider a realistic scenario where the reconstruction network is sequentially finetuned for pretrained downstream task networks, assuming limited access to the training dataset of ready-trained tasks. (Fig. 1b) This sequential finetuning strategy reduces the computational burden of processing the entire dataset for all previous tasks and handles real-world environments where multiple downstream tasks are progressively developed and introduced.\nWhen sequentially training a reconstruction network for multiple downstream tasks, one may consider na\u00efve finetuning for the current task. This approach, however, can lead to a well-known issue of catastrophic forgetting, where performance on previously optimized tasks degrades substantially [21-25]. To overcome this issue and sustain the performances for the multiple downstream tasks, we propose to embrace the notion of continual learning [26, 27] and tailor it to our approach. Our contributions are summarized as follows:\n1. We enable an MR reconstruction network to be sequentially finetuned for multiple downstream tasks."}, {"title": "II. RELATED WORKS", "content": "With the advent of deep learning-based image processing, the deep neural network has emerged as a powerful tool for MR reconstruction [28]. Initially, end-to-end supervised networks were employed, taking undersampled k-space data (or aliased image) as input and generating fully sampled k-space data (or aliasing-free image) [29-31]. Then, model-based frameworks were developed, which enforce the forward model of k-space undersampling. These methods typically incorporate an unrolled network structure [10, 11], which alternates between neural network and data consistency, resulting in robust and high-quality reconstruction for various undersampling factors and image contrasts.\nComputer vision techniques such as classification and segmentation have been successfully adopted for the clinical evaluation of MRI images [32]. Classification techniques are used for diagnosing diseases such as Alzheimer's disease [33], Parkinson's disease [4], Schizophrenia [34], and brain tumor [35]. In the case of segmentation, a lesion segmentation network is used for localizing the region of the brain associated with brain tumor [6], ischemia [5], or multiple sclerosis [36]. Segmentation is also applied to segment sub-structures of the brain [37, 38].\nContinual learning enables a neural network to learn from new data over time without forgetting previously learned information, hence, preventing catastrophic forgetting. Continual learning algorithms aim to address this challenge by enabling a network to retain previously acquired knowledge while adapting to new data. A popular approach is a replay- based algorithm, which stores subsets of past task data and utilizes them during the training process of the current task. In MRI, the deployment of continual learning has recently been suggested only in a few segmentation studies. One example is the sequential training of a segmentation network for cardiac segmentation over scanner types [39]. A similar strategy of sequential training over scanner type was adopted for the segmentation of brain tissues [40]. Another application was sequential training of a segmentation network starting with normal brain structures and subsequently on the white matter lesions [41]."}, {"title": "III. METHODS", "content": "Accelerated MRI reconstruction aims to produce high- quality images from undersampled k-space data, making them comparable to fully sampled data. Traditionally, an MR reconstruction model denoted as fr with parameter \u03b8, is trained using the fidelity loss function LR such as SSIM loss where x represents an aliased image, and y represents an aliasing-free label image:\n$\\theta^* = \\underset{\\theta}{\\text{argmin}} L_R(f_r(x; \\theta), y).$ (1)\nHowever, when this reconstructed network is used for a downstream task such as segmentation and classification, a simple cascade of independently trained reconstruction network and downstream network might not be optimal. For example, the reconstructed images may have different characteristics from the images trained for the downstream network due to the imperfection of the reconstruction network or domain gaps between the two training datasets. To address this issue, finetuning of the reconstruction network with end-to-end data (cf., data pairs of aliased image and downstream task label) using a corresponding loss function is a valuable approach (Fig. 1a) [16-19]. This task-oriented reconstruction optimization can be written as follows:\n$\\theta_{task}^* = \\underset{\\theta}{\\text{argmin}} L(f_d(f_r(x; \\theta)), z),$ (2)\nwhere fd is the downstream task network, L is the corresponding loss function (e.g., cross-entropy for classification or DICE loss for segmentation), and z is the label (e.g., classification label or segmentation map).\nWhen multiple downstream tasks exist, the task-oriented optimization for multiple downstream tasks (t = 1,2,3,\u2026, T) can be rewritten as follows:\n$\\theta_{multi-task}^* = \\underset{\\theta}{\\text{argmin}} \\mathbb{E}_t L_{t}(f_{d_t}(f_r(x_t; \\theta)),z_t),$ (3)\nwhere Lt is the loss function of t-th downstream tasks, ft d is the downstream task network. The end-to-end dataset of finetuning for t-th downstream task $D_t = \\{(x_i, z_i)\\}_{i=1}^{Z_t}$, includes an aliased image x and a downstream task label z with the size of nt. However, such multi-task learning is difficult to be optimized [20] and does not adapt well to real-world applications. In this work, we propose to apply continual learning for a single reconstruction network such that it can be sequentially finetuned for multiple downstream tasks (Fig. 1b). Our scenario assumes limited access to ready-trained datasets due to privacy concerns and computational costs. Initially, the reconstruction network fr is trained exclusively for image reconstruction using a loss function (LR) and a reconstruction dataset (DR) as written in (1). Then, we sequentially finetune the reconstruction network for multiple downstream tasks:\n$\\theta^*_t = \\underset{\\theta}{\\text{argmin}} L_{d_t}(f_{d_t}(f_r(x_t; \\theta)), z_t).$ (4)\nIt is important to stress that the finetuning process exclusively targets the reconstruction network while downstream networks are fixed. When finetuning for the t-th downstream task, we assume that access to the full dataset of the previous downstream task (Dp, p < t) is restricted and only a small subset of the dataset is available.\nFor the reconstruction network, the end-to-end variational network, which is modified to work for a single coil setting [10, 12], is deployed (see Appendix).\nIn our proposed approach, MOST, replay-based continual learning is combined with an image-guided loss to prevent catastrophic forgetting during sequential finetuning for multiple downstream tasks (Fig. 2)."}, {"title": "IV. EXPERIMENTS AND RESULTS", "content": "T1-weighted images from the five distinct datasets of the five tasks were utilized: FastMRI [12], OASIS-1 [44], BraTS [45], IXI [46], and ADNI [47] for image reconstruction, white matter (WM) segmentation, tumor segmentation, sex classification, and Alzheimer's disease (AD) classification tasks, respectively. We excluded images with large artifacts or images without labels. All images were resized as summarized in Table 1 and normalized by the 99th percentile intensity value of the whole brain. To simulate undersampled k-space data, a forward model was applied to the fully sampled data, assuming a single-coil scenario [12] with an acceleration factor of four and a central k- space fraction of 0.08. The WM segmentation utilized the tissue segmentation maps in the OASIS 1 dataset, exclusively selecting the WM region. For the tumor segmentation, all regions except the tumor or edema were labeled as non-tumor. The labels for sex and AD were from the datasets. The mild cognitive impairment cohort in ADNI was omitted from the dataset. Each task dataset was bifurcated into two segments: one designated for the initial pretraining of the downstream task, and the other for the subsequent finetuning procedure.\nThe neural network part of the variational network was designed by a U-net architecture [48] comprising four downsampling and four upsampling blocks. Each block consists of a repeated sequence of a convolution layer, instance normalization, and leaky-ReLU activation function.\nFor the replay, a fixed-size buffer denoted as M is maintained to store a subset of input-output pairs from previous tasks. After finishing each task, we randomly select input- output pairs from that task and add them to the buffer (Fig 2). The buffer size remains constant throughout the finetuning process, with newly added data pairs replacing older ones. Hence, the number of data in the buffer is kept the same across the tasks.\nUnlike conventional replay-based continual learning methods [26, 27, 42, 43], which generally combine the data of the current and previous tasks in the same mini-batch, our method presents a unique challenge in forming a combined mini-batch because the input data structure and label type can be different among tasks (e.g., segmentation: 2D input and 2D label vs. classification: 3D input and binary label). To address this challenge, data from the past task in the buffer is used in every K iteration (See Algorithm 1) during the finetuning process (Fig. 2b and 2c). The stored data are used in a round- robin fashion across the tasks.\nIn downstream tasks that generate images (e.g., segmentation tasks), we introduce an image-guided loss, LIG, to further enhance the finetuning process (Fig. 2b). This loss, which is calculated using a reconstruction loss LR, compute the difference between the intermediate reconstructed image fr(xt;\u03b8) and the aliasing-free image yt to enhance the Algorithm 1 MOST framework\nInitialize: datasets D, reconstruction network fr, downstream task networks fat, reconstruction loss function LR, downstream task loss functions Lat, learning rate \u03bb\n$\\mathbb{M}\\leftarrow \\{\\}$\nfor Dt in D do\nfor k, xt, Yt, Zt in enumerate(Dt) do\nif exist(yt) then\nLIG = LR(FR(Xt; \u03b8), yt)\n$\\theta \\leftarrow \\theta + \\lambda \\nabla(L_t(f_{d_t}(f_r(x_t; \\theta)), z_t) + L_{IG})$\nelse\n$\\theta \\leftarrow \\theta + \\lambda \\nabla(L_t(f_{d_t}(f_r(x_t; \\theta)), z_t))$\nend if\n$D_{\\epsilon} \\leftarrow \\{x_t, f_r(x_t; \\theta), f_{d_t}(f_r(x_t; \\theta))\\}$\nif modular(k, K) == 0 then\n$\\mathbb{X} \\', \\mathbb{Y} \\', \\mathbb{Z}\\} \\leftarrow \\mathbb{M}$\n$L_{IG} = L_R(F_R(\\mathbb{X}'; \\theta), \\mathbb{Y}')$\n$\\theta \\leftarrow \\theta + \\lambda \\nabla(L_t(f_{d_t}(f_r(\\mathbb{X}'; \\theta)), \\mathbb{Z}' ) + L_{IG})$\nend if\nend for\n$\\mathbb{M} \\leftarrow Reservoir(\\mathbb{M}, Sample(D'_t))$\nend for\nperformance of the reconstruction network:\n$L_{IG} = L_R(F_R(X_t; \\theta), y_t).$ (5)\nThe reconstructed image is saved to the buffer to compute the loss for past tasks. The overall pipeline of MOST is summarized in Algorithm 1.\nWe compared the performance of our MOST approach with a reconstruction network without downstream task-oriented finetuning (Without Finetuning) and a reconstruction network with na\u00efve sequential finetuning (Na\u00efve Finetuning). Additionally, performance when the aliasing-free image was inputted to the downstream task network was calculated (Recon Label Input). The buffer size was fixed to 10 subjects (see section IV.F for the buffer size test). The order of the tasks was white matter (WM) segmentation, tumor segmentation, sex classification, and finally Alzheimer's disease (AD) classification (see Section IV.D for the downstream task order test).\nWe assessed the quality of the reconstructed images using the structural similarity index (SSIM), segmentation results with the Dice similarity coefficient (DICE), and classification performance with the area under the curve (AUC) after completing finetuning for the last downstream task (Last Metric; LM). Additionally, forgetting measures (FM) were computed to quantify how much a model forgot previously learned tasks as it learned new ones. The forgetting measures were calculated by the difference between the best metric and the worst metric of a task obtained during sequential finetuning.\nThe qualitative results of the reconstruction and WM segmentation tasks are illustrated in Fig. 3. Without task-oriented finetuning (Fig. 3, third column), the reconstructed images demonstrate good reconstruction quality for the reconstruction dataset, but they exhibit subpar reconstructed images and segmentation results due to domain gaps or error propagation for the WM segmentation dataset. On the other hand, Na\u00efve Finetuning results in poor quality in both reconstruction and segmentation, indicating catastrophic forgetting (Fig. 3, fourth column). Finally, the MOST approach"}, {"title": "V. DISCUSSION", "content": "In this work, we demonstrated that a single reconstruction network can be sequentially finetuned for multiple downstream tasks by deploying continual learning. This outcome successfully generalized recently illustrated single downstream task-oriented reconstruction optimization to multiple downstream tasks. In particular, the application of replay-based continual learning along with the newly proposed image-guided loss successfully prevented catastrophic forgetting, which was observed in na\u00efve finetuning.\nReconstruction network performance has recently been evaluated by measuring the performance of a downstream task network (e.g., segmentation network) on the reconstructed images. This downstream task-oriented evaluation offers a distinct advantage over traditional image-level evaluation metrics such as PSNR and SSIM because visually appealing images may not translate into the input requirement of a downstream task as demonstrated in the previous studies [16- 19]. In this work, we extended this idea for multiple downstream tasks. This setup better aligns with current clinical practice where multiple neural networks of different tasks are progressively developed and applied.\nIn our study, MOST showed overall performance improvement in all task orders when compared to that of Na\u00efve Finetuning, but it did show task order dependency (Table III). In particular, MOST fell short in Order 3, which may be attributed to the introduction of classification tasks earlier than segmentation tasks. Classification labels had less information than segmentation labels, leading to less effective finetuning.\nOur proposed framework is based on the single-coil setting, wherein the reconstruction model takes single k-space data as the input and produces an alias-free image as the output. The reason for the single-coil setting is limited available end-to-end datasets that include multi-coil k-space data and classification/segmentation labels. The adaptation of this framework to multi-coil data may require conversion to the multi-coil variational network that includes coil sensitivity estimation.\nCurrent continual learning methods mostly target high-level computer vision tasks like classification or segmentation, [49] because catastrophic forgetting rarely arises in regression tasks. In our scenario, although we employ sequential training for the regression network, the cascaded network ultimately performs classifications or segmentations. Hence catastrophic forgetting occurs in the downstream tasks. If the reconstruction network is merely finetuned with the original reconstruction task for different domains (e.g., images with different scanners or different parameters), the effect of catastrophic forgetting may decrease, and continual learning methodologies may not be required.\nBeyond replay-based continual learning or image-guided losses, the reconstruction network itself offers advantages in mitigating catastrophic forgetting. We leverage a variational network [16] as the reconstruction network. Enforcing the forward model within this network minimizes output variability, thereby alleviating catastrophic forgetting. (Table VII)\nIn our approach, we manually trained the downstream task networks instead of adopting off-the-shelf state-of-the-art (SOTA) models. This resulted in inferior metrics compared to those from SOTA models. This manual training was utilized because the off-the-shelf SOTA model is trained on the entire training dataset of the model. On the other hand, we required the training dataset to be split into the downstream network training part and the reconstruction network finetuning part. Moreover, the BraTS dataset contained multimodal MRI data with T1-weighted, T2-weighted, and contrast agent-enhanced images, but we only used the T1-weighted images to maintain consistency with other tasks. Additionally, most SOTA models included preprocessing steps on the input image, such as skull stripping or registration to a template. Incorporating these preprocessing steps in MOST is not straightforward and therefore requires further investigation."}, {"title": "VI. CONCLUSION", "content": "In this study, we propose a scenario where a reconstruction network is sequentially optimized for multiple downstream tasks and demonstrate that replay-based continual learning techniques can prevent catastrophic forgetting. Through this approach, we effectively address the challenge of catastrophic"}, {"title": "APPENDIX", "content": "Variational network Variational networks leveraged the advantages of both model-based and learning-based methodologies by integrating a physical forward model of MRI acquisition with deep learning technique, resulting in state-of-the-art performance in MRI reconstruction. Traditionally, the problem of single-coil MR reconstruction is formulated as follows:\n$\\underset{x}{\\text{argmin}}||\\textbf{M}F\\textbf{x} - \\textbf{k}||^2 + \\lambda \\Phi(x),$ (A1)\nwhere x is resultant reconstructed image, M is undersampling mask, F is 2D Fourier Transform, k is the undersampled k-space data, and \u03a6 is a regularization function. We set A = MF. Solving this problem typically involves an iterative gradient descent method, where in the n-th step, the image is updated from xn to xn+1 using the following update rule:\n$x^{n+1} = x^n - \\eta^n (A^*(Ax^n - k) + \\Phi(x^n)),$ (A2)\nwhere \u03b7n is the learning rate, and A* is the Hermitian of the matrix A. The regularization function in (Al) is replaced by a convolutional neural network [10],[61]:\n$x^{n+1} = x^\u03b7 - \u03b7^n A^*(Ax^n - k) + CNN(x^n),$ (A3)\nTraining is conducted in an end-to-end manner, where the loss function is computed between the aliasing-free image y and the output of the last iteration xN."}]}