{"title": "MORSE: Bridging the Gap in Cybersecurity Expertise with Retrieval Augmented Generation", "authors": ["Marco Simoni", "Andrea Saracino", "Vinod Puthuvath", "Maurco Conti"], "abstract": "In this paper, we introduce MoRSE (Mixture of RAGs Security Experts), the first specialised AI chatbot for cybersecurity. MoRSE aims to provide comprehensive and complete knowledge about cybersecurity. MoRSE uses two RAG (Retrieval Augmented Generation) systems designed to retrieve and organize information from multidimensional cybersecurity contexts. MoRSE differs from traditional RAGs by using parallel retrievers that work together to retrieve semantically related information in different formats and structures. Unlike traditional Large Language Models (LLMs) that rely on Parametric Knowledge Bases, MoRSE retrieves relevant documents from Non-Parametric Knowledge Bases in response to user queries. Subsequently, MoRSE uses this information to generate accurate answers. In addition, MoRSE benefits from real-time updates to its knowledge bases, enabling continuous knowledge enrichment without retraining. We have evaluated the effectiveness of MORSE against other state-of-the-art LLMs, evaluating the system on 600 cybersecurity specific questions. The experimental evaluation has shown that the improvement in terms of relevance and correctness of the answer is more than 10% compared to known solutions such as GPT-4 and Mixtral 7x8.", "sections": [{"title": "I. INTRODUCTION", "content": "The increasing frequency and sophistication of new cyber threats have made cybersecurity a critical priority across all sectors, with a 15% increase in three years 1 on data breaches only. In recent years, the amount of cybersecurity-related information has exploded, providing important resources to protect against these threats by mitigating risk and improving cybersecurity measures. However, this rapid proliferation of information has led to a cluttered and often unstructured data landscape, complicating the task of deriving actionable insights for professionals [1], [2]. In fact, a timely, accurate, and comprehensive understanding of vulnerabilities, exploits, and defense tactics is crucial, as the promptness of such information can significantly impact cybersecurity decisions [3], [4]. Recently, large language models (LLMs) have become important tools for synthesizing huge amounts of information in various fields, including cybersecurity [5]. However, their reliability varies for technical topics where inaccuracies are critical [6], [7], [8], [9]. LLMs can produce hallucinatory responses, meaning that they produce answers that are not true or reliable, especially struggling with the dynamic and evolving nature of cyber threats [10], [11], [12]. This problem is particularly pronounced in code generation tasks, where LLMs often produce non-functioning code for complex queries [13]. Specifically, when the model does not know the correct answer, hallucinations are inevitable (Epistemic [14]). This can happen if the model does not have enough training data or if its capacity is limited. An example of hallucination in cybersecurity is shown in Example 1 (ground truth) and Example 2 (the answer of GPT-4) to the question: What is CVE-2017-5162?. This shows that GPT-4 is not able to provide the correct answer. To overcome these limitations, it is crucial to build continuous learning mechanisms into LLMS that allow them to dynamically update their knowledge base with the latest information [15]. Although retraining can be time-consuming, updating with new information is essential to maintain the relevance of LLM responses [16], [17]. For this reason, companies are quickly discovering the value of Retrieval Augmented Generation chatbots. Although RAG systems have made significant advances on cybersecurity, researchers and practitioners often lacks comprehensive models that unify diverse cybersecurity data and dynamic, real-time updated systems that are essential for addressing the evolving cyber threat landscape. In fact, effective analysis of threats, vulnerabilities and exploits requires a thorough understanding of individual entities and their broader interactions."}, {"title": "II. BACKGROUND", "content": "This section provides an overview of the basic concepts necessary for understanding the architecture of MORSE.\nA. Large Language Models\nLarge language models (LLMs) represent a significant advancement in the field of Natural Language Processing (NLP) and are based on the Transformer model [25]. These models are trained on large text datasets and are able to generate coherent and contextually relevant texts based on input prompts. The capabilities of LLMs go beyond text generation and include tasks such as language translation, summarizing, answering questions, etc.\nThe introduction of models such as GPT [26] and BERT [27] has demonstrated the potential of LLMs to revolutionize language understanding and generation through unsupervised and bidirectional training [26], [28]. With the development of GPT-3 [29], the scalability of these models reached new heights, illustrating their ability to perform a wide range of NLP tasks without task-specific training.\nDespite their advantages, LLMs face several challenges. Ethical considerations, such as the spread of bias and misinformation, are a major concern [30]. In addition, the environmental impact of training and operating these computationally intensive models has raised questions about their sustainability [31]. Efforts to overcome these challenges include research into more efficient training methods and models that are able to understand and generate texts with greater accuracy and less bias [32].\nB. Retrieval Augmented Generation\nRetrieval-Augmented Generation (RAG) combines traditional language models with external databases to improve natural language processing (NLP) tasks [33], [34], [35]. RAG models use a retriever to retrieve relevant information and a generator to generate answers based on the retrieved information. This improves accuracy and relevance, especially for domain-specific queries [36], [16].\nRAG's strengths lie in its ability to update knowledge bases without retraining and customise components for specific tasks such as cybersecurity [33], [34].\nHowever, RAG struggles with latency and scalability issues, especially when processing concurrent queries [33]. Despite these limitations, RAG remains a versatile tool for a range of NLP applications, from chatbots to content creation. Ongoing research focuses on optimizing retrieval mechanisms and computational power [36], [16].\nC. Definitions\nWe report in the following a set of definitions which will be used in the rest of the paper:\n\u2022 Retriever is a component that identifies and retrieves relevant information or documents from a knowledge base. This process is essential to provide the necessary context and content that LLM uses to generate accurate and informed answers [35], [37].\n\u2022 Knowledge Base is a repository of information that the retriever accesses to find relevant data or documents. This is fundamental to the system's ability to retrieve contextually relevant content, essential for generating well-informed and accurate answers [38].\n\u2022 Embeddings are numerical representations of text that assign a low dimension to a term. Within this context, embedding vectors of analogous terms exhibit proximity, encapsulating semantic meaning. This facilitates the comparison between queries and the knowledge base [39].\n\u2022 Context refers to the relevant information or data retrieved by the system, which surrounds and informs a particular query. The model requires this contextual information to formulate answers that are precise, comprehensive, and directly linked to the content found in the knowledge base [40].\n\u2022 Prompt refers to the structured input that is created from the retrieved context, which is then fed into the generative model. This prompt guides the model in generating a coherent, contextually relevant response that directly addresses the user's request [41].\n\u2022 Semantic Similarity evaluates how closely the content of a user's query matches the information in the knowledge base, focusing on meaning rather than word-for-word matching. This evaluation guarantees the relevance and accuracy of the retrieved data and supports the generative model in creating appropriate answers. In MoRSE, we use Cosine Similarity [42] to measure the proximity of embedding vectors because it has a high correlation with human judgment [43].\n\u2022 Multi-hop queries are defined as requests for information that necessitate indirect reasoning over multiple pieces of interconnected data. They typically arise in complex question-answering tasks where a single piece of evidence is insufficient to resolve the query, and the system must hop across different data points or documents to piece together a response."}, {"title": "III. MORSE ARCHITECTURE", "content": "This section describes the structure of the MORSE system in detail. It explains the function of the individual components and how they interact to process a request and generate a response. We used the Langchain framework 10 to develop the MORSE architecture. The Table I contains the key to the symbols used in this explanation to facilitate the understanding of the following discussion. The first two symbols, (\u03b1) and (\u03b2), are embedding models, while the last two, (\u03b3) and (\u03b8), are Transformer models.\nA. MORSE Overview\nAs shown in Figure 1, MORSE consists of two main components: a graphical user interface (GUI) and the MORSE core. The GUI enables interaction with the user by allowing the input of queries and displaying the answers in a structured way11.\nThe MORSE core consists of three key components, which in turn manage the user query and compose the answer:\n\u2022 Query Handling Module: This module performs the pre-processing of user queries and specializes in the management of multi-hop queries and complex questions, especially in the context of Common Vulnerability and Exposures (CVEs) and Common Weakness Enumerations (CWEs).\n\u2022 Structured RAG: The first of the two RAGs is composed by retrievers that retrieve information from pre-processed, structured data. The pre-processing phase involves converting chunks of text from various sources that are part of the knowledge base, such as academic papers and cybersecurity websites, into well-defined structures. These structures are designed to contain generated questions and contextualized entity descriptions that facilitate the precise retrieval of information in response to user queries.\n\u2022 Unstructured RAG: This RAG is used if the structured RAG could not find a suitable answer. It searches for information in unstructured and unprocessed raw text that belongs to its knowledge base. Accessing unstructured data allows the exploration of data in its original form without the limitations imposed by preprocessing, thus providing a wider range of search options in exchange for a higher response time. This type enables the exploration of data in its original form without the restrictions imposed by preprocessing.\nThe RAGs will compose the answer to each query and return it to the GUI for structured visualization. In the following we will detail the components of the MORSE Core.\nB. MORSE Core\na) MORSE Core Workflow: Figure 2 shows the first stage of MORSE Core process, starting with the Query Handling model. This module converts the original query x into an optimized version x* (see subsection III-C). First, x* is forwarded to the Structured RAG module for processing. The structured RAG path, denoted as S, begins with the Structured Retrievers, focused on high accuracy and fast responses to efficiently process most queries. Their primary function, S(x*), is to identify and retrieve information pertinent to the query. When activated, the structured retrieval process, which is executed via S(x*), assigns a set of potentially relevant documents from a predefined Knowledge Base to the query x*. In particular, D = top-k(S(x*)) represents the selection of the top k documents that S considers most relevant for the query based on a similarity score. If D is not empty (|D| > 0), this means that a relevant context has been found. The workflow then proceeds to use this context and moves on to the next phase, where the retrieved information (D) is wrapped in a Prompt, which is used by LLM to generate a response. If the Structured Retrievers do not yield relevant documents (|D| = 0), the workflow moves to the unstructured path and calls the Unstructured Retrievers, denoted as U. At this stage, E = top-k(U(x*)) represents the set of documents retrieved by U, which are designed to process complex queries that are not readily covered by structured data patterns. After a successful retrieval of relevant information in one of the two ways indicated by D| > 0 for structured retrieval or |E| > 0 for unstructured retrieval -the Wrapper module integrates the acquired context and generates a prompt for the Large Language Model (LLM). The LLM then performs Answer Generation, creating a detailed response to the user's question.\nb) RAG Architecture: The RAG architecture of the MORSE system, which is used in both the Structured (III-D) and Unstructured RAG (III-E), follows the same underlying logic shown in Figure 3. This architecture is divided into two parts:\n1) The Retrieval part, which consists of Parallel Retrievers used to collect relevant information for the query.\n2) The Generation part, in which the Large Language Model (LLM) uses the context provided in the Prompt to generate responses. After the retrieval phase, the collected information (info 1 to info N) is merged into a Context, which is Wrapped, along with the user query, in a Prompt used by LLM to generate the Answer. The logic of the architecture is formalized in the Algorithm 1.\nC. Query Handling\nThis component improves the intelligence of the MoRSE system by managing complex query types and enriching the context. Below are the specific functions and the composition of this component:\n1) Functionalities:\n\u2022 Multi-Hop Question Handling: Deals with queries involving multiple related entities and allows the system to handle and answer complex multi-hop questions. Existing Retrieval Augmented Generation systems struggle with multi-hop queries due to their design limitations and the lack of a dedicated benchmark dataset for this type of query [48], [49].\n\u2022 Context Enriching: Generates additional questions from each identified entity, expanding and enriching the context available for generating informed answers.\n\u2022 Solving the CVE-CWE Conundrum: Effectively handles queries related to Common Vulnerabilities and Exposures (CVE) and Common Weakness Enumerations (CWE), which are challenging for generative models due to their technical complexity [50], [51].\n2) Components:\n\u2022 User Query: Initiates the process when a user submits a query via the graphical user interface."}, {"title": "D. Structured RAG", "content": "As illustrated in Figure 4, the Structured RAG module works post-Query Handling by forwarding refined queries to seven Parallel Retrievers, called Structured Retrievers, each of which specializes in specific cybersecurity topics. Given a query, the information contained in the knowledge base of a Retriever is inserted into the Context if its similarity to the query is above a predefined threshold. In order to establish the threshold for each retriever, we conducted an analysis on the scores of top 50 results from a series of test queries. Thresholds were then determined by assessing the distribution of scores 13. In particular, we used the median value of the test distributions as threshold for the MITRE Retriever and the Malware Retriever, as these typically retrieve shorter texts. For Question Retrieval System, CWE Retriever, Metasploit Retriever and Entity Retriever, we chose the third quartile (Q3) of the test distributions as threshold, as they generally retrieve longer texts. The ExploitDB Retriever works without a threshold and uses the TF-IDF algorithm [52]. To mitigate embedding biases [53], we used two different embeddings for the retrievers, (\u03b1) and (\u03b2). The following paragraphs delineate each retriever's functionalities.\na) Mitre Retriever: The knowledge base of this retriever comes from the website of the MITRE Corporation14. It is structured as a graph database containing two primary node categories: Malware and Techniques. Each Malware node in the database contains a name and a description of MITRE. We create Technique nodes, which consist of technique names and descriptions, by collecting and analysing technique-related links from the MITRE website. This retriever utilizes embeddings (\u03b1). To ensure accurate matches, the system exclusively evaluates malware with a similarity score exceeding 0.7, corresponding to the Test distribution's median."}, {"title": "E. Unstructured RAG", "content": "The unstructured RAG, shown in Figure 5, plays a crucial role in the MoRSE system by handling cybersecurity queries that the structured RAG cannot solve. The module utilizes retrievers, called buffers, to store documents in chunks of 2000 characters while maintaining the integrity of the original information. All buffers work as hybrid retrievers that use both semantic search and keyword search with the BM25 algorithm [56]. Unlike other configurations, these retrievers do not have a fixed threshold for semantic search; instead, they are configured to return the top five documents regardless of similarity scores. This decision enables further Context Transformation process to apply semantic thresholds, ensuring the flexibility and comprehensiveness of the retrieval process.\na) Classification of Buffers: Buffers are categorized according to the type of data they process, and there are four different types of buffers:\n\u2022 Text Buffers: Process content from websites and blogs with five separate buffers, each analyzing data using the (\u03b1) embedding.\n\u2022 Metasploit Buffers: five buffers containing entire codes from the Metasploit framework that uses the (\u03b1) embedding for effective processing.\n\u2022 Code Buffers: A single buffer processes code snippets from Exploit DB and also uses (\u03b1) embedding for optimal analysis.\n\u2022 Paper Buffers: Academic papers are managed by three buffers that use the (\u03b2) embedding to better handle the complex language typical of academic content [57]. This choice is based on the higher performance values of embedding, which indicate better retrieval capabilities.\nThe process Context Transformation refines information from buffers through four phases:\n\u2022 Splitting Stage: Document are split into 300-character chunks, improving relevance selection and reducing noise from larger chunks.\n\u2022 Redundant Content Removal: In this phase, \u03b2 embeddings are used to remove redundant content from the segmented chunks and improve the clarity and uniqueness of the output.\n\u2022 Filtration Stage: Relevant data chunks are selected using (\u03b2) embeddings with a threshold of 0.6 set to the third quartile (Q3) of similarity results from tests with 156 queries to ensure relevance from the knowledge base.\n\u2022 Reordering Phase: Finally, the data is ordered according to the (Lost in the Middle) principle to prioritize the visibility of important information in the response."}, {"title": "IV. EXPERIMENTS AND EVALUATION", "content": "The evaluation of Retrieval Augmented Generation systems and Large Language Models in the field of cybersecurity is particularly challenging due to their dual role in information retrieval and content generation. The lack of standardized benchmarks covering a wide range of real-world operational cyber tasks complicates the evaluation of LLMs for cybersecurity [23], [58], [59].\nKey evaluation challenges include verifying the accuracy of the retrieved information, the effectiveness of its use by LLM, and the overall quality of the content generated. Traditional methods that focus on language comprehension may not adequately reflect real-world performance [60].\nTo effectively address these challenges, we developed a three-part evaluation strategy for MoRSE and compared its performance with other known LLMs and RAG systems in answering cybersecurity questions. MoRSE was compared to competing models such as GPT-4 0125-Preview, MIXTRAL, HACKERGPT, and GEMINI 1.0 Pro. The three different evaluation test suites are:\n\u2022 Using the RAGAS framework [23], we evaluate MoRSE's responses against a ground truth using a set of metrics.\n\u2022 Using a method proposed by Zheng et al. [24], we computed Elo Ratings for MoRSE and competing models by reference-guided pairwise comparison using GPT-4 0125-Preview as a judge. This provides a quantitative measure of relative performance.\nA. First Test Suite: Ground Truth Assessing alignment using the RAGAS framework\nUsing the RAGAS framework [23], we focused on three metrics: answer relevance, answer similarity, and answer correctness. To calculate these metrics, we used GPT-4 0125-Preview as the underlying model for all calculations.\nAnswer Relevance, shown in Equation 1, measures how pertinent the generated answer is to the given prompt. It is calculated by generating related questions from the model's answer and comparing their embeddings to the original question using cosine similarity:\nAnswer Relevance =  \\frac{1}{N} \\sum_{i=1}^{N} Cos(E_i, E_o),\nwhere  Ei and  Eo are the B-embeddings of the generated and original questions, respectively, and N equal to 3, is the number of generated questions.\nAnswer Similarity, shown in Equation 2, evaluates semantic congruence between model-generated responses and predefined correct answers, calculated as:\nAnswer Similarity =  \\frac{V_{ground truth} V_{generated}}{||V_{ground truth}|| ||V_{generated}||} ,\nwhere Vground truth and Vgenerated represent vector representations of the ground truth and generated answers, respectively.\nAnswer Correctness, shown in Equation 3 and 4, evaluates the factual accuracy of generated answers against ground truth. It combines semantic similarities and factual correctness:\nAC = wFC FC + wSS SS,\nwhere FC is the factual correctness, quantified using the F1 score that considers True Positives (TP), False Positives (FP), and False Negatives (FN):\nFC = \\frac{TP}{|TP| +0.5 (|FP| + |FN|)} ,\nand SS is the semantic similarity between the generated and ground truth answers. wFC and wSS are the weights assigned to FC and SS, respectively 0.75 and 0.25. In order to calculate TP, FP and FN, RAGAS framework uses the following prompt instruction: Extract the following from the given question and ground truth: \"TP\": statements that are present in both the answer and the ground truth, \"FP\": statements present in the answer but not found in the ground truth, \"FN\": relevant statements found in the ground truth but omitted in the answer.\nEach of these three metrics requires an embedding model to compute distances between sentences and a large language model (LLM) for evaluating answer relevance and correctness. We chose GPT-4 0125-Preview as the LLM and (3) as the embedding model.\na) Performance Analysis on General and Multi-Hop Questions: Table II shows the results of MORSE and the other models for General Cybersecurity Questions and Multi-Hop Cybersecurity Questions. The metrics for each model are expressed as mean (\u03bc) and standard deviation (\u03c3), which indicate the average performance and variability, respectively.\nInsights from General Cybersecurity Questions: For the general cybersecurity questions, MoRSE showed superior performance in all metrics, with a mean relevance score of 0.90, a similarity score of 0.95, and a correctness score of 0.71, indicating a high degree of agreement between the answers and the query prompts, as well as factual accuracy. In comparison, all other models showed lower consistency and effectiveness, especially in terms of correctness.\nInsights Multi-Hop Cybersecurity Questions: When evaluating complex multi-hop cybersecurity queries, the MORSE model outperforms its competitors and proves that it is capable of answering complicated questions. The data shows that MORSE scores consistently high on all metrics, with average scores of 0.93 for relevance and similarity and 0.70 for correctness. Other models show significant performance degradation, particularly in correctness, with GPT-4 0125-Preview achieving a mean score of 0.62 and MIXTRAL 0.61, indicating a lower capacity to handle multi-hop questions.\nb) Performance Analysis on CVE Questions: Table III shows how MORSE and GPT-4 0125 preview approach 300 CVE queries. We chose GPT-4 0125 preview because it performed best as the second model in both general and multi-hop contexts (see Table II). We focus on answer similarity and correctness metrics for scoring answers because they are strictly based on ground truth and answer relevance does not measure factuality. Moreover, we compute Accuracy metric, calculated by checking whether the models correctly identified the vulnerability in the given queries. Regarding Correctness, the MORSE model scored 0.64 because its responses often include explanation of related exploit codes, which are not present in the ground truth that only describes the vulnerability specifics. This extra information, while useful, lowers the correctness score as it deviates from the expected response. GPT-4 0125-Preview lags behind in this domain-specific challenge. MORSE achieved an accuracy of 84%, surpassing the GPT-4 0125-Preview model, which had an accuracy of 34%. Our comparison reveals that MoRSE significantly outperforms GPT-4 0125-Preview in accurately identifying vulnerabilities.\nB. Retrievers Impact analysis\nTo calculate the impact of each retriever on 600 questions, we applied a systematic methodology. First, we collected all contexts generated for 150 general questions, 150 multi-hop questions and 300 CVE questions. We then analyzed the frequency with which each retriever was able to successfully retrieve relevant information within these contexts. The frequency of successful retrievals for each retriever was then calculated as a percentage of the total questions in each category. In this way, we were able to quantify the performance and impact of each retriever in both general and multi-hop question scenarios. Figures 6a, 6b and 6c show the impact of the different retrievers for each question category. For general questions, the Question Retrieval System has the highest impact at 56.3%, followed by the Entity Retriever with 21.7%. Other retrievers, such as MITRE, CWE, ExploitDB, Metasploit and Malware Retriever, have an impact of between 6.1% and 9.0%. For multi-hop questions, the Question Retrieval System significantly influences results with a 35.4% contribution, and the Entity Retriever also plays an important role with a 28.3% contribution. The Metasploit Retriever has an increased influence of 12%. The other retrievers (Malware, CWE, ExploitDB and MITRE) have an influence of between 5% and 7%. Figure 6c shows the impact on CVE questions, where the ExploitDB and Metasploit Retrievers have the highest impact at 18% and 31% respectively. The other retrievers (Malware, CWE, MITRE, Entity, and Question Ret. Sys.) have an impact ranging from 1% to 14%.\nC. Second Test Suite with LLM as Judge: Reference-Guided Pairwise Comparison\nPrompt 1: The prompt for reference-guided pairwise comparison.\nPrompt 2: The prompt for Five-Level Judgment Criteria Referencing the Top-Scoring Reference."}, {"title": "V. RELATED WORK", "content": "We now overview recent developments in Named Entity Recognition (NER), Knowledge Graphs (KGs), and Large Language Models (LLMs) that have contributed to more sophisticated, automated, and adaptive cybersecurity systems.\na) Named Entity Recognition in Cybersecurity: Significant progress has been made in the evolving landscape of Named Entity Recognition (NER) for cybersecurity. In particular, the use of BERT and its Whole Word Masking variant with a BiLSTM-CRF framework has shown remarkable improvements in entity recognition metrics [63]. Similarly, by fusing rule-based, dictionary-based methods and CRF, the RDF-CRF model has significantly improved entity recognition in the cybersecurity domain [64]. In addition, a hybrid model that combines deep learning with dictionary-based methods has significantly improved precision and recognition in the identification of complex entities [65]. A study by Srivastava et al. [66] highlighted the differential effectiveness of word embeddings such as fastText, GloVe and BERT, with finetuned BERT embeddings with a feed forward network achieving an F1 score of 0.974, highlighting the importance of model adaptation to specific domains. In addition, the introduction of the JCLB model, which combines contrastive learning with a Belief Rule Base [67], showed improved accuracy through semantic expansion and optimized BRB parameters. Li et al. developed NEDetector [68], which improves NER by identifying cybersecurity neologisms with 89.11% accuracy, outperforming traditional trending tools in detecting threats on platforms like Twitter. Extractor distills attack behavior from CTI reports into clear, actionable insights and leverages provenance graphs to improve cyber analytics in threat hunting with real-world effectiveness [69]. Koloveas et al. [70] created the inTIME framework, which leverages machine learning to transform web data into actionable CTI, streamlining the intelligence lifecycle with a unified platform for intelligence collection, analysis and sharing. At the same time, a new threat modeling language has been developed by Xiong et al. [71] based on the MITRE Enterprise ATT&CK Matrix that integrates key elements of enterprise security to improve defense strategies through simulations. Husari et al. [72] further refines CTI analysis by automating the extraction of threat actions from unstructured texts, employing NLP and IR for semantic extraction and aligning attack patterns with standards like STIX 2.1, achieving significant precision and recall in its evaluations.\nMORSE goes beyond current NER technologies by providing dynamic entity recognition and response generation. It identifies named entities in user queries in real time and uses this information to generate precise, contextualised responses.\nb) Knowledge Graphs for Cybersecurity: Knowledge graphs (KGs) are revolutionizing cybersecurity, from threat intelligence to education. Agrawal et al. [73] have shown how KGs from unstructured text enhance cybersecurity learning, with student feedback highlighting improved understanding and engagement. Sewak et al. developed CRUSH [74], which integrates Large Language Models (LLMs) such as GPT-3.5/GPT-4/ChatGPT with Enterprise Knowledge Graphs (EKGs) to create Threat Intelligence Graphs (TIG) that achieve up to 99% recall in identifying malicious scripts. Li et al. developed AttacKG [75], which automates the extraction of attack techniques from CTI reports into structured knowledge graphs, which greatly improves the analysis of attack patterns with high accuracy and supports advanced threat detection efforts. Liu et al. [76] use NLP to convert over 29k cybersecurity reports into 113,543 actionable Cyber Threat Intelligence (CTI) points by highlighting campaign triggers for better classification accuracy. Piplay et al. [77] describes a system for generating Cybersecurity Knowledge Graphs (CKGs) from After Action Reports (AARs) using a 'Malware Entity Extractor' and neural networks that improves security analysis through refined query responses. Gao et al. [78] use of a heterogeneous information network (HIN) and meta-path approach within a graph convolutional network is characterized by its sophisticated threat type identification capabilities validated by real-world data. Sikos et al. [79] discuss how knowledge graphs help in cybersecurity threat intelligence and automated reasoning, and highlights their importance in analyzing cyber data. Ren et al. [80] present a knowledge graph for APT attack mapping that combines deep learning with network defense expertise. Mitra et al. [81] augment CKGs with provenance information to combat fake cybersecurity information and ensure data reliability.\nIn comparison, MoRSE addresses the limitations of Knowledge Graphs (KGs) in cybersecurity by providing dynamic updates with real-time adjustments as opposed to the manual revisions of KGs. It also provides interactive query capabilities that are real-time and interactive as opposed to the static KGs. In addition, MoRSE offers improved customizability and modularity, which allows for greater adaptability and easier expansion of the knowledge base compared to the fixed structures of KGs.\nc) LLMs and Chatbots in Cybersecurity Landscape: Research into chatbots in cybersecurity highlights their role in education, ethics and regulation. Yoo et al. (2024) and Abu-Amara et al. (2024) explore the impact of GDPR and the use of gamified chatbots in education, while Pieterse (2024) evaluates the utility of ChatGPT in guiding students through cybersecurity CTF challenges, noting that it reaches its limits in providing direct solutions [82], [83], [84]. Mitra et al. [85] developed LOCALINTEL, which presents an automated system that uses LLMs to create organisation-specific threat intelligence from global and local databases to improve the efficiency of SoC operations. Juttner et al. [86] use ChatGPT to make IDS alerts understandable to non-experts, improving network security in the home and home office environment. However, concerns about trust, privacy and ethics highlight the need for further research before widespread adoption. Yoo et al. [87] use CNN classifiers and AI chatbot to detect and combat SNS phishing attacks before they can occur. This is more promising than traditional methods because it provides real-time support and actions on Telegram, with validated effectiveness against LSTM models. Iqbal et al. [88] explore the dual utility of ChatGPT in cybersecurity, highlighting its benefits for defense strategies and the risks of its misuse in cyberattacks, and call for more research on its offensive capabilities. Chamberlain and Casey [89] examine the application of ChatGPT in penetration testing and CTF exercises, pointing to its potential to create dynamic scenarios and enhance the learning process. Aghaei et al. [90] developed SecureBERT, which automates critical cybersecurity tasks by introducing a specialized language model for Cyber Threat Intelligence (CTI) that uses a customized tokenizer and pre-trained weights for improved performance on NLP tasks. Ameri et al. [91] use BERT for feature classification and achieves improved accuracy from 76% to 94.4% by optimizing the hyperparameters. It demonstrated robustness with a standard deviation of \u00b10.6% across all validations and outperformed models such as GPT2, ULMFIT, ELMO, CNN, LSTM and BiLSTM on cybersecurity tasks. Voros et al. [92] use knowledge distillation from LLMs to efficiently categorize URLs, reduce the number of parameters and improve inline scanning. Happe et al. [93] use GPT-3.5 to extend penetration testing and demonstrates LLMs as AI sparring partners in security testing. Lu et al. [94] integrate graph structural information and in-context learning into LLM-based software vulnerability detection, significantly outperforming conventional models. Yu et al. [95] use GPT-3 to generate semantic honeywords containing users' PII, which improves their indistinguishability and increases defenses against security breaches.\nUnlike traditional LLMs and chatbots, MoRSE stands out by providing instant access to a constantly updating cybersecurity knowledge base, quickly integrating the latest threats and solutions, and enabling extensive customization for various cybersecurity needs. MORSE does not focus on niche cybersecurity topics; instead, it aims to provide comprehensive coverage of cybersecurity knowledge. In addition, MoRSE enhances the user experience by providing user-friendly access to complex cybersecurity information, increasing flexibility and expanding accessibility."}, {"title": "VI. CONCLUSIONS AND FUTURE WORK", "content": "With cyber threats on the rise, effective cybersecurity strategies are becoming increasingly important. Integrating continuous learning and Retrieval Augmented Generation (RAG) into large language models (LLMs) improves their accuracy and timeliness in responding to these threats. In this paper, we have investigated the use of two Retrieval Augmented Generation (RAG) systems, namely Structured RAG and Unstructured RAG, to provide precise and structured answers to cybersecurity queries. In Structured RAG, we have focused on implementing parallel retrievers to quickly and effectively find the relevant document in response to a user query. Unstructured RAG, on the other hand, is designed to answer even the most complicated cybersecurity queries. We have implemented an evaluation suite to assess the relevance, similarity, and correctness of the answers generated by our system compared to ground truth. The performance of our system was compared to other renowned commercial Large Language Models (LLMs) using two additional test suites that adhere to the LLM as a Judge paradigm. The results show that our system outperforms competing models by more than 10% in terms of the correctness and relevance of the given answers and by 50% in terms of accuracy against GPT-4 for questions related to vulnerabilities.\nIn order to make the framework publicly available, our goal is to improve MoRSE with a Prefix-aware Greedy replacement policy (PAGRP) [96] for the semantic cache. This takes into account the initial segments of queries or data to make more informed decisions about what data to store in the cache. The PAGRP prioritizes the cache items based on their access frequency and size, ensuring that the system stores the most useful data and minimizes the likelihood of cache misses. In addition, we plan to replace the MITRE retriever with a comprehensive Knowledge Graph. This Knowledge Graph will include mitigation and detection approaches and aggregate real malware reports associated with the corresponding MITRE software. This solution enables better threat insights by allowing the computation of community analysis, centrality algorithms, and threat similarities quickly and in real-time."}]}