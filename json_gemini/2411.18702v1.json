{"title": "Random Walks with Tweedie: A Unified Framework for Diffusion Models", "authors": ["Chicago Y. Park\u2020", "Michael T. McCann\u207a", "Cristina Garcia-Cardona\u2260", "Brendt Wohlberg", "Ulugbek S. Kamilov\u00b9"], "abstract": "We present a simple template for designing generative diffusion model algorithms based on an interpretation of diffusion\nsampling as a sequence of random walks. Score-based diffusion models are widely used to generate high-quality\nimages. Diffusion models have also been shown to yield state-of-the-art performance in many inverse problems. While\nthese algorithms are often surprisingly simple, the theory behind them is not, and multiple complex theoretical\njustifications exist in the literature. Here, we provide a simple and largely self-contained theoretical justification for\nscore-based-diffusion models that avoids using the theory of Markov chains or reverse diffusion, instead centering the\ntheory of random walks and Tweedie's formula. This approach leads to unified algorithmic templates for network\ntraining and sampling. In particular, these templates cleanly separate training from sampling, e.g., the noise schedule\nused during training need not match the one used during sampling. We show that several existing diffusion models\ncorrespond to particular choices within this template and demonstrate that other, more straightforward algorithmic\nchoices lead to effective diffusion models. The proposed framework has the added benefit of enabling conditional\nsampling without any likelihood approximation.", "sections": [{"title": "Introduction", "content": "Deep score-based diffusion models are a type of generative model that uses a deep neural network to learn a score\nfunction the gradient of the logarithm of a probability density from training data. This score function is then used in\nan iterative algorithm based on the mathematical theory of diffusion to generate novel samples. These models (see [1] for\na recent survey) have produced state-of-the-art results in generating natural images [2], videos [3], and 3D objects [4].\nThese algorithms have also been adapted to generate samples conditioned on noisy measurements, enabling their use for\nsolving inverse problems (see [5] for a recent survey).\nThe success of diffusion models has led to the development of many training and sampling algorithms rooted in\ndistinct mathematical theories. Although many of these algorithms have a similar structure, the specifics of the algorithm\nare often determined by the underlying theory, limiting its flexibility to accommodate different score functions and\nparameter configurations. Furthermore, conditional sampling often necessitates costly, problem-specific score training or\nrelies on approximated posterior sampling.\nThe main aim of this work is to present a simple theoretical framework within which the distinctions between\ndifferent diffusion model algorithms arise as algorithmic choices rather than as essential features of the underlying\nmathematical theory. This unified view is a step towards identifying the essential components of a diffusion model and\ndetermining how these differences contribute to algorithm performance. Our main contribution is a unified algorithmic\ntemplate for diffusion models that includes widely-used algorithms such as the score-based generative model (SGM) [6],\ndenoising diffusion probabilistic model (DDPM) [7], and score-based generative modeling through stochastic differential\nequations (Score-SDE) [8] as special cases. This framework is mathematically justified and flexible, e.g., it allows the noise\nschedule during training to differ from the one used during sampling and is compatible with pretrained denoisers (both\nvariance-exploding and variance-preserving ones). Finally, the framework enables conditional sampling and Bayesian"}, {"title": "1.1\nRelated Work", "content": "The most popular theoretical foundations for diffusion models are SGM [6], DDPM [7], and Score-SDE [8]. All these\napproaches train denoising score functions that operate on noisy data at varying noise levels. The SGM operates by\ngradually adding Gaussian noise to data and training a noise-conditional deep neural network to estimate the scores (or\ngradients) of the noisy data distributions, then generates new samples by using these estimated scores at progressively\ndecreasing noise levels. On the other hand, DDPM uses two probabilistic Markov chains: a forward chain that gradually\nadds noise to the data, transforming it into a simple prior distribution (typically a standard Gaussian), and a reverse\nchain that learns to invert this process. During sampling, the reverse chain uses the learned denoising score function to\nremove noise step by step, following the same noise schedule as in the training process. Score-SDE extends the concepts\nof both SGM and DDPM to scenarios with an infinite number of time steps or noise levels. It uses stochastic differential\nequations (SDEs) to describe noise perturbation as forward SDEs and sample from target distribution by solving the\ncorresponding reverse-time SDE using the learned score function. Although Score-SDE proposes a generalized framework\nof SGM and DDPM, it still requires corresponding denoisers for SGM-based and Markov-chain-based reverse process,\nrespectively.\nThere exist several theoretical approaches for using diffusion models in conditional settings to solve inverse problems.\nTwo common strategies are often employed to infer an unknown signal from degraded measurements using diffusion\nmodels: (a) training the conditional diffusion model on degraded measurements, allowing it to directly learn how to map\nfrom a known distribution (typically a standard Gaussian) to the desired quality signals, and (b) using a pretrained\nunconditional diffusion model and performing conditional sampling, incorporating an additional data consistency step\nduring the sampling process. Strategy (a) can directly learn the posterior distribution of the desired signal given degraded\nmeasurement, but training task-specific diffusion models is data and computationally expensive process [9-11]. On the\nother hand, strategy (b) solves the inverse problem without requiring task-specific training by leveraging a pretrained\nunconditional diffusion model, but existing algorithms require some form of approximation because of intractable\nlikelihood from multiple noise scales. One approach implements coarse-to-fine gradient ascent on the noisy distribution"}, {"title": "2 Theory of Deep Score-Based Diffusion Sampling", "content": "We now present our theoretical justification for deep score-based generative modeling. While these results are not new\n(in fact, we have intentionally relied on textbook results), when brought together they offer a simple and mathematically\nrigorous justification for many diffusion model algorithms."}, {"title": "2.1 Tweedie's formula", "content": "The score function as the gradient of the log-likelihood-guides the denoising process in diffusion sampling, leading\nnoisy data toward areas of higher probability density for image sampling. Tweedie's formula [25] establishes a relationship\nbetween the score function and an optimal denoiser, offering an elegant approximation of the score using only the MMSE\nreconstruction and noisy images.\nWe denote a noisy version of a random variable, $X \\sim f_X$, by\n$X_{\\sigma} = X + \\sigma N, \\quad N \\sim \\mathcal{N}(0, I)$,\nwhere $\\sigma$ is the specified noise level, and N is a standard Gaussian sample.\nMMSE image reconstruction recovers the image that, on average, is the closest to the ground truth given the observed\nmeasurements\n$\\hat{x}_{MMSE}(x_{\\sigma}) = arg \\min_{\\hat{x}} E[||\\hat{x} - X||^2 | X_{\\sigma} = x_{\\sigma}].$\nWith this, Tweedie's formula establishes the relationship between score function and MMSE denoiser as\n$\\nabla log f_{X_{\\sigma}}(x_{\\sigma}) = \\frac{\\hat{x}_{MMSE}(x_{\\sigma}) - x_{\\sigma}}{\\sigma^2}$\nfor $x \\in \\mathbb{R}^d$."}, {"title": "2.2 CNN denoisers as MMSE estimators", "content": "Tweedie's formula relates score functions with MMSE denoisers; we now show that neural networks trained on a denoising\nobjective approximate MMSE denosiers. Consider the denoising inverse problem, where, as above, $X_{\\sigma} = X + \\sigma N$ is a\nrandom variable representing X perturbed by Gaussian noise with variance $\\sigma^2$, and denote the corresponding MMSE\ndenoiser by $\\hat{x}_{MMSE} : \\mathbb{R}^d \\rightarrow \\mathbb{R}^d$.\nGiven a set of IID training samples, $X^{(1)}, X^{(2)}, ..., X^{(N)} \\sim f_X$, we form noisy versions according to $X_{\\sigma}^{(n)} =$\n$X^{(n)} + \\sigma N$. Then the mean squared error (MSE) loss for a reconstruction algorithm, $\\hat{x} : \\mathbb{R}^d \\rightarrow \\mathbb{R}^d$, is\n$\\mathcal{L}(\\hat{x}) = \\frac{1}{N} \\sum_{n=1}^{N} ||\\hat{x}(X_{\\sigma}^{(n)}) - X^{(n)}||^2$\n$\\approx E[||\\hat{x}(X_{\\sigma}) - X ||^2] .\n\nThe best possible reconstruction algorithm according to the average MSE metric is exactly the MMSE estimator (2)\nbecause\n$\\hat{x}_{MMSE}(x_{\\sigma}) = arg \\min_{\\hat{x}} E [||\\hat{x} - X ||^2 | X_{\\sigma} = x_{\\sigma}]$\n$= arg \\min_{\\hat{x}} \\int_{ \\mathbb{R}^d} ||\\hat{x} - x'||^2 f_{X | X_{\\sigma}}(x'|x_{\\sigma})dx'$\n$= arg \\min_{\\hat{x}} \\int_{ \\mathbb{R}^d} ||\\hat{x} - x'||^2 \\frac{f_{X_{\\sigma} | X}(x_{\\sigma}, x')}{f_X(x_{\\sigma})}dx'$\n$= arg \\min_{\\hat{x}} \\int_{ \\mathbb{R}^d} ||\\hat{x} - x'||^2 f_{X,X_{\\sigma}}(x',x_{\\sigma})dx'$\nwhich implies that\n$\\int_{ \\mathbb{R}^d} ||\\hat{x}(x_{\\sigma}) - x' ||^2 f_{X,X_{\\sigma}}(x',x_{\\sigma})dx' < \\int_{ \\mathbb{R}^d} ||\\hat{x}_{MMSE}(x_{\\sigma}) - x'||^2 f_{X,X_{\\sigma}}(x',x_{\\sigma})dx'$\nfor any reconstruction algorithm $\\hat{x}$ and noisy image $X_{\\sigma} = x_{\\sigma}$. Consequently,\n$E(||\\hat{x}_{MMSE}(X_{\\sigma}) - X ||^2 \\le E(||\\hat{x}(X_{\\sigma}) - X||^2))$\nfor all $\\hat{x}$. This implies that, within the limit of an infinitely large test set, the MMSE image reconstruction algorithm, by\ndefinition, achieves the lowest average MSE among all possible algorithms.\nThus, a well-trained deep denoiser $\\hat{x}$ re-optimized to minimize the loss function in (3) can serve as an accurate\napproximation of the MMSE estimator. The score then can be derived from this pretrained CNN denoiser using Tweedie's\nformula\n$\\nabla log f_{X_{\\sigma}}(x_{\\sigma}) = \\frac{\\hat{x}(x_{\\sigma}) - x_{\\sigma}}{\\sigma^2}.$\nThese ideas have appeared in [26], which proposed estimating the score through denoising, based on the principle\nthat the gradient of the log density at a noisy sample $X_{\\sigma}$, naturally points toward the noise-free sample X."}, {"title": "2.3 Random walk in a potential and the score function", "content": "Building on textbook results from stochastic differential equation theory, we show that simulating a particular random\nwalk allows us to sample a PDF while only having access to the corresponding score function.\nThe motion (in d dimensions) of a particle influenced by Brownian motion and a potential V can be described by the\nequation\n$dX_t = -\\nabla V(X_t)dt + \\sqrt{2T}dW_t,$\nwhere $X_t$ is a random variable that represents the position of the particle at time t, $V : \\mathbb{R}^d \\rightarrow \\mathbb{R}^d$ represents a potential,\nW denotes standard Brownian motion on $\\mathbb{R}^d$, T > 0 is the temperature parameter controlling the extent of the random\nfluctuations, and $X_0$ can be initialized either as a deterministic value or as a random variable following a specified\nprobability density, such as a Gaussian distribution [27, Section 3.5, pg. 73].\nFor a fixed temperature T > 0, if V grows fast enough that the particle cannot escape to infinity (see [27, Definition\n4.2] for the technical condition) then for any distribution $f_{X_0}$ of initial positions, the distribution\n$f(x) = \\frac{1}{Z} e^{-\\frac{V(x)}{T}}$\nwhere\n$Z = \\int_{\\mathbb{R}^d} e^{-\\frac{V(x)}{T}} dx$\nis the unique invariant distribution corresponding to (5) [27, Proposition 4.2]. This means that\n$\\lim_{t \\rightarrow \\infty} f_{X_t} = f(x)$.\nAs a first step towards our goal of drawing samples from a target distribution $f_X$, we choose the potential\n$V(x) = - log f_X(x)$.\nEquation (5) can then be discretized using the Euler-Maruyama method [27, Section 5.2, pg. 146] as follows:\n$x_{k+1} = x_k + \\tau_k \\nabla log f_X(x_k) + \\sqrt{2 \\tau_k T_k}\\zeta_k \\quad k = 0,1,2,...$\nwhere $ log f_X(x_k)$ is the score function, $\\tau_k$ denotes the step size at iteration k, and $\\zeta_k \\sim \\mathcal{N}(0, I)$.\nA similar concept underpins the sampling approach in [6], where it is referred to as Langevin dynamics."}, {"title": "2.4 Sequence of random walks", "content": "We have thus far shown (closely following [22]) how a trained score can be used to generate samples from a noisy\ndistribution, $X_{\\sigma}$. We now depart from [22] and describe how $\\sigma$ can be decreased during sampling to draw samples from\nthe target distribution. This requires two ingredients: (a) a new sampling scheme that comprises a sequence of random\nwalks with different potential functions, and (b) a denoiser for every noise level that can approximate the gradient of the\ncorresponding potential.\nTo arrive at the new sampling scheme, consider a sequence of K random walks with different potential functions,\n$dx_t =\\begin{cases} -\\nabla log f_{X_0}(x_t)dt + \\sqrt{2T_0}dW_t & t \\in [0, t_0) \\\\ -\\nabla log f_{X_{\\sigma_1}}(x_t)dt + \\sqrt{2T_1}dW_t & t \\in [t_0, t_1) \\\\ : & : \\\\ -\\nabla log f_{X_{\\sigma_{K-1}}}(x_t)dt + \\sqrt{2T_{K-1}}dW_t & t \\in [t_{K-2}, t_{K-1}) \\end{cases}.$\nwhere $\\sigma_k$ decreases from a large value at k = 0 to a small value at $\\sigma_{K-1}$ so that $f_{X_{\\sigma_{K-1}}} \\approx f_X$. (Taking $\\sigma_{K-1} = 0$ is not\nfeasible in this framework because it results in a division by zero in Tweedie's formula.) A version of this idea appeared\nin [6] under the name annealed Langevin dynamics."}, {"title": "3 Proposed Diffusion Model Templates", "content": "In summary, a diffusion model algorithm can be derived by following a training and sampling template. The training\ntemplate is\n$\\mathcal{L}(\\theta) = E_{\\sigma,X,X_{\\sigma}} [w(\\sigma)||X - r_{\\theta}(X_{\\sigma}, \\sigma)||^2]$,\nwhere $w: \\mathbb{R}_{>0} \\rightarrow \\mathbb{R}_{>0}$ is a (user-specified) weight function, $X \\sim f_X$ is a draw from the target distribution, $\\sigma \\sim f_{\\sigma}$ is a\nuser-specified noise scale distribution, and $X_{\\sigma} = X + N$ is a noisy version of $X$.\nThe sampling template is\n$x_{k+1} = x_k + \\tau_k \\nabla log f_{X_{\\sigma_k}}(x_k) + \\sqrt{2\\tau_k T_k}N, \\quad k = 0,1, ..., K - 1$\nwhere the sequences {$\\sigma_k$}, {$\\tau_k$}, and {$T_k$} are algorithmic parameters that represent noise levels, step sizes, and\ntemperatures, respectively. From a theoretical perspective, the choice of the initial value $x_0$ is arbitrary, but practically,\nit should be similar to a sample from $X$ because the network $r_{\\theta}(\\cdot, \\sigma_0)$ was trained on these samples. The noise level\n$\\sigma_k$ should decrease towards zero as the iteration k approaches K \u2013 1. The step size $\\tau_k$ controls the balance between\nnumerical stability (increasing with smaller $\\tau$) and the number of steps required for good quality samples (decreasing\nwith larger $\\tau$). The temperature sequence $T_k$ should end with $T_{K-1} = 1$ for sampling to be mathematically correct;\nsetting the temperature below one drives sampling towards high density regions, setting it larger than one promotes\nfaster mixing.\nNote that while we have used uppercase bold symbols to denote random variables so far, the $x_k$'s in the sampling\ntemplate are written in lowercase for consistency with existing formulations.\nWhen training is performed with the training template, we can substitute the trained network for the score function,\n$x_{k+1} = x_k + \\frac{\\tau_k}{\\sigma_k^2} (r_{\\theta}(x_k, \\sigma_k) - x_k) + \\sqrt{2\\tau_k T_k}N, \\quad k = 0,1,..., K - 1,$\nor equivalently\n$x_{k+1} = (1 - \\frac{\\tau_k}{\\sigma_k^2}) x_k + \\frac{\\tau_k}{\\sigma_k^2} (r_{\\theta}(x_k, \\sigma_k) + \\sqrt{2\\tau_k T_k}N, \\quad k = 0, 1, ..., K \u2013 1.$\nThe first form resembles a randomized gradient descent and provides the intuition that $\\tau_k$ should be chosen to be small\nrelative to $\\sigma_k^2$ to keep the effective step size small. The second form, emphasizes that the iterates mix the current image\n$x_k$ with its denoised version $r_{\\theta}(x_k)$.\nIn the following sections, we describe how the sampling template may be used with pretrained denoisers and interpret\nseveral existing diffusion model algorithms in terms of our proposed templates."}, {"title": "3.1 Using pretrained denoisers", "content": "Our sampling template admits the use of pretrained denoisers, however, care must be taken to properly scale their inputs\nand outputs to conform to the template. One way to achieve this is to interpret the training procedure in terms of the\ntraining template (7). Doing so results in an expression for the denoiser in the template, $r_{\\theta}$, in terms of the pretrained\ndenoiser and is immediately compatible with the denoiser form of the sampling template (9). This is the approach we\ntake in Section 3.2. In other cases, it is easier to work in terms of the score function form than the pretrained denoiser\nwhen applying the score-based sampling template (8). We pursue this approach here.\nIn deep score-based diffusion sampling, VE and VP score functions (and denoising networks) are widely used. These\nscore functions are defined by two different ways of adding noise. In the VE setting, which SGM and VE-SDE adopt, the"}, {"title": "3.2 Interpretation of Existing Methods", "content": "The VP training objective in our template. DDPM [7] and VP-SDE [8] use the same VP training objective. To\nrepresent this objective in terms of the training template (7), we set the noise variance distribution to\n$\\sigma = \\sqrt{\\frac{1 - \\bar{\\alpha}_t}{\\bar{\\alpha}_t}}, \\quad t \\sim Uniform(1, ..., T),$\nwith $\\bar{\\alpha}_t$ defined as in [7]. Doing this establishes bijections between t, $\\sigma$, and $\\bar{\\alpha}$ because $\\bar{\\alpha}_t$ is monotone by definition. Let\n$w(\\sigma) = \\sigma^{-2}$. Let the denoiser $r_{\\theta}$ take the form\n$r_{\\theta}(x, \\sigma) = x - \\sigma e_{\\theta}(\\sqrt{\\bar{\\alpha}_{t(\\sigma)}}x,t(\\sigma)),$\nwhere t($\\sigma$) denotes the t that corresponds to a given sigma via (12) and $e_{\\theta}$ is defined as in [7]."}, {"title": "4 Theory of Deep Score-Based Diffusion for Conditional Sampling", "content": "Building on our theoretical justification for deep score-based generative modeling, we extend this theory to conditional\nsampling. We provide the underlying theory and demonstrate that our sequence of random walks framework can be\nadapted for posterior sampling, offering the advantage of not requiring likelihood approximations, as is often needed in\nmany existing methods."}, {"title": "4.1 Inverse problems", "content": "Solving inverse problems involves estimating an unknown image $x \\in \\mathbb{R}^d$ from its noisy measurement $y \\in \\mathbb{R}^d$. From a\nBayesian perspective, this involves inferring the posterior distribution $f_{X|Y}(x | y)$ from the learned prior distribution\n$f_{X}(x)$ of the desired image by incorporating the likelihood term $f_{Y|X}(y|x)$\n$f_{X|Y}(x | y) \\propto f_{Y|X}(y|x)f_{X}(x),$\nwhere $f_{Y|X}(y | x)$ is a conditional PDF that describes how the known imaging system relates the measurements y\nto the unknown signal x. This relationship involves incorporating the conditional score in the sampling process as\n$\\nabla log f_{X_{\\sigma_{T-k}}|Y}(x_k | y) = \\nabla (log f_{Y|X_{\\sigma_{T-k}}}(y | x_k) + log f_{X_{\\sigma_{T-k}}}(x_k))$.\nIn practice, measurements y are modeled as\n$y = Ax + e, \\quad e \\sim \\mathcal{N}(0, \\eta^2I)$\nwhere A is the degradation operator (also called forward operator), x is the noise-free image, and e is additive white\nGaussian noise with measurement noise level $\\eta$. Since y is distributed according to $\\mathcal{N}(Ax, e)$, by the definition of normal\ndistribution PDF, we can derive the log-likelihood gradient as\n$\\nabla log f_{Y|X}(y | x) = \\frac{1}{\\eta^2} A^T (y - Ax)$.\nHowever, for a noisy latent image $x_k$ during the diffusion process, y is no longer distributed according to $\\mathcal{N}(Ax_k,e)$.\nAs a result, computing the exact log-likelihood gradient $\\nabla log f_{Y|X_{\\sigma}}(y | x_k)$ during the diffusion process remains a\nchallenge. To address this, some existing works sample from posterior distribution by training a conditional model\non degraded measurements, which allows direct approximation of $\\nabla log f_{X_{\\sigma_k}|Y}(x_k | y)$ [9-11]. However, as it requires\nproblem-specific training, leveraging pretrained unconditional diffusion model with data consistency steps is an active\nresearch area. To approximate the intractable time-dependent log-likelihood, Ajil et al. [17] proposes\n$\\nabla log f_{Y|X_{\\sigma_k}}(y | x_k) \\approx A^T \\frac{Ax_k - y}{\\eta^2 + (\\gamma_k)^2},$\nwhere $(\\gamma_k)^2$ is an annealing hyper-parameter. The class of denoising diffusion restoration models (DDRM) methods [18,19]\nadopts the approximation\n$\\nabla log f_{Y|X_{\\sigma_k}}(y | x_k) \\approx \\frac{y - x_k}{|\\eta^2 - (\\sigma_k)^2|},$\nwhere $\\sigma_k$ denotes the noise level at diffusion iteration k, in the scenario where the degradation operator $A = I$ in (17).\nFor a general A, singular value decomposition is applied to weight the spectral components based on the noise level of\neach component. Diffusion posterior sampling (DPS) [20] proposes\n$\\nabla log f_{Y|X_{\\sigma_k}}(y | x_k) \\approx \\nabla log f_{Y|X_{\\sigma_k}}(y | r_{\\theta}(x_k, \\sigma_k)),$\nwhere $r_{\\theta}(x_k, \\sigma_k)$ is the MMSE reconstruction of noise-free image $x_0$ given an input of $x_k$ and noise level $\\sigma_k$ (see [5] for\nmore comprehensive survey). The important point from the observation of existing algorithms is that those algorithms\nrequire the approximation of the log-likelihood gradient. At the end of the next section, we extend our sequence of\nrandom walks framework to solve inverse problems without any likelihood approximation."}, {"title": "4.2 Sequence of random walks to solve inverse problems", "content": "In Section 3, we introduce the sequence of random walks framework as sampling template of existing diffusion algorithms.\nOur theory of the sequence of random walks can easily be modified to enable sampling from a posterior distribution,\nthereby providing a way to solve inverse problems with a learned prior. In addition, our framework has the added benefit\nof enabling conditional sampling without any likelihood approximation.\nAs described in Section 4.1, for conditional sampling, we replace log-prior gradient $\\nabla log f_{X_{\\sigma_k}}(x_k)$ with log-posterior\ngradient $\\nabla log f_{X_{\\sigma_k}|Y}(x_k | y)$ in unconditional sequence of random walks.\n$x_{k+1} = x_k + \\tau_k \\nabla log f_{X_{\\sigma_k}|Y}(x_k | y) + \\sqrt{2\\tau_k T_k}N$\n$= x_k + \\tau_k (\\nabla log f_{X_{\\sigma_k}}(x_k) + \\frac{1}{\\eta^2} A^T (y - Ax_k)) + \\sqrt{2\\tau_k T_k}N$\nwhere $\\eta$ is the measurement noise level. Note that our conditional sequence of random walks framework does not require\nany measurement consistency projection step or approximation of log-likelihood. The logic behind it is that as $\\sigma_k \\rightarrow \\infty$\nand $\\tau_k \\rightarrow 0$, the iteration converges to the distributions $f_X$ and $f_{Y|X}$"}, {"title": "5 Demonstration of proposed theory", "content": "While the main contribution of this work is the simple theoretical justification and unified template for diffusion model\nalgorithms presented in Section 2 and 3, we now demonstrate concrete implementations of the theory. In particular, we\nshow unconditional generation using arbitrarily defined simple noise schedules and straightforward parameter specifications\nin a sequence of random walks framework. We empirically show this generalized and simplified approach can also be\napplicable to conditional generation with the added benefit of eliminating the need for any approximation of the gradient\nof log-likelihood.\nWe now describe our experimental setup, including dataset and pretrained networks, and experiment results of our\nsequence of random walks framework."}, {"title": "5.1 Dataset and pretrained neural networks", "content": "For numerical validation, we use two distinct types of pretrained diffusion models, both trained on the FFHQ 256\u00d7256\nface dataset [28]. For the VP diffusion model, we use the one from DPS [20], which follows the VP training template in\nTable 1 with a linear schedule for a ranging from $\\alpha_0 = 0.9999$ to $\\alpha_T = 0.98$. We also adapt a pretrained VE diffusion\nmodel from Score-SDE [8], which follows the VE training template in Table 1 with the noise level $\\sigma$ varies from $\\sigma_0 = 348$\nto $\\sigma_K = 0.01$. To validate the unconditional sampling capability of our framework, we demonstrate that any type of\ndenoiser can be used in our single framework. Also, we demonstrate that our framework can generate images with\narbitrary schedule sigmoid and linear, independent of the denoiser's training scheme."}, {"title": "5.2 Unconditional image sampling with straightforward parameter choice of sequence of\nrandom walks", "content": "In Section 3, we showed that both the Markov chain theory in DDPM [7] and the reverse SDE theory in Score-SDE [8]\ncan be viewed as making particular choices of step sizes $\\tau_k$ and temperature parameters $T_k$ in our framework in (8). In"}, {"title": "5.3 Solving inverse problems using sequence of random walks", "content": "We demonstrate the conditional sampling capability of our framework on two inverse problems. For random inpainting,\nthe forward operator corresponds to randomly masking out 92% of the total pixels (across all RGB channels). For\nsuper-resolution, the forward operator is bicubic downsampling by a factor of 4. For both problems, we set measurement\nnoise $\\eta = 0.2$. We took K = 10,000 sampling steps and set step size $\\tau_k = min(\\epsilon\\cdot (\\sigma_k)^2, \\eta^2)$ which ensures our step\nsize is smaller than the Lipschitz constant of log-likelihood term. We performed sampling with both the pretrained\nVP and VE networks as described in Section 5.1. To sample via the VP network, we used the sigmoid noise schedule\nfrom Section 5.2 and specified the remaining parameters as follows: for super-resolution ($T_0 = 1, \\epsilon_{sigmoid} = 0.22$) and for\ninpainting ($T_0 = 1, \\epsilon_{sigmoid} = 0.38$). For the VE network, we specified parameters as ($T_0 = 1, \\epsilon_{pretrained} = 0.05$) for both\ninverse problems.\nFigure 3 shows results for sampling with the VP network. The four conditional samples look plausible as faces and\ncorrespond well to the measurements. We also computed the pixel-wise average of 500 samples. For each of these, we\ncomputed the PSNR with respect to the ground truth according to\n$PSNR(x) = 10 log_{10} (\\frac{1}{MSE(x_{\\text{ground truth}}, x)})$.\nTraining images were scaled between 0 and 1 for the VE score and between -1 and 1 for the VP score. Sample images\nfrom the VP network were rescaled to lie between 0 and 1. No clipping was applied to either score function, allowing all"}, {"title": "6 Conclusion", "content": "We have introduced a simple and self-contained theoretical justification for score-based diffusion models that interprets\nsampling as solving a sequence of stochastic differential equations. This approach provides an algorithmic template\nthat encompasses a variety of algorithms from the literature, including SGM [6], DDPM [7], and Score-SDE [8]. The\nadvantages of our work are that (a) it provides a unified interpretation of existing score-based sampling algorithms;\n(b) it simplifies score-based generation by decoupling the sampling noise schedule from the training noise schedule,\nremoving the need to define forward and reverse stochastic processes; (c) it provides algorithms for conditional sampling\n(i.e., solving inverse problems) without any log-likelihood approximation. While we do not claim a new state-of-the-art\nfor generative modeling, we empirically demonstrate that a simple parameter and noise schedule selection within this\nframework can generate high-quality unconditional and conditional images.\nViewing diffusion models as we do here provides fertile ground for future work. We believe it will be particularly\nvaluable to compare different noise schedules and weightings in the training template and develop efficient methods for\ntuning the step size and temperature parameters during sampling. We hope that these explorations will reveal diffusion\nmodel algorithms that are easy to train and efficiently generate high-quality, diverse samples."}]}