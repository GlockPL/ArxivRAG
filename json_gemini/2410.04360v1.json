{"title": "GenSim: A General Social Simulation Platform with Large Language Model based Agents", "authors": ["Jiakai Tang", "Heyang Gao", "Xuchen Pan", "Lei Wang", "Haoran Tan", "Dawei Gao", "Yushuo Chen", "Xu Chen", "Yankai Lin", "Yaliang Li", "Bolin Ding", "Jingren Zhou", "Ji-Rong Wen"], "abstract": "With the rapid advancement of large language models (LLMs), recent years have witnessed many promising studies on leveraging LLM-based agents to simulate human social behavior. While prior work has demonstrated significant potential across various domains, much of it has focused on specific scenarios involving a limited number of agents and has lacked the ability to adapt when errors occur during simulation. To overcome these limitations, we propose a novel LLM-agent-based simulation platform called GenSim, which: (1) Abstracts a set of general functions to simplify the simulation of customized social scenarios; (2) Supports one hundred thousand agents to better simulate large-scale populations in real-world contexts; (3) Incorporates error-correction mechanisms to ensure more reliable and long-term simulations. To evaluate our platform, we assess both the efficiency of large-scale agent simulations and the effectiveness of the error-correction mechanisms. To our knowledge, GenSim represents an initial step toward a general, large-scale, and correctable social simulation platform based on LLM agents, promising to further advance the field of social science.", "sections": [{"title": "1 Introduction", "content": "Social science, which focuses on human behavior, communication, and organization, is playing an increasingly significant role as world civilization advances. One important research paradigm in social science is collecting real human data. For instance, to study the effectiveness of positive psychology interventions, [1] recruited over 6,000 participants to observe their responses to controlled experiments. Similarly, [5] employed 60 participants for a six-week user study to collect mobile personally identifiable information to investigate the economics of personal mobile data. While the paradigm of collecting real human data is widespread in social science research, it suffers from significant drawbacks, such as high cost, poor controllability, and challenges in reproducibility, which have troubled researchers for a long time.\nIn the field of artificial intelligence (AI), researchers have discovered that language serves as a crucial carrier of intelligence [7], and the objective of \u201cnext-token prediction\" using a massive training corpus (i.e., large language models, LLMs) has the potential to achieve human-like intelligence. With the advent of these high-intelligence models, a new \u201cAI for Social Science\" direction has emerged: leveraging LLMs as proxies for real humans to conduct social science experiments [2]. This approach provides the opportunities to fundamentally address the above challenges faced by social science research, potentially paving the way for an entirely new research paradigm. For instance, Generative agents [4] leverages 25 agents to simulate human daily life, and finds that these agents can autonomously host parties and conduct mayoral election. RecAgent [6] simulates user online behaviors, and studies the phenomenons of information cocoon and conformity behaviors."}, {"title": "2 Features of GenSim", "content": "There are several unique features of our platform. To begin with, we abstract a set of general functions to facilitate any customized simulation scenario according to the users' requirements. Then, our platform supports one hundred thousand agents to better simulate large-scale populations in real-world contexts. At last, we provide a series of error-correction mechanism to ensure more reliable simulation. The first two can be seen as static features from the generality and scalability perspectives, respectively, while the last one extends previous work from the dynamic perspective, making our platform can continually correct and improve itself."}, {"title": "2.1 General Simulation Framework", "content": "Our framework consists of three modules focusing on single agent, multi-agents, and environments (see Figure 1). In the single agent module, users can flexibly configure the agent's profile, memory and action components. The profile includes both public information, such as gender, name, and birthplace, as well as private attributes like income and health condition. To enable the agent to retain behaviors in various ways, users can assemble different memory components\u2014short-term memory, long-term memory, and the reflection mechanism\u2014to build the agent's memory. The actions of the"}, {"title": "2.2 Large-scale Simulation", "content": "While there are many previous studies on leveraging LLMs to simulate human social behaviors [2], the number of agents in their simulators are usually very small. In such cases, the users need to sample a small set of individuals from the real-world large-scale populations, and then leverage agents to simulate the sampled individuals, assuming that these samples can accurately approximate real-world populations. However, the sampled small number of individuals may lead to very large fluctuations of the simulation results. To verify this statement, we conduct a preliminary experiment by simulating the user-item rating behaviors on a movie website. In specific, we base our experiment on the well-known dataset MovieLens-32M\u00b9, which consists of 200,948 users' 32M ratings on 87,585 movies. For each user-movie pair, we use LLMs to simulate the user's rating on the movie in the range of $R = [0.5, 1.0, ..., 5.0]$. To study the fluctuation of the simulation results with different agent scales, we first sample 3.2K, 32K, 320K and 3.2M user-item pairs from the complete dataset, and then, for each case, we repeat the simulation of predicting user-item ratings for 10 times. Formally, suppose $p_i$ represents the rating distribution of the ith experiment, where i = 1, 2, ..., 10. For each rating $r\\in R$, we compute the standard deviation across all experiments as\n$v(r) = \\sigma(p_1(r), p_2(r), . . ., p_{10}(r))$\nwhere $\\sigma(\\cdot)$ denotes the standard deviation operation. We use the sum of the standard deviations for all possible ratings to measure the fluctuation of the simulation results. The experiment results are presented in Figure 2(a), where we can see: as the number of samples becomes larger, the fluctuation of the simulation results is greatly lowered. This result suggests that if we only have a small number of agents, then the simulation results can be not reliable, since it can be hardly reproduced due to the large simulation fluctuation.\nTo solve the above problem, in our platform, we support up to one hundred thousand agents to better simulate real-world scenarios. To accelerate the simulation speed, we adapt a series of techniques including distributed parallel computing and so on. Using our platform, we evaluate the simulation speed in the job market and recommendation scenarios, where we run our simulator for one round for both settings\u00b2. The results are presented in Figure 2(b), from which we can see: as the number of agents becomes larger, the time cost increases, and when we have 10w agents, they cost 15492 and 3024 seconds for running one round in the job market and recommendation scenarios, respectively.\nIn addition, we also evaluate the acceleration effects of distributed parallel computing in our platform. In specific, we measure the time costs of running our platform for one round with different numbers of GPUs. The results are presented in Figure 3(a), where we can see, as the number of GPUs becomes"}, {"title": "2.3 Simulation Error Correction", "content": "Most previous LLM-agent-based simulation platforms lack error-correction mechanisms, which means that if unexpected results occur during the simulation process, they can be accumulated and amplified as the simulation progresses (see Figure 3(b)). To solve this problem, in our platform, we provide two strategies for correcting the simulation errors. The first one is based on LLMs, where we leverage GPT-40 to score on or revise the simulated results. The second one is based on real humans, where we provide interfaces for the users to score or revise the simulated agent behaviors. Between these two approaches, the first is more efficient and requires no human intervention, though it may be less accurate due to the inherent biases of LLM. The second approach is more aligned with real humans but can be labor-intensive and less efficient. Suppose the simulation result is represented by a (q, a) pair, where q is the prompt for driving an agent action, and a is the action. For each of the above strategies, there are two forms of feedback provided by LLMs or real humans. Let the score for (q, a) be s, and a' be the revised results\u00b3. Then, we use (q, a, s) and (q, a') to fine-tune the backbone LLMs using PPO and SFT, respectively.\nTo evaluate the effectiveness of our designed error-correction mechanisms, we conduct experiments based on the job market scenario with LLMs as the feedback provider. To begin with, we evaluate whether PPO and SFT can improve the simulation results in a single round. In the experiments, we select different numbers of samples for labeling, and use GPT-40 to measure the reasonableness of the simulation results. From Figure 4(a), we can see: for both PPO and SFT, they can improve the simulation performance across different numbers of labeled samples. Compared with PPO, the results of SFT are better, which is reasonable, since the revised action a' used in SFT may include more effective and comprehensive information.\nNext, we evaluate the effectiveness of the error-correction mechanisms in a multi-round setting. Specifically, we fine-tune the backbone LLMs in the earlier round and use the updated models to simulate the results in the subsequent round. We present the results in Figure 4(b). We can see: if we do not conduct error-correction (the yellow line), the simulation performance is unsatisfactory. When"}, {"title": "3 Usages of GenSim", "content": "In this section, we introduce the basic methods for running a default scenario. For more details, readers can refer to our project website https://github.com/TangJiakai/GenSim.\nThe complete interfaces of our platform are presented in Figure 5. In specific, the user needs to click the 'Get Started' button to initiate our platform. Then, the user can configure the simulation by specifying the scenarios, agent profile, memory type, number of agents, LLM parameters, and more. Once configured, the platform can be launched. The simulation interface consists of three sections: At the top, there is a search box that allows the user to search for an agent to observe its status and track its behavior. In the middle, there is a display window where the behaviors of multiple agents are shown. On the right, there is a functionality window where users can view agent profiles, intervene in the system, and interact with agents. After running the platform for several rounds, the user can stop the simulation and label the results. Finally, the backbone LLMs can be fine-tuned based on the labeled results, and used in the following simulation process."}, {"title": "4 Conclusions", "content": "In this paper, we introduce a general, large-scale, and correctable social simulation platform based on LLM agents. This is the initial version of our platform, we believe there is still much room left for improvement. In the future, we plan to incorporate more advanced simulation accelerating strategies, and develop more adaptive self-correction mechanisms."}]}