{"title": "MindScope: Exploring cognitive biases in large language models through Multi-Agent Systems", "authors": ["Zhentao Xie", "Jiabao Zhao", "Yilei Wang", "Jinxin Shi", "Yanhong Bai", "Xingjiao Wu", "Liang He"], "abstract": "Detecting cognitive biases in large language models (LLMs) is a fascinating task that aims to probe the existing cognitive biases within these models. Current methods for detecting cognitive biases in language models generally suffer from incomplete detection capabilities and a restricted range of detectable bias types. To address this issue, we introduced the 'MindScope' dataset, which distinctively integrates static and dynamic elements. The static component comprises 5,170 open-ended questions spanning 72 cognitive bias categories. The dynamic component leverages a rule-based, multi-agent communication framework to facilitate the generation of multi-round dialogues. This framework is flexible and readily adaptable for various psychological experiments involving LLMs. In addition, we introduce a multi-agent detection method applicable to a wide range of detection tasks, which integrates Retrieval-Augmented Generation (RAG), competitive debate, and a reinforcement learning-based decision module. Demonstrating substantial effectiveness, this method has shown to improve detection accuracy by as much as 35.10% compared to GPT-4. Codes and appendix are available at https://github.com/2279072142/MindScope.", "sections": [{"title": "1 Introduction", "content": "Recent studies have uncovered a gradual emergence of human-like cognitive biases within LLMs [42, 16, 14]. Cognitive biases represent systematic errors in processing information and decision-making [10], which introduce unforeseeable risks in LLM-based applications. In the financial field, cognitive biases might manifest as an overemphasis on specific market trends or an inability to adequately reflect risks, leading to suboptimal investment decisions. In the medical field, LLMs can collaboratively diagnose diseases and predict patient outcomes [40, 25]. However, some cognitive biases such as the anchoring effect [34] and overconfidence [19] may lead to inaccurate medical advice or diagnosis. Hence, it is urgent and imperative to establish a robust mechanism for detecting cognitive biases, encompassing the development of comprehensive datasets that can effectively identify cognitive biases in LLMS, as well as reliable methods for detection and evaluation. There are three challenges: (1) It is difficult to construct comprehensive and standardized datasets with large-scale samples. (2) High annotation cost for detection. (3) With more cognitive bias types and scenarios involved, the detection accuracy may decrease.\nPrior studies [14, 18, 4, 29] have explored cognitive biases in LLMs, while the type of cognitive biases is limited or the data is"}, {"title": "2 Related Work", "content": ""}, {"title": "2.1 Cognitive biases in LLMs", "content": "There has been a trend in utilizing LLMs to accomplish various tasks in specific domains, such as BloombergGPT [39] and Med-PaLM [31]. However, just as humans exhibit systematic errors, known as cognitive biases [10, 5], in information processing and decision-making, LLMs also display similar biases in their decision processes [16, 1, 22, 4]. Current research of cognitive biases in LLMs primarily focuses on three areas: detecting biases [4, 18, 14, 23], mitigating biases [29, 12], and utilizing them for social experiments [30]. Study [14] has revealed previously unobserved cognitive biases in fine-tuned models. In terms of bias mitigation, researchers [12] have successfully reduced known biases by explicitly alerting the models to their potential cognitive biases. For social experiments, researchers [30] have created emails with embedded cognitive biases to compare against manually crafted scam emails. Despite these efforts, existing research is often limited by overly simplistic testing methods or a narrow scope of biases. To overcome these limitations, we introduce the MindScope dataset, designed to systematically and comprehensively assess cognitive biases in LLMs."}, {"title": "2.2 LLM-based Multi-Agent System", "content": "Multi-agent systems [20, 9, 15] enhance capabilities by specializing LLMs into distinct agents with unique skills, enabling them to interact dynamically and simulate complex environments effectively. Current research is mainly divided into problem solving and world simulation. In terms of problem-solving, this involves software development [13, 28], embodied agents [41], scientific experiments [44], and scientific debate [11]. For example, multi-agent collaboration in software development [13] significantly reduces costs, while in embodied agents, agents perform complex real-world planning tasks to address physical challenges [41]. World simulation has made rapid progress in fields such as social simulation [27], gaming [35], psychology [2], and economics [21]. For instance, [27] established a town simulation system consisting of 25 agents to study social interactions, while [2] explored how agents can acquire and develop social skills such as shared attention and cultural learning through psychological principles. In economics, [21] introduced an LLM-based multi-agent method for financial transactions, which enhances decision robustness through personalized transaction roles. However, when these systems are directly applied to cognitive bias detection, they encounter significant challenges such as difficulty in detecting unlabeled biases, lack of comprehensive consideration, and poor interpretability. To overcome these limitations, we propose a new detection method that integrates RAG, competitive debate, and reinforcement learning decision modules."}, {"title": "3 Problem Definition", "content": "This work aims to detect both explicit and implicit cognitive biases in LLMs by single-round or multi-round scene-based dialogues. In addition to detecting existing categories, users can also expand the evaluation scope according to their own needs and do more standard cognitive bias experiments. We designed two tasks: labeled cognitive bias detection and unlabeled cognitive bias detection. The labeled cognitive bias detection task aims to detect biases by explicitly providing the types of cognitive biases and evaluation criteria. Unlabeled cognitive bias detection does not provide specific kinds of cognitive biases. During the detection process, candidates need to be selected from various possible biases based on the current scene and undergo more detailed scrutiny. In Section 4.1 and Section 4.2, we employed the labeled cognitive bias detection method to provide comprehensive detection results quickly. In addition, our proposed detection method in Section 5.3 aims to address unlabeled cognitive bias detection task, which is more suitable for real-world situations."}, {"title": "4 Dataset Construction", "content": "In addressing cognitive biases in decision-making, we construct the MindScope dataset, which includes both static and dynamic scenarios. The static portion comprises 5170 open-ended questions addressing 72 different cognitive biases, while the dynamic portion includes scripts for multi-round dialogues in over 100 scenarios. Additionally, users can use these scripts to generate tailored and large-scale datasets automatically. With the combination of static and dynamic scenarios, we can more precisely and comprehensively identify and quantify cognitive biases. During the construction, each scenario was designed to contain only one cognitive bias."}, {"title": "4.1 Static dataset construction", "content": "Since we mainly explore cognitive biases related to decision-making, we selected 72 cognitive biases from the list of decision-making cognitive biases in Wikipedia's repository for in-depth analysis (see Appendix A, Tables 2-4). Initially, we extracted classic examples of cognitive biases from literature and Wikipedia to ensure the authenticity and accuracy. With the assistance of cognitive science experts, we employed GPT-4 to create corresponding scenario texts based on these examples. Guided by these scene generation texts (see Appendix A, Table 5), we prompted GPT-4 to generate diverse open-ended questions and assessment criteria. Subsequently, cognitive science experts conducted a thorough validity review of the generated scenarios, focusing on the appropriateness of the test questions, the accuracy of the assessment criteria, and the unbiased nature of the scenarios. Notably, we employed three cognitive science experts and they underwent standard training for the consistency of annotation."}, {"title": "4.2 Dynamic dataset construction", "content": "While static datasets have played a role in revealing cognitive biases of LLMs, they exhibit limitations in capturing complex biases that require multiple interactions to manifest, such as order biases and planning fallacies. These dynamic biases rely on continuous decision-making processes, which are difficult to fully capture in a single response. Hence, we developed a dynamic dataset capable of simulating and capturing cognitive biases within ongoing interactions. It comprises multi-role scenario scripts, encompassing background settings, characters, tasks, and the logic of interactions between characters. Users can modify these scripts to generate personalized data. There are three distinct roles in the scripts: the Subject, the Confederate, and the Moderator. The Subject is the focal point for cognitive biases detection, the Confederate is to induce the Subject to display the targeted biases, while the Moderator neutrally responds to the Subject's queries and poses impartial questions. Due to constraints in"}, {"title": "5 Method", "content": "The existing multi-agent frameworks based on LLMs cannot meet the controllability requirement for cognitive biases detection, and they are inflexible to construct dynamic multi-round dialogues. Hence, we propose a rule-based multi-agent communication framework (RuleGen), which allows agents to interact in an orderly and controllable manner. Moreover, to detect unlabeled biases in open environments, we propose a learnable bias detection method based on multi-agent framework. In detail, Section 5.1 explains the foundational architecture of RuleGen; Section 5.2 introduces the rules and steps for automatically building scenarios and how to supervise and correct agent behaviors; Section 5.3 describes the bias detection method involving cognitive bias identification, debate competition module, and the learnable decision module."}, {"title": "5.1 The foundational architecture of RuleGen", "content": "RuleGen is proposed for simulating the multi-round dialogue in real-world scenarios according to the given script. It needs to control the fine behaviors of agents based on the rules of the current detection task. Inspired by [27], the role agents in RuleGen are composed of memory, planning, reflection, action, and agent configuration modules (Figure 2).\nMemory module: Short-term memory stores the recent k-round dialogues. When it reaches the threshold, it will be summarized and stored in the long-term memory. The agent will retrieve the necessary memory as required.\nPlanning module: To ensure that the intelligent agent can generate effective responses, we follow the [36] settings, requiring the agent to decompose the request in the plan chain before responding.\nReflection module: Agents evaluate their behaviors, identify potential problems, and propose corresponding solution strategies. It aims at learning from historical experiences.\nAction module: Based on the provided interaction rules, along with the memory, reflection, and planning modules, it makes specific and appropriate responses.\nAgent configuration: As illustrated in Figure 2, we have established two distinct types of agents: role agents and system agents. In order to adapt to different scenarios and show personalized differences, RuleGen guides and constrains the action space of the role agents by setting the names, identities, tasks, and background stories. In addition to role agents, we also need system agents to allocate script resources, and supervise and correct the behaviors of role agents."}, {"title": "5.2 Rule-Based Multi-Agent Communication", "content": "In order to solve the problem of poor flexibility, controllability and limited interaction mode, we propose a novel rule-based multi-agent communication mechanism, that focuses on automatic scenario construction and multi-dimensional agent behavior monitoring."}, {"title": "5.2.1 Automated rule-based scenario construction", "content": "As shown in Figure 2, this part is divided into two key components: rule generation and rule interpreter, aiming at constructing various scenarios precisely according to the preset rules alone, without modifying the agent's prompt and related codes.\nScenario rule generation: Scenario rules consist of five key attributes: initiated role, received role, mode of transmission, interaction purpose, and interaction content. The initiating object and receiving object both refer to the role of agents in the scenario. The propagation mode covers four types of information dissemination: unicast (one-to-one), broadcast (one-to-all), multicast (one-to-many), and self-receival (receiving information from the system). The interaction purpose is built according to the nine basic communication objectives [6] and the received system information. The interaction content describes the tasks that the current role agent needs to perform.\nRule Interpreter: The rule interpreter module functions as the semantic parser for the scenario rules, orchestrating the flow of responses from the initiator to the recipient aligned with the chosen transmission mode, thereby ensuring the transmission's precision and efficacy. Concretely, the module processes a rule by pinpointing the initiator and recipient, assimilating the interaction purpose and content into a structured request to the initiator, and facilitating the appropriate dissemination of the initiator's response to the recipient as per the prescribed transmission mode."}, {"title": "5.2.2 Multi-Dimensional Agent Behavior Monitoring", "content": "To address the problem of unpredictable and uncontrollable agent behavior, the RuleGen framework institutes a hierarchical behavior regulation mechanism through system agents to manage and rectify agent actions within the simulation.\nMacro Behavior Monitoring: At the macro scale, system agents govern the overarching actions of role agents relative to the scenario's objectives. Deviations from the established scenario blueprint are promptly adjusted by the system agent to realign participant actions with scenario specifications.\nMicro Behavior Monitoring: As illustrated in Figure 2, micro-level behavior monitoring involves system agents conducting meticulous monitoring of role agents' interactions. These system agents evaluate responses against predefined interaction objectives and content. Employing Zero-Shot CoT [36] methodologies, the system agent assesses the appropriateness of a participant agent's actions at each timestep t, and guides corrective measures in the event of deviations. This process includes issuing a rectification directive when a role agent's behavior diverges from the script or interaction goals. The role agent then adjusts its actions to ensure adherence to designated interaction protocols. Conversely, adherence to expected behavior is confirmed through a verification instruction."}, {"title": "5.3 Detecting Cognitive Bias Without Labels", "content": "Existing models performed well when they were told what type of bias to detect [4]. However, cognitive bias detection without the type label is more difficult. This paper focuses on a deeper exploration of unlabeled cognitive bias detection, which is more in line with actual application. As shown in Figure 3, a cognitive bias detection method (CBDC) is proposed to solve the challenges of detecting potential cognitive bias and improving interpretability."}, {"title": "5.3.1 Cognitive Bias Recognition and Detection", "content": "In order to enhance the recognition and understanding capabilities of agents for recognizing cognitive biases, we constructed an external knowledge vector library $K$, which consists of detailed descriptions of 72 cognitive biases. This library stores detailed information about various cognitive biases. During the initialization of each competitive detection agent, we will retrieve the information on the corresponding biases from $K$ and pass this information to the corresponding agent, enabling them to gain a deeper understanding.\nAs the details shown in Figure 3, firstly, we screen the test text $T$ through two agents with different personalities: Aggressive $A_r$ and Conservative $A_c$, and obtain cognitive bias sets $B_r$ and $B_c$. In order to prevent the real bias from being overlooked, $B_r$ and $B_c$ are further merged to obtain the candidate set $B$. Next, a specific bias category $B_i$ in the candidate set $B$ will be passed to a specific competitive detection agent $CA_i$, and $CA_i$ will then determine whether the text $T$ contains the bias category $B_i$."}, {"title": "5.3.2 Debate competition based on loser trees", "content": "The same sample may be identified as different cognitive biases by different agents. To improve stability, we propose a multi-agent competitive debate mechanism. However, if the size of candidates is N, the complexity will be $O(N)$. Therefore, we innovatively propose a debate competition method based on a loser tree, reducing the complexity to $O(log_2N)$.\nAs revealed in Figure 3, the constructed loser tree has N leaf nodes, each node represents a competitive detection agent dedicated to detecting a specific cognitive bias. This approach can transform unlabeled detection into labeled detection, effectively simplifying the detection process. Subsequently, the agent employs labeled detection techniques to assess the presence of cognitive biases. It then constructs a loser tree for all leaf nodes that exhibit cognitive biases. These agents follow the structure of the loser tree and carry out an orderly and efficient debate in the order of: 1). Opening (introducing the features and cases of the cognitive bias); 2). Argument (citing evidence of the cognitive bias); 3). Refutation (refuting the opponent's views according to the previous debate content); 4). Summarize views. The competition process continues until finally only one competitive detection agent is left. It is considered as the final cognitive bias type."}, {"title": "5.3.3 Decision module based on reinforcement learning", "content": "In the debate, the competition between agents is decided by the referee agent. In order to ensure the reliability of the decision, we innovatively introduce two referee agents, $JA_1$ and $JA_2$, with different decision-making styles. Inspired by the scoring rules of debate competitions, we score the performance of different competitive agents from six different indicator dimensions, including argument support, logical consistency, effective rebuttal, argument completeness, persuasiveness, and reasonable assessment of cognitive bias. Lastly, we use a reinforcement learning model trained by DQN [24] to make decisions.\nAs illustrated in Figure 3, the decision module is divided into two stages: the training stage and the decision stage. Specifically, we set up a decision task to assess the performance of two agents within a given environment and make decisions based on a set of weights. In the training phase, we initialize a replay buffer with capacity N and define an action-value function $Q$ with random initial weights $\\theta$. Concurrently, the target action-value function $Q$ is initialized with $\\theta' = \\theta$. Over M episodes, each episode starts with the initial state and its preprocessed sequence. At each time step t, the agent uses a genetic algorithm strategy to search for the selection of an action $a_t$ to be performed in the environment. The resulting transition tuple $(s_t, a_t, r_t, s_{t+1})$ is stored in the replay buffer $D$. A minibatch of transitions is randomly sampled from $D$, and the target $y_j$ for each transition is computed as follows: $y_j = r_j$ if the episode ends at the next step; otherwise $y_j = r_j + \\gamma max_a Q(s_{j+1}, a'; \\theta')$. The network parameters $\\theta$ are updated by minimizing the squared error loss $(y_j - Q(s_j, a_j; \\theta))^2$ through gradient descent. To ensure stability, the weights $\\theta'$ of the target network are updated to match the current Q-network weights $\\theta$ every C step. This process refines the policy for optimal decision-making in the specified environment. In the decision phase, we leverage the best-performing weights from the training phase as the decision weights, comparing the scores of two agents to declare a winner. The specific experimental setup is detailed in Appendix F.3."}, {"title": "6 Experiments", "content": "This section details extensive experiments and analyses on the Mind-Scope dataset, focusing on key issues: (1) Assessing GPT-4's capability as a cognitive bias evaluator. (2) Evaluating cognitive bias in various LLMs. (3) Testing the effectiveness of RuleGen and CBDC. The specific models used are GPT-4-turbo and GPT-3.5-turbo-16k, respectively."}, {"title": "6.1 Proficiency testing of GPT-4 as an evaluator", "content": "Experimental Design. We sampled 10% of the data for each bias type from the static dataset and recruited three psychology graduate and PhD students for manual annotation. We ensure reliable correlation between annotators. The detailed annotation strategy can be viewed in Appendix C.\nEvaluation Method. We use accuracy, Pearson's coefficient, and the Kappa statistic to calculate the correlation between the evaluation results of GPT-4 and human evaluators. GPT-4 conducted assessments via interpretable zero-shot prompts, judging the presence of specific cognitive biases based on current scenarios, evaluation criteria, and the names and descriptions of biases. To ensure consistency, the temperature parameter was set to 0, and GPT-4's evaluation was repeated three times.\nResult analysis. The average results from three evaluations reveal a significant correlation between GPT-4 and humans in the annotation task. Notably, the average kappa statistic is 0.7180, the Pearson correlation coefficient is 0.7230, and the average accuracy is 88.08%. Specifically, the Kappa statistics for the three evaluations of GPT-4 are 0.9395, 0.9546, and 0.9402, respectively. These highly consistent statistics underscore the robustness and reliability of its assessment process. more details in Appendix C."}, {"title": "6.2 Cognitive bias in different LLMs", "content": ""}, {"title": "6.2.1 Cognitive bias detection in static dataset", "content": "Testing Methodology on static dataset: To evaluate the level of cognitive biases in LLMs, we employed the static data in MindScope to test 12 LLMs, including GPT-4, GPT-3.5-Turbo, Gemini-Pro [32], Llama2 series [33] and Vicuna series [43]. To ensure fairness, the same prompts were input to LLMs. The outputs were recorded in the format: <Question - Evaluation Tag - Answer - Model - Presence of Bias - Name of Bias>, more details in Appendix E.1."}, {"title": "6.2.2 Cognitive bias detection in dynamic datasets", "content": "Testing Methodology: We employed RuleGen for transforming scripts into test samples formatted as mulit-round dialogues, including initializing system agents and role agents, and controlling the interaction based on the rules. We used GPT4 to detect whether the Subject agent has the cognitive bias, more detail in Appendix E.2.\nResult analysis. We systematically tested 12 different cognitive biases in dynamic scenarios. As indicated in Figure 5, in the static evaluation data, both GPT-4 and GPT-3.5 showed almost no cognitive biases in Sunk Cost Fallacy, Planning Fallacy, and Unit Bias. However, as shown in Figure 6, these cognitive biases were significantly more pronounced in multi-round dialogues. That demonstrates a notable difference from the static dataset. This finding reveals that cognitive biases may be more prominent in complex interactions."}, {"title": "6.3 The effectiveness of the detection framework", "content": ""}, {"title": "6.3.1 evaluation metrics", "content": "Overall Accuracy(Acc (%)): The ratio of cases correctly identified by the algorithm to the total number of cases.\nBias Case Accuracy ($Acc_{bias}$ (%)): The proportion of actual bias-present cases that the algorithm correctly identifies.\nNo-Bias Case Accuracy($Acc_{nobias}$ (%)): The proportion of actual bias-absent cases that the algorithm correctly identifies."}, {"title": "6.3.2 Main Results", "content": "We utilized 301 static test samples annotated by psychology experts as a test dataset. As Table 2 demonstrates, our multi-agent detection method significantly outperforms existing techniques. Compared to GPT-4, our method improved overall accuracy by 35.10%. This notable enhancement is especially prominent in complex cases with cognitive biases, where our detection accuracy for such cases increased by nearly 26.48% compared to GPT-4. The experimental results indicate a clear advantage of our method in identifying cases with cognitive biases. Moreover, in cases without cognitive biases, our method achieved an improvement of approximately 38.37% over GPT-4."}, {"title": "6.3.3 Ablation Study", "content": "First, we analyzed the basic framework combining candidate generation and knowledge retrieval to detect cognitive biases. An initial agent identifies biases and construct the candidate set. The final detection is made by another agent. Next, we added the pruned loser tree method to improve debate and decision-making among agents, with a referee agent finalizing the decision. Lastly, we integrated a reinforcement learning decision module to enhance the referee agent's decision-making and adaptability. Results in Table 2 show notable improvements. Also as shown in Table 3, we use various optimization algorithms on our selected debate scenario training set as well as test set. The results show that the optimization of weights by reinforcement learning is optimal on both the training and test sets. The specific experimental setup can be found in Appendix F.2."}, {"title": "6.4 Case study", "content": "To explore how different decision-making styles affect cognitive biases in LLMs, we crafted a scenario script and use RuleGen to generate the multi-round dialogues. The key focus was on the character 'Subject' to assess the impact of the sunk cost effect. We simulated this scenario twice, once with an aggressive and once with a conservative decision-making style. As shown by the red text in Figure 7, the sunk cost effect emerged in the aggressive style but not in the conservative. This indicates that decision-making styles can influence the occurrence of cognitive biases in LLMs."}, {"title": "7 Conclusion", "content": "This paper introduces a new benchmark called MindScope for exploring the cognitive biases of LLMs. MindScope consists of both static and dynamic parts, resulting in a series of interesting findings for decision-making and model tuning. In particular, based on our proposed RuleGen, multi-round conversation can be generated controllably through a simple script. Users also can generate large personalized dataset and complete many psychological experiments by RuleGen. Moreover, we introduce a multi-agent detection method using loser trees and a decision module based on reinforcement learning for cognitive bias detection without labels."}, {"title": "Acknowledgements", "content": "This work is supported by the National Natural Science Foundation of China (Grant No. 62207013), the Science and Technology Commission of Shanghai Municipality (Grant No. 22511106103), and CCF-Baidu202322."}]}