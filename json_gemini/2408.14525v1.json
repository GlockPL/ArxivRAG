{"title": "Estimating Uncertainty with Implicit Quantile Network", "authors": ["Yi Hung Lim"], "abstract": "Uncertainty quantification is an important part of many performance critical ap-plications. This paper provides a simple alternative to existing approaches such as ensemble learning and bayesian neural networks. By directly modeling the loss distribution with an Implicit Quantile Network, we get an estimate of how uncertain the model is of its predictions. For experiments with MNIST and CI-FAR datasets, the mean of the estimated loss distribution is 2x higher for incorrect predictions. When data with high estimated uncertainty is removed from the test dataset, the accuracy of the model goes up as much as 10%. This method is simple to implement while offering important information to applications where the user has to know when the model could be wrong (e.g. deep learning for healthcare).", "sections": [{"title": "Introduction", "content": "The revolution in deep learning has led to many profound consequences across different fields. As deep learning models become more and more integrated into industry, uncertainty quantification becomes more and more important to ensure the safety of the users and the performance of the software. Many prior work has tried to tackle this problem by changing the main model architec-ture itself, leading to variants of neural networks such as bayesian neural networks. However, these approaches still fall short of ensemble models and dropout [Srivastava et al., 2014, Gal and Ghahra-mani, 2016], and sometimes even decrease in accuracy compared to vanilla models. [Ovadia et al., 2019] We propose a simple add-on to any deep learning model that would benefit from uncertainty quantification. By repurposing Implicit Quantile Network to predict the loss distribution of the pre-diction model on the training set, we can get an estimate of the uncertainty of the model on the test set. This approach does not require any architecture change to the vanilla model and does not require as much compute as ensemble models to train many independent copies of the same model."}, {"title": "Background / Related Work", "content": null}, {"title": "Implicit Quantile Networks for Distributional Reinforcement Learning", "content": "Deep Q Network agents are a class of reinforcement learning algorithms that uses Q learning to try to learn a policy that would maximize the expected return [Mnih et al., 2013]. However, these agents often output a single scalar estimate of the return value, which does not take into account the randomness of its environments. Implicit Quantile Network was proposed by Dabney et al.[Dabney et al., 2018] to introduce a new DQN-like agent that approximates the entire distribution of the return value instead of regressing the expected value. By randomly sampling \\( \\tau \\sim U([0, 1]) \\), we can approximate a value for each quantile (aka percentile) of the distribution. During inference, batches of T are sampled to approximate the true distribution. IQN outperforms DQN by a wide margin both in terms of sample efficiency and final performance. A proposed explanation for this gap is that IQN does not suffer from noisy gradients where the scalar target varies significantly due to the inherent randomness of its environment. IQN uses a quantile regression loss to try to approximate a better distribution target given its current predicted distribution."}, {"title": "Ensemble Models", "content": "Ensemble Models [Parker, 2013] is an approach to modeling uncertainty by training many indepen-dent copies of the same model. By doing so, any disagreement among these models can be labeled as uncertainty. By using significantly more compute, these models are robust when given data that are out of distribution because predictions from independent copies will disagree with each other when their predictions are wrong or if the data is out-of-distribution. Empirically, this method yields the best results in terms of accuracy and uncertainty quantification."}, {"title": "Dropout for Uncertainty Estimation", "content": "Another approach to estimate uncertainty is to use dropout [Srivastava et al., 2014, Gal and Ghahra-mani, 2016]. If the model is certain of its prediction, then dropping some units along with their connections will still result in the same prediction. However, if the predictions vary, then the dif-ference in output can be interpreted as uncertainty. Some approaches try to incorporate dropout at training time while other work try to mimic an ensemble of models by only incorporating dropout at test time."}, {"title": "Bayesian Neural Networks", "content": "Bayesian Neural Networks attempt to quantify uncertainty by learning a posterior distribution of the weights. Therefore, each weight sample produces different outputs to form a distribution which captures the modes of the output. Although there are theoretical benefits for using BNN, it can be computationally expensive and sometimes fall short in accuracy."}, {"title": "Preliminaries", "content": "We briefly review the formulation for training IQN. Instead of the computing Q(x, a), we define Z(x, a) as the distribution of all possible returns. Then, we can get Q(s, a) from Z(s, a) given \\( Q_{\\beta}(x, a) := E_{\\tau \\sim U([0,1])} [Z_{\\beta(\\tau)}(x, a)] \\). The policy would simply be to maximize the expectation where \\( \\pi_{\\beta}(x) = argmax_{a \\in A}Q_{\\beta}(x, a) \\). During training, we randomly sample \\( \\tau \\sim U([0, 1]) \\) and use the quantile regression loss [Huber, 1992] to minimize the TD-errors. Formally,\n\\[ S' = r_t + Z_{\\tau}(x_{t+1}, \\pi_{\\beta}(x_{t+1})) - Z_{\\tau}(x_t, a_t). \\]                                                        (1)\nThen, we can train the quantile estimates with threshold \\( \\kappa \\). (Alternatively, we can use the mean squared error loss instead of the huber loss for quantile regression)\n\\[\\rho_{\\kappa}^{\\tau}(\\delta_{ij}) = |\\tau - I_{\\{\\delta_{ij} < 0\\}}| \\kappa(\\delta_{ij}),\\]\nwith the Huber loss as\n\\[\\kappa(\\delta_{ij}) = \\begin{cases}\n    \\frac{1}{2}\\delta_{ij}^{2} & \\text{if } |\\delta_{ij}| \\leq \\kappa \\\\\n    \\kappa(|\\delta_{ij}| - \\frac{1}{2}\\kappa) & \\text{otherwise}\n\\end{cases}\\]\nFor two samples \\( \\tau, \\tau' \\sim U([0,1]) \\), and policy \\( \\pi_{\\beta} \\), the sampled temporal difference (TD) error at step t is\n\\[L(x_t, a_t, r_t, x_{t+1}) = \\frac{1}{NN'}\\sum_{i=1}^{N} \\sum_{j=1}^{N'}\\rho^{\\tau}_{\\kappa}(\\delta_{ij}^{t}). \\]\n(2)\nwhere N and N' denote the respective number of iid samples \\( \\tau_i, \\tau'_i \\sim U([0, 1]) \\) used to estimate the loss. Intuitively, for a given \\( \\tau_i = 0.75 \\), the pareto optimal point would be at the 75th percentile of all"}, {"title": "Modeling Loss with Implicit Quantile Network", "content": "In the reinforcement learning setting, Implicit Quantile Network takes in a state and sample many \\( \\tau \\sim U([0, 1]) \\) to output an approximated distribution of Q values. For our work, we aim to quantify uncertainty using IQN for the supervised learning setting. During training, we sample ti to approx-imate the distribution of the loss scalar, although we set the N = 64 and N' = 1, the model can still approximate the loss distribution over many iterations as the quantiles are trained to converge to its respective values.\nExisting work has only used IQN to model rewards in reinforcement learning settings. This paper shows that we can directly predict the loss of the supervised learning model to get an estimated error which can then be used to quantify how certain a model is about its prediction. This approach requires additional compute by training a separate neural network that approximates the loss distri-bution of the original model after training.\nBefore regressing the loss, we train the main model on the dataset as usual, the trained weights are then transferred to the IQN after training which is then re-trained to predict the loss distribution on the training set.\nFor all experiments, N taus are sampled at each iteration with each representing a percentile of the distribution. The IQN then outputs a predicted loss distribution based on the tau values which is then trained using the quantile regression loss. We hypothesize that estimating loss quantifies both aleatoric uncertainty (data uncertainty) and epistemic uncertainty (model uncertainty) since it is both a measure of poorly labeled data and suboptimal weights."}, {"title": "Experiments", "content": "This simple approach is tested on common image classification benchmarks including MNIST and CIFAR [Deng, 2012, Krizhevsky et al., 2009] to determine whether IQN can correctly predict which images the model is more likely to get wrong. Since the increased accuracy could be a direct result of estimating the loss, experiments are also done for models where we only predict a scalar estimate to benchmark against the gains of predicting a distribution. Code is released on Github. https://github.com/YHL04/confidenceiqn"}, {"title": "Experiment Setting", "content": "All experiments are done with a Convolutional Neural Network as backbone for all models. All benchmarks are trained in 20 epochs. We use the Adadelta optimizer with a learning rate of 1.0 and step learning rate \\( \\gamma \\) of 0.7. In addition, IQN is also benchmarked on images that are completely pitch black (hold no information) to see whether the estimated distribution agree that it should be very uncertain of its prediction."}, {"title": "Results", "content": "Below are the computed statistics for the estimated loss distribution on the datasets after training. For MNIST examples, the IQN has a predicted mean 10x higher than the dataset mean for incorrectly predicted labels while the scalar model is unable to distinguish as clearly with only a slight increase in estimated loss."}, {"title": "Distributions", "content": "The MNIST and CIFAR100 samples and its predicted distributions are shown below. According to the results, handwritten digits that are more ambiguous have a substantially higher loss distribution. The red line is the mean over all the samples. Each sample uses 10000 tau samples for the distri-bution. From the visualization of the distribution, we see that the pitch black image has very high estimated loss distribution while clearer handwritten digits have below average distributions. Even though the pitch black image is OOD, it is still able to consistently predict a high distribution. An advantage of IQN is that is it able to capture all the modes of the distribution to account for different cases (different probability densities) instead of simply regressing the expected value."}, {"title": "Future Work", "content": "A promising research direction would be to use this method to filter out bad data for different modal-ities (such as outliers or incorrect labels). After training the model and IQN, any data with abnormal estimated loss distribution can be reviewed and filtered out. This improves the accuracy compared to simply using the real error from the model. If there's a 10% chance of a defective label, IQN would be able to detect that within its distribution, where it can be flagged for further processing. Future research can also incorporate FQF which is a descendant of IQN that regress a fixed set of taus T instead of randomly sampling from the uniform distribution to further improve efficiency by having more fine grained control over the shape of the distribution."}, {"title": "Conclusion", "content": "Our work shows that Implicit Quantile Network is not only beneficial to account for randomness in reinforcement learning settings but can also be used to estimate uncertainty in supervised learning settings. For all the experimented datasets, this method improves accuracy by approximating the distribution of the loss and removing data associated with high loss distributions.\nThis simple alternative could be crucial for applications where using ensemble learning to train multiple copies of the same model is not computationally feasible. This work have practical ap-plications in medical diagnosis, financial systems and self-driving where predictions that are more likely to have a high error can be disregarded (e.g. for safety concerns or losses in equity). This paper proposes a simple add-on for deep learning models to estimate uncertainty. We advocate that all risk sensitive models adopt this method as an add-on to provide potentially crucial information."}]}