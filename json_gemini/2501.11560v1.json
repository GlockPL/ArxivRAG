{"title": "Explainable Lane Change Prediction for Near-Crash Scenarios Using Knowledge Graph Embeddings and Retrieval Augmented Generation", "authors": ["M. Manzour", "A. Ballardini", "R. Izquierdo", "M. A. Sotelo"], "abstract": "Lane-changing maneuvers, particularly those executed abruptly or in risky situations, are a significant cause of road traffic accidents. However, current research mainly focuses on predicting safe lane changes. Furthermore, existing accident datasets are often based on images only and lack comprehensive sensory data. In this work, we focus on predicting risky lane changes using the CARLA Risky-lane-change Anticipation in Simulated Highways (CRASH) dataset (our own collected dataset specifically for risky lane changes), and safe lane changes (using the HighD dataset). Then, we leverage Knowledge Graphs (KGs) and Bayesian inference to predict these maneuvers using linguistic contextual information, enhancing the model's interpretability and transparency. The model achieved a 91.5% f1-score with anticipation time extending to four seconds for risky lane changes, and a 90.0% f1-score for predicting safe lane changes with the same anticipation time. We validate our model by integrating it into a vehicle within the CARLA simulator in scenarios that involve risky lane changes. The model managed to anticipate sudden lane changes, thus providing automated vehicles with further time to plan and execute appropriate safe reactions. Finally, to enhance the explainability of our model, we utilize Retrieval Augmented Generation (RAG) to provide clear and natural language explanations for the given prediction.", "sections": [{"title": "I. INTRODUCTION", "content": "Lane-changing maneuvers (especially abrupt lane changes) are one of the causes of vehicle crashes, as a report indicated that 33% of all road crashes occur due to driver decision errors including lane changes [1]. A risky lane change occurs when drivers switch lanes suddenly without adequate warning, which leaves insufficient time for other vehicles to react, leading to frequent near-crashes or collisions. In contrast, a safe lane change usually comes with early signals or clear intentions to change lanes, giving other drivers sufficient time to react. While recent research has mainly focused on predicting safe lane changes, there is a critical gap when it comes to addressing risky lane-changing scenarios. Ignoring these unsafe lane-changing events makes it difficult for automated systems to anticipate and prevent near-crash situations. Moreover, many models that use numerical inputs function like black boxes, making it tough to interpret or explain their outputs. This lack of transparency poses challenges when trying to justify predictions to users who may not be familiar with the underlying algorithms. Additionally, existing accident datasets do not provide sufficient input for designing explainable prediction models. These datasets typically consist of video recordings without accompanying numerical or linguistic data, such as the velocities or positions of vehicles. This absence of crucial information makes it hard to develop models that provide clear and comprehensive predictions. To address these challenges, this work focuses on addressing the following points:\n1) A customized dataset (CRASH dataset) of risky lane-changing scenarios is developed using the CARLA simulator, reconstructing real-world scenes with detailed numerical data.\n2) An interpretable and transparent prediction model for safe and risky lane changes is developed by combining KGs with Bayesian inference and incorporating contextual linguistic information to improve interpretability.\n3) The model is validated in the CARLA simulator, demonstrating that it can predict unsafe maneuvers in advance and provide the vehicle with sufficient time to react accordingly.\n4) The model's explainability is increased by using RAG to provide clear natural language explanations for the predictions.\nThe rest of this article is organized as follows. Section II presents the state of the art. Section III contains a brief introduction to the CRASH dataset. Then, our proposed methodology is discussed in detail in section IV. In section V, results will be presented. Finally, section VI concludes the work and provides some recommendations for future work."}, {"title": "II. STATE OF THE ART", "content": "Recently, different works have focused on predicting vehicle lane changes using different types of inputs and using different models. In 2019, [2] used two machine learning models; Support Vector Machine (SVM) and Artificial Neural Network (ANN) to predict lane changes of surrounding vehicles on highways. They used the Next Generation Simulation (NGSIM) dataset, their input features included vehicle's speeds and accelerations in both longitudinal and lateral directions, distances to adjacent lane boundaries, yaw angles and yaw rates. Also in 2019, [3] focused on predicting the lane-changing intentions of surrounding vehicles using only visual information from the PREVENTION dataset. They explored two methods: the first was a Motion History Image (MHI) combined with a Convolutional Neural Network (CNN), where temporal and visual data were fed into the CNN. The second method involved a GoogleNet-LSTM model, where features extracted by a GoogleNet CNN were passed to an Long Short-Term Memory (LSTM) to learn temporal patterns. Inputs included RGB images, the center coordinates (x,y), and the dimensions of the bounding boxes around vehicles. In 2020, [4] trained Recurrent Neural Network (RNN) and LSTM models using the PREVENTION dataset to predict lane-changing intentions by tracking the positions of surrounding vehicles, specifically the centers of their bounding boxes. In 2018, [5] employed an LSTM model to predict lane changes by considering both the vehicle's past trajectory and the states of surrounding vehicles. Using data from the NGSIM dataset, they incorporated features such as the vehicle's lateral and longitudinal positions relative to the lane, its acceleration, the presence of vehicles to the right or left, and the distances to surrounding vehicles. In 2022, [6] utilized eXtreme Gradient Boosting (XGBoost) and LSTM models to predict lane change decisions and future trajectories using scenarios from the HighD dataset. Their approach considered factors like traffic density, vehicle type, and the relative movements between the target vehicle and the surrounding vehicles. Initially, they built a traffic flow model using the target vehicle's longitudinal speed and acceleration, headway distance, and relative velocities to the surrounding vehicles. In 2023, a dual transformer model was developed by [7], consisting of two parts: one for predicting lane changes and another for forecasting trajectories. The first transformer used the target vehicle's historical lateral movements and the states of surrounding vehicles, including distances and velocities relative to the target vehicle. The output from this lane change prediction was then combined with the target vehicle's past lateral movements and fed into the second transformer to link intentions with future trajectories. This model was trained and tested on the HighD and NGSIM datasets. In 2024, [8] used Knowledge Graph Embedding (KGE) followed by Bayesian inference which acted as a downstream task on the grounds of the learned embedding to predict safe lane changes on the HighD dataset. They considered inputs in linguistic formats to enhance the model's interpretability. The considered features are the vehicle lateral velocity and acceleration, Time To Collision (TTC) risk with the surrounding vehicles. Work [9] used the same methodology. However, it extends the architecture by adding the RAG mechanism which leverages the power of Large Language Models (LLMs) to generate context-specific explanations that are grounded in external, verifiable knowledge, and provide explanations of the scene provided with the reason for the lane change in natural language which is easy to understand by end-users. The work in [10] addressed predicting safe lane changes and trajectories in the HighD dataset by leveraging the strong reasoning capabilities and self-explanation abilities of LLMs. Data is processed as numerical values in natural language prompts to be the input to the LLMs. Then, they utilized Chain-of-Thought reasoning to enhance prediction explainability. The advantage of this work is that it achieves high-performance metrics and fine natural language explanations to the end users with only the powers of the tuned LLMs. The challenge is that even though the LLMs provides explanations and employs chain-of-thought reasoning to interpret input prompts, there remains a gap in the transparency and grounding of the LLM reasoning process as these models rely heavily on internal representations (the knowledge and patterns that the LLMs has learned internally during its training). This reliance can make the LLMs reasoning process less transparent, and the explanations might be difficult to verify or to be traced back to the inputs. So, the way it processes information internally is not easily visible or understandable to the users. Also, users and experts still cannot trace the prediction process starting from having the numerical input data till the prediction, they can't see how a change in the input can affect the probability of the final prediction, and it is often considered a \"black box\" in that case. On the other side, integrating KGs and Bayesian inference improves interpretability and transparency by creating a structured and interpretable framework where users can trace the process of obtaining the prediction and can show the effect of each input on the probability of the final prediction through the priors given by the KG for every event (input), which is something hard to trace in the tuned LLM approach. Moreover, without grounding in external knowledge, LLMs explanations may be less reliable. However, by using RAG, we ensure that explanations are grounded in external, verifiable knowledge, enhancing reliability. Finally,  presents a comparison of the literature discussed previously to highlight the identified research gaps. The first column indicates whether the models in the related works use numerical inputs or linguistic explainable inputs. The second and third columns specify whether the work addresses safe or risky lane changes respectively. The fourth column notes whether the related work includes experimental validation for simple decision-making, even if conducted in simulation. The fifth column indicates whether the architecture provides a natural language explanation. The last row summarizes the aspects that our work addresses. After a thorough examination of the existing literature, we have identified the following research gaps, which are addressed in this work:\n1) Specialized dataset for risky lane changes: There is a lack of datasets focusing specifically on risky lane-"}, {"title": "III. DATASET", "content": "This section briefly introduces the CRASH dataset which focuses on risky lane-changing maneuvers. The dataset is created by examining videos from various datasets containing different real accident and near-crash scenarios, some of these scenarios include lane changes [11][12]. These datasets were collected from front-view cameras mounted on vehicles. However, they only provide images and lack numerical data about the vehicle's state and the state of the surrounding vehicles. Therefore, CARLA simulator is utilized to recreate similar scenes [13]. By integrating CARLA, it is possible to generate comparable scenarios and obtain numerical values for all required inputs concerning the ego vehicle, target vehicle (which does the risky maneuver), and all surrounding vehicles in the scene. The dataset contains detailed information about every vehicle in the scene. For each vehicle, data are provided on its (x, y) location within the map, velocities, and accelerations in the lateral and longitudinal directions, braking status (whether the vehicle is braking or not), rear braking light and turning signal status, lane position, position relative to the center of the lane, gap distance and time to collision with the surrounding vehicles. Additionally, if there is an adjacent left or right vehicle, the lateral distance between the vehicle and the adjacent vehicle is included. The dataset also includes lane densities for the left, center, and right lanes, all measured relative to the vehicle's position, as well as the average speeds of these lanes. Furthermore, the lane attraction score is provided, which is calculated as each lane's average speed divided by its density, it gives an intuition about which lane will be more attractive to the vehicle based on the average velocity and density of that lane. The dataset contains a total of 50 samples, including 25 left lane changes, and 25 right lane changes, all these samples are classified as risky lane-changing maneuvers that end up with a collision or a near-crash. Safe maneuvers are not included because existing datasets, such as the HighD dataset, already cover safe lane-changing maneuvers. The scenarios are recorded from two different perspectives. The first is the front view from the ego vehicle's perspective, providing a realistic view of what a driver would see during the accident. The second is the bird's eye view, which allows the observer to see the entire situation, including how the ego vehicle interacts with the target vehicle's risky maneuver and all surrounding vehicles."}, {"title": "IV. METHODOLOGY", "content": "Our architecture is divided into four stages as indicated in fig. 2. The first stage is Linguistic Input Generation, where we take our numerical input values and convert it to linguistic categories. This is obtained based on literature and the data distribution along the lane-changing categories. For the second stage (Knowledge Graph Embedding), we use the linguistic inputs to create our KG, which is in the form of triples inside a CSV file. Then, this KG is embedded using the Ampligraph library. In the third stage, we carry out Bayesian inference on the grounds of these learned embeddings to get our final prediction. Finally, we feed this prediction along with the linguistic inputs to the Retrieval Augmented Generation stage in order to get an explanation of these predictions and the target vehicle decision-making process."}, {"title": "B. Input and Knowledge Graph Ontology Definition", "content": "From the dataset, the features selected include the y-velocity and y-acceleration of the target vehicle, the vehicle's lane position, distance from the center of the vehicle to the center of the lane, the time headway between the target vehicle and the preceding vehicle, time to collision with the (left preceding, preceding, right preceding, left following, and right following) vehicles, lane with the highest attraction score and lane with the highest frontal gap. These features are extracted in numerical format from the HighD [14] and CRASH datasets. The numerical features are converted into linguistic categories based on literature and the data distribution along the lane-changing categories. For instance, the y-velocity is classified into leftMotion, straightMotion, and rightMotion Similarly, the y-acceleration is classified into leftAcceleration, zeroLateralAcceleration, and rightAcceleration. These thresholds are determined by analyzing the normal distribution of each feature category, following the methodology outlined in [8]. The lane position is already a categorical feature. For the distance from the center of the lane and time headway, thresholds are determined based on the normal distribution following the same approach as in the lateral velocity and acceleration. Thresholds for the TTC are established based on previous studies [15][16]. A TTC between zero and four seconds is considered high risk, between four and ten seconds as medium risk, and greater than ten seconds or negative values as low risk. For the lane attraction and frontal gap, thresholds are not applied. Instead, the lane with the highest attraction score is identified directly. Similarly, the lane with the highest numerical value for the frontal gap is considered.  introduces the ontology of our KG which provides a formal and general representation of the entities and their relationships within a KG. Ontologies are essential in KGs because they serve as a schema for constructing the graph, ensuring consistency and improving its interpretability."}, {"title": "C. Knowledge Graph Embedding Phase", "content": "A KG is a directed heterogeneous multigraph, where nodes can have different types, and each pair of nodes can be connected by multiple types of relationships. KGs are used to represent the data in the form of triples inside a CSV file. Each feature was expressed in one triple: subject, relation, and object. For example, the triple <vehicle 445, LATERAL_ACCELERATION_IS, leftAcceleration> is mapped to <subject, relation, object>. There is a generic entity called vehicle which has several children such as vehicle 445, vehicle 446. Each vehicle ID is connected to its corresponding features. After that, we start to train/embed this knowledge graph. KGE is a supervised machine learning technique that learns to represent (embed) the knowledge graph entities and relations into a low-dimensional vector space while preserving semantic meaning [17]. In this stage, we use the Ampligraph library [18]. The scoring function used is the TransE function. The embedding size is set to 100. The model parameters include using the Adam optimizer with a learning rate of 0.0005, a batch size of 10,000, and employing SelfAdversarialLoss. Additionally, for each positive triple in our dataset, we generate five negative triples, maintaining a corruption ratio of 5 : 1. An early stopping criterion is used to monitor the Mean Reciprocal Rank (MRR) metric during validation with a patience threshold of five validation epochs."}, {"title": "D. Bayesian Inference and Prediction Phase", "content": "In this stage, Bayesian inference is performed as a downstream task using the learned embeddings from the previous stage. This stage utilizes the Bayesian inference eq. (1), which involves calculating the probabilities of a hypothesis (h), an event given the hypothesis (e|h), and an event (e), to determine the probability of the hypothesis given the event,\n\\(P(h|e) = \\frac{P(h)P(e|h)}{P(e)}\\)\n(1)\n\\(P(e) = P(e_1) \\times \\dots \\times P(e_n)\\)\n(2)\n\\(P(e|h) = P(e_1,..., e_n|h) = P(e_1|h) \\times \\dots \\times P(e_n|h)\\)\n(3)\nThese probabilities are evaluated using the embeddings obtained in the previous stage and are then fed into the Bayesian inference equation. This allows us to calculate P(LLC|e) which is the probability of the hypothesis (left lane change) given the events. However, this is just one hypothesis, we have to consider other possible maneuvers, which are lane keep or a right lane change. So, the probability for each maneuver is calculated, and the hypothesis with the highest probability is considered as the model's final prediction. Once the final prediction is obtained, its reasoning can be traced by comparing P(e|h) for each event across all hypotheses. However, this trend does not hold for the movingStraight event. This indicates that the highRiskPreceding event is the primary factor influencing the prediction in this situation and highlights the transparency of the model."}, {"title": "E. RAG Explanation Phase", "content": "After generating the prediction, we need our architecture to justify why our model provided this prediction and reason about the target vehicle decision making in natural language using an LLM. However, the challenge is that LLMs have access to a wide public database, which does not fit our purposes. We require the justifications to be based only on the provided KGs derived from the HighD and the CRASH datasets, which are private databases, not public ones. We also need the justifications to be more reliable and verifiable. This can be achieved by grounding them in external, independently verifiable knowledge sources rather than relying solely on internal knowledge acquired during the training process. RAG is used to address this issue. First, we organize our KG triples into chunks, with each chunk representing one sample from our data. We then embed these chunks using an embedding model and store the resulting embeddings in a vector database. all-MiniLM-L6-v2 from Hugging Face is the used embedding model and Chroma is the used vector database. When a user submits a query, the system embeds the query and retrieves chunks with embeddings that are most similar to the query. These retrieved chunks are then augmented to the query, and to a prompt that guides our model to the type of needed responses To ensure that the responses are accurate and based solely on the private KG data. The final augmented query is then fed into an OpenAI GPT-4 LLM to generate the required response."}, {"title": "V. RESULTS", "content": "In this section, we present the results of our work, which aims to predict both safe and risky lane changes using a unified model and consistent labels. We compare our approach with existing studies that focus solely on predicting safe lane-changing maneuvers. Furthermore, we validate our model by integrating it into an IDM within the CARLA simulation environment to test the IDM reactions with and without our prediction model. Finally, we demonstrate the explainability of our approach by utilizing the RAG module to provide natural language explanations for the model's predictions."}, {"title": "A. Model Performance and Comparative Analysis", "content": "Regarding safe lane-changing maneuvers, our model achieved an average f1-score of 90% over the interval [0,4] seconds. We identified four relevant articles addressing safe lane-changing maneuvers using the HighD dataset, and compared their results with ours in table III. The first two articles ([6], [7]) report results at specific times. Their models exhibit higher performance than ours at time points (0.5 to 2 seconds). Also, no results are indicated for longer horizons. Additionally, their models employ deep learning techniques, such as LSTMs and transformers, which are considered \"black-boxes\" and lack transparency and interpretability. In contrast, our model is interpretable and provides transparency to users, as indicated in fig. 5. The third article [8] also demonstrates consistently high-performance scores. However, like the previous two models, this model was trained only to predict safe lane changes, whereas our model is designed to predict both safe and risky lane changes. Another study reports remarkable results for safe lane-changing maneuvers on the HighD dataset, presenting performance over intervals from [0,1], (1,2], (2,3], (3,4], and [0,4] seconds. Their model utilizes an LLM with a chain-of-thought approach. While the model's results are impressive, the model is based on numerical inputs and lacks transparency and verifiability, similar to other \"black-box\" models where the internal workings of the model are not accessible, making it difficult to understand which inputs influence the predictions. In contrast, our model provides high transparency as mentioned previously and it also deals with risky situations (as mentioned in table I) which are not considered in state-of-the-art systems. For risky lane changes, results are shown in table IV. The model attained an f1-score of 91.5% over the interval [0,4] seconds. To the best of our knowledge, no prior studies have addressed these specific types of maneuvers. Therefore, we present our results accordingly without comparison to other studies. To demonstrate the significance of the risky dataset, we trained another model (model 2) only on the HighD dataset and tested it on the risky lane changes included in the CRASH dataset. The model is unable to predict risky lane changes effectively as shown in the last row of table IV, highlighting the importance of including a dataset that contains risky lane changes in the training process."}, {"title": "B. Validation in Simulation and Real-World Scenarios", "content": "Initially, some scenarios are validated using the Intelligent Driver Model (IDM) integrated on the ego vehicle in CARLA without integrating our prediction model. In these cases, the IDM didn't have enough time to brake, ending up with a collision. For example, fig. 6 shows a scenario where the ego vehicle moves forward and the target vehicle is on the right front side. The IDM detects no obstacles ahead and increases its velocity. However, the target vehicle faces a risk with the vehicle in front of it and needs to change lanes. In this situation, the IDM does not know the intention of this vehicle or that the target vehicle is at risk which will lead to the execution of a risky left lane change. Consequently, the ego vehicle suddenly encounters another vehicle changing lanes directly ahead, leaving insufficient time to brake. After integrating the prediction model, it anticipates that the target vehicle will execute a risky/sudden left lane change, as shown in fig. 7. This anticipation allowed the ego vehicle to decelerate smoothly, rather than braking abruptly. The model provides the ego vehicle with awareness of the upcoming risky lane change, enabling it to decelerate in anticipation of the target vehicle's maneuver. Eventually, the target vehicle changed lanes to the left, while the ego vehicle continued moving safely. Then, our model is tested on real world videos that contain risky lane changes. The purpose of these scenarios is to demonstrate that our model functions effectively not only with simulation data but also in real-world situations. In fig. 8, we have some captures from a real-world video where our model anticipated the risky left lane change in advance. By integrating our model into the vehicle, we can potentially avoid near-crashes or accidents resulting from risky lane changes and understand the target vehicle's decisions. Finally, Table V contains two hyperlinks. The first one directs to a website to access the CRASH dataset, and shows an interactive graph for a sample from our designed KG. The second hyperlink directs to a YouTube playlist that contains some multimedia videos of different scenes including the scenes discussed in this section."}, {"title": "C. Natural Language Explanation Through RAG", "content": "After validation of the model, we analyze one of the captions extracted from the same real-world scenario, then we feed the linguistic inputs obtained from this capture along with the prediction to the RAG model. fig. 9 shows the formed query obtained from the linguistic inputs and the predicted maneuver. Then, the query is fed to the RAG model which outputs an explanation that illustrates the model's ability to provide clear, reasonable, and precise natural language explanations for the target vehicle's predicted maneuver."}, {"title": "VI. CONCLUSION", "content": "In this work, we anticipated safe and risky lane-changing maneuvers using KGE and Bayesian inference. We trained our model on the HighD dataset for safe lane changes and on our own created CRASH dataset for risky lane changes. Our model achieved an f1-score of 90% for predicting safe lane changes with an anticipation interval of 4 seconds and an f1-score of 91.5% for risky lane changes within the same anticipation window. In terms of numerical performance, our model is competitive with other state-of-the-art systems in anticipating safe lane changes and contributes by anticipating risky lane changes. Moreover, the model's performance goes beyond numerical results by enhancing transparency and interpretability of the prediction process. We validated our model by integrating it to an IDM in the CARLA simulator, and it is proven that predicting risky lane changes provides the ego vehicle with more time to react and avoid near-crash situations. Additionally, we employed RAG to enhance the model's explainability by providing natural language explanations for its predictions. Future work can focus on the decision-making process of the ego vehicle by incorporating advanced actions based on the predicted lane change of the target vehicle."}]}