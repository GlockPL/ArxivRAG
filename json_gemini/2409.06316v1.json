{"title": "PHARMACOMATCH: EFFICIENT 3D PHARMACOPHORE SCREENING THROUGH NEURAL SUBGRAPH MATCHING", "authors": ["Daniel Rose", "Oliver Wieder", "Thomas Seidel", "Thierry Langer"], "abstract": "The increasing size of screening libraries poses a significant challenge for the development of virtual screening methods for drug discovery, necessitating a re-evaluation of traditional approaches in the era of big data. Although 3D pharmacophore screening remains a prevalent technique, its application to very large datasets is limited by the computational cost associated with matching query pharmacophores to database ligands. In this study, we introduce PharmacoMatch, a novel contrastive learning approach based on neural subgraph matching. Our method reinterprets pharmacophore screening as an approximate subgraph matching problem and enables efficient querying of conformational databases by encoding query-target relationships in the embedding space. We conduct comprehensive evaluations of the learned representations and benchmark our method on virtual screening datasets in a zero-shot setting. Our findings demonstrate significantly shorter runtimes for pharmacophore matching, offering a promising speed-up for screening very large datasets.", "sections": [{"title": "1 Introduction", "content": "A challenging task in the early stages of drug discovery campaigns is the identification of hit molecules that effectively bind to a protein target of interest. Due to the vastness of the chemical space, estimated to encompass more than 1060 small organic molecules (Virshup et al. 2013), identifying molecules with desirable drug-like properties is often compared to finding a needle in a haystack. Virtual screening methods have therefore become an essential component of the computer-aided drug discovery toolkit, aiding medicinal chemists in filtering molecular databases to efficiently explore the search space for potential hit compounds (Sliwoski et al. 2014).\nA pharmacophore represents non-bonding interactions of chemical features that are essential for binding to a specific protein target (Wermuth et al. 1998). A pharmacophore query can, for example, be generated from the interaction profile of a ligand-receptor complex and used to identify potential hit compounds from databases by searching for molecules with similar pharmacophoric patterns (Wolber and Langer 2005). The process involves a positional alignment of the pharmacophore model with the three-dimensional conformations of molecules in the database, which are ranked based on their agreement with the pharmacophore query (Wolber, Dornhofer, and Langer 2006). Since pharmacophore screening focuses on abstract interaction patterns, rather than specific molecular structures, it allows for the identification of structurally diverse hit compounds (Seidel et al. 2017).\nVirtual screening of make-on-demand libraries like Enamine REAL (Shivanyuk et al. 2007) is of growing interest because these libraries contain compounds that can be synthesized through reliable synthetic routes within a short period, making them readily commercially available. These libraries encompass billions of molecules and continue to expand due to advances in synthetic accessibility (Llanos et al. 2019). While screening larger compound libraries enhances the likelihood of identifying hit compounds, it also extends screening times, thereby necessitating the scaling up of virtual screening methods (Sadybekov et al. 2022). However, scaling up 3D pharmacophore screening to accommodate billions of molecules presents significant challenges (Warr et al. 2022). Although various filtering techniques have been developed (Seidel et al. 2010), molecules that pass these methods must still undergo alignment algorithms, which ultimately determine the speed of the process. Despite substantial efforts to optimize these algorithms (Wolber et al. 2008; Permann, Seidel, and Langer 2021), the overall screening procedure remains time-intensive.\nIn this work, we propose using self-supervised learning to create meaningful 3D pharmacophore representations for efficient virtual screening. Our PharmacoMatch model employs a graph neural network (GNN) encoder, trained with a contrastive learning objective, to map 3D pharmacophores into an order embedding space (Ying et al. 2020), thereby enabling pharmacophore matching through vector comparisons. The embedding vectors for the screening database are computed once and then used to quickly generate a hitlist based on the query embedding. An overview of the workflow is presented in Figure 1.\nOur key contributions are:\n\u2022 We develop a GNN encoder model that generates meaningful vector representations from 3D pharmacophores. The model is trained in a self-supervised manner on unlabeled data, employing a contrastive loss objective to capture the relationships between queries and targets based on their partial ordering in the learned embedding space.\n\u2022 We use the learned representation for fast virtual screening in the embedding space and evaluate the performance of our method through experiments on virtual screening benchmark datasets."}, {"title": "2 Related work", "content": "Pharmacophore alignment algorithms Alignment algorithms compute a rigid-body transformation, the pharmacophore alignment, to match a query's pharmacophoric pattern to database ligands. A scoring function then evaluates the pharmacophore matching by considering both the number of matched features and their spatial proximity. The alignment is typically preceded by fast filtering methods that prune the search space based on pharmacophoric types, pharmacophoric point counts, and quick distance checks. Only molecules that pass these filters undergo the final, computationally expensive 3D alignment step, which is usually performed by minimizing the root mean square deviation (RMSD) between pairs of pharmacophoric points (Seidel et al. 2010; Dixon et al. 2006). The algorithm by Wolber, Dornhofer, and Langer (2006) creates smoothed histograms from the neighborhoods of pharmacophoric points for pair assignment using the Hungarian algorithm, followed by alignment with Kabsch's method (Kabsch 1976). A recent implementation by Permann, Seidel, and Langer (2021) improves on runtime and accuracy by using a search strategy that maximizes pairs of matching pharmacophoric points. Alternatively, shape-matching algorithms like ROCS (Hawkins, Skillman, and Nicholls 2007) and Pharao (Taminau, Thijs, and De Winter 2008) model pharmacophoric points with Gaussian volumes, optimizing for volume overlap.\nMachine learning for virtual screening A common approach to using machine learning for virtual screening is to train models on measured bioactivity values. However, these models are constrained by the scarcity of experimental data, which is both costly and challenging to obtain (Li et al. 2021). Unsupervised training of target-agnostic models for virtual screening avoids dependence on labeled data, but remains relatively unexplored. DrugClip (Gao et al. 2023) approaches virtual screening as a similarity matching problem between protein pockets and molecules, using a multi-modal learning approach where a protein and a molecule encoder create a shared embedding space for virtual screening. Sellner, Mahmoud, and Lill (2023) used the Schr\u00f6dinger pharmacophore shape-screening score to train a transformer model on pharmacophore similarity, which is a different objective than pharmacophore matching. PharmacoNet (Seo and Kim 2023) uses instance segmentation for pharmacophore generation in protein binding sites and a graph-matching algorithm for binding pose estimation, employing deep learning for pharmacophore modeling, but not for the alignment nor matching.\nContrastive representation learning A common approach for the extraction of vector embeddings is the use of contrastive learning frameworks. These frameworks make use of a Siamese network architecture and a contrastive loss function, where an embedding space is learned by comparing positive and negative examples (Bengio, Courville, and Vincent 2013). In the last years, the computer vision community reported great improvements in the use of self-supervised learning (SSL) frameworks, which can be seen as a special case of contrastive learning. Instead of labels, these frameworks use augmentations to create positive and negative examples during training, which allows to train models on large datasets of unlabeled data. SSL is often used for model pretraining, followed by fine-tuning through supervised learning, which is especially useful when data is limited; however, the learned representations can also be utilized without fine-tuning if no labeled data is available (Balestriero et al. 2023)."}, {"title": "3 Preliminaries", "content": "Pharmacophore representation In this work, we treat 3D pharmacophores as attributed point clouds (Mah\u00e9 et al. 2006; Kriege and Mutzel 2012). A pharmacophore P can be represented by a set of pharmacophoric points P = {(r_i, l_i) \u2208 R^3 \u00d7 L}; with the Cartesian coordinates r\u012b and the label li of the pharmacophoric point pr. The label set L contains the following pharmacophoric descriptors: hydrogen bond donors (HBD) and acceptors (HBA), halogen bond donors (XBD), positive (PI) and negative electrostatic interaction sites (NI), hydrophobic interaction sites (H), and aromatic moieties (AR). Directed descriptors like HBD and HBA can be associated with a vector component, but for simplicity, we will omit this information in our study."}, {"title": "4 Methodology", "content": "Overview In the following we introduce PharmacoMatch, a novel contrastive learning framework with the aim to encode query-target relationships of 3D pharmacophores into an embedding space. We propose to train a GNN encoder model in a self-supervised fashion, as illustrated in Figure 3. Our model is trained on approximately 1.2 million unlabeled small molecules from the ChEMBL database (Davies et al. 2015; Zdrazil et al. 2023) and learns pharmacophore matching solely from augmented examples, comparing positive and negative pairs of query and target pharmacophore graphs, while optimizing an order embedding loss to extract relevant matching patterns."}, {"title": "Model input", "content": "We represent the node labels Xp(VP) of a given pharmacophore graph G(P) = (Vp, Ep, Ap) as one-hot-encoded (OHE) feature vectors h = (h\u2081, ..., h_{|P|}). We employ a distance encoding to represent pair-wise distances, which was inspired by the SchNet architecture (Sch\u00fctt et al. 2018). The edge attributes of edge euv are derived from the edge label Ap(euv) and represented by a radial basis function e_k(r_u \u2013 r_v) = exp(-\u03b2(||r_u \u2013 r_v||^2 \u2013 \u03bc_k)^2), where centers \u03bc_k were taken from a uniform grid of K points between zero and the distance cutoff at 10 \u00c5, and the smoothing factor \u03b2 represents a hyperparameter. To this end, the pharmacophore P is represented by a data point x = [h, e] which is a tuple of the feature matrix h \u2208 R^{|P|\u00d7L} and the distance-encodings e\u2208R^{(|P|\u00d7|P|)\u00d7K}."}, {"title": "GNN encoder architecture", "content": "The encoder input is the pharmacophore graph representation x = [h, e], with the feature matrix h and the edge attributes e. Node feature embeddings are generated by initially passing the OHE feature matrix through a single dense layer without an activation function. We then update the node representations through message passing using the edge-conditioned convolution operator (NNConv) by Gilmer et al. (2017); Simonovsky and Komodakis (2017), which was originally designed for representation learning on point clouds and 3D molecules, to aggregate distance information into the learned node representations (see Appendix A.3 for details). We find that DenseNet-style skip-connections (Huang et al. 2017) are beneficial for learning robust representations. Graph-level read-out is achieved by additive pooling of the updated feature matrix h\u2208 R^{|P|\u00d7m} into a graph representation q \u2208 R^m, which is then projected to the final output embedding z \u2208 R^p by a multi-layer perceptron. The employed loss function requires to map the final representation to the non-negative real number space. We accomplish this by using the absolute values of the learnable weights for the last linear transformation immediately after the final ReLU unit (see Appendix A.4 for details)."}, {"title": "Loss function", "content": "In order to encode query-targets relationship of pharmacophores into the embedding space, we employ the loss function by Ying et al. (2020). The key insight is that subgraph relationships can be effectively encoded in the geometry of an order embedding space through a partial ordering of the corresponding vector embeddings. Let zo the embedding of graph GQ, zT the embedding of graph GT, and f\u03b8 : G \u2192 R^d a GNN encoder to map pharmacophore graphs G to embedding vectors z\u2208 R^p. The partial ordering zQ > zT reflects, whether GQ is subgraph isomorphic to GT:\nz_Q[i] < z_T[i], \u2200i \u2208 {1, ..., D} iff G_Q \u2264 G_T\\\\\nThe following max-margin objective can be used to train the GNN encoder f\u03b8 on this relation:\n\\mathcal{L}(z_Q, z_T) = \\sum_{(z_Q, z_T) \u2208 Pos} E(z_Q, z_T) + \\sum_{(z_Q, z_T)\u2208Neg} max{0, \u03b1 \u2013 E(z_Q, z_T)}\\\\\nThe penalty function E : R^p \u00d7 R^p \u2192 R+ reflects violation of the partial ordering on the embedding vector pair:\nE(z_Q, z_T) = ||max{0, z_Q \u2013 z_T}||^2\\\\\nPos is the set of positive pairs per batch, these are pairs of query zQ and target graph embedding zT with a subgraph-supergraph relationship, and Neg is the set of negative examples, these are pairs of query and target embedding vectors that violate this relationship. The positive and negative pairs are generated on-the-fly via augmentation during training."}, {"title": "Augmentation module", "content": "The PharmacoMatch model correlates the matching of a query and a target pharmacophore with the partial ordering of their vector representations. Positive pairs represent successful matchings, while negative pairs serve as counter examples. In order to create these pairs from unlabeled training data, we define three families of augmentations T, which are composed of random point deletions and positional point displacements.\nFor positive pairs, valid queries are created by randomly deleting some nodes from a pharmacophore P, leaving at least three, and displacing the remaining nodes within a tolerance sphere of radius rT. This augmentation, denoted as t\u2081(\u00b7) ~ T\u2081, produces the positive pair (t\u2081(P), P).\nNegative pairs are used to show the model examples of unsuccessful matching, employing three strategies that illustrate different types of undesired outcomes. Our first strategy provides the model with examples of positional mismatch, by placing the pharmacophoric points of P on the surface of the tolerance sphere without any point deletions. This augmentation, denoted by t\u2082(\u00b7) ~ T\u2082, is used to generate the negative query-target pair (t\u2082(P), P).\nOur second strategy teaches the model that every pharmacophoric point in the query should correspond to a point in the target. This is achieved by deleting some target nodes, using an augmentation operator t3(\u00b7) ~ T3, where T3 involves node deletion without displacement. As a result, the query in the pair (t\u2081(P), t3(P)) only partially matches its target."}, {"title": "Curriculum learning", "content": "We design a curriculum learning strategy for training on pharmacophore graphs. We start training with pharmacophores containing four nodes. If the loss does not decrease significantly within 10 epochs, we add pharmacophores with one additional node to the training data. This approach allows the model to start with very simple examples, gradually increasing the difficulty of the matching task."}, {"title": "Model Training", "content": "Our GNN encoder model is implemented with three convolutional layers with an output dimension of 64. The MLP has a depth of three dense layers with a hidden dimension of 1024 and an output dimension of 512. The final model was trained for 500 epochs using an Adam optimizer with a learning rate of 10^{-3}. The margin of the best performing model was set to \u03b1 = 100. The tolerance radius rT for node displacement was set to 1.5 \u00c5, which is the default value in the pharmacophore screening functionalities of the CDPKit (see Appendix A.5 for more details)."}, {"title": "Decision function for model inference", "content": "We are using the trained GNN encoder f\u03b8 to precompute vector embeddings zT of the database pharmacophores. These are queried with the pharmacophore embedding zQ by verification of the partial ordering constraint (3), which shall not be violated by more than a threshold t. This leads to the decision function g : R^p \u00d7 R^p \u2192 {0,1}:\ng(z_Q, z_T) = \\begin{cases}\n1 & \\text{iff } E(z_Q, z_T) < t \\\\\n0 & \\text{otherwise}\n\\end{cases}\\\\\nwhich evaluates to 1 if the partial ordering on zQ and zT reflects a pharmacophore matching, and 0 otherwise. In the following, we will refer to equation (4) as matching decision function. In practice, we recommend a decision threshold of t = 6500, which was determined during our benchmark experiments."}, {"title": "5 Experiments", "content": "We designed our embeddings to reflect the type and relative positioning of pharmacophoric points. Comparison of embedding vectors via the matching prediction function should emulate the matching of the underlying pharmacophores. To get a better understanding of the encoder's latent space, we investigate these properties as follows:\n1. Pharmacophoric point perception: We investigate the learned embedding space quantitatively through dimensionality reduction.\n2. Positional perception: We investigate the influence of positional changes on the output of the matching decision function.\n3. Virtual screening performance: The performance of our model is evaluated using ten DUD-E targets, and the produced hitlists are compared with the performance and runtime of the CDPKit (Seidel 2024) alignment algorithm."}, {"title": "DUD-E benchmark dataset", "content": "We perform our experiments on the DUD-E benchmark dataset (Mysinger et al. 2012), which is commonly used to evaluate the performance of molecular docking and structure-based screening. The complete benchmark contains 102 protein targets, each accompanied by active and decoy ligands in the form of SMILES strings (Weininger 1988) and the PDB template (Burley et al. 2017) of the ligand-receptor complex. We randomly select ten different protein targets for the evaluation of our model. Ligands in these datasets are processed according to the data curation pipeline outlined in the Methodology section, except that we sample up to 25 conformations per compound. The ligand-receptor complex is used to generate a structure-based query with 5-7 pharmacophoric points (see Appendix A.6 for more details)."}, {"title": "5.1 Pharmacophoric point perception", "content": "We conduct a quantitative analysis through dimensionality reduction to gain a first intuition for the properties of the learned embedding space.\nThe partial ordering of graph representations in the embedding space, based on the number of nodes per graph, is essential for encoding query-target relationships. This ordering property of the embedding space can be visualized using principal component analysis (PCA). Figure 5a displays the first two principal component axes of the learned representations, with the representations labeled according to the number of pharmacophoric points of the corresponding pharmacophore. This visualization demonstrates how the embedding vectors are systematically ordered relative to the number of nodes in each pharmacophore graph.\nSimilarly, the Uniform Manifold Approximation and Projection (UMAP) algorithm (McInnes, Healy, and Melville 2020), a dimensionality reduction technique that preserves the local neighborhood structure of high-dimensional data, was employed. Figure 5b shows the UMAP representation of the embeddings, labeled by the number of pharmacophoric points of a specific type. This visualization suggests that pharmacophores with a similar set of points are mapped proximally within the order embedding space."}, {"title": "5.2 Positional perception", "content": "We define a family of augmentations TrD to randomly delete nodes from a pharmacophore P and displace the remaining nodes by a radius rD. We sample augmentations trD(\u00b7) ~ TrD with increasing radius rD taken from a uniform grid of m distances between 0 and 10 \u00c5.\nFor a given batch of pharmacophores {P1,..., Pn}, we generate the query-target pairs {(trD(P1), P\u2081), ..., (trD(Pn), Pn)}. We then evaluate the decision function g(,) (Equation 4) on the corresponding vector representations and calculate the mean of the decision function across all pairs against an increasing radius rD, which is illustrated in Figure 5c.\nWithout node displacement, the mean matching decision function is close to 1, indicating that the model recognizes pharmacophores with reduced node sets as valid queries. With a displacement of approximately 1.5 \u00c5, the mean matching decision value drops to 50%, demonstrating the model's consideration of the chosen tolerance radius. Beyond a displacement of 1.5 \u00c5, the decision function further decreases, approaching a plateau at approximately 6 \u00c5. The results show that our model integrates 3D-positional information of pharmacophoric points into the learned representations."}, {"title": "5.3 Virtual screening", "content": "Each benchmark set is comprised of a pharmacophore query PQ and a set of ligands L = {L1, ..., Ln}, where each ligand Li is associated with a set of pharmacophores {P\u2081,..., Pk\u2081}_i and a label yi, which indicates whether the ligand is active or decoy. The task is to rank the database ligands w.r.t. the query, based on a scoring function F : P \u00d7 P \u2192 R+. The ranking score \u03c6i of ligand Li is calculated through aggregation of the pharmacophore scores \u2295({F(PQ, P\u2081), ..., F(PQ, Pk\u2081)}_i), where \u2295 is an aggregation operator. PharmacoMatch transforms the query G(PQ) \u2192 zQ and the set of pharmacophores {G(P1), ..., G(Pk\u2081)}_i \u2192 {z\u2081,..., zk\u2081}_i via encoder model f\u03b8 : G \u2192 R^p and evaluates the penalty function E : R^p \u00d7 R^p \u2192 R+. A low penalty corresponds to a high ranking. The ranking score of database ligand Li is calculated as \u03c8i = min({E(zQ, z\u2081), ..., E(zQ, zk\u2081)}_i).\nBaseline algorithm The baseline for our comparison is the alignment algorithm implemented in the open-source software CDPKit (Seidel 2024), which utilizes clique-detection followed by Kabsch alignment (Kabsch 1976). The alignment of a query PQ and a target PT is evaluated with an alignment score S : P \u00d7 P \u2192 R+, which takes into account the number of matched features and their geometric fit (further details are provided in the Appendix A.6). The ligand ranking score is calculated as \u03c8i = max({S(PQ, P\u2081), ..., S(PQ, Pk\u2081)}_i), the highest alignment score represents the score for the database ligand. Analogous to equation (4), we can also define a matching decision function \u03c3 based on the alignment score, where t = |PQ|:\n\u03c3(P_Q, P_T) = \\begin{cases}\n1 & \\text{iff } S(P_Q, P_T) \u2265 t \\\\\n0 & \\text{otherwise}\n\\end{cases}\\\\\nEvaluation Both algorithms rank database ligands to produce a hitlist. We assess the performance of PharmacoMatch on the benchmark using two approaches. First, we demonstrate that the PharmacoMatch penalty E(,) correlates with the matching decision function \u03c3(,) of the alignment algorithm. We evaluate both functions against all pharmacophores in a dataset w.r.t. query PQ. The outputs are compared by generating the corresponding receiver operating characteristic (ROC) curves, and the performance is quantified using the area under the ROC curve (AUROC) metric.\nSecond, we compare the virtual screening performance of our model and the alignment algorithm using the ligand ranking score \u03c8. The primary objective of virtual screening is to find active compounds amongst decoys. We evaluate this using two different metrics. The AUROC metric is used to evaluate the overall classification performance w.r.t. activity label yi. A drawback of this metric is that it does not reflect the early enrichment of active compounds in the hitlist, which is of significant interest in virtual screening. Early enrichment is assessed using the Boltzmann-enhanced discrimination of ROC (BEDROC) metric (Truchon and Bayly 2007), which assigns higher weights to better-ranked samples. Note that these performance metrics are entirely dependent on the chosen query. Rather than aiming to maximize those metrics, our goal is to achieve comparable values between our model and the alignment algorithm.\nScreening performance Our results, comparing PharmacoMatch with the alignment algorithm across all ten targets, are summarized in Table 1 (ROC plots are provided in the Appendix A.6). We observe a robust correlation between the hitlists generated by the two algorithms, demonstrating the effectiveness of our approach. This correlation varies by target, reflecting the sensitivity of virtual screening to the chosen query. Although the alignment algorithm achieves generally higher AUROC scores and early enrichment, our method consistently produces hitlists with competitive performance across several targets.\nRuntime comparison In terms of runtime, PharmacoMatch significantly outperforms the alignment algorithm. We compare the time required for alignment, embedding, and vector matching per pharmacophore. Alignment is performed in parallel on an AMD EPYC 7713 64-Core Processor with 128 threads, while pharmacophore embedding and matching are run on an NVIDIA GeForce RTX 3090, with both devices having comparable purchase prices and release dates. Creating vector embeddings from pharmacophore graphs takes 92 \u00b1 12 \u03bcs per pharmacophore, which takes longer than aligning a query to a target with 13 \u00b1 7 \u03bcs. However, the embedding process only needs to be performed once. Subsequently, the preprocessed vector data can be used for vector matching, which takes 0.30 \u00b1 0.09 \u00b5s, being approximately two orders of magnitude faster than the alignment. Additionally, vector comparison is independent of the query size, an advantage not shared by the alignment algorithm. Although executed on different hardware, this comparison highlights the speed-gain of our algorithm.\nPractical considerations There are two options for integrating our model into a virtual screening pipeline. First, the PharmacoMatch model can be used in place of the alignment algorithm to generate a hitlist of ligands, which is suitable for quickly producing a compound list for experimental testing. Alternatively, our method can serve as an efficient prefiltering tool for very large databases, reducing the number of molecules from billions to millions, after which the slower alignment algorithm can be applied to this filtered subset. Note that alignment will still be necessary if visual inspection of aligned pharmacophores and corresponding ligands is desired."}, {"title": "6 Conclusion", "content": "We have presented PharmacoMatch, a contrastive learning framework that creates meaningful pharmacophore representations for virtual screening. The proposed method tackles the matching of 3D pharmacophores through vector comparison in an order embedding space, thereby offering a valuable method for significant speed-up of virtual screening campaigns. PharmacoMatch is the first machine-learning based solution that approaches pharmacophore virtual screening via an approximate neural subgraph matching algorithm. We are confident that our method will help to improve on existing virtual screening workflows and contribute to the assistance of medicinal chemist in the complex task of drug discovery."}, {"title": "Code & data availability", "content": "We will make our code publicly available upon acceptance via https://github.com/molinfo-vienna/PharmacoMatch and share the curated datasets via (https://zenodo.org/)."}, {"title": "A Appendix", "content": "A.1 Dataset curation & statistics\nUnlabeled training data was downloaded from the ChEMBL database to represent small molecules with drug-like properties. At the time of data download, the ChEMBL database contained 2,399,743 unique compounds. We constrained the compound category to \"small molecules\" and enforced adherence to the Lipinsky rule of five (Lipinski et al. 1997), specifically setting violations to \"0,\" resulting in a refined set of 1,348,115 compounds available for download. The molecules were acquired in the form of Simplified Molecular Input Line Entry System (SMILES) (Weininger 1988) strings. Subsequent to data retrieval, we conducted preprocessing using the database cleaning functionalities of the Chemical Data Processing Toolkit (CDPKit) (Seidel 2024). This process involved the removal of solvents and counter ions, adjustment of protonation states to a physiological pH value, and elimination of duplicate structures, where compounds differing only in their stereo configuration were regarded as duplicates. To prevent data leakage, we carefully removed all structures from the training data that would occur in one of the test sets we used for our benchmark experiments. The final set was comprised of 1,221,098 compounds. For each compound within the dataset, a 3D conformation was generated using the CONFORGE (Seidel et al. 2023) conformer generator from the CDPKit, which was successful for 1,220,104 compounds. To enhance batch diversity, we generated only one conformation per compound for contrastive training. Subsequently, 3D pharmacophores were computed for each conformation, with removal of pharmacophores containing less than four pharmacophoric points. The ultimate dataset comprised 1,217,361 distinct pharmacophores."}, {"title": "A.2 Augmentation module", "content": "The augmentation module receives the initial pharmacophore xo = [ho, ro], with the initial OHE feature matrix ho and the Cartesian coordinates ro. Edge attributes of the complete graph were calculated from the pair-wise distances between nodes after modifying the input according to the augmentation strategy, which combines random node deletion and random node displacement. The module outputs the modified tuple x = [h, e] with the feature matrix h and the edge attributes e.\nNode deletion Random node deletion involved removing at least one node, with the upper bound determined by the cardinality of the set of nodes Vi of graph Gi. To ensure the output graph retained at least three nodes, the maximum number of deletable nodes was Vi - 3. The number of nodes to delete was drawn uniformly at random.\nNode displacement There are two modes for the displacement of pharmacophoric points. Positive pairs were constructed by displacing the pharmacophoric points within the tolerance sphere of the initial pharmacophore. For simplicity, we assumed the same tolerance sphere radius rT across different pharmacophoric types. The coordinate displacement (\u2206x, \u2206y, \u2206z) was created from spherical coordinates \u00a2 ~ U(0,2\u03c0) and cos \u03b8 ~ U(\u22121,1), which were drawn at random from a uniform distribution. The coordinate displacement was calculated as\n\u0394x = \u0394r sin \u03b8 cos \u03c6, \u0394y = \u0394r sin \u03b8 sin \u03c6, \u0394z = \u0394r cos \u03b8\\\\\\\nwhere \u0394r = rT \u221au and u ~ U(0, 1). Negative pairs were created by displacement of the nodes at the border of the tolerance sphere. This was achieved by random sampling from a sphere surface, i.e. with u = 1."}, {"title": "A.3 Message passing neural network", "content": "Convolution on irregular domains like graphs is formulated as message passing, which can generally be described as:\nh_i^{(k)} = \u03b3^{(k)} \\Big(h_i^{(k-1)}, \\bigoplus_{j \u2208 N(i)} \u03c6^{(k)} \\big(h_i^{(k-1)}, h_j^{(k-1)}, e_{ij} \\big) \\Big) \\\\\\\\nwhere h_i^{(k)} \u2208 R^{F'} denotes the node features of node i at layer k, h_i^{(k-1)} \u2208 R^F denotes the node features of node i at layer k \u2212 1, e_{ij} \u2208 R^D the edge features of the edge from node i to node j, \u03b3^{(k)} and \u03c6^{(k)} are parameterized, differentiable functions, and \u2295 is an aggregation operator like, e. g., the summation operator (Fey and Lenssen 2019). In our encoder architecture, we employed the following edge-conditioned convolution operator, which was proposed both by Gilmer et al. (2017); Simonovsky and Komodakis (2017):\nh_i^{(k)} = h_i^{(k-1)} + \\sum_{j \u2208 N(i)} \u0398 h_j^{(k-1)} \u22c5 \u03c8_\u0398(e_{ij}) \\\\\\\\nwhere \u0398 \u2208 R^{F\u00d7F'} denotes learnable weights and \u03c8_\u0398(\u22c5) : R^D \u2192 R^{F\u00d7F'} denotes a neural network, in our case an MLP with one hidden layer. These transformations map node features h into a latent representation that combines pharmacophoric types with distance encodings."}, {"title": "A.4 Encoder implementation", "content": "The encoder was implemented as a GNN f_\u0398 : G \u2192 R^p that maps a given graph G to the abstract representation vector z \u2208 R^p. The architecture is comprised of an initial embedding block, three subsequent convolution blocks, followed by a pooling layer, and a projection block."}, {"title": "Embedding block", "content": "The embedding block receives the pharmacophore graph Gi as the tuple x_i = [h_i, e_i], with the OHE feature matrix h_i and the edge attributes e_i. Initial node feature embeddings are created from the OHE features with a fully-connected (FC) dense layer with learnable weights W and bias b:\nh_i = Wh_i + b\\\\\\"}, {"title": "Convolution block", "content": "The convolution block consists of a graph convolution layer, which is implemented as edge-conditioned convolution operator (NNConv), the update rule is described in Section A.3. The network further consists of batch normalization layers (BN), GELU activation functions, and dropout layers. The hidden representation h of graph G_i is updated at block l as follows:\n[h_i, e_i] \u2192 {NNConv \u2192 BN \u2192 GELU \u2192 concat(h_i^l, h_i) \u2192 dropout} \u2192 h_i^{l+1}\\\\\nwhere h represents the latent representation after activation. Updating the feature matrix l times yields the final node representations of the pharmacophoric points."}, {"title": "Pooling layer", "content": "We employed additive pooling for graph-level read-out r_i, which aggregates the set of |V| node representations {h_1, ..., h_{|V|}}_i of a Graph G_i by element-wise summation:\nq_i = \\sum_{k=1}^{|V|} h_k\\\\\\"}, {"title": "Projection block", "content": "The projection block maps the graph-level read-out to the positive real number space and is implemented as a multi-layer perceptron MLP : R^d \u2192 R^D, where d is the dimension of the vector representation before and D the dimension after the projection. The block consists of k sequential layers of FC layers, BN, ReLU activation, and dropout:\nq_i^l \u2192 {FC \u2192 BN \u2192 ReLU \u2192 Dropout} \u2192 q_i^{l+1}\\\\\nThe final layer is a FC layer without bias and with positive weights, only:\nz_i = abs(W)q_i\\\\\\\nMatrix multiplication of the positive learnable weights W and the output of the last ReLU activation function produces the final representation z_i \u2208 R^p."}, {"title": "A.5 Model implementation and training", "content": "Implementation dependencies The GNN was implemented in Python 3.10 with PyTorch (v2.0.1) and the PyTorch Geometric library (v2.3.1) (Fey and Lenssen 2019). Both, model and dataset, were implemented within the PyTorch Lightning (Falcon and The PyTorch Lightning team 2019) framework (v2.1.0). Model training was monitored with Tensorboard (v2.13.0). CDPKit (v1.1.1) was employed for chemical data processing. Software was installed and executed on a Rocky Linux (v9.4) system with x86-64 architecture.\nModel training Training was performed on a single NVIDIA GeForce 3090 RTX graphics unit with 24 GB"}]}