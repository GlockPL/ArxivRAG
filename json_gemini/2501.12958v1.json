{"title": "A Novel Tracking Framework for Devices in X-ray Leveraging Supplementary Cue-Driven Self-Supervised Features", "authors": ["Saahil Islam", "Venkatesh N. Murthy", "Dominik Neumann", "Serkan Cimen", "Puneet Sharma", "Andreas Maier", "Dorin Comaniciu", "Florin C. Ghesu"], "abstract": "To restore proper blood flow in blocked coronary arteries via angioplasty procedure, accurate placement of devices such as catheters, balloons, and stents under live fluoroscopy or diagnostic angiography is crucial. Identified balloon markers help in enhancing stent visibility in X-ray sequences, while the catheter tip aids in precise navigation and co-registering vessel structures, reducing the need for contrast in an- giography. However, accurate detection of these devices in interventional X-ray sequences faces significant challenges, particularly due to occlu- sions from contrasted vessels and other devices and distractions from surrounding, resulting in the failure to track such small objects. While most tracking methods rely on spatial correlation of past and current appearance, they often lack strong motion comprehension essential for navigating through these challenging conditions, and fail to effectively detect multiple instances in the scene. To overcome these limitations, we propose a self-supervised learning approach that enhances its spatio- temporal understanding by incorporating supplementary cues and learn- ing across multiple representation spaces on a large dataset. Followed by that, we introduce a generic real-time tracking framework that effec- tively leverages the pretrained spatio-temporal network and also takes the historical appearance and trajectory data into account. This results in enhanced localization of multiple instances of device landmarks. Our method outperforms state-of-the-art methods in interventional X-ray de- vice tracking, especially stability and robustness, achieving an 87% re- duction in max error for balloon marker detection and a 61% reduction in max error for catheter tip detection.", "sections": [{"title": "1 Introduction", "content": "A clear and stable visualization of the stent is crucial for coronary interventions. Stent enhancement is highly valuable specifically for estimating stent position for under-expansion, stent failure, stent disruption and treatment of aorto-ostial and bifurcation lesions [7]. Tracked balloon markers can be used as anchor points to stabilize consecutive sequence images and superimposing them to enhance the stent visualization [8]. Tracking the catheter tip serves as an anchor point for mapping vessel information between fluoroscopy and angiography images, reduc- ing contrast usage for vessel visualization [14] and aiding stent and balloon place- ment in catheterized interventions. Tracking such small objects poses challenges due to complex scenes caused by contrasted vessel structures amid additional occlusions from other devices and from noise in low-dose imaging. Distractions from visually similar image parts along with the cardiac, respiratory and the device motion itself aggravate these challenges. An example of how contrasted vessel structure cause occlusions is depicted in Fig. 1.\nIn recent years, various tracking approaches have emerged for both natural and X-ray images. Most of these methods use siamese architectures to extract features from two different crops, typically one search and one or more template frames, enabling them to adapt to changes in appearance via spatial correla- tion techniques [4,19,20,1,10]. Recently, transformers have been integrated into these architectures [18,2,3]. However, these methods rely on asymmetrical crop- ping, which removes natural motion. The small crops are updated based on past predictions, making them highly vulnerable to noise and risk incorrect field of view while detecting more than one object instance. Furthermore, using the initial template frame without an update makes them highly reliant on initializa- tion. To incorporate motion information, some methods use historical trajectory [17,13] which is suboptimal for medical datasets with sparse annotations. Semi- supervised methods like Cycle Ynet [12] have been employed to address the lack of annotated frames, but they may introduce noise due to weak-label super- vision. ConTrack [3] uses optical flow to integrate contextual spatio-temporal information from past frames, yet it is restricted to a single past frame and relies on mask segmentation, which may not be available for many datasets. Furthermore, self-supervised learning (SSL) approaches have gained popularity by demonstrating how pretraining on unlabeled datasets can enhance perfor- mance in downstream tasks [5,15,6,16]. FIMAE [9] employs a masked image modeling (MIM) based SSL method on a large unlabeled angiography dataset, but it emphasizes reconstruction without distinguishing objects. It's worth not-"}, {"title": "2 Methods", "content": "Let Du denote the large unlabeled dataset and D, represent a dataset containing pixel-level annotations of vessels. We denote the downstream dataset for tracking as Dr. For the particular objects in consideration, our goal is to track their loca- tion, \u0177t = (ut, vt) at any time t, t \u2265 0 given a sequence of X-ray images {It}0 and an initial location yo = (uo, vo). The proposed self-supervised learning and the downstream tracking framework is depicted in Fig. 2 and is explained in the subsequent subsections:"}, {"title": "2.1 Self-Supervised Learning with Supplementary Cues", "content": "We employ a task-specific model to generate weak labels, required for obtain- ing the supplementary cues. In particular, a U-Net, Fs(0), is used to train a"}, {"title": "2.2 Historical Feature Guided Tracker", "content": "We design a Historical Feature Guided Tracker (HiFT) for Di.\nSpatio-temporal encoder. We input n \u2208 N frames with symmetrical crops to the pretrained spatio-temporal encoder preserving the natural motion. Similar to the pretraining pipeline, each sampled sequence \u00f1 \u00d7 h \u00d7 \u0175 adopts a joint space-time attention (MHA) to obtain features f\u2208 R\u00fb\u00d7\u00d7\u00d7d.\nDynamic correlation with appearance and trajectory. We build cor- relation tokens as a concatenation of appearance and trajectory for model- ing relation with past frames. In particular, we use the past frame predic- tions ((uo, vo),... (Un-2, Un-2)) as the centre to crop the past frame features fo, f1... fn-2 obtaining appearance tokens ($). To obtain the trajectory (c), we tokenize each past frame predicted coordinates similar to SwinTrack [13] to provide additional information about the motion. We adopt a multi-head Cross- Attention Decoder (MCA) to correlate the current frame features (fn-1) with the correlation tokens. The output of this decoder is passed through a small Con- volutional Neural Network (CNN) head to give a heatmap (zheat) corresponding to the locations of the objects to be tracked on the current frame.\n\nZheat = HeadH (MCA(\u0192\u00f1\u22121, Concat(\u03a60, Co, \u03a61, C1, \u00b7\u00b7\u00b7 \u03a6\u00f1\u22122, \u0421\u00f1\u22122)))\n(4)\nThe coordinates of the landmarks are obtained by grouping the heatmap by connected component analysis (CCA) and obtain argmax (locations) of the number of landmarks (or instances) needed to be tracked. We adopt auxiliary decoders (Decodera, Decoder,...) for datasets Di, where additional annota- tions are present, e.g. dense mask annotations of catheter body. An auxiliary decoder simply follows MHA with a task-specific head, predicting zaux. We use a weighted loss, L\u2081 = Lp +\u2211j=1 1jLj as our loss function for I auxiliary tasks. Aj denotes the weights assigned to each auxiliary task. Lp follows a soft dice loss given by:"}, {"title": "3 Experiments", "content": "Dataset. The vesselness dataset (Ds) consists of 3300 training and 91 testing angiography sequences. Coronary arteries were annotated with centerline points and approximate vessel radius for 5 sufficiently contrasted frames, which were then used to generate target vesselness maps for training. The unlabeled dataset (Du) includes 241,362 sequences from 21,589 patients, totaling 16,342,992 frames, comprising both angiography and fluoroscopy sequences. We use two downstream datasets (Di) for evaluating the tracking performance. The balloon marker dataset consists of 1058 training and 113 test sequences consisting of both fluoroscopy and angiography sequences. All frames are annotated with the location of the balloon marker pairs. For the catheter tip dataset, there are 2,314 training se- quences totaling 198,993 frames, with annotations for 44,957 frames, and 219 test sequences with complete frame annotations. A subset of the training dataset in- cludes catheter body mask annotations. Both test datasets are divided into \"with occlusion\", where at least one frame in the sequence is obstructed, and \"no oc- clusion\", where the entire sequence is free of obstruction. The balloon marker dataset has a ratio of 38:75 for \"with occlusion\" to \"no occlusion\" cases, while the catheter tip dataset has a ratio of 125:94.\nExperimental Setup: We adopt a similar preprocessing pipeline as Con- Track [3]. During training, we randomly sample 5 consecutive annotated frames, cropping them to 256x256 using the first frame annotation as the center. During inference, similar crops are applied and updated if the distance from the past pre- diction to the border exceeds 30 pixels. Please refer to supplementary materials for more details. We train for 250 epochs using a learning rate of 0.0002.\nComparison with State-of-the-Art. We assess our approach's perfor- mance against existing methods in Table 1 for balloon marker and catheter tip detection with both manual and automatic initialization. Most trackers rely on modeling appearance changes, particularly advantageous for catheter tip track- ing, where the tip is often entirely occluded during contrast injection. While these methods demonstrate similar precision in detecting balloon markers, their high standard deviation and max error indicate inadequate motion comprehension, particularly critical for such small objects, which are vulnerable to distractions. 3D-DenseUNet utilizes multiple uncropped frames (as channels) preserving nat- ural motion, leading to comparable performance to the specialized trackers for balloon marker tracking, but fails to track catheter tip due to the absence of modeling for appearance changes. Our approach integrates both advantages, sig- nificantly reducing max error by 87% and 61% for balloon markers and catheter"}, {"title": "4 Conclusion", "content": "In this work, we enhance Self-Supervised Learning by incorporating contextual cues through weak-label supervision, encouraging the network to learn features across multiple representation spaces. We introduce a novel tracking framework leveraging the pretrained spatio-temporal network for device tracking, substan- tially reducing failures compared to prior state-of-the-art methods. Our approach shows promising results even without manual initialization. As a future work, the self-supervised learning method encourages us to explore more than 2 rep- resentation spaces and use the pretrained network for tasks other than tracking. While we use a naive method to test our performance without manual initial- ization, automatic initialization based tracking requires further investigation."}]}