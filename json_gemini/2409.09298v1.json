{"title": "Matrix Profile for Anomaly Detection on Multidimensional Time Series", "authors": ["Chin-Chia Michael Yeh", "Audrey Dert", "Uday Singh Saini", "Vivian Lai", "Yan Zheng", "Junpeng Wang", "Xin Dai", "Zhongfang Zhuang", "Yujie Fan", "Huiyuan Chen", "Prince Osei Aboagye", "Liang Wang", "Wei Zhang", "Eamonn Keogh"], "abstract": "The Matrix Profile (MP), a versatile tool for time series data mining, has been shown effective in time series anomaly detection (TSAD). This paper delves into the problem of anomaly detection in multidimensional time series, a common occurrence in real-world applications. For instance, in a manufacturing factory, multiple sensors installed across the site collect time-varying data for analysis. The Matrix Profile, named for its role in profiling the matrix storing pairwise distance between subsequences of univariate time series, becomes complex in multidimensional scenarios. If the input univariate time series has n subsequences, the pairwise distance matrix is a nxn matrix. In a multidimensional time series with d dimensions, the pairwise distance information must be stored in a n\u00d7n\u00d7 d tensor. In this paper, we first analyze different strategies for condensing this tensor into a profile vector. We then investigate the potential of extending the MP to efficiently find k-nearest neighbors for anomaly detection. Finally, we benchmark the multidimensional MP against 19 baseline methods on 119 multidimensional TSAD datasets. The experiments covers three learning setups: unsupervised, supervised, and semi-supervised. MP is the only method that consistently delivers high performance across all setups.", "sections": [{"title": "I. INTRODUCTION", "content": "The Matrix Profile (MP) is an effective and efficient tool for detecting anomalous patterns within a time series [1, 2]. It detects anomalies using the concept of time series discord [3-5], where the level of anomalousness of a subsequence is measured using the nearest neighbor distance (e.g., z-normalized Euclidean distance). In other words, if a subsequence and its most similar counterpart within the same time series are distant in Euclidean space, then the subsequence is likely an anomaly.\nThe primary challenge in extending MP to multidimensional time series for anomaly detection is that the anomalous pattern usually spans only a handful of dimensions in the multidimensional time series [6]. As a result, we cannot simply sum the distances computed using each individual dimension, as this would bury the anomalous pattern under all the dimensions consisting of normal patterns. This challenge is referred to as the K of N anomaly detection problem in [6]. Fig. 1 demonstrates that naively computing MP using all dimensions does not solve the K of N anomaly detection problem. In the figure, we have an eight-dimensional time series, of which only one dimension consists of the anomalous pattern.\nIf we compute MP using all dimensions, the result would be the Matrix Profile (naive) depicted in the figure. Unfortunately, this fails to correctly identify the location of the anomalous pattern. The maximum value, marked with an orange X in the figure, indicates the location of the subsequence with the largest nearest neighbor distance, but it is not temporally close to the anomalous pattern. This observation suggested that it is more effective to compute MP using only a subset of the dimensions rather than all of them. However, identifying the correct combination of dimensions using a brute force solution has a time complexity of O(d!), where d represents the number of dimensions in the time series. To resolve this issue more efficiently, we employ a greedy algorithm where the dimensions are selected in order from most to least anomalous. This dimension selection process can be implemented using any sorting algorithm once the distances between subsequences have been computed, thereby reducing the time complexity from O(d!) to O(dlog d).\nRecall that MP is a vector summarizing the pairwise distances between each pair of subsequences in a time series. These distances can be stored in a matrix where the (i, j) position stores the distance between the i-th and j-th subsequences in the time series. The Matrix Profile gets its name from its function of \"profiling\" this pairwise distance matrix"}, {"title": "II. RELATED WORK", "content": "Anomaly detection algorithms can be categorized into six families: 1) forecasting, 2) reconstruction, 3) distance, 4) encoding, 5) distribution, and 6) tree methods [7].\nForecasting-based methods such as Torsk [8], Telemanom [9], and DeepAnT [10] detect anomalies within time series by first building a forecasting system and then measuring the difference between the predicted and actual time series. Reconstruction-based methods like OmniAnomaly [11] and RobustPCA [12] project the input time series subsequence to a low-dimensional representation, then use a decoder to reconstruct the subsequence. The anomaly of the subsequence is measured by the difference between the original and reconstructed subsequences.\nDistance-based methods such as Matrix Profile (MP) [1], k-Means [13], kNN [14], CBLOF [15], LOF [16], PCC [17], HBOS [18], COF [19], and Hybrid kNN [20] compute the anomaly score by measuring the distance between different subsequences. Encoding-based methods like MultiHMM [21] encode the input time series subsequence to a low-dimensional representation and compute the anomaly score in the low-dimensional space. Distribution-based methods like CO-POD [22] fit a distribution model to the data and estimate the probability of the input data being anomalous. Tree-based methods such as EIF [23], iForest [24], IF-LOF [25], and HIF [26] utilize an ensemble of random trees to partition the data and compute the anomaly score based on the partition.\nThe authors of [7] have conducted a comprehensive evaluation of various time series anomaly detection (TSAD) methods and showcased the great performance of MP on univariate TSAD datasets. However, they did not evaluate MP on multidimensional time series datasets. A method which extend MP to multidimensional time series is provided in [6], but it does not address certain types of multidimensional anomalies (i.e., correlation anomalies [27]) as discussed in Section IV-A. To our knowledge, our paper is the first to offer a comprehensive study on the application of MP to multidimensional TSAD problems."}, {"title": "III. BACKGROUND", "content": "In this section, we introduce key definitions that are crucial for understanding the problem formulation and the methodology. We then present the three distinct formulations of the time series anomaly detection (TSAD) problem that we have adopted in our study. For notation, lowercase letters (e.g., x), boldface lowercase letters (e.g., x), uppercase letters (e.g., X), and boldface uppercase letters (e.g., X) are used to represent scalars, vectors, matrices, and tensors, respectively. We use B to denote the set of Boolean numbers.\nFirst, we establish the definition of a multidimensional time series.\nDefinition 1. A multidimensional time series, consisting of n time steps and d dimensions, is stored in a matrix $T \\in \\mathbb{R}^{n \\times d}$. Note that we use $T[i : i + m, j]$ to denote a subsequence of length m that begins at the i-th time step in the j-th dimension.\nAs the Matrix Profile summarizes pairwise distances between subsequences, we introduce the concept of a pairwise distance tensor. This tensor stores the pairwise distances between all subsequences in one time series and all subsequences in another time series.\nDefinition 2. Given a time series $T_1 \\in \\mathbb{R}^{n_1 \\times d}$, another time series $T_2 \\in \\mathbb{R}^{n_2 \\times d}$, and a subsequence length m, the pairwise distance tensor $D \\in \\mathbb{R}^{(n_1-m+1) \\times (n_2-m+1) \\times d}$ stores the pairwise distances between subsequences in $T_1$ and subsequences in $T_2$. Each element within D is defined as:\n$D[i, j, k] \\leftarrow \\text{DISTANCE}(T_1[i : i+m, k], T_2[j : j+m,k])$ (1)\nwhere the function $\\text{DISTANCE}(\\cdot, \\cdot) \\rightarrow \\mathbb{R}$ computes the distance between the input subsequences.\nFollowing [1, 28, 29], we use the z-normalized Euclidean distance as our distance function due to its efficacy and"}, {"title": "IV. METHODOLOGY", "content": "This section details the application of the Matrix Profile (MP) to the multidimensional time series anomaly detection (TSAD) problem. First, we discuss various strategies for creating a multidimensional MP from a pairwise distance tensor. Following this, we illustrate how to leverage the multidimensional MP in different anomaly detection problem formulations.\nBefore delving into the strategies for summarizing pairwise distance tensors from multidimensional time series, we will first demonstrate how MP summarizes the pairwise distance matrix from univariate time series. This approach will acquaint readers with both the MP concept and the graphical representation utilized to explain the summarization operations. Fig. 2\nAs demonstrated in Fig. 1, the approach of simply summing the distances computed using each individual dimension will not work, as it would obscure the anomalous pattern amidst all the dimensions that consist of normal patterns. This problem is known as the K of N anomaly detection problem, introduced in Section I. To address this, let us consider the multidimensional scenario where we have a pairwise distance tensor $D \\in \\mathbb{R}^{(n_1-m+1) \\times (n_2-m+1) \\times d}$, generated from two time series $T_1 \\in \\mathbb{R}^{n_1 \\times d}$ and $T_2 \\in \\mathbb{R}^{n_2 \\times d}$ with a subsequence length of m. Generally, the most anomalous dimension can be identified by sorting the dimension-wise distances between a subsequence and its nearest neighbor. The dimension with the largest distance value is deemed the most anomalous (as it has the largest nearest neighbor distance), and vice versa [6, 28]. Fig. 3 illustrates this: given two four-dimensional subsequences $T_i$ and $T_j$, sorting the dimensions based on the dimension-wise distances reveals that the fourth dimension is the most anomalous.\nGiven that we need to incorporate a sorting mechanism into MP computation process, we have two options: 1) a post-sorting design, where the sorting algorithm is applied after the"}, {"title": "V. EXPERIMENT", "content": "In this section, we first outline the datasets used for the experiments in Section V-A. We then discuss the experimental protocol for different learning setups, such as unsupervised, supervised, and semi-supervised, in Section V-B. The baseline methods for comparison are detailed in Section V-C, and the benchmark results, comparing the MP-based method with the baseline methods, are presented in Section V-D. As there are no labeled training data for both unsupervised and semi-supervised learning datasets, the hyper-parameters are set manually. A study on these hyper-parameters is presented in Section V-E. The source code and further details about the experiments can be found in [33].\nExperiments were conducted on multidimensional time series anomaly detection (TSAD) datasets, which are available on the supporting website of [34]. Our experimental setup made use of 48 unsupervised learning datasets, 25 supervised datasets, and 46 semi-supervised datasets. These 119 datasets, which are derived from eight different dataset collections, are detailed in Table II. The dimensionality of these datasets varies from 2 to 38. The total number of time steps across all 119 datasets is 8,849,589, and the total number of values is 71,998,980.\nThe experiment settings are determined based on the problem formulations associated with each of the learning setups (i.e., unsupervised, supervised, and semi-supervised) introduced in Section III-B. The process for measuring performance is consistent across all three learning setups. The specific performance functions utilized in this paper are AUC-ROC [40, 41] and AUC-P\u2020RT [42]. These are commonly used threshold-agnostic performance measures for TSAD problems [7].\nFor supervised learning datasets, the hyper-parameters for the MP-based method are determined based on the results of a hyper-parameter search using the training data. However, due to the absence of training labels for both unsupervised and semi-supervised datasets, the hyper-parameters are manually set. For unsupervised datasets, we set the subsequence length to 64, adopt the pre-max variant, use the first dimension of the multidimensional MP, and set k for k-th nearest neighbor finding to 15. For semi-supervised datasets, we use a similar set of hyper-parameters as the unsupervised datasets, but set the k to one instead of 15. The process of setting the hyper-parameters will be further discussed in Section V-E.\nWe included 19 baseline methods for comparison with the MP-based method. We report the performances of baseline methods that are available on at least 50% of the datasets within a learning setup. The methods included in our benchmark, along with their availability in different learning settings, are shown in Table III. We use check marks to highlight the methods that meet the availability criteria.\nWhen selecting a dimension from the multidimensional MP, the first dimension should be used as it can identify all sub-dimensional anomalies, as demonstrated in Fig. 6. We compared this strategy to an alternative approach where the dimensions are reduced using the mean function, as implemented in [34]. Based on the experimental results shown in Table V, using the first dimension outperforms the alternative. Lastly, as we demonstrate in Table V, the moving average post-processing step generally enhances performance."}, {"title": "VI. CONCLUSION", "content": "In this paper, we have provided a comprehensive study on applying the Matrix Profile (MP) to a multidimensional time series anomaly detection (TSAD) problem. We compared different methods for generating multidimensional MPs from pairwise distance tensors, proposed an efficient k-nearest neighbor MP extension, and discussed how to utilize various types of joins offered by the MP for TSAD. Using the knowledge presented, we designed an MP-based TSAD system with competitive performance on 119 datasets, compared to the other 19 baseline methods. For future work, we would like to explore the interaction between MP-based multidimensional TSAD methods with sketching [5], random projection [44], or dictionary learning [29]. It would also be interesting to explore the possibility of combining pretrained/foundation models [45, 46] with an MP-based multidimensional TSAD system."}]}