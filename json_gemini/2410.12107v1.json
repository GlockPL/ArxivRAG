{"title": "Just-In-Time Software Defect Prediction via Bi-modal Change Representation Learning", "authors": ["Yuze Jiang", "Beijun Shen", "Xiaodong Gu"], "abstract": "For predicting software defects at an early stage, researchers have proposed just-in-time defect prediction (JIT-DP) to identify potential defects in code commits. The prevailing approaches train models to represent code changes in history commits and utilize the learned representations to predict the presence of defects in the latest commit. However, existing models merely learn editions in source code, without considering the natural language intentions behind the changes. This limitation hinders their ability to capture deeper semantics. To address this, we introduce a novel bi-modal change pre-training model called BiCC-BERT. BICC-BERT is pre-trained on a code change corpus to learn bi-modal semantic representations. To incorporate commit messages from the corpus, we design a novel pre-training objective called Replaced Message Identification (RMI), which learns the semantic association between commit messages and code changes. Subsequently, we integrate BiCC-BERT into JIT-DP and propose a new defect prediction approach - JIT-BiCC. By leveraging the bi-modal representations from BiCC-BERT, JIT-BICC captures more profound change semantics. We train JIT-BiCC using 27,391 code changes and compare its performance with 8 state-of-the-art JIT-DP approaches. The results demonstrate that JIT-BiCC outperforms all baselines, achieving a 10.8% improvement in F1-score. This highlights its effectiveness in learning the bi-modal semantics for JIT-DP.", "sections": [{"title": "1. Introduction", "content": "Software defect prediction (SDP), namely, identifying potential defects before software release, has been an indispensable technique in software development [1]. SDP helps developers predict potential defects in the early stages of the software development cycle so that they can take measures to mitigate the defects [2]. The state-of-the-art approaches [3, 4] mainly employ machine learning techniques to estimate the probability or number of bugs that a given source code file contains.\nRecently, just-in-time defect prediction (JIT-DP), which aims to predict defects immediately after code changes, has emerged as a major SDP technique [5]. Source code is constantly changing in the software development process, which inevitably introduces software defects [6, 7]. It is desirable to predict potential bugs right after developers commit the code to version control systems (e.g., Git) so that developers can fix them promptly [8]. Figures 1 and 2 provide examples illustrating how code changes could in- troduce software defects, specifically, the defective commit #732682 and its fixing commit #945189 in Apache's project commons-compress.\nIn commit #732682 on 2009/01/08, developers created a new method named \"parseName\" with an added line \"result.append((char) header[i]);\" (Line 19) to store the header's entry name for the returning value. However, it was not until one year later that they discovered that this line would incur a name round-trip problem. Subsequently, they fixed this issue in commit #945189 by modifying this line to \"result.append((char) (b & 0xFF));\" (Line 15) to allow for sign-extension.\nJIT-DP is usually conceptualized as a binary classification problem [9]: given a code change represented as features, a machine-learning classifier is employed to determine whether it introduces a software defect or not. Thus, the main objective for JIT-DP is to learn code change represen- tations, namely, representing code change as feature vectors. There have been numerous features for change representa- tions [10], including expert features (also known as metric features) and semantic features.\nDespite showing promising potential, representing code changes is notably challenging. First, current change rep- resentation techniques, such as CC2Vec [11] and JIT- Fine [10], often rely on only a limited amount of manually labeled data samples to train their defect prediction models. This is usually insufficient for the models to acquire the accurate semantics in code changes with complex patterns and associations.\nMoreover, contemporary approaches [10, 11, 12] solely concern the unimodal features in source code. This restricts their capability to capture the semantic associations between commit messages and code changes. Previous work [13] has demonstrated that commit messages can provide crucial information for understanding code changes, through the gradient-weighted class activation mapping (Grad-CAM) algorithm [14]. However, existing JIT-DP approaches either completely omit commit messages in the defect prediction model [13] or oversimplify the processing of commit mes- sages [10, 15]. Therefore, they fail to leverage the explicit semantic associations between commit messages and code changes in change representations.\nTo alleviate these limitations, in this paper, we pro- pose BiCC-BERT, a novel bi-modal change representation model. To enhance the semantic representation of code changes, we design a novel pre-training objective called Replaced Message Identification (RMI), which replaces the commit message and asks the model to predict the replace- ment. This forces the model to align the semantics between commit messages and code changes.\nBased on BiCC-BERT, we present JIT-BiCC, an ap- proach for JIT-DP by integrating BiCC-BERT into the conventional defect prediction framework. Our approach takes as input code changes as well as their corresponding commit messages and extracts bi-modal semantic features using BiCC-BERT. The semantic features are fused with traditional expert features through fully-connected neural networks. Finally, the two sources of features are concate- nated and fed to a classifier for defect prediction.\nWe evaluate JIT-BiCC on the JIT-Defects4J dataset which consists of 21 open-source projects with 27,391 changes. We measure the performance using the F1-score and AUC. Experimental results demonstrate that JIT-BiCC significantly outperforms baseline approaches, with over 10.8% improvement in terms of the F1-score."}, {"title": "2. Background and Motivation", "content": "2.1. Just-In-Time Defect Prediction\nJust-in-time defect prediction (JIT-DP) aims at predict- ing whether a code commit contains defects [9]. JIT-DP assumes that historical code changes that introduce defects have similarities with future changes, and trains a machine learning model to identify defect-prone code changes [16]. Formally, for a dataset $D = \\{(x_1, y_1), ..., (X_N, Y_N)\\}$ of N code commits, where $x_i$ is a code commit and $y_i \\in \\{0,1\\}$ represents whether $x_i$ is defective (=0) or not (=1), JIT-DP aims to learn a function $f: D \\leftrightarrow Y$.\nThe input features of JIT-DP can be categorized into two types [10], namely, expert features and semantic features. JIT-DP based on expert features [17, 18, 19] hypothesizes that there is a fixed relationship between software metrics (expert features) and defects. These techniques define code change features as macro metrics such as lines of code added (LA), number of modified subsystems (NS), and developer experience (EXP) based on experts' understanding of how code commits cause defects [10]. They [17, 18, 19] use statistical machine learning models such as decision trees, support vector machines, and Bayesian networks to predict future defects. These approaches have strong interpretabil- ity [10, 20] while not relying on large datasets due to the experience of the experts. However, they often oversimplify\n2.2. Code Change Representations\nApart from JIT-DP, due to the swift advancement of deep learning, code representation learning has also emerged as a widespread technique [25]. This technology transforms code changes into discrete semantic vectors through deep neu- ral networks [26], particularly pre-trained language models (PLMs). Formally, let $x=c \\oplus m$ denote a code commit frag- ment where $c=\\{c_1, ..., c_{N_1} \\}$ is a change fragment with $N_1$ tokens, and $m=\\{m_1,\\dots, m_{N_2} \\}$ represents the corresponding commit message with $N_2$ tokens. The goal of code change representation learning is to map $x$ to a $d$-dimensional vector that captures the semantics of the code change, i.e., $f_\\theta: X \\rightarrow \\mathbb{R}^d$ [26], where $f_\\theta$ is a learnable function parameter- ized by $\\theta$. $f_\\theta$ can be implemented using deep neural networks such as MLP [27], LSTM [28], and Transformer [29]. The learned features are utilized for a broad range of downstream tasks such as change quality estimation [12], automating code review [12], and commit message generation [30].\nCode change representation learning can be broadly categorized into two types [11]: sequence-based and graph- based approaches. Sequence-based approaches treat code changes as token sequences and employ deep learning mod- els, such as Convolutional Neural Networks (CNN) [15], Long Short-Term Memory Networks (LSTM) [17], and Transformers [12, 31], to learn the semantic representations. Graph-based approaches [25, 26, 32, 33, 34, 35, 36], parse source code into abstract syntax trees (ASTs) and represent them as graphs. Nodes in the graph represent files or functions, while edges represent the dependencies and change relationships between them [32]. Structural represen- tation enables the model to capture more complex relation- ships between code structures and changes [32].\nHowever, the limitation of previous research is that they do not fully utilize the semantic associations between com- mit messages and code changes. To illustrate how important commit messages can be for understanding code changes, an example is given in Figure 3, namely, the commit #373191 in Apache's project commons-net.\nIn this commit, developers wrapped \"socket = server.accept();\" (Line 7) with a try-catch block to close the server on an IOException by \"server.close();\" (Line 11). The logic in the above code changes is precisely described by its attached commit message: \"Close ServerSocket resource on IOException.\"\nInspired by the guidance that commit messages can help developers to understand code changes, we intuitively hypothesize that code change representation models can learn more accurate code semantics guided by commit messages. To verify our hypothesis and fill the gap in previ- ous research, our work eventually designs a bi-modal change representation model incorporating both code change and commit message."}, {"title": "3. Approach", "content": "To fully exploit the semantics in commit messages, we propose a bi-modal change representation model for JIT- DP, called BiCC-BERT (Section 3.1), and then incorporate the model into the general framework of JIT-DP, denoted as JIT-BICC (Section 3.2). BiCC-BERT follows the \u201cpre- training & fine-tuning\u201d paradigm of PLMs, wherein we pre- train a Transformer encoder on a large-scale change corpus and transfer the pre-trained knowledge to JIT-DP as its downstream task.\n3.1. Learning Code Change Representations\nBiCC-BERT extends CodeBERT [37] by incorporating commit messages into code change representations. Besides masked language modeling (MLM) [38], we design a new objective of pre-training, replaced message identification (RMI). By pre-training on these two objectives, the model performs bidirectional language modeling on code commits and explicitly captures the semantic correlations between commit messages and code changes.\n3.1.1. Model Architecture\nFigure 4 illustrates the architecture of BiCC-BERT. Ini- tially, the input code commit is tokenized and embedded through an embedding layer before feeding into a Trans- former encoder to extract the change representation. The extracted change representation vectors are taken as input to two dense layers for pre-training the bi-modal change representation learning model.\nTo incorporate both commit message and code change into change representation learning, BiCC-BERT integrates three channels of information (i.e., commit message, added lines, and deleted lines) as input, separated with special to- kens. A \"[CLS]\" token is added before the commit message, an \"[ADD]\" token is added before each \"added line\", and a \"[DEL]\" token is added before each \"deleted line\". This enables the model to differentiate different components from code commits during pre-training and the downstream de- fect prediction task. The commit message, added lines, and deleted lines are then tokenized and fed into BiCC-BERT to generate the corresponding code change representation.\n3.1.2. Masked Language Modeling (MLM)\nTo enable BiCC-BERT to understand the deep semantics in code changes and commit messages, we firstly employ the widely used pre-training task \"Masked Language Modeling\" (MLM) [38]. MLM replaces a small portion of tokens in the input code with a special [MASK] symbol and trains the BiCC-BERT to predict the original tokens given the masked code, thereby encouraging the model to utilize the contextual information for semantic representations.\nFormally, given a text sequence $x = x_1, ..., X_n \\in X$, we randomly mask $m$ positions and create a masked sequence:\n$x^{(m)} = x_1,..., X_{i_1-1}, [MASK],\nXi_1+1,..., X_{i_m-1}, [MASK], X_{i_m+1},\u2026\u2026, X_n$ (1)\nwhere $i_1, i_2, ..., i_m$ are randomly generated positions for masking.\nThe MLM task [38] aims to maximize the probability of predicting the correct words given the masked sequences. The loss function is defined in the form of negative log- likelihood:\n$L_{mlm} (\\theta) = \\sum_{x^{(m)} \\in D} log p (X_{i_1},X_{i_2},..., X_{i_m} | x^{\\neg m}; \\theta)$ (2)\nwhere $D$ represents the training dataset, $x^{\\neg m}$ denotes all the tokens in $x$ except for the masked positions, and $\\theta$ represents the model parameters. The objective of the negative log likelihood loss is to maximize the conditional probability $P(X_1,X_2,..., X_{i_m} | x^{\\neg m};\\theta)$ to train the model parameters $\\theta$, enabling the model to predict the missing words correctly given the masked positions.\n3.1.3. Replaced Message Identification (RMI)\nThe MLM pre-training task enables the BiCC-BERT to capture the semantic relationships between code tokens and the surrounding context in JIT-DP. However, it does not consider the bi-modal nature of change representation which involves both change patterns and the corresponding semantics in the commit messages.\nTo explicitly learn the semantic relationship between commit messages and code changes, we propose a new pre- training objective named Replaced Message Identification (RMI). RMI randomly determines whether to replace the commit message with a non-corresponding message and trains the BiCC-BERT to predict whether the commit mes- sage is replaced, i.e., whether the commit message corre- sponds to its code change.\nThe pre-training objective of RMI is formulated as a binary classification task: given a code commit $x_i$, the model predicts whether the message has been replaced ($y_i = 0$) or not ($y_i = 1$). The prediction function $f_{RMI}$ can be learned by optimizing the cross-entropy loss function:\n$L_{rmi}(\\theta) = - log (\\prod_{i=1}^{N}P (y_i | x_i; \\theta))\n= - \\sum_{i=1}^{N} [(1 - y_i) log (1 - p (y_i | x_i ; \\theta))\n+y_i log (p (y_i | x_i; \\theta))]$ (3)\nwhere $\\theta$ represents the model parameters, and $p(y_i|x_i; \\theta)$ denotes the probability score from the model's output layer. To accomplish this objective, the model needs to under- stand the code changes and the commit messages separately, and compare their consistency. Whereby, the model is forced to learn the explicit semantic relationship between commit messages and code changes, as well as utilize the key infor- mation provided by commit messages to better understand code changes in JIT-DP.\nIn the pre-training phase, JIT-BiCC performs the MLM and RMI objectives alternately. This allows the model to"}, {"title": "3.2. Just-In-Time Defect Prediction", "content": "Based on the bi-modal change representation model, we propose a novel defect prediction approach called JIT-BICC by integrating BiCC-BERT into the general defect predic- tion framework. Figure 6 illustrates the overall architec- ture of JIT-BiCC. Given code commits, JIT-BiCC extracts two types of features, namely, code change representations learned by BiCC-BERT and 14 metric-based expert features. The extracted features and change representations are fused by concatenation. Finally, an MLP classifier is employed to predict defects based on the fused feature vector.\nThe framework can be formulated as follows: given a code commit snippet $x_i$ and a code change representation model $g_\\theta$, JIT-BiCC first extracts the semantic feature vector $s_i = g_\\theta(x_i)$ from the code commit snippet with the code change representation model. Then, JIT-BiCC extracts the expert feature vector $e_i = h(x_i)$ using a function $h$ prede- fined by experts. The fused feature vector of the semantic and expert features is denoted as $m_i = s_i \\oplus e_i$. Subsequently, the fused feature vector is fed into the JIT-DP model $f_{pp}$, which predicts the probability of the code commit snippet containing defects as $p(y_i|x_i) = f_{pp}(m_i)$, where $y_i$ indicates whether the code commit snippet contains a defect.\n3.2.1. Feature Extraction and Fusion\nTo fully leverage the code commit representations that BiCC-BERT learns from pre-training, JIT-BiCC directly in- puts code commits into the BiCC-BERT to extract semantic features from code commits.\nAt the same time, JIT-BiCC extracts expert features based on predefined metrics. JIT-BiCC represents expert features as a 14-dimensional vector, each dimensionality corresponding to a widely used change-level code metric proposed by Kamei et al. [18]. The list of all 14 metrics is presented in Table 1.\nTo make the most utility of both expert and semantic features, JIT-BiCC subsequently fuses them into one vec- tor and takes them as input to a classifier. As the change representation vectors have a different dimensionality to that of the expert feature vector, JIT-BiCC follows previous works [10, 39] and expands the expert features to the same dimensionality of the change representation vector through a trainable dense layer. Finally, JIT-BiCC concatenates the two vectors into a new vector, which serves as the fused feature vector for the entire code commit.\n3.2.2. Defect Prediction\nThe defect prediction model takes the fused vector of se- mantic and expert features as input and predicts the probabil- ity of the corresponding code commit being defective. The model maps the fused vector to a 2-dimension vector using a multi-layer perceptron (MLP) and a softmax layer. The 2-dimension vector consists of two elements respectively representing the probabilities of the code commit being defective and defect-free. Finally, the model's parameters are optimized by minimizing the loss function, which measures the difference between these probabilities and the true labels. During the fine-tuning of JIT-DP, the parameters of the code change representation model and the defect prediction model are trained simultaneously.\nThe JIT-DP model can be learned by minimizing the cross-entropy loss function:\n$L = -log \\prod_{i=1}^{\\mid D \\mid} p (y_i \\mid m_i; \\theta)\n= \\sum_{i=1}^{\\mid D \\mid} [(1 - y_i) log (1 - p (y_i \\mid m_i ; \\theta))\n+y_i log (p (y_i \\mid m_i; \\theta))]$ (4)\nwhere $\\theta$ represents the model parameters, and $p(y_i| m_i; \\theta)$ denotes the probability score from the model's output layer."}, {"title": "4. Experimental Setup", "content": "4.1. Research Questions\nTo investigate the effectiveness of JIT-BiCC, we aim to answer the following three research questions:\nRQ1. How does JIT-BiCC perform in JIT-DP? We com- pare JIT-BiCC with state-of-the-art approaches from differ- ent categories on the same dataset to evaluate the effective- ness of JIT-BICC.\nRQ2. How effective is the bi-modal change representa- tion approach? We ablate the MLM, the RMI, and both objectives individually from JIT-BiCC and conduct com- parative experiments to evaluate the effectiveness of the bi- modal change representation.\nRQ3. How can the combination of MLM and RMI affect the performance of JIT-BiCC? We explore the impact of\n4.2. Dataset\nWe train and test JIT-BiCC on JIT-Defects4J [10], a com- monly used benchmark for JIT-DP. JIT-Defects4J is derived from the manually labeled LLTC4J (Line-Labelled Tangled Commits for Java) dataset [40], with thorough preprocess- ing (e.g., ignoring excessively large commits, excluding commits with no added code lines, and filtering out non- functional code changes) to ensure high quality. In contrast, traditional JIT-DP datasets such as Hoang et al.'s [11, 15] and Zeng et al.'s [13], are automatically annotated using the SZZ algorithm [41], which was shown to introduce a large number of false positives and negatives [34, 42, 43, 44] due to tangled commits. JIT-Defects4J has also been widely used in recent studies on JIT-DP such as JIT-Fine [10] and CCT5 [45]. To establish a fair comparison, we use\n4.3. Evaluation Metrics\nWe employ two commonly used metrics, F1-score and AUC, to evaluate the performance of JIT-DP.\nF1-score: a metric for measuring the overall accuracy of a JIT-DP model. It is calculated as the harmonic mean of precision and recall and ranges between 0 and 1, with 1 being the best score. F1-score can be computed as:\n$F1 = \\frac{2 \\times Recall \\times Precision}{Recall + Precision}$\nwhere precision is the ratio of true defective predictions to the total number of defective predictions, and recall is the"}, {"title": "5. Experimental Results", "content": "5.1. Effectiveness of JIT-BiCC (RQ1)\nWe evaluate the overall performance by comparing JIT- BiCC with baseline models outlined in Section 4. The results are presented in Table 3. We observe that JIT-BiCC outperforms all other comparative approaches in all evalua- tion metrics. Compared to JIT-Fine, the highest-performing baseline, JIT-BiCC achieves a relative performance im- provement of 10.8% in terms of F1-score and 0.7% in terms of AUC. The significant improvement in F1-score balances recall and precision for JIT-DP, enabling software developers to better identify potential bugs in their code commits with minimal human effort based on JIT-BICC 's predictions.\nWe also find that JIT-Fine, CodeReviewer, and JIT-BiCC perform noticeably better compared to other approaches in terms of both F1-score and AUC. These approaches are the only ones that build change representation models based on pre-training approaches. This implies that pre-trained change representation models can contribute to a deeper understanding of code commits. Furthermore, JIT-Fine and JIT-BiCC achieve the best results among all baselines, being the only two approaches that take advantage of both expert features and semantic features. This indicates that feature fu- sion can also benefit the performance of JIT-DP, which is one of the reasons that JIT-BiCC outperforms other approaches.\nAnother interesting point is that CodeReviewer also achieves competitive performance compared to all com- parative approaches except JIT-Fine and JIT-BiCC. This is probably because CodeReviewer is also pre-trained to learn the code change representations, which contributes to more accurately identifying defective code commits. How- ever, as this model is primarily trained to automate code review tasks, it fails to outperform JIT-Fine and JIT-BiCC, which are designed to focus on JIT-DP. This highlights the importance of constructing a specialized code change representation learning model for JIT-DP, which is essential for JIT-BICC to outperform others.\nAnswer to RQ1: JIT-BiCC achieves state-of-the-art per- formance on JIT-DP, significantly aiding software develop- ers in prioritizing their efforts to hunt for potential code defects. Our bi-modal change pre-training model (BiCC- BERT) facilitates a more effective understanding of code changes.\n5.2. Effectiveness of Bi-modal Change Representation (RQ2)\nTable 4 presents the results of ablation studies. We compare JIT-BiCC with three variants of code change repre- sentation models: BiCC-BERT without the RMI and MLM objectives, BiCC-BERT without the MLM objective, and BiCC-BERT without the RMI objective. For the variants that require pre-training, we maintain the same quantity of data samples and number of training epochs as used in JIT-BiCC. We find that JIT-BiCC outperforms all variants in terms of F1-score and AUC, indicating that both MLM and RMI are effective for bi-modal change representation learning. This implies that the contextual modeling approach can enhance the model's understanding of the entire code commit by allowing the model to gradually learn the depen- dencies between different parts of a code commit. Addition- ally, explicitly capturing the semantic correlation between commit messages and code changes can further enhance the model's understanding of code changes. Therefore, both the RMI and MLM objectives contribute to strengthening the\n5.3. Impact of Pre-training Objective Combinations (RQ3)\nWe further investigate the impact of different combina- tions of pre-training objectives, including training orders and sampling probability on JIT-DP.\n5.3.1. Training Order of Pre-training Objectives\nWe examine the standard JIT-BiCC alongside two con- figurations for training the bi-modal change representation model: 1) pre-training with RMI followed by MLM (referred to as RMI\u2192MLM), and 2) pre-training with MLM followed by RMI (referred to as MLM\u2192RMI).\nThe results in Table 5 show the impact of different training orders of pre-training objectives on the performance of JIT-DP. The default setting of JIT-BiCC outperforms all the variant settings in terms of F1-score and AUC, indicating that alternating the training of MLM and RMI significantly improves the evaluation metrics compared to training MLM and RMI successively. Therefore, it can be concluded that training JIT-BiCC by alternating MLM and RMI objec- tives with probability-based sampling plays a crucial role in improving its performance. The reason is that training MLM and RMI objectives successively leads to catastrophic forgetting, where the model forgets the knowledge learned from the previous objective while training the latter one. Furthermore, alternating the training of MLM and RMI objectives facilitates mutual supervision between these two pre-training objectives, allowing the model to share and complement objective-relevant knowledge. Thus, alternately training MLM and RMI objectives can help BiCC-BERT further enhance the understanding of code commits and achieve better generalization ability, improving the perfor- mance of JIT-DP.\nAn interesting point is that pre-training the change representation model with RMI followed by MLM (i.e., RMI\u2192MLM) does not contribute to performance improve- ment. The underlying reason is perhaps the same as why pre-training JIT-BiCC with only the RMI objective performs even worse compared to no pre-training, as we have dis- cussed in RQ2. These results underscore the importance of domain adaptation for achieving improved performance.\n5.3.2. Objective Proportion\nWe contrast the default setting of JIT-BiCC (referred to as 2xMLM, 1\u00d7RMI) with two variants in the bi-modal change representation model. These variants involve differ- ent ratios for combining training objectives: 1) pre-training with MLM and RMI with 1:1 ratio (referred to as 1\u00d7MLM, 1\u00d7RMI), and 2) pre-training with MLM and RMI objectives with 3:1 ratio (referred to as 3\u00d7MLM, 1\u00d7RMI).\nThe results in Table 6 show that the sampling ratio of the pre-training objectives has a significant impact on the performance of JIT-BiCC. Among all evaluation metrics, pre-training JIT-BiCC with a sampling ratio of 2:1 outper- forms all other variants. The reason is that there is a mu- tually supervisory relationship between the MLM and RMI training objectives, and an appropriate sampling ratio allows the model to better complement the knowledge learned from alternating training. On the other hand, excessively high or low ratios hinder the formation of a good mutual supervisory relationship between the two pre-training objectives. Hence, combining the MLM and RMI objectives with a sampling ratio of 2:1 best benefits BiCC-BERT in extracting deeper semantic information from code commits, thereby exhibiting better performance in JIT-DP.\nAnswer to RQ3: Alternately training BiCC-BERT with MLM and RMI using an appropriate ratio (2:1) fosters mu- tual supervision between the objectives, thereby enhancing the model's understanding of code commits and leading to optimal performance in JIT-DP."}, {"title": "5.4. Threats to Validity", "content": "Threats to external validity primarily pertain to the characteristics of the dataset under study. Due to the limi- tation of our dataset, JIT-Defeat4J, the diversity of projects considered in our research is limited in three key aspects. First, our analysis focuses solely on projects developed in Java, overlooking other popular languages such as C/C++ and Python. Incorporating projects from these languages would provide a more comprehensive perspective.\nSecond, the projects analyzed in our study are exclu- sively open-source projects, and we have no knowledge of JIT-BiCC's performance on commercial projects.\nLastly, we must acknowledge that not all software bugs can be identified within the code repository. Despite the manual labeling conducted in LLTC4J [40], there is still a possibility of missing certain bug-fixing commits.\nThreats to construct validity correspond primarily to the selection of evaluation metrics in our experiments. To mitigate these threats, we have employed two different met- rics, F1-score and AUC, which are widely used in previous studies. By employing these metrics, we aim to provide a comprehensive and well-rounded assessment of our model's performance."}, {"title": "6. Related Work", "content": "6.1. Code Change Representation Learning\nCode change representation learning", "26": "has attracted extensive attention of researchers in recent years. Compared to code representation", "11": "proposed CC2Vec", "31": "introduced CoreGen", "54": "extended the seq2seq model to copy an entire span from the input commit in a single step", "30": "presented a novel approach to construct embeddings for code changes by unsupervised pre-training on a large unlabeled code change corpus. The embeddings are applied to the tasks of commit message generation and applying changes to code. Li et al. [12", "55": "proposed CoditT5", "56": "introduced CCBERT", "45": "proposed CCT5"}, {"26": "introduced a graph neural network-based approach that learns representations for code changes based on the AST of the code via an autoencoder framework. Brody et al. [33", "25": "presented commit2Vec", "57": "proposed a general model for incremental editing of code change ASTs that learns iterative edits on the trees", "32": "proposed ACE", "34": "proposed ccs2vec", "35": "presented a graph- based approach that encodes changes in the context of their surrounding code by converting the code changes into graphs", "36": "proposed COMU", "10": "expert- feature-based JIT-DP and semantic-feature-based JIT-DP.\nExpert-feature-based JIT-DP. It utilizes predefined metrics by experts based on their understanding and cap- turing of defect factors in code commits [10, 17, 18", "17": "proposed FENCES, which extracts six features covering different aspects of code changes and treats JIT- DP into a sequence labeling problem that is solvable by a recurrent neural network. Pornprasit et al. [49", "20": "and do not require training models on extremely large datasets. However, expert-feature-based ap- proaches oversimplify the causes of software defects and overlook the inherent semantic factors that trigger software defects.\nSemantic-feature"}]}