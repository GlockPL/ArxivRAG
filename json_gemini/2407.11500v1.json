{"title": "An AI System for Continuous Knee Osteoarthritis Severity Grading Using Self-Supervised Anomaly Detection with Limited Data", "authors": ["Niamh Belton", "Aonghus Lawlor", "Kathleen M. Curran"], "abstract": "The diagnostic accuracy and subjectivity of existing Knee Osteoarthritis (OA) ordinal grading systems has been a subject of on-going debate and concern. Existing automated solutions are trained to emulate these imperfect systems, whilst also being reliant on large annotated databases for fully-supervised training. This work proposes a three stage approach for automated continuous grading of knee OA that is built upon the principles of Anomaly Detection (AD); learning a robust representation of healthy knee X-rays and grading disease severity based on its distance to the centre of normality. In the first stage, SS-FewSOME is proposed, a self-supervised AD technique that learns the 'normal' representation, requiring only examples of healthy subjects and < 3% of the labels that existing methods require. In the second stage, this model is used to pseudo label a subset of unlabelled data as 'normal' or 'anomalous', followed by denoising of pseudo labels with CLIP. The final stage involves retraining on labelled and pseudo labelled data using the proposed Dual Centre Representation Learning (DCRL) which learns the centres of two representation spaces; normal and anomalous. Disease severity is then graded based on the distance to the learned centres. The proposed methodology outperforms existing techniques by margins of up to 24% in terms of OA detection and the disease severity scores correlate with the Kellgren-Lawrence grading system at the same level as human expert performance.", "sections": [{"title": "1 Introduction", "content": "Knee Osteoarthritis (OA) is a degenerative joint disease that affects over 250 million of the world's population [35]. Two of the most common grading systems for OA diagnosis are the Kellgren-Lawrence (KL) system [20] and the Osteoarthritis Research Society International (OARSI) atlas criteria [2,3]. The KL system consists of five ordinal classes from grade zero to four where grade zero is healthy,"}, {"title": "", "content": "grade four is severe OA and grades \u2265 2 are the cut-off for OA diagnosis [14]. The OARSI atlas criteria diagnoses OA if the subject meets specific criteria relating to the degree of Joint Space Narrowing (JSN) and the severity of osteophytes [15]. The subjectivity of these scales have been a matter of on-going concern [1] with studies reporting wide ranges of inter-observer reliability of 0.51 to 0.89 [37] for the KL system. Low agreement between the two scales has also been reported with OA being diagnosed almost twice as often using the OARSI atlas criteria compared with the KL system [14]. The variability of OA severity grading has been attributed to the difference in the level of clinician's experience and/or the use of subjective language such as 'possible' osteophytic lipping and 'doubtful' joint space narrowing in the guidelines for grading [13]. The challenges of the current OA grading systems suggests that ordinal classes may not be suitable for assessing OA severity and highlights the requirement for an automated system.\nThis work aims to overcome the weaknesses of current AI systems and models for OA grading. Firstly, the high performance of existing techniques (accuracies > 90%) is a cause for concern given the inter-rater observer reliability between human experts can be as low as 0.51 [37], suggesting that the methods have overfit to the dataset. Secondly, several of the approaches train the model as a multi-class classification problem which do not consider the ordinal nature of the data. Thirdly, existing solutions are reliant on large datasets consisting of thousands of X-rays for training, along with ground truth OA severity labels from experts which is a tedious and costly process.\nThis work proposes a three stage approach to designing a continuous automated disease severity system. The principle that underpins the proposed methodology is that healthy knee X-rays can be more easily identified but classifying the degree of OA severity is a subjective process. The first stage therefore, focuses solely on learning a robust representation of healthy X-rays through Self-Supervised Learning (SSL). The model FewSOME [7] is leveraged for this as it requires as few as 30 labels to achieve optimal performance and therefore, the challenge of acquiring a large dataset is eliminated. This work extends Few-SOME to use SSL, namely SS-FewSOME. The OA severity of an X-ray is then assessed based on its distance in Representation Space (RS) to the centre of the normal RS, borrowing the core concept of several Anomaly Detection (AD) techniques. The second stage involves using the trained technique to pseudo label unlabelled data and denoising these labels with the CLIP model. The third stage is Dual Centre Representation Learning (DCRL), where the model contrastively learns two representations, normal and anomalous. Disease severity is then graded based on the distance to the learned centres.\nThe contributions of this work are;\nA newly proposed continuous OA grading system based on the principles of AD that is not trained to overfit to a subjectively graded dataset, thus removing any subjective bias.\nWe advance the original FewSOME by including SSL, patch based contrastive learning, denoising of pseudo labels with CLIP and DCRL, increas-"}, {"title": "2 Related Work", "content": ""}, {"title": "2.1 Automated Knee OA Severity Classification", "content": "Several fully-supervised Convolutional Neural Network (CNN) based approaches have been proposed to classify knee X-rays according to the KL system. Antony et al. [4] developed a technique to localise the knee joint area on the X-ray and then classify the OA severity using a CNN. The CNN simultaneously minimised a categorical cross-entropy loss and a regression mean squared error loss. Several works approved upon this performance by employing ensembles of CNNs [5] and implementing more advanced CNNs such as the ResNET [27], the HR-Net [18], Siamese networks [34], Long Short-Term Memory models (LSTM) [36] and dual channel autoencoders [17]. These methods were further improved by incorporating complex data pre-processing such as image enhancement [25] and noise-reduction with Gaussian-filters, normalising with a pixel-centering method, and implementing a balanced contrast enhancement technique [32]. The majority of existing techniques optimised their performance using loss functions suitable for multi-class classification, where the distance between all grades are equidistant i.e. the distance between grade zero and grade four is equal to the distance between grade zero and grade one. Culvenor et al. [13], instead, employed an ordinal loss function to take into account the ordinal nature of KL grading system. More recently, MediAI-OA [38] has advanced beyond simple KL grade classification by automatically quantifying the degree of JSN in the medial and lateral tibiofemoral joint and detecting osteophytes in the medial distal femur, lateral distal femur, medial proximal tibia and lateral proximal tibia regions.\nA prior work investigated the feasibility of a continuous OA system based on Siamese networks, reporting a positive correlation between the KL grading system and the model output [24]. However, despite this progress, the existing solutions are trained to mimic a flawed grading system and they are reliant on large annotated training sets with the MediAI-OA system training on 44,193 labelled radiographs."}, {"title": "2.2 Anomaly Detection", "content": "AD is a field of study that aims to automatically identify data samples that differ substantially from normality. These typically involve one-class methods"}, {"title": "", "content": "such as DeepSVDD [30] and PatchCore [29] that learn or extract the features of normality and detect anomalies based on their distance to the normal RS. Generative models are another class of AD models [39], particularly popular in the medical field [11,6,40]. At training time, they learn to reconstruct the image. At test time, they can then identify anomalies by large reconstruction errors. However, SSL based methods such as Cutpaste [23] have been dominating the field of AD in recent years, with several works leveraging SSL for medical AD tasks [10,11]. Although the majority of AD techniques train on unlabelled data, a recent technique Dual-distribution discrepancy with self-supervised refinement (DDAD) [11] trains on both labelled and unlabelled data. They train an ensemble of reconstruction networks with the objective of modelling the normative distribution and a second ensemble of networks to model the unknown distribution. They then calculate the intra-discrepancy and inter-discrepancy of the distributions to assign anomaly scores. Finally they train a separate network via self-supervised learning to further refine the anomaly scores. They demonstrated their AD performance on chest X-rays and brain MRI.\nThere has been recent interest in Few Shot AD for settings where there is limited data. Few Shot AD focuses on learning to detect anomalies having trained on zero shots or few shots of the normal class [19,7]. FewSOME [7] is a recent few shot AD technique originally developed for poor quality data detection in medical imaging datasets [9] and has since proven its performance for AD in natural images, industrial defect detection and motion artefact detection in brain MRI [8]. FewSOME is in the category of one-class AD models as it contrastively learns the normal RS from solely nominal images and prevents representational collapse with the use of an 'anchor' and stop loss. Anomalies are identified based on their distance to the normal RS."}, {"title": "3 Materials", "content": "The baseline cohort from the Osteoarthritis Initiative (OAI) [12,26] was used for this analysis as it is the most commonly used subset in the literature. The OAI is an observational, longitudinal study of 4,796 subjects across 431,000 clinical studies with the goal of better understanding of prevention and treatment of knee osteoarthritis [26]. The images are of size 224 \u00d7 224, with 5,778 available for training, 826 available for validation and 1,526 available for testing. It was ensured that both knees belonging to a single patient were within the same dataset split to prevent any data leakage. The dataset provides the KL grades and a grading for both the severity of JSN and osteophytes on a scale from zero to three. The grading for JSN and osteophytes are provided for medial and lateral tibiofemoral compartments separately. According to the OARSI scale, OA is diagnosed if any of the following criteria are met; either JSN grade \u2265 2, sum of osteophyte grades \u2265 2 or grade one JSN in combination with a grade one osteophyte [14,15]. The dataset contained missing values for osteophyte gradings in some cases. As the missing values solely occurred when the KL grades were equal to zero or one and the JSN for both the medial and lateral compartments"}, {"title": "4 Methods", "content": ""}, {"title": "4.1 Stage 1: Self-Supervised Learning", "content": "The purpose of SSL is to learn a representation of healthy X-rays. There are K ensembles trained on a dataset XN of size N, where XN is sampled from the training data, Xtrain which consists of solely nominal images of healthy X-rays. In iteration i of training, a data sample xi \u2208 XN is paired with a randomly selected data sample xj \u2208 XN. The original FewSOME implementation relies on ImageNet pretrained weights and an 'anchor' for learning compact representations of the normal class where the ground truth label, y is equal to zero for the duration of training. This work extends this method to use SSL where both data samples, xi and xj are input into a Stochastic Data Augmentation (SDA) module. The SDA module consists of two sets of transforms, Tnorm and Tanom. The set of transforms Tnorm are applied only to xi and they consist of weak, global augmentations that aim to generate additional X-rays whose representation are within the hyper-sphere of the normal RS. Tnorm consists of the identity function (i.e. no transformation), applying jitter to the image and adjusting the sharpness and brightness. The set of transforms Tanom are applied only to x; and"}, {"title": "", "content": "they consist of the identity function and strong augmentations, random cropping followed by resizing and Cutpaste [23]. Section 7.2 presents the results of experiments conducted to choose the optimal performing transforms for Tanom.\nFollowing the SDA, the first l layers of a neural network, \u03c6, initialised with ImageNET [31] pre-trained weights are used to transform the input space, XN to the RS, \u03c6l(XN) \u2208 Rc\u00d7h\u00d7w, where c is the number of channels, h is the height and w is the width of the extracted feature maps. The later layers are removed as they are biased towards natural image classification. As the size of the training dataset is small, both \u03c6l(xi) and \u03c6l(xj), denoted as \u03c6i,l and \u03c6j,l, are converted to patch level features, P(\u03c6i,l) and P(\u03c6j,l) using a sliding window of size sw \u00d7 sw with stride = 1 with resulting dimensions of p\u00d7c \u00d7 sw \u00d7 sw where p is the number of patches. The patch level features also improve the sensitivity of the model to localised anomalies such as osteophytes. Feature aggregation is performed by average pooling for each patch and the resultant tensor is reshaped"}, {"title": "", "content": "to create patch embedding maps, F(P(\u03c6i,l)) and F(P(\u03c6j,l)) \u2208 R\u221ap\u00d7\u221ap\u00d7c. The patch embedding map, F(P(\u03c6i,l)) consists of p patches at coordinates z, k, where each patch is denoted as Pi,k,z.\nThis method exploits that X-rays are spatially similar and therefore, the Cosine Distance, CD is calculated only between patches Pi,z,k \u2208 F(P(\u03c6i,l)) and Pj,z,k \u2208 F(P(\u03c6j,l)) that have the same coordinates, z, k. The ground truth label Yi,z,k\u2200(z,k) is equal to zero if the identity transform in the SDA was applied to xj and Yi,z,k\u2200(z, k) is equal to one if cropping and resizing was applied. In the case of applying the CutPaste transform, the entire image is not affected and therefore, Yi,z,k is equal to one if the receptive field of pj,z,k was affected by the CutPasting and zero otherwise. The CD between each patch, Pi,z,k and Pj,z,k is calculated as shown in equation 1 and denoted as \u0177i,z,k. The difference between \u0177i,z,k and the ground truth label, Yi,z,k are minimised using Binary Cross Entropy during training as shown in equation 2.\nYi,z,k = 1 - \\frac{P_{i,z,k} \\cdot P_{j,z,k}}{||P_{i,z,k}|| ||P_{j,z,k}||} \\qquad(1)\nLBCE = \\frac{1}{N \\sqrt{p} \\sqrt{p}} \\sum_{z=1}^{\\sqrt{p}} \\sum_{k=1}^{\\sqrt{p}} \\sum_{i=1}^{N} Yi,z,k \\cdot log(\\hat{y}_{i,z,k}) + (1 - Yi,z,k) \\cdot log(1 - \\hat{y}_{i,z,k}) \\qquad(2)"}, {"title": "4.2 Stage 2: Pseudo Labelling and Denoising with CLIP", "content": "Given an unlabelled dataset of X-rays, Xu of size u where Xu \u2229 XN = \u00d8, the patch embedding map, F(P(\u03c6u,l)) consisting of patches p, for each data sample x \u2208 Xu is obtained. The centre, Cnorm of the normal RS is then calculated as in equation 3. An anomaly scoring function, SSSL assigns xu an Anomaly Score (AS) equal to the average CD to the centre Cnorm, as shown in equation 4.\nC_{norm} = \\frac{1}{N \\sqrt{p} \\sqrt{p}} \\sum_{i=1}^{N} \\sum_{z=1}^{\\sqrt{p}} \\sum_{k=1}^{\\sqrt{p}} P_{i,z,k} \\qquad(3)\nSSSL(Xu) = \\frac{1}{\\sqrt{p} \\sqrt{p}} \\sum_{z=1}^{\\sqrt{p}} \\sum_{k=1}^{\\sqrt{p}} \\frac{Pu,z,k \\cdot C_{norm}}{||Pu,z,k|| ||C_{norm}||} \\qquad(4)\nEach ensemble K identifies a data instance as an anomaly if the AS is greater than m times the maximum CD between all possible pairs in the training data (denoted as CDmax), where 1 < m < \u221e. Data instances that have been voted as an anomaly across all ensembles are then assumed to be severe OA cases. The model can be retrained on these cases to improve the sensitivity to OA specific anomalies with the newly assigned pseudo label of y = 1. However, knee X-rays often contain anomalies unrelated to the OA grade, such as the presence of screws and metal in the X-ray due to knee replacement implants [16]. Using"}, {"title": "4.3 Stage 3: Dual Centre Representation Learning with FewSOME", "content": "Given there are now anomalous psuedo labels available for training, this section proposes Dual Centre Representation Learning (DCRL) with FewSOME. The goal of DCRL is to simultaneously learn two separate RSs for normality and anomalies. DCRL has the same methodology as Stage 1 SSL except the SDA is switched off and the value of y is determined by where x; is sampled from. For example, in iteration i of training, xi \u2208 XN is paired with a randomly selected data sample xj where y\u2081 = 0 if xj \u2208 Xn and y\u2081 = 1 if xj \u2208 Xa. The objective of"}, {"title": "", "content": "the training is to transform xi and xj to the RS, calculate the CD between the two instances and compare this to the ground truth label yi.\nIt was found that the model learns a more robust representation of healthy X-rays when training with pseudo labels of varying OA severity, while it is less robust when exposed to only pseudo labels of severe OA cases (cases with high AS scores output from the model). However, training the model on pseudo labels of more severe OA cases (cases with high AS) results in a highly accurate severe OA detector but a less accurate OA detector. To combat this trade-off, two models are trained, DCRL-FSsev and DCRL-FSOA.\nDCRL-FSsev is used to learn a RS for healthy cases, RSnorm and another for severe OA cases, RSsev. DCRL-FSOA learns a RS for normal OA cases, RSnorm and another for all other varying severity OA cases, RSOA. The margin, m controls the level of severity of the pseudo labels. Therefore m is set higher when training DCRL-FSsev and lower when training DCRL-FSOA. DCRL-FSOA can be trained iteratively, meaning it can be used to predict additional pseudo labels, which are denoised using the method of Stage 2 and then retrained on the newly assigned pseudo labels.\nThe models are combined to develop the continuous automated grading system, DCRL-FScomb. The CD to the centre Cnorm of RSnorm (obtained from training DCRL-FSsev) is denoted as d\u2081 and the CD to Csev of RSsev is denoted as d2. The anomaly scoring function, SDCRLsev is then equal to the difference between the distances d\u2081 and d2 as can be seen from equations 5 to 7. Similarly, SDCRLOA is calculated as in equation 8, where d3 is the CD to the centre Cnorm of RSnorm (obtained from training DCRL-FSOA) and d4 is the CD to the centre COA Of RSOA. The DCRL-FSsev behaves as a severe OA detector, meaning if SDCRLsev is greater than a threshold, t, xu is assigned a score of 1 + SDCRLsev(xu), as 0 \u2264 SDCRLOA(Xu) \u2264 1. Otherwise it is equal to SDCRLOA(Xu), as shown in equation 9.\nd\u2081 = 1 - \\frac{DCRL-FS_{sev}(x_u) \\cdot C_{norm}}{||DCRL-FS_{sev}(x_u)|| ||C_{norm}||} \\qquad(5)"}, {"title": "", "content": "d\u2082 = 1 - \\frac{DCRL-FS_{sev}(x_u) \\cdot C_{sev}}{||DCRL-FS_{sev}(x_u)|| ||C_{sev}||} \\qquad(6)\nSDCRLSev = ||d\u2081 - d\u2082|| \\qquad(7)\nSDCRLOA = ||d\u2083 - d\u2084|| \\qquad(8)\nSDCRLcomb(Xu) = \\begin{cases} 1+ SDCRLsev(Xu), & \\text{if SDCRLsev(Xu) > t} \\\\ SDCRLOA(Xu), & \\text{otherwise} \\end{cases} \\qquad(9)"}, {"title": "5 Implementation Details", "content": "The hyper-parameters including the model backbones were selected based on the model's performance on the validation set. The models were trained with a batch size of one, a learning rate of 1e-06, Adam optimiser [21] and weight decay of 0.1."}, {"title": "5.1 Stage 1", "content": "The size of the training set for each ensemble, was set to 30 (N = 30) as per the original FewSOME [7] implementation. The size of the training data, Xtrain (the data where N is sampled from for each ensemble) was set to 150 and a total of K = 10 ensembles were trained. Section 7.3 presents an analysis to motivate the selection of a training set size of 150 examples. The first five layers of an AlexNET [22] was employed as the model backbone. Training was halted once the training loss began to plateau."}, {"title": "5.2 Stage 3iter1", "content": "As X-rays with psuedo labels are now available for training in stage 3, the larger VGG-16 [33] is employed. The margin, m was set to 1.184 to obtain the pseudo labels for DCRL-FSOA as this resulted in a balanced number of normal instances and anomalous instances (30 pseudo labels). Based on experiments on validation data, the margin m was set to 3.122 to obtain the pseudo labels to train DCRL-FSsev. The threshold t for combining the models was set to the AS of the 95% percentile of the training data as output by DCRL-FSsev. The training is halted when the CD between the normal centre, Cnorm and anomalous centres COA (when training DCRL-FSOA) or Csev (when training DCRL-FSsev) begins to plateau. Section 7.4 presents an analysis of the effects of this early stopping technique."}, {"title": "5.3 Stage 3iterfinal", "content": "As previously mentioned, DCRL-FSOA can be trained iteratively. In the second iteration, the number of pseudo labels was equal to 263 for DCRLOA (with m = 1.184 as before). To avoid a large class imbalance, the number of training instances for each ensemble was increased from 30 to 150 (all available labelled training data). The model was not trained for further iterations as it reached optimal performance."}, {"title": "5.4 Competing Methods", "content": "Stage 1 SS-FewSOME's performance is compared to competing methods, DeepSVDD [30], SOTA AD technique PatchCore [29] and few shot AD technique FewSOME [7]. As the original implementation of DeepSVDD is compatible with small images of 32\u00d732, the images are downsampled to 128\u00d7128 and the architecture is upscaled by increasing the number of kernels. Competing methods were trained on 150 samples of normal X-rays as was SS-FewSOME.\nStage 3 Final Iteration The final iteration of the model is compared to DDAD [11], a SOTA model in medical AD, as it trains on both labelled and unlabelled data. DDAD is trained on 150 labelled healthy knee X-rays and 5,628 unlabelled X-rays. This is the most similar set-up to the stage 3 of the proposed method as it trains on 150 labelled healthy knee X-rays and there were 5,628 unlabelled X-rays available for pseudo labelling."}, {"title": "6 Results", "content": "The methodology is assessed based on its ability to diagnose OA according to the KL scale (grades \u2265 2) and the OARSI scale. Table 2 reports the Area Under the Receiver Operator Curve (AUC) in % for both tasks, denoted as AUCKL and AUCO. The Spearman Rank Correlation Coefficient (SRC) between the model output and the KL grade is also reported as SRCKL. Finally, to ensure that the model can identify severe OA cases to a high degree of accuracy, the table reports the performance of detecting cases with KL grades > 3 as AUCKLg>3."}, {"title": "6.1 Stage 1", "content": "Each method had 150 training instances available for training. The proposed SS-FewSOME significantly outperforms competing methods and it shows substantial performance improvement on the original FewSOME implementation, increasing the AUCKL from 58.3% to 72.9%. The results also show that integrating the patches method into the model has resulted in a performance improvement, increasing SRCKL from 0.315 to 0.432."}, {"title": "6.2 Stage 3iter1", "content": "The trade-off between OA detection and severe OA detection accuracy can be evidently seen from the results of DCRL-FSOA (stage 3iter1) and DCRL-FSsev, with the former outperforming DCRL-FSsev in terms of OA detection but underperforming in terms of severe OA detection. However, the combined model DCRL-FScomb (stage 3iter1) combines both aspects of the models to accurately detect OA, severe OA and correlate with the KL grades with an SRC of 0.541. Figure 5 shows the distance of each data instance in the test set from Cnorm at stage 1 and stage 3iter1. Separation between classes can be evidently seen at"}, {"title": "6.3 Stage 3iterfinal", "content": "The final iteration achieved an SRC of 0.583, a promising result given the inter-rater reliability of human experts was reported to be as low as 0.51 in some cases [37]. The proposed methodology outperforms the competing method DDAD [11] by margins of up to 24%, which was trained on 150 labelled healthy knee X-rays and 5,628 unlabelled X-rays. Notably, the proposed work outperforms the previous OA automated continuous system that reports an SRC of 0.524 (averaged across classes), having trained on 10,012 labelled images [24]. Additionally, a paired student t-test showed that the difference between the mean model output for each KL grade was statistically significant at the 5% significance level."}, {"title": "7 Further Analysis", "content": ""}, {"title": "7.1 CLIP Ablation", "content": "To demonstrate the effectiveness of denoising the pseudo labels with CLIP, DCRL-FSOA at stage 3iter1 was also trained without denoising. This resulted in a performance degradation as can be seen from table 3. Figure 7 presents examples of false anomalies that were denoised by CLIP."}, {"title": "7.2 Analysis of Transforms for Tanom", "content": "The following transforms were assessed for inclusion in Tanom; posterising which limits the number of tones and colours in the image, random rotate, random crop and CutPaste [23] which takes a segment of the image and pastes it elsewhere on the image. Table 4 presents the results of each transform on the validation set. CutPaste outperforms the other transforms by a substantial margin. As a combination of cropping and CutPaste resulted in the optimal performance, they were selected for the final model. Examples of the transforms are shown in figure 8."}, {"title": "7.3 Training Set Size Analysis", "content": "Figure 9 shows the model performance for each metric for varying sizes of Xtrain. As SS-FewSOME in stage 1 trains on N = 30, each training set size represents an ensemble of models training on N = 30. For example, a training set size of 60 is two ensembles training on N = 30. It can be seen from the figure that there a plateau in performance begins between 90 to 150 training instances. Therefore, the experiments were conducted training on 150 labelled instances. The figure also demonstrates how SS-FewSOME can achieve optimal performance on small training set sizes of as low as 90 examples."}, {"title": "7.4 Analysis of Early Stopping", "content": "In stage 3, training is halted when the CD between the centres, Cnorm and COA begins to plateau. Figure 10 (A) shows the average value for each metric (AUCKL, AUCOARSI, AUCgrade>3 and SRCKL) over ten seeds for each epoch on the test set for DCRL-FSOA at stage 3iter1. The black vertical line shows where early stopping occurred on average. It can be seen from the figure that there is no further performance increase after early stopping and overfitting has not occurred by the time of early stopping. Figure 10 (B) shows the CD between centres Cnorm and COA at each epoch."}, {"title": "8 Conclusion", "content": "This work has demonstrated the potential for a continuous disease severity grading system, which holds promise for substantial clinical impact by eliminating subjectivity and enabling the assessment of disease severity at any stage along"}, {"title": "", "content": "a continuum, rather than predefined discrete categories. This method is particularly useful for capturing subtle variations and changes over time, providing a more detailed and dynamic understanding of the condition's progression, ultimately resulting in improved patient care. The analysis showed that the proposed method outperforms existing methods by significant margins and can achieve human level performance whilst training on few labels, thus eliminating the requirement for large annotated databases."}]}