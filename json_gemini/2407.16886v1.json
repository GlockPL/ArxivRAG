{"title": "GPT-4's One-Dimensional Mapping of Morality:\nHow the Accuracy of Country-Estimates Depends on Moral Domain", "authors": ["Pontus Strimling", "Joel Krueger", "Simon Karlsson"], "abstract": "Prior research demonstrates that Open Al's GPT models can predict variations in\nmoral opinions between countries but that the accuracy tends to be substantially higher\namong high-income countries compared to low-income ones. This study aims to replicate\nprevious findings and advance the research by examining how accuracy varies with different\ntypes of moral questions. Using responses from the World Value Survey and the European\nValue Study, covering 18 moral issues across 63 countries, we calculated country-level\nmean scores for each moral issue and compared them with GPT-4's predictions. Confirming\nprevious findings, our results show that GPT-4 has greater predictive success in high-income\nthan in low-income countries. However, our factor analysis reveals that GPT-4 bases its\npredictions primarily on a single dimension, presumably reflecting countries' degree of\nconservatism/liberalism. Conversely, the real-world moral landscape appears to be\ntwo-dimensional, differentiating between personal-sexual and violent-dishonest issues.\nWhen moral issues are categorized based on their moral domain, GPT-4's predictions are\nfound to be remarkably accurate in the personal-sexual domain, across both high-income (r\n= .77) and low-income (r = .58) countries. Yet the predictive accuracy significantly drops in\nthe violent-dishonest domain for both high-income (r = .30) and low-income (r = -.16)\ncountries, indicating that GPT-4's one-dimensional world-view does not fully capture the\ncomplexity of the moral landscape. In sum, this study underscores the importance of not only\nconsidering country-specific characteristics to understand GPT-4's moral understanding, but\nalso the characteristics of the moral issues at hand.", "sections": [{"title": "1 Introduction", "content": "Large Language Models (LLMs) form their understanding and knowledge through the\nprocessing of their pre-training data. Similar to humans, these models are susceptible to various\nbiases, including those related to race, gender, political ideology, and religious affiliation (Abid et\nal., 2021; Kirk et al., 2021; Rozado, 2023; Singh & Ramakrishnan, 2023). While multiple efforts\nof bias-reduction have proven effective, such as the utilization of reinforcement learning with\nhuman feedback and the fine-tuning of training datasets, LLMs are still not immune to biases\n(Ray, 2023). As such, it remains an ongoing endeavor to understand where these models excel\nand fall short.\nIn this study, we focus on examining GPT-4's grasp of cultural nuances within the domain of\nmoral opinions. The interest in studying moral opinions is twofold. Firstly, as people increasingly\nrely on LLMs like GPT-4 for information, it becomes crucial to understand their accuracy and\npotential biases across various domains, including that of morality. Our perceptions about other\ncultures influence how we interact with them in an increasingly globalized and digitalized world.\nSecondly, LLM's cultural knowledge may be instrumental for other tasks they perform. For\nexample, one area gaining traction is the cultural and social alignment of Al agents (AlKhamissi\net al., 2024; Lee et al., 2024; Lin & Chen, 2023). Given the global deployment of Als, it becomes\ncentral to determine the types of values these agents should embody and to mitigate any\nunintended cultural biases. Previous research has proposed various strategies for enhancing\ncultural alignment between users and LLMs (AlKhamissi et al., 2024; Tao et al., 2023), such as\ncountry-specific prompting (e.g., instructing the LLM to answer like a person from another\nsociety). However, the efficacy of such approaches, and cultural alignment in general, is likely to\ndepend on the accuracy of the LLM's cultural understanding, warranting a comparison between\nAl-generated output and real-world data on moral issues.\nPrior research has established that GPT models contain some understanding of human moral\nstandards (Almeida et al., 2024; Dillion et al., 2023; Schramowski et al., 2022). In a\ncomprehensive study, Ramezani & Xu (2023) conducted a cross-cultural examination using\nGPT-2 and GPT-3. Their research demonstrated that both models' estimates of moral opinion\nwere significantly correlated with cross-cultural variation in real-world survey data, but that\nGPT-3 exhibited superior performance compared to GPT-2. Moreover, they separated countries\nby their economic status and continent, revealing more accurate estimates in more affluent and\nWestern countries. The authors concluded that the discrepancy in the accuracy of moral opinion\nrepresentation between affluent, Western nations and those that are not affluent or non-Western\nraises concerns about the potential limitations of English-language training data. They further\nspeculated that the observed gap may stem from either a deficiency in the representation of\ndiverse cultural moral norms or the predominance of Western viewpoints in descriptions of other\ncountries and cultures.\nWhile previous studies have focused on investigating differences in GPT's accuracy between\ndifferent categories of countries (Ramezani & Xu, 2023), limited attention has been paid to\nevaluating its accuracy across different types of moral issues. This despite an extensive\nliterature advocating for multi-dimensional taxonomies of cultural values to comprehend cultural\ndiversity (Graham et al., 2013; Haidt, 2007; R. F. Inglehart, 2018; R. Inglehart & Welzel, 2010;\nSchwartz, 2004; Vauclair & Fischer, 2011). Of particular interest is the distinction first made by\nVauclair and Fischer (2011), proposing the separation of moral issues into two categories:\npersonal-sexual and dishonest-illegal issues. Drawing from evolutionary and cultural theories,\nthey hypothesized that the dishonest-illegal moral domain should be independent of cultural\nvalues, whereas personal-sexual issues should be influenced by cultural perceptions of the self\n(i.e., independent versus interdependent selves). This notion found support when examining the\nrelationship between Shwartz (2004) cultural values and the two moral domains using World\nValue Survey data, where the Autonomy-Embeddedness dimension successfully predicted\ncountries attitudes on personal-sexual but not violent-dishonest issues. Taken together, this\nexample underscores the complexity of the moral landscape and emphasizes the importance of\nrecognizing the diversity of moral issues."}, {"title": "2 Material and methods", "content": "In this study, we aim to get a better understanding of GPT-4's ability to predict variation in moral\nopinions by accounting for both characteristics of countries and the moral issues at hand. We\nbegin by replicating Ramezani and Xu's (2023) finding that GPT contains knowledge about\ncultural variation in moral opinion and that it is significantly better at inferring moral opinions in\nhigh-income than in low-income countries. We then turn to the complexity of moral issues,\ncomparing the factor structure of GPT estimates with real-world survey data. Finally, building\nupon the results of the factor analysis, we conduct a series of supplementary analyses to delve\ndeeper into potential underlying causes and ramifications of GPT's dimensional structure and\nhow it estimates moral opinions.\nLike Ramezani and Xu (2023), we used the joint EVS/WVS 2017-2022 as our reference\ndataset. The dataset is a publicly available compilation of two large cross-cultural surveys, the\nWorld Value Survey Wave 7 (WVS) and the European Value Study 2017 (WVS/EVS, 2020). We\nused all items in the WVS Ethical and Values section that were included in both the WVS and\nthe EVS, resulting in 18 moral items surveyed across 63 geographically, culturally, and\neconomically varied countries. For each item, participants in the WVS/EVS were asked to judge\nhow justifiable a behavior is (e.g. abortion) on a Likert scale ranging from 1 (\"never\") to 10\n(\"always\"). We averaged participants' scores within countries to obtain country-level scores for\neach item. Henceforth, we will refer to the joint WVS/EVS dataset as simply WVS.\nWe asked chatGPT 4 (October, 2023) to make country-level estimates for each of the 18 moral\nitems in each of the 63 countries for which there is survey data. In the prompt, we specified the\nscale ranging from 1 (\u201cnever justifiable\u201d) to 10 (\u201calways justifiable\u201d), while requesting one\ndecimal precision."}, {"title": "Analysis", "content": "To test GPT's accuracy, we calculated Pearson correlation coefficients between WVS scores\nand GPT estimates. To avoid inflated correlations due to average differences in justifiability\nbetween issues, scores were normalized across countries for each moral issue in the WVS data\nand the GPT estimates.\nWe performed an exploratory factor analysis separately on the WVS data and the GPT\nestimates."}, {"title": "3 Evaluation and results", "content": "We evaluate the overall accuracy of GPT estimates, and also how accuracy differs between\nhigh-income and low-income countries. We then compare the dimensionality of the WVS data\nwith that of GPT's estimates and investigate differences in GPT's accuracy between different\nkinds of moral issues.\nAs a first test of GPT-4's knowledge of moral cultural variation, we compared GPT estimates\nand WVS scores across all countries and issues in the WVS dataset. The results show WVS\nscores and GPT estimates to be moderately positively correlated, r(1114) = .47, p < 0.001, 95%\nCI [0.43, 0.52], confirming that the GPT model contains some information about societal\nvariance in moral opinions. The mean correlations between GPT estimates and WVS scores for\neach moral issue separately revealed a mean correlation of .48, 95%, CI [0.33, 0.63], ranging\nfrom 0.03 for the justifiability of avoiding a fare on public transport to 0.90 for the justifiability of\nhomosexuality. Further, splitting countries by income level revealed a significant difference\nbetween high-income and low-income countries, with a strong correlation in the high-income\nsubset, r(748) = .50, p < 0.001, 95% CI [0.45, 55], but only a weak correlation in the low-income\nsubset, r(364) = 0.16, p = 0.003, 95% CI [0.05, 0.25]. See Figure 1.\nTo compare the dimensionality of the two datasets, we performed an exploratory factor analysis\nseparately for the WVS and GPT data. A scree plot of eigenvalues revealed that two\ncomponents should be retained for the WVS data and only one component for the GPT data\n(see Figure 2). The first two components for the WVS data had a cumulative explained variance\nof 0.78, which was identical to the explained variance of the first component for the GPT data\n(see bottom of Table 1).\nA factor analysis with varimax rotation retaining two factors for the WVS data showed that\nalmost all of the 18 moral issues could be separated into two factors, with the exceptions of two\nissues with slight cross-loadings, the justifiability of suicide and parents beating their children,\nand one issue that did not load well on either factor, the justifiability of the death penalty. The\nloadings of the single factor for the GPT data support a similar split, with positive loadings for\nissues that correspond to the WVS first factor loadings, and negative loadings for issues that\nmostly correspond to the WVS second factor loadings. See Table 1.\nBased on the GPT factor's positive versus negative loadings, we separated the 18 moral issues\ninto two groupings or moral domains. Largely following the distinction made by Vauclair &\nFischer (2011), we refer to the first category as personal-sexual issues (abortion, divorce,\neuthanasia, homosexuality, casual sex, prostitution, sex before marriage, and suicide) and to\nthe second category as violent-dishonest issues (man beating wife, violence, stealing property,\nclaiming government benefits to which one is not entitled, avoiding a fare on public transport,\ncheating on taxes, someone accepting a bribe in the course of their duties, the death penalty,\npolitical violence, and parents beating their children).\nGiven that GPT seems to derive all its predictions based on a single underlying factor, we would\nexpect a high correlation between GPT's estimates in the two moral domains. On the other\nhand, we would expect little or no correlation between the same domains in real-world survey\ndata, as the analysis suggested that two distinct factors drive variation in the WVS data. To test\nwhether this notion finds support, we calculated country-level means for personal-sexual and\nviolent-dishonest issues and examined the correlation between the two domains for GPT and\nWVS, respectively. As for the results, there was indeed a large correlation between GPT's\ncountry estimates in the two domains, r(61) = - .86, p < 0.001, 95% CI[-0.91, -0.78], while only a\nsmall, non-significant correlation was found in real-world data, r(52) = .14, p = .3, 95% CI[-0.13,\n0.40]. See Figure 3.\nSo far, we have shown that GPT-4 performs significantly better at estimating cultural variation\nacross high-income countries than across low-income countries. We also found that GPT's\nestimations are primarily based on a single underlying factor, despite the analysis of real-world\ndata suggesting a more nuanced explanation involving two factors. Together, these results\nsuggest that it may not only be important to consider countries' income level when evaluating\nGPT's predictive success, but also the moral domain in which GPT makes its predictions. To\naccount for both these factors, we tested accuracy for all four combinations of income and\ndomain. The results, displayed in Figure 4, reveal that GPT not only performs well in the\npersonal-sexual domain in high-income countries, r(331) = .77, p < 0.001, 95% CI [0.72, 0.81],\nbut also in low-income countries r(156) = .58, p < 0.001, 95% CI [0.47, 0.68]. In contrast, GPT\nperforms relatively poorly across both income groups in the violent-dishonest domain, with a\nweak to moderate correlation amongst high-income countries, r(415) = .30, p < 0.001, 95% CI\n[0.21, 0.38], and a weak negative correlation in low-income countries, r(206) = -0.16, p < 0.02,\n95% CI [-0.29, -0.03]. GPT's high performance for personal-sexual issues and low performance\nfor violent-dishonest issues, across income levels, suggests that the accuracy of estimates\ndepends more on differences between different types of issues than on country income level.\nTo get a better overview of the difference in accuracy between the two domains, we calculated\ncountry-level means separately for each domain and then correlated the GPT-means with the\nWVS-means. We found that GPT very accurately estimated societal variation in the\npersonal-sexual domain, r(61) = .85, p < 0.001, 95% CI [0.76, 0.90], but performed poorly in the\nviolent-dishonest domain, r(61) = .23, p = 0.07, 95% CI [-0.02, 0.45]. The right panel of Figure 5\nclearly shows that GPT's single factor does not capture societal variation in the\nviolent-dishonest domain. For instance, GPT's point estimates for Armenia and the Philippines\nare barely differentiated along the x-axis, though they are furthest apart in the empirical ratings\nrecorded by the WVS, that is, along the y-axis.\nFinally, we turned to the reason why GPT was so accurate in the personal-sexual domain while\nperforming so poorly in the violence-dishonest domain. The issues in the personal-sexual\ndomain, for which GPT is highly accurate, pertain to social topics that often divide liberals and\nconservatives. For this reason, we hypothesized that GPT's one-dimensional view of morality\nmay mainly place countries along a liberal-conservative continuum. To explore this hypothesis,\nwe asked GPT to estimate how \u201cliberal/progressive\u201d or \u201ctraditional/conservative\u201d each of the 63\ncountries in the WVS dataset is, on a scale from 0 (conservative) to 100 (extremely liberal). We\nthen correlated these liberalism estimates with the same country-level means used in the\nanalysis above, that is, means across all issues in each domain for GPT estimates and WVS\nscores, respectively.\nThe results revealed a very strong positive correlation between GPT's liberalism estimates and\nGPT's mean country-level estimates in the personal-sexual domain, r(61) = .93, 95% CI [0.89,\n0.96], as well as between liberalism estimates and the WVS country-level mean scores in the\npersonal-sexual domain, r(61) = .84, 95% CI [0.75, 0.90]. This suggests that a\nliberalism-conservative dimension indeed appears to explain GPT's estimates for\npersonal-sexual issues, and also that this dimension is sufficient to capture most of the\nreal-world country variance in this domain of moral opinion. In contrast, there was a very strong\nnegative correlation between GPT's liberalism estimates and GPT's mean country-level\nestimates in the violent-dishonest domain, r(61) = r(61) = - .85, 95% CI [-0.91, -0.77], and no\nsignificant correlation between liberalism estimates and the WVS country-level mean scores in\nthe violent dishonest domain, r(61) = .13, 95% CI [-0.36, 0.12]. This suggests that a\nliberal-conservatism dimension also appears to explain GPT's estimates in the violent-dishonest\ndomain, but that this continuum explains little to no real-world variance in this domain of moral\nopinion. See Figure 6."}, {"title": "4 Discussion", "content": "In this study, we investigated whether GPT-4 could accurately estimate moral opinions across a\nlarge set of geographically, culturally, and economically varied countries. Replicating previous\nfindings by Ramezani and Xu (2023), our first analyses showed that GPT's estimates do\ncorrelate with real-world data, with estimates being significantly more accurate in high-income\nthan in low-income countries. Importantly, GPT estimates and real-world scores were not\nperfectly correlated for any moral issues, assuaging any worries that GPT may be basing its\nestimates on the WVS data. On their own, these results may be interpreted as mainly\nsupporting a Western-centric or English-language bias in the model. However, closer scrutiny\nrevealed a more complicated picture.\nFirst, we found that a single factor could explain almost all variance in GPT's estimates of moral\nopinions, while two factors were needed to explain as much variance in the WVS survey data. In\nother words, GPT's moral worldview is almost entirely one-dimensional, while the actual moral\nlandscape is largely two-dimensional. Second, factor loadings supported dividing issues into two\nmoral domains: personal-sexual and violent-dishonest issues. After dividing issues by moral\ndomain, GPT's estimates were still better in high than low-income countries, suggesting there\nmay indeed be some cultural bias in the model. Yet, there was an even greater difference in\nprediction success between domains: in both high-income and low-income countries, GPT\nperformed well in the personal-sexual domain but very poorly in the violent-dishonest domain.\nThe difference in performance between the two moral domains raises the question of what\ndefines GPT's one-dimensional moral worldview. To explore this issue further, we probed GPT\nfor country-level estimates of liberalism/conservatism for all 63 countries in the WVS dataset.\nThese estimates were nearly perfectly correlated with GPT's public opinion estimates,\nsuggesting that liberalism versus conservatism constitutes the core dimension in GPT's moral\nworldview. While the countries' degree of liberalism seems to predict moral opinions in the\npersonal-sexual domain effectively, its relevance diminishes when applied to the\nviolent-dishonest domain. This observation corresponds with prior research indicating that the\nautonomy-embeddedness dimension explains cultural variance in attitudes toward\npersonal-sexual but not dishonest-illegal moral issues (Vauclair & Fischer, 2011). As Schwartz\n(2004) has noted, his autonomy-embeddedness dimension shares significant conceptual\nsimilarities with other dimensions that differentiate individual and collective concerns, among\nwhich the degree of conservatism/liberalism can be considered.\nIn summary, GPT's moral worldview suffers from a flaw as it flattens the moral landscape onto a\nsingle liberal-conservative dimension. Nonetheless, this dimension proves remarkably effective\nin explaining cultural variance in attitudes toward personal-sexual moral issues."}]}