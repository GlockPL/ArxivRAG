{"title": "Anomaly Prediction: A Novel Approach with Explicit Delay and Horizon", "authors": ["Jiang YOU", "Arben CELA", "Jacob OUANOUNOU", "Ren\u00e9 NATOWICZ", "Patrick SIARRY"], "abstract": "Detecting anomalies in time series data is a critical challenge across various domains. Traditional methods typically focus on identifying anomalies in immediate subsequent steps, often underestimating the significance of temporal dynamics such as delay time and horizons of anomalies, which generally require extensive post-analysis. This paper introduces a novel approach for time series anomaly prediction, incorporating temporal information directly into the prediction results. We propose a new dataset specifically designed to evaluate this approach and conduct comprehensive experiments using several state-of-the-art methods. Our results demonstrate the efficacy of our approach in providing timely and accurate anomaly predictions, setting a new benchmark for future research in this field.", "sections": [{"title": "I. INTRODUCTION", "content": "Time series anomaly detection has a broad application across various domains, reflecting its critical importance and versatility. In finance, it is used to detect fraudulent transactions [1] and unusual market activities [2]. In healthcare, it aids in monitoring patient vital signs and detecting early signs of medical conditions [3]. Industrial applications include predictive maintenance, where detecting anomalies in machine operations can prevent equipment failures [4]. In server reliability engineering, anomaly detection is essential for identifying unexpected server breakdowns [5].\nOver time, methodologies in time series anomaly detection evolved significantly [6]. Initially, the field was dominated by statistical methods and simple machine learning techniques such as ARMA [7], K-Means Clustering [8], Matrix Profile [9] etc. However, with increasing data complexity, sophisticated models like deep learning approaches such as OmniAnomaly [10], TranAD [11], Anomaly Transformer [12] have become mainstream.\nWhile the classical approach of anomaly detection is to identify anomalies as they occur or in the immediate future [13], [14], recent research has been interested in providing alerts with sufficient lead times to enhance detection capabilities [15], [16]. Despite these advances, there are still significant difficulties in predicting the temporal dynamics of anomalies, particularly in predicting the lead time (or delay time) and precise range of predicted anomalies(or horizon), as well as the cumbersomeness of training models.\nRecent critiques have also highlighted issues with current research methodologies, particularly concerning the datasets used. Many datasets do not adequately reflect real-world complexities, leading to an underestimation of deep learning methods' effectiveness [17]. In some cases, simpler models like Autoregressive Moving Average (ARMA) outperform their complex counterparts (LSTM, Transformer), suggesting the need for more complex tasks and datasets for evaluation [18].\nRecognizing these challenges, this paper introduces a novel approach called \"Anomaly Prediction\". Instead of merely predicting the occurrence of an anomaly or its severity, this approach predicts the distribution density of anomaly events over future time intervals, providing clear delay time and horizon information. This enhances the practical utility of anomaly detection and demonstrates deep models' ability to recognize complex patterns in more difficult tasks.\nTo empirically validate our approach, we developed a synthetic dataset tailored to assess predictive models' performance in capturing complex temporal dynamics. We propose using Wasserstein loss to model the temporal dynamics by measuring the density distributions of anomaly events. Additionally, to thoroughly evaluate the performance of models and understand the characters of the dataset, we introduce four additional metrics (Existence, Length, Lead Time, and Dice Score) for comprehensive performance evaluation.\nThrough extensive experiments, we demonstrate that our method provides timely and precise predictions of anomalous events, integrating delay time and forecasting horizon. Our findings suggest that this approach substantially improves predictive models' utility in real-world settings, paving the way for future research in the field.\nWe summarize our contributions as follows:\n\u2022 Introduction of a novel predictive approach for time series anomaly detection incorporating delay time and horizon.\n\u2022 Application of forecastng models and Wasserstein loss to capture the distribution density of anomaly events.\n\u2022 Development of a synthetic dataset and evaluation metrics to rigorously assess models performance.\n\u2022 Empirical validation of concept for our approaches.\nIn conclusion, this study pushes the boundaries of time series anomaly detection with the introduction of \"anomaly prediction,\" a novel approach that integrates delay time and horizon information. Future research will focus on refining these techniques and exploring their applicability in more complex scenarios, thereby expanding the scope and impact of anomaly detection in real-world applications."}, {"title": "II. RELATED WORKS", "content": "In this section, we provide a comprehensive review of anomaly detection models, ranging from traditional methods to contemporary deep learning methods. Next, we delve into the latest developments in time series forecasting methods. In addition, we introduce related tasks that intersect with anomaly detection, such as event prediction, human behavior detection, and root cause analysis. Finally, we present anomaly prediction as an emerging field that combines elements of anomaly detection, time series forecasting, and event prediction."}, {"title": "A. Anomaly Detection", "content": "Anomaly detection techniques can be roughly divided into Forecasting Methods, Reconstruction Methods, Encoding Methods, Distance Methods, Distribution Methods, and Isolation Tree Methods [19]. The key idea of detecting anomaly is identifying the samples far from the majority or different from normal samples based on a distance or a metric.\nForecasting Methods involve creating a model to predict future values based on a current context window. These predicted values are compared to actual observed values to identify anomalies based on significant deviations. Representative algorithms include ARIMA [20] and LSTM-AD [21].\nReconstruction Methods encode subsequences of normal training data into a low-dimensional latent space and then reconstruct them by expanding the latent vectors. Anomalies are detected by comparing the reconstructed subsequences to the original observed values, with discrepancies indicating potential anomalies. Notable examples of reconstruction methods are AutoEncoder (AE) [22], and OmniAnomaly [10].\nEncoding Methods also encode subsequences into a low-dimensional latent space, but unlike reconstruction methods, they compute the anomaly score directly from the latent space representations without attempting to reconstruct the original subsequences. The anomaly scores are derived from the encoded representations, where anomalies are identified based on their divergence from normal patterns in the latent space. This category includes algorithms such as GrammarViz [23] and Series2Graph [24].\nDistance Methods utilize specialized distance metrics to compare points or subsequences within a time series. Anomalous subsequences are expected to have larger distances from clusters of normal subsequences. Examples of algorithm include LOF [25], CBLOF [26], STAMP [27].\nDistribution Methods estimate the data's distribution or fit a distribution model to it, identifying anomalies based on their probability or distance from the calculated distributions. Anomalies are typically found in the extremes or tails of the distributions, making this approach effective for identifying infrequent patterns. Key algorithms in this category are COPOD [28], HBOS [29].\nIsolation Tree Methods construct an ensemble of random trees to partition the samples of a time series. Anomalies are detected based on the number of splits required to isolate a sample, with anomalous samples having shorter paths to the root of the tree [30] [31] [32]."}, {"title": "B. Time Series Forecasting", "content": "In time series forecasting, transformer-based models have significantly evolved to address the complexities of long-range dependencies and computational efficiency. Early models like LogTrans [33] introduced convolutional self-attention to improve the efficiency of the self-attention mechanism, while Informer [34] utilized a ProbSparse self-attention mechanism to achieve O(Llog L) time complexity and memory usage, making it more scalable for long sequences. Pyraformer [35] advanced this further by capturing temporal dependencies in a multi-resolution manner, optimizing both time and space complexity. PatchTST employs PropSparse attention and patches, significantly reducing computation complexity to $O(\\frac{L}{S}log(\\frac{L}{S}))$, where S is the patch size, thereby enhancing the model's efficiency and ability to process long time series.\nUNet-based methods, originally designed for image segmentation, have also been adapted for time series forecasting due to their powerful feature extraction capabilities. U-Net's architecture, with its encoder-decoder structure and skip connections, facilitates the capture and merging of multi-scale information. In the context of time series, models like U-time [36] apply convolutional layers for segmentation tasks, while YFormer [37] integrates transformer blocks at each layer of U-Net for forecasting tasks, effectively utilizing multi-resolution feature maps. Further advancing this field, Kernel U-Net [38] addresses specific challenges in time series forecasting by enhancing both expressiveness and computational efficiency. This model maintains the symmetric, hierarchical U-shaped structure of traditional U-Net but separates the process of partitioning input time series into patches from kernel manipulation, allowing for customized kernel execution, and making it more suitable for diverse and large-scale time series applications."}, {"title": "C. Event Prediction", "content": "In time series event prediction, methods are categorized based on their time granularity into three types: occurrence prediction, discrete-time prediction, and continuous-time prediction [39].\nOccurrence prediction, the most straightforward, focuses on determining whether an event will occur within a future time period, often treated as a binary classification problem. Techniques for this include Support Vector Machines (SVMs) [40], neural networks [41], and decision trees [42]. Additionally, anomaly detection methods like one-class classification and hypothesis testing are used for rare event occurrences, leveraging the identification of deviations from normal samples. Regression-based approaches extend binary prediction to predict event count [43] or scale [44], enhancing the granularity of occurrence predictions.\nDiscrete-time prediction aims to forecast the approximate time slot (e.g., day, week, month) of an event's occurrence. This approach can be direct, where future time is partitioned into discrete values and predicted using regression or ordinal classification methods [45], or indirect, where time series forecasting techniques predict future values, and events are then identified within predictions [46].\nContinuous-time prediction, addressing the limitations of discrete-time methods, involves predicting the exact time of an event using techniques like regression, point processes, or survival analysis [47].\nPoint processes model the conditional intensity function to predict event times accurately, while survival analysis uses hazard functions to estimate event occurrence probabilities over time. These methods provide high-resolution and precise event timing, adapting to complex temporal patterns in time series data [48]."}, {"title": "D. Early recognition of ongoing human actions", "content": "Early recognition of ongoing human actions from video streams is a critical task with broad applications across various domains, including robotics, entertainment, surveillance, and healthcare [49]. The ability to promptly detect and recognize actions as they unfold is essential for enabling real-time decision-making and enhancing operational efficiency in these fields. Recent research [49] has proposed innovative methods utilizing Bidirectional Long Short-Term Memory (BLSTM) networks to predict the temporal initiation of actions with high precision. These methods leverage advanced training techniques such as novel loss functions based on cumulative distribution functions, aiming to minimize prediction errors and improve overall recognition accuracy. By refining the estimation of action start times, these approaches demonstrate considerable enhancements in the performance of early recognition systems, showcasing their potential to advance the state-of-the-art in action detection technologies."}, {"title": "E. Explainable Time Series Anomaly Detection", "content": "Exathlon, a pioneering public benchmark specifically designed for explainable anomaly detection over high-dimensional time series data [50]. Exathlon features real data traces derived from extensive executions of large-scale stream processing tasks on an Apache Spark cluster. They proposed Metrics such as Anomaly Existence, Range Detection, Early Detection, and Exactly-Once Detection for unsupervised anomaly detection at instant. This benchmark enables the development and evaluation of a wide range of anomaly detection and explanation discovery techniques. In their study, the authors demonstrate the practical utility of Exathlon's dataset, evaluation methodology, and data science pipeline design through experiments with three state-of-the-art anomaly detection and explanation methods\nIn this paper, we propose anomaly prediction as an emerging field that combines elements of anomaly detection, time series forecasting, and event prediction. This integrated approach not only identifies anomalies but also predicts their occurrence and assesses their potential impact, providing a comprehensive solution for proactive anomaly management. By leveraging the strengths of each component, anomaly prediction can offer earlier warnings and more accurate insights, enabling more effective responses to potential issues across various domains."}, {"title": "III. METHOD", "content": "In this section, we introduce our anomaly prediction approach, starting with problem formulation, where we define the task as predicting the distribution density of anomalies. We employ the Wasserstein distance (or cumulative sum loss) as a loss function to measure the distribution dissimilarity between actual anomalies and predicted data. To evaluate model performance, we use several metrics: the Existence of anomalies, Densities of anomalies, Lead time, and the Dice Score, which measures the overlap between predicted and actual anomalies. Our approach incorporates deep learning time series forecasting models to capture complex patterns and temporal shifts."}, {"title": "A. Problem Formulation", "content": "1) Anomaly Prediction Task: Consider a multivariate time series dataset represented by the matrix $x \\in R^{N\\times M}$, where N represents the number of sampling times, and M represents the number of features. Let L be the length of the look-back window (memory), so the slice $(x_{t+1,1}, ..., x_{t+L,M})$ (or, for short, $(x_{t+1},..., x_{t+L})$ contains historical information about the system at instant t.\nDefine the trajectory matrix $X_t \\in R^{L\\times M}$ as a historical data segment at instant $t \\in [0, N - L - 1]$. The task is to use the historical data series $(x_{t+1}, ..., x_{t+L})$ of length L to predict the probability of anomalies occurring within the next T time steps.\nThe anomaly prediction problem can be formulated as:\n$(\\hat{y}_{t+L+1},..., \\hat{y}_{t+L+T}) = f(x_{t+1}, ..., x_{t+L})$\nwhere f is a function that predicts the probabilities $Y_{t+L+1} = (y_{t+L+1},..., y_{t+L+T})$ of finding anomalies based on the historical series $(x_{t+1},..., x_{t+L})$. Here, $\\hat{y}_{t+L+i}$ represents the predicted probability of an anomaly at time t + L + i for $i \\in \\{1, ..., T\\}$.\nRemark that classic time series forecasting task takes Mean Absolute Error (MAE) or Mean Square Error (MSE) as loss function. Instead of forecasting the actual value of time series, anomaly prediction predicts the distribution of anomalous events. In this case, classical MAE or MSE loss is inappropriate because the presence and absence of anomaly events with different lead time contradict each other and makes the model collapse. Therefore, We propose using Wasserstein loss, which models anomaly events as distributions over time dimension.\n2) Wasserstein Loss: Wasserstein Loss (Cumulative Sum Loss) measures the distance or similarity of two distributions. It evaluates the overall difference between across the entire future horizon by measuring the distributional differences between predicted and actual values. Technically, this method computes the MAE or MSE of the cumulative sum loss over the time dimension. The Wasserstein loss is defined as:\n$Wasserstein(\\hat{Y}_t, Y_t) = \\frac{2}{T(T+1)} \\sum_{i=1}^{T} \\sum_{j=1}^{i} (\\hat{Y}_{t+j} - Y_{t+j})$\nwhere the cumulative sums of the MAE of predicted values $\\hat{y}$ and the true values y are compared at each time step i within the prediction horizon. This loss function captures both the location and the shape of the predicted distribution relative to the actual distribution. It can approximate a mixture of up to T distribution of anomalies in the prediction horizon."}, {"title": "B. Metrics", "content": "To evaluate the quality of anomaly predictions, we use the following metrics :\n1) Existence of Anomaly : This metric evaluates whether the model correctly predicts the existence of at least one anomaly within the prediction range. It is a binary measure that compares the presence of any anomaly in the predicted range with the ground truth. We define the True Positive (TP), False Positive (FP), False Negative (FN) for each pair of predicted probability segment of anomaly $\\hat{Y}_t$ and labels $Y_t$ as follows:\n$TP(\\hat{Y}_t, Y_t) = \\begin{cases} 1 & \\text{if } Sum(\\hat{Y}_t) > 0 \\text{ and } Sum(Y_t) > 0 \\\\ 0 & \\text{otherwise} \\end{cases}$\n$FP(\\hat{Y}_t, Y_t) = \\begin{cases} 1 & \\text{if } Sum(\\hat{Y}_t) > 0 \\text{ and } Sum(Y_t) = 0 \\\\ 0 & \\text{otherwise} \\end{cases}$\n$FN(\\hat{Y}_t, Y_t) = \\begin{cases} 1 & \\text{if } Sum(\\hat{Y}_t) = 0 \\text{ and } Sum(Y_t) > 0 \\\\ 0 & \\text{otherwise} \\end{cases}$\nwhere $Sum(Y_t) = \\sum_{i=1}^{T} Y_{t+i}$\nThe metric Existence of anomaly that measures the overall performance on the total pairs ($\\hat{Y}$, Y) is defined as:\n$Exist(\\hat{Y}, Y) = \\frac{2\\cdot TP}{2\\cdot TP+FP+FN}$\nwhere TP, FP, and FN are the sum value of all pairs of predicted probability segments of anomaly $\\hat{Y}$ and labels Y over the total timestamps.\nThis metric provides a simple outcome indicating how well the model correctly identified the presence of any anomaly in the prediction interval.\n2) Density of Anomalies: This metric measures the difference in the cumulative densities of predicted anomalies compared to the actual count of anomaly label. It is calculated as:\n$Density(\\hat{Y}_t, Y_t) = 1 - \\frac{1}{T} | \\sum_{i=1}^{T} (\\hat{Y}_{t+i} - Y_{t+i})|$\nThis metric evaluates the discrepancy in the cumulative density of predicted anomalies versus the count of actual anomaly labels. This metric ranges from 0 to 1, where 1 indicates that the size of predicted anomaly is exact, and values closer to 0 indicate over-predicting or under-predicting the size of anomaly events.\n3) Lead Time: Lead time measures how close the first predicted anomaly is to the first observed ground truth anomaly. It is calculated as:\n$LeadTime(\\hat{Y}_t, Y_t) = 1 - \\frac{1}{T} |i_{\\hat{y}} - i_y|$\nwhere $i_y = min\\{i | Y_{t+i} = 1\\}$ is the index of the first observed ground truth anomaly, $i_{\\hat{y}} = min\\{i | \\hat{y}_{t+i} > s\\}$ is the index of the first predicted anomaly probabilities that are greater than user-defined threshold s.\nThis metric ranges from 0 to 1, where 1 indicates that the first predicted anomaly exactly matches the timing of the first ground truth anomaly, and values closer to 0 indicate a larger discrepancy between the predicted and actual timing.\n4) Dice Score: The Dice Score, also known as the F1 Score for sets, measures the overlap between the predicted anomalies and the ground truth anomalies. It is defined as:\n$DiceScore(\\hat{Y}_t, Y_t) = \\frac{2|\\hat{Y} \\cap Y|}{|\\hat{Y}|+|Y|}$\nThis metric ranges from 0 to 1, where 1 indicates perfect coverness between the predicted anomalies $\\hat{y}$ and the ground truth y, and 0 indicates no overlap.\nUsing these metrics, we can comprehensively evaluate the performance of the anomaly prediction model, considering both the accuracy of the predicted anomaly intervals and the timeliness of the predictions."}, {"title": "C. Models", "content": "In this section, we describe the models employed in our experiments for anomaly detection in time series data. Our selection includes some of the most recent and fondamental techniques: FCN, PatchTST, Kernel U-Net. These models were chosen for their simplicity and demonstrated performance in the field of time series forecasting.\nFully Connected Network Fully Connected Network (FCN) serves as a baseline model for anomaly prediction in time series data. This model applies multiple linear layers with ReLU activation functions to automatically extract temporal patterns. Due to its simplicity and effectiveness, we use it as a baseline to compare the performance of more complex models in time series anomaly prediction.\nPatchTST (Patch Time Series Transformer) [51] is a novel model designed to capture long-term dependencies in time series data through the use of patches, analogous to those used in computer vision transformers. The core idea of PatchTST is to segment the time series into patches and process them using transformer encoders. This approach enables the model to efficiently learn and represent temporal patterns over extended periods. PatchTST leverages self-attention mechanisms to weigh the importance of different time steps, making it particularly effective in identifying anomalies that have complex temporal dependencies.\nKernel U-Net [38] is an extension of the traditional U-Net architecture, specifically designed to address the challenges in time series forecasting. Traditional Transformer-based U-Net models, while successful in medical image segmentation, often struggle with expressiveness and computational efficiency in time series applications. Kernel U-Net overcomes these limitations through a symmetric, hierarchical U-shaped neural network structure. Its encoder compresses input time series into latent vectors, which are then expanded into output series by the symmetric decoder. By separating the process of partitioning input time series into patches from kernel manipulation, Kernel U-Net allows for customized kernel execution, enhancing flexibility. This approach not only adapts to specific datasets but also improves computational efficiency, reducing the complexity of the Transformer layer to linear."}, {"title": "IV. DATASET", "content": "Real-world datasets for time series anomaly prediction can be scarce, incomplete, or lack sufficient anomalies to train and evaluate models effectively. This limitation necessitates the creation of synthetic datasets that can simulate various scenarios of anomalies. A synthetic dataset allows researchers to control the parameters and conditions under which anomalies occur, providing a robust platform for benchmarking and validating anomaly prediction models. In this section, we describe a synthetic dataset, a private dataset designed for anomaly prediction, and 3 datasets from anomaly detection.\nThe synthetic datasets are designed to evaluate and benchmark anomaly prediction algorithms. Datasets 1-5 are univariate, while datasets 6-10 are multivariate. The time series patterns include sinusoidal and cosine waves, with configurations being either fixed or mixed. Both the brewing time and anomaly labels are either fixed or follow a Gaussian distribution. The difficulty of the datasets increases progressively.\n1) Synthetic Time Series Anomaly: A synthetic anomaly in a time series is defined by a time series pattern, a segment that includes an anomaly pattern, brewing time, and a sequence of positive labels at the observation period . The key components are:\n\u2022 Time Series Pattern: A series of points generated by sine or cosine function. We use single fixed sine function (Fixed), mixed sine function of different frequencies (Mixed), multivariate series composed of sine or cosine functions (Mixed).\n\u2022 Anomaly Pattern: A pattern that the model can detect. It is usually not observable by human experts but contains decisive patterns indicative of an anomaly in the future. We use a fixed pattern composed of a segment of gaussian random points and a increasing line (Fixed).\n\u2022 Brewing Time: The interval between the end of the hidden anomaly pattern and the observable anomalies annotation. We use a fixed number(Fixed) or a random number following gaussian distribution (Gaussian).\n\u2022 Observation: A sequence of annotation of anomaly after the brewing time. It is typically visually evident to human experts, prompting them to raise an alert. The anomaly event is labeled as a positive example during the observation. We use a fixed number (Fixed) or a random number following gaussian distribution (Gaussian) for the size of anomaly labels.\n2) Signal-to-Noise Ratio (SNR): SNR is crucial in communication and can also be applied to anomaly detection. In this context, SNR is the user-defined ratio of the weighted sum of the inserted anomaly pattern and original time series. SNR defines the separability of anomaly and normal segments and quantifies the information in the anomaly pattern.\nWe note the Signal as an important anomaly pattern detected by a model. We note the Noise as an irrelevant pattern received in a model. We note Signal-to-Noise Ratio (SNR) as the fraction of amplitude of anomaly pattern to that of irrelevant pattern. A higher SNR indicates that the signal is evident, while a lower SNR means the signal is not evident."}, {"title": "B. Anomaly Detection Dataset", "content": "1) SMD: The Server Machine Dataset (SMD) [10] is a widely utilized dataset for anomaly detection in time series. It contains data collected from 28 servers and includes a mix of normal and abnormal behaviors. The dataset is typically used to evaluate the performance of unsupervised anomaly detection algorithms in industrial settings. We use the test set of SMD for evaluating our proposed supervised anomaly prediction task.\n2) SBDA: The server breakdown anomaly (SBDA) dataset is a private anonymized dataset. It is composed of 16 metrics, such as CPU, memory usage, and other system-related measurements, and 36 label columns annotated by experts. It contains 10 data instances collected over six months, capturing normal operations and server failures. This dataset is instrumental for evaluating and developing anomaly detection algorithms to identify server breakdowns. Compared with the SMD dataset, the SBDA dataset contains not only physical metrics but also additional expert knowledge through annotations.\n3) MSL: The Mars Science Laboratory (MSL) dataset originates from the telemetry data of NASA's Curiosity rover. It includes multiple telemetry channels recorded during the rover's mission on Mars. This dataset is often used in research to develop and test algorithms for anomaly detection in space mission data. We only use the test set of MSL for evaluation.\n4) SMAP: The Soil Moisture Active Passive (SMAP) dataset is derived from the NASA satellite mission aimed at measuring soil moisture levels. It encompasses a variety of telemetry channels that capture the satellite's operational data. Researchers utilize this dataset to benchmark and improve anomaly detection methods for satellite telemetry. We only use the test set of SMAP for evaluation."}, {"title": "V. EXPERIMENTS AND RESULTS", "content": "In this section, we present the experiments conducted to evaluate the performance of anomaly prediction models using both synthetic and real-world datasets. The datasets are split into training, validation, and test sets with a ratio of 0.7, 0.1, and 0.2, respectively, with anomalies distributed across each subset in the same ratio. For all datasets, the input length is set to 50, while the output length is 20 for the synthetic dataset and 50 for the real-world datasets. All experiments use a learning rate of 0.0005 and a hidden dimension of 128. For the models PatchTST and K-U-Net, a patch size of 5 is employed, with K-U-Net utilizing an MLP kernel, and both models consisting of a single layer. The training is conducted for up to 100 epochs, and patience for early stopping is set to 10 epochs. The threshold s is empirically set to be 0.1.\nThe experimental results demonstrated the high accuracy of the models in detecting the presence of anomalies across different synthetic datasets . FCN and K-U-Net correctly identified anomalies in over 90% of the test cases in a univariate setting, as indicated by the existence of anomaly metric. However, PatchTST quickly overfitted to particular cases, achieving only a 75% F1-score. We measured the density sum, lead time, and Dice score in cases where the models successfully predicted the existence of an anomaly (true positives). The density sum showed that the models' predictions closely matched the total anomalies expected in the future horizon, with all models reaching 0.95. The lead time metric indicated that the models' predictions were closely aligned with the actual occurrences of anomalies, with an average lead time score of 0.85, suggesting effective prediction with minimal delay. The Dice score averaged below 0.5 due to the challenges posed by temporal dynamics, reflecting that the overlap between predicted and actual anomalies varied depending on the distribution of anomaly labels and brewing time. Results for the existence of anomaly on real-world datasets such as SBDA, SMD, SMAP, and MSL were generally lower than 0.5.\nOverall, these results provide proof of concept for our anomaly prediction approach. The use of synthetic datasets allowed us to rigorously test the models under controlled conditions, ensuring their reliability before applying them to real-world applications. The results on real-world datasets initially validate the concept but also reveal existing difficulties in achieving high accuracy."}, {"title": "VI. CONCLUSION", "content": "In this work, we introduce anomaly prediction, a novel approach that integrates delay and horizon into classic anomaly detection, providing probability densities for identifying potential anomalies in a future horizon. By leveraging state-of-the-art time series forecasting techniques and anomaly detection, we validate our approach on a synthetic dataset specifically designed for benchmarking anomaly prediction models."}]}