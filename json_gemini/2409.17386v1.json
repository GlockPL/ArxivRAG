{"title": "Beyond Redundancy: Information-aware\nUnsupervised Multiplex Graph Structure Learning", "authors": ["Zhixiang Shen", "Shuo Wang", "Zhao Kang"], "abstract": "Unsupervised Multiplex Graph Learning (UMGL) aims to learn node representa-\ntions on various edge types without manual labeling. However, existing research\noverlooks a key factor: the reliability of the graph structure. Real-world data often\nexhibit a complex nature and contain abundant task-irrelevant noise, severely com-\npromising UMGL's performance. Moreover, existing methods primarily rely on\ncontrastive learning to maximize mutual information across different graphs, limit-\ning them to multiplex graph redundant scenarios and failing to capture view-unique\ntask-relevant information. In this paper, we focus on a more realistic and challeng-\ning task: to unsupervisedly learn a fused graph from multiple graphs that preserve\nsufficient task-relevant information while removing task-irrelevant noise. Specif-\nically, our proposed Information-aware Unsupervised Multiplex Graph Fusion\nframework (InfoMGF) uses graph structure refinement to eliminate irrelevant noise\nand simultaneously maximizes view-shared and view-unique task-relevant informa-\ntion, thereby tackling the frontier of non-redundant multiplex graph. Theoretical\nanalyses further guarantee the effectiveness of InfoMGF. Comprehensive exper-\niments against various baselines on different downstream tasks demonstrate its\nsuperior performance and robustness. Surprisingly, our unsupervised method even\nbeats the sophisticated supervised approaches. The source code and datasets are\navailable at https://github.com/zxlearningdeep/InfoMGF.", "sections": [{"title": "Introduction", "content": "Multiplex graph (multiple graph layers span across a common set of nodes), as a special type\nof heterogeneous graph, provides richer information and better modeling capabilities, leading to\nchallenges in learning graph representation [1]. Recently, unsupervised multiplex graph learning\n(UMGL) has attracted significant attention due to its exploitation of more detailed information from\ndiverse sources [2, 3], using graph neural networks (GNNs) [4] and self-supervised techniques [5].\nUMGL has become a powerful tool in numerous real-world applications [6, 7], e.g., social network\nmining and biological network analysis, where multiple relationship types exist or various interaction\ntypes occur.\nDespite the significant progress made by UMGL, a substantial gap in understanding how to take\nadvantage of the richness of the multiplex view is still left. In particular, a fundamental issue is\nlargely overlooked: the reliability of graph structure. Typically, the messaging-passing mechanism in\nGNNs assumes the reliability of the graph structure, implying that the connected nodes tend to have\nsimilar labels. All UMGL methods are graph-fixed, assuming that the original structure is sufficiently\nreliable for learning [3, 8-10]. Unfortunately, there has been evidence that practical graph structures"}, {"title": "Preliminaries", "content": "Notation. The multiplex graph is represented by G = {G1, ..., Gv}, where Gv = {Av, X} is the\nv-th graph. $A_v \\in {0,1}^{N \\times N}$ is the corresponding adjacency matrix and $X \\in \\mathbb{R}^{N \\times d_f}$ is the shared\nfeature matrix across all graphs. $X_i \\in \\mathbb{R}^{d_f}$ is the i-th row of X, representing the feature vector of\nnode i. N is the number of nodes and $D_v$ is a diagonal matrix denoting the degree matrix of $A_v$. Y\nis label information. For convenience, we use \u201cview\u201d to refer to each graph in the multiplex graph.\nMultiplex graph non-redundancy. Task-relevant information exists not only in the shared in-\nformation between graphs but also potentially within the unique information of certain graphs.\nFollowing the non-redundancy principle [17], we provide the formal definition of Multiplex Graph\nNon-redundancy:\nDefinition 1. Gi is considered non-redundant with Gj for Y if and only if there exists $\\epsilon > 0$ such\nthat the conditional mutual information I(Gi; Y | Gj) > $\\epsilon$ or I(Gj; Y | Gi) > $\\epsilon$.\nGraph structure learning. Existing GSL methods primarily focus on a single graph. Their pipeline\ncan be summarized as a two-stage framework [16]: a Graph Learner takes in the original graph\nG = {A, X} to generate a refined graph G\u00b3 = {A, X} with a new structure; a Graph Encoder uses\nthe refined graph as input to obtain node representations. Note that node features generally do not\nchange in GSL, only the graph structure is optimized. Related work is in Appendix B."}, {"title": "Methodology", "content": "As illustrated in Figure 2, our proposed InfoMGF consists of two modules: the Graph Structure\nRefinement module and the Task-Relevant Information Maximization module."}, {"title": "Graph Structure Refinement", "content": "We first use a graph learner to generate each view's refined graph G = {A, X}. To retain\nnode features and structure information simultaneously, we apply the widely used Simple Graph\nConvolution (SGC) [19] to perform aggregation in each view, resulting in view-specific node features\nX. A view-specific two-layer attentive network is employed to model the varying contributions of\ndifferent features to structure learning:\n$X^\\text{'} = (\\tilde{D}_v^{-1/2}\\tilde{A}_v \\tilde{D}_v^{-1/2})^r X,$\n$H^0 = \\sigma(X^\\text{'} \\odot W_1) \\odot W_2$\n(1)\nwhere $\\tilde{D}_v = D_v + I$ and $\\tilde{A}_v = A_v + I$. r represents the order of graph aggregation. $\\sigma(\\cdot)$ is the\nnon-linear activation function and $\\odot$ denotes the Hadamard product. All rows of $W_1$ are identical,\nrepresenting a learnable attention vector shared by all nodes. This strategy enables us to acquire\nview-specific features before training, thereby circumventing the time-consuming graph convolution\noperations typically required by GNN-based graph learners during training, which significantly boosts\nour model's scalability.\nLike existing GSL methods [16, 20], we apply post-processing techniques to ensure that the adjacency\nmatrix $A_s$ satisfies properties such as sparsity, non-negativity, symmetry, and normalization. Specif-\nically, we use Hu to construct the similarity matrix and then sparsify it using k-nearest neighbors\n(kNN). For large-scale graphs, we utilize locality-sensitive approximation during kNN sparsification\nto reduce time complexity [21]. Afterward, operations including Symmetrization, Activation, and\nNormalization are used sequentially to generate the final A. Following the refinement of each view,\nwe employ a shared Graph Convolutional Network (GCN) [22] as the graph encoder to obtain the\nnode representations $Z^v \\in \\mathbb{R}^{N \\times d}$ of each view, computed by $Z^v = \\text{GCN}(A, X)$."}, {"title": "Maximizing Shared Task-Relevant Information", "content": "G should contain not only view-shared but also view-unique task-relevant information. Following\nstandard contrastive learning [23, 24], for each pair of distinct views (e.g., i and j), our approach seeks\nto maximize the mutual information 0.5I(G; Gj) + 0.5I(G; Gi) to capture shared task-relevant\ninformation between views. Essentially, the maximization objective can be transformed to a tractable\nlower bound I(G; G) [25, 26]. Considering the addition of mutual information for each pair, the\nloss term for minimization can be expressed as follows:\n$L_s = -\\frac{2}{V(V - 1)} \\sum_{i=1}^{V} \\sum_{j=i+1}^{V} I(\\mathcal{G}_i; \\mathcal{G}_j)$ (2)"}, {"title": "Maximizing Unique Task-Relevant Information", "content": "Maximizing view-unique task-relevant information can be rigorously expressed as maximizing\n$I(G_i;Y| \\bigcup_{j\\neq i} G_j)$. Then, we relax the optimization objective to the total task-relevant information\nwithin the view, I(G; Y). This decision is based on the following considerations: on the one hand,\ndeliberately excluding shared task-relevant information is unnecessary and would complicate the\noptimization process. On the other hand, repeated emphasis on shared task-relevant information\nencourages the model to focus more on it in the early training stage.\nThe unsupervised nature of our task dictates that we cannot directly optimize I(G;Y) using\nlabel information. Some typical graph learning methods often reconstruct the graph structure\nto preserve the maximum amount of information from the original data [27-29]. In the context of\nour task, this reconstruction-based optimization objective is equivalent to maximizing the mutual\ninformation with the original graph structure [30, 31], i.e., I(G; Gi). However, such methods have\nsignificant drawbacks: they retain task-irrelevant information from the original data, and the graph\nreconstruction also entails high complexity. In contrast, we leverage graph augmentation to reduce\ntask-irrelevant information and retain task-relevant information without accessing Y. Following the\noptimal augmentation assumption [17, 32], we define optimal graph augmentation as:\nDefinition 2. G' is an optimal augmented graph of Gi if and only if I(G'; Gi) = I(Y; Gi), implying\nthat the only information shared between Gi and G'; is task-relevant without task-irrelevant noise.\nTheorem 1. If G' is the optimal augmented graph of Gi, then I(G; G') = I(G;Y) holds."}, {"title": "Theorem 2.", "content": "The maximization of I(G; G') yields a discernible reduction in the task-irrelevant\ninformation relative to the maximization of I(G; Gi).\nTheorem 1 theoretically guarantees that maximizing I(G; G) would provide clean and sufficient\ntask-relevant guidance for learning G. Theorem 2 demonstrates the superiority of our optimization\nobjective over typical methods in removing task-irrelevant information. Therefore, given G' =\n{A, X'} for each view, where A and X' denote the augmented adjacency matrix and node features,\nrespectively, the loss term Lu is defined as:\n$L_u = -\\frac{1}{V} \\sum_{i=1}^{V} I(\\mathcal{G};\\mathcal{G}_i^\\prime)$ (3)\nThe key to the above objective lies in ensuring that G satisfies the optimal graph augmentation.\nHowever, given the absence of label information, achieving truly optimal augmentation is not feasible;\ninstead, we can only rely on heuristic techniques to simulate it. Consistent with most existing graph\naugmentations, we believe that task-relevant information in graph data exists in both structure and\nfeature, necessitating augmentation in both aspects. We use random masking, a simple yet effective\nmethod, to perform feature augmentation. For graph structure, we propose two versions: random\nedge dropping and learnable augmentation through a graph generator.\nRandom feature masking. For node features, we randomly select a fraction of feature dimensions\nand mask them with zeros. Formally, we sample a random vector m \u2208 {0,1}df where each dimension\nis drawn from a Bernoulli distribution independently, i.e., mi ~ Bern(1 \u2013 p). Then, the augmented\nnode features X' is computed by X' = [X1 \u00a9 m; X2 \u2299 \u33a1; ...; XN \u2299m].\nRandom edge dropping (InfoMGF-RA). For a given Av, a masking matrix M \u2208 {0,1}N\u00d7N is\nrandomly generated, where each element Mij is sampled from a Bernoulli distribution. Afterward,\nthe augmented adjacency matrix can be computed as A = A\u2082 \u041c.\nLearnable generative augmentation (InfoMGF-LA). Random edge dropping may lack reliability\nand interpretability. A low dropping probability might not suffice to eliminate task-irrelevant infor-\nmation, while excessive deletions could compromise task-relevant information. Therefore, we opt to\nuse a learnable graph augmentation generator. To avoid interference from inappropriate structure\ninformation, we compute personalized sampling probabilities for existing edges in each view by\nemploying a Multilayer Perceptron (MLP) in the node features. To ensure the differentiability of\nthe sampling operation for end-to-end training, we introduce the Gumbel-Max reparametrization\ntrick [33, 34] to transform the discrete binary (0-1) distribution of edge weights into a continuous\ndistribution. Specifically, for each edge ei,j in view v, its edge weight wij in the corresponding\naugmented view is computed as follows:\n$\\theta_{ij}^v = MLP ([WX_i; WX_j]), w_{ij}^v = \\text{Sigmoid} ((\\text{log} \\delta - \\text{log} (1 - \\delta) + \\theta_{ij}^v) / \\tau)$ (4)\nwhere [;] denotes the concatenation operation and $\\delta \\sim \\text{Uniform}(0, 1)$ is the sampled Gumbel\nrandom variate. We can control the temperature hyper-parameter 7 approaching 0 to make wij\ntend towards a binary distribution. For an effective augmented graph generator, it should eliminate\ntask-irrelevant noise while retaining task-relevant information. Therefore, we design a suitable loss\nfunction for augmented graph training:\n$L_{gen} = \\frac{1}{\\mathcal{N}V} \\sum_{i=1}^V \\sum_{j=1}^\\mathcal{N} (1 - \\frac{(X^v)^\\top \\hat{X^v}}{|\\hat{X^v}\\| ||X^v||}) + \\lambda * \\frac{1}{V}\\sum_{i=1}^V I(\\mathcal{G}^\\prime;\\mathcal{G}_i)$ (5)\nwhere A is a positive hyper-parameter. The first term reconstructs view-specific features using\nthe cosine error, guaranteeing that the augmented views preserve crucial task-relevant information\nwhile having lower complexity compared to reconstructing the entire graph structure. The recon-\nstructed features $\\hat{X}^v$ are obtained using an MLP-based Decoder on the node representations $Z^v$\nof the augmented view. The second term minimizes I (G; G\u2081) to regularize the augmented views\nsimultaneously, ensuring that the augmented graphs would provide only task-relevant information as\nguidance with less task-irrelevant noise when optimizing the refined graph G through Eq.(3). Note\nthat for InfoMGF-LA, we adopt an iterative optimization strategy to update G and G alternatively,\nas described in Section 3.4."}, {"title": "Multiplex Graph Fusion", "content": "The refined graph retains task-relevant information from each view while eliminating task-irrelevant\nnoise. Afterward, we learn a fused graph that encapsulates sufficient task-relevant information from\nall views. Consistent with the approach in Section 3.1, we leverage a scalable attention mechanism as\nthe fused graph learner:\n$H = \\sigma([X; X^1; X^2;\\dots; X^V] \\odot W^1) \\odot W^2, L_f = -\\frac{1}{V}\\sum_{i=1}^V I(\\mathcal{G}; \\mathcal{G}^s_i)$ (6)\nwhere the node features are concatenated with all view-specific features as input. The same post-\nprocessing techniques are sequentially applied to generate the fused graph Gs = {A, X}. The\nnode representations Z of the fused graph are also obtained through the same GCN. We maximize\nthe mutual information between the fused graph and each refined graph to incorporate task-relevant\ninformation from all views, denoted as loss Lf. The total loss L of our model can be expressed as the\nsum of three terms: L = Ls + Lu + Lf.\nTheorem 3. The learned fused graph Gs contains more task-relevant information than the refined\ngraph G from any single view. Formally, we have:\n$I(G^s; Y) > \\text{max} I(G^v; Y)$ (7)\nTheorem 3 theoretically proves that the fused graph Gs can incorporate more task-relevant information\nthan considering each view individually, thus ensuring the effectiveness of multiplex graph fusion.\nOptimization. Note that all the loss terms require calculating mutual information. However, directly\ncomputing mutual information between two graphs is impractical due to the complexity of graph-\nstructured data. Since we focus on node-level tasks, we assume the optimized graph should guarantee\nthat each node's neighborhood substructure contains sufficient task-relevant information. Therefore,\nthis requirement can be transferred into mutual information between node representations [36], which\ncan be easily computed using a sample-based differentiable lower/upper bound. For any view i and j,\nthe lower bound Ib and upper bound Iub of the mutual information $I(Z^i; Z^j)$ are [17]:\n$I_b(Z^i; Z^j) = E_{z^i,z^{j+}~p(z^i,z^{j+}) } [\\text{log}\\frac{e^{f(z^i,z^{j+})}}{\\sum_{n=1}^N e^{f(z^i,z_n^j)}}]$ (8)\n$I_{ub}[Z^i; Z^j] = E_{z^i,z^{j+}~p(z^i,z^{j+}) } [f^*(z^i, z^{j+})] - E_{z^i~p(z^i)} [f^*(z, z)]$ (9)\nwhere f(\u00b7, \u00b7) is a score critic approximated by a neural network and $f^*(\u00b7, \u00b7)$ is the optimal critic from\nItu plugged into the Iub objective. p(zi, zi) denotes the joint distribution of node representations\nfrom views i and j, while p(z\u00b2) denotes the marginal distribution. z\u00b2 and zi+ are mutually positive\nsamples, representing the representations of the same node in views i and j respectively.\nTo avoid too many extra parameters, the function f (zi, zi) is implemented using non-linear projection\nand cosine similarity. Each term in the total loss L maximizes mutual information, so we use the\nlower bound estimator for the calculation. In contrast, we use the upper bound estimator for the\ngenerator loss Lgen in InfoMGF-LA, which minimizes mutual information. These two losses can be\nexpressed as follows:\n$\\mathcal{L} = -\\frac{2}{V(V-1)} \\sum_{i=1}^V \\sum_{j=i+1} I_b(\\mathcal{Z}^i; \\mathcal{Z}^j) - \\frac{1}{V} \\sum_{i=1}^V I_b(\\mathcal{Z}; \\mathcal{Z}^i) - \\frac{1}{V} \\sum_{i=1}^V I_b(\\mathcal{Z}; \\mathcal{Z}^i)$ (10)"}, {"title": "Finally,", "content": "we provide the InfoMGF-LA algorithm in Appendix C.1. In Step 1 of each epoch, we keep\nthe augmented graph fixed and optimize both the refined graphs and the fused graph using the total\nloss L, updating the parameters of Graph Learners and GCN. In Step 2, we keep the refined graphs\nfixed and optimize each augmented graph using Lgen, updating the parameters of the Augmented\nGraph Generator and Decoder. After training, Gs and Z are used for downstream tasks."}, {"title": "Experiments", "content": "In this section, our aim is to answer three research questions: RQ1: How effective is InfoMGF for\ndifferent downstream tasks in unsupervised settings? RQ2: Does InfoMGF outperform baselines\nof various types under different adversarial attacks? RQ3: How do the main modules influence the\nperformance of InfoMGF?"}, {"title": "Experimental Setups", "content": "Downstream tasks. We evaluate the learned graph on node clustering and node classification tasks.\nFor node clustering, following [8], we apply the K-means algorithm on the node representations Z of\nGs and use the following four metrics: Accuracy (ACC), Normalized Mutual Information (NMI), F1\nScore (F1), and Adjusted Rand Index (ARI). For node classification, following the graph structure\nlearning settings in [16], we train a new GCN on G\u00ba for evaluation and use the following two metrics:\nMacro-F1 and Micro-F1.\nDatasets. We conduct experiments on four real-world benchmark multiplex graph datasets, which\nconsist of two citation networks (i.e., ACM [18] and DBLP [18]), one review network Yelp [37] and\na large-scale citation network MAG [38]. Details of datasets are shown in Appendix E.1.\nBaselines. For node clustering, we compare InfoMGF with two single-graph methods (i.e., VGAE\n[27] and DGI [39]) and seven multiplex graph methods (i.e., O2MAC [28], MvAGC [40], MCGC\n[41], HDMI [8], MGDCR [9], DMG [3], and BTGF [10]). All the baselines are unsupervised\nclustering methods. For a fair comparison, we conduct single-graph methods separately for each\ngraph and present the best results.\nFor node classification, we compare InfoMGF with baselines of various types: three supervised\nstructure-fixed GNNs (i.e., GCN [22], GAT [42] and HAN [43]), six supervised GSL methods\n(i.e., LDS [44], GRCN [45], IDGL [46], ProGNN [11], GEN [47] and NodeFormer [48]), three\nunsupervised GSL methods (i.e., SUBLIME [20], STABLE [49] and GSR [50]), and three structure-\nfixed UMGL methods (i.e., HDMI [8], DMG [3] and BTGF [10]). GCN, GAT, and all GSL methods\nare single-graph approaches. For unsupervised GSL methods, following [20], we train a new GCN\non the learned graph for node classification. For UMGL methods, following [8], we train a linear\nclassifier on the learned representations. Implementation details can be found in Appendix E.2."}, {"title": "Effectiveness Analysis (RQ1)", "content": "Table 1 presents the results of node clustering. Firstly, multiplex graph clustering methods outperform\nsingle graph methods overall, demonstrating the advantages of leveraging information from multiple\nsources. Secondly, compared to other multiplex graph methods, both versions of our approach surpass\nexisting state-of-the-art methods. This underscores the efficacy of our proposed graph structure\nlearning, which eliminates task-irrelevant noise and extracts task-relevant information from all graphs,\nto serve downstream tasks better. Finally, InfoMGF-LA achieves notably superior results, owing to\nthe exceptional capability of the learnable generative graph augmentation in capturing view-unique\ntask-relevant information."}, {"title": "Conclusion and Limitation", "content": "This paper delves into the unsupervised graph structure learning within multiplex graphs for the\nfirst time. The proposed InfoMGF refines the graph structure to eliminate task-irrelevant noise,\nwhile simultaneously maximizing both the shared and unique task-relevant information across\ndifferent graphs. The fused graph applied to downstream tasks is optimized to incorporate clean\nand comprehensive task-relevant information from all graphs. Theoretical analyses and extensive\nexperiments ensure the effectiveness of InfoMGF. A limitation of our research lies in its focus\nsolely on the pure unsupervised scenario. In some real-world scenarios where partial node labels\nare available, label information can be used to learn a better structure of multiplex graphs. Such\nsupervised or semi-supervised problems are left for future exploration."}, {"title": "Notations", "content": ""}, {"title": "Related Work", "content": "Unsupervised Multiplex Graph Learning (UMGL). Unlike supervised methods such as HAN [43]\nand SSAMN [51] which rely on label information, UMGL tackles unsupervised tasks in multiplex\ngraphs by using node features and graph structures [52]. Early UMGL methods such as MvAGC [40]\nand MCGC [41] combine graph filtering with unsupervised techniques such as spectral and subspace\nclustering to uncover underlying patterns in complex networks. With the rise of deep representation\nlearning [53], UMGL has embraced a new paradigm: Unsupervised learning of low-dimensional\nnode representations using graph neural networks (GNN) [4] and self-supervised techniques [5]\nfor downstream tasks such as node classification, node clustering, and similarity search. O2MAC\n[28] pioneered the use of GNNs in UMGL, selecting the most informative graph and reconstructing\nall graph structures to capture shared information. DMGI [2] and HDMI [8] maximize mutual\ninformation between local and global contexts, then fuse representations from different relations.\nMGCCN [54], MGDCR [9], and BTGF [10] employ various contrastive losses to align representations\nof diverse relations and prevent dimension collapse. CoCoMG [55] and DMG [3] capture complete\ninformation by learning consistency and complementarity between graphs. Despite these advances, a\ncritical factor that limits the performance of UMGL is overlooked: the reliability of graph structures,\nwhich is the focus of our research.\nGraph Structure Learning (GSL). With the advancement of graph neural networks, instead of\ndesigning complex neural architectures as model-centric approaches, some data-centric research\nhas focused on the graph data itself [56], with graph structure learning (GSL) gaining widespread\nattention for studying the reliability of graph structures. GSL, based on empirical analysis of graph\ndata, recognizes that real-world graph structures are often unreliable, thus opting to learn new\nstructures. GSLB [16] summarizes the general framework of graph structure learning: a Graph\nLearner takes in the original graph G = {A, X} and generates a refined graph G\u00b3 = {A\u00b3, X}; then,\na Graph Encoder uses the refined graph to obtain node representations or perform class prediction.\nConsequently, GSL can be broadly categorized into supervised and unsupervised methods based on\nwhether label information is utilized to learn the new structure. For supervised GSL, probabilistic\nmodels like LDS [44] and GEN [47] are employed to generate graph structures; GRCN [45], IDGL\n46], and NodeFormer [48] calculate node similarities through metric learning or scalable attention"}, {"title": "Algorithm and Methodology Details", "content": ""}]}