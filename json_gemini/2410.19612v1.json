{"title": "Shared Control with Black Box Agents using Oracle Queries", "authors": ["Inbal Avraham", "Reuth Mirsky"], "abstract": "Shared control problems involve a robot learning to collaborate with a human. When learning a shared control policy, short communication between the agents can often significantly reduce running times and improve the system's accuracy. We extend the shared control problem to include the ability to directly query a cooperating agent. We consider two types of potential responses to a query, namely oracles: one that can provide the learner with the best action they should take, even when that action might be myopically wrong, and one with a bounded knowledge limited to its part of the system. Given this additional in-formation channel, this work further presents three heuristics for choosing when to query: reinforcement learning-based, utility-based, and entropy-based. These heuristics aim to reduce a system's overall learning cost. Empirical results on two environments show the benefits of querying to learn a better control policy and the tradeoffs between the proposed heuristics.", "sections": [{"title": "Introduction", "content": "Many modern systems require a human and a robotic system to work jointly in a coordinated manner. Surgery and service robots [1, 2], semi-autonomous vehicles [3, 4], and brain-computer interfaces [5] all involve combining the actions instructed by a human and a robot to form a shared control system. A shared control, according to Abbink et al. [6], is a system where \u201cHuman(s) and robot(s) are interacting congruently in a perception-action cycle to perform a dynamic task that either of them could execute individually under ideal circumstances.\" A key challenge in designing such a system is that the policy of the human agent is hidden from the artificial agent. The human's hidden policy can be viewed as a black box. However, existing solutions often assume learners can only interact with the black box via execution [7, 8]. In many of the mentioned applications, the black box is a cooperative agent, so a simple question can significantly improve the learning speed and accuracy of the shared system. This work aims to study the use of queries to improve learning in a shared control system. This goal is achieved by proposing a new framework for shared control as visualized in Figure 1. The framework comprises two systems: a black box (representing the human operator) and a control system (representing the robot).\nIn the proposed framework, the control can use the assistance of an oracle, which will restrict its potential action space. With the help of such an oracle, learning an efficient policy is expected to be easier, which in turn will minimize the number of failed operations or interactions in the shared system. In this work, we use two oracle types to demonstrate that this expectation is met when the oracle has full knowledge of the shared system, but in other cases, its advice can actually hinder the system's performance. Once queries become part of the robot's optional learning process, a key challenge becomes reasoning about when to query the oracle. This paper presents three heuristics that are designed to increase the accuracy of the learned control policy and to minimize the number of queries used during training and execution.\nThe contributions of this work are thus threefold: (1) A formal definition of the shared control problem with queries; (2) An introduction of two oracle types; and (3) Three heuristics for querying. These contributions are evaluated on two domains: the first is a set of carefully curated shared"}, {"title": "Related Work", "content": "Given a shared control system, a key challenge is to design or learn a control that can work with the black box agent to maximize the return of the shared execution. Dragan and Srinivasa [7] proposed to view the shared control problem as an inverse reinforcement learning (IRL) problem, in which the task is to elicit the perceived reward of humans from their joint interactions with the control. This model was recently extended to Bayesian IRL [10]. Alternatively, Flad et al. [3] presented a system that models a human driver's steering motion as a sequence of motion primitives and then uses these primitives to predict the resulting torque. Jiang et al. [11] model a higher-level layer of the intentions of the human rather than their motor primitives. Dann et al. [12] predict other agents' intentions, assuming all agents have a similar underlying model.Iosti et al. [8] learns a shared control for black box environments using a Recurrent Neural Network (RNN). We use this latter solution as the underlying learner for the control agent, as it is the most unstructured solution, not modeling reward or goal estimations but only the state and actions.\nAs often the black box agent in the shared control system is actually a human or a cooperating agent [13, 14, 15, 16, 17], we wish to leverage an additional communication channel, where the black box assumption is relaxed to allow the control to query the black box about the next best action it should take. Querying in such a manner to improve learning has been used in a variety of learning and inference problems, including active machine learning [18, 19, 20], diagnosis [21, 22], robotics [23, 24, 25] and planning [26, 27, 28]. However, to the best of our knowledge, this work is the first to leverage active learning in shared control systems. We formalize this new communication channel by incorporating an oracle into the shared control system."}, {"title": "The Query-based Shared Control Problem", "content": "We start by formalizing the query-based shared control problem using a Multi-Agent Markov Deci-sion Process (MA-MDP) that combines the state and action spaces of the black box agent and the control [29]. The key uniqueness of this model is in splitting the state space into two, according to the visibility of the agents' state, from the learning agent's perspective. This separation of the state space can also be viewed as an extension of Hidden-mode MDP into multiagent settings [30], and it differentiates from a decentralized POMDP formulation (DEC-POMDP) as the model and distribu-tion over actions of other agents is unknown [31]. Each of the two spaces can capture an aggregated state of more than one agent in the environment and thus model systems with more than two agents. However, for brevity, in this paper we focus on the simplest case where the hidden part of the state space represents the state of a single black-box agent (E), and the visible part represents the state space of the control (C)."}, {"title": "Query Heuristics for a Shared Control", "content": "To answer the question of when to query the oracle, we propose three different heuristics, each inspired by different factors: The Entropy-based heuristic takes an information-theoretical perspec-tive; A Utility-based heuristic is based on prior knowledge; and an RL-based heuristic.\nEntropy Heuristic The gist of this heuristic is to reason about the confidence of the learner about the information that was collected so far (or whether there's a need to use an oracle). Information"}, {"title": "Experiments", "content": "The underlying learning agent used in this work is the one presented in Iosti et al. [8]. However, as mentioned earlier, it can be replaced by any other learning agent that can process the states and actions of the system and recommend the next action of the control. The evaluation in this paper consists of two domains: an automata-based system and an Atari-based lunar lander simulation [33].\nDomain 1: Automata-based Shared Control We follow the definition of an automaton by Iosti et al. [8]. These automata are carefully chosen to challenge the learning of the control policy, due to sparse or delayed rewards. An automaton A is a tuple \u03a9 = (S, \u03b9, \u0391, \u03b4), where S is a finite set of states, \u03b9\u2208 S it the initial state of the automaton, A is a finite set of actions, and \u03b4 : (S \u00d7 A) \u2192 S\u222a {1} is a partial transition function, where I stands for an undefined transition. For brevity, we use a(s) to define the transition d(a, s). Denoting en(s) = {a | a \u2208 \u0391\u028c\u03b4(s, a) \u22601}, i.e., en(s) is the set of actions enabled at the state s. We assume that for each s \u2208 S, the set of possible actions is not empty, en(s) \u2260 \u00d8. A shared control system consists of two automata, a black-box (\u03a9) and the control (\u03a9). As this is a black-box environment, the control automaton is visible to the learner, but the automaton is not. The operation protocol for the two automata is an agreement operator, which is defined as:"}, {"title": "Conclusions", "content": "This paper introduces a new formalization for a shared control system with queries. It explores the new formalization by discussing and evaluating two potential oracles that can be queried, as well as three heuristic approaches for choosing when to query in such a shared system. The results show a clear trade-off between the proposed heuristics: the utility heuristic showed the best results regarding query efficiency, reducing the number of required queries, sometimes to the minimum number of queries in which the true best action cannot be learned. On the other hand, the RL heuristic can reach much lower failure rates but at the cost of a large and inconsistent number of queries. These results are consistent across two very different evaluation domains. Future work will investigate using RL techniques to make querying more efficient and consistent. One option is to replace the RNN itself with an RL algorithm that can choose between the system's different actions and querying. Our empirical evaluation also demonstrated the impact of the oracle quality, showcasing its importance. Future work can reason about the oracle type in real time and adapt the chosen heuristic to that oracle. Lastly, another question to investigate is how to design a querying heuristic that accounts for an oracle that intentionally misleads the control."}]}