{"title": "Hyperspectral Imaging-Based Grain Quality Assessment With Limited Labelled Data", "authors": ["Priyabrata Karmakar", "Manzur Murshed", "Shyh Wei Teng"], "abstract": "Recently hyperspectral imaging (HSI)-based grain quality assessment has gained research attention. However, unlike other imaging modalities, HSI data lacks sufficient labelled samples required to effectively train deep convolutional neural network (DCNN)-based classifiers. In this paper, we present a novel approach to grain quality assessment using HSI combined with few-shot learning (FSL) techniques. Traditional methods for grain quality evaluation, while reliable, are invasive, time-consuming, and costly. HSI offers a non-invasive, real-time alternative by capturing both spatial and spectral information. However, a significant challenge in applying DCNNs for HSI-based grain classification is the need for large labelled databases, which are often difficult to obtain. To address this, we explore the use of FSL, which enables models to perform well with limited labelled data, making it a practical solution for real-world applications where rapid deployment is required. We also explored the application of FSL for the classification of hyperspectral images of bulk grains to enable rapid quality assessment at various receival points in the grain supply chain. We evaluated the performance of few-shot classifiers in two scenarios: first, classification of grain types seen during training, and second, generalisation to unseen grain types, a crucial feature for real-world applications. In the first scenario, we introduce a novel approach using pre-computed collective class prototypes (CCPs) to enhance inference efficiency and robustness. In the second scenario, we assess the model's ability to classify novel grain types using limited support examples. Our experimental results show that despite using very limited labelled data for training, our FSL classifiers accuracy is comparable to that of a fully trained classifier trained using significantly larger labelled database. We also propose a novel enhancement to the squeeze and excitation attention mechanism to improve feature representation in hyperspectral images. These findings demonstrate the potential of FSL as a practical solution for rapid, accurate grain quality assessment in real-world applications. Impact Statement-This study combines hyperspectral imaging (HSI) with few-shot learning (FSL) to address the need for large labelled datasets in grain quality assessment. By introducing collective class prototypes (CCPs) and enhancing feature representation with a novel attention mechanism, the approach enables accurate classification with minimal labelled data. It performs well on both seen and unseen grain types, making it practical for real-world applications like rapid grain quality checks in supply chains. This method offers a fast, non-invasive, and efficient alternative to traditional assessments, benefiting the grain industry significantly.", "sections": [{"title": "I. INTRODUCTION", "content": "DIFFERENT types of grains, like wheat, rice, and corn serve as staple foods worldwide. Therefore, effective and efficient assessment of grain quality is significantly important, especially in grain trading process and in food safety assur-ance. Traditionally, grain quality assessments involve chemical and biological analysis. However, these methods are invasive, destructive, time-consuming, and costly. Consequently, there is a shift in the testing methodology towards faster, non-invasive, non-destructive, and real-time approaches. Hyperspectral imaging (HSI) is a promising non-invasive and real-time method for assessing grain quality. HSI has been applied successfully in agriculture and the food industry, such as in detecting damage in fruits and vegetables [1], [2], contaminants in food [3], and quality in dairy [4] and meat [5]. HSI is increasingly used for evaluating grain quality parameters like protein [6], moisture [7], defects [8], and contaminants [9]. Grain classification, an important part of quality assessment, has traditionally relied on invasive methods [10]. From the early 2000s, non-invasive techniques like X-ray imaging [11], near-infrared spectroscopy (NIRS) [12], and RGB imaging with shape, color, and texture features [13], [14] became more common. However, X-ray imaging poses health risks, and NIRS and RGB imaging have limitations in leveraging both spatial and spectral information. HSI addresses these limitations by combining NIRS and digital optical imaging to capture both spatial and spectral data as three-dimensional (3D) hypercubes with two spatial and one spectral dimension [15]. This provides comprehen-sive data, revealing patterns based on unique interactions of electromagnetic (EM) energy with biological materials, which vary by chemical composition and structure. In recent years, deep convolutional neural networks (DC-NNs) have gained popularity in image processing, excelling at recognising complex patterns in raw data. Originally used for RGB imaging, DCNNs are now widely applied to mul-tispectral and HSI data. Traditionally, DCNNs in HSI have focused on single kernels or sparse samples [16]\u2013[18], but this approach is inefficient and time-consuming [19]. Bulk HSI imaging of densely distributed kernels, however, expedites the process [20], [21], making it ideal for fast quality assessments in the grain supply chain, where time is crucial. Bulk HSI imaging enhances efficiency, surpassing traditional methods in speed and streamlining grain quality evaluation. The authors of [22] proposed a DCNN-based approach for analysing and classifying bulk grains using 3D hyperspectral"}, {"title": "II. BRIEF INTRODUCTION TO FEW-SHOT LEARNING", "content": "FSL is a sub-field of machine learning that addresses the challenge of training models with a small number of labelled examples, making it useful in scenarios where acquiring large amounts of labelled data is impractical or costly. It aims to enable pre-trained machine learning models to generalise over new categories of data, based on a limited number of samples, thus reducing the dependency on large labelled databases. It belongs to the realm of meta-learning, which involves the concept of learning to learn. [38]. The concept of FSL is discussed as follows. FSL consists of support and query sets and an N-way K-shot learning scheme. Support set: The support set contains a limited number of labelled samples (i.e., samples and their corresponding"}, {"title": "A. Prototypical Network", "content": "Prototypical networks classify images by learning a feature space through an embedding architecture which extracts fea-tures from raw data (like images) and maps them to this space. Each class has a prototype, represented by the mean vector of its support points' embeddings. To classify a new image, the network computes its embedding and measures the distance to each class prototype. The image is assigned to the class with the closest prototype. A detailed mathematical explanation of Prototypical networks is provided in the following paragraphs. Say, support set $set_{Support} = {(X_1,Y_1),..., (X_N,Y_N)}$ consists of N number of images (x) and their corresponding labels (y) and there are total K different classes. The value of N is significantly lower compared to a typical labelled image database used in standard image classification applications. The operation of Prototypical networks starts with computing prototypes of each class through an embedding function ($\\f_$\\phi) that is often a pre-trained CNN. Each prototype is derived from the mean vector of the embedded support points associated with its respective class given by (1) $$c_k = \\frac{1}{S_k}\\sum_{\\substack{(X_i,Y_i) \\in S_k}} \\f_\\phi(x_i),$$\nwhere $S_k$ and $c_k$ are the set of samples and the computed prototype, respectively of class k."}, {"title": "III. BRIEF INTRODUCTION TO SQUEEZE AND EXCITATION ATTENTION", "content": "In this section, we discuss the Squeeze and Excitation (SE) attention mechanism [42]. It has three components. They are as follows. Squeeze: In this step, the spatial dimensions of each channel are reduced to a single value which is the global representation of the corresponding channel. This is done using a pooling operation, like global average pooling (GAP). Mathematically, the squeezed representation, $z_c$ of each channel c is given by (3). $$z_c = \\frac{1}{H \\times W} \\sum_{i=1}^{H}\\sum_{j=1}^{W} I(i, j, c),$$\nwhere H, W, and C represent the height, width and the total number of spectral channels of each hyperspectral image, I. Excitation: In the excitation step, the SE block uses two fully connected (FC) layers to capture channel-wise dependencies and relationships. This step computes attention weights for each channel based on the squeezed global values. At first, the data from the last step is passed through a reduction layer that reduces the number of channels (by a factor called the reduction ratio). This introduces non-linearity and helps the model learn complex relationships between channels. After that, the reduced representation is expanded back to the original number of channels, producing a set of attention weights through a sigmoid activation function. These attention weights are in the range (0, 1), indicating the importance of each channel. The mathematical model of this step is given by (4). $$s = \\sigma (W_2. ReLU (W_1z)),$$\nwhere $W_1$, $W_2$ and $\\sigma$ are the weights of the first (reduc-tion) and second (expanding) fully connected layers and sigmoid function, respectively. Recalibration: This is the final step of SE block. In this step, given by (5) learned attention weights are"}, {"title": "IV. PROPOSED METHODOLOGY", "content": "In our proposed methodology a Prototypical network with Euclidean distance (L2-norm) to calculate pairwise distances between embeddings is considered. A state-of-the-art 2D CNN serves as the backbone for embedding hyperspectral images into feature space. For grain classification with HSI, [22] favours a 2D CNN over a 3D one, modifying a 2D ResNet to handle spectral data by adding a spectral down-sampling layer. This allowed the network to quickly reduce the spectral dimension while still utilising spectral features. This modification increased the efficiency in model training compared to using a 3D CNN. In addition, backed by the experimental results, the authors of [22] also claimed that this modification achieved better accuracy. A potential explanation for this enhancement is that the rapid reduction of spectral dimensions helped evade the overfitting problem, allowing the model to generalise better. Therefore, it was found to be more efficient in leveraging both spectral and spatial information. This motivated us to use a 2D ResNet (following the same modification of adding an spectral down sampling layer at the beginning) as the backbone for our experiments. In addition, we incorporated a channel-wise attention mechanism to em-phasise informative spectral bands and reduce noise before spectral downsampling. The mechanism utilised a squeeze-and-excitation block placed before the downsampling layer. An SE block enhances CNNs by recalibrating channel-wise features to focus on the most important ones [42]. It improves the network's ability to highlight key feature channels, particularly in the RGB imaging space [43]. While SE blocks have been applied in the HSI domain, their use has mostly been limited to recalibrating CNN-derived features rather than directly working on raw HSI data cubes [44], [45]. This limits their ability to fully utilise the rich spectral information in raw HSI data. To address this, our approach uses the SE block to assign greater weight to significant spectral bands while suppressing less informative ones. By learning attention weights for each channel, the model focuses on the most relevant channels. In this paper, we modified the squeeze step of the SE block by combining adaptive average pooling and adaptive max pooling as described in (6), instead of using only aver-age pooling. Average pooling smooths feature activations to capture global trends but may overlook key spectral features [46], while max pooling highlights strong activations but can miss broader context [47]. Combining both methods balances global feature aggregation and prominent activation detection,"}, {"title": "V. EXPERIMENT", "content": "In this paper, we have considered the HSI database used in [22]. This database consists of hyperspectral images of eight grains harvested in Denmark and Sweden. They are as follows. Midsummer Rye (Rye), Spelt wheat (Spelt), Halland wheat (Halland), \u00d8land wheat (Oland), Winter wheat, Type A - Sweden (WH 1), Spring wheat (WH 3), Winter wheat, Type A - Denmark (WH 4), Winter wheat, Type B (WH 5). A brief description of these grains provided in Table I."}, {"title": "B. Experiment settings", "content": "For the feature embedding, we have considered popular CNN architecture ResNet-18 as backbone model. Rather than being directly inputted into the feature embedding model, the hyperspectral images undergo processing through a linear downsample layer, which is added on top of the CNN archi-tecture as per [22]. This modification allows for the handling of hyperspectral image data within a 2D CNN framework. The database contains a total of 8 classes. We conducted our experiments using two scenarios as follows. Complete class training (8-way classification): This ap-proach involves training the classifier with all eight classes in the database. The objective is to evaluate the classifier's performance on unseen images from the same classes it was trained on. Partial class training (6-way classification): In this ap-proach, the classifier is trained using only six of the eight classes, excluding two classes from the training process. The goal is to assess how well the classifier generalises to unseen test images from the excluded classes, thus evaluating its ability to handle previously unseen classes. We used a shot size of 5 for support sets and 10 for query sets in our experiments. The training database had 2880 images, with 360 per class, divided into 24 episodes of support and query sets. The network was trained for 50 epochs, using all 24 episodes in each. Our objective was to adapt the ResNet-18 backbone from the RGB to the HSI domain for better feature extraction from hyperspectral images. This adaptation improved similarity measurements between support and query images, enhancing classification accuracy. Processing data with 204 channels is computationally inten-sive. In [49] and [22], the number of channels was reduced by 50% and 66.66%, respectively, by averaging every second and third consecutive channels before passing the data to the spec-tral downsampling layer. However, averaging hyperspectral channels can lead to information loss. Therefore, we utilised all 204 channels in our experiments. We conducted experiments on HSI data with 204 chan-nels in two configurations. The first fed the 204 channels directly into the spectral downsampling layer. The second"}, {"title": "VI. RESULTS", "content": "In this section, we present the results of our experiments. The results for Complete class training and Partial class training approaches are provided in separate subsections."}, {"title": "A. Complete class training evaluation results", "content": "To evaluate the classifier's performance in the 8-way classi-fication scenario, we used CCPs instead of support sets during inference, as shown in Table II. The CCPs were calculated by averaging class prototypes from each support set in the training database, as explained in Section IV. The results show improved classifier performance when all channels are used with the channel attention mechanism. This is because the hyperspectral data channels were weighted by attention based on their relevance before being processed by ResNet-18. Among the two configurations without channel attention, the reduced channel configuration performs worst, likely due to information loss from channel averaging. Table III shows the training time for 50 epochs across the three configurations. The all-channel configuration (with attention) took the longest, while the reduced channel configuration (without attention) was the quickest. As shown in Table II, the reduced channel configuration has the lowest accuracy, with differences of 2.77% compared to the all-channel configuration (without attention) and 4.42% compared to the all-channel configuration (with attention). Thus, for a faster classifier with minimal accu-racy loss, the reduced channel configuration can be considered. In this section, we present a quantitative analysis to demon-strate the advantages of using CCPs over individual support"}, {"title": "B. Partial class training evaluation results", "content": "In this section, we assess the performance of our few-shot classifier under the partial class training scenario, excluding Rye and WH 5 from the training set. Using the optimal configuration identified in Section VI.A (Table II), all hyper-spectral channels were utilised in conjunction with the channel attention mechanism for this experiment. Rye and WH 5 were excluded intentionally. Rye, being a different grain type, was ideal for testing the classifier's ability to generalise to unseen classes. Evaluating its classification without Rye samples in training assesses robustness to domain"}, {"title": "VII. CONCLUSION", "content": "This paper explored FSL scenarios for hyperspectral image classification in grain quality assessment, yielding signifi-cant findings and contributions, specifically when collecting labelled data is difficult. We introduced CCPs as a robust alternative to individual support sets during inference, demon-strating superior performance and reduced susceptibility to outliers. Our proposed channel attention mechanism enhanced feature representation of hyperspectral images, resulting in im-proved classification performance. Notably, the FSL approach achieved comparable accuracy to fully trained supervised clas-sifiers while using significantly less training data, highlighting its potential in scenarios where labelled data is scarce. Our research has important implications for hyperspectral image classification in supply chain applications, specifically in terms of reduced data requirements and adaptability to unseen classes. The classifier's ability to generalise to unseen classes is crucial for applications where new grain grades or types may be encountered. Future research could focus on exploring more complex FSL architectures, investigating applications in other domains within hyperspectral image clas-sification, and developing strategies to enhance performance when dealing with closely related classes in the feature em-bedding space. Overall, this paper demonstrates the potential of FSL in hyperspectral image classification for grain quality assessment, offering a promising approach that balances ac-curacy, efficiency, and adaptability in real-world supply chain applications."}]}