{"title": "Feature-Space Semantic Invariance: Enhanced OOD Detection for Open-Set Domain Generalization", "authors": ["Haoliang Wang", "Chen Zhao", "Feng Chen"], "abstract": "Open-set domain generalization addresses a real-world challenge: training a model to generalize across unseen domains (domain generalization) while also detecting samples from unknown classes not encountered during training (open-set recognition). However, most existing approaches tackle these issues separately, limiting their practical applicability. To overcome this limitation, we propose a unified framework for open-set domain generalization by introducing Feature-space Semantic Invariance (FSI). FSI maintains semantic consistency across different domains within the feature space, enabling more accurate detection of OOD instances in unseen domains. Additionally, we adapt a generative model to produce synthetic data with novel domain styles or class labels, enhancing model robustness. Initial experiments show that our method improves AUROC by 9.1% to 18.9% on ColoredMNIST, while also significantly increasing in-distribution classification accuracy.", "sections": [{"title": "I. INTRODUCTION", "content": "Open-set domain generalization addresses the dual challenge of domain generalization (DG) and open-set recognition (OSR) by aiming to classify in-distribution (ID) instances under domain shifts while simultaneously detecting samples from unknown classes in the unseen target domain. Despite this setting better reflecting real-world scenarios, current methods often treat it as two separate problems due to its complexities. For instance, OOD samples with styles similar to IDs are difficult to detect, while ID samples in a shifted target domain are prone to being misclassified as OOD.\nResearch in open-set domain generalization is relatively sparse, with only a few works [1]\u2013[10] making progress compared to conventional approaches that handle either DG or OSR in isolation. However, these existing methods typically rely heavily on OOD training data [11], which is rarely available in training, or utilize meta-learning strategies and complex network architectures [12]-[14] that lack compatibility with state-of-the-art OOD detection techniques, such as Energy [15] and DDU [16].\nTo address these limitations, we propose an advanced technique that enforces feature-space semantic invariance to learn high-quality domain-invariant features, and leverages synthetic OOD data to increase the separability between ID and OOD. Our main contributions are as follows:\n\u2022 We introduce Feature-space Semantic Invariance (FSI) to enforce semantic consistency across domains within the feature space. By aligning semantic features across augmented samples, FSI enables the model to learn high-quality domain-invariant features, enhancing its generalizability to unseen domains.\n\u2022 We incorporate synthetic OODs generated from ID samples to establish clearer decision boundaries between ID and OOD instances, significantly enhancing the model's robustness against OOD.\n\u2022 Preliminary experiments show that our approach improves AUROC by 9.1% to 18.9% on the ColoredMNIST dataset, with a notable increase in ID classification accuracy. These results validate the model's potential in open-set domain generalization, positioning it as a viable solution for applications with novel domains and classes."}, {"title": "II. METHODOLOGY", "content": "Problem Setting. Given a dataset $D$, we consider a set of domains $E = \\{e\\}_{E=1} \\in \\mathbb{N}$, where each domain corresponds to a data subset $D_e = \\{(x,y)\\}$ with specific data variations. The dataset $D$ is thus represented as $D = \\{D_e\\}_{E=1}$.\nWe divide $D$ into training domains $E_{tr} \\subset E$ and test domains $E_{te} = E \\backslash E_{tr}$. The training data $D_{tr}$ consists of samples $D_{tr} = \\{D_e\\}_{1} = (X \\times Y_{tr})$, where $X \\in \\mathbb{R}^d$ represents the input space and $Y_{tr} = \\{1,\\ldots, K\\}$ denotes the label space, with $K$ being the number of observed classes in $D_{tr}$. The test domains, $E_{te}$, are associated with data $D_{te} = D \\backslash D_{tr} \\in (X \\times Y_{te})$, where $Y_{te} = \\{Y_{tr},OOD\\}$, with an unknown class (OOD) label OOD.\nThe main challenge in open-set domain generalization is to develop a network $f$ that can identify novel classes in shifted domains using a semantic OOD detector $w$. Given that the test data from $E_{te}$ is unavailable and novel classes appear only in $D_{te}$, this problem is inherently difficult. We assume that inter-domain variation arises solely from covariate shift [17], meaning that domain differences stem from variations in the marginal distributions $\\{P(X)\\}_{e\\in E}$, which can be connected by a generative model $G : X \\times E \\rightarrow X$, that $x_e = G(x^{e'}, e)$ for all $e, e' \\in E$.\nLet the network be defined as $f := g \\circ h$, where $g: X \\rightarrow \\mathbb{R}^{\\Theta}$ is the feature extractor and $h : \\mathbb{R}^{\\Theta} \\times \\Theta \\rightarrow \\mathbb{R}^K$ is the classifier. To tackle the open-set domain generalization problem, we enforce the feature-space semantic invariance: the instance-conditional distributions of features extracted by $g$ should remain stable across different domains. Formally, we define the feature-space semantic invariance (FSI) as follows:\nDefinition 1 (Feature-space Semantic Invariance (FSI)). Given $G$, a network $f = g \\circ h$ is said to exhibit feature-space semantic invariance if $g(x^{e}, \\theta_g) = g(x^{e'}, \\theta_g)$ almost surely, where $x^{e} = G(x, e')$, $x^e \\sim P(X_e)$, $x^{e'} \\sim P(X_{e'})$, for all $e, e' \\in E$.\nDesign of Generative Model G. Following the data disentanglement principles of [17], [18], which separate domain variations into latent vectors, we consider an ID sample $(x, y)$ from a domain $e \\in E$. It is assumed that the sample is generated from two vectors: a latent semantic vector $s$ and a domain-specific latent variation vector $v_e$. The generative model G consists of a semantic encoder $E_{sem}: X \\rightarrow S$, a variation encoder $E_{var}: X \\rightarrow V$, and a decoder $D : S \\times V \\rightarrow X$. The model disentangles the input data into semantic and variation vectors, where $s = E_{sem}(x)$ and $v_e = E_{var}(x)$, and reconstructs the input via $x_e = D(s, v_e)$. Furthermore, G can generate a synthetic instance $x_{e'} = D(s, v_{e'})$ for a domain $e'$ by substituting $v_e$ with a randomly sampled $v_{e'} \\sim N(0, I)$.\nIn this work, G is treated as a pre-trained model that follows the architecture described in [17].\nFeature Regularization RF. To enforce feature-space semantic invariance (FSI), we propose the following regularization term:\n$R_F = E_{(x,y)\\sim D_{tr}}[d(g(x^e, \\theta_g), g(G(x, v_{e'}), \\theta_g))]$ (1)\nwhere $v_{e'} \\sim N(0,I)$. We use the $l_1$-norm for the distance function $d: \\mathbb{R}^n \\times \\mathbb{R}^n \\rightarrow \\mathbb{R}$ in $R_F$. The regularizer $R_F$ enables $g$ to capture semantic features by minimizing the distance between outputs of $g$ for original data and their augmented counterparts in the random domain $v_{e'}$, while also mitigating domain shift disruptions during OOD detection by encouraging $g$ to learn domain-invariant semantic features.\nEnergy Regularization RE. For enhanced OOD detection capability within the context of open-set recognition, we generate synthetic OODs using semantic inter-class blending. Given two instances with different class labels $(x_1, y_1)$ and $(x_2, y_2)$, we compute the augmented semantic representation $\\tilde{s}$ as follows:\n$\\tilde{s} = \\alpha \\cdot s_1 + \\beta \\cdot s_2$ (2)\nwhere $\\alpha, \\beta \\in [-100,100]$, and $s_1,s_2$ are the semantic vectors of $x^{e_1}$ and $x^{e_2}$ respectively. We can then generate synthetic OOD $x = D(\\tilde{s}, v_{e'}) \\in D_{OOD}$ that exhibit realistic variations, making them valuable for training robust OOD detectors. Specifically, we employ an energy bounding mechanism to enhance the separability between ID and OOD instances, with the regularization term RE defined as:\n$R_E = E_{(x_i, y_i \\in Y_{tr}) \\sim D_{tr}} (max(0, Energy(x_i, \\theta) - \\gamma))^2 + E_{(x_j, OOD) \\sim D_{OOD}} (max(0, \\gamma - Energy(x_j, \\theta)))^2$ (3)\nsuch that ID instances are encouraged to have energy smaller than $\\gamma < 0$, while OOD instances are encouraged to have energy larger than $\\gamma$.\nLoss Function. The overall objective combines the feature and energy regularizations:\n$l(\\theta) = E_{(x^e, y^e) \\sim D_{tr}}L_{CE}(f(x^e, \\theta), y^e) + \\zeta_1 \\cdot R_F + \\zeta_2 \\cdot R_E$ (4)\nwhere $L_{CE}$ represents the cross-entropy loss."}, {"title": "III. EXPERIMENTS", "content": "We evaluated our method on the COLOREDMNIST [19] dataset following the setting of [17]. For each OOD digit selection, we conducted three trials, each including 30 random hyperparameter search runs. This process is repeated until at least 50% of digits have been designated as OOD. For OOD regularization $R_{OOD}$, synthetic OODs are generated from ID data, particularly in low-density regions. As shown in Table I, traditional DG methods (the first four) fail to learn robust domain-invariant features, while our methods consistently outperform all baselines, particularly in AUROC and AUPR. These results emphasize the effectiveness of our approach in enhancing both OOD detection and ID classification for open-set domain generalization."}]}