{"title": "GraphiT: Efficient Node Classification on Text-Attributed Graphs with Prompt Optimized LLMs", "authors": ["Shima Khoshraftar", "Niaz Abedini", "Amir Hajian"], "abstract": "The application of large language models (LLMs) to graph data has attracted a lot of attention recently. LLMs allow us to use deep contextual embeddings from pretrained models in text-attributed graphs, where shallow embeddings are often used for the text attributes of nodes. However, it is still challenging to efficiently encode the graph structure and features into a sequential form for use by LLMs. In addition, the performance of an LLM alone, is highly dependent on the structure of the input prompt, which limits their effectiveness as a reliable approach and often requires iterative manual adjustments that could be slow, tedious and difficult to replicate programmatically. In this paper, we propose GraphiT (Graphs in Text), a framework for encoding graphs into a textual format and optimizing LLM prompts for graph prediction tasks. Here we focus on node classification for text-attributed graphs. We encode the graph data for every node and its neighborhood into a concise text to enable LLMs to better utilize the information in the graph. We then further programmatically optimize the LLM prompts using the DSPy framework to automate this step and make it more efficient and reproducible. GraphiT outperforms our LLM-based baselines on three datasets and we show how the optimization step in GraphiT leads to measurably better results without manual prompt tweaking. We also demonstrated that our graph encoding approach is competitive to other graph encoding methods while being less expensive because it uses significantly less tokens for the same task.", "sections": [{"title": "1 Introduction", "content": "Graphs are powerful tools for representing entities and the relationships between them in different applications such as social networks and citation networks. For instance, in a citation network, nodes are the articles and there is an edge between two articles if one article cites another one. In text-attributed graphs, nodes have text attributes which provide further information about the nodes. In the citation network described above, the text attributes of a node could be the content of the associated article. One of the main applications of graphs is the node classification task in which a model predicts a label for the nodes in the test set.\nGraph Neural Nets (GNNs) [14, 32] are the state of the art in graph representation learning. They typically generate a node embedding by aggregating the embeddings of neighbors of the node in a message passing mechanism [15, 25]. GNNs consider the structure and the attributes of graphs in generating embeddings. The text attributes of nodes are often represented by shallow embeddings such as bag-of-words [12] and word2vec [18] which can not capture the contextual relationships between words in text attributes. However, large language models have demonstrated great success in generating contextual text embeddings with superior performance than shallow embeddings in natural language processing (NLP) tasks.\nThe success of the LLM models is mainly due to their pre-training on a vast amount of text corpora which gives them massive knowledge and semantic comprehension capabilities. Hence, many recent efforts have explored combining LLMs and GNNs [5, 10, 28, 31, 33]. While effective, this combination results in a complex system involving two large models which increase the computational demands and require labeled training data.\nConsequently, other studies focused on evaluating the potential of LLMs to act as standalone models for both embedding generation and prediction [2, 7, 21, 30]. These methods employ various techniques for optimizing LLMs, which can be broadly categorized into prompt engineering [7] which relies heavily on manual adjustments or fine-tuning which require labeled training data [30]. Additionally, different approaches are explored for converting graph structures into sequential formats suitable for LLMs, including using text attributes, lists of a node's neighbors [30], and neighbor summaries [2] which can lead to increasing the context length of prompts making the LLM calls more expensive.\nIn this paper, we investigate the promise and limitations of using LLMs for the node classification tasks by proposing new approaches for graph encoding and prompt optimization in terms of instruction and examples using DSPy framework [13]. Specifically, we use a prompt programming approach which automates the optimization of LLMs for node classification without extra training, manual tweaks and with a small set of labeled data. Furthermore, we propose using keyphrases of neighbor nodes to represent a node, which offer several advantages. First, keyphrases require significantly less of the LLMs' context window while effectively conveying the key points. Second, when neighbor summaries are lengthy, LLMs may experience the \"lost-in-the-middle\" effect [17], where critical information representing a node's neighbors is overlooked. Lastly, in certain graph applications, including multi-hop neighbors is essential. However, summarizing such extended neighborhood information becomes challenging and less interpretable. By using keyphrases, we can generate concise yet informative summaries that capture a broader span of information within the graph. Our main contributions in this paper are as follows:\n\u2022 We present GraphiT, a novel technique for graph encoding and LLM prompt optimization in node classification task.\n\u2022 GraphiT provides an efficient solution for minimizing the use of LLM context window and automating LLM prompt optimization.\n\u2022 We evaluate the performance of our approach with three baselines on three datasets. In addition, we perform ablation studies to show the effectiveness of GraphiT components. GraphiT can be easily adapted to new tasks and datasets with minimal effort."}, {"title": "2 Related works", "content": "GNNs are the frontier techniques in the field of graph representation learning [14, 32]. However, they use shallow embeddings to represent text attributes of nodes. Given the capability of LLMs to generate rich contextual embeddings, several works have combined LLMs with GNNs to enhance GNN performance [5, 10, 28, 31, 33]. Leading [28] employs an end-to-end training of LMs and GNNs for graph prediction tasks. Engine [33] combines LLMs and GNNs using a tunable side structure. Despite their effectiveness, these integrations create complex systems that are often computationally intensive and require labeled data for training. Therefore, other studies investigate the possibility of using LLMs alone for graph prediction tasks. In [26], LLMs are utilized for several graph reasoning tasks such as connectivity, shortest path and topological sort using two instruction-based prompt engineering techniques.\nInstructGLM [30] proposes a instruction fine-tuning method for node classification by LLMs. In [2], LLMs have been used both as enhancer and predictor for node classification task. It encodes the nodes into text by incorporating text attributes and 2-hop neighbors summaries. In [7], different methods for graph encoding and prompt engineering were investigated. In [21], graphs are input to LLMs using a graph encoder which was trained similar to soft prompting methods [16]. Fine-tuning and soft promoting techniques require training with labeled data. Traditional prompt engineering relies heavily on human expertise and manual adjustments. In contrast, we programmatically optimize LLM usage with only a small set of labeled data. In addition, we efficiently capture the information in a node's neighborhood by extracting keyphrases from text attributes of neighboring nodes."}, {"title": "3 Method", "content": "3.1 Problem definition\nLet G = (V, E, S) be a text-attributed graph G where V, E and S represent nodes, edges and text attributes of nodes in the graph, respectively. For each node vi \u2208 V, si \u2208 S represents the text attributes of vi. Y is the set of labels associated with nodes. Our goal is to perform node classification on the graph using a large language model. In the node classification, a label is predicted for each node in the graph. Formally, a classifier f maps the set of nodes V to the set of labels Y represented as: f : V \u2192 Y. The core of our approach consists of three main steps: 1) each node vi in the graph is encoded into a sequential form for use by LLM, 2) an LLM prompt is optimized in terms of instruction and demonstrative examples. 3) the LLM with the optimized prompt is utilized to assign a label to each node.\n3.2 Node feature preparation\nWhile LLMs have shown remarkable success with textual data, a crucial question remains: how LLMs can best utilize the information in structured graph data? [21]. In this study, we use the homophily assumption in graphs which says connected nodes are similar [3] and for each node consider the features of the 1-hop neighbors of a node to help the LLM in predicting the node labels. For a node $v_i$ with $N_1 = \\{v_0, ..., v_k \\}$ representing the set of its 1-hop neighbors, $v_0$ to $v_k$, we consider the following features beside node text attributes.\nDEFINITION 1. (Neighbors labels). This set consists of labels of 1-hop neighbors of node $v_i$ denoted as $l_{N_1} = \\{l_0, ..., l_k \\}$.\nDEFINITION 2. (Neighbors keyphrases). Let $s_{N_i} = \\{s_0, ..., s_k \\}$ be a set consisting of text attributes of 1-hop neighbors of the node. Neighbors keyphrases denoted by $P_{N_1} = \\{P_0, ..., P_x \\}$ is a set containing the keyphrases that are shared among the node's neighbors text attributes.\nThe process for extracting neighbors keyphrases for each node is detailed in the next section. We apply the keyphrase extraction algorithm to the concatenation of elements in $s_{N_i}$.\n3.2.1 Keyphrase extraction. Keyphrase extraction (KPE) is an automated process that identifies the most important words or phrases from a given text. These keyphrases are useful for various downstream applications, such as document classification, clustering, summarization, indexing documents, query expansion, and interactive document retrieval. Various approaches have been developed"}, {"title": "3.3 Prompt optimization", "content": "Considering that the quality of the input prompt to an LLM has a huge effect on the output of the model, we optimize the LLM prompt for the node classification both in terms of instruction and examples. In order to do that, we use the optimization framework of DSPy programming model. DSPy provides a framework in which we can define our task as a program and automatically optimize the prompt for the best performance. We will explain each step in the following sections.\n3.3.1 Node classification program. The program for node classification is illustrated in Code Snippet 1. Given the node features and a set of node labels as options, an LLM predicts a label for each node. We use the chain of thought technique [27] to let the LLM solve the problem step by step by breaking down the question into simpler tasks.\n3.3.2 Signature. The prompt for the LLM in the node classification program is defined using a signature abstraction. The signature for node classification on Cora and PubMed datasets are defined in Code Snippet 2. This signature contains a task description in a docstring, the node features and a set of labels as inputs and the predicted output along with description and formatting information. As we encode the node information into a text format for use by LLM, we also formulate the node classification task into a text classification task in the task description and ask the LLM to classify a given text into the most applicable category. As Cora and PubMed are citation datasets, the task description specifies that the text is a scientific paper but this can be adjusted for any new dataset depending on the dataset graph content.\n3.3.3 Compilation. We optimize the node classification program in terms of instruction and prediction examples. DSPy compilers handle this optimization programmatically. For instruction optimization, we use COPRO (Coordinate-ascent Optimization by Prompting) [13, 19], an extension of OPRO approach [29]. The OPRO method relies on LLMs to iteratively optimize their own prompt based on a given problem description. COPRO generalizes OPRO [29] by incorporating a coordinate ascent strategy, allowing it to be applied to programs with multiple prompts. In this approach, each prompt is optimized individually while the other parameters remain fixed. In DSPy, the compiler continuously refines the program's instructions based on the LLM's performance on the validation set, ultimately converging to a set of optimized instructions tailored to the task.\nSimilarly, a set of optimized demonstrative examples are added to the prompt by an iterative process using bootstrap few-shot random search approach [13, 19]. In this process, a prediction is generated for each example within the training set. Let f(x) represent the prediction for an example x, x' denote the ground truth, and $\\mu((\\phi(x),x'))$ be the score of the prediction compared to the ground truth based on a metric $\\mu$. If $\\mu((\\phi(x), x')) \\geq \\lambda$ where $\\lambda$ is a predefined threshold, the prediction is considered successful. Upon successful prediction, a demonstration comprising the input to the LLM and the corresponding output is recorded. A predetermined maximum number of these demonstrations are then incorporated into the prompt. This process is repeated multiple times and the most performant demonstrations on the validation set are selected through random search. We measure the performance of each program using the rank-precision at top K results (RP@K) and the metric defined as [4]:\n$RP@K = \\frac{1}{N} \\sum_{n=1}^{N} \\frac{1}{min(K, R_n)} \\sum_{k=1}^{K} Rel(n,k)$ (1)\nwhere $R_n$ is the set of labels for a node n, Rel(n, k) is 1 if the k-th predicted label for node n is relevant and otherwise is 0. N is the total number of nodes in the set."}, {"title": "4 Experiments", "content": "4.1 Datasets\nWe evaluated GraphiT was on three public datasets: Cora, PubMed and Ogbn-arxiv. Cora [10] is a citation network where each node is an article and each edge indicates a citation relationship between two articles. Number of nodes and edges are 2708 and 5429. Each node belongs to one of the 7 classes: case based, genetic algorithms, neural networks, probabilistic methods, reinforcement learning, rule learning, and theory. Each node is associated with a text attribute containing the title and the abstract of the article. Similarly, PubMed [10] is a citation network with 19k nodes and 44k edges. Each node in the dataset has one of the three labels: experimental induced diabetes, type 1 diabetes, and type 2 diabetes. The text attributes of nodes in PubMed are similar to Cora. Ogbn-arxiv [11] is also a citation networks between all Computer Science arxiv papers containing 169k nodes, 1M edges and 40 subject areas.\n4.2 Settings\nSimilar to [2], we randomly selected 200 nodes from the test set of each dataset as our test data. The reported scores are averaged over two sampled test sets. Our evaluation metric is RP@1 which is equivalent to accuracy in our experiments. The LLM that we used was gpt-3.5-turbo-1106. We used BootstrapFewShotWithRandomSearch and COPRO compilers from DSPy. The length of ngrams in the keyphrase extraction step is set to ngram \u2208 {1, 2, 3} and we set \u03b6 = 5. The nodes neighbors summaries are generated using the quantized version of the Phi 3.5 model [6, 22] by llama.cpp [8].\n4.3 Node classification\nWe evaluate the performance of GraphiT compared to three baselines on three datasets. Each node in the graph is encoded by integrating the node's neighbors' keyphrases with its text attributes and the labels of its neighbors. Without the loss of generality, for prompt optimization, we generate small training and validation sets by randomly sampling 3 and 2 nodes per class from training and validation sets of Cora dataset. Then, we use the optimized programs for inference on arbitrarily large test sets.\nTable 2 presents the node classification results from GraphiT, the result from the vanilla LLM using the same graph encoding, the best results from an unoptimized few-shot learning approach using LLMs by Chen et al [2] and a graph convolutional network (GCN) result [15] obtained from [2]. We were able to compare with the methods reported in [2] as they used the same number of nodes in the test sets for each dataset as us and were designed for the node classification task. GraphiT outperforms the results by the LLM-based models on all three datasets. It also achieves superior performance on PubMed compared to GCN. However, GraphiT falls short of the performance by GCN on Cora and Ogbn-arxiv datasets. This could be because GCN captures information from 2-hop neighbors for each node, which is useful for node classification on those datasets. Exploring the incorporation of neighbors beyond 1-hop in GraphiT will be one of our future research directions.\n4.4 Ablation study\nWe investigate the effects of different components of GraphiT across three dataset. One major component of our model is the node neighbors keyphrases. We consider four settings to encode nodes into a sequence format, beginning with only the text attributes of the nodes and progressively incorporating additional features through concatenation. For all the datasets, incorporating neighbors keyphrases alongside the text attributes and neighbors labels enhances performance. Moreover, this approach has a comparable or better results compared to using neighbor summaries while significantly reducing the context length in the LLM prompt."}, {"title": "4.5 Cost comparison of using neighbors keyphrases versus summary", "content": "In Figure 2, we present a histogram depicting the ratio of the number of tokens in neighbors summary to those in neighbors keyphrases for all datasets combined. The figure indicates that the average number of tokens resulting from the KPE approach on the node neighbors text is a few times smaller that the ones from the summarization method. As a result, leveraging keyphrases leads to lower LLM API costs while still delivering competitive results compared to the summarization approach. In addition, for the KPE method, we use small encoder models for the generation of embeddings which is fast and lightweight, easily suitable for running on ordinary CPUs of today's laptops [23]."}, {"title": "5 Conclusions", "content": "Our paper focuses on graph encoding and LLM optimization for the node classification task on text-attributed graphs. We demonstrate that the information in the nodes neighborhood is efficiently represented by the right choice of keyphrases. In addition, we optimize the LLM prompt automatically by refining instructions and adding demonstrative examples to the prompt leveraging the DSPy optimization framework. We compare the performance of our approach, GraphiT, with three baselines across three public datasets. The results demonstrate that our approach has a better performance compared to other models that are based on LLM models in all experiments. While promising for optimizing LLMs in the node classification task, GraphiT falls short of the GNNs performance on two datasets, highlighting a key area for our future research. Strategies like incorporating more neighborhood information for a node and integrating LLMs with GNNs could help bridge this performance gap. Furthermore, we will extend our approach to other graph prediction tasks, including link prediction."}]}