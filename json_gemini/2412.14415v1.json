{"title": "DriveGPT: Scaling Autoregressive Behavior Models for Driving", "authors": ["Xin Huang", "Eric M. Wolff", "Paul Vernaza", "Tung Phan-Minh", "Hongge Chen", "David S. Hayden", "Mark Edmonds", "Brian Pierce", "Xinxin Chen", "Pratik Elias Jacob", "Xiaobai Chen", "Chingiz Tairbekov", "Pratik Agarwal", "Tianshi Gao", "Yuning Chai", "Siddhartha Srinivasa"], "abstract": "We present DriveGPT, a scalable behavior model for autonomous driving. We model driving as a sequential decision making task, and learn a transformer model to predict future agent states as tokens in an autoregressive fashion. We scale up our model parameters and training data by multiple orders of magnitude, enabling us to explore the scaling properties in terms of dataset size, model parameters, and compute. We evaluate DriveGPT across different scales in a planning task, through both quantitative metrics and qualitative examples including closed-loop driving in complex real-world scenarios. In a separate prediction task, DriveGPT outperforms a state-of-the-art baseline and exhibits improved performance by pretraining on a large-scale dataset, further validating the benefits of data scaling.", "sections": [{"title": "1. Introduction", "content": "Transformer-based foundation models have become increasingly prevalent in sequential modeling tasks across various machine learning domains. These models are highly effective in handling sequential data by capturing long-range dependencies and temporal relationships. Their success has been evident in natural language processing [16], time-series forecasting [31], and speech recognition [14], where sequential patterns play a crucial role. One of the key strengths of transformer-based models is their capacity to learn from large datasets including millions of training examples, enabling them to address complex tasks with increased model sizes, up to billions of model parameters.\nIn the context of autonomous driving, transformer-based models have demonstrated great success in behavior modeling [7, 22, 23]. Behavior modeling predicts future actions of traffic agents to support critical tasks such as planning and motion prediction. Unlike traditional machine learning approaches that may rely on handcrafted features or specific rules, transformers are effective at learning the underlying spatiotemporal dependencies of agent behavior from large-scale multimodal data.\nScaling up model and dataset sizes has been critical for recent advances in sequential modeling for text prediction [12], yet it remains an open question whether these scaling trends hold for the task of behavior modeling. Existing work is often limited by the training data or the model size, as summarized in Table 1.\nIn our work, we present a comprehensive study of scaling up data sizes and model parameters in the context of autonomous driving. Specifically, we train a transformer-based autoregressive behavior model on over 100 million high-quality human driving examples, ~50 times more than existing open-source datasets, and scale the model over 1B parameters, outsizing existing published behavior models.\nAs we scale up the volume of training data and the num-"}, {"title": "2. Related Work", "content": "2.1. Behavior Modeling\nBehavior modeling is a critical task in autonomous driving, which covers a broad spectrum of tasks including planning, prediction, and simulation. Taking multimodal inputs including agent history states and map information, behavior models predict the future states of these traffic agents, by reasoning agent dynamics [2, 24], interactions [10, 25], and driving environments [13, 15].\nAmong all learning-based models, transformers have gained popularity due to their capability to fuse multimodal inputs as encoders [9, 18, 30, 32] and modeling long-range temporal relationships as decoders [22, 23]. Despite the success of transformers in behavior modeling, existing literature is often restricted by the size of model parameters due to limited training data, which fail to capture the full scaling potential of transformer-based models. In our work, we scale up our transformer models to include billions of parameters, by training on a large-scale dataset including more than 100M driving demonstrations, and validate the scalability of transformer-based models in the context of autonomous driving.\n2.2. Large Transformer Models\nLarge transformers have demonstrated great success in sequential modeling tasks, by scaling up model parameters and data sizes [6, 12, 17, 29]. These scaling laws have pushed the boundary of many sequential modeling tasks including natural language processing [16], time-series forecasting [31], and speech recognition [14].\nRecent work has studied the scalability of behavior models in the context of motion prediction [22], planning [26], and simulation [8], yet these studies are either constrained by limited data size (up to a couple of million training examples), or focused on a few orders of magnitude in terms of data and model scaling, limiting the potential to draw statistically significant conclusions over a large scaling spectrum.\nIn this paper, we aim to study the scaling properties in terms of model parameters, data samples, and compute, across a much larger spectrum compared to prior work. More specifically, we target an autoregressive decoder architecture that has been proven to be both scalable as in the LLM literature and effective in generating accurate trajectories for traffic agents [22].\nBeyond autonomous driving, there exists a few relevant literature on building large transformer models for robotic tasks [19, 27], which share a similar transformer architecture as our work. Despite their successes, robotics models often share different input features and dynamic models, and operate in different environments, making them difficult to apply directly to driving tasks."}, {"title": "3. Behavior Model", "content": "We use a standard encoder-decoder architecture as our behavior model, as shown in Fig. 2. We use transformer-based models as our encoder and decoder backbones due to their scalability in sequential modeling tasks."}, {"title": "3.1. Problem Formulation", "content": "We model the problem as a sequential prediction task over the future positions of the target agent up to horizon T, by applying the chain rule at each step, conditioning on driving context information c and historical agent positions s:\n$P(s_{1:T}|c) = \\prod_{t=1}^{T} P(s_t|s_{0:t-1}, c)$.\n(1)\nThe context information includes target agent history states $C_{target}$, nearby agent history states $C_{nearby}$, and map states $C_{map}$. The historical agent information includes agent positions from previous historical steps, i.e. $s_{0:t-1}$ if we want to predict agent positions at step t.\nWe define \"state\" as a full kinematic state including position, orientation, velocity, and acceleration, which is commonly available in agent history observations, and \u201cposition\" as 2-D (x, y) coordinates to simplify the output space."}, {"title": "3.2. Scene Encoder", "content": "The encoder follows a standard transformer encoder architecture [23] that fuses all input modalities into a set of scene embedding tokens. It consumes raw input features, including target agent history states, nearby agent history states, and map states as a set of vectors, and normalizes all the inputs to an agent-centric view. Each vector is mapped to a token embedding through a PointNet-like encoder as in [4]. At the end of the encoder, we apply a self-attention transformer [28] to fuse all input context into a set of encoder embeddings, $c \\in R^{n \\times d}$, where n is the number of vectors and d is the token dimensions, that summarize the driving scene."}, {"title": "3.3. LLM-Style Trajectory Decoder", "content": "Inspired by the LLM literature [20], we follow [22] to use a transformer decoder architecture to predict the distribution of agent positions at each step in the future.\nThe decoder first tokenizes agent positions at all steps into embeddings with dimension d through a linear layer, followed by a LayerNorm layer and a ReLU layer. At each step t, the decoder takes agent embeddings up to t, and cross attends them with the encoder embeddings c to predict the distribution of agent positions at the next step t + 1.\nThe output is a set of discrete actions a represented as the Verlet action [21, 22], as the second derivative of positions. We can apply the following equation to map Verlet actions to positions:\n$s_{t+1} = s_t + (s_t - s_{t-1}) + a_t,$\n(2)\nwhere $a_t$ is the predicted Verlet action, and $(s_t - s_{t-1})$ is the estimated velocity. This representation helps predict smooth trajectories using a small set of action candidates."}, {"title": "3.4. Training", "content": "To train a DriveGPT model, we follow teacher forcing by applying ground truth future positions as inputs to the trajectory decoder. This allows us to predict all future steps in parallel.\nWe use a single cross-entropy classification loss over the action space, where the target action is selected as the one that is closest to the ground truth future trajectories. We refer the readers to the Appendix for more details."}, {"title": "3.5. Inference", "content": "At inference time, we follow a standard LLM setup and roll out a trajectory over horizon T autoregressively, by repeating the process of predicting the action distribution at the next step, sampling an action, and adding it back to the input sequence.\nWe sample multiple trajectories in batch to approximate the distribution and then subsample to the desired number of modes using K-Means, as in [22]."}, {"title": "4. Scaling Experiments", "content": "The goal of our scaling experiments is to determine the effect of model and data size on behavior prediction performance. Quantifying scaling laws similar to those seen in LLMs [12] can help prioritize the value of data and compute for future research directions in behavior modeling. We focus our effort on exploring the next frontier of model and data size over an order of magnitude beyond previously reported work.\nLarge-scale driving dataset From millions of miles of high-quality real-world human driving demonstrations, we curated a small subset of 120M segments for an internal research dataset. The dataset is balanced to cover diverse geographic regions from multiple cities and countries, and a variety of driving scenarios, such as passing a double-parked vehicle, unprotected left turns, construction zones, etc. We extracted map information, target agent states, and nearby agent states into vectorized representation, as customary in behavior modeling literature [4].\nWe scale the model size across three orders of magnitude, from 1.5 million to 1.4 billion parameters, by increasing the embedding dimension. For each model size, we explore multiple learning rate schedules and select the one that yields the best performance. Consistent with practices in large language model scaling [12], each model is trained for a single epoch.\nWe measure model performance through validation loss computed over a comprehensive validation set. We use validation loss as a proxy to measure model performance, following standard practices in scaling studies [6, 12, 17]. This loss, calculated as cross-entropy on next-action prediction, serves as our primary performance metric. Additional driving-specific metrics are reported in Sec. 5.1.1 and Sec. 5.1.2."}, {"title": "4.1. Data Scaling", "content": "Data scaling results are summarized in Fig. 3. The smallest dataset of 2.2M samples mimics the size of Waymo Open Motion Dataset (WOMD) [3], a large open-source dataset for behavior modeling (~44k scenarios with multiple target agents per scenario). Additionally, we select a few subsets of our internal research dataset to study data scaling across different orders of dataset sizes. Our experiments use ~50x more data than WOMD, exploring a new region of the design space.\nThe results indicate that as the model is trained on more unique data samples, the performance improves, regardless of model size. Extrapolating from the scaling law in Fig. 3, to improve the best loss by another 10%, we would need to include 200M more training examples. A 20% improvement would require about 900M more examples. As a result, we find that data remains to be the bottleneck for further improving driving performance.\nLastly, the scaling results remain relatively consistent across model sizes. This consistency indicates that data scaling comparisons can be done on reasonably small model sizes beyond 10M parameters."}, {"title": "4.2. Model Scaling", "content": "We now study model sizes across three orders of magnitude (1.5M to 1.4B parameters). We increase model size by increasing the hidden dimensions of transformers for simplicity. We notice that modifying other parameters such as number of attention heads and hidden dimensions per head do not lead to noticeable changes in the results.\nTraining larger models is sensitive to learning rates, as"}, {"title": "4.3. Compute Scaling", "content": "In Fig. 5, we examine how compute affects training loss, where compute is measured by Floating Point Operations (FLOPs). We identify a monotonically decreasing \"min-bound\" boundary, which shows the lowest training loss observed up to the current compute value. As we increase compute, training loss generally decreases. Initially, this decrease is quite steep, but it gradually slows down at higher FLOPs values. This trend is consistent with observations in the LLM scaling literature, such as those reported by [6], covering a subset of the full FLOP range explored in these studies.\nNext, we investigate if there is an optimal combination of model parameters and data size for a fixed compute budget. Given the large computational expense for training models at the scales we are exploring, it is important to make the best use of our data. In this study, we fixed the compute budget at different FLOP groups. For a fixed compute budget, we can allocate resources either to model parameters or data samples, keeping their product constant.\nFig. 6 plots performance with different compute budgets. The trend clearly shows that a larger compute budget leads to better performance, with optimal model size increasing accordingly, as indicated by the \"best\" gray line. The results further reveal that data is the main bottleneck, as the smallest model size performs best at the three largest FLOP groups."}, {"title": "4.4. Ablation Study on Decoder Architecture", "content": "We scale up two different model architectures by two orders of magnitude: our autoregressive decoder and a one-shot decoder. For the one-shot decoder, we follow [18] to use a transformer decoder that takes a set of learned queries and cross attends them with scene embeddings to produce trajectory samples. This decoder is referred to as \"one-shot\" because it generates the full trajectory rollout at once, where an autoregressive decoder follows an LLM-style to produce"}, {"title": "5. Planning and Prediction Experiments", "content": "In this section, we show detailed results of DriveGPT in a planning task using our internal research dataset and a motion prediction task using an external dataset. The results here further explore the impact of scaling from Section 4 and help ground those results in driving tasks and metrics."}, {"title": "5.1. Internal Evaluation: AV Planning", "content": "For the planning task, we train our model using our internal research dataset, composed of millions of high-quality human driving demonstrations, and generate AV trajectories by autoregressively predicting the next action, as described in Sec. 3.5.\nWe approximate the distribution by oversampling trajectories in batch and subsampling to 6 trajectories as in [22]."}, {"title": "5.1.1 Data Scaling Results", "content": "We compare a DriveGPT model at 26M parameters (near-optimal from Sec. 4) trained on datasets of different sizes. The baseline dataset (2.2M) is selected to mimic the training size of a typical behavior modeling dataset such as WOMD.\nThe results are presented in Table 2, where we see that training on more data samples significantly improves the quality of predicted AV trajectories, in terms of critical semantics metrics in driving including offroad rate and collision rate, as well as geometric metrics. These results are consistent with Sec. 5.1.1.\nWe further present two qualitative examples in Fig. 8 to illustrate the value of training on more data. In these examples, red trajectories represent DriveGPT trained on 120M samples, and pink trajectories are from the same model trained on 2.2M samples. The examples show that our method produces map-compliant and collision-free trajectories when trained on more data, successfully handling complicated interactions involving a jaywalking pedestrian and two double-parked vehicles."}, {"title": "5.1.2 Model Scaling Results", "content": "We train four models using our 120M internal research dataset, and select the 8M model as the baseline. The baseline represents a reasonable size at which our model starts"}, {"title": "5.1.3 Closed-Loop Driving", "content": "We demonstrate the effectiveness of DriveGPT as a real-time motion planner in a closed loop setting. The model takes input features from an industry-level perception system that outputs agent states and map information.\nIn Fig. 10, we present a challenging example in dense urban traffic where there are two double-parked vehicles blocking the path forward along with other oncoming vehicles. DriveGPT generates smooth and safe trajectories, bypassing the blocking vehicles and moving back to the original lane afterward. More examples are presented in the supplementary material."}, {"title": "5.2. External Evaluation: Motion Prediction", "content": "To directly compare with published results, we evaluate DriveGPT on the WOMD motion prediction task. Additionally, we explore the benefits of scale by pretraining on our internal research dataset and finetuning on the significantly smaller WOMD dataset."}, {"title": "5.2.1 Open-Source Encoder", "content": "For our external evaluation, we use the open-source MTR [23] encoder. This encoder is similar to the one described in Sec. 3.2. We make this change to improve the reproducibility of our results and take advantage of MTR's open-source dataloading code for WOMD. We use the same autoregressive decoder following [22], as described in Sec. 3.3."}, {"title": "5.2.2 Pretraining Setup", "content": "We made a couple of minor modifications to DriveGPT to be compatible with the WOMD dataset. First, we modify our map data to include the same semantics as in WOMD. Second, we modify our agent data to include the same kinematic features for traffic agents as in WOMD.\nWe pretrain DriveGPT by training on our internal research dataset for one epoch (as in Sec. 4). We load the pretrained checkpoint and finetune the model using the same training setup as in the MTR codebase [23], where we train the model for 30 epochs using a weighted decay learning rate scheduler."}, {"title": "5.2.3 Validation Results", "content": "We measure model performance via a set of standard WOMD metrics, including minADE (mADE), minFDE"}, {"title": "5.2.4 Data Scaling in Pretraining", "content": "We validate the effectiveness of data scaling, by pretraining DriveGPT on various sizes of our internal dataset. The results in Table 6 indicate that pretraining on more unique samples leads to better results in the finetuned model, aligning with our findings in Sec. 4.1 that data scaling improves model performance."}, {"title": "5.2.5 Test Results", "content": "We report results on the WOMD test set in Table 7. The results demonstrate that our method outperforms existing state-of-the-art non-ensemble models in terms of geometric metrics. Compared to Wayformer [18] and MotionLM [22] that use ensembles of up to 8 replicas, our model achieves the best minADE and minFDE metrics and the second-best miss rate metric without any ensembling. We observe lower Soft mAP\u00b9 scores from our method due to suboptimal probability estimates, as discussed in Sec. 5.2.3.\nConsistent with the results reported in Table. 4 and Table. 5, we observe additional gains by pretraining on our"}, {"title": "5.2.6 Qualitative Comparison", "content": "We present two qualitative comparisons in Fig. 11, where DriveGPT produces better trajectories in terms of diversity (covering more distinct outcomes) and accuracy (matching with the ground truth future) compared to MTR. This improvement is evident in challenging scenarios with limited agent history information (top row) and multiple future modalities (bottom row)."}, {"title": "6. Conclusion", "content": "We introduced DriveGPT, an LLM-style autoregressive behavior model, to better understand the effects of model and dataset size for autonomous driving. We systematically explored model performance as a function of both dataset size and model parameters, uncovering LLM-like scaling laws for data and compute scaling, along with limited model scaling properties. We showed the quantitative and qualitative benefits of scaling for planning in real-world driving scenarios. Additionally, we demonstrated our method on a public motion prediction benchmark, where DriveGPT outperformed a state-of-the-art baseline by a large margin and achieved improved performance through pretraining on a large scale dataset."}, {"title": "A. Training Detail", "content": "A.1. Internal Evaluation: AV Planning\nWe train our models on the internal research dataset for 1 epoch, as customary in the LLM scaling literature [6, 12].\nOur models follow the implementations described in [18, 22], and are trained using a batch size of 2048 and a standard Adam optimizer adopted in [12]. We follow the optimal learning rate schedule discovered in [6], which applies a cosine decay with a cycle length equivalent to the total number of training steps.\nA.2. External Evaluation: Motion Prediction\nWe train our models on the WOMD data following the same setup in [23]. More specifically, we use a batch size of 80 and an AdamW optimizer with a learning rate of 0.0001. The models are trained for 30 epochs, where the learning rate is decayed by a factor of 0.5 every 2 epochs, starting from epoch 20."}, {"title": "B. Scaling Detail", "content": "B.1. Scaling Configurations\nIn our scaling experiments, we vary the model size through the hidden dimension dmodel in both encoder and decoder transformers, as summarized in Table. 8. For each model size, we run multiple experiments at different maximum learning rates, and present the optimal value in Table. 8.\nB.2. Ablation Study on Attention Heads\nIn Fig. 12, we present an ablation study examining the impact of the number of heads in the encoder and decoder transformers, while keeping the hidden dimension the same, as specified in Table. 8. For each hidden dimension (dmodel), we conduct experiments across multiple configurations\u00b2 of attention heads and present their validation losses using a distinct color. While we notice a pattern where more decoder attention heads lead to better performance for small models, the scaling trend is more influenced by the hidden dimension size than by the number of attention heads when the hidden dimension remains fixed.\nB.3. Ablation Study on Decoder Scaling\nIn Fig. 13, we present model scaling results (in dashed lines) where we only scale up the autoregressive decoder, while keeping the encoder at a fixed size. Compared to scaling both encoder and decoder (in solid lines), scaling only the decoder exhibits a similar trend but yields worse performance, especially for models exceeding 10M parameters. Therefore, our main results focus on scaling both encoder and decoder."}, {"title": "B.4. Ablation Study on Encoder Scaling", "content": "In Fig. 13, we present model scaling results (in dotted lines) where we only scale up the encoder, while keeping the decoder at a fixed size. Similarly, scaling encoder leads to worse performance compared to scaling both encoder and decoder. Furthermore, the performance of scaling the encoder is worse than scaling the decoder."}, {"title": "B.5. Scaling From a Perplexity View", "content": "Following the LLM scaling literature, we present our scaling results as a function of validation loss. Another key aspect to highlight is the perplexity scale. Perplexity, defined as the exponentiation of entropy, quantifies how well a probability model predicts a sample. It reflects the effective number of choices the model considers: a perplexity of k implies the model is k-way perplexed.\nIn Fig. 14, we re-plot the scaling results, adding a secondary y-axis to represent perplexity. We observe that the perplexity decreases by approximately 4 each time the"}, {"title": "C. Additional Qualitative Examples", "content": "C.1. Additional Closed-Loop Driving Examples\nIn the supplementary video\u00b3, we present additional examples of using DriveGPT as a real-time motion planner in a closed loop setting. The video covers representative challenging scenarios in driving, including a) unprotected left turn, b) double parked vehicle, c) construction zone, d) blow-through cyclist, and e) lane change in heavy traffic.\nC.2. Failure Cases on WOMD\nWe show two representative failure examples of DriveGPT in Fig. 16, selected based on the largest minFDE regressions of our method compared to the MTR baseline on WOMD. In the first example (top row), our method fails to predict trajectories that make a left turn, likely due to the presence of a lane boundary. In the second example (bottom"}, {"title": "D. WOMD Model Scaling", "content": "We present an ablation study on model scaling using DriveGPT-WOMD in Table 9. The results show that the model performance continues to improve up to 14M parameters, with no further gains beyond this point due to the limited sample size in WOMD. Therefore, we choose to report the results from the 14M model in Sec. 5.2."}]}