{"title": "FissionVAE: Federated Non-IID Image Generation with Latent Space and Decoder Decomposition", "authors": ["Chen Hu", "Jingjing Deng", "Xianghua Xie", "Xiaoke Ma"], "abstract": "Federated learning is a machine learning paradigm that enables decentralized clients to collaboratively learn a shared model while keeping all the training data local. While considerable research has focused on federated image generation, particularly Generative Adversarial Networks, Variational Autoencoders have received less attention. In this paper, we address the challenges of non-IID (independently and identically distributed) data environments featuring multiple groups of images of different types. Specifically, heterogeneous data distributions can lead to difficulties in maintaining a consistent latent space and can also result in local generators with disparate texture features being blended during aggregation. We introduce a novel approach, FissionVAE, which decomposes the latent space and constructs decoder branches tailored to individual client groups. This method allows for customized learning that aligns with the unique data distributions of each group. Additionally, we investigate the incorporation of hierarchical VAE architectures and demonstrate the use of heterogeneous decoder architectures within our model. We also explore strategies for setting the latent prior distributions to enhance the decomposition process. To evaluate our approach, we assemble two composite datasets: the first combines MNIST and FashionMNIST; the second comprises RGB datasets of cartoon and human faces, wild animals, marine vessels, and remote sensing images of Earth. Our experiments demonstrate that FissionVAE greatly improves generation quality on these datasets compared to baseline federated VAE models.", "sections": [{"title": "Introduction", "content": "Generative models have attracted increasing attention in recent years due to their impressive ability to generate new data across various modalities, including images, texts, and audios [12, 28, 2]. As these models, like other deep learning systems, require substantial amounts of data, concerns regarding data privacy have elevated among regulatory authorities and the public. Unlike the traditional centralized learning paradigm, which collects all data on a single computer system for training, federated learning allows private data to remain on the owner's device. In this paradigm, local devices train models independently, and a central server aggregates these models without accessing the individual data directly. Although this distributed approach enhances privacy protection, it also introduces unique challenges not encountered in centralized systems. Since data remains distributed across various client devices, the training samples are not guaranteed to be identically distributed. This can lead to inconsistencies in learning objectives among clients, resulting in degraded performance when these models are aggregated on the server.\nIn the context of FL with non-IID data, generative models such as Generative Adversarial Networks (GANs) [6] and Variational Autoencoders (VAEs) [16] face additional challenges. These models involve sampling from a latent distribution, and the generator or decoder trained on client devices may develop differing interpretations of the same latent space. This discrepancy can lead to difficulties in maintaining a consistent and unified latent space, resulting in overlapping representations across models, shown in Figure 2. A further challenge arises from the role of the generator or decoder, which are tasked with mapping latent inputs to the sample space by synthesizing the shape, texture, and colors of images. Aggregating generative models trained on non-IID image data can produce artifacts that appear as a blend of disparate image types, because generators trained on non-IID local data capture the characteristics of varied visual features (shown in Figure 4). Specifically for GANs, another problem arises from local discriminators, which may provide conflicting feedback that hinders model convergence. With the limited data available in FL settings, discriminators can quickly overfit to the training samples [14]. If an updated generator from the server produces images of classes not present in a client's local dataset, the local discriminator might incorrectly label well-generated images as fake, simply because they do not match the local data distribution. This mislabeling can significantly impede the generator's ability to synthesize realistic images.\nExisting research on generative models for non-IID data in federated learning (FL) has primarily focused on GANs. MDGAN [8] proposes exchanging local discriminators among clients during training. This strategy allows discriminators to access a broader spectrum of local data, thereby avoiding biased feedback to the generator. The authors of [34] uses the local discriminator that gives the highest score to a generated sample to update the global generator, promoting the idea that local discriminators should only judge samples from familiar distributions. In [33], the authors aggregate generators at the group level for client groups sharing similar data distributions before performing a global aggregation, then the global generator is aggregated similar to [34]. Both [34] and [33] involve sending synthesized samples back to local clients, which could potentially increase the risk of compromising client data privacy.\nStudies employing VAEs solely for image generation purposes are less common. The works in [3] and [9] utilize VAEs to produce synthetic images that assist in training global classifiers. In [3], the global decoder generates minority samples for local classifiers by sampling from class means with added noise. The approach in [9] treats converged local decoders as teacher models and uses knowledge distillation to train a global generator on the server side without further local updates. While this decoder can produce useful samples for classification tasks, it risks overfitting to the potentially flawed output from local decoders and lacks generative diversity, which is crucial for high-quality image generation. Recent studies [1, 25] have shown that generative models trained on generated samples instead of real data are prone to collapsing.\nIn response to the challenges posed by non-IID data in federated image generation, we introduce a model named FissionVAE. This model is specifically tailored to environments featuring multiple groups of images of different types. To mitigate the problem of mixed latent space interpretation, FissionVAE decomposes the latent space into distinctive priors, effectively managing the diversity of data distributions across different image types. We further refine this approach by investigating strategies for encoding the prior Gaussians. Additionally, to prevent the blending of unrelated visual features in the generated outputs, FissionVAE employs tailored decoder branches for each client group. This method not only accommodates the unique characteristics of each data subset but also enhances the model's generative capabilities in highly heterogeneous environments. The primary contributions of our research are detailed as follows:\n1. We introduce FissionVAE for federated non-IID image generation. In FissionVAE, we decompose the latent space according to the distinct data distributions of client groups. This approach ensures that each client's data are mapped to its corresponding latent distribution without the adverse effects of averaging dissimilar distributions during aggregation. Moreover, by implementing separate decoder branches for different groups of data, FissionVAE allows for specialized generation tailored to different image types, which is crucial for preserving the distinct visual features of different image types during the generative process.\n2. We explore various strategies for encoding Gaussian priors to enhance the effectiveness of latent space decomposi-tion. We further extends FissionVAE by introducing the hierarchical inference architecture. We demonstrate that with the decomposed decoder branches, it is feasible to employ heterogeneous decoder architectures in FissionVAE, allowing for more flexible model deployment on clients.\n3. We validate FissionVAE with extensive experiments on two composite datasets combining MNIST with Fash-ionMNIST, and a more diverse set comprising cartoon and human faces, animals, marine vessels, and remote sensing images. Our results demonstrate improvements in generation quality over the existing baseline federated VAE.\nThe remainder of the paper is organized as follows: Section II reviews existing work related to generative models in federated learning. In Section III, we begin by outlining the preliminaries of Federated Averaging, followed by a detailed discussion of the baseline FedVAE model and the FissionVAE variants we propose. Section IV presents the experimental setup, including the configuration details and an analysis of the results. Finally, we conclude the paper in Section V with a summary of our findings and a discussion on potential future directions."}, {"title": "Preliminaries", "content": ""}, {"title": "Federated Averaging", "content": "Federated Averaging (FedAvg) [19] is the most commonly used algorithm for federated learning tasks. In FedAvg, the central server first distribute the initialized model to clients, ensuring that all clients starts local training with the identical model parameters. Clients train their models with local data for specified local epochs, then return their models to the central server. The central server aggregates collected client models by taking the weighted average of these models:\n$\\Wr = \\sum_{i=1}^{S} \\frac{N_i}{N_s} W_i$ (1)"}, {"title": "Variational Autoencoders", "content": "VAEs are a class of generative models designed to approximate the probability p(x) of the observed data x, which is typically intractable. Central to the optimization of VAEs is the concept of evidence lower bound (ELBO), which provides a tractable objective by bounding the logarithm of p(x) through Jensen's inequality. The ELBO is defined as follows:\n$\\log p(x) = \\log \\int \\frac{p(x,z)q_{\\phi}(z|x)}{q_{\\phi}(z|x)}dz \\geq E_{q_{\\phi}(z|x)} \\log \\frac{p(x, z)}{q_{\\phi}(z|x)} = ELBO$ (2)\nwhere $q_{\\phi}(.)$ is the encoder parameterized by $\\phi$, and z denotes the latent code derived from the input data x. The ELBO can be further decomposed into the following terms by splitting the logarithm,\n$ELBO = E_{q_{\\phi}(z|x)}[\\log p_{\\theta}(x|z)] - D_{KL}(q_{\\phi}(z|x)||p(z))$ (3)\nHere, $p_{\\theta}(.)$ is the decoder parameterized by $\\theta$. The first term of the ELBO represents the expected log-likelihood of the data reconstructed from the latent code z. The second term is the Kullback-Leibler divergence between the encoded distribution $q(z|x)$ and a predefined prior distribution p(z).\nDuring training, the encoder $q$ estimates the latent code z based on the input data x, aiming to align this estimate with the prior distribution p(z). The decoder $p_{\\theta}$ then attempts reconstruct the original input x from the estimated z. The decomposition above indicates that training objective for VAEs is optimizing both the quality of data reconstruction and adherence to the latent space structure. In the generation phase, new data instances are produced by sampling from the prior distribution p(z), which are then transformed solely by the decoder into the data space."}, {"title": "Variational Autoencoders in Federated Learning", "content": "Following the discussion on the ELBO, we note that in a centralized setting, we maximize the expectation of the reconstruction likelihood across all data, as presented in Equation 3. In contrast, federated learning distributes the training samples x are split into subsets {x1 U X2 U... U Xn} across n clients. A common assumption in federated learning is that client data are not identically distributed, yet they are independent. Furthermore, we assume that client data are conditionally independent given the latent codes z, such that $p(x_i|z, x_j) = p(x_i|z), i \\neq j$. This leads to the following factorization,\n$P(x_1,..., x_n|z) = p(x_1|z)p(x_2|x_1, z)p(X_3, ..., x_n|z) \\newline = \\prod_{i=1}^n P(x_i|z)$ (4)\nTherefore, the reconstruction likelihood in the ELBO under the federated assumption can be expressed as:\n$\\log p_{\\theta}(x|z) = \\sum_{i=1}^n \\log p_{\\theta} (x_i|z)$ (5)\nEquation 5 suggests that when training VAEs within the federated learning framework, we can independently maximize the ELBO on each client. Local VAEs are then aggregated through algorithms such as FedAvg to maximize the global ELBO.\nRegarding existing research on federated VAEs for image generation, the work in [5] shows that VAEs can generate handwritten digit images within an FL framework and [20] focuses on incorporating differential privacy into the training process of federated VAEs for image generation. In [3], the authors integrate a federated VAE into the main classification task to help clients balance their local data. This involves training a global VAE where the encoder finds the average latent representation of local classes, these representations are then sent to the central server. When needed, the global decoder and collected latent representations are distirbuted to clients for image generation. The work in [9] aims at one-shot federated learning for classification tasks, where the server distributes the initialized model and only collects the converged local models without further updates. Here, the VAE is used as a data generator to create a balanced training set through knowledge distillation from local decoders. As discussed in Section I, while effective for classification tasks where balancing the training dataset is paramount, the lack of real data exposure and a cohesive latent space constructed by an encoder challenges the utility of this approach in producing high-quality images."}, {"title": "Investigating Strategies for Non-IID Image Generation with VAEs", "content": "In this section, we describe our methodology for exploring VAE configurations tailored for generating images under non-IID conditions in a federated learning framework. We specifically address scenarios where clients are categorized based on distinct data distributions. For illustrative purposes, we consider a case where some clients exclusively possess hand-written digits from the MNIST dataset, while others maintain only clothing images from the FashionMNIST dataset. We follow to the standard federated learning framework, wherein a central server is tasked with aggregating updates from the clients and subsequently distributing the updated model back to them. Each client retains a subset of data representative of its respective group and conducts local training independently. A more complex scenario with RGB images and a larger number of client groups is explored and discussed in the experimental section (Section IV). We summarize the explored strategies in Table 1."}, {"title": "FedVAE", "content": "A straightforward strategy for implementing VAEs in federated learning is using a unified encoder-decoder architecture. In this configuration, all clients share a common latent space (often predefined as the normal distribution $\\mathcal{N}(0,1)$) and the central server indiscriminately aggregates client models at the end of each training round. Fig. 1 illustrates this training scheme.\nDespite the simplicity of this strategy, it present significant challenges in the non-IID scenario. Specifically, employing a single prior distribution for the latent space does not account for the distinct data distributions across different clients. Encoders from different client groups may map their uniquely distributed data into the same region of the latent space. Consequently, client decoders might interpret this shared latent space differently, leading to inconsistencies or even conflicts among client models during aggregation at the server. Figure 2 shows randomly selected reconstruction and generation samples produced after training the federated Vanilla VAE on the combined dataset of MNIST and FashionMNIST. These samples clearly exhibit artifacts that appear to blend features of handwritten digits with clothing items, indicating the aggregation conflicts inherent in this method."}, {"title": "FissionVAE with Latent Space Decoupling", "content": "To address the conflicting latent space issue identified above, we propose decomposing the latent space according to different data groups, while maintaining a unified architecture for the encoder and decoder. This approach corresponds to FissionVAE+L in Table 1 and its architecture is shown in Fig. 3.\nSpecifically, the encoder maps the input data to different distributions based on the client's group. For instance, MNIST client may map to $\\mathcal{N}(-1,1)$ and FashionMNIST clients to $\\mathcal{N}(-1,1)$. The KL divergence in the ELBO for this model is given by:\n$D_{KL}(\\mathcal{N}(\\mu_q, \\sigma_q||\\mathcal{N}(\\pm 1,1)) = \\frac{1}{2} \\sum_{i=1}^{k}[\\sigma_q^2 + \\mu_q^2 = 2\\mu_q \\pm 1 - \\log \\sigma_q^2]$ (6)\nHere, $\\mu_q$ and $\\sigma_q$ represent the encoder's estimates for the parameters of the latent code's distribution, and k is the dimension of the latent code.\nFigure 4 shows reconstruction and generation samples produced after training the FissionVAE with latent space decomposition on the Mixed MNIST dataset. While the quality of reconstructed images are greatly improved compared to the baseline FedVAE, the generated images still exhibit a mixture of handwritten digits and clothing items, even when explicitly sampling from their respective latent distributions. This suggests that while decomposing latent encoding helps improving reconstructions, the unified decoder still blends features due to the aggregation of model weights from diverse visual domains. This observation motivates the architecture described in the next section, where the decoder is also split based on client groups."}, {"title": "FissionVAE with Group-specific Decoder Branches", "content": "Non-Hierarchical FissionVAE Building on the concept introduced by FissionVAE with latent space decomposition, we further refines non-IID data generation by incorporating decoder branches specific to each data group while maintaining a unified encoder. This design allows the central server to aggregate the encoder updates agnostically of the client groups, whereas decoder branches are aggregated specifically according to their corresponding groups. In addition, this approach also offers flexibility in the choice of the prior latent distribution p(z), which can be identical across groups or defined uniquely for each group to exert more explicit control over the data generation through the decoder. In scenarios where p(z) are identical for all groups, although the encoder projects different samples into the same latent space, group-specific decoders ensure that the latent space is interpreted independently. Nevertheless, we find that the uniquely defined priors result in better generation quality as the number of client groups increases. Figure 5 illustrates this branching architecture which corresponds to FissionVAE+L+D in Table 1.\nFigure 6 shows randomly selected reconstruction and generation samples produced after training the Fission VAE with decoder branches on the combined dataset of MNIST and FashionMNIST. The results indicate a significant reduction in the blending feature issue in previously discussed VAE architectures.\nHierachical FissionVAE Next, we show that the branching architecture can be enhanced by integrating hierarchical inference [15, 27] to the federated learning framework, which enables the use of deeper network structures to capture more complex data distributions. Fig 7 depicts the FissionVAE with two levels of hierarchical inference, which is the FissionVAE+L+D+H configuration in Table 1. In this architecture, the first encoder module estimates $q(z_1|x)$ from the input data, then the second encoder module estimates $q(z_2|z_1)$ based on the first level latent code. The decoder reverses the encoding process, which estimates $p(z_1|z_2)$ based on $z_2$ to reconstruct $z_1$, and subsequently reconstructs the original input x by estimating $p(x|z_1)$.\nFollowing the convention in hierarchical VAEs, we assume conditional independence among the latent codes, where the encoding and decoding processes can be defined as follows:\n$q(z_1, z_2|x) = q_{\\phi}(z_1|x)q(z_2/z_1)$ (7)\n$p(x, z_1, z_2) = p(z_2)p_{\\theta}(x|z_1)p_{\\theta}(z_1|z_2)$ (8)\nThe ELBO for this hierarchical VAE is expressed as,\n$ELBO_H = E_{q_{\\phi}(z_1|x)}[\\log p_{\\theta} (x|z_1)] \\newline - E_{q_{\\phi}(z_1|x)}[D_{KL}(q_{\\phi}(z_2|z_1)||p(z_2))] \\newline - E_{q_{\\phi}(z_2|z_1)}[D_{KL}(q_{\\phi}(z_1|x)||p_{\\theta}(z_1|z_2)]$ (9)\nIn the equation above, the first term is the reconstruction term as it is the expectation of the log-likelihood for the input samples under the distribution estimated from the encoded $z_1$, the second term is the prior matching term which is enforcing the encoded $z_2$ to conform the prior distribution $z_2 \\sim \\mathcal{N}(0, 1)$, and the last term is the consistency term which requires $z_1$ from either the encoder or the decoder to be consistence. In practice, we find that adding the reconstruction loss from $z_2$ to x is also crucial for generating meaningful samples. Optionally, perceptual losses such as the VGG loss [18] or the structural similarity index measure (SSIM) [30] loss can be used to promote the fidelity of reconstructed images. However, no significant improvement is observed in our experiments. Therefore no perceptual loss is included in our implementation. The final loss function for the hierarchical and branching FissionVAE then becomes,\n$\\mathcal{L} = E_{q_{\\phi}(z_1|x)}[D_{KL}(q_{\\phi}(z_1|x)||p(z_1))] \\newline - E_{q_{\\phi}(z_2/z_1)}[\\log p_{\\theta}(x|z_1, z_2)] - ELBO_H$ (10)\nwhere we minimize the KL divergence for $z_1$ only when the prior distribution for $z_1$ is defined, otherwise this term is zero and the estimation for $z_1$ is constrained by the latent matching term in Equation 6.\nThe proposed hierarchical Fission VAE also allows heterogeneous decoder architectures for each client groups, as each decoder branch is trained and aggregated independently. This flexibility is particularly advantageous in federated learning environments, where clients often possess varying computational resources. Client groups with more resources can implement deeper and more complex network structures, while groups with limited computational capacity can utilize lighter models."}, {"title": "Experiments", "content": ""}, {"title": "Datasets and Evaluation Metrics", "content": "The experiment setup for federated image generation is summarized in Table 2. We constructed two composite datasets to evaluate the performance of the proposed federated VAEs. The first dataset Mixed Mnist combines MNIST [17] and FashionMNIST [32]. These two datasets consists of images of handwritten digits from 0 to 9 and 10 classes of various clothing items, respectively. Images from these two datasets share a common size of 28 \u00d7 28 pixels, and we retain this size for generation and evaluation purposes. In addition, each dataset contains 60,000 training samples and 10,000 test samples. We divided training samples into two client groups, one for each dataset, with each group comprising 10 clients. The training samples were randomly and evenly distributed among the clients within each group. For evaluation, we used the default test samples from both MNIST and FashionMNIST to approximate the true data distribution. We generated an equal number of samples from the global model on the central server to evaluate performance.\nIn contrast to the Mixed MNIST dataset, which primarily serves proof-of-concept purposes, we constructed a second, more complex and realistic composite dataset named CHARM, encompassing five distinct datasets: Cartoon faces from the Anime Face Dataset [4], Human faces from CelebA-HQ [13], Animals from Animals with Attributes 2 (AwA2) [31] with 50 classes, Remote sensing images of 10 land types from EuroSAT-RGB [10], and Marine vessels from MARVEL [7] with 26 classes. For AwA2 and MARVEL, we used preprocessed square images from Meta-Album [29]. All images in this composite dataset are resized to 32\u00d732 pixels for generation and evaluation. We established 20 clients for each of the five groups in CHARM. We utilized 20,000 randomly selected images from these datasets for training, with an additional 5,000 images from each used for evaluation. As with Mixed MNIST, we generated a number of images equal to the evaluation set using the global model for performance evaluation.\nOn the Mixed MNIST dataset, the encoder and decoder for all VAEs only consists of Multi-layer Perceptrons (MLP). For models trained on CHARM, the encoder $q(z_1|x)$ and the decoder $p(x|z_1)$ are primarily convolutional with MLP used for latent variable estimation. The encoder $q(z_2|z_1)$ and the decoder $p(z_1|z_2)$ are MLPs. Bernoulli distribution is used to determine whether or not a client participate in current training round. For the Mixed MNIST dataset, we set the distribution to B(0.5), indicating a 50% chance of participation. For CHARM, we adjusted the participation rate to B(0.25), meaning approximately 25 out of 100 clients participate in each training round. Regarding the hyperparameters for training, we use a learning rate of 1 \u00d7 10-\u00b3 for the Mixed MNIST and 1 \u00d7 10-4 for the CHARM dataset. The total number of training rounds is 70 on Mixed MNIST and 500 on CHARM. For both datasets, client update local models for 5 epochs with a batch size of 32. In the centralized setting, the number of training epochs on Mixed MNIST is 70 and 250 for CHARM. Other hyperparamters are kept the same as the federated configuration."}, {"title": "Results and Analysis", "content": "We conduct four sets of experiments on the Mixed MNIST and CHARM dataset. In the first experiment, we evaluate the overall generative performance of the proposed VAE architectures in both federated and centralized settings. The second experiment focuses on the hierarchical VAE's ability to control the generation process through explicit definition of the prior distributions for $z_1$. The hierarchical model allows for multiple generation pathways. For instance, one pathway involves sampling $z_2$, passing it through the decoder $p(z_1/z_2)$, and then generating the final image with $p(x|z_1)$. Alternatively, we could directly sample $z_1$ and generate the image through $p(x|z_1)$. We compare the performance of these different generation pathways to assess their impact on the quality of generated images. Following the discussion on how $z_1$ affects the generation performance, we explore various strategies for defining $z_1$'s prior distribution and assess the quality of generated images following the pathway $z_2 \\rightarrow z_1 \\rightarrow x$. Lastly, we showcase the use of heterogeneous decoder architectures in the proposed federated VAE and the effects of pixel modeling methods."}, {"title": "Overall Performance", "content": "The overall performance of the proposed FissionVAE models is summarized in Table 3, and generated examples are shown in Fig. 8. As a baseline, a Deep Convolutional GAN (DCGAN) [21] trained via FedGAN [22] is used for comparison. Since GAN does not directly model the likelihood of data, NLL is not evaluated for FedGAN. Also, FedGAN on CHARM suffers from sever mode collapse (shown in Fig. 9), therefore performance evaluation is not available on this dataset. Notably, the performance of all models on the CHARM dataset was less robust compared to the Mixed MNIST dataset. This discrepancy arises because the CHARM dataset, encompassing colorful images from diverse domains, presents a more complex and realistic federated learning scenario. The dataset's diversity, coupled with a lower local data availability and participation rate among clients, poses greater challenges to federated generative models.\nLatent Space Decoupling vs Decoder Branches Across the datasets and learning paradigm, we observe the trend that adopting latent space decoupling or group-specific decoder branches improves the quality of generated images with lower FID and higher IS. We can also tell from Table 3 that the creating decoder branches alone brings more performance improvement compared to sole latent space decoupling, showing that mixing decoders trained on non-IID data can severely affect image generation.\nAmong the proposed VAE configurations, the model FissionVAE+L (L for decoupled latent space) demonstrates a slight improvement over the baseline FissionVAE. This model adapts the latent space to the non-IID nature of nature of federated data by partitioning it according to client groups. This partitioning not only informs the decoder of the expected data characteristics more effectively but also helps to prevent the overlap of data representations from different domains. The effect of latent space decoupling can be also observed in Fig. 8. Compared to the baseline FedVAE, Fission VAE+L allows for directly sampling the latent codes specific to each client group, showing more intra-group difference in generated images. However, as the decoders in Fission VAE+L are mixed during the aggregation phase, this mixing results in noticeable artifacts that resemble overlapping images from different domains, such as creating contours of faces for latent codes sampled from marine vessels' distribution.\nFission VAE+D (D for decoder branches) greatly alleviates the problem of overlapping features. The Fission VAE+D architecture consists of a unified encoder and decoder branches for individual client groups. The unified encoder acts as a routing mechanism similar to that in a Mixture of Expert (MoE) framework, directing data to the appropriate latent distributions based on its domain. During model aggregation, these decoders among different client groups remain distinct, ensuring that textural features from different domains do not mix, thus producing cleaner and more discernible images as shown in Fig 8.\nFissionVAE+L+D is the architecture for combining both latent space decoupling and decoder branches, Table 3 shows that there is little gain on the Mixed MNIST dataset while the generative performance is further improved on the CHARM dataset. Enforcing latent space decoupling on FissionVAE+D even lowers the performance on FID. We argue that the main reason for this is the number of client groups. As there are only two groups in Mixed MNIST, decoder branches alone is sufficient for the VAE to differentiate samples from different groups. However, as the number of client groups increases, explicit latent space decoupling provides more direct signal to the VAE about the intra-group difference, allowing the model to better capture the data distribution for different groups. In Fig. 8 it can be observed that images generated by FissionVAE+L+D are sharper than the ones generated by FissionVAE+D.\nHierarchical Fission VAE As discussed in Section III, here we consider a hierarchical VAE with two levels of latent variable. In Table 3, the architecture FissionVAE+H+L+D performs the best on the CHARM dataset and falls behind its non-hierarchical counterpart on the Mixed MNIST dataset. The hierarchical VAE employs multiple levels of latent representations, which refines the model's ability to capture and reconstruct complex data distributions more faithfully. The performance degradation on simpler datasets like Mixed MNIST suggests that the hierarchical approach might introduce unnecessary redundancy without proportional gains in performance."}, {"title": "Decoupling the Prior of z1", "content": "As shown in Table 3, explicitly decoupling the latent space for different client groups can improve the VAE's ability to generate images that better reflect the true data distribution. We explore various approaches to define the prior for the latent distribution, all of which are assumed to be multivariate Gaussians with customizable means and the identity matrix as their fixed covariance matrices. The definition of investigated priors are listed in Table 4, and their evaluation results are presented in Table 5.\nFor the non-hierarchical VAE, there is a single latent variable $z_1$. In the two-level hierarchical VAE, we control only the first-level latent variable $z_1$, while the prior distribution for $z_2$ remains a standard normal distribution $\\mathcal{N}(0, 1)$. Regardless of the hierarchical architecture, the \"identical\" approach in Tables 4 and 5 serves as a baseline with no latent space decoupling, where the prior distributions are identical for all client groups and are defined as the normal distribution. The \"one-hot\" approach assigns one-hot encoded vectors as the means of $z_1$ across different client groups. In the \"symmetrical\" approach, the means of $z_1$ are set to positive and negative integers symmetrical to zero. For instance, the means for groups 1 and 2 are \u00b11, respectively, and for groups 3 and 4, they are \u00b12, and so on. The \"random\" approach involves sampling random vectors from a normal distribution as the means of $z_1$ for each client group. The \"wave\" strategy extends the one-hot encoding by including more ones. Specifically, the dimension of $z_1$ is evenly divided based on the number of client groups. The j-th division is set to 1 for the j-th client group, with the rest of the dimensions being zero. Finally, the \"learnable\" approach is unique to hierarchical VAEs, arising from the prior matching term between the encoded and decoded $z_1$ in Equation 6. This allows the model to learn to align the prior for each client group, but we lose the ability to directly sample from $z_1$ for the controlled generation process. In contrast, other approaches also need to optimize the KL divergence between the encoder's output $q_{\\phi}(z_1|x)$ and the defined prior $p(z_1)$ in addition to the prior matching divergence.\nFrom Table 5, we observe that when predefined priors are enforced on $z_1$, hierarchical FissionVAE generally un-derperforms compared to the non-hierarchical FissionVAE. This performance disparity may stem from the increased uncertainty in the latent space introduced by the hierarchical structure. Specifically, the presence of multiple latent layers in hierarchical VAEs introduces more stochasticity, which, coupled with limited local training samples and non-IID global data, causes greater variance in latent representations across different clients. This variance often results in degraded generation quality. Notably, the hierarchical VAE achieves optimal performance with a learnable approach for $z_1$, where no fixed prior distribution is enforced. This flexibility allows the model to adapt the latent space dynam-ically, enhancing generation quality. However, implementing a similar learnable approach in non-hierarchical VAEs is impractical as the ELBO formulation in Equation 2 requires the latent distribution to match the predefined prior.\nOn the Mixed MNIST dataset, employing the identical approach, where a standard normal distribution is used across all client groups, yields the lowest FID for the non-hierarchical VAE but performs poorly on the CHARM dataset. This outcome suggests that for simpler datasets with only two client groups, creating decoder branches alone is adequate for generating distinct samples from different data distributions. However, as the number of client groups increases, a more explicit latent encoding can better guide the model to capture complex data distributions. The identical approach shows diminished performance on both datasets in the hierarchical VAE context. This issue likely arises from the inference hierarchy of the latent variables. Since $z_2$ is estimated by the encoder $q_{\\phi}(z_2|z_1)$, sampling $z_1$ from the same distribution across different client groups can introduce contradictions in the latent space.\nThe symmetrical approach, where the mean of $p(z_1)$ is set as the positive or negative integer of the group index, can lead to severe model divergence on the CHARM dataset. As the number of client groups increases, this strategy results in means for $p(z_1)$ that far exceed the initialized values of the neural network, challenging the model's ability to converge, particularly for client groups with large means. The one-hot and random approaches show comparative performance but it falls behind the wave approach in terms of the consistency of lower FID on both datasets. Both the one-hot and random approaches exhibit comparative performance, yet they fall behind the wave approach in terms of consistently lower FID across both datasets. The wave approach offers a clearer distinction between the prior distributions for different client groups. Moreover, since all non-zero elements in the wave approach are 1's, it avoids the out-of-range value problem observed with the symmetrical approach."}, {"title": "Generation Pathways in Hierarchical Fission VAE", "content": "Following the discussion on decoupling the latent space of $z_1$ by defining prior distributions for individual client groups, we can now sample from either $q(z_1)$ or $p(z_2)$ to produce generated samples. There are two possible generation pathways for $z_1$. The first involves treating random samples from the prior distribution as outputs from the encoder $q_{\\phi}(z_1|x)$, which are then passed to the encoder $q_{\\phi}(z_2|z_1)$ for further processing before the hierarchical decoder outputs the final generated samples. The second pathway treats $z_1$ samples as outputs from the decoder $p_{\\theta}(z_1|z_2)$, directly generating image samples from the final decoder $p_{\\theta}(x|z_1)$. The pathway for $z_2$ follows that of non-hierarchical VAEs, involving only the decoders in the generation process. We list the discussed pathways and their evaluation results in Table 7, and the prior distributions of $z_1$ are defined with"}]}