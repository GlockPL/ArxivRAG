{"title": "Interlocking-free Selective Rationalization Through Genetic-based Learning", "authors": ["Federico Ruggeri", "Gaetano Signorelli"], "abstract": "A popular end-to-end architecture for selective rationalization is the select-then-predict pipeline, comprising a generator to extract highlights fed to a predictor. Such a cooperative system suffers from suboptimal equilibrium minima due to the dominance of one of the two modules, a phenomenon known as interlocking. While several contributions aimed at addressing interlocking, they only mitigate its effect, often by introducing feature-based heuristics, sampling, and ad-hoc regularizations. We present GenSPP, the first interlocking-free architecture for selective rationalization that does not require any learning overhead, as the above-mentioned. GenSPP avoids interlocking by performing disjoint training of the generator and predictor via genetic global search. Experiments on a synthetic and a real-world benchmark show that our model outperforms several state-of-the-art competitors.", "sections": [{"title": "1 Introduction", "content": "Selective rationalization is the process of learning by providing highlights (or rationales) as explanation, a type of explainable AI approach that has gained momentum in high-stakes scenarios (Wiegreffe and Marasovic, 2021), such as fact-checking and legal analytics. Highlights are a subset of input texts meant to be interpretable by a user and faithfully describe the inference process of a classification model (Herrewijnen et al., 2024). Among the several contributions, the select-then-predict (SPP) selective rationalization framework of Lei et al. (2016) has gained popularity due to its inherent property of defining a faithful self-explainable model. In SPP, a classification model comprises a generator and a predictor. The generator generates highlights from input texts, i.e., it selects a portion of input text tokens, which are fed to the predictor to address a task. To define interpretable highlights, the generator performs discrete selections of input tokens while regularization objectives control the quality of generated highlights.\nThis discretization process introduces an optimization issue between the generator and the predictor, hindering training stability and increasing the chances of falling into local minima, a phenomenon denoted as interlocking (Yu et al., 2021). To account for this issue, several contributions have been proposed to facilitate information flow between the generator and predictor and avoid overfitting on sub-optimal highlights. Notable examples include differentiable discretization via sampling (Bao et al., 2018; Bastings et al., 2019), weight sharing between generator and predictor (Liu et al., 2022), and external guidance via soft rationalization (Yu et al., 2021; Huang et al., 2021; Sha et al., 2023; Hu and Yu, 2024). However, these methods only mitigate interlocking by introducing ad-hoc regularization.\nA few attempts have been proposed to eliminate interlocking. These solutions either rely on feature-based heuristics to pre-train the generator (Jain et al., 2020) or partially address interlocking by introducing multiple independent training stages (Li et al., 2022). However, these methods present several limitations, including the use of heuristics for guiding the generator, limited information flow between the generator and the predictor, and introduce additional optimization issues.\nWe propose Genetic-SPP (GenSPP), the first selective rationalization framework that eliminates interlocking without requiring heuristics and architectural changes. GenSPP breaks interlocking by splitting the optimization process into two stages, optimized via genetic-based search. First, a generator instance is defined independently of a given predictor. Second, a predictor is trained from scratch while keeping the defined generator frozen. Genetic-based search allows for local and global exploration of the generator's parameters, significantly reducing the risk of getting stuck into local"}, {"title": "2 Preliminaries", "content": "We overview two fundamental concepts to understand our method: (i) selective rationalization and (ii) genetic-based search."}, {"title": "2.1 Selective Rationalization", "content": "Selective rationalization denotes a self-explainable classification model capable of extracting discrete highlights from an input text. The typical architecture for selective rationalization is based on the select-then-predict (SPP) architecture (Lei et al., 2016). In SPP, the classification model is split into a generator ($g_\\theta$) and a predictor ($f_\\omega$), where $\\theta$ and $\\omega$ are the parameter sets. Given an input text $x = \\{x_1,x_2,...,x_n\\}$ comprising $n$ tokens and its corresponding ground-truth label $y$, the generator $g_\\theta$ produces a binary mask $m = g_\\theta(x) = \\{m^1,m^2,...,m^n\\}$ where $m^i \\in \\{0, 1\\}$. The mask"}, {"title": "2.2 Genetic Algorithms", "content": "Genetic Algorithms (GAs) constitute a class of search algorithms for finding optima in optimization problems. They are based on population-based search relying on the concept of survival of the fittest (Katoch et al., 2021). Formally, a population $P$ contains a set of $I$ individuals, $P = \\{c_1, c_2, ..., c_I\\}$, where each individual $c \\in R^d$ is a parameter vector representing a candidate solution to the problem of interest.\nInitially, a population $P_0$ of $I$ individuals is initialized randomly to cover the solution search space. The individuals are evaluated by a fitness function $h : R^d \\rightarrow R$ that is the optimization objective of GAs. A portion of individuals is then selected based on their fitness scores with selection probability $p_{sl}$. An intermediate population $P_0'$ is built by generating individuals from selected ones, either by modifying a portion of individual parameters (mutation) or by mixing parameters between individual pairs (crossover). We denote $p_m$ and $p_c$ the mutation and crossover probabilities, respectively. The population for the next iteration $P_1$ is built by performing a second individual selection phase, denoted as survival selection, to keep the number of individuals equal to $I$ across generations. We denote $p_{su}$ the survival probability of each individual. The population-based search is iterated for $G$ generations or stopped preemptively if a certain fitness score is reached.\nNeuroevolution. GAs have been successfully applied to solve a wide variety of tasks (Alhijawi and Awajan, 2024), including image processing, scheduling, clustering, natural language processing, and, in particular, neural network optimization, known as neuroevolution (Galv\u00e1n and Mooney, 2021). Neuroevolution denotes the process of (i) neural network architecture search and (ii) parameter optimization by employing genetic algorithms. In the second scenario, each individual $c$ in a population $P$ denotes the parameters of a neural network. In addition to having interesting properties, such as parallel computation and reduced likelihood of getting stuck into local minima, neuroevolution also shows correspondence with gradient descent, as proved by Whitelam et al. (2021)."}, {"title": "3 Related Work", "content": "Lei et al. (2016) introduce Rationalizing Neural Predictions (RNP), the first SPP framework, whereby the generator and predictor components are trained via reinforcement learning (Williams, 1992). Several contributions have explored ways to improve RNP, including end-to-end optimizations, external guidance to mitigate spurious correlations, regularizations for faithful rationalization, and attempts to break interlocking.\nImproved Optimization. Bao et al. (2018) propose an end-to-end architecture by leveraging the Gumbel softmax trick (Jang et al., 2017) for generating differentiable discrete masks $m$. Similarly, Bastings et al. (2019) adopt rectified Kumaraswamy distributions to replace sampling from Bernoulli distributions. Parameterized sampling provides a regularization effect to mitigate interlocking, but it requires additional calibration effort to find the best trade-off between sampling stability and exploration. In contrast, genetic-based search does not require sampling to define discrete selection masks and has superior optimization stability with respect to standard reinforcement learning algorithms (Salimans et al., 2017). Contributions have also explored solutions to ease the learning process. Liu et al. (2022) propose to share embedding weights between the generator and predictor to increase information flow between the two modules. Liu et al. (2023d) employ different learning rates for $g_\\theta$ and $f_\\omega$ to mitigate selection mask overfitting. Liu et al. (2023b) use multiple generators to improve rationalization exploration to reduce the chance of interlocking. While, in principle, some of these design choices, like weight sharing, may be included in our framework, they are not required as GenSPP avoids interlocking.\nExternal Guidance. Another class of contributions leverages information from the input text to guide selective rationalization. Yu et al. (2021) define an attention-based predictor that performs soft selections to mitigate interlocking. Chang et al. (2019) propose a generator-discriminator adversarial training to learn class-wise highlights. Paranjape et al. (2020) propose a sparsity regularization objective based on information bottleneck to trade-off performance accuracy and highlight coherence. Huang et al. (2021) define a guider module that acts as a teacher for $f_\\omega$ and propose an embedding-based regularization between the embedded input $x$ and the generated highlight $\\hat{x}$ to guide $g_\\theta$. Yue et al. (2022) propose a mutual information regularization to exploit information from non-selected tokens by leveraging an additional predictor. Sha et al. (2023) introduce the InfoCal framework, where an addi-"}, {"title": "4 Motivation", "content": "We motivate our work by discussing how existing contributions only mitigate interlocking. The analysis of (Yu et al., 2021) underlines that the quality of the selective rationalization solution strongly depends on the system's capability to avoid the interlocking effect, thus reducing the probability of incurring local minima during training. Interlocking affects the following optimization problem:\n$\\min_{g_\\theta} \\min_{f_\\omega} L(f_\\omega (g_\\theta(x) \\odot x), y)$  (4)\nA major cause of interlocking is the generation of a discrete binary mask $m$ to define a faithful and interpretable model. The discretization of $m$ induces a discrepancy in how $g_\\theta$ and $f_\\omega$ learn during training. As pointed out by Yu et al. (2021), $f_\\omega$ tends to overfit to a certain sub-optimal mask $m$, causing the interlocking. More precisely, while the predictor's parameters $\\omega$ change smoothly at each gradient step thanks to the continuous nature of the learning objective, the generator $g_\\theta$ contains a discrete function (i.e., rounding) that makes its policy a piecewise constant function with respect to its parameters $\\theta$. Even by applying smoothing techniques (e.g., sampling) to mitigate the issue and achieve differentiability, the generated binary mask $m$ might remain unchanged (or change too slowly) over multiple gradient steps, thus, leading $f_\\omega$ to overfit on $m$.\nTo address this issue, contributions have proposed sampling-based methods to allow for differentiable discretization (Bao et al., 2018; Bastings et al., 2019), external guidance by introducing an additional soft rationalization system (Chang et al., 2019; Yu et al., 2021; Sha et al., 2023; Liu et al., 2023a; Hu and Yu, 2024), multi-stage training procedures (Liu et al., 2023b), and weight sharing between $g_\\theta$ and $f_\\omega$ for increased information flow (Liu et al., 2022). However, none of these methods solves interlocking, and the likelihood of rapidly falling into a local optimum is only mitigated at the cost of added optimization issues, such as increased variance.\nGiven the side effect caused by the unequal joint training of the two models via stochastic gradient descent (SGD), a logical and straightforward way to break the interlocking between $g_\\theta$ and $f_\\omega$ is to split the dual minimization problem of Eq. 4. Formally, let $\\omega^*$ be the optimal predictor's parameters, and let $l$ be its optimal solution:\n$l = L(f_{\\omega^*}(x), y)$  (5)\nEq. 4 can be reformulated as a disjoint training by"}, {"title": "5 The GenSPP Framework", "content": "We introduce GenSPP, a novel SPP framework optimized via genetic-based search. GenSPP presents several advantages over selective rationalization based on SGD. First, GenSPP is interlocking-free by splitting the optimization process into two stages (Eq. 6): each individual $c$ embodies a different generator $g_\\theta$, which is then evaluated through a unique predictor $f_\\omega$. Second, GenSPP leverages genetic-based search, allowing for both local (via mutation) and global (via crossover) search in the $\\theta$ parameter space to avoid local minima. Third, genetic-based search does not require a differentiable learning objective, allowing for more accurate training regularizations. We describe GenSPP and discuss its advantages over other selective rationalization frameworks in detail."}, {"title": "5.1 Method", "content": "GenSPP follows the same architecture of Lei et al. (2016) where hard rationalization is performed via rounding and is trained via neuroevolution. In particular, individual evaluation is a two-stage process. First, a population $P$ of individuals, each representing a configuration of the generator's parameters, is defined. Second, each individual is evaluated via a fitness function $h$. In particular, a predictor is initialized from scratch for each individual $c$ and trained to minimize the task classification loss via SGD while keeping the parameters of $c$ frozen to avoid interlocking. We compute $h$ on each trained model, and we build a new population by selecting individuals based on their fitness scores. The process is iterated until convergence or a fixed budget"}, {"title": "5.2 Individual Evaluation", "content": "We identify two major issues in Eq. 3 for model evaluation. First, finding a balance between $L_t$ and $\\Omega(m)$ is non-trivial, potentially leading to sub-optimal solutions that only minimize one of the two. Second, the joint learning formulation is not a reasonable candidate for optimization, collapsing substantially different solutions to the same cost value. Consider two instances of the learning problem, one with $L_t = 0.0$ and $\\Omega(m) = 1.0$, and another with $L_t = 0.5$ and $\\Omega(m) = 0.5$. Notably, both instances have the same average cost of 0.5, but the first does not satisfy our objective of defining a faithful rationalization framework (see Appendix A for a graphical comparison). Therefore, the two instances should be evaluated differently to favor solutions that are both accurate and interpretable.\nTo allow for more robust individual evaluation, we propose the following objective function:\n$h = \\begin{cases}\n1 - L_t, & \\text{if } L_t < l + \\epsilon \\\\\n- L_t, & \\text{otherwise}\n\\end{cases}$ (7)"}, {"title": "5.3 GenSPP Genetic Algorithm", "content": "We describe the genetic algorithm for training GenSPP. Given a population $P_0$ of $I$ individuals, each representing a different generator instance, we perform individual selection and recombination as follows. We initially evaluate $P_0$ by computing the fitness score of each individual in the population. We apply the roulette-wheel selection strategy, a stochastic process where individuals are sampled proportionally to their fitness score (Lipowski and Lipowska, 2012), to pair individuals for recombination. In total, pairs are selected. We employ one-point crossover (Poli and Langdon, 1998) to generate $I$ new individuals from selected pairs. This crossover strategy swaps parameters between two individuals by randomly choosing a swap point from a uniform distribution. We then mutate each generated individual parameter with probability $p_m$ by inserting Gaussian noise. The intermediate population $P_0'$ comprises the original $I$ individuals and the $I$ newly generated ones. To build the population $P_1$ of $I$ individuals for the next generation, we evaluate the fitness score of $P_0'$ and then perform survival selection via the half-elitism strategy (Michalewicz, 1996). In particular, we select the $\\frac{I}{2}$ with the highest fitness score, while the remaining $\\frac{I}{2}$ is sampled via roulette-wheel selection."}, {"title": "5.4 Advantages", "content": "Optimizing Eq. 6 via GAs introduces several advantages over selective rationalization based on SGD, which we discuss in detail.\nDisjoint Training. A joint training of the selective rationalization system based on SGD involves a dependency between $g_\\theta$ and $f_\\omega$: the quality of a highlight mask $m$ is also dependent on the quality of the current employed $f_\\omega$ (e.g., good masks may"}, {"title": "6 Experimental Settings", "content": "We compare GenSPP to several competitors for unsupervised selective rationalization\u00b2 on two benchmarks. We describe the data, models, and evaluation metrics in detail. See Appendix B for additional details.\nToy Dataset. We build and release a controlled toy dataset of random strings. We define three classification classes, each corresponding to a unique character-based highlight: aba, baa, abc. We design highlights to ensure that all their characters have to be selected in order to determine the corresponding class. To avoid degenerate solutions in which only a portion of the highlight is sufficient for classification, we contaminate generated strings with randomly sampled chunks of other class highlights. Lastly, we enforce that a single highlight is contained in each string. Generated strings not"}, {"title": "7 Results", "content": "We consider two sets of experiments. The first evaluates models when trained from scratch to assess their capability to avoid local minima. The second measures how good a method is at recovering from interlocking. See Appendix C for additional results.\nBenchmark Evaluation. Table 1 reports results. We observe that GenSPP significantly outperforms all competitors in selecting high-quality highlights (+10.3% HI-F1 in Toy and +6.5% HI-F1 in HateXplain), while reporting comparable classification performance. Additionally, GenSPP shows reduced variance across seed runs compared to competitors, especially in the Toy dataset, where MGR and G-RAT present notable instability. Regarding highlight regularization, GenSPP selects highlights that are more sparse and accurate compared to baseline models. Interestingly, GenSPP learns to not select any highlight for negative examples in HateXplain, while keeping valuable selections for positive examples, a flexibility that baseline models cannot achieve since they are subject to satisfy a certain sparsity threshold. Overall, these results show the advantage of GenSPP in performing a disjoint optimization problem via genetic-based search to break interlocking.\nSynthetic Skewing. We follow Liu et al. (2022) and train a skewed $g_\\theta$ for $K = 10$ epochs using the classification label as supervision for selecting the first token $x^1$. To evaluate GenSPP on this experiment, we include one skewed individual in the initial population $P_0$, while randomly initializing the remaining individuals. We experiment with $G \\in [100, 150]$ since convergence may require more time due to recombinations with the"}, {"title": "8 Conclusions", "content": "We have introduced GenSPP, the first selective rationalization framework that breaks interlocking via genetic-based search. GenSPP does not require differentiable surrogate learning objectives, additional regularization tuning, and architectural changes. Our results on two benchmarks, a controlled synthetic one that we curate, and a real-world dataset for hate speech, show the advantage of GenSPP, outperforming several competitors. Furthermore, our robust evaluation underlines the increased variance that affects competitors' models, a phenomenon that was not sufficiently explored in selective rationalization. Future research directions regard exploring more efficient genetic algorithms and implementations to reduce computational overhead and scale to more complex neural architectures."}]}