{"title": "Topological derivative approach for deep neural network architecture adaptation", "authors": ["C G Krishnanunni", "Tan Bui-Thanh", "Clint Dawson"], "abstract": "This work presents a novel algorithm for progressively adapting neural network architecture along the\ndepth. In particular, we attempt to address the following questions in a mathematically principled\nway: i) Where to add a new capacity (layer) during the training process? ii) How to initialize the\nnew capacity? At the heart of our approach are two key ingredients: i) the introduction of a \"shape\nfunctional\" to be minimized, which depends on neural network topology, and ii) the introduction of\na topological derivative of the shape functional with respect to the neural network topology. Using\nan optimal control viewpoint, we show that the network topological derivative exists under certain\nconditions, and its closed-form expression is derived. In particular, we explore, for the first time,\nthe connection between the topological derivative from a topology optimization framework with the\nHamiltonian from optimal control theory. Further, we show that the optimality condition for the\nshape functional leads to an eigenvalue problem for deep neural architecture adaptation. Our ap-\nproach thus determines the most sensitive location along the depth where a new layer needs to be\ninserted during the training phase and the associated parametric initialization for the newly added\nlayer. We also demonstrate that our layer insertion strategy can be derived from an optimal trans-\nport viewpoint as a solution to maximizing a topological derivative in p-Wasserstein space, where\np\u2265 1. Numerical investigations with fully connected network, convolutional neural network, and\nvision transformer on various regression and classification problems demonstrate that our proposed\napproach can outperform an ad-hoc baseline network and other architecture adaptation strategies.\nFurther, we also demonstrate other applications of topological derivative in fields such as transfer\nlearning.", "sections": [{"title": "1. Introduction", "content": "It has been observed that deep neural networks (DNNs) create in-\ncreasingly simpler but more useful representations of the learning problem layer by layer\n[20, 37, 36, 58]. Furthermore, empirical evidence supports the paradigm that depth of a\nnetwork is of crucial importance [43, 45, 50, 27]. Some of the problems associated with train-\ning such deep networks include: i) a possible large training set is needed to overcome the\nover-fitting issue; ii) the architecture adaptability problem, e.g., any amendments to a pre-\ntrained DNN, requires retraining even with transfer learning; iii) GPU employment is almost\nmandatory due to massive network and data sizes. Most importantly, it is often unclear on\nthe number of layers and number of neurons to be used in each layer while training a neural\nnetwork for a specific task. Therefore, there is a critical need for rigorous adaptive principles\nto guide the architecture design of a neural network."}, {"title": "1.1. Related work", "content": "Neural architecture adaptation algorithms can be broadly classified\ninto two categories: i) neural architecture search algorithms and ii) principled adaptive strate-"}, {"title": "1.2. Our contributions", "content": "In this work, we derive an algorithm for progressively increasing a\nneural network's depth inspired by topology optimization. In particular, we provide solutions\nto the following questions: i) Where to add a new layer; ii) When to add a new layer; and iii)\nHow to initialize the new layer? We shall present two versions of the algorithm: i) a semi-\nautomated version where a predefined scheduler is used to decide when a new layer needs\nto be added during the training phase [17]; ii) a fully automated growth process in which a\nvalidation metric is employed to automatically detect when a new layer needs to be added.\nOur method does not have the limitation that the loss function needs to plateau before growing\nsuch as those in [55, 24]. Our algorithm is based on deriving a closed-form expression for the\ntopological derivative for a shape functional with respect to a neural network (Theorem 2.7).\nTo that end, in Definition 2.2 and Proposition 2.3 we introduce the concept of admissible\nperturbation and suggest ways for constructing an admissible perturbation. In subsection 2.3,\nwe show that the first-order optimality condition leads to an eigenvalue problem whose solution\ndetermines where a new layer needs to be inserted along with the associated parametric\ninitialization for the added layer. The efficiency of our proposed algorithm is explored in\nsection 3 by carrying out extensive numerical investigations with different architectures on\nprototype regression and classification problems."}, {"title": "2. Mathematical framework", "content": "In this work, all the matrices and vectors are represented\nin boldface. Consider a regression/classification task where one is provided with S training\ndata points, input data dimension no, and label dimension ny. Let the inputs $x_i \\in \\mathbb{R}^{n_0}$ for\n$i \\in \\{1, 2, ...S\\}$ be organized row-wise into a matrix $X \\in \\mathbb{R}^{S \\times n_0}$ and let the corresponding true\nlabels be denoted as $c_i \\in \\mathbb{R}^{n_t}$ and stacked row-wise as $C \\in \\mathbb{R}^{S \\times n_t}$. We start by considering\nthe following empirical risk minimization problem with some loss function\u00b9 for a typical\nfeed-forward neural network:\n\n(2.1) $\\min_\\theta J(\\theta) = \\frac{1}{S} \\sum_{s=1}^S \\Phi(x_s, T), \\text{ subject to: } x_{s, t+1} = f_{t+1}(x_{s, t}; \\theta_{t+1}), x_{s, 0} = x_s$,\n\nwhere t = 0,...T \u2212 1, s \u2208 {1, ...S}, $f_{t+1} : \\mathbb{R}^{n(t)} \\times \\Theta_{t+1} \\rightarrow \\mathbb{R}^{n(t+1)}$ denotes the forward\npropagation function, n(t) denotes the number of neurons in the t-th layer, the parameter\nset $ \\Theta_{t+1}$ is a subset of a Euclidean space and $ \\Theta = \\Theta_1 \\times \\dots \\times \\Theta_T$, $\\theta_{t+1}$ represents the\nnetwork parameters corresponding to (t+1)th layer, $ \\theta = (\\theta_1,..., \\theta_T)$ such that $\\theta \\in \\Theta$ implies\n$\\theta_{t+1} \\in \\Theta_{t+1}$, $x_{s, t}$ represents the hidden states of the network, T \u2013 1 is the total number of\nhidden layers in the network. In the case of a fully connected network (FNN), one has:\n\n$f_{t+1}(x_{s, t}; \\theta_{t+1}) = \\sigma_{t+1} (W_{t+1}x_{s, t} + b_{t+1}),$"}, {"title": "2.1. Optimal control viewpoint for neural network training", "content": "Recently, there has been\nan interest in formulating deep learning as a discrete-time optimal control problem [31, 7].\nNote that in the context of popular architectures such as residual neural networks (ResNet),\nequation (2.1) can be interpreted as discretizations of an optimal control problem subject\nto an ordinary differential equation constraint [7]. The Hamiltonian for the t-th layer, $H_t :$\n$\\mathbb{R}^{n(t)} \\times \\mathbb{R}^{n(t+1)} \\times \\Theta_{t+1} \\rightarrow \\mathbb{R}$ corresponding to the loss in (2.1) is defined as [51]:\n\n(2.2) $H_t (x_{s, t}; p_{s, t+1}; \\theta_{t+1}) = p_{s, t+1}. f_{t+1}(x_{s, t}; \\theta_{t+1}).$\n\nwhere, {$p_{s, 1}, p_{s, 2},... p_{s, T}$} denote the adjoint variables computed during a particular gradient\ndescent iteration (backpropagation) as follows [51]:\n\n$\\frac{1}{S}$\n\n$p_{s, T} = -\\nabla_I (x_{s, T}),$\n\n(2.3)\n\n$p_{s, t} = \\nabla_xH_t (x_{s, t}; p_{s, t+1}; \\theta_{t+1}) = [\\nabla_x f_{t+1}(x_{s, t}; \\theta_{t+1})]^T p_{s, t+1},$\n\n$x_{s, t+1} = \\nabla_pH_t (x_{s, t}; p_{s, t+1}; \\theta_{t+1}$\n\n$\\theta_{t+1} = \\theta_{t+1} - l \\nabla_\\theta H_t (x_{s, t}; p_{s, t+1}; \\theta_{t+1}) = \\theta_{t+1} - l [\\nabla_\\theta f_{t+1}(x_{s, t}; \\theta_{t+1})]^T p_{s, t+1}.$\n\nwhere, $\\nabla_x f_{t+1}$ denotes the gradient of $f_{t+1}$ with respect to the first argument (i.e. the state\nx) and $\\nabla_\\theta f_{t+1}$ denotes the gradient of $f_{t+1}$ with respect to the second argument (i.e. the\nparameter \u03b8). From a Lagrangian viewpoint, the Hamiltonian can be understood as a device\nto generate the first-order necessary conditions for optimality [51].\nIn the topological derivative approach, one often studies how the presence of a circular\nhole (or inclusion of new material) of radius \u025b at a specific location z in the domain o C $R^2$\naffects the solution of a given partial differential equation (PDE) with prescribed boundary\nconditions [1]. In this work, we will first look at how the addition of a new layer at a specific\nlocation l \u2208 {1,2,...T \u2013 1} in the neural network No affects the solutions given by (2.3).\nTo that end, we will develop key concepts such as \"perturbed network\" and \"admissible\nperturbation\" leading to the definition of a discrete topological derivative which we call as the\n\"network topological derivative\" in our work."}, {"title": "Definition 2.1 (Network perturbation)", "content": "Consider A as the set of all feed-forward neural\nnetworks with constant width 'n' (n \u2208 N) in each hidden layer. Let No \u2208 A be a given neural\nnetwork with (T \u2013 1) hidden layers, and \u03c3 (.) : R \u2192 R be a non-linear activation function. A\nperturbation \u03a9\u025b from No at l \u2208 {1, 2, . . . T \u2013 1} along the \u201cdirection\u201d \u03c6 and with magnitude e\nis defined as:\n\n$\u03a9_\u03b5 = \u03a9_\u03bf \\oplus (l, \u03b5\u03c6, \u03c3), \\text{ s.t. } \u03a9_\u03b5 \u2208 A,$\n\nwhere \u2295 represents the operation of adding a layer between the Ith_and (l + 1)th layer of\nnetwork No initialized with vectorized parameters (weights/biases) \u03b5\u03c6 and activation \u03c3 (refer\nFigure 1). The added layer is denoted as (1+) in Figure 1. Note that \u03a9\u025b is a also a function\nof 1, & and \u03c3, but for the simplicity of the notation, we omit them."}, {"title": "Definition 2.2 (Admissible perturbation)", "content": "We say that \u03a9\u025b in Definition 2.1 is an admissible\nperturbation if:\n\n(2.4) $\u03a9_\u03b5|_{\u03b5=0} = \u03a9_\u03bf,$\n\nwhere '=' in (2.4) is used to denote the fact that the network $\u03a9_\u03b5|_{\u03b5=0}$ behaves exactly the\nsame as No under gradient based training process. In particular, the added layer in Ne\nis\nredundant and only acts as a message-passing layer. Furthermore, the solutions given by (2.3)\nfor t = {0, 1, . . . l, (l + 1), . . . T} and the loss I in (2.1) together with its gradient coincide for\nboth No and $D_\u03b5|_{\u03b5=0}$ at every gradient descent iteration."}, {"title": "Proposition 2.3 (Construction of an admissible perturbation)", "content": "Consider Definition 2.2. The\nfollowing two steps produce an admissible perturbation:\n1. Choose A as the set of all residual neural networks where the hidden layer propagation\nequation in (2.1) is written as:\n\n(2.5)\n\n$x_{s, t+1} = f_{t+1}(x_{s, t}; \\theta_{t+1}) = x_{s, t} + g_{t+1}(x_{s, t}; \\theta_{t+1}), t = 1,. . . T \u2013 2.$\n\n2. Choose the activation function o such that $g_{t+1} (.;.)$ is continuously differentiable\nw.r.t both the arguments and:\n\n$g_{t+1}(x_{s, t}; 0) = 0, \\nabla_x g_{t+1}(x_{s, t}; 0) = 0, \\nabla_\\theta g_{t+1}(x_{s, t}; 0) = 0.$\n\nProof:. Let us compute the states and adjoints in (2.3) for network \u03a9\u025b corresponding to\nthe first gradient descent iteration. The forward propagation of residual neural network \u03a9\u025b\nfrom Ith layer to (l + 1)th layer can be written as:\n\n(2.6a) $x_{s, l+\\frac{1}{2}} = f_{l+\\frac{1}{2}}(x_{s, l}; \u03b5\u03c6) = x_{s, l} + g_{l+\\frac{1}{2}}(x_{s, l}; \u03b5\u03c6),$\n\n(2.6b) $x_{s, l+1} = f_{l+1} (x_{s, l+\\frac{1}{2}}; \\theta_{l+1}) = x_{s, l+\\frac{1}{2}} + g_{l+1} (x_{s, l+\\frac{1}{2}}; \\theta_{l+1}).$\n\nNow, for \u03b5 = 0 (2.6a) gives\n\n$x_{s, l+\\frac{1}{2}} = x_{s, l}, \\rightarrow x_{s, l+1} = x_{s, l} + g_{l+1} (x_{s, l}; \\theta_{l+1}) = f_{l+1} (x_{s, l}; \\theta_{l+1}).$"}, {"title": "2.2. Topological derivative", "content": "The concept of topological derivative was formally intro-\nduced as the \"bubble method\" for the optimal design of structures [16], and further studied\nin detail by Sokolowski and Zochowski [46]. The topological derivative is, conceptually, a\nderivative of a shape functional with respect to infinitesimal changes in its topology, such as\nadding an infinitesimal hole or crack. The concept finds enormous application in the field\nof structural mechanics, image processing and inverse problems [1]. In the field of structural\nmechanics, the concept has been used to detect and locate cracks for a simple model problem:\nthe steady-state heat equation with the heat flux imposed and the temperature measured on\nthe boundary [2]. In the field of image processing, the topological derivative has been used to\nderive a non-iterative algorithm to perform edge detection and image restoration by studying\nthe impact of an insulating crack in the domain [5]. In the field of inverse problems, the\ntopological derivative approach has been applied to tomographic reconstruction problem [3].\nInspired by the topological derivative approach in mechanics, we define the \"network\ntopological derivative\" for a feed-forward neural network and derive its explicit expression.\nNote that the admissible perturbation (adding a layer) defined in Definition 2.2 can be viewed\nas an infinitesimal change in the neural network topology. In order to formally define the\n\"network topological derivative\" let us first rewrite the loss function (2.1) as follows:\n\n(2.9)\n\n$J(\\Omega_\u03b5) = \\frac{1}{S} \\sum_{s=1}^S \\Phi (\\Omega_\u03b5 (x_{s, 0}; \u03b5\u03c6)),$\n\nwhere \u025b is the initialization of the added layer in \u03a9\u025b (see Definition 2.1)."}, {"title": "Definition 2.5 (Network topological derivative)", "content": "Consider an admissible perturbation \u03a9\u025b in\nDefinition 2.2. We say the loss functional I in (2.9) admits a network topological deriva-\ntive\u2014denoted as dJ(No; (l, \u03c6, \u03c3))\u2014at \u03a9\u03c1 \u2208 A and at the location l \u2208 {1,2...T \u2013 1} along\nthe direction \u03c6 if there exists a function q : $R^+ \\rightarrow R^+$ with $lim_{\u03b5 \\rightarrow 0} q(\u03b5) = 0$ such that the following\n\"topological asymptotic expansion\u201d holds:\n\n(2.10) $J(\\Omega_\u03b5) = J(\\Omega_o) \u2013 q(\u03b5)dJ(\\Omega_o; (l, \u03c6, \u03c3)) + o(q(\u03b5)),$"}, {"title": "Remark 2.6", "content": "Note that the '-' sign is used in (2.11) to ensure that a positive derivative\nfavors layer addition and vice versa. Since for an admissible perturbation \u03a9\u025b in Definition 2.2,\nwe have $I (\\Omega)|_{\u03b5=0} = I (\u03a9)$, the \u201ctopological asymptotic expansion\" in (2.10), can be\nunderstood as the following Taylor series expansion:\n\n(2.12)\n\n$J(\u03a9_\u03b5) = J(\\Omega_\u03b5) = I (\u03a9_\u03b5) + \\frac{d}{d\u03b5} (J (I (\\Omega_\u03b5))|_{\u03b5=0}) \u03b5 + \\frac{d^2}{2 d\u03b5^2} (J (I (\\Omega_\u03b5))|_{\u03b5=0}) \u03b5^2 +\n\n...,$\n\nwhere I (\u03a9) is given by (2.9). In Theorem 2.7 we will unveil a non-trivial connection between\nthe Hamiltonian H\u2081 introduced in (2.2) with the network topological derivative in (2.11)."}, {"title": "Theorem 2.7 (Existence of network topological derivative)", "content": "Assume the conditions in Propo-\nsition 2.3 and the loss I in (2.1). Further, let X\u2081 be the set of all possible states $x_{s, t}$ reachable\nat layer t from all possible initial sample $x_{s, 0}$ and trainable parameters in \u0398. Assume that\n1. I has bounded second and third order derivatives on XT;\n2. $f_{t+1}(.;.)$ has bounded second and third order derivatives on $X_t \\times \\Theta_{t+1}$.\nThen, the network topological derivative given by (2.11) exists with $q(\u03b5) = \u03b5^2$ and is given by:\n\n(2.13)\n\n$dJ(\u03a9_\u03bf; (l, \u03c6, \u03c3)) = \\frac{1}{2} \\sum_{s=1}^S \\phi^T \\nabla_{\\theta} H_l (x_{s,l}; p_{s,l}; \\theta) \\phi |_{\u03b8=0},$\n\nwhere Hi is the Hamiltonian defined in (2.2).\nProof:. Let us represent the parameters of the perturbed network \u025b as \u03b8\u20ac and the param-\neters of the original network No as 0\u00ba. For an admissible perturbation \u03a9\u025b in Definition 2.2, \u03a9\u03bf\nis equivalent to $\u03a9_\u03b5|_{\u03b5=0}$. We thus identify \u03a90 with $\u03a9_\u03b5|_{\u03b5=0}$. By Definition 2.1 $\u03b8^\u03b5_i = \u03b8_i, \\forall i \\neq l+\\frac{1}{2}$.\nDefine\n\n$\\delta x_{s,t} = \\frac{\u2202}{\u2202 \u03b5} x_{s,t} = x^\u03b5_{s,t} - x^0_{s,t} , pst = \\frac{\u2202}{\u2202 \u03b5} p_{s,t} = p^\u03b5_{s,t} - p^0_{s,t}\n$\n\nand we have\n\n$dx_{s,t} = 0, t \\leq l$.\n\nApplying definition (2.2) for both \u03a9\u025b and No gives\n\n(2.14a) $\\sum_{t=0}^{T-1}(H_t (x^0_{s,t} + dx_{s,t}; p^0_{s,t+1} + dp_{s,t+1}; \u03b8^0_{t+1}) - (p^0_{s,t+1} + dp_{s,t+1})(x^0_{s,t+1} + dx_{s,t+1})) = 0,$\n\n(2.14b) $\\sum_{t=0}^{T-1}(H_t (x^0_{s,t} ; p^0_{s,t+1}; \u03b8^0_{t+1}) - (p^0_{s,t+1})(x^0_{s,t+1})) = 0.\n$"}, {"title": "Proposition 2.12", "content": "Let v be a vector in Rn. Define\n\n(2.32)\n\n$\u03a6_r := [ 0, ..., v, 0...0]^T.$\n\n$(r-1) \\times n.$\n\nThen v is an eigenvector of $Q^{(r)}$ if and only if \u00der is an eigenvector of Q\u0131. Furthermore, the\neigenvalues corresponding to v and \u03a6r are the same.\nAs a direct consequence of Proposition 2.12, if v is an eigenvector corresponding to the\nlargest eigenvalue (among all eigenvalues of all diagonal blocks), then the corresponding I, is\nassociated with the largest eigenvalue of Qi.\nAs a result, the shape functional is most sensitive to the rth neuron, and the rth neuron\nshould be activated (i.e. initialized with non-zero weights/biases). Alternatively, given an\ninteger m, we can identify \"the best\" m neurons such that when they are activated, the\ninduced change in the shape functional is largest.\nConsider the following constrained optimization problem:\n\n(2.33)\n\n$max_{\\Phi_i, \\Phi_j \\in {\\Phi_k\\}_{k=1}, \\Phi_i \\neq \\Phi_j} (dJ(\\Omega_\u03bf; (\u03b9, (\u03a6\u2081 +... \u03a6m), \u03c3))), s.t ||\\phi||_2 = 1, i = 1,..., m.\n$\n\nThen, the optimal value is the sum of the first m largest eigenvalues of m diagonal sub-blocks\nof Q1. The optimal solutions {pi}m1 are the corresponding eigenvectors of these diagonal\nsub-blocks written in the form given by (2.32)."}, {"title": "Proposition 2.13", "content": "Derivation of our adaptation algorithm. We now exploit the derived closed-form\nexpression for the network topological derivative (2.13) to devise a greedy algorithm for ar-\nchitecture adaptation. Given the network derivative in (2.13), the criterion is obvious: we"}, {"title": "3. Numerical experiments", "content": "In this section, we numerically demonstrate the proposed ap-\nproach using different types of architecture such as a) Radial basis function neural network;\nb) Fully connected neural network; and c) vision transformer (ViT). Our supplementary file\ncontains additional numerical examples where we considered both simulated and real-world\ndata sets and also demonstrated the approach for a convolutional neural network architec-\nture (CNN). General experimental settings for all the problems and descriptions of methods\nadopted for comparison are detailed in Appendix D. Note that in our numerical results,\nProposed (I) refers to Algorithm 2.1 and proposed (II) refers to \"fully automated growing\"\nalgorithm mentioned in Remark 2.14."}, {"title": "3.1. Proof of concept example: Radial basis function (RBF) neural network", "content": "As a proof\nof concept of our proposed approach, we first consider the problem of learning a 1-dimensional\nfunction using a radial basis function (RBF) neural network. In particular, we consider the\nmulti-layered RBF neural network [13, 8] with residual connections where $g_{t+1}(.;.)$ in (2.5)\nis given by:\n\n(3.1) $g_{i+1}(x_{s,i}; \u03b8_{i+1}) = \u03b8_{i+1}^{(3)} \\times exp (-\\frac{1}{2}(x_{s,i} - \u03b8_{i+1}^{(1)})^2 - c)^2 - \u03b8_{i+1}^{(3)} \\times exp (-\\frac{1}{2}c^2),$\n\nwhere $\u03b8_{i+1} = [\u03b8_{i+1}^{(1)}, \u03b8_{i+1}^{(2)}, \u03b8_{i+1}^{(3)}]^T \u2208 \\mathbb{R}^3$ for i = 0, . . . T \u2013 1, and c is a non-zero parameter of the\nactivation function. Note that, the second term in (3.1) is introduced to satisfy condition 2 of\nProposition 2.3 and therefore in this case we have a modified radial basis function. Further,\nnote that (3.1) corresponds to using a single neuron in each hidden layer."}, {"title": "3.1.1. Topological derivative for the modified RBF network (3.1)", "content": "The topological\nderivative is computed based on solving the eigenvalue problem (2.29) where the matrix Q\u0131\n(equation (2.29)) is given as:\n\n(3.2) $Q_l = \\frac{1}{S} \\sum_{s=1}^S \\begin{bmatrix}\n c_1^2 & c_1 p_{s, l} x_{s, l} & c_1 p_{s, l} \\\\\n c_1 p_{s, l} x_{s, l} & c_1^2 p_{s, l} x_{s, l} & c_1 p_{s, l} \\\\\n c_1 p_{s, l} & c_1 p_{s, l} & c_1^2\n\\end{bmatrix},$\n\nwhere $c_1 = c exp(-(c)^2)$ and c is a parameter in (3.1)."}, {"title": "3.1.2. Data generation and numerical results", "content": "For generating the training data set, we\nset T = 15 in (2.5) and sample a true set of parameters {0;}=1 from normal distribution\nN (0,31), where I is the 3 \u00d7 3 identity matrix. Further, we set c = 0.1 in (3.1). The\ntraining data set D = {$x_i, c_i$\\}^5000 is then generated by drawing $x_i$ uniformly from [-2,2]\nand computing the corresponding labels as $c_i = \u03a9\u2217(x_i)$, where \u03a9\u2217 denote the true map to be\nlearnt. In addition, we consider an additional 500 data points for generating the validation\ndata set and 1000 data points for the testing data set. The generated true function is shown\nin Figure 2 (rightmost figure)."}, {"title": "3.1.3. Discussion of results", "content": "As outlined in subsection 2.3, we begin the adaptive training\nprocess by starting with a one-hidden layer network and progressively adding new layers. Each\nlayer is trained to a (approximately) local minimum before adding a new layer. To validate\nour proposed theory, we compare the topological derivative predicted by our Theorem 2.7\nwith that computed numerically at each iteration of the algorithm and the results are shown\nin Figure 2 (left). Note that the derivatives are computed for the layer I with the largest\neigenvalue at each iteration and initialization $\u03c6 = \u03a6_l$ given by (2.28). We use a step size\nof $\u03b5 = 1 \u00d7 10^{\u22124}$ to compute the numerical derivative $dJ(\u03a9_\u03bf; (l, \u03c6, \u03c3))$ in (2.11). Figure 2\n(left) shows that the numerical derivative is in close agreement with the theoretical derivative.\nFigure 2 (middle) investigates how the choice of initialization & influences the derivative\n$dJ(\u03a9_\u03bf; (l, \u03c6, \u03c3))$ in (2.11). For this, we set l = 1 (at the end of training the initial one\nhidden layer network) and generated different unit vectors (each sampled vector is represented\nas a blue circle in Figure 2 (middle)). The x-axis denotes the angle that each sampled vector\nmakes with the optimal direction \u03a6\u03b9 given by (2.28) and the y-axis denotes the numerically\ncomputed derivative for each sampled . It is clear from Figure 2 (middle) that the maximum\ntopological derivative is indeed observed for the optimal eigenvector \u03a6\u03b9 predicted by (2.28).\nFigure 2 (rightmost figure) shows the learned function (by our proposed approach) at each\niteration of the algorithm.\nTypical training curves for different adaptation strategies are shown in Figure 3 (left).\nThe sharp dip in the loss in Figure 3 (left) corresponds to a decrease in loss on adding a\nnew layer. It is clear from Figure 3 (left) that our proposed framework outperforms all other\nadaptation strategies while also exhibiting superior performance in comparison to a baseline\nnetwork trained from scratch. It is also interesting to note that while Net2DeeperNet (II)\nseems to exhibit superior performance in the beginning stages in Figure 3 (left), it is clear\nthat there is no guarantee that Net2DeeperNet (II) will escape saddle points as evident from\nthe later stages of adaptation. In contrast, our layer initialization strategy ensures a decrease\nin loss for sufficiently small \u025b thereby escaping saddle points. The decision-making process at\neach iteration on where to add a new layer is shown in Figure 4 where the blocks represent the"}, {"title": "2.4.1. Activating the most sensitive neurons in a new layer", "content": "Let $Q^{(i)}_l$ be the ith block\n(along the diagonal) of Qt given by (2.31). Note that the eigenvalues of Qi are just the list\nof eigenvalues of each $Q^{(r)}_{sl}$. Therefore, one only needs to solve the eigenvalue problem\nfor each block $Q^{(r)}_{sl}$ separately thereby significantly reducing the computational cost. Let\n$Q^{(r)}_{sl} = \\sum_{s=1}^{S} p^{(r)}_{s,l}x_{s,l} x^{(r)}_{s,l} \\sigma''(0) \u2208 \\mathbb{R}^{n\\times n}$ be the rth diagonal block in Qi corresponding to the\nrth neuron. The following result is obvious."}]}