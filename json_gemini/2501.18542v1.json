{"title": "Semantic Web and Creative AI", "authors": ["Stefano De Giorgis", "Tabea Tietz", "Valentina Presutti", "Harald Sack", "Claudia d'Amato", "Irene Celino", "John Domingue", "Michel Dumontier", "Frank van Harmelen", "Aidan Hogan", "Jan-Christoph Kalo", "Valentina Presutti", "Sebastian Rudolph", "Harald Sack", "Oleksandra Bruns", "Stefano De Giorgis", "Tabea Tietz", "Eleonora Marzi", "Andrea Poltronieri", "Aleksandra Simic", "Alexane Jouglar", "Anna Sofia Lippolis", "Anouk Michelle Oudshoorn", "Antonis Klironomos", "Arianna Graciotti", "Arnaldo Tomasino", "Aya Sahbi", "Beatriz Olarte Martinez", "Bohui Zhang", "Caitlin Woods", "Celian Ringwald", "Chiara Di Bonaventura", "Cristian Santini", "Daniela Milon Flores", "Daniil Dobriy", "Dennis Sommer", "Disha Purohit", "Ebrahim Norouzi", "Eleonora Mancini", "Emetis Niazmand", "Ensiyeh Raoufi", "Francisco Bolanos", "George Hannah", "Giada D'Ippolito", "Ginwa Fakih", "Golsa Heidari", "Hassan Hussein", "Heng Zheng", "In\u00eas Koch", "Ioannis Dasoulas", "Joao Vissoci", "Johanna Rockstroh", "Kerstin Neubert", "Laura Menotti", "Liam Tirpitz", "Majlinda Llugiqi", "Mano\u00e9 Kieffer", "Marco Di Panfilo", "Martin Critelli", "Martin B\u00f6ckling", "Mary Ann Tan", "Mikael Lindekrans", "Mohammad Javad Saeedizade", "Nicolas Lazzari", "Nicolas Ferranti", "Philipp Hanisch", "Raia Abu Ahmad", "Reham Alharbi", "Rita Sousa", "Roberto Barile", "Ruben Eschauzier", "Sara Bonfitto", "Sefika Efeoglu", "Soulakshmee Nagowah", "Vidyashree Tarikere", "Vincenzo De Leo", "Weronika Lajewska", "Xinyue Zhang", "Xuemin Duan", "Yashrajsinh Chudasama", "Zafar Saeed"], "abstract": "The International Semantic Web Research School (ISWS) is a week-long intensive program designed to immerse participants in the field. It offers a blend of lectures and keynote presentations delivered by leading researchers, alongside a \"learning by doing\" teamwork program. Under the guidance of renowned scientists, teams tackle open research problems, culminating in the co-authorship of a white paper. ISWS' program is specifically designed to cultivate the next generation of semantic web researchers, emphasizing not only creativity and methodological rigor but also a sense of community and enjoyment.\nThis document reports a collaborative effort performed by ten teams of students, each guided by a senior researcher as their mentor, attending ISWS 2023. Each team provided a different perspective to the topic of creative AI, substantiated by a set of research questions as the main subject of their investigation.\nThe 2023 edition of ISWS focuses on the intersection of Semantic Web technologies and Creative AI. The recent emergence of generative AI has significantly impacted the field of AI. The public availability of Large Language Models (LLMs) marks a distinct break in technological history.\nLLMs have demonstrated their potential as tools for creative tasks such as text, image, and music generation. This strength likely stems from their ability to learn from vast amounts of data and develop the capacity to abstract over it. However, several challenges remain. These include issues like hallucination (generating factually incorrect content), information retrieval, and the knowledge acquisition bottleneck (the difficulty of efficiently incorporating new knowledge). Additionally, concerns regarding transparency, traceability, copyright, trust, and ethics require further investigation.\nSymbolic knowledge representations of the Semantic Web, in particular ontologies and knowledge graphs are instead very powerful at handling transparency, specialized knowledge, reasoning, generalization or abstraction. Combining these two approaches is not yet studied sufficiently, though.\nISWS 2023 explored various intersections between Semantic Web technologies and creative AI. A key area of focus was the potential of LLMs as support tools for knowledge engineering. Participants also delved into the multifaceted applications of LLMs, including legal aspects of creative content production, humans in the loop, decentralised approaches to multimodal generative AI models, nanopublications and AI for personal scientific knowledge graphs, commonsense knowledge in automatic story and narrative completion, generative AI for art critique, prompt engineering, automatic music composition, commonsense prototyping and conceptual blending, and elicitation of tacit knowledge.\nAs Large Language Models and semantic technologies continue to evolve, new exciting prospects are emerging: a future where the boundaries between creative expression and factual knowledge become increasingly permeable and porous, leading to a world of knowledge that is both informative and inspiring.", "sections": [{"title": "Harmonizing Creativity: Exploring the Role of Knowledge Graphs in Music Composition", "content": "Advancements in creative Artificial Intelligence (AI) have elicited significant transformations across several human creativity domains. Through the emerging generative AI approaches, systems are able to create new content such as image synthesis, music composition, and literature generation with minimal human interaction. For instance, in the realm of image synthesis, innovative models like DALL-E exemplify the ability to translate textual prompts into corresponding visuals with accuracy. Meanwhile, for text generation, transformer-based models such as GPT-3 or 4 have demonstrated unprecedented capabilities. These large language models (LLMs) leverage deep learning techniques to generate contextually relevant and coherent text, ranging from poetic verses to short stories and technical articles. Music composition has also witnessed progress with the release of models like AVIA, muBERT, Beatoven.ai, or JukeBox [56]. These models showcase the capacity to create musical compositions spanning various styles and genres, supplement incomplete symphonies, and accurately mimic or even originate voices (e.g. Murf.ai).\nThe rapid growth of generative artificial intelligence (GAI) has developed uncertainty and expectation that computers could substitute humans in complex tasks. However, ethical discussions on the use of GAI have been raised, including concerns about unintended plagiarism, dissemination of incorrect or poor-quality information, and even fabrication of false references. The progress in creative GAI extends beyond the mere automation of creative thinking. It heralds a new paradigm where AI operates as a creative collaborator, augmenting human creativity by offering fresh perspectives and possibilities driven by data and algorithms.\nFor instance, the use of creative GAI as a support tool to conduct textual writing, marketing (using chatGPT), and computational coding (using Github Copilot) has been associated with increments in time to complete the tasks when compared to control. However, while highly disruptive, the emergence of creative GAI has important limitations in relation to creativity-related tasks.\nLLMS, creative GAI still fails to respond with high-quality outputs when fed prompts contain technical language and offer very minimal interactive and creative flexibility for domain experts. A possible solution is the infusion of knowledge through domain-specific Knowledge Graphs and Ontologies. Domain-specific ontologies have been used to improve GAI in image classification and show promise to address other creative areas, such as music composition. While this collaborative role of creative GAI is cross-cutting to all fields, we will focus on the field of musical composition as the area of our discussion.\nTo summarize, the main contributions of this work are as follows:\n\u2022 We first show that current publicly available text-to-music approaches do not sufficiently use musical theoretic terms in prompts to generate music in a survey.\n\u2022 Secondly, we show that we can manually translate natural language prompts to SPARQL queries to extract domain knowledge from the KGs and generate a dataset for further training.\n\u2022 Furthermore we show, using a proof-of-concept model, that we can use LLM to translate natural language prompts into SPARQL queries on the KGs.\n\u2022 Finally, we propose a process to directly infuse relevant knowledge in the KGs into the AI."}, {"title": "Research Questions", "content": "The empirical evaluation aims to formulate the following research questions:\nA. Can existing creative generation models effectively use domain-specific technical language to guide the generation procedure?\nB. How can we use symbolic knowledge bases to improve the creative generation model's understanding and use of domain-specific technical terms?"}, {"title": "Related Work", "content": "Generative AI models have made remarkable contributions across diverse domains, revolutionizing creativity, innovation, and data generation. Their impact spans various fields including art and design, music, healthcare and medicine, gaming, and virtual reality. These models enable the creation of digital content such as images, music, and natural language. Notably, ChatGPT, DALL-E-2 [139], and Codex [46] have gained significant attention.\nIn the field of music, several studies have explored the application of machine learning techniques to generate, complete, and modify music pieces. One notable work in this domain is Jukebox, proposed by [56], which is a generative model capable of producing raw audio music with coherence extending to multiple minutes. Additionally, there have been successful attempts to generate high-fidelity music from text descriptions, as demonstrated by the work of [4]. This shows the advancement in generative models for music generations and hihglight the potential for AI-driven music composition. They learn distributions of musical sequences and use this to predict the most likely next element of a piece of music. Moreover, AIVA is another generative model that employs deep learning techniques to analyze and learn from music database to create music pieces in a variety of different styles and genres. While these endeavors have achieved success in generating music compositions, they may still yield unfavorable results when prompted with specialized requests.\nOn the other hand, numerous studies have put forward approaches for word embeddings, which involve representing words as real-valued vectors that capture their semantic meaning. In this representation, words that are closer together in the vector space are assumed to have similar meanings. Numerous works use word embedding based approaches on music to create embeddings for symbolic music data."}, {"title": "Resources", "content": "In our experiment, two Knowledge Graphs, Chord Corpus (ChoCo) and Harmory, and one generative model, muBERT, are used."}, {"title": "Proposed approach", "content": "In this section, we outline, for each research question, the approach, evaluation, and results obtained.\nRQ1. Approach. We conduct a user-based survey on the accuracy of creative GAI-generated music clip to the human-natural language prompt.\nWe create six musical clips (three-derived from the naive prompts and three from specialists). We ask six musicians to rate each musical clip with the question: \"Please rate to what extent the clip reflects the requested prompt\". Ratings are expressed using a likert type scale of four points, ranging from \"Not at all\" to \"Perfect Match\". We analyze the survey responses using descriptive statistics and divide between naive and expert-based prompts.\nRQ2. Approach. We evaluate the feasibility of using domain-specific KGs to improve (music) AI in its ability to collaborate with human professionals (e.g. musicians). We test this methodology using two approaches:\nRQ2. Working hypothesis 1 - Approach. For our first approach for the KGs integration with to GAI, we manually translate natural language prompts from musicians into SPARQL Queries to extract knowledge from the ChoCo KG. For this study, we report the translated query, the knowledge extracted and showcase the data available to be used to train or to validate the responses of GAI tools by improving their ability to respond to specialized prompts.\nRQ2. Working hypothesis 2 - Approach. Our second approach for the KGs integration with to GAI is a combination of the musician natural language"}, {"title": "Discussions and Conclusions", "content": "In this paper, we show that current tools for generative AI to interact with musicians to create new songs are not yet sufficient to capture the semantic of technical prompt. Our survey shows that current generative AI tools are better in interpreting more general prompts than technical terms. The generated audio files to the general prompts were evaluated more correct than those from technical prompts.\nThe outlined approach in section 1.5, we introduced an approach implemented in image generation. During our research, the working hypothesis for future research is, that an adoption of the underlying generative architecture to the sound could be beneficial. For the entire architecture, it is important to state that for image generation the convolutional elements are based on squares. This aspect needs to be adapted for future work to fit the vectorized structure of audio files. Furthermore, the current approach involves GANs as the main generative model. Research has indicated that diffusion models outperform current GAN architectures [52].\nFor the retrieval of the KG for the generative model, it is shown in Figure 1.1 and section 1.6 that the generation of SPARQL queries can when executed on the KG lead to error situations. Therefore, we propose to use the second outlined approach to feed the structural information from the KG into the graph neural network (GNN). Nevertheless, it might be still beneficial for researchers to make the endpoint more accessible and train a specific dataset for the text to SPARQL translation using LLM. A similar diverse dataset as used in the paper from might introduce value for the querying of KGs."}, {"title": "Can Machines Identify Great Works of Art?", "content": "In this paper, we consider how the Semantic Web can be applied for creative AI as whether machines can use data enriched by knowledge graphs (KGs) to improve their performance to identify the greatness of artworks, a subjective assessment norm often used by humans, through the objective properties pertained by the works."}, {"title": "Introduction", "content": "The aim of this work is to investigate the autonomous identification ability of great paintings by machines.\nDespite numerous attempts in art history to address objective traits of the common understanding of \"great\" art by separating aesthetics (i.e. artistic"}, {"title": "Related Work", "content": "Traditional approaches to automatic art analysis use hand-crafted features and Machine Learning algorithms [13, 32, 93]. However, these approaches face challenges in acquiring explicit knowledge of the attributes associated with specific artists or artworks. Such knowledge is often based on implicit and subjective experiences that even human experts find difficult to articulate [39, 145].\nIn contrast to these approaches, representation learning has been proven to be effective in various Computer Vision tasks, such as applying deep neural networks to art analysis [91]. Numerous works have explored the use of Deep Learning (DL) techniques, including both single-input [45] and multi-input models [158], for predicting artwork attributes based on visual features.\nAdditionally, researchers in this field have investigated other areas of interest such as visual link retrieval [37, 151], object detection [151, 73, 76], and near-duplicate detection [156].\nPredicting artwork attributes using visual information is a challenging task. However, this can be overcome with the inclusion of contextual information alongside visual features. For instance, utilizing KGs to represent contextual information and integrating it into DL models. Garcia et al. [69] introduced the ContextNet framework, which combines a multi-output Convolutional Neural Network (CNN) for attribute prediction based on visual features with an encoder that leverages non-visual information from artistic metadata encoded using a KG. However, this approach has limitations due to the availability of metadata and a lack of consideration for other distinguishing features of available artworks. These limitations are also reflected in the design of the ontology.\nTo address these limitations, Castellano et al. [36] proposed to use external knowledge from Wikipedia, which offers a vast amount of structured information. By incorporating this external knowledge source, it is possible to enhance the understanding of artwork attributes by overcoming the lack of domain information for new artworks and considering relationships between artists, such as"}, {"title": "Resources", "content": "ArtGraph. The main dataset used in this work is ArtGraph, a KG in the art domain, based on WikiArt [133] and DBpedia [170]. The dataset represents and describe concepts related to artworks [35]. The graph is made up of 135,038 resources out of which 116,475 are artworks from 186 periods. The dataset contains information about the date, title, genre, image, dimensions, URLs to Wikipedia, Wikidata, and DBPedia, and name and birth date of the author. The ArtGraph KG is accompanied by an ontology built around two main classes: Artist and Artwork (Fig. 2.1).\nFor the purpose of this initial paper, the utilized components of ArtGraph are:\n\u2022 createdBy object property: connects artworks with artists\n\u2022 wikipedia_url datatype property: provides the Wikipedia webpage URL of an artist 5\n\u2022 image_url datatype property: has the URL of painting images\nWikidata. Wikidata is a centralized knowledge base (KB) that stores structured data for Wikipedia and other Wikimedia projects, providing a common data source for information shared across multiple language editions. It supports the querying and retrieval of specific data through its triple-based structure.\nThis paper focuses on the below components of this KB:\n\u2022 has works in the collection (P6379 ) object property: connects an artist with the collection that has works made by him\n\u2022 schema:about object property: inherited by schema.org, this property links an artist's Wikipedia webpage URL (i.e. https://wikipedia.org/wiki/Pablo_Picasso) with the corresponding Wikidata URL (i.e. https://www.wikidata.org/wiki/Q5593)\n\u2022 art museum (Q207694 ) class: from this class, the top 11 most visited art museums [106] were chosen: Louvre Museum (Q19675 ), Vatican Museums (Q182955), British Museum (Q6373), Tate Modern (Q193375), National"}, {"title": "Proposed approach", "content": "Data processing\nThe primary data source is the ArtGraph KG from which the Artwork instances were filtered using SPARQL to keep only those that were connected to an Artist instance via the createdBy property. Afterward, linking was performed between ArtGraph and Wikidata using the wikipedia_url data property of ArtGraph to get the equivalent Wikidata URL from the tail entity of triples with the format: wikipedia_url schema:about wikidata_url. Eventually, the painting images were downloaded using the ArtGraph image_url data property.\nCriteria for automatic labeling\nThe binary labeling of paintings as \u2018great works of art' or not was performed in an automated fashion by taking into account the cardinality of the has works in the collection Wikidata object property. In particular, for every painting that was included in the dataset: if its artist has published at least one artwork in the collection of at least one of the ten most visited museums, then the painting is"}, {"title": "Conclusion", "content": "The presented approach allows machines to identify the greatness of artworks, which has not been well-discussed in the literature, using techniques that combine knowledge-based and learning-based AI approaches. The greatness feature of artworks is based on subjective human assessment, which is considered to be hard for autonomous identification. We, therefore, interpret this subjective assessment feature by objective properties from Wikidata, such as whether the artists behind the works have works collected by top visited museums."}, {"title": "Limitation", "content": "The property we use attributes to artists The property we used in this paper, i.e., has artworks in the collection, is a property attributed to the artists instead of the artworks themselves. Hence our results may identify the style of"}, {"title": "Future work", "content": "We are going to enrich the current dataset with the DBpedia and Wikidata knowledge graphs. Furthermore, the hyperparameters of the machine learning model should be optimized. Additionally, we are going to investigate which features of works of art influence most of the models' predictions and identify which forms of art or greatness are difficult to recognize."}, {"title": "Conclusions", "content": "In this paper, we propose a machine-learning method using enriched data to identify the greatness of artworks. We trained the machine for understanding subjective human evaluation criteria by using objective properties in Wikidata. The limitations we showed point to the future direction of our work."}, {"title": "Are Large Language Models the End of Knowledge Graphs? An Experiment in Story Completion", "content": "Within the domain of Creative AI we choose the task of story completion. Completing a short story clearly falls in the domain of \u201cCreative AI\". Furthermore, it is a task at which LLMs can be expected to perform well, so making the question of whether KGs can contribute to LLMs not simply a foregone conclusion. Finally, it is one of the few tasks in the domain of Creative AI for which there exist validated corpora that can be algorithmically validated. Our hypothesis\nthatH1: Large Language Models (LLMs) will perform so well on Creative AI tasks that injection of KG's will not further improve their performance\nH2: Small Language Models (SLMs), which we expect to perform significantly worse on this Creative AI task, will benefit from the injection of KG's for their performance on story completion."}, {"title": "Related Work", "content": "The field of story completion has witnessed remarkable advancements in recent years, driven primarily by the growth of LMs and their ability to generate coherent text [84]. Researchers have explored various approaches to further enhance the performance of LMs in story completion tasks. One promising direction is the incorporation of KGs, which offer structured representations of domain-specific information. By leveraging the rich connections between entities, concepts, and relationships encoded in KGs, researchers have aimed to enhance LMs' ability to generate more coherent and semantically accurate story completions. Several studies have demonstrated the efficacy of integrating KGs into LMs, resulting in improved narrative coherence, increased factual consistency, and enhanced contextual understanding.\nChen et al. [44] proposed a neural network model that integrates three types of information: narrative sequence, sentiment evolution, and commonsense knowledge from the ConceptNet. By combining these sources of information, they achieved improved performance compared to state-of-the-art approaches on the ROCStory Cloze Task dataset.\nGuan et al.[75] extended the GPT-2 model by incorporating external commonsense knowledge from ConceptNet and ATOMIC. By post-training the model on knowledge examples derived from these sources, they effectively enhance the long-range coherence of the generated stories. Additionally, to ensure the generation of plausible narratives, they introduce a classification task that distinguishes true stories from automatically constructed fake stories. This auxiliary task encourages the model to capture causal and temporal dependencies between sentences, leading to improved inter-sentence coherence and reduced repetition. Through comprehensive automatic and manual evaluations, the experimental results demonstrate that their model outperforms strong baselines in terms of logicality and global coherence, thereby generating more reasonable stories.\nYang et al. [182] presented an alternative method of incorporating information from a KG into the prompt. They started by extracting keywords from the context story and linking them using only text-based information to construct a KG. Furthermore, they incorporated knowledge from external sources such as DBPedia, ConceptNet, and WordNet. The resulting KG was used to extract triples, which were then injected into the prompt. Notably, their approach differs from ours as it lacks information regarding the classes of named entities.\nGoing beyond all the above, our proposed approach focuses particularly on the complexity of the LM. We compare the effect of incorporating information from KGs in LMs of different sizes."}, {"title": "Resources", "content": "We chose to utilize instruction-fine-tuned language models\u00b2, trained on the Alpaca [160] and FLAN [50] instruction datasets as our SLMs. Alpaca is available in different sizes (base, large, XL, XXL) making it possible to test our hypothesis. We decided to use Flan-Alpaca-Base (220M parameters), Flan-Alpaca-Large (770M parameters), and Flan-Alpaca-XL (3B parameters) to represent three different SLMs.\nIn addition, we are using GPT-3.5-turbo3 in order to compare the results of our KG-enhanced SLM to an LLM. The models will be tested on both ROCstories [116] and Possible Stories [15]. The model also known as text-davinci-003, is an advanced language model developed by OpenAI. It belongs to the GPT series and utilizes machine learning to generate human-like text. Trained on diverse internet text, it doesn't have access to specific training documents or personal data unless provided during conversation. Like its predecessors, GPT-3.5 employs transformer architecture, which revolutionizes sequential data processing by eliminating the need for sequential computation. With a size similar to GPT-3 (175 billion parameters), it excels at generating coherent and contextually relevant sentences. While expected to outperform previous models in language tasks, exact improvements are challenging to quantify without specific details or direct comparisons.\nThe ROCstories dataset contains context stories of four phrases and two possible candidate phrases [116]. One of the candidates is considered a good ending of the story, the other a wrong ending. The task of story completion then comes down to choosing which of the candidate phrases is the good ending.\nThe Possible Stories dataset contains a context story of four phrases [15]. For each context story, the dataset contains four candidate answers and a set of two questions. The good answer for a given story then depends on which question is asked. The task of story completion is then to find the good answer out of four candidate answers given a context story and a question."}, {"title": "Proposed approach", "content": "Our approach to enhancing a story completion prompt with the NERC information and WSD knowledge of WordNet can be described in three steps: (i) The extraction of named entities and their corresponding classes from the context stories. (ii) The disambiguation of the rest of the context story. (iii) The injection of the acquired knowledge within the prompt."}, {"title": "Evaluation and Results", "content": "We compared our proposed approach to a baseline composed of the three Flan-Alpaca models (base, large, XL) as the representative of SLMs, and GPT-3.5-turbo as the representative of LLMs. The evaluations were done on two different story completion datasets: ROCstories and Possible Stories. For both, the relevant information was given as the prompt.\nWhen injecting background knowledge we added the context information obtained from the context story and WordNet [111] using the Lesk algorithm and SpaCy in the form of triples. This knowledge follows the actual prompt. We tested our approach on 1571 ROCstories and on 3414 Possible Stories. The models were used as it is and not trained by us.\nTable 3.1 compares the accuracy of our approach and a baseline method across four levels of model complexity in two datasets, in a zero-shot experimental setting. On ROCStories dataset, for Flan-Alpaca models, the baseline approach achieves accuracy scores of 0.78, 0.89, and 0.98 for the Base, L, and"}, {"title": "Discussion and Conclusions", "content": "Discussion of Results. The largest language models reach performance close to perfection in the story completion task on the ROCStories in a zero-shot setup and with no symbolic knowledge injected. The smallest showed room for improvement so we tried injecting knowledge into them.\nWe injected knowledge in the form of triples that were added to the prompts sent to the smallest LLMs. This knowledge encompassed Named Entity Recognition and Classification (NERC) and Word Sense Disambiguation (WSD) information extrapolated from the input text (a story from ROCStories). NERC was performed using SpaCy. For WSD, we relied on WordNet as a Knowledge Base.\nThe injection of knowledge always and consistently caused a significant decrease in performance on the task of story completion.\nOur experiments show that the amount of knowledge injected matters: in the few-shot learning setting, the injection of all WSD and NERC triples significantly decreased accuracy when providing triples extracted from both the"}, {"title": "Conclusion", "content": "Our first hypothesis was easily confirmed in our experiments: LLMs have a near-perfect performance on the story completion task. However, our experiments clearly falsified our second hypothesis: the injection of knowledge always and consistently caused a significant decrease in performance on the task of story completion. This conclusion raises a number of questions to be investigated in future work.\nTypes of knowledge: Our injected knowledge was very linguistic in nature (NERC and WSD). Perhaps the injection of more factual or commonsense knowledge would be more effective in boosting the performance of small language models.\nAmounts of knowledge: Our experiments showed that the amount of injected knowledge also plays a crucial role. Again, experiments on the role of this parameter are left for future work.\nNature of the task: Our experiments are limited to choosing among two predefined completions. Future work should investigate the more creative task of actually generating a story completion. This would locate this work even more deeply in the domain of Creative AI."}, {"title": "Human After All - AI Capabilities and People's Rights", "content": null}, {"title": "A Decentralized Ecosystem to Empower Artists to have Ownership and Control over their AI-generated Art", "content": null}, {"title": "Semantic Web for Creative Al", "content": "The technologies falling under the umbrella term Generative AI, e.g. ChatGPT and DALL-E 2 by OpenAI [127], showed great potential in performing creative tasks according to user-provided prompts, e.g., storytelling or painting, so"}, {"title": "Introduction", "content": "Art has long been recognized as a powerful means of creative expression and a reflection of human culture. Artists invest their time, energy, and emotions into the creation of their works, giving birth to unique pieces that capture the essence of their vision. These works hold immense personal and societal value, often becoming an integral part of our cultural heritage.\nHowever, with the rise of generative AI, the dynamics surrounding artistic creation and ownership have begun to undergo significant transformations. Generative AI systems have demonstrated remarkable capabilities in producing art that can mimic or even surpass human creativity [139]. While this technological advancement brings forth exciting possibilities, it also raises profound concerns among artists who fear losing control over their creations [17]."}, {"title": "Related Work", "content": "Blockchain for copyright protection. Blockchain [118] can be considered as a data structure where blocks of transactions get appended in an immutable chain fashion, thanks to the use of cryptographic techniques used to link blocks. Each ledger is distributed and synchronized among the participating nodes through peer-to-peer protocols based on consensus. Common approaches used for the management of intellectual properties in the context of blockchain are based on the use of smart contracts and external storage infrastructure, particularly IPFS. Design schemes [108, 109] that uses perceptual hash functions to generate hashes for the image as its digital signature and an infrastructure based on blockchain and IPFS. Images are watermarked and smart contract are used"}, {"title": "Proposed Approach", "content": "To address RQ1.1, we present Platform for Independent Creators and Artists Supporting Self-Ownership (PICASSO), an architecture to manage the creation of works of art and preserve artists' interests. Figure 4.1 shows the main components of PICASSO. In the following, we describe how these components are integrated to achieve the main goal of preserving ownership.\nWeb Interface / Controller. This module is the main entry point of PICASSO. Artists start the process by choosing an operation. There are three main operations: (1) the inclusion of new art, (2) consulting open data about a specific work of art, and (3) a transaction to change the ownership of existing art. The Web interface checks for required parameters according to the requested operation. Parameters can include the digital version of the art, credentials to the personal Solid pod, the prompt used by the generative AI, and contextual knowledge about the artists involved.\nAfter the request validation, the controller prepares the data, instantiates the necessary data structures, and continues the execution by registering the operation on the blockchain (case 1 or 3) or directly consulting art information on the Solid pod (case 2).\nBlockchain / Smart Contract. As described in Section 4.4 with the Ethereum use-case, the combination of blockchain with smart contracts presents a suitable solution for copyright protection and trade. In our scenario, two operations will always be registered on the blockchain: the creation of a new piece of art, and the transference of ownership from one group of artists to another. Information stored on the blockchain is restricted to the identification of the entities involved in the transaction (e.g., artists) and the price of the artwork. Private information regarding the owner's consent is stored on their personal Solid data pod."}, {"title": "Theoretical Results: Use case", "content": "We demonstrate the feasibility of our approach through a description of a possible implementation and technical details about the workflow. As described in Section 4.5, the main actors and components involved are:\n\u2022 Each artist collective member; who owns the art for the case of data insertion.\n\u2022 An artist who wants to buy a prompt or a piece of generated art.\n\u2022 A Generative AI system, owned by each artist collective and trained on their real art, in order to mimic and preserve the style of the artists. The specific implementations could be different from one artist collective to the other.\n\u2022 Web Interface/ Controller component that facilitates the user with the proposed infrastructure implementing a ReST API or a complete web interface. This can be exposed through a web server of the artist collective."}, {"title": "Conclusion and Future Work", "content": "In contrast to their efficiency, generative AI systems are becoming more and more detrimental for artists and creators regarding the copyright and ownership of their AI-generated collectives. We present PICASSO, a framework that utilizes decentralized technologies and semantic web technologies to protect the copyrights and ownership of AI-generated pieces of art. We used Solid to store the AI-generated artifacts' data and Blockchain technology to record and confirm transactions among the artists. The novelty of our work is that we guarantee a safe, trustable environment for the artists and owners of AI-generated artifacts using semantic web technologies.\nFor future works, it is necessary to discuss what is public and private art metadata, as well as discuss ownership regulations. Furthermore, identities of artist collectives and artists, in general, can be managed by using the Decentralized Identifiers (DIDs) [55], allowing the creation of digital identities that are decentralized and globally resolvable through a blockchain infrastructure."}, {"title": "ChatGPT, is this legal? Impact of the unintended misuse of AI solutions", "content": null}, {"title": "Semantic Web and Creative AI", "content": "Creative AI is a sub-field of AI aiming to generate artificial relics using existing digital content by examining training examples, learning their patterns and distribution [3]. Users can interact with creative AI tools by providing a prompt and receiving an answer that can have the form of a text, image, audio, video or some combination of the above. As with most new technologies, these tools are not immune to misuse, whether intended [167, 81] or unintended. While creative AI tools possess a broad coverage of information and have seen incredible success, the generated content can often be inappropriate for certain audiences or recommend actions that may be have legal implications.\nSemantic web technologies and knowledge graphs (KGs) can play a significant role in addressing some of the issues posed by creative AI models. By incorporating KGs to creative AI tools, the models can access contextual information, enabling them to validate the facts they generate, be more coherent and filter their content better, providing additional information to the users."}, {"title": "Introduction", "content": "ChatGPT\u00b9 and other Large Language Models (LLMs) are rapidly altering the way that we search for information. With proficiency at-par or even exceeding humans, these tools have become ubiquitous in all aspects of life, from education to software engineering [120"}]}