{"title": "DiffLight: A Partial Rewards Conditioned Diffusion Model for Traffic Signal Control with Missing Data", "authors": ["Hanyang Chen", "Yang Jiang", "Shengnan Guo", "Xiaowei Mao", "Youfang Lin", "Huaiyu Wan"], "abstract": "The application of reinforcement learning in traffic signal control (TSC) has been extensively researched and yielded notable achievements. However, most existing works for TSC assume that traffic data from all surrounding intersections is fully and continuously available through sensors. In real-world applications, this assumption often fails due to sensor malfunctions or data loss, making TSC with missing data a critical challenge. To meet the needs of practical applications, we introduce DiffLight, a novel conditional diffusion model for TSC under data-missing scenarios in the offline setting. Specifically, we integrate two essential sub-tasks, i.e., traffic data imputation and decision-making, by leveraging a Partial Rewards Conditioned Diffusion (PRCD) model to prevent missing rewards from interfering with the learning process. Meanwhile, to effectively capture the spatial-temporal dependencies among intersections, we design a Spatial-Temporal transFormer (STFormer) architecture. In addition, we propose a Diffusion Communication Mechanism (DCM) to promote better communication and control performance under data-missing scenarios. Extensive experiments on five datasets with various data-missing scenarios demonstrate that DiffLight is an effective controller to address TSC with missing data. The code of DiffLight is released at https://github.com/lokol5579/DiffLight-release.", "sections": [{"title": "1 Introduction", "content": "With the acceleration of urbanization, the surge in the number of vehicles in cities has led to increasingly severe traffic congestion and pollution problems [1]. Intersections, where traffic congestion often occurs, become a key in addressing these problems. To this end, solving the traffic signal control (TSC) problem is crucial for reducing traffic congestion in intersections by controlling traffic lights.\nOver the years, many approaches have been developed to tackle the TSC problem, which can be categorized into conventional approaches and reinforcement learning-based (RL-based) approaches. Conventional approaches, like Fixed-time [2], SCOOT [3] and SCATS [4], have been widely deployed in different cities. However, these approaches struggle to adapt to the inherent stochasticity and highly dynamic nature of real-time traffic conditions, limiting their effectiveness in responding to dynamic traffic demands.\nRecently, reinforcement learning (RL) is introduced into TSC to enable adaptive traffic signal control [5, 6, 7, 8, 9, 10, 11, 12, 13]. Unlike conventional approaches, RL-based approaches for TSC deploy a learnable agent at each intersection, allowing traffic signals to be adjusted dynamically based on real-time traffic conditions. However, most existing RL-based approaches for TSC assume that traffic"}, {"title": "2 Preliminaries", "content": ""}, {"title": "2.1 Partially Observable Markov Decision Process", "content": "We consider a partially observable Markov decision process (POMDP) in the offline setting, defined as a tuple (S, A, P, R, \u03a9, \u039f, \u03b3). S is the state space, and st \u2208 S denotes the state at time t. A is the set of available actions and at \u2208 A denotes the action of an agent at time t. The observation ot \u0395 \u03a9 observed by the agent is part of the state st and can be derived from the function O(st). rt = R(st) is the immediate reward of an agent at time t. P and y denote the transition probability function"}, {"title": "2.2 Traffic Signal Control with Missing Data", "content": "We formulate TSC with missing data as POMDP, and consider TSC in a traffic network with several intersections. Agents are deployed at each intersection of the traffic network. As illustrated in Figure 1, for a four-way intersection, there are twelve traffic movements from the intersection's entrance lane lin to the departure lane lout and four pairs of traffic movements without conflict comprise four traffic signal phases. For example, the traffic signal phase of the intersection in Figure 1 is phase-A which involves\nmovement-2 = {lin \u2192lout, lin\u2192 lout, lin\u2192 lout} and\n12 711\nmovement-8 = {lin \u2192 lout, lin\u2192 lout, lin\u2192 lout}.\n18\n8 10 11 12\nIn this paper, the observation of contains the number of vehicles Lnum and queue length Lqueue in every entrance lane of the local intersection. Available actions are four phases composed of traffic movements without conflict. Tout Pout Fout in Figure 1: Illustration of a four-way inter- The immediate reward rt is defined as the sum of the section with 12 traffic movements and 4 queue length \u03a3lin Lqueue. Due to the lack or error of sen- traffic signal phases. sors resulting in missing traffic data, ot and rt, which are derived from traffic data, could be missing in a particular pattern. We consider random missing and kriging missing patterns detailed in Appendix C.2. To simplify the problem, we assume that ot and rt in an intersection are missing simultaneously."}, {"title": "2.3 Diffusion Models for Reinforcement Learning", "content": ""}, {"title": "Diffusion model.", "content": "Diffusion models [15, 24, 25], as a powerful generative model, provide a framework to model the data generative process as a discrete diffusion process. Diffusion models consist of two processes: the forward process and the reverse process. In this paper, the forward process is defined as $q(x_k|x_{k-1}) := \\mathcal{N}(\\sqrt{1 - \\beta_k}x_{k-1}, \\beta_kI)$ by the Markov process, where \u03b2k is the variance of the noise at timestep k. We adopt DDIM sampler [24] to sample in the reverse process in order to accelerate sampling. DDIM sampler is parameterized with $p_\u03b8(x_{k-1}|x_k, x_0) := \\mathcal{N}(\u03bc_\u03b8(x_k, k), (\u03c3_\u03b8)^2I)$, which can be optimized by a simplified surrogate loss,\n$\\mathcal{L}(\u03b8) := E_{k~U(1,K),\u03b5~N(0,1)}[||\u03b5_\u03b8(x_k, k) \u2013 \u03b5||^2]$.\n(1)\nThe reverse process begins by sampling an initial noise $x_K ~ N(0, I)$. The estimated mean of Gaussian is $p_\u03b8(x_k, k) = \\sqrt{\\bar{\u03b1}_{k-1}}\\hat{x}_0 + \\sqrt{1 -\\bar{\u03b1}_{k-1}}\u03b5_\u03b8(x_k, k)$ where $\\hat{x}_0 = \\frac{1}{\\sqrt{\\bar{\u03b1}_k}}(x_k - \\sqrt{1 -\\bar{\u03b1}_k}\u03b5_\u03b8(x_k, k))$, $\u03b1_k = 1 - \u03b2_k$, $\\bar{\u03b1}_k = \\prod_{i=1}^{k} \u03b1_k$ and $\u03b5_\u03b8(x_k, k)$ is a predictor used to estimate noise."}, {"title": "Diffusing decision-making.", "content": "We make a brief introduction to the diffusion model adopted to address decision-making problems in RL. Among existing works on diffusion-based RL, Diffuser [16] chooses to diffuse on an observation-action trajectory with returns condition to directly generate actions. Decision Diffuser [17] chooses to diffuse only on observation trajectory with returns condition in order to obtain better performance due to the less smooth nature of discrete actions. We focus on introducing the approach diffusing on observation trajectory \u03c4 sampled from offline dataset D. We denote the k-step denoised output of the diffusion model as $x_k (\u03c4)$. In this approach, the observation trajectory would be diffused to generate ot+1. However, only diffusing on observation trajectory is not enough to make decisions. An inverse dynamics model f\u03b8 is adapted to generate the action at that makes the observation transit from ot to Ot+1,\n$a_t := f_\u03b8(o_t, o_{t+1})$.\n(2)"}, {"title": "Classifier-free guidance.", "content": "Classifier-free guidance [26] aims to learn the conditional distribution $q(x(\u03c4)|y(\u03c4))$ without a pre-trained classifier. Instead, it learns both a conditional $\u03b5_\u03b8(x_k (\u03c4), y(\u03c4), k)$ and an unconditional $\u03b5_\u03b8(x_k (\u03c4), \\cent, k)$ for the noise. Then, the perturbed noise $\u03b5_\u03b8(x_k (\u03c4), \\cent,k) + w(\u03b5_\u03b8(x_k(\u03c4),y(\u03c4), k) \u2013 \u03b5_\u03b8(x_k(\u03c4), \\cent, k))$ can be used to generate samples, where w is the guidance scale."}, {"title": "3 Methodology", "content": "In order to effectively unify traffic data imputation and decision-making for TSC with missing data, we consider both of them as a conditional generative modeling problem via diffusion models,\n$\\max_{\u03b8} E_{\u03c4~D} [log p_\u03b8 (x^0 (\u03c4)|y(\u03c4))]$,\n(3)\nwhere p\u03b8 is a learnable model distribution to estimate the conditional data distribution of trajectory $x^0(\u03c4)$, conditioned on y(\u03c4). We construct our generative model according to the conditional diffusion process,\n$q(x_k (\u03c4)|x_{k-1}(\u03c4)), p_\u03b8(x_{k-1}(\u03c4)|x_k(\u03c4), x^0(\u03c4), y(\u03c4))$,\n(4)\nwith conditions as,\n$y(\u03c4) := [r(\u03c4), y' (\u03c4)], y'(\u03c4) := [\u03c4_{obs}, \u03c4_{nei}]$,\n(5)\nwhere r(\u03c4) is observable rewards, $\u03c4_{obs}$ is the observed part of trajectory \u03c4 of local intersection and $\u03c4_{nei}$ is the observed observations of neighboring intersections. Specifically, the observed part is the historical data collected by sensors, while the observable part refers to the data that could be collected in the past and future. Due to discrete and high-frequent actions in TSC, we choose to diffuse only on observations and use the inverse dynamic model to generate the action, which has a better performance proven in Appendix F.1 and F.6. We define the observation trajectory \u03c4 under data-missing scenarios as,\n$\u03c4 := [o_{t-C+1}, o_{t-C+2},\u2026\u2026, \\hat{o}_t, \\hat{o}_{t+1},\u2026, \\hat{o}_{t+H}]$,\n(6)\nwhere ot is the observation that has been observed, $\u00f4_t$ is the unobserved observation that needs to be generated, C is the length of historical observations and H is the horizon of future observations. According to the definition of observation trajectory \u03c4, we specify \u03c4obs as the observed part of \u03c4 from time t \u2013 C + 1 to t. Additionally, $\u03c4_{nei} = \\bigcup_{N} f_{nei}^i(\u03c4^i)$ represents the observations of entrance lanes from all neighboring intersections that feed into the entrance lanes of the local intersection, as shown in Figure 1, where \u03c4\u00b2 denotes the observation trajectory of the neighboring intersection i and N is total number of neighboring intersections. Furthermore, we define \u03c4obs as the observable part of the entire trajectory and \u03c4mis as the missing part.We detail r(\u03c4) in Section 3.1."}, {"title": "3.1 Partial Rewards Conditioned Diffusion", "content": "We adopt partial rewards as the condition instead of returns [16, 17, 19], which can be expressed as,\n$r(\u03c4) := [r_{t-C+1},r_{t-C+2},\u00b7\u00b7\u00b7,\\hat{r}_t, \\hat{r}_{t+1},\u00b7\u00b7\u00b7, r_{t+H}]$,\n(7)\nwhere rt is the observable reward and \u00eet is the missing reward. Since under data-missing scenarios, sensors deployed to collect traffic data for rewards may malfunction or be lacking. The absence of partial rewards makes it hard to calculate returns. Therefore, we have to explore how to make decisions with partial observable rewards."}, {"title": "3.2 Diffusing with Spatial-Temporal Transformer", "content": "The noise model with a U-Net structure is widely applied in image generation [15, 24, 29, 30], control [16, 17, 19] and other fields. However, it is hard to be applied to capture the spatial-temporal dependencies in TSC. The emergence of Transformer [31] and its applications on spatial-temporal modeling [32, 33, 34, 35] provide a promising solution to deal with it. In this section, we design a Spatial-Temporal transFormer (STFormer) structure to effectively model the spatial-temporal dependencies in TSC, which includes a data embedding layer, stacked L spatial-temporal encoder"}, {"title": "3.3 Diffusion Communication Mechanism", "content": "Observations of neighboring intersections are crucial for TSC with missing data [14]. However, due to the possible absence of observations from neighboring intersections, the traffic signal could be controlled ineffectively. For instance, we assume an extreme situation where there is no available observation in both the local intersection and neighboring intersections. In this case, observation trajectories of intersections are all masked by noise, leading to difficulty in decision-making at the local intersection. Therefore, we propose a Diffusion Communication Mechanism (DCM) to disseminate observation information generated by the noise model in the reverse process among intersections. Formally, we formulate DCM as,\n$\u03c4_{nei}' = \\{\n\\bigcup_{N} f_{nei}^i(\u03c4^i), k = K,\\\\ \n\\bigcup_{N} f_{nei}^i(\\frac{1}{\\sqrt{\\bar{\u03b1}_k}} (x_k (\u03c4^i) - \\sqrt{1 -\\bar{\u03b1}_k}\u03b5_\u03b8(x_k (\u03c4), k, y' (\u03c4),c,m))), k < K.\n$\n(10)\nThe reverse process begins by inputting original observations of neighboring intersections with missing data. During diffusing, we predict (T\u00b2), which is the same in Section 2.3. With the help of DCM, generated observations of neighboring intersections could be spread from neighboring intersections for better decisions of the agent at the local intersection. Note that we train our model with ground-truth values collected from neighboring intersections and only use DCM in the inference process."}, {"title": "3.4 Training and Inference of DiffLight", "content": "Training process. Given an offline dataset D which consists of observation trajectories, rewards and actions, we train the reverse process p\u03b8 parameterized through the noise model \u03b5\u03b8, and the inverse dynamics model f\u03b8 in DiffLight with the following loss,\n$\\mathcal{L}(\u03b8) := E_{(o,o',o')\u2208D}[||a \u2013 f_\u03b8(o, o')||^2 \u00b7 1(o, o')]+$\n$E_{k,\u03b5,\u03b2~Bern(p)} [||\u03b5_\u03b8(x_k(\u03c4), k, y'(\u03c4), (1 \u2212 \u03b2)r(\u03c4) + \u03b2\\cent) \u2013 \u03b5||^2]$.\n(11)\nFor each trajectory T, we sample noise $\u2208 ~ N(0, I)$ and a diffusion timestep $k ~ U(1, K)$, construct a masked noise array of observations $x_k (\u315c)$ with $\u03c4_{obs}'$, and predict the noise $\\hat{\u03b5}_\u03b8 (x_k (\u03c4), k, y'(\u03c4), r(\u03c4))$. Missing values in condition Thei are padded with zeros. It should be noted that we ignore the rewards condition r(\u03c4) with probability p and the inverse dynamics is trained with individual transitions without missing observation o or o'. For the training process of DiffLight, due to the inaccessibility of the ground-truth of missing data, we consider it self-supervised learning. In the pattern of random missing, given a trajectory 7 and conditions, we can separate the observed part into two parts and set one of them to miss. In the pattern of kriging missing, we randomly mask the whole trajectories of one observed intersection. Then, we can train the noise model \u03b5\u03b8 by solving Equation 11.\nInference process. DiffLight is deployed to every intersection in the traffic network in the inference process. Given rewards r(r), a C-length observed trajectory of local intersection \u012bobs with missing data and trajectories of neighboring intersections Thei, the agent can impute the missing observations of local intersection, predict the observations in the future and generate next action with Equation 2 and 9. In order to sample a high reward trajectory, the rewards from t + 1 to t + H are considered in r(T), which is set to 1."}, {"title": "4 Experiments", "content": ""}, {"title": "4.1 Experimental Setup", "content": "Experiment Settings We conduct our experiments on CityFlow [36], a traffic simulator widely used in various RL-based methods. Similar to existing work in [13], we set the phase number as four and the minimum action duration as 15 seconds.\nDatasets The datasets consist of two parts: offline datasets with missing data and real-world traffic flow datasets with traffic networks. We apply five real-world traffic flow datasets [9, 37] for comparison, including Hangzhou\u2081 (DHz), Hangzhou2 (DHz), Jinan\u0131 (D]N), Jinan2 (DIN) and Jinan3 (DN). Corresponding offline datasets are composed of training trajectories of three online methods. We detail the datasets in Appendix C.1. To simulate data-missing scenarios, we adopt masks of different missing rates in different missing patterns, including random missing (RM) and kriging missing (KM), to mask observations and rewards. We describe the details of two patterns and missing rates in Appendix C.2.\nEvaluation Metrics We use the average travel time (ATT) as the main metric for evaluation, which is widely used to evaluate the performance of TSC. It calculates the average time all the vehicles spend between entering and leaving the traffic network during simulation, which is formulated as,\n$ATT = \\frac{1}{N} \\sum_{i=1}^{N}(t^{leave}_i - t^{enter}_i)$,\n(12)\nwhere N is the total number of vehicles entering the road network, $t^{enter}$ and $t^{leave}$ are the entering time and leaving time for the i-th vehicle respectively. The lower ATT indicates a better control performance.\nCompared Methods We compare our method with Behavior Cloning (BC) [38] and offline approaches, including CQL [39], TD3+BC [40], Decision Transformer (DT) [41], Diffuser [16], Decision Diffuser (DD) [17]. Similar to the existing work in [14], we adopt store-and-forward method (SFM) [42], a rule-based method that has generally more stable performances, to impute missing observations and rewards for these approaches. We detail these approaches and SFM in Appendix D."}, {"title": "4.2 Performance under Data-Missing Scenarios", "content": "We train and test our method on all five datasets with different missing patterns and missing rates, and compare our method with all baselines. DiffLight performs the best on most of the datasets. We analyze experiments of different missing patterns below.\nRandom missing. In random missing, we can see that DiffLight achieves optimal or sub-optimal performance compared with baselines in all datasets in Table 1. Diffusion-based approaches, including Diffuser and DD, show a better performance than other baselines in most datasets. These diffusion-based approaches utilize a noise model to predict noise and generate actions or observations, which helps mitigate the disturbance caused by imputed observations and rewards during the diffusion process. Compared with diffusion-based approaches, the performance of other baselines without the diffusion process is disturbed by imputed observations and rewards more seriously.\nKriging missing. In kriging missing, DiffLight shows the best performance in most datasets in Table 2. Unlike the results of random missing, DD does not perform well in kriging missing compared with other baselines. Since DD must impute missing observations with the SFM model first, generate future observations with the diffusion model, and then use the inverse dynamics to generate actions, which leads to serious error accumulation. While other baselines generate actions directly, requiring only roughly imputed observations and rewards."}, {"title": "4.3 Ablation Study", "content": "We further evaluate the effectiveness of different parts in DiffLight with the following variants. (1) U-Net: this variant replaces STFormer with U-Net as the noise model and missing rewards input are zero-padded. (2) STFormer: this variant uses STFormer as the noise model and keeps missing"}, {"title": "4.4 Model Generalization", "content": "We evaluate the generalization performance of DiffLight on Hangzhou, and Jinan\u2081 with different missing rates. We train our method in a specific missing rate and test it on the same dataset with other missing rates. To better compare the generalization performance among models trained in different missing rates, we formulate the relative generalization performance as,\n$P_r = \\frac{P_g}{P_0}$,\n(13)\nwhere Pr is the relative generalization performance of the current missing rate, Pg is the performance of the model trained in other missing rates, and Po is the performance of the model trained in the current missing rate. The results in Figure 3 demonstrate that the generalization performance of DiffLight is excellent in most situations. If we train DiffLight in a high missing rate and test it in a lower missing rate, the performance of DiffLight remains stable. In contrast, if we train DiffLight in a low missing rate and test it in a higher missing rate, the performance of DiffLight would decrease slightly. As data with a higher missing rate has more complex missing situations, making it difficult for models to handle these situations."}, {"title": "5 Related Work", "content": "Traffic Signal Control TSC approaches can be categorized into conventional and RL-based methods. Conventional approaches like Fixed-time [2], SCOOT [3] and SCATS [4] have been widely deployed in different cities. In recent years, RL-based approaches for TSC get more attention. DQN algorithm is introduced into TSC in [5, 6, 7] for dynamic real-time control. Attention mechanisms are applied to promote inter-agent communication [9] and build universal models [10]. Max-pressure [8] and advanced-MP [13] are proposed to promote the performance of existing methods. TSC with missing data is considered with the help of the imputation model in the online setting. However, there is no existing work to solve this problem in the offline setting.\nDiffusion-based Reinforcement Learning There are various works applying the diffusion model to offline RL recently. Diffusion and deep q-learning are combined [18], demonstrating the potential of diffusion in RL. The state-action trajectory is encoded in latent space [43], enhancing credit assignment and reward propagation. In addition to methods relying on TD-learning, Diffuser [16] and Decision Diffuser [17] are proposed as planners to generate the trajectory with a conditional diffusion model. However, they are all studied under scenarios without missing data, while we model TSC with missing data.\nTraffic Data Imputation With the development of deep learning, RNN-based methods [44, 45, 46] show good performance for traffic data imputation. In subsequent studies, diffusion models are utilized to learn the complex distribution in traffic data [21, 22]. For TSC, store-and-forward method (SFM) [42] is proven to have a more stable performance than neural networks [14]. In this paper, we adopt SFM to impute observations and rewards for baselines."}, {"title": "6 Conclusion and Limitation", "content": "Conclusion In this paper, we introduce DiffLight, a novel conditional diffusion model designed for TSC in scenarios with missing data. Our approach centers on the Partial Rewards Conditioned Diffusion (PRCD) model, which addresses both traffic data imputation and decision-making in the presence of incomplete data. This model helps prevent missing rewards from disrupting the learning process. We address the challenge of capturing spatial-temporal dependencies across intersections by designing a Spatial-Temporal transFormer (STFormer) architecture as the noise model. Additionally, to enhance communication and control performance, we propose a Diffusion Communication Mechanism (DCM) that facilitates the propagation of generated observations. We conduct extensive experiments on different datasets and settings to demonstrate that DiffLight is an effective controller to address TSC with missing data.\nLimitation In this work, we only consider two missing patterns: random missing and kriging missing. While in the real world, the missing pattern in the traffic network is more complex. Meanwhile, we just adopt SFM which is similar to k-nearest neighbor (KNN) to impute the traffic data for baselines. In addition, we set y = 0 in the return Rt and only condition on partial rewards in DiffLight which could lead to the short-sightedness of agents. Future work could explore the influence on performance in more different missing patterns even mixed missing patterns, adopt more different imputation methods, and find out a more far-sighted method to control the traffic signals under data-missing scenarios."}, {"title": "A Broad Impacts", "content": "Our proposed method demonstrates effective abilities in TSC with missing data. It can handle different missing patterns and different missing rates when controlling traffic signals. Even in an intersection where there are no observed neighboring intersections, DiffLight can perform competitively against baselines with SFM. Moreover, the fast inference speed with fewer sampling steps and stable performance indicates that DiffLight can be deployed to achieve real-time control in the real world. However, a potential negative impact of this work is that bad decisions could lead to a collapse in the traffic network."}, {"title": "B The Details of DiffLight", "content": ""}, {"title": "B.1 Hyperparameters of DiffLight", "content": "In this section, we describe the details of hyperparameters,\n\u2022 We set the batch size as 64 and each sample contains the trajectory of the whole intersections in the traffic network. We train our model using Adam optimizer [47] with 2e-4 learning rate for 1.5e5 train steps.\n\u2022 We train DiffLight on NVIDIA GeForce RTX A5000 for around 15 hours and test it on the same GPU.\n\u2022 We choose the probability p of removing the condition information to be 0.25 and guidance scale \u03b1 = 1.2.\n\u2022 In DiffLight, we choose the length of historical observations C = 5 and the planning horizon of observation trajectory H = 3.\n\u2022 We use K = 100 for diffusion steps."}, {"title": "B.2 Structure of STFormer", "content": "STFormer is composed of a data embedding layer, stacked L spatial-temporal encoder layers, and an output layer. We detail each of them as follows.\nData embedding layer. Different inputs are embedded into embeddings e with the same dimension D by the data embedding layer which consist of separate MLPS MLP (\u00b7),\n$e_{dt} := f_{MLP}(k), e_{r} := f_{MLP}(R(\u03c4)),$\n$e_{ttr} := f_{MLP}(t_{0:T-1}), e_{ctr} := f_{MLP}(x^0(\u03c4)),$\n$e_{nei} := f_{MLP}(\u03c4_{nei})$\n(14)\nwhere to:T-1 is the timestep of trajectory, edt, ett, er, ectr and entr represent the embedding of diffusion timestep, trajectory timestep, rewards, trajectory of local intersection and partial trajectory of neighboring intersection separately.\nSpatial-temporal encoder layer. The spatial-temporal encoder layer, abbreviated as STE, is composed of Communication Cross-Attention module, Spatial Self-Attention module and Temporal Self-Attention module. We adopt the vanilla attention operator [31] in modules, represented as fatt (Q, K, V). The following slice notations are used to formulate attention modules. For the embedding of local intersection's trajectory ectr \u0395 IRL\u00d7D where L is the number of entrance lanes, the t slice is ectr \u2208 RL\u00d7D and the I slice is edir \u2208 RT\u00d7D For the embedding of neighboring intersections' partial trajectories entr \u2208 RL\u00d7(T\u00b7L')\u00d7D where L' is the number of neighboring intersections' entrance lanes taken into consideration, the I slice is eniir \u2208 R(T\u00b7L')\u00d7D.\nThe Communication Cross-Attention module, abbreviated as CCA, is designed to capture the spatial-temporal dependencies between the local intersection and neighboring intersections. As illustrated in Figure 1, entr contains information of entrance lanes from neighboring intersections feeding into lane l. This module can be formulated as,\n$f_{CCA}(e_{ctr}, e_{ntr}):= f_{att}(e_{ctr}, e_{ntr}, e_{ntr})$\n$e_{ctr}' = f_{CCA}(e_{ctr}, e_{ntr}) + e_{ctr}$\n(15)\n(16)\nThe Spatial Self-Attention module, abbreviated as SSA, and Temporal Self-Attention module, abbreviated as TSA, are designed to capture the spatial dependencies and temporal dependencies separately in the local intersection, which can be formulated as,"}, {"title": "4.2 Missing Pattern", "content": "th::\n$f_{SSA}(e_{ctr}):= f_{att}(e_{cir}, e_{ctr}, e_{ctr}), f_{TSA}(e_{ctr}) := f_{att}(e_{ctr}, e_{ctr}, e_{ctr})$\n(17)\nTherefore, the spatial-temporal encoder layer can be expressed as,\n$f_{STE} (e_{ctr}, e_{ntr}) := f_{MLP}(f_{SSA}(e_{ctr}) + f_{TSA} (e_{ctr})) + e_{ctr}$\n(18)\nTo simplify the expression, we omit the embedding of diffusion timestep, trajectory timestep and rewards in Equation 15, 16, 17 and 18. In the implementation, the embedding of diffusion timestep and trajectory timestep are added to every input of CCA, SSA and TSA, and the embedding of rewards is added to every input of SSA and TSA.\nOutput layer. We use an MLP layer as the output layer to convert the output of the spatial-temporal encoder layers into the noise we desire to predict."}, {"title": "C Datasets", "content": ""}, {"title": "C.1 Detials of Datasets", "content": "We apply five real-world traffic flow datasets in three cities of different sizes including Hangzhou and Jinan: (1) Hangzhou datasets: the road network contains 16 (4\u00d74) intersections with two traffic flow datasets, including Hangzhou, and Hangzhou2. (2) Jinan datasets: the road network contains 12 (3\u00d74) intersections with three traffic flow datasets, including Jinan1, Jinan2 and Hangzhou3. All these datasets are accessible in https://traffic-signal-control.github.io/.\nWe train AttendLight [10], Efficient-CoLight [48] and Advanced-CoLight [13] in isolation for each dataset from scratch until convergence. Then we collect all transitions in the replay buffer for each dataset during training. We present the converged performance of three methods in Table 4."}, {"title": "C.2 Missing Pattern", "content": "In TSC with missing data, missing patterns have a significant impact on the performance of control. In this paper, as shown in Figure 4, we conduct our experiments on random missing and kriging missing: (1) Random missing: traffic data collected by sensors for rewards and observations in every intersection is randomly masked with 10%~50% probability. (2) Kriging missing: there is always no traffic data collected in certain intersections with 6.25%~25.00% (1-intersection~4-intersection) probability in Hangzhou, and Hangzhou2, 8.33%~25.00% (1-intersection~3-intersection) probability in Jinan1, Jinan2 and Jinan3, and all neighboring intersections surround missing intersections are observable."}, {"title": "D Baseline Methods", "content": "In this section, we make a brief introduction to baseline approaches and the Store-and-forward method (SFM).\nBaseline approaches. We adopt six baseline approaches in experiments as follows:\n\u2022 BC is a type of imitation learning, where the agent learns to mimic the behavior of an expert demonstration. The agent is trained on a dataset of state-action pairs from the expert, and the goal is to learn a policy that can replicate the expert's actions given the same states.\n\u2022 CQL is an RL algorithm that aims to learn a conservative Q-function, which provides a lower bound on the true Q-values. This helps to address the issue of overestimation of Q-values, which can lead to poor performance in practice.\n\u2022 TD3+BC combines the TD3 algorithm with behavioral cloning. By incorporating BC into TD3, the agent can leverage expert demonstrations to accelerate learning and improve sample efficiency. TD3+BC offers the benefits of both TD3's stability and BC's ability to learn from expert demonstra- tions.\n\u2022 DT is a sequence-to-sequence model that casts reinforcement learning as a sequence modeling problem. It takes as input a sequence of past states, actions, and rewards, and it outputs a sequence of future actions that maximize the expected cumulative reward. We build DT based on the code https://github.com/kzl/decision-transformer/.\n\u2022 Diffuser is a diffusion-based approach for decision-making. Diffuser focuses on generating sequences of actions that lead to desirable outcomes by iteratively refining these sequences. We build Diffuser based on the code https://github.com/jannerm/diffuser.\n\u2022 DD is a diffusion-based approach for decision-making. DD diffuses over state trajectories and planning with an inverse dynamics model. We build DD based on the code https://github.com/ anuragajay/decision-diffuser.\nTo avoid non-convergence caused by missing data, we train baselines on datasets without missing data and test them under data-missing scenarios with observations and rewards imputed by SFM.\nStore-and-forward method. Since baselines cannot handle the data-missing scenarios, we adopt a rule- based SFM to impute observations and rewards for baselines. It is proved that SFM has more stable performance compared to learning neural networks [14]. In this paper, we model current observation as: $f(V_{t-1,k}) = Concat(U_l f'(l_i, k))$ and $f'(l_i, k) = \\frac{1}{l^{0, li-lj-1}}$, where Vt\u22121 is the intersection at time t, li \u2208 Vt\u22121 is a lane and lj is the k's neighboring lane connected by traffic movements. We set k as 12 in this paper."}, {"title": "E Proof of Partial Rewards Conditioned Diffusion", "content": "To prove that the aim of partial rewards conditioned diffusion is the same as the goal in Equation 3, we assume that the observable part of the trajectory and the missing part of the trajectory are collected by real sensors and virtual sensors separately, and the distribution of traffic data collected by two kinds of sensors are independent. Thus, the distribution in Equation 3 can be factorized as follows,\n$p_\u03b8(x^0(\u03c4)|y(\u03c4)) = p_\u03b8(x^0 (\u03c4_{obs}), x^0 (\u03c4_{mis})|y(\u03c4))$\n$= p(x^0 (\u03c4_{obs})|y(\u03c4)) \u00b7 p(x^0 (\u03c4_{mis})|y(\u03c4))$\n(19)\n$= p(x^0 (\u03c4_{obs})|r(\u03c4), y' (\u03c4)) \u00b7 p(x^0 (\u03c4_{mis})|r(\u03c4), y'(\u03c4))$\n$= p(x^0 (\u03c4_{obs})|r(\u03c4), y' (\u03c4)) \u00b7 p(x^0 (\u03c4_{mis})|y'(\u03c4))$\nThe distribution without rewards condition $p(x^0(\u03c4)|"}]}