{"title": "GLinSAT: The General Linear Satisfiability Neural Network Layer By Accelerated Gradient Descent", "authors": ["Hongtai Zeng", "Chao Yang", "Yanzhen Zhou", "Cheng Yang", "Qinglai Guo"], "abstract": "Ensuring that the outputs of neural networks satisfy specific constraints is crucial\nfor applying neural networks to real-life decision-making problems. In this paper,\nwe consider making a batch of neural network outputs satisfy bounded and gen-\neral linear constraints. We first reformulate the neural network output projection\nproblem as an entropy-regularized linear programming problem. We show that\nsuch a problem can be equivalently transformed into an unconstrained convex\noptimization problem with Lipschitz continuous gradient according to the duality\ntheorem. Then, based on an accelerated gradient descent algorithm with numerical\nperformance enhancement, we present our architecture, GLinSAT, to solve the\nproblem. To the best of our knowledge, this is the first general linear satisfiability\nlayer in which all the operations are differentiable and matrix-factorization-free.\nDespite the fact that we can explicitly perform backpropagation based on automatic\ndifferentiation mechanism, we also provide an alternative approach in GLinSAT\nto calculate the derivatives based on implicit differentiation of the optimality con-\ndition. Experimental results on constrained traveling salesman problems, partial\ngraph matching with outliers, predictive portfolio allocation and power system unit\ncommitment demonstrate the advantages of GLinSAT over existing satisfiability\nlayers.", "sections": [{"title": "1 Introduction", "content": "Constrained decision-making problems are pervasive across various disciplines. For example, logis-\ntics companies need to arrange delivery routes to minimize transportation costs while ensuring that all\norders are delivered on time. Power system operators need to decide how to allocate electricity pro-\nduction between different power plants to meet ever-changing electricity demand while maintaining\nsystem stability. Unfortunately, directly solving these complex constrained decision-making problems\nvia commercial optimization solvers requires a large amount of time. As a result, in scenarios that\nrequire rapid response, traditional solvers may not be suitable due to their long computation time.\nWith the development of deep learning, it is hopeful that neural networks can capture the domain\ncharacteristics and complex relationships involved in constrained decision-making problems through\ntheir powerful expressive capability and the solution time can be thus reduced. In recent years,\nresearch on how to use neural networks to solve constrained decision-making problems has become a\ntopic of general interest. Despite the great success of neural networks on classification and regression\ntasks, making the outputs of neural networks satisfy specific constraints is not straightforward, which\nstill needs to be further investigated."}, {"title": "2 Methodology", "content": "Sec. 2.1 formulates the neural network output projection problem as an entropy-regularized linear\nprogramming by introducing logistic entropy regularization terms in the objective function. Based on"}, {"title": "2.1 Reformulation of the neural network output projection problem", "content": "Here, we want to use a differentiable way to project the output of the neural network $c' \\in \\mathbb{R}^{n'}$ into\nvariables $x' \\in \\mathbb{R}^{n'}$ that are as similar as possible but satisfy the following constraints (1).\n\n$A_1x' \\leq b_1$ (1a)\n$A_2x' \\geq b_2$ (1b)\n$A_3x' = b_3$ (1c)\n$l' \\leq x' \\leq u'$ (1d)\n\nwhere $A_1 \\in \\mathbb{R}^{m_1 \\times n'}$, $A_2 \\in \\mathbb{R}^{m_2 \\times n'}$, $A_3 \\in \\mathbb{R}^{m_3 \\times n'}$, $b_1 \\in \\mathbb{R}^{m_1}$, $b_2 \\in \\mathbb{R}^{m_2}$, $b_3 \\in \\mathbb{R}^{m_3}$, $l', u' \\in \\mathbb{R}^{n'}$.\nMoreover, we also suppose that the feasible region in (1) is non-empty.\n\nApparently, any general linear constraints with bounded variables like (1) can be converted to the\nstandard form like (2) by shifting bounds and introducing slack variables (see Appendix A.4):\n\n$Ax = b$ (2a)\n$0 \\leq x \\leq u$ (2b)\n\nwhere $m = m_1 + m_2 + m'_3$, $n = n' + m_1 + m'_2$, $A \\in \\mathbb{R}^{m \\times n}$, $b \\in \\mathbb{R}^{m}$, $u \\in \\mathbb{R}^n$. Here, we denote\nthe vector obtained from padding ($m_1 + m_2$) zeros after the original vector $c'$ as $c$. Now, the original\nproblem is transformed into a problem of projecting $c \\in \\mathbb{R}^n$ onto $x \\in \\mathbb{R}^n$ that satisfy constraints (2).\nIn the following sections, we mainly focus on such a transformed problem in standard form.\n\nIn this paper, we regard $c_i$ as the preference of neural networks upon the i-th decision variable. The\nneural network outputs a larger $c_i$, indicating that it believes the i-th decision variable should be\ncloser to its lower bound, and vice versa. Consequently, we minimize the dot product of $c$ and $x$ as\nthe objective of the projection problem. Inspired by entropy-regularized optimal transport, here we\nformulate the projection problem as an entropy-regularized linear programming to make the entire\nproblem differentiable. Logistic entropy regularization terms are added into the objective as follows:\n\n$\\min_{\\substack{0 \\leq x \\leq u}} f(x) = \\min_{\\substack{0 \\leq x \\leq u}} c^T x + \\frac{1}{\\theta} \\sum_{j=1}^n (\\frac{x_j}{u_j} \\log(\\frac{x_j}{u_j}) + (1 - \\frac{x_j}{u_j}) \\log (1 - \\frac{x_j}{u_j})) $ (3a)\ns.t. $Ax = b$ (3b)\n\nwhere $\\theta > 0$ is the inverse temperature parameter that controls the approximation degree between the\nentropy-regularized problem and the original linear programming. As $\\theta \\rightarrow +\\infty$, the optimal solution\nof the entropy-regularized problem should approach that of the original linear programming.\n\nRemark 1. It is noteworthy that unlike entropy-regularized optimal transport problems where\nonly regularization terms in the form of $x \\log x$ are involved in the objective, here logistic entropy\nregularization terms with respect to both $x/u$ and its complement $1-x/u$ are added into the objective.\nActually, additionally incorporating the complementary entropy regularization terms is the most\nimportant part for the derivation of the Lagrange dual problem. Otherwise, we cannot obtain a\nexplicit simple expression of the dual objective in the following derivation.\n\nIf we denote the dual variables with respect to the equality constraints (3b) as $y$, the Lagrange dual\nfunction for (3) can be expressed as follows:\n\n$g(y) = \\inf_{0 \\leq x \\leq u} (c^T x + \\frac{1}{\\theta} \\sum_{j=1}^n (\\frac{x_j}{u_j} \\log(\\frac{x_j}{u_j}) + (1 - \\frac{x_j}{u_j}) \\log (1 - \\frac{x_j}{u_j})) - y^T Ax + b^T y)$ (4)\n\nwhere $a \\oslash b$, represents the element-wise multiplication and division of vector $a$ and $b$ respectively."}, {"title": "2.2 Forward pass in GLinSAT", "content": "In the previous section, we have shown that the original entropy-regularized linear programming\nproblem (3) can be equivalently converted into an unconstrained convex optimization problem (8)\nwith Lipschitz continuous gradient. Theoretically, it can be solved readily through gradient descent\nbased method. However, in the actual calculation process, it will be hard to choose a suitable step\nsize if we just use vanilla gradient descent method. If the step size is much greater than the local\nLipschitz constant, the algorithm may diverge. Otherwise, the convergence may be too slow.\n\nConsidering the strong convexity property of the entropy regularization terms, here we use a variant of\naccelerated gradient descent method, adaptive primal-dual accelerated gradient descent (APDAGD),\nwhich can adaptively approximate the local Lipschitz constant [26]. The detailed procedure of solving\nthe entropy-regularized linear programming problem (3) in GLinSAT is provided in Algorithm 1.\n\nCompared with the original version of APDAGD, here we improve the numerical performance of\nAlgorithm 1 from the following two aspects. First, we use a smoother way to update the approximation\nof the local Lipschitz constant M in GLinSAT. In Algorithm 1, M is decreased only when the decrease\nof the dual objective satisfies the corresponding condition for at least two consecutive times. As a\nresult, when M is already a good estimate of the local Lipschitz constant, the frequency of needless\nupdates can be reduced, which will lead to less computation time. Second, to handle the round-off\nerror, we also use a small number $\\delta$ to relax the criterion for the decrease of the objective function.\nOtherwise, due to the existence of numerical error, the criterion of sufficient decrease in objective\nmay be never satisfied. If we do not relax the criterion, M may become a large number and the\nalgorithm will get stuck.\n\nIn addition, it is noteworthy that most of the operations involved in Algorithm 1 are calculation\nof matrix-vector products, vector-vector element-wise products and unary functions. Therefore, it\nis convenient to execute these operations in parallel on the GPU for solving a batch of entropy-\nregularized linear programming problems.\n\nAs for the time complexity of Algorithm 1, based on Theorem 1 and Theorem 2 in the supplementary\nmaterial of [26], it can be easily proved that the number of iterations required by Algorithm 1 is\nroughly proportional to $\\sqrt{\\theta}$ and inversely proportional to $\\sqrt{\\epsilon}$. The corresponding result is given in\nCorollary 1 and the detailed discussions can be found in Appendix A.6."}, {"title": "2.3 Backward pass in GLinSAT", "content": "Since all the operations involved in Algorithm 1 are differentiable with respect to $c$, a natural idea\nis to directly use the auto differential mechanism to calculate the derivatives in the backward pass.\nHowever, directly backward propagation may require ever growing memory to store computational\ngraphs and may cost much time when the forward pass requires a lot of iteration steps. To save the\nmemory usage and accelerate the derivative calculation, we also provide an alternative way based on\nthe optimality condition to calculate the derivatives in GLinSAT.\n\nFirst, by calculating the derivative of $-g (y)$, we can obtain the optimality condition as follows:\n\n$h (y) = A (u \\circ \\sigma (-\\theta u \\circ (c - A^T y))) - b = 0$ (9)\n\nAccording to implicit differentiation and chain rule, differentiating equation (9), we can get:\n\n$\\frac{\\partial y}{\\partial c} = -(\\frac{\\partial h}{\\partial y})^{-1} \\frac{\\partial h}{\\partial c}$ (10)\n\nFurthermore, according to equation (6), the derivative of loss function $l$ with respect to $c$ can be\ncalculated as:\n\n$\\frac{\\partial l}{\\partial c} = \\frac{\\partial l}{\\partial x} \\frac{\\partial x}{\\partial c} + \\frac{\\partial l}{\\partial x} \\frac{\\partial x}{\\partial y} \\frac{\\partial y}{\\partial c} + \\frac{\\partial l}{\\partial y} \\frac{\\partial y}{\\partial c} = \\frac{\\partial l}{\\partial x} \\frac{\\partial x}{\\partial c} + (\\frac{\\partial l}{\\partial x} \\frac{\\partial x}{\\partial y} + \\frac{\\partial l}{\\partial y}) (-\\frac{\\partial h}{\\partial y})^{-1} (\\frac{\\partial h}{\\partial c})$ (11)"}, {"title": "4 Conclusion", "content": "In this paper, we reformulate the neural network output projection problem into a convex optimization\nproblem with Lipschitz continuous gradient. We then propose GLinSAT, a general linear satisfiability\nlayer to impose linear constraints on neural network outputs where all the operations are differentiable\nand matrix-factorization-free. GLinSAT can fully leverage the parallel computing capabilities of the\nGPU. We showcase four applications of GLinSAT and the advantages of our proposed framework\nover existing satisfiability layers are illustrated."}]}