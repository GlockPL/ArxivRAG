{"title": "COMPARATIVE CLINICAL EVALUATION OF\n\"MEMORY-EFFICIENT\" SYNTHETIC 3D GENERATIVE\nADVERSARIAL NETWORKS (GAN) HEAD-TO-HEAD TO STATE OF\nART: RESULTS ON COMPUTED TOMOGRAPHY OF THE CHEST", "authors": ["Mahshid Shiri", "Chandra Bortolotto", "Alessandro Bruno", "Alessio Consonni", "Daniela Maria Grasso", "Leonardo Brizzi", "Daniele Loiacono", "Lorenzo Preda"], "abstract": "Introduction: Generative Adversarial Networks (GANs) are increasingly used to generate synthetic medical images,\naddressing the critical shortage of annotated data for training Artificial Intelligence (AI) systems. This study introduces\na novel memory-efficient GAN architecture, incorporating Conditional Random Fields (CRFs) to generate high-\nresolution 3D medical images and evaluates its performance against the state-of-the-art hierarchical (HA)-GAN model.\nMaterials and Methods: The CRF-GAN was trained using the open-source lung CT LUNA16 dataset. The architecture\nwas compared to HA-GAN through a quantitative evaluation, using Fr\u00e9chet Inception Distance (FID) and Maximum\nMean Discrepancy (MMD) metrics, and a qualitative evaluation, through a two-alternative forced choice (2AFC) test\ncompleted by a pool of 12 resident radiologists, in order to assess the realism of the generated images.\nResults: CRF-GAN outperformed HA-GAN with lower FID (0.047 vs. 0.061) and MMD (0.084 vs. 0.086) scores,\nindicating better image fidelity. The 2AFC test showed a significant preference for images generated by CRF-Gan over\nthose generated by HA-GAN with a p-value of 1.93e-05. Additionally, CRF-GAN demonstrated 9.34% lower memory\nusage at 2563 resolution and achieved up to 14.6% faster training speeds, offering substantial computational savings.\nDiscussion: CRF-GAN model successfully generates high-resolution 3D medical images with non-inferior quality to\nconventional models, while being more memory-efficient and faster. Computational power and time saved can be used\nto improve the spatial resolution and anatomical accuracy of generated images, which is still a critical factor limiting\ntheir direct clinical applicability.", "sections": [{"title": "1 Introduction", "content": "Artificial Intelligence (AI) systems are proving to be valuable tools for supporting radiologists in the diagnostic\nprocess. They may be especially helpful in the interpretation of medical images, improving diagnostic accuracy and\nthe timeliness of therapeutic interventions [2]. However, the success of these systems and their widespread\nimplementation in clinical settings is still limited by the availability of large datasets with annotated medical data,\nwhich are essential for their training [3]. Annotated medical data from experts is often difficult to obtain due to privacy\nconcerns, high costs, complexity of collection procedures, and the need for approval by ethical committees [4]. In light\nof these challenges, the expansion of datasets with synthetic labeled data is of increasing interest to researchers and\nclinicians.\nPrevious models for dataset expansion were represented by Data Augmentation systems, such as intensity\ntransformations, rotation, translation, cropping, and other geometric transformations [4,5]. However, these methods\nhad limitations in capturing the heterogeneity of real image distributions, as they generated images through a one-to-\none process. In this context of scarcity of quality data, Generative Adversarial Networks (GANs) [6] offer a promising\nsolution. By learning the characteristics and distributions of real data, GANs can generate realistic and entirely new\nmedical images that replicate the variability and complexity of images used in clinical practice. This enables the training\nof more robust and accurate AI systems. GANs, whose classic architecture was proposed in 2014, consist of two deep\nneural networks: the Generator and the Discriminator. These two networks operate simultaneously in a minimax\ngame. The Generator creates new data samples, while the Discriminator evaluates both generated and real samples,\naiming to distinguish between them. This ongoing competition drives both components to improve their performances.\n3D GAN models have been proposed for various applications, including reducing noise in low-dose CT scans [7],\nenhancing the quality of CT images [8], generating realistic 3D brain MRI images [9], and creating tumor masks for\nsegmentation [10]. In the specific area of CT image generation, Ferreira et al. [11] and Han et al. [5] ,aimed to\nsynthesize realistic 3D images of lung parenchyma or lung nodules using different 3D GAN models: Progressive\nGrowing (PG)-GAN in [11] and a Multi-Conditional (MC)-GAN in [5]. However, these methods have a limitation in the\ngenerated image resolution, which is usually 1283 or smaller, because of limited memory during training [12].\nMemory-efficient GANs seek to balance memory efficiency and generative capability, ensuring effective GAN training\neven with limited computational resources. To achieve this, Lei et al. [13] and Yu et al. [14] focused on generating\nnew images slice-by-slice or patch-by-patch. However, as these methods generate patches and slices independently,\npotentially leading to artifacts at the boundaries. Also, Uzunova et al. [15] uses two GANs for image generation, with\nthe first network producing a lower-resolution version and the second generating higher-resolution patches conditioned\non the first GAN's output. This approach remains patch-based and lacks a comprehensive understanding of the entire\nimage structure. Furthermore, Sun et al. [12] introduced an end-to-end hierarchical GAN architecture (HA-GAN)\ncapable of generating high-resolution 3D images at a resolution of 2563. HA-GAN comprises two interconnected\nGANs: a low-resolution GAN that produces a low-resolution version of the 3D image, capturing the essential global\nstructure with reduced computational and memory demands, and a high-resolution GAN that generates high-resolution\npatches for a randomly selected sub-volume of the image. HA-GAN [12] has shown superior performance compared\nto several baseline models, including WGAN [21], VAE-GAN [22], GAN [23], ProgressiveGAN [24], 3D StyleGAN\n2 [25], and CCE-GAN [26]. Additionally, HA-GAN is the only model that can generate images at a resolution of\n2563, overcoming memory constraints that limit other models. For this reason, our proposed architecture is compared\ndirectly to HA-GAN.\nThis work addresses the limitations of existing 3D GAN models by proposing a novel \u201cmemory-efficient\" architecture\nfor high-resolution 3D medical image synthesis. This architecture combines Conditional Random Fields (CRFs) with\nGANs to reduce memory usage while improving performance. CRF is a probabilistic graphical model that models\ndependencies between output variables, considering the sequential or structural nature of the data. CRFs enable the\ncapture of correlations between image patches. The unary potential in a CRF represents the likelihood of assigning a\nparticular label to a patch based solely on its features, while the pairwise potential considers the relationship between\nneighboring patches, encouraging label consistency in adjacent regions and capturing the spatial structure and\ndependencies within the image.\nThe primary contribution of this work is to assess the clinical realism of synthetic images generated by memory-efficient\nGANs. This process is crucial for validating the practicality and applicability of these images in real-world medical\nsettings, thereby enhancing the potential of AI-driven healthcare solutions. The contributions of this work may be\nsummarized as follows:\n1. We present a novel, memory-efficient architecture by incorporating CRFs into the middle layers of GANs to\ncapture anatomical structures, aiming to increase consistency in the synthetic images.\n2. We assessed and analyzed the clinical value of the synthetic CRF-GAN images by comparing them, through\nqualitative and quantitative evaluation, with synthetic images from another GAN model (HA-GAN) used as a\n\"competitor.\" The goal of this evaluation is to assess the non-inferiority of CRF-GAN:\n(a) From a qualitative perspective (primary endpoint)\n(b) From a quantitative perspective (secondary endpoint)"}, {"title": "2 Materials and Methods", "content": "The study utilizes a publicly accessible 3D dataset employed for the Lung Nodule Analysis 2016 (LUNA16) challenge\n[18] which is a subset of the LIDC-IDRI dataset [19]. The Lung Image Database Consortium image collection (LIDC-\nIDRI) constitutes diagnostic thoracic computed tomography (CT) scans annotated with marked lesions. It serves as an\ninternationally accessible resource for the development, training, and evaluation of AI systems for lung cancer detection\nand diagnosis. Initiated by the National Cancer Institute and further advanced by the Foundation for the National Institutes\nof Health, this is public-private partnership, accompanied by the Food and Drug Administration. This dataset comprises\n1018 cases [19].\nA subset of the LIDC/IDRI database, publicly accessible, was utilized for the LUNA16 challenge [18]. CT scans with a\nslice thickness exceeding 2.5 mm were excluded, resulting in a total of 888 CT scans for analysis. The entire dataset was\npartitioned into 10 subsets, accessible as compressed zip files. Within each subset, CT images are stored in MetaImage\n(mhd/raw) format.\nThe dataset was divided into two subsets, allocating 90% for training and 10% for validation.\nDuring the preprocessing phase, in line with the approach of [12], blank axial slices are eliminated by substituting them\nwith zero values. Subsequently, the images are resized to dimensions of 2563. Additionally, the Hounsfield units (HU) of\nthe images undergo calibration, and air density correction is applied. To ensure uniformity, the HU are mapped to the\nintensity window of [-1024, 600], and normalized to the range [-1,1]."}, {"title": "2.2 Model", "content": "Model Description:\nThe proposed architecture introduces a novel two-step GAN framework, using CRFs for improved image synthesis by\nemphasizing consistency and structural coherence. GANs typically refine an image progressively across their layers,\nwith initial layers generating coarse structures and later layers fine-tuning details. The generator in this architecture is\ndivided into two components: the first part generates an embedding that encapsulates the image's global structure,\nwhile the second refines this embedding into high-resolution image patches. To achieve memory efficiency, the second\npart processes only a subset of the embedding during training, generating patches of the image rather than the entire\noutput. This selective approach reduces computational overhead. During inference, the second part of the generator\nutilizes the complete embedding to produce a full-resolution image, ensuring that the final output is both structurally\nconsistent and visually detailed. A critical innovation here is the application of CRFs to these embeddings, enabling\nthe model to enhance inter-patch consistency without the computational overhead of training an additional GAN [12].\nThe architecture also incorporates a \"half-encoder\" to further reinforce the generator's consistency and prevent mode\ncollapse. This encoder takes image as input and generates embeddings that are compared to the original ones during\ntraining. By focusing on embedding correlations, the CRF enhances the generator's ability to produce structurally\ncoherent and realistic images. During training, a dual-feedback mechanism operates: the CRF ensures structural\nalignment within the embeddings, while the discriminator evaluates the realism of the output image patches. This\nlightweight and memory-efficient approach improves the generator's ability to synthesize consistent and high-quality\nimages.\nThe two-step GAN structure and CRF integration present a significant advance in generative modeling, offering a\nlower computational footprint compared to traditional methods."}, {"title": "2.3 Evaluation", "content": "The comparison with HA-GAN has been conducted from both a quantitative and qualitative perspective, while the\nperformance evaluation also considers key parameters such as maximum memory usage, the number of learnable\nparameters, and training speed. The evaluation procedures employed are detailed below."}, {"title": "2.3.1 Quantitative Evaluation", "content": "To evaluate the synthetic images generated by two models, we used two key metrics: Fr\u00e9chet Inception Distance (FID)\nand Maximum Mean Discrepancy (MMD).\nHeusel et al. [27] introduced the Fr\u00e9chet Inception Distance (FID) as a metric for assessing the quality of generated\nsamples. FID accomplishes this by embedding a set of generated samples into a feature space provided by a specific\nlayer of Inception Net or any Convolutional Neural Network (CNN). The embedding layer is treated as a continuous\nmultivariate Gaussian, and both the mean and covariance are estimated for the generated and real data. The Fr\u00e9chet\ndistance, also known as the Wasserstein-2 distance, between these two Gaussian distributions is then utilized to quantify\nthe quality of the generated samples. A lower FID value indicates smaller distances between the synthetic and real data\ndistributions. FID is recognized for its ability to discriminate between samples, its robustness, and its computational\nefficiency. Although FID is considered a reliable measure, it assumes that the features follow a Gaussian distribution,\nwhich may not always hold true. The FID metric degrades as various types of artifacts are introduced into the images.\nThis score aligns well with human judgments and focuses on measuring the dissimilarity between the generated and\nreal distributions.\nThe measure known as MMD calculates the difference between two probability distributions by using independently\ndrawn samples from each distribution [28]. A lower MMD value indicates that two distributions are closer. MMD can\nbe considered as a two-sample testing method (i.e. Distinguishing two distributions by finite samples), which tests\nwhether one model or another is closer to the true data distribution.\nOverall, FID measures how closely the generated images match the real image distribution, accounting for both precision\nand recall. MMD, on the other hand, assesses the difference between real and generated images with minimal sample\nand computational complexity. Lower FID and MMD values indicate that the generated images closely resemble real\nimages."}, {"title": "2.3.2 Qualitative Evaluation", "content": "The qualitative evaluation of images aims to assess the clinical value of the synthetic CRF-GAN images by evaluating\ntheir realism from a purely subjective standpoint rather than using objective metrics. The evaluation was performed\nby a pool of twelve (12) resident radiologists, working at IRCCS San Matteo of Pavia, with experience dealing with\nchest CT imaging. The majority of them (9/12, 75%), at the time of evaluation, were attending the fourth and last year\nof residency, one of them (8,34%) was attending the third year of residency and two of them (16,67%) were attending\nthe second year of residency. All the residents involved already completed the chest CT internal rotation of six months,\nassuming that they were equally experienced on that specific topic and could provide evaluation on thoracic imaging\nwith the same amount of expertise. The evaluation was conducted through a two alternative forced choice (2AFC)\ntest composed of two sections:\n1. In the first section, the evaluator was presented with a total of 10 questions each presenting two sets of randomly\nselected images from a chest CT scan, acquired at the same slice (position) on the same anatomical plane (axial,\ncoronal or sagittal). One of the two images had been artificially generated using CRF-GAN model, while the\nother was a real CT, resized at a 2563 resolution to match the resolution of the generated image, but no\ninformation about their origin was provided.\nThe task of the evaluator was to identify which image was the real one. Subsequently, the evaluator had to assess\nthe level of difficulty of the task using a Likert scale from 1 (extremely subtle) to 5 (obvious).\n2. In the second section, the evaluator was presented with 30 questions displaying two randomly selected slices of\nchest CT images each, acquired at the same position and on the same anatomical plane; both images of each\npair had been artificially generated, one from CRF-GAN model and the other one from HA-GAN model. The\nevaluator's task was to indicate the most realistic one.\nThe test had to be completed in one sitting as it was not possible to pause and resume later to avoid any bias.\nTo determine the statistical significance of the preference for CRF-GAN or HA-GAN through our study, we used chi-\nsquare test."}, {"title": "2.3.3 Computational Performance Evaluation", "content": "For computational performance evaluation, we used a test set consisting of 10% of the LUNA16 dataset, with all experiments\nconducted at a resolution of 2563. To evaluate the model's complexity and efficiency, we monitored the maximum\nmemory usage during training with batch sizes of 2, 4, and 6. Furthermore, to enhance our evaluation, we quantified the\ntotal number of learnable parameters within the models to assess their complexity, as a higher number of parameters\nnecessitates a larger dataset. This consideration is particularly significant in clinical applications since medical datasets\nare often limited in size compared to those of natural images. Additionally, we measured the training speed of the\nmodels by conducting training over 1000 iterations and determining the average number of iterations completed per\nsecond."}, {"title": "3 Results", "content": "3.1 Quantitative results: FID and MMD scores\nLower FID and MMD scores serve as indicators of the proximity of generated images to real images, reflecting the\nperformance of the models. These scores are calculated on 2563 resolution of the synthetic images produced by CRF-\nGAN and HA-GAN and are presented in Table 1, with CRF-GAN outperforming HA-GAN in terms of both metrics.\n3.2 Qualitative results: 2AFC test\nIn the first section of the test, we compared real and synthetic images. All twelve experts correctly identified all real\nimages for every question which shows that the synthetic images are not identical with real ones. Analyzing the\ndifficulty ratings reveals that synthetic images rarely posed challenges for the experts as can be seen in Figure 2.\nThis study also aimed to compare the performance of two synthetic image generation models, CRF-GAN and HA-GAN.\nFigure 3 presents examples of image pairs, illustrating that in some instances HA-GAN was preferred more frequently,\nwhile in others, CRF-GAN received a higher number of selections. The study focused on quantifying participant\npreferences and analyzing the statistical significance of these preferences between the two models. Descriptive statistics\nin Table 2 provide an overview of the total votes received by each model, as well as the average and variability in votes\nper image pair.\n3.3 Computational Performance Evaluation\n3.3.1 Model Complexity:\nWe explored the complexity of CRF-GAN and HA-GAN models by analyzing the total number of learnable parameters\nat different resolutions, which are presented in Table 3. The proposed model demonstrates a reduction in parameters at\neach resolution, with decreases of 27.4%, 28.1%, and 28.2% observed for resolutions 643, 1283, and 2563 respectively,\nas highlighted in the table.\n3.3.2 Memory efficiency:\nIn order to compare memory usage, we captured the maximum memory allocated by each model during training. This\nprocedure was performed on batch sizes of 2, 4, and 6 on both 1283 and 2563 resolutions. The results are outlined in\nTable 4.\nAs it can be seen, HA-GAN consistently demanded more memory resources than CRF-GAN across different resolutions\nand batch sizes. On average, HA-GAN utilized approximately 9.65% more memory compared to CRF-GAN at 1283\nresolution and approximately 9.34% more memory at 2563 resolution."}, {"title": "4 Discussion", "content": "Memory-efficient 3D GANs may facilitate data generation while utilizing minimal computational resources, thereby\nexpanding datasets to mitigate data scarcity; these models, increasing iterations and so image quality without increasing\ngeneration time, may not only save time and resources but also uphold a high standard of data quality.\nWhile in literature most works focused on presenting 3D GAN models generating only specific anatomical parts [11, 5],\nor patch-based architecture prone to artifacts [13, 14, 15], in our knowledge only Sun et al. [12] introduced a low\ncomputational and memory demanding high-resolution 3D GAN architecture outperforming state-of-art models that\ngenerate coherent high-resolution 3D images, called HA-GAN.\nIn this work, we proposed a novel memory-efficient architecture for high-resolution 3D medical image synthesis thanks\nto the implementation of Conditional Random Fields and we assessed the clinical value of the synthetic images by\ncomparing them, through qualitative (endpoint 1) and quantitative (endpoint 2) evaluation.\nFrom a computational performance and workload point of view, CRF-GAN proved to be a lighter model than HA-\nGAN, both in terms of learnable parameters and memory usage. The significantly fewer learnable parameters of CRF-\nGAN compared to HA-GAN, leads to higher computational efficiency during training, reflecting in a larger number\nof iterations per second at both 1283 and 2563 resolution. Regarding memory usage, HA-GAN consistently demanded\nmore memory resources than CRF-GAN across different resolutions and batch sizes. Interestingly, as the batch size\nincreased, this percentage difference tended to increase at both resolutions, indicating that higher batch sizes amplify\nthe disparity in memory usage between the two models.\nIn terms of quantitative evaluation, both FID and MMD metrics values show better image fidelity for CRF-GAN.\nQuantitative metrics are essential for objectively assessing the quality of images generated by synthesis models, as\nthey measure the discrepancy between the distributions of real and synthetic images. However, relying solely on these\nmetrics can be misleading due to their inherent limitations. For instance, FID assumes a Gaussian distribution of the\nfeatures extracted from the images, which is not always true, thereby compromising the reliability of the evaluation.\nSimilarly, MMD quantifies the difference between two probability distributions but does not provide information on\nwhich specific features contribute to this difference, limiting the interpretability of the results. Therefore, it is crucial\nto complement these metrics with qualitative assessments to adopt a holistic approach that allows for a deeper\nunderstanding of the quality of the generated images.\nIn terms of qualitative assessment process, the 2AFC test allowed radiologists residents to formulate some subjective,\nbut globally shared, evaluations on the clinical nature of the images, stemming from their expertise in the field of\nmedical radiology. The qualitative difference, evident in comparison with real images, is not evident in comparison\nwith the generated ones: The correctness of this assumption is confirmed by the results of the 2AFC test. The result\nof the 2AFC test shows a clear preference for CRF-GAN over HA-GAN. Out of the total votes, CRF-GAN received\n215 (59,7%), while HA-GAN garnered 145, indicating that participants were more likely to choose images from CRF-\nGAN as appearing more realistic. On average, CRF-GAN received 7.16 votes per image pair, compared to HA-GAN's\n4.83. Both models showed similar variability in votes with a standard deviation of 2.66. A chi-square test was\nperformed to assess the statistical significance of this preference. The test yielded a chi-square statistic of 71.42 with\nan extremely low p-value of 1.93e-05, demonstrating that the observed difference is highly unlikely to be due to random\nchance. This indicates a strong and statistically significant preference for CRF-GAN over HA-GAN in terms of\ngenerating more realistic images.\nHowever, there remains a significant gap between the current capabilities of GAN-generated images (HA- or CRF-) and\ntheir practical application in real-world clinical settings as the qualitative distance between generated and real images\nis still evident, both in terms of spatial resolution and anatomical accuracy. While the qualitative difference is\nundeniable, it is yet to be determined whether a poor performance from a purely clinical or subjective perspective\ncorrelates with limitations in quantitative metrics. This question can guide future studies aimed at evaluating the\nperformance of AI systems trained on medical datasets, while also exploring the potential of using 3D GAN models for\ndata augmentation to improve diagnostic accuracy.\nThere are some limitations to this study. The number of participants (twelve) may restrict the generalization of the results.\nAdditionally, participant bias could be introduced, as individual criteria for evaluating image quality vary among the\nparticipants, potentially affecting the outcomes. The resolution at which the images were generated (2563) represents a\nstep forward from the point of view of 3D generative models, as already discussed in previous sections. However, in the\nclinical-radiological field, this resolution does not reflect the one usually used, which is normally 5123 or higher,\ndepending on the CT scanner setting used. Furthermore, it should be noted that this aspect did not represent a bias in the\ncomparison of the generated images with real ones since the real images were downscaled to a 2563 resolution, making\nthem comparable with the generated ones. Also, we evaluated only the GAN's capability of generating chest CT volumes"}, {"title": "5 Conclusion", "content": "Memory-efficient GANs such as CRF-GAN both on qualitatively and qualitatively evaluation results to be non-\ninferior to conventional state-of-the-art ones. Their generative effectiveness can provide significant benefits in\ncorrecting data scarcity and fragmentation present in datasets dedicated to training AI systems as well as making it\npossible to allocate saved computational power to reduce production time, increase quality, or make easier local\ngeneration and federated learning."}]}