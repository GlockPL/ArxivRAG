{"title": "A FUSION APPROACH OF DEPENDENCY SYNTAX AND\nSENTIMENT POLARITY FOR FEATURE LABEL EXTRACTION IN\nCOMMODITY REVIEWS", "authors": ["Jianfei Xu"], "abstract": "This study uses 13,218 review data entries for four categories of products-mobile phones, computers,\ncosmetics, and food-from JD.com as the data source. By integrating dependency parsing and\nsentiment polarity analysis, a novel method for extracting feature tags from product reviews is\nproposed. This approach not only addresses the issue of low robustness in extraction algorithms but\nalso improves the accuracy of the extraction results. Experimental results show that the accuracy\nof the proposed extraction method stabilizes at 0.7, with recall and F-score both stabilizing at 0.8,\nindicating overall satisfactory outcomes. However, issues such as dependence on the matching\ndictionary and the narrow scope of tag extraction require further investigation.", "sections": [{"title": "1 Introduction", "content": "In recent years, e-commerce has experienced rapid development alongside the evolution of internet technologies.\nOn May 31, 2018, the E-commerce Department of the Ministry of Commerce of China released the 2017 China\nE-commerce Report, highlighting that in 2017, the rapid development of \"Internet Plus\" accelerated the integration of\nonline and offline channels. E-commerce has become a key driver of China's economic transformation and upgrading,\nbringing significant commercial value. According to the report, China's e-commerce transaction volume in 2017\nreached 29.16 trillion yuan, an increase of 11.7% year-on-year, and 2.8 times the transaction volume of 2013. Notably,\nonline retail sales reached 7.18 trillion yuan, growing 39.1% compared to 2016. Behind this massive sales figure,\ne-commerce platforms retain a large amount of user review data. How to extract valuable insights from these review\ndatasets and utilize such information to provide more precise services to users has become a key focus for both industry\nand academia. Zhao [2018]\nDue to the massive volume and high randomness of user review data, information overload often occurs, limiting the\neffectiveness of e-commerce user reviews as online word-of-mouth. For users, processing a large number of reviews\nmakes it difficult to clearly identify product features, thereby hindering accurate decision-making. For e-commerce\nplatforms, overloaded information obstructs the identification of competitive advantages, the implementation of customer\nsegmentation, and efforts to encourage user participation in online reviews, ultimately reducing the marketing efficiency\nof word-of-mouth dissemination. Therefore, tools are urgently needed to assist consumers in processing extensive\nreview data by extracting valuable content from the flood of product reviews. These tools should condense the main\npoints and perspectives of reviews into concise, structured feature descriptions that are convenient for both consumers\nand businesses to use."}, {"title": "2 Related Work", "content": "In the context of big data, feature tags can aggregate user opinions, improve the quality of review content, and help\nusers efficiently extract highly informative and valuable references from online product reviews. This functionality has\nattracted significant attention from scholars.\nTo address the issue of correlations among multiple feature tags, scholars have primarily used methods such as\ninformation entropy and mutual information. Li et al. [2017] improved the traditional k-nearest neighbor (k-NN)\nmulti-label learning algorithm, which often ignores correlations between tags. By using mutual information to measure\nthe knowledge content of tag classification and assigning corresponding weight coefficients, they incorporated tag\ncorrelations into the weight coefficients of features, achieving promising experimental results. Chai and Yan [2018]\napplied granulation to the tag space based on the optimal granulation number obtained through average information\nentropy. They used membership degrees to assess the strength of correlations among tags and weighted the features\naccordingly, addressing issues of feature-to-tag correlation and the combinatorial explosion of tags.\nIn the issue of multi-feature tag selection, Chen et al. [2018] proposed a sparse regularization method based on\ncorrelation entropy and feature manifold learning to address the problem of multi-label feature selection through\ncorrelations. Zhang and Wang [2018] proposed a forward-search-based nonlinear feature selection algorithm, utilizing\nthe theories of mutual information and interaction information to identify the optimal subset related to multi-class\nlabels and reduce computational complexity. Yan and Wang [2019] established a multi-label feature selection model\nusing a global linear regression function, combined with an h-graph to obtain local descriptive information and improve\nmodel accuracy. They introduced L1,2 constraints to enhance the distinguishability between features and the stability of\nregression analysis, effectively avoiding noise interference.\nIn the field of feature tag classification, Zhang et al. [2019] proposed a multi-label class attribute feature extraction\nalgorithm, LIFT_RSM, to address the issue of redundancy in the attribute space caused by the construction of class\nattributes, thereby improving classification performance. Li et al. [2014] introduced a multi-label classification algorithm\nbased on information gain. This algorithm initially assumes independence among features and, after calculating mutual\ninformation, eliminates irrelevant features based on a threshold to obtain the optimal feature subset.\nIn the field of feature tag extraction, Bao and Zhou [2018] proposed a review mining model based on domain ontology to\nidentify \"feature-opinion pairs\" in fresh product reviews, addressing the issue of the rapidly increasing volume of review\ndata. This approach significantly improved computational performance. However, the model's applicability was limited\ndue to the relatively narrow range of data sources. Yin [2019] introduced a feature-opinion pair extraction method based\non a semantic dictionary, where the matching and extraction algorithm automatically generates feature-opinion pairs.\nDrawing on the aforementioned research, this study combines dependency syntax analysis and sentiment polarity\nmethods to propose a method for extracting feature tags from product review corpora. This approach can structurally\nextract review objects, degree adverbs, negation words, and opinion words, thereby improving the precision and\nrobustness of sentiment word and evaluation object identification. Additionally, through the use of window values, the\nmethod enables context analysis of reviews based on sentiment polarity, effectively addressing the ambiguity caused by\nthe one-sided judgments of conventional methods."}, {"title": "3 Feature Extraction of Product Reviews Based on the Integration of Dependency Syntax\nand Sentiment Polarity", "content": "Based on the theoretical framework of dependency syntax and the structure of feature tags, each dependency relationship\nshould include at least two components: the core word and the dependent word. Together with the semantic relationship\nbetween them, these elements form an evaluative opinion. Building on the traditional \"product feature-evaluation term\"\nstructure, this study incorporates elements of sentiment analysis. By determining sentiment polarity, negation words\nand adverbs that indicate the degree of sentiment are integrated into the traditional structure, resulting in a dependency\nstructure of \"product feature-negation word-adverb-evaluation term.\" Accordingly, the process of extracting evaluation"}, {"title": "3.1 Feature Tag Structure", "content": "The feature tags of product reviews incorporating sentiment polarity consist of three components: product feature,\nsentiment degree, and evaluation term, as shown in Table 1. Among them, the product feature refers to the evaluation\nsubject (i.e., evaluation object) extracted from the review, such as battery life, screen, charging time, appearance,\netc. Sentiment terms indicate the sentiment polarity of the product feature as expressed by the reviewer and can be\ndetermined jointly by degree adverbs and negation words in the review. For example, in the sentence \"The shape of the\nmouse is very novel, resembling an Apple machine, and its appearance feels very cool,\" the adverb \"very\" indicates the\ndegree of sentiment. The evaluation term defines the attitude toward the subject of the product. These three components\ntogether form the product feature tag, with sentiment terms and evaluation terms often needing to appear together to\nreflect the reviewer's opinion and emotional inclination toward a particular product feature."}, {"title": "3.2 Feature Tag Extraction Rules", "content": "Based on the research and analysis of dependency rules for product features and evaluation terms by Nie and Du\n2014], this study extends the scope of dependency relationships in reviews. By examining the semantic modification\nrelationships between words, the dependency relationships among \"product feature-sentiment term-evaluation term\"\ncan be identified and extracted. The main dependency rules are defined as follows:\n\u2022 Search for components dependent on the evaluation term to its left. If the component's part of speech is an\nadverb and it functions as an adverbial modifier of the evaluation term, then the sentiment term is the adverbial\ncomponent modifying the evaluation. For example, in the sentence \"The progress is very fast,\" the word \"very\"\nnot only modifies \"fast\" but also serves as an adverbial component of \"fast\" in the sentence. Therefore, \"very\"\nis the adverb modifying the evaluation term \"fast.\"\n\u2022 When both the product feature term and the evaluation term are not core words in the sentence, and the\nintermediate grammatical element reverses the opinion rather than negating an adverb in the sentence, that\nword is considered a negation term. For example, in the sentence \"The phone is not very good-looking,\" both\n\"phone\" and \"good-looking\" are not core words, and the intermediate grammatical element \"not\" negates the\nopinion about whether the phone is good-looking. Thus, \"not\" is the negation term for this feature."}, {"title": "3.3 Determination and Filtering of Sentiment Tag Polarity", "content": "Due to issues such as redundancy of sentiment words and low polarity of some sentiment words in the extracted\nresults, this study adopts the word sentiment polarity calculation method proposed by Wang et al. [2012], which\nintegrates HowNet and PMI. This method calculates the polarity of sentiment tags and filters out sentiment words\nwithout significant sentiment polarity by setting a threshold.\n\u2022 Assume that the word to compute the polarity of is wordi. First, use HowNet to perform synonym expansion.\nLet the expanded synonym set be {word\u2081, word2, word3, ..., wordr}.\n\u2022 The sentiment polarity of wordi and its synonyms can be calculated using the formula:\n$hownet(word_i) = \\sum_{i=1}^{n} Sim(word_i, commendatory) - \\sum_{i=1}^{n} Sim(word_i, derogatory)$,\nwhere Sim(wordi, commendatory) represents the similarity between wordi and the commendatory word\ncommendatory, and Sim(wordi, derogatory) represents the similarity between wordi and the derogatory\nword derogatory. When the similarity Sim(wordi, reference) between wordi and the reference word"}, {"title": "3.4 Feature Tag Extraction", "content": "Figure 1 shows the feature tag extraction process in this study, with the specific steps as follows:\n1. Preprocess the review text, including tokenization, part-of-speech tagging, named entity recognition, and\nsyntactic analysis.\n2. Match the preprocessed sentences with the feature library and rating term library to identify product features,\nsentiment terms, and evaluation terms.\n3. Since there may be one-to-many or many-to-many relationships between the extracted product features and\nevaluation terms, it is necessary to combine and merge adjacent product feature terms and evaluation terms.\nThen, simplify the extracted combinations based on direct and indirect dependency relationships: for directly\ndependent feature combinations, no restrictive conditions are applied; for indirectly associated combinations, a\nwindow value constraint is set, where the specific window value is determined by the length of the syntactic\ntemplate.\n4. Compare the simplified combinations with the template library, verify them from the perspectives of structural\ndependency relationships and part of speech, and list combinations that match the template pattern as candidate\nfeature tag pairs.\n5. Rank the filtered candidate feature tag pairs by frequency, and select the feature tags generated by the\nhighest-frequency template as the final extraction results."}, {"title": "4 Empirical Analysis", "content": "The data used in this experiment comes from 13,218 review comments on four types of products-mobile phones,\ncomputers, beauty products, and food from the JD.com online marketplace. The \"Jieba\" Python toolkit was used\nfor tokenization and part-of-speech tagging of all the review data. Named entity recognition was performed using\nthe Tencent Cloud AI platform. A subset of the review data was manually annotated for product feature terms and\nevaluation terms. Additionally, 245 sentiment words were referenced from the Baidu Baike encyclopedia for sentiment\nanalysis."}, {"title": "4.2 Evaluation Metrics", "content": "This study uses accuracy, recall, and F-value to quantitatively evaluate the performance of the experimental results. The\ndefinitions of each metric are as follows:\n\u2022 Accuracy: Represents the ratio of correctly extracted feature tags to the total number of extracted feature tags.\n$P = \\frac{A}{A+B}$                                                                                                                                                                                                                                                                                                                                                                                                                                                                 (1)\nWhere P is accuracy, A is the number of correctly extracted feature tags, and B is the number of incorrectly\nextracted feature tags.\n\u2022 Recall: Represents the ratio of correctly extracted sentiment tags to the total number of feature tags that\nactually exist in the opinion corpus.\n$R = \\frac{A}{A+C}$                                                                                                                                                                                                                                                                                                                                                                                                                                                                 (2)\nWhere R is recall, A is the number of correctly extracted sentiment tags, and C is the number of feature tags\nthat are missing in the extraction process. Where R is the recall, A is the number of correctly extracted feature\ntags, and C is the number of missed feature tags.\n\u2022 F-value: It is used to comprehensively measure both accuracy and recall metrics.\n$F = \\frac{2PR}{P+R}$                                                                                                                                                                                                                                                                                                                                                                                                                                                                 (3)"}, {"title": "4.3 Results Analysis", "content": "By analyzing the results in Table 2 and Table 3, it can be observed that this study is capable of fully capturing the\nsentiment orientation in user reviews. For example, in review number 2124, the original meaning of the sentence is that\nthe taste is not crispy. However, because the extraction method based on dependency syntax does not consider semantic\nissues and relies solely on syntactic structure, the result extracted was \"crispy taste,\" leading to an incorrect feature tag\nextraction."}, {"title": "4.3.2 Analysis of Evaluation Metrics", "content": "From Tables 4 and 5, it can be seen that, using the text-based method, the accuracy of feature extraction for mobile\nphones, computers, beauty products, and food categories is generally around 0.7, with recall rates around 0.8. Overall,\nthe results are better than those of feature extraction based on dependency syntax. In terms of accuracy, the food\ncategory has the highest accuracy. This is because user reviews of food products are generally less technical than\nthose for mobile phones and computers, and less verbose than beauty product reviews. The data is relatively clean and\nwell-organized, leading to simpler sentence structures and more precise word expressions. In terms of recall, all four\ncategories show high recall rates, indicating that the feature extraction method in this study is capable of identifying\ncertain grammatical structures in the reviews. Regarding the F-value, it remains stable at around 0.8, suggesting that the\noverall extraction performance is relatively ideal and meets the expectations of the experiment."}, {"title": "5 Conclusion", "content": "This study proposes an effective method for extracting feature tags from product reviews by integrating dependency\nsyntax analysis and sentiment polarity. The proposed method successfully captures both the semantic and syntactic\nfeatures of product reviews, improving the accuracy and robustness of sentiment analysis. Through empirical analysis,\nthe method demonstrated promising results, with accuracy and recall rates around 0.7 and 0.8, respectively, and a stable\nF-value of approximately 0.8. Despite these successes, there are still challenges, particularly related to the reliance\non syntactic structures that may lead to incorrect feature tag extraction in some cases. Future research could focus on\nfurther enhancing the method's ability to handle complex sentence structures and improve the semantic understanding\nof reviews. Overall, the study provides a solid foundation for improving the quality of feature tag extraction in online\nproduct reviews, offering valuable insights for both consumers and e-commerce platforms in enhancing decision-making\nprocesses and marketing strategies."}]}