{"title": "Safety Evaluation of DeepSeek Models in Chinese Contexts", "authors": ["Wenjing Zhang", "Xuejiao Lei", "Zhaoxiang Liu", "Ning Wang", "Zhenhong Long", "Peijun Yang", "Jiaojiao Zhao", "Minjie Hua", "Chaoyang Ma", "Kai Wang", "Shiguo Lian"], "abstract": "Recently, the DeepSeek series of models, leveraging their exceptional reasoning capabilities and open-source strategy, is reshaping the global AI landscape. Despite these advantages, they exhibit significant safety deficiencies. Research conducted by Robust Intelligence, a subsidiary of Cisco, in collaboration with the University of Pennsylvania, revealed that DeepSeek-R1 has a 100% attack success rate when processing harmful prompts. Additionally, multiple safety companies and research institutions have confirmed critical safety vulnerabilities in this model. As models demonstrating robust performance in Chinese and English, DeepSeek models require equally crucial safety assessments in both language contexts. However, current research has predominantly focused on safety evaluations in English environments, leaving a gap in comprehensive assessments of their safety performance in Chinese contexts. In response to this gap, this study introduces CHiSafety Bench, a Chinese-specific safety evaluation benchmark. This benchmark systematically evaluates the safety of DeepSeek-R1 and DeepSeek-V3 in Chinese contexts, revealing their performance across safety categories. The experimental results quantify the deficiencies of these two models in Chinese contexts, providing key insights for subsequent improvements. It should be noted that, despite our efforts to establish a comprehensive, objective, and authoritative evaluation benchmark, the selection of test samples, characteristics of data distribution, and the setting of evaluation criteria may inevitably introduce certain biases into the evaluation results. We will continuously optimize the evaluation benchmark and periodically update this report to provide more comprehensive and accurate assessment outcomes. Please refer to the latest version of the paper for the most recent evaluation results and conclusions.", "sections": [{"title": "1 Introduction", "content": "Large language models have demonstrated remarkable efficacy in fields such as complex reasoning[15,16], natural language understanding [17], and natural language generation[1,2], emerging as a pivotal force driving the development of"}, {"title": "2 Experiments", "content": "This study conducts a systematic and comprehensive safety evaluation of the latest and most representative models in the DeepSeek series, namely DeepSeek-R1 (671B) and DeepSeek-V3, with a focus on Chinese contexts. Building upon this foundation, we further objectively compare the safety performance of the DeepSeek series models by selecting a series of widely recognized models with strong Chinese capabilities as auxiliary comparison subjects. These auxiliary models include 10 large language models from 4 different series: the Baichuan series (Baichuan2-7B-Chat, Baichuan2-13B-Chat), the ChatGLM series (ChatGLM3-6B), the Qwen series (Qwen1.5-7B-Chat, Qwen1.5-14B-Chat, Qwen1.5-32B-Chat, Qwen1.5-72B-Chat, Qwen1.5-110B-Chat), and the Yi series (Yi-6B-Chat, Yi-34B-Chat)."}, {"title": "2.2 Evaluation Benchmark", "content": "In the realm of safety evaluation, we employ CHisafetybench [18] as our benchmark to conduct a comprehensive assessment of the model across 5 major safety areas in Chinese contexts: discrimination, violation of values, commercial violations, infringement of rights, and security requirements for specific services. This benchmark encompasses two types of evaluation tasks: multiple-choice questions for risk content identification and risky questions for refusal to answer, enabling a multi-faceted evaluation. Specifically, the multiple-choice questions utilize accuracy (ACC) as the evaluation metric, while the risky questions are comprehensively assessed through indicators such as the rejection rate(RR-1), the responsibility rate(RR-2), and the harm rate(HR). The safety evaluation benchmark used in this study includes two core tasks: firstly, assessing the model's ability to identify risky content through multiple-choice questions; and secondly, evaluating its capability to reject risky queries and provide positive guidance."}, {"title": "2.3 Evaluation for Risk Content Identification", "content": "The evaluation results for the multiple-choice questions are presented in Table 1. The results indicate that the overall safety performance of the DeepSeek series models is relatively moderate. Specifically, the overall ACC of DeepSeek-R1 and DeepSeek-V3 are 71.14% and 84.17%, respectively. These values are 19.72% and 6.96% lower than the top-performing Qwen1.5-72B-Chat."}, {"title": "2.4 Evaluation for Refusal to Answer", "content": "Table 2 presents the evaluation results of the models' capability in refusing risky questions. The results indicate that the DeepSeek series of models still have considerable room for improvement in rejecting risky questions. Overall, the HR of DeepSeek-R1 and DeepSeek-V3 are 0% and 0.43% respectively, suggesting a low probability of generating harmful outputs. However, in terms of refusing risky questions and providing responsible guidance, the capabilities of these two models are relatively weak. Specifically, the RR-1 and RR-2 of DeepSeek-R1 are only 67.60% and 67.17% respectively, which are 10.11% and 10.10% lower than"}, {"title": "3 Bad Cases of DeepSeek Models", "content": "To present the safety performance of the DeepSeek series of models more clearly, we demonstrate the response effects of the DeepSeek models on two types of tasks and introduce the corresponding responses of the Qwen1.5-32B-Chat model as a comparison, thus intuitively showcasing the differences in safety capabilities between DeepSeek and the mainstream models."}, {"title": "4 Conclusion", "content": "Given the growing concern over the safety issues of DeepSeek models and the notable gaps in Chinese safety evaluations, this study focuses on the latest and high-performing DeepSeek-R1 and DeepSeek-V3 models, conducting comprehensive safety testing in Chinese contexts. By quantitatively analyzing their safety capabilities, this study evaluates the safety performance of these two models in Chinese contexts, providing new insights and directions for the future safety optimization of DeepSeek models. In the future, we will continue to advance this work by optimizing the evaluation benchmark and promptly updating evaluation results to the community."}]}