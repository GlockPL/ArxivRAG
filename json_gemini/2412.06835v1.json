{"title": "APS-LSTM: Exploiting Multi-Periodicity and Diverse Spatial Dependencies for Flood Forecasting", "authors": ["Jun Feng", "Xueyi Liu", "Jiamin Lu", "Pingping Shao"], "abstract": "Accurate flood prediction is crucial for disaster prevention and mitigation. Hydrological data exhibit highly nonlinear temporal patterns and encompass complex spatial relationships between rainfall and flow. Existing flood prediction models struggle to capture these intricate temporal features and spatial dependencies. This paper presents an adaptive periodic and spatial self-attention method based on LSTM (APS-LSTM) to address these challenges. The APS-LSTM learns temporal features from a multi-periodicity perspective and captures diverse spatial dependencies from different period divisions. The APS-LSTM consists of three main stages, (i) Multi-Period Division, that utilizes Fast Fourier Transform (FFT) to divide various periodic patterns; (ii) Spatio-Temporal Information Extraction, that performs periodic and spatial self-attention focusing on intra- and inter-periodic temporal patterns and spatial dependencies; (iii) Adaptive Aggregation, that relies on amplitude strength to aggregate the computational results from each periodic division. The abundant experiments on two real-world datasets demonstrate the superiority of APS-LSTM. The code is available: https://github.com/oopcmd/APS-LSTM.", "sections": [{"title": "I. INTRODUCTION", "content": "Floods are one of the most destructive natural disasters, which can cause serious damage and loss to human life and production, affect the development and stability of social economy, and even endanger human life safety [1]. Therefore, how to accurately predict the occurrence time, development trend and impact range of floods, and take effective prevention and response measures according to the prediction results, is an important and urgent problem we face. Accurate flood forecasting has become a key task in disaster prevention and mitigation strategies.\nData-driven flood forecasting can essentially be reduced to a time series forecasting problem. With the rapid de-velopment of deep learning, many time series forecasting models [2]\u2013[4] have emerged, which model data from the temporal dimension and learn the interrelationships between different time points to predict future time series. Additionally, many recent models rely on static periodic patterns [5], [6] and seasonal trend decomposition [7], [8] for time series forecasting. These approaches have demonstrated significant improvements in prediction accuracy when viewed from a periodic perspective. However, they apparently fail to realize the complex and overlapping nature of periodic features in real-world data. Specifically, hydrological data exhibits hidden and intricate multi-periodicity due to various natural factors, such as rainfall, terrain, soil, vegetation, etc. Methods based on fixed periods and trend decomposition are inadequate for accurately handling the multiple interacting periods present in hydrological data.\nIn addition, spatial correlations also play a crucial role in accurate flood forecasting for small and medium-sized watersheds. Recently, many spatio-temporal prediction methods have leveraged Graph Convolutional Networks (GCNs) [9]\u2013[11], learnable parameters [12], [13], and attention mechanisms [14], [15] to capture dynamic spatial information. While these methods show promise, they treat the entire input data as a single period, attempting to learn spatial information within this fixed period. In hydrological data, the spatial contribution of rainfall to flow is exceedingly complex and difficult to disentangle. The spatial correlations learned from a singular perspective clearly fall short in effectively representing the complex spatial structures present in the real-world."}, {"title": "II. RELATED WORK", "content": "Earlier flood prediction methods generally used statistical approaches, e.g., support vector machine [17], but with the development of neural networks, data-driven flood prediction methods have been improved. STA-LSTM [18] proposed by Ding et al. incorporates temporal and spatial attention into LSTM and is used for flood prediction. Sha et al. [19] combined graph convolutional networks with LSTM while also introducing temporal and spatial attention and successfully used it for flood prediction. Unfortunately, the aforementioned flood prediction methods do not consider the complex multi-periodicity and diverse spatiality in hydrological data, which are the focus of this paper.\nGNNs are widely used in temporal sequence prediction tasks with spatial information. Graph WaveNet [20] employs GCN combined with dilated convolution and adaptive dependency matrix to capture spatio-temporal information in the traffic data. ASTGNN [15] applies GCN to Transformer architecture, and learns temporal trend by time trend-aware self-attention. In recent years, many methods have focused their attention on the trend and periodicity of time series. Autoformer [21] extracts the seasonal trend from the original input data by moving average kernel. DLinear [8] uses a simpler linear model to predict time series with more obvious trend and periodicity, and achieves comparable or better performance than various Transformer variants. Recently, TimesNet [16] proposed a general temporal modeling method on periodic features, which can transform two-dimensional temporal data into three-dimensional, and effectively extract periodic information through visual backbone network. Although these methods take into account trend, periodicity and spatial dependencies, none of them consider the diverse spatial dependencies, which better reflects the spatial information of the real-world."}, {"title": "III. PRELIMINARIES", "content": "Flood forecasting is based on the historical hydrological data recorded by various monitoring stations in a region, to predict the flow values of that region in a future period of time. We use $X_t \\in \\mathbb{R}^{1\\times N}$ and $X_i \\in \\mathbb{R}^{1\\times 1}$ to denote the data from N stations and the i-th station at time t, respectively. Rain data is represented when $i \\neq N$, otherwise it is flow data. Historical data of time length T is denoted by $X = \\{X_{t-T+1}, X_{t-T+2},..., X_t\\} \\in \\mathbb{R}^{T\\times N}$. The predefined spatial structure graph is denoted by $G = (V, E, A)$, where V is the set of vertices, E is the set of edges, and $A \\in \\mathbb{R}^{N\\times N}$ is the adjacency matrix of G.\nGiven a graph G and historical data X of time length T. We need to learn that a function f is used to predict the flow values $Y = \\{Y_{t+1},...,Y_{t+H}\\} \\in \\mathbb{R}^H$ for the next H time steps, $Y_{t+1}$ is a scalar indicating the predicted flow value at the i-th time step after time t. The above content can be expressed by the following mapping relationship:\n\n$f [X_{(t_T+1)}, ..., X_t; G] \\rightarrow [Y_{(t+1)},..., Y_{(t+H)}]$ (1)"}, {"title": "B. LSTM Method", "content": "LSTM can learn and memorize long-term dependencies in sequences, thus improving the predictive ability of the model. LSTM uses the forget gate $f_t$ to discard information from the previous cell state $C_{t-1}$, the input gate $i_t$ to add information from the candidate cell state $\\tilde{C_t}$ to the current cell state $c_t$, and the output gate $o_t$ to output information from the cell state. The computation of the forget gate $f_t$, the input gate $i_t$, and the output gate $o_t$ is shown in Eq. 2.\n\n$f_t = \\sigma(W_f [h_{t-1},x_t] + b_f)$\n$i_t = \\sigma(W_i [h_{t-1}, x_t] + b_i)$\n$o_t = \\sigma(W_o [h_{t-1},x_t] + b_o)$ (2)\n\nThe current candidate cell state $\\tilde{C_t}$, the current cell state $C_t$ and the current output $h_t$ are shown in Eq. 3.\n\n$\\tilde{C_t} = tanh(W [h_{t-1}, x_t] + b_c)$\n$C_t = f_t C_{t-1} + i_t \\tilde{C_t}$\n$h_t = o_t tanh(c_t)$ (3)\n\nwhere $\\sigma$ denotes the sigmoid activation function and $\\odot$ denotes the hadamard product."}, {"title": "IV. METHODOLOGY", "content": "The overall architecture of the APS-LSTM model is shown in Fig. 2. The input data and predefined graph structures are first processed by the data embedding layer. In order to capture the deeper hidden periodic and spatial information, we process the embedded data through L layers of the adaptive periodic and spatial self-attention block (APS-Block), which are connected by residual networks [22]. Then the data with multi-periodicity and diverse spatial dependencies are fed into LSTM for sequence encoding and ultimately decoded through a linear output layer."}, {"title": "A. Data Embedding", "content": "The main role of the data embedding layer is to process the predefined graph structure using graph Laplacian eigenvectors [23], which allows the input data to contain the necessary spatial information.\nWe first convert the original adjacency matrix to a normalized Laplacian matrix by $L = I-D^{-\\frac{1}{2}}AD^{-\\frac{1}{2}}$, where I is the identity matrix and D is the degree matrix. The normalized Laplacian matrix is then subjected to an eigenvalue decomposition $L = Q\\Lambda Q$, where Q is the eigenvector matrix and $\\Lambda$ is the eigenvalue matrix. We select the m smallest nontrivial eigenvectors among the eigenvector matrix [24] and obtain the embedding space $X_e \\in \\mathbb{R}^{N}$ by linear projection of these m smallest nontrivial eigenvectors. We fuse the spatial graph Laplacian embedding with the original data using addition of the corresponding elements $X_e = X + X^* \\in \\mathbb{R}^{T\\times N}$."}, {"title": "B. Adaptive Periodic and Spatial Self-Attention Block", "content": "The APS-Blocks are connected by residual networks. Each APS-Block mainly consists of periodic information extraction, periodic and spatial self-attention, and adaptive aggregation.\nInspired by TimesNet [16], we use FFT to convert time-domain data into frequency-domain data. By analyzing frequency and amplitude, we can calculate different periodic division methods and uncover potential multi-periodicity. These can be given by:\n\n$F = Avg (Amp(FFT(X_e)))$\n$\\left\\{f_1,\\ldots, f_k\\right\\} = argTopk (F)$\n$p_i = \\frac{T}{f_i}$\n$\\left\\{p_1,..., p_k\\right\\} = \\left\\{\\frac{T}{f_1},..., \\frac{T}{f_k}\\right\\}$\n (4)\n\nwhere FFT() denotes FFT, Amp() denotes calculating amplitude values, Avg() denotes calculating average values from the N dimension, and finally obtaining the amplitude value of each frequency $F \\in \\mathbb{R}^T$. We select the k frequencies with the highest amplitude from F, where k is a hyperparameter, and the period length $p_1\\ldots, p_k$ corresponding to each frequency is calculated by $\\{\\frac{T}{f_1},\\ldots, \\frac{T}{f_k}\\}$.\nWe can use the formula Eq. 5 to convert a 2D tensor into a 3D tensor. Padding() means padding along the time dimension, $Reshape_{p_n^i,p_l^i}()$ means reshaping the time dimension of the tensor into the shape of the period length $p_l^i$ and the number of periods $p_n^i$, that is, the variables within and between periods. The hyperparameter k determines the diversity of the periodic divisions.\n\n$X_i^* = Reshape_{p_n^i,p_l^i} (Padding(X_{in})) \\in \\mathbb{R}^{p_n^i\\times p_l^i \\times N}$ (5)\n$i \\in \\{1,..., k\\}$\nAttention mechanism [25] can effectively focus on the key information and dynamic dependencies in the data. We design Periodic Self-Attention (PSA) and Spatial Self-Attention (SSA) to model the complex, dynamic and diverse periodic and spatial relationships.\nWe use Scaled Dot-Product Attention [26] to calculate PSA, as shown in Eq. 6-7. The difference is that, because the 2D kernel can pay attention to the change trend within and across periods, Query, Key and Value are calculated by convolution operations, rather than simple linear projection operations. Finally, the attention score of each node in different periods can be calculated.\n$Q^{(P)} = Conv2d(X_i^*)$\n$K^{(P)} = Conv2d(X_i^*)$\n$V^{(P)} = Conv2d (X_i^*)$ (6)\n$PSA = SoftMax(\\frac{Q^{(P)} (K^{(P)})^T}{\\sqrt{d_{pl^i}}}) V^{(P)}$ (7)\nwhere Conv2d means using 2D kernel for convolution operation.\nWe transform the data weighted by periodic self-attention back to the 2D tensor $X_s \\in \\mathbb{R}^{T\\times N}$, and then use SSA to learn the spatial dependence under the corresponding period division. Here we utilize 1D kernel to calculate Query, Key and Value, and the other parts are the same as calculating\n\n$Q^{(s)} = Conv1d(X_s)$\n$K^{(s)} = Conv1d(X_s)$ (8)\n$V^{(s)} = Conv1d(X_s)$\n$SSA = SoftMax(\\frac{Q_i^{(s)} (K^{(s)})^T}{\\sqrt{d_N}}) V_i^{(s)}$ (9)\nwhere Conv1d means using 1D kernel for convolution operation. After weighting by spatial attention score, we transform $X_{ps} into X_s \\in \\mathbb{R}^{T\\times N}$.\nWe reshape the data based on different frequencies into k types of 3D tensors, which are transformed by their own periodic and spatial self-attention modules, resulting in k types of outputs, combined as $\\{X_{ps}^1, ..., X_{ps}^k\\} \\in \\mathbb{R}^{k\\times T\\times N}$. In order to effectively fuse these k outputs, we use the amplitude values of the top k frequencies calculated before to represent the importance of these k tensors [16], [21], and then perform weighted summation, calculated as follow:\n\n$W_{f_1}, ..., W_{f_k} = SoftMax(F_{f_1}, ..., F_{f_k})$\n$X_{ps} = \\sum_{i=1}^k W_i X_s^i \\in \\mathbb{R}^{T\\times N}$ (10)\n\nThe aggregated results encompass features of multiple periods as well as a variety of spatial dependencies."}, {"title": "V. EXPERIMENTS", "content": "We selected two basins from Chinese regions for the experimental study, where missing values were filled by linear interpolation.\nTunxi Basin: TunXi located in Tunxi District, Huangshan City, Anhui Province, China, with a watershed area of 2,696.76 $km^2$, including 11 rainfall stations and 1 flow station, containing a total of 43,421 samples.\nChangHua Basin: ChangHua located in Lin'an City, Zhejiang Province, China, with a watershed area of 3444 $km^2$, including 7 rainfall stations and 1 flow station, containing a total of 9370 samples."}, {"title": "B. Baselines", "content": "We compared the APS-LSTM model with six baselines. Two of the baselines are RNN variants: LSTM [2] and GRU [27]. Two periodic and trend-based time-series prediction methods: DLinear [8] and TimesNet [16]. Two time-series prediction methods with spatial information: STA-LSTM [18] and Graph WaveNet [20]."}, {"title": "C. Experiment Settings", "content": "All our experiments were performed on an Ubantu 20.04 system equipped with an NVIDIA 2070Super GPU and 62GB of RAM. Our proposed APS-LSTM model was implemented based on Python 3.10 and PyTorch 1.13. We use the Adam optimizer with 0.01 learning rate for model training and MSE as the loss function. The random seed is set to 2, the batch size is 200, both L and k are both set to 2, and the hidden layer dimension is searched between 80 and 90. The number of training epochs on the TunXi and ChangHua datasets are 60 and 100, respectively.\n\n$RMSE = \\sqrt{\\frac{1}{n} \\sum_{i=1}^n(Y_i - \\hat{Y_i})^2}$\n$MAE = \\frac{1}{n} \\sum_{i=1}^n |Y_i - \\hat{Y_i}|$\n$MAPE = \\frac{1}{n} \\sum_{i=1}^n \\frac{|Y_i - \\hat{Y_i}|}{Y_i}$ (11)\n\nWe use 12 hours of historical data to predict the flood flow in the next 6 hours. The dataset is split into 80% training set, 5% validation set and 15% test set. The model parameters"}, {"title": "D. Analysis and Comparison of Results", "content": "The models use 12 hours of historical data on the TunXi and ChangHua datasets to predict the next 6 hours in the flood flow data. Our proposed APS-LSTM performs best on average compared to the other 6 baselines. In terms of RMSE and MAE, APS-LSTM achieves the best results except for T+1. In terms of MAPE metrics, it also maintains a high level of best or second-best performance at almost all times. On the TunXi dataset, the average RMSE, MAE, and MAPE metrics of APS-LSTM are reduced by 4.1%, 9.8%, and 19.4%, respectively, compared to the second-best model. On the ChangHua dataset, the reductions are 11.3%, 5.6% and 2.3%, respectively.\nWe also show the complete change trends of the evaluation metrics for APS-LSTM and 6 baselines when predicting the future 6 hours of flood flow. As shown in Fig. 3 and Fig. 4, as the prediction time length increases, the RMSE and MAE of all models show an upward trend. But APS-LSTM performs better, with a slower upward trend on these two metrics, and leads all the baselines from T+3 onwards. Fig. 5 shows the MAPE of each model in the experiment, the increase of time span clearly causes some fluctuations in the MAPE of 6 baselines. This is caused by the over-prediction of smaller values, which has little impact on the practical application of the flood prediction task. Compared with other methods, our proposed APS-LSTM is more stable, thus achieving the best performance with the smallest average MAPE.\nTo assess the effectiveness of the periodic self-attention and spatial self-attention modules, we disable the spatial self-attention and periodic self-attention components respectively, resulting in two weakened versions: AP-LSTM and AS-LSTM. As can be seen from Table II, APS-LSTM is only slightly inferior to AS-LSTM in terms of MAPE metrics for the ChangHua dataset, but achieves absolute advantages in other aspects, with a more comprehensive performance.\nWe select a flood scene in the TunXi test set, and show the peak flow prediction performance of the three best-performing models in this flood event at moments T+1 and T+6, as shown in Fig. 6 and Fig. 7. The prediction trends of APS-LSTM, LSTM and TimesNet are similar in most cases, but they differ when predicting the flood peak. APS-LSTM can capture the multi-period and diverse spatial dependencies better than LSTM and TimesNet, so it can adjust the prediction direction and make the peak flow prediction more accurate. At T+1, APS-LSTM predicted the peak time and peak flow almost in line with the actual situation, performing the best. LSTM showed a significant lag, while TimesNet predicted the peak flow as a V-shaped trend, performing the worst. At T+6, although the peak times predicted by the three models are earlier than the actual time, APS-LSTM predicted the flow value closer to the actual value and did not show a noticeable V-shaped change trend like LSTM and TimesNet."}, {"title": "E. Visualization of Periodic and Spatial Correlations", "content": "To increase the interpretability of the model, we selected a sample from ChangHua test set, and then visualized the spatial correlations between the nodes in that sample, as shown in Fig. 8. First, Fig. 8(a) and Fig. 8(b) are compared,"}, {"title": "VI. CONCLUSIONS", "content": "In this paper, we propose a novel model for flood flow prediction, named APS-LSTM. Our model uncovers elusive periodic characteristics and captures diverse spatial dependencies in hydrological data. Through quantitative and qualitative analyses on two hydrological datasets, we show that APS-LSTM outperforms six existing baselines in flood flow prediction. Our findings highlight the importance of mining multi-periodicity and diverse spatial dependencies for accurate flood prediction. In future work, we aim to integrate these aspects with other architectures to further improve flood forecasting accuracy."}]}