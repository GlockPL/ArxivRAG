{"title": "GraphLSS: Integrating Lexical, Structural, and Semantic Features for Long Document Extractive Summarization", "authors": ["Margarita Bugue\u00f1o", "Hazem Abou Hamdan", "Gerard de Melo"], "abstract": "Heterogeneous graph neural networks have recently gained attention for long document summarization, modeling the extraction as a node classification task. Although effective, these models often require external tools or additional machine learning models to define graph components, producing highly complex and less intuitive structures. We present GraphLSS, a heterogeneous graph construction for long document extractive summarization, incorporating Lexical, Structural, and Semantic features. It defines two levels of information (words and sentences) and four types of edges (sentence semantic similarity, sentence occurrence order, word in sentence, and word semantic similarity) without any need for auxiliary learning models. Experiments on two benchmark datasets show that GraphLSS is competitive with top-performing graph-based methods, outperforming recent non-graph models. We release our code on GitHub\u00b9.", "sections": [{"title": "1 Introduction", "content": "Extractive document summarization condenses documents into summaries by selecting only the most relevant sentences. One intuitive approach is to model cross-sentence relationships using graphs. While prior work considered homogeneous graphs (Tixier et al., 2017; Xu et al., 2020), recent heterogeneous graph proposals have shown high effectiveness (Wang et al., 2020; Jia et al., 2020), as they define complex relationships between multiple semantic units and capture long-distance dependencies. Despite their success in summarizing long documents such as scientific papers, many efforts have been made to devise more effective graph constructions. These vary in their definitions of nodes, often requiring external tools or additional machine learning models (Cui et al., 2020), and of edges, which despite being effective, may lead to complex structures that reduce the intuitiveness of the resulting graphs (Zhang et al., 2022).\nThis paper introduces GraphLSS, a graph construction that avoids the need for external learning models to define nodes or edges. GraphLSS utilizes Lexical, Structural, and Semantic features, incorporating two types of nodes (sentences and words) and four types of edges (sentence order, sentences semantic similarity, words semantic similarity, and word-sentence associations). We limit word nodes to nouns, verbs, and adjectives for their high semantic richness (Bugue\u00f1o and Mendoza, 2020; Xiao and Carenini, 2019). Our document graphs are processed with GAT (Veli\u010dkovi\u0107 et al., 2018) models on two summary benchmarks, PubMed and arXiv, which are preprocessed and labeled by us.\nOur contributions are: i. A novel heterogeneous graph construction using lexical, structural, and semantic features, ii. State-of-the-art results on both benchmarks compared to previous graph strategies and recent non-graph methods, iii. We share our code, including calculated extractive labels and graph-data creation pipeline, on GitHub\u00b9 for reproducibility and collaboration."}, {"title": "2 Previous Work", "content": "Graph Structure Developing an effective graph structure for summarization has been challenging, leading to a proliferation of diverse approaches. Wang et al. (2020) proposed connecting sentence nodes to word nodes by establishing undirected associations with the contained words. Subsequently, Jia et al. (2020) extended this by introducing named entity nodes and three other edge types: directed edges for tracking subsequent named entities and words in a sentence, directed edges for entities and words within a sentence, and undirected edges for sentence pairs with trigram overlap.\nTopic-GraphSum (Cui et al., 2020) was one of the first attempts to apply graph strategies to long document extractive summarization. It integrated a joint neural topic model to discover latent topics in a document, defining these as intermediate nodes to capture inter-sentence relationships across various genres and lengths. SSN (Cui and Hu, 2021) defined a sliding selector network with dynamic memory. SSN splits a given document into multiple segments, encodes them with BERT (Devlin et al., 2019), and selects salient sentences. Instead of representing the document as a graph, it uses a graph-based memory module, updated iteratively with a GAT (Veli\u010dkovi\u0107 et al., 2018), to allow information to flow across different windows. Heter-GraphLongSum (Phan et al., 2022) utilized words, sentences, and passages as nodes, while considering undirected edges for words in sentences, and directed edges for words in passages and passage to sentences. Instead of pre-trained embeddings, it used CNNs and bidirectional LSTMs for node encoding, yielding outstanding results. MTGNN-SUM (Doan et al., 2022) achieved similar results by capturing both inter and intra-sentence information when combining a homogeneous graph of sentence nodes with a heterogeneous graph of words and sentences, as in Wang et al. (2020).\nRecent studies underscore the importance of structural information in long document summarization. HEGEL (Zhang et al., 2022) modeled documents as hypergraphs, capturing semantic edges like keyword coreference, section structure, and latent topics. CHANGES (Zhang et al., 2023) introduced a sentence-section hierarchical graph, creating fully connected subgraphs for sentences and sections, and linking sentences to their sections.\nSentence Labeling There is no consensus on generating extractive ground truth labels. Most previous work (Jia et al., 2020; Zhang et al., 2022; Wang et al., 2024) used the Nallapati et al. (2017) greedy approach without specifying the ROUGE n-gram level, which significantly impacts sentence classifier performance. Some methods (Wang et al., 2020; Doan et al., 2022; Zhang et al., 2023) selected sentences by maximizing the ROUGE-2 score against the gold summary Liu and Lapata (2019), while others (Cui et al., 2020; Cui and Hu, 2021; Phan et al., 2022) used pre-labeled benchmarks (Xiao and Carenini, 2019) which maximized ROUGE-1. Conversely, Cho et al. (2022) maximized the average of ROUGE-1 and ROUGE-2."}, {"title": "3 GraphLSS", "content": "Graph Construction We propose a heterogeneous model that represents documents as undirected graphs, G = (V, E). We use sentences and words as nodes, V = Vs \u222a Vw, and four edge types to capture Lexical, Structural, and Semantic features, as E = {Ens, Ess, Ews, Eww}. Here, Vs corresponds to the n sentences in the document, and Vw denotes the set of m unique words of the document, limited to the most semantically rich ones, nouns, verbs, and adjectives. Conversely, boolean edges Ens indicate the sentence occurrence order in documents, and Ess includes sentence pair edges, weighted by cosine similarity, within a predefined window size to account for local similarity and prevent dense graphs. Ews denotes words in sentence edges (tf-idf weighted), and Eww are word-pair edges using cosine similarity.\nAdaptive Class Weights Our graphs are processed by a heterogeneous GAT (Veli\u010dkovi\u0107 et al., 2018) followed by a sentence node classifier to conduct the extractive summarization. Since the extractive ground truth labels for long documents are highly imbalanced, we optimize the model using weighted cross-entropy loss. We assign initial class weights to relevant and irrelevant sentences, employing adaptive class weights for the relevant class and static weights for non-summary sentences:\n$\\lambda^{i+1} = \\lambda^i - (\\frac{T}{T} - log(T))$ ,\nwith the portion of sentences predicted as relevant for the summary over all the existing sentences."}, {"title": "4 Experiments", "content": "Datasets We use two publicly available benchmarks for long document summarization, PubMed and arXiv (Cohan et al., 2018). Both comprise scientific English articles and are widely used by previous work. Statistics are given in Appendix A.\nExtractive Labels Extractive labels are obtained by greedily optimizing the ROUGE-1 score, an intuitive and widely used method that allows us to label more sentences as relevant than alternative strategies. In the data from Xiao and Carenini (2019), we identified substantial errors in the sentence tokenization. Hence, we independently preprocessed and labeled the data, removing duplicates, empty samples, and instances where abstracts exceeded source document lengths. We also replaced special characters (e.g., \\\\, ..., \u00bb, \u201c\u201d, \\n) with blanks. We applied sentence tokenization using NLTK and merged particularly short sentences with their preceding ones (cf. Appendix A). For word node definitions, we converted sentence text to lowercase, removing non-ASCII characters, punctuation, and stopwords."}, {"title": "5 Results & Analysis", "content": "Table 2 presents the results of different approaches, with graph-based models listed first, followed by non-graph baselines as reference, and our results. ROUGE-1/-2/-L F1-score is measured to assess the informativeness and fluency of the summaries.\nSummarization Results GraphLSS significantly outperforms all compared approaches in ROUGE-1/-2/-L scores on PubMed and arXiv, effectively identifying relevant sentences in highly imbalanced settings (Equation 1). These results are based on our preprocessing and labeling. The Oracle results using our labels also greatly exceed those achieved with the data by Xiao and Carenini (2019). With the latter labels, GraphLSS remains competitive (especially regarding ROUGE-L), despite not relying on auxiliary tools and models. This demonstrates close alignment with reference summaries in terms of the longest common subsequence, while alternative approaches yield contaminated summaries. Only HeterGraphLongsum surpasses GraphLSS by using CNN and LSTM networks to learn text embeddings from scratch, whereas we leverage pre-trained embeddings to reduce memorization and bias. These results also suggest that GraphLSS, even with pre-labeled data, outperforms recent non-graph models. Other graph methods are included for reference only, as they are not directly comparable due to the use of different labeling strategies in part requiring extrinsic resources.\nLabeling Impact Table 2 shows that summarization results can vary significantly, depending not only on the graph construction and model but also on the strategy used for generating extractive labels. This crucial aspect has been overlooked in related work, which often focuses on ROUGE results without considering whether the corresponding methods are using the same labeling approach. Moreover, preprocessing steps prior to label calculation can also affect the results. Although Xiao and Carenini (2019) and our study aimed to maximize the ROUGE-1 score, our labels differ significantly. Comparable setups are a requirement to accurately assess the advantages of models.\nBalance of Precision & Recall Table 3 shows that a two-layer heterogeneous GAT outperforms a single-layer GAT on both datasets, indicating the benefit of extended message passing across the multiple semantic units. Additionally, previous work has not adequately addressed the balance between precision and recall, focusing solely on reporting the F1 score without analyzing the individual values and their implications. Our results show that precision and recall are similar for the experiments on PubMed, reflecting a strong alignment between generated and gold summaries for both ROUGE-1 and ROUGE-2. In contrast, recall considerably exceeds precision on the arXiv dataset, suggesting our model retrieves relevant information but generated summaries still harbors additional text. This effect is more pronounced with a two-layer GAT. Interestingly, this discrepancy is not observed when using the pre-labeled data from Xiao and Carenini (2019), where precision and recall are balanced, though lower. This suggests that the observed differences are due to data labeling artifacts rather than the graph construction or the GAT model, emphasizing our earlier discussion.\nWhile arXiv articles are around 50% longer than those in PubMed, the graph size increases only by 15% in nodes and 75% in edges. Since nodes are represented by high-dimensional vectors and edges by single values, GraphLSS disk usage is mainly determined by node count, resulting in a 15% increase for arXiv (56 KB per graph). Such an increase is also reflected in the GAT training time (Table 3). Conversely, increasing model complexity from 1 to 2 GAT layers raises training time by 32% on PubMed and 40% on arXiv.\nAblation Study We conducted an ablation study on PubMed to assess the contributions of each edge type (Table 4). The results indicate that word-in-sentence edges have the highest impact on GraphLSS performance, as their removal significantly reduces ROUGE scores. This highlights the importance of cross-granularity interactions for effective document representation. Notably, around 80% of node associations are discarded when removing such edges, isolating words and sentences into separate components. Sentence edges are also important, with a comparable effect on ROUGE. However, sentence similarity edges are relatively more influential than sentence order ones due to their lower edge count. In turn, word similarity edges have the least impact, reflecting their low representation in the graph (only 3%; Table 1)."}, {"title": "6 Conclusions", "content": "We introduced GraphLSS, a heterogeneous graph for long document summarization incorporating lexical, structural, and semantic features. Experiments on PubMed and arXiv highlight the impact of extractive labels due to their inherent imbalance. GraphLSS proves competitive with top-performing graph-based methods and outperforms recent non-graph models by using a greedy labeling strategy and adaptive weights during training. Future work will explore integrating an abstractive summarizer."}, {"title": "Limitations", "content": "While we showed the impact and potential of GraphLSS for long document extractive summarization, there are some points to keep in mind.\nStoring document graphs as a data structure obtained from the original documents (texts) involves significant additional disk usage. Previous strategies create such structures on the fly while training the underlying GNN models, and others opt for storing such graphs on disk to speed up model training. We follow the latter strategy. Therefore, the training time reported does not consider the creation of the underlying graphs.\nFurthermore, our proposal was only validated on English datasets. Applying GraphLSS to other languages may yield significantly different results, since pre-trained word and sentence embeddings are required for node initialization and thus, training the heterogeneous GAT model. Analyzing this aspect would be particularly interesting for low-resource languages. Additionally, our experiments focus on scientific papers. Although they cover multiple scientific domains, exploring other kinds of long document, e.g., narrative and legal documents, is encouraged. Also, additional data collections should be analyzed in order to generalize our findings to broader domains."}, {"title": "Ethics Statement", "content": "While extractive summaries are less prone to hallucinated content, in some instances, they may be misleading due to missing context. Another concern is that of possible bias during the content selection. Depending on the graph construction applied, a GAT model may favor certain types of content over others, such as popular sentences and entities with high degrees, as they might receive more attention. Thus, special care must be taken when relying on summaries to make high-stakes decisions, for example in the legal or medical domains.\nSummarizing articles often involves extracting information related to trending topics, institutions, people, and other entities. Balancing the delivery of valuable summaries while respecting the privacy of these entities is essential. One strategy to alleviate such concern is anonymization, which ensures that the summary content does not reveal sensitive features. In our study, we conduct all experiments on publicly available scientific articles, and hence have forgone such anonymization."}]}