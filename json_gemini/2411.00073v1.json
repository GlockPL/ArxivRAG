{"title": "RSL-SQL: Robust Schema Linking in Text-to-SQL Generation", "authors": ["Zhenbiao Cao", "Yuanlei Zheng", "Zhihao Fan", "Xiaojin Zhang", "Wei Chen"], "abstract": "Text-to-SQL generation aims to translate natural language questions into SQL statements. In large language models (LLMs) based Text-to-SQL, schema linking is a widely adopted strategy to streamline the input for LLMs by selecting only relevant schema elements, therefore reducing noise and computational overhead. However, schema linking faces risks that requires caution, including the potential omission of necessary elements and disruption of database structural integrity. To address these challenges, we propose a novel framework called RSL-SQL that combines bidirectional schema linking, contextual information augmentation, binary selection strategy, and multi-turn self-correction. Our approach improves the recall of schema linking through forward and backward pruning and hedges the risk by voting between full schema and contextual information augmented simplified schema. Experiments on the BIRD and Spider benchmarks demonstrate that our approach achieves state-of-the-art execution accuracy among open-source solutions, with 67.2% on BIRD and 87.9% on Spider using GPT-40. Furthermore, our approach outperforms a series of GPT-4 based Text-to-SQL systems when adopting DeepSeek (much cheaper) with same intact prompts. Extensive analysis and ablation studies confirm the effectiveness of each component in our framework. The codes are available at https://github.com/Laqcce-cao/RSL-SQL.", "sections": [{"title": "Introduction", "content": "The task of translating natural language questions into structured query language (SQL), known as Text-to-SQL or Text2SQL generation, is crucial for enabling non-expert users to interact with relational databases (Wang et al., 2019; Qin et al., 2022). By bridging the gap between natural language and structured query languages, text2sql systems democratize data access and empower users to extract valuable insights without deep technical knowledge (Katsogiannis-Meimarakis and Koutrika, 2023).\nIn very recent years, leveraging the powerful comprehension and generation capabilities of Large Language Models (LLMs) (Achiam et al., 2023; OpenAI, 2024; Anthropic, 2024) for Text-to-SQL tasks has become a primary approach for boosting performance and prompt engineering emerges as the mainstream technical strategy. A typical prompt provided to the LLM for Text2SQL usually includes a description of the database, user queries, and few-shot demonstrations (Gao et al., 2023; Pourreza and Rafiei, 2024a), which allows the system to be applicable to various databases. Intuitively, assuming the LLM possesses sufficiently strong capabilities, the more precise and detailed the database description, the better the quality of the generated SQL queries. Features such as the database's structure, annotations, sample data, and relational mappings has been validated in specific scenarios to benefit Text-to-SQL performance (Li et al., 2024d; Lee et al., 2024).\nFine-grained descriptions of databases pose challenges. It is common for databases, especially industrial-grade databases, to have hundreds or thousands of fields. Incorporating complete database features in the prompt leads to excessive input tokens, increased computational costs, and, critically, the introduction of substantial noise (Talaei et al., 2024). Since user queries typically refer to a small proportion of database schema elements, a large amount of irrelevant schema information can confuse LLM and degrade performance. To mitigate this, schema linking (Lei et al., 2020; Pourreza and Rafiei, 2024a) techniques have been widely adopted to identify and include only relevant schema elements in the prompts.\nHowever, as shown in Figure 1, there are two types of information loss risks associated with schema linking: 1) The generated SQL will inevitably be erroneous if schema linking fails to identify all necessary tables and columns (assuming that the LLM does not generate any hallucinations, which means schema elements of the SQL generated by the LLM are entirely derived from input database schema); 2) Pruning the database schema might disrupt inherent structural relationships and impair the LLM's understanding of the database's raw structure, resulting in incorrect queries even though if schema linking identifies all required elements. Related research (Maamari et al., 2024) shows that for high-performance LLMs, such as GPT-4 or GPT-40, schema linking may even reduce the execution accuracy of generated SQL statements.\nTo address these challenges, we propose RSL-SQL, a Robust Schema Linking based Text-to-SQL generation framework that mitigates the risks associated with schema linking while leveraging its benefits. In our framework, we first generates a preliminary SQL using complete database schema and achieves high recall rate through bidirectional schema linking. Next, we simplify the database schema and enhance it with rich contextual information to generate an another SQL. Subsequently, a binary selection strategy (selecting the better SQL generated from the complete or simplified database schema) is used to hedge against the potential risks of schema linking. Finally, we employ a multi-turn self-correction approach, integrating feedback from SQL execution results to iteratively refine and optimize bad SQL statements.\nIn the experiments, we evaluate the proposed method RSL-SQL on BIRD and Spider datasets, comparing its performance against extensive Text-to-SQL methods. The experimental results show that when using GPT-40 as the backbone LLM, RSL-SQL achieves 67.21% execution accuracy and 69.39% valid efficiency score on the BIRD dataset (new SOTA among all open-source methods), and 87.2% execution accuracy on the Spider dataset (comparable to SOTA). Moreover, we demonstrate that, when using significantly more cost-effective DeepSeek, RSL-SQL outperforms many GPT-4-based methods on both BIRD and Spider datasets, despite that per-token cost of GPT-4 is 215 times higher than DeepSeek. The ablation study reveals that each component of our method contributes to the overall performance gains. Notably, our bidirectional schema linking technique achieves a high strict recall rate of 92% (a new SOTA) on BIRD dataset, while significantly reducing the average number of columns per query. Both contextual information augmentation and binary selection strategy are verified to improve accuracy steadily, thereby mitigating potential risks associated with schema linking.\nThe main contributions of this paper can be"}, {"title": "Related Work", "content": "Text-to-SQL has long been a research challenge aimed at translating natural language questions into SQL queries. Early approaches typically relied on handcrafted templates (Zelle and Mooney, 1996), which, while effective, were labor-intensive and limited in their application scope. In recent years, with the advent of large-scale Transformer models, particularly the sequence-to-sequence architecture (Vaswani, 2017; Sutskever, 2014), the performance of Text-to-SQL tasks has seen significant improvement. Models such as IRNet (Guo et al., 2019) and RAT-SQL (Wang et al., 2019), which adopt relation-aware attention mechanisms, have enhanced the integration of database schema information with the query generation process. However, despite these advancements, particularly on complex datasets like BIRD, there remains a significant gap between current methods and human performance.\nSchema linking is a critical step in the Text-to-SQL task, aiming to identify the relevant database tables and columns associated with a natural language query. To enhance the integration of schema information and capture its relationship with the question, models like RAT-SQL (Guo et al., 2019), SchemaGNN (Bogin et al., 2019), and ShadowGNN (Chen et al., 2021) have employed relation-aware self-attention mechanisms. Additionally, SADGA (Cai et al., 2021) introduces a novel dual graph framework, which is designed to interactively encode and aggregate structural information from both the natural language question and the database schema. Furthermore, RESDSQL (Li et al., 2023) introduces a ranking-enhanced encoder that ranks schema items based on their relevance to the input question. This ranking process reduces noise by filtering out irrelevant schema items before feeding them to the seq2seq model, alleviating the difficulty of schema linking during SQL parsing. While sequence-to-sequence models have shown improved performance, additional progress is needed to close the gap with human-level performance.\nWith large language models (LLMs) having been widely adopted for diverse NLP domains, the text-to-SQL field has also seen performance improvements, driven by recent methodological advancements in large language models (LLMs), particularly through techniques like zero-shot (Rajkumar et al., 2022) in-context learning, task decomposition (Pourreza and Rafiei, 2024a; Gao et al., 2023; Wang et al., 2023; Dong et al., 2023), Chains of Thought (CoT) (Wei et al., 2022), self-consistency (Wang et al., 2022), and least-to-most prompting (Zhou et al., 2022). While proprietary models have shown the most notable performance gains, open-source LLMs have been enhanced through supervised fine-tuning in models like DAIL-SQL (Gao et al., 2023), DTS-SQL (Pourreza and Rafiei, 2024b), and CodeS (Li et al., 2024b)."}, {"title": "Method", "content": "In this section, we introduce RSL-SQL, the proposed framework for Text-to-SQL generation with LLMs. As illustrated in Figure 2, our framework comprises four components, i.e., 1) bidirectional schema linking, 2) contextual information augmentation, 3) binary selection strategy and 4) multi-turn self-correction."}, {"title": "Prompt Engineering", "content": "Leveraging LLMs for Text-to-SQL task requires careful consideration of prompt engineering that influence the portability to diverse databases and accuracy of generated SQL queries. In this paper, we considers following key input elements:\nDatabase Schema (S) Detailed information about the database structure, such as table names, column names, and foreign key relationships. Providing this schema is crucial for helping LLMs understand real-world diverse database architecture and ensuring that the generated queries reference the appropriate tables and columns.\nValue Samples (V) Randomly selected a few rows from each table, allowing LLMs to gain a better understanding of the potential values of each column and semantics of the tables and columns. For overly long values, we truncate them to maintain a manageable input size.\nSchema Descriptions (D) Textual descriptions that offer additional semantic context about all tables and columns given any database with definite schema. We generate schema descriptions D utilizing LLMs, following the approach in (Qu et al., 2024), to enrich semantic context for all schema elements of each database.\nFew-Shot Examples (E) For each question, we retrieve a few pairs of natural language questions and their corresponding SQL queries from the training set. To identify most similar questions to the target question, we employ a Euclidean distance based question selector to select the top-k pairs, exactly following (Li et al., 2024d).\nUser Question (Q) natural language question from the user, serving as the primary input for SQL translation.\nAdditional Context (Optional) (C) any supplementary information that can clarify the user's question, such as definitions, constraints, or domain-specific knowledge.\nWe show how each part of above elements is organized in the prompt of LLMs in Figure 3."}, {"title": "Step 1: Bidirectional Schema Linking", "content": "We first introduce our bidirectional schema linking approach. In this process, a preliminary SQL query is generated based on complete database schema.\nForward Schema Linking Forward Schema Linking aims to directly identify potentially relevant schema elements to Q from the full database schema. Inspired by (Lee et al., 2024), we input full schema S, value samples V, and user's question Q. We then prompt LLMs to identify and format relevant tables as table_name and columns as table_name.column_name. If additional context C is available, we augment this list by traversing all column names and including those that appear in C. This combined list results in a set of tables and columns denoted as $L_{fwd}$.\nPreliminary SQL Generation We aim to generate a preliminary SQL query SQL\u2081 using the full schema S, following the approach in (Li et al., 2024d). The input components for LLMs include the full schema S, value samples V, few-shot examples &, user's question Q and additional context C. This prompt is illustrated in Figure 4. We also incorporate the results from the forward schema linking, $L_{fwd}$, as supplementary context, which we find can slightly enhance the accuracy of the preliminary SQL query. This can be formalized as:\n$SQL1 = f_{LLM}(S,V,E, Q, C, L_{fwd})$  (1)\nWe do not include schema descriptions D since describing each table and column with a paragraph within complete schema would result in overly lengthy input that may exceed the length limit of some LLMs.\nBackward Schema Linking Backward Schema Linking is complementary to Forward Schema Linking, where we parse the preliminary SQL query SQL\u2081 to extract an additional set of referenced tables and columns $L_{bwd}$. We utilize sqlglot (tobymax, 2024) library to parse and identify the schema elements within the generated preliminary SQL. This step is crucial, as $L_{bwd}$ should encompass all necessary elements if SQL1 is already correct.\nSchema Simplification We merge the results of forward and backward schema linking to obtain a more complete subset of tables and columns, i.e., $L_{fwd} \\cup L_{bwd}$, and streamline the database schema, value samples, and schema descriptions, resulting in their condensed counterparts $S'$, $V'$, and $D'$, which we called Bidirectional Schema Linking. It can significantly reduce redundant database information irrelevant to the user question, curtail the required input length and reduce the decision space for subsequent SQL generation, while maintaining a high recall for necessary schema elements."}, {"title": "Step 2: Contextual Information Augmentation", "content": "Schema linking simplifies database structure but may compromise its integrity. To mitigate this risk, we utilize LLM to independently generate key components of an SQL statement, including schema elements, conditions, and keywords contained within the SQL. We then input these components as additional information, along with detailed descriptions of each column in the simplified schema. Finally, we generate the complete SQL statement based on these collective inputs.\nSQL Components Generation We input the user query Q, simplified schema S', value samples V', description of columns D', and optional context C, SQL Components Generation aims to to pre-generate each component necessary for SQL generation. This includes:\n\u2022 Elements (HE): A list of tables and columns likely needed in the SQL query, which is exactly the same as forward schema linking.\n\u2022 Conditions (Hc): Possible conditions and constraints for the WHERE clause, through decomposition and analysis of the question.\n\u2022 Keywords (HK): SQL keywords (e.g., DISTINCT, GROUP BY) that may be relevant, by locating key indicator words in the question.\nWe define the simplified schema descriptions D' along with the LLM-generated HE, HC, and HK as contextual augmented information, collectively denoted as $H_{Aug} = {D', H_E, H_C, H_K}$, to help LLM to better understand the simplified database schema and target SQL statement.\nSQL Generation with Simplified Schema We generate an another SQL query based on the simplified schema. The prompt for the LLM includes the simplified schema S', value samples V', contextual augmented information $H_{Aug}$, few-shot examples E, the user question Q and optional question context C, as illustrated in Figure 4. This process can be formalized as:\n$SQL2 = f_{LLM}(S', V', H_{Aug}, E, Q, C)$ (2)"}, {"title": "Step 3: Binary Selection Strategy", "content": "We generate two SQL queries: SQL\u2081 from the complete schema S for structural completeness and SQL2 from a simplified schema S' to reduce noise. To select the optimal query SQL3, we use a large language model (LLM). The selection process is shown in Figure 8.\nSQL Selection Process Both SQL\u2081 and SQL2 are executed, producing results R\u2081 and R2 for correctness evaluation. To assess these queries, we utilize the user's question Q, additional context C, simplified schema S', value samples V', and few-shot examples E. The LLM then analyzes R\u2081 and R2 to select the optimal query as SQL3, ensuring semantic alignment with Q. This process can be formalized as:\n$SQL3 = f_{LLM}(S', V',D',E, Q,C, SQL1, SQL2, R1, R2)$ (3)\nThis binary selection strategy is an important step to mitigate the risk of schema linking. In fact, the complete schema and the simplified schema"}, {"title": "Step 4: Multi-Turn Self-Correction", "content": "Queries that cannot be executed are deemed incorrect. Similarly, empty execution results may indicate faults. We apply rules to identify high-error-probability queries for iterative refinement.\nIterative Refinement Process SQL3 may still contain syntax errors or yield empty results. If execution produces a syntax error or an empty result set, we capture and log this outcome as $E^{(0)}$.\nFor SQL queries with a high likelihood of errors, we employ an multi-turn conservation-based correction process. Initially, we provide the user's question Q, context C, simplified schema S', value samples V', examples &, the query $SQL^{(0)}$ (initialized as SQL3), and the error information $E^{(0)}$ to the LLM. The LLM then generates a new SQL statement, which is executed. If errors or empty results persist, we continue the dialogue by informing the LLM of the SQL error, iterating until reaching the maximum dialogue rounds. This process can be formalized as:\n$SQL^{(t+1)} = f_{LLM}(S',V',D',E, Q, C, SQL^{(t)}, \u03b5), E^{(t)})$ (4)\nTermination Condition The refinement process concludes when SQL executes successfully without syntax errors, returns a non-empty result, or reaches the maximum number of iterations N."}, {"title": "Experiment", "content": "4.1 Datasets\nBIRD Dev Set The BIRD dataset (Li et al., 2024c) is a large-scale, cross-domain Text-to-SQL dataset. Its key characteristic is the emphasis on processing database values while highlighting the challenges posed by dirty external knowledge bases, noisy database values, and the efficiency of SQL queries \u2014especially in large-scale database environments.\nSpider Test Set The Spider dataset (Yu et al., 2018) is a large-scale, cross-domain Text-to-SQL task dataset. Its key characteristic is that it not only contains complex SQL queries but also covers multi-table databases, making it an important resource for testing model generalization capabilities."}, {"title": "Evaluation Metrics", "content": "Execution Accuracy (EX) This metric is defined as the proportion of queries for which the output of the predicted SQL query is identical to that of the ground truth SQL query. We report the execution accuracy (EX) as a percentage of the queries in the evaluation set.\nValid Efficiency Score (VES) It is designed to measure the efficiency of valid SQL queries generated by models. It is important to note that \"valid SQL queries\" refers to the predicted SQL queries whose result sets align with those of the ground-truth SQL queries.\nNon-Strict Recall(NSR) In the current paper, the recall rate has not been explicitly defined, yet it plays a critical role in determining the accuracy of SQL generation after schema linking. Therefore, we provide a precise definition of recall rate.\nWe define the Non-Strict Recall (NSR) as the ratio of the sum of the number of elements in the intersection between the linked schema set and the ground truth schema set for each question to the total number of elements in the ground truth schema set. Mathematically, this can be expressed as:\n$NSR = \\frac{\\sum_{i=1}^{n} |S_{gt,i} \\cap S_i|}{\\sum_{i=1}^{n} |S_{gt,i}|}$ (5)\nwhere n is the number of questions, $S_{gt,i}$ represents the ground truth schema elements for the i-th question, and $S_i$ represents the linked schema elements for the i-th question.\nStrict Recall Rate(SRR) If all the necessary columns to generate the correct SQL query are included in S, the value is considered 1; otherwise, it is 0. The strict recall rate is the ratio of examples where all required schema elements are successfully recalled to the total number of examples.\n$SRR = \\frac{1}{n}\\sum_{i=1}^{n} \\mathbb{I}(S_i \\supseteq S_{gt,i})$ (6)\nOur method aims to maximize SRR while keeping |\u0160| as small as possible to reduce prompt size.\nStrict Recall Rate is a metric for evaluating the effectiveness of schema linking recall. It is defined as the proportion of correctly recalled column combinations. Specifically, if the column combination recalled by schema linking exactly matches the correct combination, it is considered a successful recall. However, since there is currently only one correct SQL, we first adopt the calculation method described in Equation 6."}, {"title": "Baseline Methods", "content": "In our experiments, we compare our proposed method against a diverse range of state-of-the-art Text-to-SQL approaches. These baselines employ various strategies to enhance performance, representing the current forefront of the field. DIN-SQL(Pourreza and Rafiei, 2024a) and MAC-SQL(Wang et al., 2023) adopt a task decomposition strategy to decompose complex queries into manageable subtasks. E-SQL(Cafero\u011flu and Ulusoy, 2024) and CHESS(Talaei et al., 2024), which focus on schema enrichment and linking, aim to address the gap between natural language queries and database structures. SQL-PaLM(Sun et al., 2023) and SuperSQL(Li et al., 2024b) employ distinct prompting and fine-tuning techniques for LLM adaptation in SQL generation. TA-SQL(Qu et al., 2024) and CodeS(Li et al., 2024b), which introduce strategies to mitigate hallucinations in LLM-based SQL generation. DAIL-SQL(Li et al., 2024a) is designed to address complex database environments.\nMulti-stage strategies based methods are also included, such as DTS-SQL(Pourreza and Rafiei, 2024b) that utilizes two-stage fine-tuning, MAG-SQL(Xie et al., 2024) that adotps multi-agent generative method, and MCS-SQL(Lee et al., 2024) that leverages multiple prompts and multiple-choice selection."}, {"title": "Result and Analysis", "content": "5.1 Main Results\nBIRD Results We conducted experiments on the bird development set using GPT-40 and DeepSeek models respectively, demonstrating the performance of our proposed RSL-SQL framework. We compare with published methods (with available code base and paper) and the results are shown in Table 1. RSL-SQL with GPT-40 achieves 67.21% accuracy and 70.32% valid efficiency score on the BIRD development set, outperforming all previous open source works and setting a new state-of-the-art performance. In addition, RSL-SQL with DeepSeek achieves an execution accuracy of 63.56% and an effective score of 67.68% on the bird development set, surpassing many methods using the GPT-4 model even though GPT-4's per-token cost is 215 times higher than that of DeepSeek.\nSpider Results In order to evaluate the generalizability of the proposed RSL-SQL, we further conduct experiments on the spider test set, and the results are shown in Table 2. RSL-SQL achieved an execution accuracy of 87.7% when using the DeepSeek model, which improved to 87.9% with the GPT-40 model. This performance is closely aligned with the latest MCS-SQL model (GPT-4), which achieved an execution accuracy of 89.6%. This highlights the strong generalizability of RSL-SQL and its potential for generating high quality Text-to-SQL\nSchema Linking Results The quality of the schema link affects the accuracy of the final generated SQL and also affects the length of the input token. In order to evaluate the effect of our proposed bidirectional pattern link, we conduct experiments on the BIRD dataset and count the recall metrics reported in published papers. The results are shown in Table 3.\nAs shown in Table 3, without schema linking, each query requires an average input of 76 columns, while only 5 columns are typically needed, resulting in substantial noise. The Bidirectional Schema Linking method effectively filters out irrelevant columns, reducing the average input per query to 13 columns while maintaining a strict recall rate of over 90%, thus resulting in an 83% reduction in the number of input columns."}, {"title": "Ablation Study", "content": "We conduct an ablation study to investigate the incremental impact of each component of our proposed method on execution accuracy (EX). The results of this study on the BIRD development set are presented in Table 4.\nThis table illustrates the execution accuracy of DeepSeek and GPT-40 across various task difficulty levels, showing the effects achieved by gradually incorporating different experimental steps into the models."}, {"title": "Prompt Refinement", "content": "For large language models, the prompt plays a crucial role. Before conducting our experiments, we refine the prompt by adjusting its structure and the information it provides. As shown in Table 4, we validate the effectiveness of each piece of additional information included in the prompt.\nThe Basic Prompt is built upon a complete database schema, including table names, column names, and foreign key information. It also includes user questions and additional context.\nThe addition of few-shot examples results in a 10% improvement in execution accuracy for both DeepSeek and GPT-40, highlighting the importance of these examples.\nFollowing this, the inclusion of additional data samples contributes approximately a 2% increase in accuracy, marking the completion of our prompt adjustment process."}, {"title": "Preliminary SQL Generation", "content": "Building on the previous prompt, we incorporate the results from Forward Schema Linking into the prompt to generate preliminary SQL queries. This integration results in an approximate improvement of 1% in performance. This preliminary SQL is generated within a complete database schema, ensuring the integrity of the database structure."}, {"title": "Contextual Information Augmentation", "content": "As shown in Table 5, we examined the impact of schema linking on Execution Accuracy without any additional information augmentation components. Schema linking improves Execution Accuracy by approximately 2% for weaker models like DeepSeek, while its impact on stronger models, such as GPT-40, is limited and can even be slightly negative. This observation supports the hypothesis proposed by the paper (Maamari et al., 2024), which suggests that schema linking may benefit weaker models but could potentially hinder stronger models.\nBuilding on the results of bidirectional schema linking, we obtain a simplified database schema. We then apply information augmentation methods to further enhance the large models' ability to understand the relationship between the database structure and user queries."}, {"title": "Binary Selection Strategy", "content": "To fully leverage the integrity of the complete database structure while minimizing redundancy, we select the SQL statements generated in Steps One and Two that are more aligned with the query.\nThe effectiveness of Selection Strategy lies in the fact that complete database structure information allows the LLM to gain a comprehensive understanding of the overall database. However, this can also introduce information redundancy and interference. In contrast, a simplified database structure reduces such interference but may lead to incomplete column recall, thus compromising the integrity of the database structure. Therefore, SQL generated by the two approaches has its own strengths and weaknesses.\nAs shown in Table 4, through the Selection step, we can choose the more accurate SQL from these two options, resulting in an improvement of approximately 1.5% in performance."}, {"title": "Multi-Turn Self-Correction", "content": "To further enhance the accuracy of generated SQL statements, we propose this strategy. When SQL fails to execute or returns empty results, it often indicates an issue with the query. By using rules to assess the execution risks of SQL, we can regenerate and adjust high-risk SQL. As shown in Table 4, this strategy slightly improves the accuracy of SQL generation."}, {"title": "Conclusion", "content": "In this paper, we present a novel framework for Text-to-SQL generation that effectively tackles the challenges posed by schema linking while improving execution accuracy. By introducing bidirectional schema linking, our framework achieves a comprehensive recall of relevant database elements with a strict recall rate of 92%, and it reduces input complexity by an average of 83%. Additionally, our information augmentation strategy enriches the model's understanding of database structure, resulting in an approximate 2% performance improvement on the BIRD dataset. Our selection strategy mitigates risk by voting between the full schema and a contextually augmented simplified schema, contributing an additional 2% improvement. Finally, multi-turn self-correction further enhances SQL generation accuracy.\nThe experimental results on the BIRD and Spider benchmarks demonstrate the effectiveness of our approach, achieving state-of-the-art execution accuracy of 67.2% and 87.9%, respectively. Notably, our method outperforms several existing GPT-4-based systems, even when applied to the more cost-effective DeepSeek model, highlighting its practical applicability."}, {"title": "Limitations", "content": "While our proposed text-to-SQL generation framework demonstrates significant improvements in performance and efficiency, it is essential to acknowledge some limitations. First, our approach relies heavily on the quality and coverage of the schema linking process. Although our bidirectional schema pruning technique achieves a high strict recall rate, there may still be edge cases where relevant schema elements are not captured, potentially impacting the accuracy of the generated SQL queries. Second, the effectiveness of our information augmentation strategy may vary depending on the complexity and domain of the database. In some cases, the generated additional elements may not fully capture the nuances of the database structure, leading to suboptimal SQL generation.\nMoreover, our framework's iterative refinement process, while effective in addressing syntax errors and empty result sets, may not always converge to the optimal SQL query within the preset maximum number of iterations. This limitation could be particularly evident in highly complex or ambiguous user questions. Finally, while we have evaluated our approach on the BIRD and Spider datasets, further testing on a wider range of datasets and real-world scenarios is necessary to fully assess its generalizability and robustness. Despite these limitations, our work presents a significant step forward in mitigating the risks associated with schema linking and improving the accuracy and efficiency of text-to-SQL generation."}]}