{"title": "Enhancing Temporal Link Prediction with HierTKG: A Hierarchical Temporal Knowledge Graph Framewor", "authors": ["Mariam Almutairi", "Melike Yildiz Aktas", "Nawar Wali", "Shutonu Mitra", "Dawei Zhou"], "abstract": "The rapid spread of misinformation on social media, especially during crises, challenges public decision-making. To address this, we propose HierTKG, a framework combining Temporal Graph Networks (TGN) and hierarchical pooling (DiffPool) to model rumor dynamics across temporal and structural scales. HierTKG captures key propagation phases, enabling improved temporal link prediction and actionable insights for misinformation control. Experiments demonstrate its effectiveness, achieving an MRR of 0.9845 on ICEWS14 and 0.9312 on WikiData, with competitive performance on noisy datasets like PHEME (MRR: 0.8802). By modeling structured event sequences and dynamic social interactions, HierTKG adapts to diverse propagation patterns, offering a scalable and robust solution for real-time analysis and prediction of rumor spread, aiding proactive intervention strategies.", "sections": [{"title": "1 Introduction", "content": "The rapid spread of rumors on social media has made it critical to understand the temporal dynamics of how misinformation propagates across online platforms ?. Misinformation, especially during crises or significant events, can escalate quickly, influencing public perception and potentially leading to harmful consequences. Rumor spread patterns often vary with time, peaking at specific moments triggered by influential users or external events?. To effectively capture these propagation dynamics, it's essential to model the interactions and the timing of events in a way that reflects both individual user behavior and the hierarchical structure within social networks.\nRecent advances in Hierarchical Temporal Knowledge Graphs (HierTKG) have provided a framework for analyzing rumor spread by capturing temporal patterns in user interactions and identifying key phases in propagation ?. HierTKG are particularly suited for social media, where each user or entity can have varying levels of influence that evolve over time. By analyzing the hierarchical and temporal relationships between entities, HierTKGs enable us to identify critical points in rumor cascades where intervention may be most effective.\nHierarchical pooling methods within HierTKGs, such as aggregating nodes and edges based on temporal or structural similarities, offer an efficient way to reduce data complexity while retaining essential features?. This allows for scalable analysis even in large, complex cascades, providing insights into how rumors intensify or fade over time. However, existing methods lack comprehensive frameworks that combine both temporal and hierarchical perspectives, limiting their ability to fully capture the evolution of rumor dynamics in real-time.\nIn this work, we address the challenge of modeling rumor propagation by focusing on the evolution of entity interactions (e.g., users, posts) within social networks over time. Specifically, we investigate how hierarchical pooling techniques can simplify the graph structure to enable a multi-level understanding of rumor cascades, capturing key moments and patterns of accelerated spread."}, {"title": "Research Questions:", "content": "\u2022 How does the evolution of interactions among entities influence the spread of rumors over time? Our objective is to understand the temporal dynamics within rumor cascades and identify peak periods of propagation.\n\u2022 How can hierarchical pooling techniques be employed to streamline the analysis of complex rumor cascades, providing a multi-level perspective of propagation patterns? This aims to yield insights into the full rumor propagation cycle across varying levels of network influence."}, {"title": "", "content": "The primary aim of this paper is to introduce a novel framework that integrates Temporal Graph Networks (TGN) with hierarchical pooling techniques. This integration enables the modeling of both temporal evolution and hierarchical structures within knowledge graphs, offering valuable insights into the dynamics of rumor propagation.\nAnother objective is to develop a scalable temporal and hierarchical modeling approach that aggregates nodes and edges based on shared temporal and structural features. This approach ensures the preservation of critical information while enabling effective multi-level analysis, which is crucial for understanding complex temporal relationships in knowledge graphs.\nThe paper further aims to improve temporal link prediction accuracy by capturing multi-scale structural and temporal dynamics. By leveraging these dynamics, the proposed framework enhances the prediction of rumor spread and other temporal link prediction tasks, addressing challenges in existing methods.\nFinally, the paper seeks to provide a comprehensive evaluation of the proposed framework through extensive experiments like ablation studies and comparison with recent state-of-the-art methods.\nOur approach uniquely combines the temporal and hierarchical aspects of rumor propagation, using both Temporal Graph Networks (TGN) and DiffPool to model the evolution of interactions over time and across different network levels. This dual focus is particularly valuable for knowledge graphs, where patterns often emerge on multiple scales and evolve continuously, such as in social network communities or biological pathways in protein interaction networks.\nOur key contributions are as follows:\n\u2022 Temporal Knowledge Graph Construction: Developed a comprehensive temporal knowledge graph from the PHEME dataset, capturing nuanced temporal and relational information critical for understanding rumor propagation.\n\u2022 HierTKG Framework: Introduced a novel integration of Temporal Graph Networks (TGN) and hierarchical pooling (DiffPool) to model both the temporal evolution and hierarchical structure of knowledge graphs, enabling detailed insights into rumor propagation dynamics.\n\u2022 Enhanced Temporal Link Prediction: Integration of multi-scale structural and temporal dynamics improves accuracy in predicting rumor spread.\n\u2022 Comprehensive Evaluation: Extensive experiments, including an ablation study, demonstrate the framework's effectiveness and robustness using datasets such as a Temporal Knowledge Graph derived from the PHEME dataset."}, {"title": "2 Related Work", "content": "In this section, fours groups of related work are discussed: 1) Knowledge Graph Based Rumor Analysis 2) Graph Neural Networks for Rumor Analysis, and 3) Dynamic Graph Networks for Rumor Analysis 4) Link Prediction with Temporal Knowledge Graph."}, {"title": "2.1 Knowledge Graph Based Rumor Analysis", "content": "Knowledge graphs have become a key tool in rumor and fake news analysis, with several recent frameworks leveraging their potential to enhance detection accuracy. DEAP-FAKED ? is a knowledge graph-based fake news detection system that combines Natural Language Processing (NLP) and tensor decomposition models to improve news content encoding and entity embedding. Similarly,"}, {"title": "2.2 Graph Neural Networks for Rumor Analysis", "content": "Several graph neural network-based approaches have been proposed for rumor detection. ? introduce PGNN, a gated graph neural network that constructs a propagation graph based on Twitter post interactions, enhancing detection performance through global and ensemble learning models (GLO-PGNN and ENS-PGNN). ? propose Graph Adversarial Contrastive Learning (GACL), which improves model robustness by integrating contrastive learning and an Adversarial Feature Transformation module to handle noise, adversarial rumors, and perturbations in conversational structures, outperforming state-of-the-art methods on benchmark datasets. ? present a rumor detection model utilizing graph convolutional networks that analyze both reply trees and user graphs, capturing structural and conversational information, resulting in better performance than baseline methods on a public dataset. Lastly,? introduce the Recurrent Graph Neural Network (R-GNN) for classifying user-generated content on Reddit, using a derived social graph, post sequences, and comment trees to enhance rumor detection accuracy."}, {"title": "2.3 Dynamic Graph Networks for Rumor Analysis", "content": "Dynamic graph networks play a crucial role in understanding and detecting rumors. Dynamic GCN ?, a novel graph convolutional network with attention mechanisms, captures both the structural and temporal aspects of rumor propagation, outperforming state-of-the-art methods on real-world datasets. Building on this, DGCN-TES ? introduces a dynamic, multitask model that integrates dynamic graph convolution, LSTM-based content analysis, and temporal event sharing to capture the evolving relationships in rumor propagation, leading to significant performance improvements. Additionally, ? propose DDGCN, a Dual-Dynamic Graph Convolutional Network that models the dynamics of both message propagation and background knowledge from knowledge graphs, achieving notable advancements in early-stage rumor detection."}, {"title": "2.4 Link Prediction with Temporal Knowledge Graph", "content": "Several models have been developed for TKG completion, each leveraging unique methodologies to handle temporal and semantic complexities. SPA, proposed by Wang et al.?, leverages neural architecture search (NAS) to design task-specific message-passing architectures for TKGs. This approach addresses the limitations of hand-designed architectures by exploring diverse topological and temporal properties inherent in TKGs. SPA employs a supernet structure that is trained by sampling single paths, enabling efficient search while reducing computational costs. Zhang et al.? introduced TLT-KGE, a novel embedding framework designed to distinguish semantic and temporal components in TKGs. By embedding entities and relations into quaternion space, TLT-KGE effectively models their independence and interconnections. This separation enhances the representation of entities and relations at different timestamps, addressing the challenge of temporal ambiguity.\nTNTComplEx, proposed by Lacroix et al.?, extends the ComplEx model by incorporating tensor decomposition to address temporal constraints. The model introduces novel regularization schemes to enhance its capability for time-aware link prediction tasks. This model highlights the potential of tensor-based methods for temporal knowledge representation. Chen et al.? proposed RotateQVS, which models temporal entities as rotations in quaternion vector space and relations as complex vectors. This approach captures intrinsic patterns in temporal relations, such as symmetry, asymmetry, and inversions, while modeling their temporal evolution."}, {"title": "3 Problem Definition", "content": "In this work, we address the problem of link prediction in a temporal knowledge graph (TKG) by constructing a Hierarchical Temporal Knowledge Graph (HierTKG) that captures both temporal and structural information. Temporal knowledge graphs consist of time-stamped triples (s, r, o, t), where s is the source node, o the target node, r the relation type, and t the timestamp. These dynamic graphs reflect evolving time-sensitive relationships. Our goal is to develop a model that effectively leverages temporal evolution and hierarchical structure for accurate prediction of future interactions."}, {"title": "3.1 Objective", "content": "Given a temporal knowledge graph G = {Gt}=1, represented as a sequence of snapshots Gt = (Vt, Et) at each time step t, our objective is to predict future links. For a pair of entities (s, 0) \u2208 Vt at some time t > T, we aim to predict the probability of a future interaction (s,r, o, t), where r is the relation. This is framed as a link prediction problem over temporal graphs, estimating new interactions from historical patterns."}, {"title": "3.2 Mathematical Formulation", "content": "Let G = {G1, G2, ..., GT} be a temporal knowledge graph observed up to time T, where each Gt = (Vt, Et) consists of nodes Vt and edges Et at time t. The goal is to learn a scoring function f to predict the likelihood of a future link (s, r, o, t).\n\u2022 Input Embeddings: Let xs(t) and x\uff61(t) represent the embeddings of nodes s and o at time t, capturing both temporal and structural information. These embeddings combine temporal insights (from TGN) and structural hierarchy (from graph pooling).\n\u2022 Scoring Function: The scoring function f takes node embeddings xs(t), x(t), relation r, and time t as input, outputting the likelihood of a link:\n$\\hat{y}_{(s,o,t)} = f(x_s(t), x_o(t), r, t t)$,\nwhere \u0177(s,o,t) \u2208 [0, 1] represents the predicted link likelihood.\n\u2022 Loss Function: To train the model, we use a binary cross-entropy loss over observed (positive) and non-observed (negative) links:\n$L=-\\sum_{(s,o,t)\\in D^+}log\\hat{y}_{(s,o,t)}-\\sum_{(s,o,t)\\in D^-} log(1 - \\hat{y}_{(s,o,t)}).$"}, {"title": "3.3 Hierarchical Temporal Knowledge Graph (HierTKG) Construction", "content": "HierTKG combines temporal evolution and hierarchical structure to enhance link prediction:\n\u2022 Temporal Graph Network (TGN): TGN updates node embeddings using recent and historical interactions. Temporal embeddings $z^{TGN}_s(t)$ and $z^{TGN}_o(t)$ capture immediate temporal context.\n\u2022 Graph Pooling for Hierarchical Structure: DiffPool creates hierarchical graph representations by clustering nodes. At hierarchy level l, cluster assignment $S^{(1)}$ and pooled embeddings $H^{(1)}(t)$ are computed as:\n$S^{(1)} = softmax(W^{(1)} . H^{(l-1)}(t))$,\n$H^{(1)} (t) = S^{(1)T}H^{(1-1)}(t).$\nThe adjacency matrix $A^{(1)}$ is updated as:\n$A^{(1)} = S^{(1)T}A^{(1-1)} S^{(1)}.$\nThe final embedding $z^{HierTKG}(t)$ integrates TGN-generated temporal information and hierarchical graph structure for effective link prediction."}, {"title": "4 Methodology", "content": "Our approach constructs a Hierarchical Temporal Knowledge Graph (HierTKG) to capture both the temporal dynamics and hierarchical structural patterns of an evolving temporal knowledge graph (TKG). Using Temporal Graph Networks (TGN) with Graph Attention and graph pooling techniques, we achieve a multi-scale representation that supports robust link prediction. This section details each component: the Temporal Graph Network (TGN) with Graph Attention, Graph Pooling for hierarchical representation, and Feature Fusion for integrating the temporal and structural features in the HierTKG."}, {"title": "4.1 Knowledge Graph Construction", "content": "The PHEME dataset contains a collection of Twitter rumors and non-rumors posted during various breaking news events. All tweets and their annotations are stored as JSON files that include source tweets and their associated features such as text, user information, retweet counts, timestamps, and labels (e.g., true, false, or unverified). From this rich dataset, we created three distinct types of entities: Event, representing the overarching news story or incident; Tweet, encapsulating individual social media posts with their associated metadata; and User, capturing information about the individuals who posted the tweets. These entities allow us to model complex interactions between the actors, content, and events in a structured and insightful manner, enabling advanced analyses such as rumor detection and propagation dynamics.\nThe relationships between these entities capture the dynamics of information flow and user interaction. For instance, a Tweet is linked to its corresponding Event through the \"Related to\" relationship, establishing its contextual relevance. The \"Mentions\" relationship connects a Tweet to the User it references, while the \"Replied to\" relationship maps conversations by linking one Tweet to another. Additionally, the \"Wrote\" relationship ties a User to the Tweet they authored. This structured entity-relationship model facilitates in-depth analysis of rumor propagation and user behavior within the dataset."}, {"title": "4.2 Temporal Graph Network (TGN)", "content": "The Temporal Graph Network (TGN) ? module is the core component for capturing the temporal dependencies of interactions between nodes in the temporal knowledge graph (TKG). In this approach, the TGN module combines node memory, temporal encoding, graph attention, and message"}, {"title": "", "content": "aggregation to effectively model dynamic node embeddings. These components work together to update node embeddings based on the historical interactions of each entity over time.\nGiven an input temporal knowledge graph with interactions represented as (s, r, o, t) - where s is the source node, o is the destination node, r represents the relation type, and t is the timestamp - the TGN module operates as follows:\n\u2022 Node Memory: Each node v maintains a memory state m\u2082 that stores the historical context of past interactions. This memory state is updated as new interactions occur, allowing the model to retain relevant information over time. Memory states are initialized at the start and updated iteratively as new events in the TKG are processed. Specifically, the memory for a node v at time t is denoted by $m_v(t)$.\n\u2022 Temporal Encoding: Temporal encoding captures the time differences between consecutive interactions, adding context to each event's temporal dynamics. For a pair of nodes (s, 0) with a time difference \u2206t = t-tprev, where tprev is the time of the last interaction, the relative time At is encoded using a time encoding function. The resulting temporal embedding, TE(At), is concatenated with other input features to form a comprehensive temporal context.\n\u2022 Message Passing with Transformer-based Graph Attention: To aggregate temporal and relational information, we use a Transformer-based convolution layer that applies multi-head attention to focus on relevant interactions. Given a pair of nodes (s, 0) with relation r at time t, the attention mechanism weights neighboring nodes based on their similarity and importance in the temporal context. The node embeddings for s and o at time t are computed as:\n$z_s(t) = TransformerConv (h_s(t), h_o(t), r, t)$,\nwhere hs(t) and h\uff61(t) are the embeddings of nodes s and o, respectively, incorporating both relational and temporal features. The attention layer dynamically adjusts the influence of each neighboring node, enabling the TGN to focus on relevant interactions in varying temporal contexts.\n\u2022 Message Aggregation and Update: For each interaction (s, r, o, t), a message is generated for both nodes based on the current temporal and relational context. We use the Identity Message function to produce messages that retain the original feature dimensions, ensuring that temporal information is fully preserved. Messages are then aggregated using a Last Aggregator that selects the most recent message for each node. This aggregator is particularly effective for temporal data, as it prioritizes recent interactions.\n\u2022 Memory Update: The memory of each node is updated after processing a batch of interactions. Specifically, for nodes involved in an interaction, their memory is updated based on the most recent message, ensuring that embeddings reflect the latest context. This update is applied through a gating mechanism that balances prior memory with new information,"}, {"title": "", "content": "computed as:\n$m_v(t) = GatingFunction(m_v(t \u2212 1), NewMessage)$\nwhere GatingFunction selectively integrates new information into the node's memory, retaining essential historical details.\nThe output of the TGN module, denoted as $z^{TGN}_s(t)$ and $z^{TGN}_o(t)$, provides temporally aware embeddings for nodes s and o at time t. This embedding integrates the historical context, temporal encoding, and attention-weighted messages, capturing both the temporal evolution and relational dependencies of each node in the TKG."}, {"title": "4.3 Graph Pooling for Hierarchical Representation", "content": "To capture structural hierarchy within the TKG, we employ a Graph Pooling technique, specifically DiffPool?, which aggregates embeddings at multiple scales, creating a hierarchy of representations. This approach enables our HierTKG to capture both fine-grained and coarse-grained structural dependencies.\n\u2022 Differentiable Pooling (DiffPool): The DiffPool layer groups nodes into clusters based on similarity in feature space. At each hierarchy level l, we apply DiffPool to generate coarser graph representations:\n$G_t^{(l)} = DiffPool (G_t^{(l-1)})$, \nwhere $G_t^{(l)} = (V_t^{(l)}, E_t^{(l)})$ represents the graph at level l, with node set $V_t^{(l)}$ and edge set $E_t^{(l)}$. DiffPool provides cluster assignment matrices that adapt to the graph structure.\n\u2022 Pooling Operation and Hierarchical Embedding: The embeddings at each level, denoted as $z_v^{(l)}(t)$ for node v at level l, capture increasingly abstract representations of the graph's structure. These multi-level embeddings allow the HierTKG to capture both local and global structural information, essential for accurate link prediction in complex temporal graphs."}, {"title": "4.4 Feature Fusion for Integrating Temporal and Structural Representations", "content": "In our model, the Feature Fusion module plays a crucial role in combining the temporal and structural information of each node within the Hierarchical Temporal Knowledge Graph (HierTKG). Temporal information, derived from recent interactions, provides insight into dynamic changes in the relationships between nodes, while structural information, aggregated across multiple hierarchical levels, captures the broader network context. Fusing these two types of embeddings allows the model to create a unified representation that leverages both recent temporal patterns and long-term structural dependencies, enhancing its ability to make accurate predictions on evolving knowledge graphs.\nThis fusion is necessary because temporal and structural embeddings alone are insufficient for accurately representing complex, dynamic interactions in a temporal knowledge graph. Temporal embeddings focus on short-term dynamics and may overlook the larger relational context, while structural embeddings capture multi-scale connectivity patterns but ignore recent interactions. By integrating both, the model benefits from a holistic view, improving its capability to predict future links by balancing both local (temporal) and global (structural) information.\nThe feature fusion process proceeds as follows:\n\u2022 Projection and Alignment: The temporal embeddings from the Temporal Graph Network (TGN) and the hierarchical structural embeddings from DiffPool are initially in different feature spaces, which makes direct combination challenging. To address this, we project both embeddings to a common dimensionality. Let $z_s^{TGN}(t)$ and $z_s^{Diff Pool}(t)$ represent the embeddings for node s at time t generated by TGN and DiffPool, respectively. We project these embeddings to a shared feature space using learnable linear transformations:\n$z_s^{TGN\\_proj} (t) = W^{TGN} .z_s^{TGN} (t),  z_s^{Diff Pool\\_proj} (t) = W^{Diff Pool} .z_s^{Diff Pool} (t)$,\nwhere $W^{TGN}$ and $W^{Diff Pool}$ are weight matrices that align the embeddings in a common space. This alignment is essential for enabling effective fusion in the next step."}, {"title": "", "content": "\u2022 Attention-based Fusion: With the embeddings aligned in the same feature space, we use a multi-head self-attention mechanism to integrate the temporal and structural information. The attention mechanism allows the model to weigh the importance of each embedding dynamically, focusing on the aspects most relevant to predicting future interactions. The fused embedding for node s at time t, denoted as $z_s^{HierTKG}(t)$, is computed as:\n$z_s^{HierTKG}(t) = Attention(z_s^{TGN\\_proj} (t), z_s^{Diff Pool\\_proj} (t))$,\nwhere Attention(\u00b7) represents the multi-head self-attention function. This function learns how to weigh and aggregate the temporal and structural features, producing an integrated representation that captures both recent dynamics and the hierarchical structure of each node's interactions.\n\u2022 Combined Representation: The output $z_s^{HierTKG}(t)$ represents the final fused embedding for node s at time t, incorporating both temporal information from TGN and structural hierarchy from DiffPool. This unified embedding is used as input for downstream tasks, such as link prediction, providing a holistic representation that reflects both local temporal dependencies and global structural patterns.\n\u2022 Formulation of Attention Mechanism: The multi-head attention mechanism is implemented by computing scaled dot-products across multiple heads. For each head i, we compute:\n$\\alpha_i = softmax(\\frac{[W_i^Q z_s^{TGN\\_proj} (t)] [W_i^K z_s^{Diff Pool\\_proj} (t)]^T}{\\sqrt{d_k}})$\nwhere $W_i^Q$ and $W_i^K$ are learnable weight matrices for the query and key transformations of the i-th head, and dk is the dimensionality of the key vector. The attention weights a\u017c are used to weight the value transformation, producing an output for each head:\n$z_s^{HierTKG} (t) = Concat(\\alpha_1 W_i^V z_s^{Diff Pool\\_proj} (t), ..., \\alpha_h W_i^V z_s^{Diff Pool\\_proj} (t))$,\nwhere $W_i^V$ is the learnable weight matrix for the value transformation of head i, and h is the number of attention heads. The concatenated output from each head is then projected back to the shared feature space to form the final fused representation.\nThe fused embeddings $z_s^{HierTKG}(t)$ produced by this feature fusion mechanism provide a unified, multi-scale representation for each node in the HierTKG. By combining recent temporal trends with structural context across multiple levels, the model achieves a comprehensive view of each node's position and interactions in the evolving graph. This approach enables the HierTKG to leverage both immediate changes and long-term patterns, enhancing its ability to make accurate link predictions in dynamic, temporal knowledge graphs."}, {"title": "4.5 Link Prediction using the Fused Embeddings", "content": "Finally, we use the fused embeddings $z_s^{HierTKG} (t)$ and $z_o^{HierTKG}(t)$ for link prediction. The link prediction module computes the probability of a future link between nodes s and o at time tas follows:\n\u2022 Similarity Scoring Function: The link prediction score between nodes s and o at time t is computed by a similarity-based scoring function:\n$\\hat{y}_{(s,o,t)} = f(z_s^{HierTKG}(t), z_o^{HierTKG}(t), r)$,\nwhere f is a learnable function (e.g., a bilinear product or feedforward network) that estimates the probability of a future link between nodes s and o given their fused embeddings and relation r.\n\u2022 Training Objective: The model is trained with a binary cross-entropy loss on observed and non-observed links, encouraging high scores for observed links and low scores for non-observed ones."}, {"title": "", "content": "Our method integrates TGN with Graph Attention and DiffPool to construct a Hierarchical Temporal Knowledge Graph (HierTKG), capturing both temporal evolution and hierarchical structural dependencies. By fusing TGN-generated temporal embeddings with DiffPool-based hierarchical embeddings, the model captures the multi-scale complexity of evolving temporal graphs, enabling accurate link prediction in complex dynamic environments. This approach ensures that both local temporal patterns and global structural context are represented in the HierTKG, effectively supporting downstream predictive tasks."}, {"title": "Algorithm 1 Hierarchical Temporal Knowledge Graph (HierTKG) Link Prediction", "content": "Require: Temporal knowledge graph G = {(s,r, o, t)}, training epochs E, learning rate \u03b7, TGN parameters, DiffPool parameters\nEnsure: Predicted links in future time steps\n1: Initialize TGN memory and parameters\n2: Initialize hierarchical structure using graph pooling parameters\n3: for epoch = 1 to E do\n4: \n5: \n6: \n7: \n8: \n9: \n10: \n11: \n12: \n13: \n14: \n15: \n16: \n17: \n18: \n19: \n20: \n21: \n22: \n23: \n24: \n25: \n26: \n27: \nTemporal Embedding Update (using TGN with Graph Attention)\nfor each interaction (s, r, o, t) \u2208 G at time t do\nCompute temporal encoding for the interaction using At = t - tprev\nUpdate node embeddings $z^{TGN}_s(t)$ and $z^{TGN}_o(t)$ using TGN with graph attention\nUpdate memory states for nodes s and o based on the most recent interaction\nend for\nGraph Pooling for Hierarchical Structure\nfor each level l in the hierarchy do\nCompute cluster assignment matrix $S'(l) = softmax(W^{(l)}. H^{(l-1)}(t))$\nCompute pooled embeddings $H^{(1)} (t) = S^{(1)T}H^{(1\u22121)}(t)$\nUpdate adjacency matrix $A^{(1)} = S^{(1)T} A^{(1\u22121)} S^{(1)}$\nend for\nFeature Fusion\nfor each nodes \u2208 G at time t do\n space\nProject temporal embedding $z^{TGN}(t)$ and structural embedding $h^d_s(t)$ to a common\nFuse embeddings using multi-head attention to obtain final embedding $z^{HierTKG}_s (t)$\nend for\nLink Prediction and Loss Calculation\nfor each link prediction (s, r, o, t) do\nCompute link prediction score $\\hat{y}_{(s,o,t)} = f(z^{HierTKG}_s(t), z^{HierTKG}_o(t), r,t)$\nCompute binary cross-entropy loss for observed and non-observed links\nend for\nParameter Update\nUpdate TGN, DiffPool, and fusion parameters using gradient descent with learning rate \u03b7\n28: end for"}, {"title": "5 Experiments", "content": "To evaluate the algorithm's performance comprehensively, we employed four diverse datasets: PHEME, ICEWS14, ICEWS18, and WikiData, focusing on link prediction and robustness testing."}, {"title": "5.1 Dataset", "content": "\u2022 PHEME: Focused on rumors and misinformation in social media, capturing information dissemination during major events. It comprises tweets categorized as rumors or non-rumors.\n\u2022 ICEWS14/ICEWS18: Part of the Integrated Crisis Early Warning System, these datasets center on global conflict events, supporting longitudinal analysis of trends.\n\u2022 WikiData: Derived from user interactions on Wikipedia, it models connections between pages as a graph. WikiData supports predictions related to interaction dynamics, such as page popularity and traffic trends, drawing from frameworks like JODIE."}, {"title": "5.2 Baselines", "content": "To establish a comprehensive baseline for temporal knowledge graph (TKG) completion, we employ the ICEWS14 dataset as the primary benchmark for evaluating baseline models. Unlike static knowledge graphs, which ignore temporal evolution, ICEWS14 offers temporal quadruples (s, p, o, t), where s and o are entities, p is the predicate, and t is the timestamp. This temporal specificity makes it particularly well-suited for evaluating models designed to capture both semantic and temporal features.\nWe compared our proposed method with 4 baselines.\n\u2022 EmtE?: Used entity multi-encoding and temporal awareness, integrating time-aware embeddings and GRU-based temporal feature extraction to address the limitation of one-sided entity feature acquisition and insufficient temporal fact utilization.\n\u2022 SPA?: Leverages neural architecture search (NAS) to design task-specific message-passing architectures for TKGs, addressing the limitations of hand-designed models by exploring diverse topological and temporal properties.\n\u2022 TIE?: Proposed learning temporal interaction embeddings (TIE) to benefit link prediction performance, to include multidirectional effects between entities, relations, and timestamps matter in predicting the establishment of quadruples in Global news events graphs.\n\u2022 TLT-KGE?: Embeds entities and relations into quaternion space to distinguish semantic and temporal components, enhancing the representation of entities and relations across different timestamps."}, {"title": "5.3 Evaluation Metrics", "content": "The choice of Mean Reciprocal Rank (MRR) as the evaluation metric is driven by its effectiveness in assessing ranking-based predictions. MRR provides a fine-grained measurement of a model's ability to accurately rank the correct tail entity among a list of candidates for a given head-relation query. As link prediction in TKGs involves ranking temporal facts, MRR captures both precision and positional relevance, making it the most appropriate metric for this study."}, {"title": "6 Results", "content": ""}, {"title": "6.1 HierTKG Performance", "content": "The performance of the proposed Hierarchical Temporal Knowledge Graph (HierTKG) framework was evaluated across four diverse datasets\u2014ICEWS14, ICEWS18, WikiData, and PHEME- using Average Precision (AP) and Mean Reciprocal Rank (MRR) as the primary evaluation metrics.\nICEWS14. HierTKG achieves a remarkable AP of 0.9708 and MRR of 0.9845, underscoring its capacity to model the temporal and hierarchical structures inherent in well-curated, event-based datasets. These results highlight the effectiveness of the framework in capturing both fine-grained temporal relationships and higher-order dependencies."}, {"title": "", "content": "ICEWS18. Similar to ICEWS14, the model exhibits strong performance with an AP of 0.9479 and an MRR of 0.9646. These results validate the robustness of HierTKG across datasets with varying temporal characteristics and event densities.\nWikiData. On the WikiData dataset, HierTKG achieves an AP of 0.8627 and an MRR of 0.9312, demonstrating its ability to generalize to interaction-driven datasets. The model effectively captures the dynamic nature of user-page interactions, which highlights its adaptability to heterogeneous graph structures.\nPHEME. The PHEME dataset, characterized by its noisy and sparsely connected nature, presents significant challenges. Despite this, HierTKG attains an AP of 0.6918 and an MRR of 0.8802, outperforming existing methods and emphasizing its robustness in unstructured, real-world data scenarios.\nThe results indicate that HierTKG achieves state-of-the-art performance on structured datasets, such as ICEWS14 and ICEWS18, where temporal and hierarchical patterns are clearly defined. The superior AP and MRR scores on these datasets illustrate the model's capacity to capture both short-term temporal dynamics and long-term hierarchical dependencies. On the other hand, the comparatively lower performance on PHEME reflects the inherent challenges of modeling noisy, sparsely connected data. Nevertheless, the framework's ability to achieve competitive results on this dataset demonstrates its robustness and generalizability.\nThe HierTKG framework effectively integrates temporal and hierarchical features to achieve high predictive accuracy and ranking performance across diverse datasets. Its exceptional performance on structured datasets and competitive results on noisy social media data position it as a robust solution for dynamic knowledge graph tasks."}, {"title": "6.2 Comparison with Baselines", "content": "Table 2 compares the performance of baseline models on the ICEWS14 dataset. EmtE emerges as the best-performing model, primarily due to its entity multi-encoding and temporal awareness, integrating time-aware embeddings and GRU-based temporal feature extraction. The second best alogorithm, SPA utilizes neural architecture search to optimize task-specific message-passing architectures for TKGs. TIE introduces temporal interaction embeddings to model multidirectional effects between entities, relations, and timestamps, whereas TLT-KGE employs quaternion space embeddings to improve the representation of semantic and temporal components. Our proposed HierTKG achieves a remarkable Test MRR of 0.984 on ICEWS14, significantly surpassing all baselines."}, {"title": "6.3 Ablation Study", "content": "To rigorously test the components of our model, we performed an extensive ablation study. The model's performance is evaluated using Average Precision (AP), Mean Reciprocal Rank (MRR) and Area Under the Curve (AUC) metrics. Additionally, we provide training/validation loss and AUC plots across epochs to assess convergence and performance trends.\nAblation studies involve systematically removing or replacing specific components of the model to assess their contribution to the overall performance."}, {"title": "7 Discussion", "content": "In our study, we came to understand that the nature of our algorithm aligns better with certain datasets. Datasets like ICEWS and WikiData are highly curated with well-defined temporal and relational patterns, making it easier for hierarchical models to detect and exploit inherent structures. In contrast, the Pheme dataset, derived from social media data, is inherently noisier with informal language, incomplete information, and high variability. Social media datasets often suffer from fewer samples, high class imbalance (e.g., rumors vs. non-rumors), and sparse temporal connections, which complicate the learning process. These challenges limit the model's ability to identify and generalize patterns effectively, resulting in lower performance compared to structured datasets.\nWe also found that our model performed exceptionally better than other baselines. We found that HierTKG leverages DiffPool to rank and cluster nodes into hierarchical levels, reducing noise and emphasizing key relationships. By summarizing global and local dependencies, the model simplifies the link prediction task and enhances performance.\nFrom our ablation study, it became clear that a hybrid approach, like HierTKG, offered distinct advantages over other configurations. First, DiffPooling plays a key role in advanced feature aggregation. It allows us to cluster nodes into hierarchical levels, reducing noise while highlighting the most relevant relationships in the data"}]}