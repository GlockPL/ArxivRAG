{"title": "Evolving Skeletons: Motion Dynamics in Action Recognition", "authors": ["Jushang Qiu", "Lei Wang"], "abstract": "Skeleton-based action recognition has gained significant attention for its ability to efficiently represent spatiotemporal information in a lightweight format. Most existing approaches use graph-based models to process skeleton sequences, where each pose is represented as a skeletal graph structured around human physical connectivity. Among these, the Spatiotemporal Graph Convolutional Network (ST-GCN) has become a widely used framework. Alternatively, hypergraph-based models, such as the Hyperformer, capture higher-order correlations, offering a more expressive representation of complex joint interactions. A recent advancement, termed Taylor Videos, introduces motion-enhanced skeleton sequences by embedding motion concepts, providing a fresh perspective on interpreting human actions in skeleton-based action recognition. In this paper, we conduct a comprehensive evaluation of both traditional skeleton sequences and Taylor-transformed skeletons using ST-GCN and Hyperformer models on the NTU-60 and NTU-120 datasets. We compare skeletal graph and hypergraph representations, analyzing static poses against motion-injected poses. Our findings highlight the strengths and limitations of Taylor-transformed skeletons, demonstrating their potential to enhance motion dynamics while exposing current challenges in fully using their benefits. This study underscores the need for innovative skeletal modeling techniques to effectively handle motion-rich data and advance the field of action recognition.", "sections": [{"title": "1 Introduction", "content": "Skeleton-based action recognition has seen significant progress due to its ability to represent human motion in a structured manner, with applications ranging from surveillance to healthcare and entertainment [10, 22, 47, 65, 68, 82-84, 87, 88, 92, 93, 111]. However, as the field matures, new challenges continue to emerge. While traditional skeleton-based methods [5, 13, 44, 82, 84, 98, 104, 106, 114, 116] excel at encoding the static spatial relationships of body joints, they often struggle to capture the full spectrum of dynamic motion [19, 20, 128], particularly in complex and highly coordinated actions. Addressing this challenge requires moving beyond simple static representations and incorporating richer, motion-centric features that can better model the temporal evolution of human actions [5, 7-9, 13, 44, 62, 67, 104].\nThe recent rise of graph-based models, particularly Spatial-Temporal Graph Convolutional Networks (ST-GCN)[110], has provided a powerful framework for skeleton-based action recognition by using the relationships between body joints over both space and time. These models represent human skeletons as graphs, where joints are nodes and their interactions, whether spatial or temporal, are encoded as edges. While effective in modeling pairwise dependencies between joints, such graph-based methods [42, 50, 60, 64, 84, 102, 121] still face limitations when attempting to capture complex, higher-order relationships, particularly in actions where the coordination between multiple joints is essential.\nIn response to these limitations, more advanced techniques have been introduced, such as Taylor-transformed skeleton sequences[95], which extend traditional representations by embedding motion dynamics through higher-order temporal derivatives (Figure 1). This transformation introduces additional layers of information, such as velocity and acceleration, which enhance the temporal representation of human motion and are particularly useful for distinguishing between similar actions that differ in their dynamics. Furthermore, hypergraph-based models, such as Hyperformer [120], have emerged as a promising approach to address the complexity of joint interactions by representing not only pairwise relationships but also higher-order joint dependencies through hyperedges[2, 11, 33, 63, 81, 89, 126].\nDespite the promising potential of these approaches, there has been limited work comparing their effectiveness across different domains and contexts. This paper aims to fill this gap by evaluating three key aspects of skeleton-based action recognition: (1) the comparison between ST-GCN and Hyperformer in their ability to model both spatial and temporal relationships, (2) the examination of traditional skeleton sequences versus Taylor-transformed skeleton sequences in terms of their ability to capture dynamic motion, and (3) the evaluation of skeletal graphs versus hypergraphs in their capacity to represent joint dependencies and action dynamics. The contributions of this paper are as follows:"}, {"title": "2 Related Work", "content": "Below, we review the most closely related works, categorizing them by key methodologies, and highlighting the novel contributions of our work in evaluating these different approaches.\nGraph-based models. The use of graph-based models, particularly ST-GCN, has become a dominant approach for skeleton-based action recognition. In ST-GCN [110], the human skeleton is represented as a graph where joints serve as nodes and the connections between them as edges. The edges model spatial dependencies, while temporal dependencies are captured by treating the skeleton sequence as a dynamic graph over time. ST-GCN has been shown to be highly effective for action recognition, achieving state-of-the-art performance on several benchmark datasets such as NTU RGB+D [56, 71] and Kinetics [6]. Several improvements on the original ST-GCN have been proposed to address its limitations [24]. These include methods that incorporate attention mechanisms [15, 32, 48, 66, 80, 105, 117], multi-scale graph convolutions [4, 23, 30, 36, 49, 78, 101, 107, 113, 127], and feature fusion strategies [17, 40, 42, 61, 62, 75]. However, these models typically rely on static representations of motion, where temporal evolution is embedded indirectly within the graph structure. As a result, they often struggle to capture the more complex, dynamic motion transitions between joints, which are crucial for distinguishing between certain types of actions, such as running vs.walking.\nWhile ST-GCN remains one of the foundational models in this domain, our work differentiates itself by directly evaluating its performance in comparison with other representations, specifically Taylor-transformed skeleton sequences. We assess how enriching skeleton sequences with higher-order temporal derivatives improves action recognition, especially for actions involving complex motion dynamics. By contrasting ST-GCN with Hyperformer [120], we provide new insights into how hypergraph-based models [3, 16, 39, 43, 51, 103, 125], which consider higher-order joint dependencies, can outperform traditional skeletal graphs in certain tasks.\nMotion-centric approaches. The limitation of static representations of skeleton sequences in ST-GCN models has led to the development of motion-centric representations [14, 45, 53, 95, 97, 122], such as Taylor-transformed skeleton sequences [95]. These transformations use higher-order temporal derivatives (e.g., velocity and acceleration) to enrich skeleton representations by emphasizing dynamic motion patterns. As introduced by [95], Taylor-transformed skeletons allow for a more granular depiction of motion, enabling"}, {"title": "3 Key Aspects of Human Motion Modeling", "content": "Below, we discuss the key aspects of modeling human motion that are central to this paper (Figure 2). For our evaluation, we select the basic ST-GCN and Hyperformer models. These models serve as foundational frameworks upon which many existing approaches are built, offering simplicity and ease of experimentation while providing valuable insights into skeleton-based action recognition."}, {"title": "3.1 Skeletal Graph and Hypergraph", "content": "Skeletal graphs and graph convolutions. Skeletal graphs represent the human body as a network of nodes (joints) and edges (bones). This approach adheres to the body's natural anatomical structure. Each node represents a joint, and edges connect joints based on their physical links or spatial connectivity. Beyond spatial relationships, temporal edges are added to connect the same joint across different time steps, capturing the motion dynamics over time [38, 66, 110]. This combination of spatial and temporal edges creates a comprehensive structure for representing actions [1, 27, 28, 118]. GCNs, such as the widely used ST-GCN [110], process these skeletal graphs by aggregating information from neighboring nodes. The structure of the graph dictates how information flows during convolution, enabling the model to capture the motion of individual joints and their interactions with immediate neighbors. However, skeletal graphs inherently focus on pairwise relationships, which may miss complex interactions involving multiple joints simultaneously [119, 120].\nSkeletal hypergraphs and hypergraph convolutions. Skeletal hypergraphs build upon the limitations of standard graphs by introducing hyper-edges, which connect groups of nodes rather than just pairs. This structure allows for modeling more complex relationships, such as the coordinated movement of multiple joints during an action. For example, in a running action, a hyper-edge could connect the hip, knee, and ankle to represent the interdependence of these joints in driving the motion. Hypergraph Convolutional Networks (HGCNs), like the Hyperformer, use these hyper-edges to aggregate features not just from neighboring nodes but from entire groups of related joints. This approach enables richer representations of actions, especially those requiring intricate coordination, such as gymnastics or team sports. By focusing on group-level interactions, hypergraphs can reveal subtle patterns that are missed in traditional graph-based models[109].\nComparative insights. The primary distinction between skeletal graphs and hypergraphs lies in their representation of relationships. Skeletal graphs are effective at modeling direct, pairwise connections and are well-suited for actions with clearly defined joint dependencies, such as walking or waving. However, they may oversimplify more complex actions where interactions among multiple joints play a critical role. In contrast, hypergraphs excel in capturing higher-order relationships by focusing on joint groups rather than pairs. This makes them particularly valuable for actions involving coordinated movements, such as dancing or playing an instrument. However, the increased complexity of hypergraphs requires careful design and computational resources, as determining which joints to group and how to weight their connections significantly impacts performance."}, {"title": "3.2 Skeleton and Taylor-Transformed Skeleton", "content": "Taylor-transformed skeletons [95] offer a significant advancement by integrating motion dynamics directly into skeletal sequences. Inspired by the mathematical framework of Taylor series expansion, this method incorporates multiple temporal derivatives, such as velocity and acceleration, into the skeleton's representation. By adding higher-order derivatives, Taylor-transformed skeletons provide a more comprehensive and dynamic view of human actions, capturing not only the spatial configuration of the joints but also how they change over time. This approach highlights motion-centric features, which are crucial for differentiating between actions that may appear similar in terms of static body posture but differ in movement dynamics.\nThe transformation process begins with the standard skeletal sequence, where each frame includes the positions of body joints. The zeroth-order component represents the static positions of the joints. The first-order derivative, or velocity, is computed by subtracting consecutive joint positions, reflecting the rate of change in the joints' positions over time. The second-order derivative, or acceleration, captures the changes in velocity, providing deeper insights into the dynamics of movement transitions. Additional higher-order derivatives can be introduced to capture even more complex motion details. These temporal components are combined with the original skeleton, creating a representation that emphasizes dynamic motion rather than static configuration.\nWhat makes Taylor-transformed skeletons stand out is their ability to prioritize temporal features that are essential for recognizing dynamic actions. Traditional skeletal representations [95] often focus on the spatial arrangement of joints, but they tend to overlook the temporal evolution of these relationships. By embedding motion-related features, Taylor-transformed skeletons ensure that action recognition models focus on meaningful temporal patterns, such as the acceleration of joints during specific movements. This approach reduces the reliance on redundant or less informative static data, allowing models to capture more nuanced motion characteristics.\nComparative insights. When integrated into graph-based models, such as ST-GCNs, Taylor-transformed skeletons can enhance model performance. The inclusion of motion-sensitive features improves the propagation of information through the graph, enabling more effective capture of temporal dependencies. In HGCNs, the transformed skeletons allow for a more refined modeling of complex relationships between joints, as hyper-edges can now represent dynamic groupings of joints that move together [35, 46]. This integration across different neural architectures underscores the versatility of Taylor-transformed skeletons in enhancing both spatial and temporal representations of human actions.\nDespite their promising potential, Taylor-transformed skeletons also present challenges for future research. One challenge is the development of neural architectures that can fully use the higher-order temporal derivatives, especially when modeling more intricate and subtle motions. Additionally, adaptive methods for selecting the optimal level of Taylor expansion based on the complexity of the action could improve the efficiency and effectiveness of the transformation [95]. By addressing these challenges, Taylor-transformed skeletons could redefine motion representation in action recognition, offering a more accurate, interpretable, and dynamic approach to modeling human actions."}, {"title": "3.3 ST-GCN and Hyperformer", "content": "In the realm of skeleton-based action recognition, two prominent models have emerged: the ST-GCN [110] and the Hypergraph Transformer [120], known as Hyperformer. Both models aim to effectively capture the complex spatial and temporal dynamics inherent in human skeletal movements, yet they approach this challenge through distinct methodologies.\nST-GCN. Introduced in 2018, ST-GCN represents human skeletons as graphs, with joints as nodes and bones as edges. This graph-based representation allows the model to capture spatial dependencies between joints. To incorporate temporal dynamics, ST-GCN extends this graph structure across time, forming a spatiotemporal graph where each node connects to its temporal counterparts in adjacent frames. Graph convolutions are then applied to extract features that encapsulate both spatial configurations and their temporal evolutions. This design enables ST-GCN to model the intricate patterns of human motion effectively."}, {"title": "4 Experiment", "content": "4.1 Setup\nDatasets. We choose the large-scale NTU-RGB+D 60 [71] and NTU-RGB+D 120 datasets [56] for the evaluations. The NTU-RGB+D 60 dataset, captured in a controlled laboratory environment with Kinect sensors, comprises around 56,000 video clips across 60 action classes. Each sample provides 3D joint coordinates for 25 body joints. Evaluations are performed using two standard benchmarks: the Cross-Subject benchmark, with 39,889 samples for training and 16,390 for testing, and the Cross-View benchmark, with 37,462 samples for training and 18,817 for testing.\nNTU-RGB+D 120 extends the original dataset to include around 114,000 video clips spanning 120 action classes. This dataset introduces additional evaluation benchmarks: the Cross-Subject benchmark, with 63,026 samples for training and 25,883 for testing, and the Cross-Setup benchmark, which provides 54,471 training samples and 24,911 testing samples. The expanded dataset and benchmarks enable a more comprehensive evaluation of model performance.\nMetrics. Recognition accuracies across all action classes are often visualized using a confusion matrix, which provides a detailed view of the algorithm's classification performance. The overall effectiveness of the algorithm on a given dataset is assessed by calculating the average recognition accuracy across all action classes. In our evaluation, we primarily report the top-1 recognition accuracy, representing the percentage of correctly classified samples where the top predicted label matches the ground truth. When required for comparative analysis, we also report the top-5 recognition accuracy, which accounts for cases where the correct label appears among the top five predictions.\nModels. We use two models for evaluation: the ST-GCN and the Hyperformer. Both models are tested on the original skeleton sequences as well as their Taylor-transformed counterparts. For Taylor-transformed skeletons, we use the displacement concept with a single term, using four frames per temporal block and a step size of one across all datasets. No hyperparameter search, or skeleton sequence denoising is performed in this process.\nThe ST-GCN model begins with batch normalization, followed by nine spatial-temporal graph convolution layers. The network outputs 64 channels in the first three layers, 128 channels in the next three, and 256 channels in the final three, all using a temporal kernel size of 9. Residual connections are incorporated to improve stability and address gradient vanishing issues. Temporal strides of 2 are applied at the fourth and seventh layers to enable downsampling, and dropout with a probability of 0.5 is applied after each unit to mitigate overfitting. After the final layer, global pooling generates a 256-dimensional feature vector, which is fed into a SoftMax classifier for action recognition. The model is trained using stochastic gradient descent with an initial learning rate of 0.01, which decays by 0.1 every 10 epochs.\nThe Hyperformer model is trained for 140 epochs using a cross-entropy loss function. The initial learning rate is set to 0.025 and decays by 0.1 at the 110th and 120th epochs. Training is conducted with a batch size of 64, and all sequences are resized to 64 frames. The model comprises a 10-layer architecture with 216 hidden channels, ensuring consistency across datasets and training conditions. These settings, along with the Taylor-transformed sequences, allow for a robust evaluation of action recognition performance. We use a batch size of 32 for ST-GCN and 128 for Hyperformer."}, {"title": "4.2 Evaluation", "content": "Taylor skeletons are not always the best. Table 1 presents the experimental results on NTU-60 and NTU-120. The results reveal that, overall, the Hyperformer model outperforms ST-GCN, both with and without the use of Taylor-transformed skeletons. This superior performance is attributed to the Hyperformer's ability to capture complex joint interactions through higher-order connections, whereas ST-GCN relies on predefined graph structures based on human physical connectivity, limiting its flexibility.\nFor the ST-GCN model, the use of Taylor-transformed skeletons significantly improves recognition accuracy on both NTU-60 and NTU-120. This demonstrates that Taylor skeletons enhance performance by introducing motion-sensitive features that better propagate information through the graph structure, enabling more effective capture of temporal dependencies.\nIn contrast, for the Hyperformer model, using Taylor-transformed skeletons slightly decreases performance compared to the original skeletons. However, the Hyperformer still surpasses the ST-GCN model in all scenarios, both with and without Taylor skeletons. The reduced performance with Taylor skeletons may be due to the Hyperformer not being specifically designed to leverage this data format. While Taylor skeletons excel in representing motion dynamics, they lack detailed spatial information about joint arrangements and their interactions, which the Hyperformer may still rely on for optimal performance.\nThese findings suggest that while Taylor-transformed skeletons offer valuable motion-related features, they require new model architectures tailored to handle this data format effectively. Such advancements could further elevate the performance of skeletal action recognition tasks by combining the strengths of both motion and spatial information.\nTaylor skeletons highlight distinct motion dynamics in ST-GCN. The confusion matrices for ST-GCN on NTU-60 (X-Sub) show distinct performance patterns between the use of original skeleton sequences and Taylor-transformed skeletons (see Figure 3). Both approaches exhibit strengths and weaknesses, highlighting the trade-offs in using motion-sensitive transformations versus relying on spatially structured data. The Taylor-transformed skeletons enhance recognition accuracy for several dynamic actions, such as drinking water, making a phone call, and reading. These actions benefit from the motion-sensitive features introduced by the Taylor transformation, which emphasize temporal dynamics and fine-grained motion patterns. By capturing nuanced joint displacements, the Taylor skeletons improve the propagation of information through the graph structure, allowing the model to better understand subtle temporal dependencies.\nConversely, Taylor-transformed skeletons lead to noticeable performance declines for actions such as clapping, hopping (one-foot jumping), wearing a jacket, staggering, and handshaking. These actions often involve complex spatial interactions or are characterized by repetitive, cyclic motions. The Taylor transformation, while excellent at highlighting motion, de-emphasizes the spatial relationships and global structure of the skeleton. This shift can introduce noise, particularly in actions where spatial context plays a critical role in recognition.\nThe original skeleton sequences, despite lacking explicit motion emphasis, retain the full spatial arrangement of joints. This proves advantageous for actions heavily reliant on spatial cues, e.g., handshaking, wearing a jacket, where the relative positioning of joints is crucial. The ST-GCN model, with its predefined graph structures based on human physical connectivity, is well-suited to use such spatial information, enabling better performance on these tasks.\nThe comparative results suggest that while Taylor-transformed skeletons offer valuable insights into motion dynamics, they may not universally enhance recognition across all action types. Dynamic actions with distinct joint displacements are well-served by this transformation. However, actions requiring an understanding of spatial arrangements or involving subtle, repetitive motions may suffer from the loss of spatial information. This analysis also underscores the need for tailored model architectures capable of synergistically combining the strengths of motion-sensitive transformations and spatially structured data. Future research could explore hybrid models that integrate Taylor-transformed skeletons with spatially-aware features, potentially unlocking improved performance across diverse action categories.\nWhich actions do Taylor skeletons improve performance on with the Hyperformer model? The comparison between the confusion matrices of the Hyperformer model on NTU-60 (X-Sub) using original skeleton sequences and Taylor-transformed skeletons shows critical insights into the model's performance dynamics (see Figure 4). Each approach highlights distinct advantages and limitations, providing a nuanced understanding of how these data representations impact recognition across various action classes.\nThe Taylor-transformed skeletons enhance recognition accuracy for actions with prominent motion dynamics, such as jumping, staggering, and taking off a hat. This improvement can be attributed to the Taylor transformation's ability to emphasize fine-grained motion patterns and temporal changes, which are crucial for recognizing actions that rely heavily on dynamic motion cues. The Hyperformer, equipped with its ability to capture higher-order connections, benefits from this enriched temporal information, enabling a more detailed understanding of joint movements.\nDespite these improvements, the Taylor-transformed skeletons lead to performance drops in certain actions, such as clapping, walking apart, and handshaking, which depend significantly on spatial configurations and global context. The Taylor transformation prioritizes motion over spatial arrangement, potentially diminishing the representation of joint relationships that are pivotal for recognizing these actions. This shift may introduce noise or obscure key spatial cues, leading to reduced accuracy in these categories.\nThe original skeleton sequences maintain a balanced representation of spatial and temporal features, which proves advantageous for actions requiring detailed spatial context. For instance, actions"}, {"title": "5 Conclusion", "content": "In this paper, we explore the effectiveness of traditional skeleton sequences and Taylor-transformed skeletons for skeleton-based action recognition using ST-GCN and Hyperformer models on NTU-60 and NTU-120 datasets. Traditional skeleton sequences effectively capture spatial and temporal relationships but face limitations in distinguishing actions with subtle temporal variations. Taylor-transformed skeletons, by embedding motion dynamics, improve recognition for motion-intensive actions, though they introduce challenges for actions requiring detailed spatial context. In terms of model architectures, ST-GCN demonstrates robust performance with graph-based representations of human physical connectivity but struggles to capture higher-order joint interactions. Conversely, the Hyperformer uses hypergraph structures to model complex joint dependencies, outperforming ST-GCN overall, yet showing sensitivity to the loss of spatial information in Taylor-transformed skeletons. Key insights from our study include: (1) the potential of Taylor-transformed skeletons to enhance motion-sensitive recognition, (2) the advantages of hypergraph-based models like Hyperformer in representing higher-order dependencies, and (3) the critical interplay between motion dynamics and spatial structure in achieving optimal performance. These findings highlight the need for innovative architectures that integrate motion-sensitive features with robust spatial modeling. By advancing the synergy between representation and temporal dynamics, future research can further improve skeleton-based action recognition."}]}