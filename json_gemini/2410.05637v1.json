{"title": "Federated Neural Nonparametric Point Processes", "authors": ["Hui Chen", "Hengyu Liu", "Yaqiong Li", "Xuhui Fan", "Zhilin Zhao", "Feng Zhou", "Christopher John Quinn", "Longbing Cao"], "abstract": "Temporal point processes (TPPs) are effective for modeling event occurrences\nover time, but they struggle with sparse and uncertain events in federated\nsystems, where privacy is a major concern. To address this, we propose\nFedPP, a Federated neural nonparametric Point Process model. FedPP inte-\ngrates neural embeddings into Sigmoidal Gaussian Cox Processes (SGCPs)\non the client side, which is a flexible and expressive class of TPPs, allowing\nit to generate highly flexible intensity functions that capture client-specific\nevent dynamics and uncertainties while efficiently summarizing historical\nrecords. For global aggregation, FedPP introduces a divergence-based mecha-\nnism that communicates the distributions of SGCPs' kernel hyperparameters\nbetween the server and clients, while keeping client-specific parameters lo-\ncal to ensure privacy and personalization. FedPP effectively captures event\nuncertainty and sparsity, and extensive experiments demonstrate its supe-\nrior performance in federated settings, particularly with KL divergence and\nWasserstein distance-based global aggregation.", "sections": [{"title": "1. Introduction", "content": "Temporal point processes (TPPs) [1, 2, 3, 4] have shown great promise in\nmodeling the occurrences of events over a specific observation period. TPPs\nhave been successfully applied to various domains, including neuroscience [5,"}, {"title": "2. Background", "content": "Temporal point processes (TPPs) provide a fundamental framework for\nmodeling event occurrences over time, with a broad range of applications\nin fields such as healthcare, finance, and social networks. Several advanced\nmethods have been developed to improve the expressiveness of TPPs, includ-\ning Sigmoidal Gaussian Cox Processes (SGCPs) for nonparametric modeling\nand neural embedding methods for capturing historical event dependencies.\nIn this section, we provide an overview of TPPs, introduce SGCPs as a\nkey nonparametric approach, and discuss neural embedding techniques that\nleverage historical event data to improve event prediction."}, {"title": "2.1. Temporal Point Processes (TPPs)", "content": "[22] provided a probabilistic framework for modeling a set of random\nevents over a time period. In TPPs, the rate of event occurrences is charac-\nterized by an intensity function $\\lambda(t)$:\n$\\lambda(t) = \\lim_{\\Delta t \\to 0^+} \\frac{E[N(t + \\Delta t) - N(t)]}{\\Delta t}$                                 (1)\nwhere $N(t)$ denotes the number of events occurring up to time t. The inten-\nsity function $\\lambda(t)$ is a non-negative function of time, indicating the likelihood\nof event occurrences at time t. Larger values of $\\lambda(t)$ imply a higher chance\nof event occurrence. Given a set of $N$ observed event times $t = {t_1, ..., t_N}$\nwith $t_i \\in [0,T]$, the likelihood of observing this sequence in a point process\nis:\n$L(\\lambda(t)|{t_1,...,t_N}) = e^{-\\int_0^T \\lambda(t)dt} \\prod_{i=1}^N \\lambda(t_i)$.                                                                                                                                 (2)"}, {"title": "2.2. Sigmoidal Gaussian Cox Processes (SGCPs)", "content": "SGCPs [17, 18, 19] is a powerful nonparametric framework for learn-\ning event data. In SGCPs, the intensity function $\\lambda(t)$ is modeled as a sig-\nmoidal transformation of a random function drawn from a Gaussian pro-\ncess, expressed as $\\lambda(t) = m\\cdot\\sigma(f(t))$, where $f(\\cdot) \\sim GP(v(\\cdot), K_{t,t';w})$, and\n$\\sigma(\\cdot) = 1/(1 + exp(-))$ ensures the intensity is within (0,1). Here, $m$ is\na scaling parameter, $f(t)$ is the random function, $v(t)$ is the mean func-\ntion, and $K_{t,t';w}$ is the kernel function with hyperparameters $w$. SGCPs are\nBayesian nonparametric models capable of representing highly flexible inten-\nsity functions. However, traditional SGCPs rely on standard kernels like the\nRBF kernel, which may be inefficient to generate highly flexible intensity\nfunctions. Further, it might be difficult to directly use the rich historical\ninformation to predict future events for SGCPs."}, {"title": "2.3. Neural Embedding Methods for Event Data", "content": "For a given event $t_i$, its history, denoted as $H_{t_i} = {t_{i'} : t_{i'} < t_i}$, can\nsignificantly influence the occurrence of the next event. Neural embedding\nmethods [11, 20, 21] encode this history into a vector $h_{i-1}$, referred to as\nthe historical embedding. This embedding can be used to parameterize the\nconditional distribution of the next event time $t_{i+1}$:\n$t_{i+1}\\sim P_{\\theta}(t_{i+1}| h_i)$, where $h_i = f_{update}(h_{i-1}, e_i)$.                               (3)"}, {"title": "3. The FedPP Methodology", "content": "In this section, we introduce the methodology behind our Federated neu-\nral nonparametric Point Process model (FedPP). FedPP is designed to ad-\ndress the challenges of modeling event sparsity and uncertainty in federated\nsystems while preserving data privacy. The main idea of FedPP is to inte-\ngrate neural embeddings with Sigmoidal Gaussian Cox Processes (SGCPs)\non the client side to model client-specific event dynamics and uncertain-\nties while effectively summarizing historical information. It also introduces a\ndivergence-based mechanism for sharing kernel hyperparameters between the\nserver and clients, while keeping client-specific parameters local to preserve\nprivacy and support personalization. This section is structured as follows:"}, {"title": "3.1. Client-side modeling: Neural SGCPs", "content": "Each client in the federated learning (FL) framework models its observed\nevent sequence $t_c = {t_{ci}}_{i=1}^{n_c}$, where $n_c$ is the number of events in client $c$,\nusing a client-specific SGCP. The intensity function $\\lambda_c(t)$ is expressed as:\n$\\lambda_c(t) = m_c \\cdot \\sigma(f_c(t)), f_c(t) \\sim GP(v_c, K_{\\cdot,\\cdot;w_c})$,                                                                                             (4)\nwhere $GP(v_c, K_{\\cdot,\\cdot;w_c})$ is a Gaussian process with client-specific mean $v_c$ and\nkernel $K_{\\cdot,\\cdot;w_c}$. In our neural SGCPs for each client $c$, neural embedding meth-\nods are used to encode the historical information of events and improve the\nexpressiveness of the intensity function.\nNeural Embedding. For each event $t_i$, we encode its history $H_{t_i} = {t_{i'} :\nt_{i'} < t_i}$ using a neural embedding method, by following Eq. (3). We propose\nthat the resulting embedding $h_i$ can be used to compute the kernel values\nbetween two time points $t_i$ and $t_j$ as:\n$K_{t_i,t_j; [w;r;l]} = r\\cdot exp(-\\frac{||h_i - h_j||^2}{2l^2})$,                               (5)\nwhere $w$ are the parameters of the neural network forming the historical\nembedding, $r$ is the scaling parameter and $l$ is the length-scale parameter for\nthe RBF kernel. By incorporating neural embeddings into the kernel of the\nSGCP, we efficiently summarize historical event information and generate\na more expressive intensity function. This addresses the traditional kernel\nlimitations in SGCPs.\nPrior and Variational Distributions. FedPP sets the prior distribution\nfor the parameter vector $w = [\\hat{w}; logr; log l]$, which is a combination of the\nneural network parameters $\\hat{w}$ and the RBF kernel parameters logr and log l,\nas an isotropic multivariate Gaussian distribution:\n$P_{\\theta}(W_c) = N(w_c; \\mu, diag(\\sigma^2))$,                                                 (6)\nwhere $\\theta = [\\mu; \\sigma^2]$, with $\\mu\\in R^{(M_w+2)\\times 1}$ and $\\sigma^2 \\in [R^+]^{(M_w+2)\\times 1}$. This prior\ndistribution is shared across all clients for their respective parameter weights\n$w_c$. Each client $c$ has its own variational distribution, denoted as $q_{\\phi_c}(W_c) =$\n$N(w_c; \\mu_c, diag(\\delta_c^2))$, where the variational parameters $\\phi_c = [\\mu_c; \\delta^2]$ are client-\nspecific, with $\\mu_c\\in R^{(M_w+2)\\times 1}$ and $\\delta^2 \\in [R^+]^{(M_w+2)\\times 1}$.\nSparse Gaussian Processes. The sparse Gaussian process method is em-\nployed for each client to reduce the computational cost of neural SGCPs from"}, {"title": "3.2. Server-side aggregation: Divergence-guided global aggregation", "content": "In FedPP, the prior distribution $p_{\\theta}(\\cdot)$, specifically its parameter $\\theta$ which\nis shared among all the clients, is maintained on the server. During each\ncommunication round, the server broadcasts the prior distribution $p_{\\theta}(\\cdot)$ to\nall participating clients. After each client updates its variational distribu-\ntion $q_{\\phi_c}(w_c)$ independently, the variational parameters $\\phi_c$ are uploaded to\nthe server. The global aggregation is performed by minimizing the sum of\ndivergences between $q_{\\phi_c}(w_c)$ and $p_{\\theta}(W_c)$ with respect to $\\theta$, expressed as:\n$\\min_{\\theta} \\sum_{c=1}^C DV [q_{\\phi_c}(W_c) || P_{\\theta}(W_c)]$,                                                                       (10)\nwhere $DV [\\cdot || \\cdot]$ represents a divergence between two probability distributions.\nThis process finds the optimal prior distribution $p_{\\theta^*}(\\cdot)$ that is closest to all\nthe variational distributions ${q_{\\phi_c}(W_c)}_{c=1}^C$ of clients.\nOur proposed divergence-guided global aggregation method extends be-\nyond temporal point processes (TPPs). This approach can be applied in\nany federated learning scenario where probability distributions are commu-\nicated between the server and clients. Fig. 1 illustrates how $\\theta$ is updated\nfor the prior distribution $p_{\\theta}(W_c)$.\nTo solve Eq. (10), we consider several choices for $DV [\\cdot || \\cdot]$, primarily\nKL Divergence and Wasserstein Distance. There are several ways to define\n$DV [\\cdot || \\cdot]$, each leading to different global aggregation rules:"}, {"title": "3.3. Bi-level optimization", "content": "The inference process of FedPP is formulated as a bi-level optimization\nproblem. The outer optimization aims to minimize the global objective func-\ntion $F(\\Theta)$, which is defined as the average of local objective functions across"}, {"title": "3.4. The FedPP Algorithm", "content": "We propose a novel federated learning (FL) algorithm to instantiate\nFedPP in a practical cross-device FL setting, where a random subset $S_j$\nof all clients participates in each communication round. Directly optimiz-\ning Eq. (16) is challenging due to the absence of an analytical form for the\nreconstruction loss. To address this issue, we outline a three-step strategy.\nStep 1: Calculating $E_{q_{\\phi_c}(w_c)} [log p(t_c|w_c, z, m_c, v_c)]$. The likelihood of\nevents for client c, $p(t_c w_c, z, m_c,v_c)$, is computed by integrating out the\napproximated function $f(t)$ and the inducing points $u_c$:\n$p(t_c|w_c, z, m_c, v_c) = \\int p(t_c|m_c, f_c(t))p(f_c(t)|u_c, w_c, z, v_c)p(u_c|z, w_c) du_cd f_c(t)$,                 (19)\nwhere $f(t)$ is the approximated function and $u$ are the inducing points.\nThe expression $p(t_c|w_c, z, m_c, v_c)$ involves integration and sigmoidal op-\nerations in the exponential term, which makes direct inference challenging.\nTo overcome this, we adopt the SGCPs model [17, 18, 19, 25, 26] and aug-\nment it with latent marked Poisson processes $\\Pi_c$, where $m_c \\times PPG(\\xi|1,0)$\nserves as the intensity function. Additionally, P\u00f3lya-Gamma random vari-\nables ${\\xi_c}_{i=1}^{n_c}$, governed by the P\u00f3lya-Gamma distribution $PPG(\\xi|1,0)$, are\nincorporated. This allows us to express the augmented likelihood as:\n$p(t_c/f_c(\\cdot), m_c) = \\int p(t_c, \\Pi_c, {\\xi_c}_{i=1}|m_c, f_c(\\cdot))$\n$\\Pi [e^{g(\\xi_{c,j}, -f_c(t_{c,j}))} m_cPPG(\\xi_{c,j}|1,0)] \\cdot d\\Pi_cd{\\{\\xi_i\\}_{i=1}^{n_c}}$,                                (20)\nwhere $g(\\xi, f) = f/2 - \\xi f^2/2 - log 2$. This results in a closed-form expression\nfor the evidence lower bound (ELBO)."}, {"title": "Step 2: Mean-field Variational Inference for Random Variables $u_c$,\n$\\xi_c$, and $\\Pi_c$.", "content": "To simplify the inference, we assume independence between\nthe random variables $u_c, \\xi_c$, and $\\Pi_c$. By using the standard mean-field\nvariational inference method [27, 28], we compute the optimal variational\ndistributions as follows:\n$In q_{\\xi_i} (x_i) = E_{q_{\\setminus i}}[ln p(D, {\\xi_i}_i)] + const.$                                      (21)\nIt is noted that we are using KL-divergence between the variational distribu-\ntion of $u_c$, $\\xi_c$, $\\Pi_c$ and their prior distribution here. The divergence $DV [\\cdot || \\cdot]$\nis used for the case of $w_c$ only. That is, we are using separate divergences\nfor $u_c$, $\\xi_c$, $\\Pi_c$ and $w_c$. Further details of the calculation for each of $u_c$, $\\xi_c$, $\\Pi_c$\nare provided in Appendix F.\nStep 3: Maximizing the Local Objective Function w.r.t. $q_{\\phi_c}(w_c)$.\nThe local objective function for client c is abstracted as:\n$L_c(\\phi_c) := -E_{q_{\\phi_c}(w_c)} [DV [q(u_c) || P(U_c|w_c,Z)]]$\n$+ E_{q_{\\phi_c}(w_c)} [log p(t_c|w_c, \\cdot)] - DV [q_{\\phi_c}(W_c) || P_{\\theta}(W_c)]$.              (22)\nWe can leverage the reparameterization trick to compute a closed-form ex-\npression for the first two terms. The last term is straightforward to calculate\nsince both $q_{\\phi_c}(w_c)$ and $p_{\\theta}(w_c)$ follow Gaussian distributions.\nBrief Summary of the Local Updates: At the j-th communication\nround, the global distribution $p_{\\theta^{(i)}}(w_c)$ is sent to each client c. During each\nlocal epoch, the variational distributions of $u_c, \\xi_c$, and $\\Pi_c$ are updated using\nEq. (21). Then, the variational parameters $\\phi_c$ are optimized using first-order\nstochastic gradient descent (SGD):\n$\\phi_c^{(l)} \\leftarrow SGD(-L_c(\\phi_c); B, E, \\eta)$,                                                                                                                                                                              (23)\nwhere $B$, $E$, and $\\eta$ represent the mini-batch size, the number of local epochs,\nand the learning rate, respectively."}, {"title": "4. Related Work", "content": "Since our work is the first to apply FL to predict events, we have a\nbrief review on the FL with GPs and other typical methods in point process\nmethods. [29] explored GPs for few shot classification, which learns covari-\nance functions parameterized by deep neural networks. [30] applied GPs"}, {"title": "5. Experiments", "content": ""}, {"title": "5.1. Data, Models and Settings", "content": "In the experiments, we utilize five benchmark datasets from diverse do-\nmains: Taobao, which contains timestamped user online shopping behaviors\non the Taobao platform; Retweet, consisting of timestamped user retweet\nevents; Conttime, a simulated public dataset provided by [37]; Stack Over-\nflow, which includes question-answering badge events; and Amazon, featur-\ning timestamped user purchase behaviors on the Amazon platform. These\ndatasets are employed to evaluate the performance of our proposed model,\nFedPP, against baseline methods. For each sequence, we use the first 60% for\ntraining, the next 20% for validation (used for hyperparameter tuning), and\nthe final 20% for testing. Additionally, we normalize the entire observation\ntimeline into [0, 100] for numerical stability. To construct a heterogeneous\nsetting, where local data across clients are non-IID, we allocate an equal\nnumber of samples to all clients, with each client being assigned k(< K)"}, {"title": "5.2. Performance Comparison", "content": "Test Log-likelihood for Different Datasets. We conduct the exper-\niments under heterogeneous settings on five different benchmark datasets."}, {"title": "5.3. Further Evaluation on Federated Settings", "content": "Since this work primarily explores the feasibility and effectiveness of the\nTPPs in federated scenarios, it is crucial to investigate the performance of\nthe proposed method FedPP in various federated settings."}, {"title": "6. Conclusions", "content": "We have introduced FedPP, the first approach to learning point pro-\ncesses for uncertain and sparse events in a federated and privacy-preserving\nmanner. Extensive experimental evaluations show that FedPP consistently\noutperforms federated versions of benchmark methods across five datasets.\nThe integration of neural embeddings into Sigmoidal Gaussian Cox Processes\nproves highly effective in both summarizing historical information and learn-\ning flexible intensity functions. Additionally, we proposed a novel framework\nfor global aggregation using divergence measures, offering practical inter-\npretations for the aggregation process. This divergence-guided framework\ncan be extended to any Bayesian federated learning method that involves\nprobability distribution aggregation, paving the way for future work in this\ndirection."}, {"title": "Appendix A. Related work about Survival analysis", "content": "Survival analysis is a statistical framework used to analyze the time until\nan event of interest occurs, commonly employed in fields such as healthcare,\nfinance, and engineering to model time-to-event data [42, 43]. Traditional\nsurvival analysis often relies on techniques like the Cox proportional hazards\nmodel, where the risk (or hazard) of an event is estimated over time. In this\ncontext, events are usually assumed to occur only once, and the data might\ninvolve censoring, where the event does not occur during the observation\nperiod. When extended to FL, survival analysis must adapt to decentralized\nsettings where data is distributed across multiple clients, such as hospitals"}, {"title": "Appendix B. Deep Kernel Learning", "content": "Modern GP approaches, such as Deep Gaussian Processes (DGPs) [47]\nand Deep Kernel Learning (DKL) [48], usually use deep architectures to en-\nhance the expressive power of kernels. For instance, DKL defines kernels on\nfeatures mapped by a neural network $g_{\\hat{w}}(\\cdot)$, with $\\hat{w}$ being the neural network\nparameters. In this way, the RBF kernel entry between $x_i$ and $x_j$, as an ex-\nample, can be formulated as $k_{x_i,x_j;[w;r;l]} = r\\cdot exp(-\\frac{||g_{\\hat{w}}(x_i) - g_{\\hat{w}}(x_j)||^2}{(2l^2)})$,\nwithr and l being the scaling and band-width parameters. Without partic-\nularly specified, we use the RBF kernel as the default kernel in this work."}, {"title": "Appendix C. Additivity Property of TPPs", "content": "Property Appendix C.1. Let $N_1(t)$ and $N_2(t)$ be two independent tem-\nporal point processes with intensity functions $\\Lambda_1(t)$ and $\\Lambda_2(t)$ respectively.\nThe process $N(t) = N_1(t) + N_2(t)$ is also a temporal point process with the\nintensity function $\\lambda(t) = \\lambda_1(t) + \\lambda_2(t)$."}, {"title": "Appendix D. Sparse Gaussian Processes", "content": "Although powerful and highly flexible, GP, which is the key component\nin SGCPs, is often questioned due to its high computational cost. In par-\nticular, obtaining the posterior of the latent function requires inverting the\nkernel matrix $K_{x_{1:N},X_{1:N};w}$ of N training data points $x_{1:N}$, resulting in a com-\nputational cost scaled to $O(N\u00b3)$. Introducing sparse inducing points $u$ is a\ncommon approximation strategy to mitigate this issue. Specifically, the ker-\nnel matrix $K_{z,z;w}$ over M inducing inputs $Z_{1:M}$ can be regarded as a low-rank\napproximation to the full kernel matrix $K_{x_{1:N},X_{1:0};w}$, reducing the computa-\ntional cost from $O(N\u00b3)$ to $O(NM\u00b2)$. Given inducing inputs $z$ and inducing\npoints $u$, in which $u$ is generated as $u \\sim N (v(z), K_{z,z;w})$, we can have the\napproximated random function value $f(.)$ following the Gaussian distribution\nas:\n$\\hat{f}(\\cdot)|w, u, z \\sim N(\\hat{f}(\\cdot); v(\\cdot) + K_{\\cdot,z;w}K_{z,z;w}^{-1}(U$\n$-v(z)), K_{\\cdot,\\cdot;w} - K_{\\cdot,z;w}K_{z,z;w}^{-1}K_{z,\\cdot;w}).$                                                                                                                               (D.1)"}, {"title": "Appendix E. Steps of the Inference", "content": "Step 1, Calculating $E_{q_{\\phi_c}(w_c)} [log p(t_c|w_c, z, m_c)]$. Since we model the inten-\nsity function of client c as $\\lambda_c(t) = m_c\\cdot\\sigma(f_c(t))$, the likelihood of the event $t_c$\ncan be approximated as:\n$p(t_c |w_c, z, m_c) \\approx \\int p(t_c|\\hat{f_c(\u00b7)}, m_c)p(\\hat{f_c(\u00b7)}|u_c, w_c, z)$\n$\\int \\int p(u|w, z)dud(\\hat{f_c(\u00b7)})$,                                                                                                                                    (E.1)\nin which $p(t_c|\\hat{f_c(\u00b7)}, m_c)$ can be written as:\n$p(t_c |\\hat{f_c(\u00b7)}, m_c) = exp(-\\int_0^T m_c\\sigma(\\hat{f_c(t)})dt) \\prod_{i=1}^{n_c} m_c\\sigma(\\hat{f_c(t_{c,i})})$.                                   (E.2)\nIn Eq. (E.1), we first augment the original likelihood $p(t_c|w, z, m_c)$ with\nrandom function $\\hat{f_c(\u00b7)}$ and inducing points $u_c$. The approximation (i) in\nEq. E.1 denotes that the distribution of random function $p(f_c)$ is approxi-\nmated by $P(\\hat{f_c})$, which is supported by the sparse inducing points $u_c$ (see\ndetails in Eq. (D.1))."}, {"title": "Appendix F. Details of Mean-field Variational Inference", "content": "Optimal Polya-Gamma Density $q(\\xi_{c,m})$.\n$log q(\\xi_{c,m}) = E_q [-\\frac{[f_c]^2(t_m)}{2}\\xi_{c,m}] + log \\Gamma(\\xi_{c,m}|1, 0) + const$                                           (F.1)"}, {"title": "Appendix G. Divergence", "content": "The proofs of the following propositions follow immediately.\nProposition 1. Given $x_1 \\sim N(x_1; \\mu_1, \\sigma_1^2)$, $x_2 \\sim N(x_2; \\mu_2, \\sigma_2^2)$ and for any\n$\\delta > 0$, we can obtain the following:\n$E_{x_1\\sim N(x_1;\\mu_1,\\sigma_1^2), x_2\\sim N(x_2;\\mu_2,\\sigma_2^2)} e^{-\\frac{(x_1-x_2)^2}{\\delta^2}} = \\delta \\cdot \\frac{e^{\\frac{-(\\mu_1-\\mu_2)^2}{\\delta^2+2\\sigma_1^2+2\\sigma_2^2}}}{\\sqrt{\\delta^2 + 2\\sigma_1^2 + 2\\sigma_2^2}}$                             (G.1)\nProposition 2. Given $N(\\mu_1, \\sigma_1^2), N(\\mu_2, \\sigma_2^2)$ and for any $\\delta > 0$, the maximum\nmean discrepancy (MMD) of the RBF kernel can be expressed as:\n$MMD(N(\\mu_1, \\sigma_1^2)||N(\\mu_2, \\sigma_2^2))$\n$=\\delta \\cdot \\frac{1}{\\sqrt{\\delta^2 + 4\\sigma_1^2}} + \\delta \\cdot \\frac{1}{\\sqrt{\\delta^2 + 4\\sigma_2^2}}$                   (G.2)\n$-2\\delta \\cdot \\frac{e^{\\frac{-(\\mu_1-\\mu_2)^2}{\\delta^2+2\\sigma_1^2+2\\sigma_2^2}}}{\\sqrt{\\delta^2 + 2\\sigma_1^2 + 2\\sigma_2^2}}$                                  (G.3)\nProposition 3. $\\sum_{c=1}^CMMD [q_{\\phi_c}(W_c)||p_{\\theta}(w_c)]$ reaches its minimum for $\\theta =$\n${\\mu,\\sigma^2}$ when $\\theta$ is valued at:\n$\\mu, \\sigma^2 := arg \\min_{\\mu,\\sigma^2} \\sum_{c=1}^C [\\frac{1}{\\sqrt{\\delta^2 + 4\\sigma^2}} - \\frac{e^{\\frac{-(r_c-\\mu)^2}{\\delta^2+2\\delta_c^2+2\\sigma^2}}}{\\sqrt{\\delta^2 + 2\\delta_c^2 + 2\\sigma^2}}]$                               (G.4)"}, {"title": "Appendix H. Algorithm", "content": "Algorithm 1 shows the training procedure of FedPP."}, {"title": "Appendix J. Additional Experiments", "content": ""}, {"title": "Appendix J.1. Visualisation for the synthetic data", "content": "We use the sparse SGCP to generate synthetic point process data, with\nthe following settings: $m_1 = m_c = 50, T = 1$. The RBP kernel hyper-\nparameters in client 1 and client 2 are: [1.5, 10], [2, 8]. The number of induc-\ning points is 50. Fig. J.3 displays the traceplots of fitted random functions\nagainst that of groundtruth functions for two clients. Overall, our FedPP\nsuccessfully captures almost all of the complex patterns presented in the\ngroundtruth functions. In the top row, where the random functions $f(t)$ are\ncompared, our fitted function closely aligns with the occurrences of events,\neven outperforming the groundtruth in certain places. For example, within\nthe [40,50] interval allocated with dense events, the groundtruth function\naccidentally underestimates these events, whereas our FedPP reflects higher\nvalues. In the bottom row, out fitted intensity function is consistently lower\nthan the groundtruth one, particularly during intervals with sparse events."}, {"title": "Appendix J.2. Main Results on Homogeneous Setting", "content": "Apart from the heterogeneous setting, the homogeneous setting where\nlocal data across clients are IID is also crucial for testing the effectiveness\nof federated models. In TPPs tasks, it is natural to construct homogeneous\ndata environments based on different types of events. In this experiment,\nwe evaluate our proposed approach as well as other baselines on each type\nof events of all datasets. To ensure the validity and fairness of the results,"}]}