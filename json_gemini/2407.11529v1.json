{"title": "Cross-Phase Mutual Learning Framework for Pulmonary Embolism Identification on Non-Contrast CT Scans", "authors": ["Bizhe Bai", "Yan-Jie Zhou", "Yujian Hu", "Tony C. W. Mok", "Yilang Xiang", "Le Lu", "Hongkun Zhang", "Minfeng Xu"], "abstract": "Pulmonary embolism (PE) is a life-threatening condition where rapid and accurate diagnosis is imperative yet difficult due to predominantly atypical symptomatology. Computed tomography pulmonary angiography (CTPA) is acknowledged as the gold standard imaging tool in clinics, yet it can be contraindicated for emergency department (ED) patients and represents an onerous procedure, thus necessitating PE identification through non-contrast CT (NCT) scans. In this work, we explore the feasibility of applying a deep-learning approach to NCT scans for PE identification. We propose a novel Cross-Phase Mutual learNing framework (CPMN) that fosters knowledge transfer from CTPA to NCT, while concurrently conducting embolism segmentation and abnormality classification in a multi-task manner. The proposed CPMN leverages the Inter-Feature Alignment (IFA) strategy that enhances spatial contiguity and mutual learning between the dual-pathway network, while the Intra-Feature Discrepancy (IFD) strategy can facilitate precise segmentation of PE against complex backgrounds for single-pathway networks. For a comprehensive assessment of the proposed approach, a large-scale dual-phase dataset containing 334 PE patients and 1,105 normal subjects has been established. Experimental results demonstrate that CPMN achieves the leading identification performance, which is 95.4% and 99.6% in patient-level sensitivity and specificity on NCT scans, indicating the potential of our approach as an economical, accessible, and precise tool for PE identification in clinical practice.", "sections": [{"title": "1 Introduction", "content": "Pulmonary embolism (PE) is a critical and potentially lethal pulmonary condition, which occupies the third position in severity, trailing only behind myocardial infarction and sudden cardiac death [18]. It typically arises from a thrombotic event within the deep venous network of the lower limbs, which subsequently embarks on a path through the bloodstream, advances to the cardiac region, and culminates in an obstruction within the pulmonary arterial network [8]. The predominant factor contributing to preventable mortality in PE cases is not a therapeutic shortfall, but rather the omission of accurate diagnosis [4].\nWithin the realm of PE diagnostic modalities, computed tomographic pulmonary angiography (CTPA) has emerged as the gold standard imaging tool, facilitating visualization of pulmonary filling defects through the utilization of contrast agents [1]. Unfortunately, certain patient populations within emergency departments (ED) are unable to easily undergo intravenous contrast-enhanced computed tomography scans, predominantly attributable to renal impairment or hypersensitivity to iodine-based contrast agents [17]. On the contrary, non-contrast computed tomography (NCT) can be performed within seconds and is an economical and accessible tool. Nevertheless, the assessment of NCT scans by radiologists lacks the requisite sensitivity and specificity to dependably diagnose PE [15]. Therefore, developing an automatic and accurate PE identification framework on NCT scans is of paramount importance.\nWith recent advances in deep learning, an increasing number of researchers have devoted efforts to developing automated algorithms for PE identification on CTPA scans [5,23,2]. Huang et al. [5] presented a 3D convolutional neural network (CNN) for PE identification by decoupling the issue as a classification task, yet it lacks the capability to furnish precise localization. Recently, Yuan et al. [23] proposed a ResD-UNet framework for pulmonary artery segmentation, which enhances accuracy and efficiency through the integration of the U-Net architecture with innovative residual-dense blocks and a composite loss function, thereby tackling the challenge in assessing the severity of PE. Chen et al. [2] introduced an automated segmentation approach for PE, termed SCUNet++, which integrates the strengths of UNet++, multiple fusion dense skip connections, the Swin-Transformer attention mechanism, and the Swin-UNet architecture. Conversely, the realm of PE identification on NCT scans remains comparatively underexplored [19]. Previous research [22] targeting the pancreas has demonstrated that deep learning methodologies are capable of discerning nuanced textural and morphological alterations in NCT scans, which may elude even the observation of human experts. However, the feasibility of PE identification through NCT scans is still an open question, primarily due to the low contrast differentiation between the embolism and surrounding pulmonary vessels on NCT scans, compounded by the diverse morphological presentations of embolisms, which intensify this identification challenge.\nTo tackle the aforementioned issues and leverage dual-phase knowledge, we propose a novel Cross-Phase Mutual learNing framework (CPMN) for PE identification on NCT scans. In this work, the identification task is decoupled into"}, {"title": "2 Methodology", "content": "Problem Formulation. In the training stage, given a set of pair-wise data, namely NCT and CTPA volume, the entire dataset is denoted by S = {(X_i, X'_i, Y_i, M_i) | i = 1, 2, ..., N}, where X_i and X'_i are the i-th NCT and CTPA volume, with Y_i being the voxel-wise segmentation label map of the same size as X_i and K channels. Here, K = 2 represents the background and embolism. M_i \u2208 {0,1} is the classification label of the image, where 0 stands for \"normal\" and 1 for \"PE\". In the testing stage, solely the NCT volume X' is provided, and the objective is to predict abnormality probability and generate an embolism mask.\nMutual Learning Framework. In this section, we present our mutual learning framework designed for dual-phase medical image analysis, leveraging CTPA and NCT volumes. Our approach enhances the performance and generalization of the NCT-pathway network through a novel mutual learning strategy (MLS).\nAs shown in Fig 1, our proposed mutual learning framework is designed to simultaneously train two CNNs with distinct tasks, classification, and segmentation. The CTPA-pathway network, denoted as \\Omega_1, is tasked with classification and segmenting PE in CTPA volumes. Conversely, the NCT-pathway network, \\Omega_2, operates on NCT volumes. We choose U-Net [14] 3D version with EfficientNet-B0 [16] 3D version as the encoder for segmentation task and add an auxiliary classifier \\Theta_{i,i\\in{1,2}} with architecture avg-pool \u2192 FC layer \u2192 Relu \u2192 FC layer, after encoder. The architecture is the same for both pathways.\nBoth networks are trained in parallel, as well as leveraging the MLS that fosters knowledge transfer from \\Omega_1 to \\Omega_2. This is achieved by minimizing a divergence loss that aligns the predictive distributions of the two networks. We follow [26] employ the Kullback-Leibler (KL) divergence as a measure of the discrepancy between the output logits of p_1 and p_2, formulated as:\nDKL(p_2||p_1) = \\sum_{i=1}^N \\sum_{m=0}^1 p_1^m(x_i) log \\frac{p_1^m(x_i)}{p_2^m(x_i)}, L_{KL} = D_{KL}(p_2||p_1) \\tag{1}\nwhere p_1 and p_2 represent softmax probabilities from two classification heads (\\Theta_1, \\Theta_2) given input X and X', respectively. By minimizing L_{KL}, we encourage \\Omega_2 to adapt its predicted classification distribution towards that of \\Omega_1.\nInter-Feature Alignment (IFA). In our mutual learning framework, akin to the pair-wise Markov random field approach for enhancing spatial labeling contiguity, we focus on similarity among spatial features from the CTPA-pathway network \\Omega_2 to the NCT-pathway network \\Omega_1. Inspired by [10], an affinity graph is built to encapsulate this relationship. This graph is parameterized by connection range \u03b1 and granularity \u03b2, optimizing the graph\u2019s resolution and the fidelity of spatial relations captured. The affinity graph, with W\u2019H\u2019 nodes and W\u2019H\u2019 \u00d7 \u03b1 connections, serve as a dynamic representation of spatial correlations, enhancing the mutual learning process between the networks \\Omega_1 and \\Omega_2.\nTo quantify the knowledge transfer between them and foster the mutual learning process, we introduce a pair-wise similarity distillation loss, integrating"}, {"title": null, "content": "the squared differences of pair-wise similarities with a similarity term to measure the alignment between the networks\u2019 feature map:\nL_{align} = \\frac{1}{\\beta} \\frac{1}{Z} \\sum_{i \\in R'} \\sum_{j \\in R', j \\neq i} (a_{ij}^{\\Omega_1} - a_{ij}^{\\Omega_2})^2, R' \\in {1, 2, 3, ..., \\frac{W' \\times H'}{\\beta}} \\tag{2}\nwhere Z = W' \u00d7 H' \u00d7 \u03b1 serves as a normalization factor and a_{ij}^{\\Omega_1} and a_{ij}^{\\Omega_2} denote the similarity between the i-th and j-th nodes computed by networks \\Omega_1 and \\Omega_2, respectively. And similarity between two nodes is computed from the aggregated features f_i and f_j as a_{ij} = \\frac{f_i \\cdot f_j}{|f_i|^2|f_j|^2}. In our implementation, we use average pooling to aggregate \u03b2 \u00d7 C features in one node to be 1 x C. In the training process, since we only want the features of NCT-pathway network \\Omega_2 getting closer to the CTPA pathway network \\Omega_1, only the parameters of the \\Omega_2 is updated through L_{align}.\nIntra-Feature Discrepancy (IFD). To enhance our segmentation model\u2019s capability to distinguish discriminative features between the background and the pulmonary embolism, we propose an IFD strategy that is based on designed dense center loss derived from center loss [21], traditionally used in classification tasks. In each training iteration, the centers are computed as the centroid features of the pixels belonging to the corresponding class in our segmentation mask. This modification to the center loss method, denoted as L_{disc}, is defined as follows:\nL_{disc} = \\frac{1}{2} \\sum_{k=0}^1 \\sum_{i=1}^{|C|} ||x_k - c_k||_2^2, \\frac{\\partial L_{disc}}{\\partial x_k} = x_k - c_k \\tag{3}\nwhere \ud835\udd40 is the indicator function, x_k is the feature of the k-th pixel belonging to class k, and c_k denotes the k-th class center of deep features. The update function for centers c_k is depicted as:\n\\triangle c_k = \\frac{\\sum_{j=1}^{|C|} \\mathbb{I}(x_j = c_k) (c_k - x_j)}{1 + \\sum_{j=1}^{|C|} \\mathbb{I}(x_j = c_k)} \\tag{4}\nThis approach enables our networks to effectively learn compact and separate clusters in the feature space for each class, a critical aspect of segmentation.\nLearning and Optimization. The total loss L_{Total} of CPMN is defined as:\nL_{Total} = L_{clas} + L_{seg} + \\lambda_1 L_{KL} + \\lambda_2 L_{align} + \\lambda_3 L_{disc} \\tag{5}\nwhere \u03bb1, \u03bb2, and \u03bb3 are set to 0.25, 10, and 0.1, making these loss value ranges comparable. The classification loss L_{clas} is binary cross-entropy loss, and the segmentation loss L_{seg} is optimized through focal loss [9] to address the class imbalance ratio between the pulmonary embolism area and the background."}, {"title": "3 Experiment", "content": "3.1 Datasets\nIn-House Dataset: We establish a large-scale dual-phase dataset (ALD-PE) containing 334 PE patients and 1,105 normal subjects from a cooperative hospital between the years 2019 and 2022. Each case encompasses a CTPA scan in conjunction with the corresponding NCT phase. We use the latest patients in 2022 as a hold-out test set, resulting in a training set of 269 PE patients and 881 normal subjects, and a test set of 65 PE patients and 224 normal subjects. We randomly selected 20% of the training data as an internal validation set. LapIRN [13] is employed to register the CTPA phase to the NCT phase, and then invite an experienced radiologist to annotate labels on the CTPA phase using CTLabeler [20]. The segmentation mask and the class label are annotated based on radiology reports and clinical records. Public Benchmark: The FUMPE dataset [12] is one of the largest publicly available datasets in this field containing 8,792 CTPA images obtained from 35 patients. The partitioning of the training and test datasets aligns with the methodology delineated in prior research [2].\n3.2 Implementation Details\nWe developed our segmentation models using PyTorch, with experiments conducted on two NVIDIA A100 GPUs. We set the training batch size to 6, with transformations including random flips and rotations with 10% probabilities, spatial padding, and random cropping to a uniform size of 224 \u00d7 224 \u00d7 96. During the inference stage, we use sliding-window inference with patch size 224\u00d7224\u00d796, and the center patch is cropped with the same size as the input for the classification head. The Adam [7] optimizer, with a learning rate of 0.001, is paired with a Cosine Annealing learning [11] rate scheduler that strategically modulates the learning rate over the training epochs, with the minimum rate set at 1 \u00d7 10-5.\n3.3 Evaluation Metrics and Reader Study\nFor the binary classification task, model performance is evaluated using the area under the Receiver Operating Characteristic curve (AUC), sensitivity (Sens.), and specificity (Spec.). For the segmentation task, the dice coefficient is utilized to assess model performance. A reader study was carried out involving three radiologists in cardiopulmonary imaging: an expert radiologist (12 years experience), a senior radiologist (8 years experience), and a junior radiologist (3 years experience). The readers were given 289 non-contrast CT scans from the test set and asked to provide a binary decision for each scan, determining the presence or absence of PE. They conducted their evaluations without access to any patient information or medical records. Additionally, readers were apprised that the dataset could exhibit a higher incidence of PE cases compared to the typical prevalence encountered in routine screenings, but the exact distribution of case types was not revealed to them. Utilizing the ITK-SNAP software [25], the radiologists interpreted the CT scans, free from any time limitations."}, {"title": "3.4 Results", "content": "Ablation Study. To verify the contribution of each component, the ablation study is carried out, and the results are reported in Table 1. As for single-phase, our baseline model achieves 96.9%, 99.6%, 0.996, and 79.9% in patient-level sensitivity, specificity, AUC, and segmentation dice on CTPA scans, while realizing 84.6%, 97.8%, 0.973, and 68.8% on NCT scans. In the context of dual-phase analysis, our attention is exclusively dedicated to quantifying the performance enhancement conferred by each component on NCT scans. (1) MLS: The results demonstrate that the introduced MLS yields 7.7% and 1.3% improvement in sensitivity and specificity, which proves that MLS can synergy the strengths of both phases to enhance predictive performance on NCT scans. (2) IFA: Quantitative results show that the presented IFA strategy increases the segmentation dice from 70.1% to 75.7% while maintaining the classification performance, which indicates the effectiveness of the IFA strategy by constraint of pair-wise spatial feature similarities. (3) IFD: The results show that the designed IFD strategy can further improve the segmentation dice to 78.5%. Concurrently, there is a notable enhancement in patient-level sensitivity by 3.1%, culminating at 95.4%. It proves the importance of the designed IFD strategy.\nComparison with Literature. To evaluate the effectiveness of our proposed CPMN, we conduct a comparison with various state-of-the-art methods on two different datasets. (1) ALD-PE: Table 2 presents a comparative analysis of our proposed CPMN with four baselines. The first baseline is DML [26] based on mutual learning. The other three baselines (denoted as \"-Joint\") integrate a CNN classification head into each network and are trained in an end-to-end manner. Quantitative results show that our proposed CPMN achieves the leading classification and segmentation performance, particularly in sensitivity and segmentation dice. Qualitative results, as shown in Fig. 2(b), demonstrate that CPMN achieves more robust segmentation results. (2) FUMPE: We assess the efficacy of our training framework for segmentation tasks on single-phase data.To conduct this evaluation, we modify the CTPA-pathway network by removing the auxiliary classification head and using the 2D-EfficientNet-B0 and 2D-U-Net architecture. All other components of the CTPA-pathway network remain unchanged. This approach achieves a dice coefficient of 77.4%, surpassing the performance of a recent dedicated model (ResD-UNet [24]) tailored for PE identification, which achieves 76.5%. The results demonstrate that our introduced single-pathway network is robust and effective. More importantly, the comparison results further substantiate that the advancements in identification on NCT scans are not solely due to the choice of a powerful backbone but rather the effectiveness of the proposed CPMN itself.\nComparison with Radiologists. As shown in Fig. 2(a), our proposed CPMN's ROC curve is superior to the performance of three radiologists. The model achieves a patient-level sensitivity of 95.4% in PE identification, which significantly exceeds that of radiologists (18.5%, 43.1%, and 53.8%) while maintaining a high specificity of 99.6%. A visual example is presented in Fig. 2(b), which is miss-detected by three radiologists, whereas classified and localized precisely by CPMN. More importantly, the extra information about predicted embolism masks and CAM [27] generated from the classification head improve the interpretability of identification."}, {"title": "4 Conclusion", "content": "In this work, a novel Cross-Phase Mutual learNing framework (CPMN) has been proposed to facilitate knowledge transfer from CTPA to NCT, thereby enhancing performance for PE identification on NCT scans. Additionally, the framework provides outputs of CAM and embolism masks for improved clinical interpretability. The comprehensive evaluation demonstrates that our approach outperforms strong baselines and experienced radiologists, highlighting the potential of our approach as a robust and precise tool for PE identification in real clinical environments."}]}