{"title": "Large Language Models can impersonate\npoliticians and other public figures", "authors": ["Steffen Herbold", "Alexander Trautsch", "Zlata Kikteva", "Annette Hautli-Janisz"], "abstract": "Modern AI technology like Large language models (LLMs) has the potential to\npollute the public information sphere with made-up content, which poses a sig-\nnificant threat to the cohesion of societies at large. A wide range of research has\nshown that LLMs are capable of generating text of impressive quality, includ-\ning persuasive political speech, text with a pre-defined style, and role-specific\ncontent. But there is a crucial gap in the literature: We lack large-scale and\nsystematic studies of how capable LLMs are in impersonating political and so-\ncietal representatives and how the general public judges these impersonations\nin terms of authenticity, relevance and coherence. We present the results of\na study based on a cross-section of British society that shows that LLMs are\nable to generate responses to debate questions that were part of a broadcast\npolitical debate programme in the UK. The impersonated responses are judged\nto be more authentic and relevant than the original responses given by people\nwho were impersonated. This shows two things: (1) LLMs can be made to con-\ntribute meaningfully to the public political debate and (2) there is a dire need\nto inform the general public of the potential harm this can have on society.", "sections": [{"title": "Introduction", "content": "Modern Artificial Intelligence (AI) like ChatGPT,\u00b9 Claude, \u00b2 and Gemini\u00b3 is\nable to support humanity by generating high-quality textual content including\nsource code, persuasive student essays,5 and legal analysis.6 More questionable\nin terms of advancement is the fact that LLMs seem (at least partly) to be able\nto mimic the linguistic pattern of authors, to generate content that reflects gen-\neral political identity8, 9 and to assume the role of domain experts and answering\nas if they are in the role of an (unspecified) person from that domain. 10 Down-\nright questionable in terms of whether this technology advances humankind and\npromotes societal cohesion is the fact that LLMs are able to influence the po-\nlitical opinion of humans, 11 purport political bias12 and successfully generate\ntargeted persuasive communication.13,14 Yet another step towards poisoning\nthe processes that shape public opinion is developing technology that can be\nused to impersonate public figures and elected political representatives. This is\nthe starting point of the present paper.\nIn our study, we condition an LLM in such a way that it impersonates a\nspecific figure in the political and societal sphere in the UK. We then request\nfrom it a response to a question that the actual person has been confronted\nwith in a debate on national television. Based on a representative cross-section\nof British society (n=948), we study how UK citizens rate the actual response\nof the person in comparison to the impersonated response along three axes:\nauthenticity (the likelihood that the impersonated response comes from the\nactual person), coherence (the logical flow of the response), and relevance (the\nextent to which the response is relevant to the question). We also elicit the\ncitizens' openness to using AI technology in public debates, both before and\nafter engaging with the data of the study. This allows us to address two research\nquestions:\nRQ1: To what extent do UK citizens rate the authenticity, relevance, and\ncoherence of impersonated debate responses differently from actual debate\nresponses by the person?\nRQ2: What is the general public's view on using AI in public debates and is\nthis view affected by exposure to technology?\nThe questions and responses underlying our study originate from thirty\nepisodes of BBC's Question Time from 2020 to 2022,15 one of the most viewed\npolitical debate programmes in the UK. The public figures in the dataset belong\nto one of six categories: politicians (50%), business people (16.67%), journal-\nists (14.17%), medical experts (6.67%), writers (5.83%), and other well-known\nmembers of society (activists, actors, political expert and sports personality\n6.67%). The survey participants are asked to (i) attribute both actual and im-\npersonated response to public persons; (ii) evaluate how coherent and relevant\nboth actual and impersonated responses are; and (iii) express their opinion re-\ngarding the use of AI in public debates. The last task is split into subtasks:\nFirst, the participants give their opinions of AI unaware of the source of the\nmaterial they just rated (actual vs. impersonated), then they are shown the\nsource and they express their opinion on the technology again."}, {"title": "Results", "content": "Impersonation is credible\nOur results show clearly that LLM-generated, impersonated content is judged as\nmore authentic, coherent, and relevant than the actual debate responses. When"}, {"title": "Content is different", "content": "A factor that should influence the participants' judgments of the authenticity of\nan impersonated response is its similarity in content to the actual response. If\nthe content is different, i.e., the impersonated content is not in line with actual\nstatements of the person, and authenticity is still rated high, we are faced with\nthe situation where AI technology can used for targeted misinformation about\nthe speaker's point of view. Our results show that a significant majority of actual\nresponses is judged to be different in content to the impersonated counterpart,\nthough the spread in the distribution is fairly large (see Figure 4). About half\nof the responses are considered to be dissimilar, in comparison to only about\none third of the responses that are considered similar. Moreover, we observe\nno notable pattern or correlation between the similarity of the content and the\nauthenticity of the responses (p = \u22120.16)."}, {"title": "Linguistic structure is different", "content": "To provide a perspective different from the human evaluation, we augment our\nresults with an analysis of the linguistic surface of the responses (see Figure 5).\nThis computational linguistic analysis, which is largely comparable to a previous\napproach of measuring the linguistic properties of LLM-generated text, sheds\nlight on a number of aspects: First, the complexity of the sentences in terms of\nthe number of conjuncts, clausal modifiers, clausal complements, clausal sub-\njects and parataxes as well as the use of modals such as 'should' and 'must' are\nnot significantly different between the actual responses and the impersonated\nones. Secondly, the actual responses contain more discourse markers (e.g., \u2018be-\ncause', 'therefore') than the impersonated responses, even though with a small\neffect size (d = -0.36). The reason for the statistically significant difference is\nthat there is a long tail of actual responses that contain many discourse markers,\neven though the peak of the distributions is the same for actual and imperson-\nated responses. Moreover, the actual speakers use substantially more epistemic\nmarkers like 'I think' in their responses - these expressions are only rarely found\nin the impersonated statements, leading to a large effect size (d = -1.05).\nThirdly, the impersonated responses contain more nominalizations (d = 1.39)\nand have a higher lexical diversity (d = 1.67), both with a large effect size. The\noverlap between the words from the question and the response is higher for im-\npersonated responses than actual responses, with a large effect size (d = 1.81).\nIn fact, the distribution shows that it is not uncommon that all words from the\nquestion appear in the impersonated responses, while this is only rarely so for\nthe actual responses."}, {"title": "Human judgement is reliable", "content": "We use five-point Likert scales for the human judgments. In all variables, we\nobserve an overall modest agreement when measured with Cronbach's \u03b1, with\nvalues of at most \u03b1 = 0.55. We analysed the data to understand which combina-\ntion of different judgments we observed. Most notably, the data of the authen-\nticity for all variants of the question shows that while there are differences in the\njudgments, there are relatively few polar differences, i.e., one participant rating\nan item as authentic and the other as not authentic. For relevance, coherence\nand content the differences are rather in how positive a judgment is with small\ndifferences of a single point (e.g., 'neutral' instead of 'agreement'), again show-\ning that while the absolute ratings have some variance, the tendency regarding\nthe judgment is typically the same for both participants. Overall, the tendency\ntowards positive or negative judgements about a variable is fairly consistent,\nespecially given our large sample size which is a representative cross-cut of the\nBritish society."}, {"title": "Public opinion", "content": "Public opinion on the use of AI technology for public debates was assessed in two\nsteps: First, the participants gave their judgements without knowing the source\nof the data they had just rated in either task (i) or (ii), in the second step the\nsource of the data was revealed and they were asked the same questions on AI\ntechnology again. Regarding the first step (see Figure 6) The results of our exit\npoll prior to revealing the use of AI paints a clear picture of the public opinion\non the use of AI in public debates (see Figure 6). The participants mostly state\nthat they are familiar with AI. Interestingly, while they mostly believe that AI\ncannot provide valuable contributions to public debates, they simultaneously\nstate that they support the use of AI use, nevertheless, if it is made explicit\nand it is known how the system was developed. However, regarding a general\nregulation of AI, the participants provide a rather mixed picture, where there are\nroughly equal-sized groups favoring regulation, opposing regulation, and being\nundecided. Over 90% of the participants did not change these opinions once we\nrevealed the use of AI and asked if this affects their point of view. For those who\nchanged their opinion, we found a clear trend: the participants realize they are\nless familiar with AI than they thought, but also have a better opinion on the\nuse of AI in debates, while at the same time seeing a bigger need for regulation.\nThe optional free-text answers (n = 248) further corroborate these results.\nMany participants explicitly note that they did not change their results (n =\n107). However, the other free-text answers indicate that the changes in opinion\nare caused by the confrontation with the capabilities of AI through the survey.\nParticipants often mention that the impersonated responses are better than the\nhuman responses (n = 66) or that the quality of the impersonated responses\nis higher (n = 32). A few participants noted that the high coherence in the\nimpersonated responses made them sceptic towards AI use in the survey (n = 7)\nand also that this advantage over the humans can be explained by the setting,\nwhere the humans do not have time to carefully prepare their responses (n = 5).\nOne participant even notes that this advantage of AI means that AI could be\nused to train humans for debates. Nevertheless, many also note that they are\nnot able to distinguish between AI and humans at all (n = 26). There are also\na few comments noting negative aspects of the AI quality (n = 4) or that AI\nwas worse than the humans (n = 1), but these are rather outliers.\nAnother aspect that is stressed in the comments is the requirement to regu-\nlate the use of AI (n = 62), especially with respect to transparency: particularly\nthe potential of deceptive use and the associated risks worry many participants\n(n = 39), some even note feelings of fear, shock, and worry (n = 17). However,\nsome participants also express positive emotions like surprise and amazement\ngiven the strong capabilities of the AI (n = 16). When it comes to the use in\ndebates, some participants argue that the good performance shows a potential\nfor use in debates (n = 36), while others rather question the general concept\nAI debaters (n = 23), for instance people question how AI can represent party\nopinions at all or what the actual worth of debate is without humans."}, {"title": "Discussion", "content": "Our results demonstrate that modern AI based on LLMs is able to provide\nhigh-quality impersonated debate content that is deemed authentic\nwhen attributed to actual people. We also find indications that people rate\nthe impersonated content to be slightly more authentic than the actual human\ndebate responses. There does not seem to be a problem with an uncanny val-\nlley16 which makes humans feel uncomfortable with the impersonated answers.\nIn addition, the impersonated responses are deemed more coherent and rele-\nvant than actual responses. While the lower coherence can be attributed to\nthe humans being under scrutiny in a nationally broadcast TV politcal debate\nprogramme, the higher relevance of the LLM-generated responses indicates that\nthe LLM stays better on-topic than the human speakers.\nInterestingly, we found that the authenticity is not negatively affected by\nthe notable differences in the linguistic surface of the responses. The LLMs\nclearly had their own unique style marked marked by a diverse vocabulary\nand an avoidance of epistemic markers, but this was not picked up on by our\nparticipants.\nEven though most of our participants stated that they are familiar\nwith AI, they did not expect that AI could have generated these\nanswers and underestimated the capabilities of modern generative\nAI. When the participants were confronted with the strong capabilities of the\nAI, this elicited different responses: evidence-driven discussions of the merits of\nAI, including how to use it; negative emotional responses due to potential for\nmisuse; and positive emotional responses due to the technological capabilities.\nThis knowledge increases the appreciation for the capabilities of AI, but also\nthe desire for regulation.\nWhen asked on the merits of AI, there is a clear belief that AI can be a valu-\nable tool. There is no clear picture from the participants when asking for strong\nregulation and restrictions of use. However, when it comes to transparency,\nthe public perspective is clear: over 85% of participants think that AI\nuse has to be made explicit and that information on how the AI was\ndeveloped needs to be shared.\nThe risks that are implied by our results are severe. We already know that\nLLMs are capable of generating persuasive misinformation\u00b97 and that the auto-\nmated and human detection of such misinformation is unreliable. 18 Our work\nadds another layer on top of this: We demonstrate that LLMs can generate\nauthentic information by impersonating specific people, meaning that LLM-\npowered misinformation campaigns can go beyond targeting general topics and\ntarget individual people by impersonating statements they contribute to the\npublic discourse. Since the dissemination of excerpts from political statements\nvia social networks is a common form of political communication, 19 it is easy\nto spread such generated statements. We have not yet tested how this works\nwhen we not only generate responses, but responses that push a specific political\nagenda. Content moderation to remove false generated statement is crucial. 20\nOur own preliminary work suggests that a current model21 can be used for such"}, {"title": "Methods", "content": "We hypothesize that modern LLMs are capable of generating political speech\nthat is considered authentic for specific public persons, based on prior work that\nshows that political content can be generated, 11 linguistic styles imitated, and\nroles assumed.10 We measure this phenomenon based on the extraction of ques-\ntion/response pairs from a public debate corpus, the generation of new debate\nresponses for these questions with a LLM, a survey on the human judgment of\ndebate responses to measure the differences between the actual and imperson-\nated responses, and an assessment of the linguistic surface of the impersonated\nresponses.\nReal debate data\nThe actual questions and responses are take from QT30,15 currently the largest\ndataset of broadcast political debate. The corpus comprises the transcriptions\nof 30 episodes of the British talk show \u2018Question Time' (QT) between June 2020\nand November 2021. QT features a moderated panel format, driven by questions\nfrom the audience on the current topics of the week. The panelists are directed\nby the moderator to respond to the questions independent of a prior conversa-\ntion on the topic and the initial statements by other panellists. We manually\nextract these questions and responses from the corpus and have a total of 119\nunique questions with 555 responses from 119 different speakers. We discard\nthe responses of seven speakers who did not have a Wikipedia page, which is\nrequirement to generate debate responses (see below) and at the same serves\nas filter regarding whether the speakers are actually personalities in the public\nsphere. We also discard one response where the corpus data did not contain\ninformation about the speaker. This yields a set of 527 valid question/response\npairs from 112 different speakers. We randomly drop seven responses to achieve\na final count of 520 question/response pairs, because we require a sample size\nthat is dividable by eight to get paired from participants that each judge eight\nquestion/response pairs."}, {"title": "Impersonated debate content", "content": "We use a complex emulation protocol to impersonate people similar to Bhan-\ndarkar et al.7 with the following prompts:\n\u2022 System prompt: You are an expert at mimicking different persons\nin debates. You will be given information about a person and\na question and your task is to answer the question mimicking the\nperson. You only answer as the person you are asked to mimic.\nDo not say the name of the person you are mimicking. Don't introduce\nyourself. Only respond with the answer as the person you are\nmimicking in about 200 words in a conversational tone.\n\u2022 User prompt: Please only answer this question: [QUESTION] as\nthis person: [SPEAKER_WIKIPEDIA). Remember to only answer the\nquestion, without giving additional information, as the person\ngiven without saying the person's name and to only respond mimicking\nthe given person.\nThe system prompt defines the behaviour we expect from the model, i.e.,\nmimicking persons to impersonate them and to briefly answer questions in a\nconversational tone an introduction, as is common during debates. The user\nprompt starts with the task, then provides the question and a short biography\nof the speaker we obtain from the first paragraph of their Wikipedia article,\nas this paragraph provides a summary of information on their origin, party\naffiliation, political offices and so on. The user prompt then repeats the task to\nprompt the model to give the response in the expected format, followed by a\nmanual sanity check to ensure that the impersonated responses are appropriate,\ni.e., do not contain the name of the speaker or information that the response\nwas generated by a LLM, or a reason why no response was possible, e.g., due\nto lack of access to real-time data or for ethical reasons. This check did not\nflag problematic content, meaning that the LLM is able to generate appropriate\nresponses for all debate questions. These we use in the subsequent study.\nAs LLM, we used ChatGPT 4 Turbo.\u00b9 While more recent models, e.g., Opus\nClaude2 seem to be slightly better at logical tasks like mathematics, we are not\naware of any benchmark where ChatGPT was significantly outscored in tasks\nthat involve common knowledge like HellaSwag. 24"}, {"title": "Variables", "content": "To assess the actual and impersonated debate content, we measure the following\nvariables:\n\u2022 Authenticity: The likelihood that the response is an actual contribution\nby the speaker in a debate. This variable measures the core aspect of our\nstudy, i.e., if people believe that a statement is genuine.\n\u2022 Coherence: The logical flow of the response. This variable measures the\ninternal reasoning structure of responses."}, {"title": "Survey design", "content": "We measure these variables using a survey. The survey starts with the collection\nof demographic data about the participants, i.e., their age, gender, country of\nresidence within the United Kingdom, and political preference. At this time,\nthe participants are only informed that the debate questions and responses are\nfrom the BBC show QT, but not that some responses were generated by a LLM,\ni.e., we use a deceptive design that rather makes participants believe they only\njudge actual debate content. Afterwards, the participants are randomly sorted\ninto three tracks, such that we end up with two judgments for every data point.\nEach track provides a different perspective on the relationship between actual\nand impersonated responses.\nThe goal of the first track is to collect data regarding the judgment of the\nauthenticity, coherence, and relevance of debate responses when only a single\nresponse is shown. The participants are shown a question, a response, and the\nname of the speaker. The response is either the actual response by the speaker\nor a response we generated with an LLM, as described above.\nThe second track augments this setting that the actual and impersonated\nresponses are shown side-by-side: the participants see a question, the name\nof the speaker and both responses at the same time. Their task is to compare\nthem with each other: which is more authentic, coherent, and relevant. Whether\nthe actual and impersonated response is shown on the left side is randomized.\nAdditionally, we use this comparative assessment to collect data on whether the\ncontent of the impersonated responses is the same as of the actual responses.\nThe third track helps us understand different factors that could explain\ndifferences in authenticity. For this, the participants are shown a question, a\nresponse, the name of the speaker, and the short biography of the speaker.\nThe biography is the same that we provide to the LLM as part of the user\nprompt. There are three populations for the statistical analysis in this track."}, {"title": "Qualitative analysis", "content": "We use inductive coding25 and have one author assign one or more codes to\nthe free-text answers from the survey. The codes are aimed to capture the\nintent of the free-text answer, e.g., convey reason for changes in the exit poll, or\nobservations regarding the impersonated content the participants found striking.\nThis is initially done for twenty of the answers, at which point the coding is\nchecked by and discussed with a second author, resulting in an agreed-upon\ncoding strategy. The first author then continues to code the remainder of the\ndata. Upon completion of this coding, the second author again checks all codes\nand discusses the coding to achieve agreement in the same manner as for the\ninitial set of codes. We then conduct one round of axial coding 26 to group related\ncodes into categories. Same as above, the axial coding is initially conducted by\none author, then checked by and discussed with a second author to achieve\nagreement."}, {"title": "Survey participants", "content": "Since the debate content we study originates from a popular British topical\ndebate program, we recruited a representative sample of British citizens above\nthe age of 18. We used Prolific for this recruitment and participants received\na participation fee for compensation. Participants were informed about the\npurpose of the study and consent for participation was obtained. We recruited\na total of 948 participants who were split up randomly into the three tracks so\nthat we have at least two judgments for each of the 520 question/response pairs\n(actual responses, impersonated responses, and actual responses with random\nspeakers)."}, {"title": "Linguistic structure", "content": "We also analyse the impersonation from a linguistic perspective by comparing\ndiscourse-related linguistic markers measured on the actual and impersonated\nresponses. This allows us (1) to understand if the responses share properties\nin the linguistic surface and (2) whether the language is related to the human\njudgements in terms of authenticity, relevance and coherence. To this end, we\nmeasure the following linguistic structures.\n\u2022 Syntactic complexity: Syntactic complexity in terms of the mean number\nof conjuncts, clausal modifiers of nouns, adverbial clause modifier, clausal\ncomplements, clausal subjects and parataxis per sentence is a useful tool\nto understand the complexity of the language.27\n\u2022 Modals: The number of modal constructions (e.g., 'definitely', 'poten-\ntially') per sentence signals the stance of the speaker towards the utter-\nance.\n\u2022 Nominalizations: The number of nominalizations per sentence is associ-\nated with the complexity of the language. 28\n\u2022 Discourse markers: The number of discourse markers (e.g. first, more-\nover) per sentence is associated with the coherence of texts and the use of\nclear argumentation structure. 29\n\u2022 Epistemic markers: The number of epistemic markers (e.g., 'I think', 'in\nmy opinion') indicates a commitment of the speaker to the message they\nconvey.\n\u2022 Lexical diversity: The lexical diversity measured with MTLD gives us a\nperspective on how the diverse the used vocabulary is. 30\n\u2022 Lexical overlap: For lexical overlap between the question and the response\nwe measure the percentage of words from the question (excluding stop\nwords) that also appear in the response. This provides us with an approx-\nimation regarding the influence of the question on the response."}, {"title": "Statistical analysis", "content": "We measure the inter-rater reliability with Cronbach's \u03b131 between the two\njudgments for authenticity, coherence, relevance, and content. Additionally,\nwe report the pair-wise differences between the two participants to understand\nwhich disagreements our participants have. We exclude confidence and famil-\niarity because we cannot expect agreement regarding a subjective self-reflection.\nFor the subsequent statistical analysis, we map the Likert scales to the integers\n[-2, -1, 0, 1, 2] and compute the average rating between the two judgments for\nthe same data point. Since the variables from our survey are based on Likert\nscales, we use non-parametric rank-based statistical tests.\nFor the first track, we assess the difference in the variables authenticity,\ncoherence, and relevance between the actual responses and the impersonated\nresponses. The track has a between-subjects design (i.e., different participants\njudge the actual and impersonated responses) with data that is paired by the\nquestion and the speaker. Consequently, we use a two-sided Wilcoxon signed\nrank test32 to determine if the difference between both populations is significant.\nFor the second track, we post-process the data such that the actual response\nis always on the left and the impersonated response is always on the right. The\ntrack uses a within-subjects design (i.e., a participant judges both the actual\nand impersonated response). We conduct a two-sided one-sample Wilcoxon\nsigned rank test to determine if the judgments regarding authenticity, coherence,\nrelevance, and content are significantly different from zero. For authenticity,\ncoherence, and relevance, a significant tendency towards negative values means\nthat the participants favour the actual responses, a significant tendency towards\npositive values means that the generated, impersonated responses are favoured.\nFor the content, a significant positive value means that the contents are similar,\na negative value means that the impersonated content is different from the\nactual content by the speaker.\nWith the data for the third track, we assess if the authenticity and confi-\ndence depend on whether the speaker is real, random, or impersonated, i.e.,\nwe have three populations. The track has a between-subjects design where\nthe populations are paired by the question and the actual speaker. We use a\nFriedman test33 to test if there is any difference between the three populations\nwith a Bonferroni-Dunn post-hoc test based on pair-wise two-sided Wilcoxon\nsigned rank tests to determine which differences between pairs are significant.\nAdditionally, we use the familiarity judgments to understand how this affects\nthe authenticity. For this, we conduct a subgroup analysis where we split the\nratings into those where the familiarity is less than 0 (i.e., ratings where the par-\nticipants are not at least fairly familiar with the speaker) and judgments with\na familiarity greater than or equal to 0. For the latter subgroup we do not have\npaired data anymore. The reason for this is that we have independent raters\nfor the three populations. For instance, the raters for the responses attribute\nto the actual speakers may be familiar with different speakers than the raters\nfor the impersonated responses, leading to different subgroups. Consequently,\nwe use a Kruskal-Wallis test34 with Bonferroni-Dunn post-hoc tests based on"}, {"title": "Author information", "content": "Contributions\nS.H. and A.HJ. provided the initial idea for the study. All authors contributed\nto the design of the survey. A.T implemented and ran the survey, as well as\nengineering a suitable prompt to generate debate responses. Z.K. implemented\nanalysis of the linguistic surface and conducted the initial round of inductive\ncoding for the free-text answers and checked the outcome of the axial coding\nof categories. S.H. designed and implemented the statistical analysis, checked\nthe results of the inductive coding and performed the axial coding of categories.\nS.H. wrote the main text, the methods, and the supplementary information. All\nauthors gave critical feedback on the main text and the methods.\nCorresponding author\nCorrespondence to Steffen Herbold."}, {"title": "Ethics declarations", "content": "Competing interests\nThe authors declare no competing interests.\nData availability\nThe datasets generated during and/or analysed during the current study are\navailable online at https://github.com/aieng-lab/replication-kit-qtgpt-study\nand https://doi.org/10.5281/zenodo.12698364.\nCode availability\nAll materials are available online in form of a replication package that contains\nthe data and the analysis code at https://github.com/aieng-lab/replication-kit-qtgpt-study\nand https://doi.org/10.5281/zenodo. 12698364."}, {"title": "Extended data", "content": null}]}