{"title": "Evaluating Open-Source Sparse Autoencoders on Disentangling Factual Knowledge in GPT-2 Small", "authors": ["Maheep Chaudhary", "Atticus Geiger"], "abstract": "A popular new method in mechanistic interpretability is to train high-dimensional sparse autoencoders (SAEs) on neuron activations and use SAE features as the atomic units of analysis. However, the body of evidence on whether SAE feature spaces are useful for causal analysis is underdeveloped. In this work, we use the RAVEL benchmark to evaluate whether SAEs trained on hidden representations of GPT-2 small have sets of features that separately mediate knowledge of which country a city is in and which continent it is in. We evaluate four open-source SAEs for GPT-2 small against each other, with neurons serving as a baseline, and linear features learned via distributed alignment search (DAS) serving as a skyline. For each, we learn a binary mask to select features that will be patched to change the country of a city without changing the continent, or vice versa. Our results show that SAEs struggle to reach the neuron baseline, and none come close to the DAS skyline. We release code here: github.com/MaheepChaudhary/SAE-Ravel", "sections": [{"title": "1 Introduction", "content": "Individual neurons in neural networks represent many concepts, and individual concepts are represented by many neurons (Smolensky, 1988; McClelland et al., 1986a,b; Olah et al., 2020; Cammarata et al., 2020; Bolukbasi et al., 2021; Gurnee et al., 2023). What, if not neurons, are the relevant meaning-bearing components of neural networks? This is a fundamental question in mechanistic interpretability. A recent, and increasingly popular, unsupervised method for learning features that correspond to intuitive concepts is to train high-dimensional sparse autoencoders (SAEs) on the hidden representations of deep learning models across a wide range of possible inputs (Bricken et al., 2023; Cunningham et al., 2023; Lieberum et al., 2024; Gao et al., 2024). The encoder of an SAE unpacks neurons into a higher dimensional space with sparse linear features that are intended to be better units of analysis.\nHowever, researchers have invested more into scaling SAEs, than evaluating them (Templeton et al., 2024). In particular, only a handful of works engage with whether SAEs are useful for a causal interpretability analysis (Marks et al., 2024; Engels et al., 2024; Makelov et al., 2024). In this paper, we add to the body of evidence an example of when sparse autoencoders fail to provide a better feature space than neurons for finding model-internal mediators of concepts (Geiger et al., 2024a; Mueller et al., 2024). Specifically, we use the RAVEL benchmark (Huang et al., 2024) to evaluate whether the there are sets of SAE features that separately mediate knowledge of which country a city is in and which continent a city is in. We evaluate four publicly available SAEs for GPT-2 small: the Open AI SAE (Gao et al., 2024), two Apollo SAEs (Braun et al., 2024), and the Bloom SAE (Bloom, 2024). As a feature baseline, we use neurons; as a feature skyline, we use linear subspaces trained with distributed alignment search (DAS; Geiger et al. 2024b) to disentangle the country knowledge from the continent knowledge.\nFor each feature space, we train a differentiable binary mask to select features that encode the country of a city, but not the continent, and vice versa. We evaluate the selected features using interchange interventions, where features are fixed to values they would take if a different input were provided. For example, if we fix the 'country' features for the prompt Paris is a city in the country and set them to the value they take for the prompt Tokyo is a city in, the output should be Japan not France. If we instead target the 'continent' features, the output should be Europe not Asia.\nIn Figure 1 we show that all SAEs struggle to compete with the neuron baseline and degrade the model's knowledge. However, the DAS skyline sets a high ceiling and there is room to improve."}, {"title": "2 Related Work", "content": "Benchmarking SAEs There are many aspects of SAEs to benchmark. To what degree do the features respond precisely and accurately to the natural language labels given to them by auto-interpretability methods (Hernandez et al., 2022; Huang et al., 2023; Schwettmann et al., 2023; Bills et al., 2023; Shaham et al., 2024)? Can we do circuit discovery (Marks et al., 2024; Makelov et al., 2024), representation analysis (Engels et al., 2024), or activation steering (Templeton et al., 2024) in SAE feature space? Our question is whether SAEs provide a better feature space than neurons for localizing the concepts used by deep learning models.\nInterpretability of Knowledge Representations The RAVEL benchmark belongs to a line of research concerned with how factual knowledge is stored within a language model (Geva et al., 2021; Meng et al., 2022; Dai et al., 2022; Meng et al., 2023; Hernandez et al., 2023; Geva et al., 2023). In this paper, we are concerned with how factual knowledge is stored and processed in hidden vector representations during model inference. Activation steering or model editing ask how to control a model, whereas we ask how a model constructs and manipulates representations to control itself."}, {"title": "3 Methodology", "content": "3.1 The RAVEL Benchmark\nRAVEL (Huang et al., 2024) is an benchmark that evaluates interpretability methods on localizing and disentangling related factual knowledge. We focus on the data for disentangling the country a city is in from the continent it is in.\nFiltering Following Huang et al. (2024), we filter out all of the cities that GPT-2 small (Radford et al., 2019) doesn't know both the country and the continent. However, GPT-2 small is not a very capable model, so we give five in context examples when evaluating the knowledge of the model:\n\u201cToronto is a city in the country of Canada. Beijing is a ... <city> is a city in the country of\"\nSee Appendix A for the full 5-shot prompts. We further filter out multi-token cities to simplify the task and give the SAEs the best chance at success. The resulting dataset contains 40 cities in total.\nInterchange Interventions in Feature Space If a set of features contains the knowledge that Toronto is in Canada, then fixing those features to take on the value they would have for city Tokyo should make the model think that Toronto is in Japan. The process of fixing features to take on values they would have for a different input is an interchange intervention (Geiger et al., 2020; Vig et al., 2020; Finlayson et al., 2021). Suppose we have base input prompt b and a source input prompt s for a model M and we want to target features F. Define the interchange intervention as\n$f = get(M, s, F)$\n$\u0177 = M_{F \\leftarrow f}(b)$\nwhere $get(M, s, F)$ retrieves the value that features F take on when M is run with input s and $M_{F \\leftarrow f}(b)$ is the output produced when M is run with input b under intervention $F \\leftarrow f$.\nCounterfactual Labels The label of an interchange intervention example is determined by the concept we think is encoded in the features F and the mechanism that determines the output given the prompt (Geiger et al., 2021). For our task, the mechanism connecting the knowledge of a city and the expected behavior is simple. If we are intervening on the 'country' features, then the \u2018country\u2019 prompt should have the label from the source $y_s$ and the 'continent' prompt should have the label from the base $y_b$. If we intervene on the 'continent' feature, we use the opposite labels.\nSplits To evaluate a proposed set of 'country' features and 'continent' features, we perform interchange interventions using the RAVEL dataset prompts for base and source inputs. We filtered our dataset down to 40 cities, which can be used to generate 1600 interchange interventions targeting 'country' and 1600 interchange interventions targeting 'continent' (3200 in total). We split the interchange intervention data so that 70% is training, 10% is validation, and 20% is test. Our evaluations are i.i.d. to give SAEs the best chance at success."}, {"title": "3.2 Constructing and Selecting Features", "content": "Sparse Autoencoders for Dictionary Learning Sparse autoencoders (SAEs;Bricken et al. 2023; Cunningham et al. 2023) are a unsupervised method for unpacking a hidden vector representation into a higher dimensional, sparsely activated feature space. The hope is that dimensions in this new feature space will correspond to interpretable concepts. SAEs used for this purpose typically have an encoder with a linear transformation followed by a ReLU and a linear decoder:\n$\\tilde{x} = x - b_x$\n$f = ReLU(W_e \\tilde{x} + b_e)$\n$\\hat{x} = W_d f + b_d$\nSAEs are optimized jointly to have low reconstruction error and sparse representations:\n$\\mathcal{L} = \\frac{1}{|X|} \\sum_{x \\in X} ||x - \\hat{x}||_2 + \\lambda ||f||_1$\nLow reconstruction loss ensures that the features faithful to the underlying hidden vector and low sparsity loss is thought to create interpretable features. General purpose SAEs are trained on hidden vector representations created by the model when processing a enormous amount of text data, e.g., an SAE might be trained on residual stream representations created by the second layer of a transformer processing the Pile (Gao et al., 2021).\nThe Bloom SAE has this standard architecture and training, but the other SAEs are variants. The Open AI SAE is a top-k SAE, which (Gao et al., 2024) show to outperform the standard architecture on the sparsity-reconstruction frontier. A top-k encoder is simply the standard encoder except only the top k firing features are kept:\n$f = Topk(ReLU(W_e \\tilde{x} + b_e))$\nThe two Apollo SAEs have standard architecture, but they are trained with additional loss terms. The Apollo SAE (e2e) is trained with the additional loss objective of the KL-divergence between the output logits of the model before and after reconstruction. The Apollo SAE (e2e + ds) has the logit-based loss in addition to a mean-squared error loss between the residual stream representations in downstream layers before and after reconstruction. (Braun et al., 2024) also report a praeto improvement on the sparsity-reconstruction trade off for end-to-end models.\nDistributed Alignment Search SAEs are unsupervised, so features must be further analyzed to determine their conceptual content. In contrast, DAS (Geiger et al., 2024b) learns linear features with specific conceptual content via supervision from counterfactual data that describes how a model should act when a concept has been intervened upon. DAS features learned specifically for this task will be a skyline for general-purpose SAEs.\nIn particular, DAS learns an orthogonal matrix R that rotates a hidden vector h, with the dimensions of the rotated space Rh being the new feature space, i.e. a set of features F are dimensions of Rh. We start by randomly initializing R, which renders all features equally meaningless. Then, an interchange intervention is performed on features F with a base b and source s input prompt pair. Loss is computed from the output of the intervened model:\n$L = CE(M_{F \\leftarrow get(M,s,F)}(b), y)$\nThe expected label y is determined by the concept that we are localizing in F and the mechanism by which the concept determines behavior. See Section 3.1 for a description of the interchange intervention data. We provide details on hyperparameters in Appendix B.\nDifferential Binary Masking In order to determine which features F to select for a given concept ('country' and 'continent' in our case), we use Differential Binary Masking (DBM; De Cao et al. 2020; Csord\u00e1s et al. 2021; De Cao et al. 2022; Davies et al. 2023) to select features for intervention. Each feature f in the feature space F is masked with a vector m which is passed into a sigmoid \u03c3 after being scaled by a temperature T:\n$f_l = get(M, F, b)$\n$f_s = get(M, F, s)$\n$f = (1 - \\sigma(m/T)) \\odot f_l + \\sigma(m/T) f_s$\nThese masks are trained on an interchange intervention loss objective while the temperature is annealed to make the masks snap to 0 or 1:\n$L = CE(M_{F \\leftarrow f}(b), y)$\nWhen we DBM with DAS, the features and the masks are learned simultaneosly."}, {"title": "4 Experiments", "content": "Our goal is to find a hidden vector representation in GPT-2 small where the DAS skyline features are significantly better than the neuron baseline, and then evaluate whether SAEs are an improvement on neurons as a unit of analysis. For this reason, we follow the lead of (Huang et al., 2023) and chose to explore the residual stream representations of GPT-2 small above the <city> token in the early layers of the model. We implement our experiments with nnsight (Fiotto-Kaufman et al., 2024) and pytorch (Paszke et al., 2019)."}, {"title": "4.1 Results", "content": "In Figure 1a, we report the interchange intervention accuracy across the layers of GPT-2 small. In Figures 1b and 1c, we present the detailed results for layers 1 and 5 of GPT-2 small, because the Apollo SAEs are available for those two layers. We learned 'country' features and 'continent' features, then we used interchange interventions on those features to evaluate whether they, in fact, store the model's knowledge of the country and continent that a city is in, respectively. When targeting 'country' features for intervention, the 'country' accuracy is high when the intervention changes the output and the 'continent' accuracy is high when the intervention does not change the model output. The opposite is true for interventions on 'continent' features. The 'disentangle score' is the average of the two accuracies. In the middle three rows of the table are sparsity evaluations that report how many features were active and/or intervened upon. In the final two rows of the table are reconstruction evaluations that report the knowledge degradation of GPT-2 small when a reconstructed vector is used and the average reconstruction loss on residual stream vectors above the <city> token at a given layer."}, {"title": "4.2 Discussion", "content": "Using representations reconstructed by SAES degrades the model's knowledge of cities. The last row in Figures 1b and 1c that using a representation reconstructed by an SAE always degrades the model's knowledge of the countries and continents that cities belong to. For the first layer, we can see that the Bloom SAE and Apollo SAEe2e severely harm the model (\u2248 -50%) and the Apollo SAE e2e+ds destroys the knowledge entirely. In contrast, the Open AI SAE results in only a small drop in performance (-5%). For the fifth layer, there is less degradation, the Apollo SAE e2e+ds works, and Open AI SAE is again the best.\nThe end-to-end SAEs degrade knowledge less relative to the reconstruction loss. In our limited evaluations, there is no evidence that end-to-end training used to create the two Apollo SAEs was helpful for providing a feature space where knowledge can be disentangled. However, in the last two rows of Figure 1c we can see that despite have the highest reconstruction loss, the Apollo SAE(e2e + ds) degrades the city-knowledge of GPT-2 small an amount that is comparable with Open AI SAE and Bloom SAE. This is weak evidence that the end-to-end objective was helpful for preserving model capabilities.\nThere is a signifigant gap between baseline and skyline; neurons can be improved upon. The skyline provided by DAS at ~95% accuracy for the first 7 layers of GPT-2 small shows that there are separate linear subspaces that encode the country a city is in and the continent a city is in. This means, an SAE with linear features that span these subspaces could achieve performance equivalent to DAS. The neuron baseline at \u224870% is significantly worse than the DAS skyline, and shows that there are polysemantic neurons that need to be disentangled by a rotation via an orthogonal matrix.\nCurrent SAEs for GPT-2 small struggle to compete with the neurons. The two Apollo SAEs and Bloom SAE below the neuron baseline across all layers. The 'country' and 'continent' knowledge are even more entangled in the feature spaces provided by these SAEs. The Open AI SAE at \u224870% is able to match the performance of the neuron baseline, but not exceed it.\nThe top-k SAE is the most performant. Our evaluation is limited, however the results do seem to track improvements in SAEs. The Open AI SAE is a top k-SAE, which a performant architecture on sparsity and reconstruction evaluations (Gao et al., 2024). This is in line with our results that the Open AI SAE is the only model that competes with the neuron baseline across all layers."}, {"title": "5 Conclusion", "content": "We evaluate open-source SAEs on their ability to provide a feature space for GPT-2 hidden representations where knowledge about the country and continent a city is in can be disentangled. We used neurons as a baseline feature space, and a supervised feature learned by DAS as a skyline feature space. While we were able to see meaningful differences in performance between the three SAEs, only one of the evaluated SAEs was able to reach the neuron baseline and none could reach the DAS skyline. We hope this is a useful step in evaluating the usefulness of SAEs for a causal interpretability analysis of deep learning models."}, {"title": "Limitations", "content": "In future, we would like to scale the experiments to models with available SAEs including gemma, Mistral, Llama, and Pythia. Furthermore, we hope to use more attributes from the RAVEL dataset, such as language, gender, etc. for larger models with more knowledge."}, {"title": "A Evaluation Details", "content": "To enhance, the prediction capability of GPT-2 using in-context learning, we use 5-shot prompt for both the attributes. Specifically, for country attribute, we prepare a template as: \u201cToronto is a city in the country of Canada. Beijing is a city in the country of China. Miami is a city in the country of the United States. Santiago is a city in the country of Chile. London is a city in the country of England. <city> is a city in the country of\".\nSimilarly, to support the prediction of continent, we also prepare a similar template for the model as: \u201cToronto is a city in the continent of North America. Beijing is a city in the continent of Asia. Miami is a city in the continent of North America. Santiago is a city in the continent of South America. London is a city in the continent of Europe. <city> is a city in the continent of\u201d. The <city> is replaced with the city name in the dataset to make several samples to make the data for both the country and continent attributes.\nEventually, we prepare the final dataset consisting of base and source sentences, with their corresponding labels to evaluate different techniques. In each example, either the 'country' is targeted for intervention or the 'continent' is. When a prompt is for targeted attribute, the intervention should change the output to match the source city. When the prompt is for the other attribute, the intervention should not change the output."}, {"title": "B Hyperparameters and Compute", "content": "We used these parameters for DBM and DBM+DAS training. Batch size of 16. Temperature is annealed linearly from 10 to 0.1. Training was for 20 epochs. Learning rate is 0.001.\nA masking experiment takes 1 hour approx to run. Three layers had 4 experiments with a run for for each intervention so 4*2 experiments. Layer 1 had a total of 6 experiments with two interventions each. Total time: 1x3x4x2 + 1x6x2 = 36 hours on a 24GB Nvidia RTX A5000"}, {"title": "C Full Reconstruction Evaluation", "content": "See Tables 1 and 2 for the reconstruction evaluations done across all the layers."}, {"title": "D Training Graphs", "content": "See Figures 2a and 3a for the training graphs."}]}