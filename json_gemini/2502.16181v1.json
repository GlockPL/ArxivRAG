{"title": "BiDeV: Bilateral Defusing Verification for Complex Claim Fact-Checking", "authors": ["Yuxuan Liu", "Hongda Sun", "Wenya Guo", "Xinyan Xiao", "Cunli Mao", "Zhengtao Yu", "Rui Yan"], "abstract": "Complex claim fact-checking performs a crucial role in disinformation detection. However, existing fact-checking methods struggle with claim vagueness, specifically in effectively handling latent information and complex relations within claims. Moreover, evidence redundancy, where nonessential information complicates the verification process, remains a significant issue. To tackle these limitations, we propose Bilateral Defusing Verification (BiDeV), a novel fact-checking working-flow framework integrating multiple role-played LLMs to mimic the human-expert fact-checking process. BiDeV consists of two main modules: Vagueness Defusing identifies latent information and resolves complex relations to simplify the claim, and Redundancy Defusing eliminates redundant content to enhance the evidence quality. Extensive experimental results on two widely used challenging fact-checking benchmarks (Hover and Feverous-s) demonstrate that our BiDeV can achieve the best performance under both gold and open settings. This highlights the effectiveness of BiDeV in handling complex claims and ensuring precise fact-checking.", "sections": [{"title": "Introduction", "content": "Fact-checking is crucial for claim verification by collecting relevant evidence and determining their veracity (Guo, Schlichtkrull, and Vlachos 2022). Disinformation, concealed within plenty of daily news and reports, threatens the cyber environment and social stability (Liu et al. 2024b). Given its critical role in combating disinformation, complex claim verification has attracted considerable attention from both academics and industry professionals (Thorne and Vlachos 2018; Jiang et al. 2020; Pan et al. 2023).\nRecent fact-checking approaches can be broadly categorized into two categories: (i): Specialized Language Model (SLM)-based end-to-end methods focus on extracting representations of claims and evidence then comparing them in the feature space for verification (Popat et al. 2018; Soleimani, Monz, and Worring 2020). Typically, they employ specific fine-tuned modules to establish correlations between claims and evidence (Kruengkrai, Yamagishi, and Wang 2021; Xu et al. 2022; Liao et al. 2023). (ii): Large Language Model (LLM)-based step-by-step methods leverage LLMs to conduct questioning or decomposing progressively (Pan et al. 2023; Zhang and Gao 2023; Wang and Shu 2023). These methods benefit from the advanced semantic understanding and reasoning capabilities of LLMs, enabling more nuanced and thorough fact-checking processes.\nDespite some promising advancements, several challenges persist in current fact-checking methods, particularly concerning claim vagueness and evidence redundancy. Claim vagueness poses a primary obstacle in the fact-checking process.  In terms of content and correlation, claim vagueness can be categorized into two primary types: (i) Latent information encompasses unresolved entities that cannot be identified explicitly and undetermined attributes that remain unspecified. (ii) Complex relations include referential relations, where pronouns reference entities within the claim, and comparative relations, which compare multiple attributes. Addressing these aspects is crucial for accurately clarifying claims, yet previous approaches often fall short in comprehensively handling these nuances, leading to inadequate verification performance (Liao et al. 2023; Rani et al. 2023). The quality of evidence is essential for claim verification. However, original documents often contain extensive, irrelevant details. This redundancy complicates fact-checking, as current methods overly rely on the evidence and fail to effectively filter out unnecessary information, leading to increased complexity and distraction during the fact-checking process (Zou, Zhang, and Zhao 2023; Zhang and Gao 2023).\nTo address these challenges, we aim to improve the complex claim fact-checking from two aspects: (i) claim simplification identifies the latent information and resolves the complex relations to simplify the claim; (ii) evidence selection retains the pertinent evidence and exclude the redundant content. To this end, we propose Bilateral Defusing Verification (BiDeV), a novel complex claim fact-checking working-flow framework that integrates multiple role-played LLMs to imitate the human-expert fact-checking process. To effectively tackle claim vagueness and evidence redundancy, BiDeV incorporates two dedicated modules: (i) Vagueness Defusing (VD) formulates claim simplification into two stages: perceive-then-rewrite iteratively identifies latent information in the claim, generates corresponding queries for explicit background information, and rewrites the claim for clarity; decompose-then-check decomposes the simplified claim, resolves the complex relations, and verifies each sub-claim step by step; (ii) Redundancy Defusing (RD) evaluates and filters evidence based on the relevance to specific queries, thus obtaining more precise and pertinent evidence. The VD module aims to simplify claims, reducing the complexity of the fact-checking process by eliminating vagueness. Meanwhile, the RD module enhances the evidence quality by excluding irrelevant content, thus minimizing distractions during verification.\nWe conduct comprehensive experiments on widely used challenging complex claim fact-checking benchmarks: Hover (Jiang et al. 2020) and Feverous-s (Pan et al. 2023). Experimental results show that BiDeV achieves the best performance, improving Macro-F1 by 3.88% in both annotated evidence (gold) and retrieved evidence (open) settings. This indicates the effectiveness of the proposed VD and RD modules. Also, BiDeV exhibits remarkable improvements on more complex claims, highlighting its competitive generalization ability in handling intricate scenarios.\nOverall, our contributions can be summarized as follows:\n\u2022 We propose BiDeV, a novel fact-checking working-flow framework integrating LLMs to eliminate the vague information in the claim and the noisy redundancy in the evidence, which imitates the fact-checking process of the human experts.\n\u2022 We introduce the vagueness defusing module formulated as a two-stage process fact-checking a complex claim through perceive-the-rewrite and decompose-then-check. This module concentrates on ascertaining latent information and resolving complex relations, contributing to reducing the complexity of fact-checking complex claims.\n\u2022 We present the redundancy defusing module to filter out irrelevant information leading to more effective and pertinent evidence in sub-claim verification. Extensive experimental results demonstrate that BiDeV greatly advances the performance in complex claim fact-checking."}, {"title": "Related Work", "content": "Complex claim fact-checking aims to identify factual conflicts existing between the claim and the given evidence, which serves as a pivotal technique to address fake news and rumor detection (Liu et al. 2024a).\nPrevious works can be categorized as SLM-based end-to-end methods, which focus on obtaining more effective representations of claims and evidences to conduct verification by comparing them in the feature space (Popat et al. 2018; Ma et al. 2019). Utilizing specific models pre-trained or fine-tuned on some NLI datasets allows them to outperform traditional methods on fact-checking (Kruengkrai, Yamagishi, and Wang 2021; He, Gao, and Chen 2022; Wadden et al. 2022). Moreover, designing some specific modules to correlate the claim and evidence is necessary to achieve more precise verification (Xu et al. 2022; Liao et al. 2023).\nAs large language models (LLMs) have demonstrated advances in reasoning (Wei et al. 2022; Wang et al. 2022; Sun et al. 2024c), various LLM roles have achieved success in different fields (Sun et al. 2024b,a; Liu et al. 2025). Recent works instruct LLMs to think step-by-step to gradually conduct fact-checking, such as iteratively questioning (Press et al. 2023) and program-guided reasoning (Pan et al. 2023). Some approaches split the complex claim into several simple sub-claims, which reduce the difficulty of verifying each sub-claim (Zhang and Gao 2023; Wang and Shu 2023).\nHowever, previous works have not adequately addressed vague information in the claim and noisy redundancy in the evidence, which limits their performance. To address these issues, we propose BiDeV, which imitates the verification process of human experts, to achieve accurate complex claim fact-checking through more effective claim simplification and evidence selection."}, {"title": "Bilateral Defusing Verification", "content": "The complex claim fact-checking task places a central emphasis on verifying the veracity of the claim based on the pertinent evidence. Specifically, given a claim C, an evidence source S, a fact-checking model M concentrates on predicting the veracity label Y using the evidence from S.\n$Y = M(C, S), Y\\in [Support, Refute]$\t\t(1)\nWe address that complex claim fact-checking focuses on claim simplification and evidence selection, thus we formulate our working-flow framework as two main modules: Vagueness Defusing for claims and Redundancy Defusing for evidence. The overview of our BiDeV is shown in Figure 2. In the subsequent sections, we will introduce how to integrate LLMs to eliminate the vagueness in the claim and the redundancy in the evidence."}, {"title": "Vagueness Defusing", "content": "As shown in Figure 1, complex claims often contain two types of vagueness: latent information and complex relations. These elements increase the complexity of fact-checking. When human experts face such complex claims, they first query for undetermined information to obtain explicit background knowledge. Then, they analyze and reconstruct the claim based on the collected background knowledge to eliminate this undetermined information, unravel the complex internal correlations to split several sub-claims, and finally verify the sub-claims to derive the ultimate result (Nakov et al. 2021; Das et al. 2023; Pan et al. 2023). To imitate the iterative process of human experts, we divide the vagueness defusing process into two stages: perceive-then-rewrite for latent information and decompose-then-check for complex relations.\nLatent information can be classified into two categories: unresolved entities and undetermined attributes. In the example shown in Figure 1, \"the writer\" is an unresolved entity since its reference is not specified within the claim; \"the birth date\" is an undetermined attribute as it is not mentioned in the claim. To defuse the latent information, we instruct LLMs to implement an iterative and collaborative process involving three roles: the perceptor, querier, and rewriter. This process transforms the initial complex claim C into the simplified claim $C^*$ step by step. The details of their working order are discussed below.\n\u2022 Perceptor ($M_p$) is performed by the LLM through a step-by-step thinking process to perceive latent information in the following standard: (1) An entity is considered to be unresolved if the entity it refers to cannot be found in the claim; (2) An attribute is considered to be undetermined if the attribute of the subject is not mentioned in the claim. Specifically, given the rewritten claim $c_{i-1}$ in the (i-1)th iteration, the perceptor is responsible for accurately identifying both types of latent information and generating targeted question $q_i$ for explicit background knowledge:\n$q_i = M_p(C_{i-1})$\t\t(2)\n\u2022 Querier ($M_q$) is responsible for answering the question generated by the perceptor for precise and explicit content of latent information. Given the question $q_i$ generated by $M_p$, we instruct the LLM to comprehend and integrate pertinent information within the evidence e extracted and refined from evidence source S, then generate a precise and dependable answer $a_i$:\n$a_i = M_q(q_i, e)$\t\t(3)\n\u2022 Rewriter ($M_r$) is essential at this stage as it integrates explicit background knowledge and simplifies the statement of the claim. Since the claim may contain complex internal correlations, merely using these QA pairs as supplementary evidence is insufficient for verification. Given the question $q_i$ in the ith iteration, the rewriter first finds the direct counterparts and the indirect relevance in the claim $C_{i-1}$, then rewrites them using the answer $a_i$. The rewriting process can be formulated as:\n$C_i = M_r(C_{i-1}, q_i, A_i)$         (4)\nAfter the perceive-then-rewrite stage, the simplified claim $C^*$ has effectively reduced the latent information but may still contain some complex relations: referential relation and comparative relation. As shown in Figure 1, \"She\" is a referential relation as it refers to \"the writer\" in the former sentence; \"younger\u201d is a comparative relation as it compares the birth date of \"She\" and \"the author\u201d. To further clarify claims, we employ a decomposer to disentangle these complex relations and a checker to perform more detailed verification.\n\u2022 Decomposer ($M_d$) is performed by the LLM to resolve the complex relations: it replaces referential relations with explicit entities in the claim and splits comparative relations using determined attributes. Then the complex claim is decomposed into a series of brief declarative sub-claims with simple logic and unitary content. Given the simplified claim $C^*$, the process of decomposing sub-claims $s_c$ is given by:\n$s_c = M_d(C^*)$\t(5)\n\u2022 Checker ($M_c$) conducts the final step of fact-checking to verify each sub-claims and conclude the veracity result of the entire claim. Since the claim and evidence may describe the same facts in different ways, we guide the LLM to comprehensively understand and extract valuable insights from evidence, then integrate and match them with the claim, and finally produce a dependable result after meticulous reasoning. With the relevant evidence e, we obtain the verification result $y_j$ of the sub-claims $sc_j$, and ultimately conclude the predicted veracity label Y of the entire claim:\n$Y = \\prod_j y_j, Y_j = M_c(sc_j, e)$\t(6)"}, {"title": "Redundancy Defusing", "content": "When answering questions and verifying claims, human experts first extract potential evidence and then select pertinent paragraphs providing precise and credible information. Hence, we emulate this process by initially extracting coarse-grained relevant evidence from the evidence source S. For the gold setting, we directly use the evidence from annotated with the gold labels in the dataset. For the open setting, we retrieve evidence from external knowledge bases (e.g., Wikipedia). However, the initially extracted evidence often contains redundant and noisy information, which can confuse the querier and checker. Therefore, we filter out the irrelevant information through step-by-step thinking.\n\u2022 Filter ($M_f$) firstly segments the initially extracted evidence into multiple paragraphs and then evaluates whether each paragraph is relevant to the question or the sub-claim, which involves not only directly relevant content but also potentially contributed information. The irrelevant paragraphs are eliminated to get the most imperative and effective evidence. As an example of answering a question $q_i$, given the extracted evidence $e_r$, we obtain the filtered evidence $e_t$ by:\n$e_t = M_f(e_i, q_i)$\t(7)"}, {"title": "Experiments", "content": "There are two widely used and challenging datasets to evaluate the fact-checking performance of baselines and our BiDeV: (i) Hover (Jiang et al. 2020) and (ii) Feverous-s (Pan et al. 2023). Both of the datasets need to verify the given claim with multiple evidences through multi-step reasoning.\nTo demonstrate the effectiveness of our method, we compare BiDeV with the following four types of baselines: (i) Pre-trained methods: BERT-FC (Soleimani, Monz, and Worring 2020) and LisT5 (Jiang, Pradeep, and Lin 2021). (ii) Fine-tuned methods: RoBERTa-NLI (Nie et al. 2020), DeBERTaV3-NLI (He, Gao, and Chen 2022) and MULTIVERS (Wadden et al. 2022). (iii) LLM-ICL methods: FLAN-T5 (Chung et al. 2024) and Codex (Chen et al. 2021). (iv) LLM-reason methods: Hiss (Zhang and Gao 2023), FOLK (Wang and Shu 2023), ProgramFC (Pan et al. 2023) and FactcheckGPT (Wang et al. 2024).\nWe use Macro-F1 as metrics in order to better deal with unbalanced proportions between support and refute samples.\nIn our proposed method, we use gpt-3.5-turbo as the base model of Perceptor, Rewriter, Decomposer, and Filter by accessing to OpenAI API with few-shot demonstrations. For a fair comparison, we leverage Flan-T5-XL (3B) as the Querier and Checker without additional fine-tuning. In the vagueness defusing, we iteratively perceive-then-rewrite for 3 rounds. To evaluate in the open setting, we use BM25 (Robertson, Zaragoza et al. 2009) to retrieve top-K (K=10) evidence documents."}, {"title": "Overall Performance", "content": "We evaluate BiDeV and the compared baselines on two challenging benchmarks under two settings: annotated evidence as gold-setting and retrieved evidence as open-setting. The overall performance is shown in Table 1. The experimental results demonstrate the following conclusions.\n\u2022 BiDeV achieves the best performance. Our BiDeV achieves appealing performance improvement against 11 baselines from 4 categories. Specifically, BiDeV outperforms fine-tuned baselines by 10.69% (gold) and 15.27% (open) on average without training. Compared to both LLM-based baselines, BiDeV also obtains 6.22% performance improvement. The experiment results demonstrate that our proposed BiDeV could achieve outstanding performance gains.\n\u2022 BiDeV improves on more complex claims. Although DeBERTaV3-NLI could be competitive with BiDeV on easier 2-hop claims, its performance drops extremely as the complexity increases, and BiDeV surpasses it by 5.33% and 12.31% on 3-hop and 4-hop claims. Overall, BiDeV achieves improvement by 10.86%@2-hop, 11.72%@3-hop, and 17.72%@4-hop under gold-setting, which indicates that BiDeV performs more effectively on complex claims.\n\u2022 Integrating perceiving, rewriting, and decomposing is effective. Compared with decomposition-based Hiss, question-based FOLK, and program-guided ProgramFC, BiDeV surpasses them by 5.67% on average, which demonstrates that the integration of perceiving, rewriting, and decomposing could inject explicit background information, resolve intricate correlations, simplify the claim, and reduce the complexity of fact-checking."}, {"title": "Ablation Study", "content": "In this section, we eliminate perceptor, rewriter, decomposer, and filter respectively, and explore to what extent these modules have an impact on the complex claim fact-checking. We conducted an ablation study on the gold setting, which is more representative because of its balanced performance. As shown in Figure 3, the perceptor has the most impact, which indicates that generating questions for explicit background information is necessary. The decomposer contributes to the verification as it disentangles a complex claim into several brief sub-claims that are much easier to be verified. The rewriter could reduce the complexity of understanding claims as well. These three modules demonstrate that vagueness defusing is effective in simplifying the claim and leading to better fact-checking accuracy. The feasibility of the filter has also confirmed that redundancy defusing could estimate and improve the evidence quality."}, {"title": "Additional Analysis", "content": "We conducted comparative experiments with a selected strong baseline ProgramFC to explore the performance in retrieving different numbers of evidence and the results are shown in Figure 4.\nIntuitively, more evidence will provide more information, leading to more accurate fact-checking. However, the performance of ProgramFC exhibits an upward-then-downward trend as the number increases, because the gain from useful information is offset by the interference from redundant information when too many evidences are retrieved. Compared to ProgramFC, BiDeV achieves consistent performance improvement as the number of retrieved evidences increases, which demonstrates that redundancy defusing module performs fine-grained filtering from the extracted evidences to obtain more pertinent and effective information.\n\u2022 Iteration of perceive-then-rewrite. Perceive-then-rewrite is an iterative process designed to involve more precise information and simplify the complex claim. We designed experiments to investigate the effect of different numbers of iterations on the verification accuracy. As shown in Figure 6, with the increase in the number of iterations, the accuracy of fact-checking gradually increases and tends to stabilize. The experimental results reveal that it is necessary and effective to constantly rewrite the claim based on queried explicit background knowledge, which eliminates vague information and simplifies the claim. In the trade-off between performance and cost, we finally set the maximum number of iterations to 3 according to the results.\n\u2022 Strategies of decomposition. Decomposition plays an important role in decompose-then-verify, thus we explore the effects of different decomposition strategies: (1) Direct: directly verify the simplified claim; (2) Naive: naively decompose the simplified claim; (3) BiDeV: decompose the simplified claim to resolve complex relations. We conduct evaluation on both gold and open settings, the experimental result is shown in Table 2. Comparison with Direct demonstrates the necessity of the decomposition, and comparison with Naive proves the effectiveness of the complex relation-oriented decomposition in BiDeV.\nIn our proposed BiDeV, the accuracy of answering the questions affects the effectiveness of claim rewriting, and the verification of the sub-claim directly influences the overall fact-checking accuracy. Consequently, we scale the base model of Querier and Checker and conduct a comparison on Hover that is more direct to evaluate performance on different complexity of claims (Pan et al. 2023). As shown in Figure 5, our BiDeV allows for better generalization on larger-scale base models. Compared to FLAN-T5, the improvement is more on a smaller base model, 35.22% on 80M parameters, because the reasoning ability is constrained by the model scale. Our bilateral defusing effectively alleviates this issue by simplifying the claim and selecting pertinent evidence. It reveals that BiDeV better eliminates the obstacles to verifying complex claims that we surpass ProgramFC with the sub-task solver of 11B by only using the base model of 250M as Querier and Checker."}, {"title": "Case Study", "content": "To present a more intuitive presentation of BiDeV in the fact-checking process, we select FOLK and ProgramFC for comparison. As shown in Figure 7, the vague information in the claim has been eliminated after perceive-then-rewrite stage and the decomposed sub-claims have been verified successfully. However, FOLK generates invalid predicates leading to improper answers to the follow-up questions confused by the complex statement in the claim. Similarly, ProgramFC encounters wrong variable correlation and sub-task function calls. Both FOLK and ProgramFC are close to machine-centric reasoning, which is constrained by complex claims. In contrast, BiDeV imitates the thinking process of human experts achieving more accurate fact-checking."}, {"title": "Conclusion", "content": "We propose Bilateral Defusing Verification (BiDeV) in this paper, a novel framework integrating multiple LLMs to effectively imitate the complex claim fact-checking process of human experts. The vagueness defusing module eliminates latent information and resolves complex correlations, thereby simplifying the claims. The redundancy defusing module filters out irrelevant evidence to provide more pertinent information for verification. Experimental results show that BiDeV advances the best performance on two challenging benchmarks (Hover and Feverous-s). This highlights BiDeV's significant improvements in handling complex claims and offering more intuitive reasoning processes."}]}