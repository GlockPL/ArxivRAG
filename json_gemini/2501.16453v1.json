{"title": "Detecting Zero-Day Attacks in Digital Substations via In-Context Learning", "authors": ["Faizan Manzoor", "Vanshaj Khattar", "Akila Herath", "Clifton Black", "Matthew C Nielsen", "Junho Hong", "Chen-Ching Liu", "Ming Jin"], "abstract": "The occurrences of cyber attacks on the power grids have been increasing every\nyear, with novel attack techniques emerging every year. In this paper, we address\nthe critical challenge of detecting novel/zero-day attacks in digital substations\nthat employ the IEC-61850 communication protocol. While many heuristic and\nmachine learning (ML)-based methods have been proposed for attack detection in\nIEC-61850 digital substations, generalization to novel or zero-day attacks remains\nchallenging. We propose an approach that leverages the in-context learning (ICL)\ncapability of the transformer architecture, the fundamental building block of large\nlanguage models. The ICL approach enables the model to detect zero-day attacks\nand learn from a few examples of that attack without explicit retraining. Our\nexperiments on the IEC-61850 dataset demonstrate that the proposed method\nachieves more than 85% detection accuracy on zero-day attacks while the existing\nstate-of-the-art baselines fail. This work paves the way for building more secure\nand resilient digital substations of the future.", "sections": [{"title": "1 Introduction", "content": "The modern-day power grids continuously face the possibility of being disrupted by\ncyber attacks. This is evident from the recent increase in the cases of cyber attacks on\npower grids worldwide. For example, in 2015, a coordinated cyber-attack was respon-\nsible for the mass-scale power outages in Ukraine [1]. In 2016, another cyber-attack\nin Ukraine also led to a mass power outage and affected the SCADA system at the\ntransmission level [2].\nIntrusion Detection Systems (IDSs) play an important role in detecting potential\ncyber-attacks on substations so that timely action can be taken. However, most of\nthe existing IDS methods, heuristic or machine learning-based, struggle when they\nencounter a novel or an unseen attack. We refer to these kinds of attacks as zero-\nday attacks as they present themselves for the first time. A recent study showed that\nmillions of new cyber-attacks were detected annually worldwide from 2015 to 2020\n[3]. This highlights the importance of developing IDSs that can effectively detect zero-\nday attacks. As a consequence, cybersecurity of digital substations against zero-day\nattacks has recently been a focus for many researchers [4].\nIn this paper, we specifically consider IEC-61850 digital substations [5, 6]. Although\nIDS techniques are well-explored for traditional TCP/IP-based substation communi-\ncation networks [7], the specific requirements and unique communication protocols of\nIEC-61850 substations have not been adequately addressed.\nThe IEC-61850 communication protocol is commonly used in digital substations to\ncommunicate between Intelligent Electronic Devices (IEDs) and Merging Units (MUs).\nIt allows for efficient connectivity and control in digital substations [8], however, there\nare numerous vulnerabilities that an attacker can exploit to disrupt the operation of\nthese digital substations [9]. Many existing IDS methods, whether heuristic-based [10]\nor machine learning (ML)-based [11, 12], are designed for specific attacks, which can\nlimit their ability to generalize to zero-day attacks.\nHeuristic-based methods use a predefined set of rules to determine if the incom-\ning data packet is a specific attack or not. In [13], the authors use timestamp and\nsequence numbers to detect a replay attack. In [14], authors investigated the injected\nspoofing attack on the IEC-61850-based standard. However, the proposed model was\nspecifically designed for spoofing attacks and may have limited applicability to other\ntypes of attacks. The work in [15] develops an IDS for the IEC-61850 protocol, but\nthey only consider information carried within sampled value messages, which restricts\nits application to other message-sharing protocols, such as GOOSE.\nIn [16], the authors use a neural network-based approach to detect spoofed packets.\nAnother work improved the previous approach using the decision trees and random\nforests [17]. However, many of these existing ML-based methods focus on specific\nattack cases and do not generalize to novel attacks.\nTherefore, we propose a generalizable IDS framework for the IEC-61850 commu-\nnication protocol that can detect zero-day attacks on digital substations. Our method\nleverages the \"in-context learning\" (ICL) ability of transformer architectures [18],\nwhich are a basic building block of large language models (LLMs) [19].\nIn-context learning is the ability to generalize rapidly from a few examples of a\nnew task that have not been previously seen, without any updates to the model,"}, {"title": "2 Results", "content": "We validate the proposed ICL-based IDS framework on a real-world attack dataset\nfrom ERENO-IEC-61850 [29]. The ERENO-IEC-61850 dataset provides a rich testing"}, {"title": "2.1 The Impact of Training Data Diversity", "content": "To address Q1, we examine how training data diversity impacts ICL and zero-day\nattack detection performance by training the GPT-2 transformer on various numbers\nof attack classes (data diversity), $K_{syn} \\in \\{100,300,500,700\\}$, generated using the\nmulti-mixing approach described in our methodology in Section 4.1. To quantify the\nperformance of the transformer models on zero-day attack detection, we use the con-\ncept of shots, which are the maximum instances of attacks in the in-context data. We\nquantify ICL capability as the total change in accuracy across maximum shots.\nFirst, as shown in Figures 3a and 3b, increasing the number of shots (instances of\nattacks in the in-context data) improves accuracy across all four types of attacks not\nencountered during training for both the TF and DTF models. This trend indicates\nthat the models are effectively adapting to OOD attack patterns as more attack packets\nare sent by attackers.\nSecond, we observe that the 0-shot accuracy (when the model encounters an OOD\nattack for the first time) of the DTF model is higher compared to the TF model. This\nsuggests that DTF is better suited for scenarios where the volume of attack packets\nsent by an attacker is uncertain, as it can detect OOD attacks effectively even on\nthe first instance. This characteristic makes DTF more effective in environments like\ndigital substations, where even a single undetected attack packet could disrupt the\nwhole system.\nThird, as shown in Figure 3c, increasing training attack classes enhances the ICL\ncapability for both TF and DTF models across different OOD attacks. For attacks\nlike masquerade fake fault and poisoned high rate, the ICL capability is nearly zero,"}, {"title": "2.2 Comparative Analysis of Label Choices During Training", "content": "To address Q2, we examine the impact of different in-context Lab/Dist choices during\ntraining: (1) Lab/Dist from weak classifiers only and (2) a mixture of weak classifier\nand ground-truth Lab/Dist.\nFirst, we experimented with various mixing ratios. We discovered that for the TF\nmodels, a training ratio of 60% weak classifier labels and 40% ground-truth labels\nyielded the highest attack detection accuracy during testing. In contrast, for the DTF\nmodel, we achieved the best performance with a minimal ground-truth label ratio of\n5%. This asymmetry appears to stem from the different information density in label\nversus distribution-based training. Additionally, we found that using a high proportion\nof ground-truth labels (greater than 10%), in the case of DTF, led to model instability,\ncharacterized by decreasing accuracy with additional shots and significant performance\nvariation across five different seeds.\nFigure 3e compares attack detection accuracy during testing for TF and DTF\nmodels trained with only weak classifier labels versus mixed labels (40:60 for TF\nand 95:5 for DTF). The figure clearly illustrates that incorporating a mix of ground\ntruth and weak classifier labels during training improves both zero-shot and n-shot\nperformance.\nThe WCTF model shows low zero-shot performance but high ICL, while the MTF\nmodel demonstrates both high zero-shot performance and high ICL, suggesting that\nincluding ground-truth labels for in-context data during training enhances the trans-\nformer models' attack detection accuracy. From an engineering perspective, DTF offers\nan advantage over TF, as a stable mix of only 2-5% ground-truth labels yields the\nbest results, eliminating the need to fine-tune the ground-truth-to-weak-classifier label\nratio and reducing the number of hyper-parameters requiring adjustment."}, {"title": "2.3 Sensitivity Analysis", "content": "To address Q3, we conducted a sensitivity analysis of our models by synthetically\ntraining multiple weak classifiers with accuracies varying in increments of 0.1 for OOD"}, {"title": "2.4 Zero-day Attack Detection", "content": "We answer Q4 by validating the trained model on the attacks not seen during the\ntraining (OOD attacks) and on the attacks that are seen during the training (ID\nattacks). We compare our results against widely known ML-based classification meth-\nods. The TF and DTF models are trained across 700 attack classes, using a 40:60 of\nground-truth to weak classifiers Lab/Dists for TF, and a 5:95 for DTF.\nTable 1 presents the final results, where red cells indicate 'failure cases,' defined as:\n1) inability to reach an accuracy threshold of 80% for a specific attack, and 2) failure\nto achieve 100% accuracy on normal data.\nAs shown in Table 1, widely used ML-based methods encountered at least one fail-\nure case, demonstrating limitations in detecting certain zero-day attacks. Furthermore,\ntraditional ensembling techniques, like hard voting applied to weak classifiers, also\nresulted in failure cases. In contrast, our proposed ICL-based methods, evaluated under\nmax-shot conditions, did not show these failures when using weak classifiers. Although\nthe MTF model encountered a failure case in the 0-shot scenario, it still achieved\nhigher accuracy than hard-voting accuracy with weak classifiers. The MDTF model,\nhowever, demonstrated no failure cases, even in the 0-shot scenario, and surpassed\n90% accuracy under max-shot conditions across all OOD attacks. This observation\nsuggests an inherent capacity of MDTF models to recognize previously unseen attacks."}, {"title": "2.5 Deployment in Digital Substations", "content": "To answer Q5 and demonstrate the feasibility of deploying our DTF model for real-time\nanomaly detection in IEC 61850-compliant digital substations, we trained the model\noffline on an NVIDIA RTX A6000 GPU (5000 iterations, 1 hour of training). After\ntraining, we evaluated inference performance on standard computing platforms\u2014an\nAMD Ryzen 7 6800H CPU and an NVIDIA RTX 3070 Ti GPU-using different opti-\nmization and runtime frameworks (ONNX, OpenVINO, TensorRT). Table 2 reports\nthe average inference time per sample under various batch sizes, hardware, and\nframeworks.\nFigure 2c illustrates the high-level integration of our DTF model in a digital sub-\nstation. At the process-bus level, SV packets arrive from MUs at a sampling rate\n$F_{sv} = 4800 Hz$, while GOOSE packets arrive from IEDs at a rate $F_{GOOSE}$. Under\nnormal operating conditions, $F_{GOOSE}$ may be as low as 0.5 Hz, but it can surge to\n250 Hz during faults [31]. Both SV and GOOSE streams are downsampled by factors\n$D_{sv}$ and $D_{GOOSE}$, respectively, and then preprocessed. Thus, the combined data rate\nat the input of the model is\n$F = max(F_{GOOSE} \\times D_{GOOSE}, F_{sv} \\times D_{sv})$.\nTo improve inference throughput, we collect data in batches of size BS. Once BS pre-\nprocessed samples are accumulated, the batch is fed to the model. Let $T_{average}(H, BS)$\nbe the average per-sample inference time on hardware and framework H and batch\nsize BS. Then, the time to process one full batch is\n$T_{TF} = T_{average}(H, BS) \\times (BS - 1)$, $T_{batch} = \\frac{BS}{F}$,\n$T_{pro} = T_{batch} + T_{TF}$,\nwhere $T_{pro}$ represents the total time overhead introduced by batching and processing.\nThe total detection latency is then\n$T_{total} = T_{pre} + T_{pro}$,\nwhere $T_{pre}$ is the (typically small) preprocessing time.\nIEC 61850 classifies substation applications based on how quickly messages (e.g.,\nGOOSE) must be exchanged among networked IEDs. For instance, the fastest cate-\ngory (Type 1A, performance class P2/P3) specifies a 3 ms upper bound for message\n\"transmission time\u201d ($T_{transmission}$) in fast-messaging (trip) applications [31]. The"}, {"title": "3 Discussion", "content": "Here we propose two distinct transformer architectures that harness ICL to detect\nzero- day attacks in digital substations. In doing so, we also demonstrate how inaccu-\nrate or noisy labels in in-context can be leveraged to enhance generalization. Through\nsensitivity analysis we show that weak learners achieving only 40-50% accuracy can"}, {"title": "4 Methodology", "content": "In this section, we describe our overall ICL-based IDS framework with the training\nand testing procedures in detail."}, {"title": "4.1 Training Data Generation", "content": "Many recent works have highlighted the importance of training data diversity to\nimprove ICL capabilities in transformer models [32-34]. Specifically, within the cyber-\nsecurity context, this translates to the inclusion of various types of attack scenarios.\nHowever, there are not many existing cyber-attack datasets for the IEC-61850 pro-\ntocol. Therefore, to increase the diversity of the training data for ICL capabilities,\nwe propose an approach called multi-mixing, where the key idea is to generate syn-\nthetic attacks, without collecting additional data, by linearly combining features from\ndifferent attack classes. By creating these synthetic examples, we aim to expose the\ntransformer model to a wider range of attack patterns, potentially improving its abil-\nity to detect zero-day attacks. In the traditional mixup approach [35], two data points\nare selected randomly and combined according to weights derived from a beta dis-\ntribution. Instead, in our proposed multi-mixing strategy, we extend this concept by\nselecting random data points from each available class and linearly combining them\nto form a new, synthetic class. This approach ensures each new data point is a mix-\nture of multiple classes, enhancing the dataset's overall diversity. To formalize this,\nconsider a dataset with $K_{ori}$ distinct classes. Multi-mixing generates a new synthetic\nclass as follows:\n$A_{new} = \\sum_{k=1}^{K_{ori}} \\alpha_{k} A_{k}$,\nwhere $A_{k}$ represents all data points (shuffled) belonging to the kth class, and $a_{k} \\in [0,1]$\ndenotes the weight of the kth class incorporated into the new class, denoted as $A_{new}$.\nEach of these new classes is assigned a new label, which allows the model to learn more\nlatent features and generalize better. We denote the total number of classes generated"}, {"title": "4.2 In-context Data from Weak Classifiers", "content": "In our proposed methodology, the transformer model uses ICL to detect the novel\nincoming attack packet as normal or attack. However, during testing, the true labels\nof incoming data packets are not available. To achieve ICL, the in-context data should\nconsist of the input-label pairs (same as $D_{N-1}$ in Section A.1). Hence, we utilize\nweak classifiers, which are pre-trained models (such as neural networks). These models\ngenerate probability scores, $y_{pr,n}^{w,k} \\in [0, 1]$, representing the likelihood that the nth data\npacket, $x_{n} \\in R^{d}$, in the in-context data belongs to class $k \\in \\{0,1,..., K_{syn}\\}$. The\nclass with the highest probability, $\\hat{y}_{n} = arg max_{k} Y_{pr,n}$, is then used as a pseudo-label\nfor the in-context data processed by the transformer model.\nThese classifiers are termed \"weak\" because they may not achieve perfect detection\naccuracy but offer preliminary predictions that guide the transformer model's ICL\nprocess. To reduce the influence of individual weak classifier errors, we aggregate the\nargmax outputs from multiple weak classifiers and provide the concatenated results\nas input to our transformer model as follows:\n$Y_{wc,n} = [\\hat{y}_{n}^{1}, \\hat{y}_{n}^{2}, ..., \\hat{y}_{n}^{W}, -1] \\in R^{d}$,\nwhere $\\hat{y}_{n}^{w}$ denotes the class predicted by the $w^{th}$ weak classifier for the $n^{th}$ data packet\nin in-context data. The padding token -1 is used to ensure uniform input length,\nand W is the number of weak classifiers. We employ deep neural networks as weak\nclassifiers, designed specifically for multi-class classification."}, {"title": "4.3 Training the Transformer Model", "content": "To train the transformer model for intrusion detection, we explore two possible label-\ning approaches for each in-context sample: 1) labels from weak classifiers, and 2) a\ncombination of weak classifier labels and ground-truth labels. We label the former\nas Weak Classifier Trained Transformer (WCTF) and the latter as Mixed Trained\nTransformer (MTF). Our experimental results, presented in Section 2.2, demonstrate\nthat this mixed labeling approach achieves the highest accuracy for zero-day attack\ndetection.\nWe train the transformer model using N input-label pairs, denoted as\n$\\{(X_{1}, Y_{tr,1}), (X_{2}, Y_{tr,2}), ..., (X_{N}, Y_{tr,N})\\}$, where tr indicates a training sample. Each $X_{n}$\nis sampled randomly and burstily from the $K_{syn}+1$ attack classes and the normal\ndata [36]. The label $y_{tr,n}$ for each sample $n \\in \\{1, 2, ..., N\\}$ is determined by the fol-\nlowing labeling methods: when using only weak classifier labels, the $Y_{tr,n}$ is denoted\nby $Y_{wc,n}$; when using mixed-labels, it is represented as $Y_{mix,n}$.\nFor each input n, the transformer model considers the data $S_{n} =$\n$(X_{1}, Y_{tr,1},..., X_{n}, Y_{tr,n})$-where $D_{n-1} = \\{(X_{1}, Y_{tr,1}), (X_{2}, Y_{tr,2}),..., (X_{n-1}, Y_{tr,n-1})\\}$\ndenotes the in-context data and $(x_{n}, Y_{tr,n})$ denotes the query set, $x_{qs} = (X_{n}, Y_{tr,n})$- to\nmake its prediction $M_{\\theta}(S_{n})$ for target $y_{n}$. We append $Y_{tr,n}$ alongside $X_{n}$ to provide\nadditional information to the model about the potential true label.\nWe use the cross-entropy loss functions for training: (i) WCTF and (ii) MTF loss:\n$L_{WCTF}(\\theta) = L_{MTF}(\\theta) = -\\sum_{i=1}^{I} \\sum_{n=1}^{N} \\sum_{k=1}^{K_{syn}} y_{n}^{i} log(M(S_{n,i})),$"}, {"content": "where $M()$ denotes the probability of an $x_{n}$ in $i^{th}$ data sample belonging to class\nk, and $y_{n}$ is an indicator of the correct label for $x_{n}$ in $i^{th}$ data sample. Although\nwe initially train the model for multi-class classification, our primary goal is binary\nclassification, specifically detecting whether incoming packets are normal or represent\nan attack."}, {"title": "4.4 Distributional Transformer Model", "content": "In Section 4.2, we generated weak classifiers' outputs $Y_{wc,n}$ for in-context data by\nconcatenating $\\hat{y}_{n}^{w}$, the hard-label prediction from each $w^{th}$ weak classifier for the $n^{th}$\ndata packet in in-context data. Here, we consider a more nuanced approach: instead\nof using only hard-label predictions, we investigate whether incorporating the full\nprobability distribution over $K_{syn}$ classes from each weak classifier could enhance\nzero-day attack detection.\nWe propose a distributional transformer (DTF) model, which takes modified weak\nclassifiers' outputs, $Y_{wcd,n}$, defined as:\n$Y_{wcd,n} = [Y_{prd,n}^{1}, Y_{prd,n}^{2},..., Y_{prd,n}^{W}] \\in R^{K_{syn} \\times W}$,\n$Y_{prd,n} = [y_{pr,n}^{w,1}, y_{pr,n}^{w,2}, ..., y_{pr,n}^{w,K_{syn}}] \\in R^{K_{syn}},$"}, {"title": "4.5 Testing", "content": "Once trained, we can deploy the transformer models to detect anomalies in real-time.\nThe most recent data packet received, and its weak classifier Lab/Dist are treated\nas the query set, $x_{qs} = (X_{N}, \\hat{y}_{wc,N})$, where $\\hat{y}_{wc,N} = Y_{wc,N}$ for TF models and $Y_{wcd,N}$\nfor DTF models. The preceding N-1 packets and their weak labels/distributions\nserve as the in-context data $D_{N-1}$. Under standard substation operations, we would\nanticipate that all packets within the sequence are normal. However, in the event\nof an attack, the $x_{N}$ becomes anomalous, while the earlier in-context packets would\nlikely still reflect normal conditions. We refer to the transformer model's ability to\ndetect anomalies where the context remains normal while only the query point is\nanomalous--as its zero-shot performance. This scenario assesses the model's ability\nto detect completely novel attacks based solely on its learned representations.\nAs the attack persists, the attacker continues to send anomalous packets, which\nbegin to appear in the in-context data. The model's performance in this setting eval-\nuates its ability to adapt and detect the new attack based on these few new unlabeled\nexamples. This gradual transition from normal to anomalous in the in-context data\nallows us to evaluate the model's n-shot performance, where n denotes the number\nof anomalous packets present within the in-context data $D_{N-1}$.\nNote that our approach differs from traditional ICL. Instead of having access to true\nlabels, we rely solely on pseudo-labels generated by weak classifiers. From a deployment\nperspective, this methodology is especially beneficial for real-time intrusion detection\nin digital substations. It enables the model to quickly adapt to new types of attacks\nbased on just a few observed instances."}, {"title": "Appendix A Preliminaries", "content": null}, {"title": "A.1 Transformer Architecture and In-context Learning (ICL)", "content": "Transformers are a class of deep neural networks that have achieved state-of-the-\nart performance in diverse sequence modeling tasks [18]. Central to this architecture\nis the self-attention mechanism, which efficiently captures long-range dependencies\nwithin sequential data. By stacking multiple layers of multi-head self-attention and\nfeed-forward networks, transformers enable robust feature extraction and flexible\nrepresentation learning.\nOur approach adopts a decoder-only transformer (GPT-2 [30]) but specialized\nfor network traffic analysis. Three key design elements underlie its effectiveness in\nsequential pattern recognition:\n1. Causal Attention Mechanism. Each prediction depends only on past observa-\ntions, naturally aligning with the temporal ordering of packet streams in digital\nsubstations.\n2. Parameter-Sharing Through Transformer Blocks. This facilitates handling\nvariable-length input sequences without architectural changes, crucial for evolving\nnetwork traffic patterns.\n3. Streamlined Decoder-Only Inference. By omitting an encoder stage, the\nmodel can efficiently process real-time data while preserving strong pattern-\nrecognition capabilities.\nAlthough these architectural choices draw from GPT-2's language modeling\nadvances, they generalize to intrusion detection by capturing temporal dependencies\nin packet streams. The causal attention mechanism suits event-sequential data, while\nthe parameter sharing and decoder-only configuration reduce latency-both critical\nfor real-time anomaly detection in digital substations.\nIn-context learning (ICL). A particularly appealing property of transformer\nmodels, including GPT-2-style decoders, is their ability to adapt to new tasks or\npatterns given as input context (e.g., prompt examples) [19]. Formally, consider a\ntransformer model $M_{\\theta}$ that processes a sequence of length N. The first N - 1 tokens\nor samples, $\\{(X_{1},Y_{1}), (X_{2},Y_{2}), ..., (X_{N-1}, Y_{N-1})\\}$, serve as the in-context data $D_{N-1}$.\nThe query point $x^{q}$ appears in the Nth position, and the model predicts its label $y^{q}$ as\n$y^{q} = M_{\\theta}(x^{q}; D_{N-1})$.\nIn effect, the model produces\n$P(y^{q} | x^{q}, D_{N-1}),$"}, {"title": "A.2 IEC-61850 Digital Substations", "content": "In the digital substations that use the IEC-61850 protocol, there are three main net-\nwork protocols: Sampled Values (SV), Generic Object-Oriented Substation Events\n(GOOSE), and MMS [29]. In this paper, we only consider the SV and GOOSE, as they\nare involved in substation protection functions. SV packets transmit sampled voltage\nand current values from MUs to IEDs, while GOOSE packets enable fast and reliable\ncommunication between IEDs for exchanging control commands. Despite the benefits\noffered by the IEC-61850, it also introduces vulnerabilities that can be exploited by\nattackers. For example, the lack of authentication and encryption in GOOSE and SV\nprotocols can allow attackers to inject false data, manipulate control commands, or\nlaunch denial-of-service attacks [37]. These vulnerabilities highlight the need for devel-\noping effective IDS for IEC-61850-based digital substations. As each IED continuously\nreceives the packets, a time window of incoming packet data can be used as the in-\ncontext data for the transformer architecture (same as $D_{N-1}$ in the last section). The\ngoal is to infer whether the next observed packet data will be an attack or not."}]}