{"title": "LEARNING FROM DEMONSTRATION WITH IMPLICIT NONLINEAR DYNAMICS MODELS", "authors": ["Peter David Fagan", "Subramanian Ramamoorthy"], "abstract": "Learning from Demonstration (LfD) is a useful paradigm for training policies that solve tasks involving complex motions. In practice, the successful application of LfD requires overcoming error accumulation during policy execution, i.e. the problem of drift due to errors compounding over time and the consequent out-of-distribution behaviours. Existing works seek to address this problem through scaling data collection, correcting policy errors with a human-in-the-loop, temporally ensembling policy predictions or through learning the parameters of a dynamical system model. In this work, we propose and validate an alternative approach to overcoming this issue. Inspired by reservoir computing, we develop a novel neural network layer that includes a fixed nonlinear dynamical system with tunable dynamical properties. We validate the efficacy of our neural network layer on the task of reproducing human handwriting motions using the LASA Human Handwriting Dataset. Through empirical experiments we demonstrate that incorporating our layer into existing neural network architectures addresses the issue of compounding errors in LfD. Furthermore, we perform a comparative evaluation against existing approaches including a temporal ensemble of policy predictions and an Echo State Networks (ESNs) implementation. We find that our approach yields greater policy precision and robustness on the handwriting task while also generalising to multiple dynamics regimes and maintaining competitive latency scores.", "sections": [{"title": "1 INTRODUCTION", "content": "Learning from demonstration or imitation learning is a valuable paradigm for training policies that mimic motions demonstrated by an expert. The practical value of this paradigm is evident in the field of robotics where it has been applied to learn policies that are capable of real-world tasks such as stacking kitchen shelves Team et al. (2024), fitting shoes Zhao et al. (2023), performing surgical incisions Strai\u017eys et al. (2023) and knot tying Kim et al. (2024). In spite of recent progress in LfD for robot automation, policies and the motions they generate often struggle to simultaneously meet the (a) precision, (b) latency and (c) generalisation requirements of real-world tasks. Existing approaches seek to satisfy these requirements through scaling data collection Padalkar et al. (2023); Khazatsky et al. (2024), applying data augmentations Zhou et al. (2023); Ankile et al. (2024), ensembling model predictions Zhao et al. (2023) and enforcing policy convergence guarantees Khansari-Zadeh & Billard (2011). The efficacy of each of these approaches is however bottlenecked by the policy parameterisation itself, we argue that this is a crucial design point for overcoming the challenges of LfD.\nThe LfD paradigm can be viewed through the lens of explicitly learning dynamical systems Billard et al. (2022). This characterisation of LfD has resulted in policy parameterisations and optimisation procedures that combine insights from dynamical system theory Strogatz (2018) with tools from machine learning Bishop & Nasrabadi (2006) to provide guarantees on policy convergence Khansari-Zadeh & Billard (2011). Such an approach can lead to policies that are highly reactive and robust enabling applications such as catching objects in flight Kim et al. (2014), however this often comes at the cost of policy generalisation as the optimisation procedure requires restrictive constraints in"}, {"title": "2 RELATED WORK", "content": ""}, {"title": "2.0.1 LEARNING FROM DEMONSTRATION AS LEARNING DYNAMICAL SYSTEMS", "content": "Learning from demonstration can be formalised through the lens of learning a dynamical system Billard et al. (2022). A canoncical example is given by an autonomous first-order ODE of the form:\n$$f:RN \u2192 RN$$ \n$$\\dot{x} = f(x)$$\nwhere x represents the system state and $\\dot{x}$ the evolution of the system state. We can seek to learn an approximation of the true underlying system by parameterising a policy $\\pi_{\\theta} \\approx f$ and learning parameters \u03b8 from a set of M expert demonstrations {$X, \\dot{X}$} = {$X_m, \\dot{X}_m$}$_{M-1}$ of the task being solved. A benefit of this formulation is the rich dynamical systems theory it builds upon Strogatz (2018), enabling the design of dynamical systems with convergence guarantees Khansari-Zadeh & Billard (2011); Kim et al. (2014); Shukla & Billard (2012). For the task of reproducing human handwriting motions, Khansari-Zadeh & Billard (2011) design a learning algorithm called Stable Estimator of Dynamical Systems (SEDS) that leverages the constrained optimisation of the parameters of a Gaussian Mixture Regression (GMR) model to ensures global asymptotic stability of the policy, which includes states outside the distribution of states seen in the expert demonstrations hence addressing the issue of compounding errors due to distributions mismatch. A crucial limitation of this approach however is the expressiveness and generality of the policy parameterisation and requirements for for-mulating optimsation constraints. For instance the optimisation constraints require the fixed point of the dynamical system to be known and the policy parameterisation requires the hyperparameter for the number of Gaussian to be optimised for the given task. Furthermore, results from SEDS op-timisation on the LASA Human Handwriting Dataset demonstrate predicted dynamics that generate trajectories which don't perfectly model the trajectories of all characters in the demonstration data. Our work takes inspiration from the robustness of the dynamical systems modelling approach but chooses to implicitly rather than explicitly model system dynamics."}, {"title": "2.0.2 LEARNING FROM DEMONSTRATION WITH DEEP NEURAL NETWORKS", "content": "A purely statistical viewpoint of LfD seeks to learn the parameters @ of a policy $$\\pi_{\\theta}$$ that models a distribution over actions from expert demonstrations D while simultaneously demonstrating the"}, {"title": "2.0.3 RESERVOIR COMPUTING", "content": "Reservoir computing is a computational paradigm that relies on learning from high-dimensional rep-resentations generated by dynamical systems commonly referred to as reservoirs Yan et al. (2024).\nA reservoir can either be physical Nakajima et al. (2021) or virtual Jaeger & Haas (2004); we focus on the latter as our proposed architecture digitally simulates a reservoir. A Reservoir Computer (RC) is formally defined in terms of a coupled system of equations; following the convention outlined in Yan et al. (2024) that describes the reservoir dynamics and an output mapping:\n$$\\begin{cases} \\Delta x = F(x; u; p), \\\\ y = G(x; u; q). \\end{cases}$$\nwhere u \u2208 $R^{N_{in}}$ is the reservoir input, x \u2208 $R^{N_{dynamics}}$ the reservoir's internal state and y \u2208 $R^{N_{out}}$ the output prediction. The parameters of the system are represented by p and q respectively where p is fixed and corresponds to the reservoir dynamics while q is learnable and associated with an output mapping commonly referred to as the readout. Reservoir computing variants have traditionally been used to model temporal data, demonstrating state-of-the-art performance in the modelling of non-linear dynamical systems Kong et al. (2024). Common instantiations of reservoir computers include Echo State Networks (ESNs) Jaeger & Haas (2004) and Liquid State Machines (LSMs) Maass et al. (2002). The dynamical systems or reservoirs we construct within our proposed neural network layer are inspired by ESNs and hence we provide a preliminary introduction in the following paragraph.\nEcho State Networks (ESNs) proposed by Jaeger & Haas (2004) are a class of reservoir computers in which the reservoir is represented by a sparsely connected weighted network that preserves the echo state property Yildiz et al. (2012). The reservoir is generated through first sampling an adjacency matrix A to represent graph topology and subsequently a weight matrix $W_{dynamics}$ representing the connection strength between nodes in the graph where disconnected nodes have zero connection weight by default. In addition to generating a graph representing the reservoir, a linear mapping $W_{in}$ from input data to the dimension of the reservoir (i.e. the number of nodes in the graph) is also sampled. The reservoir weights are scaled appropriately in order to maintain the echo state property using the spectral radius \u03c1 of the weight matrix $W_{dynamics}$. Both the reservoir and input mapping weights are fixed after construction and leveraged in the reservoir state dynamics equations (corresponding to \u2206x in Eqn 2) as follows:\n$$x(t) = tanh(W_{in}u(t) + W_{dynamics}x(t \u2212 1))$$ \n$$x(t) = (1 \u2212 \u03b1)x(t \u2212 1) + \u03b1x(t)$$\nwhere x(t), $x(t) \u2208 R^{N_{dynamics}}$ represent node update and state at timestep t respectively, u(t) \u2208 $R^{N_{in}}$ are the input data and a \u2208 [0, 1] is a leak rate parameter that controls the speed of state updates. The output mapping (G in Eqn 2) commonly referred to as the readout is represented by a linear map $W_{out}$, resulting in the following equation for output predictions y:\n$$y(t) = W_{out}x(t)$$ \nESNs are traditionally optimised using ridge regression on a dataset of input, output pairs. For a more comprehensive introduction and practical guide to implementing and optimising ESNs we refer the reader to Luko\u0161evi\u010dius (2012)."}, {"title": "3 APPROACH", "content": "Our architecture shown in Fig 1, combines a nonlinear dynamics model with traditional neural net-work layers. In Sec 3.1.1-3.1.2 we outline the nonlinear dynamics model that we propose, high-lighting the mechanism by which it incorporates learnt embeddings. After introducing our nonlinear dynamics model we discuss overall architecture parameters optimisation. Architectures incorporat-ing our neural network layer are composed of both learnable and fixed parameters, as a result, we provide details of how each is optimised, with dynamics model parameter optimisation outlined in Sec 3.2.1 and learnable neural network parameter optimisation outlined in Sec 3.2.2."}, {"title": "3.1 MODEL ARCHITECTURE", "content": ""}, {"title": "3.1.1 \u039d\u039fNLINEAR DYNAMICS MODEL", "content": "Our discrete-time nonlinear dynamics model is heavily inspired by the construction of a reservoir in ESNs Jaeger & Haas (2004) and the dynamics outlined in Eqn 3. In contrast to ESNs we incorporate learnable embeddings as inputs into our dynamics model making it compatible with existing neural network architectures. Similar to ESNs, our dynamics are represented by a weighted graph with spe-cific discrete-time dynamics. We start constructing our dynamics model by sampling the topology of a network graph, in our implementation we sample node connections at random with only 1% of nodes in the graph maintaining connections, this is represented by our adjacency matrix A. Given the resulting sparsely connected graph topology A, we seek to define a weighted network graph that results in dynamics which satisfy the echo state property Yildiz et al. (2012). To accomplish this we start by uniformly sampling a weight matrix representing the weighting of connections between nodes in the graph where disconnected nodes have zero connection strength by default. In order to ensure the echo state property is satisfied we scale our sampled weights matrix using the spectral radius \u03c1, to create a weight matrix with unitary spectral radius. The resulting matrix is scaled once more this time by a hyperparameter S < 1 to yield the dynamical system weights $W_{dynamics}$. This procedure for generating the graph representing our discrete-time nonlinear dynamics is formally outlined below:\n$$A_{ij} = \\begin{cases} 1 & \\text{with probability 0.01} \\\\ 0 & \\text{with probability 0.99} \\end{cases}$$\n$$W_{ij} = \\begin{cases} W_{ij} & \\text{if } A_{ij} = 1; W_{ij} \\sim U[-1,1] \\\\ 0 & \\text{if } A_{ij} = 0 \\end{cases}$$\n$$\u03c1(W) := \\text{max} {|\u03bb_i| : \u03bb_i \\text{ is an eigenvalue of W}}$$\n$$W_{dynamics} = \\frac{S}{\u03c1(W)}W$$\nThe discrete-time dynamics or node update rules we define incorporate learnable embeddings using an additive relationship between a learnt and fixed embedding vector as outlined below:\n$$I(t) := W_{in}u(t) + f_{\\theta_{in}} (u(t), T)$$\n$$x(t) := tanh(I(t) + W_{dynamics}x(t \u2013 1))$$\n$$x(t) := (1 \u2212 \u03b1)x(t \u2212 1) + \u03b1x(t)$$"}, {"title": "3.1.2 DYNAMICS MODEL INPUT TRANSFORMATION", "content": "Our dynamics model requires a fixed and learnable transformation of the input data. The fixed trans-formation follows from Jaeger & Haas (2004) in that we sample weights for a linear transformation $W_{in}$ uniformly at random. The learnable transformation $f_{\\theta_{in}}$ is parameterised by a neural network. This learnable transformation can be used to condition the input state of the dynamics model on task relevant data as shown in Fig 1."}, {"title": "3.1.3 DYNAMICS MODEL OUTPUT TRANSFORMATION", "content": "In contrast to traditional ESNs, the output transformation $g_{\\theta_{out}}$ from dynamical system state x(t) to prediction y(t) is represented neural network.\n$$y(t) = g_{\\theta_{out}}(x(t))$$"}, {"title": "3.2 MODEL OPTIMISATION", "content": ""}, {"title": "3.2.1 DYNAMICAL SYSTEM PARAMETERS", "content": "The optimisation of parameters associated with our dynamics model is mostly addressed as a hy-perparameter search problem (optimising the structure of forward dynamics equations themselves is addressed in future work). In the proposed neural network layer we seek to optimise our model dynamics while preserving the echo state property. In order to accomplish this we employ the pro-cedure that has been outlined in Sec 3.1.1 for ensuring the echo state property is satisfied. In order to search for optimal dynamics parameters we bound the range of parameters to ensure the echo state property and then perform hyperparameter search. The parameters we optimise include (a) the leak rate a, (b) spectral radius \u03c1 and (c) scale of weights in the input projection $W_{in}$."}, {"title": "3.2.2 NEURAL NETWORK PARAMETERS", "content": "Learnable neural network parameters are trained via backpropagation over demonstration sequences as outlined in Alg 1. Unlike purely feedforward architectures; architectures that incorporate our layer have predictions that depend on the state xt of a nonlinear dynamical system. This has conse-quences for model training as the model must be trained on sequences of data rather than individual datapoints. In practice we parallelise the training step across batches of demonstrations and found the learning dynamics and evaluation performance to have greater stability when compared with purely feedforward alternatives."}, {"title": "4 EXPERIMENTAL SETUP", "content": ""}, {"title": "4.1 LASA HUMAN HANDWRITING DATASET", "content": "Our experiments leverage the Human Handwriting Dataset Khansari-Zadeh & Billard (2011) which is composed of demonstrations for 30 distinct human handwriting motions. Each demonstration is recorded on a tablet-PC where a human demonstrator is instructed to draw a given character or shape with guidance on where to start the drawing motion and the point where it should end. For each demonstration, datapoints containing the position, velocity, acceleration and timestamp are recorded. In our problem formulation, we denote a set of M character demonstrations as {$D_j$}$_{j=M}$. From each demonstration $D_j$ we select datapoints corresponding to 2D position coordinates $P_j$ = ($p_1, p_2, ..., p_T$): $p_k$ = ($x_1, x_2$) and split the overall trajectory of 2D coordinates into N sequences"}, {"title": "4.2 BASELINES", "content": ""}, {"title": "4.2.1 ECHO STATE NETWORKS", "content": "In order to distinguish our contribution from existing reservoir computing architectures we imple-ment an echo state network Jaeger & Haas (2004) as one of our baseline models. We employ the same reservoir dynamics as defined in Eqn 3 for this baseline. In order to make a fair comparison with our architecture, we use the same sampling scheme for the fixed weights defining the dynamics; we also ensure the same parameter count and hyperparameter optimisation procedure."}, {"title": "4.2.2 \u0410\u0421TION CHUNKING AND TEMPORAL ENSEMBLING", "content": "To motivate the efficacy of our approach in overcoming compounding errors compared to existing SOTA feedforward architectures, we baseline against feedforward architectures that incorporate the techniques of action chunking and temporal ensembling introduced by Zhao et al. (2023). When implementing this baseline we assume the same learnable layers as our architecture and remove our neural network layer from the architecture. Similar to other baselines we perform hyperparameter optimisation over the model parameters."}, {"title": "4.3 EVALUATION METRICS", "content": ""}, {"title": "4.3.1 PRECISION", "content": "Assessing the precision of dynamic motions is non-trivial as it involves multiple characteristics in-cluding position, velocity, acceleration and jerk. In this work we are primarily concerned with successful character drawing and hence we focus our attention on precision in terms of the ability of the model to reproduce the spatial characteristics of a character. To assess the spatial precision of an architecture we leverage the Fr\u00e9chet distance metric Eiter & Mannila (1994) between a demonstra-tion curve and the curve produced by the model. While our focus remains on the ability of the model to reproduce the spatial characteristics of a character within a reasonable amount of time, we also recognise the importance of appropriately modelling motion dynamics especially when extending this work to experiments in robotics. As a result we also examine the smoothness of trajectories by evaluating the mean absolute jerk associated with trajectories as well as the Euclidean distance between dynamically time warped velocity profiles for demonstrations and predicted trajectories."}, {"title": "4.3.2 GENERALISATION", "content": "We are interested in highlighting the flexibility of our approach to adapt to more than one dynamics regime, which to our knowledge hasn't been addressed in traditional reservoir computing literature. To motivate the ability of our approach to generalise we report the average Fr\u00e9chet distance of a multi-task variant of our architecture given in Fig 1 when trained across multiple character drawing tasks."}, {"title": "4.3.3 LATENCY", "content": "For each architecture we report the total time taken for the architecture to complete the character drawing task. In practice, the relationship between prediction latency and the dynamics of control is complex, here we aim to highlight the differences in prediction latency alone and reserve the discussion of their interplay for future work."}, {"title": "4.4 EXPERIMENTS", "content": "In the following experiments we aim to assess the performance of our architecture under the headings of precision Sec 4.4.1, latency Sec 4.4.2 and generalisation Sec 4.4.3 through benchmarking against the baselines outlined in Sec 4.2."}, {"title": "4.4.1 RESULTS ON PRECISION AND OVERCOMING COMPOUNDING ERRORS", "content": "In this experiment, we wished to investigate whether our architecture can successfully overcome compounding errors on a given character drawing task by accurately reproducing characters. We report quantitative results on both the single task Table 1 and multitask Table 2 settings. In both settings we find that our model consistently obtains the lowest Fr\u00e9chet distance hence modelling the spatial characteristics of expert demonstrations the best. In general, all models encapsulate the spatial characteristics in the individual character drawing task as seen in the reported Fr\u00e9chet distances and qualitative plots Fig 5, however, in the multitask setting this is not always the case with ESNs producing erroneous results in certain cases Fig 7. To further test the ability of each model to overcome compounding errors we introduce random noise at various scales, as demonstrated in Fig 3 (e) our model remains the most robust to increasing levels of noise, closely followed by temporal ensembling predictions of feedforward architectures. Unlike our model, temporal ensembling of"}, {"title": "4.4.2 RESULTS ON ARCHITECTURE LATENCY", "content": "In this section, we wish to highlight the low computation overhead and efficacy of our approach in reducing model latency when compared with the technique of temporally ensembling of pre-dictions. As outlined in Table 1 and Table 2 temporal ensembling of model parameters results in large increases in the latency of the drawing task (in this case ensembling over history of 2 predic-tions results in 2-fold increase in latency for completing the drawing task). Without the ensembling of model parameters all models have similar latency performance, hence demonstrating that our incorporated neural network layer has minimal computational overhead when compared with an equivalent feedforward architecture without our layer included."}, {"title": "4.4.3 RESULTS ON TASK GENERALISATION", "content": "In this section we aim to highlight how our method builds upon existing reservoir computing liter-ature through demonstrating how task-conditioning with learnable input embeddings enables task generalisation. In Table 2 we see that the ESN baseline demonstrates poor performance in the multitask setting, with it achieving the largest Fr\u00e9chet distance metric. In contrast, our method and feedforward architectures which each incorporate learnable transformation of task relevant data demonstrate the ability to complete the character drawing tasks while maintaining Fr\u00e9chet distances that are comparable with individual character drawing performance."}, {"title": "5 LIMITATIONS AND CONCLUSIONS", "content": "In this work, we introduced a novel neural network layer for addressing the issue of compound-ing errors in imitation learning through combining nonlinear dynamics models with the echo state property and traditional neural network components. We demonstrated that the proposed architec-ture outperforms existing architectures on a LfD benchmark of learning human handwriting mo-tions from demonstration. In particular, our architecture demonstrates predicted trajectories that more closely align with the dynamics of the demonstrations while maintaining competitive latency scores. We also validated the integration of our discrete-time dynamics into more elaborate architec-tures of neural network components and demonstrated the capability of combining the generalisation strengths of neural network components such as the attention mechanism with our dynamics model through learning to draw multiple characters with a single multi-task architecture. A key limita-tion of the current architecture is its convergence, notably in the current experiments the model can in certain cases fails to cease making predictions once it has successfully completed a character drawing task which is in contrast to existing work on learning dynamical system with convergence guarantees, we aim to address this point in future work. Another limitation of the current report is that we have not evaluated the performance of our architecture on real-world tasks involving real hardware, we intend to address this limitation in future work by assessing the performance of the architecture on real-robot manipulation tasks."}, {"title": "A DYNAMICAL SYSTEM PROPERTIES", "content": "Dynamical system properties are a crucial component of our model and the general thesis of this paper; we argue they can be used in the design of temporal inductive biases that are suitable for learning representations. The echo state property of the nonlinear dynamical system we incorporate into our neural network layer is key to the success of our approach. In this section we review the echo state property which is leveraged in our dynamics model and briefly discuss the inductive bias this introduces and how it is well suited to learning representations for modelling temporal data."}, {"title": "A.1 ECHO STATE PROPERTY", "content": "The echo state property defines the asymptotic behaviour of a dynamical system with respect to the inputs driving the system. Given a discrete-time dynamical system F : X \u00d7 U \u2192 X, defined on compact sets X, U where X \u2282 $R^N$ denotes the state of the system and U \u2282 $R^M$ the inputs driving the system; the echo state property is satisfied if the following conditions hold:\n$$x_k := F(x_{k\u22121}, u_k),$$\n$$\u2200u^{+\u221e} \u2208U^{+\u221e}, x^{+\u221e} \u2208 X^{+\u221e}, y^{+\u221e} \u2208 X^{+\u221e}, k \u2265 0,$$\n$$\u2203(\u03b4_k)_{k\u22650}: ||x_k - y_k|| \u2264 \u03b4_k.$$\nwhere $(\u03b4_k)_{k\u22650}$ denotes a null sequence, each $x^{+\u221e}, y^{+\u221e}$ are compatible with a given $u^{+\u221e}$ and right infinite sets are defined as:\n$$U^{+\u221e} := {u^{+\u221e} = (u_1, u_2, ...)|u_k \u2208 U \u2200k > 1}$$\n$$X^{+\u221e} := {x^{+\u221e} = (x_0, x_1, ...)|x_k \u2208 X \u2200k > 0}$$\nThese conditions ensure that the state of the dynamical system is asymptotically driven by the se-quence of inputs to the system. This is made clear by the fact that the conditions make no assump-tions on the initial state of trajectories, just that they must be compatible with the driving inputs and asymptotically converge to the same state. This dynamical system property is especially useful for learning representations for dynamic behaviours as the current state of the system is driven by the control history."}, {"title": "B TRAJECTORY SIMILARITY METRICS", "content": "Trajectory similarity metrics are important for assessing how well predicted trajectories align with expert demonstrations, they also give us a sense of the model's ability to overcome the issue of com-pounding errors when we introduce random noise and perturbations during policy rollouts. In this work, we focus on reproducing the spatial characteristics of expert demonstration trajectories; we choose the Fr\u00e9chet distance as our evaluation metric since it is well suited to the task of assessing the similarity of human handwriting as demonstrated in existing works in handwriting recognition Sriraghavendra et al. (2007); Zheng et al. (2008). In addition, we assess the smoothness of predicted trajectories through computing the mean absolute jerk of the trajectory. Finally through leverag-ing dynamics time warping we compute the Euclidean distance between velocity profiles for the predicted trajectory when compared to the expert demonstration."}, {"title": "B.1 FR\u00c9CHET DISTANCE", "content": "Given a metric space S := (M, d), consider curves C \u2208 S of the form C : [a, b] \u2192 S with a < b. Given two such curves P, Q of this form, the Fr\u00e9chet distance between these curves is formally defined as:\n$$F(P,Q) = inf_{\u03b1,\u03b2} max_{t\u2208[0,1]} {d(P(\u03b1(t)), Q(\u03b2(t)))}$$"}, {"title": "B.2 MEAN SQUARED ABSOLUTE JERK", "content": "Jerk is defined as the rate of change of acceleration. Given a discrete set of points $P_i$ = ($P_0, P_1, ..., P_N$) representing the positions overtime across an individual dimension of a trajectory (e.g. y coordinates), we can approximate the jerk by taking the third order difference, where impor-tantly we assume a fixed timestep \u2206t between positions:\n$$j_i := \\frac{P_{i+3} \u2212 3p_{i+2} + 3p_{i+1} \u2212 P_i}{\u0394t^3}$$\nGiven a set of jerk values across the trajectory we compute the mean squared absolute jerk as a summary metric as follows:\n$$I := \\frac{\\sum_{i=0}^{M} |j_i|^2 }{M}$$"}, {"title": "B.3 DYNAMIC TIME WARPING", "content": "The Dynamic Time Warping (DTW) objective for aligning two time series X = [$x_1, x_2,...,x_n$] and Y = [$y_1, y_2, ..., y_m$] is defined as follows:\n$$DTW(X, Y) = min_{\u03c0\u2208A(X,Y)} \\sum_{(i,j) \u2208 \u03c0} d(x_i, y_j)$$\nwhere d($x_i, y_j$) is a distance metric, A(X, Y) is the set of all admissible warping paths \u03c0 where a warping path is a sequence of index pairs \u03c0 = [(i_0, j_0), (i_1, j_1), . . ., (\u0456_\u043a, \u0458_\u043a)]. For a warping path \u03c0 to be admissible, it must satisfy the following conditions:\n1. Boundary Conditions:\n($i_0, j_0$) = (1, 1) and (\u0456_\u043a, \u0458_\u043a) = (\u043f, \u0442)\nThis ensures that the warping path starts at the first elements and ends at the last elements of both sequences."}, {"title": "C ADDITIONAL EXPERIMENTAL DETAILS", "content": ""}, {"title": "C.1 DATA PREPROCESSING", "content": "As outlined in the main text, we denote a set of M character demonstrations as {$D_j$}$_{j=M}$. From each demonstration $D_j$ we select datapoints corresponding to 2D position coordinates $P_j$ = ($p_1, p_2, ..., p_T$): $p_k$ = ($x_1, x_2$) and split the overall trajectory of 2D coordinates into N sequences of non-overlapping windows of fixed length R. The resulting dataset is {{$P_{j,i}$}$_0^N$}$_{j=M}$ where each $P_{j,i}$ = ($P_{i\u2217R:(i\u2217R)+R}$) is composed of N non-overlapping subsequences from the 2D position trajectory of the demonstration. Within each subsequence we treat the first datapoint $P_i$ as the current state and model input and the proceedings datapoints $P^R_j$ are prediction targets, as a result, all models perform action chunking with a fixed windows size of R \u2013 1."}, {"title": "C.2 MODEL TRAINING", "content": "The proposed neural network layer makes the overall neural network architecture recurrent, there-fore, we train the model in a sequential manner as outlined in Alg 1. In practice, for training effi-ciency we batch sequences of demonstrations, however, for the purpose of outlining the algorithm we demonstrate the individual demonstration case of which the batched case is a generalisation. The convention we adopt for initialising the state of the dynamical system is to initialise it as a vector of zeros $x^T(0)$ = [0, 0, 0, ..., 0]."}, {"title": "C.3 HYPERPARAMETERS AND HYPERPARAMETER TUNING", "content": "The dynamics parameters we optimise include scale of fixed input projection weights, spectral ra-dius, probability of node connections and the leak rate a. In the multitask setting where computa-tional resources limit our ability to run multiple training jobs concurrently, we tune the hyperparam-eters for the dynamics of our model and the baseline ESN using a Bayesian optimisation implemen-tation provided by the Weights and Biases platform. For single task training jobs we perform a grid search over candidate hyperparameter sets. This results in the following set of hyperparameters for the dynamics:"}, {"title": "D QUALITATIVE RESULTS", "content": ""}, {"title": "D.1 SINGLE TASK", "content": ""}, {"title": "D.2 MULTITASK", "content": ""}, {"title": "D.2.1 OURS", "content": ""}, {"title": "D.2.2 ESN", "content": ""}, {"title": "D.2.3 FF", "content": ""}, {"title": "D.2.4 FF+ENSEMBLE", "content": ""}, {"title": "E NOTES ON EXTENSIONS", "content": "A key motivation of this work is to develop neural network architectures that are well suited to producing precise and dynamic motions on real robot hardware. As a result, we briefly note details of extending this work to real robot hardware. Since our neural network model directly predicts position targets, a low-level controller is required to achieve these targets. To extend this work, we intend to couple our proposed approach to learn a visuomotor policy that relies on images and the current robot state information with an impedance controller used to achieve position targets. The impedance controller ensures compliant motions as the robot interacts with its workspace (subject to hardware constraints). We hypothesise that the strengths of our approach demonstrated in the handwriting task will extend to LfD on real robot hardware resulting in the ability to model a greater set of dynamic behaviours with improved reaction speeds to visual feedback.\nIn addition, we realise that this paradigm of incorporating dynamical systems into neural network architectures has a lot of potential in real-world robotics tasks. In this paper we argue that this direction should be explored further through optimising the design of the properties of the dynamical systems being used and how they are integrated into the overall architecture. We are excited to continue to pursue this direction and welcome collaborators interested in these topics."}]}