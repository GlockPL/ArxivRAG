{"title": "On the Completeness of Conflict-Based Search: Temporally-Relative Duplicate Pruning", "authors": ["Thayne T. Walker", "Nathan R. Sturtevant"], "abstract": "A well-known and often-cited deficiency of the Conflict-Based Search (CBS) algorithm for the multi-agent pathfinding (MAPF) problem is that it is incomplete for problems which have no solution; if no mitigating procedure is run in parallel, CBS will run forever when given an unsolvable problem instance. In this work, we introduce Temporally-Relative Duplicate Pruning (TRDP), a technique for duplicate detection and removal in both classic and continuous-time MAPF domains. TRDP is a simple procedure which closes the long-standing theoretic loophole of incompleteness for CBS by detecting and avoiding the expansion of duplicate states. TRDP is shown both theoretically and empirically to ensure termination without a significant impact on runtime in the majority of problem instances. In certain cases, TRDP is shown to increase performance significantly.", "sections": [{"title": "1 Introduction", "content": "The objective of multi-agent pathfinding (MAPF) (Stern et al. 2019) is to find paths for multiple agents to move from their current configurations (or states) to goal states such that their respective paths do not conflict at any time. A conflict occurs when agents' shapes overlap at the same time. In contrast to \"classic\" MAPF with actions of unit duration, real world domains often require the use of continuous-time, non-unit duration actions. In this paper, we seek optimal, conflict-free solutions to the MAPF problem in both classic MAPF and continuous-time MAPF, also known as MAPFR (Walker, Sturtevant, and Felner 2018).\nOptimal MAPF solvers are classified into two broad categories: coupled and decoupled. Coupled algorithms such as multi-agent A* (MA-A*) (Standley 2010), enhanced partial expansion A* (Goldenberg et al. 2014) and M* (Wagner and Choset 2011) solve MAPF problems in a joint state space, where the joint states of all agents are aggregated into a single state. Decoupled algorithms such as CBS (Sharon et al. 2015), ICTS (Sharon et al. 2013), CBICS (Walker et al. 2021), branch-and-cut-and-price (BCP) (Lam et al. 2019) and enhanced variants of these (Gange, Harabor, and Stuckey 2019; Surynek et al. 2016; Li et al. 2019a) solve MAPF problems without aggregating the agents' state spaces together, or by partially aggregating only some of them. In general, decoupled algorithms have a lower practical computational complexity and hence are more popular. CBS is a popular MAPF algorithm. In this paper we focus on the completeness of CBS, but our approach (especially for duplicate detection) is applicable to most coupled and decoupled algorithms for MAPFR.\nA long-standing problem for CBS is that it will run forever if given an unsolvable problem instance (Sharon et al. 2015). The suggested remedy for this is to run a sub-optimal, polynomial-time, complete algorithm (Kornhauser, Miller, and Spirakis 1984; Sajid, Luna, and Bekris 2012; Okumura 2022) in parallel with the main solver. In the case that no solution exists, the polynomial-time algorithm will report this fact, and then CBS can be terminated. But this reliance on a second MAPF algorithm means that CBS is not natively complete. When using CBS for domains other than classic MAPF (e.g., MAPFR), it may be difficult to find or invent a separate, complete algorithm for the desired domain. At this time, no complete algorithms generally applicable to MAPFR are known. In summary, there is a need for making CBS natively complete.\nTemporally-relative duplicate pruning (TRDP) is a novel technique for CBS which can guarantee completeness for classic MAPF and MAPFQ, a subset of MAPFR with discrete rational values. TRDP renders otherwise infinite CBS search spaces finite by detecting and eliminating multi-agent \u201cloops\u201d. TRDP can be applied to virtually any MAPF domain to guarantee completeness. Importantly, the theory of TRDP resolves a long-standing deficiency of CBS. Furthermore, our empirical results show that TRDP correctly detects and terminates on unsolvable MAPF problem instances while having only a small effect on the runtime in a representative set of (solvable) classic MAPF and MAPFQ instances."}, {"title": "2 Problem Definition", "content": "MAPF was originally defined for a \"classic\" setting (Stern et al. 2019) where the movements of agents are coordinated on a two dimensional grid, usually represented as a graph \\(G=(V, E)\\). In classic MAPF, edges have a unit time duration and agents occupy a point in space. This paper uses the definition of MAPFR (Walker, Sturtevant, and Felner 2018), a variant of MAPF for continuous time execution where G is a weighted graph which (unlike grids) may be non-planar, meaning edges may intersect in areas other than vertices. Every vertex \\(v \\in V\\) has coordinates in a metric space and every edge \\(e \\in E\\) has a positive real-valued edge weight \\(w(e) \\in \\mathbb{R}^+\\). This includes self-directed edges for wait actions. MAPFQCMAPFR uses only positive, rational-valued edge weights \\(w(e) \\in \\mathbb{Q}^+\\). Weights usually represent the times it takes to traverse edges, but cost and time duration can be treated separately. In MAPF there are k agents and each agent is assigned a start and a goal vertex \\(V_s={start_1, .., start_k} \\subseteq V\\) and \\(V_g={goal_1,.., goal_k} \\subseteq V\\) such that \\(start_i \\neq start_j\\) and \\(goal_i \\neq goal_j\\) for all \\(i \\neq j\\).\nA solution to a MAPFR (MAPFQ) instance is \\(\\Pi={\\pi_1, .., \\pi_{\\kappa}}\\), a set of single-agent paths composed of states. A state \\(s=(v, t)\\) is composed of a vertex \\(v \\in V\\) and a time \\(t \\in \\mathbb{R}^+\\) (\\(t \\in \\mathbb{Q}^+\\)). A single-agent path is a sequence of d+1 states \\(\\pi_i=[s_0, .., s_d]\\), where \\(s_0=(start_i, 0)\\) and \\(s_d=(goal_i, t_g)\\) where \\(t_g\\) is the time the agent arrives at its goal and all vertices in the path traverse edges in E. Costs and time steps are always monotonically increasing in a path because edge costs are always greater than zero.\nAgents have a shape, (e.g., a circle or polygon), which is situated relative to a reference point (Li et al. 2019b). Agents move along edges from a vertex to an adjacent vertex, and could use constant or variable velocity in the metric space. A conflict happens when two agents perform actions (by either waiting or traversing edges) which results in their shapes overlapping simultaneously. We seek a feasible solution, which has no conflicts between any pairs of paths in \\(\\Pi\\). MAPF solvers typically optimize for minimum makespan or minimum flowtime. Optimization of classic MAPF, MAPFQ and MAPFR is NP-hard (Yu and LaValle 2013)."}, {"title": "3 Background and Motivation", "content": "Decoupled, search-based algorithms for MAPFR include sub-optimal ones (Silver 2005; Jansen and Sturtevant 2008; Yakovlev and Andreychuk 2017; Cohen et al. 2019) and optimal ones (Walker, Sturtevant, and Felner 2018; Andreychuk et al. 2019; Walker, Sturtevant, and Felner 2020; Walker et al. 2021; Andreychuk et al. 2021; Copp\u00e9 and Schaus 2022; Walker 2022), but none of them will terminate when no solution exists for the problem instance. Recall that completeness means that an algorithm is guaranteed to terminate in a finite amount of time. There are two parts to completeness (Edelkamp and Schrodl 2011):\n1. Termination with a solution if one exists.\n2. Termination with if a solution does not exist.\nThe proof for part 1 in classic MAPF and MAPFR has been shown repeatedly for CBS (Sharon et al. 2015; Li et al. 2019b; Walker, Sturtevant, and Felner 2020). Significantly, part 2 has been shown to be a problem for CBS and other decoupled algorithms (Sharon et al. 2015; Walker 2022). In fact, these algorithms will run forever given an unsolvable problem instance if another complete algorithm is not run in parallel. Even a simple unsolvable instance like the one shown above will cause CBS to run forever.\nBecause agents can take actions such as waiting or moving back and forth without coming into conflict, the high-level search tree grows infinitely. The reason for this infinite growth is related to the inclusion of time in the state space. Time is typically part of the state space in MAPFR and decoupled algorithms, but not necessarily coupled classic MAPF algorithms. Adding the time dimension to a finite map like the one in Figure 1 makes the state space infinite since each time step is distinct and agents can wait in place forever. Special attention to duplicate detection is necessary to make the search space finite.\nWe again emphasize that no complete, polynomial-time solvers for MAPFR are known at this time. This means that the strategy of running a separate polynomial-time algorithm in parallel to determine solvability of a MAPFR instance is not currently an option. Figure 2 illustrates a phenomenon that is introduced by MAPFR, that agents can conflict in ways that are undefined in Classic MAPF. Although the classic MAPF instance with point agents in Figure 2(a) is solvable, the MAPFR instance in Figure 2(b) is not. Because of this phenomenon (and others related to non-planar graphs and non-unit costs), one cannot simply analyze the graph of a MAPFR instance, nor run a classic polynomial-time MAPF solver on the graph to determine solvability."}, {"title": "4 Completeness of CBS", "content": "Before discussing the completeness of CBS, it is worth mentioning that in popular MAPF benchmark sets (Stern et al. 2019) there are no unsolvable problem instances. Generally speaking, unsolvable instances are often hand-crafted, and (depending on the domain) tend to be very rare. Our purpose here is not to make CBS scale to larger problem instances, but to close the question of completeness by adding functionality to CBS so that it is natively complete for classic MAPF, and identify an approach to completeness adequate for MAPFR as well.\nAside from duplicate pruning, CBS could be made complete by first computing the theoretical upper bound on the size of the CT for a problem instance, and then forcing CBS to terminate once the CT grows beyond that upper bound.\nThe total number of unique states in all possible paths of cost C for a single agent in a Classic MAPF instance can not exceed the lesser of \\(C^3\\) and \\(|V|^C\\), where C is the makespan of the lowest-cost solution (Gordon, Filmus, and Salzman 2021). Hence the total number of unique multi-agent states in all possible solutions is bounded by the lesser of \\((C^3)^k\\) and \\((|V|^C)^k\\). A similar bound for MAPFR does not exist because the number of unique times for states in a path is infinite. However, for MAPFQ, the bound is \\((Cr)^{3k}\\) or \\((|V|Cr)^k\\). Where \\(r \\in \\mathbb{Q}^+\\) is the inverse resolution of time (e.g., r=100 for a resolution of 1/100). Note, r=1 for Classic MAPF.\nIt has been shown that the makespan, C, for a solvable MAPF instance is O(\\(|V|^3\\)) (Kornhauser, Miller, and Spirakis 1984). Substituting for C, we find that CBS can immediately terminate when the CT reaches a size of \\(2^k(|V|r)^k\\). This approach trivially makes CBS complete. However, this simple approach is not practical. For the example instance in Figure 1, where the red agent must swap places with the blue agent, CBS could not terminate safely until generating a CT of size \u039f\\((2^{2*34})\\).\nThis is often worse than running a coupled algorithm like A*, which (with proper duplicate detection) would terminate after O\\((|V|^{4*})\\) expansions. This is because a coupled algorithm in Classic MAPF doesn't have to keep track of time, just the relative locations of the agents. If A* were to include time in the duplicate detection (as it usually must for continuous-time MAPF), it too would be incomplete. Neither of these bounds (for A* and CBS) are tight because most of the multi-agent state space is not reachable. For the example instance in Figure 1, only 3 unique states would be expanded in total by A* before termination.\nThe number of high-level expansions with TRDP is finite, but still has the same upper bound for CBS (on a solvable problem instance) without TRDP. However, with TRDP, the actual search space may theoretically be"}, {"title": "5 Mechanics of Duplicate Detection", "content": "Duplicate pruning is a technique commonly used with search algorithms in graphs with cycles in order to eliminate exploring sub-optimal paths with loops (Taylor 1997). A loop happens when a path visits the same state twice. It is trivial to see that any path with a loop is sub-optimal because concatenating the portions of the path before and after the loop results in a shorter path to the goal.\nIn MAPF, single-agent loops may be necessary a feasible solution may correctly contain many agents visiting the same vertex more than once (for example when one agent waits for another), however, k-agent loops can be a source of incompleteness. For CBS and many other algorithms that include the time dimension as a part of the state, loops are not recognized by comparing states since revisiting a state (in a multi-agent sense) happens at a different time.\nTemporally-relative duplicate pruning (TRDP) defines temporally-relative duplicate (TRD) detection which allows the removal of states which have been visited before in a temporally-relative sense.\nWe define TRD formally as follows: Let \\(S={s_1,.., s_k}\\) be a joint-state composed of k single-agent states. All single-agent states are not required to to have identical times in S, but in our definition, the respective actions taken to arrive at S, must have time overlap. Specifically, for each single-agent action \\((s_i, S_i)\\) for \\(S_i \\in \\hat{S}\\) and \\(s_i \\in S\\) where \\(\\hat{S}\\) is the ancestor of S, must have time overlap with every other action \\((s_j, S_j)\\):\n\\[S_i.t \\leq s_j.t \\leq S_i.t\\]\nor\n\\[S_j.t \\leq s_i.t \\leq S_j.t\\]\nTo define a TRD S' of S, we first define \\(t_{min}(S)\\) to be the earliest single-agent time of S:\n\\[t_{min}(S) = MIN_{s_i.t \\atop s_i \\in S}\\]\nNext, we define a joint-state temporal adjustment function \\(\\Delta_t(S)\\), which adjusts the time component of all single-agent states in S to be relative to \\(t_{min}(S)\\):\n\\[\\Delta_t(S) = {\\forall s_i \\in S; (s_i.v, s_i.t \u2013 t_{min}(S))}\\]\nS', a descendant of S, is a TRD of S iff the vertex part of the states are identical and the temporally-relative times are identical. That is: \\(\\Delta_t(S) = \\Delta_t(S')\\). For example, from Figure 1 we could have a joint state S = \\({(A_1,0.1), (A_3, 0.2)}\\). Thus, \\(t_{min}(S) = 0.1\\), and therefore \\(\\Delta_t(S) = {{(A_1,0.0), (A_3, 0.1)}\\). Supposing another state S' = \\({(A_1, 0.2), (A_3, 0.3)}\\), then \\(\\Delta_t(S') = {{(A_1, 0.0), (A_3,0.1)}\\). Because \\(\\Delta_t(S) = \\Delta_t(S')\\), S' is a TRD of S."}, {"title": "6 Duplicate Pruning in CBS", "content": "Our discussion will now focus on the implementation of TRDP in CBS (Sharon et al. 2015). First, we explain the CBS algorithm, then we explain the TRDP implementation. Pseudocode for the CBS algorithm is shown in Algorithm 1 with changes for TRDP on line 6.\n6.1 CBS\nCBS searches a conflict tree (CT) where each node N contains a solution N.\\(\\Pi\\). The root node contains paths for each agent without taking the paths of other agents into account (line 3). N.\\(\\Pi\\) may contain conflicts, and CBS will detect conflicts between the paths in N.\\(\\Pi\\) (line 8). If any conflict exists between the paths for agents i and j, two child nodes \\(N_i\\) and \\(N_j\\) are generated, one for each agent in conflict. Each child node contains a new constraint for a single agent to avoid the conflict (line 15).\nMany different types of constraints are possible. For example, a vertex constraint c = (i, v, t) blocks agent i from entering vertex v at time t. Taking constraints for \\(N_i\\) and all its ancestors into account (line 14), \\(\\pi_i \\in N.\\Pi\\) is re-planned (line 16) to respect the new constraints (and consequently avoid the conflict with agent j). This process is done analogously for agent j. In any case that the agent cannot reach its goal in the context of all constraints (i.e., over-constrained) the CT node is pruned (line 17). Eventually, after enough constraints are accumulated, CBS will find a feasible solution iff one exists.\nA partial example of a CT is shown in Figure 4. The root node contains shortest paths to the goal and child nodes resolve conflicts by adding constraints to one agent or the other, which in this case causes the agents to wait. In the figure, an arrow (\\(\\leftarrow\\)) means an action that moves the agent to an adjacent node, and a looped arrow (O) means a wait action. A wait action at the goal is shown with a box around it. The pruning shown with 'X's in the figure is due to TRDP and will be discussed later. The search stops when a conflict-free solution is found in the node with a green border.\n6.2 CBS+TRDP\nAs previously mentioned, any solution containing a k-agent loop is sub-optimal. Since CBS is an optimal algorithm, a solution containing a k-agent loop in a CT node can be treated similar to an infeasible solution. Therefore, TRDP introduces a new type of conflict called a temporally-relative duplicate conflict or TRD conflict. A TRD conflict occurs when a temporally-relative k-agent loop exists in a solution N.\\(\\Pi\\). Thus, in addition to detecting traditional motion conflicts between pairs of agents (see Algorithm 1 line 8), CBS+TRDP detects TRD conflicts (Algorithm 1 line 6) using the approach defined in the previous section (Algorithm 2).\nIn response to a TRD conflict, TRDP generates k constraints, one for each agent, which causes CBS to generate k child nodes \\(N_1, ..., N_k\\), such that each child node \\(N_i\\) contains a TRD constraint. A TRD constraint is a tuple (i, [\\(t_{start}\\), \\(t_{end}\\)), \\(t_{offset}\\)), where i is the agent number, [\\($t_{start}\\), \\($t_{end}\\))] is a time range in which states are considered to be a loop-start candidate state, and \\($t_{offset}\\) is an exact time offset from a loop-start candidate. For example, a TRD constraint of: (i, [0.1, 0.3), 0.4), means that for agent i, any state in the time range [0.1, 0.3) will be considered a loop-start candidate, and any descendant state at the same vertex with an exact time offset of 0.4 is considered a duplicate.\nThus, a TRD constraint enforces the rule that the agent being re-planned at the low level will avoid all states s', which are duplicates of any loop-start candidate s, such that s.t\\(\\in\\) [\\(t_{start}\\), \\(t_{end}\\)), s.v=s'.v and s'.t=s.t+ \\($t_{offset}\\). For example, during low-level planning, given a TRD constraint of: (i, [0.1, 0.3), 0.4), if the agent's path were to visit the loop-start candidate s=(v, 0.2), it would not be allowed to visit s'=(v, 0.6) because it visits the same vertex at the exact offset time.\nThe expansion routine for the low-level A* search is shown in Algorithm 3. During the expansion, for any loop-start candidate, we add a TRD list to search nodes that contains a list of TRD pairs (line 18). Each TRD"}, {"title": "7 Theoretical Analysis", "content": "We now show that CBS+TRDP is optimal and complete. First, we show that k-agent loops are sub-optimal. Second, resolving them using TRD constraints can never block an optimal, feasible solution. Finally, that if the problem instance is unsolvable, TRDP guarantees termination.\nDefinition 1. Over-constrained: A CT node is over-constrained when a solution cannot be found in its sub-tree due to a constraint or collection of constraints which blocks a solution.\nDefinition 2. Loop: A loop occurs when a single agent visits the same vertex more than once in its path. This includes waiting in place for one or more actions.\nLemma 3. An optimal path cannot contain a loop.\nProof. An optimal path cannot contain a loop because a shorter path can always be obtained by concatenating the sub-path before the loop to the sub-path after the loop. \nCorollary 4. By extension of Lemma 3, if a solution has a temporally-relative k-agent loop, the solution must be sub-optimal.\nNow that we have shown that TRDs are sub-optimal, we show that pruning them with TRDP never precludes an optimal solution.\nLemma 5. CBS+TRDP only eliminates sub-optimal or infeasible solutions.\nProof. Let N be a CT node for which N.\\(\\Pi\\) contains a k-agent loop. N.\\(\\Pi\\) is sub-optimal per Lemma 3. Consider all optimal solutions which can be reached on a path in the CT:\n1. There is no path through N to an optimal solution.\n2. There is a path through N to an optimal solution.\nFor case (1), either some agents are over-constrained in N, or there is no solution to the problem instance in general. Since an optimal solution is not reachable through N, any actions blocked by \\(c_i\\) have no effect on finding an optimal solution in the sub-tree of N.\nThe proof for case (2) is very similar to the original proof for CBS. In this case, it is certain that at least one of the single-agent loops must be avoided in an optimal solution, thus at least one \\(c_i\\) added to one of the child nodes \\(N_i\\) in the k-way split (based on the k TRD constraints generated in Algorithm 1 line 6) must be correct. If any \\(c_i\\) is incorrect (blocks an optimal solution) then that solution is guaranteed to be found in at least one sibling node of \\(N_i\\). By contradiction, if the optimal solution is blocked in every sub-tree, then either N is already over-constrained (contradicting our assumptions) or a TRD can exist in an optimal solution, but this violates Lemma 3.\nIn summary, TRDP either prunes unsolvable sub-trees, or the optimal solution is guaranteed to lie in at least one sub-tree of the child nodes of N. \nNext, we show that TRDP guarantees termination.\nLemma 6. TRDP renders the search space of CBS finite for Classic MAPF and MAPFQ.\nProof. Let E, the set of edges of G, be finite. Let \\(W \\in \\mathbb{Q}\\) be the set of edge weights for E. W must be finite. Recall that duplicate detection is performed based on a transformed form of S via the function \\(\\Delta_t(S)\\). This is done by subtracting \\($t_{min}(S)\\) from the time (s.t) of each single-agent state in S. The range of \\(t_{min}(S)\\) consists of combinations of multiples of W, hence the maximum number of unique times in the range of \\(\\Delta_t(S)\\) is O(MAX(W)/GCD(W)), where GCD is the greatest common denominator of floating point numbers. Because \\(W \\in \\mathbb{Q}\\), GCD(W) is well-defined and the range of times for \\(\\Delta_t(S)\\) is finite. Since the range of times for \\(\\Delta_t(S)\\) is finite, and V is finite, the range of \\(\\Delta_t(S)\\) is finite.\nIn summary, although the domain of S is infinite because there is no upper bound on the domain of s.t, CBS+TRDP performs duplicate detection on \\(\\Delta_t(S)\\) which has a finite range, therefore the search space of CBS+TRDP is finite. \nFinally, we combine Lemmas 5 and 6 to show that CBS+TRDP is optimal and complete.\nTheorem 7. CBS+TRDP is optimal and complete.\nProof. Per Lemma 5, CBS+TRDP only eliminates sub-optimal and infeasible solutions. Since CBS searches the CT in a best-first fashion, and optimal solutions cannot be eliminated by TRDP, CBS+TRDP is optimal. Per Lemma 6, TRDP makes the search space finite. Therefore, the size of the CT has a finite upper bound. Hence, CBS+TRDP is guaranteed to terminate, regardless of whether the problem instance is solvable."}, {"title": "8 Bypassing TRD Splits", "content": "In settings where the number of agents is large compared to the size of the graph (agent-dense settings), many TRDs can occur, resulting in many k-way splits in the CT. This can lead to a very large CT and cause a significant amount of work. Our experiments showed that TRDP often reduces the depth in the CT at which a solution is found when compared to regular CBS in agent-dense settings. However, the average branching factor is increased. Thus TRDP usually causes a significantly larger CT to be generated when compared with regular CBS.\nFortunately, the k-way split can be completely avoided in many cases. The procedure to do so is simple and is based on the bypass procedure for regular CBS (Boyarski et al. 2015). When a TRD is found, we test each agent individually for a bypass by adding a TRD constraint and re-planning its path. If the agent is able to find an alternate path that (1) avoids the loop, (2) does not increase the path cost, and (3) does not incur more conflicts, this path is a bypass. Upon finding a bypass, we replace \\(\\pi_i \\in N.\\Pi\\) with the bypass in the parent node N. Then N is re-inserted into the OPEN list. If we fail to find a bypass, the results of this computation (each \\(c_i\\) and corresponding re-planned paths) are used to generate the k successor nodes.\nWe found that this simple procedure, on average, avoided up to 99% of k-way splits for agent-dense, solvable instances. We now prove that the TRDP bypass procedure preserves optimality and completeness.\nTheorem 8. CBS+TRDP with the bypass procedure is optimal and complete.\nProof. Let N be a CT node containing a TRD in N.\\(\\Pi\\). If a bypass is found, N.\\(\\Pi\\) is fixed with a new \\(\\pi_i\\) to avoid the TRD to create N', and N' is inserted into OPEN. Per the bypass procedure, the cost of N'.\\(\\Pi\\) is not increased nor decreased, hence does not change the optimality properties of CBS+TRDP. No constraints are added to N', hence it is impossible to block any optimal or feasible solution in the sub-tree of N'. Therefore, the completeness properties of CBS+TRDP are preserved. In summary, adding the bypass procedure to CBS+TRDP retains optimality and completeness as shown in Theorem 7."}, {"title": "9 Empirical Results", "content": "We preface this section by reminding the reader that the primary intent of TRDP is to make CBS natively complete, not necessarily to scale to larger problems. Depending on the domain, the probability of encountering an unsolvable instance may be low. (None of the MAPF benchmark set contain unsolvable problem instances.) Additionally, the probability of encountering k-agent loops during the search may be low. In our investigation, we found that the probability of encountering TRDs during the search is rare in typical problem instances. When running all grid MAPF benchmark problems (Stern et al. 2019), less than 0.01% of problem instances triggered the TRDP logic. The most common encounter of TRDs was in small mazes with corridor widths of 1 (an agent-dense setting).\nFortunately, although problem instances which actually exercise TRDP logic may be relatively rare in practice, its inclusion in CBS has many benefits. Foremost, it ensures completeness for CBS in both MAPF and MAPFQ settings. Second, TRDP has the ability to prune portions of the high-level search which are unsolvable. Finally, including TRDP it is relatively inexpensive. The complexity of detecting TRDs in a solution is O(\\(kC^2\\)) where C is the makespan of a solution. The expense is normally mitigated further because the occurrence of single-agent loops is also relatively rare, meaning the TRD check usually exits early (see Algorithm 2 line 3 and line 5).\nIn this section we show two things: (1) that TRDP has performance benefits for hand-crafted examples with high agent density and (2) that TRDP incurs no significant cost for MAPF instances in general.\nWe ran CBS with TRDP for the entire set of MAPF benchmarks on 4-, 8-, 16- and 32-neighbor grid domains (Rivera, Hern\u00e1ndez, and Baier 2017). Note that 4-neighbor grids are classic MAPF instances, but the other domains with higher connectivity are MAPFQ instances. Our tests start with two agents and increase the number of agents by one until the problem instance is no longer solvable in under 30 seconds. We recorded the runtimes and the total number of agents for which we could solve within the 30 second time limit. Additionally, we counted the number of times that TRDs occurred in any CT node in this process.\nOver the nearly 32,000 experiments and millions of CT nodes generated, only 29 TRDs were ever encountered. Most TRDs were found to occur in settings with narrow corridors. These have high agent density per the"}, {"title": "10 Conclusion", "content": "We have introduced temporally-relative duplicate pruning (TRDP), a technique for decoupled MAPF and MAPFQ algorithms for guaranteeing completeness. TRDP solves a long-standing problem for CBS by making CBS natively complete. We have also shown theoretically and empirically that TRDP has desirable properties for MAPF algorithms, namely, increased efficiency for agent-dense settings and completeness guarantees. TRDP adds these benefits while adding no significant computational overhead."}]}