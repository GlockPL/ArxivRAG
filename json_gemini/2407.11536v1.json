{"title": "Fine-Tuning Medical Language Models for Enhanced Long-Contextual Understanding and Domain Expertise", "authors": ["Qimin Yang", "Rongsheng Wang", "Jiexin Chen", "Runqi Su", "Tao Tan"], "abstract": "Large Language Models (LLMs) have been\nwidely applied in various professional fields. By\nfine-tuning the models using domain specific ques-\ntion and answer datasets, the professional domain\nknowledge and Q&A abilities of these models\nhave significantly improved, for example, medical\nprofessional LLMs that use fine-tuning of doctor-\npatient Q&A data exhibit extraordinary disease di-\nagnostic abilities. However, we observed that de-\nspite improvements in specific domain knowledge,\nthe performance of medical LLM in long-context\nunderstanding has significantly declined, espe-\ncially compared to general language models with\nsimilar parameters. The purpose of this study is\nto investigate the phenomenon of reduced perfor-\nmance in understanding long-context in medical\nLLM. We designed a series of experiments to con-\nduct open-book professional knowledge exams\non all models to evaluate their ability to read long-\ncontext. By adjusting the proportion and quantity\nof general data and medical data in the process of\nfine-tuning, we can determine the best data com-\nposition to optimize the professional model and\nachieve a balance between long-context perfor-\nmance and specific domain knowledge.", "sections": [{"title": "1. Introduction", "content": "LLMs have demonstrated excellent performance in multi-\nple professional fields, they have exhibited powerful un-\nderstanding and generation capabilities in natural language\nprocessing (NLP) tasks by absorbing massive amounts of\ngeneral data and specialized domain data. However, despite\nsignificant progress in domain-specific knowledge mastery,\nthese models tend to suffer from a decline in long-context\nunderstanding and instruction following abilities. This phe-"}, {"title": "2. Related Work", "content": "LLMs are one of the major breakthroughs in the field of arti-\nficial intelligence in recent years. These models utilize deep\nlearning techniques, especially neural networks based on the\nTransformer architecture(Vaswani et al., 2017), and can be\ntrained on massive amounts of data, thus possessing a power-\nful ability to generate and understand natural language. The\nemergence of LLMs marks an important milestone in NLP\ntechnology, which not only excels in traditional applications\nsuch as generating natural language text, automatic trans-\nlation, and text summarization(Radford et al., 2019), but\nalso demonstrates great potential in emerging areas such as"}, {"title": "3. Methodology", "content": "We designed an evaluation method to test the model's con-\ntextual capabilities and instruction following capabilities\nthat shown in figurel. We have collected some Chinese\nmedical exams, including physician exams, nursing exams,\npharmacist exams, medical technology exams, professional\nknowledge exams and medical postgraduate exams, and\nuse these exams to test the model, all these exams are con-\nducted in a single choice or multiple choice format. But\nunlike other studies that directly test the model, we input\nthe relevant knowledge required to answer the question as a\nprompt to the model at the same time as the question, and\nthen require the model to answer only based on the given\ninformation and directly output the correct option.\n\nThe relevant fine-tuning datasets we collected include both\nthe publicly available Alpaca Chinese dataset and a large\nnumber of Chinese and Western medicine datasets we col-\nlected ourselves and sampled from them. Both are Q&A\ndatasets, with each sample containing instructions, input,"}, {"title": "4. Experiments", "content": "4.1. General Model Exam\n\nFirstly, we tested some general LLMs that can be publicly\nused online for daily Q&A purposes. The results show that\nthe context ability and instruction following ability of the\ngeneral LLMs are both good, with the majority of testing\naccuracy reaching over 50%. Their performance depends not\nonly on the number of parameters and architecture inherent\nin the model itself, but also on their training methods and\ndata. Models trained with multiple rounds of dialogue or\nlong contextual dialogue can achieve excellent results in\nthis test."}, {"title": "4.2. Medical Model Exam", "content": "We selected some medical LLMs from the Medical Bench-\nmark in Chinese (CMB)(Wang et al., 2023c) list for the\nsame test, all of which were able to achieve excellent results\nin the CMB professional medical proficiency test. Based on\nthe test re-\nsults, we found that the results of medical LLM (especially\nmodels with better medical capabilities) were relatively un-\nsatisfactory compared to general models. It is worth noting\nthat HuatuoGPT-II has excellent medical abilities among\nthese tested models, but the average accuracy rate of the\nopen book exam is only 4.37%, far lower than other mod-\nels, meanwhile, during the process of using PULSE, we\nfound that it often relies on multiple rounds of dialogue to\nobtain more information for more accurate diagnosis. Long-"}, {"title": "4.3. Fine-tuning with general data", "content": "In order to explore the potential improvement of the long-\ncontext understanding ability of medical LLMs by general\ndata, we first fine-tune medical LLMs that we tested in the\nprevious section by using the general data that mentioned\nabove. After fine-tuning, we gave these models the same\nopen-book exam as before to evaluate their improvement\nin long-context understanding and instruction following\nabilities. The results indicate that fine-\ntuning with general data did indeed bring improvements.\nMeans that general data can improve the contextual under-\nstanding ability of medical LLMs. This is most evident in\nHuatuoGPT-II, which basically has the strongest medical\nability among these models. It uses a large amount of medi-\ncal question and answer data for fine-tuning, which makes\nits ability to understand long-context insufficient. Once it\nis fine-tuned with general data for a second time, its ability\nto read long-context can be greatly improved. This also\nindicates proves that there is almost a trade-off between\ncontextual reading ability and professional ability, and more\nattention needs to be paid to the use of general data in model\nfine-tuning. On the contrary, models that have achieved\nexcellent results in previous tests may have a decline issue.\nWhen these models were first fine-tuned, they focused on"}, {"title": "4.4. Fine-tuning with different data composition", "content": "Based on the above knowledge, we believe that general data\nplays a crucial role in the fine-tuning process of medical\nprofessional models. Therefore, we designed a second ex-\nperiment to investigate the impact of different mixing ratios\nof general data and medical data on the performance of LLM\nfine-tuning. The experimental subjects are different param-\neter versions of the Qwen1.5 model. The reason for using\nQwen1.5 is that it has various parameter values to demon-\nstrate the general properties of mixed proportion training\nin models with different levels of parameters. We have\nprepared training datasets with different mixing ratios, in-\ncluding a certain proportion of general and medical data. For\neach parameter size model, we use these mixed datasets for\nfine-tuning separately. After fine-tuning, we conducted the\nsame medical open-book exam on each model to evaluate\ntheir performance in understanding context and following\ninstructions.\n\nThe result shows in table4, it indicates that a basic trend is\nthat the higher the proportion of general data, the better the\nperformance of each model in the open-book exam. This\nfinding shows the importance of general data in improving\nthe model's long-context understanding and instruction fol-\nlowing capabilities, and it is recommended to retain a certain\nproportion of general data when fine-tuning professional\nmodels to maintain comprehensive language understanding\ncapabilities. We believe that the reason for this phenomenon\nis that data in the medical field is usually more professional,\ncovering relatively narrow content and form, while general\nquestion and answer data usually covers a wider range of top-\nics and language forms, including more complex structures\nand diversity in natural language communication, allowing\nmodels to learn a wider range of contextual understanding\nabilities."}, {"title": "4.5. Fine-tuning with different data quantity", "content": "Furthermore, within the scope of exploring the impact of\ndata volume effects on specific models in the medical field,\nwe focused on the Qwen1.5-7B model, especially in pure\nmedical data application scenarios, and conducted in-depth\nanalysis. The choice of Qwen1.5-7B as the basic model\nfor research is mainly due to its moderate parameter scale,\nwhich facilitates the observation of the direct impact of data\nvolume changes on model performance, and also does not\ncause over-fitting due to insufficient model parameters or\nexcessive data volume. In order to construct this analytical\nframework, we systematically prepared a series of medical\ndatasets, gradually expanding the data size from 10k Q&A\npairs to 200k, aiming to discover the trend of the impact of\nprofessional data on the model's contextual reading ability.\nConsidering the wide and diverse nature of the medical field,\nwe have specifically included Q&A pairs from traditional\nChinese medicine and Western medicine in our dataset, with\na balanced ratio set at 1:1 to address different types of exam\nquestions. Subsequently, using these medical datasets of\ndifferent scales, we fine tuned the Qwen1.5-7B model and\nunderwent the same open-book examination as before to\nevaluate the impact of different data volumes on model\nperformance.\n\nThe experimental results shows in table5 reveal an impor-\ntant phenomenon: in the early stage of limited data size,\nthe increase or decrease in data volume has a significant"}, {"title": "5. Conclusion", "content": "Through a series of experiments, we explored the impact of\nthe ratio and the amount of general data to medical data on\nthe context understanding and instruction following abili-\nties of medical LLMs. Finding that general LLMs perform\nwell in long-context understanding and instruction follow-"}]}