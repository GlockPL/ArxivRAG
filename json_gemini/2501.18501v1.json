{"title": "Beyond Prior Limits: Addressing Distribution\nMisalignment in Particle Filtering", "authors": ["Yiwei Shi", "Jingyu Hu", "Yu Zhang", "Mengyue Yang", "Weinan Zhang", "Cunjia Liu", "Weiru Liu"], "abstract": "Particle filtering is a Bayesian inference method and a fundamental tool in state esti-\nmation for dynamic systems, but its effectiveness is often limited by the constraints\nof the initial prior distribution, a phenomenon we define as the Prior Boundary Phe-\nnomenon. This challenge arises when target states lie outside the prior's support,\nrendering traditional particle filtering methods inadequate for accurate estimation.\nAlthough techniques like unbounded priors and larger particle sets have been pro-\nposed, they remain computationally prohibitive and lack adaptability in dynamic\nscenarios. To systematically overcome these limitations, we propose the Diffusion-\nEnhanced Particle Filtering Framework, which introduces three key innovations:\nadaptive diffusion through exploratory particles, entropy-driven regularisation to\nprevent weight collapse, and kernel-based perturbations for dynamic support ex-\npansion. These mechanisms collectively enable particle filtering to explore beyond\nprior boundaries, ensuring robust state estimation for out-of-boundary targets. The-\noretical analysis and extensive experiments validate framework's effectiveness,\nindicating significant improvements in success rates and estimation accuracy across\nhigh-dimensional and non-convex scenarios.", "sections": [{"title": "Introduction", "content": "Particle filtering has become an essential tool in state estimation for dynamic systems, with widespread\napplications in fields such as target tracking Djuric et al. (2008), robotics Thrun (2002a), and sensor\ndata fusion Caron et al. (2007). At its core, particle filtering operates by maintaining a set of weighted\nparticles that approximate the posterior distribution of the system's state. Despite its effectiveness,\nparticle filtering faces significant limitations due to the dependence on the initial prior distribution. In\nthis study, we introduce the Prior Boundary Phenomenon (PBP), a term we define to describe how\nthe particles' support range is restricted to the region defined by the prior, rendering states outside this\nboundary inaccessible. To the best of our knowledge, this study is one of the first to systematically\nidentify and analyse this phenomenon within the context of particle filtering\nThis limitation becomes particularly evident when considering the sample efficiency of particle\nfiltering, which heavily depends on the initial prior distribution. The Prior Boundary Phenomenon\nconfines particles to the region defined by the prior, significantly restricting their ability to explore\nand estimate states beyond this boundary. Such constraints are especially critical for tasks where\nthe target state lies outside the support of the prior."}, {"title": "Related Work", "content": "Prior Region Misalignment in Bayesian Inference: The effectiveness of particle filtering relies\nheavily on the alignment between the prior distribution and the true target state. Historically,\nmisaligned priors have led to biased state estimations, a challenge highlighted by foundational works\nSteel (2010); Kruschke (2010). Traditional techniques, such as importance sampling Ristic (2013),\noperate effectively within prior boundaries but fail for states beyond the initial support. Methods\nlike adaptive particle filters Fox (2001) and hybrid resampling strategies Douc & Capp\u00e9 (2005) have\nsought to address sample efficiency but remain limited in their ability to dynamically adapt.\nBayesian Inference of Prior Boundary Phenomena: The Prior Boundary Phenomenon, formalised\nin this work, extends insights from particle filtering's recursive limitations Doucet et al. (2000).\nTraditional methods, including the bootstrap filter Gordon et al. (1993a), confine particles within\nthe prior's initial support. This limitation has been underscored in dynamic contexts such as robot\nlocalisation Thrun (2002b) and sensor fusion Candy (2016), where prior misalignment impacts perfor-\nmance. However, these methods focus on local mismatches and fail to address global misalignment\nor adaptive boundary expansion.\nBayesian Inference in Out-of-Distribution Problems: Out-of-distribution (OOD) problems repre-\nsent a critical challenge for Bayesian inference, as they require models to generalise beyond prior\nknowledge. Advances such as Posterior Networks Charpentier et al. (2020) and Bayesian OOD de-\ntection with uncertainty exposure Wang & Aitchison have addressed OOD detection in classification\ntasks but are less effective in sequential estimation. Traditional particle filtering methods, such as\nRao-Blackwellised filters Li et al. (2004) and model-switching approaches Moradkhani et al. (2005b),\ndemonstrate limited adaptability to OOD scenarios."}, {"title": "Peliminaries", "content": null}, {"title": "Mathematical Description of Particle Filtering", "content": "Particle filtering is a sequential Bayesian estimation technique designed to approximate the posterior\ndistribution of dynamic systems, $P(x_t|Y_{1:t})$, where $x_t$ represents the latent state at time t and $Y_{1:t}$\nrepresents the sequence of observations up to time t. The method operates by maintaining a set of\nweighted particles $\\Theta_t = \\{x_t^{(i)}, w_t^{(i)}\\}_{i=1}^N$, which provide a discrete approximation to the posterior"}, {"title": "Prior Boundary Definition in Particle Filtering", "content": "In particle filtering, the effectiveness of state estimation is fundamentally constrained by the prior\ndistribution, which determines the initial support range of particles. This subsection formalises key\nconcepts relevant to the prior boundary and its role in particle filtering:\nDefinition 3.1 (Prior Boundary). The prior boundary is the region of the state space where the prior\ndistribution $P(x_0)$ has non-zero probability. Mathematically, it is defined as:\n$S_{prior} = \\{x \\in X : P(x_0) > 0\\}$,\nwhere $X$ denotes the entire state space. The prior boundary $S_{prior}$ defines the initial region of interest\nthat particles can explore at time t = 0.\nDefinition 3.2 (Support Range). The support range at time t, denoted as $S_t$, represents the subset\nof the state space where the particle distribution has non-zero probability. It evolves recursively\nbased on the state transition model $P(x_t|x_{t-1})$ and the previous support range $S_{t-1}$. Formally, it is\nexpressed as:\n$S_t = \\bigcup_{i=1}^N \\{x_t \\in X : P(x_t|x_{t-1}) > 0\\}$, where $x_{t-1} \\in S_{t-1}$.\nThe recursive evolution of the support range is fundamentally constrained by the prior boundary.\nThe recursive relationship described in the proposition implies that the initial prior boundary $S_{prior}$\nimposes an absolute constraint on the regions of the state space that particles can reach during the\nfiltering process. This highlights the critical dependence of particle filtering on the prior distribution\nand its boundary."}, {"title": "Proof and Statement of the Prior Boundary Phenomenon", "content": "Given the definitions of the prior boundary $S_{prior}$ and the support range $S_t$, we formally prove that the\nrecursive nature of particle filtering confines the support range within the prior boundary, thereby\nlimiting its ability to explore regions outside $S_{prior}$.\nProposition 3.3 (Recursive Confinement of Support Range). The support range $S_t$ at time t satisfies\nthe recursive relationship:\n$S_t \\subseteq S_{t-1} \\subseteq \\dots \\subseteq S_{prior}, \\forall t \\geq 0$.\nwith the base case:\n$S_0 = S_{prior}$.\nThus, for any time $t \\geq 0$, the support range is strictly confined by the prior boundary:\n$S_t \\subseteq S_{prior}$\nProof. By definition, the support range $S_t$ is given as:\n$S_t = \\bigcup_{i=1}^N \\{x_t \\in X : P(x_t|x_{t-1}) > 0\\}$, where $x_{t-1} \\in S_{t-1}$."}, {"title": "Methodology", "content": "Particle filtering operates as a sequential Bayesian estimation framework, leveraging particles and\ntheir associated weights to approximate posterior distributions. While effective in many scenarios, the\nrecursive nature of the particle filtering process inherently limits the particle support range $S_t$ to the\nprior boundary $S_{prior}$, as defined by the initial prior distribution $P(x_0)$. This limitation, known as the\nPrior Boundary Phenomenon, arises because particles cannot be generated outside $S_{prior}$, restricting\nthe filter's ability to estimate states beyond this range.\nTo overcome the constraints imposed by the Prior Boundary Phenomenon, this section introduces an\nenhanced particle filtering framework. The proposed methodology combines adaptive exploration,\nentropy regularisation, and kernel-based perturbations to expand the effective support range of\nparticles, allowing the particle filter to explore and estimate states outside $S_{prior}$. Below, we first\ndescribe the standard steps of particle filtering, followed by the proposed modifications to address\nthis phenomenon."}, {"title": "Particle Filtering: Recursive Approximation of Posterior Distributions", "content": "The particle filtering process can be summarised in four recursive steps: sampling, weight update,\nnormalization, and resampling. These steps enable the particle filter to sequentially approximate the\nposterior distribution $P(x_t|Y_{1:t})$ by adapting the particle set to new observations.\nStep 1. Sampling (Prediction): Gordon et al. (1993a) In this step, particles are drawn from an\nimportance distribution $q(x_t|x_{t-1}, Y_t)$, which reflects the conditional probability of the current state\ngiven the previous state and the current observation. Typically, the state transition model $P(x_t|x_{t-1})$\nis used as an approximation of the importance distribution. The propagation of particles can thus be\nexpressed as:\n$x_t^{(i)} \\sim P(x_t/x_{t-1}^{(i)})$,"}, {"title": "Diffusion-Driven Support Range Expansion", "content": "The Prior Boundary Phenomenon arises due to the recursive confinement of the particle support\nrange $S_t$ within the initial prior boundary $S_{prior}$. If a target state $x_g \\notin S_{prior}$, no particles can be\ngenerated near $x_g$, resulting in the failure of state estimation. To address this, we propose a diffusion-\ndriven particle filtering framework that incorporates dynamic exploration, entropy-driven diffusion\nregularisation, and kernel-based stochastic perturbations to expand the effective support range.\nAdaptive Diffusion through Exploratory Particles\nAt each time step, a subset of particles is designated as exploratory particles, which introduce\na uniform diffusion process into the framework. These particles are sampled from an extended\nbounding box $B$ that covers regions beyond $S_{prior}$:\n$x_t^{(i)} \\sim \\mathcal{U}(B), j \\in \\mathcal{E}$,\nwhere $B$ defines the extended state space, and $\\mathcal{E}$ represents the indices of exploratory particles. The\nexploratory particles are initialised with small weights:\n$w_t^{(j)} = \\epsilon, \\quad \\epsilon << 1$.\nThis diffusion mechanism enables the particle filter to sample states outside the original support range\n$S_{prior}$, thereby increasing the likelihood of reaching states such as $x_g \\notin S_{prior}$."}, {"title": "Entropy-Driven Diffusion Regularisation", "content": "To ensure that the exploratory diffusion does not collapse prematurely, an entropy regularisation term\nis added during the weight update step. This regularisation diffuses the weights across all particles,\nencouraging exploration of low-probability regions:\n$\\widetilde{w_t}^{(i)} = w_t^{(i)} + \\beta H$,\nwhere $H$ is the entropy of the weight distribution, defined as:\n$H = - \\sum_{i=1}^N \\widetilde{w_t}^{(i)} \\log(\\widetilde{w_t}^{(i)} + \\epsilon)$.\nBy penalising weight distributions that become overly concentrated, this mechanism promotes\nbalanced diffusion across the state space. The diffusion of weights helps exploratory particles retain\ninfluence and encourages the discovery of regions beyond $S_{prior}$."}, {"title": "Kernel-Induced Stochastic Diffusion", "content": "To further expand the particle support range dynamically, we introduce a stochastic diffusion mecha-\nnism based on kernel perturbations. Each particle $x_t^{(i)}$ is perturbed by a Gaussian kernel that models\ndiffusion within the local neighbourhood:\n$\\Delta x_t^{(i)} \\sim h_{opt} \\cdot \\mathcal{L} \\cdot \\mathcal{N}(0, I)$,\nwhere: - $h_{opt} = A \\cdot N^{-\\frac{1}{n+4}}$ is the optimal kernel bandwidth dynamically adjusted to balance explo-\nration and precision; - $\\mathcal{L}$ is the lower triangular matrix obtained from the Cholesky decomposition of\nthe covariance matrix $\\Sigma$, ensuring diffusion adapts to the local particle distribution.\nThe covariance matrix $\\Sigma$ is computed dynamically:\n$\\Sigma = \\sum_{i=1}^N w_t^{(i)} (x_t^{(i)} - \\mu)(x_t^{(i)} - \\mu)^T + \\lambda I$,\nwhere $\\mu = \\sum_{i=1}^N w_t^{(i)} x_t^{(i)}$ is the weighted mean, and $\\lambda > 0$ ensures positive definiteness of $\\Sigma$.\nThis perturbation mechanism expands the effective support range by introducing stochastic diffusion,\nallowing particles to explore new regions iteratively:\n$\\widehat{x_t}^{(i)} = x_t^{(i)} + \\Delta x_t^{(i)}$."}, {"title": "Diffusion-Driven Validation via MCMC", "content": "To ensure consistency with the target posterior distribution, a Metropolis-Hastings (MCMC) accep-\ntance criterion Hastings (1970) validates the diffused particles. For each perturbed particle $\\widehat{x_t}^{(i)}$, the\nacceptance probability is:\n$a_i = \\min(1, \\frac{\\widetilde{w_{new}}}{\\widetilde{w_{old}}} exp(-\\frac{1}{2} \\Delta x_t^{(i)^T} \\Sigma^{-1} \\Delta x_t^{(i)})$.\nA uniformly sampled random variable $u_i \\sim \\mathcal{U}(0, 1)$ determines whether the particle is accepted:\n$\\begin{cases} x_t^{(i)}, & \\text{if } a_i \\geq u_i, \\\\ x_t^{(i)} - \\Delta x_t^{(i)}, & \\text{otherwise.} \\end{cases}$\nThis step ensures that the diffusion-driven expansion aligns with the posterior distribution, preserving\nthe accuracy of the particle filter."}, {"title": "Diffusion-Enhanced Particle Filtering", "content": "By integrating exploratory particles, entropy-driven diffusion regularisation, and kernel-induced\nstochastic perturbations, the proposed framework creates a dynamic diffusion process that iteratively\nexpands the effective support range. The recursive relationship for the support range becomes:\n$S_{t+1} = (S_t \\cup B) \\oplus h_{opt}$,\nwhere $h_{opt}$ represents kernel-induced stochastic diffusion.\nThis diffusion framework overcomes the Prior Boundary Phenomenon by continuously extending the\nparticle filter's exploration capability, enabling robust state estimation for target states $x_g \\notin S_{prior}$."}, {"title": "Proof of Support Range Expansion Beyond the Prior Boundary", "content": "Given the enhancements of exploratory diffusion (B), entropy-driven regularisation, and kernel-\ninduced stochastic perturbations ($\\oplus h_{opt}$), we formally prove that the proposed framework enables the\nsupport range $S_t$ to expand beyond the prior boundary $S_{prior}$, enabling the particle filter to explore\nregions where $x_g \\notin S_{prior}$.\nProposition 4.1 (Expansion of Support Range). With the proposed enhancements, the support range\n$S_t$ satisfies the recursive relationship:\n$S_{t}^{new} = S_t \\cup B, \\quad S_{t+1} = S_{t}^{new} \\oplus h_{opt}$,\nwhere $B$ is the extended bounding box sampled by exploratory particles, and $\\oplus h_{opt}$ represents the\nkernel-induced expansion. Starting from the initial prior boundary:\n$S_0 = S_{prior}$,\nthe recursive updates ensure that for any target state $x_g \\in B$, there exists a time step t such that:\n$x_g \\in S_t$.\nProof. The proof proceeds in three steps, corresponding to the three key mechanisms of the unified\ndiffusion framework."}, {"title": "Extended Related Work", "content": null}, {"title": "Particle Filtering", "content": "Particle filtering (PF) Isard & Blake (1996) is initially designed for object tracking in cluttered\nenvironments, and has shown broad application in diverse domains like hydrology Moradkhani et al.\n(2005a), mobile robot Fox et al. (2001); Shi et al. (2024b,a), geophysics Van Leeuwen (2009), etc..\nTechnically, particle filtering uses Bayesian inference to estimate the dynamic states within the system\nSoto (2005): First initializes a series of particles randomly based on prior knowledge. Then iteratively\nrefines these particles through prediction, update, normalization, and resampling steps. The final goal\nis to expect these particles to converge to approximate the system's posterior distribution, which can\nbe used for system state estimation.\nThe efficiency and accuracy of the particle filter are generally discussed and optimized in iteration\nsteps, such as comparing different resampling methods Douc & Capp\u00e9 (2005); Li et al. (2015),\nmaking the number of particles sampled adaptive Fox (2001); Soto (2005), among others. However,\nthese optimizations assume that the target state aligns with the prior's support. Cases where the target\nstate lies beyond the prior boundaries are an underexplored area in PF."}, {"title": "Bayesian Inference", "content": "The broader Bayesian inference literature provides more insights into prior distribution discussions."}, {"title": "Prior Selections in Bayesian Inference", "content": "A prior is a probability distribution of a parameter before observing data. Informative priors can be\ndifficult to obtain, and an inappropriate prior can lead to misleading Bayesian inferences, thus making\nprior selection important and challenging Berger (1990); Richardson & Leblond (1997). Discussions\nin prior selection include choosing an appropriate distribution and defining its support range.\nFor prior type selections, Winkler (1967) examines methods for assessing priors in Bayesian analysis,\naiming to quantify prior knowledge into a probability distribution. Gelman et al. (2017) proposes an\nimprovement of integrating prior selection into the entire Bayesian workflow.\nFor challenges arising from prior boundary constraints, an intuitive solution is to apply unbounded\ndistributions as priors, allowing the shape to maximize coverage of the target range. While the normal\ndistribution is a common unbounded distribution option, it performs unideal with non-normal data.\nThe Johnson unbounded distribution Johnson et al. (1995) is proposed to address this limitation by\nenabling transformations that handle skewness and kurtosis to fit various distribution shapes. Sadok\net al. (2023); Hartigan (1996) explores the use of unbounded uniform priors, which assigns equal\nweight to all possible values. The application of Bayesian inference with these distributions includes\nscenarios with small samples Marhadi et al. (2012), automatic threshold setting for distribution-\nuncertain wind turbine monitoring systems Marhadi & Skrimpas (2014), etc.. However, using\nunbounded distributions as priors requires significantly more computing resources and time to\ncalculate posterior probabilities Doshi-Velez et al. (2009), and makes their application challenging in\nlarge-scale data scenarios."}, {"title": "Out of Distribution in Bayesian Inference", "content": "The regression and classification tasks in machine learning also discuss prior boundary constraints.\nData points that exceed prior knowledge distributions are labeled as anomalies or out-of-distribution\n(OOD) samples. Models' generalization and detection ability are investigated in these OOD samples.\nNatPN Charpentier et al. (2021) parameterizes conjugate prior distributions to enable efficient\nuncertainty estimation. Posterior network Charpentier et al. (2020) applies Normalizing Flows to"}]}