{"title": "REG: REFINED GENERALIZED FOCAL LOSS FOR ROAD ASSET\nDETECTION ON THAI HIGHWAYS USING VISION-BASED\nDETECTION AND SEGMENTATION MODELS", "authors": ["Teerapong Panboonyuen"], "abstract": "This paper introduces a novel framework for detecting and segmenting critical road assets on Thai\nhighways using an advanced Refined Generalized Focal Loss (REG) formulation. Integrated into\nstate-of-the-art vision-based detection and segmentation models, the proposed method effectively\naddresses class imbalance and the challenges of localizing small, underrepresented road elements,\nincluding pavilions, pedestrian bridges, information signs, single-arm poles, bus stops, warning\nsigns, and concrete guardrails. To improve both detection and segmentation accuracy, a multi-task\nlearning strategy is adopted, optimizing REG across multiple tasks. REG is further enhanced by\nincorporating a spatial-contextual adjustment term, which accounts for the spatial distribution of\nroad assets, and a probabilistic refinement, which captures prediction uncertainty in complex environ-\nments, such as varying lighting conditions and cluttered backgrounds. Our rigorous mathematical\nformulation demonstrates that REG minimizes localization and classification errors by applying\nadaptive weighting to hard-to-detect instances while down-weighting easier examples. Experimental\nresults show a substantial performance improvement, achieving a mAP50 of 80.34 and an F1-score\nof 77.87, significantly outperforming conventional methods. This research underscores the capability\nof advanced loss function refinements to enhance the robustness and accuracy of road asset detection\nand segmentation, thereby contributing to improved road safety and infrastructure management. For\nan in-depth discussion of the mathematical background and related methods, please refer to previous\nwork available at https://github.com/kaopanboonyuen/REG.", "sections": [{"title": "1 Introduction", "content": "The task of detecting and segmenting road assets, such as pavilions, pedestrian bridges, and information signs, is\npivotal for modern infrastructure management and road safety. Accurate identification of these assets is crucial for\npreventing accidents and maintaining road systems efficiently. While vision-based detection REGs have achieved\nsubstantial success across various domains [HGDG17, LGG+17], these REGs often encounter difficulties when applied\nto real-world conditions characterized by class imbalance and complex backgrounds [ZCY+20, Pan19, PNP+23]. For\nroad asset detection, small, underrepresented classes, such as single-arm poles and bus stops, pose significant challenges\nin localization and segmentation.\nRecent advancements in deep learning REGs for object detection and segmentation have led to increasingly sophisticated\narchitectures, including Transformer-based REGs [CMS+20], attention mechanisms [VSP+17], and feature pyramids\n[LDG+17]. Despite these advancements, these REGs often experience performance degradation when tasked with\ndetecting small objects in highly cluttered environments [LQQ+18]. To address these limitations, we propose a\nrefined version of the Generalized Focal Loss (GFL), which we term Refined Generalized Focal Loss (REG). This"}, {"title": "2 Mathematical Formulation of Refined Generalized Focal Loss", "content": "In this section, we present the mathematical framework for Refined Generalized Focal Loss (REG), designed to enhance\nmulti-task learning for road asset detection and segmentation on Thai highways. This formulation addresses challenges\nrelated to class imbalance and spatial-contextual intricacies in detecting and segmenting small, underrepresented road\nelements."}, {"title": "2.1 Generalized Focal Loss for Multi-Class Detection", "content": "The detection task involves identifying objects across $C_{det}$ = 7 classes:\n\u2022 Pavilions\n\u2022 Pedestrian bridges\n\u2022 Information signs\n\u2022 Single-arm poles\n\u2022 Bus stops\n\u2022 Warning signs\n\u2022 Concrete guardrails\nFocal Loss was initially proposed to address class imbalance by focusing on hard-to-classify examples. We extend this\nto Generalized Focal Loss (GFL) for multi-class detection, expressed as:\n$L_{GFL}=\\frac{1}{N_{det}}\\sum_{i=1}^{N_{det}}\\sum_{c=1}^{C_{det}}\\alpha_{c}(1 - p_{i,c})^{\\gamma} log(p_{i,c}),$\nwhere:\n\u2022 $N_{det}$ is the number of detection samples.\n\u2022 $C_{det}$ is the number of detection classes.\n\u2022 $p_{i,c}$ is the predicted probability of class c for sample i.\n\u2022 $\\alpha_{c}$ is the class balancing weight, compensating for class imbalance.\n\u2022 $\\gamma$ is the focusing parameter that emphasizes hard-to-classify examples.\nThe parameter $\\alpha_{c}$ plays a crucial role in managing class imbalance. For instance, a higher $\\alpha_{c}$ is applied to less frequent\nclasses such as bus stops to enhance their contribution to the loss function."}, {"title": "2.2 Refined Generalized Focal Loss for Segmentation", "content": "For segmentation tasks, we address $C_{seg}$ = 5 classes:\n\u2022 Pavilions\n\u2022 Pedestrian bridges\n\u2022 Information signs\n\u2022 Warning signs\n\u2022 Concrete guardrails\nThe goal is to classify each pixel into one of the $C_{seg}$ classes. The segmentation loss, akin to the detection loss, is\ndefined as pixel-wise Generalized Focal Loss:\n$L_{Seg-GFL}=\\frac{1}{N_{seg}}\\sum_{i=1}^{N_{seg}}\\sum_{c=1}^{C_{seg}}\\alpha_{c}(1 - p_{i,c})^{\\gamma} log(p_{i,c}),$\nwhere:\n\u2022 $N_{seg}$ is the number of segmentation pixels.\n\u2022 $C_{seg}$ is the number of segmentation classes.\n\u2022 $p_{i,c}$ is the predicted probability for class c at pixel i.\nIn segmentation, accurately predicting object boundaries is crucial. The parameter $\\gamma$ helps focus on pixels near object\nboundaries, which are typically more challenging to classify correctly."}, {"title": "2.3 Refinement Term for Spatial-Contextual Learning", "content": "To further enhance model learning, we introduce a spatial-contextual refinement term $g_{i,c}$ that adjusts the loss based on\nthe geometric and contextual relevance of each class. The refined loss is defined as:\n$L_{REG}=\\frac{1}{N}\\sum_{i=1}^{N}\\sum_{c=1}^{C}\\alpha_{c}(1 - p_{i,c})^{\\gamma} log(p_{i,c}) \\cdot g_{i,c},$\nwhere:\n\u2022 $N = N_{det} + N_{seg}$ is the total number of samples.\n\u2022 $C = C_{det} + C_{seg}$ is the total number of classes.\n\u2022 $g_{i,c}$ is the spatial-contextual refinement term.\nThe refinement term $g_{i,c}$ is determined by the spatial distance and contextual relevance of the predicted class. We define\n$g_{i,c}$ using a sigmoid function:\n$g_{i,c}=\\frac{1}{1+ e^{-\\beta \\cdot (d_{i,c}-\\delta)}}$,\nwhere:\n\u2022 $d_{i,c}$ is the spatial distance from sample i to the nearest ground-truth object of class c.\n\u2022 $\\delta$ is a threshold controlling the influence of proximity.\n\u2022 $\\beta$ is a scaling factor that adjusts the sharpness of the refinement.\nThis term penalizes predictions that are spatially inconsistent with the object context, such as a pedestrian bridge\npredicted far from its actual location."}, {"title": "2.4 Joint Optimization for Detection and Segmentation", "content": "We combine the losses for detection and segmentation using a balancing weight $\\lambda$:\n$L_{total} = L_{det} + \\lambda \\cdot L_{seg},$\nwhere $L_{det}$ and $L_{seg}$ represent the Refined Generalized Focal Loss for detection and segmentation, respectively. The\nparameter $\\lambda$ governs the relative importance of detection versus segmentation tasks. This joint optimization allows the\nmodel to learn shared features that benefit both tasks."}, {"title": "2.5 Incorporating Prediction Uncertainty", "content": "To enhance REG, we incorporate prediction uncertainty using a Gaussian distribution to model the inherent noise and\nambiguity in predictions:\n$p_{i,c} \\sim N(\\mu = p_{i,c}, \\sigma^2),$\nwhere $\\sigma^2$ represents the variance of the prediction. The loss is modified to account for this uncertainty:\n$L_{REG-U}=\\frac{1}{N}\\sum_{i=1}^{N}\\sum_{c=1}^{C}\\alpha_{c}(1 - \\hat{p_{i,c}})^{\\gamma} log(\\tilde{p_{i,c}}) \\cdot g_{i,c},$\nwhere $\\tilde{p_{i,c}}$ is the expected value of $p_{i,c}$ marginalized over the Gaussian distribution:\n$\\tilde{p_{i,c}}=\\int p_{i,c} \\cdot N(p_{i,c}; \\mu, \\sigma^2)dp_{i,c}.$\nThis probabilistic approach improves robustness to noisy or uncertain predictions, particularly in complex environments\nlike highways with varying lighting conditions."}, {"title": "2.6 Mathematical Foundations for Optimization in REG", "content": "The optimization problem for Refined Generalized Focal Loss (REG) is defined over a high-dimensional, non-convex\nloss landscape. To solve it efficiently, we employ advanced techniques in stochastic optimization and variational\ninference, leveraging concepts from Riemannian geometry, Lagrangian multipliers, and proximal gradient methods."}, {"title": "2.6.1 Stochastic Gradient Descent on Riemannian Manifolds", "content": "Given the non-Euclidean nature of the optimization space in multi-task learning, we extend the standard stochastic\ngradient descent (SGD) to operate on a Riemannian manifold. Let $\\mathcal{M}$ represent the Riemannian manifold where the\nmodel parameters $\\theta \\in \\mathcal{M}$ reside. The update rule for Riemannian SGD (R-SGD) is given by:\n$\\theta_{t+1} = R_{\\theta_t} (-\\eta_t \\cdot grad_{\\mathcal{M}} L_{REG}(\\theta_t)),$\nwhere:\n\u2022 $\\eta_t$ is the learning rate at iteration t,\n\u2022 $grad_{\\mathcal{M}} L_{REG}(\\theta_t)$ is the Riemannian gradient of the REG loss function,\n\u2022 $R_{\\theta_t}$ is the retraction operation that maps the parameters back onto the manifold $\\mathcal{M}$.\nThe Riemannian gradient is obtained from the Euclidean gradient via the projection onto the tangent space $T_{\\theta}\\mathcal{M}$ at\npoint $\\theta$. This ensures that the updates respect the geometric constraints of the parameter space."}, {"title": "2.6.2 Lagrangian Dual Formulation for Class Imbalance", "content": "The REG optimization can be framed as a constrained optimization problem where class balance constraints are\nintroduced through Lagrangian multipliers $\\lambda_c$. The constrained optimization is formalized as:\n$\\min L_{REG}(\\theta) \\quad \\text{s.t.} \\quad \\sum_{c=1}^{C} \\alpha_c = 1, \\quad \\alpha_c \\geq 0.$\nWe introduce the Lagrangian:\n$\\mathcal{L}(\\theta, \\lambda) = L_{REG}(\\theta) + \\sum_{c=1}^{C} \\lambda_c (\\alpha_c - \\frac{1}{C}),$\nwhere $\\lambda_c$ are the Lagrange multipliers enforcing the equality constraints on the class weights. The solution involves\nsolving the dual optimization problem:\n$\\max_{\\lambda} \\min_{\\theta} \\mathcal{L}(\\theta, \\lambda),$\nwhich can be tackled using the primal-dual algorithm."}, {"title": "2.6.3 Proximal Gradient Method for Spatial-Contextual Refinement", "content": "The inclusion of the spatial-contextual refinement term $g_{i,c}$ introduces non-smoothness in the optimization landscape.\nTo handle this, we employ the proximal gradient method, where the non-smooth term $g_{i,c}$ is separated from the smooth\npart of the loss function. The update rule is:\n$\\theta_{t+1} = prox_{\\eta_t g} (\\theta_t - \\eta_t \\nabla L_{REG}(\\theta_t)),$\nwhere $prox_{\\eta_t g}$ is the proximal operator for the refinement term, defined as:\n$prox_{\\eta_t g} (\\theta) = \\arg \\min_{\\theta'} (\\frac{1}{2\\eta_t} ||\\theta' - \\theta||^2 + g(\\theta')).$\nThe proximal operator enforces the spatial-contextual constraints, ensuring the solution remains within a feasible region\nthat aligns with the geometric structure of the data."}, {"title": "2.6.4 Variational Inference for Uncertainty Estimation", "content": "To model prediction uncertainty, we employ a variational inference approach. The prediction probabilities $P_{i,c}$ are\ntreated as latent variables, modeled by a variational distribution $q(p_{i,c})$. The objective becomes minimizing the\nvariational free energy:\n$\\mathcal{F}(q) = E_{q(p_{i,c})} [L_{REG}] + D_{KL}(q(P_{i,c})||P(P_{i,c})),$\nwhere:\n\u2022 $L_{REG}$ is the REG loss as a function of the latent probabilities,\n\u2022 $D_{KL}(\\cdot)$ is the Kullback-Leibler divergence between the variational distribution $q(p_{i,c})$ and the true posterior\n$P(P_{i,c})$.\nThe variational distribution $q(p_{i,c})$ is parameterized by a Gaussian distribution $q(p_{i,c}) = \\mathcal{N}(p_{i,c}; \\mu_{i,c}, \\sigma^2_{i,c})$, allowing\nus to marginalize over uncertainty and obtain a robust estimation of the loss."}, {"title": "3 Results and Analysis", "content": "In this section, we explore the performance metrics of various advanced object detection and segmentation frameworks\nto illustrate the impact of our sophisticated mathematical enhancements. Through detailed analysis, we highlight how\nthe incorporation of advanced mathematical techniques, particularly the Refined Generalized Focal Loss (REG), has\nsignificantly improved performance in complex, real-world scenarios."}, {"title": "3.1 Performance Evaluation Formula", "content": "To rigorously evaluate the performance of our refined object detection and segmentation framework, we employ\nseveral key metrics, including mean Average Precision (mAP), Precision, Recall, and the F1 Score. The mathematical\nformulation of these metrics is critical for quantifying model efficacy, particularly in challenging scenarios involving\nclass imbalance and spatial complexity."}, {"title": "3.1.1 Mean Average Precision (mAP)", "content": "The mAP metric aggregates precision across multiple Intersection over Union (IoU) thresholds, providing a holistic\nmeasure of detection accuracy. Formally, mAP at a specific IoU threshold $\\theta$ is defined as:\n$mAP_{\\theta} = \\frac{1}{|Q|}\\sum_{q \\in Q} \\frac{1}{|T_q|} \\sum_{t \\in T_q} Precision_t(IoU \\geq \\theta)$\nwhere: - Q represents the set of all queries (i.e., detected objects), - $T_q$ is the set of true positives for query q, -\n$Precision_t(IoU > \\theta)$ is the precision value for true positive t, evaluated at IoU threshold $\\theta$."}, {"title": "3.1.2 Precision", "content": "Precision P measures the ratio of correctly identified positive instances to the total predicted positive instances. It is\nmathematically defined as:\n$P = \\frac{TP}{TP + FP}$\nwhere: - TP is the number of true positives, - FP is the number of false positives."}, {"title": "3.1.3 Recall", "content": "Recall R quantifies the model's ability to identify all relevant instances, formulated as:\n$R = \\frac{TP}{TP + FN}$\nwhere: - FN denotes the number of false negatives."}, {"title": "3.1.4 F1 Score", "content": "The F1 Score provides a harmonic mean of precision and recall, offering a balanced measure between the two:\n$F_1 = 2 \\times \\frac{P \\times R}{P + R}$"}, {"title": "3.1.5 IoU Calculation", "content": "The Intersection over Union (IoU) between the predicted bounding box $B_p$ and the ground truth bounding box $B_g$ is\ncomputed as:\n$IoU = \\frac{|B_p \\cap B_g|}{|B_p \\cup B_g|}$"}, {"title": "3.5 Insights and Implications", "content": "The results highlight the significant impact of integrating sophisticated mathematical formulations into object detection\nand segmentation frameworks. The Refined Generalized Focal Loss (REG) has proven to be a pivotal enhance-\nment, effectively addressing issues related to class imbalance and spatial context. This has resulted in considerable\nimprovements across key performance metrics, making the REGs more robust and accurate in real-world applications."}, {"title": "4 Conclusion", "content": "In this study, we introduced a novel enhancement to object detection and segmentation frameworks by refining the\nGeneralized Focal Loss (REG), incorporating spatial context and adjustments for class imbalance. This refined loss\nfunction, termed REG, demonstrated substantial improvements in performance metrics, particularly in challenging\nenvironments with class imbalance and cluttered backgrounds.\nOur empirical results reveal that the refined REG approach significantly boosts detection accuracy and segmentation\nprecision, achieving notable gains in mean Average Precision (mAP) and F1 Score. By dynamically addressing\nclass imbalance and leveraging spatial context, this framework enhances robustness and accuracy, underscoring the\nimportance of mathematical innovation in advancing object detection and segmentation capabilities."}, {"title": "A.1 Why REG Matters in Real-World Applications", "content": "In real-world applications like road asset detection and segmentation, the challenges often stem from severe class\nimbalance and small object detection. For instance, classes like \"single-arm poles\" and \"bus stops\" are underrepresented\ncompared to more common objects like \"pavilions\" and \"information signs.\" Traditional loss functions such as cross-\nentropy fail to handle these cases effectively, as they equally weigh all examples, leading to a bias toward the dominant\nclasses. To address these challenges, the Refined Generalized Focal Loss (REG) introduces mechanisms to focus the\nlearning process on hard-to-classify instances and adjusts based on spatial and contextual relevance. This appendix\nexpands upon the mathematical rigor behind REG and its optimization principles."}, {"title": "A.2 Mathematical Derivation of Refined Generalized Focal Loss (REG)", "content": "REG extends the standard Generalized Focal Loss (GFL) by incorporating a refinement term that accounts for spatial-\ncontextual learning. We start by recalling the Generalized Focal Loss for multi-class detection:\n$L_{GFL}=\\frac{1}{N_{det}}\\sum_{i=1}^{N_{det}}\\sum_{c=1}^{C_{det}}\\alpha_{c}(1 - p_{i,c})^{\\gamma} log(p_{i,c}),$\nwhere:\n\u2022 $N_{det}$ is the number of detection samples.\n\u2022 $C_{det}$ is the number of detection classes.\n\u2022 $p_{i,c}$ is the predicted probability of class c for sample i.\n\u2022 $\\alpha_{c}$ is the class-balancing weight.\n\u2022 $\\gamma$ is the focusing parameter that emphasizes hard-to-classify examples."}, {"title": "A.3 Incorporating Spatial-Contextual Refinement Term", "content": "To enhance this formulation, we introduce a refinement term $g_{i.c}$, which adjusts the loss based on the spatial and\ncontextual significance of the predicted class. This term is crucial for road asset detection in cluttered environments\nwhere small objects may be overlooked.\nThe refined loss function is expressed as:\n$L_{REG}=\\frac{1}{N}\\sum_{i=1}^{N}\\sum_{c=1}^{C}\\alpha_{c}(1-p_{i,c})^{\\gamma} log(p_{i,c}) \\cdot g_{i,c},$\nwhere:\n\u2022 $N = N_{det} + N_{seg}$ is the total number of samples.\n\u2022 $C = C_{det} + C_{seg}$ is the total number of classes.\n\u2022 $g_{i,c}$ is the spatial-contextual refinement term.\nThe refinement term $g_{i,c}$ is designed to incorporate spatial distance and contextual relevance. Mathematically, it can be\ndefined using a sigmoid function that captures the spatial closeness between the predicted object and its ground-truth\nlocation:\n$g_{i,c}=\\frac{1}{1+ e^{-\\beta \\cdot (d_{i,c}-\\delta)}}$"}, {"title": "A.4 Proof of the Effectiveness of the Refinement Term", "content": "The refinement term ensures that the loss function emphasizes instances that are spatially and contextually consistent\nwith the ground truth. This refinement is particularly useful in environments where object overlap or clutter increases\nthe prediction difficulty."}, {"title": "A.4.1 Proof Outline:", "content": "Consider two samples i and j where $d_{i,c} < d_{j,c}$ for the same class c. The refinement term behaves as follows:\n$g_{i,c} > g_{j,c}$ if $d_{i,c} < d_{j,c}$.\nThus, for sample i, the refined loss $L_{REG}$ will down-weight the prediction error more than for sample j. This shows that\nspatially closer predictions receive higher weight, which improves the model's ability to focus on hard-to-detect but\nspatially important objects."}, {"title": "A.5 Joint Optimization of Detection and Segmentation", "content": "We further enhance REG by incorporating both detection and segmentation tasks into a unified multi-task learning\nframework. The total loss is:\n$L_{total} = L_{det} + \\lambda \\cdot L_{seg},$\nwhere:\n\u2022 $L_{det}$ is the detection loss (REG for detection).\n\u2022 $L_{seg}$ is the segmentation loss (REG for segmentation).\n\u2022 $\\lambda$ is a balancing parameter that controls the relative importance of the two tasks.\nBy sharing representations between detection and segmentation, the model learns to optimize complementary tasks,\nwhich enhances overall performance."}, {"title": "A.6 Optimization of REG Using Advanced Techniques", "content": "The optimization problem for REG involves a high-dimensional, non-convex loss landscape. To solve this problem, we\nuse a combination of stochastic optimization and variational inference techniques."}, {"title": "A.6.1 Stochastic Gradient Descent (SGD) on Riemannian Manifolds", "content": "Since the parameter space for multi-task learning often exhibits non-Euclidean properties, we employ Stochastic\nGradient Descent (SGD) on a Riemannian manifold. Let $\\mathcal{M}$ be the Riemannian manifold representing the parameter\nspace. The update rule for Riemannian SGD (R-SGD) is:\n$\\theta_{t+1} = R_{\\theta_t} (-\\eta_t \\cdot grad_{\\mathcal{M}} L_{REG}(\\theta_t)),$\nwhere:\n\u2022 $\\eta_t$ is the learning rate at iteration t.\n\u2022 $grad_{\\mathcal{M}} L_{REG}(\\theta_t)$ is the Riemannian gradient of the REG loss function.\n\u2022 $R_{\\theta_t}$ is the retraction operation that maps the parameters back onto the manifold $\\mathcal{M}$."}, {"title": "A.6.2 Incorporating Variational Inference for Prediction Uncertainty", "content": "To further improve REG, we model prediction uncertainty by assuming that the predicted probabilities $p_{i,c}$ follow a\nGaussian distribution. This leads to the following probabilistic formulation:\n$p_{i,c} \\sim N(\\mu = p_{i,c}, \\sigma^2),$\nwhere $\\sigma^2$ represents the variance of the prediction. The refined loss with uncertainty is given by:\n$L_{REG-U}=\\frac{1}{N}\\sum_{i=1}^{N}\\sum_{c=1}^{C}\\alpha_{c}\\sum_{i=1}^{N}\\sum_{c=1}^{C} (1 - \\hat{p_{i,c}}) log(\\tilde{p_{i,c}}) \\cdot g_{i,c},$\nwhere $\\tilde{p_{i,c}}$ is the expected value of $p_{i,c}$ marginalized over the Gaussian distribution:\n$\\tilde{p_{i,c}}=\\int p_{i,c} \\cdot N(p_{i,c}; \\mu, \\sigma^2)dp_{i,c}.$\nThis uncertainty-aware loss function improves robustness in noisy and cluttered environments, such as highways with\nvarying lighting and weather conditions."}, {"title": "A.7 Mockup Annotation Counts (Real-World Example)", "content": "Detection Task Annotations\n\u2022 Pavilions: 200\n\u2022 Pedestrian bridges: 100\n\u2022 Information signs: 700\n\u2022 Single-arm poles: 1500\n\u2022 Bus stops: 50\n\u2022 Warning signs: 800\n\u2022 Concrete guardrails: 300\nSegmentation Task Annotations\n\u2022 Pavilions: 100\n\u2022 Pedestrian bridges: 50\n\u2022 Information signs: 500\n\u2022 Warning signs: 400\n\u2022 Concrete guardrails: 150\nFrom this, it is evident that some classes dominate the dataset (e.g., Single-arm poles, Information signs), while others\n(e.g., Bus stops, Pedestrian bridges) are underrepresented."}, {"title": "A.8 Weighted Loss Function for Imbalanced Data", "content": "To mitigate the imbalance, we apply a weighted loss function. The loss for class c is adjusted by a weight $\\alpha_c$ that is\ninversely proportional to the frequency of class c:\n$\\alpha_c = \\frac{N_{total}}{N_c}$\nwhere:\n\u2022 $N_{total}$ is the total number of annotations across all classes.\n\u2022 $N_c$ is the number of annotations for class c.\nFor the detection task, the total number of annotations is:\n$N_{total}^{det} = 200 + 100 + 700 + 1500 + 50 + 800 + 300 = 3650$\nFor the segmentation task, the total number of annotations is:\n$N_{total}^{seg} = 100 + 50 + 500 + 400 + 150 = 1200$\nUsing these totals, we calculate the class-specific weights $\\alpha_c$.\nExample: Weighted Loss for Detection\nFor Bus stops (with only 50 annotations), the weight would be:\n$\\alpha_{Bus stops} = \\frac{3650}{50} = 73$\nFor Single-arm poles (with 1500 annotations), the weight would be:"}, {"title": "A.9 Mathematical Proof of Effectiveness", "content": "Let the total loss for a task be given by:\n$L = \\sum_{c=1}^{C} \\alpha_c \\cdot L_c$\nwhere C is the total number of classes, $L_c$ is the loss for class c, and $\\alpha_c$ is the weight for class c. Substituting the class\nweights $\\alpha_c = \\frac{N_{total}}{C \\cdot N_c}$, the total loss becomes:\n$L = \\sum_{c=1}^{C} \\frac{N_{total}}{C \\cdot N_c} L_c$\nThis formulation ensures that the loss for rare classes (with small $N_c$) is up-weighted, while the loss for frequent classes\n(with large $N_c$) is down-weighted. The scaling factor $\\alpha_c$ normalizes the loss contributions based on the inverse of class\nfrequency, thus balancing the gradient updates during training."}, {"title": "A.10 Handling Imbalanced Real Asset Numbers: Mathematical Proof and Application", "content": "One of the major challenges in object detection, particularly when dealing with real-world data, is the issue of\nimbalanced asset numbers. In many cases, the distribution of asset classes (e.g., different types of road assets or\ndamages in the auto insurance industry) can be heavily skewed, where common classes dominate the dataset while rare\nclasses are severely underrepresented. This imbalance can negatively impact model performance, leading to biased\npredictions toward the majority class. In this section, we will mathematically demonstrate how to address this problem\nand show that our approach can work under these conditions."}, {"title": "A.10.1 Problem Formulation", "content": "Let's define a dataset $\\mathcal{D} = \\{(x_i, y_i)\\}_{i=1}^N$, where $x_i \\in \\mathbb{R}^d$ represents the input image features and $y_i \\in \\mathcal{Y}$ represents\nthe label associated with the corresponding asset class. Assume there are C different asset classes, $\\mathcal{Y} = \\{1, 2, ..., C\\}$,\nand the frequency of asset class c in the dataset is given by $N_c$, where $\\sum_{c=1}^{C} N_c = N$. If $N_{min}$ and $N_{max}$ represent\nthe cardinalities of the least and most frequent asset classes, we are dealing with a heavily imbalanced dataset if\n$N_{min} << N_{max}$.\nOur goal is to ensure that the model performs well across all classes, including the minority ones, by addressing the\nimbalance issue. Traditional cross-entropy loss tends to bias the model toward majority classes, so we need a solution\nthat rebalances the impact of each class during training."}, {"title": "A.10.2 Loss Function Rebalancing", "content": "To mitigate the class imbalance, we propose a weighted loss function. Specifically, we introduce class-wise weights $\\alpha_c$\nfor each class c, which inversely scale according to the class frequency:\n$\\alpha_c = \\frac{N_{total}}{C \\cdot N_c}$\nwhere $N_{total}$ is the total number of samples in the dataset and $N_c$ is the number of samples in class c. By applying these\nweights to the standard cross-entropy loss, the rebalanced loss function becomes:\n$\\mathcal{L}_{rebalance} = - \\sum_{c=1}^{C} \\alpha_c \\sum_{i=1}^{N} \\mathbb{I}(y_i = c) \\log p_c(x_i)$"}, {"title": "A.10.3 Proof of Convergence", "content": "We now prove that under certain conditions, this rebalancing approach leads to a better distribution of errors across\nasset classes, ensuring that minority classes are not overlooked. Let's assume that the gradient of the rebalanced loss\nfunction is given by:\n$\\frac{\\partial}{\\partial \\theta} \\mathcal{L}_{rebalance} = - \\sum_{c=1}^{C} \\alpha_c \\sum_{i=1}^{N} \\mathbb{I}(y_i = c) \\frac{\\partial}{\\partial \\theta} \\log p_c(x_i)$\nUsing stochastic gradient descent (SGD), we update the model parameters $\\theta$ as:\n$\\theta_{t+1} = \\theta_t - \\eta \\frac{\\partial}{\\partial \\theta} \\mathcal{L}_{rebalance}$\nFor classes with lower sample counts (i.e., minority classes), the weight $\\alpha_c$ ensures that the corresponding gradient\nterms are scaled up, giving them a larger step size in parameter space. This effectively rebalances the learning process\nby compensating for the smaller number of training examples.\nWe prove convergence by showing that the total error $E = \\sum_{c=1}^{C} error_c$, where $error_c$ is the classification error for class\nc, decreases as a function of time t. Assuming that the error decreases proportional to the negative gradient of the loss,\nwe have:\n$\\frac{dE}{dt} = -\\eta \\sum_{c=1}^{C} \\alpha_c \\frac{\\partial error_c}{\\partial \\theta}$\nSince $\\alpha_c$ compensates for the imbalance, it ensures that the error decrease rate for minority classes (with smaller $N_c$)\nis comparable to that for majority classes. Therefore, the total error decreases uniformly across classes, leading to\nimproved performance on imbalanced datasets."}, {"title": "A.10.4 Experimental Validation", "content": "In practice, we validate our theoretical findings using a real-world asset dataset. We first calculate the imbalance ratio\nas:\n$r_{imbalance} = \\frac{N_{max}}{N_{min}}$\nFor extreme cases where $r_{imbalance} >> 1$, our rebalanced loss function significantly improves performance on minority\nclasses compared to the unweighted baseline, as evidenced by metrics like per-class precision, recall, and F1 score.\nEmpirical results demonstrate that our approach yields a more uniform distribution of these metrics across all asset\nclasses, effectively mitigating the detrimental effects of class imbalance."}, {"title": "A.10.5 Conclusion", "content": "We have shown mathematically and empirically that rebalancing the loss function using class-specific weights is an\neffective strategy for handling imbalanced real asset numbers. The proof of convergence indicates that minority classes\nare not only accounted for but also significantly improved in the training process. This ensures that our model can work\neffectively even in the presence of highly imbalanced data distributions, leading to robust and fair predictions across all\nasset types."}]}