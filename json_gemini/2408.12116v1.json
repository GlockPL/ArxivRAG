{"title": "Geolocation Representation from Large Language Models are Generic Enhancers for Spatio-Temporal Learning", "authors": ["Junlin He", "Tong Nie", "Wei Ma"], "abstract": "In the geospatial domain, universal representation models are significantly less prevalent than their extensive use in natural language processing and computer vision. This discrepancy arises primarily from the high costs associated with the input of existing representation models, which often require street views and mobility data. To address this, we develop a novel, training-free method that leverages large language models (LLMs) and auxiliary map data from OpenStreetMap to derive geolocation representations (LLMGeovec). LLMGeovec can represent the geographic semantics of city, country, and global scales, which acts as a generic enhancer for spatio-temporal learning. Specifically, by direct feature concatenation, we introduce a simple yet effective paradigm for enhancing multiple spatio-temporal tasks including geographic prediction (GP), long-term time series forecasting (LTSF), and graph-based spatio-temporal forecasting (GSTF). LLMGeovec can seamlessly integrate into a wide spectrum of spatio-temporal learning models, providing immediate enhancements. Experimental results demonstrate that LLMGeovec achieves global coverage and significantly boosts the performance of leading GP, LTSF, and GSTF models.", "sections": [{"title": "Introduction", "content": "Geolocation representation models encode geographical coordinates into latent embeddings with enriched geographic contextual information. Such embeddings ensure that similar representations reflect analogous sociodemographic attributes, activity patterns, and climatic characteristics across locations over the globe (Wang et al. 2022; Jean et al. 2019; Lee et al. 2021; Wang, Li, and Rajagopal 2020; Zhang et al. 2021, 2023a; Zhou et al. 2023b; Kim and Yoon 2022).\nThese geolocation representations are naturally suited to enhance spatio-temporal learning because they carry spatial contextual semantics. Previous research has focused only on how geolocation representations can be used for geographic prediction (GP). Specifically, GP tasks are trained on the attributes of some locations and used to predict the attributes of the remaining locations. These attributes include crime rate (Li et al. 2022b; Kim and Yoon 2022), poverty rate (Jean et al. 2016; Chi et al. 2022; Marty and Duhaut 2024), public health (Yeh et al. 2021; Nilsen et al. 2021; Draidi Areed et al. 2022; Chang et al. 2022; Sheehan et al. 2019), and so on. However, these geolocation representations are not used for more complex tasks.\nThe reason why previous approaches do not further extend the complex applications is that they do not achieve global coverage and they have a heavy reliance on expensive input data such as street views, travel patterns, and traffic trajectories (Wang, Li, and Rajagopal 2020; Kim and Yoon 2022; Lee et al. 2021; Zhang et al. 2023a). Although studies have used free and globally available satellite imagery for geolocation representation, their effectiveness has been hampered by the low resolution and absence of important features such as activity patterns (Manvi et al. 2023; Robinson, Hohman, and Dilkina 2017; Head et al. 2017; Jean et al. 2019; Elmustafa et al. 2022; Xi et al. 2022).\nOur objective is to develop a generic and effective geolocation representation method that utilizes only readily accessible global data to improve more spatio-temporal learning tasks: GP, long-term time series forecasting (LTSF), and graph-based spatio-temporal forecasting (GSTF). The latter two are typical spatio-temporal datasets that, given the values of many nodes at historical moments, predict the future values of those nodes. They differ in that the former tends to deal with correlations between nodes by channel-mixing strategies while the latter aggregates spatial connections between nodes by graph neural networks (GNNs).\nRecent advancements have demonstrated the extensive spatio-temporal and human-related knowledge embedded within large language models (LLMs). Some studies have transformed GP tasks as text generation tasks in LLMs (Manvi et al. 2023, 2024), and some have even found that LLMs learn linear representations of space and time across multiple scales (global, country, city) (Gurnee and Tegmark 2023). Inspired by these findings, we explore the potential of LLMs to generate effective geolocation representations.\nIn this paper, we introduce a novel, training-free method that utilizes LLMs and auxiliary map data from OpenStreetMap to derive geolocation representations (LLM-Geovec). As illustrated in Fig. 1, our approach first extracts textual descriptions of the coordinates from OpenStreetMap, which provides a sufficient geographic context. LLMs process these descriptions, and the final hidden states of individual tokens are averaged to form the LLMGeovec embedding for each coordinate."}, {"title": "Related Work", "content": "Geolocation Representation Models\nGeolocation representation models encode spatial coordinates into latent embeddings enriched with contextual geographic information. These embeddings ensure that similar representations reflect analogous social attributes and climatic characteristics across diverse locations (Wang et al. 2022; Jean et al. 2019; Lee et al. 2021; Wang, Li, and Rajagopal 2020; Zhang et al. 2021, 2023a; Zhou et al. 2023b; Kim and Yoon 2022).\nCurrently, there are three primary types of geolocation representation models: GNN-based models, image-based models, and natural language processing (NLP)-based models. GNN-based models construct graphs from correlations between locations, such as geographic distance, points of interest (POI), and human mobility patterns. These models generate node representations through message passing on the constructed graphs (Zhang et al. 2021; Kim and Yoon 2022; Zhang et al. 2023a; Zhou et al. 2023b). In contrast, Image-based models utilize street view or satellite imagery and employ contrastive learning to generate representations tied to specific coordinates (Jean et al. 2019; Wang, Li, and Rajagopal 2020; Liu et al. 2023c; Li et al. 2022a; Xi et al. 2022). Meanwhile, NLP-based models leverage textual representations to represent the textual descriptions associated with the corresponding locations.\nHowever, GNN-based models are highly dependent on human mobility data, which restricts their applicability to urban environments where such records are available. This limitation also challenges the modeling of cities on a global scale. Image-based models face challenges as well; those relying solely on satellite imagery often lack critical human activity information (Xi et al. 2022; Manvi et al. 2023), while street view images can be costly and not universally accessible. NLP-based models show promise due to the abundance of geographically relevant textual data available online, which is typically free and globally accessible. However, existing NLP-based models, such as using Doc2vec to represent textual descriptions from Wikipedia, are inherently limited in their data source and model ability to fully capture the richness of geographic information (Sheehan et al. 2019).\nTo address these limitations, this paper introduces LLM-Geovec, an NLP-based geolocation representation model that extracts extensive spatio-temporal and human-related knowledge compressed in LLMs to represent locations effectively."}, {"title": "LLMs for GP", "content": "Recent advancements in LLMs have seen their application in various GP tasks. Utilizing pre-trained LLMs, researchers have addressed various challenges such as forecasting dementia patterns over time series data, predicting urban functionalities, and estimating socio-climatic variables (Mai et al. 2023; Manvi et al. 2024; Zhang et al. 2023b). Despite these applications, the efficacy of LLMs not specifically fine-tuned for geographic tasks remains suboptimal. Significant efforts have been directed towards customizing LLMs for geospatial analytics. For example, some researchers have fine-tuned LLMs in geoscience text corpora to enhance their performance in geographic question answering, summarization, and text classification tasks (Deng et al. 2024). Furthermore, more recent studies have constructed training sets derived from OpenStreetMap data and associated GP tasks, leading to improved performance by fine-tuning LLMs on training sets (Manvi et al. 2023).\nHowever, fine-tuning LLMs is resource-intensive, often requiring substantial computational and data resources (Hu et al. 2021; Kaddour et al. 2023). Previous approaches mainly generate texts with LLMs to approximate GP, focusing more on relevance rather than precision (Lopez-Lira and Tang 2023). In contrast, our proposed LLMGeovec framework leverages pre-trained LLMs for direct geolocation representation. This approach facilitates the use of geographic knowledge of LLMs within various prediction models. Our experimental results confirm the robustness and utility of LLMGeovec in practical GP."}, {"title": "LLMs for LTSF and GSTF", "content": "LTSF and GSTF involve the analysis of spatio-temporal data, which encapsulate both the temporal dynamics of individual nodes and the spatial dependencies among them. Recent advancements have explored the integration of LLMs to leverage their sequence modeling capabilities and the spatio-temporal knowledge they encode. This is typically achieved by tokenizing time series and graph data, fine-tuning LLMs on these tokens, and subsequently employing customized prompts to improve forecast accuracy (Jiang et al. 2024; Li et al. 2024; Zhou et al. 2023a; Chang et al. 2024; Sun et al. 2023; Cao et al. 2023; Jin et al. 2023).\nHowever, existing approaches predominantly utilize LLMs as direct predictors, necessitating substantial computational resources for fine-tuning and often falling short in embedding spatio-temporal knowledge into existing advanced forecasting models. Our work addresses this limitation by extracting geolocation representations from LLMs, enriching the LTSF and GSTF models with enhanced spatial correlation learning, leading to direct performance improvements."}, {"title": "Preliminaries", "content": "In this section, we introduce the definitions of geolocation representation learning, GP, LTSF and GSTF.\nGeolocation Representation Learning. Given a set of nodes $P\\in \\mathbb{R}^{2\\times N}$, where N represents the number of nodes, and $P_i = (P_{lon}, P_{lat})$ denotes the longitude and latitude of the i-th node. The goal of geolocation representation learning is to construct an effective encoder f that transforms P into geographically informative representations $Z = f(P)$. Here, $Z\\in \\mathbb{R}^{M\\times N}$ with M denoting the dimensionality of the representation.\nGP. Given a set of nodes $P\\in \\mathbb{R}^{2\\times N}$, each node is associated with geographic attributes such as climatic indicators (e.g., average annual temperature, humidity) and social indicators (e.g., regional average educational attainment, average annual income, poverty rate, crime rate). For a given set of geographic attributes $A \\in \\mathbb{R}^{1\\times N}$, GP in the context of geolocation representation learning involves training a linear regressor with $Z[:K] = f(P[:K])$ to fit $A[:K]$ using K training samples. The performance of the regressor on the test sets $Z[K:] = f(P[K:])$ and $A[K:]$ is used to measure the prediction task performance and the quality of the encoder f and representations Z.\nLTSF. We consider a historical multivariate time series (MTS) $X \\in \\mathbb{R}^{H\\times N}$, where N represents the number of nodes (variates) and H is the number of historical time slots. The objective is to predict future values $Y \\in \\mathbb{R}^{F\\times N}$, with F as the number of future time slots. Each value of node i at time slot t is denoted by $X_{t}^{i}$, and their coordinates by $P\\in \\mathbb{R}^{2\\times N}$.\nGSTF. Different from LTSF, GSTF constructs a weighted adjacency matrix $A \\in \\mathbb{R}^{N\\times N}$, where $A_{ij} = 1/dist(P_i, P_j)$ and $dist(P_i, P_j)$ represents the spatial distance between node $P_i$ and $P_j$. A graph G is then formed based on A. Unlike LTSF, GSTF leverages GNNs to aggregate the features of nodes $X_t$ at t-th time slot, enhancing prediction by incorporating spatial relationships."}, {"title": "LLMGeovec: A Generic Enhancer for Spatio-Temporal Learning", "content": "As depicted in Fig. 1, the proposed LLMGeovec method encapsulates two primary phases: prompt generation and text embedding via LLMs. Initially, we generate geographic descriptions based on specified coordinates leveraging map data. These descriptions are then transformed into embeddings by LLMs. The obtained embeddings can be used for GP, LTSF, and GSTF."}, {"title": "Prompt Generation", "content": "Given a coordinate, we generate universal prompts, intentionally devoid of task-specific data, to enable the effective extraction of geographic knowledge of LLMs. As outlined in Fig. 1, the prompt structure incorporates:\n\u2022 Instruction: Guides LLMs in identifying essential geographic information linked to specific coordinates.\n\u2022 Address: Utilizes reverse-geocoding to detail the hierarchy of location, from local neighborhoods to national identifiers.\n\u2022 Nearby Places: Enumerates the ten nearest points of interest within a 100-kilometer radius, including their names, distances, directions and bearings.\nData sources include OpenStreetMap (Neis and Zipf 2012), with addresses derived through Nominatim's reverse geocoding (Serere, Resch, and Havas 2023) and nearby places via the Overpass API (Olbricht et al. 2011). This approach aligns with and extends previous studies (Manvi et al. 2023, 2024) by focusing on the extraction of generalized geographic information without specifying downstream tasks."}, {"title": "Text Embedding Using LLMs", "content": "With the geolocation prompts generated, we proceed to embed these textual descriptions using LLMs. Recent studies have explored enhancing text embeddings generated by LLMs, typically by modifying attention mechanisms or repeating prompts to circumvent the limitations of decoder-only models (BehnamGhader et al. 2024; Muennighoff 2022; Ma et al. 2024; Wang et al. 2023; Springer et al. 2024). Our structured prompts, particularly with crucial geographic context presented at the end of prompts, allow LLMs to generate sufficiently high-quality geolocation representations without repetition of prompts or modification of models. To be specific, we use the average word embeddings from the last layer of a pre-trained LLM as the text representation, ensuring our LLMGeovec method remains adaptable to the latest LLMs without training. In addition, by avoiding fine-tuning, our method preserves the intrinsic geographic knowledge within LLMs (Zhai et al. 2023; Lin et al. 2023)."}, {"title": "Incorporating LLMGeovec into GP", "content": "Consistent with many previous studies, high-quality geolocation representations can be used for GP with the help of partial region labeling (Wang et al. 2022; Jean et al. 2019; Lee et al. 2021; Wang, Li, and Rajagopal 2020; Zhang et al. 2021, 2023a; Zhou et al. 2023b; Kim and Yoon 2022). This is a direct application of LLMGeovec. To be specific, we will divide the locations into a training set and a test set, and use linear regression in the training set to map geolocation representation to location attributes. This is followed by testing in the test set. It is worth noting that since LLMGeovec achieves global coverage, it can be used in GPs of various scales (global, country, city) and can also be combined with other geolocation representations through feature concatenation."}, {"title": "Incorporating LLMGeovec into LTSF", "content": "In this section, we describe the integration of LLMGeovec with LTSF models. We start by outlining a general LTSF model, which typically consists of a token embedding layer E, an encoder C, and a predictor D (Chen et al. 2023; Li et al. 2023; Liu et al. 2023b; Yi et al. 2024). The embedding layer E projects the the t-th historical record $X_t \\in \\mathbb{R}^{1\\times \\check{N}}$ into hidden temporal embeddings $S_t = E(X_t) \\in \\mathbb{R}^{d_t\\times N}$, where $d_t$ is the embedding dimension. Note that there can be a normalization operation in this embedder such as RevIN (Kim et al. 2021) to address the nonstationarity of time series. The encoder C then models the node-to-node and slot-to-slot relationships across H historical time slots, and the predictor D generates predictions $\\hat{Y} \\in \\mathbb{R}^{F\\times N}$ for the future F time slots. This process is formulated as follows:\n$S = {S_0,\u2026\u2026, S_t,\u2026\u2026, S_H}, S_t = E(X_t), \\tag{1}$\n$LOSSLTSF = min ||D(C(S)) \u2013 Y||, \\tag{2}$\nwhere the model parameters are updated automatically through gradient descent. In practice, the encoder C can be instantiated by Transformer blocks, convolution, and MLPs, to model either channel dependencies or token correlations. Many state-of-the-art LTSF models follow this architectural template, such as TSMixer (Chen et al. 2023), RMLP (Li et al. 2023), iTransformer (Liu et al. 2023b), and FreTS (Yi et al. 2024). For other Transformer-based architectures that employ token-wise embedding, such as Autoformer (Wu et al. 2021) and Informer (Zhou et al. 2021), we can adapt them with a simple inverting strategy (Liu et al. 2023b).\nFor an LTSF task, we collect the latitude and longitude of each node that generates the time series to construct the node set P. We then select an LLM (e.g., LLaMa3) and use our proposed LLMGeovec to generate the geolocation representation $Z\\in \\mathbb{R}^{M\\times N}$. A two-layer MLP acts as an adapter for LLMGeovec, projecting Z into a low-dimensional space $Z' = Adapter(Z) \\in \\mathbb{R}^{d_s\\times N}$ to align with the LTSF task. This process is described by the following equations:\n$Z' = Adapter(Z), \\tag{3}$\n$S' = {S'_0,\u2026\u2026, S'_t,\u2026\u2026, S'_H}, S'_t = Concat(E(X_t), Z'), \\tag{4}$\n$LOSSLTSF = min ||D(C(S')) \u2013 Y||, \\tag{5}$\nwhere $S'\\in \\mathbb{R}^{(d_t+d_s)\\times N}$ is formed by concatenating the series embeddings $E(X_t)$ with the geolocation representations $Z'$ along the feature dimension. The parameters of both the adapter and the original components are updated automatically via gradient descent."}, {"title": "Incorporating LLMGeovec into GSTF", "content": "Previous spatio-temporal prediction models often employ GNNs to capture spatial relationships between nodes, aggregating them into node features, which are then input into the temporal modeling component sequentially or alternatively (Shao et al. 2022a,d,c; Wu et al. 2019a; Tang, He, and Zhao 2022; Tang et al. 2022). We refer to the spatio-temporal model as STGNN. Given the graph G, the structural template is framed as follows:\n$S = {S_0,..., S_t,\u2026\u2026, S_H}, S_t = E(X_t), \\\\\n\\hat{S} = STGNN(S, G), \\\\\nLOSSGSTF = min||D(\\hat{S}) \u2013 Y||. \\tag{6}$\nwhere the embedder E projects the node signal to hidden states, and all node states are collected into the STGNN processor to generate the graph representation $\\hat{S}$.\nOn top of them, we first concatenate LLMGeovec into node features (e.g., temporal readings), which are then processed by STGNN. This process is described by:\n$Z' = Adapter(Z), \\tag{7}$\n$S' = {S'_0,\u2026\u2026, S'_t,\u2026\u2026, S'_H}, S'_t = Concat(E(X_t), Z'), \\tag{8}$\n$\\hat{S'} = STGNN(S', G), \\tag{9}$\n$LOSSGSTF = min ||D(\\hat{S'}) \u2013 Y||, \\tag{10}$\nwhere the parameters of both the adapter, the STGNN and D are updated automatically via gradient descent.\nNote that this scheme is applicable for STGNNs with different types of processing methods. Specifically, different models have different instantiations of Eq. 9, e.g., spatio-temporal message passing mechanisms. Both the mainstream time-then-space and time-and-space STGNN family discussed in Cini et al. (2023) can be seamlessly adopted simply by concatenating LLMGeovec into the input of each node."}, {"title": "Numeric Experiments", "content": "We study the effectiveness of LLMGeovec through extensive experiments. We first demonstrate that in geolocation representation models, LLMGeovec performs SoTA in GP tasks at all three scales: city, national, and global, and even outperforms end-to-end supervised training models. We examine two LLMS, LLaMa3 8B and Mistral 8x7B, both of which are able to produce high-quality geolocation representations with LLMGeovec. Moreover, LLMGeovec is seamlessly embedded into various LTSF and GSTF models and directly improves the model performance under various tasks. Notably, in the GSTF tasks, the use of a simple MLP and LLMGeovec outperforms many GNN-based approaches, and LLMGeovec shows great potential as an alternative to time-consuming GNNs. For a detailed description of the models and the datasets (GP, LTSF, GTSF), please refer to Appendix."}, {"title": "LLMGeovec for GP", "content": "To comprehensively validate the quality of LLMGeovec and its effectiveness in GP tasks, we constructed a multi-scale, multi-topic benchmark encompassing a range of scenarios from city-level poverty rates to global population density. Unlike many existing powerful baselines, our approach can generate high-quality geolocation representations for any location without expensive data or extensive training.\nA Multi-scale and Multi-topic GP Benchmark. As illustrated in Table 1, at the global scale, we collect 14 GP tasks. These include three climate indicators such as Annual Air Temperature and 11 social indicators like Population Density and Human Modification (detailed descriptions please refer to Appendix). We utilize 100,000 locations with global coverage, which are generated by Manvi et al. (2024) (Africa: 19,855; Asia: 55,893; Europe: 6,825; North America: 8,440; South America: 5,189; Oceania: 2,049). In line with Manvi et al. (2023, 2024), each GP task is associated with a corresponding GeoTIFF file. For each coordinate, the average value of 12 pixels surrounding the coordinate is taken as the value of the coordinate. Following the protocol of Kim and Yoon (2022), we perform five cross-validation using ridge linear regression implemented in Sklearn (Feurer et al. 2020; McDonald 2009), and the average of mean absolute error (MAE), root mean square error (RMSE) and $R^2$ are reported. On the country and city scales, we use existing benchmarks, including the social indicators in India (Lee et al. 2021) and NYC (Zhou et al. 2023b). We also employ ridge linear regression in Sklearn and report the MAE, RMSE, and $R^2$ on the test sets.\nBaselines. We compare the LLMGeovec generated by LLaMa3 8B (Touvron et al. 2023) and Mistral 8x7B (Jiang"}, {"title": "LLMGeovec for LTSF", "content": "In the previous section, we discussed how to seamlessly embed LLMGeovec into existing LTSF models. Next, we will conduct detailed experiments to verify the effectiveness of LLMGeovec using popular LTSF benchmarks and various models. Due to limited computational resources, we choose LLMGeovec (LLaMa3 8B) with the best performance in the GP to be added to the various models.\nDatasets and models. Following the settings of Zhang et al. (2024a); Wu et al. (2022); Shao et al. (2022a), we select five LTSF datasets from a wide range of domains, including Solar Energy, Global Wind, Global Temperature, Traffic flow, Delivery demand, and air quality. Several representative LTSF models are selected, including both Transformer-based and MLP-based methods. They are iTransformer (Liu et al. 2023b), TSMixer (Chen et al. 2023), RMLP (Li et al. 2023), and Informer (Zhou et al. 2021).\nHyperparameters Settings. We adapt the suggested hyperparameters in Time-Series-Library benchmark (Wang et al. 2024) for all model.\nPerformances of LTSF. As shown in Table 3, LLMGeovec can consistently improve the original performances of different models in almost all scenarios. This effect is noticeable in datasets related to both natural processes and human activities, which demonstrates the generality of LLM-based geolocation representation.\nPerformances Comparisions using different geolocation embeddings. In this section, we compare the effects of two geolocation representations on LTSF models, and for reference, we also add learnable embeddings (Shao et al. 2022b) (e.g., STID) with the same feature dimensions as LLMGeovec. For a fair comparison, all three methods use the same Adapter and model parameters. As shown in Tab. 7, LLMGeovec, which contains richer spatial semantics, achieves the greatest improvement."}, {"title": "LLMGeovec for GSTF", "content": "Finally, we evaluate the effectiveness of LLMGeovec in GSTF tasks and models. As with LTSF, we choose LLaMa3 8B to generate LLMGeovec.\nDatasets and models. We select the large-scale LargeST traffic flow benchmark (Liu et al. 2023a) and the LaDe demand dataset (Wu et al. 2023) for evaluations. Several competitive baselines that are widely adopted in related work are considered, including DCRNN (Li et al. 2017), STGCN (Yu, Yin, and Zhu 2017), ASTGCN (Guo et al. 2019), AGCRN (Bai et al. 2020), GWNET (Wu et al. 2019b), MTGNN (Wu et al. 2020b), and STID (Shao et al. 2022b).\nHyperparameters Settings. We adapt the suggested hyperparameters in LargeST benchmark (Liu et al. 2023a) for all models.\nPerformances in GSTF. Tab. 8 reports the evaluation results on the LargeST benchmark. Mainstream GNN-based models can benefit from the incorporation of LLMGeovec. This clearly shows that LLMGeovec is able to complement the spatial relationships captured by GNNs with the rich geographic knowledge of LLMs. Surprisingly, the vanilla MLP model equipped with LLMGeovec can achieve comparable performance to the GNN counterparts. This suggests that LLMGeovec can even be used as an alternative to GNNs to provide geographic correlation for temporal models.\nPerformances in zero-shot scenarios. In addition to enhancing various models in full training scenarios for GSTF, LLMGeovec also has the potential for enhancing zero-shot transfer. We compare the performance of the learnable node embedding (STID) introduced by Shao et al. (2022a) and LLMGeovec in zero-shot scenarios. As a reference, we also test the transferability of the baseline GWNET and MLP. The LaDe data is adopted for this experiment. It is evident from Fig. 2 that when models are transferred to a new region in a zero-shot scenario, the learnable embedding harms the performance of MLP significantly because the embedding has adapted to the source data with specific patterns. In contrast, universal LLMGeovec can be generalized to other regions without any adjustment. This indicates that LLMGeovec features intrinsic geolocation knowledge that is generalizable for different regions."}, {"title": "Conclusion and Future Work", "content": "The acquisition of universal geolocation representations to improve downstream tasks has been a long-standing pursuit. This paper presents our first attempt to utilize recent advanced LLMs to extract such representations. By the merit of the geospatial knowledge within LLMs, the extracted embedding from the pre-activated layer achieves global coverage and serves as a generic enhancer for spatio-temporal learning. We demonstrate the effectiveness of embedding in various tasks, including GP, LTSF, and GSTF. Empirical results indicate that LLMGeovec can improve the performances of various models simply by incorporating it into the model input (i.e., feature concatenation). In future work, we are interested to see if larger LLMs (e.g., LLaMa3 70B) can further improve the quality of LLMGeovec. We can adopt LLMGeovec in more challenging spatio-temporal learning tasks, such as spatio-temporal imputation (Nie et al. 2024b; Yuan et al. 2022) and traffic flow generation (Wu et al. 2020a). It is also interesting to explore the possibility of integrating LLM-Geovec into pre-trained foundational architectures for unified spatio-temporal learning tasks (Jin et al. 2023; Yuan et al. 2024; Zhang et al. 2024b)."}, {"title": "Appendices", "content": "Descriptions of datasets and models in GP\nDatasets We utilized a variety of global-scale datasets to inform our models. The datasets are listed below with their key characteristics:\n\u2022 Annual Air Temperature: Mean annual daily mean air temperature data.\nCHELSA_biol_1981-2010_V.2.1.tif\n\u2022 Annual Precipitation: Mean annual accumulated precipitation amount.\nCHELSA_bio12_1981-2010_V.2.1.tif\n\u2022 Monthly Climate Moisture: Average monthly climate moisture index.\nCHELSA_cmi_mean_1981-2010_V.2.1.tif\n\u2022 Population Density: GeoLLM aggregates WorldPop population data at 1km resolution, employing importance sampling by population size.\nppp_2020_1km_Aggregated.tif\n\u2022 Nighttime Light Intensity: Satellite images capturing nighttime luminosity from VIIRS with a 500-meter resolution.\nVNL_npp_2023_global_vcmslcfg_v2_\nc202402081600.cvg.dat.tif\n\u2022 Human Modification Terrestrial: A cumulative metric of human modification of terrestrial lands at a 1-km resolution, modeled from 13 anthropogenic stressors.\nlulc-human-modification-terrestrial-\nsystems_geographic.tif\n\u2022 Global Gridded Relative Deprivation: Index of multidimensional deprivation and poverty, ranging from 0 (lowest) to 100 (highest), at 30 arc-second (1 km) resolution.\npovmap-grdi-v1.tif\n\u2022 Other Indicators: Additional indicators include the Ratio of Built-up Area to Non-built Up Area, Child Dependency Ratio, and Subnational Human Development Index.\npovmap-grdi-v1_BUILT.tif, povmap-grdi-\nv1_CDR_CopyRaster.tif, povmap-grdi-v1_\nSHDI.tif\n\u2022 Infant Mortality Rates: Subnational Infant Mortality Rate estimates for 234 countries and territories.\npovmap_global_subnational_infant_\nmortality_rates_v2_01.tif\n\u2022 SustainBench Indicators: Asset index, sanitation index, and women's BMI collected from Demographic and Health Surveys across 48 countries.\ndhs_asset_index.tif,\ndhs_sanitation_\nindex.tif, dhs_women_bmi.tif\nFor country-scale and city-scale datasets, we used the datasets provided by MapillaryGCN and HKGL, respectively. The MapillaryGCN dataset records poverty rate, population density, and women's BMI across 6,000 communities in India, as detailed in the original article. The HKGL dataset captures population density, education level, income level, and crime rate across 1,500 census tracts in NYC.\nModels We evaluate several baseline models, as detailed below:\n\u2022 Image Supervised Learning: Trains a ResNet34 pretrained on ImageNet1k to predict cluster-specific indicators from street view images.\n\u2022 Object Counts: Utilizes object detection outputs from street view images, followed by MLPs for indicator prediction.\n\u2022 MapillaryGCN: Combines street view images and object detection results with a GCN for feature aggregation and prediction.\n\u2022 Node2Vec: Employs random walks to learn node embeddings using skip-gram models.\n\u2022 GCN: Aggregates information from neighboring nodes for embedding learning.\n\u2022 GAT: Utilizes attention mechanisms to differentially weight information from neighboring nodes during aggregation.\n\u2022 ZE-Mob: Leverages the co-occurrence of origin-destination locations to learn location embeddings from mobility flow data.\n\u2022 MGFN: Fuses mobility graphs with similar patterns, then learns location embeddings using a multi-level attention mechanism.\n\u2022 MV-PN: Constructs multi-view POI-POI networks per location and learns embeddings through an encoder-decoder framework.\n\u2022 HDGE: Jointly learns location embeddings from both spatial and flow graphs.\n\u2022 HUGAT: Defines meta-paths to capture semantics in LBSN, applying a heterogeneous graph attention network for embedding learning.\n\u2022 MVURE: Models various location correlations using different graphs, with a joint learning module for location embeddings.\n\u2022 HKGL: Implements a hierarchical KG learning model, using LBKG for global knowledge distillation and sub-KGs for domain-specific knowledge capture.\n\u2022 Bert-whitening: In Bert, sentence representations are obtained by averaging the vectors of individual words, on the basis of which the isotropy of sentence representations is enhanced by whitening operations."}, {"title": "Datasets and Models in LTSF", "content": "Datasets We evaluate the proposed models on a diverse set of datasets", "patterns": "n\u2022 Global Wind", "Temp": "This dataset, provided by Corrformer, originates from the National Centers for Environmental Information (NCEI). It encompasses hourly averaged wind speeds and temperatures from 3,850 global stations, spanning from January 1, 2019"}]}