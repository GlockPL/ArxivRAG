{"title": "Practical and Ready-to-Use Methodology to Assess the re-identification Risk in Anonymized Datasets", "authors": ["Louis-Philippe SONDECK", "Maryline LAURENT"], "abstract": "To prove that a dataset is sufficiently anonymized, many privacy policies suggest that a re- identification risk assessment be performed, but do not provide a precise methodology for doing so, leaving the industry alone with the problem. This paper proposes a practical and ready-to-use methodology for re-identification risk assessment, the originality of which is manifold: (1) it is the first to follow well-known risk analysis methods (e.g. EBIOS) that have been used in the cybersecurity field for years, which consider not only the ability to perform an attack, but also the impact such an attack can have on an individual; (2) it is the first to qualify attributes and values of attributes with e.g. degree of exposure, as known real-world attacks mainly target certain types of attributes and not others.\nKeywords Privacy Impact Assessment, re-identification risk assessment, Anonymized dataset, Dataset, GDPR, HIPAA, Privacy.", "sections": [{"title": "1 Introduction", "content": "There are several policies in the healthcare industry that address the issue of anonymizing data for disclosure, including the Health Insurance Portability and Accountability Act (HIPAA) Privacy Rule, the EMA 0070 Policy and the GDPR. These guidelines generally refer to well-known anonymization techniques (e.g. k-anonymity, l-diversity, differential privacy,...). Many of them define a two-sided approach to anonymization, either by applying a well-defined method (e.g. Safe Harbor for HIPAA, WP29 anonymization criteria fulfillment for GDPR or by performing a re-identification risk assessment (e.g. Expert Determination for HIPAA, risk analysis assessment for GDPR). However, the well-defined methods are in most cases either too restrictive, leading to a poor useful dataset (e.g. GDPR, EMA Policy 0070) or too simplistic, leading to privacy concerns (e.g. HIPAA).\nThis paper proposes a practical and ready-to-use methodology for re-identification risk assessment and results in quantifying the risk to privacy. It emphasizes the notion of \"feared event\", which is well known in the context of cybersecurity risk, but which is not considered in current methodological proposals. This allows for a more accurate assessment of the re-identification risk, by taking into account not only the likelihood of an attack, which refers to the ability of an attacker to perform an attack, but also the severity of this attack, which describes the impact on the individual. The re- identification risk is then calculated based on both the likelihood and the severity. After positioning our contribution against current approaches in Section 2, three sections describe the method to compute severity (Section 3), likelihood (Section 4) and re-identification risk (Section 5). Well-chosen examples are given throughout the paper to help understand the proposed methodology: the initial dataset in Table 1 and the two anonymized versions of it in Tables 2 and 3, which re-identification risk is assessed."}, {"title": "2 Background and Positioning against EU and US Legislations", "content": ""}, {"title": "2.1 Re-identification Risk Calculated based on two Criteria: Severity and Likelihood", "content": "In cybersecurity, every risk assessment begins by identifying the \"feared event\" that describes what is actually feared and should be avoided. In the context of personal data, the \"feared event\" is of 3 categories: illegitimate access, unwanted modification, and disappearance of data [GL23] [SG20]. For re-identification, the \"feared event\" is simply \"illegitimate access\", as we are trying to prevent sensitive data from being disclosed to unauthorized persons. Once identified, the \"feared event\" is then assessed to provide a \"severity level\", which is then used to calculate the risk. For re-identification, the \"feared event\" is assessed by the \"Severity\" of the impact on individuals, which depends on the sensitivity of the data to be disclosed (Section 3). To explain the relevance of the \"Severity\" of an attack for re-identification risk assessment, let us consider the dataset in Table 1. Although it is relatively easy to re-identify User 3, because he is unique within the table (the only one who is 25), the related feared event would be the disclosure of information \"Colds\", which is not very sensitive compared to \"HIV\" ; therefore, the risk related to User 3 should be lower, compared to User 6, for example. However, \"Severity\" is only one part of the risk calculation, the other part is \"Likelihood\", which refers to the attackers' ability to execute an attack. Unlike the common definition of re-identification risk, which considers only the attackers' ability , cybersecurity risk considers both \"Severity\" and \"Likelihood\".\nDrawing on proven cybersecurity risk analyses, e.g. EBIOS [oFA19], we define the 2 vulnerabilities severity and likelihood, and the re-identification risk as follows:\n\u2022 Severity (S): Severity is related to the \"feared event\" and describes the impact on individuals if the \"feared event\" occurs. Severity in the context of re-identification reflects the sensitivity of the attributes to be disclosed and therefore, the impact on the individual if these sensitive attributes are disclosed.\n\u2022 Likelihood (L): Likelihood is the probability that an attack will occur. The likelihood describes the attacker's ability to perform an attack and how vulnerabilities can be exploited to do so. It is assessed by the exploitability of such vulnerabilities or by previous occurrences of such attacks. In the context of re-identification, the vulnerabilities can come from information inside the anonymized dataset (e.g. quasi-identifiers) and/or outside the anonymized dataset (e.g. flaws related to access controls). The exploitability describes how vulnerabilities can be used to link an individual to sensitive information.\n\u2022 Re-identification Risk (R): Based on the EBIOS definition of risk, we define re-identification risk as the probability of associating sensitive information with an individual and having an impact on that individual. It is calculated based on the severity of such an impact on the individual, and the likelihood of the attack. R can be calculated as follows: R = S x L.\nAnother point of interest in cybersecurity risk analyses, and one from which we can draw inspiration, is that it is not necessary to address all risks, but only the most important ones. Thanks to our methodology of assessing severity and likelihood at the attribute value level, this allows us to focus our attention on specific parts of the data, as shown in bold in Table 6."}, {"title": "2.2 Positioning the Contribution against Existing EU and US Legislations", "content": "The EU and US approaches to re-identification have some limitations; some are specific to each and others are common. Next, we position our contribution against both approaches."}, {"title": "2.2.1 US Approach Limitations", "content": "The risks considered by the US approach [EED08] [DEE10] are:\n\u2022 Prosecutor risk: the probability that a subject is unique in the dataset for an attacker who knows that the subject is in the dataset.\n\u2022 Journalist risk: the probability that a subject is unique in the population from which the dataset was sampled. The attacker does not know if the subject is in the dataset and assumes that if he is unique in the population from which the dataset was sampled, then he is unique in the dataset.\n\u2022 Marketer risk: the probability that each subject is unique in the dataset, the attacker is willing to identify as many subjects as possible. The risk of the journalist or the prosecutor is always greater than or equal to the marketer risk."}, {"title": "2.2.2 EU Approach Limitations", "content": "The vulnerabilities considered by EU in the WP29 Opinion on Anonymisation Techniques [Par14] are:\n\u2022 Singling out: the ability to isolate some or all of the records that identify an individual in the dataset. For example, in Table 1, the value \"37\" of \"Age\" attribute isolates User 6 because he is the only one of that age in the dataset.\n\u2022 Linkability: the ability to link at least two records concerning the same data subject or a group of data subjects (either in the same database or in two different databases). For example, using the demographic attributes in Table 1 (\"Age\", \"Gender\", \"Country\"), we can link this dataset to an auxiliary dataset containing the same attributes concerning the same individuals.\n\u2022 Inference: the ability to deduce, with significant probability, the value of an attribute from the values of a set of other attributes. For example, in Table 1, all men \"M\" have \"Colds\".\nWe consider \"Singling out\" to be a special case of \"Inference\". In fact, \"Singling out\" is used to isolate an individual within the dataset, and this is a case of perfect inference of the sensitive information. For example, in Table 1, User 6 can be singled out by his age (\"37\"), and this is used to infer that he has \"HIV\". The more general case of inference is described in Table 2 where inference is performed through equivalence classes. For example, using Group 1, we can perform a different case of perfect inference, as all the individuals in this equivalence class suffer from \"Colds\". The other equivalence classes do not allow a perfect inference as they are well diversified.\n=> Therefore, our framework only considers \"Inference\" and \"Linkability\" for com- puting the likelihood of an attack (see Section 4)."}, {"title": "2.2.3 Common Limitations of EU and US Approaches", "content": "Both approaches suffer from a mismatch between likelihood and re-identification. In fact, as explained in Section 2.1, a risk is not only about the ability of an attacker to perform an attack (likelihood), but also about the sensitivity of the information to be disclosed (severity). Our framework takes both severity and likelihood to compute the re-identification risk (Section 3 and Section 4)"}, {"title": "3 Computing the Severity (S)", "content": "Severity refers to the impact that disclosure of sensitive information could have on the individual, and this depends on the sensitivity of the attribute. For example, in Table 1, not all attributes have the same sensitivity because some may have more impact on the individual than others. For example, linking someone to a disease has a greater impact than linking them to their country or age as attribute \"Disease\" may reveal more compromising information about the individual. In addition, the difference in the sensitivity levels is also related to the specific values of the attributes. For example, for the \"Disease\" attribute, the value \"Colds\" is less sensitive than the values \"HIV\" or \"Diabetes\" because the latter two are serious diseases while the former is not. Our framework takes into account the severity of a risk based on the sensitivity of specific attributes and values.\nTo assess the sensitivity of a given attribute, we use the classification proposed by the French Data Protection Authority (CNIL) , which defines 3 types of effects on an individual, with 4 levels for each: negligible (level 1), limited (level 2), significant (level 3), maximum (level 4). The 3 types of effects are:\n\u2022 Bodily: refers to the impacts related to the body of the individual (e.g. impairment of physical integrity as a result of an assault, domestic accident, work accident, etc.)\n\u2022 Material: refers to the effects related to the material assets of the individual (e.g. insurance price increase, bank ban)\n\u2022 Moral: refers to impacts related to moral issues (e.g. sense of invasion of privacy and irreparable harm, discrimination)\nBased on this classification, we evaluate each of the attributes of Table 1 with the results provided in Tables 4 and 5. In Table 4, only the attribute type is considered and a Global Severity level, ranging from 1 to 4, is calculated as the maximum of all sensitivity levels associated with each impact type. In Table 5, we focus on the values of the \"Disease\" attribute and assign the most sensitivity to the values \"HIV\" and \"Cancer\", as the disclosure of this information may have a greater impact on the individual. Based on these two tables, we can already propose a first assessment of the initial Table 1. The resulting Table 6 highlights the entries that can have the greatest impact on individuals."}, {"title": "4 Computing the Likelihood (L)", "content": "As presented in Section 2.1, the Likelihood refers to an attacker's ability to perform a re-identification attack, and thus his ability to link a given piece of sensitive information to an individual. To perform this attack, the attacker may rely on vulnerabilities inside and/or outside the anonymized records. As concluded in Section 2.2.2, he can carry out an inference attack and/or a linkability attack."}, {"title": "4.1 Exposure of Attributes (Linkability)", "content": "The linkability vulnerability from the anonymized dataset is measured by the ability of the attributes to be linked to an auxiliary dataset. In fact, not all attributes have the same linking potential; some are easier to use than others. For example, in Table 1, the quasi-identifiers \"Age\", \"Gender\" and \"Country\" are easier to use for linkage than the quasi-identifiers \"Admission Date\" and \"Blood Type\". Indeed, the former can easily be found in an auxiliary dataset, as they are demographic data. To capture those characteristics, we introduce a new criterion called \"Exposure\". Exposure char- acterizes the ability of an attribute to be found in an auxiliary dataset. We define 4 levels of Exposure:\n\u2022 \"Internal Restricted\" (IR): Attributes related to specific operations that are not used outside of the context of those operations and are therefore difficult to find in another dataset (e.g. some medical test results, technical data, etc.).\n\u2022 \"Internal Extended\" (IE): Attributes used by several services within an organization, but not used outside the context of that organization (e.g. personnel number, department name, etc.).\n\u2022 \"External Restricted\" (ER): Attributes that can be found outside the organization but require in-depth research on social networks (e.g. smoker/non smoker, etc.).\n\u2022 \"External Extended\" (EE): Attributes that are widely used in different contexts and easily accessible from social networks or search engines (e.g. demographics, last name, first name, age, location data, etc.).\nHowever, while the exposure levels highlight whether the attributes are widespread enough to perform a linking attack, they are not sufficient to capture the linkability vulnerability. Indeed, we should also consider the granularity of the attribute, which refers to the number of different values of the attribute. For example, in Table 1, while the attributes \"Age\" and \"Gender\" are both \"EE\", they do not share the same Linkability level because the attribute \"Age\" is more granular (has more values) than the attribute \"Gender\", and is therefore easier to use for a linkage attack. The granularity of an attribute is captured by the \"Singling out\" vulnerability, which is already included in the inference vulnerability (Section 2.2.2), so it does not need to be explicitly included in the Likelihood computation."}, {"title": "4.2 Assessment of the Inference Vulnerability", "content": "The inference vulnerability is computed between the quasi-identifiers and the sensitive attribute to infer the values of the sensitive attribute using the quasi-identifiers. For example, in Table 1, the sensitive attribute is attribute \"Disease\", and using the attribute \"Country\", it is possible to guess some of the values of the attribute \"Disease\". For example, all people from \"Nigeria\" suffer from \"Colds\". Finally, we can combine different attributes to calculate the inference vulnerability. For example, all males \"M\" who are \"23\" suffer from \"Colds\" in Table 1.\nTo calculate the inference vulnerability, we use the Discrimination Rate\u00b9 (DR) metric [SLF17a] [SLF17b], although other metrics may be used:\n1. Weak: the DR is between 0 and 0.25\n2. Moderate: the DR is between 0.25 and 0.5\n3. Severe: the DR is between 0.5 and 0.75\n4. Critical: the DR is between 0.75 and 1"}, {"title": "4.3 Computing the Likelihood", "content": "Based on our proposed exploitability scale, presented in Figure 1, we are able to calculate the Like- lihood, i.e. the exploitability for our two anonymized dataset examples, as shown in Tables 9 and 10 for the k-anonymity dataset and Tables 11 and 8 for the HIPAA dataset. Note that the inference level (4-Critical) is obtained by calculating the DR of the combined quasi-identifiers or the individ- ual attributes. For a more conservative assessment, we can assume that an attacker would be able to access all the attributes belonging to the same exposure level at the same time. As indicated in bold in the Tables, the highest risk corresponds to an attacker using the combined attributes \"Age\", \"Gender\" and \"Country\", or the individual attributes \"Age\" or \"Country\" to infer \"very easily\" the \"Disease\" attribute of an individual, as the exposure level of these attributes are classified as \"External Extended\". The only difference between Tables 10 and 11 is related to the inference level of the \"Blood Type\" which is evaluated as severe vs critical thus leading to a difficult vs easy level of exploitability."}, {"title": "5 Computing the re-identification Risk", "content": "Based on our proposed re-identification risk scale, presented in Figure 2, we are able to assess the risk of re-identification for each anonymized dataset, Table 13 for the k-anonymity dataset and Table 12 for the HIPAA dataset. Both resulting tables show that the risk of re-identification is critical for both anonymized datasets. This is due both to the size of \"k\" in the k-anonymity Table 2, which is very small, and to the fact that there is a perfect inference for Group 1. A larger \"k\" would have provided a better level of security."}, {"title": "6 Conclusions", "content": "With the size of the data masking market estimated at $1.08 billion in 2025 and $2.14 billion by 2030 2, it is important to provide solutions to the enormous challenge posed by the field of database anonymization and the evaluation of such anonymization processing. The goal of this paper is to assist the industry with a practical and ready-to-use methodology, which is fully presented in this paper. The methodology introduces new concepts such as severity, exposure and operability, each of which plays a key role in the construction of the methodology. The results are not presented in the form of a cut-and-dried yes or no answer, but provide more information for assessing risk and interpreting results, and therefore greater precision, with criteria that can be explained and made transparent.\nThis contribution also has enormous potential in that it can be used to improve anonymization techniques by identifying which attributes or attribute values to focus on in the anonymization process for greater efficiency and to avoid degrading attributes that have little impact on the re-identification risk.\nThis contribution not only provides a methodology for assessing privacy risks, but also paves the way for designing more accurate anonymization techniques that will help achieve a better trade-off between privacy and data utility."}]}