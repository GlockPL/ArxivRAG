{"title": "The Emotional Spectrum of LLMs: Leveraging Empathy and Emotion-Based Markers for Mental Health Support", "authors": ["Alessandro De Grandi", "Andrea Raballo", "Federico Ravenda", "Fabio Crestani"], "abstract": "The increasing demand for mental health services has highlighted the need for innovative solutions, particularly in the realm of psychological conversational AI, where the availability of sensitive data is scarce. In this work, we explored the development of a system tailored for mental health support with a novel approach to psychological assessment based on explainable emotional profiles in combination with empathetic conversational models, offering a promising tool for augmenting traditional care, particularly where immediate expertise is unavailable. Our work can be divided into two main parts, intrinsecaly connected to each other. First, we present RACLETTE, a conversational system that demonstrates superior emotional accuracy compared to considered benchmarks in both understanding users' emotional states and generating empathetic responses during conversations, while progressively building an emotional profile of the user through their interactions. Second, we show how the emotional profiles of a user can be used as interpretable markers for mental health assessment. These profiles can be compared with characteristic emotional patterns associated with different mental disorders, providing a novel approach to preliminary screening and support.", "sections": [{"title": "Introduction", "content": "Empathetic chatbots represent a significant evolution in the field of conversational AI, designed not just to understand commands or queries, but to perceive and interpret the emotional states of their users. These advanced agents leverage Natural Language Processing (NLP) approaches to analyze text for emotional content, enabling them to engage in interactions that feel more human-like. By recognizing and responding to a wide range of emotions, empathetic chatbots can tailor their responses to provide comfort, advice, or support, thereby enhancing the user experience. This capability is particularly valuable in applications ranging from customer service and mental health support to personal assistants and social companions, where understanding and addressing the emotional needs of users can significantly impact satisfaction and outcomes (Crestani et al., 2022; Cena et al., 2023).\nWith the advent of advanced large language models (LLMs), the interaction experience with conversational agents has seen remarkable improvements. These new models exhibit enhanced understanding of natural language, greater contextual awareness, and the ability to generate more coherent and contextually appropriate responses. This technological leap has not only transformed how conversational agents interact with users but has also opened new avenues for analyzing and understanding human emotional expressions (Sekuli\u0107 et al., 2021).\nThe motivation behind this research is rooted in the understanding that mental health support can be augmented through the use of empathetic conversational AI. For this purpose, we developed a conversational system called RACLETTE (Responsive Analysis with Chatbot LLMs for Emotional and Therapeutical Tracking and Evaluation).\nThe key highlights of this paper include the development of a conversational model capable of detecting, understanding, and responding to emotional cues similar to human empathy (see Figure 1 for a visual example). This model is based on a novel approach to create emotion embeddings, which allows for the gradual construction of a user's emotional profile through interaction with the empathetic conversational model. We show how the user's emotional profile can be compared with known, pre-computed emotional profiles extracted from specialized datasets where individuals discuss their own experiences on specific mental health issues, with the rationale of potentially obtaining an explainable assessment of the mental state of the user engaging with the system.\nThe contributions and findings of this work are twofold: (1.) We define a method to tailor a chatbot, RACLETTE, for reacting empathetically to a specific user. RACLETTE uses an unconventional 3-turn structure where the model is trained to predict the user's emotion as a next-token prediction, leveraging the generative capabilities of the underlying Mistral 7B model, and responds empathetically based on the predicted emotion. Additionally, during the conversation, the user's emotional profile is updated, making the chatbot aware of the user's emotional condition in real-time. This updating allows the system to refine its understanding of the user's emotional state, enabling more precise and empathetic responses. (2.) We demonstrate how different mental disorders can be viewed as mixtures of specific emotions, guided by psychological theory. This framework suggests that emotional states are interconnected components forming distinct patterns linked to various mental health conditions. Emotional profiles for specific disorders can be pre-calculated and compared with users' emotional profiles to differentiate between conditions, potentially aiding in early detection and diagnosis. These emotional profiles can be viewed as markers for identifying different groups of mental disorders.\nThe paper is structured as follows. Section 2 discusses the Related Work. Section 3 presents the methodology, data, and provides a psychological rationale supporting our approach. Section 4 presents the results of our model on the task of correct emotion classification and the quality of empathetic response generation. Section 5 discusses the explainable method for generating embeddings associated with various mental disorders and shows qualitative results. In Section 6 we present the results of an experiment using emotional profiles to discriminate users belonging to different subreddit communities. Finally, Section 7 presents the conclusions."}, {"title": "Related Works", "content": "Significant research efforts have been devoted to developing sophisticated conversational models capable of understanding human emotions and generating empathic responses. The detection of sentiment and emotions has been recognized as crucial for the development of empathetic chatbots, as highlighted in (Felbo et al., 2017; Xu et al., 2018; Shin et al., 2019; Zhou et al., 2020). These works underline the importance of integrating emotional understanding capabilities into automatic dialogue systems to enhance human-computer interaction. In (Morris et al., 2018), authors demonstrated the feasibility of using corpus-based approaches to enable conversational agents to simulate subtle empathy. Recent research has focused on developing personalized conversational systems that can maintain coherence and user engagement throughout interactions (Madotto et al., 2019; Cho et al., 2022). These systems aim to create more natural and personalized dialogue experiences by adapting their responses to specific user characteristics and conversation contexts.\nFurthermore, the comprehensive scoping review by (Abd-Alrazaq et al., 2021) sheds light on patient perceptions of mental health chatbots, revealing a positive outlook but emphasizing the need for enhanced linguistic capabilities and personalized interactions.\nRecently, there has been a significant rise in the application of NLP techniques within the field of psychology (Le Glaz et al., 2021). This growing interest stems from the ability of NLP to extract valuable linguistic markers from both spoken and written communication, offering crucial insights into various mental health disorders (Agurto et al., 2023; Corcoran et al., 2020; Corona Hern\u00e1ndez et al., 2023; He et al., 2024).\nResearch has shown, for example, that measures of language coherence can serve as strong predictors of psychotic symptoms in individuals at high clinical risk (Just et al., 2020). Clearer language production deficits are typically observed during the first episode of psychosis (Gargano et al., 2022). One of the core symptoms, language disorganization, can be evaluated by analyzing the coherence and logical consistency of speech. For example, topic models (Blei et al., 2003) have been used to assess psychotic symptoms during patient interviews. In this context, the use of markers proves valuable for identifying differences within patient groups in an interpretable way. Our method aligns with the trend of leveraging the representational power of large language models to create useful markers for identifying trends within populations. This approach extends the current research in NLP applications for mental health, where language patterns serve as indicators of psychological states. By using emotion embeddings as markers, our method offers a novel way to quantify and analyze the emotional content of language, offering a computational framework for understanding mental health through affective patterns. Similar to how language coherence and organization have been used to predict psychotic symptoms, these emotional markers could potentially serve as early indicators or diagnostic aids for a range of mental disorders.\nBuilding upon these foundational works, this study draws inspiration from CAiRE's empathetic neural chatbot model by (Lin et al., 2020), and the innovative approach of using grayscale labels for emotion recognition as suggested by \u201cThe Emotion is Not One-hot Encoding\u201d by (Lee, 2022)."}, {"title": "Methodology", "content": "This work proposes a novel methodology, guided by the intuition that one of the fundamental qualities of a therapist is empathy. This direction aims to synthesize empathetic responses based on a broader understanding of affective language, circumventing the need for sensitive, real-world conversational data, enabling the model to detect emotions, and create explainable emotional profiles that can be useful for mental health assessment."}, {"title": "A Psychological Rationale for our Approach", "content": "Empathy has two main components:\n(1.) Cognitive Empathy, the intellectual ability to understand another person's emotions, thoughts, and motives. It involves the ability to comprehend someone else's mental state and why they might be feeling a certain way, which is essential for effective communication and social interaction.\n(2.) Affective Empathy, the ability to physically feel another person's emotions, often leads to emotional responses such as compassion or concern. For a more detailed discussion, see (Decety, 2005).\nThis research focuses on Cognitive Empathy, aiming to classify the emotional state of a patient and enable the system to respond appropriately. Teaching machines to physically feel the emotions of others raises deep ethical and philosophical questions about the nature of consciousness and emotion in artificial systems, a topic that will likely remain at the forefront of futuristic research.\nThe approach aims to leverage and enhance the capabilities of empathetic LLMs by integrating emotion embeddings into their framework, guided by the intuition that the emotional spectrum is complex, and many emotions may coexist in a single sentence or piece of text.\nWe define an emotion embedding as a high-dimensional vector representing an emotional state. Unlike word embeddings (Allen and Hospedales, 2019), which capture semantic meaning, emotion embeddings synthesize an individual's emotional state within a conversation by encoding affective information. A distribution is generated by sampling and normalizing multiple predictions from a probabilistic classifier. These distributions can also be interpreted as embeddings, enabling meaningful algebraic operations. Complex emotions are encoded and represented by sequentially accumulating through the summation of many emotion embeddings, e.g., by accumulating over the many interactions that occur over an entire conversation (see Figure 2 for a visual explanation).\nAn emotion embedding can be defined as:\nEmotion Embedding = $\\sum_{j}^{K} a_{j}e_{j}$\nwhere $\\sum_{j}^{K} a_{j} = 1$, K is the total number of all the different type of emotions considered and $e_{j}$ is a specific emotion."}, {"title": "Datasets", "content": "In this work, three main sources of open-source data were used:\nEmpathetic Dialogues Dataset (Rashkin et al., 2018): it has been used to train the RACLETTE model to identify emotions and respond empathically. This dataset is a large-scale multi-turn empathetic dialogue dataset collected on the Amazon Mechanical Turk, containing 24,850 one-to-one open-domain conversations. This dataset was selected for this task because, other than its high quality and appropriate size, it considers a much wider range of emotions compared to all other available datasets, which usually consider only a very limited subset (5-8) of fundamental emotions (Zahiri and Choi, 2017; Li et al., 2017).\nReddit Mental Health Dataset (Low et al., 2020): a collection of posts from specific Reddit forums (also called subreddits, Table 3 shows all the subreddits considered) have been used to construct the discrete distributions associated with each mental disorder to extract emotion embeddings.\nDailyDialog Dataset (Li et al., 2017): a collection of posts used to establish a control group for the emotional profiles assessment. It contains 13,118 dialogues split into a training set with 11,118 dialogues and validation and test sets with 1,000 dialogues each."}, {"title": "Tailoring an LLM to React Empathetically", "content": "For this study, we chose to fine-tune the Mistral 7B model (Jiang et al., 2023), a 7-billion-parameters state-of-the-art LLM, known for its great performance combined with both computational and memory efficiency. This approach aligns with recent findings from (Sekuli\u0107 et al., 2024), which demonstrate that fine-tuning LLMs on task-oriented dialogue data can reduce hallucinations.\nThe Empathetic Dialogues Dataset is purposefully formatted using a specific structure that allows to fully leverage the causal attention mask of the transformer decoder model to generate tokens for both the empathic response prediction and dialogue emotion detection tasks. Placing prompts before emotion labels enforces the autoregressive property of the model during training and inference (Sun et al., 2023), allowing the generative model to be used both as a classifier and a conversational agent. The model learns to predict the next tokens by only attending to previous positions in the sequence in order to generate predictions sequentially. Let $P(y<emotion>|Y_{1}, Y_{2},..., Y_{N})$ be the probability of the model predicting the emotion token Y<emotion> given the sequence of previous tokens $Y_{1}, Y_{2},..., Y_{N}$, then the model's objective can be defined as:\n$\\max \\sum_{t=1}^{N} log P(y<emotion>|Y_{1}, Y_{2},\u2026\u2026\u2026, Y_{N})$\nwhere N is the length of the sequence.\nWhen generating the prediction of an emotion, the model iteratively produces the tokens that are more likely, given the previous tokens (see Figure 2). Unlike deterministic methods, this process can be guided to generate a diverse set of emotions by iteratively sampling over the predicted probability distribution of all tokens in the vocabulary. In this implementation, Top-K Sampling is used (Holtzman et al., 2019), which limits the sampling pool to the top-K most probable tokens, in this case, top-10, balancing diversity with relevance. Then to generate multiple emotions, this process is repeated 10 times independently for each prompt. Let V be the vocabulary and K be the sampling parameter:\nTopK(P(y_{t}|Y_{<t}), K) = y_{i} \\in V: P(y_{i}|Y_{<t})\nis among top-k probabilities.\nThese empirical distributions are aggregated across the entire conversation to obtain the emotional profile of the speaker. Let C be the set of all prompts in a conversation and $e_{i,k}$ the sampled emotion (K = 10 samples in total) for prompt i :\nEmotional Profile = $\\frac{1}{\\vert C\\vert} \\sum_{i \\in C} \\frac{1}{K} \\sum_{k=1}^{K} e_{i,k}$\nFor this study, an unconventional 3-turns structure was implemented (see Figure 1 for an example). It can be summarized as Prompt, Emotion, and Response, separated by the special tokens: <|prompter| >, <|emotion| >, <|assistant| > and < endoftext >.\nWhen predicting empathetic responses, the model will attend to the previous tokens in its context, (1) the whole history of the conversation, (2) the current prompt followed by the emotion, and learn to generate the appropriate reply as seen in the training dataset."}, {"title": "Emotion Recognition and Empathetic Response", "content": "Table 1 shows the results of RACLETTE in detecting the correct emotion for each conversation both at prompt and conversation levels. The results related to individual prompts refer to the correct classification of emotions for single conversation turns. Regarding the conversation, this approach progressively concatenates each prompt, its predicted emotion, and subsequent response, thus enriching the model's contextual awareness with each conversational turn. The accumulated emotion distributions for each prompt contribute to a more precise classification, resulting in a 3% increase in accuracy (from 56% to 59%). Notably, this methodology enhances accuracy, as the expanding conversational context provides more information for discerning the speaker's emotional profile.\nOut of approximately 10.9k utterances present in the test set, the report categorizes 5,242, as the classification is made solely on the speaker's contributions. In addition, to evaluate empathic replies to each of the speaker prompts, this table includes the BERTSCORE (Zhang et al., 2019), an automatic evaluation metric for text generation. Unlike traditional metrics that rely on exact word matches or n-grams, BERTSCORE evaluates the similarity between predicted and target replies by analyzing contextual embeddings of tokens obtained with the BERT model. This approach allows for a semantical understanding of the model's performance, capturing the comparison of empathetic responses beyond mere lexical matching. Notably, a BERTSCORE of 0.87 indicates high semantic similarity between the responses given by the model and the target replies contained in the test set that were given by the human listeners.\nTable 2 compares the overall emotional accuracy of RACLETTE with the accuracy of CAIRE, as reported by (Lin et al., 2020). For completeness, in addition to CAIRE, we present other baselines from the literature that have used the same dataset to evaluate their performance. As benchmarks for emotion classification accuracy, we consider the following approaches: (1.) In (Chen et al., 2024), authors propose a cause-aware empathetic generation method using Chain-of-Thought fine-tuning on Large Language Models. (2.) In (Li et al., 2022), authors introduced a knowledge-enhanced empathetic dialogue generation method incorporating external knowledge and emotional signals. (3.) The approach from (Gao et al., 2021), who proposed incorporating emotion cause recognition into empathetic response generation using an emotion reasoner and gated attention mechanism.\nWe report the accuracy value as presented in works that have used the same dataset, as shown in their respective manuscripts.\nTable 2 shows how RACLETTE outperforms the benchmarks considered. Also in this case, it can be observed that the choice of fine-tuning a generative model, leveraging its autoregressive characteristics for classification, leads to the best results."}, {"title": "Mental State as Mixtures of Emotions", "content": "This experiment shows a possible novel approach to create explainable mental state embeddings based on emotions, expanding the conversational model's role from empathetic response generation to emotion analysis and diagnostic tool. The approach involves leveraging the fine-tuned model from the previous experiment, primarily as an emotion classifier. The idea is to extract emotional embeddings, used as markers that are indicative of specific mental disorders from specialized corpora, in this case from social media interactions in mental health forums. The goal is to later compare the distinctive emotional profiles obtained in this experiment to the profiles obtained from users interacting with the model in a conversation.\nFor this experiment, considering the lack of professionally labeled data, various datasets are gathered from Reddit, a social news website and forum where content is socially curated and promoted by site members through voting. It must be acknowledged that the data obtained from Reddit or other social media platforms may not accurately represent the broader population with mental illnesses, as it only captures those who choose to discuss their experiences online.\nReddit is organized into forums known as \u201csubreddits\u201d. Each subreddit focuses on a specific topic, interest, or theme, creating a unique community within the broader Reddit platform. In Table 3 all the considered subreddits obtained from (Low et al., 2020) are reported (for a more in-depth discussion we refer to Section E in Appendix), together with a graphical visualization in Figures 5 and 6 in Appendix of the relative mental state embeddings based on emotions obtained by processing 1,000 posts from each subreddit.\nIn the approach described in this section, embeddings for each mental disorders were generated by processing posts from the respective subreddits. The methodology involves the empathetic conversational model obtained in the previous experiment. However, rather than responding with both emotion and a reply, the posts are segmented into individual phrases. For each phrase, the model predicts a set of 10 emotions. These predicted emotions are then aggregated across all posts by summation and subsequently normalized. This process results in a characteristic emotional distribution profile for each mental disorder.\nThis experiment yielded interesting results: the obtained emotion embeddings show significant differences across a spectrum of Reddit communities. Also, similarities across related disorders were to be expected. For instance, depression and suicide, or addiction and alcoholism, show consistent similarities. Overall, these distributions can provide insights into how individuals discussing their experiences with similar conditions might perceive and express their feelings. In Figure 4(A), we observe the mental disorder representations in a two-dimensional reduced space after applying t-SNE on top of the emotional embeddings. We can observe how mental disorders such as alcoholism, addiction, and eating disorder are close in the embedding space, as are depression and loneliness or schizophrenia and post-traumatic stress disorder (PTSD). We can also observe interesting properties of our representations, for example, by summing the depression and schizophrenia's embeddings, a new representation can be obtained, that is very close, in the embedding space, to bipolar.\nThe assumption that mentally distressed individuals show identifiable skewed patterns of emotions must be addressed, by first establishing a normal distribution for comparison. For this, the Daily Dialogue Dataset (Li et al., 2017), a high-quality multi-turn open-domain English dialogue dataset, was chosen as a control group. On average there are around 8 speakers turns per dialogue with around 15 tokens per turn where people discuss their daily lives, the whole training set was used to extract the embedding for this dataset.\nThe order of the emotional features in the embeddings can be arbitrary. But as an example, for clarity and visual comparison, the control group embeddings and the depression embeddings can be ordered according to what are most commonly considered positive and negative emotions: Figure 4(B-C) clearly shows the contrast in emotional profiles, emphasizing the marked disparities in how emotions are manifested and experienced by those within the reddit depression community, exhibiting an extremely skewed distribution towards negative emotions, compared to individuals engaging in daily dialogues."}, {"title": "Reddit's Emotion embeddings applied to the Detection of Suicide Risk", "content": "This experiment aims to evaluate the use of emotion to create mental state embedding as a mechanism for diagnosing the potential risk of suicide. For lack of a professionally labeled dataset, this experiment, like the previous one, focuses on Reddit's users. To compare our approach with other related tasks and methods, we have built a dataset for binary classification of general conversation text versus suicidal text. We used the two subreddits CasualConversation and SuicideWatch, where CasualConversation is a subreddit for general conversation, and has generally been used by other methods as data for a clinically healthy class in other works (Haque et al., 2021; Shen and Rudzicz, 2017). This dataset is part of a larger collection available on Kaggle\u00b9, which has been carefully cleaned to ensure the reliability of the data. We select 5% of the initial samples at random as a test set (\u2248 10,585 samples). After inspecting posts for anomalous length deviations from the average, those lacking informative content are removed.\nTo compute the sample embeddings, each post is divided into sentences, with 10 emotions predicted per sentence. The final embedding aggregates these emotions across all sentences in the post, following a similar approach as used in Section 5 to extract reference embeddings.\nThe methodology encompasses the use of three distinct metrics for comparing embeddings: Kullback-Leibler (KL) divergence, Jensen-Shannon (JS) divergence, and Cosine Similarity (CS). Our approach is based on the use of emotional profiles embeddings that are most closely associated with an elevated risk of suicide and match them against the user's emotional profile. Table 3 compares various emotion embeddings, focusing on their differences from the suicide embedding, measured by KL, JS, and CS. The results show emotional proximity between Suicide and Depression, as well as Borderline Personality Disorder, followed by Bipolar Disorder, Addiction, PTSD, and Schizophrenia. This pattern aligns with psychological insights that these mental health conditions are often linked to an increased risk of suicidal tendencies (Song et al., 2020).\nFor these reasons, this experiment will focus on the use of these specific emotion embeddings, considering the embedding that is most similar to what is obtained by processing the sample post, and mapping it to the predicted label, in an unsupervised fashion, as follows:\nPositive labels: suicide, depression, borderline personality disorder (BPD), bipolar disorder, PTSD, addiction, and schizophrenia. By combining these particular embeddings, the study aims to capture a spectrum of characteristic emotional patterns that are potentially indicative of an elevated risk of suicide.\nNegative labels: normal and uniform distributions, where normal is obtained from the Daily Dialogue dataset, and embedding obtained from\u00b9https://www.kaggle.com/datasets/suicide-watch"}, {"title": "Results for Mental Health Classification", "content": "Table 4 shows the performance metrics: precision, recall, F1 score and accuracy. For each similarity metrics Kullback-Leibler divergence, Jensen-Shannon divergence, and Cosine Similarity we also introduce a combined method, where if any of these methods detect a risk of suicide, the label is assigned as positive. This experiment is designed to maximize recall, a critical metric in scenarios where missing a positive instance has severe consequences, thus reducing the emphasis on precision and false positives. As the quantitative results show, this approach achieves high recall at the cost of other metrics. Additionally, these methods are compared with state-of-the-art unsupervised approaches based on RoBERTa (Liu et al., 2019) and BERT's (Devlin et al., 2019) embedding representations, before grouping them into two classes using a K-Means clustering approach, as done in (Subakti et al., 2022).\nThe results show RACLETTE's Combined method achieving the highest recall of 0.95, indicating superior ability to identify relevant cases, though this comes with a trade-off in precision at 0.63. Conversely, RoBERTa leads in precision at 0.72, but with lower recall at 0.84. The KL Divergence variant of RACLETTE stands out for its balanced performance, maintaining strong scores across all metrics (precision: 0.71, recall: 0.90, F1: 0.79, accuracy: 0.77). Both JS Divergence and Cosine Similarity methods show similar patterns, with high recall (0.93) but lower precision. The color intensity (green shading) in Table 4 indicates better performance, visually highlighting that RACLETTE's approaches generally outperform the benchmark models.\nA key advantage of this method is that it generates explainable representations and emotion embeddings, which can be visually inspected, providing valuable insights into an individual's emotional profile."}, {"title": "Conclusions", "content": "This paper introduces the RACLETTE system, which addresses two critical challenges in mental health support: the need for empathetic AI-driven conversation and reliable assessment tools. By fine-tuning a LLM, we demonstrate that it's possible to create effective conversational agents that can accurately recognize users' emotional states while generating high-quality empathetic responses, all while avoiding the use of sensitive clinical data. The system not only achieves state-of-the-art performance in emotion recognition, but also introduces a novel methodology for creating emotional profiles. These profiles, generated by aggregating emotion distributions from user interactions, serve as interpretable markers that can be compared with characteristic patterns associated with various mental health conditions. Our experimental results demonstrate both the system's effectiveness in maintaining empathetic conversations and its potential as a preliminary screening tool through the analysis of emotional embeddings."}, {"title": "Limitations", "content": "One of the main critical point of this work is represented by the quality and reliability of the emotional data used for training. Emotional data must be diverse and accurately labeled to ensure the model can understand and respond to a wide range of emotional expressions. This data collection process is complex and time-consuming, often requiring manual annotation by experts to maintain high standards.\nFurthermore, findings have revealed that individuals affected by mental disorders commonly turn to social media to share their personal experiences, seek out information about mental health and treatment options, and either offer or gain support from others who are dealing with similar challenges (Naslund et al., 2020; Dodemaide et al., 2022). However, noise in the data is another significant limitation. For example, individuals may seek advice on behalf of others, such as family members, which can introduce inaccuracies. Self-reported information, while valuable, may not always be as reliable or accurate as clinically diagnosed conditions due to personal biases, misunderstandings, or intentional misreporting. Additionally, online self-expression can vary greatly between individuals, influenced by factors such as cultural differences, personal communication styles, and the specific context of the interaction.\nConfounding factors, such as comorbidities, must also be taken into account. Individuals with multiple overlapping conditions may exhibit complex emotional and psychological profiles that are difficult for the model to parse accurately. Moreover, the way individuals express themselves online can differ significantly from in-person interactions, adding another layer of complexity to the model's ability to interpret and respond appropriately.\nDespite these challenges, the methodology addresses crucial privacy and confidentiality issues that are particularly important in the mental health domain. However, it does not fully address the ethical implications of using AI as a clinical tool, including the potential for misuse and the need for safeguards against harmful or biased behaviors in the conversational model. Continuous improvements and validation against clinical standards are essential to ensure that these tools effectively integrate into traditional care pathways, enhancing rather than disrupting the therapeutic process."}, {"title": "Ethical Considerations", "content": "The proposed methodology for mental health support and assessment, while innovative, brings several ethical considerations to the forefront that must be addressed to ensure responsible deployment.\nThere is a potential for AI to be misused as a clinical tool. Without proper safeguards, these models could exhibit harmful or biased behaviors, leading to adverse outcomes for users.\nImplementing ethical safeguards is crucial to mitigate the risks associated with AI in mental health. Developing clear guidelines on the appropriate use of AI, managing sensitive data protocols, and ensuring transparency in operations are essential steps. Involving ethicists, and clinicians in the development process will help create a balanced and ethical approach.\nIt is also crucial to clearly communicate the supplementary nature of these tools and the necessity of professional evaluation and treatment. There is a risk that users may become overly reliant on automated mental health support, potentially neglecting the importance of seeking help from qualified professionals. By ensuring that these tools are integrated into traditional care pathways, they can enhance the therapeutic process, providing additional support while maintaining the central role of professional mental health care providers."}, {"title": "Finetuning Details", "content": "For finetuning, this study employed SFTTrainer and QLoRa, implemented in the respective HuggingFace libraries (Wolf et al., 2019; Dettmers et al., 2023). The model parameters are quantized to the 4-bit NormalFloat(nf-4) datatype and the computations are performed in 16-bit Brain-Float (bFloat16). For reproducibility purposes, the following LoRa hyperparameters were used: scaling factor lora_alpha = 16, dropout probability lora_dropout = 0.1 and the rank of the update matrices lora_r = 64. The training hyperparameters: batch_size = 1, gradient accumulation steps = 16, warmup_ratio = 0.3, cosine learning rate scheduler with an initial l_r = 2e - 5, the model was trained for 3 epochs, using AdamW optimizer."}, {"title": "Error Analysis", "content": "This section presents the model's performance in predicting correct emotions from the Empathetic Dialogues dataset, analyzing results at both individual prompt level (Table 5) and conversation level (Table 6). While our model demonstrates overall good emotional accuracy, certain metrics for specific emotions exhibit suboptimal performance. This is particularly evident with emotions that are closely related but vary in intensity, such as \u2018angry' and 'furious'. These emotions, while technically distinct, can be challenging to differentiate even in human evaluation, as they often share similar underlying sentiments and can sometimes be considered interchangeable."}, {"title": "Beyond the 32 Emotion Classes", "content": "Even though having 32 emotion classes may seem difficult enough for the classification task, ideally an empathic conversational agent should be able to understand and recognize the broadest possible range of emotions. Table 7 shows that RACLETTE also correctly predicts emotions that are not part of the dataset used for fine-tuning, especially when prompts contain explicit references to these new emotions, showing a great understanding of the task. This phenomenon is indicative of our model's ability to generalize beyond its explicitly taught categories, showing that the model has effectively generalized the concept of emotion beyond its training examples, which is particularly fascinating in the context of emotion recognition. The base model already had some semantic understanding of the words associated with the concept of emotion, which are likely used in similar contexts and are similar to each other in the input embedding space. The fine-tuning process further enforced the similarity in the learned representations, while the generative method used for the classification task allows for more flexibility compared to conventional classification approaches.\nIn summary, this feature is a consequence of an unconventional use of a generative pre-trained transformer decoder model as a classifier. It allows the fine-tuned model to sometimes \"think outside the box\" of the constrained range of emotions typical of conventional classification approaches (Table 7 shows examples of \u201cout-of-training-labels\" predictions). For consistency in the experiments, these new emotions are discarded as outliers but serve as an interesting example to show the potential of generative models used for classification tasks."}, {"title": "Qualitative results and analysis", "content": "The following examples show the inputs, targets, and prediction outputs, qualitatively comparing the predictions with the targets used to evaluate the model on the Empathetic Dialogues dataset. These example conversations are taken from the test set, during the quantitative evaluation of the fine-tuned model."}, {"title": "Dealing with coexisting emotions", "content": "This example aims to show how the model deals with coexisting emotions, adjusting its prediction as the conversation goes along:\nINPUT PROMPT: <|prompter|>I\ncouldn't wait to go to the concert.<lendoftext|><lemotion|>\nTARGET EMOTION: excited\nTARGET RESPONSE: Which Concert?\nPREDICTED EMOTION: (excited: 3, anticipating: 7)\u2192 anticipating\nPREDICTED RESPONSE: What concert was it?\nFor the first prompt in this example conversation, the target emotion is 'excited', and it will be the same for the whole conversation, as the dataset is structured this way. The 10 emotions predicted are 3 \"excited\" and 7 \"anticipating\". Given the prompt: \"I couldn't wait to go to the concert.\", both emotions classified by the model seem to be correct. Even though the target is \"excited\" the model decided that \"anticipating\u201d is more likely, which actually seem appropriate, if not more accurate than the target emotion.\nRegarding the response, the model predicts a very similar response as the target, semantically the same. The conversation goes on, appending the predicted emotion to the conversation history, during evaluation the target response is appended instead of the predicted response, otherwise, the conversations might not make sense. Because, obviously, the following prompt in the dataset is responding to the target reply of the previous one. So the conversation continues:\nINPUT PROMPT: <|prompter|>I couldn't\nwait to go to the concert.<lendoftext|>\n<lemotion|>anticipating<lendoftext|>\n<lassistant|>What concert was it?<lendoftext|>\n<|prompter|>The U2 concert. Tickets\nwere really expensive and I never\nthought we would be able to go, but\nsomehow we did!!!<lendoftext|>\nTARGET EMOTION: excited\nTARGET RESPONSE: Wow, that's awesome!\nI have never been to an actual concert.\nPREDICTED EMOTION: (excited: 8, joyful:\n1, anticipating: 1)\u2192 excited\nPREDICTED RESPONSE: Wow, that's awesome! I've always wanted to go to a U2 concert!\nThe final prediction is computed by aggregating all the emotions across the entire conversation, establishing 'exited' as the prominent emotion, in this example:\nCONVERSATION TARGET EMOTION:\nexcited\nCONVERSATION PREDICTED EMOTIONS:\n('excited': 11, 'anticipating': 8, 'joyful':\n1)\u2192 excited\nThis example also provides an interesting insight on empathy, occasionaly the model seems to mimic the emotions of the prompter, in this conversation, the speaker expresses excitement and the model reacts by also expressing excitement. This behavior has been inferred from the data by imitating humans. Sometimes when emotions resonate to others, they become contagious, and the involountary empathic response is to feel and express this shared emotion, it is a natural way of showing understanding of how the other is feeling and helps people relate to each other. It is notably interesting to observe the model pick up on this subtle but fundamental aspect of empathy."}, {"title": "Dealing with different intensities of the same emotion", "content": "The following is another simple example"}]}