{"title": "Evaluating improvements on using Large Language Models (LLMs) for property extraction in the Open Research Knowledge Graph (ORKG)", "authors": ["Sandra Schaftner"], "abstract": "Current research highlights the great potential of Large Language Models (LLMs) for constructing Scholarly Knowledge Graphs (SKGs). One particularly complex step in this process is relation extraction, aimed at identifying suitable properties to describe the content of research. This study builds directly on previous research of three Open Research Knowledge Graph (ORKG) team members who assessed the readiness of LLMs such as GPT-3.5, Llama 2, and Mistral for property extraction in scientific literature. Given the moderate performance observed, the previous work concluded that fine-tuning is needed to improve these models' alignment with scientific tasks and their emulation of human expertise. Expanding on this prior experiment, this study evaluates the impact of advanced prompt engineering techniques and demonstrates that these techniques can highly significantly enhance the results. Additionally, this study extends the property extraction process to include property matching to existing ORKG properties, which are retrieved via the API. The evaluation reveals that results generated through advanced prompt engineering achieve a higher proportion of matches with ORKG properties, further emphasizing the enhanced alignment achieved. Moreover, this lays the groundwork for addressing challenges such as the inconsistency of ORKG properties, an issue highlighted in prior studies. By assigning unique URIs and using standardized terminology, this work increases the consistency of the properties, fulfilling a crucial aspect of Linked Data and FAIR principles \u2013 core commitments of ORKG. This, in tum, significantly enhances the applicability of ORKG content for subsequent tasks such as comparisons of research publications. Finally, the study concludes with recommendations for future improvements in the overall property extraction process.", "sections": [{"title": "1 Introduction", "content": "Large Language Models (LLMs) have seen rapid adoption since the release of GPT- 3 in 2020 and have had a significant impact on many aspects of modern life, serving as assistants in the workplace or as creative tools for leisure activities. LLMs have also gained considerable importance in research, functioning as tools for literature searches, writing assistance, and even as subjects of investigation themselves [1]. A relatively new field of research is the integration of LLMs and Knowledge Graphs (KGs), which aims to generate useful synergies. KGs offer the advantages of accuracy and structured knowledge, while LLMs excel in contextual understanding and language comprehension [2]. These qualities make LLMs ideal tools for creating KGs based on natural language [3],[4]."}, {"title": "2 Problem Analysis", "content": "In the field of KGs for scientific publications, the requirements are particularly high, as understanding the language of scientific texts and ensuring the precision of information extraction are critical. A well-known initiative in this area is the Open Research Knowledge Graph (ORKG) [5], which not only represents metadata but also captures the content of research publications in the form of an SKG. The ORKG is manually curated by experts and authors using a crowdsourcingapproach. According to members of the ORKG team, the ORKG adheres to best practices (e.g., FAIR principles) and provides services to support the production, curation, publication, and use of FAIR scientific information [6].\nHowever, the current manual curation approach has certain disadvantages, such as the significant time required, which hinders scalability, and the inconsistencies arising from the crowdsourcing process [7], [8]. To address these issues, Nechakhin et al. [8] conducted a study evaluating the readiness of LLMs for extracting properties, referred to as dimensions in their study. They concluded that the prompt engineering strategies few-shot prompting, and Chain of Thought (CoT) prompting did not provide better results than zero-shot prompting without applied techniques. Furthermore, when comparing LLM-generated results with ORKG gold-standard properties, they found that the \u201calignment with scientific tasks and mimicry of human expertise\" [8] was insufficient. Consequently, they recommended using LLMs merely as suggestion tools for human experts and identified fine-tuning as necessary for achieving better results [8].\nThis paper aims to demonstrate that significant and highly impactful improvements in LLM results can be achieved not only through fine-tuning but also through better-"}, {"title": "3 Related Work", "content": "In the following three subsections, the topic of this study is situated within the current research landscape on Scholarly Knowledge Graphs (SKGs), LLMs for Knowledge Graph (KG) construction, and the specific task of relation extraction."}, {"title": "3.1 Scholarly Knowledge Graphs (SKGs)", "content": "In response to the challenges posed by the ever-growing number of scientific publications, organizing publication information in SKGs has been proposed as a solution. Unlike the widely used PDF format, SKGs are more amenable to machine processing and, through the encoding of semantic relationships via ontologies, pave the way for sophisticated analyses and advanced services, such as forecasting research trends and generating scientific hypotheses [14], [15], [16]. Furthermore, SKGs contribute to making research findable, accessible, interoperable, and reusable (FAIR) [17]. Quality criteria for SKGs can be derived from the Linked Open Data principles and the FAIR guidelines [7].\nAmong the SKGs widely referenced in the relevant literature is the ORKG, for example in the papers by Borrego et al. [14], Verma et al. [16], Karmakaretal. [17], and Meloni et al. [18]. According to a recent evaluation in 2024 by members of the ORKG team, the ORKG faces significant challenges, including high workload and inconsistencies [7]. Additionally, the literature identifies several further issues of existing KGs such as incompleteness [14] and lack of accuracy [5]. Recent studies suggest that leveraging LLMs in KG construction could help address these challenges, a topic explored in more detail in the next subsection."}, {"title": "3.2 LLMs for Knowledge Graph (KG) Construction", "content": "Before the advent of Large Language Models (LLMs), context posed a significant challenge for Natural Language Processing (NLP) methods [18]. Recent advancements in LLMS recognized for their superior knowledge completion, context awareness, linguistic capabilities, and reasoning have heightened expectations for their role in KG construction, with potential to replace traditional methodologies [1], [4], [8], [19]. Zhu et al. [3] describe LLMs as \u201cprimary tools for KG construction\".\nIn a review paper, Pan et al. [2] outline that the combined use of KGs and LLMs can leverage synergies due to the complementary strengths and weaknesses of these technologies. While KGs excel in accuracy, decisiveness, interpretability, and knowledge structuring, LLMs demonstrate exceptional capabilities in natural language understanding, processing, generalizability, and general knowledge [2]. These attributes of LLMs not only mitigate the prevailing issue of lacking language understanding of traditional methods but also enable greater scalability and allow continuous updates for evolving KGs, unlike embedding-based methods [20].\nHowever, studies also highlight limitations of LLMs that can affect the quality of constructed KGs. A major issue is known as hallucinations, where LLMs generate"}, {"title": "3.3 Relation Extraction for Knowledge Graph (KG) Construction", "content": "The task of ORKG property extraction falls under the broader scope of Relation Extraction (RE), a widely used term in the respective literature. As outlined by Kerijiwal et al. [29], relations are actually a subtype of properties, which can be categorized into object properties (also referred to as relations) and datatype properties (also known as attributes). Furthermore, the term predicates is often used synonymously with properties. In graphs, properties are represented as edges [29].\nAccording to Jiang et al. [30], the task of RE has been significantly transformed by the advent of LLMs, as they are capable of comprehending input texts and identifying complex relationships without the constraints of predefined patterns. Various studies have already demonstrated promising results in employing LLMs for RE. Based on these findings, Wadhwa et al. [12] even conclude that LLMs should become the default approach for RE.\nJiang et al. [30] refer to RE performed by LLMs as generative RE (GRE) and distinguish three forms: open, semi-open, and closed RE. They note that most"}, {"title": "4 Materials and Methods", "content": "The following subsections describe the underlying materials (Subsection 4.1) as well as the methods used in this study (Subsections 4.2, 4.3, and 4.4). All materials and scripts employed for method implementation and evaluation are publicly accessible on the project's GitHub page2."}, {"title": "4.1 Material: Preliminary comparison study and evaluation dataset by Nechakhin et al.", "content": "This study builds on the work titled \u201cEvaluating Large Language Models for Structured Science Summarization in the Open Research Knowledge Graph\" by Nechakhin et al. [8]. It replicates the original study while in parallel implementing and validating proposed improvements. Consequently, much of the initial material originates from Nechakhin et al.'s study [8], hereafter referred to as the preliminary study.\nThe primary resource for replicating the study was the dataset published by Nechakhin et al.3 This dataset, provided as a CSV file, includes information on 153 ORKG contributions that serve as the subject of investigation, as well as the experimental results from Nechakhin et al.'s study [8]. The columns of the dataset are described by the authors on the dataset's download page3."}, {"title": "4.2 Method: Advanced prompt engineering techniques applied", "content": "In the preliminary study, the three prompting strategies zero-shot, few-shot [35] and Chain of Thought (CoT) [36] were tested. According to Nechakhin et al., the results demonstrated that \u201cthe analysis shows that the utilization of more advanced prompting techniques did not necessarily result in superior outcomes, which leads us to believe that our original zero-shot prompt is sufficient for our task's completion\" [8]. However, the paper does not provide detailed results comparing the prompting strategies. The conclusion that prompt engineering did not improve the results, which was reproduced in this study using the same prompts, contradicts the broader consensus in research that well-applied prompt engineering can significantly enhance the performance of LLMs.\nThe author of this paper hypothesizes that the prompt engineering techniques in the preliminary study were not applied correctly. Possible reasons for the poor performance of these strategies, informed by relevant scientific insights, are discussed below. Recommendations for improvements derived from the literature are then applied to develop an optimized prompt for the specific task of property extraction.\nOne of the most well-known prompting techniques is few-shot learning, also referred to as in-context learning (ICL). This involves including examples in the"}, {"title": "4.3 Method: Property matching to ORKG property URIs", "content": "Matching properties to unique URIs is the next step in the KG construction process following property extraction, often referred to as \"relation mapping\" [21] [44]. \u03a4\u03bf avoid confusion with the term \"mappings\" used by Nechakhin et al. [8] for comparing the number of similar properties to the gold standard, this study adopts the term \u201cmatching\u201d for aligning properties to URIs, which is also used in the literature [44]. Through matching, the extracted properties \u2013 initially just words"}, {"title": "4.4 Method: Evaluation", "content": "The evaluation of LLM results is conducted in exactly the same manner as in Nechakhin et al.'s preliminary study [8]. The primary reason for this approach is to ensure maximum comparability. Additionally, the author considers the evaluation method used by Nechakhin et al. [8] to be effective, as it does not rely on a strict (exact matching) evaluation against the gold standard but instead employs a softer matching evaluation with alignment and deviation. This approach has been recommended by other studies as well [12], [30]. Specifically, Nechakhin et al. [8] instruct the LLM GPT-3.5-Turbo which is used as a judge, to rate the semantic alignment or deviation between two lists \u2013 the LLM extracted properties and the gold standard properties on a scale from 1 to 5.\nThe combination of alignment and deviation provides an inherent control mechanism for the overall accuracy of the evaluation.\nFurthermore, no need was identified to modify the evaluation method, as it is assumed that the surprising result of Nechakhin et al. that the prompting techniques few-shot and CoT did not show improvements \u2013 likely stems from other causes already discussed in Subsection 4.2. The evaluation method itself appears to be well-designed, and the use of LLMs for evaluating LLM responses is supported by several other studies. Nechakhin et al. cite examples of studies that use LLMs for evaluating translation and summary quality [8]. Similarly, in the domain of constructing KGs, there are studies that utilize LLMs for evaluation [23], including specifically for the task of relation extraction [30].\nTo measure the significance of differences between the various prompting strategies, the sign test is applied. The hypotheses tested include: (1) that the few- shot and CoT strategies each yield better results than zero-shot; (2) that the combined prompting strategy delivers better results than zero-shot, few-shot, and CoT; and (3) that the optimized prompts outperform all other prompting strategies. The sign test is applied to the evaluation results regarding alignment, deviation, and the number of mappings."}, {"title": "5 Results and Discussion", "content": "In the following two subsections, the research questions RQ1 and RQ2, presented in the introduction, are addressed based on the empirical results and discussed in the context of relevant literature."}, {"title": "5.1 RQ1: Evaluation of different prompting strategies", "content": "The evaluation of different prompting strategies replicated the methodology of the preliminary study by Nechakhin et al. [8] and extended it to additional prompting strategies. Before delving into a detailed comparison of these strategies, it should be noted that the findings of Nechakhin et al.'s preliminary study [8] - for no clear reason could only be partially replicated. For the extracted GPT dimensions and the evaluations of deviation and the number of mappings, comparable results to the CSV file from Nechakhin et al.3 were achieved. However, the alignment evaluation scores could not be replicated, even after multiple attempts using the exact same zero-shot prompts described in the preliminary study.\nThe alignment scores listed in the CSV file from the preliminary study are on average approximately one scale point higher than the replicated results. For example, the alignment score for ID 3 (paper title: Km4City ontology building vs data harvesting and cleaning for smart-city services, research problem: Smart city ontology) is listed as 4, indicating \u201csubstantial semantic alignment\u201d. However, an examination of the gold-standard ORKG properties and GPT dimensions shows no apparent basis for this score:\n\u2022\nORKG properties: ['research problem', 'Linked Ontology', 'Ontology domains']\n\u2022\nGPT dimensions: ['Urban planning', 'Internet of Things', 'Data analytics', 'Sustainable development', 'Wireless communication', 'Energy management', 'Citizen participation', 'Traffic management', 'Environmental monitoring', 'Infrastructure management']\nAlthough occasional errors by LLMs are well-documented, the discrepancies observed in this instance are not isolated cases. At the same time, the LLM generally demonstrated a tendency to assign scores correctly in the evaluations of other strategies.\nThe cause of the significant alignment score deviations in Nechakhin et al.'s preliminary study remains unclear. A plausible explanation, though unlikely based on the current experiment, is the use of a different version of the GPT-3.5-turbo model. The preliminary study does not specify which version was used, so this study tested both \u201cgpt-3.5-turbo-0125\u201d (January 2024) and \u201cgpt-3.5-turbo-1106\" (November 2023). While there were minor differences between the versions, these variations do not account for the large discrepancies in alignment scores.\nHowever, comparing the two versions revealed the interesting result that the older model, \u201cgpt-3.5-turbo-1106\", made no errors in property extraction, even across multiple runs, while the newer model more frequently produced errors in the output format and failed to adhere to the required Python list format, complicating the parsing of the outputs. Conversely, in the evaluation tasks, the older model produced more output errors. These findings align with prior studies, which report task-specific performance variations across different GPT-3.5-turbo releases. For example, Frey et al. [45] found that the November 2023 release performed best for\""}, {"title": "5.2 RQ2: Ontology matching to address inconsistencies and further improvements", "content": "With RQ2, the question was raised which measures could help minimize the existing inconsistencies in ORKG properties and improve the overall property extraction process. The response is structured around three aspects: 1) minimizing inconsistencies, 2) providing expanded context as input for LLMs, and 3) redesigning the process with predefined properties. While improvement 1) is implemented in the present study, aspects 2) and 3) are discussed here only conceptually, as these overarching improvements impact the entire process.\nTo minimize inconsistencies, this study proposes property matching as an additional step alongside the property extraction conducted in the preliminary study. Within the property matching process, the extracted properties are aligned with the appropriate URIs of existing ORKG properties. As discussed in Section 4.3, however, the effectiveness of this matching depends significantly on the quality of the existing ORKG property base, which must be free of duplicates and inaccuracies. An effective elimination of inconsistencies further necessitates the proposed consolidation of the current ORKG properties.\nThe property matching process itself yielded promising results in this study. Although the matching implementation was relatively straightforward-comprising direct comparisons of phrases with substitutions for characters like underscores, hyphens, and spaces, as well as conversion to singular forms \u2013 the optimized prompt still achieved an average match rate of 40%. There is considerable potential for a more sophisticated implementation that could further increase this proportion."}, {"title": "Expanded context as input for LLMs", "content": "A key improvement involves expanding the context provided to the LLM as input for its task. Several studies have suggested and evaluated this approach as beneficial [23], [47], [48]. For the present use case, the author suggests that including the abstract and methods section of the studies as context would be particularly effective. Using only the research problem often yields unsatisfactory results because it is sometimes just a single word or phrase. Even human experts would likely struggle to produce a precise list of properties with only terms like supply chain, aiming, orientation, or nanothermometer (examples from this and the preliminary study) as context. Notably, the human experts whose results were used as the gold standard in Nechakhin et al. [8] had access to the full research papers when generating the benchmark properties.\nAn expanded context is also essential if subsequent steps in KG construction are to be automated. For this use case, such a step might involve linking the extracted properties to object entities. The tables used in ORKG comparisons illustrate this process well: properties form the row labels, contributions serve as the column labels (subject entities), and object entities populate the inner cells. For example, for the property Study Area, the corresponding cells might contain entries like \"Europe\", \"North America\u201d, or \u201cHanover\u201d. However, determining such object entities often requires more context than the research problem alone. For certain properties, such as data source or data coverage, even the abstract might be insufficient, making the inclusion of the methods section as additional context advisable."}, {"title": "Redesigned process with predefined properties", "content": "The results of matching LLM-extracted properties to existing ORKG properties demonstrate that while feasible, this process is not trivial. The author questions whether this approach is optimal and proposes a conceptual two-step process instead.\nIn the first step, a predefined set of properties \u2013 such as research field, research problem, method, evaluation data set and evaluation benchmark \u2013, similar to the templates used in the ORKG, would be provided and evaluated for applicability to a specific contribution. Properties deemed irrelevant for that specific contribution by the LLM would be excluded. In the second step, the LLM would be allowed to freely suggest additional relevant properties, as was done in the current study.\nThis approach offers several advantages. First, the predefined properties would promote greater consistency across all contributions, which is particularly useful for comparisons, as it ensures a larger number of common properties for direct comparison. Furthermore, these predefined properties would already be linked to appropriate URIs, eliminating the challenging and time-consuming step of URI matching for these properties. Simplifying the process with predefined properties and their associated URIs would also likely reduce errors compared to the method proposed by Nechakhin et al. [8]."}, {"title": "6 Future Work", "content": "In terms of further research and possible implementation of LLM-based property extraction for the ORKG, there is still potential for several improvements. An essential and fundamental requirement for effective property matching is the consolidation of the ORKG ontology to avoid duplicate representations of concepts through multiple URIs. In light of recent efforts towards overarching standards and recommendations, such as those promoted by the German National Research Data Infrastructure (NFDI) initiative [17], the ORKG ontology could be adapted to align with NFDI guidelines as part of this consolidation effort.\nFor real-world applications of property extraction and mapping, integrating a mechanism to allow LLMs to propose new properties for the ontology could further enhance the system. These newly proposed properties would require approval from human experts to ensure consistency and quality. This approval process, however, is expected to be far less labor-intensive than the current manual extraction of all properties from research publications.\nFurther possibilities for improvement in future work include incorporating more context into the input [23], [47], [48], and generating a larger number of properties, which can subsequently be filtered [30]. Future studies could also explore the use of alternative LLMs. For instance, in a study focused specifically on relation extraction, OpenChat-3.5 (7B) outperformed GPT-3.5-Turbo and other large models like LLaMA-2-70B across most datasets [30].\nWhen designing a comprehensive KG construction pipeline, it is crucial to address inherent LLM issues such as hallucinations and non-determinism. Jiang et al. [30] proposed a framework for factualness checks to mitigate these challenges. In the current use case of open-ended relation extraction without entity extraction, distinguishing between creativity and hallucination remains challenging. However, with the inclusion of entity extraction, the full triples could be more effectively evaluated for factualness.\nA feasible improvement in this study's context is validating and correcting the output format. For example, with version \u201cgpt-3.5-turbo-0125\", there were instances where the prompting strategy combined failed to adhere to the required output format of a python list. In such cases, even script-based parsing of the LLM response could not produce usable results. A potential solution is employing a second LLM to convert the output from the first LLM call into the correct format. Preliminary experiments confirmed that this approach works, such as when the first LLM outputs a numbered list without brackets, which the second LLM can properly format as a python list.\nThis tactic, referred to as output guardrails, is widely applied also outside of scientific programming and is recommended by OpenAI [49]. It involves using a"}, {"title": "7 Conclusions", "content": "This study demonstrates that prompt engineering techniques, when applied correctly, can significantly improve the performance of LLMs in the task of property extraction. Additionally, implementing a matching step to align extracted properties with existing ORKG properties enhances the process by addressing issues of inconsistency and lack of uniformity in properties. This matching step also improves the quality of results by ensuring that the extracted properties align with a predefined ontology, allowing for criteria such as generalizability to be systematically enforced."}]}