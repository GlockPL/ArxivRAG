{"title": "DRESSING UP LLM: EFFICIENT STYLIZED QUESTION- ANSWERING VIA STYLE SUBSPACE EDITING", "authors": ["Xinyu Ma", "Yifeng Xu", "Yang Lin", "Tianlong Wang", "Xu Chu", "Xin Gao", "Junfeng Zhao", "Yasha Wang"], "abstract": "We introduce DRESS, a novel approach for generating stylized large language model (LLM) responses through representation editing. Existing methods like prompting and fine-tuning are either insufficient for complex style adaptation or computationally expensive, particularly in tasks like NPC creation or character role-playing. Our approach leverages the over-parameterized nature of LLMs to disentangle a style-relevant subspace within the model's representation space to conduct representation editing, ensuring a minimal impact on the original semantics. By applying adaptive editing strengths, we dynamically adjust the steering vectors in the style subspace to maintain both stylistic fidelity and semantic integrity. We develop two stylized QA benchmark datasets to validate the effectiveness of DRESS, and the results demonstrate significant improvements compared to baseline methods such as prompting and ITI. In short, DRESS is a lightweight, train-free solution for enhancing LLMs with flexible and effective style control, making it particularly useful for developing stylized conversational agents.", "sections": [{"title": "1 INTRODUCTION", "content": "Large language models (LLMs) like GPT-4 (Achiam et al., 2023) and LLaMA-3 (Dubey et al., 2024) have demonstrated exceptional performance across a range of natural language processing (NLP) tasks including question-answering. This evokes the wide use of LLMs as conversational agents (Weizenbaum, 1966) for various applications, including psychological counseling (Li et al., 2023a), creating gaming NPCs (non-player characters) (Cox & Ooi, 2023) and character simulacra (Shao et al., 2023). While LLMs are adept at providing accurate and coherent answers, they lack the intrinsic ability to tailor responses in a specific language style. Language style (Jin et al., 2022) is linguistically defined as the manner of expressing the semantics, depicted by multiple attributes like personality, emotion, authorship, era background, etc. Stylized responses are crucial for LLM agents as the style can shape the interaction tone, making the agents more immersive and engaging, and ensuring that responses are empathetic and appropriately tailored to the user's emotional states. Hence, crafting the language style is essential for shaping the specific image and personality of conversational agents. Therefore, we aim to solve the following question: How to make LLMs respond to user questions in a specific style?\nCurrently, there are two main approaches to achieving stylized responses - prompting with few-shot demonstrations and fine-tuning. Prompting methods (Park et al., 2023) leverage the in-context"}, {"title": "2 RELATED WORKS", "content": "Recently, there has been a line of research embarking on controlling the behavior of LLMs through representation editing, most of which focuses on truthfulness enhancement (Zou et al., 2023; Li et al., 2023b), knowledge editing (Todd et al., 2023; Hernandez et al., 2023), etc. This technique is based on the linear representation hypothesis (Elhage et al., 2022) supposing that most high-level concepts are represented linearly as directions in LLMs, which is theoretically supported by the approximate orthogonality assumption under overparameterized networks (Wang & Zhu, 2023), and practically demonstrated by the success of linear probing techniques (Alain & Yoshua, 2016; Belinkov, 2022).\nThe primary objective of representation editing is to identify some steering vectors and add them to some layers of the forward pass of LLMs to introduce certain attributes (i.e., language style in this work or truthfulness, etc.) into the LLM outputs. Mean-Centring (Jorgensen et al., 2023) computes the steering directions using the mean difference between paired activations. RepE (Zou et al., 2023, Representation Engineering) applies PCA to the set of difference vectors and selects the principal component as the steering vector. CCS (Burns et al., 2023, Contrast Consistence Search) obtains the steering vector through the probing vector that well classifies the activation pairs. ITI (Li et al., 2023b, Inference-Time Intervention) further enhances CCS by locating attribute-relevant attention heads. However, due to the intricacy of language attributes, it is insufficient to depict them with a single direction as in the aforementioned works. TrFr (Chen et al., 2024b, Truth Forest) proposes a specific combination of several vectors under orthogonality regularization to enhance the expressiveness of the target attribute. Nevertheless, none of the methods above attempt to explicitly disentangle the attribute subspace from the entire representation space to avoid affecting the original semantics. Moreover, previous works overlook the varying importance of different attribute components across various contexts, which can adversely affect the quality of the outputs. In this work, we propose DRESS to solve the problems. DRESS comprises three progressive mechanisms to isolate the attribute-relevant subspace and conduct adaptive editing in order to enhance the expressiveness and flexibility of steering, meanwhile ensuring the semantics are preserved."}, {"title": "3 PRELIMINARIES", "content": "Problem Formulation In this paper, we aim at making LLMs respond to user queries in a specific style. Rigorously, given each user query q, an LLM $M(\u00b7)$ to respond the query with $M(q)$ as the original response, and a target language style S depicted by QA examples ${q_i, a_i}_{i=1}^n$ where $a_i$ are all stylized responses (i.e., $a_i \\sim S$), our objective is to edit the representation space of LLM and obtain a new response $M'(q)$ of user query q, where the response $M'(q)$ is of the same style with S (i.e., $M'(q) \\sim S$).\nRepresentation Editing Here we rigorously introduce where representation editing takes place in the transformer-based LLMs. To set notation and contexts, we first briefly introduce the transformer (Vaswani, 2017) architecture adopted by mainstream LLMs. A transformer-based LLM comprises several stacked transformer blocks, each composed of a multi-head self-attention (MHA) block and a successive MLP layer. Specifically, a transformer block could be expressed as follows:\n$x^{(l+1)} = MLP(MHA(x^{(l)})) = MLP(\\bigoplus_{h=1}^H W^O(Attn_h(x^{(l)}))).$ \nIt has been demonstrated that the MHA block and the feed-forward network (FFN) perform different functions in LLM, where MHA blocks tend to encode language attributes (Clark, 2019) while FFNs tend to conduct reasoning (Geva et al., 2020). Hence, it is more reasonable to edit representations in MHA blocks to minimize the influence on semantics. Specifically, the edited steering vector is attached after the Attn operator and before $W^O$ following Li et al. (2023b); Chen et al. (2024b):\n$x^{(l+1)} = MLP(MHA'(x^{(l)})) = MLP(\\bigoplus_{h=1}^H W^O(Attn_h(x^{(l)}) + v^{(h,l)})).$"}, {"title": "4 METHODS", "content": "In this section, we introduce how DRESS solves the steering vectors and conducts representation editing for stylized outputs without compromising the semantics. Specifically, the pipeline is shown in Fig.2, and we introduce the details as follows.\n4.1 DATASET CONSTRUCTION\nTo conduct effective representation editing, it is necessary to investigate the differences between the activations of QA samples with different styles but the same semantics for deriving a style- relevant steering vector. The target style is inherently implied by QA examples ${q_i, a_i}_{i=1}^n$, which are collected from literature, scripts, or chat records. Therefore, to compute the steering vector, we also need to obtain the ordinary style of these responses (i.e., the style LLM generates), thereby constructing the dataset $D = {q_i, a_i, a_i^-}_{i=1}^n$ to solve the steering vector, where $a_i^-$ is the response to $q_i$ in the ordinary style and $a_i^+$ is the collected target style response. To obtain the ordinary style expression of $a_i^+$ (i.e., $a_i^-$) without altering its semantics, we apply GPT-4 to rewrite $a_i^+$ to align with the typical LLM language style (i.e., modern daily language style). The specific prompt used for this task can be found in Appendix C.1.\nAdditionally, since the dataset often originates from scripts and literary works, the language style of the queries tends to be biased. To mitigate the influence, we introduce another general-purpose LLM QA dataset (e.g., Alpaca (Taori et al., 2023), MOSS (Sun et al., 2024)) $D' = {q_i', a_i^{-'}, a_i^{+'}}_{i=1}^{n'}$, to diversify the style distribution of the queries. Specifically, the general-purpose QA dataset already contains the ordinary style QA data pair (i.e., $q_i, a_i^-$), so we need to construct corresponding target style responses $a_i^{+'}$ to perform data augmentation. Here, we again prompt GPT-4 to generate the target style responses, with a brief introduction of the target style and randomly sampled target style responses $a_i^+$ from the collected dataset D as few-shot examples. The detailed prompt can be found in Appendix C.2. Finally, the dataset are constructed as $D := D \\cup D'$ sized $N = n + n'$.\n4.2 ATTENTION HEAD FILTERING\nRecent works (Ge et al., 2024) have demonstrated that different attention heads perform different functions in LLMs. Therefore, identifying the attention heads most closely related to styles is crucial for conducting semantic-isolated representation editing. Probing, as highlighted in works like (Alain & Yoshua, 2016; Conneau et al., 2018; Belinkov, 2022), has emerged as a robust and effective technique for analyzing the internal functions and behavior patterns within LLM representations. Our key idea is to train a linear probing classifier on the activations of LLMs to discriminate between the ordinary and target language styles. Since each pair of responses in our dataset (i.e., $a_i^-, a_i^+$)"}, {"title": "STYLE SUBSPACE FILTERING", "content": "Given the selected attention heads, we aim to further filter out the style-irrelevant components and disentangle the subspaces that are more closely related to style for editing. Since the activations in the high-dimensional space of LLMs can be assumed to be approximately orthogonal with high probability (Wang & Zhu, 2023; Ortiz-Jimenez et al., 2023), we can hypothesize that the language styles reside in a subspace orthogonal with semantics. Given that our positive and negative sample pairs (i.e., $(q_i, a_i^-), (q_i, a_i^+)$) differ only in style while maintaining consistent semantics, their activation differences (i.e., $\\delta u_i^{(h,l)} = u_i^{(h,l)+} - u_i^{(h,l)-}$) primarily capture the variation in style, with minimal inclusion of semantic or other noisy components. Thus, DRESS proposes to isolate the style-relevant subspace by denoising the space spanned by these activation differences.\nSpecifically, we first collect the activation differences of all sample pairs, denoted as $\\Delta U^{(h,l)} = [\\delta u_1^{(h,l)}, \\delta u_2^{(h,l)}, ..., \\delta u_N^{(h,l)}]^T \\in \\mathbb{R}^{N \\times d}$. Then we apply Singular Value Decomposition (SVD) on $\\Delta U^{(h,l)}$, and select the top-K singular vectors with the largest singular values to form the orthogonal basis of the style subspace, thereby capturing the most representative style-related features while filtering out irrelevant noises. Rigorously,\n$\\Delta U^{(h,l)} = S^{(h,l)}\\Sigma^{(h,l)}V^{(h,l)T} = \\sum_{i=1}^d \\sigma_i s_i^{(h,l)} v_i^{(h,l)T} = \\sum_{i=1}^K \\sigma_i s_i^{(h,l)} v_i^{(h,l)T},$ \nwhere $v_i^{(h,l)} \\in \\mathbb{R}^{d}$ is the singular vector and $\\sigma_i \\in \\mathbb{R}$ is the corresponding singular value satisfying $\\forall i > j, \\sigma_i > \\sigma_j$. Finally, the editing is conducted in the style subspace spanned by $v_i^{(h,l)}$ as follows:\n$x^{(l+1)} = MLP(\\bigoplus_{h=1}^H W^O(Attn_h(x^{(l)}) + \\sum_{i=1}^K \\alpha_i^{(h,l)} v_i^{(h,l)})),$ \nwhere $\\alpha_i^{(h,l)}$ is the editing strength of the corresponding basis $v_i^{(h,l)}$ in the style subspace, and especially, for attention heads that have been filtered out in the previous step, $\\alpha_i^{(h,l)} = 0$.\n4.4 ADAPTIVE EDITING\nSince different style components (e.g., tone, formality) may have varying importance or influence depending on the specific context, a uniform adjustment would fail to capture these subtleties. Thus, in this subsection, we introduce our adaptive editing strategy, designed with the adaptive strength coefficient $\\alpha_i^{(h,l)}$ in Eq.(5). This coefficient comprises two key components: a global editing strength and an adaptive scaling factor. The global editing strength reflects the population-level steering intensity across the dataset, capturing the overall style shift observed in the majority of the samples. Specifically, the global editing strength, denoted as $\\beta_i^{(h,l)}$, is measured by the projection of the mean difference between positive and negative activations (i.e., $\\delta u^{(h,l)} = \\frac{1}{N}\\sum_{i=1}^N \\delta u_i^{(h,l)}$) onto the"}, {"title": "5 EXPERIMENTS", "content": "5.1 EVALUATION BENCHMARK\nDatasets We constructed the evaluation benchmark with representative language styles in Chinese and English, i.e., Shakespeare-style and Dream of the Red Chamber-style. These styles exhibit significant differences from contemporary language in tone, idiomatic expressions, historical context, etc., making them easy to observe and evaluate. The Shakespeare-style benchmark aims to mimic the language style in Shakespeare's works, with the dataset derived from the original texts of his plays following (Xu et al., 2012). The QA pairs are constructed from excerpts of single-round conversations between different characters in the plays. Dream of the Red Chamber is a lengthy fictional novel published in the 18th century and is one of China's Four Great Classical Novels. The Dream of the Red Chamber-style benchmark aims to replicate the dialogue style of its characters, with the dataset sourced from the original novel and adapted scripts from film and television. Similarly, the QA pairs are constructed from individual character dialogues in these works.\nAdditionally, as mentioned in Section 4.1, for each dataset, we incorporated the general question- answer dataset (i.e., MOSS (Sun et al., 2024) in the corresponding language) to address the bias in question style distribution. We then randomly divided each of them into training and testing sets at a ratio of 10:1. The training set is used to solve the stylized QA model, while the testing set only utilizes the questions as the test queries to evaluate the model performances. The detailed statistics and the examples of the datasets are introduced in Appendix E.\nEvaluation Metrics A successful stylized response not only needs to demonstrate the target style, but also ensures that the original semantics are preserved and the language remains fluent given the inherent uncontrollability of LLMs. Hence, following Jin et al. (2022), we evaluate the quality of the stylized responses in three aspects, including style intensity, semantic preservation, and fluency:\n\u2022 Style Intensity (SI): we leverage a separately trained style classifier to distinguish whether the response could demonstrate the target style (Shen et al., 2017). Specifically, the classifier is fine- tuned on BERT (Devlin et al., 2018) models using the responses of the target style as positive samples and those of the ordinary style as negative samples. The style intensity is calculated as:\n$\\frac{\\text{#. Responses classified as the target style}}{\\text{#. All responses}}$, ranging from [0, 1]."}, {"title": "5.3 ANALYSES", "content": "Effects of Editing Strength In this subsection, we analyze the impact of different editing strengths (i.e., $\\lambda$) on the performance of various methods, as illustrated in Fig.3. We compare DRESS with the most representative conventional method, ITI. The results show that DRESS consistently outperforms ITI across all $\\lambda$ values on the overall metric. Both methods display a pattern where overall performance initially improves and then declines as $\\lambda$ increases. This behavior is due to the inherent trade-off between style strength and the other two metrics (i.e., semantic preservation and fluency). However, as editing strength increases, DRESS maintains consistently higher fluency and preserves semantics more effectively compared to ITI. This is because ITI does not further disentangle the style subspace of selected attention heads, which results in some semantic damage during the editing process. Furthermore, even at lower editing strengths, DRESS exhibits a stronger style intensity than ITI. This can be attributed to our adaptive editing strategy, dynamically adjusting the strength according to current contexts and providing some remedy when the strength is insufficient. These results demonstrate that DRESS not only achieves better performance across all metrics but also exhibits greater robustness across various levels of editing strength.\nEffects of the Number of Selected Heads We further analyze the impact of varying number of selected heads (i.e., $H$) as illustrated in Fig.4. It can be observed that DRESS maintains stable performance as the number of attention heads (i.e., $H$) increases and consistently outperforms ITI. In contrast, ITI shows a significant decline in semantic preservation and fluency with larger $H$. This is because, more style-irrelevant contents are incorporated as H increases, leading to semantic distortion and degraded language quality during editing. In comparison, DRESS applies additional subspace filtering to denoise the representation space of the selected heads, preserving semantic integrity and enhancing overall performance.\nAre Style Subspaces Really Relevant to Styles? To better understand whether the learned style subspaces are indeed style-"}, {"title": "6 CLOSING REMARKS", "content": "In this work, we introduced DRESS, a novel train-free framework for efficient stylized QA via style subspace editing in LLMs. Our approach disentangles the style-relevant subspaces within the representation space of LLMs, enabling adaptive and controllable stylization via representation editing while preserving semantic integrity. We construct two distinct benchmark datasets, Shakespeare-style (English) and Dream of the Red Chamber-style (Chinese), for comprehensively evaluating the quality of stylized responses. Through adequate experiments on the two datasets, we demonstrate that DRESS significantly outperforms existing methods, including prompting, SFT, and conventional representation editing techniques. Our results confirm the effectiveness of DRESS in enhancing LLMs with flexible style control, making it particularly valuable for developing conversational agents.\nDespite its strengths, DRESS has some limitations that warrant future exploration. Although DRESS establishes a solid foundation for language style adaptation, building scenario-specific conversational agents (e.g., a chatbot embodying a historical figure, an assistant for medical prediction and counseling (Ma et al., 2023)) still requires careful modeling of character personalities and the implementation of dialogue memory capabilities. This is an important step towards developing more systematic and humanoid agents, and retrieval-augmented generation (RAG) techniques have been widely researched to achieve this goal (Zhang et al., 2024; Xu et al., 2024). We regard them as our significant future work. Moreover, due to the limitation of our computation resources, the scalability to larger LLMs (e.g., 100B+) has not been validated yet. We also look forward to exploring the effectiveness of DRESS on those models from a self-play perspective, and we hope to validate this in our future work."}]}