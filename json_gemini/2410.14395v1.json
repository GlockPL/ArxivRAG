{"title": "Generative AI, Pragmatics, and Authenticity in Second Language Learning", "authors": ["Robert Godwin-Jones"], "abstract": "There are obvious benefits to integrating generative AI (artificial intelligence) into language learning and teaching. Those include using AI as a language tutor, creating learning materials, or assessing learner output. However, due to how AI systems understand human language, based on a mathematical model using statistical probability, they lack the lived experience to be able to use language with the same social awareness as humans. Additionally, there are built-in linguistic and cultural biases based on their training data which is mostly in English and predominantly from Western sources. Those facts limit AI suitability for some language learning interactions. Studies have clearly shown that systems such as ChatGPT often do not produce language that is pragmatically appropriate. The lack of linguistic and cultural authenticity has important implications for how AI is integrated into second language acquisition as well as in instruction targeting development of intercultural communication competence.", "sections": [{"title": "Introduction", "content": "Generative AI (artificial intelligence), as represented by ChatGPT and other systems, offers significant affordances for language learning and teaching. Second language learners are using AI chatbots to practice speaking or to improve their writing. AI can take on the role of language tutor, providing feedback and learning materials. Teachers can use AI to create level-appropriate stories/exercises, help assess student work, or even plan out a curricular unit. A flurry of blog posts, conference papers, and peer-reviewed articles have explored the affordances of AI for language learning and teaching (Godwin-Jones et al., 2024; Kohnke et al., 2023; Poole & Polio, 2023). We are still in the early, exploratory stage of seeing how AI can enhance the language learning process, but it is evident already that AI is being widely used by both learners and teachers and is likely to bring about significant changes in language learning, teaching, and assessment (Godwin-Jones, 2024).\nAI users of all kinds have marveled at the proficiency and speed with which such systems produce texts that seem indistinguishable from human writing: coherent, well-structured, and grammatically flawless. Al's language abilities come from machine learning applied to a vast language dataset, building a \u201clarge language model\u201d (LLM) which uses statistical probability to predict the next likely word in a text sequence. That ability is then extrapolated to generate phrases, sentences, paragraphs, complete discourses. This mathematical model of language in AI has no lived experience with humans or human society, limiting its understanding of the social and cultural dimensions of human interactions and of human language use. Furthermore, the dataset used to build an LLM is not representative of the world at large, as it draws from digital sources that are overwhelmingly in English and reflect the values and behaviors of Western, industrialized cultures (Naous et al., 2023). This has serious consequences for the social and cultural dimensions of AI output, calling into question its linguistic and cultural authenticity. In particular, AI is incapable of handling the nuances of pragmatic language use, as that requires an ability to negotiate sociocultural common ground with the interlocutor. That has implications for the viability of AI chatbots as effective vehicles for second language learning, especially at more advanced proficiency levels.\nMost studies of pragmatics in AI use the Grice cooperative principle (Grice, 1989) to examine whether AI output follows the Gricean maxims of quality, quantity, relevance, and manner (Harnad, 2024; Sydorenko et al., 2024); others have looked at performance related to speech acts (Gubelman, 2024; Tao et al., 2024) and implied meanings (Ruis et al. 2024). Those studies point to"}, {"title": "Generative AI's Language Abilities", "content": "Artificial intelligence itself is not new, but generative AI represents a sharp break from earlier efforts. While AI was initially designed to function as an \u201cexpert system\" within a narrow range of functionality, ChatGPT and other generative AI are general use systems that work within a broad range of contexts and can generate language in a wide variety of genres. Additionally, natural language processing was developed in traditional AI by training systems in the rules of how language works (i.e., syntax, morphology, etc.) as well as programming them with knowledge about the social and natural world in which humans live (something akin to humans' common sense). Early AI systems met with only limited success. It turns out to be too complex and vast a task to program computers with enough rules and facts to deal adequately with phenomena as complex as human language and human society (Sutton, 2019).\nA different approach to natural language understanding and processing has yielded incredibly better results, namely that used in generative AI. The LLMs that power generative AI systems are created by feeding the system a huge amount of data (digital texts scraped from online sources), turning the text chunks into mathematical symbols (\u201cvectors\u201d). Then, deep machine learning (multiple neural networks operating simultaneously) enables the system to uncover and store representations of patterns and regularities (\u201cparameters\u201d). That results in a statistical, not a linguistic model of language. This is very different from how humans acquire language, through a gradual process of socialization. The statistical model of language in AI is very effective at generating output that seems in its fluency, flow, and idiomaticity to have come from a human source. While AI output seems \"authentic,\" and is certainly grammatically correct, studies have shown that the texts it produces tend to be bland and uninspired (Kramsch, 2023; Poole & Polio, 2023). They lack the spark of human creativity, representing as they do simply repackaging of their textual training data. AI output is form without substance.\nAl has no real understanding of the texts it generates and no lived experience in our world to go by to judge the appropriateness of its output for the human user with whom it is interacting. Those limitations result in the fact that AI can \u201challucinate,\" producing statements that are false or inappropriate. Hallucination is not actually an accurate term to use, in that it implies AI is fundamentally in a normal state of reality from which it occasionally and temporarily departs. In fact, LLM's are totally untethered from reality, relying on internal processes based on their training data. AI systems may provide false information, but they do not lie or hallucinate, as that would imply that they have an awareness of truth or an intent to deceive. They are designed to give the impression of objectivity and accuracy but there is no active, intentional being behind the output (Hicks et al., 2024). As Giannakidou and Mari (2024) comment, AI is \u201cepistemologically empty\" (p. 3), or, as Shanahan et al. (2023) put it, with AI there is \"no-one home\" (p. 7).\nStudies have shown that, unsurprisingly, AI systems lack cultural sensitivity (Cao et al., 2023). That derives in part from their training data, that represents the largely Western, \u201cfirst world\u201d, male-oriented cultural orientation of the Internet, its principal training source (see Atari et al., 2023). That has been shown in a number of studies that examine AI output from the perspective of particular cultures. Naous et al. (2023) show how Western biases are evident in soliciting Arabic output from an AI. Testing 16 different LLMs, the researchers found consistently cultural faux-pas and inaccuracies, even in Arabic-trained systems. When asked to provide a completion task based"}, {"title": "AI, Authenticity, and Pragmatics", "content": "The concept of authenticity in language learning is complex and has proven to be controversial (2013, Buendgens-Kosten, 2014; Mishan, 2005). Gilmore (2019) provides seven different kinds of authenticity in language learning. How authenticity is understood and valued is linked to the dominant pedagogical approach in effect at the time (Zyzik & Polio, 2017), so that it has become something of a moving target. There is not unanimity among SLA research that authenticity is even desirable (Long, 2014). Furthermore, how authentic texts or tasks are received and used by learners is unpredictable in that \u201cL2 developmental trajectories are likely to be highly idiosyncratic\"\n(Gilmore, 2019, p. 305). No matter what approach is used, not all variables in language learning can be controlled, so that what each participant gets out of an \u201cauthentic\" L2 encounter may be quite different. Gilmore (2019) concludes his examination of different versions of authenticity in asserting that a social constructivist perspective on authenticity is closest to the lived experience of language teachers. That interpretation of the term stresses the social connectivity of a L2 text or task. That view accords with other scholars who have highlighted the interactional aspects of authenticity, emphasizing the need in designing learning activities to reflect the original communicative purpose of the task, to approximate real life interactions, and to involve purposeful communication (Mishan, 2017; Poole & Polio, 2023). If we are to consider authenticity from the perspective of interactions, then that brings into play the social and cultural dimensions of communication, essential for effective conversational exchanges. That places a greater weight on language pragmatics.\nAccording to the widely used cooperative principle in pragmatics (Grice, 1989), conversation in normal social settings is guided by a desire to cooperate and accommodate ones partner. Cooperation in conversation necessitates on-the-fly adaptation based on reading the interlocutor's state of mind, emotional response, and physical reactions. This is clearly problematic for AI. The statistical model of language in AI lacks the sociocultural grounding humans have through sensorimotor interactions and from simply living in the real world. Studies of Al's capabilities to engage in pragmatically effective language use have shown significant limitations (Lee & Cook, 2024; Su & Goslar, 2023; Tao et al., 2024). While AI systems can gain pragmalinguistic knowledge and learn appropriate formulaic sequences (conventions for apologizing, for example) through the verbal exchanges in their training data, they have proven to be much less effective in sociopragmatic engagement, that is, in generating contextually acceptable speech reflecting an interlocutor's state of mind, intentions, and emotional status. Pragmatic appropriateness is not pre-set but is developed in interaction. Pragmatic meanings \u201cdo not inhere in linguistic conventions but result from participants' ongoing, contingent interpretive work during jointly pursued practical activities\u201d (Kasper, 2009, pp. 278-279). Knowledge of normalized formulae is not enough. Contextual factors such as social distance, relative power, ranking of imposition determine pragmatic language, as do concerns such as face, rights, and obligations (Sykes & Gonz\u00e1lez-Lloret, 2020). There is a complex sociocultural process at play.\nA study by Gerhalter (2024) reflects others that have examined the pragmatic competence of AI systems. That paper examined the use of topicalized infinitives in Spanish and Portuguese, with the finding that ChatGPT had no trouble with understanding meanings but could not properly integrate their use in conversational exchanges nor interpret inferred meanings they contained. The author concluded: \u201cChatGPT is good at mimicking common speech patterns, but has no idea what it is talking about\u201d (p. 32). As every L2 learner has experienced, knowing the appropriate forms and formulae is not enough for communicating effectively; those constructions need to be integrated properly into the give and take of a conversation. That process will require interactional and strategic competence that comes from human experiences in carrying out speech acts such as greetings or apologies, negotiating cultural/personal characteristics such as degree of directness or shyness, or learning how to maintain a conversation (topic selection/change, repair, role of silence, closings). Dombi et al. (2024) comment that for developing such conversational skills, synthetic conversations will not suffice; human conversations are needed for \u201callowing learners to practice turntaking and social language using natural discourse patterns\" (p. 43). In addition to sociopragmatic limitations, studies of AI and pragmatics have shown that in some cases, ChatGPT may even struggle with the pragmalinguistic forms themselves, as Lee and Wang (2023) found for the use of politeness conventions in Korean (using honorifics, recognizing hierarchical distinctions). It is likely that performance in pragmatics will vary considerably across languages, due to the skewed linguistic training data which heavily relies on English.\nMore studies of the pragmatic language abilities of ChatGPT have recently emerged. Several use the well-known Gricean maxims for guiding effective communication in social situations,\""}, {"title": "Intercultural pragmatics, cultures-of-use, and AI", "content": "To explore the issues that AI systems have in dealing adequately with pragmatically rich contexts, it can be helpful to look to intercultural pragmatics (Kecskes, 2013, 2015, 2019; McConachy, 2019). Gricean approaches to pragmatics tend to focus mostly on English in monolingual contexts (Kecskes, 2014). Given the reality of multilingualism in most parts of the world today (especially in online environments), pragmatics needs to be able to explain behaviors and language use in multilingual and multicultural settings (Kecskes, 2015). The Gricean cooperative principle assumes that conversants in social situations are rational, well-meaning, and intentional in striving to achieve a mutually beneficial outcome (Tao et al., 2024). That process presumes no ambiguity, dissembling, or misrepresentation on the part of speakers (Setlur & Tory, 2022), which may not universally be the case.\nGricean pragmatics assumes that speakers have the same goals and are able to use common ground to facilitate effective communication. That common ground is built on accepted cultural norms and behaviors drawn from prior life experiences and shared linguistic practices, such as the use of familiar formulaic expressions (Dombi et al., 2022). In intercultural encounters and in L2 conversations with speakers of different L1s (in English as a lingua franca settings, for example), the common ground based on shared culture and language is missing. Instead, an emergent and reciprocally constructed common ground needs to be created by the conversation partners, negotiated on the fly (Dombi et al., 2022; Kecskes, 2015). Studies of English as a lingua franca have shown how non-native English speakers in conversation are characterized by a mutual conscious strategy to cooperate (Baker & Sangiamchit, 2019; Godwin-Jones, 2020). That is different from the non-reflective, automatic linguistic and cultural common ground among common L1 speakers (Dombi et al., 2024). In intercultural contexts, common ground is achieved through a process of adapting language to the evolving conversation and to the reading of the other person's state of mind and feelings. In that setting, speakers need to overcome the \u201ccommunication asymmetry\" (Dombi et al., 2022, p. 8) based on the absence of a shared system of knowledge and experience (Balaman & Sert, 2017).\nFinding common ground in intercultural encounters increasingly occurs in online settings. That fact adds another layer to the negotiation of identity positions and linguistic/cultural commonalities. Technologies have their own \u201ccultures-of-use\u201d (Thorne, 2003), pragmatic norms for acceptable user activity. Digital tools and services are not neutral but themselves can have a co-determining influence on how a communicative event plays out (Darvin, 2023). Thorne (2003) found that there were very different norms and expectations for how exchanges between learners with different L1s took place in email, online forums, or different forms of computer-assisted communication. With technology use, there is in effect a kind of double intercultural layer:\nVirtual communication creates its own cultures and expectations, opening spaces for double intercultural communication, where not only different language and cultural\""}, {"title": "AI and Functional Authenticity", "content": "Poole and Polio (2023) point out that although, as we have seen, AI output lacks both linguistic and cultural authenticity, its use can be functionally authentic through using AI to help produce texts used in settings beyond the classroom. Authenticity related to interactions in extramural settings has increasingly been seen as more critical in instructed SLA then looking at the authenticity of texts or tasks in isolation (Gilmore, 2019; Mishan, 2015). Poole and Polio (2023) present examples that feature real-world integration such as writing a restaurant review for Yelp or generating tweets for marketing a product. Similar \u201crenewable assignments\" that feature real-world integration of student writing are outlined in Blyth (2023) and in the studies discussed in the collection by Ryan and Kautzman (2022). In the process of writing for real audiences, students see that AI literacy is something useful beyond the classroom. Comparing real-world texts with AI generated content can be revelatory in terms of what AI can do well-writing high quality connected discourse-and where it might be deficient understanding and integrating social and cultural nuance. In shared writing with humans, AI functions as a mediating tool, as does, crucially, the teacher in guiding learners towards critical evaluation of Al output.\nOne approach to exploring AI use in functionally authentic tasks is to generate examples of particular genres of writing. That could range from simple, everyday text forms (blog posts, Amazon reviews, YouTube comments) to professional/academic genres (news reports, abstracts, peer reviews) to multimodal examples (social media). Poole and Polio (2023) point out that for some genres authentic model texts may not be easily available, such as for letters of recommendation. In such cases AI could provide helpful models. The authors provide the example of an email in an academic setting. A student has missed a quiz because of illness and needs to explain the situation to the instructor. A variety of classroom tasks could be based on comparing a ChatGPT version of the email with those written by students. That might include examining in AI and in human texts formal elements of the genre, language register used, formulaic sequences, and typical rhetorical moves. Having students examine the specific genre characteristics can raise genre awareness so that students can transfer their genre analysis skills to other tasks, particularly those they might encounter in their professional lives (Poole & Polio, 2023).\nThis kind of rhetorical training is a valuable service that AI can help deliver, provided that it occurs in an instructional context that stresses critical thinking and careful textual analysis. The sample student email generated by ChatGPT provides a good illustration of both the positive and problematic aspects of AI-generated texts. The e-mail contains all the genre-typical formal elements and rhetorical moves and is written in an appropriate register. However, it is overly long and repetitive and obsequious in tone with awkward and inappropriate comments such as \u201cI'm aware of the importance of quizzes as an assessment tool\u201d (Poole & Polio, p. 261). Comparing that text with those generated by students would likely illustrate a greater awareness of the importance of language fitting the social setting and context.\nIn an L2 instructional setting, in which intercultural awareness is represented by a diversity of student backgrounds or in which developing intercultural competence is an instructional goal, there might be analysis of the email from a multicultural, pragmatic perspective. That might entail"}, {"title": "Conclusion", "content": "In writing about Al systems, one should note that they are in a rapid process of change, so that generalizations are problematic. It is also the case that AI systems are likely to improve through user interactions added to their language models, through enlarging their datasets, and through multimodal incorporation (adding video and image training). However, those measures still will not supply the lived experience humans go through in negotiating common ground linguistically and culturally in social interactions and therefore the ability to deal with nuanced pragmatic scenarios. Al generated language-while valuable as a resource in language learning\u2013will remain artificial and inauthentic in ways that cannot serve as an acceptable substitute for actual learner engagement in the L2 with peers and expert speakers. That assertion necessarily leads to the question, what then is the usefulness of AI for language learning and teaching. That is a question that is made even more difficult in that the rapid evolution of AI may render any suggestions quickly out of date.\nSpoken dialogue systems have been shown to be helpful for novice level learners to practice pronunciation and to try out their developing L2 skills in dialogic interactions (Bibauw et al., 2022; Godwin-Jones, 2022). With AI chatbots, there is additionally the option of receiving feedback on grammar, word choice, or other L2 features. Those advantages may make it worthwhile for more advanced learners to practice their L2 with AI, especially if they lack conversation partners.\nLearners at all levels should be aware, however, of the artificiality of those exchanges and not assume they are gaining the same L2 skills that come from interactions with human partners. With AI, they will not be learning pragmatic behaviors through negotiation of meaning and thus developing interactive and strategic competence. That limitation may change as AI systems are trained with multimodal input and gain capabilities to interpret human tone of voice to gauge users' intent and emotional state. Computer vision, enabled through cameras built into smartphones, VR headsets, or robots, could equip Al with the ability to see and interpret human nonverbal behaviors, an essential element in human meaning-making.\nFor helping develop L2 writing skills, AI likewise offers both benefits and limitations. AI can assist in many facets of L2 writing: brain-storming ideas, suggesting story lines, and providing feedback of a variety of kinds (grammar, vocabulary, style, structure). Due to its extensive training data, Al systems have knowledge of conventional features for all kinds of writing. That allows them to provide guidance on what might be missing or inappropriate for a specific genre. While Al can supply valuable assistance in formal and structural elements of a text, their textual output will always require critical assessing and correction. Depending on the genre and on the intended audience, minimal adjustments may suffice. In other cases-such as in academic writing settings-substantial reworking will likely be needed. As discussed above, Al output is coherent but uninspiring. It lacks the creativity and personal voice that humans are capable of. AI assistance will be ineffective in guiding writers towards tailoring their texts to the needs and expectation of intended readers. To provide learners with experience in considering texts from the perspective of audience receptivity, it can be advisable to provide writing assignments that have a real-world validity.\nGiven the linguistic and cultural inauthenticity of AI, L2 learners will need more than reliance on synthetic partners to develop full proficiency, whether that be for oral or written skills. AI only simulates human communication and so needs to be supplemented with interactions with human beings. That could occur in person or in online environments. In instructed settings, virtual exchange provides an ideal vehicle for peer learning. In conversations with fellow learners, particularly in lingua franca environments, there is a need to negotiate not only language forms but sociocultural values and behaviors as well. Pragmatic abilities gained through such interactions are the key to real-world language competence. In addition to virtual exchange, there are many other opportunities online for L2 use in affinity groups or social media. It is important for learners to realize-and for teachers to emphasize\u2013that while AI can provide significant help in a variety of ways to practice and learn another language, ultimately it takes real human interaction in the L2 to develop the ability to use language in way that is socially and culturally appropriate."}]}