{"title": "Is thermography a viable solution for detecting pressure injuries in dark skin patients?", "authors": ["Miriam Asare-Baiden", "Kathleen Jordan", "Andrew Chung", "Sharon Eve Sonenblum", "Joyce C. Ho"], "abstract": "Pressure injury (PI) detection is challenging, especially in dark skin tones, due to the un- reliability of visual inspection. Thermography has been suggested as a viable alternative as temperature differences in the skin can indi- cate impending tissue damage. Although deep learning models have demonstrated consider- able promise toward reliably detecting PI, the existing work fails to evaluate the performance on darker skin tones and varying data collec- tion protocols. In this paper, we introduce a new thermal and optical imaging dataset of 35 participants focused on darker skin tones where temperature differences are induced through cooling and cupping protocols. We vary the im- age collection process to include different cam- eras, lighting, patient pose, and camera dis- tance. We compare the performance of a small convolutional neural network (CNN) trained on either the thermal or the optical images on all skin tones. Our preliminary results suggest that thermography-based CNN is robust to data col- lection protocols for all skin tones.\nKeywords: Pressure injury, Thermal imaging, Erythema detection, Supervised learning, Fine- tuning", "sections": [{"title": "1. Introduction", "content": "A pressure injury (PI) refers to \"localized damage to the skin and underlying soft tissue, usually occur- ring over a bony prominence or related to medical devices\" (European Pressure Ulcer Advisory Panel et al., 2019). It continues to be a major issue with at least 1 in 10 adults admitted to the hospital de- veloping a PI (Li et al., 2020). Furthermore, PI is linked to a decline in quality of life (Khor et al., 2014), increased mortality rates (Bergquist-Beringer et al., 2013), extended hospital stays, and a higher likeli- hood of requiring institutional care after discharge. Identifying warning signs of PI, such as erythema (Shi et al., 2020; Guihan et al., 2012), can lead to effec- tive preventive actions and early interventions (Jiang et al., 2020; Baron et al., 2022).\nContemporary techniques for assessing PI risk in- clude using the Braden Scale (Bergstrom et al., 1987; Borghardt et al., 2015) and visual inspection. Visual inspection includes assessing the skin for tempera- ture variations, changes in tissue consistency, and the presence of tenderness. Yet visual inspection for dark skin tone patients is especially challenging and has led to racial disparities in PI outcomes (Black et al., 2023). Given that PI may result in temperature ab- normalities from partial or complete capillary occlu- sion at the site, thermography (i.e., thermal imag- ing) has been explored as an alternative technolog- ical approach for PI detection (Baron et al., 2023). Several existing works have suggested deep learning models such as convolutional neural networks (CNNs) can achieve high predictive performance for detecting PI (Wang et al., 2021; Pandey et al., 2022; Fergus et al., 2023). However, these studies suffer from 3 major limitations. (1) Limited work has been done to validate the use of thermal imaging across differ- ent skin tones (Aloweni et al., 2019; Sprigle et al., 2003). There still remains an open question of how much melanin impacts the effectiveness of thermog- raphy by absorbing more infrared radiation. For in- stance, infrared thermometers under-reported fevers in African Americans admitted to the hospital (Bha- vani et al., 2022). However, thermography sensitivity to melanin has remained understudied in the context of erythema and PI detection. (2) There has been no"}, {"title": "2. Method", "content": "2.1. Data Collection\nOur study collected optical and thermal images from 35 healthy adults in a controlled simulation environ- ment. The study procedure was reviewed and ap- proved by the Emory University Institutional Review Board, eRIB number 00005999. 30 participants had darker skin tones (Monk Skin Tone Scale level 6 or greater) and 5 had lighter skin tones (Monk Skin Tone Scale level 5 or lower). Using a digital colorimeter, we categorized the skin tone of subjects using Eumelanin (Inter), Eumelanin Intermediate Mid (InterMid), and Eumelanin Intermediate High (InterHigh) categories as shown in Figure 1. The lower back of each par- ticipant was marked to conduct both a cooling and cupping protocol separately. The cooling protocol in- volved a cooled stone cylinder placed on the right lower back. The cupping protocol was performed us- ing a suction device to induce erythema (i.e., abnor- mal redness of the skin).\nFor the cooling protocol, images were taken with 2 thermal imaging cameras, the FLIR E8-XT (320x240 resolution) and the FLIR Pro One (160x120 reso- lution). The imaging collection protocol was var- ied to capture (i) two lighting settings (ambient and ring light), (ii) two distances (35 and 50 cm), and (iii) three different postures (forward placement of top knee, knees stacked, backward placement of top knee). For each image acquisition setting (lighting, distance, posture) and camera, we captured a control and cool image pair (i.e., one before the cooling pro- tocol and one after applying the stone cylinder). This yielded a total of 1680 images for the cooling dataset.\nFor the cupping protocol, we used only the FLIR E8-XT at a single acquisition setting (50 cm and knees stacked). Although the erythema task offers valuable insight, as visual indicators of erythema are often missed in individuals with darker skin, envi- ronmental factors such as lighting changes or camera distance adjustments can affect erythema visibility. We also observed erythema faded quickly in some subjects. Moreover, some individuals may not visi- bly develop erythema at all. These challenges led to the restriction of testing thermography's effectiveness across varying conditions to only the cooling proto- col. We collected a control image and 8 images within the first 7 minutes after the cupping device was re- moved (9 images per patient). Thus, we captured 314 images in the erythema dataset."}, {"title": "2.2. CNN", "content": "CNNs have achieved remarkable performance in var- ious medical imaging applications including derma- tological assessments (Esteva et al., 2017). Wang et al. (2021) proposed a CNN approach for classi- fying infrared thermal images, using 246 images from 82 patients with stringent imaging protocols. Pandey et al. (2022) used the MobileNetV2 Object Detection Model (Giron et al., 2020) to identify the PI location using thermal images from 10 subjects and 18 images"}, {"title": "Task Classification", "content": "We evaluate the efficacy of 3 image types for de- tecting temperature: an optical image, a black and white (B&W) thermal image and thermal color im- age. Thermal color images are the original tem- peratures captured directly by the thermal camera whereas the B&W thermal images are grayscale ver- sion (0-255) derived from the color image. We as- sess the 3 image types on 2 tasks, cooling and ery-"}, {"title": "Results", "content": "Overall Predictive Performance\nTable 1 summarizes the performance of MobileNet V2 on the 3 image types for the 2 tasks. For both tasks, thermal imaging (B&W and color) outper- forms their optical counterparts. For the cooling task (an easier and more obvious temperature difference task), both thermal image types achieve perfect per- formance with an AUC and F1 of 1, as opposed to 0.818 and 0.711 respectively for optical images. For the erythema task, the optical image achieved bet- ter performance than the cooling task with an F1 and AUC of 0.858 and 0.909, respectively. This may be because erythema is accompanied by more visual color change than temperature change. The thermal- based CNN model achieves better performance with F1 and AUC scores of at least 0.914 and 0.935 respec- tively. These results suggest thermography is more reliable than optical imaging for detecting tempera- ture changes in darker skin tones. Additional results for both tasks are available in Appendix C."}, {"title": "Impact of Image Protocol", "content": "Table 1 suggests that thermography-based models are not sensitive to the image collection protocol, as the performance is stellar even with different lighting, camera distances, and patient poses. For the opti- cal images, Figure 2 summarizes the errors associated with each of the 12 image collection protocols across the two cameras. The plot suggests that having the knees stacked together and taking the camera from a further distance (50 cm) generally yielded better per- formance. The ring light setting also was less ideal for when the top knee was forward or backward as it may create more shadows."}, {"title": "Impact of Skin Tone for Erythema Detection", "content": "To better understand which skin tone categories are most susceptible to misclassification for the 3 image types, we further investigated the performance for each of the four skin tone categories. Table 2 sum- marizes the results of the test set for InterLow, Inter, InterMid, and InterHigh. As can be seen from the Table, many of the images were from the InterMid skin tone category. The results suggest that optical images perform slightly better for the Inter category (1 incorrect versus 2 for thermal imaging). However, thermal imaging is better for the InterMid category as there are 4 fewer mistakes in thermal imaging sug- gesting that for darker skin tones it is harder to detect redness in the skin."}, {"title": "2.3. Conclusion and Future work", "content": "Our findings demonstrate the potential of thermog- raphy and CNNs to detect temperature changes in individuals with darker skin tones more reliably than optical images. Although the MobileNetV2 perfor- mance is slightly lower for detecting erythema in slightly darker skin (InterMid skin tone category), the results are still better than their optical counterparts. This suggests that thermography may be a viable so- lution for detecting PI even on dark skin tones a significant challenge under current clinical practices. Our preliminary results also suggest that thermog-"}, {"title": "Appendix A. Dataset Details", "content": "Cupping was used to induce erythema. A total of 9 images, consisting of 1 control image and 8 other images taken from 0 to 7 minutes after cupping were captured per patient. At each timeframe, the ery- thema index was taken with a colorimeter. An ery- thema index of 6 color units above baseline is assigned a positive label, otherwise, negative. As a result, 57 (18%) of the 314 images were labeled as positive.\nVariations in lightning, distance, cameras, and pos- ture was not conducted on the erythema dataset because the variation across individual responses to cupping is still not well understood. Moreover, a re- cent study (Bates-Jensen et al., 2024) found weak correlations between the erythema index and tem- perature changes when erythema was induced ery- thema on the forearm. Nonetheless, we plan to in- vestigate the impact of different lighting conditions on erythema detection in darker skin tones in the fu- ture."}, {"title": "Appendix B. Additional Methods", "content": "Data is split randomly into training and test sets with 80% for training and 20% for testing as shown in Ta- ble 4. For fair comparison, we ensure the same images appear in the train and test splits across all image modalities. For instance, if image 1 is in the training data of the optical dataset, the corresponding image 1 from both the thermal colored dataset and the ther- mal B&W dataset will be included in their respective training data sets. After data splitting, we perform 5-fold cross-validation using the train data, with 4 folds for training and 1 fold for validation as shown in Figure 4. Both train and test images were normal- ized with mean of [0.485, 0.456, 0.406] and standard deviation of [0.229, 0.224, 0.225]. The best model based on the highest validation accuracy over the 5- fold cross-validation was selected and finally used to classify the images in the test set."}, {"title": "Model Hyperparameters", "content": "We used the MobileNet V2, which is pre-trained on ImageNet (Russakovsky et al., 2015) for fine-tuning to speed up the model convergence and improve the overall classification accuracy. Hyperparameters used for training are (a) batch size of 32 (b) 50 epochs (c) learning rate of 1 \u00d7 e-\u00b3 and (d) early stopping (pa- tience of 10). Adam optimizer (Kingma et al., 2020) and binary-cross entropy loss function were used. The Adam optimizer is a stochastic gradient descent approach that uses adaptive estimates of first-order and second-order moments. The best model based on the highest validation accuracy was saved and used for classification on the test set.\nOur system was implemented using Python, lever- aging the PyTorch framework (Paszke et al., 2019) for deep learning operations. Additional libraries used are Numpy (Harris et al., 2020) for numerical com- putations, Matplotlib (Hunter, 2007) for data visual- ization, and OpenCV (Bradski, 2000) for image pro- cessing tasks. The development was carried out using Jupyter notebook within Visual Studio Code."}, {"title": "Appendix C. Additional Results", "content": "Classification Analysis\nFigures 5 and 6 show the confusion matrix for the cooling dataset and the erythema dataset respec- tively, which offers insights into the classification performance of our fine-tuned MobileNetV2 model across the different imaging modalities. These visual representations allow us to assess the accuracy and potential misclassifications. With the cooling dataset (Figure 5), both thermal color and thermal black and white imaging demonstrate perfect classification (174 true negatives and 169 true positives).\nThe erythema dataset is also examined, compar- ing the model's predictions against true labels for the presence or absence of skin redness. Among these, the thermal color imaging shows the highest overall ac-"}, {"title": "C.1. Additional Image Protocol Analysis", "content": "We also assessed the protocols used in the data col- lection process to identify which will potentially be useful for detecting PI. We analyzed the misclassi- fied optical images in the cooling dataset, consider- ing the number of misclassified images per protocol used. In Figure 2, each protocol is represented as Combo. A higher number of images is an indication that a given protocol will perform poorly in detect- ing pressure injury, while a lower number of images indicates a potentially high performance of this pro- tocol in detecting pressure injury. These 12 protocols represent distinct combinations, each varying by knee position (Forward, Stacked, or Back), lighting condi- tion (Room Light or Ring Light), and distance (35 cm or 50 cm). Analysis reveals that Combo 3 (Knee Forward, Ring Light, 35 cm) resulted in the highest number of misclassifications (12-13), while Combo 8 (Knees Stacked, Ring Light, 50 cm) had the lowest (about 5). As shown in Figure 2, misclassification rates varied considerably, ranging from 5 to 13 across different combinations. Generally, the 35 cm distance led to more misclassifications compared to 50 cm un- der similar conditions. The effects of lighting and knee position on misclassification rates were mixed, showing no consistent pattern. These findings sug- gest that imaging conditions significantly impact clas- sification accuracy, with certain setups posing greater challenges for the algorithm. It also shows that im- ages taken with knees stacked under ring lighting con-"}]}