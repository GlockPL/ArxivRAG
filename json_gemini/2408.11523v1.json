{"title": "LARR: Large Language Model Aided Real-time Scene Recommendation with Semantic Understanding", "authors": ["Zhizhong Wan", "Bin Yin", "Junjie Xie", "Fei Jiang", "Xiang Li", "Wei Lin"], "abstract": "Click-Through Rate (CTR) prediction is crucial for Recommendation System(RS), aiming to provide personalized recommendation services for users in many aspects such as food delivery, e-commerce and so on. However, traditional RS relies on collaborative signals, which lacks semantic understanding to real-time scenes. We also noticed that a major challenge in utilizing Large Language Models (LLMs) for practical recommendation purposes is their efficiency in dealing with long text input. To break through the problems above, we propose Large Language Model Aided Real-time Scene Recommendation(LARR), adopt LLMs for semantic understanding, utilizing real-time scene information in RS without requiring LLM to process the entire real-time scene text directly, thereby enhancing the efficiency of LLM-based CTR modeling. Specifically, recommendation domain-specific knowledge is injected into LLM and then RS employs an aggregation encoder to build real-time scene information from separate LLM's outputs. Firstly, a LLM is continual pretrained on corpus built from recommendation data with the aid of special tokens. Subsequently, the LLM is fine-tuned via contrastive learning on three kinds of sample construction strategies. Through this step, LLM is transformed into a text embedding model. Finally, LLM's separate outputs for different scene features are aggregated by an encoder, aligning to collaborative signals in RS, enhancing the performance of recommendation model.", "sections": [{"title": "1 INTRODUCTION", "content": "As an important task in field of recommendation systems (RS), Click-Through Rate (CTR) prediction aims to forecast whether a user will click on a certain product, content, or advertisement. In the domain of RS, models need to analyze data such as user characteristics and item features to predict the probability of a user clicking on a specific objective, thereby helping to optimize the effectiveness of recommendation strategies.\nIn the context of food delivery service, the volume of data that needs to be processed each day reaches hundreds of millions. Unlike typical e-commerce recommendations or content recommendations, food delivery recommendations place a stronger emphasis on analyzing real-time scenes such as geographical location, mealtime, weather, etc. Among them, there exist strong correlations and rich semantics. Consider a specific scene: a user traveling to another city arrives late at night while many restaurants are already closed, and it is raining heavily with low temperatures. Due to the user's unfamiliarity with the surrounding environment and the poor weather conditions, there is a high probability that he will order a takeout from a nearby restaurant. What's more, he's more likely to order some hot food or local specialties.\nPoints of Interest (POI) is a concept we define based on food delivery recommendations, aimed at abstracting the focus of user interest. It can be understood as a collection of POIs, environment, and geographic locations. Traditional recommendation models use feature crossing to handle POIs in real-time scene data. For correlated and important features, common feature crossing methods include manual explicit crossing followed by logistic regression [5], explicit low-order crossing [5], or directly using deep learning for automatic high-order crossing [12, 15, 29]. However, regardless of which method is used, the essence of feature crossing is based on the co-occurrence probability of strongly correlated features to determine whether a user will click, lacking an understanding of the POI in the scene's semantic information."}, {"title": "2 RELATED WORK", "content": "Large Language Models (LLMs) possess extensive semantic knowledge and excellent reasoning capabilities [13, 14], which can effectively understand the semantic information in real-time scenes. However, in the field of RS, LLMs still face some difficulties. In particular, LLMs in their original form may not possess in-depth knowledge specific to the recommendation domain, which could affect their comprehensive understanding of POI and user information. At the same time, LLMs typically do not directly handle the cross-feature signals present in traditional recommendation models, which may limit their ability to accurately capture and understand user needs.\nThe unique recommendation scene of food delivery presents us with two core challenges:\nTypical RS treats each food delivery POI as mapped unique id token as inputs of the recommendation model to predict user behavior. However, this approach treats all POI equally without considering semantic information of POIs, such as the menu similarity of food delivery, relevance of restaurant's main business direction to the scene and so on. For instance, pizza shops with different names would be treated as two unrelated POIs in a normal RS, neglecting the fact that both of them primarily sell pizza. During summer, people tend to order something cold rather than taste spicy and hot food.\nIndustrial RS needs to serve for millions of users, unacceptable time consuming of LLM's inference stays a unsolved problem in the exploring of combination with RS and LLM. Real-time scenes are composed of many individual scene features, with combinations of different scene features giving rise to an exponential number of different real-time scenes. To understand real-time scenes, LLMs need to process combinations of scene feature texts during serving, which seems that LLMs have to be involved in inference, leading to service latency. How to efficiently utilize LLMs to handle real-time scenes is an urgent problem to be solved.\nTo address the two problems mentioned above, inspired by recent work in the LLM field [19, 24] and recommendation system domain [7, 11], we propose a three-stage model LARR (Large Language Model Aided Real-time Scene Recommendation with Semantic Understanding). Figure 1 uses an intuitive example to show how LARR works. The LLM, infused with recommendation domain knowledge,\n2.1 Large Language Model\nSubstantial work [8, 16, 37] has shown that Pre-trained models (PTMs) on a large corpus can learn universal language representations, which are beneficial for downstream NLP tasks and can avoid training a new model from scratch [26]. Large language models (LLMs) mainly refer to transformer-based [31] neural language models that contain tens to hundreds of billions of parameters [38]. Those language models are pre-trained on massive text data, such as PaLM [6], LLAMA [30], and GPT-4 [1]. Compared to PLMs, LLMs are not only significantly larger in model size but also demonstrate superior language understanding and generation capabilities, more importantly, they exhibit emergent abilities [32] that are absent in smaller-scale language models.\n2.2 LLM in Recommend System\nTraditional recommendation models are designed to leverage a huge amount of ID tokens to train, which is an ID paradigm, with the majority of parameters concentrated in the embedding layer [21, 29]. In contrast, LLMs would use a tokenizer to segment the text into vocab tokens to reduce the size of the vocabulary at the very first of input, which is a tokenization paradigm, with the bulk of parameters being concentrated in the network itself. Recommendation models excel in memorization, while LLMs demonstrate superior capabilities in logical reasoning and generalization. A 6-billion parameter LLM such as ChatGLM-3 [9] has a vocabulary less than 65,000 tokens, a scale that is significantly smaller than the number of ID tokens in a recommendation model of the same scale [23]. It's apparent that simple integration of recommendation systems with LLMs is infeasible. If ID tokens are directly used as input, tokenization may establish connections between unrelated IDs (e.g., 'id_499' tokenized into 'id', '_', '4', '9', '9', creating overlapping embeddings with IDs containing the digits 4 and 9, which does not meet our expectations). Alternatively, regard the ID tokens as special tokens of LLM's vocabulary, that is, without tokenization on ID input, would face gap problem between ID tokens representing user/item collaborative information and pre-trained vocab tokens holding content semantics information [4]. Moreover, the typically vast number of ID tokens could dilute the LLM's own vocabulary, inject noise into the vocab tokens, and result in poor learning of the ID tokens.\nDespite the challenges mentioned above associated with applying language models to the field of recommendation, researchers continue to dedicate efforts to applying language models to Recommender Systems (RS), due to the astonishing capabilities demonstrated by LLMs [20, 33]. The researchers of P5 [11] proposed a unified text-to-text paradigm recommendation model based on T5 [27], hoping to handle rating prediction task, sequential recommendation task and more downstream tasks by zero-shot or few-shots. An embedding method called whole-word embedding whose design inspiration is very similar to position embedding is introduced to address ID-related gap problem mentioned above. M6-rec [7] converts all recommend downstream tasks into language understanding or generation tasks by representing user behavior data and candidates data if necessary as natural language plain texts for fine-tuning based on M6 [22]. CLLM4Rec [39] propose a novel soft/hard prompting strategy, mutually-regularized pre-training two LLMs and two set of id tokens on two corpora to facilitate language modeling on RS-specific corpora with heterogeneous user/item collaborative tokens and content tokens.\nAs an unsupervised method, Contrastive Learning (CL) assumes some observed pairs of text that are more semantically similar than randomly sampled text. By maximazing their mutual information, neural network could learn useful embeddings for downstream tasks [2, 36]. OpenAI has attempted to convert pre-trained"}, {"title": "3 METHODOLOGY", "content": "In this section, we will then introduce the framework of LARR, which comprises three stages, with the overall structure illustrated in Fig 2. The first stage is the continual pretraining stage, where we construct natural language texts corpus from the Meituan Waimai dataset. Then we continue pretraining the LLM that has been pretrained on general corpora based on corpus to inject the domainspecific knowledge. In the second stage, we additionally add billions of user profile and user history behavior data into the corpus, which is proven to be useful [10], constructing 3 kinds of contrastive learning positive and negative samples, transforming the LLM into a text embedding model, enabling the LLM to fully understand the semantics of real-time scenes. The final third stage is the multi-modal alignment stage, where contrastive learning is used to maximize the mutual information between semantic embeddings and collaborative embeddings, aligning the takeout scene semantic information understood by the LLM with the collaborative signals extracted by the fine-tuning model from ID tokens, cross features, and statistical features. The aligned semantic information will enhance performance of recommendation system.\n3.1 Continual Pretraining Task Design\nTo facilitate LLM's understanding in food delivery domain-specific knowledge from the natural language perspective, we first construct a corpus using datasets relevant to all POIs. Following this, we perform continual pretraining task on the LLM which had already been pre-trained on generic corpora, using this corpus to enhance its understanding of domain-specific knowledge.\nHow to use id tokens in LLM efficiently remains an unsolved problem for a long-time. In industrial scene, encoding the ids of millions of different POIs as whole words is impractical due to the high time and memory costs involved. Moreover, simply treating POI id tokens as indivisible inputs to the LLM brings a semantic and collaborative signal gap, as mentioned in section 2.2; segmenting and encoding ids could also introduce unintended connections between id tokens. Consequently, we abandoned the use of id token as LLM inputs and instead used unique natural language description texts to represent id features. We noted that a POI can be uniquely identified by its its name and geographical location, which is equivalent to an id feature. The advantage of using name and geographical location to represent a POI is apparently: natural language input makes it easier for LLM to understand. It retains the uniqueness of id inputs while avoiding the semantic meaninglessness of id inputs. Specifically, assuming that there are $N_p$ POIs, we merge name, geographical location, introduction, and statistical information to form a description $D_i$ for each POI $POI_i$.\n$D = {D_i | i \u2208 N, 0 \u2264 i \u2264 N_p}$  (1)\nThe description $D_i$ is cut into $n_k$ different slices and we named each slice a keyword, such as name, location, tag name... The $i^{th}$ restaurant's description $D_i$ could be formulated as a text set $t_i$:\n$t_i = {t_{ik} | k \u2208 N, 0 \u2264 k \u2264 n_k}$  (2)\n$D_i = [t_{i_0}, t_{i_1}, ...t_{i_{n_k}}]$ (3)\nwhere $[...]$ is concatenation between different text and $t_{ik}$ is a discrete text feature, $t_i$ is the aggregation of a bunch of discrete text features.\nThrough the descriptive text, the LLM could capture the similarity among different POIs. Since the language model was pre-trained on general corpora, thus there are some gap between the pretraining and continual pretraining corpora. To address this problem, we introduce some special tokens to assist the LLM in better understanding the content during the continual pretraining stage. To be specific, we use a set of special token $s_p$ for $n_k$ keywords in description to wrap key information.\n$s_{pp} = {(s_{p_{bos}}, s_{p_{eos}}) | k \u2208 N, 0 \u2264 k \u2264 n_k}$ (4)\nFor example, <POI_name> and </POI_name> would be added at the very first and the very last of the $0^{th}$ keyword POI name respectively, the former special token is $s_{p_{bos}}$ indicating that the following information pertains to the restaurant's name while the trailing one is is $s_{p_{eos}}$, signaling the end of the name input. With the help of special token set $s_p$, We split the original description of each POI into $D_i = [x_i, y_i]$ for LLM. The text input $x_i$ and expected text output $y_i$ could be formulated as follows:\n$x_i = [s_{p_{bos}}^0, t_i^0, s_{p_{eos}}^0, s_{p_{bos}}^1, t_i^1, s_{p_{eos}}^1,... s_{p_{bos}}^{n_k}, t_i^{n_k}, s_{p_{eos}}^{n_k}]$  (5)\n$y_i = [s_{p_{bos}}^0, t_i^0, s_{p_{eos}}^0, s_{p_{bos}}^1, t_i^1, s_{p_{eos}}^1,... s_{p_{bos}}^{n_k}, t_i^{n_k}, s_{p_{eos}}^{n_k}]$  (6)\nwhere $[...]$ means concatenation between different text.\nWe denote the LLM parameters as $\\theta$ and employ a generative loss $L_{cp}$ for continual pretraining.\n$L_{cp} = \\frac{1}{|N_p|} \\sum_{x_i, y_i \\in N_p} \\sum_{s=1}^{N_p} log(P_\\theta (y_{is}| x_i, y_{i&lt;s}))$  (7)\nThe input of LLM consists of restaurant's name and location $x_i$, aiming to predict other detail information $y_i$ such as POI's introduction, main dishes offered... During the training process, the model learned the associations between similar dishes and built connections among geographical locations, POI names, menu and so on.\n3.2 Text Embedding via Contrastive Learning\nThere is a huge gap between the normal decoder-only architecture of LLM and text embedding models, because language models train and infer in a way of autoregressive approach. To efficiently leverage the semantic information from the LLM, a critical problem we faced is how to transform the LM into a text embedding model. Common methods for converting a language model into one that could encode a sentence into a embedding include using the output embedding corresponding to some special tokens as the sentence embedding, or directly use some pooling methods on embeddings of all words in sentence to obtain the sentence embedding. Inspired by OpenAI [24], we decide to adopt contrastive learning to convert the LLM into a text embedding model. In NLP field, contrastive learning methods usually construct positive sample pairs by applying corruptions such as dropout on text to generate positive sample pairs, random sampling for negative sample pairs. However, in RS, the importance of user, POI pairs in the food delivery context is very high, so we do not simply use corruption. Instead, we constructed positive and negative sample pairs from three perspectives: user-user, POI-POI, and user-POI.\nAs is shown in figure 3, the LLM tends to in classify three kinds of input is positive or not in contrastive learning procedure. First of all, because of user-side text is added, we utilize a set special tokens $s_u$ for user-side text similar to $s_p$ in section 3.1.\n$s_u = {(s_{b_{uos}}^k, s_{e_{uos}}^k) | k \\in N, n_k + 1 \u2264 k \u2264 n_k + n_q}$ (8)"}, {"title": "3.3 Information Alignment in RS", "content": "The $n_g$ represents the number of keywords in user-related text. We denote the union of two sets as $s_p$.\n$s_p = s_{pp} U s_u$ (9)\nHere, set $s_p$ has $n_k + n_g$ elements.\nWe define a LLM-based score functiona $s_e$ for evaluating the similarity of inputs. The score functiona $s_e$ would calculate the similarity of two input text base on $P_e$. Similar to continual pretraining stage, the description z of POI or user is divided into several segments, interspersed with special tokens in SP. Assuming that there's a series of text input $z = [s_{bos}^0, z^0, s_{eos}^0, s_{bos}^1, z^1, s_{eos}^1...s_{bos}^l, z^l, s_{eos}^l]$, it would be first tokenized into a series of tokens and mapping to a series of token embedding $Z = [Z_0, Z_1...Z_m]$, then sending to LLM after padding.\n$h_z = MLP(LLM(z)_m)$ (10)\nwhere MLP is a linear layer to project the embedding of last token in last hidden layer to a continuous vector space for scoring.\n$S_e (Z_1, Z_2) = s(h_{z_1}, h_{z_2})$ (11)\nHere, s could be a similarity function such as cosine similarity; or negative form of the output of a distance function such as cosine distance. It could be symmetric or asymmetric. If s is symmetric, then $s_e$ is symmetric; otherwise $s_e$ asymmetric.\nUSER-USER In user-user contrastive learning, we focus on user's profile text descriptions $U_p$ (such as nicknames, gender, etc.) and the user's action text descriptions $U_a$ (such as historical actions, environments, click and order price statistics...).\nThese two types of text descriptions are positive samples for the same user and negative samples for different users. During training, we adopt a contrastive learning approach, with the loss being the Info NCE Loss. For user-user contrastive loss $L^{UU}$, considering the general situation, we assume that $s_e$ is asymmetric. As a result, the form of contrastive loss is symmetrical and the sub loss $L_{pa}^{UU}$ could be fomulated as follows:\n$L_{pa}^{UU} = \\frac{1}{N_u} \\sum_{i=1}^{N_u} [-\\frac{exp(s_e(U_p, U_a^+)/\\tau)}{exp(s_e(U_p, U_a^+)/\\tau) + \\sum exp(s_e(U_p, U_a^-)/\\tau)}$\n$-\\frac{exp(s_o(U_a, U_p^+)/\\tau)}{exp(s_e(U_a, U_p^+)/\\tau) + \\sum exp(s_e(U_a, U_p^-)/\\tau)}]$ (12)\n$L_{ap}^{UU} = \\frac{1}{N_u} \\sum_{i=1}^{N_u} [-\\frac{exp(s_e(U_p^+, U_a)/\\tau)}{exp(s_e(U_p^+, U_a)/\\tau) + \\sum exp(s_e(U_p^-, U_a)/\\tau)}$\n$-\\frac{exp(s_e(U_a^+, U_p)/\\tau)}{exp(s_e(U_a^+, U_p)/\\tau) + \\sum exp(s_e(U_a^-, U_p)/\\tau)}]$ (13)\nhere $s_e$ is a score function for evaluating the similarity of inputs.symbol + means corresponding positive sample and - is negative samples that using in-batch negative sampling strategy.\nThe final loss of user-user contrastive loss is average of $U_p$ to $U_a$ and $U_a$ to $U_p$.\n$L^{UU} = \\frac{L_{pa}^{UU} + L_{ap}^{UU}}{2}$ (14)\nPOI-POI POI-POI contrastive learning considers the POI's food delivery business text description $P_d$ (such as name, location, menu) and the POI's basic information text description $P_b$ (such as shop normal introduction and some tags). Descriptions of the same POI are positive sample pairs, while those of different POIs form negative sample pairs. Similarly, the sub loss $L^{PP}$ POI-POI contrastive loss is as follows:\n$L^{PP} = \\frac{1}{N_p} \\sum_{i=1}^{N_p} [-\\frac{exp(s_e(P_d, P_b^+)/\\tau)}{exp(s_e(P_d, P_b^+)/\\tau) + \\sum exp(s_e(P_d, P_b^-)/\\tau)}$\n$-\\frac{exp(s_e(P_b, P_d^+)/\\tau)}{exp(s_e(P_b, P_d^+)/\\tau) + \\sum exp(s_e(P_b, P_d^-)/\\tau)}]$  (15)\nThe POI-POI contrastive loss $L^{PP}$ is just like what $L^{UU}$ organizes:\n$L^{PP} = \\frac{L_{db}^{PP} + L_{bd}^{PP}}{2}$ (16)\nUSER-POI The user-POI pairs are based on user's comprehensive text description U (including user profile and user history texts):\n$U = [U_p, U_a]$ (17)\nThe POI's comprehensive text description P (including food delivery business text and basic information text):\n$P = [P_d, P_b]$ (18)\nIf a user paid for delivery in a POI, the comprehensive text descriptions of that user and POI constitute a positive sample pair;\nIn this section, contrastive learning is applied to alignment, maximizing the mutual information between the semantic information of the food delivery scene understood by LLM and the collaborative signals extracted from ID tokens, cross features, and statistical features by the RS model. The alignment not only extracts the shared information between semantic and collaborative signals but also reduces the noise from both, significantly enhancing the performance of the recommendation.\nSpecifically, our RS utilizes real-time scene embedding produced by the LLM after continual pretraining in stage 1 and fine-tuning in stage 2. Throughout this process, all parameters of the LLM are frozen, meaning the LLM acts like an encoder, converting a scene description into continuous vector representations to aid the training of the recommendation model. Since we want the model to be industry-friendly, the LLM should avoid participating in real-time inference as much as possible. We select r real-time scene text features and decide to deal with scene text $s_i$ one by one, storing them in advance for the recommendation model to utilize, where $0 \u2264 i \u2264 r$.\n$h_i = LLM(S_i)_{s_{eos}}$ (22)\nHere $s_{eos}$ represents the position of corresponding key real-time scene feature's end special token. We use the embedding of end special token in last hidden layer to represent real-time scene text. In reality, we selected 10 real-time scene text, that is, r is set to 10.\nWe employ a bidirectional transformer encoder $\\S$ to tackle the problems that discrete real-time embeddings lack interaction. Since the LLM's outputs have already implicitly encoded the semantic associations between different scene features, so interactions provided by $\\S$ is necessary.\nThese semantic embeddings produced by LLM are stacked into a sequence and fed into $\\S$ for further aggregation and processing. To more effectively aggregate scene information, we introduced a trick at the beginning of the input sequence, a trainable aggregation token $&lt;agg&gt;$, corresponding to a vector $\\alpha_{agg}$ that has the same dimension with real-time scene embedding. This special token plays a crucial role in aggregating all scene keyword and is trained within the transformer encoder to capture and integrate key information from different scene embedding. After processing of transformer encoder $\\S$, pooling method and a projection head (a normal MLP) is applied to the output embedding sequence, the result is denoted as $e_s$, the real-time scene embedding with scene semantic information.\n$e_s = MLP(pooling(([\\alpha_{agg}, h_0, h_1...h_r])))$ (23)\nHere MLP projects the semantic embedding into the vector space of recommendation model and aligns the dimensions of pooling result and alignment objective. r represents the number of real-time scene texts, as mentioned above.\nThen we align $e_s$ with target embedding $e_t$ produced by recommendation model. $e_t$ is the concatenation of user embedding and POI embedding in recommendation system. The procedure of alignment could be formulated as:\n$L_{cl}^{st} = \\frac{1}{N} \\sum [-\\frac{exp(s(e_s, e_t^+)/\\tau)}{exp(s(e_s, e_t^+)/\\tau) + \\sum exp(s(e_s, e_t^-)/\\tau)}$\n$-\\frac{exp(s(e_t, e_s^+)/\\tau)}{exp(s(e_t, e_s^+)/\\tau) + \\sum exp(s(e_t, e_s^-)/\\tau)}]$ (24)\nHere s is the similarity scoring function. Considering the different symmetry properties of s, N is batch size. total loss is the sum of two symmetric sub losses.\n$L_{cl} = \\frac{L_{cl}^{st} + L_{cl}^{ts}}{2}$ (25)\nThis design not only improves the quality of both representations but also enables the model to more accurately grasp the connection between user needs and real-time scenes, leading to a significant improvement in recommendation results. With this approach, our recommendation system can provide more personalized and precise recommendations in real-time scenes.\nDuring training, the loss is a weighted sum of the recommendation CTR loss $L_{ctr}$ and the contrastive learning loss $L_{cl}$. $L_{ctr}$ is BCE which is widely-used.\n$L = \\beta_1 * L_{ctr} + \\beta_2 * L_{cl}$ (26)"}, {"title": "4 EXPERIMENT", "content": "To tackle the lack of understanding of semantic information in RS and the efficiency challenges in LLM-based CTR models, this paper proposes a novel LARR method. LARR continues to pretrain and fine-tune the LLM on some corpora with an enlarged vocabulary, using contrastive learning to align semantic signals and collaborative signals, leverage shared information, and reduce noise. Extensive online and offline experimental results demonstrate that LARR achieves low latency and enhances CTR performance, offering fresh insights for the practical deployment of LLM-based CTR models.\nIn this section, contrastive learning is applied to alignment, maximizing the mutual information between the semantic information of the food delivery scene understood by LLM and the collaborative signals extracted from ID tokens, cross features, and statistical features by the RS model. The alignment not only extracts the shared information between semantic and collaborative signals but also reduces the noise from both, significantly enhancing the performance of the recommendation."}, {"title": "5 CONCLUSION", "content": "To tackle the lack of understanding of semantic information in RS and the efficiency challenges in LLM-based CTR models, this paper proposes a novel LARR method. LARR continues to pretrain and fine-tune the LLM on some corpora with an enlarged vocabulary, using contrastive learning to align semantic signals and collaborative signals, leverage shared information, and reduce noise. Extensive online and offline experimental results demonstrate that LARR achieves low latency and enhances CTR performance, offering fresh insights for the practical deployment of LLM-based CTR models."}]}