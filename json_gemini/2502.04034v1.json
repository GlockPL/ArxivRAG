{"title": "Generalize Drug Response Prediction by Latent Independent Projection for Asymmetric Constrained Domain Generalization", "authors": ["Ran Song", "Yinpu Bai", "Hui Liu"], "abstract": "The accurate prediction of drug responses remains a formidable challenge, particularly at the single-cell level and in clinical treatment contexts. Some studies employ transfer learning techniques to predict drug responses in individual cells and patients, but they require access to target-domain data during training, which is often unavailable or only obtainable in future. In this study, we propose a novel domain generalization framework, termed panCancerDR, to address this challenge. We conceptualize each cancer type as a distinct source domain, with its cell lines serving as domain-specific samples. Our primary objective is to extract domain-invariant features from the expression profiles of cell lines across diverse cancer types, thereby generalize the predictive capacity to out-of-distribution samples. To enhance robustness, we introduce a latent independence projection (LIP) module that encourages the encoder to extract informative yet non-redundant features. Also, we propose an asymmetric adaptive clustering constraint, which clusters drug-sensitive samples into a compact group while drives resistant samples dispersed across separate clusters in the latent space. Our empirical experiments demonstrate that panCancerDR effectively learns task-relevant features from diverse source domains, and achieves accurate predictions of drug response for unseen cancer type during training. Furthermore, when evaluated on single-cell and patient-level prediction tasks, our model-trained solely on in vitro cell line data without access to target-domain information-consistently outperforms and matched current state-of-the-art methods. These findings highlights the potential of our method for real-world clinical applications. The source code and datasets are available at: https://anonymous.4open.science/r/panCancerDR-FC03.", "sections": [{"title": "1 Introduction", "content": "To explore the drug responses of in vitro cancer cells, several projects have utilized high-throughput profiling to assess cell viability when subjected to varying drug concentration treatments and yielded half-maximal inhibitory concentration. For instance, the Genomics of Drug Sensitivity in Cancer project (GDSC) [Yang et al., 2012] has assayed the sensitivity of more than one thousand of cancer cell lines to more than two hundreds of compounds. The Cancer Cell Line Encyclopedia (CCLE) [Barretina et al., 2012] is another effort that compiles genomic, transcriptomic, and drug sensitivity data for over 1,000 cancer cell lines. These public resources promote the development of machine learning methods for predicting drug response based on gene expression profiles [He et al., 2022; Chawla et al., 2022; Ma et al., 2021]. However, while some drugs exhibit promising sensitivity against tumor cells cultured under laboratory conditions, such observations offer limited guidance for clinical drug selection due to substantial discrepancy between in vitro cellular context and in vivo physiological environment. This disparity results in predictive methods that perform well on cell lines being less effective in predicting drug response in patients.\nRecent advances in single-cell RNA sequencing (scRNA-seq) promote the generation of large-scale scRNA-seq data [Franz\u00e9n et al., 2019; Han et al., 2023], offering an opportunity to identify the drug responses at single-cell level. However, scRNA-seq data showed notably different distribution relative to bulk RNA-seq data, posing substantial challenges on drug response prediction for out-of-distribution individual cells. A few studies have employed deep transfer learning techniques to translate drug response insights derived from source domains (e.g., cell lines) to target domains (e.g., single cells or patients). For example, scDEAl [Chen et al., 2022a] and SCAD [Zheng et al., 2023] utilizes domain adaptation to extract domain-invariant features between source and target domains, thereby transferring drug response knowledge from cell lines to single cells. The CODE-AE model [He et al., 2022] applies the domain separation network to extract shared features between cell line and patient expression profiles to predict clinical drug responses. However, existing methods predominantly rely on domain adaptation, which requires model training on a predefined target domain, making them unsuitable for applications involving unseen target domains during training. In some real-world scenario, target-domain data may be currently unavailable or only accessible in future (e.g., data from newly diagnosed tumor patients).\nTo overcome this limitation, we propose a novel domain generalization framework, termed panCancerDR, to generalize the predictive capacity of drug response on cell lines to out-of-distribution samples, such as individual cells and patients. We conceptualize each cancer type as a distinct source domain, with its cell lines serving as domain-specific samples, and then employed adversarial domain generalization to capture essential task-relevant features across multiple source domains. In particular, we introduce a plug-and-play module, referred to as latent independence projection (LIP), which encourages the encoder to extract informative and decorrelated features from expression profiles. We are further inspired by the observation that an anticancer drug exhibit initial effectiveness in inhibiting cancer cells. However, over time, cancer cells often develop resistance through various biological mechanisms. The phenomenon suggests that drug-sensitive cells share common feature, whereas drug-resistant cells exhibit diverse and heterogeneous traits. So, we propose an asymmetric adaptive clustering constraint that drives the sensitive samples aggregated into a single compact cluster, while resistant samples dispersed across multiple separate clusters in the latent space. To validate panCancerDR's performance, we firstly evaluate it on bulk RNA-seq and drug response data from cell lines, using a leave-one-out validation strategy to assess its generalizability in predicting drug responses for unseen cancer types during training. The results demonstrated that panCancerDR achieved superior predictive performance across ten major cancer types. Moreover, we applied the model, trained exclusively on bulk RNA-seq of cell lines, to single-cell and patient-level prediction tasks. The results confirmed it achieved better or comparable performance compared to current state-of-the-art (SOTA) methods.\nThe primary contributions of this study are as follows:\n\u2022 Development of a novel latent independent projection module: We introduce a plug-and-play module capable of extracting informative and mutually decorrelated features from versatile cancer types so that each feature dimension represents a unique signal associated to prediction task. This module has been empirically validated to significantly mitigate overfitting.\n\u2022 Proposal of asymmetric domain generalization: Inspired by the observation that sensitive cells share common feature, whereas resistant cells exhibit significant variability and heterogeneity, we introduce an asymmetric adaptive clustering constraint to ensure that sensitive samples are aggregated into a single compact cluster, while resistant samples are dispersed across multiple separate clusters.\n\u2022 Extensive performance validation across diverse datasets: We conducted a comprehensive evaluation of panCancerDR on bulk RNA-seq, scRNA-seq, and patient drug response datasets. The results demonstrate that our model, trained exclusively on in vitro cell line bulk RNA-seq data, can effectively generalize to predict drug responses in both single-cell and patient-specific contexts, exemplifying a \"train once, adapt anywhere\" framework."}, {"title": "2 Related Works", "content": null}, {"title": "2.1 Domain Generalization", "content": "Domain generalization (DG) is proposed to construct models that perform well on unseen domains without access to their data during training. Recent advancements in DG have achieved remarkable progress [Wang et al., 2022], with approaches generally categorized into three main groups: data manipulation [Shankar et al., 2018; Yue et al., 2019; Zhou et al., 2021], representation learning [Ghifary et al., 2015; Li et al., 2018; Shao et al., 2019; Sicilia et al., 2023; Zhang et al., 2022], and learning strategy [Chen et al., 2022b; Tian et al., 2022; Carlucci et al., 2019]. While our method falls within the realm of representation learning, it significantly differs from existing domain adversarial learning-based methods. Specifically, we introduce an asymmetric adaptive clustering constraint, enabling the model to better capture the nuances of real-world drug response data. The most closely related work is the SSDG[Jia et al., 2020], a single-sided domain generalization approach for face anti-spoofing. However, our method distinguishes itself through the incorporation of contrastive learning-based asymmetric clustering constraints and the proposal of a latent independent projection module, allowing the encoder to learn non-redundant features and thereby enhance the model's generalization capability."}, {"title": "2.2 Drug Response Prediction", "content": "The prediction of clinical drug responses has drawn considerable attention from machine learning community. Some studies employed patient drug response data to fine-tune models initially trained on cell line datasets. For instance, CODE-AE [He et al., 2022] is based on domain separation network [Bousmalis et al., 2016]to extract shared features between cell lines and patients. It was trained on cell line drug sensitivity data and then used to predict the drug response for tumor patients. Precily [Chawla et al., 2022] integrated signaling pathway and drug feature to predict drug responses in vitro and in vivo. In contrast, drug response prediction at the single-cell level is still in its infancy, due to the scarcity of drug response data in single-cell context. Only a few studies leveraged domain adaptation between bulk RNA-seq (source domain) and scRNA-seq (target domain) data to predict drug sensitivity of individual cells. For example, scDEAL [Chen et al., 2022a] aligned the bulk RNA-seq and scRNA-seq features by minimizing the maximum mean discrepancy (MMD) [Gretton et al., 2012] in the latent space for single-cell drug response prediction. SCAD [Zheng et al., 2023] adopted adversarial domain adaptation to learn drug-gene signatures from the GDSC dataset [Yang et al., 2012] for inferring drug sensitivity in single cells. Distinct from the existing methods, we aim to establish a predictive model with superior generalizability across distinct target domains, spanning both single-cell and patient-level datasets, without access to target-domain data during training."}, {"title": "3 Methods", "content": null}, {"title": "3.1 Problem Definition", "content": "Assume we have M domains D = {D\u2081, D\u2082...D\u2098}, with each domain correspons to a specific cancer type. Each domain D\u2096 comprises the gene expression profiles of N\u2096 cell lines regarding to k-th cancer type, denoted as D\u2096 = {X\u2081,X\u2082,... X\u2099\u2096}. For a given drug, the response labels of the N\u2096 cell lines in domain D\u2096 are represented by Y\u2096 = {Y\u2081, Y\u2082,..., Y\u2099\u2096}. Our primary objective is to build a deep learning-based model that accurately map the gene expression profiles of the cell line to their respective drug response labels. Once trained, the model can generalize effectively to predict drug responses in target domains, such as single-cell or patient samples."}, {"title": "3.2 PanCancerDR Framework", "content": "The panCancerDR architecture consists of five components: an encoder G, a classifier P, a domain discriminator D, a latent independence projection (LIP) module, and an asymmetric adaptive clustering constraint. As shown in Figure 1, the expression profile of a cell line is taken as input to the encoder for feature extraction. The latent independence projection module functions to decorrelate extracted features, which is then used by the classifier to identify its drug response label. Meanwhile, the domain discriminator aims to distinguish the domain of each sample (i.e., to identify the cancer type from the expression profile). The encoder and the domain discriminator are adversarially trained so that the encoder is incentivized to learn features that make it increasingly difficult for the domain discriminator to correctly identify the domains. This adversarial training enables the encoder to capture domain-invariant features pertinent to drug response. The asymmetric adaptive clustering imposes the constraint that would aggregate sensitive samples tightly together while dispersing resistant samples across distinct clusters."}, {"title": "3.3 Latent Independence Projection", "content": "The encoder maps input expression profiles into high-dimensional feature representations in the latent space. However, not all dimensions of the primary feature contribute equally to the prediction task, i.e., certain dimensions carry valuable insights, while others may represent redundant or irrelevant information. To promote the extraction of independent and non-redundant features, we project the extracted features onto an orthogonal basis. Formally, let G(X\u1d62) denote the feature extracted from expression profile X\u1d62, the independence project is implemented as follows:\n\nZ\u1d62 = LG(X\u1d62)\n\n in which L is a well-designed matrix whose row vectors are mutually orthogonal, serving as an orthogonal basis in the latent space. For simplicity, we term the orthogonal projection in the latent space as latent independent projection (LIP). To construct L, we employ the sine and cosine waves of varying periods, from which evenly spaced points are sampled within the interval [-1,1]. By exploiting the orthogonality properties of trigonometric functions, we ensure that pairwise row vectors sampled from different periods are approximately orthogonal (see Appendix for further details).\nIt is noteworthy that LIP has three distinctive characteristics that distinguish it from other approaches. First, LIP differs from the sinusoidal positional encoding employed in the Transformer architecture [Vaswani et al., 2017]. While sinusoidal positional encoding introduces position-dependent constants to generate differential embeddings for identical tokens appeared at different positions, it is not inherently orthogonal. This limitation constrains its capacity for feature disentanglement and prevents the realization of independent projections. Second, LIP circumvents the need to directly impose orthogonality constraints on embeddings, which is employed by prior approaches [Lv et al., 2022; Liu et al., 2024]. The orthogonality constraints introduce additional loss terms, which complicate the total loss function, posing challenges on parameter optimization and increasing"}, {"title": "3.4 Adversarial Domain Generalization", "content": "The objective of domain generalization is to learn domain-invariant features relevant to the prediction task, while eliminating domain-specific information. For this purpose, we introduce a domain discriminator designed to classify the domain of each input sample. The encoder and domain discriminator are trained in an adversarial manner, with the encoder learning to extract features that prevent the discriminator from accurately identifying the domain. This adversarial training process encourages the encoder to capture features that are both predictive of drug response and consistent across all domains. Denote by L\u2090\ud835\udcb9\u1d65 the cross entropy loss for domain discrimination, we have\n\nmin max L\u2090\ud835\udcb9\u1d65 = - \u03a3\u2096=\u2081\u2098 \u03a3\u1d62=\u2081\u1d3a\u2096 [y\u1d62(\u1d30) log D(z\u1d62) + (1 - y\u1d62(\u1d30)) log(1 - D(z\u1d62))]\n\nin which y\u1d62(\u1d30) is the true domain label of the input sample X\u1d62, D(z\u1d62) represents the domain label predicted by the domain discriminator. The domain discriminator D aims to minimize the loss, whereas the encoder strives to maximize it. In our practice, we employ the Gradient Reversal Layer (GRL) to implement the adversarial training between the encoder and the domain discriminator."}, {"title": "3.5 Asymmetric Adaptive Clustering Constraint", "content": "Anticancer drugs are typically designed to target specific molecules or disrupt the biological processes critical for tumor cell proliferation. So, we observed that the tumor cells responsive to a specific drug often exhibit similar characteristics, while non-responsive tumor cells develop drug resistance through diverse biological mechanisms, such as genetic mutations, alterations in cell cycle checkpoints, activation of alternative proliferation signaling pathways, and epigenetic modifications. Without loss of generality, we assume that sensitive cells share common features, while resistant cells exhibit diverse heterogeneity in their features. To reflect this observation, we introduce an asymmetric adaptive clustering constraint. Specifically, we require the encoder G to extract the features so that sensitive samples are aggregated closely together in the latent space, whereas the resistant samples are dispersed into different clusters.\nWe leverage an approach inspired by InfoNCE loss [van den Oord et al., 2018] to achieve our objectives: 1) aggregating the sensitive samples from all source domains; 2) pulling apart the resistant samples away from"}, {"title": "3.6 Drug Response Prediction", "content": "The drug response labels of cell lines subjected to specific drug exposure is used to train the classifier. It takes as input the features after latent independence encoding to predict the response labels. We use cross-entropy as the classification loss, with the loss function Lcls defined as:\n\nmin Lcls = -\u03a3\u2096=\u2081\u2098 \u03a3\u1d62=\u2081\u1d3a\u2096 [y\u1d62 log(P(z\u1d62)) + (1 - y\u1d62) log(1 - P(z\u1d62))]\n\nin which P(z\u1d62) represents the predicted drug response label by the predictor.\nFinally, the total loss is defined as below:\n\nL = L\u2090\ud835\udcb9\u1d65 + \u03bb\u2081 L\u2090\u209b\u1d67 + \u03bb\u2082Lcls\n\nwhere \u03bb\u2081 and \u03bb\u2082 are the balanced parameters.\nIn our practice, the encoder are realized using fully-connected feed-forward networks with rectified linear unit (ReLU) activation function. It consist of only two feed-forward layers with sizes of 1024 and 740, respectively. Each feed-forward layer is followed by a batch normalization layer, and a dropout layer with the dropout probability set to 0.1. The learning rate is set to 8e-5. Our model was implemented in PyTorch 3.10, and all experiments were conducted on a CentOS Linux 8.2.2004 (Core) system, equipped with a GeForce RTX 4090 GPU and 128GB memory. During the model training and cross-validation stage, these loss terms were appropriately weighted."}, {"title": "4 Experiments", "content": null}, {"title": "4.1 Data Resource and Preprocessing", "content": "We regard the bulk RNA-seq data from different cell lines of same cancer type as a source domain, with drug response (sensitive vs resistant) as class labels. The dataset were obtained from the Genomics of Drug Sensitivity in Cancer (GDSC) project [Yang et al., 2012], which contained a wealth of data about the responses of 1074 cancer cell lines to 226 therapeutic agents. These cell lines come from more than 20 cancer types. The drug sensitivity were quantified using the half maximal inhibitory concentration (IC50).\nFrom the GDSC dataset, we first identified all cell lines treated by the drug of interest. Next, the cell lines were then ranked based on their IC50 values and categorized into two"}, {"title": "4.2 Drug Response Prediction on Leave-One-Out Cancer Type", "content": "We first evaluated the performance of panCancerDR in predicting drug response for unseen cancer types during training. For objective evaluation, all cell lines of a specific cancer type were designated as the test set, while cell lines from other cancer types were used for training. This leave-one-out approach enabled us to evaluate the performance of panCancerDR on unseen cancer types for a specific drug. Notably, some cancer types have an insufficient number of samples (cell lines) for reliable performance evaluation. These cancer types were excluded from testing but were still included as source domains in the training set. As a result, the leave-one-out test set included ten cancer types: Lung Adenocarcinoma (LUAD), Small Cell Lung Cancer (SCLC), Breast Cancer (BRCA), Colorectal Adenocarcinoma (COREAD), Head and Neck Squamous Cell Carcinoma (HNSC), Ovarian Cancer (OV), Neuroblastoma (NB), Pancreatic Adenocarcinoma (PAAD), Acute Myeloid Leukemia (LAML), and Mesothelioma (MESO). Our evaluation considered five distinct drugs: Afatinib, AR-42, Docetaxel, Etoposide, and PLX4720. These drugs represent a diverse array of therapeutic classes, including chemotherapy agents, targeted therapies, and broad-spectrum inhibitors.\nThe experimental results demonstrated that our model achieved superior performance in predicting drug responses across ten major cancer types (Figure 2a), with particularly high AUC values exceeding 0.9 in the cancers such as neuroblastoma (NB), mesothelioma (MESO), and acute myeloid leukemia (LAML). Next, we validated the effectiveness of the latent independent projection in improving performance. As illustrated in Figure 2b, inclusion of this module led to remarkably improved model performance. To further validate that the encoder captured the discriminative feature related"}, {"title": "4.3 Generalization to Single-Cell Drug Response", "content": "The inherent heterogeneity of tumors often leads to significant variability in gene expression profiles of individual cancer cells within a tumor. Meanwhile, the noise present in single-cell RNA sequencing (scRNA-seq) data further complicates this issue, leading to data distributions that differ substantially from the bulk RNA-seq data used during model training. To assess the generalizability of our proposed method, we systematically evaluated its performance in predicting drug responses at the single-cell level.\nThe single-cell drug response datasets used for performance evaluation comprised both pre-treatment scRNA-seq data from CCLE [Barretina et al., 2012] and post-treatment scRNA-seq data from GEO repository (accession numbers: GSE149215 and GSE108383). The pre-treatment dataset included the expression profiles and drug response labels of JUH006 cell line to the treatment of three distinct drugs (Gefitinib, Vorinostat and AR-42), as well as the data of SCC47 cell line treated with other four distinct drugs (NVP-TAE684, Afatinib, Sorafenib, Cetuximab). The post-treatment datasets contained the expression profiles and drug response labels of PC9 cell line following Etoposide treatment [Aissa et al., 2021], as well as the A375 and 451Lu cell line treated with PLX4720 [Ho et al., 2018]. For performance evalua-"}, {"title": "4.4 Generalization to Patient Drug Response", "content": "For further evaluation, we applied panCancerDR to predict clinical drug responses in patients. In vivo drug response prediction poses significant challenges due to the influence of many biochemical factors, making it inherently more difficult than in vitro predictions on cell lines. This experimental setting provides a more stringent evaluation of the model's generalizability.\nThe expression profiles and clinical metadata of patients were obtained from the TCGA repository [Hutter and Zenklusen, 2018]. The patients treated with one of four drugs-Fluorouracil, Gemcitabine, Temozolomide, or Cisplatin-were selected for analysis. These drugs were chosen"}, {"title": "5 Conclusion", "content": "In this study, we propose a novel domain generalization framework designed to predict drug responses without access to target-domain data during training. By treating each cancer type as a distinct source domain, the model extracts domain-invariant features and generalizes to out-of-distribution samples. Our primary innovations include a latent independence projection (LIP) module for non-redundant feature extraction and an asymmetric adaptive clustering constraint to improve latent space organization. Our empirical experiments confirmed that our method outperforms current state-of-the-art methods in predicting drug responses at both single-cell and patient levels, demonstrating its potential for clinical applications."}, {"title": "Appendix", "content": null}, {"title": "Constructing latent independence projection matrix", "content": "The sine and cosine waves with varying periods are widely acknowledged as an effective basis set in vector spaces. Following this principle, we generated m sinusoidal waves with distinct periods and sampled each wave across a defined interval, resulting in a discretized matrix representation as below:\n\nL =\n\n[\n\nL\u2081\u2081  ... L\u2081\u2099\n\n\u22ee   ... \u22ee\n\nLm\u2081  ... Lmn\n]\n\nin which each row represents n samples taken from a sinusoidal wave with a specific period.\nAccording to the orthogonality of sine waves, we know that the inner product of two sinusoidal functions with distinct frequencies equals zero over a complete period. Mathematically, for sinusoidal functions sin(ax) and sin(bx), where a \u2260 b, their inner product over an interval [-\u03c0, \u03c0] satisfies:\n\u222b\u208b<binary data, 1 bytes><binary data, 1 bytes><binary data, 1 bytes>+<binary data, 1 bytes><binary data, 1 bytes><binary data, 1 bytes> sin(ax) sin(bx)dx = 0.\n\nTherefore, the orthogonality between discrete row vectors becomes increasingly pronounced as the density of sampling points increases. When the number of sampling points n approaches infinity, the inner product of any two distinct row vectors is equal to the integral of two sine waves with corresponding periods. Formally, we have\n\nlim\u2099\u2192\u221e 1/n \u03a3\u2096=\u2081\u207f L\u1d62\u2096 L\u2c7c\u2096 \u2248 \u222b\u208b<binary data, 1 bytes><binary data, 1 bytes><binary data, 1 bytes>+<binary data, 1 bytes><binary data, 1 bytes><binary data, 1 bytes> sin(ax) sin(bx)dx.\nAccording to the formulation , we have lim\u2099\u2192\u221e \u03a3\u2096=\u2081\u207f L\u1d62\u2096 L\u2c7c\u2096 = 0 (i \u2260 j).\nSimilarly, the cross terms between sine and cosine also vanish:\n\u222b\u208b<binary data, 1 bytes><binary data, 1 bytes><binary data, 1 bytes>+<binary data, 1 bytes><binary data, 1 bytes><binary data, 1 bytes> sin(ax) cos(bx)dx \u2248 0.\nTherefore, the L matrix can be constructed by sampling from sine and cosine waves with varying periods.\nFurthermore, let x = \u03c0t, the integral for sine wave within the interval [-\u03c0,\u03c0] can be changed to \u03c0\u222b\u208b\u2081\u207a\u00b9 sin(a\u03c0t) sin(b\u03c0t)dt through integral transform. This effectively shifts the orthogonal interval from (-\u03c0,\u03c0) to (-1, 1). As a result, for the same number of sampling points, the sampling density is increased. In our practice, the odd rows are sampled from the sine wave, while the even rows are sampled from the cosine wave. Assuming the number of sampling points are n, we have:\nL\u1d62,\u2096 = cos (2\u03c0\u00b7 k/(n-1) \u00b7(i-1)),\nLi+1,k = sin (2\u03c0\u00b7 k/(n-1) \u00b7(i-1)) .\nTo validate the orthogonality, we sampled 740 points from 16 waves with distinct periods and computed the pairwise inner products of these sampled waves, yielding a 16\u00d716 matrix . The resulting matrix closely approximates the identity matrix, characterized by diagonal elements equal to 1 and off-diagonal elements near 0. This result demonstrates that the generated matrix successfully forms an orthogonal basis."}]}