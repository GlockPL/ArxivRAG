{"title": "Uncertainty Quantification with Bayesian Higher Order ReLU KANS", "authors": ["James Giroux", "Cristiano Fanelli"], "abstract": "We introduce the first method of uncertainty quantification in the domain of Kolmogorov-Arnold Networks, specifically focusing on (Higher Order) ReLU-KANs to enhance computational efficiency given the computational demands of Bayesian methods. The method we propose is general in nature, providing access to both epistemic and aleatoric uncertainties. It is also capable of generalization to other various basis functions. We validate our method through a series of closure tests, including simple one-dimensional functions and application to the domain of (Stochastic) Partial Differential Equations. Referring to the latter, we demonstrate the method's ability to correctly identify functional dependencies introduced through the inclusion of a stochastic term. The code supporting this work can be found at https://github.com/wmdataphys/Bayesian-HR-KAN.", "sections": [{"title": "1 Introduction", "content": "The introduction of Kolmogorov-Arnold Networks (KANs) [1] as substitutes for more traditional Multi-Layer Perceptron (MLP) has been seen as a form of revolution in the deep learning community. MLP's, backed by the universal approximation theorem [2], deploy functional learning directly through a set of weight matrices. As such, the 'activation' function applied at each layer must be chosen apriori. In contrast, KAN's, backed by the Kolmogorov-Arnold representation theorem [3], learn both the weights and the functional form of the activation function at training time. Specifically, KAN's rely on the fact that any continuous multivariate function f, operating on a bounded domain can be written as a finite sum of continuous univariate functions, Eq. 1. [1]\n\n\nf(x) = \\sum_{q=1}^{2n+1} \\Phi_q(\\sum_{p=1}^{n} (\\sum_{a=1}^{n_i+1} \\phi_{q,p}(x_p))), \\Phi_{q,p} : [0,1] \\rightarrow \\mathbb{R}, \\Phi_q : \\mathbb{R} \\rightarrow \\mathbb{R}\n\n(1)\nThe above representation is limiting due to limited non-linearities (2) and small number of terms (2n + 1). Liu et al. [1] remove this limitation through the realization of the relation to MLPs, in which a single KAN layer, Eq. 2, with n-dimensional inputs, can be defined as a matrix of one-dimensional functions, capable of being chained together to form a network of any depth.\n\nX =\n\\begin{pmatrix}\n\\phi_{1,1,1}(\\cdot) & \\phi_{1,1,2}(\\cdot) & \\dots & \\phi_{1,1,n_i}(\\cdot) \\\\\n\\phi_{1,2,1}(\\cdot) & \\phi_{1,2,2}(\\cdot) & \\dots & \\phi_{1,2,n_i}(\\cdot) \\\\\n\\vdots & \\vdots &  & \\vdots \\\\\n\\phi_{1,n_i+1,1}(\\cdot) & \\phi_{1,n_i+1,2}(\\cdot) & \\dots & \\phi_{1,n_i+1,n_i}(\\cdot)\n\\end{pmatrix}\nX_{l-1}\n\n(2)\nIn Liu et al. [1], the activation functions \\phi(x), are chosen to be linear combinations of a basis function and a B-Splines."}, {"title": "2 Related Works", "content": "Since the introduction of KAN, many improvements have been made both from computational standpoints, but also choices of expressive basis functions. [4, 5, 6, 7, 8, 9, 10] In [11], the authors introduce ReLU-KAN, in which the choice of basis functions is replaced with those more suitable for GPU parallelization. Specifically, the functions require only matrix addition, dot products and ReLU activations. They replace the B-Spline functions in [1] with combinations of ReLU functions and a normaliation term, Eq. 3, where si and ei are learnable parameters defining the start and end of the domains.\n\n\nR_i(x) = [ReLU(e_i \u2013 x) \u00d7 ReLU(x \u2013 s_i)]^2 \u00d7 16/(e_i - S_i)^4\n\n(3)\n\\phi(x) can be represented through Eq. 4, where G and k are the number of grids and the span parameter, respectively. The Grid parameter G controls the number of functions contributing to individual activations, and the span parameter k parameterizes the non-zero region of individual basis functions.\n\n\n\\varphi(x) = \\sum_{i=1}^{G+k} w_i k_i(x)\n\n(4)\nAs described in Qiu et al. [11], the input/output scheme of a input vector x = {x_1,x_2,...,x_n} and output vector y = {y_1, y_2,\u2026\u2026\u2026, y_m} can be decomposed into singular matrix operation:\n\ny = W \\begin{pmatrix}\nR_1(x_1) & R_2(x_1) & \\dots & R_{G+k}(x_1) \\\\\nR_1(x_2) & R_2(x_2) & \\dots & R_{G+k}(x_2) \\\\\n\\vdots & \\vdots &  & \\vdots \\\\\nR_1(x_n) & R_2(x_n) & \\dots & R_{G+k}(x_n)\n\\end{pmatrix}\n\n(5)\nWhere \u2299 denotes the convolution operation. The result is a more computationally efficient and expressive set of a basis functions. However, as pointed out in So et al. [12], the smoothness of higher order derivatives of the perviously defined basis functions is a highly limiting factor, specifically for Partial Differential Equations (PDEs) that posses higher order derivatives. As a result, they provide a more general framework, in which higher order basis functions (opposed to the square of ReLUs) are represented in Eq. 6.\n\n\nR_{i,m}(x) = [ReLU(e_i \u2013 x) \u00d7 ReLU(x \u2212 s_i)]^m \u00d7 (2/(e_i - S_i))^{2m}\n\n(6)"}, {"title": "3 The Bayesian Approach", "content": "Inspired by Bayesian Neural Networks (BNNs), we aim to define posterior distributions, q(W|D), over the parameter space of KAN, allowing prediction through a posterior distribution q(y|x, D), integrated over the space of the weights. In reality, such a posterior is intractable and one must utilize Bayesian inference techniques during optimization. We define posteriors over the basis functions Ri,m(x), at both second (default ReLU-KAN) and higher order (m > 2) such that we can efficiently account for the uncertainty in our network. Specifically, we define posteriors over the parameters ei, si through variational inference by introducing two new learnable parameters \u03bc(ei), \u03c3(si):\n\ns_i = \\mu(s_i) + \\sigma(s_i) \\Theta_e\n\n\n\\hat{e_i} = \\mu(e_i) + \\sigma(e_i) \\Theta_e\n\nWhere e is represented by a fully factorized Gaussian. In essence, we are defining a posterior over the start and end of the unary bell shaped basis functions. Furthermore, we wish to parameterize the weights of the convolution (W of Eq. 5) making the posterior over the two operations joint. To do so, we utilize the convolutional layers defined in [13]. In contrast to the fully-factorized assumption on q(W) made prior, which can limit inherent network complexity, the authors instead represent the posterior distribution through the product of a fully-factorized Gaussian and a mixing density, Eq. 7."}, {"title": "q(W)", "content": "q(W) = \\int q(W|z)q(z)dz\n(7)\nWhere q(z) is a set of random variables acting only multiplicatively on the means of q(W|z) to reduce computational overhead. The resulting posterior distribution over the weights becomes more flexible, capable of capturing complex multi-modal dependencies. However, this leads to intractability, necessitating the construction of an approximate lower bound for the entropy. This is achieved using an auxiliary distribution, r(z|W), which is equivalent to performing variational inference in an augmented probability space [13]. Importantly, the approximate posterior remains valid due to the fact that the auxiliary distribution can be marginalized out. As [13] state, the tightness of the bound on q(W) \u2014 and thus its quality \u2014 depends on how well r(z|W) approximates the posterior q(z|W). To achieve this, inverse normalizing flows are employed. During training, the approximate posterior is constrained by Eq. 8, serving as a regularization term alongside the standard loss function.\n\n\\mathcal{L}_{KL} = -KL(q(W)||p(W))\n\n\n= \\mathbb{E}_{q(W,Z_T)} [-KL(q(W|z_T)||p(W))\n+ logr(z_t; |W) \u2013 log q(Z_T)]\n\n(8)\nThe above formulation allows estimation of the epistemic uncertainty (i.e., model uncertainty) at inference through sampling of the posterior. However, in the space of physical problems in which inputs are injected from physical processes, aleatoric uncertainty (i.e., stochastic uncertainty inherent to the data) must be accounted for. In [14], the authors propose directly learning the aleatoric uncertainty at training time through a Gaussian Log-likelihood, in which the output of the network y = {y_1, y_2, \u2026\u2026\u2026, y_n } is augmented with the associated uncertainty (y) = {\u03c3(y_1), \u03c3(y_2), ..., \u03c3(y_n)}, learned through Eq. 9, where w denotes parameterization through a model. In our case, the output of the network is one-dimensional, resulting in easy computation and no consideration of covariance.\n\n\n\\mathcal{L}(\\mathbf{u}_x, \\hat{\\mathbf{u}}_\\mathbf{w}, \\sigma_\\mathbf{w}) = \\frac{1}{N} \\sum_j (\\frac{1}{2} (e^{-r_j} ||u_j \u2013 \\hat{u}_j||^2 + r_j), r_j = log \\sigma_j^2)\n\n\n(9)\nIn the case of BNNs, this is often represented through a bicephalous network, in which the output is formulated into two disjoint heads. [15, 16] We instead represent the aleatoric uncertainty through a surrogate model, taking the form of another Bayesian KAN, depicted in Fig. 1.\nThis surrogate KAN inherits its structure from the functional KAN by default, although we encode the ability to define separate structures. The loss is then given by the summed contributions of Eq. 8 and 9. We also provide code for fitting through a Student-t distribution, Eq. 10, in which we introduce another learnable parameter \u03bd. Such a likelihood may be more robust to outliers, although this is generally data-dependent and inherently tied to the complexity of the problem. In simple cases, a Gaussian assumption is often sufficient even under the presence of strong outliers.\n\n\\mathcal{L}(\\mathbf{u}_x, \\hat{\\mathbf{u}}_\\mathbf{w}, \\sigma_\\mathbf{w}, \\nu_\\mathbf{w}) = \\frac{1}{N} \\sum_j -\\frac{1}{2}log (\\frac{\\nu}{\\gamma}) + log \\Gamma(\\frac{\\nu+1}{2}) - log \\Gamma(\\frac{\\nu}{2}) + log \\sqrt{\\nu \\pi \\sigma_j^2}\n+\n\\frac{\\nu+1}{2} log (1+\\frac{||u_j - \\hat{u}_j||^2}{\\nu\\sigma_j^2})\n\n(10)"}, {"title": "4 Experiments", "content": "In the following, we demonstrate the the ability of the Bayesian model on function fitting, along with the ability to extract meaningful representations of both the epistemic, and aleatoric uncertainties."}, {"title": "4.1 One Dimensional Fits", "content": "We follow the experiments in [11], selecting set of one-dimensional functions given below:\n\nf_1(x) = sin(\\pi x)\n\n\nf_2(x) = sin(5x) + x\n\n\nf_3(x) = e^x\n\n(11)\nWe also define the \"noised\" version of these functions, in which we introduce a stochastic term drawing samples from a Student-t distribution with \u03bd = 3. We then perform a series of fits under different likelihoods, namely a Gaussian likelihood, the center column of Fig. 2 and a Student-t likelihood, the rightmost column of Fig. 2. The true underlying function is shown in the leftmost column. The network structure used is summarized in Tab. 4 for all three functions.\nFrom inspection of Fig. 2, it can be seen that under the presence of strong outliers, i.e., long tails, the Student-t likelihood less affected, correctly recovering the scale parameter (\u03c3 ~ 1.0) of the core distribution, along with the correct \u03bd value. The Gaussian likelihood under such outliers tends to overestimate the scale parameter. The results are summarized in Tab. 1. Note that, in general, epistemic uncertainty decreases as the number of samples increases. In our studies, we use relatively high-statistics datasets, which allows the model to achieve low values of epistemic uncertainty across the domain."}, {"title": "4.2 Partial Differential Equations", "content": "Given the model's ability to extract both epistemic and aleatoric uncertainties on the one-dimensional fits shown prior, we extend this space of solutions to Stochastic Partial Differential Equations (SPDEs). We define toy problems following the equations used in other works such as [17, 18, 19, 1, 20]. Specifically, working with the two-dimensional Poisson and Helmholtz equations. We add a stochastic term (f in Eq.12) to validate the ability of the surrogate model to learn the aleatoric component, specifically under the case of a functional form. At each iteration of training, the noise over the solution space is sampled randomly.\n\nf = N (0, (|x|\\sigma)^2), \\sigma = 0.1\n\n(12)\nThis is more aligned with real-world scenarios, in which measurement devices may inherently contain a functional dependence on the amount of noise measured. In both cases, we fit a Gaussian likelihood to our function, leaving the inclusion of Student-t likelihoods for future works involving real-world applications.\nStochastic Poisson Equation A two-dimensional stochastic Poisson equation is given by:"}, {"title": "\u22072u+2\u03c0\u00b2 sin(\u03c0x) sin(\u03c0y) + f = 0", "content": "(x, y) \u2208 [-1,1] \u00d7 [-1,1]\n\n\n\\begin{cases}\nu(-1,y) = 0\\\\\nu(1, y) = 0\\\\\nu(x, -1) = 0\\\\\nu(x, 1) = 0\\\\\n\\end{cases}\n\n\n\\nu(x, y) = sin(\\pi x) sin(\\pi y)\n(13)\nWe define a 64 \u00d7 64 grid over the solution space for training and use the same hyperparameter setup across all three models, i.e., the ReLUKAN, HR-ReLUKAN and the Bayesian HR-ReLUKAN. Specifically, we set the width of each network as [2,2,1], with a grid of 5 and a k value of 3 (summarized in Tab. 4). The order used for both higher order networks is 4. All models are trained for 60k iterations using the Adam optimizer with a learning rate of 10-3. For training the deterministic KANs, the loss function is given by Eq. 14, in which \u03b1 = 5 \u00d7 10\u22122. Lpde. corresponds to the loss contribution over the interior of the function, and Lbc. corresponds to the boundary conditions.\n\n\n\\mathcal{L} = \\alpha \\mathcal{L}_{pde.} + \\mathcal{L}_{bc.}\n\n(14)\nWhere mean squared error (MSE) is used between the second order derivatives on \u00fb from the network and the driving function, and on the boundary condition values defined prior. The loss function for the Bayesian networks is given by Eq. 15, in which we fit a Gaussian likelihood over both the boundary interior and boundary conditions of the PDE in combination, and scale the KL contribution with \u03b2 = 10-3. At inference, we sample the posterior distributions over the basis functions 5k times to provide accurate estimations of both the aleatoric and epistemic uncertainties.\n\n\\mathcal{L}_{Bayes.} = \\mathcal{L}(u|x, \\hat{u}_{\\sigma w}, \\hat{\\sigma}_{\\phi w})_{pde.} + \\mathcal{L}(u|x, \\hat{u}_{\\sigma w}, \\hat{\\sigma}_{\\phi w})_{bc.} + \\beta \\mathcal{L}_{KL}.\n\n(15)"}, {"title": "Stochastic Helmholtz Equation", "content": "Stochastic Helmholtz Equation A two-dimensional stochastic Helmholtz equation is given by:\n\n\u2207\u00b2u + k\u00b2u - [k \u2212 (\u03b1\u2081\u03c0)\u00b2 \u2013 (\u03b1\u2082\u03c0)\u00b2] sin(a\u2081\u03c0x) sin(a2\u03c0y) + f = 0\n\n\n(x, y) \u2208 [-1,1] \u00d7 [-1,1]\n\n\\begin{cases}\nu(-1, y) = 0\\\\\n\\nu(1,y) = 0\\\\\n\\nu(x, -1) = 0\\\\\n\\nu(x, 1) = 0\n\\end{cases}\n\n(16)\n\\nu(x, y) = sin(\u03b1\u2081\u03c0\u03c7) sin(a2\u03c0y), a\u2081 = 1, a2 = 2, k = 1\nWe define a 256 \u00d7 256 grid over the solution space for training and use the same hyperparameter setup across all three models, i.e., the ReLUKAN, HR-ReLUKAN and the Bayesian HR-ReLUKAN. 1 Specifically, we set the width of each network as [2,2,1], with a grid of 10 and a k value of 3 (summarized in Tab. 4). The order used for both higher-order networks is 4. All models are trained for 60k iterations. For training the deterministic KANs, the loss function is given by Eq. 14, in which \u03b1 = 5 \u00d7 10-2, and the loss function for the Bayesian method is given by Eq. 15. Note that the loss function in this case will encompass the second order derivatives of \u00fb, the function \u00fb itself, and the driving function. Note that unlike the Poisson equation shown prior, the magnitude of the driving function is relatively large (in relation to the magnitude of the function u(x, y)), making the learning of the aleatoric component through the Gaussian likelihood challenging. In order to reduce the deviation from the true mean, the surrogate model tends to push uncertainties towards unary values to allow the functional KAN to converge. As a result, the parameters of the Adam optimizer saturate and must be \"reset\" in order to provide better convergence. In [21], the authors show that in the context of Reinforcement Learning (RL), the debiasing quantities of Adam quickly saturate, implying the debiasing steps will have no effect on the overall update and ultimately plague the convergence. We observe similar behavior and therefore deploy a training scheme of resetting the optimizer state every 10k iterations of training, in which the final 10k the learning rate is also dropped by an order of magnitude to 10-4. We find this to be crucial for the aleatoric component to correctly converge under the Gaussian likelihood and can be numerically validated through the loss function, i.e., the likelihood becomes negative. Fig. 5 shows the learned solution surface for the three models, along with their residuals for an individual sample."}, {"title": "6 Conclusion", "content": "We have introduced the first method of uncertainty quantification in the domain of KANs, specifically focusing on (Higher Order) ReLUKANs [11, 12] to enhance computational efficiency given the overhead of Bayesian methods. Our method is general and can be translated to various other basis functions given a method of defining posteriors over their parameter space. Our method has been validated on simple one-dimensional functions, demonstrating accurate fitting procedures and precise representations of both epistemic uncertainty (true deviation from the mean) and aleatoric uncertainty (stochastic noise). This approach has been extended to the domain of SPDEs, where we construct toy scenarios for the Poisson and Helmholtz equations with the inclusion of a stochastic term. Additionally, we have demonstrated the method's ability to correctly identify functional dependencies introduced by this noise. We also identified potential challenges in optimizing the aleatoric model under large driving functions, specifically referring to large magnitudes in relation to the underlying solution and noise. In these cases, the optimizer generally pushes the aleatoric component away from its true values. To cope with those cases, in this work we proposed solutions based on empirical approaches found in other fields [21]."}, {"title": "Acknowledgments", "content": "We thank William & Mary for supporting the work of CF and JG through CF's start-up funding. The authors acknowledge William & Mary Research Computing for providing computational resources and technical support that have contributed to the results reported within this article. We would also like to thank Dr. Karthik Suresh for insightful discussions surrounding this work."}]}