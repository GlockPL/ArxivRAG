{"title": "FIRING RATE MODELS AS ASSOCIATIVE MEMORY:\nEXCITATORY-INHIBITORY BALANCE FOR ROBUST RETRIEVAL", "authors": ["Simone Betteti", "Francesco Bullo", "Giacomo Baggio", "Sandro Zampieri"], "abstract": "Firing rate models are dynamical systems widely used in applied and theoretical neuroscience to\ndescribe local cortical dynamics in neuronal populations. By providing a macroscopic perspective\nof neuronal activity, these models are essential for investigating oscillatory phenomena, chaotic\nbehavior, and associative memory processes. Despite their widespread use, the application of firing\nrate models to associative memory networks has received limited mathematical exploration, and most\nexisting studies are focused on specific models. Conversely, well-established associative memory\ndesigns, such as Hopfield networks, lack key biologically-relevant features intrinsic to firing rate\nmodels, including positivity and interpretable synaptic matrices that reflect excitatory and inhibitory\ninteractions. To address this gap, we propose a general framework that ensures the emergence of\nre-scaled memory patterns as stable equilibria in the firing rate dynamics. Furthermore, we analyze\nthe conditions under which the memories are locally and globally asymptotically stable, providing\ninsights into constructing biologically-plausible and robust systems for associative memory retrieval.", "sections": [{"title": "1 Introduction", "content": "The modelling of associative memory processes began in the early 1970's and 1980's with the mathematical formaliza-\ntion of Amari and of Grossberg and the elegant and explicit construction of\nHopfield . The authors drew inspiration from the early successes of statistical physics in the\ndescription of glassy phenomena , leveraging the\naverage properties of simple interconnected units. The key idea was to define a network of neuron-like computational\nunits, similar to those studied by McCulloch and Pitts , and investigate memory retrieval as\nemergent processes. Within this context, the authors conceptualized associative memory networks as dynamical systems\ndefined by ordinary differential equations (ODEs) having as stable equilibrium points the memory patterns to retrieve.\nThe first key contribution was the definition of a Lyapunov function for the associative memory system that ensured\nglobal asymptotic convergence to the equilibria of the system. Thus, any initial condition for the system would lie in\nthe basin of attraction of one of these equilibria, and the system trajectory will inevitably evolve towards it. The second\nkey contribution was the explicit definition of the set of memory vectors as binary patterns taking values in {\u22121,+1},\nanalogously to ferromagnets in spin glasses. The binary representation of the memory vectors allowed for the explicit"}, {"title": "2 Voltage vs. firing rate models", "content": "The voltage and firing rate models are two widely used neural network models for associative memory. In its classic\nautonomous version, the continuous-time voltage model is\n\\(v(t) = \u2212v(t) + W\u03a8(v(t)),\\) \nwhere v(t) is an n-dimensional, time-dependent vector containing voltages of neuronal populations, v(t) is its time\nderivative, \\(W \u2208 R^{n\u00d7n}\\) is the synaptic matrix, and \\(\u03a8 : R^n \u2192 R^n\\) denotes the activation function. The activation function\n\\(\u03a8(\u00b7)\\) is typically assumed to be diagonal and homogeneous, meaning that \\(\u03a8(v)_i = \u03c8(v_i)\\), where \u03c8: R \u2192 R is a scalar\nfunction applied entrywise to \\(v \u2208 R^n\\). Moreover, \u03c8(\u00b7) is typically assumed to be weakly increasing and odd. The\nprototypical memories of interest are binary vectors encoded in the synaptic matrix W, by means of one-shot Hebbian\nlearning . Scaled version of these memories are subsequently retrieved as the\nstable equilibria of equation (V).\nIf, in addition to the previous assumptions, W is symmetric and the activation function \\(\u03a8(\u00b7)\\) is differentiable, bounded\nand strictly increasing, then the trajectories of (V) are guaranteed to converge to the set of its equilibria. The classic\nproof of this result resorts to the LaSalle invariance principle and to the associated energy function\n:\n\\(E_H(v) = -\\frac{1}{2}\u03a8(v)^T W\u03a8(v) + \\sum_{i=1}^{n} \\int_{0}^{(\u03a8(v))_i} \u03c8^{-1}(z) dz.\\)\nIndeed, it can be shown that along the system's trajectories, the time derivative of the energy function is\n\\(\\dot{E_H}(v) = -\\dot{v}^T diag(\u03a8'(v))\\dot{v},\\)\nwhich is strictly negative for all v such that v \u2260 0.\nIn contrast, the autonomous continuous-time firing rate model reads as\n\\(\\dot{x}(t) = -x(t) + \u03a6(Wx(t)),\\)\nwhere the n-dimensional state vector x contains the firing rates of the neuronal populations, and \\(\\dot{x}(t)\\) denotes its time\nderivative. The activation function \u03a6(\u00b7) is typically assumed to be diagonal and homogeneous, meaning \\(\u03a6(x)_i = \u03c6(x_i)\\),\nwhere \u03c6: R \u2192 R is a scalar, weakly increasing function. In firing rate systems, the activation function is assumed to\nbe non-negative, meaning \u03c6(x) \u2265 0 for all x \u2208 R. The non-negativity of \u03c6(\u00b7) implies that (FR) is a positive system,\nmeaning that the trajectories of (FR) do not leave the positive orthant for non-negative initial conditions: if each entry\nof the initial condition satisfies \\(x_i(0) \u2265 0\\), then each entry remains non-negative for all time.\nFinally, the relationship between the voltage and firing rate models has been investigated in prior work . These studies demonstrate that the two models\u00b9 can be made equivalent through\nappropriate transformations of state and input. However, they do not address the challenge of designing the synaptic\nmatrix W to achieve desired memory patterns as stable equilibria within the system. Moreover, when W is low-rank, as\nis typical in associative memory contexts, the relationship between the models becomes less direct and more nuanced.\nSpecifically, the equivalence is derived by projecting the firing rate dynamics onto the subspace spanned by the columns\nof W, a constraint absent in the original dynamics. In addition, bridging the dynamics of the two models introduces a\ntime-varying external input, complicating the use of standard Lyapunov methods to establish convergence to equilibria."}, {"title": "3 Equilibria assignment through synaptic weights", "content": "Consider the firing rate model (FR). From now on we will assume that the activation function satisfies the following\nhypothesis.\n\u00b9In these works, the voltage model is presented with dynamical equations \\(\\dot{v} = \u2212v + W\u03a6(v)\\), while the firing rate model is\nexpressed as \\(\\dot{r} = -r + \u03a6(Wr)\\). Both models are grouped under the umbrella of firing rate systems, assuming they share a common\npositive activation function \\(\u03a6(\u00b7)\\) and the same synaptic matrix W."}, {"title": "3.1 Design techniques", "content": "Assumption 1 (Positive and monotonic activation functions). The activation function \\(\u03a6(\u00b7)\\) in (FR) is diagonal and\nhomogeneous, i.e., there exists \u03c6: R \u2192 R such that \\(\u03a6(x)_i = \u03c6(x_i)\\) for all \\(x \u2208 R^n\\). Moreover, the function \u03c6(\u00b7) is\ncontinuous, non-negative, and weakly increasing.\nGiven a set of {0, 1}-valued vectors in \\(R^n\\)\n\\({\\mathbf{\\xi}^\\mu}_{\\mu=1}^{P}\\)\ncorresponding to prototypical memory patterns with either active or inactive units, we are interested in designing\nbiologically plausible synaptic matrices W such that an appropriately scaled version of these vectors are equilibria of\nthe firing rate dynamics (FR). We consider prototypical memories \\(\\{\\mathbf{\\xi}^\\mu\\}_{\\mu=1}^{P}\\) satisfying the following hypothesis.\nAssumption 2 (Equally sparse and correlated memories). Given an average activity parameter p \u2208 (0,1), the\nprototypical memories \\(\\{\\mathbf{\\xi}^\\mu\\}_{\\mu=1}^{P}\\), \\({\\mathbf{\\xi}^\\mu} \u2208 \\{0,1\\}^n\\) satisfy\n(equal sparsity):\n(equal correlation):\n\\(||\\mathbf{\\xi}^\\mu||_1 = \u03c1n, \u2200\u03bc\u2208 {1,..., P},\\)\n\\({\\mathbf{\\xi}^{\\mu}}^T{\\mathbf{\\xi}^\\nu} = p^2n, \u2200\u03bc\u2260\u03bd.\\)\nThe conditions in Assumption 2 are inspired by the choice of prototypical memories in the classic Hopfield and firing rate models . In probabilistic terms, the\nparameter p is related to the average activity of the network in each memory pattern assuming that these activities are\nuncorrelated. The equal sparsity (4a) and equal correlation (4b) constraints refer to the simplest statistical structure that\nmemory patterns can have. As a matter of fact, if we assume that the entries of prototypical memories \\(\\{\\mathbf{\\xi}\\_{h}^\\mu\\} \u2208 \\{0,1\\},\n\u03bc = 1, . . ., P, h = 1, . . ., n\\) are i.i.d. random binary variables such that the probability that \\(\\{\\mathbf{\\xi}\\_{h}^\\mu = 1\\}\\) is equal to p for\nall h, u, then the conditions (4a) and (4b) are satisfied in expectation. However, as described in the first section of the\nAppendix, our analysis applies to a more general scenario where the memory patterns have more general correlations.\nWe now provide two useful definitions.\nFrom prototypical memories to synaptic matrices. To a set of prototypical memories \\(\\{\\mathbf{\\xi}^\\mu\\}_{\\mu=1}^{P}\\) satisfying the\nsparsity and correlation Assumption 2 with average activity p, we associate an n \u00d7 n dimensional covariance-based\nsynaptic matrix\n\\(W = \\frac{\u03b1}{p(1-p)n} \\sum_{\\mu=1}^{P} ({\\mathbf{\\xi}^\\mu}-p{\\mathbf{1}}\\_n) ({\\mathbf{\\xi}^\\mu}-p{\\mathbf{1}}\\_n)^T + \\frac{\u03b3}{n}1\\_n1\\_n^T,\\)\ndefined by the following parameters:\n\u2022 the correlation strength \u03b1 \u2208 R which modulates the covariance part of W given by the outer products of the\nshifted prototypical memories, and\n\u2022 the homeostatic strength \u03b3 \u2208 R which controls the magnitude of the component of the covariance-based\nsynaptic matrix that modulates the synaptic response proportionally to the global network activity. This\ncontribution to the global activity is referred to as homeostatic from the electrochemical balancing mechanism\nobserved in real neuronal networks. Typically, homeostatic terms are discussed in the literature as global inhibitory terms, with homeostatic strength \u03b3 \u2264 0.\nFrom prototypical memories and selected firing rates to retrievable memories. Select low and high firing rates\n\\(x_0 < x_1 \u2208 R\\) both belonging to the range of the activation function \u03c6, and associate to each prototypical memory\\(\\{\\mathbf{\\xi}^\\mu \u2208 R^n\\}\\) a retrievable memory \\(\\{\\mathbf{g}^\\mu \u2208 R^n\\}\\) defined by\n\\(\\mathbf{g}^\\mu = \\{\n\\begin{cases}\nx_o, & \\text{if } {\\mathbf{\\xi}\\_i}^\\mu = 0, \\\\\nx_1, & \\text{if } {\\mathbf{\\xi}\\_i}^\\mu = 1.\\\n\\end{cases}\n\\}\\)\nIn vector format, \\(\\mathbf{g}^\\mu := (x_1 - x_o){\\mathbf{\\xi}^\\mu} + x_01\\_n\\).\nThe firing rates \\(x_0\\) and \\(x_1\\) are the neural manifestation of the activity of population of neurons experiencing different\ninput currents . The input currents are the incoming activity that each neuron processes\nand filters by means of its activation function. Therefore, we can mathematically relate input currents and firing rates in\nthe following way. Let \\(I\\_0 \u2208 R\\) represent a weak input current, and \\(I\\_1 \u2208 R\\) a strong input current, so that \\(I\\_0 < I\\_1\\). Then\nthe states of the neurons associated with low and high firing rates are \\(x\\_0 = \u03c6(I\\_o)\\) and \\(x\\_1 = \u03c6(I\\_1)\\), respectively.\nGiven the definitions of covariance-based synaptic matrix and retrievable memories, the following theorem characterizes\nwhen the retrievable memories are equilibria of the firing rate system (FR). We postpone the proof to the Appendix."}, {"title": "3.2 The canonical case of Dayan & Abbott", "content": "The matrix in (5) closely resembles the one in , which is the canonical choice\nthroughout the theoretical neuroscience literature. We next show that the latter is indeed a special case of (5). The\nconstruction presented in assumes the following:\n(i) there exists z\u2217 such that \u03c6(z) = 0 for z < z\u2217;\n(ii) there are scalars \u03bb, \u03b4 > 0 such that \\(I\\_0 = \u2212\u03b4(1 + p\u03bb) < z\u2217, I\\_1 = \u03b4(\u03bb \u2212 1 \u2212 p\u03bb)\\) and \\(x\\_1 := \u03c6(I\\_1) = \u03b4\\). Since\nit is assumed that \\(I\\_0 < z\u2217\\), then \\(x\\_0 := \u03c6(I\\_0) = 0\\).\nFrom the previous relations it can be seen that \\(I\\_0, I\\_1\\) cannot be chosen arbitrarily. Indeed, the above defined \\(I\\_0\\) and \\(I\\_1\\)\nhave to satisfy the equation \\(pI\\_1 + (1 \u2212 p)I\\_0 + \u03c6(I\\_1) = 0\\). This implies that for this type of construction we can start\nfrom any \u03c6(\u00b7) satisfying condition (i) and any real number \\(I\\_1\\) such that\n\\(pI\\_1 + \u03c6(I\\_1) < z\u2217\\)."}, {"title": "3.3 A bridge from math to biology", "content": "We now want to address the biological interpretation of the map (5) and gain some insight on how the model can capture\ndifferent aspects of neural processing. As it stands, the positivity of the firing rate model offers a valuable interpretative\ntool to bridge dynamical system theory and neural processes. Specifically, it offers the possibility to understand the role\nof the different components of the covariance-based synaptic matrix and how they interact with the network activity to\ngenerate neuronal rates of firing. Separating the different components\n\\(W = \\frac{\u03b1}{p(1-p)n} \\sum_{\\mu}  \\underbrace{{\\mathbf{\\xi}^\\mu}{\\mathbf{\\xi}^{\\mu}}^\\_T}\\_{\\text{excitatory correlation network }W\\_{\\text{ex}}} -  \\underbrace{\\frac{\u03b1}{(1-p)n}  {\\mathbf{1}\\_n(\\sum_{\\mu}  {\\mathbf{\\xi}^{\\mu}}^T)}\\_{\\text{inhibitory memory-network interaction }W\\_{\\text{in}}} +  \\underbrace{\\frac{\u03b3}{n}  {\\mathbf{1}\\_n1}\\_n}\\_{\\text{global homeostatic network }W\\_{\\text{hom}}},\\)\nwe observe that\n\u2022 \\(W\\_{\\text{ex}}\\) is a relatively sparse excitatory network that takes into account how specific neuronal sub-clusters\npositively excite to produce fixation of the activity on a given pattern. Indeed, from the outer product of the\npatterns, we have that W\u2260 0 only if there exists \u03bc = 1, \u2026 \u2026 \u2026, P such that \\({\\mathbf{\\xi}\\_i}^\u03bc = 1\\) and \\({\\mathbf{\\xi}\\_g}^\u03bc = 1\\).\n\u2022 \\(W\\_{\\text{in}}\\) is the inhibitory network and is the sum of two terms, both regulating the global network activity with\nweights proportional to the parameters \u03b1,p. The first term, given by the outer products \\({\\mathbf{1}\\_n{\\mathbf{\\xi}^{\\mu}}}^T\\), provides\nglobal inhibition proportional to the correlation of the network activity and the different memory patterns.\nThe second term, given by the outer products \\({\\mathbf{1}\\_n1}\\_n\\), provides selective inhibition to the units of the memory\npatterns proportional to the summed network activity.\n\u2022 \\(W\\_{\\text{hom}}\\) is the homeostatic network and it exercises global regulation of the firing rate network via stimulation\nthat depends on the normalized network rate\n\\(s(t) = \\frac{1}{n}  \\sum\\_i x\\_i(t)\\).\nElaborating further on the biological constraints that lead to the construction of the covariance-based synaptic matrix,\nwe observe that the W in (5) depends explicitly from the prototypical memory vectors \\(\\{\\mathbf{\\xi}^\\mu\\}_{\\mu=1}^{P}\\). Notably, the form of\nW resembles the synaptic matrix of the classic Hopfield model , which can be constructed using the\nbiologically plausible Hebbian learning rule . Hebbian learning is a co-variation learning rule\nbased on the principle articulated by D. O. Hebb \u201ccells that fire together, wire together\" , implying the\nuse of local information to alter the strength of the synaptic couplings. In our case, we have that the covariance-based\nsynaptic matrix is simply given by a one-shot Hebbian learning rule. Hebbian learning as a learning framework adheres\nto the biological plasticity processes known as long-term potentiation (LTP) and long-term depression (LTD), known to be responsible for learning and forgetting in mammals.\nThese local synaptic modifications aim to stabilize the connection strengths between neurons, enabling the retrieval of\ncertain patterns through the collective dynamics of the network."}, {"title": "3.4 When the antimemories are equilibria", "content": "Consider a set of prototypical memories (3) satisfying the equal sparsity and the equal correlation constraints of\nAssumption 2 and let W be as in Theorem 4. Assume that \u03c6(\u00b7) in (FR) satisfies Assumption 1. For any prototypical\nmemory \\(\\mathbf{\\xi}\\^\u03bc\\) we define the corresponding antimemory as \\({\\mathbf{\\xi}\\^{\\mu\text{ant}}} := 1\\_n - \\mathbf{\\xi}\\^\u03bc\\) that is the vector in which we exchange the zeros\nwith ones and vice versa. We wonder whether \\({\\mathbf{g}\\^{\\mu\text{ant}}} := (x\\_1 - x\\_o){\\mathbf{\\xi}\\^{\\mu\text{ant}}} + x\\_01\\_n\\) is an equilibrium point of (FR). Notice\nthat this is exactly what happens for the Hopfield models. The answer to this question is given in the Appendix where it\nis shown that anti-memories provide equilibrium points for (FR) if and only if\n\\(\u03c1 = 1/2 or I\\_ox\\_1 = I\\_1x\\_0.\\)\nNotice that, while for the Hopfield model we have that \\(I\\_ox\\_1 = I\\_1x\\_0\\) and so anti-memories are equilibrium points\nregardless the value of p, this is not true for firing rate models since the condition \\(I\\_ox\\_1 = I\\_1x\\_0\\) generally fails."}, {"title": "3.5 Existence of homogeneous equilibria", "content": "A well-known issue in associative memory networks with a Hebbian synaptic matrix is the emergence of spurious\nequilibria , which are equilibria that do not correspond to the\nintended memories. We show now how the covariance-based synaptic matrix invariably produces at least one spurious\nequilibrium point with equal entries. Such equilibria will be called homogeneous equilibria.\nLemma 1 (Homogeneous equilibria). With the same notation and under the same assumptions as Theorem 1,\n(i) there exists at least one solution z to the equation\n\\(\u03b3^{\u22121}z = \u03c6(z),\\)\n(ii) for each solution z, the vector x = \\(\u03b3^{\u22121}z\\mathbf{1}\\_n\\), is an equilibrium point for the firing rate model (FR).\nEquation (12) has a simple graphical interpretation. Indeed, its solutions result from the intersections between the graph\nof \u03c6(z) and the straight line \\(\u03b3^{\u22121}z\\). Observe that in case \u03b3 < 0, then \\(f(z) := \u03c6(z) \u2013 \u03b3^{\u22121}z\\) is strictly increasing and\nsuch that \\(f(\u2212\u221e) = \u2212\u221e\\) and \\(f(+\u221e) = +\u221e\\). Hence there always exists exactly one solution to equation (12). If\ninstead \u03b3 > 0, then there might be multiple solutions."}, {"title": "4 Stability analysis", "content": "In this section, we examine the stability of equilibria of the firing rate dynamics (FR) with synaptic matrix W constructed\nas in the previous section."}, {"title": "4.1 On the local stability of retrievable memories", "content": "A sufficient condition that ensures local asymptotic stability of an equilibrium point can be derived via Lyapunov's\nindirect method . Specifically, if the Jacobian matrix of (FR) evaluated at an equilibrium\npoint, namely\n\\(J(\\mathbf{x}) = \u2212I + diag(\u03c6'(W\\mathbf{x}))W,\\)\nhas all its eigenvalues with strictly negative real part, then \\(\\mathbf{g}^\\mu\\) is locally asymptotically stable.\nBuilding on this result, we next establish a sufficient condition for the local stability of the retrievable memories as\nequilibria of (FR). The proof is postponed to Appendix.\nTheorem 2 (Local stability condition). With the same notation and under the same assumptions as Theorem 1, if\n\\(max\\{\u03c6'(I\\_o), \u03c6'(I\\_1)\\} max\\{\u03b1, \u03b3\\} < 1,\\)\nthen each retrievable memory \\(\\mathbf{g}^\\mu\\) is locally asymptotically stable for the firing rate model (FR).\nRemark 1 (The canonical case of Dayan & Abbott (2005)). For the memories construction presented in , since \\(\u03b3 = \u2212 \\frac{\u03bb}{p} < 0, \u03bb = x > 0\\), and \u03c6'(I\\_o) = 0, the stability condition (14) is simply\n\\(\u03c6'(I\\_1) < \u03bb^{\u22121}\\).\nTheorem 2 indicates that the derivative of the activation function \u03c6'(\u00b7) at the input coordinates \\(I\\_o\\) and \\(I\\_1\\) plays an\nimportant role in the stability of the retrievable memory patterns \\(\\{\\mathbf{g}^\\mu\\}_{\\mu=1}^{P}\\). Specifically, the smaller are \u03c6'(I\\_o) and\n\u03c6'(I\\_1), the smaller is the left-hand side of (14), suggesting that the retrievable memories are more likely to be stable. In\naddition, the slope of the straight line intersecting the activation function at \\(I\\_o\\) and \\(I\\_1\\) also affects the condition (14)\nthrough parameter \u03b1. In particular, when \u03b3 \u2264 \u03b1, stability is guaranteed if both \u03c6'(I\\_o) < 1/\u03b1 and \u03c6'(I\\_1) < 1/\u03b1, which\nmeans that the straight line intersecting the activation function at the points \\((I\\_o, x\\_o)\\) and \\((I\\_1, x\\_1)\\) has to intersect it from\nbelow.\nRemark 2 (The case \u03b3 \u2264 \u03b1). We have seen that when \u03b3 < \u03b1, the stability condition simplifies to max\\(\\{\u03c6'(I\\_o), \u03c6'(I\\_1)\\} <\n\u03b1^{-1}\\). It can be proved that \u03b3 < \u03b1 holds if and only if \\(I\\_ox\\_1 < I\\_1x\\_0\\). Observe that this condition always holds if\n\\(I\\_o \u2264 0 \u2264 I\\_1\\).\nRemark 3 (Instability condition). Techniques similar to those in the proof of Theorem 2 lead to the following statement:\nif\n\\(max\\{\u03c6'(I\\_o)[p\u03b1 + (1 \u2212 p)\u03b3], \u03c6'(I\\_1)[(1 \u2212 p)\u03b1 + p\u03b3]\\} > 1,\\)\nthen the equilibria \\(\\{\\mathbf{g}^\\mu\\}_{\\mu=1}^{P}\\) of (FR) are unstable.\nRemark 4 (homogeneous equilibria). The local stability of homogeneous equilibria introduced in Section 3.5 can be\nanalyzed with similar arguments used for proving Theorem 2. Specifically, if \\(\\mathbf{x} = \u03b3^{\u22121}z\\mathbf{1}\\_n\\) an equilibrium point for\n(FR), where z is a real number satisfying equation (12), then it is easy to see that \\(\\mathbf{x}\\) is locally stable if\n\\(\u03c6'(z) max\\{\u03b1, \u03b3\\} < 1\\).\nIt can also be proved that such equilibrium point is unstable if instead\n\\(\u03c6'(z) max\\{\u03b1, \u03b3\\} > 1\\),\nIn the special case in which \u03b3 < \u03b1, the stability condition simplifies to \\(\u03c6'(z) < \u03b1^{\u22121}\\)."}, {"title": "4.2 On the global stability of retrievable memories", "content": "We now present a result on the global behavior of the trajectories of (FR) based on an energetic characterization of the\nfiring rate model.\nThe function\n\\(E\\_{\\text{FR}}(\\mathbf{x}) = \\frac{1}{2}\\mathbf{x}^T W\\mathbf{x} + \\sum\\_{i=1}^n \\int\\_{0}^{x\\_i} \u03c6^{-1}(z) dz\\)\nwill serve as energy for the firing rate model (FR), where \u03c6\u22121 denotes any right inverse of \u03c6.2 Note that (16) coincides\nwith the classic Hopfield energy (1) expressed in the variable \\(\\mathbf{y} = \u03a6(\\mathbf{x})\\). The proof of the following theorem can be\nfound in the Appendix.\nTheorem 3 (Global convergence to equilibria). With the same notation and under the same assumptions as Theorem 1,\nassume that the activation function \u03c6(\u00b7) takes value in a bounded interval I. If \\(\\mathbf{x}(0) \u2208 I^n\\), then \\(\\dot{E}\\_{\\text{FR}} \u2264 0\\) along the\nflow of (FR) and each trajectory of (FR) converges to the set of equilibrium points of (FR)."}, {"title": "5 Illustrative examples", "content": "The aim of this section is to provide hints to the reader on the design choices that result in effective associative memory\nfiring rate networks. Choosing the proper combination of parameters to set up an effective firing rate model can be\nchallenging due to the presence of five free parameters; namely, the average activation p, the input currents \\(I\\_0, I\\_1\\), the\ngain factor \u03c1 and the activation current \\(I^*\\). The latter two parameters were not previously discussed, but as we will\nsee while we study two relevant examples, they are of critical importance in determining the stability properties of the\nsystem. Therefore, we will begin by fixing three out of the five free parameters, and study the stability properties of the\nsystem as the other two varies. Specifically, taking inspiration from neurobiological reality we will fix\nthe average neural activation as p = 0.2. We will then continue with the definition of two paradigmatic examples of\nactivation function, and numerically study the stability properties of the system as the slope and offset parameters vary.\nThe stability condition (14) is independent of network size; instead, the numerical stability of the firing rate model is\nstudied for a network with n = 1000 and P = 6. We considered the firing rate system to have numerically stable retrievable memories when the Jacobian of\nthe vector field (FR) evaluated at each of the memories has all eigenvalues with negative real part. Additionally, we will\npresent the energy function associated to specific firing rate models where the slope and offset parameters have been\nfixed to values that ensure either the stability or instability of the memories as equilibria for the system. In order to do\nso, we will evaluate the energy on a mesh interpolating the space between two memories as\n\\(\\mathbf{x} = t\\_1{\\mathbf{\\xi}^1} + t\\_2{\\mathbf{\\xi}^2}, t\\_1, t\\_2 \u2208 [0,1].\\)\nThe energy profiles are plotted only for values of \\(t\\_1, t\\_2\\) such that \\(\\mathbf{x} \u2208 [0,1]\\).\nFinally, we test the retrieval performances of the firing rate model using the average overlap parameter\n\\(s^\\nu(t) = \\frac{{\\mathbf{x}(t)}^T{\\mathbf{\\xi}^\\nu}}{\u03c1n}\\)\nwhere the average is taken over all the \u03bd = 1,..., P. In this testing phase, the prototypical memories \\(\\{\\mathbf{\\xi}^\\mu\\}_{\\mu=1}^{P}\\) are\ndrawn randomly so that the equal sparsity and equal correlation constraints are satisfied in expectation. Each retrieval is\ncharacterized by dynamics initialized arbitrarily close to the pattern \\(\\mathbf{\\xi}^\u03bd\\) and, if the memory is a stable equilibria of the\nsystem, then by the equal sparsity constraint there exists a \\(\\bar{t} > 0\\) such that \\(s^\u03bd(t) \u2248 1\\) for all \\(t > \\bar{t}\\). Conversely, by the\nequal correlation constraint we would expect that \\(s^\u03bc(t) \u2248 p\\) for all \\(t > \\bar{t}\\) and \u00b5 \u2260 \u03bd."}, {"title": "5.1 Rectified activation functions", "content": "Consider the rectified hyperbolic tangent activation\n\\(\\\n\u03c6(I) = \\{\n\\begin{cases}\n tanh(\u03c1(I \u2013 I\u2217)), & \\text{x > I\u2217,}\\\n0, & \\text{x < I\u2217,}\\\n\\end{cases}\n\\)\nwhere the parameter \\(I^*\\)\ncurrent, and \u03c1\u2208 R, \u03c1 > 0,\nequals the maximal derivative\nlargest input current that yields a zero output and will be referred to as activation\ntermed gain factor"}, {"title": "5.2 Sigmoidal activation functions", "content": "Consider the sigmoidal activation function\n\\(\\\n\u03c6(I) = \\frac{1}{1 + e^{-4\u03c1(I - I^* - (2\u03c1)^{-1})}}, \u03c1, I^* \u2208 \\mathbb{R}, \u03c1 > 0.\n\\)\nThis function has a long history in machine learning research and is a commonly employed activation function in\n(artificial) neural networks , especially for binary classification problems where the output is\ninterpreted as a probability. The sigmoidal activation function offers a smoothed transition compared to the sharp\nthreshold of the rectified hyperbolic tangent, providing more gradual changes in neural firing rates. As such, it makes\nsense to define the activation current \\(I^*\\)\nfrom Fig.\nas the point in which the firing rates start to considerably rise, as observable\n7. Mathematically, \\(I^*\\) is defined by \\(\u03c6(I^* + (2\u03c1)^{\u22121}) = 1/2\\), indicating the I-axis intersection with the tangent\nto \u03c6 at its inflection point. In this case, the\nto the maximum slope of\nboth functions. The aim\nhow the stability of the system varies depending on the values of the parameters \u03c1 and \\(I^*\\)\nalong\nsome fixed intervals. As shown in the stability condition widens when \u03b3 < 0, whereas it shrinks considerably to a narrow region for \u03b3 > 0. Figures 7(b) and\n7(e) plot the energy associated with\n(blue square marker in\nwith, \u03c1 = 4.8, \\(I^* =\n(red starred marker in\n\ngain factor \u03c1 is scaled by 4 in\nthe rectified hyperbolic tangent, allowing a direct comparison"}, {"title": "6 Conclusion", "content": "Firing rate models provide a biologically plausible and efficient framework for representing neural activity at the\npopulation level, making them particularly well-suited for capturing key macroscopic behaviors in neuronal networks,\nincluding associative memory formation. This study introduces a positive firing rate model that encodes memories as\nneural firing rates, mirroring realistic activity levels observed in the brain. Through a balanced excitatory-inhibitory"}]}