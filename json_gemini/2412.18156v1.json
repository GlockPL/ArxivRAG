{"title": "SCREADER: Prompting Large Language Models to Interpret scRNA-seq Data", "authors": ["Cong Li", "Qingqing Long", "Yuanchun Zhou", "Meng Xiao"], "abstract": "Large language models (LLMs) have demonstrated remarkable advancements, primarily due to their capabilities in modeling the hidden relationships within text sequences. This innovation presents a unique opportunity in the field of life sciences, where vast collections of single-cell omics data from multiple species provide a foundation for training foundational models. However, the challenge lies in the disparity of data scales across different species, hindering the development of a comprehensive model for interpreting genetic data across diverse organisms. In this study, we propose an innovative hybrid approach that integrates the general knowledge capabilities of LLMs with domain-specific representation models for single-cell omics data interpretation. We begin by focusing on genes as the fundamental unit of representation. Gene representations are initialized using functional descriptions, leveraging the strengths of mature language models such as LLaMA-2. By inputting single-cell gene-level expression data with prompts, we effectively model cellular representations based on the differential expression levels of genes across various species and cell types. In the experiments, we constructed developmental cells from humans and mice, specifically targeting cells that are challenging to annotate. We evaluated our methodology through basic tasks such as cell annotation and visualization analysis. The results demonstrate the efficacy of our approach compared to other methods using LLMs, highlighting significant improvements in accuracy and interoperability. Our hybrid approach enhances the representation of single-cell data and offers a robust framework for future research in cross-species genetic analysis.", "sections": [{"title": "I. INTRODUCTION", "content": "Large Language Models (LLMs) [1], [2] have revolutionized various fields by demonstrating exceptional capabilities in understanding and generating human language [3]. Their ability to capture intricate patterns and relationships within sequential-like data makes them powerful tools for knowledge representation and natural language processing [4], [5], [6]. In recent years, LLMs have also shown potential in broader applications, such as interpreting structured data and providing insights across diverse domains [7], such as bioinformatics [8], chemistry [9], and scientometrics [10], [11]. This versatility stems from their extensive training on vast corpora, enabling them to encapsulate a wide range of general knowledge [12], [13]. As Foundation Models, LLMs offer flexibility and scalability, making them well-suited for complex datasets, including those encountered in the life sciences [14], [15]. Despite these advancements, existing research in gene representation [16] and cell-level analysis [8] often fail to leverage the full potential of LLM. Studies [17], [18], [19] have focused mainly on large-scale gene expression data but have not fully incorporated external descriptions and common knowledge available through LLM. This oversight limits the depth and richness of gene representations, as current models do not adequately utilize the comprehensive knowledge embedded in LLMs. Furthermore, the application of LLMs in life sciences remains underexplored, lacking opportunities to enhance the interpretation of biological data with linguistic insights.\nIn summary, the integration of large language models (LLMs) into genomic data interpretation faces several challenges. (C1) Ignore Existing Knowledge: There is insufficient utilization of detailed gene knowledge, such as the well-constructed description of gene functions [20], [21], which limits the enrichment of gene representations. (C2) Limited Domain Data: Although sequencing techniques generate numerous high-throughout data [22], [23], [24], [25], the disparity in data volume across species poses a challenge, as many species lack the extensive data required for training large models, complicating the development of universally applicable representations. (C3) Biomodel Semantic Gap: Lastly, existing biological large language models are mostly trained solely on omics data, which is a type of sequence data, neglecting the vast amount of high-quality textual semantic information that has made large language models successful [26]. This approach causes existing models to overlook the common sense understanding of the world that humans possess [27].\nTo address these challenges, we propose a novel framework named LLM AS SINGLE-CELL RNA DATA READER (SCREADER), which integrates LLMs with gene expression data interpretation. Our strategy involves using functional gene descriptions to initialize gene representations, enhancing the model with detailed biological insights. By treating genes as the fundamental unit of analysis, we connect different species through common genetic knowledge, overcoming data limitations. In addition, we employ prompt learning techniques to leverage mature LLMs, harnessing their capabilities to interpret and distinguish cell types in gene expression data effectively. Our contributions can be summarized as follows:\n\u2022 We introduce a method for initializing gene representations using functional descriptions, enriching the interpretative depth of genomic data.\n\u2022 We propose a cross-species approach using genes as the basic unit, facilitating insights even with limited data availability.\n\u2022 We demonstrate the application of prompt learning to adapt LLMs for life sciences, enhancing the analysis of gene expression data.\n\u2022 Our preliminary experiments show that SCREADER excels in accurately categorizing cell types, highlighting the utility of LLMs in bridging linguistic and biological knowledge to uncover new biological insights."}, {"title": "II. PRELIMINARY", "content": "A. Important Definitions\nDefinition 1 (Gene Description): A gene description is a textual sequence that provides a concise summary of a gene's function, structure, and other relevant biological information. It typically includes details such as the gene's name, associated protein products, cellular localization, and its role in biological processes or pathways. Formally, a gene description can be denoted as a word sequence: $T = {t_0, t_1,...}$.\nDefinition 2 (Large Language Model): A Large Language Model (LLM) can be conceptualized as a function that takes a word sequence as input and output: $f : R^{n\u00d71} \u2192 R^{m\u00d71}$, where n and m are the length of the input and output sequence.\nDefinition 3 (Single-cell RNA sequencing Data): scRNA-seq data can be represented as a sequence $C \u2208 R^{ng\u00d71}$, where $n_g$ is the total gene number. Each column of C corresponds to a gene. The values in the matrix represent gene expression levels, typically measured in counts or normalized units.\nB. Problem Statement\nThis study aims to evaluate the ability of LLM to understand and analyze single-cell RNA sequencing (scRNA-seq) data by focusing on the cell-type annotation task. Cell type annotation is a crucial step in single-cell genomic analysis, involving the assignment of cell type labels to individual cells based on their gene expression profiles. Formally, the cell type annotation task can be defined as follows:\nDefinition 4 (Cell Type Annotation Task): Given A set of cells $C = {C_1,C_2,...,C_n}$ and a set of predefined cell type labels $L = {l_1, l_2, ..., l_k }$ The task is to find a function $f : C \u2192 L$ that assigns a cell type label to each cell, such that $f(c_i) = l_j$, where $l_j \u2208 L$ is the most appropriate cell type label for cell $c_i$ based on its gene expression profile."}, {"title": "III. RELATED WORK", "content": "The transcriptome [28], which refers to the collective expression states of thousands to tens of thousands of genes in each cell in biology [29], is a crucial determinant of the cell state. With the continuous advancement of modern sequencing technologies [30], the number of transcriptomes [31], [32] worldwide is accumulating astonishingly. Effectively interpreting this information and further analyzing life processes has become a significant challenge. Over the centuries of life science development, humans have gained a substantial understanding of life systems, including elucidating the functions of many genes [20], [21]. This knowledge is stored in the medium of natural language. Although directly using LLMs to understand omics data might be quite challenging due to the significant differences between characters and gene meanings or the dimension curse [33], initializing each gene based on the semantics of its function. At the same time, LLM offers a promising and feasible approach [16]. Previous works have established foundational models [34] for directly interpreting transcriptome information. By adopting an approach similar to language models [35], [36], these methods [17], [18] encode the categories and expression values of active genes into token embeddings, which are further applied with attention mechanisms and can capture the interactions between genes and their determinative roles in the overall state of the cell. The success of such foundation models also prompts new considerations: could larger parameters and more knowledge-rich LLM be adapted to understand omics data as well? In this study, we introduce a novel approach to answer this question."}, {"title": "IV. METHODOLOGY", "content": "As depicted in Figure 1, SCREADER consists of two main parts. The first part aims to generate the gene-level representation via LLMs based on the descriptive text of each gene. The second part aims to generate the cell embedding via the specific gene expression and LLM. After these stages, we could obtain the cell embedding and then feed it into the downstream task, such as cell-type annotation.\nGene-level Embedding Initialization. The representation of each gene is initialized with its descriptive texts, which is extracted from the NCBI dataset\u00b2. Those texts will then be fed into the GPT-3.5\u00b3 to generate the embeddings for each gene. For each gene in our dataset, we extract its descriptive text from the NCBI Gene database. This database integrates information from a wide range of species and includes crucial details such as nomenclature, Reference Sequences (RefSeqs), maps, pathways, variations, and phenotypes. The rich textual information provided by NCBI serves as a comprehensive representation of each gene's biological context and function. As illustrated in Figure 1(a), we employ the GPT-3.5 model's embedding functionality to convert these textual descriptions into numerical representations suitable for computational analysis, defined as:\n$e_i = f_{gpt}(T_i)$,\nwhere $T_i$ is the description of a given gene $g_i$, $f_{gpt}(\u00b7)$ represents the text-embedding-ada-002 model in GPT-3.5, and e is the representation of this gene.\nThe process is as follows.\n1) Data Extraction: We query the NCBI Gene database using each gene's identifier or symbol to retrieve its associated descriptive text.\n2) Text Preprocessing: The extracted text is cleaned and standardized to ensure consistency across all gene de-scriptions. This may involve removing special characters, standardizing formatting, and truncating to a uniform length if necessary.\n3) Embedding Generation: Each preprocessed gene de-scription is then passed through the GPT-3.5 embedding API. This API transforms the textual input into a high-dimensional vector (typically 1536 dimensions for GPT-3.5) that captures the semantic content of the description.\n4) Embedding Storage: The resulting embeddings are stored in a format that allows efficient retrieval and manipulation during subsequent analysis steps.\nThis approach leverages the power of large language models to capture complex biological information in a dense, numerical format. By using GPT-3.5 for embedding generation, we benefit from its deep understanding of language and context, which has been trained on a vast corpus of text, including scientific literature. This allows our gene-level representations to potentially capture nuanced relationships and functional similarities that might not be immediately apparent in the raw text descriptions.\nThe resulting gene embeddings serve as the foundation for our subsequent analysis, providing a rich, contextual representation of each gene that goes beyond simple sequence-based or keyword-based approaches.\nCell-level Representation. Gene expression levels are crucial for distinguishing cell types in single-cell RNA sequencing data. We leverage this information by ranking genes based on their expression levels within each cell, combining this ordinal information with gene embeddings to construct a comprehensive cell representation. The process is as follows:\n1) Expression Ranking: For each cell, we rank all genes based on their expression levels in descending order. Let $[g_1, g_2,..., g_n]$ represent the ranked sequence of genes for cell c, where $g_i$ is the i-th highest expressed gene in the cell. We then take the top-2048 genes to form the ranked gene sequence.\n2) Embedding Lookup: For each gene $g_i$ in the ranked sequence, we retrieve its corresponding embedding vector $e_i$ generated in the previous step (Gene-level Embedding Initialization).\n3) Position-aware Representation: To incorporate both the gene's identity and its relative expression level, we combine the gene embedding with its rank information. For the i-th ranked gene, we compute a position-aware representation $p_i$ as follows:\n$p_i = e_i \u2295 PE(i)$\nwhere \u2295 denotes vector concatenation and $PE(i)$ is a positional encoding vector that captures the gene's rank.\n4) Cell Representation: The final representation for cell c is then constructed as the sequence of these position-aware gene representations:\n$E_c = (p_1, p_2, ..., p_n)$\nThis Ranked Gene Sequence approach offers several advantages: (1) It preserves the relative expression levels of genes within each cell, which is often more informative and robust than absolute expression values. (2) It combines the rich semantic information captured in gene embeddings with the cell-specific expression patterns. (3) The resulting representation is invariant to technical factors that might affect absolute expression levels across cells or experiments. (4) It provides a fixed-length representation for each cell, regardless of the number of non-zero expressed genes, facilitating downstream analysis. (5) Finally and most importantly, our approach only utilizes the knowledge in gene summary and LLM, so training is unnecessary.\nBy constructing cell representations in this manner, we create a rich, informative input for subsequent cell-type annotation tasks that captures both the cell-specific expression patterns and the broader biological context of each gene.\nLLMs as the Gene Interpreter. We select Llama-13b [37] as the based LLM. The cell representation then projects to 5120 dimensions through a multi-layer perceptron (MLP) containing to conform to the Llama-13b's input dimensions h:\n$E_{cell} = MLP_p(E_c)$,\nwhere $MLP_p(\u00b7)$ is the projection layer with the learnable parameter. $C \u2208 R^{n\u00d7h}$ is the embedding of the given cell.\nWe then pass the cell embedding matrix into the Llama-13b along with the downstream task instruction, such as 'what is the cell type of this given embedding?'. After that, we take the class-token (< cls >) from the output and feed it into a trainable classification head:\n$E_{ins} \u2295 E_{cell} \u2192 \u00ea_{cls}$,\n$\u0177 = Softmax(MLP_c(\u00ea_{cls}))$,\nwhere $E_{ins}$ is the text embedding of the given instruction, $\u00ea_{cls}$ is the embedding of the class-token. After fed into LLM, scInterpreter will ReadOut the output. For the cell-type annotation task, we set the ReadOut operation as directly taking the class-token embedding from the output. $\u00ea_{cls}$ is the class-token embedding after the aggregation within the LLM. \u0177 is the model prediction. During the training process, the Llama model will be frozen. The cross-entropy loss will optimize the projection layer, the classification head, and the class-token token's embedding layer.\nOptimization Objective. The model is trained to minimize the cross-entropy loss between the predicted label distribution and the true label distribution. For a single cell, the loss is defined as:\n$L = - \\sum_{i=1}^{K} y_i log(\u0177_i)$\nwhere K is the number of cell type classes, $y_i$ is the true probability of the cell belonging to class i (usually a one-hot encoded vector), and $\u0177_i$ is the predicted probability for class i."}, {"title": "V. DATA PREPARATION AND EXPERIMENTAL SETTINGS", "content": "To validate SCREADER, we construct two scRNA-seq datasets. HUMAN-10k comprises 10,000 single-cell sequencing records with 61 different cell types, each having 23,111 genes records. MOUSE-13k comprises 13,000 records with 37 different cell types, each having 27,443 gene records.\nDatasets Preparation. The preprocessing and the golden label generation of the above single-cell RNA sequencing dataset are conducted via Seurat [38] in R [39]. First, we performed quality control to filter out low-quality cells and genes based on gene expression counts and mitochondrial gene percentage. We normalized the data using log-normalization and identified highly variable genes with the FindVariableFeatures function. The data was scaled with ScaleData and subjected to Principal Component Analysis (PCA) using the top 10 principal components. We projected the data into two dimensions with UMAP and conducted clustering with the FindNeighbors and FindClusters functions (resolution = 0.5). Marker genes were identified through differential expression analysis (FindAll-Markers) for each cluster. The golden label of the Cell type annotation was then identified by comparing the expression of marker genes with known cell type-specific genes from databases such as PanglaoDB [40] and CellMarker [41]. After cell clustering, manual annotation of cell types is performed by specifying marker genes for different cell clusters. Only genes with a log fold change greater than 0.3, expressed in at least 30% of cells, and positively regulated are considered.\nCell Embedding Initialization. For the initialization of gene knowledge, we first selected 23,111 human genes and 27,443 mouse genes based on the expression median of each gene in the above dataset. Subsequently, we retrieved the description information for each gene from NCBI. The information entries included: Official Symbol, Official Full Name, Gene Type, Organism (organs and tissues where the gene is mainly distributed), Lineage, Expression (expression values in major organs obtained from experimental sequencing, represented in RPKM), and Summary (description of the gene's functional distribution based on past knowledge and experience). The retrieved gene knowledge was embedded using the GPT-3.5 API's 'text-embedding-ada-002', with the resulting embeddings having a dimension of 1536. Among the 23,111 human genes, 593 did not have corresponding NCBI entries (approximately 2.5%). For these genes, we manually queried the GPT-3.5 conversational model: \"Please provide a detailed description of the functions, distribution, and expression of human gene gx as much as possible\" using the GPT-generated responses as the knowledge for these genes, where gx is the gene without description. Similarly, we employed the same method for embedding generation for the 4,503 mouse genes out of the 27,443 (approximately 16.4%) that lacked NCBI entries. After obtaining the initialized embeddings of individual human and mouse genes, we screened the expression values of genes in each cell within the dataset. By normalizing using the median expression value of each gene, we only selected the top 2048 highly variable genes. The embedding of each gene was multiplied by its expression value in that cell, and then the 2048 new embeddings were stacked. This resulted in the initial cell embedding for each cell.\nTraining Workflow. Our methods were implemented according to the following workflow: The initialized embeddings were fed into a Multilayer Perceptron (consisting of 5 layers, where the 1536-dimensional input is projected to 4096 dimensions to fit the input requirements of Llama-13b). Then these embeddings were passed through a frozen Llama-13b model, followed by the embedded text instruction 'What is the cell type of this given embedding?'. A <cls> token was attached to the end of the sFinally, <cls> states were read out of hidden output states and applied with another MLP classifier head to do cell-type classification training. For comparison, we removed the frozen Llama model as the GenePT group, the two MLPs remained and were trained normally. The initialized cell embeddings are first passed through an up-projection MLP, increasing the dimensionality to 4096. Subsequently, the embeddings of each gene within the cell are averaged and then directly fed into a classification MLP for cell-type classification training. In both sets of experiments, the human and mouse datasets were randomly split into a 10-fold validation split ratio to serve as training and testing sets, respectively. Both sets of experiments were trained for 10 epochs, using the same learning rate of 5e-5, batch size of 64, and 1000 warm-up steps.\nBaseline Methods. We select GenePT [16] as the compared method. GenePT is a novel approach that leverages pre-trained language models for interpreting single-cell RNA sequencing data. The selection of GenePT as our baseline is motivated by several factors:\n\u2022 Similar Conceptual Framework: Like our approach, GenePT utilizes the power of large language models to process and understand gene expression data, making it a suitable candidate for comparison.\n\u2022 Proven Effectiveness: GenePT has demonstrated strong performance in various single-cell analysis tasks, including cell type annotation, which aligns with our primary objective.\n\u2022 Adaptability: The method is adaptable to different types of single-cell data and various downstream tasks, allowing a fair comparison across different experimental settings.\nIn our comparative analysis, we evaluated both GenePT and our proposed method on the same datasets, using identical train-test splits and evaluation metrics. This ensures a fair and rigorous comparison of the two approaches."}, {"title": "VI. EXPERIMENTS", "content": "In this section, we conducted the cell-type annotation task to illustrate the advantage of introducing the large language model to facilitate understanding of the single-cell omic data.\nStudy of the Cell-type Annotation. Figure 2 reported the classification performance of GenePT and sCREADER on the HUMAN-10k and MOUSE-13k. We used four classification metrics, accuracy, precision, recall, and F1 score to evaluate two methods. We can observe that SCREADER outperformed GenePT on two datasets with a huge margin. The two methods compared have the same initial gene embedding, so we speculate that the common knowledge from the large language model could provide a better-supervised signal for the downstream task training, thus resulting in better performance. The equal performance among each metric from SCREADER showed our proposed method and training strategy could provide robust downstream performance.\nAdditionally, we observed that, compared to the GenePT, our methods showed a more significant improvement on the HUMAN-10k dataset compared to the MOUSE-13k dataset. This may be due to the higher proportion of genes with NCBI knowledge entries in human genes (up to 97.5%) compared to mouse genes (only 83.6%). As a result, the embeddings of human cells benefited from better interpretation after processing with the large language model.\nTo step further, we reported the confusion matrix of each method on dataset MOUSE-13k, to show the difference between the prediction result and the true label. From the left part of Figure 3, we could observe that most prediction results were scattered across the matrix, indicating a high degree of misclassification. The lighter regions of the diagonal suggest that the model frequently confuses certain cell types with others, highlighting deficiencies in either feature representation or classification capability. In contrast, the right part of the matrix presents a starkly different scenario, where the majority of predictions align closely with the diagonal, thus reflecting a high concordance between predicted and actual labels. In addition to the overall performance improvement shown by the confusion matrix, we also observed that our method performs poorly on certain specific cell types, such as Parietal Endoderm. Our method tends to misclassify Parietal Endoderm cells as Rostral Neurectoderm, which are two significantly different cell types. Upon further investigation, we found that the MOUSE-13k dataset contains only 284 Parietal Endoderm cells, which is a very small number, while there are 5,392 Rostral Neurectoderm cells, making it the most numerous cell type in the dataset. This imbalance in data labels is likely the cause of the misclassification.\nIn Figure 4, we report the confusion matrix on the HUMAN-10k dataset. As can be seen, the confusion matrix on the left shows lighter and more chaotic colors along the diagonal, indicating significant misclassification of cell types. In contrast, the confusion matrix on the right, which represents our method, shows a notable improvement. The colors along the diagonal are darker, indicating that almost all cell types can be correctly identified. This phenomenon denotes a significant improvement in classification accuracy, attributable to the sophisticated feature encoding and contextual understanding afforded by the prompt-based training method employed with the large language model.\nStudy of the Visualization Analysis. Figure 5 reported the UMAP visualization of the cell embedding from the initial state, GenePT, and SCREADER, on MOUSE-13k dataset. In the initial state of the MOUSE-13k datasets, as observed on the left side of the visualization, each cell types cluster together, exhibiting poor separability. The middle visualization, i.e. GenePT, shows some improvement in terms of separability among different categories. However, several cell types remain interspersed. It can be observed that in the left clustering diagram, cell groups such as dark blue, yellow, and purple already exhibit noticeable cluster separation using only text-initialized embeddings without any training. In the middle UMAP plot, these cell groups still maintain good separation. While other cell groups show some improvement in separation, they do not exhibit a clear pattern. The clustering performance of the GenePT group is consistent with the results presented in the confusion matrix on the left side of Figure 3. The cell groups Definitive Endoderm, Cardiomyocytes, and surface ectoderm perform excellently in the confusion matrix, and their separation trends in the clustering diagram are more pronounced compared to other groups. In contrast, the visualization of SCREADER demonstrates a markedly superior clustering effect. Cells of the same type exhibit exceptional aggregative properties, suggesting a high degree of intra-class similarity and inter-class divergence. Additionally, the visualization of SCREADER demonstrates improvements corresponding to the GenePT group. Cell types such as Definitive Endoderm, Cardiomyocytes, and surface ectoderm maintain their original excellent performance. Other previously mixed groups, such as the Nascent Mesoderm, Primitive Streak, and Spinal Cord, which were mixed together in the GenePT group, show better separation trends in the right visualization. This improvement is also reflected in the right-side confusion matrix of Figure 3.\nIn Figure 6, on the HUMAN-10k dataset, our method also shows significant improvement in transcriptome interpretation. The left clustering diagram shows that the human-initialized cell embeddings tend to be mixed together. The middle GenePT clustering diagram shows a slight improvement; previously well-separated cells, such as Epithelial cells and Cardiomyocytes, remain clearly separated, while other groups show only slight improvement. This aligns with the left-side confusion matrix in Figure 4, where these cell types perform better than others. In the right UMAP plot, cells of the same type, represented by the same color, show more organized clustering, demonstrating a substantial improvement. This indicates that our method using LLM for transcriptome interpretation is quite effective. The underlying driver is that our proposed method leverages the broad, generalized knowledge inherent in LLMs to provide more effective supervisory signals, thereby enhancing the separability of learned cell embeddings."}, {"title": "VII. CONCLUSION REMARKS", "content": "This study represents a preliminary stride in the application of leveraging large language models for interpreting single-cell omics data, particularly in the context of cell-type annotation. The experimental results demonstrate that integrating LLMs into single-cell omics analysis pipelines can significantly enhance our ability to interpret and classify cell types. Additionally, extending this method to multi-omics integration and rare cell type identification could yield valuable insights for precision medicine and developmental biology. In conclusion, our study marks a significant step forward in the application of artificial intelligence to single-cell biology, paving the way for more sophisticated, knowledge-driven approaches to understanding cellular complexity at unprecedented resolution."}]}