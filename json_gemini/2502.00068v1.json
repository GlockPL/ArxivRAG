{"title": "Privacy Preserving Charge Location Prediction for Electric Vehicles", "authors": ["Robert Marlin", "Raja Jurdak", "Alsharif Abuadbba", "Dimity Miller"], "abstract": "By 2050, electric vehicles (EVs) are projected to account for 70% of global vehicle sales. While EVs provide environmental benefits, they also pose challenges for energy generation, grid infrastructure, and data privacy. Current research on EV routing and charge management often overlooks privacy when predicting energy demands, leaving sensitive mobility data vulnerable. To address this, we developed a Federated Learning Transformer Network (FLTN) to predict EVs' next charge location with enhanced privacy measures. Each EV operates as a client, training an onboard FLTN model that shares only model weights, not raw data with a community based Distributed Energy Resource Management System (DERMS), which aggregates them into a community global model. To further enhance privacy, non-transitory EVs use peer-to-peer weight sharing and augmentation within their community, obfuscating individual contributions and improving model accuracy. Community DERMS global model weights are then redistributed to EVs for continuous training. Our FLTN approach achieved up to 92% accuracy while preserving data privacy, compared to our baseline centralised model, which achieved 98% accuracy with no data privacy. Simulations conducted across diverse charge levels confirm the FLTN's ability to forecast energy demands over extended periods. We present a privacy focused solution for forecasting EV charge location prediction, effectively mitigating data leakage risks.", "sections": [{"title": "1 INTRODUCTION", "content": "The global shift from internal combustion engine vehicles (ICEVs) to Electric Vehicles (EVs) marks a critical move toward sustainable transportation, with EVs projected to account for up to 70% of global vehicle sales by 2050 [1]. While this transition supports environmental goals, it also increases energy demands within communities and cities. Managing this demand across large EV networks will require advanced technology, with Distributed Energy Resource Management Systems (DERMS) playing a crucial role in enabling efficient energy management. However, processing EV data through DERMS raises critical privacy and security concerns due to the sensitivity of location history, charging patterns, and trip details. Federated Learning (FL) has emerged as a promising method to address these concerns by decentralising model training, allowing data to remain on devices rather than being transmitted to a central server [2]. Traditional FL models are generally designed for static environments with relatively stable client data distributions, making them less effective for highly mobile agents such as EVs. The lack of focus on leveraging mobility for privacy leaves a gap in existing FL approaches, particularly for dynamic, geographically dispersed data sources like EV networks. To address these concerns, our FLTN solution embraces agent mobility for privacy through a mechanism called peer weight sharing, and enables compliance with data privacy regulations, such as the European Union's GDPR [3] and California's CCPA [4].\nThe FLTN framework enhances data privacy by decentralising model training, addressing the challenge of managing sensitive, distributed data across large, dynamic EV networks. To achieve this, community DERMS collect local model weights from EVs during charging sessions. For non-transitory EVs, this process includes peer-to-peer weight sharing and augmentation, further strengthening privacy measures. Augmentation, in the context of this work, involves non-transitory EVs collaboratively combining their locally trained model weights through a peer-to-peer sharing mechanism before sending the combined weights to the community DERMS. This obfuscates the origin of individual weight updates, breaking the direct link between an EV's data and its contribution to the global model. Additionally, augmentation mitigates the influence of outliers, enhancing the robustness and reliability of the FL process while maintaining convergence efficiency. Achieving reasonable predictive accuracy in this framework typically requires a minimum of 50\u2013100 EVs. As more EVs contribute, the diversity and representativeness of the data improve, further boosting the model's performance. Using Federated Averaging (FedAVG), DERMS aggregates these weights, including those from transitory EVs, to form a community global model. FedAVG is well-suited to bandwidth-limited environments, such as EVs with constrained processing power [2], and effectively manages diverse non-IID data patterns across EVs, like varying charging habits and usage behaviors, enhancing accuracy while preserving privacy. FLTN further mitigates risks from malicious EVs that could upload falsified updates by exchanging model weights rather than gradients, which are more vulnerable to inversion and backdoor attacks [5]. Additionally, DERMS"}, {"title": "2 RELATED WORK", "content": "2.1 Privacy Preservation for Mobility Data\nMobility data, which encompasses the tracking and analysis of transportation modes, is increasingly essential for applications like urban planning, traffic management, and personalised services. However, its misuse can lead to privacy breaches, exposing individuals to unwanted surveillance, discrimination, or identity theft [6]. Preserving privacy in mobility data is challenging due to its sensitive nature, often including granular details such as visited locations, time spent, and travel routes. As Miguel et al. [7] highlight, even anonymised data can be re-identified through linkage with external datasets, a process known as de-anonymisation.\n2.1.1 Techniques for Privacy Preservation\nVarious techniques have been proposed to address privacy challenges in mobility data. Differential privacy is widely used, introducing noise to data to obscure true values while allowing aggregate analysis, ensuring that query outputs are statistically indistinguishable regardless of an individual's presence [8]. Building on these principles, our solution enhances privacy by employing peer-to-peer model weight sharing and augmentation among locally stationed (non-transitory) EVs before community DERMS modeling. During this step, non-transitory EVs exchange their locally trained model weights with peers in the same community, combining them into a shared set of augmented weights. This process obfuscates the origin of individual EV updates, reducing the risk of direct exposure to sensitive data. Additionally, by incorporating contributions from multiple EVs, this step mitigates the influence of potential outliers, enhancing the robustness of the combined updates. The approach assumes that neighboring EVs act as 'honest but curious' participants, acknowledging that a malicious EV could theoretically infer patterns from shared weights, though this risk is reduced by the obfuscation introduced through augmentation. However, augmenting weights within peer groups before transmission to the community DERMS helps obscure individual contributions, aligning with the principles of differential privacy by making specific data points harder to isolate. Unlike traditional differential privacy techniques, which typically inject noise into the data or model updates and may reduce prediction accuracy, our FLTN framework achieves strong privacy without sacrificing data quality. This is accomplished by directly sharing and augmenting model weights among peers, preserving both privacy and predictive performance.\n2.1.2 Federated Learning for Data Privacy\nRecently, FL has emerged as a privacy-preserving approach by training models across devices without data sharing, offering privacy advantages over differential privacy methods [9]. One such study applied FL in EV charging contexts, demonstrating FL's potential but also highlighting specific limitations that our approach aims to address. For instance, 'Predicting Electric Vehicle Charging Stations Occupancy: A Federated Deep Learning Framework' proposes an FL framework for predicting charging station occupancy. While it achieves accurate occupancy forecasts, it is limited to"}, {"title": "2.1.3 Swarm Learning Approach for Data Privacy", "content": "Swarm learning, a decentralised machine learning approach, has gained attention as an alternative to traditional FL. Unlike FL, which typically relies on a central aggregator, swarm learning enables participants to share and update model weights directly in a peer-to-peer fashion, often using a ring or daisy-chain topology [13]. This architecture reduces dependence on a central server, enhancing resilience and privacy. However, the sequential nature of weight exchanges in swarm learning can introduce increased communication latency and risks of propagating corrupted updates through the network.\nOur approach draws inspiration from swarm learning's decentralised principles but adapts them to better accommodate the dynamic mobility patterns of EVs. Specifically, non-transitory EVs in the FLTN framework augment weights by combining contributions from all peers within a community before sharing with the DERMS. A key aspect of this process is the assignment of alphas, which determine the relative weight of each EV's contribution during augmentation. In this work, we assume equal alphas across all non-transitory EVs, ensuring uniform contributions and simplifying the augmentation mechanism. Unlike the sequential weight-sharing in swarm learning, this parallel peer-to-peer augmentation obfuscates the origin of individual updates while preserving robust model convergence. Additionally, the FLTN framework incorporates mechanisms tailored to EV spatio-temporal characteristics, enhancing predictive accuracy and scalability compared to existing swarm learning techniques.\nComparison to Well-Known Aggregation Functions\nOur augmentation function extends traditional federated aggregation methods like FedAvg by introducing a peer-to-peer pre-combination step. Unlike FedAvg, where individual updates are directly aggregated at the central server, the augmentation strategy obfuscates the origin of updates by combining contributions within a peer group before submission. This enhances privacy by reducing the risk of associating individual EV updates with specific data points. Compared to swarm learning, which relies on sequential weight-sharing, the augmentation function operates in parallel, reducing communication latency and improving scalability. While it lacks the outlier detection features of advanced aggregation methods like Krum [14], the augmentation process inherently mitigates the impact of outliers by combining updates locally, offering a simpler yet effective mechanism for robust and privacy-preserving FL."}, {"title": "2.1.4 Attacks in Edge Machine Learning", "content": "Data poisoning attacks pose a serious threat in edge machine learning, where models are trained directly on source-collected data. Adversaries exploit the decentralised structure and data variability of edge computing to manipulate training data and degrade model performance [15]. FLTN mitigates this threat through several mechanisms. By sharing model weights rather than raw data or gradients, FLTN limits the impact of any single EV's contribution, reducing the likelihood that a malicious actor can substantially influence the DERMS community model. The peer-to-peer weight sharing and augmentation process for non-transitory EVs further dilutes individual contributions before updates reach the community model, making it more challenging for injected false data to significantly alter model outcomes. Additionally, the natural agent mixing resulting from EV mobility enhances privacy and mitigates poisoning risk by distributing data contributions across different communities.\nModel inversion attacks also pose a significant threat to the privacy and security of machine learning models. This vulnerability arises from the overexposure of model outputs, which adversaries can exploit to gain insights into the underlying data distribution, effectively revealing private information through repeated interactions [16]. The risk is heightened in edge computing environments, where models interact with potentially untrusted users, as is common in federated systems [17]. Our FLTN framework mitigates these inversion risks by sharing only model weights rather than gradients or raw data which significantly reduces the exposure of sensitive data while maintaining data utility. By sharing only the final trained weights from each local model, rather than gradients or activations, we minimise the potential for inversion attacks. Gradients, which represent the direction of model updates during backpropagation, can reveal sensitive information if accessed by a malicious actor. Activations are also excluded, as they could be used to infer input data characteristics, thus protecting sensitive user data.\nWhile much of the existing literature addresses vulnerabilities in EV mobility systems through regulatory frameworks or broad technological approaches, this paper introduces a novel FLTN framework specifically designed for EV charge location prediction with enhanced privacy"}, {"title": "3 PROBLEM DEFINITION", "content": "This section outlines the problem addressed in this paper: predicting the next location where an EV will recharge its battery. We introduce the relevant background concepts and notation necessary for understanding the EV mobility dataset, particularly focusing on the prediction task within the context of protecting EV data privacy using our FLTN system. Unlike traditional methods that rely on centralised data repositories, our approach safeguards EV data privacy by sharing only locally trained model weights with a community-based DERMS. Our study considers the spatio-temporal mobility patterns associated with EV-based services, including features such as pick-up locations, adjacent community areas, current battery levels, and timestamps for each trip. Understanding these factors is crucial for accurately predicting where an EV is likely to recharge next.\nOur goal is to develop a model capable of predicting an EV's next charging location, represented by the community area where the EV is expected to be when its battery reaches a critical charging threshold. Community areas are defined as distinct regions within or around a city, acting as potential sites for pick-ups, drop-offs, or EV charging. To ensure data privacy, we use an FLTN system that allows individual EVs to train locally on their respective datasets. EVs share only local model weights with community-based DERMS, which act as distributed servers that train on EV (client) weights. For locally stationed (non-transitory) EVs, peer-to-peer model weight sharing and augmentation occur before submitting weights to DERMS, adding an extra layer of privacy. Community DERMS then share their aggregated global model weights with EVs during charging sessions. This approach mitigates the risk of exposing sensitive data containing locations, timestamps, and social interactions while enabling effective prediction of the next charging location.\nWhere:\n\u2022 W(t)i: The model weights on local client i (an EV) at training iteration t.\n\u2022 N: The total number of EVs (local clients) participating in the federated learning process.\n\u2022 DERMSi: The distributed energy resource management system (DERMS) aggregates local model weights from EVs and updates the community global model weights.\n\u2022 W(t+1): The updated community global model weights after aggregation by DERMS at iteration t+1.\n\u2022 YEV: The predicted next charge location for the EV.\n\u2022 FL_Transformer(): The federated learning transformer model that takes input data and the community model weights to predict the next charging location.\n\u2022 XEV: The input feature set for the EV, including pick-up locations, neighbouring community areas, current battery level, time stamps, etc.\n\u2022 PeerShare(\u00b7): The peer-to-peer sharing and augmentation of local model weights among non-transitory EVs before sharing with DERMS."}, {"title": "FEDERATED LEARNING EQUATION FOR PREDICT-ING EV NEXT CHARGE LOCATION", "content": "Global Model Weight Update (with Peer-to-Peer Sharing and Augmentation):\n$W^{(t+1)}_{DERMS} = DERMS \\left( \\frac{1}{N} \\sum_{i=1}^{N} PeerShare (W^{(t)}_{i}) \\right)$ (1)\nPrediction Equation:\n$Y_{EV} = FL\\_Transformer(X_{EV}, W^{(t+1)})$ (2)\nEXPLANATION\n1) Local Training: Each EV i trains a local FL transformer model using its data to update its model weights Wti.\n2) Peer-to-Peer Sharing and Augmentation: For non-transitory EVs, local model weights are shared within peer groups, and the weights are augmented using PeerShare(.) before being sent to DERMS.\n3) Weight Aggregation: The DERMS servers, distributed across each community, aggregate the weights from all participating EVs (including augmented peer weights) to form a community model W(t+1).\n4) Community Model Update: The aggregated community weights W(t+1) are shared with the EVs during charging sessions. Each EV then uses these updated weights for future training of their local on-board model.\n5) Prediction: Using the community model weights W(t+1), the FL transformer model on each EV predicts the next charging location \u0177EV.\nThis equation represents the iterative process of federated learning where local models contribute to a community global model without sharing raw data, thereby preserving privacy while still enabling accurate predictions."}, {"title": "4 MATHEMATICAL FRAMEWORK", "content": "4.1 Local Model Training and Peer-to-Peer Sharing with Augmentation\nLet Di represent the local dataset for EV i, where i \u2208 {1,2,..., N} and N is the total number of EVs. Each EV i trains a local model fi(W) on its dataset Di, where W represents the model parameters (weights) for EV i at time t. The local objective function to minimise is given by:\n$W = arg \\min\\limits_{W} L_{i}(f_{i} (W), D_{i})$ (3)\nwhere Li is the loss function for EV i. After local training, non-transitory EVs engage in peer-to-peer sharing and augmentation. Each EV i shares its local weights W with its peer group, receiving peer weights Wpgi from other non-transitory EVs. These peer weights are then used to augment the EV's own weights, introducing diversity and obfuscating individual EV contributions. The augmented weights are defined as:\n$W^{t}_{aug} = W^{t}_{i} + \\alpha \\sum_{j \\in peers} W^{t}_{pg_{j}}$ (4)\nwhere \u03b1 is a scaling factor controlling the contribution of peer weights. The augmented weights Waug are then transmitted to the community DERMS. In contrast, transitory EVs send their locally trained weights W directly to the DERMS without peer-to-peer sharing or augmentation.\n4.2 Community Model Aggregation by DERMS\nEach community DERMS aggregates the model weights from all participating EVs, including the augmented weights from non-transitory EVs, to update the community global model. The community model parameters are computed as:\n$\\Theta = \\frac{1}{N} \\sum\\limits_{i=1}^{N} W^{t}_{aug_{i}}$ (5)\nwhere Wi represents either the augmented weights Waug for non-transitory EVs or the original weights Wi for transitory EVs.\n4.3 Model Update During Charging Transaction\nWhen an EV i connects to a charging station, it receives the latest community global model weights \u0398 from the DERMS. The EV then updates its local model as follows:\n$W^{t+1}_{i} \\leftarrow \\Theta$ (6)\nThe updated local model fi(Wt+1) is now ready for further training.\n4.4 Federated Learning Process\nThe overall federated learning process, including peer-to-peer sharing and augmentation, can be summarised as follows:"}, {"title": "5 PROPOSED SOLUTION", "content": "This section discusses three fundamental components of our research: 1) the solution architecture, 2) our taxi EV mobility dataset, and 3) the proposed FLTN system to secure private EV data. First, we present the system pipeline, outlining the sequence of processes from data input to the final prediction of EV's next charge location. We detail the key stages, including data preprocessing, and the prediction mechanism, emphasising the role of each in the overall system. Second, we describe the construction and characteristics of the taxi EV mobility dataset, highlighting the methodologies used for data collection, feature engineering, and the assumptions incorporated into the dataset. Last, we explore the implementation of our FLTN system, explaining its structure, training process, and its specific application in predicting the EV's next charging location.\n5.1 Proposed Pipeline\nOur pipeline architecture, shown in Figure 1, summaries processes within our proposed FLTN solution. This includes data loading and pre-processing, model definition, training local models, peer-to-peer sharing and augmentation, averaging weights and updating both our community global model and our local model, testing our community model, and finally, prediction output for the global and local model"}, {"title": "5.2 EV Taxi Dataset", "content": "Our proposed solution, leveraging machine learning, required a large dataset containing EV mobility and charge transactions. For this, we used a dataset created in [18], comprising both empirical and synthetic data. The empirical component is based on a real-world Chicago taxi mobility dataset (non-EV taxis), while the synthetic data incorporates EV industry metrics [19]. This dataset assumes that (1) most taxis will be EVs by 2050, and (2) all charge transactions will"}, {"title": "5.3 Our Proposed Solution", "content": "This section first discusses FL for data privacy. We then discuss model selection for our proposed solution. Following this we discuss training, validation, test outcomes, and methods. Then we look at performance evaluation, followed by baseline modelling and finally, we cover results and analysis.\n5.3.1 Federated Learning for Data Privacy\nIn a previous study [18], we used a centralised CNN model to predict EVs' next charge location. While this provided accurate predictions, it lacked data privacy considerations. To address this, we employ FL, a decentralised approach that preserves data privacy by enabling local model training on EV mobility spatio-temporal data [21]. However, applying FL in this context is not straightforward; achieving reliable accuracy depends on aggregating contributions from a sufficient number of EVs, which varies based on community size and mobility patterns. Determining the optimal number of EVs is crucial for effective learning, as sparse participation may lead to reduced predictive accuracy and data utility. Data leakage risks, including insights into locations, mobility patterns, and transaction behaviors, are reduced as FL allows each EV to train locally, sharing only model updates. In our implementation, EVs share local model weights with a community-based DERMS, which aggregates these into a community global model across 77 communities in the city of Chicago. This decentralised approach ensures raw data remains on vehicles, significantly reducing privacy risks and meeting data protection standards [22].\nThe use of a decentralised FL network specifically for our study also addresses challenges for data heterogeneity and the need for robust, generalised models across different types of vehicles and driving environments [23]. However, implementing FL in EVs is challenging. Security threats such as model inversion attacks within FL networks pose significant privacy risks by exploiting the shared model updates to reconstruct sensitive information from the training data [24]. In such an attack, an adversary with access to the global model, or the gradients shared during the training process, can infer details about the original data, such as personally identifiable information (PII), even though the raw data was never explicitly shared. This vulnerability arises because the model parameters encode information about the training data, which can be reverse-engineered to reveal private information. To Address and prevent model inversion attacks, we utilise FLTN model parameters such as large batch sizes and normalisation for model training, as well as only sharing local model weights with the community DERMS, and peer-to-peer sharing and augmentation adding an additional layer of privacy.\n5.3.2 Model Selection\nTo understand which model would be best suited to our problem area, we experimented with three machine learning models. These models included; a Bi-directional Long Short-Term Memory (BiLSTM) model, then a Convolutional Neural Network (CNN) model, and finally a Transformer model. These models were selected based on their success in previous spatio-temporal mobility research studies [25] and [26] and [27].\nThe BiLSTM model was chosen for its proven efficacy in working with spatio-temporal sequences [28]. BiLSTM's efficiency in addressing mobility problems stems from its architecture as an advanced Recurrent Neural Network (RNN) that modifies the standard LSTM to process input sequences in both forward and backward directions. This dual processing allows the model to capture context from both past and future states, making it particularly effective for tasks involving sequential data, such as time series prediction, natural language processing, and spatio-temporal analysis. The next model we experimented with consisted of a CNN model. Previous studies by authors Jeon et al., [29] and [30] discuss the efficiency of spatio-temporal sequence modelling using CNN models. All spatio-temporal sequence data were first converted into images, with each batch represented by images of uniform dimensions. When image sizes vary, the input layer and subsequent filters require substantial preprocessing to handle them, complicating model design and decreasing training efficiency.\nFinally, we utilised a PyTorch-based Transformer model, specifically designed to handle our EV mobility spatio-temporal sequence data. This model architecture is particularly well-suited for capturing both spatial dependencies e.g., the relationships between different locations, and temporal dependencies e.g., how these relationships create patterns over time. Our Transformer model was configured with six encoder layers, following standard practices seen in successful implementations such as the original model by Vaswani et al. [31]. This number of layers was chosen based on the complexity of EV mobility data and the need to capture temporal dependencies. Each encoder layer used eight attention heads, which allow the model to attend to different parts of the input sequence simultaneously, capturing nuanced relationships across time and space. After testing various configurations, this setup provided an optimal balance between computational efficiency and model performance. The multi-head attention mechanism is particularly beneficial for spatio-temporal data, as it allows the model to consider multiple aspects of the sequence concurrently, learning intricate dependencies between spatial regions and time steps.\n5.3.3 Training and Validation\nOur solution included machine learning on datasets containing spatio-temporal sequences representing EV taxi trips, with each EV treated as an independent client within our FLTN system. Datasets maintained chronological order of sequences to preserve the temporal dependencies inherent in the data. By treating each EV taxi as a distinct client, we were able to train model weights locally on each EV's dataset before aggregating these weights into a community-level DERMS global model.\nTo ensure a balanced representation of different EV taxi models and to avoid the pitfalls of an imbalanced dataset where some models with higher market shares could dominate the learning process we randomly assigned EV datasets to various taxi vehicles. This method facilitated the"}, {"title": "6 PERFORMANCE EVALUATION", "content": "This section compares centralised and decentralised modeling approaches. We begin by examining three centralised models used as baselines to assess their effectiveness in addressing our problem area. Next, we discuss, evaluate, and analyse the final decentralised FL model selected for our proposed solution.\n6.1 Baseline Modelling\nFor our baseline modelling experiment we evaluated three centralised models: a Bi-directional LSTM, a CNN, and a transformer model. Our goal was to determine which model could best interpret data representing EV taxi spatio-temporal sequences, encompassing both mobility and charge transaction features. The results of these experiments are presented in the central model results table (Table 1) and a bar graph (Figure 3). After completing these experiments, it became clear that the transformer model demonstrated the strongest understanding of the problem. Consequently, we selected this model for further decentralised experiments.\n6.2 Results and Analysis\nFirst we discuss our FLTN results in Table 2 containing the following features, which presents results from an experiment where EVs were split into groups to simulate real-world community structures. Grouping EVs allows us to evaluate the effectiveness of peer-to-peer sharing and augmentation and assess privacy preservation within and across different community models. Our decentalised results table contains the following features 2:"}, {"title": "6.3 Privacy Preservation for Mobility Data", "content": "This paper introduces a novel solution to protect EV users' private data while maintaining accurate predictions of EVs' next charging locations. The approach leverages spatio-temporal mobility sequences that contain sensitive spatial (location) and temporal (time) information, both of which could reveal individual mobility patterns if not carefully handled. To address privacy risks, this solution differentiates between non-transitory and transitory EVs, reflecting the natural movement patterns of EVs as mobile agents, as shown in Figure 5.\nNon-transitory EVs, which operate mainly within specific communities, engage in localised peer-to-peer model weight sharing and augmentation before communicating with the community DERMS. This initial exchange helps obfuscate individual EV contributions, adhering to differential privacy principles by making personal data less distinguishable within a group context. On the other hand, transitory EVs, which move across multiple communities, share their model weights directly with the community DERMS, safeguarding broader mobility patterns without compromising privacy. By incorporating peer-to-peer sharing and augmentation, the solution minimises exposure of individual data, promoting both predictive accuracy and enhanced user privacy across varying mobility levels.\nThe DERMS mobility Figure 6 illustrates the rate of EV consistency within a DERMS area, with the X-axis representing the duration (in epochs) an EV stays within the DERMS, and the Y-axis (on a logarithmic scale) showing the count of EVs remaining for each duration. The sharp drop-off at the beginning highlights that most EVs stay for only a few epochs before moving, indicating high mobility within the DERMS area. This behavior aligns with privacy goals in the FLTN framework, as frequent movement makes it challenging for anyone EV to consistently observe others, thus reducing the risk of inference attacks. The logarithmic Y-axis reveals occasional spikes and long-tail behavior at certain durations, suggesting that a few EVs remain longer but are rare. This high turnover rate of EVs, coupled with the 1000 EV sample size, reinforces the robustness of the privacy solution by demonstrating how constantly changing DERMS populations protect against persistent observation attempts."}, {"title": "6.3.1 Privacy Threat Model", "content": "In the FLTN framework, both DERMS and EVs are considered honest but curious. This implies that while they adhere to the established protocols, they may still attempt to infer additional information from the shared model weights. To mitigate this, the framework incorporates peer weight sharing and augmentation specifically among non-transitory EVs, facilitating weight mixing that obscures direct associations between these EVs and their shared weights. This weight mixing approach prevents DERMS from identifying specific non-transitory EVs through the weights they share, effectively breaking potential links that might compromise privacy. Additionally, the random mobility of transitory EVs adds an inherent layer of anonymity, as their frequent movement across DERMS areas makes it more challenging to associate them with specific weights over time. By anonymising shared weights, the system further reduces the risk of revealing sensitive information, even if DERMS or EVs analyse the data beyond its intended use. This layered approach ensures that privacy is maintained throughout the FL process, minimising potential leakage of sensitive mobility patterns from both DERMS and EVs."}, {"title": "6.3.2 FLTN Privacy Evaluation and Analysis", "content": "To evaluate the privacy efficacy of our FLTN system, we introduce an entropy-based privacy metric, emphasising how increased randomness within shared weights reduces the potential for data reconstruction attacks. Higher entropy values across layers indicate greater uncertainty and obfuscation of individual data, complicating adversarial attempts to infer sensitive information. In FLTN, peer-to-peer sharing and augmentation among non-transitory EVs introduces variability in the shared weights, potentially raising entropy by increasing the uncertainty of the original source. The entropy H for each layer is calculated as:\n$H = - \\sum_{i=1}^{n} p_{i} log(p_{i})$ (7)\nwhere pi represents the probability distribution of weights. Unlike regular FL, which aggregates weights uniformly, FLTN's peer-to-peer sharing and augmentation process introduces variability, potentially yielding higher entropy across critical layers. This increase in entropy enhances privacy by making patterns less traceable.\nAdditionally, FLTN amplifies privacy through minor noise addition within weight-sharing processes. This controlled noise infusion, spread through peer-to-peer exchanges, increases randomness, making it challenging to isolate individual EV patterns or discern specific data trends. The entropy increase of approximately 0.15-0.2 in absolute terms (or 2-2.5% relative to normal FL entropy) suggests that FLTN provides a more robust privacy layer compared to regular FL. This higher entropy reflects improved obfuscation articulated in Figure 8, reducing the likelihood of adversaries reconstructing sensitive information from the shared weights.\nTo further ensure privacy, non-transitory EVs engage in peer-to-peer weight sharing and augmentation before sharing with the community DERMS. Rather than one EV aggregating the weights, this process involves an exchange and mixing of weights among non-transitory EVs, helping to obfuscate individual contributions. By the time the weights reach the DERMS, they have been anonymised through peer-to-peer exchanges, breaking potential links to specific non-transitory EVs. The inclusion of these exchanges and controlled noise addition strengthens FLTN's privacy, providing greater resistance to data reconstruction attacks compared to regular FL."}, {"title": "7 DISCUSSION AND CONCLUSION", "content": "Our proposed FLTN system successfully balances prediction accuracy with enhanced privacy protections, though it introduces some trade-offs inherent to FL approaches in dynamic EV networks. Aggregating model weights across a range of battery levels (20% to 100%) improves generalisability and reflects real-world conditions, though this diversity can increase model complexity, potentially impacting training time and computational demands. Large batch sizes, peer-to-peer sharing and augmentation further strengthen privacy by obfuscating individual EV data but may slightly reduce sensitivity to nuanced, individualised patterns, potentially affecting accuracy in unique or rapidly changing scenarios. Nonetheless, FLTN's multi-layered privacy design offers a robust and scalable solution that not only aligns with privacy regulations but also provides a practical pathway for energy providers to implement data-driven demand forecasting without compromising user privacy. By securely predicting EV charge locations, this system supports privacy-friendly insights into urban mobility patterns, empowering energy providers to meet community energy needs effectively and ethically.\nFuture Works\nAs the landscape of EV mobility evolves, further research is needed to strengthen the security and privacy guarantees of FLTN. A key area for exploration is the incorporation of advanced privacy-preserving techniques, such as secure multiparty computation and homomorphic encryption. Additionally, embedding real-time anomaly detection mechanisms within the FLTN could help identify and counteract data poisoning attacks more effectively, preserving the integrity of predictive models used in EV infrastructure. Moreover, addressing the trade-offs between security and computational efficiency will be crucial for real-time applications like V2X communication. Future research should also focus on improving model scalability and robustness to ensure the FLTN framework remains resilient in larger and more complex EV networks. By pursuing these advancements, the security and reliability of the EV mobility ecosystem and the power grid can be significantly enhanced."}]}