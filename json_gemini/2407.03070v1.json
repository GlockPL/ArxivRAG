{"title": "Federated Learning for Zero-Day Attack Detection in 5G and Beyond V2X Networks", "authors": ["Abdelaziz Amara korba", "Abdelwahab Boualouache", "Bouziane Brik", "Rabah Rahal", "Yacine Ghamri-Doudane", "Sidi Mohammed Senouci"], "abstract": "Deploying Connected and Automated Vehicles (CAVs) on top of 5G and Beyond networks (5GB) makes them vulnerable to increasing vectors of security and privacy attacks. In this context, a wide range of advanced machine/deep learning-based solutions have been designed to accurately detect security attacks. Specifically, supervised learning techniques have been widely applied to train attack detection models. However, the main limitation of such solutions is their inability to detect attacks different from those seen during the training phase, or new attacks, also called zero-day attacks. Moreover, training the detection model requires significant data collection and labeling, which increases the communication overhead, and raises privacy concerns. To address the aforementioned limits, we propose in this paper a novel detection mechanism that leverages the ability of the deep auto-encoder method to detect attacks relying only on the benign network traffic pattern. Using federated learning, the proposed intrusion detection system can be trained with large and diverse benign network traffic, while preserving the CAVs' privacy, and minimizing the communication overhead. The in-depth experiment on a recent network traffic dataset shows that the proposed system achieved a high detection rate while minimizing the false positive rate, and the detection delay.", "sections": [{"title": "I. INTRODUCTION", "content": "Fifth generation (5G) and beyond (5GB) networks promise to revolutionize the transportation industry by enabling ultra-reliability with ultra-low latency and high bandwidth communications [1]. These advances will significantly empower many verticals, such as smart agriculture, health, and Intelligent Transportation Systems (ITS). As part of ITS, Connected and Automated Vehicles (CAVs) have been taken significant and careful considerations in 3GPP 5G standards [2]. Specifically, integrating V2X communications into the 5G ecosystem has enabled innovative use cases and applications, such as advanced driving, vulnerable road user protection, and vehicle platooning [3]. Yet this progress is expected to be extended with 5GB, contributing thus to reducing traffic accidents and dramatically saving road users' lives. However, CAVs at all automation levels will face a massive vector of cyberattacks coming from 5GB technologies and leading to hazardous situations for road users. For example, Distributed and Denial of Service (DDoS) attacks have already been demonstrated to break 5G services [4]. But the impact of these attacks are likely to be more expansive with the integration of CAVs. More than this, cyberattacks are working continuously to develop novel tactics for breaching and breaking such systems. Facing all these challenges, Machine Learning (ML) appears as a key cybersecurity enabler to protect 5GB-enabled CAVs [5]. Various Machine Learning (ML)/ Deep Learning (DL) based Intrusion Detection Systems (ML/DL-based IDSs) have been proposed to protect vehicular networks against attacks. Most of them rely on supervised and centralized learning [6]. Centrally training the detection model requires significant data collection and labeling, which increases the communication overhead, and may raise privacy concerns. To mitigate centralized learning limitations, collaborative ML [7] has been used, enabling thus continuous accuracy evolution and flexibility. Nevertheless, several limitations exist in early collaborative ML-based IDSs [8]\u2013[10]. Specifically, they generate a significant communication overhead during ML model updates and may violate data privacy, since learning nodes might share private information. To cope with the aforementioned issues, recent research [11]\u2013[14] leveraged the potential of federated leaning (FL) paradigm, which has shown promising results in many applications. FL is a distributed ML paradigm allowing several nodes to train a global model cooperatively without sharing their datasets, avoiding thus overhead and mitigating privacy risks [7]. Interestingly, all existing FL-based IDSs for 5GB-enabled CAVs rely on supervised learning techniques. One important limitation of using such techniques is their inability to detect attacks different from those seen during the training phase (unseen attacks), and zero-day attacks. Another challenging issue is data imbalance, i.e., the numbers of benign and malicious traffic samples are not in the same range. Benign network traffic samples are easily available. On the other hand, malicious samples are scarce or unavailable. The lack of a thorough dataset of attack samples limits the usage of supervised techniques. Finally, most existing detection approaches assume that FL clients maintain labeled datasets that may use at each round. This assumption may not be realistic, as CAVS cannot label the network flow on every turn.\nAs a CAV runs a set of well-known applications (safety, convenience, commercial, etc), their communication pattern"}, {"title": "II. RELATED WORK", "content": "Several distributed ML-based IDSs have been proposed for detecting attacks in 5GB-enabled CAVs. Negi et al. [8] presented a DL-based IDS to detect anomalies in ITS based on Long Short-Term Memory (LSTM). In this work, time series data are collected by CAVs and sent to the cloud to enable the training and retraining of a global model using a cluster of servers instead of one server. Shu et al. [9] proposed a collaborative IDS based on supervised DL, Generative Adversarial Networks (GANs), and Software Defined Networking (SDN). The proposed system enables distributed SDN controllers managing sub-networks of CAVs to train a global model for the whole network without directly exchanging their sub-network flows. However, both [8] and [9] raise privacy issues since datasets are shared between learning nodes. Zhang et al. [10] proposed a distributed ML-based IDS that enables CAVs to directly communicate to train a global model based on supervised learning without sharing their datasets. However, peer-to-peer distributed learning generates a large overhead, degrading communication performance. Uprety et al. [11] proposed a FL-based privacy-preserving collaborative IDS for CAVs. This work enables CAVS (FL clients) to train DL models on a locally labeled dataset and share their parameters with the central FL server to build a global model. Boualouache et al. [12] proposed a FL-based privacy-preserving collaborative IDS based on supervised learning that leverages a set of FL servers to train the global model. Liu et al. [13] proposed FL for collaborative IDS. This work suggests offloading the training to distributed vehicular edge nodes. Specifically, CAVs act as FL clients for building models based on their locally labeled datasets and Roadside Units (RSUS) for aggregating global models. Hbaieb et al. [14] proposed SDN-FL-based IDS for CAVs. In this work, SDN controllers train local models based on labeled datasets built using data collected from CAVs, while the aggregation of global models is performed on the cloud.\nOverall, existing FL-based IDSs for 5GB-enabled CAVs [11]\u2013[14] have specifically two main limitations: (i) they are based on supervised learning which limits their effectiveness against unseen and zero-day attacks, and (ii) they assume that FL clients have labeled datasets, which in practice might be unrealistic. Considering these gaps, we propose a novel network-based IDS trained using a deep auto-encoder model. Relying only on benign network traffic, our system can detect unseen or zero-day attacks so long as they alter the benign communication pattern of the CAV. Additionally, our solution does not compromise the CAV's privacy since it is built through federated learning."}, {"title": "III. PROPOSED SOLUTION", "content": "Collaborative learning allows training the model with a large amount of network traffic from diverse CAVs, while preserving data privacy, and minimizing the communication overhead. The proposed MEC-enabled learning scheme trains the deep Auto-Encoder (AE) model in a federated way, as illustrated in Figure 1. First, the raw captured packets are converted to flows. Then, for each flow, a set of pertinent features are calculated. Next, the local dataset of flows is fed to the AE model initially distributed by the MEC server. The training rounds are orchestrated by the MEC server and executed by the AE on the participating CAV's local dataset.\nFirst, to identify a traffic flow, we use a combination of five properties from the packet header, including the network and the transport layer headers of the TCP/IP protocol stack. These are as follows: source IP address, destination IP address, source port number, destination port number, and protocol. For each flow extracted, a set of features are calculated according to a given time window (ex. 100 seconds). Flow features include mainly packet header characteristics and statistics computed from the aggregating network and transport layers header information of the packets in a flow. The network features are related to: time, packets, bytes, and flag groups.\nThe Auto-Encoder (AE) model [15] is an unsupervised model that compresses input vectors as code vectors using a set of recognition weights and then converts back to m (m < d) number of neurons reconstructed input vectors using a set of generative weights. There are two major parts in an AE architecture: the encoder and the decoder. The encoder reduces the dimension of the input vectors (xi \u2208 Rd) to numbers of neurons that form the hidden layer. The activation of the neuron i in the hidden layer is given by:\n$$h_i = f(x) = s(\\sum_{j=1}^{n} w_{ij}^{input}.x_j + b_i^{input})$$\nwhere X is the input vector, \u03b8 is the parameters {Winput, binput}, W is an encoder weight matrix of dimension m \u00d7 d, while b is a bias vector of dimension m. Thus, the input vector is encoded to a vector with fewer dimensions. The decoder maps the low-dimensional hidden representation hi to the original input space Rd by the same transformation as the encoder. The function of mapping is as follows:\n$$x = 9_{\\theta'} (h) = (W_{hidden}h_j + b_i^{hidden})$$\nThe set of decoder parameters is \u03b8'(Whiddenhj + bhidden). The objective of an autoencoder is to minimize the reconstruction error relative to @ and 0' :\n$${{\\theta }^*},{{\\theta '}^*} = \\underset{\\theta ,{{\\theta '}}}{\\arg \\min } \\sum_{i=1}^{n} \\varepsilon (x_i, 9_{\\theta '} (f_{\\theta } (x_i)))$$"}, {"title": "IV. PERFORMANCE EVALUATION", "content": "In this section, we first briefly describe the dataset [17] used in this research. Then, we present and discuss in detail the detection performances of the proposed system. Finally, we compare our approach with supervised and centralized approaches.\nTo the best of our knowledge, VDoS [17] is the only publicly available dataset that includes benign and malicious traffic generated based on a realistic testbed. The network traffic was gathered in three different settings: urban, rural, and highway. The experimental environment included two vehicles, 3 physical machines, 4 virtual machines, 2 access points, a 4G modem, and two Cisco antennas. Common user applications such as Google Maps, YouTube, social networks, and other real-time applications (video/audio calls) have been run to generate benign network traffic. To generate malicious traffic, three Kali-Linux machines run three scenarios of DoS attack: UDP Flood, SYN Flood, and Slowloris packets alter-nately. In this research, we do not consider the third scenario, because we believe it is quite unusual that a CAV may hosts a web server. For further details about the testbed and the dataset generation please refer to [17].\nTo extract flows and calculate features from raw traffic (PCAP files), we developed some scripts using Tranalyzer flow traffic exporter [18]. We tried several time windows"}, {"title": "V. CONCLUSION", "content": "New attack vectors have emerged from the integration of V2X communication in the 5G ecosystem, which may lead to hazardous situations for road users. Most of the existing IDSs in 5G-V2X are either unable to detect emerging zero-day attacks because they rely on supervised learning, or do not meet privacy requirements due to data collection required for centralized learning. To tackle these limits, we proposed in this paper a new IDS based on a deep auto-encoder model, which leverages the predictability of benign network traffic to detect attacks. Relying on federated training orchestrated by the MEC server, the proposed IDS did not require any data collection or labeling. Through in-depth experiments on a recent dataset, we have shown that the proposed IDS provides high performance even with few communication rounds and a short TW sampling, which allows fast training and low detection delay. In future work, we plan to evaluate the proposed IDS on other non-Identical Independent Distribution (non-IID) datasets including more sophisticated and recent attacks."}]}