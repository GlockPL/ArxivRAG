{"title": "Unified Gradient-Based Machine Unlearning with Remain Geometry Enhancement", "authors": ["Zhehao Huang", "Xinwen Cheng", "JingHao Zheng", "Haoran Wang", "Zhengbao He", "Tao Li", "Xiaolin Huang"], "abstract": "Machine unlearning (MU) has emerged to enhance the privacy and trustworthiness\nof deep neural networks. Approximate MU is a practical method for large-scale\nmodels. Our investigation into approximate MU starts with identifying the steepest\ndescent direction, minimizing the output Kullback-Leibler divergence to exact MU\ninside a parameters' neighborhood. This probed direction decomposes into three\ncomponents: weighted forgetting gradient ascent, fine-tuning retaining gradient\ndescent, and a weight saliency matrix. Such decomposition derived from Euclidean\nmetric encompasses most existing gradient-based MU methods. Nevertheless,\nadhering to Euclidean space may result in sub-optimal iterative trajectories due\nto the overlooked geometric structure of the output probability space. We suggest\nembedding the unlearning update into a manifold rendered by the remaining geom-\netry, incorporating second-order Hessian from the remaining data. It helps prevent\neffective unlearning from interfering with the retained performance. However, com-\nputing the second-order Hessian for large-scale models is intractable. To efficiently\nleverage the benefits of Hessian modulation, we propose a fast-slow parameter up-\ndate strategy to implicitly approximate the up-to-date salient unlearning direction.\nFree from specific modal constraints, our approach is adaptable across computer\nvision unlearning tasks, including classification and generation. Extensive ex-\nperiments validate our efficacy and efficiency. Notably, our method successfully\nperforms class-forgetting on ImageNet using DiT and forgets a class on CIFAR-10\nusing DDPM in just 50 steps, compared to thousands of steps required by previous\nmethods. Code is available at Unified-Unlearning-w-Remain-Geometry.", "sections": [{"title": "Introduction", "content": "Machine Unlearning (MU) [1-3] aims to remove the influence of samples from a pre-trained model,\nensuring the model behaves as if it has never encountered those samples. The significance of\nMU research has grown following data protection regulations [4, 5]. It has rapidly developed\nin recent years, becoming an important means to help pre-trained large-scale models adapt to\nvarious trustworthy challenges [6] in computer vision (CV). In general, MU aids in purging outdated\nknowledge [7, 8], mitigating biases [9, 10], and preventing large text-to-image models from generating\nnot-safe-for-work (NSFW) images [11-14].\nExisting MU methods are mainly divided into two categories: exact (or certified) MU [15] and\napproximate MU [16]. For deep neural networks, achieving exact MU necessitates retraining on a\ndataset excluding forgetting samples. However, retraining is computationally prohibitive for recent\nlarge-scale deep networks. Thus, in MU for deep networks, this retrained model only serves as an\naspirational standard to be approached [17]. We primarily focus on more efficient approximate MU.\nApproximate MU strives to align the output distribution of unlearned models with that of retrained\nmodels. We initially explore the vanilla gradient descent of minimizing the output Kullback-Leibler"}, {"title": "Preliminary", "content": "Problem Setup. MU aims to help a well-trained model eliminate the influence of specific data points,\ncategories, or high-level concepts and patterns [1, 38]. Let $\\mathcal{D} = \\{z_i\\}_{i=1}^{N}$ represent a pretraining\ndataset of N data points, including $z_i = (x_i, y_i)$ features and labels in supervised learning. The\nforgetting dataset, $\\mathcal{D}_f = \\{z_i\\}_{i=1}^{N_f} \\subset \\mathcal{D}$, is a subset of the pretrained dataset. Its complement,\n$\\mathcal{D}_r = \\{z_i\\}_{i=1}^{N_r} = \\mathcal{D} \\setminus \\mathcal{D}_f$, is the remaining dataset that we wish to retain. The learner is a model\nparameterized by $\\theta$. $p_z(\\theta) = p(z; \\theta)$ represents the model output probability. The pre-trained model"}, {"title": "Approximate MU from Perspective of Steepest Descent", "content": "Revisit Approximate MU Methods via Vanilla Gradient Descent. We begin with the vanilla\ngradient descent direction to address approximate MU. This involves finding the steepest descent\ndirection that minimizes the KL divergence with the retrained output within the vicinity of the current\nmodel $\\theta_t$. The optimization problem can be formalized as follows:\n\n$\\theta_{t+1} = \\underset{\\theta_{t+1}}{\\text{arg min}} D_{KL} (p_z(\\theta^*)||p_z (\\theta_{t+1})) + \\frac{1}{A_t}\\rho(\\theta_t, \\theta_{t+1})$ (2)\n\n$\\underset{\\theta_{t+1}}{\\text{arg min}} D_{KL} (p_{z_f}(\\theta^*)||p_{z_f} (\\theta_{t+1})) p^f + D_{KL} (p_{z_r}(\\theta^*)||p_{z_r} (\\theta_{t+1})) p^r + \\frac{1}{A_t}\\rho(\\theta_t, \\theta_{t+1})$\n\n\nwhere $p^f = p(\\mathcal{D}_f|\\mathcal{D})$ and $p^r = p(\\mathcal{D}_r|\\mathcal{D}) = 1 - p^f$ denote the partition of forgetting and remaining\ndataset, respectively. Analyzing (2), (a) seeks to eliminate the influence of the target forgetting"}, {"title": "Proposed Method", "content": "Implicit Online Hessian Approximation (R-on). Given that computing the inverse of even well-\napproximated Hessian demands substantial computational resources, it is more practical to estimate\nthe unlearning direction post-Hessian inversion modulation directly. Inspired by recent insights into\nthe connection between Meta-Continual Learning and Hessian approximation [50], we propose a\nfast-slow weight [36, 37] method for implicitly approximating the desired updates. The optimization\nproblem for fast weight updates is formulated as follows:\n\n$\\underset{\\theta_f}{\\text{min}} L_u (\\theta_f) \\text{ s.t. } \\theta_t^* = \\theta_t - \\beta_t\\nabla L^r (\\theta_t^*)$, (5)\n\nwhere $L_u$ represents an arbitrary forgetting loss and $\\beta_t$ is its learning rate. The iterative process is\ndepicted in Fig. 1. A step of forgetting is taken at the current model, resulting in $\\theta_f$. Several gradient\ndescent updates on the remaining set follow to obtain the minimum point $\\theta_t^*$. This fine-tuning ensures\nthat the updated model adheres to the remain-preserving manifold. The slow weight updates leverage\nthe underlying connection between $\\theta_t^*$ and $\\theta_t$, as stated in Prop. 3.\n\nProposition 3. For implicit online Hessian approximation in (5), suppose $\\beta_t, \\delta_t$ is small, $\\beta_t <\n\\sqrt{\\delta_t/|\\nabla L^r (\\theta_t^*) - [\\nabla L^r(\\theta_t^*)]^2|}$, $L^r$ is $\\mu$-smooth, i.e., $||\\nabla L^r (\\theta) - \\nabla L^r (\\theta')||_2 \\leq \\mu||\\theta - \\theta' ||_2$, and\nthere exist an $\\zeta_t$-neighborhood $\\mathcal{N}(\\theta, \\zeta_t)$ of the optimal model parameter $\\theta_t^* = \\underset{\\theta_f}{\\text{arg min}} L_u (\\theta_f)$,\nwhich includes $\\theta_t^*$ and $\\theta_t$. Then, the iterative update term approximately is,\n\n$\\theta_t^* - \\theta_t \\approx \\beta_t^2 [\\nabla^2 L^r (\\theta_t^*)]^{-1} \\nabla L^r (\\theta_t^*)= \\beta_t^2(H_t^r)^{-1}\\nabla L^r(\\theta_t^*)$ (6)\n\nThe proof is in Appendix A.4. Prop. 3 indicates that the model $\\theta_t^*$, obtained after fine-tuning using\nthe process described in (5), is approximately equivalent to updating the current model $\\theta_t$ by one step\nin the Hessian-adjusted unlearning direction. We use this direction to update the outer loop.\nComparison with the joint loss (R). We investigate the differences in the updates between our\noptimization in (5) (R-on) and the joint optimization of forgetting and remaining losses (R) [23, 25].\nWe take the checkpoint after the first step of fine-tuning the remaining set as an example and ignore\nthe step size.\n\n$L^R(\\theta_t) = L_u(\\theta_t) + L^r (\\theta_t), \\nabla R = \\nabla L^u(\\theta_t^*) + \\nabla L^r (\\theta_t^*)$, (7)\n\n$\\triangle R^{\\text{-on}} \\approx \\nabla L^u (\\theta_t^*) + \\nabla L^r (\\theta_t^*) + \\nabla^2 L_r (\\theta_t)(\\theta_t^* - \\theta_t) = (I - H_t^r)\\nabla L^u(\\theta_t^*) + \\nabla L^r (\\theta_t^*)$, (8)\n\nComparison of the updates in (7) and (8) reveals that the remaining gradient is the same. Our forgetting\nupdate in fast weight is adjusted by an additional term $-H_t^r$, which is absent in joint optimization.\nThis modification weakens the directions that significantly impact the remain, thereby mitigating the\ndamage of forgetting loss on the retained performance. Furthermore, certain methods [24] suggest\ntwo-stage unlearning that first impairs the model and then repairs it, actually paralleling a single\nfast-slow weight update of our method."}, {"title": "Experiments", "content": "Datasets, Models, and Settings. In image classification, we primarily focus on the random subset\nunlearning task. Evaluations are conducted using ResNet-18 [52] on CIFAR10 [53] and Swin-\nT [54] on TinyImageNet [55], with additional tests on random subset and class-wise forgetting\ntasks involving CIFAR100 [53] and SVHN [56], detailed in Appendix F.2. In image generation,\nour main interest lies in class-wise forgetting tasks. Following [35, 26], we unlearn conditional\nDDPM [40] with the UNet architecture [57] on CIFAR10. Moreover, for the first time, we explore\nthe latent diffusion model [42] equipped with Diffusion Transformer (DiT) [58] on ImageNet [59],\nwhich demonstrates superior scalability in learning large-scale data generation tasks. Finally, we\nperform concept forgetting tasks using the open-source Stable Diffusion (SD) V1.4 [42] to inhibit\nthe generation of NSFW content, specifically by targeting the prevention of nude images. Further\ndetails on unlearning setups and training are available in Appendix E.\nBaselines and Evaluation. We regard RT as an oracle of approximate MU and compare our proposal\nwith eight MU methods, including six gradient-based MU approaches outlined in Sec. 3: FT [19],\nGA [21], BT [23], RL [20], SalUn [26], and SA [35]. We also consider SCRUB [25], an enhanced\nvariant of BT, for image classification, and ESD [11] for removing concepts in SD. For the evaluation\nof random subset unlearning tasks, we measure the output KL divergence $D_{KL}$ between the unlearned\nand retrained models, which is the direct target of approximate MU. Besides, we assess the accuracy\non the forgetting set (FA) for unlearning efficacy, and the accuracy on the remaining (RA) and test\n(TA) sets for preserved generalization ability. We also consider the success rate of membership\ninference attack (MIA) [60, 38] on the forgetting set as a privacy metric. Note that the smaller the\ndisparity in these metrics against RT, the more effective the unlearning. Run-time efficiency (RTE) is\nalso reported. For class-wise forgetting tasks in image generation, we evaluate the accuracy of the\nunlearned model's generated images on forgetting classes (FA) by a pre-trained classifier. The Fr\u00e9chet\nInception Distance (FID) [61] metric assesses the retained generative capability for remaining classes.\nFor ablating the 'nudity' concept in SD, we employ the NudeNet [62] detector to identify and count\nnude body parts in generated NSFW images. For further introduction to the baselines and detailed\nevaluation metrics, please refer to Appendix E.1 and D.\nTo assess the unlearning effectiveness and efficiency of SFR-on, we perform comprehensive experi-\nments and conduct ablation studies to address the following four key questions:\nQ1: How does SFR-on perform on unlearning in image classification? We first evaluate the\nperformance of our method, SFR-on, against existing gradient-based MU methods on the image\nclassification random subset unlearning task. In this scenario, the forgetting set, remaining, and test\nsets all originate from the same distribution. Consequently, even if the model undergoes unlearning\non the random subset, it may still generalize to these samples. To avoid potential biases from only\nusing FA as an unlearning metric, we incorporate MIA to assess the privacy retention of the forgetting\nset, enhancing the robustness of assessments. As detailed in Tab. 2, for forgetting 10% random subset\non CIFAR-10 and TinyImageNet, SFR-on not only most closely aligns with RT in the averaging\nmetric disparity but also exhibits the smallest output KL divergences w.r.t. RT. This performance\nunderscores our effectiveness and efficiency in achieving the objective of approximate MU. The\nresults of the increased 50% random subset unlearning task are included in Appendix F.2."}, {"title": "Conclusion", "content": "This paper revisits gradient-based approximate MU methods from the perspective of the steepest\ndescent. The descent direction under an Euclidean manifold metric can be divided into three\nintegral components: weighted forgetting gradient ascent, fine-tuning remaining gradient descent,\nand weight saliency matrix. Our approach advances beyond the Euclidean constraints by embedding\nthe unlearning update within a remain-preserving manifold. This novel strategy incorporates the\nsecond-order Hessian of the current model on remaining, safeguarding against detrimental impacts\non retained performance. To circumvent the prohibitive computational demands of the Hessian in\nlarge-scale models, we introduce an efficient fast-slow weight update method to approximate the\nHessian-adjusted direction. Furthermore, our innovative adaptive coefficient for weight forgetting\nloss and a forget-remain balanced weight saliency map facilitate near-retraining unlearning. Our\nmethod can be applied to popular CV unlearning tasks with empirically verified unlearning efficacy."}, {"title": "Appendix", "content": "A Detailed Proof\nA.1 Proof of Equation (1)\nProof. We form the following optimization problem for the steepest descent of approximate MU,\nwhich is to find the direction $\\delta \\theta = \\theta_{t+1} - \\theta_t$ that drives the objective function $F(\\theta)$ descent fastest\nwithin a $\\xi$-neighborhood of the current parameters $\\theta_t$, and the $\\xi$-neighborhood is rendered by the\nmanifold metric $\\rho(\\cdot,\\cdot)$:\n\n$\\delta \\theta = \\underset{\\delta \\theta}{\\text{arg min}} F(\\theta_t + \\delta \\theta) \\text{ s.t. } \\rho(\\theta_t, \\theta_t + \\delta \\theta) \\leq \\xi$. (A1)\n\nWe introduce a Lagrange multiplier $\\eta \\geq 0$ to construct the Lagrangian $\\mathcal{L}$ for this optimization\nproblem:\n\n$\\mathcal{L}(\\delta \\theta, \\eta) = F(\\theta_t + \\delta \\theta) + \\eta(\\rho(\\theta_t, \\theta_t + \\delta \\theta) - \\xi)$. (A2)\n\nUsing the Karush-Kuhn-Tucker (KKT) theorem, we can take the derivative of $\\mathcal{L}$ w.r.t. $\\delta \\theta$ and set it\nto zero:\n\n$\\nabla_{\\delta \\theta}\\mathcal{L}(\\delta \\theta, \\eta) = \\nabla_{\\delta \\theta}F(\\theta_t + \\delta \\theta) + \\eta\\nabla_{\\delta \\theta}\\rho(\\theta_t, \\theta_t + \\delta \\theta) = 0$, (A3)\n\nwhere $\\eta$ depends on $\\xi$ and $\\theta_t$ implicitly. We can rewrite (A3) by variable substitution $\\theta_{t+1} = \\theta_t + \\delta \\theta$\nand $\\eta = 1/\\alpha_t (\\xi, \\theta_t)$.\n\n$\\nabla_{\\theta_{t+1}}\\mathcal{L}(\\theta_{t+1}, \\eta) = \\nabla_{\\theta_{t+1}}F(\\theta_{t+1}) + \\frac{1}{\\alpha_t (\\xi, \\theta_t)}\\nabla_{\\theta_{t+1}}\\rho(\\theta_t, \\theta_{t+1}) = 0$. (A4)\n\nThus, the original problem is transformed into an unconstrained optimization problem w.r.t. $\\theta_{t+1}$,\nwhere the neighborhood size is implicitly given by $\\alpha_t$:\n\n$\\theta_{t+1} = \\underset{\\theta_{t+1}}{\\text{arg min}} F(\\theta_{t+1}) + \\frac{1}{\\alpha_t(\\xi, \\theta_t)} \\rho(\\theta_t, \\theta_{t+1})$. (A5)\n\nA.2 Proof of Proposition 1\nThe optimization problem of Prop. 1 is to find the steepest descent direction that minimizes the KL\ndivergence with the retrained output within the vicinity of the current model $\\theta$:\n\n$\\theta_{t+1} = \\underset{\\theta_{t+1}}{\\text{arg min}} D_{KL} (p_z(\\theta^*)||p_z (\\theta_{t+1})) + \\frac{1}{A_t}\\rho(\\theta_t, \\theta_{t+1})$ (A6)\n\n$\\underset{\\theta_{t+1}}{\\text{arg min}} D_{KL} (p_{z_f}(\\theta^*)||p_{z_f} (\\theta_{t+1})) p^f + D_{KL} (p_{z_r}(\\theta^*)||p_{z_r} (\\theta_{t+1})) p^r + \\frac{1}{A_t}\\rho(\\theta_t, \\theta_{t+1})$\n\n\nProposition 1. Under the Euclidean manifold metric, $\\rho(\\theta_t, \\theta_{t+1}) = \\frac{1}{2}||\\theta_t - \\theta_{t+1}||^2$. Assuming\nthat the current model $\\theta_t = \\underset{\\theta}{\\text{arg min}} \\mathcal{L}^r (\\theta) + \\mathcal{L}^f(\\theta;\\epsilon_t)$. Let $H_t^f = \\nabla^2\\mathcal{L}^f (\\theta^*;1)$ and $H_t^r =\n\\nabla^2\\mathcal{L}^r (\\theta^*)$ denote the Hessian matrix of the retrained model on the forgetting set and the remaining\nset, respectively. Then, the direction of the steepest gradient descent that minimizes the KL divergence\nbetween the output of the current model and the retrained model is approximately:\n\n$\\theta_{t+1} - \\theta_t \\approx -a_t[H_t^f (H_t^r)^{-1}[-\\nabla \\mathcal{L}^f (\\theta_t; \\epsilon_t)]p^f + \\nabla \\mathcal{L}^r (\\theta_t)p^r]$ (A7)"}]}