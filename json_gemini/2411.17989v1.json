{"title": "Regularized Multi-LLMs Collaboration for Enhanced Score-based Causal Discovery", "authors": ["Xiaoxuan Li", "Yao Liu", "Ruoyu Wang", "Lina Yao"], "abstract": "As the significance of understanding the cause-and-effect relationships among variables increases in the development of modern systems and algorithms, learning causality from observational data has become a preferred and efficient approach over conducting randomized control trials. However, purely observational data could be insufficient to reconstruct the true causal graph. Consequently, many researchers tried to utilise some form of prior knowledge to improve causal discovery process. In this context, the impressive capabilities of large language models (LLMs) have emerged as a promising alternative to the costly acquisition of prior expert knowledge. In this work, we further explore the potential of using LLMs to enhance causal discovery approaches, particularly focusing on score-based methods, and we propose a general framework to utilise the capacity of not only one but multiple LLMs to augment the discovery process.", "sections": [{"title": "1 Introduction", "content": "Causal discovery endeavours to uncover the cause-and-effect relationships among variables, revealing how changes in one can influence others [12]. Understanding causality becomes increasingly important in many fields, such as economics[12] and biology[14]. While conducting randomized control trials (RCTs) is the golden rule for testing causality, the execution of RCTs can be prohibitively costly, time-consuming, and ethically problematic in various domains. To avoid these inevitable problems, researchers seek to reconstruct causal relationships only relying on observational data without using RCTs. However, learning causality from observational data makes it difficult to distinguish the correct causal graph from a set of similar distributions[15]. Consequently, one popular research direction is to use some other supplementary information to augment or guide the"}, {"title": "2 Related Works", "content": "Causal Discovery Methods for causal structure learning typically fall into two categories: constraint-based methods and score-based methods. The constraint-based methods reconstruct the causal graph by examining the properties of conditional independencies, such as PC[13] and FCI[16] algorithm; the score-based methods evaluate various estimated causal graphs by a predefined score function such as Bayesian Information Criterion(BIC)[4] and BDe(u) [8], seeking to find the graph that minimises the objective score and satisfies the acyclicity constraint[1,3,6,20]. A prominent score-based algorithm is Greedy Equivalence Search(GES) [3] which utilises a greedy method to guide the search process. However, score-based methods encounter scalability problems due to the super-exponential growth of the search space with respect to the number of nodes. NOTEARS[20] firstly introduced a smooth characterization for the acyclicity hence converting the combinatorial optimization problem to a continuous optimization problem, enabling the utilization of existing numerical and gradient-based methods for solving the problem.\nCausal Discovery with Prior Knowledge Numerous researchers have tried to leverage the benefit of prior knowledge. Wang et al. [17] studied a specific problem with Type II diabetes and proposed a PKCL algorithm. Hasan and Gani [6] introduced a framework called KCRL to leverage prior knowledge into the reinforcement learning causal discovery method proposed by Zhu et al. [21]. Hasan and Gani [7] leveraged prior knowledge within the context of GES and introduced a novel method termed KGS. Chowdhury et al. [5] integrated experts' knowledge into NOTEARS[20] as some additional constraints.\nCausal Discovery with LLMs The emergence of LLMs also gives a potential direction for improving causal discovery methods. Ban et al. [2] introduced an innovative framework to integrate knowledge-based LLM with data-driven causal structure learning. Long et al. [11] studied the capacity of LLMs to build causal graphs and discussed their potential to complement causal graph development. Long et al. [10] treat the LLMs as an imperfect expert and incorporate this imperfect knowledge into current causal discovery mechanisms."}, {"title": "3 Methodology", "content": "In this section, we first define the causal discovery task. Then, we elaborate on our framework, including the acquisition of LLMs, and the combination and imposition of LLM-derived information into the existing score function as an additional penalty term. Furthermore, we illustrate two examples demonstrating the integration of the penalty term into specific algorithms, GES and NOTEARS."}, {"title": "3.1 Problem Definition", "content": "The causal structure learning problem is defined as the following: Given the observational dataset $X \\in \\mathbb{R}^{n \\times d}$, consisting of $n$ data and each data contains $d$ features. The task of causal discovery is to learn a Directed Acyclic Graph (DAG) G(V, E) where each node $v \\in V$ corresponding to a feature and the presence of an edge $e = (i, j) \\in E$ indicates that feature $x_i$ is a direct cause of feature $x_j$. To retrieve the true causal relation, the distribution of the dataset P(X) needs to be Markov to the graph G we learnt, which means $p(x) = \\prod_{i=1}^{d} P_i(x_i | pa(x_i))$ where $pa(x_i)$ represents the parent set of $x_i$ in the graph G.\nThe Score-based methods formulate the problem as a combinatorial optimization problem: Given a DAG G and a score function S, the score of the graph S(G, X) indicates how good the graph is corresponding to the data X (normally lower the better). Hence, the problem becomes an optimization problem:\n$\\min_G S(G, X)$\nsubject to $G\\in DAGS$\nOur framework seeks to integrate the knowledge derived from LLMs' knowledge into the learning process of any score-based causal discovery methods, as shown in Figure 2. This process involves two primary stages: Initially, we interact with multiple LLMs to inquire about the dataset and establish causal relationships by combining the information from different LLMs; after getting the result, we incorporate the findings from LLMs into our causal discovery scoring function by introducing an additional penalty term."}, {"title": "3.2 Querying the LLMs", "content": "Initially, information retrieval is conducted through querying the LLMs. To make the information useful and more reliable, we need to carefully design our prompt"}, {"title": "3.3 Imposing Multi-LLMs' Collective Knowledge", "content": "After the initial stage, the outcomes yielded by LLMs are obtained. However, note that these results are not infallible, and different LLMs would produce results of various quality. We proposed a framework designed to integrate diverse outcomes from multiple LLMs and impose any score-based method.\nFor any score-based approach, the fundamental objective is to find a DAG G that optimises the score across all feasible graphs. Based on any existing score function $S_{score}(G)$, we introduce an additional penalty term to encapsulate the disparity between the graph and the outcomes produced by LLMs with a hyper-parameter $\\lambda$ to reflect our degree of confidence in the LLM outcomes. The augmented score function is:\n$S(G) = S_{score}(G) + \\lambda \\times P(G)$\nTo compute the penalty term, we primarily explore two methods: $l_1$-penalty and $l_2$-penalty to suit different score-based methodologies and scenarios. Let $M$ be the adjacency matrix corresponding to the estimated graph Goutputted by the original score-based method, and $M_{LLM}$ be the adjacency matrix corresponds to the predicted graph $G_{LLM}$ generated by our LLMs from the first stage. The $l_1$-penalty quantifies the absolute difference between the estimated graph and the LLM results, i.e. $||M \u2013 M_{LLM}||$, this is equivalent to assessing the discrepancy between the estimated graph and the LLM outcomes. The $l_2$-penalty computes the squared difference between the estimated graph and the LLM results, represented as $||M - M_{LLM}||^2$.\nAs we employ multiple LLMs, we initially assess the quality of each LLM result using the identical score function and dataset to get a score denoted as $S_{score}(G_{LLM})$ for each LLM. Subsequently, we normalize them to ensure their summation equals one, obtaining a weight $\\mu$ for each LLM model. Therefore, the penalty term is:\n$P_{l_1}(G) = \\sum_{for\\ each\\ model} \\mu_{model} \\times ||M - M_{model}||\n$P_{l_2}(G) = \\sum_{for\\ each\\ model} \\mu_{model} \\times ||M - M_{model}||^2$"}, {"title": "4 Experiments", "content": "In this section, We evaluate the efficacy of our framework through experimentation across various datasets and compare the results generated by several score-based methods with those from the same methods enhanced by our LLM framework."}, {"title": "4.1 Datasets and Evaluation Metrics", "content": "To ensure the comprehensiveness of our experimental evaluation, we employed a diverse set of benchmark datasets, such as LUCAS, Asia, Earthquake, Child and SACHS, including both synthetic and real-world data.\nWe mainly assess our framework on three evaluation metrics: False Discovery Rate (FDR) which calculates the proportion of estimated edges that are false, with lower values indicating better performance; True Positive Rate (TPR) which measures the likelihood of correctly identifying true edges within the estimated graph, with higher values indicating better performance;\n$fdr = number\\ of\\ wrong\\ edges\\ discovered\\ /\\ number\\ of\\ total\\ edges\\ discovered$\n$tpr = number\\ of\\ correct\\ edges\\ discovered\\ /\\ number\\ of\\ total\\ correct\\ edges$\nAnd Structural Hamming Distance (SHD) which quantifies the number of edge insertions, deletions, or flips necessary to transform the estimated graph into the true causal graph, with lower values indicating better performance."}, {"title": "4.2 Results", "content": "We delve into the experiments conducted and the resultant findings. For the LLMs, we utilized GPT-3.5, GPT-4, and Gemini to gather information about each dataset.\nCase Study We analyze the efficacy of the information provided by each LLM on three datasets-LUCAS, Asia and SACHS. We queried GPT-3.5, GPT-4, and Gemini regarding the three datasets, and obtained the results, depicted in Figure 3 where black edges indicate correct predictions and red edges indicate incorrect predictions.\nFor the LUCAS dataset, Gemini yielded the most favourable outcome, correctly predicting all 5 edges. GPT-4 predicted 4 edges accurately but also generated 2 incorrect edges. Conversely, GPT-3.5 exhibited the poorest performance, predicting 5 correct edges but with 4 incorrect ones. Additionally, it is evident from the figure that while Gemini achieved the highest accuracy, both GPT-4 and GPT-3.5 still managed to predict some correct edges not identified by Gemini.\nIn the case of the Asia dataset, the results reveal that GPT-4 accurately predicted all 8 edges without generating any incorrect edges. This emphasises the remarkable capability of LLMs in causality discovery tasks. Contrastingly, GPT-3.5 predicted 5 correct edges but with 3 incorrect edges, while Gemini"}, {"title": "4.3 Discussion", "content": "Throughout the experiments, we encountered challenges due to the quality of LLM results, which significantly limited the effectiveness of our approach. Despite incorporating a weight parameter to signify our confidence in the LLM results, tuning this parameter remains a complex task. Additionally, our current approach employs a weighted sum to combine information of varying quality, yet exploring more sophisticated methods for integrating this information could yield superior results, thereby enhancing the performance of original score-based methods further. Moreover, the incorporation of additional information into existing score functions warrants further investigation. Given the non-convex nature of the problem, conventional score-based methods often encounter challenges in escaping local minima. Designing improved score functions holds the potential to guide algorithms away from local minima towards global optimal solutions."}, {"title": "5 Conclusion", "content": "In this study, we introduce a novel framework aimed at integrating the capabilities of multiple LLMs into the score-based causal discovery methodology. In contrast to conventional methods guided by prior knowledge, our approach circumvents the need for potentially costly acquisition of expert knowledge or randomized control trials by leveraging the capacity of LLMs. We incorporate LLM information as an additional penalty term into existing score functions, thereby prompting the original methodology to account for this supplementary information. Through a series of diverse experiments, we demonstrate the efficacy of our framework in enhancing existing score-based algorithms."}]}