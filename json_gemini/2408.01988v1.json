{"title": "MetaWearS: A Shortcut in Wearable Systems Lifecycle with Only a Few Shots", "authors": ["Alireza Amirshahi", "Maedeh H. Toosi", "Siamak Mohammadi", "Stefano Albini", "Pasquale Davide Schiavone", "Giovanni Ansaloni", "Amir Aminifar", "David Atienza"], "abstract": "Wearable systems provide continuous health monitoring and can lead to early detection of potential health issues. However, the lifecycle of wearable systems faces several challenges. First, effective model training for new wearable devices requires substantial labeled data from various subjects collected directly by the wearable. Second, subsequent model updates require further extensive labeled data for retraining. Finally, frequent model updating on the wearable device can decrease the battery life in long-term data monitoring. Addressing these challenges, in this paper, we propose MetaWearS, a meta-learning method to reduce the amount of initial data collection required. Moreover, our approach incorporates a prototypical updating mechanism, simplifying the update process by modifying the class prototype rather than retraining the entire model. We explore the performance of MetaWearS in two case studies, namely, the detection of epileptic seizures and the detection of atrial fibrillation. We show that by fine-tuning with just a few samples, we achieve 70% and 82% AUC for the detection of epileptic seizures and the detection of atrial fibrillation, respectively. Compared to a conventional approach, our proposed method performs better with up to 45% AUC. Furthermore, updating the model with only 16 minutes of additional labeled data increases the AUC by up to 5.3%. Finally, MetaWearS reduces the energy consumption for model updates by 456x and 418x for epileptic seizure and AF detection, respectively.", "sections": [{"title": "1 Introduction", "content": "Advancements in biomedical signal monitoring tech- niques have contributed significantly to the early diagno- sis and treatment of various medical conditions. Immedi- ate and accurate detection of these conditions can guide appropriate medical interventions, thereby improving patient care[1, 2]. Wearable systems are increasingly being used to mon- itor health conditions and provide real-time data on vari- ous physiological parameters. Wearable devices, such as smartwatches, fitness trackers, and specialized medical wearables, can track and record data related to heart rate, blood pressure, sleep patterns, physical activity, etc. [3- 5]. Deep learning has demonstrated significant advances in a variety of biomedical applications. However, imple- menting these advances into practical wearable systems often faces numerous challenges. These challenges span the entire lifecycle of a wearable device, from its data collection phase to its utilization by end-users. Fig. 1a shows the definition of a wearable system lifecycle and its challenges. The first challenge, shown in Fig. 1a with 1, is the requirement for substantial biomedical labeled data to train deep learning models. Data collection is a costly and time-consuming process [6]. This issue is further exacerbated in wearable systems by the fact that the data beneficial to the model training should ideally be collected from identical devices [7-10]. The next challenge for deep learning deployment in wearable systems is the data requirement for the updating process, shown by \u2461 in Fig. 1a. In this phase, data should ideally be collected from a large number of new participants to have enough data to retrain the model. Otherwise, with a limited number of data, the model can suffer from an overfitting problem, where it becomes too fit to the new training data and performs poorly on unseen data[11, 12]. Finally, once new signals are obtained and the model is updated, the updated model should be sent back and re- placed on the wearable system. However, deep learning models are typically large. When models are transmit- ted and read by processors from a wireless network, modeling transmission can be quite time-consuming and energy-intensive[13]. This significantly impacts battery life, a critical factor for wearable devices. As depicted in Fig. 1a by 3, the third challenge is a high energy consumption for frequent model updates.\nIn our paper, we introduce MetaWearS, a novel Meta- learning method for Wearable Systems that addresses the critical challenges of data scarcity and resource effi- ciency. Remarkably, as shown in Fig. 1b, our approach reduces the data required for the initial training of the model (1) and for the update process (\u2461). This is achieved through a targeted modification of the few-shot learning strategy specifically designed to address the aforementioned challenges.\nFurthermore, our method incorporates an energy- efficient updating mechanism, and instead of retraining and transmitting the entire model, we update only a sin- gle vector, called prototype. In line with the principles of prototypical networks [14], the prototype size is con- siderably smaller than the model weight. Therefore, the processor consumes less time and energy to receive the prototypes instead of receiving the whole model (3). This can significantly increase the battery life time.\nTo evaluate MetaWearS, Epilepsy and Atrial Fibrilla- tion (AF) arrhythmia, two distinct but critical biomedical conditions, are chosen as two case studies based on Elec- troencephalogram (EEG) and Electrocardiogram (ECG), respectively, as two different types of biomedical sig- nals. Moreover, we use two types of deep learning models for our study: MobileNetV2 [15] and Vision- Transformer [16]. This not only highlights the generality and adaptability of our approach, but also emphasizes its potential to surpass the limitations of traditional single- domain evaluations in biomedical signals.\nThis paper presents four key contributions in the application-based wearable system design for biomedi- cal abnormalities monitoring as follows:\n\u2022 Our work introduces MetaWears as a few-shot learning strategy specifically designed for the effec- tive detection of abnormalities in biomedical sig- nals, particularly in scenarios where initial labeled data is scarce.\n\u2022 The proposed MetaWearS can update the mod- els with minimal additional labeled data when end users are actively using the wearable system. This demonstrates the practical advantages of our methodology in reducing the data requirement.\n\u2022 We propose an update process that involves modi- fying only the prototypes without necessitating re- training and replacing the entire model. This update protocol significantly improves battery life.\n\u2022 To assess the generalization capabilities of MetaWearS in the context of few-shot learning, we carried out comprehensive experiments on two sep- arate case studies with two types of biomedical signals: AF arrhythmia detection using ECG and epileptic seizure detection using EEG signals."}, {"title": "2 Background", "content": "Few-shot learning methods aim at designing a model that classifies a test sample based on a very limited num- ber of previously seen labeled examples. For instance, Fig. 2a shows an example of a few-shot learning task. In this figure, the test sample must be classified only using a small group of limited labeled samples, referred to as support set.\nA potential solution for the few-shot learning chal- lenge, in the context of meta-learning, is to simulate the situation of having a few labeled samples during training. Essentially, the model is trained on a large dataset, re- ferred to as the base dataset, to learn the similarities and differences among a few objects. This step of training the model on a base dataset is called meta-train, shown in Fig. 2b.\nThe training step, as shown in Fig. 2b, involves sev- eral episodes. In each episode, N distinct classes are randomly selected from the base dataset, and k random samples are chosen from each class. These samples collectively form a support set for the episode.\nLet \\( D_{\\text{train}} \\) be the base dataset for meta-training. The support set for episode e is randomly selected from \\( D_{\\text{train}} \\) to create \\( S_e = \\{(x_i, y_i)\\}_{i=1}^{kN} \\). The goal of this episode is to classify new samples x; that belong to these N classes. Thus, we create a query set with these new samples as \\( Q_e = \\{(x_i, y_i)\\}_{i=1}^{mN} \\), where m is the number of new samples in each class. The loss function during meta- training aims to minimize the log-likelihood of each predicted class \\( y_i \\) of the samples in \\( Q_e \\) compared to the corresponding ground truth y.\nAs depicted in Fig. 2b, the process of creating episodes and selecting samples and classes is repeated multiple times during meta-training. The underlying idea"}, {"title": "3 PROPOSED METHODS", "content": "This section is structured into the following steps. Ini- tially, we explain how MetaWearS tackles challenge 1. As mentioned in Section 1, this challenge pertains to the initial data collection required for training the first model. In Section 3.2, we employ our proposed few-shot learn- ing method to address Challenge 2, aiming to reduce the demand for a large quantity of annotated new sam- ples for updates during their usage by end-users. Finally, in Section 3.3, we discuss the solution for Challenge 3. In this section, we explain the impact of MetaWearS on the efficient updating of prototypes and models on the hardware to minimize energy and time consumption."}, {"title": "3.1 MetaWearS for reducing initial data collection", "content": "Our proposed method is inspired by the meta-transfer learning method [17]. Meta-transfer learning is a general approach in which pre-trained models on large datasets are used as a foundation for new tasks, often referred to as fine-tuning. The goal of transfer learning, in this method, is to use existing knowledge and reduce the need for extensive new training data.\nAlgorithm 1 formulates the explained meta-train pro- cedure applied initially to the base dataset for pretraining and, consequently, to the target dataset for fine-tuning. During meta-train, each episode consists of a support set and a query set. The support set contains a small number k of samples from each class (normal and ab- normal) from \\( N_s \\) patients. Similarly, the query set con- tains k samples of the same classes from \\( N_Q \\) patients. Based on prototypical networks, in our proposed method, both support and query set samples are processed by the model to extract features \\( f_{\\phi}(x_i) \\in \\mathbb{R}^D \\) within each episode. \\( f_{\\phi}(x_i) \\) is considered as a D-dimensional vector extracted from the output of the layer that precedes the final output layer in the models.\nAs discussed in Section 2, a class prototype \\( c_n \\) for class n is defined as the average of all vectors \\( f_{\\phi}(x_i) \\) in the support set such that \\( Y_i = n \\). After computing the prototypes in the query dataset, classes with proto- types that are closer to the query feature \\( f_{\\phi}(x_i) \\) obtain higher probability scores. The similarity between the query sample and each class prototype is computed us- ing squared Euclidean distance. Learning proceeds by applying softmax over the negative of these distances and the probability for each class is obtained. The loss function L is computed as Equation (2).\n\\[ L_D(\\phi) = \\frac{1}{|D|} \\sum_{(x,y) \\in D} l \\left( \\sigma(\\text{-}||f_{\\phi}(x) - c_y||_2), y \\right), \\]"}, {"title": "3.2 MetaWearS for updating the model using few new shots", "content": "In this section, we discuss the methods corresponding to Challenge 2. Assume that some new annotated samples are collected from new subjects. We denote the new dataset from these subjects as \\( D_{\\text{new}} \\). By feeding the samples of \\( D_{\\text{new}} \\) into the model, we are able to compute \\( f_{\\phi}(x_i) \\) for all the samples. As discussed in Section 2, we use the samples in the target set (\\( D_{\\text{train}} \\)) and the small sample set in \\( D_{\\text{new}} \\) to reconstruct the support set for each class n as follows:\n\\[ S_n \\leftarrow \\text{Random Sample}(D_{\\text{train}, n} \\cup D_{\\text{new}, n}, k), \\]"}, {"title": "3.3 Hardware architecture in Meta WearS", "content": "The system considered in our scenario for wearable systems is based on X-HEEP [18], an open-source RISC-V extensible and configurable platform for edge-computing.\nShown in Fig.3, X-HEEP comprises three key hardware components: an OpenHW Group CV32E40P RISC-V processing unit (CPU) [19], an on- chip memory, and a peripheral subsystem, all intercon- nected via a bus. The CPU implements RV32IMFC RISC-V extensions and is designed to deliver high per- formance while maintaining energy efficiency, a critical requirement for wearable devices due to their limited battery capacity.\nThe peripheral unit of our system encompasses sev- eral subsystems, one of which is the Serial Peripheral Interface (SPI) unit. This unit is tasked with sending and receiving data from an external wireless communication system. In our specific scenario, this unit receives all updated models and prototypes from a BLE unit. It is im- portant to note that accessing the data via the SPI takes significantly longer than accessing the on-chip memory.\nThe process of updating the model or prototype, as received from the server side, unfolds as follows: The updated model weights or prototypes start arriving from BLE. The CPU then fetches these values using the SPI protocol and replaces the corresponding parameters in the on-chip memory."}, {"title": "4 EXPERIMENTAL SETUP", "content": "As mentioned in Section 1, we perform experiments on two different case studies of epileptic seizure detection and AF arrhythmia detection. In the following, we de- scribe the datasets and settings used in these case studies."}, {"title": "4.1 EEG data for epileptic seizure detection", "content": "The training dataset for the base learner in our study com- prises the publicly available Temple University Hospital EEG Seizure Corpus (TUSZ) [20]-v2.0.0, encompassing data from 675 subjects with a cumulative duration of 1476 hours. Notably, the dataset exhibits imbalances, characterized by predominantly short files (average du- ration of 10 minutes) and a significant preponderance of normal non-seizure signals. Additionally, the dataset features heterogeneity in sampling frequency and the number of channels. To ensure uniformity, all files are resampled to 256 Hz as suggested in [21]. The spatial arrangement of channels follows the 10-20 system, and we adopt the bipolar montage [22].\nThe second database comprises EEG recordings from a limited number of 14 subjects acquired at the Unit of Neurology and Neurophysiology of the University of Siena [23, 24]. In particular, four subjects lack seizure data and, consequently, they are always used in the test set. The original signals were captured at 512 Hz, and we resampled them to 256 Hz for consistency."}, {"title": "4.1.1 Data preprocessing and network architecture", "content": "The EEG signals in the base and target datasets are fil- tered by a band-pass filter on [0.5\u201360] Hz, as well as a 50 Hz notch filter. Subsequently, we extract a short-time Fourier transform (STFT) from each 12-second window of the filtered signal. The STFT employs one-second segmenting, 50 overlapping samples, and a frequency resolution of 2. These parameter choices are extracted by the recommendations in [25].\nThe model used for this task is a 4-layer Vision Transformer-based model [16], which is modi- fied for epileptic seizure detection by [25]. The STFT extracted from the EEG input signal is considered as an input image to this 4-layer transformer encoder. Origi- nally, the decoder was implemented as a fully connected layer, reducing the dimensionality to match the number of classes. However, in our approach, using the proposed method, we modify the decoder to employ a fully con- nected layer, aligning the output dimension with that of the prototypes, which, in this case, is set to 16."}, {"title": "4.2 ECG data for AF detection", "content": "The large-scale dataset used for base dataset is Physionet Computing in Cardiology Challenge 2017 [26], which consists of 8528 single-lead ECG recordings, divided among AF, normal, noisy, and other classes. We have extracted 7561 signals which have more than 30 seconds of signal. The dataset consists of 5154 normal record- ings, 771 AF recordings, 46 noisy recordings, and 2557 records in the other rhythm classes. These recordings have a sampling frequency of 300 Hz. The duration of ECG recordings varies from 9 seconds to 60 seconds, with a median recording length of 30 seconds.\nThe second dataset is a private dataset in which data are obtained by a wearable device. This dataset contains 303 records of single-lead ECG signals, with each record having a duration of 40 seconds. The sampling rate of the dataset is 200 Hz. This dataset contains ECG signals for normal heart rhythms and AF. From this dataset, 150 ECG samples were selected for fine-tuning, and the remaining data was reserved for testing."}, {"title": "4.2.1 Data Augmentation", "content": "Within our base training dataset, a total of 7561 ECG signals with a recording length of 30 seconds are present. However, this dataset demonstrates a pronounced im- balance, with approximately 89% of the data affiliated with a specific class, leading to a potential bias towards the class with the most data. In our study, we choose a combined approach involving random resampling and the Gaussian noise method. Initially, random resampling is used to balance the AF and Other classes, rectifying any imbalances. This technique selects samples from the minority class at random and integrates them into the training data. Furthermore, it introduces noise to the synthetic data points, improving variation and smoothing class boundaries, which in turn helps reduce overfitting. After balancing the number of data in each class, we added amplified noise to only half of the data."}, {"title": "4.2.2 Data preprocessing and network architecture", "content": "Data preprocessing is an essential step in ECG signal analysis, enhancing data quality, reducing noise, and fa- cilitating reliable analysis and modeling. These prepro- cessing steps help to improve the quality of the ECG sig- nals and reduce inconsistency across different datasets, as in [27]. This method involves the application of a second-order band-pass Butterworth filter to eliminate baseline drift and high-frequency noise from ECG sig- nals. Following this, downsampling at 100 Hz is used to ensure uniformity in sampling rates across different datasets. The signals are then normalized using min-max scaling, resulting in values within the range of 0 to 1.\nThe CNN structure employed in this study draws inspiration from MobileNetV2 architecture and the ar- chitecture in [27], where a 7-layer instantiation of Mo- bileNetV2 is optimized for AF detection. Based on the memory capacity in our hardware system, we increased the number of layers to 13 layers.\nThe employed model consists of ten inverted residual blocks connected in sequence. Each inverted residual block includes a depthwise convolutional layer, followed by a projection layer that reduces the channel size back to the original size. The number of output channels for each inverted residual block is designed to be 8, 12 (x2), 16 (x3), and 24 (x4), respectively. The activation func- tion used in each convolutional layer is the Rectified Linear Unit (ReLU). The model also includes a sepa- rable 1D convolutional layer (separable Conv1D) with channel expansion and a pointwise convolutional layer with six times extended channels. The kernel size for the separable Conv1D layer and the inverted residual blocks is set to 7 and 5, respectively. The last layer of the model is a dense layer followed by a relu activation function, which performs the classification into the four ECG classes: normal sinus rhythm, atrial fibrillation, atrial premature contraction, and ventricular premature contraction. Overall, the proposed CNN structure is designed to be lightweight and efficient for ECG classifi- cation on low-power wearable devices."}, {"title": "5 RESULTS", "content": ""}, {"title": "5.1 Primary data collection and training", "content": "In the first phase of a wearable system lifecycle, wear- able data must be collected from the patients and must be annotated. These labeled signals form the \"target dataset,\" in which all the signals are derived from the target wearable system. We assume that the amount of labeled signals is too small for training a model. In this section, we tackle Challenge 1 to meta-train the model only with a minimal amount of annotated signals in the target dataset.\nIn our work, we use a \"base dataset\", which contains a large number of signals with the same type as the target dataset, albeit in a different setting. In particular, for the epileptic seizure detection task, both the base and target datasets have EEG signals, but the base dataset is collected with hospital setting devices. Similarly, in the case of AF detection, the type of signal in the base and target datasets is ECG, with the base dataset gathered in a hospital setting and the target dataset from wearable systems.\nFig. 5a shows the base dataset. The base dataset is an extensive dataset, and it contains signals acquired from hospital setting devices. From a large pool of patients, for each episode, we randomly select non-overlapping patients, for the support set and query set, respectively. We randomly choose samples from these patients to form a support set and a query set to pretrain the model in the base dataset.\nFig. 5b shows the target dataset, where signals are col- lected from wearable devices and annotated by clinicians. The number of patients in this target dataset is signifi- cantly smaller. Here, we fine-tune the model based on this target dataset. Again, we apply the random sampling of patients to form the support set and the query set in each episode. Through fine-tuning, the model becomes adapted to wearable signals.\nIn the inference meta-test step, as illustrated in Fig.6, random patients and random samples are selected from the target dataset to create the support set and the test sample is derived from a non-overlapping patient."}, {"title": "5.1.1 Quantitative results", "content": "Fig. 7 shows the results of our experiments based on the amount of labeled data in the target dataset. For epilepsy, we have selected annotated groups from the target dataset with one, three, and five patients, and similarly, for AF, we have selected annotated groups with varying ECG signal durations of 5, 15, and 25 minutes to investigate the effect of the number of initial annotated signals on the performance of the model. As shown in Fig. 7, the results have improved consistently as the number of samples within each group has gradually increased.\nDuring pretraining on the base dataset, in each episode, we set a query set size of 15 from two classes in the AF large-scale dataset and two classes in the epilepsy base dataset. At test time, we similarly sample episodes from target classes and average the results over 10 iter- ations to get trustworthy measures of the model perfor- mance. During fine-tuning on the target datasets, in each epoch, there are 5 episodes for AF and 100 episodes for epilepsy and then selected k = 5 samples for the support set. Also, 20% of the data are selected as validation. In case where the validation loss is not decreased for five epochs, the fine-tuning is stopped.\nIn the meta-test phase, we perform multiple iterations to evaluate our model's performance under varying con- ditions. For each iteration, the model is applied to the test data, resulting in a set of the Area Under the ROC Curve (AUC). We then report the mean AUC value.\nAs shown in Fig. 7a, by increasing the number of pa- tients in each group, the AUC value increases by 16%. With fine-tuning on only five patients, our model ob- tained an AUC value of 87.7%. Similarly, in Fig. 7b, by increasing the time of the ECG signals in each group, we have an increase in the AUC value by 2% and then 4% for 15 and 25 minutes of data in fine-tuning, respectively. Finally, with fine-tuning on 25 minutes of signals, our model's AUC value is 93%."}, {"title": "5.1.2 Comparison with previous studies", "content": "As discussed in the previous section, Challenge \u2460 is related to the limited data available in the target dataset for training an ML model. In previous works, this chal- lenge is often tackled by training a model on a larger dataset (base dataset) and directly evaluating it on the target dataset. This approach has been commonly used in various medical research studies that involve various input data, including medical images [28-31], biomed- ical signals [32-37], electronic health records [38-41], and combinations of these [42-45].\nThis section compares the performance of MetaWearS with this conventional approach. To ensure a fair comparison, we conducted multiple experiments based on different patient combinations within the target dataset. We then obtained the corresponding results for both MetaWearS and the conventional approach. The AUC improvement using MetaWearS for each target dataset was then calculated as the subtraction between MetaWearS result with the convention approach one. Fig. 8 presents the distribution of AUC improvement for various patient combinations in the target dataset for both seizure and AF detection tasks.\nAs shown in the figure, the median AUC improvement for MetaWearS compared to the conventional approach is 2.7% and 29.0% for seizure and AF detection, re- spectively. To further analyze this, a one-sample t-test was performed to determine if the AUC improvement is significantly greater than zero. The null hypothesis as- sumed that zero belongs to the distribution. The obtained p-value was less than 0.05, leading to the rejection of the null hypothesis. This evidence confirms that the AUC improvement is statistically greater than zero, indicating that the MetaWearS model outperforms the conventional approach in the studied detection tasks.\nThe results reveal a greater performance difference between MetaWearS and the conventional approach for AF detection compared to seizure detection. In particu- lar, the AF detection task does not exhibit instances of extreme under-performance or outliers. This observa- tion can be attributed to the larger discrepancy in signal"}, {"title": "5.2 Updating the model using few new shots", "content": "In the second phase of wearable system lifecycles, the wearable devices equipped with our model are dis- tributed to new patients for detection purposes. The wearable systems begin collecting signals from the in- dividuals. The system is designed to detect target ab- normalities and transmit this data to a server for further processing. As data is accumulated from the wearable systems, clinicians are able to annotate the signals. In this way, a new labeled sample is available for updating the model. In this section, we discuss the reduction of the number of new labeled data for updating the model using MetaWearS to address Challenge 2.\nAs shown in Fig. 9, the new shot is included in the support set that was also created with samples from the target dataset. Therefore, the support set is updated, and the new few shots play a crucial role in the inference step.\nTo evaluate the effectiveness of our model update sce- nario for the detection of AF and epilepsy, we conducted experiments to evaluate the results of the phase where prototypes are calculated based on the newly received annotated shots, typically on the server side. For AF, we performed fine-tuning on the group that included the smallest number of patients, which is equal to 30 ECG records and takes 5 minutes, and then we only took a few shots from other groups of patients that are not part of the test data in the meta-test phase. For epilepsy, fine-tuning was performed in one patient and then new shots were taken from one and two additional patients. These experiments involved varying the shot values of k = 1, 3, 5, 10, 15, and 20.\nAs shown in Fig. 10a, for epileptic seizure detection, the baseline AUC is 70.3%, where no additional shots are applied. When k = 10 shots are received from a sin- gle additional patient in \\( D_{\\text{new}} \\), there is an improvement in the AUC by 3.4% compared to the baseline. This improvement is even more pronounced when k = 20 shots are received from the same patient, resulting in 74.4% of AUC.\nThe figure also presents the results when two addi- tional patients shared their shots. With k = 20 new shots from these two patients, the model can achieve 75.6% of AUC, which is 5.3% more than the baseline, only by a total of 16 minutes of signals.\nAn observation in Fig. 10 in both cases of epileptic seizure detection and AF detection is the slight perfor- mance degradation compared to the baseline when only a single shot is received from one or two additional pa- tients. The reason for the performance degradation can be the low robustness of randomly selecting a single shot as opposed to multiple shots."}, {"title": "5.3 Battery life with Meta WearS", "content": "Addressing Challenge \u2462 that considers the energy ef- ficiency of the updates, we use X-HEEP as the energy- efficient and low-power system for implementing the models [18].\nThe X-HEEP hardware supports both low-latency and low-power modes, detailed in Table 1. In low-latency mode, the system uses a 1.2V supply and 450 MHz fre- quency, allowing rapid execution and subsequent idling. The transformer model used for epileptic seizure detec- tion processes each 12-second window as input. Re- markably, we observe that the processing time for each window is 1.9 seconds when X-HEEP operates at the low-latency mode. Also, in AF detection, we process a 10-second window in 0.76 seconds at the low-latency mode. The estimated power consumption is 50 mW during operations. Using a battery with a capacity of 480 mAh, we can execute the seizure detection and AF detection tasks on X-HEEP for 24.3 and 27.3 hours, respectively. Therefore, thanks to the optimized imple- mentation and quantization efforts undertaken for these models, they can operate in real-time on the X-HEEP system.\nConversely, the low-power mode focuses on reducing power usage by adjusting frequencies to just meet real- time demands, eliminating idle periods. Here, epilepsy detection operates at 75 MHz with 3.7 mW power, and AF detection at 34.4 MHz with 1.9 mW power. A battery with the same capacity of 480 mAh can last in the low- power mode as long as 103.8 and 202.1 hours for seizure detection and AF detection, respectively.\nFor epilepsy detection, updating the prototypes via the Bluetooth Low Energy (BLE) module takes 239 mil- liseconds, which is 12% of the total execution time. For AF detection, updates take 1.7 seconds, amounting to 225% of the execution time, significantly impacting per- formance.\nA common approach to updating models on wearable devices involves sending the entire updated model back to users' devices from the server. This method is preva- lent in federated learning scenarios, as seen in several works [46\u201351].\nIn contrast, our proposed MetaWearS method enables us to update the wearable system by only updating the prototypes instead of updating the entire model's weights. This benefit reduces the time and energy consumption for updating the framework by 456x and 418x for epileptic seizure detection and AF detection, respectively. In case of frequent updating of the model, the battery life is decreased significantly in the conventional approach."}, {"title": "5.3.1 Optimizing memory usage in MetaWearS-based wearable systems", "content": "Table 2 provides the details of the models used in this study. In the case of epilepsy, the transformer model is deployed on X-HEEP using 16-bit fixed-point parame- ters. Within the transformer, the linear operations are ex- ecuted with fixed-point operations, while the non-linear operations, namely Softmax, Normalization, and GELU activation, are operated by a 32-bit floating-point unit. While quantization of the parameters and the linear oper-"}, {"title": "6 DISCUSSION", "content": "In this work, we have discussed several significant obsta- cles that are currently at the cutting edge of personalized healthcare and wearable technology. In Challenge \u2460, we highlight the issue of insufficient data collected from wearable devices, which often reduces the effective- ness of machine learning models. Further research has been conducted to advance meta-learning strategies that address these challenges in various health monitoring applications. One study introduces MetaPhys, a meta- learning framework that optimizes remote physiological measurements and is capable of high-speed inference, showing promise for edge or wearable devices [52]. Furthermore, a study explores the use of model-agnostic meta-learning (MAML) [53] to improve wearable plat- forms for real-time glucose monitoring, specifically in the management of type 1 diabetes [54].The study in [55] presents a meta-learning neural network framework for genomic survival analysis, achieving effective pre- dictive modeling with limited data and highlighting key cancer-related genes and pathways. Another work [56] introduces the model named MetaSense, which effec- tively generalizes across multiple datasets using limited mobile sensing data. While these papers tackled the challenge of limited data and cross-dataset through meta- learning, they have not taken into account the scenarios where the training set has no data from the target subject. In the context of wearable devices, acquiring annotated data from each user for model training is not only costly but also time-intensive due to the infrequency of abnor- mal events. In MetaWearS, we have clearly separated the meta-train and meta-test based on individual patients to have the real-world applicability of our proposed algo- rithm. Furthermore, while the mentioned papers provide foundational insights, they have not considered hard- ware implementation in their methods, nor have they addressed the ongoing updates to the framework over time, which we identify as Challenge 2.\nIn Challenge 2, we introduced MetaWearS to up- date models efficiently with minimal wearable device data. Unlike the other update processes performed in the previous study, such as integrating multi-resolution ker- nels [57] or optimizing memory management through gradient descent [58], MetaWearS simplifies the up- date process. Traditional approaches, like the hardware- software integration for energy efficiency [59] or us- ing the modified hardware-aware meta-learning pro- cess [60], often increase computational demands and energy consumption. Some recent researches focus on self-powered flexible devices using energy harvesting and low-power designs optimized for healthcare applica-"}, {"title": "6.1 Visual representation of samples", "content": "In Fig. 11, we present a visual representation of the support and query data, highlighting the impact of fine- tuning in our meta-learning framework in Challenge \u2460. Fig. 11a presents the support and query data related to epilepsy patients, which has been subject to dimen- sionality reduction through Principal Component Anal- ysis (PCA). In Fig. 11b, we provide a parallel analysis for AF, with both cases being processed similarly using PCA for feature space transformation. This visualiza- tion showcases the distribution of query data points after fine-tuning. In particular, our results reveal distinct clus- tering patterns between the support and query data after fine-tuning, indicating a substantial improvement in their separability.\nFurthermore, we show the results corresponding to Challenge 2, where the data requirement for the pro- cess to update the values poses a significant considera- tion. To gain a better understanding of this phenomenon, we visualized the feature set of labeled samples in the target dataset and the samples in the test set in a two- dimensional representation using Principal Component Analysis (PCA). Fig. 12 shows this representation for AF detection"}]}