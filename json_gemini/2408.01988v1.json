{"title": "MetaWearS: A Shortcut in Wearable Systems Lifecycle with Only\na Few Shots", "authors": ["Alireza Amirshahi", "Maedeh H. Toosi", "Siamak Mohammadi", "Stefano Albini", "Pasquale\nDavide Schiavone", "Giovanni Ansaloni", "Amir Aminifar", "and David Atienza"], "abstract": "Wearable systems provide continuous health monitoring and can lead to early detection of potential health\nissues. However, the lifecycle of wearable systems faces several challenges. First, effective model training for\nnew wearable devices requires substantial labeled data from various subjects collected directly by the wearable.\nSecond, subsequent model updates require further extensive labeled data for retraining. Finally, frequent model\nupdating on the wearable device can decrease the battery life in long-term data monitoring. Addressing these\nchallenges, in this paper, we propose MetaWearS, a meta-learning method to reduce the amount of initial data\ncollection required. Moreover, our approach incorporates a prototypical updating mechanism, simplifying the update\nprocess by modifying the class prototype rather than retraining the entire model. We explore the performance of\nMetaWearS in two case studies, namely, the detection of epileptic seizures and the detection of atrial fibrillation.\nWe show that by fine-tuning with just a few samples, we achieve 70% and 82% AUC for the detection of epileptic\nseizures and the detection of atrial fibrillation, respectively. Compared to a conventional approach, our proposed\nmethod performs better with up to 45% AUC. Furthermore, updating the model with only 16 minutes of additional\nlabeled data increases the AUC by up to 5.3%. Finally, MetaWearS reduces the energy consumption for model\nupdates by 456x and 418x for epileptic seizure and AF detection, respectively.", "sections": [{"title": "1 Introduction", "content": "Advancements in biomedical signal monitoring tech-\nniques have contributed significantly to the early diagno-\nsis and treatment of various medical conditions. Immedi-\nate and accurate detection of these conditions can guide\nappropriate medical interventions, thereby improving\npatient care[1, 2].\nWearable systems are increasingly being used to mon-\nitor health conditions and provide real-time data on vari-\nous physiological parameters. Wearable devices, such as\nsmartwatches, fitness trackers, and specialized medical\nwearables, can track and record data related to heart rate,\nblood pressure, sleep patterns, physical activity, etc. [3\u2013\n5].\nDeep learning has demonstrated significant advances\nin a variety of biomedical applications. However, imple-\nmenting these advances into practical wearable systems\noften faces numerous challenges. These challenges span\nthe entire lifecycle of a wearable device, from its data\ncollection phase to its utilization by end-users. Fig. la\nshows the definition of a wearable system lifecycle and\nits challenges. The first challenge, shown in Fig. la with\n1, is the requirement for substantial biomedical labeled\ndata to train deep learning models. Data collection is\na costly and time-consuming process [6]. This issue is\nfurther exacerbated in wearable systems by the fact that\nthe data beneficial to the model training should ideally\nbe collected from identical devices [7-10].\nThe next challenge for deep learning deployment in\nwearable systems is the data requirement for the updating\nprocess, shown by \u2461 in Fig. 1a. In this phase, data\nshould ideally be collected from a large number of new\nparticipants to have enough data to retrain the model.\nOtherwise, with a limited number of data, the model can\nsuffer from an overfitting problem, where it becomes\ntoo fit to the new training data and performs poorly on\nunseen data[11, 12].\nFinally, once new signals are obtained and the model\nis updated, the updated model should be sent back and re-\nplaced on the wearable system. However, deep learning\nmodels are typically large. When models are transmit-"}, {"title": "2 Background", "content": "Few-shot learning methods aim at designing a model\nthat classifies a test sample based on a very limited num-\nber of previously seen labeled examples. For instance,\nFig. 2a shows an example of a few-shot learning task. In\nthis figure, the test sample must be classified only using\na small group of limited labeled samples, referred to as\nsupport set.\nA potential solution for the few-shot learning chal-\nlenge, in the context of meta-learning, is to simulate the\nsituation of having a few labeled samples during training.\nEssentially, the model is trained on a large dataset, re-\nferred to as the base dataset, to learn the similarities and\ndifferences among a few objects. This step of training\nthe model on a base dataset is called meta-train, shown\nin Fig. 2b.\nThe training step, as shown in Fig. 2b, involves sev-\neral episodes. In each episode, N distinct classes are\nrandomly selected from the base dataset, and k random\nsamples are chosen from each class. These samples\ncollectively form a support set for the episode.\nLet $D_{train}$ be the base dataset for meta-training. The\nsupport set for episode e is randomly selected from $D_{train}$\nto create $S_e = \\{(x_i, y_i)\\}_{i=1}^{k \\cdot N}$. The goal of this episode is\nto classify new samples $x_j$ that belong to these N classes.\nThus, we create a query set with these new samples as\n$Q_e = \\{(x_i,y_i)\\}_{i=1}^{m \\cdot N}$, where m is the number of new\nsamples in each class. The loss function during meta-\ntraining aims to minimize the log-likelihood of each\npredicted class $y_i$ of the samples in $Q_e$ compared to the\ncorresponding ground truth $y_i$.\nAs depicted in Fig. 2b, the process of creating\nepisodes and selecting samples and classes is repeated\nmultiple times during meta-training. The underlying idea"}, {"title": "3 PROPOSED METHODS", "content": "This section is structured into the following steps. Ini-\ntially, we explain how MetaWearS tackles challenge 1.\nAs mentioned in Section 1, this challenge pertains to the\ninitial data collection required for training the first model.\nIn Section 3.2, we employ our proposed few-shot learn-\ning method to address Challenge 2, aiming to reduce\nthe demand for a large quantity of annotated new sam-\nples for updates during their usage by end-users. Finally,\nin Section 3.3, we discuss the solution for Challenge 3.\nIn this section, we explain the impact of MetaWearS on\nthe efficient updating of prototypes and models on the\nhardware to minimize energy and time consumption."}, {"title": "3.1 MetaWearS for reducing initial data\ncollection", "content": "Our proposed method is inspired by the meta-transfer\nlearning method [17]. Meta-transfer learning is a general\napproach in which pre-trained models on large datasets\nare used as a foundation for new tasks, often referred\nto as fine-tuning. The goal of transfer learning, in this\nmethod, is to use existing knowledge and reduce the\nneed for extensive new training data.\nAlgorithm 1 formulates the explained meta-train pro-\ncedure applied initially to the base dataset for pretraining\nand, consequently, to the target dataset for fine-tuning.\nDuring meta-train, each episode consists of a support\nset and a query set. The support set contains a small\nnumber k of samples from each class (normal and ab-\nnormal) from $N_S$ patients. Similarly, the query set con-\ntains k samples of the same classes from $N_Q$ patients.\nBased on prototypical networks, in our proposed method,\nboth support and query set samples are processed by the\nmodel to extract features $f_\\phi(x_i) \\in R^D$ within each\nepisode. $f_\\phi(x_i)$ is considered as a D-dimensional vector\nextracted from the output of the layer that precedes the\nfinal output layer in the models.\nAs discussed in Section 2, a class prototype $c_n$ for\nclass n is defined as the average of all vectors $f_\\phi(x_i)$\nin the support set such that $Y_i = n$. After computing\nthe prototypes in the query dataset, classes with proto-\ntypes that are closer to the query feature $f_\\phi(x_i)$ obtain\nhigher probability scores. The similarity between the\nquery sample and each class prototype is computed us-\ning squared Euclidean distance. Learning proceeds by\napplying softmax over the negative of these distances\nand the probability for each class is obtained. The loss\nfunction L is computed as Equation (2).\n$L_D(\\phi) = \\frac{1}{|D|} \\sum_{(x,y) \\in D} l(\\sigma(-||f_\\phi(x) - c_n||_2), y),$ (2)\nwhere l is the log-likelihood function and $\\sigma$ is softmax."}, {"title": "3.2 MetaWearS for updating the model us-\ning few new shots", "content": "In this section, we discuss the methods corresponding to\nChallenge 2. Assume that some new annotated samples\nare collected from new subjects. We denote the new\ndataset from these subjects as $D^{new}$. By feeding the\nsamples of $D^{new}$ into the model, we are able to compute\n$f_\\phi(x)$ for all the samples. As discussed in Section 2, we\nuse the samples in the target set ($D^{train}$) and the small\nsample set in $D^{new}$ to reconstruct the support set for each\nclass n as follows:\n$S_n \\leftarrow Random \\ Sample \\bigg(D_{train,n} \\cup \\substack{Pats \\\\ Pats} Random \\ Sample \\bigg(D_{new,n}, k\\bigg),\\bigg)$ (3)\nwhere $k < |D^{new}| < |D^{train}|$. The inference al-\ngorithm in this part is identical to Algorithm 2 ex-\ncept Line 4, where $S_n$ should be reconstructed by the\nsupport sets based on the assignment (3). For each\n$(x_j, y_j) \\in D_{test}$, $f_\\phi(x_j)$ is compared to the updated\nprototypes $c_n$ to compute the Euclidean distance and\nclassify the sample.\nIn this phase, we calculate the prototypes based on\nthe few new shots that have been received and annotated,\ntypically on the server side. Once these new prototypes\nare updated, they can be transmitted back to the wearable\nsystems. By replacing and updating these prototypes\nin wearable systems, subjects can benefit from a more\ngeneralized prototype, leading to improved performance.\nThese updates can be performed frequently for two\nreasons. First, we only require a few annotated samples\nfor the update. Second, the prototype vectors are com-\npact enough to consume minimal energy during updates.\nThe details of updating the prototype are discussed in\ndetail in Section 5.3.1, where we explain Challenge 3\nwithin the hardware system."}, {"title": "3.3 Hardware architecture in Meta WearS", "content": "The system considered in our scenario for wearable\nsystems is based on X-HEEP [18], an open-source\nRISC-V extensible and configurable platform for edge-\ncomputing.\nShown in Fig.3, X-HEEP comprises\nthree key hardware components: an OpenHW Group\nCV32E40P RISC-V processing unit (CPU) [19], an on-\nchip memory, and a peripheral subsystem, all intercon-\nnected via a bus. The CPU implements RV32IMFC\nRISC-V extensions and is designed to deliver high per-\nformance while maintaining energy efficiency, a critical\nrequirement for wearable devices due to their limited\nbattery capacity.\nThe peripheral unit of our system encompasses sev-\neral subsystems, one of which is the Serial Peripheral\nInterface (SPI) unit. This unit is tasked with sending and\nreceiving data from an external wireless communication\nsystem. In our specific scenario, this unit receives all\nupdated models and prototypes from a BLE unit. It is im-\nportant to note that accessing the data via the SPI takes\nsignificantly longer than accessing the on-chip memory.\nThe process of updating the model or prototype, as\nreceived from the server side, unfolds as follows: The\nupdated model weights or prototypes start arriving from\nBLE. The CPU then fetches these values using the SPI\nprotocol and replaces the corresponding parameters in\nthe on-chip memory."}, {"title": "4 EXPERIMENTAL SETUP", "content": "As mentioned in Section 1, we perform experiments on\ntwo different case studies of epileptic seizure detection\nand AF arrhythmia detection. In the following, we de-\nscribe the datasets and settings used in these case studies."}, {"title": "4.1 EEG data for epileptic seizure detec-\ntion", "content": "The training dataset for the base learner in our study com-\nprises the publicly available Temple University Hospital\nEEG Seizure Corpus (TUSZ) [20]-v2.0.0, encompassing\ndata from 675 subjects with a cumulative duration of\n1476 hours. Notably, the dataset exhibits imbalances,\ncharacterized by predominantly short files (average du-\nration of 10 minutes) and a significant preponderance\nof normal non-seizure signals. Additionally, the dataset\nfeatures heterogeneity in sampling frequency and the\nnumber of channels. To ensure uniformity, all files are\nresampled to 256 Hz as suggested in [21]. The spatial\narrangement of channels follows the 10-20 system, and\nwe adopt the bipolar montage [22].\nThe second database comprises EEG recordings from\na limited number of 14 subjects acquired at the Unit of\nNeurology and Neurophysiology of the University of\nSiena [23, 24]. In particular, four subjects lack seizure\ndata and, consequently, they are always used in the test\nset. The original signals were captured at 512 Hz, and\nwe resampled them to 256 Hz for consistency."}, {"title": "4.1.1 Data preprocessing and network architecture", "content": "The EEG signals in the base and target datasets are fil-\ntered by a band-pass filter on [0.5\u201360] Hz, as well as a\n50 Hz notch filter. Subsequently, we extract a short-time\nFourier transform (STFT) from each 12-second window\nof the filtered signal. The STFT employs one-second\nsegmenting, 50 overlapping samples, and a frequency\nresolution of 2. These parameter choices are extracted\nby the recommendations in [25].\nThe model used for this task is a 4-layer\nVision Transformer-based model [16], which is modi-\nfied for epileptic seizure detection by [25]. The STFT\nextracted from the EEG input signal is considered as an\ninput image to this 4-layer transformer encoder. Origi-\nnally, the decoder was implemented as a fully connected\nlayer, reducing the dimensionality to match the number\nof classes. However, in our approach, using the proposed\nmethod, we modify the decoder to employ a fully con-\nnected layer, aligning the output dimension with that of\nthe prototypes, which, in this case, is set to 16. Fig. 4a\ndisplays the preprocessing steps and model architecture\nthat were utilized for the Epilepsy detection."}, {"title": "4.2 ECG data for AF detection", "content": "The large-scale dataset used for base dataset is Physionet\nComputing in Cardiology Challenge 2017 [26], which\nconsists of 8528 single-lead ECG recordings, divided\namong AF, normal, noisy, and other classes. We have\nextracted 7561 signals which have more than 30 seconds\nof signal. The dataset consists of 5154 normal record-\nings, 771 AF recordings, 46 noisy recordings, and 2557\nrecords in the other rhythm classes. These recordings\nhave a sampling frequency of 300 Hz. The duration of\nECG recordings varies from 9 seconds to 60 seconds,\nwith a median recording length of 30 seconds.\nThe second dataset is a private dataset in which data\nare obtained by a wearable device. This dataset contains\n303 records of single-lead ECG signals, with each record\nhaving a duration of 40 seconds. The sampling rate of\nthe dataset is 200 Hz. This dataset contains ECG signals\nfor normal heart rhythms and AF. From this dataset,\n150 ECG samples were selected for fine-tuning, and the\nremaining data was reserved for testing."}, {"title": "4.2.1 Data Augmentation", "content": "Within our base training dataset, a total of 7561 ECG\nsignals with a recording length of 30 seconds are present.\nHowever, this dataset demonstrates a pronounced im-\nbalance, with approximately 89% of the data affiliated\nwith a specific class, leading to a potential bias towards\nthe class with the most data. In our study, we choose a"}, {"title": "4.2.2 Data preprocessing and network architecture", "content": "Data preprocessing is an essential step in ECG signal\nanalysis, enhancing data quality, reducing noise, and fa-\ncilitating reliable analysis and modeling. These prepro-\ncessing steps help to improve the quality of the ECG sig-\nnals and reduce inconsistency across different datasets,\nas in [27]. This method involves the application of a\nsecond-order band-pass Butterworth filter to eliminate\nbaseline drift and high-frequency noise from ECG sig-\nnals. Following this, downsampling at 100 Hz is used\nto ensure uniformity in sampling rates across different\ndatasets. The signals are then normalized using min-max\nscaling, resulting in values within the range of 0 to 1.\nThe CNN structure employed in this study draws\ninspiration from MobileNetV2 architecture and the ar-\nchitecture in [27], where a 7-layer instantiation of Mo-\nbileNetV2 is optimized for AF detection. Based on the\nmemory capacity in our hardware system, we increased\nthe number of layers to 13 layers.\nThe employed model consists of ten inverted residual\nblocks connected in sequence. Each inverted residual\nblock includes a depthwise convolutional layer, followed\nby a projection layer that reduces the channel size back\nto the original size. The number of output channels for\neach inverted residual block is designed to be 8, 12 (x2),\n16 (x3), and 24 (x4), respectively. The activation func-\ntion used in each convolutional layer is the Rectified\nLinear Unit (ReLU). The model also includes a sepa-\nrable 1D convolutional layer (separable Conv1D) with\nchannel expansion and a pointwise convolutional layer\nwith six times extended channels. The kernel size for\nthe separable Conv1D layer and the inverted residual\nblocks is set to 7 and 5, respectively. The last layer of\nthe model is a dense layer followed by a relu activation\nfunction, which performs the classification into the four\nECG classes: normal sinus rhythm, atrial fibrillation,\natrial premature contraction, and ventricular premature\ncontraction. Overall, the proposed CNN structure is\ndesigned to be lightweight and efficient for ECG classifi-\ncation on low-power wearable devices. Fig.4b displays\nthe preprocessing steps and model architecture that were\nutilized for the AF detection."}, {"title": "5 RESULTS", "content": ""}, {"title": "5.1 Primary data collection and training", "content": "In the first phase of a wearable system lifecycle, wear-\nable data must be collected from the patients and must"}, {"title": "5.1.1 Quantitative results", "content": "Fig. 7 shows the results of our experiments based on the\namount of labeled data in the target dataset. For epilepsy,\nwe have selected annotated groups from the target dataset\nwith one, three, and five patients, and similarly, for AF,\nwe have selected annotated groups with varying ECG\nsignal durations of 5, 15, and 25 minutes to investigate\nthe effect of the number of initial annotated signals on\nthe performance of the model. As shown in Fig. 7, the\nresults have improved consistently as the number of\nsamples within each group has gradually increased.\nDuring pretraining on the base dataset, in each\nepisode, we set a query set size of 15 from two classes in\nthe AF large-scale dataset and two classes in the epilepsy\nbase dataset. At test time, we similarly sample episodes\nfrom target classes and average the results over 10 iter-\nations to get trustworthy measures of the model perfor-\nmance. During fine-tuning on the target datasets, in each\nepoch, there are 5 episodes for AF and 100 episodes for\nepilepsy and then selected k = 5 samples for the support\nset. Also, 20% of the data are selected as validation. In\ncase where the validation loss is not decreased for five\nepochs, the fine-tuning is stopped.\nIn the meta-test phase, we perform multiple iterations\nto evaluate our model's performance under varying con-\nditions. For each iteration, the model is applied to the\ntest data, resulting in a set of the Area Under the ROC\nCurve (AUC). We then report the mean AUC value.\nAs shown in Fig. 7a, by increasing the number of pa-\ntients in each group, the AUC value increases by 16%.\nWith fine-tuning on only five patients, our model ob-\ntained an AUC value of 87.7%. Similarly, in Fig. 7b, by\nincreasing the time of the ECG signals in each group, we\nhave an increase in the AUC value by 2% and then 4%\nfor 15 and 25 minutes of data in fine-tuning, respectively.\nFinally, with fine-tuning on 25 minutes of signals, our\nmodel's AUC value is 93%."}, {"title": "5.1.2 Comparison with previous studies", "content": "As discussed in the previous section, Challenge \u2460 is\nrelated to the limited data available in the target dataset\nfor training an ML model. In previous works, this chal-\nlenge is often tackled by training a model on a larger\ndataset (base dataset) and directly evaluating it on the\ntarget dataset. This approach has been commonly used\nin various medical research studies that involve various\ninput data, including medical images [28-31], biomed-\nical signals [32-37], electronic health records [38-41],\nand combinations of these [42-45].\nThis section compares the performance of MetaWearS\nwith this conventional approach. To ensure a fair\ncomparison, we conducted multiple experiments based\non different patient combinations within the target\ndataset. We then obtained the corresponding results\nfor both MetaWearS and the conventional approach. The\nAUC improvement using MetaWearS for each target\ndataset was then calculated as the subtraction between\nMetaWearS result with the convention approach one.\nFig. 8 presents the distribution of AUC improvement\nfor various patient combinations in the target dataset for\nboth seizure and AF detection tasks.\nAs shown in the figure, the median AUC improvement\nfor MetaWearS compared to the conventional approach\nis 2.7% and 29.0% for seizure and AF detection, re-\nspectively. To further analyze this, a one-sample t-test\nwas performed to determine if the AUC improvement is\nsignificantly greater than zero. The null hypothesis as-\nsumed that zero belongs to the distribution. The obtained\np-value was less than 0.05, leading to the rejection of the\nnull hypothesis. This evidence confirms that the AUC\nimprovement is statistically greater than zero, indicating\nthat the MetaWearS model outperforms the conventional\napproach in the studied detection tasks.\nThe results reveal a greater performance difference\nbetween MetaWearS and the conventional approach for\nAF detection compared to seizure detection. In particu-\nlar, the AF detection task does not exhibit instances of\nextreme under-performance or outliers. This observa-\ntion can be attributed to the larger discrepancy in signal"}, {"title": "5.2 Updating the model using few new\nshots", "content": "In the second phase of wearable system lifecycles, the\nwearable devices equipped with our model are dis-\ntributed to new patients for detection purposes. The\nwearable systems begin collecting signals from the in-\ndividuals. The system is designed to detect target ab-\nnormalities and transmit this data to a server for further\nprocessing. As data is accumulated from the wearable\nsystems, clinicians are able to annotate the signals. In\nthis way, a new labeled sample is available for updating\nthe model. In this section, we discuss the reduction of\nthe number of new labeled data for updating the model\nusing MetaWearS to address Challenge 2.\nAs shown in Fig. 9, the new shot is included in the\nsupport set that was also created with samples from the\ntarget dataset. Therefore, the support set is updated, and\nthe new few shots play a crucial role in the inference\nstep.\nTo evaluate the effectiveness of our model update sce-\nnario for the detection of AF and epilepsy, we conducted\nexperiments to evaluate the results of the phase where\nprototypes are calculated based on the newly received\nannotated shots, typically on the server side. For AF,\nwe performed fine-tuning on the group that included\nthe smallest number of patients, which is equal to 30\nECG records and takes 5 minutes, and then we only took\na few shots from other groups of patients that are not\npart of the test data in the meta-test phase. For epilepsy,\nfine-tuning was performed in one patient and then new\nshots were taken from one and two additional patients.\nThese experiments involved varying the shot values of\nk = 1, 3, 5, 10, 15, and 20.\nAs shown in Fig. 10a, for epileptic seizure detection,\nthe baseline AUC is 70.3%, where no additional shots\nare applied. When k = 10 shots are received from a sin-\ngle additional patient in Dnew, there is an improvement"}, {"title": "5.3 Battery life with Meta WearS", "content": "Addressing Challenge \u2462 that considers the energy ef-\nficiency of the updates, we use X-HEEP as the energy-\nefficient and low-power system for implementing the\nmodels [18].\nThe X-HEEP hardware supports both low-latency and\nlow-power modes, detailed in Table 1. In low-latency\nmode, the system uses a 1.2V supply and 450 MHz fre-\nquency, allowing rapid execution and subsequent idling.\nThe transformer model used for epileptic seizure detec-\ntion processes each 12-second window as input. Re-\nmarkably, we observe that the processing time for each\nwindow is 1.9 seconds when X-HEEP operates at the\nlow-latency mode. Also, in AF detection, we process\na 10-second window in 0.76 seconds at the low-latency\nmode. The estimated power consumption is 50 mW\nduring operations. Using a battery with a capacity of\n480 mAh, we can execute the seizure detection and AF\ndetection tasks on X-HEEP for 24.3 and 27.3 hours,\nrespectively. Therefore, thanks to the optimized imple-\nmentation and quantization efforts undertaken for these\nmodels, they can operate in real-time on the X-HEEP\nsystem.\nConversely, the low-power mode focuses on reducing\npower usage by adjusting frequencies to just meet real-\ntime demands, eliminating idle periods. Here, epilepsy\ndetection operates at 75 MHz with 3.7 mW power, and\nAF detection at 34.4 MHz with 1.9 mW power. A battery\nwith the same capacity of 480 mAh can last in the low-\npower mode as long as 103.8 and 202.1 hours for seizure\ndetection and AF detection, respectively.\nFor epilepsy detection, updating the prototypes via\nthe Bluetooth Low Energy (BLE) module takes 239 mil-\nliseconds, which is 12% of the total execution time. For\nAF detection, updates take 1.7 seconds, amounting to\n225% of the execution time, significantly impacting per-\nformance.\nA common approach to updating models on wearable\ndevices involves sending the entire updated model back\nto users' devices from the server. This method is preva-\nlent in federated learning scenarios, as seen in several\nworks [46\u201351].\nIn contrast, our proposed MetaWearS method enables\nus to update the wearable system by only updating the\nprototypes instead of updating the entire model's weights.\nThis benefit reduces the time and energy consumption for\nupdating the framework by 456x and 418x for epileptic\nseizure detection and AF detection, respectively. In case\nof frequent updating of the model, the battery life is\ndecreased significantly in the conventional approach."}, {"title": "5.3.1 Optimizing memory usage in MetaWearS-based wearable systems", "content": "Table 2 provides the details of the models used in this\nstudy. In the case of epilepsy, the transformer model is\ndeployed on X-HEEP using 16-bit fixed-point parame-\nters. Within the transformer, the linear operations are ex-\necuted with fixed-point operations, while the non-linear\noperations, namely Softmax, Normalization, and GELU\nactivation, are operated by a 32-bit floating-point unit.\nWhile quantization of the parameters and the linear oper-"}, {"title": "6 DISCUSSION", "content": "In this work, we have discussed several significant obsta-\ncles that are currently at the cutting edge of personalized\nhealthcare and wearable technology. In Challenge \u2460,\nwe highlight the issue of insufficient data collected from\nwearable devices, which often reduces the effective-\nness of machine learning models. Further research has\nbeen conducted to advance meta-learning strategies that\naddress these challenges in various health monitoring\napplications. One study introduces MetaPhys, a meta-\nlearning framework that optimizes remote physiological\nmeasurements and is capable of high-speed inference,\nshowing promise for edge or wearable devices [52].\nFurthermore, a study explores the use of model-agnostic\nmeta-learning (MAML) [53] to improve wearable plat-\nforms for real-time glucose monitoring, specifically in\nthe management of type 1 diabetes [54].The study in\n[55] presents a meta-learning neural network framework\nfor genomic survival analysis, achieving effective pre-\ndictive modeling with limited data and highlighting key\ncancer-related genes and pathways. Another work [56]\nintroduces the model named MetaSense, which effec-\ntively generalizes across multiple datasets using limited\nmobile sensing data. While these papers tackled the\nchallenge of limited data and cross-dataset through meta-\nlearning, they have not taken into account the scenarios\nwhere the training set has no data from the target subject.\nIn the context of wearable devices, acquiring annotated\ndata from each user for model training is not only costly\nbut also time-intensive due to the infrequency of abnor-\nmal events. In MetaWearS, we have clearly separated\nthe meta-train and meta-test based on individual patients\nto have the real-world applicability of our proposed algo-\nrithm. Furthermore, while the mentioned papers provide\nfoundational insights, they have not considered hard-\nware implementation in their methods, nor have they\naddressed the ongoing updates to the framework over\ntime, which we identify as Challenge 2.\nIn Challenge 2, we introduced MetaWearS to up-\ndate models efficiently with minimal wearable device\ndata. Unlike the other update processes performed in the\nprevious study, such as integrating multi-resolution ker-\nnels [57] or optimizing memory management through\ngradient descent [58], MetaWearS simplifies the up-\ndate process. Traditional approaches, like the hardware-\nsoftware integration for energy efficiency [59] or us-\ning the modified hardware-aware meta-learning pro-\ncess [60], often increase computational demands and\nenergy consumption. Some recent researches focus on\nself-powered flexible devices using energy harvesting\nand low-power designs optimized for healthcare applica-"}, {"title": "6.1 Visual representation of samples", "content": "In Fig. 11, we present a visual representation of the\nsupport and query data, highlighting the impact of fine-\ntuning in our meta-learning framework in Challenge \u2460.\nFig. 11a presents the support and query data related\nto epilepsy patients, which has been subject to dimen-\nsionality reduction through Principal Component Anal-\nysis (PCA). In Fig. 11b, we provide a parallel analysis\nfor AF, with both cases being processed similarly using\nPCA for feature space transformation. This visualiza-\ntion showcases the distribution of query data points after\nfine-tuning. In particular, our results reveal distinct clus-\ntering patterns between the support and query data after\nfine-tuning, indicating a substantial improvement in their\nseparability.\nFurthermore, we show the results corresponding to\nChallenge 2, where the data requirement for the pro-\ncess to update the values poses a significant considera-\ntion. To gain a better understanding of this phenomenon,\nwe visualized the feature set of labeled samples in the"}, {"title": "6.2 Ablation study", "content": "In order to investigate the effect of the base dataset, we\nconducted experiments without pretraining the model"}, {"title": "6.3 Study limitations and future perspec-tive", "content": "Our work presents two key limitations. Firstly, we\ntrained MetaWearS using publicly available datasets\n(TUH for seizure detection [20] and PhysioNet for AF\ndetection [26]) where data originated from hospital set-\ntings. However, the scarcity of public datasets involving\nwearable devices and data collected outside hospitals\nhinders a more generalizable evaluation. To partially\naddress this, we employed the Siena dataset [23], albeit\nsmall and still hospital-based, to simulate data from a\ndifferent clinical setting. For AF detection, we were"}, {"title": "7 CONCLUSION", "content": "In this paper, we have proposed a novel few-shot learning\nmethod to detect abnormalities in scarce signals acquired\nby wearable"}]}