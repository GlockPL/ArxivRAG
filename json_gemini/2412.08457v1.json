{"title": "Efficient Rectification of Neuro-Symbolic Reasoning Inconsistencies by Abductive Reflection", "authors": ["Wen-Chao Hu", "Wang-Zhou Dai", "Yuan Jiang", "Zhi-Hua Zhou"], "abstract": "Neuro-Symbolic (NeSy) AI could be regarded as an analogy to human dual-process cognition, modeling the intuitive System 1 with neural networks and the algorithmic System 2 with symbolic reasoning. However, for complex learning targets, NeSy systems often generate outputs inconsistent with domain knowledge and it is challenging to rectify them. Inspired by the human Cognitive Reflection, which promptly detects errors in our intuitive response and revises them by invoking the System 2 reasoning, we propose to improve NeSy systems by introducing Abductive Reflection (ABL-Refl) based on the Abductive Learning (ABL) framework. ABL-Refl leverages domain knowledge to abduce a reflection vector during training, which can then flag potential errors in the neural network outputs and invoke abduction to rectify them and generate consistent outputs during inference. ABL-Refl is highly efficient in contrast to previous ABL implementations. Experiments show that ABL-Refl outperforms state-of-the-art NeSy methods, achieving excellent accuracy with fewer training resources and enhanced efficiency.", "sections": [{"title": "Introduction", "content": "Human decision-making is generally recognized as an interaction between two systems: System 1 quickly generates an intuitive response, and System 2 engages in further algorithmic and slow reasoning (Frederick 2005; Kahneman 2011). In Neuro-Symbolic (NeSy) Artificial Intelligence (AI), neural networks often resemble System 1 for rapid pattern recognition, and symbolic reasoning mirrors System 2 to leverage domain knowledge and handle complex problems thoughtfully, yet in a slower and more controlled way (Bengio 2019). Like human System 1 reasoning, when facing complicated tasks, neural networks often produce unreliable outputs which cause inconsistencies with domain knowledge. These inconsistencies can then be reconciled with the help of the symbolic reasoning counterpart (Hitzler 2022).\nTo achieve the above process, some methods relax symbolic domain knowledge as neural network constraints (Xu et al. 2018; Yang, Lee, and Park 2022), some attempt to approximate logical calculus using distributed representations within neural networks (Wang et al. 2019). However, a loss of full symbolic reasoning ability often occurs during these relaxation or approximation, hampering the ability of generating reliable output.\nAbductive Learning (ABL) (Zhou 2019; Zhou and Huang 2022) is a framework for bridging machine learning and logical reasoning while preserving full expressive power in each side. In ABL, the machine learning component first converts raw data into primitive symbolic outputs. These outputs can be utilized by the symbolic reasoning component, which leverages domain knowledge and performs abduction to generate a revised, more reliable output. However, previous implementations of ABL require a highly discrete combinatorial consistency optimization before applying abduction, and this optimization has high complexity which encumbers, thereby severely limiting the efficiency and applicability to large-scale scenarios.\nHuman reasoning naturally exploits both sides efficiently, a hypothetical model for this process is called Cognitive Reflection, where the fast System 1 thinking is called to quickly generate an approximate over-all solution, and then seamlessly hands the complicated parts to System 2 (Frederick 2005). The key to this process is the reflection mechanism, which promptly detects which part in the intuitive response may contain inconsistencies with domain knowledge and invokes System 2 to rectify them. This reflection typically positively associates with System 2 capabilities, as both are closely linked to an individual's mastery of domain knowledge (Sinayev and Peters 2015). Following the reflection, the process of the step-by-step formal reasoning becomes less complex: With a largely reduced search space, deriving the correct solution for System 2 becomes straightforward.\nInspired by this phenomenon, we propose a general enhancement, Abductive Reflection (ABL-Refl). Based on ABL framework, ABL-Refl preserves full expressive power of neural networks and symbolic reasoning, while replacing the time-consuming consistency optimization with the reflection mechanism, thereby significantly improves efficiency and applicability. Specifically, in ABL-Refl, a reflection vector is concurrently generated with the neural network intuitive output, which flags potential errors in the output and invokes symbolic reasoning to perform abduction, thereby rectifying these errors and generating a new output that is more consistent with domain knowledge. During model training, the training information for the reflection derives from domain knowledge. In essence, the reflection vector is abduced from domain knowledge and serves as an attention mechanism for narrowing the problem space of symbolic reasoning. The reflection can be trained unsupervisedly, requiring only the same amount of domain knowledge as state-of-the-art NeSy systems without generating extra training data.\nWe validate the effectiveness of ABL-Refl in solving Sudoku NeSy benchmarks in both symbolic and visual forms. Compared to previous NeSy methods, ABL-Refl performs significantly better, achieving higher reasoning accuracy efficiently with fewer training resources. We also compare our method to symbolic solvers, and show that the reduced search space in ABL-Refl improves the reasoning efficiency. Further experiments on solving combinatorial optimization on graphs validate that ABL-Refl can handle diverse types of data in varied dimensions, and exploit knowledge base in different forms."}, {"title": "Related Work", "content": "Recently, there has been notable progress in enhancing neural networks with reliable symbolic reasoning. Some methods use differentiable fuzzy logic (Serafini and Garcez 2016; Marra et al. 2020) or relax symbolic domain knowledge as constraints for neural network training (Xu et al. 2018; Yang, Lee, and Park 2022; Hoernle et al. 2022; Ahmed et al. 2022), while others learn constraints within neural networks by approximating logic reasoning with distributed representations (Amos and Kolter 2017; Selsam et al. 2018; Wang et al. 2019). These models tend to soften the requirements in symbolic reasoning, impacting the reliability of output generation. Models like DeepProbLog (Manhaeve et al. 2018) and NeurASP (Yang, Ishay, and Lee 2020) interpret the neural network output as a distribution over symbols and then apply a symbolic solver, incurring substantial computational costs. Abductive Learning (ABL) (Zhou 2019; Zhou and Huang 2022) attempts to integrate machine learning and logical reasoning in a balanced and mutually supporting way. It features an easy-to-use open-source toolkit (Huang et al. 2024) with many practical applications (Huang et al. 2020; Cai et al. 2021; Wang et al. 2021; Gao et al. 2024). However, the consistency optimization is with high complexity.\nAnother category of work related to our study also follows a similar process of prediction, error identification, and reasoning (Nair et al. 2020; Nye et al. 2021; Han et al. 2023). These methods are usually constrained in a narrow scope of domain knowledge, confined to specific mathematical problems or are bounded within a minimal world model.\nCornelio el al. (2023) generates a selection module to identify errors requiring symbolic reasoning rectification. In constrast to their approach which requires the preparation of a large synthetic dataset in advance, our approach automatically abduces the reflection vector during model training."}, {"title": "Abductive Reflection", "content": "This section presents problem setting and the Abductive Reflection (ABL-Reft) method."}, {"title": "Problem Setting", "content": "The main task of this paper is as follows: The input is raw data \u00e6, which can be in either symbolic or sub-symbolic form, and the target output is $y = [y_1, y_2,..., y_n]$, with each $y_i$ being a symbol from a set $Y$ that contains all possible output symbols. We assume two key components at our disposal: neural network $f$ and domain knowledge base KB. $f$ can directly map x to y, and KB holds constraints between the symbols in y. KB can assume various forms, including propositional logic, first-order logic, mathematical or physical equations, etc., and can perform symbolic reasoning operations by exploiting the corresponding symbolic solver. The output y should adhere to the constraints in KB, otherwise it will inevitably contain errors that lead to inconsistencies with the domain knowledge and incorrect reasoning results.\nThis problem type has broad applications. For example, it can be used to solve Sudoku puzzles, where the output y consists of n = 81 symbols from the set Y = {1, 2, ..., 9}, and the constraints in KB are the rules of Sudoku. It can also be applied in deploying generative models for text generation, gene prediction, mathematical problem-solving, etc., producing outputs that adhere to intricate commonsense, biological, or mathematical logics in KB."}, {"title": "Brief Introduction to Abductive Learning", "content": "When Abductive Learning (ABL) receives an input x, it initially employs f to map \u00e6 into an intuitive output \u0177 = [$\u0177_1, \u0177_2,..., \u0177_n$]. When f is under-trained, \u0177 might contain errors leading to inconsistencies with KB. ABL then tries to rectify them, and obtains a revised \u1ef9. As shown in Figure 1, the final output, y, consists of two parts: the green part retains the results from neural network, and the blue part is the modified result obtained by abduction, a basic form of symbolic reasoning that seeks plausible explanations for observations based on KB.\nSpecifically, the process of obtaining y can be divided into two sequential steps. The first step, consistency optimization, determines which positions in \u0177 include elements that contain errors causing inconsistencies, so that performing abduction at these positions will yield a y consistent with KB. Essentially, this process is pinpointing propositions (or ground atoms, etc.) which have incorrect truth assignments, and most neuro-symbolic tasks can be formalized into this form. Once these positions are determined, the second step is rectifying by abduction, which then becomes easy for KB and its corresponding symbolic solver."}, {"title": "Challenge", "content": "In previous ABL, consistency optimization has always been a computational bottleneck. It operates as an external module using zeroth-order optimization methods, independent from both f and KB (Dai et al. 2019; Zhou and Huang 2022). For each time of inference, it involves repetitively selecting various possible positions and querying the KB to see if a consistent result can be inferred. Each query involves an invocation of KB for slow symbolic reasoning. Also, since it is a complex combinatorial problem with a highly discrete nature, the number of such queries required escalates exponentially as data scale increases. This large number leads to a marked increase in time consumption, hence confines the applicability of ABL to only small datasets, usually those with output dimension n less than 10."}, {"title": "Architecture", "content": "To address the challenges above, we propose Abductive Reflection (ABL-Refl). In this section, we will provide a detailed description of its architecture.\nLet's first revisit the role of the neural network f when we map the input to symbols from the set Y. Typically, the raw data is first passed through the body block of the network, denoted by $f_1$, resulting in a high-dimensional embedding which encapsulates a wealth of feature information of the raw data. The form of $f_1$ varies, including structures like recurrent layers, graph convolution layers, or Transformers, etc. The result of $f_1$ is subsequently passed into several layers, usually linear layers, denoted by $f_2$, to obtain the intuitive output: \u0177 = argmax($f_2$($f_1$(x))) \u2208 $y^n$.\nBesides the structure described above, as shown in Figure 2, our architecture further incorporates a reflection layer R after the body block $f_1$, generating a reflection vector: r = argmax(R($f_1$(x))) \u2208 {0,1}n. The reflection layer R and reflection vector r together constitute the reflection mechanism. This vector r has the same dimensionality n as the intuitive output \u0177, and each element, $r_i$, acts as a binary classifier to indicate whether the corresponding element $\u0177_i$ is an error leading to inconsistencies with KB (flagged as 1 for an error, and 0 otherwise). The reflection vector r is generated concurrently with the intuitive response during inference, resonating with human cognition where cognitive reflection typically forms right upon generation of an intuitive response (Frederick 2005).\nWith the initial intuitive output \u0177 and the corresponding reflection vector r, we seamlessly obtain the error-removed output y': In y', elements flagged as error by r are removed and left as blanks, while the rest are retained. Subsequently, KB applies abduction to fill in these blanks, thereby generating an output y that is consistent with KB. That is:\n$y_i = \\begin{cases}\n    \u0177_i & r_i = 0 \\\\\n    \u03b4(\u0177_i), & r_i = 1\n  \\end{cases} i = 1, 2, ..., n$\nwhere \u03b4 denotes abduction. We treat y = [$y_1, y_2,..., y_n$] as the final output.\nDuring model training, the reflection is abduced from KB by directly leveraging information from domain knowledge (discussed later in Section 3.4). It can be seen as an attention mechanism generated from neural networks, which can help quickly focus symbolic reasoning specifically on areas it identifies as errors, hence largely narrowing the problem space of deliberate symbolic reasoning (Zhang et al. 2020).\nBenefits. Compared to previous ABL implementations, ABL-Refl replaces the zeroth-order consistency optimization module with the reflection mechanism to address the computational bottleneck. In this way, the need for a substantial number of querying KB is mitigated: After promptly pinpointing inconsistencies in System 1 output, regardless of the data scale, only a single invocation of KB is required to obtain a rectified and more consistent output.\nAnother thing worth noticing is that, in the architecture, the reflection layer directly connects to the body block, which helps leveraging information from the embeddings and linking more closely with the raw data. Therefore, the reflection vector r establishes a more direct and tighter bridge between raw data and domain knowledge."}, {"title": "Training Paradigm", "content": "In this section, we will discuss how to train the ABL-Refl method, especially the reflection in it.\nIn ABL-Refl, when each input \u00e6 is processed by the neural network, we obtain the intuitive output \u0177 and the reflection vector r, and subsequently obtain the error-removed (by r) output \u0177'. With \u0177 and \u0177', we can measure their consistency with KB, respectively. We denote these consistency measurements as Con(\u0177, KB) and Con(\u0177', KB), as shown in Figure 3. For a simplest example, if all elements in \u0177 (or \u0177') adhere to constraints in KB, the consistency measurement is 1; otherwise, it is 0.\nConsequently, the improvement in consistency measurement after reflection, as denoted by\n\u2206Con,(\u0177) = Con(\u0177', KB) \u2013 Con(\u0177, KB)\nnaturally indicates the effectiveness of the reflection vector: A higher value of it signifies that reflection r can more effectively detect inconsistencies within \u0177. Our training goal is to guide the neural network's parameters towards generating reflections that can maximize this value. Given that \u2206Con(\u0177) is usually a discrete value, we employ the RE-INFORCE algorithm to achieve this goal (Williams 1992), which optimizes the policy (implicitly defined by neural network f) through maximizing a specified reward \u2013 in this case, \u2206Con,(\u0177). This process leads to the following consistency loss:\n$L_{con}(x) = -\u2206Con_(\u0177) \u00b7 V_@ log f_@(\u0177, r | x)$ (1)\nwhere @ are parameters of neural network f.\nAdditionally, given that the time abduction required often escalates with problem size, we want to invoke it judiciously during inference, applying it only when it is truly necessary. Therefore, we aim to avoid the reflection vector from flagging too many elements in \u0177 as error. To achieve this, we then introduce a reflection size loss:\n$L_{size}(x) = \u0424(C - \\frac{1}{n} \\sum_{i=1}^n(1 \u2013 R(f_1(x)))$ (2)\nwhere \u0424(a) = max(0, a)2 and C is a hyperparameter ranging between 0 and 1. When C is set at a higher value, the reflection vector tends to retain a greater number of intuitive output elements instead of flagging them as error and delegating to abduction.\nIn addition to the above-mentioned training methods, using labeled data, we employ data-driven supervised training methods similar to common neural network training paradigm. The loss function in this process, e.g., cross-entropy loss, is denoted by $L_{labeled} (X, Y)$.\nTherefore, combining all the training loss, the total loss for ABL-Refl is represented as follows:\n$L = \\frac{1}{\\vert D_i \\vert} \\sum_{(x,y)\u2208Di} L_{labeled}(X, Y) + \\frac{1}{\\vert D_i U D_u\\vert} \\sum_{X\u2208DIUDU} (\u03b1L_{con}(x) + \u03b2L_{size}(x))$ (3)\nwhere \u03b1 and \u03b2 are hyperparameters, $D_i = {(x_1, y_1), (x_2, y_2),...}$ are the labeled datasets and $D_u = {x_1,x_2,... }$ are the unlabeled datasets.\nNote that neither $L_{con}$ nor $L_{size}$, which are loss functions specifically related to the reflection, incorporate information from the data label. Instead, we leverage training information directly from KB to train the reflection. Also, despite sharing the prior feature layers, the output layer $f_2$ and reflection layer R utilize different training information, thereby decoupling the objectives of intuitive problem-solving and inconsistency reflection."}, {"title": "Experiments", "content": "In this section, we will conduct several experiments. First, we will test our method on the NeSy benchmark task of solving Sudoku to comprehensively verify its effectiveness. Next, we will change the Sudoku input from symbols to images, which requires integrating and simultaneous reasoning with both sub-symbolic and symbolic elements, representing one of the most challenging tasks in this field. Finally, we will tackle NP-hard combinatorial optimization problems on graphs, using a knowledge base of only mathematical definitions, to demonstrate our method's versatility. Through these experiments, we aim to answer the following questions:\nQ1 Compared to existing neuro-symbolic learning methods, can ABL-Refl achieve better performance in tasks requiring complex reasoning?\nQ2 Can ABL-Refl reduce the training resources required?\nQ3 Can ABL-Refl narrow the problem space for symbolic reasoning to achieve acceleration?\nQ4 Does ABL-Refl possess the capability for broad application, such as handling diverse data scenarios or various forms of domain knowledge?\nAll experiments are performed on a server with Intel Xeon Gold 6226R CPU and Tesla A100 GPU. In our experiments, we simply set hyperparameters \u03b1 and \u03b2 in Eq. (3) to 1, since adjusting them does not have a noticeable impact on the results. For the hyperparameter C in (2), we set it to 0.8, and have provided discussions in Appendix C, demonstrating that setting it to a value within a broad moderate range (e.g., 0.6-0.9) would always be a recommended choice. All experiments are repeated 5 times."}, {"title": "Solving Sudoku", "content": "Dataset and Setting. This task aims to solve a 9\u00d79 Sudoku: Given 81 digits of 0-9 (where 0 represents a blank space) in a 9\u00d79 board, we aim to find a solution y \u2208 {1,2,..., 9}81 that adhere to the Sudoku rules: no duplicate numbers are allowed in any row, column, or 3\u00d73 subgrid. In this section, we first consider inputs in symbolic form, x \u2208 {0,1,...,9}81, and use datasets from a publicly available Kaggle site (Vopani 2019).\nFor the neural network f, we use a simple graph neural network (GNN): the body block $f_1$ consists of one embedding layer and eight iterations of message-passing layers, resulting in a 128-dimensional embedding for each number, and then connects to both a linear output layer $f_2$ to obtain the intuitive output \u0177 and a linear reflection layer R to obtain the reflection vector r. We use the cross-entropy loss as $L_{labeled}$. For the domain knowledge base KB, it contains the Sudoku rules mentioned above. We express KB in the form of propositional logic and utilize the MiniSAT solver (S\u00f6rensson 2010), an open-source SAT solver, as the symbolic solver to leverage KB and perform abduction.\nFor the consistency measurement, we define it as follows: one point is awarded for each row, each column and each 3\u00d73 subgrid with no duplicate numbers, additionally, ten points are awarded if the entire board has no inconsistencies with KB. In this way, it is entirely based on KB. Notice that we deviated from the 1 or 0 measurement example setup mentioned in Section 3.4 to avoid a predominance of zero values in \u2206Con(\u0177) of Eq. (1), facilitating effective training with the REINFORCE algorithm. Similar considerations are applied in subsequent experiments."}, {"title": "Compared Methods and Results", "content": "We compare ABL-Refl with the following baseline methods: 1) Recurrent Relational Network (RRN) (Palm, Paquet, and Winther 2018), a pure neural network method, 2) CL-STE (Yang, Lee, and Park 2022), a representative method of logic-based regularized loss, and 3) SATNet (Wang et al. 2019). A detailed description of these methods is provided in Appendix A. We also report the result for Simple GNN, which is the very same neural network used in our setting, yet directly treats the intuitive output y as the final output.\nWe report the training time (for a total of 100 epochs using 20K training data), inference time (on 1K test data) and accuracy (the percentage of completely accurate Sudoku solution boards on test data) in Table 1. We may see that our method outperforms the baselines significantly, improving by over 20% while maintaining a comparable inference time. This suggests an answer to Q1: ABL-Refl can achieve better reasoning performance. This improvement is primarily due to the use of abduction to rectify the neural network's output during inference.\nFurthermore, our method reaches high accuracy in only a few epochs (training curve is shown in Appendix B), significantly reducing training time. Even considering under identical training epochs, our total training time is less than baseline methods, despite involving a time-consuming symbolic solver. This partly stems from the neural network in our approach being less complex than those in baseline methods while achieving high accuracy. Overall, this suggests an answer to Q2: ABL-Refl can reduce the training time required.\nWe also attempt to reduce the amount of labeled data, removing labels from 50%, 75%, and 90% of the training data. We record the inference accuracy in Table 2. It can be observed that even with only 2K labeled training data, our method still achieves far better accuracy than the baseline methods with 20K labeled training data. This suggests an answer to Q2 from another aspect: ABL-Refl can reduce the labeled training data required.\nComparing to Symbolic Solvers. We next compare our method with merely employing symbolic solvers from scratch, to demonstrate its capability in accelerating symbolic reasoning. We perform inference on 1K test data and record the accuracy and time in Table 3. The inference time for our method includes the combined duration for data processing through both the neural network (NN time) and symbolic reasoning (abduction time).\nAs observed in the former two lines, our method achieves a notable acceleration in the abduction process, consequently decreasing the overall inference time, with only a minor compromise in accuracy. This efficiency gain is due to the fact that in ABL-Refl, after quickly generating an intuition through the neural network, abduction only needs to focus on areas identified as necessary by the reflection vector, whereas using only symbolic solvers requires abduction to reason through all blanks in a Sudoku puzzle. Overall, this suggests an answer to Q3: ABL-Refl can quickly generate the reflection, thereby reducing the symbolic reasoning search space and enhancing reasoning efficiency.\nWe also compared with Prolog with CLP(FD) (Triska 2012) solver, by expressing the same KB with a first-order constraint logic program. As shown in the table, we observe a significant reduction in abduction time and overall inference time, which puts another evidence to our previous answer to Q3, and also suggests an answer to Q4: ABL-Refl can effectively utilize the two most commonly used forms in symbolic knowledge representation, propositional logic and first-order logic."}, {"title": "Solving Visual Sudoku", "content": "Dataset and Setting. In this section, we modify the input from 81 symbolic digits to 81 MNIST images (handwritten digits of 0-9). We use the dataset provided in SATNet (Wang et al. 2019) and use 9K Sudoku boards for training and 1K for testing.\nIn order to process image data, we first pass each image through a LeNet convolutional neural network (CNN) (LeCun et al. 1998) to obtain the probability of each digit. The rest of our setting follows from that described in Section 4.1."}, {"title": "Compared Methods and Results.", "content": "We compare ABL-Refl with SATNet, as both methods allow for end-to-end training from visual inputs. We report the results in Table 4 and the training curve in Appendix B. Compared to SATNet, ABL-Refl shows notable improvement in reasoning accuracy within only a few training epochs. We then consider pretraining the CNN in advance using self-supervised learning methods (Chen et al. 2020) and find that this can further improve accuracy. Overall, the results further suggest positive answers to Q1 and Q2.\nWe also compare with CNN+Solver: each image is first mapped to symbolic form by a fully trained CNN (with 99.6% accuracy on the MNIST dataset) and then directly fed into the symbolic solver to fill in the blanks and derive the final output. In such scenarios, the problem space for the symbolic solver includes all the Sudoku blanks, and additionally, since the symbolic solver cannot revise errors from CNN, any inaccuracies in CNN's output could lead the symbolic solver to crash (i.e., output no solution). Consequently, inference accuracy and time are adversely affected. This confirms the positive answer to Q3.\nFinally, an overview of Sections 4.1 and 4.2 also suggests an answer to Q4: ABL-Refl is capable of handling both symbolic and sub-symbolic forms of input data."}, {"title": "Solving Combinatorial Optimization Problems on Graphs", "content": "In this section, we will further expand the application domain of our method. We apply ABL-Refl to solving combinatorial optimization problems on graphs. We conduct the experiment on finding the maximum clique in this section, and provide an additional experiment in Appendix E."}, {"title": "Dataset and Setting.", "content": "In this task, we are given a graph G = (V, E) with |V| = n nodes, and aim to output y \u2208 {0,1}n, where each index corresponds to a node, and the set of indices assigned the value of 1 collectively constitute the maximum clique. Note that this problem is a challenging NP-hard problem with extensive applications in real-life scenarios, and is generally considered challenging for neural networks (Zhang et al. 2023).\nWe use several datasets from the TUDatasets (Morris et al. 2020), with their basic information shown in Table 5. We use 80% of the data for training and 20% for testing.\nIn our method, the body layer $f_1$ consists of a single GAT layer (Veli\u010dkovi\u0107 et al. 2017) and 16 gated graph convolution layers (Li et al. 2015), and the output layer $f_2$ and reflection layer R are both linear layers. We use binary cross-entropy loss as $L_{labeled}$. The domain knowledge base KB expresses the mathematical definition of maximum clique, i.e., every pair of vertices in the output set should be connected by an edge. We use Gurobi solver, an efficient mixed-integer program solver, to perform abduction. We define the consistency measurement as follows: one point is awarded for each pair of vertices if they are not connected by an edge; additionally, the size of the output set multiplied by 10 is added if the output set is indeed a clique."}, {"title": "Compared Methods and Results.", "content": "We compare our methods with the following baselines: 1) Erdos (Karalias and Loukas 2020), 2) Neural SFE (Karalias et al. 2022), both leading methods for solving graph combinatorial problems. Their detailed descriptions are provided in Appendix A.\nWe report the approximation ratios in Table 5. The approximation ratio, indicating the result set size relative to the actual maximum set size, is better when closer to 1. We may observe that our method outperforms the baseline methods, achieving near-perfect results on all datasets. This confirms the positive answer to Q1. Also, as the scale of the data increases, our method maintains a high level of accuracy, showing a more pronounced improvement compared to baseline methods. This suggests an answer to Q4: ABL-Refl is capable of handling scalable data scenarios, even in high-dimensional settings that are challenging for previous methods. Finally, an overview of this section provides another aspect to Q4: ABL-Refl can utilize a wide range of KB, not limited to logical expressions but can also operate effectively with just the basic mathematical formulations."}, {"title": "Effects of Reflection Mechanism", "content": "This section provides a further analysis on the reflection mechanism. In ABL-Refl, the reflection is abduced from domain knowledge, and acts as an efficient attention mechanism to direct the focus for symbolic search. This reflection is the key in our method to accomplish the NeSy reasoning rectification pipeline, i.e., a pipeline that detects errors in neural networks and then invokes symbolic reasoning to rectify these positions. To corroborate the effectiveness of the reflection, we conduct direct comparison with other methods that achieve the same pipeline:\n1) ABL, minimizing the inconsistency of intuitive output and knowledge base with an external zeroth-order consistency optimization module, as detailed in Section 3.2;\n2) NN Confidence, retaining intuitive output with the top 80% confidence from the neural network result (other retain thresholds are explored in Appendix D) and passing the remaining into symbolic reasoning;\n3) NASR (Cornelio et al. 2023), using a Transformer-based external selection module to detect error, and the module is trained on a large synthetic dataset in advance.\nWe compare them on the solving visual Sudoku task in Section 4.2. For a fair comparison, all methods employ the same neural network, KB and MiniSAT solver setup. We report the recall (the percentage of errors from neural networks that can be identified), inference time and accuracy (on 1K test data) in Table 6. Note that \"recall\" directly evaluates the effectiveness of the detection module itself. The following analysis examines the results:\n\u2022 The consistency optimization in ABL faces significant efficiency challenges due to the large data scale (output dimension n = 81). In such scenarios, the potential rectifications can reach up to 281, resulting in an overwhelmingly large search space for consistency optimization. Also, as an external module, its only way of interacting with KB is to treat it as a black box and repetitively submit queries for consistency evaluation. As a result, it may require more than 109 queries to identify errors for each Sudoku example, resulting in several hours to complete inference on 1K test data.\n\u2022 NN Confidence performs poorly in identifying outputs with errors. Since the pure data-driven neural network training does not explicitly incorporate KB information, a low confidence from it does not necessarily indicate an inconsistency with the domain knowledge. This subsequently results in the frequent crashing in symbolic solver, therefore hampering the overall inference time and accuracy. This result parallels human cognitive reflection abilities, which do not show much positive correlation with System 1 intuition (Pennycook et al. 2016). To further illustrate this point, we provide additional analysis, including a case study, in Appendix D.\n\u2022 Our method also outperforms NASR, and notably, without the need of a synthetic dataset. This could be due to the fact that NASR's error-selection module is trained independently from other components, and operates sequentially and separately during inference. Therefore, it can only rely on information from the output label, in contrast to our method, which can leverage information directly from the body block of neural network, establishing a deeper connection with the raw data. Additionally, in NASR, traversing the separate selection module takes additional time, whereas in ABL-Refl, the reflection is generated concurrently with the neural network output, avoiding efficiency loss."}, {"title": "Conclusion", "content": "In this paper, we present Abductive Reflection (ABL-Refl). It leverages domain knowledge to abduce a reflection vector, which flags potential errors in neural network outputs and then invokes abduction, serving as an attention mechanism for symbolic reasoning to focus on a much smaller problem space. Experiments show that ABL-Refl significantly outperforms other NeSy methods, achieving excellent reasoning accuracy with fewer training resources, and has successfully enhanced reasoning efficiency.\nABL-Refl preserves the integrity of both machine learning and logical reasoning with superior inference speed and high versatility. Therefore, it has the potential for broad application. In the future, it can be applied to large language models (Mialon et al. 2023) to help identify errors within their outputs, and subsequently exploit symbolic reasoning to enhance their trustworthiness and reliability."}]}