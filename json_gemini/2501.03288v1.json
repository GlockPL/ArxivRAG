{"title": "CodeVision: Detecting LLM-Generated Code Using 2D Token Probability Maps and Vision Models", "authors": ["Zhenyu Xu", "Victor S. Sheng"], "abstract": "The rise of large language models (LLMs) like ChatGPT has significantly improved automated code generation, enhancing software development efficiency. However, this introduces challenges in academia, particularly in distinguishing between human-written and LLM-generated code, which complicates issues of academic integrity. Existing detection methods, such as pre-trained models and watermarking, face limitations in adaptability and computational efficiency. In this paper, we propose a novel detection method using 2D token probability maps combined with vision models, preserving spatial code structures such as indentation and brackets. By transforming code into log probability matrices and applying vision models like Vision Transformers (ViT) and ResNet, we capture both content and structure for more accurate detection. Our method shows robustness across multiple programming languages and improves upon traditional detectors, offering a scalable and computationally efficient solution for identifying LLM-generated code.", "sections": [{"title": "Introduction", "content": "Recent advances in LLMs have dramatically improved their capabilities in understanding and generating code. Commercial models like ChatGPT (OpenAI 2023) and Codex (Chen et al. 2021), along with powerful tools from the open-source community such as CodeLlama (AI 2023b), CodeQwen (Academy 2023), StarCoder2 (Project 2023), and DeepSeek (AI 2023a), exhibit near-expert levels of programming proficiency. These models not only enhance the efficiency of software development but also democratize programming skills, making it easier for non-experts to engage in technology creation and problem solving. However, these technological advances present unprecedented challenges in computer science education, particularly in terms of academic integrity. As LLMs become increasingly integrated into educational settings, they can inadvertently encourage dependency, where students might rely on these tools via commercial APIs or open-source platforms to effortlessly produce high-quality code for assignments and exams. This raises concerns because the sophisticated nature of LLM outputs, which closely mimic human coding styles, complicates the differentiation between LLM-generated and student-written code (Xu, Xu, and Sheng 2024b), rendering traditional plagiarism detection ineffective. This situation underscores the pressing need for reliable and efficient tools to detect LLM-generated code.\nRecent research has introduced various methodologies for detecting model-generated code, reflecting significant advancements in this area. A prominent approach involves a pre-trained model detection system (Nguyen et al. 2023; Oedingen et al. 2024) that utilizes code as input to predict its origin, employing pre-trained feature embedding models alongside supervised learning algorithms. This system transforms code snippets into high-dimensional vector spaces and applies classifiers to ascertain whether the code was human-authored or LLM-generated. Concurrently, watermarking techniques (Lee et al. 2023; Guan et al. 2024) have been developed to embed unique identifiers directly into the outputs of Large Language Models, with some techniques utilizing grammar-guided strategies to embed multi-bit watermarks, thereby enriching the informational content of the generated code. Additionally, perturbation methods (Xu and Sheng 2024a; Shi et al. 2024; Ye et al. 2024) from DetectGPT (Mitchell et al. 2023) strategically insert or replace stylistic tokens, such as code tokens, whitespace, and newline characters, and rewrite segments to highlight the distinct patterns between machine-generated and human-authored code, facilitating accurate predictions regarding the origin of the code .\nCurrent approaches for detecting LLM-generated code face significant limitations. Pre-trained model methods, which rely on input token embeddings, are susceptible to becoming outdated as language models evolve, and struggle with scaling issues, as evidenced by OpenAI's GPT-2 detector study (OpenAI 2019) showing decreased efficacy of smaller detectors against larger models' outputs. Moreover, these methods often require specific fine-tuning for each programming language, limiting their generalizability and increasing the effort needed to maintain effective detection across multiple languages. Wang et al. (Wang et al. 2023a) demonstrated that these detectors perform poorly when applied to code-related tasks such as code summarization and generation. Watermarking techniques, while promising, may not be optimal for code detection. Suresh et al. (Suresh et al. 2024) demonstrated that semantic-preserving modifications can easily circumvent watermark detection for LLM-"}, {"title": "Watermark", "content": "SWEET (Lee et al. 2023) is a selective watermarking method for code generation. It only watermarks high-entropy tokens, balancing detection effectiveness with code quality. This approach outperformed existing methods in identifying machine-generated code while maintaining code functionality. Signal-based watermarking approaches like FreqMark and signal watermarking (Xu, Zhang, and Sheng 2024; Xu and Sheng 2024b) also demonstrated robust detection capabilities. Beyond Binary Classification (Xu, Xu, and Sheng 2024a) introduces a customizable watermarking technique embedding metadata like model origin, generation date, and user identifiers. CodeIP (Guan et al. 2024) is a grammar-guided multi-bit watermarking technique for code generation by large language models. It embeds watermarks during the code generation process by manipulating the probability distribution of the model's vocabulary. The method incorporates a type predictor to forecast the grammatical type of the next token, ensuring syntactical and semantic correctness of the generated code."}, {"title": "Perturbation", "content": "The perturbation method was first proposed and applied by DetectGPT (Mitchell et al. 2023) for machine-generated text detection. Yang et al. (Yang et al. 2023) developed a zero-shot detection method using LLMs to rewrite code and detect machine-generated content by comparing the original and rewritten code's similarity. Xu and Sheng (Xu and Sheng 2024a) introduced AIGCode Detector, which uses perplexity measures from large language models to detect LLM-generated code, employing targeted mask perturbation and comprehensive scoring. Shi et al. (Shi et al. 2024) analyzed differences between machine and human-written code, proposing the DetectCodeGPT method that detects machine-generated code by perturbing stylistic tokens like whitespace. Ye et al. (Ye et al. 2024) created a zero-shot synthetic code detector based on the similarity between code and its LLM-rewritten variants, using self-supervised contrastive learning to evaluate the method on synthetic code detection benchmarks."}, {"title": "Approach", "content": "Our approach transforms the task of detecting LLM-generated code into a 2D matrix classification problem by converting code snippets into log probability matrices and using vision models to capture spatial features and make predictions. This method leverages the unique structural characteristics of code and the power of vision models to detect subtle patterns in probability distributions. Key advantages include the preservation of code structure, allowing the model to learn from both the content and layout of the code simultaneously, language agnosticism since we work with log probabilities rather than raw tokens, enabling generalization across programming languages, and robustness to model evolution, as our approach can adapt to advancements in code generation capabilities by using the latest language models to compute log probabilities."}, {"title": "Converting Code to Log Probability Matrix", "content": "The first step in our approach is converting code snippets into log probability matrices, preserving the spatial structure of the code, including key features such as indentation, brackets, and line breaks. This process consists of three stages:\nTokenization We tokenize the input code snippet using the cl100k_base encoding, which is optimized for code-like content. This ensures that code-specific tokens, such as symbols and keywords, are accurately recognized.\nLog Probability Calculation For each token in the sequence, we compute its log probability using a large language model via the OpenAI API. The process involves iterating through the token sequence, sending each token along with the preceding ones as a prompt to the LLM, and retrieving the log probabilities for the top 10 most likely next tokens. We then extract the log probability corresponding to the actual next token in the sequence.\n2D Matrix Construction The computed log probabilities are arranged into a 2D matrix that mirrors the structure of the original code. We initialize empty matrices for both log probabilities and tokens. Each token and its corresponding log probability are processed sequentially. When a newline character is encountered, it signifies the end of a line, and the current line's log probabilities and tokens are appended to their respective matrices. This continues until all tokens are processed, ensuring that the final matrix accurately reflects the structure of the code, including indentation and line breaks. Empty spaces are filled with a placeholder value (e.g., -100) to maintain the spatial layout. The resulting log probability matrix M has dimensions n \u00d7 m, where n is the number of lines in the code and m is the maximum number of tokens in any line. Each element $M_{ij}$ represents the log probability of the j-th token in the i-th line of code."}, {"title": "Vision Models for Classification", "content": "Once we have the log probability matrix, we treat it as an image and input it into a vision model for classification. We primarily used a ViT and a modified ResNet for LLM-generated code detection. The ViT processes input patches with a projection layer, uses positional encoding for spatial information, and applies transformer encoder layers with self-attention for feature extraction, followed by a classification head. The ResNet model, adapted for single-channel input, includes convolutional layers, batch normalization, residual blocks, and a fully connected layer for classification. Both models end with global average pooling and are designed to process 2D code representations using either self-attention (ViT) or convolution (ResNet) to capture relevant features.\nVision Transformer The ViT model processes input code as a sequence of patches. The input $X \\in R^{H\u00d7W\u00d7C}$ is divided into N fixed-size patches and linearly embedded into a dimension D:\n$Zo = [xE; xE; ...;xE] + E_{pos}$"}, {"title": "Evaluation Metrics", "content": "We employ three key metrics to evaluate detector performance: AUC, FPR, and FNR. The Area Under the Receiver Operating Characteristic Curve (AUC) measures overall discrimination ability, with scores closer to 1.0 indicating better performance. False Positive Rate (FPR) represents the proportion of human-written code mistakenly flagged as LLM-generated, while False Negative Rate (FNR) shows the fraction of LLM-generated code incorrectly classified as human-written. Together, these metrics provide a comprehensive assessment of detection accuracy and error rates. Additionally, we use FLOPs (Floating Point Operations per Second) to quantify the computational resources required, allowing us to compare the efficiency of different models and methods."}, {"title": "Research Questions", "content": "Our experiment addresses three primary research questions:\nRQ 1: Performance Evaluation We assess the effectiveness of our model in detecting LLM-generated code by comparing it to established baselines. This includes analyzing performance across different code generators.\nRQ 2: Robustness Against Attacks We evaluate the model's resilience to common evasion techniques, focusing on three types of attacks: code mixing, code translation, and insertion of redundant code snippets.\nRQ 3: Impact of Model Scaling We examine how variations in model architecture and input characteristics affect detection performance. This includes analyzing the impact of different parameter scales in ResNet and ViT, investigating the influence of varying code lengths on detection accuracy, and evaluating detection speed for practical applicability."}, {"title": "Implementation Details", "content": "Log probabilities for each token were calculated using GPT-3.5-turbo-instruct with a temperature of 0 and top-p set to 1 for deterministic outputs. The dataset was generated in July 2024 via OpenAI's API, using both GPT-3.5-turbo-instruct and GPT-4-turbo. Unless noted otherwise, default parameters (temperature 0.9, top-p 0.95) were applied, similar to the ChatGPT web interface.\nWe implemented three base models: ResNet and ViT for processing 2D log probability matrices, and Transformer-XL for sequence log probabilities. Transformer-XL was chosen for its ability to handle longer sequences. The ViT model utilizes a 128-dimensional embedding, 3 Transformer encoder layers with 4 attention heads each, and a 256-dimensional MLP. ResNet was modified to a 56-layer convolutional network with 9 basic blocks per stage, across three stages. Transformer-XL has 6 layers, 8 attention heads, a 512-dimensional hidden layer, and a memory length of 50. Binary classification layers were added to all models. Training was conducted with the Adam optimizer (learning rate 1e-4), with early stopping based on validation performance.\nBaselines include DetectGPT and NPR (DetectLLM), which use a perturbation-based method masking 15% of code tokens with a span length of 2. CodeT5p-6B (Wang"}, {"title": "Impact of Model Scaling", "content": "Figure 2 illustrates the performance of ViT and ResNet architectures across various model sizes for LLM-generated code detection. Both ViT and ResNet architectures demonstrate that smaller models (0.5M to 20M parameters) achieve remarkably high AUC scores (>0.97). This suggests that the task of detecting LLM-generated code does not necessarily require large model capacities. As model size increases beyond these optimal points, we observe a performance plateau or even decline, despite substantial increases in parameter count and computational requirements (GFLOPs). These findings suggest that LLM-generated code detection may rely more on the identification of specific patterns or features that can be effectively captured by smaller models. The performance decline in larger models could be attributed to overfitting or the learning of redundant features that do not contribute to improved detection accuracy."}, {"title": "Limitations", "content": "Our approach relies on the OpenAI API for log probability matrix calculations, which increases cost and makes the method dependent on external service availability, potentially affecting performance and reliability if the API is down or restricted. Additionally, interpretability remains a challenge, as it is difficult to understand why the model makes certain predictions, especially in differentiating human-written from LLM-generated code, limiting its transparency in educational or real-world applications."}, {"title": "Future Work", "content": "Future work will focus on replacing the OpenAI API with an open-source model to reduce cost and explore whether smaller language models can effectively generate log probability matrices. We also aim to fully localize the detection process to minimize resource requirements. Another direction involves enhancing interpretability by analyzing which parts of the code are emphasized by attention mechanisms in human vs. AI code. Ablation studies will investigate how the 2D structure impacts ViT's performance by altering code indentation and structure, and we will explore visualization techniques to highlight ViT's ability to capture code patterns."}, {"title": "Conclusion", "content": "Our method improves upon existing techniques by effectively capturing the hierarchical and syntactical nature of code, leading to more accurate detection of LLM-generated content across multiple programming languages. By training vision models on log probability matrices, we enable the detection of patterns characteristic of human-written and LLM-generated code. This approach combines the strengths of large language models for computing accurate token probabilities and vision models for capturing spatial patterns, offering a powerful and flexible solution. Additionally, our method supports fast detection with minimal computational requirements, making it ideal for deployment on standard classroom computers with stable network connections. This ensures practical and efficient detection of LLM-generated code in educational settings without requiring extensive infrastructure, helping to uphold academic integrity."}]}