{"title": "Integrating Frequency Guidance into Multi-source Domain Generalization for Bearing Fault Diagnosis", "authors": ["Xiaotong Tu", "Chenyu Ma", "Qingyao Wu", "Yinhao Liu", "Hongyang Zhang"], "abstract": "Recent generalizable fault diagnosis researches have effectively tackled the distributional shift between unseen working conditions. Most of them mainly focus on learning domain-invariant representation through feature-level methods. However, the increasing numbers of unseen domains may lead to domain-invariant features contain instance-level spurious correlations, which impact the previous models' generalizable ability. To address the limitations, we propose the Fourier-based Augmentation Reconstruction Network, namely FARNet. The methods are motivated by the observation that the Fourier phase component and amplitude component preserve different semantic information of the signals, which can be employed in domain augmentation techniques. The network comprises an amplitude spectrum sub-network and a phase spectrum sub-network, sequentially reducing the discrepancy between the source and target domains. To construct a more robust generalized model, we employ a multi-source domain data augmentation strategy in the frequency domain. Specifically, a Frequency-Spatial Interaction Module (FSIM) is introduced to handle global information and local spatial features, promoting representation learning between the two sub-networks. To refine the decision boundary of our model output compared to conventional triplet loss, we propose a manifold triplet loss to contribute to generalization. Through extensive experiments on the CWRU and SJTU datasets, FARNet demonstrates effective performance and achieves superior results compared to current cross-domain approaches on the benchmarks.", "sections": [{"title": "1. Introduction", "content": "Intelligent fault diagnosis technologies, grounded in artificial intelligence methodologies, have experienced significant advancements, facilitating the precise and efficient automated monitoring of industrial equipment health status [1, 2]. The strategic deployment of this technology is an indispensable condition for realizing industrial intelligence.\nDeep learning-based fault diagnosis approaches [4, 5, 6] are particularly adept at uncovering the intricate relationships within fault data, thereby achieving promising results in the supervised setting. However, most of them assume consistent data distributions between training and testing data. In real-world industrial applications, factors such as variations in work speed, load, and mechanical equipment inevitably amplify the distribution gap between the data in the source and target domains [7, 8]. Essentially, collecting adequate training data from all possible working conditions is costly and even impossible in some practical environments. Thus, it's more common that source domain"}, {"title": "2. Related Work", "content": "Domain Adaptation (DA) methods have achieved results comparable to supervised learning, but these approaches require data from the target domain, which still presents a significant discrepancy from real-world scenarios. Domain Generalization aims to distill knowledge from source domains and apply it to unseen target domains. To extend diagnostic knowledge to unseen domains, DG methods[29, 30, 31] have been preliminarily deployed in the context of bearing fault diagnosis. For instance, Zhang et al. [32] proposed a DG method utilizing conditional adversarial training to tackle distribution changes in the target domain, yielding high fault diagnosis rates. Li et al. [33] achieved enhanced generalization through adversarial domain-enhanced training, facilitating the learning of general and enhanced features, which leads to improve model's generalization performance. For domain augmentation method, Zhao et al. [25] used a semantic regularization-based mixup strategy to generate sufficient data to tackle the issue of imbalanced domain generalization. For metric learning method, Mo et al. [34] considered instance-to-prototype distance, additional instance-to-instance and prototype-to-prototype distances and further proposed a distance-aware risk minimization framework through two novel losses. Despite the impressive performance of these methods, most of them predominantly explore spatial domain information while overlooking discriminative and generalizable information in the frequency domain. Our approach innovatively combines the extraction of domain-invariant features with domain augmentation. We leverage information in the Fourier space to reconstruct diverse frequency representations, resulting in a significant improvement on performance.\nEarly research [19] validated an important property of the Fourier transform: the phase components of the Fourier spectrum retain the high-level semantic information of the original signal, while the amplitude spectrum components contain low-level statistical information. Recently, in the researches of computer vision, Yang et al. [35] proposed integrating the Fourier transform with DA by replacing partial amplitude spectra in the source domain images with those from the target domain, thereby reducing domain differences. Xu et al. [36] introduced a Fourier-based data augmentation strategy that enables the model to capture phase information, achieving good generalization effects in unseen domains through linear interpolation of amplitude spectra which is similar to mix-up. Lin et al. [37] uncovered that Deep Neural Networks have preference on some frequency components and used Deep Frequency Filtering (DFF) to explicitly extract the components in frequency domain of different transfer difficulties across domains in the latent space during training. The previous generalizable fault diagnosis method [38] only proposes a Fourier transform at the level of data pre-processing. To the best of our knowledge, Fourier-based data augmentation fault diagnosis is the firstly introduced in the cross-domain fault diagnosis. We propose a Fourier-based data augmentation reconstruction module and manifold deep metric learning to explore the potential information to improve the performance under unseen working conditions."}, {"title": "3. Method", "content": "Influenced by industrial factors (i.e., working load, vibration frequency and temperature), the data distribution gap significantly affects the performance of fault diagnosis models. Previous works rarely focused on feature extraction in the frequency domain, despite its proven effectiveness in alleviating domain-shift issues. To address this gap, we introduce a Fourier-based Augmentation Reconstruction Network designed to effectively capture discriminative and generalizable information in the frequency domain by reconstructing frequency representations.\nFirst, we revisit the definition and properties of the Fourier transform. For a signal x with the shape of C\u00d7H\u00d7W, its Fourier transformation F(x) is formulated as:\n$F(x)(c, u, v) = X(c, u, v)\nH-1 W-1\n= \\sum\\sum x(c, h, w)e^{-j2\\pi(\\frac{uh}{H}+\\frac{vw}{W})},\\quad\\quad(1)$"}, {"title": "3.2. The Fourier-based Augmentation Reconstruction Network", "content": "Based on the aforementioned analysis, we introduce a simple yet effective FARNet, illustrated in Fig.3. The entire network comprises an amplitude spectrum sub-network and a phase spectrum sub-network, dedicated to reconstructing and enhancing amplitude and phase representations. Additionally, both sub-networks incorporate FSIM as a fundamental module to facilitate feature extraction and reconstruction by integrating both global and local spatial information. Further details on this aspect will be discussed in Section 3.3. The figure above illustrates the flow that samples from domain A are the input and the Fourier-based Augmentation Reconstruction Network strives to pull the input to align with the samples from domain B in the perspectives of amplitude and phase while .\nThe amplitude sub-network adopts an encoder-decoder architecture, comprising five FSIMs for amplitude reconstruction, where the Encoder FSIMs are the squeeze modules, FSIM keeps the dimensions unchanged and the Decoder FSIMS strive to expand and reconstruct the xin. Among multiple source domains, we select one domain (working condition) as the ground truth, denoted by xgt, while the remaining source domain data are denoted as xin and the output of the amplitude sub-network is denoted as Xout1. They are represented in the Fourier space as Xgt, Xin, and Xout1. To guide the learning of amplitude representations, this sub-network is supervised by the ground truth amplitude A(Xgt). The loss function of the amplitude sub-network, denoted as $\\mathcal{L}_{amplitude}$, is described as:\n$\\mathcal{L}_{amp} = ||A(X_{out1}) - A(X_{gt})||_1,\\quad\\quad(3)$\nwhere ||.||1 represents the mean absolute error.\nIn the phase sub-network, four FSIMs are employed for the phase representation where the former two blocks fuse the residual from Amplitude Sub-Network. To ensure consistency of phase components, we use the reconstructed component $F^{-1}(A(X_{out1}), P(X_{in}))$ instead of xout1 as input to the sub-network. Additionally, considering variations in the sampling environment of bearing fault data, where structural components are sensitive to environmental factors, we leverage the residual of the outputs from amplitude sub-network and xin to capture domain shift differences (variations on speeds and fault diameters). By connecting the residuals of Xout1 and Xin with the feature input of this sub-network through 1\u00d71 convolutions, we guide its learning process. The output of the phase sub-network is denoted as Xout2, and the loss function $\\mathcal{L}_{phase}$ for this sub-network is expressed as:\n$\\mathcal{L}_{pha} = ||P(X_{out2}) - P(X_{gt})||_1.\\quad\\quad(4)$\nFARNet's data augmentation module is composed of these two sub-networks for end-to-end training. Therefore, the overall loss $\\mathcal{L}_{aug}$ of this augmentation module is formulated as:\n$\\mathcal{L}_{aug} = \\lambda_1\\mathcal{L}_{amp} + \\lambda_2\\mathcal{L}_{pha},\\quad\\quad(5)$\nwhere $\\lambda_1$ and $\\lambda_2$ are the weight factors."}, {"title": "3.3. Frequency-Spatial Interaction Module", "content": "According to Fourier theory [39], processing information in Frequency domain allows the model to capture global representations, while convolutional operations focus primarily on learning local spatial features. Motivated by this insight that enhances the learning of amplitude and phase representations, we introduce the Frequency-Space Interaction Module (FSIM) as the feature-fusion block for both the amplitude and phase sub-networks, enhancing their feature representation capabilities.\nThe amplitude format of FSIM is depicted in Fig.4, comprising both a frequency flow and a spatial flow. Initially, f\u2081, representing features from the source domain data, is input into FSIM. In the spatial flow, it undergoes processing through a Conv Block, utilizing multiple 3\u00d73 2-D convolutional layers to enhance spatial domain information, yielding fs1. Simultaneously, the frequency flow processes f\u2081 with a 1 \u00d7 1 2-D convolution, resulting in fo. Subsequently, it reconstructs phase and amplitude in the frequency domain through Fourier transformation. Amplitude information is extracted using a Conv Block comprising multiple 1 \u00d7 1 2-D convolutional layers, producing ff1 as the output of frequency domain processing. The representation of ff1 is defined as:\n$ff_1 = F^{-1}(Conv_{1\\times1}(A(F_{f0})),P(F_{f0})),\\quad\\quad(6)$\nwhere $Conv_{1\\times1}$ denotes the 1 \u00d7 1 operation.\nThen, ff1 and fs1 are separately fed into a 3 \u00d7 3 convolutional layer to facilitate the interaction of features between the frequency and spatial flows. In this case, ff1 and f\u2081\u2081 can be expressed as:\n$ff_1 = ff_1 + Conv_{3\\times3}(f_{s1}),\\quad\\quad(7)$\n$f_1 = f_{s1} + Conv_{3x3}(ff_1),$\nwhere Conv3x3 is represented as the 3 \u00d7 3 operation.\nAs shown in Fig.4, we observe that both ff1 and f\u2081\u2081 acquire complementary feature representations effectively aiding in the extraction of more discriminative features. Then, the frequency and spatial flows follow similar operations sequentially, culminating in an output fo from FSIM after passing through a final 1 \u00d7 1 convolutional layer.\nSimilarly, for the phase components of the FSIM, we replace the operations on the amplitude components in the frequency flow with operations on the phase components, while keeping the remaining structure unchanged."}, {"title": "3.4. Manifold Triplet Loss", "content": "In paper [40], the author highlighted the effectiveness of using Euclidean neighbors as positive training instances to separate different classes into distinct subspaces. However, this may not be necessary in the manifold space. Therefore, we propose a modified triplet loss, namely the manifold triplet loss. In the manifold triplet loss, we replace the Euclidean distance in the triplet loss with the distance designed through a non-linear activation function $d_{new}()$:\n$d_{new}(x) = \\begin{cases}\n    kx, & \\text{if } x > r\\\\\n    x & \\text{if } x \\leq r\n\\end{cases},\\quad\\quad(8)$\nwhere x denotes the euclidean distance between two samples, r is the constant threshold and k is the weight factor, respectively.\nBy applying this activation operation to the Euclidean distances, we break the triangle inequality property of Euclidean space, where the sum of any two sides is greater than the third side. This characteristic enables us to explore not only the nearest neighbors but also encourages detour calculations when conducting depth measurements in manifold spaces. Specifically, we scale up long distances by a factor of k while reducing short distances by a factor of k, encouraging detours when performing depth measurements in manifold spaces. Thus, the calculation of the manifold triplet loss is defined as follows:\n$\\mathcal{L}_{manifold-triplet} = max(d_{new}(x) - d_{new}(x) + \\gamma, 0),\\quad\\quad(9)$\nwhere $d_{new}(x)$ and $d_{new}(x)$ denote the manifold distance of the hardest positive sample and negative sample in a batch respectively, and $\\gamma$ represents the margin of triplet loss."}, {"title": "3.5. Optimization", "content": "Aggregating all loss functions, we can obtain the training objective of FARNet as follows:\n$\\mathcal{L}_{total} = \\mathcal{L}_{aug} + \\mathcal{L}_{clf} + \\alpha\\mathcal{L}_{manifold-triplet},\\quad\\quad(12)$\nwhere \u03b1 is the weight factor to balance the convergence of the two modules."}, {"title": "4. Experiment", "content": "In this section, we demonstrate the superiority of our approach compared to several Domain Adaption and Domain Generalization methods. We also conduct ablation experiments on some hyperparameters and finally validate the effectiveness of our approach through visualization."}]}