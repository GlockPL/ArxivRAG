{"title": "Improving Radiology Report Conciseness and Structure via Local Large Language Models", "authors": ["Iryna Hartsock", "Cyrillo Araujo", "Les Folio", "Ghulam Rasool"], "abstract": "We aim to improve radiology reporting by enhancing report conciseness and structuring (also known as templating) the findings according to organs, enabling physicians to locate relevant information quickly. We employ LLMs (e.g., Mixtral, Mistral, and Llama) to create concise, well-structured reports, primarily focusing on the Mixtral model due to its superior adherence to a specific output formatting requirement compared to other models. We run these LLMs locally behind our institution's firewall, ensuring the safety and privacy of data. In addition, we utilize the LangChain framework and five different prompt approaches to enforce a specific structure in radiology reporting and remove excessive words and phrases to enhance the conciseness of reports. We introduce a new metric, the Conciseness Percentage (CP) score, to evaluate report conciseness. Our dataset comprises 814 radiology reports from seven board-certified body radiologists from our cancer center. Our study evaluated various prompting approaches to condensing and structure radiology reports. Our results demonstrate that first prompting the LLM to make the report concise and then structuring it according to specific instructions given in the prompt is the best approach for creating concise, well-structured reports. We assessed all prompting methods based on how they handled formatting errors, reduced report length, and followed formatting instructions. We show that open-source and locally run LLMs can improve the conciseness and structure of radiology reports according to specific instructions.", "sections": [{"title": "Introduction", "content": "A significant challenge in radiology reporting is that reports tend to be overly verbose and poorly structured, making it difficult for referring physicians to discern crucial findings and potentially overlooking important information (1,2). Implementing structured (templated) reporting methods provides a viable solution, enabling physicians to access relevant information efficiently (3\u20135). Imaging findings can be structured in various ways, such as organizing them from head-to-toe, prioritizing from the most critical to the least important, and/or itemizing them by specific organs (6,7). Removing redundancies, unnecessary words, and phrases from a radiology report without compromising its meaning further enhances interpretation efficiency (8,9). Ultimately, well-structured and concise radiology reporting is not just about documentation; it is crucial for delivering high-quality healthcare (2,3,10).\nIn recent years, numerous studies have explored using LLMs to improve the readability of radiology reports (11\u201314). LLMs are powerful artificial intelligence (AI) models capable of analyzing and generating human-like natural language text (15\u201319). For instance, Jeblick et al. used ChatGPT to simplify radiology reports for a child's understanding (11). While 15 radiologists generally found the simplified reports to be factually accurate and not harmful, some noted errors and overlooked details. Adams et al. employed GPT-4 to transform 170 free-text CT and MRI reports into structured formats by selecting the best templates from a predefined list, achieving successful conversions for all reports (12). Additionally, Mallio et al. demonstrated the efficacy of ChatGPT-3.5 Turbo and GPT-4 models in reducing the verbosity of radiology reports (13). However, a key limitation of these three studies is the use of application programming interfaces (APIs) or LLMs provided as a service on the Internet, which often involves sharing data with third parties or using synthetically-generated radiology reports (11\u201313). Using external LLMs raises concerns regarding data privacy, security, adherence to"}, {"title": "Materials and Methods", "content": "In this retrospective IRB-approved quality improvement study, we sample 814 radiology reports collected from seven board-certified body radiologists at our Cancer Center. The reports were generated from CT exams of the chest, abdomen, and pelvis and were written in the years 2023 and 2024. Each report comprises two sections: \"Findings\", which describes medical observations in these regions, and \"Impressions\", which summarizes key findings. The length of the reports varies from 182 to 981 words, with a mean of 372 words and a median of 344 words. While most reports are structured by organs, they lack a consistent formatting style due to differing approaches among radiologists. Before analysis, all reports were de-identified to ensure patient confidentiality."}, {"title": "Large Language Models (LLMS)", "content": "The study employs the Mixtral 8x7B LLM, which utilizes a sparse mixture-of-experts (SMoE) architecture with a total of 56B parameters (i.e., eight experts, each with approximately 7B parameters) (15). For efficiency, the study employed pre-existing 6Q quantized weights of Mixtral. In the Mixtral architecture, each layer incorporates eight distinct feedforward expert blocks. During inference, based on the specific characteristics of each token, two out of these eight experts are selected to process the input, and thus, only 14B parameters are active during inference. Mixtral benefits from a substantially large context window of 32,768 tokens and was pre-trained on multilingual data extracted from the open web (15). Mixtral was selected over other LLMs, including Mistral 7B (16) and Llama 3 8B (18), due to its superior adherence to a specific output formatting requirement compared to other models. All LLMs were run locally behind a secure firewall using the Ollama framework to ensure data security and privacy (22). The temperature of the LLMs was set to zero to reduce randomness and ensure more consistent outputs."}, {"title": "Prompt Engineering (In-Context Learning)", "content": "We employed the LangChain library to programmatically prompt LLMs (23). The LLMs used in our experiments were downloaded from the Ollama store and were not fine-tuned or updated in any manner. Each report was processed with one or two calls to the LLM to enforce adherence to the structure depicted in Figure 1. Our study explored five distinct prompt approaches:\n*   Structure: This approach used only a single prompt to structure reports in a predefined format (see Supplementary Figure 1).\n*   Structure >> Conciseness: The LLM was initially prompted to structure the reports in a specified format. Subsequently, a second prompt instructed the model to refine the structured output further for conciseness. Thus, each report processing consisted of two calls to the LLM (see Supplementary Figure 2).\n*   Conciseness >> Structure: The LLM was first prompted to generate concise reports and then instructed to organize the concise information into a predefined structure. In this case, each report processing consisted of two calls to the LLM (see Figure 2)."}, {"title": "Concise Percentage (CP) Score", "content": "We introduce a Concise Percentage (CP) score to evaluate the conciseness of the radiology reports by measuring the percentage of \"meaningful\" words in the report. Assuming that all words in the LLM-generated report are meaningful, the CP score is computed as follows:\n$CP Score = \\frac{Total\\ number\\ of\\ words\\ in\\ LLM\\ generated\\ Report}{Total\\ number\\ of\\ words\\ in\\ Original\\ Report} \\times 100%$.\nA CP score near 100% indicates that the original report was already relatively concise, requiring the LLM to remove a small number of words. Conversely, a lower CP score suggests that the original report was less concise and required significant condensation by the LLM. A CP score exceeding 100% is also possible, as the LLM can be verbose and add content, potentially lengthening rather than condensing the report. While the CP score is valuable for evaluating the LLM effectiveness in reducing unnecessary content and improving report conciseness, it does not fully reflect the clinical utility or relevance of a radiology report's content. Also, we may get a different CP score for the same report due to the different prompts or models used for processing the report."}, {"title": "Results", "content": "We processed radiology reports with different LLM prompting strategies, assessing their effectiveness in handling formatting errors, streamlining the unstructured radiology reports, and managing different radiologists' report writing styles."}, {"title": "Formatting Errors of LLMs", "content": "We observed two types of formatting errors in the radiology reports processed by LLMs. The first type of error occurs when the LLM fails to structure a report according to the format shown in Figure 1 after two attempts. In the second type of error, the LLM generates a list of individual letters from impressions rather than the full impressions. This results in an excessively long list of impressions and CP scores exceeding 100%. We excluded such reports from further analysis. Also, a report might have formatting issues with one prompting method but not others. In such cases, we excluded the report only for the problematic prompting approaches.\nIn this study, we focus on the Mixtral LLM, as it has the lowest rate of formatting errors compared to Mistral 7B (v0.2) and Llama 3 8B. Llama 3 8B struggled significantly with following the formatting instructions. For instance, under the \"Conciseness >> Structure\" prompting approach, Llama 3 8B caused formatting errors in 726 (89.2%) reports. The Mistral 7B performed more similarly to Mixtral in adhering to formatting instructions. Under the \"Conciseness >> Structure\" prompting approach, Mistral 7B produced formatting errors in 107 (13.1%) reports, while Mixtral had formatting errors only in 88 (10.8%) reports."}, {"title": "Streamlining an Unstructured Radiology Report: A Case Study", "content": "We applied the Mixtral LLM to the radiology report with unstructured findings (see Figure 3 A) to assess its ability to structure the report while enhancing its conciseness. The resulting structured and concise reports generated using five different prompting strategies are shown in Figure 3 B-F. All CP scores of the LLM-streamlined reports range from 49.7% to 62.4%. The \"Structure\" approach, which only prompts the LLM to follow formatting instructions without emphasizing conciseness, achieved the highest CP score and reduced the report length by 37.6%. The lowest CP scores had the \"Conciseness >> Structure\" and \"Structure + Conciseness (F, I)\" methods, indicating they made the reports the most concise.\nWe observed significant variation in how Mixtral handled the \u201cImpressions\u201d section. With the \"Conciseness >> Structure\" and \"Structure + Conciseness (F, I)\" approaches, Mixtral extracted and condensed content directly from the \"Impressions\" section as instructed. In contrast, with the other three strategies, Mixtral relied more on information from the \"Findings\" section to generate \"Impressions\", deviating from the intended prompt instructions.\nWhile Mixtral processed the \"Findings\" section similarly across prompting approaches, we noticed several discrepancies. We instructed Mixtral to extract findings for an organ, specifying that \"Unremarkable\" should be used for normal findings and \"None\" for the absence of findings (see Figure 2). As shown in Figure 3 B, E-F, Mixtral incorrectly indicated no findings for the hepatobiliary system and adrenals, possibly due to failure to identify certain findings or misclassifying them as \"None\"."}, {"title": "Evaluation of Conciseness and Prompting Approaches Across Radiologists", "content": "For each participating radiologist, we computed the CP scores for their sampled reports using five prompting approaches. These scores are represented using boxplots in Figure 4, illustrating their distribution, quartiles, and outliers. The figure also reveals consistent trends in concise report writing among radiologists, with Radiologist 1 producing the least concise reports and Radiologist 7 the most concise, regardless of the prompting method. Figure 5 compares the average word count of original reports and their successfully LLM-processed versions (where CP \u2264 100%) using the \"Conciseness >> Structure\" strategy across all radiologists. Similarly, it also compares the total word count for a sample of reports, illustrating Mixtral's effectiveness in reducing verbosity."}, {"title": "Discussion", "content": "In this study, we demonstrated that LLMs, locally run behind institutional firewalls on a Windows Desktop with GeForce RTX 3060 GPU with 12 Gigabytes of VRAM, can effectively enhance the conciseness and structure of radiology reports. When we refer to \"structured reports\", we mean reports that are \"templated\" by organs, which differs from the ACR RADS definition that includes detailed categorization and management recommendations, potentially incorporating CDE macros (modules). In our initial experiments, we utilized several state-of-the-art open-source LLMs like Mixtral (15), Mistral (16), and Llama 3 (18). However, we focused our efforts on Mixtral due to its comparatively lower rate of formatting errors. We evaluated five different prompting methods using Mixtral across 814 radiology reports of the chest, abdomen and pelvis written by seven body radiologists, assessing the Mixtral's ability to reduce report length, minimize formatting issues, and follow prompt instructions. To our knowledge, this study is among the first to explore the application of LLMs in private, resource-constrained environments for processing radiology reports, underscoring the potential of locally deployed models in clinical settings.\nAmong the various prompting strategies tested, the \"Conciseness >> Structure\" approach proved to be the most effective. This method prioritized conciseness first, followed by addressing formatting issues, and excelled in keeping the report length within the original limits while adhering closely to the prompting instructions. We believe this strategy is superior because condensing the radiology reports first simplifies the subsequent formatting task, reducing the risk of omitting relevant details during the formatting phase. Notably, the \"Structure + Conciseness (F, I)\" approach, which prompted the LLM separately for the \"Findings\" and \"Impressions\" sections, yielded the fewest formatting errors among all methods. This suggests that focused prompting for specific sections can improve accuracy in structure without compromising content.\nWe proposed using the CP score to evaluate the conciseness of radiology reports before and after processing by LLMs. By measuring the percentage of \"meaningful\" words, the CP score highlights opportunities to reduce report length while preserving essential content. However, caution is warranted when using this metric, as not all words contribute equally to the clinical relevance of a report. Certain words or phrases, though they increase the word count, may be vital for clinical interpretation, and removing them in the pursuit of conciseness could compromise the report's accuracy. The CP score can facilitate peer benchmarking, motivating radiologists to improve conciseness while maintaining both clinical relevance and informational integrity. Incorporating the CP score into training programs could further support radiology residents in tracking their progress in producing concise reports. Nevertheless, the CP score should not solely drive decisions about content reduction, as the clinical significance of specific details may outweigh the benefits of brevity and conciseness.\nWe observed several limitations that may be associated with the use of locally-run LLMs. One of the major challenges was the occurrence of formatting errors, which appeared in 23 to 181 reports across the five prompting strategies. These errors may be less frequent in API-based LLMs, which are often more robust due to extensive pre-training and broader infrastructure. Additionally, despite our efforts to ensure that Mixtral followed prompt instructions accurately, it occasionally missed key medical findings, particularly for organs such as the hepatobiliary system, pancreas, spleen, and adrenals, incorrectly marking them as \"None.\" This issue was least frequent with the \"Conciseness >> Structure\" approach. However, it is important to note that this limitation is not unique to smaller, locally-run LLMs; larger API-based models can also struggle to follow prompts accurately under certain conditions. Another notable issue was that 61 LLM-processed reports ended up longer than the original versions, contrary to the objective of producing concise outputs. On rare occasions, Mixtral even assigned medical findings to multiple organs simultaneously or to less relevant organs, further highlighting the need for ongoing refinement in prompting strategies and model training/fine-tuning. However, we intentionally limited our current study to prompt-only without any model fine-tuning.\nIn summary, our study demonstrates Mixtral's capability to streamline and structure radiology reports, with the \"Conciseness >> Structure\" prompting approach proving particularly effective. Despite these strengths, challenges such as formatting errors and the omission of medical findings for certain organs persist. Future work will focus on addressing these limitations through prompt refinement, expanding the LLM's vocabulary to include missing medical terminology, and incorporating feedback from participating radiologists. Additionally, model fine-tuning will be explored to improve performance in clinical contexts. These enhancements will contribute to more precise and clinically relevant report generation, ultimately advancing the practical application of LLMs in medical environments."}]}