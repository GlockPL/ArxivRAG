{"title": "Langya: Revolutionizing Cross-Spatiotemporal Ocean Forecastin", "authors": ["Nan Yang", "Chong Wang", "Meihua Zhao", "Zimeng Zhao", "Huiling Zheng", "Bin Zhang", "Jianing Wang", "Xiaofeng Li"], "abstract": "Ocean forecasting is crucial for both scientific research and societal benefits. Currently, the most accurate forecasting systems are global ocean forecasting systems (GOFSs), which represent the ocean state variables (OSVs) as discrete grids and solve partial differential equations (PDEs) governing the transitions of oceanic state variables using numerical methods. However, GOFSs processes are computationally expensive and prone to cumulative errors. Recently, large artificial intelligence (AI)-based models significantly boosted forecasting speed and accuracy. Unfortunately, building a large AI ocean forecasting system that can be considered cross-spatiotemporal and air-sea coupled forecasts remains a significant challenge. Here, we introduce LangYa, a cross-spatiotemporal and air-sea coupled ocean forecasting system. Results demonstrate that the time embedding module in LangYa enables a single model to make forecasts with lead times ranging from 1 to 7 days. The air-sea coupled module effectively simulates air-sea interactions. The ocean self-attention module improves network stability and accelerates convergence during training, and the adaptive thermocline loss function improves the accuracy of thermocline forecasting. Compared to existing numerical and AI-based ocean forecasting systems, Lang Ya uses 27 years of global ocean data from the Global Ocean Reanalysis and Simulation version 12 (GLORYS12) for training and achieves more reliable deterministic forecasting results for OSVs. LangYa forecasting system provides global ocean researchers with access to a powerful software tool for accurate ocean forecasting and opens a new paradigm for ocean science.", "sections": [{"title": "1 Main", "content": "Ocean forecasting aims to forecast future ocean dynamic states and is crucial for understanding ocean activities. Numerical global ocean forecasting systems (GOFSs), such as the Mercator Ocean physical system (PSY4) and the Real-Time Ocean Forecasting System (RTOFS), rely on geophysical fluid dynamics and partial differential equations (PDEs) to describe future ocean conditions, and such systems remain widely used worldwide. However, improving the inference accuracy and speed of numerical forecast models is a significant challenge. First, numerical forecasting heavily depends on parameterizations and the extent of human knowledge regarding oceanic physical laws. Approximation functions can exacerbate forecast errors. In addition, even on supercomputers equipped with hundreds of computing nodes, it takes several hours to generate a single forecast. Large AI models are reshaping interactions between humans and technology through their massive learning parameters and powerful learning capabilities, e.g., ChatGPT and Sora. Such advances open the way for the development of geophysical system forecasting, including large AI models for weather (e.g., Fourcast-Net, PanGu-Weather) and ocean (e.g., XiHe [1], AI-GOMS [2]) forecasts. These large models are mainly data-driven, recasting air state variables (ASVs) and ocean state variables (OSVs) forecasting problems as autoregressive video generation, thereby avoiding much computational complexity and uncertainties inherent in physical pro-cesses. Moreover, specialized computing devices such as graphics processing units (GPUs) offer extremely fast inference speeds. By investigating and practicing ocean forecasting, we summarize two key barriers in current large ocean forecasting models: (1) Future OSVs are forecasted autoregressively in a step-by-step manner, with temporal information not incorporated into the training and inference processes. It neglects the time-dependent evolution of OSV fields and their interdependencies, making it impossible to achieve cross-timescale forecasts. (2) Air and ocean data are concatenated as model inputs to represent air-sea interactions, a simple way that cannot effectively simulate these interactions nor integrate their underlying mechanisms into the training and inference processes. Although researchers agree that large AI models hold tremendous potential for ocean forecasting, it should be acknowledged that revolutionary breakthroughs are still needed before an AI ocean forecasting system capable of cross-timescale, air-sea coupled forecasts can be realized. Fortunately, the breakthroughs have now come as expected. Here, we present the LangYa forecasting system (see the Methods section for \"LangYa\"), a powerful large AI-based model for cross-spatiotemporal, air-sea coupled ocean forecasting. Lang Ya delivers faster and more accurate forecasts for OSVs (temperature, salinity, and currents) than both traditional numerical weather prediction (NWP) systems and XiHe (an influential large AI-based model). Our contributions are fourfold: (1) We propose a large-language-model-based (LLM-based) Time Embedding Module that achieves high spatiotemporal resolution (1/12\u00b0, 1 day) forecasts for OSVs. It enables cross-timescale forecasts (up to 7 days) without iterative steps, allowing training and inference for future 7-day OSVs with one-off. (2) We develop an asynchronous cross-iterative random sampling strategy to simulate the atmospheric's stochastic interaction with the ocean, improving the forecasting skill for variables with different rates of change, such as sea temperature and currents. (3) We introduce an ocean self-attention module based on cosine attention,"}, {"title": "2 Cross-SpatioTemporal and Air-Sea Coupled Ocean Forecasting System", "content": "LangYa adopts the idea of data-driven that builds ocean forecasting as a video pre-diction task. The design contains training and testing phases by using oceanic and atmospheric reanalysis data as inputs and generating forecasts for Ocean State Vari-ables (OSVs) - such as sea temperature, salinity, and currents through single-pass inference over 1-7 days. The system uses 11,322 samples and mitigates overfitting risks by randomly shuffling sample order at the beginning of each training iteration. The training was conducted using a distributed data-parallel (DDP) strategy on a cluster of 16 NVIDIA A800 GPUs, completed in just 14 days. The core architecture of the LangYa system is shown in Figure 1a, which integrates multiple innovative components. The input state variables include ASVs, which are u- and v-components of wind speed, temperature, and relative humidity across 1000 to 200 hPa. Sea Surface State Variables (SSSVs): u- and v-components of 10-m wind speed, sea surface temperature, and mean sea level pressure. OSVs: Temperature, salinity, and currents spanning depths of 0 to -500 m. OSVs, ASVs, and SSSVs derived from the European Centre for Medium-Range Weather Forecasts (ECMWF) fifth-generation reanalysis dataset (ERA5) and GLORYS12 reanalysis datasets. The data is complemented by temporal information processed via a time-embedding module based on LLM (Figure 1b). The module extracts spatial features for individual time steps and temporal fea-tures across multiple time steps, and then integrates prior knowledge from the LLM to encode forecast durations. The unique fusion of spatiotemporal data supports highly efficient cross-spatiotemporal forecasting. A key innovation of LangYa is its Asynchronous Cross-Iterative Random Sampling Strategy (Figure 1c), which adaptively links ASVs, SSSVs, and OSVs to simulate air-sea interactions. Unlike traditional meth-ods that rely on physics-based assumptions or simple data concatenation, this strategy learns spatiotemporal relationships and effectively captures air-sea variation patterns, significantly enhancing forecast accuracy without introducing additional physical con-straints. The processed input data are passed through an encoder-decoder architecture equipped with an Ocean Self-Attention Module (Figure 1d). The module, based on cosine attention, ensures stable training and accelerates convergence by reducing gra-dient explosions common in high-dimensional data processing. Additionally, Lang Ya incorporates an Adaptive Thermocline Loss Function (Figure le) to address the chal-lenges of forecasting thermocline mutations. The loss function is tailored to capture the steep vertical gradients and dynamic variability of the thermocline, improving"}, {"title": "3 Experimental Setting and Main Results", "content": "The study trained the LangYa forecasting system using reanalysis data (GLORYS12 and ERA5) and evaluated it with both reanalysis (GLORYS12) and observational datasets. The observational datasets are derived from the GODAE Ocean View Inter-comparison and Validation Task Team (IV-TT) Class 4 framework, which provides observation datasets from Argo, Jason-1, Jason-2, and Envisat CLS AVISO level 3 satellite altimeters. 27 years of GLORYS12 data (1993-2019) were used for training LangYa, while data from 2020-2021 were reserved for testing. LangYa forecasts 128 variables, including temperature, salinity, and zonal and meridional ocean currents across 32 depth layers. Compared with reanalysis and observational data, LangYa achieved lower RMSEs for temperature and ocean currents (both zonal and merid-ional) than XiHe, XiHe-Autoregression (XiHe-AR), PSY4, BLK, GIOPS, and FOAM numerical models (Figure 2). Notably, the released XiHe version consists of 20 separate models, each designed to forecast OSVs for 1-10 days in either the upper or lower ocean layers. XiHe-AR refers to an autoregressive approach that generates multiday forecasts by sequentially chaining two 1-day XiHe models, resulting in higher cumulative errors. For salinity, LangYa's forecast accuracy was comparable to XiHe and the numerical models but outperformed XiHe-AR.\nIn addition, Lang Ya achieved an inference time of 1 second for forecasts of any scale (1-7 days) on a single GPU, which is over 10,000 times faster than operational numerical models. Results from the 2020-2021 test data indicate that Lang Ya provided \"perfect\" quantitative forecasts (RMSE), particularly for challenging ocean phenomena such as thermoclines. Compared to the world's leading OSVs forecasting systems (e.g., XiHe, PSY4, BLK, GIOPS, and FOAM numerical models), Lang Ya significantly reduced cumulative forecast errors and demonstrated remarkable improvements in thermocline forecasting.\nBoth quantitative and qualitative experimental results confirm that the AI-based LangYa forecasting system for OSVs holds tremendous potential for practical applications.\nFigure 3 illustrates the RMSE of LangYa's forecasts for temperature and salinity at 1, 4, and 7 days. Spatially, LangYa achieves RMSEs below 0.3\u00b0C for temperature forecasts across most ocean regions. Areas with higher RMSEs are concentrated in the western boundary currents (e.g., the Kuroshio Extension, Gulf Stream), east-ern boundary currents (e.g., the Peru Current, California Current), and the Somali Current. These regions experience intense temperature variations, making them challenging to forecast accurately using numerical models or XiHe. Nevertheless, LangYa demonstrates significant advantages in these areas. For salinity, LangYa achieves RMSEs below 0.05 psu across most ocean regions, particularly in open oceans. Higher RMSEs are observed near the equator, western boundary currents, and the Indonesian Throughflow region, where salinity is heavily influenced by complex processes such as evaporation, precipitation, river runoff, and water mass exchange. Despite these"}, {"title": "4 Thermocline Forecast", "content": "The thermocline, a transitional layer in the ocean characterized by a sharp temperature gradient, is a critical interface for energy exchange, water mass mixing, and biogeochemical processes. Typically located at depths of 100-200 m, the thermocline exhibits complex regional and seasonal variations due to its involvement in multiple coupled physical processes, such as ocean stratification, vertical mixing, and air-sea interactions. Accurate forecasting of the thermocline is essential for advancing the"}, {"title": "5 Discussion", "content": "LangYa forecasting system addresses the bottlenecks in cross-temporal, air-sea cou-pled, and thermocline forecasting. By integrating Time Embedding, air-sea interaction simulation, and adaptive loss function for thermocline, Lang Ya demonstrates significant advantages in forecasting OSVs across temporal scales. Compared with other forecasting systems (e.g., GOFSs and XiHe), Lang Ya completes global OSVs inferenc-ing within a short period and exhibits superior performance in accuracy, timeliness, and stability, offering feasibility for real-time ocean forecasting deployment.\nTraditional ocean forecasting systems rely on iterative processes to estimate future OSVs, which are computationally expensive and prone to cumulative errors. Lang Ya overcomes the limitations by employing a Time Embedding module, enabling forecasts for up to 7 days without iterative steps. The innovation enhances its cross-temporal forecasting capabilities and improves forecasting flexibility and efficiency. In terms of simulating air-sea interactions, Lang Ya utilizes an asynchronous cross-iterative random sampling strategy, successfully overcoming the simplistic concatenation of air-sea"}, {"title": "6 Methods", "content": ""}, {"title": "6.1 Dataset", "content": "The OSVs data used in LangYa are derived from the GLORYS12 reanalysis data. GLORYS12 was developed and implemented under the framework of the Copernicus Marine Environment Monitoring Service (CMEMS) [28]. It has a horizontal resolution of 1/12\u00b0, 50 vertical layers, and a temporal spanning from January 1993 to December 2021. Due to its high resolution, temporal continuity, long coverage period, and excellent data quality, GLORYS12 has become the preferred dataset for large model development. Considering the important role of air-sea interactions in ocean dynam-ics, LangYa incorporates ASVs (u- and v-components of wind speed, temperature, and relative humidity at 200, 500, 850, and 1000 hPa) and SSSVs (u- and v-components of 10-m wind speed, sea surface temperature, and mean sea level pressure) in the design. The ASVs and SSSVs data are sourced from the ERA5, which has a spatial resolution of 0.25\u00b0 and includes 37 vertical pressure levels."}, {"title": "6.2 Data Preprocessing", "content": "The input data for LangYa includes a total of 149 variables, categorized as follows: (1) 5 SSSVs: sea surface temperature, sea surface height, mean sea level pressure, u-, and v-components of 10-m wind speed. (2) 128 OSVs: These are distributed across 32 vertical depth layers (0.49, 1.54, 2.65, 3.82, 5.08, 6.44, 7.93, 9.57, 11.41, 13.47, 15.81, 18.50, 21.60, 25.21, 29.44, 34.43, 40.34, 47.37, 55.76, 65.81, 77.85, 92.32, 109.73, 130.67, 155.85, 186.13, 222.48, 266.04, 318.13, 380.21, 453.94, and 541.09 m), with four variables per depth layer: ocean temperature, salinity, u-, and v- components of ocean currents. (3) 6 ASVs: These are distributed across four pressure levels (200, 500, 850, and 1000 hPa), with four variables per level: air temperature, relative humidity, u-, and v-components of wind speed.\nThe study focuses on a global domain with longitude spanning -180\u00b0 to 180\u00b0 and latitude spanning -80\u00b0 to 90\u00b0. The grid dimensions for OSVs are H=4320, W=2041."}, {"title": "6.3 LangYa Forecasting System", "content": "LangYa was trained on 27 years of data from 1993 to 2019 and tested using data from 2020 and 2021. LangYa inputs OSVs, ASVs, and SSSVs, to forecast OSVs (channels, C=128) with a spatial resolution of 1/12\u00b0. As shown in Figure 1, the forecasting process can be expressed as:\n$X_{t+ \\tau} = F_{\\theta} (H (X_t, A_{(t-7):t}) | E(t, \\tau))$\nwhere $X_t \\in \\mathbb{R}^{(D_x,H,W)}$ represents the OSVs at time $t$ inputted to the fore-casting system. It includes temperature, salinity, and ocean currents at 32 depth levels, which are combined along the channel dimension. $A_{(t-7):t} \\in \\mathbb{R}^{(D_a,H,W)}$ represents the historical ASVs over the previous 7 days, forming the contextual input for the forecasting system (The study primarily focuses on short-term forecasts of OSVs at a daily time resolution.). $\\hat{X}_{t+\\tau}$, denotes the LangYa forecast for OSVs at time $\\tau\\in \\{1,2, ..., K\\}$. To standardize notation, $X_{t+\\tau}$ represent the corresponding ground truth at the timestep $(t+\\tau)$. $F_{\\theta}(\\cdot)$ denotes LangYa's ocean self-attention module. $H(\\cdot)$ represents LangYa's modeling of air-sea interaction mechanisms, specifically imple-mented via the asynchronous cross-iterative random sampling strategy. $E(t, \\tau)$ encodes the temporal information of LangYa's initial and forecast horizons.\nThe specific forecasting steps of LangYa are as follows:\n(1) Coupling of OSVs, ASVs, and SSSVs: LangYa integrates OSVs, ASVs, and SSSVs using the asynchronous cross-iterative random sampling strategy within the air-sea coupled module. The process generates data with dimensions 2041x4320x133. Subsequently, the Time Embedding module, based on LLMs, encodes the tem-poral information of the current and forecast times into a 96-dimensional feature vector. These two features are combined to form the input to LangYa.\n(2) Spatiotemporal Feature Extraction: LangYa employs an ocean self-attention mod-ule to extract spatiotemporal features, capturing the complex dependencies across spatial and temporal dimensions in the input data. For OSVs, LangYa utilizes a Patch Embedding module to perform dimensionality reduction by dividing the input grid into non-overlapping patches, with each patch encoded into a latent representation of dimension C. During experiments, the patch size is set to 4x4, resulting in feature dimensions of 510x1080xC.\n(3) Deep Feature Extraction via Swin Transformer Blocks (ST Blocks): LangYa uses five ST blocks to extract deep features from the patch tokens. The ST blocks are organized hierarchically, where the number of tokens is progressively reduced"}, {"title": "6.4 Time Embedding Module", "content": "There are two methods for forecasting long-term time series of OSVs and ASVs: (1) autoregressive forecasting methods (e.g., Pangu-weather) and (2) building separate forecasting models for each forecast day (e.g., XiHe). The first method leads to sig-nificant cumulative errors, while the second entails high training costs due to the need for multiple models. Neither method satisfies the requirement of using a single"}, {"title": "6.5 Air-Sea Coupling Module", "content": "The variations in OSVs do not occur in isolation but are driven by the complex interactions between the ocean and the atmosphere. These coupled relationships pose significant challenges for high-precision forecasting of OSVs, particularly under limited computational resources. Many existing models either fail to simultaneously handle ASVs, SSSVs, and OSVs data or inadequately account for their interactions, relying solely on simple data concatenation for modeling. Additionally, the inconsistency in spatial resolutions between ASVs, SSSVs, and OSVs data further complicates their integration within models."}, {"title": "6.6 Ocean Self-Attention Module", "content": "OSVS, SSSVs, and ASVs often have very high resolutions, which makes gradient explo-sion (i.e., the rapid increase of deep activation values) more common during large model training. To address this issue, we propose a stability-enhancing module based on cosine attention. Two key modifications were made. First, we replaced the previ-ous pre-normalization architecture with a post-normalization structure in the residual blocks. Thus, the output of each residual block is normalized before merging back into the main branch. The design ensures that the amplitude of the main branch does not accumulate as the network depth increases. The computation of each ST block is given"}, {"title": "6.7 Adaptive Thermocline Loss Function", "content": "The thermocline is a transition layer in the ocean where temperature changes drasti-cally with depth. Its formation mechanism is complex, making accurate thermocline forecasting a significant challenge in ocean modeling. The difficulty of forecasting the thermocline lies in the sharp gradient changes in water temperature within this region, which are often difficult for traditional models to learn and capture effectively. To address this, we developed an adaptive thermocline loss function to enhance the model's learning capability in the thermocline. The loss function is expressed as:\n$L_T = |[X_T] - [\\hat{X_T}]| \\times [Norm (\\frac{ d[X_T](x,y,z)}{dz} ) + 1]$\nwhere $[X_T]$ represents the grid for temperature, and $0 < x < W$, $0 < y < H$, $0 < z < CT$ represents the grid coordinates for longitude, latitude, and depth. $Norm$ denotes the min-max normalization, scaling the data to a range of [0,1]. $[X_T]$, $[\\hat{X_T}]$ represent the corresponding ground truth from the reanalysis and LangYa's forecast values. The loss function enables the model to focus more on regions with significant verti-cal gradients, particularly the temperature variations near the thermocline, thereby significantly improving its ability to learn the complex evolution of the thermocline. Based on the definition above, the overall training loss for LangYa is defined as:\n$L = |X - \\hat{X}| + \\lambda L_T$\nwhere $\\lambda = 1.0$ is the weight for the thermocline loss."}, {"title": "6.8 Model Training and Metrics", "content": "LangYa was trained to forecast time ranging from 1 to 7 days. The air-sea coupled module considers atmospheric influences on the ocean for a period of 3 to 7 days. LangYa was trained for 100 epochs using the Adam optimizer. The training process was executed over 14 days on a cluster of 16 NVIDIA Tesla-A800 GPUs. The batch size was set to 16, and the initial learning rate was 0.001, which was gradually reduced to 0 during training using a cosine annealing strategy. To mitigate overfitting, the train-ing dataset (1993\u20132019) was shuffled randomly within each epoch, while no random sampling was applied during the testing phase.\nThe study follows a recent work (XiHe) that adopted RMSE to measure the accuracy of forecasted OSVs compared to ground truth. To provide more objective experimental comparisons, MAE and PSNR are introduced as additional evaluation metrics. RMSE and MAE evaluate the global forecasting accuracy of variables from a grid-level perspective, while PSNR captures the quality of the forecast data relative to the ground truth. The formula for calculating RMSE is defined as follows:\n$MAE (X, \\hat{X}) = \\frac{1}{C \\cdot H \\cdot W} \\sum_{z,x,y}^{C,H,W} |X(z,x,y) - \\hat{X}(z,x,y)|$\n$MSE (X, \\hat{X}) = \\frac{1}{C \\cdot H \\cdot W} \\sum_{z,x,y}^{C,H,W} |X(z,x,y) - \\hat{X_t}(z,x,y)|^2$\n$RMSE (X, \\hat{X}) = \\sqrt{MSE (X, \\hat{X})}$\n$PSNR (X, \\hat{X_t}) = 10 \\cdot log_{10} \\frac{max(X)^2}{MSE (X, \\hat{X_t})}$\nThe results calculated using the above metrics are averaged across all time steps (testing set time range) and horizontal grid points to produce the mean RMSE, MAE, and PSNR values for the forecasted OSVs at a lead time. These metrics also remain robust in local regions, allowing for evaluation of RMSE, MAE, and PSNR for specific basins, such as Northwest Pacific, Northeast Pacific, etc."}, {"title": "6.9 Comparative Methods", "content": "Four numericial systems (PSY4, BLK, GIOPS, and FOAM) and one AI system (XiHe) that can be used for 1/125 numerical global thermosaline and current OSV forecasts are included in our comparison experiment.\nThe methods used to evaluate the model include the AI-based global OSVs fore-casting system XiHe. XiHe achieves a high spatial resolution of approximately 1/12\u00b0 and can complete a 10-day forecast within 0.36 seconds, which is thousands of times faster than traditional numerical Global Ocean Forecast Systems (GOFS).The eval-uation also includes datasets from the IV-TT Class 4 framework, which provides observational datasets from Argo, Jason-1, Jason-2, and Envisat CLS AVISO level 3 satellite altimeters."}, {"title": "7 Data availability", "content": "For training and testing LangYa, we downloaded the GLORYS12 dataset from and ERA5 dataset from https://cds.climate.copernicus.eu/. For comparison with other methods, we downloaded the IV-TT Class 4 framework from https://thredds.nci.org.au/thredds/catalog/rr6/intercomparison_files/catalog.html. All these data are publicly available for research purposes. Source data will be provided in this paper."}, {"title": "8 Code availability", "content": "The code base of LangYa was established on PyTorch, a Pythonbased library for deep learning. The details of LangYa, including network architectures, modules, optimiza-tion tricks and hyperparameters, are available in the paper and the pseudocode. We released the trained models, inference code and the pseudocode of details to the public at a GitHub repository: https://github.com/iocaswolfteam/LangYa_v1_0. The trained models allow the researchers to explore LangYa's ability on either GLORYS12 and ERA5 initial fields."}]}