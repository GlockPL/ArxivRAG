{"title": "Automating grapevine LAI features estimation with UAV imagery and machine learning", "authors": ["Muhammad Waseem Akram", "Marco Vannucci", "Giorgio Buttazzo", "Valentina Colla", "Stefano Roccella", "Andrea Vannini", "Giovanni Caruso", "Simone Nesi", "Alessandra Francini", "Luca Sebastiani"], "abstract": "The leaf area index determines crop health and growth. Traditional methods for calculating it are time-consuming, destructive, costly, and limited to a scale. In this study, we automate the index estimation method using drone image data of grapevine plants and a machine learning model. Traditional feature extraction and deep learning methods are used to obtain helpful information from the data and enhance the performance of the different machine learning models employed for the leaf area index prediction. The results showed that deep learning based feature extraction is more effective than traditional methods. The new approach is a significant improvement over old methods, offering a faster, non-destructive, and cost-effective leaf area index calculation, which enhances precision agriculture practices.", "sections": [{"title": "I. INTRODUCTION", "content": "Global climate challenges and complex field conditions necessitate innovative approaches to enhancing agricultural yields and ensuring food safety. Effective agricultural management heavily relies on rapid, accurate, timely, and non-destructive monitoring of the Leaf Area Index (LAI), a crucial vegetation characteristic closely linked to crop development and influenced by various climatic factors such as atmospheric temperature, precipitation, and solar radiation. Traditional methods [1] for determining LAI, including destructive sampling and manual measurements, are labor-intensive and limited in scale. Conversely, adopting remote sensing technologies [2] have surged, since they offer promising alternatives. These technologies, particularly satellite imagery and unmanned aerial vehicle (UAV) based remote sensing, enhance yield estimations and monitoring crop growth. For instance, HJ-1A satellite remote sensing data [3] have been used to assess the LAI and biomass of various crops. Estimates of winter wheat yield and other crops like cotton and soybean have been derived from remote sensing images captured by the ERTS-1 satellite operated by Xie et al. [4]. Despite their potential, high-quality satellite images are often expensive and challenged by limitations such as poor geographical and temporal resolution, real-time availability, and atmospheric sensitivity. Moreover, while satellites like Landsat offer extensive coverage, their optical sensors are hindered by a minimum repeat cycle of 16 days, and adverse weather conditions can compromise image accuracy.\nHyperspectral and multispectral imaging technologies via UAVs provide a wide spectral range and high resolution as a more adaptable and cost-effective alternative [2]. However, those solutions face widespread adoption obstacles due to complexity of data processing and high equipment costs. In developing countries, such challenges are particularly pronounced with small-scale farming. UAV systems equipped with RGB cameras have become a compelling choice due to their superior spatial resolution and more manageable costs, making them particularly suitable for agricultural surveillance in resource-limited settings. Integrating machine learning (ML) and deep learning (DL) algorithms has significantly advanced the analysis of agricultural remote sensing data [5], [6]. For example, Li et al. [7] uses UAV-based photographs to estimate rice LAI via multiple models. Another Wittstruck et al. [8] tested DL models for wheat LAI inversion, and Han et al. [9] explore ML techniques to predict maize above-ground biomass. By effectively modeling the non-linearity and heterogeneity in extensive image data, ML and DL algorithms are excellent tools to estimate crop growth. Advanced feature extraction techniques, whether traditional or derived from pre-trained DL models, greatly enhance the efficacy of ML models, providing more comprehensive and informative data representations, as well as facilitating better learning and generalization [5], [10].\nThe study presented in this paper is aimed at comparing various ML models and feature extraction technique combinations to assess their effectiveness in LAI estimation from crop images captured by UAVs. Through experimental validation, we intend to demonstrate the benefits of sophisticated feature extraction methods, particularly those utilizing DL techniques. The objective of this study is to highlight how these technologies can improve the accuracy and efficiency of ML models in the agriculture sector. It offers a quick, cost-effective, and scalable method for automated LAI estimation, enhancing agricultural management and food safety in the face of global climate variability."}, {"title": "II. MATERIALS AND METHOD", "content": "The dataset used for ML training and validation contains images of the investigated individual grapevine plants captured by the drone and their LAI values. The plants were identified by means of a marker placed on the ground that allowed their identification. The LAI was estimated using a non-destructive canopy analysis system (SunScan SS1-R3-BF3, Delta-T Devices, Cambridge, UK) as reported in [11]. The images of the individual plants were obtained from the aerial images captured by the drone by means of an annotation process using commercial software that allows generating the bounding box for each plant subjected to measurement and to associate the corresponding LAI measured value. Our dataset consists of 498 images, each associated to a multiple plants and a LAI value. After extracting each plants image the final dataset consist of 1469 images. LAI values are normally distributed with mean value \u03b7 = 0.96, standard deviation \u03c3 = 0.67, minimum value of \u03bc = 0.24, maximum value of M = 3.17."}, {"title": "B. Methodology", "content": "Figure 3 depicts the working pipeline of our proposed method for estimating LAI from a dataset D = {I\u2081, I\u2082,..., I\u2099} consisting of n images, each associated with a plant within the crop. Features F\u2096 are extracted from each image using advanced image processing techniques, denoted by\n\nF\u2096 = ExtractFeatures(I\u2096).\n\nThese features feed into various machine learning (ML) models to accurately predict the LAI, represented by\n\nLAI\u2096 = EstimateLAI(F\u2096).\n\nFeatures are crucial for improving the performance of ML models. We employed three different feature extraction methods:\n1) Green Area Features Extraction using an Edge Detection Pipeline.\n2) Feature vocabulary development.\n3) Features extraction using a pre-trained deep learning (DL) model."}, {"title": "C. Green Area Features Extraction using an Edge Detection", "content": "Green Area Features Extraction using an Edge Detection [12] pipeline includes LAI estimation from digital images through a sequence of sophisticated image processing techniques to highlight and isolate vegetation.\nFirstly, images are thresholded to enhance contrast:\nPixel values above 50 are set to 255, highlighting key features crucial for vegetation detection.\nImages are then converted to the HSV color space:\nThis conversion is used to effectively segment green hues via a specific color mask that filters out non-green colors, isolating areas essential for plant analysis.\nA Gaussian blur is applied to the green regions:\nThis step reduces noise and enhances clarity, facilitating precise edge detection.\nEdge detection is performed using Canny's method:\nThreshold values of 50 and 150 are used for this method.\nThese steps systematically enhance the raw imagery, emphasizing vegetation edges and contours, which are crucial to accurately measure leaf coverage relative to the ground area, thus providing a reliable LAI value for environmental and agricultural assessment. The reported values for all images are consistent and correspond to the best results."}, {"title": "D. Feature vocabulary development", "content": "Feature vocabulary development is utilized to combine different image attributes [7]. LAI estimation from plant imagery benefits from integrating color, shape, and texture features extracted using Color Histograms, Hu Moments, and Haralick Textures. The color histogram for each image,\n\nHc(i) = \u03a3[c(p) = i],\np\u2208I\n\nassesses the canopy color distribution, particularly focusing on the green spectrum, to estimate leaf coverage density. Hu Moments, resistant to image transformations such as scaling and rotation, quantify geometric features, distinguishing between overlapping leaves and canopy gaps, which is essential for accurate LAI calculation.\nTexture features are derived from the Gray-Level Co-occurrence Matrix (GLCM):\n\nGLCM(i, j) = \u03a3[I(p) = i \u2227 I(q) = j],\np\u2208I\n\nFrom this matrix, measures such as Contrast,\n\nContrast = \u2211(i \u2013 j)\u00b2 \u00b7 GLCM(i, j),\ni,j\n\nEnergy, \n\nEnergy = \u2211[GLCM(i, j)]\u00b2,\ni,j\n\nand Homogeneity,\n\nHomogeneity = \u2211  GLCM(i, j) / 1 + (i - j)\u00b2,\ni,j\n\nprovide insights into the canopy textural patterns. These metrics, reflecting leaf density and arrangement, enhance the LAI estimation process, allowing for a comprehensive analysis beyond what single indexes offer."}, {"title": "E. Pre-trained model to extract features from images", "content": "Recent advancements in DL that have shown remarkable results in agriculture [5], [6], we used a pre-trained model to extract features from images. Training a powerful DL model from scratch requires significant amounts of data, time, and resources. Pre-trained models are a more practical option. Features extraction includes a pre-trained ResNet50 model that offers a powerful method to analyse complex image data, such as for LAI estimation [5]. Leveraging the features learned from extensive visual data by the ResNet model allows capturing detailed characteristics such as leaf texture, shape, and health, which are crucial to accurately determine the LAI. This method significantly enhances the efficiency and robustness of LAI estimation, offering superior performance over traditional image processing techniques by providing a comprehensive understanding of vegetation features critical for ecological and agricultural assessment."}, {"title": "F. Machine Learning Models", "content": "Three different machine learning regression models, including Linear Regression (LR), Support Vector Machines (SVM), and Random Forest (RF), were used to estimate the Leaf Area Index (LAI) from the features extracted through the methods mentioned above.\n1) Linear Regression (LR): LR serves as one of the most basic and interpretable methods for regression analysis, assuming a direct linear relationship between the predictor variables and the target variable, LAI. The prediction model is defined by the equation:\n\n\u0177 = \u03b2\u2080 + \u03b2\u2081x,\n\nwhere y is the predicted value of LAI, \u03b2\u2080 is the intercept, and \u03b2\u2081 is the coefficient representing the weight of the feature x.\nDespite its simplicity, LR provides valuable insights into how each feature influences the target, making it particularly useful when the relationships are expected to be linear or nearly linear. However, LR's predictive power can be limited in the presence of non-linear interactions or when the data exhibit complex patterns. Therefore, while LR is efficient and computationally inexpensive, it may not fully capture the intricacies of LAI variability unless the linearity assumption holds.\n2) Support Vector Machines (SVM): SVM extend beyond linear regression by introducing non-linear modeling capabilities through the use of kernel functions. The primary advantage of SVM is its ability to handle high-dimensional data and complex, non-linear relationships. The SVM regression model, or Support Vector Regression (SVR), operates by mapping the input data into a higher-dimensional feature space using a kernel function, thereby allowing the model to fit more complex functions to the data. The SVR model can be expressed as:\n\nf(x) = w \u00b7 \u03c6(x) + b,\n\nwhere \u03c6(x) denotes the transformation function (kernel), w represents the model weights, and b is the bias term. The Radial Basis Function (RBF) kernel was utilized in this study due to its proficiency in modeling non-linear patterns, which are common in biological and ecological datasets. The RBF kernel effectively measures the similarity between data points based on their distance, making it well-suited for scenarios where relationships are not straightforward. SVM is particularly beneficial when the data is complex and contains noise, as it aims to minimize prediction error while maintaining model robustness.\n3) Random Forest (RF): RF is an ensemble learning technique that combines the outputs of multiple decision trees to improve the prediction accuracy and stability of the model. Unlike individual decision trees, which can be prone to overfitting, RF mitigates this by averaging the results of numerous trees, each constructed from random subsets of the data and features. The RF regression model is expressed mathematically as:\n\nLAI = 1 / B  \u2211 tb(x),\nb=1\n\nwhere B is the number of decision trees, and tb(x) represents the prediction made by the b-th tree. For this study, the RF model was configured with 100 trees, optimizing performance while maintaining computational efficiency. This ensemble approach is particularly effective in handling large datasets with high dimensionality and complex interactions among features. RF provides several advantages, such as its ability to model non-linear relationships and automatically handle missing data, making it highly versatile and powerful for predictive modeling."}, {"title": "G. Model Implementation and Parameter Tuning", "content": "These models provide robust, scalable methods for precise LAI calculations [6]. We employed the different parameters specified in the Scikit-Learn library to train the models. This approach involved using the Radial Basis Function (RBF) kernel for the SVM and configuring the RF model to operate with 100 trees, among other settings."}, {"title": "III. RESULTS AND DISCUSSION", "content": "Table I compares 3 different ML models, i.e. LR, SVM, and RF applied to 3 feature extraction methods for LAI estimation. Performances are quantified in terms of Mean Squared Error (MSE), Mean Absolute Error (MAE) and Mean Absolute Percentage Error (MAPE). The training dataset includes overlapping leaves and intricate plant structures, thus posing significant hurdles for feature extraction and model training.\nThe achieved results show that the combination of SVM with ResNet outperforms other models, as it shows the lowest MSE (0.21) and MAE (0.32) values. This proofs a strong fit to critical data, showing the superior capabilities of DL algorithms in dealing with the complexity of overlapping leafs and variable plant orientation.\nThe variable LR performance across multiple feature sets demonstrates its sensitivity to the adopted feature type, with Green Area features producing the smallest errors. This could indicate that Green Area features are better at capturing linear relationships in data, which are easier for LR to model. When SVM and RF are paired with ResNet and Green Area feature extraction, both perform well in LAI estimation. SVM great performance with ResNet features is most likely due to its ability to handle complex data structures. Future improvements could include increasing the dataset size and DL fine-tuning to boost model accuracy even further. Meanwhile, our methodology provides agricultural practitioners with practical insights, allowing them to track growth effectively even with small data sets. This makes our approach extremely relevant for both academic research and practical farming applications, ensuring that it remains accessible and valuable at many levels of agricultural management."}, {"title": "IV. CONCLUSION AND FUTURE WORK", "content": "This paper presented a comparative evaluation of various ML models and feature extraction techniques to assess their effectiveness in LAI estimation from crop images captured by a drone. The achieved results show that integrating advanced DL techniques and traditional feature extraction methods significantly enhances the accuracy of LAI estimation. While DL models like ResNet excel in processing complex data, simpler methods such as Green Area feature extraction also proved to be effective, offering flexibility for different agricultural settings. Future work will focus on expanding the dataset and fine tuning the DL models to optimize their performance across diverse agricultural landscapes. Moreover, exploring automation of data processing and integrating real-time data analysis could provide more dynamic and accessible solutions for precision agriculture."}]}