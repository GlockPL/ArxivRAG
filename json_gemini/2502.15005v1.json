{"title": "A Socratic RAG Approach to Connect Natural Language Queries on Research Topics with Knowledge Organization Systems", "authors": ["Lew Lefton", "Kexin Rong", "Chinar Dankhara", "Lila Ghemri", "Firdous Kausar", "A. Hannibal Hamdallahi"], "abstract": "In this paper, we propose a Retrieval Augmented Generation (RAG) agent that maps natural language queries about research topics to precise, machine-interpretable semantic entities. Our approach combines RAG with Socratic dialogue to align users' intuitive understanding of research topics with established Knowledge Organization Systems (KOSs). The proposed approach will effectively bridge \"little semantics\" (domain-specific KOS structures) with \"big semantics\" (broad bibliometric repositories), making complex academic taxonomies more accessible. Such agents have the potential for broad use. We illustrate with a sample application called CollabNext, which is a person-centric knowledge graph connecting people, organizations, and research topics. We further describe how the application design has an intentional focus on HBCUs and emerging researchers to raise visibility of people historically rendered invisible in the current science system.", "sections": [{"title": "Introduction", "content": "What is a research topic? Research is carried out on almost everything, so the concept space is wide and deep. It is unsurprising that there is no universal resource that covers all research concepts. Instead, many domain-specific Knowledge Organization Systems (KOS) have emerged providing ontologies, taxonomies, lists, and thesauri of their areas (Salatino et al. 2024). These KOSs are good sources of expert-curated ground truth. Unfortunately, in a KOS, topic data typically consists only of strings and not semantic entities, which makes research topics a weak link in knowledge axiomatization and research classification.\nA knee-jerk reaction to this challenge is to leverage a Large Language Model (LLM) to generate research topics, based on a corpus of research papers, datasets, etc. In fact, there are many tools in the area of topic classification that do precisely that. Unfortunately, LLM generated topics do not align well with how human beings talk and think about research.\nAlignment of natural language research topics with structured KOSs is needed for CollabNext (CollabNext 2024), an application currently under development as part of the"}, {"title": "Related Work", "content": "In this section, we review approaches for automatically generating topics in scientific publications. We focus on three main paradigms: supervised topic classification, unsupervised topic modeling, and knowledge organization systems."}, {"title": "Topic Classification", "content": "Topic classification takes a supervised approach, using often manually curated document topics to train models for categorizing new publications. However, obtaining high-quality ground truth labels at scale remains challenging, forcing many methods to build topic taxonomies from scratch (Liu, Zhang, and Chen 2014).\nThe Microsoft Academic Graph (MAG) (Sinha et al. 2015) represents a significant effort in this direction. Their methodology began with manual definition of a small number of top-level concepts, followed by extraction of 28,000 academic concepts from Wikipedia articles (Shen, Ma, and Wang 2018). MAG implemented topic assignment as a multilabel classification problem, enabling papers to be tagged with multiple concepts. After the discontinuation of MAG in 2021, OpenAlex attempted to reproduce the topic classification model using historical MAG data as training labels (Priem, Piwowar, and Orr 2022). During this process, OpenAlex identified several limitations of MAG concepts, including term polysemy, ambiguity, and the static nature of concepts that failed to evolve with research trends. OpenAlex subsequently adopted a labeled dataset from CWTS (Van Eck and Waltman 2024) and integrated it with concepts from the All Science Journal Classification (ASJC) codes. However, obtaining high-quality training labels at scale remains a challenge, often forcing methods to construct topic taxonomies from scratch (Liu, Zhang, and Chen 2014)."}, {"title": "Topic Modeling", "content": "Unsupervised topic modeling techniques discover common themes within document collections by clustering similar documents and deriving topic labels from shared characteristics within clusters. For scientific papers, these methods typically leverage multiple signals including semantic similarity from titles and abstracts, citation network structures, and shared references. Domain-specific pretrained models like SciBERT (Hosokawa et al. 2024) have been shown to enhance clustering quality of abstract embeddings by using purpose-built tokenizers and specialized pretraining that capture field-specific terminology.\nSimilarly, BERTopic (Grootendorst 2022) uses a pretrained language model to generate document embedding, performs dimensionality reduction, and creates semantically similar clusters (using HDBSCAN) that each represent a distinct topic. BERTopic uses a variant of TF-IDF to extract topic representations from each topic. CWTS (Van Eck and Waltman 2024) leverages large language models (LLMs) to generate research topic labels. The LLM receives titles of the 250 most cited publications in each cluster and generates a label and a brief summary of the research area.\nHowever, clustering-based approaches face limitations: extracted topics often fail to align with established ontologies, and poor clustering quality can result in topics lacking clear interpretability."}, {"title": "Knowledge Organization Systems", "content": "A Knowledge Organization System (KOS) (Salatino et al. 2024) is a structured framework that enables the arrangement, management, retrieval, and dissemination of information. These systems are crucial to library science, information retrieval, and knowledge management, offering standardized vocabularies and defined relationships between concepts to improve information accessibility and interoperability (Hodge 2000).\nKOS encompasses several key methodologies:\n\u2022 Classification schemes: Systems such as the Dewey Decimal Classification (DDC) (Dewey et al. 2011) and Library of Congress Classification (LCC) systematically group related concepts based on shared characteristics, providing logical organization for library resources.\n\u2022 Thesauri: Controlled vocabularies that map relationships between terms, including synonyms, antonyms, and hierarchical relationships. A prominent example is the Medical Subject Headings (MeSH), which is the controlled vocabulary used to index the huge amount of biomedical literature (NLM 2022).\n\u2022 Taxonomies: Hierarchical systems organizing concepts into parent-child relationships, commonly used in web navigation and content management systems.\n\u2022 Ontologies: Formal and machine-interpretable specifications that define domain concepts and their relationships (Guarino, Oberle, and Staab 2009). These are crucial for semantic web technologies and AI applications, enabling data interoperability and automated reasoning.\n\u2022 Controlled Vocabularies: Curated term lists ensure consistent language across collections, enhancing retrieval precision and accuracy.\nKOSs help to uncover knowledge from various sources, especially in the context of big data and the semantic web. Integrating and discovering knowledge from heterogeneous sources becomes a lot easier with KOS, which is also very usefu; for advanced research and development tasks. The Simple Knowledge Organization System (SKOS) presents a model for sharing and linking knowledge organization systems on the web (Miles and Bechhofer 2009). This W3C-endorsed model based on Resource Description Framework (RDF) promotes interoperability, as well as the seamless exchange of information between heterogeneous systems.\nDespite their utility, KOSs encounter some issues, such as how to remain pertinent in rapidly changing areas of knowledge and how to ensure that they work well with other systems. (Lauruhn and Groth 2016) comment on the need for KOSs to have adaptive management strategies that allow them to change along with our knowledge structures.\nRecent research shows promises of integrating KOS with large language models (LLMs) to enhance AI explainability. (Ahmed et al. 2023) demonstrated that the combination of knowledge graphs with LLM produces more interpretable outputs than LLMs alone, while (Krause and Stolzenburg 2024) showed that LLMs coupled with external knowledge sources improve commonsense reasoning capabilities in AI systems."}, {"title": "CollabNext", "content": "There are many potentially impactful applications which would benefit from having a RAG agent that provides an explainable topic identifier based on established ground truth of human-generated KOSs. To serve as an illustrative example, we describe CollabNext (CollabNext 2024) which is currently under development as part of the NSF's Prototype Open Knowledge Network (NSF 2023). This application depends on open, robust, and structured data on research topics."}, {"title": "Application Overview", "content": "CollabNext implements a knowledge graph with entities consisting of people, organizations, and research topics. The primary data source is currently the bibliometric dataset from OpenAlex (Priem, Piwowar, and Orr 2022), but the intention is to include other relevant data sources as development continues. Relationships between people and organizations are available directly in OpenAlex via author and institution tables. Relationships between people and topics are inferred, since people are connected to OpenAlex works as authors, and works are connected to topics. See Figure 1 for a conceptual schema of the CollabNext knowledge graph. Note, that the schema in Figure 1 includes additional data like Grants and Patents which are not yet in OpenAlex, but these objects could still be assigned topics via methods discussed above.\nThe CollabNext application is being developed using an intentional design approach, initially prioritizing Historically Black Colleges and Universities (HBCUs) and emerging researchers. This is a deliberate effort to counterbalance the accumulated advantage of well-resourced research organizations, which is an example of the Matthew Effect (Merton 1968). This effect is a common phenomenon in social systems, and can be summarized as \"the rich get richer and the poor get poorer.\" CollabNext is being designed to counterbalance this bias, specifically in the social system of science research (Bol, de Vaan, and van de Rijt 2018; Rossiter 1993; Petersen et al. 2011).\nOne of the ways to do this is to, by default, focus on HBCUs and other organization where there are a high percentage of underrepresented researchers. Another design decision which can help raise visibility of invisible researchers is to not order researchers by citation count, which exacerbates the Matthew effect, but rather default to use geospatial data like location and distance as a primary filter. This is effectively adding an implicit \"near me\u201d search filter and showing people who work on a specific research topic who are also geographically close, e.g. at your same institution, in your same state, or your same timezone. The rationale for this approach is based on work in Team Science, which shows that geographical distance is a major barrier for scientific collaboration (Hoekman and Rake 2024). The work of (Katz 1994) shows that the probability of collaboration decreases as distance grows, based on co-authorship relations."}, {"title": "Challenge: Topic Search Needs an NLP interface", "content": "During the development of CollabNext, it became apparent that there was a disconnect between how people see research topics and how research topics are classified by AIs. We will illustrate with an example.\nSuppose a user wants to find researchers who are working on the topic of plastic recycling at a nearby University. There is no OpenAlex topic that directly matches this. Matching just for plastic yields 14 topic ids in the subfield Polymers and Plastics. This topic could also be considered Waste Management and Disposal which is in the subfield Environmental Science. Or it may be the topic Biodegradable Polymers as Biomaterials and Packaging which is in the subfield Biomaterials. It may even be the case that the user is not interested in the Chemistry of plastic recycling at all, but rather the economics or logistics of it. Similar collisions and ambiguities arise when the keyword recycling is used. More clarification is needed from the user. This subtle but important challenge can be improved with the RAG agent described below."}, {"title": "Proposed Approach", "content": "We propose an LLM agent leveraging multi-round Retrieval-Augmented Generation (RAG) to bridge the semantic gap between users' natural language queries on research topics and structured KOSs. While LLMs have demonstrated remarkable capabilities, they often struggle with domain-specific knowledge and are prone to hallucinations (Zhao et al. 2023), particularly in specialized academic contexts. Retrieval-augmented approaches have emerged as a promising solution by grounding LLM outputs in external knowledge bases (Lewis et al. 2020).\nTraditional RAG systems typically employ single-round retrieval, where knowledge is retrieved solely based on the initial query (Izacard et al. 2022). However, this approach proves insufficient for complex questions that require iterative refinement and disambiguation, such as mapping colloquial research descriptions to formal taxonomic structures. Recent work has demonstrated the effectiveness of multi-round retrieval and reasoning (Borgeaud et al. 2022; Shao et al. 2023; Zhuang et al. 2024), where each round of interaction refines the query and retrieval process.\nBuilding on these advances, we propose a Socratic dialogue approach where the agent guides users through structured exploration of research topics, by asking questions of users, rather than simply offering answers. We anticipate that this dialog will be more than simple clarification questions. The agent should engage in meaningful conversation to examine and understand the user's research topic of interest at multiple levels of granularity. The agent will be guided by reasoning across the multiple KOS's on which it was trained. By grounding these conversations in human-curated KOSs as the knowledge foundation, the system provides transparent data provenance and explainable recommendations.\nIf successful, the proposed agent would be able to effectively bridge \"little semantics\" (domain-specific KOS structures) with \"big semantics\" (broad bibliometric repositories), making complex academic taxonomies more accessible to users who naturally express research interests in colloquial language. This approach enables precise mapping between informal research descriptions and formal knowledge structures while maintaining transparency and interpretability. Figure 2 illustrates the high-level workflow of our proposed system, and we overview the detailed design below."}, {"title": "Topic Retrieval", "content": "To effectively identify relevant research topics from KOS taxonomies, we propose a novel hierarchical retrieval mechanism. We will use domain-specific, pretrained models such as SciBERT (Beltagy, Lo, and Cohan 2019) to generate embeddings for each topic node. The retrieval process occurs in two stages:\n1. Initial Semantic Search: Topic embeddings are represented as dense embeddings of topic title and description strings. These are retrieved based on embedding similarity with the user query, using cosine similarity normalized by a temperature parameter 7 to control retrieval diversity - higher values generate more diverse candidates while lower values prioritize closer semantic matches.\n2. Hierarchy-Aware Reranking: Given the initial topic list, we rerank them by considering the ontological structure of topics. The reranking score combines three components: (1) direct semantic similarity between query and topic; (2) weighted ancestor path similarity computed as\n$score(t) = sim(q, t) + a \\sum_{a \\in ancestors(t)} \\beta^d \\times sim(q, a)$\nwhere a controls the overall influence of ancestral relationships and \u1e9e determines the decay rate with ancestral distance d; and (3) sibling coherence that boosts topics whose siblings also show high query similarity. This scoring function ensures that retrieved topics are both semantically relevant and structurally coherent within their respective taxonomies."}, {"title": "Multi-round RAG", "content": "The academic knowledge landscape is characterized by fragmented KOS resources: broad multi-field systems that cover multiple disciplines but lack depth, and specialized single-field KOS that provide granular topic categorization within specific domains. Our proposed multi-round RAG process is specifically designed to navigate this fragmented structure through a two-phase approach.\nIn the first phase, the system queries broad multi-field KOS systems such as All Science Journal Classification Codes, OpenAIRE's Field of Science Taxonomy, or Dewey Decimal Classification to identify relevant high-level research areas. For each retrieved topic, the LLM generates contextual explanations by synthesizing definitions and descriptions from linked knowledge bases. The agent engages in iterative dialogue with users, presenting candidate topics along with their explanations and soliciting feedback to refine the search. This phase continues until users confirm their broad research direction.\nThe second phase starts when users confirm topics that have corresponding single-field KOS coverage. For instance, in Computer Science, the system can leverage multiple specialized taxonomies including the Computer Science Ontology (CSO), ACM Computing Classification System (CCS), and Wikipedia's Computer Science Subject Headings. The agent uses context accumulated from the first phase to guide exploration within these detailed taxonomies. For fields lacking comprehensive KOS coverage (Salatino et al. 2024), the system employs more stringent filtering within multi-field KOS to identify the most precise available classifications."}, {"title": "Conclusion and Next Steps", "content": "We have outlined a RAG agent that takes natural language queries about research topics and provides focused machine-representable semantic entity identifiers based on the ground truth of human generated KOSs. We have also described the CollabNext application. One of the goals of CollabNext is to construct a knowledge graph that makes visible the relationships between people, research organizations, and research topics. CollabNext is being intentionally designed to make emerging researchers more visible and thereby help reduce the Matthew Effect in scientific research. We further illustrate how the RAG agent could be used, and provided an approach to building the agent.\nThe agent described here has potential beyond the use case of CollabNext. Indeed, any application that links its data to research topics via an existing KOS could also leverage the agent as a research topic \"Rosetta Stone.\" Moreover, disparate research artifacts could be semantically linked using research topics as an index, including articles, datasets, websites, Al models, GitHub repositories, theses, posters, etc. An existing example of this is the OpenAlex \"about-ness\" endpoint. This could lead to broader integration of research knowledge and data across diverse domains using a well-defined topic architecture. New research topics at disciplinary boundaries could also emerge and be naturally included as domain specific KOSs incorporate new structure and data.\nWe note that there are multiple other data-driven products which are relevant for this discussion. Examples include Google Scholar, LinkedIn (owned by Microsoft), Clarivate, Elsevier, Semantic Scholar, Metaphacts, System.com, etc. Some of them are commercial and are only available to well resourced institutions. Others leverage proprietary data and are not well suited to open systems. Also, these tools are more focused on research artifacts, and less on the researchers themselves.\nIn some sense, the RAG agent serves the role of a topic disambiguation tool. This is clearly needed for tools that work at the interface of humans and Als. Nuance and subtlety of how different researchers think about the \"same\" thing may provide insight and new results, and allow researchers to see integrative work and connect with adjacent researchers whom they did now know about.\nThis paper is admittedly only a high level description of the agent. We are taking to heart the workshop submission guidelines (AAAI 2025) which welcome short papers focused on case studies, work-in-progress, or visionary ideas. There are many unanswered questions including\n1. What happens if there is a topic that cannot be resolved by the KOSs that the agent knows about. This knowledge gap could be a signal of an emerging research area or perhaps a need for KOS improvement. Some KOSs are updated more frequently than others, so this may be an opportunity to provide a feedback loop.\n2. Would it be possible for users to explore topics both up and down a refinement, i.e. broadening and narrowing vertically, as well as exploring adjacent siblings (horizontally).\n3. How would user interactions be incorporated into the agent's knowledge over time? Could histories and usage patterns help with noisy/overlapping topics, or identify frequently asked questions that could indicate gaps between user needs and KOS data structures.\nThe CollabNext team has plans to build a simple proof-of-concept prototype of the proposed RAG agent. Such a prototype would likely be focused on only a handful of available KOSs, but would likely include both OpenAlex and Wikidata as a starting point."}]}