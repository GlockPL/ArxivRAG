{"title": "Implementation of a Generative AI Assistant in K-12 Education: The CGScholar AI Helper Initiative", "authors": ["Vania Castro", "Ana Karina de Oliveira Nascimento", "Raigul Zheldibayeva", "Duane Searsmith", "Akash Saini", "Bill Cope", "Mary Kalantzis"], "abstract": "This paper focuses on the piloting of the CGScholar AI Helper, a Generative AI (GenAI) assistant tool that aims to provide feedback on writing in high school contexts. The aim was to use GenAI to provide formative and summative feedback on students' texts in English Language Arts (ELA) and History. The trials discussed in this paper relate to Grade 11, a crucial learning phase when students are working towards college readiness. These trials took place in two very different schools in the Midwest of the United States one in a low socio-economic background with low-performance outcomes and the other in a high socio-economic background with high-performance outcomes. The assistant tool used two main mechanisms: \u201cprompt engineering\u201d based on participant teachers' assessment rubric and \"fine-tuning\" a Large Language Model (LLM) from a customized corpus of teaching materials using Retrieval Augmented Generation (RAG). This paper focuses on the CGScholar AI Helper's potential to enhance students' writing abilities and support teachers in ELA and other subject areas requiring written assignments.", "sections": [{"title": "1. Background", "content": "The term \"artificial intelligence\" (AI) was coined by John McCarthy to attract funding for a small seminar of experts at Dartmouth College in 1956 (McCarthy et al., 1955). He proposed that machines could eventually perform the same cognitive operations as humans. This definition assumed that machines could replicate human intelligence. However, the concept was not entirely new; it rephrased Alan Turing's earlier idea of \"intelligent machinery\" (Turing, 1948).\nThis study challenges McCarthy's definition of AI, which views machines as behaving intelligently like humans. The critique lies in the assumption that machines and humans can be evaluated on the same scale\u2014a notion considered misleading. This perspective leads to an unrealistic humanization of computing machines and a machine-like view of human brains (Cope and Kalantzis, 2022)."}, {"title": "2. Context for CGScholar AI helper", "content": "Much debate about AI and its impact has grown since the launch of ChatGPT in November 2022 (Cope and Kalantzis, 2023), particularly concerning the possibility of students cheating when doing their assigned writing tasks.\nCheating, however, is one of the lesser issues that GPTs pose to education. Learning encompasses much more than just individual long-term memory, especially since a significant portion of this memory has been outsourced to the interconnected knowledge devices we carry. However, the teachers' concerns need to be recognized and addressed. The following is an account of a particular incorporation of GenAI in education, through the CGScholar AI Helper, which aims to provide a helping hand to both the teacher and the students in writing tasks and to demonstrate how Al's more negative potential can be curtailed in classroom contexts."}, {"title": "3. The CGScholar AI Helper and its Implementation", "content": "The process of implementing the CGScholar AI Helper in schools begins by integrating teaching materials, writing prompts, and rubrics from the teacher into the RAG knowledge database. These materials are processed through AI prompt engineering to align feedback with classroom expectations.\nThe initial trials were conducted in two high schools. The first one, referred to as School A, is a public school located in an underserved area in the Midwest region of the United States. The second one, referred to as School B, is a university laboratory high school, also located in the Midwest region of the US. The schools are very different in the sense that School A is located in a low socially advantaged area and receives students from different backgrounds, while School B selects its students from highly socially privileged families.\nSchool A has 824 students enrolled in the 2024 school year, grades 9 to 12. Its demographics show that approximately 35% of the school population are white, 30% are Hispanic, and 24% are Black. The highest number of students are enrolled in grades 9 (n=233) and 10 (n=235), while there is a decrease in grades 11 (n=184) and 12 (n=175). The teacher-student ratio is 13 to 1. The school has a total dropout rate of 2.8%, mostly among the Hispanic population. Regarding low-income students, 99.6% represent the percentage of students at the school who are eligible to receive free or reduced-price lunches, live in substitute care, or whose families receive public aid (Illinois Report Card, 2023).\nSchool B has 314 students enrolled in the 2024 school year, grades 8 to 12. According to the school demographics, around 35% of the school are Asian, the same percentage are white, while approximately 14% are Hispanic, and about 7% are Black. There is an even distribution of students enrolled in each grade: 8 (n=64), 9 (n=64), 10 (n=60), 11 (n=65), 12 (n=61). The teacher-student ratio is 9 to 1. The school has a zero dropout rate (Illinois Report Card, 2023). In addition, the data related to low-income students, which indicates the percentage of students eligible to receive free or reduced-price lunches, live in substitute care, or whose families receive public aid, is redacted. Therefore, this information is unavailable, unlike School A (Illinois Report Card, 2023).\nRegarding the participating teachers, in School A, the participating teacher is a female English Language Arts (ELA) teacher who holds two master's degrees in education and is currently pursuing doctoral studies. In School B, the participating teacher is a male History teacher who holds a PhD in Education. Both teachers were enthusiastic about participating in the research. Both chose their 11th graders to be participants in the study. In School A, consent was obtained from 6 students, all from the same ELA class whose parents and they themselves granted permission to be participants in the pilot project. In School B, there were 61 participating students divided into 3 classes: 17 in the first class, 23 in the second, and 21 in the last class, all part of the History component.\nDuring an initial conference with the teachers, the research team asked about the length of learners' required writing tasks, whether they would have an average required number of words, and whether they would consist of text-only or multimodal productions. Teachers were asked to share their own prompts with the research team. They were also asked about the content material and their rubric so that the RAG system could correspond to teachers' work and expectations before the AI Helper review was implemented.\nThe project for School A was called \u201cThe World on the Turtle's Back\u201d Writing Assessment. The teacher's prompt was: \"How are the Indigenous values of nature, balance, and tradition still seen today? Write a paragraph that analyzes the similarities with one of these values in both 'The World on the Turtle's Back,' translated by David Cusik, and an article, 'Returning \u2018Three Sisters' to Indigenous Farms Nourishes People, Land, and Cultures,' by Christina Gish Hill.\" To accomplish their work, students needed to read the aforementioned materials. Thus, digital versions of those reading materials were uploaded to the CGScholar RAG database. Additionally, the teacher provided the research team with her rubric, which involved the following criteria:\n1. Compare and contrast: Compare/contrast author choices, central ideas, and interpretations for two or more passages or whole texts;\n2. Identify: Identify and apply proper writing conventions;\n3. Compose: Compose defensible claims in both individual paragraphs and an essay as a whole;\n4. Introduce and Connect: Introduce and connect evidence to claim;\n5. Support Evidence: Support evidence with detailed elaboration;\n6. Analyze: Analyze how Indigenous culture is represented in society. In order to accomplish the task, the teacher informed us that students would write around 200 words.\nThe project for School B was called \"The History of Democracy.\" Students were required to write a paper examining the history of democracy, analyzing the current situation of democracy, and proposing a path forward. To accomplish this, they needed to read classroom materials created by the teacher as well as the following materials:\n\u2022 \"Global Freedom Is in Decline, But What About Democracy?\" from the website: https://www.journalofdemocracy.org/online-exclusive/global-freedom-is-in-decline-but-what-about-democracy/\n\u2022 Freedom House's \u201cGlobal Freedom Status\u201d map from https://freedomhouse.org/explore-the-map?type=fiw&year=2024\n\u2022 The trend lens and the \"Aggregate Category and Subcategory Scores, 2003\u20132024\" document in the Freedom House archives\n\u2022 The Political Handbook of the World from SAGE Publications\n\u2022 Freedom House's methodology from https://freedomhouse.org/reports/freedom-world/freedom-world-research-methodology\n\u2022 The book \"Democracy: A Very Short Introduction\" by Naomi Zack\n\u2022 Freedom House's policy recommendations from https://freedomhouse.org/policy-recommendations\nThis assignment was part of group work, and the final draft was reviewed using CGScholar AI feedback based on the following criteria:\n1. History of Democracy\n2. The Current Situation\n3. A Path Forward\n4. Research\n5. Analysis\nAfter the teacher's rubric was integrated into CGScholar and the resource materials were uploaded to the RAG database, the implementation with students began. When logging in, students saw the screen shown in Figure 02."}, {"title": "4. Application in K-12: Reports on the First Two Trials on Grade 11", "content": "The work plan for the research involved the development of the prototype for the new AI Helper module in CGScholar. To achieve this, the team employed fast-established strategies and cycles, which are part of a collaborative process that is well-suited to research-based software development and is lightly structured for diverse project teams (Martin, 2009; Stober and Hansmann, 2009).\nThis process ensured that the research team was closely engaged with trial teachers during the software development process outlined in this paper. Teachers had opportunities to share their impressions and make suggestions concerning the use of the CGScholar AI Helper and its functionality. One of the advantages of the agile methodology is that it allows for optimal use of the extended group's expertise, as each development cycle provides a natural juncture for individual researchers to move in or out of direct involvement in the software development process.\nSome of the team members have recently published a detailed exposition of the approach, which has been termed \u201ccyber-social education research\u201d (Tzirides, Saini, et al., 2023). By utilizing these methods, the team successfully created advanced software that functioned effectively in the participating classroom settings. The incremental development cycles included design, planning, implementation, release, and evaluation phases.\nEach week, the research team gathered to share a report on the implementation process, including newly released features, feedback from users, and proposed software updates for the next cycle. Upon each new trial, a functional evolution of the prototype was implemented, and the next development cycle was built upon that work. As part of this iterative process, the shared impressions of teachers and students were discussed and considered for incorporation. A post-survey was also used as part of data collection to help the research team improve the prototype and understand the extent to which AI Helper has the potential to enhance students' writing abilities and support teachers' work in ELA and History.\nIn the current research, this paper aims to answer the following research question: \u03a4\u03bf what extent does the CGScholar AI Helper have the potential to enhance students' writing abilities and support teachers' work in ELA and History?\nFrom a technical and prompt-engineering perspective, the system was trained using a combination of teachers' materials, writing prompts, and a sequence of assessment criteria drawn from teachers' work to provide detailed and systematic feedback to students."}, {"title": "5. Discussion", "content": "The research team trained all participants to utilize the platform and conducted a pre-intervention survey regarding their familiarity with AI and their future expectations of receiving AI feedback before the project implementation. The research team created CGScholar platform accounts and passwords for students.\nThe teacher provided a practical model of the CGScholar AI Helper by pre-loading a sample text and walking students through each step of the activity. This demonstration helped clarify the assignment structure and the responses expected from students. It also helped students better understand how to use the CGScholar AI Helper, even though the research team had previously explained it. The teacher provided a rubric to guide students in receiving Al feedback.\nOn the day of implementation in School A, the research team noticed that there were students with diverse writing levels who required different levels of support. For example, students with lower writing proficiency needed additional guidance to interpret and apply feedback and took a longer time to finish the activity. Students were tasked with completing their initial writings. After receiving the first round of AI Helper feedback, they were expected to revise their writings according to the input, which was based on the following criteria mentioned earlier in the paper: Compare and Contrast, Identify, Compose, Introduce and Connect, Support Evidence, and Analyze.\nIt was observed that students encountered the following challenges: time constraints, as the assignment allowed only 20 minutes for students to read and apply AI feedback. However, some technical delays made this difficult to manage. Additionally, many students felt the feedback was too long to read and implement within the given time. Students also struggled with tool navigation. They had to log in, generate initial feedback, revise their drafts, and then log out and log back in to generate a second round of feedback. This repetitive process involved many steps and took longer than anticipated."}, {"title": "5.1 CGScholar AI Helper for Students", "content": "Student reactions to the AI feedback provided by CGScholar are detailed below.\nSome students could see improvements in their scores, which meant that the AI Helper had provided them with valuable feedback for their further writing development. For example, one student from School A improved his writing in the Compare and Contrast criterion from 0 to 2. This meant that the student could hardly show any signs of comparison and contrast in his initial writing. However, after the first round of AI Helper feedback, he could identify some similarities and differences between two texts used in writing assignments, which resulted in a higher rating. Overall, according to initial findings, based on the students' writing data analysis, five out of six students improved their writing in at least one criterion.\nThe implementation revealed both strengths and areas for improvement. Regarding the teacher's support, the teacher made significant efforts in training, rubric guidance, and step-by-step assistance, which were very helpful in helping students navigate the AI Helper tool successfully. Furthermore, scaffolding made the process manageable, particularly for students requiring extra assistance. There were also some procedural challenges: the AI tool's interface was a bit complex and not optimized for school devices like Chromebooks. The Chromebooks presented issues such as a lack of shortcuts, and the AI Helper lacked features like automatic data saving and intuitive navigation for subsequent revisions after AI feedback. This limited students' autonomy and increased the teacher's and the research team's workload in School A.\nIt was found that student feedback on CGScholar AI Helper in School A mostly acknowledged that the feedback was useful for enhancing their writing.\nThey all added that they had never experienced AI before. They noted also that the feedback length was too long and some reported that the language used was hard to understand in some passages:\nThese ideas match the teacher's post-survey feedback, where she stated \u201cThe students were very engaged in revision, but they were also overwhelmed by the amount of feedback. I suggest the feedback be written at an 11th grade reading level and be much shorter\u201d.\nThe following key insights emerged from this first implementation in School A:\nThe teacher's guidance was essential to student success, in School A, particularly in the new digital environment. The teacher's voice was critical in leading the students through the instructional steps required to undertake the task and thus played a very important role in the trial's completion and success.\nAnother key finding relates to the need for tool familiarization. Both students and teachers would benefit from sufficient time to familiarize themselves with any new digital tool before they are introduced into classroom practices. This would help prevent navigation issues and provide a smoother user experience. Based on the mentioned implementation limitations, the following key recommendations are suggested for future implementations:\nThe second trial was conducted in School B. The initial meeting of the research involved, discussing possible dates, and writing assignments that could be part of the implementation. Request for the teacher's rubric, based on the curriculum. Scheduling a training session for the teacher on the use of CGScholar AI Helper.\nDuring the teacher training session, the CGScholar interface was introduced, and the steps for enabling AI review were explained. The teacher was then instructed to provide the rubric and subject materials so the research team could upload them into the RAG system. The teacher asked ChatGPT to create a text based on the prompt he was using with students and uploaded it into CGScholar AI Helper in order to familiarize himself with the prototype and get to know the feedback provided. After that, accounts and passwords for the CGScholar platform were created for the students in order for them to have their training session later.\nIn the following week, students received their training. Since there were 3 groups, for the first one, the training was guided by the research team with the help of the teacher. For the second group, the teacher, who had become very familiar with the prototype, was responsible for delivering the training on how to use the platform, counting on the research team for support if necessary. In the third session, the teacher was also responsible for conducting the training and the research team was there only to clear up possible doubts. As with School A the teachers' authority and instructional guidance were critical in the successful introduction of a new digital tool to his students, who on this site, were more tech-savvy than those at site A. His class also had access to the school's tech support team. The participating teacher of School B, explained the procedures and the purpose of the task inappropriately adjusted, clear language. The student participants and the teacher demonstrated much enthusiasm for the project. It should be noted that some students had already experienced getting AI feedback before. They used ChatGPT before, but AI Helper is different because the tool uses all the teachers' materials and rubrics in the knowledge database, providing feedback on students' texts based on what they have been studying. The research team explained that difference to the students.\nThe high-performing set of students found the 4-star system rating too restrictive. Their teacher from School B reported that the 4-star rating was too simplistic and could be distracting: \"My students are already too distracted by the stars and not paying close enough attention to the feedback that the assistant gives\" (Teacher from School B). He suggested replacing the stars with points (0-10) or percentages. He referred to the stars as \"basic\" and explained that the scoring should be tougher for his students. He suggested further, that having both stars and feedback on their work might be confusing for his students; explaining that if his high-performing students received 3 out of 4 stars, they might feel satisfied and not read the feedback for any particular criterion. However, student feedback from School B highlighted a different perspective: \"I liked the star ratings and how in-depth the explanations were.\"\nGiven these findings, the following key recommendations are proposed for future implementation of the CGScholar AI Helper tool:\n1. reconsideration of the star scoring system or even using different scoring systems for teachers to choose from,\n2. improving CGScholar AI Helper's prompt analyzing features.\nThe implementation phase for School B was organized in an online format, students had a confirmed deadline to upload their writings which, different from School A, were generated in groups as part of the assignment. The research team created a separate box and Google Docs with open access for all research team members, so they could have immediate updates. According to the post-survey, students from School B, stated that the AI feedback encouraged them to strengthen their arguments and improve specific parts of the paper including the conclusion:"}, {"title": "5.2. CGScholar AI helper for teachers", "content": "It is hypothesized that the wide range of functions that AI can perform may take over some of the responsibilities that are part of teachers' jobs. Teachers need to allocate a certain amount of time to administrative tasks such as checking attendance, revising homework, classroom supervision, and completing paperwork. With the introduction of AI, teachers can not only rethink some of these tasks but also perform them much more efficiently with the use of AI (Chan et al., 2023). AI has great potential to help teachers with student assessment, as developments in natural language processing facilitate applications such as assessment scoring and automated feedback provision (Chen et al., 2020). As AI continues to integrate into classrooms and educational institutions all over the world, it is essential to understand teachers' perspectives on this transformative force (Uygun, 2024).\nThe AI Helper, for example, when it comes to writing, provides feedback based on the content of texts in specific subject areas, which is more detailed, timely, and tailored to the immediate learning needs of students. In the AI Helper implementation, the researchers collaborated with the teachers to test the tool and its abilities to support their students in enhancing their writing skills. Also, the AI tool used was populated with appropriate prompts and rubrics that aligned with mainstream education standards and the teachers' syllabi, rubrics, and goals, accessible both to humans (teachers and students) and the GenAI through specific, detailed prompt engineering. Key features associated with CGScholar AI Helper included:"}, {"title": "5. Final Considerations", "content": "The main objective of the present paper was to investigate the extent to which the GenAI tool CGScholar AI Helper has the potential to enhance students' writing abilities and support teachers, specifically in ELA and History. The initial results show that the AI Helper has great potential to improve students' writing and support teachers in their instruction.\nThe AI Helper allowed timely and detailed feedback integrated into the teachers' specific content and subject. The GenAI tool brought benefits for both students and teachers. It helped the teachers with formative assessment during the learning process. The tool offered customization features, such as the possibility to insert and edit their rubrics, and add their activity prompts aligned with classroom-specific learning goals. There was a collaborative process between the research team, the participating teachers, and the AI developer. The collaborative communication promoted teachers' involvement in shaping the tool, increasing its effectiveness in these two diverse educational contexts.\nThe AI Helper is under research development and will consider the improvements suggested by the participating teachers and students along with the observation from the research team for the next phase of implementation. Iterative cycles of development and evaluation will continue as they are essential to realizing its full potential as a transformative educational tool in more real-world educational settings."}]}