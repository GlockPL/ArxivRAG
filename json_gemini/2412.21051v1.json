{"title": "Toward Intelligent and Secure Cloud: Large Language Model Empowered Proactive Defense", "authors": ["Yuyang Zhou", "Guang Cheng", "Kang Du", "Zihan Chen"], "abstract": "The rapid evolution of cloud computing technologies and the increasing number of cloud applications have provided a large number of benefits in daily lives. However, the diversity and complexity of different components pose a significant challenge to cloud security, especially when dealing with sophisticated and advanced cyberattacks. Recent advancements in generative foundation models (GFMs), particularly in the large language models (LLMs), offer promising solutions for security intelligence. By exploiting the powerful abilities in language understanding, data analysis, task inference, action planning, and code generation, we present LLM-PD, a novel proactive defense architecture that defeats various threats in a proactive manner. LLM-PD can efficiently make a decision through comprehensive data analysis and sequential reasoning, as well as dynamically creating and deploying actionable defense mechanisms on the target cloud. Furthermore, it can flexibly self-evolve based on experience learned from previous interactions and adapt to new attack scenarios without additional training. The experimental results demonstrate its remarkable ability in terms of defense effectiveness and efficiency, particularly highlighting an outstanding success rate when compared with other existing methods.", "sections": [{"title": "I. INTRODUCTION", "content": "The rapid technological advancement of cloud computing has notably accelerated recently, establishing itself as a significant paradigm in service-oriented computing. In the last decade, cloud computing has received huge attention due to its notable advantages such as scalability, flexibility, and increased cost-efficiency. For example, cloud computing has entangled with the daily lives of businesses and individuals, offering a diverse range of services (e.g., storage, network-ing, and platform provisions) seamlessly accessible from any geographical location connected to the Internet.\nDespite the obvious benefits of cloud computing, the diverse and complex nature of its various components, i.e., network, architecture, APIs, and hardware, has led to heightened secu-rity apprehensions. Due to the utilization of standard Internet protocols and virtualization methods, it is susceptible to po-tential security breaches. These vulnerabilities may stem from conventional sources such as IP spoofing, Address Resolution Protocol, and Distributed Denial of Service (DDoS) attacks, among others. Additionally, emerging threats such as zero-day attacks, characterized by their unknown nature, pose a considerable challenge to traditional solutions, which may not be sufficiently effective in mitigating such attacks.\nTo address the aforementioned challenges, several proactive defense techniques have been proposed, including Moving Target Defense (MTD) [1], cyber deception [2], Mimic Defense [3], among others. These methods emphasize the proac-tive identification, warning, and response to potential threats through automated and adaptive mechanisms, either before or during an attack, thereby effectively reducing security risks and minimizing potential losses.\nAlthough these solutions overcome, to some extent, the shortcomings of traditional solutions, they require modification of the mitigation mechanisms which may fail across diverse environments. Moreover, the decision-making of defense de-ployment predominantly relies on heuristic, machine learning, and deep learning algorithms. Nevertheless, given the increas-ing complexity of cloud-based applications and the wide array of attack vectors, it is hard for any specific strategy to fully adapt to the different and time-varying scenarios in the cloud. For this reason, there is an urgent requirement for an intelligent and adaptable guidance to facilitate proactive defense within the cloud environment.\nFortunately, as a typical example of Generative Foundation Models (GFMs) that can be adapted for specific purposes, Large Language Models (LLMs) have made a profound im-pact on research and practical applications [4]. Specially, LLMs excel in addressing general tasks through in-context learning, generating multimodal data via prompt engineering, breaking down complex problems into simpler components through strategic reasoning, simulating specified scenarios through role-playing, and making decisions based on prior knowledge and situational understanding [5]. Building upon these advantages, recent research has leveraged LLMs in the cybersecurity community, empowering security professionals to explore various attack vectors (e.g., vulnerability detection) and develop autonomous agents (e.g., code fixing). Therefore, the extensive knowledge encoded in LLMs has sparked our interest in explore their potential for comprehensive protection in the complex and ever-changing cloud security scenarios.\nIn this paper, differing significantly from the previous defense using expert knowledge or specific strategies, we leverage pre-trained LLMs with different prompts and deploy them across a variety of attack scenarios in the cloud domain, achieving enhanced protection and proactive response. The main contribution of this work includes the following.\n\u2022\tWe design a novel robust and efficient defense architec-ture called LLM-PD, with essential components of col-lection, assessment, decision, deployment, and feedback,"}, {"title": "II. BACKGROUND AND RELATED WORK", "content": "Proactive defense empowers cybersecurity personnel with anticipatory control over system defenses, establishing an advantage and enhancing protection to a more sophisticated level. Different from the reactive approach, it involves real-time monitoring of the system, enabling the rapid detection of changes in network traffic, analysis of program behavior, and the prevention of suspicious activities to ensure security.\nThere have been some efforts that attempted to enhance security in a proactive manner. For example, Zhou et. al [6] combine MTD technologies and Deep Reinforcement Learn-ing (DRL) in a seamless way to proactively defend against Low-rate DDoS attacks. This approach introduces a Markov decision process (MDP) to formalize attack scenarios and adopts a Deep Q-network (DQN) algorithm to mitigate the impact of attacks in a resource-efficient manner.\nMa et. al [7] leverage the mutation-enabled defense mech-anism in the cloud-native applications for mitigating Man-in-The-Middle (MITM) attacks. Driven by a maximizing coloring-based mutation grouping algorithm, it improves the robustness against attacks while guaranteeing the continuity of network connection with an acceptable performance loss.\nWu et. al [8] propose a security defense framework based on Intrinsic Cloud Security (ICS). It fuses the MTD concept and mimic defense theory within the Network Functions Virtualization (NFV) based cloud and subsequently imple-ments the integration to achieve proactive protection against multiple threats, including cache side-channel attacks, code reuse attacks, and latent persistent threats.\nHowever, existing work exhibits certain shortcomings, no-tably a lack of intelligent and adaptive strategic guidance, which is crucial for preventing advanced and sophisticated intruders. Although some methods incorporate intelligent al-gorithms, they often require extensive training over thousands of episodes. Moreover, the policies learned in one specific configuration typically do not generalize well and necessitate retraining when applied to even slightly different scenarios."}, {"title": "A. Proactive Defense in Cloud Networks", "content": null}, {"title": "B. LLM for Cybersecurity Enhancement", "content": "Traditional approaches, such as signature-based detection and rule-based systems, often struggle to keep pace with the ever-changing threat landscape in the dynamic cyberspace. However, advancements in LLMs have marked in a signifi-cant shift in cybersecurity paradigms, offering more adaptive and intelligent technologies [9]. Specifically, functionalities of LLMs have contributed to promising enhancements in defense applications, including threat detection, vulnerability analysis, automated defense mechanisms, and others.\nFor instance, SecurityBERT [10] processes network traffic by integrating the Privacy-Preserving Fixed-Length Encod-ing (PPFLE) method with the Byte-level Byte-Pair Encoder (BBPE) Tokenizer. It employs the Bidirectional Encoder Rep-resentations from Transformers (BERT) model in identifying fourteen types of attacks with high accuracy.\nFurthermore, Yin et. al [11] propose a pipeline for quan-titatively evaluating LLMs' performance in various software vulnerability-related tasks using publicly available datasets. Their evaluation results indicate that while LLMs perform well in certain aspects, there is still a need for improvement in understanding the subtle differences in code vulnerabilities and in their ability to describe these vulnerabilities, in order to fully realize their potential.\nAdditionally, an LLM-based software honeypot named SheLLM [12] was introduced to generate Linux-like shell output. This honeypot aims to evaluate the model's credibility by having security experts assess its responses to attackers' commands. The experimental results suggest that SheLLM can produce credible and dynamic responses, effectively address-ing the limitations of existing honeypots.\nOne of the main issues with these works is that the comprehensive aspect of the mitigation problem, which is not limited to the implementation of a single security feature, is often missing. Defending against complex threat vectors entails lifecycle protection over a relatively long time period and necessitates effective responses to attacker behaviors."}, {"title": "III. LLM EMPOWERED PROACTIVE DEFENSE ARCHITECTURE FOR CLOUD SECURITY", "content": "To achieve a self-autonomous, AI-driven, and secure-by-design defense implementation, we present an architecture, namely LLM-PD, that deeply integrates LLMs with existing security features. This integration aims to deliver intelligent, efficient, scalable, and proactive security enhancement across cloud networks. Fig. 1 illustrates the architecture of LLM-PD, which consists of five essential components as below."}, {"title": "A. Data Collection and Reconstruction", "content": "In cloud networks, the extensive deployment of network applications results in a substantial volume of data available for security purposes. This data includes network traffic, performance metrics, logs, events, and service configurations, etc. Essentially, each type of data is considered as independent and is formatted differently. For example, Wireshark is a tool that used to capture network traffic, typically in .pcap format, whereas alarm events are generated in .txt format based on firewall rules. Therefore, the ability to proficiently use multiple security tools and analyze massive heterogeneous data poses a significant challenge, even for cybersecurity professionals.\nPowered by the extraordinary prowess of LLMs, this com-ponent works as a collector, which is generally fed with a prompt of natural language descriptions that cover the range of targets, tools, time, and reconstruction format. In detail, the collector is first designed to call multiple security tools to gather data from the target cloud network within given time pe-riod. Specially, when new collection tools are introduced in the future, this collector can adapt by modifying its prompts easily. Next, to extract key concepts from multiple forms of data, it requires converting the data into text format and obtaining a brief report on the cloud network. Nevertheless, given the large number of data sources, redundant and irrelevant information is inevitable. To this end, the collector aggregates data by evaluating the relationships between them and eliminating duplicate contents. Finally, this module reconstructs the refined results into a standardized representation (e.g., JSON file) and transmits it to the next stage for further processing."}, {"title": "B. Status and Risk Assessment", "content": "Upon receiving the formatted information from the collec-tor, we necessitate another module prompted to serve as an analyzer to perform a thorough assessment of the data. To effectively ascertain the system's status and identify potential risks, this module encompasses two primary functions.\n1) Status Analysis: Within the status analysis function, information regarding hardware (e.g., power consumption), system (e.g., system load), network (e.g., inflow and outflow traffic volumes), and applications (e.g., number of connec-tions) can be readily extracted from specific fields in the received standardized file. Note that the status information of the target cloud network not only reflects the operational state of the system but also allows for the derivation of constraints for subsequent defense tasks. For example, when the system utilization is high, it implies that the defense objectives must be achieved under conditions of limited available resources.\n2) Risk Evaluation: The risk evaluation function primarily focuses on the security indicators of cloud networks. This function utilizes information collected from various monitor-ing tools, in conjunction with historical normal data, to identify potential threats and anomalies within the system. Concur-rently, the risk level is quantified (e.g., on a scale of 0-10) based on the scope, impact, and duration of the threat, thereby prioritizing following defense tasks. Additionally, in cases of cloud network failures caused by severe attacks or malicious disruptions (such as service interruptions), this feature can also leverage existing information for fault localization, effectively identifying attack targets and generating defense goals.\nFinally, the analyzer integrates the results of both functions and output them to the subsequent module. It then awaits the arrival of new data to initiate the next round of analysis."}, {"title": "C. Task Inference and Decision-Making", "content": "Based on the evaluation results from the analyzer, this module, functioning as a decision-maker, infers the defense tasks that need to be completed and formulates corresponding strategies. In complex cloud environments, however, multiple threats or failure points may arise simultaneously, requiring the simultaneous achievement of multiple defense objectives within a single overarching task. To prevent task conflicts and facilitate efficient decision-making, we have developed a hier-archical agent based on LLMs that decomposes complicated defense tasks into multiple subtasks, enabling the independent development of defense policies for each subtask.\n1) Task Decomposition: In a high-level threat scenario involving multiple defense objectives, it is significant to clearly plan and generate detailed tasks for better strategic reasoning. To this end, we have designed a task decomposition function that breaks down complex tasks into multiple independent subtasks. We require the LLM to delineate the implementation constraints of each subtask, assign priorities based on the previously mentioned risk levels, and analyze the dependencies among tasks for sequential arrangement.\n2) Inference and Decision-Making: In this process, tasks are executed sequentially according to their assigned order. For each subtask, this function systematically deduces the necessary step-by-step process required for decision-making, with the logic outlined as follows. First, details of the task are extracted from each subtask. Then, based on the current task requirements and constraints, human-like sequential reasoning for defensive actions over future attack-defense interactions is conducted. Additionally, this function is designed not only to enhance security but also to incorporate preferences, such as focusing on reducing defense overhead or ensuring user expe-rience. These preferences can be preset by security personnel and dynamically adjusted during implementation. Finally, by balancing defense effectiveness and preferences, it imports solvers to optimize the policy among the available strategies."}, {"title": "D. Defense Deployment and Execution", "content": "This module, which plays the role of deployer, is responsible for the deployment, implementation, and execution of defense strategies. Specifically, upon receiving a defense strategy, the module first extracts the defense mechanisms and actions in-cluded in the strategy. Then, it queries these defense measures involved to the matching function and determines if there are any corresponding items with the existing defense database.\nWhen a match is successful, the deployer proceeds to extract additional detailed information from the strategy, including deployment targets, execution commands, and implementation parameters. Subsequently, the module leverages these config-urations to invoke the existing defense actions, ensuring that they are aligned with the strategic objectives. These actions are then executed automatically within the target cloud net-work, facilitating efficient deployment of defense mechanisms without the need for manual intervention.\nWhen a particular mechanism does not exist in the defense library, the deployer harnesses the capabilities of LLMs to invoke programming languages, thereby generating useful scripts based on carefully crafted prompts to construct the nec-essary defense mechanism. Once these scripts are generated, they undergo a compilation process to ensure their operational integrity and compatibility with the cloud environment. Upon successful compilation, the scripts are deployed and executed within the cloud infrastructure, effectively implementing the desired defense mechanism according to the generated policy. Simultaneously, these newly generated scripts are archived in the defense library, enriching the repository with new capabilities and ensuring that similar requirements in the future can be addressed more efficiently.\nThis module not only enhances the adaptability and re-silience of the defense system but also ensures that the deploy-ment is both efficient and effective. Through this meticulous approach empowered by LLMs, the deployer allows itself to evolve dynamically in response to providing comprehensive protection against emerging threats."}, {"title": "E. Effectiveness Analysis and Feedback", "content": "After the execution of defense actions, this module plays the role of feedback giver to determine whether the current threat has been mitigated and to offer insights for future attack-defense interactions. By conducting a comprehensive evaluation of the defense effectiveness, the module quantifies the performance of the defense mechanisms post-execution, verifies if it meets expectations, and subsequently generates feedback for the LLM to incorporate into its memory.\nSpecifically, the evaluation of defense effectiveness is not limited to the analysis of a single factor. In this framework, we incorporate additional parameters beyond security, such as recovery time, resource consumption, financial cost, and Qual-ity of Service (QoS), to achieve a more comprehensive and rational assessment of effectiveness. Among these parameters, security remains the core element, signifying the capability to effectively mitigate cloud threats. Recovery time, on the other hand, is a critical measure of efficiency, reflecting the sys-tem's ability to swiftly restore cloud services to their normal operational state following an incident. Resource expenditure and financial cost provide insights into the expenses incurred by the defense actions. Meanwhile, QoS is assessed from the user perspective, highlighting the potential impact of defense actions on application performance and user experience.\nSubsequently, we introduced a validation function to rig-orously assess the effectiveness of the defense measures. This function serves a dual purpose: initially, it evaluates the efficacy of the strategies generated during the defense process, ensuring that they meet the desired objectives and effectively mitigate identified threats. Secondly, it verifies the correct implementation of the defense actions, confirming that they are executed as intended and align with the strategic goals. Additionally, this function annotates the current round's strategies and actions based on the validation results and transmits these annotations to the memory module for stor-age. The memory module plays a pivotal role in the self-improvement and evolution of the defense architecture by feeding both positive and negative memories back to other LLM agents. This iterative feedback loop enables a dynamic learning process and allows the system to adapt and refine its strategies over time, enhancing its resilience and effectiveness in the face of evolving security challenges. Importantly, this entire process occurs without the need for human intervention or expert knowledge, highlighting the autonomous and robust nature of the proposed protection."}, {"title": "IV. CASE STUDY", "content": "We simulate a prototype of LLM-PD with the support of GPT-40 mini, where five models are initially prompted to act as collector, analyzer, decision-maker, deployer, and feedback giver, respectively. Each model is constructed through a series of prompt engineering techniques, and Table I entails the input prompts for each component.\nTo evaluate our proposed architecture in defeating threats in cloud networks, we involve a DoS attack scenario. Specially, for SYN flooding and SlowHTTP attacks, we simulate an elas-tic service that can create up to 10 replicas, using a total pool of 100 pods. Each pod supports 256 connections and a maxi-mum memory utilization of 100. The initial setup activates 5 replicas, each comprising 10 pods. Moreover, we also discuss Memory DoS, a co-resident attack that specifically targets cloud infrastructure. Here we model a cluster infrastructure with 5 racks, each containing 10 physical machines, and each machine capable of hosting up to 10 Virtual Machines (VMs). The maximum number of memory contention per VM is limited to 100 with runtime capped at 100 time steps. We conduct 10 episodes per test, in which an episode concludes when the system status remains stable for 5 consecutive steps.\nIn addition, we extensively compare our proposed method with several well-known existing schemes, including DQN [6], Actor-Critic (AC) [13], and Proximal Policy Optimization (PPO) [14]. For fairness in our experiments, we adopt the same configurations and environments for training each scheme with the discount factor set to 0.98. The learning rate is 0.001 for the Q-network in DQN and the policy network in AC and PPO, and 0.01 for the value network in AC and PPO. All networks are shallow, with a single hidden layer containing 256 neurons. All the experimental results are collected from 200 independent tests, which are performed to mitigate environmental uncertainties."}, {"title": "A. Experimental Setups", "content": null}, {"title": "B. Results", "content": "Fig. 2 presents the performance when defending against three attacks within different attack strengths, where the x-axis represents the number of episodes, the y-axis represents the average surviving rate under the current episode, and n denotes the number of attackers. It is important to note that the average survival rate is measured by the probability of successfully mitigating an attack at each time step after a defensive action is taken to protect the system. Additionally, an episode refers to a complete operation cycle of LLM-PD architecture, and each episode retains the memory of feedback obtained from previous episodes. As we can see, the average surviving rate gradually increases for all attacks and strengths when running tests for more episodes, which implies the effectiveness of the generated policy, the correct deployment of defense mechanisms, and especially, the significant increase brought by the learned experience. Although more attackers pose a challenge and slightly decrease its performance, our solution still exhibits high surviving rates of 88.8%, 92.1%, and 93.5% when defending against attacks launched from 50 attackers due to the guidance from the LLM-based agents in our defense architecture.\nWe also present the number of average steps needed for successful defense against these attacks within 50 attackers in Table II, where e denotes the number of episodes. There is an observation that the steps for mitigating SYN Flooding, SlowHTTP, and Memory DoS attacks is 9.79, 9.55, and 16.3, respectively, when e = 2. This implies the difficulty of defeating different attacks is significantly different when equipped with less knowledge and experience. As the episode progresses, the accumulation of knowledge allows our method to respond with fewer steps and reduced response times, reducing the number of steps needed to successfully defend against various attacks. Specifically, the number of steps required converges to 7.51, 7.23, and 7.53 when e = 10. This can be attributed that LLM-PD avoids ineffective strategies and actions based on previous memory, thus promoting efficient resolution of diversified threats.\nIn addition, we compare LLM-PD with three previously discussed solutions in terms of success rate, and all methods are trained or prompted with the SYN Flooding scenario of 10 attackers in this comparison. It is worth noting that the success rate is a relatively broad indicator, focusing solely on whether the attack is ultimately resisted successfully, without considering whether all intermediate processes are optimal. As illustrated in Fig. 3, all methods exhibit more than 97.4% of success rate, and especially, our solution achieves the highest performance when there are 10 attackers. Nevertheless, unlike existing approaches, LLM-PD encapsulates a vast spectrum of knowledge and a rich understanding from previous experience that enables it to act without additional or specific training. Not only that, when there are more attackers involved, LLM-PD exhibits remarkable adaptability, remaining high success rate while other approaches significantly reduce to 48.5%, 24.5%, and 31.5% when dealing with 50 attackers. This observation implies that LLM-PD can be easily and swiftly adapted to new tasks or scenarios with relatively minimal additional training, offering a significant advantage over other methods that may require extensive retraining."}, {"title": "C. Designing LLM Empowered Secure Network Components", "content": "The proposed LLM-based proactive defense architecture is integrated into the existing cloud environment through additional attachment. However, the network components and defense mechanisms are predominantly implemented by hu-mans, which may introduce inherent flaws and maintenance challenges. Consequently, a significant direction for future research will be the design of LLM empowered network components that are flexible to adapt to various network architectures and incorporate built-in security features. Among them, compatibility and reliability will be key issues, that is, the newly generated components need to be able to seamlessly integrate with existing infrastructure, and be able to operate stably under high concurrency and load scenarios."}, {"title": "V. CHALLENGES AND FUTURE DIRECTIONS", "content": "LLMs are notoriously complex black-box systems, where the intricate nature of their design poses significant chal-lenges to interpretation and understanding. As these models become integrated into design, management, and control of the defense, and are entrusted with authoritative and decision-making roles, it is necessary to comprehend how they arrive at their conclusions and the rationale behind their decisions. In addition, understanding the logic behind can promote us to optimize and improve them, as well as trusting the behaviors of LLM agents. Therefore, developing explainable LLMs is essential for building user trust, ensuring a responsible and reasonable use of these models in the security domain."}, {"title": "A. Developing Explainable LLMs in the Security Domain", "content": null}, {"title": "B. Training and Updating Fully Automatic LLM agents", "content": "The development of fully-automatic, security-oriented LLM agents necessitates the integration of diverse capabilities in multiple techniques to achieve effective and efficient end-to-end protection, promoting a paradigm shift from human-assisted operations to the full replacement of security experts. Moreover, a significant challenge lies in ensuring the model's long-term relevance. The rapid evolution of network technolo-gies and security tools demands continuous updates to the training data. In this context, maintaining and updating the model in a resource-efficient manner is a critical issue for future research and efforts."}, {"title": "VI. CONCLUSION", "content": "The development of LLM is promising for tackling chal-lenges associated with mitigating cyberattacks. In this paper, we first introduce an innovative proactive defense architecture empowered by LLM to facilitate security improvement and threat mitigation within the cloud environment. By leveraging the advanced capabilities of LLM in data collection, security analysis, task inference, defense deployment, and effectiveness evaluation, our method is capable of thoroughly analyzing the security situation, efficiently executing suitable actions, and continuously evolving itself to adapt to varying and complex attack scenarios. Then a detailed case study on three kinds of DoS attacks is discussed. Experimental results demonstrate that the proposed architecture improves effectiveness and efficiency of defense than the state-of-the-art methods. Finally, we highlight future directions and open challenges to further enhance cloud security."}]}