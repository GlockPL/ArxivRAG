{"title": "Boundary-Decoder network for inverse prediction of capacitor electrostatic analysis", "authors": ["Kart-Leong Lim", "Rahul Dutta", "Mihai Rotaru"], "abstract": "Traditional electrostatic simulation are meshed-based methods which convert partial differential equations into an algebraic system of equations and their solutions are approximated through numerical methods. These methods are time consuming and any changes in their initial or boundary conditions will require solving the numerical problem again. Newer computational methods such as the physics informed neural net (PINN) similarly require re-training when boundary conditions changes. In this work, we propose an end-to-end deep learning approach to model parameter changes to the boundary conditions. The proposed method is demonstrated on the test problem of a long air-filled capacitor structure. The proposed approach is compared to plain vanilla deep learning (NN) and PINN. It is shown that our method can significantly outperform both NN and PINN under dynamic boundary condition as well as retaining its full capability as a forward model.", "sections": [{"title": "I. INTRODUCTION", "content": "The test case chosen to demonstrate the proposed approach is a simple electrostatic problem of a rectangular coaxial capacitor (Fig 1) [1], [3]. The electrostatic problem can be formulated as a Laplace equation which can be then solved applying FDM with a successive over-relaxation (SOR) algorithm [2], [3]. Although SOR is accurate and easy to implement, it is slow to compute as it has to comb through each node for the entire 2D grid to perform iterative update. Also, when the boundary conditions changes the computation has to be repeated. In this work, we target how to allow parameter changes on a single boundary condition without incurring new computational cost.\nConsidering the problem sketched in Fig 1, this structure has a symmetry that can be exploited when the origin is placed in the middle of the inner plate. With this arrangement only a quadrant of the problem need to be considered. For different lengths of the middle plate the parameter d changes which affects the boundary conditions, which in turns affects the solution of this problem. The effects of the electric potential distribution V(x, y) with changes in d are shown graphically in Fig 2 (Top). The boundary conditions definition as used in the FDM are given in eqn (1). In Fig 1 a, b are assumed fixed. The effect of increasing d on V is such that as d \u2208 [0, 1] increases, V increases in volume as shown in Fig 2 (top row)."}, {"title": "A. Problem Statement", "content": "Given that a regression model can model 1...m samples of electrostatic field as V1...m and corresponding boundary condition parameter as output BC (V1...m). Inverse prediction then tries to recover input V when presented with an output BC (.) = d.\nInverse prediction is an ill-posed problem due to: (i) The dimension of input is much larger than the output i.e. V\u2208 R1\u00d7N and BC(V) \u2208 R\u00b9 respectively. (ii) The regression model & in Algorithm 1 is sparsely distributed with a large number of zero coefficients. (iii) An initial estimate is necessary. Due to (i), (ii) and (iii), the optimization of V involves root solving a large number of coefficients e.g. N = 16081. Even a good initial value does not always"}, {"title": "II. PROPOSED METHOD", "content": "We simplify inverse prediction by proposing an end-to- end approach known as the boundary-decoder network in Algorithm 2. Both regression and inverse prediction are replaced by the boundary network. Instead, we directly feed an arbitrary boundary parameter to the network, and it will online reconstruct a corresponding V at the decoder using (2b). The offline training only involves a boundary-decoder loss\u00b2 in (2a) using the architecture in Fig 2 (bottom left). The advantages are: (i) Efficient representation: regression modeling, inverse prediction and latent representation are all handled by a boundary network. (ii) Semi-supervised model: the latent space is jointly trained by both encoder-decoder (unsupervised) and boundary-decoder network (supervised)."}, {"title": "III. EXPERIMENTS", "content": "In Table I, we compare the sum of squared error of reconstructed V vs groundtruth (SOR) using baseline and proposed method. Without any latent space, the overall inverse prediction is the poorest. Also for inverse prediction, we use a less accurate initial estimate to be \u00b10.2 from the actual d. For baseline we only train the encoder-decoder network (unsupervised). For proposed method, we separately train the boundary-decoder network (supervised) and the encoder- decoder+boundary-decoder network (semi-supervised). From the result, we observed that inverse prediction using the unsupervised method give the worst result. The proposed method does not require any initial estimate. Although the"}, {"title": "IV. CONCLUSION", "content": "We propose the boundary-decoder network which is an end- to-end approach that allows a user to directly feed boundary information into the latent space such that the decoder can reconstruct an electrostatic distribution that accurately corresponds to the boundary. We demonstrated our proposed method on a long air-filled capacitor dataset and compared that to using other computational method such as the PINN and the NN found in electrostatic analysis. We showed that our method can easily outperforms both NN and PINN under dynamic boundary condition of the underlying governing Laplace equation, as well as regression model both in the original space and latent space."}]}