{"title": "Expectation vs. Reality:\nTowards Verification of Psychological Games", "authors": ["Marta Kwiatkowska", "Gethin Norman", "David Parker", "Gabriel Santos"], "abstract": "Game theory provides an effective way to model strategic\ninteractions among rational agents. In the context of formal verification,\nthese ideas can be used to produce guarantees on the correctness of multi-\nagent systems, with a diverse range of applications from computer secu-\nrity to autonomous driving. Psychological games (PGs) were developed\nas a way to model and analyse agents with belief-dependent motivations,\nopening up the possibility to model how human emotions can influence\nbehaviour. In PGs, players' utilities depend not only on what actually\nhappens (which strategies players choose to adopt), but also on what\nthe players had expected to happen (their belief as to the strategies that\nwould be played). Despite receiving much attention in fields such as eco-\nnomics and psychology, very little consideration has been given to their\napplicability to problems in computer science, nor to practical algorithms\nand tool support. In this paper, we start to bridge that gap, proposing\nmethods to solve PGs and implementing them within PRISM-games, a\nformal verification tool for stochastic games. We discuss how to model\nthese games, highlight specific challenges for their analysis and illustrate\nthe usefulness of our approach on several case studies, including human\nbehaviour in traffic scenarios.", "sections": [{"title": "Introduction", "content": "Probabilistic model checking is a well established technique for formally verifying\ncomputerised systems that operate in uncertain or stochastic environments. In\norder to verify systems comprising multiple autonomous agents and/or those in-\nvolving human interactions, various models and concepts from game theory have\nbeen adapted for probabilistic model checking. Stochastic games, in particular,\nhave shown to be a versatile and useful formalism to model and study situations\ninvolving collaboration or competition among agents, successfully applied to, for\nexample human-in-the-loop autonomous systems [12], robot navigation in the\npresence of humans [18] and attack-defence scenarios [2].\nWhile traditional game theory is often used to model human decision making,\nit is unable to model situations such as emotional response and social norms,"}, {"title": "Preliminaries", "content": "We first recall normal form games (NFGs), over which we define Nash equilibria\n(NE), and then proceed by defining the psychological equivalents: normal form\npsychological games (NFPGs) and psychological Nash equilibria (PE).\nClassical games. We will write $Dist(X)$ for the set of probability distributions\nover a finite set $X$.\nDefinition 1 (Normal form game). A (finite, $n$-person) normal form game\n(NFG) is a tuple $N = (N, A, u)$ where:\n- $N = \\{1, ..., n\\}$ is a finite set of players;\n- $A = A\u2081 \u00d7 \u00d7 An, Ai$ is a finite set of actions available to player $i \u2208 N$\nand $Ai \u2229 Aj = \u00d8$ for $i \u2260 j \u2208 \u039d$;"}, {"title": "Equilibria Computation for Psychological Games", "content": "We now propose methods for analysing NFPGs in order to determine their PEs\nand corresponding values. The approach builds upon techniques for the non-\npsychological setting, i.e., finding NEs for NFGs. For the case of two-player\nNFGs (bimatrix games), we can use well known approaches such as the Lemke-\nHowson [28] algorithm or mixed-integer programming based on regret min-\nimisation [32]. For NFGs with more than two players, algorithms include the\nGovindan-Wilson [14] or Simplicial Subdivision [27], as well as search methods\nbased on support enumeration [30].\nWe take the support enumeration approach for NFPGs, by adapting the\nmethod of [24], which has been used to find social welfare optimal NEs for\nNFGs in a similar fashion. This approach exhaustively inspects sub-regions of\nthe strategy profile space, based on the idea that searching for NEs within a\nspecific support (see Definition 3) of a strategy profile is computationally easier.\nIt relies on encoding the computation of a (social welfare optimal) NE as a\nnon-linear programming (NLP) problem.\nThe NLP encoding leverages conditions for a strategy profile to characterise\nan NE, presented as a lemma in [24], and based on the notion of feasibility\nprogram introduced in [9,30]. The lemma states that a strategy profile of an NFG\nis an NE if and only if any player switching to a single action in the support\nof the profile yields the same utility for the player, and switching to an action\noutside the support can only decrease its utility. We adapt that lemma here to\ncharacterise a PE of an NFPG. This result follows directly from Definition 8 and,\nin particular, the fact that in equilibrium the belief profile needs to correspond\nto the strategies being played.\nLemma 1. A pair $(b,\u03c3)$ comprising a belief profile $b$ and a strategy profile\n$\u03c3=(\u03c3\u2081,...,\u03c3n)$ of $Np = (N, A, u)$ is a PE if and only if (1) and the following\nconditions are satisfied:"}, {"title": "Psychological Concurrent Stochastic Games", "content": "We next consider concurrent stochastic games (CSGs) [33], which are multi-\nstage games played over graphs where, at each state, players make simultaneous\nchoices that cause the game's state to be probabilistically updated. We present\na psychological variant of CSGs, in which, similarly to NFPGs, a player's utility\n(reward accumulated over a finite horizon) can depend on its belief as to the\nstrategies to be played as well as the actions that players select. We outline a\nprocedure to compute equilibria for a class of such games, which restricts the\nnature of the players' beliefs. As in previous work for CSGs [23], we consider\nsubgame perfect equilibria, which are equilibria at every state of a CSG.\nDefinition 9 (Concurrent stochastic game). A concurrent stochastic multi-\nplayer game (CSG) is a tuple $C = (N, S, \u00a7, A, \u0394, \u03b4)$ where:\n- $N = \\{1, ..., n\\}$ is a finite set of players;\n- $S$ is a finite set of states and $s \u2208 S$ is the initial state;\n- $A = (A\u2081\u222a\\{1\\})\u00d7\u2026\u00d7(An\u222a\\{1\\})$ where $A\u00bf$ is a finite set of actions available\nto player $i \u2208 N$, $A\u00bf \u2229 Aj = \u00d8$ for $i \u2260 j \u2208 N$ and $I$ is an idle action disjoint\nfrom the set $U_{i=1}^{N} Ai$;\n- $\u0394: S \u2192 2^{U_{i=1}^{N} Ai}$ is an action assignment function;\n- $\u03b4: (S\u00d7A) \u2192 Dist(S)$ is a probabilistic transition function."}, {"title": "Case Studies and Experimental Results", "content": "We have built a prototype implementation to model and solve psychological\ngames, and used it to investigate the applicability and performance of our ap-\nproach on a selection of normal form and multi-stage psychological games. We\nfirst consider two-player instances of the ultimatum and reciprocity games of [6],\nwhich exemplify how psychological games can also be used in the computation\nof fairness equilibria, as well as how psychological utilities can influence the\nstrategies of the players. We then present two- and multi-player normal form\ngames modelling traffic interactions between pedestrians, cyclists and vehicles,\none of which is then extended to a psychological CSG, used to investigate how\ninformation on past decisions can influence players' strategies.\nImplementation. We build on top of the PRISM-games model checker [23],\nextending its existing modelling language for CSGs (in which normal form games\ncan also be encoded as simple instances). The key difference is that in PG models\nthe specification of reward structures needs to incorporate a player's beliefs about\nthe other players' strategies. Since we currently only allow for beliefs in CSGs\nover local strategies (see Section 4), rewards for a state can only make reference\nto (the probability of) actions played in that state. Figure 2 shows a reward\nstructure definition in our extension of the PRISM-game modelling language for\nthe ultimatum game example (see Section 5.1, below). For simplicity, in this\nsyntax, we just use the name of the action to denote the probability of choosing\nit, e.g., reject denotes what we refer to elsewhere as $p_{reject}$."}, {"title": "Reciprocity and Ultimatum Games", "content": "We considered instances of the reciprocity and ultimatum games from [6], which\nare shown in Figure 3. In each case, player 1 chooses between making a fair (f)\nor greedy (g) proposal, and player 2 decides to reject (r) or accept (a) it. The\nrectangular boxes show the corresponding utilities of players 1 and 2, with player\n1's utility being above that of player 2. We present the games, as in [6], in\nextensive form, with the players' decisions taken sequentially, but will treat them\nas simultaneous moves in a single NFPG. Otherwise, beliefs would no longer be\nlocal since player 2's utility would depend on an earlier decision by player 1."}, {"title": "Traffic Games", "content": "We now report on a selection of case studies inspired by game-theoretic models of\ntraffic and road user behaviour. We start with a simple one-shot game between a\nvehicle and a pedestrian in a road crossing scenario, and how their expectations\ncan incentivise safe behaviour. Next we introduce a psychological variant of the\nBayesian game presented in [29], which examined how cyclists would interact\ndifferently with autonomous and regular vehicles. Finally, we extend the road\ncrossing scenario into a CSG and investigate the impact of combining information\non past decisions with local expectations in a multi-stage, probabilistic model.\nPedestrian crossing. We consider a scenario where a pedestrian is deciding\nwhether to cross a road near oncoming traffic, illustrated in Figure 5. We assume\nthat the car has a right of way and can reduce (r) or maintain (m) its speed,\nwhile the pedestrian may choose to cross (c) or wait (w). A psychological game\ncan be constructed by including incentives set to discourage behaviour based\non what they expect the other will do. We assume the pedestrian would be\n(illegally) jaywalking if they decided to cross, and so give them a negative reward\nproportional to the probability $p_c$ of that action being taken (multiplied by a\nconstant $\u03bc$), to model the pedestrian's fear of being caught and incurring a\npenalty. This parameterisation results in the following utility matrices for the\nvehicle and the pedestrian:"}, {"title": "Conclusions", "content": "We have presented techniques that expand the scope of modelling and verifica-\ntion for game-theoretic probabilistic models. Starting with psychological normal\nform games, we proposed an NLP encoding that allows us to compute optimal\nequilibria for individual supports and, through support enumeration, an overall\noptimal equilibrium for a given NFPG. We then considered CSGs whose states\ncan be expressed as NFPGs, and developed an algorithm to compute equilib-\nria for such CSGs under some restrictions on the type of the players' beliefs.\nFinally, we reported on a prototype implementation and showcased novel auto-\nmated analysis, made possible through our method, for a range of case studies.\nVerification of psychological games is still a largely unexplored topic and\nthere is ample room for expansion in theory, practice and applications to prob-\nlems in computer science. Equilibria computation is a hard problem in general,\nand algorithms for psychological equilibria suffer from some of the same com-\nputational drawbacks as those for Nash or correlated equilibria, in addition to\npresenting new challenges of their own. The main current limitation is having to\nrely on enumeration for computing an optimal solution, which could be some-\nwhat mitigated by parallelisation and filtering supports as a precomputation\nstep. Future work includes investigating dynamic psychological games [5], which\nhave the advantage of allowing belief updates but pose new modelling and com-\nputational challenges, and considering aspects of coordination and robustness\nvia correlated [1] and trembling-hand [21] variants."}]}