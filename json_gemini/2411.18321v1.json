{"title": "LEARNING OPTIMAL OBJECTIVE VALUES FOR MILP", "authors": ["Lara Scavuzzo", "Karen Aardal", "Neil Yorke-Smith"], "abstract": "Modern Mixed Integer Linear Programming (MILP) solvers use the Branch-and-Bound algorithm\ntogether with a plethora of auxiliary components that speed up the search. In recent years, there\nhas been an explosive development in the use of machine learning for enhancing and supporting\nthese algorithmic components [18]. Within this line, we propose a methodology for predicting the\noptimal objective value, or, equivalently, predicting if the current incumbent is optimal. For this\ntask, we introduce a predictor based on a graph neural network (GNN) architecture, together with\na set of dynamic features. Experimental results on diverse benchmarks demonstrate the efficacy of\nour approach, achieving high accuracy in the prediction task and outperforming existing methods.\nThese findings suggest new opportunities for integrating ML-driven predictions into MILP solvers,\nenabling smarter decision-making and improved performance.", "sections": [{"title": "1 Introduction", "content": "Mixed Integer Linear Programming (MILPs) is a widespread tool for modelling mathematical optimization problems,\nwith applications in numerous real-world scenarios. The Branch-and-Bound (B&B) algorithm, which employs a\ndivide-and-conquer approach, is the preferred method for solving MILPs to global optimality. In recent years, there\nhas been a surge in interest in harnessing the power of machine learning (ML) tools to aid the solution process of\nMILPs. From solution prediction (e.g. [6, 15, 20]) to interventions on the heuristic rules used by the solvers (e.g.\n[9, 4, 16]), several approaches have been studied in the literature (see Scavuzzo et al. [18] for an in-depth discussion\nof this topic). The overarching trend is to build dynamic MILP solvers that can make active use of the large amounts\nof data produced during the solving process.\n\nMany of the decisions that must be made during the B&B process could be better informed were the optimal solution\nknown from the start. In fact, even knowing the optimal objective value can positively influence the solver behaviour.\nFor example, once a solution is found that matches this value, any effort to find new solutions can be avoided. With\nperfect information of the optimal objective value, a solver can further do more aggressive pruning of nodes. In\ngeneral, having this knowledge can allow the solver to adapt its configuration, putting more emphasis on different\ncomponents. Even in absence of perfect information, a good prediction of the optimal objective value can still be used\nto change the solver settings or to devise smarter rules, such as node selection policies that account for this predicted\nvalue. Inspired by these observations we ask the two following closely-related questions:\n\n(Q1) How well can we predict the optimal objective value?\n\n(Q2) With what accuracy can we predict, during the solution process, whether or not a given solution is optimal?\n\nOur contributions are as follows. First, we propose a methodology to predict optimal objective values, answering (Q1).\nWe then use the output of this predictive model, together with additional data, as input of our proposed classifiers,\nwhich give an answer to question (Q2). For this second task, we also propose some metrics that capture the state of the\nsolving process, and that prove to be valuable for our classifier. Our computational study shows the high accuracy of\nour proposed predictor. Furthermore, when compared to previous methods, our classifiers show better performance.\nFinally, we provide further insight into how the performance can be tuned to the desired behaviour and into the ways\nthat the classifier makes use of the provided data.\n\nOur discussion is organized as follows. We start by defining some key concepts and notation in Section 2, followed\nby a discussion of the work most closely related to ours (Section 3). Section 4 describes our methodology in detail."}, {"title": "2 Background", "content": "Mixed Integer Linear Programming Given are a matrix $A \\in Q^{m\\times n}$, vectors $c\\in Q^n$ and $b \\in Q^m$, and a partition\n(I, C) of the variable index set {1, 2, ..., n}. A Mixed Integer Linear Program is the problem of finding\n\n$z^* = \\min c^T x$\nsubject to $Ax \\geq b$,\n$x_j \\in \\mathbb{Z}_{\\geq o} \\forall j\\in I$,\n$x_j\\geq 0 \\forall j\\in \u0421$.\n\nNotice that the variables in I are required to be integer. Removing this integrality constraint turns the problem into a\nLinear Program (LP), which constitutes a relaxation of the original MILP, known as the LP relaxation. While MILP\nis NP-hard, LPs are polynomial solvable.\n\nSolving Mixed Integer Linear Programs The standard approach to solving MILPs is to use the LP-based branch-\nand-bound (B&B) algorithm. This algorithm sequentially partitions the feasible region, while using LP relaxations to\nobtain lower bounds on the quality of the solutions of each sub-region. This search can be represented as a binary\u00b9 tree.\nAt a given time t of the solution process we use $T_t$ to denote the search tree, i.e. the set of nodes, constructed so far by\nthe B&B algorithm. We denote by $x^*$ the optimal solution to Problem (1) and $z^*$ its corresponding optimal objective\nvalue. For a given node i of the search tree, let $z_i^{LP}$ be the optimal objective value of the node's LP relaxation. We\nuse the notation $z^{LP}$ for the root node, i.e., the solution to the original problem's LP relaxation. At any point of the\nsearch, an integer feasible solution provides an upper bound on the optimal objective value. Let $x(t)$ be the best known\nsolution at time t and let $z(t) = cx(t)$ denote its objective value (also called the incumbent). Then we can prune any\nnode i such that $z_i^{LP} > z(t)$.\n\nThe nodes of $T_t$ can be classified into three types:\n\n\u2022 $I_t$ is the set of inner nodes of the tree. This is, nodes that have been processed (its LP relaxation solved) and\nresulted in branching.\n\n\u2022 $L_t$ is the set of leaves of the tree. This is, the set of nodes that have been processed and resulted in pruning or\nin an integer feasible solution.\n\n\u2022 $O_t$ is the set of open nodes, i.e., nodes that have not been processed yet.\n\nAs mentioned before, the incumbent $z(t)$ provides an upper bound on $z^*$. We can also obtain a global lower bound.\nLet $z(t) := \\min_{i\\in O_t}{z_i^{LP}}$. Then notice that necessarily $z(t) \\leq z^*$.\n\nIn practice, MILP solvers implement a plethora of other techniques to accelerate the solution process. Among them,\ncutting planes and primal heuristics are essential parts of today's mathematical optimization software.\n\nMILP solving phases The B&B algorithm can solve MILPs to optimality. This means that, if the algorithm termi-\nnates, it does so after having obtained a feasible solution and a proof of its optimality (or, on the contrary, proof of\ninfeasibility). Several solver components work together for this goal, each with more or less focus on the feasibility\nand the optimality parts. Berthold et al. [2] point out that, typically, the optimal solution is found well before the solver\ncan prove optimality. Following this, they propose partitioning the search process into phases, according to three target\ngoals. These phases are the following.\n\n1. Feasibility. This phase encompasses the time spanned from the beginning of the search until the first feasible\nsolution is found.\n\n2. Improvement. From the moment the first feasible solution is found until an optimal solution is found.\n\n3. Proving. Spans the time elapsed from the moment the optimal solution is found until the solver terminates\nwith a proof of optimality."}, {"title": "3 Related Work", "content": "MILP solution prediction In recent years, the topic of solution prediction for combinatorial optimization problems\nhas gained momentum [19, 7, 10]. For MILPs, the goal is to produce a (partial) assignment of the integer variables\nvia a predictive machine learning model. This prediction can then be used to guide the search in different ways. Ding\net al. [6] impose a constraint that forces the search to remain in a neighbourhood of the predicted optimal solution. In\nthis way, by restricting the size of the feasible region, the authors aim to accelerate the solution process. In contrast,\nthe approaches of Nair et al. [15] and Khalil et al. [12] consist in fixing a subset of variables to their predicted optimal\nvalue, letting the solver optimize over the remaining ones. Khalil et al. [12] further propose a solver mode that uses\nthe predicted solution to guide the node processing order. In the present work, we take a different path by aiming to\npredict the optimal objective value, as opposed to the solution, i.e., the values that each variable takes. This task is\neasier from a learning perspective, yet still offers several ways in which one can exploit this information.\n\nPhase transition predictions Berthold et al. [2] defined the three phases of MILP solving that were introduced\nin Section 2. Their goal is to adapt the solver's strategy depending on the phase. For this purpose, they propose\ntwo criteria that can be used to predict the transition between phase 2 (improvement) and phase 3 (proving) without\nknowledge of the optimal solution. These criteria are based on node estimates: for every node $i \\in T_t$, the solver SCIP\nkeeps an estimate $\\hat{e}(i)$ of the objective value of the best solution attainable at that node (see [2] for a formal definition\nof how this is computed). At time t of the solving process, let $\\hat{c}_{min}(t) := \\min{\\{\\hat{c}(i) | i \\in O_t\\}}$ be the minimum of\nthese estimates among the open nodes. We further define $d(i)$ to be the depth\u00b2 of node i. The first transition criterion,\nthe best-estimate criterion, indicates that the transition moment is the first time the incumbent becomes smaller than\n$\\hat{c}_{min}(t)$. Formally, let us define a binary classifier $C^{best}$ that indicates if the transition has occurred using the criterion\n\n$C^{best} = \\begin{cases}\n1 & \\text{if } \\min_{s\\in [0,t]} \\{z(s) \u2013 \\hat{c}_{min}(s)\\} < 0 \\\\\n0 & \\text{otherwise}.\n\\end{cases}$\n\nThe second criterion is called rank-1 and is based on the set of open nodes with better estimate than the processed\nnodes at the same depth. Formally, let\n\n$R'(t) := \\{i \\in O_t | \\hat{e}(i) \\leq \\inf{\\{\\hat{c}(j) : j \\in I_t \\cup L_t, d(j) = d(i)\\}}\\}.$\n\nThis set can be used to define a classifier $C^{rank-1}$ that indicates that the transition has occurred once the set becomes\nempty for the first time. This is,\n\n$C^{rank-1} = \\begin{cases}\n1 & \\text{if } \\min_{s\\in [0,t]} |R^1(s)| = 0 \\\\\n0 & \\text{otherwise}.\n\\end{cases}$\n\nThe authors use these criteria to switch between different pre-determined solver settings depending on the phase of\nsolving. Their experiments show improved solving time, especially when using the rank-1 criterion. However, it is\nalso clear that both criteria tend to be satisfied before the phase transition actually occurs, and there is some room for\nimprovement in the accuracy of the classifiers, as we shall see from our own computational study.\n\nB&B resolution predictions Closely related to the present work is that of Hendel et al. [11], who use a number\nof solver metrics to predict the final B&B tree size. They use a combination of metrics from the literature, together\nwith their own, as input to a machine learning model that estimates the final tree size dynamically as the tree is being\nconstructed. Their method was incorporated into version 7.0 of the solver SCIP as a progress metric for the user. In\na similar fashion, Fischetti et al. [8] use a number of solver metrics to predict, during the solving process, whether or\nnot the run will end within the given time limit. This prediction can be used to adapt the solver behaviour in the case\nthat the answer is negative."}, {"title": "4 Methodology", "content": "This section details the methodology used to answer questions Q1 (Section 4.1) and Q2 (Section 4.2). We assume\nwe are given a space X of instances of interest. For some tasks, we will use the bipartite graph representation of\nMILPs introduced by Gasse et al. [9]. This is, given an MILP instance X \u2208 X defined as in Eq. 1, we build a graph\nrepresentation as follows: each constraint and each variable have a corresponding representative node. A constraint\nnode is connected to a variable node if the corresponding variable has a non-zero coefficient in the corresponding\nconstraint. Each node has an associated vector of features that describes it. We utilize the same features as Gasse et\nal., except that we do not include any incumbent information. In short, instead of the raw data in X \u2208 X we use the\ngraph representation, which we denote $X_G \\in X_G$, and is composed of a tuple $X_G = (C, V, A)$, where $C\\in \\mathbb{R}^{m\\times d_c}$\nand $V \\in \\mathbb{R}^{n\\times d_v}$ represent the constraint and variable features, respectively, and $A \\in \\mathbb{R}^{m\\times n}$ is the adjacency matrix.\n\n4.1 Optimal value prediction\n\nThe first task we tackle is the one of predicting the optimal objective value (Q1). That is, given an MILP in-\nstance X \u2208 X, we want to predict the optimal objective value $z^*$. This prediction is computed once and for all at\nthe root node, once the LP solution is available. We frame this as a regression task. This process is depicted in Figure 1.\n\nFor this regression task, we utilise the bipartite graph representation of Gasse et al. [9] defined above, which is pro-\ncessed using a Graph Neural Network (GNN) that performs two half-convolutions. In particular, the feature matrices\nC and V first go through an embedding layer with two feedforward networks with ReLU activation. Next, one\nfirst pass updates the constraint descriptors using the variable descriptors, while a second pass updates the variable\ndescriptors using the (new) constraint descriptors. This is done with message-passing operations, computed as\n\n$c_i^' = W^{(11)} c_i + W^{(12)} \\sum_{j=1}^{n} A_{i,j} v_j$\n\n$v_j^' = W^{(21)} v_j + W^{(22)} \\sum_{i=1}^{m} A_{i,j} c_i$\n\nwhere $W^{(11)}$, $W^{(12)}$, $W^{(21)}$ and $W^{(22)}$ are trainable weights, $c_i$ is the feature vector of constraint i and $v_j$ is\nthe feature vector of variable j. The variable descriptors then go through another feedforward network with ReLU\nactivation. Finally, average pooling is applied to obtain one single output value.\n\nOur goal is to learn a mapping $f(X_g) : X_G \\rightarrow \\mathbb{R}$ which outputs an approximation $\\tilde{z}^*$ of the optimal objective value $z^*$.\nAt the moment of this prediction, the solution to the root LP relaxation is known and can be used for further context.\nIn order to exploit that knowledge, we test three potential targets for the machine learning model, namely\n$\\Theta_1 = z^*$"}, {"title": "4.2 Prediction of phase transition", "content": "The second task (Q2) is predicting the transition between phases 2 (improvement) and 3 (proving). That is, at any\npoint during the solution process we want to predict whether the incumbent is in fact optimal. We cast this problem\nas a classification task.\n\nWe test the performance of two classifiers. The first one is based on the output of the GNN model discussed in Section\n4.1. Given an instance X \u2208 X (in fact its associated graph representation $X_G$) and the current incumbent z, we obtain\na binary prediction $C^{GNN} : X_G \\times \\mathbb{R} \\rightarrow \\{0,1\\}$ in the following way\n\n$C^{GNN} (X_G, Z) = \\begin{cases}\n1 & \\text{if } z < f(X_G) + \\epsilon\\cdot |f(X_G)| \\\\\n0 & \\text{otherwise}\n\\end{cases}$\n\nfor some $ \\epsilon \\in [-1,1]$. The $ \\epsilon $ parameter allows us to control the confidence in the prediction.\n\nThe $C^{GNN}$ classifier is static, in the sense that it does not make use of any information coming from the B&B process.\nOn the contrary, the second predictor we propose, which we call $C^D$, is based on a set of dynamic metrics that are\ncollected during the solving process. The metrics are the following.\n\nGap Following SCIP [3], we define the gap as\n\n$g(t) := \\begin{cases}\n1 & \\text{if no solution has been found yet or } z(t) z(t) < 0, \\\\\n\\frac{|z(t)-\\underline{z}(t)|}{\\max{\\{|z(t)|,|\\underline{z}(t)\\} \\}}} & \\text{otherwise}.\n\\end{cases}$\n\nTree weight For a given node $v \\in T_t$, let $d(v)$ denote the node's depth. Then, the tree weight at time t is defined as\n\n$w(t) := \\sum_{v\\in L_t} 2^{-d(v)}.$\n\nThis metric was first defined by Kilby et al. [13].\n\nMedian gap Let $m(t) = median\\{z_i^{LP} | i \\in O_t\\}$ and let $z^0$ be the first incumbent found. We define the median gap\nas\n\n$\\mu(t) = \\frac{|z^{(t)} - m(t)|}{z^0}$.\n\nTrend of open nodes For a certain window size h, we store the values of $|O_k|$ for $k \\in \\{t - h, t \u2212 h + 1, ..., t\\}$. We\nthen fit a linear function using least squares to compute the trend of this sequence. We denote this trend at time t as\n$\\tau(t)$.\n\nRatio to GNN prediction We make use of the prediction $f(X_G)$ coming from the GNN model and include the ratio\nwith respect to the current incumbent as a metric. In particular we use\n\n$\\rho(t) = \\frac{f(X_G)}{z(t)}$.\n\nNotice that, while the gap and the tree weight are metrics from the literature, the other three are our own.\n\nThe input to the classifier is therefore a tuple $X_D = (g(t),w(t), \\mu(t), \\tau(t), \\rho(t))$. We train a classifier $C^D(X_D)$ that\nmakes use of these dynamic features to make a binary prediction on whether we are in phase 2 or 3. We use a simple\nlogistic regression, which will allow us to more easily interpret the resulting model, in contrast to more complex\nmachine learning models."}, {"title": "5 Computational Results", "content": "This section describes our computational setup and results. All experiments were performed with the solver SCIP\nv.8.0 [3]. Code for reproducing all experiments in this section is available online [17].\n\n5.1 Experimental Set Up\n\nBenchmarks We use three NP-hard problem benchmarks from the literature: set covering, combinatorial auctions\nand generalized independent set problem (GISP). We create a fourth benchmark (mixed) that is comprised of instances\nof the three types, in equal proportion. The method and configuration used for generation of the instances is summa-\nrized in Table 1. For each instance type, we generate 10,000 instances for training, 2000 instances for validation and\nanother 2000 for testing.\n\nPhase analysis As a first approach to the instances, we run an experiment to analyze the breakdown into solving\nphases. We solve 100 of the training instances, each with 3 different randomization seeds, which gives us a total of\n300 data points per benchmark. During the solution process we record the time when branching starts, the time when\nthe first solution is found, the time when a solution within 5% of the optimal is found, and the time when the optimal\nsolution is found. This allows us to compute the percentage of time spent on each phase, and the percentage of time\nspent branching versus before branching (i.e., pre-processing the instance and processing the root node). We average\nthese numbers over the 300 samples to obtain a view of the typical behaviour of the solver on each benchmark. We\nfurther divide phase 2 (improvement) into two sub-phases: (2a) from the first feasible solution to the first feasible\nsolution with objective value within 5% of the optimal, and (2b) which encompasses the rest of phase 2. The results\nare shown in Figure 2. We observe the following. For all benchmarks, obtaining a feasible solution is trivial. For set\ncovering instances, the optimal solution is often known by the time that branching starts. In the case of combinatorial\nauctions, the optimal solution is typically not known at the start of B&B, but a good solution is. For GISP, finding\noptimal, or even good, solutions is not as easy, making the proving phase relatively shorter. We conclude that these\nbenchmarks allow us to test our methodology on three very different settings that may arise in a real-life situation.\n\nData collection procedure For each instance, we collect information at the root node: the bipartite graph represen-\ntation $X_G = (C, V, A)$ and the optimal root LP value $z^{LP}$. We then proceed to solve the instance. For the first 100\nprocessed nodes and as long as no incumbent exists, no samples are collected. This allows us to initialize statistics\nas the trend of open nodes $ \\tau(t)$, and to ignore instances that are solved within 100 nodes which are therefore too\neasy. After 100 nodes have been processed and an incumbent exists, we collect samples with a probability of 0.02.\nAt sampling time, we record the value of the dynamic features (see Section 4.2), as well as the incumbent value $z(t)$.\nOnce the instance is solved, the collected samples are completed by appending the root node information $(X_G, z^{LP})$\nas well as the optimal objective value $z^*$, which will be used as a target.\n\nOptimal objective value prediction (Q1) We test the prediction accuracy of our GNN model on the four bench-\nmarks. We train a model for each of the targets described in Section 4. We measure the error as\n\n$e = 100 \\times \\sqrt{ \\frac{1}{N} \\sum_{i=1}^{N} |\\frac{z_i^* - \\tilde{z}_i}{z_i^*}|^2}$"}, {"title": "6 Conclusions", "content": "In this paper, we presented our methodology for predicting the optimal objective value of MILPs. Compared to the\nliterature on predicting optimal solutions, our learning task is easier, yet still offers a variety of possibilities for its\napplication within MILP solvers. Our methods can be used to both predict the optimal objective value and to classify a\nfeasible solution into optimal or sub-optimal. Our computational study shows that our proposed approach outperforms\nthe existing approaches in the literature. Further, they provide more flexibility to tune the model into the desired\nbehaviour. We show that there are benefits to learning a model that specializes to an instance type, yet our model is\nstill able to generalize well and have superior performance to other methods on mixed instance sets.\n\nThese results open the door for many possible applications. In general terms, this prediction can be used to adapt the\nbehaviour of the different solver components and rules depending on the solving phase. These applications, however,\nrequire further study and will be the subject of future work."}]}