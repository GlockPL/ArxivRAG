{"title": "ADAM: An Embodied Causal Agent in Open-World Environments", "authors": ["Shu Yu", "Chaochao Lu"], "abstract": "In open-world environments like Minecraft, existing agents face challenges in continuously learning structured knowledge, particularly causality. These challenges stem from the opacity inherent in black-box models and an excessive reliance on prior knowledge during training, which impair their interpretability and generalization capability. To this end, we introduce ADAM, An emboDied causal Agent in Minecraft, that can autonomously navigate the open world, perceive multimodal contexts, learn causal world knowledge, and tackle complex tasks through lifelong learning. ADAM is empowered by four key components: 1) an interaction module, enabling the agent to execute actions while documenting the interaction processes; 2) a causal model module, tasked with constructing an ever-growing causal graph from scratch, which enhances interpretability and diminishes reliance on prior knowledge; 3) a controller module, comprising a planner, an actor, and a memory pool, which uses the learned causal graph to accomplish tasks; 4) a perception module, powered by multimodal large language models, which enables ADAM to perceive like a human player. Extensive experiments show that ADAM constructs an almost perfect causal graph from scratch, enabling efficient task decomposition and execution with strong interpretability. Notably, in our modified Minecraft games where no prior knowledge is available, ADAM maintains its performance and shows remarkable robustness and generalization capability. ADAM pioneers a novel paradigm that integrates causal methods and embodied agents in a synergistic manner. Our project page is at https://opencausalab.github.io/ADAM.", "sections": [{"title": "Introduction", "content": "Embodied agents exploring open-world environments mark a critical frontier in artificial intelligence (AI) research (Cassell, 2000; Xia et al., 2018; Savva et al., 2019). The ultimate goal is to build generally capable agents (GCAs) (Team et al., 2021) that can autonomously perform a broad range of tasks through perception, learning, and interaction (Mnih et al., 2015; Xi et al., 2023; Park et al., 2023). Minecraft (Nebel et al., 2016), a globally renowned 3D video game, serves as a representative open-world environment for these agents. It offers a randomly generated world of massive blocks, where players need to master complex crafting recipes (e.g., planks + sticks\u2192 wood_pickaxe) and gather resources (e.g., mining cobblestone with wood_pickaxe), progressively unlocking new items in the technology tree. The substantial freedom and precise simulation of physical laws in Minecraft render it an exceptional platform for researching GCAs."}, {"title": "Preliminaries", "content": "Causal graphical models (CGMs). A CGM represents the structure of causality within a system (Peters et al., 2017) by detailing the direct causal relationships among a set of variables $X_1, . . ., X_n$. It is characterized by a distribution over these variables and is associated with a directed acyclic graph (DAG), known as a causal"}, {"title": "Method", "content": "In this section, we begin with the basic notations and definitions in our work (Sec. 3.1). Then, we give an overview of our ADAM framework (Sec. 3.2). Next, we detail the four modules of ADAM: interaction module (Sec. 3.3), causal model module (Sec. 3.4), controller module (Sec. 3.5), and perception module (Sec. 3.6)."}, {"title": "Notations and Definitions", "content": "We first introduce several key notations and definitions in our work. Sets are denoted by uppercase letters, and their elements by lowercase letters.\nInventory: The set $I_t$ of items possessed by the agent at any step $t$. Initialization: At the initialization of Minecraft instances, the initial inventory $I_0$ can be specified by the agent. Action Space: The set $A$ of actions whose names (e.g., gatherWoodLog) are replaced by letters and invisible. ADAM must independently discover the effects of these actions. Movement Space: The set $M$ of basic movements whose names (e.g., moveForward, moveBackward) are visible to ADAM. Step: The agent takes an action $a$ in the environment. A step ends either when action completes or when execution times out. Observed Item Space: The set $S$ of all items that ADAM has encountered. Initially, $S$ is empty. Environmental Factors: The set $\\mathcal{E}$ of environment conditions (e.g., biome, surrounding block types). Task: Denoted by the tuple $(I_{goal}, \\mathcal{E})$, a task is accomplished at step $t$ if $I_{goal} \\subseteq I_t$ and the factors $\\mathcal{E}$ are present within a certain distance around the agent."}, {"title": "Overview", "content": "ADAM comprises four modules as depicted in Fig. 1.2. Given a task $(I_{goal}, \\mathcal{E})$, the interaction module enables the agent to execute each action $a$ and records data $D_a$. This data is then utilized by the causal model module, which employs LLM-based CD to make causal assumptions and intervention-based CD to refine these assumptions into causal subgraphs. These subgraphs are integrated into a causal graph (i.e., technology tree). Once the causal graph $\\mathcal{G}$ contains all required items $I_{goal}$ in the task, the controller module completes the task from an empty inventory, aided by visual descriptions from the perception module. Newly discovered items enable the execution of new unknown actions and the CD on these actions. This iterative process ensures the lifelong learning through continuous engagement and adaptation. ADAM is a general framework that can be extended to other open-world environments, as discussed in Appendix F."}, {"title": "Interaction Module", "content": "The interaction module (Fig. 3.1) enables the agent to execute actions for sampling and records observable information. Initially, the action space $A$ contains one element gatherWoodLog, which is the most basic action in Minecraft and a common setup for Minecraft agents (Wang et al., 2023a). As the agent acquires certain new items, new actions are unlocked in $A$. For example, the action of mining becomes available only after the agent obtains a mining tool (e.g., a wooden_pickaxe). By continuously collecting data on each action and coordinating with other modules, the nodes on the technology tree are progressively discovered by the agent.\nSampling. This involves initiating a Minecraft instance with all observed items $S$ as the initial inventory $I_0$, and then executing action $a$ to observe the agent's inventory $I_1$ after this step. The quantity of each item in $S$ and $I_1$ is recorded. This sampling, represented as $(a, S, I_1)$, is performed $N$ times, focusing on one specific action at a time. Due to the same configuration of these $N$ samplings, parallelization is available and accelerates the exploration.\nRecording. This involves processing the results of samplings and documenting them. For the sampling (a, S, I\u2081), consumed items are denoted by X, which includes items with decreased quantities and items that are present in S but absent in I\u2081. Conversely, obtained items are denoted by Y, which includes items with increased quantities and items that newly appear in I\u2081. A single record is denoted as R = (S, X, Y). Such N records on action a collectively form data Da = {R1,...,RN}."}, {"title": "Causal Model Module", "content": "The causal model module uses data $D_a$ to infer causal relationships and constructs causal subgraphs for each action $a$. These subgraphs are then integrated into a comprehensive causal graph.\nA causal relationship is a stable and repeatable dependence in any step, where the agent takes an action $a$ and the acquisition of items $E$ (effect items) relies on the items $C$ (cause items) possessed by the agent before the step. Since ADAM focuses on item acquisition, causal relations where no items are obtained do not contribute to the technology tree.\nIn the causal model module, LLM-based CD makes assumptions on the causal relationships, which effectively reduces the number of item nodes that need to be confirmed in the causal subgraph and achieves acceleration. Then, intervention-based CD refines these assumptions and accurately constructs causal subgraphs. We also detail our optimization techniques employed in this module.\nLLM-based CD. The input to LLM-based CD (Fig. 3.2) is the data $D_a$ containing $N$ records, and the output is a causal assumption, which consists of cause items $C$ and effect items $E$. The prompt is designed"}, {"title": "Intervention-based CD", "content": "Intervention is a method to experimentally verify causal relationships among variables. Intervention-based CD (Fig. 3.3) can refine the causal assumptions and construct a highly accurate causal graph.\nBefore interventions, it has to be confirmed that $C$ is a sufficient condition for $E$. If $C$ has already lacked the necessary items to achieve $E$, then the vital edges are missing and the graph cannot be corrected by excluding redundant edges. Specifically, by sampling $(a, C, I_1)$ as described in section 3.3, if $E$ is consistently absent from $I_1$, the assumption is deemed incorrect, leading the LLM-based CD to re-infer the assumption. If these inferences continue to fail, the interaction module will resample data $D_a$.\nIntervention-based CD performs sampling $(a, C \\setminus \\{c\\}, I_1)$ for each item $c \\in C$. For each item $e \\in E$, if there is always $e \\notin I_1$ within a maximum number of samplings, then c is the cause of e, and the edge $c \\rightarrow e"}, {"title": "Controller Module", "content": "During the execution of task $(I_{goal}, \\mathcal{E})$, ADAM starts from an empty inventory (i.e., $I_0 = \\varnothing$) to ensure the fair comparison with other methods. After all items in $I_{goal}$ have been obtained in the causal graph, the controller module (Fig. 3.4) is responsible for executing the task. If there are newly discovered items, they will be added to the observed item space $S$ and pend for a new cycle of CD, thus achieving lifelong learning. The controller module comprises three components as described below.\nPlanner. The Planner utilizes LLMs to decompose the task with current inventory $I_t$ at step $t$ and the learned causal graph. Relying solely on the causal graph is suboptimal as actions may fail or have side effects. LLMs can fully utilize the inventory information and provide detailed thought process of the decomposition process, which is passed to the Actor for action choosing.\nActor. The Actor leverages LLMs to choose an action $a \\in A$ or a movement $m \\in M$ to execute. It receives the task decomposition from the Planner, the description of game image at this step, and the records from the Memory. In the task $(I_{goal}, \\mathcal{E})$, the Actor prioritizes obtaining the items $I_{goal}, because this process may affect the agent's surroundings. For instance, consider the task $(I_{goal} = \\{raw\\_iron\\}, \\mathcal{E} = \\{grass\\}\\)$, this"}, {"title": "Perception Module", "content": "The perception module (Fig. 3.5) utilizes MLLMs for environmental observation, enabling ADAM to perceive the world without relying on metadata such as the names of surrounding blocks, GPS coordinates, or the biome names, which are typically invisible to human players. This module captures first-person screenshots between steps, which are processed by MLLMs to generate descriptions. This text description is subsequently passed to the Actor in the controller module for action choosing."}, {"title": "Experiments", "content": "In our study, we employ Mineflayer (PrismarineJS, 2023a), a JavaScript-based framework providing control APIs for the commercial Minecraft (version 1.19) *. The encapsulation of Mineflayer uses the implementation in VOYAGER (Wang et al., 2023a). For visual processing, we utilize prismarine-viewer (PrismarineJS, 2023b), an API for rendering game scenes from the agent's perspective. ADAM and our baselines all use GPT-4-turbo (gpt-4-0125-preview) (Achiam et al., 2023) for LLM inference, with the temperature set to 0.3 based on"}, {"title": "Main Results", "content": "Interpretability. We evaluate the interpretability of agents by assessing their ability to construct a causal graph. Structure Hamming Distance (SHD) (Zheng et al., 2024) can quantify the discrepancy between the learned causal graph and the target graph as presented in Tab. 4.1. Despite applying our TM and SD optimization techniques (Section 3.4), non-embodied agents without built-in interventions fail to achieve the optimal accuracy. For CDHRL, we directly provide ADAM'S sampling data for its CD. CDHRL performs CD with all nodes in the causal graph, which hampers its performance as CDHRL shows improved performance when integrated with our SD optimization. Nevertheless, these competitive methods exhibit at least 30% errors or omissions, whilst ADAM is capable of learning a nearly perfect causal graph. VOYAGER does not organize knowledge in a causal graph.\nEfficiency. Efficiency is evaluated in the original Minecraft as shown in Tab. 4.2. ADAM achieves a 2.2\u00d7 speedup compared to the SOTA in the task of obtaining diamonds. Its design facilitates parallel sampling (Section 3.3), which significantly boosts exploration efficiency. While VOYAGER leverages prior knowledge from LLMs to excel in simple tasks, ADAM independently discovers world knowledge from scratch, outper- forming VOYAGER in complex tasks. Due to the absence of intervention-based CD, non-embodied agents are unable to refine their causal assumptions, limiting their exploration speed and confining them to the lower levels of the technology tree. Additionally, ADAM achieves higher success rate across most tasks compared to other methods."}, {"title": "Ablation Studies", "content": "Ablation of LLM-based CD Prior knowledge and inference capabilities are key factors in ablating LLM- based CD. Prior knowledge can be ablated in modified environments and enhanced through fine-tuning LLMs on MC-QA dataset we constructed*. Reasoning capabilities can be ablated by replacing SOTA LLMs with smaller LLMs. Our result in Tab. 4.4 shows that LLMs with strong reasoning abilities but limited prior knowledge (e.g., gpt-4-turbo-preview in modified environments) perform well, while LLMs with extensive prior knowledge but weak reasoning abilities (e.g., fine-tuned Llama-2-13B) perform suboptimally. This demonstrates that Adam primarily utilizes the reasoning abilities of LLMs rather than relying on prior knowledge.\nAblation of intervention-based CD. Without intervention-based CD, agents are forced to rely on ex- haustive trials to learn the game knowledge, significantly impairing their efficiency and effectiveness. Our experimental results are shown in Fig. 4.2. Through interventions, ADAM achieves up to 4.4 \u00d7 speedup and a higher accuracy compared to the ablated group."}, {"title": "Related Work", "content": "Causality in Agent. The integration of causality (Pearl, 2009; Peters et al., 2017; Sch\u00f6lkopf, 2022) into agents is primarily aimed at enhancing the learning efficiency (M\u00e9ndez-Molina et al., 2020; Seitzer et al., 2021; Gasse et al., 2021; Sun et al., 2021; Peng et al., 2022). Peng et al. (2022) propose CDHRL to build high-quality hierarchical structures in complicated environments. M\u00e9ndez-Molina et al. (2020) employ the causal models to restrict the search space. Zeng et al. (2023) distinguish agents with causality in two categories: ones relying on prior causal information and ones learn causality by causal discovery algorithms (Spirtes et al., 2000; Sun et al., 2007; Zhang & Hyv\u00e4rinen, 2009; Zhang et al., 2011; Peters et al., 2014; Zhu et al., 2019). Our work aligns"}, {"title": "Conclusion", "content": "In this work, we introduce ADAM, an embodied causal agent in open-world environments. ADAM innovatively incorporates CD with embodied exploration, significantly improving the accuracy of CD while enhancing the efficiency and interpretability of embodied exploration. Not relying on prior knowledge, ADAM demonstrates strong robustness, and its multimodal perception aligns with human behavior. Our work sets a foundation for developing autonomous agents that can understand and manipulate environments in a causal manner."}, {"title": "MC-QA dataset", "content": "Minecraft is an open-world game with a high degree of freedom. Players can freely gather materials (e.g., log$\\uD83E\\uDDF1$ , mine ore (e.g., iron_ore$\\uD83E\\uDDF1$), craft tools (e.g., wooden_pickaxe$\\uD83E\\uDDF1$), and more. Crafting recipes (e.g.,\nplanks$\\uD83E\\uDDF1$ + sticks\u2192 wood_pickaxe$\\uD83E\\uDDF1$) are the main knowledge in the Minecraft game, and serve as\nthe basis for players to climb the technology tree and obtain more advanced items.\nGiven this, LLMs' mastery of crafting recipes can reflect the strength of their prior knowledge in the Minecraft\ngame. We utilize the crafting recipes in Minecraft (version 1.19) to create the MC-QA dataset. An example of\nthe QA pairs in the dataset is shown in Fig. .1. The questions in this dataset ask for the crafting ingredients\nrequired to obtain higher-level items in the technology tree, and the answers are the ingredient items. LLMs\nneed to give their answers in the specified format. The order of the items in the answer is not required. For\neach question, we provide 3 examples to help LLMs understand the QA task and the format of the answers.\nFor situations where there are multiple ways to craft the same item, we take them all into account to avoid\nthe model being biased toward a fixed understanding of the game. The dataset contains 754 QA pairs on the\nknowledge of obtaining items in the Minecraft."}, {"title": "LLM's prior on Minecraft", "content": "We utilize the Minecraft crafting recipes to construct an MC-QA dataset (introduced in Appendix A), aiming\nto evaluate the prior knowledge of various LLMs on Minecraft. We test and determine that 0.3 is the optimal\ntemperature as shown in Fig. B.1a. Then we test various LLMs on this dataset. The GPT series (Ouyang et al.,\n2022; Achiam et al., 2023) show significantly stronger Minecraft prior knowledge than other LLMs as shown\nin Fig. B.1b.\nUtilizing this dataset to fine-tune LLMs can improve their prior knowledge on Minecraft as shown in Fig.\nB.1c. On the other hand, by modifying the crafting recipes in Minecraft, we can make the SOTA LLMs (e.g.,\nGPT series) have no prior of this modified environment. This setup enables us to distinctively analyze the"}, {"title": "Agent in Minecraft", "content": "RL explorations in Minecraft agents focus on the efficient use of data (Baker et al., 2022; Fan et al., 2022),\nhierarchical RL design (Lin et al., 2021; Mao et al., 2022), innovative architecture modeling (Hafner et al., 2023),\netc. Hafner et al. (2023) use world models to achieve a general and scalable RL without human data or curricula.\nMuch work (Guss et al., 2019, 2021; Kanervisto et al., 2022; Fan et al., 2022) has made different simplifications\nfor the Minecraft environment to facilitate the RL agent systems. The MineDojo framework (Fan et al., 2022)\nprovides an internet-scale knowledge database and game environments for CLIP model (Radford et al., 2021)\nand RL training. These efforts provide efficient optimization for agent sampling and interaction, but there\nis still a gap to commercial Minecraft games with complete game features like in VOYAGER (Wang et al.,\n2023a) and our work.\nThe reasoning capabilities and rich prior knowledge of LLMs have contributed to much work on Minecraft\nagents (Yuan et al., 2023; Zhu et al., 2023; Wang et al., 2023a; Qin et al., 2023b; Nottingham et al., 2023; Wang\net al., 2023d,c). VOYAGER (Wang et al., 2023a) and GITM (Zhu et al., 2023) use LLMs' prior knowledge of\nMinecraft and environment feedback to complete exploration tasks in a text-based manner. Qin et al. (2023b)\nleverage MLLMs to introduce visual information as the contextual basis for action execution. These methods\nmore or less rely on prior knowledge of Minecraft. Our ADAM shows effectiveness even when the game rules\nare modified.\nThere are also Minecraft agents that integrate LLMs with RL, including Plan4MC (Yuan et al., 2023), DEPS\n(Wang et al., 2023d), and JARVIS-1 (Wang et al., 2023c). These methods operate in non-commercial Minecraft\nenvironments and utilize frame-level control, with approximately 104 steps for a task, in contrast to the\nactions with around 102 steps for a task. Furthermore, these RL methods require training stages, whereas our system does not involve weight updates. Notably, JARVIS-1 incorporates\ncrafting recipes as an integral part of the system, utilizing prior knowledge rather than learning from scratch."}, {"title": "Implementation Details", "content": "The prompt for LLM-based CD is shown in Fig. D.1, which is composed of 5 components: (1) Role Playing,\nwhich assigns a specific role to the LLM; (2) Problem Setting, which provides specific details of the inference\ntask; (3) Letter Mapping, which involves mapping item names to letters, a simplification that facilitates the\nformatted output; (4) Few-shot Prompting, which involves providing the LLM with several inference examples\nin chain-of-thought (Wei et al., 2022b) style; (5) Data Da, which is the data collected by the interaction module\nfor inference."}, {"title": "Action Space and Movement Space", "content": "We have implemented 41 discrete actions and 6 movements to ensure the agent can freely explore the Minecraft\nworld through a diverse range of combinations. The actions can be divided into three categories: \u201cSmelting\u201d,\n\"Collecting\", and \"Crafting\". \"Smelting\" actions have complex causal subgraphs, often leading to omissions in\nLLM-based CD. \"Collecting\" actions have noisy sampling data, and the results of the LLM-based CD are often\nredundant. The \"Crafting actions have complex causal subgraphs and clean sampling data."}, {"title": "Robustness", "content": "Tab. E.1 shows our experiment result in the modified Minecraft environment where the crafting recipes are\naltered. ADAM can maintain its performance as it is equipped with CD methods, whereas agents that rely on\nprior knowledge struggle to explore efficiently. The result demonstrates the robustness and generalization\ncapabilities of our ADAM architecture."}, {"title": "Generalization", "content": "The ADAM architecture is a general framework for embodied agents operating in various open-world environments including Minecraft. When adapting ADAM to other application scenarios, some modifications may be\nnecessary:\n(1) The world knowledge in Minecraft is the dependence between items and actions. Consequently, in this\npaper, items and actions are designed as causal graph nodes. When migrating to other environments,\nkey elements related to the agent's task objectives can be similarly designed as causal graph nodes.\n(2) In ADAM, the perception module utilizes a vision-based MLLM and does not rely on omniscient\nmetadata. This allows the module to adapt well to other visual tasks. If conditions permit (e.g., a robot\nequipped with LiDAR), the perception module can provide more precise information, potentially further\nimproving performance.\n(3) To model actions as a finite set of causal graph nodes, it is necessary to discretize the continuous action\nspace. The granularity of this discretization should be determined based on the specific environment."}]}