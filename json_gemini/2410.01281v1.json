{"title": "UNCERTAINTY-AWARE HUMAN MOBILITY MODELING AND\nANOMALY DETECTION", "authors": ["Haomin Wen", "Shurui Cao", "Leman Akoglu"], "abstract": "Given the GPS coordinates of a large collection of human agents over time, how can\nwe model their mobility behavior toward effective anomaly detection (e.g. for bad-\nactor or malicious behavior detection) without any labeled data? Human mobility\nand trajectory modeling have been studied extensively with varying capacity to han-\ndle complex input, and performance-efficiency trade-offs. With the arrival of more\nexpressive models in machine learning, we attempt to model GPS data as a sequence\nof stay-point events, each with a set of characterizing spatiotemporal features, and\nleverage modern sequence models such as Transformers for un/self-supervised\ntraining and inference. Notably, driven by the inherent stochasticity of certain indi-\nviduals' behavior, we equip our model with aleatoric/data uncertainty estimation.\nIn addition, to handle data sparsity of a large variety of behaviors, we incorporate\nepistemic/model uncertainty into our model. Together, aleatoric and epistemic\nuncertainty enable a robust loss and training dynamics, as well as uncertainty-\naware decision making in anomaly scoring. Experiments on large expert-simulated\ndatasets with tens of thousands of agents demonstrate the effectiveness of our model\nagainst both forecasting and anomaly detection baselines. All code is available at\nhttps://anonymous.4open.science/r/mobility-ad.", "sections": [{"title": "1 INTRODUCTION", "content": "Anomaly detection of human mobility has become crucial for various applications, ranging from\nsecurity and surveillance to health monitoring. Accurately detecting anomalous human behavior\nfrom GPS data can reveal critical insights, such as abnormal patterns that indicate security threats or\nspread of infectious diseases Meloni et al. (2011); Barbosa et al. (2018); Stanford et al. (2024).\nHowever, the complexity and inherent uncertainty of human behavior make this task particularly\nchallenging: (1) The first difficulty lies in capturing the complex spatiotemporal dependencies both\nwithin individual activities and between multiple activities across different times and locations. The\nformer aims to capture the correlations between different spatiotemporal features (a.k.a. markers) of\na single activity; such as the time-of-day (e.g. 4am) being indicative of POI location (e.g. home). The\nlatter associates with the dependency patterns between different activities over time (e.g. restaurant at\nweekday lunchtime followed by office building). (2) Furthermore, human activity data is abound with\nuncertainty arising from the unpredictable behavior of inherently stochastic individuals as well as\ndata sparsity-making accurate anomaly detection even more difficult.\nPrior work on behavior modeling often focused on temporal event forecasting, either ignoring spatial\ninformation Minor et al. (2015); Manzoor and Akoglu (2017) or based only on a few markers Du et al.\n(2016); Zhou et al. (2022). With the emergence of the Transformer architecture Vaswani et al. (2023),\nmore recent work modeled complex spatiotemporal events more expressively Xue et al. (2022);\nCorrias et al. (2023). However, to our knowledge, no existing work considered uncertainty-aware\nanomaly detection of human mobility.\nTo address both of the above challenges, we introduce UIFORMER for uncertainty-incorporated\nhuman behavior modeling and anomaly detection, which takes advantage of a \"dual\" Transformer\narchitecture Truong Jr and Bepler (2023) as well as aleatoric and epistemic uncertainty into account.\nTransformer has emerged as the de facto model for modern AI problems, due to its superior ability to"}, {"title": "2 PROBLEM AND PRELIMINARIES", "content": "We introduce related concepts and formulate the anomaly detection problem on human mobility.\nStay-point Event. As shown in Figure 1, a stay-point\nevent is extracted from raw GPS data that is used to\ndescribe an individual's daily activity. Let er be an\nevent with spatiotemporal features (or markers) xi:\n$x_i = (x_{st}^i, x_{sd}^i, x_x^i, x_y^i, x_{poi}^i, x_{dow}^i)$,\nwhere $F_n = {x_{st}^i, x_{sd}^i, x_x^i, x_y^i}$ is the numerical feature set: $x_{st}^i$ and $x_{sd}^i$ are the start time and stay du-\nration of the event, $x_x^i, x_y^i$ are the two-dimensional coordinates depicting the latitude and longitude of the\nevent's location. $F_c = {x_{poi}^i, x_{dow}^i}$ is the categorical feature set, depicting the Point-of-Interest (POI)\nsuch as office building, store, etc. and Day-of-Week(DOW) of the event, respectively.\nSpatiotemporal Event Sequence. Let $E_u = [e_1^u, e_2^u, ..., e_{N_u}^u]$ be the event sequence that records\nall historical events of individual u in the dataset, where $N_u$ is u's total number of historical events.\nFurthermore, let $e_i^{u,d}$ be the i-th event of individual u at day d, and $N_{u,d}$ be the number of events of\nu on day d. The event sequence with w-day time window can be given as\n$E_u = [e_1^{u,d-w}, e_2^{u,d-w}, ..., e_{N_{u,d-w}}^{u,d-w},..., e_1^{u,d}, ..., e_{N_{u,d}}^{u,d}],$"}, {"title": "3 PROPOSED MODEL", "content": "Figure 2 illustrates the overall architecture of UIFORMER, which learns human mobility patterns in\na self-supervised manner through pre-training, with the goal of accurately reconstructing masked\nevents as well as evaluating the prediction uncertainty. In a nutshell, the feature tokenizer first projects\nfeatures into high-dimensional space by representing each event's feature as an individual token (\u00a73.1).\nThen, the Dual-Transformer encoder further encodes the input by both feature-level and event-level\nself-attention (\u00a73.2). Lastly, unlike previous work, we introduce the uncertainty-aware decoder to\nrecover all features of the masked event along with the aleatoric and epistemic uncertainty associated\nwith each feature (\u00a73.3). These estimates are used to compare the predicted versus observed events at\ninference time for uncertainty-incorporated anomaly scoring (\u00a73.4).\n3.1 FEATURE TOKENIZER\nThe feature tokenizer transforms all features $x \u2208 R^F$ of an event into embeddings $e \u2208 R^D$, where F\nis the number of input features and D is the embedding dimension. Specifically, a numerical feature\n$x_j^{(num)}$ is projected by a linear transformation with weight $W_j^{(num)} \u2208 R^D$ and bias $b_j \u2208 R^D$, and the\nembedding of a categorical feature is implemented as the embedding lookup table $W_j^{(cat)} \u2208 R^{C_j\u00d7D}$,"}, {"title": "3.2 DUAL TRANSFORMER ENCODER", "content": "Inspired by (Truong Jr and Bepler, 2023), we design a Dual Transformer encoder that treats the data\nas a sequence-of-sequences, which takes the sequence of events each with a sequence of feature\nembeddings as input, and models both feature-level and event-level interactions with two types of\nTransformer-based (Vaswani et al., 2023) components. A description of the Transformer block is\nincluded in Appendix B.\nFeature-level Transformer. By considering each feature as an input token to the Transformer, the\nFeature-level Transformer represents a feature in a way that explicitly incorporates other features'\ninformation. In the implementation, we convert the feature tokenizer's output $E_0 \u2208 R^{B\u00d7L\u00d7F\u00d7D}$\ninto $E_1 \u2208 R^{(B\u00d7L)\u00d7F\u00d7D}$, which is then fed into $M_1$ Transformer blocks to get the updated feature\nembeddings $E_2 \u2208 R^{(B\u00d7L)\u00d7F\u00d7D}$. Note that we do not include any positional embedding as input for\nthis module as there is no sequential relationship between the features of an event.\nEvent-level Transformer. Based on $E_2$, we calculate\nan event's embedding by averaging all its corresponding feature embeddings, which results in the input of the\nEvent-level Transformer $E_3 \u2208 R^{B\u00d7L\u00d7D}$. The Event-level\nTransformer then captures the dependencies (e.g., sequential patterns) between different events by considering each\nevent as a token. Moreover, considering that the sequential\ninformation in the event sequence is important to reflect\nhuman mobility behavior, we design two types of positional encoding for each event: (i) Sequence positional encoding; used to describe the order of an\nevent in the input sequence, and (ii) Within-day positional encoding (as shown in Figure 3); used to\ndescribe the order of the event in its specific day, explicitly demarcating day boundaries. After $M_2$\nupdates of the Event-level Transformer blocks, we get the final output of the encoder $\u0112 \u2208R^{B\u00d7L\u00d7D}$."}, {"title": "3.3 UNCERTAINTY-AWARE DECODER", "content": "Motivation. Uncertainty modeling has shown great promise in various fields, such as computer\nvision (Kendall and Gal, 2017; Kendall et al., 2016) and natural language processing (Xiao and Wang,\n2019; Gal and Ghahramani, 2016b). In particular, human mobility sequences are inherently associated\nwith uncertainty. For instance, certain individuals (e.g., shift workers) may exhibit highly predictable\npatterns (i.e., low uncertainty), while others (e.g., retirees) can be much more unpredictable in their\nactivities over time. This type of uncertainty, known as aleatoric uncertainty (or data uncertainty)\n(Kendall and Gal, 2017), arises naturally from the data itself and cannot be reduced by simply adding\nmore training data. In addition to aleatoric uncertainty, our setting also involves epistemic uncertainty,\nwhich refers to the uncertainty in the model itself due to limited knowledge. This type of uncertainty\ncaptures the model's confidence in its own predictions and can be reduced by acquiring more data or\nimproving the model specification or architecture. In human event sequence modeling, epistemic\nuncertainty is crucial for identifying situations where the model lacks sufficient information to make\nconfident predictions, especially in underrepresented or complex scenarios. Furthermore, given that\ndifferent features can have different predictability even for the same individual/event, we design a\nfeature-level uncertainty learning mechanism. In the following part, we elaborate on how we model\nthe epistemic and aleatoric uncertainty for both numerical and categorical features."}, {"title": "3.3.1 EPISTEMIC UNCERTAINTY MODELING", "content": "Inspired by (Kendall, 2018), we model the epistemic uncertainty by placing a prior distribution over\nthe model's parameters, and then try to capture how much these parameters vary given observed data.\nTo ease the presentation, we use s to denote the input instance Eu, and \u03b8 to denote all parameters of\nthe model M. We start by assuming \u03b8 follows a prior distribution, which reflects our initial belief\nabout the possible values of these parameters. The goal is to update this belief based on the available\ndata s by calculating the posterior distribution of \u03b8, that is p(\u03b8|s). This posterior captures how the\nparameters might vary, thereby reflecting the model's uncertainty about its predictions. Formally,\nBayes' theorem (Bayes, 1763) gives us the posterior: $p(\u03b8|s) = \\frac{p(s|\u03b8)p(\u03b8)}{p(s)}$\nHowever, computing the exact posterior distribution in deep learning models is often intractable due\nto the high dimensionality of the parameter space and the complexity of the model. As a practical\nalternative, we apply Monte Carlo (MC) Dropout (Gal and Ghahramani, 2016a) to approximate the\nposterior. In practice, we introduce dropout layers after the embedding layer of each feature with a\ndropout ratio of 0.05, which randomly drops a subset of neurons during both training and inference.\nMC Dropout works by sampling different subsets of model parameters \u03b8 during each forward pass,\nthereby creating an ensemble of models. The variance in the predictions across these passes provides\nan estimate of the epistemic uncertainty.\nEpistemic uncertainty for numerical features: The decoding of numerical feature $f \u2208 F_n$ is modeled\nas a regression task. In this case, the variance of the predictions across T (equals 50 in our model)\nsteps of stochastic forward passes quantifies the epistemic uncertainty $a_f^{num}$ for f, formulated as\n$a_f^{num} : Var(y) = \\frac{1}{T}\\sum_{t=1}^T (M_{\u03b8_t}(s) - \\bar{y})^2, where  \\bar{y} = \\frac{1}{T} \\sum_{t=1}T M_{\u03b8_t}(s)$,\nEpistemic uncertainty for categorical features: The decoding of categorical feature $f \u2208 F_c$ is\nmodeled as a classification task. We apply the softmax function to the logits produced by the\nmodel, giving a probability distribution over the classes: $p(y|M_\u03b8(s)) = softmax(M_\u03b8(s))$. Here, the\nepistemic uncertainty is measured by the entropy of the predicted probability distributions averaged\nby multiple forward processes, formulated as\n$a_f^{cat} : H(p) = - \\sum_c p_c log(p_c), where p(y = c|s) = \\frac{1}{T} \\sum_{t=1}^T softmax(M_{\u03b8_t}(s))$.\nOverall, we approximate the epistemic uncertainty for both numerical and categorical features by MC\nDropout, providing a practical and scalable way to capture the model's uncertainty in its predictions."}, {"title": "3.3.2 ALEATORIC UNCERTAINTY MODELING", "content": "We model aleatoric uncertainty by placing a distribution over the model's output. For example,\nin this paper, we model the regression output as a Gaussian distribution with random noise, i.e.,\n$p(y|M_\u03b8(s)) = N(M_\u03b8(s), \u03c3^2)$, where aleatoric uncertainty aims to learn the variance of noise as a\nfunction of the input data.\nAleatoric uncertainty for numerical features: Let $\u03c3_f$ denote the noise level of a feature $f \u2208 F_n$,\nwhich captures how much noise we have in the output of the feature. Moreover, we assume that $\u03c3_f$ is\ndata-dependent and can vary with the input. Then, $\u03c3_f$ can be learned as a function of the data:\n$L_f^{reg} = \\frac{1}{2\u03c3_f^2} ||y_f - \\hat{y}_f||^2 + \\frac{1}{2}log \u03c3_f^2$\nwhere yf and \u0177f are the true and predicted value of f. $\u03c3_f$ is also a model's output that serves as a\nlearned loss attenuation. It gives less penalty to the model when the input data is associated with high\naleatoric uncertainty, thus making the loss more robust to noisy data. The second term in Eq. (5) is a\nregularization term that prevents the model from learning a high uncertainty score for all instances,\ntrivially driving the first term to zero. In practice, we further adopt a more numerically stable loss\ngiven as: $L_f^{reg} = exp(-r_f) ||y_f - \\hat{y}_f||^2 + \\frac{1}{2}r_f$, where $r_f = log \u03c3_f^2$. Instead of predicting the\nvariance directly, predicting the log variance followed by an exponential function can ensure the\npositive value of the variance and make the training more numerically stable. In that case, the aleatoric\nuncertainty for numerical feature f is denoted as $\u03b2_f^{num} := \u03c3_f^2$."}, {"title": "Aleatoric uncertainty for categorical features:", "content": "Let $C_f$ denote the number of unique categories (i.e.\nclasses) of feature $f \u2208 F_c$. For the classification task, the model assumes that the prediction logits at\nsample time t for each category follows a Gaussian distribution:\n$m_{f,t} = \u03bc_f + \u03c3_f\u03f5_t, \u03f5_t \u223c N(0, I)$,\nwhere the predicted mean logits $\u03bc_f \u2208 R^{C_f}$ and uncertainty term $\u03c3_f \u2208 R^{C_f}$ are the model outputs,\nas a function of its parameters at the t-th sample time. $\u03f5_t \u2208 R^{C_f}$ represents a random vector drawn\nfrom a unit normal distribution N(0, I). Here $\u03c3_f$ accounts for the inherent uncertainty in the feature\nwhen conducting the prediction. The aleatoric uncertainty of categorical feature f is then the average\nof variance across all classes, given as $\u03b2_f^{cat} := \\frac{1}{C_f} \\sum_c \u03c3_{f,c}^2$\nTo learn such uncertainty, the loss function $L_f^{cls}$ calculates the cross entropy based on the average\npredicted logits, normalized over all possible categorical outcomes:\n$L_f^{cls} = - \\frac{1}{C_f} log \\sum_c exp m_{f,t,c} - log  \\sum_{c'} exp m_{f,t,c'}$\nThe above loss function achieves a similar effect to the numerical case, which can also be considered\nas learning the loss attenuation (Kendall and Gal, 2017). When the model assigns a high logit value\nmt to the observed class c, and the noise value \u03c3\u03b5 is low, the loss approaches zero which is\nthe desired outcome. Overall, the total training loss is the sum of the regression and classification losses\nacross all features, given as:\n$L = \u03bb \\sum_{f \u2208 F_n} L_f^{reg} + \\sum_{f\u2208F_c} L_f^{cls}$ ,\nwhere \u03bb is a hyper-parameter designated to balance the scale of regression and classification losses.\nIn our model, we set \u03bb = 1 for simplicity."}, {"title": "3.4 UNCERTAINTY-INCORPORATED ANOMALY SCORING", "content": "We compute event-level anomaly scores by aggregating deviations between the predicted and the\nobserved values of all features, incorporating both epistemic and aleatoric uncertainties into the\ncomputation. For each test event on a given day, we first create a sequence of events spanning\na 3-day window, including the previous and next day as context. We mask the event of interest\nand use the pre-trained UIFORMER to predict the masked features. For numerical features, we\ncalculate the deviation as: $\u2206_f = |y_f - \\hat{y}_f|$ with yf and \u0177f depicting the observed and predicted\nvalues, respectively. For categorical features, the deviation is computed as: $\u2206_f = 1 - p_f$ where pf is\nthe predicted probability of the observed class. UIFORMER learns the inherent patterns of human\nbehaviors using only normal data during training. Intuitively, higher deviations from these patterns\nsuggest that an event is less consistent with learned behaviors and thus, more anomalous. Then, we\ncan compute an anomaly score (AS) for a target event e from the deviations alone as:\n$AS(e) = agg (pth (\u2206_f) | f \u2208 F_nUF_c)$,\nwhere agg(\u00b7) denotes the aggregation function (e.g., mean or max) applied over $\u2206_f$'s across all\nfeatures F. The percentile function pth(\u00b7) is used to standardize deviations across features of different\nscales, effectively capturing the relative ranking of the deviation for each feature. This helps ensure\nthat features with smaller absolute deviations are not undervalued compared to those with larger\ndeviations. However, using deviations alone to detect anomalies is insufficient due to the diverse\nnature of human mobility. Some agents may deviate from the general population's behavior but are\nnot necessarily anomalous. For instance, a (stochastic) agent with a tendency to explore different\nlocations frequently (i.e., with high data uncertainty) may have higher deviations naturally, which does\nnot imply an anomaly. To account for such cases, we propose to incorporate uncertainty estimates\ninto the anomaly score. By scaling down deviations by the uncertainties, we can prevent inflating the\nanomaly scores of agents whose behaviors, though atypical, are still consistent with natural variability.\nAs such, we compute an uncertainty-incorporated anomaly score (UI-AS) for a target event e as:\n$UI-AS(e) = agg  pth (\\frac{\u2206_f}{1 + a_f + \u03b2_f}  | f\u2208 F_nU F_c)$\nwhere $a_f + \u03b2_f$ denotes the total of the aleatoric and epistemic uncertainties for feature f."}, {"title": "4 EXPERIMENTS", "content": "We conduct extensive experiments to investigate the following research questions (RQs):\nRQ1: What is the performance of UIFORMER in the masked prediction task?\nRQ2: Can our model outperform previous approaches in the anomaly detection task?\nRQ3: Does UIFORMER have the ability to accurately capture aleatoric and epistemic uncertainty?\nRQ4: How does each uncertainty component contribute to UIFORMER?\nDatasets. We utilize two human activity datasets, namely SimLA and NUMOSIM. SimLA is an expert-\nsimulated dataset that contains human mobility data in greater Los Angeles area. NUMOSIM (Stanford\net al., 2024) is a publicly-available synthetic human mobility dataset, designed to benchmark anomaly\ndetection techniques for mobility data. Both datasets are obtained by training deep learning models\non real mobility data and simulating realistic human mobility patterns, incorporating both normal and\nanomalous behaviors. The statistics of the two datasets are shown in Appendix Table 5.\nWe split the data into train/validation/test temporally by date, respectively spanning 3/1/2 weeks.\nDuring training, we randomly mask events in each sequence using a specified mask ratio. For\nvalidation and test data, we mask only one event per sequence, aligning with how we use the\npre-trained model for anomaly detection."}, {"title": "4.1 RQ1: MASKED PREDICTION RESULTS", "content": "Settings. For baselines, we include classical deep models MLP (Murtagh, 1991), LSTM (Hochreiter\nand Schmidhuber, 1997), the original Transformer (Vaswani et al., 2023), as well as Dual-Tr; a variant\nof UIFORMER that removes the uncertainty estimation mechanism and only keeps the dual Trans-\nformer architecture (w/ cross-feature and cross-event attention). In addition, since UIFORMER can\nestimate the uncertainty of its prediction, we also report its conformal prediction performance where\nthe top-5% most uncertain test samples are not evaluated, denoted by UIFORMER (5%). We report\nMAE and MAPE to evaluate the prediction performance of numerical features and use accuracy\n(ACC) for the categorical features. Higher ACC and lower MAE and MAPE indicate better perfor-\nmance. The models are trained on 1 GPU of NVIDIA RTX A6000. We search the hyperparameters\nin a given model space for all deep models, and each model's best performance is reported in the\nexperiments. Detailed experiment settings and model configurations can be found in Appendix C."}, {"title": "4.2 RQ2: ANOMALY DETECTION RESULTS", "content": "Settings. There are only a few related public achievements for human mobility anomaly detection,\nthus it is difficult to find state-of-the-art models for direct comparison. For a comprehensive evaluation,\nwe implement some baselines as well as extract core components from related literature in trajectory\nanomaly detection, including Spatial-Temporal Outlier Detector (STOD) (Cruz and Barbosa, 2020),\nRioBus (Bessa et al., 2016), a self-supervised (SS) MLP, LSTM, and Transformer. STOD and RioBus\nare designed for bus trajectories to predict the Bus ID from the sequence of GPS coordinates which we\nrepurpose for human trajectories. SS-MLP is trained to distinguish real events from fake ones that are\nsynthetically-constructed via random alterations. Further details on baselines are given in Appendix\nD. We report two common metrics for evaluation: AUROC (Area Under ROC curve) and AUPR\n(Area Under Precision-Recall curve). These are frequently used for anomaly detection as quantities\nof ranking quality. As the percentage of anomalous events is very small on the original datasets, we\nconstruct two additional one with around 5% anomalies by including agents with anomalous events\nand randomly sampling normal agents without any anomalous events. Dataset statistics for anomaly\ndetection can be found in Appendix Table 6."}, {"title": "4.3 RQ3: ANALYSIS OF UNCERTAINTY ESTIMATION", "content": "Next we scrutinize the quality of the estimated uncertainty scores. To this end, we analyze the\nrelationship between prediction accuracy as a function of total uncertainty, as well as how the\nestimated aleatoric and epistemic uncertainty scores vary by the amount of training data using SimLA.\nRelationship between uncertainty and MAE/accuracy. We first sort the test samples by the\ntotal AU+EU uncertainty score (i.e., $\\sum_{f\u2208F}\u03b1_f + \u03b2_f$), and then gradually remove test samples with\nuncertainty larger than a certain percentile threshold while recording the prediction performance of\nUIFORMER on the rest. As shown in Figure 4, UIFORMER's performance gradually improves as\nwe exclude test samples with large total uncertainty. This means that the uncertainty estimates are\nwell aligned with prediction performance, as all MAE (Accuracy) curves follow a monotonically\nincreasing (decreasing) trend for numerical (categorical) features. Notably, for stay duration (SD)\nprediction (middle), MAE increases sharply from around 20 minutes to 35 minutes due to the top\n5% most uncertain samples. As for the POI prediction (right), around 50% of the most certain\nsamples can yield a quite promising performance that achieves near 100% accuracy, which gradually\ndrops with increasing uncertainty. Interestingly, AU-only UIFORMER (in blue) appears to be more"}, {"title": "4.4 RQ4: ABLATION STUDY", "content": "As uncertainty is a key component of our anomaly detection model, we conduct ablation studies on\nits role from both the training and inference perspectives.\nUncertainty from the training perspective. To study the role of aleatoric versus epistemic un-\ncertainty estimation, we consider three variants of UIFORMER: (i) UIFORMER-AU, which only\nimplements the aleatoric uncertainty while keeping the model backbone the same as UIFORMER, (ii)\nUIFORMER-EU, which only models epistemic uncertainty; and (iii) UIFORMER-none, which only\nhas the bare Dual Transformer and does not model epistemic or aleatoric uncertainty."}, {"title": "5 RELATED WORK", "content": "Human Mobility Modeling. Methods in this field can be broadly categorized into traditional\nstatistical models and the more recent deep learning approaches. Traditional statistical approaches\ntypically rely on specific functional forms such as Poisson or Hawkes processes to predict event\narrival times (Hawkes, 1971; Daley and Vere-Jones, 2008; Ogata, 1998), which struggle to capture\nthe intricate spatiotemporal patterns present in human mobility data. Other statistical methods\nlike Markov Chains, use transition matrices to predict future locations (Chen et al., 2014; Gambs\net al., 2012; Cheng et al., 2013; Monreale et al., 2009) yet they fall short in modeling long-term\ndependencies. With the rise of deep learning, models such as RNNs and LSTMs have been used to\nlearn the complex transition patterns (Gao et al., 2017; Song et al., 2016; Du et al., 2016), leading\nto better performance in the next location and trajectory prediction. Most recently, there has been\na growing trend of using Transformer-based models for human mobility and trajectory data (Wan\net al., 2021; Feng et al., 2018; Xue et al., 2021; Abideen et al., 2021; Wu et al., 2020; Wang and\nOsaragi, 2024), mainly inspired by its immense success in modeling inherently sequential data in NLP.\nHowever, most Transformer-based models overlook the underlying uncertainty in the data, especially\nas it pertains to human behavior over time. Specifically, most prior work focus on pretraining solely\nbased on the masked reconstruction loss, without uncertainty estimation of the prediction. This\nmotivates us to develop a new uncertainty-aware model to fill the gap, toward more effectively\ncapturing human behavior that is often dependent on time and context.\nUncertainty Estimation in Deep Neural Networks. Uncertainty estimation has been studied in\nthe field of NLP (Gal and Ghahramani, 2016b; Xiao and Wang, 2019) and CV (Kendall et al., 2016;\nHuang et al., 2018), which shows great promise in reflecting the underlying uncertainty in outcomes\nand thus improving task performance. One common approach is the Monte Carlo (MC) Dropout (Gal\nand Ghahramani, 2016a), which estimates uncertainty by applying dropout during inference, thereby\nimproving model robustness. Others employ deep ensembles for model uncertainty estimation\nLakshminarayanan et al. (2017). Kendall and Gal (2017) propose to learn aleatoric uncertainty\nthrough loss attenuation while modeling epistemic uncertainty using MC Dropout in both regression"}, {"title": "6 CONCLUSION", "content": "We introduced UIFORMER for human mobility modeling and anomalous behavior detection.\nUIFORMER is equipped with both data and model uncertainty estimation to account for the stochas-\nticity inherent to human nature as well as the data scarcity in sufficiently observing complex human\nbehavior. While its dual-attention mechanism captures dependencies among features and events,\nuncertainty estimation lends itself to more robust training and more nuanced anomaly scoring. Exper-\niments on two benchmark datasets showed that UIFORMER outperforms existing baselines, while\nablation analyses underscored the benefit of uncertainty-aware forecasting and anomaly detection."}, {"title": "A DATA STATISTICS", "content": null}, {"title": "B DETAILS OF TRANSFORMER BLOCK", "content": "Transformer Block, which contains two key components: a Multi-Head Self-Attention (MSA) layer\nand a Feed-Forward Network (FFN) layer. The MHA layer facilitates message passing between\ninput tokens, while the FFN applies non-linear transformations to enhance feature extraction across\ndifferent dimensions of the input vectors. To capture more complex interactions between tokens,\nmulti-head attention is employed, where the attention mechanism is defined in Equation (11).\n$Attention(Q, K, V) = softmax( \\frac{QKT}{\\sqrt{d}} )V$,\nwhere $Q \u2208 R^{N\u00d7D}, K \u2208 R^{N\u00d7D}$, and $V \u2208 R^{N\u00d7D}$ represent the query, key, and value matrices,\nrespectively, all projected from the same input matrix E (which have different forms in Feature-level\nTransformer and Event-level Transformer) with different learnable weight matrix. The softmax\nfunction transforms the scaled dot product into attention weights for V, and d is the dimensionality of\nK used for scaling the inner product. Besides, more high-order mutual information can be captured by\nstacking multiple Transformer blocks. Denote the embedding outputted by block $m \u2208 {1,\u2026, M}$\nas em, its updating process can be formulated as follows\n$\\hat{e_i} = e^{m-1} + MSA^m(head^{m-1},..., head^{m-1})$\n$e^m = \\hat{e_i} + FFN(\\hat{e_i})$.\nwhere nhead is the number of heads."}, {"title": "C DETAILED SETTINGS FOR MASKED PREDICTION", "content": "Baselines. The following methods are chosen as baselines: (1) MLP (Murtagh, 1991), which applies\nmultiple Linear layers to encode the event sequence, and decodes the masked features according\nto the embedding from the last layer. (2) LSTM (Hochreiter and Schmidhuber, 1997), a recurrent\nneural network commonly used to model sequential data, it reads the event sequence and decodes\nthe masked event based on its hidden vector. (3) Transformer(Vaswani et al., 2023), one of the most\npowerful sequence models nowadays, which models the correlation of different events by multi-head\nself-attention. (4) Dual-Transformer, a variant of our proposed model, which removes the uncertainty\nlearning mechanism and only keeps the dual Transformer architecture.\nMetrics. We consider the prediction of numerical features and categorical features as regression and\nclassification tasks, respectively. To this end, we apply MAE and MAPE to evaluate the performance\nof regression, and Accuracy (ACC) is applied to evaluate the classification performance. The unit for\nx, y are kilometers while the unit for start time and stay duration are minutes.\nSettings. The models are trained on 1 GPU of NVIDIA RTX A6000. For all deep models, we search\nthe parameters in a given parameter space, and each model's best performance is reported in the\nexperiment. Here we report the parameter search space of our model: the mask ratio for pre-training\nis searched from [0.05, 0.3]. The embedding size for the transformer is searched from [32, 64, 128],\nand the layers for the transformer are searched from [2, 3, 5]. The batch size of each epoch is searched\nfrom 128 and the learning rate of Adam optimizer starts from 1e-3 with a weight decay le-05."}, {"title": "D DETAILED SETTINGS FOR ANOMALY DETECTION", "content": "Baselines. We selected the following baseline methods for comparison: RioBus Bessa et al. (2016),\nSpatial-Temporal Outlier Detector (STOD) Cruz and Barbosa (2020), a self-supervised MLP (SS-\nMLP), LSTM, and Transformer. RioBus Bessa et al. (2016) is initially applied to bus trajectories and\nemploys a Convolutional Neural Network (CNN) to predict the ID of the bus based on the sequence\nof GPS coordinates. For agent-level anomaly scores, it uses the negative probability of"}]}