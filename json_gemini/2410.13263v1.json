{"title": "A Simplifying and Learnable Graph Convolutional Attention Network for Unsupervised Entity Alignment", "authors": ["Weishan Cai", "Wenjun Ma", "Yuncheng Jiang"], "abstract": "The success of current Entity Alignment (EA) task depends largely on the supervision information provided by labeled data. Considering the cost of labeled data, most supervised methods are difficult to apply in practical scenarios. Therefore, more and more works based on contrastive learning, active learning or other deep learning techniques have been developed, to solve the performance bottleneck caused by the lack of labeled data. However, the existing unsupervised EA methods still have some limitations, either their modeling complexity is high or they cannot balance the effectiveness and practicality of alignment. To overcome these issues, we propose a Simplifying and Learnable graph convolutional attention network for Unsupervised Knowledge Graphs alignment method (SLU). Specifically, we first introduce LCAT, a new and simple framework as the backbone network to model the graph structure of two KGs. Then we design a reconstruction method of relation structure based on potential matching relations for efficiently filtering invalid neighborhood information of aligned entities, to improve the usability and scalability of SLU. Impressively, a similarity function based on consistency is proposed to better measure the similarity of candidate entity pairs. Finally, we conduct extensive experiments on three datasets of different sizes (15K and 100K) and different types (cross-lingual and monolingual) to verify the superiority of SLU. Experimental results show that SLU significantly improves alignment accuracy, outperforming 25 supervised or unsupervised methods, and improving 6.4% in Hits@1 over the best baseline in the best case.", "sections": [{"title": "1. Introduction", "content": "Knowledge Graphs (KGs) have gradually become a new approach to manage massive information, and various domains such as social networking, reasoning, question answering, recommendation, safety and security are actively exploring their relevant applications [1, 2, 3]. Despite the growing data volume and application scope, KGs still cannot provide enough knowledge to support downstream applications due to their limited coverage. Therefore, it is important to study the integration techniques for heterogeneous KGs. One of the core tasks is Entity Alignment (EA), which aims to identify the same entities in different KGs, thus realizing data merging of multiple KGs.\nRecent advances in representation learning techniques have accelerated the development of embedding-based EA methods. Traditional EA methods first rely on known aligned entities (also called alignment seeds, or pre-aligned entity pairs) as supervisory signals, learn entity embeddings by projecting entities with different KGs into a uniform embedding space, then utilize some vector similarity functions to measure entity similarities and predict alignment results. Existing EA methods can be categorized into two main groups: relation-based methods and auxiliary-based methods. The relation-based EA methods are built on the assumption that aligned entities have similar relation neighborhood structures. They utilize translate-based methods (e.g., TransE [4]) or GNNs (e.g., GCN [5], GAT [6]) to obtain relation structural features of entities. Auxiliary-based methods introduce additional information of entities such as attributes, attribute values, images, etc., to improve embedding learning of entities. However, there are still some limitations of these methods nowadays, weakening their usefulness and robustness in real KGs.\nLimitation 1: Most methods use increasingly sophisticated models to better capture the neighborhood similarity of aligned entities. Due to the powerful structure learning capabilities, GNNs have been used as the encoders in many works [7, 8, 9] to enhance the ability to capture structural information of KGs. For example, RPR-RHGT [7] and RANM [8] design the variant attention mechanism, which adds the relational heterogeneity of KGs into the calculation of attention coefficient. PEEA [9] introduces a novel position encoding method that considers both anchor links and relational information from a global view. However, these work usually employ variants of GNNs or superimpose multiple GNNs, which inevitably introduces a large number of neural networks parameters. As a result their modelling complexity is increasing and model training is inefficient. This problem will be more prominent if these methods are applied to large KGs in real scenarios. Therefore, how to balance the effectiveness and complexity of the model is the issue to focus on in this task.\nLimitation 2: Auxiliary-based methods [10, 11, 12, 13] fall short in terms of in model effectiveness, usefulness and modelling efficiency. Firstly, the introduction of auxiliary information helps to enhance the extraction of entity features, but also introduces more noise. The auxiliary information associated in different KGs is often inconsistent, making the selection or identification of valid and identical auxiliary information a complex task. These methods usually require a significant amount effort and time to eliminate the heterogeneity of auxiliary information among KGs. Secondly, real KGs do not always contain information such as attributes, attribute values, images, etc. The more auxiliary information a method utilizes, the more data it requires for its application, which means that the method is more demanding for the application scenario. Thirdly, it is obvious that the more auxiliary information introduced, the complexity of the method inevitably increases. This issue has received increasing attention recently, but there is still no effective solution.\nTo resolve the above limitations, we propose a Simplifying and Learnable graph convolutional attention network for Unsupervised Knowledge Graphs alignment method (SLU). For limitation 1, we abandon the use of complex network and introduce a novel GNN, LCAT [14] as the backbone network to model the graph structures of KGs. LCAT has the advantage of simplicity and outperforms existing benchmark GNNs in terms of robustness to input noise and network initialization.\nFor limitation 2, we select only partial relation information as model inputs. According to our observation, most of aligned entities a and b have different neighbor structures, where only some of the neighbors (connected by solid edges) are the same, while other neighbors (connected by dashed edges) become interfering data for alignment, as shown in Figure 1. Therefore, we first design a reconstruction method of relation structure based on potential matching relations, to efficiently filter the effective neighbors of aligned entities. Specifically, we select only those triples that are favorable for alignment into the LCAT model learning, inspired by RPR-RHGT [7]. Secondly, we also add entity-context embedding as model input to improve the alignment effect without significantly increasing the complexity of the model. The above all designs not only reduce the data flow into the encoder model, but also reduce the model's requirement.\nIn addition, we introduce contrastive learning [15] to eliminate the reliance on alignment seeds, which makes our proposed method more useful and robust in real scenarios. Finally, we also propose a novel similarity function for evaluating the similarity of aligned entities, since conventional similarity functions only consider the diversity of entity pairs in their own features. Our experiments on three benchmark datasets show SLU outperforms state-of-the-art EA methods. We also performed some thorough additional analysis to demonstrate the effectiveness of our simplifying and learnable convolutional attention network. More specifically, we summarize our contributions as follows:\n\u2022 A reconstruction method of relation structure based on potential matching relations is designed, which improves alignment accuracy while reduces the amount of model training.\n\u2022 A simplifying and learnable GNN model (LCAT) is introduced into entity feature learning, which has high robustness and modeling efficiency for EA task.\n\u2022 A novel similarity function based on consistency is proposed, for better measure the similarity of candidate entity pairs.\n\u2022 Extensive experiments on three well-known benchmark datasets show SLU not only outperforms 25 state-of-the-art models significantly, but also has impressive scalability and robustness."}, {"title": "2. Related Work", "content": "Existing embedding-based EA methods can be categorized into two groups according to whether they use the training set: (Semi-)supervised methods, self-supervised or unsupervised methods. Depending on the graph structure modeling method, we classify the former into two groups: translation-based methods, GNN-based methods. Also, GNN-based methods can be subdivided into two groups: relation-based methods and auxiliary-based methods. In this section, we briefly review each of these related works."}, {"title": "2.1. EA based on Transnational model.", "content": "TransE [4] is an energy-based model that maps entities and relations of KGs into different embedding spaces and then finds suitable translations between them. Translation-based methods are the main means of early EA work, which encode the structural information of KGs through TransE and its variants. MTransE [16] is the earliest work in this, which utilizes only relation structures of KGs.\nSubsequent researchers propose various enhancements, such as JAPE [17], AttrE [18] and MultiKE [19] to add modeling of attributes, BootEA [20] to optimize the performance using iterative strategies. Beside, NAEA [21] combines TransE and GCN to enhance the extraction of entity features. However, translation-based methods fail to achieve the desired results, because the high heterogeneity of KGs makes it difficult to transform one KG into another through a linear mapping function similar to the multilingual lexical space transformation."}, {"title": "2.2. EA based on relation structures.", "content": "Since entities with similar neighborhood structures in different KGs may be aligned, GNN becomes the most popular solution for EA. GNN-based methods use some well-known GNNs (e.g., GCN, GAT) and some variants to extract neighborhood features of entities in KGs, which are used to make the final alignment judgments. Relation-based method is the most common methods where the input is only relation structures of KGs, such as RDGCN [22], AliNet [23], KAGNN [24], etc. These methods are the most practical because they use only the most basic data (i.e., the relation structure) of KGs.\nSome other works cleverly model both intra-graph and cross-graph information, such as Dual-AMN [25] and PEEA [9]. In which the cross-graph information is constructed via graph matching networks (GMNs). Moreover, some works also add modeling of heterogeneous information (e.g., relation edges) in KGs, such as MRAEA [26], RPR-RHGT [7], RANM [8], etc. They propose or apply some new heterogeneous graph embedding methods to learn better entity representations\nSome researchers embark on the study of semi-supervised methods, such as MRAEA [26], RANM [8], PEEA [9], etc. These works use some iterative strategies to extend the training set to generate new alignment seeds during training. In addition to the semi-supervised learning, some new techniques (e.g., active learning, deep reinforcement learning, adversarial learning, etc.) are applied to improve the efficiency and usefulness of EA methods [27, 28, 29, 30]."}, {"title": "2.3. EA based on auxiliary information.", "content": "In addition to the relation structure, many studies add some auxiliary information (e.g., attributes, entity descriptions and images) to the entity encoding process. The relation structure represents the external relationships between entities, while the attribute structure (i.e., the attributes and attribute values of associated entities) represents the internal relationships of entities. Attribute-based methods request simultaneous input of the relation and attribute structure of KGs, such as HMAN [10], AttrGNN [11], MRAEA [26], \u039c\u0397\u039d\u0391 [12], RoadEA [31], EAMI [13].\nThere are also methods that use powerful pre-trained or large language models to model descriptive information about entities in addition to relation and attribute structures, such as HMAN [10], SDEA [32], SKEA [33], MMEA-cat [34], etc. Since most entities have distinctive visual feature (e.g., human beings, objects, or animals)s, or have obvious logo markings (e.g., companies, organizations or associations), this is highly conducive to alignment judgments. Therefore, some method use image information as the additional input, such as MMEA-cat [34], SKEA [33], GEEA [30], etc."}, {"title": "2.4. Self-Supervised or Unsupervised EA methods.", "content": "Most of the early EA methods are (semi-)supervised methods, which use alignment seeds during the training process. Despite the success of the above methods, the imperative need for labelled data still bridges the gap between these methods and practical applications [35]. Tagging alignment seeds is a naturally time-consuming and labor-intensive task, so self-supervised or unsupervised EA is receiving increasing academic attention, typically utilizing external information to eliminate the need for labeled data.\nSelf-supervised learning is the automatic construction of supervised information in large-scale unsupervised data through auxiliary tasks (pretext), followed by training as supervised methods. For example, MultiKE [19] devises some cross-KG inference methods to enhance the generation of labeled data, EVA [36] uses images as pivots to generate pseudo-labeled data, and UPLR [37] computes the graph interaction divergence of entity pairs between KGs and adaptively mines confidence samples from unlabeled data.\nUnsupervised EA methods do not have the process of generating labeled data, but construct loss functions from the perspective of data distribution. For example, ICLEA [35] and SelfKG [38] both utilize comparative learning to unsupervisedly learn the features of entities in two KGs. The difference is that ICLEA simultaneously fuses semantic information, entity description, relation and attribute structures for alignment inference. SEU [39] and UDCEA [40] transform EA tasks into assignment problems and propose new unsupervised methods without neural networks. They simply utilize machine translation and pre-trained language models to compute similarities between multi-view information (including entity names, structures, and attributes) and combine them with global alignment.\nThe supervised learning methods described above, especially those based on auxiliary information, tend to easily obtain better results because alignment seeds and auxiliary information tend to be more informative. However, they have following limitations: 1) More auxiliary information contains more noise, so most methods require customized pre-processing of this data. 2) The introduction of auxiliary structure greatly increases model complexity, leading in inefficient training. 3) Obtaining alignment seeds and auxiliary information is naturally time-consuming and labor-intensive for most KGs applications, which limits the scalability of these methods. Existing unsupervised methods suffer from similar problems. Therefore, we propose SLU, which utilizes only basic semantic information and relation structures of entities. In this work, we avoid using complex neural networks, such as stacking or splicing of multiple networks, heterogeneous GNNs, GMNs, etc., which makes our method more useful and robust in practical applications."}, {"title": "3. Preliminaries", "content": "Before starting the method description, we proceed to introduce the preliminary definitions.\nDEFINITION 1. A Knowledge Graph (KG) can be denoted as G = (E, R, A, V, TR, TA), where E, R, A, V respectively represent the entity set, relation set, attribute set and value set. $T_R \\subseteq E \\times R \\times E$ is relation structure, and each relation triple $(e_h, r_k, e_t) \\in T_R$ represents the relationship between two entities. $T_A \\subseteq E \\times A \\times V$ is attribute structure, and each attribute triple $(e_n, a_g, v_l) \\in T_A$ represents the properties of entities. In this paper, We only focus on the relation structure, so the KG can be simplified to G = (E, R, T), where T is the set of relation triples.\nDEFINITION 2. Entity Alignment (EA) task aims to find matching entities with the same meaning from two KGs, $G^1 = (E^1, R^1, T^1)$ and $G^2 = (E^2, R^2, T^2)$. In practice, there are usually some pre-aligned involved in model training provides as seed alignments. However, this paper focuses on unsupervised entity alignment models, and there is no involvement of seed alignments in our model training.\nFor convenience, we put $G^1$ and $G^2$ together as a primal graph G = (E,R,T) in the experiment, where $E = E^1 \\cup E^2$, $R = R^1 \\cup R^2$ and $T = T^1 \\cup T^2$. Formally, we use bold letter for embedding vector, i.e., $\\mathbf{E^1}$ represents the embedding matrix of $E^1$, and $\\mathbf{e}$ represents the embedding of e."}, {"title": "4. Methodology", "content": "This section introduces the core work of this paper. Figure 2 depicts the SLU consists of five major parts, which we will provide describe in detail."}, {"title": "4.1. Textual Feature", "content": "Firstly, we build the textual features of entities, which are the input for SLU training. In this paper, we construct input embeddings through the entity-text information and entity-context semantics of KGs.\nEntity-Text Embedding. Entity name is a general form of recognizing entity, which contains rich semantic information and is very helpful for the alignment task. Therefore, many tasks use pre-trained word embeddings to obtain entity name embedding. A lot of work [22, 39] uses Google Translate to translate non-English entity names into English ones. However, the entity embeddings generated by these works are not good enough, because of translation errors and the out-of-vocabulary (OOV) problem [41] faced by existing pre-trained embeddings. In this paper, we use LaBSE [42] to train the name information. Multi-language embeddings models are powerful tools for encoding text from different languages into a shared embedded vector space. Among them, LaBSE is a multi-language BERT embedded model from Google Researchers, which is a language-agnostic BERT sentence embedding in a single model. Without the loss of generality, let $W(e_i) = (w_1, w_2, ..., w_n)$ denote the entity name of $e_i \\in E$ consisting of n words or characters, we construct its name embedding by LaBSE as follows:\n$\\mathbf{e_i^n} = f_{LaBSE}(W(e_i))$, (1)\nwhere $f_{LaBSE}$ is the LaBSE encoder directly used to initialise the embeddings without additional fine-tuning.\nEntity-Context Embedding. In the relation structure of KGs, most entity have some entities associated with the context, which surely helps to determine the similarity of aligned entities. Inspired by [41], we use a random walk to obtain the walk path of each entity, thus making sentences for the dependency information of entity context."}, {"title": "4.2. Reconstruction of Relation Structure", "content": "Most related works put the entire KGs relation structure into convolution networks. However, because the data sources of real KGs are different, the structure of different KGs must be different. In other words, the neighborhoods of alignment entity are not fully matched most of the time. Some works use random sampling to reconstruct the relation structure, which randomly selected the neighbor nodes of an entity, so it is easy to lose some important neighbors. This paper proposes a more effective relation structure restructuring method, which is then achieved by filtering the entity neighbors through the generated matching relations. Following [7], we generate matching relations based on pseudo-labels, which are built through the name embedding.\nPseudo-Labels. The relation matching method that proposed by [7] is based on alignment seeds, but we studies unsupervised learning in this paper which is no participation of alignment seeds. To solve this problem, we generate pseudo-labels through the entity names, since most aligned entities have good similarities in names.\nWith the embedding of entity text features constructed in the previous section, we generate pseudo-labels for new reliable alignment pairs. A simple method is to calculate the embedded distance for each entity pair across two KGs, and identify the alignment pairs whose distance smaller than a scheduled threshold. However, this simple method may cause errors. To improve the accuracy of the labelling results, we use bidirectional one-to-one alignment. To be specific, we first define a function used to screen a similar entity pair:\n$D(e_i^1, E^1) = \\{e_i | e \\in E^1, d(e_i^1, e) > \\gamma_{sim}\\}$, (4)\nwhere d() denotes cosine function, the larger the value, the more similar the entity pair is; $\\gamma_{sim}$ is a pre-defined similarity threshold, which is used to screen more credible alignment pairs. As the formula Eq.(4), the output of function $D(e_i^1, E^1)$ is a subset of $E^1$, where each element is similar to $e_i^1$ with a value greater than $\\gamma_{sim}$. Then, we find the pseudo-labels set by one-to-one alignment:\n$PL = \\{(e_i^1, e_i^2) | e_i^1 = arg \\underset{e \\in D(e_i^2, E^1)}{min} d(e_i^2, e), \\newline e_i^2 = arg \\underset{e \\in D(e_i^1, E^2)}{min} d(e_i^1, e)\\}$. (5)\nRelation Matching. In this step, we match similarity relations between the neighbors of each pseudo-labels. For each $(e_i^1, e_i^2) \\in PL$, we first calculate the similarities of each pair of their neighbors, then sort the pairs of neighbors whose similarity is greater than a preset threshold $\\overline{\\gamma}_{sim}$ from high to low, and"}, {"title": "4.3. LCAT-based Neighborhood Aggregator", "content": "LCAT-based neighborhood aggregator is designed to update the entity embeddings by performing message passing with the help of the KG's relation information. This aggregator aggregates neighborhood information to the central node entity, which is the core of obtaining the useful information for EA. As shown in Figure 2, SLU first develops different graph data augmentation to form two graph structures of KGs, then use LCAT as the backbone network to model the graph structures of two KGs.\nGraph Data Augmentation. Graph contrastive learning has been demonstrated to improve the performance of graph learning, such as overcoming over-fitting and over-smoothing problems. Data augmentation in Graph contrastive learning usually performs perturbations on the input graph, such as masking, denoising and dropping. In this work, we achieve graph data expansion by masking some neighbors, which is the simplest method. The exact implementation will be given in detail in the next subsection.\nLCAT model. As discussion in Introduction, GCN [5] or GAT [6] are used obtain entity embedding in many previous works. But as [43] presented, these two architectures have certain limitations, since their performance is fully data-dependent, as expected. Therefore, this paper introduces the learnable graph convolutional attention network (LCAT) [14] to better learn the embeddings of align entities. LCAT learns proper operations to apply at each layer, thus combining different layer types in the same GNN architecture. Related experiments also demonstrate LCAT outperforms existing benchmark GNNs in terms of performance, network initialization, and robustness to input noise.\nIt is well known that a message-passing GNN layer yields the node embedding by collecting and aggregating the information from its neighbors. This operation can be defined as following:\n$\\mathbf{\\widetilde{e_i} = \\sum_{j \\in N_i} \\alpha_{ij}W_1e_j}$, (10)\nwhere $W_1$ is a learnable matrix, $N_i$ denotes the set of neighbors of node i (including node i itself), f() is a feature extraction function, $\\alpha_{ij} \\in [0, 1]$ is the coefficient such that $\\sum_{j} \\alpha_{ij} = 1$. Different GNN styles are determined according to the calculation of $\\alpha_{ij}$. For example, GCN calculates the average of messages, assigning the same coefficient $\\alpha_{ij} = 1/|N|$ to each neighbor. Instead of assigning a fixed coefficient, GAT computes the attention coefficient for each neighbor as follow:\n$\\alpha_{ij} = \\frac{exp(\\psi(e_i, e_j))}{\\sum_{k \\in N_i} exp(\\psi(e_i, e_k))}$, (11)\nwhere $\\psi(e_i, e_j) = LeakyRelu(a^\\top [W_1e_i||W_1e_j])$, $a \\in R^{2d}$ is the"}, {"title": "4.4. Contrastive Learning", "content": "Contrastive learning allows the model to perceive structural differences by generating two different graph views without training data, thus maximizing the consistency between the original KG and the augmented KG. Learning how to separate positive and negative samples from two different distributions is the key mind in contrastive learning. Taking inspiration from the recent successful applications of unsupervised learning in EA tasks [15], the framework proposed in this paper follows the common paradigm of graph contrastive learning, which seeks to maximize the consistency of representations between different views.\nConcretely, we perform random graph augmentation on the relation structure T using two different perturbing ratios $\\gamma_1$ and $\\gamma_2$, thereby generating two graph views of KGs. Let $\\widetilde{e_i^{(1)}}$ and $\\widetilde{e_i^{(2)}}$ denote the embeddings on the two views about the entity $e_i$ generated by two LCAT-based layers respectively. Finally we use the InfoNCE [15] as loss function to train the model, which aims to force the node embeddings of each entity in two views to be consistent with each other and distinguishable from the embeddings of other entities:\n$L_{InfoNCE} = -\\sum_{e_i \\in E} log \\frac{s(\\widetilde{e_i^{(1)}}, \\widetilde{e_i^{(2)}})}{\\sum_{k \\neq i} s(\\widetilde{e_i^{(1)}}, \\widetilde{e_k^{(2)}}) + \\sum_{k \\neq i} s(\\widetilde{e_i^{(2)}}, \\widetilde{e_k^{(1)}})}$, (14)\nwhere $s(\\mathbf{\\widetilde{e}}, \\mathbf{\\overline{e}}) = e^\\top \\overline{e} / \\tau$, and $\\tau$ is a temperature hyper-parameter. Under the guidance of loss function, the model is optimized through back propagation to learn the entity embeddings."}, {"title": "4.5. Alignment with Consistency Similarity", "content": "After obtaining the final entity embeddings, we measure the similarities of candidate entity pairs. In real KGs, most entities possess rather sparse neighborhood structures, and only a few entities are densely connected to other entities. As a result, the number of entities in real KGs has a long-tailed distribution.\nMost works directly use conventional similarity functions (e.g., cosine, Manhattan, Euclidean, etc.) to calculate the similarity of entity pairs, which consider the difference between entity pair only in terms of entity own features. This lead to two problems, one is that the effect of correlations between one entity and all other entities is ignored, and the other is that many one-to-many pairs are produced in the alignment results. To eliminate the effect of the above discrepancies on the alignment, we reconstruct a similarity function based on consistency that introduces two local maxima (i.e., row maxima and column maxima of the similarity matrix) after the dot product operation, as implemented below:\n$d'(e_s, e_t) = (max_{e_i \\in E^2} d(e_s, e_i) + max_{e_j \\in E^1} d(e_t, e_j))/2 - d(e_s, e_t)$, (15)\nwhere a smaller $d'(e_s, e_t)$ means a higher probability of entity alignment. The final experiment also demonstrates that this function can eliminate the effects of the above differences and better measure similarity of entity pair."}, {"title": "5. Experiments", "content": "5.1. Experiment Settings\nDatasets. To fairly and comprehensively evaluate the performance of SLU, we conduct experiments on three extensive benchmark datasets, including two 15K standard datasets (DBP-15K [17], WK31-15K [44]), and a 100K large dataset (DWY-100K [20]). The detailed statistics of datasets are listed in Table 1."}, {"title": "5.2. Overall Results on DBP-15K and WK31-15K", "content": "In Tables 2 and 3, we report the performances of SLU and baselines on DBP-15K and WK31-15K. The baseline results marked with \"*\" are implemented using its source code, while others are directly obtained from OpenEA [44] or their original papers. Those baselines marked with \"\u2020\" use pre-trained language model (e.g., LaBSE, FastText) to generate initial embeddings of entity names, and those marked with \"\u2021\" use image information. In addition, we mark the best performance results of the first two categories with underline and the best performance results of the unsupervised methods with bold.\nComparison with supervised methods using pure relation structures. Our proposed method is first compared with 11 supervised and relation-based methods, and it consistently performs best on all datasets except the JA-ENDBP dataset. Specifically, compared to the state-of-the-art method RANM [8], our method improves Hits@1 by 6.4% on FR-ENDBP and 6.1% on EN-FRV1. Since RANM takes into account the heterogeneous information of KGs and PEEA performs searching one-to-one alignments, their training or alignment efficiency is lower than that of SLU. This shows that SLU is still very competitive in this type of method, although it does not perform as well as them on JA-ENDBP dataset. In addition, as unsupervised methods, SLU and some other unsupervised methods do not have input labelled data, but they still perform better than these supervised methods. One of the main reason for this is that the contrastive learning mechanism provides more positive samples (each entity is its own positive sample) and the InfoNCE loss function can better extract information about entities across KGs. In summary, SLU breaks the upper performance limit of relation-based EA methods and proves the efficiency of the design.\nComparison with supervised methods using auxiliary information. Among the eight supervised methods with auxiliary information, the best performer is SDEA [32] that far outperforms our method on ZH-ENDBP datasets. We attribute this to its effective combination of various information, especially its attribute and description information of entities based on BERT [50]. Both MMEA-cat [49] and GEEA [30] do not consider the name information of entities but consider the image information, and GEEA also consider the attribute information. As shown in the experimental results, both methods exhibit lower performance compared to other baselines. This suggests that modelling of entity names based on pre-trained language models is better than image-based. In conclusion, SLU still shows"}, {"title": "5.3. Overall Results on DWY100K", "content": "To verify the effectiveness of our method on a large-scale dataset, we also report in this section the end-to-end comparison of SLU with 16 baselines on the DWY100K dataset. As shown in Table 4, SLU first outperforms other unsupervised methods and achieves the best performance in all metrics. Second, the Hits@1 of both supervised methods on DBP-WD reaches up to 99.3%, which is only 1% higher than SLU's 98.3%. However, our SLU method is still significantly better than all supervised methods on DBP-YG. Finally, while most baselines show commendable performance, SLU's Hits@1 on DBP-YG clearly reaches 100.0%. This shows that the monolingual setting effectively alleviates the name bias and promotes the recognition of aligned entities. Overall, given that the size of DWY-100K is several times that of WK31-15K and DBP-15K, this experiment demonstrates the good scalability and superiority of our method on larger real-world and monolingual KGs."}, {"title": "5.4. Ablation Experiments", "content": "In the previous section we have shown the overall success of SLU. To demonstrate the validity of each component design in SLU, we offer 5 variants of SLU for ablation studies on DBP-15K in this part and the result are shown in Tables 5.\n\u2022 SLU w/o ECE+RRS, where the modules of entity-context embedding and reconstruction of relation structure is removed;\n\u2022 SLU w/o ECE, where the module of entity-context embedding is removed;\n\u2022 SLU r Cosine, where the similarity function based on consistency is replaced by cosine function;\n\u2022 SLU r GAT, where the LCAT model is replaced by a GAT model;\n\u2022 SLU r GCN+GAT, where the LCAT model is replaced by a superimposed network of GCN+GAT.\n, First, it can observe that the Hits@1 of SLU w/o ECE and SLU w/o ECE+RRS degrade by 0.2%-1.9% and 0.3%-2.1% respectively. The results confirm the effectiveness of the entity-context embedding, in that it further extracts information about entity names, compared to simply utilizing individual entity names. Although the effect of relation structure reconstruction is not significant, its key role is to reduce the amount of model training by removing some triples (those that have no effect on alignment) before training the model. Second, we tested the performance of SLU without using the new similarity function, which means it uses a universal cosine function to calculate entity similarity, and most baselines do so. The results demonstrate that the similarity function based on consistency is significant effective, and it brings about an absolute return of over 2.2% -4.5% of Hits@1. Third, to analyze the effect of LCAT model, we compare the performance SLU r GAT, SLU r GCN+GAT and SLU. As illustrated in Table 5, SLU achieves best performance across most metrics and datasets. Thus, the LCAT model does capture rich and subtle alignment information for EA task."}, {"title": "5.5. Additional Analysis", "content": "In this section, we first explore the stability of EA method on datasets with different densities. A sensitivity analysis is performed on the hyper-parameters of graph data augmentation, in particular the perturbation rate $\\gamma_1$, temperature $\\tau$, and momentum coefficients m, in order to assess their impact on the robustness of SLU.\nEffect of dataset sparsity. The WK31-15K dataset contains four subsets with different densities, where V1 is a sparse dataset and V2 is a dense one. Intuitively, the EA method have better performance on dense KGs because their entities have more neighborhood information. From Table 3, most of supervised methods confirm to this judgment, that is, their performance on V2 is significantly better than that on V1, especially AliNet, PEEA and MRAEA. However, this phenomenon does not continue in most unsupervised methods, whose performance difference between V1 and V2 datasets is not very large. This shows that the supervised methods, guided by the alignment seed, can train the model to better capture the similarity of aligned entities in the neighborhood. Unsupervised methods rely more on the similarity of entity information (e.g., entity names) during model training to obtain the labeled data for alignment, and in contrast, do not have too bright results in terms of improving the ability to obtain neighborhood features. Therefore, this is one of our subsequent research directions on how to improve the ability of GNNs models in acquire neighborhood features under the unsupervised learning framework.\nImpact of perturbing ratio $\\gamma_1$. In the experiments of graph data augmentation, it is common to set the perturbation rates to change in one view while the other remains constant. In this experiment, we set six perturbation ratios ranging from 0.0 to 0.5, where the zero ratio means that any disturbance is excluded at one view. Obviously, the higher the perturbation ratio, the more noise is introduced. As shown in Figure 3(a), the overall performance of SLU exhibits some stability even when the perturbation ratio increases. That demonstrates SLU is less sensitive to these noises and that an appropriate proportion of noise can bring some help to the performance.\nImpact of temperature $\\"}]}