{"title": "Pruning Boolean d-DNNF Circuits Through Tseitin-Awareness", "authors": ["Vincent Derkinderen"], "abstract": "Boolean circuits in d-DNNF form enable tractable probabilistic inference. However, as a key insight of this work, we show that commonly used d-DNNF compilation approaches introduce irrelevant subcircuits. We call these subcircuits Tseitin artifacts, as they are introduced due to the Tseitin transformation step a well-established procedure to transform any circuit into the CNF format required by several d-DNNF knowledge compilers. We discuss how to detect and remove both Tseitin variables and Tseitin artifacts, leading to more succinct circuits. We empirically observe an average size reduction of 77.5% when removing both Tseitin variables and artifacts. The additional pruning of Tseitin artifacts reduces the size by 22.2% on average. This significantly improves downstream tasks that benefit from a more succinct circuit, e.g., probabilistic inference tasks.", "sections": [{"title": "I. INTRODUCTION", "content": "Boolean circuits represent Boolean functions in a manner that allows certain operations to become feasible. In this work we focus on d-DNNF circuits (see Fig. 1 for an example), because they allow us to compute the weighted model count in polytime, despite it being a computationally hard task in general [1]. As such, they play an important role in enabling tractable probabilistic inference [2]\u2013[7]. Furthermore, a key advantage of the circuit-approach to computing the weighted model count, is that when the weights change, the same compiled circuit can be reused and only the circuit evaluation must be repeated. This effectively amortizes the compilation cost across evaluations, and is especially relevant in the context of parameter learning where the parameters evolve over many evaluations. However, in such a context, the circuit size also becomes important. In neuro-symbolic AI, for instance, where such circuits are being combined with neural networks, many evaluations take place during training and an efficient circuit evaluation is key to maintaining a fast enough neural network learning pipeline [8], [9]. To conclude, besides efficiently obtaining a d-DNNF circuit, it is also important that these circuits are succinct.\nTo obtain a succinct d-DNNF circuit from any Boolean circuit, the field of knowledge compilation has developed several d-DNNF compilers. The CDCL-based class of compil-ers, which includes D4 [10] and sharpSAT-TD [11], requires the input circuit to be in conjunctive normal form (CNF).\nThe most prominent algorithm to efficiently obtain this form"}, {"title": "II. BACKGROUND", "content": "We use the standard terminology of propositional logic. A literal is a Boolean variable v or its negation \u00ac\u03c5. \u0391 propositional formula \u03c8 is inductively defined as a literal l, the negation of a formula \u00ac\u03c8\u2081, a conjunction of formulas \u03c8\u2081 \u2227 \u03c8\u2082, or a disjunction of formulas \u03c8\u2081 \u2228 \u03c8\u2082, each with the usual semantics. We will also allow \u22a4 (\u2018true\u2019) and \u22a5 (\u2018false\u2019) to appear in the formula, and when convenient, also the equivalence symbol \u2194 (\u03c8\u2081 \u2194 \u03c8\u2082 defined as (\u03c8\u2081 \u2227 \u03c8\u2082) \u2228 (\u00ac\u03c8\u2081 \u2227 \u00ac\u03c8\u2082)).\nA clause is a literal or a disjunction of multiple literals, and a formula \u03c8 is in conjunctive normal form (CNF) iff it is a clause or a conjunction of multiple clauses.\nAn interpretation is a truth assignment to the Boolean variables. When formula \u03c8 is satisfied under the assignment, we say the interpretation is a model of \u03c8. When a formula is trivially satisfied, that is, satisfied under any interpretation, we call it a tautology. A trivial example of a tautology is x \u2228 \u00acx.\nWe use \u03c8|l to denote formula \u03c8 conditioned on l being true. This is different from \u03c8 \u2227 l, as l and \u00acl no longer occur within \u03c8|l. The existential quantification of a variable X in \u03c8, denoted as \u2203X.\u03c8, is semantically equivalent to \u03c8|x \u2228 \u03c8|\u00acx. This process is also called \u201cforgetting variable X\". We extend this notation to operate on a set of variables X={X\u2081, X\u2082, ..., Xn}: \u2203X.\u03c8 = \u2203X\u2081\u2203X\u2082...\u2203Xn.\u03c8.\nExample 1: Consider \u03c8 := a \u2227 (\u00acb \u2228 c). This is a CNF formula of two clauses. There exist 2\u00b3 interpretations over V = {A, B, C}, three of which are a model of \u03c8: {a, b, c}, {a, \u00acb, c} and {a, \u00acb, \u00acc}. \u03c8 is not a tautology. When condi-tioning on a, we have \u03c8|a = \u00acb \u2228 c.\""}, {"title": "B. Weighted Model Counting", "content": "Given a propositional formula \u03c8 over variables V, and weight function w that maps each literal to a real value, the weighted model count is defined as\n$$WMC(\u03c8, V, w) = \\sum_{\\text{model of } \u03c8} \\prod_{\\text{lit } \\in \\text{model}} w(\\text{lit}).$$\nWe will use WMC(\u03c8,w) when V is clear from context, and MC(\u03c8) to refer to unweighted model counting, which is equivalent to using weight 1 for all literals. Since probabilistic inference can be cast as a weighted model counting (WMC) task [2], [13], efficiently computing the WMC is of great interest. This is possible using a compilation-based approach."}, {"title": "C. Circuit Properties", "content": "The structure of a propositional formula \u03c8 is a tree. When allowing reuse of substructures, i.e., when we have a more general single-rooted DAG structure, we instead use the term Boolean circuit. There are several structural properties [2] that such a circuit may have, and that are of interest to our work.\nDefinition 2 (determinism (d)): A Boolean circuit \u03c8 is deterministic iff for each \u03c8\u2081 \u2228 \u03c8\u2082 within \u03c8, \u03c8\u2081 and \u03c8\u2082 do not share any models. That is, \u03c8\u2081 \u2227 \u03c8\u2082 = \u22a5.\nDefinition 3 (Decomposability (D)): A Boolean circuit \u03c8 is decomposable iff for each \u03c8\u2081 \u2227 \u03c8\u2082 within \u03c8, \u03c8\u2081 and \u03c8\u2082 do not share any variables.\nDefinition 4 (Negation Normal Form (NNF)): A Boolean circuit is in negation normal form iff it consists only of \u2228, \u2227, and literals (negation is only allowed over variables)."}, {"title": "D. CDCL Algorithm", "content": "Several algorithms have been developed to compile a Boolean circuit into a d-DNNF. Many state-of-the-art compilers are based on the CDCL algorithm that was initially developed for SAT solving, but can be adapted for compilation. Examples include D4 [10] and sharpsat-TD [11], [16]. For a more detailed explanation of these algorithms we refer to [10], [11], [17].\nImportant to understanding our contributions is that these al-gorithms operate on a CNF formula \u03c8, and that they iteratively condition on literals until the remaining formula is satisfied.\nExample 2: Consider the following \u03c8, a CNF of two clauses.\n$$\u03c8 := (a \u2228 \u00acb) \u2227 (a \u2228 \u00acc)$$\nIf a CDCL-based algorithm were to condition on \u00acb, clauses that contain \u00acb are removed, and b is removed from every clause. The remaining formula is \u03c8|\u00acb = (a \u2228 \u00acc). When then conditioning on a, the remaining formula is \u03c8|\u00acb,a = \u22a4, and the algorithm backtracks to cover the other models in a similar fashion.\nAlso relevant is component decompositioning [18], a very effective optimisation used within weighted model counting and d-DNNF compilation to reduce the search space. This optimisation exploits the fact that if a CNF can be partitioned into sets of clauses that do not share any variables (called components), then these can be treated separately. Furthermore, these components can be cached such that when they are encountered again later in the search space, the cached result can be reused. For d-DNNF compilation, this enables reuse of subcircuits and results in a DAG rather than a tree. The effectiveness of this optimisation has lead the community to propose a variety of component representations [19]\u2013[21].\nExample 3: Consider the following CNF of three clauses.\n$$\u03c8 := (a \u2228 \u00acb) \u2227 (a \u2228 \u00acc) \u2227 (\u00acd \u2228 e)$$\nThe first two clauses together form a component C\u2081, while the third clause forms component C\u2082 as it does not share any variables with the previous clauses. From a weighted model count perspective we have (3) which indicates that the model count of each component can be computed separately.\n$$WMC(\u03c8, V, w) = WMC(C\u2081, w) \u00d7 WMC(C\u2082, w)$$"}, {"title": "E. Tseitin Transformation", "content": "The Tseitin (or Tseytin) transformation is a procedure by which any Boolean circuit \u03c8 can be converted into CNF [12]. The main idea powering this transformation is that, when we introduce a new auxiliary Boolean variable x to refer to a subcircuit \u03c8\u2019, we can conveniently replace each occurrence of \u03c8\u2019 by x. For larger nested circuits this significantly simplifies the CNF transformation because each (l \u2194 \u2228\u1d62 l\u1d62) and (l \u2194 \u2227\u1d62 l\u1d62) can easily be transformed into a CNF where the number of clauses is exactly equal to the number of literals l\u1d62 and l. The number of clauses in the resulting CNF is therefore linear in the number of subcircuits \u03c8\u2019 and in the number of literals occurring in \u03c8.\nExample 4 (Tseitin transformation): Consider the circuit \u03c8 given below.\n$$\u03c8 := (a \u2227 b) \u2228 (c \u2227 d)$$\nThe Tseitin transformation introduces new variables x\u2081 and x\u2082 to refer to (a \u2227 b) and (c \u2227 d) respectively. Using this new equivalence, the original circuit \u03c8 could be summarized as\n$$T(\u03c8) := (x\u2081 \u2228 x\u2082) \u2227 (x\u2081 \u2194 a \u2227 b) \u2227 (x\u2082 \u2194 c \u2227 d).$$\nAs CNF, this results in circuit CNF(T(\u03c8)), displayed below as a conjunction of seven clauses.\n$$(x\u2081 \u2228 \u00aca \u2228 \u00acb) \u2227 (\u00acx\u2081 \u2228 a) \u2227 (\u00acx\u2081 \u2228 b) \u2227$$(x\u2082 \u2228 \u00acd \u2228 \u00acc) \u2227 (\u00acx\u2082 \u2228 d) \u2227 (\u00acx\u2082 \u2228 c) \u2227 (x\u2081 \u2228 x\u2082)$$\nIn this example we distinguished T(\u03c8) from CNF(T(\u03c8)). In the remainder of this paper we use T(\u03c8) to refer to the circuit resulting from the Tseitin transformation on \u03c8. Its exact representation, as a CNF or not (5), will generally not be important. In case it is important, the representation we refer to will be clear from context.\nNote that \u03c8 and T(\u03c8) are not equivalent as T(\u03c8) contains variables that are not present in \u03c8, and that were introduced by the Tseitin transformation. We call these Tseitin variables. Importantly, there is a one-to-one mapping between the models of \u03c8 and the models of T(\u03c8) [22]. By construction, each model of \u03c8 implies a truth value for the Tseitin variables in T(\u03c8) through the equivalences introduced by the transformation (5). In the other direction, ignoring the Tseitin variables from a model of T(\u03c8) yields exactly one model of \u03c8. As a consequence, we have the following relation (7) where X is the set of Tseitin variables introduced during the Tseitin transformation.\n$$\u2203X.T(\u03c8) = \u03c8$$\nWhen computing the weighted model count of \u03c8 using T(\u03c8), the weight of a Tseitin variable X is typically set to one (w(x)=1=w(\u00acx)). This preserves the weight of each model and consequently also the weighted model count of \u03c8."}, {"title": "III. WHAT ARE TSEITIN ARTIFACTS?", "content": "We first informally introduce the concept that we refer to as a Tseitin artifact. A more formal definition is then provided afterwards. We study these artifacts in the context of d-DNNF compilation. Therefore, suppose we wish to obtain a d-DNNF representation of circuit \u03c8 (4) in Example 4. We will use a CDCL-based d-DNNF compiler that requires a CNF as input, so we first use the Tseitin transformation to obtain T(\u03c8) (6). Fig. 1 shows a possible output of the compiler, a d-DNNF circuit representing T(\u03c8). Since we are interested in the number of computations during evaluation, we define the circuit size as the number of binary nodes (e.g., a node with three inputs represents two binary nodes, and so on). The size of the d-DNNF in Fig. 1 is 16."}, {"title": "A. Existential Quantification of Tseitin Variables", "content": "The circuit in Fig. 1 is a d-DNNF and can hence be used to efficiently compute the weighted model count of T(\u03c8) and \u03c8. The current representation, however, does contain many unnecessary elements. In particular, the Tseitin variables X were introduced by the Tseitin transformation to easily obtain a CNF, but are irrelevant to downstream counting tasks. These variables can be removed through existential quantification, i.e., by computing \u2203X.T(\u03c8).\nThanks to the decomposability property, existential quantifi-cation of X \u2208 X is very simple here: replace each occurrence of x and \u00acx in the formula by \u22a4. We refer to this procedure as EXISTS(\u03c8, X). This procedure is guaranteed to preserve the DNNF properties [22]. Additionally, recent work has proven that since we existentially quantify Tseitin variables, this procedure is guaranteed to also preserve determinism [11]. Fig. 2 shows the circuit of Fig. 1 after performing existential quantification of the Tseitin variables. Combining the results above with (7), it follows that Fig. 2 again represents circuit \u03c8 instead of T(\u03c8), but now as a d-DNNF due to the earlier compilation step."}, {"title": "B. Tseitin Artifacts", "content": "The subcircuit f whose root is marked in red in Fig. 2, is given in (8). While this subcircuit initially represented (x\u2082 \u2194 c \u2227 d), which is not a tautology, after performing the existential quantification of x\u2082, it did become a tautology.\n$$\u2203x\u2082. f = (((\u00acd \u2227 c) \u2228 \u00acc) \u2227 \u22a4) \u2228 (\u22a4 \u2227 c \u2227 d) = \u22a4$$\nThis means that f can be entirely replaced by \u22a4. Indeed, consider the initial circuit \u03c8 of Example 4 and note that \u03c8|a,\u00acb = \u22a4. We call f a Tseitin artifact, a tautological subcircuit introduced to the compiled circuit due to the Tseitin transformation.\nDefinition 6 (Tseitin artifact): A (sub)circuit f(X, Y) over Tseitin variables X and non-Tseitin variables Y is a Tseitin artifact if and only if it is a tautology when existiantially quantifying over X. That is, when \u2203X. f(X, Y) = \u22a4.\nThis definition can be generalised beyond Tseitin variables X, to variables that are completely defined by other variables (cf. the definition of definability by [11], [23]). Our focus on Tseitin variables is a practical choice. First, they are known to be defined by other variables so we do not need a procedure to determine the set of defined variables. Second, they are irrelevant from a user perspective. That is, these variables are not present in the original circuit (pre-Tseitin transformation) so we can safely assume they are irrelevant to any downstream model counting task and can thus be removed.\nOur insight can be applied more generally: if a (sub)circuit is equivalent to \u22a4, you can replace it with \u22a4 to reduce the cir-cuit size. However, a top-down d-DNNF compiler would never produce such subcircuits under normal conditions because a non-empty CNF is never equivalent to \u22a4 (unless we allow CNFs of only trivial clauses such as x \u2228 \u00acx). Subcircuits that are equivalent to \u22a4 only emerge within a d-DNNF once we perform existential quantification, which is advised when using the Tseitin transformation as we show in the experiments. We therefore position our insight around Tseitin variables, and refer to the subcircuits as Tseitin artifacts.\nExistential quantification of Tseitin variables using the EXISTS procedure of section III-A does not eliminate all Tseitin artifacts. For example, while propagating \u22a4 in Fig. 2, we would not have realised that subcircuit f (node marked in red) is equivalent to \u22a4, missing the possible reduction to a circuit of size 6 instead of 11. In the next section we study how to detect these artifacts and how they emerge."}, {"title": "IV. DETECTING TSEITIN ARTIFACTS", "content": "Tseitin artifacts can be detected in an sd-DNNF represen-tation in time linear in the size of the sd-DNNF.\nProposition 1: When f(X, Y) is a (sub)circuit of a d-DNNF representation for T(\u03c8), over Tseitin variables X and non-Tseitin variables Y, then f is a Tseitin artifact if and only if the unweighted model count is MC(f) = 2|Y|.\nProof: We know MC(f) = MC(\u2203X. f(X, Y)), because by construction a Tseitin variable X is completely defined by non-Tseitin variables Y.\nMC(f) = 2|Y| \u2194 MC(\u2203X. f(X, Y)) = 2|Y|\n\u2194 \u2203X. f(X, Y) = \u22a4 \u2194 f(X, Y) is a Tseitin artifact\nIt is well known that the model count for each sd-DNNF (sub)circuit can be computed in time linear in the size of the representation, and that a similar approach can be used for non-smooth d-DNNF representations by performing the appropriate smoothing operations in polytime either before or during evaluation [1], [15]. Furthermore, since we only require unweighted model counts, smoothing is unnecessary and we only need to know the number of variables that would have to be smoothed over. The number of these so called free variables is easy to extract during the compilation process. Combining this fact with Proposition 1, we can detect Tseitin artifacts by computing the unweighted model count of each subcircuit f(X, Y) using a single bottom-up evaluation. If the model count is equivalent to 2|Y|, f is a Tseitin artifact and it can be removed when we existentially quantify over X."}, {"title": "B. When Do They Emerge?", "content": "Next we provide more intuition on when these artifacts may emerge within CDCL-based d-DNNF compilers. This helps to identify the types of circuits for which our proposed technique (removing Tseitin artifacts) has a high impact. Consider again \u03c8 and T(\u03c8) from Example 4.\n$$\u03c8 := (a \u2227 b) \u2228 (c \u2227 d)$$\n$$T(\u03c8) := (x\u2081 \u2228 x\u2082) \u2227 (x\u2081 \u2194 a \u2227 b) \u2227 (x\u2082 \u2194 c \u2227 d)$$\nWhen a d-DNNF compiler conditions on x\u2081 (9), the clause (x\u2081 \u2228 x\u2082) becomes satisfied and, since x\u2082 is not used elsewhere, the Tseitin equivalence (x\u2082 \u2194 c \u2227 d) will emerge as a Tseitin artifact (after component decompositioning which splits off the (a \u2227 b) part).\n$$T(\u03c8)|x\u2081 = (a \u2227 b) \u2227 (x\u2082 \u2194 c \u2227 d)$$\nMore generally, if \u03c8\u2081 and \u03c8\u2082 are circuits more complex than a single literal, appearing together as \u03c8\u2081 \u2228 \u03c8\u2082, such that \u03c8\u2081 \u2227 \u03c8\u2082 \u2260 \u22a5, then a Tseitin artifact may emerge depending on the variable ordering of the CDCL compiler. We empirically"}, {"title": "V. RELATED WORK", "content": "Prior work [22] has studied the usage of existential quan-tification, the EXISTS procedure, to obtain succinct DNNF circuits. Continuing on this result, [11] proved that existential quantification of X also preserves determinism if X is defined in terms of the other variables, and is thus applicable when targetting d-DNNF circuits. Our work continues on these findings, realising that this procedure may result in subcircuits that can be removed to reduce the circuit size even further.\nThe concept of definability, which strongly relates to the Tseitin variables, has previously been used in preprocessing, altering the CNF to improve model counting [23], [26]. Similarly, the variable elimination approach of [11] could eliminate Tseitin variables prior to compilation. While this is beneficial in some cases, it may also degrade performance in the context of Tseitin variables as these were introduced exactly to ensure a small CNF size (with likely faster compilation) [11]. For this reason they consider heuristics to determine which variables to eliminate. Furthermore, prior elimination of the Tseitin variables prevents the compiler from conditioning on them. This may lead to larger circuit sizes and a potential increase in compilation time.\n[27] proposed a novel projected model counter restricted to Horn clauses, which are clauses whose form is equivalent to (\u00acl\u2081 \u2227 ... \u2227 \u00acln) \u21d2 h, with l\u1d62 and h positive literals or \u22a4. The relation to our work is their propagation technique. This technique is based on the insight that during the counting process, if h is an auxiliary variable that is not constrained by any other remaining Horn clause, then its associated clause can be satisfied without impacting the count. In other words, they can remove such clauses (only because h is an auxiliary variable). This relates to the Tseitin artifacts, although these emerge from an equivalence structure rather than an implication and are not restricted to projected model counting."}, {"title": "VI. EXPERIMENTS", "content": "Given the influence of the variable ordering and the structure of disjunctions within \u03c8, a natural research question is: how prevalent are Tseitin artifacts? We primarily focus on the former, avoiding instances that we know will not contain Tseitin artifacts (i.e., Bayesian networks with mutual exclusive disjunctions). We study the effect of removing Tseitin artifacts on the circuit size, and compare the effect of performing sim-ple existential quantification (denoted as d-DNNF+p) versus removing the Tseitin artifacts entirely as well (denoted as d-DNNF+t)."}, {"title": "A. Datasets", "content": "a) Reverse-engineered CNFs (MCC): Benchmarks used for weighted model counting and d-DNNF compilation are typically CNF formulas already, so these are not useful from a Tseitin transformation perspective. In our experiments however, we will assume these CNFs were produced by a Tseitin transformation before they were made publicly available. We determine the set of Tseitin variables X by identifying equiv-alences (l \u2194 \u2228\u1d62 l\u1d62 or l \u2194 \u2227\u1d62 l\u1d62). As dataset, we consider the CNF instances of the 2022 and 2023 model counting competitions (MCC) [28], [29], only using instances with more than 25% Tseitin variables. We ran the D4 d-DNNF compiler [10] with a timeout of 3600 seconds, resulting in 65 completed instances (after removing duplicate instances).\nb) CNFs with Tseitin variables (CNFT): We also con-sider the dataset of [11]: \"a new set of benchmarks using two tools to translate (probabilistic) logic programs to CNFs [30], [31] on standard benchmarks from probabilistic logic pro-gramming\". By construction, their auxiliary variables are completely defined in terms of the other remaining variables. We include additional programs that were translated using ProbLog [13], for instance the power transmission networks from [32], originating from [33]. These two datasets resulted in 146 and 34 instances respectively (already excluding time-outs). From the neuro-symbolic (NeSy) AI setting we include the Countries knowledge graph: \"Countries is a knowledge graph with the locatedIn and neighborOf relations between the countries and continents on Earth\" [34]. There are three tasks leading to three DNF formulas. While more instances can be created, the results are expected to be similar since the structure will be similar. We therefore consider the three DNF formulas, and apply the Tseitin transformation to obtain CNFs and Tseitin variables X."}, {"title": "B. Results", "content": "The additional contribution of detecting Tseitin artifacts, that is, d-DNNF+p compared to d-DNNF+t, is shown in Fig. 6. This improves 27 out of the 65 instances, with an average of 24.0% nodes pruned (for those 27, with std. of 26.7%).\nb) CNFT dataset: Fig. 7 shows the relative number of nodes that remain after removing the Tseitin artifacts and performing existential quantification. On average, this prunes 81.1% of the nodes (std. of 13.1%). The additional contribution of detecting Tseitin artifacts, that is, d-DNNF+p compared to d-DNNF+t, is shown in Fig. 8. This improves 155 out of the 180 instances, with an average of 30.6% nodes pruned (for those 155, with std. of 15.7%). The three NeSy instances we illustrate separately, in Table I.\nc) Discussion: The overall results indicate the impor-tance of existentially quantifying over irrelevant variables, and the additional reductions that can be achieved through the removal of Tseitin artifacts. As previously discussed, Tseitin artifacts do not necessarily appear in every circuit. This is observed in Fig. 8 where the circuits of class gnb do not result in any additional reduction, meaning no Tseitin artifacts arose. We hypothesize, and manually confirmed for a few disjunctions, that the disjunctions within the gnb circuits are mutually exclusive. This supports the explanation in Sec-"}, {"title": "VII. CONCLUSION", "content": "The Tseitin transformation introduces auxiliary variables to obtain a small CNF circuit. These variables can easily be removed after d-DNNF compilation. But as we have shown, subcircuits that are trivially satisfied may then emerge. Fortunately, we can easily detect and remove such artifacts using a single bottom-up evaluation of the d-DNNF circuit. We have empirically shown the positive impact of pruning these artifacts on the final circuit size. In future work, we will investigate the detection and removal of these artifacts during compilation, with the additional aim of reducing compilation time. This requires a new detection mechanism as the current one relies on each subcircuit to already be compiled."}, {"title": "APPENDIX A MUTUALLY EXCLUSIVE DISJUNCTION", "content": "A Bayesian network whose conditional probability tables are encoded in a way that each \u2228 is mutually exclusive, results in few Tseitin artifacts. We illustrate one such probability table, P(C|A, B):\n$$\\begin{array}{cc}C & \\\\\n & \\left(\\begin{array}{c}a \\wedge b \\wedge \\theta_{a,b} \\\\\\a \\wedge \\neg b \\wedge \\theta_{a, \\neg b} \\\\\\neg a \\wedge b \\wedge \\theta_{\\neg a, b} \\\\\\neg a \\wedge \\neg b \\wedge \\theta_{\\neg a, \\neg b}\\end{array}\\right)\\end{array}$$\nWe now briefly discuss one of the few found Tseitin artifacts. The subformula that formed this artifact was (using equiva-lences instead of CNF for clarity, and x and y to distinguish the Tseitin and non-Tseitin variables respectively):\n$$(x_{306} \\leftrightarrow x_{296})\\wedge (x_{296} \\leftrightarrow y_{295}) \\wedge (x_{321} \\leftrightarrow y_{311}) \\wedge$$ $(x_{311} \\leftrightarrow y_{310}) \\wedge (x_{322} \\leftrightarrow x_{321} \\vee x_{306}).$$\nThe Tseitin artifact of this formula is illustrated in Fig. 9. To understand how this artifact emerged, we explain the meaning behind (13) and how the conditioning process led to its existence. The role of x306 within andes is akin to c in (12). (x306 \u2194 x296) was a larger equivalence with a four-case disjunction, similar to how (12) has four cases. After conditioning on several literals during the compilation process, the equivalence was reduced to (x306 \u2194 x296). The case itself, like a \u2227 b \u2227 \u03b8a,b, is represented by x296, whose definition was reduced to x296 \u2194 y295 (where y295 is akin to \u03b8a,b). The third and fourth conjunct within (13)"}]}