{"title": "Energy Score-based Pseudo-Label Filtering and Adaptive Loss for Imbalanced Semi-supervised SAR target recognition", "authors": ["Xinzheng Zhang", "Yuqing Luo", "Guopeng Li"], "abstract": "Automatic target recognition (ATR) is an important use case for synthetic aperture radar (SAR) image interpretation. Recent years have seen significant advancements in SAR ATR technology based on semi-supervised learning. However, existing semi-supervised SAR ATR algorithms show low recognition accuracy in the case of class imbalance. This work offers a non-balanced semi-supervised SAR target recognition approach using dynamic energy scores and adaptive loss. First, an energy score-based method is developed to dynamically select unlabeled samples near to the training distribution as pseudo-labels during training, assuring pseudo-label reliability in long-tailed distribution circumstances. Secondly, loss functions suitable for class imbalances are proposed, including adaptive margin perception loss and adaptive hard triplet loss, the former offsets inter-class confusion of classifiers, alleviating the imbalance issue inherent in pseudo-label generation. The latter effectively tackles the model's preference for the majority class by focusing on complex difficult samples during training. Experimental results on extremely imbalanced SAR datasets demonstrate that the proposed method performs well under the dual constraints of scarce labels and data imbalance, effectively overcoming the model bias caused by data imbalance and achieving high-precision target recognition.", "sections": [{"title": "I. INTRODUCTION", "content": "SYNTHETIC Aperture Radar (SAR) is a high-resolution imaging radar that is frequently employed in homeland security since it can operate day and night [1]. Automatic target recognition (ATR) technology can interpret complicated SAR target samples into valuable intelligence information [2], [3], making it useful in a variety of military applications such as precise guidance and battlefield monitoring.\nIn recent years, the rapid growth of deep learning technology has brought about tremendous improvements in SAR ATR tasks [4]. Zhou et al. introduced mor-phological operations to improve the quality of SAR target data. They designed a large-margin softmax batch-normalization CNN network structure to enhance the separability of samples after clutter removal [5]. Zhang et al. fused the semantic features extracted by convolu-tional neural networks with traditional scattering center features, achieving a recognition accuracy of 99.59% on the MSTAR dataset [6]. Li et al. proposed a multiscale convolutional network and fully utilized the scattering centers of SAR targets to learn robust target features [7].\nDeep learning algorithms offer higher prediction accu-racy but larger model parameter sizes than conventional machine learning algorithms, and they require a signif-icant amount of labeled data to support model training [8], [9]. However, manually labeling SAR images is costly, time-consuming, and error-prone. In recent years, various semi-supervised learning (SSL) systems have arisen, including Mean-Teacher [10], MixMatch [11], ReMixMatch [12], and FixMatch [13]. These models have gained great success in the field of optical image identification, as well as offered strategies to address the label scarcity problem in SAR-ATR. Wang et al. introduced Mixup [14] technique to combine labeled and unlabeled SAR data, which effectively utilizes unlabeled data and enhances SAR ATR performance [15]. Yue et al. developed a semi-supervised SAR ATR framework that leverages labeled data for active learning and employs unlabeled data to impose constraints, yielding a notable improvement in recognition performance [16]. Zhang et al. proposed a pseudo-label selection mechanism based on epoch and uncertainty sensitivity, which resulted in remarkable performance gains in scenarios with scarce labels [17]. Zhang et al. designed two azimuth-aware discriminative representation losses that suppress intra-class variations among samples with large azimuth-angle differences, while simultaneously enlarging inter-class differences of samples with the same azimuth angle [18].\nIn general, the success of deep learning approaches is implicitly determined by the data scale's completeness. However, due to the unpredictable nature of wartime conditions and the high value of some prized military targets, certain unusual targets have characteristics such as excellent camouflage and mobility [19]. This complicates the acquisition of their image data. Consequently, the lack of samples in some categories causes many SAR image"}, {"title": "II. Related work", "content": "In SAR target recognition tasks, the class imbalance problem poses a significant challenge. Researchers have put out several strategies to enhance recognition perfor-mance to overcome this problem. Data-level methods like oversampling [22], under-sampling [23], and the SMOTE technique [36] balance the data by increasing the minority class samples or decreasing the majority class samples. Data augmentation techniques generate more minority class samples by rotating, translating, cropping, and other operations on SAR images. In recent years, generative adversarial networks, or GANs, have garnered a lot of attention as a new technique for synthesizing data. Cao et al. proposed a novel class-oriented GAN to augment imbalanced SAR datasets [25]. This technique directs the balance by embedding a matrix into the model to reflect the generative model's requirement for various class samples.\nAlgorithm-level methods include cost-sensitive learn-ing, which assigns higher weights to minority class sam-ples during training, making the model more attentive to the minority class. Balanced loss functions such as Focal Loss, improves the model's ability to recognize minority classes by reducing the loss contribution from easily classified samples and increasing the loss contribution from hard-to-classify samples [29]. Cui et al. proposed a class-balanced loss function based on the effective number of samples, effectively addressing the class imbalance problem in SAR image classification [23]. Cao et al. addressed the issue of data imbalance from both data and algorithmic perspectives. They combined various over-sampling methods to mitigate adverse correlations among target samples and employed a cost-sensitive model to alleviate the model's bias towards majority class samples [37].\nClass imbalance has also been addressed through the use of transfer learning [38]-[40]. Zhang et al. combined meta-learning and transfer learning and designed a cross-task and cross-domain SAR target recognition model. Which further enhanced recognition performance by in-corporating domain confusion loss and a domain discrim-inator [40]. Currently, little research on situations when labeled data is scarce is focused on class-imbalanced SAR"}, {"title": "B. Pseudo-label Imbalance", "content": "Pseudo-labeling is a widely used strategy in semi-supervised learning that generates pseudo-labels based on model predictions on unlabeled data, hence improving model performance by using more data. When generating pseudo-labels, state-of-the-art SSL techniques usually de-pend on confidence-based thresholds [11]\u2013[13] [15] [17]. Nonetheless, in situations involving long-tailed data distri-butions, these techniques frequently use higher confidence levels to enhance the precision of pseudo-labels [33]. Sadly, this worsens the imbalance problem by drastically lowering the recall rate of pseudo-labels for minority class samples. Moreover, studies show that pseudo-labels may still display bias even when trained on balanced data [41]. The DASO model dynamically adjusts the contri-bution of each class's pseudo-label based on the class distribution, thus improving the recall rate of pseudo-labels for minority classes without sacrificing accuracy [42]. Wang et al. first addressed the inherent imbalance issue in pseudo-labeling and proposed a debiased pseudo-label learning method [41], which eliminates the response bias of the classifier and adjusts the classification margins of each class. Yang et al. combined FixMatch and focal loss to alleviate the class imbalance issue in pseudo-labels [43], and accelerate model learning and convergence by adjusting loss weights based on predicted confidence."}, {"title": "III. Method", "content": "Figure 2 shows details of the proposed imbalanced semi-supervised SAR ATR approach. The method uses the EUAPS pseudo-label extraction process introduced by Zhang et al. as the first step to enlarge the original labeled dataset. Following that, experiments are run with the Wide ResNet 28-2 as the backbone network."}, {"title": "A. Energy Score-based in-distribution Pseudo-label Selection", "content": "In SSL, confidence-based pseudo-label generating al-gorithms are frequently employed to ensure pseudo-label reliability by imposing a high threshold on low-confidence pseudo-labels. However, in the case of long-tailed distri-butions, such techniques drastically decrease the recall"}, {"title": "B. Loss Term", "content": "In SSL, objective recognition models typically com-prise two loss function terms. One is the supervised loss $L_s$, computed on labeled data, and the other is the unsupervised loss computed on unlabeled data. The supervised loss $L_s$ is usually calculated to measure the discrepancy between the predicted labels of weakly aug-mented versions of labeled data and their true labels, and the formula can be written in the following form:\n$L_s = \\frac{1}{N_x} \\sum_{(x,y) \\in X} H(y, p(\\tilde{y}|w(x); \\theta))$\nWhere $(x, y)$ represents a sample and its correspond-ing label in the labeled dataset X, and $w(x)$ represents its weakly augmented version. $N_x$ represents the number of samples in the labeled dataset X, and $p(\\tilde{y}|w(x); \\theta)$ represents the predicted class probabilities by the $\\theta$ pa-rameterized model for sample $w(x)$.\nThe focus of semi-supervised learning research lies in designing the unsupervised loss function term to fully utilize the information in unlabeled data. Nowadays, the predominant approach is consistency regularization. It enhances the model's robustness by imposing consistency on the predictions of unlabeled samples subjected to different perturbations using a distance metric function. In recent years, SSL methods often introduce strong and weak augmentation to data to improve the model's gen-eralization. Additionally, they employ thresholding and softmax confidence to select pseudo-labels. Assuming the weakly augmented version of unlabeled data $u$ is $w(u)$, and the model's predicted probabilities for $w(u)$ repre-sented as $p(\\tilde{y}_{w(u)};\\theta)$, a method based on confidence selects samples with predicted probabilities higher than a confidence threshold $T_c$ as pseudo-labeled samples, with their one-hot labels denoted as $p(\\tilde{y}|w(u); \\theta)$. Then, a con-sistency loss function is constructed between the model's predictions on strongly augmented versions $s(u)$ and the pseudo-labels obtained on weakly augmented versions. Assuming the number of samples in the unlabeled dataset is $N(U)$, the form of the unsupervised loss function is as follows:\n$L_u = \\frac{1}{N_u} \\sum_{u \\in U} 1[max(p(\\tilde{y}|w(u); \\theta)) > T_c] H(p(\\tilde{y}|w(u);\\theta), p(\\tilde{y}|s(u);\\theta))$\nThe shortcomings of pseudo-label generation methods based on softmax confidence were discussed, and the concept of energy scores was introduced to filter pseudo-labels close to the distribution. Therefore, the energy score of the weakly augmented version of unlabeled data $w(u)$ is calculated using formula (4), denoted as $E(w(u), f(w(u)))$. If the energy score is lower than a predefined threshold $T_e$, the model's predicted class for the sample is considered its pseudo-label. Thus, the unsupervised loss function term is rewritten from equation (4.6) to the following form:\n$L_u = \\frac{1}{N_u} \\sum_{u \\in U} 1[E(w(u), f(w(u)) < T_e] H((p(\\tilde{y}|w(u); \\theta), P_{model}(\\tilde{y}|s(u); \\theta))$\nHowever, in practical applications, raw data that has not been preprocessed manually is mostly long-tailed distributed, making machine learning models prone to biases towards head classes. Therefore, it is necessary to consider imbalanced classification to prevent the clas-sification model from being dominated by head classes. Additionally, research has shown that pseudo-labels gen-erated in SSL tasks naturally suffer from imbalance issues, exacerbating the bias towards head classes. To address these issues, this paper improves the problem of model preference for majority classes from two aspects. Firstly, the cross-entropy term in the unsupervised loss function of semi-supervised learning is replaced by an adaptive margin loss to eliminate biases in the pseudo-label generation process. Secondly, an adaptive triplet loss"}, {"title": "a. Adaptive Margin Loss", "content": "The analysis above highlighted the inherent imbalance issue in the pseudo-label generation process. In such cases, the model is prone to generating biased pseudo-labels, and training the model with these incorrect labels further exacerbates the classifier's probability of misclas-sification. Wang et al. conducted in-depth research on the reasons for the imbalance in pseudo-labels in the FixMatch method, and through analysis of the correlation between different classes, they found that pseudo-labels for erroneous predictions often occur near the decision boundary. Therefore, biased pseudo-labels are largely attributed to inter-class confusion of the classifier. If unla-beled samples near the decision boundary can be pushed away from it, inter-class confusion can be effectively mitigated. Thus, it's beneficial to increase the distance between different classes in the feature space as much as possible, especially for classes with high similarity, to reduce the probability of generating incorrect pseudo-labels.\nBased on these findings, this chapter introduces the Adaptive Margin Loss (AML) to dynamically adjust the margins of each class based on the imbalance degree of pseudo-labels. Specifically, it requires the model to main-tain larger margins between highly biased and unbiased classes to ensure that the prediction scores of head classes do not overwhelmingly dominate over other classes. Such adjustments can effectively alleviate the imbalance issue caused by pseudo-labels while strengthening the model's discriminative ability across different classes. As shown in Figure 5, the classification boundary between Class 1 (yellow circle) and Class 2 (red triangle) in the left subplot is very close in the original feature space. AML aims to increase the boundary distance between these two classes to reduce inter-class confusion. Furthermore, throughout the training process, the data distribution constantly changes, so the bias between different classes should not be fixed but rather a dynamic process.\nBefore introducing the Adaptive Margin Loss func-tion, let's briefly introduce the general softmax cross-entropy loss, which is widely used in fields like face recognition. It is composed of the softmax function and the cross-entropy loss, with the formula as follows:\n$L = -\\sum_{i=1}^{N} y_i log S_i = \\frac{1}{N} \\sum_{i=1}^{N} log \\frac{ef_{y_i}(x)}{\\sum_{k=1}^{C} ef_k(x)}$\nHere, $S_i$ represents the output probability value of the softmax function. $y_i$ denotes the true label of the sample, $f_i(x)$ represents the logits value for the classification of the sample, N denotes the total number of samples, and C represents the total number of classes.\nThe adaptive margin loss function used in this paper introduces some changes to the calculation of output probabilities using the softmax function compared to the regular softmax cross-entropy loss function. Specifically, AML adds an adaptively adjusted margin interval param-eter m at the position of the power. The core idea of AML is to dynamically adjust m in the feature space, making the boundary distance between different classes larger to reduce inter-class confusion. For example, in a binary classification task, $\\vec{z_1}$ and $\\vec{z_2}$ represent the output vectors of two different classes after passing through the last fully connected layer, denoted as $f(x_1), f(x_2)$. To obtain a classifier with a larger inter-class margin, it is enforced that $f(x_1) - m_1 > f(x_2)$ and $f(x_2) - m_2 > f(x_1)$, where $m_1,m_2 \\geq 0$ is used to adjust the inter-class margin in real-time. In this way, the classifier's ability to distinguish between different class features is strengthened, thereby improving overall classification performance. The specific form of $L_{AML}$ is as follows:\n$L_{AML} = \\frac{1}{N} \\sum_{i=1}^{N} log \\frac{e^{(f_j(x_i)-m_j)}}{e^{(f_j(x_i)-m_j)} + \\sum_{k \\neq j} e^{(f_k(x_i)-m_k)}}$ where $m_j = log(\\frac{1}{p_j}), j \\in \\{1,...,C\\}$\nIn the equation, $f_j(x_i)$ represents the logits value for sample $x_i$ classified as class $j$, $k \\in [1,C']. N and C re-spectively denote the total number of samples and the total number of classes. $m_j$ is the adaptively adjusted margin parameter calculated based on the predicted probabilities of different classes. $p_j$ is the average model prediction value updated by exponential moving average at each iteration. When a sample belongs to the majority class, its contribution to the loss is reduced by the adaptive margin, thus preventing the majority class from suppressing the minority class. Finally, the $L_{AML}$ loss is used instead of the unsupervised loss, replacing the cross-entropy term in equation (7), to mitigate the imbalance issue in the pseudo-label generation process."}, {"title": "b. Adaptive Hard Triplet Loss", "content": "In scenarios of data imbalance, machine learning models tend to be biased towards the majority class. One approach to overcome this bias is Deep Metric Learning (DML). DML is a category of algorithmic methods that utilize neural networks to map samples into an embedding space, continuously reducing intra-class distances and increasing inter-class distances in this space to address the model's bias issue. Among them, Triplet Loss is the"}, {"title": "IV. Numerical Experiments", "content": "In the practical application of SAR ATR, class im-balance is a challenge faced by many practitioners. The imbalance ratio (IR) typically represents the ratio of the number of samples in the majority class to the number of samples in the minority class in a dataset. The ef-fect of different IR values on target recognition models varies. Generally, an IR value exceeding 9 indicates a highly imbalanced dataset. In this chapter, we select the representative MSTAR [9] and FUSAR-ship datasets [87] to validate the performance of the proposed method on imbalanced data."}, {"title": "(1) MSTAR", "content": "The MSTAR dataset is obtained through a high-resolution, coherent X-band radar sensor with an imaging resolution of 0.3 m \u00d7 0.3 m, using the HH polarization mode. It contains images of various categories of static vehicle targets. The commonly used MSTAR dataset consists of ten classes, including the following target categories: 2S1, BMP2, BRDM2, BTR60, BTR70, D7, T62, T72, ZIL131, and ZSU234. The images of each target class are distributed at intervals of 1-5\u00b0 in azimuth angle. Additionally, all target images are sampled at 15\u00b0 and 17\u00b0 elevation angles. Typically, images at a 17\u00b0 elevation angle are used as the training dataset, while those at a 15\u00b0 elevation angle are used as the testing dataset.\nTo obtain imbalanced datasets, we set the IR values to 10, 20, and 30, respectively. Following the work of previous researchers [97], we construct imbalanced datasets that follow a long-tailed distribution. Assuming the total number of samples in the majority class is N, and K is the total number of classes in the dataset, the formula for calculating the number of samples for class k when the imbalance ratio is IR is shown in equation (14). Due to the inconsistent sizes of the original data images and the concentration of vehicle targets mainly in the central range of the images, all images are cropped to the center to obtain slices of size 128 \u00d7 128. Figure 7 illustrates the SAR images of all classes in the MSTAR dataset along with their corresponding optical images. Table 1 provides detailed information on the number of samples for each class in the imbalanced MSTAR training set under different IR values.\n$N_k = N \\cdot IR^{-(k-1)/(K-1)}$"}, {"title": "(2) FUSAR-ship", "content": "In 2020, Hou et al. released the FUSAR-ship dataset collected by the Gaofen-3 satellite. Gaofen-3 is China's first civilian fully polarimetric C-band synthetic aper-ture radar (SAR) satellite, with a resolution of up to 1 meter. FUSAR-ship is an open SAR-AIS co-registered dataset containing matching information on time, space, and coordinate transformation. The azimuth resolution of these target images is 1.124 m, and the range resolution ranges from 1.700 m to 1.754 m. The FUSAR-ship dataset exhibits an issue of data imbalance. In the experiments, five classes of ship targets were selected for training and testing: bulk carriers, oil tankers, fishing boats, container ships, and general cargo ships. The ratio between the majority and minority classes in this dataset is 10, making the IR equal to 10. Similarly, images were cropped from the center of the original images to a size of 96 x 96 as input for the model. Figure 8 displays the SAR images of these five types of ship targets, and Table 3 lists detailed information about the training and testing sets."}, {"title": "B. Implement details", "content": "This chapter proposes a model that uses Wide ResNet 28-2 as the backbone network, with network parameters referencing FixMatch. The learning rate of the model is set to 0.03. SGD is chosen as the optimizer, with a momentum of 0.9. Within each training batch, there are 16 labeled samples, and the ratio of unlabeled samples to labeled samples is 7:1. By using more unlabeled data within each training batch, the training performance of the model can be effectively improved. For the MSTAR and FUSAR-ship datasets, the threshold for the energy score te in equation (7) is set to -9.5 and -9, respectively. The temperature parameter T in equation (4) is set to 1 and 0.5 for the two datasets, respectively. Similarly, for the above two datasets, the hyperparameter in equation (11) is set to 0.3. The weights du and AAHTL for the unsupervised loss in equation (13) are set to 1.0 and 1.5, respectively. Test experiments are conducted using the exponential moving average of model parameters. All experiments are implemented on a personal computer with an Intel Core i7-7700K CPU and 16GB of memory. The computer is equipped with a GeForce GTX 1080Ti GPU with 11GB of memory and PyTorch 1.9.0."}, {"title": "C. Comparative experiments", "content": "In this subsection, ablation experiments will be con-ducted to provide a more intuitive demonstration of the contribution of the three components in the proposed method, including: the energy-based intra-class pseudo-label selection mechanism, the adaptive margin loss func-tion, and the adaptive hard triplet loss function. Unless otherwise specified, all ablation experiments are con-ducted on the MSTAR dataset with IR set to 10 and the FUSAR-ship dataset with IR set to 10, with the proportion of labeled samples set to 20%. The results of all ablation experiments are shown in Table 5 where the first row represents the recognition results of FixMatch ensemble with EUAPS."}, {"title": "1) ESIDPS", "content": "First, the effectiveness of the energy-based intra-class pseudo-label selection mechanism is evaluated relative to the traditional method based on softmax confidence scores. In the FixMatch model, only the method based on softmax confidence scores is used to select pseudo-labels. As shown in the first row of Table 5, the FixMatch ensemble with EUAPS achieves a recognition accuracy of 93.56% on the MSTAR dataset. When the ESIDPS mechanism is introduced, a recognition rate of 94.79% is achieved, which is an improvement of 1.23% compared to the baseline, as shown in the second row of Table 5. Similarly, on the FUSAR-ship dataset, the introduction of the ESIDPS mechanism increases the recognition rate from 81.74% to 82.46%, an improvement of 0.72%. Thus, the energy-based intra-class pseudo-label selection mechanism effectively reduces the error rate of pseudo-labels by selecting labels close to the training distribution based on energy scores. Compared to the method based on softmax confidence scores, it exhibits higher reliability and robustness."}, {"title": "2) AML", "content": "Considering the ease of classifier-induced inter-class confusion, leading to natural imbalance in the pseudo-label generation process even when labeled and unla-"}, {"title": "3) AHTL", "content": "The Adaptive Hard Triplet Loss (AHTL) function designed in this paper aims to construct hard triplets, directing the model's attention to more challenging sam-"}, {"title": "E. Hyper-parameter Analysis Experiment", "content": "This section will focus on several key hyperparameters in the proposed method: the energy score threshold $T_e$ in Equation (4.7), the temperature parameter T in Equation (4.4), the distance margin m in Equation (4.11), and the loss weights \u5165u and XAHTL in Equation (4.13). Unless otherwise specified, all experiments are conducted on the MSTAR dataset with IR set to 10 and the FUSAR-ship dataset, with the proportion of labeled samples set to 20"}, {"title": "1) Energy score threshold $T_e$", "content": "In the energy-based pseudo-label selection method, a key hyperparameter is the energy score threshold te. As shown in Equation (4.7), it determines which samples can be chosen as pseudo-labels. From Equation (4.4), it can be observed that the computed energy scores are negative and proportional to the total number of classes. Addi-tionally, through experimentation, it has been found that the energy scores of samples mainly distribute between [-11, -6]. Therefore, the energy score threshold should also be within this range. Further, by sampling different thresholds within this interval to examine their effects on the target recognition accuracy, experimental results are depicted in Figure 10. Considering that only samples with energy scores lower than Te can be selected as pseudo-labeled samples, the x-axis of Figure 10 varies from -6 to -11 to ensure that the selection process of pseudo-labels gradually becomes stricter.\nFrom Figure 10(a), it is observed that as the thresh-old decreases gradually from -6 to -9.5, the recognition accuracy of the model on the MSTAR dataset steadily improves. This is because a smaller threshold makes the model more stringent in selecting pseudo-labels, only al-lowing unlabeled samples very close to the distribution to be chosen as pseudo-labels, thus increasing the accuracy of pseudo-labels. However, as the threshold continues to decrease within the range [-9.5, -11], the recognition accuracy shows a decreasing trend. This change occurs because some correctly predicted pseudo-labels are fil-tered out by the model's overly strict energy threshold, significantly affecting the recall rate of pseudo-labels and consequently impacting the overall recognition rate of the model. Similarly, observing the experimental results on the FUSAR-ship dataset shown in subfigure 10(b), when the threshold is set to -9, the recognition accuracy peaks.\nIn summary, through the above experimental analysis, it can be determined that for the MSTAR and FUSAR-ship datasets, the optimal energy score thresholds are -9.5 and -9, respectively."}, {"title": "2) Temperature parameter T", "content": "The calculation formula for the energy score includes a temperature parameter T, which is used to adjust the distribution of energy scores. Generally, when the temperature parameter T is smaller, the differences in energy scores are larger, resulting in a steeper distribution; conversely, when T is larger, the distribution becomes smoother. Here, experiments are conducted to evaluate the impact of this parameter on recognition performance.\nFigure 11 shows the recognition results on the MSTAR and FUSAR-ship datasets when the temperature parame-ter T takes values 0.0, 0.5, 1.0, 1.5, 2.0, 4.0."}, {"title": "3) Distance margin m", "content": "In the formula (4.11) of the AHTL function, there exists a crucial distance margin parameter m. Its presence constrains the distance between the anchor sample and the positive sample in a triplet, requiring it to be smaller than the distance between the anchor sample and the negative sample in the constructed feature space, thereby reducing intra-class variance and increasing inter-class variance. In this section, experiments are conducted to explore the im-pact of the parameter m on the recognition model and to find the optimal value. It is clear that the distance margin parameter m is a constant greater than 0. Too small values of m cannot enhance the model's ability to distinguish between different class samples, while too large values increase the training difficulty of the model, leading to non-convergence. The experiments found that when the size of m exceeds 0.5, the model becomes difficult to converge. Therefore, only the variation of m from 0.1 to 0.4 is studied to observe the changes in the recognition results of the model on the MSTAR and FUSAR-ship datasets. The experimental results are shown in Figure 12, indicating that when the distance margin parameter m is very small (e.g., 0.1), the model's recognition performance is poor on both datasets. This is consistent with the previous observation that too small values of m"}, {"title": "4) Loss weights Au and \u039b\u0391HTL", "content": "As shown in Equation (4.13), the weights Au and XAHTL of the unsupervised loss function balance the supervised and unsupervised terms in the loss function. In this section, experiments are conducted on two datasets to separately discuss the effects of Au and AAHTL on the model performance. The experimental results are shown in Figures 13 and 14."}, {"title": "V. Discussion", "content": "This study proposes and validates a semi-supervised SAR target recognition method adaptable to category imbalance on two extremely imbalanced SAR target datasets, with the findings demonstrating higher recog-nition performance. First, the generic softmax-based pseudo-label screening method may worsen the data imbalance issue by decreasing the pseudo-label recall of unlabeled samples in a few classes under the class imbalance scenario [33], [34]. In this paper, we dis-card the softmax-based pseudo-label selection mechanism and instead screen pseudo-labels by judging whether the unlabeled samples are close to within the training distribution. Additionally, energy scores are integrated with it for quantitative screening. The data distribution of pseudo-labels is updated and expanded during the training iteration process, increasing the pseudo-labels' depend-ability in situations when there is data imbalance. When calculating the unsupervised loss of pseudo-labeling, most semi-supervised models often assign the same weight to all samples [11]-[13] [15] [17]. While, even when the original labeled and unlabeled data are balanced, the generated pseudo-labels exhibit a natural imbalance problem [35], which is mostly caused by the classifier's inter-class confusion mistake. As a result, this research replaces an adaptive marginal loss (AML) function for the usual cross-entropy term to strengthen the model's classification marginal differences between easily con-"}, {"title": "VI. Conclusions", "content": "This work presents a semi-supervised SAR target recognition approach using dynamic energy scores and adaptive loss functions. First, the method overcomes the problem of class imbalance generated by the softmax threshold-based pseudo-label generation method, which lowers the recall rate of pseudo-labels for minority classes. Instead, a pseudo-label selection technique based on energy scores is used to generate pseudo-labels. This strategy not only improves the reliability of pseudo-labels in long-tailed distribution scenarios, but it also responds better to the constantly changing data distribution because its pseudo-labels are dynamically updated. Second, an adaptive margin-aware loss function is proposed to re-place the cross-entropy term in the unsupervised loss, addressing the biased pseudo-label problem caused by the classifier's inter-class confusion. Furthermore, an adaptive hard triplet loss function is used to push the model to focus on complicated challenging samples during training, hence enhancing the model's capacity to acquire discrim-inative features and reducing the model's tendency for majority classes. On long-tailed distribution datasets like MSTAR and FUSAR-ship, the proposed approach sig-nificantly improves recognition performance, demonstrat-ing its effectiveness and application. Adequate ablation and hyperparameter experiments confirm the proposed method's robustness and generalizability."}]}