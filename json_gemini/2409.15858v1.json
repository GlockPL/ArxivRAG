{"title": "Identification For Control Based on Neural Networks: Approximately Linearizable Models", "authors": ["Maxime Thieffry", "Alexandre Hache", "Mohamed Yagoubi", "Philippe Chevrel"], "abstract": "This work presents a control-oriented identification scheme for efficient control design and stability analysis of nonlinear systems. Neural networks are used to identify a discrete-time nonlinear state-space model to approximate time-domain input-output behavior of a nonlinear system. The network is constructed such that the identified model is approximately linearizable by feedback, ensuring that the control law trivially follows from the learning stage. After the identification and quasi-linearization procedures, linear control theory comes at hand to design robust controllers and study stability of the closed-loop system. The effectiveness and interest of the methodology are illustrated throughout the paper on popular benchmarks for system identification.", "sections": [{"title": "1 Introduction", "content": null}, {"title": "1.1 Context and Related Works", "content": "The ongoing growth of data and computing resources prompts all scientific communities to take an interest in data-driven methods, and automatic control is no exception [1]. However, while modern machine learning techniques can handle very large datasets, the underlying dynamics renders data generated by dynamical systems temporally correlated which makes control-oriented learning algorithms less efficient [2]. Whereas different literature works aim at either reducing the computational complexity of the learning problem or improving model identification performances, see e.g. [3,4,5], our objective is slightly different as we seek to provide a control-oriented identification method to ease the observer and/or controller design process. Control-oriented learning takes different forms but one can find among others: the identification of linear parameter varying (LPV) approximation of nonlinear models [6,7], the use of Koopman theory to learn a linear representation of a nonlinear system [8,9] or learning-based model predictive control [10].\nWe consider a plant whose evolution is described by an unknown discrete-time nonlinear state-space model of the form:\n$$x(t) = Ax(t) + Bu(t) + Fdc(t)$$\n$$y(t) = Cx(t) + Du(t) + Exc(t)$$\n$$0 \u2264 y(t) \u2212 x(t) \u2265 0$$"}, {"title": null, "content": "$$\\dot{z}(t) = \\\u00c1o(t)z(t) + Bo(t)u(t)$$\n$$y(t) = Cx(t) + Du(t) + Exc(t)$$\n$$0 \u2264 y(t) \u2212 x(t) \u2265 0$$"}, {"title": null, "content": "$$\\min J(u, x, c) = \\int_{0}^{T} (x(t)Qx(t)+u(t)u(t) + \\lambda c)$$\n$$x(t) = Ax(t) + Bu(t) + FXc(t)$$\n$$y(t) = Cx(t) + Du(t) + Exc(t)$$\n$$0 \u2264 y(t) \u2212 \\lambda c(t) \u2265 0$$"}, {"title": null, "content": "$$x1) = x2) + \\phi1 (t, x$$\n$$X$$\n$$:$$\n$$X$$\n$$\\phi1 (t, x(t))$$\n$$x(9-1) = x(9) + \\phiq-1 \\phiq-1 (t, x(t),...,x(9-1) (t))$$\n$$xq) = ui(t) + \\phiq (t, x$$\n$$Xi$$\n$$X$$\n$$\\phiq(t, x(t),...,x(t))$$"}, {"title": null, "content": "$$x(t+1) = f(x(t), u(t))$$\n$$y(t) = Cx(t)$$"}, {"title": null, "content": "where u(t) \u2208 Rm is the system input, y(t) \u2208 RP the output, x(t) \u2208 Rn is the state and where the function f : R\u2033 \u00d7 Rm \u2192 Rn is unknown and generally nonlinear. For sake of clarity, results are presented for the linear-output case, where the matrix C from equation (5) is unknown. Discussion at the end of the paper shows how to extend the results to models with nonlinear output terms.\nA neural state-space model is a model where the function f from equation (5) is approximated using a neural network fn with I hidden layers of the form:\n$$20 = 2$$\n$$Zi+1 = \\sigmai+1(Wizi + bi), i = 0, . . ., l \u2212 1$$\n$$fn(z) = W\u0131z\u0131 + bi$$\nwhere Wi and bi are weights matrices and biases vectors respectively and \u03c3\u03b5 is an appropriate nonlinear activation functions, usually sigmoid or hyperbolic tangent.\nThe inclusion of an explicit linear part in the nonlinear model has been studied by several authors that show how it improves the identification of the nonlinear model, see e.g. [11,12] The model to be identified is then written as:\n$$x(t + 1) = Ax(t) + Bu(t) + fn(x(t), u(t))$$\n$$y(t) = Cx(t)$$"}, {"title": null, "content": "This model - possibly including a nonlinear output term - is defined as generalized residual state-space neural network (GR-SSNN) in [13]. However, even if the structure of model (7) makes it suitable for system identification/simulation, it does not necessarily ease the design of efficient control laws as the function fn is still nonlinear.\nIn recent years, there has been a considerable increase in research related to robustness or stability analysis of neural models. Incremental quadratic constraints are now widely used to analyze a posteriori the properties of the neural networks [14,15] or to train robust models [16]. These properties are generally written as linear matrix inequality (LMI) constraint problems and included into the learning scheme in the form of a barrier term using the logdet matrix function [16,17]. This solution raises challenges during the optimization process, the logdet function being undefined outside the LMI feasibility set. One proposed strategy to address this challenge is to implement a backtracking line search, as in [18]. However, due to the non-convex nature of the optimization profile, this step may either not converge or induce conservatism.\nInspired by previous works on approximate linearization [19] and data driven linearization [20], this paper presents a different strategy by imposing a specific structure for the neural network such that the design of a feedback-linearizing control law trivially follows the learning stage. This facilitates the stability analysis and control design for nonlinear systems."}, {"title": "1.2 Problem Statement and Contributions", "content": "A way to tackle the issue of efficient design of controller for model (7) is to consider that the term based on the nonlinear function fn(x(t), u(t)) is modest compared with the linear part and to consider this term as a bounded disturbance. Thus, the vast literature on linear systems comes at hand to design an adequate controller to cope with these uncertainties to make them vanish via the robustness property of the feedback control law. However, there is no reason for fn(x(t), u(t)) to be small after the identification procedure. On the contrary, if one wishes to minimize the output simulation error, then minimizing fn would be an antagonistic objective.\nAn immediate substitute would be to identify a linear time invariant (LTI) model, but this kind of model is generally not representative enough of the underlying system dynamics. Yet, if one manages to render the dynamic behavior of model (7) linear by feedback, then the design of the control law is made simple. Condition for exact feedback linearization are however often complicated to meet in practice [21] and even to check for neural networks architectures [22].\nOne solution to overcome this issue is to perform approximate feedback linearization, where the objective is to minimize the residual nonlinearity fn. This can be achieved by decomposing it into an input nonlinearity associated with an unavoidable modeling error. The control law can then easily deal with the input nonlinearity and the training procedure ensures that the residual nonlinearity is minimized."}, {"title": null, "content": "This paper introduces a control-oriented identification procedure, namely approximately feedback-linearizable state-space neural networks, to identify system (5) with a given parameterized evolution equation such that the nonlinearity is explained as much as possible by a nonlinearity on the input. This ensures that the model is approximately linearizable by feedback. This work is an extension of previous work [23] where the nonlinear system was assumed to be exactly feedback linearizable."}, {"title": "1.3 Notations", "content": "The notations used in this article are standard. For any vector or matrices x \u2208 Rn or M\u2208 Rnxm, xT and MT are their transpose and for M\u2208 Rn\u00d7n, M = MT > 0 defines a symmetric positive definite matrix. We use the standard Euclidian norm, \u2200x \u2208 R, ||x|| = \u221axTx \u2208 R. Finally, a function f : R\u2265o \u2192 R\u2265o is a K-function if it is continuous, strictly increasing and f(0) = 0. In addition, a K-function is a K-function with limx\u2192\u221e f(x) = \u221e. Results are presented for discrete-time systems and x+ stands for the value of x at next time step, i.e. X+ = x(t + 1). In the remainder of this document, time dependence of time varying vectors will be omitted for simplicity when there is no ambiguity."}, {"title": "2 Approximately feedback-linearizable neural state-space models", "content": "Without loss of generality, function fn(x, u) can be written as the addition of an input nonlinearity hn(y) and an unavoidable residual nonlinearity gn(x, u) such that it holds:\n$$fn(x,u) = Bhn(y) + gn(x, u)$$\nNext section introduces a class of state-space neural networks where the nonlinearity is explained as much as possible by the input nonlinearity hn(y) while we seek to minimize the residual nonlinearity gn(x, u)."}, {"title": "2.1 Definitions", "content": "Proposition 1. (AL-SSNN) We call Approximately feedback-Linearizable State-Space Neural Networks nonlinear models with linear output of the form:\n$$x+ = Ax + B(u+hn(y)) + In(x, u)$$\n$$Yo = Cx$$\nwith parameters 0 = {A, B, C, hn, gn} and where functions hn and gn are neural networks."}, {"title": null, "content": "The interest of this class of model comes from closed-loop control design, as the approximately-linearizing control input trivially writes:\n$$u = v - hn(y)$$\nwhich yields the corresponding closed-loop model:\n$$X+ \u0391\u03c7 + \u0392\u03c5 +\u03c9$$\n$$Yo = Cx$$\nwhich is a LTI model with the closed-loop input v and a bounded perturbation w = gn(x, v - hn(y)), as illustrated on figure 1. Control input (10) is an output-feedback and therefore does not require the design of a state-observer for the initial nonlinear model.\nTo ensure that the AL-SSNN model is suitable for control design, the model parameters are obtained through the minimization of the mean-squared error between data measurements and model output, plus the minimization of the residual nonlinearity gn:\n$$\\theta=\\arg \\min J_{N}(\\theta)$$\n$$J_{N}(\\theta) = \\frac{1}{N} \\sum_{k=1}^{N} ((y(k)-y_{0}(k))^{2} + \\gamma g_{n}(x(k),u(k))^{2})$$\nwhere y is the real system output, yo is the output of model (9) given parameters \u03b8 and N is the number of samples used for training. Finally, \u03b3 is a positive scalar that weights the minimization of the nonlinearity compared to the precision of the resulting model."}, {"title": "3 Identification procedure", "content": "This section details the implementation of the training procedure of the AL-SSNN model (9)."}, {"title": "3.1 Network structure", "content": "Functions hn(y) and gn(x, u) are both represented by a one-hidden-layer feed-forward neural network with nonlinear activation function with respectively nh and ng hidden neurons, and a linear output layer:\n$$hn(y) = Wh\\sigma_{\\eta} (W_{y}y + b_{y}) + b_{h}$$\n$$gn(x, u) = W_{g} \\sigma_{g}(W_{x}x + W_{u}u + b_{x}) + b_{g}$$\nwhere \u03c3\u03b7: Rnn \u2192 Rnhandog: Rng \u2192 Rngare element-wise nonlinear activation functions that can be set independently but in the following we use hyperbolic tangent as activation function.\nThe approximately-linearizing control input (10) is applied around an equilibrium point xe induced by ue and, arbitrarily close to this equilibrium point, the residual nonlinearity gn vanishes. Its biases terms br and by are therefore computed such that gn (xe, ue) = 0."}, {"title": "3.2 Software Implementation", "content": "The cost function (12) is nonlinear and not convex but its gradient can be computed efficiently, which makes the choice of gradient descent algorithm appropriate. The model is trained using algorithm implemented within the Matlab Deep Learning toolbox [24] and Levenberg-Marquardt algorithm [25]. The training configurations for each example is detailed in table 6, the identification method presented here involves only few parameters to tune and does not require the use of deep networks with large number of hidden neurons.\nThe control-oriented architecture eventually slows down the identification procedure, as illustrated in table 6. Training and simulations tests were carried out on a laptop with an Intel(R) Core(TM) i7 CPU at 1.80 GHz x 4 with 32GB of system memory."}, {"title": "3.3 Initialization", "content": "Inspired from [13], the training procedure is iterative and starts by linear initialization, i.e. the AL-SSNN model (9) is initialized as:\n$$X+ A_{0}x + B_{0}u$$\n$$Yo = C_{0}x$$\nwhere matrices A0, Bo and Co are obtained using a linear identification algorithms, namely the subspace method implemented within the Matlab function ssest together with n4sid algorithm [26]. In other words, functions hn and gn are initialized as hn(y) = 0 and gn(x, u) = 0."}, {"title": "3.4 Implementation of Cost Function", "content": "Our objective is not only to minimize the nonlinear term gn(x, u), but rather to minimize the ratio between this nonlinearity and the linear part so that the nonlinear term is negligible in regards to the linear one. In other words, we aim at minimizing |gn(x,u)||. However, the computation of the gradient is computationally expensive and may lead to poor training performances.\nWe propose a different approach to overcome this issue. The minimization of ||gn(x, u) || is added in the objective function as in (12) and to ensure that ||Ax + Bu|| is not minimized jointly, we impose that the output matrix remains fixed during training, i.e. C = Co. Therefore, the optimization solver cannot scale down ||x|| and scale up matrix C accordingly, otherwise the ratio |gn(x,u) | would not be minimized."}, {"title": "4 Illustrations of training results", "content": "The effectiveness of the proposed identification procedure is illustrated thanks to a popular benchmarks for system identification, a Wiener-Hammerstein process.\nThe Wiener-Hammerstein system is a block-oriented structure composed of a static nonlinearity between two LTI blocks. The underlying differential equations are considered as unknown, we only assume that the state vector is in R6, following system description [27].\nWe seek to identify a AL-SSNN model (9) from time domain input-output data measurements consisting in 188 000 points available online\u00b9. The data set is decomposed into training (first 100 000 points) and test (last 88 000 points)."}, {"title": null, "content": "We compare the identification capabilities of the presented AL-SSNN model (9) with the one of the generalized nonlinear model (7) where the nonlinear function fn is unconstrained. Results are illustrated on figure 2 that shows the error between the simulated output of the proposed model (9) and the real output data. In addition, table 1 gathers the root-mean-squared errors (RMSE) between real output measurements and our proposed model. We provide the RMS errors between the data and a LTI model and the generalized nonlinear model (7) for comparison.\nThe results indicate that the proposed identification method performs better than standard LTI model and reaches same order of magnitude compared to state-of-the-art nonlinear identification. Our approach performs equally well when y\u2192 0, it is then a compromise to be found between the models precision and ease of use for control synthesis, keeping in mind that the inaccuracies of the model can be tackled by a closed loop control scheme. A detailed analysis of the influence of parameter y is given in next section in table 4.\nPrey-Predator system We consider a discretized version of a three species prey-predator system of the form:\n$$\\frac{dx_{1}}{dt} = a_{1}x_{1} - b_{1}x_{1}x_{2} - c_{1}x_{1}x_{3} + d_{1}u$$\n$$\\frac{dx_{2}}{dt} = a_{2}x_{2} - b_{2}x_{1}x_{2} - c_{2}x_{1}x_{3} + d_{2}u^{2}$$\n$$\\frac{dx_{3}}{dt} = -ex_{3} + fx_{1}x_{3} + gx_{2}x_{3}$$\nfor which the output is the predator X3. The two prey species x1 and 12 are actuated with ur and us. The parameters ai, bi, ci, di, e, f and g represents the growth/death rates, the effect of predation on the prey population, and the growth of predators based on the size of the prey population. Inspired by [28], for the data generation, we force the system sinusoidally with ui(t) = Aisin(t+ i) + Aisin(t/10 + i) and generate 50 000 data points from which we use the first half for training and second half for validation.\nThe identification results are illustrated on figure 3 and gathered in table 2. It shows that the LTI is not able to represent faithfully the underlying dynamics but the identification method proposed above (AL-SSNN, equation (9)) achieves the same order of magnitude as the generalized nonlinear model used for comparison."}, {"title": null, "content": "In addition, the training procedure ensures that the residual nonlinearity norm ||gn(x, u) || is minimized. If successful, one should get after training ||gn(x, u)|| \u00ab ||Ax + Bu||. This is confirmed by results in table 3 that presents the mean and maximum values of the ratio between the nonlinear and linear terms of equation (9). Results show an average ratio of 1.9 \u00d7 10-4 for the Wiener-Hammerstein example and 2.5\u00d710-2 for the prey-predator system while it was only of 0.20 and 0.75 for the generalized nonlinear model (7). The proposed approach therefore divide by at least one order of magnitude the norm of the nonlinear residual."}, {"title": "5 Closed-loop analysis", "content": "AL-SSNN model (9) in closed with u = v - hn(y) is a LTI model with bounded disturbance w:\n$$x+ = Ax + B\u03c5 + \u03c9$$\n$$y = Cx$$"}, {"title": null, "content": "with ||w|| = ||gn (x,v \u2013 hn(y)|| \u2264 6. As w is bounded and negligible compared to the linear term, the vast theory of linear control theory come at hand to design robust control laws.\nThe training procedure ensures that the open-loop residual nonlinearity norm ||gn(x, u) || is minimized for all combinaison of (x, u) included in the training set. In the following, it is assumed that minimizing the open-loop norm implies minimizing the closed-loop residual nonlinearity ||gn (x, v - hn(y))||. This assumption holds if one consider that v -hn(y) stays in the training set, i.e. the training set is exhaustive enough to capture the system dynamics in its whole. This assumption is verified experimentally in the following sections."}, {"title": "5.1 Approximate Linearization", "content": "To estimate how dominant is the linear part of model (16), we simulate this model with v being the real data measurements and compare the norm of the linear and nonlinear term of the state equation. If ||w|| is negligible compared to ||Ax + Bv||, then system (16) is approximately linear, i.e. linear if ||wx+Bv||\nResults are gathered in table 5 and show that there is on average a ratio of order 10-2 between the linear and nonlinear term of the Wiener-Hammerstein process. Therefore, the linear part of model (16) is at least one order of magnitude superior to the residual nonlinearity w. This ratio can be tuned with the scalar value y in the cost function (12). If y\u2192 0, the results are similar with the ones of the generalized model (7), on the contrary when y increases, then the residual nonlinearity is further minimized, as illustrated by table 4. For training, the value of y is tuned by trial and errors, with the objective of optimizing the compromise between linearization capabilities and precision of the nonlinear model."}, {"title": "5.2 Stability Analysis", "content": "To ensure that the residual nonlinearity do not affect the stability of the closed-loop system, it is taken into account in the stability analysis thanks to input-to-state stability (ISS) property.\nSystem (16) is then ISS if it admits a Lyapunov function V(x) such that:\n$$\u2206V(x) < -\u03a6(||x||) + \u03a8(||w||)$$\nIn the remainder of the document, we use quadratic functions defined as V(x) = xTPx, \u03a6(||x||) = \u03c6xT Px and I(||\u03c9||) = \u03c8\u03c9\u03c4\u03c9, where 4 and 4 are two positive scalars.\nAbove Lyapunov inequality is then equivalent to:\n$$\\begin{pmatrix}A^{T}PA+(\\Omega-1)P & A^{T}P\\\nPA & P-\\Psi I\\end{pmatrix}<0$$\nfor which a sufficient condition is the following linear matrix inequality (LMI) constraint problem with decision variables & \u2208 R>0, \u03c8 \u2208 R>0, P > 0 \u2208 Rn\u00d7n :\n$$\\begin{pmatrix}A^{T}PA+(\\Omega-1)P & A^{T}P\\\nPA & P-\\Psi I\\end{pmatrix}<0$$\nIt ensures that, for large enough time, the closed-loop state x converges to a hyperball I whose radius depends on 4 and 4:\n$$I = { x \u2208 R, \u03a6(||x||) \u2264 \u03a8(||w||) }$$\nLet us now recall that after training, ||w|| \u2264 e, a specific bound that can be computed on training and validation sets easiliy. Then, it holds (||||) =\n\u03c8||w||2 < \u03c8\u03b5\u00b2. We finally get the following stability property.\nProposition 2.\nAssuming that:"}, {"title": null, "content": "the AL-SSNN model (9) approximates system (5) with ||gn(x, u) || \u2264 \u0454\nLMI (19) holds\nthen the closed-loop state x of (16) converges to an invariant manifold defined as:\n$$I = {x \u2208R\",xTPx <\\frac{\\psi\\epsilon^{2}}{\\phi}} $$\nLMI (19) can be computed using semi-definite programming solvers such as YALMIP [29] and the final values of stability certificates for Wiener-Hammerstein system are $ = 0.1,\\psi = 11.,  3.1 \u00d7 10-4 and Amin(P) = 2 x 10-2 and \u0410\u0442\u0430\u0445 = 1.5.\""}, {"title": "6 Discussion", "content": "This contribution is a proof of concept illustrating the possibility of parameterizing and learning a nonlinear model, which opens up the field and its application to practical problems of greater complexity. Results are presented for the linear-output case but can be extended to the general nonlinear case of the form:\n$$x(t+1) = Ax(t) + B(u(t) + hn(y(t)) + gn(x(t), u(t))$$\n$$y(t) = Cx(t) + Du(t) + kn(x(t), u(t))$$\nIn this case, the optimization problem should be adapted accordingly to include a minimization of the output residual nonlinearity kn:\n$$\\theta = \\arg \\min J_{N}(\\theta)$$\n$$J_{N}(\\theta) = \\frac{1}{N} \\sum_{k=1}^{N} ((y(k)-y_{0}(k))^{2} + \\gamma g_{n}(x(k),u(k))^{2} + \\sqrt{k_{n}(x(k),u(k))}$$"}, {"title": "7 Conclusions", "content": "This work proposes a procedure to identify nonlinear state-space models from input-output data. The specificity is that, in addition to faithfully representing the input-output behavior of the plant, its parameterization is devoted to facilitating the design of control laws. From time-domain input-output data measurements, a neural-network is trained to identify a nonlinear discrete-time model that is approximately linearizable by output-feedback. The quasi-linearizing control law derives directly from the identification stage and the residual closed-loop nonlinearity is minimized, which makes it possible to use the classical tools of linear control theory.\nSimulation results on popular and competitive benchmarks available online illustrate the effectiveness and genericity of the approach for robust control.\nThe results are presented here for the discrete-time case but can be adapted to the continuous-time case with few modifications. Our current work focuses on taking into account new constraints in the identification procedure; always with the aim of improving performances and robustness of the control laws designed from data."}]}