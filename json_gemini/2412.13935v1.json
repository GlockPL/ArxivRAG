{"title": "Spatio-Temporal Forecasting of PM2.5 via Spatial-Diffusion guided Encoder-Decoder Architecture", "authors": ["Malay Pandey", "Vaishali Jain", "Nimit Godhani", "Sachchida Nand Tripathi", "Piyush Rai"], "abstract": "In many problem settings that require spatio-temporal forecasting, the values in the time-series not only exhibit spatio-temporal correlations but are also influenced by spatial diffusion across locations. One such example is forecasting the concentration of fine particulate matter (PM2.5) in the atmosphere which is influenced by many complex factors, the most important ones being diffusion due to meteorological factors as well as transport across vast distances over a period of time. We present a novel Spatio-Temporal Graph Neural Network architecture, that specifically captures these dependencies to forecast the PM2.5 concentration. Our model is based on an encoder-decoder architecture where the encoder and decoder parts leverage gated recurrent units (GRU) augmented with a graph neural network (TransformerConv) to account for spatial diffusion. Our model can also be seen as a generalization of various existing models for time-series or spatio-temporal forecasting. We demonstrate the model's effectiveness on two real-world PM2.5 datasets: (1) data collected by us using a recently deployed network of low-cost PM2.5 sensors from 511 locations spanning the entirety of the Indian state of Bihar over a period of one year, and (2) another publicly available dataset that covers severely polluted regions from China for a period of 4 years. Our experimental results show our model's impressive ability to account for both spatial as well as temporal dependencies precisely. The code is publicly available at https://github.com/malayp717/pm2.5.", "sections": [{"title": "1 Introduction", "content": "Spatio-temporal forecasting [12] aims to integrate spatial and temporal information in data to predict future events or trends, and has widespread usage in diverse areas, such as climate science, urban planning, and epidemiology. The problem of spatio-temporal forecasting distinguishes itself from standard time-series forecasting as it needs to account for the evolution over time and across different locations. Unlike standard time-series forecasting, spatio-temporal forecasting requires capturing the complex interactions arising due to both space and time.\nA motivating problem we consider in this work is from the domain of Air Quality Monitoring (AQM) [11]; in particular, forecasting the concentration levels of fine particulate matter PM2.5 (particles with aerodynamic diameter \u2264 2.5 \u00b5m) for a given set of stations at various geographical locations. Elevated levels of PM2.5 pollution in the atmosphere have far-reaching health implications, including the development of severe medical conditions, such as cardiovascular obstructive pulmonary disease, lung cancer, stroke, and asthma [31]. Accurate forecasts can help in taking mitigating measures and help inform policy-makers for early warning systems as well as long-term planning.\nPM2.5 concentration is characterized by complex processes, starting from emission generated by pollution sources to transport and diffusion influenced by meteorological and geographical information, which often have wide range and long-lasting effects. As reported by [10] PM2.5 can be transported hundreds of kilometers in 72 hours. Thus, not only does spatial diffusion play a significant role in PM2.5 concentration, but long-term dependencies also play a role, making it a complex spatio-temporal forecasting problem.\nFor the forecasting of standard time-series data, a number of approaches have been considered in prior work, ranging from classical time-series forecasting methods, such as autoregressive (AR) and exponential smoothing [19], to more recent deep learning approaches, such as recurrent neural networks and temporal convolutional neural networks [17]. However, while being effective for the forecasting of a single time-series, these methods are not able to leverage the complex dependencies across different locations, each of which is defined by its own time-series. This necessitates time-series forecasting methods that can account for spatial dependence across locations and has led to significant research interest in spatio-temporal forecasting [12].\nSpatio-temporal forecasts are often also dependent on not just the previous values in the time-series and the values at other neighboring locations, but also on exogeneous variables. For example, in the PM2.5 forecasting problem, the concentrations of PM2.5 at any station not only exhibit spatial and temporal dependencies but are also dependent on meteorological and other weather-related variables at that location. If thinking of each location as a node of a"}, {"title": "2 Methodology", "content": "We start by describing the dataset and the area of interest where our proposed model is evaluated. Subsequently, we formulate the PM2.5 forecasting problem in mathematical terms and discuss construction of the graph over locations from our area of interest. Finally, we present the proposed architecture to model the spatio-temporal evolution of PM2.5 concentration levels over the area of interest."}, {"title": "2.1 Dataset", "content": "This study focuses primarily on the region of Bihar, India. An extensive network of Air Quality Monitoring (AQM) stations distributed across the entire state provided verifiable ground truth PM2.5 concentrations, as well as readings for meteorological features, such as relative humidity (RH) and diurnal temperature (T), on an hourly basis. Please refer to Section 4.1 to find the distribution of these AQM stations across the entire state.\nFollowing [29], we utilize data from two sources: the AQM stations (RH, T, PM2.5) and the ERA5 climate reanalysis data from the European Centre for Medium-Range Weather Forecasts (ECMWF) 2, to obtain an additional set of features, namely: Planetary Boundary Layer (PBL) height, u10-component of wind, v-10 component of wind, K-index, Surface Pressure and Total Precipiation. We refer to the meteorological features and the features from ERA5 data collectively as \"node attributes\" which are available for each station. In addition to these node attributes, we also leverage space and time information; in particular, the location information (latitude-longitude) and time-stamp associated with the recorded PM2.5 observations. The time-stamps (hour-of-the-day, day-of-the-week, and month) are important because PM2.5 concentrations vary throughout the day, and the concentrations drop on the weekend. To address the issue of missing data (e.g., due to a malfunctioning sensor), we employed the Multiple Imputation by Chained Equations (MICE) algorithm [2] for missing data imputation.\nTo further examine the model's capabilities and robustness, we also leverage the KnowAir dataset, utilized by [29], which covers the severely polluted regions of China. The dataset uses the same set of node attributes as the Bihar Dataset."}, {"title": "2.2 Problem Definition", "content": "The PM2.5 concentration forecasting can be formulated as a spatio-temporal problem. Let $y_t \\in \\mathbb{R}^L$ denote the PM2.5 concentrations at time t, where L is the total number of locations. We define a directed graph G = (V, E), where V is the set of nodes representing different locations, and E is the set of edges denoting potential"}, {"title": "2.3 Our Model: AGNN_GRU", "content": "As illustrated in Figure 1, the proposed architecture represents an enhanced version of the Sequence-to-Sequence model, consisting of two main components: an Encoder (left block of Figure 1) and a Decoder (right block of Figure 1). We refer to our model as AGNN_GRU where 'A' stands for Attention, specifically the Luong attention mechanism [20] employed in the decoder; 'GNN' denotes the Graph Neural Network incorporated in the encoder to capture spatial dependencies, including spatial-diffusion; and 'GRU' represents the Gated Recurrent Units used in both the encoder and decoder to model temporal sequences. This combination of GNN and GRU in the encoder, coupled with an attention-enhanced GRU in the decoder, forms a powerful framework for capturing both spatial and temporal dynamics in sequence-to-sequence tasks.\nThe primary objective of the encoder is to identify trends based on historical node attributes, location and time-stamp, and PM2.5 concentrations. This is accomplished by initially capturing spatial dependencies through a Graph Neural Network (GNN) and subsequently integrating these to capture temporal dependencies using a Gated Recurrent Unit (GRU).\n2.3.1 Graph Construction. For directed graph construction, we follow a methodology similar to the one employed in [29]. In this approach, the nodes represent the meteorological characteristics of different locations in our dataset. The edges define how these nodes will interact with one another. The key idea behind edge attributes is influenced by wind speed and direction since it is a major contributor to the PM2.5 horizontal transport. The edge attributes are defined by the following values: distance between source and sink, angle between source and sink, source wind speed, source wind direction, and Advection Coefficient.\nFollowing the Transformer Convolution [25] message-passing paradigm, the GNN module of our encoder (left block of Figure 1) learns enhanced spatial representations by iteratively aggregating neighboring information on the graph, as formulated in Equations 3-4. Since the graph is directed, and the edges encapsulate the wind speed and direction information, the edge attributes help enhance the spatial representations by establishing a direct relationship between the source and sink. The Transformer Convolution is mathematically defined as\n$a_{ij} = W_1P_i + \\sum_{j\\in N_i} (W_2P_j+W_6E_{ij})$\n$\\alpha_{ij} = softmax \\left(\\frac{(W_3P_i)^T (W_4P_j+W_5E_{ij})}{\\sqrt{d}}\\right)$"}, {"content": "where $W_1, W_2 W_6$ represent trainable parameters, that are shared across all time-stamps, $P_i$ represents meteorological, location, and air quality information at location i and time-step t, as expressed in Equation 5, $E_{ij}$ represent the edge attributes of the directed edge between source (i) and sink (j), at time step t, and d is the normalization constant added in the denominator, to help combat the exploding or vanishing gradient problem.\nTo learn the temporal trends, we first concatenate the enhanced spatial representations with the input node attributes, at each time-step, and send them to a Gated Recurrent Unit (GRU) [5], as formulated in Equations 7 and 8. This allows our encoder unit to model"}, {"title": "3 Related Work", "content": "The problem of spatio-temporal forecasting has been studied extensively in several prior works; see Z. Liu et al. [12] for an excellent survey on this topic, [36] for specifically for deep learning architectures for prediction of PM2.5, and [8] for machine learning methods for air-quality analytics in general.\nIn this section, we mainly focus on forecasting of air-quality (e.g., fine particulate matter concentrations) using commonly used time-series methods as well as more sophisticated spatio-temporal approaches that take into account both spatial and temporal information in the air-quality data from multiple locations."}, {"title": "3.1 Classical Time-Series Methods", "content": "Time-series forecasting methods have been traditionally employed to predict air quality. These methods include classical statistical models like ARIMA [34], which are designed to capture temporal dependencies in data. While these models are straightforward and interpretable, they often fall short when it comes to capturing the complex spatio-temporal dynamics present in air quality data.\nDeep learning based sequential data models, such as RNN, LSTM, GRU, and their bi-directional counterparts have also been used for time-series forecasting [13, 24]; however, these approach do not consider the spatial information."}, {"title": "3.2 Spatio-Temporal Approaches", "content": "MasterGNN [7] performs joint prediction of air-quality and weather variables using a multi-adversarial spatio-temporal network, while we focus on the forecasting of PM2.5 using weather and other relevant variables from the historical data, and do not aim to forecast these weather variables which was the focus of [7]."}, {"title": "3.3 Other Related Works", "content": "Another recent method Airformer [16] leverages transformers for forecasting air-quality. While leveraging the power of transformer architectures and also latent variables to capture the uncertainty in air-quality data, this approach does not explicitly capture the spatial diffusion phenomenon as captured by our model.\nAmong other related works, denoising diffusion model based approaches [30, 32] have also been proposed for spatio-temporal forecasting leveraging their impressive generative modeling capability. [3] developed group-aware GNN for nationwide city air quality forecasting. [22] focus on standard GRU based encoder-decoder architectures but with a focus on explainability, in particular to identify key meteorological and temporal features that contribute to air-pollutants. It would be of interest to integrate such approaches into our proposed method which also leverages various meteorological features.\nIn another recent work, [4] proposed an adaptive adjacency matrix-based graph convolutional recurrent network for air quality prediction. [9] used graph neural process for forecasting along with uncertainty estimates of the forecasts.\nSpatio-temporal data can also exhibit distribution shifts over long time horizons. Recent work [18] has looked at this challenging problem, and it would be of interest to extend our approach using ideas in these works to handle distribution shifts.\nRecent works have also started exploring the use of transformers and, more generally, foundation models for time-series forecasting [15, 21, 33]. While promising, the current models do not consider aspects such as spatial relationships among the different locations, or other domain-specific knowledge, such as spatial-diffusion. It would be of interest to extend these models to take such information into account."}, {"title": "4 Experiments", "content": "In this section, we carry out comprehensive experiments to showcase the effectiveness of our model. Subsequently, we carefully analyze our model's performance, not only on a macroscopic scale but also region-wise, to demonstrate its robustness."}, {"title": "4.1 Dataset", "content": "As stated in Section 2.1, we collected a comprehensive dataset spanning an entire year (from 2023-05-01 to 2024-04-30) from 511 AQM stations (nodes), which practically covers most of the region of Bihar. To gain a better understanding of our model's performance, we have subdivided the AQM stations into different regions, as"}, {"title": "4.2 Baselines", "content": "We compare our proposed method AGNN_GRU with a number of high-performing baselines. It is important to highlight that these baselines are not only specific instances of our more general architecture but also represent special cases of several state-of-the-art models for spatio-temporal forecasting, including those proposed in [6, 28]. Including these baselines in our experiments thus serves as an ablation study, enabling us to thoroughly assess the contributions of the individual components within our proposed model.\nIn our comprehensive ablation study, we systematically altered or removed certain components from our proposed model, which resulted in the following methods, which we subsequently compare with as strong baselines"}, {"title": "4.3 Experimental Settings", "content": "We run experiments on a single NVIDIA A30 with 24G memory. As a pre-processing step, all the meteorological attributes, including the ground truth PM2.5 concentrations have been normalized for better convergence. All the remaining details regarding experimental settings can be found in Table 4. After the complete training, we employ inverse standardization to get PM2.5 concentrations back within the required range."}, {"title": "4.3.1 Evaluation Metrics", "content": "To evaluate the model performance, we consider test loss, Root Mean Squared Error (RMSE), and Mean Absolute Error (MAE) for evaluation where a smaller metric corresponds to better performance. Furthermore, we also report Spearman's rank correlation values, to check the correlation between our predictions and the ground truth. The model becomes more adept at analyzing spatio-temporal trends and adapting to changes as the value approaches 1, resulting in improved model performance.\nThe RMSE is defined as RMSE = $\\sqrt{\\frac{1}{N} \\sum_{i=1}^N (Y_i - \\hat{Y_i})^2}$, the MAE is defined as MAE = $\\frac{1}{N} \\sum_{i=1}^N |y_i - \\hat{y_i} |$, and\n$\\text{Spearman R (}\\rho\\text{)} = \\frac{\\sum_{i=1}^N (y_i - \\overline{y}) (\\hat{y_i} - \\overline{\\hat{y}})}{\\sqrt{\\sum_{i=1}^N (y_i - \\overline{y})^2 \\sum_{i=1}^N (\\hat{y_i} - \\overline{\\hat{y}})^2}}$"}, {"content": "To check the model performance near a critical threshold (haze threshold), we also evaluate the Critical Success Index (CSI), Probability of Detection (POD), and False Alarm Rate (FAR), to account for abrupt changes in PM2.5 concentration. To calculate CSI, POD, and FAR, we convert the real-valued predictions to binary labels, using haze threshold. The threshold is chosen as 100 \u00b5g/m\u00b3 (75 \u00b5g/m\u00b3 for China), which is the average PM2.5 concentration across all locations for the entire year. Following this threshold, we calculate hits (truth=1, prediction=1), misses (truth=1, prediction=0), and false alarms (truth=0, prediction=1). Note that the higher the CSI and POD values, the better the model performance. A smaller metric for FAR corresponds to a better performance. These metrics are defined as follows\n$CSI = \\frac{\\text{hits}}{\\text{hits} + \\text{misses} + \\text{false\\_alarms}}$\n$POD = \\frac{\\text{hits}}{\\text{hits} + \\text{misses}}$\n$FAR = \\frac{\\text{false\\_alarms}}{\\text{hits} + \\text{false\\_alarms}}$\nThe performance of each model is determined by averaging these metrics across all the locations. To get a fair estimate, we take five different initializations for each model, train on MSELoss, and subsequently report the mean and standard deviation of all the metrics."}, {"title": "4.3.2 Hyperparameter Tuning", "content": "In order to optimise the model's performance, we implement Bayesian search from wandb [1] for 17 iterations for hyperparameter optimization. The hyperparameters that were optimised include learning rate [1e-5, 1e-2], regularisation parameter (\u03bb) [5e-2, 5e-4], and embedding dimension (for the embeddings of the latitude-longitude based location features and timestamp features) {8, 16}. The model's performance on the validation set (MSE loss) was employed as the primary metric to determine the optimal configuration. After extensive cross-validation, the best-performing model used a learning rate of 1e-3, a lambda of 3e-3, and an embedding dimension of 8."}, {"title": "4.4 Results and Discussion", "content": "Initially, we present the results from metrics mentioned in Section 4.3, and then demonstrate the characteristics of the proposed model (AGNN_GRU), through careful analysis. To verify the performance of our proposed model, we present results in two experimental settings: (i) History Length of 24-hours with Forecast Length of 12-hours, and (ii) History Length of 48-hours with Forecast Length of 24-hours.\nIt is important to note that the dataset characteristics significantly influence the model's performance and the observed patterns. The dataset for Bihar spans only a single year, which limits the model's ability to capture long-term seasonality patterns. Consequently, we observe slightly more irregular patterns for this region. On the contrary, the dataset for China covers a span of 4 years, allowing the model to capture strong seasonality patterns. As a result, the results for China dataset are more coherent with our expectations, reflecting the impact of multi-year seasonal variations on the model's predictive capabilities."}, {"title": "4.4.1 12h Forecast Analysis", "content": "As shown in Tables [2, 3], our proposed model outperforms the baselines in almost all metrics. Specifically, our model obtains the lowest Normalized Test Loss, RMSE, and MAE, while simultaneously achieving the highest values for Spearman Rank Relation Coefficient and CSI (Bihar), and POD"}, {"title": "5 Conclusion", "content": "In this paper, we study a significant problem of real-world interest: how to precisely forecast PM2.5 concentrations across different locations. Due to the spatio-temporal nature of the problem, we designed AGNN_GRU, a sequence-to-sequence architecture, coupled with a graph neural network, to capture spatial diffusion and factor in long-term dependencies. The experimental results illustrate the prospective efficacy of the proposed AGNN_GRU technique in both short-term and long-term prediction tasks, as well as the model's generalizability across various geographies. The geography of China substantially differs with that of Bihar, as altitude above sea level is an important consideration in China. Notably, despite not relying on any pre-training, the model due to its relatively simpler architecture as compared to some of the other recent works on air-quality prediction, such as those based on transformers [16], is still able to achieve impressive performance.\nFuture work could include some key areas to enhance the model's performance and applicability, as well as deploying these lightweight models on IoT devices for real-time forecasts. PM2.5 concentrations exhibit significant seasonal variations, as depicted in Figure 3, due to which, it becomes imperative to collect datasets, especially for longer periods rather than from more stations, is critical to understanding the recurring seasonal patterns in PM2.5 concentrations. Such a dataset would likely improve both the quantitative and qualitative aspects of our model."}]}