{"title": "Evaluation of GPT-4o & GPT-4o-mini's Vision Capabilities for Salt Evaporite Identification", "authors": ["Deven B. Dangi", "Beni B. Dangi", "Oliver Steinbock"], "abstract": "Identifying salts from images of their 'stains' has diverse practical applications. While specialized AI models are being developed, this paper explores the potential of OpenAI's state-of-the-art vision models (GPT-4o and GPT-4o-mini) as an immediate solution. Testing with 12 different types of salts, the GPT-4o model achieved 57% accuracy and a 0.52 F1 score, significantly outperforming both random chance (8%) and GPT-4o mini (11% accuracy). However, GPT-4o mini also had significantly biased responses, diminishing the representativeness of its accuracy. Results suggest that current vision models could serve as an interim solution for salt identification from their stain images.", "sections": [{"title": "Introduction", "content": "Whether it is forensics experts identifying residues at a crime scene or astronomers examining materials from other planets, the ability to rapidly identify salts from macroscopic images has significant implications for various fields (1, 2). Potential software could enable low-cost, equipment-free salt analysis, benefiting both specialized and general users.\nCurrent efforts are underway, and somewhat successful, in making such an ability a reality (3)\u2014but these methods are not immediately available, and it is unknown how long it will take for them to become viable for general or specialized use. Thus, a possible alternative method for identifying salts through these images is the target of investigation: using state-of-the-art large language models (LLMs) with vision capabilities. These models have demonstrated remarkable capabilities in transferring knowledge across domains and an impressive level of ability in identifying certain complex visual patterns without domain-specific fine-tuning (4), suggesting potential applicability to salt crystal morphology analysis.\nOpenAI's GPT-4o and GPT-4o-mini models represent current state-of-the-art capabilities in image recognition and analysis, with GPT-4o-mini being a lighter, cost-efficient variant of GPT-4o (4). For cost- and time-efficiency, the batch processing method offered by OpenAI was preferred, which allows for processing of multiple requests simultaneously with half the cost and greater granularity (5, 6). Most significantly, it allows control over parameters such as model type, temperature, and seed values, which can help produce outputs that are closer to being deterministic and reproducible, despite the inherently probabilistic nature of these models (7)."}, {"title": "", "content": "This study examines 12 salts (NaCl, KCl, NH4Cl, Na2SO4, K2SO4, NH4NO3, NaH2PO4, NaNO3, Na3PO4, KBr, KNO3, and RbCl) selected to represent a diverse range of ionic compounds, including both naturally occurring minerals and industrially significant compounds, to evaluate the accuracy and consistency of these models in salt identification. The findings reveal significant variations in identification accuracy across different salt types, with implications for practical applications."}, {"title": "Method", "content": "The GPT-4o and GPT-4o-mini models have a wide breadth of knowledge, but their knowledge is not deep enough to understand what the macroscopic images of salt deposits formed by the evaporation of droplets look like for each type of salt (4). Thus, training images for each type of salt are included for the model to understand their appearance, sourced from images of laboratory-generated salts from Dr. Steinbock's website, which were created for the related machine learning methods of identification (3, 8). These training images were the same for all trials."}, {"title": "", "content": "The OpenAI APIs were leveraged in order to specifically utilize the batch processing method, allowing for multiple requests simultaneously at lower pricing and with higher token limits compared to regular requests (5, 6). Using the API also ensures every request is independent (stateless), with no memory carrying over between requests (9). This also means the training images the model requires to grasp the differences between salts must be provided in every single request, significantly contributing to the token count and therefore the total cost."}, {"title": "", "content": "For batch processing, a JSONL file is required, in which every line contains a valid JSON object representing individual requests to the API. Each trial would require multiple batches due to file size and token limits per batch. In order to generate the batches, 12 folders containing the images of the salts were iterated over. For each salt type, an empty set would be created, which would keep track of already-seen images to avoid duplicate requests within the same trial. A total of 100 images would be randomly chosen from that folder to ensure an unbiased representation of each salt type's potential morphological variations, then added to the current batch as individual requests. In total, each trial contains 1200 requests (12 salts times 100 images), which were spread across as many batches as necessary.\nEach request had a few key parameters: the ID, which was determined by combining the image's name (a randomly generated and unique 9-digit number) and the name of the image's parent folder, allowing later identification of the image's true identity. Each request also contained the specific model name (either gpt-4o-mini-2024-07-18 or gpt-4o-2024-08-06), a temperature of 0, and a seed of 17 (chosen arbitrarily) in order to push the results closer to being deterministic (7). Each request also had the system prompt as shown below:\nYou are a helpful assistant who is knowledgeable about different types of salt crystals and can identify them from images. You can identify these 12 different salts: NaCl, KCl, NH4Cl, Na2SO4, K2SO4, NH4NO3, NaH2PO4, NaNO3, Na3PO4, KBr, KNO3, and RbCl.\nFor training, each request had 12 user messages passed in as context, each formed by 5 images and a line of text. Finally, a 13th user message would be included in the request, reading, \"Identify this salt with just the name.\" In other words, the models were trained using 12 sets of images labeled with their corresponding salt types, allowing the models to learn the visual characteristics of each salt.\nOnce all the JSONL files (batches) were created programmatically, they were then sent to be processed and receive a response from the specified model. For convenience and ease of use for non-experts, the web interface was used for batch processing (https://platform.openai.com/batches), though the underlying logic is the same as using the APIs. Initially, due to OpenAI's usage tier system, only one batch of a relatively smaller size could be done at a time, but at higher tiers it is possible to run multiple large batches simultaneously without hitting a rate limit.\nEach batch, once fully processed, outputs a JSONL file that contains the responses received for each of the requests within the batch. In order to analyze the data, the custom ID associated with each request is used to identify what salt the image is in actuality, and the model's response is also recorded. This is done by searching the response for the first mention of one of the 12 salts, which should be the only salt named in the concise outputs, due to the prompt."}, {"title": "Results", "content": "Agreements\nFirst, the results for all models were tested with each other for agreement using Cohen's Kappa. Cohen's Kappa is a statistical measure used to evaluate the level of agreement between two raters while accounting for the likelihood of agreement occurring by chance. (10). Cohen's Kappa values range from -1 to 1, with 1 representing perfect agreement and values close to and lower than 0 representing very poor agreement (11). Figure 2 displays the Cohen's Kappa values for comparisons between each of the four batch results.\nThe 4o-mini batch 1 and batch 2 trials, when compared to each other, had a kappa value of 0.91, signifying high consistency between the trials of the same model. This holds true for the full-sized 4o model as well, with its batch 1 and batch 2 trials achieving an even higher kappa value of 0.96.\nThe value of each kappa being below 1, meaning the trials of the same model do not display total agreement, is to be expected. Since the batches used different random sets of 100 images from the pool of 500 total images for each salt, each batch had slightly different testing images, meaning the model is expected to have different responses. Still, due to the overall similarity between images of the same salt, we can still apply Cohen's Kappa.\nWhen comparing the full-sized 4o and the 4o-mini models, however, the kappa values are near 0, indicating virtually no agreement across the models. Clearly, the two models are consistent throughout their own trials but have minimal agreement with each other's predictions when accounting for agreement by chance.\nAccuracies\nGiven the consistency within and disagreement between models, it is then crucial to know which model is more accurate. In terms of pure accuracy, the 4o full-sized model trials show significantly"}, {"title": "", "content": "better results, with 57.25% and 57.17% accuracy, respectively. Meanwhile, the 4o-mini model responses had a relatively low 11% and 10.09% accuracy, respectively. However, both the mini and full models had higher accuracy than the guessing accuracy would be given 12 salts (8%), though the mini model only exceeds that marker by a marginal amount."}, {"title": "", "content": "Looking closer at the responses from the first batch of the mini model, as can be seen in Figure 3, there is a clear bias towards Na3PO4 in the model's responses. In fact, the accuracies for every other salt are substantially lower, suggesting that the overall accuracy for the mini model is deceptively high due to its tendency to predict Na3PO4. This pattern is reconfirmed in Figure 4, as the second batch of the mini model's responses demonstrates a similar pattern, with approximately 55% of all its predictions being Na3PO4. This bias, which is not present in the full model results, suggests potential limitations in the model's visual learning capabilities compared to the 4o model."}, {"title": "", "content": "Comparatively, the first batch of the 4o full-sized model lacks this bias, showing much better results overall with multiple salts having 90%+ accuracy, even reaching 100% on NaH2PO4. However, the results are still uneven, as can be seen in Figure 5; in particular, KBr and KCl were very often misidentified as NaCl (98 and 99 times, respectively), leaving their individual accuracies at 2% and 1%. Clearly, there is massive confusion between these three salts for the model, alongside a bias towards NaCl. This may be due to the prevalence of NaCl in the model's original training data as one of the most common salts. Another major point of confusion was Na2SO4, as the model often misidentified multiple other salts (RbCl, K2SO4, and NH4Cl especially) as Na2SO4 instead."}, {"title": "", "content": "The second batch remains highly consistent with the first, as seen in Figure 6. This is further evidenced by the high Cohen's Kappa value and is in part due to the temperature of 0 applied to each request (7) along with the model's superior vision capabilities compared to its mini version. While there are slight differences numerically, these are to be expected due to differences in the randomly chosen testing images, and the overall patterns remain the same. The issues from the first batch are still prevalent in the second batch, alongside similar strengths, maintaining a 100% accuracy on NaH2PO4 and frequent confusions concerning NaCl."}, {"title": "F1 Scores", "content": "F1 scores, which provide a balanced measure of precision and recall, were also calculated for each salt type across all models. The macro F1 scores for each model differed slightly from the accuracies. To be exact, the mini model had 0.0522 and 0.0443 F1 scores across trials (compared to accuracies of 11% and 10.09%), while the full model had 0.5253 and 0.5263 F1 scores (compared to accuracies of 57.25% and 57.17%). All 12 classes of salts are equally represented in our provided"}, {"title": "", "content": "training data, but the difference between the F1 scores and the accuracy implies an imbalance in responses. This could be due to a similar imbalance in the original training data of the 4o and 4o-mini models stemming from the differences in the prevalence of certain salts, or simply difficulties in identifying certain salts in particular. This difference between accuracy and F1 scores is especially visible in the mini models, aligning with previous observations in the individual trial data."}, {"title": "", "content": "Figure 7 shows the F1 scores for each of the 12 salt types for all the trials. The full model is obviously more capable overall, but it shares a few weaknesses and strengths with the mini model. Firstly, the two most obvious weaknesses in the responses are KBr and KCl, both of which have extremely low F1 scores for both models. Clearly, there is heavy confusion concerning those salts.\nBeyond that, Figure 7 also elucidates other weaknesses of the models, such as K2SO4, NaCl, and RbCl; this could be attributed to class imbalance caused by prior knowledge the model has (especially for common salts like NaCl) or possible deficiencies in the training data. Many of the salts also appear similar on a macroscopic scale, making them difficult to discern and identify due to the variability in their possible forms."}, {"title": "Conclusions", "content": "In lieu of more reliable methods, large language models with vision capabilities are a possible method of identifying the original salt from an image of its evaporite. In testing, between the 4o-mini and full 4o models, the mini model performed drastically worse, proving to be ineffective even when considering cost and computing efficiency. For the full models, we see considerably higher"}, {"title": "", "content": "than random accuracy and F1 scores, indicating acceptable performance for initial testing; potential improvement can be found in the fine-tuning feature (13), leaving an opportunity for better results. In general, vision models excel at identifying common objects in images but struggle when it comes to learning from images to identify new things\u2014and, in particular, when it comes to images that require granular attention to detail and can often be homogeneous between classes (4). However, such confusion is not unexpected and can be improved on by allowing for greater attention to detail in models. Overall, the full GPT-4o model shows promising results for salt-evaporite analysis, allowing for quick picturing and identification of salts when provided with the appropriate training data."}]}