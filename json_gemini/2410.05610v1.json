{"title": "CHAIN-OF-THOUGHTS FOR MOLECULAR UNDERSTANDING", "authors": ["Yunhui Jang", "Jaehyung Kim", "Sungsoo Ahn"], "abstract": "The adaptation of large language models (LLMs) to chemistry has shown promising performance in molecular understanding tasks, such as generating a text description from a molecule. However, proper reasoning based on molecular structural information remains a significant challenge, e.g., even advanced LLMs such as GPT-40 struggle to identify functional groups which are crucial for inferring the molecular property of interest. To address this limitation, we propose STRUCTCOT, a structure-aware chain-of-thought (CoT) that enhances LLMs' understanding of molecular structures by explicitly injecting the key structural features of molecules. Moreover, we introduce two fine-tuning frameworks for adapting the existing LLMs to use our STRUCTCOT. Our experiments demonstrate that incorporating STRUCTCOT with our fine-tuning frameworks leads to consistent improvements in both molecular understanding tasks.", "sections": [{"title": "1 INTRODUCTION", "content": "Large language models (LLMs; Touvron et al., 2023; OpenAI & et al., 2024; Raffel et al., 2020) have demonstrated remarkable performance across various tasks. To leverage their strong capabilities in chemistry, several prior works (Edwards et al., 2022; Christofidellis et al., 2023a; Fang et al., 2024; Pei et al., 2023) have proposed chemical LLMs that have shown superior performance in molecular understanding tasks such as molecule captioning (Mol2Text) and text-based molecule generation (Text2Mol) (Edwards et al., 2022), which are crucial for designing new molecules.\nReasoning based on molecular structures plays an important role in molecular understanding tasks in practice. For example, chemists are likely to consider a molecule toxic if it contains a phenol group due to the formation of phenoxyl radicals and the compound's ability to interact with biological membranes (Hansch et al., 2000). However, despite its significance, there exists a lack of studies on the role of reasoning in LLM-based molecular understanding. In other domains such as arithmetic and commonsense reasoning, chain-of-thought (CoT; Wei et al., 2022; Kojima et al., 2022) has shown that explicitly incorporating such reasoning steps significantly improves the performance of LLMs. In detail, CoT aims to generate intermediate reasoning steps before arriving at a final answer.\nOne might consider the naive adaptation of CoT prompting to include molecular structural information in reasoning. However, we observe this to be ineffective because even state-of-the-art LLMs (OpenAI & et al., 2024; Touvron et al., 2023) struggle to capture the structural details of molecules, as described in Figure 1 and Section 3.2. This hinders their ability to perform reasoning effectively in molecular understanding tasks. While some prior works (Ouyang et al., 2024; Jin et al., 2024; M. Bran et al., 2024) have proposed CoTs for chemistry, they are either not applicable or exhibit limited performance in molecular understanding tasks.\nIn this paper, we propose STRUCTCOT, a chain-of-thought that progressively sketches the structural features of molecules to solve molecular understanding tasks. STRUCTCOT consists of six key structural elements, ranging from the primary structure to the smaller components. We propose to explicitly inject the appropriate structural information with STRUCTCOT to enhance the language models' understanding of molecules, which compensates for the lack of structural information."}, {"title": "2 RELATED WORK", "content": "Large language models for chemistry. General-purpose large language models (generalist LLMs) often struggle to solve basic chemistry problems and molecular understanding tasks (White et al., 2023; Castro Nascimento & Pimentel, 2023; Guo et al., 2023). To address this issue, prior works have introduced specialist LLMs, i.e., chemical LLMs, by pre-training models on molecule-related texts (Edwards et al., 2022; Christofidellis et al., 2023b; Liu et al., 2023a; Pei et al., 2023), through instruction tuning (Fang et al., 2024; Cao et al., 2023), and using retrieval-based in-context learning (Li et al., 2024a). Additionally, some works have improved LLMs by incorporating graph or 3D coordinate information (Liu et al., 2023b; Li et al., 2024b; Liu et al., 2024). Our work focuses on reasoning processes that are broadly applicable to these specialist LLMs as well as generalist LLMs.\nChain-of-thought reasoning. Chain-of-thought (CoT) aims to generate intermediate reasoning steps before arriving at a final answer (Wei et al., 2022; Kojima et al., 2022). CoT not only enhances the reasoning capabilities of LLMs but also improves the overall quality of generated answers. Most prior works generated CoTs via few-shot learning based on the manually written CoTs (Wei et al., 2022) or by prompting LLMs with \u201cLet's think step by step.\u201d (Kojima et al., 2022). In addition, several approaches have proposed to further enhance CoT, including techniques such as self-consistency (Wang et al., 2023), least-to-most prompting (Zhou et al., 2023), complexity-based prompting (Fu et al., 2023b), and self-polish (Xi et al., 2023). However, the ability to perform complex reasoning remains limited to extremely large language models (>100B parameters).\nTo address this challenge, various approaches have been introduced to distill knowledge from very large language models to smaller ones (<10B). Specifically, Ho et al. (2023); Fu et al. (2023a); Magister et al. (2023) employed the larger models as teacher models to generate CoTs for fine-tuning smaller student models. Nevertheless, even recent LLMs struggle to generate appropriate CoTs that demonstrate a correct understanding of molecular structures (as described in Figure 1 and Section 3.2), restricting the efficacy of LLMs in generating appropriate CoTs for molecular understanding tasks.\nChain-of-thought reasoning for chemistry. Recently, a few works have extended CoT reasoning to address chemistry-related problems. For instance, Ouyang et al. (2024) proposed to employ the program-of-thoughts (PoT; Chen et al., 2023) to handle chemical question-answering tasks. Additionally, Jin et al. (2024) presented the protein chain of thought (ProCoT) to replicate the signaling pathways in the context of the protein-protein interaction (PPI) problem. Despite these advances, none of these works target molecular understanding tasks such as molecule captioning and text-based molecule generation. We note that M. Bran et al. (2024) provided CoT comparable to ours, but their CoTs are less focused on molecule structural reasoning, e.g., they propose CoTs based on tools like LitSearch/WebSearch, PatentCheck, ReactionPlanner, and SMILES2Price. Moreover, it shows limited performance improvements in molecule understanding tasks as observed in Table 4."}, {"title": "3 STRUCTURE AS MILESTONES OF LLM-BASED CHEMICAL REASONING", "content": "In this section, we emphasize the importance of incorporating molecular structural information into the reasoning of LLMs for molecular understanding. We first outline key structural information essential for understanding the chemical and physical properties of a molecule, providing specific examples. Then, we show that even the state-of-the-art LLMs, such as GPT-40 (OpenAI & et al., 2024) and Llama3-8B-Instruct (Touvron et al., 2023), often fail to accurately infer crucial structural details from the molecule or the text description of the molecule. This observation implies that recent LLMs may struggle to implicitly reason these foundational structural elements when tackling molecular tasks, highlighting the potential benefits of explicitly integrating such information through a chain-of-thought approach.\n3.1 EXAMPLES OF IMPORTANT STRUCTURAL INFORMATION\nHumans typically analyze a molecule by progressively mapping its structure, starting with primary elements like rings and long carbon chains, and then identifying smaller components such as functional groups and chiral centers. Reflecting this approach, we identify six key elements of molecular structure that are critical for chemical reasoning. To highlight the importance of these structural elements, we demonstrate how even slight modifications in molecular structure can lead to significant changes in chemical or physical properties, as shown in Figure 3.\nMolecular formula. The molecular formula provides essential information about a molecule's composition, specifying the number and type of atoms present. This information is critical because, for example, it directly determines the molecular weight. To illustrate, although 2-Butanol (C4H10O) and 2-Propanol (C3H8O) are composed of the same type of atoms, i.e., carbon, hydrogen, and oxygen, their differing molecular formulas result in distinct molecular weights (74.1g/mol for 2-Butanol and 60.1g/mol for 2-Propanol). These differences lead to the change in boiling points, 99.4\u00b0C and 82.3\u00b0C, respectively, as shown in the gray part of Figure 3.\nLongest carbon chain. The longest carbon chain (excluding atoms in ring systems) forms the molecular backbone where functional groups are attached. The length of this chain significantly influences properties like solubility. For example, extending the carbon chain of 2-Butanol from four to six carbons creates 2-Hexanol, which exhibits reduced solubility. This is illustrated in the green section of Figure 3.\nAromatic rings. Aromatic rings, such as benzene or pyridine, play a critical role in determining the stability and electronic properties of molecules. For instance, adding a benzene ring to 2-Butanol yields 1-Phenyl-2-Propanol, which has enhanced stability and greater oxidation resistance. This transformation is shown in the blue section of Figure 3."}, {"title": "3.2 RECENT LARGE LANGUAGE MODELS DO NOT UNDERSTAND STRUCTURAL INFORMATION", "content": "Next, we demonstrate that even recent LLMs, i.e., GPT-40 (OpenAI & et al., 2024) and LlaMA3-8B-Instruct (Touvron et al., 2023), fail to infer important structural information from the given molecule and the text description of the molecule. We evaluate the LLMs by querying the structural information from the SMILES string (Weininger, 1988) and the text description, which can be considered as a simple task that could be solved by someone with a bachelor's degree in chemistry.\nAs shown in Figure 4, both GPT-40 and LlaMA3-8B-Instruct fail to capture the structural information accurately. First, when the SMILES string is provided, both models perform best in counting the number of aromatic rings, with accuracies around 50% and 75%, respectively. However, their accuracies are significantly lower for other structural information. This implies that LLMs cannot fully understand the molecular structures given the molecular string. We provide an example of a failure case in Figure 1.\nSimilarly, when the text description is given, both models also fail to achieve a high accuracy in inferring the structural information. This indicates that LLMs cannot properly understand the structure of molecules even when provided with the text description of molecules. These observation highlight the potential benefits of explicilty incorporating structural CoT to enhance molecular comprehension."}, {"title": "4 STRUCTCOT: STRUCTURE-AWARE COTS FOR MOLECULES", "content": "In this section, we describe our framework to enhance the capability of language models to perform reasoning using structure-aware CoTs of molecules (STRUCTCOT). Although our method is broadly applicable, we focus on two tasks commonly used to evaluate the ability of LLMs to understand chemical knowledge (Edwards et al., 2022). The first task is molecule captioning (Mol2Text), where the goal is to generate a text description from an input molecule's SMILES representation. The second task is text-based molecule generation (Text2Mol), where the LLM aims to generate a molecule that corresponds to a given textual description.\nWe incorporate our STRUCTCOT through a two-stage procedure of reasoning and answering. In the reasoning step, a reasoning module generates STRUCTCOT that will be used as additional structural information for understanding the molecule. Next, in the answering step, an answering module generates the answer from the input augmented with the generated CoTs. Note that we separate the two different architectures for each task since the reasoning module differs by the task: (1) one has access to the ground-truth reasoner for molecule captioning and (2) one needs to additionally fine-tune the reasoning module for improved reasoning capability for text-based molecule generation.\nThe rest of this section is organized as follows. First, in Section 4.1, we introduce STRUCTCOT, the structure-aware CoTs inspired by the significance of structural information explained in Section 3.1. Then, in Section 4.2 and Section 4.3, we present the fine-tuning process to incorporate the STRUCTCOT into both molecule captioning and text-based molecule generation tasks.\n4.1 STRUCTCOT\nWe introduce STRUCTCOT, a structure-aware CoT designed to enhance language models' understanding of molecular structures. Each component of STRUCTCOT follows the six important structural information introduced in Section 3.1 and illustrated in Figure 5.\nMolecular formula is expressed as \u201cThe molecular formula is $X_1 N_1\\cdots X_M N_M$.\u201d, where $X_m$ and $N_m$ represent the m-th atom type and the associated number of atoms, respectively.\nLength of the longest carbon chain takes the following form: \"The longest carbon chain length is N carbons long.\", where N denotes the length of the longest carbon chain of the molecule.\"\nNumber of aromatic rings takes the following form: \"The molecule contains X aromatic ring(s).\", where X denotes the number of aromatic rings in the molecule.\"\nTypes of ring compounds is expressed as \"It includes $N_1 X_1$ rings, \u2026\u2026\u2026, $N_M X_M$ ring(s).\", where $X_m, N_m$ represents the International Union of Pure Applied Chemistry (IUPAC) name of the ring compound and the number of the rings, respectively."}, {"title": "4.2 MOLECULE CAPTIONING", "content": "Molecule captioning aims to generate an accurate and detailed text description of a given molecular SMILES string. We incorporate our STRUCTCOT scheme through (1) using external tools like RDKit (Landrum et al., 2024) as a ground-truth reasoning module and (2) fine-tuning the answering module LLM with the generated CoT as an additional input. We provide the description in Figure 2a.\nReasoning module. One can obtain the true structural information of the given molecule from RDKit, which allows us to guide the answering module without uncertainty. This is natural as the structural information is deterministic given the molecule. Consequently, the obtained true structural information is used as STRUCTCOT. For this task, we consider the molecular weight CoT and IUPAC name CoTs (M. Bran et al., 2024) in addition to the CoTs described in Section 4.1.\nAnswering module. With the molecule and the acquired CoT as an input, we fine-tune the LLMs to generate the description of the molecule. In the experiments, we mainly consider chemical LLMs, i.e., MolT5 (Edwards et al., 2022) and ChemT5 (Christofidellis et al., 2023a), as the answering module."}, {"title": "4.3 TEXT-BASED MOLECULE GENERATION", "content": "Text-based molecule generation is the reverse process of molecule captioning, intending to generate the corresponding molecular string based on the given description. Following the two-stage framework that separates rationale generation and answer inference (Zhang et al., 2024), we first generate STRUCTCOT using the fine-tuned reasoning module and then attach this to the input and employ this as an input for the answering module. We provide the description in Figure 2b.\nNotably, we selectively use CoT elements in STRUCTCOT. This is because the reasoning modules need to generate CoTs of sufficient quality for the answering module, but this is not possible for some types of CoTs. Therefore, we evaluate the abilities of the reasoning module to correctly generate the CoTs and exclude those with low accuracy (presented in Table 2), specifically the molecular formula CoT and the two CoTs proposed by M. Bran et al. (2024).\nReasoning module. For the reasoning module, following Ho et al. (2023); Fu et al. (2023a); Magister et al. (2023), we enable CoT reasoning of the models by fine-tuning the reasoning module on the STRUCTCOT as the molecule is not given. This is in contrast to the molecule captioning task where the exact structural information can be extracted from external tools with the given molecule. We mainly fine-tune the chemical LLMs, i.e., MolT5 and ChemT5 for this module.\nAnswering module. For the answering module, similar to that of molecule captioning, we fine-tune a chemical LLM to generate an appropriate molecule given the text description and generated STRUCTCOT. Moreover, we propose the matching ratio-based rejection sampling, which forces the generated molecule to align with STRUCTCOT, as described in the following.\nThe proposed matching ratio-based rejection sampling aims to match the structural information of the generated molecule with the given STRUCTCOT. In detail, we generate multiple k molecules using beam search and then score each molecule based on the matching ratio, which counts the number of matching structural information elements between STRUCTCOT and the generated molecule. Finally, we choose the best-scoring molecule as the final output. This approach also leverages the deterministic nature of structural information, i.e., we can easily compare the alignment between each structural information and the generated molecule. Notably, this differs from the prior works with iterative approaches (Wang et al., 2023; Xi et al., 2023; Sun et al., 2024), as we focus on the alignment between CoT and generated answer without needing to generate multiple rationales."}, {"title": "5 EXPERIMENTS", "content": "In this section, we present our experiments on molecule captioning and text-based molecule generation tasks, including the experimental results, setting details, and ablation studies. We first explain the common settings shared by both tasks.\nDataset. Following prior works (Edwards et al., 2022; Christofidellis et al., 2023a), we employ the widely used CHEBI-20 dataset (Edwards et al., 2021), which consists of 33,010 pairs of molecular SMILES and their text descriptions. We also use the same train/validation/test split of 80%/10%/10%.\nBaselines. We verify the performance enhancement of STRUCTCOT in two settings: specialist and generalist models. On the one hand, we employed two popular specialist models, i.e., chemical LLMs: MolT5 (Edwards et al., 2022) and Text+CHem T5 (ChemT5; Christofidellis et al., 2023a). To validate the efficacy of our method across various model sizes, we used small (77M) and base (252M) for ChemT5 and base and large (800M) for MolT5. On the other hand, we employed two recent large language models: Llama3-8B-Instruct (Touvron et al., 2023) and GPT-40 (OpenAI & et al., 2024) as our generalist models.\n5.1 MOLECULE CAPTIONING\nExperimental setup and metrics. For specialist models, we follow the method proposed in Section 4.2. For generalists, we cannot guarantee that the generated descriptions align with those in our training data. Therefore, we apply few-shot learning by attaching CoTs in the same way as for the specialist models. Performance is evaluated by comparing the generated captions with the ground-truth captions using six metrics."}, {"title": "5.2 TEXT-BASED MOLECULE GENERATION", "content": "Experimental setup and metrics. We follow the fine-tuning framework proposed in Section 4.3. The performance is evaluated by comparing the generated molecules with the reference molecules using eight metrics: SMILES comparison metrics, fingerprint similarity metrics , a molecular distribution metric , and the validity of the generated molecule. Reasoning accuracy. We first measure the reasoning accuracy to filter out low-accuracy reasoning components that may misguide the answer module."}, {"title": "5.3 ABLATION STUDY", "content": "Comparison to ChemCrow. To validate the efficacy of our STRUCTCOT, we compare our method with ChemCrow (M. Bran et al., 2024), which has employed CoTs for various chemical tasks.\nMatching ratio-based rejection sampling. Here, we discuss the efficacy of matching ratio-based rejection sampling in the answer module of text-based molecule generation."}, {"title": "6 CONCLUSION", "content": "In this paper, we introduced STRUCTCOT, a structure-aware chain-of-thought framework that enhances language models' understanding of molecular structures by explicitly incorporating key structural features. Our analysis demonstrated that recent large language models struggle to accurately infer structural information from molecular representations like SMILES strings or textual descriptions, highlighting the need for explicit structural reasoning. By fine-tuning domain-specific specialist models with STRUCTCOT, we achieved consistent improvements in molecule captioning and text-based molecule generation tasks. This work underscores the effectiveness of small, domain-specific models in capturing molecular structures, and offers a solution for molecular reasoning."}, {"title": "A EXPERIMENTAL DETAILS", "content": "In this section, we provide the details of the experiments.\nA.1 STRUCTURE INFORMATION ANALYSIS\nHere, we describe the detailed settings for the analysis in Section 3.1. To evaluate the understanding of two recent LLMs: Llama3-8B-Instruct (Touvron et al., 2023) and GPT-40 (OpenAI & et al., 2024), we prompt the LLMs to infer the structural information from the given molecular SMILES string and text description of the molecule.\nPrompts given SMILES string. First, we asked LLMs to infer the structural information from the SMILES string, with the prompt described in Table 6."}, {"title": "A.2 MOLECULE CAPTIONING", "content": "Here, we describe the detailed settings for the experiments of molecule captioning in Section 5.1.\nHyperparameters. The hyperparameters for the specialist models are provided in Table 7. Note that MolT5-large was not trained for the same number of epochs as the other models due to limited time constraints.\nPrompts. The prompts used for the generalist models are described in Table 11. We primarily followed the prompt presented by Li et al. (2024a)."}, {"title": "A.3 TEXT-BASED MOLECULE GENERATION", "content": "Here, we described the detailed settings for the experiments of text-based molecule generation in Section 4.3.\nHyperparameters. The hyperparameters for the reasoning and answering module for the specialist models are provided in Table 9 and Table 10, respectively. Note that MolT5-large was not trained for the same number of epochs as the other models due to limited time constraints.\nPrompts. The prompts used for the generalist models are described in Table 8. We also primarily followed the prompt presented by Li et al. (2024a)."}, {"title": "A.4 ABLATION STUDY", "content": "Here, we describe the detailed settings for the ablation study.\nPrompts for ChemCrow. The prompts used for ChemCrow (M. Bran et al., 2024) are described in Table 12 and Table 13. Notably, it was not able to apply few-shot learning for ChemCrow as it was not applicable as the original prompt proposed in ChemCrow does not include any few-shot setting."}, {"title": "B ADDITIONAL EXPERIMENTAL RESULTS", "content": "In this section, we provide additional experimental results including several concrete examples of generated samples.\nB.1 MOLECULE CAPTIONING\nHere, we show the samples of molecule captioning, i.e., generated text descriptions of given molecules in Figure 9. Notably, we show the generated samples from base-sized models for fair comparison.\nB.2 TEXT-BASED MOLECULE GENERATION\nHere, we show the samples of text-based molecule generation, i.e., generated molecules for the given text description in Figure 10. Notably, we show the generated samples from base-sized models for fair comparison."}]}