{"title": "AN INTERPRETABLE X-RAY STYLE TRANSFER VIA TRAINABLE LOCAL LAPLACIAN FILTER", "authors": ["Dominik Eckert", "Ludwig Ritschl", "Christopher Syben", "Christian H\u00fcmmer", "Julia Wicklein", "Marcel Beister", "Steffen Kappler", "Sebastian Stober"], "abstract": "Radiologists have preferred visual impressions or 'styles' of X-ray images that are manually adjusted to their needs to support their diagnostic performance. In this work, we propose an automatic and interpretable X-ray style transfer by introducing a trainable version of the Local Laplacian Filter (LLF) [1]. From the shape of the LLF's optimized remap function, the characteristics of the style transfer can be inferred and reliability of the algorithm can be ensured. Moreover, we enable the LLF to capture complex X-ray style features by replacing the remap function with a Multi-Layer Perceptron (MLP) and adding a trainable normalization layer. We demonstrate the effectiveness of the proposed method by transforming unprocessed mammographic X-ray images into images that match the style of target mammograms and achieve a Structural Similarity Index (SSIM) of 0.94 compared to 0.82 of the baseline LLF style transfer method from [2].", "sections": [{"title": "1. INTRODUCTION", "content": "The human eye is unable to simultaneously perceive the entire spectrum of signals acquired by an X-ray detector. Consequently, the signal must be compressed in to a visible range of approximately 500-1000 shades of gray [3]. Inevitably, information is lost during this compression. At the same time crucial diagnostic information is often contained in subtle changes [4]. Due to the ambiguity of this complex task, various processing algorithms have emerged over time, each producing unique X-ray image impressions, also referred to as 'style'. In addition, radiologists have distinct preferences for X-ray image styles, shaped by their training, personal inclinations, and neurophysiological processes [4, 5]. Modifications to the X-ray image impression can affect their diagnostic process, as 60-80% of errors are attributed to perceptual mistakes [6]. Nonetheless, radiologists encounter variations in X-ray machines, equipment modifications, and improvements in image processing pipelines, continuously. This difficulty is mitigated by X-ray System Vendors, who manually adjust pipeline parameters, to align with the preferences of radiologists based on existing acquisitions with the preferred style.\nWe posit that, in the era of machine and deep learning, adapting an X-ray image style to a target image style can be automated. Various methods have been proposed to transfer the presentation of a medical image from one domain to another. The most prominent approaches for domain transfer in medical imaging are Generative Adversarial Network (GAN)-based methods [7, 8, 9] and diffusion models [10, 11]. However, manipulating X-ray image features can inadvertently remove diagnostic information or introduce artifacts, especially when complex Neural Networks (NNs) are involved, a scenario that might negatively impact clinical practice.\nA more reliable approach is offered by [2], who proposed a photographic style transfer method based on the LLF by [1]. The LLF is a powerful image processing algorithm used to enhance or diminish image structures according to their local contrast and continues to be utilized in recent studies [12, 13]. Its functionality is entirely governed by a Remapping Function (RM) $r(\\cdot) : \\mathbb{R} \\rightarrow \\mathbb{R}$. Consequently, the shape of $r(\\cdot)$ provides insights into the feature alterations performed by the LLF. [2] suggests employing the LLF for style transfer by determining $r(\\cdot)$ such that the LLF matches the gradient histograms of the input and target images.\nWhile this approach is promising, it should be noted that gradient histograms do not fully encapsulate the style of an X-ray image. This raises the question of how to capture and transfer the subtle details of X-ray image styles while maintaining interpretability and reliability. Instead of relying on handcrafted features like gradient histograms, we propose to let the feature manipulation for style transfer be learned by the LLF itself. To achieve this, we propose a trainable LLF, which can be optimized to transform input images to match a specific target style. Moreover, we propose to enhance the LLF to enable more complex and subtle style changes: We replace the RM $r(\\cdot)$ of the LLF, which is defined by only three parameters, with a more complex MLP $m(\\cdot) : \\mathbb{R} \\rightarrow \\mathbb{R}$. This MLP maintains the capability to map an input scalar to an output scalar, thus preserving interpretability, while also"}, {"title": "2. METHOD", "content": "The objective of this study is to devise an automated style transfer for X-ray images. To enable an interpretable and reliable operation of the processing algorithm in clinical practice, we propose a trainable and enhanced version of the LLF [1] fitting for style transfer on X-ray images. Fig. 1 illustrates the complete optimization pipeline, with each component described in the following sections."}, {"title": "2.1. LLF Algorithm", "content": "Since the LLF is central to our approach, we first provide an overview of its key aspects relevant to this work. For a detailed description of the LLF, refer to [1] and [2].\nThe LLF is a non-linear image processing algorithm that utilizes Gaussian and Laplacian pyramid decompositions. It facilitates the manipulation of image features based on their local context, i.e., differences to neighboring pixels.\nIn the LLF, the local context is aggregated by decomposing an input image $I$ into a Gaussian pyramid $G$, where the local context is represented by a value $G(p)$ at position $p$ in this pyramid. An output pixel $i'$ is then calculated from the respective input pixel $i$ by the following nonlinear function:\n$i' = r(d_p) + G(p),$\nwith $d_p = i-G(p)$ being the difference of $i$ to its local context $G(p)$. It is important to note that the Remapping Function (RM) $r(\\cdot) : \\mathbb{R} \\rightarrow \\mathbb{R}$ is the only adjustable component of the LLF and determines the behavior of the algorithm.\nThe original non-linear RM proposed by [1] comprises three parameters ($\\sigma$, $\\alpha$, and $\\beta$) to adjust the behavior of the"}, {"title": "2.2. Trainable LLF", "content": "To automatically adjust the LLF, we optimize its parameters using Stochastic Gradient Descent (SGD) and backpropagation. We implemented the LLF in PyTorch [14], which inherently supports automatic differentiation, following the algorithmic description of [1]. Additionally, we adopt the approach of [2] by implementing a Look-Up Table (LUT) to"}, {"title": "2.3. Enhanced Remap Function", "content": "The remap function introduced by [1] is effective but limited in shape flexibility due to its three parameters. Given the diverse nature of X-ray image styles, these parameters are insufficient to allow the LLF to effectively match target image styles. Consequently, we propose replacing $r(\\cdot)$ with an MLP, denoted as $m(\\cdot) : \\mathbb{R} \\rightarrow \\mathbb{R}$, which, like $r(\\cdot)$, operates on $d_p$, processing a scalar input to a scalar output. On the one hand, the functionality and reliability of the LLF are maintained, and its interpretability is preserved by examining the shape of the $m(\\cdot)$ for all possible values $i \\in [0, 1]$. On the other hand, this replacement enhances the flexibility of the RM's possible shapes and can be effectively optimized with backpropagation, making it a suitable component for the trainable LLF.\nThe MLP comprises six hidden linear layers, each employing Rectified Linear Unit (ReLU) activation [15] and batch normalization [16], except for the final layer. The number of neurons in the layers are 3, 12, 24, 24, 12, and 3, respectively."}, {"title": "2.4. Normalization Layer", "content": "Unprocessed X-ray images have a wide pixel value range, requiring the X-ray image pipeline to compress it to a smaller range for visibility of all structures simultaneously. The LLF, however, is not specifically designed for this task, as it manipulates only relative pixel differences. For this reason, we propose the addition of a trainable normalization layer at the output of the LLF to enable simple scaling and shifting of the pixel range. This normalization layer can be defined as:\n$I_{norm} = I_{LLF} \\gamma + \\omega,$\nwhere $\\gamma$ and $\\omega$ are the trainable parameters of the layer. With this addition, the X-ray LLF pipeline is now complete and can effectively adjust the immage scale and offset based on learned parameters, as illustrated in Fig. 1."}, {"title": "2.5. Datasets", "content": "To evaluate the LLF on X-ray images, we use the Malm\u00f6 Breast Tomosynthesis Screening Trial (MBTST) dataset, which contains mammograms from over 7325 patients. For LLF optimization, we use a subset of 145 images, with 130 for testing and 15 for optimization, as the small number of parameters in the LLF requires only a small training set. These images are preprocessed using a closed-source vendor pipeline to generate corresponding pairs of unprocessed raw projections and processed mammograms with a clinically relevant image impression."}, {"title": "2.6. Optimization", "content": "The complete optimization is depicted in Fig. 1. The processed data from Section 2.5 is used to optimize the LLF parameters. All optimization processes are conducted using the Adam optimizer [17] with a learning rate of 0.0001, and the LLF is trained for 300 epochs. As a loss function, we use a combination of Mean Squared Error (MSE) and Mean Structural Similarity Index (MSSIM) [18]:\n$\\mathcal{L}(I_{out}, I_{target}) = MSE(I_{out}, I_{target}) + \\frac{1}{MSSIM(I_{out}, I_{target})}.$\nWe empirically found that training with the MLP remap function converges faster if the MLP is preinitialized to depict an identity function. Therefore, before optimizing on the dataset, we optimize the MLP to approximate the identity function."}, {"title": "3. EXPERIMENTS & RESULTS", "content": "In this section, we evaluate our proposed method and compare it with the gradient histogram matching baseline method from [2]. We conduct four experiments, designed in accordance with the configurations outlined in Table 1. First, we demonstrate the feasibility of a differentiable LLF by training it with its original RM $r(\\cdot)$. Second, we explore the benefits of substituting $r(.)$ with a MLP. Third, we perform an ablation study to understand the impact of a NormL on the optimization process. The quantitative results of these experiments are summarized in Table 1, while Fig. 3 and Fig. 4 showcase visual results and the optimized RMs respectively.\nFig. 3 presents an image from the test set in its raw form, the target image with the target style, and the output images of the five different configurations of Table 1. Optimized LLFs with MLP (M Nand M-) process the input image to closely resemble the target. The results of the three parameter $r(.)$ and NormL (RN) closely resemble the target style. The trainable LLF with $r(.)$, but without NormL (R|-) creates a back-"}, {"title": "4. CONCLUSION", "content": "In this work, we demonstrated the trainable and enhanced LLF's ability to map raw X-ray images into specific medical styles, capturing intrinsic nuances. Despite using an MLP as the mapping function, the LLF stays interpretable and information preservation with constraints like monotonicity of the RM can be ensured. The differentiability of the LLF enables automated style mappings, and also opening new opportunities to utilize it as an operator within neural networks in future work. Given its proven effectiveness in complex mammographic transformations, we are confident in the LLF's versatility for other X-ray images and future work may explore the method's generalizability to other image types."}]}