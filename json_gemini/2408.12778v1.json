{"title": "Data-Centric Approach to Constrained Machine Learning: A Case Study on Conway's Game of Life", "authors": ["Anton Bibin", "Anton Dereventsov"], "abstract": "This paper focuses on a data-centric approach to machine learning\napplications in the context of Conway's Game of Life. Specifically,\nwe consider the task of training a minimal architecture network\nto learn the transition rules of Game of Life for a given number of\nsteps ahead, which is known to be challenging due to restrictions\non the allowed number of trainable parameters. An extensive quan-\ntitative analysis showcases the benefits of utilizing a strategically\ndesigned training dataset, with its advantages persisting regardless\nof other parameters of the learning configuration, such as network\ninitialization weights or optimization algorithm. Importantly, our\nfindings highlight the integral role of domain expert insights in\ncreating effective machine learning applications for constrained\nreal-world scenarios.", "sections": [{"title": "INTRODUCTION", "content": "In this work we consider the problem of learning the rules of Con-way's Game of Life, posed as an image-to-image translation task.\nSuch a setting is inspired by [57], where the authors investigate\nthe ability of neural networks to learn the rules of Conway's Game"}, {"title": "Conway's Game of Life", "content": "Conway's Game of Life, created by mathematician John Conway\nin 1970, is a two-dimensional cellular automaton where cells are\neither alive or dead. The evolution of the system is determined\nby rules based on the states of neighboring cells, as shown in Fig-ure 1. Despite its simplicity, it remains significant in mathematics\nand machine learning due to its inherent complexity and applica-tions [51, 52].\nThe Game of Life models how simple rules can produce complex\npatterns. This has led to studies on its mathematical properties\nand its use in developing neural networks to simulate and predict\nsystem evolution [4, 27, 29, 34].\nIn this work we explore the role of the training data on a task of\nlearning the multi-step Game of Life with the minimal conventional\narchitecture. Specifically, we use a convolutional neural network\n(CNN) to learn the rules of the game and predict the next state of\nthe board. Training on our custom-made board outperforms the\ntraditional paradigm in terms of accuracy and speed, and showcases\nthe advantage of a data-centric approach in constrained machine\nlearning applications."}, {"title": "Constrained Machine Learning", "content": "Machine learning has become essential in many fields, but tra-ditional methods often ignore constraints necessary for ethical,\nreliable, and safe decision-making. Constrained machine learn-ing integrates explicit constraints (either mathematical, logical,\nor rule-based) derived from domain knowledge, into the learning\nprocess [26, 48, 62].\nThis approach is crucial in areas like healthcare [5, 13, 43], au-tonomous vehicles [14, 24], finance [6, 10], and natural language\nprocessing [7, 61, 66].\nIt is important to note that incorporating additional constraints\ncan increase the implementation, training, and deployment com-plexity of machine learning models. But despite the potential chal-lenges, constrained machine learning offers a promising avenue\nfor improving the behavior and performance of machine learning\nmodels in critical real-life applications."}, {"title": "Data-Centric Machine Learning", "content": "Data-centric machine learning focuses on the quality, diversity, and\nrelevance of data rather than just model complexity and hyper-parameter tuning. High-quality and abundant data significantly\naffect model performance and generalization [38, 45]. Data-centric\nmachine learning finds application in numerous real-world sce-narios across various industries, including healthcare [18, 21, 63],\nfinance [30, 36], and environmental sciences [16, 35].\nChallenges include ensuring data quality and accessibility, han-dling imbalanced or noisy data, and addressing privacy and ethical\nconcerns [32, 53]. Domain expert insights are crucial for evaluating"}, {"title": "Related Work", "content": "We chose Game of Life as a challenging environment that is compli-cated for conventional machine learning algorithms to learn. Such\na setting is inspired by [57], where the authors investigated how\nnetwork overparameterization affects performance. In contrast, we\nonly consider the minimal network architectures.\nIn this work we only consider the classical discrete formulation\nof Game of Life, however numerous other generalizations have\nbeen proposed and studied, see e.g. [1, 3, 49].\nTraining networks of the smallest feasible architecture is consid-ered in [44], where the authors observe the inability of learning the\nparity function and fast Fourier transform with the minimal net-works. Research on the training of small networks is relevant, see\ne.g. [60] where the authors consider slim networks for deployment\non mobile devices. Additionally, small, or even minimal, networks\ncan be obtained by pruning, which is another prominent area of\nresearch, see e.g. [11].\nWe consider the setting of constrained machine learning, where\nthe main constraint is the size of the network. Depending on the\napplication, researchers are interested in other practical constraints,\nsuch as the scarce amount of data [15, 22], skewed distribution\nof historical data [9, 12], and other practical limitations [20, 59].\nDue to the restricted nature of our setting, we employ full-CNN\nnetworks to perform image-to-image translation. However, more\nsophisticated techniques are available if the condition of minimal\narchitecture is relaxed, see e.g. [31, 42, 46].\nOne of our main results demonstrates that even a single state\nobservation could be sufficient to learn the Game of Life. Similar\nfindings are presented in [41], where the authors achieve high per-formance in an image classification task by removing a significant\npart of the training data and only keeping the highest quality im-ages. The process of designing or creating training data itself is\nan actively developing area that has seen significant progress in\ndifferent areas of machine learning, see e.g. [2, 50]."}, {"title": "GAME OF LIFE AS A NEURAL NETWORK", "content": "In the Game of Life, the state of the board changes each turn, depend-ing on the current board configuration, according to the following\nrules:\n(1) Any live cell with fewer than two live neighbors dies, as if\nby underpopulation.\n(2) Any live cell with two or three live neighbors lives on to the\nnext generation.\n(3) Any live cell with more than three live neighbors dies, as if\nby overpopulation.\n(4) Any dead cell with exactly three live neighbors becomes a\nlive cell, as if by reproduction.\nFollowing the established convention, we represent a state of\nthe board in Game of Life by a grayscale image, see Figure 1, where\na pixel value of 1 indicates that the cell is alive and a value of 0\nindicates that the cell is dead. Thus at a time t > 0 the state is given"}, {"title": null, "content": "as a binary matrix $s_t \\in \\mathbb{R}^{M\\times N}$, where each value c e $s_t$ represents\nthe condition of a cell at time t with c = 1 indicating that the cell is\nalive and c = 0 indicating that the cell is dead. Therefore the Game of\nLife transition can be viewed as an operator $G : \\mathbb{R}^{M\\times N} \\rightarrow \\mathbb{R}^{M\\times N}$\nacting on the current state $s_t$ and outputting the next state $s_{t+1}$, i.e.\n$G(S_t) = S_{t+1}$."}, {"title": null, "content": "To establish a neural network representation of the operator G, note\nthat a single step $s_t\\rightarrow S_{t+1}$ of Game of Life consists of transforming\neach cell c\\rightarrow c' as\n$ c' = \\begin{cases}\n  1 & \\text{if the 3 x 3 patch centered at c}\\\\\n  & \\text{has at least 3 living cells and}\\\\\n  & \\text{c has at most 3 living neighbors,}\\\\\n  0 & \\text{otherwise.}\n\\end{cases} $  (1)\nTherefore in order to make a transition $s_t\\rightarrow S_{t+1}$, for each cell\nc one has to know two pieces of information: the condition of\nthe cell c itself and the conditions of the cells in the 3 x 3 patch\ncentered at cell c. A conventional architecture that can efficiently\nextract this information with just a few trainable parameters is the\nConvolutional Neural Network, see e.g. [25].\nIndeed, the Game of Life operator $G : \\mathbb{R}^{MXN} \\rightarrow \\mathbb{R}^{MXN}$ can\nbe represented as a 2-layer convolutional neural network with 23\ntrainable parameters, see Figure 2. Conceptually, the first layer\ncontains two 3 \u00d7 3 filters, extracting the information on the number\nof alive neighbors and the condition of the cell itself. This layer can\nbe followed by any reasonable activation function, so we consider\nReLU and Tanh - the most popular choices among practitioners.\nThe second layer combines these two features to make a prediction\non the cell condition on the next step. Unlike the first layer, the\nchoice of activation function here is more restrictive since the\noutput of G should only consist of 0 and 1, regardless of the input.\nAs such, we only consider the ReLU activation after the second\nlayer.\nBelow we provide two minimal configurations with conventional\narchitectures that are capable of capturing the transition rules (1).\nWe note that while it is technically possible to construct a smaller\nnetwork recreating the rules for Game of Life, it would require either\na use of residual connections, unconventional layer structures, or\nactivation functions, which is beyond the scope of the current work,\nand hence we only consider the fully-CNN architectures."}, {"title": "ReLU Activation", "content": "Consider a 2-layer convolutional neural network with the ReLU\nactivation after each layer:\n$ S_t\\xrightarrow[]{ReLU} 2 Conv2D (3 \\times 3) \\xrightarrow[]{ReLU} 1 Conv2D(1\\times1) S_{t+1}$"}, {"title": "Tanh Activation", "content": "Consider a 2-layer convolutional neural network with the Tanh\nactivation after the first layer:\n$ S_t\\xrightarrow[]{Tanh} 2 Conv2D(3 \\times 3) \\xrightarrow[]{ReLU} 1 Conv2D(1\\times1) S_{t+1}$"}, {"title": "Multi-step Game of Life", "content": "In order to evaluate the benefits of a data-centric approach in more\nchallenging scenarios, we consider the task of learning n-steps\nGame of Life, which becomes increasingly more complex with the\nincrease of the number of steps n. In this formulation, the training\ndata is given in the form of pairs (x, y), where y is the state x after\nn steps of the Game of Life. In this case the multi-step operator $G_n$\ncan be represented in either of the following ways:\n\u2022 1-step network, recursively fed into itself n times, which\nresults in a total of 23 trainable parameters, same as the\nsingle-step network, see Figure 3;\n\u2022 n instances of the 1-step network connected sequentially,\nwhich results in a total of 23n trainable parameters, see Fig-\nure 4.\nIn our numerical experiments we consider both options. We also\nnote that in this paper we only consider 1- and 2-step formulations\nof Game of Life learning, since for n \u2265 3 none of the learning\nconfigurations managed to learn the environment regardless of the\nchoices of initialization weight, optimization algorithm, and hyper-parameters. This is due to the constrained nature of our setting as\nwe are only considering networks of minimal architecture."}, {"title": "TRAINING DATA DESIGN", "content": "A state in Game of Life is represented by a board - a 2-dimensional\nbinary matrix where a value of 0/1 represents a dead/alive cell\nrespectively - and a training set is given as a collection of boards.\nWhen constructing a training set, one has to decide on the number\nof training boards, size of each board, and an average board density\nthe percentage of alive cells on the board. Below we explain the\nchoice of these parameters for each of two datasets we use in this\npaper: the \"random\" dataset and the \"fixed\" dataset.\nA conventional way of obtaining training data for a classifica-tion task typically involves generating a sufficiently large number\nof pairs (x, y) via the methods appropriate for the current sce-nario [53]. In the case of n-step Game of Life, x represents the input\nboard and y represents the corresponding output board same state\nafter n steps. In practice, such a dataset can be obtained by fixing\nsome initial states and computing the corresponding outputs."}, {"title": "Random Dataset", "content": "While there are multiple viable choices for each of these parameters,\nin the interest of being consistent with the existing literature, we\nreplicate the data collection choices employed in [57]. Specifically,\nwe implement a data generator to randomly sample boards with\nan average density of 38%, as such a density minimizes the distri-bution shift between the inputs and outputs, see Figure 5, and also\nmaximizes the learning success rate, see [57, Section 3.4]."}, {"title": "Fixed Dataset", "content": "A comprehensive answer on the most appropriate training dataset\ndesign is highly application-specific and is yet to be found in gen-eral. In the context of Game of Life, the main challenges are the\nredundancy of the patterns in random board that dilute the knowl-edge and the undecidability of the state dynamics. To address these\nchallenges, we utilize two main concepts in the process of board\nconstruction: symmetry and meaningful diversity of patterns.\nAs it follows from the rules (1), in order to make a prediction on\nthe condition of the current state, one does not have to distinguish\nthe neighboring cells; thus, one can deduce that the filters of the\nfirst layer should be symmetric about the center. However, it is\nnon-trivial to achieve symmetry of the filters by utilizing a ran-domly sampled dataset. To endorse the symmetric structure of the\nconvolutional filters, we make our board symmetric by performing\nhorizontal and vertical reflections. Such an arrangement essentially\nmeans that each 3 \u00d7 3 patch is seen by the network 4 times with\ndifferent orientations, thus promoting symmetry of the filters.\nIt is evident that the training data must contain a variety of 3 \u00d73\npatches from which the rules (1) can be learned. While considering\nevery possible 3 \u00d7 3 patch is hardly feasible, as it results in $2^9$ = 512\ndifferent configurations, it is also not necessary, as most of them\nare redundant due to the indistinguishability of the neighbors and\nthe symmetry of the filters. As such, one can prioritize putting the\nmore important patterns in the training board and thereby avoid\nexcessive redundancy, which is the approach we pursue. Some of\nthe patterns we use are presented in Figure 8.\nTo accommodate the above concepts, we first construct a 32 \u00d7 32\nboard that contains the critical patterns, and then reflect it hori-zontally and vertically to harness the power of symmetry, which"}, {"title": "NUMERICAL EXPERIMENTS", "content": "Our experiments are performed in Python 3.8 on a personal laptop.\nTraining of all the neural networks is done with TensorFlow 2.12.\nThe source code reproducing the presented experiments is available\nat https://github.com/sukiboo/game_of_life.\nIn this section we provide an extensive quantitative analysis to\nshowcase the advantage of a data-centric approach. To this end, we\nemploy all available optimization methods currently implemented\nin Tensorflow 2.12. Specifically, we deploy the following opti-mization algorithms: Adadelta [64], Adafactor [56], Adagrad [19],\nAdam and Adamax [33], AdamW [37], Ftrl [39], Nadam [17], RMSprop [28],\nand SGD with momentum [58]. The details for each algorithm and\nthe exact values of the hyperparameters are given in Appendix."}, {"title": "Discussion", "content": "We note that the advantage of designing a fixed training board is\nnot necessarily evident in the 1-step prediction setting, and in some\ncases results in slower convergence. We hypothesize that this is\ndue to the relative simplicity of the environment, where even the\nconventional approaches perform well. However, considering the\n2-step prediction settings is where one observes the benefits of\nusing custom designed training data, as is apparent from Figures 10,\n11 and Tables 2, 3. Overall, our results highlight the importance of\na data-centric approach on challenging tasks where conventional\napproaches struggle to achieve satisfactory performance."}, {"title": "CONCLUSION", "content": "In this work we study the importance of training data for the effi-ciency of machine learning algorithms in constrained environments,\nrepresented by the multi-step Game of Life prediction tasks. We ob-serve the advantage of a data-centric approach over its conventional\ncounterpart, which becomes especially evident in more challenging\nenvironments.\nSpecifically, we demonstrate that training on a single strategi-cally designed data point can be more beneficial than 10,000 gener-ated data points in terms of both convergence and efficiency. Our\nfindings highlight the essential role of data design in constrained\nmachine learning, necessitating a collaborative approach between\nML practitioners and domain experts for successful real-world ap-plications."}, {"title": "Limitations and Future Research", "content": "In this paper we focus on learning the Game of Life in the min-imal architecture, which posses certain limitations. In particular,\nwe were unable to learn a single instance of n-step Game of Life\nfor n \u2265 3, which is likely due to the unpredictability of the state\ndynamics given by the rules (1). Exploring ways to overcome this\nlimitation without sacrificing the minimality is one of the natural\nfuture research directions.\nWhile the presented numerical experiments are performed only\non the backpropagation algorithms, we observe the similar behav-ior on the genetic algorithms [55] and the family of the blackbox\noptimization algorithms based on Gaussian smoothing [67]. For the\nconsistency of presentation we do not report these results in the\ncurrent work.\nWe consider the canonical formulation of Conway's Game of\nLife to act as a benchmarking environment. It would be of interest\nto replicate our findings on other versions or generalizations, or\nother cellular automaton games, e.g. [47]."}, {"title": "HYPERPARAMETER SEARCH", "content": "For each algorithm and environment we perform an extensive\nhyperparameter search to find the appropriate value of the learning\nrate \u03bb. Specifically, we perform an exhaustive grid search over the\nvalues\n\u03bb\u03b5 {1e-1, 3e-2, 1-2, 3e-3, 1e-3, 3e-4, 1e-4}\nby running 100 tests and measuring their corresponding conver-gence rates. In the case of a tie, the smaller learning rate was used.\nWe note that, since the random dataset generation is seedable, the\nhyperparameter search is performed on exactly the same datasets\nthat the algorithms are evaluated on. The results of all tests are\nprovided in Figures 12-17. The value of the learning rate A providing\nthe highest convergence rate is selected for each algorithm/environment\npair, see Tables 4, 5, and 6, where the entry \"--\" indicates the ab-sence of successful simulations for any of the values of \u03bb."}]}