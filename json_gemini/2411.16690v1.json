{"title": "Benefits and Risks of Using ChatGPT as a Support Tool for Teaching in Computer Science", "authors": ["Yaiza Aragon\u00e9s-Soria", "Julia Kotovich", "Chitsutha Soomlek", "Manuel Oriol"], "abstract": "Upon release, ChatGPT3.5 shocked the software engineering community by its ability to generate answers to specialized questions about coding. Immediately, many educators wondered if it was possible to use the chatbot as a support tool that helps students answer their programming questions.\nThis article evaluates this possibility at three levels: fundamental Computer Science knowledge (basic algorithms and data structures), core competency (design patterns), and advanced knowledge (quantum computing). In each case, we ask normalized questions several times to ChatGPT3.5, then look at the correctness of answers, and finally check if this creates issues.\nThe main result is that the performances of ChatGPT3.5 degrades drastically as the specialization of the domain increases: for basic algorithms it returns answers that are almost always correct, for design patterns the generated code contains many code smells and is generally of low quality, but it is still sometimes able to fix it (if asked), and for quantum computing it is often blatantly wrong.", "sections": [{"title": "1. Introduction", "content": "Answering questions, writing emails and essays, creating poems, composing music or solving math problems are only some tasks that chatbots such as Chat Generative Pretrained Transformer (ChatGPT) can perform. This new technology promises to change our society, especially in education and research (Murugesan and Cherukuri, 2023; Eke, 2023; Yilmaz and Karaoglan Yilmaz, 2023; Lim et al., 2023). Both fields need to adapt to the existence of chatbots, such that they do not become a threatening tool but a support for sharing knowledge. The first step for adaptation is to recognise that the change is happening and gather knowledge about its strengths and limitations to take advantage of it. It is important that the education and scientific communities become aware of the capabilities of Generative AI.\nSince the appearance of ChatGPT, the most famous chatbot to date, several studies have tested its capabilities. Wang (2023) shows that ChatGPT exhibits satisfactory performance when asked formulaic physics problems, which required assuming relevant parameters and writing correct code. Its calculation ability and capacity to answer conceptual questions are however limited.\nThis article explores the benefits and risks of using ChatGPT as a support tool for teaching in the context of computer science (CS). The study considers three categories: fundamental knowledge (taught to first-year students in computer science), core competency (taught to students finishing a three-year bachelor in computer science), and advanced topics (only taught at the masters level) in computing-related curriculum. The approach is to take one course in each category and evaluate how well ChatGPT is answering requests. Questions at each level are asked several times to observe the variation in answers. Answers are then categorized as correct (complete and accurate), incomplete (true but lacking some information), or incorrect (containing false information).\nThe evaluation of fundamental knowledge is a continuation of the work from Kotovich and Oriol (2023), which showed that ChatGPT is answering correctly simple coding assignments. The rest of the article is brand new.\nFor core competency, the reliability, benefits, and risks of using ChatGPT to support students on design patterns, anti-patterns, code quality, and soft-"}, {"title": "2. Research Methodology", "content": "This section outlines the general methodology to evaluate the performances of ChatGPT. Each subsequent section provides further details of the specific methodology at each level: fundamental knowledge, core competency, and advanced topics.\nWe first select standard questions for each level, we then ask ChatGPT version 3.5 each question three times. Although ChatGPT tends to repeat some sentences, it never gives the exact same answer. In case an answer, or part of it, is unclear, we ask ChatGPT for a clarification in the same conversation.\nAll answers are evaluated and classified individually according to the following categories:\n\u2022 correct answer - when all information given by ChatGPT is true and complete,\n\u2022 incomplete answer - when all information given by ChatGPT is true but incomplete,"}, {"title": "3. Fundamental Knowledge in Computer Science", "content": "Sorting algorithms and data structures are fundamental concepts that all developers should understand and be able to implement. With the appearance of ChatGPT, one may argue that memorizing the specific code to implement these algorithms or data structures is no longer essential. Instead, developers could rely on ChatGPT as a supporting tool to generate the desired code snippet. This section, evaluates if this scenario is realistic and determines whether students and developers can rely on ChatGPT's abilities to code sorting algorithms and data structures."}, {"title": "3.1. Experiment", "content": "The experimenter asks ChatGPT to generate a Python piece of code for a concrete sorting algorithm or data structure. We chose Python as a target language because it is taught at many school and universitiess. Python is also the most popular general-purpose programming language on Stack Overflow (2021).\nThe algorithms selected for the test correspond to the most used data structure and sorting algorithms presented on Rodwell (2023), which appears as the first result on a Google search that describes \u201calgorithms complexity\" with a complete list of algorithms (January 2023). In that list, there are 13 sorting algorithms and 13 data structures (see Table 1).\nFor each data structure and algorithm (except the Array type, which is a base type in Python), ChatGPT is asked to create an implementation in Python using the question \"write a python code for X\u201d (for example \"write a python code for Bubble Sort\"). For each piece of code, ChatGPT provides a code snippet and a short comment such as \u201cThis code sorts an input array 'arr' using the bubble sort algorithm. The algorithm compares each pair of adjacent elements and swaps them in they are if the wrong order. This process is repeated until the array is sorted in ascending order.\u201d\nThe resulting (generated) code is copied to an integrated development environment (IDE) to check if it has any errors. In case the code can be built and run without an error, the answer is considered correct. If there are small and easy-to-fix errors, the answer is incomplete. The answer is incorrect when it contains major errors or the code does not align with the algorithm used in the question. The percentages in Table 1 are calculated by repeating each question three times."}, {"title": "3.2. Results", "content": "In 82% of the cases, the code generated by ChatGPT is correct. In 18% of the cases it is incomplete. It is never incorrect (see Table 1). The results confirm that ChatGPT can assist students in producing the correct code for the selected data structures and algorithms. Further to these results, ChatGPT can be used as a tutor that explains algorithms (see Figure 2).\nFor instructors, data structure and algorithms are the pre-requisite and important fundamental knowledge for both basic and more sophisticated programming problems. If students do not code the algorithm themselves, as with any high-level explanations, answers from ChatGPT might create a false sense of understanding that is not validated by a practical implementation."}, {"title": "3.3. Limitations and Threats to Validity", "content": "The question considered in this section is whether ChatGPT is reliable as a support tool for computer science education and research to acquire and validate fundamental knowledge of Computer Science. We conclude that ChatGPT is indeed a useful support tool at this level giving a correct answer in a high probability."}, {"title": "4. Core Competency in Computer Science", "content": "To develop a high quality software system that meets industrial needs, one must master software design concepts, design patterns, anti-patterns, and software quality. The Association for Computing Machinery (ACM) even suggests software design problems, implementation, design software tests, debugging, refactoring an industry computer program, and analysis of trade-offs (e.g., maintainability, efficiency, intellectual property constraints, usability, correctness, graceful failure, efficiency, etc.) as core competencies in curricula recommendations for global computing education and other computing-related disciplines (Clear et al., 2019; Gal-Ezer et al., 2020). This section explores how ChatGPT can help with such topics by looking at various design patterns and evaluating the quality of the produced solutions.\nA design pattern is a repeatable design solution to a problem and is comprised of a pattern name, a problem, solutions, and consequences (Gamma et al., 1995; Freeman et al., 2004). A design pattern is a reusable design template for a common problem found when designing a software. Anti-patterns and code smells are the opposite (Fowler et al., 1999; Fowler, 2018; Martin, 2008). They are the solutions that one should avoid. Students need to practice thoroughly to be able to analyze and choose a suitable design pattern for a programming problem, and to identify potential design issues. A tool such as ChatGPT could be very beneficial to help students reach proficiency."}, {"title": "4.1. Experiment", "content": "The experiments consist in the workflow presented in Figure 3. The intent is to mimic the approach that a student would take when using ChatGPT. The experiment then evaluates whether ChatGPT is a reliable support tool when it is asked to generate a piece of code for a particular design pattern, find design and implementation flaws (i.e., code smells, violations of design concepts, best practice violations, and maintainability issues) in the generated code, refactor the code, and write a unit test for the code.\nFigure 3 illustrates the flow of the questioning process. The experimenter starts by asking ChatGPT to implement a selected design pattern in the Java programming language for a computer programming problem. Then, she asks ChatGPT to find code smells in the code. If a flaw is found, she then asks ChatGPT to refactor the code. After that, ChatGPT is asked if there are any other code smells in the refactored code."}, {"title": "4.2. Results", "content": "At first, the experimenter checks if the generated code matches to the specified pattern, by comparing the design diagram of the code and the structure of the code to the design pattern, and by examining the implementation. Then, she checks if the code can run by creating a Java project in IntelliJ IDEA with initial setup. If the code cannot run, she examines the errors. When the errors require minimal configuration and changes, e.g., setting class path and importing libraries and packages, are needed, the experimenter configures and changes the code accordingly to explore if the code can run. In case there are further errors, i.e., build errors and run-time errors, then there is no further change to the code. For the generated code, refactored code, and test code, we calculated the percentages of Java code that is ready-to-use, requires minimal changes before it can run, or can not run at all after the configuration and changes have been made. Table 2 shows the results.\nThe experimental results confirm that the generated code, refactored code, and test code are not ready to use. The major reason is that ChatGPT always writes everything in one single file. When writing a Java program, it is important to separate Java classes into files with names matching the class name, especially when the class is public. Note that it is possible to have multiple classes in a Java file. A package in Java is commonly used to organize the related classes. These are the parts of Java specific best practices since each class can be executed separately to confirm their functionalities"}, {"title": "4.3. Limitations and Threats to Validity", "content": "ChatGPT 3.5 architecture is not the only representative of a Generative AI. As mentioned previously experiments could use ChatGPT4 and result in different results. In addition, other large language models and Generative AI specifically trained to support coding and code completion, e.g., Replit Ghostwriter (Replit, 2023), GitHub Copilot (GitHub, Inc, 2023), Hugging Face (Hugging Face, 2023), tabnine (Tabnine, 2023), etc., that were not evaluated in this research. One could adopt our research methodology and series of questions for further evaluations on those tools to obtain additional results.\nThere is no one single solution in programming. One programming problem can be solved by many solutions. In addition, when considering the quality of a software or the quality of a source code, the result depends on subjective evaluation. For example, if maintainability is one of the key quality attributes needed for a software project, it is important to be clear on what quality metrics should be measured and the decision criteria to be used.\nThe same idea is applied to grading student works. Each instructor defines grading criteria for an assignment. This research defines criteria to evaluate correct, incomplete, and incorrect results. When the definitions and the criteria are different, the evaluation results also indicate otherwise. There are still subjectivity issues involved. Therefore, the experiment does not compare the quality of the generated code, refactored code, and test code with the results from other tools. The experiments analyzed the generated code and measured a wide range of software metrics to demonstrate that the responses from ChatGPT is not an out-of-the-box solution.\nThe formulated series of questions might not cover all of the use cases. There are other areas of competencies in computing-related education that are not"}, {"title": "5. Advanced Topics in Computer Science", "content": "Advanced topics in computer Science are somewhat uneasy to define. In many cases, they require the use of advanced theoretical notations and specialized knowledge. For example, formal methods, static analysis, software architecture, cryptography, symbolic artificial intelligence, parallel and distributed computing, quantum informatics all contain some parts with much theoretical background. All these courses are part of the curriculum of the Masters in Computer Science, Software Engineering, and Leadership from Constructor Institute.\nIn this study, we picked the topic that is the most difficult to tackle for our master students: quantum computing. Using principles from computer science, physics, and mathematics, quantum computing is an interdisciplinary domain that harnesses quantum mechanics to efficiently solve intricate problems. Several software tools have already been developed for quantum computing, such as Qiskit (IBM Research, 2023) by IBM Research, Silq (ETH Zurich, 2023) by ETH Z\u00fcrich, or Cirq (Google Quantum AI, 2023) by by Google AI Quantum Team. This section examines the potential of ChatGPT as a tool for supporting research and education in quantum computing, an advanced topic in computer science."}, {"title": "5.1. Experiment", "content": "To evaluate if ChatGPT is reliable when asked about quantum computing, the experimenter asks simple questions about quantum gates and analyses the answers given by ChatGPT. The gates considered consist of the identity gate, all one-qubit gates, and all two-qubit gates mentioned as common by Wikipedia (Wikipedia contributors, 2023). For each of these quantum gates, the experimenter asks ChatGPT three elements:\n1. a definition of the gate,\n2. a circuit representation, and\n3. the final state after applying the quantum gate to a given initial state."}, {"title": "5.2. Results", "content": "As described in Section 2, the experiment computes the percentages of correct answers, incomplete answers and an incorrect answers. In practice, the experiment considers independently each question element - definition, circuit, final state."}, {"title": "5.3. Limitations and threats to validity", "content": "In the evaluation of ChatGPT as a support tool for research and education in quantum computing, ChatGPT returns more often a correct answer when asked for the definition of a quantum gate than for the circuit or the final state. The percentages of correct answers for the definition is only 84%. This means that ChatGPT cannot be a main tool for research and education in quantum computing. At best, we can only imagine it as a test generation tool to find potentially incorrect answers for students to fix.\nSeveral questions remain open. Would ChatGPT become a reliable support tool for teaching and research in quantum computing if it had access to logic? In March 2023, a plugin for ChatGPT that connects it with WolframAlpha was released (WolframAlpha, 2023). This plugin provides ChatGPT4 access to the well-known Wolfram Language, and promises that using this plugin ChatGPT4 can do nontrivial computations as well as systematically produce correct data. Since all computations evaluated ChatGPT3.5 can be done using matrix multiplications, it would be promising to repeat our evaluation using the WolframAlpha plugin. A preliminary research shows that ChatGPT4 gives more often a correct answer than ChatGPT3.5 for one-qubit quantum gates, while results seem similar for two-qubit quantum gates and concatenations of gates. Further research should be performed to confirm it.\nThis study uses the quantum computing model based on quantum gates, but there exists others such as one-way quantum computers or adiabatic quantum computers. Would ChatGPT perform better if we considered another model of quantum computing? Further research should also be performed to answer that question."}, {"title": "6. Implications for Education in Computer Science", "content": "After working extensively on these topics, we believe that our work has several implications for the near future:\n\u2022 Regarding the quality of student education: simple questions can be answered automatically by ChatGPT and, by extension, other conversational agents. Such agents can, already now, be considered as a good way to help first year students self-check and get started. The use of such tools, could then be encouraged as they give an answer faster than a teaching assistant. The discussion whether it is better for students to"}, {"title": "6.1. Teaching Sequence to find Limitations of Conversational Agents", "content": "This section presents the teaching sequence that allows students to find limitations of conversational agents.\nThe exercices are presented below:\nThese exercises aim at making students aware of the strength and weaknesses of conversational agents as helpers for programming tasks\nQuestion 1: Use a conversational agent to obtain an implementation of a binary search tree in Java.\nExpected answer: a program that someone can copy/paste and arrange in the proper files to compile. The program will work.\nQuestion 2: Can you compile the result?\nFor students who do not have the JDK installed, time will be spent installing and finding out how to install components. The program will be able to compile and run.\nQuestion 3: Use a conversational agent to create test cases with a unit test framework for the binary search tree."}, {"title": "6.2. Example of Assignments that Further the Students' Understanding", "content": "In this section we ask the student to use usual mistakes by students to fool ChatGPT. We believe that this experience can enhance the students' understanding about the limitations of ChatGPT. A possible exercise could be the following.\nExample: What is the most common mistake that programmers do when trying to exchange variables? Can you make ChatGPT generate the wrong explanation? Explain why the answer generated by ChatGPT is wrong.\nGenerating such examples is surprisingly easy. Here are a few statements that can be falsified easily by ChatGPT:\n\u2022 What is this doing: int a, b; a=b, b=a? (answer is wrong because of assignment erasing the other value, see Fig. 10)\n\u2022 int a; is a*a positive? (answer is wrong because of overflows)\n\u2022 int a,b; is (a*b)/b equal to a? (answer is wrong because of overflows)\n\u2022 paste some code that shows the diamond problem in C++, and remove the main function. Ask if this compiles. (ChatGPT says no, but if there is no use of the code, it compiles)\nStudents trying to fault ChatGPT will learn more about its limitations, and the finesse of the problem at hand than if the questions are simple to answer."}, {"title": "7. Related Work", "content": "Bots are becoming available to software engineers willing to improve their productivity (Erlenhov et al., 2019; Santhanam et al., 2022). For example, Carr et al. (2017) created a bot that inserts automatically proven contracts in source code, Tian et al. (2017) made a chat bot that answers questions about APIs, Bradley et al. (2018) made a development assistant able to understand commands for Git and GitHub tasks. Finnie-Ansley et al. (2022) evaluated the results from Codex in programming CS1 tests and even solving a Rainfall Problem. In 2021, GitHub Copilot was introduced as an AI programming assistant that can suggest code completion. Vaithilingam et al. (2022) showed that despite the average results in terms of time and correctness of the generated code, it is at least a good starting point to approach"}, {"title": "8. Conclusions", "content": "Some tools suddenly open possibilities that we thought would never be reality. ChatGPT is one of these tools. It suddenly sparked a very strong interest and captured the imagination of many. Is it interesting? Yes! Is it the silver bullet that it appears to be at first? No yet!\nThe present article evaluates the performance of ChatGPT as a support tool for teaching topics related to the computer science curriculum. It evaluates the answers of ChatGPT at three levels: fundamental (first-year students), core (finishing bachelor students), and advanced (master-level students). For fundamental knowledge, the evaluation focuses on answers about standard algorithms and data structures. For core knowledge, it explores the answers on design patterns. For advanced knowledge, it studies answers on one and two qubits gates in quantum computing.\nThe main result of this study is that the output of ChatGPT contains more errors as the questions target more advanced topics: it answers fundamental questions almost perfectly, it answers questions about design patterns mostly correctly even if it contains code smells and generally poor quality code, it has generally poor performances on quantum computing. The most concerning in this is that it always answers questions with the highest level of certainty, even when it is completely wrong.\nWe have no doubts that ChatGPT will improve in the future (and we will undoubtedly reevaluate further tools and further versions of the tools). For the time being, however, we believe that students can use ChatGPT for their studies, but they need to be warned. Even if, at first, they can use it for basic requests, as they progress in their curriculum, they will need to question its answers because they will contain more and more incorrect statements."}, {"title": "Appendix A. Quantum gates", "content": "In Section 5, we have tested ChatGPT capabilities concerning quantum computing. In concrete, we have considered common quantum gates and asked for their definition, circuit representation and application on a given quantum state. This section contains the theoretical background behind the questions.\nBelow, we use the computational basis denoted by $\\{|0\\rangle,|1\\}\\}$, and corresponding tensor products for higher dimensions. We refer to one- and two-qubit arbitrary quantum states as $|\\psi\\rangle$, which can be expanded in the corresponding computational basis as\n$|\\psi\\rangle = \\frac{1}{\\sqrt{N}}(a|0\\rangle+b|1\\rangle)$,                                                                                                                  (A.1)\n$|\\psi\\rangle = \\frac{1}{\\sqrt{N}}(a|00\\rangle + b|01\\rangle + c |10\\rangle +d|11\\rangle)$,                                                 (A.2)\nrespectively. Here, $a, b, c, d$ are complex numbers, and $N$ is the normalization factor satisfying that $|\\langle \\psi|\\psi \\rangle|$.\nThe most simple, but essential quantum gate is the so-called Identity. The Identity gate, $I$, is a one-qubit gate that does not affect the input state. Mathematically,\n$I |\\psi\\rangle = |\\psi\\rangle \\forall |\\psi\\rangle$.\nThe circuit representation of the Identity gate, as well as the upcoming gates, can be found in Table A.7.\nThe Pauli X, $X$, also known as bit-flip gate, is a one-qubit gate that exchanges the states of the computational basis. In other words,\n$X |0\\rangle = |1\\rangle$,\n$X |1\\rangle = |0\\rangle$.\nTherefore, given an arbitrary state in the computational basis, we have\n$X |\\psi\\rangle = \\frac{1}{\\sqrt{N}}(a|1\\rangle + b|0\\rangle)$."}, {"title": null, "content": "The Pauli Y, $Y$, is a one-qubit gate that exchanges the states of the computational basis while introducing a phase factor as\n$Y |0\\rangle = i |1\\rangle$,\n$Y |1\\rangle = -i|0\\rangle$.\nGiven an arbitrary state in the computational basis, the resulting state after applying a Pauli Y is\n$Y |\\psi\\rangle = \\frac{i}{\\sqrt{N}}(a|1\\rangle - b|0\\rangle)$,\nwhere the global phase factor $i$ can be absorbed by the normalization factor and it has no physical meaning. Note that the relative phase factor -1 does have implications in the physical properties of $|\\psi\\rangle$.\nThe last Pauli gate is the Pauli Z, $Z$, which is also referred to as phase flip. The action of Pauli Z on the computational basis is\n$Z |0\\rangle = |0\\rangle$,\n$Z |1\\rangle = - |1\\rangle$.\nIn other words, the Z gate leaves $|0\\rangle$ unchanged and flips the phase of $|1\\rangle$. Thus, the Pauli Z transforms an arbitrary state to\n$Z |\\psi\\rangle = \\frac{1}{\\sqrt{N}}=(a|0\\rangle \u2013 b|1\\rangle)$.\nThe Hadamard gate, $H$, is a one-qubit gate that takes the computational-basis states and creates an equal-superposition state as\n$H |0\\rangle = \\frac{1}{\\sqrt{2}}(|0\\rangle + |1\\rangle)$,\n$H |1\\rangle = \\frac{1}{\\sqrt{2}}(|0\\rangle - |1\\rangle)$.\nGiven an arbitrary state $|\\psi\\rangle$, the application of a Hadamard gate yields to\n$H |\\psi\\rangle = \\frac{1}{\\sqrt{2N}}[(a + b) |0\\rangle + (a \u2013 b) |1)]$"}, {"title": null, "content": "The Phase shift is a family of one-qubit gates denoted by $P(\\phi)$. It introduces a relative phase factor of $\\phi$ between the computational-basis states. Mathematically,\n$P|0\\rangle = |0\\rangle$,\n$P|1\\rangle = e^{i\\phi} |1\\rangle$.\nThe action of a phase shift on an arbitrary quantum state is\n$P|\\psi\\rangle = \\frac{1}{\\sqrt{N}}(a |0\\rangle + b e^{i\\phi} |1\\rangle)$.\nFor some values of the phase factor $\\phi$, the phase shift has a concrete name. For example, $P$ is known as the phase gate or the $S$ gate, $S$, when $\\phi = \\pi/2$. The phase shift $P(\\pi/4)$ is referred to as the $T$ gate or the $\\pi/8$-gate. Note that $Z = P(\\pi)$, $S = P(\\pi/2) = \\sqrt{Z}$ and $T = P(\\pi/4) = \\sqrt[4]{Z}$.\nThe controlled NOT gate, CNOT(c, t), is a two-qubit quantum gate that applies a bit flip to the target qubit, t, if and only if the control qubit, c, is in |1). Otherwise, the target qubit is unchanged. Considering the first qubit as the control qubit and the second qubit as the target qubit, the application of the CNOT on the computational basis results in\nCNOT(1, 2) |00\\rangle = |00\\rangle,\nCNOT(1, 2) |01\\rangle = |01\\rangle,\nCNOT(1, 2) |10\\rangle = |11\\rangle,\nCNOT(1, 2) |11\\rangle = |10\\rangle$.\nIf we apply the CNOT gate on an arbitrary two-qubit state (Eq. (A.2)), we obtain\nCNOT|\\psi\\rangle = \\frac{1}{\\sqrt{N}}(a|00\\rangle + b|01\\rangle + c|11\\rangle + d|10\\rangle)$.\nAnalogously to the controlled NOT gate, there exists the controlled phase gate, CZ(c, t), which applies a phase flip to the target qubit, t, if and only if the control qubit, c, is in |1). Mathematically, we write\nCZ(c, t) |00\\rangle = |00\\rangle,\nCZ(c, t) |01\\rangle = |01\\rangle,"}, {"title": null, "content": "CZ(c, t) |10\\rangle = |10\\rangle,\nCZ(c, t) |11\\rangle = - |11\\rangle$.\nNote that the controlled phase gate is independent of the role of each qubit, i.e., CZ(c, t) = CZ(t, c). After applying the CZ gate on an arbitrary two-qubit state in Eq. (A.2), we obtain\nCZ |\\psi\\rangle = \\frac{1}{\\sqrt{N}}(a|00\\rangle + b |01\\rangle + c|01\\rangle \u2013 d|11\\rangle)$.\nThe SWAP gate is a two-qubit gate that swaps the state of the qubits on which it acts. Applying the SWAP gate on the computational basis yields to\nSWAP|00\\rangle = |00\\rangle,\nSWAP |01\\rangle = |10\\rangle,\nSWAP |10\\rangle = |01\\rangle,\nSWAP |11\\rangle = |11\\rangle$.\nTherefore, if we apply the SWAP gate on an arbitrary two-qubit state, we get\nSWAP|\\psi\\rangle = \\frac{1}{\\sqrt{N}}(a|00\\rangle + b|10\\rangle + c|01\\rangle + d|11\\rangle)$."}]}