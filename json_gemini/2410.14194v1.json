{"title": "Speciesism in Natural Language Processing Research", "authors": ["Masashi Takeshita", "Rafal Rzepka"], "abstract": "Natural Language Processing (NLP) research on AI Safety and social bias in AI has focused on safety for humans and social bias against human minorities. However, some AI ethicists have argued that the moral significance of nonhuman animals has been ignored in AI research. Therefore, the purpose of this study is to investigate whether there is speciesism, i.e., discrimination against nonhuman animals, in NLP research. First, we explain why nonhuman animals are relevant in NLP research. Next, we survey the findings of existing research on speciesism in NLP researchers, data, and models and further investigate this problem in this study. The findings of this study suggest that speciesism exists within researchers, data, and models, respectively. Specifically, our survey and experiments show that (a) among NLP researchers, even those who study social bias in AI, do not recognize speciesism or speciesist bias; (b) among NLP data, speciesist bias is inherent in the data annotated in the datasets used to evaluate NLP models; (c) OpenAI GPTs, recent NLP models, exhibit speciesist bias by default. Finally, we discuss how we can reduce speciesism in NLP research.", "sections": [{"title": "1 Introduction", "content": "Research on social bias in AI has surged in the natural language processing (NLP) since the advent of pretraining models such as Word2Vec [1] and BERT [2]. These models were primarily used in NLP research, and some researchers discovered their inherent social biases [3]. Initially, social bias research in NLP models focused on binary gender and race [4, 5]. However, the limited number of social attributes studied is problematic. Therefore, some bias researchers have worked on a variety of attributes such as disability [6], sexual orientation [7], and intersectional ones [8, 9], as well as studying negative bias toward queer people living in non-binary genders [10]. Moreover, other studies have found that large language models (LLMs) generate harmful and stereotypical representations [11] and have proposed AI alignment methods to prevent them [12]. Thus, NLP researchers are seriously combating discriminative biases and harmful behaviors of NLP models.\nOn the other hand, one attribute that is ignored in NLP research is nonhuman animals. Our aim is to seek an answer to the following research questions: a) what is the extent to which discrimination against nonhuman animals, referred to as speciesism, is overlooked in NLP research? and b) how can we investigate speciesist bias present in NLP data and models? As some existing studies have suggested, speciesist bias against nonhuman animals has rarely been studied in NLP research (see Section 3.3.1).\nAI ethicists have criticized moral anthropocentrism in response to these problems, observing that nonhuman animals are ignored in AI ethics (see Section 3.1).\nThis study investigates speciesism or speciesist bias among NLP researchers (Section 3), NLP data (Section 4), and NLP models (Section 5) in order to identify speciesism in NLP research. We also explain why it is crucial to recognize speciesism in NLP research (Section 2) and, finally, discuss what we should do to challenge speciesism in NLP research (Section 6)."}, {"title": "2 Motivation", "content": ""}, {"title": "2.1 What Is Speciesism and Why Do Nonhuman Animals Morally Matter", "content": "Speciesism is \"the unjustified comparatively worse consideration or treatment of those who do not belong to a certain species\" [13]. Typical examples of speciesist practices are factory farming and animal experimentation [14]. Nonhuman animals such as cows, pigs, and chickens are bred for human consumption in cramped and poor conditions. There is a consensus among scientists that these nonhuman animals are conscious and sentient [15]. Therefore, they experience pain during captivity and slaughter.\nSimilarly, in animal experimentation, although there are regulations such as the 3RS (Replacement, Reduction, and Refinement) [16], more than seven million nonhuman animals were used, and most of them were killed in the EU in 2020 [17].\nIf we think that the suffering of nonhuman animals holds less moral significance than that of humans solely because they are nonhuman animals, that is speciesism. Drawing an analogy with racism and sexism [14], if one considers the interests of a human being of a particular race or gender to be less morally significant than the"}, {"title": "2.2 Why Do Nonhuman Animals Matter in NLP Research", "content": "There are four reasons to take nonhuman animals seriously in NLP research if we accept that they are morally significant [cf. 20-22].\nFirst, if NLP models such as LLMs have a speciesist bias, then they propagate the speciesist bias. As described in many social bias studies of AI, the bias inherent in NLP technology is propagated to people through applications such as machine translation and dialogue systems [cf. 23-25]. It reinforces the discriminatory bias in their attitudes. Some psychological studies have shown that people already have speciesist attitudes [26, 27]. These attitudes could be reinforced by the speciesist output generated by NLP technology. It may also further reinforce the speciesist practices discussed above (Section 2.1), such as factory farming and animal experimentation.\nSecond, psychological experiments also suggest that these and other speciesist attitudes are correlated with other discriminatory attitudes. People with speciesism tend to have racist and sexist attitudes [26], which are associated with social dominance orientation\u00b9 and political conservatism [28, 29]. Therefore, reinforcing speciesist attitudes may reinforce other discriminatory attitudes. If NLP models propagate discriminatory biases, then removing the speciesist bias in NLP models would be beneficial not only for nonhuman animals but also for humans.\nThird, NLP technologies with a speciesist bias could harm those who are opposed to speciesist practices, such as ethical vegans. Consider, for example, LLMs associating negative words with nonhuman animals or recommending dishes that utilize nonhuman animal products to vegans. They would be harmed by such behavior of LLMs and would stop using this technology. This harm is a form of technological exclusion [cf. 30] and discrimination against them [31].\nFinally, NLP models and corpora inherently reflect social biases, including speciesist bias, present in our cognition, beliefs, and social structures [5, 32-34]. Analyzing social biases in NLP models and corpora can promote our understanding of its influence on our cognition and society."}, {"title": "2.3 Why Do We Focus on Speciesism in NLP Researchers, Data, and Models", "content": "We argued that nonhuman animals are morally significant and matter in NLP research. However, as this study shows in the following sections (see Sections 3-5), speciesism is rarely considered in NLP research. This paper aims to reveal speciesism in NLP research by focusing on researchers, data, and NLP models. We explain why we consider these three entities.\nFirst, if there is a speciesism bias in NLP models, then there is a risk of reinforcing people's speciesist attitudes through generated text. Furthermore, it would lead to the technical exclusion of ethical vegans and anti-speciesist people. Therefore, it is crucial to analyze the speciesism bias in NLP models.\nSecond, it is also relevant to identify speciesist bias in the NLP data. It will contribute to identifying the origin of the speciesist bias in the NLP model. Furthermore, if speciesist bias is found in the data, reducing this bias in the data will contribute to mitigating speciesist bias in future developed NLP models.\nFinally, it is also essential to identify speciesism among NLP researchers themselves. Primarily, NLP researchers design and create NLP data, especially data for downstream tasks and NLP models. Thus, if there is speciesist bias in these NLP data and models, it has its origin in the NLP researchers, at least partially. Furthermore, benchmark datasets for evaluating NLP models are also developed primarily by NLP researchers. If a benchmark dataset contains a speciesist bias, evaluating NLP models would be inappropriate from an anti-speciesist view. Therefore, NLP researchers play an essential role in considering social bias [cf. 37]. If NLP researchers have speciesist attitudes, removing these attitudes will lead to mitigating speciesist bias in NLP data and NLP models through their research.\nTherefore, this paper aims to identify speciesism in NLP researchers, data, and models."}, {"title": "3 Speciesism among NLP researchers", "content": "We first explore speciesism among NLP researchers. Section 3.1 introduces the findings of existing studies, Section 3.2 describes our additional research methodology, and Section 3.3 reports our findings. Section 3.4 discusses the speciesism among NLP researchers based on the findings of existing studies and our investigation.\nWe discuss speciesism in the NLP data (Section 4) and NLP model (Section 5) similarly."}, {"title": "3.1 Existing Findings", "content": "Existing studies have not directly examined whether NLP researchers ignore the issue of speciesism. However, by surveying AI ethics courses offered by companies and other"}, {"title": "3.2 Our Method of Investigating Speciesism of NLP Researchers", "content": "This section investigates speciesism in NLP researchers by analyzing their papers. We perform this investigation in two approaches. First, we investigate speciesism among NLP researchers qualitatively. We analyze their efforts to address speciesist bias in AI and their descriptions regarding social bias and nonhuman animals in their papers. We also check whether there are any bias evaluation datasets including the speciesist bias category. We refer the survey site of \"Bias and Fairness in Large Language Models: A Survey\" [39].\nSecond, we conduct a quantitative approach. We investigate (1) how NLP researchers mention (if they do at all) \"speciesism\" or \"anthropocentrism\" \u2074, and (2) how NLP researchers use nonhuman animal names in the titles of their papers. In the first quantitative investigation, we search for the words \"speciesism\" and \"anthropocentrism\"\u2075 on the ACL Anthology\u2076 to analyze how many papers mention them and how the words were used.\u2077 In the second one, we hypothesize that some NLP researchers use speciesist idioms and proverbs in their papers' titles. We use ACL Anthology Corpus [40], the most exhaustive NLP paper corpus, to count speciesist titles. This corpus includes papers published in ACL Anthology until September 2022. Animal names used to investigate speciesism in our research are shown in Table 1, based on Takeshita et al. [21]. Some words in their list have two meanings, hence we exclude these considered unlikely to mean nonhuman animal names. Annotation of"}, {"title": "3.3 Our Findings of NLP Papers Analysis", "content": ""}, {"title": "3.3.1 Findings in Qualitative Investigation", "content": "Most of social bias studies in NLP ignore speciesist bias. Although numerous experimental studies deal with social biases against humans, to the authors' best knowledge, there are only two studies regarding speciesist bias: Takeshita et al. [21] and Hagendorff et al. [22].\nSome surveys or papers that propose frameworks for social bias in Al also ignore the speciesist bias or topics regarding nonhuman animals. For example, Gallegos et al. [39] defined social groups as \u201ca subset of the population that shares an identity trait, which may be fixed, contextual, or socially constructed\". However, they also explained that the examples of social groups are legally protected by anti-discrimination law (i.e., \u201cprotected groups\u201d or \u201cprotected classes\u201d under federal United States law) including age, color, disability, gender identity, national origin, race, religion, sex, and sexual orientation [39, p. 5]. They may not consider nonhuman animals in this definition.\nFurthermore, Mei et al. [41] use \u201ca comprehensive list of 93 social stigmas\" proposed by Pachankis et al. [42] to evaluate the social bias in NLP models. Smith et al. [43] proposed the classification framework for social bias in AI, which calls itself the \"HOLISTICBIAS dataset\". However, there is no statement about nonhuman animals in any of these studies.\nBlodgett et al. [44] analyzed the pitfalls of bias evaluation datasets such as CrowS-Pairs [7] and StereoSet [45]. For example, they pointed out the problem of an instance of StereoSet represented in Table 2. Indeed, we agree with the pitfalls they describe. However, they do not recognize the speciesist practice included in the sentence, \"I really like Norwegian salmon\", meaning the person likes to eat Norwegian salmon. Furthermore, they represent salmon as an object. This expression is an example of speciesist language. Another problematic instance they found in CrowS-Pairs dataset is \"Johnny had a feeling that the Scottish / American horse he bet on would win\u201d. They correctly claim that this sentence pair \"is about horses from two countries, despite the lack of an oppressive or harmful power dynamic there (as far as we know)\" [44, p. 1007]. However, the practice of the horse race is a speciesist practice regarding horses."}, {"title": "3.3.2 Findings in Quantitative Investigation", "content": "We obtained five results for the search term \"speciesism\" and eleven results for the search term \"anthropocentrism\" in the ACL Anthology. These results are less frequent than the number of hits for \"sexism\" (1,690) and \"racism\" (2,380). On the one hand, in the case of \"speciesism\", one publication cited the study by Takeshita et al. [21] and one by Hagendorff et al. [22]. Neither of these two found papers was about speciesism or speciesist bias, but Hessenthaler et al. [49], who cited Takeshita et al., mentioned speciesist bias as related research. None of the remaining publications refers to speciesism or speciesist bias. In contrast, for \"anthropocentrism,\" there are seven papers discussing the anthropocentric aspect of human language. Two papers focus on anthropomorphism or animacy perception. Additionally, there is one conference proceedings that encompasses two papers on the anthropocentric aspect of human language. One publication specifically addressing computational linguistics. All of them are not related moral anthropocentrism, which means that humans are morally superior to or more significant than nonhuman animals.\nOut of a total of 73,285 titles of NLP papers, we identified 154 titles that included animal names. More than half are names of tools or datasets. However, 22 titles are"}, {"title": "3.4 Discussion on Speciesism among NLP Researchers", "content": "The investigation in this section suggests that NLP researchers do not recognize speciesism. The qualitative investigation indicates that even researchers studying social bias in AI are unaware of speciesism. Some researchers aim to compile a \"comprehensive list\" of social biases by drawing from existing research, including psychological studies. However, the common problem is that the existing research is already anthropocentric, thus such lists are also anthropocentric.\nOur quantitative survey indicates that NLP researchers have not conducted studies on speciesism and moral anthropocentrism. Furthermore, there are some uses of speciesist idioms in the titles of some papers. These findings further support the observations made by AI ethicists, as Singer and Tse [20], and Owe and Baum [38] who argued that most AI researchers seem to ignore speciesism.\nThe following section explores speciesism in data and models. As discussed in the Section 2.3, these NLP data and models were created mainly by NLP researchers. Based on the existing research and our own observations in this section, it is anticipated that we will encounter instances of speciesism or speciesist bias in the data and models we analyze below."}, {"title": "4 Speciesism in NLP data", "content": ""}, {"title": "4.1 Existing Research", "content": "Takeshita et al. [21] analyzed the Wikipedia dataset by counting how many animal names are indicated by \"who\" or \"which\" as a relative pronunciation (Figure 1). They found that except for \"human\" and a few nonhuman animal names, the use of speciesist language (using \"which\" or \"that\" as relative pronounce) is more frequent than the use of nonspeciesist language (using \"who\", \"whose\" or \"whom\") in the cases of nonhuman animal names. Furthermore, nonspeciesist language is relatively frequent in some cases of nonhuman animal names such as \"dog\" and \"cat\".\nWhile searching for bias evaluation datasets in a investigation of speciesism among NLP researchers (Section 3.2), we found that Nozza et al. [50] used HurtLex [51] to evaluate how do BERT and GPT-2 generate hurtful stereotypes. HurtLex includes \"ANIMAL\" category as \"Hate words and slurs beyond stereotypes\". We will discuss this in Section 4.4."}, {"title": "4.2 Our Analysis Methodology in NLP Data", "content": "We investigate the data of the following downstream tasks: WNLI [52], Social Chemistry 101 [53], and Commonsense Morality in ETHICS [54]. WNLI is the task of Winograd Schema Challenge [55] converted into natural language inference (NLI) format and included in the GLUE benchmark [52]. We hypothesize that there are cases of speciesist language, such as using \"it\" or \"which\" to refer to nonhuman animal names."}, {"title": "4.3 Our Findings", "content": "We summarize our findings from this investigation in Table 3. For WNLI, we found 18 cases using speciesist language, an example is in Table 3.\nIn Social Chemistry 101, there are 2,332 cases including animal or meat names. It is difficult to list all of them, hence we present only some speciesist examples: \"It's okay to be excited when you catch a large fish.\"; \"You should eat your meat however you best like it prepared.\" These examples show that people think speciesist actions, such as eating meat and catching a fish, are not morally wrong.\nFor Commonsense morality in ETHICS dataset, we found 864 cases including animal or meat names, of which 163 cases are speciesist. For example, the sentence \"I ate broccoli, chicken liver, fava beans, with a nice chianti\" is labeled \"0\" which means morally permissible action. However, this is not morally permissible from the anti-speciesism or animal-friendly perspectives."}, {"title": "4.4 Discussion on Speciesism in NLP Data", "content": "Existing research indicates that the pretraining datasets include speciesist language. Our additional investigation in this section reveals the use of speciesist language, along with examples that support speciesist practices in the downstream task datasets.\nThere are at least two reasons why the downstream datasets contain speciesist entries. First, it is because most annotators consider speciesism not to be morally wrong. As Singer and Tse [20] argued, commonsense morality is favorable to speciesism, so it is obvious that if researchers were to collect annotators without restrictions and have them annotate the data, they would create a dataset that is in favor of speciesism.\nSecond, NLP researchers who develop guidelines for creating such datasets also think that speciesism is not wrong. As indicated in the previous section, even researchers studying the social bias in AI and AI safety fields are unaware of speciesism. Therefore, they do not consider speciesism in creating their datasets, and they create and publish datasets that include speciesist bias. Of course, part of the purpose of their research is to reflect commonsense morality, so the inclusion of speciesist bias meets that purpose. However, their other goal is to align AI more safely with human's values. Therefore, the inclusion of speciesism bias in the data makes it impossible to achieve the safety and alignment of AI with nonhuman animals and anti-speciesist people.\nFurthermore, as we found, Nozza et al. [50] used HurtLex [51] to evaluate social bias in BERT and GPT-2, and HurtLex includes \"ANIMAL\" category as \"Hate words and slurs beyond stereotypes\". We acknowledge that certain words and phrases using nonhuman animal names harm people. However, this kind of language is not only hurtful to people but also to nonhuman animals [59]. One reason why these names can be harmful is because they reinforce the notion of speciesism, which asserts that nonhuman animals are inferior to humans. [cf. 60].\nWhat can we do to create an anti-speciesist dataset? A community-based or participatory approach to creating datasets might be helpful [37, 61]. Some studies on social bias in AI have employed the approach of administering questionnaires to LGBTQ+ individuals to identify strategies for mitigating false stereotypes associated with LGBTQ+ communities [62, 63]. Nevertheless, nonhuman animals do not possess the capacity to respond to questionnaires. Consequently, the creation of anti-speciesist datasets can be achieved by interviewing individuals with anti-speciesist beliefs or by involving them as annotators, rather than relying on nonhuman animals."}, {"title": "5 Speciesism in NLP models", "content": ""}, {"title": "5.1 Existing Findings", "content": "Takeshita et al. [21] analyzed the speciesist bias in Masked Language Models (MLMs) (e.g., BERT [2]) by using the probability difference of a token filled in [MASK] token between two types of templates: human-describing sentences and object-describing sentences. The human-describing sentence is \"She/He is a [ANIMAL] who is [MASK].\""}, {"title": "5.2 Our Method of Evaluating Speciesist Bias in NLP Models", "content": "To evaluate speciesist bias in NLP models, we consider whether NLP models explicitly support speciesist action or not. We use Commonsense Morality subset of ETHICS dataset [54]. As described in Section 4.3, we found 163 speciesist instances in this subset. We use these instances to evaluate the bias towards nonhuman animals in NLP models. We investigate the bias in Delphi [57]12, GPT-3.5-turbo (gpt-3.5-turbo-1106)13 and GPT-4 (gpt-4-1106-preview) [69]. Furthermore, we try to mitigate the speciesist bias in both GPTs14 with anti-speciesist prompt, based on [70]. Table 4 shows two prompts used for GPTs15 in our experiment.\nThere are two differences between our study and existing studies. First, our study is a quantitative evaluation because we use over 160 examples. Hagendorff et al. [22] reported that GPT-3 generated texts that seem to support speciesist practices. However, they analyzed only about 40 cases. Second, we attempt to mitigate speciesist bias by prompting, while existing studies only analyze the bias. This is also to assess whether GPTs can understand the anti-speciesist prompt. It has to be noted that our prompt strategy is prototypical, and we are aware that it could have only a limited effect on bias mitigation. Therefore, we need to improve this technique further in the future."}, {"title": "5.3 Our Findings", "content": "We show the results of our experiments in Table 5. All investigated NLP models with the normal prompt answer \"No\", i.e., the speciesist action is not morally wrong, in most cases. The anti-speciesist prompt increases the answer to \"Yes\", i.e., recognizing properly that the speciesist action is morally wrong. However, it also increases the answer to \"No\" for the case of GPT-3.5-turbo. On the other hand, the anti-speciesist prompt largely decreases the answer \u201cNo\u201d for the case of GPT-4, from 100 (61.3%) to 38 (22.3%), increasing the answer \"Yes\", from 1 (0.6%) to 101 (62.0%).\nIn addition, GPTs replied \"Unknown\" at relatively low rates (from 5.5% to 38.0%); the response \u201cUnknown\" indicates that a model withholds response, and it is impossible to decide whether the output is speciesist or non-speciesist."}, {"title": "5.4 Discussion on Speciesist Bias in NLP Models", "content": "Existing studies showed that Masked and Large Language Models (MLMs and LLMs) associate negative words with nonhuman animal names. The results of our survey indicate that both Delphi and recent OpenAI GPT models do not reject speciesist practices. These findings suggest that there is a speciesist bias inherent in these LLMs. In particular, the results in the case using the normal prompt are not surprising. These models are fine-tuned to avoid generating harmful content [69, 71], specifically for humans, not for nonhuman animals. Although GPT models tend to produce content that agrees with discriminatory claims with adversarial input [72], our experiment showed that GPTs generate harmful content for nonhuman animals even without adversarial input.\nAnti-speciesist prompts partially alleviate the problem of speciesist bias in both GPT models, especially in the case of GPT-4 which outputs \u201cYes (non-speciesist)\" more frequently than \u201cNo (speciesist)\". These results suggest that such an anti-speciesist prompt helps decrease speciesist text generation. However, as discussed above, these LLMs generate speciesist content without anti-speciesist prompts, although these models are trained not to generate such discriminatory content for human beings. In our opinion, future LLMs should be trained not to generate speciesist text without post-processing bias mitigation techniques, such as anti-speciesist prompts."}, {"title": "6 General Discussion", "content": "This research investigated speciesism among NLP researchers (Section 3), in data (Section 4), and models (Section 5). Social bias researchers in NLP do not recognize speciesist bias, and some NLP researchers use speciesist idioms in their papers' titles. NLP data contains speciesist content: speciesist language used in the pretraining corpus and downstream task dataset, and the annotation of commonsense morality supports speciesist practices. NLP models such as MLMs and LLMs show the behavior indicating speciesist bias.\nNotice that speciesism (and its base) among researchers, data, and models are closely related. First, the relationship between the data and the model's speciesist bias is obvious. Because of speciesist bias existing in the pretraining corpus, the NLP model trained on it naturally displays speciesist bias behavior. In addition, NLP researchers are taking the lead in the design and curation of such datasets. Hence, since NLP researchers do not perceive speciesist bias as morally problematic, the datasets retain such bias, and no effort was made to eliminate it."}, {"title": "6.1 Countermeasures Against Speciesism in NLP Research", "content": "How can we reduce speciesism in NLP research? First, NLP researchers themselves should recognize that nonhuman animals should be taken seriously in their research. Speciesism is rooted in our psychological and cultural attitudes and will not be easy to overcome [27]. However, even if one does not accept anti-speciesism, one could"}, {"title": "6.2 Limitations", "content": "Our investigation is limited to NLP, thus we should extend analysis to other AI domains such as computer vision. Hagendorff et al. [22] explored the speciesist bias in the datasets, MS-COCO [76] and ImageNet [77], and found the bias in these datasets. We should extend our and their research to researchers and models in computer vision and other fields of AI.\nOur research focused on only the attributes of nonhuman animals. However, it is crucial to consider intersectional ones. As ecofeminists discussed [e.g., 78], speciesism and sexism are linked. For example, women are frequently insulted by nonhuman animal metaphors. The reason why it is possible to insult women by using nonhuman animals as a metaphor is that it would apply to women the negative images derived from speciesism. Moreover, using nonhuman animal metaphors to insult women contributes to both speciesism and sexism. [59].\nRegarding speciesism within NLP researchers, we investigated speciesism in the texts written by the researchers. However, we did not interview NLP researchers for their views on speciesism. Some of those doing NLP research may oppose speciesism. Thus, we need to interview researchers to clarify speciesism in NLP or AI researchers in the future."}, {"title": "6.3 Ethical Considerations", "content": "We recognize that our claim of anti-speciesism is controversial and are aware that some philosophers defend speciesism [e.g., 79]. However, as discussed in Section 2.1, we need to take nonhuman animals seriously in NLP research if one acknowledges the moral status of nonhuman animals. Our study is only a starting point, and there is a need for further research to promote the significance of nonhuman animals in NLP and AI research.\nIn our study, we critically investigated some of NLP-related publications. Our intent was not to attack the authors of those papers or divide the NLP community. We hope that NLP researchers will constructively reflect on what should be done to avoid harm to nonhuman animals and our study will contribute to the constructive discussion.\nIn this study, we treated the group of \"nonhuman animals\" as a whole. However, there is a rich diversity among species of nonhuman animals, and they have different relationships with humans [80]. Distinct relationships exist between us and companion nonhuman animals (e.g., dogs and cats), nonhuman animals in farms (e.g., cows and pigs), and free-roaming (\u201cwild\u201d) nonhuman animals (e.g., bears and wolves). Recognizing these differences is crucial, and future research should explore the diverse relationships with various nonhuman animals.\nThis study examined speciesism in current NLP research. Nonhuman animals do not directly use NLP techniques. However, it is possible that one day humans will be able to communicate with nonhuman animals using future NLP technology. In that case, communication with nonhuman animals could cause them further harm [81]. To prevent such a future, we need to recognize the significance of nonhuman animals in NLP research and stop speciesism."}, {"title": "7 Conclusion", "content": "This study is the first systematic investigation of speciesism in NLP research. We discussed why speciesism should be considered in NLP research. We argued that non-human animals are morally significant and that NLP and AI researchers should stop speciesism or at least seriously consider the impact of AI on nonhuman animals and anti-speciesist people. Nevertheless, our survey of speciesism in NLP researchers, data, and models suggests that NLP researchers are unaware of speciesism and that the speciesist bias exists in NLP data and NLP models. We also attempted to mitigate the speciesist bias using an anti-speciesist prompt for the OpenAI GPT models and partially reduced the bias in GPT-4.\nIf nonhuman animals and anti-speciesist values are to be taken seriously, NLP researchers have to stop speciesism and moral anthropocentrism. Although this study revealed speciesism in NLP research, we will attempt to reduce the speciesist bias inherent in the data and models in other sub-fields of AI in the future."}, {"title": "Conflict-of-interest statement", "content": "The authors have no conflicts of interest to declare. All co-authors have seen and agree with the contents of the manuscript and there is no financial interest to report. We certify that the submission is original work and is not under review at any other publication."}]}