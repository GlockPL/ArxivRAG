{"title": "ON LEARNING CAPACITIES OF SUGENO INTEGRALS WITH SYSTEMS OF FUZZY RELATIONAL EQUATIONS", "authors": ["Ismail Baaj"], "abstract": "In this article, we introduce a method for learning a capacity underlying a Sugeno integral according to training data based on systems of fuzzy relational equations. To the training data, we associate two systems of equations: a max min system and a min max system. By solving these two systems (in the case that they are consistent) using Sanchez's results, we show that we can directly obtain the extremal capacities representing the training data. By reducing the max min (resp. min - max) system of equations to subsets of criteria of cardinality less than or equal to q (resp. of cardinality greater than or equal to n q), where n is the number of criteria, we give a sufficient condition for deducing, from its potential greatest solution (resp. its potential lowest solution), a q-maxitive (resp. q-minitive) capacity. Finally, if these two reduced systems of equations are inconsistent, we show how to obtain the greatest approximate q-maxitive capacity and the lowest approximate q-minitive capacity, using recent results to handle the inconsistency of systems of fuzzy relational equations.", "sections": [{"title": "1 Introduction", "content": "In decision theory, Sugeno integral [13] is commonly used as a qualitative aggregation function [8] with values on a finite scale L. The definition of this integral is based on an set function called capacity, which qualitatively models the importance (or interaction) of subsets of criteria, and is used in many fields [7] such as uncertainty modeling, multicriteria aggregation or in game theory.\nIn recent years, many approaches, e.g. [1, 3, 5], have been proposed to learn (in closely related senses) the capacity of a Sugeno integral according to N training data, each training data item being a pair (object, targeted global evaluation).\nIn this article, we propose an approach for learning a capacity underlying a Sugeno integral according to training data, which is based on systems of fuzzy relational equations. Our goal is as follows: the Sugeno integral defined by a learned capacity should allow us to obtain, for each object in the training data, its targeted global evaluation, or an approximated value in a specific sense. Our approach is based on the fact that the definition of the Sugeno integral of an object defined by a capacity is given by a max min product between a row matrix containing the minimum of the partial evaluations of the object studied with respect to the subsets of criteria, and a column vector whose components are the measures of the subsets of criteria defined by the capacity. The Sugeno integral can also be obtained by a min max product similarly defined.\nThese two expressions of the Sugeno integral allow us to introduce two systems of fuzzy relational equations, one of type max min and a second of type min max for our learning problem. The matrix of each system is constructed from the objects in the training data, while the second member of each system consists of the targeted global evaluations. Under some natural conditions, the solving of each of the two systems, based on the work of Sanchez [12], produces a vector whose components define the measures of the subsets of criteria of a capacity."}, {"title": "2 Background", "content": "In what follows, we recall the definition of the Sugeno integral and the main results for solving systems of fuzzy relational equations."}, {"title": "2.1 Sugeno integral", "content": "The Sugeno integral framework (see [6] for more details) includes:\nC = {1,2,..., n} : a set of n criteria,\nL = {\u00a71 = 0, \u00a72, . . ., \u03be\u03b9 = 1} : an evaluation scale (a totally ordered finite set \u00a71 = 0 < \u00a72 < \uff65\uff65\uff65 < \u03be\u03b9 = 1) or L = [0, 1].\n\u03bc: 2C \u2192 La capacity, i.e., a set function such that \u03bc(0) = 0,\u03bc(C) = 1 and A C B \u21d2 \u03bc(A) \u2264 \u03bc(\u0392). The conjugate capacity \u03bc\u03b5 is defined by \u03bc\u00ba(A) = \u03b9(\u03bc(A)) with \u03b9 : L \u2192 L : \u00a7i \u2192 \u03be\u03b9\u2212i+1, or 1 : [0, 1] \u2192 [0, 1] :\nt-1-t.\nx = [xi] \u2208 Ln\u00d71 : an object where each xi is a partial evaluation of the object x according to the criterion i.\nThe Sugeno integral is given by two equivalent formulas [9, 6] (other equivalent formulas exist):\n$S_{\\mu}(x) = \\max_{A\\in 2^C} \\min (\\min_{i\\in A} x_i, \\mu(A))$ (1)\n$S_{\\mu}(x) = \\min_{A\\in 2^C} \\max (\\max_{i\\in A}x_i, \\mu(A)).$ (2)\nwhere A denotes the complementary of the subset A of C. The following two notions have been introduced in [4, 10, 14]:"}, {"title": "Definition 1.", "content": "Let \u00b5 : 2C \u2192 L a capacity and q \u2208 {1, 2, ..., n} where n =| C |.\n1. p is said to be q-maxitive iff for all subsets X C C verifying | X |> q, we have \u00b5(X) = maxy\u2282X,|Y|\u2264q\u03bc(Y).\n2. \u00b5 is said to be q-minitive iff for all subsets X \u2286 C verifying | X |< (n - q), we have \u00b5(X) =\nminy\u2283X,|Y|>(n-q) \u03bc(\u03a5).\nIt is easy to check that a capacity \u00b5 is q-maxitive iff its conjugate \u03bc\u03b5 is q-minitive. Any capacity \u03bc: 2C \u2192 Lis (trivially) n-maxitive and n-minitive. Moreover, the two formulas (1) and (2) become:"}, {"title": "Lemma 1.", "content": "Let \u00b5 : 2C \u2192 L a capacity, q \u2208 {1, 2, . . ., n}, n =| C | and x = [xi] \u2208 Ln\u00d71.\n1. If u is q-maxitive, then:\n$S_{\\mu}(x) = \\max_{A\\in 2^C\\{0\\},\\|A\\|\\leq q} \\min(\\min_{i\\in A} x_i, \\mu(A)).$\n2. If u is q-minitive, then we have:\n$S_{\\mu}(x) = \\min_{A\\in 2^C\\{C\\},\\|A\\|\\geq n-q} \\max(\\max_{i\\in A}x_i, \\mu(A)).$"}, {"title": "2.2 Solving systems of max-min fuzzy relational equations", "content": "A system of fuzzy relational equations of type max min based on a matrix A [aij] \u2208 Ln\u00d7m of size (n, m) and a vector b = [bi] \u2208 Ln\u00d71 of n components, is of the following form:\n$(S): A \\bigodot_{max} x = b,$ (3)\nwhere x = [Xj]1<j<m \u2208 Lm\u00d71 is an unknown vector with m components and the operator $\\bigodot_{max}$ is the matrix product which uses the t-norm min as the product and the function max as the addition.\nFrom the vector\n$e = A^t\\bigodot_{min}b,$\n(4)\nwhere At is the transpose of A and the matrix product $\\bigodot_{min}^{\\rightarrow_G}$ use the G\u00f6del implication \u2192G defined by:\n$x\\rightarrow_G y = \\begin{cases}\n1 & x \\leq y\\\\\ny & otherwise.\n\\end{cases}$ (5)\nas the product and the function min as the addition, Sanchez [12] showed the following equivalence:\nThe system (S) is consistent  $A \\bigodot_{max}e \\leq b$.\nIf the system (S) is consistent, the vector e is its greatest solution [12]."}, {"title": "2.3 Solving systems of min-max fuzzy relational equations", "content": "A system of fuzzy relational equations of type min max can be defined similarly. Given a matrix \u0393 = [Yij] \u2208 Lnxm of size (n, m) and a vector \u03b2 = [\u1e9ei] \u2208 Ln\u00d71 of n components, we define a system of min max fuzzy relational equations by:\n$(\\Sigma): \\Gamma \\bigodot_{min}^{max} x = \\beta,$ (6)\nwhere x = [xi]1<j<m \u2208 Lm\u00d71 is an unknown vector with m components and the operator $\\bigodot_{min}^{max}$ is the matrix product which uses the function max as the product and the function min as the addition.\nFrom the vector\n$f = \\Gamma^t\\bigodot_{min}^{{\\epsilon}}\\beta,$\n(7)\nwhere It is the transpose of F and the matrix product $\\bigodot_{min}^{\\epsilon}$ uses the epsilon product (denoted \u20ac) defined by:\n$x{\\epsilon}y = \\begin{cases}\n0 & x<y\\\\\n1 & x \\geq y.\\\n\\end{cases}$ (8)\nas the product and the function max as the addition, we have the following equivalence:\nThe system (2) is consistent $\\Leftrightarrow \\Gamma \\bigodot_{min}^{max} f = \\beta$.\nIf the system (\u03a3) is consistent, the vector f is its lowest solution [12]."}, {"title": "3 Learning capacities for Sugeno integrals according to data with systems of fuzzy relational equations", "content": "In this section, we introduce our method for learning capacities for Sugeno integrals based on training data using systems of fuzzy relational equations. We consider a set of N training data {(x(1), q(1)), (x(2), \u03b1(2)), ..., (x(N), \u03b1(N))}.\nFor k = 1, 2, ..., N, each pair (x(k), a(k)) consists of an object x(k) \u2208 Ln\u00d71 which contains the partial evaluation xk) of the object x(k) according to the criterion i, and the targeted global evaluation of the object, which is denoted by a(k) \u2208 L."}, {"title": "3.1 Constructing two systems of fuzzy relational equations from training data", "content": "From the data (x(k), a(k))1\u2264k\u2264N, we construct two matrices and a vector:\nM = [mk,A]1\u2264k<N,A\u22082C\\{0} where Mk,A = $\\min_{i\\in A} x_i^{(k)}$,\n\u0393 = [/k,A]1<k<N,A\u22082C\\{C} where /k, A = $\\max_{i\\in A} x_i^{(k)}$,\n\u03b1 = [a(k)] \u2208 LN\u00d71: a vector containing the targeted global evaluations of the objects.\nWe form the following system of fuzzy relational equations of type max min from the matrix M and the vector \u03b1:\n$(S): M \\bigodot_{max} X = \\alpha$ (9)\nwhere X = [A] A\u22082c\\{0} is an unknown vector and e = Mt $\\bigodot_{mina}$ is the potential greatest solution of the system (S), see (4). We form the following system of fuzzy relational equations of type min max from the matrix \u0393 and the vector a:\n$(\\Sigma): \\Gamma \\bigodot_{min}^{max} X = \\alpha$ (10)\nwhere X = [\u00a7A] A\u22082c\\{c} is an unknown vector and f = rt $\\bigodot_{max}^{{\\epsilon}}$a is the potential lowest solution of the system (\u03a3), see (7)."}, {"title": "3.2 Preliminary results", "content": "The potential extremal solutions of the two systems (S) and (\u03a3) viewed as set functions e : 2C\\{0} \u2192 Land\nf : 2C\\{C} \u2192 L are increasing:"}, {"title": "Lemma 2.", "content": "1. \u00d8 c A \u2282 B \u21d2 e(A) \u2264 e(B).\n2.A \u2282 B C C \u21d2 f(A) \u2264 f(B).\nThese two implications can be deduced from the properties of G\u00f6del's implication \u2192G, see (5) and those of the epsilon product e, see (8): \u2200x, x' \u2208 L such that x \u2264 x', we have \u2200y \u2208 L, x' \u2192G y \u2264 x \u2192G y and x'ey \u2264 xey.\nFor all \u00d8 CA\u2286 C and B \u2282 C, we put:\n\u2022 J\u2081 = {k \u2208 {1, 2, ..., N} | $\\min_{i\\in A} x_i^{(k)} > a^{(k)}$},\n\u2022 KB = {k \u2208 {1,2,..., N} | $\\max_{i\\in B} x_i^{(k)} <a^{(k)}$}."}, {"title": "Lemma 3.", "content": "1. e(A) = $\\min_{k\\in J_A} a^{(k)}$, with the convention: min\u00f8 = 1.\n2. f(B) = $\\max_{k\\in K_B} a^{(k)}$, with the convention: max\u00f8 = 0.\nIn particular, we have:\n\u2022 e(C) = 1 \u21d4 \u2200k \u2208 {1, 2, . . ., N}, $\\min_{i\\in C} x_i^{(k)} \\leq a^{(k)}$,\n\u2022 f(0) = 0 \u21d4 \u2200k \u2208 {1, 2, ..., N}, $\\max_{i\\in C} x_i^{(k)} \\geq a^{(k)}$"}, {"title": "3.3 Learning capacities", "content": "We construct two set functions from the potential extremal solutions e and f of the systems (S) and (2) defined from the training data, see (9) and (10), as follows:"}, {"title": "Theorem 1.", "content": "The following three conditions are equivalent:\n1. There exists a capacity \u03bc : 2C \u2192 L which represents the training data i.e., a capacity such that \u2200k \u2208 {1,2,..., N}, we have $S_{\\mu}(x^{(k)}) = a^{(k)}$,\n2. The system (S) : MaxX = a is consistent and e(C) = 1,\nmin\n3. The system (\u03a3): \u0393max X = a is consistent and f (\u00d8) = 0.\nmin\nSketch of the proof: for any capacity \u03bc : 2C \u2192 L, we put: v : 2C\\{0} \u2192 L : A \u2194 v(A) = \u03bc(A) and w : 2C\\{C} \u2192 L : A \u2192 w(A) = \u03bc(A). Therefore, it results from the formulas (1) and (2) that we have:\n\u2200k\u2208 {1,2,...,N}, $S_{\\mu}(x^{(k)}) = a^{(k)} \\Leftrightarrow \n \tbinom{M\\bigodot_{max}v = \\alpha}{ \\Gamma \\bigodot_{min}^{max} \\omega = \\alpha}.$"}, {"title": "Corollary 1.", "content": "If the equivalent conditions of Theorem 1 are verified, we have:\n\u2022 \u00b5e is a capacity that represents the training data and it is the greatest.\n\u2022 \u00b5f is a capacity that represents the training data and it is the lowest.\n\u2022 For any capacity \u03bc : 2C \u2192 L that represents the training data, we have:\n\u03bc\u03b5 \u2264 \u03bc\u2264 \u03bc\u03b5.\nThe methods presented in this article for obtaining the extremal capacities \u03bc\u03b5 and \u00b5f that represent the training data, based on Sanchez's results [12], are simpler than those given in [11]."}, {"title": "3.4 Constructing q-maxitives and q-minitives capacities", "content": "For a given training data item (x(k), a(k)), a necessary condition for being able to relate the object x(k) to its targeted global evaluation a(k) using a Sugeno integral is:\n$\\min_{i\\in C}x_i^{(k)} \\leq a^{(k)} \\leq \\max_{i\\in C}x_i^{(k)}$\nFor our learning problem, if for all k \u2208 {1,2,..., N}, each training data item (x(k), a(k)) satisfies this constraint, then we can provide sufficient conditions for the existence of q-maxitive and q-minitive capacities (where 1 < q \u2264 n), which we deduce from the extremal solutions of the systems (S) and (\u03a3)."}, {"title": "Proposition 1.", "content": "Let q \u2208 {1, 2, . . . n}. Assume that there exists A \u2286 C such that | A |= q and e(A) = 1. We put:\n$ \\mu_{\\vee}: 2^C \\rightarrow L$\n$\\ X \\mapsto \\mu_{\\vee}(X)$\n$ \\mu_{\\vee}(X) = \\begin{cases}\n0 & \\text{if } X = \\emptyset\\\\\ne(X) & \\text{if } 0 < |X| \\leq q.\\\\\n\\max_{\\emptyset \\subset Y \\subset X, |Y| \\leq q} e(Y) & \\text{if } |X| > q\n\\end{cases}$ \nThen, \u00b5\u2228 is a q-maxitive capacity on C."}, {"title": "Proposition 2.", "content": "Let q \u2208 {1, 2, . . . n}. Assume that there exists A' \u2286 C such that | A' |= n \u2212 q and f (A') = 0. We put:\n$ \\mu_{\\wedge}: 2^C \\rightarrow L$\n$\\ X \\mapsto \\mu_{\\wedge}(X)$\n$ \\mu_{\\wedge}(X) = \\begin{cases}\n1 & \\text{if } X = C\\\\\nf(X) & \\text{if } n - q < |X| < n.\\\\\n\\min_{Y \\supset X, n-q \\leq |Y| < n} f(Y) & \\text{if } |X| < n - q\n\\end{cases}$ \nThen, \u00b5 is a q-minitive capacity on C."}, {"title": "3.5 Example", "content": "Let n = 3 criteria i.e., C = {1,2,3}. The scale is L = {0.05\u00b7i | 1 < i < 20}. We consider the following N = 3 training data items:\n- x(1) = (0.15, 0.2, 0.3), \u03b1(1) = 0.2,\n- x(2) = (0.5, 0.25, 0.3), \u03b1(2) = 0.3,\n- x(3) = (0.4, 0.7, 0.35), \u03b1(3) = 0.4.\nWe construct the system (S) : Mmax X = a where:"}, {"title": "4 Learning q-maxitive/minitive capacities in practice", "content": "In practice, we restrict ourselves to learning the measures of the sets of criteria with cardinality less than or equal to q (with 1 \u2264 q < n) of a capacity by considering the following system:\n$(S_q): M_q\\bigodot_{max} X = \\alpha,$\nwhere Mq = [mk,A]1\u2264k\u2264N,A\u20ac2\u00a2\\{0},\\A\\\u2264q and we denote by eq the potential greatest solution of (Sq), see (4). For q = n, it is clear that the system (Sn) coincide with the system (S), see (9).\nProperty 1. The system (Sq) is said to verify the q-maxitivity property if \u2203A \u2286 C such that 0 A = q and eq(A) = 1.\nFor any non-empty subset A C C such that | A |\u2264 q, we have eq(A) = e(A). The condition eq(A) = 1 means that \u2200k \u2208 {1, 2, ..., N}, $\\min_{i\\in A} x_i^{(k)} \\leq a^{(k)}$, see Lemma 3. We have the following result:"}, {"title": "Theorem 2.", "content": "The following two statements are equivalent:\n1. There exists a q-maxitive capacity : \u03bc 20 L which represents the training data: Vk E {1,2,..., N}, we have $S_{\\mu}(x^{(k)}) = a^{(k)}$,\n2. The system (Sq) : MqmaxX = a is consistent and it verifies Property 1.\nSketch of the proof: Let \u00b5 : 2C \u2192 La q-maxitive capacity. For all A \u2208 2C\\{0} verifying | A |\u2264 q, we put \u03c5(\u0391) = \u03bc(\u0391). Therefore, it results from the formula (1) that we have:\n\u2200k \u2208 {1,2,..., N}, $S_{\\mu}(x^{(k)}) = a^{(k)} \\Leftrightarrow M_q \\bigodot_{max}v = \\alpha$.\nFor q \u2208 {1, 2, ..., n}, the learning of q-minitive capacity in practice is analogous. We construct the reduced system:\n$(\\Sigma_q): \\Gamma_q\\bigodot_{min}^{max} X = \\alpha$ (13)\nwith q = [/k,A]1<k<N,A\u20ac2C\\{C},\\A\\>n-q and we note fq its potential lowest solution, see (7).\nProperty 2. The system (\u2211q) is said to verify the q-minitivity property if \u2203A C C such that | A |= n q and fq(A) = 0.\nFor any subset A C C such that | A |\u2265 n - q, we have fq(A) = f(A). The condition fq(A) = 0 means that \u2200k \u2208 {1,2,..., N}, $a^{(k)} \\leq \\max_{i \\in A} x_i^{(k)}$ (Lemma 3)."}, {"title": "Theorem 3.", "content": "The following two statements are equivalent:\n1. There exists a q-minitive capacity \u03bc: 2C \u2192 L which represents the training data ke {1,2,..., N}, we have $S_{\\mu}(x^{(k)}) = a^{(k)}$,\n2. The system (q) : qmaxX = a is consistent and it verifies Property 2.\nSketch of the proof: let \u00b5 : 2C \u2192 L a q-minitive capacity. For all A \u2208 2C\\{C} verifying | A |\u2265 n q, we put w(A) = \u03bc(\u0391). Therefore, it results from the formula (2) that we have:\n\u2200k \u2208 {1,2,..., N}, $S_{\\mu}(x^{(k)}) = a^{(k)} \\Leftrightarrow \\Gamma_q \\bigodot_{min}^{max} \\omega = \\alpha$."}, {"title": "4.1 Learning approximate capacities", "content": "If we use the systems of fuzzy relational equations (Sq) and (\u2211q) with real data, which may be subject to noise or contain outliers, the systems (Sq) and (Eq) may become inconsistent. In this case, when L = [0,1], we can rely on the work of [2] on the handling of inconsistent systems of fuzzy relational equations to obtain capacities that approximately represent the training data. For an inconsistent system of max-min fuzzy relational equations A maxx = b, the author of [2] provides an explicit analytical formula for computing the Chebyshev distance, denoted by A = (A, b) = minc\u2208c ||b \u2013 c||\u221e (expressed with the L\u221e norm), between the second member b and the set\nmin\nC = {c\u2208 [0,1]n\u00d71 | the system Amax = min c is consistent}\nformed by the second members of the consistent systems defined with the same matrix: the matrix A of the considered inconsistent system. The same result is provided in [2] for systems of min max fuzzy relational equations, where the Chebyshev distance is denoted by V. The formula of the Chebyshev distance Aq = \u2206(Mq, a) of the system (Sq) is as follows (we use the notation x+ = max(x, 0)):\n$\\Delta_q = \\max_{1 \\leq I \\leq N} \\max_{1 \\leq i \\leq N} \\delta_i \\text{ with } \\delta_i = \\min_{A \\in 2^C\\{0\\}, |A|\\leq q} \\delta_{i, A}$ (14)\nwhere \u03b4\u03b9, \u0391 = max((a(i) \u2013mi,A)+, $\\sigma_G(a^{(i)}, m_{I,A}, a^{(1)})$) and $\\sigma_G(a^{(i)}, m_{I,A}, a^{(1)})$ = min(((a)-a)+, (m\u0131,A-\na(1))+). The value of Aq gives an estimate of the quality of the training data used to build the system (Sq), i.e., the data are of good quality if \u2206q \u2248 0 and not otherwise. Note that for q \u2264 q', we have \u2206q' < Aq.\nThe tools given in [2] can then be used to obtain approximate solutions of the system (Sq) via Aq, from which q-maxitive capacities can be deduced. We use the greatest approximate solution of the system (Sq), which is the vector nq = M\u25a1mina(\u2206q) where \u0101(\u2206q) = [min(a(i) + \u2206q, 1)]1<i<N, see [2], to give sufficient conditions for the existence of the greatest approximate q-maxitive capacity, and we show how to construct it:"}, {"title": "Proposition 3.", "content": "If \u2203A \u2286 C such that | A |= q and yq(A) = 1, we put:\n$ \\mu^*: 2^C \\rightarrow L$\n$\\ X \\mapsto \\mu^*(X)$\n$ \\mu^*(X) = \\begin{cases}\n0 & \\text{if } X = \\emptyset\\\\\n\\eta_q(X) & \\text{if } 0 < |X| \\leq q.\\\\\n\\max_{\\emptyset \\subset Y \\subset X, |Y|\\leq q} \\eta_q(Y) & \\text{if } |X| > q\n\\end{cases}$ \nThen p* is a q-maxitive capacity that verifies max1<k\u2264N | $S_{\\mu^*}(x^{(k)})$ \u2013 a(k) |= \u2206q.\nThe proof of this proposition relies on the fact that the vector [$S_{\\mu^*}(x^{(k)})]$1<k<N (resp. the vector ng), is the greatest Chebyshev approximation (resp. the greatest approximate solution) of the system (Sq): Mq maxX = a, see [2]. Using this proposition and the results of [2], we deduce the following two results:"}, {"title": "Theorem 4.", "content": "If \u2203A \u2286 C such that | A |= q and nq(A) = 1 then:\n$\\min_{\\text{q-maxitive capacity } \\mu} \\max_{1<k<N} | S_\\mu(x^{(k)}) - a^{(k)} | = \\Delta_q$.\nThe minimal learning error of the q-maxitive capacities is equal to Aq.\nThe idea of the proof is based on Proposition 3 and the fact that for any q-maxitive capacity u, the system Mamax X =\nc, where c = [S\u00b5(x(k))]1<k<N, is a consistent system. Note that the algorithm in [3] provides an approximate value\nof min max1<k\u2264N | S\u03bc(x(k)) \u2013 a(k) |, whereas the formula (14) allows us to obtain the exact value, i.e., An. As\n\u03bc capacity\na consequence of this theorem, we have the following important result:"}, {"title": "Corollary 2.", "content": "If \u2203A \u2286 C such that | A |= q and yq(A) = 1, then the capacity \u03bc* (Proposition 3), is the greatest q-maxitive capacity \u00b5 verifying max1\u2264k\u2264N | $S_{\\mu}(x^{(k)})$ \u2013 a(k) |= \u2206q.\nTo learn approximate q-minitive capacities, we use the system (\u03a3q) : \u0393\u2084minX = a, see (13), whose Chebyshev\ndistance is:\n$\\nabla_q = \\max_{1 \\leq I \\leq N} \\nabla_i \\text{ with } \\nabla_i = \\min_{A \\in 2^C\\{C\\}, |A| \\geq n-q} \\nabla_{i, A}$", "text": "The idea of the proof is based on Proposition 3 and the fact that for any q-maxitive capacity u, the system Mamax X =\nc, where c = [S\u00b5(x(k))]1<k<N, is a consistent system. Note that the algorithm in [3] provides an approximate value\nof min max1<k\u2264N | S\u03bc(x(k)) \u2013 a(k) |, whereas the formula (14) allows us to obtain the exact value, i.e., An. As\na consequence of this theorem, we have the following important result:"}, {"title": "Proposition 4.", "content": "If \u2203A \u2286 C such that | A |= n \u2212 q and vq(A) = 0, we put:\n$ \\mu_*: 2^C \\rightarrow L$\n$\\ X \\mapsto \\mu^*(X)$\n$ \\mu^*(X) = \\begin{cases}\n1 & \\text{if } X = C\\\\\n\\nu_q(X) & \\text{if } n - q < |X| < n.\\\\\n\\min_{Y \\supset X, n-q \\leq |Y| < n} \\nu_q(Y) & \\text{if } |X| < n - q\n\\end{cases}$ \nThen, \u00b5\u2217 is a q-minitive capacity which verifies max1<k<N | $S_{\\mu_*}(x^{(k)})$ \u2013 a(k) |= \u2207q.\nThe proof of this proposition relies on the fact that the vector [S\u00b5\u2084(x(k))]1<k<N (respectively the vector vq), is the lowest Chebyshev approximation (respectively the lowest approximate solution) of the system (\u03a3q) : \u0393,maxX = a, see [2]. Using this proposition and [2], we deduce the following two results:"}, {"title": "Theorem 5.", "content": "If \u2203A C C such that | A = n q and vq(A) = 0 then:\n$\\min_{\\text{q-minitive capacity } \\mu} \\max_{1<k<N} | S_\\mu(x^{(k)}) - a^{(k)} | = \\nabla_q$.\nThe minimal learning error of the q-minitive capacities is equal to \u2207 q."}, {"title": "Corollary 3.", "content": "If \u2203A C such that | A |= n q and vq(A) = 0, then the capacity \u00b5\u2217 (Proposition 4), is the lowest q-minitive capacity \u00b5 verifying max1\u2264k\u2264N | $S_{\\mu}(x^{(k)})$ \u2013 a(k) |= \u2207q."}, {"title": "5 Conclusion", "content": "In this article, we have introduced a method for learning capacities of Sugeno integrals according to training data based on systems of fuzzy relational equations. In particular, we have shown that this approach can learn approximate q-maxitive and q-minitive capacities in a precise sense.\nIn perspective, we are currently working on the relationship between the systems (S) and (\u03a3) when they are inconsistent, in order to relate their respective approximate solution sets using the tools of [2]. Finally, we want to test our method on real data."}]}