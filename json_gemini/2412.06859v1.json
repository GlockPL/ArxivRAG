{"title": "Generating floorplans for various building functionalities via latent diffusion model", "authors": ["Mohamed R. Ibrahim", "Josef Musil", "Irene Gallou"], "abstract": "In the domain of architectural design, the foundational essence of creativity and human intelligence lies in the mastery of solving floorplans, a skill demanding distinctive expertise and years of experience. Traditionally, the architectural design process of creating floorplans often requires substantial manual labour and architectural expertise. Even when relying on parametric design approaches, the process is limited based on the designer's ability to build a complex set of parameters to iteratively explore design alternatives. As a result, these approaches hinder creativity and limit discovery of an optimal solution. Here, we present a generative latent diffusion model that learns to generate floorplans for various building types based on building footprints and design briefs. The introduced model learns from the complexity of the inter-connections between diverse building types and the mutations of architectural designs. By harnessing the power of latent diffusion models, this research surpasses conventional limitations in the design process. The model's ability to learn from diverse building types means that it cannot only replicate existing designs but also produce entirely new configurations that fuse design elements in unexpected ways. This innovation introduces a new dimension of creativity into architectural design, allowing architects, urban planners and even individuals without specialised expertise to explore uncharted territories of form and function with speed and cost-effectiveness.", "sections": [{"title": "1. Introduction", "content": "The process of architectural design is a complex and multifaceted endeavour that presents numerous challenges [12, 13, 16, 31]. Architects face the task of finding optimal solutions that not only satisfy the functional requirements of a building but also possess aesthetic appeal, adhere to site regulations, and meet the expectations of their clients. Ultimately, architectural design goes beyond mere functionality and compliance; it aspires to make a lasting impression on the built environment. Architects aspire to create designs that transcend time, leaving a legacy that enriches the fabric of a place. Achieving functionality in architectural design, however, involves a deep understanding of the intended purpose and user needs which require an intensive iterative design process. To reach an optimal design, accordingly, the architectural design process of creating floorplans often requires substantial manual labour and architectural expertise which are often limited by projects' resources and timelines. Over the last few decades, there has been continuous progress in design process and aided software developments to explore iterative design alternatives before decision-making, moving from hand sketching and drawing to Computer Aided Drawing (CAD) software, to parametric design, a realm where designers develop set of rules and parameters, orchestrating a design process that is"}, {"title": "2. Background", "content": "The stated issue of generating floor plans pertains to four distinct domain areas that hold significance. In these areas, we will succinctly outline the cutting-edge advancements as well as the existing limitations.\nIterative design: Iterative design is a design methodology that applies to various fields, including the classical approach of designing floor plans [17, 21, 38, 45, 48, 58, 60]. It comprises a cyclical approach of prototyping, testing, and refining to develop optimal floor plan designs. The process recognises the importance of ongoing feedback and continuous improvement throughout the design journey. When designing floor plans, the iterative approach begins by establishing design goals and understanding the requirements of the space and its occupants. Based on this information, an initial floor plan prototype is created, considering factors such as functionality, spatial organization, and aesthetics. The prototype is then evaluated through various means, such as reviewing user feedback, conducting usability tests, and consulting with experts in architecture and interior design. This evaluation stage helps identify strengths, weaknesses, and areas for improvement in the floor plan design. Although iterative parametric design is a successful process for creating floor layouts [14, 19, 33], it has several drawbacks. The lack of resources and time is one of the major restrictions. The floor plan must be developed, tested, and improved with each step of the design process. As a result, there could be practical restrictions on how many iterations can be successfully completed within a certain timeframe or using the resources at hand. Additionally, not every design alternative might be investigated during the iterative design process. Instead of exhaustively examining every design option, architects and designers may need to concentrate on a subset of feasible solutions due to time restrictions or other practical concerns. This limitation means that there is a possibility of missing out on alternative design approaches or potentially superior solutions.\nConditional image generation: To explore different design strategies and layout options, relying on generative AI approaches for image generations becomes a crucial approach. Generative AI refers to a branch of artificial intelligence that focuses on creating models and algorithms capable of generating new and original content, such as images, text, audio, or even videos [1, 11, 26, 56]. Generative AI has been particularly successful in the field of image generation. Models like Generative Adversarial Networks (GANs) have demonstrated the ability to generate highly realistic and diverse images. Conditional GANs allow for targeted image synthesis by conditioning the generation process on specific attributes or conditions, such as class labels, semantics, or textual descriptions [18, 24, 27, 41, 53, 56]. Similarly, few models have developed relying on conditional GANS to generate floor layouts from a zoning diagram [29, 50]. Lately, the field of image generation has witnessed remarkable advancements with the emergence of diffusion models [8, 36, 44, 62]. These models have demonstrated ex-"}, {"title": "3. Methodology", "content": "The concept of the proposed model is to allow planners and designers to generate a floorplan representation based on two given conditions: representing the building's footprint and a text briefing explaining the aimed design. The goal is to create a scale-agnostic model that, given the stated conditions, can adapt to generate a floorplan based on learning the specifics that correspond to a given building's type (i.e., residential, office building, stadium, etc.) without the scale being explicitly given. The main reason for creating a scale-agnostic model is to allow users to iteratively explore design options based on different architectural programs for a given footprint without worrying about calculating dimensionality and scale representation.\nWe propose a Latent Diffusion Model (LDM) that outputs an image x \u2208 Rh\u00d7w\u00d7c given two conditions: a design brief as a text prompt y1 and a building's footprint in the form of an image y2. The conditional distribution can be expressed in the form of p(x|Y1, Y2). To do so, the model architecture involves two main stages; a diffusion mode conditioned based on the first condition, and an additional training procedure to constrain and further condition the trained model in the first state based on the second condition. Fig. 2 shows the overall architecture of the proposed model.\nAt the first stage, a given image sample x is passed through a diffusion process of t steps by introducing a Gaussian noise at each t step, given that t is sampled from {1,...,T}, to generate a latent space zt. x is encoded to a latent space z\u0142 by a probabilistic encoder, and then it is decoded back to the original space by a probabilistic decoder. zt is represented as a probability distribution, typically Gaussian:\nq\u00a2(zt|x) = N(z; \u03bc(x), \u03c3\u00b2(x)I) \\tag{1}"}, {"title": "3.1. Model Concept and Utility", "content": null}, {"title": "3.2. Objective Loss", "content": "In the first stage, the model focuses on learning both the temporal function Te and the noise model e\u0398 conditioned on a single context, such as text prompts y1. The loss function LLDM that is optimized during this stage is given by:\nLLDM := EE(x),y1,\u20ac~N(0,1),t[||\u20ac-\u20ac\u0473(zt, t, To(Y1))||2] \\tag{5}\nwhere E(x) stands for the encoder function that maps the observed data x to the latent space, zt is the latent variable at time t, and e is sampled from a Gaussian distribution N(0, 1).\nIn the second stage, the model learns to condition its noise model es on multiple contexts, namely the text prompts y1 and additional information like the building's footprint y2. The overall learning objective L for this stage is:\nL = Ezo,t,y1,42,\u20ac~N(0,1) [||\u20ac \u2013 \u20ac9(zt, t, Y1, Y2) ||2] \\tag{6}\nThe difference between L and LLDM is the inclusion of the second condition y2. Here, 20 denotes the initial latent state, zt the latent state at time t, and again e is sampled from N(0, 1). This two-stage process allows the model to initially adapt to simpler conditions and then extend its capabilities to more complex, multiple conditional inputs. The model's parameters are jointly optimised to minimise the respective loss functions during each training stage. By using this approach, the conditional latent diffusion model aims to provide a nuanced representation that can be adapted based on various conditions, thereby increasing its versatility and applicability across different tasks and data types."}, {"title": "4. Experiments and ablation study", "content": "We conducted multiple experiments focused on enhancing image fidelity. The findings from these investigations are encapsulated in the models we present here, which exhibit superior performance in delivering high-quality images.\nDatasets: The first stage is trained on 400 million text-to-image synthesis using LAION dataset [46], whereas the second stage is trained in our newly collected dataset. While there are datasets that focuses on generating residdential floorplans from semantics [50], to the best of our knowledge, currently, there is no existing dataset that encompasses all three elements of a textual description of design, footprint, and the final design of a floor plan. As a result, we took the initiative to create our own dataset, which consists of 500 pairs of images and corresponding text prompts. Each sample comprises three distinct components: 1) a mask image that visually represents the designated shape for the building's footprint, 2) a text prompt that serves as a concise brief for the intended floor plan design, and 3) a high-quality floor plan that represents the ultimate output of our model. The first two components serve as the input for our model, while the third component represents the output generated by the model. To compile this dataset, we gathered floor plans from various sources on the internet. Additionally, we manually labelled each floor plan to accurately depict the corresponding footprint using mask images and to provide a concise description of the design based on the architectural expertise of our labellers. Fig. 3 shows a diverse selection of data samples obtained from our dataset. It showcases the wide range of footprints alongside various building types, highlighting the variability within our collected data.\nEvaluation Metrics: We employed both quantitative and qualitative methods to assess the logic and excellence of the produced images [3, 44, 56]. Although it's typical to calculate quantitative metrics like Fr\u00e9chet Inception Distance (FID) [61], Kernel Inception Distance (KID) [3, 4], Structural Similarity Index (SSIM) [55] and Signal-to-Noise Ratio (PSNR) score [9], the objective of producing multiple samples for identical inputs makes it challenging to evalu-"}, {"title": "Generating floorplans based on functionality", "content": "Investigating the outcomes of our trained model in Fig. 6, we unveil the achievements in generating diverse floor plans catering to distinct design briefs and footprints. The visual representations presented therein not only underscore the"}, {"title": "Scale-agnostic approach", "content": "Undertaking a scale-agnostic approach, our introduced method transcends conventional limitations imposed by fixed scales. This innovative paradigm empowers our approach to seamlessly adapt to diverse scales, accommodating the design needs spanning from small-scale to large-scale building types (See Fig. 6). The introduced method relies on a ratio-based driven approach, harnessing the inherent relationships between architectural components to guide the design process. Just as humans, when they learn to design, are able to adapt to different design briefs and building functionalities, our approach capitalises on the adaptability innate to the human design process.\nBy leveraging the intrinsic proportions and ratios that underpin well-balanced designs across various buildings functionalities, we facilitate the creation of harmonious and aes-"}, {"title": "Latent space (zt) visualisation", "content": "To foster a deeper understanding of our model and advance the cause of explainable AI, we present a visualisation of our model's latent space ((zt)) in Fig. 12. This space is based on 1600 distinct generated outputs, resulting from various input forms and text prompts characterising different building functionalities. By applying Principal Component Analysis (PCA) to reduce the dimensionality of these embeddings\u2014and without prior knowledge of specific input labels such as 'area', 'office', or 'stadium'\u2014this figure demonstrates the model's capability to project embeddings that capture the nuances of building functionality. For example, it discerns the similarity between an arena's design and that of a stadium, or between a one-bedroom and a two-bedroom apartment. It also observes the affinity between the designs of office buildings and libraries. Furthermore, the model presents the design of a studio (a singular room) as a foundational design, exhibiting proximity to various other building functionalities. Such insights emphasise the model's exceptional skill in data representation and its inherent sense of the relational closeness among diverse design principles."}, {"title": "Image fidelity and denoising steps", "content": "Figure 13 sheds light on the intricate connection between image fidelity and the denoising steps inherent in our model. These steps guide the transition from noisy starting points to polished images. The number of steps plays a pivotal role, impacting the depth of transformations. An increased number of steps"}, {"title": "Comparing the results to baselines", "content": "In Fig. 14, we present a comparative analysis, juxtaposing the outcomes of our model against one of the state-of-the-art text-to-image foundational models and cutting-edge AI tools. This comparison highlights the existing challenges in generating floorplans, specifically regarding inconsistencies in quality and style. The significance of our contributions is empirically underscored by this demonstration. The ability to consistently imbue floorplans with a distinct architectural style not only sets our model apart but also accentuates its pioneering position within the landscape of state-of-the-art"}, {"title": "5. Conclusion", "content": "In this paper, we introduce a method for an AI-generative floorplan driven by a latent diffusion model. Unlike traditional architectural design processes, which are labour-intensive and rely heavily on architectural expertise, our model redefines floorplan creation. It not only replicates existing designs but also generates entirely new configurations by learning from diverse building types and architectural design variations. A key feature of our model is its inherent scale adaptability, effortlessly adjusting floorplan scale based on input footprints. This adaptability enhances versatility, enabling architects to design structures of varying sizes and footprint, from single houses to complex public buildings, without scale constraints. Importantly, our model surpasses the limitations of existing AI models for generated floorplans, which predominantly focus on residential functionalities. In contrast, our model extends its capabilities to various functionalities, providing architects with a comprehensive toolset for a wide range of design scenarios. Our research empowers architects to transcend traditional constraints, explore novel design solutions, and address diverse architectural needs."}, {"title": "6. Supplementary Material", "content": "We followed closely the implementation of latent diffusion described by [44, 62]. At the first stage of our method, we leveraged the existing pretrained weights for a diffusion model trained on LAION dataset [46] for text-to-image generation [44]. At the second stage, there are several training procedures that we undertook to synergise image, building form input, and textual prompt as follows:\nGenerator implementations: We used a Spatial Control Mechanism to infuse spatial inductive biases into our framework. With spatial transformers, it modulates image features based on: x' = Ax + t where x' is the adjusted position, x is the original, A is the transformation matrix, and t is the translation vector. We combined the U-Nets with additional transformer layers as previously described in methodology and in our experiments we used one layer to enhance the model's contextual understanding based on the described attention mechanism. During training the images are processed at a resolution of 64x64 and upsampled to 512X512 at inference. The architecture further ensures that the conditioning stage remains non-trainable, utilising cross-attention based on the conditioning building's form. We monitoried performance via validation loss metric. Diving deeper into the control mechanism, the ControlNet is configured to accept inputs with 4 channels, complemented by a 3 channel text prompts. This network harnesses 320 model channels, with attention mechanism designed across resolutions [4, 2, 1] and a transformer depth of 1.\nLatent Space Modelling: To model the generative latent space, we used Autoencoder architecture introduced by [62] to project multi-modal data into a unified latent space, characterised by encoding function f(x) and decoding mechanism g, its primary objective defined as: L(x, g(f(x))) ensuring the latent representation's fidelity to the original data. The Autoencoder undertakes initial processing, embracing an embedding dimension of 4 and operating at 256x256 resolution with a layered approach of 3 input channels, 4 latent space z-channels, and 3 output channels for the generated image.\nTextual Embeddings: Leveraging the robustness of the OpenCLIP model [47], we createdd a frozen OpenCLIP embedder to transfrom texts into textual embeddings. This pre-trained module assists in integrating textual content into the introduced framework, ensuring the embedding mechanism remains static during the training process.\nTraining Paradigm: Trained models are resumed from pre-trained checkpoints of the first-stage. The training regimen is executed with 32-bit precision, with batch size 1, and training cycles 429 epochs. We used Adam [23] optimiser to train our model with a learning rate that progresses linearly across timesteps. Specifically, the learning rate is initiated at a rate of 0.00085 and culminating at 0.0120. Over its span of 1000 timesteps, periodic logs are captured every 200 timesteps."}, {"title": "6.1. Training and implementation details", "content": null}, {"title": "6.2. Floorplan evaluation tool", "content": null}, {"title": "6.3. High-resolution images", "content": null}, {"title": "6.4. Prompt engineering", "content": "Prompt engineering plays a pivotal role in elevating the quality of generated images through precise and strategic manipulation of input prompts [28, 52, 64]. This technique involves fine-tuning the textual or input prompts provided to generative models, with the aim of steering the output towards desired visual outcomes. By carefully crafting prompts that encapsulate specific visual details, styles, or attributes, users can effectively guide the model's creative process. By tailoring prompts to emphasize certain features, textures, or compositions, the generative model becomes more attuned to the creator's intent. Consequently, the resulting images exhibit heightened fidelity to the envisioned aesthetics. Based on your experiments, we found that even subtle modifications to the provided prompt can wield over the quality of the generated image. our experiments showed that simple adjustments to the wording, context, or emphasis within the prompt can trigger nuanced shifts in the generative model's output. By crafting prompts that encapsulate not only visual specifics but also stylistic preferences, the user can effectively guide the model's interpretive process. As a result, the generated images exhibit an elevated level of alignment with the desired aesthetics."}]}