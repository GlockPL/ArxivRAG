{"title": "LLM4AD: A Platform for Algorithm Design with Large Language Model", "authors": ["Fei Liu", "Rui Zhang", "Zhuoliang Xie", "Rui Sun", "Kai Li", "Xi Lin", "Zhenkun Wang", "Zhichao Lu", "Qingfu Zhang"], "abstract": "We introduce LLM4AD, a unified Python platform for algorithm design (AD) with large language models (LLMs). LLM4AD is a generic framework with modularized blocks for search methods, algorithm design tasks, and LLM interface. The platform integrates numerous key methods and supports a wide range of algorithm design tasks across various domains including optimization, machine learning, and scientific discovery. We have also designed a unified evaluation sandbox to ensure a secure and robust assessment of algorithms. Additionally, we have compiled a comprehensive suite of support resources, including tutorials, examples, a user manual, online resources, and a dedicated graphical user interface (GUI) to enhance the usage of LLM4AD. We believe this platform will serve as a valuable tool for fostering future development in the merging research direction of LLM-assisted algorithm design.", "sections": [{"title": "1 Introduction", "content": "Algorithms are pivotal in solving diverse problems across various fields such as industry, economics, healthcare, and technology (Kleinberg, 2006; Cormen et al., 2022). Traditionally, algorithm design has been a labor-intensive process requiring deep expertise. In the last three years, the use of large language models for algorithm design (LLM4AD) has emerged as a promising research area with the potential to fundamentally transform how algorithms are designed, optimized, and implemented (Liu et al., 2024b). The remarkable capabilities and flexibility of LLMs have shown potential in enhancing the algorithm design process, including performance prediction (Hao et al., 2024), heuristic generation (Liu et al., 2024a), code optimization (Hemberg et al., 2024), and even the creation of new algorithmic concepts (Girotra et al., 2023). This approach not only reduces the human effort required in the design phase but also boosts the creativity and efficiency of the solutions produced (Liu et al., 2024a; Romera-Paredes et al., 2024).\nDespite the rapid emergence of LLM4AD methods (Liu et al., 2024b) and the expanding range of application domains (Romera-Paredes et al., 2024; Liu et al., 2024a; Ye et al., 2024; Yao et al., 2024b; Guo et al., 2024a,b), this area faces three challenges:\n1. Lack of an easy-to-use toolkit and platform. It is difficult for researchers from diverse backgrounds to conduct studies at this intersection, as they need to address issues from both LLMs and algorithm design and implement their own code.\n2. Lack of a generic implementation pipeline. Existing works are implemented using different pipelines and programming languages. There are inconsistencies such as varied running times and LLMs queries.\n3. Lack of benchmarks specifically for LLM-assisted algorithm design. Existing works either compare selected instances or propose their own algorithm design tasks. Even when compared on the same tasks, different prompt engineering or templates can be used, leading to varied performance. A unified benchmark with a proper template and default settings would enable fair comparisons.\nThis paper introduces LLM4AD, a unified Python library for LLM-based algorithm design that addresses these gaps. The platform integrates numerous key methods and supports a wide range of algorithm design tasks across various domains, including optimization, machine learning, and scientific discovery. We have also designed a unified evaluation sandbox to ensure a secure and robust assessment of algorithms. Additionally, we have compiled a comprehensive suite of support resources, including tutorials, examples, a user manual, online resources, and a graphical user interface (GUI) to enhance the usability of LLM4AD. We believe this platform will serve as a valuable tool by fostering usage and comparison in the emerging research direction on LLM-based algorithm design. The code is available at: https://github.com/Optima-CityU/LLM4AD."}, {"title": "2 LLM4AD", "content": "As illustrated in Figure 1, the platform consists of three blocks: 1) Search methods, 2) LLM interface, and 3) Task evaluation interface.\n\u2022 Search methods: We build the pipeline with an iterative search framework, in which a population is maintained and elite algorithms are survived.\nMultiple Objectives: The task of designing algorithms may involve one or more objectives, such as optimizing performance and efficiency. Our approach incorporates both single-objective and multi-objective search methods.\nPopulation Size: In many search methods, e.g., neighbourhood search methods, the population size can be set to one."}, {"title": "2.1 Framework", "content": "LLMs are guided by prompts to create new algorithms. These LLMs can be utilized either locally or remotely, with a unified interface available for both options. To enhance efficiency, we have implemented parallelization in the sampling process."}, {"title": "2.2 Usage", "content": "In each generation, algorithms for a specific problem are assessed on a set of instances on the target algorithm design task and given a fitness score. Our evaluation sandbox guarantees a secure, effective, and manageable evaluation process for various problems and implementations."}, {"title": "2.2.1 SCRIPT USAGE", "content": "\u2022 Import method, tasks, and llm interface.\n\u2022 LLM interface initialization: Set up host endpoint, key and llm.\n\u2022 Task evaluation interface initialization: Initialize the evaluation interface with settings to manage the evaluation process, e.g., maximum wall-clock time for each evaluation.\n\u2022 Search method initialization: Set up the Profiler and parameters. Pass LLM and Task interfaces into the search procedure."}, {"title": "2.2.2 GUI USAGE", "content": "LLM4AD provides an easy-to-use graphical user interface (GUI). Through this GUI, users can easily configure settings, execute experiments, and monitor results without any coding knowledge. This interface simplifies user interaction, making the LLM4AD platform more accessible and easier to use.\nThe GUI is launched by executing the run_gui.py Python script. As shown in Figure 2, the main window of GUI includes six components: 1): Menu bar; 2): Configuration panel; 3): Results dashboard; 4): Run button; 5): Stop button; 6): Log files button.\nThe Menu bar offers quick access to various resources, such as documentation or the website of the LLM4AD platform, through clickable buttons that redirect users to the relevant pages. To conduct experiments via the GUI, users should\n\u2022 Set up LLM interface. Set up the parameters of the LLM interface in the Configuration panel. These parameters include the internet protocol (IP) address of the application programming interface (API) provider, an API key, and the name of the LLM."}, {"title": "2.3 Search Methods", "content": "Search methods are crucial for effective LLM-based algorithm design. Recent studies have shown that standalone LLMs, even when enhanced with various prompt engineering techniques, are often insufficient for many algorithm design tasks (Zhang et al., 2024a). We have integrated a variety of search methods, including simple sampling, commonly used single-objective evolutionary search methods, multi-objective evolutionary search, and various neighborhood searches."}, {"title": "\u2022 Single-objective Search", "content": "Sampling: repeated sampling.\nNeighborhood search: tabu search, iterated local search, simulated annealing, variable neighbourhood search.\nEvolutionary search: EoH (Liu et al., 2024a), FunSearch (Romera-Paredes et al., 2024), (1+1)-EPS (Zhang et al., 2024a)\n\u2022 Multi-objective Search\nMulti-objective evolutionary search: MEoH (Yao et al., 2024a), NSGA-II (Deb et al., 2002), MOEA/D (Zhang and Li, 2007)\nAn abstract base method is provided to modularize the essential format and functions of these methods, maintaining flexibility to facilitate easy extension and implementation of custom search methods by users.\nEach method is equipped with three profilers: 1) base profiler, 2) Tensorboard profiler, and 3) Weights & Biases (wandb) profiler, to meet diverse user requirements."}, {"title": "2.4 Evaluation Interface and Tasks", "content": "As illustrated in Figure 1, LLM4AD is applicable to a broad range of algorithm design domains including\n\u2022 Optimization: combinatorial optimization (Liu et al., 2024a; Ye et al., 2024), continuous optimization, surrogate-based optimization (Yao et al., 2024b).\n\u2022 Machine learning: agent design (Hu et al., 2024), computer vision (Guo et al., 2024a).\n\u2022 Science discovery: biology (Shojaee et al., 2024), chemistry, physics, fluid dynamics (Zhang et al., 2024b) and Feynman Equation (Matsubara et al., 2022).\n\u2022 Others: game theory, mathematics (Romera-Paredes et al., 2024), etc.\nAs illustrated in Table 1, the platform includes a diverse collection of over 20 tasks (there will be 160+ tasks soon) from various domains such as optimization, machine learning, and scientific discovery. These tasks are quick to evaluate and have clearly defined formulations for easy comparison."}, {"title": "2.4.2 EXAMPLES", "content": "We also offer a variety set of example algorithm design tasks. These examples are used for 1) demonstrating different settings and 2) showcasing more complex tasks on local algorithm design tasks."}, {"title": "2.4.3 EVALUATION SANDBOX", "content": "A secure evaluation sandbox is provided, enabling the safe and configurable evaluation of generated code. This includes optional optimizations and safety features such as timeout handling and protected division."}, {"title": "2.5 LLM Interface", "content": "We have provided a general LLM interface tailored for iterative algorithm search. This interface supports two types of demo interactions:\n\u2022 Remote API interaction: We offer OPENAI format API interaction, suitable for most LLM API requests.\n\u2022 Local deployment: A guide and template for local open-source LLM deployment are provided.\nBoth interfaces are modularized to ensure efficiency and control, with features including parallel processing, time control, and failure detection."}, {"title": "3 Benchmark Results", "content": "We choose four search methods in our platform with consistent benchmark settings. We initialize all compared methods with the respective template algorithm on each problem. \nWe investigate a subset of nine algorithm design tasks provided by our platform, encompassing machine learning, combinatorial optimization, and scientific discovery scenarios.\nWe use a diverse set of eight open-source and closed-source general-purposed LLMs, i.e., Llama-3.1-8B, Yi-34b-Chat, GLM-3-Turbo, Claude-3-Haiku, Doubao-pro-4k, GPT-3.5-Turbo, GPT-40-Mini, and Qwen-Turbo, and compare their results on nine automated algorithm design tasks."}, {"title": "3.1 Settings", "content": "https://llm4ad-doc.readthedocs.io/en/latest/"}, {"title": "3.2 Results on Different Tasks", "content": "Fig. 3 demonstrates the convergence curve of the performance of the top-1 algorithms generated by GPT-40-Mini. The performance is measured by the objective score on each task. The mean and standard deviation performance over three independent runs are denoted as markers and shaded areas, respectively. We draw observations from the experimental results that:\n\u2022 LLM4AD is applicable to diverse algorithm design tasks and application scenarios.\n\u2022 Methods coupled with a search strategy, \u0456.\u0435., \u0415\u043e\u041d, (1+1)-EPS, and FunSearch, significantly outperform random sampling on most tasks. This underscores the importance of synergizing LLMs with search.\n\u2022 All tested methods demonstrate marginal performance variations on the Mountain Car problem. However, there is a noticeable performance gap between different methods on OSC, SET, TSP, and VRPTW problems. This reveals that tasks provided in our platform have different difficulties.\n\u2022 EoH and FunSearch exhibit better performance on most tasks due to their inherent diversity control mechanism. While the performance of (1+1)-EPS variants significantly across different tasks due to its greedy nature.\n\u2022 LLM4AD provides useful tools and APIs to help code manipulation, secure evaluation, and task definition. Besides, LLM4AD has released elaborated documents as well as jupyter-notebooks for each module, aiming to demonstrate and visualize the functionality and effect of each module and each API. We believe this will foster in-depth comprehension of our search and code-manipulating pipeline."}, {"title": "3.3 Results with Different LLMS", "content": "Fig. 4 and Fog. 5 compare the performance of various LLMs on three tasks. We can summarize from the results that:\n\u2022 LLM4AD can easily integrate open- and close-source LLMs with different capabilities.\n\u2022 There are significant variances in performance attributable to the choice of LLM on three tasks, with the notable exception of the CAR problem where this variance is marginal.\n\u2022 LLMs with more coding capability (denoted by a better HumanEval score as demonstrated in Table 4) do not necessarily lead to better performance on AD problems.\n\u2022 No single LLM exhibits notable superiority over others, as the standard deviations are overlapped in Fig. 4. This indicates that our platform supports a diverse set of LLMs."}, {"title": "4 Extensibility", "content": "LLM4AD platform encourages users to perform further optimization and customization to existing algorithm design methods. Our support for developers can be summarized in two perspectives as follows:\n\u2022 LLM4AD has fully open-sourced code implementations for various evolutionary search-based algorithm design methods for reference. The source code incorporates implementations of various population management strategies such as genetic algorithm (implemented in EoH), island model (implemented in FunSearch), and 1+1 search (implemented in (1+1)-EPS)). In addition, LLM4AD has integrated diverse test cases (algorithm design tasks) and LLMs with unified interfaces, enabling prompt validation and debugging during development."}, {"title": "4.1 Add New Methods", "content": "LLM4AD is designed to be easily applicable to customized algorithm design tasks and has unified the evaluation interface for each algorithm design task. There are two major steps to apply LLM4AD to a specified algorithm design task:\n\u2022 Extend the llm4ad.base.Evaluation interface class and override the evaluate_program() method, which defines how to measure the objective score of a searched algorithm. Users can also restrict the timeout seconds during evaluation and perform numba.jit acceleration through setting the corresponding arguments.\n\u2022 Specify an executable template program that comprises Python packages import, a function call with input/output types, a doc-string with the exact meaning of each argument, and a function body to show an example implementation. Since the tem-"}, {"title": "4.2 Add New Tasks", "content": "plate program will be assembled to the prompt content in the search process later, providing informative and precise doc-string is therefore required.\nOnce the modified evaluation instance is passed into the search method, LLM4AD will automatically invoke the specified evaluation method and perform a secure evaluation (prevent algorithms that may be harmful to the search pipeline, e.g., abort the search or endless loop) of each algorithm code."}, {"title": "4.3 Add New LLM Sampler", "content": "A sampler defines and specifies the method to access an LLM. For instance, users can choose to either query remote LLMs (e.g., GPT-40) using HTTPS requests, or infer a locally deployed LLM using inference libraries (e.g., transformers, and vLLM). To increase the extensibility of samplers, LLM4AD defines an interface llm4ad.base.Sampler where the draw_sample() function leaves unimplemented. Users are able to customize their sampler by overriding the method and passing the user-defined-sampler instance to a search method."}, {"title": "5 Conclusion", "content": "In conclusion, LLM4AD stands as a comprehensive and unified Python platform tailored for the design of algorithms using large language models. It features a generic framework with modularized components, including search methods, algorithm design tasks, and an LLM interface, catering to a broad spectrum of domains such as optimization, machine learning, and scientific discovery. The platform is enriched with a robust evaluation sandbox to ensure secure and reliable algorithm assessment, alongside a wealth of support resources like tutorials, examples, a user manual, online resources, and a dedicated GUI. These elements collectively enhance the user experience and utility of LLM4AD. We are confident that LLM4AD will significantly contribute to the advancement and standardization of LLM-based algorithm design, promoting extensive usage and facilitating comparative research in this emerging field. Through these efforts, LLM4AD aims to accelerate innovation and exploration in algorithm design, leveraging the capabilities of large language models."}]}