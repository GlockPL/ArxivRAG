{"title": "Analysis of a Memcapacitor-Based for Neural Network Accelerator Framework", "authors": ["Ankur Singh", "Dowon Kim", "Byung-Geun Lee"], "abstract": "Data-intensive computing tasks, such as training neural networks, are crucial for artificial intelligence\napplications but often come with high energy demands. One promising solution is to develop specialized hardware\nthat directly maps neural networks, utilizing arrays of memristive devices to perform parallel multiply-accumulate\noperations. In our research, we introduce a novel CMOS-based memcapacitor circuit validated using the cadence\ntool. Additionally, we developed the device in Python to facilitate the design of a memcapacitive-based accelerator.\nOur proposed framework employs a crossbar array of memcapacitor devices to train a neural network capable of\ndigit classification and CIFAR dataset recognition. We tested the non-ideal characteristics of the constructed\nmemcapacitor-based neural network. The system achieved an impressive 98.4% training accuracy in digit\nrecognition and 94.4% training accuracy in CIFAR recognition, highlighting its effectiveness. This study\ndemonstrates the potential of memcapacitor-based neural network systems in handling classification tasks and\nsets the stage for further advancements in neuromorphic computing.", "sections": [{"title": "1. Introduction", "content": "Memelements have emerged as a promising class of devices, demonstrating remarkable performance, particularly\nwhen deployed in crossbar architectures [1-3]. Their integration into these structures significantly enhances the\nefficiency of vector-matrix multiplication (VMM) by enabling the parallel execution of product and summation\noperations through the devices. This capability is particularly beneficial in the domain of convolutional neural\nnetworks (CNNs), where extensive matrix operations are fundamental to both training and inference processes.\nThe combination of in-memory computing (IMC) architectures with the adjustable analog memductance of\nmemelements further contributes to power-efficient VMM and training, enabling the development of highly\nintegrated memory architectures. Consequently, a wide array of CNN hardware designs utilizing memelements-\nbased VMM accelerators [3-6] has been proposed, with their effectiveness consistently demonstrated in various\nstudies.\nNeuromorphic computing, modeled after brain-like processes and grounded in artificial neural networks, presents\neffective solutions for a wide range of computationally demanding tasks. Originally conceptualized in the 1980s\n[7-8], this field has seen substantial progress with the advent of memristive devices [9] and the introduction of\nconvolutional layers in deep neural networks [10-11]. These innovations have facilitated the development of\nvarious resistive neuromorphic systems that employ materials such as oxides [12-14], phase-change memory [15],\nspintronic devices [16-17], and ferroelectric components, including ferroelectric tunnel junctions [18-19] and\nferroelectric field-effect transistors (FeFETs) [20-21]. Among these, devices like ferroelectric tunnel junctions\nand silicon-oxide-nitride-oxide-silicon (SONOS) transistors have achieved remarkable energy efficiencies,\nreaching up to 100 tera-operations per second per watt (TOPS/W) [22]. These neuromorphic systems operate by\nstoring synaptic weights in analog form for multiplication tasks, utilizing Kirchhoff's current law to sum currents\nthrough crossbar arrays.\nMemcapacitive devices, akin to memristive devices but operating on a capacitive principle, hold the promise of\nlower static power consumption [23]. While theoretical models for memcapacitive devices have been extensively\nexplored [23-27], practical implementations remain relatively scarce [28-31]. These devices can be realized"}, {"title": "2. Proposed Memcapacitor Device", "content": "2.1 CMOS based model\nThe memcapacitor represents the relationship between the time integral of charge and flux, defined by the inverse\nmemcapacitance function Mc(q), with constants a and \u03b2. The mathematical model of a charge-controlled\nmemcapacitor is expressed as follows [33]."}, {"title": "2.1 CMOS based model", "content": "Mc =\\frac{Vin(t)}{q(t)} = \u03b2\u00b1\u03b1\u03c3(t)"}, {"title": "2.1 CMOS based model", "content": "The emulator proposed in this work comprises three functional blocks: two operational transconductance\namplifiers (OTA) and a buffer. These blocks are interconnected to achieve the desired memcapacitor characteristic,\nwhich relates the input voltage Vin to the charge q(t). The overall design of the memcapacitor emulator is\nillustrated in Fig. 1 [34]. In this design, the body terminals of all PMOS and NMOS transistors are connected to\nVDD and Vss, respectively. The port characteristics of the OTA [35] can be mathematically defined by the\nfollowing equations:"}, {"title": "2.1 CMOS based model", "content": "Io = gmi (Vpi-Vni)"}, {"title": "2.1 CMOS based model", "content": "where gmi, Vpi, and Vni represents the transconductance gain and input voltage of each OTA. The routine analysis\nyields the following expression for gm:"}, {"title": "2.1 CMOS based model", "content": "gmi = K (Vbi -VSS\nth"}, {"title": "2.1 CMOS based model", "content": "Where \"i\" is the OTA number, Vss is the supply voltage of the OTA, Vth is the threshold voltage of MOSFET\ndevice and \"K\" is a parameter of the MOSFET device given by"}, {"title": "2.1 CMOS based model", "content": "K = \u00b5\u201eCox \\frac{W}{L}"}, {"title": "2.1 CMOS based model", "content": "In this formulation, W represents the channel width, L denotes the channel length, un is the mobility of the carrier,\nand Cox refers to the oxide capacitance per unit area in the MOSFET.\nThe detailed working principle of the proposed emulator is analyzed through these functional blocks. OTA-1 and\nOTA-2, both OTAs, are crucial in defining the dynamic relationship between the charge and the flux. OTA-3, \u0430\nbuffer, ensures proper signal conditioning and stability of the emulator output. This configuration effectively\nreplicates the theoretical behavior of a memcapacitor, providing a practical and implementable circuit design. The\nanalysis shows how the integration of these blocks results in the desired emulation between the input voltage and\nthe resulting charge over time.\nIn OTA-1, the positive terminal of the input signal VinP is connected. It is important to note that Vin's positive\nand negative terminals are labelled VinP and VinN, respectively. The transistors M12 and M13 form an input\ndifferential pair and are biased by the current sink transistor M14, as illustrated in Fig. 1 for OTA-1. This\nfunctional block converts the differential voltage into a current, as described below."}, {"title": "2.1 CMOS based model", "content": "Iot = gml(VinP-Vn1)"}, {"title": "2.1 CMOS based model", "content": "Iot = gmlVinP"}, {"title": "2.1 CMOS based model", "content": "In this configuration, gm1 represents the transconductance of OTA-1, with Vn1 grounded as depicted in Figure 1.\nFunctional Block-3 functions as a buffer, where the input signal is applied to the gate of transistor M23.\nMeanwhile, the gate of transistor M22 is connected to its drain terminal, establishing a negative feedback loop as\nillustrated in Figure 1. The corresponding analytical model for Functional Block-3 is provided below."}, {"title": "2.1 CMOS based model", "content": "I22 = 822 (Vp; \u2212 V x ) = g23 (Vy -Vx)"}, {"title": "2.1 CMOS based model", "content": "Given that g22=g23, it follows that VP-VN'. Consequently, VN' at the output terminal mirrors the input VP', which\nis essential for ensuring the reliable operation of the proposed emulator.\nThe behaviour of the memcapacitor is demonstrated through the analysis of the functional blocks shown in Fig.\n1. A sinusoidal input signal is applied to the proposed emulator between Vinp and Vinn, as illustrated below."}, {"title": "2.1 CMOS based model", "content": "V. = V.\nin inP inN"}, {"title": "2.1 CMOS based model", "content": "In the proposed design, a sinusoidal signal is applied to Vin across C1, causing the input current (Iin) to flow through\nit. The voltage across C\u2081 is mathematically expressed as follows."}, {"title": "2.1 CMOS based model", "content": "Vc\u2081 =Vinp =\\frac{1}{C_1}\u222b I_i dt = \\frac{q(t)}{C_1}"}, {"title": "2.1 CMOS based model", "content": "The output current of OTA-1 is (gm1*q(t))/C1. The output terminal of OTA is connected to V62 of OTA-2, which\nis the voltage across C2 and can be expressed as,"}, {"title": "2.1 CMOS based model", "content": "Vc\u2081 =Vb2 = \\frac{gml}{C2}\u222b Vinpdt = \\frac{gml q(t)}{C C\u2082}"}, {"title": "2.1 CMOS based model", "content": "Changing C2 alters V62 due to the variation in charge, where V62 can be referred to as the charge control voltage.\nUpon analyzing OTA-2, the output current can be expressed by the following equation."}, {"title": "2.1 CMOS based model", "content": "I = 8m2(Vp2-Vn2)"}, {"title": "2.1 CMOS based model", "content": "I = 8m2VinP"}, {"title": "2.1 CMOS based model", "content": "The above current flows through R generating a voltage VR as shown below:"}, {"title": "2.1 CMOS based model", "content": "VR = IR"}, {"title": "2.1 CMOS based model", "content": "VR = 8m2VinPR"}, {"title": "2.1 CMOS based model", "content": "Substituting V62 depicted in eq. 8 in eq. 3, gm2 can be expressed as:"}, {"title": "2.1 CMOS based model", "content": "8m2 = K \\frac{8ml\\frac{q(t)}{CC\u2082}-Vss-Vth}{VinP}"}, {"title": "2.1 CMOS based model", "content": "Now putting eq. 11 into eq. 10 and VR = VP` = VN from the buffer, we get"}, {"title": "2.1 CMOS based model", "content": "VR=VP=VinN =\\frac{q(t)}{C} -\\frac{q(t)RK}{C}\\[\\frac{8ml\\frac{q(t)}{CC\u2082}-Vss-Vth}{C}"}, {"title": "2.1 CMOS based model", "content": "Consequently, by Substituting eq. 12 into 6, the corresponding memcapacitance can be calculated as follows"}, {"title": "2.1 CMOS based model", "content": "Vin(t) = \\frac{q(t)}{C} -\\frac{q(t)RK}{C}\\[\\frac{8ml\\frac{q(t)}{CC\u2082}-Vss-Vth}{C}"}, {"title": "2.1 CMOS based model", "content": "Mc = \\frac{V}{q(t)} = \\[1+\\frac{Vs+V}{C}+\\frac{Vs+V}{C}-\\frac{RK8ml\\frac{q(t)}{CC\u2082}\\]"}, {"title": "2.1 CMOS based model", "content": "The proposed design features a meminductor model, initiating with a memcapacitance value calculated as\n[(1/C1)(1+Vss+Vth)] according to the formula provided above. The rate at which the capacitance changes is\ndetermined by[((RK/C1)(gm1*\u03c3(t))/C1*C2)]. Here gmlrepresent the transconductance values of the OTA-1 [36].\nThe simulation setup for the proposed work comprises Cadence Virtuoso software on the TSMC 180-\nnmtechnology node. All the simulations were carried out in Analog Design Environment (ADE) window having\n27\u00b0C as the nominal temperature setting and the plot shown in Fig. 2 [37]. Also, the proposed work employs only\na positive power supply i.e., VDD Which is taken to be 1.8V\u0442."}, {"title": "2.1 Memcapacitor spice model", "content": "The proposed memcapacitor circuit is meticulously designed using TSMC 180nm CMOS technology, tailored for\nimplementing vector-matrix multiplication-a fundamental operation in CNN. This circuit leverages the non-\nlinear characteristics of memcapacitors to perform computational tasks typically associated with neuromorphic\ncomputing. The model is built using a combination of NMOS and PMOS transistors with varying channel lengths\nand widths, carefully selected to optimize the circuit's performance in terms of speed, power consumption, and\naccuracy. The circuit architecture involves the strategic placement of MOSFETs (Metal-Oxide-Semiconductor\nField-Effect Transistors) that act as switches, enabling the memcapacitor to store and manipulate charge in a way\nthat emulates synaptic behavior in biological neurons. The SPICE model incorporates three different CMOS\nconfigurations to accommodate the various transistor dimensions required for different stages of the circuit [38].\nAdditionally, passive components like capacitors and resistors are integrated into the design to stabilize the circuit\nand control the flow of current.\nA sinusoidal voltage source is applied as the input to the circuit, with parameters such as amplitude and frequency\nfinely tuned to mimic the dynamic signals encountered in neuromorphic systems [39]. The transient simulation of\nthis circuit is performed using a step-by-step approach, where the time-dependent voltage across different nodes\nis analyzed to verify the memcapacitor's performance. This model is pivotal for simulating the behavior of the\nmemcapacitor in a controlled environment, providing insights into its potential application in energy-efficient,\nhigh-performance neuromorphic computing [40]. To systematically develop and validate the memcapacitor model,\nan algorithm has been structured, as illustrated in Fig. 1. The algorithm outlines the following critical steps for\nimplementing the memcapacitor model in Python."}, {"title": "3. Memcapacitive-based Vector Matrix Multiplication", "content": "The Memcapacitor-based VMM is a novel and promising approach in the field of neuromorphic computing, where\nthe goal is to mimic the way the human brain processes information [41]. In traditional digital systems, VMM is\na core operation in machine learning algorithms, particularly in CNN. However, as these systems scale, the energy\nconsumption and speed of conventional hardware become significant bottlenecks [42]. This is where\nmemcapacitors, with their unique ability to retain information and perform non-linear operations, offer a distinct\nadvantage. Memcapacitors are passive electronic components that combine the properties of memory and\ncapacitance. Unlike traditional capacitors, which store charge linearly, memcapacitors can store different amounts\nof charge based on their history of applied voltage, making them ideal for use in systems that require complex,\nnon-linear operations such as VMM. In a memcapacitive VMM circuit, the stored charge in each memcapacitor\nrepresents the weight of a connection in a neural network, while the input voltage corresponds to the input signals\nof the neurons [43]. This setup allows the circuit to perform multiplication and accumulation in a single step,\nsignificantly reducing the computational overhead. The VMM can be represented mathematically as:"}, {"title": "3. Memcapacitive-based Vector Matrix Multiplication", "content": "(....) = (X\u2081....xm).\\[\\begin{array}{cccc} W_{11} & W_{1n}\\\\ Wm1 & W_{mn}\\end{array}\\]"}, {"title": "3. Memcapacitive-based Vector Matrix Multiplication", "content": "The output vector y is calculated by the inner product of the input vector x and weight matrix w and each element\nof the output vector yi can be expressed as follows:"}, {"title": "3. Memcapacitive-based Vector Matrix Multiplication", "content": "= \u03a3 XkWki"}, {"title": "3. Memcapacitive-based Vector Matrix Multiplication", "content": "In memcapacitor-based VMM, as shown in Fig. 3, the weight matrix is implemented by a crossbar memcapacitor\narray with m-rows and n-columns [44]. The rows and columns of the memcapacitor array are connected to m\ninput pulses and n output, respectively."}, {"title": "4. Results and Discussion", "content": "In this section, we utilized both the MNIST and CIFAR datasets for training and inference within our system. The\nMNIST dataset, a widely recognized benchmark in image processing, consists of 70,000 grayscale images of\nhandwritten digits, each measuring 28 x 28 pixels and representing digits from 0 to 9. For our experiments, we\ndivided this dataset into 40,000 training images and 20,000 testing images [45]. The CIFAR dataset, another\nprominent dataset in the field of machine learning, comprises 60,000 color images divided into 10 classes, with\n50,000 images designated for training and 10,000 for testing [46]. The core of our work involves the meticulous\ndesign of a memcapacitor circuit using TSMC 180nm CMOS technology, as outlined in Algorithm 1, with the\nprimary objective of implementing VMM for image classification tasks. The memcapacitor's ability to store\ndifferent charge levels, which represent the weights in a neural network, is central to this VMM operation. This\ncircuit design is emulated in Python, where we applied the memcapacitor-based model to implement a CNN for\ndigit recognition using the MNIST dataset. The combination of MNIST and CIFAR datasets allowed us to validate\nthe versatility and effectiveness of the proposed system in different image classification scenarios [47].\nIn our proposed neural network architecture, we implemented a 5 x 5 x 5 vector matrix multiplication (VMM)\nutilizing a memcapacitor SPICE model as the first convolutional layer. To optimize computational efficiency, the\nMNIST dataset was resized from its original 28 x 28 dimensions to 20 x 20 pixels before being processed through\nthe memcapacitor-based VMM. As depicted in Fig. 4, this VMM leverages the unique properties of\nmemcapacitors to perform computations, with initial capacitance values determined by Equation 13. During each\ntraining epoch, the VMM weights representing capacitance values were iteratively adjusted to enhance model\nperformance. The processed output from the VMM is subsequently passed through a neural network that includes\nlayers with ReLU activation functions and a dense layer with 64 units, culminating in a softmax output layer for\nimage classification. This method harnesses the computational efficiency of memcapacitor-based VMMs while\nintegrating the adaptability of neural networks, resulting in an effective and accurate image classification\nframework. The training accuracy of 98.4% and a testing accuracy of 94.6% as shown in Fig. 5. The algorithm 2\nis used implement the simulator for classification of MNIST dataset. Additionally, Fig. 6 provides a visual\nrepresentation of the confusion matrix, illustrating the correlation between the true labels and the predicted labels,\nthereby offering insights into the model's performance. Fig. 7 showcases the optimized weights within the\nmemristor crossbar array. These weights are indicative of the learned patterns that enable the model to perform\nwith high accuracy. We further extended our approach to the CIFAR dataset for both training and inference. In\nthis scenario, two convolutional layers were implemented using memcapacitor-based VMM. The first\nconvolutional layer utilized a 5 x 5 x 5 VMM, while the second layer employed a 5 x 5 x 15 VMM configuration,\nas depicted in Fig. 8. These VMM, which leverage the distinct characteristics of memcapacitors, efficiently\nprocessed the input data. The output from these convolutional layers was subsequently fed into a neural network\narchitecture consisting of layers with ReLU activation functions. This was followed by a dense layer with 128\nunits, culminating in a softmax output layer for image classification [48-49]. This approach yielded a training\naccuracy of 94.4% and a testing accuracy of 89.8% as shown in Fig. 9. The algorithm used for this process is\nanalogous to the one employed for the MNIST dataset."}, {"title": "5. Conclusion", "content": "In this research, we have successfully demonstrated the potential of a memcapacitor-based neural network\nframework for data-intensive tasks such as digit classification and image recognition. By leveraging the unique\ncharacteristics of memcapacitors, we were able to design and implement a CMOS-based circuit that not only\nemulates synaptic behavior but also performs vector matrix multiplication (VMM) efficiently. The proposed\nsystem was validated using the MNIST and CIFAR datasets, where it achieved impressive training accuracies of\n98.4% and 94.4%, respectively, highlighting its effectiveness in neuromorphic computing applications. The\nresults of our study indicate that memcapacitor-based systems can significantly reduce the energy demands\nassociated with training and inference in neural networks, making them a viable solution for future AI hardware\ndesigns. The integration of memcapacitor technology within the neural network architecture has proven to\nenhance computational efficiency while maintaining high accuracy, setting a new benchmark for energy-efficient\ncomputing.\nOur work opens the door for further exploration into memcapacitor-based hardware accelerators, particularly in\nthe field of artificial intelligence and neuromorphic computing. Future research can build on these findings by\nexploring the scalability of this approach, the integration with other emerging technologies, and the development\nof more complex neural network architectures. Ultimately, this study underscores the potential of memcapacitor-\nbased systems to revolutionize the design of low-power, high-performance computing devices, paving the way\nfor more sustainable and efficient AI-driven technologies."}]}