{"title": "Semantic Convergence: Harmonizing Recommender Systems via Two-Stage Alignment and Behavioral Semantic Tokenization", "authors": ["Guanghan Li", "Xun Zhang", "Yufei Zhang", "Yifan Yin", "Guojun Yin", "Wei Lin"], "abstract": "Large language models (LLMs), endowed with exceptional reasoning capabilities, are adept at discerning profound user interests from historical behaviors, thereby presenting a promising avenue for the advancement of recommendation systems. However, a notable discrepancy persists between the sparse collaborative semantics typically found in recommendation systems and the dense token representations within LLMs. In our study, we propose a novel framework that harmoniously merges traditional recommendation models with the prowess of LLMs. We initiate this integration by transforming ItemIDs into sequences that align semantically with the LLMs' space, through the proposed Alignment Tokenization module. Additionally, we design a series of specialized supervised learning tasks aimed at aligning collaborative signals with the subtleties of natural language semantics. To ensure practical applicability, we optimize online inference by pre-caching the top-K results for each user, reducing latency and improving efficiency. Extensive experimental evidence indicates that our model markedly improves recall metrics and displays remarkable scalability of recommendation systems.", "sections": [{"title": "Introduction", "content": "Recent advancements in Large Language Models (LLMs) technologies, particularly those exemplified by trailblazing models such as GPT-4, have signified a substantial progression in the sphere. The intersection of these advancements with recommendation technologies has engendered significant intrigue due to the renowned proficiency of LLMs in the area of advanced natural language processing. This confluence suggests a promising trajectory for augmenting semantic comprehension and behavioral inference within recommendation systems.\nNevertheless, the fusion of LLMs with recommendation systems engenders a unique set of complexities. The modality of language token representation in LLMs is fundamentally divergent from the myriad of sparse identifiers employed by traditional recommendation algorithms. This semantic representation disparity precipitates considerable alignment and scalability challenges (Zheng et al. 2023), elements that are crucial for the efficacious implementation of these hybrid systems. Existing methodologies, inclusive of fine-tuning LLMs on user behavior sequences (Zhang et al. 2023; Li et al. 2023) and the integration of supplementary item identifiers into the LLMs (Zhu et al. 2024; Ren et al. 2024), has several limitations as depicted in Figure. 1. Firstly, in existing methods, as shown in (a), the LLM is either used merely as a feature extractor (LLM as feature), where textual information is fed into the LLM to extract semantic features to enhance existing recommendation models. However, this approach may be limited by the incompatibility between the semantic information generated by the LLM and the recommendation models based on behavior information. It also overlooks the LLM's ability to understand user behavior sequences. Alternatively, as illustrated in (b), large-scale item ID sequences are trained into the LLM through instruction fine-tuning. While this method attempts to leverage the LLM's understanding of user behavior sequences, it lacks important textual semantic signals. Moreover, the large-scale item IDs in real industrial environments increase the difficulty of fine-tuning the LLM.\nIn response to these challenges, as shown in (c), we propose an innovative two-stage alignment framework, conceived to synchronize recommendation models with LLMs via a process of semantic convergence. Initially, the proposed Alignment Tokenization Module is entrusted with the translation of item embeddings from recommendation systems into sequences that are semantically congruent with the representations utilized by LLMs. This pivotal step serves to bridge the divide between sparse and dense representations, thereby augmenting the comprehension of user interests. Subsequent to this, we have engineered a series of Alignment Tasks, meticulously crafted to further hone the semantic calibration of LLMs. These tasks strategically leverage the inherent features of recommendation systems, thus enabling LLMs to more astutely discern user interests across a variety of domains. Our framework, which integrates harmoniously with extant systems, has achieved substantial progress in improving recommendation metrics and scalability.\nOur contributions can be encapsulated as follows:\n1) A two-stage recommendation system is designed with LLMs, effectively aligning the semantics of both behavior and language signals.\n2) A novel methodology has been devised to map the product ID representation, derived from the recommendation system, to a sequential representation that can undergo further training with any LLM structure or traditional recommendation model.\n3) We propose several fine-tuning tasks for LLM, which includes Sequential alignment, text alignment, and negative sampling strategies. This approach effectively models user interests and enhances the robustness of the task."}, {"title": "Related Works", "content": "Sequential Recommendation. The field of Sequential Recommendation is widely applied, with ongoing research dedicated to forecasting consumer preferences based on their historical interactions. LSTM (Wu et al. 2017) and GRU4Rec (Hidasi et al. 2015) have demonstrated their proficiency in capturing both long-term dependencies and immediate associations. Current endeavors are increasingly adopting sophisticated graph convolutional neural network models within recommendation systems like NGCF (Wang et al. 2019) and lightGCN (He et al. 2020). Additionally, Transformer-based models, e.g. SASRec (Kang and McAuley 2018), BERT4Rec (Sun et al. 2019), S3-Rec (Zhou et al. 2020) have garnered attention for their ability to leverage self-attention mechanisms.\nLLM in Recsys. Incorporating Large Language Models (LLMs) into Recommendation Systems (RS) has become a hot topic in recent research, thanks to the vast knowledge base and superior reasoning abilities of LLMs. By enhancing the representation of IDs (Hou et al. 2022; Hua et al."}, {"title": "Method", "content": "In this section, we present our two-stage alignment framework for Large Language Models (LLMs) in recommendation systems, as depicted in Fig. 2. The first stage, Alignment Tokenization, mitigates the inefficiency of LLM training due to the vast scale of items. This is achieved by mapping items onto a discrete vector set (tokenization). During this process, we introduce an alignment module to better synchronize the tokenization with the LLM's input semantic space. The second stage, Alignment Task, enhances the LLM's ability to predict user interests by incorporating training data that is beneficial to recommendation task into LLM's training process. Concurrently, We pre-cache predictions of LLM to facilitate feasible online usage. These modules will be elaborated further in the subsequent sections."}, {"title": "Alignment Tokenization", "content": "To enable LLM to comprehend items, it is necessary to represent items as tokens in the LLM's vocabulary. However, in recommendation scenarios, the number of items is typically vast. Utilizing the original item IDs as LLM tokens would result in increased training sparsity and cost. To address this issue, we propose a mapping method that transforms large-scale item space into smaller discrete space. Our approach involves constructing a small-scale discrete index library, that is, the CodeBook1 to CodeBook4 on the left side of Fig. 2, where each item is represented by four indices from the CodeBooks. These indices can be shared among items, with more related items sharing greater number of indices.\nTo create the CodeBooks, we draw inspiration from the concept of RQ-VAE (Rajput et al. 2024). Firstly, we define a cascaded CodeBooks with N levels, ranging from coarse to fine-grained, with each layer containing C codes. Each item selects an optimal code from each layer, and is thereby represented by N codes.\nIn training stage, for the first layer of the CodeBooks, We initially cluster the codes into C centers based on a batch of input item embeddings, which serve as the initial code embeddings of the first layer. It is worth noting that LLM have strong semantic understanding capabilities but lack an un-"}, {"title": "Alignment Task", "content": "After obtaining the item quantization representation for each item through our Alignment Tokenization, the subsequent task involves fine-tuning the LLM using user interaction and text descriptions. To prevent training instability arising from substantial dimensional differences of embeddings between CodeBooks and LLM, We utilize only the code indices of each item rather than their embeddings. Consequently, the newly introduced tokens representing items remain in an untrained state until the LLM undergoes fine-tuning. Following prior work (Zheng et al. 2023), as depicted on the right side"}, {"title": "Inference", "content": "Following supervised fine-tuning, The prompt \"The user has interacted with <item>,... in chronological order. Can you predict the next possible item that the user may expect?\" which mentioned in LC-Rec (Zheng et al. 2023) is used for inference. However, due to the large number of parameters in the LLM, the inference process incurs significant computational costs and exhibits slow inference speed, rendering it unsuitable for real industrial system. To address this limitation, as depicted on the Fig. 3, we pre-cache the top-K item codes for each user, generated through beam search inference within the LLM. The valid codes refers to the collection of item codes corresponding to all possible items obtained from the CodeBooks. We only cache valid item codes. During the online inference phase, retrieval of the relevant user's cached data suffices.\nIt is important to note that when new items are introduced into the item pool, it is unnecessary to retrain LLM and CodeBooks. The token representation of items can be derived through inference during our alignment tokenization stage. Despite the fact that new items have not been trained in the LLM, these items have acquired meaningful representations during CodeBook's inference, thereby mitigating the cold start problem for new items."}, {"title": "Experiment Setup", "content": "Datasets We evaluated our proposed method by utilizing the \"Games\", \"Arts\" and \"Instruments\" datasets from the Amazon review dataset (Ni, Li, and McAuley 2019). These datasets encompass user interactions with items, with each item accompanied by a title and description. To mitigate the impact of long-tail data on training, we define the maximum sequence length for user interactions as 20. Furthermore,"}, {"title": "Experiment Results", "content": "We conducted a comparison between our method and several baseline models. The results are presented in Tab. 1. It is evident that the LLM-based approach outperforms traditional methods across all three datasets. This superiority can be attributed to the LLMs, which encompasses a wealth of world knowledge and enhances recommendation effectiveness by incorporating information such as behavior or text. Moreover, our proposed method exhibits improvements over the LLM-based approach, LC-Rec (Zheng et al. 2023) on all three datasets, as shown in the last column of Tab. 1. This primarily owe to the two-stage alignment that we specifically designed for the recommendation task.\nOur results indicate that the improvement achieved by our method on the Games dataset is more significant compared to the Arts and Instruments datasets. This discrepancy may be attributed to longer average sequence length and higher proportion of long-sequence users in the Games dataset, as illustrated in Table. 2. The richer the user behavior, the more significant performance enhancement of LLM. It suggests that LLMs with robust semantic parsing capabilities possess a superior ability to learn from multi-modal behavior.\nAdditionally, we found that the gains from comparing fewer recommendation results are greater than those from comparing more results, e.g., the gain in HR@5 is greater"}, {"title": "Ablation Study", "content": "To demonstrate the benefits of each feature of our proposed method, considering that LC-Rec (Zheng et al. 2023) is the best-performing method among baselines, we compare the results with the variants by removing each newly added cue compared to LC-Rec (Zheng et al. 2023), i.e., 1) \"ED\", our tokenization incorporates an Encoder-Decoder similar to RQ-VAE (Rajput et al. 2024), 2) \u201cw/o LA\", our method without the LLM alignment loss $L_a$ in eq. (3), 3) \u201cw/o NS\u201d, our method without negtive sampling, as shown in Tab. 3. Our method shows significant improvement over \"ED\", indicating that the encoder-decoder module used for generative tasks is not suitable for our clustering representation task. The penalty function designed for generative capabilities can weaken our representation ability. Furthermore, our method shows a slight improvement compared to \"w/o AM\", this is because the alignment loss helps pre-align with LLM input space in our tokenization stage, facilitating more efficient convergence of the LLM during fine-tuning phase. The slight improvement in performance may be attributed to LLM's rich general knowledge, which eases convergence challenges. Lastly, our method shows significant improvement over \"w/o NS\", thanks to our negative sampling strategy that adds a large amount of effective data, enhances generalizability, and alleviates sample selection bias.\nDifferent negative sampling ratios. Table. 4 illustrates the evaluation of different negative sampling ratios and their performance. It is evident that as the negative sampling ratio increases, the performance gradually improves, albeit at a diminishing rate when the negative sampling ratio reaches 1:4. This is attributed to our negative sampling strategy, which has enhanced the LLM's generalization ability regarding behaviors and alleviated sample selection bias.\nVarying numbers of CodeBooks. Table. 5 presents the performance for varying numbers of CodeBooks. We observe that when the number of CodeBooks is 2, the collision rate exceeds 10%. However, when C is 3 or greater, the collision rate becomes negligible. Token sharing among items facilitates more comprehensive token training. Consequently, an excessive number of new words in LLM can result in sparse token training, while too few new words may lead to fewer token representations for individual items, potentially caus-"}, {"title": "Limitation and Future Work", "content": "While our work has demonstrated outstanding performance, caching results during inference phase may be constrained by storage space and is inadequate for managing frequently changing item pool. Pre-caching vectors reveal an alternative method. However, the beam search decoding method incurs high costs for vector retrieval. Consequently, one of our future endeavors is to enhance efficiency of online inference. Furthermore, the large-scale data inherent in the recommendation domain renders the training costs of LLMs prohibitively high. Thus, improving training efficiency in the recommendation domain is our another focus. Additional, our work only involves text and behavior, we plan to incorporate additional modalities such as images. Lastly, in ablation study on scaling law of recommendation capability, we were constrained by computational resources and thus only conducted experiments with 13B model and below. We plan to allocate more computational resources to the experiments."}, {"title": "Conclusion", "content": "In this paper, we propose a method via Alignment Tokenization and Alignment Task to enhance the recommendation system based LLM. Specifically, for Alignment Tokenization, to alleviate the issues of increased training costs and sparsity caused by large-scale items, we present a method for mapping large-scale items to a smaller-scale index library. Additionally, we introduce LLM alignment loss to pre-align during the tokenization phase, addressing the misalignment between tokenization and input space of LLM. For Alignment Task, to increase data volume and mitigate sample selection bias, we incorporate a negative sampling strategy in the training data of LLM, aligning the traditional recommendation model's ability of generalize user interests. Our method's effectiveness is validated on three datasets."}]}