{"title": "TFG-FLOW: TRAINING-FREE GUIDANCE IN MULTI-MODAL GENERATIVE FLOW", "authors": ["Haowei Lin", "Shanda Li", "Haotian Ye", "Yiming Yang", "Stefano Ermon", "Yitao Liang", "Jianzhu Ma"], "abstract": "Given an unconditional generative model and a predictor for a target property (e.g., a classifier), the goal of training-free guidance is to generate samples with desirable target properties without additional training. As a highly efficient technique for steering generative models toward flexible outcomes, training-free guidance has gained increasing attention in diffusion models. However, existing methods only handle data in continuous spaces, while many scientific applications involve both continuous and discrete data (referred to as multimodality). Another emerging trend is the growing use of the simple and general flow matching framework in building generative foundation models, where guided generation remains under-explored. To address this, we introduce TFG-Flow, a novel training-free guidance method for multimodal generative flow. TFG-Flow addresses the curse-of-dimensionality while maintaining the property of unbiased sampling in guiding discrete variables. We validate TFG-Flow on four molecular design tasks and show that TFG-Flow has great potential in drug design by generating molecules with desired properties.", "sections": [{"title": "1 INTRODUCTION", "content": "Recent advancements in generative foundation models have demonstrated their increasing power across a wide range of domains (Reid et al., 2024; Achiam et al., 2023; Abramson et al., 2024). In particular, diffusion-based foundation models, such as Stable Diffusion (Esser et al., 2024) and SORA (Brooks et al., 2024) have achieved significant success, catalyzing a new wave of applications in areas such as art and science. As these models become more prevalent, a critical question arises: how can we steer these foundation models to achieve specific properties during inference time?\nOne promising direction is using classifier-based guidance (Dhariwal & Nichol, 2021) or classifier-free guidance (Ho & Salimans, 2022), which typically necessitate training a specialized model for each conditioning signal (e.g., a noise-conditional classifier or a text-conditional denoiser). This resource-intensive and time-consuming process greatly limits their applicability. Recently, there has been growing interest in training-free guidance for diffusion models, which allows users to steer the generation process using an off-the-shelf differentiable target predictor without requiring additional model training (Ye et al., 2024). A target predictor can be any classifier, loss, or energy function used to score the quality of the generated samples. Training-free guidance offers a flexible and efficient means of customizing generation, holding the potential to transform the field of generative AI.\nDespite significant advances in generative models, most existing training-free guidance techniques are tailored to diffusion models that operate on continuous data, such as images. However, extending generative models to jointly address both discrete and continuous data\u2014referred to as multimodal data (Campbell et al., 2024)\u2014remains a critical challenge for broader applications in scientific fields (Wang et al., 2023). One key reason this expansion is essential is that many real-world problems involve multimodal data, such as molecular design, where both discrete elements (e.g., atom types) and continuous attributes (e.g., 3D coordinates) must be modeled together. To address this, recent generative foundation models have increasingly adopted the flow matching framework (Esser et al., 2024), prized for its simplicity and general applicability to both data types. Multiflow, recently"}, {"title": "2 PRELIMINARY", "content": "In this section, we provide readers with the essential knowledge required for 3D molecule generation using a multimodal flow model.\n2.1 SO(3) INVARIANT 3D MOLECULE MODELING AND GENERATION\n3D molecular representations. Let A denote the set of all atom types plus a \"mask\" state [M] which indicates an undetermined atom type and will be useful in our generative model. A molecule with n atoms can be represented as G = (X, a) \u2208 G, where G = \\mathbb{R}^{3\\times n} \\times A^{n}, X denotes the atomic coordinates, and a represents the atom types. We also use x^{(i)} and a^{(i)} to denote the coordinates and type of the i-th atom, respectively.\nInvariant probabilistic modeling for 3D molecules. Invariance is a crucial inductive bias in mod-eling 3D geometry of molecules (Gilmer et al., 2017). Molecular systems exist in three-dimensional Euclidean space, where the group associated with rotations is known as SO(3). In this work, we are interested in the distribution p(X, a) whose marginal of X satisfies the following property:\nSO(3)-invariance: p(X) = p(SX) \\text{ for any } S\\in SO(3).\nHere, SO(3) denotes the set of all the rotation matrices in 3D space. Intuitively, the definition requires the likelihood of a molecular structure to be invariant with respect to any transformation in SO(3).\nAdditionally, molecular representations need to be invariant to translations. To ensure this, we always project the atomic coordinates to \\Gamma = \\{X \\vert x^{(1)} + \\cdots + x^{(n)} = 0\\} via mean subtraction:\n\\text{Project}(X) := X - \\frac{1}{n} \\sum_{i=1}^{n} x^{(i)} 1_{n}, \\frac{1}{n} \\sum_{i=1}^{n} x^{(i)} 1_{n}, where 1_{n} denotes the n-dimensional all-one row vector.\nEquivariant graph neural networks. In this work, we follow existing research and employ equiv-ariant neural networks to model the SO(3)-invariant distribution of molecule structures (Hoogeboom et al., 2022; Xu et al., 2022). Specifically, we apply Equivariant Graph Neural Networks (EGNNS) to process molecular representations (Satorras et al., 2021). EGNN takes molecular representations G = (X, a) as its input and translate the atom type a^{(i)} into d-dimensional embedding h^{(i)} \\in \\mathbb{R}^{d} for each atom. In each layer, EGNN updates atomic coordinates and embeddings as follows:\nm_{e}^{(i, j)} \\leftarrow \\phi_{m}(h^{(i)}, h^{(i)}, ||x^{(i)} - x^{(j)}||^{2}; \\theta_{m});\nh^{(i)} \\leftarrow \\phi_{h}(h^{(i)}, \\sum_{j=1}^{n} m_{e}^{(i, j)}; \\theta_{h});\nx^{(i)} \\leftarrow x^{(i)} + \\sum_{j=1}^{n} (x^{(i)} - x^{(j)}) \\phi_{x}(m_{e}^{(i, j)}; \\theta_{x}),\nIn the above, m_{e}^{(i, j)} denotes intermediate message from atom i to j, and \\phi_{m}, \\phi_{h}, \\phi_{x} are learnable modules parameterized by \\theta_{m}, \\theta_{h}, \\theta_{x}, respectively. We will formally prove that this architecture, along with the design of our algorithm, leads to SO(3)-invariant distributions.\n2.2 MULTIMODAL FLOW MODEL\nMultiflow is a multimodal flow model originally developed for protein co-design (Campbell et al., 2024). In this work, we adapt it for small molecule design. Multiflow constructs a probability flow p_{t}(G_{t}) for t \\in [0, 1], where p_{0}(G_{0}) = p_{noise}(G_{0}) and p_{1}(G_{1}) = p_{data}(G_{1}). During inference, one first samples G_{0} \\sim p_{0} and then generates a sequence of G_{t} values by simulating the flow."}, {"title": "Conditional flow, velocity, and rate matrix.", "content": "At the core of the sampling process is the multimodal conditional flow p_{t|1}(G_{t} | G_{1}). By design, this flow can be factorized over both the number of atoms and their modalities:\np_{t|1}(G_{t} | G_{1}) := \\prod_{i=1}^{n} p_{t|1}(x_{t}^{(i)} | x_{1}^{(i)})p_{t|1}(a_{t}^{(i)} | a_{1}^{(i)}).\nIn the above, the flows p_{t|1}(x_{t}^{(i)} | x_{1}^{(i)}) (continuous) and p_{t|1}(a_{t}^{(i)} | a_{1}^{(i)}) (discrete) are defined such that they transport the noise distribution to the data distribution following straight-line paths, which is known as rectified flow (Liu et al., 2022): x^{(i)}_{t} \\sim \\mathcal{N}(tx^{(i)}_{1}, (1-t)^{2} I) and a_{t}^{(i)} \\sim a_{1}^{(i)} \\sim Cat(t\\delta\\{a_{1}^{(i)}, a_{1}^{(i)}\\} + (1 - t)\\delta\\{[M], a_{1}^{(i)}\\}). Here, \\delta\\{b, b'\\} is the Kronecker delta, which is 1 when b = b' and 0 otherwise, and Cat denotes a Categorical distribution over \\mathcal{A}.\nWith the definition, we can build in closed form the conditional velocity v_{t|1}(\\cdot | x_{1}^{(i)}) and conditional rate matrix R_{t|1}(\\cdot, \\cdot | a_{1}^{(i)}) which characterize the dynamics of the above conditional distributions:\nv_{t|1}(x_{t}^{(i)}) = \\frac{x_{1}^{(i)} - x_{t}^{(i)}}{1 - t}; R_{t|1}(a, b | a_{1}^{(i)}) = \\frac{\\delta\\{b, a_{1}^{(i)}\\} - \\delta\\{[M], a_{1}^{(i)}\\}}{1 - t}.\nDeriving the unconditional flow. With Eq. (7), the conditional velocity and rate matrix can then be used to derive their unconditional counterparts by sampling from p_{1|t}(G_{1} | G_{t}), which the flow model learns during training. In Multiflow and our implementation, the flow model takes G_{t} as the input and predict the expectation of x_{1|t} for the continuous part as well as the distribution p_{1|t}(a_{1} | G_{t}) for the discrete part. Note that directly modeling the expectation \\mathbb{E}_{1|t}[X_{1|t} | G_{t}] instead of the distribution p_{1|t}(x_{1|t} | G_{t}) is not a problem since v_{t|1} is linear w.r.t. x_{1}, which will be discussed in App. C.4.\nv_{t}(x_{t}^{(i)}) = \\mathbb{E}_{p_{1|t}(G_{1}|G_{t})} [v_{t|1}(x_{t}^{(i)} | x_{1}^{(i)})]; R_{t}(a, b) = \\mathbb{E}_{p_{1|t}(G_{1}|G_{t})} [R_{t|1}(a, b | a_{1}^{(i)})].\nThe unconditional continuous and discrete flows satisfy the Fokker-Planck and Kolmogorov Equations: \\frac{d}{dt}p_{t} = -\\nabla \\cdot (v_{t}p_{t}) and \\frac{d}{dt}p_{t} = p_{t}R_{t}. Therefore, during inference, starting from an initial sample G_{0} \\sim p_{0}, one can iteratively estimate the unconditional velocity and rate matrix at the current time step t by sampling from the learned distribution p_{1|t}(G_{1} | G_{t}). The Fokker-Planck and Kolmogorov Equations can then be simulated to generate G_{t+\\Delta t} for the next time step, ultimately resulting in G_{1} \\sim p_{1} which approximates the data distribution."}, {"title": "3 METHODOLOGY", "content": "Problem setup. Our objective is to develop an effective, training-free method to guide an uncondi-tional multimodal flow model to generate samples with desired properties. Formally, let c denote our target property, and assume we have a time-independent target predictor f_{c}(G_{1}) = p(c | G_{1}) that quantifies how well a given molecule G_{1} satisfies the target property c. We also have access to a model g(G_{t}), which represents p_{1|t}(G_{1} | G_{t}) of a flow model \\{p_{t}(G_{t})\\}_{t\\in[0, 1]}, i.e., it takes G_{t} as input and returns the sample/likelihood of G_{1}, as defined in Sec. 2.\nIn this section, we present our construction of a multimodal guided flow \\{p_{t}(G_{t} | C)\\}_{t\\in[0, 1]} that satisfies p_{1}(G_{1} | C) = p_{data}(G_{1} | c). Then we derive an algorithm which simulates the constructed flow using the target predictor f_{c}(G_{1}), the flow model g(G_{t}), and a suitable velocity and rate matrix.\n3.1 CONSTRUCTING THE GUIDED FLOW\nRecall that the critical factor in the inference with flow models is to derive the velocity and rate matrix in the Fokker-Planck and Kolmogorov Equations so that we can simulate the sample over time. For guided generation, we need to address the following two challenges:"}, {"title": "4 EXPERIMENTS", "content": "In this paper, we explore the application of TFG-Flow across four types of guidance targets: single quantum property, combined quantum properties, structural similarity, and target-aware drug design quality. Quantum properties are examined using QM9 dataset (Ramakrishnan et al., 2014), while structural similarity is assessed on both QM9 and the larger GEOM-Drug dataset (Axelrod & Gomez-Bombarelli, 2022). The target-aware drug design quality is tested using CrossDocked2020 dataset (Francoeur et al., 2020). The baseline implementation and datasets details are in App. D.\n4.1 QUANTUM PROPERTY GUIDANCE\nDataset and models. We follow the inverse molecular design literature (Bao et al., 2022; Hoogeboom et al., 2022) to establish this benchmark. The QM9 dataset is split into training, validation, and test sets, comprising 100K, 18K, and 13K samples, respectively. The training set is further divided into two non-overlapping halves. To prevent reward hacking, we use the first half to train a property prediction network for guidance and an unconditional flow model, while the second half is used to train another property prediction network that serves as the ground truth oracle, providing labels for MAE computation. All three networks share the same architecture as defined by EDM, with an EGNN as the backbone. In inference, we use 100 Euler sampling steps for the flow model."}, {"title": "4.2 STRUCTURE GUIDANCE", "content": "Guidance target. Following Gebauer et al. (2022), we represent the structural information of a molecule using its molecular fingerprint. This fingerprint, denoted as c = (c_{1}, ..., c_{L}), consists of a sequence of bits that indicate the presence or absence of specific substructures within the molecule. Each substructure corresponds to a particular position l in the bit vector, with the bit c_{l} set to 1 if the substructure is present in the molecule and 0 if it is absent. To guide the generation of molecules with a desired structure (encoded by the fingerprint c), we define the guidance target as f(G) := \\exp(-\\vert\\vert \\mathbb{E}(G) - c\\vert\\vert^{2}). Here, \\mathbb{E} refers to a multi-label classifier trained using binary cross-entropy loss to predict the molecular fingerprint, as detailed in App. D.2.\nEvaluation metrics. We use Tanimoto coefficient (Bajusz et al., 2015) TC(c_{1}, c_{2}) = \\frac{\\vert c_{1} \\cap c_{2}\\vert}{\\vert c_{1} \\cup c_{2}\\vert} to measure the similarity between the fingerprint c_{1} of generated molecule and the target fingerprint c_{2}.\nResults analysis. The results are shown in Table 3. TFG-Flow improves the similarity of uncondi-tional generative model by 76.83% and 22.35% on QM9 and GEOM-Drug, respectively. But we still note that the Tanimoto similarity of 0.290 and 0.208 are not satisfactory for structure guidance. We will make efforts to improve training-free guidance for better performance on this task in the future.\n4.3 POCKET-TARGETED DRUG DESIGN\nWe also introduce a novel benchmark for training-free guidance. In practical drug design, the goal is typically to create drugs that can bind to a specific protein target (see related work discussion in App. C), making the inclusion of pocket targets a more realistic setting for guided generation. To enhance the effectiveness of drug design, we aim for the generated molecules to exhibit strong drug-like properties, demonstrate high binding affinity to the target pocket, and be easily synthesizable. We integrate these criteria into our TFG-Flow to guide the drug design.\nDatasets and Models. We utilize CrossDocked2020 training set to train both the unconditional flow model and the drug quality prediction network. Unlike QM9 and GEOM-Drug, the input graph G to the flow model includes not only the coordinates and atom types of molecules but also the protein pocket, which remains fixed during message passing in the EGNN. Also, there is no need to train an oracle target predictor, as the relevant metrics can be derived from publicly available chemistry software. Further details regarding the network and dataset are provided in App. D.\nGuidance target. We use Vina score, QED score, and SA score as the proxy of binding affinity between the molecules and the protein, the drug-likeness of a molecule, and the synthetic accessibility of a molecule, respectively. We combine the three scores as a holistic evaluation of the drug quality via linear combination: c = -0.1\\times \\text{Vina score} + \\text{QED} + \\text{SA}, and train a quality prediction network \\mathbb{E}(G) to approximate the value. The guidance target is given as f(G) := \\mathbb{E}(G).\nEvaluation metrics. We compute Vina Score by QVina (Alhossary et al., 2015), SA and QED by RDKit. The metrics are averaged over 100 molecules per pocket in CrossDocked test set.\nBaselines. We compare TFG-Flow with different state-of-the-art target-aware generative models AR (Luo et al., 2021), Pocket2Mol (Peng et al., 2022), and TargetDiff (Guan et al., 2023). We implement Multiflow for target-aware molecular generation and apply TFG-Flow on it."}, {"title": "4.4 ABLATION STUDY", "content": "To understand how different hyper-parameters (N_{iter}, \\tau, \\rho, K) affect the performance of TFG-Flow, we conduct ablation study on quantum property guidance for polarizability \\alpha. On this task, the searched (\\rho, \\tau) is (0.02, 10) and recall that we set K = 512 and N_{iter} = 4 constantly. In our ablation, we fixed all the other hyper-parameters and change one of them to a grid of values except for the study of N_{iter}, and plot the validity (the ratio of valid molecules) and guidance accuracy (MAE) in Figure 2. For N_{iter}, we present the results with the best (\\rho, \\tau) for the corresponding N_{iter}.\nThe study on N_{iter} shows N_{iter} = 4 already achieves good performance while maintaining compu-tational efficiency, as N_{iter} = 8 don't bring significant improvement. For other experiments, we could see a positive correlation between validity and MAE as a trade-off between the quality of unconditional generation and the desired property alignment. Importantly, We note that the number of samples K \\approx 16 is sufficient in our discrete guidance (Eq. (13)), which demonstrates the efficiency of our estimation technique with fast convergence rate. We can also learn that too strong guidance strength \\rho and \\tau may not improve the guidance (MAE) but will severely deteriorate the validity."}, {"title": "5 DISCUSSIONS AND LIMITATIONS", "content": "Our TFG-Flow complements the trend of generative modeling through the straightforward and versatile flow matching framework (Esser et al., 2024). It also unlocks the guidance for multimodal flow (Campbell et al., 2024) and has been applied effectively to both target-agnostic and target-specific molecular design tasks. We notice that a concurrent research (Sun et al., 2024) explores training-free guidance on continuous flow in image generation, however, we have identified several theoretical concerns with this approach as detailed in App. C.2. Overall, our TFG-Flow proves to be both novel and effective, with solid theoretical foundations.\nThough TFG-Flow boosts the state-of-the-art training-free guidance, a performance gap persists between training-based and training-free methods. But as training-free guidance allows for flexible target predictor, we replace the guidance network as a pre-trained foundation model UniMol (Zhou et al., 2023) for Table 1 in App. D.6, where the performance gap with EEGSDE is further narrowed. We also notice that some literature indicates that training-free guidance tends to perform well in powerful foundation models, such as Stable Diffusion (Ye et al., 2024; Bansal et al., 2023; Yu et al., 2023). This suggests that more capable models which learn from diverse data could possibly offer better steerability. On top of that, the future trajectory for AI-Driven Drug Design might involve developing large generative foundation models and applying training-free guidance seamlessly to achieve desired properties. Beyond molecular design, our insights on multimodal guided flow are broadly applicable to other fields such as material, protein, or antibody. Given that multimodality encompasses both discrete and continuous data types, TFG-Flow provides a general framework that could handle all kinds of guidance problem. We hope that TFG-Flow will inspire further innovation within both the generative modeling and molecular design communities."}]}