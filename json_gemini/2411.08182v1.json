{"title": "SCORE: SYNTACTIC CODE REPRESENTATIONS FOR STATIC\nSCRIPT MALWARE DETECTION", "authors": ["Ecenaz Erdemir", "Kyuhong Park", "Michael J. Morais", "Vianne R. Gao", "Marion Marschalek", "Yi Fan"], "abstract": "As businesses increasingly adopt cloud technologies, they also need to be aware of new security\nchallenges, such as server-side script attacks, to ensure the integrity of their systems and data. These\nscripts can steal data, compromise credentials, and disrupt operations. Unlike executables with\nstandardized formats (e.g., ELF, PE), scripts are plaintext files with diverse syntax, making them\nharder to detect using traditional methods. As a result, more sophisticated approaches are needed\nto protect cloud infrastructures from these evolving threats. In this paper, we propose novel feature\nextraction and deep learning (DL)-based approaches for static script malware detection, targeting\nserver-side threats. We extract features from plain-text code using two techniques: syntactic code\nhighlighting (SCH) and abstract syntax tree (AST) construction. SCH leverages complex regexes to\nparse syntactic elements of code, such as keywords, variable names, etc. ASTs generate a hierarchical\nrepresentation of a program's syntactic structure. We then propose a sequential and a graph-based\nmodel that exploits these feature representations to detect script malware. We evaluate our approach\non more than 400K server-side scripts in Bash, Python and Perl. We use a balanced dataset of\n90K scripts for training, validation, and testing, with the remaining from 400K reserved for further\nanalysis. Experiments show that our method achieves a true positive rate (TPR) up to 81% higher\nthan leading signature-based antivirus solutions, while maintaining a low false positive rate (FPR) of\n0.17%. Moreover, our approach outperforms various neural network-based detectors, demonstrating\nits effectiveness in learning code maliciousness for accurate detection of script malware.", "sections": [{"title": "1 Introduction", "content": "Script-based malware has emerged as a potent threat vector, frequently leveraged in attacks against Linux systems due to\nthe versatility, portability, and ease of use of modern scripting languages. As this threat becomes more prevalent, cloud\nenvironments and Linux systems have also become prime targets, especially for script malware written in server-side\nlanguages like Python, Perl, and shell scripts. These malicious scripts can serve as standalone threats, such as denial-of-service bots, ransomware, or backdoors, or function as components in multi-stage attacks by facilitating payload\ndelivery and execution. With capabilities comparable to traditional executable malware, including data exfiltration and\nsystem resource abuse, these script-based malware poses a significant challenge for detection mechanisms that rely on\nstatic signatures or traditional machine learning (ML) techniques.\nThe threat posed by script malware targeting cloud infrastructure is particularly concerning. These malicious scripts can\ndirectly access and manipulate underlying cloud resources, providing attackers with powerful capabilities. For instance,\na recent Python-based credential harvester and hacking tool called Legion and AlienFox have been observed targeting\nAWS console credentials, SNS, S3, and SES services [1, 2]. Attackers can leverage the hijacked cloud infrastructure"}, {"title": "2 Motivation and Scope", "content": "To illustrate and motivate our problem clearly, we consider a real-world script malware case study. Recent Python-based\ncredential harvester and hacktool, called Legion, exploits web servers that run Content Management Systems (CMS),\nPHP, or PHP-based frameworks like Laravel. It employs regex patterns to extract credentials from these servers for\nvarious web services such as email providers, cloud services like AWS, server management systems, databases, and\npayment systems like Stripe and PayPal [1]. More specifically, Legion targets AWS console credentials, AWS SNS,\nS3 and SES specific credentials. It uses the infrastructure of the hijacked service for mass spamming or opportunistic\nphishing campaigns, and also includes code to implant webshells, brute-force CPanel or AWS accounts and send SMS\nto dynamically-generated US mobile numbers. Similarly, another real-world credential harvester, called AlienFox, is\nused by attackers to extract sensitive information such as API keys and secrets from service providers such as AWS\n[2]. AlienFox can establish AWS account persistence and privilege escalation, collect send quotas and automate spam\ncampaigns through victim accounts or services. Hence, it is crucial to accurately detect these malicious scripts for cloud\nusers' security.\nTraditional signature-based scanners rely on identifying specific patterns to detect such threats. For instance, in the\nsource code in Figure 1, we showcase a function from Legion that uses brute force to generate AWS ID and KEY by\nrandomly selecting characters to create strings. Attackers can easily evade detection by modifying function names"}, {"title": "2.1 Motivation", "content": "To illustrate and motivate our problem clearly, we consider a real-world script malware case study. Recent Python-based\ncredential harvester and hacktool, called Legion, exploits web servers that run Content Management Systems (CMS),\nPHP, or PHP-based frameworks like Laravel. It employs regex patterns to extract credentials from these servers for\nvarious web services such as email providers, cloud services like AWS, server management systems, databases, and\npayment systems like Stripe and PayPal [1]. More specifically, Legion targets AWS console credentials, AWS SNS,\nS3 and SES specific credentials. It uses the infrastructure of the hijacked service for mass spamming or opportunistic\nphishing campaigns, and also includes code to implant webshells, brute-force CPanel or AWS accounts and send SMS\nto dynamically-generated US mobile numbers. Similarly, another real-world credential harvester, called AlienFox, is\nused by attackers to extract sensitive information such as API keys and secrets from service providers such as AWS\n[2]. AlienFox can establish AWS account persistence and privilege escalation, collect send quotas and automate spam\ncampaigns through victim accounts or services. Hence, it is crucial to accurately detect these malicious scripts for cloud\nusers' security.\nTraditional signature-based scanners rely on identifying specific patterns to detect such threats. For instance, in the\nsource code in Figure 1, we showcase a function from Legion that uses brute force to generate AWS ID and KEY by\nrandomly selecting characters to create strings. Attackers can easily evade detection by modifying function names"}, {"title": "2.2 Scope", "content": "In this work, we concentrate exclusively on server-side script languages within the context of cloud security, such\nas Python, Perl and Bash. By \"server-side scripts\", we refer to programs operating on servers, whether they're web\nservers, application servers, etc. These scripts handle requests, execute computations, interact with databases or file\nsystems, and generate responses or outcomes for clients or other server-side components. They serve purposes such\nas automating server provisioning and configuration, managing deployments, orchestrating services, processing and\nanalyzing data, implementing serverless functions or microservices, and facilitating communication between different\nserver-side components. These are the most common tasks in cloud environment, therefore targeted by most threat\nactors. Orthogonal to existing works that consider the client-side languages, e.g., Javascript, PHP, HTML, etc., our\nprimary focus is on identifying and mitigating malware threats for server-side covering Bash, Python and Perl languages.\nIt is important to note that our script malware detection method, which relies on code structure, does not address\nSupply Chain Attacks, such as the 2021 Python Package Index (PyPI) attack [20], where malicious code was distributed\nthrough the official PyPI by compromising the accounts of package maintainers. These attacks are not directly related\nto script code itself and are out of scope of this paper [21, 22]."}, {"title": "2.3 Related Work", "content": "In the literature, there are various studies that encompass client-side script languages, most specifically tailored for\nJavaScript [23, 24, 25, 26, 27]. On the other hand, server-side script malware detection has not been well-studied in the\ncontext of DL. In this paper, we propose script malware detection for server-side languages utilizing syntactic feature\nextraction and DL-based detection techniques. Our approaches stand as a novel mitigation for such threats targeting\ncloud environment. This section briefly summarizes the related work to our paper.\nIn recent years, there has been significant interest in using DL for malware detection by converting malware binaries\ninto grayscale images [28, 29, 30, 31, 32]. However, the focus has primarily been on malware binaries since it is easier\nto find visual patterns in binaries due to their fixed and regular structure unlike scripts. Existing approaches typically\nconvert these binaries into 8-bit vectors, treating them as grayscale images. This has enabled the application of computer\nvision techniques. However, scripts lack such fixed, simple structures by nature, and hence, these approaches are out of\nscope of this paper. Instead, script malware requires a contextual understanding of code rather than focusing on visual\nappearance in byte-strings, which is the approach we propose in this work.\nMalConv [17] is a well-known DL-based malware detector that uses raw byte sequences as input without pre-processing.\nIts CNN-based detection model can process a raw byte sequence of over two million steps, and allow for interpretable\nsub-regions of the binary to be identified. However, its linear complexity dependence on the sequence length is\nmemory-inefficient. Later, MalConv2 [18] improved [17] by introducing a temporal max pooling approach which\nis much more memory efficient and faster to train model. This model has two modules, one for capturing overall\ncontext and one for extracting detailed code features, i.e., content. It consists of 1D CNNs and gating for feature\nweighting. The extracted context and features are fed to an attention mechanism that weights the features according\nto their context. This aspect of MalConv2 makes it a general purpose malware detector. Despite being cheap and\ngeneralizable, byte-level detection has limitations in capturing sophisticated malicious behavior, and often obfuscation\nor commented byte-strings can cause malware evasion.\nAs an effort to extract structural information from scripts, as opposed to byte analysis, Dendroid approach [33]\nintroduces a notion of code chunks as a functional unit of static malware analysis, which inspired our novel feature\nextraction method explained in Section 3.1. Dendroid uses a hierarchical-dendrographic-clustering to group code\nchunks by function, and even common source code. It replaces a sequence of instructions in a code chunk by a list of\nstatements defining its control flow. After parsing each code chunk with a particular grammar for Android malware,\nthe resulting structure is a sequence of symbols of varying length. These hierarchical sequences of symbols help\nrepresenting code as a natural language and employ language models for downstream tasks.\nAnother method for code representation learning is proposed in [12], where ASTs of programming languages are\nconsidered. First a unified vocabulary is created for different AST nodes with the same functionality, then two AST"}, {"title": "3 Syntactic COde REpresentations (SCORE)", "content": "Specialization to script malware detection allows us to benefit from existing highly sophisticated tools for parsing\nplain-text code. Static code analysis is a fundamental task for programming language design, and, as such, we can\ndirectly utilize tools like syntax highlighting, used for visualization by humans, and abstract syntax tree construction,\nused for compilation or interpretation by computers. Both of the above use complex grammars that efficiently construct\nvarious representations of the input code. Our contributions translate intermediate data structures of such parsing\nlibraries into features that can be harnessed as input for ML-based malware detection. We describe the methodology\nof our syntax Highlighting-based feature extractor (SCORE-H) and our abstract syntax Tree-based feature extractor\n(SCORE-T) in the following subsections (see Figure 2)."}, {"title": "3.1 Syntax highlighting features (SCORE-H)", "content": "Syntax highlighting is a mainstay of modern IDEs that colorizes keywords, variable names, class methods, function\ndefinitions, brackets, indents and more to enhance user experience. These colorizations encode the functional role and\ncontext of code strings, as well as operate at near-zero latency to highlight code as it is written by the user. To harness\nthese ideas for malware detection, we adapted a popular syntax highlighter syntect [35], which is used in text editors\nsuch as VSCode [36] and Sublime Text [37]. We chose syntect primarily because it is a fast and reliable Rust-based\nsyntax highlighter. Additionally, it is already utilized in production in industry and numerous open-source projects [35].\nSpecifically, we use only the parsing capabilities of the library, which use the recursive regex grammars also\nused in Sublime Text to tokenize plain-text code into named regex matches called scopes (Figure 2b). Scopes\nare hierarchically organized identifiers of syntactic content, composed of dot separated atoms. For example, in\nPython code 'import base64', import keyword matches the scopes meta.statement.import.python and\nkeyword.control.import.python, signposting its role as the keyword of an import statement. In practice, we\ntruncate the last atom identifying the language (python) to condense the syntactic features and permit cross-language\ninferences in the model. However, traces of each script's language remain, as keywords, syntax, and usage still vary\nacross languages.\nWe parse each script into a stack of such scopes, and unravel that stack into a sequence of tokenized byte-strings and\ntheir corresponding scopes. Such coupled sequences of scope and raw-byte content is the representation defining the\nSCORE-H feature extractor. We only utilize this feature representation in sequential models (see Section 4.1)."}, {"title": "3.2 Abstract syntax tree features (SCORE-T)", "content": "ASTs are a core code representation for compilers to generate intermediate code, linters to detect errors, and more.\nThe tree structure of nested nodes and edges reflects hierarchical syntactic structure and context of the corresponding\ncode, and parses with very low latency. To harness these ideas for malware detection, we adapted the AST parsing\nlibrary tree-sitter [38]. Our primary reason for choosing Tree-sitter is its Rust-based implementation, similar to Syntect,\nensuring it is fast, robust, and secure. Additionally, Tree-sitter is dependency-free and can be seamlessly embedded in\nany application.\nTree-sitter has its own context-free regex grammars for parsing various code languages into ASTs, and these tokenize\nplain-text code into named nodes (Figure 2a). For example, in the same Python code above \u2018import base64', the\nimport keyword generates the node import statement, signposting its role as the keyword of an import statement.\nThe subsequent identifier node for the imported package, base64, becomes a leaf branching from that node. In\nthis way, ASTs nest functionally-related chunks of code, such as function definitions and control-flow statements, into\nsubtrees. (Syntax highlighting, in contrast, only partially replicates this behavior.) In practice, we further standardize\nthe node naming schema into a unified cross-language vocabulary, following the unified AST approach proposed\nin [12]. For example, the root node of Bash is represented by program, while in Python and Perl ASTs they are\nrepresented by module and source file nodes, respectively. Despite their different names, they represent the same\nconcept: the code file or program. Additionally, the node names for code blocks also vary between languages, with\ncompound statement in Perl and block in Python. We unify the node naming to condense the AST features and\npermit cross-language inferences as above, noting the same limitations.\nWe parse each script into an AST and couple each node with its associated raw code (byte-strings), and use this graph\ndata structure as features by either (i) traversing the graph and generating a sequence or (ii) directly utilizing the graph.\nIn the former case, we traverse the AST to generate a coupled sequence of AST node-names and raw-byte content,\nusing either depth first traversal (DFT) and breadth first traversal (BFT), and can apply sequential models (Section 4.1).\nIn the latter case, we preserve the tree structure, and apply graph-based models (Section 4.2)."}, {"title": "4 Malware detection", "content": "In this section, we propose sequential and graph representation learning-based models (SM and GRL, respectively) that\ntranslate our syntax highlighting and AST-based code representations into malicious and benign verdicts. We designed"}, {"title": "4.1 Sequential model (SM)", "content": "The sequential script malware detector is a convolutional and RNN model of the joint byte-syntactic features of both\nthe SCORE-H and serialized SCORE-T feature representations. It is composed of two modules-one for generating\nembeddings of the joint byte-syntactic features, and one for generating malicious and benign verdicts from the resulting\nsequences of feature embeddings.\nThe embedding module fits two embeddings, one for the syntactic features (syntax highlighting and AST-based features)\nand one for the byte features, and concatenates them together into a joint embedding per item in the sequence (Figure 3).\nIt is common to implicitly draw analogies to language modeling when designing embeddings of tokenized sequential\ndata, e.g. to sequences of letters defining words, and sequences of words as documents; to this end, we draw particular\nattention the unusual hierarchical structure of the scopes and atoms in the SCORE-H features. We recognized that\nsuch structure parallels not the organization of Western languages where Letter<Word<Phrase<Sentence, but instead\nthe organization of East Asian languages using hanzi/kanji where Radical<Character<Word<Phrase<Sentence. The\ndecomposition of scopes into atoms, e.g. meta.statement.import\u2192 [meta, statement, import], is analogous to\nthe decomposition of characters into radicals, e.g. \u8a9e\u2192[\u8a00,\u4e94,\u53e3], insofar as each radical/atom encodes distinct-but-\nrelated information to the aggregate character/scope. This structure hard-codes similarity between scopes with shared\natoms irrespective of model training, such that meta.statement.import is similar to meta.statement.try and\nalso to keyword.control.import.\nOperationalizing this analogy, we designed a specialized CNN-based model adapted from [39] to generate embeddings\nof the SCORE-H syntax highlighting features (see Figure 3, left). To capture both atom- and scope-level meaning in the\ntrained embeddings, we use three 1-D convolutional modules with filter dimensions 64, 128, 192 and kernel sizes from 1\nto 3 (covering one atom/radical) and three modules with kernel sizes from 6 up to 18 (covering three scopes/characters).\nThen, the concatenation of all convolutional module outputs is sent through a highway layer [40], which implements a\nself gating mechanism to control information flow and adds skip connections to prevent vanishing gradients. A plain\nfeedforward neural network layer typically applies an affine transform followed by a nonlinear activation, $H(\\cdot, W_H)$, \nto its input x, e.g.,\n$y = H(x, W_H)$,\nwhere y is the layer output and the transform H is parametrized by $W_H$. On the other hand, a highway layer contains\ntwo additional nonlinear transforms $T(x, W_T)$ and $C(x, W_C)$ such that:\n$y = H(x, W_H) \\cdot T(x, W_T) + x \\cdot C(x, W_C)$.\nWe designed a similar CNN-based model to generate embeddings of the SCORE-H byte features (see Figure 3, right).\nThe only difference is we learn an embedding for each byte, followed by three 1-D convolutional modules with filter"}, {"title": "4.2 Graph representation learning (GRL) model", "content": "This section presents a methodology that use byte-syntactic representations of scripts by incorporating their tree\nstructure into the detection model. We leverage the graph similarity learning approach proposed in [34] to obtain graph\nembeddings from our tree-structured SCORE-T features. Our goal is to learn embeddings for scripts such that similar\nscripts have similar graph vector representations, and these models are invariant to permutations of graph elements.\nOur GRL-based model computes graph node representations through a propagation process that iteratively aggregates\nlocal structural information, which is used directly for the classification of malicious behavior. We treat SCORE-T\nfeatures as graphs, and apply GRL to learn embeddings. The embedding models learn vector representations of ASTs\nthat makes similar graphs close in the vector space, such as benign-benign and malicious-malicious, and dissimilar\ngraphs far apart, such as benign-malicious scripts.\nGiven two graphs $G_1 = (V_1, E_1)$ and $G_2 = (V_2, E_2)$ represented by their sets of nodes V and edges $E^*$, we aim to\ncompute a similarity score $s(G_1, G_2)$ between these two graphs. In this context, we consider our ASTs as the graphs,\nand each node $i \\in V$ in the graph is associated with a vector $x_i$, and each edge $(i, j) \\in E$ is associated with a feature\nvector $X_{i,j}$. If a node or edge does not have any associated features, we set the corresponding vector to a constant"}, {"title": "5 Experimental Study", "content": "In this section, we present our experiments and evaluate their success with respect to the following goals:\n1. High Accuracy Our first goal is to demonstrate the high accuracy of our proposed methods, measured in terms\nof True Positive Rate (TPR), False Positive Rate (FPR), Precision, F1 score, and AUROC score.\n\u2022 We established the accuracy of our experiments based on curated ground-truth data from reliable sources\nincluding VirusTotal (VT) and an in-house honeypot (HP) for malicious files. Benign scripts were\ncollected from newly provisioned cloud instances and public GitHub repositories, simulating a diverse\nand realistic cloud user environment. Our dataset incorporates a mix of large and small files, including\nobfuscated ones, mirroring common scenarios faced by cloud users (Section 5.1).\n2. Comparison with Existing Tools Another goal is to evaluate the superiority of our approaches compared to\nexisting tools.\n\u2022 BitDefender is a commercial AV, while ClamAV is an open-source AV toolkit both utilizing signature-\nbased malware detection. They target a wide range of file-types and malware families. We aim to\nshow that these AVs are insufficient for script malware detection and showcase significant performance\nimprovements with our methods. (Section 5.4)\n\u2022 Our approach includes various feature extraction methods and deep learning-based approaches, therefore\nwe compare our approaches both in terms of preprocessing and DL-based detection models. We compare\nour approaches with MalConv2 which originally operates at the byte-level and leverages CNNs for\ncontent and context extraction from files. We also do an ablation study on the proposed AST-based\nfeatures and train MalConv2. The objective is to showcase the superiority of our feature extraction over\nbyte-level representations as well as our model architecture over the CNN approach of MalConv2 in a\nfair comparison. Furthermore, we conduct comparisons with AST-based code representation learning\napproaches. This comparative analysis aims to highlight that despite utilizing similar feature extraction\ntechniques, our DL-based detectors exhibit a more profound understanding of scripts compared to\nexisting code representation learning methods. Finally, we compare our approaches with a token-based\n(CodeBERT) pre-trained code representation learning approach. (Section 5.5)\n3. High Threat Coverage Finally, we aim to achieve comprehensive coverage of threats commonly encoun-\ntered in cloud environments that pose risks to users. As threat identification ground-truth, we utilized both\nBitDefender and VT for a fair evaluation of our best approach. (Section 5.6)\nBy addressing these goals, we demonstrate the effectiveness and superiority of our script malware detection methods in\nrealistic cloud environments."}, {"title": "5.1 Dataset", "content": "We curated a balanced dataset from our total script malware and benign-ware in Python, Bash, and Perl, as detailed in\nTable 1. The dataset was split into train/validation/test sets with a 10:1:1 ratio (75K:7.5K:7.5K samples), maintaining\nequal representation of benign and malicious files across languages. Additional benign files were preserved for further\nanalysis in Appendix B.\nBenign Set: Scripts were collected from newly provisioned cloud instances such as EC2 (including Amazon Linux 2\nand Ubuntu), and GitHub repositories with at least 1000 stars. This approach ensures representation of both typical\ncloud environments and a wide variety of benign scripts that real cloud users might run.\nMalicious Set: We collected malicious samples from VT and our HP. VT samples, with their first detection occurring\nno earlier than 2019 and their last detection in late 2024, were included if flagged as malicious by at least 10 out of 64\nAV vendors. This threshold addresses limitations of traditional AVs in detecting script malware, which often prioritize\nlow FPR over high TPR. We consider this multi-AV consensus a more reliable indicator of maliciousness, representing\nagreement among high-accuracy AVs such as Kaspersky, ESET-NOD32, FireEye, and etc. Furthermore, we curated\ndata from our HP, which enables to gather malicious samples from attackers directly targeting the cloud environment,\nand its samples have been verified as malicious via VT or by manually inspection if they are not in VT. SHA256 of"}, {"title": "5.2 DL Model parameters", "content": "To reduce the memory requirement for our models, we introduce a cap at 2048 for the number of scope-token pairs for\nSCORE-H. Similarly, we limit the number of AST nodes of a script to 700 and the length of their byte-strings to 512\nfor SCORE-T. These limits are empirically selected for our dataset; larger sentence limits cause excessive zero padding\nof short scripts, which reduces the information content. Our SM uses binary cross entropy loss, Adam optimizer with\nlr = 0.001 and weight decay= 0.0001 for training, and GRL-based model uses hamming loss, Adam optimizer with\nlr = 0.0001 and weight decay= 0.00001 for learning the embeddings. We set the number of graph propagation to\nT = 5. The numerical results show performance comparisons between the proposed models, BitDefender, ClamAV\nand DL-based approaches: 1) MalConv2, which is a popular DL-based malware detector [18], trained with byte-level\nfeatures (no preprocessing) as well as SCORE-T (BFT) features for a fair comparison, 2) SAST, which is a sequential\nmodel utilizing bi-LSTMs and AST-based features, 3) GAST, which is a GCN-based model utilizing graphical structure\nof AST features through their adjacency matrix, 4) UAST, which is a unified model comprising of SAST and GAST,\nand 5) an XGBoost detector that uses script embeddings from pre-trained CodeBERT model [14]. We run all our\nexperiments on an Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz with 4 Tesla V100-SXM2 GPUS."}, {"title": "5.3 Evaluation", "content": "Here, we present experimental results for our script malware detectors: SM with SCORE-H, SM with SCORE-T and\nGRL with SCORE-T, as well as their comparisons with AVs, i.e., BitDefender and ClamAV, and DL-based detectors,\ni.e., MalConv2 [18], SAST, GAST and UAST [12], and a CodeBERT-based detector. Table 2 shows their performances\non our dataset. Throughout evaluations, we refer to our approaches by their malware detectors and feature extractors:\nSM with SCORE-H, SM with SCORE-T (DFT), SM with SCORE-T (BFT), GRL with SCORE-T (label-wise) and\nGRL with SCORE-T (threat-wise)."}, {"title": "5.3.1 Overall Detection Results", "content": "Overall, we observe a high detection rate which is greater than 0.95 TPR for all the proposed approaches for a fixed\nFPR around 0.0017. Both SM and GRL models with SCORE-T features outperform the SM with SCORE-H. This\nperformance gap can be attributed to the effectiveness of ASTs in capturing intricate hierarchical script structure,\nsurpassing the sequential syntax highlighting employed by SCORE-H. Our performance analysis, as depicted in Table\n2, reveals notable distinctions among malware detectors concerning AST traversal methods for SM and contrastive\nlearning strategies for GRL. SM with SCORE-T has better performance when the AST is traversed in BFT order\nthan in DFT order. Here, the advantage of BFT becomes evident due to the AST node cap, allowing for broader\ncoverage of oversized scripts compared to DFT. This proves advantageous when malicious behavior manifests later in\nthe code, enhancing the model's capability to detect threats effectively. Furthermore, GRL with SCORE-T demonstrates\nenhanced performance when leveraging threat-wise clustering for contrastive learning of graph-based embeddings,\nas opposed to label-wise clustering. Contrastive learning, which bases representation learning on script similarity,\nbenefits significantly from syntactic structural similarity provided by threat identification in contrast to the binary\nmalicious-or-benign information provided by label-wise clustering. Thus, GRL with SCORE-T showcases superior\nperformance in threat-wise contrastive learning, enhancing its ability to discern and detect threats effectively compared\nto the label-wise case."}, {"title": "5.3.2 FP and FN Analysis", "content": "Upon conducting an analysis of FPs and FNs detected by our approaches, we identified common causes for FPs.\nThe majority of FPs were attributed to two main factors: 1) manually written data in scripts and 2) the presence of\nnon-English characters. Long strings of hard-coded numbers lead to confusion in the detector as it mimicks obfuscation.\nAdditionally, non-English characters are often used to hide suspicious behavior in the code or pass language-specific\nsecurity controls of signature based anti-virus tools. Since our training set potentially contains these types of malware,\nall our approaches including the AST-based models mis-classified these scripts as malicious. Following this intuition,\nwe expect this information to be coming from the byte features since the AST nodes only contain the hierarchical\nsyntactic structure of the code rather than the content of byte-strings. Therefore, this is relatively easy to mitigate for all\napproaches by introducing weights between the features from AST or syntax highlighting and the byte-features paired\nwith them."}, {"title": "5.4 Comparison with AVs", "content": "We compare our approach with traditional AV solutions to evaluate its effectiveness against common defenses in cloud\nenvironments. Our findings in Table 2 reveal that our proposed approaches exhibit a notable improvement in detection\nrates when comparing our proposed approaches to traditional AV solutions ClamAV\u00b9 and BitDefender2. These are\nwidely recognized AV solutions in the cybersecurity domain. We selected these AVs for comparison due to their robust\nLinux support (since most clouds are based on Linux), their capability for script detection, and their widespread use in\ncloud environments. ClamAV is a popular open-source antivirus that runs natively on Linux and is known for detecting\nvarious malware types in scripts, while BitDefender, a commercial AV product, offers Linux support and advanced\nfeatures with its comprehensive database of signatures allowing it to effectively detect and mitigate a wide range of\nthreats.\nThis improvement of our models is particularly noteworthy given a minor increase in FPR. The enhanced performance\nof our methods stems from their behavior-based detection mechanisms, which go beyond the limitations of static\nsignature-based approaches. SCORE-T and SCORE-H are designed to extract the syntactic structure of malicious\nscripts, while our SM and GRL detectors are trained to learn the contextual nuances of these representations within the\ndataset. This performance gap is apparent particularly because of irregular and complex structure of scripts which are\nbetter captured by our behavior-based detection techniques. This enables our approaches to effectively identify and\nmitigate threats that may evade traditional signature-based AV solutions."}, {"title": "5.5 Comparison with DL-based Approaches", "content": "Our proposed models are evaluated against various DL-based approaches to assess their quality from multiple angles.\nWe consider the following approaches for comparison, namely 1) MalConv2 [18], a malware detector that employs\nCNNs and trained with byte-level features, 2) MalConv2 trained with SCORE-T (BFT) features treated as byte-strings,\n3) AST-based script classifiers of [12] that utilize a sequential model with attention (SAST), a GCN-based model\n(GAST) and their joint model (UAST), and 4) an XGBoost-based detector that is trained with CodeBERT embeddings.\nFirstly, the ablation study comparing our approaches to (1) and (2) highlights the benefits of incorporating syntactic\nstructures into script malware representations over byte-level representations. Additionally, comparisons with other\nAST and graph-based script representations (3) in the literature demonstrate the effectiveness of our approaches. These\nrepresentations, i.e., SAST, GAST and UAST, are originally designed for task classification, and repurposed to detect\nmalware in our comparisons. Finally, our comparison with CodeBERT representations demonstrate the superiority of\nsyntax structure over more popular foundational model based feature representations. These decisions were driven by\nour goal to showcase how well our approaches understand code behavior within the context of script malware, and\nour aim is to demonstrate the superiority of our methods, even when compared to other code representation learning\napproaches in addition to malware detectors.\nAs shown in Table 2, most DL-based models demonstrate superior TPR compared to ClamAV and BitDefender, with\na slight increase in FPR. However, GAST [12] deviates from this trend, exhibiting weaker performance in the low\nFPR range despite comparable AUROC. This suggests GAST's reliance on GCNs, capturing only spatial correlations\nbetween AST nodes, limits its effectiveness in our target operating range compared to the spatio-temporal analysis\nof SM-based approaches using LSTMs. Notably, MalConv2 excels among DL-based models, surpassing SAST and\nUAST in TPR due to its ability to directly process large files as raw byte-strings. Performance further improves when\nMalConv2 is trained on SCORE-T (BFT) features treated as byte-strings, highlighting the efficacy of SCORE-T feature\nextraction. Furthermore, integrating GRL with SCORE-T significantly benefits both graph and sequence-based models\nfrom [12] and MalConv2. Notably, threat-wise similarity learning in GRL achieves a remarkable TPR of 0.97855,\ndemonstrating the advantage of incorporating threat labels into similarity calculations. The superior performance of"}, {"title": "5.6 Threat coverage and robustness", "content": "We delve deeper into the threat coverage of our top-performing model", "41": "which provides a label based on a consensus among\nmultiple AV vendors. Two special categories are worth noting: VT Unknown and VT Missed. VT Unknown represents\nthe malicious samples that were not found in VT"}]}