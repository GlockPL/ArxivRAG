{"title": "Which Optimizer Works Best for Physics-Informed Neural Networks and Kolmogorov-Arnold Networks?", "authors": ["Elham Kiyani", "Khemraj Shukla", "Jorge F. Urb\u00e1n", "J\u00e9r\u00f4me Darbon", "George Em Karniadakis"], "abstract": "Physics-Informed Neural Networks (PINNs) have revolutionized the computation of PDE solutions by integrating partial differential equations (PDEs) into the neural network's training process as soft constraints, becoming an important component of the scientific machine learning (SciML) ecosystem. In its current implementation, PINNs are mainly optimized using first-order methods like Adam, as well as quasi-Newton methods such as BFGS and its low-memory variant, L-BFGS. However, these optimizers often struggle with highly non-linear and non-convex loss landscapes, leading to challenges such as slow convergence, local minima entrapment, and (non)degenerate saddle points. In this study, we investigate the performance of Self-Scaled Broyden (SSBroyden) methods and other advanced quasi-Newton schemes, including BFGS and L-BFGS with different line search strategies approaches. These methods dynamically rescale updates based on historical gradient information, thus enhancing training efficiency and accuracy. We systematically compare these optimizers on key challenging linear, stiff, multi-scale and non-linear PDEs benchmarks, including the Burgers, Allen-Cahn, Kuramoto-Sivashinsky, and Ginzburg-Landau equations, and extend our study to Physics-Informed Kolmogorov-Arnold Networks (PIKANs) representation. Our findings provide insights into the effectiveness of second-order optimization strategies in improving the convergence and accurate generalization of PINNs for complex PDEs by orders of magnitude compared to the state-of-the-art.", "sections": [{"title": "1. Introduction", "content": "This section begins by providing the necessary background and motivation for our study, highlighting the key challenges and objectives. Following this, we present an overview of the BFGS (Broyden-Fletcher-Goldfarb\u2013Shanno) and SSBroyden (Self-Scaled Broyden) optimization methods, discussing their theoretical foundations and main characteristics. Section 2 presents a comprehensive study comparing different optimization methods with various line search and trust-region strategies. Specifically, in Subsections 2.1.1 and 2.1.2, we discuss a wide range of scenarios for the Burgers equation. We extend our study to more complex PDEs, including the Allen-Cahn equation in Section 2.3, the Kuramoto-Sivashinsky equation in Subsection 2.4, and the Ginzburg-Landau equation in Section 2.5. The conclusions of our study are summarized in Section 3. Finally, in Appendix A 4, we review the performance of optimizers for the Lorenz system. Additionally, in Appendix B 5, we analyze the performance of BFGS and SSBroyden in finding the global minimum of the multi-dimensional Rosenbrock function as a pedagogical example."}, {"title": "1.1. Background and Motivation", "content": "Physics-Informed Neural Networks (PINNs), introduced in 2017, are a groundbreaking development in scientific machine learning (SciML) [2, 3]. By seamlessly integrating the fundamental physical principles of a system with neural networks, PINNs offer a versatile and mesh-free framework for solving nonlinear partial differential equations (PDEs). Unlike traditional numerical methods, PINNs directly incorporate initial and boundary conditions as well as PDE residuals into their loss functions, enabling them to address both forward problems (predicting solutions) and inverse problems (e.g.,estimating unknown parameters or unknown functions). Their adaptability and scalability make PINNs particularly well-suited for tackling challenges in high-dimensional spaces and complex geometries that conventional methods struggle to handle. The network parameters are updated during training to minimize the loss function, resulting in a solution that meets the constraints applied in the loss function."}, {"title": "1.2. Overview of BFGS and SSBroyden", "content": "In optimization, a fundamental challenge is determining the optimal direction and step size to transition from the current point xk to an improved solution. Broadly, two primary approaches address this problem: line-search methods and trust-region methods. Both rely on a quadratic model to approximate the objective function around the current iterate. The key distinction lies in how they utilize this approximation, line-search methods determine the step size along a chosen direction, while trust-region methods restrict the step to a pre-defined neighborhood where the model is considered reliable."}, {"title": "1.2.1. Line-search methods", "content": "A common approach in optimization is the line-search strategy, where the algorithm first selects a search direction pk that ideally points towards a region of lower function values. Once this direction is determined, the next crucial step is to decide the step size ak, which dictates how far to move along the chosen direction to achieve sufficient improvement in the objective function f. This step involves solving approximately a one-dimensional minimization problem:\nmin  f(xk + apk). (1)\n\u03b1>0\nThe selection of both the search direction and step size plays a fundamental role in the convergence behavior and overall effectiveness of the optimization process. While an exact solution to (1) would maximize the benefit of the chosen direction pk, finding the exact minimum is often computationally prohibitive. Instead, line search methods typically rely on an approximate solution, evaluating a finite number of trial step lengths ar until a suitable reduction in f is achieved. This search, which receives commonly the name of inexact line search, relies in a series of mathematical conditions to really ensure to obtain an satisfactory step length.\nOnce an acceptable step length a is identified, the algorithm updates the current iterate\nXk+1 = Xk + Akpk. (2)\nAt the new point xk+1, the process is repeated by selecting a new search direction pk+1 and step length ak+1. This iterative process continues until convergence criteria are satisfied.\nIn this paper we explored two well-known methodologies that we briefly describe next.\nWolfe conditions:\nThe Wolfe conditions are mathematical criteria used to ensure that a step size in iterative optimization methods satisfies specific properties of sufficiency. Given a point xk and a direction pr, the Wolfe conditions consist of the following two inequalities:\nf (xk + akPk) \u2264 f (xk) + C1\u03b1kfPk\u2207fk, (3)\nT\nVf (xk + CkPk) Pk \u2265 C2Vf Pk \u2265 C2Vf (xk) Pk, (4)\nwhich commonly receive the names of Armijo and sufficient decrease conditions, respectively. The quantities c\u2081 and c\u2082 are constants that should follow 0 < C\u2081 < C2 < 1. While the first condition ensures a sufficient decrease in the function f, the second one rules out unacceptably short steps. The latter inequality is commonly replaced by taking absolute values at both sides\nf(xk+akPk) Pk \u2264 C2 f (xk) Ph (5)\nThe conditions (3) and (5) together receive the name of Strong Wolfe conditions. For all tests we set C1 = 10-4 and c2 = 0.9, which are the standard choices in the optimization literature.\nBacktracking:\nBy only using equation (3), sufficient progress between iterates is not guaranteed, as it does not exclude unacceptably low values of ak. Because of that, the Wolfe or Strong Wolfe conditions introduce an additional condition given by (4) or (5), respectively. However, another line-search strategy that has proven numerically to be successful and does not need an additional condition apart from the Armijo one is backtracking [56]. In a backtracking strategy the step-length is chosen in a more systematic way; instead of evaluating the objective function multiple times for various step-lengths, we start with a reasonable (but not small) initial value of \u0101. If the condition is satisfied, the step-size a is accepted (that is, we set ak = \u0101), and the algorithm proceeds to the next iteration. Otherwise, the step size is reduced by multiplying it by the factor p < 1, i.e., \u0101 \u2013 p\u0101. The process is then repeated multiple times until the Armijo condition (3) is met. Additionally, we incorporate the following condition along with (3):\npk\u2207fk \u2264 0. (6)"}, {"title": "1.2.2. Trust-region methods", "content": "Another class of optimization methods is the family of trust-region methods. The key distinction between trust-region and line-search methods is that the former defines a region (the trust region) around the current point \u00d7k and seeks a suitable point within this region that reduces the objective function. To achieve this, a trust-region algorithm first constructs a local quadratic approximation of the function, denoted as mk, and then approximately solves the following subproblem:\nmin mk (p) = Vfp +  PBP\nsubject to:\n||P|| \u2264 Ak,\nwhere Ak is the radius of the trust-region, and Bk is some approximation of the Hessian matrix at Xk. Then, the proposed step pk is evaluated. If it results in a significant improvement in the objective function, the step is accepted and the trust-region can be expanded. If the step yields poor results, it is rejected, and the trust-region is reduced. Finally, the iterate xk is updated simply as\nXk+1 = Xk + Pk,\nthat is, in a trust-region algorithm the direction and the step-length are calculated at the same time."}, {"title": "1.2.3. Quasi-Newton methods", "content": "A well-known example of a line-search direction is the steepest descent direction, which is given by the negative gradient at xk, that is,\npk = \u2212\u2207fk,\nwhich ensures locally the steepest decrease in f at xk. Another well-known example is Newton's method, which stands out for its remarkable quadratic rate of convergence near the solution. By leveraging both first- and second-order derivatives of the function, Newton's method computes the following search direction pk by\npk = \u2212(\u22072fk)\u00af\u00b9\u2207fk,\nwhere \u22072fk is the Hessian matrix evaluated at the current iterate xk. In both cases, the search direction is then used to determine an appropriate step length a, ensuring a sufficient decrease in f."}, {"title": "1.3. Broyden family of optimizers", "content": "Many quasi-Newton methods fall under the Broyden family of updates, which is characterized by the following general formula:\nBk+1 = Bk\u2212 BkSks Bk + \u0423\u043a\u0443\u043a +0k(sBksk)wkwk,\nwhere Ok is a scalar parameter that could vary between iterations, and\nWk BkSk Sk BkSk\nThe BFGS and DFP methods are both special cases of the Broyden class. Specifically, we recover the BFGS method by setting Ok = 0 and the DFP method by setting \u03b8k 1. The search direction for quasi-Newton methods are defined as\npk = -Hkfk,\nwhere Hk denotes the inverse of Bk. In practice, the different Quasi-Newton formulas to update the Hessian approximations are especially meant to work directly with Hk, thus avoiding any matrix inversion during the calculations. Certainly, if we apply the inverse in the expression (10) at both sides, then with the aid of the well-known Sherman-Morrison formula in matrix theory, we get"}, {"title": "2. Computational experiments", "content": "In this section, we conduct various computational experiments to evaluate the performance of optimizers across a diverse range of steady-state and time-dependent PDEs. To ensure a comprehensive assessment, we select PDEs that encompass a wide spectrum of classes, including parabolic, hyperbolic, elliptic, and hyperbolic-parabolic equations. It is worth noting that the computations for BFGS and SSBroyden with Wolfe line-search are performed on an NVIDIA RTX A6000 GPU, while the computations for BFGS with backtracking and trust-region methods are conducted on an NVIDIA RTX 3090 GPU."}, {"title": "2.1. Burgers equation", "content": "To begin with, we consider the viscous Burgers' equation in a spatially periodic domain, given by,\n+ u = \u03bd , (15)\nwith an initial condition\nu(x, 0) = \u2212 sin(\u03c0\u03c7) (16)\nand periodic boundary conditions. The viscosity is given by v = \u2248 0.003, and the spatio-temporoal domain for computing the solution is (x, t) \u2208 [\u22121, 1] \u00d7 [0, 1]."}, {"title": "2.1.1. BFGS and SSBroyden optimization with Strong Wolfe line-search", "content": "A comparative study of the performance of L-BFGS, BFGS and SSBroyden optimization with Strong Wolfe line-search for solving the Burgers' Equation has been conducted using seven different case studies. In all PINNs cases, the hidden layers utilize the hyperbolic tangent (tanh) activation function. Model training is performed in two stages: first, the Adam optimizer is employed with a learning rate of 10-3 for 1000 iterations. Moreover, the adaptive sampling strategy (RAD) algorithm defined in [71] is employed to dynamically resample points in regions with high errors."}, {"title": "2.1.2. Performance of optimzers based on composition operator in the JAX ecosystem", "content": "Approximating solutions of PDEs with neural networks involves randomly initializing the network parameters using a normal probability distribution [72]. The random sampling of the parameters depends on the random seeds, which also defines the reproducibility of the results. The framework presented above is based on Tensorflow, which generates the random number using a stateful random number generators. A stateful generator has the following three characteristics:\n1. It maintains an internal state that is updated after each random number generation.\n2. The next random number depends on the current internal state.\n3. The generator needs to be reseeded explicitly to reset or reproduce results.\nTherefore, the main drawback with stateful random number generators can result in non-neproducibility as the internal state can cause issues when working in parallel systems. Secondly, it requires careful management in multithreaded contexts to avoid race conditions, which is very common in GPU based architectures, as stateful random number generator consider previous state for future number generation. To overcome these issues, the JAX framework [73] is based on a stateless random number generator which does not maintain any internal state between calls. Instead, it uses the provided input (such as a seed or key) to generate each random number independently, without relying on previous outputs. The state must be explicitly passed along with the call, and the RNG (Random Number"}, {"title": "2.3. Allen-Cahn equation", "content": "Next, we consider the Allen-Cahn equation, given by\n+ \u043a (u\u00b3 \u2013 u) = 0,\nwith the initial condition u(x, 0) = x\u00b2 sin (2\u03c0x) and periodic boundary conditions:\nu(t, -1) = u(t, 1), ux(t, \u22121) = ux(t, 1),\nwhere \u20ac = 10-4, \u043a = 5, and the spatio-temporoal domain for computing the solution is [x, t] \u2208 [-1,1]\u00d7[0, 1]. The periodicity at the boundaries is enforced using interpolation polynomials {v(i) (x)}=1 (see [80]) and defined as\nv(i) (x) = s(i) + s[i) (x \u2013 a)(b - x)(a + b \u2212 2x) + (r) + rex) (x - a) (x - b)\u00b2,\nwhere a and b represent the spatial domain boundaries, and the coefficients {si), si), ri), ri)} are defined for i = 1,2 corresponding to n = 2. For all case studies involving the Allen-Cahn equation, the PINNs architecture utilizes the hyperbolic tangent activation function (tanh) in its hidden layers. The training process begins with the Adam optimizer at \u043a = 1, incorporating a learning rate decay schedule. Following this initial phase, \u043a is increased to 5, and the model is further refined using the BFGS and SSBroyden algorithms. This training strategy starts with Adam on a simplified problem by reducing the parameter k, and subsequently resumes with BFGS or SSBroyden at the original k value until convergence. We found this strategy to be highly robust in achieving convergence to the global minimum. In contrast, maintaining \u043a = 5 throughout training occasionally led to stagnation in the loss function at relatively higher values for certain initializations, suggesting that the PINN converged to a stationary point distinct from the global minimum."}, {"title": "2.4. Kuramoto-Sivashinsky equation", "content": "In this example, we illustrate the effectiveness of the SSBroyden method for tackling spatio-temporal chaotic systems, with a particular focus on the one-dimensional Kuramoto-Sivashinsky equation. Known for its intricate spatial patterns and unpredictable temporal dynamics, the Kuramoto-Sivashinsky equation poses a significant challenge to conventional numerical approaches. The governing equation is given by:\n+ au + \u03b2 + y = 0, (18)\nwhere a = 100, \u03b2 = , and y = . The initial condition is defined as"}, {"title": "2.5. Ginzburg-Landau equation", "content": "In this section, we illustrate the effectiveness of the two-dimensional Ginzburg-Landau equation, expressed as:\n\u0414\u0410 = \u20ac\u22072A + (\u03bd - \u03b3 |A|2) \u0391, (19)\nwhere A is a complex-valued function, and e, v, and y are constant coefficients. Here, e and vare real numbers, while y is a complex constant (\u03b3\u2208 C). Representing A in terms of its real and imaginary components, A = u + iv, where u and v are real-valued functions and i is the imaginary unit, we derive the following system of PDES:\n\u0434\u0438 = \u20ac\u22072u + vu \u2212 (u\u00b2 + v\u00b2) (Re(\u03b3)u \u2013 Im(\u03b3)v), (20)\n\u03b8\u03c5 = \u03b5\u22072v + vv \u2212 (u\u00b2 + v\u00b2) (Re(\u03b3)v + Im(\u03b3)u), (21)\nwhere Re() and Im() denotes the real and the imaginary parts, respectively. Specific values for these coefficients are \u0454 = 0.004, v = 10, \u03b3 = 10 + 15i, which are the same values as the ones chosen in [84]. The initial condition is\nAo(x, y) = 10 (y + ix) e-25(x\u00b2+y\u00b2).\nThe solution domain is defined as (t,x) \u2208 [0,1] \u00d7 [\u22121,1]2. Periodic boundary conditions are enforced using a hard-enforcement method with polynomials defined in (17) for n = 4, applied to each spatial variable x and y. Initial conditions, on the other hand, are applied using a soft-enforcement method. Consequently, the loss function integrates contributions from the PDE residuals and the initial conditions. The temporal domain is divided into 5 time windows, each of length At = 0.2, with a separate PINN trained for each window. A fully connected neural network is designed to predict the solution fields u and v. The network architecture consists of five dense layers, each with 30 neurons, where all hidden layers utilize the hyperbolic tangent (tanh) activation function. The output layer contains two neurons, providing simultaneous predictions for u and v. To enhance training efficiency, the model incorporates the adaptive sampling strategy (RAD) algorithm."}, {"title": "3. Summary", "content": "In this study, we conducted a comprehensive comparison of multiple second-order optimizers for PINNS and PIKANs, focusing on BFGS, SSBroyden, and L-BFGS with Wolfe line-search conditions, as well as BFGS with Backtracking line search and trust-region methods. Utilizing the optax and optimistix library in JAX, we systematically evaluated these optimization techniques across a range of PDEs. We note that we obtained state-of-the-art results by only employing the bets optimizers without fine-tuning our loss functions with self-adaptive or attention-based weights or any other enhancemts. We simply pursued a straightforward application of good optimization solvers in order to demonstrate that the big bottleneck for PINNs or PIKANs is the optimization error.\nOur initial investigation focused on the Burgers equation, where we assessed the impact of combining first-order optimizers such as Adam with second-order optimizers like BFGS and SSBroyden. We then extended our analysis to more challenging PDEs, including the Allen-Cahn equation, the Kuramoto-Sivashinsky equation, and the Ginzburg-Landau equation, providing a detailed evaluation of efficiency and accuracy. The results demonstrate that advanced quasi-Newton methods, particularly SSBroyden and BFGS with Wolfe line-search, significantly improve the convergence rate and accuracy of PINNS, especially for complex and stiff PDEs. Across all cases, SSBroyden consistently outperformed BFGS, achieving faster convergence and exhibiting greater robustness in handling complex optimization landscapes. These findings highlight the effectiveness of quasi-Newton methods in accelerating the training of PINNs and enhancing numerical stability. Furthermore, we extended our analysis to PIKANs, replacing traditional multilayer perceptron architectures with KANs utilizing Chebyshev polynomials. In this setting, SSBroyden continued to demonstrate superior optimization performance, reinforcing its robustness across diverse network architectures. Additionally, our study emphasized the importance of implementing PINNs and PIKANs with double-precision arithmetic, which improves numerical stability and enhances optimization efficiency across all tested scenarios. This study demonstrates that SSBroyden with Wolfe line-search is an effective and reliable optimizer for training PINNS and PIKANS. Its capacity to handle complex PDEs and its strong convergence properties make it well-suited for advanced applications in deep learning-based scientific computing. Future research could focus on incorporating domain-specific adaptations to further improve the accuracy, efficiency, and generalization of PINNS and PIKANs, particularly in high-dimensional and multi-scale problem settings."}, {"title": "4. Appendix A: Lorenz system", "content": "Considering the the Lorenz system, as described in [85]. It is governed by the following set of coupled ordinary differential equations:\ndx = \u03c3(y \u2013 x), (22)\ndy = x(p \u2013 z) \u2013 y, (23)\ndz = xy \u2212 \u03b2z, (24)\nwhere the parameters of the Lorenz system are given as \u03c3 = 10, p = 28, and \u03b2 = 3. The system continues to display chaotic behavior [86]. The solution is computed up to t = 20, starting from the initial condition (x(0), y(0), z(0)) = (1, 1, 1).\nThe neural network architecture consists of three hidden layers, each containing 30 neurons. The hyperbolic tangent (tanh) activation function is applied across all hidden layers to capture the system's inherent nonlinearity. Training begins with the Adam optimizer, following an exponential decay schedule with an initial learning rate of 5 \u00d7 10-\u00b3, which decays by a factor of 0.98 every 1000 iterations. Subsequently, the BFGS and SSBroyden optimizers, incorporating Wolfe line-search, are employed for further optimization.\nTo address the extended time horizon [0, 20], the time domain is partitioned into 40 time windows, each of length At = 0.5. A separate PINNs is trained for each window, using the final state of the previous window as the initial condition for the next. Figure 26 compares the numerical solution of the Lorenz system with PINNs predictions obtained via BFGS and SSBroyden over 40 time windows in [0,20]. The plots show x(t) (left), y(t) (middle), and z(t) (right). Table 16 summarizes the L2 relative errors for predicting x(t), y(t), and z(t) across all 40 time windows and reports the corresponding training times for BFGS and SSBroyden."}, {"title": "5. Appendix B: Multi-dimensional Rosenbrock function", "content": "Considering non-quadratic objective functions Rosenbrock, which is commonly used to evaluate optimization algorithms. The Rosenbrock function is defined as:\nf(x1,x2) = 100(x2 \u2212 x\u2081)\u00b2 + (x1 \u2212 1)\u00b2.\nThe SSBroyden method with Strong Wolfe line-search demonstrates performance comparable to BFGS with Strong Wolfe line-search, with the optimization starting from xi = 0.5. When applied to challenging optimization problems, including the Rosenbrock function-characterized by a narrow, curved valley and multi-modal landscapes, SSBroyden efficiently converges to the global minimum with accuracy similar to BFGS.\nAs evident from Figure 27, the number of iterations required to reach the global minimum increases as the dimensionality of the problem grows. However, for the 10-dimensional case, SSBroyden requires more iterations to reach global optimization compared to BFGS. In contrast, for the 2D and 5D cases,"}]}