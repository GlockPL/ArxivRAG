{"title": "TrialBench: Multi-Modal Artificial Intelligence-Ready Clinical Trial Datasets", "authors": ["Jintai Chen", "Yaojun Hu", "Yue Wang", "Yingzhou Lu", "Xu Cao", "Miao Lin", "Hongxia Xu", "Jian Wu", "Cao Xiao", "Jimeng Sun", "Lucas Glass", "Kexin Huang", "Marinka Zitnik", "Tianfan Fu"], "abstract": "Clinical trials are pivotal for developing new medical treatments, yet they typically pose some risks such as patient mortality, adverse events, and enrollment failure that waste immense efforts spanning over a decade. Applying artificial intelligence (AI) to forecast or simulate key events in clinical trials holds great potential for providing insights to guide trial designs. However, complex data collection and question definition requiring medical expertise and a deep understanding of trial designs have hindered the involvement of Al thus far. This paper tackles these challenges by presenting a comprehensive suite of meticulously curated Al-ready datasets covering multi-modal data (e.g., drug molecule, disease code, text, categorical/numerical features) and 8 crucial prediction challenges in clinical trial design, encompassing prediction of trial duration, patient dropout rate, serious adverse event, mortality rate, trial approval outcome, trial failure reason, drug dose finding, design of eligibility criteria. Furthermore, we provide basic validation methods for each task to ensure the datasets' usability and reliability. We anticipate that the availability of such open-access datasets will catalyze the development of advanced Al approaches for clinical trial design, ultimately advancing clinical trial research and accelerating medical solution development. The curated dataset, metrics, and basic models are publicly available at https://github.com/ML2Health/ML2ClinicalTrials/tree/main/AI4Trial.", "sections": [{"title": "1 Background & Summary", "content": "The clinical trial process is an essential step in developing new treatments (e.g., drugs or medical devices). It involves evaluating their safety, appropriate dosage, and effectiveness in treating specific diseases in the human body. However, these exploratory trials, often spanning three or four phases, have a high failure rate1,2. Compounding the issue, clinical trials are known for being time-consuming, labor-intensive, and costly. clinical development programs containing the set of phase 1-3 trials typically span 7-11 years, cost an average of 2 billion USD, and achieve approval rates of only around 15%3. Clinical Trials are inherently risky (they have a trial in the name), and artificial intelligence (AI) is particularly suited to making accurate estimates to reduce risk.\nYears of clinical trials have generated a vast amount of multi-modal data, encompassing aspects such as inclusion/exclusion criteria designs, adverse event statistics, and patient enrollment results. This extensive dataset offers a robust foundation for developing advanced artificial intelligence algorithms. However, identifying key clinical trial challenges and effectively"}, {"title": "2 Methods", "content": "In this paper, we identify nine AI-solvable clinical trial tasks. For each task, we elaborate on its background, explain how it would help clinical trial design and management, curate the dataset, evaluate the performance of well-known artificial intelligence methods, and report the empirical results.\nWe provide the following three aspects for each learning task: (1) Background. Background of the learning task. (2) Definition. A formal definition of the learning task (input feature and output). (3) Broad impact. The broader impact of advancing real clinical trials on the task."}, {"title": "2.1 Al-solvable Clinical Trial Task Definitions", "content": ""}, {"title": "2.1.1 Trial Duration Prediction", "content": "Background. The duration of a clinical trial is defined as the number of years from the trial's start date to its completion date, representing a continuous numerical value. The clinical trial duration is directly related to its cost because longer trials require more extended use of resources, including personnel, facilities, and materials, leading to increased expenses27.\nDefinition. This task focuses on predicting trial duration (time span from the enrollment of the first participant to the conclusion of the study) based on multi-modal trial features such as eligibility criteria, target disease, etc.\nBroad impact. Predicting the duration of clinical trials offers several significant benefits that enhance drug development efficiency and effectiveness. AI-driven predictions allow for better planning and resource allocation, leading to more accurate staffing, budgeting, and management of clinical sites. This enhances decision-making by enabling stakeholders to prioritize projects based on expected timelines and identify risks early, allowing for proactive measures to mitigate delays. Ultimately, accurate duration predictions assists pharmaceutical companies in more accurately estimating costs, determining the right number of sites for potential acceleration, and strategizing effective market launch plans in a single, comprehensive solution."}, {"title": "2.1.2 Patient Dropout Forecasting", "content": "Background. Clinical trials often suffer from high patient dropout rates, which can compromise the validity of the results and lead to increased costs and delays.\nDefinition. This task aims to predict the patient dropout rate (percentage) of the clinical trial based on multi-modal trial features such as eligibility criteria, target disease, and so on.\nBroad impact. Predicting patient dropout rates in clinical trials holds significant promise for improving the efficiency and effectiveness of drug development processes. Predicting patient dropout rates can significantly enhance the efficiency of clinical trials. High dropout rates often necessitate the recruitment of additional participants to meet the required sample size, which can be both time-consuming and costly."}, {"title": "2.1.3 Serious Adverse Rate Prediction", "content": "Background. Adverse event prediction is crucial in clinical trials as it directly impacts the safety, efficacy, and overall success of the trial. The primary concern in any clinical trial is the safety of the participants28.\nDefinition. The task targets forecasting the probability of serious adverse effects given multi-modal clinical trial features such as drug molecule, target disease, eligibility criteria, etc.\nBroad impact. Predicting adverse events helps in identifying potential risks to patients before they occur, allowing for proactive measures to be taken. On the other hand, regulatory organizations such as the FDA and EMA have strict guidelines for monitoring and reporting adverse events in clinical trials29. Accurate prediction and early detection of adverse events can ensure compliance with these regulations."}, {"title": "2.1.4 Mortality Rate Prediction", "content": "Background. The mortality rate in a clinical trial refers to the proportion of participants who die during the study. The mortality rate is an important measure used to assess the safety and potential risks associated with a treatment or intervention being tested in the trial.\nDefinition. The task targets forecasting the probability of mortality rate given multi-modal clinical trial features such as drug molecule, target disease, eligibility criteria, etc.\nBroad impact. Accurately predicting the mortality rate of a clinical trial significantly enhances patient safety by identifying potential risks early, allowing for timely interventions. This leads to more efficient trial designs, optimizing resource allocation and reducing costs. Furthermore, it accelerates the drug development process, bringing effective treatments to market faster, and increases compliance with regulatory standards, thereby building public trust and ethical standards in clinical research."}, {"title": "2.1.5 Trial Approval Prediction", "content": "Background. Clinical trial approval refers to whether a drug can pass a certain phase of clinical trial, which is the most important outcome of a clinical trial. It is a binary variable.\nDefinition. This task aims to predict the probability of trial approval given multi-modal trial features such as drug molecule, disease code, and eligibility criteria.\nBroad impact. Predicting trial approval can significantly enhance the efficiency and success rates of drug development. By accurately forecasting which drugs are likely to pass clinical trial phases, companies can focus their resources on the most promising candidates, reducing wasted time and money on less viable options. This targeted approach can accelerate the development of effective treatments, bringing them to market faster and improving patient outcomes. Additionally, reliable approval predictions can streamline regulatory processes and increase investor confidence in the pharmaceutical industry."}, {"title": "2.1.6 Trial Failure Reason Identification", "content": "Background. Clinical trials usually fail due to a couple of reasons30: (1) business decision (e.g., lack of funding, company strategy shift, pipeline reorganization, drug strategy shift); it is challenging to predict business decision, so we do not involve these trial in our dataset; (2) Poor enrollment. Insufficient enrollment can compromise the statistical power of the study, making it difficult to detect a significant effect of the drug. Also, poor enrollment can lead to delays in the trial timeline and increased costs, as more resources are required to recruit additional participants. (3) Safety. Unexpected adverse reactions or side effects can occur, posing significant risks to participants' health. This can lead to the trial being halted or terminated. (4) Efficacy (effectiveness). In the trial, we expect the tested drug to outperform the standard treatment in curing the target disease. Thus, efficacy (effectiveness) is typically required.\nDefinition. Given clinical trial features, the goal of this task is to leverage the AI model to classify it into one of these four categories, including (1) successful trials, (2) failure due to poor enrollment, (3) failure due to drug safety issue; (4) fail due to lack of efficacy. It is a multi-category classification problem.\nBroad impact. Accurately predicting the reasons for clinical trial failures can greatly enhance the efficiency of drug development by preventing costly delays and optimizing resource allocation. This leads to faster delivery of effective treatments to patients, improving patient outcomes and public health. Additionally, better-designed trials with higher success rates can encourage greater confidence and participation in clinical research."}, {"title": "2.1.7 Eligibility Criteria Design", "content": "Background. To achieve statistically significant results, a clinical trial must meet its target sample size31. Insufficient patient numbers can lead to underpowered studies, which may fail to demonstrate the effectiveness of a treatment or may miss important safety information. Eligibility criteria are essential to patient recruitment32. They describe the patient recruitment requirements in unstructured natural language. Eligibility criteria comprise multiple inclusion and exclusion criteria, which specify what is desired and undesired when recruiting patients. Each individual criterion is usually a natural language sentence.\nDefinition. This task aims to design eligibility criteria given a series of clinical trial features such as target disease, phase, drug molecules, etc.\nBroad impact. Using AI models to design eligibility criteria for clinical trials offers several significant advantages. Al can predict which patients are more likely to meet the eligibility criteria based on historical data and real-world evidence. This speeds up the recruitment process by identifying suitable candidates faster and reducing the time and cost associated with screening large numbers of unsuitable participants."}, {"title": "2.1.8 Drug Dose Finding", "content": "Background. One of the primary goals of clinical trials is to determine the drug dose. Determining the correct dosage of a drug is crucial to ensure its effectiveness in treating a particular condition. In the early stages of drug development, predicting the optimal dosage is essential for designing clinical trials26, 33.\nDefinition. This task aims to predict drug dosage based on drug molecular structure and target disease.\nBroad impact. By estimating the dose-response relationship and identifying the dosage range that balances efficacy and safety, researchers can design more informative and efficient clinical studies."}, {"title": "2.1.9 Generalization of These Tasks", "content": "In real-world clinical trials, the design, structure, cost of clinical trials, and the drug structures of interest evolve significantly over time1,34,35. Thus, these prediction tasks require a model to generalize to a set of unseen clinical trials that are structurally distant to the known clinical trial set. The time information is available for all the trials; we use time split (detailed in Section 2.6) so that we learn from earlier trials and test on later ones to assess the model fairly."}, {"title": "2.2 Data Acquisition", "content": "We create the dataset benchmark from multiple public data sources, including ClinicalTrials.gov, DrugBank, Trial- Trove, ICD-10 coding system, as elaborated below.\n\u2022 ClinicalTrials.gov. ClinicalTrials.gov is a publicly accessible database maintained by the U.S. Na- tional Library of Medicine (NLM) at the National Institutes of Health (NIH). It provides detailed information about clinical trials conducted around the world, including those funded by public and private entities. Each clinical trial in ClinicalTrials.gov is provided as an XML file, which we parse to extract relevant variables. For each trial, we retrieve the NCT ID (unique identifiers for each clinical study), disease names, associated drugs, title, summary, trial phase, eligibility criteria, results of statistical analyses, and other details. Some of these features are not always available. For example, observational clinical trials do not involve treatment and drugs.\n\u2022 DrugBank. DrugBank (https://www.drugbank.com/) is a comprehensive, freely accessible online database that provides detailed information about drugs and their biological targets. It integrates chemical, pharmacological, and pharmaceutical data with comprehensive drug target information, making it a valuable resource for researchers, healthcare professionals, and students in the fields of drug discovery, pharmacology, and medicinal chemistry.\n\u2022 TrialTrove. TrialTrove is a comprehensive database and intelligence platform designed to provide detailed information and analysis on clinical trials across the pharmaceutical and biotechnology industries. TrialTrove serves as a critical resource for professionals involved in clinical development, competitive intelligence, and market analysis. We obtain the trial outcomes of some trials from the released/public subset of the TrialTrove database36,37.\n\u2022 ICD-10. ICD-10-CM (International Classification of Diseases, 10th Revision, Clinical Modification) is a medical coding system for classifying diagnoses and reasons for visits in U.S. healthcare settings. Diseases are extracted from https: //clinicaltrials.gov/ and linked to ICD-10 codes and disease description using Clinical Table Search Service APId and then to CCS codes via hcup-us.ahrq.gov/toolssoftware/ccs10/ccs10.jsp."}, {"title": "2.3 Data Source Linking", "content": "Next, we describe how we process and link the parsed trial data to AI-ready input and output format:\n\u2022 Drug names are extracted from ClinicalTrials.gov and linked to its molecule structure (SMILES strings and the molecular graph structures) using the DrugBank Database.\n\u2022 Disease data are extracted from ClinicalTrials.gov and linked to ICD-10 (International Classification of Diseases, Tenth Revision) codes and disease description using clinicaltables.nlm.nih.gov and then to CCS codes via hcup-us.ahrq.gov/toolssoftware/ccs10/ccs10.jsp.\n\u2022 Trial outcomes are available at TrialTrove and linked through NCTID."}, {"title": "2.4 Dataset Curation and Feature Organization", "content": "We apply a series of selection filters to ensure the selected trials have high-quality. There are hundreds of multi-modal features in ClinicalTrials.gov for each trial organized in XML format,\nWe only leverage the features that are available before trials start and remove the remaining features. Different tasks rely on different subsets of features. Based on clinical trial knowledge, we manually select the appropriate features for various tasks. In addition, we also remove features whose values are identical or all null across different trials. Following are the additional selection criteria for each task.\n\u2022 Trial duration forecasting: We only consider the trials whose start and completion dates are available. We only consider the trials with realistic completion dates and remove the cases with only anticipated completion dates provided. We found that trials with duration over 10 years are outliers38,39, so we removed them to facilitate regression analysis.\n\u2022 Patient dropout rate prediction: The results are available at ClinicalTrials.gov and the number of dropout and total enrolled patients are reported.\n\u2022 Serious adverse event prediction: The results are available at ClinicalTrials.gov and the serious adverse events are reported."}, {"title": "2.5 Data Annotation", "content": "Data annotation (a.k.a. labeling data) is a fundamental step when curating a dataset. Labels of all the datasets can be inferred from various data sources. For some tasks, such as drug dose finding, trial approval prediction, and trial failure reason identification, we use external tools such as GPT to obtain the label from the raw text.\n\u2022 Trial duration forecasting: The duration of a clinical trial refers to the number of years the trial lasts, i.e., the difference between the start and complete date. It is a continuous numerical value. For some trials, the start and completion date are available in Clinical Trials.gov. We can use this information to calculate the trial duration.\n\u2022 Patient dropout rate prediction: Some clinical trials on ClinicalTrials.gov present the number of dropout patients and the number of enrolled patients. We compute the patient dropout rate by dividing the number of dropout patients by the number of enrolled patients. The resulting dropout rate is a percentage.\n\u2022 Serious adverse event prediction: ClinicalTrials.gov presents the results of some trials. Adverse events are reported for some of these trials.\n\u2022 Mortality event prediction: The results of clinical trials presented on ClinicalTrials.gov may include mortality events. We binarize the mortality event as the prediction target indicating whether a mortality event occurred, and remove all other trials that lack mortality event information.\n\u2022 Trial approval outcome prediction: The annotations come from two sources. First, the HINT paper36,36,37,40\u201342 builds a benchmark dataset for trial approval prediction, with approval labels sourced from TrialTrove. Additionally, ClinicalTrials.gov provides termination reasons for some trials, such as poor enrollment or lack of efficacy, included in the \"why stopped\" node in the XML files. We incorporate these trials, along with termination reasons indicating failed approval, into the dataset as negative samples.\n\u2022 Trial failure reason identification: For some of the terminated trials, ClinicalTrials.gov provides a \"why stopped\" tag that uses natural language to describe the failure reason. We use OpenAI ChatGPT API \u00a9 to automatically convert into three categories of failure reason, including (1) poor enrollment; (2) drug safety issue; (3) lack of efficacy (in treating the"}, {"title": "2.6 Data Split/Segmentation", "content": "Artificial intelligence models need to be evaluated on (future) unseen data. To simulate that setting, data split strategies are employed to partition the dataset into training, validation, and testing sets for unbiased evaluation of the artificial intelligence models. In this paper, we leverage temporal split, which refers to splitting the data samples based on their time stamps. The earlier data samples are used for training and validation, while the later data are used for testing. The reason is that the design of later clinical trials relies on earlier clinical trials. The training/test split ratio is 8:2."}, {"title": "3 Data Records", "content": "The clinicalTrials.gov/website (https://clinicaltrials.gov/) provides public data resources for clinical trials.\nhttps://www.fda.gov/regulatory-information/search-fda-guidance-documents/ enhancing-diversity-clinical-trial-populations-eligibility-criteria-enrollment-practices-and-trial\nfhttps://clinicaltrials.gov/ct2/show/NCT01026194"}, {"title": "3.1 Multi-Modal Features", "content": "Clinical trials involve diverse modalities of data, as shown in the following.\nCategorical Feature For example, there are mainly two study types: interventional and observational. The intervention type can be a small-molecule drug, biologics, or surgery, etc. Clinical trial sponsors can be pharmaceutical companies or research institutes, e.g., Johns Hopkins University, or Pfizer.\nNumerical Feature Numerical features, such as the minimum/maximum age of recruited patients and the number of real/expected recruited patients, are also common in clinical trials.\nghttps://clinicaltrials.gov/ct2/show/NCT03269136\nhhttps://clinicaltrials.gov/ct2/show/NCT03299816"}, {"title": "4 Technical Validation", "content": "To show the processed datasets are AI-ready and of reasonable quality, we evaluate the performance of these datasets on mainstream artificial intelligence algorithms. We leverage a multi-modal deep neural network to represent the multi-modal features and concatenate all these representations to make the prediction. In this section, we first discuss the multi-modal deep learning method, then describe the experimental setup, and present the experimental results finally."}, {"title": "4.1 Multi-modal Deep Neural Networks", "content": "For all the classification and regression tasks, we apply state-of-the-art multi-modal deep neural networks to represent multi-modal features. Each representation is an embedding vector with continuous values. Then, we combine these representations and make the prediction. For the eligibility criteria design task, we use OpenAI ChatGPT API with the prompt to produce eligibility criteria.\nRecently, numerous tabular data processing models52\u201354 have been proposed for numerical and categorical feature processing. Among them, DANets\u00b9\u00b9 stand out due to its key component's modularity and ability to achieve competitive performance without hyper-parameter tuning. The key component, the basic block module, supports flexible stacking, making DANets suitable as a submodule for processing numerical and categorical features. After preprocessing (e.g., normalization), three lightweight basic blocks are sequentially stacked to hierarchically select, extract, and merge features from input categorical and numerical features, ultimately yielding a 50-dimensional embedding.\nSpecifically, each disease code is assigned a basic embedding, e.g., the disease code $d_i$ has basic embedding, denoted $e_i \\in \\mathbb{R}^d$. Then, to impute the hierarchical dependencies, the embedding of current disease $d_i$ (denoted $h_i$) is represented as a weighted average of the basic embeddings ($e \\in \\mathbb{R}^d$) of itself and its ancestors, the weight is evaluated by the attention model. It is formally defined as\n$h_i = \\sum_{j \\in Ancestors(i) \\cup \\{i\\}} a_{ij} e_j$,\nwhere $a_{ji} \\in (0,1)$ represents the attention weight and is defined as\n$a_{ji} = \\frac{\\exp(\\phi([e_i, e_j]))}{\\sum_{k \\in Ancestors(i) \\cup \\{i\\}} \\exp(\\phi([e_i, e_k]))}, \\sum_{j \\in Ancestors(i) \\cup \\{i\\}} a_{ji} = 1,$\nwhere the attention model $\\phi(\\cdot)$ is an MLP with a single hidden layer, the input is the concatenation of the basic embedding, the output is a scalar, $e_i$ serves as the query while all the ancestors embeddings $\\{e_j\\}$ serve as the keys. $Ancestors(i)$ represents the set of all the ancestors of the disease code $d_i$.\nMesh-Embedding has pretrained a MeSH embedding layer using the node2vec algorithm55 with default parameters. For MeSH terms that have not been included in pretraining the MeSH embedding layer, we employ a new parametric embedding layer learned from scratch.\nBERT is constructed by stacking multiple layers of Transformer blocks. The output of each layer is used as the input to the subsequent layer, thus allowing the model to learn increasingly complex representations of the input data. This technique results in a deep, bidirectional architecture that is capable of capturing contextual information from both the past and future tokens in a sequence.\nDrug Molecule is essentially 2D planar graph. Graph neural network (GNN) is a neural network architecture that takes graph-structured data as input, transmits the information between the connected edges and nodes to capture the interaction between them, and learns a vector representation of graph nodes and the entire graph57. First, on the node level, each node $v$ has a feature vector denoted $e_v$. For example, node $v$ in a molecular graph $G$ is an atom, $e_v$ includes the atom type, valence, and other atomic properties. $e_v$ can be a one-hot vector indicating the category of the node $v$. On the edge level, $e_{uv}$ is the feature vector for edge $(u, v)$. $N(u)$ represents the set of all the neighbor nodes of the node $u$. At the $l$-th layer, $m_{uv}^{(l)}$ and $m_{vu}^{(l)}$ are the directional edge embeddings representing the message from node $u$ to node $v$ and vice versa. They are iteratively updated as\n$m_{uv}^{(l)} = f_1(\\e_u \\oplus e_{uv} \\oplus (\\sum_{w \\in N(u) \\backslash v} m_{wu}^{(l-1)})), \\forall l=1,\\dots,L,$\nwhere $\\oplus$ denotes the concatenation of two vectors; $f_1(\\cdot)$ is a multiple layer perceptron (MLP), $m_{uv}^{(l)}$ is the message vector from node $u$ to node $v$ at the $l$-th iteration, whose initialization is all-0 vector, i.e., $m_{uv}^{(0)} = 0$, following the rule of thumb58,59. After $L$ steps of iteration ($L$ is the depth), another multiple layer perceptron (MLP) $f_2(\\cdot)$ is used to aggregate these messages. Each node has an embedding vector as\n$h_u = f_2(\\e_u \\oplus (\\sum_{v \\in N(u)} m_{vu}^{(L)})).$\nWe are interested in graph-level representation $h_G$, we can further use the readout function (e.g., average) to aggregate all the node embeddings.\nAfter obtaining the representations of multi-modal data, we concatenate these representations, feed the concatenated vector into MLP, and make the prediction. For binary classification tasks (e.g., trial approval prediction), we use sigmoid function as the activation function in the output layer to yield predicted probability; for multi-category classification tasks (e.g., trial failure reason identification), we use softmax as the activation function in the output layer to produce probability distribution over all the categories; for regression tasks (e.g., trial duration prediction), we do not use activation function in the output layer to produce continuous-valued prediction. We use cross-entropy criterion as the loss function for classification tasks and mean-square error (MSE) as the loss function for regression tasks."}, {"title": "4.2 Experimental Setup", "content": "Implementation Details All the code is implemented in Python 3.8. All the deep learning models are implemented in PyTorch. We use GPT 4.0 for data annotation and some generation tasks. The total cost was around $100 US dollars. The embedding size of all the representations is set to 100. We use Adam60 as the numerical optimizer to minimize the loss function with an initial learning rate at 1e-3 and zero weight decay. The batch size is set to 64. The maximal training epochs is set to 20."}, {"title": "Evaluation Metrics", "content": "For classification tasks, we assess the model performance using accuracy, PR-AUC (the area under the Precision-Recall curve), F1 score (the harmonic mean of precision and recall), and ROC-AUC (the Area Under the Receiver Operating Characteristic Curve). For regression tasks, we use RMSE (Root Mean Squared Error), MAE (Mean Absolute Error), Concordance Index, and Pearson Correlation as metrics. For generation tasks (eligibility criteria design), we design some semantic metrics to measure the alignment between real and designed criteria, including text embeddings' cosine similarity, informativeness, and redundancy, detailed in supplementary materials."}, {"title": "4.3 Experimental Results", "content": "In this section, we demonstrate the experimental results of multi-modal deep learning methods on all the curated tasks and datasets in\nWe find that the direct use of a multimodal deep learning method leads to decent performance in most of the curated tasks. Specifically, for 14 binary classification datasets (across patient dropout prediction, adverse event prediction, mortality rate prediction, and trial approval prediction), the multimodal deep learning method achieves at least 0.7 F1 scores in 11 datasets. On regression and generation tasks, the simple multi-modal deep learning method also achieves decent performance. These results validate the AI-readiness and high quality of the curated datasets."}, {"title": "5 Usage Note", "content": "This paper extracts various properties of clinical trials and integrates them with multiple data sources. These properties are essential for analyzing and predicting different aspects of clinical trial performance and outcomes. The properties extracted include:\n\u2022 Trial duration: The length of time a clinical trial lasts, from its start date to its completion date. This helps in understanding the efficiency and planning required for trials.\n\u2022 Patient dropout rate: The proportion of participants who leave the trial before its completion. This is critical for assessing the trial's ability to retain participants and the reliability of the results.\n\u2022 Serious adverse event: Instances of significant negative health effects observed during the trial, which are crucial for evaluating the safety profile of the treatment being tested.\n\u2022 Mortality rate: The proportion of participants who die during the trial. This measure is vital for assessing the potential risks associated with the treatment.\n\u2022 Trial approval outcome: Whether a drug can pass a certain phase of the clinical trial, which is a binary outcome indicating success or failure.\n\u2022 Trial failure reason: The identification of reasons why a clinical trial may fail, such as poor enrollment, safety issues, or lack of efficacy. This helps in improving the design of future trials.\n\u2022 Eligibility criteria design: The inclusion and exclusion criteria for participants are essential for ensuring that the right population is targeted for the trial.\n\u2022 Drug dosage: Estimating the appropriate dosage of drugs being tested to ensure safety and efficacy.\nThese properties and the datasets provided in this study enable researchers and AI practitioners to apply advanced machine learning models to predict and optimize various aspects of clinical trials. The datasets include multi-modal data, such as drug molecules, disease codes, textual descriptions, and categorical/numerical features, making them versatile for different predictive tasks. By leveraging these datasets, researchers can improve clinical trial design, enhance patient safety, optimize resource allocation, and ultimately accelerate the development of new medical treatments.\nAI4Trial is intended for healthcare, biomedical, and artificial intelligence researchers and data scientists who want to apply AI algorithms and innovate novel methods to tackle problems formulated in TrialBench datasets and tasks."}, {"title": "Hosting and Maintenance Plan", "content": "All datasets in TrialBench are hosted and version-tracked via GitHub and are publicly available for direct download using the persistent data identifier. Our core developing team is committed and has the resources to maintain and actively develop TrialBench for, at minimum, the next five years. We plan to grow TrialBench in several dimensions by including new learning tasks, datasets, and leaderboards. We welcome external contributors."}, {"title": "Computing Resources", "content": "We use a server with an NVIDIA GeForce RTX 3090 GPU, Intel(R) Xeon(R) CPU with 50GB RAM for all empirical experiments in this manuscript."}, {"title": "Limitations", "content": "Artificial intelligence for clinical trial is a vast and fast-growing field, and there are important tasks and datasets yet to be included in However, is an ongoing effort and we strive to continuously include more datasets and tasks in the future."}, {"title": "Licensing", "content": "Most of the data features come from ClinicalTrials.gov, which is a service of the U.S. National Insti- tutes of Health, provides access to information on publicly and privately supported clinical studies. The data available on ClinicalTrials.gov is generally free for use. Some TrialBench tasks involve data in DrugBank, which is available for free to academic institutions and non-profit organizations for research and educational purposes. The subset of TrialTrove is released by Fu's study36 and is publicly available for Non-Commercial Use."}, {"title": "Ethics Statement", "content": "The development and dissemination of the TrialBench dataset adhere to stringent ethical standards to ensure the protection of patient privacy, the integrity of the data, and the responsible use of the information. The source of the data is clearly documented, and proper attribution is given to ClinicalTrials.gov and other databases such as DrugBank and TrialTrove. This transparency ensures that users of the TrialBench dataset understand the origin of the data and the context in which it was collected."}, {"title": "Code Availability", "content": "The curated dataset and relevant code are publicly available at https://github.com/ML2Health/ ML2ClinicalTrials/tree/main/AI4Trial."}, {"title": "Competing Interests", "content": "The authors declare no competing interests."}]}