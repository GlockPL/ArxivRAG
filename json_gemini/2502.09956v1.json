{"title": "KGGEN: EXTRACTING KNOWLEDGE GRAPHS FROM PLAIN TEXT WITH LANGUAGE MODELS", "authors": ["Belinda Mo", "Kyssen Yu", "Joshua Kazdan", "Proud Mpala", "Lisa Yu", "Chris Cundy", "Charilaos Kanatsoulis", "Sanmi Koyejo"], "abstract": "Recent interest in building foundation models for KGs has highlighted a funda- mental challenge: knowledge-graph data is relatively scarce. The best-known KGs are primarily human-labeled, created by pattern-matching, or extracted us- ing early NLP techniques. While human-generated KGs are in short supply, au- tomatically extracted KGs are of questionable quality. We present a solution to this data scarcity problem in the form of a text-to-KG generator (KGGen), a pack- age that uses language models to create high-quality graphs from plaintext. Unlike other KG extractors, KGGen clusters related entities to reduce sparsity in extracted KGs. KGGen is available as a Python library (pip install kg-gen), mak- ing it accessible to everyone. Along with KGGen, we release the first benchmark, Measure of of Information in Nodes and Edges (MINE), that tests an extractor's ability to produce a useful KG from plain text. We benchmark our new tool against existing extractors and demonstrate far superior performance.", "sections": [{"title": "1 INTRODUCTION", "content": "Knowledge graph (KG) applications and Graph Retrieval-Augmented Generation (RAG) systems are increasingly bottlenecked by the scarcity and incompleteness of available KGs. KGs consist of a set of subject-predicate-object triples, and have become a fundamental data structure for information retrieval (Schneider, 1973). Most real-world KGs, including Wikidata (contributors, 2024), DBpedia (Lehmann et al., 2015), and YAGO (Suchanek et al., 2007), are far from complete, with many missing relations between entities (Shenoy et al., 2021). The lack of domain-specific and verified graph data poses a serious challenge for downstream tasks such as KG embeddings, graph RAG, and synthetic graph training data.\nEmbedding algorithms such as TransE (Bordes et al., 2013) rely on abundant relational data to learn high-quality KG representations. In particular, TransE represents relationships as vector transla- tions between entity embeddings and has demonstrated strong performance in link prediction when trained on large KGs (e.g., 1M entities and 17m training samples). However, if the KG is sparse or incomplete, embedding models struggle \u2013 they cannot learn or infer missing links effectively, degrading performance on knowledge completion and reasoning tasks (Pujara et al., 2017; Pote, 2024).\nConsider retrieval-augmented generation (RAG) with a language model (LM) \u2013 this requires a rich external knowledge source to ground its responses. For instance, GraphRAG integrates a KG into the RAG pipeline (Edge et al., 2024). In GraphRAG, a language model (LM) like GPT-40 is used to extract a KG from a text corpus automatically, and this graph is used for retrieval and reasoning. This structured, graph-based augmentation has been shown to improve multi-hop reasoning and syn- thesis of information across documents (Larson & Truitt, 2024). By traversing relationships in the constructed graph, GraphRAG can \u201cconnect the dots\u201d between disparate pieces of information, out- performing baseline RAG that relies only on semantic search over text. However, GraphRAG's per- formance ultimately depends on the quality of the extracted graph (Zhang et al., 2024). In practice, automatically constructed graphs can be noisy and incomplete \u2013 some false nodes and edges may"}, {"title": "2 EXISTING METHODS", "content": "Before describing KGGen, we explain the two leading existing methods for extracting KGs from plain text, which will serve as a basis for comparison throughout the rest of this paper."}, {"title": "2.1 \u039f\u03a1\u0395\u039d\u0399\u0395", "content": "Open Information Extraction (OpenIE) was implemented by Stanford CoreNLP based on Angeli et al. (2015). It first generates a \"dependency parse\u201d for each sentence using the Stanford CoreNLP pipeline. A learned classifier then traverses each edge in the dependency parse, deciding whether to create (Yield), continue (Recurse), or stop processing a clause. These decisions split complex sentences into shorter, self-contained clauses. From these clauses, the system produces (subject, relation, object) tuples, each accompanied by a confidence score. Because OpenIE does not require its input text to have a specific structure, OpenIE can handle text in any format."}, {"title": "2.2 GRAPHRAG", "content": "Microsoft developed GraphRAG, which integrated graph-based knowledge retrieval with language models (LMs) Larson & Truitt (2024). As a first step, GraphRAG provides functionality for gen- erating KGs from plain text to use as its database. In this process, GraphRAG creates a graph by"}, {"title": "3 KGGEN: KGS FROM PLAIN TEXT", "content": "Unlike most previous methods of LLM-based KG extraction, we rely on a multi-stage approach involving an LLM (in our case, GPT-40) to (1) extract entity and relations from each source text, (2) aggregate graphs across sources and (3) iteratively cluster entities and relations. We implement these stages in a modular fashion via a new kg-gen Python toolkit consisting of a 'generate' module for extraction, an 'aggregate' module for source consolidation, and a \u2018cluster' module for dynamic entity resolution. We use the DSPy framework throughout these stages to define signatures that ensure that LLM responses are consistent JSON-formatted outputs. In our case, we use GPT-40, although the implementation may be used with any model supported by DSPy.\nWe impose strong constraints on the LLM via prompting to reduce the likelihood of semantically dissimilar duplicate entities. We introduce multiple passes through our extracted edges and relations to cluster similar entities and consolidate the number of edge types. Consolidation and clustering prevent the formation of sparse KGs, which may produce meaningless KG embeddings under stan- dard algorithms such as TransE.\nOur extraction method involves several steps, which we outline below. The exact prompts for each step can be found in Appendix A, and the process is illustrated in Figure 1."}, {"title": "3.1 ENTITY AND RELATION EXTRACTION (\u2018GENERATE')", "content": "The first stage takes unstructured text as input and produces an initial knowledge graph as extracted triples. We invoke the GPT-40 model for each input text through a DSPy signature that instructs the model to output detected entities in a structured format. Then, we invoke a second LLM call through DSPy that instructs the model to output the subject-predicate-object relations, given the set of entities and source text. We find this 2-step approach works better to ensure consistency between entities."}, {"title": "3.2 AGGREGATION (\u2018AGGREGATE')", "content": "After extracting triples from each source text, we collect all the unique entities and edges across all source graphs and combine them into a single graph. All entities and edges are normalized to be in lowercase letters only. The aggregation step reduces redundancy in the KG. Note that the aggregation step does not require an LLM."}, {"title": "3.3 ENTITY AND EDGE CLUSTERING (\u2018CLUSTER')", "content": "After extraction and aggregation, we typically have a raw graph containing duplicate or synonymous entities and possibly redundant edges. The clustering stage is a key innovation in our KG extraction methodology that aims to merge nodes and edges representing the same real-world entity or concept. We take an iterative LLM-based approach to clustering, inspired by how a group of humans might gradually agree on consolidating terms. Rather than attempting to solve the entire clustering in one shot (which is intractable for an extensive list of entities), KGGen performs a sequential series of clustering operations for entities:\n1. The entire entities list is passed in context to the LLM, and it attempts to extract a single cluster. An optional cluster-instruction string may be passed to decide how to cluster. The default instructions account for close synonyms and differences in tense and plurality.\n2. Validate the single cluster using an LLM-as-a-Judge call with a binary response. If it passes, then add the cluster and remove the cluster entities from the entities list.\n3. Assign a label to the cluster that most closely captures the shared meaning of entities in the cluster.\n4. Repeat steps 1\u20133 until n loops happen without a successful cluster extraction.\n5. Remaining entities are checked batch-by-batch, with batch size b, for whether they should be added to an existing cluster.\n6. For each new addition to a cluster, validate the cluster once more using an LLM-as-a-Judge call with a binary response.\n7. Repeat steps 5\u20136 until there are no remaining entities to check.\nThe same operations are performed on edges, albeit with slightly modified prompts.\nThe clustering process allows us to create dense KGs that admit meaningful embeddings. To give a real example of the usefulness of our process, in one of our raw KGs, we found the entities \"vulnerabilities\u201d, \u201cvulnerable\u201d, and \u201cweaknesses\". Although these are different words, they have similar meanings and should be viewed as equivalent in our KG."}, {"title": "4 A BENCHMARK FOR EXTRACTION PERFORMANCE", "content": "Although a handful of existing methods attempt to extract KGs from plain text, it is difficult to measure progress in the field due to the lack of existing benchmarks. To remedy this, we pro- duce the Measure of Information in Nodes and Edges (MINE), the first benchmark that measures a knowledge-graph extractor's ability to capture and distill a body of text into a KG."}, {"title": "4.1 MINE DESCRIPTION", "content": "MINE involves generating KGs for 100 articles, each representing a distinct source of textual data. Each article is approximately 1,000 words long and is generated by an LLM based on a diverse list of 100 topics that range from history and art to science, ethics, and psychology. To evaluate the quality of the generated KGs, we develop a metric to assess how effectively they capture critical information from the articles.\nWe extract 15 facts-here defined as statements present in the plain text article-from each article by providing an LLM with the article and the extraction prompt found in Appendix C. We manually verify that the 15 facts are accurate and contained in the article. MINE assesses how well a text-to- KG extractor captures the information present in the text by determining whether these 15 facts are captured by the KG generated from the article."}, {"title": "5 RESULTS", "content": "We use MINE to benchmark KGGen against leading existing methods of plain-text-to-KG extrac- tion: OpenIE Angeli et al. (2015) and GraphRAG Larson & Truitt (2024). After providing this quantitative comparison of extraction fidelity, we present qualitative results demonstrating the ad- vantages of KGGen over past methods."}, {"title": "5.1 EVALUATIONS ON MINE", "content": "Figure 3 displays accuracies from KGGen, OpenIE, and GraphRAG on MINE. Figure 4 shows an example query from MINE and relevant relations extracted by KGGen, OpenIE, and GraphRAG."}, {"title": "5.2 QUALITATIVE RESULTS", "content": "As seen in Figure 5b and 5e, GraphRAG often generates a minimal number of nodes and connections for an entire article. This sparsity results in the omission of critical relationships and information. For compression, Figure 5a and 5d illustrate sections of the KGs generated by KGGen for the same articles. Figure 5c illustrates one of many issues in OpenIE's KGs. Firstly, most nodes are un- reasonably long, incoherent phrases. Many of these nodes are redundant copies of one another, adding unnecessary complexity to the graph. Additionally, as seen in 5f OpenIE frequently pro- duces generic nodes such as \u201cit\u201d and \u201care.\u201d Due to their frequency, these nodes, which contain no useful information, often end up as some of the most well-connected nodes in the graph. By con- trast, KGGen consistently generates KGs that are dense and coherent, effectively capturing critical relationships and information from the articles."}, {"title": "6 FUTURE WORK", "content": "We propose MINE \u2013 the first benchmark for KG extraction from plain text. To solve the data-shortage hindering development of graph-based foundation models, we present KGGen, a plain- text-to-KG extractor that outperforms existing approaches by up to 18% on MINE.\nAlthough KGGen beats existing methods by significant margins, the graphs still exhibit problems, like over or under-clustering. More research into better forms of clustering could improve the quality of our KGs. Additionally, our benchmark, MINE, currently measures performance on relatively short corpora, whereas KGs are primarily used to handle massive amounts of information efficiently. Future expansions of our benchmark could focus on larger corpora to better measure the practicality of different extraction techniques."}, {"title": "7 RELATED WORK", "content": "Interest in automated methods to produce structured text to store ontologies dates back to at least 2001 when large volumes of plain text began to flood the fledgling internet (Maedche & Staab, 2001). KG extraction from unstructured text has seen significant advances through rule-based and LM-powered approaches in the last 15 years. Early work (Suchanek et al., 2007) used hard-coded rules to develop YAGO, a KG extracted from Wikipedia containing over five million facts, and rules- based extraction still has appeal for those producing KGs in multi-modal domains today (Norabid & Fauzi, 2022; Oramas et al., 2015). With the development of modern natural language processing, hard-coded rules generally ceded to more advanced approaches based on neural networks. For instance, OpenIE (Angeli et al., 2015) provides a two-tiered extraction system: first, self-contained clauses are identified by a classifier; then, Angeli et al. run natural logic inference to extract the"}, {"title": "8 ACKNOWLEDGMENTS", "content": "JK acknowledges support from NSF grant number DGE-1656518. SK acknowledges support from NSF 2046795 and 2205329, the MacArthur Foundation, Stanford HAI, and Google Inc."}, {"title": "A PROMPTS FOR KG EXTRACTION", "content": "This section provides the exact prompts used to extract KG's from the text.\nThe initial KG is extracted using the following two prompts."}, {"title": "B VALIDATION OF KG EXTRACTION", "content": "This section provides the LLM generations used to validate our KG extraction method."}, {"title": "C PROMPTS FOR MINE", "content": "This section provides the LLM prompts used by MINE to evaluate KGs."}, {"title": "D EXAMPLE ARTICLE FROM MINE", "content": "This section provides the article that the example fact is from."}]}