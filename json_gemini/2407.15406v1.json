{"title": "Automated Road Safety: Enhancing Sign and Surface Damage Detection with AI", "authors": ["Davide Merolla", "Vittorio Latorre", "Antonio Salis", "Gianluca Boanelli"], "abstract": "Public transportation plays a crucial role in our lives, and the road network is a vital component in the implementation of smart cities. Recent advancements in AI have enabled the development of advanced monitoring systems capable of detecting anomalies in road surfaces and road signs, which, if unaddressed, can lead to serious road accidents. This paper presents an innovative approach to enhance road safety through the detection and classification of traffic signs and road surface damage using advanced deep learning techniques. This integrated approach supports proactive maintenance strategies, improving road safety and resource allocation for the Molise region and the city of Campobasso. The resulting system, developed as part of the Casa delle Tecnologie Emergenti (House of Emergent Technologies) Molise (Molise CTE) research project funded by the Italian Minister of Economic Growth (MIMIT), leverages cutting-edge technologies such as Cloud Computing and High Performance Computing with GPU utilization. It serves as a valuable tool for municipalities, enabling quick detection of anomalies and the prompt organization of maintenance operations.", "sections": [{"title": "Introduction", "content": "According to latest World Health Organization (WHO) [1] public road networks are the lifeblood of modern societies, playing a crucial role for goods and people transportation, which is fundamental for trade, commerce and tourism. At the same time, they enable easy access to jobs, education, healthcare, and social activities, both in urban and rural regions. The status of road safety is crucial: harsh weather conditions can accelerate road degradation, and time the volume of traffic, including heavy traffic, grows, thus requiring frequent repairs. Any fault in maintenance could lead to severe incidents with death and injury worldwide. The latest report (2023) states that about 1.19 million people die each year as a result of road traffic crashes.\nThis paper explores a novel approach to traffic sign and road damage detection using advanced deep learning techniques, that are used in a Road Management System of a Public Municipality. This work is in progress within the Molise CTE research project, funded by the Italian Ministry of the Economic Growth (MIMIT), with the aim to leverage the best emerging technologies such as Cloud Computing, High Performance Computing, Artificial Intelligence, and AR/VR to develop and demonstrate state-of-the-art solutions in the Smart City environment.\nThe paper is structured as follows. Section 2 introduces a Literature Review, with description of more recent trends in research about the topic, then Section 3 provides a detailed description of the proposed solution, including information on the supporting cloud infrastructure. Section 4 gives a description of computational experiments with relevant metrics and giving evidence of the effectiveness of the proposed solution. Finally, Section 5 describes further improvements under development, the benefits and exploitation opportunities, and concludes the paper."}, {"title": "Literature Review", "content": "The detection and classification of traffic signs and road damage are vital components of intelligent transportation systems. Recent advancements in deep learning have significantly enhanced the capabilities of these systems, making them more accurate and efficient. This literature review explores various methods and approaches used in traffic sign detection, classification, and road damage detection, with a particular focus on the use of YOLO architecture and Convolutional Neural Networks (CNNs).\nTraffic Sign Detection and Classification\n1) Seminal Papers: Early research laid the groundwork for the development of automated traffic sign detection and classification systems. An influential paper by Maldonado-Bascon et al. [2] introduces an automatic road-sign detection and recognition system utilizing Support Vector Machines (SVMs). The system improves driver-assistance by effectively detecting and recognizing various road sign shapes through a combination of color segmentation, linear SVM-based shape classification, and Gaussian kernel SVM recognition. The approach exhibits high success rates and robustness against transformations and occlusions. Another notable paper by Fang, Chen, and Fuh [3] outlines a method for road sign detection and tracking using neural networks and Kalman filters. This system leverages neural networks to extract color and shape features and employs Kalman filters to track the detected signs through image sequences, maintaining robust performance under diverse environmental conditions.\n2) YOLO Architecture: The YOLO (You Only Look Once) architecture has emerged as a popular choice for object detection tasks due to its real-time processing capabilities"}, {"title": null, "content": "and high accuracy. Several studies have demonstrated the effectiveness of YOLO in traffic sign detection. For instance, Yang and Zhang (2020) [4] compared the performance of YOLOv4 and YOLOv3, finding that YOLOv4 significantly improved detection accuracy on a dataset of Chinese traffic signs. Similarly, Zhang (2023) [5] showed that YOLOv3 outperformed R-CNN algorithms in terms of speed and accuracy for traffic sign detection.\n3) Enhancements in YOLO: Recent enhancements in YOLO include the development of lightweight models such as Sign-YOLO, which integrates the Coordinate Attention (CA) module and High-BiFPN to improve feature extraction and multi-scale semantic information fusion. This model achieved significant improvements in precision, recall, and detection speed on the CCTSDB2021 dataset [6]. Another example is the PVF-YOLO model, which uses Omni-Dimensional Convolution (ODconv) and Large Kernel Attention (LKA) to enhance detection accuracy and speed [7].\n4) Traffic Sign Classification: After detection, traffic signs need to be classified into specific categories. Convolutional Neural Networks (CNNs) have been widely used for this purpose due to their strong feature extraction capabilities. Ciresan et al. (2012) [8] employed a CNN-based approach to classify German traffic signs, achieving state-of-the-art results. Additionally, improved YOLO models like TSR-YOLO have incorporated advanced modules to enhance accuracy in complex scenarios [9].\n5) Traffic Sign Damage Classification: To the best of our knowledge, only two papers address traffic sign damage classification comprehensively. Ana Trpkovi\u0107, Milica Selmic, and Sreten Jevremovic' (2021) [10] developed a CNN model to identify and classify damaged and vandalized traffic signs. Another significant contribution is by J. N. Acilo et al. (2018) [11], who presented a study titled \"Traffic Sign Integrity Analysis Using Deep Learning.\" This research employed transfer learning with the ResNet-50 architecture to classify the compliance and physical degradation status of traffic signs, achieving high accuracy.\nRoad Damage Detection\n1) Dataset Utilization: Public datasets such as Mappilary [18] and the Road Damage Detection (RDD) [19] dataset provide comprehensive collections of annotated images for training and evaluating models. These datasets cover various types of road damage, including potholes, cracks, and surface wear, facilitating the development of robust detection models.\n2) Deep Learning Approaches: Deep learning approaches, particularly those using CNNs and YOLO architectures, have shown significant advancements in road damage detection. Zhang et al. (2018) [12] employed a deep CNN model to detect road cracks from images, achieving high precision and recall rates. Similarly, Maeda et al. (2018) [13] applied YOLO to detect multiple types of road damage, demonstrating the model's effectiveness in real-world scenarios.\nGPS Data\n1) Integration of GPS Data: M. Strutu, G. Stamatescu, and D. Popescu (2013) [14] introduced a mobile sensor network-based system for monitoring road surfaces, incorporating 3D accelerometers, GPS, and video modules. Their research demonstrated the effectiveness of integrating multiple sensors for comprehensive road monitoring. Similarly, M. Perttunen et al. (2011) [15] developed a system for detecting road surface anomalies using accelerometers and GPS readings from"}, {"title": null, "content": "mobile phones. Their pattern recognition system showcased the potential of mobile devices in monitoring road conditions effectively. Furthermore, R. Tarun and B. P. Esther (2023) [16] created an affordable road sign detection system utilizing a Raspberry Pi and GPS. Their system achieved high detection precision and demonstrated efficient real-time operation.\nAdditional Insights from Recent Advances\nRecent advances in traffic sign recognition have explored a variety of machine learning and deep learning techniques. Lim et al. (2023) [17] provided a comprehensive overview of these advancements, highlighting the importance of preprocessing techniques, feature extraction methods, classification techniques, and the use of diverse datasets to address the challenges posed by different geographical regions, complex backgrounds, and varying illumination conditions.\nKey contributions from recent studies include [17]:\nA comprehensive review of state-of-the-art traffic sign recognition work, categorizing studies into conventional machine learning and deep learning approaches.\nDiscussion of widely adopted traffic sign recognition datasets, their challenges, and limitations, as well as future research prospects in this field.\nEmphasis on the importance of diverse datasets for improving model generalization and robustness."}, {"title": "Methodology", "content": "First Datasets\nMapillary:\nMapillary Vistas Dataset [18] is a large-scale street-level imagery dataset designed for training and evaluating semantic segmentation models. This dataset is highly diverse, covering a wide range of environments, lighting conditions, and geographical locations. It includes various types of road signs, objects, and infrastructure commonly found in urban, suburban, and rural areas. The dataset is particularly useful for developing and testing algorithms for autonomous driving and urban planning applications.\nClasses: 401\nImages: 41,906\nSize: 32.8 GB\nThe dataset is split into training and validation sets, with 80% of the images used for training and 20% reserved for validation."}, {"title": null, "content": "RDD 2022:\nThe Road Damage Detection (RDD) 2022 dataset [19] focuses on identifying and classifying different types of road surface damages. This dataset includes annotated images of road damage from various countries, making it a valuable resource for training machine learning models aimed at improving road maintenance and safety. The primary goal of using this dataset is to detect and classify road damages such as cracks, potholes, and other surface irregularities.\nClasses: 4\nImages: 34,007\nSize: 9.6 GB\nSimilar to the Mapillary dataset, the RDD 2022 dataset is also divided into an 80% training set and a 20% validation set. This split ensures that the models can be trained effectively while also being evaluated on a separate set of images to test their performance and generalization capabilities.\nA comprehensive representation of the architecture for the road sign detection and classification system is depicted in Figure 1. For road damage, detection alone is sufficient, as these are already considered anomalies; therefore, the Yolo model is adequate."}, {"title": null, "content": "B. First Phase\nBefore training the YOLO architectures, data manipulation is essential to ensure optimal performance and accuracy. The data manipulation techniques include the following:\nData Augmentation: This involves applying various transformations to the training images, such as rotations, scaling, flipping, and color adjustments. These techniques help to increase the diversity of the training data and make the model more robust to different conditions.\nNormalization: Image pixel values are scaled to a standard range, typically between 0 and 1, to ensure uniformity and improve the convergence of the model during training.\nLabel Smoothing: This technique is used to reduce overfitting by softening the hard labels in the training data, making the model less confident in its predictions and improving generalization.\nAnchor Box Calculation: Custom anchor boxes are computed based on the dataset to improve the detection accuracy of the YOLO model, especially for objects of various sizes.\nYOLOv8s for Road Surface Damages Detection:\nYOLOv8s is a specific architecture within the YOLO (You Only Look Once) family, optimized for real-time object detection with a balance between speed and accuracy. It is particularly suitable for detecting road surface damages dueto its efficient design.\nPretrained: Yes\nEpochs: 160\nImage Size: 640\nPatience: 100\nCache: RAM\nDevice: GPU\nBatch Size: 64"}, {"title": null, "content": "YOLOv8x for Road Signs Detection:\nYOLOv8x is a larger and more powerful version of the YOLO architecture, designed for detecting objects with higher precision and accuracy. This makes it well-suited for the detailed task of road signs detection.\nPretrained: Yes\nEpochs: 100\nImage Size: 640\nPatience: 100\nCache: RAM\nDevice: GPU\nBatch Size: Auto\nC. Second Dataset\nOnce the YOLO model is trained, it is necessary to build a dataset for the classification of road signs. To achieve this, videos recorded with a dashcam on the road are processed with YOLO, which crops the road signs from the frames. An example of the detected road sign is illustrated in Figure 3. The cropped signs are then labelled as damaged or not damaged based on the following criteria:\n\u2022 Signs covered with spray-painted graffiti\nSigns covered with stickers\nBent or physically damaged signs\n\u2022 Rusty signs\nThe resulting dataset, in preliminary tests, is unbalanced, with 203 damaged and 46 undamaged signs. To address this imbalance, we employed two advanced techniques:\nFocal Loss: This loss function is designed to handle class imbalance by assigning more weight to hard-to-classify examples, reducing the impact of easily classified examples, and improving model performance on imbalanced data.\nCutout Regularization: This technique involves randomly removing sections of the image during training. It helps improve model robustness and prevent overfitting, thereby enhancing the model's ability to generalize to new data."}, {"title": null, "content": "D. Second Phase\nIn this phase, we develop a Convolutional Neural Network (CNN) for classifying road signs as damaged or not damaged. The CNN architecture and training process are described as follows:\nThe CNN model consists of the following layers:\nAn input layer that accepts images of size 150x150x3 (height, width, and color channels).\nA 2D convolutional layer with 32 filters of size 3x3, followed by a ReLU activation function.\nA max-pooling layer with a pool size of 2x2.\nA 2D convolutional layer with 64 filters of size 3x3, followed by a ReLU activation function.\nA max-pooling layer with a pool size of 2x2.\nA 2D convolutional layer with 128 filters of size 3x3, followed by a ReLU activation function.\nA max-pooling layer with a pool size of 2x2.\nA flattening layer to convert the 2D matrix data to a vector.\nA dense (fully connected) layer with 512 units and aReLU activation function.\nA dropout layer with a dropout rate of 0.5 to prevent overfitting.\nA dense output layer with 1 unit and a sigmoid activation function for binary classification.\nThe model is optimized by using Adam, with the Sigmoid Focal Cross-Entropy loss function, particularly effective for handling class imbalance. The accuracy metric is used to evaluate the model's performance.\nTo improve the robustness of the model and generalization capability, data augmentation techniques are applied, including rotation, width and height shifts, shear, zoom, and horizontal flips. Additionally, cutout regularization is implemented by randomly masking sections of the input images during training.\nThe training process involves:"}, {"title": "Computational Experiments", "content": "A. Computational Characteristics\nThe training of the YOLO models is conducted using Google Colab, leveraging the NVIDIA Tesla T4 GPU. Google Colab provides a high-performance computing environment suitable for deep learning tasks. The key specifications of the hardware used are as follows:\nGPU: NVIDIA Tesla T4\nCUDA Cores: 2560\nTensor Cores: 320\nGPU Memory: 16 GB GDDR6\nMemory Bandwidth: 320 GB/s\nPerformance: Up to 8.1 TFLOPS (FP32)\nCPU: Intel(R) Xeon(R) CPU\nvCPUs: 2 (Base Frequency: 2.3 Ghz)\nRAM: 12.7 GB available in the Colab environment\nDisk: 100 GB available storage\nFor the CNN, training was performed on Reevo servers from Tiscali with the following specifications:\nRAM: 32 GB\nCPU: 24 vCPUs (Base Frequency: 2.5 Ghz)\nThe combination of these computational resources provides a robust environment for training and validating the deep learning models, enabling efficient processing of large datasetsand complex computations required for road sign detection and classification.\nB. Metrics for Performance Evaluation and Results\nTo evaluate the performance of the YOLOv8x model for road sign detection, we analyze several key metrics, including accuracy, box loss, and object loss. These metrics provide insights into the model's effectiveness in detecting and classifying road signs accurately.\n1) YOLOv8x Accuracy: Figure 4 shows the accuracy of the YOLOv8x model over the training epochs. The accuracy metric includes the mean Average Precision (mAP) at different Intersection over Union (IoU) thresholds and other performance metrics such as precision and recall."}, {"title": "Conclusions", "content": "In this study, we successfully develop and train YOLO models for road sign detection and CNN models for classifying road signs as damaged or not damaged. Our approach utilizes data augmentation and cutout regularization techniques to improve the robustness and generalization of our models. The computational experiments conducted on Google Colab and Tiscali servers demonstrates the effectiveness of our methods in handling large datasets and complex computations.\nFor future work, we propose the following extensions to enhance the capabilities and applications of our models:\nIncorporating Retroreflectivity Factors: To further refine the classification of road signs, we plan to include retroreflectivity factors in our analysis. This involves detecting and classifying faded or discolored signs, which can significantly impact road safety. Developing models that can identify such signs will be crucial for timely maintenance and replacement.\nLeveraging Generative AI for Data Labeling: The process of manually labeling large datasets is time- consuming and prone to human error. By employing generative Al techniques, we can automate the labeling process, thereby reducing the time and effort required. This will also enable us to handle larger datasets more efficiently.\nGenerating Synthetic Data for Balanced Datasets: One of the challenges we faced was the imbalance between damaged and non-damaged road signs in our dataset. To address this, we propose using generative AI to create synthetic images of damaged signs. By artificially \u201cdamaging\u201d images of non-damaged signs (e.g., adding graffiti, stickers, rust, and physical damage), we can construct a balanced dataset. This synthetic data will enhance the training process, making our models more robust and accurate."}]}