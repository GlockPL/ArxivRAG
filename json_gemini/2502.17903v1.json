{"title": "TOWARDS SUSTAINABLE WEB AGENTS: A PLEA FOR TRANSPARENCY AND DEDICATED METRICS FOR ENERGY CONSUMPTION", "authors": ["Lars Krupp", "Daniel Gei\u00dfler", "Paul Lukowicz", "Jakob Karolus"], "abstract": "Improvements in the area of large language models have shifted towards the construction of models capable of using external tools and interpreting their outputs. These so-called web agents have the ability to interact autonomously with the internet. This allows them to become powerful daily assistants handling time-consuming, repetitive tasks while supporting users in their daily activities. While web agent research is thriving, the sustainability aspect of this research direction remains largely unexplored. We provide an initial exploration of the energy and CO2 cost associated with web agents. Our results show how different philosophies in web agent creation can severely impact the associated expended energy. We highlight lacking transparency regarding the disclosure of model parameters and processes used for some web agents as a limiting factor when estimating energy consumption. As such, our work advocates a change in thinking when evaluating web agents, warranting dedicated metrics for energy consumption and sustainability.", "sections": [{"title": "1 Introduction", "content": "Web agents are LLM-powered systems capable of \"browsing the web\u201d. Considered the next milestone in advancing large language models GoogleDeepMind (2025); David (2025), the idea enables automated interaction with the internet. In essence, allowing web agents to explore much like a human would. While this concept has offered vast potential for intelligent tools, high computational costs Samsi et al. (2023) still remain a major issue. Context window sizes have exploded, exponentially increasing energy consumption and questioning the sustainability of this research direction."}, {"title": "2 Related Work", "content": "With the rapid improvements of LLMs in recent years Dubey et al. (2024) and their ever improving capabilities in tool-use Dubey et al. (2024) a new frontier of research has become possible. With the goal of building agents that can interact with the internet much like a human would, web agents recently are gaining traction Deng et al. (2024); Yao et al. (2022). In this newly developing field, many different benchmarks are being proposed in rapid succession Yao et al. (2022); Deng et al. (2024); He et al. (2024). While efforts to unify these benchmarks exist Chezelles et al. (2024), at the moment, comparing the performance of different web agents is often not feasible. Analogously, the approaches in web agent construction show a high diversity. While some only use HTML for their input Ma et al. (2023); Deng et al. (2024), others use the accessibility tree instead Chezelles et al. (2024) or supplement it with screenshots Zheng et al. (2024) or even use screenshots exclusively, like Pix2Act L\u00f9 et al. (2024). This extends into the approaches used for preprocessing Deng et al. (2024); Gur et al. (2023), the integration of memory modules Ma et al. (2023) and which kind of language models are used. While some approaches use open source models Deng et al. (2024); Gur et al. (2023) many use proprietary models Ma et al. (2023); Zheng et al. (2024); Yang et al. (2024); Zhang et al. (2024) making a precise evaluation of the environmental impact difficult."}, {"title": "2.1 Environmental Impact of LLMs", "content": "There is a pressing discussion on sustainability and the environmental impact of developing and deploying LLMs Bender et al. (2021). Since LLMs are trained on massive amounts of data to provide thorough knowledge, large-scale data centers are required to train the complex model architectures in sufficient time properly. Even though detailed information about LLMs are usually not publicly available, data from previous versions such as OpenAIs GPT-3 already state the usage of 175 billion model parameters being trained on 570 GB of data Brown (2020).\nStatistics on the energy consumption are even sparser and commonly rely on rough estimations due to multiple unknown factors, such as the hardware architecture and efficiency, the training and optimization strategies, and most importantly the energy mix. In work by Lannelongue et al. (2021), a Green Algorithm Calculator is proposed to estimate the Carbon Footprint of LLM training. Depending on the utilized hardware's location, the energy mix between fossil and renewable energies severely impacts the environmental stress. For instance, 20g CO2e kWh (carbon dioxide equivalent per kilowatt hour) in Norway and Switzerland to over 800g CO2e kWh in Australia, South Africa, and the USA. Based on the BERT model Devlin (2018), trained in the USA, they calculated a potential environmental impact of 0.754 metric tons of CO2 for a single training of 79h on 64 Tesla V100 GPUs with an average utilization of 62.7%. For the popular GPT-3 model, also based on the USA energy mix, it is estimated that around 550 metric tons of CO2 emissions were produced to complete the full training, exceeding the previous estimations from BERT tremendously due to the complexity and dataset size increase Shi et al. (2023). On top of the single training run, usually, a significant"}, {"title": "3 Estimating the Energy Consumption of Web Agents", "content": "Web agents are capable of autonomously navigating websites based on a task given by the user. To do this, they execute actions, like using a search field or pressing a button. Which action to take to advance is a complex challenge that current approaches try to solve using LLMs. To decrease this complexity, many approaches Deng et al. (2024); Gur et al. (2023) employ various preprocessing steps to generate likely candidates for actions. From these candidates, the action prediction model then selects the action to take. Figure 1 represents a generic pipeline for web agents.\nWith MindAct Deng et al. (2024) and LASER Ma et al. (2023) we chose two web agents differing in many aspects to provide an example of the diversity in approaches and mentalities present in the field. While MindAct uses comparatively small open-source models and does extensive preprocessing to get the best possible performance out of the available resources, LASER uses a proprietary model at its core with minimal preprocessing being done. The difference in philosophy also shows in the resulting energy cost.\nTo estimate the energy cost for each model, we analyzed and dissected available resources such as the accompanying publications Deng et al. (2024); Ma et al. (2023) and the publicly available source code (https://github.com/OSU-NLP-Group/Mind2Web, https://github.com/Mayer123/LASER). For the open-source models (used in MindAct), we set up a custom test environment to measure their energy consumption.\nFor our evaluation, we decided to use the popular Mind2Web Deng et al. (2024) benchmark. In contrast to other web agent benchmarks Yao et al. (2022); Liu et al. (2018), Mind2Web consists of real-world websites. This allows for a realistic evaluation with respect to the average number of tokens per website. Mind2Web consists of 2350 tasks on 137 websites in 31 domains with an average number of actions needed for task completion of 7.3 and an average number of 1135 HTML elements per website."}, {"title": "3.1 MindAct", "content": "MindAct Deng et al. (2024) divides the process of finding the correct action to advance with fulfilling a given task on the web into two stages, as depicted in Figure 2. The first stage, called candidate generation, is treated as a ranking task. Here, their finetuned DeBERTa 86M He et al. (2021) model is given as input: the user query, previous actions and a cleaned representation of each element in the Document Object Model (DOM) of the HTML webpage. Each cleaned element consists of its tag, its textual content, its salient attribute values and a textual representation of its respective parent and child nodes. From this, DeBERTa estimates a matching value $MS_\u2081$ between 0 and 1 \u2014 indicating how well an element matches to the given user query. This process is repeated for all elements in the DOM. We estimate that the total number of tokens processed by DeBERTa at the end of this process is at the very minimum equivalent to the amount of tokens in the original HTML (no parent/child elements for any DOM element) and at most three times the original HTML tokens (all DOM elements have both parent and child elements). After processing all elements, the 50 elements with the highest matching values are used in the second stage. The second stage, called action prediction,"}, {"title": "3.2 LASER", "content": "In contrast to MindAct, LASER Ma et al. (2023) makes use of a proprietary language model, specifically GPT-4 OpenAI et al. (2024). Since OpenAI has not published any numbers that would allow us to do precise estimations we have to rely on the best estimates made by external observers. LASER itself introduces states and state transitions for web agents, allowing to better recover from mistakes and restricting the possible actions depending on the state of the agent. LASER uses one-shot prompting and makes the model think step-by-step to improve the models capabilities when dealing with complex user queries. Additionally, LASER has access to a memory buffer, to store and access intermediary results (previous actions). Finally, it is specified that LASER is forced to produce a result after a maximum of 15 actions were generated.\nHowever, the authors do not specify explicitly what the input of their web agent is. We inferred, that they use the raw unmodified HTML by analyzing their results and WebShop Yao et al. (2022), the benchmark on which they tested their agent.\nTo compare LASER to MindAct, we calculated the average number of tokens within a HTML page for the Mind2Web benchmark using the GPT-4 OpenAI et al. (2024) tokenizer at $N_{GPT-4}$ = 93778 tokens. We estimate the energy per token $e_{GPT-4}$ through using reported token costs $C_{token} = \\frac{10\\$}{10^6}$ OpenAI (2024) and average energy costs in the US at $C_{energy} = \\frac{0.16\\$}{kWh}$ Department (2024) as a proxy. Note that we also assume that the energy costs only make about $k = 50\\%$ of the token pricing Soham (2024).\n$E_{action} = N_{GPT-4} \\cdot e_{GPT-4}$\nWhere:\n$e_{GPT-4} = k \\cdot \\frac{C_{token}}{C_{energy}}$\n$e_{GPT-4} = 0.5 \\cdot \\frac{\\frac{10}{10^6}\\$\\}{\\frac{0.16 \\$}{kWh}}$\n$e_{GPT-4} = 0.03125 \\frac{Wh}{t}$\nEntering this into 11:\n$E_{action} = 93778 \\cdot 0.03125 \\frac{Wh}{t}$\n$E_{action} = 2930.5625 Wh$"}, {"title": "3.3 Comparing MindAct and LASER", "content": "Due to the lack of relevant information about the energy consumption of LLMs and the challenges involved in gathering this information as a third party, our results should be seen as estimations within a given range. For MindAct, we estimated upper and lower bounds (see Equations (8) and (9)), where the upper bound consumes about two times the amount of energy compared to the lower bound. Compared to these, LASER consumes approximately 2900 times (lower bound of MindAct) and 1500 times (upper bound of MindAct) more energy.\nWhen comparing the energy consumption per token for LASER and MindAct, it becomes clear that the preprocessing done in MindAct is vital. The energy consumption of Laser is only 600 times higher compared to flan-T5XL on its own. By utilizing the small and therefore energy efficient DeBERTa (which consumes 15000 times less energy per token than GPT-4) for preprocessing tasks, MindAct becomes significantly more energy efficient."}, {"title": "3.4 Carbon Dioxide Emissions", "content": "In the previous sections, we estimated the energy consumption per action. However, generally the tasks given to web agents require multiple actions to complete. In the Mind2Web benchmark the average number of actions per task is 7.3 Deng et al. (2024). This is a task taken from the training dataset of Mind2Web Deng et al. (2024) requiring 7 actions:\nUsing the energy consumption estimated above, paired with the information on number of actions needed to complete a task, we can calculate the CO2 emissions per task. In our calculations $N_{actions}$ denotes the amount of actions taken to finish a task, $\u00d8_{CO\u2082}$ the average CO2 emission per Wh and is given as $\u00d8_{co\u2082} = 0.453 \\frac{g}{Wh}$ based on the energy mix of the US Administration (2022). Finally, $E_x$ denotes the energy consumed by web agent a to take one action.\n$Emission_x = N_{actions} \\cdot \u00d8_{CO2} \\cdot E_x$\n$Emission_x = 7.3 \\cdot 0.453 \\frac{g}{Wh} \\cdot \\frac{E_x}{Wh}$\nLower bound for MindAct (Equation (8)):\n$Emission_{min(MindAct)} = 7.3 \\cdot 0.453 \\frac{g}{Wh} \\cdot 0.997432 Wh = 3.30 g$\nUpper bound for MindAct (Equation (9)):\n$Emission_{max(MindAct)} = 7.3 \\cdot 0.453 \\frac{g}{Wh} \\cdot 1.947816 Wh = 6.44 g$\nFor LASER (Equation (16)):\n$Emission_{LASER} = 7.3 \\cdot 0.453 \\frac{g}{Wh} \\cdot 2930.5625 Wh = 9691.08 g$\nThese values are equivalent to driving approximately between 13 m and 25 m for MindAct but a much larger distance of 39 km for LASER with an average car, assuming 248.55 g of CO2 emissions per kilometer driven\u00b9."}, {"title": "4 A Plea for Dedicated Metrics and Small Models", "content": "Our results in Section 3 highlight that the differences in energy consumption between models can be several orders of magnitude even for conservative estimations. While web agents are not widely used yet, they are bound to become a normal part of interacting with the internet in the future. To make their use sustainable at scale, we need to evaluate web agents with respect to their energy efficiency as well, enforcing a more holistic evaluation on the available benchmarks. To do to this, a standardized way of reporting energy consumption is necessary:\nDedicated Metrics: For each LLM in the web agent's pipeline, provide number of tokens per action as well as the energy cost per token.\nWhile these metrics will not allow for a perfectly accurate energy calculation, they serve as a valuable indicator for the web agents' sustainability. In addition, reporting these metrics aids in providing transparency about the energy consumption of web agents. Especially for agents powered by open source LLMs, it is feasible to readily run tests to obtain these numbers on local hardware.\nFurthermore, reporting the energy consumption instead of the CO2 emissions is advantageous, as it is independent of the respective energy mix of the country in which the evaluation is conducted. This further aids comparability while being easily convertible into more tangible values like CO2 emissions using the respective energy mix for the calculation.\nAs shown in Section 3.3, smaller LLMs generally have a smaller energy footprint than larger ones. While larger models are often more capable, the small models can perform well in predefined tasks, such as candidate generation"}, {"title": "5 Limitations", "content": "The accuracy and certainty of our calculations is limited by the availability of trustworthy information regarding the energy cost of the used LLMs. This is an issue especially for proprietary models, where it is not possible to run them locally and track the amount of energy used. While we can assume, that companies generally try to make these models cheaper to use to increase their profit margins, having them disclose this information would significantly increase the accuracy of such estimations. As such, we limited our calculation to a coarse and conservative estimation in terms of orders of magnitude. Doing so, allows us to still draw implications and provide generalizable recommendation for future web agents and their evaluation."}, {"title": "6 Conclusion", "content": "In this work we provide a comparison between energy consumption of two web agents, MindAct and LASER. We show that web agent design can influence the energy consumption by orders of magnitude and propose the introduction of standardized metrics to evaluate the energy consumption of web agents. Our work has revealed several current gaps in web agent research, such as a lack of awareness for sustainability and transparency. We believe that accounting for sustainability in web agent research is important due to the environmental impact of these agents at scale. By using smaller models where possible and developing efficient algorithms, it is possible to reduce the amount of data the larger LLMs have to process, making the pipeline more energy efficient. In addition, we advocate for dedicated metrics to make the energy consumption of different web agents for the same task comparable."}]}