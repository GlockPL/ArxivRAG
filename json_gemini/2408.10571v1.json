{"title": "Prompt-Agnostic Adversarial Perturbation for\nCustomized Diffusion Models", "authors": ["Cong Wan", "Xiang Song", "Yuhang He", "Yihong Gong"], "abstract": "Diffusion models have revolutionized customized text-to-image generation, allow-\ning for efficient synthesis of photos from personal data with textual descriptions.\nHowever, these advancements bring forth risks including privacy breaches and\nunauthorized replication of artworks. Previous researches primarily center around\nusing \"prompt-specific methods\" to generate adversarial examples to protect per-\nsonal images, yet the effectiveness of existing methods is hindered by constrained\nadaptability to different prompts. In this paper, we introduce a Prompt-Agnostic\nAdversarial Perturbation (PAP) method for customized diffusion models. PAP first\nmodels the prompt distribution using a Laplace Approximation, and then produces\nprompt-agnostic perturbations by maximizing a disturbance expectation based on\nthe modeled distribution. This approach effectively tackles the prompt-agnostic at-\ntacks, leading to improved defense stability. Extensive experiments in face privacy\nand artistic style protection, demonstrate the superior generalization of our method\nin comparison to existing techniques.", "sections": [{"title": "Introduction", "content": "Generative methods based on diffusion models [1-4] have made significant improvements in recent\nyears, enabling high quality text-to-image synthesis [5, 6], image editing [7], video generation [8, 9],\nand text-to-3D conversion [10] by prompt engineering. One of the most representative methods in this\nfield is the Stable Diffusion [11, 12], which is a large-scale text-to-image model. By incorporating\ncustomized techniques such as Text Inversion [13] and DreamBooth [14], Stable Diffusion only\nrequires fine-tuning on a few images to accurately generate highly realistic and high-quality images\nbased on the input prompts.\nDespite this promising progress, the abuse of these powerful generative methods with wicked exploita-\ntion raises wide concerns [15], especially in portrait tampering [16] and copyright infringement [17].\nFor example, in Figure 1(a), given several photos of a person, attackers can utilize diffusion models to\ngenerate fake images containing personal information, leading to reputation defamation. Even worse,\nattackers can easily plagiarize unauthorized artworks using diffusion models, leading to copyright and\nprofit issues. There is an urgent technology need to protect images from diffusion model tampering.\nTo this end, recent research studies delve into adding human-invisible adversarial perturbations onto\nthe images to prevent prompt-based tampering using diffusion models. The method Photoguard [18]\nmaximizes the distance in the VAE latent space. Glaze [19] aims to hinder specific style mimicry,\nwhile Anti-DreamBooth [20]introduces an alternating training approach between the model and\nadversarial examples. The AdvDM series [21, 22], Adv-Diff [23] present theoretical frameworks and\nimproved methods for attacking LDM."}, {"title": "Related Work", "content": "Text-to-image generation models. In the past decade, there have been significant advancements\nin text-to-image generation models. Early models, such as cGANs [24], introduce label-based\ncontrol, while diffusion models further advance the field by pushing the boundaries of application"}, {"title": "Prompt-Agnostic Adversarial Perturbation", "content": "3.1 Background and Motivation\nPrompt-based Diffusion Models. A vanilla diffusion model [1, 3] aims to gradually transfer a\nsimple Gaussian noise into high-quality images through a series of denoising steps. It mainly\ncontains a forward process (i.e., diffusion) and a backward process (i.e., denoising). Begin with an\nimage xo, the forward process iteratively adds Gaussian noise $$\\epsilon$$ ~ N(0, I) with a noise scheduler\n$${a}_{t}$$, $${\\bar{a}}_{t}$$ \u2208 (0,1)=1 to the input image. The t-step obtained noised image xt can be written as:\n$$x_{t} = \\sqrt{{\\bar{a}}_{t}}x_{0} + \\sqrt{1 - {\\bar{a}}_{t}} \\epsilon$$\nwhere $$\\bar{a}_{t}$$ = $$\\prod_{i=1}^{t} a_{i}$$. When t \u2192 \u221e, xt is a Gaussian noise (i.e., xt = $${\\epsilon}$$). In the backward process,\nthe objective is to learn a noise predictor $$\\epsilon_{\\theta}(x_{t}, t)$$ predicting the added Gaussian noise at each step\nt. On this basis, taking a Gaussian noise (i.e., xt(t \u2192 \u221e)) as input, the diffusion model denoise\nthe image xt using $$e_{\\theta}(\\cdot)$$, i.e., $$\\textstyle x_{t-1} = \\frac{1}{\\sqrt{a_{t}}}(x_{t} - \\frac{1-\\bar{a}_{t}}{\\sqrt{1 - {\\bar{a}}_{t}}}\\epsilon_{\\theta}(x_{t}, t)) + \\sigma_{t}z$$, z ~ N(0, I), and iteratively\ngenerates a high-quality image xo by t denoising steps.\nThe prompt-based diffusion models [11] aim to generate a semantic guided image xo from the\nGaussian noise $${\\epsilon}$$. To this end, in the backward process, they additionally take a text prompt c as the\ninput of noise predictor $$e_{\\theta}(x_{t}, t, c)$$ alongside the Gaussian noise xt, and align the image and text\nrepresentation by cross-attention mechanism. The image generation objective of the prompt-based"}, {"title": "PAP: Prompt-Agnostic Perturbation by Prompt Distribution Modeling", "content": "different from the existing methods that compute a prompt-specific perturbation by enumerating\nprompt instances, we attempt to compute a prompt-agnostic perturbation by prompt distribution\nmodeling, wherein the obtained perturbation is robust to both seen and unseen attack prompts.\nTo this end, we first model and compute a prompt distribution by Laplace approximation, wherein\ntwo estimators $$\\hat{c}_{x}$$ and $$\\hat{H}$$\n are developed to compute the distribution parameters. And then we perform\nMonte Carlo sampling on each input distribution to maximize a disturbance expectation.\nSpecifically, for the prompt distribution modeling, we consider a protecting image xo as input and\nassume a probability-distance correlation between the attacker prompt c and xo, i.e., the further c\nis from xo, the lower probability of c is in the distribution, and vice versa. The distribution relies\non xo is ambiguous, thus we introduce an auxiliary text prompt co roughly depicting xo into the\nmodeling. Based on this foundation, we model the prompt distribution in the embedding space\nas $$c \\in \\mathcal{Q}(x_{0}, c_{0})$$, where $$\\mathcal{Q}(x_{0}, c_{0})$$ represents the theoretical distribution with a probability density\nfunction $$p(c | x_{0}, c_{0})$$. Based on this setup, we approximate the original distribution $$\\mathcal{Q}(x_{0}, c_{0})$$ using a\nGaussian distribution $$\\tilde{\\mathcal{Q}}(x_{0}, c_{0})$$ by Laplace approximation, i.e., $$c \\in \\mathcal{Q}(x_{0}, c_{0}) \\sim \\mathcal{N}(\\hat{c}_{x}, \\hat{H}^{-1})$$, where\n$$\\hat{c}_{x} = \\arg \\max_{c} p(c|x_{0}, c_{0})$$, and $$\\hat{H}$$ is the Hessian matrix of $$c_{x}$$. As we derived in Section 3.3.1, the\napproximation error is $$\\mathcal{O}(|c - c_{x}|^{3})$$, which is negligible as the sampled $$c \\in \\mathcal{Q}(x_{0}, c_{0})$$ is close to $$\\hat{c}_{x}$$.\nOn this basis, we propose two estimators $$\\hat{\\psi}$$ and $$\\hat{\\phi}$$ used to estimate $$\\hat{c}_{x}$$ and $$\\hat{H}^{-1}$$, respectively. For\n$$\\hat{\\psi}$$, to compute $$c_{x} = \\arg \\max_{c} p(c|x_{0}, c_{0})$$ that best describe xo, we approximate $$\\hat{c}_{x} = \\tilde{c}(x_{0}, \\epsilon)$$\nby minimizing the generation loss in Eq. (2) with momentum iterations starting from co. This\napproach accelerates convergence and avoids getting trapped in local minima. For $$\\hat{\\phi}$$, we approximate\n$$\\hat{H}^{-1} = \\mathcal{H}(x, \\epsilon, c_{0}, t)$$ by performing a Taylor expansion around the flattened $$\\hat{c}_{x}$$ and incorporating\nprior information from co. In Appendixes A.2 and A.3, we have proven that the estimation errors of Cx\nand H-\u00b9 are with explicit upper bounds, and more detailed descriptions are provided in Section 3.3.2.\nThen, we compute the prompt-agnostic adversarial perturbation $$\\delta$$ by maximizing the expectation of\n$$L_{cond}$$ in Eq.(2) over the prompt distribution $$\\mathcal{Q}(x_{0}, c_{0})$$. The objective can be formulated as:\n$$\\delta^{*} = \\arg \\max_{\\delta} \\mathbb{E}_{c\\sim\\mathcal{Q}(x_{0}, c_{0})} [L_{cond}(x_{0} + \\delta, c_{0}; \\theta)]$$\n$$= \\arg \\max_{\\delta} \\int p(c|x_{0}, c_{0}) \\cdot L_{cond}(x_{0} + \\delta, c_{0}; \\theta) dc, s.t. ||\\delta||_{p} \\leq \\eta,$$"}, {"title": "Modeling the Prompt Distribution $$\\mathcal{Q}(x_{0}, c_{0})$$", "content": "In this subsection, we first approximate the form of $$\\mathcal{Q}(x_{0}, c_{0})$$ and then estimate its mean and variance.\n3.3.1 Laplace Modeling\nDefinition 3.1. Since xo and co are independent of c, we consider Z = p(xo, co) as a constant. De-\nnote g(c) := p(xo, co|c)\u00b7p(c), $$c_{x}$$ := arg maxc g(c), and H := \u2212\u2207\u2207clogg(c) |$$c_{x}$$, for convenience.\nWe adopt Laplace approximation to model $$\\mathcal{Q}(x_{0}, c_{0})$$. Using Bayes' theorem, we obtain:\n$$p(c|x_{0}, c_{0}) = \\frac{p(x_{0}, c_{0} | c) \\cdot p(c)}{p(x_{0}, c_{0})}$$\nWe then approximate log g(c) in Definition 3.1 around $$\\hat{c}_{x}$$ using a second-order Taylor expansion:\n$$\\text{log} g(c) \\approx \\text{log} g(c_{x}) - \\frac{1}{2}(c - c_{x})^{T}H(c - c_{x}).$$\nFrom Eq.(6) and by ignoring terms that are independent of c, we infer that\n$$p(c|x_{0}, c_{0}) \\propto \\text{exp} \\Big(-\\frac{1}{2}(c - c_{x})^{T}H(c - c_{x})\\Big)$$,\nwhich means p(c|x0, co) could be approximated as a normal distribution, i.e.,\n$$\\mathcal{Q}(x_{0}, c_{0})(c) \\sim \\mathcal{N}(c_{x}, H^{-1}).$$\nThe derivation is provided in Appendix A.1, wherein the error of the Gaussian approximation is the\nthird-order derivatives of log p(x) around cx, i.e., $$\\mathcal{O}(|c - c_{x}|^{3})$$.\n3.3.2 Parameter Estimators\nEstimator $$\\hat{\\psi}$$. According to Definition 3.1, $$c_{x}$$ is defined as the text feature that maximizes the joint\nprobability of xo and co. As directly maximizing the likelihood is untrackable, similar to [43], we\nconvert the likelihood maximization problem into an expectation minimization problem with a proper\napproximation (please kindly refer to Appendix A.2) for more details), which can be written as:\n$$\\hat{c}_{x} = \\tilde{c}(x_{0}, \\epsilon) = \\arg \\min_{c} \\sum_{t=0}^{T} L(x_{0}, \\epsilon, t, c; \\theta) = \\arg \\min_{c} \\sum_{t=0}^{T} ||\\epsilon - \\epsilon_{\\theta} (x_{t}, t, c)||^{2}$$\nTo solve for $$\\hat{c}_{x}$$ in Eq.(9) and avoid local minimal, we derive a momentum-based iterative method\n[31] with the initial value set as the reference prompt co:\n$$m_{i} = \\beta m_{i-1} + (1 - \\beta) \\nabla \\mathcal{L}(x, \\epsilon, t, c; \\theta),$$\n$$c_{i} \\gets c_{i-1} - r \\cdot m_{i},$$\nwhere mi represents the momentum term at iteration i, and r, \u03b2 are learning rates.\nEstimator $$\\hat{\\phi}$$. To compute H in Definition 3.1, we adopt three operations: substituting - logg(c) with the loss function L in Eq.(2), incorporating prior information from co, and applying the Taylor\napproximation of L around the flattened $$\\hat{c}_{x}$$ Detailed in Appendix A.3.1),which enable us to compute:\n$$(c_{0} - c_{x})^{T}H(c_{0} - c_{x}) = 2 \\cdot (\\mathcal{L}(x, \\epsilon, t, c_{0}; \\theta) - \\mathcal{L}(x, \\epsilon, t, \\hat{c}_{x}; \\theta)),$$\nTo obtain H-1 from Eq.(11), we simplify the effective dimensionality of H in Appendix A.3.2). This\nallows us to estimate the H-1 using the following expression:\n$$H^{-1} = \\psi(x, \\epsilon, c_{0}, t) = \\frac{\\|c_{0} - c_{x}\\|^{2}}{2 \\cdot (\\mathcal{L}(x, \\epsilon, t, c_{0}; \\theta) - \\mathcal{L}(x, \\epsilon, t, \\hat{c}_{x}; \\theta))} I,$$\nwhere I represents the identity matrix and x are input images. As we analyzed in Appendix A.3.2,\nthe cosine distance between the approximated $$\\hat{H}^{-1}$$ and H-1 (diagonalized assumption) is with an\nupper bound of 0.0909 under our standard experimental settings. This simplification significantly\nreduces the computational complexity with a minor approximation error."}, {"title": "Maximizing the disturbance expectation", "content": "In this subsection, we devise the strategy of maximizing the disturbance expectation based on the\nmodeled prompt distribution, thereby obtaining the final PAP algorithm outlined in Algorithm 1.\nSampling Distributions for maximization. To maximize the optimization objective Eq. (4) from\na global perspective, we adopt Monte Carlo sampling on all input distributions, including $$\\mathcal{Q}(x_{0}, c_{0})$$.\nDrawing inspiration from established adversarial attack methods [21, 28, 44], we iteratively sample\nvalues for t, $${\\epsilon}$$, and $${\\epsilon}_{c}$$. Subsequently, we perform a gradient ascent step of L(x, $${\\epsilon}$$, t, c; $$\\theta$$) with respect\nto x, which can be summarized as:\n$$x_{i+1} = x_{i} + \\alpha \\cdot \\text{sgn}(\\nabla_{x_{i}} \\mathcal{L}(x_{i}, \\epsilon, t, c; \\theta) | {\\epsilon} \\sim \\mathcal{N}(0, I), t \\in \\mathcal{U}(0, T), c \\sim \\mathcal{Q}(x_{0}, c_{0})),$$,\nwhere sgn(\u00b7) refers to the sign function, and \u03b1 controls the step size of the gradient ascent.\nFurther Discussion. To further enhance the effectiveness of our proposed algorithm, we seamlessly\nintegrate it with other techniques in Appendix C, such as ASPL [20], to reach a better performance.\nWe also discuss modifying the perturbation space with the tanh function for smoother optimization\nwith better flexibility [44] than clipping-based constraints in Appendix B. Lastly, Appendix H explores\nthe limitations and future directions of our model."}, {"title": "Experiments", "content": "In this section, we experimentally compare PAP with other protection methods for customized\nmodels, specifically targeting DreamBooth, the leading customized text-to-image diffusion model\nfor personalized image synthesis. DreamBooth customizes models by reconstructing images using a\ngeneric prompt that includes pseudo-words like \"sks,\" while also addressing overfitting and shifting\nthrough a prior preservation loss. We evaluate PAP on various tasks, including privacy and style\nprotection, using diverse datasets."}, {"title": "Experimental setup", "content": "Datasets. Our experiments involve face generation tasks using CelebA-HQ [45] and VGGFace2\n[46] datasets, as well as style imitation task using the Wikiart dataset [47]. For CelebA-HQ and\nVGGFace2, we select subsets of 600 images respectively, with each of 12 photos from an identical\nindividual. For Wikiart, we choose 100 paintings, with each set consisting of 20 paintings from the\nsame artist.\nImplementation Details. We optimize adversarial perturbations over 50 training steps and 20 text\nsampling steps. The step size of image, text and momentum is set to 1/255 and 0.001, 0.5 respectively,\nand the default noise budget is 0.05. For the Dreambooth, LoRA,TI models, we train the models"}, {"title": "Comparison with State-of-the-Art Methods", "content": "4.2.1 Face Privacy Protection\nWe first conduct experiments in preserving face privacy. During training, the reference and training\nprompt are both set as \u201ca photo of sks person\". Then we use ten prompts related to sks person\nto evaluate the models' ability to synthesize images. The average results are presented in Table 1,\nshowcasing the superior performance of our method in terms of all metrics on both the CelebA-HQ\nand VGGFace2 datasets. For example, on the CelebA-HQ dataset, our method exceeds the second-best\nAnti-DB by 13.55% in LPIPS, and reduces by 13.06% and 3.948% in CLIP-I and LAION. Also, on\nthe VGGFace2 dataset, our method exceeds the second-best method by 6.347% in BRISQUE, and\nreduces by 5.818% and 6.833% in CLIP-I and CLIP. These results highlight the effectiveness of our\nmethod in preserving face privacy as well as robustness to datasets and various prompts' attacks.\n4.2.2 Style Imitation\nWe also evaluate methods' ability to prevent artistic style imitation using the Wikiart dataset. The\nreference and training prompt are both set as \"a sks painting\". Ten prompts related to the style of"}, {"title": "Ablation Study", "content": "Text Sampling Steps. We evaluate PAP under different text sampling steps N (ranging from 0 to\n25) used for sampling the prompt e during training. We use the Wikiart dataset and \"a sks painting\"\nprompt to conduct this ablation experiment (see Table 2). Taking into account the cycle time and\nmodel performance, we set the text sampling step N to 15.\nInference Prompt Combination. To analyze the effect of prompt variation, we design combinations\nof prompt categories and quantity: 4\u00d720, 8\u00d710, 10\u00d78, 16\u00d75, 20\u00d74. This keeps the total number of\ngenerated images constant while varying the number of prompt categories, allowing us to isolate the\neffect of prompt categories on the results. As Figure 3 shows, PAP consistently surpasses all other\ncomparison methods and maintains a robust defense against changes in prompt categories.\nPseudo-word. In our experiments, we conduct evaluations using the commonly used pseudo-word\n\"sks,\" which is representative but may not cover all possible cases. To further validate our method,\nwe included additional less commonly used pseudo-words. Results in Table 10 clearly demonstrates\nthat our method consistently outperforms the others with other pseudo-word.\nOther Customized Models. To verify the robustness of proposed methods to fine-tuning methods,\nwe apply PAP to Textual Inversion and DreamBooth with LoRA. LORA [52], a widely used efficient"}, {"title": "Conclusion", "content": "This work mitigates risks from misusing customized text-to-image diffusion models. We introduce\nsubtle perturbations optimized from a modeled prompt distribution, fooling such models for any\nprompt. Demonstrating resilience against diverse attacks, our framework surpasses prior prompt-\nspecific defenses through robustness gains. By efficiently perturbing content via a distribution-aware\nmethod, our contributions effectively safeguard images from diffusion model tampering under\nunknown prompts."}, {"title": "Derivation of Prompt Distribution Modeling", "content": "In this section, our goal is to develop an algorithm for modeling the prompt distribution given a\nreference prompt co and protecting images xo. Since the exact form of this distribution is impractical\nto derive, we employ the idea of Laplace approximation. By considering a second-order Taylor\nexpansion at a critical point, we approximate the distribution near this critical point as a Gaussian\ndistribution. To reduce computational complexity, we make assumptions and approximate estimates\nfor the mean and variance. The algorithm is presented in Algorithm 2."}, {"title": "Laplace Approximation Details", "content": "A.1.1 Motivation and Basic Idea\nLaplace approximation is a simple yet widely used method for approximating probability distributions,\nespecially in the context of Bayesian inference and machine learning. The main idea behind Laplace\napproximation is to approximate a target distribution p(x) by a Gaussian distribution $$\\mathcal{N} (\\mu, \\Sigma)$$, where\nthe mean \u00b5 and covariance \u2211 are determined by matching the extreme point and curvature of the\ntarget distribution at its extreme point.\nSpecifically, let cr be the maximum point of p(x), i.e., $$c_{x} = \\arg \\max_{x} p(x)$$. Laplace approximation\nuses a second-order Taylor expansion of log p(x) around cx to construct the approximate Gaussian\ndistribution:\n$$\\text{log} p(x) \\approx \\text{log}(c_{x}) - \\frac{1}{2}(x - c_{x})^{T}H(c_{x})(x - c_{x}) + \\mathcal{O}(|x - c_{x}|^{3}),$$\nwhere H(cx) is the Hessian matrix (the matrix of second-order partial derivatives) of log p(x)\nevaluated at Cr. Exponentiating both sides and ignoring the higher-order terms, we obtain the Laplace\napproximation:\n$$p(x) \\approx \\mathcal{N}(c_{x}, -H(c_{x})^{-1}).$$\nA.1.2 Error Analysis\nThe error of the Laplace approximation comes from neglecting the higher-order terms in the Taylor\nexpansion. The approximation error can be quantified by the remainder term $$\\mathcal{O}(|x \u2212 c_{x}|^{3})$$, which\nrepresents the third and higher-order derivatives of log p(x) evaluated at some point between x and\nCx.\nMore precisely, let \u00a7(x) denote the remainder term, then the Laplace approximation can be written\nas:\n$$p(x) = \\mathcal{N}(c_{x}, -H(c_{x})^{-1})\\text{exp}(\\xi(x)),$$"}, {"title": "Estimation of Cr", "content": "From Definition 3.1 and derivations in AdvDM [21], we have:\n$$\\text{log}g(c) = \\text{log} p(c) + \\text{log} p(x_{0}, c_{0} | c)$$\n= log p(c) + $$\\mathbb{E}_{t} [\\text{log} p(x_{t-1}|c, x_{t})]$$,\nwhere xt is defined in Eq.(1).\nSince minimizing the diffusion loss to maximize likelihood is a common practice, we have:\n$$c_{x} = \\arg \\max_{c} \\mathbb{E}_{t} [\\text{log} p(x_{t-1} | c, x_{t})]$$\n= arg min $$\\mathbb{E}_{t, \\epsilon \\sim \\mathcal{N} (0,1)} \\mathcal{L}_{cond}(x_{0} + \\delta, c; \\theta)$$.\nTo reduce computational cost, we approximate Eq.(18) with bounded error, and estimate Cr using\na single sample of $${\\epsilon}$$ instead of averaging. The detailed derivation and justification can be found in\nAppendix A.2.1 and A.2.2. The final estimation of Cr can be derived as follows:\n$$ = \\arg \\min_{c} \\sum_{t=0}^{T} \\mathcal{L}(x, \\epsilon, t, c; \\theta).$$$\nEmpirical ablation experiments validate the effectiveness of this estimation, as demonstrated in Table\n8.\nTo solve for $$\\hat{c}_{x}$$ and avoid local optima, we employ an iterative method with momentum to estimate\nCr instead of directly solving for a local minimum. In this approach, we leverage the ensemble of loss\nfunctions from different time steps in Eq. (2). Inspired by transferable adversarial attacks [31], we\naim to find a transferable Cr that navigates the diverse loss landscape using the momentum iteration\nalgorithm.\n$$m_{i} = \\beta m_{i-1} + (1 - \\beta) \\nabla \\mathcal{L}(x, \\epsilon, t, c; \\theta),$$\n$$c_{i} \\gets c_{i-1} - r \\cdot m_{i}.$$\nHere, mi represents the momentum term at iteration i. The details of the information about the\ntransferable adversarial attacks can be found in Appendix D.\nAdditionally, considering that co serves as a reference prompt input that is typically expected to be\nhighly correlated with the content of the image, we assume that co and Cx are very close in the textual\nspace. Then the iterative solution for cr can be initialized from co."}, {"title": "Upper bound of Cr estimation error.", "content": "Theorem A.1. Assume g : $$\\mathbb{R}^{m \\times m}$$\u2192 R is Lipschitz continuous under $$\\mathcal{L}_{1}$$ norm. Then, as n \u2192 \u221e,\nwe have\n$$|\\frac{1}{n} \\sum_{i=1}^{n} g(x_{i}) - g(\\frac{1}{n} \\sum_{i=1}^{n} x_{i})| < 2L\\frac{\\sqrt{\\pi}}{n} ,$$\nwhere $$x_{i} ~ \\mathcal{N}(0, I)$$ for i = 1 : n.\nProof. The Lipschitz continuity condition for the 1-norm can be expressed as follows: For any\nx, y \u2208 $$\\mathbb{R}^{m \\times m}$$, there exists a constant L > 0 such that $$\\mid \\mid g(x) \u2212 g(y)\\mid \\mid \\leq L \\mid \\mid x \u2212 y\\mid \\mid$$. By taking the"}, {"title": "Single sample for e", "content": "Based on the theorem's conclusion, we have the flexibility to choose between weighting before the\nforward pass or weighting after the forward pass during Gaussian sampling, while ensuring that\ntheir errors are within a certain upper bound. By introducing the scaling factor \u221an, we are able to\npreserve the distribution characteristics of the input samples, which is crucial for subsequent diffusion\nprocesses.\nAn easy corollary of Theorem A.1 further states:\nCorollary A.2. Let L(e) denotes Eq.(2) for convenience, given t, xo, c, 0. As n \u2192 \u221e, we have\n$$\\frac{1}{n} L(e_{i}) - L(\\frac{1}{\\sqrt{n}} \\sum_{i=1}^{n} e_{i})| < 2K\\frac{\\sqrt{2}}{\\sqrt{n}},$$$\nwhere $$e_{i} \\overset{i.i.d.}{\\sim} \\mathcal{N}(0, I)$$ for i = 1 : n, K is finite.\nTo enable backpropagation, the model loss L(\u20ac) must be differentiable with bounded gradients,\nsatisfying the Lipschitz continuity condition with respect to \u20ac . In Corollary A.2, we observe that\n$$\\sum_{i=1}^{n} \\frac{e_{i}}{\\sqrt{n}}$$  N(0, 1). Instead of computing the entire average, we can directly sample e from\nN(0, 1) for the forward process. This allows estimating Eq.(18) practically with a single sample \u20ac,\nwhile ensuring that the estimation error is within a certain range as introduced in Eq.(31).\nPlease note that this is a very coarse upper bound estimation. In practice, we find that the actual\ndifference is far less than this upper bound. This may be because we use a pretrained large model\nwhich has already been well-trained and generalized well to lots of inputs, making the loss typically\nvery close to and small (always within 1(K)). Therefore, we corroborate with experimental results\nand find that it unnecessary to resample e repeatedly in the process of optimizing Cr.\nMoreover, merely comparing the L values is insufficient. We must show that when L values are close,\nthe difference between the corresponding c values is sufficiently small. When the loss difference\nL(cx) - L(cy) is constrained within a certain range, the text embedding difference Cx Cy will also\ntypically be limited, due to the following reasons:\n\u2022 Pretrained language generation models are extremely sensitive to even minor changes in\ninput sequences [56], such as the prompt. These subtle alterations can result in significant\nvariations in the model's predicted outcomes and loss function. Therefore, when the\ndifference in loss is constrained within a certain range, we can infer that the semantic\ndisparity in the prompts is also effectively controlled.\nTherefore, restricting the loss difference helps bound the text embedding difference, validating that\nthe proposed c values indeed represent meaningful alternative text options rather than arbitrary or\nrandomly perturbed sequences. This ensures the method can generate semantically-meaningful\nalternatives as expected."}, {"title": "Estimation of H-1", "content": "A.3.1 Derivation of H\nDirectly computing the H matrix requires quadratic complexity, and calculating its inverse further\nrequires cubic complexity. Even with an A800 device with 80GB of memory, it is insufficient to\nsupport such a computational workload.\nRecall that we are interested in estimating the inverse of the Hessian matrix H = -\u2207\u2207clogg(c) |$$c_{x}$$.\nIn general, the inverse of a matrix is expensive to compute, especially for large matrices. Therefore,\nwe seek to simplify the computation of H\u00af\u00b9 by leveraging low-order information.\nWe begin by considering the second-order Taylor expansion of g(c) around $$\\hat{c}_{x}$$ (flattened 59,136-\ndimension vector) :\n$$g(c) \\approx g(c_{x}) + \\nabla g(c_{x})^{T} (c-c_{x}) - \\frac{1}{2}(c - c_{x})^{T}H(c - c_{x})$$\nSince cx is the maximizer of g(c), we have \u2207g(cx) = 0. Therefore, Eq. 32 simplifies to:\n$$g(c) \\approx g(c_{x}) - \\frac{1}{2}(c - c_{x})^{T}H(c - c_{x})$$\nWe can obtain the estimation formula of H with respect to L(c) since \u2013L(c) is used to compute g(c):\n$$H = \\nabla \\nabla \\mathcal{L}(c) |c_{x}$$,\nTherefore, we have:\n$$(c_{0} - c_{x})^{T}H(c_{0} - c_{x}) = 2(\\mathcal{L}(c_{0}) - \\mathcal{L}(c_{x})),$$\nSimplification for Estimation of H-1\nResearch [57] has shown that word embeddings can represent word semantics through distributed,\nlow-dimensional dense vectors. These embeddings capture linguistic patterns and regularities while\nrequiring substantially less memory than sparse high-dimensional representations.\nBased on the aforementioned research findings and previous approaches for variance estimation in\nLaplace modeling [58], we make the assumption that the Hessian matrix is a positive definite diagonal\nmatrix. This assumption is reasonable since calculating the Hessian matrix in the high-dimensional\ntext feature space poses significant computational challenges for stable diffusion models. Furthermore,\nas the Hessian matrix represents the second-order derivative of the log-likelihood function, it must be\npositive definite at the maximizer Cx to ensure the local convexity of the function.\nDefinition A.3. Let $$(c_{0} - c_{x}) = [t_{1}, t_{2},...,t_{n}]^{T}$$. Let H = diag(h1, h2, ..., hn), $$ \\frac{1}{l} > h_{i} > 0$$, i =\n1,2, ..., n. Denote L := 2($$\\mathcal{L}(c_{0}) - \\mathcal{L}(c_{x})$$). Define D := $$\\sum_{i=1}^{n} \\frac{1}{h_{i}}$$.\nFrom Definition A.3, we have:\n$$H = $$\n$$(c_{0} - c_{x})^{T}H(c_{0} - c_{x}) = [t_{1}, t_{2},...,t_{n}] $$\n=\nThis implies that Eq.(35) can be written as:\n$$\\sum_{i=1}^{n} t_{i}^{2}h_{i} = L$$\nGiven Eq.(37) as a n-variable linear equation, solving it alone is insufficient. Additional n-1 equations\nare required to obtain a complete solution. However, due to the large value of n=51,396, solving this\nsystem of equations would be highly time-consuming."}, {"title": "Discussion for PAP", "content": "We propose to incorporate prompt sampling and optimization into the PGD framework, analogous to\nAdvDM. Inspired by CW attacks [44], which maps adversarial examples to the tanh space, we can\nrelax the constraints on the optimization problem compared to standard PGD."}]}