{"title": "ProtoNAM: Prototypical Neural Additive Models for Interpretable Deep Tabular Learning", "authors": ["Guangzhi Xiong", "Sanchit Sinha", "Aidong Zhang"], "abstract": "Generalized additive models (GAMs) have long been a powerful white-box tool for the intelligible analysis of tabular data, revealing the influence of each feature on the model predictions. Despite the success of neural networks (NNs) in various domains, their application as NN-based GAMs in tabular data analysis remains suboptimal compared to tree-based ones, and the opacity of encoders in NN-GAMS also prevents users from understanding how networks learn the functions. In this work, we propose a new deep tabular learning method, termed Prototypical Neural Additive Model (ProtoNAM), which introduces prototypes into neural networks in the framework of GAMs. With the introduced prototype-based feature activation, ProtoNAM can flexibly model the irregular mapping from tabular features to the outputs while maintaining the explainability of the final prediction. We also propose a gradient-boosting inspired hierarchical shape function modeling method, facilitating the discovery of complex feature patterns and bringing transparency into the learning process of each network layer. Our empirical evaluations demonstrate that ProtoNAM outperforms all existing NN-based GAMs, while providing additional insights into the shape function learned for each feature. The source code of ProtoNAM is available at https://github.com/Teddy-XiongGZ/ProtoNAM.", "sections": [{"title": "1 Introduction", "content": "In the field of machine learning, generalized additive models (GAMs) have been recognized for their interpretability [6, 12, 14, 15, 28, 33]. It provides a transparent perspective through which the impact of individual features on predictions can be observed. This transparency is achieved by independently modeling each feature with a non-linear transformation, thus providing an intuitive understanding of the data. With the evolution of machine learning, sophisticated modeling tools such as Gradient Boosting Decision Trees (GBDTs) and neural networks (NNs) have been integrated with GAMs. This integration aims to harness the expressive power of these advanced models while preserving the interpretability that is the hallmark of GAMs, seeking to strike a balance between expressiveness and interpretability.\nDespite the great success of deep neural networks (DNNs) in areas such as computer vision [17, 18, 21, 39] and natural language processing [9, 19, 25, 37], they fail to establish a definitive advantage over GBDTs in the area of tabular data analysis [11, 24]. Tabular data is prevalent in high-stakes domains such as finance and healthcare, where numerical features may exhibit complex patterns due to their potential correlation with discrete categorical features (e.g., age and retirement status). Capturing these patterns is particularly challenging in the context of GAM, where information is encoded independently for each tabular feature. Neural networks, which tend to smooth learned functions, may struggle in modeling these intricate relationships, resulting in their performance often being inferior to GBDT-based methods [11].\nHowever, while GBDT-based GAMs maintain their lead in performance, they are not as flexible as NNs in terms of multitask modeling. Neural networks exhibit unique capabilities in multi-task learning [1, 31], fitting multiple tasks simultaneously with one network, which can help mitigate model bias and thus improve AI fairness. In practice, it is crucial to handle sensitive features such as gender and race with care, as they may not be suitable to serve as direct predictors. Instead, it would be appropriate to treat the prediction for each group as a separate task and design the training on the whole dataset as multitask learning, which can hardly be performed by GBDT-GAMs.\nIn response to these challenges, we introduce ProtoNAM, an interpretable deep tabular learning architecture that improves the performance of NN-based GAMS on tabular data using prototypes. ProtoNAM incorporates a novel prototype-based feature activation, which captures representative feature values from data and learns the corresponding activation patterns, facilitating the learning of subtle variations of model predictions in the feature domain. We also propose a hierarchical shape function modeling method inspired by gradient boosting, which further reveals the intrinsic mechanism of shape function learning by providing layer-wise explanations. This combination enables ProtoNAM to effectively capture the nuanced patterns present in tabular data while maintaining a high degree of interpretability."}, {"title": "2 Related Work", "content": "2.1 Machine Learning for Tabular Data. In the realm of machine learning, the handling of tabular data has traditionally been dominated by tree-based methods, such as Gradient Boosted Decision Trees (GBDTs) [10] and their highly optimized implementations like XGBoost [8]. These methods have proven effective due to their ability to capture non-linear interactions and complex patterns inherent in tabular datasets. Despite the attempt to use neural network (NN)-based methods for tabular data that incorporate mechanisms such as contrastive learning [2] and attention-based pre-training [36], neural networks have not yet consistently surpassed the performance of their tree-based counterparts on tabular data [2, 7, 34]. This shortfall is attributed to several factors, as outlined by [11], among which neural networks' inherent bias towards learning overly smooth functions is a critical one. Such an issue is particularly pronounced in the context of GAMs, where each feature is encoded to pursue a nuanced understanding of the underlying knowledge without information from any other factors. Consequently, the challenge remains to develop neural network architectures that can effectively model the complex and often discrete patterns present in tabular data.\n2.2 Generalized Additive Models. Generalized Additive Models (GAMs) [13] are a class of interpretable models where the impact of individual features on the final output can be independently modeled and visualized. These models, which explicitly present the influence of individual features in an additive manner, have been extended and enhanced through various innovative approaches [1, 5, 23, 30, 38]. The Explainable Boosting Machine (EBM) [23] exemplifies this evolution by incorporating boosting techniques to refine the accuracy of traditional GAMs without compromising their interpretability. Based on it, the Neural Oblivious Decision Ensembles for GAM (NODE-GAM) [5] integrates the principles of GAMs with the NODE architecture [29], leveraging differentiable decision trees to enhance interpretability while maintaining the model's capacity to capture complex patterns. The Neural Additive Models (NAMs) [1] further advance this field by employing neural networks in the encoding of each feature, which starts the exploration of NN-based GAMs. Building upon the foundation laid by NAMS, Neural Basis Models (NBMs) [30] have been proposed to reduce the complexity of these models by learning shared basis functions, thus striking a balance between parameter efficiency and interpretability. While [1] demonstrated the unique capabilities of NN-based GAMs on multitask learning, the performance of existing NN-based GAMS is not on par with their tree-based counterparts, which results in an imprecise interpretation of feature attributions and limits their use in real-world scenarios.\n2.3 Prototype-based Neural Network. Prototype-based approaches provide case-based explanations that explain a model with sample representatives learned from the dataset. There are some existing works that tried to incorporate prototypes in machine learning models for interpretable classification [3, 20]. [35] and [22] proposed to explain each data point as a combination of learnable prototypes. Specifically, [35] consider prototypical representation of a class as a means for classification, essentialy learning a metric space partitioned by prototypes. Li et al. [22] learn prototypes in the latent space, explaining each sample by looking at the model's learned weights on different prototypes. However, the use of prototypes in GAMs for tabular data is still under-explored."}, {"title": "3 Methodology", "content": "3.1 Problem Formulation. Given a tabular sample with n features $x_1,...,x_n$, the task of a GAM, in general, is to learn corresponding feature encoders $f_1,, f_n$ which map the input values from feature domains to the prediction domain. The final predicted value of the target output y is computed as\n\\[\n\\hat{y} = w_0 + \\sum_{i=1}^{n} w_i f_i(x_i),\n\\]\nwhere $w_1,..., w_n$ are the weights for different features, indicating their relevance in the final prediction. An additional bias term $w_0$ is also introduced as a learnable inductive bias of the output distribution.\nTo better capture localized information in tabular features as tree-based GAMs do, we consider a specific task for our NN-based GAM where each encoder $f_i$ takes both the original input $x_i$ and the local information $\\Upsilon_i(x_i)$. $\\Upsilon_i$ maps $x_i$ to the localized information by indicating which range the value is on in the domain of the i-th feature. The process can be formulated as\n\\[\nf_i(x_i) = g_i(x_i, \\Upsilon_i(x_i)).\n\\]\n3.2 Prototype-based Feature Activation. The motivation for our prototype-based feature activation is to enable neural networks to capture localized information for precise feature encoding. Specifically, the model will learn t feature prototypes $\\mu_{i1}, \\cdots, \\mu_{it}$ for the i-th feature $x_i$. The value of t is kept the same for different features for simplicity. The input value $x_i$ will then be mapped to\n\\[\n\\Upsilon_i(x_i) = [\\rho (||x_i - \\mu_{i1} ||), \\cdots, \\rho (||x_i - \\mu_{it} ||)],\n\\]\nwhere $\\forall j \\in {1,...,t}$,\n\\[\n\\rho(||x_i - \\mu_{ij} ||) = exp(\\frac{-||x_i - \\mu_{ij} ||^2}{2\\sigma^2}).\n\\]\nThe parameter $\\sigma$ controls the extent of localization, which can change dynamically from 1 to 0 during the training. In our implementation, $\\sigma$ is defined as\n\\[\n\\sigma = (\\frac{1 + exp(\\tau (\\frac{T - T_{max}}{2}))}{1})^{-1},\n\\]\nwith $T$ as the current iteration number and $T_{max}$ as the maximum iteration number. $\\sigma$ will converge to 0 as $T \\rightarrow T_{max}$, and a hyperparameter $\\tau$ is introduced to control the convergence speed.\nEach component in $f_i(x_i)$ reflects the distance of the feature value $x_i$ to one representative feature prototype, and $f_i(x_i)$ in general shows the location information of $x_i$ on the feature domain. Based on $\\Upsilon_i(x_i)$, we propose to provide localized linear activation for the input feature by calculating\n\\[\nA_i (x_i, \\Upsilon_i(x_i)) = \\frac{\\sum_{j=1}^{t}(a_{ij}x_i + b_{ij})\\rho(||x_i - \\mu_{ij} ||)}{\\sum_{j=1}^{t} \\rho(||x_i - \\mu_{ij} ||)}\n\\]\nwhere $\\rho(||x_i - \\mu_{ij} ||) / \\sum_{j=1}^{t} \\rho(||x_i - \\mu_{ij} ||)$ is the normalized radial-basis-function (RBF) value for the prototype $\\mu_{ij}$, and $a_{ij}$ and $b_{ij}$ are parameters of the local linear activation for values around the prototype. By using the normalized RBF transformation as shown in Formula 3.8, we ensure that every value on the feature domain can be properly activated. When $\\sigma$ is close to 0, the activation of the input value will be determined by the local linear mapping of its closest prototype only.\n3.3 Hierarchical Shape Function Modeling. Though the localized RBF feature activation with prototypes enhances the ability of NN-based GAMs to capture nuanced local information, they still present an inferior performance to GBDT-based ones, as shown in our experiments. Moreover, the DNN structure of each feature encoder is not transparent enough to show how the input value \"jumps\" to the predicted outcome.\nInspired by the idea of gradient boosting, we propose an innovative hierarchical modeling of shape functions that utilizes each layer in the feature encoder as a weaker learner and encourages the model to capture hierarchical information from the data with different layers. Consider we have a d-layer neural network as the encoder for the i-th feature, whose layers are labeled as $l_{i1}, \\cdots, l_{id}$. Given an activated input value $A_i (x_i, \\Upsilon_i(x_i))$, the encoder can output a sequence of embeddings $v_{i1}, \\cdots, v_{id}$ that are generated by each layer. Formally, the embeddings are computed as\n\\[\nv_{im} = \\begin{cases}\nl_{im} (A_i(x_i, \\Upsilon_i (x_i))) & \\text{if } m = 1, \\\nl_{im} (v_{i(m-1)}, A_i (x_i, \\Upsilon_i(x_i)) & \\text{if } m > 1,\n\\end{cases}\n\\]\nwhere $l_{i2},..., l_{id}$ takes both the original activated value and the embedding from the previous layer as the input for in-depth encoding.\nThe generated embeddings will then be used to supervise the model for hierarchical shape function modeling. As mentioned above, we treat each layer as a weak learner which is prepared for \"gradient boosting\". To map the embeddings from the latent spaces to the predicted label space, we introduce d weaker predictors $h_{i1},..., h_{id}$, which are NNs with only one or two layers. The training objective is then designed to encourage each layer in the encoder to learn \"pseudo-residuals\" of layers previous to it. Specifically, the d-layer encoder for the i-th feature can output d different encoded values $f_{i1},..., f_{id}$, where the m-th value is computed as the sum of outputs from the first m layers:\n\\[\nf_{im} = h_{i1}(v_{i1}) + \\cdots + h_{im} (v_{im}).\n\\]\nWe can then generate d different predictions based the encoded values:\n\\[\n\\hat{y}_m = w_{0m} + \\sum_{i=1}^{n} w_{im} f_{im}, m \\in {1,...,d}\n\\]\nwhere $w_{0m}, w_{1m},..., w_{nm}$ are the bias and weights for the prediction based on the first m layers. It should be noted that the prediction with m = d is the exact final prediction that the model generates for the downstream task, i.e., $f_i(x_i) = f_{id}$ and $\\hat{y} = y$. The function $g_i$ in Formula 3.2 can then be rewritten as\n\\[\ng_i = H_i L_i A_i,\n\\]\nwhere $L_i$ is the mapping from the activated input $A_i (x_i, \\Upsilon_i(x_i))$ to $v_{i1}, ..., v_{id}$ (Formula 3.9) and $H_i$ maps $v_{i1}, ..., v_{id}$ to $f_i(x_i)$ (Formula 3.10). The learned bias and weights $w_{0d}, w_{1d},..., w_{nd}$ in Formula 3.11 are the corresponding parameters used in Formula 3.1.\nTo encourage the learning of hierarchical information, the training objective is set as\n\\[\nminimize \\sum_{i=1}^{d}L(y, \\hat{y}_m)\n\\]\nwhere $L$ is the cross-entropy loss for classification tasks and mean square error loss for regression tasks. The objective guides the model to make precise predictions in a hierarchical way by penalizing the prediction errors given by the first m layers for all $m \\in {1,...,d}$. Our empirical results show that each feature encoder in our model does utilize the first few layers to capture the major pattern in the shape function, allowing the subsequent layers to model nuanced variations in the shape plot.\n3.4 Conditional Feature Interaction Modeling. While the GAMs only learn n encoders for n different features, things become complex when it comes to the modeling of feature interactions. As shown in Formula 3.4, for possible interactions of k feature, a total number of $\\binom{n}{k}$ encoders are required, which can be costly when n or k is large. For the scalability of high-order feature interaction modeling, we simplify Formula 3.4 as follows:\n\\[\n\\hat{y} = w_0 + \\sum_{i_k\\in{1,..., n}^k} w_{i_k} f(x_1,..., x_n; i_k).\n\\]"}, {"title": "4 Experiments", "content": "4.1 Datasets. To systematically evaluate our proposed model and compare it with other methods, we choose four tabular datasets that are commonly used in prior research on GAMs [1, 30, 5], including Housing [27], MIMIC-II [32], MIMIC-III [16], and Income [4]. The statistics and detailed descriptions of the datasets used are presented in Appendix A.1.\n4.2 Baseline Models. ProtoNAM is first compared with existing NN-based GAMs. We consider the Neural Additive Models (NAMs) [1] and Neural Basis Models (NBMs) [30], both of which encode features using neural networks but differ in their approach to sharing basis functions. We then compare ProtoNAM with tree-based GAMs, including Explainable Boosting Machine (EBM) [23, 26], a GBDT-based GAM which utilizes an ensemble of gradient-boosted decision trees for prediction, and NODE-GAM [5], which is a GAM adaption of Neural Oblivious Decision Ensembles (NODE) [29] that utilizes MLPs to learn the nodes of decision trees for differentiability. In addition to the GAMs compared, we also include the logistic regression and the spline function as two baselines, which can also explain their predictions with feature attributions.\nTo evaluate the generalizability of our model to high-order feature interaction modeling, we compare ProtoNA2M, a generalized ProtoNAM that learns binary feature interactions with the proposed conditional modeling, to the second-order version of the baseline GAMs, including NA2M, NB2M, EB2M, and NODE-GA2M. More details about the implementation details and the evaluation setting of our experiments can be found in Appendix A.2 and A.3.\n4.3 Performance of ProtoNAM. Our experimental results, as presented in Table 1, offer a comprehensive comparison of the proposed models, ProtoNAM and ProtoNA2M, against various baseline methods. In Table 1, it can be observed that the tree-based GAMs (EBM & NODE-GAM) indeed outperform existing NN-based ones (NAM & NBM) on the tabular datasets with significantly lower average ranks. However, with our proposed methods, ProtoNAM, as a new NN-based GAM, demonstrates superior performance compared to state-of-the-art tree-based models. Notably, on the Housing and Income datasets, ProtoNAM achieves the highest performance among all GAMs tested, which is particularly significant given that tree-based GAMs have traditionally shown strong results on these datasets.\nProtoNA2M, as shown in Table 1, also exhibits outstanding performance, ranking first on average across the datasets. It outperforms other baselines, including both tree-based ones and NN-based ones, on most datasets. However, an exception is observed with the MIMIC-III dataset, where NN-based models generally achieve better results. Upon closer examination of the MIMIC-III dataset, originally processed and provided by NODE-GAM [5], we found that all categorical variables had been transformed into dummy variables, which are well-suited for neural network processing. Although ProtoNA2M is neural network-based, it incorporates shared predictors for conditional modeling to balance the expressiveness and scalability of the model. This design choice may lead to a slight performance decrease, as observed with ProtoNA2M's performance on MIMIC-III, which is marginally lower than that of NA2M.\nOverall, the average rank scores in Table 1 underscore the expressiveness of ProtoNAM and ProtoNA2M, with ProtoNAM achieving an average rank of 1.500 and ProtoNA2M achieving an average rank of 1.875. These results highlight the effectiveness of our proposed models in capturing complex data relationships while maintaining interpretability, a key advantage in the realm of GAMs for explainable AI.\n4.4 Interpretability of ProtoNAM. While ProtoNAM demonstrates its superior performance over existing GAMs on tabular datasets, we are curious to see if it can capture more nuanced feature patterns in the shape plots than others for more precise feature interpretation. We train an ensemble of 100 ProtoNAMs and visualize the mean-centered predictions on the shape plots as NAM [1] and NBM [30] did. The normalized density of feature values is also presented on the plots using different colors of bars in the background.\n4.5 Multitask Learning of ProtoNAM for Fairness. As discussed in Introduction, one of our motivations for the continued exploration of NN-based GAMs is their intrinsic capability as multitask learners, which can be used to address social biases in data from an algorithmic standpoint. To illustrate this, we choose the Income dataset for the case study, where the feature \"Gender\" can be a sensitive input variable. Prior analyses using EBM and NODE-GAM showed that \"Female\" could be a negative predictor of annual income [5], raising ethical concerns due to the potential reinforcement or amplification of societal biases and disparities.\nTo bolster algorithmic fairness with respect to \"Gender\", we implement a multitask learning framework that omits the \"Gender\" feature and instead adjusts the weights of other predictors for different demographic groups as described in Formula 3.3. Specifically, ProtoNAM will learn group-specific weights for its predictors at each layer, corresponding to parameters shown in Formula 3.11.\nThe multitask ProtoNAM achieves a mean AUC score of 0.927 on the test set of the Income dataset with 5-fold cross-validation, which is on par with the one in the original one-task setting. Rather than considering \"Gender\" as a standalone predictor for income estimation, multitask ProtoNAM offers a nuanced approach by providing group-specific feature attributions. This approach not only maintains fairness by excluding sensitive features but also sheds light on the differential impact of other features across demographic groups.\n4.6 Ablation Studies. In our ablation study, we first investigate the impact of two key aspects of ProtoNAM: the number of prototypes for each feature and the number of layers in the hierarchical shape function modeling. As shown in Table 2, the results reveal that increasing both the number of prototypes and the hierarchical layers leads to improved performance. The increase in the prototype count enables a more nuanced representation of local patterns, which is beneficial for modeling unsmooth relationships within tabular data. Additionally, adding more layers to the hierarchical shape function modeling allows for a more refined capture of intricate data details. Each successive layer builds on the previous, enabling the model to represent increasingly subtle relationships and offering a sophisticated understanding of the data on a deeper level."}, {"title": "5 Conclusion", "content": "We propose Prototypical Neural Additive Model (ProtoNAM), a new deep tabular learning method, which introduces prototypes into neural networks in the framework of generalized additive models (GAMs). Our extensive experiments demonstrate that ProtoNAM not only outperforms existing GAMs in terms of predictive performance on tabular datasets but also provides additional insights into the learned shape functions through its novel prototype-based feature activation and hierarchical shape function modeling. With its neural network-based design, ProtoNAM can be an effective multitask learner, improving algorithmic fairness without compromising on performance. The ablation studies further validate the importance of each proposed component in enhancing the model's capabilities."}]}