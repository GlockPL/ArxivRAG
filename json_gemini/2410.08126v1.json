{"title": "Mars: Situated Inductive Reasoning in an Open-World Environment", "authors": ["Xiaojuan Tang", "Jiaqi Li", "Yitao Liang", "Song-chun Zhu", "Muhan Zhang", "Zilong Zheng"], "abstract": "Large Language Models (LLMs) trained on massive corpora have shown remark-\nable success in knowledge-intensive tasks. Yet, most of them rely on pre-stored\nknowledge. Inducing new general knowledge from a specific environment and\nperforming reasoning with the acquired knowledge\u2014situated inductive reasoning,\nis crucial and challenging for machine intelligence. In this paper, we design Mars,\nan interactive environment devised for situated inductive reasoning. It introduces\ncounter-commonsense game mechanisms by modifying terrain, survival setting\nand task dependency while adhering to certain principles. In Mars, agents need to\nactively interact with their surroundings, derive useful rules and perform decision-\nmaking tasks in specific contexts. We conduct experiments on various RL-based\nand LLM-based methods, finding that they all struggle on this challenging situated\ninductive reasoning benchmark. Furthermore, we explore Induction from Reflection,\nwhere we instruct agents to perform inductive reasoning from history trajectory.\nThe superior performance underscores the importance of inductive reasoning in\nMars. Through Mars, we aim to galvanize advancements in situated inductive\nreasoning and set the stage for developing the next generation of AI systems that\ncan reason in an adaptive and context-sensitive way.", "sections": [{"title": "1 Introduction", "content": "Imagine a scenario: in the United States, you drive on the right side of the road. When you travel to\nthe UK, you might initially find it strange how people drive. However, you soon realize that driving\non the left is the norm here and adapt yourself to the new rule. Inductive reasoning, a capacity that\nidentifies underlying rules, mechanisms, or general claims of unobserved experience based on past\nobservations, undoubtedly plays a pivot role in scientific discoveries as well as in the conduct of our\neveryday affairs. Research on the origin and justifications of such inductive aptitude can date back\nto the 1900s. David Hume, one of the most influential philosophers in human nature, presented\na critical dilemma as follows:\n\"Why from this (present) experience we form any conclusion beyond those past\ninstances, of which we have had experience.\""}, {"title": "2 The Mars Environment", "content": "Mars is designed as an interactive open-world survival game, aiming at evaluating an agent's situated\ninductive reasoning capability, as depicted in Figure 1. Building on the foundation of Crafter [Hafner,\n2021], Mars can strategically alter certain commonsense, including terrain, survival settings and task\ndependencies, while adhering to certain principles related to resource balance, item quantities, and\ntask achievability."}, {"title": "2.1 Basic Setting: Crafter", "content": "Crafter Hafner [2021] is an open-world survival game designed to evaluate a wide range of general\nabilities, including robust generalization, deep exploration and long-horizon reasoning. In this\ndemanding environment, the agent (e.g., a policy model) is asked to unlock all achievements while\nensuring its survival. Each episode generates a unique world featuring diverse terrains such as"}, {"title": "2.2 Modification: From Crafter to Mars", "content": "To challenge the agent with an environment that deviates from prior (parametric) knowledge and\nnecessitates situated inductive reasoning, we introduce targeted modifications to typical commonsense\nelements, classified into three categories (Figure 2):\nTerrain Terrain includes two aspects: terrain distribution and terrain effect. In the default Crafter\nsetting, common terrain distributions are predictably arranged, e.g., minerals like coal, iron, and\ndiamonds are discovered near stone formations. Terrain effects involve whether a terrain can be\ntraversed and whether doing so benefits or harms the agent's health, or even results in death. These\nterrain characteristics guide the agent's exploration strategies and efficiency. We disrupt these norms\nby altering the distribution and effects of these elements, i.e., trees may now grow near sand rather\nthan grass and lava is not hot.\nSurvival Settings We introduce a novel axis of variation in survival dynamics. It mainly involves\ncharacteristics of entities like cows, zombies, skeletons, plants (edibility, aggressiveness, proximity\neffects, mobility) as well as the impact on the agent's status level (health, food and drink) when\nconsuming these entities and drink. For example, in Crafter world, cows can enhance the agent's\nfood levels upon consumption; in this altered reality, cows may exhibit hostile behaviors.\nTask Dependency Agents can collect many resources by mining some materials and use them\nto build tools and place objects. To this end, we classify them into three kinds of achievements:\ncollecting, placing and crafting."}, {"title": "2.3 Principles of new world", "content": "While we can sample numerous new worlds following the above procedure, we carefully designed\nseveral strict principles so that they are not completely fantastical and are always playable.\n\u2022 The new world does not introduce additional resources or objects; it only modifies the functions\nor effects of existing game objects and materials. To ensure playability, we guarantee that each\ncollected item has at least one obtainable method and each tool has a practical use, motivating the\nagent to engage in crafting. We maintain the same achievements as the default Crafter environment\nto allow for fair comparisons in subsequent experimental evaluations.\n\u2022 We adhere to the resource balance principle. For every resource that can be increased by some\nevent, there must be a corresponding event that can decrease the resource, maintaining a balance.\nFor instance, if the agent loses health when attacked by a cow, there should be scenarios where\nthe health level increases, such as eating zombie.\n\u2022 We also ensure that each achievement is achievable. For example, if mining wood requires a\nwooden pickaxe, but crafting a wooden pickaxe requires wood, this creates a deadlock. To prevent\nsuch scenarios, we construct an and-or tree and use the depth-first search (DFS) algorithm to\nverify that each task in the technology tree has a viable path to the root node, confirming the\nfeasibility of each task. Additionally, we also develop an automated program to evaluate terrain\ndistribution, walkable materials, and task dependencies generated by item recipes, ensuring all\nitems are accessible. For example, assuming that coal and stone are not directly traversable, if we\nplace diamonds around the stone (because mining stone is a precondition for mining diamonds\nbased on task dependency and diamonds are not walkable), the agent is unable to reach the stone\nand complete the \u201cmine stone\u201d task.\n\u2022 We ensure supply exceeds demand: the quantity of items required for task achievements must\nbe greater than what the world provides. For instance, if wood requires collecting at least\nfive diamonds, but the world does not has enough diamonds. Additionally, our world includes\nmechanisms for renewable resources, such as mining a tree potentially leaving behind a coal\nterrain. This dynamic aspect means that the availability of resources cannot be measured statically.\nTo address this, we develop an algorithm that simulates the process of unlocking all achievements\nwithin the Tech Tree to test whether the dynamically regenerating resources of the world are\nsufficient to complete all tasks."}, {"title": "3 Evaluation on Mars", "content": ""}, {"title": "3.1 Evaluation Setup", "content": "Metrics We use three evaluation metrics as in Hafner [2021] to assess the performance of models'\nsituated inductive reasoning abilities: i) The reward metric reflects the agent's skills. Each time\nan agent unlocks an achievement, the reward increases by 1. When an agent's health increases or\ndecreases by 1, the reward adjusts by +0.1 or -0.1, respectively. ii) The success rate is defined as\nthe proportion of achievements unlocked during the episodes. iii) The overall score averages the\nsuccess rate of the 22 achievements in log-space (to account for differences in their difficulties) as:\n$S = exp(\\frac{1}{N} \\sum_{i=1}^{N} ln(1 + s_i)) \u2013 1$.\nEvaluation worlds In Mars, we meticulously select seven different worlds, focusing on individual\nmodifications to terrain, survival settings, and task dependency: Terrain, Survival, and Task Dep.\nrespectively; we concurrently modify two types of commonsense rules: Terr. Surv., Terr. Task., and\nSurv. Task.; as well as all three types simultaneously: All three. We also conduct experiments in the\nCrafter setting (i.e., Default)."}, {"title": "3.2 Baselines", "content": "To evaluate Mars, we design (1) RL-based methods: PPO [Schulman et al., 2017], Dreamer V3 [Hafner\net al., 2023]; (2) LLM-based methods: ReAct [Yao et al., 2022], Reflexion [Shinn et al., 2023], revised\nframework motivated by skill library [Xin et al., 2023, Wang et al., 2023a] and (3) our proposed\nframework induction from reflection. Note that RL-based methods individually train a model for\neach world with 1 million training steps. They do not truly solve the problem of quickly adapting\nto new environments in situated inductive reasoning scenarios. Here, we conduct the experiments\nonly to provide the reference. To assess the situated inductive reasoning capabilities of RL-based\nmethods, we also further test different worlds using the DreamerV3 trained in Crafter"}, {"title": "3.3 Induction from Reflection (IfR)", "content": "Building on the Skill Library frame-\nwork, we further introduce the induc-\ntion from reflection module in con-\ntroller, as depicted in Figure 3. When\nthe controller finishes a subgoal (in-\ncluding \"succeed\", \"failed\" or \"time-\nout\"), we force LLM to engage in\nreflective thinking to induce possi-\nble game mechanisms based on the\nagent's historical trajectory. The de-\nrived rules are then stored in a rule\nlibrary, which the task proposer, plan-\nner, and controller can use.\nFor Skill Library and IfR, we set the\nlearning episodes to 5. For ReAct and\nReflexion, which rely on in-context\nmemory instead of external memory,\nwe restrict them to use a finite con-\ntext window (10 steps or 3896 tokens\ntrajectory). For all LLM-based meth-\nods, we use the GPT-4-0125-preview\nmodel through\nOpenAI's API, with a temperature\nof 0.7. Other hyper-parameters (e.g.,\ntop_k) are kept at their default settings. The full prompts for all different methods are provided in\nAppendix L."}, {"title": "3.4 Main Results", "content": "Table 2 presents the performance of various methods across different environments. Notably, all\nbaseline models exhibit a performance decline when transitioning from the Default to Mars scenarios,\nwith the extent of the decline dependent on the type (e.g., terrain, survival, and task dependency)\nand the number of modifications. This underscores that Mars presents significant challenges for\ncurrent methodologies. Although our proposed method shows some improvement, its suboptimal\nperformance in the \"All three\" modified world highlights the urgent need for further research in this\ncomplex reasoning context."}, {"title": "3.5 Further Analysis", "content": "We further plot the success rate of unlocking achievements by the Skill Library model, comparing the\ndefault world (Crafter) to the \"Task. Dep\" world in Mars, as shown in Figure 4. Most achievements\ninvolving task dependency category (e.g., collecting, placing) experience a significant drop in\nperformance. Even tasks related to survival, such as collecting drinks, are slightly affected. The\nperformance for \u201ckill something\u201d tasks is likely impacted due to the difficulty in making a sword.\nInterestingly, the unlock rate for the \u201ccollect diamond\u201d task in the \u201cTask. Dep\" world is higher than\nin the \"Default\" world. This is because, in the modified world, diamonds can be directly mined\nby hand, making it a straightforward, one-step process that is easy to discover through exploration.\nHowever, for the more complex two-step task, \u201cplace table\u201d, which requires using two diamonds,\nthe performance is still poorer. These results again highlight that Mars is challenging for current\nmethods. Next, we conduct experimental analyses on situated reasoning and inductive reasoning\nseparately. More details and case studies are presented in Appendix I."}, {"title": "4 Related Work", "content": "Inductive Reasoning. Inductive reasoning is the ability to infer general principles from specific\nobservations or evidence and apply them to novel situations, which is fundamental to human intel-\nligence [Peirce, 1868]. A few researchers have proposed a myriad of tasks to evaluate inductive\nreasoning in AI. Representative benchmarks include vision-based reasoning [Mirchandani et al.,"}, {"title": "5 Conclusion", "content": "In this paper, we introduce Mars, designed to evaluate models' situated inductive reasoning\nabilities in adaptive and context-sensitive way. Key components, including terrain, survival settings,\nand task dependencies, are modified according to certain principles. In Mars, agents are required\nto actively interact with their surroundings, learn to derive new general knowledge, and perform\nreasoning using the acquired knowledge. Furthermore, we propose Induction from Reflection method,\nwhich compels LLMs to perform inductive reasoning from historical trajectories. This approach\nhas demonstrated better performance compared to other LLM-based methods, underscoring the\nsignificance of inductive reasoning in counter-commonsense environments.\nLimitations and Future Work Despite the improved performance of IfR compared to other LLM-\nbased method, the overall performance remains suboptimal. In addition to the model's limitations\nin identifying the underlying causes of observations, this could be due to the limited exploration\ntime provided by the five episodes and the relatively inefficient exploration process. Future research\ncould focus on enhancing the model's exploration efficiency and utilizing induced rules to make\nmore informed guesses. For example, if an agent discovers that lava is walkable and safe, it might\nhypothesize that water could be dangerous due to resource balance. Additionally, future models could\nbe designed to automatically identify the causes and perform inductive reasoning when encountering\na new environment, eliminating the need for enforced induction from historical trajectories."}, {"title": "6 Acknowledgements", "content": "I would like to express my gratitude to my advisors for their guidance and to my peers for their\nvaluable suggestions. This work is partially supported by the National Key R&D Program of China\n(2022ZD0160300), the NationalNatural Science Foundation of China (62376031)."}, {"title": "Appendix", "content": ""}, {"title": "A Additional Mars details", "content": ""}, {"title": "A.1 Benchmark URLs and Links", "content": "Mars is published under the open-source MIT license on Github https://github.com/\nXiaojuanTang/Mars. Code for all the benchmark models are available within the same GitHub\nrepository. We provide detailed descriptions at https://github.com/XiaojuanTang/\nMars/blob/master/README.md.\nThe documentation covers:\n\u2022 Step-by-step instructions for setting up the Mars environment.\n\u2022 Guidelines on how to load and use various world configurations.\n\u2022 Descriptions of the configurations. See details in Appendix A.5 and Appendix M. Our code\nrepository also includes a demo video for each world to enhance understanding of these\nconfigurations.\n\u2022 Benchmark code and examples of how to run the benchmarks."}, {"title": "A.2 Implementation details", "content": "The detailed hyperparameters of the RL-based baselines are provided in Section 3.2. Specifi-\ncally, for the PPO experiment, we utilize the default parameters from the stable_baselines3 library,\nwhile for DreamerV3, we adopt the default parameters as specified in the source code (available at\nhttps://github.com/NM512/dreamerv3-torch). All agents are trained for 1 million environment steps\nwith rewards and tested over 20 independent trials. For further details on the LLM baselines, please\nrefer to Section 3.2. Additional prompts can be found in Appendix L. We also provide the code\nincluding all baselines, at https://github.com/XiaojuanTang/Mars, which can help with reproducing\nour results."}, {"title": "A.3 Maintenance and Long Term Preservation", "content": "The Mars dataset is an interactive environment built on the Crafter framework, designed to evaluate\nsituated inductive reasoning in agents. The authors of Mars are committed to maintaining and\npreserving this environment. Ongoing maintenance also encompasses tracking and resolving issues\nidentified by the broader community after release. User feedback will be closely monitored via the\nGitHub issue tracker."}, {"title": "A.4 Details of environment descriptor", "content": "The gameplay screen consists of a 9 \u00d7 9 grid ((i, j)|1 \u2264 i, j \u2264 9). The top seven rows provide a local\nview of the world; each cell (i, j) is associated with a predefined background (e.g., \u201cgrass\u201d, \u201cstone\u201d,\n\"sand\") and potentially an object (e.g., \u201ctree\u201d, \u201ccow\u201d). The bottom two rows represent the agent's\nstatus (e.g., \"health\", \"food\") and item inventories, which include images of items (e.g., \u201cstone\u201d,\n\"stone sword\") and the quantity of each item in the inventory.\nOur environment descriptor processes the gameplay screen as input and outputs a textual description\nof the screen. This description includes the agent's action, nearby block information, agent status,\nand inventory details. Specifically:\n\u2022 Action: The descriptor outputs the specific action taken by the agent, such as \u201cI took action\nmove_left\".\n\u2022 Nearby Block Information: For cells containing objects, the descriptor focuses on the objects;\nfor cells without objects, it focuses on the background. It first identifies all types of backgrounds\nand objects within the 7 \u00d7 9 grid. The text descriptor outlines the background material closest to\nthe agent and enumerates all objects, including their coordinates. For example, \"I see: (objects\nwith coordinate) path is in front of me. <path(-1, 0), path(1, 0), path(0, -1), path(0, 1), path(-1,\n-1), path(1, -1), path(-1, 1), path(1, 1), stone(-2, -1), tree(-3, 0)>\"."}, {"title": "A.5 Details of modified commonsense elements", "content": "In this section, we introduce the modified commonsense elements in detail, including terrain, survival\nsettings and task dependency. We also provide the configuration of Crafter world. The configurations\nof Mars world are in Appendix M."}, {"title": "A.5.1 Terrain", "content": "Modification of terrain involves two aspects: terrain distribution and terrain effect. The terrain\nmaterial includes water, grass, stone, path, sand, tree, lava, coal, iron and diamond,\n\u2022 Terrain Distribution: In the default Crafter environment, common terrain distributions\nare predictably arranged: sand typically encircles bodies of water; trees are prevalent near\ngrasslands; and minerals like coal, iron, diamonds, and lava are found near stone formations.\nThe player is usually born in grass. In Mars, we modify the terrain neighbors or swap terrain\nnames to change the terrain distribution. Specifically, for the first modification type, we\nsample the surroundings of coal, iron, diamond, lava, tree, player, and water terrains with\none of the terrain materials. For example, coal could be placed near grasslands. Note that\nwe ensure each type of terrain material is sampled, and each item is accessible. For the\nsecond modification type, we exchange different terrain names. For instance, we swap the\npositions of stone and iron terrains.\n\u2022 Terrain Effect: This involves whether a terrain can be traversed and whether doing so\nbenefits or harms the agent's health or even results in death. To this end, we assign each\nterrain material (except trees, due to their inherent height, despite the 2D game's limitations)\nthree attributes: walkable, walk_health, and dieable. We randomly assign values to these\nthree attributes: walkable: [True, False]; walk_health: [-1,0,+1]; dieable: [True, False]. For\nexample, envision a planet where you discover energy stones unlike anything on Earth, or\nwhere, surprisingly, lava is not hot. Note that if the terrain material is not walkable, the\ndieable and walk_health attributes have no practical significance.\nHere is the Crafter setting:\nTerrain distribution of Crafter:\nterrain_neighbour:\ncoal: stone\niron: stone\ndiamond: stone\nlava: stone\ntree: grass"}, {"title": "A.5.2 Survival settings", "content": "This modification mainly involves the characteristics of objects, including cows, zombies, skeletons,\nripe-plants, as well as drinks like water and lava. For example, in Crafter world, cows can enhance\nthe agent's food levels upon consumption; zombies approach and harming the agent; skeletons shoot\narrows that cause damage to the agent; water replenishes the agent's drink level. In this altered\nreality, cows may exhibit hostile behaviors, consuming a ripe plant could increase hunger due to its\ndigestion-enhancing properties, and consuming overly salty zombie flesh could increase thirst (if the\nzombie is edible in this world). Specifically, for objects, we set the following attributes:\n\u2022 eatable: Indicates if the object is edible;\n\u2022 eat_health_damage_func: The impact on the agent's health when consumed (increase, decrease,\nor no effect);\n\u2022 inc_food_func: The impact on the agent's food level when consumed.\n\u2022 inc_thirst_func: The impact on the agent's thirst level when consumed;\n\u2022 arrowable: Indicates if the object can perform shooting actions;\n\u2022 arrow_damage_func: the impact on the agent's health when shot.\n\u2022 closable: Indicates if the object will move towards the agent;\n\u2022 can_walk: Indicates if the object can move.\n\u2022 closable_health_damage_func: The impact on the agent's health when the object is near.\nFor drinks, we set the following attributes:\n\u2022 inc_drink_func: The impact on the agent's drink level when consumed.\n\u2022 inc_health_func: The impact on the agent's health level when consumed.\n\u2022 inc_food_func: The impact on the agent's food level when consumed.\nWe randomly assign the value to those attributes to modify the survival setting. For example, zombies\nshooting arrows that cause damage to the agent, i.e., \u201carrowable=True, arrow_damage_func=-1\";\ndrink lava can increase agent's health, i.e., \u201cinc_health_func=+1\"."}, {"title": "A.5.3 Task Dependency", "content": "Agents can collect many resources, such as saplings, wood, stone, coal, iron and diamond and use\nthem to build tools or place objects. Many of the resources require tools that require even more\nbasic tools and resources, leading to a technology tree with several levels. Typically, agents start\nby collecting wood, crafting a wooden pickaxe, then progressing to stone, coal, and so on, with\ndiamond collection being the ultimate and most challenging achievement. However, in our new\nenvironment, these dependencies are disrupted; for example, collecting diamonds no longer requires\nan iron pickaxe, and collecting wood now requires specific tools. To this end, we consider three kinds\nof achievements: collecting, placing and crafting. Refer to Appendix A.5 for more details.\nCollecting: The task of collecting involves mining a terrain material with a tool or hand to receive\nitems while leaving other materials behind. For example, chopping down a tree by hand may yield\nwood while leaving grass. Following this, we implement three different changes to received items:\n\u2022 Visual Misleading: In this modified world, mining a resource may yield an unexpected item.\nFor instance, what appears to be coal could actually yield stone instead, as stone may visually\nresemble coal in this unconventional world. Specifically, we randomly permutate the expected\nitems (including wood, stone, coal, iron, diamonds and sapling) for terrains (including grass,\ntrees, stone, coal, iron, and diamonds). For liquid terrains such as water and lava, the output\n(e.g., whether agents receive a drink) is randomly assigned as \u201cTrue\u201d or \u201cFalse\u201d. This approach\nselectively disrupts the visual alignment of solid materials without confusing them with liquids,\nmaintaining the challenge of non-common knowledge rather than creating a completely fantastical\nor symbolic world.\n\u2022 Traditional Association with Exceptions: Contrary to the first, this easier modification maintains\nthe traditional association between an item's appearance and its material composition, i.e.,"}, {"title": "A.6 Key considerations for modification", "content": "In addition to several strict principles to prevent the new world from collapsing, we also implemented\nother measures. Specifically:\n\u2022 We do not roughly make sweeping changes to the entire Crafter world. Instead, we selectively\nmodify specific types and numbers of elements to control the difficulty. Generally, modifying\nonly the terrain (e.g., water nearby stone instead of sand) is the simplest. Modifying\nsurvival settings (e.g., zombies can shoot) presents a moderate challenge, while altering task\ndependencies (e.g., mining stone yields diamonds) is the most difficult. The more rules we\nmodify, the greater the challenge.\n\u2022 Additionally, we meticulously consider the content of these rule modifications. While they\nmay seem counter-intuitive, most of them remain reasonable and plausible. For instance,\nhaving stone near water is possible, as in cave systems where water of underground lakes\nor streams often flows over stone. Similarly, zombies infected by a virus might shoot;\nconsuming overly salty beef could increase thirst; a frenzied cow might attack humans; and\ntrees could grow rapidly, with a new tree sprouting immediately after the original one is cut\ndown.\n\u2022 Furthermore, we specifically invite skilled Crafter players to test the seven chosen exper-\nimental worlds. After five episodes of learning and adaptation, these players achieved\nrewards in the range of 16-18 out of 22 possible achievements. This demonstrates that while\nour benchmark is challenging, it is also reasonable."}, {"title": "B Evaluating Crafter's knowledge of GPT-4", "content": "LLMs are pre-trained on vast and diverse textual data, which provides them with extensive world\nknowledge and commonsense information. This knowledge often aligns with the mechanisms of\nthe Crafter [Hafner, 2021] game, which is why many studies leverage the commonsense knowledge\nencoded in LLMs to guide RL for more efficient exploration in Crafter. For instance, ELLM [Du\net al., 2023] shapes rewards towards commonsense and useful behaviors through a pretrained LLM,\nwhile AdaRefiner [Zhang and Lu, 2024] uses sub-goals suggested by the LLM to guide exploration.\nTo further validate the LLMs' understanding of Crafter's game mechanics, we conduct two additional\nexperiments:"}, {"title": "C Pipeline of Skill Library", "content": "In this section, we introduce the revised pipeline of Skill Library. Based on JARVIS-1 and Voy-\nager [Wang et al., 2023a,b], we further simplify the framework to adapt to our environment. Specifi-\ncally, given the agent's observation (location, inventory, nearby blocks) and task list, we prompt the\nLLM as a task proposer to select a feasible and novel task. Then, the LLM-based planner decomposes\nthis high-level task into a sequence of subgoals. The LLM-based controller executes these subgoals\nsequentially by outputting available actions (e.g., move left, place table). However, if the controller\noutputs \"failed\u201d or believes it \u201csucceeded\u201d but the task cannot be accomplished (as indicated by the\nenvironment's feedback), it suggests that the initial plan provided by the planner may contain errors\nor that the controller experienced execution failures. Then, the explainer tries to identify the errors\nand re-plan the current task. For successful plans, we store in the skill library along with the task and\nthe agent situation for future reuse in similar situations. Here, task proposer, planner, explainer, and\ncontroller are fulfilled by the LLMs."}, {"title": "D More results of Dreamer V3", "content": "We further test Mars using the model trained in Crafter. The results are shown in Table 7. From the\nresults, we observe that DreamerV3 performs well in Default (the same world as training). However,\nwhen adapting to a new world that includes partial counter-commonsense elements, the performance\ndrops significantly. These results indicate that the state-of-the-art RL-based method DreamerV3\nstruggles to quickly adapt to environments with even minor differences (e.g., the \"Terrain\" world\nachieves a reward of only 5.3), demonstrating that it does not solve the situated inductive reasoning\nproblem."}, {"title": "E More results of ELLM", "content": "In this section, we conduct experiments using ELLM [Du et al., 2023], which leverages LLMs for\nreward design. To ensure consistency with our setup, we include both intrinsic rewards and health\nrewards during training. For other hyperparameters, we use the default settings provided in their\ncode\u00b3. The results are shown in Table 6. The performance of ELLM drops in Mars compared to the\nCrafter (Default) environment, which aligns with the findings using both RL-based and LLM-based\nmethods. These results suggest that while LLM priors can guide RL exploration, when transferring\nto a novel world with different game mechanics and knowledge, LLMs struggle due to their lack\nof situated inductive reasoning. This further validates the difficulty of our Mars benchmark under\ncurrent methods, underscoring the need for more advanced AI systems that can adapt and reason\ncontextually in novel environments."}, {"title": "F More results of the open-source model", "content": "We conduct additional experiments with the open-source model LLaMA-3.1-8B-instruct. We evaluate\nboth the ReAct and IfR models across different worlds, using the same prompts and hyperparameters\nas with GPT-4. The results show that LLaMA's performance declines when encountering the Mars\nenvironment. Additionally, our model IfR consistently outperforms ReAct across all scenarios. These\nfindings align with the results obtained using GPT-4, further validating the importance of inductive\nreasoning and highlighting the challenges posed by our benchmark."}, {"title": "G Failure cases of Skill Library", "content": "Skill Library's memory only involves successful subgoal sequences, making it difficult to be aware of\nthe real situation for task completion. Consequently, the incorrect path will be reused repetitively.\nFor example, for the task \"place table\", if the planner outputs \"step1: mine tree; step2: place table\"\nand the LLM-based controller accidentally mines grass and obtains wood, the Skill Library will save\nthe incorrect plan for \"place table\". This reuse of erroneous plans significantly reduces the model's\nexploration efficiency."}, {"title": "H Examples of induced rules", "content": "Induced rules:\n1. Interacting with water blocks replenishes the player's drink status.\n2. Standing on the iron can increase the player's health.\n3. The player can use the table and wood to craft a wood pickaxe.\n4. The player can move left on the path."}, {"title": "I More detailed analysis and case studies", "content": "The results in Table 2 have indicated that our benchmark, Mars, is challenging for current methods\nprimarily due to their lack of situated inductive reasoning ability. This ability encompasses two\nkey aspects: inductive reasoning, the ability to summarize observations into abstract \"conclusions\"\nthat go beyond prior experiences, and situated reasoning, which requires understanding situations\ndynamically and reasoning with present knowledge accordingly. We provide experimental analyses\non both situated reasoning and inductive reasoning separately in Section 3.5. Here, we would like to\nreiterate and further justify the underlying reasons with sampled cases.\nFor inductive reasoning: To evaluate it, we measure the precision and recall of the rules predicted\nby IfR using a GPT-4 evaluator (refer to Figure 5). After five episodes of learning, the precision of\nrules reached a maximum of only 0.68, with recall not exceeding 0.28. We delve into specific cases\nto identify two potential reasons for this:\n\u2022 Firstly, the LLMs' inherent priors limit its exploration space to commonsense domains rather\nthan encouraging open-ended exploration. For example, the model failed to induce the rule\n\"Collecting from diamond without any tools yields 1 coal\". According to commonsense\nscenarios, mining diamonds requires crafting an iron pickaxe. When the inventory lacks an\niron pickaxe, the model does not attempt to mine diamonds, thus missing the opportunity to\ninduce this rule.\n\u2022 Secondly, the model is not truly performing inductive reasoning but is instead relying on\nretrieving prior knowledge for predictions. Continuing with the previous example, even"}, {"title": "J Compute Resource Details", "content": "For running all experiments, we use the hardware resources as listed in Table 8."}, {"title": "K Licenses", "content": "In our code, we have used the following libraries which are covered by the corresponding licenses:\n\u2022 Crafter (MIT license)\n\u2022 OpenAI GPT (CC BY-NC-SA 4.0 license)\n\u2022 Stable Baselines3 (MIT license)\n\u2022 DreamerV3 (MIT License)"}, {"title": "L Prompt", "content": ""}, {"title": "L.1 ReAct", "content": "Instruction: You are playing a new [counter-commonsense", "do": "nmeans to interact the block at front of the player, including mine the block, attack the creature,\nand drink.\nUnlock the following achievements < Collect Coal, Collect Diamond, Collect Drink, Collect\nIron, Collect Sapling, Collect Stone, Collect Wood, kill Skeleton, kill Zombie, kill Cow, Eat\nPlant, Make Iron Pickaxe, Make Iron Sword, Make Stone Pickaxe, Make Stone Sword, Make\nWood Pickaxe"}]}