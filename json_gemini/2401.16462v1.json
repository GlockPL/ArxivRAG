{"title": "Supervised Contrastive Learning based Dual-Mixer Model for Remaining Useful Life Prediction", "authors": ["En Fu", "Yanyan Hua", "Kaixiang Peng", "Yuxin Chu"], "abstract": "The problem of the Remaining Useful Life (RUL) prediction, aiming at providing an accurate estimate of the remaining time from the current predicting moment to the complete failure of the device, has gained significant attention from researchers in recent years. In this paper, to overcome the shortcomings of rigid combination for temporal and spatial features in most existing RUL prediction approaches, a spatial-temporal homogeneous feature extractor, named Dual-Mixer model, is firstly proposed. Flexible layer-wise progressive feature fusion is employed to ensure the homogeneity of spatial-temporal features and enhance the prediction accuracy. Secondly, the Feature Space Global Relationship Invariance (FSGRI) training method is introduced based on supervised contrastive learning. This method maintains the consistency of relationships among sample features with their degradation patterns during model training, simplifying the subsequently regression task in the output layer and improving the model's performance in RUL prediction. Finally, the effectiveness of the proposed method is validated through comparisons with other latest research works on the C-MAPSS dataset. The Dual-Mixer model demonstrates superiority across most metrics, while the FSGRI training method shows an average improvement of 7.00% and 2.41% in RMSE and MAPE, respectively, for all baseline models. Our experiments and model code are publicly available at https://github.com/fuen1590/PhmDeepLearningProjects.", "sections": [{"title": "1. Introduction", "content": "The prognostication of Remaining Useful Life (RUL), an essential component within the Prognostic and Health Management (PHM) system[1][2][3], has increasingly captured the focus of researchers. The primary goal of RUL prediction is to anticipate the remaining operational time or cycle lifespan of equipment or other designated objects, thereby offering valuable maintenance insights to maintenance personnel[4][5]. The prevalence of data-driven approaches in RUL prediction has surged, primarily due to their robust nonlinear representation and commendable generalization capabilities[6]. Recently, deep learning-based data-driven methods have exhibited renewed vitality. Such methods can fully leverage existing equipment monitoring data, achieving robust predictive performance in complex operating conditions without the need to delve into the intricacies of equipment mechanisms. Numerous studies have already demonstrated the effectiveness of these methods when confronted with abundant equipment monitoring data[7][8][9][10][11].\nDeep learning methods aim to uncover information at different levels hidden within data and encode these insights into a high-dimensional feature space, revealing characteristics that cannot be directly expressed in the original data dimensions, referred to as \"features\". Temporal and spatial dimensions are widely regarded as fundamental dimensions for characterizing equipment monitoring data[9][10][12]. Given the inherent temporal characteristics of equipment monitoring data, the temporal feature mining module is considered a foundational element and is widely employed as a basic module in numerous methods. Spatial features are equally crucial in certain scenarios, especially when there are multiple monitoring points or the equipment is complex[13][14]. In such cases, the spatial relationships among data variables become more intricate, and a single variable alone cannot accurately describe the characteristics of the equipment. Therefore, spatial features are utilized to compensate for the limitations of temporal features, collectively serving as descriptors for the equipment. However, we have identified two primary problems in existing methods:\n1.  RUL prediction typically involves multivariate equipment monitoring time series data, such as multiple sets of vibration signals in different directions, etc. To fully utilize the information provided by temporal and spatial dimensional, multi-dimensional feature fusion is a fundamental module in data-driven methods. However, most current methods are constrained by the fact that temporal and spatial features are extracted from different modules. The differences in feature structures result in feature fusion being predominantly accomplished through simple operations, such as addition or concatenation, thus lacking flexibility. This makes it challenging for the model to distinguish the importance of different features. Therefore, investigating flexible feature fusion is crucial for enhancing the flexibility and robustness of data-driven methods.\n2.  Currently, the RUL prediction problems are often transformed into regression problems, regressing the corresponding RUL values using samples from a single time window. Common approaches individually regress one RUL value with one sample for training, without taking into account the potential relationships between samples. This relationship becomes more apparent when the degradation intervals are sufficiently large. For example, as illustrated in Figure 1, samples A, B, and C are constructed using a sliding window. Sample B is mapped into the feature space and subsequently regressed to its corresponding RUL. Obviously, the degradation time between samples A and B is much shorter than that between B and C. In the high-dimensional feature space, the similar relationship should be remained to simplify subsequent regression task in the output layer. The excessive freedom in the feature extractor of current models hinders the stability of the final output results. Therefore, correctly incorporating the global relationship between samples as a constraint in the feature extractor optimization process will enhance the performance of existing data-driven methods in RUL prediction."}, {"title": "2. Realted Work", "content": "RUL Prediction: In recent years, with the improvement of data collection capabilities, advancements in sensor technology, and the widespread adoption of big data techniques, data-driven RUL prediction methods have gradually become the mainstream of research. Among them, deep learning-based approaches can fully exploit internal information in the data, offering strong robustness, generality, and ease of use. The latest achievements primarily revolve around enhancing the model's ability for temporal feature extraction, spatial-temporal fusion feature extraction, and improvements in attention mechanisms. For instance, Zhang et al.[7] proposed a temporal attention mechanism combined with bidirectional Gated Recurrent Units (GRUs) for temporal feature extraction, aiming to construct a more accurate RUL prediction model. Zhang and Li et al. [8] based their work on self-attention modules, incorporating two types of sparse self-attention mechanisms, achieving state-of-the-art results on the C-MAPSS dataset. Zhang and Tian et al. [9] integrated one-dimensional CNN with bidirectional GRU networks to simultaneously extract spatiotemporal features, significantly improving the model's accuracy in RUL prediction. Pei et al.[15] introduced an interactive prediction framework that utilizes stacked autoencoders for constructing health indicators and incorporates a nonlinear degradation model. The effectiveness and superiority of the method were demonstrated through two case studies involving turbofan engines. Ren et al. [13] comprehensively employed autoencoder structures, CNN, and LSTM to achieve adaptive spatiotemporal feature extraction for battery data, used for predicting battery RUL. While these works attempt to enhance the accuracy and applicability of deep learning methods in RUL prediction from different perspectives, we observe that the RUL prediction problem can be extended to a regression problem for multivariate time series. Therefore, starting from the latest time series analysis models can further improve the performance of data-driven methods in RUL prediction.\nMultivariate Time Series Analysis: Recently, research in time series analysis has predominantly focused on Transformer architectures, attention mechanisms, and Multi-Layer Perceptron (MLP) models, which have significantly influenced the development of RUL prediction in various domains[8][13][16][17]. While Transformers exhibit excellent sequential modeling capabilities, their bulky architecture and parameter scale often pose challenges in industries due to difficulties in lightweight implementation[8]. Therefore, there is a growing interest in more lightweight MLP-like models for time series analysis. Zhang et al. [18] decomposed time series into trend and cyclical components, utilizing a lightweight MLP network for prediction. Zeng et al.[19] discovered that simple MLP models can achieve, and sometimes surpass, the performance of complex Transformer networks in handling time series data, paving the way for new avenues in time series analysis research. TS-Mixer[20] adopted the approach of MLP-Mixer[21] from computer vision, employing MLPs for feature extraction across Patch, Spatial, and Temporal dimensions. It achieved outstanding results in time series prediction and featured a simpler structure with fewer parameters compared to Transformer architectures. Similarly, Google proposed Tsmixer[22], a pure MLP-based architecture for multivariate time series prediction, highlighting the robust potential of pure MLP structures in processing multivariate time series data. Therefore, this paper will explore the application of pure MLP structures in data-driven RUL prediction."}, {"title": "3. Methodology", "content": "This chapter will first introduce the basic definition of the RUL prediction problem in Section 3.1. Subsequently, Section 3.2 will provide detailed insights into the proposed Dual-path Mixer model. Finally, Section 3.3 will present the training method based on the FSGRI constraint."}, {"title": "3.1. Notations", "content": "The problem description for the RUL prediction problem discussed in this paper is as follows. $X^{l \\times m}_i$ represents the i-th multivariate equipment monitoring time series sample with a length of $l$ and $m$ variables.$F(\\cdot)$ denotes the feature extractor, $A(\\cdot)$ represents the output layer used for regression, $Y_i$ denotes the true RUL value for the i-th sample, and $\\hat{Y_i}$ represents the predicted RUL value for the i-th sample. The expression for the process RUL prediction can be formulated as follows:\n\n$Y_{i}=A(F(X_{i}^{l \\times d}))$"}, {"title": "3.2. Dual-path Mixer for Remaining Useful Life Prediction", "content": "3.2.1. Basic Block\nIn recent years, MLP Mixer has demonstrated powerful processing capabilities in time series feature extraction[20][22]. Inspired by models like MLP Mixer, which are based on a pure MLP architecture, the construction of a spatial-temporal homogeneous feature extractor has become feasible. This paper utilizes a standard MLP module as the fundamental unit for feature extraction, as illustrated on the left side of Figure 2. The matrix shapes of the output features for each layer are indicated in the figure. The core of this module is a linear transformation layer with shared parameters across channels, represented mathematically as follows:\n\n$x^{l \\times d}=GeLU(x^{l \\times m} * W_{m1}) * W_{m2}$\n\nwhere $W_{m1} \\in \\mathbb{R}^{m \\times (2*d)}$ and $W_{m2} \\in \\mathbb{R}^{(2*d) \\times d}$ are the parameter matrices to be optimized, $d$ is the feature dimension of the model, $GeLU$ stands for Gaussian Error Linear Units[23] activation function, and (*) denotes matrix multiplication. Additionally, a simple lightweight gating unit is designed for subsequent dynamic feature fusion, as illustrated on the right side of Figure 2. Inspired by the LSTM gating mechanism[24], this module eliminates the need for a complex attention mechanism, allowing the removal of interference components from features and providing the model with feature selection capabilities. Its mathematical form is as follows:\n\n$x^{l \\times d}_{g}=Sigmoid(x^{l \\times d} * W_{g}) \\odot x^{l \\times d}$\n\nwhere $\\odot$ represents the element-wise product (Hadamard product), and $W_{g} \\in \\mathbb{R}^{d \\times d}$ is the parameter matrix to be optimized. Essentially, this module learns a weight matrix with the same shape as the input features and filters the original input features with the weight matrix through Hadamard product."}, {"title": "3.2.2. Dual-path Mixer Layer", "content": "Through the basic modules introduced in the previous section, the proposed Dual-path Mixer Layer (DML) can be constructed. The goals of designing DML are threefold: 1) Construct a homogeneous feature extractor to make the feature structures of different dimensions similar without introducing additional priors, maintaining the generality of the structure. 2) Achieve flexible feature fusion and interaction, endowing the final model with feature selection capability. 3) Be easily stackable into a deep architecture, maintaining the flexibility of DML and enabling the final model to achieve stronger non-linear mapping capabilities with a limited number of parameters. Based on the above three main goals, the DML structure is designed as illustrated in Figure 3. Firstly, DML consists of two parts: the temporal part and the spatial part (but not limited to two parts; more parallel parts can be constructed when additional feature dimensions are available). The core difference between the two parts lies in the dimensionality of the processing of their respective input features. Due to the shared linear mapping layers across the first dimension in the MLP Block and Gate Block, as introduced in Section 3.2.1, we can achieve distinct dimensions of focus for the two parts of DML by applying a transpose operation. By processing them separately on two sets of different dimensions, the model can capture diverse aspect features of the data. Moreover, since the module architecture used by the two parts of the feature extractor is entirely identical, differing only in parameter matrices, goal 1) is effectively accomplished.\nSecondly, the interaction and fusion of features from the two parts occur at the red connection lines shown in the Figure 3, referred to as \"interaction connections.\" Similar to the residual connection exchanging information in the depth direction of the network, interaction connections exchanging information in the width direction of the network. To control the flow of features between the two parts, a Gate Block is employed for feature filtering before feature fusion, achieving goal 2).\nFinally, it's worth noting that the features filtered by the Gate Block are used only for feature exchange and not for subsequent processing steps within its own part. This is done to avoid the gradient being propagated only through the Sigmoid function used by the Gate Block during backpropagation, mitigating the impact of the Sigmoid's gradient saturation region on the convergence speed of the model. Additionally, after the MLP Block and feature fusion, a combination of residual connection and LayerNorm is used to stabilize the gradient values during backpropagation[25]. This allows the model to be stacked into a deep and narrow structure, gaining stronger non-linear mapping capabilities without affecting the convergence speed, achieving goal 3).\nIn summary, the overall workflow of the DML module can be described as follows:\n\n$Z^{l \\times d}=LN (M_{1} (X^{l \\times d}) + X^{l \\times d})$\n\n$Z^{d \\times l}=LN (M_{2} ((X^{l \\times d})^{T}) + X^{d \\times l})$"}, {"title": "3.2.3. Dual-path Mixer Model", "content": "Through the basic modules and DML modules mentioned above, a RUL prediction model called Dual-path Mixer (Dual-Mixer) is constructed for equipment multivariate monitoring time series data, as illustrated in Figure 4. The model is divided into a feature extractor and a regression layer. The feature extractor is used to map input samples from the raw data space to a high-dimensional feature space, while the regression layer is employed to regress the extracted high-dimensional features to the RUL. The feature extraction part consists of a linear mapping layer, multiple DML layers, and two independent Gate Blocks. The role of the linear mapping layer is to initially map the input samples to the model's feature dimensions, and its mathematical form is as follows:\n\n$x^{l \\times d}=x^{l \\times m} * W_{m}$\n\nwhere $W_{m} \\in \\mathbb{R}^{m \\times d}$ represents the parameters to be optimized and d is the feature dimension. Subsequently, for the first layer of DML, both the temporal and spatial parts receive input from the same input matrix $X^{l \\times d}$, where the spatial part is distinguished from the temporal part through the transposition operation illustrated in Figure 3. The computational process for each layer of DML is described in Section 3.2.2. Finally, the last layer of the DML module outputs two distinct features: temporal features $X^{l \\times d}_s$ and spatial features $X^{l \\times d}_s$. Each feature undergoes further filtering through a Gate Block before being summed together to form the final feature. As the ultimate feature integrates both temporal and spatial characteristics, it can be conveniently flattened for subsequent processing by the regression layer. The regression part is composed of a linear mapping layer, and its mathematical form is as follows:\n\n$\\hat{Y} = x^{1 \\times (l*d)} * W_{r}$\n\nwhere $W_{r} \\in \\mathbb{R}^{(l*d) \\times 1}$."}, {"title": "3.3. Feature Space Global Relationship Invariance Training", "content": "3.3.1. Feature Space Global Relationship Invariance\nThe proposed FSGRI aims to preserve the relative spatial relationships in the original data space within the feature space. The envisioned relationships between features established by FSGRI can be described as:\n\n$S(Z_{i}, Z_{i}) > S(Z_{i}, Z_{i+1}) > \\dots > S(Z_{i}, Z_{t})$\n\nwhere $Z_i$ represents the high-dimensional features of the i-th sample, s is a scoring function, and its output score $s_{ik}$ quantifies the degree of matching between sample features. A higher score indicates a higher degree of match. In this paper, s is the cosine similarity function, and i \u2208 [1, t], arranged in chronological order. This corresponds to the RUL of the samples, satisfying:\n\n$V_{i} > V_{i+1} > \\dots > V_{t}$\n\nThis relationship indicates that samples with close distances in the original space have similar features. Conversely, samples that are farther apart exhibit greater feature differences, and these differences vary with distance. This constraint is employed to achieve continuous encoding in the feature space, simplifying the regression challenge for RUL.\nContrastive learning can constrain the encoding distances of features between different samples from the perspec-tive of the feature space and is widely applied in various pre-training and classification tasks[26]. Due to its inherent ability to impose constraints on the feature space, contrastive learning is selected to implement FSGRI. The next section will first introduce the construction method for positive and negative sample pairs."}, {"title": "3.3.2. Gaussian Threshold Sampling method", "content": "The strategy for constructing positive and negative sample pairs significantly impacts learning effectiveness. Inspired by the TNC[27] sampling method, we propose a Gaussian Threshold Sampling method for RUL prediction to construct positive and negative sample pairs, as illustrated in Figure 5. Given the complete degradation data $X^{l \\times m}$ for one device, a sliding window of size w and step size sl is used to generate t samples $[X_{1}, X_{2}, ..., X_{t}]$, where $X_{i} \\in \\mathbb{R}^{w \\times m}$ During the training phase, when sample $X_i$ is chosen as the training sample (anchor sample), the probability $p(X_k)$ of sampling the other samples as negative samples is as follows:\n\n$p(x_{k}) \\sim N(\\eta_i, \\sigma^2_i), k < (i-\\frac{\\beta}{2}) or k > (i+\\frac{\\beta}{2})$\n\n$p(x_{k})=0, (i-\\frac{\\beta}{2}) \\leq k \\leq (i + \\frac{\\beta}{2})$\n\nwhere $\\beta$ is the threshold coefficient, indicating the non-sampling range centered around i. The sampling probability of other samples follows a Gaussian distribution $N(\\eta_i, \\sigma^2_i)$, with the distribution always centered at the sampling index i. In other words, samples around $X_i$ are more likely to be sampled as negative samples, but the threshold coefficient $\\beta$ ensures that the sampling distance is not too close. Finally, by non-repetitively sampling, m negative samples $[X^-_{i,1},..., X^-_{i,m}]$ can be obtained.\nThe construction of positive sample is achieved by adding Gaussian noise to the anchor sample $X_i$:\n\n$X^+ = X_{i} + \\epsilon, \\epsilon \\sim N(0, \\sigma^2_i)$"}, {"title": "3.3.3. Distance Weighted InfoNCE", "content": "InfoNCE[28] is a common contrastive learning loss function that leverages positive and negative sample pairs to establish relationships between features:\n\n$L_{InfoNCE} = -log \\frac{exp(\\frac{s(Z_{i},Z^{+}_{i})}{\\tau})}{ \\sum_{k!=i} exp(\\frac{s(Z_{i},Z^{-}_{i,k})}{\\tau}) + exp(\\frac{s(Z_{i},Z^{+}_{i})}{\\tau})} $ \n\n$= -log \\frac{exp(\\frac{s_{i,i}}{\\tau})}{ \\sum_{k!=i} exp(\\frac{s_{i,k}}{\\tau}) + exp(\\frac{s_{i,i}}{\\tau})} $\n\nwhere $Z_i$ and $Z^+_i$ are the feature encodings in the feature space for the anchor sample $X_i$ and the positive sample $X^+_i$ respectively. $Z^-_{i,k}$ represents the feature encoding for the negative sample $X^-_{i,k}$ constructed by Gaussian Threshold Sampling method introduced in Section 3.3.2. $\\tau$ is the temperature coefficient. s is the scoring function. $s_{ii}$ represents the score value between the anchor sample and the positive sample, while $s_{ik}$ represents the score value between the anchor sample and the negative sample. Minimizing InfoNCE encourages high similarity between $Z_i$ and $Z^+_i$ and low similarity between $Z_i$ and $Z^-_{i,k}$, reinforcing feature distinctiveness. Ideally, the final optimization result of InfoNCE can be expressed as:\n\n$s_{i,i} > s_{i,k}, \\forall k \\in [1, 2, ..., m]$\n\nFor the RUL prediction task in this paper, there are two reasons for improving InfoNCE:\n1.  Equations 10 and 11 can be further described as relationships between positive and negative sample pairs and the anchor sample:\n\n$s_{ii} > s_{i,1} > s_{i.2} > ... > s_{i,m}$\n\n$V_i > V_{i.1} > V_{i.2} > ... > V_{i.m}$\n\nStandard InfoNCE tends to simultaneously minimize all terms involving $s_{ik}$ as shown in Equation 15, which fails to satisfy the Equation 16."}, {"title": "3.3.4. Training Process", "content": "By combining the DW-InfoNCE proposed in the previous section with the Mean Squared Error (MSE) loss function used for RUL prediction, we can form the FSGRI training method proposed in this paper. The composition of the loss functions and details of FSGRI training will be elaborated below. For most deep learning-based data-driven RUL prediction methods, the fundamental architecture can be divided into two parts: a feature extractor and a regression layer. The FSGRI training method is applicable to any model that adheres to this architecture, as illustrated in Figure 6.\n\nFirst, after constructing positive and negative sample pairs for the sample $X_i$ using the Gaussian threshold sampling method described in Section 3.3.2, high-dimensional features $Z_i$, $Z^+_i$ and $Z^-_{i,m}$ are obtained through the model's feature extractor. These features are then used to calculate the DW-InfoNCE loss according to Equation 20. Subsequently, separate RUL regressions are performed for $Z_i$, $Z^+_i$ and $Z^-_{i,m}$, and their respective MSE losses are calculated. The sum of these MSE losses, denoted as $MSE_{all}$, is computed. The overall computation process is as follows:\n\n$MSE_{all} = MSE(\\hat{Y_{i}}, Y_{i}) + MSE(\\hat{Y^{+}_{i}}, Y_{i}) + MSE(\\hat{Y^{-}_{i,m}}, Y_{i,m})$\n\nUltimately, FSGRI loss function is as follows:\n\n$L_{FSGRI} = L_{DW-InfoNCE} + MSE_{all}$\n\nThrough the $L_{FSGRI}$, the model weights can be optimized using gradient descent. To provide a more details for the batch gradient descent process, the pseudocode of FSGIR is presented in Algorism 1.\nIt is noteworthy that in line 4 of Algorithm 1, the additional sampling of negative samples may result in the effective number of samples involved in the computation being larger than the specified batch size during batch gradient descent. Therefore, the batch size is scaled to ensure that the actual number of computed samples aligns with the expectations."}, {"title": "4. Experiments", "content": "4.1. Dataset Description and Evaluation Metrics\nThis paper validates the proposed method's effectiveness using the commonly employed C-MAPSS[29] dataset in RUL prediction. The C-MAPSS dataset, proposed by NASA Ame Prediction, consists of four sub-datasets, and their basic information is shown in Table 1.\nEach sub-dataset of C-MAPSS has been divided into a training set and a test set. The training set includes operational data throughout the entire lifecycle of multiple engines, while the test set data is incomplete and randomly truncated at some point before engine failure. Lifecycle data consists of monitoring values from multiple sensors, recording parameters during each engine run. There are 21 variables, as shown in Table 2.\nThis paper employs commonly used metrics in regression problems and RUL prediction, namely RMSE (Root Mean Square Error) and MAPE (Mean Absolute Percentage Error), to assess the performance of the model. The mathematical formulations of these metrics are as follows:\n\n$RMSE (Y, \\hat{Y}) = \\sqrt{\\frac{1}{N} \\sum_{i=1}^{N} (Y_{i} - \\hat{Y_{i}})^2}$\n\n$MAPE (Y, \\hat{Y}) = \\frac{100\\%}{N} \\sum_{i=1}^{N} |\\frac{Y_{i} - \\hat{Y_{i}}}{Y_{i}}|$\n\nwhere N is the number of samples, $Y_i$ is the true RUL of the i-th sample, and $\\hat{Y_i}$ is the predicted RUL"}, {"title": "4.2. Dataset Preprocessing", "content": "The C-MAPSS dataset contains some variables with constant values that do not provide meaningful information. Therefore, these variables are removed and excluded from the model training and testing processes. Following the approach in the literature[9], corresponding to the indices in Table 2, the selected variable indices are 2, 3, 4, 7, 8, 9, 11, 12, 13, 14, 15, 17, 20, and 21.\nTo construct input samples for the data-driven model, the sliding window method is a commonly used approach. As shown in Figure 7, for the original time series data with a length of $l$ composed of $m$ sensors, a window of size $w$ is slid along the time dimension with a step size of $sl$. The data within each window is considered as one sample, and each sample $X_{i} \\in \\mathbb{R}^{w \\times m}$.\nData normalization is a standard procedure in data-driven methods. In this paper, the Min-Max normalization method is utilized to normalize all samples. Its formulation is as follows:\n\n$x^{w \\times m}_{i} = \\frac{x^{w \\times m}_{i} - x^{w \\times m}_{i min}}{x^{w \\times m}_{i max} - x^{w \\times m}_{i min}}$\n\nwhere $x^{w \\times m}_{i min}$ and $x^{w \\times m}_{i max}$ are the minimum and maximum values of the data from each of the m sensors, and $x^{w \\times m}_i$ is the i-th original data sample.\n\nSegmented linear degradation labels are a commonly employed labeling method for RUL in C-MAPSS data[8][9][10][17]. The construction process is as follows:\n\n$Y_k = 1, k \\geq 125$ \n\n$Y_k = \\frac{l-k}{l-125} ,k < 125 and l > 125 $\n\n$Y_k = \\frac{k}{l} , k < 125 $\n\nwhere $Y_i$ is the RUL percentage corresponding to the k-th cycle, and l is the total number of cycles. After constructing samples using the sliding window method, the RUL of the last cycle within the sample window is taken as the label for each sample, which serves as the prediction target for the model."}, {"title": "4.3. Tuning Experiments", "content": "In this section, the experiment will first determine the two main hyperparameters of the proposed Dual-Mixer: the number of DML layers and the feature dimension d. At the same time, the effectiveness of the model will be preliminarily verified. The number of DML layers is adjusted within the range [2, 4, 6, 8, 10, 12], and the feature dimension is adjusted within the range [16, 32, 64, 128] (for FD001 and FD003) and [16, 32, 64, 128, 256] (for FD002 and FD004). Using a pairwise combination approach, validation is conducted on the four sub-datasets, and the experimental results are shown in Figure 8. In Figure 8, each subplot's X-axis represents the model's feature dimension. For FD001 and FD003, due to the smaller data size, feature dimensions are selected from [16, 32, 64, 128]. For FD002 and FD004, considering the larger data size, an additional dimension of 256 is considered, and feature dimensions are selected from [16, 32, 64, 128, 256]. The color of each bar in the plot represents the number of DML layers, with lighter colors indicating more layers. The Y-axis represents the RMSE value, where lower values indicate higher predictive accuracy.\nFrom the figure, it can be observed that, in most cases, a feature dimension of 32 and 6 layers of DML are most suitable, achieving the best RMSE in the majority of situations. Therefore, for this experiment, a feature dimension d of 32 and 6 DML layers are chosen. The performance with a feature dimension of 16 is generally worse, indicating insufficient non-linear mapping capability and occurrence of underfitting. Increasing the number of DML layers significantly improves the model's performance at a feature dimension of 16. As the feature dimension increases and the number of DML layers deepens, there is an increasing risk of overfitting. However, due to the residual connections and LayerNorm within DML, the overfitting phenomenon is not very pronounced, and the network's performance does not significantly degrade as the number of layers increases. Therefore, when applying Dual-Mixer to other datasets, careful adjustment of the feature dimension is recommended."}, {"title": "4.4. Comparison Experiments", "content": "To further validate the effectiveness of the proposed Dual-Mixer model and the FSGRI training method, we selected the following state-of-the-art models as baseline methods:\n1) IMDSSN[8]: A recent RUL prediction method based on Transformer encoder and attention mechanisms.\n2) BTSAM[9]: A RUL prediction model based on bidirectional GRUs and temporal attention mechanisms.\n3) CNN-GRU[9]: A multi-dimensional feature fusion network using convolutional networks and GRUs for RUL prediction.\n4) DAMCNN[30]: A convolutional neural network incorporating multiple attention mechanisms for RUL prediction.\n5) MLP-Mixer[21]: A deep network architecture for extracting multi-dimensional features, applicable to time series data. In our experiments, a 2-layer MLP-Mixer with 128 feature dimensions was used.\n6) TS-Mixer [20]: A recent time series prediction model based on improvements to MLP-Mixer. It exhibits excellent performance in multivariate time series prediction and is adapted for RUL prediction. In our experiments, we used the same configuration as Dual-Mixer, i.e., 6 layers with 32 feature dimensions.\n7) LSTM[31]: A basic deep learning method for processing time series data. We used a 3-layer LSTM with 256 dimensions.\nWe reproduced these methods in the experiments, and the code can be found at:https://github.com/fuen1590/PhmDeepLearningProjects. All these methods follow the architecture shown in Figure 6, making them compatible with the FSGRI training method. The hyper-parameters configuration for the proposed Dual-Mixer method is provided in Table 3.\nAll experiments in this study were implemented on Ubuntu 18.02 with PyTorch 2.0. The inference and training were accelerated using Nvidia GeForce RTX 3090. The final experimental results are summarized in Table 4.\nThe models in the table with the suffix \"-F\" represent the results obtained using FSGRI training, while models without the suffix were trained using conventional gradient descent. The underscore (_) indicates improved performance metrics compared to the original method when using FSGRI, and bold font represents the globally optimal performance metric. The \"Improvement\" in the table indicates the extent to which FSGRI enhances the model's performance. All experimental results are based on the average of three trials.\nWe compared each model using normal training methods with FSGRI training methods. In almost all cases, FSGRI consistently led to stable improvements in predictive performance. For all models using FSGRI training, the improvement rates for RMSE and MAPE were, on average, 9.14% and 2.38% in FD001, 7.55% and 4.97% in FD002, 4.34% and 0.97% in FD003, and 6.98% and 1.32% in FD004. Overall, FSGRI leads to average improvements of 7.00% and 2.41% in RMSE and MAPE, respectively, across all models in the C-MAPSS dataset.\nIn cases without FSGRI, Dual-Mixer, except for a slightly higher MAPE in FD001 and FD004 compared to BTSAM, achieved the optimal values in all metrics among all models. For an intuitive assessment of the models' RUL prediction capabilities, Figure 9 presents the prediction results for all models on the FD004 test set for Engine 1. Compared to other models, the proposed Dual-Mixer demonstrates a stronger ability to capture detailed features in the data. For example, around 200 cycles, Dual-Mixer maintains good predictive capabilities."}, {"title": "4.5. Features Visualization", "content": "We visualized the output features of the models before and after FSGRI training to further analyze the impact of FSGRI on the distribution of model features, as shown in Figure 10. In the visualization process, we selected data from Engine 1 of the FD004 test set as the test sample and applied dimensionality reduction and visualization using the t-Distributed Stochastic Neighbor Embedding (t-SNE)[28"}]}