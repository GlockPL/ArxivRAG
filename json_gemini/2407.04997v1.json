{"title": "ACHIEVING TOOL CALLING FUNCTIONALITY IN LLMS USING ONLY PROMPT ENGINEERING WITHOUT FINE-TUNING", "authors": ["Shengtao He"], "abstract": "Currently, the vast majority of locally deployed open-source large language models (LLMs) and some commercial model interfaces do not support stable tool calling functionality. The existing solution involves fine-tuning LLMs, which results in significant time and computational resource consumption. This paper proposes a method that enables LLMs to achieve stable tool calling capabilities using only prompt engineering and some ingenious code design. We conducted experiments on multiple LLMs that lack tool calling capabilities across various tool calling tasks, achieving a success rate of 100%.", "sections": [{"title": "1 Introduction", "content": "Currently, the primary method for enabling large language models (LLMs) to achieve tool calling capabilities is through fine-tuning. For example, ToolLLM is a general framework for tool usage. Y. Qin et al. proposed a fine-tuning technique to enable tool calling capabilities in LLMs, providing a comprehensive API dataset [1]. After extensive training on a large number of real API datasets, the ToolLlama model achieved stable tool calling capabilities. I. Abdelaziz et al. enabled function calling capabilities (i.e., tool calling) in LLMs through fine-grained multi-task learning [2]. Fine-tuning LLMs requires significant time and computational resources, and may even result in an LLM with lower intelligence levels than before fine-tuning. This leads to high trial-and-error costs. When a different type or more complex API structure needs to be called, the fine-tuned LLM requires additional time and computational resources for further fine-tuning to meet new demands. This is clearly detrimental to the practical application of LLMs in industry.\nPrompt engineering can enable LLMs to achieve tool calling capabilities with almost no cost and high efficiency. By dynamically adjusting prompts for different application scenarios, LLMs can adapt to new tool libraries. However, the drawback of using prompt engineering is its instability. This paper proposes a method to achieve stable tool calling capabilities in LLMs using only prompt engineering."}, {"title": "2 Principle", "content": "The prompt engineering method used in this paper consists of two main parts: prompt injection and tool result feedback. Prompt injection is used to add tool information and prompts for using the tool into the system prompt. Tool result feedback involves parsing the output of the tool calling and embedding the content returned by the tool back into the LLMs.\nDuring the prompt injection phase, the prompts used are as follows:\nif tools is not None:\ntools_dis = json.loads(tools)\nfor tool_dis in tools_dis:\ntools_list.append(tool_dis [\"function\"])\ntools_instructions =\n\"\"\ntools_instruction_list = []\nfor tool in tools_list:\ntools_instruction_list.append(tool [\"name\"])\ntools_instructions += (\nstr(tool [\"name\"])\n+\":\"\n+ \"Call this tool to interact with the \"\n+ str(tool [\"name\"])\n+ \" API. What is the \"\n+ str(tool [\"name\"])\n+ \" API useful for?\\n\"\n+ str(tool [\"description\"])\n+ \". Parameters:\\n\"\n+ str(tool [\"parameters\"])\n+ \"Required parameters:\\n\"\n+ str(tool [\"parameters\"] [\"required\"])\n+ \"\\n\"\n)\nTOOL_EAXMPLE = \"You will receive a JSON string containing a list of callable tools. Please parse this JSON string and return a JSON object containing the tool name and tool parameters. Here is an example of the tool list:\\n\\n{\\\"tools\\\": [{\\\"name\\\": \\\"plus_one\\\", \\\"description\\\": \\\"Add one to a number\\\", \\\"parameters\\\":{\\\"type\\\": \\\"object\\\",\\\"properties\\\":{\\\"number\\\":{\\\"type\\\": \\\"string\\\",\\\"description\\\": \\\"The number that needs to be changed, for example: 1\\\",\\\"default\\\": \\\"1\\\",}},\\\"required\\\": [\\\"number\\\"]}},{\\\"name\\\": \\\"minus_one\\\", \\\"description\\\": \\\"Minus one to a number\\\", \\\"parameters\\\":{\\\"type\\\": \\\"object\\\",\\\"properties\\\":{\\\"number\\\":{\\\"type\\\": \\\"string\\\",\\\"description\\\": \\\"The number that needs to be changed, for example: 1\\\",\\\"default\\\": \\\"1\\\",}},\\\"required\\\": [\\\"number\\\"]}}]}\\\\nBased on this tool list, generate a JSON object to call a tool. For example, if you need to add one to number 77, return:\\n\\n{\\\"tool\\\": \\\"plus_one\\\", \\\"parameters\\\":{\\\"number\\\": \\\"77\\\"}}\\n\\nPlease note that the above is just an example and does not mean that the plus_one and minus_one tools are currently available.\"\nREUTRN_FORMAT=\\\"{\\\"tool\\\": \\\"tool name\\\", \\\"parameters\\\":{\\\"parameter name\\\": \\\"parameter value\\\"}}\\\"\nINSTRUCTION = f\\\"\"\"\n{TOOL_EAXMPLE}\nAnswer the following questions as best you can. You have access to the following APIs:\n{tools_instructions}\nUse the following format:\n````json\n{REUTRN_FORMAT}\n````\nPlease choose the appropriate tool according to the user's question. If you don't need to call it, please reply directly to the user's question. When the user communicates with you in a language other than English, you need to communicate with the user in the same language.\nWhen you have enough information from the tool results, respond directly to the user with a text message without having to call the tool again.\n\"\"\"\nsystem_prompt=INSTRUCTION\nINSTRUCTION is the final string injected into the system prompt, which includes three parts: TOOL EXAMPLE, tools instructions, and RETURN FORMAT. TOOL EXAMPLE is used to guide the LLMs on how to understand and use the tool. When writing TOOL EXAMPLE, it is important to use trivial tools as examples, such as the tools used in this paper for incrementing and decrementing numbers, to avoid confusing the LLMs with actual usable tools. tools instructions is a list of currently available tools converted into a format readable by the LLMs. When using the LLMs in practice, tools instructions can be dynamically adjusted by inputting different tools, allowing the LLMs to know which tools are available and how to use them. RETURN FORMAT defines the format for calling the API."}, {"title": "Achieving Tool Calling Functionality in LLMs", "content": "During the tool result feedback phase, regular expressions are used to extract the \u201ctool\" and \"parameters\" from the output. For the interpreter tool, another regular expression is used to extract the code output by the LLMs, increasing the success rate of the LLMs using the interpreter tool. The code used in this paper is as follows:\nhistory.append({\n \"role\": \"user\",\n \"content\": user_prompt.strip()\n})\nresponse= model.create_chat_completion(\n messages = history,\n max_tokens=max_length,\n temperature=temperature,\n)\nresponse_content=response ['choices'] [0] ['message'] ['content']\npattern = r'{\\s*\"tool\":\\s*\"(.*?)\",\\s*\"parameters\":\\s*\\{(.*?)\\}\\s*}'\nwhile re.search(pattern, response_content, re. DOTALL)!=None:\n match=re.search (pattern, response_content, re.DOTALL)\n tool = match.group(1)\n parameters = match.group (2)\n json_str = '{\"tool\": \"' + tool + '\", \"parameters\": {' + parameters + '}}'\n parameters = json.loads('{' +parameters+ '}')\n results = dispatch_tool(tool, parameters)\n print(results)\n history.append({\"role\":\"assistant\", \"content\": json_str})\n history.append({\"role\": \"observation\", \"content\": results})\n response= model.create_chat_completion(\n messages = history,\n max_tokens=max_length,\n temperature=temperature,\n)\nresponse_content = response.choices[0].message.content\npattern = r\"\u2018\u2018\u2018python\\n(.*?)\\n\u2018\u2018\u2018\"\nwhile re.search(pattern, response, re.DOTALL) !=None:\n matches = re.search(pattern, response, re. DOTALL)\n code = matches.group(1)\n results = interpreter (code)\n print (results)\n json_str = '{\"tool\": \"interpreter\", \"parameters\": '+code+'}'\n history.append({\"role\":\"assistant\", \"content\": json_str})\n history.append({\"role\": \"observation\", \"content\": results})\n response= model.create_chat_completion(\n messages = history,\n max_tokens=max_length,\n temperature=temperature,\n)\nresponse_content = response.choices[0].message.content\nBy identifying the dictionary of tools called by the LLM and extracting the corresponding values, these values are then passed into the appropriate tool functions. Finally, the results returned by the tools are sent back to the LLM in the role of \"observation.\" For some LLM interfaces that do not accept the roles of \u201cobservation,\u201d \u201ctool,\u201d or \u201cfunction,\" the results can be returned to the \"user\" role instead. For example:\nhistory.append({\"role\": \"user\", \"content\": \"Call\" + tool + \"The result returned by the tool is:\" + results + \". Please continue to answer my previous question based on the result returned by the tool.\"})\nBy using the above prompt engineering method, it is possible to avoid fine-tuning and enable LLMs that originally lack tool calling capabilities to achieve stable tool calling functionality."}, {"title": "3 Experimental Results", "content": "In this study, we used the quantized versions of the current mainstream small open-source models llama3-8b, gemma2-9b, qwen2-7b, and mistral-7b from Ollama as test models [3]. The following tool calling tasks were tested, each with 10 different queries:\n1. Querying real-time time in different time zones.\n2. Querying real-time weather in different locations.\n3. Answering recent events after performing a Google search.\n4. Solving mathematical problems using a Python interpreter.\n5. Searching local file information to answer questions.\n6. Querying relevant papers on arXiv.\n7. Searching local knowledge graphs to answer questions.\nThe tests were conducted on an NVIDIA GeForce RTX 4080, using a platform developed by the author: the open-source project ComfyUI LLM Party [4]. This project is available on GitHub. To quickly reproduce the results of this paper, you can download the project for testing. Table 1 shows the number of successful tool calls for multiple models across various tool calling tasks using the prompt engineering method proposed in this paper. For models that do not use the prompt injection method, tool information is passed to these models via the tool interface. However, since these models do not support tool calling functionality, they cannot call these tools.\nTable 1 shows that all models successfully executed the tool calling step and correctly output dictionaries that could be captured by regular expressions. However, due to limitations in code generation capabilities, the Ollama-quantized versions of the llama3-8b and mistral-7-b models did not consistently output correct code in the Python interpreter task, resulting in unstable completion of computational tasks. In the knowledge graph search task, all models successfully returned relevant knowledge using the tools. However, due to limitations in logical understanding capabilities, the Ollama-quantized versions of the qwen2-7b and mistral-7b models could not consistently understand the logical relationships between multiple edges in the knowledge graph.\nThese experimental results demonstrate that prompt engineering can enable LLMs that originally lack tool calling capabilities to achieve tool calling functionality. However, the ability to effectively utilize the information returned by the tools to solve user problems is still limited by the LLM's own intelligence level. Larger models, such as gemma2-9b, show significantly more stable capabilities in utilizing the results returned by the tools.\nThe Figure 1 shows the output of the gemma2-9b model when calling the weather tool. When prompt engineering is not used, the 'is tools in sys prompt' attribute is set to disable, and the gemma2-9b model believes it cannot obtain"}, {"title": "Achieving Tool Calling Functionality in LLMs", "content": "real-time information, thus rejecting the user's request. When prompt engineering is used, the \u2018is tools in sys prompt' attribute is set to enable, and the gemma2-9b model provides the correct real-time weather information."}, {"title": "4 Conclusion", "content": "This study demonstrates that prompt engineering alone can enable LLMs to achieve tool calling capabilities, significantly saving time and computational resources required for fine-tuning. All models in the experiment successfully output the correct format for regular expression recognition. However, due to the intelligence level limitations of small LLMs, some models lacked the programming or logical capabilities to produce correct results for certain complex tasks. Due to the limitations of the author's equipment, the effects of prompt engineering were not tested on larger LLMs. Researchers who have doubts about the experimental results can use the author's open-source project on GitHub, ComfyUI LLM Party [4], to reproduce the work presented in this paper."}]}