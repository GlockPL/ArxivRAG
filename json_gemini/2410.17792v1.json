{"title": "Enhancing Federated Learning Convergence with Dynamic Data Queue and Data Entropy-driven Participant Selection", "authors": ["Charuka Herath", "Xiaolan Liu", "Sangarapillai Lambotharan", "Yogachandran Rahulamathavan"], "abstract": "Federated Learning (FL) is a decentralized approach for collaborative model training on edge devices. This distributed method of model training offers advantages in privacy, security, regulatory compliance, and cost-efficiency. Our emphasis in this research lies in addressing statistical complexity in FL, especially when the data stored locally across devices is not identically and independently distributed (non-IID). We have observed an accuracy reduction of up to approximately 10% to 30%, particularly in skewed scenarios where each edge device trains with only 1 class of data. This reduction is attributed to weight divergence, quantified using the Euclidean distance between device-level class distributions and the population distribution, resulting in a bias term (\u03b4\u03ba). As a solution, we present a method to improve convergence in FL by creating a global subset of data on the server and dynamically distributing it across devices using a Dynamic Data queue-driven Federated Learning (DDFL). Next, we leverage Data Entropy metrics to observe the process during each training round and enable reasonable device selection for aggregation. Furthermore, we provide a convergence analysis of our proposed DDFL to justify their viability in practical FL scenarios, aiming for better device selection, a non-sub-optimal global model, and faster convergence. We observe that our approach results in a substantial accuracy boost of approximately 5% for the MNIST dataset, around 18% for CIFAR-10, and 20% for CIFAR-100 with a 10% global subset of data, outperforming the state-of-the-art (SOTA) aggregation algorithms.", "sections": [{"title": "I. INTRODUCTION", "content": "The remarkable expansion of cloud-based Al solutions has been closely linked to the rapid growth of the Artificial Intelligence (AI) market significantly in the Internet of Things (IoT) related industries and topics. A primary driver of this technological revolution is the increasing prevalence of personal smart devices. These intelligent devices are now an integral part of people's lives, equipped with numerous sensors that provide access to vast amounts of valuable training data crucial for developing machine learning (ML) models [1], [2]. Considering the issues of data availability, and privacy sensitivity, Federated Learning (FL) has become increasingly popular as it allows organizations to leverage the distributed data available on personal smart devices without the need to centralize it [3]\u2013[5]. Moreover, the rapid proliferation of the Internet of Things (IoT) has ushered in an era of interconnected devices generating vast volumes of data across various application domains. In this context, our proposed Dynamic Data queue-driven Federated Learning (DDFL) approach emerges as a promising solution to optimize ML models in IoT scenarios.\nFL involves two key entities: the device, responsible for owning the training data, and the server, the aggregator for the primary model (global model) by utilizing each device's gradients. The distinguishing aspect of FL lies in its ability to achieve superior global model performance while keeping all training data securely stored within the devices' devices. FL architecture operates in training rounds. During each round, the server initializes the parameters of the global model and distributes it to each device. devices then train their local models using their respective data. Once training is complete, the devices upload their local models to the server, where an aggregation algorithm [6] is applied to combine and refine the models into an enhanced global model. This collaborative and privacy-conscious approach to ML is at the forefront of research and is making significant strides in various application domains such as personal credit scoring, environmental monitoring, health and gesture monitoring, traffic and closing management in autonomous vehicles, etc.\nYet FL has drawbacks when dealing with real-world data distribution, device selection for secure aggregation, privacy and security. The distribution of data among devices can be classified into two main categories: independent and identically distributed data (IID) and not identically and independently distributed (non-IID). In practical scenarios, private data use for FL is unbalanced and biased towards unique model creations and will result in less model accuracy, and poor convergence. Works by [7], [8] state that the presence of non-IID data distribution introduces a range of complex challenges within the context of FL. In non-IID scenarios, data distributions across devices are disparate and may exhibit covariate shift, concept drift, and imbalanced learning. This diversity often leads to biased models and skewed predictions, undermining fairness, communication overhead and difficulties in aggregating models due to varying optima further delaying model convergence.\nIn the context of IID data distribution, the devices possess data independently sampled from the same underlying distribution. This means that the data across all devices are relatively similar in terms of feature distributions, class"}, {"title": "A. Contributions and Motivations", "content": "Our method is designed to tackle several critical challenges commonly encountered in the training process, including slow convergence and low model accuracy. Moreover, we focus on the efficient selection of devices for updating the global model, a key aspect that leads to a more equitable and fair model training process in FL by reducing the biases between the global model and local models. To summarize, our work makes the following significant contributions to the field.\n1) Faster convergence and better accuracy: We propose a novel data distribution mechanism for non-IID data where each device in each round has additional training data. In this approach, the y portion of data will be saved in the server and distributed dynamically among devices in each training round. It will enhance the model convergence speed, average model aggregation time and accuracy. Here we replicate the real-world FL scenario where the local model training data is dynamic. Additionally, we observe a reduction in the bias term \u03b4, quantified by the Euclidean distance between device-level class distributions and the population distribution, resulting in improved model convergence.\n2) Rigourous experiment: We comprehensively evaluate the issue of non-IID data which leads to poor accuracy, sub-optimal models and low convergence using model weight divergence. We further compare the weight divergence concerning the DDFL approach and evaluate the DDFL approach using data entropy.\n3) Entrophy-based user section: We propose a model aggregation mechanism by effectively selecting \u039b devices based on the data entropy of each local device. This approach will ensure the fairness of device selection during aggregation. Our analytical results show that in each training round the data entropy improved significantly. As a result, the effect on data in each round and devices rich in data will play a vital role in model convergence and accuracy in FL."}, {"title": "B. Paper Organisation", "content": "The subsequent sections of this paper are organized as follows. Section II summarizes the related work in the same research areas and the challenges in the current work. Section III states the problem scope and provides a mathematical explanation of why the traditional FedAvg fails on non-IID data. Furthermore, shows the accuracy reduction and low convergence rate when having non-IID data, and explains the root cause using weight divergence in each scenario and the distribution of classes in each device. Section IV explains the proposed DDFL Framework. Section V states the results and discussion on the proposed approach which reduces \u03b4, improves the convergence speed and improves model accuracy by 10% and efficient model convergence. Section VI serves as the conclusion of the paper, summarizing the key findings, contributions and future work."}, {"title": "II. BACKGROUND AND RELATED WORK", "content": null}, {"title": "A. The Preliminaries of Federated Learning", "content": "In the context of FL, the goal is to reduce the federated objective function F(w), where w denotes the model parameters. This objective function, F(w), is formulated as the weighted mean of individual local objective functions Fk(w) corresponding to each device k within the FL framework. Mathematically, we have:\n$\\min_w F(w), where F(w) = \\sum_{k=1}^{K} p_kF_k(w),$ (1)\nwhere K signifies the overall number of devices, with pk \u2265 0 and the constraint that $\\sum_{k=1}^{K} p_k = 1$. The function Fk(w) denotes the local objective function corresponding to the kth device. Typically, this local objective function is defined as the empirical risk based on the data specific to that particular device as in the following formula\n$F_k(w) = \\frac{1}{n_k} \\sum_{j=1}^{n_k} f(w, x_{k,j}, y_{k,j}),$ (2)\nIn this context, nk stands for the quantity of locally available samples on device k, and (xk,j,\u0177k,j) denotes the jth sample along with its associated label. The parameter pk serves as a user-defined weight, determining the proportional influence of each device's contribution on the overall objective function. Two common settings for pk are $p_k = \\frac{n_k}{\\sum_{i=1}^{K} n_k}$ or $p_k = \\frac{1}{K}$ where x = $\\frac{1}{ \\sum_{k=1}^{K} n_k}$ is the total number of samples across all devices.\nThe FedAvg, as outlined by [25] in Algorithm 4, represents an enhanced iteration of FedAvg and stands out as a cutting-edge aggregation mechanism for FL. This approach enables devices to train their local models using diverse sets of local data. Subsequently, these models are exchanged with the central server."}, {"title": "B. Related Work", "content": "A work by [9] proposed a practical data-sharing strategy which involves a globally shared dataset, denoted as GD, which is centrally stored in the cloud. This dataset GD comprises a uniform distribution over classes. The process begins with the initialization phase of FedAvg, where a warmup model trained on GD and a random y proportion of GD are allocated to each device. Each device possesses a local model, which is trained not only on the shared data from GD but also on the private data unique to each device. The local model training leverages a combination of shared data and device-specific data to learn and improve its performance. Once the local models are trained on their respective data, the cloud performs model aggregation using FedAvg. This aggregation process involves combining the local models from all devices to create a global model that represents the collective knowledge from the entire network of devices. There are two key trade-offs to consider in this data-sharing strategy which are the trade-off between the size of the globally shared dataset GD and the test accuracy. This trade-off is quantified by the parameter \u03b3, which is the percentage of the size of GD (||GD||) to the total data from all devices (||LD||) expressed as a percentage (\u03b3 = ||GD||\u00d7100%). Adjusting the size of GD can influence the overall test accuracy of the FL system. Secondly, there is a trade-off between the proportion y and the test accuracy of the globally shared dataset GD distributed to each device during the initialization stage. The value of y determines the fraction of shared data available to each device at the beginning of the training process. Different values of y can impact the final test accuracy achieved by the FL model.\nAdditionally, in [12], a novel technique was introduced involving utilising a warmup model. This approach entails the initial model being capable of leveraging pre-trained weights and adjusting to the data similarity among clients through the feature extractor. The weights generated by the warmup model serve the purpose of mitigating the effects of weight divergence within the models.\nThe work by [10] introduces the concept of \u201cmodel distillation\u201d as a cornerstone of their approach. The framework named FL via Model Distillation (FedMD) is presented to harness model distillation to facilitate proficient learning in scenarios characterized by heterogeneous data distributions. This approach is designed to concurrently uphold the imperatives of privacy and communication efficiency. At the core of model distillation lies the principle of training a more compact student model to emulate the performance of a larger, proficient teacher model. The authors underscore the limitations faced by conventional aggregation techniques such as Federated Averaging when confronted with non-IID data. They emphasize that the straightforward averaging process employed in traditional methods can result in compromised convergence rates and sub-optimal outcomes. Furthermore, in [11], they presented Client Selection for FL (FedCS), which focuses on managing devices efficiently by considering their resource conditions. This protocol effectively addresses a device selection problem, accounting for resource constraints. By doing so, the server can aggregate a maximum number of device updates, thereby accelerating the performance enhancement of ML models. Moreover, [26] proposed a method that selects devices with a fairness guarantee in training. Furthermore, the experimental results show that a fairer strategy could promise efficiency in training and model convergence and higher final accuracy. However, all these approaches perform below average in non-IID data distribution.\nA work in [27] proposed a dynamic device scheduling mechanism, which can select qualified edge devices to transmit their local models with a proper power control policy to participate in the model training at the server for FL via over-the-air computation. Moreover, work in [28] proposed an adaptive device selection mechanism for FL. Devices are selected based on their communication channel conditions and computational resources. This approach ensures that devices with better connectivity and computational capabilities contribute more to the model training process, leading to faster convergence and improved performance. Moreover, [29] introduced a priority-based device scheduling mechanism for FL. Devices are prioritized based on the importance of their updates to the global model. The measure of importance is determined by considering factors such as the relevance of the local data and the impact of the device's update on the model's performance. This approach accelerates model convergence and enhances overall performance by prioritising devices with more significant updates. Furthermore, the work in [30] proposed a dynamic client selection approach using reinforcement learning. The selection of clients for participation in FL is treated as a sequential decision-making process. Reinforcement learning techniques dynamically adapt client selection based on channel conditions, update importance, and historical performance. This adaptive approach improves the efficiency and effectiveness of FL in heterogeneous environments. Moreover, in [14], the author proposed a novel mutual knowledge transfer algorithm called Def-KT in a decentralized federated learning (FL) setup. Traditional FL involves the participating clients sending their model updates to the central server after each round.\nAlthough each of these approaches is promising, we have found that they are plagued by common issues such as the computational overhead caused by complex system designs, low accuracies when handling complex and high-dimensional datasets like CIFAR-100, and biased device selection. In essence, DDFL is a novel approach that addresses the most pressing challenges in FL: slow convergence, local model accuracy, and effective and fair client selection based on the quality of each device's data, even when dealing with complex and high-dimensional datasets in a non-IID data setting."}, {"title": "III. PROBLEM STATEMENT AND FORMULATION", "content": "In this section, we demonstrate that the reasons for challenges in FL: slow convergence, and local model accuracy, are due to non-IID data leading to sub-optimal models. Furthermore, extensive experiment results will be discussed in Section V."}, {"title": "A. non-IID Causing on Sub-optimal Global Model", "content": "Suppose a client possesses significantly more data than others or has a significantly high amount of data from a single class following a non-IID distribution. In that case, it can bias the global model towards its skewed distribution, diverting performance on other devices' data. This is a critical drawback of the weight aggregation strategy, which may lead to a sub-optimal model inference.\nNow, let's analyze the impact of the weights pk on the model updates which were previously discussed in Section II which is deriving from Equation (2). The SGD update for FL is typically performed as follows:\n$w_k^{(n)} = w_k^{(n-1)} \u2013 \u03b7\u2207F_k(w_k^{(n-1)})$ (3)\nAssuming a small learning rate n, the update term can be approximated as:\n$\\Delta w_k^{(n)} \\approx -\u03b7 \u2207F_k(w_k^{(n-1)})$ (4)\nNow, consider the impact of pk on the update:\n$\\Delta w_k^{(n)} \\approx -\u03b7 p_k \u2207F_k(w_k^{(n-1)})$ (5)\nwhere $\u2207F_k(w_k^{(n-1)})$ is the gradient of the global objective function concerning the parameters at device k.\nIf pk is chosen based on the local data size, the update is influenced by pk. Devices with larger data sizes (xk) will have smaller pk values, leading to larger updates. This can result in biased model updates, favouring devices with larger data sizes.\nIf pk is chosen as $p_k = \\frac{n_k}{\\sum n_k}$ (normalized by the total data size across all devices), the bias in model updates is mitigated to some extent. However, bias can still occur if the local data distributions are highly skewed.\nIn both cases, if the pk values do not accurately reflect the true distribution of data characteristics across devices, bias in model updates can lead to a global model that is skewed towards the data characteristics of devices with higher weights. Therefore, careful consideration of the choice and normalization of weights (pk) is crucial to minimize bias in model updates and ensure fair contributions from all participating devices in FL.\nFurthermore, Let F(w) represent the globally optimal model that we would achieve if we could aggregate all the data in a centralized manner. In FL with non-IID data, each device k computes a local model Fk(w) based on its respective non-IID data distribution dk(x).\nIn the local model update the local model of device k is obtained by minimizing its local loss function:\n$F(w) = \\arg \\min_{F_k(w)} L_k(F_k(w))$ (6)\nwhere Lk(w) is the local loss function based on the non-IID data distribution dk(x). Then the global model is updated by aggregating the local models:\n$F(w) = \\sum_{i=k}^K \\frac{n_k}{n} F_k(w)$ (7)"}, {"title": "B. Effect of non-IID on Slower Convergence Speed", "content": "where k is the total number of devices, xk is the size of device k's data, and x is the total size of the aggregated data. Define a bias term \u03b4\u03ba representing the bias introduced by device k:\n$\u03b4_\u03ba = F_k(w) \u2013 F(w)$ (8)\nThe updated global model considers bias from all devices:\n$F(w)* = F(w) + \\sum_{k=1}^K \\frac{x_k}{x} \u03b4_\u03ba$ (9)\nDue to the non-IID nature of the data, F(w)* might not be the same as the globally optimal model F(w) that we would obtain with IID data, which leads to a sub-optimal global model F(w).\nDue to non-IID data, the updates proposed by each device k during FL have different convergence rates. This is due to the varying data distributions and quality across devices, leading to diverse learning rates \u03b7. In a typical FL update, the global model F(w) at round n is updated as follows:\n$F(w)* = F(w) \u2013 \u03b7\u2207L(F(w), \u00cek), where \u00c2k ~ dk(x)$ (10)\ndevices with more representative or easier-to-learn data (higher quality) may have larger learning rates, converging faster. Conversely, devices with challenging or less representative data may have smaller learning rates, converging more slowly. The consequence of diverse learning rates is that model updates across devices have varying convergence speeds. This leads to a slower overall convergence of the global model since we need to aggregate these diverse updates over multiple communication rounds.\nVarious strategies have been proposed to address non-IID data distribution challenges in FL. The approach by [9] involves a globally shared dataset (GD) for initialization, with trade-offs between the size of GD and test accuracy, and between y and the accuracy of GD during initialization. Additionally, [12] introduces a warmup model technique to address weight divergence effects. The work by [10] uses \"model distillation,\" while [11] presents FedCS, managing devices efficiently based on resource conditions. [26] proposes a fairness guarantee method. Thus, [14] is a promising approach, the design architecture leads to computational and communications overhead. Despite their contributions, these approaches exhibit limitations in addressing issues like sub-optimal global models, slow convergence, and biased device selection in FL with non-IID data. To overcome these challenges, our proposed DDFL and novel aggregation mechanism based on devices' data entropy aim to enhance convergence, accuracy, and fairness in dynamic real-world scenarios."}, {"title": "IV. PROPOSED DDFL FRAMEWORK", "content": "In this section, we explain our proposed method to overcome the challenge of non-IID data distribution in dynamic real-world scenarios by introducing the DDFL and the novel aggregation mechanism based on the data entropy of devices."}, {"title": "A. Dynamic Data Distribution - DDFL", "content": "A work by [22] proposed the concept of information entropy which can be seen as a measure of the average amount of information needed to describe an event or message. In information theory, higher entropy implies higher uncertainty and a greater need for information to represent the data. Conversely, lower entropy indicates a more predictable or structured dataset, requiring less information for its representation. In mathematical representation, Entropy can be defined as a discrete random variable H(x), which takes items of certain classes i in a dataset and distributes them such that p : x \u2192 [0,1]. Here, in the following equation, the negative sign ensures that the overall entropy is a positive value or zero, implying that lower entropy corresponds to more ordered or certain datasets.\n$H(x) = - \\sum_i p(x_i) \\log_2(p(x_i))$ (11)\nIn our study, in MINIST and CIFAR-10 experiments i = 10 as there are 10 classes in both datasets and i = 100 for the CIFAR-100 dataset. In the IID setting, each device is randomly assigned a uniform distribution over the 10 classes. In the non-IID setting, the data is organized by class and partitioned, creating an extreme scenario of single-class non-IID, wherein each device exclusively receives data from a unique class. The data distribution is explained in Fig. 3 using data entropy in the Section V.\nFor both the non-IID and IID settings, we uphold a queue housing y = 0.1 training samples. These samples are randomly selected from this queue in each training iteration to cater to every device's learning process. Importantly, during this phase, the class assignments are randomized, introducing an additional layer of complexity to the data composition. Furthermore, we set y = 0.2 as an alternative setting setting. A deep analysis of the experimental results and the justifications for selecting effective hyper-parameters are stated in Table. III.\nAs illustrated in Algorithm 2 we introduce a novel data-sharing approach within the context of FL, as depicted in Fig. 2. We establish a centralized dataset denoted as GD, which is stored in a global data queue and comprises a uniform distribution spanning all available classes in datasets. For this experiment, we stored 10% data samples as GD and the rest of the 90% were distributed among the devices. This dataset resides in the server. At the onset of the initialization phase, the baseline model structure is shared with the participating entities. Starting from the second iteration onwards, each device k is allocated a segment of fresh data Dk. extracted from the global dataset GD.\nMoreover, Fig. 3b, illustrates the data entropy variation of each device in each training round in the proposed method. for example in the 20th device's data entropy will be changed from 0.1 to 0.48 during 100 epochs. It is an increment of 80% total increment for the data entropy.\nSubsequently, devices train their respective local models using the FedAvg. Throughout this training, devices' models are fine-tuned based on their assigned data subsets. In each training round, devices calculate the local update Fr(w) and data entropy H(Xk) calculated using Equation (11) and send it to the server.\n$F(w)* = \\sum_{k=1}^K \\frac{H(x_k)F(w)}{\\sum_{k=1}^K H(x_k)}$ (12)\nFor instance, we consider the nth synchronization round. Here, we have k number of local updates and compare their respective, H(Xk) and select \u039b amount of devices for aggregation. Furthermore, we conclude that this potion of devices has the highest quality data from all k devices in the nth round. Moreover, we ran out simulations for an extensive amount of rounds and decided the best y value is 0.9. In Section V we illustrate our test results and justify selecting this"}, {"title": "B. Entropy-based Aggregation", "content": "hyper-parameter. Then each device's updates will be scaled based on their data entropies using Equation (11).\nFinally, the global model will be averaged using the scaled device updates. This mechanism ensures fairness in FL when it comes to selecting devices that have low skewness in data.\nThe concluding step in this iterative process involves the server executing an aggregation mechanism, specifically designed according to the aggregation algorithm outlined in Algorithm 3. In this context, we focus on selecting the top \u039b fraction of devices with the highest entropy values during each training round and utilize their computed gradients for the aggregation process. For our experiments and evaluations, we set the baseline \u039b value to 0.9 and compared it with an alternative setting where \u039b was set to 0.8, as detailed in Section V. By consolidating the updates provided by each device, this aggregated knowledge is subsequently employed to enhance the overall performance of the global model.\nThe next section will illustrate our simulations and findings from the proposed framework."}, {"title": "C. Convergence Analysis", "content": "In this section, we perform fundamental convergence analysis for our proposed DDFL algorithm, the server selects the top \u039b fraction of devices which have higher data entropy for aggregation. We analyze the convergence performance of the proposed DDFL algorithm under non-IID data [7] with the dynamic device selection scheme. We first present the preliminaries and assumptions, and then the convergence result is obtained.\n1) Preliminaries: The optimal solution of the global loss function L(w) is defined in the Equation (6). So the minimum loss is L* = L(F(w)). Similarly, the minimum loss of k, Lk is denoted by $L_k = L_k(F(w))$. Then the local-global objective gap is defined as\n$\\Phi = L* - \\sum_{k=1}^K p_k L_k$ (13)\nwhere I is nonzero, quantifying the degree of non-IID data; its magnitude reflects the heterogeneity of the data distribution. Larger \u03a6 implies higher data heterogeneity over the K. If the data is IID and the number of samples is large then \u03a6 \u2192 0 [7].\n2) Assumptions: We make the following assumptions on the functions F1,\u2026\u2026, FN. Assumptions 1 and 2 are standard; typical examples are the l2-norm regularized linear regression, logistic regression, and softmax classifier.\nAssumption 1. F1,\u2026\u2026, FN are all L-smooth: for all v and w, Fk(v) \u2264 Fk(w) + (v\u2212 w)TVFk(w) + L/2||v - w||2.\nAssumption 2. F1,\u2026\u2026, FN are all \u00b5-strongly convex: for all v and w, Fk(v) \u2265 Fk(w) + (v\u2212 w)T\u2207Fk(w) + \u00b5/2||v - w||2. Assumptions 3 and 4 have been made by the works [31], [32].\nAssumption 3. Let gk be sampled from the k-th device's local data uniformly at random. The variance of stochastic gradients in each device is bounded: $E ||\u2207Fk (w, h) \u2013 \u2207Fk (wh) ||\u00b2 < \u03c3\u00b2 for k = 1,\u2026, N.\nAssumption 4. Suppose the samples on all the devices are homogeneous due to the dynamic environment assume that N\u2192\u221e. In that case, i.e., they are sampled in an IID fashion, then as H(Xk) \u2192 1, $p_k \\to \\frac{1}{K}$, it follows | \u03c3\u03ba,n |>| Ok,n+1 |.\nAssumption 5. Assume that that assumption 4 holds, it follows | \u03c3\u03af,\u03b7 \u2013 Oj,n |>| 0i,n+1 \u2212 0j,n+1 |, (i, j \u2282K).\nAssumption 6. The expected squared norm of stochastic gradients is uniformly bounded, i.e., E ||\u2207Fk (w, h) ||\u00b2 \u2264 G2 for all k = 1,\u2026, K and n = 0,\u2026\u2026, N-1\nHere we analyze the case in which the \u039bK device participates in the aggregation step. Let the FedAvg algorithm terminate after N iterations and return WN as the solution. We always require N to be evenly divisible by E so that FedAvg can output WN as expected.\nTheorem 1. Let Assumptions 1 to 6 hold and L, \u03bc, \u03c3\u03ba, G, \u0395 (Steps of the local Update) be defined therein. Choose \u03ba = 1, p = max{\u03b4\u03ba, E} and the learning rate $\u03b7n = \\frac{\u03ba}{\u03bc(\u03c1+\u03b7)}$. Then FedAvg with spatial device participation satisfies [33],\n$E [F (w_N)] - F* < \\frac{\u03c1 + \\frac{N-1}{2}}{N} (\\frac{2B}{\u03bc\u03c1} + \\frac{ME}{K} ||w_0-w*||^2)$\nWhere,\n$B = \\sum_{k=1}^K p (\u03c3^2 + 6kG^2) + 8(E \u2013 1)^2G^2 + E^2G^2$ (14)\nAssumption 7 Suppose the samples on all the devices are homogeneous and let Assumption 4 hold. In that case, i.e., they are sampled in an IID fashion, then as H(Xk), it follows $p_k \\to \\frac{1}{K}$, it follows that \u03a6 \u2192 0 for every w as all the local functions converge to the same expected risk function in the large sample limit.\nTheorem 2. DDFL requires $p_k = \\frac{H(X_k)}{\\sum_{1}^{K}H(X_i)}$;P1+\u2026\u2026+PK = 1 which does not violate the unbalanced nature of FL. Let Fk(w) ~ pkNFk(w) be a scaled local objective Fk. Let Assumption 7 hold, then the global objective becomes a simple average of all scaled local objectives:\nThen the global objective becomes a simple average of all scaled local objectives:\n$F(w) = \\sum_{k=1}^{AK} p_kF_k(W) \\sim \\sum_{k=1}^K \\frac{1}{K} F_k(w)$ (15)\nThe derived proofs of key assumption are shown in [33]. The above demonstration proves that DDFL aggregation is"}, {"title": "V. EXPERIMENTS AND EVALUATION", "content": null}, {"title": "A. Experimental Setup", "content": "The experiments were conducted on a high-performance computing setup, utilizing an NVIDIA RTX 6000 GPU with 48GB of VRAM, coupled with an Intel Core i9-10980 processor. This hardware configuration ensured efficient training and evaluation of our models, providing reliable and indicative results.\nIn the experimental setup, we utilized three distinct datasets, MNIST, CIFAR-10, and CIFAR-100 to evaluate the performance of our models. MNIST comprises 60,000 training images and 10,000 test samples, each depicting handwritten grayscale digits ranging from 0 to 9 in a 28x28 format. CIFAR-10 consists of 60,000 32x32 colour images distributed across 10 classes. In contrast, CIFAR-100 consists of 60,000 32x32 colour images, just like CIFAR-10, but is divided into 100 distinct classes. Each class contains 600 images, with 500 images for training and 100 images for testing. For MNIST, a Convolutional Neural Network (CNN) was employed, featuring two convolution layers with 32 and 64 kernels of size 3 \u00d7 3, followed by a max-pooling layer and two fully connected layers with 9216 and 128 neurons. Meanwhile, CIFAR-10 and CIFAR-100 involved a more intricate model architecture, specifically the ResNet-18, chosen to accommodate the complexity of the dataset with its 10 classes and 100 class cases. This experimental design allowed us to comprehensively assess the models' capabilities across varied image classification challenges."}, {"title": "B. Dynamic Data Distribution", "content": "In our proposed DDFL approach, we computed data entropy during the initial epoch for both non-IID and IID settings in this section, using the CIFAR-10, CIFAR-100 and MNIST datasets. Moreover, we calculated the dynamic data entropy for each device in each synchronization round. Equation (11) guided our computation of individual data entropies of each setting.\nAs anticipated, the entropy visualization in Fig. 3a validates the concept that the IID approach yields a data entropy of 1 for each device. This outcome results from the uniform distribution of classes among participating entities. Moreover, Fig. 3b confirms the expected data entropy of 0.1 for all devices in the non-IID setting. This is because each device has data from a single class, highlighting the absence of uniform data distribution.\nIn contrast, when employing dynamic data distribution, device data entropies evolve. Fig. 3b demonstrates that the data entropy of each device increases with the increasing of epochs, leading to improved data distribution uniformity. In training epoch 1, the data entropy of each device is 0.1, akin to the initial non-IID distribution. Then, it's evident that the data entropy significantly increases from the 1st training round to the 100th training round. Nonetheless, class imbalances persist within each local dataset as the data is distributed randomly.\nIn the DDFL approach, device selection is determined by data entropy. Notably, the data entropy for each device increases with each epoch. For example, as illustrated in Fig. 3b, during the 20th epoch, devices contributing to the aggregation are those with the highest data entropy. This mechanism serves to eliminate bias and unfairness in device selection within FL. This statement will be justified in the next section using the simulation results."}, {"title": "C. The detailed performance of the proposed framework", "content": "During simulations, we compared the proposed approach in the non-IID setting with the FedAvg [13", "12": "in the non-IID setting by considering them as unique SOTA methods.\nIn the non-IID setting, the data is organized based on their respective classes and then divided into an extreme scenario known as 1-class non-IID. In this extreme scenario, each device exclusively receives data from just one class. We investigate three approaches by adjusting the value of \u03b3 to 0.1 and 0.2, and \u03bb to 0.8, 0.9, and an extreme 0.5.\nAs depicted in Fig. 4, under the IID data sets, all three datasets exhibit high accuracies, and the model achieves convergence between 20-40 epochs. Conversely, in a dynamic non-IID setting, employing initial FedAvg and the warm-up model approaches reveals a notable decline in accuracy and sub-optimal model convergence. The accuracies for MNIST datasets range between 78% - 85%, for the CIFAR-10 dataset, they range between 63% 74%, and for the CIFAR-100 dataset, they range between 59% 70% under these approaches. However, a distinct improvement is evident with the implementation of the proposed DDFL approach. The accuracy increases by a minimum of 4% - 10% for MNIST, 6% 18% for CIFAR-10, and 18% - 20% for CIFAR-100 datasets. Moreover, the model demonstrates accelerated convergence, particularly notable between epochs"}]}