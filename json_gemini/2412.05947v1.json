{"title": "Materials-Discovery Workflows Guided by Symbolic Regression: Identifying Acid-Stable Oxides for Electrocatalysis", "authors": ["Akhil S. Nair", "Lucas Foppa", "Matthias Scheffler"], "abstract": "The efficiency of active learning (AL) approaches to identify materials with desired properties relies on the knowledge of a few parameters describing the property. However, these parameters are unknown if the property is governed by a high intricacy of many atomistic processes. Here, we develop an AL workflow based on the sure-independence screening and sparsifying operator (SISSO) symbolic-regression approach. SISSO identifies the few, key parameters correlated with a given materials property via analytical expressions, out of many offered primary features. Crucially, we train ensembles of SISSO models in order to quantify mean predictions and their uncertainty, enabling the use of SISSO in AL. By combining bootstrap sampling to obtain training datasets with Monte-Carlo feature dropout, the high prediction errors observed by a single SISSO model are improved. Besides, the feature dropout procedure alleviates the overconfidence issues observed in the widely used bagging approach. We demonstrate the SISSO-guided AL workflow by identifying acid-stable oxides for water splitting using high-quality DFT-HSE06 calculations. From a pool of 1470 materials, 12 acid-stable materials are identified in only 30 AL iterations. The materials-property maps provided by SISSO along with the uncertainty estimates reduce the risk of missing promising portions of the materials space that were overlooked in the initial, possibly biased dataset.", "sections": [{"title": "Introduction", "content": "The discovery of improved materials is critical for addressing global challenges such as the transition to renewable energies [1, 2]. However, the space of possible materials is practically infinite and the materials that exhibit desired properties are often very few. Thus, direct, high-throughput screening materials discovery is impractical. Artificial intelligence (AI) can accelerate materials discovery by identifying complex, nonlinear relationships between materials' parameters and certain properties of interest [3, 4]. In particular, AI can guide workflows that perform complex tasks such as the synthesis of materials or the evaluation of their properties [5, 6]. An Active-learning (AL) workflow, for instance, can cast materials discovery as an optimization problem [7]. In such AL frameworks, the AI model for the property of interest is retrained (updated) iteratively with more and more data acquired by the workflow. A data-acquisition strategy informed by the AI model is defined in order to identify the materials that present the desired behavior, e.g., presenting a materials-property value below or above a certain threshold, in an efficient manner. Here, efficiency means that the number of property evaluations is kept at a manageable level, for instance, by intelligently selecting the materials that should be studied. The acquisition strategy might not only target materials with desired behavior (exploitation), but it might also include data associated with high prediction uncertainty (exploration), assuming that regions of the materials space that were overlooked in the training data are associated with uncertain predictions [8, 9]. Despite their demonstrated success [10-12], the efficiency of AL workflows based on widely used machine-learning approaches often relies on the knowledge of a few input parameters or features, i.e., on a low-dimensional representation. This might be a drawback in materials science because the high intricacy of many atomistic processes governing certain materials properties or functions implies that the key parameters required to describe them are typically unknown.\nHere, we address this challenge by developing an AL workflow for materials discovery based on the sure-independence screening and sparsifying operator (SISSO) symbolic-regression approach [13-15]. SISSO identifies models for a given target property of interest in the form of analytical expressions. These expressions depend only on a few key physical parameters, out of many offered primary features. By constructing models with physical parameters, SISSO might better capture the relationship between materials' parameters and the property of interest across the materials space compared to interpolation schemes [16, 17]. Crucially, we construct ensembles of SISSO models to obtain their mean predictions and uncertainty estimates, which are used to steer data acquisition from the parts of the materials space that are not covered by the training data.\nThe SISSO-guided AL workflow is demonstrated for the computational discovery of acid-stable oxides for electrocatalytic water splitting, a key process for sustainable hydrogen production (Scheme 1). In particular, earth-abundant materials that withstand the harsh conditions of the oxygen evolution reaction (OER) are urgently required. However, accurately evaluating the thermodynamic stability of an oxide under electrochemical conditions (voltage and pH) requires the consideration of many competing phases that could co-exist in the Pourbaix diagram such as hydrides, hydroxides, elemental solids, etc. [18]. This severely limits the number of oxides that can be calculated using reliable methods such as hybrid density functional theory (DFT).\nHere, SISSO is used to intelligently select the materials that should be evaluated by high-quality DFT-HSE06 calculations. As a result, 12 acid-stable oxides are identified out of a space of 1470 oxides within only 30 iterations of the AL workflow. Many of these oxides have not been previously identified by widely used DFT calculations under the generalized gradient approximation (GGA)."}, {"title": "RESULTS", "content": "The SISSO analysis starts with the collection of its input parameters termed primary features. By iteratively applying mathematical operators such as addition, multiplication, etc. to these primary features and also to the previously generated expressions q times, SISSO generates ~10^8 analytical functions. Then, a few, D expressions, typically 2 or 3, components of a descriptor vector d_1,d_2,..d_D, are selected (see Methods for more details). These components, combined with weighting coefficients, are those that best correlate with the target property for the training dataset. q and D are hyperparameters of SISSO and are generally determined by resampling methods such as nested cross-validation (NCV).\nIn this work, the target property modeled by SISSO is the thermodynamic stability of oxide under acidic OER conditions: applied voltage of 1.23 V and pH=0, denoted $\\Delta G_{pbx}^{OER}$ hereafter. This quantity corresponds to the Pourbaix decomposition free energy and it is calculated with DFT using the Heyd-Scuseria-Ernzerhof (HSE06) exchange-correlation functional [19] as efficiently implemented in the FHI-aims code [20]. A low $\\Delta G_{pbx}^{OER}$ indicates high stability of the material. We stress that the stability under operation is an overlooked yet crucial criterion for the design of OER catalysts [21, 22] in addition to surface reactivity [23, 24]. The significant improvements of DFT-HSE06 with respect to DFT-GGA for the description of oxide formation energy and $\\Delta G_{pbx}^{OER}$ are discussed in detail in Supplementary sections I-III. In order to model $\\Delta G_{pbx}^{OER}$ with SISSO, 14 primary features are offered (Table S2). These are elemental and compositional properties of free-atoms and the oxide, respectively such as orbital radii and oxidation state distribution. A training dataset containing 250 oxides was created by computing $\\Delta G_{pbx}^{OER}$ for these materials. Among these, the well-known water splitting catalysts are found, such as IrO_2 ($\\Delta G_{pbx}^{OER}$= -0.62 eV/atom) and RuO_2 ($\\Delta G_{pbx}^{OER}$=-0.26 eV/atom). The $\\Delta G_{pbx}^{OER}$ distribution over these 250 materials has a mean value of 0.61 eV/atom (Figure S8).\nThree strategies are investigated for constructing ensembles of SISSO models: bagging, model complexity bagging, and bagging with Monte-Carlo dropout of primary features (Figure 1a). All three begin by generating k distinct training sets from the original dataset through randomly sampling data subsets with replacement (boot-strapping). This is followed by aggregating the predictions from SISSO models trained on these subsets. In the bagging approach, a SISSO model is trained on each of these k bootstrapped datasets. Model complexity bagging is a modification of the bagging approach involving training two models for each training set: one with D = 1 and another with D=2. This results in 2k models in the ensemble. For bagging with Monte-Carlo dropout of primary features, each model is trained using a subset (here 20%) of primary features, created by Monte Carlo dropout from the bootstrapped subsets. Different k values are analyzed and k = 10 is selected based on the convergence of prediction errors and uncertainty estimates (see Figure S11). For all the ensemble methods, an optimal model complexity (q=2, D=2) identified by NCV (see Supplementary Section IV) is used unless otherwise mentioned (as in model complexity bagging). We define $\\Delta G_{pbx, ESISSO}^{OE}$ as the mean prediction of a given ensemble. The standard deviation of the predictions of the different SISSO models ($\\sigma_{E}^{SISSO}$) serves as an estimate of the prediction uncertainty. Note that the uncertainty quantification by the ensemble does not necessarily reflect the uncertainty related to lack of data [25, 26].\nWe apply these three ensemble approaches to a training set of 200 materials, randomly drawn from the dataset of 250 materials. The performance of different ensemble approaches is compared using two metrics which are the absolute prediction errors (e) and the miscalibration scores (z) [27]. \u03b5 is evaluated as the difference in predicted and DFT calculated $\\Delta G_{pbx}^{OER}$ values. z measures how calibrated the uncertainty estimates are [28]. z = 1 indicates well calibrated uncertainty estimates, while z > 1 suggests overconfidence, and z < 1 signifies underconfident predictions. The \u03b5 and z values are evaluated for the 50 materials of the dataset that were not used for training. To evaluate the performance of the ensemble approaches, we also consider a single SISSO model obtained by training on the same 200 data points used to train the ensembles but without bootstrapping.\nThe distributions of \u03b5 and z are shown in Figure 1b for the three different ensemble approaches. The single SISSO model achieves a mean absolute error (MAE) of 0.34 eV/atom. In comparison, the bagging approach shows a reduced MAE of 0.29 eV/atom. Both model complexity bagging and bagging with Monte Carlo dropout of primary features further reduce the MAE to 0.29 and 0.26 eV/atom, respectively. The 90%-iles of the \u03b5 distributions for the three ensemble approaches (0.85, 0.37, and 0.35 eV/atom) also demonstrate improvement compared to a single SISSO model.\nThe analysis of z shows a relatively more distinct performance across the three approaches. The bagging method exhibits significantly high z-values, with a mean of 2.76, indicating overconfident predictions. This issue is moderately addressed by the model complexity bagging approach, which lowers the mean z-value to 2.36. Bagging with Monte Carlo dropout of primary features achieves the most balanced uncertainty estimates, with a mean z-value of 1.76, marking a clear improvement over the other methods. A similar trend is observed in the 90%-iles of the z-value distributions (5.62, 3.23, 2.44), further highlighting the superior performance of the Monte Carlo dropout method. Based on these findings, bagging with Monte Carlo dropout of primary features is identified as the most effective ensemble approach among the considered ones for uncertainty estimation in SISSO models. Consequently, this approach is adopted in the AL workflow discussed in the next section.\nThe dataset containing 250 oxides, is employed as the initial dataset for AL. A SISSO model trained on this dataset has an RMSE of 0.38 eV/atom and R^2=0.87. The candidate space, i.e., the set of new materials that could be queried during AL, consists of 1470 oxides (see Supplementary section V). The majority of materials in the candidate space are ternary oxides. We note that ternary oxides are less considered by DFT-HSE06 studies compared to binary oxides due to their typically larger unit-cell sizes, which makes the calculations expensive [29, 30]. These 1470 materials together with the competing phases needed to evaluate the $\\Delta G_{pbx}^{OER}$ correspond to a total number of ~ 12 thousand materials.\nOur goal is to identify acid-stable oxides, i.e., materials with very small $\\Delta G_{pbx}^{OER}$. To achieve this goal, we consider the probability of feasibility (POF) as the data-acquisition strategy. POF quantifies the probability that an oxide is acid-stable. It is defined as;\n$POF = P(\\Delta G_{pbx}^{OER} < \\tau) = F (\\frac{\\tau - \\Delta G_{pbx, ESISSO}}{\\sigma_{E}^{SISSO}})$                                                                                                                               (1)\nwhere P is the probability that $\\Delta G_{pbx}^{OER}$ is less than $\\tau$=0.00 and F is the cumulative distribution function of the standard normal distribution. POF is informed by both mean predictions ($\\Delta G_{pbx, ESISSO}$) and the standard deviations of the predictions ($\\sigma_{E}^{SISSO}$), both obtained by the bagging with Monte-Carlo dropout of primary features ensemble approach. In each AL iteration, we train ensembles of SISSO models (vide supra). The material associated with the highest POF value is selected and the corresponding $\\Delta G_{pbx}^{OER}$ is calculated. This is followed by ranking the candidate materials based on the values of the POF. We also consider random selection (RS) as a baseline data-acquisition strategy that selects material from the candidate space randomly. The selected material is moved from the candidate space to the training dataset, and the process is repeated.\nThe results of the SISSO-based AL campaigns are shown in Figure 2 for 30 iterations. Materials selected and evaluated based on RS and POF are displayed in grey and red colors, respectively. We use a stability threshold of $\\Delta G_{pbx}^{OER}$ <0.1 eV/atom to label an oxide as acid-stable as materials with small positive $\\Delta G_{pbx}^{OER}$ can retain their stability under acidic conditions due to self-passivation and formation of more stable phases [31-33]. Previous high-throughput studies have used higher stability thresholds (e.g., 0.2 [34] or 0.5 [35] eV/atom), but we adopt a more conservative criterion as we use higher-accuracy HSE06 functional. In Figure 2a, the filled square markers correspond to $\\Delta G_{pbx}^{OER}$ values obtained by DFT-HSE06 calculations. The open square markers show $\\Delta G_{pbx, ESISSO}^{OER}$ and the error bars reflect $\\sigma_{E}^{SISSO}$. Oxides selected by RS have $\\Delta G_{pbx}^{OER}$ in the range [0.04, 1.04] eV/atom and only two of them are acid-stable. This indicates that $\\Delta G_{pbx}^{OER}$ for the materials in the candidate space are concentrated in a rather narrow range with $\\Delta G_{pbx}^{OER}$ \u2265 0.1 eV/atom, corresponding to unstable materials. The situation is similar to the training dataset (Figure S8). However, in contrast with a random search, materials suggested by POF have $\\Delta G_{pbx}^{OER}$ in the range [-0.04, 0.82] eV/atom. This shows that by using the mean predictions and uncertainty estimates from SISSO ensembles, we are able to identify the stable materials in the candidate space much more efficiently than a random selection. An overall reduction in uncertainty estimates is visible with the error bars becoming narrower as the iterations progress. While overconfidence is occasionally observed (e.g., iterations 10,22,26), the error bars generally capture the true values, highlighting the reliability of the uncertainty estimates. Within 30 iterations, 12 acid-stable materials are successfully identified (Figure 2b). The number of iterations can be extended to identify more acid-stable materials.\nThe descriptors identified by SISSO can be used to construct materials-property maps. In Figure 3, we show such a map for the property $\\Delta G_{pbx, ESISSO}^{OER}$ constructed based on the initial training set of 250 materials. In this map, we plot the materials in this training set and in the candidate space as black and white circles, respectively. We also show the oxides selected via AL using POF and RS as red and grey circles, respectively. The filled and hollow red and grey circles indicate materials that turned out to be stable and unstable according to the DFT-HSE06 calculations, respectively. Only a small fraction of the 250 oxides in the initial training data are acid-stable, which is well captured by the SISSO model. The oxides chosen by RS predominantly fall within high-$\\Delta G_{pbx, ESISSO}^{OER}$ regions of the descriptor space. In contrast, many oxides selected by POF are concentrated in the low-$\\Delta G_{pbx, ESISSO}^{OER}$ region predicted by the SISSO model. This indicates that this initial SISSO model trained on 250 oxides is valid for most of the discovered materials. However, the oxides Ni(PtO2)3, Co(PtO2)3, identified to be acid-stable by POF, were incorrectly predicted to be unstable by the initial SISSO model. This reflects that the performance of the SISSO model for the stable materials of interest is improved by using the ensemble approach and also by the inclusion of more training data suggested by the AL workflow. The Pourbaix diagrams of all the oxides identified by AL as acid-stable are given in Figure S12.\nSome of the materials identified from the AL approach were also observed in previous high-throughput screening studies based on DFT-PBE(+U) [33, 35] such as MoWO6 and Fe2(MOO4)3. Overall, the presence of elements such as Mo, Ta, W are observed to favour acid-stability. We compare the stability of the oxides suggested by our AL framework as described by HSE06 and PBE in Table I. Five out of these twelve oxides are predicted to be acid-unstable based on PBE. For instance, NiMoO4 has $\\Delta G_{pbx}^{OERPBE}$ =0.27 eV/atom whereas $\\Delta G_{pbx}^{OERHSE06}$ =-0.04 eV/atom. This underscores the importance of combining an AI-driven approach with high-quality data for an accurate yet efficient screening of the vast materials space.\nHigh-quality materials data is often scarce and expensive to obtain, posing significant challenges to the application of AI in materials discovery. AL frameworks mitigate this limitation by guiding models toward unexplored, high-potential regions of the materials space. The approach presented here addresses key limitations of interpolation-based AI methods commonly used in AL workflows by eliminating reliance on pre-assumed representations, incorporating explainability, and enabling effective mapping of the target materials space. This advancement holds promise for expanding the application of symbolic regression methods in closed-loop materials discovery workflows. While challenges remain, such as the computational expense of generating large candidate feature spaces, recent developments, including GPU-accelerated SISSO++ implementations [15], can partially address these issues. Furthermore, exploring additional uncertainty quantification techniques, such as mathematical operator-based or distance-based approaches, could further alleviate overconfidence concerns. Overall, this work constitutes a step forward in the design of efficient AL-based workflows for AI-driven materials discovery."}, {"title": "METHODS", "content": "All-electron DFT calculations were performed with the FHI-aims (version 230629) electronic structure package with numeric atom-centered-orbital basis sets [36]. The standard \"light\" basis sets are used with zero-order regular approximation to account for the relativistic effects. A k-grid density of 5 \u00c5^(-1) is applied to divide an evenly split k-points grid along the reciprocal lattice vectors. A tight self-consistency cycle convergence criteria of 10^(-5) e\u00c5^(3) for charge density, 10^(-6) eV for total energy and 10^(-3) eV for sum of eigenvalues is used. For geometry relaxations, forces are converged within 10^(-2) eV/\u00c5.\nA computational workflow is devised to execute various tasks within the AL framework. The Atomic Simulation Recipes (ASR) [37] framework is used with an interface to FHI-aims. In this framework, DFT calculations are categorized as dependent or independent tasks. Then, these tasks are distributed across multiple batches. The submission of a large number of tasks is handled by workers from a MyQueue front-end deployed on a SLURM-based high-performance computing system [38]. The workflow provenance is stored in a registry and monitored for error handling. At each iteration of AL, one oxide from the candidate space is selected by the (AI-model-informed) acquisition strategy. The workflow initiates a sequence of actions, including the selection of competing phases, the preparation of input files (geometry optimization at PBE level and self-consistent-field energy evaluation at the HSE06 level), the collection of thermodynamic data, and the construction of Pourbaix diagrams. The input and output files of the calculations as well as the data associated with each iteration of AL (SISSO models, acquisition scores, and selected material) are recorded. Finally, the workflow closes the loop by updating the initial database with all newly acquired data.\nSure-Independence-Screening and Sparsifying Operator (SISSO) is a symbolic regression method to identify descriptors governing material properties or functions [13]. Given a set of primary features (\u03c6_1, \u03c6_2, ... , \u03c6_n \u2208 \u03a6) and a set of unary and binary mathematical operators (\u03c9_1, \u03c9_2, ... , \u03c9_m \u2208 \u03a9), SISSO generates descriptors by iteratively applying the operators over the primary features up to the assigned rung value (q). A subspace of the constructed feature space (P_N) is selected by sure-independence screening (SIS), where descriptors are ranked by projection score on the target property. The N_SIS descriptors with the highest projection scores to the target property are used to create the best one-dimensional (1D) model. A second round of SIS is applied where the target property is now replaced by N_res residuals of the 1D model, followed by an l_0-regularized optimization to generate the best two-dimensional (2D) model. This process is repeated D times to generate the best D-dimensional SISSO model. In this work, the following set of mathematical operations are considered;\n\u03a9 = {\u03c6_1 + \u03c6_2, \u03c6_1 - \u03c6_2, |\u03c6_1 - \u03c6_2|, exp(\u03c6_1), exp(-\u03c6_2), [\u03c6_1], \u03c6_1 * \u03c6_2, \u03c6_1/\u03c6_2, \u221a\u03c6_1, ln(\u03c6_1), \u03c6_1^(q), \u03c6_1^(\u221a2), \u03c6_1^(-1), \u03c6_1^(-q) \u03c6_1^(\u221a(\u03c6_1)), \u03c6_1^(2)}                                                                                                                               (2)\nThe electronic structure data can be accessed at the NOMAD archive at https://nomad-lab.eu/prod/v1/gui/user/datasets/dataset/id/ONOmTt4eRr67PE3h9K61_Q\nThe electronic structure package FHI-aims is freely available for academic use with a voluntary donation. SISSO++ [39] is used for all the SISSO analysis. The source code of the active learning workflow along with all the processed data and supporting scripts are available at Gitlab repository https://gitlab.com/akhilsnair/workflow_sisso. A tutorial demonstrating the approach is provided at https://gitlab.com/FHI-aims-club/tutorials/tutorial-al-sisso."}]}