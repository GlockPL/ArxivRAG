{"title": "REASONING LIMITATIONS OF MULTIMODAL LARGE LANGUAGE MODELS. A CASE STUDY OF BONGARD PROBLEMS", "authors": ["Miko\u0142aj Ma\u0142ki\u0144ski", "Szymon Pawlonka", "Jacek Ma\u0144dziuk"], "abstract": "Abstract visual reasoning (AVR) encompasses a suite of tasks whose solving requires the ability to discover common concepts underlying the set of pictures through an analogy-making process, similarly to human IQ tests. Bongard Problems (BPs), proposed in 1968, constitute a fundamental challenge in this domain mainly due to their requirement to combine visual reasoning and verbal description. This work poses a question whether multimodal large language models (MLLMs) inherently designed to combine vision and language are capable of tackling BPs. To this end, we propose a set of diverse MLLM-suited strategies to tackle BPs and examine four popular proprietary MLLMs: GPT-40, GPT-4 Turbo, Gemini 1.5 Pro, and Claude 3.5 Sonnet, and four open models: InternVL2-8B, LLaVa-1.6 Mistral-7B, Phi-3.5-Vision, and Pixtral 12B. The above MLLMs are compared on three BP datasets: a set of original BP instances relying on synthetic, geometry-based images and two recent datasets based on real-world images, i.e., Bongard-HOI and Bongard-OpenWorld. The experiments reveal significant limitations of MLLMs in solving BPs. In particular, the models struggle to solve the classical set of synthetic BPs, despite their visual simplicity. Though their performance ameliorates on real-world concepts expressed in Bongard-HOI and Bongard-OpenWorld, the models still have difficulty in utilizing new information to improve their predictions, as well as utilizing a dialog context window effectively. To capture the reasons of performance discrepancy between synthetic and real-world AVR domains, we propose Bongard-RWR, a new BP dataset consisting of real-world images that translates concepts from hand-crafted synthetic BPs to real-world concepts. The MLLMs' results on Bongard-RWR suggest that their poor performance on classical BPs is not due to domain specificity but rather reflects their general AVR limitations.", "sections": [{"title": "1 INTRODUCTION", "content": "Analogy-making is a critical aspect of human cognition, tightly linked with fluid intelligence, the capacity to apply learned skills in novel settings (Lake et al., 2017). Several approaches have been proposed to build systems capable of making analogies. Notably, the structure-mapping theory explores methods for discovering structural correspondences between pre-existing object representations (Winston, 1982; Gentner, 1983; Carbonell, 1983; Falkenhainer et al., 1989; Holyoak & Thagard, 1989). However, these approaches often overlook the perceptual aspect, assuming object representations are already given. Chalmers et al. (1992) highlight that forming useful representations is an intricate challenge. In particular, perception is not merely a passive reception of sensory data, but rather an active interpretation influenced by prior knowledge. This process involves the detection of patterns, recognition of analogies, and abstraction of concepts. The resultant representations may vary significantly depending on the context, which underscores the importance of modeling perception and cognition jointly (Hofstadter, 1995)."}, {"title": "2 RELATED WORK", "content": "AVR tasks. The AVR field encompasses a broad set of problems aimed at studying various aspects of visual cognition (Gardner & Richards, 2006; Ma\u0142ki\u0144ski & Ma\u0144dziuk, 2023). Recent DL research in this domain gravitated towards utilizing certain well-established datasets, e.g. with visual analogies (Hill et al., 2019; Webb et al., 2020) or RPMs (Zhang et al., 2019; Barrett et al., 2018), to measure the progress of DL models. However, such benchmarks evaluate system performance in learning a particular task, rather than assessing its general ability to acquire new AVR skills. To address this limitation, certain tasks have adopted few-shot learning setups, requiring models to learn from a few demonstrations, as exemplified by SVRT (Fleuret et al., 2011) or Bongard-LOGO (Nie et al., 2020). Nonetheless, these benchmarks follow a discriminative setting where a set of possible answers is provided. Conversely, other datasets such as ARC (Chollet, 2019) or PQA (Qi et al., 2021) pose a generative challenge, which may be considered more difficult due to its open-ended nature. In addition to synthetic tasks featuring 2D geometric shapes, certain datasets present analogous reasoning tasks using real-world images (Teney et al., 2020; Ichien et al., 2021; Bitton et al., 2023). This approach extends the range of concepts that can be expressed and, above all, allows employing models pre-trained on large image datasets. In this work, we concentrate on several BP datasets that present a few-shot learning challenge, cover both synthetic and real-world images, and consider settings involving both binary classification and answer generation in natural language.\nApproaches to solve BPs. Initial approaches to tackle BPs involved cognitive architectures (Foundalis, 2006a), program synthesis coupled with inductive logic programming (Saito &"}, {"title": "3 SOLVING BPS WITH MLLMS", "content": "In this paper, we propose a set of novel strategies for solving BPs using MLLMs. Definition of each strategy includes the input on which the model operates and the sequence of reasoning steps performed by the model. A high-level overview of these methods is provided in Fig. 2. In the main tested setting, we follow the initial BP formulation that requires providing an answer in natural language, and propose a model-based approach to automatically evaluate such model predictions. In addition, we consider simpler formulations of the problem, casting it into a binary classification framework that enables detailed evaluation of AVR abilities of the tested MLLMs. An illustration of these evaluation settings is presented in Fig. 3. In what follows, let $BP^X = {C^X, R^X, y^X}$ denote a BP instance (\u03a7\u2208 N is an index), composed of $L^X = {L^X_1,..., L^X_6}$ left and $R^X = {R^X_1,..., R^X_6}$ right panels, resp., and its concept $y^X$ expressed in natural language.\n3.1 PROMPTING STRATEGIES FOR NATURAL LANGUAGE ANSWER GENERATION\nWe start by defining the strategies for generating answers in natural language. In each strategy, the model receives a general description of Bongard Problem with two BP examples with correct answers. Additionally, besides this generic introductory information, a given task $BP^X$ to be solved is presented in a strategy-specific way. Appendix A.4 presents the exact prompt formulations.\nDirect (Fig. 2a). The model receives an image presenting $BP^X$ and is asked to directly formulate an answer (i.e., describe the difference between $L^X$ and $R^X$ panels in natural language).\nDescriptive (Fig. 2b). Defines a more granular approach in which the model is first requested to generate a textual description of each image panel of the matrix. Each description is generated in a separate context, such that the model doesn't have access to the prior panels nor to their descriptions. Next, the model is requested to provide an answer to the problem based only on the generated textual descriptions of all image panels.\nDescriptive-iterative (Fig. 2c). Evaluates the role of the reasoning context and utilizes a context window comprising the dialog history concerning all images in the given side of the problem. After generating the description of the first image, the model iteratively refines its output based on subsequent images from the same side. Based on the textual descriptions of both sides of the problem, the model is requested to provide the final answer.\nDescriptive-direct (Fig. 2b with a dashed element). In both above Descriptive strategies, the model is never presented with the image of the whole matrix $BP^X$. Descriptive-direct strategy extends Descriptive by providing the image of $BP^X$ along with the textual panel descriptions.\nContrastive (Fig. 2d). A critical aspect of BPs is the focus on forming concepts within the specific context of the matrix $BP^X$. It's often the case that correct identification of the concept governing one side requires analysis of the other side to identify their key differences. In Descriptive strategies, the model provides image descriptions concerning a single problem side $L^X$ or $R^X$ without taking into account the images from the other side. Conversely, in the Contrastive strategy, the model is tasked with describing the difference between a pair of corresponding images from both sides of the problem $(L^X_1, R^X_1),..., (L^X_6, R^X_6)$. After describing the differences between all six image pairs in separate contexts, the model generates its final answer based on these textual descriptions.\nContrastive-iterative (Fig. 2e). Extends Contrastive by performing all reasoning steps in a single context window, enabling the model to gradually improve its understanding of the rule separating both sides.\nContrastive-direct (Fig. 2d with a dashed element). Extends Contrastive by including the image of the whole matrix together with textual descriptions of differences within each panel pair.\n3.2 EVALUATION OF SOLUTIONS EXPRESSED IN NATURAL LANGUAGE\nThe correct answer to a BP may be formulated in natural language in many different ways. To account for this inherent variability, we utilize a model-based approach to assess whether the generated answer \u0177 matches the ground-truth y. In the proposed setting, an MLLM ensemble receives both \u0177 and y and is requested to output a binary yes/no answer whether both descriptions refer to the"}, {"title": "4 BONGARD-RWR: SYNTHETIC BPS EXPRESSED IN REAL-WORLD IMAGES", "content": "One of the interesting research avenues is to compare the MLLMs performance on synthetic BPs vs. real-world ones. Note, however, that a direct performance comparison on synthetic Bongard dataset vs. real-world Bongard HOI and Bongard-OpenWorld datasets is not meaningful, as these datasets depict different concepts. To enable a meaningful comparison and additionally determine whether the MLLMs performance score is domain-related, we introduce Bongard Real-World Representations, a focused dataset that expresses concepts present in synthetic BPs using real-world images, thus creating their real-life equivalents, as illustrated in Fig. 1b. Appendix C contains additional examples. The dataset is available at: https://github.com/pavonism/bongard-rwr.\n4.1 BONGARD-RWR DATASET GENERATION\nFor a given instance $BP^X$, we first use GPT-4o to describe its underlying concept $y^X$ in N = 10 different ways using the prompt listed in Prompt 1. We obtain N real-world textual descriptions $D^X = {D^XL, D^XR}, i = 0, . . ., N \u2013 1$, of each side $S \u2208 {L, R}$. Then, we use image search engine Pexels API (Pexels, 2024) to download M = 15 images per each described side $D^XS$. We employ GPT-40 (see Prompt 2 in Appendix A.1) to select only those images that properly illustrate the concept of the respective side and are indeed distinguishable from the alternative concept. We"}, {"title": "5 EXPERIMENTS", "content": "To evaluate the AVR capabilities of MLLMs, we conduct experiments in two main settings, involving 3 binary classification setups and 7 proposed generation methods. Our evaluation spans a range of MLLMs, including 4 proprietary models accessible via API: GPT-40, GPT-4 Turbo (Achiam et al., 2023), Gemini 1.5 Pro (Reid et al., 2024), and Claude 3.5 Sonnet (Anthropic, 2024), alongside 4 open-access models run locally on an NVIDIA DGX A100 node: InternVL2-8B (Chen et al., 2024b;a), LLaVa-1.6 Mistral-7B (Liu et al., 2024b;a; Jiang et al., 2023), Phi-3.5-Vision (Abdin et al., 2024), and Pixtral 12B (MistralAI, 2024). We consider four BP datasets covering both synthetic and real-world images. Specifically, we use the first 100 manually constructed (synthetic) BPs from (Bongard, 1970), 100 problem samples from Bongard HOI and Bongard-OpenWorld, and all 60 instances from Bongard-RWR. Table 1 presents the results.\nBinary classification (Ground-truth). We first assess whether MLLMs can determine if a given concept matches a problem instance. On synthetic BPs, 3 proprietary (GPT-40, Gemini 1.5 Pro, Claude 3.5 Sonnet) and 2 open-access (LLaVa-1.6 Mistral-7B, Pixtral 12B) models outperform a random classifier by a notable margin. On Bongard HOI, 3 proprietary (GPT-40, GPT-4 Turbo, Gemini 1.5 Pro) and the same 2 open-access models also surpass random guessing. Notably, Pix-"}, {"title": "6 CONCLUSIONS", "content": "In this paper, we investigate the reasoning capabilities of proprietary and open-access MLLMs using BPs as a case study. Despite rapid progress, MLLMs still exhibit significant reasoning limitations. Across all proposed answer generation strategies, the best-performing model managed to solve only 22 out of 100 synthetic BPs. Performance moderately improves when dealing with real-world concepts, as demonstrate the results on the Bongard HOI and Bongard-OpenWorld datasets. However, the models still struggle to leverage additional multimodal data and effectively utilize the dialog context window. To delve deeper into the performance discrepancies between synthetic and real-world domains, we introduced Bongard-RWR, a new BP dataset designed to represent concepts from synthetic BPs via real-world images. Focused experiments with this dataset suggest that the models' weak performance on synthetic BPs is not domain-specific but rather indicative of broader limitations in their reasoning abilities. On a positive note, experiments conducted in three binary classification settings show that some models achieve encouraging results, suggesting that current limitations may be overcome with future advancements."}, {"title": "A MLLM PROMPTS", "content": "A.1 PROMPTS FOR BONGARD-RWR GENERATION\nPrompt 2 was used to select those images that correctly represent given concept translation. In addition to the left and right concepts, we also provided prompts briefly explaining the context that the image should match. These prompts were generated during the translation stage of our algorithm (see the fourth line in Algorithm 1).\nPrompt 2: Prompt used for the selection of proper images for a translated concept.\nPrompt 3: Prompt explaining Bongard problems to an MLLM.\nA Bongard Problem is composed of left and right sides separated by a line. Each side contains six images. All images belonging to one side present a common concept, which is lacking in all images from the other side. The goal is to describe the rule that fits all images on the left side, but none on the right, and, conversely, the rule that fits all images on the right side, but none on the left. The description of the rule should be simple and concise. Example 1: All shapes on left are small. All shapes on right are big. Example 2: The left side contains circles. The right side contains triangles.\nA.3 PROMPTS FOR CLASSIFICATION STRATEGIES\nPrompt 5 was used to assess solution correctness (see Section 3.2). Prompt 4 was used to assign images to sides (see Section 3.3)."}, {"title": "B EVALUATION OF MLLMS ANSWERS", "content": "Preliminary experiments revealed that proprietary MLLMs are generally much more effective in solving Bongard Problems than open, publicly-available MLLMs. Therefore, all efforts devoted to optimizing the final scores, in particular tuning the evaluation prompt were performed using these 4 commercial MLLMs.\nOpen-ended characteristics of BPs stemming from a textual form of an answer, and the number of considered models (8), generation strategies (7), datasets (4), and BP instances per dataset (60 in Bongard-RWR and 100 in the remaining cases) require the use of an automated NLP-based evaluation of the model's answers. For this task we employed MLLMs with a specially designed prompt. The initial version of the evaluation prompt (see Prompt 14) was intentionally relatively simple a model received an answer to be evaluated as well as the ground-truth labels, and was requested to output a binary yes/no answer. This prompt formulation turned out to be too simplistic. While the level of agreement between all models was relatively high (87% of responses were rated unani-"}, {"title": "C BONGARD-RWR DATASET", "content": "Bongard-RWR dataset developed in this work is attached in the technical appendix and will also be released for the reserach community under the MIT license. The dataset generation algorithm is presented in Algorithm 1 using notation introduced in Section 4.1."}, {"title": "E COMPARISON OF SYNTHETIC BONGARD VS. BONGARD-RWR RESULTS", "content": "Our research shows that all of the tested models have difficulty solving synthetic concepts when applied to real-world images. Comparing the results for both datasets (see Figures 10 and 16) we identified some discrepancies. Four problems that remained unsolved in the synthetic BPs were successfully solved in the real-world domain of the Bongard-RWR dataset: #56, #7, #88, and #98. However, three of these problems differ slightly from their synthetic counterparts. The images in #56 from Bongard-RWR feature a variety of colors instead of the usual black-and-white figures. Furthermore, in real-world version of problem #87 more images feature disjoint elements instead of"}]}