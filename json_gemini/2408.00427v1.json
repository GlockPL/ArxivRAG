{"title": "CARMIL: Context-Aware Regularization on Multiple Instance Learning models for Whole Slide Images", "authors": ["Thiziri Nait Saada", "Valentina Di-Proietto", "Benoit Schmauch", "Katharina Von Loga", "Lucas Fidont"], "abstract": "Multiple Instance Learning (MIL) models have proven effective for cancer prognosis from\nWhole Slide Images. However, the original MIL formulation incorrectly assumes the patches\nof the same image to be independent, leading to a loss of spatial context as information flows\nthrough the network. Incorporating contextual knowledge into predictions is particularly\nimportant given the inclination for cancerous cells to form clusters and the presence of\nspatial indicators for tumors. State-of-the-art methods often use attention mechanisms\neventually combined with graphs to capture spatial knowledge. In this paper, we take a\nnovel and transversal approach, addressing this issue through the lens of regularization.\nWe propose Context-Aware Regularization for Multiple Instance Learning (CARMIL), a\nversatile regularization scheme designed to seamlessly integrate spatial knowledge into any\nMIL model. Additionally, we present a new and generic metric to quantify the Context-\nAwareness of any MIL model when applied to Whole Slide Images, resolving a previously\nunexplored gap in the field. The efficacy of our framework is evaluated for two survival\nanalysis tasks on glioblastoma (TCGA GBM) and colon cancer data (TCGA COAD).", "sections": [{"title": "1 Introduction", "content": "The digitization of histopathology Whole Slide Images (WSIs) and the development of deep\nlearning methods has lead to promising computational methods for cancer prognosis. One\ncomputational challenge is the large size of WSIs, of the order of 100,000 \u00d7 100,000 pixels.\nProcessing images of such size with a deep neural network directly is not possible with the\nGPUs commonly available. Overcoming this problem, previous work proposes to tessellate\neach WSI into thousands of smaller images called tiles and global survival prediction per\nslide is obtained in two steps. The tiles are first embedded into a space of lower dimension\nusing a pre-trained feature extractor model, and a MIL model is trained to predict survival\nfrom the set of tiles embeddings of a WSI (Herrera et al., 2016).\nOne limitation of MIL is the assumption that tiles from the same WSI are independent\n(Ilse et al., 2018). In particular, MIL models fail to leverage spatial interactions between\ntiles and their ordering in a WSI. In contrast, pathologists take into account the spatial"}, {"title": "2 Methods", "content": "2.1 Background: classical MIL framework for risk prediction\nIn this section, we summarize the main steps of the classical MIL pipeline, that we enhance\nwith our Context-Aware Regularization in the next section.\nPreprocessing. Each WSI is segmented to keep only the tissue and remove the back-\nground (e.g. using the otsu method). The tissue parts are then tessellated into tiles of size\n224 \u00d7 224 pixels taken at 20X magnitude (0.5\u00b5m/pixel) and each WSI is reduced to a set"}, {"title": "2.2 Context-Aware Regularization (CAR)", "content": "We propose a general approach to leverage local spatial context in computational histopathol-\nogy. Our pipeline, which can be applied to any task or MIL model, is depicted in fig. 1.\nGraph construction. For each WSI, we build a graph $G^{(i)} = (X^{(i)}, A^{(i)})$ where the\nvertices are the tiles features $X^{(i)} \u2208 R^{n\u00d7d}$, as described in the previous section, and $A^{(i)} \u2208\nR^{n\u00d7n}$ is the adjacency matrix computed based on the euclidean distance between the spatial\ncoordinates of the tiles in the original WSI for a given number k of nearest neighbors.\nContext-Aware Regularization. To embed the spatial structure of the WSI into the\ntiles features, we introduce a spatial encoder $f_E$ of parameters $\u03b8_E$ and a spatial decoder $f_D$"}, {"title": null, "content": "$f_E: R^{n\u00d7d} \u00d7 R^{n\u00d7n} \u2192 R^{n\u00d7d_e}$\n$(X, A) \u2192 Z,$\n$f_D:R^{n\u00d7d_e} \u2192 R^{n\u00d7n}$\n$ZHA.$\n(3)\nHere, the goal of $f_E$ is to distill the spatial information contained in an input WSI\ngraph $G = (X, A)$ into tiles features X, resulting in a new low-dimensional Context-Aware\nembedding $Z \u2208 R^{n\u00d7d_e}$ of the WSI. To achieve this goal, $f_D$ aims at reconstructing the input\nadjacency matrix A from Z during training while, concurrently, $f_{MIL}$ aims at predicting the\npatient risk from Z. Formally, this corresponds to adding a Context-Aware Regularization\nterm $LCAR$ to the training optimization problem of classical MIL (2):\n$\\min_{\\theta_{MIL}, \\theta_E, \\theta_D} \\frac{1}{N} \\sum_{i=1}^N ((1-\\beta) L_{MIL} (f_{MIL}(Z^{(i)}; \\theta_{MIL}), y^{(i)}) + \\beta L_{CAR} (f_D(Z^{(i)}; \\theta_D), A^{(i)}))$ (4)\nwhere the same notations as in (2) are used and,\n$\\begin{cases}\nZ^{(i)} = f_E (G^{(i)}; \\theta_E),\n\\\\ L_{CAR}(A,\\hat{A}) = \\frac{1}{n^2} \\sum_{p,q} (A_{pq} \\log(\\hat{A}_{pq}) + (1 - A_{pq}) \\log(1 - \\hat{A}_{pq})).\n\\end{cases}$\n(5)\nBy reformulating the training problem as a joint optimization task, the models' parameters\nare obtained by simultaneously solving a pair of objectives, which may initially appear\northogonal. When \u03b2 = 0, the method boils down to the classical MIL pipeline, whereas\n\u03b2 = 1 reduces the task to encoding the spatial context only as in a Graph AutoEncoder\n(GAE) (Kipf and Welling, 2016a). Note that the spatial decoder $f_D$ is not required at\ninference.\nThe spatial encoder $f_E$ and spatial decoder $f_D$ are obtained by stacking up, respectively\nlE and lD, graph convolutional network (GCN) layers:\nGCN((X, A); \u03b8) := A ReLU(X)W\u03b8, (6)\nwhere W\u03b8 is a learnable weight matrix and the matrix A may be preprocessed. If we denote\nthe composition of a function f by itself t times as $f^{\\circ t}$, then,\n$Z = f_E(G;\u03b8_E) := GCN^{\\circ l_E} (G; \u03b8_E),$\n$\\hat{A} = f_D(Z;\u03b8_D) := GCN^{\\circ l_D} ((Z, A); \u03b8_D).$\n(7)\nSimilarly to a GAE, the last layer of the spatial decoder is an inner-product decoder\nwith a sigmoid function \u03c3, that aims at reconstructing the input adjacency matrix A,\n$\\hat{A} = f_D(Z;\u03b8_D) := \u03c3(\\hat{U}_D(Z)\\hat{U}_D(Z)^T).$\n(8)"}, {"title": "2.3 DeltaCon for quantitative measure of Context-Awareness", "content": "Reporting task-related scores alone is not enough to quantify the amount of Context-\nAwareness in a tiles embedding space. To overcome this issue, we propose a novel Context-\nAwareness metric based on DELTACON (Koutra et al., 2013).\nLet $Z \u2208 R^{n\u00d7r}$ be tiles descriptors, we denote $\\hat{A}(Z) \u2208 R^{n\u00d7n}$ the adjacency matrix based\non the k nearest neighbors for the euclidean distance between the components of Z. This"}, {"title": null, "content": "is different from A, defined in sec. 2.2, that is based on the distance between the spatial\ncoordinates of the tiles. Z can be any representation of the tiles, here it will either be the\nfeatures X or the embeddings Z as defined in sec. 2.2.\nWe propose to use the DELTACON similarity between the adjacency matrix based on\ntiles descriptors $\\hat{A}(Z)$ and the adjacency matrix based on the spatial coordinates A for\nthe same WSI as our metric of Context-Awareness. Since we have directed graphs and\nthe adjacency matrices A and $\\hat{A}(Z)$ are non-symmetric, we propose this extension of the\noriginal DELTACON similarity\nDELTACON($\\hat{A}(Z), A$) = $\\frac{1}{1 + ||S(\\hat{A}(Z)) \u2013 S(A)||_F}$ , $S(A) := (I + \\epsilon^2D \u2013 \\epsilon A)^{-1}$, (9)\nwhere D := Din+Dout, where Din, resp. Dout, is the diagonal matrix counting the incoming,\nresp. outcoming, edges and $||.||_F$ denotes the Frobenius norm.\nIntuitively, S(A) \u2208 R^{n\u00d7n} is a matrix capturing the degrees of similarity between all tiles\nwhen one travels in the original graph corresponding to A. Direct neighbors are the most\nsimilar tiles, followed by neighbors of neighbors, and so on. As a result, DELTACON ($\\hat{A}(Z), A$)\nis close to 1 when the neighbors in the tiles descriptors space and the spatial coordinates\nare almost the same and it smoothly decreases towards 0 when those neighbors become\ndissimilar between the tiles representations and the spatial coordinates."}, {"title": "3 Implementation details", "content": "3.1 Datasets for survival prediction using whole slide images\nGlioblastoma data. We used H&E slides of patients with glioblastoma from the datasets\nTCGA GBM (Brennan et al., 2013; McLendon et al., 2008) and TCGA LGG (The Cancer\nGenome Atlas Research Network, 2015). We filtered cases according to the latest WHO\nclassification for gliomas (Louis et al., 2021). See App. A for more details.\nColon cancer data. We used H&E slides of patients with colon adenocarcinoma from\nTCGA. The TCGA COAD dataset contains a total of 431 cases from 24 centers."}, {"title": "3.2 Evaluation", "content": "All models were trained and evaluated on TCGA COAD and TCGA GBM using 5-fold\nnested cross validation (Bengio, 2012) to allow for hyperparameters tuning and assess the\ngeneralisation independently on those datasets. Three repeats were used in the inner loop,\ncorresponding to three different random initializations of the MIL or CARMIL models. As\na result, metric evaluation on each of the 5 test splits was performed using an ensemble of\n15 models (5 inner validation splits and 3 repeats). Ensembling was performed by averaging\nthe risk output of the models of an ensemble. In all the tables, we show the mean (std)\nC-index for OS obtained using 5-fold nested cross validation. The best results are in bold."}, {"title": "3.3 Preprocessing", "content": "For tissue segmentation, a 2D U-net (Ronneberger et al., 2015) trained on a pancancer\ndataset of manually annotated WSIs is used. Tile features of dimension d = 768 are"}, {"title": "3.4 Deep learning training", "content": "The Cox loss was employed in the supervised training of all models, utilizing overall survival\nlabels. This corresponds to $L_{MIL}$ in eq. (4). The CAR loss, denoted as $L_{CAR}$ in eq. (5), is\napplied across all CAR models and we use \u03b2 = 0.5 in eq. (4) for the total loss accross all\nCAR models. The choice of \u03b2 = 0.5 followed the empirical observation that $L_{MIL}$ and $L_{CAR}$\nhave similar range of values during the first epoch of training. Adam optimizer (Kingma\nand Ba, 2014) with momentum \u03b2\u2081 = 0.9 and \u1e9e2 = 0.999 is used for training with a learning\nrate on the grid {0.001,0.003,0.01} for all models. The maximum learning rate value 0.01\nwas chosen heuristically to be the smallest value on the grid for which most MIL models\ndiverged during training. The number of training epochs is optimized on the grid {20,30}.\nOne NVIDIA Tesla T4 GPU with 16GB of VRAM and 8 Intel(R) Xeon(R) 2.00GHz CPUs\nare used for training and inference of each model."}, {"title": "4 Experiments", "content": "4.1 Survival prediction performance\nIn tables 1 and 2, we report the performance of various MIL models for the challenging task\nof survival prediction on TCGA COAD and TCGA GBM. In table 1, we compare classical\nMIL models, selected for being agnostic to the spatial context, to their performance when"}, {"title": "4.2 Context-Awareness performance", "content": "In this section, we compile evidence supporting the successful injection of spatial information\nin the proposed CAR models and its associated performance benefits. First, we assess\nwhether CAR models genuinely exploit the input graph for their predictions. To this end,\nwe perturb the graph at inference time by randomly shuffling all the off-diagonal terms of\nthe adjacency matrix A. If the CAR models were to fail to exploit the graph structure, this\ndisruption would not impact their performance. However, the results reported in table 3\nindicate that graph shuffling leads to a degradation in the model's performance, showcasing\nthat the graph structure is indeed used in the model's decision-making process.\nSecondly, we assess the Context-Awareness of trained CARMIL models compared to the\nfeature extractor, using the DELTACON metric that we defined in sec. 2.3. For each WSI,\nthe adjacency matrix computed in the embedding space learnt by the spatial encoder of\nfig. 1 is compared to the original adjacency matrix that accounts for the spatial arrangement\nof the tiles within the slide. The DELTACON provides us with a score between 0 and 1.\nA higher DELTACON score indicates a higher degree of spatial consistency in the learnt\nembedding space as it implies that the arrangement in the embedding space closely aligns\nwith the original spatial organization within the slide. We average this slide-level score\nacross the whole TCGA COAD and GBM datasets, see table 4. In app. B.4, we showcase\nan example of a WSI illustrating how the embeddings provided by CARMIL encoders are\nmore spatially consistent than the original features. Moreover, in fig. 2, we can clearly see\nhow the spatial encoders implement more Context-Awareness than the feature extractor\n(dotted lines). Indeed, DELTACON is almost always greater for CARMIL models than for\nthe feature extractor. Therefore, these findings confirm the successful injection of spatial\nknowledge resulting from the CAR. Additionally, we explored the relationship between\nspatial information incorporated by the spatial encoder and C-index performance. In TCGA"}, {"title": "5 Conclusion", "content": "The MIL framework fails to leverage spatial interaction and organization of tiles in WSIs,\npotentially limiting prognostic model performance. In this work, we proposed to tackle this\nissue by injecting spatial knowledge into the traditional MIL framework exclusively through\nthe prism of regularization. We introduced CARMIL, a method to embed spatial relations\nbetween tiles directly into tile features. This addition mimics the pathologist's considera-\ntion of spatial arrangement in slide-level prognosis. We evaluated our method on survival\nprediction for colon cancer and glioblastoma, showing improved performance and revealing\nperformance declines when spatial context is disregarded. We also introduced a metric for\nquantifying Context-Awareness, hoping to help researchers assess spatial consistency more\nsystematically. Lastly, we discussed in App. C the influence of certain parameters on our\nmethod, but we did not investigate the impact of the feature extractor on overall perfor-\nmance. The relationship between model robustness and Context-Awareness remains an\nopen question, suggesting avenues for future research."}, {"title": "Appendix A. Glioblastoma WHO 2021 classification", "content": "The WHO 2021 classification defines glioblastoma as IDH-wild type and H3-wild type brain\ntumor with at least one of the following features: necrosis and/or microvascular prolifera-\ntion, TERT promoter mutation, EGFR amplification, or concomitant gain of chromosome 7\nand loss of chromosome 10. We will refer as TCGA GBM to those glioblastoma cases from\nthe datasets TCGA GBM and TCGA LGG after reclassification. TCGA GBM contains 352\ncases from 18 centers.This change of classification of glioblastoma has been shown to have\na negative impact on the prognostic value of previously published biomarkers (Zakharova\net al., 2022). Therefore, it is clinically important to evaluate previous and new prognostic\nmodels on glioblastoma using the new WHO classification."}, {"title": "Appendix B. Reproducibility", "content": "B.1 Construction of the spatial adjacency matrix A\nEach WSI G = (X, A) consists of a set of n tiles. For each tile p, we keep track of its spatial\ncoordinates in the 2D plane formed by the tissue region, cp = (xp, Yp), in addition to the\nd-dimensional features vector up produced by the feature extractor for that tile. We thus\ncompute the gaussian kernel, Vp \u2260 q,\n$K_{pq} = exp(-\\frac{||c_p - c_q||_2}{2})$,\nand we set the diagonal to 0. Provided k the number of neighbors, we select the k nearest\nneighbors for each node based on the similarity matrix K. The adjacency matrix A is\ndefined such that Apq equals Kpq if tile q is one of the nearest neighbors of tile p, and 0\notherwise."}, {"title": "B.2 Construction of the adjacency matrix \u0100 in the embedding space", "content": "Adjacency matrices in the embedding space are used for the evaluation of Context-Awareness\nusing DELTACON.\nConsider training of our model complete and the final parameters to have converged\nto OMIL, \u03b8\u03b5, Op. Given a WSI, represented as G = (X, A), our spatial encoder returns a\nlower dimensional vector Z = fe(G;\u03b8\u03b5) \u2208 Rn\u00d7de. Observe that Zp is the de-dimensional\nembedding for tile p. Based on this vector, we construct an adjacency matrix A, following\nthe same principle as before, but this time based on the affinity between embeddings rather\nthan using the spatial coordinates of the tiles, namely, \u2200p \u2260 q,\n$K_{pq} = exp(-\\frac{||Z_p - Z_q||_2}{2})$,\nand we set the diagonal to 0. We similarly pick the k nearest neighbors for each tile and we\nconstruct the adjacency matrix \u00c3, that we refer to as the adjacency matrix in the embedding\nspace. Therefore, Apq is the affinity between the embeddings of the tiles p and q."}, {"title": "B.3 Computation of DeltaCon", "content": "Observe that both adjacency matrices, A and A, are non-symmetric. Indeed, they are\nderived by taking the k-nearest neighbors of each node in the kernel matrices K and K,\nwhich is an inherently non-symmetric operation. In simple words, tile i can be connected to\ntile j, but i is not necessarly a neighbor of j, meaning the induced graphs are directed. In\nKoutra et al. (2013), the authors introduce a proxy function defined for undirected graphs\nwith symmetric adjacency matrix A and degree matrix D as\nS(A) := (I + \u03b5\u00b2D \u2013 \u03b5A)\u22121. (10)\nWe extend this definition to directed graphs by considering a non-symmetric adjacency\nmatrix A and a degree matrix that accounts for the number of edges entering or leaving\neach node. Namely, considering D := Din + Dout, where Din, resp. Dout, is the diagonal\nmatrix counting the incoming, resp. outcoming, edges, then we can refer back to eq. (10)\nto generalize the definition of DELTACON similarity between directed graphs. Given A and\n\u0100, as described in sec. B.1 and B.2, and their associated degree matrices D and \u010e, we can\nnow quantitatively assess the amount of spatial information, or Context-Awareness, of any\nCARMIL model by computing,\nDELTACON(A, \u0100) := $\\frac{1}{1+ ||S(A) \u2013 S(\\bar{A})||_F}$ (11)\nIn table 4, we assess the Context-Awareness of the best-performing CARMIL model from\nthe 15 models evaluated through nested cross-validation, see sec. 3.2. For each WSI in each\ndataset, we first compute the spatial adjacency matrix A with k = 8 nearest neighbors,\nas in sec. B.1. Then, for all rows in table 4 except the first, the matrix $\\bar{A}$ is computed\nbased on the embedding vector Z from the model's encoder after training, also with k = 8,\nsee sec. B.2. For the first row, the adjacency matrix $\\bar{A}$ is based on the feature vector X"}, {"title": "B.4 Qualitative assessment of Context-Awareness in CARMIL models", "content": "Consider a WSI, from which n tiles are sampled. Passing this slide to our feature extractor,\nwe get a vector X \u2208 R^{n\u00d7d}. For each tile, we compute the mean of the eucliden distance\nbetween the d-dimensional features of this very tile with the features of all its k = 8 spatial\nnearest neighbors within the slide. This results in a vector Yfeatures \u2208 R^n that accounts\nfor how well aligned the features learnt by the feature extractor conform to the spatial\narrangement of the slide. If the features exactly reflect the spatial context of each tile, the\ncoefficients in the vector Yfeatures should be fairly constant and of low magnitude. Their\nvariations are shown in fig. 3a, where we superposed the underlying slide with the values\nof Yfeatures. Next, we pass these features through our CARMIL encoder at inference time,\nfollowing the same procedure but using the embedding vector Z \u2208 R^{n\u00d7d_e} \u2013 with the same\nnotation as before. This results in a vector YCARMIL \u2208 R^n. We report the coefficients in"}, {"title": "Appendix C. Discussion on certain parameters", "content": "Number of tiles n. The number of tiles n that we randomly select from the tissue region\nof each WSI has a significant impact, and we provide an intuitive explanation for this. The\namount of spatial context required to make accurate predictions is inherently tied to the\nnumber of tiles, as it determines the scale at which patterns can be grouped. Moreover, we\nobserve that different WSIs can vary greatly in size, resulting in a wide range of number of\ntiles across datasets. Whilst we fixed n regardless of the WSI at stake, it would be a natural\nimprovement to choose n for each slide in proportion to the original size of the tissue region.\nNumber of nearest neighbors k. Similar to the number of tiles, it is probably advisable\nto choose k, the number of nearest neighbors, in proportion to the number of tiles n, and\nsubsequently, the size of the WSI. In our experiments, we optimized k across a fixed grid\nof values, independent of n.\nNumber of GCN layers lE, lD. The number of layers lE and lD in the spatial encoder\nand decoder, as well as the dimensions for the projections they induce were part of our grid\nsearch. We observed that (lE,lD) = (1,1) worked best for TCGA COAD and (lE,lD) =\n(2, 2) for TCGA GBM. The dimensions of each layer were also finetuned from a grid of fixed\nvalues, resulting in de = d as an optimal choice for the spatial encoder and all intermediate"}]}