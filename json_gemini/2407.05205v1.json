{"title": "The AI Companion in Education: Analyzing the Pedagogical Potential of ChatGPT in Computer Science and Engineering", "authors": ["Zhangying He", "Thomas Nguyen", "Tahereh Miari", "Mehrdad Aliasgari", "Setareh Rafatirad", "Hossein Sayadi"], "abstract": "Artificial Intelligence (AI), with ChatGPT as a prominent example, has recently taken center stage in various domains including higher education, particularly in Computer Science and Engineering (CSE). The AI revolution brings both convenience and controversy, offering substantial benefits while lacking formal guidance on their application. The primary objective of this work is to comprehensively analyze the pedagogical potential of ChatGPT in CSE education, understanding its strengths and limitations from the perspectives of educators and learners. We employ a systematic approach, creating a diverse range of educational practice problems within CSE field, focusing on various subjects such as data science, programming, AI, machine learning, networks, and more. According to our examinations, certain question types, like conceptual knowledge queries, typically do not pose significant challenges to ChatGPT, and thus, are excluded from our analysis. Alternatively, we focus our efforts on developing more in-depth and personalized questions and project-based tasks. These questions are presented to ChatGPT, followed by interactions to assess its effectiveness in delivering complete and meaningful responses. To this end, we propose a comprehensive five-factor reliability analysis framework to evaluate the responses. This assessment aims to identify when ChatGPT excels and when it faces challenges. Our study concludes with a correlation analysis, delving into the relationships among subjects, task types, and limiting factors. This analysis offers valuable insights to enhance ChatGPT's utility in CSE education, providing guidance to educators and students regarding its reliability and efficacy.", "sections": [{"title": "I. INTRODUCTION", "content": "Recent advancements in the field of Artificial Intelligence (AI) have shown significant promise across various applications, notably in augmenting the quality of education [1, 2]. In recent decades, Natural Language Processing (NLP), as a pivotal domain within AI, has experienced remarkable growth. This evolution is marked by significant strides in neural network architectures and learning methodologies [3, 4]. The development of deep learning models including Recurrent Neural Networks (RNNs), Recurrent Neural Network Language Model (RNNLM), Latent Semantic Analysis (LSA) [5], Long Short-Term Memory (LSTM) [6], and Gated Recurrent Units (GRUs) [7] is pivotal in harnessing the power of deep neural networks for comprehending and processing natural language.\nThe word embedding technique introduced by [8] encodes words within sentences as dense vectors in a continuous space, capturing semantic relationships between words and ensuring that words with similar meanings have similar representations. This breakthrough facilitates efficient information retrieval within sentences and enhances the ability to predict subsequent words, thereby advancing language models. While deep learning models can enhance accuracy with ample training data, they initially struggled to map sequences in language processing. Sutskever et al. [9] proposed an encoder-decoder model architecture, leveraging RNNs, to effectively map input sequences to corresponding outputs, marking a significant advancement in NLP architecture. Despite its strengths, this model faces challenges in handling longer sentences with varying input lengths, a limitation addressed by the Transformer architecture.\nThe advent of Attention mechanism enabled neural networks to selectively focus on sentence elements, enhancing contextual understanding and handling longer sequences [10]. The self-attention mechanism enables the model to focus on various segments within sentences, regardless of their proximity, assigning weights based on their relevance. Among the breakthrough applications stemming from this advancement is ChatGPT, a generative AI Large Language Model (LLM) trained on extensive text data that demonstrates the capacity for intelligent, human-like conversation across a spectrum of tasks. In less than nine months since its launch in Nov. 2022, ChatGPT has reached an impressive milestone with 100 million active monthly users and 1.6 billion monthly visitors across diverse domains, marking a record-breaking growth in technological history [11].\nChatGPT rapidly found a place in academia, intriguing students to utilize it for generating reports, essays, and code, and aiding in exam preparation, often outperforming humans. This surge sparked discussions on its impact on higher education. Recent studies explore its potential to enrich teaching programs, expand learning materials, and enhance student assessment [12, 13, 14]. Furthermore, ChatGPT assists students in refining critical-thinking skills, test preparation, and real-time feedback, as seen in [15] where it achieved comparable results to a third-year medical student in medical examinations.\nNevertheless, the application of ChatGPT in education has raised concerns about academic integrity, that students may submit generated work without effort, prompting calls for improved detection methods [16]. Scholars advocate updating academic integrity policies to address technology-driven plagiarism and suggest adapting examinations to emphasize higher-order reasoning [17, 18]. Some express concerns about excessive reliance on ChatGPT, potentially leading to a decline in critical thinking skills [19]. Moreover, biases and inaccuracies in ChatGPT's outputs are highlighted as its challenges in education [20]. Despite notable performance, investigations reveal limitations in ChatGPT's mathematical capabilities, often falling short of graduate-level proficiency [21].\nDebates persist over whether generative AI, like ChatGPT, will replace jobs and disrupt economies. McKinsey's recent research [22] suggests viewing generative AI as a productivity enhancer rather than a job eliminator. They project a potential 3% to 5% annual productivity increase in the US through 2030 by combining generative AI with existing advanced processes like automation. Their report indicates that leveraging generative AI, such as ChatGPT, allows the workforce to redirect efforts from mundane tasks to more creative and collaborative endeavors. To prepare for this shift, higher education must adapt its teaching methods. Recent studies showcase ChatGPT's positive impact in education, spanning computer science, engineering, statistics, student perspectives, programming training, and responsible use considerations [14, 23, 24, 25, 26, 27]. However, given its emergence and challenges, further research is essential to delve deeper into the application of ChatGPT in CSE education.\nIn this paper, we focus on comprehensively analyzing ChatGPT's pedagogical potential within computer science and engineering education. We undertake a systematic approach, creating diverse educational practice problems while centering on pertinent areas like data science, programming, AI, machine learning, networks, and computer architecture. Through rigorous experimentation, we identify question types that challenge ChatGPT, offering valuable insights into its limitations. Notably, our study excludes less challenging queries and instead emphasizes personalized, project-oriented tasks, incorporating non-public datasets for evaluation. We introduce a comprehensive five-factor reliability analysis methodology, aiming to pinpoint ChatGPT's strengths and weaknesses. Our correlation analysis unveils intricate relationships between subjects, task types, and reliability factors: correctness, usefulness, clarity, coherence, and completeness, presenting actionable recommendations to augment ChatGPT's efficacy in education.\nSubsequently, we conduct an in-depth investigation into each unresolved prompt, examining causal factors based on subject and task type. We offer suggestions on utilizing ChatGPT's flawed responses to assist enhanced learning as well as improving ChatGPT's performance in CSE education. Finally, we evaluate ChatGPT's cognitive capabilities, offering an assessment of its intellectual quality. The goal is to provide educators and learners with insights into what aspects of ChatGPT's responses can be trusted and where caution is warranted, which can guide the enhancement of learning objectives while establishing it as an effective educational tool. Embracing the inevitability of ChatGPT's societal impact, we suggest higher education's adaptation to propose tailored policies and methods, keeping up with the ever-increasing expansion of AI-assisted tools in educational settings.\nThe remainder of this paper is organized as follows. Section II outlines ChatGPT's background, its architecture, and its educational applications. Following that, Section III introduces our proposed methodology, while Section IV delves into our evaluation results, analysis, recommendations, and ChatGPT's impact on learning and assessment in CSE education. Lastly, Section VI concludes our study."}, {"title": "II. CHATGPT: BACKGROUND AND RELATED WORK", "content": "In this section, we provide an overview of the context and previous research work related to ChatGPT for education. The objective is to elucidate the foundational aspects and pertinent relevant literature, thereby laying the groundwork for further discussions on the topic and implying necessity of proposing a comprehensive analysis of the pedagogical potential of ChatGPT in computer science and engineering education."}, {"title": "A. ChatGPT Overview and Architecture", "content": "ChatGPT, part of OpenAI's GPT models, is an advanced conversational AI developed to produce human-like text responses and engage in dialogue. It has versatile applications, serving as virtual assistants, customer support chatbots, and an educational tool. Evolving from GPT-1 to GPT-3, these predecessors laid the foundation for ChatGPT. While GPT-4 introduces enhanced capabilities like image recognition, GPT-3.5, chosen for its accessibility, remains pertinent, especially for educators and student learners seeking optimal performance without a monthly subscription.\nAt its core, ChatGPT relies on GPT-3.5, a Large Language Model (LLM) using the Transformer architecture introduced by Vaswani et al [10], in particular, using sparse attention in each transformer layer [28]. This architecture efficiently handles data sequences. GPT-3.5 undergoes two primary stages: Pre-training and Fine-tuning. Pre-training involves learning statistical patterns and linguistic structures from a vast internet text corpus to predict subsequent words. With 175 billion parameters across 96 layers, GPT-3.5 stands as one of the largest deep learning models. Fine-tuning customizes it for diverse applications, including enhancing conversational abilities through training on specific datasets.\nThe backbone of the ChatGPT's pre-trained language model is using Transformer architecture, which employs self-attention mechanisms to weigh word importance, understand text context and dependencies. It contains a stack of encoder layers, a stack of decoder layers, and an output layer to generate the response from the prompt. Before the encoder and decoder layers, it first feeds the input data to word embeddings and position encoding. Transformer architecture enables the computation of the relationship among words in the input sequence and allows the model to focus on those words that are related to the current word.\nSubsequently, ChatGPT utilizes supervised learning and human feedback demonstration data to fine-tune the pre-trained LLM model. This heavily involves human experts and feedback. The demonstration dataset contains example prompts and expected responses created by these trained human experts. Then, it retrains/fine-tunes the LLM model to enhance the model performance, ensuring its adaptability and versatility across different applications. In the next stage, a reward model is trained to guide the model to produce conversational-style responses according to the best-rated output.\nFirst, for each prompt, it collects comparison data which uses the prompt as input in the language model to produce 4 to 9 outputs/responses [29, 31]. Then, the trained human experts rate each response from the best to the worst. This comparison data is used to train a reward model, which is the same language model without the last output layer so that it produces a scalar reward value for each ranked output. The reward model is trained to predict the response that human experts consider the best when given a prompt, using the training comparison dataset as a basis.\nAs the last stage of optimizing the reward model, new prompts are used to output rewards from the reward model, which are subsequently utilized to train a Proximal Policy Optimization (PPO) [32] based on reinforcement learning (RL). The environment operates within a bandit framework, simulating a reinforcement learning environment. It generates random prompts and seeks human-preferred responses guided by the reward policy. Upon receiving the prompt and response, the reward model generates a reward. This refined policy aims to generate the most fitting responses for each input prompt [31]. Along with more queries with ChatGPT, the reward model is continuously optimized to better align with human preferences. This optimization process follows a framework which delineates the conditions under which a model is aligned with user intent [33]."}, {"title": "B. Related Work on ChatGPT for Education", "content": "Table I provides a comprehensive summary of recent research efforts delving into the evaluation of ChatGPT's potential in the field of education. Hassani et al. [27] conduct a comparative analysis of language processing models, focusing on ChatGPT's role in data science education. Highlighting its potential to advance workflows and outcomes for data scientists, the study acknowledges ChatGPT's imperfections. It notes that, like any language model, ChatGPT is not perfect, and its accuracy depends on various factors, including the quality and diversity of training data, the complexity of input text, and the nature of the task. The work in [23] showcases ChatGPT's application as a personalized data scientist. The system, VIDS (Virtual Interactive Data Scientist), functions as an AutoML assistant. Despite improved precision, the model occasionally generated displayed shortcomings, especially when presented with few-shot learning examples.\nEllis et al. [14] discuss ChatGPT excels with tailored prompts, outperforming conventional search engines, especially in addressing nuanced statistical queries. However, ChatGPT generates varied responses to prompts about confidence intervals and p-values. Also, instead of banning ChatGPT, the paper recommends educators adopt alternative approaches for students to harness generative AI effectively. Examining ChatGPT's role in data science education, the work in [24] acknowledges its efficacy as an educational tool. However, limitations arise in its effectiveness for assessing problem-solving questions with multiple correct answers. The study included 28 students in its exploration. Student feedback showcased positive experiences but highlighted challenges in critical thinking and problem-solving support.\nThe research in [38] assessed the effectiveness of using ChatGPT for solving programming problems, involving 24 students. Results showed that the group utilizing ChatGPT performed better, achieving higher scores in less time, despite facing code inaccuracies. The study in [37] raises concerns about ChatGPT's overuse in lower division courses, potentially impeding student learning and graduation rates. The authors evaluate ChatGPT's abilities in solving assignments in computer security specialization.\nSingh et al. [36] echo similar concerns in their exploration of ChatGPT's challenges and potential risks in higher education. Surveying 430 students, the paper reveals students' apprehensions about misuse despite their familiarity with ChatGPT. While acknowledging its benefits in writing and code generation, students express concerns about their limited understanding of the tool. The paper advocates for integrating ChatGPT in education with defined guidelines instead of outright restrictions.\nThe study in [26] explores ChatGPT's potential applications in engineering education while highlighting its imperfections, including the generation of potentially biased or incorrect information. The article takes an unconventional approach, engaging ChatGPT to differentiate acceptable from non-acceptable educational use, addressing concerns about plagiarism, academic integrity, and its impact on online exams.\nThe work in [21] presents a testing methodology to gauge ChatGPT's math capabilities. Establishing a benchmark for large language models, the paper explores ChatGPT's practicality in mathematical contexts. It reveals ChatGPT lack the adequate proficiency for advanced university-level math due to limitations in delivering high-quality proofs and calculations. However, it underscores ChatGPT's potential as a valuable assistant, especially with users able to assess its output.\nFirat et al. [13] explored scholars' views on integrating ChatGPT and Al in universities. Findings from 21 participants echoed existing literature, highlighting Al's potential benefits and challenges in education. However, concerns arose about assessment methods and ethical implications. The study emphasizes the necessity for clear guidelines and policies to prevent misuse and educate students on effectively integrating AI into their learning processes. Moreover, the study in [39] assesses ChatGPT in education and research, acknowledging its fast conversational responses but noting limitations like the absence of citations and possible inaccuracies. It emphasizes concerns about hindering learners' creativity and the model's restricted scope, urging action to address these issues.\nRahman et al. [19] delve into ChatGPT's role in programming education. It includes coding experiments like code generation, pseudocode creation, and correction, validated via an online judge system. Additionally, a survey with students and teachers evaluates ChatGPT's impact on programming education. Results show around 50% of teachers rated ChatGPT 3/5, indicating partial trust in programming education. Farrokhnia et al. [40] conducted a SWOT analysis of ChatGPT in education. It outlined strengths like generating personalized responses and potential for improvement, along with opportunities for personalized learning. However, it noted weaknesses such as limited understanding and biases, highlighting threats to academic integrity and cognitive skills.\nThe paper in [35] explores ChatGPT's code generation capabilities across different programming languages and analyzes sentiment regarding ChatGPT on social media. The finding reveals that Python and JavaScript are the most popular languages, with ChatGPT used for various purposes (e.g., debugging, interview preparation). In [25], 45 undergraduates split into two groups one using ChatGPT during programming practices showed improvements in critical thinking and problem-solving. However, motivation for tough tasks didn't change, suggesting exploring new ways to boost motivation during challenging assignments.\nThe study outlined in [41] devised a dual-anonymous protocol to evaluate responses to questions from four end-of-module assessments in a basic computer science course. These responses, from both ChatGPT and students, formed part of a quality assurance investigation. Findings revealed ChatGPT achieved a pass rate exceeding 40%, notably scoring over 85% in the introductory module but falling below 40% in questions relating to personal development planning and reflection. Additionally, the study assessed the effectiveness of plagiarism detection tools such as GPT-2 and TurnItIn AI in identifying Al-generated content. Results demonstrated TurnItIn AI detected all AI-generated work with 100% accuracy, while GPT-2 had partial success.\nThe work in [42] explored ChatGPT's impact on engineering education across seven Australian universities, assessing its effectiveness in ten subjects. Tasks encompassed online quizzes, oral assessments, and coding exercises. Results, akin to student grading, indicated ChatGPT's success in three subjects, failure in five, and indeterminate outcomes in two. Variability in performance across subjects and task types was noted, with suggestions offered for maximizing strengths and mitigating weaknesses to enhance engineering learning."}, {"title": "III. PROPOSED METHODOLOGY", "content": "This section outlines the proposed methodology for analyzing the potential of ChatGPT for CSE education. Initially, we introduce the overarching methodology, followed by an exposition of the five factors contributing to reliability scores and the metric formula. Subsequently, we present a correlation analysis-based approach to explore causal factors, complemented by qualitative analysis aimed at providing deeper insights into the quantitative results. Additionally, we present an examination of implications and weaknesses for comprehensive analysis."}, {"title": "A. Overview of Methodology", "content": "Figure 2 demonstrates the comprehensive methodology proposed in this work for assessing the potential of ChatGPT in supporting computer science and engineering education. Initially, we specify various primary subjects within undergraduate CSE curricula at the University level including data structures & algorithms, networking, machine learning, data analytics & visualization, computer architecture & organization, database, and probability & statistics. Subsequently, we summarized twelve common task types in Table II, which serve as a foundation for crafting prompts to engage with ChatGPT.\nAcknowledging ChatGPT's proficiency in certain tasks, our prompt design strategy centers on formulating challenging yet college-level questions pertinent to the subject matter and task types. Employing an iterative approach, we systematically generate five questions per subject across various task types (35 scenarios in each iteration), aimed at pushing the boundaries of ChatGPT's response capabilities. Through successive interactions, we gather responses and continually refine the prompts until we accumulate at least ten unsatisfactory answers. Following this data collection phase, reliability analysis is conducted on all responses, utilizing the evaluation metrics and formula described in Subsection III-B. Responses yielding a reliability score exceeding a threshold of 90% are deemed satisfactory. For those falling below this threshold, a detailed quantitative and qualitative analysis of causal factors is undertaken to delve into the shortcomings.\nFrom a quantitative perspective, the reliability analysis involves examining the subjects, task types, and five key reliability factors: correctness, usefulness, clarity, coherence, and completeness. A lower reliability score might stem from task type, subject matter, or their interplay, significantly influencing correctness, usefulness, completeness, and beyond. The objective is to discern how subjects as well as the educational task types, impact a user's perception of ChatGPT's reliability. Employing quantitative correlation analysis provides a robust assessment of ChatGPT's suitability as an educational tool, offering insights crucial for enhancing its reliability, and facilitating its use for CSE education. Details on analysis and the implications for improvement are presented in Section IV-A.\nIn addition to the quantitative analysis, we delve into our experience with unsatisfactory prompts to elucidate the quantitative findings. This approach allows us to offer valuable insights, provide intricate details, and meticulously evaluate ChatGPT's limitations in CSE education. We curate screenshots of unsuccessful prompts, conducting a granular analysis to pinpoint specific issues encountered line by line. This examination enables us to offer recommendations for ChatGPT's enhancement, envisioning how it can mitigate these identified limitations. Further elaboration on these observations and improvement suggestions is presented in Section IV-B."}, {"title": "B. Reliability Factors and Evaluation Metrics", "content": "We assess the reliability of all ChatGPT responses using a framework comprising five key factors. Each factor is evaluated on a scale from 1 to 5, and the cumulative scores yield the overall reliability score for each response. Responses achieving a reliability score of 90% or higher are considered acceptable. However, for responses falling below this threshold, a comprehensive analysis follows, integrating quantitative and qualitative methods. This examination aims to uncover the reasons behind their lower reliability, shedding light on the primary factors impacting response quality. The reliability factors are described below:\nCorrectness: This metric assesses the accuracy of the generated answers, focusing on factual correctness, coherence, and absence of synthetic content. Additionally, it considers the accuracy and clarity of visual aids like diagrams or plots when presenting factual information.\n\u2022 1- Incorrect: Generated responses lack factual evidence and information might be fabricated.\n\u2022 2- Contains a mix of accurate and inaccurate (>50%) information.\n\u2022 3- Contains a mix of accurate (>60%) and inaccurate information.\n\u2022 4- Mix of accurate (>80%) and inaccurate (<20%) information.\n\u2022 5- Fully Correct: Generated responses are factually sound.\nUsefulness: This metric evaluates the quality or fact of being useful from a user's perspectives. It gauges practicality, determining whether the answer fulfills the user's needs. We can ask questions when evaluating this factor, such as \"Would I use this answer?\" or \"How much of them would I use?\".\n\u2022 1- Useless: Generated responses lack practical usability.\n\u2022 2- <40% of usefulness, meaning user has to add another 60% more work to make the response useful.\n\u2022 3- <60% of usefulness, meaning user has to add another 40% more work to make the response useful.\n\u2022 4- >80% of usefulness, meaning user need to add another 20% more work to make the response useful.\n\u2022 5- Useful: Generated responses are useful (near 100%, repeated content is acceptable), that user can use it without any further effort and major adjustment.\nClarity: This metric evaluates how well the language model can produce output that is fluent and easily comprehensible and offers sufficient evidence to support the response. The output should demonstrate proper grammar, use appropriate language, while avoiding unnecessary or confusing information.\n\u2022 1- Hard to Understand: Generated responses are difficult to understand maybe due to lack of context and evidence, or the output does not represent natural language, or poor or incorrect grammar.\n\u2022 2- Contains a mix of clarified and unclarified (>50%) information.\n\u2022 3- Mix of clarified (>60%) and unclarified (<40%) information.\n\u2022 4- Mix of clarified (>80%) and unclarified (<20%) information.\n\u2022 5- Easy to Understand: Responses are easy to understand; output is well-constructed with adequate evidence and context.\nCoherence: This metric assesses the model's ability to maintain a coherent conversation and provide non-repetitive, context-aware responses. If the user requires further insights, the model should seamlessly continue the conversation, offering valuable information without unnecessary duplication.\n\u2022 1- Incoherent: Generated responses lack cohesiveness from the previous response; the responses either are repetitive or lack awareness of the conversation context.\n\u2022 2- Contains a mix of coherent and incoherent (>50%) information.\n\u2022 3- Mix of coherent (>60%) and incoherent (<20%) information.\n\u2022 4- Mix of coherent (>80%) and incoherent (<20%) information.\n\u2022 5- Coherent: Responses show coherence with prior answers, minimal repetition, and an understanding of the conversation's context.\nCompleteness: Given that a user can engage with ChatGPT incrementally, it assesses the entirety of responses, ensuring they are comprehensive across all interactions.\n\u2022 1- Incomplete: Generated responses are not complete and the prompt is partially answered. It falls within this range if the answer's completeness is below 20% (over 80% incompleteness).\n\u2022 2- >60% incomplete, needs 60% more work to make it complete.\n\u2022 3- >40% incomplete, needs 40% more work to make it complete.\n\u2022 4- >80% complete, needs 20% more work to make it complete.\n\u2022 5- Complete: Responses are fully complete (e.g. code is fully generated and libraries are properly imported, so that the code can be run without further modification).\nWeights Assigned to Each Metric: Acknowledging the varying significance of evaluation metrics, we have assigned specific weights to each metric, aligning them with their relative importance about the examined course subjects and tasks. The detailed distribution of these weights is outlined in Table III, reflecting their respective significance in guiding educators' decision-making processes. The allocation of weights is derived from our analysis encompassing diverse subjects, tailored to assist educators and learners. Notably these weights, while structured for this context, may differ in other domains or educational settings. They are not fixed and could be adjusted to accommodate the unique requirements of different subject areas. The flexibility of these weights ensures adaptability across diverse educational environments.\nThe Reliability Score in our analysis is calculated as below:\nR-Score = (Correctness\u00d70.4)+(Usefulness\u00d70.2)+(Clarity\u00d70.2) + (Coherence \u00d7 0.1) + (Completeness \u00d7 0.1)\nThe weighted R-Score is a composite measure derived from evaluating various metrics correctness, usefulness, clarity, coherence, and completeness. Each metric's contribution to the overall score is determined by its assigned weight. The proposed equation aggregates the weighted metrics to provide a comprehensive assessment of the reliability of ChatGPT's responses in CSE educational contexts."}, {"title": "C. Integrating ChatGPT in Learning and Assessment", "content": "Anderson et al. [43] redefined Bloom's taxonomy by emphasizing the hierarchical nature of learning objectives. These objectives encompass various levels of skills development, including remembering, understanding, applying, analyzing, evaluating, and creating (presented in Subsection IV-C). Notably, these skills are not necessarily acquired sequentially but represent a spectrum illustrating the depth and extent of skill development throughout education. The conducted reliability analysis in this work aligns with Bloom's taxonomy in evaluating ChatGPT's proficiency across various cognitive skill levels. Correctness pertains to the foundational level of remembering and understanding, ensuring factual accuracy and comprehension of content. Usefulness and clarity correspond to higher levels such as applying and analyzing, emphasizing the practical application and critical evaluation of information.\nCoherence and completeness signify the synthesis and creation of new knowledge, aligning with evaluation and creation levels in Bloom's taxonomy. Thus, the proposed reliability analysis serves as a complementary assessment, mapping ChatGPT's performance onto Bloom's taxonomy, enabling a comprehensive understanding of its effectiveness across diverse cognitive skill levels crucial for educational integration (described in Subsection V). Particularly, Bloom's taxonomy serves as a framework to assess ChatGPT's proficiency across essential skill metrics, rating them on a scale of excellent, good, fair, and poor. This evaluation offers insights into ChatGPT's capabilities aligned with the spectrum of cognitive skills outlined in Bloom's taxonomy. Moreover, it informs suggested implications for higher education, spanning areas such as open challenges of reliability, fairness, and integrity. Hence, CSE programs are urged to update educational policy, curriculum, and assessment methods to adapt to such challenges."}, {"title": "IV. RESULTS, ANALYSIS, AND INSIGHTS", "content": "This section delves into our experimental evaluation of ChatGPT's reliability in CSE education. We analyze unresolved prompts (detailed in Table IV) encountered while interacting with ChatGPT. For example, when requesting code generation for a CNN model and a train-validation dataloader, errors were identified, leading to an unsatisfactory prompt (prompt #7) within machine learning topics. We quantitatively examine reliability factors concerning subject, task type, and specific prompts. Unsatisfactory prompts prevail in all CSE subjects and task types (e.g. code generation, problem-solving, and data analysis). Specifically, as shown in Table IV, computer architecture, data analysis, machine learning, and probability questions have notably lower reliability scores, reaching as low as 42% (#12), 50% (#6), 52% (#7) and 52% (#10), respectively. Next, we perform an analysis of each unresolved prompt, examining causal factors based on subject and task type. We provide suggestions to address errors and enhance ChatGPT's performance. Additionally, we assess ChatGPT's cognitive abilities in CSE education to guide educators and learners on its reliability and limitations."}, {"title": "A. Reliability Analysis", "content": "1) Reliability Scores: Utilizing the reliability score formula described in Section III-B, we calculate the R-Score for each prompt tested. We then determine its percentage score (R-Score/5) and present in Table IV the prompts that did not meet the predefined reliability threshold (90%). Figure 3 depicts the summative reliability scores of the unsatisfactory prompts by subject and task type resulting from our experiments. Figure 3-(a) outlines that among CSE subjects, different areas faced limitations, averaging a reliability score of 73%. Notably, the subjects in machine learning, probability and statistics, and computer architecture and organization scored below this average.\nFigure 3-(b) illustrates that challenging tasks averaged a 72% score, with data analysis, code generation, and problem-solving falling below this mark. While ChatGPT showcased proficiency in code generation, unreliability issues emerged upon closer inspection, such as incorrect code outputs. For instance, in prompt #7, the generated code appeared accurate but produced incorrect results when run. Similarly, in prompt #10, ChatGPT showed inconsistencies while solving probability questions, providing conflicting answers within the reasoning process. While competent in computer architecture, it struggled with fundamental concepts like binary number operations and converting MIPS instructions. We observed that ChatGPT alternates between recalling memorized answers and attempting logical reasoning by running code to generate responses. This has led to inconsistencies and reliability issues when applying knowledge to practical scenarios, technical tasks, problem-solving, and advanced analyses.\n2) Reliability Factors Analysis: Figure 4 illustrates the reliability scores across five factors correctness, usefulness, clarity, coherence, and completeness within different subjects. Figure 5 showcases how ChatGPT's reliability varies across task types, from coding tasks to providing personalized tutoring, focusing on these same five factors. In addition, Figure 6 depicts the average score for each of the five reliable factors. Our primary observations across these results include:\n\u2022 Among the five reliability factors, usefulness and correctness pose the most significant challenges, followed by completeness, which is far below the mean score as shown in Figure 6. These are essential metrics for users' trust in ChatGPT.\n\u2022 Overall, ChatGPT performs well in clarity and coherence by subject and task type."}, {"title": "B. Exploring Unsatisfactory Responses: Case Studies", "content": "This section aims to analyze ChatGPT's weaknesses", "Code": "ChatGPT generally performs well in providing accurate answers in computer science and engineering topics", "random_split": "r 'SubsetRandomSampler') from the PyTorch library was necessary for successful execution. Our interaction with ChatGPT effectively guided us developing a CNN model. However", "code.\nAssessment": "ChatGPT showcases a range of cognitive abilities", "code.\nRecommendations": "ChatGPT offers a quicker way to grasp new concepts", "Skill": "We tasked ChatGPT with different data visualization assignments. Initially", "architecture.\nAssessment": "ChatGPT shows entry-level skills in data visualization. It struggles compared to humans using tools like Excel or PPT", "generation.\nRecommendations": "Data visualization can be challenging due to its artistic nature and the need to convey meaningful information on the graph. ChatGPT can help by offering various visualization options and explanations. However", "Response": "We found that some of ChatGPT's responses were overly simplistic", "knowledge.\nAssessment": "These questions demand high-order cognitive skills that involve applying"}, {"title": "The AI Companion in Education: Analyzing the Pedagogical Potential of ChatGPT in Computer Science and Engineering", "authors": ["Zhangying He", "Thomas Nguyen", "Tahereh Miari", "Mehrdad Aliasgari", "Setareh Rafatirad", "Hossein Sayadi"], "abstract": "Artificial Intelligence (AI), with ChatGPT as a prominent example, has recently taken center stage in various domains including higher education, particularly in Computer Science and Engineering (CSE). The AI revolution brings both convenience and controversy, offering substantial benefits while lacking formal guidance on their application. The primary objective of this work is to comprehensively analyze the pedagogical potential of ChatGPT in CSE education, understanding its strengths and limitations from the perspectives of educators and learners. We employ a systematic approach, creating a diverse range of educational practice problems within CSE field, focusing on various subjects such as data science, programming, AI, machine learning, networks, and more. According to our examinations, certain question types, like conceptual knowledge queries, typically do not pose significant challenges to ChatGPT, and thus, are excluded from our analysis. Alternatively, we focus our efforts on developing more in-depth and personalized questions and project-based tasks. These questions are presented to ChatGPT, followed by interactions to assess its effectiveness in delivering complete and meaningful responses. To this end, we propose a comprehensive five-factor reliability analysis framework to evaluate the responses. This assessment aims to identify when ChatGPT excels and when it faces challenges. Our study concludes with a correlation analysis, delving into the relationships among subjects, task types, and limiting factors. This analysis offers valuable insights to enhance ChatGPT's utility in CSE education, providing guidance to educators and students regarding its reliability and efficacy.", "sections": [{"title": "I. INTRODUCTION", "content": "Recent advancements in the field of Artificial Intelligence (AI) have shown significant promise across various applications, notably in augmenting the quality of education [1, 2]. In recent decades, Natural Language Processing (NLP), as a pivotal domain within AI, has experienced remarkable growth. This evolution is marked by significant strides in neural network architectures and learning methodologies [3, 4]. The development of deep learning models including Recurrent Neural Networks (RNNs), Recurrent Neural Network Language Model (RNNLM), Latent Semantic Analysis (LSA) [5], Long Short-Term Memory (LSTM) [6], and Gated Recurrent Units (GRUs) [7] is pivotal in harnessing the power of deep neural networks for comprehending and processing natural language.\nThe word embedding technique introduced by [8] encodes words within sentences as dense vectors in a continuous space, capturing semantic relationships between words and ensuring that words with similar meanings have similar representations. This breakthrough facilitates efficient information retrieval within sentences and enhances the ability to predict subsequent words, thereby advancing language models. While deep learning models can enhance accuracy with ample training data, they initially struggled to map sequences in language processing. Sutskever et al. [9] proposed an encoder-decoder model architecture, leveraging RNNs, to effectively map input sequences to corresponding outputs, marking a significant advancement in NLP architecture. Despite its strengths, this model faces challenges in handling longer sentences with varying input lengths, a limitation addressed by the Transformer architecture.\nThe advent of Attention mechanism enabled neural networks to selectively focus on sentence elements, enhancing contextual understanding and handling longer sequences [10]. The self-attention mechanism enables the model to focus on various segments within sentences, regardless of their proximity, assigning weights based on their relevance. Among the breakthrough applications stemming from this advancement is ChatGPT, a generative AI Large Language Model (LLM) trained on extensive text data that demonstrates the capacity for intelligent, human-like conversation across a spectrum of tasks. In less than nine months since its launch in Nov. 2022, ChatGPT has reached an impressive milestone with 100 million active monthly users and 1.6 billion monthly visitors across diverse domains, marking a record-breaking growth in technological history [11].\nChatGPT rapidly found a place in academia, intriguing students to utilize it for generating reports, essays, and code, and aiding in exam preparation, often outperforming humans. This surge sparked discussions on its impact on higher education. Recent studies explore its potential to enrich teaching programs, expand learning materials, and enhance student assessment [12, 13, 14]. Furthermore, ChatGPT assists students in refining critical-thinking skills, test preparation, and real-time feedback, as seen in [15] where it achieved comparable results to a third-year medical student in medical examinations.\nNevertheless, the application of ChatGPT in education has raised concerns about academic integrity, that students may submit generated work without effort, prompting calls for improved detection methods [16]. Scholars advocate updating academic integrity policies to address technology-driven plagiarism and suggest adapting examinations to emphasize higher-order reasoning [17, 18]. Some express concerns about excessive reliance on ChatGPT, potentially leading to a decline in critical thinking skills [19]. Moreover, biases and inaccuracies in ChatGPT's outputs are highlighted as its challenges in education [20]. Despite notable performance, investigations reveal limitations in ChatGPT's mathematical capabilities, often falling short of graduate-level proficiency [21].\nDebates persist over whether generative AI, like ChatGPT, will replace jobs and disrupt economies. McKinsey's recent research [22] suggests viewing generative AI as a productivity enhancer rather than a job eliminator. They project a potential 3% to 5% annual productivity increase in the US through 2030 by combining generative AI with existing advanced processes like automation. Their report indicates that leveraging generative AI, such as ChatGPT, allows the workforce to redirect efforts from mundane tasks to more creative and collaborative endeavors. To prepare for this shift, higher education must adapt its teaching methods. Recent studies showcase ChatGPT's positive impact in education, spanning computer science, engineering, statistics, student perspectives, programming training, and responsible use considerations [14, 23, 24, 25, 26, 27]. However, given its emergence and challenges, further research is essential to delve deeper into the application of ChatGPT in CSE education.\nIn this paper, we focus on comprehensively analyzing ChatGPT's pedagogical potential within computer science and engineering education. We undertake a systematic approach, creating diverse educational practice problems while centering on pertinent areas like data science, programming, AI, machine learning, networks, and computer architecture. Through rigorous experimentation, we identify question types that challenge ChatGPT, offering valuable insights into its limitations. Notably, our study excludes less challenging queries and instead emphasizes personalized, project-oriented tasks, incorporating non-public datasets for evaluation. We introduce a comprehensive five-factor reliability analysis methodology, aiming to pinpoint ChatGPT's strengths and weaknesses. Our correlation analysis unveils intricate relationships between subjects, task types, and reliability factors: correctness, usefulness, clarity, coherence, and completeness, presenting actionable recommendations to augment ChatGPT's efficacy in education.\nSubsequently, we conduct an in-depth investigation into each unresolved prompt, examining causal factors based on subject and task type. We offer suggestions on utilizing ChatGPT's flawed responses to assist enhanced learning as well as improving ChatGPT's performance in CSE education. Finally, we evaluate ChatGPT's cognitive capabilities, offering an assessment of its intellectual quality. The goal is to provide educators and learners with insights into what aspects of ChatGPT's responses can be trusted and where caution is warranted, which can guide the enhancement of learning objectives while establishing it as an effective educational tool. Embracing the inevitability of ChatGPT's societal impact, we suggest higher education's adaptation to propose tailored policies and methods, keeping up with the ever-increasing expansion of AI-assisted tools in educational settings.\nThe remainder of this paper is organized as follows. Section II outlines ChatGPT's background, its architecture, and its educational applications. Following that, Section III introduces our proposed methodology, while Section IV delves into our evaluation results, analysis, recommendations, and ChatGPT's impact on learning and assessment in CSE education. Lastly, Section VI concludes our study."}, {"title": "II. CHATGPT: BACKGROUND AND RELATED WORK", "content": "In this section, we provide an overview of the context and previous research work related to ChatGPT for education. The objective is to elucidate the foundational aspects and pertinent relevant literature, thereby laying the groundwork for further discussions on the topic and implying necessity of proposing a comprehensive analysis of the pedagogical potential of ChatGPT in computer science and engineering education."}, {"title": "A. ChatGPT Overview and Architecture", "content": "ChatGPT, part of OpenAI's GPT models, is an advanced conversational AI developed to produce human-like text responses and engage in dialogue. It has versatile applications, serving as virtual assistants, customer support chatbots, and an educational tool. Evolving from GPT-1 to GPT-3, these predecessors laid the foundation for ChatGPT. While GPT-4 introduces enhanced capabilities like image recognition, GPT-3.5, chosen for its accessibility, remains pertinent, especially for educators and student learners seeking optimal performance without a monthly subscription.\nAt its core, ChatGPT relies on GPT-3.5, a Large Language Model (LLM) using the Transformer architecture introduced by Vaswani et al [10], in particular, using sparse attention in each transformer layer [28]. This architecture efficiently handles data sequences. GPT-3.5 undergoes two primary stages: Pre-training and Fine-tuning. Pre-training involves learning statistical patterns and linguistic structures from a vast internet text corpus to predict subsequent words. With 175 billion parameters across 96 layers, GPT-3.5 stands as one of the largest deep learning models. Fine-tuning customizes it for diverse applications, including enhancing conversational abilities through training on specific datasets.\nThe backbone of the ChatGPT's pre-trained language model is using Transformer architecture, which employs self-attention mechanisms to weigh word importance, understand text context and dependencies. It contains a stack of encoder layers, a stack of decoder layers, and an output layer to generate the response from the prompt. Before the encoder and decoder layers, it first feeds the input data to word embeddings and position encoding. Transformer architecture enables the computation of the relationship among words in the input sequence and allows the model to focus on those words that are related to the current word.\nSubsequently, ChatGPT utilizes supervised learning and human feedback demonstration data to fine-tune the pre-trained LLM model. This heavily involves human experts and feedback. The demonstration dataset contains example prompts and expected responses created by these trained human experts. Then, it retrains/fine-tunes the LLM model to enhance the model performance, ensuring its adaptability and versatility across different applications. In the next stage, a reward model is trained to guide the model to produce conversational-style responses according to the best-rated output.\nFirst, for each prompt, it collects comparison data which uses the prompt as input in the language model to produce 4 to 9 outputs/responses [29, 31]. Then, the trained human experts rate each response from the best to the worst. This comparison data is used to train a reward model, which is the same language model without the last output layer so that it produces a scalar reward value for each ranked output. The reward model is trained to predict the response that human experts consider the best when given a prompt, using the training comparison dataset as a basis.\nAs the last stage of optimizing the reward model, new prompts are used to output rewards from the reward model, which are subsequently utilized to train a Proximal Policy Optimization (PPO) [32] based on reinforcement learning (RL). The environment operates within a bandit framework, simulating a reinforcement learning environment. It generates random prompts and seeks human-preferred responses guided by the reward policy. Upon receiving the prompt and response, the reward model generates a reward. This refined policy aims to generate the most fitting responses for each input prompt [31]. Along with more queries with ChatGPT, the reward model is continuously optimized to better align with human preferences. This optimization process follows a framework which delineates the conditions under which a model is aligned with user intent [33]."}, {"title": "B. Related Work on ChatGPT for Education", "content": "Table I provides a comprehensive summary of recent research efforts delving into the evaluation of ChatGPT's potential in the field of education. Hassani et al. [27] conduct a comparative analysis of language processing models, focusing on ChatGPT's role in data science education. Highlighting its potential to advance workflows and outcomes for data scientists, the study acknowledges ChatGPT's imperfections. It notes that, like any language model, ChatGPT is not perfect, and its accuracy depends on various factors, including the quality and diversity of training data, the complexity of input text, and the nature of the task. The work in [23] showcases ChatGPT's application as a personalized data scientist. The system, VIDS (Virtual Interactive Data Scientist), functions as an AutoML assistant. Despite improved precision, the model occasionally generated displayed shortcomings, especially when presented with few-shot learning examples.\nEllis et al. [14] discuss ChatGPT excels with tailored prompts, outperforming conventional search engines, especially in addressing nuanced statistical queries. However, ChatGPT generates varied responses to prompts about confidence intervals and p-values. Also, instead of banning ChatGPT, the paper recommends educators adopt alternative approaches for students to harness generative AI effectively. Examining ChatGPT's role in data science education, the work in [24] acknowledges its efficacy as an educational tool. However, limitations arise in its effectiveness for assessing problem-solving questions with multiple correct answers. The study included 28 students in its exploration. Student feedback showcased positive experiences but highlighted challenges in critical thinking and problem-solving support.\nThe research in [38] assessed the effectiveness of using ChatGPT for solving programming problems, involving 24 students. Results showed that the group utilizing ChatGPT performed better, achieving higher scores in less time, despite facing code inaccuracies. The study in [37] raises concerns about ChatGPT's overuse in lower division courses, potentially impeding student learning and graduation rates. The authors evaluate ChatGPT's abilities in solving assignments in computer security specialization.\nSingh et al. [36] echo similar concerns in their exploration of ChatGPT's challenges and potential risks in higher education. Surveying 430 students, the paper reveals students' apprehensions about misuse despite their familiarity with ChatGPT. While acknowledging its benefits in writing and code generation, students express concerns about their limited understanding of the tool. The paper advocates for integrating ChatGPT in education with defined guidelines instead of outright restrictions.\nThe study in [26] explores ChatGPT's potential applications in engineering education while highlighting its imperfections, including the generation of potentially biased or incorrect information. The article takes an unconventional approach, engaging ChatGPT to differentiate acceptable from non-acceptable educational use, addressing concerns about plagiarism, academic integrity, and its impact on online exams.\nThe work in [21] presents a testing methodology to gauge ChatGPT's math capabilities. Establishing a benchmark for large language models, the paper explores ChatGPT's practicality in mathematical contexts. It reveals ChatGPT lack the adequate proficiency for advanced university-level math due to limitations in delivering high-quality proofs and calculations. However, it underscores ChatGPT's potential as a valuable assistant, especially with users able to assess its output.\nFirat et al. [13] explored scholars' views on integrating ChatGPT and Al in universities. Findings from 21 participants echoed existing literature, highlighting Al's potential benefits and challenges in education. However, concerns arose about assessment methods and ethical implications. The study emphasizes the necessity for clear guidelines and policies to prevent misuse and educate students on effectively integrating AI into their learning processes. Moreover, the study in [39] assesses ChatGPT in education and research, acknowledging its fast conversational responses but noting limitations like the absence of citations and possible inaccuracies. It emphasizes concerns about hindering learners' creativity and the model's restricted scope, urging action to address these issues.\nRahman et al. [19] delve into ChatGPT's role in programming education. It includes coding experiments like code generation, pseudocode creation, and correction, validated via an online judge system. Additionally, a survey with students and teachers evaluates ChatGPT's impact on programming education. Results show around 50% of teachers rated ChatGPT 3/5, indicating partial trust in programming education. Farrokhnia et al. [40] conducted a SWOT analysis of ChatGPT in education. It outlined strengths like generating personalized responses and potential for improvement, along with opportunities for personalized learning. However, it noted weaknesses such as limited understanding and biases, highlighting threats to academic integrity and cognitive skills.\nThe paper in [35] explores ChatGPT's code generation capabilities across different programming languages and analyzes sentiment regarding ChatGPT on social media. The finding reveals that Python and JavaScript are the most popular languages, with ChatGPT used for various purposes (e.g., debugging, interview preparation). In [25], 45 undergraduates split into two groups one using ChatGPT during programming practices showed improvements in critical thinking and problem-solving. However, motivation for tough tasks didn't change, suggesting exploring new ways to boost motivation during challenging assignments.\nThe study outlined in [41] devised a dual-anonymous protocol to evaluate responses to questions from four end-of-module assessments in a basic computer science course. These responses, from both ChatGPT and students, formed part of a quality assurance investigation. Findings revealed ChatGPT achieved a pass rate exceeding 40%, notably scoring over 85% in the introductory module but falling below 40% in questions relating to personal development planning and reflection. Additionally, the study assessed the effectiveness of plagiarism detection tools such as GPT-2 and TurnItIn AI in identifying Al-generated content. Results demonstrated TurnItIn AI detected all AI-generated work with 100% accuracy, while GPT-2 had partial success.\nThe work in [42] explored ChatGPT's impact on engineering education across seven Australian universities, assessing its effectiveness in ten subjects. Tasks encompassed online quizzes, oral assessments, and coding exercises. Results, akin to student grading, indicated ChatGPT's success in three subjects, failure in five, and indeterminate outcomes in two. Variability in performance across subjects and task types was noted, with suggestions offered for maximizing strengths and mitigating weaknesses to enhance engineering learning."}, {"title": "III. PROPOSED METHODOLOGY", "content": "This section outlines the proposed methodology for analyzing the potential of ChatGPT for CSE education. Initially, we introduce the overarching methodology, followed by an exposition of the five factors contributing to reliability scores and the metric formula. Subsequently, we present a correlation analysis-based approach to explore causal factors, complemented by qualitative analysis aimed at providing deeper insights into the quantitative results. Additionally, we present an examination of implications and weaknesses for comprehensive analysis."}, {"title": "A. Overview of Methodology", "content": "Figure 2 demonstrates the comprehensive methodology proposed in this work for assessing the potential of ChatGPT in supporting computer science and engineering education. Initially, we specify various primary subjects within undergraduate CSE curricula at the University level including data structures & algorithms, networking, machine learning, data analytics & visualization, computer architecture & organization, database, and probability & statistics. Subsequently, we summarized twelve common task types in Table II, which serve as a foundation for crafting prompts to engage with ChatGPT.\nAcknowledging ChatGPT's proficiency in certain tasks, our prompt design strategy centers on formulating challenging yet college-level questions pertinent to the subject matter and task types. Employing an iterative approach, we systematically generate five questions per subject across various task types (35 scenarios in each iteration), aimed at pushing the boundaries of ChatGPT's response capabilities. Through successive interactions, we gather responses and continually refine the prompts until we accumulate at least ten unsatisfactory answers. Following this data collection phase, reliability analysis is conducted on all responses, utilizing the evaluation metrics and formula described in Subsection III-B. Responses yielding a reliability score exceeding a threshold of 90% are deemed satisfactory. For those falling below this threshold, a detailed quantitative and qualitative analysis of causal factors is undertaken to delve into the shortcomings.\nFrom a quantitative perspective, the reliability analysis involves examining the subjects, task types, and five key reliability factors: correctness, usefulness, clarity, coherence, and completeness. A lower reliability score might stem from task type, subject matter, or their interplay, significantly influencing correctness, usefulness, completeness, and beyond. The objective is to discern how subjects as well as the educational task types, impact a user's perception of ChatGPT's reliability. Employing quantitative correlation analysis provides a robust assessment of ChatGPT's suitability as an educational tool, offering insights crucial for enhancing its reliability, and facilitating its use for CSE education. Details on analysis and the implications for improvement are presented in Section IV-A.\nIn addition to the quantitative analysis, we delve into our experience with unsatisfactory prompts to elucidate the quantitative findings. This approach allows us to offer valuable insights, provide intricate details, and meticulously evaluate ChatGPT's limitations in CSE education. We curate screenshots of unsuccessful prompts, conducting a granular analysis to pinpoint specific issues encountered line by line. This examination enables us to offer recommendations for ChatGPT's enhancement, envisioning how it can mitigate these identified limitations. Further elaboration on these observations and improvement suggestions is presented in Section IV-B."}, {"title": "B. Reliability Factors and Evaluation Metrics", "content": "We assess the reliability of all ChatGPT responses using a framework comprising five key factors. Each factor is evaluated on a scale from 1 to 5, and the cumulative scores yield the overall reliability score for each response. Responses achieving a reliability score of 90% or higher are considered acceptable. However, for responses falling below this threshold, a comprehensive analysis follows, integrating quantitative and qualitative methods. This examination aims to uncover the reasons behind their lower reliability, shedding light on the primary factors impacting response quality. The reliability factors are described below:\nCorrectness: This metric assesses the accuracy of the generated answers, focusing on factual correctness, coherence, and absence of synthetic content. Additionally, it considers the accuracy and clarity of visual aids like diagrams or plots when presenting factual information.\n\u2022 1- Incorrect: Generated responses lack factual evidence and information might be fabricated.\n\u2022 2- Contains a mix of accurate and inaccurate (>50%) information.\n\u2022 3- Contains a mix of accurate (>60%) and inaccurate information.\n\u2022 4- Mix of accurate (>80%) and inaccurate (<20%) information.\n\u2022 5- Fully Correct: Generated responses are factually sound.\nUsefulness: This metric evaluates the quality or fact of being useful from a user's perspectives. It gauges practicality, determining whether the answer fulfills the user's needs. We can ask questions when evaluating this factor, such as \"Would I use this answer?\" or \"How much of them would I use?\".\n\u2022 1- Useless: Generated responses lack practical usability.\n\u2022 2- <40% of usefulness, meaning user has to add another 60% more work to make the response useful.\n\u2022 3- <60% of usefulness, meaning user has to add another 40% more work to make the response useful.\n\u2022 4- >80% of usefulness, meaning user need to add another 20% more work to make the response useful.\n\u2022 5- Useful: Generated responses are useful (near 100%, repeated content is acceptable), that user can use it without any further effort and major adjustment.\nClarity: This metric evaluates how well the language model can produce output that is fluent and easily comprehensible and offers sufficient evidence to support the response. The output should demonstrate proper grammar, use appropriate language, while avoiding unnecessary or confusing information.\n\u2022 1- Hard to Understand: Generated responses are difficult to understand maybe due to lack of context and evidence, or the output does not represent natural language, or poor or incorrect grammar.\n\u2022 2- Contains a mix of clarified and unclarified (>50%) information.\n\u2022 3- Mix of clarified (>60%) and unclarified (<40%) information.\n\u2022 4- Mix of clarified (>80%) and unclarified (<20%) information.\n\u2022 5- Easy to Understand: Responses are easy to understand; output is well-constructed with adequate evidence and context.\nCoherence: This metric assesses the model's ability to maintain a coherent conversation and provide non-repetitive, context-aware responses. If the user requires further insights, the model should seamlessly continue the conversation, offering valuable information without unnecessary duplication.\n\u2022 1- Incoherent: Generated responses lack cohesiveness from the previous response; the responses either are repetitive or lack awareness of the conversation context.\n\u2022 2- Contains a mix of coherent and incoherent (>50%) information.\n\u2022 3- Mix of coherent (>60%) and incoherent (<20%) information.\n\u2022 4- Mix of coherent (>80%) and incoherent (<20%) information.\n\u2022 5- Coherent: Responses show coherence with prior answers, minimal repetition, and an understanding of the conversation's context.\nCompleteness: Given that a user can engage with ChatGPT incrementally, it assesses the entirety of responses, ensuring they are comprehensive across all interactions.\n\u2022 1- Incomplete: Generated responses are not complete and the prompt is partially answered. It falls within this range if the answer's completeness is below 20% (over 80% incompleteness).\n\u2022 2- >60% incomplete, needs 60% more work to make it complete.\n\u2022 3- >40% incomplete, needs 40% more work to make it complete.\n\u2022 4- >80% complete, needs 20% more work to make it complete.\n\u2022 5- Complete: Responses are fully complete (e.g. code is fully generated and libraries are properly imported, so that the code can be run without further modification).\nWeights Assigned to Each Metric: Acknowledging the varying significance of evaluation metrics, we have assigned specific weights to each metric, aligning them with their relative importance about the examined course subjects and tasks. The detailed distribution of these weights is outlined in Table III, reflecting their respective significance in guiding educators' decision-making processes. The allocation of weights is derived from our analysis encompassing diverse subjects, tailored to assist educators and learners. Notably these weights, while structured for this context, may differ in other domains or educational settings. They are not fixed and could be adjusted to accommodate the unique requirements of different subject areas. The flexibility of these weights ensures adaptability across diverse educational environments.\nThe Reliability Score in our analysis is calculated as below:\n$R\\text{-Score} = (\\text{Correctness}\\times0.4)+(\\text{Usefulness}\\times0.2)+(\\text{Clarity}\\times 0.2) + (\\text{Coherence} \\times 0.1) + (\\text{Completeness} \\times 0.1)$\nThe weighted R-Score is a composite measure derived from evaluating various metrics correctness, usefulness, clarity, coherence, and completeness. Each metric's contribution to the overall score is determined by its assigned weight. The proposed equation aggregates the weighted metrics to provide a comprehensive assessment of the reliability of ChatGPT's responses in CSE educational contexts."}, {"title": "C. Integrating ChatGPT in Learning and Assessment", "content": "Anderson et al. [43] redefined Bloom's taxonomy by emphasizing the hierarchical nature of learning objectives. These objectives encompass various levels of skills development, including remembering, understanding, applying, analyzing, evaluating, and creating (presented in Subsection IV-C). Notably, these skills are not necessarily acquired sequentially but represent a spectrum illustrating the depth and extent of skill development throughout education. The conducted reliability analysis in this work aligns with Bloom's taxonomy in evaluating ChatGPT's proficiency across various cognitive skill levels. Correctness pertains to the foundational level of remembering and understanding, ensuring factual accuracy and comprehension of content. Usefulness and clarity correspond to higher levels such as applying and analyzing, emphasizing the practical application and critical evaluation of information.\nCoherence and completeness signify the synthesis and creation of new knowledge, aligning with evaluation and creation levels in Bloom's taxonomy. Thus, the proposed reliability analysis serves as a complementary assessment, mapping ChatGPT's performance onto Bloom's taxonomy, enabling a comprehensive understanding of its effectiveness across diverse cognitive skill levels crucial for educational integration (described in Subsection V). Particularly, Bloom's taxonomy serves as a framework to assess ChatGPT's proficiency across essential skill metrics, rating them on a scale of excellent, good, fair, and poor. This evaluation offers insights into ChatGPT's capabilities aligned with the spectrum of cognitive skills outlined in Bloom's taxonomy. Moreover, it informs suggested implications for higher education, spanning areas such as open challenges of reliability, fairness, and integrity. Hence, CSE programs are urged to update educational policy, curriculum, and assessment methods to adapt to such challenges."}, {"title": "IV. RESULTS, ANALYSIS, AND INSIGHTS", "content": "This section delves into our experimental evaluation of ChatGPT's reliability in CSE education. We analyze unresolved prompts (detailed in Table IV) encountered while interacting with ChatGPT. For example, when requesting code generation for a CNN model and a train-validation dataloader, errors were identified, leading to an unsatisfactory prompt (prompt #7) within machine learning topics. We quantitatively examine reliability factors concerning subject, task type, and specific prompts. Unsatisfactory prompts prevail in all CSE subjects and task types (e.g. code generation, problem-solving, and data analysis). Specifically, as shown in Table IV, computer architecture, data analysis, machine learning, and probability questions have notably lower reliability scores, reaching as low as 42% (#12), 50% (#6), 52% (#7) and 52% (#10), respectively. Next, we perform an analysis of each unresolved prompt, examining causal factors based on subject and task type. We provide suggestions to address errors and enhance ChatGPT's performance. Additionally, we assess ChatGPT's cognitive abilities in CSE education to guide educators and learners on its reliability and limitations."}, {"title": "A. Reliability Analysis", "content": "1) Reliability Scores: Utilizing the reliability score formula described in Section III-B, we calculate the R-Score for each prompt tested. We then determine its percentage score (R-Score/5) and present in Table IV the prompts that did not meet the predefined reliability threshold (90%). Figure 3 depicts the summative reliability scores of the unsatisfactory prompts by subject and task type resulting from our experiments. Figure 3-(a) outlines that among CSE subjects, different areas faced limitations, averaging a reliability score of 73%. Notably, the subjects in machine learning, probability and statistics, and computer architecture and organization scored below this average.\nFigure 3-(b) illustrates that challenging tasks averaged a 72% score, with data analysis, code generation, and problem-solving falling below this mark. While ChatGPT showcased proficiency in code generation, unreliability issues emerged upon closer inspection, such as incorrect code outputs. For instance, in prompt #7, the generated code appeared accurate but produced incorrect results when run. Similarly, in prompt #10, ChatGPT showed inconsistencies while solving probability questions, providing conflicting answers within the reasoning process. While competent in computer architecture, it struggled with fundamental concepts like binary number operations and converting MIPS instructions. We observed that ChatGPT alternates between recalling memorized answers and attempting logical reasoning by running code to generate responses. This has led to inconsistencies and reliability issues when applying knowledge to practical scenarios, technical tasks, problem-solving, and advanced analyses.\n2) Reliability Factors Analysis: Figure 4 illustrates the reliability scores across five factors correctness, usefulness, clarity, coherence, and completeness within different subjects. Figure 5 showcases how ChatGPT's reliability varies across task types, from coding tasks to providing personalized tutoring, focusing on these same five factors. In addition, Figure 6 depicts the average score for each of the five reliable factors. Our primary observations across these results include:\n\u2022 Among the five reliability factors, usefulness and correctness pose the most significant challenges, followed by completeness, which is far below the mean score as shown in Figure 6. These are essential metrics for users' trust in ChatGPT.\n\u2022 Overall, ChatGPT performs well in clarity and coherence by subject and task type."}, {"title": "B. Exploring Unsatisfactory Responses: Case Studies", "content": "This section aims to analyze ChatGPT's weaknesses, identify causes, and suggest improvements for enhanced educational integration.\n1) Hidden Errors in Code: ChatGPT generally performs well in providing accurate answers in computer science and engineering topics, showcasing considerable knowledge and attention to detail. However, we observed instances where the code suggested by ChatGPT contained hidden errors that were challenging to identify upfront. In particular, in some cases, ChatGPT can suggest a chunk of code, that some lines of code are incorrect, or partially incorrect.\nFor example, as shown in Figure 7, initially, we engaged ChatGPT to aid in constructing a Convolutional Neural Network (CNN) model using PyTorch. After executing the supplied code on our dataset, we sought guidance on customizing the PyTorch dataset class for tabular data within a CSV file comprising 10,000 rows and 4 columns as features. ChatGPT provided code for a customized data class in PyTorch, seemingly accurate. However, upon attempting to run the code for creating a train-validation dataset, as depicted in the initial prompt in Figure 7, errors surfaced.\nUpon inspection, we realized that the suggested approach by ChatGPT, while commonly used for train-validation splits, did not function correctly within the context of a customized dataset's Dataloader in PyTorch. Recognizing this discrepancy, we found that employing a different method (such as 'random_split' or 'SubsetRandomSampler') from the PyTorch library was necessary for successful execution. Our interaction with ChatGPT effectively guided us developing a CNN model. However, it is notable that despite its valuable assistance, hidden errors might exist highlighting the possibility of overlooking crucial details. Notably, ChatGPT omitted the necessity to encode categorical label data into a numerical format a requisite for the dataloader to function correctly. In subsequent interactions, when we flagged the code's inaccuracies, ChatGPT acknowledged the issue and provided a corrected version of the code.\nAssessment: ChatGPT showcases a range of cognitive abilities, including memorization, understanding, and higher-level thinking to apply acquired knowledge. Notably, ChatGPT offers a comprehensive set of codes that function effectively, streamlining the process of searching and comprehending information. However, while the solutions provided by ChatGPT are generally applicable, they may encounter difficulties in adapting to specific use cases. Hence, users should exercise caution when implementing the suggested code.\nRecommendations: ChatGPT offers a quicker way to grasp new concepts, but educators must recognize its limitations. While it accelerates information gathering, it can't replace higher-level skills like critical thinking. Combining its data with traditional resources is beneficial, yet true learning demands more than just information absorption. Relying solely on ChatGPT for learning poses risks, as demonstrated in a case study. Learners may use ChatGPT as a starting point for basic concepts. They should further deepen their understanding through critical analysis and creativity. By doing so, they turn ChatGPT's mistakes into opportunities for cognitive growth. However, spotting these errors might challenge undergraduates still mastering the fundamentals. Meanwhile, it provides an opportunity for educators to use unsatisfied responses as lesson materials and engage students with collective inquiries with step-by-step guidance in the classroom. For ChatGPT improvement, continuous training and collecting users' feedback for better problem-solving in specific situations is crucial.\n2) Weak Visualization Skill: We tasked ChatGPT with different data visualization assignments. Initially, we requested clustered column charts with error bars, depicted in the first prompt of Figure 8. While ChatGPT showed a good understanding of the chart type, the plotted graph had inaccuracies the error arrows did not correspond correctly to the error values and were inconsistently placed for all bars. In the second prompt, we asked ChatGPT to create PowerPoint slides explaining how Transformers work. Although it could generate extensive text content upon request for a description, its performance in creating slides was notably disappointing. The generated content lacked depth and completeness, resembling a preliminary outline drafted in a rush. Despite seeking further elaboration on Transformers' architecture, ChatGPT struggled to provide useful information. When prompted to include an architecture diagram, it produced a very abstract representation, affected by display issues such as overlapping elements and improper positioning of figures and text in the PowerPoint. From our observation, ChatGPT seems to generate diagrams based on its recall of abstract-level processes, attempting to code the components without delving into the detailed workflow of the architecture.\nAssessment: ChatGPT shows entry-level skills in data visualization. It struggles compared to humans using tools like Excel or PPT, where the human ability to combine existing and new knowledge surpasses its limitations. ChatGPT lacks seamless integration of its knowledge with external sources like search engines. Yet, it excels when prompted to generate code for standard graphs using libraries like scikit-learn and Matplotlib. Human creators can outperform ChatGPT in more complex tasks like multi-variant analysis and graph generation.\nRecommendations: Data visualization can be challenging due to its artistic nature and the need to convey meaningful information on the graph. ChatGPT can help by offering various visualization options and explanations. However, its limitations create an opportunity for educators. They can use ChatGPT's suggested plots as case studies in data analysis courses, discussing strengths and weaknesses with students to enhance their skills in this field. Some suggestions for enhancement include incorporating an option for ChatGPT to save the generated data and chart into an Excel file, allowing further editing. Additionally, enabling a search function could assist in consolidating information from various sources, enhancing the quality of generated slides. Training ChatGPT to understand blogs and concepts, could provide more insightful information. To address potential plagiarism concerns, ChatGPT could be trained to cite sources used in its responses.\n3) Oversimplified and Ineffective Response: We found that some of ChatGPT's responses were overly simplistic, and lacking practical usefulness and utility. For instance, as shown in Figure 9 when prompted to create an Entity-Relationship (ER) model for an online banking system, as commonly encountered in CS courses, ChatGPT generated a simple yet technically correct response. For this question, providing an ER diagram is essential. However, the lack of an expected ER diagram diminished its usefulness. In contrast to online resources that detail such designs with labeled cardinalities and relationship types, ChatGPT's performance fell relatively short of user expectations. Our second inquiry involves asking ChatGPT to design a database system for facial recognition applications. As depicted in the second prompt in Figure 9, the response merely presents a broad overview of the database system design without offering detailed guidance, code samples, or thorough explanations. Comparable online educational materials are notably more informative. Despite the abundance of available public content on the internet, it appears that ChatGPT cannot synthesize its existing knowledge into a comprehensive system design. It currently operates without a holistic intelligence, accumulating fragmented knowledge.\nAssessment: These questions demand high-order cognitive skills that involve applying, synthesizing, and creating knowl"}]}]}