{"title": "Bifurcation Identification for Ultrasound-driven Robotic Cannulation", "authors": ["Cecilia G. Morales", "Dhruv Srikanth", "Jack H. Good", "Keith A. Dufendach", "Artur Dubrawski"], "abstract": "In trauma and critical care settings, rapid and precise intravascular access is key to patients' survival. Our research aims at ensuring this access, even when skilled medical personnel are not readily available. Vessel bifurcations are anatomical landmarks that can guide the safe placement of catheters or needles during medical procedures. Although ultrasound is advantageous in navigating anatomical landmarks in emergency scenarios due to its portability and safety, to our knowledge no existing algorithm can autonomously extract vessel bifurcations using ultrasound images. This is primarily due to the limited availability of ground truth data, in particular, data from live subjects, needed for training and validating reliable models. We introduce BIFURC (Bifurcation Identification For Ultrasound-driven Robot Cannulation), a novel algorithm that identifies vessel bifurcations and provides optimal needle insertion sites for an autonomous robotic cannulation system. BIFURC integrates expert knowledge with deep learning techniques to efficiently detect vessel bifurcations within the femoral region and can be trained on a limited amount of in-vivo data. We evaluated our algorithm using a medical phantom as well as real-world experiments involving live pigs. In all cases, BIFURC consistently identified bifurcation points and needle insertion locations in alignment with those identified by expert clinicians.", "sections": [{"title": "I. INTRODUCTION", "content": "In trauma and critical care, adequate arterial and venous access can mean the difference between life and death [1]. Catheters allow for rapid administration of medications and fluids, live hemodynamic monitoring, and occasionally life support options through extracorporeal membrane oxygenation (ECMO) or resuscitative endovascular balloon occlusion of the aorta (REBOA). These options are essential for the optimal care of accident victims or individuals wounded in underserved areas or in combat scenarios [2]. Appropriate insertion of needles and catheters into central arteries and veins requires expert medical personnel, often working under adverse circumstances and time pressure. Since adequate access to experienced staff is not always possible, especially in mass casualty events, we develop an automated system that enables novice medical providers with limited training to initiate intravascular treatment safely and quickly.\nIdentifying the patient's anatomy is crucial for gaining intravascular access. According to Rupp's rule, the bifurcation of the common femoral artery into the superficial femoral artery and profunda femoris artery is a key anatomical landmark for safely performing femoral arterial and venous cannulation [3].\nGiven the importance of precise anatomical identification, ultrasound (US) imaging emerges as the optimal tool for navigating intravascular access in emergency and field care scenarios [4]. Its portability, versatility, affordability and ac- cessibility surpass other modalities such as X-ray, computed tomography (CT), or magnetic resonance imaging (MRI) [4]. Despite its potential, US-guided central access is rarely utilized in prehospital settings. Additionally, there has been limited effort to integrate autonomous robotic ultrasound scanning into minimally invasive procedures [5]. The key barrier is the lack of advanced US interpretation skills and expertise in image-guided needle placement among emer- gency medicine field personnel, exacerbating the risk of complications [6].\nWe automatically detect vessel bifurcations using a robotic ultrasound system. Below, we summarize the key contribu- tions of our work:\n1) To accurately and autonomously identify vessel bifur- cations, we propose the first method to create a 3D vessel skeletonization using a linear ultrasound probe.\n2) The first algorithm to automatically detect an optimal needle insertion point in the femoral area.\n3) Evaluation on a greater number of real-world instances vs. any other machine learning study of needle inser- tion in the femoral vessel using ultrasound."}, {"title": "II. BACKGROUND AND RELATED WORK", "content": "Although research on autonomous needle insertion with ultrasound in femoral vessels is limited [7], some advance- ments have been made in related areas, such as femoral vessel visualization techniques [5], [8], [9], segmentation uncertainty [10], vessel deformability [11], and needle track- ing [12], [13]. Despite those developments, identifying the optimal needle insertion site remains an underexplored and novel area of investigation. We draw insights from three review papers on medical imaging and vessel segmenta- tion [14], [15], [16]. Our approach is inspired by the per- formance boost observed when deep learning techniques are integrated with manually crafted features, rather than relying solely on one methodology.\n1) Autonomous and Semi-Autonomous Robotic Systems for Optimal Needle Insertion Location: Chen et al. pre- sented a benchtop system combining infrared and ultrasound technologies alongside deep learning algorithms to aid in needle selection and insertion [17]. However, unlike our approach, their system predominantly targeted peripheral vessels near the skin's surface. This is also seen in [18]. Consequently, they leveraged infrared imaging to visualize the vessel structure beneath the skin but lacked the ability to address larger, deeper vessels essential for critical medical procedures. This limitation was similarly noted in Cheng et al.'s Cathbot proposal, which required practitioner interven- tion and encountered comparable restrictions [19].\nIn contrast, AI-GUIDE, a semi-autonomous device aimed at assisting users with femoral US-guided vascular catheteri- zation [20], showed promising outcomes on three pigs. How- ever, AI-GUIDE relies primarily on classification techniques to detect vessel bifurcations, which does not utilize temporal data. In our preliminary tests, we encountered limitations with the multiclass classification YOLO model employed by AI-GUIDE, yielding an average intersection over union (IoU) in vessel detection of 0.23, as seen in Table III, which is insufficient for vessel identification purposes. Instead, our approach relies on segmentation and reconstruction, which enhance its ability to accurately identify bifurcations. It is important to note that AI-GUIDE's reliance on human intervention introduces the potential for errors, a factor that our fully automated system seeks to address.\n2) Vessel Extraction: Vessel extraction involves outlining blood vessels in medical images for analysis. Although research has largely focused on stationary imaging modalities such as CT, MRI, and X-rays [16], automated US segmen- tation faces distinct challenges. US images are frequently affected by issues like speckle noise, shadowing, and in-complete boundaries [14], which can obscure vessel outlines and hinder delineation of vessel boundaries and centerlines. Moreover, although some methods for extracting vessels using ultrasound exist as in [5], they are typically limited to phantoms and do not effectively address more advanced capabilities such as autonomous identification of bifurcations, as shown in [9].\n3) Vessel Tracking: Vessel tracking refers to the process of locating and monitoring the movement or trajectory of vessels within the human body. Vessel tracking is important for medical procedures including catheterization [15], [16], [21]. Several algorithms have explored Kalman filters (KFs) to refine tracking accuracy [9], [22], [23]. However, KFS introduce spurious data points which can hinder downstream tasks, such as bifurcation identification and optimal needle insertion point detection. Some other studies model 3D geometry information using Bayesian 3D U-Net models. But these models are computationally expensive and have lower IoU scores in comparison to 2D techniques (cf. Tab. III). Recognizing the computational hurdles with the implementation of deep learning 3D models, particularly in embedded systems, underscores the need for innovative ap- proaches [24]. We propose training 2D deep learning models while utilizing 3D structural information captured at multiple robot poses. This approach aims to mitigate computational burdens and improve the performance of portable, fully autonomous, and quasi-real-time systems for vessel tracking.\n4) Spatio-Temporal Information for Vessel Bifurcation Identification: The US technology presents a significant advantage over other imaging modalities due to its capacity to generate real-time video. Within fields such as echocar- diography and obstetrics, the integration of machine learning techniques to support interpretation of US data has become increasingly prevalent, leveraging spatio-temporal data to enhance diagnostic accuracy and treatment outcomes [14]. While video clips offer a richer source of information com- pared to individual image frames, there is a notable gap in re- search regarding their application in identifying bifurcations, a technique commonly employed by clinicians [25]. We aim to address this gap by harnessing robot poses and timestamps to reconstruct vessels, thereby incorporating the temporal aspect. By discerning the origin of vascular branches and tracking their progression over time of scan, our method seeks to improve the identification of vessel bifurcations.\n5) Real vs. Synthetic Data: Limited availability of US data poses a significant challenge for machine learning appli- cations, especially with limited research focus on the femoral area [14]. When data is scarce, alternative imaging modalities often resort to training on data from physical or digital simulations, which may not generalize well to real-world ultrasound images [26]. Synthetic data may lack crucial realistic features found in reality, such as accurate waveform source signatures, realistic noise, and precise reflectivity, leading to notable discrepancies between datasets [26]. To address this, we conduct testing on both phantom and real- world data, noting significant differences between them. Phantom data tends to be cleaner, with less densely packed vessels compared to real-world scenarios. Consequently, we use phantom data for experiment development and validate our findings using real-world data."}, {"title": "III. METHODS", "content": "We combine deep learning techniques with anatomically inspired heuristics to develop an algorithm capable of iden- tifying bifurcations and recommending optimal needle inser- tion points. An overview can be seen in Figure 2.\nA. Vessel Segmentation\nIn response to the scarcity of extensive and high-quality US images, we utilize the RESUS algorithm developed by Morales et al. [27] for vessel segmentation. RESUS particularly excels in limited datasets such as the one we are working with.\nAlthough RESUS yields satisfactory IoU results with our data, it is not without limitations, occasionally exhibiting segmentation inaccuracies and noise artifacts. It also faces a specific challenge when two vessels are placed in close proximity, effectively merging them into a single segmented object. This situation poses a substantial risk, especially in the context of bifurcation identification, as it becomes increasingly challenging to differentiate be- tween cases where vessels are adjacent and those where they genuinely bifurcate. If the segmentation process merges these adjacent vessels, crucial differentiation becomes nearly impossible, which motivates the use of spatiotemporal infor- mation.\nThis problem introduces significant risk when considering needle insertion procedures. When attempting to insert a needle between two vessels aligned in parallel, the risk of inadvertently damaging vessel walls escalates, potentially resulting in the formation of hematomas. The occurrence of such hematomas can have dire consequences for patient safety.\nB. Centerline Prediction\n1) Erosion: To address the issue of adjacent vessels appearing merged, and to remove artifacts and small vessels, we employ an erosion algorithm to post-process the outputs of the segmentation model. The algorithm iteratively removes boundary pixels around the segmented vessels. To do this, we compute the convolution of the segmentation map with a 3 \u00d7 3 kernel with all values 1, scale the result into [0, 1], then binarize by thresholding at 0.5. This is repeated until the radius of the minimum enclosing circle is smaller than stopping criterion $\\delta\\epsilon$ for all segments. Additionally, in scenarios involving distinct vessels, the algorithm aids in their separation, making them easily distinguishable from bifurcations.\n2) Vessel Detection: We use the center of the minimum enclosing circle as the position for each segment. To filter out remaining noise, we remove any segment where the radius of the circle is less than noise threshold $\\delta\\eta$.\n3) Vessel Tracking: Vessel tracking involves grouping center points into distinct tracks to represent their spatial configuration. To begin this process, we first transform the vessel centers into temporally arranged 3D point coordinates using the robot pose. Then, we iterate over the timesteps and group these points into tracks to discern individual vessels. Initially, each point in the first frame corresponds to a separate track. Subsequently, new points in each frame are assigned to existing tracks, aiming to minimize the Euclidean distance between the new points and the last point incorporated into the track. Each track can accomodate at most one new point per frame, and this assignment is efficiently computed using the Hungarian Algorithm [28]. A track is terminated if it remains unassigned for five consecutive frames, and if a point cannot be assigned to a new track within a specified threshold distance $d_{td}$, a new track is initiated with that point. Tracks with a length of fewer than five center points are discarded. Finally, the tracks are denoised: each track's points are clustered using the Density Spatial Clustering of Applications with Noise (DBSCAN) algorithm [29]. Any outliers identified through this process are subsequently removed from the track.\n4) Merging Tracks: We merge the identified tracks based on a set of medical heuristics designed in collaboration with physicians. Our algorithm involves minor adjustments, when applied to a medical phantom, as opposed to real-life pigs, due to inherent disparities, discussed in II-.5.\nFor each track, we compute a least squares line in 3D space that characterizes its center line. The least squares line is\n$P_n(t_n) = S_n+t_nV_n$\nwhere $t_n$ ranges over all real numbers, $S_n$ is the mean of the points that describe the track, and $V_n$ is the first principal component of differences from the mean, which we obtain by singular value decomposition."}, {"title": "C. Identifying Bifurcations", "content": "Bifurcations are identified through an iterative search within each track, checking if any pair of points meet the following criteria:\n1) Time between the points is less than $d_t$.\n2) Distance between the points is less than $\\delta_{bb}$.\n3) The points originate from different tracks before merg- ing.\nD. Identifying the Needle Insertion Point\nGiven that the robot consistently scans from proximal to distal, the needle insertion spot will be cranially positioned relative to the bifurcation point. Thus we choose the point on the track closest to 2cm away from the bifurcation in the cranial direction."}, {"title": "IV. EXPERIMENTS", "content": "A. Data set\nWe test BIFURC on both simulated and real-world data. Simulated data was collected from a medical imaging phan- tom based on the CAE Blue Phantom anthropomorphic gel model\u00b9. Following successful validation on the phantom, we proceeded to implement our method in a surgical environ- ment at the University of Pittsburgh Medical Center (UPMC) with live pigs under anesthesia. Although stable at the time of collection, the pigs had previously undergone experiments involving hemorrhage and resuscitation, which left them in a weakened state. As a result, their vessels were more closely representative of those encountered in an emergency scenario. These experiments involving live animals were conducted in accordance with the Institutional Animal Care and Use Committee (IACUC) protocol approved by the cog- nizant authority. We collected 2D ultrasound images of the femoral vessels of six different pigs using a 6-DoF Universal Robot UR3e serial manipulator, as shown in Figure 4, to autonomously move the probe used for scanning. The Fukuda Denshi portable point-of-care scanner (POCUS) probe, with a 5MHz linear transducer and a maximum depth of 5cm, was operated at a constant velocity of 0.05m/s, and the US images were recorded at 30 frames per second. An expert surgeon was present during the experiments to ensure the quality of the ultrasound images. Five expert clinicians labeled vessels, bifurcation points, and a needle insertion range using the Computer Vision Annotation Tool (CVAT) [31], ensuring intra-rater reliability in the annotation process. Finally, we used Robot Operating System (ROS) [32] to capture time-synchronized robot poses and ultrasound images.\nThe system calibration is conducted once after assembling the robot and does not need to be repeated before each subject. It starts with a preliminary calibration using a robot CAD model to align the robot with the ultrasound system. For refinement, we use a mock phantom with known geometry, containing wires immersed in water, and track these wires with Gaussian fitting to accurately determine their positions in ultrasound images. The robot then follows a predefined trajectory over the wire phantom to calibrate both the time delay between the robot's movements and the ultrasound measurements, and the transformation between the ultrasound and robot coordinate systems. This process involves computing a transformation matrix to align the ultrasound coordinates with those of the robot and optimizing this matrix to reduce the error between the projected and actual wire positions.\nB. Training\nTo segment vessels from US images, we used a U- Net architecture with a ResNet34 [33] backbone as the encoder, following the methodology outlined in Morales et al. [27]. This implementation utilized the Segmentation Mod- els library [34]. We train our network on lower resolution (256x256) images, using Dice loss until convergence. We use a batch size of 8, learning rate of le- 4 and Adam Optimizer [35] for training. These models were trained on a cluster with NVIDIA RTX A6000 GPUs with 48 GiB RAM. We evaluate our models using the leave-one-subject- out cross-validation protocol, in which each pig's data is used once as a test set, while data from the remaining pigs form the training set. RESUS [27] augmented images are only used for training. To avoid overfitting, the images resliced from the test pig imagery are removed from the training set."}, {"title": "V. RESULTS AND ANALYSIS", "content": "We evaluate BIFURC using a combination of qualitative and quantitative assessments. Table II presents a summary of our results. The IoU score represents the accuracy of vessel segmentation relative to expert annotations. Bifurcation error quantifies the Euclidean distance between the predicted bifurcation locations within the vessel, and the corresponding ground truth labels provided by expert clinicians. The time column denotes the time it takes our model to identify bifurcations and optimal needle insertion points. Furthermore, we provide the mean and standard deviation of these metrics across the evaluated pigs and phantom. Below, we outline some key observations.\nBIFURC effectively identifies optimal needle insertion points using US images. We test on six pigs and one phantom. On pigs, BIFURC achieved an 85.7% success rate in identifying and localizing bifurcations. The error is due to the single false positive; however, even in this instance, the system identified a range that would lead to an optimal needle insertion site. Remarkably, throughout the trials, our robot consistently reported a needle insertion location within the range reported by clinicians. Each identification took an average of 2.61 seconds. Scanning time is not included in this duration. For pig legs, the scanning process typically takes 3-4 seconds. For humans, considering that the common femoral artery is usually about 4 cm long [36] and the robot scans at a speed of 0.05 m/s, we estimate the scanning time to be around 2-3 seconds, which aligns with preliminary experimental results. Additionally, experiments indicate that the robot may require another 1-2 seconds for needle insertion. Therefore, the total time is significantly less than the 185 \u00b1 175 seconds that human experts need for the entire procedure, including both scanning and needle insertion [37]. For context, human experts have an initial success rate of 83%, but this rate also reflects the overall procedure, including needle insertion. Experts typically make 1.3 attempts per procedure, which affects their success rate. Since BIFURC focuses solely on identifying the optimal insertion points and does not perform needle insertion, it provides a more specific metric of its performance in pinpointing the exact site. BIFURC's average algorithmic deviation from actual bifurcation points is 7.66 mm, with the optimal insertion site usually 2-5 cm away from the bifurcation [3]. This indicates that BIFURC is both efficient and accurate in identifying insertion sites, offering significant improvements in time efficiency compared to human experts and the potential to aid practitioners at various experience levels to achieve near-expert performance.\nNoise in real-world data affects vessel segmentation performance. A mean IoU of 0.66 across all pigs is a reflection of the noise present in the segmentations. In a qualitative assessment, we reconstruct the vessel centerlines and visually inspect our predicted bifurcation points to ensure they accurately correspond to the bifurcation areas. Although certain instances, such as Pig 5, exhibit larger deviations, we hypothesize that these anomalies may be attributed to segmentation noise, which can occasionally create speckle-like artifacts that influence the algorithm's accuracy.\nOur estimated hyperparameters generalize across most pigs. Through empirical experiments, we discovered a set of hyperparameters that generalize across the majority of the data, as shown in Table I. We made only slight adjustments to the parameters for bifurcation identification and the kernel erosion algorithm due to the inherent variations in noise levels and spatial arrangements of vessels between phantoms and pigs. Also, we made minor adjustments to the bifurcation identification hyperparameters for Pig 4, as physicians noted its vessels displayed highly distinctive shapes, classifying it as abnormal.\nRESUS outperforms other segmentation methods. To justify our choice of RESUS, we conducted a comparative analysis on our chosen segmentation algorithm against al- ternative segmentation algorithms used by prior work [38], [20]. Specifically, we evaluate segmentation outcomes on several pigs using leave-one-subject out cross-validation. Our results in Table III revealed that, while segmentations were not perfect, RESUS consistently outperformed other methods in terms of segmentation quality."}, {"title": "VI. CONCLUSION", "content": "We leverage domain expertise in developing heuristic- based algorithms integrated with deep learning methods to produce novel results on the problem of vessel bifurcation identification. Our work has several limitations. Firstly, it currently lacks the ability of multi-class segmentation, and the tracking performance is not yet ideal. This is mainly due to the intrinsic cylindrical shape of the vessels, which poses challenges in feature extraction, making differentiation be- tween the arteries and veins a complex task. We recommend using Doppler US and pressure sensing to enable accurate vessel type identification by estimating intravascular pres- sure. Further, our experiments involve anesthetized animals, minimizing subject movement during procedures. We have not studied the potential impact of minor movements on the optimality of the inferred needle insertion points, but in practice, one can perform a final check just before insertion to verify the continued accessibility of the target vessel. Lastly, our current in-vivo dataset is modest in size, having a limiting impact on the generalizability and, potentially, effectiveness of our segmentation algorithm. For future work, we plan to increase our subject sample size, explore multi-class segmentation, and study vessels in various anatomical regions to improve the generalizability of the algorithm. Additional factors to consider include tissue deformation during needle insertion, as well as insertion angle and force. They are key to creating a precise and safe intravascular access system. To further assess the reliability and accuracy of the model, we consider incorporating additional validation methods, including CT scans of the same test subjects. Finally, we plan to explore the cognitive burden that the proposed automation may impose on its users."}]}