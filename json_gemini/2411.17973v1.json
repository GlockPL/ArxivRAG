{"title": "Improved implicit diffusion model with knowledge distillation to estimate the spatial distribution density of carbon stock in remote sensing imagery", "authors": ["Zhenyu Yu"], "abstract": "The forest serves as the most significant terrestrial carbon stock mechanism, effectively reducing atmospheric CO2 concentrations and mitigating climate change. Remote sensing provides high data accuracy and enables large-scale observations. Optical images facilitate long-term monitoring, which is crucial for future carbon stock estimation studies. This study focuses on Huize County, Qujing City, Yunnan Province, China, utilizing GF-1 WFV satellite imagery. The KD-VGG and KD-UNet modules were introduced for initial feature extraction, and the improved implicit diffusion model (IIDM) was proposed. The results showed: (1) The VGG module improved initial feature extraction, improving accuracy, and reducing inference time with optimized model parameters. (2) The Cross-attention + MLPs module enabled effective feature fusion, establishing critical relationships between global and local features, achieving high-accuracy estimation. (3) The IIDM model, a novel contribution, demonstrated the highest estimation accuracy with an RMSE of 12.17%, significantly improving by 41.69% to 42.33% compared to the regression model. In carbon stock estimation, the generative model excelled in extracting deeper features, significantly outperforming other models, demonstrating the feasibility of Al-generated content in quantitative remote sensing. The 16-meter resolution estimates provide a robust basis for tailoring forest carbon sink regulations, enhancing regional carbon stock management.", "sections": [{"title": "Introduction", "content": "Given the increasing threat of global climate change, human activities pose unprecedented challenges to Earth's ecosystems\u00b9. As a result, forest resource management and use have become primary concerns for researchers and policymakers worldwide\u00b2. Forest ecosystems provide a variety of ecological services and play a crucial role as regulators of the global carbon cycle, contributing significantly to climate change mitigation\u00b3. It is imperative to monitor and quantify the temporal and spatial variations in regional carbon stocks to understand the dynamics of forest carbon sources and sinks and to develop effective regulatory strategies4,5.\nForest carbon stock monitoring is increasingly integrating ground-based sample data with satellite remote sensing observations6\u20139. While ground monitoring provides precise data, it is hindered by time-consuming and labor-intensive processes, making it impractical for large-scale observations10,11. In contrast, remote sensing inversion methods offer a viable solution by overcoming the limitations of sample-based monitoring, enabling more efficient and accurate monitoring with continuous improvements12,13. Spectral information-based methods can infer vegetation growth status and identify vegetation types within ecosystems, aiding in estimating carbon stocks. However, despite their high accuracy, these methods often struggle to explore intricate nonlinear relationships due to image quality issues, resulting in limited improvements in estimation accuracy14.\nMethods based on structural information can directly measure biomass and carbon stock, but their effectiveness is constrained by the resolution and coverage of remote sensing images10. Physical model-based approaches estimate the carbon stock by developing carbon-cycle models that simulate the carbon sink and cycle processes within ecosystems. Although this method can account for the variations and complexities of different ecosystems, it requires precise ecological parameters and robust data support15. Conversely, machine learning-based methods uncover deeper relationships between image data and carbon stock, enabling rapid and efficient estimates16,17. Integrating sample monitoring data with remote sensing data to establish a universal and high-precision remote sensing monitoring model for regional forest carbon stock has become an urgent priority.\nIn summary, we have successfully reframed the carbon stock estimation problem as an image translation task and utilized the implicit diffusion model as our foundational network structure. Using GF-1 WFV satellite imagery as the primary data source and adapting our methodology to the specific characteristics of Huize County, we achieved precise estimations of the regional carbon stock distribution density. This work provides a critical theoretical foundation for informing forest carbon sink regulation strategies and decision-making. Our main contributions include:"}, {"title": "Related work", "content": "Key issues in carbon stock estimation\nData selection. Ground monitoring, while providing precise data, is impractical for large-scale observations due to its labor-intensive and time-consuming nature10,11. Remote sensing inversion methods mitigate these issues, improving both efficiency and accuracy12,13. Among the most promising remote sensing resources for additional data sets are medium-resolution (10~30 m) optical data. The long operational lifetimes of these satellites make them ideal for continuous monitoring of forest dynamics18. When utilizing multispectral images as data sources, carbon stock calculations have mainly focused on estimating biomass and stock, with relatively few studies directly estimating carbon stock from image data.\nMethod selection. Zhang et al.19 combined ground observations, MODIS, GLAS, climate, and terrain data with the random forest algorithm to generate a 1 km resolution aboveground biomass map for China, achieving an interpretability of 75% and an RMSE of 45.5 Mg/ha. Puliti et al.18 estimated the total change in forest aboveground biomass over approximately 1.4 million hectares in northern Norway using National Forest Inventory (NFI), Sentinel-2, and Landsat data. Chopping et al.20 estimated aboveground biomass in the southwestern U.S. from 2000 to 2015 using the Multi-angle Imaging Spectro Radiometer (MISR), achieving an RMSE of 37.0 Mg/ha. Despite the detailed spatial features and rich surface texture information provided by medium-resolution remote sensing images, these images typically have limited spectral bands, and existing carbon stock data products usually exhibit low resolution. Therefore, the key to accurately estimating carbon sinks lies in developing effective algorithms capable of extracting deep-seated features.\nChallenges for quantitative remote sensing\nOne of the most significant challenges in quantitative remote sensing is effectively managing complex non-linear relationships to improve data accuracy 21,22. Although remote sensing inversion methods can efficiently monitor and estimate forest carbon stocks, they still face obstacles such as poor image quality and complex identification of vegetation growth and types. Consequently, there is a need for the development of new techniques and methods in quantitative remote sensing to address these issues and improve the accuracy and efficiency of data processing and estimation21,23.\nDeep learning surpasses traditional machine learning methods in data processing capabilities, automated feature learning, and generalization, making it well-suited for handling complex, high-dimensional big data and achieving superior performance in various tasks21,24. This paper investigates the feasibility of integrating quantitative remote sensing with computer vision, using generative modeling in deep learning as a case study. We explore how combining these fields can enhance data processing and analysis in quantitative remote sensing.\nThe Intersection of Quantitative Remote Sensing and Computer Vision\nThe widespread adoption of deep learning techniques has enabled the extraction of deep-seated features to their fullest potential, leading to significant improvements in accuracy10,25,26.\nMachine learning. Many current studies have utilized traditional machine learning methods such as Ordinary Least Squares (OLS), Random Forest (RF), and Support Vector Regression (SVR)21,24,27. While these methods are straightforward and efficient, their estimation accuracy is often limited. The application of deep learning methods in carbon stock estimation remains relatively unexplored. Deep learning models, particularly generative models, have the ability to generate new samples, enhance data utilization, improve model generalization, and address issues related to insufficient or incomplete data, making them well-suited for carbon stock estimation. Generative models aim to model the distribution of real data by learning from multi-modal data using implicit variable techniques.\nGenerative model. The Generative Adversarial Network (GAN), proposed by Goodfellow et al.28, comprises generators and discriminators that engage in adversarial training to produce high-quality samples. However, GAN training can be unstable and prone to mode collapse, requiring careful parameter tuning and attention throughout the training process. Variational Autoencoders (VAE), proposed by Kingma and Welling29, enhance sample continuity and controllability by learning a continuous latent space. Despite this, VAEs often underperform compared to GANs in generating high-quality, realistic samples, possibly due to the vagueness inherent in their latent space."}, {"title": "Diffusion model", "content": "The diffusion model, first introduced in 201530, aims to progressively remove Gaussian noise from training images, functioning similarly to a series of denoising autoencoders. Variants like the Latent Diffusion Model (LDM) train autoencoders to map images into low-dimensional latent spaces. The diffusion model excels in generating high-quality samples with flexibility, stability during training, and resistance to mode collapse, effectively bridging the gaps between GANs and VAEs by combining their strengths. Subsequent models such as DDPM31, DDIM32, and Stable Diffusion33 have extended the diffusion model's applications to image generation, consistently achieving state-of-the-art (SOTA) results. These models have been widely applied in image translation tasks. Building on these advancements, we applied the diffusion model structure to estimate carbon stock in remote sensing images, aiming to achieve improved accuracy in this domain."}, {"title": "Materials", "content": "Study area\nHuize County is part of Qujing City, Yunnan Province, China, located at the intersection of Yunnan, Sichuan, and Guizhou Provinces. Covering an area of 5,889 km\u00b2 (Figure 1), Huize features a ladder-shaped terrain with higher peaks in the west and lower valleys in the east. The county experiences a typical temperate plateau monsoon climate, with climates ranging from subtropical in the south to cold temperate in the north. Elevations vary widely, from the highest peak at 4,017 m to the lowest point at 695 m. According to Forest Management Inventory data, Huize County has approximately 3,080.53 km\u00b2 of forest land, with arbor forest land covering approximately 2,538.20 km\u00b2 (82.39%). Rich in forest resources, Huize provides diverse research samples, although its complex landscape poses significant challenges.\nData sources\nSurvey data. The study utilized 2020 data from the Forest Management Inventory obtained from the Huize County Forestry and Grass Bureau. This comprehensive data includes over 70 attributes such as forest area and type, providing an objective overview of forest resources. It aids in understanding and evaluating the status, trends, distribution, and ecological environment"}, {"title": "Methods", "content": "Pre-processing\nPre-processing procedures are described in Appendix Section 1. The pre-processing process includes carbon stock & distribution density calculation, and forest/non-forest areas identification.\nKnowledge distillation (KD) module\nThe Knowledge Distillation (KD) module consists of four parts, and a detailed description is provided in Appendix Section 2.\nSource model. VGG-19 was selected as an illustrative model for our approach. In this context, the input layer of VGG-19 served as the source model, denoted as ENC, from which the knowledge of the features was extracted. Subsequently, this knowledge was transferred to a smaller target model, referred to as enc. The architecture of the enc model mirrored that of the source model (ENC), albeit with a reduced channel length at each layer.\nGlobal eigenbases. We adopted a global image-independent eigenbase denoted as $W_{N,g} \\in R^{C_W \\times C_N}$. In essence, we established a distinctive $C$-dimensional space adept at effectively encapsulating the overarching global features present in the image, as evidenced by Eq. 8."}, {"title": "Implicit representation", "content": "Presently, prevalent algorithms often rely on intricate cascading or two-stage training procedures. However, our research discovered that the use of implicit neural representations for image representation learning notably enhanced estimation accuracy. To implement this, we incorporated several coordinate-based Multi-layer Perceptrons (MLPs) into the up-sampling stage of the UNet architecture, thereby enabling the parameterization of implicit neural representations. We employed a two-layer MLP denoted as $D$ to perform up-sampling."}, {"title": "Improved implicit diffusion model (IIDM)", "content": "The Implicit Diffusion Model (IDM) combined diffusion models and implicit neural representations for image-to-image transformation. The Improved Implicit Diffusion Model (IIDM) workflow is shown in Fig. 3. We used a Recurrent Neural Network (RNN) to create a time-dependent structure with shared parameters, including a denoising and implicit representation model, employing variational inference. Unlike Variational Autoencoders (VAE), the implicit variables in diffusion models have the same dimensionality as the original data, with a predefined and fixed diffusion process.\nThe Diffusion principle's derivation of forward and reverse processes is shown in Appendix Section 3. The diffusion model included two processes: the diffusion process (that is, the forward process) and the reverse process. Both the forward and reverse processes were a parameterized Markov chain, in which the reverse process can be used to generate data.\nThe added KD-VGG module can extract the shallow features of x and yt, which are then passed into KD-UNet for encoding and decoding to reconstruct the spatial distribution density image. The concatenation of f\u2070 and yt enables real-time updating of the model, i.e., updating with the change of t. Cross-attention effectively handles the relationship between the two features, facilitating their fusion. The multi-layer perceptron (MLP) merges the condition and features, increasing the influence of the condition on the parameters and speeding up the fitting process."}, {"title": "Optimization", "content": "The implicit diffusion model aimed to infer the target image yo using a series of denoising steps. To achieve this, the denoising model $\\varepsilon_{\\theta}$ was optimized to restore the target image yo from a noisy target image $\\tilde{y}_t = \\sqrt{\\gamma} y_0 + \\sqrt{1 - \\gamma} \\varepsilon$. To achieve this, the denoising model $\\varepsilon_{\\theta}$ was optimized to restore the target image yo from a noisy target image $\\tilde{y}_t = \\sqrt{\\gamma} y_0 + \\sqrt{1 - \\gamma} \\varepsilon$. Ultimately, the denoising network was optimized to achieve the goal while maintaining the accuracy of the predicted noise e, as shown in Eq. 4."}, {"title": "Evaluation metrics", "content": "Mean Absolute Error (MAE) measures the average absolute error between predicted and actual values. Mean Squared Error (MSE) is the average squared error, and Root Mean Squared Error (RMSE) is the square root of the MSE. Peak Signal-to-Noise Ratio (PSNR) and Structural Similarity Index Metric (SSIM) are full-reference image quality indices, with PSNR assessing overall image quality and SSIM evaluating similarity in brightness, contrast, and structure."}, {"title": "Results", "content": "Inference time\nWe used 256 \u00d7 256 images, and the test results included seven models (as shown in Appendix Table A3): VGG, KD-VGG, Stable Diffusion (SD), DDPM, DDIM, Ours-VGG, and Ours-KD-VGG. DDPM, DDIM, and SD were diffusion models with more than 450M parameters. Adding modules for improved accuracy could lead to high system overhead and reduced feasibility, prompting a discussion on the justification for such additions."}, {"title": "Model compression", "content": "KD-VGG.\nDuring the distillation process, principal components with a cumulative contribution rate higher than 85% were selected to maximize effective information extraction unsupervisedly. This enabled channel dimensionality reduction, decreasing model parameters. VGG initially presented an increasing channel length, which was reduced after dimensionality reduction. This indicated that deeper layers had more invalid channels, and reducing these channels effectively decreased parameters with minimal impact on accuracy. This is likely because most effective features are extracted in the middle layers, while deeper layers do not require such complexity. VGG-11, VGG-16, and VGG-19 all showed improved performance with deeper layers.\nKD-UNet.\nPCA performed dimensionality reduction based on feature transformations and spatial mapping, while PCA-based distillation was interpretable and generalizable and can be used for model compression of other network structures. IDM contained the UNet structure, and we applied this to the UNet with a view to maximize the compression of diffusion models."}, {"title": "Ablation study", "content": "Five modules were selected for the ablation experiment: Mask, VGG, KD-VGG, KD-UNet and Attention + MLP, detailed in Table 1. Mask filtered vegetation and non-vegetation areas effectively, serving as the initial data preprocessing stage. VGG and KD-VGG modules were employed for the initial extraction of features, with a comparable performance observed between KD-VGG and VGG models. However, VGG slightly outperformed KD-VGG, highlighting the effectiveness of knowledge distillation in extracting critical model parameters while indicating areas for further enhancement. Introducing attention and MLP modules resulted in improved model performance, albeit with increased computational influence time. The results indicated a significant accuracy enhancement after the integration of the modules, confirming the optimization achieved through the joint use of the KD-VGG and Attention + MLP modules. Thus, the strategy of prioritizing accuracy over computational time proved beneficial."}, {"title": "Comparison of different models", "content": "We selected seven comparison models, including commonly used regression models in remote sensing estimation (OLS, RF, and SVR), and deep learning generative models (VAE, GAN, and IIDM proposed in this paper). The results are presented in Table 2. OLS was the simplest and least computationally expensive algorithm among all models. RF and SVR were the most widely used machine learning algorithms for estimation. However, the accuracy of these three algorithms was similar and generally poor in all models. The accuracy of deep learning algorithms was significantly better, with generative models outperforming VAE and diffusion models outperforming GAN. Among all models, IDM-VGG achieved the best performance,"}, {"title": "Comparison with existing products", "content": "The abundant forest resources provide a solid research foundation, but its varied altitude complicates precise carbon stock calculations. Current estimation methods using satellite imagery are divided into optical imagery and LiDAR. Although LiDAR offers high accuracy, it faces challenges in large-scale applications and data acquisition. Optical imagery, particularly from GF-1, overcomes these issues, making high-precision carbon stock estimation a key research challenge.\nTraditional multi-spectral carbon stock estimation has relied on machine learning models like OLS, RF, and SVR, which mainly extract linear and shallow nonlinear features. The complex relationship between spectral/textural features and biomass/carbon stock is nonlinear. To address this, we introduced the IIDM algorithm, which extracts deeper features using a deep learning diffusion model, integrating VGG for initial feature extraction, Attention + MLP for feature fusion, and a Mask for non-vegetation area filtering.\nThe IIDM model significantly improved the estimation accuracy (RMSE = 12.17 Mg/ha), outperforming the LiDAR-based methods (RMSE = 25.64 Mg/ha) and multisource coarse resolution imagery-based methods (RMSE\u224830 Mg/ha)46,47. These results highlight the effectiveness of artificial intelligence generated content (AIGC) in remote sensing image-based land surface parameter estimation."}, {"title": "Conclusion", "content": "Our study focused on Huize County, using GF-1 WFV images and a deep learning generative diffusion model enhanced by knowledge distillation. This approach integrated the VGG module for initial feature extraction, followed by cross-attention + MLPs for feature fusion, and a mask to filter non-vegetated areas, resulting in the IIDM model for accurate regional carbon sink estimation. Key findings include:\nKnowledge Distillation-Based Module: By incorporating VGG-19 into the diffusion model for initial feature extraction, the IIDM model reduced inference time, increased accuracy, and minimized model parameters.\nFeature Fusion with Cross-Attention + MLP: This method improved carbon stock estimation accuracy by establishing relationships between global and local features, with only a slight increase in inference time, which remained shorter than other diffusion models."}, {"title": "Discussion", "content": "Simplify temporal and spatial complexity\nPCA, a widely used data transformation method, primarily focuses on dimensionality reduction by identifying principal components. It transforms original data into a new coordinate system, preserving variance while reducing dimensionality. PCA"}]}