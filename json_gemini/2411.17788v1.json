{"title": "Geometric Point Attention Transformer for 3D Shape Reassembly", "authors": ["Jiahan Li", "Chaoran Cheng", "Jianzhu Ma", "Ge Liu"], "abstract": "Shape assembly, which aims to reassemble separate parts into a complete object, has gained significant interest in recent years. Existing methods primarily rely on networks to predict the poses of individual parts, but often fail to effectively capture the geometric interactions between the parts and their poses. In this paper, we present the Geometric Point Attention Transformer (GPAT), a network specifically designed to address the challenges of reasoning about geometric relationships. In the geometric point attention module, we integrate both global shape information and local pairwise geometric features, along with poses represented as rotation and translation vectors for each part. To enable iterative updates and dynamic reasoning, we introduce a geometric recycling scheme, where each prediction is fed into the next iteration for refinement. We evaluate our model on both the semantic and geometric assembly tasks, showing that it outperforms previous methods in absolute pose estimation, achieving accurate pose predictions and high alignment accuracy.", "sections": [{"title": "1. Introduction", "content": "Shape assembly aims to combine parts or fragments to create a complete 3D object, with applications in fields such as robotics [46, 47], bone reconstruction [23, 42], archaeology [4, 11], and manufacturing [34]. This task is challenging and requires expertise in understanding mechanical structures and accurately matching components, making it prone to errors. Broadly speaking, shape assembly can be divided into two tasks: semantic part assembly and geometric fractured assembly. Semantic assembly [16, 17, 48] involves assembling meaningful parts, such as the legs and handles of a chair, into a complete structure by using both geometric clues to understand part functions and semantic information to determine their positions. In contrast, geometric assembly [32, 40] focuses on reassembling objects that have been broken by external forces, such as putting together fragments of a bowl, where only geometric information (e.g., shapes and textures) is available, without semantic labels for individual parts.\nWith the release of large-scale 3D datasets like Part-Net [21] and Breaking Bad [32], shape assembly methods have evolved from traditional geometric matching based on hand-crafted features [11, 24] to more advanced deep learning approaches [2, 8, 16, 22, 35, 48]. In these modern methods, each part is represented as a point cloud in 3D space. Typically, an encoder extracts part-level features from each point cloud, which are then used to predict the 6-DoF (Degrees of Freedom) pose for each part, including rotation and translation vectors to align the part in its target position. Architectures for predicting these part-level poses include multi-layer perceptrons, LSTMs, and graph neural networks (GNNs) [29, 33, 39]. To improve regression accuracy and placement precision, recent approaches also explore techniques such as equivariant representations [39], generative modeling [3, 18, 28], and the application of prior knowledge and post-processing matching methods [14, 17, 19].\nDespite these advancements, current shape assembly methods still face significant challenges, particularly those that use regression networks to predict the absolute poses of each part based on extracted features [40, 48]. First, in addition to global features from the encoder, it is crucial to accurately model the local geometric relationships between different parts. For instance, when assembling a chair, the legs must be positioned at precise distances and angles relative to the seat; even minor deviations can lead to instability or misalignment. Second, since shape assembly is framed as a part-level 6-DoF prediction problem, the network must explicitly consider both rotation and translation transformations for each part. However, common architec-"}, {"title": "2. Related Work", "content": "Research in 3D shape assembly focuses on reconstructing complete objects from either predefined semantic parts (part assembly) or fractured pieces (geometric assembly). In the context of part assembly, the large-scale PartNet dataset [21] has facilitated significant progress. For example, Li et al. [16] assemble parts into a target shape by predicting the translations and rotations of given point clouds using image priors. RGL-Net [22] and DGL [48] leverage dynamic graph learning and iterative message-passing techniques to merge parts into cohesive structures. However, these methods heavily rely on the availability of semantic segmentation to guide the assembly process. This reliance poses challenges when such labels are missing, especially in geometric assembly tasks, where models must reassemble fractured parts of objects like vases or artifacts based purely on geometric clues.\nFor geometric assembly, the Breaking Bad dataset [32] provides non-semantic fragments, creating a more challenging scenario. In this context, NSM [2] prioritizes shape geometries over semantic cues, while Wu et al. [40] extract geometric features using SE(3)-Equivariant representations. Other approaches explore generative models for fragment reassembly [3, 28]. Additionally, methods have begun to utilize fracture surface features or complete shape templates to streamline assembly, aiming for more general-purpose models [18, 19]. Techniques such as mapping relative transformations using correspondence alignment estimation have also been proposed [14]. In contrast, our work focuses on developing a novel network architecture capable of handling both semantic and geometric assemblies. We frame the task as an absolute pose prediction problem, integrating both geometric and contextual information to achieve precise assembly, even in the absence of semantic labels."}, {"title": "3. Method", "content": "Given an object segmented into N parts, such as the legs and base of a stool, or the shards of a shattered beer bottle, the objective of the shape assembly task is to reassemble these parts to reconstruct the original object with a specified shape. Formally, we represent the parts as \\(P = \\{P_i\\}_{i=1}^{N_i}\\), where each part \\(P_i = \\{x_j \\in \\mathbb{R}^3\\}_{j=1}^{N_j}\\) is a point cloud containing \\(N_i\\) points for each part i, uniformly sampled from its surface. For tasks involving semantic part assembly (e.g., reconstructing parts of a stool), each part is labeled with a semantic tag indicating its type. In contrast, for purely geometric assembly tasks, only geometric features such as point cloud coordinates are available.\nMathematically, the goal of shape assembly can be formulated as the prediction of the canonical 6-DoF poses \\(\\{T_i \\in SE(3)\\}\\}_{i=1}^{N}\\) for each part, where \\(T_i = (R_i \\in SO(3), t \\in \\mathbb{R}^3)\\) consists of both the rotation matrix and translation vector. Using the predicted pose, each part's point cloud is transformed to obtain its grounded position: \\(P_i^{pred} = T_i \\circ P_i = P_i R_i + t_i\\), ultimately reassembling the complete object \\(P^{pred} = \\{T_i \\circ P_i\\}_{i=1}^{N}\\).\nOur work focuses on designing a network architecture capable of accurately estimating the absolute poses and capturing the local geometry of each part and pose. To this end, we propose a geometric point attention module, which, together with node and edge attentions, helps better capture the geometric interactions between different parts. Additionally, to enable dynamic reasoning and iterative pose refinement, we introduce a geometric recycling procedure that recursively predicts and refines poses. The overall framework is illustrated in Figure 1. Initially, features are extracted from the input point clouds and fed into a transformer. Within the transformer, poses and features are iteratively updated by distinct multi-head cross-attention modules, with regularization imposed based on geometric relationships. The output poses serve as predictions and are transformed into recycled features if further refinement is required. In Section 3.2, we provide details on the Geometric Point Attention Transformer, and in Section 3.3, we introduce the novel geometric recycling module."}, {"title": "3.1. Feature Extraction", "content": "We begin with a backbone feature extractor, such as Point-Net [25, 26] or DGCNN [38], to capture local hidden geometric features from the point cloud of each part. To provide a shape prior, we also extract a global shape feature by pooling these local geometric features [29]. The part-level geometric features \\(h_i^{local}\\), global feature \\(h^{global}\\), and recycled geometric features \\(h_i^{os}, h^{ose}\\) are then concatenated and processed by multi-layer perceptrons (MLPs), referred to as part embedders, to generate the node feature \\(h_i \\in \\mathbb{R}^d\\) for each part. The recycling mechanism is further elaborated in Section 3.3. In the first round of network prediction,"}, {"title": "3.2. Geometric Point Attention", "content": "After extracting features from the point cloud of each part, we use the geometric point attention module to update both the node features and the poses of each part. Current attention modules [36] can capture global context and cross-part information, which are essential in point cloud modeling. However, these networks tend to ignore the geometric features of part pairs and pose information. Our proposed module not only incorporates high-level node features in Part Attention but also considers high-level pair representations and geometric pair features in Pair Attention. Furthermore, we introduce the invariant Point Attention module to directly model pose information across different parts and update poses across layers in an equivariant way. While our attention module is designed to be multi-layer and multi-head, we omit the layer and head notations for simplicity.\nPart Attention. The first part of the geometric attention module is part attention, where part features attend to each other to compute relative attention weights, which indicate high-level part interactions and global context extraction. This can also be viewed as a fully connected graph [17, 48]. The node features are transformed into query, key, and value vectors, and the squared multiplication between the query and key vectors represents the part-level attention weights:\n\n\n\n\n\\((q_i, k_i, v_i) = (W_q h_i, W_k h_i, W_v h_i), \\quad N_{ij} = \\frac{q_i k_i}{\\sqrt{d}}\\)\n\nPair Attention. After modeling part-level attention, we introduce cross-part pair features, which are incorporated as an additional term in the attention calculation to regulate the cross-part relative weights. First, we transform the input pair feature into the edge attention term as \\(b_{ij} = W_b z_{ij}\\). However, in addition to high-level cross-part representations, the geometric structure between parts should also be included to ensure geometric consistency. This encourages the modeling of dynamic geometric relations between parts, such as the distance and orientation between the feet of a chair, which should stay within an appropriate range when assembled into the complete object [48]. To achieve this, we include geometric invariant distances and orientations between parts in the edge module. Since each part is represented as a point cloud, we first compute the center of mass for each part, which is invariant to global translations:\n\n\n\n\n\\(p_i = \\frac{1}{N_i} \\sum_{j=1}^{N_i} x_j\\)\n\nNext, we compute pairwise distances and triplet-wise dihedral angles between different parts [27, 44]. To adopt continuous representations of scalar distances and angles, we use Gaussian radial basis functions [9, 10] to map them into a vector space, given d basis functions:\n\n\n\n\n\\(d_{ij} = RBF(||p_i - p_j||_2) \\in \\mathbb{R}^d\\)\n\n\n\n\n\\(\\tau_{ijk} = \\sum_{k=1}^{N} RBF(\\cos \\angle_{ijk}) \\in \\mathbb{R}^d\\)\n\nFinally, we combine the high-level edge features with the transformed geometric invariant distance and angle features to obtain the final edge attention term:"}, {"title": "3.3. Geometric Recycling", "content": "To enhance the dynamic geometric reasoning capabilities within the stacked geometric point attention layers", "features": "n\n\n\n\n\\(P'_i = stopgrad(T_i) P_i", "feature": "n\n\n\n\n\\(p'_i = \\frac{1}{N_i} \\sum_{j=1}^{N_i} x_j, \\quad z_{ij}^{pos} = RBF(||p'_i - p'_j||_2) \\in \\mathbb{R}^d\\)\n\nP\n```"}]}