{"title": "ChinaTravel: A Real-World Benchmark for Language Agents in Chinese Travel Planning", "authors": ["Jie-Jing Shao", "Xiao-Wen Yang", "Bo-Wen Zhang", "Bai-Zhi Chen", "Wen-Da Wei", "Lan-Zhe Guo", "Yu-Feng Li"], "abstract": "Recent advances in LLMs, particularly in language reasoning and tool integration, have rapidly sparked the real-world development of Language Agents. Among these, travel planning represents a prominent domain, combining academic challenges with practical value due to its complexity and market demand. However, existing benchmarks fail to reflect the diverse, real-world requirements crucial for deployment. To address this gap, we introduce ChinaTravel, a benchmark specifically designed for authentic Chinese travel planning scenarios. We collect the travel requirements from questionnaires and propose a compositionally generalizable domain-specific language that enables a scalable evaluation process, covering feasibility, constraint satisfaction, and preference comparison. Empirical studies reveal the potential of neuro-symbolic agents in travel planning, achieving a constraint satisfaction rate of 27.9%, significantly surpassing purely neural models at 2.6%. Moreover, we identify key challenges in real-world travel planning deployments, including open language reasoning and unseen concept composition. These findings highlight the significance of ChinaTravel as a pivotal milestone for advancing language agents in complex, real-world planning scenarios.", "sections": [{"title": "1 Introduction", "content": "A long-standing goal in AI is to build planning agents that are reliable and general, able to assist humans in real-world environments. Recently, Large Language Models (LLMs) (Brown et al., 2020; Ouyang et al., 2022; Achiam et al., 2023) have demonstrated remarkable potential in achieving human-level understanding and planning capabilities. This has sparked the rapid development of a field called Language Agents, employing LLMs to perceive the surroundings, reason the solutions, and take appropriate actions, ultimately building an autonomous planning agent (Shinn et al., 2024; Yao et al., 2023; Xi et al., 2023). Equipping LLMs born from web-scale corpora, language agents demonstrate a proficient ability to understand general natural language instructions and collect domain-specific information via tools (Yao et al., 2022; Xie et al., 2023; Jimenez et al., 2024). It alleviates the need for intensive domain-specific goal definition and model deployment with traditional rule-based or reinforcement-learning-based agents, showing few-shot generalization across various domains. This presents a solid step toward the goal of building general artificial intelligence.\nTravel planning stands out as a significant domain, presenting both academic challenges and practical value due to its inherent complexity and real-world relevance. However, LLMs are still not able to accurately solve complex combinatorial optimization problems and tend to provide infeasible plans in travel planning. In a recently proposed U.S. domestic benchmark TravelPlanner (Xie et al., 2024) with intercity itinerary planning, the advanced LLM, GPT-4, only achieves a success rate of 0.6%. This result is disappointing and might make one pessimistic about the capabilities of Language Agents in travel planning. However, a few months later, Hao et al. (2024) introduced a neural-symbolic solution, which incorporates formal verification tools into language agents and achieved a 97% success rate on the LLM-synthesized queries from TravelPlanner benchmark. Despite this progress, travel queries posed by humans present significantly greater challenges than synthesized queries. The open-ended expression styles of humans, characterized by ambiguous phrasing and context-dependent meanings, make understanding these requirements difficult for LLMs. Furthermore, the diverse nature of user needs renders constraint verification based on predefined concepts hard to scale, limiting its applicability to evaluating human queries.\nIn this work, we introduce ChinaTravel, tailored to authentic Chinese travel requirements. It concentrates on multi-point-of-interest (multi-POI) itineraries within specified cities (as illustrated in Fig. 1), which are in higher demand compared to the intercity itineraries provided by TravelPlanner. The main contributions of this work are as follows:\n1. Comprehensive Evaluation Framework: It provides a sandbox enriched with authentic travel data, a domain-specific language for scalable requirements definition and automated evaluation, and diverse metrics covering feasibility, constraint satisfaction, and preference ranking.\n2. Integration of Synthetic and Human Queries: The benchmark includes both LLM-generated and human-derived queries, offering a realistic and open testbed for evaluating agents' capabilities in addressing diverse travel requirements.\n3. Empirical Neuro-Symbolic Insights: Our experiments reveal that neuro-symbolic agents significantly outperform pure LLM-based solutions, achieving a constraint satisfaction rate of 27.9% compared to 2.60% by purely neural methods, thus highlighting their promise for travel planning.\n4. Identified Challenges for Future Research: We pinpoint key challenges of open-ended requirements: open language reasoning, and unseen concept composition, providing a foundation for advancing agents toward real-world applicability.\nOverall, ChinaTravel provides a challenging yet meaningful testbed for evaluating language agents in travel planning, serving as a critical bridge between academic research and practical applications."}, {"title": "2 ChinaTravel Benchmark", "content": "Motivated by the significant travel demand in China, this benchmark offers a sandbox environment for generating multi-day, multi-POI itineraries for specified cities. ChinaTravel is designed to serve as a comprehensive and scalable benchmark for evaluating language agents in travel planning, including arrangements for attractions, restaurants, accommodations, and transportation between events."}, {"title": "2.1 Environment Information", "content": "ChinaTravel provides a sandbox with real-world travel information. We collect information from 10 of the most popular cities in China. It includes 720 airplanes and 5,770 trains connecting these cities, with records detailing departure and arrival times, origins, destinations, and ticket prices. Additionally, the dataset contains 3,413 attractions, 4,655 restaurants, and 4,124 hotels, each annotated with name, location, opening hours, and per-person prices. Type annotations for these POIs are included to meet user needs. Fig. 2 has demonstrated the travel information from Beijing and Nanjing, two of the most popular cities in China. For a more realistic interaction, we simulate the API interface of real market applications to query real-time information. The detailed designs of the sandbox are available in App. B.1. Environmental constraints act as a feasibility metric, ensuring that the generated plans are both valid and effective. For example, POIs in the plan must exist in the designated city, transportation options must be viable, and time information must remain accurate. Tab. 1 summarizes the environmental constraints."}, {"title": "2.2 Logical Constraint", "content": "A crucial ability for travel planning is to effectively satisfy personalized user needs. We extend the logical constraints from TravelPlanner (Xie et al., 2024) and present a Domain-Specific Language (DSL) to support general reasoning in logical constraints. ChinaTravel's DSL is a general set of pre-defined concept functions with built-in implementations and is listed in Tab. 2. TravelPlanner relies on 5 pre-defined concepts {total budget, room rules, room types, cuisines, and transportation types}, to evaluate the logical constraints, where each concept is equivalent to a specific logical requirement. We find that this approach limits the ability to validate diverse logical needs in an open-world context. For example, such an evaluation cannot express that the dining expenses should be within 1000 yuan or that arriving in Shanghai should be before 6 PM on the second day, despite the generated plan already including the expenses for each activity and time information of the return flight. Each new logical requirement necessitates human intervention for definition. To address this issue, our approach is grounded in a DSL-based solution that leverages basic concept functions and syntax to express and fulfill various logical requirements.\n```python\n# Dining expenses <= 1000 CNY.\ndining_cost = 0\nfor act_i in allactivities(plan):\n typ = activity_type(act_i)\n if typ==\"breakfast\" or typ==\"lunch\" or\n typ==\"dinner\": dining_cost =\n dining_cost + activity_cost(act_i)\nreturn dining_cost <= 1000\n```"}, {"title": "2.3 Preference Requirement", "content": "Travel requirements encompass not only hard logical constraints but also soft preferences. The term \"soft\" implies that these preferences cannot be addressed as boolean constraint satisfaction problems, instead, they involve quantitative comparisons based on continuous values. This distinction highlights the unique nature of preference-based requirements compared to logical constraints. Common preferences identified through surveys include maximizing the number of attractions visited, minimizing travel time between destinations, and visiting positions near the specific POI, among others. In ChinaTravel, we formalize such preferences as minimization or maximization objectives via our DSL, thereby providing an automated evaluation."}, {"title": "2.4 Benchmark Construction", "content": "ChinaTravel provides user queries reflecting diverse requirements through a four-stage process that integrates LLM-based generation with questionnaires.\nStage I: Manual design of database and APIs. We collect travel information for multi-day, multi-POI itineraries across attractions, accommodations, and transportation. We define essential POI features, such as cuisine types and hotel characteristics, to construct the database from public information. APIs are designed to support agent queries via regular expressions and modeled after commercial APIs to ensure realism. See App. B.1 for details.\nStage II: Automatic data generation with LLMs. We define common travel information (e.g., origin, destination, days, number of people) and logical constraints to model travel tasks. To enable scalable queries, query skeletons are randomly constructed from this information and transformed into natural language queries using advanced LLMs. The generated queries are categorized into two difficulty levels: Easy, with 1 logical requirement beyond basic constraints like people number and trip duration, and Medium, with 3\u20135 additional logical requirements. We encourage the LLM to generate diverse, human-like expressions, such as turning \"Taste Beijing cuisine\" into \"Try local food in Beijing.\" See App. B.3 for an example snippet and more details.\nStage III: Quality control and auto-validation. To ensure data quality, we manually check whether the generated queries conform to symbolic skeletons, and re-calibrate natural language descriptions that contain ambiguities. Based on the symbolic skeletons of queries, we could verify whether the plan can pass the required logical constraints by executing the DSL code via Python compiler. Building on this, we ensure that each query has at least one solution that satisfies the logical constraints by implementing a heuristic search algorithm.\nStage IV: Open requirements from humans. After the first round of closed-loop development with LLM, including data generation and annotation, baseline development, and evaluation, we further collected travel requirements from more than 250 humans through questionnaires. Based on a new round of quality control on these data, a more challenging set with 154 queries is constructed. These queries even include unseen logical constraints in the deployment process, such as \u2018departure time' and 'dining cost', reflecting the real challenges of neural-symbolic systems in travel planning. We carefully annotate the required logical constraints for each query based on the DSL, enabling the automated evaluation of these challenging samples and forming the Human level dataset.\nTo support global research on travel planning, we provide an English version of all queries in ChinaTravel. However, we recommend that researchers primarily use the Chinese version, as it better captures the expression from native speakers."}, {"title": "3 Empirical Study", "content": "LLMs. We test both state-of-the-art proprietary and open LLMs: OpenAI GPT-40, DeepSeek-V2.5, as well as Qwen-2.5-7B (Bai et al., 2023). The first two models are chosen for their strong performance, while the latter is selected for their Chinese language capabilities and ability to perform inference with limited local computational resources.\nMetrics. We examine the Delivery Rate (DR), Environmental Pass Rate (CPR), Logical Pass Rate (LPR), and Final Pass Rate (FPR) from TravelPlan (Xie et al., 2024). Furthermore, we design a novel metric, Conditional Logical Pass Rate (C-LPR), evaluating the success rate of plans that first fulfill environmental constraints prior to logical constraints. It ensures that logical requirements are met within a realistic travel context, eliminating cases where unrealistic or incorrect information might lead to shortcutting logical constraints, such as misreporting costs to fit budget requirements. By introducing C-LPR, we aim to enhance the feasibility and meaningfulness of constraint satisfaction.\n$C-LPR=\\frac{\\sum_{p\\epsilon P} 1_{passed(Env,p)}.\\sum_{c\\epsilon C_p} 1_{passed(C_p,p)}}{\\sum_{p\\epsilon P} |C_p|}$\nP is the plan set, $C_p$ is the set of constraints for plan p, and passed(c, p) indicates whether p satisfies c.\nMethods. We evaluate the performance of both pure-LLM-based and neuro-symbolic solutions on the ChinaTravel benchmark. For the former, we primarily test the well-known method, ReAct (Yao et al., 2023), and its Act-only ablation. We exclude Reflexion (Shinn et al., 2024) due to its performance being similar to ReAct on the TravelPlanner (Xie et al., 2024) and the high economic overhead associated with the larger input token size. For the latter, we adapt existing neuro-symbolic pipelines (Hao et al., 2024; Pan et al., 2023; Deng et al., 2024) using our proposed DSL to handle the complexities of multi-day, multi-POI itineraries."}, {"title": "3.1 Neuro-Symbolic Planning", "content": "This subsection presents a neuro-symbolic solution as a preliminary baseline for ChinaTravel. This solution consists of two stages. Stage 1: NL2DSL translation translates natural language queries into logical, preference-based DSL requirements. We use Reflexion (Shinn et al., 2024) and a DSL syntax checker to iteratively assist the LLM (5 rounds in experiments). Stage 2: Interactive search uses a neuro-symbolic solver to sequentially arrange activities, guided by a symbolic sketch and LLM-driven POI recommendations, generating a multi-day itinerary with DSL validation. If constraints are violated, the process backtracks until a feasible solution is found. To ensure fairness, the symbolic sketch search is limited to 5 minutes per query, excluding LLM inference time. To observe the performance across the two stages, we also evaluated the planning results based on the Oracle DSL. App. C includes pseudo-code and LLM prompts."}, {"title": "3.2 Main Results", "content": "Based on the results presented in Table 3, we have the following observations and analyses:\nPure LLMs struggle in ChinaTravel. The DR evaluates an agent's ability to generate valid JSON plans (see Fig. 1). While high DRs indicate that advanced LLMs can produce structured outputs for travel planning, the near-zero EPR (Environmental Constraints Pass Rate) reveals their inability to gather and strictly adhere to required information. The sole exception is the DeepSeek model, which achieves the 5% EPR and 4.33% FPR, likely due to its strong capability to follow Chinese requirements. ReAct (one-shot, GPT-40) excels in Macro LPR but achieves no FPR, suggesting it circumvents constraints via shortcuts. Our proposed C-LPR metric offers a more reliable measure of logical constraints, serving as a supplement to FPR.\nNesy Planning provides a promising solution."}, {"title": "3.3 Ablation Study with Preference", "content": "The comparison of preferences should be conducted under the premise that both environmental and logical constraints are satisfied. Given the limited FPR achieved by existing methods on the challenging ChinaTravel, we perform a separate analysis of preference optimization in this section. Specifically, we sampled 50 queries from the easy subset that NeSy-DeepSeek-Oracle successfully passed as seed samples. Based on these, six subsets were created by introducing common preferences identified from user surveys. Three comparative scenarios were designed to explore the roles of LLMs and symbolic search in optimizing preferences during NeSy Planning: (1) Baseline Query (BQ): Results obtained by directly querying the seed samples without preference requirements. (2) Preference-Enhanced Query (PEQ): Results based on seed samples augmented with natural language preference expressions (e.g., \"visit more attractions\"), evaluating whether embedding preferences into POI recommendations via LLMs improves outcomes. (3) Preference-Driven Search (PDS): Results using both natural language and DSL-based expressions, where the agent, within the 5-minute search time limit, computes the preference concept for solutions that pass environmental and logical constraints and retains plans that maximize or minimize the preference objective.\nFrom the results(Fig. 6, where \u2191 indicates maximization), PEQ outperforms BQ in preference optimization. This ablation demonstrates that LLMs can effectively capture natural language needs during the POI ranking stage, contributing to preference improvements. However, on P2, PEQ underperforms BQ, indicating that LLMs can sometimes have a negative impact. This may be due to the complexity of the preference in P2, which involves minimizing transport time to restaurants, leading to misinterpretation. PDS achieves more significant improvements in preference optimization, relying on DSL-based preference calculations that filter plans more effectively over extended search times. This supports the scalability of DSL in preference optimization but also highlights the pressing need for more efficient algorithms."}, {"title": "4 Conclusion", "content": "We present ChinaTravel, a benchmark for multi-day multi-POI travel planning focused on authentic Chinese needs. We address the limitations of previous benchmarks by incorporating open-ended and diverse human queries, capturing real-world user needs. Additionally, we propose a scalable evaluation framework based on DSL, enabling comprehensive assessments of feasibility, constraint satisfaction, and preference comparison. These advancements provide a foundation for developing language agents capable of meeting diverse user requirements and delivering reliable travel solutions."}, {"title": "5 Limitations", "content": "Our research represents a significant step forward in evaluating the travel planning capabilities of language agents, but it is not without challenges. One limitation lies in its focus on Chinese travel planning. Due to the inherent differences in natural language, the translated versions of queries may fail to fully capture the challenges of understanding requirements in Chinese queries, potentially limiting its applicability in a global context. However, given the substantial demand within China's travel market, we believe a benchmark tailored to Chinese travel planning is both necessary and socially valuable. Although our benchmark is comprehensive, it may not encompass the full range of requirements encountered in real-world scenarios. The high cost of collecting authentic data has limited the number of human queries in our study. To address this, future work will focus on combining LLMs with real user queries to automate the generation of a wider variety of human-like queries. Continuous refinement and expansion of our benchmark are crucial for more accurately reflecting the realistic travel planning needs."}, {"title": "A Discussion with Related Work", "content": "LLM-based Agents have demonstrated significant capability in understanding complex instructions and employing domain-specific tools to complete tasks, showcasing their potential in fields such as visual reasoning (Gupta and Kembhavi, 2023), healthcare (Zhang et al., 2023) and robotics (Liu et al., 2024). This reduces the reliance of previous agents on domain-specific efforts, that is, either mainly following domain-specific rules to plan (rule-based agents, such as DeepBlue (Campbell et al., 2002) and Eliza (Sharma et al., 2017)) or mainly learning from domain-specific data to plan (reinforcement-learning-based agents, such as AlphaGo (Silver et al., 2017) and Atari DQN (Mnih et al., 2013)). While the language agents have shown promising results in some domains, most of their planning scenarios are limited to simple tasks with single objective function and fail in the travel planning benchmark with complex logical constraints on the results.\nNeuro-Symbolic Learning explores to combine traditional symbolic reasoning with learning to enhance the reliability (Manhaeve et al., 2018; Wang et al., 2019; Dai et al., 2019). In the era of large language models, Pan et al. (2023) presents the LogicLM integrates LLMs with separate symbolic solvers for various logical reasoning tasks. They first utilize LLMs to translate a natural language problem into a symbolic formulation. Afterward, a deterministic symbolic solver performs inference on the formulated problem to ensure the correctness of the results. Deng et al. (2024) supplement LogicLM with a Self-Refinement Module to enhance the reliability of LLM translation. In the travel planning domain, Hao et al. (2024) presents a framework with a similar pipeline. It first extracts the logical constraints from natural language queries and then formalizes them into SMT code. Thanks to SMT solvers being sound and complete, this neuro-symbolic solution guarantees the generated plans are correct and has basically solved the TravelPlanner benchmark with a 97% pass rate.\nTravel Planning is a time-consuming task even for humans, encompassing travel-related information gathering, POI selection, route mapping, and customization to meet diverse user needs (Halder et al., 2024). Natural languages are one of the most common ways for users to express their travel requirements. However, the ambiguity and complexity of travel requirements make it still challenging for LLMs to generate accurate and reliable travel plans. Xie et al. (2024) presents the TravelPlanner benchmark for cross-city travel planning and reveals the inadequacies of pure-LLM-driven agents. TravelPlanner generates user queries through LLMs and provides a rigorous evaluation mechanism to verify whether the provided plans can meet the logical constraints in the queries. It has become a pivotal benchmark for language agents in real-world travel planning. Tang et al. (2024) study the open-domain urban itinerary planning where a single-day multi-POI plan is required. They integrates spatial optimization with large language models and present a system ITTNERA, to provide customized urban itineraries based on user needs. A concurrent work, TravelAgent (Chen et al., 2024), also considers a multi-day multi-POI travel planning problem for the specified city. It constructs an LLM-powered system to provide personalized plans. However, due to the high cost of collecting and annotating real travel needs, they evaluate the proposed TravelAgent in only 20 queries. This also demonstrates the necessity of introducing a new benchmark for travel planning."}, {"title": "B Detailed Design of ChinaTravel", "content": "We started collecting travel information with the motivation of planning a multi-day, multi-POI itinerary in four aspects: attractions, accommodation, activities, and transportation. Developers first determine the POI description information that needs to be obtained from the user's perspective, such as cuisine and hotel features. Based on this feature set, we collect public information to construct the database. For the design of APIs, we directly support queries based on the regular expressions from agents. At the same time, we expect the design of APIs to have similar features and characteristics to existing commercial APIs, enabling our dataset to be applicable to more realistic scenarios. The information our database contains is shown in Table 4 and the APIs we offer is in Table 5"}, {"title": "B.2 Concept Function", "content": "We defined 35 concept functions. Their definition and implementation is in Table 6, 7, 8 and 9."}, {"title": "B.3 Query Synthesis", "content": "We designed common travel information (origin, destination, days, number of people) and logical constraints based on the nature of travel tasks. To facilitate scalable queries for ChinaTravel, we randomly constructed query skeletons from the aforementioned information and used advanced LLMS to generate natural language queries from these skeletons. The automatically generated data is categorized into two difficulty levels: In the Easy level, user inputs encompass a single logical requirement, sourced from categories such as transportation, restaurants, attractions, and accommodations. In the Medium level, user inputs involve 2 to 5 logical requirements, introducing more complex constraints. During the generation, we encourage the LLMs to provide varied and human-like expressions, necessitating a deeper understanding and processing to accurately interpret and fulfill the user's needs. For instance, the logical requirement \"taste Beijing cuisine\" could correspond to the natural language query: \"Try local food in Beijing.\" We utilize prompt engineering to guide LLMs in refining natural language expressions to facilitate automated generation."}, {"title": "C NeSy Planning", "content": "Since the Z3 solver from (Hao et al., 2024) would restructure the tool API to return travel information expressed in specific Z3 variables, which may not be feasible given that APIs in the real world are typically black boxes that agents can only call. Following their two-stage solution, we first extract logical constraints from natural language. Based on these constraints, we implement a step-by-step plan generation process using depth-first search, mimicking how humans plan to travel by arranging activities one by one. As shown in Fig. 3, we first translate the natural languages to logical constraints through prompting. generate the next activity type based on the current plan, and then recursively generate the next activity until the goal is reached. The generated plan is then used to solve the problem. In the second step, we define the rule-based activity selection and score function. For example, if the current time is in the [10:30, 12:30] and there is no scheduled lunch in the current plan, then the agent should find a restaurant to have lunch at this time. If the current time is after 22:00 and there are no open-time attractions nearby, the agent should choose to return to the hotel. For the score function, we select the restaurants that satisfy the required cuisine and sort the candidates by the price if there a budget constraints in the constraints C. These ranking functions will help us to find a feasible solution as soon as possible. In ChinaTravel, the duration arrangement of activities is continuous and difficult to enumerate and search. We pre-define a meal or a visit to an attraction as 90 minutes, and when there are less than 90 minutes until closing time, the event continues until the closing time.\nGiven these designs, we adapt the neural-symbolic solution into a multi-POI planning problem and evaluate it in the ChinaTravel benchmark.\nGiven that some queries are particularly challenging due to the limited number of feasible plans, we set the maximum runtime for the symbolic sketch from interactive search to 5 minutes per query, excluding the LLM inference time, to ensure a fair comparison across different models. If a plan satisfying the generated DSL validation is found within the time limit, it is returned directly. Otherwise, the program halts when the time limit is reached, and the plan that satisfies environmental constraints while achieving the highest number of validation code successes among all intermediate results is returned. In cases where no environment-compliant plan is identified, the partially completed plan generated up to that point is returned."}]}