{"title": "Non-stationary BERT: Exploring Augmented IMU Data For Robust Human Activity Recognition", "authors": ["Ning Sun", "Yufei Wang", "Yuwei Zhang", "Jixiang Wan", "Shenyue Wang", "Ping Liu", "Xudong Zhang"], "abstract": "Human Activity Recognition (HAR) has gained great attention from researchers due to the popularity of mobile devices and the need to observe users' daily activity data for better human-computer interaction. In this work, we collect a human activity recognition dataset called OPPOHAR consisting of phone IMU data. To facilitate the employment of HAR system in mobile phone and to achieve user-specific activity recognition, we propose a novel light-weight network called Non-stationary BERT with a two-stage training method. We also propose a simple yet effective data augmentation method to explore the deeper relationship between the accelerator and gyroscope data from the IMU. The network achieves the state-of-the-art performance testing on various activity recognition datasets and the data augmentation method demonstrates its wide applicability.", "sections": [{"title": "I. INTRODUCTION", "content": "Human activity recognition (HAR) has been an important research area for decades and plays a crucial role in many applications, such as human-computer interaction, human be-haviour analysis, and ubiquitous computing [1]-[3]. In recent years, advancements in sensing analytics of mobile devices have driven the rapid development of human activity recog-nition. They provide opportunities for continuous tracking of physiological signals and boost seamless communication between humans and machines [4]. Inertial measurement units (IMUs), which contain accelerometers and gyroscopes, are typically electromechanical or solid-state devices that detect linear acceleration and angular velocity [5]. They are widely applied in mobile devices due to their adaptability and sim-plicity [6].\nBy utilizing the data from the IMU implemented in mobile devices, real-time human activity recognition becomes feasi-ble. Due to the power and computing limitations of mobile devices, classifiers for HAR are typically lightweight. Various Machine Learning (ML) algorithms, RNN, CNN, Transformer, and mixed-architecture models are proposed [7]\u2013[12].\nIn alignment with the development of HAR systems, several datasets are introduced, including UCI [13], shoiab [14], mhealth [15]. Prior studies [16]-[18] also apply data aug-mentation methods on IMU data, e.g., adding random noise, rotation, flipping, bias, physical transformation, etc. These data augmentation methods increase the diversity of the training data, thereby mitigating over-fitting and improving the gener-alization ability of the HAR model.\nHowever, the prior works have several drawbacks. Firstly, existing models frequently struggle to adapt to real-world scenarios as each user has his own movement pattern. A user might want to record some specific but uncommon activity, such as skiing. Previous models need to be trained from scratch to accommodate a new activity. Secondly, they do not delve deeply enough into the relationship between accelerator and gyroscope data for a robust data augmentation method.\nTo address these drawbacks, we implement a two-stage inference pipeline. As depicted in the Figure 1, the model separates the pretraining of the Encoder and the finetuning of the Classifier. Pretraining always requires a significant amount of time, thus can be done in the cloud; Finetuning can be conducted on users' mobile devices as we want to use the user-labeled activity data to train their own classifiers, which also ensures user privacy.\nIn this work, we have three primary contributions:\n\u2022 We propose a new human activity recognition dataset named OPPOHAR, which encompasses a diverse range of human activities using the phone in various gestures.\n\u2022 We introduce an effective data augmentation method tailored for processing IMU data.\n\u2022 We propose a lightweight network optimized for dis-tributed deployment for HAR, dedicated to privacy-protecting user-specific activity recognition."}, {"title": "II. DATASET", "content": "We define seven common human activities for mobile devices: staying still, walking, walking up and down stairs, running, cycling, taking car, and taking subway. For conve-nience, we name them respectively as activity A, B, C, D, E, F, and G. These activities cover a large variety of scenarios with phones in human daily life, making the dataset practically valuable. Data are collected from seven different activities mentioned above by two collectors. Take the activity walking as an example, we use 2 different devices and different hands holding the phone to collect data at 3 different speeds, slow, medium, and fast. We illustrate the duration of time for each activity in our dataset as in the first two rows of Table I.\nWe also construct an uncommon dataset including activities distinguished from daily activities. We define six distinct hand gestures holding mobile devices: rotating the phone like a circle, tracing a \"W\" shape in the air, tracing a \"Z\" shape in the air, vigorously shaking the phone up and down, tapping the phone from behind, gently shaking the phone from side to side. For convenience, we name them respectively as activity a, b, c, d, e, and f. These activities deviate from typical phone usage behaviors and serve as triggers for specialized phone functions, enabling quick access to certain functions of their devices. Each activity mentioned above is recorded in ten sets collected by three collectors. Within each set, the activity will be repeated continuously approximately 20 times. In the last two rows of Table I, we illustrate the duration of time for each activity in our dataset."}, {"title": "III. METHODOLOGY", "content": "In this section, we present the overall design for our Non-stationary BERT (Bidirectional Encoder Representations from Transformers [19]) network. As depicted in Figure 1, it in-cludes two phases: self-supervised pretraining and supervised classifying. Inspired by the previous work LIMU-BERT [20], we adopt a similar architecture, which contains three parts: a BERT-like Encoder, a Decoder, and a Classifier.\nDuring the self-supervised pretraining phase, raw IMU data is first pre-processed and then sent to the Encoder-Decoder module for sequence recovery task. The NS-BERT Encoder is designed to learn an effective hidden representation of the input sequence and the Decoder is designed to recover this time sequence based on former hidden representation. For the supervised classification phase, we freeze the Encoder and replace the Decoder with a Classifier for human activity recognition. The network is finetuned for the HAR task. The pretraining network can be trained online and later send Encoder to all users. Classifiers can be trained on user mobile devices.\nThe accelerator data and the gyroscope data from IMU present different characteristics of the activity. Previous work [17], [21]-[23] do not consider the inter-relationship between them. They usually concatenate them and send them directly to the network, or use two encoders to extract the features respectively and concatenate them with later fusion.\nInstead, we propose an efficient data augmentation method, FM (Factorization Machine [24]). Consider a time sequence from IMU data, $acc_{i,j}$ and $gyro_{i,k}$ represent respectively the accelerator data and gyroscope data of time step i and of axis j, where j and k come from axis x or y or z. We select a sequence of $acc_{i,j}$ and a sequence of $gyro_{i,k}$ and multiply them at each time step and get a new sequence called $fm_{i,j,k}$ as in equation below:\n$fm_{i,j,k} = acc_{i,j} \\times gyro_{i,k}$    (1)\nAs the accelerator and gyroscope have each 3 axes, we have a total of 9 new time sequences, which are also regarded as the input. These created feature sequences contain hidden trends of data fluctuation, facilitating the neural network to discover the underlying laws between them.\nWith a detection window of 6 seconds, the raw IMU data is split into sequences. After data normalization, we got data in a shape like T * SR * FS, where T, SR, and FS denote time length, sampling rate, and feature shape respectively. In this scenario, the feature shape is 15. In the following Embedding phase, we project feature shape from 15 into embedding size.\nTime series is commonly non-stationary, which means that the statistical properties and joint distribu-tion of time series can change over time. For IMU data of"}, {"title": "IV. EXPERIMENT AND RESULTS", "content": "We select our OPPOHAR and another three public datasets, including UCI, Mhealth, and Shoaib for evaluation. We choose accuracy and F1-score as our metrics. All datasets are equally down-sampled to 20Hz and sliced into non-overlapping windows with a length of 120 units, which is a time span of 6 seconds.\nFor comparison with our NS-BERT, we choose LIMU-BERT [20], DCNN [30], Deepsense [31], GRU [29] and LSTM [32]. For NS-BERT and LIMU-BERT, they both adopt a two-stage training method. The preliminary experiments show that the GRU classifier achieves the best results for fine-tuning them. Thus, in subsequent experiments, we rename NS-BERT as NS-GRU, indicating we use GRU for the classifier, the same as LIMU-GRU.\nTo ensure the experiment's fairness and prevent over-fitting, different training epochs are chosen according to the size of the datasets. For LIMU-BERT and NS-BERT, the number of pretraining epochs are 1500-5000. The classification training adopts 1000-1200 epochs. All models utilize the same dataset for training, validation, and testing. The learning rate in the pretraining phase and classification phase are 0.0001 and 0.001, respectively. The batch size is 2048.\nIn Table II, our baseline model achieves the best performance among all models. Compared with the baseline LIMU-GRU, which does not have sta-tionarization mechanism, our model NS-GRU shows a great performance improvement, proving the effectiveness of Non-stationary structure.\nTo evaluate the effectiveness of the data augmentation method we presented\nregard $\\sigma_x$ as $\\tau$ and $K'^T$ as $\\Delta$. The original attention score without normalization can be deduced as follows:\nAttention(Q, K, V) = Softmax(\\frac{QK^T}{\\sqrt{d_k}})V = Softmax(\\frac{Q'K'^T + \\Delta}{\\sqrt{d_k}})V = Softmax(\\frac{TQ'K'^T + \\Delta}{\\sqrt{d_k}})V    (3)\nTwo de-stationary factors are learned by MLP using $\\mu_x, \\sigma_x$ and raw data. By introducing these factors, we can recover the non-stationary information deep in the model, which improves its performance in predicting real-world time series.\nThe task of the Decoder is to reconstruct the original values of IMU sequences with the representations extracted by Encoder. During the training period, we use a Mean Square Error loss to optimize.\nAt the output side of decoder, $\\mu_x$ and $\\sigma_x$ are used to transform the model output, $y' = [y_1, y_2, ..., Y'_s]^T \\in R^{S \\times E}$. De-normalization module operates as follows:\n$\\hat{y_i} = \\sigma_x \\odot y + \\mu_x$ (4)\nIn III-A, we compare the accuracy of models with and with-out data augmentation. For simplicity, we only compare the models whose classifier phase uses GRU. Table III presents the performance of NS-GRU, LIMU-GRU, and GRU on four datasets before and after data augmentation. \"FM\" denotes using data augmentation method. The number in bold indicates higher performances. All models' performance has greatly improved with the data augmentation method. According to our research, our model NS-GRU-FM achieves the state-of-the-art performance on UCI and OPPOHAR datasets in current open-source methods.\nTo facilitate user-specific activity recognition, we pretrain NS-GRU on common activities and finetune on uncommon activities as all other models. As shown in Table IV, our model achieves the best results among all models, suggesting the effectiveness of the pretrained Encoder for special action recognition.\nFor training the classifier on mobile devices, faster convergence will reduce the time and power consumption. Figure 3 shows the training loss of different models on common activities of OPPOHAR dataset with epochs. Results show our NS-GRU-FM model converges fastest, indicating the effectiveness of learning better repre-sentation of our network architecture and data augmentation method. This ensures the possibility of finetuning the classifier on user devices."}, {"title": "V. CONCLUSION", "content": "In this paper, we present a smartphone-IMU-based human activity recognition dataset named OPPOHAR. To enable the user-specific activity detection and to promote the implemen-tation in mobile devices, we propose Non-stationary BERT network and a new data augmentation method for IMU data. Experiment results show the effectiveness of NS-BERT model and the universality of the data augmentation method."}]}