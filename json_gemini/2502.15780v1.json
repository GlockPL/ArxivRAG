{"title": "Feature Engineering Approach to Building Load Prediction: A Case Study for Commercial Building Chiller Plant Optimization in Tropical Weather", "authors": ["Zhan Wang", "Chen Weidong", "Huang Zhifeng", "Md Raisul Islam", "Chua Kian Jon"], "abstract": "In tropical countries where humidity levels are high, air-conditioning can account for up to 60% of a building's energy use. For commercial buildings with centralized air-conditioning systems, the efficiency of the systems largely depends on the performance of the chiller plant, and model predictive control is a promising strategy for optimizing chiller plant control due to its ability to make dynamic adjustments based on predictive load. The accuracy of the predictive load is undeniably important in such control strategies. The advantages of artificial neural networks in modeling nonlinear complex systems have made them a prominent data-driven method for load prediction. However, they are often prone to overfitting due to their complex layers and numerous parameters. Appropriate feature engineering can overcome this challenge. While weather data are key features for load prediction and have been used in almost all neural network models, they are often input as raw numerical values without being treated with advanced feature engineering methods. Clustering feature inputs is a promising feature engineering technique that can reduce model complexity while increasing prediction accuracy. Though previous studies have investigated using clustering algorithms on past cooling load and temperature for load prediction, no existing study has utilized them on multidimensional weather data. This highlights a research gap in applying clustering algorithms to transform raw weather data into new features that could improve prediction accuracy. Additionally, few studies have considered the uncertainties and noise in the cooling load profile. In response to these challenges, this study developed a cooling load prediction model that combines a neural network with Kalman filtering and K-means clustering. By applying the model to real-world data from a commercial skyscraper in Singapore's central business district, we improved the cooling load prediction accuracy by 46.5%. Furthermore, an optimal chiller sequencing strategy was developed for the studied building through genetic algorithm optimization based on the predictive load, leading to potential energy savings of 13.8%. Finally, the study also assessed the integration of thermal energy storage systems into the chiller plant design, demonstrating potential reductions in capital and operational costs by 26% and 13%, respectively.", "sections": [{"title": "1. Introduction", "content": "The building sector is accounted for 39% of carbon emission globally and is the second largest energy consumption sector in Singapore. In alignment with the Paris Agreement, Singapore has committed to achieving net-zero emissions by 2050. T\u03bf realize this commitment, the Singapore Green Building Master Plan has outlined ambitious targets, aiming to make 80% of buildings green and achieve an 80% improvement in energy efficiency for the highest standard green buildings by 2030. Inevitably, there exists substantial potential and pressing need for reducing energy consumption in the building sector.\nHeating, ventilation, and air-conditioning (HVAC) systems play a significant role in the overall energy consumption of buildings. In the United States, for instance, these systems account for 50% of the energy consumption in buildings [1]. This figure can escalate to 60% in Singapore due to the prolonged need on air conditioning with the necessity of both sensible and latent heat removal in tropical climate [2]. Notably, chiller is the principal energy-consuming component within the air conditioning systems. A typical chiller plant is made up of chiller, cooling tower, pumps and its overall performance is commonly measured in kW/RT, which represents the electricity used by the plant for producing 1 refrigeration tonne of cooling effect to the building. The performance of chiller varies with the operating capacity, and centrifugal chillers are more efficient when its at full or nearly full load [3]. Hence, it is of best practices to operate chillers at the loading condition that consumes least energy. Optimization of the chiller plant aims to minimize the power consumption and achieve a lower kW/RT energy input while maintaining the needs and comfort of building occupants.\nTraditionally, optimization of HVAC systems is done through supervisory control where techniques can be classified into model-free or model-based supervisory control. The commonly used model-free control strategies including expert systems and reinforcement learning face challenges of unstable behaviour due to incomplete knowledge database, intensive fine tuning and the dynamics of the HVAC systems. Model-based supervisory control, on the other hand, utilized tools to model the system component are responsive to changes in control parameters and enjoys the"}, {"title": null, "content": "benefits of adapting to rapid changes in environment conditions [4]. Model predictive control(MPC) is a more advanced supervisory control strategy that emphasizes the influences of time varied environmental condition on system control effectiveness and incorporates future conditions in the present decision making and has demonstrated prominent performance in HVAC controls [5, 6, 7]. Intuitively, for implementing MPC on a chiller plant, the accurate prediction of building's cooling load is the first and crucial step.\nCooling load prediction methods can be broadly classified into physics-based and data-driven methods. The physics-based approach involves the creation of a detailed physics model based on fundamental heat transfer laws and comprehensive understanding of building characteristics. While this technique may capture the actual thermal response of the building, it encounters implementation challenges due to the considerable complexity of buildings and the lack of information updates over their operational life [8]. On the other hand, the data-driven method does not need to incorporate prior knowledge of the building characteristics and is built upon historical operational data collected from building's operational data [4]. The advantages of artificial neural network(ANN) in modeling non-linear complex systems and handling multi-variable problems have made it a prominent data-driven method for load prediction since 1990s [9, 10, 11]. In this study, we propose to incorporate feature engineering techniques that can potentially increase the prediction accuracy of ANN for building load prediction."}, {"title": "1.1. Previous Studies", "content": "As one of the pioneering works in using ANNs for load prediction, Kreider et al. [9] utilized data such as operating schedules, outside temperature, water temperature, food retailer sales, and a binary heating control signal to predict steam, water, electricity, and natural gas consumption. Since then, the ability of ANNs to provide accurate predictions without the need for building complex numerical simulations has made their adoption in load prediction common among researchers [12, 13]. Over the years, studies have explored the use of ANNs for predicting cooling load [8, 14, 15], heating load [16, 17], HVAC load [18, 19], electricity load [20, 21], and energy efficiency [22, 23]. Different ANN architectures have been investigated by previous studies including multilayer perceptron (MLP) [19, 24, 25], recurrent neural network(RNN)[26], long short-term memory(LSTM) [27], convolutional neural network (CNN)[28]. Besides building an effective model architecture, adopting feature engineering techniques is critical for developing an ANN model, as these transform raw data into meaningful features that ultimately improve the model's predictive performance.\nFeature engineering is the process of selecting, transforming, and creating input features to improve the performance of machine learning models. Since neural networks are often prone to overfitting due to their complex layers and numerous"}, {"title": null, "content": "parameters [29], feature engineering can reduce the model complexity while attaining the relevant information and patterns, hence helping to mitigate overfitting of ANN. Building cooling load can be broken down into three components: heat transferred through the envelope, heat produced by occupancy, and cooling and dehumidification of ventilation air. Existing studies have used weather conditions such as dry-bulb temperature and relative humidity as input features, due to their correlation with heat transferred through the envelope and ventilation air [30, 31], as well as day type and time features to account for occupancy load, given the daily seasonality in building load profiles [32, 33]. While some studies suggest that using a building's load at the previous time step can provide more reliable and accurate predictions due to the dynamics and auto-correlation of the building's load [34, 35], the ideal number of time steps often varies across studies, and there is no universal guideline for selecting the optimal number of past time steps. It is important to note that adding more features does not necessarily improve prediction reliability and accuracy, as too many features can lead to model overfitting and perform poorly on test dataset[26].\nClustering of feature inputs is a promising technique that can reduce model complexity while increasing prediction accuracy [47]. A clustering algorithm is a machine learning technique used to group similar data points into clusters, thereby uncovering inherent patterns in the data. When applied to ANNs, clustering can reduce dimensionality and highlight key features, leading to improved model performance [48, 49]. Previous studies investigating the application of clustering algorithms for building load prediction are summarized in Table 1, note that the applications also extend to energy classification, study of energy patterns, and occupant behavior, as these areas share similarities with load prediction. While most of the studies summarized used historical building load data with clustering algorithms, only a few investigated the use of outdoor temperature, and none explored clustering based on multiple weather parameters for building load prediction. Notably, the prediction model's ability in understanding and processing weather parameters plays an important role in short-term load forecasting [50]. And with the appropriate construction of these parameters, there is potential for developing adaptive control strategies that can response to the dynamics of building's load profile [51]. Hence, there exists a research gap in investigating the usefulness of clustering multi dimensional weather data for building load prediction, thereby unleashing the full potential of weather data for load prediction."}, {"title": "1.2. Proposed Study", "content": "Figure 1 illustrates the overall workflow of this study. First, a month of chiller plant's operation data from a 65-storey mixed-use commercial skyscraper located at Singapore central business district is sampled for this study. Second, the collected data are processed and prepared into feature sets incorporating feature engineering techniques including Kalman Filter and K-means clustering. Third, the training and validation of the neural network models is developed and compared between two commonly used model architecture, namely multi-layer perceptron (MLP) and long short-term memory (LSTM), following which the best performing validation model is used for load prediction on test dataset. A new chiller sequencing strategy targeted at minimizing chiller energy consumption is then derived from a optimization model built upon chiller partial load efficiency profile using genetic algorithm. Finally, the energy and cost benefits of integrating a thermal storage system into the chiller plant design is evaluated as a holistic approach to reduce the carbon footprints of the commercial building.\nThe rest of this study is structured into three sections, section 2 explains the methodology, where 2.1 elaborates on the data source, 2.2 explains on the feature engineering techniques, 2.3 details on structure of the neural network models, and 2.4 illustrates on the formalization of the optimization problem. Section 3 presents and discusses the results from the prediction model (3.1), optimization model (3.2, and integration with thermal energy storage (3.3). Section 4 concludes and highlights the main contributions of this study."}, {"title": "2. Methodology", "content": ""}, {"title": "2.1. Data Collection", "content": "A commercial mixed development located in the central hub of Singapore is sampled for purpose of the study. The development comprises four commercial uses: office, retail, residential, and hotel. The office strata has a total gross floor area of nearly 100,000 square meters, while the retail strata covers approximately 15,000 square meters. Both the office and retail strata share a common chiller plant, while the hotel and residential strata have individual air-conditioning systems. This study specifically utilizes data from the combined office and retail strata, collectively referred to as \"the building\u201d throughout the remainder of the study.\nThe air-conditioning system of the building is supported by a water-cooled chiller plant with a rated capacity of 5,000 refrigeration tons(RT). Six variable speed centrifugal chillers are deployed onsite, four of which are of 1000 RT capacity and the others are of 500 RT capacity each. The chilled water loop, which circulates chilled water to the air-handling units in the office strata and fan coil units in the retail strata, is facilitated by six chilled water pumps. Additionally, six condenser water pumps transport condenser water to the cooling tower, where the heat is expelled into the atmosphere. The building operates 24 hours a day, year-round, as chilled water is required for the server rooms of office tenants during nighttime hours. The standard operational hours are from 9 am to 6 pm for the office strata and from 10 am to 9 pm for the retail strata.\nOne months' operational data from the chiller plant is collected from the building management system, spanning from 1 August 2023 till 31 August 2023 at one minute interval. The data collected includes chilled water supply temperature, chilled water return temperature, chilled water header flow rate, condenser water"}, {"title": null, "content": "supply temperature, condenser water return temperature, condenser water return header flow rate, power consumption in kW of the respective water pumps and cooling towers. The cooling load of the building is calculated using the formula\n\\(CoolingLoad = C_{p,w} \\cdot m_w \\cdot (T_R - T_S)\\), where \\(C_{p,w}\\) is the specific heat capacity of water, \\(m_w\\) is the mass flow rate of the chilled water, \\(T_R\\) is the chilled water return temperature and \\(T_S\\) is the chilled water supply temperature. Weather data were extracted from the database the nearest weather observation station at Changi at half-hourly intervals. The data includes temperature, humidity, wind direction, wind speed, and pressure."}, {"title": "2.2. Feature Engineering", "content": "Selecting appropriate feature sets is crucial in prediction models because they: (a) improve prediction accuracy, (b) enhance the computational efficiency of training models, and (c) offer insights into data generation mechanisms. The cooling load of a building is typically from three components, heat transferred through the envelope, heat produced by occupancy, cooling and dehumidification of ventilation air. Heat transferred through roof and walls are driven by the temperature differences and the material's thermal resistance by the Fourier's Law. Since the properties of the building envelope remain unchanged and the indoor temperature is typically maintained at a constant level, the primary driving factor for heat transfer through the roof and walls is the outdoor temperature. Additionally, wind speed affects the convection heat transfer coefficient of the building envelope and is incorporated as a feature in the study. Heat gain through windows is influenced by the orientation of the building, the sun's angle, and atmospheric conditions such as cloud coverage. While the building's orientation is fixed and the sun's angle depends on time, cloud coverage is uncontrollable and challenging to quantify. Heat generated by occupancy fluctuates depending on the nature of human activities within the building and is contingent on building occupancy. Given the unavailability of specific occupancy data, the occupancy profile for a commercial building with office and retail functions is typically set for weekdays and weekends, correlated with time. Day type and time are utilized as variables to account for the influence on the human, lights, and equipment load. Cooling and dehumidification of ventilation air involves both sensible and latent heat gain. Sensible heat gain is driven by temperature differences, whereas latent heat gain is driven by the humidity ratio difference. In tropical countries like Singapore, where maintaining indoor humidity within a comfortable range requires the removal"}, {"title": null, "content": "of more moisture, latent heat gain often constitutes a substantial portion of the total cooling load.\nIn the context of cooling load prediction, feature selection faces several challenges: (a) balancing the model's complexity and the number of features to avoid overfitting or underfitting. Overfitting leads to high training accuracy but low testing accuracy, whereas underfitting fails in modeling complex systems accurately; (b) the varying nature of buildings means that the same features can have different impacts across different buildings; (c) potential noise introduced by the measurements from building automation systems [67]. In this study, two novel methods is proposed to address the challenges. The noise in measurements is managed by Kalman Filter and the complexity of the prediction model is brought down by introducing unsupervised machine learning algorithm K-means Clustering on weather data."}, {"title": "2.2.1. Kalman Filter", "content": "Chiller cut in may results in heavy fluctuations in building's cooling load profile. This phenomenon arises when a new chiller initiates operation, initially producing chilled water at a temperature higher than the desired setpoint. Consequently, this leads to an abrupt increase in the chilled water supply temperature and a sharp decrease in the calculated cooling load. These fluctuations pose challenges for load prediction. To address this, a common statistical method, the Kalman Filter, is employed."}, {"title": null, "content": "The Kalman Filter is adept at producing the best estimate of the system's true current state and is initially applied to the raw cooling load dataset. The Kalman filter algorithm is illustrated in Figure 2a and it can be broke down into a prediction stage and an estimate stage. Step I represents the prediction stage, the state prediction and error covariance are calculated by\n\\(\\hat{x_k} = A \\hat{x}_{k-1}\\)\n\\(P_k = AP_{k-1}A^T + Q\\)\nwhere A is the state transition matrix, \\(P_k\\) denotes the predicted covariance of the state estimate error, providing a measure of the estimated accuracy of the state prediction and Q is the process noise covariance matrix, representing the uncertainty of the system dynamics. The estimate stage involves step II and III. In step II, the Kalman gain is computed by\n\\(K_k = P_kH^T (HP_kH^T + R)^{-1}\\)\nwhere the Kalman gain \\(K_k\\) is a factor that balances the weight given to the predicted state and the new measurement, H is the measurement matrix that relates the state to the measurement, and R is the measurement noise covariance matrix, indicating the uncertainty in the measurements. In step III, the estimate is computed by\n\\(\\hat{x_k} = \\hat{x_k} + K_k(Z_k - H\\hat{x_k})\\)\nwhere \\(z_k\\) is the measurement at time \\(t_k\\). In step IV, the error covariance gets updates by\n\\(P_k = (I - K_kH)P_k^-\\)\nin every loop. The state transition matrix A is set to 1 as it is assumed that the closest estimate of the current prediction is the last estimate. As the cooling load is directly measurable, the measurement matrix H is set to 1. Q and R matrices are also set to 1 assuming there is no process noise and measurement noise."}, {"title": "2.2.2. K-means Clustering", "content": "Weather information is often used in prediction model as the dynamic changes in building cooling load is often related to temperature, humidity [60, 8]. However, the conventional way of inputting weather data as individual features and in numerical format has a few challenges: a) as there are more features input to the system, it unnecessarily complex the model. This will lead to more computation time that is not desirable. b) inputting weather data in raw format may not yield the best test performance. Clustered weather data as input to the model is proposed in this study to address these challenges."}, {"title": null, "content": "K-means clustering is an unsupervised machine learning technique that groups objects with more similarities into the same cluster and the algorithm is visualized in Figure 2b. In the Initialization step, k random points are selected as cluster centers, called centroids. These centroids are denoted as \\(\\mu_1,\\mu_2,...,\\mu_k\\). Next in the Assignment step, each observation point is assigned to the cluster with the nearest centroid. This is done by calculating the distance between each observation and each centroid. The commonly used distance metric is the Euclidean distance. The assignment of an observation \\(x_i\\) to cluster j is represented as:\n\\(Cluster(x_i) = \\arg \\min_j \\| x_i - \\mu_j \\|^2\\)\nThe update step recalculates the centroids of the clusters by taking the average of all points assigned to that centroid's cluster. The update of centroid \\(\\mu_j\\) is calculated as:\n\\(\\mu_j = \\frac{1}{\\|S_j\\|} \\sum_{x_i \\in S_j} x_i\\)\nwhere \\(S_j\\) is the set of all points assigned to the j-th cluster. The assignment and update steps will be repeated until the centroids no longer change, indicating that the clusters are as stable as possible and the algorithm has converged.\nThe effect of K-means clustering on the prediction model is evaluated on ambient dry bulb temperature, humidity ratio, and wind speed and compared with normalized raw weather data."}, {"title": "2.2.3. Construction of Feature Sets", "content": "Figure 3 summarizes the construction of feature sets. Eight sets of features are created as model inputs, namely: Raw N = 1,Raw _N = 5,K = 2 _N = 1,K = 2 N = 5,K = 3 _ N = 1,K = 3 N = 5,K = 4 _N = 1,K = 4 _N = 5, where Raw represents feature sets with raw weather data being z-score normalized, K refers to the numbers of clusters used in K- means clustering, N refers to the historical cooling load in N time steps (includes the current state, e.g., N = 1 refers to the current time step, N=5 refers to the current time step and the past 4 time steps). Using historical cooling load data to forecast future cooling load is a commonly used technique for load prediction [68, 67]; however, the ideal number of time steps may vary between models and datasets. Therefore, the suitability of this technique is being investigated"}, {"title": null, "content": "by comparing N = 1 and N = 5 in the proposed model. Other input features include workday/off-day encoded in a one-hot categorical format and normalized time data. Due to the limited time interval of the available weather data, the output target is set as the half-hourly ahead cooling load.\nA benchmark feature set is established to assess the performance of the 8 feature sets. The benchmark is constructed with cooling load without Kalman Filter, weather data without K-means clustering, and only the current state cooling load to predict the half-hourly ahead cooling load."}, {"title": "2.3. Prediction Model", "content": ""}, {"title": "2.3.1. Multi-layer Perception", "content": "A feedforward MLP network with one hidden layer is constructed in MATLAB using the feedforwardnet function on an 11th Gen Intel(R) Core(TM) i7-1165G7 machine with 16GB RAM. Previous studies have shown that increasing the number of layers does not significantly improve performance but does increase computational demand [69]. The network uses Levenberg-Marquardt backpropagation as the training function, and reasonable hyperparameter selections were made through manual tuning for the sake of brevity. However, it is acknowledged that auto-tuning could potentially enhance the model's performance.\nThe training process of MLP is illustrated in Figure 4. A feedforward network processes information stored in the input layer, containing input features. This information is then passed in one direction to the hidden layer and subsequently to the output layer, with different weights connecting them. Neurons in the hidden layer incorporate non-linear activation functions, introducing non-linearity to the model."}, {"title": null, "content": "After being processed by the activation functions in the hidden layer, signals are passed to the output layer with another set of weights connecting the two layers. The errors between the predicted output and the actual target is calculated by the loss function\n\\(J = \\frac{1}{m} \\sum_{i=1}^m (y_i-\\hat{y_i})^2\\)\nwhere m is the number of training examples, \\(y_i\\) and \\(\\hat{y_i}\\) are the actual and predicted values. The errors are then processed through the optimizer to update the weights, known as backpropagation. The fundamental formula governing the weight updates in the backpropagation algorithm can be expressed as\n\\(W_{ij}^{(l)} = W_{ij}^{(l)} - \\alpha \\frac{\\partial J}{\\partial W_{ij}^{(l)}}\\)\nwhere \\(W_{ij}^{(l)}\\) represents the weight between neuron i in layer I and neuron j in layer l + 1, ff is the learning rate, and \\(\\frac{\\partial J}{\\partial W_{ij}^{(l)}}\\) denotes the partial derivative of the cost function J with respect to the weight. The training of the weights iterates until the loss function is minimized or the maximum training epochs is achieved."}, {"title": "2.3.2. Long Short-term Memory", "content": "LSTM is a type of Recurrent Neural Network (RNN) designed to capture underlying sequential relationships in time series data by preserving information processed in past time steps, achieved through a specialized gating system consisting of an input gate, an output gate, a forget gate as illustrated in Figure 5. These gates collectively help the network to retain or forget information over long periods, addressing the vanishing gradient problem found in standard RNN.\nThe forget gate layer decides which information is to be retained and which discarded. For a given LSTM unit at time step t, the forget gate \\(f_t\\) is updated using the equation:\n\\(f_t = \\sigma(W_f \\cdot [h_{t-1}, x_t] + b_f)\\)\nwhere denotes the sigmoid function, \\(W_f\\)are the weights applied to the forget gate, \\(h_{t-1}\\) is the hidden state from the previous time step, \\(x_t\\) is the input vector at the current time step, and \\(b_f\\)represents the bias term for the forget gate."}, {"title": null, "content": "where * denotes element-wise multiplication.\nThe output gate layer decides what the next hidden state should be. The output gate \\(o_t\\) and the hidden state \\(h_t\\) are updated as follows:\n\\(O_t = \\sigma(W_o\\cdot [h_{t-1}, x_t] + b_o)\\)\n\\(h_t = o_t * \\tanh(C_t)\\)\nwhere \\(W_o\\) are the weights applied to the output gate and \\(b_o\\) represents the bias term for the output gate."}, {"title": "2.4. Optimization Problem", "content": "The goal of optimizing the chiller plant is to achieve minimum energy consumption while meeting the cooling load demand of the building. For development with multiple chillers, conventional chiller sequencing strategy is usually dependent on the chilled water supply temperature and flow rate. For example, for a primary pumping system where there's only one set of chiller water pump to support the chilled water loop, additional chiller will cut in when chilled water supply temperature exceeds the set point, or the measured cooling load meets or exceeds the operating chiller capacity. This conventional strategy ensures that the cooling load for the building can always be supplied by the chiller plant without considering the efficiency aspect, the reason is due to that chillers have different efficiency varying with part load ratio (PLR), where PLR of the chiller is defined as:\n\\(PLR_i = \\frac{chiller\\ operation\\ load_i}{chiller\\ capacity_i};\\)"}, {"title": null, "content": "Chiller power can be represented by the polynomial functions of the part load ratio (PLR) [70, 71, 72]:\n\\(P_i = a_i + b_i \\cdot PLR_i + c_i \\cdot PLR_i^2 + d_i \\cdot PLR_i^3\\)\nwhere \\(a_i\\), \\(b_i\\), \\(c_i\\), and \\(d_i\\) are interpolation coefficients relating the consumed power to the PLR for the ith chiller.\nAs chiller's operating efficiency is dependent on chiller loading, and it varies with brand, type of compressor and refrigerant used, it is hence important that chiller sequencing strategy can ensure chillers are operated in the manner that the minimum energy consumption can be achieved while ensuring that the cooling load of building is matched. Mathmatically, the optimization problem can be expressed as:\n\\(P_{total} = \\sum_{i=1}^k P_i(PLR_i)\\)\nwhere \\(P_{total}\\) is the total power, \\(P_i\\) is the power of chiller i, and \\(PLR_i\\) is the part load ratio of chiller i. The optimization problem is subject to the constraint that the building cooling load must be met by total chiller operation load:\n\\(\\sum_{i=1}^k PLR_i \\cdot chiller \\ capacity_i > Cooling \\ Load\\)\nConsidering the suggestions of the manufacturer, the PLR of the chiller should not operate below 0.3. Hence, the optimization problem is subject to the second constraint:\n\\(0.3 < PLR \\le 1 or PLR = 0\\)"}, {"title": "2.4.1. Genetic Algorithm", "content": "The GA is an evolutionary algorithm inspired by the process of natural selection and the algorithm is as illustrated in 6. Initially, the algorithm generates a diverse population of PLR settings randomly. Each set in this population acts as a potential solution, represented as a vector of PLR values for the chillers. The algorithm evaluates the fitness of each individual by using an objective function, aimed at minimizing the total energy consumption.\nSelection for reproduction is based on fitness, where individuals with higher fitness are more likely to be chosen, facilitating the spread of desirable characteristics. Through crossover, the genetic information of two parents merges to create offspring, whereas mutation introduces random changes, fostering new explorations in the search space."}, {"title": "3. Results and Discussion", "content": ""}, {"title": "3.1. Load Prediction", "content": ""}, {"title": "3.1.1. Prediction Performance", "content": "The feature sets are trained with the methodology illustrated in section 2.3. Each feature set is divided into a training set, validation set, and test set with a ratio of 70%, 15%, 15%. The model with the best validation performance from 10 runs on each feature set is then applied to the test set for prediction performance evaluation. Prediction performance is evaluated using the root mean squared error (RMSE) metric defined as\n\\(RMSE = \\sqrt{\\frac{\\sum_{i=1}^n (y_i - \\hat{y_i})^2}{n}}\\)\nwhere \\(y_i\\) and \\(\\hat{y_i}\\) are the actual and predicted values at time i respectively, and n is the total observation number.\nTable 3 summarizes the resulting prediction performance of the benchmark feature set and the 8 feature sets on MLP and LSTM models. Overall, the performance of"}, {"title": null, "content": "the \\(K = 2 _N = 1\\) feature set with a combination of Kalman Filter and K-means clustering achieves a 46.5% improvement against the benchmark on the MLP model and 41.8% on the LSTM model.\nFigure 7 and 8 presents the comparison of benchmark MLP model and the \\(K = 2 N = 1\\) MLP model. The performance comparison demonstrates that incorporating Kalman filtering and K-means clustering provides clear improvements in cooling load prediction accuracy. The benchmark MLP model, though capable of capturing the overall cooling load pattern, exhibits notable deviations from the target values, especially during periods of peak and valley load. In contrast, the \\(K = 2 _N = 1\\) MLP model, which utilizes Kalman Filter to smooth the noisy raw cooling load and K- means clustering to better structure the feature set, significantly reduces the error range and improves the alignment of the predicted values with the actual cooling load. The prediction curve of this model more closely follows the target, with fewer and smaller deviations. This is demonstrated in the RMSE for the \\(K = 2_N = 1\\) model is markedly lower at 82.1567 RTon, nearly half that of the benchmark MLP model."}, {"title": "3.1.2. Effect of Kalman Filter", "content": "The application of the Kalman Filter effectively smooths the fluctuations observed in the raw cooling load profile, particularly during the chiller cut-in periods. As shown in Figure 9, the fluctuations present in the cooling load measurements are smoothed, resulting in a more stable and accurate representation of the cooling load.\nKalman Filter managed the noise presented in the cooling load measurement and improved the prediction performance. Comparing the performance of Raw N = 1 feature set against the benchmark on both MLP and LSTM models, where the difference between the two feature sets is only the use of cooling load measurement and Kalman Filter cooling load, it is demonstrated 23.1% improvement on MLP model and 39.3% on LSTM are achieved. Figure 10 presents the performance regression for both the Raw N = 1 and benchmark MLP models, along with the corresponding prediction errors. In the benchmark model, the prediction output exhibit fluctuations, this behavior is reflected in the higher RMSE of the model performance. However, with the Raw _N = 1 model, the variance of the error is notably reduced, indicating more stable predictions with less fluctuation."}, {"title": "3.1.3. Effect of K-means Clustering", "content": "Figure 11 presents the clustering results for the weather data, including dry temperature, humidity, and wind speed. While clear boundaries are observable for K = 2 and K = 3, the boundaries become less distinct when the number of clusters"}, {"title": null, "content": "is set to 4. As a result, clustering for values of K greater than 4 was not investigated. Comparing the RMSE for feature sets with different weather clusters, the K = 2 feature set outperforms all raw weather feature sets, indicating that weather clustering not only reduces model complexity but also enhances overall prediction performance. For N = 1 feature sets in both MLP and LSTM models, the RMSE increases as K values rise, suggesting that increasing the number of weather clusters increases the likelihood of model overfitting on the test dataset. Weather clustering on N = 5 feature sets does not necessarily improve test performance, which may be due to the fact that including more historical cooling load data makes the model more complex and prone to overfitting.\nOverall, the K = 2 N = 1 feature set outperforms others on both MLP and LSTM models. For MLP, it achieves a 14.1% improvement compared to Raw N = 1 and a 46.5% improvement over the benchmark. For LSTM, it achieves a 4.5% improvement over Raw N = 1 and a 41.8% improvement over the benchmark. Notably, most N = 1 feature sets outperform all N = 5 feature sets, except for Raw N = 1 on MLP and K = 4 N = 1 on LSTM. This suggests that including more historical cooling load data does not necessarily improve prediction accuracy, as the current cooling load itself is a comprehensive feature that captures the necessary information for half-hour-ahead predictions. These results emphasize the importance of constructing balanced feature sets to prevent overfitting in load prediction models."}, {"title": "3.1.4. MLP vs. LSTM", "content": "The comparison results between MLP and LSTM models suggests that, despite being a simpler neural network, the performance of the MLP models can surpass that of the LSTM model for the purpose of this study with the best-performing MLP outperforms LSTM by 10.4% on K = 2 N = 1 feature set. It it also noted that MLP models generally can outperform LSTM models on feature sets with fewer parameters, while LSTM performs better than MLP on more complex feature sets with more"}, {"title": null, "content": "parameters (N = 5, K = 3,4). This observation supports the argument that current cooling load is a more useful feature than previous time steps, as LSTM inherently captures that information. Additionally, the MLP model offers significant computational savings, reducing the training time from over a minute with LSTM to within 5 seconds."}, {"title": "3.2. Chiller Optimization", "content": ""}]}