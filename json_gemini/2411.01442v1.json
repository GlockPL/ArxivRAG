{"title": "Online Relational Inference for Evolving Multi-agent Interacting Systems", "authors": ["Beomseok Kang", "Priyabrata Saha", "Sudarshan Sharma", "Biswadeep Chakraborty", "Saibal Mukhopadhyay"], "abstract": "We introduce a novel framework, Online Relational Inference (ORI), designed to efficiently identify hidden interaction graphs in evolving multi-agent interacting systems using streaming data. Unlike traditional offline methods that rely on a fixed training set, ORI employs online backpropagation, updating the model with each new data point, thereby allowing it to adapt to changing environments in real-time. A key innovation is the use of an adjacency matrix as a trainable parameter, optimized through a new adaptive learning rate technique called AdaRelation, which adjusts based on the historical sensitivity of the decoder to changes in the interaction graph. Additionally, a data augmentation method named Trajectory Mirror (TM) is introduced to improve generalization by exposing the model to varied trajectory patterns. Experimental results on both synthetic datasets and real-world data (CMU MoCap for human motion) demonstrate that ORI significantly improves the accuracy and adaptability of relational inference in dynamic settings compared to existing methods. This approach is model-agnostic, enabling seamless integration with various neural relational inference (NRI) architectures, and offers a robust solution for real-time applications in complex, evolving systems.", "sections": [{"title": "Introduction", "content": "Multi-agent interacting systems have been studied in various fields, including particle-based physical simulations [1-3], traffic systems [4, 5], and social networks [6-8]. Interaction among agents are crucial information to accurately model such systems and providing the interpretability in agent behaviors as well [9]. However, external observers can only access the trajectory of agents without knowing interaction graphs. Accordingly, Identifying unknown interaction graphs from observable trajectories of agents has been emerged as a specific problem referred to as relational inference [10].\nIn recent years, neural relational inference (NRI) and its variants have shown promising performance in synthetic and real-world environments [11-16]. Prior studies mostly aimed to present better network for NRI based on variational autoencoder (VAE) built with graph neural networks (GNN) [14, 15, 12, 17]. These methods involve an encoder to infer an interaction graph as an adjacency matrix from observed trajectories and a decoder to predict the future trajectories employing the inferred interaction graph. They generally perform training offline assuming the well-aligned distribution in training and testing data. Unfortunately, such assumption is frequently violated in practice due to the shifts in test condition, including sudden changes in the interaction, evolving system parameters and even dynamics itself. Building a relational inference model generalizable to all the different scenarios is challening [18-20]. In this case, online learning is an attractive approach to continuously adapt the model to the newly observed environments [5]. However, online learning for relational inference has been rarely explored."}, {"title": "Related Works", "content": "Neural relational inference. NRI [11] is the first work that formulated the problem of an unsupervised relational inference from observed agent trajectories. They implemented a VAE-based graph neural network that encodes trajectories into an adjacency matrix, representing relation types, and then decodes the trajectory using the predicted adjacency matrix. This approach has been established as a standard in several follow-up works. For example, dNRI [12] and EvolveGraph [15] introduced graph recurrent network-based architectures to encode and generate dynamic priors for predicting evolving interactions. Additionally, a memory-augmented architecture has been proposed for en- hanced long-term prediction using external associative memory pools [24]. More recently, finer granularities in relation modeling have been considered, such as edge to edge interaction [23], relation potentials using an energy-based function [25], and disentangled edge features [13]. However, all of these method commonly rely on an encoder-decoder pair in an offline setting, supported by a large amount of batched training samples, without considering various evolving scenarios.\nEvolving multi-agent systems. Apart from relational inference, trajectory learning of evolving multi-agent interacting systems have actively explored using graph neural networks [18, 26, 6]. In particular, graph neural ordinary different equations (ODE) have been applied to various evolving scenarios, including evolving environments (e.g., temperature and pressure) [18, 20] and stochastic motion [19]. However, these approaches assume a known graph structure, focusing on accelerating the simulation of physical dynamical systems [1, 7]. Additionally, each model addresses a specific type of evolution, raising questions about its generalizability to other scenarios. Moreover, adapting neural ODEs, potentially through online backpropagation, is a challenging problem since they are optimized from initial values [27].\nOnline learning for multi-agent systems. Online learning for relational inference in multi-agent systems is a rarely explored research problem despite its significance. One primary related work [5] also treats the adjacency matrix as a trainable parameter without using an encoder, optimizing it with an online expert mixture algorithm, a type of online convex optimization algorithm. Consequently, the loss function needs to be convex over the adjacency matrix to guarantee optimization. Their model architecture is specifically designed to place message passing in the last layer of the model to ensure the model output is a linear combination of hidden states and the adjacency matrix, maintaining the convex property. However, this simple architecture significantly differs from recent architectures (e.g., NRI and its variants), making it challenging to model nonlinear and complex interactions. Additionally, this work only report trajectory prediction errors without providing any accuracy metrics on relational inference. Please note that comparison with ORI is provided in the supplementary material."}, {"title": "Proposed Approach", "content": ""}, {"title": "Background", "content": "Neural relational inference. Relational inference aims to identify an unknown interaction graph represented by an adjacency matrix $I^* \\in R^{N\\times N\\times m}$, where N is the number of agents and m is the number of interaction types, from their trajectory in a given time period $x_{t:t+\\Delta t}$, which generally include positions and velocities of agents. Existing approaches are mostly designed with a neural network-based encoder and decoder pair, where encoder (g) predicts the adjacency matrix $I_t$ from an observed trajectory (i.e., $g(x_{t-\\Delta t:t}$) and then decoder predicts the future trajectory ($\\hat{x}_{t:t+\\triangle t}$) by $f_\\theta(x_{t-\\Delta t:t}, I_t)$. That is, the encoder is optimized to return the adjacency matrix for a lower error on the predicted trajectory (decoder output), assuming $I^* = arg \\min_{I_t} L(x_{t:\\Delta t}, f_\\theta(x_{t-\\Delta t:t}, I_t)$.\nOnline learning. Online learning problems have traditionally been formulated within the online convex optimization (OCO) framework, as introduced in [28]. Conventional gradient descent-based online optimization projects the updated variables onto a convex set at each step [29]. Such learning settings provide theoretical convergence guarantees when the loss function is convex with respect to the optimization variables. However, applying online gradient descent to deep neural networks (DNNs) is challenging due to the nonconvex nature of the loss function, and standard backpropagation performs poorly in an online setting [21]. Two primary directions of study have emerged to tackle the challenges of online backpropagation. One approach involves employing a flexible network structure, where the DNN architecture evolves over time [21, 30]. The other approach focuses on using an adaptive learning rate, where the learning rate is adjusted over time [31, 32]. Since our primary focus"}, {"title": "Motivation of ORI", "content": "Our objective is to discover hidden relations between agents in evolving multi-agent interacting systems using their streaming trajectories. The motivation of this work is from the primary challenges to apply existing methods to implement a fast-adapting, accurate, and stable online relational inference framework. Accordingly, we summarize our key motivations into three categories.\nWhy we consider adjacency matrix as trainable parameter? It may not be effective to simply apply the encoder and decoder-based existing methods to evolving multi-agent systems in the online setting. The primary challenge is that, the intricate encoder is slowly trained with streaming and evolving data. It eventually degrades the decoder as well since the encoder and decoder are jointly trained, influencing each other. Whereas, ORI allocates the adjacency matrix as a trainable parameter, significantly enhancing the training speed in both the matrix and decoder. While such allocation is motivated from [5], this work still faces following crucial challenges.\nWhy we need model-agnostic learning? The relation inference is performed through the trajectory prediction without an explicit supervision on graph structures (i.e., true relation is not observable). This means the only supervision is defined by the predicted trajectories from the decoder, and hence largely depending on how effectively the decoder responds to changes in the embedding adjacency matrix. If a learning method is particular constrained to a specific decoder design, like [5], the performance achievable by the method can be constrained by the decoder design. Ideally, the learning method should offer the flexibility to seamlessly integrate to various decoder designs.\nWhy we need adaptive learning rate? The choice of a learning rate is particularly important in the evolving systems since the loss landscape can significantly vary with the evolution in the systems. For example, a low learning rate may be suitable for a slowly evolving dynamics A, but may a high one is needed for stable operation in a fast evolving dynamics B. A constant (or decaying) learning rate leads to a slow convergence or/and potentially a sub-optimal performance as the dynamics evolves over time. Ideally, the learning rate needs to be automatically tuned over time, avoiding a trade-off between faster convergence and unstable learning."}, {"title": "Training Procedures of ORI", "content": "First, the key difference in our training setup compared to the offline learning setup is both batch and epoch are 1 (i.e., streaming data). There is no separate validation or test dataset in online learning. Training of ORI is performed by online backpropagation on each individual training sample every iteration. Note that the input and output to the decoder in the figure (denoted as GNN) and its optimization are essentially the same as existing methods. Our contribution is primarily in the optimization method for the adjacency matrix given by:\n$I(t + 1) = I(t) - h_n(D_I(t), \\eta(t)) \\frac{dL_{mse}(x_{t-\\Delta t+1:t+\\Delta t})}{dI(t)}$         (1)\nwhere $h_n(D_I(t), \\eta(t)) \\in R^1$ is the relation-aware adaptive learning rate, elaborated in the following paragraph. Initially, the adjacency matrix ($I(t) \\in R^{N\\times N\\times m}; I_{i,j}(t) \\in [0,1]$) is filled with 0.5. Each training sample given to the model involves a single trajectory for a time period of $t - \\Delta t : t + \\Delta t$ (i.\u0435., $x_{t-\\Delta t:t+\\Delta t}$). The decoder ($f_\\theta$) observes $x_{t-\\Delta t:t}$ and then predicts the future trajectory by $\\hat{x}_{t:t+\\Delta t} = f_\\theta(x_{t-\\Delta t:t}, I(t))$ in an autoregressive manner. It also reconstructs the trajectory $\\hat{x}_{t-\\Delta t+1:t}$ during the observation. ORI estimates a MSE loss on the predicted and reconstructed trajectory at $t+ \\Delta t$ (i.e., $L_{mse}(x_{t-\\Delta t+1:t+\\Delta t})$) and then updates the decoder and adjacency matrix using gradient descent. Note that, the adjacency matrix is updated only once at each iteration. The model infers the relation in the given trajectory at the last time step. While the training objective is to minimize the overall MSE loss throughout the streaming data, our primary evaluation criterion is the relation accuracy representing the proportion of true positive and true negative in the adjacency matrix.\nAdaptive relation-aware learning rate. We propose AdaRelation, a learning rate adaptation technique specifically designed for relational inference. AdaRelation adjusts the learning rate for the adjacency matrix (not the decoder) based on changes in the norm of the adjacency matrix. For example, if the norm exceeds a certain threshold, it gradually decrease the learning rate within a defined range.\nThe mechanism is intuitive: a good trajectory predictor should show large output variance depending on the adjacency matrix, meaning the quality of a predicted trajectory should vary clearly with changes in the adjacency matrix. We observe that the norm of gradient ($|| \\frac{dL_{mse}}{dI(t)}||_1$) indeed increases as the model adapted to the evolved system, often making the adjacency matrix unstable (see (1)). Conversely, it decreases when the system suddenly evolves, slowing down the update of the adjacency matrix. Therefore, the gradient norm indicates when the update of the adjacency matrix needs to be stabilized or accelerated. Given the adjacency matrix is the sum of this gradient over time, comparing the current matrix with a past one essentially reflects changes in the gradient norm. Accordingly, we define $D_I(t)$ to estimate the evolution in the L1 norm of the adjacency matrix over w time steps as follows:\n$D_I(t) = \\frac{1}{N^2m} ||I(t) - I(t - w)||_1$ (2)\nThis measures how much the predicted interaction strength ($I_{i,j,k}$) changes on average over w time steps. We define a threshold parameter $\\epsilon$ to constrain changes in $I_{i,j,k}$ to be remain near this threshold. The update of $\\eta(t)$ involves adding or subtracting $\\alpha$, an adaptation step size, determined by the range of $D_I(t)$ and the threshold:\n$\\Delta \\eta(\\tau) = \\begin{cases}\n-\\alpha & \\text{if } D_I(t) > \\epsilon \\\\\n\\alpha & \\text{otherwise}\n\\end{cases}$       (3)\nConsequently, the next learning rate ($\\eta(t + 1)$) is represented by $h_n(D_I(t), \\eta(t))$:\n$h_n(D_I(t), \\eta(t)) = clip_{\\eta_{min};\\eta_{max}} (\\eta(t) + \\Delta \\eta(t)))$           (4)\nwhere $clip_{\\eta_{min};\\eta_{max}}$ limits the learning rate within the lower bound ($\u03b7_{min}$) and upper bound ($\u03b7_{max}$). This effectively controls the learning rate to automatically stabilize and accelerate the update of the adjacency matrix. More intuition behind AdaRelation is discussed in the supplementary material.\nTrajectory Mirror. The models trained by the online backpropagation are often prone to be biased to certain training samples. It also happens in multi-agent interacting systems. For example, the coordinates and velocities of agents in the currently observed data samples can be biased. Such scenario has not been discussed much in literature because existing works expose the model to the huge amount of simulations with short-term trajectories, ensuring several different initial positions and velocities. However, our problem addresses streaming trajectories in a much longer-term, where we do not have an access to initialize their positions and velocities. Ideally, the relation between agents should be correctly inferred regardless where the model observes them. Accordingly, we consider a data augmentation technique named Trajectory Mirror, which flips the axis and generate, for example in a two-dimensional space, three additional trajectories. It is simple yet effective to avoid the model bias and significantly enhance the convergence speed of the model without storing the past trajectories. Ablation studies are available in the supplementary material.\nTechnical novelty. ORI is a novel model-agnostic online relational inference framework, incor- porating a strategic combination of two different learning methods for the adjacency matrix and decoder. ORI introduces AdaRelation, an adaptive learning rate technique designed for relational inference, and Trajectory Mirror, a simply yet effective data augmentation technique proved in several evolving scenarios (results are in supplementary). Our approach clearly differs from existing methods which perform end-to-end gradient descent on the encoder [11, 12, 23] or online convex optimization constrained to a specific decoder design [5]."}, {"title": "Experimental Results", "content": "Dataset. We experimented with three common benchmarks, synthetic springs and charged systems, and CMU MoCap (human motion) [22]. The synthetic datasets were generated using the open-source code from NRI [11]. For the springs and charged systems, 10 simulations with 90k time steps each were created, involving 10 agents with different random interactions (p = 0.5). These simulations are sequentially presented to models. The evolving relation dataset features different interaction graphs in each simulation with fixed spring k = 0.1 and ke = 1.0. Another dataset varies these constants, generated from uniform distributions [0.1, 0.2] for springs and [1,2] for charged constants. The evolving relation and dynamics dataset randomly selects each simulation from either the springs or charged systems. The CMU MoCap dataset, processed using dNRI's open-source code [12], includes human motion data with 31 joints and various actions, captured at 120Hz.\nBaseline and Implementation Detail. ORI is a model-agnostic online learning framework in- volving the trainable adjacency matrix. The adjacency matrix is initialized only at the initialization stage. The same adjacency matrix is used throughout the entire samples and simulations without assuming that we know when the interaction evolves. ORI can integrate with various models as long as they use the adjacency matrix as input. Most prior works use decoders based on graph multi-layer perceptron (MLP) and graph recurrent neural networks (RNN), as seen in NRI [11], incorporating node-to-edge and edge-to-node message passing. Additionally MPM [23] introduces a graph RNN and an attention-based graph RNN for more efficient edge-to-edge message passing. To demonstrate ORI's effectiveness, we use four different trajectory predictors: NRIm (MLP-based), NRIr (RNN-based), MPMr (RNN-based), and MPMa (attention-based). Since ORI employs the decoders in NRI and MPM, we primarily compare our approach with the original NRI and MPM. We also include dNRI [12], which is specifically designed for dynamically evolving interaction graphs. As these works analyzed the performance in the offline setup, we evaluated their models in the online setup. We follow their default implementation but replace the encoder with the trainable adjacency matrix. More details on the training setup is available in the supplementary material."}, {"title": "Inferring Relation in Evolving Interaction Graph", "content": "We explore relation inference accuracy in the synthetic systems incorporating evolving interaction graphs. These systems involve constant parameters and no switching in the dynamics. The relation accuracy is evaluated based on the number of true positives and true negatives excluding self-interaction (i.e., total 10\u00d79 relations). Our approach is able to quickly recover the relation accuracy when the model encounters a new interaction graph. For example, in the bottom , the target interaction matrix suddenly changes at the 15k-th iteration. While it fails to adapt in a single iteration, the target and predicted matrices are aligned well after 100 iterations. In contrast, the baseline (MPM)'s accuracy slowly increases throughout the entire training iterations, showing a significant gap in the average relation accuracy. Figure 2(b) compares the target and predicted trajectories at the 15k-th iteration (i.e., right after the new interaction) and 18k-1-th iteration (i.e., right before another interaction), indicating the trajectory quality also improves along with the accuracy.\nTable 2 showcases the average accuracy and average MSE loss during entire iterations in the springs and charged systems. As the interaction graph changes over time, simply reporting the final accuracy only represents how well the model adapts to the last graph. Accordingly, we report the average accuracy over entire iterations to understand the model's accuracy on the multiple graphs and how fast it adapts to the change in the graphs. ORI with four different decoders consistently outperform the existing encoder and decoder-based methods with respect to the accuracy. Note that TM is applied to both existing methods and ours for the fair comparison. It is crucial to emphasize that, in the charged system, our results with almost 40% higher accuracy does not exhibit lower trajectory errors. For example, NRI reaching at only 52.0% accuracy still shows the lower MSE of 3.80\u00d710-3 ~ 4.63 \u00d7 10-2 over all the prediction steps than our results. This implies the comparison solely using the MSE loss may not indicate the quality of inferred relations at all. The lower MSE in existing methods is probably achieved by the larger capacity than our methods due to the encoder, overfitting to the trajectory modeling, not the relation inference. However, in spring systems, the methods with higher accuracy exhibits lower trajectory errors."}, {"title": "Inferring Relation in Evolving Interaction Graph and Dynamics", "content": "ORI is evaluated on the two additional evolving scenarios in the springs (spr) and charged (cha) systems, where 1) interaction graph and parameter evolve and 2) interaction graph and the dynamics itself evolve. In addition, we analyse the relation learning rate to understand how the relation accuracy responds depending on the learning rate. The yellow, red, and blue curves correspond to ORI with AdaRelation, ORI with constant learning rate (lower bound), and ORI with constant learning rate (upper bound). Figure 3 showcases the relation accuracy and relation learning rate over 30k training iterations in both the evolution scenarios. Although the models tend to slowly converge compared to the springs systems, they can still adapt to the systems with evolving parameters or switching dynamics, reaching to the 1.0 accuracy given enough training iterations.\nAn interesting observation lies in changes of the relation learning rate. For example, the learning rate in AdaRelation (yellow) automatically increases at the 12k-th iteration, decreases over time, and then increases again at the 15k-th iteration. This means that AdaRelation notices a change in the interaction graph of the systems in an unsupervised manner and hence increases the learning rate for a while. This ensures not only the fast adaptation to a new environment but also the stability (i.e., less fluctuation in the accuracy) after the relation accuracy converges. Moreover, Figure 3 (right bottom) demonstrates that AdaRelation controls the learning rate depending on the dynamics as well. The models with a high learning rate are stable enough in the springs systems. However, the fluctuation in the accuracy emerges in the charged systems, particularly when the accuracy almost reaches at 1. AdaRelation effectively suppresses such flucutation without sacrificing the convergence speed. For example, between the 18k-th and 21k-th iterations, the accuracy of AdaRelation converges as fast as the high learning rate's one while having much less fluctuation in the later iterations. Thus, AdaRelation effectively enhances the convergence speed, stability, and overall accuracy in evolving multi-agent interacting systems. The related accuracy and ablation studies are available in the supplementary material."}, {"title": "Discussion on Performance Gain in ORI", "content": "We discuss how existing methods fail to clarify the benefit of ORI over them. Since they share the same trajectory predictors, the primary reason should be studied with respect to the encoder side.\nLightweight encoders in existing works. One of the key features in ORI is the encoder-less design, having much fewer trainable parameters, excluding the trajectory predictor, than existing works. To clarify whether the performance gain is from the less trainable parameters, we demonstrate how existing methods perform when their encoder is significantly lightened while having the same decoder. Figure 4(a) showcases the relation accuracy depending on the encoder complexity in the spring system with evolving interaction. However, the performance gain from their lightweight encoders are not significant, indeed still much lower than ORI. Accordingly, we explore the following two additional experiments."}, {"title": "Real-world Application", "content": "ORI is assessed in the real-world human motion dataset (CMU MoCap) [22] against existing offline methods. Figure 5 showcases the target and predicted trajectories on walking motion from ORI (1-st row) and the top-30 strongest relations between joints in a skeleton model for the corresponding frame (2-nd row). Additionally, the figure incorporates the inferred relations from MPM (3-rd row). The visual comparison illustrates that ORI's predicted joint trajectories closely alighn with the target, yet ORI exhibits higher MSE loss compared to MPM However, similar with the observation in the charged systems ORI appears to offer more interpretable relation inference on the joints. For example, in 3-rd row of the figure, MPM simplifies the relational inference by cyclically focusing on right foot, left foot, and right foot again. In contrast, ORI introduces an additional layer of shifts in the relation, emphasizing primary connections between left foot, right knee, and right foot. This additional detail enhances the interpretability of the walking motion."}, {"title": "Conclusion", "content": "Summary. We introduced Online Relational Inference (ORI), a novel framework for online re- lational inference in evolving multi-agent interacting systems. ORI employs an adaptive learning rate technique, AdaRelation, allowing it to adapt dynamically to changing environments through online backpropagation. Our approach also includes the Trajectory Mirror (TM) data augmentation method to enhance generalization. This model-agnostic framework seamlessly integrates with various neural relational inference architectures, providing a robust solution for real-time applications in com- plex, evolving systems. Future work will focus on enhancing the adaptability in more fast-evolving interaction and exploring its applicability to a wider range of multi-agent systems.\nLimitation and future work. Our current experiments do not evaluate ORI in non-ideal environ- ments, incorporating directed interaction graphs or/and variable number of nodes. This limits the potential of ORI in relatively ideal environments. We expect that ORI can be extended to scenarios when agents are added or deleted, provided we are aware of which agent is added and deleted by adding and deleting corresponding row and column in the adjacency matrix. While the experiments in the paper do not explicitly include directed interactions, ORI does not assume any symmetry (undirected graph) in the adjacency matrix. In other words, there is no technical limitation to apply ORI in directed interaction."}, {"title": "Training Setup", "content": "Training setup. For the synthetic datasets, the model observed the first 30 time steps ($x_{t-30:t}$) and then predict the next 30 time steps ($x_{t:t+30}$). The next prediction window is defined on $x_{t+30:t+90}$. Simialrly, for the CMU MoCap data, the model observed the first 10 time steps and then predict the next 10 time steps. We trained the models with a single GTX 2080Ti GPU.\nImplementation details. We directly use the implemented decoders from NRI [11] and MPM [23] for ORI with NRI and ORI with MPM. The hidden size on the decoders are set to 256 as default. The learning rate for the decoders is 1e-4.\nThe initial learning rates ($\\eta(0)$) for the adjacency matrix is 100 for ORI with NRI decoders and 20 for ORI with MPM decoders. The lower and upper bound for learning rates in AdaRelation are $\\eta_{min} = 100 \\eta_{max} = 200$ for ORI with NRI decoders, $\\eta_{min} = 20 \\eta_{max} = 50$ for ORI with MPM decoders. The threshold $\\epsilon$ and adaptation step size $\\alpha$ in AdaRelation are set to 0.05 and 1. For the CMU MoCap dataset, we observe that the gradient on the adjacency matrix is relative small; in order to ensure more dynamic updates in the adjacent matrix, we largely increase the $\\eta(0)$ to 100k."}, {"title": "Additional Discussion", "content": "Computational complexity. In terms of trainable parameters, NRI has 721.4k for encoder and 727.3k for decoder; MPM has 1724.9k for encoder and 1071.7k for decoder; dNRI has 883.7k for encoder and 269.8k for decoder. In terms of FLOPs per iteration, NRI shows 177.8MFLOPs for encoder and 5040.5MFLOPs for decoder; MPM shows 3.9GFLOPs for encoder and 10.9GFLOPs for decoder. It indicates that the decoder consumes more computation than the encoder even though they are with the similar level of trainable parameters.\nIntuition behind the norm of gradient $||\\frac{dL_{mse}}{dI(t)}||_1$. The norm of gradient indicates that how the trajectory error ($\\Delta L_{mse}$) changes by the adjacency matrix ($\\Delta I(t)$). Ideally, we expect this norm being high enough so that the model learns the strong correlation between the trajectory of agents and their relation. In other words, the low norm of gradient means that, the model returns the similar trajectory regardless of the relation (i.e., adjacency matrix), which is undesirable.\nIntuition behind the deviation $D_I(t)$. The deviation is a function of $||I(t) - I(t-w)||_1$, where both $I(t)$ and $I(t - w)$ are the learned adjacency matrix, not the actual one. Hence, the significant change in the actual adjacency matrix used for generating the observed time series, may not necessarily lead to large values of the deviation. This depends on the how quickly ORI learns the new adjacency matrix as discussed below.\nConsider a scenario when the actual adjacency matrix significantly changes between the time step t-w and t. Assume ORI has learned the actual adjacency matrix at time step t w. Now, at time step t, ORI can respond in two possible ways.\nFirst, ORI may quickly identify the new adjacency matrix at the time step t. In this case, $I(t)$ and $I(t - w)$ will be related to the new and previous actual adjacency matrices, respectively. Assuming the two actual adjacency matrices are significantly different, the deviation between two learned adjacency matrices will also be large. Hence, based on equation (3), the learning rate will decrease. This will make the learned adjacency matrix stable, thereby helping ORI to stay at the new learned adjacency matrix at time t, which is desirable as that is also the actual adjacency matrix.\nLet us now consider the second case where ORI does not quickly learn the new actual adjacency matrix and hence, the learned adjacency matrix at time t stays close to the one learned at time step t - w. In other words $||I(t) - I(t - w)||_1$ remains low even if the actual adjacency matrices have changes. In this case, following equation (2), the learning rate increases to rapidly update the learned adjacency matrix, which is desirable to quickly move the learned matrix to the actual one.\nIn summary, the equation (2) and (3) appropriately updates the learning rate when actual adjacency matrix changes, even without any knowledge/supervision of that actual matrices."}]}