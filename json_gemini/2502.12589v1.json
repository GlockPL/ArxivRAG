{"title": "RM-PoT: Reformulating Mathematical Problems and\nSolving via Program of Thoughts", "authors": ["Yu Zhang", "Shujun Peng", "Nengwu Wu", "Xinhan Lin", "Yang Hu", "Jie Tang"], "abstract": "Recently, substantial advancements have been made in training language models\nto carry out step-by-step reasoning for solving intricate numerical reasoning tasks.\nBeyond the methods used to solve these problems, the structure and formulation of\nthe problems themselves also play a crucial role in determining the performance of\nlarge language models. We observe that even small changes in the surface form of\nmathematical problems can have a profound impact on both the answer distribution\nand solve rate. This highlights the vulnerability of LLMs to surface-level variations,\nrevealing its limited robustness when reasoning through complex problems. In\nthis paper, we propose RM-PoT, a three-stage framework that integrates problem\nreformulation (RM), code-aided reasoning (PoT), and domain-aware few-shot\nlearning to address these limitations. Our approach first reformulates the input\nproblem into diverse surface forms to reduce structural bias, then retrieves five\nsemantically aligned examples from a pre-constructed domain-specific question\nbank to provide contextual guidance, and finally generates executable Python code\nfor precise computation.", "sections": [{"title": "1 INTRODUCTION", "content": "Mathematical reasoning is a cornerstone of problem-solving, with applications spanning diverse\nfields such as physics, engineering, economics, and computer science. However, despite their success\nin general natural language processing tasks, existing Large Language Models (LLMs) such as GPT-4\nstruggle with mathematical problems that demand precision, logical reasoning, and step-by-step\ncomputation Hendrycks et al. (2021). This gap arises because LLMs rely heavily on statistical\npatterns in natural language, which often fail to capture the formal structure and symbolic complexity\nof mathematical problems. Cobbe et al. (2021).\nCurrent advancements in mathematical reasoning with LLMs have primarily focused on methods\nlike Chain-of-Thought (CoT) prompting Wei et al. (2022); Diao et al. (2023); Zhang et al. (2022),\nwhich encourages models to break problems into reasoning steps. Self-Consistency (SC) methods\nfurther refine CoT by introducing multiple reasoning paths to identify consistent answers. While\neffective, these approaches are still limited when faced with problems requiring complex computation\nor diverse logical forms. As shown in Fig 1(a), the LLM fails to provide the correct answer directly\nwhen posed with a complex calculation problem.\nThis limitation is handled by another notable approach, Program of Thoughts (PoT), which introduces\nintermediate code generation to represent reasoning steps explicitly, improving the interpretability of\nsolutions and disentagle computation from the reasoning process. However, PoT alone cannot resolve\ninconsistencies arising from ambiguous structured problem forms. As shown in Fig 1(b), we can\nobserve that small changes in the surface form of the mathematical problem can lead to significantly\ndifferent outcomes.\nTo address these challenges, we propose RM-PoT, a novel two-stage framework that integrates\nReformulation of Mathematical Problems (RM) and Program of Thoughts (PoT). The RM stage\nprompts the LLM to generate multiple paraphrased versions of the same problem, thereby mitigating\nthe adverse effects of poorly structured problem formulations. By generating multiple reformulations\nof a given problem and exposing the model to various formulations of the same task, LLMs can\nuncover the core mathematical structure underlying the problem zho. This diversity in problem\npresentation improves the LLM's accuracy and consistency in solving the problem. In the PoT stage,"}, {"title": "2 RELATED WORK", "content": "In recent years, numerous studies have explored using the System-2 reasoning approach to solve\nmathematical problems with LLMs Wei et al. (2022); ?); ?. As a prominent framework, chain-of-\nthought(CoT) is proposed by Wei et al. (2022). Rather than generate the answer directly, it prompts\nthe LLMs to produce a sequence of intermediate reasoning steps. ? further extended CoT by\nself-consistency. They generate multiple reasoning steps from different angles and potentially lead\nto the same answer. Chen et al. (2022) proposes program-of-thoughts, using intermediate codes to\nrepresent the reasoning process."}, {"title": "2.2 SPECIALIZED MODELS FOR MATHEMATICAL TASKS", "content": "To address the limitations of general-purpose LLMs, specialized approaches have been developed.\nFor instance, MathGPT ? integrates symbolic computation engines to solve algebraic problems,\ncombining language modeling with symbolic reasoning. However, this hybrid approach still depends\nheavily on the capabilities of external tools. Other models, such as GeoSolver? and MathQA ?,\nfocus on specific domains like geometry or math question-answering, using domain-specific datasets\nand tailored architectures. While these models perform well in their respective areas, their narrow\nfocus limits generalization to broader mathematical tasks."}, {"title": "2.3 PROBLEM REFORMULATION IN MATHEMATICAL PROBLEM SOLVING", "content": "The role of problem reformulation in enhancing the performance of language learning models (LLMs)\nin mathematical problem solving has gained increasing attention in recent years. Early work by ??\ndemonstrated that altering the structure and phrasing of a problem can lead to improved reasoning\noutcomes in LLMs. This line of research has been extended by?, who explored how different surface\nforms of mathematical problems can significantly influence the solve rate of LLMs. Further studies\nhave investigated the impact of reformulation strategies such as paraphrasing? and introducing\nproblem variants ?, suggesting that diverse representations help models better understand and process\ncomplex tasks. Building on these insights, recent works have also delved into the combination of\nreformulation with in-context learning techniques to optimize model performance through adaptive\nproblem presentations."}, {"title": "3 METHOD", "content": "We propose RM-POT, a framework that leverages the potential of large language models (LLMs) to\nsolve mathematical problems. The overall architecture of RM-POT is illustrated in Fig. 2, consisting\nof two stages.\n\u2022 Stage I: We reformulate the given mathematical problems into diverse surface forms,\nenabling the LLM to better grasp the underlying structure of the problems.\n\u2022 Stage II: We employ the Program of Thoughts Chen et al. (2022) (PoT) approach, which\ngenerates Python code to solve the reformulated problems. This approach not only reveals\nthe reasoning process of the LLM but also separates the computational steps from the\nreasoning process.\nThe details of these two stages are described in the following subsections."}, {"title": "3.1 REFORMULATE MATHEMATICAL PROBLEMS(RM)", "content": "As demonstrated in Section 1, the surface form of a problem significantly influences the performance\nof LLMs zho. Therefore, we prompt the LLM to generate K different surface forms of the original\nproblem and use a voting mechanism to determine the answer. The intuition behind this approach\nis that if a problem exhibits a low solve rate and ineffective reasoning paths due to its original\nsurface form, introducing diversity in its surface forms can enhance the likelihood of finding a correct\nsolution."}, {"title": "3.2 PROGRAM OF THOUGHTS(POT)", "content": "Program of Thoughts (PoT) is a method aimed at enhancing the reasoning capabilities of large\nlanguage models (LLMs) Chen et al. (2022). It works by decomposing complex tasks into a series\nof intermediate steps, or \"thoughts\", which guide the model through a structured reasoning process.\nEach thought represents a logical step that incrementally leads to the final answer, enabling the model\nto tackle intricate problems using a step-by-step approach.\nThis method improves the model's ability to solve tasks that require multi-step reasoning, such as\nmathematical or logical problems, by fostering transparency in the reasoning process and increasing\naccuracy in the final result. PoT has proven effective in scenarios where direct answers are difficult,\nallowing LLMs to perform more reliably in problem-solving tasks.\nIn our proposed RM-PoT, we aim to instruct the LLM to generate intermediate Python code to solve\nmathematical problems. This approach can clearly show the reasoning process of LLM and improve\naccuracy."}, {"title": "3.3 SELF-CONSISTENCY (SC) AND VOTING", "content": "In our proposed RM-PoT framework, we reformulate the original problems into K different surface\nforms. Morever, we utilize the Self-Consistency(SC) ? method. Specifically, for each formulated\nproblem, we let LLM generate reasoning paths, and thus the total number of generated answer is\nN. We then vote for the final answer."}, {"title": "4 EXPERIMENTS", "content": ""}, {"title": "4.1 EXPERIMENTAL SETTINGS", "content": "Datasets We evaluate our approach on the following public mathematics reasoning benchmarks:\n\u2022 GSM8k Cobbe et al. (2021) contains 8.5K linguistically diverse grade school-level math\nquestions with moderate difficulties.\n\u2022 AQUA? consists of 100K algebraic word problems, including the questions,the possible\nmultiple-choice options, and natural language answer rationales from GMAT and GRE.\n\u2022 SVAMP? contains 1K arithmetic word problems. It focuses on basic arithmetic operations\nsuch as addition, subtraction, multiplication, and division.\nLarge Language Model We use GLM-4-9B ? as our base model. All experiments are conducted in\nzero-shot or few-shot settings, without training or fine-tuning it. For generation configs, We set the\ntemperature T = 0.7, Top-p= 0.8 and Top-k= 3. The total number of reasoning paths N we sample\nfor each problem is 16.\nImplementation Details For problem solving, the PoT process consists of two steps, as illustrated in\nFig. 4. First, we prompt the LLM to generate Python code and store the result in a variable with a\nfixed name, allowing for convenient extraction. If the problem includes options, we instruct the LLM\nto identify the closest match among the provided options."}, {"title": "4.2 EFFECTIVENESS OF REFORMULATING", "content": "To verify the effectiveness of RM, we reformulate the selected problems from the AQuA dataset and\ncalculate the solve rate difference between the original problems and their reformulated versions. An\nexample is shown in Fig. 5 to provide readers with an intuitive understanding of the RM process.\nWhen the surface form of the original problem is altered, the solve rate increases from 43.8% to\n81.3%."}, {"title": "4.3 MAIN RESULTS", "content": "In this subsection, we compare the performance of RM-PoT with Chain of Thoughts (CoT), vanilla\nself-consistency (SC), and vanilla Program of Thoughts(PoT). All results are presented in Table 1. In\nthis evaluation, we apply the naive reformulation of the original problems. the number of reformulated"}, {"title": "4.4 ABLATION STUDY", "content": "In this subsection, we vary the number of reformulated problems K across {1,2,4}, while keeping\nthe total reasoning paths fixed at N = 16. Additionally, we compare the naive reformulation with the\nIn-Context reformulation, as outlined in Fig 3. The results are shown in Table 2.\nWe observe that as K increases, the performance of the LLM improves as well. This further validates\nour assumption that exposing the LLM to different surface forms of a problem allows it to better\ngrasp the underlying structure. Notably, on the SVAMP dataset, the LLM performs better when\nK = 2 than when K = 4. This may be because the problems in this dataset are relatively simple,\nand the process of reformulating and solving the problems involves some degree of randomness.By\ncomparing the naive reformulation with the In-Context reformulation, we can conclude that the LLM\nlearns the reformulation method more effectively when provided with good examples."}, {"title": "5 DISCUSSION", "content": "In this section, we discuss how RM-PoT helps the LLM solve math problems through the example\nshown in Fig. 7. When applying CoT, the LLM makes two mistakes. First, there is an error in\nrearranging the terms of the equation in the second step.econd, the result of 21.90/1.60 is actually\n20.660, not 20.741. This demonstrates that the LLMs has certain shortcomings in computation and\nreasoning.\nTo disentangle computaion from reasoning process, we then apply the PoT method. We find that\nthe LLM's answer is generally correct, but it misinterprets the original price as the discounted price\nduring the understanding of the problem. However, after reformulating the original problem, the\nLLM correctly understands the question and provides the correct answer. Although both versions\nof the problem contain the term 'original price,' the LLM does not fully grasp this in the original\nformulation. The deeper reasons behind this remain unclear and will be explored in future work."}, {"title": "6 CONCLUSION", "content": "In this paper, we present RM-PoT++, a framework that advances mathematical reasoning in LLMs\nthrough domain-aware few-shot learning, problem reformulation, and Program of Thoughts. By\nretrieving semantically aligned examples from a pre-constructed question bank, our method primes\nLLMs to interpret problems consistently, while reformulation and code generation mitigate struc-\ntural ambiguities and computational errors. Experiments across datasets demonstrate statistically\nsignificant accuracy gains and robustness to linguistic variations.\nHowever, the underlying reasons why naive reformulation can enhance performance are still unclear.\nIn some cases, the reformulated problem even exhibits a lower solve rate than the original. Future\nwork could explore more effective ways to reformulate problems and integrate fine-tuning methods\nto further improve the performance of LLMs. At the same time, this method can be improved in the\nfollowing ways:\n\u2022 Generalization: Extend to geometry and calculus by curating domain-specific banks with\ndiagram-to-code mappings.\n\u2022 Adaptive Retrieval: Dynamically adjust the number of few-shot examples (K) based on\nproblem complexity.\n\u2022 Human-in-the-Loop: Integrate user feedback to refine the question bank and domain classi-\nfier."}]}