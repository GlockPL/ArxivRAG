{"title": "Interpretable Rule-Based System for Radar-Based Gesture Sensing: Enhancing Transparency and Personalization in AI", "authors": ["Sarah Seifi", "Tobias Sukianto", "Cecilia Carbonelli", "Lorenzo Servadei", "Robert Wille"], "abstract": "The increasing demand in artificial intelligence (AI) for models that are both effective and explainable is critical in domains where safety and trust are paramount. In this study, we introduce MIRA, a transparent and interpretable multi-class rule-based algorithm tailored for radar-based gesture detection. Addressing the critical need for understandable AI, MIRA enhances user trust by providing insight into its decision-making process. We showcase the system's adaptability through personalized rule sets that calibrate to individual user behavior, offering a user-centric AI experience. Alongside presenting a novel multi-class classification architecture, we share an extensive frequency-modulated continuous wave radar gesture dataset and evidence of the superior interpretability of our system through comparative analyses. Our research underscores MIRA'S ability to deliver both high interpretability and performance and emphasizes the potential for broader adoption of interpretable AI in safety-critical applications.", "sections": [{"title": "I. INTRODUCTION", "content": "In a time where the importance of transparency within Artificial Intelligence (AI) is ever-increasing, our research presents an innovative Rule-Based System (RBS) explicitly designed for radar-based gesture sensing. This contrasts sharply with the prevalent black-box Neural Networks (NNs), which, despite their effectiveness, often fail to provide clarity in decision-making processes. In sectors where interpretability is critical, such as healthcare and security, this raises concerns [1]. Radar-based gesture-sensing offers unique advantages to common camera-based sensors, particularly in scenarios where visual or tactile interaction is limited. This technology enables hands-free interactions, making it ideal for automotive, healthcare, and smart home applications. However, existing gesture-sensing approaches often rely on complex NNs [2], hindering interpretability and customization. To meet the growing demand for personalized experiences, there is a pressing need for Machine Learning (ML) models that can adapt to individual users' behavior and characteristics. In response, we propose an interpretable and personalizable multi-class rule-based algorithm (MIRA), which employs rule induction to automatically generate transparent if-then rules. Each rule, potentially composed of multiple conditions known as literals, uncovers meaningful patterns within the data and shows the reasoning behind the system's decisions.\nMIRA is specifically tailored for sensing applications and is applied to Frequency-Modulated Continuous Wave (FMCW) radar-based gesture sensing. Distinguishing our algorithm from conventional RBSs like RIPPER [3], IREP [4], SkopeRules [5], and FOLD-R++ [6], MIRA can perform multi-class (gesture) classification. Past models have predominantly focused on binary classification tasks, neglecting the complexities inherent in multi-class scenarios commonly encountered in gesture classification applications. Additionally, they obscure interpretability through the use of non-interpretable ML models like Random Forests or heuristics, e.g., information gain and the Gini impurity index for rule development. Our approach, on the other hand, harnesses a comprehensible combination of a weighted Silhouette score (SC) and the F-Beta score. This approach not only promotes interpretability but also refines the rules for each gesture class, ensuring that significant features are not overlooked and providing a more balanced assessment across different classes. Additionally, we innovate through the introduction of personalized rule systems. These personalized rules enhance the model's adaptability, allowing it to adjust to the nuances of individual user behaviors and preferences, thereby tailoring the user experience.\nWe present a novel methodology adapted for FMCW radar-based gesture sensing. This approach harnesses the strengths of RBSs to capture relationships in radar data, translating them into simple yet informative rules for distinguishing between five gesture classes.\nOur contributions include: 1. Introducing MIRA, a new RBS architecture based on the F-Beta score and a novel weighted SC for multi-class (radar-based gesture) classification, expanding beyond previous algorithms only supporting binary classification. 2. Development of personalized rule systems based on foundational rules, enhancing adaptability and performance. 3. Publication of an extensive FMCW radar-based gesture-sensing dataset containing 21k gestures [7]."}, {"title": "II. RULE-BASED GESTURE SENSING", "content": "This section outlines the architecture of MIRA, our RBS for gesture sensing, covering the rule induction process and the integration of personalized rules for improved user adaptability."}, {"title": "A. Algorithm for Rule-Based Gesture Sensing", "content": "Rule Induction Based on Sequential Covering. In this work, we employ a rule induction process based on sequential covering to develop the RBS for interpreting radar-based gesture sensing. MIRA iteratively selects the best rule to add to an initially empty rule set and hence sequentially removes samples that the rule covers until (almost) all samples have been accounted for or a stopping criterion is met. Our algorithm develops and optimizes rules based on a training and a validation dataset, respectively, using rule-stopping and early-stopping criteria. The primary criteria involve setting a maximum number of rules and literals, to maintain the complexity of the rule set. Other criteria are based on the coverage and the accuracy of a rule. The former refers to the fraction of samples that satisfy the rule's conditions, whereas the latter is the fraction of correctly covered samples. In this work, we set the minimum coverage of the newly developed rule on the training dataset. Additionally, minimum rule coverage and accuracy rate are defined on a validation dataset. As a last stopping criterion, a minimum number of samples in the training and the validation dataset are defined. If the number of samples left in each dataset is less than the specified values, the rule development is stopped. These measures are put in place to prevent overfitting rules on a small number of samples and outliers in the training dataset. On top of that, they ensure generalizability by evaluating the rule on a separate validation dataset. These stopping criteria balance model complexity and performance, ultimately reducing the number of conditions and overall rules.\nWeighted Silhouette and F-Beta Score for Rule Development. To enable multi-class classification, we identify the most compact gesture class for rule development based on a weighted SC. This is the first step of MIRA. The SC of a cluster is computed based on the average distances within and outside the cluster, providing an intuitive alternative to traditional methods like information gain. This score ranges from -1 to 1, where a score closer to 1 indicates that the object is well-matched to its own and poorly matched to neighboring clusters. The SC of a gesture class j is defined as:\n$\\text{SC}_j = \\frac{1}{N} \\sum_{i=1}^N \\frac{b(x_i) - a(x_i)}{\\max\\{a(x_i), b(x)\\} } $ (1)\nwith N being the total number of samples. $a(x_i)$ is the average distance of the gesture sample $x_i \\in \\mathbb{R}^{n_{\\text{frames}} \\times n_{\\text{features}}}$, with $n_{\\text{frames}}$ being the number of frames and with $n_{\\text{features}}$ being the number of features, to all other samples in the same cluster. $b(x_i)$ is the average distance of $x_i$ to the samples in other clusters.\nTo prevent biased rule development towards classes with fewer samples, a weighted SC method, incorporating cluster size and sample distribution, is proposed. This approach aims to avoid favoring smaller clusters with a higher SC, ensuring a fair evaluation of all classes. The weighted SC developed in this work is:\n$\\text{SC}_{\\text{weighted},j} =  \\lambda_1 \\frac{\\sqrt{N_j}}{\\sqrt{N_{\\text{left}}}} + \\lambda_2  \\cdot \\lambda_3 \\cdot \\text{SC}_j $ (2)\nwith $ \\lambda_1 \\in [0,1] $ weighting the overall transformed impact based on the cluster size and $\\lambda_2 \\in [0,\\infty)$ directly weighting $n_j$, the number of samples in the current cluster j relative to all not yet classified samples $ N_{\\text{left}} $ remaining in the training dataset. $\\lambda_3 \\in [0, 1]$ adjusts the weight of SCj.\nOnce the optimal gesture class is identified, the second step of MIRA is started, which is rule development and evaluation using the F-Beta score. It combines precision and recall into a single metric, with the flexibility of adjusting the importance ratio $\\beta \\in [0,\\infty)$:\n$\\text{F-Beta} = (\\beta^2 + 1) \\frac{\\text{Precision} \\cdot \\text{Recall}}{\\beta^2 \\text{Precision} + \\text{Recall}} = (\\beta^2 + 1)  \\frac{\\text{TP}}{\\beta^2(\\text{FN} + \\text{FP}) + (1 - \\beta^2)\\text{TP}}$ (3)\nThe F-Beta score is useful when both precision and recall are taken into account, but their respective weights should be adjusted. In this work, we prioritize False Positives (FP), i.e., precision, over False Negatives (FN), i.e., recall by setting $\\beta < 1$ to 0.3. Falsely negative predicted gestures, which are not being covered by a rule, can be correctly classified by a subsequent rule, whereas the opposite is not achievable. The algorithm allows for dynamic evaluation and refinement of rule literals based on the F-Beta score, providing control over the rule-generation process.\nAs a last step, upon meeting one of the defined stopping criteria, a default-else rule based on majority voting is incorporated into the rule set. This final rule is assigned to the most prevalent gesture class among the samples not accounted for by the preceding rules. Fig. 1 illustrates the main components of the rule-based gesture sensing algorithm."}, {"title": "B. Foundational and Personalized Rules", "content": "In the realm of gesture sensing, the performance gap between a RBS and more advanced techniques like black-box NNs is evident. The latter can achieve superior results. The former is constrained by its inability to capture the complex dynamics of gestures across diverse individuals and environments, limiting its generalization abilities even with validation sets and early-stopping criteria.\nTo overcome these constraints, we propose an innovative approach centered on foundational and personalized rule sets. Foundational rules provide a broad understanding of gesture"}, {"title": "III. EXPERIMENTS AND DISCUSSION", "content": "This section presents MIRA's performance in multi-class gesture classification with our radar dataset, contrasts it with conventional RBSs and a Feed-Forward Neural Network (FFNN), and highlights the interpretability and customization through foundational and personalized rules."}, {"title": "A. Radar System and Dataset Description", "content": "In this research, Infineon Technologies' XENSIVTM BGT60LTR13C 60 GHz FMCW radar has been used. This radar was set to function across a frequency range from 58.5 GHz to 62.5 GHz, providing a range resolution of 37.5 mm and a maximum resolvable range of 1.2 m. For the transmission of signals, it uses a burst configuration, emitting 32 chirps within each burst at a frame rate of 33.3 Hz, and a pulse repetition time of 300 \u03bc\u03b5.\nA total of 21,000 gestures were performed by eight individuals in six different locations, with a field view of \u00b145\u00b0 and a distance of < 1 m from the radar. The dataset includes five different gesture types, including Swipe Left, Swipe Right, Swipe Up, Swipe Down, and Push. A recording has an approximate duration of 3s or 100 frames with the gesture execution itself being 0.3s or ten frames long. The dataset is accessible on IEEE Dataport [7].\nSince this work is centered on the interpretability of radar-based AI, we utilize the lightweight radar processing algorithm introduced in [8]. The hand movements are characterized via five features, i.e., radial distance (range), radial velocity (Doppler), horizontal angle (azimuth), vertical angle (elevation), and signal magnitude (peak). For the input to the ML models, we distilled these features by averaging their values across only the ten gesture frames."}, {"title": "B. Comparative Evaluation of Rule-Based Systems", "content": "This section details a comparative analysis that reveals MIRA's enhanced performance, particularly in multi-class classification tasks, as outlined in Table 1. This capability is a notable advancement over conventional RBS frameworks, which typically do not support multi-class functionality. The evaluation protocol was rigorous, involving experiments not only on the training data but also on both In-Distribution (ID) and Out-Of-Distribution (OOD) datasets, incorporating data from a variety of users and environments. ID and OOD data refer to matching and non-matching distributions with the training data, respectively. The dataset of 21, 000 gestures were split into 11,000 gestures based on four users in three locations and into 10, 000 remaining gestures. From the 11,000 gestures, 7,920 and 1,980 gestures were used as training and validation data, respectively. 1, 100 recordings were used as ID test data whereas the remaining 10,000 were used as OOD test data.\nTo facilitate a fair comparison with binary classification RBSs, we developed individual rule sets for each class. These were then merged to construct a comprehensive rule set designed for multi-class classification. To ensure comparability, we standardized the number of rules and literals across systems to a limit of 15 rules with a maximum of two literals each. For MIRA, the minimum rule coverage on the training dataset was set to eight, and on the validation dataset was set to five samples. The minimum validation rule accuracy rate for rule evaluation was set to 70%. If less than six or two samples were left in the training and validation dataset, respectively, early stopping was triggered to avoid overfitting. The empirically found parameters of the weighted SC were always set to $ \\lambda_1 = 0.5, \\lambda_2 = 10$, and $ \\lambda_3 = 0.7$.\nOur findings show that MIRA not only attains higher accuracy in real-world multi-class scenarios (accuracy increase up to 13.4% for ID 14% for OOD data) but also provides a more streamlined and intuitive set of rules. Instead of needing different rule sets for each gesture class, we can provide an interpretable rule list capable of multi-class classification. This leads to greater model transparency, meeting the growing need for AI systems that are both effective and easy to understand."}, {"title": "C. Performance-Interpretability Trade-off in Radar-based Gesture Sensing", "content": "This section emphasizes the trade-off between performance and interpretability when choosing between an RBS and a FFNN for radar-based gesture sensing. The FFNN consists of three fully connected layers. The first two layers each have 16 nodes and a ReLU activation function, while the third layer has five nodes (corresponding to the number of classes) and a softmax activation function. During training, the model uses the Adam optimizer, a learning rate of 0.001, the sparse categorical cross-entropy loss function, and a batch size of 32 for 100 epochs."}, {"title": "D. Foundational and Personalized Rules for Improved Radar-Based Gesture Sensing", "content": "By introducing the concept of foundational and personalized rules, as highlighted in Fig. 2A), the study achieved higher model performance while still maintaining interpretability and allowing model customization. As shown in Table??, the model accuracy for six different users with and without personalized rules was assessed. The removal of the last else-default rule and the addition of up to four personalized rules to the foundational rules improved model performance (average performance boost of up to 9.6%). The user pattern may not be captured sufficiently with fewer rules and may lead to overfitting with more rules. The study found that a small set of personalized rules, developed using only five gestures per gesture class, was sufficient to achieve this performance improvement.\nIn summary, MIRA presents a significant advancement over existing methods in terms of interpretability and customizability. It outperforms other RBSs with its transparent and user-tailored approach, which is crucial for applications requiring a clear understanding of model decisions. Although a FFNN might achieve better predictive performance, MIRA offers greater transparency, making it a preferable choice when explainability is a priority. The integration of personalized rules further accentuates the RBS's ability to fine-tune predictions to individual user characteristics, showcasing its adaptability and user-centric design."}, {"title": "IV. CONCLUSION", "content": "This paper presents a significant advancement in the context of RBSs, offering an interpretable solution tailored for radar-based gesture-sensing applications. We addressed the limitations of existing models and introduced novel methodologies for rule induction. By focusing on rule transparency and the incorporation of personalized rules, our RBS MIRA not only meets the demands for interpretable Al but also provides a customized interface that adapts to individual users. The comparative evaluations and discussions based on an extensive FMCW radar gesture dataset presented in this paper underscore the practicality and necessity of such systems."}]}