{"title": "KPCA-CAM: Visual Explainability of Deep\nComputer Vision Models using Kernel PCA", "authors": ["Sachin Karmani", "Thanushon Sivakaran", "Gaurav Prasad", "Mehmet Ali", "Wenbo Yang", "Sheyang Tang"], "abstract": "Deep learning models often function as black boxes,\nproviding no straightforward reasoning for their predictions.\nThis is particularly true for computer vision models, which\nprocess tensors of pixel values to generate outcomes in tasks\nsuch as image classification and object detection. To elucidate\nthe reasoning of these models, class activation maps (CAMs) are\nused to highlight salient regions that influence a model's output.\nThis research introduces KPCA-CAM, a technique designed to\nenhance the interpretability of Convolutional Neural Networks\n(CNNs) through improved class activation maps. KPCA-CAM\nleverages Principal Component Analysis (PCA) with the kernel\ntrick to capture nonlinear relationships within CNN activations\nmore effectively. By mapping data into higher-dimensional spaces\nwith kernel functions and extracting principal components from\nthis transformed hyperplane, KPCA-CAM provides more ac-\ncurate representations of the underlying data manifold. This\nenables a deeper understanding of the features influencing CNN\ndecisions. Empirical evaluations on the ILSVRC dataset across\ndifferent CNN models demonstrate that KPCA-CAM produces\nmore precise activation maps, providing clearer insights into the\nmodel's reasoning compared to existing CAM algorithms. This\nresearch advances CAM techniques, equipping researchers and\npractitioners with a powerful tool to gain deeper insights into\nCNN decision-making processes and overall behaviors.", "sections": [{"title": "I. INTRODUCTION", "content": "In recent years, Convolutional Neural Networks (CNNs) [1]\nhave emerged as the cornerstone of various artificial intel-\nligence applications, demonstrating unparalleled performance\nin computer vision tasks. However, despite their remarkable\nachievements, CNNs are often characterized as opaque \"black\nboxes,\" leaving developers in the dark regarding the underlying\ndecision-making processes. This lack of interpretability poses\nsignificant challenges, particularly in fields where accountabil-\nity, fairness, and trust are paramount.\nThe opacity of CNNs [1] stems from their complex archi-\ntectures, consisting of multiple layers of interconnected neu-\nrons that transform input data into high-level representations.\nWhile these networks excel at capturing intricate patterns and\nfeatures, understanding how they arrive at their predictions\nremains elusive. This inherent black-box nature hinders not\nonly users' ability to interpret and trust CNN outputs but also\nlimits the potential for identifying biases, errors, or unethical\ndecision-making within these models."}, {"title": "II. BACKGROUND", "content": "The original CAM technique [2] represents a significant leap\nin the realm of CNN [1] interpretability. These techniques offer\na window into understanding which regions of an input image\nplay pivotal roles in the decision-making process of CNNs.\nThe foundational work by Zhou et al. introduced CAM [2],\na technique that directly visualizes feature activations related\nto specific output classes, but required extensive modifications\nto the network architecture. This method facilitated compre-\nhension of the model's focus areas, laying the groundwork for\nsubsequent advancements.\nBuilding upon CAM, Selvaraju et al. introduced Grad-CAM\n[3], which utilized gradient information from the last convo-\nlutional layer to generate more effective visual explanations.\nUnlike CAM [2], Grad-CAM's versatility allowed it to be\napplied across various CNN models [1], without changing the\narchitecture of the model. Grad-CAM's limitations in local-\nization granularity and interpretability for multiple objects led\nto refinements proposed in Grad-CAM++ [4], which improved\nthe visualization by considering the importance of each pixel\nfor the decision of interest.\nScore-CAM [5] utilized a score-based weighting approach\nto generate class activation maps. This method did not rely on\ngradient information, offering a more intuitive visualization of\nmodel decision-making processes. There are set of challenges,\nsuch as increased computational intensity due to need for\nmultiple forward passes through the network and potential\nambiguity in cases of subtle feature influences. Jiang et al.\nproposed Layer-CAM [6], enhancing the granularity of class\nactivation mappings by leveraging hierarchical information\nacross different CNN layers. This technique provided more\ndetailed visual explanations of model behavior by dynamically\nweighting the contribution of each layer's feature maps to the\nfinal decision. Muhammed et al. introduced Eigen-CAM [7],\nwhich employed PCA [8] on feature maps to generate class\nactivation maps. This model-agnostic technique highlighted\ndiscriminative features with minimal computational overhead.\nDespite its advantages, Eigen-CAM's simplification via PCA\nmight overlook critical details in understanding the model's\ndecision-making process."}, {"title": "III. PROPOSED APPROACH", "content": "Images have instrinsic dimensionality [10], composed of\nsignals with varying degrees of freedom and cannot be\nevaluated using linear operators. Therefore, CNNs employ\nnon-linear activation functions [11] to learn abstract features\nin non-linear space. A limitation of Eigen-CAM is that it\ncomputes a linear combination of activations from a specific\nconvolutional layer to provide salient features in the direction\nof the first principal component. While this approach offers\nvaluable insights into the most influential features within the\ninput data, it may oversimplify the decision-making process\nof the CNN due to capturing only linear combinations. CNNS\noperate through nonlinear transformations, meaning that the\nrelationship between input features and network activations is\noften complex and nonlinear. It's reliance on linear combina-\ntions may fail to capture the full complexity of these relation-\nships, potentially leading to a loss of important information\nsuch as the non-linear spatial relationships present within\nCNN feature maps. CNNs learn hierarchical representations\nof the input data, where features at higher layers represent\nincreasingly abstract concepts. Eigen-CAM's linear approach\nmay overlook these hierarchical structures, limiting its ability\nto provide a comprehensive understanding of CNN behavior."}, {"title": "A. Kernel PCA", "content": "PCA [8] is highly effective for linear data transformations\nbut it may not capture the data in the underlying structure\nof nonlinear datasets. Kernel Principal Component Analysis\n(Kernel PCA) [9] is an extension of PCA [8] that allows for\nthe nonlinear mapping of data into higher-dimensional spaces,\nwhere nonlinear relationships can be better captured. Unlike\nPCA, Kernel PCA employs kernel functions to project data\ninto higher-dimensional feature spaces, enabling the extraction\nof nonlinear patterns and structures from the data. In short,\nKernel PCA [9] takes a dataset and maps it into some higher\ndimension, and then performs PCA on the new dimensional\nspace.\nLet K denote the kernel matrix, where each element\nrepresents the dot product of one point with respect to all\nother points. The kernel formulation of PCA computes the\nprojections of data onto the principal components (not the\ncomponents themselves). The projection from a point in the\nfeature space onto the k-th principal component is defined as\nProjection(x, k) = vk \u00b7 K. (1)\nIn (1), vk is the k-th eigenvector of the kernel matrix, and\nK is the dot product of x with all other transformed points."}, {"title": "B. Kernels", "content": "1) Radial Basis Function (RBF): The Radial Basis Func-\ntion (RBF) [9] is a kernel function that computes the similarity\nor distance between pairs of data points based on their radial\ndistance from a center. The RBF kernel between two data\npoints $x_i$ and $x_j$ is defined as\nK(xi, xj) = exp(-$\\gamma$ * ||xi \u2013 xj ||2) . (2)\nIn (2), $\\gamma$ defines the spread of the kernel and determines the\ninfluence of nearby points on the similarity measure."}, {"title": "2) Sigmoid Kernel:", "content": "The Sigmoid function [9] is an acti-\nvation function commonly used to add non-linearity into a\nmodel's architecture. It converts the input to a value between\n0 and 1, making it usable for binary classification tasks. It is\ndefined between two data points $x_i$ and $x_j$ as\nK(xi, xj) = tanh($\\gamma$ * xxj + r). (3)\nIn (3), $\\gamma$ is a scale parameter that controls the slope of the\nhyperbolic tangent function, while r is an offset parameter that\nshifts the input to the hyperbolic tangent function."}, {"title": "\u0421. \u041a\u0420\u0421\u0410-CAM", "content": "To generate activation maps which capture non-linear repre-\nsentations learned by the CNN model, we apply Kernel PCA\non the feature maps generated by convolutional layers.\nLet C represent the output of the last convolution layer. We\nconstruct a kernel matrix K using a kernel function applied\nto the feature vectors in C to calculate pairwise distances.\nThe eigenvectors of K can be obtained by solving:\nK = V\u039bV-1, (4)\nwhere V is an orthogonal matrix and \u039b is he diagonal matrix\nof eigenvalues.\nThe class activation map, L is given by the projection of K\non the first eigenvector V\u2081 in the matrix V. Formally, this is\ndefined as\nL = KV1. (5)"}, {"title": "IV. EXPERIMENT RESULTS", "content": "In this section, we will briefly explain the experiments\nand metrics used to evaluate the performance of the novel\napproach as well as provide the performance comparison and\nanalysis to alternate CAM methods. We create two K\u0420\u0421\u0410-\nCAMS, KPCA-CAM(S), which uses the sigmoid kernel and\nKPCA-CAM(R), which uses the RBF kernel. For the sigmoid\nkernel, we use a gamma value of 0.1, while we employ a\ngamma value of 0.001 for the RBF kernel. Two experiments\nwere conducted on 5000 randomly sampled datapoints from\nthe ILSVRC validation set [14], which contains images along\nwith their classes and bounding boxes. We used VGG-16 [15],\nResNet-50 [16] and DenseNet-161 [17] as the base models and\ngenerated class activation maps from the last convolutional\nlayer of these models."}, {"title": "1) Weakly supervised object localization:", "content": "This experiment\ninvolves creating a bounding box of the image using only\nthe class activation map and checking the IoU between this\npredicted bounding box and the actual coordinates. IoU [18]\nmeasures the overlap between two bounding boxes or regions.\nIt is calculated by dividing the area of intersection between the\npredicted bounding box and the ground truth bounding box by\nthe area of their union. The resulting value lies between 0 and\n1, where 0 indicates no overlap and 1 indicates perfect overlap.\nThe mathematical formulation for IoU is\nIoU = Area of Intersection / Area of Union. (6)\nIn (6), Area of Intersection is the area shared by the\npredicted bounding box and the ground truth bounding box\nwhile Area of Union is the total area covered by both boxes."}, {"title": "V. CONCLUSION", "content": "In this paper, we present a novel approach to Class Acti-\nvation Mapping, KPCA-CAM, which uses advanced kernel\ntechniques to enhance the interpretability of convolutional\ndeep neural networks. Through rigorous experiments, we\ndemonstrate the effectiveness of KPCA-CAM in providing\nclearer visual explanations of model predictions. KPCA-CAM\nis intuitive and easy to use, requiring only the learned represen-\ntations from the last convolution layer, making it independent\nof fully connected layers. These insights aid in understand-\ning neural network decision-making and improving computer\nvision model performance. Future work in this field can be\nto explore the use of CAM techniques for explainability of\nvision models in tasks such as caption generation and visual\nquestion answering."}]}