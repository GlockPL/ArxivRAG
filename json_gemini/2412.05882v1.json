{"title": "Towards Modeling Data Quality and Machine Learning Model Performance", "authors": ["Usman Anjum", "Chris Trentman", "Elrod Caden", "Justin Zhan"], "abstract": "Understanding the effect of uncertainty and noise\nin data on machine learning models (MLM) is\ncrucial in developing trust and measuring perfor-\nmance. In this paper, a new model is proposed to\nquantify uncertainties and noise in data on MLMs.\nUsing the concept of signal-to-noise ratio (SNR), a\nnew metric called deterministic-non-deterministic\nratio (DDR) is proposed to formulate performance\nof a model. Using synthetic data in experiments,\nwe show how accuracy can change with DDR and\nhow we can use DDR-accuracy curves to deter-\nmine performance of a model.", "sections": [{"title": "1 INTRODUCTION", "content": "Machine learning-based models and algorithms are being\nused widely for many different tasks. They are increasingly\nbeing used in sensitive domains like healthcare, finance &\nbanking, security, etc. to make critical decisions. In addition,\nmost of the machine learning algorithms are \"black-box\"\nmodels which means the information of the internal work-\nings is not known. As a result, we may not completely trust\na machine-learning algorithm and its results Kaplan et al.\n[2023] and it becomes necessary to understand the strength\nand limitations of a model.\nBiases, strengths, and limitations of machine learning al-\ngorithms can also arise from the quality of the data and\ninductive bias of the algorithm itself. In the machine learn-\ning domain, biases have also been referred to as \"fairness\".\nFairness is the absence of any prejudice or favoritism to-\nwards an individual or group based on their inherent or\nacquired characteristics Mehrabi et al. [2021]. An unfair\nalgorithm and low-quality data can result in skewed results\nthat can lead to incorrect conclusions Pagano et al. [2023].\nA major reason for the data quality is the uncertainty and\nnon-deterministic nature of data which is caused by the\ndata source, and during data entry or acquisition. The non-\ndeterministic nature of the data is usually considered as\nnoise, but it may not necessarily be noise and there may\nbe inherent properties of the data that are necessary for\nthe analysis. For example, consider weather data that has\nsome uncertainty due to patterns. Non-deterministic data\nwould cause models to have difficulty in understanding\nand interpreting such data correctly. Most of the current\nresearch has focused on how to deal with the problem of\nnon-deterministic nature of data sets. For example, filter-\ning out noise Quinlan [1983, 1986] or enhance the quality\nby pre-processing by 'hand' or automatically Zhu and Wu\n2004]. There are numerous pre-processing methods to deal\nwith the noise and non-deterministic nature of data, such as\neliminating the noisy instances completely and interpolation\nto correct the non-deterministic data to match the determin-\nistic data points. However, the pre-processing techniques\nare dependant on the task being performed. Hence, the non-\ndeterministic nature of data can adversely affect the results\nof any data analysis and reduce accuracy of the model.\nUnderstanding the effect of noisy and nondeterministic data\nin the model can help understand the performance and lim-\nitations of a model under uncertain and noisy conditions.\nUncertainty in data is an important aspect to consider when\nmeasuring model performance. Uncertainty can arise due\nto imperfect or unknown information Hariri et al. [2019].\nHence, if we can quantify and measure the uncertainty and\nnoise, we could in fact get a true measure of the performance\nof a model.\nCurrent machine learning algorithms only focus on measur-\ning the accuracy of the model, as to how well the predicted\ndata match the actual data Flach [2019]. However, this in-\nformation may not be enough, especially when we want to\nmeasure the performance of a model Brown et al. [2021]. In\nfact a research conducted by Wu and Keogh [2021] explored\nthe quality of data in anomaly detection and showed that\nthe benchmark dataset used for anomaly detection had very\nlittle uncertainty in the data and hence, even the most simple"}, {"title": "2 RELATED WORKS", "content": "The need to develop a comprehensive technique to measure\nthe performance of a model has been mentioned widely in\nprevious literature Brown et al. [2021]. Currently, the mod-\nern way to measure performance is to measure the difference\nbetween predicted and actual values. But these methods of\nmeasuring performance do not include data quality and the\nuncertainty.\nOne way of measuring the performance is to use the con-\ncept of trust. There are few ways that trust in AI can be\nquantified. Previous research has understood the importance\nof noise and its effect on the accuracy of a model. For ex-\nample, the National Institute of Science and Technology\n(NIST) has modeled trust in the system in terms of two\nimportant parts. User Trust Potential, which is a function of\nthe user, and Perceived System Trustworthiness, which is a\nfunction of the user, the system, and context Stanton et al.\n[2021]. Consequently, the main attributes that define AI sys-\ntem trustworthiness are: Accuracy, Reliability, Resiliency,\nObjectivity, Security, Explainability, Safety, Accountability,\nand Privacy. Trust was measured as the user's perception of\neach attribute.\nAn example metric for measuring trust in a machine learn-\ning method was proposed by Wong et al. Wong et al. [2020].\nThe measure of trustworthiness of a particular deep neural\nnetwork is according to how it operates under correct and\nincorrect result situations; trust density, a description of the\ndistribution of general trust of a deep neural network for a\nparticular answer situation; trust spectrum, a model of gen-\neral trust in accordance with the variety of possible answer\nsituations across both correctly and incorrectly answered\nquestions; and NetTrustScore, a scalar metric summing up\nthe general trustworthiness of a deep neural network accord-\ning to the trust spectrum.\nAnother aspect of trust is in relation to how the model in-\nteracts with different qualities of data. The quality of data\nis related to the uncertainty in the data, mainly arising dur-\ning data collection Hariri et al. [2019]. This quality of the\ndata is based on some features, such as noise, fairness, or\nbias, found in the data. A model that cannot handle low-\nquality data would be considered low in performance and\nless trustworthy than other models. Mehrabi et al. looked at\nthe quality of data in terms of fairness and produced a taxon-\nomy of different fairness definitions that other researchers\nmade to avoid bias and compiled the results to show the un-\nfairness present in current AI systems and how researchers\naddress these issues Mehrabi et al. [2021].\nQuality in data was also studied by the papers in Anjum et al.\n2022] and Anjum et al. [2023]. According to the authors\nthe data source determines the quality of the data and they"}, {"title": "3 PRELIMINARIES", "content": "Data is typically classified as being structured or unstruc-\ntured Majumdar et al. [2013]. Structured data is data that is\norganized and ordered, like tabular data. Unstructured data\nincludes data with no organization, for example text data.\nSince unstructured data is converted into structured form,\nwe focus on structured data in this paper. We assume that\neach column represents a variable and each row represents\nthe record of the data.\nWe assume that any observed data Y(t) can then be\nexpressed as the sum of the deterministic and non-\ndeterministic components:\n$Y(t) = D(t) + E(t)$    (1)\nIn the equation, the observed data is Y(t), t represents the\ntime index or any other relevant index from a finite index\nset T. D(t) is the deterministic component and E(t) is the\nnon-deterministic component.\nThe objective of this paper is to understand the relationship\nbetween the deterministic and non-deterministic compo-\nnents of data and how they influence accuracy of a model.\nWe do not aim to quantify model accuracy as most previous\nworks have done that H\u00fcllermeier and Waegeman [2021],\nGawlikowski et al. [2023], St\u00e5hl et al. [2020]. We hypoth-\nesise that non-deterministic components of data can effect\nthe performance of a models in different ways. Any model\ncan easily determine the deterministic component in data,\nbut it is the non-deterministic component that truly effects\na model. By quantifying the non-deterministic component\nof data and using it as a data quality metric, we can better"}, {"title": "4 METHODOLOGY", "content": "To understand the performance and trustworthiness of ma-\nchine learning algorithms, most previous works (e.g. Zhu\nand Wu [2004]) have used synthetic data. The synthetic data\nare generated by adding noise to a real-world or a generated\ndata set. We call this a top-down approach.\nHowever, we propose a bottom-up approach to generate\nthe data set to measure the performance of a model. In\nother words, we use a predetermined value for the noise\nlevel and modify the real-world or generated data so that\nthe noise level is incorporated into the data set. This gives\nmore control over the noise in the data and standardizes the\ndata set and helps measure the effect of deterministic and\nnondeterministic components of a data set more fully.\nTo plot accuracy vs. DDR for several models for a given task,\nwe need to be able to compare accuracy for datasets with\ndifferent DDRs and models. Typically, one can accomplish\nthis comparison by standardizing the datasets so that for\neach dataset the mean is 0 and the variance is 1. In addition,\nwe would like the accuracy vs. DDR plots to be representa-\ntive so that the DDRs of the points are uniformly distributed.\nHowever, standardization may change the DDRs of datasets\nso that the distribution of DDRs is no longer uniform.\nThe noise is added to the features of the data set. The fea-\ntures are the explanatory variables and adding noise to the\nexplanatory or dependent variables affects the independent\nvariable. Since, the objective of any model is to predict the\nindependent variable adding non-deterministic component\nto features would also effect a model's ability to predict the\nindependent variable.\nIn the real world splitting the data into deterministic and\nnon-deterministic components is very complicated and the\nsolution may be unknown. There may be infinite possible"}, {"title": "5 MODEL PERFORMANCE METRIC", "content": "In this paper a new metric, the trustworthiness portfolio\np, was defined. The trustworthiness portfolio measures the\nperformance of a model. As a single-number measure of the\nreliability of a model M on a given noisy data set Y, for a\ngiven model and the deterministic component, trustworthi-\nness portfolio can be obtained from the accuracy-DDR.\nThe trustworthiness portfolio should be a metric that looks\nat the change in performance of a model when the non-\ndeterministic component (or the noise) changes. Ideally,\nperformance should not change when DDR changes. Since\nDDR and accuracy are normalized between 0 and 1, the\nmaximum value of the trust should be 1. Hence, the trust-\nworthiness portfolio is between $0 < DDR < 1 \\DDR$.\nWhen data set has $DDR = 0$ then the data has a high non-\ndeterministic component level and there is no reliable way\nof making predictions without a lot of pre-processing.\nHence, a simple way of defining trustworthiness portfolio\nis:\n$PM,Y = accuracy \u00d7 DDR$    (10)\nThe above definition of metric is for a single point. For a\nspecific model and dataset, we can use the accuracy-DDR\nplot to measure the true performance of a model under\nuncertain conditions. The true performance of a model is\ndefined as follows:\n$\\int PM = \\int accuracy(DDR)d(DDR)$    (11)\nwhere $accuracy(DDR)$ is the function from the accuracy-\nDDR plot. It should be noted that pm is equivalent to the\narea-under-the-curve of the accuracy-DDR plots. When PM\nis close to 1, then model has high performance and can\nperform well under uncertain conditions. This happens when\nthe model accuracy does not change with changing DDR\nwhich is ideally how a model should perform. When pm < 1\nwhen model's accuracy changes with changing DDR and\nthe lower the value, worst is the performance of the model\nunder uncertain conditions."}, {"title": "6 EXPERIMENTAL DESIGN & RESULT", "content": "In this section, we look at the experiments that we performed\nto create the accuracy-DDR plots. The experiments were\ndone using Python and implemented Pytorch Paszke et al.\n[2019] and Scikit-learn Pedregosa et al. [2011]. Pytorch\nwas generally used for data generation and implementing\ndifferent machine learning models. Scikit-learn was used\nto get basic machine learning models, along with other\nplaces used to get widely accessible versions of common\nand uncommon models. Our code can be found at Github\nWe collected scores for ten types of machine learning mod-\nels on multiple appropriate datasets with varying DDRs of\nfeature matrix. The models were not altered in any way\nfrom where we obtained them unless specified in the code,\nthis includes no hyperparameter tuning being performed.\nWe included ten supervised learning model types, which\nconsisted of five regression model types and five binary clas-\nsification model types. The regression model types included\na linear regression model type, Ordinary Least Squares Re-\ngressor (OLSRR); Decision Tree Regressor (DTR); a sup-\nport vector regression model type, Linear Support Vector\nRegressor (LSVR); a nearest neighbors regression model\ntype, K-Nearest Neighbors Regressor (KNNR). The binary\nclassification model types included a linear binary classi-\nfication model type, Binary Logistic Regression Classifier\n(BLRC); Decision Tree Classifier (DTC); a support vec-\ntor binary classification model type, Linear Support Vector\nClassifier (LSVC); a nearest neighbors binary classifica-\ntion type, K-Nearest Neighbors Classifier (KNNC); and a\nneural network binary classification model type, Multilayer\nPerceptron Classifier (MLPC).\nWe measured the results of each model's accuracy based\non it's type. All five regression models' accuracy was mea-\nsured using normalized mean square error (NMSE)-based\naccuracy. The five binary classification models' accuracy\nwere measured using F1-Score."}, {"title": "7 CONCLUSION", "content": "In summary, we proposed a metric called DDR, which\nwe showed to be a valid measure of the non-deterministic\ncomponent in a dataset and the trustworthiness portfolio for\na model that incorporates DDR to measure the performance.\nOur results also in line with the claims from other research\nlike Zhu et al. Zhu and Wu [2004] who showed that the\naccuracy of a decision tree classifier increases as the noise\nlevel of a data set decreases. But we have gone beyond the\nwork in previous research by creating a framework that can"}]}