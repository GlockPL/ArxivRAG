{"title": "Learning the rules of peptide self-assembly through data mining with large language models", "authors": ["Zhenze Yang", "Sarah K. Yorke", "Tuomas P. J. Knowles", "Markus J. Buehler"], "abstract": "Peptides are ubiquitous and important biologically derived molecules, that have been found to self-assemble to form a wide array\nof structures. Extensive research has explored the impacts of both internal chemical composition and external environmental\nstimuli on the self-assembly behaviour of these systems. However, there is yet to be a systematic study that gathers this\nrich literature data and collectively examines these experimental factors to provide a global picture of the fundamental rules\nthat govern protein self-assembly behavior. In this work, we curate a peptide assembly database through a combination of\nmanual processing by human experts and literature mining facilitated by a large language model. As a result, we collect more\nthan 1,000 experimental data entries with information about peptide sequence, experimental conditions and corresponding\nself-assembly phases. Utilizing the collected data, ML models are trained and evaluated, demonstrating excellent accuracy\n(>80%) and efficiency in peptide assembly phase classification. Moreover, we fine-tune our GPT model for peptide literature\nmining with the developed dataset, which exhibits markedly superior performance in extracting information from academic\npublications relative to the pre-trained model. We find that this workflow can substantially improve efficiency when exploring\npotential self-assembling peptide candidates, through guiding experimental work, while also deepening our understanding of\nthe mechanisms governing peptide self-assembly. In doing so, novel structures can be accessed for a range of applications\nincluding sensing, catalysis and biomaterials.", "sections": [{"title": "Introduction", "content": "Self-assembly is a ubiquitous phenomenon in nature that plays a critical role in the formation of hierarchical biomaterials.\nA wide array of building blocks ranging from organic molecules and proteins to nucleic acids and amphiphilic compounds\ncan self-assemble into nano- and micro- scale structures, driven by various molecular interactions1\u20133. Among these building\nblocks, peptides present unique structural and functional characteristics with their simple yet versatile chemical compositions\nand non-covalent, weak intermolecular interactions. In the past few decades, a rich diversity of self-assembled peptide-based\nnanostructures have been reported, including tubes, fibers, ribbons, plates and spheres4\u20139. These assembled peptide serve\nas structured, functional biomaterials, spanning a broad spectrum of applications from drug delivery systems10 and tissue\nengineering11, to catalysis12 and electronics13.\nThe self-assembly behaviour of peptides is mediated by the underlying thermodynamics and kinetics of the systems14.\nPeptides can adopt specific organisations, such as supra-molecular a-helices, \u03b2-sheets, and \u1e9e-hairpins, which are key building\nblocks of specific assembled nanostructures15. As a result, extensive studies have demonstrated that one can use a range\nof factors to manipulate a system into forming specific secondary structures. These include intrinsic parameters, such as\npeptide sequence16 and chemical modifications7, as well as extrinsic factors such as pH17, temperature18, solvent type19\u201321, and\nconcentration22. However, a systematic study collecting this literature data and exploring how these experimental conditions\ncollectively influence the phase diagram of peptide materials is yet to be conducted. Something of this nature would be a\ngroundbreaking tool, helping to streamline experimental investigations through identifying key mediators of self-assembly."}, {"title": "Results", "content": "Overall workflow\nThe overall workflow of this study is depicted in Fig. 1. We first collect scientific publications related to polypeptide self-\nassembly from publishers directly, and from scientific databases such as the PubMed database, based on a previous polypeptide\ndatabase known as SAPdb46. SAPdb is a collection of 1049 entries of experimentally validated short peptides (di-, tri-peptides)\nfrom 301 papers. We screen the entire database based on whether each publication can be adopted into our feature template\nfor ML predictions. In our feature template, we have 9 categorical features and 4 numerical features as shown in Fig. 2a, b.\nAcademic publications that extend experimental control beyond these specified features are not included in the database, due to\ntheir scarcity and limited utility. Following the screening process, we identified a total of 75 publications. All 75 publications\nare cited in Supporting Information. With these selected publications, we focus on extracting experimental details and the\nassembled phases from the main texts, which results in a total of 1012 data entries.\nWith the curated database, we then train ML models to predict the self-assembly phases from peptide sequence and ex-\nperimental parameters. To obtain an optimal performance in the classification, we compare multiple classic ML algorithms\nwith hyperparameter optimization which are discussed more in detail in the following content (see Section ML algorithms\nfor phase prediction). In contrast to the costly and time-consuming processes of peptide synthesis and characterization, the\nML model offers the ability to rapidly classify the peptides with moderate accuracy. However, the manual process of paper\nreading and data collection is human resource-extensive and time-consuming. Therefore, we further leverage pretrained LLM\n(GPT-3.5 turbo) to accelerate the process of literature mining. The LLM is engineered to perform a task known as \"named\nentity extraction\", enabling the model to efficiently extract key information from text documents based on given targeted entity.\nTo adapt the GPT model to be specialized in understanding scientific writing related to peptide self-assembly, the manually\ncurated dataset is split into training and testing sets, with the training set being used to fine-tune the GPT-3.5 turbo model\nand testing set being implemented for performance evaluation. We demonstrate that fine-tuning can significantly enhance the\nperformance of information extraction and requires only a small amount of data for transfer learning.\nWith the fine-tuned LLM assistant, we are able to perform efficient literature mining for future publications or research\nworks that are not among selected publications such as those studying longer peptides. This new data, obtained by LLMs,\ncan be further added into our database and used for boosting the performance of our ML model in phase classification. As\na result, the proposed approach paves the way for an autonomous workflow capable of continuously collecting data from\npapers, augmenting the existing dataset, and refining the classification model. Furthermore, this workflow offers the potential to\nfacilitate the design of experiments and screening of promising peptide candidates."}, {"title": "Features and statistics of dataset", "content": "The statistics of curated polypeptide dataset is shown in Fig. 2. There are 9 categorical features including: (1) \"Peptide Se-\nquence\": which is the amino acid sequence of peptides and is specified for dipeptides (length of 2) or tripeptides (length of 3); (2)\n\"N-terminal Modification\": which describes chemical modifications, such as the protecting groups, at the N-terminal of peptides;\n(3) \"C-terminal Modification\": which involves chemical modifications at the C-terminal of peptides; (4) \"Non-terminal Modifi-\ncation\": referring to chemical modifications of the R-group; (5) \"Category: Peptide/Conjugate/Mixture\": indicating whether\nthe peptide system consists of a single peptide, a conjugate, or a mixture; (6) \"Conjugate Partner\": identifying the conjugated\npeptide within a conjugate system; (7) \"Thermal Process: Heating/Cooling\": indicating the presence of temperature changes,\nsuch as heating or cooling, during the experimental process; (8) \"Linear/Cyclic\": distinguishing between linear and cyclic\nself-assembling peptides; (9) \"Solution\": detailing the solution environment including information about the solvent and solute."}, {"title": "ML algorithms for phase prediction", "content": "With the curated dataset, we are now able to train ML algorithms for phase prediction with different experimental conditions and\npeptide sequences. Categorical features are converted to one-hot encodings based on the number of classes. All input features\nare then concatenated into a 1D vector as input to classic ML algorithms. We compare 4 different classic ML algorithms;\nrandom forest (RF), multilayer perceptron (MLP) classifier, Gaussian process classifier (GPC) and K-nearest neighbor classifier\n(KNC). To optimize the performance of these models, we conduct a grid search of hyperparameters for each of them. More\ndetails of hyperparameter selection can be found in Methods section ML algorithms for phase classification and the grid search\nresults are displayed in Fig. S1. Considering the dataset's imbalance across eight distinct phases (Fig. 2c), metrics including\nprecision, recall, and F\u2081 scores are integrated to provide a comprehensive evaluation of 4 different ML algorithms. Among\ntested ML models, RF exhibits the best performance, achieving the highest score (precision=0.814, recall=0.806 and F\u2081=0.808)\nacross all 3 metrics (Fig. 3a). KNC model ranks second because it exhibits a precision score comparable to that of the RF model\nand its recall and F\u2081 scores are slightly lower. This indicates that KNC's performance is more easily affected by the imbalance\nof the dataset. In contrast to the RF and KNC algorithms, the MLP classifer exhibits much worse accuracy, characterized by not\nonly lower overall scores but also a large discrepancy among different metrics.\nTo further evaluate the performance of our ML models, we utilize an oversampling technique known as Synthetic Mi-\nnority Oversampling Technique (SMOTE)49 to address the imbalance of the dataset. The SMOTE approach generates synthetic\nexamples of the minority class to balance the dataset by interpolating between existing minority instances. When utilizing\nan oversampled dataset, the F\u2081 scores of the MLP classifier and GPC model see a substantial improvement, whereas the RF\nand KNC algorithms maintain performances comparable to those observed with the original dataset (Fig. 3b). Among the 4\nmodels evaluated, the RF model consistently demonstrates the highest accuracy when tested with a synthetic balanced dataset.\nHowever, our current method of randomly splitting the dataset may introduce bias, as both the training and testing sets could\ncontain data from the same publication. This is because a single paper often contributes multiple data entries to the dataset. To\nevaluate the generalization ability of our models, we partition the dataset into training and testing sets based on publications,\nwhich ensures that the data in the testing set originates from publications completely unseen by the training set. As illustrated\nin Figure 3b, the F\u2081 scores of models evaluated on the generalized test set are dramatically lower than in the original scenario.\nHowever, the RF model still exhibits a relatively high F\u2081 score (greater than 0.5), noteworthy considering that a random phase\nguess would only achieve a score of 0.125, given the 8 phase categories in total.\nBased on thorough evaluation of the models, we conclude that the RF model is the optimal choice for phase prediction,\ngiven its consistently superior performance across all tests. Fig. 3c shows the confusion matrix predicted by the RF model,\nwhich compares the true and predicted classifications, visualizing the counts of correct and incorrect predictions across\ndifferent categories. The high values observed along the diagonal of the confusion matrix underscore model's effectiveness\nand consistency in classification across different phases. All other confusion matrices for different ML algorithms tested with\ndifferent situations are listed and compared in Fig. S2.\nAfter identifying an optimal model and assessing its performance, we aim to delve deeper into understanding how vari-\nous input features\u2014from peptide sequences to external stimuli-impact the final output, the self-assembly phase. To acquire\ninterpretability of our model, we employ the SHapley Additive exPlanations (SHAP) technique48 which is a game theoretic\napproach that explains the importance of input features to the output for a ML model. Among all input features, \"N-terminal\nmodification:, \"solution\" and \"concentration\" are the top 3 most influential features for phase classification overall (Fig. 3d).\nAmong the two most common phases (\"liquid solution\" and \"hydrogel\"), \"concentration\" is the most critical feature for the\n\"no-assembly\" phase, whereas \"solution\" stands out as the paramount feature for the \"hydrogel\" phase. This is expected given\nthat for a new phase to be nucleated, a critical concentration must be reached. The correlations uncovered by our model offer\nvaluable insights that can inform experimental designs. For instance, researchers can prioritize the most influential features\n(identified in the SHAP analysis) in their experiments when aiming to achieve a specific phase."}, {"title": "LLM-assisted literature mining", "content": "While the manual extraction of data from literature by human experts offers high accuracy, it is time-consuming and labor-\nintensive. To streamline the information extraction process and enhance the efficiency of data collection, we here implement\nLLMs for automated mining of polypeptide self-assembly literature and further utilize our manually curated database to\nfine-tune and evaluate the performance of LLMs. The overall workflow of LLM-assisted literature mining is shown in Fig. 4a.\nWe first download the PDF files of 75 academic publications from different journal publishers (Fig. S3). The PDF files are then\nconverted to texts using PDFMiner python package50. We then locate experimental sections from the whole text document by\nsearching for section headings such as \u201cMaterial(s)", "Method(s)\" and \\\"Experimental section/detail(s)\". If no section heading is\nfound, all texts are kept for further processing. Afterwards, we gather relevant paragraphs based on the occurrence of key words\nassociated with the information we aim to collect. For example, we collect paragraphs with key words such as \\\"fibers\\\" and\n\\\"hydrogel\\\" to obtain content related to self-assembly phases. Finally, we add the abstract text, which provides a summary of each\nscientific paper, into the processed main text. We preprocess the texts to reduce the volume of text input, thereby meeting the\ntoken (number of words) limits for the training and inference of LLMs, and to augment the efficiency of data mining of literature.\nThe distribution of token numbers for the 75 publications after preprocessing is shown as Fig. 4b. We utilize the Ope-\nnAI API to call the GPT model51 for information extraction from these processed texts. The task is known as \u201cNamed entity\nextraction\\\" (NER) which identifies and classifies key information elements from text into predefined categories (Fig. 4a).\nTo enhance the model's performance on NER for peptide literature mining, we fine-tune the GPT model with our peptide\ndatabase. The peptide database is divided into training (52 papers) and testing (23 papers) sets. Given that most publications\nyield multiple data entries, we incorporate all data entries from the same publication into a single output, allowing the GPT\nmodel to better extract multiple sets of target entities from a single paper. We compare the performances of the original and\nfine-tuned GPT models by evaluating their prediction accuracy on the testing papers from the manually curated dataset.\nFor 9 categorical features, we assess the performance of LLMs as a True-or-False task by comparing features extracted\nby the LLMs with those identified by human experts. The fine-tuned LLM dramatically outperformed the pretrained model\nfor all 9 categorical features with an average accuracy over 80%. In comparison, the original GPT model only achieves an\naverage accuracy of 62.7%. More specifically, fine-tuning significantly enhances the accuracy of predictions for classification\nqueries. For example, the accuracy for identifying the feature \u201ccategory: peptide/conjugate/mixture": "which determines\nwhether the peptide system comprises a single peptide, a conjugate, or a mixture increases from less than 10% to over 90%\nafter fine-tuning. However, fine-tuning does not improve the model's ability to extract information for the feature \u201csolution.\u201d\nThis limitation arises from several factors: (1) \"solution\" often involves multiple chemicals, complicating the capture of\ncomprehensive information; (2) information about the solution is frequently sparse or absent (appear in figures instead) in the\nprocessed texts used as input, making accurate extraction challenging.\nIn terms of the numerical features, we calculate the mean absolute error (MAE) of extracted and ground truth values to\ncompare the accuracy for LLMs with and without fine-tuning. As clearly depicted in Fig. 4d, the fine-tuned model not only\nattains a MAE value but also exhibits a narrower error distribution compared to the pretrained model. This demonstrates\nthat fine-tuning significantly enhances both the accuracy and robustness of the GPT-3.5 turbo model for peptide literature\nmining. With our fine-tuned LLM, we can significantly enhance the efficiency of dataset curation for learning rules of peptide\nself-assembly. Furthermore, this workflow can be adapted to other fields of the physical sciences, as experimental conditions\nare crucial for scientific investigations."}, {"title": "Discussion", "content": "In this work, we manually collect data from academic literature to construct a dataset of peptide self-assembly systems, with\na particular emphasis on peptide sequences and experimental conditions. Utilizing the database, classical ML algorithms,\nsuch as the RF model, are employed to predict the phases of assembled nanostructures based on information regarding both\ninternal chemical composition and external experimental stimuli. The model demonstrates high accuracy in classifying various\nphases and exhibits moderate generalization capabilities. By further interpreting the classification results, the importance of\ndifferent experimental conditions to individual phases can be evaluated. These insights offer valuable guidance for researchers\nin designing experiments aimed at creating specific phases of peptide nanostructures.\nWe further replace the labor-intensive manual data collection process with an LLM assistant. Compared to human ex-\nperts, the LLMs are capable of processing academic texts and extracting target entities in an automate and efficient manner. We\nutilized the giant pre-trained GPT model and demonstrated that by fine-tuning it with only a small set of publications, the LLM\nassistant can achieve impressive accuracy in extracting experimental information, significantly surpassing the performance\nof the original GPT model designed for general human language tasks. This fine-tuned model will facilitate the streamlining\nof the data collection process for future publications. The extracted data can subsequently be integrated into our database,\nfurther refining the ML algorithm trained for phase classification. Despite the notable improvements in accuracy achieved\nthrough fine-tuning our language model, it's important to recognize the existing limitations of our LLM-assisted literature\nmining approach, which present opportunities for further investigation and refinement in future studies. The major limitations\nand potential solutions to them are shown in Fig. S4 and Table S4.\nThe proposed workflow and developed models from this work can help us deepen our understanding of the self-assembly\nof peptide materials. However, it is important to note that the experimental data extracted from literature tends to be biased\ntowards specific peptides (as shown in Fig. 2d, e) or experimental methodologies (as shown in Fig. 2a, b, c). Therefore,\nfuture efforts could be directed towards incorporating data from domains that have been less explored in previous exper-\niments. Multiple methodologies can be employed to achieve this objective. For example, given the costs of conducting\nexperiments, an active learning-based framework could be adapted to identify a minimal number of experiments required to\nextend knowledge beyond the current database. High-throughput screening is another potential way of conducting massive\nexperiments in a systematic and automate manner52. Compared to experiments, computational tools such as coarse-grained\nMD simulations are generally much faster but less accurate in phase prediction. Nevertheless, we can harness the strengths\nof both experimental (high-fidelity but limited in quantity) and computational (low-fidelity but abundant) techniques through\nthe application of multi-fidelity learning53. This approach allows the integration of both experimental and computational data\nto train ML models with both high accuracy and data efficiency. Apart from physics-based experimentation and modeling,\ngenerative modeling also serves as a useful method for data generation. Model architectures from variational autoencoder,\ngenerative adversarial networks to diffusion models are widely applied to augment the data pool of materials and proteins54,55.\nThese approaches can be easily adapted to produce new experimental data of peptide self-assembly by learning from the\nexisting data we have collected. Further provided with certain conditions like desired phase or constrained experimental param-\neters, a conditional generative model is a promising approach to assisting experimental design as we discussed in earlier sections.\nFinally, while this study primarily concentrates on extracting information about the self-assembly phase of peptide ma-\nterials, the overarching workflow can be applied more broadly. For instance, as a structured functional material, tuning the\nself-assembly process is essential for accessing diverse applications. Leveraging our fine-tuned LLM for literature mining\nand the ML classifier for phase prediction, it becomes straightforward to gather property information about peptides from\nthe literature and to construct a model for predicting their functions. Given the similarity between these tasks, there's no\nnecessity to train these models from scratch; transfer learning suffices for precise data extraction and function predictions.\nFurther with the generative models, we can not only design experimental parameters but also the peptide sequences to realize\nspecific functions. These approaches will largely facilitate designing self-assembling peptide materials without conducting\ncostly experiments."}, {"title": "Methods", "content": "Manual processing of peptide database\nWe first select the data entries from SAPdb database based on the self-assembly phase. Our database includes the top 7 most\nfrequently occurring phases, 8 inclusive of 'no assembly'-hydrogel, fiber, tube, sphere, particle, ribbon and vesicle-since\nother phases have too few data entries, likely making them difficult to be accurately predicted by ML algorithms. Including\nthe non-assembly case, there are a total of 8 phases. We also excluded publications that involve rare methods and techniques\nthat can not be incorporated within the 13 features illustrated in Fig. 2. These publications include following cases: (1)\nExperiments of co-assembly of multiple peptides such as Ref.56; (2) Purely computational study such as Ref.57; (3) Studies on\npeptides that can not split into a sequence of amino acids such as Ref.58; (4) Experimental control beyond solution environment,\nPH, temperature such as in-situ ultrasound approach59, oxidation60, electromagnetic field61 ; (5) Experiments in a solution\nenvironment with more than one solvents, Ref.62; (6) Experiments without information of solvent/peptide concentration, Ref.63;\n(7) Experiments with rare (less than 5 entries in SAPdb) solvents, additives or chemical modifications such as Ref.64."}]}