{"title": "Unifying Invariant and Variant Features for Graph Out-of-Distribution via Probability of Necessity and Sufficiency", "authors": ["Xuexin Chen", "Ruichu Cai", "Kaitao Zheng", "Zhifan Jiang", "Zhengting Huang", "Zhifeng Hao", "Zijian Li"], "abstract": "Graph Out-of-Distribution (OOD), requiring that models trained on biased data generalize to the unseen test data, has considerable real-world applications. One of the most mainstream methods is to extract the invariant subgraph by aligning the original and augmented data with the help of environment augmentation. However, these solutions might lead to the loss or redundancy of semantic subgraphs and result in suboptimal generalization. To address this challenge, we propose exploiting Probability of Necessity and Sufficiency (PNS) to extract sufficient and necessary invariant substructures. Beyond that, we further leverage the domain variant subgraphs related to the labels to boost the generalization performance in an ensemble manner. Specifically, we first consider the data generation process for graph data. Under mild conditions, we show that the sufficient and necessary invariant subgraph can be extracted by minimizing an upper bound, built on the theoretical advance of the probability of necessity and sufficiency. To further bridge the theory and algorithm, we devise the model called Sufficiency and Necessity Inspired Graph Learning (SNIGL), which ensembles an invariant subgraph classifier on top of latent sufficient and necessary invariant subgraphs, and a domain variant subgraph classifier specific to the test domain for generalization enhancement. Experimental results demonstrate that our SNIGL model outperforms the state-of-the-art techniques on six public benchmarks, highlighting its effectiveness in real-world scenarios.", "sections": [{"title": "1. Introduction", "content": "Graph representation learning with Graph Neural Networks (GNNs) has gained remarkable success in complicated problems such as intelligent transportation and the inverse design for polymers [49, 7]. Despite their considerable success, GNNs generally assume that the testing and training graph data are independently sampled from the identical distribution (IID). However, the validity of this assumption is often difficult to guarantee in real-world scenarios.\nTo solve the Out Of Distribution (OOD) challenge of graph data, one of"}, {"title": "2. Preliminaries", "content": ""}, {"title": "2.1. Problem Setup", "content": "In this paper, we focus on domain generalization in graph classification where GNNs are trained on data from multiple training domains with the goal of performing well on data from unseen test domains. Formally, we consider datasets $D = \\{D^e\\}_{e\\in E_{train}}$ collected from $m$ different training domains or environments $E_{train} = \\{1,...,m\\}$, with each dataset $D^e = \\{(G_i, y_i)^e\\}_{i=1}^{n^e}$ containing graph data pairs $(G_i, y_i^e)$ sampled independently from an identical distribution $P(G,Y|E = e)$, where G, E, Y denotes the variables of input graph, environment (i.e., domain indicator) and ground-truth label. $G_i = (V_i, L_i, X_i)$ denotes the i-th graph instance where $V_i$ is a set of nodes, $L_i \\subseteq V_i \\times V_i$ is a set of edges and $X_i \\in \\mathbb{R}^{|V_i| \\times d_{V_i}}$ is the node feature matrix. Each row of $X_i$ denote the $d_{V_i}$-dimensional feature vector for node $v \\in V_i$. Let G and y be the graph and label space. The goal of domain generalization on graphs is to learn an invariant GNN $g_c \\circ f_c$ that performs well on a larger set of possible domains $E_{all} \\supset E_{train}$, where $f_c : G \\rightarrow \\mathbb{R}^d$ is the encoder of invariant GNN that is used to extract domain invariant subgraph or representation $C = f_c(G)$ from each graph G and $g_y : \\mathbb{R}^d \\rightarrow Y$ is the downstream classifier to predict the label $Y = g_c(C)$.\nGraph generation process. Generating predictions that can generalize out of distribution requires understanding the actual mechanisms of the task of interest. Following previous works [61, 10], here we present a generation process of graph data behind the graph classification task, by inspecting the causalities among five variables: input graph G, ground-truth label Y, domain invariant subgraph C, domain variant subgraph S and environment E, where noises are omitted for simplicity. Figure 2 illustrates the causal diagram, where each link denotes a causal relationship between two variables. $C\\rightarrow G \\leftarrow S$ indicates that the input graph G consists of two disjoint components: the invariant subgraph C and the variant or unstable subgraph S, according to whether they are affected by environment E, such as the orange and green components of $G_1$ in Figure X. Moreover, $C \\rightarrow Y \\rightarrow S$ indicates C is partially informative about Y, i.e., $(S, E) \\bot Y \\vert C$ [10]. $C \\rightarrow Y$ indicates the labeling process, which assigns labels Y for the corresponding G merely based on C. Taking the house classification example in Figure X again, C of input graph $G_1$ can be the $G_9$, $G_{10}$ or $G_{11}$ (which one is better will be discussed in Section 2.2), which perfectly explains why the graph is"}, {"title": "2.2. Probability of Necessity and Sufficiency", "content": "Current OOD generalization methods on graph data mainly focus on learning only domain invariant features for label prediction. However, domain-invariant features can be divided into three categories, each of which has different effects on graph label prediction.\n1) Sufficient but unnecessary causes. Knowing cause A leads to effect B, but when observing effect B, it is hard to confirm A is the actual cause. For example, the domain invariant feature $G_9$ can predict the label \"house\", but a graph with the label \u201chouse\" label might not contain this feature, such as $G_2$. 2) Necessary but insufficient causes. Knowing effect B we confirm the cause is A, but cause A might not lead to effect B. For example, if the input graph does not contain the invariant feature $G_{11}$, then we can confirm that the label of this graph is not \u201chouse\u201d. However, graph $G_4$ with the \u201cgrid\u201d label also has the same invariant feature $G_{11}$ as a \"house\u201d. Thus invariant feature $G_{11}$ is not a stable feature to predict houses. 3) Necessary and sufficient causes. Knowing effect B we confirm the cause is A, and we also know that A leads to B. In the \u201chouse\" and \"grid\" classification tasks, invariant feature $G_{10}$ could be a necessary and sufficient cause. It is because $G_{10}$ allows humans to distinguish a \u201chouse\" from a \"grid\", and when we know there is a \u201chouse\u201d, $G_{10}$ must exist. In conclusion, the accuracy of predictions based on domain-invariant features with sufficient necessary information will be higher than those based on other types of invariant features.\nIn order to learn sufficient and necessary domain invariant features of the input graph, we resort to the concept of Probability of Necessity and Sufficiency (PNS) [47], which is defined as follows.\nDefinition 1. (Probability of necessity and sufficiency (PNS) [47]) Let the specific values of domain invariant variable C and label Y be $c$ and $y$. The probability that $C = c$ is the necessary and sufficiency cause of $Y = y$ is\n$PNS(C=c, Y = y) := \\underbrace{P(Y_{do(C=c)}=y \\vert C\\neq c, Y\\neq y)}_{sufficiency} P(C \\neq c,Y \\neq y) + \\underbrace{P(Y_{do(C\\neq c)}\\neq y \\vert C=c,Y=y)}_{necessity} P(C=c,Y=y).$ (1)"}, {"title": "3. Theory: Unifying Invariant and Variant Features for Graph OOD via PNS", "content": "In this section, motivated by the fact that not necessary or not sufficient invariant features may be harmful to domain generalization on the graph, we present our main theoretical result which shows how to unify invariant and variant subgraphs for graph OOD via PNS. We begin by describing how to extract necessary and sufficient invariant information by identifying the subspace of the variable C. Since not every graph contains this invariant subgraph, we describe how to alleviate this problem by reconstructing $P(Y|C, S)$ from $P(Y|C)$ and $P(C, S)$ which involves exploiting domain variant features to enhance domain generalization."}, {"title": "3.1. Necessary and Sufficient Invariant Subspace Learning", "content": "In this section, supposing that we have already identified the domain invariant subgraph C, we analyze the problem of extracting the necessary and sufficient invariant features about C from G. We first reduce it to an optimization problem for PNS, i.e., identify the subspace of C with the largest PNS with respect to C and Y given a graph G. However, PNS is usually intractable because counterfactual data are not available. We show this issue can be solved exactly by deriving the lower bound of PNS for optimization.\nWe now formalize the two key assumptions underlying our approach. These assumptions below will help us derive the lower bound of PNS based on conditional probability.\nDefinition 2. (Exogeneity [48]) Variable C is exogenous relative to variable Y if C and Y have no common ancestor in the graph generation process.\nDefinition 3. (Consistency [48, 23]) If variable C is assigned the value c, then the observed outcome Y is equivalent to its outcome $Y_{do(C=c)}$ of intervention; i.e., if C = c, then $Y = Y_{do(C=c)}$."}, {"title": "3.1.1. PNS Risk", "content": "Based on the PNS lower bound (Eq. 2), this section presents the PNS risk which shows how to estimate the subspace of variable C. The objective"}, {"title": "3.2. Ensemble Learning with Variant Features", "content": "In this section, to mitigate the negative impact of not sufficient or not necessary invariant subgraphs on prediction, our key observation is that if the domain variant subgraph S is related to the label Y, then we can improve prediction accuracy by ensembling predictions based on unstable or domain variant subgraphs specific to the test domain e. Based on this observation, we describe a boosted joint GNN in the test domain e as a combination of an invariant GNN $g_c \\circ f_c$ and an unstable GNN $g_{s,e} \\circ f_s$ training on the domain variant subgraphs on test domain e. The unstable GNN $g_{s,e} \\circ f_s$ is composed of a domain variant subgraph extractor $f_s : G \\rightarrow (0,1)^{n \\times n}$ across domains, and a domain-specific classifier $g_{s,e}$ on test domain e, where n is"}, {"title": "4. Algorithm: Sufficiency and Necessity Inspired Graph Learning", "content": "In this section, we will leverage the above theoretical results and propose a data-driven method called Sufficiency and Necessity Inspired Graph Learning (SNIGL) to employ necessary and sufficient invariant subgraphs and domain variant subgraphs specific to the test domain e for domain generalization. On the training domains, we describe learning an invariant GNN that extracts necessary and sufficient invariant features and an unstable GNN that extracts domain variant features. On the test domain, we then describe how to combine these features to enhance the performance of domain generalization."}, {"title": "4.1. Training domains: Learning necessary and sufficient invariant and variant subgraphs.", "content": "Our goal in the training domains is to learn three modules $f_c$, $g_c$ and $f_s$ parameterized by $\\theta_c$, $\\phi_c$ and $\\theta_s$, respectively. The first two modules are the estimated necessary and sufficient invariant subgraphs extractor $f_c$ and its downstream classifier $g_c$, which form the invariant GNN $g_c \\circ f_c$. The third module is the variant subgraphs extractor $f_s$ across domains that will be employed to adapt a classifier $g_{s,e}$ specific to the test domain e, which form the unstable GNN $g_{s,e} \\circ f_s$ in the test domain e.\nTo achieve these learning goals, let $R_{INV}$ denote the risk of learning invariant GNNs proposed by existing methods, $R_{joint}$ denotes the risk (e.g., cross entropy) of the joint predictions $COMBINE(g_{c} \\circ f_{c}, g_{s,e'} \\circ f_{s})$ (Eq. 6) of the invariant GNN $g_{c} \\circ f_{c}$ and unstable GNN $g_{s,e'} \\circ f_{s}$ specific to the training domain $e'$, and $R_{C \\bot I}$ denote the penalty encouraging conditional independence $C \\bot S|Y$. Technologically, we estimate modules $f_c$ and $g_c$ in two steps. First, we encourage the estimated invariant GNN $g_{c} \\circ f_{c}$ to learn an invariant feature space through the invariant risk. Second, use our"}, {"title": "4.1.1. Implementation of Necessary and Sufficient Invariant Subgraphs Extractor $\\mathbf{f_{c}}$ and Domain Variant Subgraphs Extractor $\\mathbf{f_{s}}$", "content": "We employ the following implementation of $f_c$ and $f_s$ to generate an invariant subgraph c and variant subgraph s, which can be formalized as follows. We first assume that variables C and S follow multivariate Bernoulli distributions with the parameters $B^C\\in (0,1)^{n\\times n}$ and $B^S\\in (0, 1)^{n\\times n}$, i.e., C ~ Bernoulli($B^C$) and S ~ Bernoulli($B^S$), where n is the number of nodes in graph G. Technologically, we estimate the parameters $B^C$ and $B^S$ of the Bernoulli distribution in three steps. First, we use two layer graph neural network (GNN) to generate the node embeddings $Z^c$ and $Z^s$. Second, we calculate the parameter matrices $B^C$ and $B^S$, which denote the probability of the existence of each edge of C and S. Third, we sample C and S from the estimated distributions. In summary, the aforementioned three steps can"}, {"title": "4.1.2. Implementation of Invariant Classifier $\\mathbf{g_{\\phi}}$ and Variant Classifier $\\mathbf{g_{\\phi_{s,e}}}$", "content": "To estimate the predicted class probabilities, we use the READOUT (e.g., mean) [67] function aggregates node embeddings to obtain the entire graph\u2019s representation, and employ different three layer Multilayer Perceptron (MLP) with SOFTMAX function activation to estimate the probabilities for each different environment, as follows:\n$P(Y = y\\vert C = c) = g_{\\phi_c}(c)_y := SOFTMAX(MLP(READOUT(Z_c)))_y, \\\\ P(Y = y\\vert S = s, E = e) = g_{\\phi_{s,e}}(s)_y := SOFTMAX(MLP_e(READOUT(Z_s)))_y,$ (11)\nwhere $g()_y$ denotes the $y$-th entry of the prediction and $MLP_e$ represents an MLP specific to environment e."}, {"title": "4.1.3. Implementation of $\\mathbf{P_{\\theta_c}(C = c|G)}$ and $\\mathbf{P(Y = y|E = e)}$", "content": "To estimate the component $P_{\\theta_c}(C = c|G)$ of PNS risk $R_{NS}$ (Eq. 3), our main idea is to draw samples from $P_{\\theta_c}(C|G)$ and estimate the probability $P_{\\theta_c}(C = c|G)$ by counting how many samples are isomorphic to c. Since graph isomorphism is an NP-hard problem, we simplify this problem by calculating the similarity between their graph representations. First, based on our implementation of $P_{\\theta_c}(C|G)$ (Section 4.1.1), we draw k subgraphs $c_1,..., c_k$ from $P_c(C|G)$. Second, referring to Eq. 10-11, we feed these subgraphs $c_1, ..., c_k$, and c into the GNN($\\cdot; \\theta_c$) and use the READOUT function to obtain their graph representations. Third, compute the similarity (we adopt the inner product) between c and $c_1, ..., c_k$ in terms of their representation and average these similarities. The three steps can be summarized as follows:\n$P_{\\theta_c}(C = c|G) \\approx \\frac{1}{k}\\sum_{i=1}^{k}\\sigma(\\widetilde{Z}^c(c_i)^T\\widetilde{Z}^c(c)), \\; c_1,..., c_k \\overset{i.i.d}{\\sim} P_c(C\\vert G), \\\\ \\widetilde{Z}^c(c_k) = READOUT(GNN(G^{c_k};\\theta_c)), \\widetilde{Z}^c(c) = READOUT(GNN(G^c;\\theta_c)),$ (12)"}, {"title": "4.2. Test-domain Adaptation Without Labels.", "content": "Given the trained invariant GNN $g_c \\circ f_c$ and the domain varying feature extractor $f_s$, our goal in the test domain is to adapt a classifier $g_{s,e}$ specific to test domain e learned on top of trained $f_s$, so that we can make optimal use of the domain variant features extracted from $f_s$. By Theorem 2, this goal can be achieved through the following three steps. First, given the unlabelled test domain data $\\{G_i\\}_{i=1}^n$, compute soft pseudo-labels $\\{\\widehat{Y}_i\\}_{i=1}^n$ with\n$\\widehat{y} = \\arg \\max_y g_c(f_c(G_i)).$ (14)\nSecond, letting $l : Y \\times Y \\rightarrow \\mathbb{R}$ be a loss function (e.g., cross entropy), fit the biased classifier $\\widehat{g}_{s,e} (S)$ specific to test domain e on pseudo-labelled data $\\{(S_i = f_{s,e}(G_i), \\widehat{y}_i)\\}$ with\n$\\min_{\\widehat{\\phi}_{s,e}} \\frac{1}{n} \\sum_{S_i, \\widehat{Y}_i} l(\\widehat{g}_{s,e}(S_i), \\widehat{y}_i).$ (15)\nThird, through optimizing Eq. 15, we are given the trained biased classifier $\\widehat{g}_{s,e}(S)$ specific to the test domain e. By Theorem 2, we calibrate $\\widehat{g}_{s,e}(S)$ as follows:\n$g_{\\phi_{s,e}}(s_i) = \\frac{\\widehat{g}_{\\phi_{s,e}} (S_i) + \\epsilon_0 - 1}{\\epsilon_0 + \\epsilon_1 - 1},$ (16)\n$\\epsilon_1 = \\frac{\\sum_{G_i} g_{\\phi_c} (f_c(G_i))^2}{\\sum_{G_i} g_{\\phi_c} (f_c(G_i))}, \\epsilon_0 = \\sum_{G_i} \\frac{\\sum_{G_i} \\frac{1- g_{\\phi_c} (f_c(G_i))^2}{1 - g_{\\phi_c} (f_c(G_i))}.$ (17)\nFinally, by the first line of Eq. 5, we combine the prediction between the trained invariant GNN $g_c \\circ f_c$ and the trained calibrated unstable GNN $g_{s,e} \\circ f_s$ specific to the test domain e."}, {"title": "5. Experiments", "content": "In this section, we evaluate the effectiveness of our proposed SNIGL model on both synthetic and real-world datasets by answering the following questions.\n\u2022 Q1: Whether the proposed SNIGL can outperform existing state-of-the-art methods in terms of model generalization.\n\u2022 Q2: Can the proposed PNS risk learning necessary and sufficient invariant latent subgraphs well?\n\u2022 Q3: Do ensemble strategies that exploit domain-varying subgraphs benefit model performance?\n\u2022 Q4: What are the learning patterns and insights from SNIGL training? In particular, how do invariant or variant subgraphs help improve generalization?"}, {"title": "5.1. Experimental Setup", "content": ""}, {"title": "5.1.1. Dataset", "content": "To evaluate the effectiveness of our proposed SNIGL, we utilize six public benchmarks under different distribution shifts for graph classification tasks, including two synthetic datasets Spurious-Motif-Mixed [65] and GOOD-Motif [19], as well as four real-world datasets GOOD-HIV [19], OGBG-Molsider, OGBG-Molclintox and OGBG-Molbace [24]. Table 1 summarizes the statistics of seven datasets."}, {"title": "5.1.2. Baselines", "content": "We compare the proposed SNIGL method with three categories of methods, namely the state-of-the-art OOD methods from the Euclidean regime, and from the graph regime, as well as the conventional GNN-based methods. The OOD methods from the graph regime include:\n\u2022 GroupDRO [50] involves using regularization with Distributionally Robust Optimization (DRO) to enhance worst-group generalization in over-"}, {"title": "5.1.3. Implementation Details", "content": "The configurations of our SNIGL as well as baselines are as follows. For a fair comparison, all methods utilize GIN as the underlying GNN backbone and use the max readout function to derive the embedding for the graph. We use ADAM optimizer in all experiments. We use ADAM optimizer in all experiments. All experiments are implemented by Pytorch on a single NVIDIA RTX A5000 24GB GPU. For our SNIGL, we set the dimensions of node embedding $d^c$ and $d^s$ in Eq. 10 are both set to 300. We further set the regularization coefficient $A$ in Eq. 9 to 0.001. We used the Adam optimizer and the learning rate in the optimization algorithm in the training phase and the test phase was set as 0.001 and 0.0001, respectively. The maximum number of training epochs was set as 200. For the baselines, we tuned their settings empirically.\nFor performance evaluation, we closely follow the literature of GOOD [19] and OGBG [24]. Specifically, similar to the experimental setup in GOOD and OGBG, we report the ROC-AUC for all datasets, except for SP-Motif-Mixed where we use accuracy following CIGA [11]. Further, we repeat the evaluation four times, select models based on the validation performances,"}, {"title": "5.2. Comparison to baselines", "content": "In this section, we answer Question Q1: how effective is our approach compared to existing methods? As shown in Table 2, we can find that our SNIGL method outperforms the other baselines with a large margin in different biases on the standard SPMotif-Mixed dataset, and in different split methods (i.e., structure, scaffold, size) on GOOD-Motif and GOOD-HIV datasets. In particular, we can obtain the following conclusions. 1) GALA achieves the second best performance on SP-Motif-Mixed under bias b = 0.5 and b = 0.9, while Mixup and GSAT achieve the second best performance on GOOD-Motif under motif-splitting and size-splitting, respectively, as well as Coral and DANN achieve the second best performance on GOOD-HIV under scaffold-splitting and size-splitting, respectively. Our proposed SNIGL is capable of achieving further improvements against GALA by 11.2% and 11.1% on SP-Motif-Mixed under bias b = 0.5 and b = 0.9, against Mixup and GSAT by 11.2% and 4.1% on GOOD-Motif, as well as against Coral and DANN by 3.0% and 1.7% on GOOD-HIV, indirectly reflecting that our method can extract the invariant subgraphs with the property of necessity and sufficiency. 2) We also find that the performance drops with increasing"}, {"title": "5.3. Ablation Study", "content": "As Section 4 states, the PNS risk and the ensemble strategy of combining domain-variant and domain-invariant features are key components in our"}, {"title": "5.4. Visualization", "content": "To answer question Q4, i.e., what patterns are actually learned by our SNIGL and how such patterns improve the generalization of SNIGL, we visualize the domain invariant and domain variant subgraphs learned by SNIGL on the OGBG-HIV dataset as shown in Figure 4. The visualization results allow us to draw the following conclusions. 1) The domain invariant sub-structures are sparse basic structures, showing that our method is capable of identifying necessary and sufficient latent substructures. 2) Our SNIGL model is capable of generating reasonable molecular substructures comprising basic functional groups. For example, SNIGL can extract substructures such as \"-NO2\u201d in the second line's domain invariant subgraph, which is composed of two purple nodes and one green node. This may offer an efficient avenue for uncovering the latent value of molecules. 3) We find that some atoms appear neither in the domain-invariant subgraph nor in the domain-variant subgraph. For example, in the example on the third line, atom -Cl"}, {"title": "6. Related Work", "content": ""}, {"title": "6.1. Graph Out-of-Distrubtion.", "content": "In this subsection, we provide an introduction to domain generalization of graph classification [14, 70, 20, 39, 11, 15]. Existing works on out-of-distribution (OOD) [51] mainly focus on the fields of computer vision [76, 75] and natural language processing [6], but the OOD challenge on graph-structured data receives less attention. Considering that the existing GNNs lack out-of-distribution generalization [37, 77, 42, 54, 56, 34, 38], Li et al. [34] proposed OOD-GNN to tackle the graph OOD (OOD) challenge by addressing the statistical dependence between relevant and irrelevant graph representations. Recognizing that spurious correlations often undermine the generalization of graph neural networks (GNN), Fan et al. propose the StableGNN [14], which extracts causal representation for GNNs with the help of stable learning. Aiming to mitigate the selection bias behind graph-structured data, Wu et al. further proposes the DIR model [65] to mine the invariant causal rationales via causal intervention. These methods essentially employ causal effect estimation to make invariant and spurious subgraphs independent. And the augmentation-based model is another type of the important method. Liu et al. [40] employ augmentation to improve the robustness and decompose the observed graph into the environment part and the rationale part. Recently, Chen et al. [11, 9] investigate the usefulness of augmented environment information from a theoretical perspective. And Li et. al [38] further consider a concrete scenario of graph OOD, i.e., molecular property prediction from the perspective of latent variables identification [36]. Although the aforementioned methods mitigate the distribution shift of graph data to some extent, they can not extract the invariant subgraphs with Necessity and Sufficiency [69]. Moreover, as [13] discussed, the domain variant subgraphs also play a critical role when the data with noisy labels [41, 64, 2]. In this paper, we propose the SNIGL method, which unifies the extraction of the invariant latent subgraph with necessity and sufficiency and the exploitation of variant subgraphs via an ensemble manner."}, {"title": "6.2. Probability of Necessity and Sufficiency", "content": "As the probability of causation, the Probability of Necessity and Sufficiency (PNS) can be used to measure the \u201cif and only if\u201d of the relationship between two events. Additionally, the Probability of Necessity (PN) and Probability of Sufficiency (PS) are used to evaluate the \u201csufficiency cause\u201d and \u201cnecessity cause\u201d, respectively. Pearl [48] and Tian and Pearl [58] formulated precise meanings for the probabilities of causation using structural causal models. The issue of the identifiability of PNS initially attracted widespread attention [17, 21, 46, 4, 58, 30, 32, 44, 12, 33, 18, 74, 31]. Kuroki and Cai [28] and Tian and Pearl [58] demonstrated how to bound these quantities from data obtained in experimental and observational studies to solve this problem. These bounds lie within the range in which the probability of causation must lie, however, it has been pointed out that these bounds are too wide to assess the probability of causation. To overcome this difficulty, Pearl demonstrated that identifying the probabilities of causation requires specific functional relationships between the causes and their outcomes [48]. Recently, incorporating PNS into various application scenarios has also attracted much attention and currently has many applications [57, 16, 62, 5, 44, 3, 52]. For example, in ML explainability, CF2 [57], LEWIS [16], LENS [62], NSEG [5] and FANS [8] use sufficiency or necessity to measure the contribution of input feature subsets to the model's predictions. In the causal effect estimation problem [44, 3, 52], it can be used to learn individual responses from population data [44]. In the out-of-distribution generalization problem, CaSN employs PNS to extract domain-invariant information [69]. Although CaSN is effective in extracting sufficient and necessary invariant representations, CaSN ignores the fact that the data may not have sufficient and necessary invariant features. Furthermore, CaSN requires the assumption that the classifier is linear in order to learn sufficient and necessary invariant features, which is unrealistic for GNN-based predictors."}, {"title": "7. Conclusion", "content": "This paper presents a unified framework called Sufficiency and Necessity Inspired Graph Learning (SNIGL) for graph out-of-distribution learning, leveraging the probability of necessity and sufficiency (PNS) for invariant subgraph learning, and combining domain-variant subgraphs with learned invariant subgraphs for ensemble reasoning. Initially, we outline a conventional"}, {"title": "Appendix A. Proof of Theorem 1", "content": "Proof. To find the lower bound of PNS, by Bonferroni's inequality, for any three events A, B, we have the bounds\n$P(A, B) \\geq max(0, P(A) + P(B) \u2013 1)$ (A.1)\nWe substitute A for $Y_{do(C=c)} = y$ and B for $Y_{do(C\\neq c)} \\neq y$. Then, we have\n$P(Y_{do(C=c)} = y, Y_{do(C\\neq c)} \\neq y) \\\\ \\geq max(0, P(Y_{do(C=c)} = y) + P(Y_{do(C\\neq c)} \\neq y) - 1)$ (A.2)\nBased on the assumption of our causal model, the condition that there is no confounding between variables C and Y is met. Thus, the intervention probability $P(Y_{do(C=c)} = y)$ and $P(Y_{do(C\\neq c)} \\neq y)$ can be identified by conditional probabilities $P(Y_{do(C=c)} = y)$ and $P(Y_{do(C\\neq c)} \\neq y)$, respectively. Then, Eq. A.2 can be rewritten as\n$P(Y_{do(C=c)} = y, Y_{do(C\\neq c)} \\neq y) \\\\ \\geq max(0, P(Y = y|C = c) + P(Y \\neq y|C \\neq c) - 1) \\\\ = max(0, P(Y = y|C = c) \u2013 P(Y = y|C \\neq c))$ (A.3)\nWe now prove that $P(Y_{do(C=c)} = y, Y_{do(C\\neq c)} \\neq y)$ is equivalent to PNS. Specifically, according to the consistency assumption of counterfactual reasoning, i.e., $(C = c) \\Rightarrow (Y_{do(C=c)} = y) = (Y = y), (C \\neq c) \\Rightarrow (Y_{do(C\\neq c)} \\neq y) = (Y \\neq y)$, we know that\n$(Y_{do(C=c)} = y) \\land (Y_{do(C\\neq c)} \\neq y) \\\\ =((Y_{do(C=c)} = y) \\land (Y_{do(C\\neq c)} \\neq y)) \\land ((C = c) \\lor (C \\neq c)) \\\\ =((Y_{do(C=c)} = y) \\land (Y_{do(C\\neq c)} \\neq y) \\land (C = c)) \\lor  \\\\  ((Y_{do(C=c)} = y) \\land (Y_{do(C\\neq c)} \\neq y) \\lor (C \\neq c)) \\\\ =((Y = y) \\land (Y_{do(C\\neq c)} \\neq y) \\land (C = c)) \\lor  \\\\  ((Y_{do(C=c)} = y) \\land (Y \\neq y) \\lor (C \\neq c))$ (A.4)\nBy Eq. A.4, we have\n$P(Y_{do(C=c)} = y, Y_{do(C\\neq c)} \\neq y) \\\\ =P(Y_{do(C=c)} = y,C \\neq c,Y \\neq y) + P(Y_{do(C\\neq c)} \\neq y, C = c, Y = y) \\\\ =P(Y_{do(C=c)} = y|C \\neq c,Y \\neq y)P(C \\neq c,Y \\neq y) + \\\\ P(Y_{do(C\\neq c)} \\neq y|C = c, Y = y)P(C = c, Y = y),$ (A.5)"}, {"title": "Appendix B. Proof of Theorem 2", "content": "Before proving Theorem 2, we prove Lemma 1, which allows us to safely divide by the quantity\nLemma 1.```json\n\nProof. Given C, Y and \u0176 have the same conditional distribution, i.e.,\n$P(\\widehat{Y}|C) = P(Y|C)$ (\u0392.4)\nNext we prove P(Y = 1) = P(\u0176 = 1).\n$P(\\widehat{Y}) = \\sum_C P(\\widehat{Y}, C) = \\sum_C P(C)P(\\widehat{Y}|C) \\\\ = E_c[P(\\widehat{Y}|C)] = E_c[P(Y|C)] = P(Y)$ (\u0392.5)\nBased on the above equalities, we first derive the calculation formulas for P(\u0176 = 1|Y = 1) and P(Y = 0|Y = 0).\n$P(\\widehat{Y} = 1|Y = 1) = \\frac{P(\\widehat{Y} = 1, Y = 1)}{P(Y = 1)} \\\\ = \\frac{P(\\widehat{Y} = 1, Y = 1)}{P(\\widehat{Y} = 1)} (according to Eq. B.5) \\\\ = \\frac{\\sum_C P(\\widehat{Y} = 1, Y = 1, C)}{\\sum_C P(\\widehat{Y} = 1, C)} \\\\ = \\frac{E_c[P(\\widehat{Y} = 1, Y = 1|C)]}{E_c[P(\\widehat{Y} = 1|C)]} \\\\ = \\frac{E_c[P(\\widehat{Y} = 1|C) \\cdot P(Y = 1|C)]}{E_c[P(\\widehat{Y} = 1|C)]} \\\\ = \\frac{E_c[P(Y = 1|C)^2]}{E_c[P(Y = 1|C)]} (according to Eq. B.4)$ (\u0392.6)\nSimilarly, we can obtain\n$P(\\widehat{Y} = 0|Y = 0) = \\frac{E_c[P(Y = 0|C)^2]}{E_c[P(Y = 0|C)]}$ (B.7)\nNext we will discuss the connection between $P(\\widehat{Y} = 1|S, E)$ and P(Y = 1|S, E) by expanding $P(\\widehat{Y} = 1|S, E)$.\n$P(\\widehat{Y} = 1|S, E) = \\frac{P(\\widehat{Y} = 1, S, E)}{P(S, E)} \\\\ = \\frac{P(\\widehat{Y} = 1, S, E, Y = 1)}{P(S, E)} + \\frac{P(\\widehat{Y} = 1, S, E, Y = 0)}{P(S, E)}$ (Law of Total Probability) \\\\ =P(Y = 1|S, E) \\cdot P(\\widehat{Y} = 1|S, E, Y = 1) + P(Y = 0|S, E) \\cdot P(\\widehat{Y} = 1|S, E, Y = 0) \\\\ =P(Y = 1|S, E) \\cdot P(\\widehat{Y} = 1|Y = 1) + P(Y = 0|S, E) \\cdot P(\\widehat{Y} = 1|Y = 0)(C \\bot \\{S, E\\}|Y, and C \\rightarrow \\widehat{Y}) \\\\ =P(Y = 1|S, E)(P(\\widehat{Y} = 1|Y = 1) + P(\\widehat{Y} = 0|Y = 0) - 1) + 1 - P(\\widehat{Y} = 0|Y = 0)$ (\u0392.8)\nCombining the conclusion of Lemma 1, we can get $P(\\widehat{Y} = 1|Y = 1) + P(\\widehat{Y} = 0|Y = 0) \\neq 1$, so we have\n$P(Y = 1|S, E) = \\frac{P(\\widehat{Y} = 1|S, E) - 1 + P(\\widehat{Y} = 0|Y = 0)}{P(\\widehat{Y} = 1|Y = 1) + P(\\widehat{Y} = 0|Y = 0) - 1}$ (B.9)"}, {"title": "Appendix C. Multiclass Case", "content": "In the main text of the paper, we employed a simplified notation to present our test domain adaptation method in the context of binary labels Y. However, in numerous instances, including our experiments in Section 5, the label Y can have more than two classes. Consequently, in this section, we illustrate the means of extending our method to the multiclass setting.\n$P(\\widehat{Y} = y|S, E) = \\sum_{Y' \\in \\mathbb{V}} P(Y = y|S, E, Y = y')P(Y = y'|S, E) \\\\ = \\sum_{Y' \\in \\mathbb{V}} P(Y = y|Y = y')P(Y = y'|S, E) (C \\bot \\{S, E\\}|Y, and \u0176 is determined by the C)$ (C.1)\nLet M\u2208 [0, 1]|\u00d7| = Y), ...,| denote a matrix with\n$M_{ij} = P(\\widehat{Y} = i|Y = j)$. (C.2)\nLet h\u2208 [0, 1]| denote a vector with\n$h_i = P(Y = i|S, E)$. (C.3)\nIn matrix notation, Eq. C.1 can be seen as a\n$P(\\widehat{Y}|S, E) = Mh\u2208 [0, 1]^2$ (C.4)\nWhen M is non-singular, we can calibrate $P(\\widehat{Y} = y|S, E)$ using the following equality.\n$P(Y|S, E) = M^{-1} \\cdot P(\\widehat{Y}|S, E)$ (C.5)\n$P(\\widehat{Y} = y|Y = y') = \\frac{P(Y = y, \\widehat{Y} = y')}{P(\\widehat{Y} = y')} \\\\ = \\frac{E_c[P(\\widehat{Y} = y, \\widehat{Y} = y'|C)]}{E_c[P(\\widehat{Y} = y'|C)]} \\\\ = \\frac{E_c[P(\\widehat{Y} = y'|C)P(\\widehat{Y} = y|C,Y)]}{E_c[P(\\widehat{Y} = y'|C)]} (\\widehat{Y} is determined by the C)$ (C.6)\nSimilarly, we start by calculating the Odds of P(Y = y|Xs, , E).\n$\\frac{P(Y = y|C, S, E)}{P(Y \\neq y|C, S, E)} = \\frac{P(Y = y)}{ \\sum_{y'\\neq y} P(Y = y'|C, S, E)} \\\\ = \\frac{P(Y = y, C, S, E)}{ \\sum_{y'\\neq y} P(Y = y', C, S, E)} \\\\ = \\frac{P(Y = y)P(C, S, E|Y = y)}{ \\sum_{y'\\neq y} P(Y = y')P(C, S, E|Y = y')} \\\\ = \\frac{P(Y = y)P(\\widehat{Y}|Y = y)P(\\widehat{Y}|S, E)}{ \\sum_{y'\\neq y} P(Y = y')P(\\widehat{Y}|Y = y')P(\\widehat{Y}|S, E)} (C \\bot \\{S, E\\}|Y)$ (C.7)"}]}