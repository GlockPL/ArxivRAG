{"title": "From Argumentation to Deliberation: Perspectivized Stance Vectors for Fine-grained (Dis)agreement Analysis", "authors": ["Moritz Plenz", "Philipp Heinisch", "Janosch Gehring", "Philipp Cimiano", "Anette Frank"], "abstract": "Debating over conflicting issues is a necessary first step towards resolving conflicts. However, intrinsic perspectives of an arguer are difficult to overcome by persuasive argumentation skills. Proceeding from a debate to a deliberative process, where we can identify actionable options for resolving a conflict requires a deeper analysis of arguments and the perspectives they are grounded in as it is only from there that one can derive mutually agreeable resolution steps. In this work we develop a framework for a deliberative analysis of arguments in a computational argumentation setup. We conduct a fine-grained analysis of perspectivized stances expressed in the arguments of different arguers or stakeholders on a given issue, aiming not only to identify their opposing views, but also shared perspectives arising from their attitudes, values or needs. We formalize this analysis in Perspectivized Stance Vectors that characterize the individual perspectivized stances of all arguers on a given issue. We construct these vectors by determining issue- and argument-specific concepts, and predict an arguer's stance relative to each of them. The vectors allow us to measure a modulated (dis)agreement between arguers, structured by perspectives, which allows us to identify actionable points for conflict resolution, as a first step towards deliberation.", "sections": [{"title": "1 Introduction", "content": "Diverse stakeholders exchange their opinions and arguments on social media, news, debating portals and other private or public discussion formats. Often, they are in strong opposition, leaving little room for a consensus that could resolve the conflict. While argument mining technology has concentrated on analysing and generating arguments that can support arguers in winning a debate (Habernal and Gurevych, 2016; Wang et al., 2017; Wachsmuth et al., 2018), so far there has been limited interest in identifying points in opposing positions that bear a chance for consensual resolution of the conflict. Identifying points that offer a chance for resolution requires fine-grained analysis of the stances expressed by different stakeholders, to understand on which specific aspects they disagree and on which they actually might agree, and which of these are crucial for their mutual (dis)agreement.\nThis requires an analysis of the perspectives an arguer has on an issue \u2013 which may be grounded in their values, attitudes or specific goals and needs (Falk et al., 2024; Kiesel et al., 2022; Alshomary et al., 2022). We aim to compare arguments within a given issue based on their expressed perspectives, which means that we require a fixed set of perspectives for each issue. Issue-specific 'frames' are commonly used to group and analyze arguments from a given issue (Opitz et al., 2021; Heinisch et al., 2022), which makes them promising for modeling perspectives. Following Plenz et al. (2024), we use a data-driven approach to extract issue-specific frames from the commonsense knowledge graph ConceptNet (Speer et al., 2017), meaning that concepts (i.e., nodes from ConceptNet) form our basis for perspectives. To support a deliberative analysis of arguments, we develop tools to i) determine relevant concepts that characterize differ-"}, {"title": "2 Related Work", "content": "Overall stance. PSVs are a fine-grained representation of stances. Classifying the overall stance of arguments towards a topic is a core task in argument mining (Bar-Haim et al., 2017; Kobbe et al., 2020; Luo et al., 2020). However, assigning an argument a global stance tag (e.g., PRO, CON and NEUTRAL or UNRELATED) lacks expressivity: it divides sets of arguments into only a couple of groups, neglecting crucial nuances. The task of same-side classification (predict whether two arguments share their overall stance) in Hou and Jochim (2017); K\u00f6rner et al. (2021) does not address this problem either. Further, it does not unveil the underlying reasons why arguments share a stance.\nTo counter this issue, prior work incorporated background knowledge, by including reasoning paths to explain, e.g., for which reasons a premise supports or attacks a conclusion (Paul et al., 2020), or to generate an explanation graph for a premise-conclusion pair that explains the stance of the argument (Saha et al., 2021; Saadat-Yazdi et al., 2023; Plenz et al., 2023b). We build on this work by including concepts from a commonsense resource to define the PSV signature concepts.\nPerspectives in argumentation. Our work is related to Barrow et al. (2021), who rely on graphs to represent arguments and their relationships as a basis to detect viewpoints. They proposed so-called syntopical graphs that model pairwise textual relationships between claims to enable a better reconstruction of latent viewpoints in a collection, thereby making points of (dis)agreement within the collection explicit. In a similar way, PSVs enable the detection of (dis)agreement. But in addition,"}, {"title": "3 Perspectivized Stance Vectors", "content": "We introduce Perspectivized Stance Vectors (PSVs), a new representation to record the perspectives expressed in or underlying an argument, with the aim to detect and measure agreement and conflicts between pairs or a set of arguments on a given issue. To construct a PSV, we need to define its signature and corresponding stance values. Given a debate topic $d_t$, the signature is determined by a list of concepts ${c_i}_{i=1}^n$ relevant for topic $d_t$.\nGiven an argument $a$ on topic $d_t$, we abstract a PSV $v_a$ from argument $a$ by determining a stance $s_i$ for each concept $c_i$, where $s_i$ represents the stance the arguer expresses with argument $a$ towards the concept $c_i$. We choose stance values $s_i \\in [-1,0,1]$ to represent a stance of against, neutral, or in favor, respectively. We formalize PSVs as either n-dimensional vectors of stance values $s_i$, or $(n \\times 3)$ dimensional matrices where each entry represents the probability of concept $c_i$ to belong to one of the three stance value classes:\n$S \\epsilon \\{-1,0,1\\}$ where $\\quad S=\\{-1,0,1\\}$\\\n$P \\epsilon p^{n \\times 3}$ where $\\quad P=[0, 1].$\nIf the exact representation is not relevant, we use $\\tilde{v}$ to denote a general PSV. When comparing pairs of PSVs $(\\tilde{v}_{a_1}, \\tilde{v}_{a_2})$ for arguments $(a_1, a_2)$, aligned vs. opposing dimensions indicate agreement or disagreement, respectively. Dimensions with neutral stance labels in $(\\tilde{v}_{a_1}, \\tilde{v}_{a_2})$ indicate orthogonality, as the arguers neither agree nor disagree.\nWe next describe our methods to construct PSVs, including their signatures and stance values in \u00a73.1. We then describe how to aggregate or compare PSVs to obtain predictions for agreement, orthogonality and disagreement between arguments and which specific perspectives cause them (\u00a73.2)."}, {"title": "3.1 PSV Construction", "content": "Below we show how to construct PSVs given a topic $d_t$ and a set of arguments $A_{d_t}$ on that topic."}, {"title": "3.1.1 Signature concepts for Debate Topic", "content": "As a signature for PSVs we are interested in general \u2013 and potentially conflicting \u2013 concepts that capture the perspectives of diverse arguers towards a topic. Following Plenz et al. (2023b, 2024), we align arguments to the commonsense knowledge graph ConceptNet (Speer et al., 2017). First, we split arguments into individual sentences, then we select for each sentence the most similar concepts (i.e.,"}, {"title": "3.1.2 Perspectivized stances for Arguments", "content": "We develop different models to compute the stance value $s_i$ for a given argument and signature concept $c_i$. Here we provide an overview of the methods, please refer to \u00a7A.2 for more in-depth descriptions.\nBaseline. Our Baseline assigns each argument $a$ and concept $c_i$ the stance value 0 if the concept is not in the concept graph, i.e., $s_i = 0$ for $c_i \\notin C_a$."}, {"title": "3.2 Computing Acceptability Scores", "content": "Standard stance classification allows us to predict whether two arguments agree or disagree on a debate topic. Using PSVs, we can now detect and predict agreement on a more fine-grained level. E.g., there is a partial agreement between the arguers in Fig. 1: Both parties are against trophy hunting while they are in favor of sustainability. Such partial agreements are instrumental to find compromises between arguers who disagree on a topic.\nPerspectivized Acceptability Scores. Our hypothesis is that i) arguers agree or disagree on the concepts $c_i$, depending on whether their arguments express the same perspectivized stances $s_i$ towards $c_i$ within the debated topic. Yet, ii) if at least one of two arguments has a neutral perspective towards concept $c_i$, then the arguers neither agree nor dis-"}, {"title": "4 PSV-Experiments", "content": "Given a set of arguments on an issue, our approach first finds signature concepts, then computes perspectivized stances which yields PSVs and finally aggregates PSVs to obtain acceptability scores. In this section, we empirically assess the quality of each of these steps by comparing to human annotations. Where possible, we augment our manual evaluation with automatic evaluations that do not require human labels. Section 5 presents a comple-mentary case study."}, {"title": "4.1 Experimental setup", "content": "Data. We conduct our analyses and case study using PAKT (Plenz et al., 2024), a debate resource that presents issues as binary questions, and answers to these questions as arguments for either stance. The arguments, on avg. 7 sentences long, discuss an author's points without elaborating on the entire issue. This makes PAKT well-suited for our purposes. Fig. 1 shows two shortened example arguments from PAKT. For our case study we further enrich PAKT with stakeholder groups (for details see \u00a7A.4).\nAnnotation. To assess the quality of our methods, three annotators labeled data from 5 different evenly represented topics: 300 topic-level annotations to evaluate PSV signatures, 500 argument-level annotations to evaluate PSV values and 1,500 annotations for pairs of arguments to evaluate our methods to predict acceptability scores on debate topics. We collect annotations from all three an-notators for the topic Should animal hunting be banned? to estimate inter-annotator agreement. For most subtasks we achieve moderate to high agreement as shown by Tab. 5, despite the high subjectivity in argumentative tasks. \u00a7B.1 presents more details on the annotation procedure."}, {"title": "4.2 Analyzing PSV Construction Methods", "content": "First, we analyze how best to construct PSVs. This includes i) the selection of perspectives for the PSV signature and ii) how to predict PSV values.\nPSV signature. Signature perspectives should be relevant to the topic. Also, if a perspective is too general (or too specific), it will be evoked by almost all (or no) arguments. Neither is useful for comparing arguments \u2013 hence, we check whether our signature concepts' granularity is in-between."}, {"title": "4.3 Evaluating Aggregation Methods", "content": "Unless stated otherwise, the reported results use 100 dimensional PSVs w/o filtering and GPT40 (0-shot) for perspectivized stance prediction."}, {"title": "4.3.1 Global acceptability: Partial agreement among argument pairs of opposite stance", "content": "In our manual annotation, argument pairs of opposite stances had been annotated for global acceptability, i.e., being in i) partial agreement, ii) agreement, iii) disagreement or for being iv) orthogonal to each other. Since only two argument pairs were annotated with \u201cagreement\u201d (which is expected, since all annotated argument pairs are of opposite stance), we group \u201cagreement\u201d and \u201cpartial agreement\" to form one agreement class."}, {"title": "4.3.2 Perspectivized acceptability: Identifying aspects of (dis)agreement", "content": "In \u00a74.3.1 we predicted global agreement between arguments, classifying argument pairs as a whole. However, using PSVs, we can also identify which perspectives an argument pair agrees or disagrees on. Again, we compare to our human annotation.\nAblation without PSVs. A valid concern regarding our approach is that our method reduces arguments to static vectors, which might oversimplify the nuances of deliberation. Further, it is of interest to what extent (dis)agreement scores could be predicted, in context, by a strong LLM. Thus, we also experimented with directly prompting GPT4o to predict the acceptability of two arguments on a specific perspective. This allows the model to di-"}, {"title": "4.3.3 Evaluation with unannotated data", "content": "So far we evaluated our methods on our manually annotated data, which is naturally limited in size. To consolidate our analyses, we aim to verify our methods on larger amounts of unannotated data.\nSame stance. To this end we perform same-side classification: predicting whether two arguments from the same topic share the same stance. We expect that arguments that share the same stance have higher agreement and lower disagreement scores, on average. Orthogonality is likely mostly independent of the stances from the argument pairs."}, {"title": "5 Case Study", "content": "For our case study we construct PSVs with a signature of 100 perspectives and GPT40 (zero-shot) to predict PSV stance values. As aggregation method we use $P_o$. We discuss our findings for the issue \"Should animal hunting be banned?\u201d. \u00a7C shows results for all 5 topics from our annotation.\nWe first look at global acceptability scores between different stakeholder groups, as shown in Figs. 4 and 11. We observe that related stakeholder groups have higher agreement scores among each other, for example animal rights activists and environmentalists. Between these two and opposing stakeholder groups, such as hunters, the disagreement scores are highest. Orthogonality scores are highest between the stakeholder groups government officials, hunters and local communities. Indeed, government officials and local communities are vague and potentially diverse stakeholder groups for the given issue, which could explain why more arguments are orthogonal to each other. Fig. 5 and Tab. 9 show the top-3 and top-5 perspectives per acceptability score (agreement, orthogonal and disagreement). Across all arguments,"}, {"title": "6 Conclusions", "content": "We present Perspectivized Stance Vectors (PSVs) \u2013 a novel approach to represent fine-grained perspectives expressed in arguments on a debated topic. PSVs effectively identify and explain mutual (dis)agreement between arguments and potential stakeholder groups, offering deep interpretability by revealing issue-specific perspectives driving such (dis)agreements. Identifying (dis)agreement perspectives can reveal the underlying reasons for conflicting viewpoints, and how they can potentially be resolved. Thus, we believe that our fine-grained analysis of perspectives using PSVs provides a valuable contribution to the growing field of deliberative decision making."}, {"title": "Limitations", "content": "We evaluate our approach on PAKT (Plenz et al., 2024), which is limited to English arguments from a predominantly US-context. As our PSV construction partially relies on LMs, it is to be expected that the quality of individual PSVs would be lower for data from a different background. However, our aggregation method is language- and culture agnostic and thus should be robust.\nWhere possible we assess the quality of our approach automatically using data which is already available in large amounts (cf. \u00a74.3.3). However, for fine-grained stance values and acceptability scores we had to rely on our manually annotated data. The annotated data covers 5 topics with 10 arguments each, which may seem like a rather small resource. However, collecting this data was a considerable annotation effort since we required annotations for argument pairs at the level of distinct perspectives. As our experiments are supported with a large-scale case study, we believe that our findings are reliable and trustworthy.\nFinally, predicting aspects of a debated issue which a group of arguments / authors agrees or disagrees on is a challenging task. Reducing this task to our PSV framework might cause oversimplifications. Nonetheless, we study these structured representations of arguments for two good reasons. First, they are highly interpretable \u2013 which we believe to be important for deliberation tasks, to enhance (i) the trust of users and (ii) control for moderators. Second, large parts of our method have to be unsupervised due to a lack of training data. This makes training of end-to-end models infeasible. That being said, a more flexible end-to-end system might be able to obtain better performance in future work, for example, by creating larger amounts of partially annotated data, using our methods."}, {"title": "A Method", "content": null}, {"title": "A.1 Signature", "content": "Concept selection The commonsense knowledge graphs are taken from the published data of Plenz et al. (2024). Lemmatization was performed with the en_core_web_trf model from Spacy. Future work could experiment with supervised concept selection, e.g., by finetuning models (Plenz and Frank, 2024) designed for knowledge graphs such as ConceptNet.\nHypernym filtering. We identify hypernyms using the NLTK implementation of WordNet. To allow for greater coverage we check for hypernyms within the lemmatized set of concepts. For each concept we only consider the first synset, and do not remove concepts which do not have a synset in WordNet.\nChatGPT-based relevance filtering. We use ChatGPT-3.5-0125 to assign each concept with a score to reflect its relevance for a given issue, using the following prompt:\nWe plan to compare arguments depending on which concepts they evoke. Therefore, we created a catalog of concepts for each issue. For the following concept, decide whether it is relevant for the given issue:\n1: yes\n2: no\nExample Annotation for issue 'gun control':\narm themselves: 1\ncontrol: 1\ncriminals: 1\ndangerous: 1\nlaws regulate who: 1\nown guns: 1\npolice: 1\npolitics: 1\nshooting guns: 1\nwrong: 1\nIssue: {debate topic}\nConcept: {concept}\nThe prompt is taken from our annotation guidelines. Depending on ChatGPT's output, we assign a binary label (relevant / irrelevant) to each concept, for each issue. The resulting labels are used as a filter to remove unrelated concepts.\nTo the best of our knowledge we are the first to use ChatGPT to assess the relevance of concepts for a given debate topic. Our human annotation indeed verifies that filtering with ChatGPT can boost precision for relevance (Table 2). In a more general scope, ChatGPT was successfully used for many argument classification tasks such as quality (Rocha et al., 2023; Plenz et al., 2023a) and stance (Zhao et al., 2024; Zhang et al., 2024, 2023; Plenz et al., 2023a) classification, which motivates our approach."}, {"title": "A.2 Stance values", "content": "ROBERTa. We compose a synthetic dataset using the stance dataset of Sobhani et al. (2016); Mohammad et al. (2017) and the dataset on human-values detection by Mirzakhmedova et al. (2024). In the stance dataset, which is based on annotated tweets, we select those tweets that address the annotated target, by being against, in favor, or none of those (neutral). To increase the target diversity, we map each of the six targets to a hand-crafted set of synonyms and antonyms\u2074. To adapt the genre (from short tweets to more comprehensive arguments), we concatenate up to four tweets toward the same target to new instances. We follow the same procedure with the human-values detection dataset on arguments, where we treat an annotated encouragement of a human value as in favor of a set of"}, {"title": "A.3 Aggregation Methods for Acceptability Scores", "content": "We first discuss the stance value-based aggregation methods $S, S_0$ and $S_D$.\nWe use the notation from Tab. 1, where $s\\epsilon \\{-1,0,1\\}$ is the stance value of argument $j$ towards concept $i$. Kronecker delta $\\delta(x, y)$ is 1 if $x = y$ and 0 else.\nStance Value $S$. For agreement $(S^+(s^1_i, s^2_i) = \\delta(s^1_i, s^2_i))$ we simply consider whether the arguments have the same stance value towards concept $c_i$ - if yes, the agreement is 1 and otherwise 0. For disagreement $(S^-(s^1_i, s^2_i) = 1 - \\delta(s^1_i, s^2_i))$ we instead check whether the stance values are different - different values means the disagreement is 1, and otherwise it is 0.\nStance Value (Considering Neutral) $S_0$. For this adaptation we consider the special role of neutral stance values: If both arguers are neutral towards a concept $c_i$, $c_i$ is not a meaningful indicator of agreement. Hence, we only record a perspectivised agreement if both stance values are in favor or against the concept \u2013 but not if both are neutral:\n$S_0^+(s^1_i, s^2_i) = \\delta(s^1_i, s^2_i) (1 - \\delta(s^1_i, 0)).$\nSimilarly, we do not record disagreement if at least one of the arguers is neutral to-wards a perspective $c_i$. Hence, we only record disagreement if one stance value is in favor, while the other is against: $S_0^-(s^1_i, s^2_i) = (1 - \\delta(s^1_i, s^2_i)) (1 - \\delta(s^1_i, 0)) (1 - \\delta(s^2_i, 0)).$\nFor Orthogonality it is enough if at least one arguer is neutral towards the given perspective $c_i$. Hence, the orthogonality score is 1 if at least one arguer is neutral, and otherwise 0: $S_0^\\bot = min (\\Sigma^2_{j=1}\\delta(s^j_i,0),1)$\nStance Value (Difference) $S_D$. For agreement the previous approach might have the limitation that disagreement and orthogonal concepts both contribute 0 when computing a global agreement score by averaging over all concepts. It could be more expressive to have disagreement con-cepts reduce the overall agreement, instead of treating them the same as orthogonal concepts. Hence, we designed $S_D^+(s^1_i, s^2_i) = S^+(s^1_i, s^2_i) - S_0^\\bot (s^1_i, s^2_i)$ to be +1, 0 and \u22121 for agreement, orthogonal and disagreement concepts, respectively. Analogously, we constructed $S_D^-(s^1_i, s^2_i) = S_0^+(s^1_i, s^2_i) - S^+(s^1_i, s^2_i)$"}, {"title": "A.4 Stakeholder Annotation", "content": "Debate portals are commonly lacking information about the authors of arguments, given privacy concerns. To associate arguments with stakeholder information, we enrich our dataset by creating automatic predictions of stakeholder group information using ChatGPT, at issue and argument level.. To this end, we apply ChatGPT-3.5-0125 for two subtasks: First, we let ChatGPT predict potential stakeholder groups at issue-level, by prompting ChatGPT to return a set of relevant stakeholder groups for a given topic:\nA stakeholder is a group of people who are affected by a topic. For example, the topic \"Should young children have access to the internet?\" has the stakeholders \"Children\" and \"Parents\". Return a list of the most important stakeholders for the topic \"{debate topic}\". Return a simple list without explanations. Limit yourself to the few most important ones.\nWe then use this set of stakeholder groups proposed by the model as input to a second call, to assign stakeholder types at argument-level. We ask ChatGPT to select, from the given set of possible stakeholders, those types of stakeholders that could could plausibly utter a given argument from the relevant topic, using the following prompt:\nHere is an argument from someone: '{argument}'. Which of these stakeholders are most likely to utter this argument: {stakeholder set}? Return a list of stakeholders without additional information. Multiple may apply.\nWe extract the stakeholder groups the model predicts to extend each argument in our dataset. This typically results in 1\u20133 stakeholder labels per argument."}, {"title": "A.5 Ablation without PSV: Pairwise GPT40 prompting", "content": "We use gpt-40-2024-11-20, which is the same model used to predict the perspectivized stances (c.f. \u00a73.1.2). The prompt is\nArguments of opposite stance can have agreements even though they don't agree on the issue at a binary level. Similarly, arguments with the same stance can disagree. We are interested in identifying and specifying such (dis)agreements. We will present you with two independently written arguments of opposite stance and a list of concepts.\nFor each concept, annotate whether it is part of the agreement or disagreement:\n1: agreement, i.e., the authors could likely find agreement regarding this concept.\n2: neutral\n3: disagreement, i.e., it is not likely that the authors could agree regarding this concept.\nArgument 1: {argument_1}\nArgument 2: {argument_1}\nConcepts: {python_list_of_concepts}\nReturn your output as a list of integers, where each integer corresponds to the concept at the same index in the list of concepts. Do not include any additional information in your output."}, {"title": "B Experiments", "content": null}, {"title": "B.1 Annotation", "content": "Table 5 shows the number of annotations and inter-annotator agreement (IAA) scores for different subtasks. IAA is measured using Krippendorff's \u03b1 (Krippendorff, 2019).\nWe annotate data from 5 distinct topics:\ni) Should animal hunting be banned?\nii) Do you support the death penalty?\niii) Should students get paid for good grades?\niv) Should illegal immigrants be deported?\nv) Should kids have to wear school uniforms?\nThe first topic was annotated by all 3 annotators, to assess IAA. The remaining topics were annotated by only one annotator, allowing us to collect more annotated data. All annotators are experts in computational linguistics and argumentation in particular.\nFor each topic we annotate 30 signature concepts for i) their relevance with respect to the topic and ii) their granularity. These 30 concepts are the top-15 concepts per stance without any filtering. For each topic, we consider 10 arguments \u2013 5 from each stance. For each of these arguments, we annotate a topic-specific set of 10 concepts (top-5 concepts per stance, with hypernym filtering) for the PSV stance (one of the values for, against, neutral), yielding 500 annotations in total.\nTo obtain annotations for agreement between arguments, we annotate all arguments pairs of opposite stance within a topic, i.e., 25 argument-pairs per topic, on whether there is full or partial agreement, disagreement or whether they are orthogonal to each other. Further, for each of these argument-pairs, we annotate the same 10 concepts for whether the arguments (or rather the authors of the arguments) would agree, disagree or are neutral in relation to that concept. The annotated data as well as detailed annotation guidelines will be published upon acceptance."}, {"title": "B.2 Confusion matrices for PSV stance value prediction", "content": "Figure 6 shows the confusion matrix for GPT40 (zero shot)."}, {"title": "B.3 Impact of PSV length on Acceptability scores", "content": "Figure 8 shows the impact of the number of perspectives (i.e., the dimension or length of a PSV) on global agreement, orthogonality and disagreement prediction. Figure 7 shows corresponding ROC curves for orthogonality."}, {"title": "B.4 Same stance prediction", "content": "Figure 9 shows the (dis)agreement distributions for argument pairs of same and different stances."}, {"title": "C Case Study", "content": "This section collects plots and tables for the case study. Figure 10 presents acceptability scores between different stakeholders. Figure 11 shows argument pairs depending on whether the respective stakeholders are the same or different. Table 9 and Figure 12 show the perspectives with highest acceptability scores depending on the topic and"}, {"title": "D Usage of AI assistants", "content": "We use GitHub Copilot (https://github.com/features/copilot) for speeding up programming, and ChatGPT (https://chat.openai.com) to aid with reformulations. The content of this work is our own, and not largely inspired by AI assistants."}]}