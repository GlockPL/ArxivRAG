{"title": "Generative AI Policies under the Microscope: How CS Conferences Are Navigating the New Frontier in Scholarly Writing", "authors": ["MAHJABIN NAHAR", "SIAN LEE", "BECKY GUILLEN", "DONGWON LEE"], "abstract": "Since the rise of ChatGPT, generative AI (Gen-AI) technologies have gained widespread popularity, impacting academic research, professional tasks, and everyday communication [5, 10]. While Gen-AI offers significant benefits in content generation and task automation [9], it can be also misused and abused in nefarious applications [7], with more significant risks toward long-tail populations and regions [6]. Professionals in fields like journalism and law still remain cautious due to concerns over hallucinations and ethical issues but scholars in Computer Science (CS), the field where Gen-AI originated, appear to be cautiously but actively exploring its use. For instance, [3] reports the increased use of large language models (LLMs) in the CS scholarly articles (up to 17.5%), compared to Mathmatics articles (up to 6.3%), and [2] reports that between 6.5% and 16.9% of peer reviews at ICLR 2024, NeurIPS 2023, CoRL 2023, and EMNLP 2023 may have been significantly altered by LLMs beyond minor revisions.\nConsidering the merits and demerits of Gen-AI, therefore, it is crucial to establish usage guidelines for academic research that balance its potential benefits and limitations. Previous research examined Gen-AI policies for academic usage in psychology, management, and neuroscience [5], but there is still a lack of clear understanding of how CS is adapting to this paradigm shift. Hence, in this article, we provide a summarized overview of the \u201cscholarly writing\u201d policy landscape of major CS conferences over the most recent two years (2024 and 2025 if available; otherwise 2023 and 2024) and offer our recommendations. Conferences studied in this analysis were selected based on csrankings\u00b9 to include leading conferences in each CS subfield. Furthermore, we analyzed the Gen-AI policies of major computing societies: ACM, IEEE, and AAAI.\nOur analysis shows that many CS conferences have not established Gen-AI policies and those that have, vary in leniency, disclosure, and sanctions. Policies for authors are more prevalent compared to ones for reviewers, with few conferences providing reviewer-specific guidelines. Some also address code writing and documentation. These policies are evolving, as demonstrated by conferences such as ICML 2023, which initially prohibited LLM-generated text but later clarified its allowance for editing author-written content, reflecting ongoing refinement. However, by and large, adoption remains inconsistent across conferences, creating uncertainty in their application.", "sections": [{"title": "LANDSCAPE OF GENERATIVE AI POLICIES IN CS CONFERENCES", "content": "Since the rise of ChatGPT, generative AI (Gen-AI) technologies have gained widespread popularity, impacting academic research, professional tasks, and everyday communication [5, 10]. While Gen-AI offers significant benefits in content generation and task automation [9], it can be also misused and abused in nefarious applications [7], with more significant risks toward long-tail populations and regions [6]. Professionals in fields like journalism and law still remain cautious due to concerns over hallucinations and ethical issues but scholars in Computer Science (CS), the field where Gen-AI originated, appear to be cautiously but actively exploring its use. For instance, [3] reports the increased use of large language models (LLMs) in the CS scholarly articles (up to 17.5%), compared to Mathmatics articles (up to 6.3%), and [2] reports that between 6.5% and 16.9% of peer reviews at ICLR 2024, NeurIPS 2023, CoRL 2023, and EMNLP 2023 may have been significantly altered by LLMs beyond minor revisions.\nConsidering the merits and demerits of Gen-AI, therefore, it is crucial to establish usage guidelines for academic research that balance its potential benefits and limitations. Previous research examined Gen-AI policies for academic usage in psychology, management, and neuroscience [5], but there is still a lack of clear understanding of how CS is adapting to this paradigm shift. Hence, in this article, we provide a summarized overview of the \u201cscholarly writing\u201d policy landscape of major CS conferences over the most recent two years (2024 and 2025 if available; otherwise 2023 and 2024) and offer our recommendations. Conferences studied in this analysis were selected based on csrankings\u00b9 to include leading conferences in each CS subfield. Furthermore, we analyzed the Gen-AI policies of major computing societies: ACM, IEEE, and AAAI.\nOur analysis shows that many CS conferences have not established Gen-AI policies and those that have, vary in leniency, disclosure, and sanctions. Policies for authors are more prevalent compared to ones for reviewers, with few conferences providing reviewer-specific guidelines. Some also address code writing and documentation. These policies are evolving, as demonstrated by conferences such as ICML 2023, which initially prohibited LLM-generated text but later clarified its allowance for editing author-written content, reflecting ongoing refinement. However, by and large, adoption remains inconsistent across conferences, creating uncertainty in their application."}, {"title": "AREA-LEVEL TRENDS", "content": "We compared the trend of Gen-AI policy adoption across different CS areas, following the classification from csrankings: AI, Interdisciplinary, Systems, and Theory. We then compared the presence of Gen-AI policies in each area for both years and, for conferences with such policies, examined how they adopted them in terms of leniency.\nFigures 1a and 1b illustrate the presence of Gen-AI policies for authors and reviewers in CS conferences, respectively. For AI, 30.8% of conferences had Gen-AI policies for authors in Year 1, which increased to 76.9% in Year 2, indicating that conferences in Al field are the most active in adopting Gen-AI policies for authors. Next, conferences in the Interdisciplinary area showed 20.0% in Year 1 and 46.7% in Year 2, making them the second most proactive in introducing Gen-AI policies for authors. While these two areas are leading in Gen-AI policy adoption for authors, the Systems area lagged slightly behind the overall trend in Year 1 (10.3%) but saw a 17.3% increase in Year 2 (27.6%), implying that the area is gradually aligning with the overall trend. A similar pattern was observed for reviewer policies, with AI (Year 1: 15.4%, Year 2: 23.1%) and Interdisciplinary (Year 1: 6.7%, Year 2: 26.7%) leading Gen-AI policy adoption, while the Systems area (Year 1: 0.0%, Year 2: 3.4%) is gradually converging with the broader trend. In contrast, no conferences in the Theory area had Gen-AI policies for authors or reviewers in both years. This may be due to the conservative nature of the area or lack of active Gen-AI usage in writing theory articles."}, {"title": "TEMPORAL TRENDS", "content": "We also examined the Gen-AI policies for conferences for two consecutive years of 2024 and 2025, and when unavailable, 2023 and 2024. Overall, conferences are moving toward introducing new Gen-AI policies. In Year 1, out of 64 conferences, only 10 (15.6%) had Gen-AI policies, either for authors or reviewers. This number increased to 26 (40.6%) in Year 2. Specifically, for author policies (see Figure 1a), only 10 (15.6%) conferences had Gen-AI policies in Year 1, but this increased to 25 (39.1%) in Year 2, showing a 23.4 percentage point increase. In contrast, for reviewer policies (see Figure 1b), only 3 (4.7%) conferences had Gen-AI policies in Year 1, and this rose to 8 (12.5%) in Year 2. These findings suggest that while many conferences are increasingly adopting and publicly sharing Gen-AI policies for authors, they are slower in providing clear guidelines for reviewers. Conferences may be unaware of reviewers' needs or could be implementing Gen-AI policies for"}, {"title": "SOCIETY VS. CONFERENCE-LEVEL TRENDS", "content": "We reviewed the Gen-AI policies of ACM, IEEE, and AAAI, as many CS conferences are affiliated with these societies. While conference-specific policies differ in disclosure requirements and flexibility, society-level policies generally permit Gen-AI use by authors with proper disclosures. ACM and AAAI also permit reviewers to enhance their reviews using Gen-AI, as long as the submissions remain unexposed to these systems. In contrast, IEEE has no policies for conference reviewers, though it provides guidelines for journal reviewers. None of these policies mention sanctions for authors or reviewers.\nAs Table 1 summarizes, some conferences do not have conference-specific Gen-AI policies for authors and instead simply refer to the society-level policies-e.g., WWW, SIGCSE, VIS, SIGMOD, SIGCOMM, IMC, while others have established their own Gen-AI policies for authors instead of referring to society-level policies, including CVPR (IEEE), UIST (ACM), and VR (IEEE). Especially, 10 out of 13 conferences in the AI area have their own conference-specific Gen-AI policies while 7 out of 8 Systems conferences with policies simply refer to society-level policies. Still, many conferences appear unaware of society-level Gen-AI policies, as their websites do not mention these society-level policies. This includes ACM-affiliated conferences like SIGIR, ASPLOS, SIGGRAPH, IEEE-affiliated ones like S&P, FOCS, and ACM/IEEE-affiliated ones like MICRO and ICCAD (see Table 1). For reviewers, only 3 society-affiliated conferences fully adhere to society-level policies (e.g., IMC, SIGCSE, IMWUT), while many follow their own (e.g., ICCV, VIS, CVPR)."}, {"title": "RECOMMENDATIONS", "content": "Among 64 conferences analyzed, 26 (40.6%) implemented Gen-AI policies for authors or reviewers over the two years. Only 10 conferences (15.6%) had policies for reviewers. Considering policies for authors or reviewers, Theory and Systems conferences were slower, with none of 7 Theory and only 27.6% Systems conferences adopting policies by Year 2, compared to 84.6% in AI and 46.7% in Interdisciplinary fields. Notably, 16 of 26 conferences with policies introduced them in the second year and no conference allowed authorship for Gen-AI. Besides, many ACM and IEEE conferences seem unaware of society-level Gen-AI policies, highlighting inconsistent adoption.\nWith the rise of Gen-AI, we recommend that conferences without Gen-AI policies establish guidelines for both authors and reviewers. Reviewer policies should address writing reviews and evaluating AI use in submissions. Additionally, adopting Gen-AI policies at the area or society level would ensure consistency across conferences, benefiting both authors and reviewers by streamlining expectations and simplifying processes, especially for resubmissions within the same research community.\nGen-AI is a phenomenal technological advancement that will enhance efficiency across disciplines, and fields that do not adapt, risk falling behind. Thus, we recommend lenient use of Gen-AI in conferences, particularly to help level the playing field for non-native English speakers in their scholarly writings. Gen-AI should be utilized as a tool to enhance the author's work [4], without altering the core substance or narrative. Similarly, reviewers' judgments must be their own, but both authors and reviewers should take full responsibility and disclose Gen-AI use transparently. Given the imperfections of Gen-AI tools, especially with even humans' difficulty to recognize hallucinations [8], scholars must verify its content and ensure their writing is accurate and ethically generated. Ultimately, scholars bear the responsibility for ensuring that their scholarly writing is correct and the Gen-AI use is ethical, yet effective."}]}