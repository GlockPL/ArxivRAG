{"title": "Deep Manifold Part 1: Anatomy of Neural Network Manifold", "authors": ["Max Y. Ma", "Gen-Hua Shi"], "abstract": "Based on the numerical manifold method principle, we developed a mathematical framework of a neural network manifold: Deep Manifold and discovered that neural networks: 1) is numerical computation combining forward and inverse; 2) have near infinite degrees of freedom; 3) exponential learning capacity with depth; 4) have self-progressing boundary conditions; 5) has training hidden bottleneck. We also define two concepts: neural network learning space and deep manifold space and introduce two concepts: neural network intrinsic pathway and fixed point. We raise three fundamental questions: 1). What is the training completion definition; 2). where is the deep learning convergence point (neural network fixed point); 3). How important is token timestamp in training data given negative time is critical in inverse problem.", "sections": [{"title": "Introduction", "content": "A neural network is a powerful numerical computation architecture. To evaluate the capacity of any numerical computation architecture, there are three fundamental questions to consider:\nWhat degree of freedom does the system have? This will determine how many dimensions the system can compute.\nWhat degree of non-linearity can the system handle? This will determine how complex a problem the system is capable of solving.\nWhat kind of boundary conditions can the system handle? This will determine how well the system can manage external constraints.\nWe did not initially start with such a broad scope. Our initial effort was focused on understanding the nonlinear aspects of neural networks. Naturally and gradually, the scope expanded. We aimed to ensure our work was mathematically grounded, and the numerical manifold method became a natural choice."}, {"title": "Numerical Manifold Method", "content": "Manifolds are familiar to deep learning researchers and practitioners, especially for their ability in nonlinear dimensionality reduction. The principle behind these"}, {"title": "Anatomy of Neural Network Manifold", "content": ""}, {"title": "Inverse and Forward Enablement", "content": "Neural network is inverse and forward enabled:\nModel training is solve the inverse problem: $0 = F^{-1}(d)$\nModel inference is solve the forward problem: $d = F(0)$\nBackpropagation is to find 0 such that $||F(0) \u2013 d||$ is minimized\nThe neural network is able to solve forward and inverse problems with one architecture, this is very remarkable. In some inverse problems, there is a concept of negative time. Currently, training data lacks explicit timestamps (representing negative time); within a given context window, the timestamp is implicitly embedded in the token's position embedding. This implicit temporal encoding aids LLM training by compensating for the absence of explicit timestamps in the content, yet it also limits the exposure of negative time issues. Since LLMs learn from text data written in the past (negative time) without explicit timestamps, the representation of the time dimension within the model is often unclear and ambiguous.\nIn an example from Shi et al. (2023) [13], such as 'How many World Cups has Argentina won?', the correct answer is three, as Argentina won in 1978, 1986, and 2022. However, if the majority of the training data for an LLM predates 2022, the model might incorrectly answer with two. The reason is that the training data is weighted equally before and after 2022. By incorporating negative time, explicit content timestamps, and embedding these into the model similar to position embeddings, there is a high likelihood of obtaining 'three' as an answer."}, {"title": "Dynamic computation with infinite degree of freedom", "content": "According to the discretization theorem, actual computation is carried out at each node. We can extend the inverse problem formulation as follows\n$\\theta = F^{-1}(d) \\sim \\sum_{n=1}^{nodes} f_n(x_n)$\n$f_n$ is an integrable function, x is an input value.\nAccording to the Numerical Manifold Method, there is a cover (cover topology) per node, which we refer to as the node cover. The node cover changes its orientation after the weight update during the backward pass. Consequently, the neural network now has an almost infinite degree of freedom, as the orientation can take on nearly unlimited directions."}, {"title": "Exponential computation", "content": "Neural networks can be viewed as a composition of functions. For a single pathway connecting one node per layer across all hidden layers (H) end to end, the composition of functions can be represented as follows.\n$g(x) = (f_1 \\circ f_2 \\circ . . . \\circ f_n)(x) = f_1(f_2(... f_n(x) ...))$\nThis notation illustrates how the output of each function becomes the input to the next, forming a nested composition of functions from the input layer to the final output layer. In the Numerical Manifold Method, a dual pairing (dual topology) connects node covers together."}, {"title": "Self-progressing boundary condition", "content": "For any numerical computation, boundary conditions are required. Let's examine the loss function: $L(\\hat{y}, y)$, $\\hat{y}$ is the computed output (predicted value) at the end of the forward pass, while y is the actual target value applied at the beginning of the backward pass. The annotation, which is the target value (y), becomes the boundary condition for neural networks. This target value (y) is back-propagated through the neural network in a self-progressing manner. This self-progressing nature of boundary condition implementation makes self-supervised learning possible, as seen in models like GPT."}, {"title": "Learning Transformation", "content": "Neural network training is learning transformation powered by Learning capacity (T):\n$T \\rightarrow O(A^{WH}) : R^{LS\\cdot J} \\rightarrow R^{dm\\cdot J}$\nThis means a neural network is capable of handling non-linearity. We explicitly highlight the degree of non-linearity for three reasons:\nThe function high order (non-linearity) represents computation power mathematically.\nHigh-order non-linearity is often the most challenging aspect of numerical computation.\nThe non-linearity of neural networks and learning spaces is not yet well understood."}, {"title": "Neural Network Hidden Bottleneck", "content": "during the slow decline stage of almost all foundation model training, suggesting that training is struggling to converge-a hidden bottleneck identified in our analysis. A model is considered to have converged effectively when the standard deviation (SD) of its loss (error) values stabilizes at less than 5.\nAccording to our analysis, hidden bottleneck mitigation are already incorporated into deep learning practices. They are\n1. Dropouts and shortcut/skip connections\n2. Data engineering work including labeling function [9]\n3. Transformer has the best mitigation strategy\nThese mitigation either delay the development of non-linearity in the deep manifold space (#1) or reduce the learning space non-linearity from the beginning (#2). The Transformer architecture (#3) employs the most aggressive and effective mitigation strategy: reducing non-linearity at each node in every iteration. The attention layer functions as the data processing layer, effectively reducing non-linearity. In addition to the data processing concept, the Transformer includes two implementations that align with the principles of the numerical manifold method.\nAs the strength of the bottleneck increases, so does the rigidity of the deep manifold space. At this point, Fourier features within the space should become apparent. Fourier analysis helps in understanding the frequency components that constitute the deep manifold space response. In general, the more rigid a system is, the more it tends to exhibit high-frequency components in its response. In this context, Fourier analysis can be an effective method for measuring learning capacity during training.\nWe are surprised by the prolonged slow decline, which is accompanied by a relatively high standard deviation (SD) in the loss values. This suggests that other factors may be at play."}, {"title": "Neural Network Intrinsic Pathway", "content": "The prolonged, slow decline in the loss curve suggests that the neural network is a robust and resilient system. We have concluded the following from the previous sections\n1. Dynamic computation with infinite degree of freedom (section 3.2).\n2. The fluidity in self-progressing boundary conditions (section 3.4).\nThe neural network operates as a power-efficient system, with each node requiring minimal computational power, even when the deep manifold space becomes rigid and a bottleneck develops. Additionally, all foundation model pre-training is self-supervised. The neural network's self-progressing boundary condition imposes no restrictions on where incoming data is processed. Incoming data will be directed to whichever nodes are capable of processing it. This means that the neural network continues to learn even during the slow decline stage. In this sense, grokking and double descent are evidence of this continued learning.\nIt also means that the same token will be processed in different nodes. It is highly likely that many replicas of identical or near-identical feature bits (units of feature) disperse throughout the network. The inequality in mathematics, as described in the 'Contact Theory' (Shi, G. 2015) [12], suggests that connections between nodes (pathways) are not equal due to random neural network initialization. Our working theory proposes that feature bits propagate through the network, with their propagation distance determined by the computational capacity of each node. The pathway appears to be power-driven, prioritizing certain features or patterns during learning in a discriminatory manner. While this Intrinsic Pathway (IP) is mathematically plausible, the underlying theory remains unclear. It seems that neural networks are leading us into the realm of bifurcation theory."}, {"title": "Neural Network Fixed Point and Convergence", "content": "A fixed-point theorem in mathematics states that a function F will have at least one point x such that F(x) = x provided certain general conditions are met for the function F. The general condition is learning space (section 3.4) for neural networks. The theory of Fixed Point Classes 1 (Kiang Tsai-Han, 1980) [4], a concept rooted in algebraic topology and fixed-point theory, suggests the existence of numerous fixed points. Yet, not all these fixed points necessarily represent true or final solutions. We establish a linkage between this false fixed point and the occurrence of hallucinations in foundation models. This linkage offers a promising pathway for further research into the mechanisms underlying hallucinations. The hallucinations have many contributing factors or sources. One of them is the convergence due to inadequate learning space (section 3.4) and hidden bottleneck (3.6)."}, {"title": "Discussion", "content": "We found that neural networks function as a numerical computation framework, and more precisely, they operate as a form of numerical manifold. The question then arises: if they aren't numerical computation, what kind of computation are they doing? For numerical computation, the primary focus is on convergence-both its reliability and speed."}, {"title": "Convergence and Training Completion", "content": "In most physics-based numerical computations, equilibrium states, either static or dynamic, are typically derived from theoretical or empirical formulations and"}, {"title": "Convergence and Boundary Condition", "content": "Boundary conditions play a crucial role in numerical computation. As outlined in Section 3.4 (Learning Space), the boundary condition in a neural network corresponds to annotations, which are embedded within the training data for supervised or self-supervised learning, shaping the learning space. These boundary conditions can be categorized into two aspects: 1) weak annotations (labels) with noise, and 2) symmetric boundary conditions. Similar to other numerical computations, boundary conditions guide the direction or path toward convergence.\nWeak annotations are easier to obtain than strong annotations (ground truth), as demonstrated by the Snorkel approach (Ratner et al., 2017) [9]. Multiple weak annotations, such as using three weak labels, can provide a more reliable direction for convergence compared to relying on a single strong annotation. Additionally, since training data is fed iterative in batches, neural network training can be viewed as a dynamic process. According to perturbation theory, noise plays a"}, {"title": "Convergence and High Order Non-linearity", "content": "High-order non-linearity becomes increasingly critical and may present a bottleneck for foundation models processing trillions of tokens. On the surface, techniques like Chain of Thought (CoT) exemplify high-order non-linearity with their complex, multi-step reasoning. Within the transformer architecture, normalization plays a pervasive role, occurring throughout the entire network. The reason for normalization is to prevent the divergence.\nConvergence in high-order nonlinear systems is particularly challenging, as even small errors can quickly lead to divergence. The key lies in balancing the preservation of high-order nonlinear features (information) while minimizing the computational complexity associated with them. From an architectural standpoint, techniques like dropout and skip connections effectively mitigate the degree of high-order non-linearity. From the data perspective, weak annotations (with noise) and symmetric distributions help reduce the computational demands of handling high-order non-linearity.\nThere are a good number of alternatives to gradient descent for achieving convergence. However, the current implementation of gradient descent presents a limitation in the training of foundation models. This issue isn't exclusive to foundation model training. When high-order non-linearity is not accurately modeled"}, {"title": "Future Work", "content": "This Part 1 work aims to establish key baselines grounded in solid mathematical reasoning. It should be viewed as a conceptual and directional study. Further rigorous proofs and empirical validation are necessary to fully substantiate the merits of the ideas presented in this paper."}]}