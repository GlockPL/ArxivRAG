{"title": "A Mathematical Framework, a Taxonomy of Modeling Paradigms, and a Suite of Learning Techniques for Neural-Symbolic Systems", "authors": ["Charles Dickens", "Connor Pryor", "Changyu Gao", "Alon Albalak", "Eriq Augustine", "William Wang", "Stephen Wright", "Lise Getoor"], "abstract": "The field of Neural-Symbolic (NeSy) systems is growing rapidly. Proposed approaches show great promise in achieving symbiotic unions of neural and symbolic methods. However, each NeSy system differs in fundamental ways. There is a pressing need for a unifying theory to illuminate the commonalities and differences in approaches and enable further progress. In this paper, we introduce Neural-Symbolic Energy-Based Models (NeSy-EBMs), a unifying mathematical framework for discriminative and generative modeling with probabilistic and non-probabilistic NeSy approaches. We utilize NeSy-EBMs to develop a taxonomy of modeling paradigms focusing on a system's neural-symbolic interface and reasoning capabilities. Additionally, we introduce a suite of learning techniques for NeSy-EBMs. Importantly, NeSy-EBMs allow the derivation of general expressions for gradients of prominent learning losses, and we provide four learning approaches that leverage methods from multiple domains, including bilevel and stochastic policy optimization. Finally, we present Neural Probabilistic Soft Logic (NeuPSL), an open-source NeSy-EBM library designed for scalability and expressivity, facilitating real-world application of NeSy systems. Through extensive empirical analysis across multiple datasets, we demonstrate the practical advantages of NeSy-EBMs in various tasks, including image classification, graph node labeling, autonomous vehicle situation awareness, and question answering.\nKeywords: Neural-Symbolic AI, Energy-based Models, Deep Learning", "sections": [{"title": "1 Introduction", "content": "The promise of mutually beneficial neural and symbolic integrations has motivated significant advancements in machine learning research. Much of the recent progress has been achieved in the neural-symbolic (NeSy) computing literature (d'Avila Garcez et al., 2002, 2009, 2019). NeSy is a large and quickly growing community that has been holding regular workshops since 2005 (NeSy2005) and began holding conferences in 2024 (NeSy2024). At a high level, NeSy research aims to build algorithms and architectures for combining neural and symbolic components (Xu et al., 2018; Yang et al., 2020; Cohen et al., 2020; Manhaeve et al., 2021a; Wang et al., 2019; Badreddine et al., 2022; Ahmed et al., 2022a; Pryor et al., 2023a). With its rapid growth, the field of NeSy needs a unifying framework to function as a common foundation for further progress. Such a unifying theory should support the understanding and organization of the strengths and weaknesses of NeSy methods and help to align design decisions to the needs of an application. Moreover, it should support the development of new and widely applicable NeSy inference and learning algorithms.\nIn this paper, we introduce Neural-Symbolic Energy-Based Models (NeSy-EBMs), a unifying framework for NeSy. NeSy-EBMs are a family of Energy-Based Models (EBMs) (LeCun et al., 2006) defined by energy functions that are compositions of parameterized neural and symbolic components. The neural component is a collection of deep models, and its output is provided to the symbolic component, which measures the compatibility of variables using domain knowledge and constraints. This general formalization serves multiple purposes, including functioning as a foundation for identifying modeling paradigms and reasoning capabilities of NeSy models and developing generally applicable NeSy inference and learning algorithms. Additionally, energy-based modeling is an established and recognized perspective that connects NeSy to the broader machine learning literature.\nWe use the NeSy-EBM framework to introduce a general formalization of reasoning as mathematical programming. This formalization motivates a new NeSy taxonomy that categorizes models based on their reasoning capabilities. Specifically, we organize approaches into three modeling paradigms that vary with increasing expressivity and complexity: deep symbolic variables, deep symbolic parameters, and deep symbolic potentials. These categories are differentiated by their neural-symbolic connection, i.e., the way in which the neural component output is utilized in the symbolic component. Our modeling paradigms organize and illuminate the strengths and limitations of existing NeSy systems. Moreover, we identify architectures that support NeSy use cases, such as learning from domain knowledge and data, satisfying prediction constraints, and consistent reasoning in open-ended domains.\nFurther, we develop a suite of principled neural and symbolic parameter learning techniques for NeSy. NeSy-EBM predictions are typically obtained by finding a state of variables with high compatibility (i.e., low energy). The high compatibility state is found by minimizing the energy function via an optimization algorithm, for instance, an interior point method for continuous variables (Nocedal and Wright, 2006) or a branch-and-bound strategy for discrete problems (H. Papadimitriou and Steiglitz, 1998). The complex prediction process makes finding a gradient or descent direction of a standard machine learning loss with respect to the parameters difficult. To formalize these challenges and propose solutions, we introduce a categorization of learning losses based on the complexity of the relation to the NeSy-EBM energy function. We derive general expressions for gradients of the"}, {"title": "2 Motivation", "content": "We highlight five applications that motivate NeSy: 1) constraint satisfaction and joint reasoning, 2) fine-tuning and adaptation, 3) few-shot and zero-shot reasoning, 4) semi-supervised learning, and 5) reasoning with noisy data. This list of use cases is not exhaustive. However, the efficacy of the NeSy approach in these applications is well established, and we will illustrate four of these use cases in our empirical evaluation. The following subsections define the problem and the high-level motivation for utilizing NeSy techniques in such settings. Additionally, we discuss collections of existing NeSy systems for each application."}, {"title": "2.1 Constraint Satisfaction and Joint Reasoning", "content": "In real-world settings, a deployed model's predictions must meet well-defined requirements. Additionally, leveraging known patterns or dependencies in the output can significantly improve a model's accuracy and trustworthiness. Constraint satisfaction is finding a prediction that satisfies all requirements. NeSy systems perform constraint satisfaction by reasoning across their output to provide a structured prediction, typically using some form of joint reasoning. In other words, NeSy systems integrate constraints and knowledge into the prediction process.\nA commonly used example of constraint satisfaction and joint reasoning with NeSy techniques is puzzle-solving. Many NeSy frameworks are introduced with an evaluation on visual Sudoku and its variants (Wang et al., 2019; Augustine et al., 2022). In the visual Sudoku problem, puzzles are constructed with handwritten digits, and a model must classify the digits and infer numbers to fill in the empty cells using the rules of Sudoku. Empirical evaluations of NeSy systems that perform constraint satisfaction and joint reasoning on visual Sudoku problems can be found in Wang et al. (2019), Augustine et al. (2022), Pryor et al. (2023a), and Morra et al. (2023). Similarly, Vlastelica et al. (2020) introduces the shortest path finding problem as a NeSy task. Images of terrain maps are partitioned into a grid, and the model must find a continuous lowest-cost path between two points. The works of Vlastelica et al. (2020) and Ahmed et al. (2022a) perform constraint satisfaction and joint reasoning with NeSy models for shortest path finding.\nConstraint satisfaction and joint reasoning with NeSy models are also effective for real-world natural language tasks. For instance, Sachan et al. (2018) introduces the Nuts&Bolts NeSy system to build a pipeline for parsing physics problems. The NeSy system jointly infers a parsing from multiple components that incorporates domain knowledge and prevents the accumulation of errors that would occur from a naive composition. In another work, Zhang et al. (2023) propose GeLaTo (generating language with tractable constraints) for imposing constraints on text generated from language models. GeLaTo generates text tokens by autoregressively sampling from a distribution constructed from a pre-trained language model and a tractable probabilistic model encoding the constraints. More recently, Pan et al. (2023) introduced the Logic-LM framework for integrating LLMs with symbolic solvers to improve complex problem-solving. Logic-LM formulates a symbolic model using an"}, {"title": "2.2 Fine-tuning and Adaptation", "content": "We are in the era of foundation models in AI (Bommasani et al., 2022). It is now commonplace to adjust a model that is pre-trained on large amounts of general data (typically using self-supervision) for downstream tasks. Fine-tuning and adaptation are two methods for updating the parameters of a pre-trained model to perform a specific problem or a dataset in a new domain (Devlin et al., 2019; J. Hu et al., 2022). Fine-tuning and adaptation adjust the pre-trained model parameters by minimizing a learning objective over a dataset, both of which are specialized for the downstream tasks. These are necessary steps in the modern AI development process.\nNeSy frameworks are used in the fine-tuning and adaptation steps to design principled learning objectives that integrate knowledge and constraints relevant to the downstream task and the application domain. Giunchiglia et al. (2022) provides a recent survey of the use of logically specified background knowledge to train neural models. NeSy learning losses are applied in the work of Giunchiglia et al. (2023) to fine-tune a neural system for autonomous vehicle situation awareness (Singh et al., 2021). In another computer vision task, Arrotta et al. (2024) develop a NeSy loss for training a neural model to perform context-aware human activity recognition. NeSy fine-tuning and adaptation have also been explored in the natural processing literature. Recently, Ahmed et al. (2023b) proposed the pseudo-semantic loss for detoxifying large language models. The authors disallow a list of toxic words and show this intuitive approach steers a language model's generation away from harmful language and achieves state-of-the-art detoxification scores. Feng et al. (2024) has explored directly learning the reasoning process of logical solvers within the LLM to avoid parsing errors. Finally, Cunnington et al. (2024) introduced NeSyGPT, which fine-tunes a vision-language"}, {"title": "2.3 Few-Shot and Zero-Shot Reasoning", "content": "Training data for a downstream task may be limited or even nonexistent. In few-shot settings, only a few examples are available, while in zero-shot settings, no explicit training data is provided for the task. In these settings, few-shot and zero-shot reasoning techniques are used to enable a model to generalize beyond the limited available training data. Leveraging pre-trained models and domain knowledge are key ideas for succeeding in few-shot and zero-shot contexts.\nNeSy techniques have been successfully applied for various few-shot and zero-shot settings. Integrating symbolic knowledge and reasoning enables better generalization from a small number of examples. NeSy systems can utilize symbolic knowledge to make deductions about unseen classes or tasks. For instance, providing recommendations for new items or users can be viewed as a few-shot or zero-shot problem. Kouki et al. (2015) introduce the HyPER (hybrid probabilistic extensible recommender) framework for incorporating and reasoning over a wide range of information sources. By combining multiple information sources via logical relations, the authors outperformed the state-of-the-art approaches of the time. More recently, Carraro et al. (2022) developed an LTN-based recommender system to overcome data sparsity. This model uses background knowledge to generalize predictions for new items and users quickly. Few-shot and zero-shot reasoning tasks are also prevalent in object navigation. The ability to navigate to novel objects and unfamiliar environments is vital for the practical use of embodied agents in the real world. In this context, Zhou et al. (2023) presents a method for \u201cexploration with soft commonsense constraints\" (ESC). ESC first employs a pre-trained vision and language model for semantic scene understanding, then a language model to reason from the spatial relations, and finally PSL to leverage symbolic knowledge and reasoning to guide exploration. In natural language processing, Pryor et al. (2023b) infers the latent dialog structure of a goal-oriented conversation using domain knowledge to overcome the challenges of limited data and out-of-domain generalization. Sikka et al. (2020) (mentioned above) also finds that the few-shot and zero-shot capabilities of NeSy models help in visual relationship detection. Specifically, the addition of commonsense reasoning and knowledge improves performance by over 10% in data-scarce settings."}, {"title": "2.4 Semi-Supervised Learning", "content": "Semi-supervised approaches facilitate learning from labeled as well as unlabelled data by combining the goals of supervised and unsupervised machine learning. We refer the reader to this recent excellent survey on semi-supervised approaches (E. van Engelen and H. Hoos, 2020). In short, supervised methods fit a model to predict an output label given a corresponding input, while unsupervised methods infer the underlying structure in the data. The ability to leverage both labeled and unlabelled data leads to performance improvements, better generalization, and reduced labeling costs.\nNeSy is a functional approach to semi-supervised learning that leverages knowledge and domain constraints to train a model. This is achieved with loss functions that encode domain knowledge and structure and depend only on the input and output; that is, they"}, {"title": "2.5 Reasoning with Noisy Data", "content": "Errors and noise in training data arise from various sources, such as mislabeling, data entry mistakes, measurement inaccuracies, and inherent variability. Noise affects both the inference and learning stages of a machine learning model. It can make learning the true underlying relationship in the data difficult and lead to incorrect predictions. Data cleaning, regularization, ensemble learning, and data augmentation are some techniques for reasoning with noisy data.\nNeSy techniques are beneficial for reasoning with noisy data as they can improve generalizability and provide a principled method for regularization with knowledge to prevent overfitting. For instance, Donadello et al. (2017) shows that using knowledge adds robustness to the learning process when errors are present in the training labels. Specifically, the proposed LTN model is more robust to mislabeling noise than a stand-alone deep neural network object detection model, realizing a more controlled drop in performance as label noise increases. Similarly, Manhaeve et al. (2021a) demonstrates the ability of symbolic models to overcome noise in the classic MNIST addition setting."}, {"title": "3 Related Work", "content": "There is a long, rich history of research on the integration of symbolic knowledge and reasoning with neural networks, which has rapidly evolved in the past decade. In this work, we establish a unifying framework for achieving such integration by connecting two foundational areas of machine learning research: Neural-Symbolic (NeSy) AI and energy-based modeling (EBMs). We use bilevel optimization techniques to propose a new family of algorithms for end-to-end gradient-based learning of the neural and symbolic component parameters. The remainder of this section provides an overview of the related work in NeSy, EBMs, and bilevel optimization."}, {"title": "3.1 Neural-Symbolic Frameworks", "content": "NeSy empowers neural models with domain knowledge and reasoning through integrations with symbolic systems (d'Avila Garcez et al., 2002, 2009, 2019; De Raedt et al., 2020; Besold et al., 2022). Various taxonomies have been proposed to categorize NeSy literature. Bader and Hitzler (2005), d'Avila Garcez et al. (2019), and most recently Besold et al. (2022)"}, {"title": "3.1.1 LEARNING WITH CONSTRAINTS", "content": "The essence of learning with constraints is using domain knowledge and common sense to construct a loss function (Giunchiglia et al., 2022; van Krieken et al., 2022). This approach encodes the knowledge captured by the loss into the weights of the network. A key motivation is to ensure the compatibility of predictions with domain knowledge and common sense. Moreover, learning with constraints avoids potentially expensive post-prediction interventions that would be necessary with a model that is not aligned with domain knowledge. However, consistency with domain knowledge and sound reasoning are not guaranteed during inference for NeSy models in this class.\nDemeester et al. (2016), Rockt\u00e4schel and Riedel (2017), Diligenti et al. (2017), Bo\u0161njak et al. (2017), and Xu et al. (2018) are prominent examples of the learning-with-constraints NeSy paradigm. Demeester et al. (2016) incorporates domain knowledge and common sense into natural language and knowledge base representations by encouraging partial orderings over embeddings via a regularization of the learning loss. Similarly, Rockt\u00e4schel and Riedel (2017) leverage knowledge represented as a differentiable loss derived from logical rules to train a matrix factorization model for relation extraction. Diligenti et al. (2017) use fuzzy logic to measure how much a model's output violates constraints, which is minimized during learning. Xu et al. (2018) introduces a loss function that represents domain knowledge and common sense by using probabilistic logic semantics. More recently,"}, {"title": "3.1.2 DIFFERENTIABLE REASONING LAYERS", "content": "Another successful area of NeSy is in differentiable reasoning layers. The primary difference between this family of NeSy approaches and learning with constraint is that an explicit representation of knowledge and reasoning is maintained in the model architecture during both learning and inference. A defining aspect of differentiable reasoning layers is the instantiation of knowledge and reasoning components as differentiable computation graphs. Differentiable reasoning layers support automatic differentiation during learning and symbolic reasoning during inference.\nPioneering works in differentiable reasoning include those of Wang et al. (2019), Cohen et al. (2020), Yang et al. (2020), Manhaeve et al. (2021a), Derkinderen et al. (2024), Badreddine et al. (2022), Ahmed et al. (2022a) and Ahmed et al. (2023a). Wang et al. (2019) integrates logical reasoning and deep models by introducing a differentiable smoothed approximation to a maximum satisfiability (MAXSAT) solver as a layer. Cohen et al. (2020) introduces a probabilistic first-order logic called TensorLog. This framework compiles tractable probabilistic logic programs into differentiable layers. A TensorLog system is end-to-end differentiable and supports efficient parallelizable inference. Similarly, Yang et al. (2020) and Manhaeve et al. (2021a) compile tractable probabilistic logic programs into differentiable functions with their frameworks NeurASP and DeepProblog, respectively. NeurASP and DeepProblog use answer set programming (Brewka et al., 2011) and ProbLog (De Raedt et al., 2007) semantics, respectively. Winters et al. (2022) proposes DeepStochLog, a NeSy framework based on stochastic definite clause grammars that define a probability distribution over possible derivations. Recently, Maene and Raedt (2024) proposes DeepSoftLog, a superset of ProbLog, adding embedded terms that result in probabilistic rather than fuzzy semantics. The logic tensor network (LTN) framework proposed by Badreddine et al. (2022) uses neural network predictions to parameterize functions representing symbolic relations with real-valued or fuzzy logic semantics. The fuzzy logic functions are aggregated to define a satisfaction level. Predictions can be obtained by evaluating the truth value of all possible outputs and returning the highest-valued configuration. Badreddine et al. (2023) has expanded upon LTNs and presents a configuration of fuzzy operators for grounding formulas end-to-end in the logarithm space that is more effective than previous proposals. Recently, Ahmed et al. (2022a) introduced a method for compiling differentiable functions representing knowledge and logic using the semantics of probabilistic circuits (PCs) (Choi et al., 2020). Their approach, called semantic probabilistic layers (SPLs), performs exact inference over tractable probabilistic models to enforce constraints over the predictions and uses the PC framework to ensure that the NeSy model is end-to-end trainable.\nAs pointed out by Cohen et al. (2020), answering queries in many (probabilistic) logics is equivalent to the weighted model counting problem, which is #P-complete or worse. Similarly, the MAXSAT problem studied by Wang et al. (2019) is NP-hard. Thus, since deep neural networks can be evaluated in time polynomial in their size, no polysize network can implement general logic queries unless #P=P, or MAXSAT solving, unless NP=P. For this reason, researchers have made progress towards building more efficient differentiable"}, {"title": "3.1.3 REASONER AGNOSTIC SYSTEMS", "content": "More recently, researchers have sought to build NeSy frameworks with more general reasoning and knowledge representation capacities with expressive mathematical program blocks for reasoning. Mathematical programs are capable of representing cyclic dependencies across variables and ensuring the satisfaction of prediction constraints during learning and inference. Moreover, the system's high-level inference and training algorithms are agnostic to the solver used for the mathematical program.\nProminent reasoner-agnostic systems include the works of Amos and Kolter (2017), Agrawal et al. (2019a), Vlastelica et al. (2020), and Cornelio et al. (2023). Amos and Kolter (2017) integrate linearly constrained quadratic programming problems (LCQP) as layers in deep neural networks with their OptNet framework, and show that the solutions to the LCQP problems are differentiable with respect to the program parameters. The progress of OptNet was continued by the work of Agrawal et al. (2019a) with the application of domain-specific languages (DSLs) for instantiating the LCQP program layers. DSLs provide a syntax for specifying LCQPs representing knowledge and constraints, making optimization layers more accessible. Vlastelica et al. (2020) propose a method for computing gradients of solutions to mixed integer linear programs based on a continuous interpolation of the program's objective. In contrast to the works of Amos and Kolter (2017) and Agrawal et al. (2019a), the approach introduced by Vlastelica et al. (2020) supports integer constraints and achieves this by approximating the true gradient of the program output. Cornelio et al. (2023) takes a different approach from these three methods by employing reinforcement learning techniques to support more general mathematical programs. Specifically, the neural model's predictions are interpreted as a state in a Markov decision process. Actions from a policy are taken to identify components that violate constraints to obtain a new state. The new state is provided to a solver, which corrects the violations, and a reward is computed. The solver is not assumed to be differentiable, and the REINFORCE algorithm (Williams, 1992) with a standard policy loss is used to train the system end-to-end without the need to backpropagate through the solver."}, {"title": "3.2 Energy-Based Models", "content": "Our NeSy framework makes use of Energy-Based Models (EBMs) (LeCun et al., 2006). EBMs measure the compatibility of a collection of observed (input) variables \\(x \\in \\mathcal{X}\\) and target (output) variables \\(y \\in \\mathcal{Y}\\) via a scalar-valued energy function: \\(E : \\mathcal{Y} \\times \\mathcal{X} \\rightarrow \\mathbb{R}\\). Low energy states represent high compatibility. EBMs are appealing due to their generality in both modeling and application. For instance, EBMs can be used to perform density estimation by defining conditional, joint, and marginal Gibbs distributions with the energy"}, {"title": "4 A Mathematical Framework for NeSy", "content": "With this extensive motivation and background in hand, in this section, we introduce Neural-symbolic energy-based models (NeSy-EBMs): a unifying mathematical framework for NeSy. Intuitively, NeSy-EBMs formalize the neural-symbolic interface as a composition of functions. The theory and notation introduced in this section are used throughout the rest of this paper."}, {"title": "4.1 Neural Symbolic Energy-Based Models", "content": "NeSy-EBMs are a family of EBMs (LeCun et al., 2006) that integrate deep architectures with explicit encodings of symbolic relations via an energy function. EBM energy functions measure the compatibility of variables where low energy states correspond to high compatibility. For NeSy-EBMs, high compatibility indicates that the variables are consistent with domain knowledge and common sense. In the following section, the formal NeSy-EBM definition provided below is grounded with intuitive examples of NeSy modeling paradigms.\nAs diagrammed in Fig. 1, a NeSy-EBM energy function composes a neural component with a symbolic component, represented by the functions \\(g_{\\text{nn}}\\) and \\(g_{\\text{sy}}\\), respectively. The neural component is a deep model (or collection of deep models) parameterized by weights from a domain \\(W_{\\text{nn}}\\), that takes a neural input from a domain \\(X_{\\text{nn}}\\) and outputs a real-"}, {"title": "5 A Taxonomy of Modeling Paradigms for NeSy", "content": "Using the NeSy-EBM framework introduced in the previous section, we introduce a taxonomy of NeSy modeling paradigms determined by the neural-symbolic interface. Our modeling paradigms are characterized by how the neural component is utilized in the symbolic component to define the prediction program in (7). To formalize the modeling paradigms, we introduce an additional layer of abstraction we refer to as symbolic potentials, denoted by \\(\\psi\\). Further, we collect symbolic potentials into symbolic potential sets, denoted by \\(\\Psi\\). Symbolic potentials organize the arguments of the symbolic component by the role they play in formulating the prediction program in (7)."}, {"title": "5.1 Deep Symbolic Variables", "content": "The deep symbolic variables (DSVar) paradigm trains neural components efficiently with a loss that captures domain knowledge. Representative methods following this paradigm include semantic loss networks (Xu et al., 2018) and learning with logical constraints (Giunchiglia et al., 2022). Concisely, the neural component directly predicts the values of targets in a single symbolic potential. In other words, there is a one-to-one mapping from the neural output to the targets. Note, however, that the mapping is not necessarily onto, i.e., there may be target variables without a corresponding neural output. For this discussion of modeling paradigms, we use the term \"latent\" to refer to target variables without a neural output in a DSVar model."}, {"title": "5.2 Deep Symbolic Parameters", "content": "The deep symbolic parameters (DSPar) modeling paradigm allows targets and neural predictions to be unequal or represent different concepts. Prominent NeSy frameworks supporting this technique include DeepProbLog (Manhaeve et al., 2021a), semantic probabilistic layers (Ahmed et al., 2022a), and logic tensor networks (Badreddine et al., 2022). Succinctly, the neural component is applied as a parameter in the symbolic potential. This paradigm allows the symbolic component to correct constraint violations made by the neural component during prediction. For this reason, DSPar's inference and learning processes are typically"}, {"title": "5.3 Deep Symbolic Potentials", "content": "Deep-symbolic potentials (DSPot), the most advanced paradigm we propose, enhances deep models with symbolic reasoning tools. The Logic-LM pipeline proposed by Pan et al. (2023) is an excellent example of this modeling paradigm. At a high level, the neural component is a generative model that samples symbolic potentials from a set to define the symbolic component. Specifically, input data is used as context to retrieve relevant domain knowledge and formulate a program to perform inference in open-ended problems.\nIn our view, DSPot is the only applicable paradigm for truly open-ended tasks. Moreover, DSPot enhances generative models, such as LLMs, with consistent symbolic reasoning capabilities. This feature is demonstrated in constraint satisfaction and joint reasoning experiments in our empirical analysis. DSPot's limitation is that the neural component must learn to sample from a large potential set. For instance, in the example, an LLM must reliably generate syntax to define a symbolic potential for solving the word problem. LLMs require a substantial amount of computational resources to train and then fine-tune for a specific NeSy framework. Furthermore, the inference time is dependent on the sampled symbolic potential. If the neural component samples a complex symbolic potential, inference may be slow. These strengths and limitations are outlined in Table 1."}, {"title": "6 A Suite of Learning Techniques for NeSy", "content": "Having identified a variety of modeling and inference paradigms, we turn to learning. This section formalizes the NeSy-EBM learning problem, identifies challenges, and proposes effective solutions. At a high level, NeSy-EBM learning is finding weights of an energy function that associates higher compatibility scores (lower energy) to targets and neural outputs near their true labels provided in training data. Further, predictions with NeSy-EBMs are obtained by minimizing a complex mathematical program, raising several obstacles to learning. For instance, NeSy-EBM predictions may not be differentiable with respect to the model parameters, and a direct application of automatic differentiation may not be possible or may fail to produce principled descent directions for the learning objective. Moreover, we will show that even when predictions are differentiable, their gradients are functions of properties of the energy function at its minimizer that are prohibitively expensive to compute. We create general and principled learning frameworks for NeSy-EBMs that address these challenges.\nThis section is organized into four subsections. We begin with preliminary notation and a general definition of NeSy-EBM learning. Then, we present a classification of learning losses first introduced by Dickens et al. (2024a) and expand theoretical differentiability results presented in Dickens et al. (2024b). The learning losses motivate and organize the exposition of four NeSy-EBM learning frameworks, one for learning the neural and symbolic weights separately and three for end-to-end learning."}, {"title": "6.1 NeSy-EBM Learning", "content": "We use the following notation and general definition of NeSy-EBM learning throughout this section. The training dataset, denoted by \\(\\mathcal{S}\\), is comprised of \\(P\\) samples and indexed by \\({1,\\dots, P}\\). Each sample, \\(S_i\\) where \\(i \\in \\{1,\\dots, P\\}\\), is a tuple of inputs, labels, and latent variable domains. Sample inputs consist of neural inputs, \\(x_{\\text{nn}}\\), from \\(X_{\\text{nn}}\\), and symbolic inputs, \\(x_{\\text{sy}}\\) from \\(X_{\\text{sy}}\\). Similarly, sample labels consist of neural and symbolic labels, which are truth values corresponding to a subset of the neural predictions and target variables, respectively. Neural labels, denoted by \\(t_{\\text{nn}}\\), are \\(d_{\\text{nn}}' \\leq d_{\\text{nn}}\\) dimensional real vectors from a domain \\(T_{\\text{nn}} \\subseteq \\mathbb{R}^{d_{\\text{nn}}}', i.e., \\(t_{\\text{nn}} \\in T_{\\text{nn}} \\subseteq \\mathbb{R}^{d_{\\text{nn}}}'\\). Target labels, denoted by \\(t_{\\text{y}}\\), are from a domain \\(T_{\\text{y}}\\) that is a \\(d_{\\mathcal{Y}}' \\leq d_{\\mathcal{Y}}\\) subspace of the target domain \\(\\mathcal{Y}\\), i.e., \\(t_{\\text{y}} \\in T_{\\text{y}}\\).\nLastly, the neural and symbolic latent variable domains are subspaces of the range of the neural component and the target domain, respectively, corresponding to the set of unlabeled variables. The range of the neural component, \\(\\mathbb{R}^{d_{\\text{nn}}}\\), is a superset of the Cartesian product of the neural latent variable domain, denoted by \\(Z_{\\text{nn}}\\), and \\(T_{\\text{nn}}\\), i.e., \\(\\mathbb{R}^{d_{\\text{nn}}} \\supseteq T_{\\text{nn}} \\times Z_{\\text{nn}}\\). Similarly, the target domain \\(\\mathcal{Y}\\) is a superset of the Cartesian product of the latent variable domain, denoted by \\(Z_{\\text{y}}\\), and \\(T_{\\text{y}}\\), i.e., \\(\\mathcal{Y} \\supseteq T_{\\text{y}} \\times Z_{\\text{y}}\\). With this notation, the training dataset is expressed as follows:\n\\[\\begin{aligned} \\mathcal{S} := \\{ & (t_{\\text{y}}^1, t_{\\text{nn}}^1, z_{\\text{nn}}^1, z_{\\text{y}}^1, x_{\\text{sy}}^1, x_{\\text{nn}}^1), \\dots, \\\\ & (t_{\\text{y}}^P, t_{\\text{nn}}^P, z_{\\text{nn}}^P, z_{\\text{y}}^P, x_{\\text{sy}}^P, x_{\\text{nn}}^P) \\} \\end{aligned}\\]\nA learning objective, denoted by \\(\\mathcal{L}\\), is a functional that maps an energy function and a training dataset to a scalar value. Formally, let \\(\\mathcal{E}\\) be a family of energy functions indexed by"}, {"title": "6.2 Learning Losses", "content": "A NeSy-EBM learning loss functional, \\(\\mathcal{L}^i\\), is separable into three parts: neural, value-based, and minimizer-based losses. In this subsection, we formally define each of the three loss types. At a high level, the neural loss measures the quality of the neural component independent from the symbolic component. Then, the value-based and minimizer-based losses measure the quality of the NeSy-EBM as a whole. Moreover, value-based and minimizer-based losses are functionals mapping a parameterized energy function and a training sample to a real value and are denoted by \\(L_{\\text{val}} : \\mathcal{E} \\times S_i \\rightarrow \\mathbb{R}\\) and \\(L_{\\text{Min}} : \\mathcal{E} \\times S_i \\rightarrow \\mathbb{R}\\), respectively. The learning loss components are aggregated via summation:\n\\[\\begin{aligned} \\mathcal{L}^i(\\mathcal{E}(\\cdot, \\cdot, \\cdot, W_{\\text{sy}}, W_{\\text{nn}}), S_i) = & L_{\\text{NN}}(g_{\\text{nn}}(x_{\\text{nn}}, W_{\\text{nn}}), t_{\\text{nn}}) \\\\ &+ L_{\\text{val}}(\\mathcal{E}(\\cdot, \\cdot, \\cdot, W_{\\text{sy}}, W_{\\text{nn}}), S_i) \\\\ &+ L_{\\text{Min}}(\\mathcal{E}(\\cdot, \\cdot, \\cdot, W_{\\text{sy}}, W_{\\text{nn}}), S_i) \\end{aligned}\\]"}, {"title": "6.2.1 NEURAL LEARNING LOSSES", "content": "Neural learning losses are scalar functions ofthe neural network output and the neural labels and are denoted by \\(L_{\\text{NN}} : \\text{Range}(g_{\\text{nn}}) \\times T_{\\text{nn}} \\rightarrow \\mathbb{R}\\). For example, a neural learning loss may be the familiar binary cross-entropy loss applied in many categorical prediction settings. Minimizing a neural learning loss with respect to neural component parameters is achievable via backpropagation and standard gradient-based algorithms."}, {"title": "6.2.2 VALUE-BASED LEARNING LOSSES", "content": "Value-based learning losses depend on the model weights strictly via minimizing values of an objective defined with the energy. More formally, denote an objective function by \\(f\\), which maps a compatibility score, target variables, and the training sample to a scalar value:\n\\[f : \\mathbb{R} \\times \\mathcal{Y} \\times \\{S_i\\} \\rightarrow \\mathbb{R}.\\]\nAn optimal value-function, denoted by \\(V\\), is the value of \\(f\\) composed with the energy function and minimized over the target variables:\n\\[\\begin{aligned} V(W_{\\text{sy}}, W_{\\text{nn}}, S_i) := & \\underset{\\hat{y} \\in \\mathcal{Y}}{\\text{min}} f (E(y, x_{\\text{sy}}, x_{\\text{nn}}, W_{\\text{sy}}, W_{\\text{nn}}), \\hat{y}, S_i) \\\\ := & \\underset{\\hat{y} \\in \\mathcal{Y}}{\\text{min}} f(g_{\\text{sy}} (y, x_{\\text{sy}}, W_{\\text{sy}}, g_{\\text{nn}} (x_{\\text{nn}}, W_{\\text{nn}})), \\hat{y}, S_i) \\end{aligned}\\]\nValue-based learning losses are functions of one or more optimal value functions. In this work, we consider three instances of optimal value functions: 1) latent, \\(V_z\\), 2) full, \\(V_y\\), 3) and convolutional, \\(V_{\\text{conv}}\\). The latent optimal value function is the minimizing value of the energy over the latent targets. Further, the labeled targets are fixed to their true values using the following indicator function:\n\\[I_{T^i}(y, t_{\\text{y}}) := \\begin{cases} 0 & y = t_{\\text{y}} \\\\ \\infty & \\text{o.w.} \\end{cases}\\]\nThe full optimal value function is the minimizing value of the energy over all of the targets. Lastly, the convolutional optimal value function is the infimal convolution of the energy function and a function \\(d : \\mathcal{Y} \\times \\mathcal{Y} \\rightarrow \\mathbb{R}\\) scaled by a positive real value \\(\\lambda \\in \\mathbb{R}\\). Formally:\n\\[\\begin{aligned} V_z(W_{\\text{sy}}, W_{\\text{nn}}, S_i) := & \\underset{\\hat{y} \\in \\mathcal{Y}}{\\text{min}} \\mathcal{E} (y, x_{\\text{sy}}, x_{\\text{nn}}, W_{\\text{sy}}, W_{\\text{nn}}) + I_{T^i}(y, t_{\\text{y}}), \\\\ = & \\underset{z \\in \\mathcal{Z}}{\\text{min}} \\mathcal{E} ((t_{\\text{y}}, z), x_{\\text{sy}}, x_{\\text{nn}}, W_{\\text{sy}}, W_{\\text{nn}}), \\end{aligned}\\]\n\\[\\begin{aligned} V_y(W_{\\text{sy}}, W_{\\text{nn}}, S_i) := & \\underset{\\hat{y} \\in \\mathcal{Y}}{\\text{min}} \\mathcal{E} (y, x_{\\text{sy}}, x_{\\text{nn}}, W_{\\text{sy}}, W_{\\text{nn}}), \\end{aligned}\\]\n\\[V_{\\text{conv}}(W_{\\text{sy}}, W_{\\text{nn}}, S_i; y, d) := \\underset{\\hat{y} \\in \\mathcal{Y}}{\\text{min}} \\mathcal{E} (y, x_{\\text{sy}}, x_{\\text{nn}}, W_{\\text{sy}}, W_{\\text{nn}}) + \\lambda d(\\hat{y},y).\\]\nAn illustration of an example latent optimal value-function is provided in Fig. 4. Intuitively, the latent optimal value-function is the greatest lower bound of the set of symbolic components defined for each latent variable.\nThe simplest value-based learning loss is the energy loss, denoted by \\(L_{\\text{Energy}}\\). The energy loss is the latent optimal value function,\n\\[L_{\\text{Energy}}(\\mathcal{E}(\\cdot,\\cdot, \\cdot, W_{\\text{sy}}, W_{\\text{nn}}), S_i) := V_z(W_{\\text{sy}}, W_{\\text{nn}}, S_i).\\]\nMinimizing the energy loss encourages the parameters of the energy function to produce low energies given the observed true values of the input and target variables. This loss is motivated by the intuition that the energy should be low for the desired values of the targets. Notice, however, that the loss does not consider the energy of incorrect target variable values."}, {"title": "6.2.3 MINIMIZER-BASED LEARNING LOSSES", "content": "A minimizer-based loss is a composition of a differentiable loss, such as cross-entropy or mean squared error, with the energy minimizer. Intuitively, minimizer-based losses penalize parameters yielding predictions distant from the labeled training data. In the remainder of this subsection, we formally define minimizer-based learning losses. Further, for completeness, we derive general expressions for gradients of minimizer-based losses with respect to symbolic and neural weights. However, as will be shown, direct computation of minimizer-based loss gradients requires prohibitive assumptions on the energy function and can be impractical to compute. Moreover, the derivation of the gradients motivates learning algorithms that do not perform direct gradient descent on minimizer-based losses. For this reason, in the following subsection we propose algorithms that do not require minimizer gradients.\nTo ensure a minimizer-based loss is well-defined, we assume a unique energy minimizer exists, denoted by \\(y^*\\), for every training sample. This assumption is formalized below.\nUnder Assumption 1, d is a mapping of targets and labels to a scalar value:\n\\[d : \\mathcal{V} \\times T \\rightarrow \\mathbb{R},\\]\nand a minimizer-based loss is a composition of d and \\(y^*\\):\n\\[L_{\\text{Min}}(\\mathcal{E}(\\cdot,\\cdot, \\cdot, W_{\\text{sy}}, W_{\\text{nn}}), S_i) := d(\\underset{\\hat{y} \\in \\mathcal{Y}}{\\text{arg min}} \\mathcal{E} (y, x_{\\text{sy}}^i, x_{\\text{nn}}^i, W_{\\text{sy}}, W_{\\text{nn}}), t_{\\text{y}}) := d(y^* (x_{\\text{sy}}^i, x_{\\text{nn}}^i, W_{\\text{sy}}, W_{\\text{nn}}), t_{\\text{y}}).\\]\nTo ensure principled gradient-based learning, we must further assume that the minimizer is differentiable.\n\\[\\nabla_{W_{\\text{sy}}} L_{\\text{Min}}(y^* (x_{\\text{sy}}^i, x_{\\text{nn}}^i, W_{\\text{sy}}, W_{\\text{nn}})), t_{\\text{y}}) = (\\nabla_{y^*} d(y^* (x_{\\text{sy}}^i, x_{\\text{nn}}^i, W_{\\text{sy}}, W_{\\text{nn}}), t_{\\text{y}}))^\\intercal \\nabla_{W_{\\text{sy}}} y^* (x_{\\text{sy}}^i, x_{\\text{nn}}^i, W_{\\text{sy}}, W_{\\text{nn}}),\\]\n\\[\\nabla_{W_{\\text{nn}}} L_{\\text{Min}}(y^* (x_{\\text{sy}}^i, x_{\\text{nn}}^i, W_{\\text{sy}}, W_{\\text{nn}})), t_{\\text{y}}) = (\\nabla_{y^*} d(y^* (x_{\\text{sy}}^i, x_{\\text{nn}}^i, W_{\\text{sy}}, W_{\\text{nn}}), t_{\\text{y}}))^\\intercal \\nabla_{W_{\\text{nn}}} y^* (x_{\\text{sy}}^i, x_{\\text{nn}}^i, W_{\\text{sy}}, W_{\\text{nn}}),\\]"}, {"title": "6.3 Learning Algorithms", "content": "Next, we present four principled techniques for learning the neural and symbolic weights of a NeSy-EBM to minimize the losses introduced in the previous subsection: 1) Modular, 2) Gradient Descent, 3) Bilevel Value-Function Optimization, and 4) Stochastic Policy Optimization. The four techniques are defined, and we discuss their strengths and limitations in relation to the motivating applications in Section 2 and modeling paradigms in Section 5."}, {"title": "6.3.1 MODULAR LEARNING", "content": "The first and most straightforward NeSy-EBM learning technique is to train and connect the neural and symbolic components as independent modules. For instance, the neural component can be trained via backpropagation and Adam to optimize a neural loss given neural labels. Then, the symbolic component can be trained using an appropriate method to optimize a value or minimizer-based loss. The neural component weights are frozen during the symbolic weight learning process.\nBy definition, modular learning algorithms are not trained end-to-end, i.e., the neural and symbolic parameters are not jointly optimized to minimize the learning loss. For this reason, modular approaches may struggle to find a weight setting with a learning loss as low as end-to-end techniques. Moreover, modular approaches are not suitable for fine-tuning and adaptation. Additionally, they require labels to train the neural component. Thus, modular learning is not used to learn neural parameters in unsupervised or semi-supervised settings.\nNevertheless, modular learning approaches are appealing and widely used for their simplicity and general applicability. Importantly, no assumptions are made about the neural-symbolic interface; hence, modular learning is effective for every modeling paradigm presented in Section 5. Notably, minimizers and value-functions of DSPot models are typically non-differentiable with respect to the neural weights due to the complex neural-symbolic interface. However, because modular techniques are not end-to-end, this is not an issue. Moreover, modular learning can be used to train a NeSy-EBM for constraint satisfaction and joint reasoning, zero-shot reasoning, and reasoning with noisy data. There are many established and effective modular neural and symbolic learning algorithms (see Srinivasan et al. (2021) for a recent taxonomy of symbolic weight learning algorithms)."}, {"title": "6.3.2 GRADIENT DESCENT", "content": "A conceptually simple but oftentimes difficult in-practice technique for end-to-end NeSy-EBM training is direct gradient descent. Specifically, the gradients derived in the previous subsection are directly used with a gradient-based algorithm to optimize a NeSy-EBM loss with respect to both the neural and symbolic weights. Backpropagation and Theorem 6 produce relatively inexpensive gradients for neural and value-based losses for a general class of NeSy-EBMs. Moreover, for a smaller family of NeSy-EBMs, gradients of energy minimizers exist and may be cheap to compute. For instance, if the energy minimizer is determined via a simple closed-form expression (e.g., if inference is an unconstrained strongly convex quadratic program or a finite computation graph).\nAs shown in Section 6.2, learning loss gradients for fully expressive NeSy-EBMs only exist under certain conditions. Further, computing the gradients generally requires expensive second-order information about the energy function at the minimizer. For this reason, direct gradient descent only applies to a relatively small class of NeSy-EBMs with specialized architectures that ensure principled and efficient gradient computation. Such specialized architectures are less likely to support more complex modeling paradigms such as DSPar and DSPot. However, provided a NeSy-EBM with such an architecture, gradient descent techniques can be used in all motivating applications cited in Section 2."}, {"title": "6.3.3 BILEVEL VALUE-FUNCTION OPTIMIZATION", "content": "As shown in the earlier subsection, minimizer gradients are relatively more computationally expensive to compute and require more assumptions than value-function gradients. In this subsection, we devise a technique for optimizing a minimizer-based loss with only first-order gradients. This technique is built on the fact that the general definition of NeSy-EBM learning (18) is naturally formulated as bilevel optimization. In other words, the NeSy learning objective is a function of variable values obtained by solving a lower-level inference problem that is symbolic reasoning:\nIrrespective of the continuity and curvature properties of the upper and lower level objectives,\n(40) is equivalent to the following:\nThe formulation in (41) is referred to as a value-function approach in bilevel optimization literature (V. Outrata, 1990; Liu et al., 2021, 2022; Sow et al., 2022; Kwon et al., 2023). Value-function approaches view the bilevel program as a single-level constrained optimization problem by leveraging the value-function as a tight lower bound on the lower-level objective.\nThe inequality constraints in (41) do not satisfy any of the standard constraint qual- ifications that ensure the feasible set near the optimal point is similar to its linearized approximation (Nocedal and Wright, 2006). This raises a challenge for providing theoretical convergence guarantees for constrained optimization techniques. Following a recent line of value-function approaches to bilevel programming (Liu et al., 2021; Sow et al., 2022; Liu et al., 2023), we overcome this challenge by allowing at most an \u03b9 > 0 violation in each constraint in (41). With this relaxation, strictly feasible points exist and, for instance, the linear independence constraint qualification (LICQ) can hold.\nAnother challenge that arises from (41) is that the energy function of NeSy-EBMs is typically non-differentiable with respect to the targets and even infinite-valued to represent constraints implicitly. As a result, penalty or augmented Lagrangian functions derived from (41) are intractable. Therefore, we substitute each instance of the energy function evaluated"}, {"title": "6.3.4 STOCHASTIC POLICY OPTIMIZATION", "content": "Finally, another approach to NeSy-EBM learning that avoids directly computing the energy minimizer's gradients with respect to the weights is to re-formulate NeSy learning as stochastic policy optimization. Fig. 5 shows the modifications to the standard NeSy-EBM framework to create a stochastic NeSy-EBM. The symbolic and neural weights are used to condition a symbolic weight and neural policy, denoted by \\(\\pi_{\\text{sy}}\\) and \\(\\pi_{\\text{nn}}\\), respectively. Samples from the policies replace the symbolic weights and neural output as arguments of the symbolic component. Specifically, given symbolic and neural weights \\(w_{\\text{sy}}\\) and \\(w_{\\text{nn}}\\) and input features \\(x_{\\text{nn}}\\) from a training sample \\(S_i \\in \\mathcal{S}\\), \\(h_{\\text{sy}}\\) and \\(h_{\\text{nn}}\\) are random variables with the following conditional distributions:\n\\[h_{\\text{sy}} \\sim \\pi_{\\text{sy}}(h_{\\text{sy}} | W_{\\text{sy}}),\\]\n\\[h_{\\text{nn}} \\sim \\pi_{\\text{nn}}(h_{\\text{nn}} | g_{\\text{nn}}(x_{\\text{nn}}, W_{\\text{nn}})).\\]"}, {"title": "7 Neural Probabilistic Soft Logic and Deep Hinge-Loss Markov Random Fields", "content": "Sections 4-6 covered a general mathematical framework, modeling paradigms, and learning algorithms for NeSy EBMs. Here, we introduce Neural Probabilistic Soft Logic (NeuPSL), an expressive framework for constructing a broad class of NeSy-EBMs by extending the probabilistic soft logic (PSL) probabilistic programming language (Bach et al., 2017). NeuPSL is designed to be expressive and efficient to support every modeling paradigm and easily be used for a range of applications. We begin by presenting the essential syntax and semantics of NeuPSL, encompassing Deep Hinge-Loss Markov Random Fields, the underlying distribution (see Bach et al. (2017) for an in-depth introduction to PSL syntax and semantics). Then, we present a new formulation and regularization of (Neu)PSL inference as a constrained quadratic program. Our formulation is utilized to guarantee differentiability properties and provide principled gradients to support end-to-end neural and symbolic parameter learning, instantiating the learning algorithms introduced in Section 6.3."}, {"title": "7.1 Neural Probabilistic Soft Logic", "content": "NeuPSL is a declarative language used to construct NeSy-EBMs. Intuitively, NeuPSL provides a syntax for encoding dependencies between relations and attributes of entities and for integrating neural components in a symbolic model. Specifically, dependencies and neural component compositions are expressed as first-order logical or arithmetic statements referred to as rules. Each rule is a template for instantiating, i.e., grounding, potentials or constraints to define the NeuPSL energy function. Every rule is grounded over a set of domains, D = {D1, D2,\u2026 }, where each of the domains D\u00bf is a finite set of elements referred to as constants. For instance, referring to the visual Sudoku problem described in Example 2, the constant \"A1\" can denote the cell at position Al in a Sudoku puzzle and the constant \"1\" can denote the digit 1. Constants are grouped and aligned with a corresponding domain from D using placeholders or variables. Relations between constants are predicates. In NeuPSL, a predicate is referenced using its unique identifier. For instance, CELLDIGIT is a predicate that can represent whether a cell contains a specified digit. Another example is the predicate SUDOKUVIOLATION representing whether a Sudoku rule is violated given the digits in two specified cells. Finally, the predicate NEURALCLASSIFIER is a predicate that represents the predicted digit in a cell made by a neural network classifier. Predicates with specified constant domains are atoms. NeuPSL extends PSL with deep atoms: atoms backed by a deep model."}, {"title": "7.2 Deep-Hinge Loss Markov Random Fields", "content": "The rule instantiation process described in the previous subsection results in a set of ground atoms. Each ground atom is mapped to either an observed variable, \\(x_{\\text{sy},i}\\), target variable, \\(y_i\\), or a neural function with inputs \\(x_{\\text{nn}}\\) and parameters \\(w_{\\text{nn},i}\\): \\(g_{\\text{nn},i}(x_{\\text{nn}}, w_{\\text{nn},i})\\). Specifically, all atoms instantiated from a deep atom are mapped to a neural function, and the observed and target atom partitions are pre-specified. Further, variables are aggregated into the vectors \\(x_{\\text{sy}} = [x_{\\text{sy},i}]_{i=1}^{N_x}\\) and \\(y = [y_i]_{i=1}^{N_y}\\) and neural outputs are aggregated into the vector \\(g_{\\text{nn}} = [g_{\\text{nn},i}]_{i=1}^{N_y}\\).\nThe ground rules and variables are used to define linear inequalities in a standard form: \\(l(y, x_{\\text{sy}}, g_{\\text{nn}}(x_{\\text{nn}}, W_{\\text{nn}})) \\leq 0\\), where \\(l\\) is a linear function of its arguments. To achieve this, logical rules are first converted into disjunctive normal form. Then, the rules are translated into linear inequalities using an extended interpretation of the logical operators, namely \u0141ukasiewicz logic (Klir and Yuan, 1995). Similarly, arithmetic rules define one or more standard form inequalities that preserve the rules' dependencies via algebraic operations.\nFurther, linear inequalities instantiated from soft ground rules define potential functions of the form:\n\\[\\phi(y, x_{\\text{sy}}, g_{\\text{nn}}(x_{\\text{nn}}, W_{\\text{nn}})) := (\\max\\{l(y, x_{\\text{sy}}, g_{\\text{nn}}(x_{\\text{nn}}, W_{\\text{nn}})), 0\\})^q.\\]\nIntuitively, the value of potential is the, possibly squared, level of dissatisfaction of the linear inequality created by the ground rule. Further, each potential is associated with the weight of its instantiating rule. Weight sharing among the potentials is formalized by defining a partitioning using the instantiating rules, i.e., every potential instantiated by the same rule belongs to the same partition and shares a weight. The potentials and weights from the instantiation process are used to define a tractable class of graphical models, which we refer to as deep hinge-loss Markov random fields (Deep HL-MRF):"}, {"title": "7.3 A Smooth Formulation of Deep HL-MRF Inference", "content": "This subsection introduces a primal and dual formulation of Deep HL-MRF MAP inference as a linearly constrained convex quadratic program (LCQP) (see Appendix B for details). The primal and dual LCQP formulation has theoretical and practical advantages. Theoretically, the new formulation will be utilized to prove continuity and curvature properties of the Deep HL-MRF energy minimizer and value-function. Practically, LCQP solvers (e.g. Gurobi (Gurobi Optimization, 2024)) can be employed to achieve highly efficient MAP inference. Moreover, features of modern solvers, including support for integer constraints, can be leveraged to improve prediction.\nIn summary, m slack variables with lower bounds and 2\u22c5ny+m linear constraints are defined to represent the target variable bounds and deep hinge-loss potentials. All 2\u22c5ny+m variable bounds, m potentials, and q \u2265 0 constraints are collected into a (2\u22c5ny+q+2\u22c5m)\u00d7(ny+m) dimensional matrix A and a vector of (2\u22c5ny+q+2\u22c5m) elements that is an affine function of the neural predictions and symbolic inputs b(xsy,gnn(Xnn,Wnn)). Moreover, the slack variables and a (ny + m) \u00d7 (ny + m) positive semi-definite diagonal matrix, D(wsy), and a (ny + m) dimensional vector, c(wsy), are created using the symbolic weights to define a quadratic objective. Further, we gather the original target variables and the slack variables into a vector v\u2208 Rny+m. Altogether, the regularized convex LCQP reformulation of Deep HL-MRF MAP inference is:\n\\[V(w_{\\text{sy}}, b(x_{\\text{sy}}, g_{\\text{nn}}(x_{\\text{nn}}, W_{\\text{nn}}))) := \\underset{v \\in \\mathcal{R}^{n_y+m}}{\\text{min}} \\frac{1}{2} v^T (D(W_{\\text{sy}}) + \\epsilon I)v + c(W_{\\text{sy}})v \\text{ s.t. } Av + b(x_{\\text{sy}}, g_{\\text{nn}}(x_{\\text{nn}}, W_{\\text{nn}})) \\leq 0,\\]"}, {"title": "8 Empirical Analysis", "content": "In this section, we perform an empirical analysis of the NeSy-EBM modeling paradigms and learning algorithms presented in this work using the NeuPSL system introduced in Section 7. Our experiments are designed to investigate the four following research questions:\nOur empirical analysis is organized into four subsections. First, in Section 8.1, we introduce the neural-symbolic datasets and models used in the experiments. In Section 8.2, we study the application of NeSy-EBMs for constraint satisfaction and joint reasoning. In Section 8.3, we evaluate the performance of modular learning and the performance and empirical convergence properties of the value-based, bilevel, and stochastic policy optimization learning algorithms presented in Section 6.3 for fine-tuning and few-shot learning. Finally, in Section 8.4, we analyze the effectiveness of the NeSy-EBM framework for training a neural component in a semi-supervised setting. All code and data for reproducing our empirical analysis are available at https://github.com/linqs/dickens-arxiv24."}, {"title": "8.1 Datasets and Models", "content": "This subsection introduces the NeSy datasets and models, which will be utilized through- out the empirical analysis. Moreover, any modifications made to answer specific re- search questions will be described in the following subsections. Additional details on the architectures of both the neural and symbolic components are available at https: //github.com/linqs/dickens-arxiv24."}, {"title": "9 Limitations", "content": "In this section, we discuss the limitations of the NeSy-EBM framework, NeuPSL, and our empirical analysis. The NeSy-EBM framework is a high-level and general paradigm for NeSy. The value of the framework is that it provides a unifying theory for NeSy and a foundation"}, {"title": "10 Conclusion and Future Work", "content": "This paper establishes a mathematical framework for neural-symbolic (NeSy) reasoning with Neural-Symbolic Energy-Based Models (NeSy-EBMs). The NeSy-EBM framework is a unifying foundation and a bridge for adapting techniques from the broader machine learning literature to solve challenges in NeSy. Additionally, we introduce Neural Probabilistic Soft Logic (NeuPSL), an open-source and highly expressive implementation of NeSy-EBMs. NeuPSL supports the primary modeling paradigms and continuity properties required for efficient end-to-end neural and symbolic parameter learning.\nWe show that NeSy-EBMs provide a unifying view of NeSy by building a taxonomy of fundamental modeling paradigms. Our modeling paradigms organize the strengths and limitations of NeSy systems and clarify architecture requirements for applications. NeSy-EBMs and the paradigms are valuable mechanisms for practitioners and researchers to understand the growing NeSy literature and design effective systems. Further, NeSy- EBMs illuminate connections between NeSy and the broader machine learning community. Specifically, we formalize a general NeSy learning loss and the necessary assumptions for supporting direct gradient descent on the loss. Moreover, we leverage methods from reinforcement learning and bilevel optimization literature to work around the assumptions and design more practical and general algorithms.\nThe insights we gained from creating the mathematical framework, the taxonomy of modeling paradigms, and the suite of learning techniques shaped the development of the NeuPSL NeSy modeling library. NeuPSL is built to support every modeling paradigm and learning technique we cover. We demonstrate the effectiveness of NeuPSL in our empirical analysis. Specifically, we explore four practical use cases of NeSy that are identified through a literature review. We show compelling results in real-world applications and see NeSy-EBMs enhance neural network predictions, enforce constraints, improve label and data efficiency, and empower LLMs with consistent reasoning.\nLooking ahead, several promising avenues for future research have emerged. For instance, a more extensive exploration into techniques for leveraging symbolic knowledge to fine- tune and adapt foundation models is a promising direction. The NeSy-EBM framework and our proposed learning techniques are a solid basis for building pipelines to fine-tune foundation models. Moreover, stochastic policy optimization for end-to-end NeSy learning has great potential due to its general applicability to every modeling paradigm and most NeSy-EBMs. Finally, contributing to the active area of research on overcoming the challenge of high-variance gradient estimates would be highly beneficial for improving NeSy learning."}, {"title": "B.1 Extended Smooth Formulation of Inference", "content": "Recall the primal formulation of NeuPSL inference restated below:\n\\[\\underset{y}{\\text{arg min}} \\,\\, W_{\\text{sy}} \\Phi(y, x_{\\text{sy}}, g_{\\text{nn}}(x_{\\text{nn}}, W_{\\text{nn}})) \\text{ s.t. } y \\in \\Omega(x_{\\text{sy}}, g_{\\text{nn}}(x_{\\text{nn}}, W_{\\text{nn}})).\\]\nImportantly, note the structure of the deep hinge-loss potentials defining \\(\\Phi\\):\n\\[\\Phi_k(y, x_{\\text{sy}}, g_{\\text{nn}}(x_{\\text{nn}}, W_{\\text{nn}})) := (\\text{max}\\{a_{\\phi_k,y}^T y + a_{\\phi_k,x_{\\text{sy}}}^T x_{\\text{sy}} + a_{\\phi_k,g_{\\text{nn}}}^T g_{\\text{nn}}(x_{\\text{nn}}, W_{\\text{nn}}) + b_{\\phi_k}, 0\\})^p_k.\\]"}]}