{"title": "Large Language Model Driven Agents for Simulating Echo Chamber Formation", "authors": ["Chenhao Gu", "Ling Luo", "Zainab Razia Zaidi", "Shanika Karunasekera"], "abstract": "The rise of echo chambers on social media platforms has heightened concerns about polarization and the reinforcement of exist- ing beliefs. Traditional approaches for simulating echo chamber forma- tion have often relied on predefined rules and numerical simulations, which, while insightful, may lack the nuance needed to capture complex, real-world interactions. In this paper, we present a novel framework that leverages large language models (LLMs) as generative agents to simulate echo chamber dynamics within social networks. The novelty of our ap- proach is that it incorporates both opinion updates and network rewiring behaviors driven by LLMs, allowing for a context-aware and semantically rich simulation of social interactions. Additionally, we utilize real-world Twitter (now X) data to benchmark the LLM-based simulation against actual social media behaviors, providing insights into the accuracy and realism of the generated opinion trends. Our results demonstrate the efficacy of LLMs in modeling echo chamber formation, capturing both structural and semantic dimensions of opinion clustering.", "sections": [{"title": "1 Introduction", "content": "In recent years, the rise of echo chambers on social media platforms has be- come a significant concern, particularly due to their impact on polarization, misinformation, and the reinforcement of existing beliefs. Echo chambers, where individuals are exposed predominantly to information that confirms their pre- existing opinions, can lead to social fragmentation and hinder healthy public discourse [2]. Understanding and simulating the dynamics of echo chambers is crucial for advancing our knowledge of how opinions evolve and cluster within online communities. Traditional models for studying echo chamber formation have largely relied on pure numerical simulations, using predefined behavioral rules to predict the evolution and clustering of opinions [1]. While these models have contributed valuable insights, they often fall short of capturing the rich, complex interactions that occur in real-world social networks.\nThe rapid advancements in Large Language Models (LLMs) offer a new av- enue for exploring these complex dynamics. LLMs, with their deep understanding of language and context, provide the potential to simulate not only the structure of social interactions but also the nuanced content and sentiment that drive echo"}, {"title": "2 Related Work", "content": "Echo Chambers Modeling. The study of opinion dynamics and echo cham- bers in social networks has a rich history, with foundational models such as the Friedkin-Johnson Dynamics Model [6], which simulates opinion evolution based on intrinsic beliefs and social influence, and the Bounded Confidence Model by Deffuant et al. [4], which restricts interactions to individuals within a confidence range. More recent works, such as Sasahara et al. [13], emphasize the dynamic in- terplay of opinion polarization and structural adjustments, such as unfollowing, and demonstrate how these behaviors accelerate the formation of echo chambers. Our work builds on these models by incorporating LLMs to simulate user behav- ior and opinion dynamics, leveraging advanced natural language understanding to provide deeper insights into the formation and evolution of echo chambers.\nLLM-Driven Social Simulation. Leveraging LLMs for social simulation has emerged as a novel research direction, enabling both downstream task fa- cilitation and a deeper understanding of LLM capabilities. Early work, such as Generative Agents [10], explored LLM-empowered agents that simulate human behavior in interactive environments. This idea was extended to social networks with systems like S3 [7], which simulate emotions, attitudes, and interactions to study population-level phenomena like information and emotion propagation. Furthermore, there have been attempts to use LLMs for simulating echo cham- bers [14], which differ from our approach in two key aspects: we argue that echo chambers partially stem from changes in network structures, and we emphasize that simulating echo chambers does not imply that more polarization is always better. Instead, we advocate for validating the performance of LLM-based sim- ulations through comparisons with real-world data."}, {"title": "3 Problem Statement and Definitions", "content": "This study aims to simulate the formation of echo chamber by capturing the evolution of user opinions and the structural changes in social networks.\n3.1 Opinion Evolution\nEach user i holds an opinion $O_i(t)$ at time t, influenced by their neighbor set $N_i(t)$, representing their current social connections. The opinion update rule is inspired by the classical DeGroot model [5], where opinions evolve as a weighted average of neighboring opinions. The general update rule is:\n$O_i(t+1) = O_i (t) + \\frac{1}{|N_i(t)|}\\sum_{j\\in N_i(t)} f(O_j(t), O_i(t)),$\nwhere $f(O_j, O_i(t))$ quantifies the impact of neighbor j's opinion $O_j$ on user i. In the simplest form, $f(O_j, O_i(t)) = w_{ij}(O_j \u2013 O_i(t))$, where $w_{ij}$ is the weight of influence assigned to neighbor j.\n3.2 Network Rewiring\nUsers dynamically adjust their connections over time based on opinion compat- ibility and recommendations, reflecting real-world follow/unfollow behaviors.\nThe probability of severing a connection (unfollow) or forming a new con- nection (follow) is determined by the compatibility function g, defined as:\n$P_{unfollow}(i, j) \\propto 1 \u2013 g(O_i, O_j), P_{follow}(i, k) \\propto g(O_i, O_k)$,\nwhere $0 \\leq g(O_i,O_j) \\leq 1$ quantifies the similarity between user i's and j's opinions. The neighbor set $N_i(t)$, representing user i's incoming connections in the directed graph, evolves as these follow/unfollow actions modify the graph.\n3.3 LLM-enhanced Approach\nIn the LLM-enhanced framework, the influence function $f(O_j, O_i(t))$ and the compatibility function $g(O_i, O_j)$ are defined through prompt-driven models, in- corporating textual context into the simulation. Specifically, the functions are reformulated as:\n$f (O_j, O_i(t)) = LLM(T_o(C_i, C_j)), g(O_i, O_j) = LLM(T_r(C_i, C'_j)),$\nwhere $T_o$ (Prompt template for opinion dynamic) and $T_r$ (Prompt template for rewiring compatibility) serve as input structures to instruct the LLM on specific tasks. The input $C_i$ represents the historical content of user i, while $C_j$ represents the historical content of user j. Here, \"historical content\" typically refers to a subset of the user's recent posts, such as their 10 most recent posts.\nAdditionally, the LLM generates a new post $y_i(t)$ for user i, reflecting their opinion and the surrounding context. This process is defined as:\n$y_i(t) \\sim LLM(T_g(C_i, \\{C_j | j \\in N_i(t)\\}))$,\nwhere $T_g$ (template for content generation) combines $C_i$ with the contexts $\\{C_j\\}$ from neighbors in $N_i(t)$ to produce context-aware content. These template struc- tures ensure that the LLM can dynamically adapt to the textual and contextual information, unifying opinion dynamics, rewiring decisions, and content genera- tion into a cohesive framework."}, {"title": "4 Model Framework", "content": "The objective of this study is to develop a simulation framework that models echo chamber dynamics with theoretical and practical alignment to real-world social network behaviors, including opinion distribution and network structure dynamics. The framework captures the interactions and structural changes in social networks, encompassing opinion evolution, network rewiring, and content generation, as outlined in Figure 1.\n4.1 Data Preparation\nThe framework primarily uses Twitter data due to its rich interaction patterns, though it supports datasets from other platforms as well. Key inputs include user interactions, posts, and follow relationships, which are used to construct an active user network.\nTo enhance efficiency and relevance, the framework prioritizes highly active users, motivated by two key considerations: (1) the computational infeasibility of simulating the entire network due to the substantial resources required, and (2) the limited interactions of infrequent users, which are insufficient for meaningful simulation and may introduce noise into the analysis. By prioritizing active users, the simulation captures meaningful network dynamics.\nThe constructed network comprises nodes (users) with distinct opinions and edges (social connections) based on social interactions, such as retweets on Twit- ter. This network evolves over time to reflect the dynamic of social interactions.\n4.2 Simulation Process\nThe simulation captures the dynamic user opinions and network connections in social networks. At each iteration, a randomly selected user refreshes their feed, viewing a limited subset of prioritized posts from connected \"friends\" or recommended content. This process, referred to as the screen, represents the information accessible to users via social media and simulates their finite cogni- tive capacity in real-world interactions."}, {"title": "4.3 Analysis and Validation", "content": "Based on the screen and the user's historical activity, the LLM generates a new post that reflects the user's updated opinion. Subsequently, the user evalu- ates their network connections, probabilistically disconnecting from those with conflicting opinions and forming new connections with like-minded individuals. This adaptive process, as outlined in Section 3.3, is driven by the LLM and mirrors real-world social interactions where network structures evolve based on opinion alignment.\nOver time, the network exhibits clustering of users with similar opinions, while those with conflicting opinions become isolated. The simulation concludes when the network reaches a stable state, characterized by stabilized opinions and connections, or after a predefined number of iterations. The simulation Process component of Figure 1 illustrates how historical data and network information contribute to opinion updates and connection adjustments.\nThe final component of the framework focuses on validation and analysis to ensure the simulation's relevance and reliability. This process involves a quali- tative comparison between the simulated network and real-world social network data across various metrics. The goal is to evaluate how well the LLM-driven simulation aligns with real-world social network phenomena, identifying both consistencies and discrepancies.\nThis approach is conceptually similar to a digital twin, where the simulation serves as a virtual counterpart to the initial real-world social network. By ana- lyzing how the simulated network evolves under LLM influence, researchers can gain insights into behavioral dynamics, such as opinion formation, clustering, and network rewiring, and compare them with real-world trends."}, {"title": "5 Prompt Templates", "content": "To ensure reproducibility and enable systematic exploration of different prompt designs, the framework employs standardized prompting mechanisms. These prompts guide the LLM to model user behaviors effectively while maintaining consistency across tasks. The prompt design adheres to two key principles: Standardization. Prompts follow a consistent format with explicitly defined tasks and output specifications. This ensures clarity and reproducibility across sim- ulations. Chain-of-Thought Reasoning [15]. Prompts encourage step-by-step reasoning to enhance the interpretability and reliability of the generated outputs.\nAn example prompt template for generating a new post based on a user's his- tory and surrounding tweets is shown in Figure 2. This template can be adapted for other tasks, such as opinion updates or network rewiring, by modifying the task-specific instructions and input contexts. The consistent use of structured prompts facilitates future exploration of prompt designs and their effects on simulation outcomes."}, {"title": "6 Experiments", "content": "6.1 Stand Alone Simulation\nIn this section, we present a pure simulation experiment using ChatGPT and Gemini to explore the formation of echo chambers. This feasibility test aims to demonstrate how LLMs simulate the evolution and divergence of opinions, ultimately leading to distinct clusters of like-minded users.\n6.2 Real data-driven simulation\nIn this section, we outline the experimental setup designed to evaluate our pro- posed framework for modeling echo chamber formation using real-world data. We provide a detailed description of the datasets, simulation parameters and evaluation metrics employed to analyze opinion dynamics and echo chamber formation across different contexts.\nThe experiments are conducted on two datasets:\n1. COVID-19 Vaccination Dataset: This dataset was collected from global English-language tweets using COVID-19-related keywords. Details about the keywords and the collection process can be found in [8,16]. The dataset includes tweets with stances categorized as favoring vaccination (pro-vax), opposing vaccination (anti-vax), or neutral, focusing on the topic of vaccine hesitancy [16].\n2. Ukraine War Dataset: Introduced in [11], this dataset includes 1 million English-language tweets collected using a keyword search between August 1 and August 31, 2022. Each tweet's stance was labeled as pro-Russian, pro-Ukrainian, or neutral, providing a rich resource for studying polarized discourse.\nModel Selection and Experimental Setup To evaluate the simulation of opinion dynamics, we utilized six generative models and one traditional numer- ical simulation, facilitating a comparison between LLM-driven and rule-based approaches.\nThe LLM-based models included both closed-source and open-source options, offering diverse capabilities. Closed-source models include ChatGPT (OpenAI), GPT40 Mini (OpenAI), and Gemini (DeepMind), while open-source mod- els include Gemma (DeepMind) Gemma2-27b version, Meta-Llama (Meta)"}, {"title": "7 Experimental Result Analysis", "content": "7.1 Network Metrics\nTable 1 compares network metrics for different LLMs and traditional methods on the COVID-19 and Ukraine War datasets. We evaluate the models' ability to replicate key structural properties related to echo chamber formation us- ing modularity, clustering coefficient, average path length, and network density.\nThe COVID-19 dataset reflects entrenched polarization, while the Ukraine War dataset shows less division due to a dominant pro-Ukraine community. It is im- portant to note that in these simulations, a stronger echo chamber effect is not always desirable. Our aim is for the simulated results to closely match the pat- terns observed in real data. For instance, some models may exhibit very high modularity, which could be an extreme outcome and not necessarily beneficial, depending on the purpose of the simulation.\nFor the COVID-19 dataset, real-world data shows high modularity (0.7125) and clustering structure, indicative of echo chambers in vaccine discourse. In LLM simulations, certain models like Meta-Llama (0.7257) and Gemma (0.7299) further amplify modularity, suggesting exaggerated division, while ChatGPT (0.6855) exhibits weaker polarization, reflecting a less distinct community struc- ture compared to real-world data. Clustering coefficients increase in LLM simula- tions, highlighting strong local cohesion, but average path lengths decrease (e.g.,"}, {"title": "7.2 Track Stance Dynamics", "content": "ChatGPT: 4.8250 vs. real data: 5.1384), suggesting faster information spread. Network density uniformly decreases across different models, reflecting sparser connections in simulations.\nIn the Ukraine War dataset, real-world data shows lower modularity (0.3706) due to a dominant pro-Ukraine community. LLM-based models, such as Gemini (0.3837) and Meta-Llama (0.3792), enhance modularity and clustering, creating more distinct communities. However, traditional methods like Equation (0.4137) tend to overemphasize the formation of echo chambers, resulting in more polar- ized communities that deviate significantly from the lower modularity observed in real-world data. Average path lengths decrease across models (e.g., Gemini: 2.8269 vs. real data: 2.9399), indicating efficient information diffusion. Network density remains consistent (0.0026), preserving overall connectivity.\nDiscussion The findings highlight the clear advantages of LLM-based sim- ulations over traditional methods like Equation-based simulation in modeling complex social networks. LLMs demonstrate superior adaptability, effectively capturing the distinct structural properties of datasets with varying initial con- ditions. For the COVID-19 dataset, they replicate the entrenched modularity and clustering of real-world networks, while for the Ukraine War dataset, they enhance community distinction and local connectivity, even when starting from a less structured network.\nOne of the key takeaways is the ability of LLMs to balance modularity and clustering. While higher modularity indicates more distinct community forma- tion, excessively high values, such as those produced by Meta-Llama and Gemini, may reflect overfitting to echo chamber dynamics. Conversely, models like Chat- GPT offer a more balanced approach, aligning more closely with real-world data\nIn this section, we evaluate the LLM simulators' performance in tracking the stance dynamics in real-world data. By using real data as a benchmark, we can compare the accuracy of different simulation models in replicating observed opinion trends."}, {"title": "7.3 Language Distribution Analysis", "content": "while maintaining meaningful structural insights. This balance is critical for sim- ulations that aim to realistically represent social network dynamics rather than amplify existing biases.\nThe consistent underperformance of Equation underscores the limitations of traditional methods in capturing the complexity of real-world social networks. The method's inability to achieve realistic clustering and modularity, particularly for the Ukraine War dataset, suggests that it lacks the nuanced understanding required to model evolving network structures. In contrast, LLMs leverage their advanced language understanding and contextual capabilities to simulate both entrenched and emergent echo chambers effectively.\nUsing LLMs to generate natural language tweets represents a significant advan- tage in LLM-based simulations, marking a breakthrough compared to previous simulations that lacked this generative capability. To evaluate the quality of the generated language, we compared simulated and real-world tweets by trans- forming both datasets into embeddings using the sentence transformer model [12] and performing clustering to analyze language distribution and structural differences."}, {"title": "8 Conclusion", "content": "Figure 5 presents the clustering results for real-world and simulated tweet embeddings. Simulated tweets demonstrate more concentrated semantics, form- ing tighter clusters with a silhouette score of 0.0966 compared to 0.0485 for real-world tweets and an average intra-cluster distance of 0.5321 versus 0.7456. While this indicates that simulations capture cohesive trends, they also reveal less linguistic diversity and dispersion than real-world tweets, as shown by the smaller average inter-cluster distance (0.4354 vs. 0.3712). This suggests that although simulated tweets exhibit certain clustering structures, they lack the broader variability and richness found in real-world data.\nIn this study, we explored the use of LLMs as generative agents for simulating echo chamber formation in social networks. Leveraging the interpretive power of LLMs, our framework not only captures complex social dynamics, opinion interactions, and realistic user-generated content but also tracks the evolving structure of network changes, offering a significant improvement over traditional numerical simulations. Experiments demonstrated that LLMs provide a closer approximation of real-world echo chambers, effectively simulating nuanced opin- ion updates, rewiring decisions, and stance predictions. By using real-world data as a validation benchmark, our model ensures greater alignment with actual so- cial media dynamics and highlights its robustness in replicating real-world pat- terns. In future work, we can incorporate diverse training data or refined prompt"}]}