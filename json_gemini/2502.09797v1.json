{"title": "A Survey on LLM-based News Recommender Systems", "authors": ["Rongyao Wang", "Veronica Liesaputra", "Zhiyi Huang"], "abstract": "News recommender systems play a critical role in mitigating the information overload problem. In recent years, due to the successful applications of large language model technologies, researchers have utilized Discriminative Large Language Models (DLLMs) or Generative Large Language Models (GLLMs) to improve the performance of news recommender systems. Although several recent surveys review significant challenges for deep learning-based news recommender systems, such as fairness, privacy-preserving, and responsibility, there is a lack of a systematic survey on Large Language Model (LLM)-based news recommender systems. In order to review different core methodologies and explore potential issues systematically, we categorize DLLM-based and GLLM-based news recommender systems under the umbrella of LLM-based news recommender systems. In this survey, we first overview the development of deep learning-based news recommender systems. Then, we review LLM-based news recommender systems based on three aspects: news-oriented modeling, user-oriented modeling, and prediction-oriented modeling. Next, we examine the challenges from various perspectives, including datasets, benchmarking tools, and methodologies. Furthermore, we conduct extensive experiments to analyze how large language model technologies affect the performance of different news recommender systems. Finally, we comprehensively explore the future directions for LLM-based news recommendations in the era of LLMs.", "sections": [{"title": "I. INTRODUCTION", "content": "A Large amount of news is generated in the era of Internet. It is difficult for users to find news that they are interested in from online news applications such as Google News, Bing News, and Toutiao. In these applications, news recommender systems are employed to help users alleviate this information overload as well as to improve users' reading experience [1], [2]. In recent years, increasing attention to news recommendation has led to a growing number of publications on news recommender systems as shown in Figure 1. With the growth of deep-learning techniques in Natural Language Processing (NLP), various deep-learning methods are utilized in the news recommender systems [3] and achieve state-of-the-art performances.\nMost news recommender systems are built on deep neural network frameworks, such as Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs), and Graph Neural Networks (GNNs), due to their superior abilities at representing and learning textual information. CNNs are leveraged to extract textual local features from news contents [4]\u2013[6], such as fine-grained news features, and knowledge-based news features. RNNs are utilized to capture users' diverse preferences based on their behavior sequences [7], [8], for example, long- and short-term user interest and multiple user interest. Furthermore, GNNs are commonly employed to model structural news-user representations [9]\u2013[12] such as structural intent-aware user representation. Although these neural networks can improve the performance of the news recommender systems, many researchers have found that these general deep-learning methods tend to reach their limitations at learning more complex information [13]\u2013[16] such as deep news-user relationship and multi-modal representation.\nWith the advancement of Transformers [17]\u2013[19] in NLP, researchers utilize DLLMs such as BERT [17], ROBERTa [20] and BART [21] as news encoders to capture the potential semantic information in news content [15], [22]\u2013[24], or apply DLLMs' special training strategy to model news-user semantic relationship in news recommender systems [25]\u2013[27]. These DLLM-based methods achieve better performance than general neural networks (e.g., CNNs, RNNs, GNNs). However, DLLM-based news recommender systems are constrained by their limited pre-trained knowledge, which makes it challenging to leverage them effectively for addressing cold-start problem and modeling accurate news and users' representations [17], [20], [26].\nRecent GLLMs (e.g., GPT-4, LLaMA, PaLM ) have a substantially larger number of parameters and are pre-trained on significantly higher amount of data, which makes it more powerful at semantic understanding and generation. Recently, there are rapid growth in GLLM-based news recommender system, and some can achieve state-of-art performance [28]\u2013[30] because it can alleviate the cold-start problem by generating relevant information, and use its strong reasoning and learning abilities to explore accurate news features and model users' interests. However, GLLM-based news recommender systems typically require significant training time and resources.\nThere are many useful survey studies that summarize and review various methodologies of news recommender system. For instance, Wu et al. [3] reviewed different challenges, technologies and future directions of deep-learning based personalized news recommender systems. While Meng et al. [31] reviewed various significant parts of personalized news recommender system such as data collection, news recommendation model, and personalized news display. They focused on discussing different news recommendation methods based on graph structure learning. Iana et al. [32] categorized knowledge-aware news recommendation into three parts: neural methods, non-neural entity-centric method, and non-neural path-based methods. Specifically, they review different methodologies of news recommender systems which utilize external knowledge to help the systems. However, currently, there are no survey studies on DLLM- or GLLM-based news recommender systems. We have also conducted comprehensive benchmark experiments within a unified framework to thoroughly compare and review the performance, advantages, disadvantages, and limitations of the existing systems.\nIn this paper, we summarize and review various LLM-based (including DLLM and GLLM) news recommendation approaches based on three aspects: news-oriented modeling, user-oriented modeling, and prediction-oriented modeling. Text-oriented modeling is defined as a set of text-based encoding methods that use DLLMs and GLLMs in news recommender systems."}, {"title": "II. OVERVIEW OF DEEP LEARNING-BASED NEWS RECOMMENDER SYSTEMS", "content": "Before the era of large language models, deep-learning methods (e.g., CNNs, RNNs, GNNs) were commonly used to design news recommender systems [33]\u2013[39]. Research works in each period have demonstrated consistent patterns across different deep-learning technology development stages. Based on our knowledge and previous works [3], [15], [32], we can conclude a general uniform news recommendation framework as shown in Figure 2, which consists of three main components: news encoder, user encoder and click predictor. Specifically, the news encoder is devised to construct accurate news representations and support user interest modeling. The user encoder is designed to explore users' preferences and build users' representations based on accurate news representations. The click predictor is proposed to calculate matching scores between candidate news representations and users' representations. In this section, we categorize different research works into three types based on the characteristics of each period as follows: news-oriented modeling and user-oriented modeling."}, {"title": "A. News-oriented Modeling", "content": "Initially, most researchers focus on applying basic deep-learning methods to construct news embeddings. To be specific, CNNs are among the earliest deep-learning methods applied in news recommender systems. For example, Wang et al. [4] managed to design CNN-based news encoders with a knowledge graph. Khattar et al. [40] utilized 3D-CNNs to encode news representations. Moreover, attention mechanism (e.g., additive attention, multi-head self-attention) is employed to accurate news representation [33], [43] as well as capture textual content representations [1]. In particular, Gabriel et al. [42] proposed a deep learning-based news recommendation architecture that applied deep neural networks (DNNs) and RNNs to encode content representations. Wu et al. [6] designed a topic-aware news encoder to build news representations with news categories. To construct comprehensive news representations, other researchers focus on devising effective news encoders to encode informative news features. To capture sufficient textual information in news content, Wu et al. [52] proposed a multi-view news encoder that can encode all informative news features such as title, category, and abstract. Lian et al. [56] proposed applying multi-layer fully connected networks and attention mechanisms to design a deep fusion model for news representation learning. The models as mentioned above all encode basic news features (e.g., title, category, abstract) with different deep-learning methods. Due to the limitations of deep-learning methods during this period, most researchers are interested in exploring different deep-learning methodologies to improve the accuracy of news recommender systems."}, {"title": "B. User-oriented Modeling", "content": "With the growth of deep learning-based news recommender systems, researchers focus on user representation learning. For example, Liu et al. [54] utilized self-attention networks to encode deep user representations. Aiming to capture users' long- and short-term representations, An et al. [7] proposed to employ RNNs (e.g., gated recurrent unit networks) to model users' consistent and temporal preferences. Ge et al. [47] employed GNNs (e.g., graph attention networks) and modified transformer networks to model users' high-order relatedness. Although these representation learning methods are proposed to encode news and users' features in order to generate accurate embedding representations for news recommendation, they are only at the mid-exploration stage of deep learning-based news recommender systems.\nDuring the rapid development stage of deep-learning methods, researchers have observed that deep-learning methods not only explore more accurate textual features but also model real-world user profiles (e.g., interest, intention, behaviour). Aiming to build accurate users' interests and obtain more effective recommendation performance, most works utilize different sufficient deep-learning methods to devise their innovative user interest models [5], [11], [57], [58], [60]. They all aim to extract diverse user interests from historical records and achieve state-of-the-art performance in experiments. Using effective and available deep-learning methods, we can acquire accurate user interest representations that are expected. For instance, applying RNNs could help our model capture long sequential features [8], while GNNs could assist in modeling structural interest representations and high-order relationships between news and users [10]. Moreover, user intention is a critical concept in news recommendation, originating from the field of psychology [61]. In order to model users' intentions from sequential history records, Wang et al. [12] devised a GNN-based framework to extract intentions with a knowledge graph. In addition to modeling user representations, other aspects of the user experience (e.g., privacy, fairness, sentiment) should also be taken into account in news recommender systems. In terms of privacy, Yi et al. [67] proposed using federated learning to protect users' privacy while reducing computation and communication costs. For fairness, Wu et al. [64] first employed decomposed adversarial learning to learn bias-free representations in the news recommender system. Furthermore, Wu et al. [62] devised to model sentiment-aware news representations with a sentiment prediction task. The research directions mentioned above have become prominent research topics in the field of news recommender systems in recent years."}, {"title": "III. LLM-BASED NEWS RECOMMENDATION METHODOLOGY", "content": "In this section, we review how DLLM- or GLLM are used to model the three main components of a news recommendation system: news representation, user representation and click prediction. We believe that this framework can help researchers to efficiently understand and master the latest research developments and directions in news recommender systems."}, {"title": "A. News-oriented Modeling", "content": "Initially, most researchers utilize various DLLMs to encode the news textual content. Specifically, Wu et al. [15] first proposed the use of BERT to enhance the natural language understanding capabilities of news recommender systems. Their core contribution is replacing the conventional news encoder module consisting of CNNs, RNNs and GNNs with a module composed of DLLMs and attention mechanisms. Huang et al. [69] introduced a multi-factor fusion model to address the impact of specific news events (i.e., breaking news) To enable multi-aspect customization for news recommendation, such as incorporating news features like sentiment and categories, Iana et al. [70] proposed a novel framework that leverages DLLMs and contrastive learning to model both content- and aspect-based news representations. These methods commonly leverage BERT-based models to enhance the comprehension of textual information in news recommender systems. As demonstrated in these studies, BERT-based models have enhanced news recommender systems, achieving approximately a 3% improvement in performance compared to general deep-learning methods.\nThe application of GLLMs in news recommender systems is distinct from the approach used in DLLM-based news recommender systems. At the inception of GLLMs, most researchers favored incorporating additional critical information generated by GLLMs into news recommender systems. For example, Gao et al. [28] proposed a novel generative news recommendation framework that constructs news narratives (e.g., personalized multi-news narratives) using GLLMs, with a newly proposed training method to enhance recommendation accuracy. Similarly, Yada et al. [71] applied GLLMs (i.e., GPT-4) to generate category descriptions in the news recommender system. Chen et al. [30] effectively leveraged GLLMs to construct rich semantic news representations and utilize Wikidata KG to tackle the long-tail problem of news recommender systems. Liu et al. [72] proposed a novel framework to apply large language models (e.g., GPT-4, LLaMA) to learn contextual information with effective prompts and fine-tuning methods on the news recommendation dataset (e.g., MIND). In order to alleviate the problem of media bias, Ruan et al. [29] proposed leveraging GLLMs to rewrite news headlines for users in news recommender systems. The researchers effectively leverage the powerful generative capabilities of GLLMs to achieve approximately a 10% improvement in the performance of news recommender systems."}, {"title": "B. User-oriented Modeling", "content": "Modeling users' preferences lies at the heart of news recommender systems. An advanced modeling method could enhance our models' ability to understand users' needs and recommend relevant articles that meet their preferences. The applications of LLMs in news recommender systems not only improve the ability to understand textual information but also enable the creation of accurate user profiles by leveraging contextual features. For instance, Zhang et al. [27] designed a user-news matching framework with BERT, which core idea is matching clicked and candidate news with multi-grained representations (i.e., word-level representations, news-level representations) in a BERT architecture. During the same period, the attentive multi-field matching framework is proposed by Zhang et al. [25]. Although their methodology is similar to that of [27], the matching objects and granularity differ (i.e., news titles, abstracts, and bodies are used in this matching process). Similarly, Li et al. [23] proposed a multi-interest matching framework that applies a poly attention scheme to extract multiple interests with BERT-based news encoders. To effectively model users' immediate and long-term preferences, Liu et al. [73] utilized attention mechanisms and GLLMs to address these challenges, using clicked news articles as the basis. As far as we observed, GLLM-based user models are less than DLLM-based user models. Therefore, a significant gap exists in modeling user preferences using GLLMs."}, {"title": "C. Prediction-oriented modeling", "content": "The prediction-aspect modeling consists of a combination of training strategies and prediction methods. Specifically, NewsBERT [26] is a novel DLLM-based news recommendation framework that simultaneously learns valuable insights from both teacher and student models through the distillation of BERT. Yu et al. [74] first proposed a self-supervised domain-specific post-training approach into a DLLM-based news recommendation framework with a novel two-stage knowledge distillation methodology. Moreover, Xiao et al. [75] proposed an innovative training framework SpeedyFeed to reduce the time and resource costs associated with training DLLM-based news recommender systems. To enhance the performance of news recommendation tasks, Bi et al. [22] designed a multi-task framework that improves effectiveness by incorporating multi-field features, including news recommendation, news classification, and named entity recognition (NER). Furthermore, Liu et al. [76] proposed a prompt-based news recommendation framework that demonstrates the effectiveness of a GLLM-based prompt strategy by leveraging an iterative bootstrapping process. Wang et al. [77] proposed a GLLM-based news recommendation model that utilizes a GLLM to filter out low-value news and recommend high-value news to users, using a newly designed metric called CherryRec. These methods provide great strategies to assist us train and optimize LLM-based news recommender systems. However, research on GLLM-based news recommender systems is still in the early stages and presents researchers with more opportunities and challenges to overcome."}, {"title": "IV. CHALLENGES", "content": "In this section, we discuss our observations on the challenges of LLM-based news recommender systems, focusing on datasets, tools, and methodologies."}, {"title": "A. Challenges of Datasets", "content": "There are some publicly available news recommendation datasets such as Globo [83], Plista [84], Adressa [85], MIND [86], NPR [87] and XMIND [88]. We summarize their characteristics in Table II. Specifically, Plista offers a large collection of news texts and user behaviors gathered from 13 German news portals. Globo only includes word embeddings of the news texts, without additional textual features, which significantly limits the available information. Because textual information is essential in constructing news and user representations.\nAs we can observe, Adressa and MIND are the most popular news recommendation datasets, which include informative news and user features. NPR is an enhanced news dataset by Globo, offering more comprehensive news content and detailed user behavior data, which consists of metadata information about news articles, recommendation impressions and user consumption history. XMIND is a multilingual news recommendation dataset built on MIND, which includes 14 linguistically and geographically diverse languages. EB-NeRD is collected from the information of Ekstra Bladet, which consists of 37 million impression logs, 251 million interactions and news metadata.\nDespite the availability of some resources, public news recommendation datasets face significant challenges.\n1) Quantity: The available public news datasets are insufficient to meet the rapid growth of news recommender systems. As we can see in Table II, MIND dataset is the most popular dataset on which most researchers prefer to conduct experiments.\nHowever, the MIND dataset has nearly reached its limitation in some works [15], [26]. We are in the zone of model overfitting to this dataset. So we need more datasets to really evaluate the generalizability of the model. It is essential to release some new news datasets to enable researchers to conveniently design and conduct experiments across different datasets.\n2) Information: MIND dataset contains the most informative features (e.g., title, abstract, category, entity) compared with others. However, this alone is insufficient to significantly enhance news recommender systems. This is because additional information (e.g., publisher, location, reading time, etc) is required to model more accurate user representations. Incorporating users' reading time per news article could improve the accuracy of modeling their preferences [68]. Including publisher information could contribute to building fairness-aware news recommender systems [19]. Additionally, utilizing images within news articles could enable researchers to develop multi-modal news recommender systems, which can empower news representation learning [89]. As a result, the development of news recommender systems is constrained by available news datasets. Moreover, an LLM trained solely on English is unlikely to perform well on Norwegian or other language datasets without additional training."}, {"title": "B. Challenges of Benchmarking Tools", "content": "Smart and user-friendly benchmarking tools enable researchers to conduct studies more easily. In recent years, several benchmarking tools have been released to support the development of news recommender systems. We collect and review important benchmarking tools related to news recommendations illustrated in Table III, including Microsoft Recommenders [92], RecBole [93], News-Recommendation, NewsRecLib [90].\n1) Microsoft Recommenders: Microsoft Recommenders is published by Microsoft Recommenders team providing several examples and practices for building recommender systems. This benchmarking tool contains five essential news recommendation models including NRMS [43], NPA [1], NAML [52], LSTUR [7] and DKN [4], which code is generated by Keras in Tensorflow programming environment. Although this repository offers several news recommendation models for practical use, it is not a specialized benchmarking tool for news recommendation. and only conducts experiments on a single news recommendation dataset (i.e., MIND).\n2) RecBole: RecBole is a general recommendation benchmarking tool developed by PyTorch , which contains various recommendation algorithms such as sequential recommendation, context-aware recommendation, and knowledge-based recommendation. This repository also supports news recommender systems, but only two models (NRMS [43] and NAML [52]). Therefore, RecBole is insufficient for researchers studying news recommendation due to its limited number of models and reliance on a single news recommendation dataset.\n3) News-Recommendation: News-Recommendation is a personal open-source benchmarking tool available on GitHub. This benchmarking tool consists of six important news recommendation models such as DKN [4], NAML [52], NPA [1], NRMS [43], TANR [6] and HiFi-Ark [54]. Additionally, the author uses MIND datasets to conduct experiments. Although the repository implements various news recommendation models, the author will likely discontinue updating the code. As a result, these models are outdated and unable to support future research.\n4) NewsRecLib: NewsRecLib is a news recommendation benchmarking tool built by a personal researcher based on PyTorch Lightning and Hydra frameworks. This benchmarking tool contains various neural news recommender systems (e.g., TANR [6], CAUM [59], CenNewsRec [66], MINS [8], etc) and news datasets (e.g., MIND, Adressa, xMIND), which enables researchers to quickly reproduce news recommendation methods and conduct experiments among different datasets. Although this benchmarking tool categorizes news recommender systems into two classes: deep learning-based news recommendation and fairness-aware news recommendation, the models provided are insufficient to support future research due to the lack of multi-modal news recommender systems, GLLM-based news recommender. systems, etc. Several future directions require attention, including debiased news recommender systems, LLM-based news recommender systems, multi-modal news recommender systems, and privacy-preserving news recommender systems.\n5) Legommender: Legommender is a content-based recommendation benchmarking tool released by personal researchers, which aims to support LLM-based recommender systems. This benchmarking tool contains four news recommendation models such as NAMLc [52], NRMS [43], LSTUR [7] and PLMNR [15]. They devised this tool to serve their research such as ONCE [72], SPAR [94], GreenRec [95] and UIST [96]. Legommender guides researchers on effectively applying LLMs to news recommendations including DLLM- and GLLM-based frameworks. However, it is not sufficient to support a wide range of news recommendation models with LLMs. Furthermore, additional news recommendation datasets are expected to better serve LLM-based news recommender systems."}, {"title": "C. Challenges of Methodologies", "content": "LLM-based news recommender systems face several challenges in the era of LLMs. We will review these various challenges from four aspects: GLLM-based modeling, news-oriented modeling, user-oriented modeling, and prediction-oriented modeling.\n1) News-oriented Modeling: News representation modeling is critical for accurate news recommendation, strongly related to NLP technologies such as word embedding [37] and LLMs. LLM-based news recommender systems utilize LLMs as news encoders to learn informative news representations, and their superior performance has been validated in numerous studies [15], [72], [90]. Although language models offer promising advantages for news representations, challenges still need to be addressed. First of all, the information generated by GLLMs is not always credible (i.e., GLLMs may exhibit hallucinations.) [97]. Therefore, it is essential to develop more reliable methodologies to validate the accuracy of generated representations. Second, processing large volumes of textual information with LLMs consumes significant time and resources [98]. Third, LLM-based news recommender systems are unable to process long documents due to their limited context window, which restricts their ability to construct comprehensive news representations. Furthermore, modeling multiple languages poses a significant challenge for LLM-based news recommender systems, as not all LLMs are equipped to handle multiple languages effectively. In summary, more effective and efficient LLM-based news encoders are needed to better leverage LLMs for constructing informative news representations.\n2) User-oriented Modeling: User-oriented modeling plays a critical role in news recommender systems. As far as we know, most researchers prefer to model user and news representations simultaneously using DLLMs [23], [25]\u2013[27], [69], [70], [74]. As a result, there is limited research focused on building special user representations independently such as multiple interests modeling, intention modeling, and sentiment modeling [8], [12], [62]. In the real world, user behaviors are complex and dynamic. Current user representation models cannot describe complex and dynamic user behaviors. For example, users' interests might be influenced by breaking news along with time. It is essential to carefully analyze and understand users' interests based on their behaviors. Although DLLMs enhance news representations as well as user representations, it is not sufficient to fully understand real complex users' behaviors. On the other hand, limited research has focused on modeling user representations using GLLMs [28], [30]. They propose generating additional information such as narratives by GLLMs and then aggregating it with the original features of news articles. However, these published studies ignore exploring deep and various user behaviours based on GLLM-enhanced context. For example, user behaviours when reading online newspapers may be influenced by their purpose and preferences. Therefore, efficiently building complex and dynamic user representations using GLLMs remains a significant challenge for news recommendation.\n3) Prediction-oriented Modeling: Prediction-aspect modeling is related to training strategies and prediction including different training frameworks, evaluation methods, and ranking methodologies. It is more and more pivotal for news recommender systems in the period of LLMs. Due to the high time and resource consumption of DLLMs and GLLMs, LLM-based news recommender systems require optimization during training and prompting. First of all, LLM-based news recommender systems often apply one-tower architecture to match candidate news and user interests [25], [27]. These ranking methods can accurately explore the relatedness between candidate news and user interests with multi-grained features. However, these methods are unsuitable for low-latency or low-resource scenarios due to their high inference time and resource requirements [19]. Moreover, training open-source GLLMs, such as LLaMA, for use in news recommendation requires significant time and expensive hardware to support these experiments. Efficient and effective training frameworks and ranking methods are required to accelerate prediction without high time and resource consumption. Second, current LLM-based methods lack accountability for their generated results. Many researchers have already utilized LLMs to replace traditional prediction frameworks such as the two-tower model as shown in Figure 2 [99]\u2013[102]. However, the generated results by GLLMs are not credible. Therefore, how to evaluate the accuracy of the generated information is a significant challenge. Moreover, new metrics are required to support LLM-based news recommender systems in order to verify their robustness, reliability, and performance."}, {"title": "V. EXPERIMENTS", "content": "In this section, we conduct experiments and compare to objectively evaluate the performance of different news recommendation methodologies including LLM and non-LLM based news recommender systems in terms of accuracy, diversity, and personalization."}, {"title": "A. Datasets", "content": "For our experiments, we will utilize the two most commonly used dataset in news recommendation system: MIND [86] and Adressa [85].\n1) MIND: MIND was released by Microsoft in 2020 [86] and constructed based on anonymous user logs obtained from Microsoft News platform. There are two versions: MIND-small and MIND-large. MIND-small contains 65,238 news metadata and 347,727 logs generated by 94,057 users. MIND-large consists of 24,155,470 logs of 1,000,000 users and 161,013 pieces of news. Each piece of news contains titles, abstracts, categories, and entities In terms of users, MIND provides their IDs and clicked logs including news clicks and impressions.\n2) Adressa: Adressa was published by Norwegian University of Science and Technology, which contains a collection of news articles and sessions from Adressavisen news platform [85]. There are two sub-datasets: one-week and ten-week. The one-week Adressa dataset is comprised of 11,207 articles and 2,286,835 session logs of 561,733 users. The 10-week Adressa dataset is composed of 48,486 articles and 27,223,576 session logs of 3,083,438 users. Each news article consists of titles, categories, bodies, and entities. Each session log includes various information about the user such as IDs, regions, time, browser, and city.\nDue to the limitation of training time and resources, we use the MIND-small and one-week Adressa dataset to conduct our experiments."}, {"title": "B. Evaluation Metrics", "content": "Several evaluation metrics are utilized to verify the performance of news recommender systems in terms of accuracy, ranking, classification, diversity, personalization, and fairness. In this section, we present the metrics employed in our experiments.\n1) Classification Metrics: News recommendation can be considered as a classification task. Hence, several classification metrics can be used. Area Under Curve (AUC) score is commonly used in the evaluation of news recommendations. A high AUC score indicates that the news recommendation model has a stronger ability to distinguish between negative and positive samples, enabling it to recommend relevant news to users effectively. The score is calculated as follows:\n$AUC = \\frac{1}{P \\times N} \\sum_{p \\in P} \\sum_{n \\in N} I(s(p) > s(n)),$ (1)\nwhere $P$ is positive samples, $N$ is negative samples, $p$ is one of positive samples, $n$ is one of negative samples, $s(p)$ is the predicting score of positive samples, $s(n)$ is the predicting score of negative samples. $I(s(p) > s(n))$ indicates that if $s(p) > s(n)$, the result is 1; otherwise, it is 0, computed as follows:\n$I(s(p) > s(n)) = \\begin{cases} 1, & \\text{if } s(p) > s(n) \\\\ 0, & \\text{otherwise} \\end{cases}$ (2)\nAdditionally, there are other popular metrics used in the evaluation of news recommender systems such as Precision, Recall, and Hit rate, which are computed as follows:\n$Precision = \\frac{TP}{TP + FP},$ (3)\n$Recall = \\frac{TP}{TP + FN},$ (4)\n$Hit@k = \\frac{1}{|U|} \\sum_{u \\in U} I(R_u \\cap R_u(k) \\neq \\emptyset),$ (5)\nwhere $TP$ indicates true positive samples, $FP$ means false positive samples, $FN$ indicates false negative samples, $R_u$ is the collection of interested items for user $u$, $R_u(k)$ is a top-k list of interested items for user $u$, $I$ is exponential function, if true, return 1; otherwise, return 0. In summary, AUC is widely utilized to evaluate the models' ability to recognize positive and negative samples. Precision measures the accuracy of correctly predicting positive samples. Recall is widely used to verify the ability to distinguish all positive samples. Hit rate is proposed to evaluate whether the recommended news list contains the user's interested news."}, {"title": "C. Methods", "content": "In order to evaluate the performance of LLM-based news recommendation models, we conduct several experiments on various methodologies which are classified into three groups: deep learning-based news recommendation models, DLLM-based news recommendation models, and GLLM-based news recommendation. \n1) deep learning-based News Recommendation Models:\nDKN [4], a deep-learning news recommendation model, which enhances news representations with external entities in a knowledge graph using knowledge-aware CNNs.\nNPA [1], a personalized news recommendation model, which applies users' IDs to improve the performance of news recommendations with CNNs and attention mechanisms.\nTANR [6], a topic-aware news recommendation model, which promotes news recommendations with a topic classification task using CNNs and attention mechanisms.\nNAML [52], a deep-learning news recommendation model with multi-viewing learning, which builds news representations from various news features such as titles, abstracts, and categories using CNNs and attention mechanisms.\nLSTUR [7], a deep-learning news recommendation model, which employs RNNs to learn long- and short-term user representations.\nNRMS [43], a deep-learning news recommendation model, which utilizes multi-head self-attention mechanisms to capture complex news and users' features.\nCenNewsRec [66], a privacy-preserving news recommendation model, which applies federated learning to jointly train accurate news recommender systems on users' devices and servers.\nCAUM [59], a candidate-aware news recommendation model, which learns candidate-aware user representations using self-attention mechanisms and CNNs in order to accurately match users' interests.\nMINS [8], a deep-learning news recommendation model, which can learn multi-interest user representations through a multi-channel network consisting of RNNs and self-attention mechanisms.\nSentiDebias [63], a deep-learning news recommendation model, which employs decomposed adversarial learning to achieve fairness-aware news recommendation in terms of different sentiments.\nSentiRec [62], a diversity-aware news recommendation model, which applies Transformers to model sentiment-aware news and user representations, jointly training with a sentiment prediction task.\n2) DLLM-based News Recommendation Models:\nMINER [23], a DLLM-based news recommendation model, which proposes a poly attention scheme to learn multi-interest user representations over BERT."}, {"title": "E. Performance Comparison on Classification and Ranking", "content": "1) Comparison w.r.t. AUC and Recall: As we can see in Table IV", "NDCG": "As shown in Table IV, ranking metrics are composed of MRR, NDCG@5, and_NDCG@10. For the MIND dataset, MANNeR outperforms other models in terms of all ranking metrics. These results emphasize the superiority of LLM-based news recommendation models in ranking compared with deep learning-based news recommendation models such as LSTUR, NRMS, and NAML. Moreover, LKPNR exhibits lower performance than MANNER. It is evident that using GLLM-based approaches is not necessarily effective compared with DLLM-based news recommendation models. For the Adressa dataset, we can observe that LSTUR stands out as one of the few models achieving top-ranking performance"}]}