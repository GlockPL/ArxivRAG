{"title": "Self-Supervised Radio Pre-training: Toward Foundational Models for Spectrogram Learning", "authors": ["Ahmed Aboulfotouh", "Ashkan Eshaghbeigi", "Dimitrios Karslidis", "Hatem Abou-Zeid"], "abstract": "Foundational deep learning (DL) models are general models, trained on large, diverse, and unlabelled datasets, typically using self-supervised learning techniques have led to significant advancements especially in natural language processing. These pretrained models can be fine-tuned for related downstream tasks, offering faster development and reduced training costs, while often achieving improved performance. In this work, we introduce Masked Spectrogram Modeling, a novel self-supervised learning approach for pretraining foundational DL models on radio signals. Adopting a Convolutional LSTM architecture for efficient spatio-temporal processing, we pretrain the model with an unlabelled radio dataset collected from over-the-air measurements. Subsequently, the pretrained model is fine-tuned for two downstream tasks: spectrum forecasting and segmentation. Experimental results demonstrate that our methodology achieves competitive performance in both forecasting accuracy and segmentation, validating its effectiveness for developing foundational radio models.", "sections": [{"title": "I. INTRODUCTION", "content": "A foundational model is a general model pretrained on a large-scale - usually unlabeled - dataset, typically through self-supervised learning [1]. Through this training, the model develops a solid understanding of the target modality, such as text in natural language processing (NLP) or images in computer vision. This understanding allows the model to be fine-tuned for diverse downstream tasks. Foundational models in NLP [2], [3] and computer vision [4] have driven significant advancements through leveraging the knowledge encoded in their pretrained representations. This facilitates quicker experimentation, more efficient resource utilization, and potentially, improved performance on downstream tasks that smaller models or those with more limited domain knowledge cannot achieve.\nDeep learning has showcased promising results when applied in wireless communication [5]. The effectiveness has been demonstrated across various tasks, including automatic modulation classification [6], channel estimation [7], constellation and waveform design [8], among others. However, these models are highly specialized, echoing the early stages of deep learning's evolution in NLP and computer vision. The reliability of these models across data distribution shifts and their ability to generalize is also usually limited.\nIntroducing the concept of foundational models into wireless communication holds substantial promise to overcome these limitations [9]. We argue that as in NLP and computer vision, where a wealth of unlabeled data exists communication signals can be harnessed for pretraining such foundational models through self-supervised learning, mitigating the expense associated with data labeling. Moreover, leveraging a foundational model as a backbone for multiple downstream tasks, which utilize its pretrained representations in subsequent processing, reduces computational demands. This approach can also improve generalization by leveraging the broader knowledge encoded within foundational model representations compared to highly specialized models which suffer from limited scope.\nDrawing inspiration from these advancements, particularly in [2], [4], [10], we introduce a foundational radio model pretrained using masked spectrogram modelling (MSM) a novel technique, we propose for wireless signals. This model is then fine-tuned to perform two different downstream tasks: spectrogram forecasting, which involves predicting future spectrogram based on past data, and spectrogram segmentation, which consists of distinguishing between background noise and other signal activities within the spectrogram. These tasks, while different, are complementary in the context of spectrum analysis and constitute a usage scenario for a foundational model integrated in a opportunistic spectrum access system. The primary contributions of our paper are:\n\u2022\tWe propose and develop a novel self-supervised learning approach, MSM, for pre-training foundational models on radio signals. To the best of our knowledge, this work represents the first demonstration of radio foundational models for spectrogram learning using unlabeled data.\n\u2022\tWe demonstrate the effectiveness of the proposed approach utilizing a real-world dataset that we collected over a software-defined radio testbed. The recordings are time-domain IQ samples received between 2.4 to 2.65 GHz.\n\u2022\tOur results show that the developed MSM approach is able to learn features that generalize to both related and unrelated downstream tasks. Fine-tuning the foundational model demonstrated competitive results for spectrum fore-"}, {"title": "II. TESTBED AND DATASETS", "content": "We leverage two datasets in this paper. The first is a Real-time Radio Dataset (RRD), captured in real-time using a software-defined radio (SDR) test-bed developed with PlutoSDRs. The second dataset simulates 5G New Radio (NR) and LTE transmissions in neighboring bands. This is called the Segmentation Dataset (SD). In both datasets, our primary emphasis is on processing spectrogram data rather than IQ samples, thus a significant portion of preprocessing and data preparation revolves around spectrogram computation.\nA. Real-time Radio Dataset (RRD)\nThe RRD dataset consists of time-domain recordings of IQ samples, which represent both the in-phase (I) and quadrature (Q) components of the RF signal. Each recording corresponds to a distinct center frequency, sampling frequency, and running for a specific duration. The center frequency spans from 2.4 to 2.65 GHz, with the sampling frequency varying between 10 MHz and 60 MHz. The time duration typically averages around 100 ms. The data was collected in downtown Toronto, Canada. We utilize the dataset for foundational model pretraining and spectrum forecasting. There are 240 recordings in total corresponding to approximately 24 seconds of RF activity.\nSpectrogram Computation. The spectrogram of each IQ recording is then computed as follows.\n1) Divide the recording into non-overlapping 2 ms slices.\n2) Compute the spectrogram for each 2 ms slice.\n3) Convert each spectrogram from the linear to the log scale.\nThe parameters used to generate the RRD dataset are summarized in Table I.\nB. NR-LTE Segmentation Dataset (SD)\nThe process of creating the SD dataset begins with the generation of 5G NR and LTE signals individually. Subsequently, these signals are transmitted through their respective wireless channels in adjacent bands. We employ the Matlab Communication Toolbox for signal generation, following the guidelines outlined in [11]. The parameters for generating 5G NR and LTE signals are presented in Tables II and III respectively."}, {"title": "III. FOUNDATIONAL MODEL FOR SPECTROGRAM LEARNING", "content": "In this section we first present the methodology we propose to create the equivalent of sentences and tokens in the context of spectrograms. These radio sentences are then utilized by the proposed self-supervised masked spectrogram modelling approach which we present next. Here we utilize a convolutional LSTM (ConvLSTM) model introduced in [12]. This model is specifically crafted to capture crucial spatio-temporal features, aligning with our spectrogram learning needs. The convolutional component focuses on spatial properties, while the LSTM configuration handles temporal aspects. It accepts a sequence of two-dimensional spectrogram tokens as input and produces an output sequence of equal length. The details of the two downstream tasks that leverage this foundational ConvLSTM are then presented.\nA. Creation of Radio Sentences and Tokens\n(a) Randomly sample a sequence of successive spectrograms with a duration ranging from 10 to 20 ms.\n(b) Concatenate the sequence of spectrograms along the time-axis.\n(c) Resize the result to a shape of (256, 256).\n(d) Divide the result along the time-axis into a sequence of tokens with a shape of (256, 16), allowing the sequence of tokens to be represented as a 3D array with a shape of (16, 256, 16).\n(e) Append the resulting sentence\u2014a sequence of tokens-to the corpus, which will contain sentences of variable size.\nB. Masked Spectrogram Modelling\nWe propose a technique, we refer to as masked spectrogram modeling (MSM) for pretraining the foundational model. This approach involves inputting a spectrogram into a deep learning model and masking a portion of it-typically 20%. Masking involves replacing the actual content of the spectrogram with white noise as shown in Figure 4. The model's objective is to reconstruct the original spectrogram from the masked version, effectively denoising it in the process. To achieve this, the model analyzes the surrounding context and infers what was likely in the masked positions. Throughout the learning process, the model is expected to develop an understanding of radio signals as represented by spectrograms, creating an internal representation that enables it to accurately recover the original spectrograms. A notable advantage of this approach is that it operates without the need for labels. Radio signals can be recorded and fed directly into the model pipeline, which then leverages them to refine its internal representation. The pretrained model can then be fine-tuned for any related downstream task, the procedure is illustrated in Figure 3 and a general algorithm is described in Algorithm 1."}, {"title": "C. Spectrum Forecasting", "content": "In this task, the model takes a sequence of tokens {w_{1}^{(n)},...,w_{T}^{(n)}\\} as input and aims to predict the next token W_{T+1}^{(n)}. Training involves minimizing the mean-square-error loss between the predicted token and the actual next token for a batch of inputs {W_{T+1}^{(n)}\\}_{n=1}^{N}  {W_{T+1}^{(n)}\\}_{n=1}^{N} where n is the sample index and N represents the batch size. This loss function, denoted as L_{SF}, is formulated as follows:\n\nL_{SF} = \\sum_{n=1}^{N}  || vec (W_{T+1}^{(n)}) - vec (w_{T+1}^{(n)} ) ||^{2}\n\nThe model architecture described in Table IV is used, yet with two notable modifications: first, only the initial token of the output Conv3D layer is considered, disregarding the remaining outputs. Second, the backbone of the model, consisting of the 5 ConvLSTM layers, is frozen, and its weights are initialized with those obtained from the MSM task. Consequently, the features learned during the MSM task are utilized, while only the final layer undergoes fine-tuning for spectrum forecasting purposes."}, {"title": "D. Spectrogram Segmentation", "content": "In this task, the model processes a spectrogram of size (256, 256), which is then tokenized into 16 tokens of shape (256, 16). Consequently, the input comprises a sequence of tokens {w_{1}^{(n)},...,w_{16}^{(n)}\\}  while the output is a segmented image Y^{(n)} \\in {0,1}^{(256, 256, 3)}  that is one-hot encoded and the model prediction is denoted as \\hat{Y}^{(n)} \\in [0,1]^{(256, 256, 3)}. For a batch of size N, we utilize the cross entropy loss written as:\n\nL_{SG} = -\\sum_{i} \\sum_{j} \\sum_{n=1}^{N} Y_{ij}^{(n)}  log(\\hat{Y}_{ij}^{(n)})\n\nSimilar to spectrum forecasting, the backbone consists of 5 ConvLSTM layers. Subsequently, the backbone's output is concatenated to form a shape of (256, 256), serving as input to"}, {"title": "IV. RESULTS AND DISCUSSION", "content": "This section evaluates the proposed self-supervised radio pre-training methodology by comparing the performance of the resulting foundational model when fine-tuned on two downstream tasks\u2014spectrum forecasting and segmentation\u2014to a baseline. The baseline model shares the same architecture but is trained from scratch on identical data.\nA. Downstream Task-1: Spectrum Forecasting\nData and Model Training: We partition the RRD dataset, allocating 50% for pretraining and reserving the remaining 50% for forecasting.\nWe fine-tune the pretrained model using the remaining 50% of the RDD dataset, which we further split into training and test sets with an 80% to 20% ratio.\nEvaluation Metric: To evaluate the model's forecasting performance, relying solely on visual comparison between the target and predicted spectrograms will not suffice. Therefore, we adopt a more robust metric by transforming each spectrogram into a resource grid composed of resource blocks (RBs) with predefined time and frequency resolutions. This process involves dividing the spectrogram into these blocks and computing the mean value for each. Subsequently, a threshold is applied to the resulting grid, rendering it binary-where a value of 1 denotes an occupied block and 0 denotes a vacant one.  The threshold \\delta is empirically determined as:\n\n\u03b4 = \u03bc + 0.5 \u00d7 \u03c3\n\nwhere \u03bc and \u03c3 represent the mean and standard deviation of the spectrogram, respectively.\nOur primary evaluation metric focuses on the model's capacity to correctly predict the occupancy of a resource block when it is indeed occupied. Predicting vacancy is straightforward, given its prevalence as the dominant class. From the perspective of opportunistic spectrum access, it is crucial to consistently detect occupied blocks to mitigate potential collisions.\nThis metric is depicted in  for predictions extending 4 tokens into the future, across various time and frequency resolutions for the resource block, with (b) representing the baseline. The specialized baseline outperforms the tuned foundational model, though by a small margin.\nB. Downstream Task-2: NR-LTE Segmentation\nFor the segmentation task, we utilize the SD dataset to fine-tune the foundational model. The main challenge here lies in the distinct nature of the spectrograms within this dataset compared to those used during the self-supervised pre-training. Consequently, the learned features may not generalize as effectively to segmentation as they do to forecasting. In addition, segmentation is a classification task and the model was pre-trained on regression only. Our objective is to examine the extent to which the learned representations of the foundational model can generalize under such distinct data distributions and across task types.\nWe evaluate the model's performance using confusion matrices for the three classes: Noise, NR, and LTE, which quantify the model's prediction accuracy for each class.  presents the confusion matrices for both the baseline and fine-tuned models. Notably, the fine-tuned model struggles with distinguishing NR signals, while the baseline model demonstrates strong performance across all classes. This suggests that the features provided by the pretrained backbone are not sufficiently discriminative to differentiate NR signals from other classes, though they perform adequately in separating signals (NR or LTE) from noise. A more complex head and fine-tuning training process may also be needed.\nTo further illustrate this, we simplify the task to binary segmentation, merging NR and LTE into a single signal class. The resulting confusion matrices are shown in Figure 8. Here, while the baseline model still outperforms the fine-tuned model, the correct detection of signals is higher. We attribute this to differences in data distribution between the pretraining and SD datasets. Pretraining on a larger and more diverse dataset may help bridge this gap. Further research by the community will be needed in these directions to build large-scale foundational radio models."}, {"title": "V. CONCLUSION", "content": "In this paper, we introduced a self-supervised radio pre-training approach, MSM, to build a foundational model for spectrogram learning. Drawing inspiration from the success of foundational DL models in various domains, the goal was to learn features that could generalize to related downstream tasks. We demonstrated that by fine-tuning the developed MSM model for two downstream tasks: spectrum forecasting and segmentation. Our results show that the fine-tuned models exhibited competitive performance compared to baselines trained from scratch, while requiring much less training time to converge. We believe that extending the proposed MSM approach to larger models and utilizing large-scale, diverse datasets for pretraining has the potential to develop robust radio foundational models that yield competitive performance across various spectrogram learning tasks."}]}