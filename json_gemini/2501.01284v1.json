{"title": "NEUTRASUM: A LANGUAGE MODEL CAN HELP A BALANCED\nMEDIA DIET BY NEUTRALIZING NEWS SUMMARIES*", "authors": ["Xi Luo", "Junjie Liu", "Sirong Wu", "Yuhui Deng"], "abstract": "Media bias in news articles arises from the political polarisation of media outlets, which can rein-\nforce societal stereotypes and beliefs. Reporting on the same event often varies significantly between\noutlets, reflecting their political leanings through polarised language and focus. Although previous\nstudies have attempted to generate bias-free summaries from multiperspective news articles, they\nhave not effectively addressed the challenge of mitigating inherent media bias. To address this gap,\nwe propose NeutraSum, a novel framework that integrates two neutrality losses to adjust the seman-\ntic space of generated summaries, thus minimising media bias. These losses, designed to balance\nthe semantic distances across polarised inputs and ensure alignment with expert-written summaries,\nguide the generation of neutral and factually rich summaries. To evaluate media bias, we employ\nthe political compass test, which maps political leanings based on economic and social dimensions.\nExperimental results on the Allsides dataset demonstrate that NeutraSum not only improves sum-\nmarisation performance but also achieves significant reductions in media bias, offering a promising\napproach for neutral news summarisation.", "sections": [{"title": "Introduction", "content": "Media bias is inevitable in mass media, when journalists frame news stories to support their political stances [9, 34].\nEven if they are reporting on the same event, they can manifest entirely disparate emphases on the salient aspects of\nan event based on their intended points of emphasis [16]. This selective framing encourages readers to consume news\nthat aligns with their pre-existing political beliefs, further reinforcing political stereotypes and potentially distorting\ndecision-making on critical political issues [38]. Therefore, how to mitigate media bias in news articles becomes an\nimportant research topic.\nA feasible systemic research framework to mitigate media bias from the news is news aggregation [33, 23, 43, 6].\nIt provides a comprehensive perspective of an event to mitigate the exposure of the far-left or far-right slanted bias.\nFounded on this approach, one early study [23] proposed a new task to generate a neutral summary from a triplet of\nnews articles reporting on the same issues. To promote the goal of news neutralisation, they utilized a hierarchical\nframework from title to articles to generate a bias-free summary. A further refined work [6] introduced polarity loss\nto minimise the polarity difference in the input articles. While these studies contribute valuable insights, they also\nexhibit notable limitations. Although indicative information and polarity regularisation techniques were explored to\nproduce bias-free summaries, their effectiveness in achieving genuine neutrality remains uncertain. For instance, while\ntitle neutralisation can serve as a helpful subtask, it does not directly address the inherent bias embedded in the"}, {"title": "Related Work", "content": null, "sections": [{"title": "Media Bias Detection", "content": "News journalists would frame their news stories to omit or exaggerate some parts of the facts to support their political\nleaning, which could be referred to as media bias [17]. There is a series of computational approaches to identify media\nbias by extracting the polarity features [29, 5, 13, 18, 40]. A line of work employed the additional mechanism or\ninformation to detect media bias on the document level. For example, some auxiliary losses were added to demand\nthe semantic space clustering news articles with the same political direction [29, 5], which assists in predicting the\npolitical leaning. It has also been found that headlines could act as additional cues to classify media bias [15]. Besides"}, {"title": "Media Bias Mitigation", "content": "Despite the current absence of large-scale media annotation datasets including bias span and expert-written summaries,\nalong with standardized measurements for media bias mitigation, numerous studies have still endeavored to reduce\nmedia bias in news coverage. [32, 33, 39, 22, 23]. A GAN framework [26] was designed to reverse or neutralize the\npolitical polarity of the news articles. However, the definition of neutrality adopted is limited to the \"center\" media\nrating. It is insufficient to assert a reduction in media bias, as a center stance does not inherently equal bias-free [1].\nThey further deployed a depolarisation algorithm [28] to mitigate bias in polarised texts, while the measurement of\nmedia bias was conducted using both manual and model-based methods, which could not be considered as a universe\nof media bias metrics since no consistently reliable predicted results could be produced. Another emerging mitigation\ntask generates a neutral summary based on the same-story polarity news articles [22, 23, 6]. However, they did not\nprovide a clear neutralisation guidance or mechanism to reduce media bias. Therefore, we followed this task and\nintroduced the new neutrality losses. These losses prompt the generated tokens to exhibit neutrality traits within the\nsemantic space."}]}, {"title": "Methodology", "content": "In this section, we introduce the details of our NeutraSum model. To achieve good summarisation performance\nwhile minimising a lower media bias, our model is governed by a multi-document summarisation loss to generate\nhigh-quality summaries. Additionally, two neutrality losses (contrastive loss and equal-distance loss) are employed to\nmitigate media bias in summaries. The whole architecture is shown in Fig. 1."}, {"title": "Multi-document Summarisation Loss", "content": "To align with the neutral summarisation task, multi-document summarisation loss is the main loss to ensure coherent\nand content-focused writing by conditional generation. To ensure the comprehensiveness and accuracy of the news,\nmulti-document summarisation would be utilized to aggregate left, center, and right-wing media coverage to generate\na relatively bias-free summary. In the training phase, the generation process would learn the neutral writing features by\nfollowing the texts of the expert-written summary YD. The multi-document summarisation loss could be illustrated as\nfollows:\n$X^{D} = Concat(X^{P}, X^{U}, X^{R}) = \\{x_{i}^{D}\\}_{i=1}^{|T|}$\n$Y^{D} = \\{y_{i}^{D}\\}_{i=1}^{|Y|}$\n$H_{Summ}^{D} = Enc_{summ}(X^{D})$\n$O_{Summ}^{D} = Dec_{summ}(H_{Summ}^{D})$\n$\\hat{Y}^{D} = W H_{Summ}^{D} + b_{H}$\n$\\mathcal{L}_{M D S} = C E(\\hat{Y}^{D}, Y^{D}) = -\\sum_{i=1}^{|Y|} y_{i}^{D} log \\hat{y}_{i}^{D}$\nWhere $X^{P}, X^{P}, X^{R}$ represents the left-wing, center-wing, and right-wing news articles relevant to the same event.\nD denotes the multi-document dataset crawled from Allsides that is used for the summarisation task. $X^{D}$ is the input\nthat concatenates three different political leanings news articles $X^{P}, X^{D}, X^{R}$ into a sequence of |T| tokens, denoted\nas $\\{x_{i}^{D}\\}_{i=1}^{|T|}$. $Y^{D}$ represents the expert-written summary towards the same event of input articles consisting of |Y|\ntokens, denoted as $\\{y_{i}^{D}\\}_{i=1}^{|Y|}$.\n$Enc_{summ}$ and $Dec_{summ}$ demonstrate the encoder and decoder part of the summarisation BART architecture. Input\narticles $X^{DB}$ would go through the encoder framework $Enc_{summ}$ to obtain the hidden state $H_{umm}^{D} \\in \\mathbb{R}^{|T| \\times d}$ in a\nd-dimensional semantic embedding, which is default to 1024. Then $H_{umm}^{D}$ would feed into the decoder framework\n$Dec_{summ}$ to get the hidden state $O_{umm}^{D} \\in \\mathbb{R}^{|Y| \\times d}$. Finally, to obtain the probabilities of each generated token, the\ndecoder hidden state $O_{umm}^{D}$ would be projected to a w-dimensional semantic embedding $\\hat{Y}^{D} \\in \\mathbb{R}^{|Y| \\times w}$ through the"}, {"title": "Equal-Distance Loss", "content": "A neutral news summary is considered to deliver news content factually and does not have a slant towards each side\nof the political leaning. From the NLP (Natural Language Processing) perspective, the news article of each side of\npolitical leaning would be expressed as an embedding in the semantic space through a pre-trained language model.\nTo preserve the no-slant trait in political polarity, the expected neutral embedding will have an equal distance towards\nthe left-side and right-side embeddings. This expected neutral embedding is the encoder hidden state trained on the\naggregated left, center, and right-wing news articles. It is noted that we introduce another dataset $D_{aux}$ to provide\nadditional samples of left-side and right-side news articles $X_{P}^{D_{aux}}, X_{P}^{R_{aux}}$ to accomplish the equal-distance loss.\nThis design is to preserve the internal alignment of the same-event news articles to do the summarisation task. Then\nequal-distance loss could be described as follows:\n$H_{aux}^{P}, H_{aux}^{R} = Enc_{aux}(X_{aux}^{P}), Enc_{aux}(X_{aux}^{R})$\n$\\left[H_{aux}^{P}, H_{aux}^{R}, \\hat{H}_{Summ}^{D}\\right] = A v g\\left(\\left[H_{aux}^{P}, H_{aux}^{R}, H_{umm}^{D}\\right]\\right)$\n$\\mathcal{L}_{E D} = \\left|\\operatorname{sim}\\left(H_{aux}^{P}, \\hat{H}_{S u m m}^{D}\\right)-\\operatorname{sim}\\left(H_{aux}^{P}, \\hat{H}_{S u m m}^{D}\\right)\\right|$\nWhere $Enc_{aux}$ is the auxiliary encoder model, which adopts the Roberta pre-trained language model. A batch of\nleft-side and right-side news articles denoted as $X_{P}^{D_{aux}} , X_{aux}^{D}$ and $X_{aux}^{D}$, would be fed into the auxiliary encoder model\n$Enc_{aux}$ to obtain their embedded hidden states $H_{aux}^{P}$ and $H_{aux}^{P}$. To capture the general semantic meaning and\nimplement equal-distance loss, we take an average of their embedded hidden states in the batch size dimension as the\narticles' semantic representations, which is represented as $H_{aux}^{D}, H_{aux}^{D} $. The hidden state for the summarisation task\nis also averaged, denoted as $\\hat{H}_{S u m m}^{D}$ Finally, since we expect $H_{u}$ represented as neutral summarized embedding,\nit requires maintaining equal distance with left-side and right-side averaged semantic embedding, which is shown in\nEq. (9). sim() represents the similarity function. |\u00b7 | remains the equal-distance loss $\\mathcal{L}_{E D}$ to be positive."}, {"title": "Contrastive Loss", "content": "Besides the characteristic of equal distance with different political directions, a neutral summary should also learn the\nbias-free lexicons and writing styles from expert-written summaries, since expert-written summaries are considered\nrelatively bias-free compared to the news coverage written by mass media. To achieve this goal, it is expected to\ndistinguish the writing manner between polarised news articles and expert-written ones. In the semantic space, the\nlatent semantic space of the architecture should still be further optimized towards the semantic representation of the\nhuman-written summary and get away from the embeddings of polarised news coverages.\nInspired by contrastive learning [8, 41, 20], we utilized normalized temperature-scaled cross-entropy loss (NT-\nXent) [8] as the contrastive loss and considered generated summaries as anchors. Expert-written summaries act as\npositive samples, pulling closer to anchors. While those news articles in the auxiliary dataset with strong political po-\nlarisation act as negative samples, moving away from the anchors. The contrastive loss could be described as follows:\n$\\hat{H}_{y} = A v g\\left(E n c_{s u m m}\\left(Y^{D}\\right)\\right)$\n$\\mathcal{L}_{c o n}=-\\log \\frac{\\exp \\left(\\operatorname{sim}\\left(H_{u m m}^{D}, \\hat{H}_{y}^{P}\\right) / \\tau\\right)}{\\sum_{\\left\\{X^{P}, X^{R}, P\\right\\}} \\exp \\left[\\operatorname{sim}\\left(H_{u m m}^{D}, H_{u}^{P}\\right) / \\tau\\right]}$\nWhere $\\hat{H}_{y}^{P}$ is the averaged encoded hidden state for the expert-written summary. $\\operatorname{sim}(\\cdot)$ denotes the similarity function\nand $\\tau$ denotes the temperature. In the contrastive loss, the encoded embedding of summarized input $H_{u m m}^{D}$ and\nexpert-written summary $H_{y}$ should be pulled closer to the semantic space. In contrast, the encoded summarized\nembedding should maintain a greater distance from the left and right political-leaning embeddings in the auxiliary\ndataset $\\left\\{H_{a u x}^{P}, H_{a u x}^{R}\\right\\}$."}, {"title": "Overall Model", "content": "Generally, we employ the BART pre-trained language model as our main architecture to fine-tune toward an expert-\nwritten summary. Besides the traditional pre-trained language modeling, two additional neutrality losses are proposed\nto provide bias-free writing. All three losses would join the optimisation process during training. The loss function of\nthe model in the training stage would be formulated as:\n$\\mathcal{L}_{o v e r a l l}=\\lambda_{1} \\mathcal{L}_{M D S}+\\lambda_{2} \\mathcal{L}_{E D}+\\lambda_{3} \\mathcal{L}_{c o n}$\nWhere $\\lambda_{i}$ should be the balanced weight for each loss, and the sum should be 1. Normally, we will take each $\\lambda_{i}$ as\n1/3. The overall loss $\\mathcal{L}_{o v e r a l l}$ consists of $\\mathcal{L}_{M D S}$, $\\mathcal{L}_{E D}$, and $\\mathcal{L}_{c o n}$ representing multi-document summarisation loss,\nequal-distance loss, and contrastive loss."}, {"title": "Experiment", "content": null, "sections": [{"title": "Dataset", "content": "We leveraged data from Allsides Dataset [23] for the summarisation task. This dataset consists of a wide range of\nU.S political topics such as 'Election', 'Immigration', 'Healthcare', 'Abortion', etc.etc. The dataset incorporates 3464\ntriplets of news articles. Each triplet consists of left, center, and right-wing news articles reporting the same issue, as\nwell as an expert-written summary. It is mentioned that the \"center\" still contains media bias, which does not represent\nbias-free [1]. The dataset details are illustrated in Table 1. We randomly split this dataset into training, validation\nand testing. To integrate neutrality losses for the mitigation of media bias, we obtained the auxiliary dataset [5] that\nincorporates left-wing and right-wing news articles, covering many topics and media sources from Allsides. It is noted\nthat the incorporation of an auxiliary dataset aims to guide the generated summary away from polarised texts while\ncompacting the same-story news articles from diverse political perspectives. Allsides dataset and auxiliary dataset use\nMIT and Apache 2.0 license respectively."}, {"title": "Evaluation Metrics", "content": "Salient Information Preservation Metric To assess the performance of the generated summaries retrieving essential\ninformation from the input articles, we use the ROUGE [25] and BLEU [31] to calculate the information preserva-\ntion between generated summaries and expert-written summaries. ROUGE is to measure how often n-grams in the\nmachine-generated summary capture from the human-written summary, and BLEU is to measure how often n-grams\nin the human summary appear in the human-written summary. It is noted that higher ROUGE and BLEU represent a\nbetter information preservation performance.\nMetric Bias Metric To measure the media bias, we adopted the political compass test [14]. The test is grounded on the\npolitical spectrum theories [11, 35] to provide different perspectives to measure the political ideology of media, which\nis based on two factors: economic factors (from liberal to conservative) and social factors (from left to right). Previous\nstudies usually quantify media bias primarily based on the pre-trained language model [26, 27, 21] and sentiment-\nbased annotation [23]. However, the pre-trained language model could not yield stable results and sentiment-based\nannotation lacks a clear association between sentiment words and polarity polarisation."}, {"title": "Experiment Details", "content": "The hyperparameters of the NeutraSum model during training are illustrated below: models for summarisation and\nneutralisation are \"Bart-large\" and \u201cRoberta-large\" in HuggingFace. Their corresponding datasets are Multi-document\nDataset and Auxilary Dataset. Multi-document Dataset contains a triplet of the left, center, and right-wing news articles\nfor summarisation tasks. The auxiliary dataset consists of different left and right-wing news articles to join neutrality\nlosses. Learning rates for them are 3e-5 and 2e-5. As for the batch size, a sample from a Multi-document Dataset will"}, {"title": "Baselines", "content": "Since we followed a summarisation task to do the neutral summary, we would conduct some experiments on some\ncurrent state-of-the-art summarisation models.\nLEXRANK [10]: An extractive single-document summarisation model that extracts the sentences with high similarity\nin documents, which is finetuned in DOC 2004 [30].\nBARTCNN: An abstract single-document summarisation utilizing CNN/Dailymail [19] to finetune on the BART-\nlarge [24] model.\nBARTMULTI: A multi-document abstractive summarisation model, which is finetuned on the BART-large [24] model\nusing Multi-News dataset [12].\nPEGASUSMULTI: An multi-document summarisation model finetuned on pegasus model [42] using Multi-News\ndataset.\nNEUSFT [22]: An abstract multi-document summarisation model that proposes this task to finetune the Allsides\ndataset.\nNEUS-TITLE [23]: An improved version of NEUSFT that adds the title summarisation."}]}, {"title": "Experimental Results", "content": "In this section, we illustrated the experimental results of baselines and our model NeutraSum, which is shown in Table\n2. Based on the experimental performance in salient information preservation and media bias reduction, we pointed\nout the significant observations by quantitative analysis.\nEffectivness of neutrality losses in media bias mitigation and salient information preservation As illustrated in\nTable 2, our proposed model NeutraSum and its variants (w/o Contrastive Loss and w/o Equal-distance Loss) have a\nnoticeable impact on reducing media bias, especially NeutraSum, moving the score closer to a neutral point (-0.38,\n2.41) on the political compass test, which is 71% and 45% the sharp reduction compared to extreme polarised baseline\nPEGASUSMULTI. As for the summarisation performance, our proposed NeutraSum model with the variants keeps\nthe most salient information among all the other baselines. More specifically, NeutralSum shows high scores in BLEU\n(11.99), and the variant \"w/o Contrastive Loss\" has comparable scores with a slight increase in BLEU (12.01) and\nROUGE-2 (28.43%). Another variant \"w/o Equal-distance Loss\u201d records a similar pattern of performance, with the\nhighest ROUGE-L (48.42%). Therefore, this result indicates that NeutraSum and its variants are effective at generating\nhigh-quality summaries that not only retain the essential information but also exhibit less media bias.\nNecessity of two Neutrality Losses We investigate that although the variants of NeutraSum have a similar summari-\nsation performance in BLEU and ROUGE, their bias reduction effects are quite different. More specifically, variants\nwith only one neutrality loss would have an unstable performance in the political compass test, since some of their\nresponses to the test may hover between agree and disagree. This would lead their economic score to a slight positive\nshift in their economic axis scores to 0.38 and 0.42. While for the NeutraSum with both the neutrality losses, it could\neffectively and robustly reduce the media bias to (-0.38, 2.41).\nLeft and Authoritarian of the baselines in Polarity Among all the baselines and our proposed models, most of them\nare slanted to the left and authoritarian in polarity based on the results of the political compass test. A contributing fac-\ntor is that many media datasets crawled lots of news coverage from left-wing media outlets, such as CNN, Guardian,\nBuzzFeed News, etc. Summarisation models are fine-tuned on these news datasets and learn polarised writing styles.\nThis proficiency is useful for detecting the political orientations of media content. However, this kind of feature adop-\ntion could potentially exacerbate the skew towards more leftist and authoritarian biases in media representation."}, {"title": "Analysis", "content": null, "sections": [{"title": "Analysis of weight for losses", "content": "The configuration of weights for different losses is a critical issue to discuss. We chose different weight combinations\nfor the three losses and did the experiments in Table 3. From the first row of weight configuration, we adjust the weight\nof MDS Loss (Multi-document Summarisation Loss) progressively scaled down from 0.98 to 0.02. Meanwhile, the\nweights for neutrality losses, namely ED Loss (Equal-distance Loss) and Con Loss (Contrastive Loss), are weighted\nnearly identically due to their similar efficacy and significance. The weight combination (0.2:0.5:0.4) in the NeutraSum\nyields relatively high summarisation results, while the (0.33:0.33:0.33) configuration effectively minimises media bias,\nachieving a score of (-0.38, 2.41) in the political compass test. Excessive weight for MDS Loss (0.98:0.01:0.01) might\nlead to more bias (-1.63, 3.96) in the summaries. In contrast, having a higher neutrality loss weight (0.02:0.49:0.49)\ndoes not necessarily ensure the best reduction in bias. It implies that there isn't a straightforward relationship where\nsimply increasing the weight of these losses leads to less biased summaries. By considering the final effect observed\nin bias reduction, the weight configuration of (0.33:0.33:0.33) has been selected as the final setting. This is because it\ncan reduce bias more effectively while maintaining a certain level of summarisation quality."}, {"title": "Analysis of Generated Summary", "content": "As illustrated in Fig. 3 and 4, we showed two cases of reporting of the same event, with input (left, center, right news\narticle), expert-written summary, and the generated summary from the NeutraSum model.\nIn Fig. 3, all of the relevant news articles and summaries wrote about the issue of cancelation of the president's\nagenda, the left-wing article speculated that President Biden \"create desperately needed momentum\" to his agenda,\nwhile right-wing article stated that the reason for canceling agenda is \"stalled negotiations over Democrats' infras-\ntructure legislation\", which amplifies the negative impact of the issue. An interesting pattern is shown in the generated\nsummary. While BART is an automatic abstract summary model that will not directly copy the sentences from the\ninput, we could observe that the generated summary extracts some bias-free sentences from the inputs to describe the\nissue. This seems to demonstrate the model's certain capacity and semantic understanding on media bias neutralisation.\nFig. 4 still illustrates subtle word choice in different polarised articles and abstractive summarisation capacity. Regard-\ning the coverage of abortion law issues, articles from the left-wing use the verb \"blow\" to convey the adverse effects of\nthe efficacy of abortion laws on proponents of abortion rights. Articles from the Center share a comparable viewpoint\nwith the left-wing, employing \"curb\" to depict the challenges associated with prohibiting abortion law. Conversely,\nright-wing articles employ terms like \"allows\u201d and \u201csue\u201d, reflecting a more positive stance in favor of abortion leg-\nislation. An interesting notion is that the generated summary, in its conclusion, presents a neutral perspective on the\""}]}, {"title": "Conclusion and Future Work", "content": "This paper followed the task of generating a bias-free summary from a triplet of news articles with left, center, and\nright-wing reporting on the same event. Such a neutral summary could provide a more comprehensive and impartial\nview to the readers to alleviate their ideological and political stereotypes. By considering fine-tuning the semantic\nspace of the generated summary towards a neutral representation, we proposed the NeutraSum model, a neutral sum-\nmarisation approach designed to guide summarisation models towards a more neutral stance, and added two additional\nneutrality losses by adjusting the semantic distance among different inputs and labels to mitigate media bias using the\nBART model. To ensure impartiality in the semantic space, the desired neutral summary is structured to be equidis-\ntant from both left-leaning and right-leaning news articles. It also requires following the objective writing style of the\nexpert-written summary while keeping a distance from polarised news articles. Moreover, as for the media bias mea-\nsurement, we utilized the political compass test, which evaluates political ideologies on economic and social factors\nto provide a more nuanced understanding of an individual's political stance.\nDespite its promising results, NeutraSum has several limitations in communication theory and AI applications. The\nframework focuses on overt bias and semantic neutrality but overlooks nuanced rhetorical strategies, such as tone\nand story prioritization, which remain challenging. Its reliance on datasets like Allsides limits generalizability, as\nthese may not capture global or cross-cultural media diversity. While the neutrality losses reduce bias in semantic\nspace, they fail to address pragmatic neutrality-how audiences interpret content. The lack of explainability in AI-\ndriven decisions also limits transparency and trust, while latent biases in pre-trained models like BART and ROBERTa\nmay still influence summaries. Scalability is another concern, as the framework's computational complexity may\nhinder real-time applications. Finally, ethical concerns regarding the definition and measurement of neutrality, such as"}, {"title": "Ethical Statement", "content": "Media bias can be considered abstract in the sense that it involves subjective perceptions, opinions, and preferences\nwithin a political context. In this paper, we utilize the political compass test to measure media bias based on the general\npolitical background. However, this test could not assess the political attitude towards the specific event. While early\nresearch [23] has proposed sentiment-annotation lexicons to measure media bias by calculating the sentiment scores in\nthe summary, there is no clear relation between sentiment and political polarity. Therefore, it is essential to be mindful\nof media bias considerations in both the model and the generated summaries in future research.\nAnother noteworthy phenomenon is that not all the same-story news articles with diverse political slants would have\ndifferent attitudes. As for extreme cases, media outlets commonly adopt similar stances when reporting on particular\nissues. A broader investigative focus is warranted on relative polarity, which means that media outlets with various\npolitical ideologies have different attitudes toward the same issue. This could also be considered as a more nuanced\nperspective on future media bias metric design.\nThe final consideration is that to do this neutral summary task, we take out some notable cases to illustrate the framing\nof different polarised news outlets. It is noteworthy that not all news articles employ overly emphasized or derogatory\nlanguage, this is primarily utilized to showcase the effectiveness of our summary generation."}]}