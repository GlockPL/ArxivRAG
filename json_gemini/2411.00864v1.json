{"title": "ADVANCING CRIME LINKAGE ANALYSIS WITH MACHINE LEARNING: A COMPREHENSIVE REVIEW AND FRAMEWORK FOR DATA-DRIVEN APPROACHES", "authors": ["Vinicius Lima", "Umit Karabiyik"], "abstract": "Crime linkage is the process of analyzing criminal behavior data to determine whether a pair or group of crime cases are connected or belong to a series of offenses. This domain has been extensively studied by researchers in sociology, psychology, and statistics. More recently, it has drawn interest from computer scientists, especially with advances in artificial intelligence. Despite this, the literature indicates that work in this latter discipline is still in its early stages. This study aims to understand the challenges faced by machine learning approaches in crime linkage and to support foundational knowledge for future data-driven methods. To achieve this goal, we conducted a comprehensive survey of the main literature on the topic and developed a general framework for crime linkage processes, thoroughly describing each step. Our goal was to unify insights from diverse fields into a shared terminology to enhance the research landscape for those intrigued by this subject.", "sections": [{"title": "1 Introduction", "content": "Crime Linkage (CL) [1] is a multidisciplinary field that has garnered significant attention from sociologists, psychologists, statisticians, and computer scientists [2, 3, 4, 5, 6, 7]. In essence, they aim to connect pairs of crimes by creating crime link associations [3]. The CL analysis is typically based on Modus Operandi (MO) or criminal behavior, which can be inferred from evidence found at crime scenes or other source of police data [8]. These MOs/behaviors are systematically compared to assess the similarities between different crimes [9]. High similarity scores often indicate potential connections, providing valuable insight into shared offender characteristics or underlying patterns within these criminal acts.\nThe literature on crime linkage encompasses a wide array of methods and evaluation metrics, alongside various data sets used to establish connections between criminal incidents. Numerous studies have showcased CL outcomes, particularly in cases involving property crimes and sexual offenses [5]. The CL is in essence a classification problem, where the goal is to either assess if a pair of crimes is linked or not, or to associate a case to a series of offenses, based on pattern characteristics.\nThere are many methodologies for modeling and evaluating crime linkage. Data-driven approaches in CL have been explored using statistical methods, fuzzy logic, and machine learning techniques. Although recent years have seen a surge in artificial intelligence (AI) research, studies applying machine learning to crime linkage are still in the early stages. We sought to understand the reasons behind this. To gain insight, we surveyed key data-driven work, including both statistical and machine learning approaches, and analyzed the challenges - whether implicit or explicit - associated with handling large amounts of data."}, {"title": "2 Related Work", "content": "Crime Linkage, a.k.a. Case Linkage or Behavioral Crime Linking, has been a subject of extensive study, particularly within domains such as Criminology and Psychology. Its origins trace back to the 1970s [1], with a notable surge in practical research observed in the 2000s [4]. Although related to criminal profiling [5], crime linkage specifically refers to \"the process of linking two or more crimes together on the basis of the crime scene behavior exhibited by an offender\" [10]. In other words, this discipline is interested in understanding pattern characteristics in criminal behavior that might suffice connections between which seem to be unrelated crimes, often in the context of serial offenders.\nCrime Linkage is underpinned by two assumptions in criminal behavior: consistency and distinctiveness. The latter posits that serial criminals exhibit patterned actions akin to a signature behavior [11], while the former suggests that this signature is unique enough to differentiate their criminal activity from others [10]. However, in terms of data-driven CL, Bennell et al. [12] introduced three other assumptions that challenge research in this area: the reliability of coded data within systems, the accuracy of the data, and analysts' ability to accurately link crimes using this data. Basically, the reliability and suitability of the data to draw conclusions on the link between crime remain the subject of debate [13].\nThe primary focus of this topic lies in identifying pairs or series of crimes committed by the same perpetrator. This field is of significant importance, and CL has already been used as evidence in court proceedings to implicate suspects [14, 15, 16]. In particular, Keppel documented the first case in Canada where crime linkage was used as evidence, which a decision later corroborated the result through DNA analysis [17]. However, the authors have debated whether and how pattern behavior can be used as evidence in court. Labuschagne [18] points out that a linkage decision should not be based only on computerized approaches, while Canter et al. [19] do not recommend exclusively experience-based decisions.\nIn 1993, the U.S. Supreme Court established guidelines for the incorporation of scientific evidence into legal proceedings, now enshrined in Rule 702, commonly known as the Daubert standard [20]. This landmark decision provided a framework to bolster the credibility of forensic science evidence. The standards outlined for admissible scientific evidence include factors such as reliability, peer review and publication, error rates, general acceptance within the scientific community, the existence of known standards, and applicability to the specific case at hand. In the context of Data-Driven Crime Linkage and its conformity with the Daubert standard, Pakkanen et al. [20] proposed an evaluation framework centered on three key aspects:\n\u2022 Consistent Behavior: This pertains to assessing the probability of consistency in linking one crime to another and the associated margin of error. It also involves determining to what extent the findings from specific samples can be generalized to broader populations. A comprehensive examination of the core attributes linking ostensibly distinct crimes becomes imperative.\n\u2022 Reliable Database: This aspect revolves around the meticulous coding of variables in databases. Given the subjective nature of variables, careful selection methods are essential yet challenging. In addition, determining which variables are crucial in establishing crime linkages warrants further investigation. Furthermore, databases should encompass not only solved cases but also unsolved ones. Thus, preliminary studies are needed to discern when a crime constitutes a part of a serial set to ensure ecological validity."}, {"title": "2.1 Modus Operandi in the Crime Linkage Context", "content": "As highlighted, understanding signature criminal behavior is pivotal to crime linkage. Commonly known as modus operandi, it refers to the patterned behavior exhibited by a perpetrator during criminal activities, aimed at safeguarding their identity, selecting a victim, ensuring the success of the crime, facilitating escape, and evading detection [31, 32, 33, 34, 35]. In the context of crime linkage, the aim is to gather sufficient evidence to discern these behavioral patterns and encapsulate them as a signature behavior. Assuming they are consistent and \u201cindividualizable\u201d (distinctiveness), these patterns can be utilized to identify serial offenders or establish connections between related crimes (for example, using MOs to cluster a network of offenders). Data-driven studies typically deal with a predefined set of MO attributes, usually coded by experts or directly inputted into databases. However, this approach somewhat contradicts the assumptions posited by Woodhams et al. (2007) [3] since a finite and discrete number of MO characteristics may limit the diverse possibilities of distinctiveness within offender behavior. It is expected that the signature behavior lies within the nuances of the crime scene rather than in a generalized combination of attributes. This will be further discussed in the challenges section.\nThe discussion of whether MO is sufficient to translate links in crime has been topic of many research discussions. In fact, certain studies have indicated that spatial analysis of crime (i.e. proximity of crimes) is a more effective feature for linking crimes compared to traditional MO [36]. Indeed, due to the dynamic nature of MO, extracting its key elements is a hard task that necessitates extensive experience [8]. This difficulty in delineating MO may contribute to the scarcity of data-driven studies in crime linkage, particularly in homicides [5], as it will be discussed later. It can be inferred that"}, {"title": "2.2 Data-driven studies", "content": "This section is dedicated to briefly outline the main applied studies on Crime Linkage, with a particular emphasis on data-driven methods, i.e. falling under the CCA approach. Four literature review papers were identified concerning crime linkage in practice. Woodhams et al. [37] provided an early review, discussing fundamental concepts and the primary challenges faced by CL at that time. Bennell et al. (2012) delved into the underlying assumptions of computerized crime linkage systems. In a subsequent work, authors in [38] analyzed evaluation measures of crime linkage, particularly focusing on the AUC (Area Under the Curve), and identified crime type, behavior domain, and distance as key factors affecting performance. While predominantly focused on criminal profiling, Fox et al. [5] dedicated a section to discussing the 17 papers compiled by Bennell et al. (2014), with a focus on the effect size of the studied samples. Davies et al. [39] conducted the most recent literature review on the topic, describing the challenges to obtain crime linkage in practice. Their focus extended beyond the methodology for crime linkage outcomes to encompass studies exploring the overall practice and usage of crime linkage, yielding 30 relevant papers. Simirlaly, this study concentrates specifically on practical methods for deriving crime linkage, particularly focusing on studies utilizing crime datasets. However, unlike previous works, this study will emphasize statistical/machine learning methods and the nuances of applying these techniques.\nIn this context, much of the research has focused on property crimes such as burglary [40, 36, 41, 42, 43, 44, 45, 6, 46, 47, 48, 49, 50, 2, 51], robbery [52, 53, 54, 45, 55, 56, 57], car theft [58, 59, 44], and arson [60]. In terms of crimes against individuals, there is a notable focus on sexual crimes (not necessarily involving murder) [61, 62, 63, 64, 65, 66, 67, 68], with three studies delving into homicide [42, 69, 70]. Additionally, there are studies where researchers have examined crime linkage across various crime types, including a variety of crime categories [71], burglaries, robberies, and car thefts [72, 73], and burglaries, robberies, and assaults in general [47]. Refer to the Appendix table (Section 6) to check other crime types related to topic in question in this paper.\nWithin purely statistical approaches, researchers have explored various methodologies to ascertain the probability of linking one crime to another, employing techniques such as logistic regression (LR), Naive Bayes, and decision trees (DT). Naive Bayes is based on Bayes' Theorem, which calculates the probability of a particular event occurring given the occurrence of another event. Despite its simplicity, the \"naive\" assumption assumes that features (variables) are independent of one another, which rarely holds in real-world scenarios but still often yields good results. For example, Porter (2016) took this a step further by utilizing the Bayes factor to inform the decision-making process regarding which model to employ [2]. The main advantage for using Bayes models is that the results are more easily interpret as compared to other more advanced machine learning techniques.\nThe main methodological preference among many researchers for CL is logistic regression [74]. This approach is suitable for CL, as the task typically involves binary classification-deciding whether crimes are linked or not. LR estimates the probability of crimes being linked based on a linear combination of input features, using a logistic function (sigmoid, for instance) to constrain the output between 0 and 1, which can be interpreted as a probability. During training, the model learns the optimal weights for the features and identifies a decision threshold, which can later be evaluated for performance. One limitation of this method is its assumption of a linear relationship between the input features (crime features) and the output (linkage decision), which may not accurately capture more complex or non-linear patterns in real-world crime data. Decision Trees have also being in CL context, but mainly as a comparison with LR approaches. For example, Tonkin et al. [73] demonstrated the superior performance of regression models over tree-based models and showcased that incorporating specific crime type behaviors could further enhance performance. The Appendix table (Section 6) provides more examples on how these models have been used.\nThis study will give more emphasis on more advanced machine learning techniques, particularly because these approaches have not been covered in previous literature surveys. We will also focus on CCA reactive linkages, as this method is preferred among researchers. However, other studies have explored machine learning clustering techniques to evaluate crime linkage decisions [48, 75, 76]. Additionally, while not strictly classified as machine learning, some authors have utilized fuzzy logic to assess crime linkage scenarios [77, 78, 79, 49]."}, {"title": "2.3 Machine Learning studies", "content": "With the advancements in Artificial Intelligence, numerous studies have harnessed these technologies for applications within the justice system. It is important to distinguish between crime prediction and crime linkage. Crime prediction, also known as Predictive Policing, has been the focus of numerous authors in Computer Science, employing a wide array of methodologies [80]. Essentially, crime prediction involves the creation of a model trained on big data, typically to detect crime locations, although it has also been used to predict the likelihood of an individual committing a crime [81]. In contrast, Crime Linkage is concerned with connecting one crime to another, potentially identifying the same offender. Within the realm of Machine Learning, there also exists a diverse range of methodologies to address the crime linkage problem.\nMachine Learning is the science behind Artificial Intelligence focused on discovering patterns and insights in large and complex datasets. While both statistics and ML share common foundations, they usually differ in their applications [82]. Statistics typically deals with well-defined models and smaller datasets, aiming to make inferences and understand relationships. In contrast, machine learning often handles larger, more intricate datasets, using advanced algorithms to uncover patterns and make predictions. Notably, Natural Language Processing (NLP) techniques, a branch from ML, have been employed on textual data from police reports to discern relationships among incidents and thereby establish case links [6, 46, 83, 84, 85, 86, 54]. Most of the NLP works focused on different techniques to retrieve information and extracting MO features from these police narratives. Additionally, some studies have utilized text vectorization techniques to compute similarity scores. Commonly referred to as embeddings, this approach involves transforming textual information into high-dimensional vectors, thereby capturing latent textual features that can be compared against other reports.\nA summary of data-driven studies on crime linkage can be found in the Appendix (Section 6). However, below we describe the main works that can be considered purely based on ML.\nChi et al. [57] implemented a simple three-layer neural network, with the middle layer comprising two nodes designed to calculate the similarity within input crime features (MOs). The third layer generated the final output similarity score between the two crimes. While the neural network automatically calculated weights to fit the model, the authors proposed the involvement of an experienced human in the loop to adjust the weights as needed. Additionally, they introduced a separability index to prune input features that did not contribute to the linkage output, thus enhancing the process. This approach not only improved the accuracy of linkage analysis but also revealed to analysts which input features were actually related to the crime linkages. The authors noted that this technique was successfully incorporated into a government security office in China.\nY.-S. Li and Qi [54] introduced a methodology to compare robbery cases in China by employing various steps to measure differences between two crimes. Their approach involved using absolute distance for numerical attributes, Jaccard's coefficient for categorical attributes, similarity between Word2Vec [87] embeddings of selected keywords, and Dynamic Time Warping (DTW) [88] Information Entropy [89] for assessing dissimilarities between the narratives of two crimes, also referred to as \"crime processes\".\nZhu and Xie (2021) proposed employing TF-IDF and Restricted Boltzmann Machine (RBM) [90] with regularization on a textual dataset of 911 calls to extract location, time, and MOs [45]\u2013 an approach they initially presented in their earlier work [91]. This unsupervised technique enabled them to determine if a crime series had been detected within a pool of crime incidents. However, personal narratives of crimes can inherit bias context [92, 93] and their method utilizing 911 calls and a bag of words approach may not be the best choice for detecting crime linkage. For instance, the word \"black\" was among the keywords identified by their method to be used as what they considered MO. Moreover, TF-IDF does not take into account the context in which the retrieved keywords were inserted, rendering it susceptible to bias detection towards longer documents [94]. More on textual embedding techniques will be discussed later.\nAnother comparable study is conducted by Solomon et al. [46], in which the authors leverage burglary police reports to extract 40 predefined MO details using fastText [95] and smooth inverse frequency (SIF) [96] embedding techniques. They then assess the similarity between the two crimes by incorporating the distance and time difference between the two cases into the MO vector. Subsequently, they input these MO vectors, along with the spatial-temporal differences, into a Siamese neural network [97] to determine the probability of these two inputs being identical. The authors demonstrated the efficacy of their methods in a different language (Hebrew) using narrative text from victims and dialogue between victims and police officers. While their techniques exhibited high performance in burglaries cases where a predefined set of MO may suffice to characterize the crime, it remains unclear whether these methods would also be applicable to crimes against persons [98].\nIn a pragmatic approach, Chohlas-Wood and Levine [99] from the New York Police Department (NYPD) developed an application called Patternizr. This tool utilizes a blend of structured information, including location, crime subcategory, modus operandi details (weapon, victim count, etc.), suspect information (weight, height, etc.), and unstructured data such as crime narrative complaints. The primary objective is not to compute the final crime linkage, akin to the objective of this research, but rather to furnish a list of the most similar cases to glean insights and enhance investigations. However, while the authors assert fairness by excluding the race attribute, other studies have demonstrated that this approach does not eliminate bias [83, 100]. Furthermore, they utilized Word2Vec which has also been demonstrated to carry potential bias in its embeddings [101, 102]."}, {"title": "3 Crime Linkage Framework", "content": "Overall, the crime linkage assessment process follows a similar structure among the studies reviewed. The pairwise comparison is illustrated in Figure 1. The primary goal is to extract variables that characterize each crime case (C1, C2,...Cn), which in our context are referred to as MO attributes. Next, the idea is to calculate similarity measurements between these attributes. Finally, all these similarity scores (SS) are averaged (or combined using other methods, such as weighted averaging) to determine a final score (FS). A score above a certain threshold is considered linked, while a score below that threshold is considered unlinked. However, just averaging the scores might not take into consideration other complexities of the criminal information, and thus a machine learning method might be necessary at this stage.\nIn summary, we can observe three steps in the CL process:\n1. Identifying MO attributes from each criminal case.\n2. Calculating similarity measures between each pair of crimes.\n3. Using Machine Learning to classify whether this pair is considered linked or unliked.\nMore details on each step are provided in the following subsections:"}, {"title": "3.1 MO variables", "content": "In this first step, the MO variables are either pre-defined and pulled from a database or extracted from crime narratives or reports. Although techniques vary, most approaches treat the MO as a set of finite attributes that characterize a particular crime. This may explain why most of the work has focused on property crimes, as these types of crimes tend to have more standardized criminal behaviors compared to crimes against persons [5]. This retrieval step is crucial because some level of expertise is necessary to understand which variables influence crime linkage analysis. Human coders, who either insert variables into the database (such as ViCAP [104]) or extract them from police data, are typically subjected to inter-rater reliability assessments to measure agreement in their results. As mentioned in Section 2, this has been a persistent issue in the domain, but it is important to address the significance of reliability in data-driven approaches for crime linkage systems [12]. In Machine Learning method the extraction can be done automatically, typically with the support of Natural Language Processing techniques that retrieves variables from reports, based on textual context or keywords. Lin et al. [105] proposed a feature selection process by calculating a index separability in order to prune data to better results in crime linkage. Solomon et al. [46] converted typical police questions into sentence embeddings to find MOs in massive amount of crime narratives.\nCommon attributes include the location and time of the event, as well as behavioral characteristics such as methods of trespassing, the weapon used, the number of victims, the type of target location, and others. These variables can be numerical, binary, categorical, or based on descriptive words. This step is important because the type of variable dictates the type of similarity measure used in the following step. It is worth noting that a categorical attribute will need to be converted to hot encoding or other sort of numbered format in order to serve as input into a ML algorithm.\nAs illustrated in the Appendix table (Section 6), a wide range of MO choices are available for selection in a given model. Nevertheless, location and time, or more precisely, spatiotemporal differences, emerged as some of the most consistent MO characteristics in the literature. Bennell et al. [40] demonstrated that even using just distance as a factor, without incorporating additional MO features, resulted in high accuracy scores. Similarly, Tonkin et al. [73] showed that both time and location are sufficient predictors for linking crimes, showing that residential burglaries and commercial robberies tend to happen in regions familiar to the criminal in short lapses of time. Beyond these, there appears to be little consistency among other MO attributes, as they tend to vary significantly depending on the type of crime and the data available.\nMany authors thus consider a crime as a vector of MOs. In this way, each crime case can be described as vector C = {X1, X2, ...Xk}, where X represents a specific MO or crime feature, and k is the total number of features or dimensions. Following this approach, it is essential to map and order every MO attribute correctly. This includes having policies to handle missing values or when certain behaviors are not present. As it will be shown in the next step, each MO needs to be compared pairwise, making the order of the vector crucial, as a similarity cannot be calculated between different types of MOs. For example, it is illogical to compare the location of an event with the time of the event. Some studies have mapped MOs based on the degree of a particular behavior. For instance, a crime analyst might evaluate the level of violence in a particular case. This approach is common when working with fuzzy logic models, where a degree of membership is required to characterize sets of MOs [49, 79, 78]."}, {"title": "3.2 Similarity measures", "content": "As mentioned earlier, similarity scores are used to compare how similar one crime is to another. Most studies use a single method to contrast each feature in the crime vector, while others employ a combination of methods depending on the feature type. The most common measurements are as follows:\n3.2.1 Numerical attributes\nOne of the simplest methods for measuring similarity between features, particularly with quantitative attributes, is to use the absolute distance or difference between pairs of attributes. This is rather a dissimilarity score and thus a value close to zero indicates greater similarity. In crime linkage studies, common numerical features are time and location. Researchers often calculate similarity based on the distance between two points in a map (using Euclidean distance, for example) or the difference in time (measured in days, hours, or exact values). This approach is supported by criminology literature, which suggests that crimes committed by the same offender are likely to occur in close proximity both spatially and temporally [58, 106, 107].\n3.2.2 Categorical attributes\nThere are many different was to calculate similarity between categorical values [108]. The most common technique among CL studies is the Jaccard's coeficient (J) [109]. Here the coefficient measures not only a single behavior but a collection of them and calculates the ratio between common features and the total number of features (Equation 1). The range of the Jaccard coefficient spans from 0, indicating no common features, to 1, indicating identical vector dimensions.\nJ(C1, C2) = \\frac{C1 \\cap C2}{C1 \\cup C2}\nwhere C\u2081 and C2 are the sets being compared.\nAs an example, imagine that we have a case where MOs are \"Entrance by Window\u201d, \u201cHouse without Fences\", and \"Criminal Record = Yes\", and another where we have \"Entrance by Door\u201d, \u201cHouse without Fences\u201d, and \u201cCriminal Record = Yes\". Comparing these two cases, Jaccard measurement between them would be 2/3."}, {"title": "3.2.3 Cosine Similarity", "content": "Considering NLP studies on crime linkage, a typical similarity measure is the cosine similarity (also found in the literature as normalization inner product or word-to-word similarity), which has been calculated between word or sentence embeddings. Embeddings are the product of the converstion of textual data into multidimensional, using techniques such as Word2Vec [87]. These vectors capture the semantic relationships between words, and thus, similar words are likely to be close to each other in this multidimensional space. Cosine similarity is then a suitable method to calculate the similarity between two words. This approach can account for word variations existing in categorical attributes, potentially offering a better solution than the Jaccard coefficient in some situations. The Cosine Similarity formula between two vectors, A and B, can be see in Equation 4.\nCosine Similarity(A, B) = \\frac{A\\cdot B}{||A||||B||} = \\frac{\\sum_{i=1}^{n} A_i B_i}{\\sqrt{\\sum_{i=1}^{n} A_i^2} \\sqrt{\\sum_{i=1}^{n} B_i^2}}"}, {"title": "3.3 Machine Learning Classification", "content": "The use of machine learning techniques in crime linkage is primarily aimed at classifying whether certain features of a crime indicate a linked crime or associating a crime with a specific crime series, as it can be seen in Figure 3. These predictions are made after training a chosen algorithm on a large dataset. When data was scarce, simpler algorithms such as linear regression or decision trees were oftenly used. In our study, we observed that most CL approaches input similarity scores between pairs of crimes into the algorithms, rather than using the MO attributes directly. The choice of input features depends on the specific elements the researcher deems relevant for capturing crime patterns. For instance, Chohlas-Wood et al. [99] incorporated historical arrest data alongside similarity scores, allowing the model to learn from this additional information as well.\nBelow is a brief summary of the most common algorithms found in our literature:\n\u2022 Logistic Regression (LR): Logistic Regression is a statistical model primarily used for binary classification tasks. It predicts the probability that a given input belongs to a particular class using the logistic function (sigmoid function). This results in outputs that range between 0 and 1, representing class probabilities. It is simple, interpretable, and works well for linearly separable data, making it a popular choice for problems like spam detection and medical diagnosis.\n\u2022 Decision Tree (DT): A Decision Tree is a non-parametric supervised learning method used for classification and regression. It splits the data into subsets based on feature value tests, creating a tree-like model of decisions and their possible consequences. This model is easy to understand and visualize, as it mimics human decision-making processes. However, decision trees can be prone to overfitting, especially with complex datasets, although they handle both numerical and categorical data effectively.\n\u2022 Random Forest (RF): Random Forest is an ensemble learning method that constructs multiple decision trees during training and outputs the mode of the classes for classification or the mean prediction for regression of the individual trees. This approach reduces overfitting compared to individual decision trees and enhances model robustness and accuracy. It is particularly effective in handling large datasets and high-dimensional spaces, making it suitable for a variety of applications, from financial modeling to image classification.\n\u2022 Support Vector Machine (SVM): Support Vector Machine (SVM) is a supervised learning algorithm used for both classification and regression tasks. It finds the hyperplane that best separates the data into classes in high-dimensional space, with an emphasis on maximizing the margin between different classes. SVMs are effective in high-dimensional spaces and can handle non-linear data through the use of kernel tricks. They are particularly useful in applications like text classification, image recognition, and bioinformatics.\n\u2022 k-Nearest Neighbors (k-NN): k-Nearest Neighbors (k-NN) is an instance-based learning algorithm used for classification and regression. It classifies a data point based on the majority class of its k-nearest neighbors in the feature space. The simplicity of k-NN makes it easy to implement, but it is sensitive to the choice of k and the distance metric used. It is particularly useful for pattern recognition tasks, such as handwriting digit classification and recommendation systems.\n\u2022 Neural Networks (NN): Neural Networks are a set of algorithms modeled after the human brain, used for a wide range of tasks, including classification, regression, and complex tasks like image and speech recognition. They consist of layers of interconnected nodes (neurons) that can capture and model complex patterns and non-linear relationships in data. Neural Networks are highly flexible and powerful, but they require large amounts of data and significant computational resources, making them suitable for applications in artificial intelligence and deep learning.\n\u2022 Gradient Boosting Decision Tree (GBDT): Gradient Boosting Decision Tree (GBDT) is an ensemble learning method that builds multiple decision trees sequentially. Each new tree is trained to correct the errors made by the previous ones, and the trees are combined to make a final prediction. This sequential approach reduces overfitting and increases model accuracy, making GBDT highly effective for a variety of tasks, including ranking, classification, and regression. Careful tuning of parameters like learning rate and the number of trees is essential for optimal performance.\nIn supervised machine learning, the training process requires labeled data. In crime linkage studies, this means that it must be known in advance whether crimes are linked. In practice, this requires that an offender responsible for multiple crimes has already been convicted and that this information is recorded in a relevant database. However, in many cases, a significant portion of the dataset consists of unlabeled data-crimes that are still under investigation. While this unlabeled data can be used to predict whether a crime is linked or belongs to a known offender series, it cannot be used for training. Another major challenge in supervised learning is the class imbalance. Ideally, the model needs examples of both linked and unlinked crimes for training, but in reality, there is often a significant disparity between these two classes, with far more unlinked cases than linked ones. This imbalance can cause the model to favor the majority class, leading to biased predictions. We will explore this issue in greater detail in the following section.\nWhile crime linkage is typically considered as a binary classification problem, Li and Shao [84] demonstrated the suitability of a three-way analysis. In addition to the linked and unlinked classes, they introduced a third category called \"boundary\". This category encompasses cases that are difficult to classify definitively, which are then referred to a human crime analyst for further evaluation. The challenge lies in minimizing the number of cases that fall into this boundary region, as overloading analysts with too many cases is undesirable, while still maintaining high uncertainty within this region. Increasing the number of cases in the boundary region can enhance the measurement of uncertainty but also places greater demands on human analysis.\nAlthough less common, some studies have approached the crime linkage problem using unsupervised methods. This approach is appealing in the crime linkage context because it addresses the inherent issue of class imbalance and takes out the burden of labeling data. Some studies have explored clustering methods to analyze associations between different crime series [76, 75, 77, 48]. However, designing a model to identify connections between crimes without knowing which cases are actually linked presents a big challenge. For instance, Zhu et al. (2022) modeled crime linkage using a Hawkes process, where incidents are governed by an intensity function that decays over time [6]. This approach, inspired by the behavior of earthquakes, posits that crimes can trigger other crimes, creating a sort of network of linked or associated events. This is somewhat analogous to the predictive policing software PredPol, which employs the Epidemic-Type Aftershock Sequence (ETAS) model [119]."}, {"title": "3.4 Evaluation Metrics", "content": "Within machine learning studies, it is common to separate data to test the trained model. As consequence, the researcher needs to selected an evaluation method to confirm whether his model provides a good performance. The thresholds to determine whether the model had a good performance will depend on the type of crime and the metrics used. There"}, {"title": "4 Challenges in Crime Linkage", "content": "Applying machine learning to large-scale crime data is valuable for uncovering the nuances and complexities of criminal behavior patterns. However, this field presents several challenges that require careful consideration. We have identified four key challenges associated with working with these approaches. A related work comes from Yang et al. [122], although their survey is based on a very short pool of papers."}, {"title": "4.1 Imbalanced Data", "content": "Probably the most common issues encountered in the literature when using big amounts of data to crime linkage is the problem of data imbalance. In crime series analysis, most available data points are typically unlinked. Although recidivism is not rare in criminal behavior, this imbalance can arise for various reasons, such as ongoing investigations where no offender has been identified yet or limitations in police infrastructure, such as jurisdictional constraints, which hinder the ability to connect offenders. Consequently, when preparing the data, there is often a decision to determine some cases as labeled (linked or not) and others as unlabeled. It is anticipated that there will be fewer serial crimes compared to one-off cases.\nIn these imbalanced datasets, machine learning models tend to favor the majority class, typically the non-linked cases, due to several factors. First, most algorithms aim to minimize overall error during training, which can lead them to focus on the majority class to achieve higher accuracy. When the vast majority of cases are non-linked, the model can achieve a seemingly high accuracy rate simply by predicting all cases as non-linked, as the model is trained to minimize error across the dataset. This tendency to favor the majority class can result in poor performance when predicting the minority class (linked cases). For example, a model may produce an accuracy of 90% in a dataset where 95% of the cases are non-linked, yet it may fail to identify any linked cases at all. This scenario highlights a critical issue: accuracy alone is an inadequate metric for evaluating model performance in imbalanced contexts. Instead, other metrics such as precision, recall, F1-score, and the area under the receiver operating characteristic curve (AUC-ROC) provide a more nuanced understanding of model performance, especially for the minority class."}, {"title": "4.2 Bias", "content": "Although the issue of bias is not extensively discussed in the specific literature", "125": ".", "126": ".", "stage": "preprocessing (trained data), in-processing (withing the algorithm itself), and post-processing (after training) [127, 128", "45": "where the author used 911 call narratives to train their model, using TF-IDF to extract keywords from the texts. The word \"black\" was among the keywords identified by their method, which would later to be used as a particular attibute to describe that crime. Although extracting keywords from documents seems a good approach to characterize a document, in a police context, it is important to either debias the dataset first or evaluate how potential biased keywords are affecting your results (and workaround them).\nChohlas-Wood and Levine [99"}]}