{"title": "U-MedSAM: Uncertainty-aware MedSAM for Medical Image Segmentation", "authors": ["Xin Wang", "Xiaoyu Liu", "Peng Huang", "Pu Huang", "Shu Hu", "Hongtu Zhu"], "abstract": "Medical Image Foundation Models have proven to be powerful tools for mask prediction across various datasets. However, accurately assessing the uncertainty of their predictions remains a significant challenge. To address this, we propose a new model, U-MedSAM, which integrates the MedSAM model with an uncertainty-aware loss function and the Sharpness-Aware Minimization (SharpMin) optimizer. The uncertainty-aware loss function automatically combines region-based, distribution-based, and pixel-based loss designs to enhance segmentation accuracy and robustness. SharpMin improves generalization by finding flat minima in the loss landscape, thereby reducing overfitting. Our method was evaluated in the CVPR24 MedSAM on Laptop challenge, where U-MedSAM demonstrated promising performance.", "sections": [{"title": "1 Introduction", "content": "Medical image segmentation is vital in clinical practice, enabling precise medicine assessing therapeutic outcomes, and disease diagnosis by delineating organ boundaries and pathological regions, enhancing anatomical understanding, and abnormality detection . Early segmentation models for medical images are typically designed for specific tasks with limited data. They might not handle the complex patterns and minute variations in medical images, which are often critical for clinical diagnosis and health science study. Recently, foundation models, such as MedSAM  have been developed for medical image segmentation which are more strong, efficient, and applicable to different data modalities and situations. However, the uncertainty of the learning process associated with MedSAM on the diverse dataset has not been thoroughly investigated. By understanding this uncertainty,"}, {"title": "2 Method", "content": "This section will describe the entire workflow and implementation details.  shows an overview of our proposed method."}, {"title": "2.1 Preprocessing", "content": "We follow the preprocessing in LiteMedSAM implementation (baeline) ."}, {"title": "2.2 Proposed Method", "content": "Uncertainty-aware Auto-learning. Uncertainty-aware learning enables the model to adapt its learning process based on detected uncertainties, enhancing resilience and precision by focusing on confident predictions and minimizing the influence of ambiguous ones . This optimization of the training process across various datasets results in improved overall performance . By incorporating uncertainty into the loss computation, the model can dynamically assign weights to each loss component . This strategy effectively balances global and local accuracy while mitigating the impact of class imbalance. This approach allows the model to prioritize learning from reliable instances and reduce the impact of potentially erroneous or ambiguous data. Consequently, the model becomes more resilient to noisy or ambiguous data, leading to significantly improved segmentation performance."}, {"title": "3 Experiments", "content": ""}, {"title": "3.1 Dataset and evaluation measures", "content": "We only used the challenge dataset for model development. The evaluation metrics consist of two accuracy measures: the Dice Similarity Coefficient (DSC) and"}, {"title": "3.2 Implementation details", "content": "Environment settings The development environments and requirements are presented in Table 1.\nStage 1. Code and models are available at: https://github.com/liangzw599/\nCo-developed-by-LiteMedSAM.\nStage 2 (Post challenge analysis). Code and models are available at: https:\n//github.com/liangzw599/Co-developed-by-LiteMedSAM.\nTraining protocols We follow the training protocols in LiteMedSAM imple-\nmentation (baseline) ."}, {"title": "4 Results and discussion", "content": ""}, {"title": "4.1 Quantitative results on validation set", "content": "Table 3 summarizes these results. The results demonstrate that incorporating uncertainty-aware loss and the SharpMin optimization indeed improves segmentation accuracy.\nTraining using only the SD loss yields 83.86% DSC. In comparison, training using the uncertainty-aware loss (which incorporates the DC loss, CE loss, and focused loss), enhances DSC to 85.48%. This result shows the capability of the uncertainty-aware loss to increase the robustness and accuracy of models by prioritizing confident predictions and minimizing the impact of uncertain ones. It effectively addresses the limitations of using a single loss function by balancing various aspects of the segmentation task."}, {"title": "4.2 Qualitative results on validation set", "content": "We show some examples with good segmentation results in Fig. 3 and examples with bad segmentation results in Fig. 4."}, {"title": "4.3 Segmentation efficiency results on validation set", "content": "As shown in Table 4, we compared the running speed of the proposed method to the LiteMedSAM (baseline) ."}, {"title": "4.4 Results on final testing set", "content": "This is a placeholder. We will announce the testing results for Post-challenge analysis."}, {"title": "4.5 Limitation and future work", "content": "Despite achieving promising dice scores, we did not optimize the model's speed, encountering limitations in this area.\nIn future work, we will explore various model compression techniques to address these speed constraints. Techniques such as quantization and tensor compression will be investigated to enhance the model's efficiency. Additionally, we will examine other advanced methods and approaches to further improve the performance and speed of the model. Our goal is to balance high accuracy with faster processing times, ensuring the model's effectiveness and efficiency for practical applications. By integrating these enhancements, we aim to develop a more robust and versatile model capable of handling real-world scenarios with greater ease and reliability."}]}