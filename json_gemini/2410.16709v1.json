{"title": "Universal approximation property of ODENet and ResNet with a single activation function", "authors": ["Masato Kimura", "Kazunori Matsui", "Yosuke Mizuno"], "abstract": "We study a universal approximation property of ODENet and ResNet. The ODENet\nis a map from an initial value to the final value of an ODE system in a finite interval. It\nis considered a mathematical model of a ResNet-type deep learning system. We consider\ndynamical systems with vector fields given by a single composition of the activation function\nand an affine mapping, which is the most common choice of the ODENet or ResNet vector\nfield in actual machine learning systems. We show that such an ODENet and ResNet with\na restricted vector field can uniformly approximate ODENet with a general vector field.", "sections": [{"title": "1 Introduction", "content": "Neural networks have significantly impacted computer vision, natural language processing, and learning\nmethods [24]. Historically, these networks have been seen as models inspired by the human brain and eye\n[9, 20]. A neural network, with the input layer as layer 0, the output layer as layer L, and the dimensions\nof each layer as $N\\in \\mathbb{N}$, is represented by the following equations:\n\n$\\begin{cases}\nx^{(l+1)} = f^{(l)} (x^{(l)}) \\quad (l = 0, 1, . . ., L - 1),\n\\\\x^{(0)} = \\xi \\in D,\n\\end{cases}$\n\nwhere $f^{(l)} : \\mathbb{R}^N \\rightarrow \\mathbb{R}^N$ and $D\\subset \\mathbb{R}^N$ is a bounded closed subset. The network's input and output are\n$\\xi$ and $x^{(L)}$, respectively. Neural networks with a large number of layers are called deep networks and\nperform better than single-hidden-layer neural networks for large-scale and high-dimensional challenges.\nNotable models like AlexNet [16] and GoogLeNet [26] contain many layers.\nHowever, if the depth is overly increased, the accuracy might stagnate or degrade [13]. Additionally,\ngradient vanishing or exploding issues may arise in deeper networks, making these networks harder to\ntrain [3, 10]. To address these issues, the authors in [14] recommended using residual learning to facilitate\nthe training of considerably deeper networks than previously used. Such a network is called a residual\nnetwork or ResNet, which has the form:\n\n$\\begin{cases}\nx^{(l+1)} = x^{(l)} + f^{(l)} (x^{(l)}) \\quad (l = 0,1,..., L - 1),\n\\\\x^{(0)} = \\xi \\in D.\n\\end{cases}$\n(1.1)\nResNet can be viewed as an explicit discretization of a system of ordinary differential equations [5].\nChoosing a small $h > 0$ and denoting $f^{(l)}/h$ again by $f^{(l)}$ in (1.1), we obtain\n\n$\\begin{cases}\nx^{(l+1)} = x^{(l)} + hf^{(l)}(x^{(l)}) \\quad (l = 0,1,..., L - 1),\n\\\\x^{(0)} = \\xi \\in D,\n\\end{cases}$\n(1.2)"}, {"title": "2 ODENet and universal approximation property", "content": "For $a = (a_1, a_2,..., a_N)^\\top, b = (b_1, b_2, ..., b_N)^\\top \\in \\mathbb{R}^N$, the Hadamard product of a and b is defined by\n\n$a \\odot b := (a_1b_1, a_2b_2,...,a_Nb_N) \\in \\mathbb{R}^N$.\n(2.1)\nFor a function $f : \\mathbb{R}^N \\times [0, T] \\rightarrow \\mathbb{R}^N$, we define its Lipschitz constant by\n\n$Lip(f) := sup\\left\\{ \\frac{||f(z,t) - f(\\zeta,t)||}{||z - \\zeta||} : z, \\zeta \\in \\mathbb{R}^N, z \\neq \\zeta, t \\in [0,T]\\right\\}$,\nand, if $Lip(f) < \\infty$, we say that f satisfies a Lipschitz condition with respect to x.\nWe define a solution to the system of ODEs (1.3) as\n\n$\\begin{cases}\nx(t) = \\xi + \\int_0^t f(x(s), s)ds \\quad (0 \\leq t \\leq T),\n\\\\x \\in C^0 ([0, T]; \\mathbb{R}^N).\n\\end{cases}$\n(2.2)"}, {"title": "3 Main theorems", "content": "Theorem 3.1 (UAP for ODENet). It holds that\n\n$\\overline{S(F)^{C^0(D;\\mathbb{R}^N)}} = \\overline{S(H)^{C^0(D;\\mathbb{R}^N)}}$,\ni.e., for given $F \\in \\overline{S(F)^{C^0 (D;\\mathbb{R}^N)}}$ and $\\epsilon > 0$, there exists $h \\in H$ such that\n\n$||F - S_h(T)||_{C^0 (D;\\mathbb{R}^N)} < \\epsilon$.\nTheorem 3.2. It holds that\n\n$\\overline{S(F)^{L^p(D;\\mathbb{R}^N)}} = \\overline{S(H)^{L^p(D;\\mathbb{R}^N)}}$,\ni.e., for given $F \\in \\overline{S(F)^{L^p(D;\\mathbb{R}^N)}}$ and $\\epsilon > 0$, there exists $h \\in H$ such that\n\n$||F - S_h(T)||_{L^p(D;\\mathbb{R}^N)} < \\epsilon$.\nHere we show that, in general, any $F\\in C^0(D; \\mathbb{R}^N)$ cannot be approximated by $S_f(T)$.\nProposition 3.5 ([30]). Let $N = 1$, $D = [-1,1]$, and let $F : D \\rightarrow \\mathbb{R}$ satisfy\n\n$F(\\xi) = -\\xi \\quad (\\xi\\in D)$.\nThen, we have $||F - S_f(T)||_{C^0(D;\\mathbb{R})} \\geq 1$ for all $f \\in F$.\nBy Theorem 3.1, we also obtain the following theorem.\nTheorem 3.6. For all $f \\in F$ and $\\epsilon > 0$, there exists $s^{res} \\in S^{res}$ such that\n\n$||S_f(T) - s^{res} ||_{C^0(D;\\mathbb{R}^N)} < \\epsilon$."}, {"title": "4 Preliminary results", "content": "Theorem 4.1 (Existence and uniqueness of solutions). Let $f : \\mathbb{R}^N \\times [0,T] \\rightarrow \\mathbb{R}^N$ be measurable and\nsatisfy (2.3). If there exists $\\xi_0 \\in \\mathbb{R}^N$ such that $f(\\xi_0,\\cdot) \\in L^\\infty(0,T)$, then there exists a unique solution\n$x(t)$ to (2.2). In particular, if f satisfies (2.3) and (2.4), then there exist a unique solution x(t) to (2.2).\nProof. We prove Theorem 4.1 using Picard's successive approximation method. Let $F_0 = ||f(\\xi_0,\\cdot)||_{L^\\infty(0,T)}$.\nFirst, we show the existence of a solution x(t). Consider the following sequence of functions:\n\n$\\begin{cases}\nx_0(t) := \\xi_0 \\quad (0 \\leq t \\leq T)\\\\\nx_n(t) := \\xi_0 + \\int_0^t f(x_{n-1}(s), s)ds \\quad (0 \\leq t \\leq T) \\quad (n = 1, 2, ...).\n\\end{cases}$\n(4.1)\nThe sequence {$x_n$}$_{n=0}^\\infty \\subset C^0 ([0, T]; \\mathbb{R}^N)$ satisfies, for all $n = 1, 2, ...$ and $0 \\leq t \\leq T$,\n\n$||x_n(t) - x_{n-1}(t)|| \\leq F_0 \\frac{(Lip(f)t)^n}{n!}$,\n(4.2)\nwhich can be proved by induction. Hence, it holds that for all $m \\geq l \\geq 1$,\n\n$||x_m(t) - x_l(t)|| \\leq \\sum_{j=l+1}^m ||x_j(t) - x_{j-1}(t)|| \\leq \\frac{F_0}{(Lip(f))} \\sum_{j=l+1}^m \\frac{(Lip(f)T)^j}{j!} \\rightarrow 0$\nas $l \\rightarrow \\infty$. Therefore, {$x_n$}$_{n=1}^\\infty$ is a Cauchy sequence in $C^0([0,T])$ and there exists $x \\in C^0([0,T])$ such\nthat\n\n$x_n \\rightarrow x \\quad on [0, T] \\quad as \\quad n\\rightarrow\\infty$.\nSince we have that\n\n$\\int_0^t f(x_n(s), s)ds - \\int_0^t f(x(s), s)ds|| \\leq \\int_0^t ||f(x_n(s), s) - f(x(s), s)||ds \\leq Lip(f) \\int_0^t ||x_n(s) - x(s)||ds$\n$\\leq Lip(f)T||x_n - x||_{C^0 ([0,T])} \\rightarrow 0$\nas $n \\rightarrow \\infty$. we obtain that $x(t) = \\xi + \\int_0^t f(x(s), s)ds \\quad (0 \\leq t \\leq T)$.\nSecond, we show the uniqueness of x using contradiction. Suppose that there exist two solutions x, $\\bar{x}$\nsatisfying $x \\neq \\bar{x}$. Then, it holds that\n\n$||x(t) - \\bar{x}(t)|| \\leq \\int_0^t ||f(x(s), s) - f(\\bar{x}(s), s)||ds \\leq Lip(f) \\int_0^t ||x(s) - \\bar{x}(s)||ds$.\nBy Gronwall's inequality, we have that\n\n$||x(t) - \\bar{x}(t)|| \\leq 0 \\cdot e^{Lip(f)t} = 0$.\nIt means $x = \\bar{x}$. But this contradicts the assumption. Therefore, the solution to (2.2) is unique.\nLemma 4.2. Under the assumption of Theorem 4.1, we have that\n\n$||S_f(t)\\xi_0 - \\xi_0|| \\leq M \\quad (0 \\leq t \\leq T)$,\nwhere $M = F_0Te^{Lip(f)T}$ and $F_0 = ||f(\\xi_0,\\cdot)||_{L^\\infty(0,T)}$.\nProof. Let x(t) = $S_f(t)\\xi$ ($0 \\leq t \\leq T$). It holds that\n\n$||x(t) - \\xi_0|| = ||\\int_0^t f(x(s), s) ds|| = ||\\int_0^t (f(x(s), s) - f(\\xi_0, s) + f(\\xi_0, s)) ds|| \\leq \\int_0^t ||f(x(s), s) - f(\\xi_0, s)||ds + ||\\int_0^t F_0 ds||\n$\\leq Lip(f) \\int_0^t ||x(s) - \\xi_0||ds + F_0T$.\nBy Gronwall's inequality, we have\n\n$||x(t) - \\xi_0|| \\leq F_0Te^{Lip(f)t} < F_0Te^{Lip(f)T}$.\nBy (2.3) and (2.4), $f(\\cdot,t)$ is continuous on $\\mathbb{R}^N$ for all $0 \\leq t \\leq T$, and $f \\in L^\\infty(0,T; C^0(D))$. By\nLemma 4.2, it holds that for all $\\xi \\in D$,\n\n$||S_f(t)\\xi - \\xi|| < ||f||_{L^\\infty(0,T;C^0(D))}Te^{Lip(f)T}$.\nHence, if we define $E = {\\xi\\in\\mathbb{R}^N | ||\\xi - \\xi|| \\leq ||f||_{L^\\infty(0,T;C^0(D))}Te^{Lip(f)T}, \\xi \\in D}$, then it holds that\n\n$S_f(t)\\xi\\in E \\quad (\\xi \\in D, 0 \\leq t \\leq T)$.\nLemma 4.3. Let $f, g : \\mathbb{R}^N \\times [0,T] \\rightarrow \\mathbb{R}^N$ satisfy (2.3) and (2.4). Let $E \\subset \\mathbb{R}^N$ be a bounded closed subset\nand satisfy that\n\n$E \\supset {S_f(t)\\xi | \\xi \\in D, 0 \\leq t \\leq T}$.\nThen, we have\n\n$||S_f(t) - S_g(t)||_{C^0(D)} \\leq ||f - g||_{L^\\infty(0,T;C^0(E))}Te^{Lip(f)T} \\quad (0 \\leq t \\leq T)$.\nProof. Let $x_f(t) = S_f(t)$ and $x_g(t) = S_g(t)$ ($0 \\leq t \\leq T, \\xi \\in D$). Then, it holds that for all 0<t$\\leq$T\nand $\\xi \\in D$,\n\n$||x_f(t) - x_g(t)|| = ||\\int_0^t f(x_f(s), s) - g(x_g(s), s)ds||\n$< ||\\int_0^t (f(x_f(s),s) - f(x_g(s), s)) + (f(x_g(s), s) - g(x_g(s), s))ds||\n$\\leq \\int_0^t ||f(x_f(s),s) - f(x_g(s), s)||ds + \\int_0^t ||f(x_g(s), s) - g(x_g(s), s)||ds$\n$\\leq Lip(f) \\int_0^t ||x_f(s) - x_g(s)||ds + ||f - g||_{L^1(0,T;C^0(E))}$.\nHence, by Gronwall's inequality,\n\n$||x_f(t) - x_g(t)|| \\leq (||\\xi - \\xi|| + T||f - g||_{c^0(B_{\\alpha})}) \\cdot e^{Lip(f)t} < (||\\xi - \\xi|| + T||f - g||_{c^0(B_{\\alpha})}) \\cdot e^{Lip(f)T}$,\nwhich holds for all $\\xi \\in D$ and implies the conclusion.\nLemma 4.4. Given $\\delta > 0$, there exist $K \\in \\mathbb{N}$ and {$(\\alpha_i, \\beta_i, \\gamma_i)$}$_{i=1}^K \\subset \\mathbb{R}^N \\times \\mathbb{R}^{N\\times N} \\times \\mathbb{R}^N$ such that for all\n$x \\in D$,\n\n$max_{x\\in D} ||f(x) - \\sum_{i=1}^K \\alpha_i \\odot \\sigma(\\beta_ix + \\gamma_i)|| < \\delta$.\nProof. Let $f(x) = (f_1(x), f_2(x), ..., f_n(x))^\\top$. Since $\\sigma$ has UAP, for all $\\delta > 0$ and l = 1, 2, . . ., N, there\nexist $K_l \\in \\mathbb{N}$ and {$(\\alpha_i^{(l)}, \\beta_i^{(l)}, \\gamma_i^{(l)})$}$_{i=1}^{K_l} \\subset \\mathbb{R} \\times \\mathbb{R}^{N} \\times \\mathbb{R}$ such that for all $x \\in D$,\n\n$||f_l(x) - \\sum_{i=1}^{K_l} \\alpha_i^{(l)} \\sigma(\\beta_i^{(l)}x + \\gamma_i^{(l)})|| < \\delta$.\nLet $K := max_{l=1,2,...,L} K_l$. We define {$(\\hat{\\alpha}_i^{(l)}, \\hat{\\beta}_i^{(l)}, \\hat{\\gamma}_i^{(l)})$}$_{l=1,2,...,L} \\in \\mathbb{R} \\times \\mathbb{R} \\times \\mathbb{R}$ as for l = 1, 2, ..., L,\n\n$(\\hat{\\alpha}_i^{(l)}, \\hat{\\beta}_i^{(l)}, \\hat{\\gamma}_i^{(l)}):=(\\alpha_i^{(l)}, \\beta_i^{(l)}, \\gamma_i^{(l)}) \\quad (i = 1,2,..., K_l)$\n\n$(\\hat{\\alpha}_i^{(l)}, \\hat{\\beta}_i^{(l)}, \\hat{\\gamma}_i^{(l)}):=(0,0,0) \\quad (i = K_l + 1, K_l + 2, . . ., K)$\nand we set for i = 1, 2, ..., K,\n\n$\\alpha_i := (\\alpha_i^{(1)}, \\alpha_i^{(2)}, ..., \\alpha_i^{(N)})^\\top \\in\\mathbb{R}^N$,\n$\\beta_i := (\\beta_i^{(1)}, \\beta_i^{(2)}, ..., \\beta_i^{(N)})^\\top \\in\\mathbb{R}^{N\\times N}$,\n$\\gamma_i := (\\gamma_i^{(1)}, \\gamma_i^{(2)}, ..., \\gamma_i^{(N)})^\\top \\in\\mathbb{R}^N$.\nThen, it holds that for all $x \\in D$\n\n$max_{x\\in D} ||f(x) - \\sum_{i=1}^K \\alpha_i \\odot \\sigma(\\beta_ix + \\gamma_i)|| \\leq \\delta$.\nTheorem 4.5 ([22]). Let $f : \\mathbb{R}^N \\times \\mathbb{R} \\rightarrow \\mathbb{R}^N$ satisfy $f(x,t + T) = f(x,t)$ for a.e. $(x,t) \\in \\mathbb{R}^N \\times \\mathbb{R}$ for a\nconstant $T > 0$. For $m \\in \\mathbb{N}$, we define\n\n$f_m(x,t) := f(x, mt)$,\n$f(x) := \\frac{1}{T} \\int_0^T f(x,t)dt$.\nThen, for all $\\xi \\in D$,\n\n$S_{f_m}(\\cdot)\\xi \\rightarrow S_{\\bar{f}}(\\cdot)\\xi \\quad on \\quad [0, T] \\quad as \\quad m\\rightarrow\\infty$.\n(4.3)\n(4.4)"}, {"title": "5 Proofs of the main theorems", "content": "For Theorems 3.1 and 3.2, it is enough to prove that $F\\in S(F)$ belongs to $\\overline{S(H)^{C^0(D;\\mathbb{R}^N)}}$. We divide the\nproof of Theorem 3.1 into three steps. For a given $\\epsilon > 0$, we aim to derive the following inequality: for\nall $0 \\leq t \\leq T$,\n\n$||S_f(t) - S_h(t)||_{C^0(D;\\mathbb{R}^N)}$\n$<||S_f(t) - S_{f_L} (t)||_{C^0(D;\\mathbb{R}^N)} + ||S_{f_L} (t) - S_{h_1} (t)||_{C^0(D;\\mathbb{R}^N)} + ||S_{h_1} (t) - S_{h}(t)||_{C^0(D;\\mathbb{R}^N)}$\n$<\\frac{\\epsilon}{3} + \\frac{\\epsilon}{3} + \\frac{\\epsilon}{3} = \\epsilon$,\nwhere $f_L$ is a piecewise constant approximation of f in the time direction, $h_1$ is an approximation of $f_L$\nthat can be expressed as $\\alpha \\odot \\sigma(\\beta x + \\gamma)$ at each time, and h is a smooth approximation of $h_L$.\n5.1 Proof of $||S_f(t) - S_{f_L}(t)||_{C^0(D;\\mathbb{R}^N)} < \\frac{\\epsilon}{3}$\nLet $L \\in \\mathbb{N}$, $r := \\frac{T}{L}$, $t_l := lr \\quad (l = 0, 1, ..., L)$, $f^{(l)} (x) := f(x,t_l)$, and $f_L(x,t) := f^{(l)}(x) \\quad (t_{l-1} < t < t_l, l =\n1,2,..., L)$. By Lemma 4.2, we know that $S_f(t), S_{f_L} (t)\\xi\\in B_1 = B_R$ for all $\\xi \\in D$ and $0 \\leq t \\leq T$,\nwhere $R = max_{\\xi\\in D} ||\\xi|| + Te^{Lip(f)T} || f ||_{L^\\infty(0,T;C^0 (D))}$. By Lemma 4.2 and the uniform continuity of f, for all\ngiven $\\epsilon > 0$, there exists $L_\\epsilon \\in \\mathbb{N}$ such that\n\n$|| f- f_L||_{L^\\infty(0,T;C^0 (B_0))} < \\frac{\\epsilon}{3Te^{Lip(f)T}}$.\nTherefore, by Lemma 4.3, it holds that for all $0 \\leq t \\leq T$,\n\n$||S_f(t) - S_{f_L} (t)||_{C^0(D)} \\leq t||f - f_L||_{L^\\infty(0,T;C^0 (B_0))}e^{Lip(f)T} < \\frac{\\epsilon}{3Te^{Lip(f)T}}Te^{Lip(f)T} = \\frac{\\epsilon}{3}$.\nFrom now on, this L will be fixed.\n5.2 Proof of $||S_{f_L} (t) - S_{h_1}(t)||_{C^0(D;\\mathbb{R}^N)} < \\frac{\\epsilon}{3}$\nLet $\\xi \\in D$. We introduce two notations:\n\n$b_l = \\frac{\\epsilon}{3(4e^{Lip(f)})^L-1}, \\quad \\xi_l = \\begin{cases}\n\\xi & (l = 0)\nS_{h^{(l)}}(T)\\xi_{l-1} & (l = 1, 2, . . ., L).\n\\end{cases}$\nWe inductively construct functions $h^{(l)} : \\mathbb{R}^N \\times [0,T] \\rightarrow \\mathbb{R}^N$ and subsequently the function $h_1 : \\mathbb{R}^N \\times\n[0,T] \\rightarrow \\mathbb{R}^N$. We aim to find $h^{(l)} (l = 1, 2, ..., L)$ such that if $\\xi_{l-1} \\in\\mathbb{R}^N$ satisfies\n\n$||\\xi_{l-1} - \\zeta_{l-1}|| \\leq b_{l-1}$,\n(5.1)\nthen $\\xi_l = S_{h^{(l)}}(T) \\zeta_{l-1}$ satisfies\n\n$||\\xi_l - \\zeta_l|| < b_l$.\n(5.2)\nFor l = 1,2,..., L, assume that $\\zeta_{l-1} \\in \\mathbb{R}^N$ satisfies (5.1). Since $\\sigma$ has universal approximation\nproperty, by Lemma 4.4, there exist $K_l \\in \\mathbb{N}$ and {$(\\alpha_i^{(l)}, \\beta_i^{(l)}, \\gamma_i^{(l)})$}$_{i=1}^{K_l} \\subset \\mathbb{R}^N \\times \\mathbb{R}^{N\\times N} \\times \\mathbb{R}^N$ such that\n\n$|| f^{(t)} - \\bar{g_l}||_{C^0 (B_0)} \\leq \\frac{b_{l-1}}{4Te^{Lip(f)}}$,\nwhere $B_0$ is $b_l$-neighborhood of $B_0$ and\n\n$\\bar{g_l}(x) := \\sum_{i=1}^{K_l} \\alpha_i^{(l)} \\odot \\sigma(\\beta_i^{(l)}x + \\gamma_i^{(l)})$.\nBy Lemma 4.6, we have\n\n$||S_{f^{(l)}}(t)\\zeta_{l-1} - S_{\\bar{g_l}}(t)\\zeta_{l-1}|| \\leq \\frac{b_{l-1}}{4} \\quad (0 \\leq t \\leq T)$.\nOn the other hand, let a T-periodic function $\\bar{g_l} : \\mathbb{R}^N \\times \\mathbb{R} \\rightarrow \\mathbb{R}^N$ and a function $g_{l,m}: \\mathbb{R}^N \\times [0, \\tau] \\rightarrow \\mathbb{R}^N$\nbe defined by\n\n$\\bar{g_l}(x,t) := \\sum_{i=1}^{K_l} \\alpha_i^{(l)} \\odot \\sigma(\\beta_i^{(l)}x + \\gamma_i^{(l)}) \\quad (\\frac{i-1}{K} \\tau < t \\leq \\frac{i}{K} \\tau, i = 1,2,...,K_l)$,\n$g_{l,m}(x,t) := \\bar{g_l}(x,mt) \\quad (x \\in \\mathbb{R}^N, 0 \\leq t \\leq \\tau, l = 1, 2, . . ., L, m \\in \\mathbb{N})$.\nBy Theorem 4.5, there exists $m_l \\in \\mathbb{N}$ such that\n\n$||S_{\\bar{g_l}} (t)\\zeta_{l-1} - S_{g_{l,m_l}} (t)\\zeta_{l-1}|| \\leq \\frac{b_l}{2} \\quad (0 \\leq t \\leq 1)$.\nHence, if we set $h^{(l)} = g_{l,m_l}$ and $\\zeta_l = S_{h^{(l)}}(T) \\zeta_{l-1}$, then we get (5.2):\n\n$||\\xi_l - \\zeta_l|| = ||S_{f^{(l)}}(T)\\xi_{l-1} - S_{h^{(l)}}(T)\\zeta_{l-1}|| \\leq ||S_{f^{(l)}}(T)\\xi_{l-1} - S_{\\bar{g_l}}(T)\\zeta_{l-1}||+ ||S_{\\bar{g_l}}(T)\\zeta_{l-1} - S_{h^{(l)}}(T)\\zeta_{l-1}|| \\leq b_l$.\nLet\n\n$h_1(x, t) := h^{(l)} (x, t - t_{l-1}) \\quad (x \\in \\mathbb{R}^N, t_{l-1} < t < t_l,l = 1, 2, . . ., L)$.\nIf we put $\\zeta_i = S_{h_1} (t)$ for all l = 0, 1, . . ., L, then we get inductively for $t_{l-1} \\leq t \\leq t_l$ with l = 1, 2, . . ., L:\n\n$||\\xi_l - \\zeta_l|| \\leq b_l(\\leq b_L), ||S_{f_L} (t)\\xi - S_{h_1}(t)\\xi|| \\leq b_l(\\leq b_L)$.\nEspecially, we have\n\n$||S_{f_L} (t)\\xi - S_{h_1}(t)\\xi|| \\leq b_L = \\frac{\\epsilon}{3} \\quad (0 \\leq t \\leq T)$\nfor all $\\xi$. Therefore, we obtain\n\n$||S_{f_L} (t) - S_{h_1}(t)||_{C^0(D)} < \\frac{\\epsilon}{3} \\quad (0 \\leq t \\leq T)$.\n5.3 Proof of $|| S_{h_1} (t) - S_{h}(t) ||_{C^0(D;\\mathbb{R}^N)} < \\frac{\\epsilon}{3}$\nBy definition of $h_1$, $h^{(l)}$, $g_{l,m}$, and $\\bar{g_l}$, there exist $\\alpha_L$, $\\gamma_L \\in L^\\infty(0, T; \\mathbb{R}^N)$ and $\\beta_L \\in L^\\infty(0, T; \\mathbb{R}^{N\\times N})$ such\nthat\n\n$h_1(x,t) := \\alpha_L(t) \\odot \\sigma(\\beta_L(t)x + \\gamma_L(t)) \\quad (0 \\leq t \\leq T, x\\in\\mathbb{R}^N)$.\nWe define $h \\in C^0(\\mathbb{R}^N \\times [0, T]; \\mathbb{R}^N)$ as\n\n$h(x,t) := \\alpha_{L,\\delta}(t) \\odot \\sigma(\\beta_{L,\\delta}(t)x + \\gamma_{L,\\delta}(t)) \\quad (x \\in \\mathbb{R}, 0 \\leq t \\leq T)$.\nBy Lemma 4.7, there exist $M_1$ and $M_2$ such that for all $\\xi \\in D$ and $0 \\leq t \\leq T$,\n\n$||S_h(t)\\xi|| \\leq M_1, ||\\sigma(\\beta_{L,\\delta}(t)S_h(t)\\xi+\\gamma_{L,\\delta}(t))|| \\leq M_2$.\n(4.6)"}]}