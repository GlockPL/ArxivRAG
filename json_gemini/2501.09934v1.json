{"title": "HEART: Achieving Timely Multi-Model Training for Vehicle-Edge-Cloud-Integrated Hierarchical Federated Learning", "authors": ["Xiaohong Yang", "Minghui Liwang", "Xianbin Wang", "Zhipeng Cheng", "Seyyedali Hosseinalipour", "Huaiyu Dai", "Zhenzhen Jiao"], "abstract": "The rapid growth of AI-enabled Internet of Vehicles (IoV) calls for efficient machine learning (ML) solutions that can handle high vehicular mobility and decentralized data. This has motivated the emergence of Hierarchical Federated Learning over vehicle-edge-cloud architectures (VEC-HFL). Nevertheless, one aspect which is underexplored in the literature on VEC-HFL is that vehicles often need to execute multiple ML tasks simultaneously, where this multi-model training environment introduces crucial challenges. First, improper aggregation rules can lead to model obsolescence and prolonged training times. Second, vehicular mobility may result in inefficient data utilization by preventing the vehicles from returning their models to the network edge. Third, achieving a balanced resource allocation across diverse tasks becomes of paramount importance as it majorly affects the effectiveness of collaborative training. We take one of the first steps towards addressing these challenges via proposing a framework for multi-model training in dynamic VEC-HFL with the goal of minimizing global training latency while ensuring balanced training across various tasks\u2014a problem that turns out to be NP-hard. To facilitate timely model training, we introduce a hybrid synchronous-asynchronous aggregation rule. Building on this, we present a novel method called Hybrid Evolutionary And greedy allocation (HEART). The framework operates in two stages: first, it achieves balanced task scheduling through a hybrid heuristic approach that combines improved Particle Swarm Optimization (PSO) and Genetic Algorithms (GA); second, it employs a low-complexity greedy algorithm to determine the training priority of assigned tasks on vehicles. Experiments on real-world datasets demonstrate the superiority of HEART over existing methods.", "sections": [{"title": "I. INTRODUCTION", "content": "The rapid advancement of Artificial Intelligence (AI), communication and computing technologies, as well as evolving vehicle design requirements have led to the integration of Machine Learning (ML)-driven applications within the Internet of Vehicles (IoV) [1], [2], aiming to enhance vehicular services and driving experiences. However, the distributed nature of data generated across the IoV and the high mobility of vehicles introduce significant challenges to the efficient utilization of IoV data for ML training purposes. This is due to the fact that conventional ML training methods often rely on centralized procedures that entail transferring data from all data-generating units (e.g., vehicles) to a single location (e.g., a cloud server). This approach results in high latency, increased network traffic congestion, and raises privacy concerns due to the exposure of raw data. Federated Learning (FL) has emerged as an innovative distributed ML framework that addresses these issues by pushing model training to the data-generating units themselves, thereby preserving data privacy and reducing communication overhead [3]. Nevertheless, in dynamic vehicular environments, FL still suffers from low communication efficiency and frequent communication failures [4]\u2013[6] due to the high mobility of vehicles and unstable network connections. To overcome these challenges, Hierarchical Federated Learning (HFL) has been proposed as a multi-layer extension of FL [7]. HFL introduces intermediate aggregators (e.g., edge servers) between the vehicles and the cloud server, helping to balance the trade-off between communication efficiency and computational overhead. This hierarchical approach enhances the robustness and efficiency of the learning process, making HFL a promising solution for efficient ML training and execution in IoV systems.\nRecent integrations of conventional FL and HFL over IoV systems predominantly emphasize single-task/model FL [8]\u2013[10], where all vehicles are engaged in training a single ML model. However, in real-world vehicular networks, vehicles often need to execute multiple ML tasks simultaneously, such as object detection for autonomous driving, traffic prediction for route optimization, and driver behavior analysis for safety enhancements. This necessitates the use of multi-model training approaches that can handle diverse ML models concurrently. Despite its promising potential, there exists very limited literature addressing multi-model FL over wireless networks [11], [12], and these works often rely on conventional FL training methods, which face significant communication overhead. Consequently, reducing communication costs while accelerating the overall multi-model training process is a primary concern that demands critical attention for both IoV systems and wireless networks more broadly.\nSome early efforts have been dedicated to address these concerns, focusing on the conventional FL architecture. For instance, recent studies have considered the unique characteristics of diverse ML models by leveraging vehicle-side resources to reduce the required number of global iterations, thereby ensuring timely and efficient model training [13], [14]. In these approaches, local models are collectively transmitted only once when their training is finalized on the vehicles, effectively minimizing the frequency of communication with the global aggregator, e.g., a cloud server [6]. Additionally, some research highlights the importance of selecting appropriate clients for training and effectively aggregating results from various tasks in FL [15]. While these contributions have advanced the new field, they often overlook the impact of balanced scheduling of ML tasks on global model convergence when handling multiple tasks with a HFL over dynamic IoV systems. In such systems, risks may arise due to model obsolescence if the trained models are not promptly aggregated upon completion [5]. Further, improper prioritization of task training on vehicles can lead to prolonged waiting times for model aggregation, further exacerbating potential model obsolescence.\nThis work is among the first in the literature to address the multi-model training within VEC-HFL. In our problem of interest, vehicles serve as training clients, multiple edge servers (ESs) act as middle-layer aggregators, and a cloud server (CS) functions as the global aggregator. We first note that a key challenge in facilitating multi-model training is mitigating model obsolescence risks while enhancing the utilization of distributed and dynamic training data from vehicles. In particular, we observe that traditional model aggregation methods in FL and HFL are either synchronous or asynchronous. Synchronous aggregation waits for all clients to upload their models to maintain consistency, but this can introduce significant delays and increase the risk of model obsolescence. Conversely, asynchronous aggregation initiates the aggregation process as soon as a subset of clients uploads their models, effectively reducing latency. However, this method may suffer from model instability and struggle to fully utilize data from all participating clients, potentially impacting the convergence speed of the global model. To address these challenges, we introduce a hybrid synchronous-asynchronous aggregation rule for VEC-HFL. This rule operates on a per-task basis: at the edge layer, each ES performs an aggregation only after receiving all local models of a specific task from vehicles (synchronous approach), while at the cloud layer, the CS conducts a global aggregation after obtaining a subset of the corresponding ES models (asynchronous approach). This hybrid approach leverages the advantages of both synchronous and asynchronous methods. By synchronously aggregating at the edge layer, we ensure model consistency and fully utilize the local training data from all participating vehicles, enhancing model accuracy and convergence speed. Simultaneously, the asynchronous aggregation at the cloud layer reduces overall latency by not waiting for all ESs, which can have different delays of model aggregation based on the distribution of vehicles covered by them and their channel conditions, to report their models, thereby mitigating delays and the risk of model obsolescence. This combination provides a natural solution that balances the trade-offs between timeliness and model quality, making it particularly suitable for dynamic IoV environments where both factors are critical.\nBuilding on this novel hybrid aggregation rule, we then target minimizing the global time/latency costs while ensuring balanced training across diverse ML tasks over resource-limited vehicles. We formulate this problem as a min-max optimization that turns out to be NP-hard, making the obtaining of its solution challenging in dynamic IoV systems. To tackle this problem, we propose a stagewise solution called the Hybrid Evolutionary And gReedy allocaTion method (HEART). In Stage 1 of HEART, we optimize the assignment between model training tasks and heterogeneous resource-limited moving vehicles. To this end, leveraging the strong global search capabilities and computational efficiency of Particle Swarm Optimization (PSO) and Genetic Algorithms (GA), we develop an efficient combination of improved PSO and GA to achieve or closely approximate the optimal and balanced task assignment solution. In Stage 2 of HEART, we coordinate the training sequence/rank of assigned tasks on each selected vehicle to accelerate decision-making by designing a greedy-based task ranking optimization method."}, {"title": "C. Summary of Contributions", "content": "Our major contributions can be summarized as follows:\n\u2022 Hybrid Synchronous-Asynchronous Aggregation Rule for Multi-Model Training in VEC-HFL: We introduce a novel aggregation rule tailored for VEC-HFL. This hybrid approach performs synchronous aggregation at the ES and asynchronous aggregation at the CS. By doing so, it effectively leverages the rich data generated by vehicles while significantly mitigating the adverse effects of model obsolescence, thereby enhancing the overall timeliness of the training process across ML tasks.\n\u2022 Efficient Two-Stage Optimization Method, HEART, to Minimize Global Time Cost: Addressing the NP-hard nature of minimizing the overall time cost in the VEC-HFL process, we develop an efficient two-stage optimization method named HEART. In Stage 1, we optimize task scheduling for vehicles by designing a hybrid Particle Swarm Optimization-Genetic Algorithm (PSO-GA), which combines the global search capabilities of PSO with the robust convergence properties of GA. In Stage 2, we optimize the task training sequence on the vehicle side by introducing a low-complexity greedy algorithm, which sequentially assigns tasks to maximize overlap and minimize uploading time. This two-pronged approach ensures both effective task distribution and efficient training sequence/rank planning, benefiting from a low computational complexity while maintaining high performance.\n\u2022 Superior Performance Demonstration through Extensive Simulations on Real-World Datasets: We conduct comprehensive simulations using real-world datasets to evaluate the performance of HEART. The results demonstrate its superior performance in terms of time efficiency and the overall communication costs compared to baseline methods. These findings highlight the effectiveness of HEART in dynamic IoV systems, showcasing its potential for practical deployment and scalability in real-world scenarios."}, {"title": "II. BACKGROUND AND PRELIMINARIES", "content": "The VEC-HFL architecture of our interest (see Fig. 1) comprises one CS as the global aggregator, multiple ESs as middle-layer aggregators, and multiple vehicles as model training clients moving between ESs. We collect the ESs via the set $M = \\{1,..., M\\}$, where each ES $m \\in M$ has a certain communication coverage. Also, we denote the set of vehicles in the IoV system by $N = \\{1, ..., N\\}$, where each vehicle $n \\in N$ is assumed to be located inside the considered IoV region during the training process, moving between the ESs. Moreover, we denote the set of all ML tasks in the system by $I = \\{1,..., J\\}$, which are expected to be scheduled and trained/executed over moving vehicles.\nTo enhance data utilization and mitigate model obsolescence, we introduce a hybrid synchronous-asynchronous aggregation rule for VEC-HFL as illustrated in Fig. 2. Presuming a specific task/model training rank across the vehicles (further concertized in Section III and optimized in Section IV), once vehicle n completes the local training of a task $j \\in I$, it transmits the local model to its associated ES, and then proceeds to training the next task according to the task ranking. In this framework, for each task j, an ES waits for the reception of local models of all the vehicles in its coverage who train this task before conducting a local model aggregation for this task. Once the models for task j are aggregated at each ES, the ES broadcasts the updated edge model back to its associated vehicle to prompt the start of the next local training round at the vehicles. Differently, the CS employs an asynchronous aggregation rule where once it receives a subset of edge models (e.g., from Qi ESs) for task j, it performs global aggregation and broadcasts the updated model to the ESs.\nSubsequently, the processes taken place in VEC-HFL can be divided into local iterations (i.e., local ML training using stochastic gradient descent), edge iterations (i.e., model transfer from the vehicles to the ESs followed by model aggregation), and global iterations (i.e., model transfer from a subset of ESs to the CS followed by model aggregations), where we use notation h, k and g to index them, respectively. Besides, for different task (e.g., task j), we also set corresponding maximum number of local iteration and edge iterations to be $H^{(j)}$ and $K^{(j)}$, which implies $h \\in \\{1,\u2026,H^{(j)}\\}$ and $k \\in \\{1,\u2026\u2026, K^{(j)}\\}$. We assume that the training of each task j starts with broadcasting a unified global model $w^{(j)}$ across all the ESs and vehicles and further assume that each task j continues its global iterations until its global model satisfies its convergence condition. Consequently, the maximum number of global iterations g is not predetermined. Next, we provide a mathematical formalization of the VEC-HFL architecture.\nFor each task j, we model the dataset of the nth vehicle within the coverage of ES m as $D_{m,n}^{(j)} = \\{(x_i, y_i) : 1\\leq i \\leq |D_{m,n}^{(j)}|\\}$, where x and y describe the feature vector and the label of the ith data point and $|D_{m,n}^{(j)}|$ represents the size of the dataset. Accordingly, the loss function of task j at this vehicle is given by\n$L_{m,n}^{(j)}(w_{m,n;[g,k]}^{(j)}) = \\sum_{i=1}^{|D_{m,n}^{(j)}|} l_{i}^{(j)}(w_{m,n;[g,k,h]}^{(j)})$, (1)\nwhere $l_{i}^{(j)}(w_{m,n;[g,k,h]}^{(j)})$ denotes the loss function for the ith data point given the instantaneous local model parameters $w_{m,n;[g,k,h]}^{(j)}$ for the nth vehicle covered by ES m during the hth local iteration of the kth edge iteration of global iteration g. In particular, the update process of the instantaneous local model on this vehicle is carried out using stochastic gradient descent (SGD) iterations as follows ($h\\in \\{1,..., H^{(j)}\\}$):\n$w_{m,n;[g,k,h]}^{(j)} = w_{m,n;[g,k,h-1]}^{(j)} - \\eta_{m,n}^{(j)} \\nabla l^{(j)}(w_{m,n;[g,k,h-1]}^{(j)}, B_{m,n;[g,k,h]}^{(j)}), (2)$\nwhere $\\eta_{m,n}^{(j)}$ is the learning rate, and $B_{m,n;[g,k,h]}^{(j)}$ is a mini-batch of data sampled randomly from the local dataset $D_{m,n}^{(j)}$. The local model of the edge iteration k for each global iteration g is initialized with $w_{m,n;[g,k,0]}^{(j)} = w_{m;[g,k-1]}^{(j)}$, which is the latent model received from the edge. Also, the latest local model $w_{m,n;[g,k,H^{(j)}]}^{(j)}$ is sent to the ES and used to obtain the next edge model as discussed below.\nConsidering the kth edge iteration of global iteration g for an ES m, we denote the set of vehicles under its coverage who also train task j as $N_{m;[g,k]}^{(j)}$. Letting $w_{m;[g,k]}^{(j)}$ represent the edge model for task j at the kth edge iteration of global iteration g, its update can be expressed as follows:\n$w_{m;[g,k]}^{(j)} = \\sum_{n\\in N_{m;[g,k]}^{(j)}} \\frac{|D_{m,n}^{(j)}|}{|D_{m;[g,k]}^{(j)}|} w_{m,n;[g,k,H^{(j)}]}^{(j)}, (3)$\nwhere $|D_{m;[g,k]}^{(j)}| = \\bigcup_{n\\in N_{m;[g,k]}^{(j)}} |D_{m,n}^{(j)}|$, and $D_{m;[g,k]}^{(j)}$ represents the overall data volume for task j during the kth edge iteration possessed by the vehicles covered by ES m. The latest edge model $w_{m;[g,K^{(j)}]}^{(j)}$ is sent to the CS and used to obtain the next global model as discussed below.\nFor each $j \\in I$, once the CS receives a predetermined number of edge models (i.e., $Q^{(j)}$), it performs the global aggregation. Let $M^{(j)}$, where $M^{(j)} = Q^{(j)}$, represent the set of ESs who deliver the edge model of task j to the CS at the gth global aggregation. The update process of global model for task j is as follows:\n$w_{[g]}^{(j)} = \\alpha_{[g]}^{(j)} w_{[g-1]}^{(j)} + (1 - \\alpha_{[g]}^{(j)}) \\sum_{m\\in M^{(j)}} \\frac{|D_{m;[g,K^{(j)}]}^{(j)}|}{|D_{[g]}^{(j)}|} w_{m;[g,K^{(j)}]}^{(j)}, (4)$\nwhere $\\alpha^{(j)}$ represents the weighting coefficient between the current global model and the updated edge models received from the ESs. $D_{m;[g,K^{(j)}]}^{(j)}$ and $D_{[g]}^{(j)}$ represents the overall number of data points involved in training task j during the gth global aggregation. The global model $w_{[g]}^{(j)}$ is then sent back to these ESs, which relay it back to their covered vehicles to synchronize their local models and start the next round of local training. We consider that the global iterations for each task j ends at iteration g when its following convergence criterion\n$||w_{[g]}^{(j)} - w_{[g-1]}^{(j)}|| \\leq B^{(j)}, (5)$\nwhere $|| ||$ represents the Euclidean 2-norm, and $B^{(j)}$ represents a small positive value used to control the convergence criterion. Alg. 1 provides an overview of our designed hybrid synchronous-asynchronous aggregation rule for VEC-HFL."}, {"title": "III. MULTI-TASK SCHEDULING OVER VEC-HFL ARCHITECTURE", "content": "In this section, to better analyze the time cost of the proposed VEC-HFL architecture, we first analyze the local and edge iterations, deriving the local training time for vehicles and the time required for ESs to complete an entire edge iteration. Then, we provide an analysis for the global iteration.\nThe time consumed to perform one local training round (i.e., one SGD iteration) at the nth vehicle covered by ES m for task j can be calculated as follows:\n$t_{m,n;[g,k,h]}^{(j)} = \\frac{c_{m,n}^{(j)}}{|B_{m,n;[g,k,h]}^{(j)}|}+b_{m,n}^{(j)}, (6)$\nwhere $c_{m,n}^{(j)}$ represents the number of cycles that it takes to process one data point of task j, $f_{n}^{(j)}$ denotes the allocated CPU clock frequency of the vehicle to conduct ML training for task j, and $B_{m,n;[g,k,h]}^{(j)}$ is the number of data points contained in the mini-batch of SGD. Moreover, $b_{m,n}^{(j)}$ is a constant value, representing the migration time of the model between the CPU and GPU, or instantiating the model parameters. Harder tasks (e.g., those that use deeper neural networks) are often associated with larger values of $c_{m,n}^{(j)}$ and $b_{m,n}^{(j)}$.\nWe model the configuration of task processing (i.e., task-to-vehicle assignment) via a binary indicator variable $\\chi_{m,n;[g]}^{(j)} : \\chi_{m,n;[g]}^{(j)} = 1$ indicates that task j is processed on the nth vehicle of ES m during the gth global iteration; and $\\chi_{m,n;[g]}^{(j)} = 0$ otherwise. Additionally, since the ESs employ a synchronous aggregation rule for each task, when the task sequence of vehicles (i.e., the order in which the vehicles execute their local tasks) within the ES coverage exhibit a higher degree of overlap, the local models of all tasks can be aggregated at shorter intervals to mitigate the effects of model obsolescence. Furthermore, in the dynamic IoV channels considered in this work, uploading local models at optimal times during each edge iteration, which can be achieved through optimizing the task sequence of vehicles, can significantly reduce communication latency and global communication costs. For instance, uploading tasks with larger model parameters when vehicles are closer to the ES dramatically decreases both model upload time and communication delays compared to uploading when vehicles are farther away.\nTo formally describe this process, we introduce $A_{m,n;[g,k]}$ to represent the training sequence of tasks on the nth vehicle covered by ES m during the kth edge iteration of global iteration g. For example, if this vehicle is assigned tasks 1, 3, and 4, then the training sequence $A_{m,n;[g,k]}$ is [4,1,3]. We further use $I(\\chi_{m,n;[g]}^{(j)})$ to denote the position of task j on the nth vehicle within the coverage of ES m. Continuing the previous example, if $A_{m,n;[g,k]} = [4,1,3]$, then $I(\\chi_{m,n;[g]}^{(j)}) = 2$. This notation helps model the completion time for each task during edge iterations, which in turn provides a tractable framework to address the aforementioned challenges by optimizing the task training sequence $A_{m,n;[g,k]}$ across various vehicles. Below, we integrate task training sequence in modeling the task completion time and will later provide the details of the optimization of the task training sequence in Section IV.\nDue to the complexities involved in modeling the timeline of the processes that take place at each vehicle in our hybrid synchronous-asynchronous aggregation rule, we divide the time span dedicated to conducting local iterations of a vehicle into two parts: task-training time and non-task-training time. For the former, the task-training time of the nth vehicle covered by ES m to complete a task (e.g., task j) during the kth edge iteration of the gth global iteration can be calculated by considering the number of local iterations ($H^{(j)}$), and the time consumed by each local training round (i.e., $t_{m,n;[g,k,h]}^{(j)}$ given by (6)), which can be defined as\n$t_{Cmp,m,n;[g,k]}^{(j)} = \\sum_{h=1}^{H^{(j)}} t_{m,n;[g,k,h]}^{(j)}, (7)$\nThe non-task-training time primarily consists of (i) the local model upload time and (ii) any idle period from the completion of one task's local iteration to the start of the next. However, modeling this time needs careful considerations because, during the gth global iteration, vehicles immediately transmit their local models to the associated ES once they finish training, and thus two scenarios may arise:\n\u2022 Case (i): Immediate local execution. If a vehicle receives the edge model for the next task in its training sequence before completing its current one, it can begin the new local iterations for the next task right away. In this case, since the local training of the next task and model transmission of the finished task occur concurrently, both the upload time of the completed task and the potential idle time can be effectively neglected.\n\u2022 Case (ii): Delayed local execution. If the edge model of the next task in the training sequence of a vehicle is available (i.e., not yet received from the ES) once the current task finishes, the vehicle will experience a nonzero non-task-training time. This includes the upload time of the finished model plus any idle time until the next task is broadcasted and received at the vehicle.\nFirstly, the upload time of task j of the nth vehicle covered by ES m during the kth edge iteration of the gth global iteration can be expressed by\n$t_{m,n;[g,k]}^{V2E,(j)} = \\frac{I_{m,n;[g,k]}^{V2E,(j)}}{r_{m,n;[g,k]}^{V2E}}, (8)$\nwhere $r_{m,n;[g,k]}^{V2E}$ represents the vehicle-to-edge data rate of vehicle n under the coverage of ES m during the kth edge iteration, which is related to the distance between the vehicle and ES and the channel conditions [17]. Besides, the size of the local model (in bits) is denoted by $I_{m,n;[g,k]}^{V2E,(j)}$.\nLet $t_{m,n;[g,k]}^{inact,(j)}$ denote the inactive time of the nth vehicle covered by ES m after completing its local iteration at edge iteration k of global aggregation g. It can be observed that this inactive time is a function of the completion time of edge iteration k-1 within global aggregation g for a task j, which we denote it by $t_{m,n;[g,k-1]}^{end,(j)}$. Mathematically, we obtain this inactive time as follows:\n$t_{m,n;[g,k]}^{inact,(j)} = \\max \\{ \\max_{n'\\in N_{m;[g,k]}^{(j)}} t_{m,n';[g,k-1]}^{end,(j)}, t_{m,n;[g,k]}^{V2E,{(j')} + t_{m,n;[g,k]}^{end,(j')}, 0, j': I(\\chi_{m,n;[g]}^{j'}) = I(\\chi_{m,n;[g]}^{(j)}) - 1\\}, (9)$\nwhere term (a) represents the time where all the other vehicles send their local models of task j to ES m at the (k \u2212 1)th edge iteration, which creates the updated edge model for starting the next edge iteration (i.e., the kth within the global iteration g), and (b) indicates the time that vehicle n will start processing task j during the kth edge iteration in global iteration g. We will later obtain $t_{m,n;[g,k]}^{end}$ as a function of $t_{m,n;[g,k]}^{inact}$ in (12), which combined with (9) forms a recursive expression between these two quantities.\nSubsequently, the non-task training time of the nth vehicle covered by ES m is given by\n$t_{m,n;[g,k]}^{Ntt,(j)} = \\begin{cases} 0 & \\text{if case (i)} \\\\ t_{m,n;[g,k]}^{V2E,(j)} + t_{m,n;[g,k]}^{inact,(j)} & \\text{if case (ii)} \\end{cases}, (10)$\nTherefore, for the nth vehicle covered by ES m, the time required to complete location iterations for task j in the kth edge iteration of global iteration g can be expressed as\n$t_{m,n;[g,k]}^{(j)} = t_{Cmp,m,n;[g,k]}^{(j)} + t_{m,n;[g,k]}^{Ntt,(j)}, (11)$\nSince the ESs utilize synchronous aggregation rule, it needs to wait for all vehicles assigned to the task to upload their local models before performing edge aggregation. Nevertheless, different vehicles have different training sequences for tasks, and their training and uploading times are also different. Thus, the completion of edge iteration k of global aggregation g for a task j at the nth vehicle covered by ES m is a function of the execution times of the tasks that have lower execution rank as compared to this task (i.e., get processed before task j); mathematically, we have\n$t_{m,n;[g,k]}^{end,(j)} = \\sum_{j':I(\\chi_{m,n;[g]}^{(j')})\\leq I(A_{m,n;[g]})} t_{m,n;[g,k]}^{(j')}, j' \\in J, (12)$\nwhere the summation is taken over all the tasks that get executed before task j, where the execution time of task j is included as well. Then, combined with the synchronous aggregation rule, the overall time cost/overhead of execution of task training for task j at ES m, which is dictated by the last vehicle that uploads it model to the ES, at the end of edge iteration k of global aggregation g can be obtained as\n$T_{m;[g,k]}^{(j)} = \\max_{n\\in N_{m;[g]}^{(j)}} \\{t_{m,n;[g,k]}^{end,(j)}\\}, (13)$\nWhen an ES completes the edge training of task j, the edge model will be transmitted to CS for global aggregation. We denote the upload time from ES m to the CS as\n$t_{m}^{E2C,(j)} = \\frac{I_{m}^{E2C,(j)}}{r_{m}^{E2C}}, (14)$\nwhere $I_{m}^{E2C,(j)}$ represents the size of edge model, and $r_{m}^{E2C}$ represents the data rate of ES m to CS, which is assumed to be time-invariant as these communications often take place over the backhaul network wired links. Then, we can get the time required for each task to complete one round of global iteration at ES m, as given by\n$T_{m;[g]}^{(j)} = t_{m}^{E2C,(j)} + \\sum_{k=1}^{K^{(j)}} T_{m;[g,k]}^{(j)}, (15)$"}, {"title": "IV. PROBLEM FORMULATION AND DESIGN OF HEART", "content": "In this section, we first provide the key constraints that are involved in our scenario of interest. Then, we present our problem formulation and explain our solution method.\nIn the IoV context, one key concern is ensuring that vehicles complete their training tasks and transmit the results to the corresponding ES promptly, mitigating potential negative impacts on training performance caused by network dynamics. Accordingly, we introduce a constraint given by\n$\\sum_{j\\in J} \\sum_{k\\in K^{(j)}} \\chi_{m,n;[g]}^{(j)} t_{m,n;[g,k]}^{(j)} < t_{stay,m,n;[g]}, (16)$\nwhere $t_{stay,m,n;[g]}^{(j)}$ represents the dwell time of the nth vehicle within its associated ES m coverage, where $\\chi_{m,n;[g]}^{(j)} \\in \\{0,1\\}$ is defined in Sec. III-A. Next, we focus on imposing balance across the training of different tasks. To reach this, we let $\\sum_{m\\in M} \\sum_{n\\in N_{m;[g,k]}^{(j)}} \\chi_{m,n;[g]}^{(j)}$ denote the number of times that task j has been assigned/trained at the gth global iteration. Subsequently, we impose the training balance across the tasks via the following constraint\n$\\frac{N}{J} - \\xi_1 < \\sum_{m\\in M} \\sum_{n\\in N_{m;[g,k]}^{(j)}} \\chi_{m,n;[g]}^{(j)} < \\frac{N}{J} + \\xi_2, \\forall j \\in J. (17)$\nIn (17), $ \\xi_1, \\xi_2 \\in N^+$ are adjustment coefficients. This constraint is inspired by the fact that achieving the pure fairness across the tasks, which equivalents to distributing all tasks evenly to vehicles (e.g., during a global iteration, each task will be is trained by $\\frac{N}{J}$ vehicles) is not practical due to variations in the time vehicles remain within the edge coverage and the training time required for each task across different vehicles, which in turn depends on the task complexity. To address this, we constrain the number of times each task is assigned for training within a range centered around the average value $\\frac{N}{J}$. Specifically, the left side of the equation denotes the lower bound on the number of times task j is assigned for training, while the right side represents the upper bound. This approach aims to achieve task scheduling fairness considering the dynamic nature of vehicle availability.\nWe next focus on optimizing the latency of the entire process taken place in each round of global iteration (e.g., the gth round). Our major goal is to obtain task scheduling $\\chi_{m,n;[g]}^{(j)}$ and training sequence $A_{m,n;[g,k]}$, upon considering mobility of vehicles and task training balance, which we formulate through the following optimization problem\n$\\mathcal{P}: \\underset{\\chi_{m,n;[g]}^{(j)}, A_{m,n;[g,k]} (j\\in I, m \\in M)}{\\text{argmin}} \\{ \\underset{m;[g]}{\\text{max}} \\{T_{m;[g]}^{(j)}\\} \\} \\text{s.t.} (16), (17) (18)$\nIntegrating asynchronous aggregation rule in the CS, in this formulation, we aim to optimize $\\chi_{m,n;[g]}^{(j)}$ and $A_{m,n;[g,k]}$ for all the vehicles n, ESs m, and tasks j so as to minimize the cumulative time required for all the tasks to undergo a complete round of global iteration, which is captured by the objective function, thereby reducing the time cost of the entire VEC-HFL process.\nDue to the integer/discrete nature of the optimization variables, P belongs to a sub-category of integer programming problems which are known to be NP-hard. To tackle this problem, we propose a stagewise scheduling method called HEART, designed to achieve a near-optimal solution in a timely manner.\nIn HEART, problem P is solved in two stages. In Stage 1, we primarily address the task scheduling problem, which includes scheduling tasks to appropriate vehicles and ensuring balanced task training across the system. For this stage, we propose a hybrid heuristic approach that combines an improved"}, {"title": "C. Proposed Stagewise Scheduling through Hybrid Evolutionary And gReedy allocation (HEART)", "content": "Particle Swarm Optimization (PSO) algorithm with a Genetic Algorithm (GA). By integrating crossover and mutation operations from GA into PSO, our method enhances global search capabilities and explores a broader solution space, significantly reducing the risk of getting trapped in local optima. In Stage 2, we focus on optimizing the training sequence/rank of the assigned tasks on each vehicle, ensuring that the tasks are trained in an appropriate order to minimize delays. Besides, to guarantee that the vehicles' task training sequence accounts for both task overlap and model upload time, we introduce the concept of a task training scheduling combination score. We will aim to maximize this score at the edge by optimizing the vehicles' task training sequence through an efficient greedy algorithm.\nHeuristic algorithms such as PSO and GA are widely used due to their exceptional performance in scheduling and resource allocation problems [18", "19": ".", "20": [21], "22": [23]}]}