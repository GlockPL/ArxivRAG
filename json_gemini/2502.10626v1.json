{"title": "K-Edit: Language Model Editing with Contextual Knowledge Awareness", "authors": ["Elan Markowitz", "Anil Ramakrishna", "Ninareh Mehrabi", "Charith Peris", "Rahul Gupta", "Kai-Wei Chang", "Aram Galstyan"], "abstract": "As the world changes, we need to be able to update our models and correct false information without costly retraining. Knowledge-based model editing enables precise modifications to the weights of large language models in order to modify the information encoded within. Recent approaches have seen success in enabling recall of edited information for thousands of edits at once. However, these approaches fail to produce edits that account for associated contextual information. We present K-Edit, an effective approach to generating contextually consistent knowledge edits. By using knowledge graphs, which maintain contextual consistency when an edge is edited, we are able to generate additional contextual edits that ensure consistency of related information in the language model. Our experiments demonstrate significant improvements in multi-hop question answering while maintaining the general effectiveness and scalability of model edits.", "sections": [{"title": "1 Introduction", "content": "The ability to pinpoint and edit knowledge within the parameters of a Large Language Model (LLM) is a powerful tool for maintaining alignment with an ever-changing world. Existing approaches to direct model editing make shallow edits that fail to integrate with contextual knowledge the model possesses (Zhong et al. 2023). This work proposes and explores a simple solution to better enhance knowledge reasoning over edits by including contextual and associated knowledge in the editing process. We use the contextual consistency of knowledge graphs when edited to improve the consistency of language models under direct model editing.\nDirect Model Editing (or Knowledge-based Model Editing) aims to change the implicit knowledge in an LLM's weights with no other changes to how the model is used (Wang et al. 2023b; Mazzia et al. 2023; Yao et al. 2023). Prior methods have focused on the ability to edit and recall a new fact without affecting neighboring facts or general generation ability (Zhu et al. 2020; Mitchell et al. 2021; Meng et al. 2022a,b). Recently, however, researchers have begun to question the effectiveness of these edits through benchmarks evaluating the ability of models to use these edits for multi-hop reasoning (Zhong et al. 2023). For example, if we edit the British Prime Minister to be Rishi Sunak instead of Boris Johnson, we would expect the model to be able to answer Who is the British Prime Minister's wife? with the correct answer Akshata Murty. Existing direct model editing techniques largely fail in this regard. We address this issue by utilizing the relational information in knowledge graphs.\nIn this work, we propose K-Edit, a simple, yet effective, approach of adding more contextual knowledge into the editing process. In contrast to text (and thus LLMs), knowledge graphs are very simple to edit. Knowledge graphs are graph databases encoding the relations between real-world entities. Since the structure of knowledge is explicit in a knowledge graph, editing a single edge immediately updates connected associations as well. We propose a method that incorporates these automatic associations into the editing process. After an edit is made, we extract related contextual information from a knowledge graph. We then construct contextual edits that ensure the context is ingrained in addition to the initial edit.\nOur results show that this method significantly helps with the primary goal, as measured by significant improvement on multi-hop reasoning over edited information. We even show that such edits improve multi-hop reasoning even when the required reasoning path does not directly appear in the context. Our results also indicate that there is no cost to quality as measured by other knowledge editing metrics, and that thousands of such edits can be applied without degradation compared to baselines.\nOur contributions are\n1. K-Edit, a new direct model editing algorithm for improving contextual and associated knowledge awareness through incorporation of knowledge graph data.\n2. Experimental evaluation that shows improved multi-hop reasoning with K-Edit and its ability to generalize.\n3. Additional experiments and ablations showing no degradation to other knowledge editing metrics and the ability to apply thousands of such edits at a time."}, {"title": "2 Background", "content": "2.1 Knowledge Graphs\nKnowledge graphs encode real world entities and the relations between them. The most prominent knowledge graphs contain billions of edges covering a vast array of subjects, such as Wikidata (Vrande\u010di\u0107 and Kr\u00f6tzsch 2014) and DBPedia (Lehmann et al. 2015). We define a knowledge graph K = (E,R,T) where E is the set of entities, R is the set of relations, and T is the set of edges (s,r,o) \u2208 E \u00d7 R \u00d7 E that represent true relationship in the knowledge base between subject s and o. For example, if (Blank Space, performer, Taylor Swift) \u2208 T, then the statement \"The performer of Blank Space is Taylor Swift\" is considered true. One feature of knowledge graphs is that if an edge is updated, all multi-hop relations associated with that edge will be correct without any additional explicit updates.\n2.2 Knowledge-based Model Editing\nWe define some background notation and concepts for knowledge-based model editing. Here we deal with edits of the form, (s, r, o \u2192 o*), meaning we want to edit subject s such that the relationship r now refers to object o* instead of o. We define a text prompt tr(s) for the edit (also referred to as a cloze statement) in which o* is the desired output, e.g."}, {"title": "3 K-Edit Algorithm", "content": "K-Edit leverages knowledge graphs to improve the quality of model edits by incorporating contextual information. The algorithm consists of three main steps that work together to create more comprehensive knowledge updates.\nExisting approaches modify representations of the subject s such that the model generates the desired association o* for relationship r. However, generating the associated text is not the same as internalizing the association. K-Edit uses external knowledge bases to improve the quality of model edits such that the new subject representation is integrated with connected contextual associations.\nK-Edit works according to the following steps. (1) initial edits are applied the model using a batch editing approach (e.g. MEMIT). (2) Contextual knowledge is extracted from a knowledge graph around the edit and converted to contextual edits. (3) The contextual edits are applied using the same batch editing approach from step 1. This can be repeated for deeper depths of multi-hop contextual knowledge. Algorithm 1 shows the high level algorithm for implementing K-Edit.\n3.1 Creating Contextual Edits\nContextual edits are model editing prompts that are constructed to not just reinforce a simple edited fact, but also to ensure the fact is linked with connected facts (Examples of connected facts in figure 1). With this goal in mind, we design contextual edits that both require the model to recall the edited information on its own and require the model to follow the multi-hop relationships. The following section describes the construction of such prompts.\nFor a given edit (s, r1,01 \u2192 01), we compute k-hop edits by sampling relationships from the neighborhood of ot, N(01). We then combine these edges with the original edit to get multi-hop edges of the form (s,r1,01), (01, 02, 02) e.g. (United Kingdom, Prime Minister, Rishi Sunak), (Rishi Sunak, spouse, Akshata Murty). Simply applying the edit (Rishi Sunak, spouse, Akshata Murty\u2192Akshata Murty) would not work as the model already knows this information (01, 02, 02 \u2192 02). Instead, we construct the edit statement in a way that forces the model to incorporate both the edited edge and associated edge together. Specifically, we construct an edit of the format tr\u2082 (r1(s)) \u2192 02 e.g. \u201cThe spouse of {the United Kingdom Prime Minister} is\u2192Akshata Murty\u201d. Here, r\u2081(s) is a text template that maps to the object referred to from s on relation r\u2081 and presents it in text as a subject-relation clause. We can see that this edit does not include o explicitly. As a result, the model must rely on the previously updated association (s, r1,01 \u2192 0\u2081) in order to complete the prompt.\nWe also note that we treat the United Kingdom Prime Minister as the subject to edit which means the [Minister] token rather than [Kingdom] token is the one that is the target of the update. We do this in accordance with the findings of Geva et al. (2023) that the final token of a subject aggregates the information and relationships from preceding tokens. This process allows the model to learn the 2nd hop association in the context of the previous edit as opposed to memorizing all 2-hop associations for the subject token. We note that this setup is coincidentally similar to the approach used to analyze models in Yang et al. (2024). It is encouraging that our approach to edit multi-hop associations corresponds to the way they discovered models perform latent multi-hop reasoning in the first place. Algorithm 2 presents the detailed description for constructing contextual edits of any hop depth.\n3.2 Scaling Contextual Edits\nOne of the challenges with generating multi-hop contextual edits is that the number of templates for editing rapidly explodes. For instance, with 50 relationship types, there are potentially 2,500 different templates required for 2-hop contextual edits (though most of those will not exist in practice). This could be solved naively by generating the templates with an LLM but that could still get burdensome for larger KGs or hop depths and could introduce errors. Instead, our approach employs a linguistic mechanism that enables the scalable creation of contextual edits for any hop length.\nTo use this method all that is needed is two text templates for each relation type r. We require one template tr(s) that creates a cloze statement for each relation r. This is a fill-in-the-blank style prompt. For example, the template \"The Prime Minister of {s} is\" prompts the model to complete the association. Additionally we need one more template, r(s) that creates a subject-relation clause that semantically refers to the corresponding object e.g. \"the spouse of {s}\". With these mappings we create a single cloze statement template for a multi-hop edit, using the template tr\u2081 (r2(...(rk(s))). This means we only need to create 2 \u00d7 |R| templates rather than |R|k. Note that their is no dependence on depth k. Algorithm 2 presents the method for constructing these contextual edits. These more simple templates enable the easy use of LLMs for further generation (Appendix E)."}, {"title": "4 Experiments", "content": "We run experiments on K-Edit to evaluate its ability to incorporate contextual information under edits as well as the general quality of the model edits produced.\n4.1 Datasets\nWe use two datasets, MQuAKE (Zhong et al. 2023) and MultiCounterFact(Meng et al. 2022b). Dataset statistics can be found in Table 1.\nThe primary dataset, MQuAKE, is used for evaluating multi-hop reasoning on edits (Zhong et al. 2023). This dataset contains 3,000 multi-hop questions (2-4 hops) with each answer based on 1-4 counterfactual edits. For example, the question \"What is the headquarters location for the broadcaster of True Detective?\" is paired with two edits: (True Detective, broadcaster, HBO \u2192 ABC) and (ABC, headquarters location, New York City \u2192 Los Angeles). These edits are not real in the world, but are plausible counterfactual edits that could be applied. This example was a two-hop question with two edits, however, the number of edits does not need to be the same as the number of hops. The exact breakdown can be found in Table 2.\nWe also use a subset of MultiCounterFact dataset (Meng et al. 2022b) derived from CounterFact (Meng et al. 2022a). This dataset contains 30,000 counterfactual edits and is used to evaluate the strength of an edit, whether unaffected neighboring relations remain unchanged, and the generation ability of the model post editing. The MultiCounterFact modification ensures there are no direct conflicts between edits in the dataset (i.e. no duplicate edits for a given subject and relation). We use a subset of 10,000 questions for our experiments.\n4.2 Baselines\nWe compare against a number of alternative direct model editing baselines.\nFT-W is a finetuning approach with weight decay to avoid altering other memories or changing unrelated model behavior (Zhu et al. 2020).\nMEND uses a hypernetwork meta-trained to modify fine-tuning gradients so that they produce higher quality edits (Mitchell et al. 2021).\nROME uses counterfactual tracing to locate what layer of the model contains the information to be edited before updating the MLP component in that layer (Meng et al. 2022a).\nMEMIT (presented above) uses a similar objective to ROME but modified to enable editing large sets of facts at once, which none of the other baselines are able to do well (Meng et al. 2022b). We consider this to be the main baseline as it is also the editing mechanism we use in our K-Edit implementation.\nWhile there are a number of knowledge editing approaches based on retrieval mechanisms, these methods fundamentally alter the nature of the model. Our focus is on direct model editing approaches. This is discussed further in the related works section."}, {"title": "5 Results and Analysis", "content": "Our results show that K-Edit improves multi-hop contextual reasoning over edited information without sacrificing in terms of scalability or individual edit performance.\nTable 3 shows our main results for GPT-J and Falcon-7b on the MQuAKE dataset. We see that the model's multi-hop answering ability vastly exceeds the other baselines with a relative improvement of 57.6% over the best baseline MEND (14.5% versus 9.2%) and close to doubling the performance of ROME and MEMIT (+90.8% and +79.0% respectively). Under Chain-of-Thought prompting, K-Edit significantly outperforms MEMIT while slightly underperforming ROME. We note that the MQuAKE results are from applying the edits for one question at a time. ROME has noted weaknesses when applying edits in bulk as will be discussed later.\nWe also compare K-Edit to MEMIT for Falcon-7b and find a even greater improvement than for GPT-J with the multi-hop accuracy nearly doubling.\nWhile K-Edit significantly improves multi-hop accuracy, we note that there is still room for improvement. The GPT-J Base model gets 43.4% accuracy on the unedited answers which sets a rough upper bound for where we could expect to see results.\n5.1 Generalization\nOne question that may arise is whether the benefit of K-Edit is simply from the multi-hop questions being covered by the contextual edits. Specifically, are the observed gains due to brute force inclusion of related information or is there an aspect of K-Edit that improves the edited representations in a more generalized way? To address this question, we run additional ablation experiments in which the question edges from MQuAKE are filtered out of the contextual edits. We present these experiments in Table 4. We see that while performance does decrease (as expected), it is still significantly better than the original MEMIT performance. Specifically, we observe that roughly half of the improvement from K-Edit generalizes to edges not covered by contextual edits. This is a somewhat surprising result. Including contextual edits on tangentially related edges improves the quality of original edit such that other multi-hop information is easier for the model to retrieve. The implication of this is that the quality of K-Edit is not solely limited to the relation types present in the knowledge graph.\nWhen we break down these gains by the number of hops, we see that the gains from generalization are spread across the dataset, with gains on 2, 3, and 4-hop questions. Table 5 shows the incremental gain from generalization and from memorization on GPT-J using CoT reasoning. We see that the incremental gain from memorized associations are concentrated on the 2-hop questions. This is expected since we only use 2-hop contextual edits in our experiments. This is also evidence that K-Edit could perform even better if contextual edits of greater depth were included.\nWhen we filter the analysis for questions with only a single edited hop, we find only a 2.8% accuracy difference performance between full K-Edit and the generalization ablation, and absolutely no difference if employing CoT reasoning. This makes sense since questions with multi-edits would be especially hard to generalize. Generalization relies on using some degree of the LLM's implicit knowledge. When that knowledge is also edited, it would be much harder to associate the correct contextual information.\n5.2 Edit Quality Remains High for Standard Metrics and Larger Scales\nK-Edit's edit quality remains high when evaluated under metrics other than multi-hop accuracy (see Table 6). These experiments show the results of running editing algorithms when only a single edit is applied at a time (@1) or when batches of 1,000 edits are applied at a time (@1,000). We see that K-Edit is at or near state-of-the-art for all metrics for both @1 and @1,000. While ROME slightly outperforms K-Edit in @1 results, it dramatically underperforms in results @1,000. The overall score (harmonic mean of efficacy, paraphrase, and specificity) for ROME@1,000 is 60.3 relative to K-Edit's 90.6.\nCompared to MEMIT we see highly comparable scores across the board. We note that while K-Edit does introduce additional edits in the form of contextual edits, these edits are primarily there to reinforce the associated information of the initial edit. As a result, there is no noticeable impact to scalability. Though further research is needed to understand the full scalability limits of K-Edit.\nUnfortunately, while the edits in the MultiCounterFact dataset do not conflict with each other directly, the contextual edits of K-Edit might conflict with the dataset as we treat the knowledge graph as a source of truth when applying the contextual edits. For example, if one question includes the edit (LA Lakers, owner, Jeanie Buss\u2192 Bill Gates), K-Edit would include the contextual edit for \"The owner of the LA Lakers was born in\u2192Seattle\u201d. However, if another question included the edit (Bill Gates, place of birth, Seattle\u2192New York), it would create a conflict. This could result in lower Specificity, Efficacy, and Generalization for K-Edit@1,000. However, this is not common and the affect is not large.\n5.3 Sequential Ordering is Important\nK-Edit applies the contextual edits after applying the original edits. This is so that the contextual edits can refine the initial edit to incorporate the related information. We find that running K-Edit in parallel (meaning the model updates for both original edits and contextual edits are computed at the same time) leads to significant decline in performance. Table 7 shows the importance of using sequential edits compared to parallel ones (14.5 to 12.6 and 17.0 to 12.7 for CoT reasoning). We theorize that when the contextual edits are not applied after the initial edits, the model may be updating the wrong associations. For instance, in our running example, if Boris Johnson is still associated as \"the United Kingdom Prime Minister\", the algorithm may be updating the spouse of Boris Johnson rather than enhancing the association of Rishi Sunak as Prime Minister.\n5.4 Analysis by number of hops and edits\nWe see an overall trend of declining performance with increasing number of hops. However, the 4-hop questions have actually better performance than the 3-hop questions. The primary reason for this is that the MQuAKE dataset contains a more limited variety of reasoning paths for 4-hops relative to 3-hops and the LLM happens to perform better with those style of questions.\nThe trend for the number of edits is much clearer in that the more edits there are that affect a question, the lower the performance is. This makes sense as each edit increases the chance of the edit being improperly incorporated. There are some outliers in this trend such as for 3-hop questions, increasing the number of edits increases the CoT performance. We suspect there may also be some unexpected interactions when multiple edits are applied at once. Since, these are counterfactual edits, the surrounding context may actually imply contradictory information. For instance, if we modify (Hello, performer, Adele Taylor Swift) and change (Taylor Swift, citizenship, United States\u2192Belgium). The contextual edit for the first edit contains both \"The performer of Hello was born in\"\u2192\"United States\" which may be slightly contradictory to the \"citizenship\" edit. In a real world setting, the knowledge graph will change in ways that are consistent with real-world correlations. As a result, we would not need to worry about such behavior outside of rare edge cases."}, {"title": "6 Related Works", "content": "Direct Model Editing Works These approaches include aforementioned works (Zhu et al. 2020; Mitchell et al. 2021; Meng et al. 2022b,a). Other works use a hypernetwork to predict parameter updates for a model Cao, Aziz, and Titov (2021)\nRetrieval Based Works Outside of direct model editing approaches (Zhu et al. 2020; Meng et al. 2022a; Mitchell et al. 2021; Meng et al. 2022b; Ma et al. 2023), other approaches have sought to adapt to changing knowledge via storing external edit memories and employing various in-context learning and retrieval mechanisms. IKE and others add all edits in the LLM context (Zheng et al. 2023; Onoe et al. 2023); SERAC identifies if a related fact has been edited and retrieves it (Mitchell et al. 2022); MeLLo and DeepEdit iteratively retrieve edited memories during the generation and decoding process (Zhong et al. 2023; Wang et al. 2024).\nWe note that these retrieval-based editing approaches are fundamentally different than direct model editing approaches. Direct model editing leaves the model architecture and code entirely the same with the only change being to parameter weights. This means any system developed to use the original model can use the updated model with no other changes. In contrast, retrieval-based editing systems fundamentally change how the model is used and functions. For example, MeLLo requires setting up a retrieval database, iteratively prompting the LLM, making multiple calls to the database, and prompting the LLM to create further sub-questions (Zhong et al. 2023). This fundamentally changes the characteristics of the model, increases latency, and alters model behavior for non-QA tasks. An alternate line of work aims to supplement the parametric knowledge of LLMs by augmenting the model prompt with information retrieved from an indexed corpus (Lewis et al. 2020) or Knowledge Graphs (Markowitz et al. 2024).\nAdditional Aspects of Model Editing Other papers have looked into other aspects of contextual knowledge for edits such as reversibility (Ma et al. 2023), multi-linguality (Wang, Haddow, and Birch 2023; Si, Zhang, and Zhang 2024), or other implied logical conditions given an edit (Wang et al. 2023a; Cohen et al. 2023; Li et al. 2023)."}, {"title": "7 Future Work", "content": "Future directions include both straightforward advancements as well as further analytical directions. Simple advancements include extending K-Edit to broader and deeper contexts. This can include more relation types, increasing the number of iterations to k > 2, and including contextual edges connected to the edit subject s instead of just o*. These directions could yield simple improvements and benchmark gains, especially on the MQuAKE dataset.\nOther interesting future directions include counterfactual knowledge tracing for contextual information as well as better measures of contextual knowledge in edited representations beyond output related metrics. Further, more study on enhancing the generalization effect would enable the creation of better knowledge edits. While K-Edit makes meaningful advancement in contextual integration for knowledge editing, there is still more progress to be made."}, {"title": "8 Conclusion", "content": "This paper presents a K-Edit, an algorithm for improving knowledge-based model editing to better incorporate contextual information. Our experiments show that our approach greatly improves results on multi-hop question answering tasks when edits have been applied. We further show intriguing results demonstrating the potential for better contextual generalization of edits under K-Edit. In addition, our approach scales to thousands of edits at once with no significant degradation on standard metrics. These combine to show that K-Edit is a strong and easy tool for updating and editing knowledge in LLMs while maintaining consistency of information."}, {"title": "9 Limitations", "content": "Our method and experiments have a number of limitations. Our experiments are limited to adding context from a single additional hop from the edit target o*, and only in the \"forward\" direction. However, the evaluation contains up to four hops and also uses context from edges connected to the subject s as well. This means that K-Edit could show improved results if subject context and deeper context were used.\nWe are also limited by the available datasets. Currently, there are only English based datasets for evaluating knowledge editing in multi-hop settings. In addition, we do not know if the multi-hop templating would function the same way in all languages. However, this could be mitigated with falling back to LLM-based generations if needed.\nFinally, this evaluation is limited to 7 billion parameter models or less. While model editing approaches generally become more effective on more capable models, they can also become more computationally costly."}, {"title": "10 Ethical Statement", "content": "We find no major negative ethical implications of this work. Hopefully, enabling high quality model editing work will allow providers to avoid retraining models from scratch, thus avoiding costs and reducing environmental impact.\nAs noted in the limitations, this work is limited to English. We hope that the construction of multi-lingual model editing and multi-hop model editing datasets will enable this work to be studied under other languages. Since many knowledge graphs, Wikidata included, are multi-lingual, we see no reason why this work could not be applied in other languages."}, {"title": "A Hardware", "content": "The hardware requirements depend more on the underlying editing software, in this case MEMIT. We run software using 4 V100-16GB GPUs and make some optimizations for using multiple-GPUs and improving memory management."}, {"title": "B Definitions for Additional Edit Metrics", "content": "These definitions come from prior work and are used in Table 6.\nEfficacy is the expectation that the target generation is more likely than the original fact.\nParaphrase is the expectation that the target generation is more likely than the original fact under paraphrased prompting.\nSpecificity is the expectation that neighborhood prompts remain correct after an edit. Neighborhood prompts are prompts for semantically related subjects instead of s.\nFluency is the weighted sum of the entropy of bi- and tri-gram distributions of the generated text.\nConsistency is computed by generating text about s and checking the TF-IDF similarity with a reference Wikipedia text about o*. Specifically measured as cosine similarity between the TF-IDF vectors."}, {"title": "C MEMIT", "content": "MEMIT (Meng et al. 2022b) works as follows. MEMIT determines a small change to the L-th layer activation of the last token of s (e.g. [Kingdom] in the example above) such that tr(s) produces the desired output o*. It then modifies a subset of the model weights to produce the desired activation for a whole batch of such edits.\nLet $h^L$ be the L-th activation of the last token of s. The target change is $\\tilde{h^L} = h^L + \\delta$ where $\\delta$ is optimized to according to the following:\n$\\delta = \\underset{\\delta}{\\text{argmax}} {\\frac{1}{P} \\sum_{j=1}^{P} \\text{log} P_{\\theta}(h^{L}+=\\delta) \\; [o*|x_j\\oplus \\text{tr}(s)]} $ (1)\nThis calculates a residual vector to be added to $h^L$ such that when tr(s) is input, the model outputs o* with maximum probability. $(h^{L}+= \\delta)$ represents the LLM in which $\\delta$ is added to $h^L$. A weight decay penalty is applied to $\\delta$ to minimize the change. $x_j$ are various contextual inputs prepended to tr(s) to improve generalization.\nAfter computing each desired $\\delta_i$ for each memory i to be batch edited, MEMIT then computes how to spread those changes across a set of \"critical layers\" $[l_0: L]$. Each $\\delta_i$ is split into a residual $r_i$ to be added to each layer according to $r_i = \\frac{\\delta_i}{L - l_0 + 1}$. This assigns each of the critical layers an approximately equal amount of modification towards the desired $\\delta_i$. The following optimization is then applied to the output matrix of the Multi-Layer Perceptron (MLP) block for each critical layer:\n$W_{out} = \\underset{W}{\\text{argmin}} \\frac{\\lambda}{n} \\sum_{i=1}^{n} ||W_{ki} - W_{out \\; ki} - r_i||_2 + \\frac{(1-\\lambda)}{u} \\sum_{i=n+1}^{n+u} ||W_{ki} - W_{out \\; ki}||_2$ (2)\nWhere $W_{out}$ is the new final weight matrix of the MLP block of layer l, $W_{out}$ is the original weight matrix, $k_i$ is the activation input to the weight matrix being changed (intermediate activation of the MLP block). This computation modifies $W_{out}$ so that n edited associations are modified by residual $r_i$ while not affecting u unchanged associations. The actual computation is done using a more efficient format that does not require recomputing large numbers of unchanged associations. Further details can be found in the original paper."}, {"title": "D Hyperparameters", "content": "We introduce no additional hyperparameters beyond hop-count and use hyperparameters from Meng et al. (2022b) otherwise."}, {"title": "E Creating New Relation Templates with LLMS", "content": "The composable structure of our templates for contextual edits allows us to scale K-Edit to exponentially many combinations of multi-hop relations from the number of base templates we have. We note that this approach easily meets the needs of our experiments.\nIn actual deployments it may be worthwhile to include methods for scaling the number of relation types even further. Many knowledge graphs include thousands of different relation types. We introduce an LLM based approach to automatically constructing these base templates. The prompts we use can be found in figures 2 and 3."}]}