{"title": "Optimizing Data Delivery: Insights from User Preferences on Visuals, Tables, and Text", "authors": ["Reuben Luera", "Ryan Rossi", "Franck Dernoncourt", "Alexa Siu", "Sungchul Kim", "Tong Yu", "Ruiyi Zhang", "Xiang Chen", "Nedim Lipka", "Zhehao Zhang", "Seon Gyeom Kim", "Tak Yeon Lee"], "abstract": "In this work, we research user preferences to see a chart, table, or text given a question asked by the user. This enables us to understand when it is best to show a chart, table, or text to the user for the specific question. For this, we conduct a user study where users are shown a question and asked what they would prefer to see and used the data to establish that a user's personal traits does influence the data outputs that they prefer. Understanding how user characteristics impact a user's preferences is critical to creating data tools with a better user experience. Additionally, we investigate to what degree an LLM can be used to replicate a user's preference with and without user preference data. Overall, these findings have significant implications pertaining to the development of data tools and the replication of human preferences using LLMs. Furthermore, this work demonstrates the potential use of LLMs to replicate user preference data which has major implications for future user modeling and personalization research.", "sections": [{"title": "1 INTRODUCTION", "content": "As data and large language models (LLMs) continue to grow in prominence, it is crucial to identify the most effective ways to present data outputs, as the format, whether chart, table, or text, significantly influences how users engage with and interpret information [6, 22]. With datasets becoming larger and more complex, visualizations are increasingly necessary to help users digest the information effectively [7]. The expansion of LLM use in data analysis adds another layer, making it essential to understand when these models should present different output formats. Moreover, individuals have varying preferences for data representation, driven by their unique characteristics, such as experience with data analysis and visualization, age, and work experience. This paper investigates these preferences, exploring how user characteristics shape their choice of data outputs, and how LLMs can adapt to deliver more personalized and intuitive results [1]. Ultimately, by dynamically tailoring outputs based on user backgrounds, LLMs can offer a more customized and effective experience, helping users better understand and utilize data."}, {"title": "Summary of Main Contributions", "content": "The key contributions of this work are as follows:\n\u2022 A comprehensive user survey and methods design. We outline the key components of the Amazon Mturk survey, detailing the respondent population, survey setup, specific user and data-related questions, and the instructions provided to participants.\n\u2022 An analysis of general data output preference results. The first research question examined the general population's preferred data output for a given question, aiming to establish a baseline for data preferences without considering user characteristics.\n\u2022 An overview of data output preferences when organized by personal user characteristics. The 2nd research question explored how a user's personal characteristics influence their data output preferences, focusing on experience with data analysis and visualization and their age.\n\u2022 An overview of data output preferences when organized by work experiences. The third research question explored how work experience, including industry and role, influences users' data output preferences.\n\u2022 A comparison between human and GPT preferences. We used GPT to see if it could predict the human preference data we received throughout the study"}, {"title": "2 RELATED WORK", "content": ""}, {"title": "2.1 Text to Visualization Generation", "content": "Visualization generation, whether charts or tables, from natural language, has become increasingly common as LLMs and natural language interfaces (NLIs) for data grow in popularity. These systems allow users with less data literacy to create comprehensive charts and expansive tables. Current research in this area often focuses on the creation of these systems [15, 16, 21], but does not do expansive research on which data output is best given a natural language question or a user's individual characteristics.\nIn ChartGPT, [21] explains their system as an LLM that is capable of generating charts given abstract natural language inputs. ChartGPT is effective at grouping parts of the natural language inputs into subtasks to identify key parts of it to present an appropriate visualization. Similarly, [16]'s Text2Chart uses BERT and LSTM, two deep learning models, to also create visualizations from natural language. Meanwhile, [15]'s NL4DV relies on traditional NLP methods, like dependency analysis and lexical parsing, instead of on an LLM. We aim to take this research further by simulating the natural language interactions in these systems and exploring data output mediums while also considering different user characteristics."}, {"title": "2.2 Visualization + Text for Analysis", "content": "A lot of work has been done to test the varying degrees in text and data visualizations can be used in tandem with one another to help users digest data. Systems like Eviza [17] create visualization and text combinations that make it easier for users to understand the data they are dealing with. Meanwhile, systems like [18, 19] help users create alt-text for a given data visualization. Creating text for a given data visualization helps users understand data visualizations that may have been inaccessible to them for whatever reason. On the other hand, [8] found that 40% of users do not prefer to see charts when in a conversational UI. Instead, they prefer their answers to be outputted in text.\nWork by [20] investigated the value of including varying degrees of textual information for understanding univariate line charts. This work focused only on univariate line charts and also investigated the placement of text and its impact. While that work investigated showing only a line chart, a line chart with visual and short text annotations, along with showing the user a longer text description. It did not investigate the combination of showing the user a line chart with a detailed text description, nor do they study the utility of including a table with raw data. Furthermore, the findings of that work also conflated visual annotations, as the intermediate charts included in their study, include both visual annotations (i.e. highlighting the maximum value of a time series, and then displaying a textual annotation near it) as well as short textual annotations that are placed near the highlighted point on the line chart."}, {"title": "2.3 Accessibility & Technical Literacy", "content": "The capability to display data in several different formats, such as in charts, tables, or text, is significant for accessibility reasons. As data becomes more relevant to different sectors, data illiteracy can be a limiting factor [4, 5, 23]. Moreover, taking physical and neurological disabilities into account ensures that these systems are more accommodating [10, 11, 24]. Overall, by researching how a person's unique characteristics impact their data preferences, data visualization applications can become more accessible.\nTaking data literacy issues a step further, many users in non-technical fields often find themselves having to interact with complex data sets and visualizations [23]. Furthermore, many companies have limited resources to teach their technically limited workers how to use data appropriately [5], and often have to rely on common end-of-year performance reviews to gauge a worker's technical literacy. For most companies and employees, by this point, it is often too late. Again, most companies do not have the resources to bring their employees up to speed on data techniques, so research continues to be needed for an alternative. Given this, conducting research that takes varying technical literacy and disabilities into account can help understand how to best serve those who are often marginalized in data conversations."}, {"title": "3 STUDY", "content": "We aim to conduct a user study, focused on when it is best to show a visualization, table, text, or any combination of these options to the user for a given question. Our study consists of a user survey and a pre-survey questionnaire. The survey will ask a question and then prompt the user to choose between a chart, text, or table result. We will conduct this user study collecting user preference data and synthesizing these results, highlighting interesting trends.\nIn this work, we study the following research questions:\nRQ1: Given a data question, in general, will users prefer to see the answer visualized as a table, text, or chart?\n\u2022 H1 users will prefer to see their data represented as charts, tables, and then text in that order.\nRQ2: Are there certain personal user characteristics that correlate with the users' preference to see a chart, table or text?"}, {"title": "3.1 Participants", "content": "In order to conduct the survey, we used Amazon Mechanical Turk. In total we uploaded 5 different sets of questions, each set having approximately 50 questions each in addition to the eight demographic questions at the beginning. The data questions were created in a different survey on Upwork, where we asked participants to create general data questions that a user might ask an LLM. In doing so, we pulled from that bank of questions and select them based on their relevance to our survey. Given that there were 5 sets of questions, and 50 questions per set, we essentially had 250 unique questions in total. For each set of questions, the users were compensated $1.40."}, {"title": "3.2 Method", "content": "The survey was broken down into three subsections: the demographic questions, the instructions, and the data survey questions. The answers from the two sections were used in tandem to identify trends and correlations. The same instructions were presented to each user, ensuring consistency with every survey."}, {"title": "3.2.1 User Characteristic Questions", "content": "In order to answer RQ1 and gain a better understanding of if and how a person's characteristics impact their data output preference, we first had to gather user characteristics from each respondent. In doing so, we can map which, if any, user characteristics impact a person's data output and which do not. The questions asked at the beginning of the survey can be found in section B.3."}, {"title": "3.2.2 Instructions", "content": "After the user characteristic questions, we showed a consistent figure that presented an example scenario (Fig. 1). As seen in Fig. 1 the figure consists of a given prompt and then shows three examples of the potential data output mediums. As the user goes through the rest of the survey, they can reference this figure for examples of the different output mediums.\nFurthermore, it was decided that the instructions would be the only place where the user could see examples of text, tables, and charts. This was intentionally done so as not to bias the respondent on each question. If the respondent saw a specific text, table, or chart for each question, this could potentially disrupt their own personal beliefs on what the output could look like. While we understand the drawbacks of this approach, this was the best way to mitigate bias. Given these reasons, we maintained that the instructions would be succinct and section that respondents can reference to get examples of what type of data output they would prefer."}, {"title": "3.2.3 Survey Questions", "content": "As mentioned, each survey had 50 unique questions that all had the same question structure. Each question begins with the same basic instruction: \"Given the question below, please select your preference on how the answer to the question should be presented.\" After this instruction, the user is presented with a generic prompt and asked to choose what data output medium would best fit the needs of that given question (Fig 1).\nAfter being shown these questions, users were presented with three options: text, table, or chart. Given the question, the users were tasked with choosing which of these three data output methods they preferred. These options were presented as radial buttons and the respondents were tasked with choosing one of the three options for each of the 50 questions."}, {"title": "4 RESULTS", "content": ""}, {"title": "4.1 RQ1: General Preferences", "content": "Findings: RQ1 asks: Given a data question or prompt will users prefer to see the answer visualized as a table, text, or chart? From the results, we found that the most common preference was for tables at 41.70%, with charts at 36.2%, and text preferred far less at 21.97% (Fig. 10).\nGiven this, it was clear that there was a large amount of variability between the three data output preferences. Figures 2 & 28 illustrate how user preferences are distributed across individual users and questions. Looking at Figure 2, it is clear that users exhibited preferences for all three data output types to some degree. This signifies the variability within the preferences and speaks to the complexity of the task. The user preferences did not have a uniform consistency and instead displayed significant variation. On a similar note, Figure 28 shows that there was a wide distribution given individual questions, following a similar pattern to Figure 2. Overall, this variability in preferences underscores the need for a deeper analysis on ways to personalize outputs based on user characteristics.\nAnalysis Details & Discussion:\nIn our original hypothesis (H1) it was stated that H1: Users will prefer to see their data represented as charts, tables, and then text in that order.\nThis hypothesis was partially correct as the text was the least preferred output format, but unlike our hypothesis tables and charts were the most preferred outputs, respectively. These results were gathered by calculating the percentage of each output answer within the larger dataset."}, {"title": "4.2 RQ2: User Characteristics", "content": "RQ2 asks: Are there certain personal user characteristics that correlate with the users' preference to see a chart, table, or text?"}, {"title": "4.2.1 Findings Summary", "content": "After conducting the aforementioned study and analyzing the results, we were able to make significant findings pertaining to the relationship between personal user characteristics and their preferred data output. In short, we found that a user's familiarity with data visualization, familiarity with data analysis, and their age all influenced their data output preferences to some degree. For one, in both tests run for data analysis and visualization, we found that those with more experience in either preferred charts. Meanwhile, those with less experience were more drawn to tables. Similarly, in terms of age, younger respondents were more inclined to favor charts, while older respondents had a bias for tables."}, {"title": "Analysis Details", "content": "After we got results from the respondents, we organized the respondents based on their personal characteristics; specifically looking at their familiarity with data analysis and visualizations and their age. We organized the findings into heatmaps that compared the user characteristic (y-axis) with the different data outputs. Unless otherwise mentioned, the heatmaps are normalized row-wise. A p-value that is less than 0.05 shows that a statistically significant association exists and that the null hypothesis can be rejected. The p-values revealed that there were highly significant associations between user characteristics and user preferences."}, {"title": "4.2.2 H2a: Influence of Data Visualization Experience on Preference", "content": "H2a: Respondents with more data visualization experience will prefer charts, while users with less experience will show a stronger preference towards tables and text.\nFigure 3 shows the relationship between a user's familiarity with data visualizations and their data output preferences. As seen in the figure, participants who referred to themselves as \"very familiar\" with data visualizations had the strongest preference for charts (43.2%). As experience with data visualization decreased, so did the preference for charts, with only 26.4% of very unfamiliar respondents preferring charts. Similarly, preference for text also grew stronger as familiarity with data visualization waned, with respondents who were \"very unfamiliar\" preferring text at 36.4% and tables at 37.3%.\nAnalysis: The hypothesis that respondents with more data visualization experience will prefer charts over tables and text was supported (p < 0.01). The values outputted by the study and the statistical tests both support H2a, signifying that users who are more familiar with data visualizations have a stronger preference towards charts. Charts are often only useful to those with a certain level of data visualization literacy, which could explain this trend. Similarly, the converse can be said for the stronger preference for tables and charts for those with less familiarity. Those with less familiarity might prefer these outputs as they are easier to understand with less data visualization experience. Looking at Figure 3 from a high level, there is almost a diagonal that forms from top left to bottom right. This diagonal illustrates that as familiarity wanes, so does the preference for chart. Conversely, the preference for table gets stronger as familiarity wanes, with the \"very unfamiliar\" row being the main outlier."}, {"title": "4.2.3 H2b: Influence of Data Analysis Experience on Preference", "content": "H2b: Respondents with more data analysis experience will also prefer charts over text and table outputs.\nFigure 4 shows the relationship between a contingency table that compares a user's familiarity with data analysis to whichever data output they prefer. In creating this table, we found that data analysis experience is strongly associated with data output preference. More specifically, users who identified themselves as being very familiar with data analysis preferred charts at 41.4%. Meanwhile, those with lower familiarity with data analysis had a stronger bias towards tables with users who identified themselves as unfamiliar and very unfamiliar preferring tables at a rate of 46.0% and 38.3% respectively. Finally, text output was always the least preferred but it grew marginally as familiarity waned.\nAnalysis: The hypothesis that respondents with more data analysis experience will prefer charts over tables and text was supported (p < 0.01). The results from our comparison of a user's data preference output with their data analysis experience are not too dissimilar to the results from the data visualization experience part of the study. For example, users with the most experience with data Analysis showed a strong preference for charts, with the preference dropping with a user's familiarity. However, the difference is that users with the least amount of familiarity with data analysis put an end to the trends in both the chart and table rows. Once again, the preference for charts among the most familiar could be because of the extra level of data literacy that is required to understand charts. Overall, this table shows that there is an association between the two variables. When designing LLMs, designers and developers can use this information to create a better user experience for their users."}, {"title": "4.2.4 H2c: Influence of Age on Preference", "content": "H2c: In terms of age, younger respondents will show a stronger preference towards charts, while older respondents will prefer tables and text.\nFigure 5 shows the relationship between a user's age range to what data output they prefer. In doing so, we found that different age groups prefer different data output methods. For one, younger users aged 18-24 showed the strongest bias toward charts at 43.1%. On the other hand, the preference for tables increased with age, with users 45 and older showing a preference for tables. Finally, text was the least preferred data output across all ages with 18-24 year olds preferring it the least at 15.9%.\nAnalysis: The hypothesis that younger respondents will prefer charts over tables and text while older respondents would prefer the opposite was supported (p < 0.01). The data outputted in the contingency table in Figure 5 and the p-value show that age is strongly associated with a user's data output method of choice. As mentioned, younger user's seem to prefer charts the most, but the interesting part is that this preference for charts seems to steadily drop with age, with the biggest drop coming between the 18-24 group and the 25-34 group. According to [12, 14, 25], younger generations prefer receiving information in easier-to-understand snippets, than larger sets of texts. Given this, it makes sense that this age group has a stronger preference for charts, with there also being a steady decline in chart preferences with each age group. Conversely, table preferences typically increase as participants get older. All in all, this data can be used when designing user experiences as it shows that a user's primary data output preference may change with age."}, {"title": "4.3 RQ3: Work Experience", "content": "RQ3 asks: Does a respondent's role at work or industry they work in correlate with their preference to see a visualization, table, or text?"}, {"title": "4.3.1 Findings Summary", "content": "After conducting a study comparing the influence of a user's work experience on their data output preferences, we concluded that there are highly significant associations between the two. Specifically in terms of roles, we found that those in decision-maker roles strongly preferred tables, while analysts had the strongest preference for charts among the group (Fig. 6). Meanwhile, in terms of a user's industry, there was a lot of variation but industries like development and IT, and Sales and Marketing preferred charts more than other industries (Fig. 7).\nAnalysis Details: After we got results from the respondents, we organized the respondents based on their work experiences; specifically looking at the role they played at work and the industry they worked in. Given these findings, we used p-values as forms of statistical analysis. The p-values revealed highly significant associations between the users' work experiences and the user data output preferences."}, {"title": "4.3.2 H3a: Influence of Role on Preference", "content": "H3a: Respondents will prefer different data outputs based on the role they play at work, with more presentation-oriented roles preferring charts.\nFigure 6 shows the relationship between a user's role at work with their data output preferences. In general, the results show that the data preferences are significantly different depending on a user's role. For example, for those who identified as analysts, charts were the most preferred data output method (38.7%). On the other hand, decision makers were the group that preferred charts the least at 28.5%, but preferred tables 51.9% of the time. Finally, support specialists had the highest bias for text at 27.5% of responses.\nAnalysis: The hypothesis that respondents with more presentation oriented workers will prefer charts over tables and text was not supported (p < 0.01). For the most part, each role had a stronger preference for tables than they did for charts, even if for some it was not by much. Considering that each role has a varied preference percentage breakdown and that the P-value is p < 0.01, there is a strong indication that there is a significant association between data preference and role. From these results, it can be concluded that LLMs could use a user's work role to influence what data output they use. For example, if a user is marked as a decision maker, it may make sense to show them a table given that respondents preferred tables 51.0% of the time. Furthermore, an LLM might also want to give more weight to charts for analysts as they preferred charts 38.7% of the time. Given all of this information, LLMs have the opportunity to be more personalized by incorporating data like this that presents data based on a user's persona."}, {"title": "4.3.3 H3b: Influence of Industry on Preference", "content": "H3b: Respondents will prefer different data outputs based on the industry they work in, with more technical industries preferring tables and text.\nFigure 7 displays the relationship between the industry a user works in and whether they prefer data outputted as a table, chart, or text. From this chart, it is clear that respondents in the Development and IT industry had the highest preference for charts at 39.2%. Meanwhile, industries like finance and accounting have a stronger preference for tables at 43.5%. Finally, text was most strongly preferred by unemployed respondents at 30.1%, suggesting that they prefer a narrative with their data.\nAnalysis: The findings support (p < 0.01) our hypothesis as respondents preferred different data outputs based on the industries they worked in. Even more so, technical fields like Development and IT have a stronger preference for charts. This could potentially be because they are more efficient at conveying trends [22]. Similarly, those in the Finance and Accounting industries preferred tables, suggesting that they may have wanted to look at many data points and potentially compare them [6]. Developers of LLMs can use this information to make their systems more responsive to users in a wide array of industries."}, {"title": "4.3.4 Preferences When Combining User Characteristics", "content": "Figure 8 highlights how the intersection of a user's combined experience with both data analysis and visualizations influences their data output preferences. This further segmentation of the data can help gain more granular insights into how different user characteristics influence a user's preferences.\nFor example, if a respondent marked that they were highly familiar with both data analysis and visualizations (data visualization experience = 5; data analysis experience = 5), then they were more likely to prefer charts (46%) over tables (35%) or text (18%). However, when a respondent indicated that they were experienced in only data analysis (data visualization experience = 1; data analysis experience = 5) we found that their preference shifted heavily towards text (78%). The shift away from visualizations makes sense as these users most likely have to use text to compensate for their lack of visualization experience. Similarly, novices in both data analysis and visualizations (data visualization experience = 1; data analysis experience = 1) both show a marginal preference for charts (37%). However, with an increase in data analysis experience, users begin to strongly prefer tables at 45%.\nThe takeaways about user preferences become more substantial when comparing two unalike user characteristics, such as a user's role and visualization experience (Figure 23). While users may have one characteristic consistent, the difference in the other characteristic often causes a sizeable swing in their data preferences. For example, an analyst with high visualization experience prefers charts (43%), while analysts with less experience prefer tables (47%). All in all, the fluctuations across similar roles and similar visualization experiences produce the finding that even the slightest change in user characteristics can influence their preferences.\nThese particular data points underscore that not all users with the same user characteristics have the same preferences. The preferences do not exist in a vacuum and often are dependent on other user characteristics. For this reason, LLMs and other data tools need to be able to dynamically adjust to a combination of user characteristics to best meet the needs of the user."}, {"title": "4.4 RQ4: LLM Preference Predictions", "content": "RQ4: Can LLMs be used to predict whether a question should be answered with a visualization, data table, or text?\nIn other words, is there alignment on this task between what humans actually prefer and the inferences generated by the LLM? Notably, this question is of fundamental importance since if this holds, then LLMs can be used to infer how a question should be answered for a specific user."}, {"title": "4.4.1 H4a: LLM Alignment with Humans", "content": "H4a: Using an LLM without user-specific personalization will perform poorly on predicting whether a user should be answered with a chart, table, or text.\nTo answer this question, we used the approach shown in Figure 27. For the LLM we used GPT40 (gpt-40-2024-05-13b). Using this non-personalized approach to predict the answer preferred by a user for a given question, the average accuracy is 0.367. Notably, the average accuracy of the non-personalized LLM approach is very close to what would be expected by random selection. This finding implies that different users often have different preferences for how they want the answer to be presented for a given data analysis question. Hence, this result is interesting and important from a personalization perspective, and leads us to the next few research questions that seek to test whether including user-specific information including their characteristics and preferences about other questions can lead to better predictive performance."}, {"title": "4.4.2 H4b: Personalized LLMs", "content": "H4b: Does including user-specific examples and user characteristics in the LLM improve the accuracy of the LLM in generating the preferred answer for individual users?\nTo answer this question, we personalized the LLM by including the user characteristics and previous preferences that a specific user had, that is, we included questions along with how they prefer to view the answer to it (text, data table, visualization). We provide an overview of the approach in Figure 26. In Figure 9, we observe that the accuracy in terms of how well we personalize the responses for the specific user increases as a function of the number of user-specific examples we use for inference. To understand the effectiveness of our approach, we also investigated the accuracy when we removed different components of our approach. Notably, when we remove the few-shot examples, our approach achieves only 0.377 accuracy whereas when both the few-shot examples and user characteristics are removed, the performance decreases further to 0.367. We note that this last ablation is the case where no personalization is used since we do not include any user-specific examples (few-shot) and we do not provide any user characteristics to the model. In comparison, we achieve an accuracy of 0.469 and 0.487 when 20 and 40-shots are used by the model, respectively.\nAs an aside, we also investigated GPT3.5 using 40-shot user-specific examples with visualization experience, data analysis experience and the users' role. For this model, we achieved an accuracy of 0.441 compared to 0.487 using the GPT40 model."}, {"title": "4.4.3 H4c: User-specific Accuracy", "content": "H4c: Can the personalized LLM approach perform well for some users and worse for others? In other words, are some users easier to personalize and others more difficult.\nWe also investigated the accuracy of individual users in Table 1. For brevity, we provided the accuracy of ten users across the different models. We also selected a small subset of users and provided their user-specific accuracies from the various models investigated. We also now show accuracy for a small subset of users, and this just shows that for some users, predicting how they want the answer to be is easy, but for others it is more difficult."}, {"title": "5 DISCUSSION", "content": "This study focuses on how user characteristics influence a user's data output preferences, specifically conducting a user study measuring the preferences between charts, tables, and text outputs. We then synthesized and presented the results, and in this section, we discuss the results, examine common themes and highlight practical takeaways that can be applied to existing data tools."}, {"title": "5.1 General Preferences", "content": "Research question 1 (RQ1) looked at the issue from a bird's eye view and established the framework for later RQs, but also was significant in its own right in that it provided insight into general preferences. We hypothesized that charts would be the most preferred, but users actually generally preferred tables 41% of the time. Charts were preferred at a somewhat similar rate of 36.2% and text was the least preferred at 21.9%.\nFrom this data, we can gather that tables are still preferred because of their ability to quickly display large data sets and allow the user to find and compare specific pieces of data [6]. Considering that charts are not far behind, the utility of charts should not be underestimated as they are useful in identifying trends [22]. Finally, text still had a substantial amount of users saying they preferred it, which can have something to do with its straightforward nature or even its ability to tell a narrative."}, {"title": "5.2 Influence of User Characteristics and Work Experience", "content": "The results show that user characteristics such as data visualization experience, data analysis experience, and age significantly influence data output preferences. Users with more experience in data visualization and analysis demonstrated a strong preference for charts, likely because they are more accustomed to interpreting trends and complex data [22]. Meanwhile, those with less experience tended to prefer tables, possibly due to the need for quickly comparing and contrasting large data sets. Age also plays a role, as younger users favored charts, likely due to their familiarity with visually rich platforms, while older users were more inclined to prefer tables and text. This indicates that user characteristics indeed shape the way users prefer to receive data outputs.\nWork experience also greatly affects data preferences, with users' roles and the industries they work in shaping their output preferences. Analysis-oriented roles leaned towards charts, as they offer high-level insights, while decision-makers showed a stronger preference for tables, valuing the quick and accurate information they provide. Likewise, industry differences were notable: development and IT professionals preferred both charts and tables, likely for presenting trends and precise data, while those in finance and accounting favored tables due to their need for large volumes of exact, easily comparable data. These findings emphasize the opportunity to personalize data outputs based on work roles and industries, tailoring data presentations to better suit the needs of different users based on their professional backgrounds."}, {"title": "5.3 Human Preference vs. GPT Preference", "content": "The results from investigating RQ4 reveal that providing user-specific information helps large language models predict how users will prefer to see their data. By feeding the LLMs user data like user role, data visualization experience, age, etc., we can increase the effectiveness of the models' predictions. Specifically, the LLM performed much better as we increased the user data we provided during a few shot learning, with accuracy numbers rising from 0.367 with no user data to 0.487 with forty or so examples. Providing LLMs with few shot examples significantly increased its accuracy. Overall, from this, we can gather that feeding an LLM personal data alters an LLM's outputs.\nFurthermore, comparing GPT40 with GPT3.5 revealed that using the more advanced models for predicting personalization improves accuracy. Despite the finding that feeding LLM models improves accuracy, the user-specific accuracy variance still shows that some users are harder to predict. With this in mind, LLMs still require further tuning before they can be considered fully accurate or reliable in this space. With this in mind, we summarize our findings by stating that feeding personalized information improves GPT's ability to predict user preferences, but continued work should be done to optimize models to improve accuracy."}, {"title": "6 CONCLUSION", "content": "In this paper, we conducted a research survey that investigated how user characteristics and work experiences shape data output preferences. We found that each of the characteristics we studied influenced a user's data output preference in some way. For this reason, we recommend that data tools tailor their outputs to the personal characteristics of each user. Doing so will create a better user experience and is likely to increase efficiency. Additionally, we used this data to explore how effective LLMs are at predicting these user preferences. Our findings indicate that when LLMs are given no personalization information, they perform poorly. However, when the LLM is provided with user-specific information, its performance improves significantly, with accuracy increasing markedly. These findings underscore the significance of understanding a user's characteristics when creating data tools and attempting to replicate preferences when using LLMs."}, {"title": "B STUDY DESIGN", "content": ""}, {"title": "B.1 Human Annotations", "content": "\u2022 Title: Output Medium Preference for Data Analytics Natural Language Questions\n\u2022 Description: We require output preferences for questions asked to an Analytics system. Given a question about analytics data such as \"What is the total revenue last month\"", "Questions": "We aim to have participants do 20 Questions. Justification: for this is that we may want to keep it brief for MTurkers so that they do not just click through the survey. Potential drawback: not getting a large amount of results from the same MTurker.\n\u2022 Fifteen Minutes: Given that we will have 20 questions with the reader having to read the instructions", "questions": "No. Justification: providing different types of questions can give us a wider spread of data. However", "Drawback": "Maybe more variation.\n\u2022 Price: \".40 cents\" Given that we will have up to 20 questions, we may want to offer more money than usual as the survey"}]}