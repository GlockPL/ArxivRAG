{"title": "OPTIMAL DECISION MAKING THROUGH SCENARIO\nSIMULATIONS USING LARGE LANGUAGE MODELS", "authors": ["Sumedh Rasal", "E. J. Hauer"], "abstract": "The rapid evolution of Large Language Models (LLMs) has markedly expanded their application\nacross diverse domains, transforming how complex problems are approached and solved. Initially\nconceived to predict subsequent words in texts, these models have transcended their original design\nto comprehend and respond to the underlying contexts of queries. Today, LLMs routinely perform\ntasks that once seemed formidable, such as writing essays, poems, stories, and even developing\nsoftware code. As their capabilities continue to grow, so too do the expectations of their performance\nin even more sophisticated domains.\nDespite these advancements, LLMs still encounter significant challenges, particularly in scenarios\nrequiring intricate decision-making, such as planning trips or choosing among multiple viable op-\ntions. These tasks often demand a nuanced understanding of various outcomes and the ability to\npredict the consequences of different choices, which are currently outside the typical operational\nscope of LLMs.\nThis paper proposes an innovative approach to bridge this capability gap. By enabling LLMs to\nrequest multiple potential options and their respective parameters from users, our system introduces\na dynamic framework that integrates an optimization function within the decision-making process.\nThis function is designed to analyze the provided options, simulate potential outcomes, and de-\ntermine the most advantageous solution based on a set of predefined criteria. By harnessing this\nmethodology, LLMs can offer tailored, optimal solutions to complex, multi-variable problems, sig-\nnificantly enhancing their utility and effectiveness in real-world applications. This approach not\nonly expands the functional envelope of LLMs but also paves the way for more autonomous and\nintelligent systems capable of supporting sophisticated decision-making tasks.", "sections": [{"title": "1 Introduction", "content": "Large language models (LLMs) have demonstrated remarkable utility across various domains [Brown et al., 2020]\n[Thoppilan et al., 2022], showcasing their ability to solve programming challenges [Chen et al., 2021], elucidate com-\nplex topics in simpler and more understandable language, and generate unique texts that include novel and in-\nteresting content [Ouyang et al., 2022] [Wei et al., 2022] [Bubeck et al., 2023]. From generating human-level text\nto tackling intricate programming questions, LLMs have continually proven their versatility and effectiveness\n[Saunders et al., 2022] [Touvron et al., 2023] [Devlin et al., 2018] [OpenAI, 2023].\nDespite their impressive capabilities, LLMs face significant limitations when addressing complex problems that re-\nquire more than just pattern recognition and language generation [Liu et al., 2023]. While LLMs can autonomously\noperate and learn patterns to generate coherent text, they are not inherently designed to tackle complex, multi-\nfaceted problems that involve multiple possible solutions [Rajani et al., 2019] [Ling et al., 2017] [Cobbe et al., 2021]\n[Chen et al., 2019] [Patil et al., 2023] [Lu et al., 2023] [Yao et al., 2022] [Li et al., 2023]. For instance, solving pro-\ngramming problems may seem magical at first glance, but it relies on the LLM's ability to recognize and apply pat-\nterns, structures, and meanings inherent in the problem statements. Given sufficient data for training, the architecture\nof LLMs is adept at understanding these patterns and producing accurate solutions."}, {"title": "2 Methodology", "content": "Recently, large language models (LLMs) have been employed in numerous applications. For example, they are used to\nsummarize text, generate ideas, and solve novel coding problems. They can be prompted to assume various personas\nto answer questions in specific contexts, such as legal, business, or sports. LLMs are capable of holding extended\nconversations, though they have their shortcomings. One key limitation is their dependency on pre-existing knowl-\nedge bases for retrieving factual information, which can lead to inaccuracies when faced with novel questions, often\nresulting in random or incoherent text, a phenomenon known as hallucination [Azamfirei et al., 2023].\nRetraining LLMs [Rasal and Boddhu, 2024] to expand their knowledge base is an expensive and resource-intensive\nprocess. While creating context-specific LLMs is a viable alternative, it does not solve the problem of developing an\nall-purpose LLM. Moreover, the concept of an all-purpose LLM leading to true artificial general intelligence (AGI)\nremains questionable. Without perceptors, an LLM cannot achieve true AGI [Rasal and Hauer, 2024]. Therefore,\nwe propose an approach that uses LLMs as the core of the operation, augmented by additional perceptors to aid in\ndecision-making and provide users with solutions to complex problems.\nOur system architecture comprises the following components: User Input Interface, LLM Chat Agent, Simulation\nModule, Optimization Engine, Context-Aware Data Warehouse, and Result Interface. We will now discuss each\ncomponent to understand the overall workflow.\nUser Input Interface\nThis module serves as the portal through which users submit their problem statements. It is powered by an LLM chat\nagent, which extracts user requirements and converts them into input parameters for the simulation module. The chat\nagent also queries context-aware data relevant to the user problem and asks pertinent questions to ensure all necessary\ninformation is gathered. This enables users to make informed decisions once the results are computed. Our approach\nis designed to tackle problems that resemble decision tree scenarios or combinatorial problems.\nLLM Chat Agent\nWe utilize OpenAI's GPT-4 chat agent with specific prompts to engage with users and extract detailed information\nabout their problem statements. These details are crucial for the simulation module to run multiple scenarios on the\ngiven problem. The optimization engine then narrows down the best options for the user, considering the constraints"}, {"title": "3 Experiments", "content": "To illustrate the practical application of our proposed system, we conducted an experiment focusing on the decision-\nmaking process involved in choosing between buying and leasing a car. This experiment demonstrates how the various\nmodules in our system work together to provide users with optimal solutions based on their specific needs and con-\nstraints. We will walk through the experiment step-by-step, highlighting the interactions between the user and the\nLLM agent, as well as between the LLM agent and the Python interpreter.\nUser Input Interface\nThe user begins by interacting with the User Input Interface, which is powered by the LLM chat agent. The user\nprovides their initial query about whether to buy or lease a car.\nUser: \"I'm trying to decide if I should buy or lease a car. Can you help me figure out\nthe best option?\"\nLLM Agent: \"Of course! To help you decide, I'll need some additional information. Can\nyou tell me about your driving habits, budget, and any preferences you have for the car?\"\nUser: \"I drive about 15,000 miles a year. My budget for monthly payments is around $400.\nI prefer a new car with good fuel efficiency.\"\nThe LLM agent gathers these inputs and converts them into specific parameters for the simulation module.\nLLM Chat Agent\nThe LLM chat agent continues to engage with the user to extract more detailed information and ensure all necessary\nvariables are captured.\nLLM Agent: \"Great! I need to know the following details to proceed: the expected duration\nof ownership if you choose to buy, any down payment you can make, and your estimated\nannual maintenance costs. For leasing, I need to know the lease term you're considering\nand any potential mileage overage charges.\"\nUser: \"If I buy, I plan to keep the car for about 5 years. I can make a down payment of\n$3,000, and I estimate annual maintenance costs at $500. For leasing, I'm considering a"}, {"title": "4 Results", "content": "To validate the proposed architecture and methodology for using LLMs to simulate and optimize decision-making pro-\ncesses, we conducted a series of tests on the system's individual components. The goal was to assess the effectiveness\nof the system in understanding the user's problem, generating accurate simulations, running optimization processes,\nand retrieving relevant data from the data warehouse.\n4.1 User Input Interface\nThe objective was to determine if the system could ask all relevant questions needed to understand the user's problem.\nWe provided a series of user inputs and evaluated the completeness of the system's questions. The system success-\nfully asked all necessary questions, ensuring comprehensive data collection and a deep understanding of the user's\nrequirements.\n4.2 LLM Chat Agent: Information Extraction\nThe LLM's ability to extract and convert user requirements into simulation parameters was evaluated by processing\nuser inputs and reviewing the extracted parameters for accuracy. The LLM accurately converted the user input into\nparameters suitable for simulation, demonstrating its capability to handle complex problem statements and translate\nthem into actionable data.\n4.3 Simulation Module: Environment Generation\nWe checked if the simulation module could generate a functional simulation environment by tasking it with creating\nenvironments based on various user scenarios. The simulation module consistently produced valid and functional\nsimulation environments, proving its robustness and flexibility in handling different types of problems.\n4.4 Optimization Engine: Function Execution\nThe optimization engine's ability to run the simulation function and derive an optimal solution was ensured by exe-\ncuting the simulation functions and analyzing the outputs. The engine successfully ran the simulations and provided\noptimal solutions based on the given data, showcasing its effectiveness in optimizing complex decision-making pro-\ncesses.\n4.5 Context-Aware Data Warehouse: Data Retrieval\nFinally, the system's ability to retrieve relevant data and assign probabilities to the output was assessed. The data\nretrieval and probability assignment processes were tested with various queries, and the system accurately retrieved"}, {"title": "5 Limitations", "content": "While the proposed architecture demonstrates significant potential in addressing a variety of problem statements, there\nare several limitations that need to be acknowledged. First, although the architecture is designed to handle a range of\nproblems, we were not able to validate its performance across a wide variety of problem domains. The experiments\nconducted focused on specific scenarios, and thus, further testing is required to ensure its robustness and versatility in\ndifferent contexts.\nAnother key limitation is the dependency on the data warehouse to supply relevant probability information. The\naccuracy of the system's output is highly contingent on the quality and comprehensiveness of the data stored in the\nwarehouse. Populating the data warehouse with relevant and up-to-date information is a continuous process and poses\na significant challenge. Without a well-maintained data warehouse, the probability assignments and, consequently, the\nrecommendations generated by the system might not be accurate.\nAdditionally, there were instances where the LLM chat agent failed to collect all the required information before\ninitiating the optimization step. This shortcoming highlights the need for improved mechanisms within the chat agent\nto ensure thorough data collection. Incomplete data can lead to suboptimal or inaccurate solutions, undermining the\neffectiveness of the entire system. Enhancements in the question-asking algorithms and context understanding of the\nLLM chat agent are necessary to mitigate this issue.\nDespite these limitations, the architecture provides a promising approach to leveraging LLMs in decision-making\nprocesses. Future work should focus on expanding the validation of the system across diverse problem statements,\nimproving data warehouse maintenance strategies, and refining the LLM chat agent's data collection capabilities to\nensure more reliable and accurate outcomes."}, {"title": "6 Conclusion", "content": "The evolution of large language models (LLMs) has profoundly impacted various domains, from generating human-\nlike text to solving complex programming challenges. Our proposed approach leverages the advanced capabilities\nof LLMs to tackle decision-making problems by simulating multiple scenarios and providing users with the optimal\nsolution. This methodology integrates several key components: the user input interface, LLM chat agent, simulation\nmodule, optimization engine, context-aware data warehouse, and result interface. Each of these components plays\na crucial role in ensuring that the system can accurately interpret the user's problem statement, simulate potential\nsolutions, and optimize the final recommendations.\nThrough our experiments, we demonstrated the utility of this architecture using a practical example of deciding be-\ntween buying and leasing a car. The system effectively collected the necessary information, ran simulations using a\nPython-based Monte Carlo simulator, and employed the optimization engine to deliver a well-informed decision to the\nuser. This approach not only provided the optimal solution but also detailed the impact of various factors on the final\ndecision.\nDespite the promising results, our system faces several limitations. We could not validate its performance across\na wide array of problem domains, indicating the need for further testing to ensure its robustness and versatility. The\ndependency on a well-maintained data warehouse is another significant challenge, as the accuracy of the output heavily\nrelies on the relevance and quality of the stored data. Additionally, there were instances where the LLM chat agent did\nnot collect all necessary information before starting the optimization process, highlighting the need for enhancements\nin the data collection mechanisms.\nFuture work should focus on expanding the validation of the system across diverse problem statements, improving\nstrategies for maintaining the data warehouse, and refining the LLM chat agent's capabilities to ensure thorough data\ncollection. By addressing these limitations, we can enhance the reliability and effectiveness of our approach, making\nit a valuable tool for decision-making in various complex scenarios."}]}