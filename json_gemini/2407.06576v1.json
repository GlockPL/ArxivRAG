{"title": "Virtual Personas for Language Models via an Anthology of Backstories", "authors": ["Suhong Moon", "Marwa Abdulhai", "Minwoo Kang", "Joseph Suh", "Widyadewi Soedarmadji", "Eran Kohen Behar", "David M. Chan"], "abstract": "Large language models (LLMs) are trained from vast repositories of text authored by millions\nof distinct authors, reflecting an enormous diversity of human traits. While these models bear\nthe potential to be used as approximations of human subjects in behavioral studies, prior efforts\nhave been limited in steering model responses to match individual human users. In this work,\nwe introduce \u201cAnthology\u201d, a method for conditioning LLMs to particular virtual personas by\nharnessing open-ended life narratives, which we refer to as \u201cbackstories.\u201d We show that our\nmethodology enhances the consistency and reliability of experimental outcomes while ensuring\nbetter representation of diverse sub-populations. Across three nationally representative human\nsurveys conducted as part of Pew Research Center's American Trends Panel (ATP), we demon-\nstrate that Anthology achieves up to 18% improvement in matching the response distributions\nof human respondents and 27% improvement in consistency metrics. Our code and generated\nbackstories are available at https://github.com/CannyLab/anthology.", "sections": [{"title": "Introduction", "content": "Large language models (LLMs) are trained from vast repositories of human-written text (Tou-\nvron et al., 2023; Meta, 2024; Brown et al., 2020; OpenAI, 2024; MistralAI, 2024; Jiang et al., 2024a).\nThese texts are authored by millions of distinct authors, reflecting an enormous diversity of human\ntraits Choi and Li (2024); Wolf et al. (2024). As a result, when a language model completes a prompt,\nthe generated response implicitly encodes a mixture of voices from human authors that have pro-\nduced the training text from which the completion has been extrapolated. Although this nature\nof language models has been overlooked due to its marginal influence in current widely-adopted\nusages of LLMs, such as factual question-answering (QA) and algorithmic reasoning, when the\nmodel is queried with open-ended questions or is intended to be conditioned as particular personas,\nit is critical to address the fact that these models inherently reflect an averaged voice from the mixture\nof human authorship."}, {"title": "Conditioning LLMs to Virtual Personas via an Anthology of Backstories", "content": "In this section, we discuss details of the proposed Anthology approach. We start with answering the\ncore question: What are backstories and how might they help condition LLMs to particular personas\nwhen given as context? With an example, we examine and lay out the advantages of conditioning\nmodels with backstories in Section 2.1."}, {"title": "What are Backstories?", "content": "We use the term backstories to refer to first-person narratives that encompass various aspects of an\nindividual's life, from where and how they grew up, their formative experiences, education, career,\nand personal relationships, to their values and beliefs. These stories are inherently open-ended and\npersonal, touching upon diverse facets of the author's demographic and personality traits.\nConsider the example shown in Figure 3. We observe that the life story both explicitly and im-\nplicitly encodes information about the author, thereby providing rich insight into who the author is.\nFor instance, the backstory provides explicit hints about the author's age (\u201cin my 60s\u201d), hometown\nand/or region (\u201cbackwoods of this country\u201d), and financial status during childhood (\u201cgrew up\nwith very little\u201d). But rather than being a simple listing of the aforementioned traits, the story itself\nembodies a natural, authentic voice of a particular human that reflects their values and personality.\nMcAdams (1993); Bruner (1991).\nOur proposed approach is to condition language models with backstories by placing them as a\nprefixes to the LLM Brown et al. (2020); Touvron et al. (2023) so as to strongly condition the ensuing text\ncompletion, in the same spirit of standard prompting approaches. As we see in Figure 3, backstories\ncapture a wide range of attributes about the author through high levels of detail and are naturalistic\nnarratives that provide realism and consistency of the persona to which the LLM is conditioned."}, {"title": "LLM-Generated Backstories", "content": "A collection of human-written backstories could be drawn from existing sets of autobiographies or\noral history collections. The challenge, however, is both in terms of scale and diversity Yang et al.\n(2023, 2022). We find that, in their current standing, publicly available sources of autobiographical\nlife narratives and oral histories are limited in the number of samples to sufficiently approximate\nlarger human studies.\nInstead, we propose to generate conceivably realistic backstories with language models as cost-\nefficient alternatives. As shown in Step 1 of Figure 2, we prompt LLMs with an open-ended prompt\nsuch as, \u201cTell me about yourself.\u201d We specifically care for the prompt to be simple so that the\nmodel responses are unconstrained and not biased. The prompt, however, does implicitly ask for\na comprehensive narrative. Responding to this prompt requires the language model to generate a\nseries of interconnected events and experiences that form a coherent life trajectory, which inherently\nimplies consistency and progression as in Figure 3. With sampling temperature T = 1.0, we generate\nbackstories that encapsulate a broad range of life experiences of diverse human users. Further details\nabout LLM generation of backstories, including examples, are summarized in Appendix B."}, {"title": "Demographic Survey on Virtual Personas", "content": "As we intend to utilize virtual personas in the context of approximating human respondents in\nbehavioral studies, it is critical that we curate an appropriate set of backstories that would condition\npersonas representing the target human population. Each study would have a specific set of demo-\ngraphic variables and an estimation or accurate statistics of the demographics of its respondents.\nNaturalistic backstories, despite their rich details about the individual authors, are however not\nguaranteed to explicitly mention all demographic variables of interest. Therefore, we emulate the\nprocess of how the demographic traits of human respondents have been collected\u2014performing\ndemographic surveys on virtual personas, as shown in Step 2 of Figure 2.\nWhile we use the same set of demographic questions as used in the human studies, we consider\nthat, unlike human respondents who each have a well-defined, deterministic set of traits, LLM virtual\npersonas should be described with a probabilistic distribution of demographic variables. As such,\nwe sample multiple responses for each demographic question to estimate the distribution of traits\nfor the given virtual persona. Further details about the process and prompts used in demographic\nsurveys are described in Appendix E."}, {"title": "Matching Target Human Populations", "content": "The remaining question is: How do we choose the right set of backstories for each survey to approx-\nimate? With the results of the demographic survey, we match virtual personas to the real human\npopulation, presented as Step 3 in Figure 2. In doing so, we construct a complete weighted bipartite\ngraph defined by the tuple, $G = (H, V, E)$.\nThe vertex set $H = {h_1, h_2, ..., h_n}$ represents the human user group with the size of n, while the\nother vertex set $V = {V_1, V_2, ..., V_m}$ represents the virtual user group with the size of m. Each vertex\n$h_i$ consists of demographic traits of i-th human user. Specifically, $h_i = (t_{i1}, t_{i2}, ..., t_{ik})$ where k is the\nnumber of demographic variables, and $t_{il}$ is the l\u2014th demographic variable's trait of i\u2014th user. Sim-\nilarly, for each vertex in V, $v_j$ comprises probability distributions of demographic variables of each\nvirtual user, defined as $v_j = (P(d_{j1}), P(d_{j2}), ..., P(d_{jk}))$, where $d_{j1}$ is j\u2212th user's l\u2013th demographic"}, {"title": "Approximating Human Studies with LLM Personas", "content": "In this section, we discuss the large-scale human studies that we aim to approximate (Step 4 of\nFigure 2) using LLM virtual subjects, based on varying methods of persona conditioning. We detail"}, {"title": "Related Work", "content": "Generating Personas with LLMS Recent advancements in language model applications have\nexpanded into simulating human responses for psychological, economic, and social studies (Karra\net al., 2023; Aher et al., 2023; Binz and Schulz, 2023; Horton, 2023; Fatouros et al., 2024; Argyle\net al., 2023). Specifically, the generation of personas using LLMs to respond to textual stimuli has\nbeen explored in various contexts including human-computer interaction (HC), multi agent system,\nanalysis on biases in LLMs, and personality evaluation. (Kim et al., 2020; Simmons, 2022; Park et al.,\n2022; Santurkar et al., 2023; Jiang et al., 2024b; Choi and Li, 2024; Liu et al., 2024a; Wu et al., 2024; Li\net al., 2023; Hilliard et al., 2024; Serapio-Garc\u00eda et al., 2023; Hu and Collier, 2024; Hwang et al., 2023;\nAbdulhai et al., 2023). For instance, Park et al. (2022) and Santurkar et al. (2023) develop methods\nto prime LLMs with crafted personas, influencing the models' outputs to simulate targeted user\nresponses. Additionally, Liu et al. (2024a) introduces a method where personas are generated by\nsampling demographic traits coupled with either congruous or incongruous political stances. Our\napproach, Anthology, advances this concept by employing dynamically generated, richly detailed\nbackstories that include a broad spectrum of demographic and economic characteristics, enhancing\nthe granularity and authenticity of simulated responses.\nLLMs in Social Science Studies The integration of LLMs into social science research has been\nsteadily gaining attention, as highlighted by several studies (Bail et al., 2023; Park et al., 2023a;\nDillion et al., 2023; Ziems et al., 2023; Korinek, 2023). Notably, the use of LLMs to mimic human\nresponses to survey stimuli has gained popularity, as evidenced by recent research (Tjuatja et al., 2023;\nDominguez-Olmedo et al., 2023; Kim and Lee, 2024). A notable example is the \"media diet model\u201d\nby Chu et al. (2023), which predicts consumer group responses based on their media consumption\npatterns. Further, studies like Wu et al. (2023) and Ziems et al. (2023) demonstrate the potential of\nLLMs in zero-shot learning settings to analyze political ideologies and scale computational social\nscience tools. Our work builds on these methodologies by using LLMs not only to generate responses\nbut to create and manipulate backstories that reflect diverse societal segments, providing a nuanced\ntool for social science research and beyond."}, {"title": "Limitations and Societal Impact", "content": "This work introduces Anthology, a new methodology for conditioning large language models (LLMs)\non dynamically generated, narrative-driven backstories, effectively simulating human-like personas.\nThis approach exploits the diverse human experiences embedded within the training data, enhancing\nthe applicability of virtual personas in social sciences and beyond. However, despite promising\nresults, the approach encapsulates inherent limitations and significant societal implications which\nwarrant careful consideration."}, {"title": "Limitations", "content": "This study, while advancing the application of LLMs in social sciences through Anthology, acknowl-\nedges several inherent limitations:\n\u2022 Simulation Fidelity: We do not suggest that LLMs can fully simulate a given human user\nmerely by using a user's backstory as a prompt prefix. Instead, we propose Anthology as"}, {"title": "Societal Impact", "content": "Employing LLMs to create virtual personas presents both transformative possibilities and ethical\nchallenges. Positively, it could significantly impact market research, psychological studies, and the\nsimulation of social behaviors, providing cost-effective and rapid data collection while minimizing\nrisks to real individuals. Conversely, there exists a potential for misuse, such as influencing public\nopinion or perpetuating biases through skewed data representations. Such risks highlight the im-\nperative for stringent ethical oversight and regulation in deploying these technologies to safeguard\nagainst misuse."}, {"title": "Conclusion", "content": "In this paper, we have proposed and tested a method, Anthology, for the generation of diverse\nand specific backstories. We have demonstrated that this method closely aligns with real-world\ndemographics and demonstrates substantial potential in emulating human-like responses for social\nscience applications. While promising, the method also highlights critical limitations and ethical\nconcerns that must be addressed. Future advancements must focus on enhancing the representation\nand consistency of virtual personas to ensure their beneficial integration into societal studies."}, {"title": "Additional Experimental Results", "content": "In this section, we conduct the ATP W34 survey with various models, including fine-tuned models\nlike Llama-3-70B-Instruct, Mixtral-8x22B-v0.1, GPT-3.5-0125, and a smaller model, Llama-3-7B.\nNotably, none of the fine-tuned models show better metrics in both Representativeness and Consistency\ncriteria, which are defined in Section 3. Despite these models achieving better results on several\nbenchmarks Gao et al. (2023); Hendrycks et al. (2021); Chiang et al. (2024), they do not adequately\napproximate human responses for this survey. Additionally, the other interesting observation is that\nthe best-performing model in terms of approximation to human responses is Llama-3-8B, which\nis the smallest model among those evaluated. We hypothesize that fine-tuning LLMs including\ninstruction fine-tune, RLHF, DPO Rafailov et al. (2023); Ouyang et al. (2022); Chung et al. (2022)\nmakes them converge to a singular persona Park et al. (2023b); Anwar et al. (2024); Bommasani et al.\n(2022a), which makes LLMs unsuitable for the tasks that requires diverse responses. And this makes\nthe larger fine-tuned models less capable on approximating the diverse humans' responses.\nWe hypothesize that fine-tuning LLMs through methods such as instruction fine-tuning, RLHF,\nand DPO Rafailov et al. (2023); Ouyang et al. (2022); Chung et al. (2022) leads them to converge\ntowards a singular persona Park et al. (2023b); Anwar et al. (2024); Bommasani et al. (2022a). This con-\nvergence potentially renders LLMs less suitable for tasks requiring diverse responses, consequently\nmaking larger fine-tuned models less effective at approximating the varied responses of humans.\nThis finding aligns with the insights from Santurkar et al. (2023) discussing that the base models\nare more steerable than fine-tuned models, and suggests the need for careful model selection for this\nspecific task Liang et al. (2023)\nWe observe that the Llama-3-8B model exhibits a higher Cronbach's alpha value. This increased\nconsistency is attributed to the model's tendency to select responses same as previously generated\nresponses Zheng et al. (2023); Pezeshkpour and Hruschka (2023); Zheng et al. (2024), resulting in\nmore correlated responses over survey questions. Consequently, this leads to a higher Cronbach's\nalpha compared to the results shown in Table 1, even though the average Wasserstein distance is\nsignificantly higher."}, {"title": "LLM-Generated Backstories", "content": "In this section, we discuss additional details about the process of generating realistic backstories\nusing language models, as mentioned in Section 2. We detail the prompts used and examples of\nLLM-generated backstories.\nThen, we discuss the alternative method of generating backstories given a particular combination\nof demographic traits, referred in Section 3 as the \u201cDemographics-Primed\u201d method in contrast to\nthe \u201cNatural\u201d backstories generated without conditioning on demographics."}, {"title": "Natural Generation of Backstories", "content": "We use OpenAI's davinci-002 for generating backstories with the prompt specified in the top of\nFigure 6. This model is chosen as it is base model (i.e. not instruction-tuned) of the largest model\ncapacity at the time of the project. Figure 6 shows two examples of backstories of different lengths\ngenerated with this prompt."}, {"title": "Generating Demographics-Primed Backstories", "content": "Target demographics-primed backstories are generated by prompting a language model with de-\nmographic information of a human from a target population. In contrast to naturally generated\nbackstories whose demographic trait cannot be predetermined but can only can be sampled by\nthe demographic survey method outlined in E, demographic traits of target demographics-primed\nbackstories are determined at the time of generation. We use five demographic variables (age, annual\nhousehold income, education level, race or ethnicity, gender) for ATP Wave 34, 99 and an additional\nvariable (political affiliation) for ATP Wave 92.\nA generation prompt example for ATP Wave 34 is presented in Figure 7. Answers for each\nquestion are taken from the demographic information of a human respondent in the ATP survey\ndata. To accurately incorporate the target population's demographic information, we use the same\nlist of choices as used in the actual survey. Orders of demographic variables are randomized every\ngeneration to minimize the effect of question ordering. We use two styles of prompt, which we refer\nto a Question-Answer and a Biography as presented in Figure 7.\nTo take a full advantage of the demographics-primed backstory generation, backstories should\nsufficiently reflect the given demographic information. Due to pre-trained base models' limited in-"}, {"title": "Details on Experiments", "content": "In this section we provide examples of prompts used in the experiments approximating human\nstudies, as described in Section 3 and used to produce the results in Section 4. Additionally, we\noutline the survey procedure for conducting these experiments, providing a comprehensive review\nof methodologies and operational frameworks involved."}, {"title": "Prompts for Baseline: QA", "content": "We construct a series of multiple choice demographic survey question-answer pairs given the de-\nmographic traits. The five demographic traits we use are taken from the human respondent data\nof ATP surveys. The order of five questions is randomized every time to minize the effect of question\nordering."}, {"title": "Prompts for Baseline: Bio", "content": "As in Santurkar et al. (2023), we construct free-text biographies in a rule-based manner given the\ndemographic trait. The five demographic traits we use are taken from the human respondent data\nof ATP surveys. The order of five sentences each describing demographic traits is randomized every\ntime to minimize the effect of sentence ordering."}, {"title": "Target Demographics-Primed Backstory", "content": "The details of target demographics-primed backstory used in the survey experiment are presented in\nFigure 9. The demographic traits used to generate the backstory and append are taken from human\nrespondents data of ATP surveys."}, {"title": "Natural Backstory", "content": "The details of natural backstory used in the survey experiment are presented in Figure 10. The\ndemographic traits appended to the backstory are traits of matched human respondents with either\ngreedy or maximum weight sum matching."}, {"title": "Survey Procedure", "content": "In this study, we try our best to mimic the same survey procedure as human surveys. Human survey\ntypically shuffle or reverse the order of the multiple choice options or change the order of questions\nfor each survey participant to reduce the bias in the results. Typically, human surveys employ\ntechniques like shuffling or reversing the order of multiple-choice options or altering the sequence\nof questions for each participant to minimize bias in the results. Following the topline reports for"}, {"title": "Details on Human Studies", "content": "American Trends Panel (ATP) is a nationally representative panel of U.S. adults conducted by the\nPew Research Center. ATP is designed to study a wide variety of topics, including politics, religion,\ninternet usage, online dating, and more. We analyze sampled questions from three waves, where\nquestions are drawn from ASK ALL questions (i.e. asked to all human respondents, instead of\nquestions asked for selective demographic groups or conditionally asked based on the response to\nthe previous question) in order to investigate the response of overall population.\nIt is worth noting that in the original ATP surveys, some questions have answer choices in a Likert\nscale with the order of choices (e.g. positive-to-negative or negative-to-positive) randomized for\neach respondent. For such questions, we also randomize the order of these options when presenting\nthem in prompts to LLMs. Here we present the list of sampled questions from each wave."}, {"title": "ATP Wave 34", "content": "American Trends Panel Wave 34 is conducted from April 23, 2018 to May 6, 2018 with a focus on\nbiomedical and food issues. The number of total respondents is 2,537."}, {"title": "ATP Wave 92", "content": "American Trends Panel Wave 92 is conducted from July 8, 2021 to July 21, 2021 with a focus on political\ntypology. We randomly sampled 2,500 respondents for the study from the total 10,221 respondents."}, {"title": "ATP Wave 99", "content": "American Trends Panel Wave 99 is conducted from November 1, 2021 to November 7, 2021 with a\nfocus on artificial intelligence and human enhancement. We randomly sampled 2,500 respondents\nfor the study from the total 10,260 respondents."}, {"title": "Demographic Survey on Virtual Subjects", "content": "The goal of demographic survey is to obtain the demographic information encoded in backstories.\nFive demographic variables (age, annual household income, education level, race or ethnicity, and\ngender) and a party affiliation question are asked to backstories as they are utilized in the downstream\ntarget population matching. We take two approaches to obtain the probable demographics of authors.\nIn the first approach, we use GPT-40 OpenAI (2024) to locate demographic information from\nthe backstory. To minimize hallucination, we prompt GPT-40 to retrieve the demographic trait only\nif the backstory explicitly mentions related context (prompts are shown in E.1). This approach is\nlimited to specific demographic variables, especially age, annual household income, and education\nlevel questions, since we avoid inferring race / ethnicity, gender, and party affiliation even in the\ncase when backstory mentions those traits. Decoding hyperparameters are set to top_p = 1.0, T = 0."}]}