{"title": "METAFOR: A Hybrid Metaheuristics Software Framework for Single-Objective Continuous Optimization Problems", "authors": ["CHRISTIAN CAMACHO-VILLAL\u00d3N", "MARCO DORIGO", "THOMAS ST\u00dcTZLE"], "abstract": "Hybrid metaheuristics are powerful techniques for solving difficult optimization problems that exploit the strengths of different approaches in a single implementation. For algorithm designers, however, creating hybrid metaheuristic implementations has become increasingly challenging due to the vast number of design options available in the literature and the fact that they often rely on their knowledge and intuition to come up with new algorithm designs. In this paper, we propose a modular metaheuristic software framework, called METAFOR, that can be coupled with an automatic algorithm configuration tool to automatically design hybrid metaheuristics. METAFOR is specifically designed to hybridize Particle Swarm Optimization, Differential Evolution and Covariance Matrix Adaptation-Evolution Strategy, and includes a local search module that allows their execution to be interleaved with a subordinate local search. We use the configuration tool irace to automatically generate 17 different metaheuristic implementations and evaluate their performance on a diverse set of continuous optimization problems. Our results show that, across all the considered problem classes, automatically generated hybrid implementations are able to outperform configured single-approach implementations, while these latter offer advantages on specific classes of functions. We provide useful insights on the type of hybridization that works best for specific problem classes, the algorithm components that contribute to the performance of the algorithms, and the advantages and disadvantages of two well-known instance separation strategies, creating stratified training set using a fix percentage and leave-one-class-out cross-validation.", "sections": [{"title": "1 INTRODUCTION", "content": "Continuous optimization problems are ubiquitous in many areas of science and technology, including engineering, finance, education, e-commerce and healthcare, to name a few. In a d-dimensional continuous optimization problem,"}, {"title": "2 CONTINUOUS OPTIMIZATION PROBLEMS, METAHEURISTICS, AND AUTOMATIC DESIGN", "content": "Without loss of generality, in a continuous optimization problem, the goal is to minimize a d-dimensional continuous objective function f : S \u2286 Rd \u2192 R by finding a vector \u1ecf in the search space S, such that \u2200 x \u2208 S, f(\u1ecf) \u2264 f(x). The search space S is a subset of Rd in which a solution is represented by a real-valued vector \u3121, and each component xj of x is constrained by a lower and upper bound: lbj \u2264 xj \u2264 ubj, for j = 1, . . ., d. Although there are many different approaches that can be used to deal with continuous optimization problems [24], in our work we focused on PSO, CMA-ES, DE and LS algorithms, which are among the best performing ones reported in the literature [60, 90]. The main characteristic of PSO, CMA-ES and DE is that they are population-based metaheuristics, that is, at each iteration, they keep a population of solutions and perform a parallel exploration-exploitation of the search space. Differently, local search algorithms, such as multiple trajectory search local search [97], make small changes to a single solution based on a step-size parameter that determines how far a new candidate solution will be created. Since population-based metaheuristics and local search have complementary characteristics, they are often combined to create algorithms that are better equipped to solve difficult optimization problems [31, 62, 71, 72]."}, {"title": "2.1 Population-based metaheuristics", "content": null}, {"title": "2.1.1 Particle Swarm Optimization", "content": "In particle swarm optimization (PSO) [26, 53], particles try to discover the region of the search space where the best quality solutions are located by moving in directions that are estimated based on the best locations that they and their neighboring particles have visited in the past. The standard version of PSO (StaPSO) [89] uses a computational model composed of three main elements: (i) a cognitive component that allows each particle i in the swarm to memorize the best position it has visited so far, called personal best position p\u00b9; (ii) a social component that allows a particle to know the best position i ever found by any of the particles in its neighborhood; and (iii) a velocity update rule and a position update rule that specify how the particles move in the search space and that are defined respectively as follows:\n\n+1 = w\u1ed5 + \u03c61U\u2081t(pi \u2013 x) + \u03c62U+ ( \u2212 \u3121) for i = 1,..., n, (1)\n+1 =++1(2)\n\nwhere n is the number of particles.\nThe position of the particles (vectors x), which represent candidate solutions to the optimization problem, are updated in every iteration t of the algorithm by computing a new velocity vector (Equation 1) that is added to their current positions (Equation 2). The computation of a particle's new velocity makes use of two random diagonal matrices, Uit"}, {"title": "2.1.2 Covariance Matrix Adaptation-Evolution Strategy", "content": "The evolution strategy (ES) with covariance matrix adaptation (CMA-ES) [36, 41] is a ES in which the complete covariance matrix of the normal mutation distribution is adapted at execution time. The main idea in ESs is to simulate the process by which a population of \u03bc parents (solutions) undergoes recombination and mutation to generate A offspring (new solutions). Then, a selection operator is applied to choose a subset of these solutions to form the population for the next iteration. CMA-ES is similar to the Quasi-Newton method [75] in the sense that it is a second-order estimator that iteratively estimates a positive definite matrix, specifically the covariance matrix. However, unlike the Quasi-Newton method, CMA-ES does not use approximate gradients, nor does it assume their existence. The standard CMA-ES implementation [37, 38] is composed of three main steps.\nThe first step, random sampling, consist in sampling a population of a solutions from a multivariate normal distribution N with mean m \u2208 Rd and covariance C \u2208 Rd\u00d7d, as shown in the following equation:\n\ni\nX\n+1 = mt + ot \u00d7 N(0, C\u2081) for i = 1, . . ., \u03bb, (3)\n\nwhere x+1 is a vector representing the i-th individual in the population, and \u03c3\u03c4 > 0 is the standard deviation that controls the sampling radius or step-size.\nIn the second step, weighted intermediate recombination, the A individuals are ranked in ascending order and the \u00b5 best ones are selected to update the mean of the sampling distribution. The equation describing this process is the following:\n\n=mt+1 =\u03a3wiz(i)\nXt+1,\ni=1\n(i)\u03bb -1 ((\u03bb)\nwhere w\u00b9 > w\u00b2 \u2265 ... w\u00a3 > 0, \u03a3=1 wi 1, and x+1denotes the i-th ranked individual of the solutions sampledusing Equation 3. The weights w\u00b2 are decreased logarithmically using:\n\nw\u00b2 = log+1-log(i) for i = 1 1, ..., \u03bc. (5)\n\nThe last step is the covariance matrix adaptation. The process of adapting the covariance matrix for the next iteration uses a combination of rank-one update (i.e., the mean of the estimated covariance matrices using a single selected step, namely the \"evolution path\") and the rank-u update (i.e., the mean of the estimated covariance matrices from all previous iterations). The update of the covariance matrix is done as follows:\n\nCt+1 = (1-Ccov) Ct +\nCcov\n\u03bc\u03bf\u03bdPt+1 Pt+1T+\nCcov\n\u03bc\n\u03a3i=1\nwyt(i)yt+1\nT(6)\nrank-one update rank-u update\n\nwhere Ccov \u2208 [0,1] is the learning rate for the covariance matrix update, \u00b5cov is used to determine the weighting between the rank-one and rank-u update, p\u2081 is the evolution path (i.e., the search path the algorithm takes over a number of iterations and it is expressed as a sum of consecutive steps of m), and yt+1 (x+1)-mt)/\u03c3\u03c4. For a detailed explanation of how to compute the evolution path P1 and the new step-size ot+1, we refer the reader to [38, 39]."}, {"title": "2.1.3 Differential Evolution", "content": "Differential Evolution (DE) [82, 93] is another evolutionary approach, though it is often regarded as distinct because it incorporates concepts that are similar to those found in SI methods. DE implements a mutation operator, called differential mutation, that is similar to the moves in the Nelder-Mead simplex search method [74]. The differential mutation operator consists of selecting three solutions from the population, computing the difference of the first two solutions and multiplying it by a scaling factor, and then adding the scaled vector difference to the third solution. More formally, in DE, the mutation operator is defined as follows:\n\nm\u00b2 = x\u00b2 + \u03b2 \u00b7 (x \u2013 ),(7)\n\nwhere i = 1,...,n denotes the ith individual in a population of n solutions, \u03b2 is the scaling factor and vectors xa \u2260\u2260 \u02c7 are the three solutions randomly chosen from the population. Vector \u3121, which is referred to as base vector and can be selected in many ways, has to be different from the solution in the population for which it is targeted, that is, vector x, which is referred to as target vector. The result of applying Equation 7 is a vector called mutant vector, indicated as m\u00b2.\nThe creation of the mutant vector is followed by recombination, in which the mutant vector (m\u00b2) is recombined with target vector (\u3121) to create a trial vector \u1eed\u00b9. The equation to apply recombination and obtain the trial vector is the following:\n\nui,k =misk, if (U[0, 1] \u2265 pa) V (k = kiand)Vk, Vi,(8)xi,k otherwise\n\nwhere k = 1,..., d allows to iterate between the values of the vectors, U[0, 1] is a random number sampled from a uniform distribution, d is the number of dimensions of continuous optimization problem, pa is a real parameter in the range [0, 1] that controls the fraction of values copied from the mutant vector into the trial vector, and ki Krand is a randomly chosen dimension that ensures that the trial vector is not a duplicate of the target vector. The newly generated trial vector u only replaces the target vector x in the population if it has better quality, otherwise is discarded. Also, as indicated in Equation 8, the mutation and recombination operators are iteratively applied for every solution in the population."}, {"title": "2.2 Local search strategies for continuous optimization problems", "content": "Among the best-known local search algorithms proposed to tackle continuous optimization problems are the Nelder-Mead Simplex algorithm [74], the Powell's conjugate directions set algorithm [79], and the BOBYQA algorithm [81] (also by Powell). In this paper, we consider the more recent multiple trajectory search local search (MTSIs) algorithm [97]. The choice of MTSIs was motivated by the excellent results obtained by various hybrid algorithms for continuous optimization that integrate this local search [56, 62].\nThe MTSIs algorithm starts by generating a candidate solution 3 = (S1, S2, ..., $d) uniformly at random inside the search range. The initial step size ss is set to ss = 0.5 \u00d7 (ubj \u2013 lbj), where 0.5 is a default value [97] and ub and lb are, respectively, the upper and lower bounds of dimension j. MTSls visits the dimensions of the problem in a fixed order, searching one dimension at a time. For j = 1 . . . d, MTSls proceeds as follows. First, the value s; is modified as s; = sj\u2212ss and the resulting solution s' is evaluated. If f (s') < f(s), then sj = s; and the search continues in dimension j+1; otherwise, s';' = sj+0.5\u00d7ss and the candidate solution s\u201d is evaluated. If f (s\") < f(s), then sj = s'' and the search continues in dimension j + 1. However, if both s; and s; do not improve over sj, then sj remains unchanged and the same process is applied to dimension j + 1. If no improvement is found in any of the dimensions during one iteration\""}, {"title": "2.3 Automatic design of metaheuristic implementations", "content": "Automatic design [17] has been proposed as an alternative to manual design, with the goal of reducing the burden on algorithm designers who have to deal with the problem of creating metaheuristic implementations that meet certain performance requirements. In automatic design [17, 94], generating effective algorithm designs is treated as an optimization problem, focused on discovering high-performing combinations of algorithm components and parameter settings. By using an automatic design approach, algorithm designers do not have to deal themselves with the tasks of composing many different metaheuristic designs, assessing their performance and selecting the best ones, since these tasks are delegated to an automatic algorithm configuration tool (AACT). The AACT can systematically explore the design space of a metaheuristic until it finds one that meets the user's needs or until a maximum computational budget is exhausted.\nThe AACT used in this paper is irace [64, 65], which implements an iterated racing approach. The iterated racing approach [8, 69] is based on the idea of performing sequential statistical testing in order to create a sampling model that can be refined by iteratively \"racing\" candidate configurations and discarding those that perform poorly. The way in which irace works can be summarized as follows. First, it samples candidate configurations from the parameter space and evaluates these configurations on a set of instances using a racing procedure, where each configuration is tested on one instance at a time. Then, irace eliminates the statistically inferior configurations based on Friedman's non-parametric two-way analysis of variance by ranks. Throughout the configuration process, which proceeds sequentially within a given computational budget, irace adjusts the sampling distribution to favor the best configurations identified so far. This process is repeated iteratively until a computational budget is exhausted and irace returns the configuration that performed best on the training instances."}, {"title": "3 PREVIOUS WORKS ON HYBRIDIZATION AND AUTOMATIC DESIGN", "content": "The goal of creating hybrid metaheuristics is to exploit the strengths that different optimization techniques can offer to solve optimization problems [9, 13, 34, 94, 96]. In the following, we discuss the main ideas proposed in hybrids of PSO, CMA-ES and DE, as well as some modular metaheuristic software frameworks that have been proposed to study these metaheuristics and their hybrids in an automatic design context. Note, however, that this review of the literature is by no means exhaustive, as we focus on papers proposing ideas that are particularly amenable to be implemented in METAFOR, such as single-objective hybrids and not overly complicated hybrids."}, {"title": "3.1 PSO and DE hybrids", "content": "Hendtlass proposed an algorithm called swarm differential evolution algorithm (SDEA) [43]. SDEA works mainly as the standard PSO algorithm, but intermittently applies the DE mutation operator to the particles' current solutions to avoid local minima. Zhang and Xie proposed an algorithm called DEPSO, in which the standard PSO is applied during even iterations of the algorithm, and the DE mutation operator is applied to the particles' personal best during odd iterations [101]. Das et al. proposed a hybrid algorithm in which the personal component of the velocity update rule of the standard PSO is modified based on the mutation operator of DE [20]. In [76], Omran et al. introduced a modified version of Hendtlass' SDEA that uses a probabilistic approach based on the \"barebones\" PSO. In their algorithm, with probability pr, particles update their position using the barebones PSO position update rule and add a vector difference,"}, {"title": "3.2 PSO and CMA-ES hybrids", "content": "One of the earliest PSO-ESs hybrids is the \"particle swarm guided evolution strategy\" proposed by Hsieh et al. [47]. Although this approach is not properly based on CMA-ES, the authors introduced the idea that ESs can be used to focus on exploiting good quality solutions, while PSO can be used to focus on performing effective search space exploration. M\u00fcller et al. proposed to run multiple CMA-ES instances in parallel considering each instance as an individual particle in PSO [72]. The proposed algorithm is divided into two phases: a CMA-ES phase, which follows the usual CMA-ES algorithm, and a PSO phase, where the best solutions found by each CMA-ES instance applies the standard PSO velocity and position update rules. The equation to adapt the covariance matrix of CMA-ES was modified to combine the local information gathered by a CMA-ES with the global information of PSO. M\u00fcller et al. also added a bias to the mean of the sampling distribution of CMA-ES in the following cases: (i) when the instance has already converged to a local minimum located far from the the global best solution, and (ii) when the instance is different from the one that produced the global best solution and the step-size has fallen below a certain threshold. In [99], Peilan et al. introduced a hybrid, three-phase algorithm that uses multiple populations and two different versions of PSO, the standard PSO and a PSO with time windows (PSOtw). In PSOtw, particles can only access their personal best if it is within a certain time window tw given in number of iterations. The first phase of Peilan et al.'s algorithm consists in applying PSOtw by each population for a number of iterations; in the second phase, the best and second best solutions in each population are selected to create a temporary population Pt; in the third phase and last, the standard PSO and CMA-ES algorithms are applied one after the other to Pt for a number of function evaluations and the best solutions in Pt are selected for the next iteration."}, {"title": "3.3 CMA-ES and DE hybrids", "content": "K\u00e4mpf and Robinson proposed to execute CMA-ES and DE in sequential order, with CMA-ES followed by DE [50]. The elite solutions found by CMA-ES are input to DE, but since DE uses a larger population size compared to CMA-ES, the DE population is completed with randomly created solutions. Ghosh et al. introduced a hybrid algorithm that incorporates the operators of DE into the structure of CMA-ES [31]. The standard mechanism of CMA-ES is used in each iteration to sample new solutions from a multivariate normal distributions, after which the population is handled as in DE. At each iteration, Ghosh et al' algorithm performs the following steps: (i) update the mean of the sampling distribution; (ii) adapt the covariance matrix; (iii) create a population of mutants using components from the eigen decomposition of the covariance matrix; and (iv) apply the crossover and selection operators of the usual DE algorithm. In [35], Guo and Yang proposed a crossover operator that allows individuals to exchange information between the target vector and the mutant vector using the eigenvector basis instead of the natural basis, thus rotating the coordinate system and making the algorithm rotation invariant. In [42], He and Zhou presented a hybrid algorithm based on a new mutation operator and a simplified step-size control rule. The mutation operator used the information of previously rejected solutions and a Gaussian distribution to sample probabilistically \"better\" solutions. The standard"}, {"title": "3.4 Modular metaheuristic software frameworks for PSO, CMA-ES and DE", "content": "Metaheuristic software frameworks (MSFs) that can be used to automatically generate implementations of PSO, CMA-ES and DE have already been proposed in the literature: PSO-X [15], autoCMAES [22], autoDE [98] and modP-SODE [10]. Both PSO-X, autoCMAES and autoDE are parameterized MSFs that allow users to create many different implementations by simply changing the parameters used to execute the framework. This aspect makes them particularly suitable for an automatic design context, as they can be easily coupled with an AACT tool such as irace. On the other hand, the main drawback of these MSFs is that they only contain components of a specific metaheuristic, PSO, CMA-ES and DE, respectively.\nThe modular modPSODE framework is, to the best of our knowledge, the only MSF specifically developed for creating PSO and DE hybrids in an automatic design context [10]. Unfortunately, it has two important downsides: (i) a limited number of components of PSO and DE compared to PSO-X and autoDE; and (ii) lack of flexibility to combine components at a fine-grained level. The modPSODE framework is based on the idea of simultaneously generating two populations, one using PSO components and the other using DE components, and combining them into a single population that is then reduced to a predefined population size using a selection operator. This type of hybridization is not particularly useful to explore the interaction of PSO components in DE and vice-versa."}, {"title": "4 THE METAFOR SOFTWARE FRAMEWORK", "content": "METAFOR is composed of three main modules: a PSO module (PSOmod), which includes algorithm components of PSO to update solutions by adding a velocity vector; a DE module (DEmod), which includes algorithm components of DE to update solutions using differential mutation, recombination and selection; and a CMA-ES module (CMA-ESmod), which includes algorithm components of CMA-ES to update solutions by applying random sampling, recombination and covariance matrix adaptation. METAFOR also includes a local search module (LSmod), which allows the execution of PSOmod, DEmod and CMA-ESmod to be interleaved with a local search (MTSIs or CMA-ES) for a number of function evaluations (FEs) and then resume with the main algorithm execution.\nPSOmod, DEmod and CMA-ESmod can be used standalone or in combination with other modules by selecting specific components from them. As an example, with METAFOR it is possible to create a hybrid DE-PSO implementation that combines the differential mutation of DE with the velocity update rule of PSO, and runs CMA-ES as local search for a number of FEs. The way in which PSOmod, DEmod and CMA-ESmod interact with each other is controlled by the algorithm component Execution. Execution operates at a high level in METAFOR and contains the necessary options for creating different types of hybrid implementations (e.g., component-based, multiple phases, etc.). We will now provide a detailed description of the modules that comprise METAFOR. We use a sans-serif font to indicate both the algorithm components implemented in the framework and their available options."}, {"title": "4.1 PSOmod", "content": "PSOmod includes all the algorithm components and implementation options as the original PSO-X framework [15].1 The two top-level algorithm components of PSOmod are Population and Topology. Population handles the number of solutions (particles) in the implementation and has three options available: Pop-constant, Pop-incremental and Pop-time-varying. When Pop-incremental or Pop-time-varying are used, the user has to specify the way new solutions added to the population are initialized, which is done via the algorithm component Initialization using option Init-horizontal or Init-random. The Topology algorithm component determines the way particles connect to each other and it can be implemented in seven different ways: Top-fully-connected, Top-hierarchical, Top-Von Neumann, Top-ring, Top-random edge, Top-time-varying and Top-wheel; each option providing different connectivity and information transfer speed to the swarm.\nIn PSOmod, the components involved in the computation of a particle's new velocity vector (41) are combined using a generalized velocity update rule, which is defined as follows:\n\n+1 = 1 + 02 DNPP(i, t) + w3 Pertrand (i, t),(9)\n\nwhere w\u2081, w2 and w3 are three real parameters in the range [0, 1] used to control the influence of each term in the equation, i is the velocity of the particle i at iteration t, DNPP is an algorithm component that determines the type of mapping from a particle's current position to the next one, and Pertrand is an optional algorithm component to add a perturbation vector. PSOmod provides nine options for computing the value of w\u2081, most commonly known as the inertia weight (IW). Three of these options update their value at regular intervals of the algorithm execution based on predefined schedules (IW-linear decreasing, IW-linear increasing and IW-random), whereas the other six options update their value adaptively, based on information gathered from the option process (IW-self-regulating, IW-adaptive based on velocity, IW-double exponential self-adaptive, IW-rank-based, IW-success-based and IW-convergence-based). The parameters w2 and w3, which regulate the influence of DNPP and Pertrand, respectively, can either be set equal to w\u2081 or determined using the IW-random and IW-constant options.\nThe options for implementing the DNPP algorithm component are DNPP-rectangular, DNPP-spherical, DNPP-standard, DNPP-discrete, DNPP-Gaussian and DNPP-Cauchy-Gaussian. The DNPP-rectangular option is the most commonly used in PSO variants, including the standard PSO [54], the fully-informed PSO [70] and the locally convergent rotationally invariant PSO [12], and it was used as the basis for the DNPP-spherical option, proposed for the standard PSO-2011 [19, 100]. In the case of DNPP-standard, DNPP-discrete, DNPP-Gaussian and DNPP-Cauchy-Gaussian, they were proposed for the so-called simple dynamic PSO algorithms, whose main characteristic is that they do not use the previous velocity vector or the random diagonal matrices. The algorithm component Vector-Basis, which is not part of the original PSO-X framework, works in combination with DNPP. Vector-Basis uses the eigenvector information of the population covariance matrix to rotate the coordinate system, with the goal of making the implementation invariant to rotated search spaces. Vector-Basis can be implemented using the option VB-natural, where no changes are made to the coordinate system, or the option VB-eigenvector, where the vectors involved in the computation of the DNPP are rotated in the direction of the eigenvector basis.\nWhen DNPP is implemented as DNPP-rectangular or DNPP-spherical, the user has to indicate the options for the Random Matrices (Mtx), Model of influence (Mol) and Acceleration Coefficients (AC) components. Mtx refers to the different ways in which the random matrices can be constructed, such as Mtx-random diagonal, Mtx-random linear,"}, {"title": "4.2 CMA-ESmod", "content": "CMA-ESmod was developed based on the implementation of CMA-ES publicly available from its creator's website.2 CMA-ESmod allows to implement the algorithm components proposed in some of the best-known variants of CMA-ES, including the standard-CMA-ES with intermediate recombination [40], the separable-CMA-ES [86] and the restart-CMA-ES with increasing population size [4]. CMA-ESmod is composed of four main algorithm components: CMAES-population, which handles the number of solutions in the implementation; CMAES-Mtx, which specifies the way the covariance matrix is adapted; CMAES-restart, which restarts the algorithm based on criteria related to the range of improvement of the solutions found by the population; and CMAES-recombination-weights, which specifies the weighing mechanism used by recombination.\nIn CMA-ESmod, the size of the population is controlled using the CMAES-population algorithm component. The two options available for implementing this component are CMAES-pop-constant, where the size of the population remains the same throughout the algorithm execution, and CMAES-pop-incremental, where it increases according to a multiplication factor. The initial population size (denoted by t=0) and the number of parents selected for recombination (denoted by \u00b5t) are computed using t=0 = 4 + [cmaes_par_aln(d)\u300d and \u00b5\u2081 = \u03bb\u2081/cmaes_par_b, where cmaes_par_a"}, {"title": "4.3 DEmod", "content": "DEmod was developed considering some of the most popular variants of DE published in the literature [21, 98]. DE implementations are typically referred to using a mnemonic of the form DE/term_2/term_3/term_4, where term_2 indicates the way in which the base vector is chosen, term_3 indicates the number of vector differences added to the base vector, and term_4 indicates the number of values donated by the mutant vector (see Section 2.1.3 for details). Some popular variants of DE indicated using their mnemonics are DE/rand/1/bin (classic DE), DE/target-to-best/1/bin, and DE/rand/1/exp. The implementations created with DEmod can be referred to in a similar way using the following extended mnemonic:\nDE/DE-Base Vector/DE-vector-differences/DE-Recombination/DE-Vectors/Vector-Basis (11)\n\nwhere DE-Base Vector, DE-vector-differences and DE-Recombination refer to the same concepts as term_2, term_3 and term_4 in the original mnemonic, DE-Vectors indicates the solution vectors used to compute the vector differences, and Vector-Basis indicates the vector basis used in the implementation. In DEmod, the population is handled using the algorithm component Population (already described in Section 4.1) with the exact same options available (i.e., Pop-constant, Pop-incremental and Pop-time-varying).\nThe algorithm component DE-Base Vector determines the way the base vector (vector x in Equation 7) is chosen. DE-Base Vector provides five options for its implementation: BV-random, BV-best, BV-target-to-best, BV-directed-random and BV-directed-best. The first three options are the most commonly used in popular DE variants. In BV-random the base vector is chosen at random; in BV-best the base vector is the best-so-far solution; and in BV-target-to-best the base vector lies between the target vector and the best-so-far solution. The implementation options BV-directed-random and BV-directed-best seek to incorporate information from the objective function into the creation of the mutant vector. When options BV-directed-random and BV-directed-best are used, the creation of the mutant vector is done as follows:\n\nm\u00b2 = x\u00b2 +(--),(12)\n\nwhere, and are chosen at random, with f(x) \u2264 {f(b), f(x)}. The only difference between BV-directed-best and BV-directed-random is that, in BV-directed-best, a is the best solution found so far. The numerical parameter \u03b2\u03b5 (0, 1] scales the vector differences added to the base vector and is divided by the number of vector differences when there are more than one, as shown in Equation 12.\nThe number of vector differences added to a base vector is computed by the algorithm component DE-vector-differences. Although most implementations of DE only add one or two vector differences, DE-vector-differences allows to add up to a quarter of the population size as vector differences. In practice, DE-vector-differences takes into account the option implemented for DE-Base Vector and assigns to each individual in the population the set of solutions that will be used to create its mutant vector. Also, when options Pop-incremental or Pop-time-varying are used, DE-vector-differences adjusts the number of vector differences according to the current population size.\nThe DE-Recombination component specifies the type of recombination (RCB) used in the implementation. The options available for implementing DE-Recombination are RCB-binomial and RCB-exponential. The option RCB-binomial, a.k.a. uniform random, is the one shown in Equation 8 in Section 2.1.3, where the number of values donated by the mutant vector follows a binomial distribution. Differently, in the RCB-exponential (or two-point modulo), the number of values donated by the mutant vector follows an exponentially distributed random variable. The fraction of values copied from the mutant vector into the trial vector during recombination is controlled by the parameter pa (see Equation 8), whose value is a real number in the range [0, 1].\nIn addition to the typical algorithm components used in DE implementations, DEmod includes components DE-Vectors and Vector-Basis. The algorithm component DE-Vectors allows to use different types of solutions when creating a mutant vector. The options available to implement DE-Vectors are V-positions, which uses the current solutions (most DE implementations used this option); V-pbest, where individuals keep track of their the personal best solutions and use them to compute the mutant vector (an idea borrowed from PSO); and V-mixture, which uses a combination of the current and personal best solutions. On the other hand, the algorithm component Vector-Basis allows to rotate"}, {"title": "4.4 LSmod", "content": "LSmod allows to interleave the execution of PSOmod, DEmod and CMA-ESmod with a subordinate local search. The execution of the local search algorithm is controlled by two parameters, LS-budget and LS-divide. LS-budget, which is a real number in the range (0, 1], indicates what percentage of the total number of FEs is allocated to local search, whereas LS-divide, which is an integer in the range [1, 100], specifies the number of independent runs of the local search in the implementation. For example, setting LS-budget = 0.25 and LS-divide = 10 produces 10 independent runs of the local search, where each run has a maximum budget of (0.25 total number of function evaluations)/10. If the local search algorithm reaches the value of LS-divide without finishing its budget, LSmod adds extra runs, one at a time per iteration, until there is no more budget available.\nThe two local search algorithms that can be implemented using LSmod are CMA-ES and MTSIs. Although the implementation of CMA-ES as local search is also done via CMA-ESmod with the exact same available options and parameters (see Section 4.2), each CMA-ES instance is treated independently in METAFOR. In other words, in a single METAFOR implementation, it is possible to have two instances of CMA-ES, one as (or part of) the main optimization algorithm, and another as local search, each with its own algorithm components and parameter values. Whatever the type of implementation, LSmod uses as input for the local search algorithm the best solution found so far (best), which in the case of CMA-ES is used as mean for the random sampling, and in the case of MTSls as starting solution.\nThe implementation of MTSIs works as described in Section 2.2 and has three parameters associated: MTSLS-init-ss, which is the initial step size, MTSLS-iterations, which is an integer in the range [1, 3] that determines the number of iterations per run of MTSIs, and MTSLS-bias, which is a real number in the range [-1,1] that controls how close a randomly generated solution is to best. In our implementation of MTSIs, solutions that exceed the boundaries of the search space are penalized by adding the sum of the squares of their offsets to the function evaluation. This ensures that the farther a solution is from the search space, the greater the penalty it incurs. At the end of each iteration, MTSIs"}, {"title": "4.5 The Execution algorithm component", "content": "Based on the literature review in Section 3, we developed an algorithm component called Execution that allows to replicate the way in which hybrids of PSO, CMA-ES and DE are created. The three options available to implement Execution are EXE-component-based, EXE-probabilistic and EXE-multiple phases. The EXE-component-based option (available for each module when used standalone and for PSOmod and DEmod when used together) allows users to compose an algorithm by selecting individual algorithm components from different modules.\nDifferently, in the EXE-probabilistic option (available only for PSOmod and DEmod), each module is applied probabilistically based on parameter pr\u2208 [0, 1"}]}