{"title": "Beyond the Eye: A Relational Model for Early Dementia Detection Using Retinal OCTA Images", "authors": ["Shouyue Liu", "Jinkui Hao", "Yonghuai Liu", "Huazhu Fu", "Xinyu Guo", "Shuting Zhang", "Yitian Zhao"], "abstract": "Early detection of dementia, such as Alzheimer's disease (AD) or mild cognitive impairment (MCI), is essential to enable timely intervention and potential treatment. Accurate detection of AD/MCI is challenging due to the high complexity, cost, and often invasive nature of current diagnostic techniques, which limit their suitability for large-scale population screening. Given the shared embryological origins and physiological characteristics of the retina and brain, retinal imaging is emerging as a potentially rapid and cost-effective alternative for the identification of individuals with or at high risk of AD. In this paper, we present a novel PolarNet+ that uses retinal optical coherence tomography angiography (OCTA) to discriminate early-onset AD (EOAD) and MCI subjects from controls. Our method first maps OCTA images from Cartesian coordinates to polar coordinates, allowing approximate sub-region calculation to implement the clinician-friendly early treatment of diabetic retinopathy study (ETDRS) grid analysis. We then introduce a multi-view module to serialize and analyze the images along three dimensions for comprehensive, clinically useful information extraction. Finally, we abstract the sequence embedding into a graph, transforming the detection task into a general graph classification problem. A regional relationship module is applied after the multi-view module to excavate the relationship between the sub-regions. Such regional relationship analyses validate known eye-brain links and reveal new discriminative patterns. The proposed model is trained, tested, and validated on four retinal OCTA datasets, including 1,671 participants with AD, MCI, and healthy controls. Experimental results demonstrate the performance of our model in detecting AD and MCI with an AUC of 88.69% and 88.02%, respectively. Our results provide evidence that retinal OCTA imaging, coupled with artificial intelligence, may serve as a rapid and non-invasive approach for large-scale screening of AD and MCI.", "sections": [{"title": "1. INTRODUCTION", "content": "Alzheimer's Disease (AD) is a progressive and irreversible neurodegenerative condition that is being diagnosed with increasing frequency and contributing substantially to the global disease burden (Gaugler et al., 2021). Mild cognitive impairment (MCI) can be an early stage of memory or cognitive ability loss, and is an intermediate stage between cognitive normalcy and AD, with a high likelihood of regression to AD. Early and accurate diagnosis of AD/MCI is critical to facilitate timely interventions and treatments. Currently, brain imaging, including magnetic resonance imaging (MRI) and positron emission tomography (PET), and neurobiological testing, such as cerebrospinal fluid amyloid, tau, and genetic risk scores, are commonly used in hospitals for the diagnosis of AD and MCI. However, they suffer from such limitations as being time-consuming, invasive, low accuracy, or high cost, which hinders their adoption in mass screening and routine clinical practice(Saykin et al., 2010).\nThe eye and brain share similar tissue origin, and their similarity and association of structural characteristics and functional mechanisms have been previously investigated (Yin et al., 2024; Liu et al., 2016). Recently, significant differences in retinal biomarkers between AD and healthy controls have been reported, suggesting that AD affects the eyes and leads to changes in retinal structures. For example, Wu et al.(Wu et al., 2020a) reported that both AD and MCI patients have a loss of retinal microvascular density in the macular region. Curcio (Curcio, 2018) extracted structural features in optical coherence tomography angiography (OCTA), and showed that cognitively impaired participants have a significant decrease in the thickness of inner fovea compared to healthy controls. Zabel et al. (Zabel et al., 2019) demonstrated that AD is associated with retinal neuronal apoptosis and retinal vascular dysfunction. These studies suggest that retinal microvascular attenuation may serve as a potential biomarker for signs of MCI and AD. Thus, retinal imaging has become a potential tool for detecting AD and MCI, and previous studies (Kim et al., 2022; Cheung et al., 2022) have mainly applied machine learning methods over color fundus photography (CFP) for AD/MCI detection. Kim et al. (Kim et al., 2022) used CFP to train a modified MobileNet model to identify individuals with AD. This work modified the attention mechanism to the weighted attention mechanism and applied the mask-adding process to predict the likelihood of AD. Cheung et al. (Cheung et al., 2022) used thousands of CFP samples to develop a deep-learning model for the detection of AD. These methods rarely follow the clinical region-based analysis routine, which limits their ability to incorporate valuable clinical statistical findings and generate easily interpretable results.\nMost existing work has used the CFP imaging modality for the study of AD or MCI. Although CFP has advantages in terms of accessibility and cost-effectiveness, its native resolution (60-300 \u00b5m in vessel diameter) is insufficient to image the retinal microvascular network in detail, as demonstrated in Fig. 1-(a): this prevents the detection of subtle vascular changes in the early stages of diseases such as MCI. In contrast, Optical Coherence Tomography Angiography (OCTA) is an advanced imaging modality that provides non-invasive and rapid imaging of the retinal microvasculature and choroidal capillaries with high resolution (5-6 \u00b5m in diameter) across multiple layers, including the superficial vascular complex (SVC), deep vascular complex (DVC) and choriocapillaris (CC). Their maximum projection of OCTA flow signals, a.k.a. en face images (Fig. 1-(b)), which enhanced depth-resolved microvascular imaging facilitates the detection of subtle vascular changes, is critical for accurate screening and early diagnosis of many eye-related diseases, such as diabetic retinopathy (Sampson et al., 2022).\nIn clinical practice, ophthalmologists often use regional analysis tools to study retinal biomarkers on retinal images. The most commonly used is the Early Treatment of Diabetic Retinopathy Study grid (ETDRS), as shown in Fig. 1-(c). The ETDRS grid is a standardized grid that divides the retina into nine regions with three concentric circles and two orthogonal lines: a central foveal ring of 1 mm diameter, an inner macular ring, and an outer macular ring. The ETDRS grid provides a systematic and consistent assessment of the macular region, allowing a more specific evaluation of retinal changes in a standardized manner, which can provide a more nuanced understanding of the disease(R\u00f6hlig et al., 2019; Demirkaya et al., 2013; Xu et al., 2018). As illustrated in Fig. 1-(c), it can be found that both the ETDRS grid and the en face images of the retina have circular characteristics that follow the nature of biology. Large vessels in SVC grow around a circle and gradually disappear near the center of the circle, forming a capillary-free foveal avascular zone (FAZ)(Conrath et al., 2005). Thus, in our previous work (Xie et al., 2023), we used the ETDRS grid to investigate the association of structural features with AD and MCI, and the results have shown significant reductions in vessel area density and vessel length density in specific regions of the inner vascular complexes in AD and MCI participants.\nInspired by the above observations and findings, we propose a novel end-to-end framework in this work, namely PolarNet+, to take full advantage of clinical region-based analysis for EOAD and MCI detection using OCTA images. We aim to integrate the region-based feature extraction procedure, which is consistent with the ETDRS grid, into a deep learning-based classification model. To obtain a more accurate and interpretable result, it is worth noting that we specifically designed an approximate sector convolution, and the polar transformation was then applied to the regions of the ETDRS grid in order to take advantage of spatial constraints and improve the feature extraction and classification performances.\nThe proposed PolarNet+ significantly extends our work published in MICCAI-2023(Liu et al., 2023), which was only verified on a single dataset containing 114 subjects. In this work, we expand the data pool from 114 to 1671 participants and make significant technical improvements: as a result, the new approach can also discriminate MCI subjects from healthy controls using retinal OCTA images, while achieving more accurate detection results. Overall, the major differences with the previous work and the main contributions of this work can be summarised as follows:\n\u2022 We consider our work to be the first attempt in this research area for the detection of EOAD and MCI using retinal OCTA images. In addition to providing classification results, our model also provides a regional importance map and a regional relationship graph, highlighting discriminative patterns that drive decision-making, and revealing connections between retinal regions that are informative of neurological disease, respectively.\n\u2022 We develop a 3-dimensional-serialization technique that models different retinal regions as sequences, allowing accurate extraction of image features. This approach captures spatial patterns that were previously overlooked by the CNN model, resulting in improved representational capabilities.\n\u2022 We introduce a rewiring-based graph reasoning module to fully exploit and understand the relationships across diverse retinal and choroidal layers, leveraging the unique characteristics of OCTA data. This achieves promising classification performances. More importantly, it provides interpretable region connections to improve model transparency.\n\u2022 Our interpretability analyses validate known eye-brain links and reveal new discriminative patterns, demonstrating the model's potential as a computer-aided pathology tool for studying little-known associations between ophthalmic and complex neurological conditions."}, {"title": "2. METHOD", "content": "In this section, we detail the proposed PolarNet+ for EOAD/MCI detection method using retinal OCTA images, including image polar transformation, classification model architecture, and three specific modules for end-to-end training.\nFig. 2 illustrates the outline of our EOAD/MCI detection method using multiple en face angiograms of OCTA as input. We first employ VAFF-Net(Hao et al., 2022) to locate the FAZ center point on the SVC layer, and then transform the original images from polar coordinates to Cartesian coordinates, as shown in Fig. 2 (a) and (b). These transformed images are fed into the PolarNet+ for the extraction of sequential features in circle-area, ring-area, and sector-area along three dimensions. After sequencing, the sequences that encode complementary region-specific information are treated as graph nodes and fed into a regional relationship module. Finally, PolarNet+ aggregates the node features and relationships for the generation of the final detection output. In addition, PolarNet+ can provide two visualizations for improved model interpretability, as demonstrated in Fig. 2 (e) and (f): a region importance map highlighting discriminative patterns that drive the decision-making, and a regional relationship graph revealing connections between retinal areas that are informative for neurological conditions.\n2.1. Polar transformation of OCTA image\nHere we introduce the polar transformation to realize region-based analysis. It aims to map coordinates from the polar coordinates (r, \u03b8) to the Cartesian coordinate system (x, y). Many image analysis tasks, such as pattern analysis, shape identification, or feature extraction, benefit from this transformation: e.g., Fu et al. (Fu et al., 2018) use polar transformation to transfer the redial relationship to a spatial relationship on the image segmentation task.\nAs shown in Fig. 2 (a) and (b), the polar transformation converts the region of interest (yellow circle) into a Cartesian coordinate system with the FAZ center $O_p(x_o, y_o)$ defined as the pole point. The original image is represented as points in the polar system p(r, \u03b8): their corresponding points in the Cartesian system are represented by p'(x, y) with the horizontal axis as the X axis, and the vertical axis as the Y axis. The following equations give the relationship between these two coordinate systems:\n$\\begin{cases}x = r \\cos \\theta\\\\y = r \\sin \\theta\\end{cases} \\Leftrightarrow \\begin{cases}r = \\sqrt{x^2 + y^2}\\\\\\theta = \\tan^{-1}y/x\\end{cases}$\t\t(1)\nIn order to preserve as much of the original data as possible, we chose the largest internally connected circle as the region of interest and retained the outermost pixels of the region of interest as the edges were cropped out. The width of the transformed image is equal to the radius R of the yellow circle, and the height is 2\u03c0R. Since the corners are cropped, the outermost pixels of the region of interest are kept to preserve as much of the original information as possible, and the part near $O_p$ is filled by nearest neighbor interpolation. The polar transformation represents the original image in the polar coordinate system by pixel-wise mapping(Fu et al., 2018) and has the following properties:\n2.1.1. Approximate sector-shaped computing\nThe basic operations of deep learning rely mainly on linear algebra, such as convolution and linear operations, and include elements of rectangular or linear operations, such as vectors, matrices, and kernels(Aggarwal et al., 2020). However, in the real world, many semantics are non-rectangular, e.g., retinal (circular or fan-shaped), which makes deep learning-based networks less optimal for OCTA-based image analyses. For the polar transformation, the mapping relationship is fixed, enabling us to approximate the sector convolution with a rectangular convolution kernel, thus facilitating its implementation.\nFor the sake of simplicity and clarity, Fig. 2(c) illustrates the ETDRS grids mapped on the polar transformed image. Approximate sector calculation functions can be adapted to any sector herein. For instance, when we perform a rectangular kernel convolution along the TI \u2192 SI direction on the transformed image, it is equivalent to performing a sector kernel convolution around the center of the FAZ in the original image in a counter-clockwise direction.\n2.1.2. Equivalent augmentation\nSince the transformation is a pixel-by-pixel mapping, applying data augmentation to the original image is equivalent to applying data augmentation in the polar system (Fu et al., 2018). For example, we can implement the drift cropping operation in a polar coordinate system by changing the transformation center $O_p(x_o, y_o)$ and the start angle. This is equivalent to changing the transform radius R and applying different cropping factors for data augmentation.\n2.2. The classification model: PolarNet+\nOCTA provides in-depth information to visualize the retinal and choroidal microvascular network and the structure of the FAZ at different layers. To this end, we take advantage of three different en face angiograms from different layers and explore intra- and inter-instance relationships across different retinal and choroidal layers, exploiting the unique characteristics of OCTA data. In this work, the SVC, DVC, and CC layers are used as input to the given PolarNet+, and we stack these three en face images as 3D volume data.\nThe overall architecture of the proposed PolarNet+ is shown in Fig. 3. It consists of three individual components: the spatial extension module, the multi-view module, and the regional relationship module. Since the stacked images are considered volumetric data, all computational operations are three-dimensional.\n2.2.1. Spatial Extension Module (SEM)\nThe spatial extension module is designed to solve the thin volume problem. Considering that we only stack three images as a volume, if the number of stacked layers of the input is too small (e.g., we input three layers), the features in the stacked dimension will be very short (3 for raw data and 1 after convolution with a kernel size of 3), and numerous (Height x Width e.g., 224 x 224 = 50176) for raw data. This leads to insufficiently rich feature semantics, and also greatly reduces the speed of computation. SEM can map three input layers to eight or more using linear layers, and the convolution can then extract features from multiple channels. By applying SEM, the data is transformed from a wide and thin shape to a thick and relatively narrow volume format.\nDenote the input OCTA image as $X^k \\in X$ of size h \u00d7 w, k\u2208 [1, K], and K as the total number of images from one patient. The spatial extension module consists of a multi-layer perceptrons (MLP) layer, a convolution layer, and a ReLU activation layer, which can be represented as:\n$X_{vol} = SEM(X^k) = ReLU(Conv(MLP(X^k)))$ (2)\nwhere the $X_{vol}$ is the spatial extended volume.\n2.2.2. Multi-View Module (MVM)\nThe multi-view module is designed to serialize and integrate volumetric features from different dimensions. A more comprehensive representation can be obtained by extracting features separately along the x, y, and z axes. Each MVM consists of one or more Res3D blocks followed by a Sequencer3D block. The Res3D block performs 3D convolutions to extract features, while avoiding vanishing gradients through residual connections: it can be repeated to adjust depth as needed. The Sequencer3D block is inspired by the Sequencer module (Tatsunami and Taki, 2022), which was the first to successfully apply bidirectional long short-term memory (BiLSTM) for image classification. We adopt a similar design, but modify it to take advantage of polar transformations. Specifically, the Sequencer3D block consists of one BiLSTM3D unit. This contains three standard BiLSTMs one for each of the three dimensions. Each BiLSTM unit contains two LSTM units in two directions, i.e., forward and backward. Consider an input series denoted as $\\overline x$ and let $\\overleftarrow x$ represent the rearranged version of $\\overline x$ in reverse order. The outputs obtained by processing $\\overline x$ and $\\overleftarrow x$ with their respective LSTMs are referred to as $\\overrightarrow x$ for and $\\overleftarrow x$ back. $\\overleftarrow x$ back is then rearranged in the original order of the output $\\overrightarrow x$ for, and the output b of the BiLSTM, B(\u00b7), is derived as follows:\n$\\begin{cases}\\overrightarrow x_{for}, \\overleftarrow x_{back} = LSTM_{for}(\\overline x), LSTM_{back}(\\overline x), \\\\\\\\b = B(\\overline x) = concatenate (\\overrightarrow x_{for}, \\overleftarrow x_{back}).\\end{cases}$ (3)\nWe implemented BiLSTM3D $B^{3D}(\u00b7)$ by applying BiLSTM on three dimensions. Since $X_{vol}$ is in volume format, we can split $X_{vol}$ into $X_{vol}^x, X_{vol}^y,$ and $X_{vol}^z$ according to x, y, and z dimensions. Fusionchannel(\u00b7) denotes a channel fusion operation, and $X_{vol}^{\\text{concat}}$ denotes the volume sequence from three directions:\n$\\begin{aligned} X_{vol}^{emb} &= embedding(X_{vol}) \\\\\\\\X_{vol}^{\\text{concat}} &= concatenate(B(X_{vol}^x), B(X_{vol}^y), B(X_{vol}^z)), \\\\\\\\X_{vol}^{\\text{new}} &= B^{3D}(X_{vol}^{emb}) = Fusionchannel(X_{vol}^{\\text{concat}}). \\end{aligned}$ (4)\nHere, we get an updated $X_{vol}$ as $X_{vol}^{\\text{new}}$. We define a recursive operation $\u0393_t(f_t(\u00b7), d), t \u2208 Z^+$ which denotes $f_t(...(f_2(f_1(x)))),$ where $f_i()$ is the function to recursion, and \u03bb is an input. We repeat Res3D block Res(\u00b7) several times and tandem the blocks to a Sequencer3D block Seq(\u00b7) to get a multi-view block P(\u00b7). Then, by recursing multi-view blocks, we obtain multi-view module $P_m(\u00b7)$:\n$\\begin{aligned} S_1(\\lambda) &= B^{3D}(Norm(\\lambda)) + \\lambda, \\\\\\\\Seq(\\lambda) &= MLP(Norm(S_1(\\lambda))) + S_1(\\lambda), \\\\\\\\P(\\lambda) &= ReLU(Conv(Seq(\\Gamma_{t_1}(Res(\u00b7), \\lambda)))), \\\\\\\\P_m(\\lambda) &= \\Gamma_{t_2}(P(\u00b7), \\lambda), t_1, t_2 \u2208 Z^+, \\\\\\\\X_{seq} &= P(X). \\end{aligned}$ (5)\nwhere \u03bb represents any input, $S_1(\u00b7)$ is a function to package the intermediate stage, the Norm() is the normalisation function and $X_{seq}$ is the processed sequences data.\n2.2.3. Regional Relationship Module (RRM)\nModeling the relationships and connections between different regions in the ETDRS grid is critical to establishing the association between pathological conditions and the retinal microvasculature for the accurate detection of EOAD and MCI. To this end, we propose the regional relationship module (RRM), which transforms the image classification problem into a graph representation, with region sequences modeled as graph nodes.\nGraph neural networks are naturally suited to learning from relational data and can embed high-dimensional connectivity patterns in a low-dimensional space (Wu et al., 2020b). Critically, rather than relying on a predefined adjacency matrix, the RRM incorporates a rewiring mechanism(Arnaiz-Rodr\u00edguez et al., 2022) to learn the edges between regions. Through rewiring, it can learn an enriched representation of the relationships (Nguyen et al., 2023) between different regions within the ETDRS grid, which then allows the revelation of critical interdependencies associated with disease. The RRM contains two differentiable layers, the commute times layer and the spectral gap optimization layer, for rewiring. The commute times layer CT() (Arnaiz-Rodr\u00edguez et al., 2022) identifies salient edges based on resistance; while the spectral gap optimization GAP(\u00b7) (Arnaiz-Rodr\u00edguez et al., 2022) layer optimizes the topology using spectral graph theory.\nTo find optimal clusters in the graph, we introduce MinCUT pooling (Bianchi et al., 2020). Given an adjacency matrix A \u2208 $R^{n\u00d7n}$ and a feature matrix X \u2208 $R^{n\u00d7F}$, we get a node cluster ($A_{n\u00d7n}, X_{n\u00d7F}$) where n denotes the number of nodes and F denotes the dimensions of the features. For a given input node cluster ($A_{n\u00d7n}, R_{n\u00d7F}$), a MinCUT pooling layer MC(\u00b7) is applied to learn a new number k of clusters: ($A_{n\u00d7n}, X_{n\u00d7F}$) \u2192 ($A_{k\u00d7k}, X_{k\u00d7F}$), k < n.\nWe denote an operation that applies a linear operation L to a function f() as $f_L(\u00b7)$, which can be represented as a regional relationship module RRM(\u00b7):\n$\\begin{aligned} S_2(\\lambda) &= GAP_L(Linear(\\lambda)), \\\\\\\\S_3(A) &= Conv(CT_L(A)), \\\\\\\\RRM(\\lambda) &= Conv(MC_L(S_3(S_2(\\lambda))), \\\\\\\\ [X_{cls}, X_{node}, X_{adj}] &= RRM(X_{seq}). \\end{aligned}$ (6)\nwhere \u03bb represents any input, $S_2$ and $S_3$ are the packaging of the GAP layer and the commute times layer. The $X_{cls}, X_{node},$ and $X_{adj}$ are the classification results, nodes matrix, and adjacency matrix, respectively.\n2.2.4. Polar Regional Importance Module (PRIM)\nIn order to obtain the importance of different regions for EOAD and MCI prediction, we designed a polar regional importance module (PRIM) to facilitate prediction visualization and explanation. The regional importance matrix $L_R$ is calculated as follows:\n$L_{RI} = AvgPool[ReLU(\\alpha_i^*)]$ (7)\nwhere the $L_R$ is the regional importance (RI) on the feature map k for class c. We denote $\\alpha_i^*$ as the gradient of the score for class c, with respect to the feature map activations $A^k$ of the last layer (Liu et al., 2023)."}, {"title": "3. Datasets", "content": "Two different datasets were used: ROAD (Retinal OCTA for EOAD study) and ROMCI (Retinal OCTA for MCI study). All OCTA images in these two datasets were obtained from a multi-center case-control study for the detection of AD and MCI. The SVC, DVC, and CC angiograms were used to train, test, and validate the proposed automated method, because together they contain the complete vasculature from superficial to deep. Images from any given subject were alloted only to either the training or test sets, to avoid information leakage. All images analyzed were fovea-centered. The clinical protocol of this study was approved by the Ethics Committee of the Cixi Institute of Biomedical Engineering, Chinese Academy of Sciences, and adhered to the tenets of the Declaration of Helsinki. Informed written consent was obtained from the participants enrolled in our study.\n3.0.1. Retinal OCTA data for EOAD study (ROAD)\nThe ROAD dataset consists of an internal subset (ROAD-I) used for model development and internal testing and an external subset (ROAD-II) used exclusively for external testing. ROAD-I includes 810 OCTA volumes from the Affiliated People's Hospital of Ningbo University, China, featuring 199 early-onset AD subjects and 611 controls. Inclusion criteria for EOAD subjects adhered to the National Institute on Aging and Alzheimer's Association (NIA-AA) guidelines, with diagnosis occurring before the age of 65. Exclusion criteria ensured the absence of other brain disorders, substance abuse, suicidal behaviors, and neurological diseases. The internal test and training sets used a fivefold cross-validation approach, with 20% of the data allocated for internal testing and 80% for training. ROAD-II, an independent dataset acquired from another center (West China Hospital, Sichuan University, Chengdu, China). It included 382 OCTA volumes (150 EOAD and 232 controls). By using it we aim to further validate the generalisability of our model.\n3.0.2. Retinal OCTA data for MCI study (ROMCI)\nThe ROMCI dataset also consists of internal and external subsets, ROMCI-I and ROMCI-II. The former includes 545 OCTA volumes (104 MCI and 441 controls) from the Second Affiliated Hospital of Zhejiang University, Hangzhou, China. Participants with MCI were clinically assessed and diagnosed according to the diagnostic guidelines and recommendations of the Petersen Criteria. Clinical history, cognitive testing, and neuroimaging were reviewed for accuracy by an experienced neurologist specializing in memory disorders. Exclusion criteria included significant sensory impairment and psychiatric disorders. ROMCI-II includes 180 OCTA volumes (35 MCI and 145 controls) obtained from the Affiliated People's Hospital of Ningbo University, Ningbo, China, and follows the same inclusion criteria as ROMCI-I."}, {"title": "4. Experimental Results", "content": "4.1. Implementation details\nWe selected SVC", "methods": "ResNet(He et al."}, {"methods": "Early fusion(Hermessi et al."}, {"methods": "MUCO-Net(Wang et al.", "metrics": "ACC (0.8839)", "dataset": "this makes the training of the model more susceptible to potential overfitting problems.\nExternal validation As expected, all the methods had relatively low metric scores over the ROMCI-II compared to those over the ROMCI-I. As in the EOAD detection task, the proposed PolarNet+ outperformed all competitors, achieving a superior ACC (0.8077), AUC (0.8316), and Kappa (0.5448). However, the performance gap between our MCI detection and other methods is narrower, when compared to the EOAD detection. This is probably due to the small amount of data, and the fact that there are fewer features for the detection of the disease in MCI. Overall, the results confirm the effectiveness and broad applicability of our model in detecting MCI in datasets obtained from different clinical centers.\n4.3. Explainability analysis\nThis subsection presents a visualization of the unique patterns learned by our model. The purpose is to gain a better understanding of the decision-making process of PolarNet+ and to explore how the relationships between different retinal and choroidal layers support the detection of EOAD and MCI. As stated in Section II, PolarNet+ can generate a regional importance map and a regional relationship graph. This allows for the identification of discriminative patterns that influence decision-making and the relationships between retinal areas that are relevant to neurological conditions.\n4.3.1. Regional importance analysis\nIn the testing stage, we engaged the PRIM and produced a 4 \u00d7 2 \u00d7 3 importance matrix, and accumulated the entire testing set. Subsequently, we performed an inverse operation of the polar transformation to generate the corresponding importance map based on the ETDRS grid, as shown in Fig. 4-(a). Furthermore, we analyzed eight distinct parameters that collectively described the retinal microvasculature and the FAZ. These parameters encompass vascular length density (VLD), vascular area density (VAD), vascular bifurcation number (VB), vascular fractal dimension (VFD), FAZ area (FA), FAZ circularity (FC), FAZ roundness (FR), and FAZ solidity (FS). Subsequently, we examined the disparities between the EOAD/MCI and control groups, with the findings presented in Fig. 4-(c). Compared to a commonly-used visualization method, such as Grad-CAM (Selvaraju et al., 2017), as shown in Fig. 4-(b), our region importance map is more clinician-friendly and more easily understandable.\nAs shown in Fig. 4-(a), it can be seen that across the range of the entire ETDRS field, the importance of CC is the highest, which aligns with research (Corradetti et al., 2024), which may indicate a substantial decrease in choriocapillaris flow density among individuals diagnosed with EOAD. Simultaneously, the importance attributed to the DVC corresponds with research (Xie et al., 2023) discoveries and may indicate a substantial reduction in vascular area density and other pertinent factors within the DVC in EOAD (similar to Xie's (Xie et al., 2023) result of the vascular bifurcation number (VBN) analysis). Interestingly, across the three layers, the higher importance occurred on the nasal sides and the superior sides, which may be explained by the research result from Asanad et al. (Asanad et al., 2019). Significant variations in the retinal choroid were observed both in terms of layers and regions, specifically in the nasal and temporal aspects concerning the optic nerve. Our results reveal a consistent pattern wherein heightened importance coincides with regions featuring greater micro-vessel density, such as the CC, DVC, and the parafovea, which is similar to the observation from studies (Corradetti et al., 2024). This may indicate a significant decrease in microvasculature in both the brain and retina of individuals affected by EOAD.\nAdditionally, our findings may also be confirmed partly through our statistical parameters results. As presented in Fig. 4-(c), we found that in EOAD, compared to healthy control, the parameters of VLD, VAD, and VB showed significance in SVC-IE and DVC-II, and VAD and FR showed significance in"}]}