{"title": "LawLuo: A Chinese Law Firm Co-run by LLM Agents", "authors": ["Jingyun Sun", "Chengxiao Dai", "Zhongze Luo", "Yangbo Chang", "Yang Li"], "abstract": "Large Language Models (LLMs) demonstrate substantial potential in delivering legal consultation services to users without a legal background, attributed to their superior text comprehension and generation capabilities. Nonetheless, existing Chinese legal LLMs limit interaction to a single model-user dialogue, unlike the collaborative consultations typical of law firms, where multiple staff members contribute to a single consultation. This limitation prevents an authentic consultation experience. Additionally, extant Chinese legal LLMs suffer from critical limitations: (1) insufficient control over the quality of instruction fine-tuning data; (2) increased model hallucination resulting from users' ambiguous queries; and (3) a reduction in the model's ability to follow instructions over multiple dialogue turns. In response to these challenges, we propose a novel legal dialogue framework that leverages the collaborative capabilities of multiple LLM agents, termed LawLuo. This framework encompasses four agents: a receptionist, a lawyer, a secretary, and a boss, each responsible for different functionalities, collaboratively providing a comprehensive legal consultation to users. Additionally, we constructed two high-quality legal dialogue datasets, KINLED and MURLED, and fine-tuned ChatGLM-3-6b using these datasets. We propose a legal query clarification algorithm called ToLC. Experimental results demonstrate that LawLuo outperforms baseline LLMs, including GPT-4, across three dimensions: lawyer-like language style, the usefulness of legal advice, and the accuracy of legal knowledge. Our code and datasets are available at https://github.com/NEFUJing/LawLuo", "sections": [{"title": "1. Introduction", "content": "Since the release of ChatGPT, the development of Chinese Large Language Models (LLMs) has advanced rapidly, resulting in the emergence of several influential base models, including ChatGLM (Du et al. 2022), LLaMa (Touvron et al. 2023a), and BaiChuan (Yang et al. 2023). These models excel in fluent Chinese dialogue and comprehension of complex contexts and user intentions. Additionally, domain-specific Chinese LLMs such as Medical LLMs (Yang et al. 2024; Zhang et al. 2023a), Legal LLMs (Huang et al. 2023; Zhou et al. 2024), and Financial LLMs (Zhang and Yang 2023) have emerged, showcasing exceptional domain-specific conversational abilities and meeting diverse user needs.\nChinese Legal LLMs offer users without a legal background timely, accurate, and clear solutions to legal issues, effectively addressing the shortage of legal resources. Recently, notable Chinese Legal LLMs such as LawGPT (Zhou et al. 2024) and lawyer-llama (Huang et al. 2023) have emerged. They leverage extensive Chinese legal dialogue datasets to fine-tune Chinese base large models, resulting in LLMs equipped with comprehensive Chinese legal knowledge and the capability to engage in legal consultation dialogues. Nevertheless, a standalone legal LLM fall short in simulate the Standard Operating Procedure (SOP) of real-world legal consultations, thus failing to deliver an authentic consulting experience to users. Additionally, existing LLMs encounter several issues: (1) Users consulting these models often lack a legal background, leading to vague and imprecise queries that exacerbate models' tendency to produce hallucinations; (2) Despite utilizing large datasets for instruction fine-tuning, current legal LLMs do not sufficiently control for data quality; (3) Existing models employ single-turn legal dialogue data for fine-tuning, neglecting multi-turn dialogue data, which undermines models' ability to follow instructions after multi-turn conversation.\nTo address the aforementioned issues, we propose a novel legal dialogue framework, termed LawLuo, grounded in LLM multi-agents. Initially, we fine-tune the Chinese base LLM, ChatGLM-3-6b, leveraging our meticulously constructed high-quality legal dialogue dataset, KINLED, alongside the multi-turn legal consultation dataset, MURLED. Contrary to other models of employing extensive datasets, our findings indicate that fine-tuning with a smaller, high-quality legal dialogue dataset yields superior performance. Subsequently, we design multiple agents-receptionist, lawyer, secretary, and boss based on the SOP of actual law firms. We design a collaborative framework wherein these agents synergistically handle a user's legal consultation, thereby enhancing the user consultation experience. We further specialize the roles of lawyer agents via role enhancement (Shao et al. 2023; Wang et al. 2023b), according to different consultation domains. For instance, a corporate lawyer is designated to engage with users seeking advice on corporate law, whereas a traffic accident"}, {"title": "2. Related work", "content": "Legal Question Answering. Legal Question Answering (LQA) is considered one of the most challenging tasks in legal artificial intelligence due to its flexible input-output requirements. In this task, users ask legal questions, and systems provide detailed answers that meet their expectations. Early LQA systems fall into three main categories: retrieval-based LQA systems (Yoshioka, Aoki, and Suzuki 2021), knowledge-based LQA systems (Taniguchi and Kano 2017), and machine reading comprehension-based LQA systems (Xiao et al. 2021). Significant advancements in Chinese LQA have been driven by datasets like the Chinese Judicial Reading Comprehension dataset (CJRC) (Duan et al. 2019) and the Judicial Examination Chinese QA dataset (JEC-QA) (Zhong et al. 2020). However, early methods struggle to personalize answers. Additionally, many legal consultations require multi-turn dialogues rather than a single question and answer exchange.\nIn recent years, applying LLM to LQA has shown great promise. Compared to traditional LQA models, LLMs generate personalized responses based on user queries and support multi-turn dialogues for more precise legal inquiry resolution. LawGPT (Zhou et al. 2024) continuing pre-trains and instruction fine-tunes Chinese-LLaMa-7B (Touvron et al. 2023a), a Chinese base model, with publicly available legal documents and judicial examination data, thereby enhancing its understanding and execution of legal content. LexiLaw\u00b9 fine-tunes ChatGLM-6B with data from Huazhi.com\u00b2, judicial examination data, and Q&A data with legal references, using Freeze, Lora, and P-Tuning-V2 techniques to boost training efficiency. LawGPT_zh fine-tunes ChatGLM-6B using existing legal datasets and scenario-based Q&A data with statutory references, while lawyer-llama (Huang et al. 2023) uses judicial examination data to fine-tune Chinese-LLaMA-13, enhancing its application of legal knowledge to dialogue scenarios. However, these models only use a single LLM for legal consultations, unlike real-world law firms where multiple staff collaborate on a user's consultation. This limitation fails to provide users with the most realistic and expected LQA experience. Additionally, while current legal LLMs use numerous fine-tuning datasets, their quality varies significantly, contradicting recent findings that in large model instruction fine-tuning, \u201cless is more\u201d (i.e., data quality is more important than quantity) (Wei et al. 2023b; Xia et al. 2024).\nMulti-Agent Collaboration. In LLM-based multi-agent systems, an agent is defined as an autonomous entity capable of perceiving, thinking, learning, making decisions, and interacting with other agents (Xi et al. 2023). Research shows that breaking complex tasks into simpler subtasks and tackling these with agents that have diverse functions can significantly enhance the problem-solving capabilities of LLMs. (Wang et al. 2024). Fundamentally, Retrieval-Augmented Generation (RAG) based on LLMs constitutes a straightforward multi-agent system wherein a retrieval agent is tasked with sourcing relevant knowledge from a vector database, while an LLM agent is responsible for generating responses based on the query and associated knowledge (Louis, van Dijck, and Spanakis 2024). Furthermore, some works have developed more complex multi-agent collaborative systems to address intricate challenges. For instance, (Qian et al. 2023) designed a multi-agent collaborative workflow in which agents assuming roles such as CTO, programmer, designer, and tester work closely together to complete software development and document the development process. (Hemmer et al. 2022) have facilitated the construction of machine learning models through collaboration between multiple agents and humans. Additionally, LLM-based multi-agent systems can also be employed for realistic environment simulation. For example, (Wang et al. 2023a) utilized multiple generative LLM agents in a sandbox environment to simulate consumer behavior in merchandise recommendation scenarios, (Wei et al. 2023a) assigned various roles to agents for the collection and evaluation of multi-party dialogue data, and (Du et al. 2023) leveraged debates among agents with different personalities to enhance the factual accuracy of LLM reasoning."}, {"title": "3. LawLuo Framework for LQA", "content": "In real-world scenarios, a consultation in law firms is conducted through the collaboration of multiple staff members, whereas existing legal LLMs generally engage with a user in isolation. To bridge this gap, we introduce a multi-agent collaborative legal dialogue framework, named LawLuo.\nFirstly, we perform LoRA fine-tuning on ChatGLM-3-6b using knowledge-intensive dialogue data and real multi-turn dialogue data from a Chinese law firm, resulting in a multi-turn dialogue LLM with a legal background, denoted as $LLM_{Legal}: (s_0, U_{1:T}) \\rightarrow R_{1:T}$, where $U_{1:T}$ represents the sequence of user queries from the first to the T-th turn, $R_{1:T}$ represents the sequence of model responses, and $s_0$ represents the initial dialogue state.\nNext, we design various agents with different roles, including a receptionist agent responsible for allocating lawyers from different fields based on user queries, lawyer agents for conducting multi-turn LQA with users, a secretary agent for organizing the dialogue between users and lawyers into consultation reports, and a boss agent supervising other agents. Finally, we construct a collaborative framework to guide interactions among these agents, thereby providing users with a high-quality LQA experience."}, {"title": "3.1 Instruction Fine-tuning", "content": "Existing LLMs in the legal domain, despite leveraging a substantial volume of dialogue data during the instruction fine-tuning process, frequently contend with quality deficiencies. Figure 2 presents the lawyer consultation data\u00b3 utilized by LawGPT_zh and the Baidu Zhidao Q&A data\u2074 employed by LexiLaw. It is apparent that the questions' clarity and the responses' professionalism in these dialogues are suboptimal, impairing models' instruction follow capabilities in LQA.\nRecent studies indicate that utilizing fewer but higher-quality data can significantly enhance the instruction-following capabilities of LLMs (Wei et al. 2023b; Xia et al. 2024). Consequently, we developed a smaller but higher-quality dataset, termed Knowledge-INtensive LEgal Dialogue (KINLED) dataset. Firstly, we screened existing legal dialogue datasets, discarding lower-quality dialogues and retaining those of higher-quality. Moreover, to enhance the model's application of critical legal terminologies, we constructed legal term and explanation dialogue data. Additionally, to improve the model's understanding of significant charges and legal provisions, we created legal judgment dialogue and judicial interpretation dialogue. The KINLED dataset construction employed the self-instruct strategy, with specific construction details provided in Appendix A. Table 1 presents the statistical information of the KINLED dataset.\nThe existing legal LLMs have all been fine-tuned using single-turn dialogue data, which hinders their ability to follow instructions in multi-turn dialogue scenarios. To address this limitation, we constructed a fine-tuning dataset based on 3,260 anonymized multi-turn legal consultations from a law firm, termed MUltiple Rounds LEgal Dialogue (MURLED). Figure 3 presents an example of a multi-turn"}, {"title": "3.2 Agent Definition", "content": "We define the following agents based on the Standard Operating Procedures (SOP) of law firms: 1) Receptionist, responsible for assigning lawyers to users based on the queries they present. 2) Lawyers, engage in multiple rounds dialogue to resolve users' legal issues. 3) Secretary, responsible for compiling the dialogues between users and lawyers into consultation reports, and then submitting them to both the users and the boss. 4) Boss, charged with evaluating the lawyers and the secretary. Subsequently, we will provide a detailed exposition of these agents.\nReceptionist Given the user's initial question $u_1$ and the initial dialogue state $s_0$, the role of the receptionist agent is to assign it a consultation domain label $d \\in D$, as shown in Equation 2:\n$Rec: (u_1, s_0) \\leftrightarrow d \\in D$   (2)\nwhere the set $D$ represents our predefined consultation domains. We adhere to the classification of legal consultation domains as outlined on the HuLaw website\u2076, encompassing a total of 16 domains, as depicted in Figure 4. Of these, 15 are common consultation fields, while other less common consultation areas are collectively categorized under \"Others\".\nWe use a contrastive trained RoBERTa as the secretary agent. We first crawled 35,060 legal questions with domain tags from HuaLaw web, with the number of questions in each domain illustrated in Figure 4. Subsequently, we used the current question as the anchor, questions from the same domain as positive examples, and questions from different domains as negative examples. We optimized the semantic distance between samples using contrastive loss, as depicted in Equation 3.\n$\\mathcal{L} = \\frac{1}{N} \\sum_{n=1}^{N}[\\|d_i - p_i\\|^2 + max(0, \\alpha - \\|d_i - \\tilde{n_i}\\|^2)]$   (3)"}, {"title": "Algorithm 1: Tree of Legal Clarifications (ToLC)", "content": "Require: User's query in the t-th round $u_t$, ChatGPT-40's API, lawyer agent $Lawyer_a$, maximum height H, maximum width $K^{(H-1)}$, Case bank C\nEnsure: $Lawyer_a$'s response $r_t$\n1: Initialize tree T \u2190 {}\n2: $N_1$ = root \u2190 $u_t$  \u25b7 The root node is numbered 1\n3: Add $N_1$ into T\n4: for h = 1 to H - 1 do\n5:   for k = 1 to $K^{(h-1)}$ do\n6:     $i = K^{h-1} + k$  \u25b7 Index of the k-th node on the h-th layer.\n7:     $C_i$ \u2190 Retriever($N_i$,C)  \u25b7 Retrieve relevant cases from C\n8:     Children \u2190 ChatGPT($N_i, C_i$)  \u25b7 Generate legal elements\n9:     Add Children into T\n10:   end for\n11: end for\n12: $V$ \u2190 User(T)  \u25b7 User actively choose Yes/No nodes\n13: $r_t$ \u2190 $Lawyer_a$ (V) \u25b7 Lawyer agent generates a response\nas shown in Equation 5.\n$Sec: (s_0, U_{1:T}, R_{1:T}) \\rightarrow r$   (5)\nwhere $r$ denotes the consultation report generated by the secretary agent. We utilize ChatGLM-3-6b as the secretary agent and employ In-Context Learning (ICL) to guide the model in producing consultation reports that meet expectations. We have constructed four standard consultation report samples, as shown in Appendix B, to serve as demonstrations in ICL reasoning.\nBoss The boss agent is responsible for evaluating the lawyer and secretary agents. Essentially, the boss agent is a Reward Model (RM). We first train a binary evaluation RM, $RM:o \\rightarrow y$, where o represents the output of the lawyer or secretary agent, and y represents the RM's evaluation of o, categorized into \u201cbetter\u201d and \u201cworse\u201d. The training objective of the RM is to minimize the following loss function:\n$C_{RM} = \\frac{1}{N} \\sum_{i=1}^N [y_i log (\\hat{y_i} (o_i; \\theta_{RM})) + (1 - y_i) log (1 - \\hat{y_i} (o_i; \\theta_{RM}))]$   (6)\nwhere $y_i$ represents the true label of the i-th sample, taking values of either 0 or 1, which correspond to \"worse\" and \"better\", respectively. Besides, $\\hat{y_i}(o_i; \\theta_{RM})$ denotes the probability that RM predicts the i-th output $o_i$ as \u201cbetter.\u201d We employed the PPO algorithm (Wang, He, and Tan 2020) during the reinforcement learning phase, an efficient reinforcement learning method that utilizes RM's evaluation outcomes to guide the updates of the LLM. This approach further aligns the LLM's performance with the preferences of human experts (the boss agent).\nBased on the definitions of the agents, we constructed a collaborative pipeline designed to imitate the SOP of legal"}, {"title": "4. Experimental Setup", "content": "All our experiments were conducted on a 40G A100 GPU. The PyTorch 2.3.0 and the HuggingFace Transformers 4.40.0 were used. The learning rate for LoRA fine-tuning was set to 0.00005, with a training batch size of 2, over a total of 3 epochs, and model weights were saved every 1,000 steps. Additionally, the rank of LoRA was set to 16, the alpha parameter was set to 32, and the dropout rate was set to 0.05. The case database used in the ToLC algorithm was sourced from the China Judgments Online website."}, {"title": "5. Results and Analysis", "content": "5.1 Results on Single-turn Questions\nWe follow the current mainstream evaluation methods for large models to assess our LawLuo (Thirunavukarasu et al. 2023; Xiong et al. 2023; Zhang et al. 2023b). We engaged both human experts and GPT-4o to evaluate the model's performance based on the following criteria: lawyer-like language style, usefulness of legal advice, and accuracy of legal knowledge. We employed pairwise evaluation, where given a response from LawLuo and a baseline response, the better one is selected. Figure 6 shows the win rate of LawLuo compared to baselines. Overall, LawLuo significantly outperforms the baselines. Additionally, as seen in the figure, LawLuo achieved a 72% win rate against ChatGLM-3-6b, demonstrating the effectiveness of our instruction fine-tuning process, given that LawLuo was fine-tuned on ChatGLM-3-6b. Furthermore, the figure indicates that LawLuo outperforms the other two legal large models, LawGPT and LawyerLLaMa. Lastly, even when compared to GPT-4, LawLuo still exhibits a significant advantage.\n5.2 Results on Multi-turn Dialogues\nThis section aims to analyze the advantages of LawLuo in multi-turn dialogue scenarios. We employed GPT-4o to rate the responses generated by the model in each turn of the dialogue, assessing the quality variation of the responses as the number of dialogue turns increased. We set a scoring range of 1-10, using the criteria of lawyer-like language style, the usefulness of legal advice, and the accuracy of legal knowledge as mentioned in Section 5.1. The prompt driving GPT-4o's scoring is provided in Appendix C. As shown in Figure 7, LawLuo's responses maintain a high score as the number of dialogue turns increases. This result is primarily attributed to our use of multi-turn dialogue data, enhanced by ChatGPT and sourced from actual law firms, for instruction fine-tuning, as opposed to other legal LLMs that only use single-turn dialogue data.\n5.3 Ablation Study\nThis section aims to validate the contributions of each component within the framework. We continue to use GPT-4o as the evaluator to assess the win rate of LawLuo over Chat-GPT after ablation, as illustrated in Figure 8. From the figure, it is evident that the win rate of LawLuo over Chat-GPT decreases by 3% after ablating the receptionist agent and role enhancement. This result validates our hypothesis that legal LLMs should be assigned different domain-specific roles to provide more targeted answers based on the user's consultation field. Additionally, the figure shows that the boss agent also contributes to LawLuo's performance, as it can optimize the responses generated by the lawyer. Finally, we observe a significant decline in model performance after removing the ToLD module. This indicates that clarifying users' vague and ambiguous queries is crucial for generating high-quality responses in legal question-answering.\n5.4 Case Study of ToLD\nThis section elucidates the contributions of ToLD through a specific case study. We take the query\u201c\u6211\u8981\u79bb\u5a5a,\u8be5\u600e\u4e48\u529e? (I want a divorce, what should I do?)\" as an example initiated by a user. The left side of Figure 9 displays the clarifying questions generated by the ToLD algorithm. The results after the user actively marked Yes/No are shown on the right side of Figure 9.\nAdditionally, the first row of Table 2 in Appendix D presents the answer generated by LawLuo without TOLD, while the second row shows the answer generated by LawLuo with ToLD. It can be observed that TOLD assists legal LLMs in generating more accurate and personalized responses.\""}, {"title": "6. Discussion", "content": "Enlightenment\nThis study has provided us with several intriguing insights. Firstly, we discovered that omitting continue pre-training and directly conducting instruction fine-tuning does not impact the effectiveness of the legal LLM. This indicates that the Chinese base model has already acquired a certain degree of legal knowledge during the pre-training phase, obviating the need for additional pre-training with legal corpora. In fact, the pre-training corpora used by many Chinese base models are extraordinarily large and likely encompass a substantial amount of legal text. We also found that the instruction fine-tuning phase does not require tens of thousands or even hundreds of thousands of dialogue data; approximately thousands high-quality legal dialogue data are sufficient to elicit the model's legal knowledge application capabilities in dialogue scenarios. This paves a new path for the future fine-tuning of legal LLMs. Lastly, the effectiveness of role enhancement and multi-agent collaboration in our method validated our hypothesis that a legal consultation should not be a mere conversational process but a complex task involving multiple business processes.\nLimitation and Future Work\nAlthough we observed that the receptionist agent achieved a question classification accuracy rate exceeding 98% in our experiments, any misclassification leads to the lawyer agent continuing the interaction based on the initial error (a matrimonial lawyer could handle legal inquiries related to traffic accidents, albeit with reduced effectiveness). In the future, we plan to design a dynamic receptionist mechanism that reallocates the user to the appropriate lawyer based on conversation content whenever a domain mismatch is detected during the interaction with the legal LLM.\nDespite introducing the concept of multi-agent collaboration, not every agent is an LLM, resulting in limited thinking and decision-making capabilities. In the future, we intend to develop a collaborative framework in which all agents are LLMs, thereby enhancing the overall framework's cognitive and decision-making abilities."}, {"title": "Conclusion", "content": "We propose a multi-agent collaboration framework for legal dialogue, termed LawLuo. Experimental results demonstrate that LawLuo outperforms baseline LLMs in three dimensions: lawyer-like language style, the usefulness of legal advice, and the accuracy of legal knowledge. Moreover, it continues to produce high-quality answer even after multiple rounds of dialogue. We contribute two high-quality datasets for legal LLM instruction fine-tuning, KINLED and MURLED. Experimental results indicate that using these datasets can fine-tune more effective legal LLMs."}]}