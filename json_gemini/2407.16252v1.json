{"title": "LawLuo: A Chinese Law Firm Co-run by LLM Agents", "authors": ["Jingyun Sun", "Chengxiao Dai", "Zhongze Luo", "Yangbo Chang", "Yang Li"], "abstract": "Large Language Models (LLMs) demonstrate substantial potential in delivering legal consultation services to users without a legal background, attributed to their superior text comprehension and generation capabilities. Nonetheless, existing Chinese legal LLMs limit interaction to a single model-user dialogue, unlike the collaborative consultations typical of law firms, where multiple staff members contribute to a single consultation. This limitation prevents an authentic consultation experience. Additionally, extant Chinese legal LLMs suffer from critical limitations: (1) insufficient control over the quality of instruction fine-tuning data; (2) increased model hallucination resulting from users' ambiguous queries; and (3) a reduction in the model's ability to follow instructions over multiple dialogue turns. In response to these challenges, we propose a novel legal dialogue framework that leverages the collaborative capabilities of multiple LLM agents, termed LawLuo. This framework encompasses four agents: a receptionist, a lawyer, a secretary, and a boss, each responsible for different functionalities, collaboratively providing a comprehensive legal consultation to users. Additionally, we constructed two high-quality legal dialogue datasets, KINLED and MURLED, and fine-tuned ChatGLM-3-6b using these datasets. We propose a legal query clarification algorithm called ToLC. Experimental results demonstrate that LawLuo outperforms baseline LLMs, including GPT-4, across three dimensions: lawyer-like language style, the usefulness of legal advice, and the accuracy of legal knowledge. Our code and datasets are available at", "sections": [{"title": "1. Introduction", "content": "Since the release of ChatGPT, the development of Chinese Large Language Models (LLMs) has advanced rapidly, resulting in the emergence of several influential base models, including ChatGLM (Du et al. 2022), LLaMa (Touvron et al. 2023a), and BaiChuan (Yang et al. 2023). These models excel in fluent Chinese dialogue and comprehension of complex contexts and user intentions. Additionally, domain-specific Chinese LLMs such as Medical LLMs (Yang et al. 2024; Zhang et al. 2023a), Legal LLMs (Huang et al. 2023; Zhou et al. 2024), and Financial LLMs (Zhang and Yang 2023) have emerged, showcasing exceptional domain-specific conversational abilities and meeting diverse user needs.\nChinese Legal LLMs offer users without a legal background timely, accurate, and clear solutions to legal issues, effectively addressing the shortage of legal resources. Recently, notable Chinese Legal LLMs such as LawGPT (Zhou et al. 2024) and lawyer-llama (Huang et al. 2023) have emerged. They leverage extensive Chinese legal dialogue datasets to fine-tune Chinese base large models, resulting in LLMs equipped with comprehensive Chinese legal knowledge and the capability to engage in legal consultation dialogues. Nevertheless, a standalone legal LLM fall short in simulate the Standard Operating Procedure (SOP) of real-world legal consultations, thus failing to deliver an authentic consulting experience to users. Additionally, existing LLMs encounter several issues: (1) Users consulting these models often lack a legal background, leading to vague and imprecise queries that exacerbate models' tendency to produce hallucinations; (2) Despite utilizing large datasets for instruction fine-tuning, current legal LLMs do not sufficiently control for data quality; (3) Existing models employ single-turn legal dialogue data for fine-tuning, neglecting multi-turn dialogue data, which undermines models' ability to follow instructions after multi-turn conversation.\nTo address the aforementioned issues, we propose a novel legal dialogue framework, termed LawLuo, grounded in LLM multi-agents. Initially, we fine-tune the Chinese base LLM, ChatGLM-3-6b, leveraging our meticulously constructed high-quality legal dialogue dataset, KINLED, alongside the multi-turn legal consultation dataset, MURLED. Contrary to other models of employing extensive datasets, our findings indicate that fine-tuning with a smaller, high-quality legal dialogue dataset yields superior performance. Subsequently, we design multiple agents-receptionist, lawyer, secretary, and boss based on the SOP of actual law firms. We design a collaborative framework wherein these agents synergistically handle a user's legal consultation, thereby enhancing the user consultation experience. We further specialize the roles of lawyer agents via role enhancement (Shao et al. 2023; Wang et al. 2023b), according to different consultation domains. For instance, a corporate lawyer is designated to engage with users seeking advice on corporate law, whereas a traffic accident"}, {"title": "2. Related work", "content": "Legal Question Answering. Legal Question Answering (LQA) is considered one of the most challenging tasks in legal artificial intelligence due to its flexible input-output re- quirements. In this task, users ask legal questions, and sys- tems provide detailed answers that meet their expectations.\nEarly LQA systems fall into three main categories: retrieval- based LQA systems (Yoshioka, Aoki, and Suzuki 2021), knowledge-based LQA systems (Taniguchi and Kano 2017), and machine reading comprehension-based LQA systems (Xiao et al. 2021). Significant advancements in Chinese LQA have been driven by datasets like the Chinese Judicial Reading Comprehension dataset (CJRC) (Duan et al. 2019) and the Judicial Examination Chinese QA dataset (JEC-QA) (Zhong et al. 2020). However, early methods struggle to per- sonalize answers. Additionally, many legal consultations re- quire multi-turn dialogues rather than a single question and answer exchange.\nIn recent years, applying LLM to LQA has shown great promise. Compared to traditional LQA models, LLMs gen- erate personalized responses based on user queries and sup-"}, {"title": "3. LawLuo Framework for LQA", "content": "In real-world scenarios, a consultation in law firms is con- ducted through the collaboration of multiple staff members, whereas existing legal LLMs generally engage with a user in isolation. To bridge this gap, we introduce a multi-agent collaborative legal dialogue framework, named LawLuo.\nFirstly, we perform LoRA fine-tuning on ChatGLM-3- 6b using knowledge-intensive dialogue data and real multi- turn dialogue data from a Chinese law firm, resulting in a multi-turn dialogue LLM with a legal background, denoted as LLMLegal: $(s_0, U_{1:T}) \\rightarrow R_{1:T}$, where $U_{1:T}$ represents the sequence of user queries from the first to the T-th turn, $R_{1:T}$ represents the sequence of model responses, and $s_0$ represents the initial dialogue state.\nNext, we design various agents with different roles, including a receptionist agent responsible for allocating lawyers from different fields based on user queries, lawyer agents for conducting multi-turn LQA with users, a secretary agent for organizing the dialogue between users and lawyers into consultation reports, and a boss agent supervising other agents. Finally, we construct a collaborative framework to guide interactions among these agents, thereby providing users with a high-quality LQA experience."}, {"title": "3.1 Instruction Fine-tuning", "content": "Existing LLMs in the legal domain, despite leveraging a sub- stantial volume of dialogue data during the instruction fine- tuning process, frequently contend with quality deficiencies. Recent studies indicate that utilizing fewer but higher-quality data can significantly enhance the instruction- following capabilities of LLMs (Wei et al. 2023b; Xia et al. 2024). Consequently, we developed a smaller but higher-quality dataset, termed Knowledge-INtensive LEgal Dialogue (KINLED) dataset. Firstly, we screened existing legal dialogue datasets, discarding lower-quality dialogues and retaining those of higher-quality. Moreover, to enhance the model's application of critical legal terminologies, we constructed legal term and explanation dialogue data. Additionally, to improve the model's understanding of signifi- cant charges and legal provisions, we created legal judgment dialogue and judicial interpretation dialogue. The KINLED dataset construction employed the self-instruct strategy, with specific construction details provided in Appendix A. The existing legal LLMs have all been fine-tuned using single-turn dialogue data, which hinders their ability to fol- low instructions in multi-turn dialogue scenarios. To ad- dress this limitation, we constructed a fine-tuning dataset based on 3,260 anonymized multi-turn legal consultations from a law firm, termed MUltiple Rounds LEgal Dialogue (MURLED)."}, {"title": "3.2 Agent Definition", "content": "We define the following agents based on the Standard Op- erating Procedures (SOP) of law firms: 1) Receptionist, re- sponsible for assigning lawyers to users based on the queries they present. 2) Lawyers, engage in multiple rounds dia- logue to resolve users' legal issues. 3) Secretary, responsi- ble for compiling the dialogues between users and lawyers into consultation reports, and then submitting them to both the users and the boss. 4) Boss, charged with evaluating the lawyers and the secretary. Subsequently, we will provide a detailed exposition of these agents.\nReceptionist Given the user's initial question $u_1$ and the initial dialogue state $s_0$, the role of the receptionist agent is to assign it a consultation domain label $d \\in D$, as shown in Equation 2:\n$Rec: (u_1, s_0) \\leftrightarrow d \\in D$ (2)\nwhere the set $D$ represents our predefined consultation do- mains. We adhere to the classification of legal consultation domains as outlined on the HuLaw website.\nWe use a contrastive trained RoBERTa as the secretary agent. We first crawled 35,060 legal questions with domain tags from HuaLaw web, with the number of questions in each domain illustrated in Figure 4. Subsequently, we used the current question as the anchor, questions from the same domain as positive examples, and questions from different domains as negative examples. We optimized the semantic distance between samples using contrastive loss, as depicted in Equation 3.\n$L = \\frac{1}{N}\\sum_{n=1}^{N}[||d_i - p_i||^2 + max(0, \\alpha - ||d_i - \\tilde{n_i}||)^2]$ (3)\nwhere $d_i$ represents the embedded representation of the i-th anchor sample, $p_i$ denotes the representation of the positive sample from the same domain as the anchor, and $\\tilde{n_i}$ signifies the embedded representation of the negative sample from a different domain than the anchor. Furthermore, $\\alpha$ is the hyperparameter in the contrastive loss, and $|| \\cdot ||$ denotes the Euclidean distance. We utilize Lawformer (Xiao et al. 2021) as the embedding model.\nLawyers We utilize the LLMLegal we fine-tuned as the lawyer engine and employ role enhancement to guide LLMLegal in acting as lawyers proficient in various fields. For consultation domain d, the lawyer proficient in that do- main is denoted as Lawyera, as shown in Equation 4\n$Lawyer_d \\leftarrow REd(LLM_{Legal})$ (4)\nwhere $RE_d(\\cdot)$ represents the prompt function used for role enhancement.\nIn addition, existing legal LLMs overlook a critical chal- lenge in LQA: the legal questions posed by users are often rough and ambiguous. Directly inputting such questions into the LLM makes it difficult to obtain the desired answers. By contrast, in real-world practice, lawyers typically guide users to clarify their questions, resulting in clear and detailed inquiries. Therefore, we propose the Tree of Legal Clarifica- tions (ToLC) algorithm, which builds on the Tree of Clarifi- cations (ToC) proposed by (Kim et al. 2023). The ToC uses top-K articles from Wikipedia to guide LLM in generating clarification questions. We adapted this by searching for top- K relevant cases from a legal case database to guide LLM in generating necessary legal clarifications. The ToC prunes unhelpful nodes through LLM's self-verification, while we altered this process to involve active Yes/No answering by users. We believe users understand their own cases better than any language model or external knowledge. In other words, lawyers should guide users in clarifying legal facts, not fabricate the facts involved. Algorithm 1 describes the implementation of ToLC.\nSecretary The duty of the secretary agent is organizing the dialogue between the user and the lawyer into a consultation report and then submitting it to both the user and the boss, as shown in Equation 5.\n$Sec: (s_0, U_{1:T}, R_{1:T}) \\rightarrow r$ (5)\nwhere r denotes the consultation report generated by the secretary agent. We utilize ChatGLM-3-6b as the secretary agent and employ In-Context Learning (ICL) to guide the model in producing consultation reports that meet expecta- tions. We have constructed four standard consultation report samples, as shown in Appendix B, to serve as demonstra- tions in ICL reasoning.\nBoss The boss agent is responsible for evaluating the lawyer and secretary agents. Essentially, the boss agent is a Reward Model (RM). We first train a binary evaluation RM, $RM: o \\rightarrow y$, where o represents the output of the lawyer or secretary agent, and y represents the RM's evaluation of o, categorized into \u201cbetter\u201d and \u201cworse\u201d. The training objective of the RM is to minimize the following loss function:\n$C_{RM} = \\frac{1}{N}\\sum_{i=1}^{N}[y_i log (\\hat{y_i}(o_i; \\theta_{RM})) + (1-y_i) log (1 - \\hat{y_i}(o_i; \\theta_{RM}))]$ (6)\nwhere $y_i$ represents the true label of the i-th sample, tak- ing values of either 0 or 1, which correspond to \"worse\" and \"better\", respectively. Besides, $\\hat{y_i}(o_i; \\theta_{RM})$ denotes the probability that RM predicts the i-th output or as \"better.\" We employed the PPO algorithm (Wang, He, and Tan 2020) during the reinforcement learning phase, an efficient reinforcement learning method that utilizes RM's evaluation outcomes to guide the updates of the LLM. This approach further aligns the LLM's performance with the preferences of human experts (the boss agent).\nBased on the definitions of the agents, we constructed a collaborative pipeline designed to imitate the SOP of legal"}, {"title": "Algorithm 1: Tree of Legal Clarifications (ToLC)", "content": "Require: User's query in the t-th round $u_t$, ChatGPT-4o's API, lawyer agent $Lawyer_a$, maximum height H, maximum width $K^{(H-1)}$, Case bank C\nEnsure: $Lawyer_a$'s response $r_t$\nInitialize tree $T \\leftarrow {}$\n$N_1 = root \\leftarrow u_t$  The root node is numbered 1\nAdd $N_1$ into T\nfor $h = 1$ to $H - 1$ do\nfor $k = 1$ to $K^{(h-1)}$ do\n$i \\leftarrow K^{(h-1)}+k$ Index of the k-th node on the h-th layer.\n$C_i \\leftarrow Retriever(N_i, C)$ Retrieve relevant cases from C\n$Children \\leftarrow ChatGPT(N_i, C_i)$ Generate legal elements\nAdd Children into T\nend for\nend for\n$V \\leftarrow User(T)$ User actively choose Yes/No nodes\n$r_t \\leftarrow Lawyer_a (V)$ Lawyer agent generates a response"}, {"title": "4. Experimental Setup", "content": "All our experiments were conducted on a 40G A100 GPU. The PyTorch 2.3.0 and the HuggingFace Transformers 4.40.0 were used. The learning rate for LoRA fine-tuning was set to 0.00005, with a training batch size of 2, over a to- tal of 3 epochs, and model weights were saved every 1,000 steps. Additionally, the rank of LoRA was set to 16, the al- pha parameter was set to 32, and the dropout rate was set to 0.05. The case database used in the ToLC algorithm was sourced from the China Judgments Online website."}, {"title": "5. Results and Analysis", "content": "5.1 Results on Single-turn Questions\nWe follow the current mainstream evaluation methods for large models to assess our LawLuo (Thirunavukarasu et al. 2023; Xiong et al. 2023; Zhang et al. 2023b). We engaged both human experts and GPT-4o to evaluate the model's per- formance based on the following criteria: lawyer-like lan- guage style, usefulness of legal advice, and accuracy of le- gal knowledge. We employed pairwise evaluation, where given a response from LawLuo and a baseline response, the better one is selected. Overall, LawLuo sig- nificantly outperforms the baselines. Additionally, as seen in the figure, LawLuo achieved a 72% win rate against ChatGLM-3-6b, demonstrating the effectiveness of our in- struction fine-tuning process, given that LawLuo was fine-"}, {"title": "5.2 Results on Multi-turn Dialogues", "content": "This section aims to analyze the advantages of LawLuo in multi-turn dialogue scenarios. We employed GPT-40 to rate the responses generated by the model in each turn of the dia- logue, assessing the quality variation of the responses as the number of dialogue turns increased. We set a scoring range of 1-10, using the criteria of lawyer-like language style, the usefulness of legal advice, and the accuracy of legal knowl- edge as mentioned in Section 5.1.\nLawLuo's responses maintain a high score as the num- ber of dialogue turns increases. This result is primarily at- tributed to our use of multi-turn dialogue data, enhanced by ChatGPT and sourced from actual law firms, for instruction fine-tuning, as opposed to other legal LLMs that only use single-turn dialogue data."}, {"title": "5.3 Ablation Study", "content": "This section aims to validate the contributions of each com- ponent within the framework. We continue to use GPT-4o as the evaluator to assess the win rate of LawLuo over Chat- GPT after ablation. From the fig- ure, it is evident that the win rate of LawLuo over Chat- GPT decreases by 3% after ablating the receptionist agent and role enhancement. This result validates our hypothe- sis that legal LLMs should be assigned different domain- specific roles to provide more targeted answers based on the user's consultation field. Additionally, the figure shows that the boss agent also contributes to LawLuo's performance, as it can optimize the responses generated by the lawyer. Fi- nally, we observe a significant decline in model performance after removing the ToLD module. This indicates that clari- fying users' vague and ambiguous queries is crucial for gen- erating high-quality responses in legal question-answering."}, {"title": "5.4 Case Study of TOLD", "content": "This section elucidates the contributions of ToLD through a specific case study. We take the query\u201c\u6211\u8981\u79bb\u5a5a,\u8be5\u600e \u4e48\u529e? (I want a divorce, what should I do?)\" as an exam- ple initiated by a user. The left side of Figure 9 displays the clarifying questions generated by the ToLD algorithm. The results after the user actively marked Yes/No are shown on the right side of Figure 9.\nAdditionally, the first row of Table 2 presents the answer generated by LawLuo without TOLD, while the second row shows the answer generated by LawLuo with ToLD. It can be observed that TOLD assists legal LLMs in generating more accurate and personalized responses."}, {"title": "6. Discussion", "content": "Enlightenment\nThis study has provided us with several intriguing insights. Firstly, we discovered that omitting continue pre-training and directly conducting instruction fine-tuning does not im- pact the effectiveness of the legal LLM. This indicates that the Chinese base model has already acquired a certain de- gree of legal knowledge during the pre-training phase, obvi- ating the need for additional pre-training with legal corpora. In fact, the pre-training corpora used by many Chinese base models are extraordinarily large and likely encompass a sub- stantial amount of legal text. We also found that the instruc- tion fine-tuning phase does not require tens of thousands or even hundreds of thousands of dialogue data; approximately thousands high-quality legal dialogue data are sufficient to elicit the model's legal knowledge application capabilities in dialogue scenarios. This paves a new path for the future fine-tuning of legal LLMs. Lastly, the effectiveness of role enhancement and multi-agent collaboration in our method validated our hypothesis that a legal consultation should not be a mere conversational process but a complex task involv- ing multiple business processes."}, {"title": "Limitation and Future Work", "content": "Although we observed that the receptionist agent achieved a question classification accuracy rate exceeding 98% in our experiments, any misclassification leads to the lawyer agent continuing the interaction based on the initial error (a matri- monial lawyer could handle legal inquiries related to traffic accidents, albeit with reduced effectiveness). In the future, we plan to design a dynamic receptionist mechanism that reallocates the user to the appropriate lawyer based on con- versation content whenever a domain mismatch is detected during the interaction with the legal LLM.\nDespite introducing the concept of multi-agent collabora- tion, not every agent is an LLM, resulting in limited thinking and decision-making capabilities. In the future, we intend to develop a collaborative framework in which all agents are LLMs, thereby enhancing the overall framework's cognitive and decision-making abilities."}, {"title": "Conclusion", "content": "We propose a multi-agent collaboration framework for le- gal dialogue, termed LawLuo. Experimental results demon- strate that LawLuo outperforms baseline LLMs in three di- mensions: lawyer-like language style, the usefulness of le- gal advice, and the accuracy of legal knowledge. Moreover, it continues to produce high-quality answer even after mul- tiple rounds of dialogue. We contribute two high-quality datasets for legal LLM instruction fine-tuning, KINLED and MURLED. Experimental results indicate that using these datasets can fine-tune more effective legal LLMs."}]}