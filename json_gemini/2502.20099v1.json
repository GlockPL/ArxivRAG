{"title": "Sanity Checking Causal Representation Learning on a Simple Real-World System", "authors": ["Juan L. Gamella", "Simon Bing", "Jakob Runge"], "abstract": "We evaluate methods for causal representation learning (CRL) on a simple, real-world system where these methods are expected to work. The system consists of a controlled optical experiment specifically built for this purpose, which satisfies the core assumptions of CRL and where the underlying causal factors-the inputs to the experiment are known, providing a ground truth. We select methods representative of different approaches to CRL and find that they all fail to recover the underlying causal factors. To understand the failure modes of the evaluated algorithms, we perform an ablation on the data by substituting the real data-generating process with a simpler synthetic equivalent. The results reveal a reproducibility problem, as most methods already fail on this synthetic ablation despite its simple data-generating process. Additionally, we observe that common assumptions on the mixing function are crucial for the performance of some of the methods but do not hold in the real data. Our efforts highlight the contrast between the theoretical promise of the state of the art and the challenges in its application. We hope the benchmark serves as a simple, real-world sanity check to further develop and validate methodology, bridging the gap towards CRL methods that work in practice. We make all code and datasets publicly available at github.com/simonbing/CRLSanityCheck.", "sections": [{"title": "1. Introduction", "content": "Uncovering the underlying factors that determine the behavior of a system is a problem with a long history, both in theoretical treatise (Comon, 1994; Hyv\u00e4rinen & Pajunen, 1999; Bengio et al., 2013; LeCun et al., 2015; Lake et al., 2017), as well as practical applications (Johansson et al., 2022; Tibau et al., 2022; Lopez et al., 2023). Causal representation learning is among the newest approaches in this line of work, and its enticing promise lies in recovering the causal latent ground-truth model from high-level observations of a system. While this problem is provably hard (Locatello et al., 2019), there has been a considerable effort to advance the understanding of the theoretical constraints within which causal representation learning may be successfully applied (Hyv\u00e4rinen & Morioka, 2016; Khemakhem et al., 2020; Gresele et al., 2021; Brehmer et al., 2022; Ahuja et al., 2023; Zhang et al., 2023; Lippe et al., 2022; 2023a;b; Lachapelle et al., 2023; Var\u0131c\u0131 et al., 2023; Saengkyongam et al., 2024; von K\u00fcgelgen et al., 2024; Yao et al., 2024b). Applying established causal inference methods to unstructured, high-dimensional data, addressing the inherent limitations of machine learning methods in out-of-distribution scenarios, or learning mechanistic models of the world are among the multitude of promises that drive research in the field of causal representation learning (Sch\u00f6lkopf et al., 2021).\nA challenge that obfuscates the progress towards these goals is the lack of meaningful real-world benchmarks, to evaluate methods and identify theoretical approaches that hold potential for application. By and large, new methods are evaluated on synthetic datasets generated according to their own underlying assumptions (Brehmer et al., 2022; Ahuja et al., 2023; Lippe et al., 2022; 2023a;b; Squires et al., 2023; Lachapelle et al., 2023; 2024; Liang et al., 2023; Buchholz et al., 2023; Var\u0131c\u0131 et al., 2023; Bing et al., 2024; von K\u00fcgelgen et al., 2021; von K\u00fcgelgen et al., 2024; Yao et al., 2024c; Xu et al., 2024). This practice provides further validation for the theoretical foundations of these methods but yields limited insight into their applicability to real-world problems. More sophisticated synthetic benchmarks have been proposed (Lippe et al., 2022; 2023a; Ahmed et al., 2021; von K\u00fcgelgen et al., 2021; Liu et al., 2023), e.g., using visualizations of computer games or renderings of three-dimensional scenes. Because these do not cater to the assumptions of any particular method, they are extremely valuable for the standardized evaluation of CRL methods."}, {"title": "2. Experimental Setup", "content": "Our physical system is a light tunnel like the one introduced by Gamella et al. (2025). We provide a schematic of its main components and relevant variables in Figure 1. The tunnel is an elongated chamber with a controllable light source at one end, two linear polarizers mounted on rotating frames, a camera, and sensors to measure different physical quantities. As control inputs, the system takes the brightness level of the red, green, and blue LEDs of the light source (R, G, B) and the polarizer positions ($\\theta_1$, $\\theta_2$). Its outputs are the images captured by the camera (Figure 2) and readings of the infrared (I1, I2, I3) and visible (V1, V2, V3) light intensity at different positions, the electrical current drawn by the light source (C), and additional noisy measurements of the polarizer angles ($\\tilde{\\theta_1}$,$\\tilde{\\theta_2}$). A detailed description of all the variables can be found in Gamella et al. (2025, Appendix\nII).\nAs a data-generating process, the light tunnel satisfies the core assumptions of causal representation learning. In particular, it transforms some underlying causal factors-the control inputs-into observations consisting of images and numeric sensor measurements. Because we control the inputs to the system, we can sample them from any distribution or causal structure, as we do in the experiments of Section 3. However, this means that the underlying causal structure is synthetic, and the real-world applicability of the corresponding assumptions cannot be evaluated. Therefore, using the current setup we can only test the assumptions corresponding to the mixing function, but not those placed on the latent causal model generating the data.\nA real-world mixing function The light tunnel provides an ideal testbed to evaluate assumptions concerning the mixing function that transforms the ground-truth causal factors into observations. In the tunnel, the process that produces the images is far simpler than those in common synthetic benchmarks, which arise, for example, from visualizations of computer games (Lippe et al., 2022; 2023a) or renderings of a physical simulator (Ahmed et al., 2021; von K\u00fcgelgen et al., 2021). Evidence of this simplicity is that the process"}, {"title": "3. Results", "content": "We apply our sanity check to methods representative of three different families of approaches: contrastive CRL (Section 3.1), multiview CRL (Section 3.2), and CRL from temporal intervened sequences (Section 3.3). As a result, the methods differ greatly in their setup and assumptions on the latent causal structure, as well as in their goals and the metrics to evaluate them. This makes a direct comparison between them difficult, and we instead perform our analysis method-by-method, introducing the necessary background together with the results.\nIn our efforts, we encounter a first challenge in the application of causal representation learning methods to real-world problems: a recurrent lack of public, well-documented, and tested code. As a result, our choice of methods is biased towards those with public code, or for which the authors provided code upon request.\nWe find that pre-processing steps and implementation decisions such as network architectures and training procedures-have a drastic effect on the performance of some of the methods. This also highlights a potential difficulty in re-implementing CRL methods to reproduce their results. To minimize potential points of failure, we used the original implementations as much as possible. We thank the authors of the selected methods for their assistance, which was instrumental in getting them to run for this benchmark. To further ensure that a bug in our pipeline does not distort our results, we ran preliminary tests on synthetic datasets replicating the settings used in the respective original works (Buchholz et al., 2023; Yao et al., 2024c; Lippe et al., 2022). Our experimental pipeline for each method is described in detail in Appendix A."}, {"title": "3.1. Contrastive CRL", "content": "The most prevalent class of CRL methods are those that assume access to data from different environments, stemming from interventions (or counterfactual observations) on some of the underlying causal factors (Brehmer et al., 2022; Ahuja et al., 2023; Zhang et al., 2023; Squires et al., 2023; Buchholz et al., 2023; Var\u0131c\u0131 et al., 2023; Liang et al., 2023; Bing et al., 2024; von K\u00fcgelgen et al., 2024). We choose the method of Buchholz et al. (2023) as a representative of this family of models. In the remainder of the text, we will refer to it as Contrastive CRL (CCRL).\nBackground. As an underlying causal model, CCRL assumes a linear structural causal model (SCM) with additive Gaussian noise (Buchholz et al., 2023, Assumption 2). The underlying causal factors are transformed into observations through a nonlinear and deterministic mixing function (Buchholz et al., 2023, Assumption 1); while in theory their results can be extended to stochastic mixing functions with additive noise, both their experiments and implementation assume a deterministic mixing function. Provided with data from environments that correspond to a single-node intervention on each causal variable, the goal of the method is to recover the ground-truth causal factors and the graph encoding the causal structure between them (Buchholz et al., 2023, Theorem 1).\nData generation. In line with the assumptions made by the method, we sample the values for the ground-truth factors the tunnel inputs R, G, B, $\\theta_1$ and $\\theta_2$-from a linear SCM with additive Gaussian noise; the corresponding ground-truth graph is shown in Figure 3. To generate the interventional data, we perform interventions that shift the mean of their target, closely following the assumptions described in Buchholz et al. (2023, Assumption 3). We collect 10K observations per environment, constituting a total of 60K images provided as input to the method. A detailed exposition of the data-generating process is available in Appendix A.1.1.\nResults. In Figure 3, we provide a summary of the results of applying CCRL to the real images and to the synthetic images (e.g., Figure 2F) produced by the deterministic simulator of the light tunnel described in Section 2 and Appendix C. We report the same metrics used in the original experiments of the method: the commonly used mean correlation coefficient (MCC, Hyv\u00e4rinen & Morioka, 2016; Khemakhem et al., 2020), which is a measure of how well the method recovers the latent factors, and the structural Hamming distance (SHD, Tsamardinos et al., 2006) that measures the recovery of the latent causal graph.\nThe method obtains fairly good metrics on the data from the deterministic simulator, indicating that this is a setting"}, {"title": "3.2. Multiview CRL", "content": "The multiview approach to CRL (Gresele* et al., 2019; Locatello et al., 2020; von K\u00fcgelgen et al., 2021; Daunhawer et al., 2023; Ahuja et al., 2024; Xu et al., 2024; Yao et al., 2024c) relies on having different sets of observations, or views, that arise from mixtures of different subsets of the underlying causal factors. We choose the method introduced by Yao et al. (2024c) as a representative of this family of approaches.\nBackground. As opposed to CCRL, the method from Yao et al. (2024c) places more flexible assumptions on the distribution of the underlying causal factors, where any smooth, continuous distribution with a positive density almost everywhere is allowed (Yao et al., 2024c, Assumption 2.1). The underlying factors are transformed into observations via multiple diffeomorphic mixing functions that share (subsets of) these factors as their inputs, resulting in multiple views on the underlying causal model. For our testbed, we group the images and sensor measurements produced by"}, {"title": "3.3. CRL from temporal intervened sequences", "content": "As a third group of CRL approaches, we consider methods that exploit the causal temporal structure of a process evolving in time (Yao et al., 2021; 2022; Lippe et al., 2022; 2023a;b; Lachapelle et al., 2024). To represent this group of methods, we select CITRIS (Lippe et al., 2022), for which well-documented code is publicly available.\nBackground. CITRIS assumes that the underlying causal factors follow a first-order Markov, stationary dynamic Bayesian network (DBN, Dean & Kanazawa, 1989; Murphy, 2002) without instantaneous causal effects (Lippe et al., 2022, Section 2). Furthermore, the method assumes to have access to information about which underlying causal factor has undergone an intervention at each time step (Lippe et al., 2022, Section 3.1). In contrast to most other methods, CITRIS allows for multidimensional causal ground-truth variables. It explicitly models observations as variables with noise in its theoretical assumptions (Lippe et al., 2022, Section 3.1).\nData generation. We generate the ground-truth causal factors by sampling from the temporal causal process described in Appendix A.3.1. As in the experiments of the original paper (Lippe et al., 2022, Appendix C.2), at each time step we randomly intervene on one of the factors (also including the possibility of intervening on none), and record the vector of the intervention targets at each time step. The original paper uses an additional loss metric (the \"triplet\" loss, Lippe et al., 2022, Section 6.1) for model selection during training, which requires access to the ground-truth factors and requires the collection of an additional dedicated dataset. Since collecting data on a physical system is costly, and assuming access to the ground-truth factors during training is unrealistic, we forego the use of this metric. We use the CITRIS-VAE variant of this method (Lippe et al., 2022, Section 4.1) for all experiments.\nAs in the original paper (Lippe et al., 2022, Section 6.1), we generate an additional dataset from independently sampled underlying factors to calculate the final metrics: the $R^2$ (Wright, 1921) and Spearman's rank correlation coefficients (Spearman, 1904), which show how well the model can predict the ground-truth factors from the latents learned during training. Please see Appendix A.3.3 for details on these metrics.\nResults. We present the results for the $R^2$ score in Figure 6; the results for the Spearman's rank coefficient are provided in Appendix A.3.4. Both metrics-employed in the original paper-produce a correlation matrix between the learned latents and the ground-truth factors. An optimal model displays values close to one on the diagonal and zeros everywhere else (see Appendix A.3.3 for details).\nThe results indicate that CITRIS fails catastrophically in recovering the ground-truth factors, both from the real data and the ablation with synthetic images and measurements. The metrics along the diagonal display a low score, while the off-diagonal values are relatively higher. This suggests that the model does not learn an encoding that separates the ground-truth causal factors nor a correct mapping between latents and causal factors.\nCITRIS is a complex method with many sub-modules that interact during training. We hypothesize that a failure in one of these modules, such as the encoder struggling to extract information about one of the latents, can compound and drive down the method's performance. Although CITRIS and its variants have shown favorable performance on several visually complex synthetic datasets (Lippe et al., 2022; 2023a;b), the exact reason for the failure in this setting remains elusive. Further analysis to pinpoint where things go wrong would require an in-depth study and additional ablations on the underlying data-generating process, e.g., by considering a simpler benchmark with only R, G, and B as ground-truth factors. We believe this to be beyond the scope of this work."}, {"title": "4. Discussion", "content": "We have constructed a testbed for causal representation learning using a real and tightly controlled physical system built around a well-understood optical experiment. The data-generating process of this system satisfies the core assumptions of causal representation learning, and the straightforward mixing process is described by simple physical principles. Furthermore, we have access to ground-truth labels of the underlying causal factors. Therefore, the testbed serves as a sanity check where a CRL method that is expected to work on a variety of real-world scenarios should also succeed. A failure on this testbed indicates a potential failure on other, more complex real-world systems. However, the opposite does not hold, as success on this simple and controlled testbed is not guaranteed to carry over to more complex scenarios.\nAs a first application of our testbed, we evaluated three methods representative of different approaches to causal representation learning: contrastive CRL, multiview CRL, and CRL from temporal intervened sequences. Due to the different setups, assumptions, and goals of each method, we performed our analysis on a method-by-method basis. However, some general patterns emerge. First, all methods failed to attain their goals in recovering-up to their corresponding theoretical constraints-the ground-truth causal factors. Except for a single sub-result of the multiview method, the failure is catastrophic, and the output of the methods has a very weak or no association with the ground-truth causal factors. To better understand the reasons for this failure,"}, {"title": "4.1. Outlook", "content": "Although we advocate for the use of real-world data, we believe that synthetic data is crucial for the development and validation of new methods. However, there is an inherent conflict of interest if the validation of a new method is limited to synthetic data produced by its authors. Method-agnostic benchmarks have been catalysts of progress in various other fields (LeCun et al., 1998; Deng et al., 2009; Rajpurkar et al., 2016; Runge et al., 2019; Lin et al., 2022), especially if they include or resemble data that we may find in the real world. Thus, we applaud existing efforts in this regard, including the synthetic benchmarks mentioned throughout the manuscript (Lippe et al., 2022; 2023a; Ahmed et al., 2021; von K\u00fcgelgen et al., 2021; Liu et al., 2023).\nWhile the community acknowledges that applications of CRL to real-world problems are lacking, the response has largely been to push the theoretical frontier and relax the assumptions needed to establish identifiability results. We argue that, in many regards, the theory in the field is already quite advanced and is, therefore, not the only bottleneck. It is equally important to make a real effort to implement and apply the existing theory in a robust, reproducible, and efficient manner. Without pursuing the engineering endeavor to develop actionable algorithms from the existing theory, we cannot hope to know where the true obstacles to application lie.\nUnless we abandon the ultimate goal of applying causal representation learning to real-world problems, we cannot be satisfied with validating our methods on purely synthetic data. Our goal with this physical testbed is to provide researchers in the field with a stepping stone toward more complex real-world scenarios, with the hope of breaking down this hard problem into manageable steps.\nThe datasets we provide constitute a small fraction of all experiments possible with the light tunnel, which offers additional control inputs not described here that can be used to construct more complex tasks. We are open to suggestions for additional experiments that may prove useful-please reach out to the corresponding authors."}, {"title": "A. Experimental Details", "content": "In this section we provide details on all data generation procedures, hyperparameters, training procedures, and minor adjustments made to the original implementations required to reproduce the results of this work. Our general approach was to use each method's existing code as out-of-the-box as possible, and almost all hyperparameters and settings are the same as reported in the original papers. However, slight modifications were inevitable in making the code run for our data, and we thank the authors of the methods for their guidance. All implementations use the PyTorch machine learning library (Paszke et al., 2019). The data used in this work is available through the 1t_crl_benchmark_v1 dataset at github.com/juangamella/causal-chamber and the code, including all implementations of the considered methods, is available at https://github.com/simonbing/CRLSanityCheck.\nComputational resources and compute time. All experiments were run on a high-performance cluster with NVIDIA A100 GPUs. The total compute time required to reproduce all experiments in this work is approximately 100 GPU hours."}, {"title": "A.1. Contrastive CRL", "content": "A.1.1. DATA GENERATION\nWe define a linear SCM with additive Gaussian noise between the variables (R, G, B, $\\theta_1$, $\\theta_2$) with causal relations encoded by the graph shown in Figure 7. The independent Gaussian noise variables all have zero mean and a variance sampled from $U([0.01, 0.02])$. To generate interventional data, we consider interventions that shift the mean of their target by adding a factor $\\eta$. We sample the value of the shift $\\eta$ from $U([1, 2])$ for all interventions. Each variable is intervened upon individually and we collect $n = 10000$ samples from each intervention, as well as the observational distribution. The full dataset is then split into train, validation, and test subsets according to the ratios (80/10/10) while ensuring that each subset contains the same fraction of samples from each environment.\nA.1.2. TRAINING DETAILS\nFor our experiments with the CCRL method, we rely on the code kindly provided by the authors of the original work. As the original implementation only included a shallow convolutional encoder for images, we found it useful to extend the image encoder to a slightly deeper architecture, which we report in Table 1. Otherwise, we use the exact same architecture and implementation as in the original paper. We report the hyperparameters used during training in Table 2.\nOur initial experiments revealed it was crucial that the noise terms of the underlying SCM have mean zero. Attempts with a non-zero mean led to the failure of the method.\n\u0391.1.3. \u039c\u0395TRICS\nMean Correlation Coefficient. The Mean Correlation Coeefficent (MCC, Hyv\u00e4rinen & Morioka, 2016; Khemakhem et al., 2020) measures the pairwise correlation between the learned representation and the ground truth latents. If $C \\in \\mathbb{R}^{d \\times d}$ is the Pearson correlation matrix between the ground truth variables and the learned embeddings and $S_d$ denotes the set of d-permutations, the MCC score is formally defined as\n$MCC:= \\max_{\\pi \\in S_d} \\frac{1}{d} \\sum_{j=1}^{d} |C_{j,\\pi(j)}|.$"}, {"title": "A.2. Multiview CRL", "content": "A.2.1. DATA GENERATION\nThe underlying causal model used in our experiments for the Multiview CRL method is identical to the one used for the Contrastive CRL method described in Appendix A.1.1. In addition to first view given by the images ($\\mathbb{I}m$)-which depend on (R, G, B, $\\theta_1$, $\\theta_2$) - we consider three additional views. The second view consists of the electrical current drawn by the light source and the infrared and visible light intensities from sensors one and two, i.e., ($\\tilde{C}$, $I_1$, $V_1$, $I_2$, $V_2$). These depend on the underlying causal factors (R, G, B). The third and fourth views consist of the angle measurements of the first ($\\tilde{\\theta_1}$) polarizer and second polarizers, respectively. In turn, they depend on the corresponding polarizer angles ($\\theta_1$) and ($\\theta_2$). A graphical overview of the data-generating process is shown in Figure 8. These views consist of either real images and sensor measurements collected from the tunnel, or their synthetic and deterministic counterparts produced by the simulator given in Appendix C. To increase the overall sample size, we include observational samples, as well as all interventional samples described in Appendix A.1.1, arriving at a dataset with $n = 60000$ samples. The data is randomly split into train, validation, and test sets according to a 80/10/10 ratio.\nA.2.2. TRAINING DETAILS\nWe use the publicly available implementation of the Multiview CRL method from https://github.com/CausalLearningAI/multiview-crl. For our experiments, we use the variant of this implementation that relies on BarlowTwins (Zbontar et al., 2021), in accordance with the experiments that use image data in the original paper. The hyperparameter settings used in our experiments are reported in Table 3. The number of training steps is chosen to obtain approximately the same number of epochs given our chosen batch size as the original paper uses for their image data experiments.\n\u0391.2.3. \u039c\u0395TRICS\nThe theory of the Multiview CRL method states that the model achieves block-identifiability (Yao et al., 2024c, Definition 2.3), meaning that the information of the ground-truth variables belonging to the content block of a set of views is perfectly"}, {"title": "A.3. CITRIS", "content": "A.3.1. DATA GENERATION\nWe generate the data for the CITRIS experiments by defining a time-evolving process given by the following time-series graph and assignments:\n$G^{t+1} \\leftarrow f \\left( G^{t} + \\epsilon_{G} \\right)$\n$B^{t+1} \\leftarrow f \\left( B^{t} + \\frac{G^{t} - R^{t}}{4} + \\epsilon_{B} \\right)$\n$ \\theta^{t+1}_{1} \\leftarrow g \\left( \\theta^{t} + \\epsilon_{1} \\right)$\n$ \\theta^{t+1}_{2} \\leftarrow g \\left( S \\left(R^{t}, B^{t} \\right) \\frac{\\left(\\theta^{t}_{1} - \\theta^{t}_{2}\\right)}{4} + \\epsilon_{2} \\right)$\nwhere the random innovations are sampled as $\\epsilon_{R}, \\epsilon_{G}, \\epsilon_{B} \\stackrel{i.i.d}{\\sim} Unif[-50, 50]$, $\\epsilon_{1} \\stackrel{i.i.d}{\\sim} Unif[-10, 10]$, and $\\epsilon_{2} \\stackrel{i.i.d}{\\sim} Unif[-5,5]$. Furthermore, the functions S, f and g are defined as\n$S(R^{t}, B^{t}) := \\begin{cases} 1 & \\text{if } B^{t} > R^{t} \\\\ -1 & \\text{if } B^{t} < R^{t} \\end{cases}$, $f(x) := \\begin{cases} -x & \\text{if } x < 0 \\\\ 510 - x & \\text{if } x \\ge 255 \\end{cases}$, and $g(x) := \\begin{cases} -180 - x & \\text{if } x < -90 \\\\ 180 - x & \\text{if } x \\ge 90 \\end{cases}$\nThe purpose of f and g is to ensure that the values of $R^{t}, G^{t}, B^{t}, \\theta^{t}_{1}, \\theta^{t}_{0}$ remain within the bounds of the control inputs for the light tunnel ([0, 255] for R, G, B and [-90, 90] for $\\theta_1$, $\\theta_2$).\nIntuitively, the process can be understood as follows: the variables R and $\\theta_1$ follow random walks. $G^{t+1}$ tries to approach $R^{t}$ in each step, and $B^{t+1}$ approaches $G^{t}$ in the same fashion. However, the innovations $\\epsilon_{R}, \\epsilon_{G}$, and $\\epsilon_{B}$ prevent these variables from converging to their targets. Finally, $\\theta_2$ tries to exploit the color-shifting effect of the polarizers to maximize the ratio of the blue to red pixels in the resulting images. It does so by approaching $\\theta_1$-aligning the polarizer axes-if $B^{t} > R^{t}$, and receding if $R^{t} > B^{t}$. The behavior is regulated by the function $S(\\cdot)$ above. At each time step, we perform no intervention with probability 0.3, or we select an intervention target at random from {$\\theta_{1}, G^{t}, B^{t}, \\theta^{t}_{1}, \\theta^{t}_{0}$}, setting it to a value sampled uniformly at random from its valid range. We encode the intervention target at each time step in a one-hot vector, with a vector of zeroes indicating that no variable is intervened upon. A Python implementation of the process is provided in github.com/juangamella/causal-chamber/blob/main/datasets/lt_crl_ benchmark_v1/generators/citris_1.py.\nWe collect a sequence of n = 100000 samples from this process and use the first $n_{train}$ = 80000 samples as the training dataset and the following $n_{val}$ = 10000 and $n_{test}$ = 10000 as validation and test datasets. Following the experiments in the original paper, to evaluate the final metrics we collect an additional dataset with n = 1000 samples, where the latent variables are sampled uniformly at random from their valid range."}]}