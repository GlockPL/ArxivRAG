{"title": "Sanity Checking Causal Representation Learning on a Simple Real-World System", "authors": ["Juan L. Gamella", "Simon Bing", "Jakob Runge"], "abstract": "We evaluate methods for causal representation learning (CRL) on a simple, real-world system where these methods are expected to work. The system consists of a controlled optical experiment specifically built for this purpose, which satisfies the core assumptions of CRL and where the underlying causal factors-the inputs to the experiment-are known, providing a ground truth. We select methods representative of different approaches to CRL and find that they all fail to recover the underlying causal factors. To understand the failure modes of the evaluated algorithms, we perform an ablation on the data by substituting the real data-generating process with a simpler synthetic equivalent. The results reveal a reproducibility problem, as most methods already fail on this synthetic ablation despite its simple data-generating process. Additionally, we observe that common assumptions on the mixing function are crucial for the performance of some of the methods but do not hold in the real data. Our efforts highlight the contrast between the theoretical promise of the state of the art and the challenges in its application. We hope the benchmark serves as a simple, real-world sanity check to further develop and validate methodology, bridging the gap towards CRL methods that work in practice. We make all code and datasets publicly available at github.com/simonbing/CRLSanityCheck.", "sections": [{"title": "1. Introduction", "content": "Uncovering the underlying factors that determine the behavior of a system is a problem with a long history, both in theoretical treatise (Comon, 1994; Hyv\u00e4rinen & Pajunen, 1999; Bengio et al., 2013; LeCun et al., 2015; Lake et al., 2017), as well as practical applications (Johansson et al., 2022; Tibau et al., 2022; Lopez et al., 2023). Causal representation learning is among the newest approaches in this line of work, and its enticing promise lies in recovering the causal latent ground-truth model from high-level observations of a system. While this problem is provably hard (Locatello et al., 2019), there has been a considerable effort to advance the understanding of the theoretical constraints within which causal representation learning may be successfully applied (Hyv\u00e4rinen & Morioka, 2016; Khemakhem et al., 2020; Gresele et al., 2021; Brehmer et al., 2022; Ahuja et al., 2023; Zhang et al., 2023; Lippe et al., 2022; 2023a;b; Lachapelle et al., 2023; Var\u0131c\u0131 et al., 2023; Saengkyongam et al., 2024; von K\u00fcgelgen et al., 2024; Yao et al., 2024b). Applying established causal inference methods to unstructured, high-dimensional data, addressing the inherent limitations of machine learning methods in out-of-distribution scenarios, or learning mechanistic models of the world are among the multitude of promises that drive research in the field of causal representation learning (Sch\u00f6lkopf et al., 2021).\nA challenge that obfuscates the progress towards these goals is the lack of meaningful real-world benchmarks, to evaluate methods and identify theoretical approaches that hold potential for application. By and large, new methods are evaluated on synthetic datasets generated according to their own underlying assumptions (Brehmer et al., 2022; Ahuja et al., 2023; Lippe et al., 2022; 2023a;b; Squires et al., 2023; Lachapelle et al., 2023; 2024; Liang et al., 2023; Buchholz et al., 2023; Var\u0131c\u0131 et al., 2023; Bing et al., 2024; von K\u00fcgelgen et al., 2021; von K\u00fcgelgen et al., 2024; Yao et al., 2024c; Xu et al., 2024). This practice provides further validation for the theoretical foundations of these methods but yields limited insight into their applicability to real-world problems. More sophisticated synthetic benchmarks have been proposed (Lippe et al., 2022; 2023a; Ahmed et al., 2021; von K\u00fcgelgen et al., 2021; Liu et al., 2023), e.g., using visualizations of computer games or renderings of three-dimensional scenes. Because these do not cater to the assumptions of any particular method, they are extremely valuable for the standardized evaluation of CRL methods."}, {"title": "2. Experimental Setup", "content": "Our physical system is a light tunnel like the one introduced by Gamella et al. (2025). We provide a schematic of its main components and relevant variables in Figure 1. The tunnel is an elongated chamber with a controllable light source at one end, two linear polarizers mounted on rotating frames, a camera, and sensors to measure different physical quantities. As control inputs, the system takes the brightness level of the red, green, and blue LEDs of the light source (R, G, B) and the polarizer positions ($\\theta_1$, $\\theta_2$). Its outputs are the images captured by the camera (Figure 2) and readings of the infrared ($I_1, I_2, I_3$) and visible ($V_1, V_2, V_3$) light intensity at different positions, the electrical current drawn by the light source (C), and additional noisy measurements of the polarizer angles ($\\tilde{\\theta_1}$, $\\tilde{\\theta_2}$). A detailed description of all the variables can be found in Gamella et al. (2025, Appendix II).\nAs a data-generating process, the light tunnel satisfies the core assumptions of causal representation learning. In particular, it transforms some underlying causal factors-the control inputs-into observations consisting of images and numeric sensor measurements. Because we control the inputs to the system, we can sample them from any distribution or causal structure, as we do in the experiments of Section 3. However, this means that the underlying causal structure is synthetic, and the real-world applicability of the corresponding assumptions cannot be evaluated. Therefore, using the current setup we can only test the assumptions corresponding to the mixing function, but not those placed on the latent causal model generating the data.\nA real-world mixing function The light tunnel provides an ideal testbed to evaluate assumptions concerning the mixing function that transforms the ground-truth causal factors into observations. In the tunnel, the process that produces the images is far simpler than those in common synthetic benchmarks, which arise, for example, from visualizations of computer games (Lippe et al., 2022; 2023a) or renderings of a physical simulator (Ahmed et al., 2021; von K\u00fcgelgen et al., 2021). Evidence of this simplicity is that the process"}, {"title": "3. Results", "content": "We apply our sanity check to methods representative of three different families of approaches: contrastive CRL (Section 3.1), multiview CRL (Section 3.2), and CRL from temporal intervened sequences (Section 3.3). As a result, the methods differ greatly in their setup and assumptions on the latent causal structure, as well as in their goals and the metrics to evaluate them. This makes a direct comparison between them difficult, and we instead perform our analysis method-by-method, introducing the necessary background together with the results.\nIn our efforts, we encounter a first challenge in the application of causal representation learning methods to real-world problems: a recurrent lack of public, well-documented, and tested code. As a result, our choice of methods is biased towards those with public code, or for which the authors provided code upon request.\nWe find that pre-processing steps and implementation decisions such as network architectures and training procedures-have a drastic effect on the performance of some of the methods. This also highlights a potential difficulty in re-implementing CRL methods to reproduce their results. To minimize potential points of failure, we used the original implementations as much as possible. We thank the authors of the selected methods for their assistance, which was instrumental in getting them to run for this benchmark. To further ensure that a bug in our pipeline does not distort our results, we ran preliminary tests on synthetic datasets replicating the settings used in the respective original works (Buchholz et al., 2023; Yao et al., 2024c; Lippe et al., 2022). Our experimental pipeline for each method is described in detail in Appendix A."}, {"title": "3.1. Contrastive CRL", "content": "The most prevalent class of CRL methods are those that assume access to data from different environments, stemming from interventions (or counterfactual observations) on some of the underlying causal factors (Brehmer et al., 2022; Ahuja et al., 2023; Zhang et al., 2023; Squires et al., 2023; Buchholz et al., 2023; Var\u0131c\u0131 et al., 2023; Liang et al., 2023; Bing et al., 2024; von K\u00fcgelgen et al., 2024). We choose the method of Buchholz et al. (2023) as a representative of this family of models. In the remainder of the text, we will refer to it as Contrastive CRL (CCRL).\nBackground. As an underlying causal model, CCRL assumes a linear structural causal model (SCM) with additive Gaussian noise (Buchholz et al., 2023, Assumption 2). The underlying causal factors are transformed into observations through a nonlinear and deterministic mixing function (Buchholz et al., 2023, Assumption 1); while in theory their results can be extended to stochastic mixing functions with additive noise, both their experiments and implementation assume a deterministic mixing function. Provided with data from environments that correspond to a single-node intervention on each causal variable, the goal of the method is to recover the ground-truth causal factors and the graph encoding the causal structure between them (Buchholz et al., 2023, Theorem 1).\nData generation. In line with the assumptions made by the method, we sample the values for the ground-truth factors the tunnel inputs R, G, B, $\\theta_1$ and $\\theta_2$-from a linear SCM with additive Gaussian noise; the corresponding ground-truth graph is shown in Figure 3. To generate the interventional data, we perform interventions that shift the mean of their target, closely following the assumptions described in Buchholz et al. (2023, Assumption 3). We collect 10K observations per environment, constituting a total of 60K images provided as input to the method. A detailed exposition of the data-generating process is available in Appendix A.1.1.\nResults. In Figure 3, we provide a summary of the results of applying CCRL to the real images and to the synthetic images (e.g., Figure 2F) produced by the deterministic simulator of the light tunnel described in Section 2 and Appendix C. We report the same metrics used in the original experiments of the method: the commonly used mean correlation coefficient (MCC, Hyv\u00e4rinen & Morioka, 2016; Khemakhem et al., 2020), which is a measure of how well the method recovers the latent factors, and the structural Hamming distance (SHD, Tsamardinos et al., 2006) that measures the recovery of the latent causal graph.\nThe method obtains fairly good metrics on the data from the deterministic simulator, indicating that this is a setting"}, {"title": "3.2. Multiview CRL", "content": "The multiview approach to CRL (Gresele* et al., 2019; Locatello et al., 2020; von K\u00fcgelgen et al., 2021; Daunhawer et al., 2023; Ahuja et al., 2024; Xu et al., 2024; Yao et al., 2024c) relies on having different sets of observations, or views, that arise from mixtures of different subsets of the underlying causal factors. We choose the method introduced by Yao et al. (2024c) as a representative of this family of approaches.\nBackground. As opposed to CCRL, the method from Yao et al. (2024c) places more flexible assumptions on the distribution of the underlying causal factors, where any smooth, continuous distribution with a positive density almost everywhere is allowed (Yao et al., 2024c, Assumption 2.1). The underlying factors are transformed into observations via multiple diffeomorphic mixing functions that share (subsets of) these factors as their inputs, resulting in multiple views on the underlying causal model. For our testbed, we group the images and sensor measurements produced by"}, {"title": "3.3. CRL from temporal intervened sequences", "content": "As a third group of CRL approaches, we consider methods that exploit the causal temporal structure of a process evolving in time (Yao et al., 2021; 2022; Lippe et al., 2022; 2023a;b; Lachapelle et al., 2024). To represent this group of methods, we select CITRIS (Lippe et al., 2022), for which well-documented code is publicly available.\nBackground. CITRIS assumes that the underlying causal factors follow a first-order Markov, stationary dynamic Bayesian network (DBN, Dean & Kanazawa, 1989; Murphy, 2002) without instantaneous causal effects (Lippe et al., 2022, Section 2). Furthermore, the method assumes to have access to information about which underlying causal factor has undergone an intervention at each time step (Lippe et al., 2022, Section 3.1). In contrast to most other methods, CITRIS allows for multidimensional causal ground-truth variables. It explicitly models observations as variables with noise in its theoretical assumptions (Lippe et al., 2022, Section 3.1).\nData generation. We generate the ground-truth causal factors by sampling from the temporal causal process described in Appendix A.3.1. As in the experiments of the original paper (Lippe et al., 2022, Appendix C.2), at each time step we randomly intervene on one of the factors (also including the possibility of intervening on none), and record the vector of the intervention targets at each time step. The original paper uses an additional loss metric (the \"triplet\" loss, Lippe et al., 2022, Section 6.1) for model selection during training, which requires access to the ground-truth factors and requires the collection of an additional dedicated dataset. Since collecting data on a physical system is costly, and assuming access to the ground-truth factors during training is unrealistic, we forego the use of this metric. We use the CITRIS-VAE variant of this method (Lippe et al., 2022, Section 4.1) for all experiments.\nAs in the original paper (Lippe et al., 2022, Section 6.1), we generate an additional dataset from independently sampled underlying factors to calculate the final metrics: the $R^2$ (Wright, 1921) and Spearman's rank correlation coefficients (Spearman, 1904), which show how well the model can predict the ground-truth factors from the latents learned during training. Please see Appendix A.3.3 for details on these metrics.\nResults. We present the results for the $R^2$ score in Figure 6; the results for the Spearman's rank coefficient are provided in Appendix A.3.4. Both metrics-employed in the original paper-produce a correlation matrix between the learned latents and the ground-truth factors. An optimal model displays values close to one on the diagonal and zeros everywhere else (see Appendix A.3.3 for details)."}, {"title": "4. Discussion", "content": "We have constructed a testbed for causal representation learning using a real and tightly controlled physical system built around a well-understood optical experiment. The data-generating process of this system satisfies the core assumptions of causal representation learning, and the straightforward mixing process is described by simple physical principles. Furthermore, we have access to ground-truth labels of the underlying causal factors. Therefore, the testbed serves as a sanity check where a CRL method that is expected to work on a variety of real-world scenarios should also succeed. A failure on this testbed indicates a potential failure on other, more complex real-world systems. However, the opposite does not hold, as success on this simple and controlled testbed is not guaranteed to carry over to more complex scenarios.\nAs a first application of our testbed, we evaluated three methods representative of different approaches to causal representation learning: contrastive CRL, multiview CRL, and CRL from temporal intervened sequences. Due to the different setups, assumptions, and goals of each method, we performed our analysis on a method-by-method basis. However, some general patterns emerge. First, all methods failed to attain their goals in recovering-up to their corresponding theoretical constraints-the ground-truth causal factors. Except for a single sub-result of the multiview method, the failure is catastrophic, and the output of the methods has a very weak or no association with the ground-truth causal factors. To better understand the reasons for this failure,"}, {"title": "4.1. Outlook", "content": "Although we advocate for the use of real-world data, we believe that synthetic data is crucial for the development and validation of new methods. However, there is an inherent conflict of interest if the validation of a new method is limited to synthetic data produced by its authors. Method-agnostic benchmarks have been catalysts of progress in various other fields (LeCun et al., 1998; Deng et al., 2009; Rajpurkar et al., 2016; Runge et al., 2019; Lin et al., 2022), especially if they include or resemble data that we may find in the real world. Thus, we applaud existing efforts in this regard, including the synthetic benchmarks mentioned throughout the manuscript (Lippe et al., 2022; 2023a; Ahmed et al., 2021; von K\u00fcgelgen et al., 2021; Liu et al., 2023).\nWhile the community acknowledges that applications of CRL to real-world problems are lacking, the response has largely been to push the theoretical frontier and relax the assumptions needed to establish identifiability results. We argue that, in many regards, the theory in the field is already quite advanced and is, therefore, not the only bottleneck. It is equally important to make a real effort to implement and apply the existing theory in a robust, reproducible, and efficient manner. Without pursuing the engineering endeavor to develop actionable algorithms from the existing theory, we cannot hope to know where the true obstacles to application lie.\nUnless we abandon the ultimate goal of applying causal representation learning to real-world problems, we cannot be satisfied with validating our methods on purely synthetic data. Our goal with this physical testbed is to provide researchers in the field with a stepping stone toward more complex real-world scenarios, with the hope of breaking down this hard problem into manageable steps.\nThe datasets we provide constitute a small fraction of all experiments possible with the light tunnel, which offers additional control inputs not described here that can be used to construct more complex tasks. We are open to suggestions for additional experiments that may prove useful-please reach out to the corresponding authors."}]}