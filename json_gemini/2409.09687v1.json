{"title": "Training Safe Neural Networks with Global SDP Bounds", "authors": ["Roman Soletskyi", "David \u201cdavidad\u201d Dalrymple"], "abstract": "This paper presents a novel approach to training neural networks with formal safety guarantees using semidefinite programming (SDP) for verification. Our method focuses on verifying safety over large, high-dimensional input regions, addressing limitations of existing techniques that focus on adversarial robustness bounds. We introduce an ADMM-based training scheme for an accurate neural network classifier on the Adversarial Spheres dataset, achieving provably perfect recall with input dimensions up to d = 40. This work advances the development of reliable neural network verification methods for high-dimensional systems, with potential applications in safe RL policies.", "sections": [{"title": "1 Introduction", "content": "Reinforcement learning (RL) has demonstrated remarkable capabilities in tackling complex control problems, leading to a growing interest in its application to safety-critical domains. Nevertheless, traditional RL algorithms prioritize optimizing performance without incorporating safety constraints, which poses significant risks in environments where unsafe actions can result in severe consequences. Therefore, it is both a challenging and practical problem to develop a neural RL policy along with a formal certificate guaranteeing its safety.\nTo characterize the safety and desired behavior of a system moving in space, one introduces safe and target subsets, respectively. The objective is to produce a policy that always remains within the safe subset, given a proper starting point, and eventually reaches the target subset. One line of work [13],[8] focuses on over-approximating forward reachable sets; if they always lie within the safe region, one can immediately deduce that the system is safe. Another line of research, notably[6], produces a neural Lyapunov function that constrains the dynamics to remain within the attraction region, while [28] generalizes the Lyapunov function to a reach-avoid supermartingale in stochastic systems.\nA major bottleneck of the described approaches is that one typically has to verify that the closed neural system satisfies a property over the entire safe region. For instance, in [6], one"}, {"title": "2 Preliminaries", "content": "As discussed in Section 1, when the input region becomes sufficiently large, empirically, linear-based bounds become too loose compared to SDP-based ones, and verification over the entire region becomes prohibitively costly. The main purpose of this section is to conduct a series of experiments to quantify this effect. We describe the paper's setup, review how SDP bounds are computed, discuss the experiment results, and provide a theoretical explanation."}, {"title": "2.1 Setup", "content": "We are interested in verifying a 2-class neural network classifier $f_\\theta : \\mathbb{R}^d \\rightarrow \\mathbb{R}$ that satisfies a simple provable safety specification. Let $X$ be a convex region; we aim to efficiently verify the bound\n$\\max_{x \\in X} f_\\theta(x) \\leq B$ (2.1)\nFor example, if one class lies entirely within $X$, verifying this condition gives us a classifier that is always correct for the elements of this class, assuming $B$ is taken as the threshold value. To further"}, {"title": "2.2 SDP bound computation", "content": "This subsection introduces SDP bound for 2.1 and we focus on computing it precisely and efficiently in the following subsections. We follow [19] by introducing a quadratically constrained quadratic program (QCQP) and then relaxing it to SDP. The key idea is that computing $z = \\text{relu}(x)$ is equivalent to constraining $z$ with\n$z(z - x) = 0; \\quad z \\geq 0; \\quad z \\geq x$ (2.8)\nWe use $\\odot$ to denote the pointwise multiplication of vectors' entries. Then, instead of computing post-activations 2.4 we can constrain them with\n$x_l \\geq 0$ (2.9)\n$x_l \\geq W_l x_{l-1} + b_l$ (2.10)\n$x_l \\odot (x_l - W_l x_{l-1} - b_l) = 0$ (2.11)\nLet us gather all activations into one vector $v$ and introduce matrix $P$ as\n$v = \\begin{bmatrix} 1 \\\\ x_0 \\\\ x_1 \\\\ \\vdots \\\\ x_L \\end{bmatrix}; \\quad P = vv^\\top = \\begin{bmatrix} 1 & x_0^\\top & x_1^\\top & \\cdots & x_L^\\top \\\\ x_0 & x_0 x_0^\\top & x_0 x_1^\\top & \\cdots & x_0 x_L^\\top \\\\ x_1 & x_1 x_0^\\top & x_1 x_1^\\top & \\cdots & x_1 x_L^\\top \\\\ \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\ x_L & x_L x_0^\\top & x_L x_1^\\top & \\cdots & x_L x_L^\\top \\end{bmatrix}$ (2.12)"}, {"title": "2.3 Gap experiments", "content": "The metric we aim to measure is the gap \u2206 between the true maximum value and the bound, defined as\n$\\Delta = B - \\max_{x \\in X} f_\\theta(x)$ (2.22)\nThe bound $B$ is calculated using SDP, as explained in subsection 2.2 or using \u03b1-CROWN [25], which serves as a representative of linear-based bounds. We chose \u03b1-CROWN because not many verification methods natively support $l_2$-norm input constraint. For instance, Marabou [14], MN-BaB [10], and PyRAT [18] focus exclusively on $l_\\infty$-norm constraints. To nonetheless assess the verification ability of these methods, we generated random neural networks of various sizes and"}, {"title": "2.4 Theoretical explanation", "content": "We adapt Proposition 1 from [19] to our setting and obtain a theoretical upper bound on $B^{\\text{SDP}}$ for a randomly initialized neural network.\nTheorem 2.1. Consider the limit as $d, h \\rightarrow \\infty$ while $d/h$ converges to a constant ratio. Let $f_\\theta$ be a Xavier initialized [12] feedforward neural network with $L$-hidden layers and the structure described in subsection 2.1. Then, for a given $p = 2$ or $p = \\infty$ and $\\epsilon$, the SDP bound over the region $||x||_p \\leq \\epsilon$ almost surely satisfies\n1. If $p=2$, $B^{\\text{SDP}} = O(1+\\epsilon)$\n2. If $p=\\infty$, $B^{\\text{SDP}} = O(\\epsilon \\sqrt{d})$\nWe prove this bound in the limit of very wide neural networks to simplify the proof (Section B.1), as this approach relies on known results about the concentration of norms of random matrices. However, the result should still hold for finite dimensions $(d, h)$ and is practically relevant, as demonstrated - at least qualitatively - by the experiments in the previous section. Furthermore, we prove that linear methods, such as linear programming and \u03b1-CROWN, produce loose bounds even when the network has only one hidden layer.\nTheorem 2.2. Consider the limit $d, h \\rightarrow \\infty$ while $d/h$ converges to a constant ratio. Let $f_\\theta$ be a Xavier initialized, 1-hidden layer feedforward neural network without biases. Then for given $p$, both linear programming and \u03b1-CROWN bounds over the region $||x||_p \\leq \\epsilon$ almost surely satisfy $B^{\\text{LP}} = \\Omega(\\epsilon d)$ and $B^{\\alpha-\\text{CROWN}} = \\Omega(\\epsilon d)$.\nWe expect that for neural networks with $L$-hidden layers, the bounds will be even looser, implying that beyond a certain value of $d$, the SDP bound will always be tighter. These results also explain that in the context of adversarial robustness, when $\\epsilon$ is very small, linear bounds may be sufficiently accurate, and computing the expensive SDP bound may not be necessary. When $d$ is moderately small, the branch-and-bound method may work by partitioning the region into sufficiently small subregions of effective size $\\epsilon' < \\epsilon$, and then applying cheap linear bounds. Unfortunately, as $d$ grows, the number of regions grows exponentially, making this approach intractable."}, {"title": "3 Methods", "content": "In this section we formalize the main task of training a safe network and propose a constrained optimization method to solve it."}, {"title": "3.1 Main task", "content": "We aim to train an accurate neural classifier $f_\\theta$ on the Adversarial Spheres dataset $D_2$, described in section 2.1 with the safety property\n$\\max_{x \\in X} f_\\theta(x) \\leq 0; \\quad X = \\{x : ||x||_2 \\leq 1\\}$ (3.1)\nWe choose 0 as the threshold value for the classifier, where negative values of $f_\\theta(x)$ correspond to the inner class $||x||_2 = 1$, and positive values correspond to the outer class $||x||_2 = R$. If this property is satisfied, the classifier is guaranteed to output the correct answer for any point $x$ from the dataset's inner class. Unfortunately, we cannot enforce similar guarantees for the outer class. Due to the convex nature of the SDP bound, any bound on region $X$ is, in fact, a bound on its convex completion. Therefore, if we try to enforce the condition for the outer class $\\max_{||x||_2=R} f_\\theta(x) \\geq 0$, it will also be enforced on the inner class, forcing the classifier to output zero everywhere.\nAccording to the Adversarial Spheres paper [11], if we simply train the classifier $f_\\theta(x)$ in a supervised manner until it reaches a perfect score, numerous adversarial examples will arise that cause $\\max_{x \\in X} f_\\theta(x)$ to become positive. These examples can be found using a PGD attack, demonstrating that the classifier is provably unsafe. On the other hand, when the classifier does become perfect and safe, we observe that the norms of its weight matrices become so large that any incomplete verifier (including SDP and \u03b1-CROWN) is unable to verify the network, making the verification process hopeless unless we branch on all neurons."}, {"title": "3.2 Constrained optimization problem", "content": "We propose to view task as a constrained optimization problem. Specifically, we aim to minimize the classifier loss $\\mathcal{L}_c(\\theta)$ while satisfying condition 3.1. In its abstract form, this problem can be written as\n$\\min_\\theta \\mathcal{L}_c(\\theta)$ (3.2)\n$\\max_{x \\in X} f_\\theta(x) \\leq B^{\\text{SDP}}(\\theta) \\leq 0$ (3.3)\nFirst, we express this as\n$\\max_X (C, X) = \\min_y \\max_X (C, X) + y^\\top (a - A(X)) = \\min_y \\max_X a^\\top y + (C - A^\\top(y), X) = a^\\top y$ (3.4)\nas long as $A^\\top(y) - C \\geq 0$. Therefore, the dual of the 2.19 problem is\n$B^{\\text{SDP}} = \\min_y a^\\top y + c$ (3.5)\n$A^\\top(y) - C = S \\geq 0$ (3.6)\nWe assume that the problem is not degenerate and that there is no duality gap.\nThe advantage of the dual problem over the primal one is that any valid $(y, S)$ yields an upper bound on $B^{\\text{SDP}} = B^{\\text{SDP}}_*$, and by 3.3, on the maximum of $f_\\theta(x)$ over $X$. Therefore, we can replace the constraint 3.3 by instead bounding the dual value at $y: a^\\top y + c \\leq 0$, and write a new non-convex"}, {"title": "3.3 ADMM scheme", "content": "This scheme is inspired by [23] with the addition of optimization over weights \u03b8 and the constraint 3.8. We begin by writing the augmented Lagrangian, which includes all constraints\n$\\mathcal{L} = \\mathcal{L}_c(\\theta) - \\chi (a^\\top y + c + s) - \\langle X, A^\\top(y) - S - C \\rangle + \\frac{\\rho}{2} ||a^\\top y + c + s||^2 + \\frac{\\mu}{2} ||A^\\top(y) - S - C||^2$ (3.10)\nHere, we introduce the Lagrange multiplier \u03c7 \u2208 R and the slack variable s \u2265 0 for the constraint 3.8, as well as the matrix multiplier X \u2265 0 for the dual constraint 3.9. To perform the ADMM steps, we find the optimal y from the KKT conditions\n$\\nabla_y \\mathcal{L} = - \\chi a - A(X) + a (a^\\top y + c + s)/\\rho + A (A^\\top(y) - S - C)/\\mu = 0$ (3.11)\n$y = (AA^\\top / \\mu + aa^\\top/\\rho)^{-1} [A(S + C)/\\mu + A(X) - a(c + s)/\\rho + a \\chi]$ (3.12)\nThe optimal S is found by noting that the lagrangian $\\mathcal{L}$ is quadratic in S and completing the square\n$\\mathcal{L} = \\frac{1}{2\\mu} ||S||^2 + \\frac{1}{\\mu} \\langle S, C - A^\\top(y) \\rangle + \\langle X, S \\rangle + ... = \\frac{1}{2\\mu} ||S - V||^2 + ...; \\quad V = A^\\top(y) - C - \\mu X$ (3.13)\nSince S \u2265 0, the optimal S is found by diagonalizing V as $V = QAQ^\\top$, where A is a diagonal matrix, and then setting $S = QA^+ Q^\\top$, where A+ is A with only positive entries retained. Similarly, the Lagrangian is quadratic in s, and the optimal value is found by\n$\\mathcal{L} = \\frac{1}{2\\rho} (s^2 + 2s(a^\\top y + c) - 2s \\rho \\chi + ...) = \\frac{1}{2\\rho} (s - v)^2 + ...; \\quad v = \\rho \\chi - (a^\\top y + c)$ (3.14)\nSince s \u2265 0, we set $s = \\max(0, v)$.\nThe entire iteration scheme is as follows\n1. Set $y^{k+1} = (AA^\\top / \\mu + aa^\\top/\\rho)^{-1} [A(S^k + C)/\\mu + A(X^k) - a(c + s^k) /\\rho + a \\chi^k]$.\n2. Compute $V = A^\\top(y^{k+1}) - C - \\mu X^k$, diagonalize it, and set $S^{k+1} = QA^+ Q^\\top$.\n3. Perform the dual update\n$X^{k+1} = X^k - \\frac{A^\\top(y^{k+1}) - S^{k+1} - C}{\\nu \\mu}$ (3.15)\nWe set v = 1.6, as recommended by [23].\n4. If the norm $||A^\\top(y^{k+1}) - C - S^{k+1}|| < \\delta$, where d is the set tolerance, continue to the next step. Otherwise, set $s^{k+1} = s^k$, $X^{k+1} = X^k$, $\\theta^{k+1} = \\theta^k$ and return to step 1."}, {"title": "4 Results", "content": "We trained a suite of neural network with different d and h using the ADMM scheme described in subsection 3.3. All neural networks had L = 2 hidden layers. The largest neural network had 40 input neurons, 240 hidden neurons, and 20k parameters. During the experiments, we found that choosing the right hyperparameters, such as the learning rate \u03b7, dual update rate a, and stopping tolerance d, was very important. To ensure a fair stopping criterion for hyperparameter tuning, we fixed the maximum number of allowed ADMM steps for each d, h. Further experimental details can be found in appendix A.2.\nWe report the best accuracy of a trained safe model that satisfies property 3.1. Additionally, we report the total training time as well as the time needed to verify the network with SDP and \u03b1, \u03b2-CROWN once it is trained. While the ADMM steps are fast, the obtained bound typically lacks precision. Therefore, we always recompute the SDP bound at the end using the CVXPY package [7]. The verification time using CVXPY is reported as $t_{SDP}$. A \"Recall\" column is added to indicate that the network correctly classifies any point from the inner class, thus satisfying the safety property.\nWe also conducted experiments by training neural network in the same fashion on $D_\\infty$ while requiring safety property\n$\\max_{x \\in X} f_\\theta(x) \\leq 0; \\quad X = \\{x : ||x||_\\infty \\leq 1\\}$ (4.1)\nUnfortunately, resulting accuracy quickly drops as we increase d, even when allowing the ADMM algorithm to run much longer than was required for the $D_2$ case."}, {"title": "5 Discussion", "content": "From Table 1, we observe that \u03b1, \u03b2-CROWN times out when verifying any of the trained networks with d > 10, as the verification time grows exponentially with the network's size, as expected. On the other hand, we successfully trained safe neural networks with the SDP bound up to d = 40, with no signs of degrading accuracy, and the total training time grows polynomially.\nWe suspect that in the case of the $l_\\infty$-norm, based on the experimental results of Section 2.3 and the theoretical result 2.1, the SDP bound becomes too imprecise to guide the training effectively. As this gap grows with d, which does not happen in the $l_2$-norm case, the final accuracy of the trained network worsens as d increases, as shown in Table 2.\nThe logical continuation of this research is to search for new global bounds that can be used for neural network training in the $l_\\infty$-norm case and, at the same time, are computationally efficient enough to be applicable. We highlight works that employ ideas from the sum of squares (SOS) hierarchy [1], [4] and Positivstellensatz [20], [17], which naturally extend the SDP framework and provide more accurate bounds. Another direction is to incorporate the SDP bound with a branch-and-bound algorithm. Even though BaB scales poorly with neural network size, for a given network, it may serve as a way to trade off computational complexity with final accuracy by making the SDP bounds tighter and more useful in guiding the network's training.\nFinally, it's important to demonstrate the applicability of this method to safe RL control by extending it to simultaneously train neural policies and neural Lyapunov functions [6] or reach-avoid supermartingales [28], while using SDP bounds to ensure their safety properties."}, {"title": "6 Conclusion", "content": "This work presents a novel approach for training safe neural networks that satisfy verified properties over large regions in high-dimensional spaces using SDP bounds. By leveraging the power of custom ADMM SDP solver, we are able to efficiently train networks that maintain safety guarantees, even as network dimensions increase, in polynomial time. Our experiments demonstrate the effectiveness of this method for the $l_2$-norm safety specifications, successfully training networks up to d = 40 without compromising accuracy or safety. This approach has significant potential for future developments in safe reinforcement learning and safety-critical applications where verified robustness is essential.\nHowever, our results also highlight the challenges of dealing with $l_\\infty$-norm safety specifications, where the SDP bounds become less effective as the input dimension increases, leading to diminished accuracy. This limitation underscores the need for tighter global bounds that can efficiently handle $l_\\infty$-norm cases while remaining computationally feasible, which we aim to explore in future work."}, {"title": "A Experiments details", "content": "A.1 Gap experiments\nTo calculate $B^{\\text{PGD}} \\leq \\max_{x \\in X} f_\\theta(x)$, we randomly sample a batch of points $\\{x_i\\}$ of size b = 256 inside an $l_p$ ball of radius $\\epsilon$ and perform PGD step with respect to empirical maximum as follows\n$x_{t+1} = \\Pi^{\\rho, \\epsilon}_{p} (x_t + \\eta \\nabla_{x_t} \\max_{x_i} f_\\theta(x_i))$ (A.1)\nwhere $\\Pi^{\\rho, \\epsilon}_{p}$ is a projection onto the $l_p$ ball. We continue this process until the empirical maximum $\\max_i f_\\theta(x_i)$ does not increase for 100 steps, within a tolerance of $10^{-4}$. Finally, we set $B^{\\text{PGD}} = \\max_i f_\\theta(x_i)$. For the gradient ascent steps, we use Adam with a learning rate of $\\eta = 0.01$ and standard values $\\beta_1 = 0.9, \\beta_2 = 0.999$.\nFor each experiment, s = 10 neural networks are created with Xavier initialization. The randomly initialized neural networks are left untrained, and bounds are computed for them. The trained neural networks are optimized using the classification loss $\\mathcal{L}_c(\\theta)$ until a threshold accuracy of 95% is reached, or the accuracy does not improve for 100 steps, within a tolerance of $10^{-3}$, using Adam with a learning rate of $\\eta = 10^{-3}$.\nA.2 Main experiments\nAll experiments and time measurements were conducted on a single Apple M2 Pro chip. We used Bayesian optimization in logarithmic scale for hyperparameter tuning to find the optimal configuration. The range of variation is shown below."}, {"title": "B Theoretical explanation proof", "content": "B.1 SDP bound\nWe use the following classical lemma without proof\nLemma B.1. Let P be positive semidefinite block matrix of the form\n$P = \\begin{bmatrix} A & B \\\\ B^\\top & C \\end{bmatrix}$ (B.1)\nthen $||B||_* < ||A||_* \\cdot ||C||_*$, where $|| \\cdot ||_*$ denotes the matrix nuclear norm.\nSince the matrix P in 2.12 is positive semidefinite, any its upper-left corner, including those obtained by permuting rows and columns, is also positive semidefinite. Thus, $\\begin{bmatrix} P[1] & P[x_L] \\\\ P[x_L]^\\top & P[x_L x_L^\\top] \\end{bmatrix} \\geq 0$ and by Lemma B.1, $||P[x_L]||_*^2 \\leq ||P[1]||_* \\cdot ||P[x_L x_L^\\top]||_*$. This gives us the bound\n$B^{\\text{SDP}} = \\max W_{L+1} P[x_L] + b_{L+1} \\leq ||W_{L+1}||_2 ||P[x_L]||_2 + ||b_{L+1}||_2 \\leq ||W_{L+1}||_2 \\sqrt{||P[x_L x_L^\\top]||_*} + ||b_{L+1}||_2$ (B.2)\nTo bound the norm of $P[x_L x_L^\\top]$, we will use the following lemma by working backward through the layers.\nLemma B.2. For any l = 1 . . . L we have bound\n$\\sqrt{||P[x_l x_l^\\top]||_*} \\leq ||W_l||_2 \\sqrt{||P[x_{l-1} x_{l-1}^\\top]||_*} + ||b_l||_2$ (B.3)\nProof. First, we take the trace from equation 2.15\n$||P[x_l x_l^\\top]||_* = tr P[x_l x_l^\\top] = tr W_l P[x_{l-1} x_{l-1}^\\top] W_l^\\top + b_l^\\top P[x_l] < ||W_l||_2 tr P[x_{l-1} x_{l-1}^\\top] + ||b_l||_2 \\sqrt{tr P[x_l x_l^\\top]}$ (B.4)\nThen we apply Lemma B.1 to the submatrix $\\begin{bmatrix} P[x_{l-1} x_{l-1}^\\top] & P[x_{l-1} x_l^\\top] \\\\ P[x_l x_{l-1}^\\top] & P[x_l x_l^\\top] \\end{bmatrix} \\geq 0$ which gives $||P[x_{l-1} x_l^\\top]||_*^2 \\leq ||P[x_{l-1} x_{l-1}^\\top]||_* ||P[x_l x_l^\\top]||_*$. As a result,\n$||P[x_l x_l^\\top]||_* \\leq \\Big( ||W_l||_2 \\sqrt{||P[x_{l-1} x_{l-1}^\\top]||_*} + ||b_l||_2 \\Big) \\sqrt{||P[x_l x_l^\\top]||_*}$ (B.5)\nwhich readily leads to the desired conclusion.\nNow we can prove\nProof of Theorem 2.1. By recursively applying Lemma B.2, we obtain\n$B^{\\text{SDP}} \\leq \\prod_{l=1}^{L+1} ||W_l||_2 \\sqrt{||P[x_0 x_0^\\top]||_*} + \\sum_{l=1}^{L+1} ||b_l||_2 \\prod_{m=l+1}^{L+1} ||W_l||_2$ (B.6)\nThe norm of the input block is constrained by the input region. If p = 2, $||P[x_0 x_0^\\top]||_* = tr P[x_0 x_0^\\top] < \\epsilon^2$. If $p = \\infty$, $||P[x_0 x_0^\\top]||_* < d \\epsilon^2$."}, {"title": "B.2 LP and a-CROWN bound", "content": "Proof of Theorem 2.2. First we prove a lower bound for a-CROWN, followed by the linear programming (LP) bound. We start by unfolding the output computation procedure 2.3- 2.5 for an L = 1 network without biases, and then calculate the intermediate bounds starting from the input, as decribed in [25].\n$y = W_1 x$ (B.8)\n$\\chi_1 = \\sigma(y)$ (B.9)\n$f_\\theta(x) = W_2 x_1$ (B.10)\nThe input constraint is $x \\in X = \\{x : ||x||_p \\leq \\epsilon \\}$, meaning that each coordinate is bounded as $-\\epsilon < x_i < \\epsilon$. Then y is bounded as\n$-\\epsilon \\sum |W_i^1| \\leq y \\leq \\epsilon \\sum |W_i^1|$ (B.11)\nUnder Xavier initialization, $W_i^1$ is sampled from Uniform[-1/$\\sqrt{d}$, 1/$\\sqrt{d}$], and $\\sum_i |W_i^1|$ concentrates around $\\sqrt{d}/2$. Neuron j is unstable and a-CROWN bound looks like\n$aly \\leq \\frac{\\epsilon}{2} \\sum |W_i^1|$ (B.12)\nThe upper bound on $f_\\theta(x)$ is\n$f_\\theta(x) \\leq \\sum W_2^j y / (\\frac{\\epsilon}{2} 1[W_2^j \\geq 0] - a 1[W_2^j \\leq 0]) + \\frac{\\epsilon}{2} \\sum 1[W_2^j \\geq 0] \\sum |W_i^1|$ (B.13)\nWhatever the linear relationship between y and x, the linear perturbation bound over ball X cannot be smaller than the bias term, we have\n$\\max_X f_\\theta(x) < B^{\\alpha-\\text{CROWN}}; B = \\frac{\\epsilon}{2} \\sum 1[W_2^j \\geq 0] \\sum |W_i^1| \\leq B^{\\alpha-\\text{CROWN}}$ (B.14)"}]}