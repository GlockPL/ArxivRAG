{"title": "Time and Frequency Synergy for Source-Free Time-Series Domain Adaptations", "authors": ["Muhammad Tanzil Furqon", "Mahardhika Pratama", "Ary Shiddiqi", "Lin Liu", "Habibullah Habibullah", "Kutluyil Dogancay"], "abstract": "The issue of source-free time-series domain adaptations still gains scarce research attentions. On the other hand, existing approaches rely solely on time-domain features ignoring frequency components providing complementary information. This paper proposes Time Frequency Domain Adaptation (TFDA), a method to cope with the source-free time-series domain adaptation problems. TFDA is developed with a dual branch network structure fully utilizing both time and frequency features in delivering final predictions. It induces pseudo-labels based on a neighborhood concept where predictions of a sample group are aggregated to generate reliable pseudo labels. The concept of contrastive learning is carried out in both time and frequency domains with pseudo label information and a negative pair exclusion strategy to make valid neighborhood assumptions. In addition, the time-frequency consistency technique is proposed using the self-distillation strategy while the uncertainty reduction strategy is implemented to alleviate uncertainties due to the domain shift problem. Last but not least, the curriculum learning strategy is integrated to combat noisy pseudo labels. Our experiments demonstrate the advantage of our approach over prior arts with noticeable margins in benchmark problems.", "sections": [{"title": "1. Introduction", "content": "The advent of deep learning [1] has triggered significant research progresses in many applications. The success of deep learning is largely attributed to the i.i.d conditions where the training and deployment phases follow the same distributions but it performs poorly in the case of domain shifts. This problem has motivated the rise of unsupervised domain adaptation (UDA) field [2, 3] where the objective is to develop a model to generalize well in the unlabelled target domain given labelled samples of the source domain. The source domain and the target domain follow different distributions or are drawn from different domains. Nevertheless, most UDA works rely on the access of labelled samples of the source domain which might be inaccessible because of privacy constraints or limited computational resources. This issue has motivated researchers to explore the source-free domain adaptation (SFDA) topic [4, 5, 6] which addresses no access of source-domain samples and only exploits a pretrained source-domain model alongside with unlabelled target-domain samples.\nThere exist increasing research attentions to study the SFDA topic. In [4], the self-training mechanism is proposed for SFDA using the cluster structure. [7] utilizes the generative model to perform SFDA. [8] combines the self-supervised learning approach and the pseudo-labelling approach. Similar approach is put forward in [9] to refine model's predictions with the self-supervised learning strategy. [5] designs the curriculum learning approach to prevent early memorization of noisy pseudo-labels while [6] presents the loss re-weighting approach based on uncertainties of predictions. All these works focus on image classification problems, possessing no spatio-temporal characteristics compared to that of the time-series classification problems. To the best of our knowledge, the problem of SFDA on time-series data is relatively an uncharted territory where only two works [10, 11] have been proposed thus far. [10] addresses the problem but is limited to the case of seizure predictions. In [11], the imputation strategy is offered for SFDA on time-series data. These works rely solely on time-domain features and do not yet consider frequency components potentially aiding performance's improvements on time-series domain adaptations [12]. It is perceived that the use of frequency domain is capable of boosting the numerical results by up to 4% compared to that of without the frequency domain.\nTime Frequency Domain Adaptation (TFDA) method is proposed in this paper to handle the absence of source domain data points in UDA given time-series samples. Given a pre-trained source model, the underlying objective is to generalize well over unlabelled target-domain samples. TFDA is built upon a dual branch network structure taking into account both time and frequency features. That is, it possesses a time encoder and a frequency encoder processing time and frequency features independently. The final output is aggregated based on their confidence degrees. It adopts the self-training mechanism taking into account the neighborhood structure of target domain samples. That is, a pseudo-label is derived from those of neighboring samples given that adjacent samples"}, {"title": "2. Related Works", "content": "2.1. Time Series Domain Adaptation\nThe problem of domain shifts on time-series data has been studied where it aims to generalize well over unlabelled samples of the target domain given labelled samples of the source domain. The underlying challenge lies in the temporal nature of time-series samples besides the distribution shifts of the source domain and the target domain. Existing works can be categorized into two groups: adversarial-based approach and discrepancy-based approach. AdvSKM [14] presents a discrepancy-based approach integrating spectral kernel to address the temporal dependencies on top of the MMD approach. SASA [15] utilizes the association structure across the two domains for time-series UDA. The adversarial-based method plays the adversarial game to minimize the domain gap. Such approach is exemplified by CoDATS [16] incorporating the adversarial learning for multi-source human-activity recognition tasks. DAATTN [17] combines the adversarial training strategy and the attention sharing mechanism. SLARDA [18] presents an autoregressive approach for adversarial training. In [19], the concept of mixup domain adaptation is developed to handle domain adaptations of aircraft engines.\nThese works depend on the access of source-domain data, often unavailable in several practical applications due to the privacy constraints or the storage limitations. TFDA works with only a pretrained source model with the absence of any source-domain data. The pretrained source model is adapted using only unlabelled target-domain data.\n2.2. Source-Free Domain Adaptation\nSource-free domain adaptation (SFDA) aims to address the issue of privacy in unsupervised domain adaptation (UDA) where source-domain data are unavailable when performing domain adaptations. [4] puts forward the self-training mechanism using the cluster's structure. [7] presents the generative model to perform SFDA. The self-supervised learning strategy is offered in [9]. [5] devises the curriculum learning strategy to prevent early memorization of noisy pseudo-labels while [6] is based on the loss re-weighting strategy. These works are designed for visual applications which do not possess any temporal properties.\nTo date, only two methods have been proposed in the literature to deal with source-free time-series domain adaptation. [10] utilizes the Gaussian Mixture Model (GMM) for seizure data. In [11], the time-series imputation strategy is proposed. These works are solely based on temporal features without taking advantages of frequency features which can improve model's generalization on time-series data [12]."}, {"title": "3. Problem Formulation", "content": "Given a pretrained source model $g_{\\theta}(f_{\\theta}(x))$ where $f_{\\theta}(.) : \\mathcal{X} \\rightarrow \\mathcal{Z}$ is a feature extractor mapping the input space to the latent space while $g_{\\theta}(.) : \\mathcal{Z} \\rightarrow \\mathcal{Y}$ is a classifier converting the feature space into the output space, the objective of SFDA is to generalize well over the unlabelled target domain $\\mathcal{T} = \\{(x_i, y_i)\\}_{i=1}^{N_T}$ where $N_T$ denotes the number of unlabelled samples in the target domain, $x_i \\in \\mathcal{X}_T, y \\ni \\mathcal{Y}_T,\\mathcal{X}_T \\times \\mathcal{Y}_T \\in \\mathcal{D}_T$. The source model $g_{\\theta}(f_{\\theta}(.))$ is pretrained using the labelled samples of the source domain $\\mathcal{S} = \\{(x_i, y_i)\\}_{i=1}^{N_s}$ where $N_s$ stands for the number of labelled source-domain samples, $x_s \\in \\mathcal{X}_S,y_S \\in \\mathcal{Y}_S,\\mathcal{X}_S \\times \\mathcal{y}_S \\in \\mathcal{D}_S$. The source domain and the target domain possess the domain shift problem $\\mathcal{D}_S \\neq \\mathcal{D}_T$ due to different marginal distributions $P_S(x) \\neq P_T(x)$ but share the same label space $\\mathcal{y}_S = \\mathcal{Y}_T$.\nWe limit our scope of study to a closed-set problem. $\\mathcal{D}_S, \\mathcal{D}_T$ stand for the source domain and the target domain respectively while $P_S(x), P_T(x)$ denote the marginal distribution of the source domain and the target domain respectively. Because of the issue of privacy, the domain adaptation phase is done with the absence of any source-domain data $\\mathcal{S}$. That is, $\\mathcal{S}$ is discarded once used in the pre-training phase."}, {"title": "4. Method", "content": "TFDA is developed from the teacher-student architecture as shown in Fig. 2 under a dual-branch network structure processing temporal and frequency features independently. That is, the exponential moving average strategy is applied to tune the teacher's model based on the parameters of the student's model. First, the student model is trained to minimize the teacher model losses. This strategy is implemented because a weighted-average model normally performs better than the final model. It starts with the neighborhood pseudo-labelling strategy followed by the sample selection strategy to determine reliable and unreliable samples learned differently under the roof of the curriculum learning. The contrastive learning strategy is integrated to satisfy the smoothness constraint while the uncertainty learning strategy is incorporated to overcome the domain shift problem. The contrastive learning approach takes place in both time domain and frequency domain. The domain adaptation mechanism is attained by aligning the time components and the frequency components via the self-distillation technique."}, {"title": "4.1. Dual Branch Structure", "content": "TFDA is developed from a dual branch network structure where each branch mines the time features or the frequency features independently. The motivation of the use of frequency features lies in the fact that the frequency features are representations of the same signal as the features, thereby offering complementary information. That is, it possesses the time encoder $f_{\\theta}(.) : \\mathcal{X} \\rightarrow \\mathcal{Z}$ and the frequency encoder $f_{\\theta^f}(.) : \\mathcal{X}^F \\rightarrow \\mathcal{Z}^F$ where $\\mathcal{X}^F$ is a frequency input $x$ using the Fourier transform for transformation. Each encoder is coupled with its own classifier $g_{\\theta}(.) : \\mathcal{Z} \\rightarrow \\mathcal{P}$ and $g_{\\theta^f}(.) : \\mathcal{Z}^F \\rightarrow \\mathcal{P}^F$. The final prediction is drawn from the weighted mixture of the two network outputs [20].\n$P_i = \\alpha p(y_i = c|x_i) + \\beta p^F(y_i = c|x_i)$ (1)\nwhere $\\alpha = \\frac{\\arg \\max_{c \\in [0, C]} a_c}{\\arg \\max_{c \\in [0, C]} a_c + \\arg \\max_{c \\in [0, C]} \\beta_c}$ and $\\beta = \\frac{\\arg \\max_{c \\in [0, C]} \\beta_c}{\\arg \\max_{c \\in [0, C]} a_c + \\arg \\max_{c \\in [0, C]} \\beta_c}$, $\\alpha, \\beta$ respectively stand for the soft labels produced by $p, p^F$. This strategy allows rich information of the time and frequency spectrum to be considered when inducing the final predictions."}, {"title": "4.2. Pseudo-labelling Strategy", "content": "Inspired by [6], TFDA applies the concept of neighborhood aggregation when deriving pseudo labels. That is, similar samples should share the same label and be close in the feature space whereas dissimilar samples should possess distinct label and be far away in the latent space. It is attained via the contrastive learning strategy pulling similar samples while pushing dissimilar samples. The use of sample groups in deriving pseudo labels reduces the risk of noisy pseudo label better than based on a single sample.\nFor a target sample $x_i$, and a weak augmentation $t_{wa}$ of the distribution $T_{wa}$, a feature vector $z = f_{\\theta}(t_{wa}(x_i))$ is elicited and used to find neighboring samples. The weak augmentation applies the jitter-and-scale strategy [21] where random variations are added to the signals and its magnitudes are scaled up. The pseudo label of $x_i$, is obtained from aggregations of neighbors:\n$\\tilde{p}_i = \\frac{1}{K} \\sum_{j \\in \\mathcal{I}} p_j$ (2)\nwhere $\\mathcal{I}$ denotes the set of indices of the neighbors and $K$ stands for the number of neighbors. The $\\arg \\max$ operator is applied to obtain the refined pseudo label.\n$\\tilde{y}_i = \\arg \\max_c \\tilde{p}_i^c$ (3)\nWe apply the memory bank $\\mathcal{B}$ of length $M$ which stores the candidates of neighbors $\\{z, p\\}^M$. The neighbors are selected by the cosine distance between the target feature $x_i$ and those of the memory bank where the $K$ features with the smallest distances are selected as neighbors."}, {"title": "4.3. Sample Selection", "content": "TFDA applies the sample selection strategy to prevent the influence of noisy pseudo-labels. That is, reliable labels are learned confidently since the beginning of the training process whereas unreliable labels are initially avoided. Motivated by [5], we put forward the prediction confidence and uncertainty as a reliable measure of pseudo label accuracy. Nevertheless, the problem of domain shifts bias the model's predictions and no source data samples are available to estimate the domain's discrepancy. To this end, an augmentation policy is designed to indicate the virtual distribution shift across target domain data where prediction variance or uncertainty over augmented distributions offers the close estimate of the domain shift.\nSuppose that $h_i = g_{\\theta}(f_{\\theta}(x_i))$ and $conf(h_i) = \\max_c h_i$ where $C$ stands for the number of target classes, The reliability score is derived as follows:\nr = $\\begin{cases} 1, & conf(h_i) \\ge t_c \\& U_i \\le t_u \\\\ 0, & otherwise \\end{cases}$ (4)\nwhere $u_i$ denotes the uncertainty of the $i - th$ sample calculated as the standard deviation of the prediction confidence over $L$ augmentations $u_i = std\\{conf(h_i)\\}_{i=1}^L$ and $L$ stands for the number of augmented samples. $t_c, t_u$ stand for the confidence and uncertainty thresholds simply set as the average over a batch $t_c = \\frac{1}{B} \\sum_{i=1}^B conf(h_i)$ and $t_u = \\frac{1}{B} \\sum_{i=1}^B u_i$ where $B$ denotes the mini-batch size."}, {"title": "4.4. Self-Distillation Strategy", "content": "The reliability score $r^i$ allows segregation of data samples into two groups: reliable group $\\mathcal{R} = \\{(x_i, y_i) : r_i = 1\\}_{i=1}^{B_1}$ and non-reliable group $\\overline{\\mathcal{R}} = \\{(x_i, y_i) : r_i = 0\\}_{i=1}^{B_1}$ to be learned with different paces. We apply the top-2 confidence score from $\\mathcal{R}$ to guarantee diversity of the reliable group $\\mathcal{R}$. The class-balanced cross-entropy loss function $\\mathcal{L}_{ce}$ is implemented to learn the reliable group $\\mathcal{R}$ whereas the non-reliable group $\\overline{\\mathcal{R}}$ is learned by the label propagation loss $\\mathcal{L}_{lp}$:\n$\\mathcal{L}_{lp} = \\frac{1}{2|\\overline{\\mathcal{R}}|} \\sum_{i \\in \\overline{\\mathcal{R}}} ||g_{\\theta}(f_{\\theta}(x_i)) - \\tilde{y}_i||_2$ (5)\nwhere the label information is transferred from the reliable group $\\mathcal{R}$ to the non-reliable group $\\overline{\\mathcal{R}}$ due to the transductive property $\\mathcal{L}_{lp}$."}, {"title": "4.5. Contrastive Learning", "content": "The contrastive learning strategy [13, 6] is adopted to pull similar samples, positive pairs, together while pushing away dissimilar samples, negative pairs. This strategy is required because of the neighborhood pseudo-labelling strategy where adjacent samples should share the same label. Two strong augmentations $t_{sar}^s, t_{sar}^t \\in T_{sa}$ are selected to generate two different views of a sample $t_{sar}^s(x), t_{sar}^t(x)$ encoded to be query $q = f_{\\theta}(t_{sar}^s(x))$ and key $k = f_{\\theta}(t_{sar}^t(x))$ through the encoder $f_{\\theta}$. The keys and queries construct the positive pair, while the negative pairs are created from a queue $\\mathcal{Q}$ storing key features of each mini-batch $\\{k\\}_{i=1}^N$, i.e., other samples in the mini-batch as per [22]. The strong augmentation is resulted from the permutation-and-jitter strategy [21]. That is, a signal is split into a random number of segments with a maximum of $M$ and randomly shuffled.\nWe consider pseudo-labels when performing the contrastive learning mechanism to avoid features having the same category to be pushed away. This problem is addressed in [9] with the negative pair exclusion strategy where the negative pair is masked out if the two samples possess the same pseudo-label. Nevertheless, this strategy ignores the noisy pseudo label problem undermining the negative pair assumption. We follow [6] which takes into account the history of pseudo labels. That is, the queue $\\mathcal{Q}$ is converted into a temporal queue also memorizing the pseudo labels $\\{\\hat{y}\\}_{i=1}^N$ across the past $T$ epochs. The pair is excluded if it has the same pseudo-label at least once over the past $T$ epochs. The contrastive learning is achieved by minimizing the following InfoNCE loss function.\n$\\mathcal{L}_{cd} = -log \\frac{exp (q.k_+/\\tau)}{\\sum_{j \\in \\mathcal{N}_i} exp (q.k_j/\\tau)}$ (6)\n$\\mathcal{N}_i = \\{j | \\hat{y}_j \\neq \\hat{y}_i, \\forall j \\in \\{1, ..., N\\}, \\forall i \\in \\{1, ...,T\\}\\}$ (7)\nwhere $\\mathcal{N}_i$ is the set of indices in $\\mathcal{Q}$ that never possess the same pseudo label with the query sample in the past $T$ epochs. $q, k$ respectively stand for the query and the key\nExisting SFDA methods focus solely on the time domain and overlooks the frequency domain [13] potentially boosting the performances given time-series data. As a matter of fact, the time and frequency domains are different views of the same data which should be invariant regardless of the time series distributions. We are motivated to extract a general characteristic preserved across the time-series datasets.\nThe frequency spectrum $x^f$ is produced by applying a transform operator to the time-domain sample $x_i$. The frequency encoder $f_{\\theta^f}$, is applied to embed the frequency spectrum $x^f$. The augmentation procedure follows [13] where the frequency spectrum is perturbed by adding or removing the frequency components. Via the two augmentation methods $t_{sar}^s, t_{sar}^t \\in T_{sa}$, the query $q^f = f_{\\theta^f}(t_{sar}^s(x))$ and the key $k^f = f_{\\theta^f}(t_{sar}^t(x))$ are generated to produce two different views of the frequency spectrum $x^f$ and form the positive pair. As with the time-domain features, the negative pair exclusion strategy is applied. The frequency contrastive learning is expressed mathematically as follows:\n$\\mathcal{L}_{cd}^f = -log \\frac{exp (q^f.k^f/\\tau)}{\\sum_{j \\in \\mathcal{N}_i^f} exp (q^f.k_j^f/\\tau)}$ (8)\n$\\mathcal{N}_i^f = \\{j | \\tilde{y}_j \\neq \\tilde{y}_i, \\forall j \\in \\{1, ..., N\\}, \\forall i \\in \\{1, ...,T\\}\\}$ (9)\nwhere $\\tau$ is the temperature constant. Given the time embedding via the time encoder $f_{\\theta}(.)$ and the frequency embedding via the frequency encoder $f_{\\theta^f}(.)$, the next task is to perform the contrastive learning between time and frequency features $\\mathcal{L}_{cl}$. This is done by projecting their representations into a joint time-frequency space through projectors $\\mathcal{R}(.)$ and $\\mathcal{R}_f(.)$ mapping the frequency or time embedding into the joint embedding. That is, the query and the key are constructed as $q = \\mathcal{R}(f_{\\theta}(x))$ and $k = \\mathcal{R}_f(f_{\\theta^f}(x^f))$. The time-frequency contrastive learning is performed similarly as that the time or frequency contrastive learning considering the presence of pseudo labels with the negative pair exclusion strategy. The main distinction lies in the use of joint embedding $\\mathcal{R}(.)$ and $\\mathcal{R}_f(.)$ to produce the time-frequency features.\n$\\mathcal{L}_{cl} = -log \\frac{exp (q.k/\\tau)}{\\sum_{j \\in \\mathcal{N}_i} exp (q.k_j/\\tau)}$ (10)\nThis implies time and frequency features of the same classes are pulled together while pushing apart those of different class. That is, the time and frequency features should be close to each other because they represent the same sample. Because of the absence of ground truth, the supervision signal is generated by the pseudo-labelling process with the negative pair exclusion method. The overall contrastive learning strategy is formulated:\n$\\mathcal{L}_{CL} = a_1(\\mathcal{L}_{cd} + \\mathcal{L}_{cd}^f) + a_2 \\mathcal{L}_{cl}$ (11)\nwhere $a_1, a_2$ stand for the tradeoff constants fixed at 0.5 in our simulations meaning that both terms possess equal impacts."}, {"title": "4.6. Time Frequency Consistency", "content": "The consistency between the time component and the frequency component is attained via the self-distillation technique and done in the output space. That is, the outputs of frequency encoder and time encoder are forced to be consistent. The following consistency loss is formulated using the KL divergence.\n$\\mathcal{L}_{cons} = D_{KL}(g_{\\theta}(f_{\\theta}(x))||g_{\\theta^f}(f_{\\theta^f}(x^f)))+\nD_{KL}(g_{\\theta^f}(f_{\\theta^f}(x^f))||g_{\\theta}(f_{\\theta}(x)))$ (12)\nwhere $D_{KL}(a||b) = \\sum_{x \\in \\mathcal{X}} a(x) log(\\frac{a(x)}{b(x)})$. It differs from [13] where the consistency is maintained in the embedding space. Our approach constructs different architectures between the frequency component and the time component where the outputs of the two architectures are matched at the end."}, {"title": "4.7. Uncertainty Reduction Strategy", "content": "In realm of SFDA, the domain shift causes uncertainties of model predictions [10] and minimization of uncertainties leads to improved robustness. Due to the domain shift, a model tends to learn samples with high confidence but underutilize those having high uncertainties. We apply a modified Tsallis entropy approach [23, 10] to minimize uncertainties.\n$\\mathcal{L}_{ul} = \\frac{1}{\\beta} (1 - \\frac{1}{C} \\sum_{i=1}^{n_T} \\sum_{c=1}^C \\eta_i (h_i^c)^{\\mu})$ (13)\n$\\beta = \\sum_{i=1}^{n_T} \\eta_i$ (14)\n$\\eta_i = \\frac{n_i[1 + exp(-E(h_i))]}{\\sum_{j=1}^{n_T} [1 + exp(-E(h_j))]}$ (15)"}, {"title": "4.8. Overall Loss Function", "content": "The overall loss function is formalized as follows:\n$\\mathcal{L}_{all} = \\mu_r \\mathcal{L}_{ce} + (1 - \\mu_r)\\mathcal{L}_{lp} + \\mu_c \\mathcal{L}_{CL} + \\mu_{cons} \\mathcal{L}_{cons} + \\mu_u \\mathcal{L}_{ul}$ (16)\nwhere $\\mu_r, \\mu_c, \\mu_{cons}, \\mu_u$ are trade-off coefficients controlling the pace of learning process. We adopt the curriculum learning principle to steer the tradeoff coefficients.\nSince the performance of a weighted-average model over time steps is generally better than the final model [24], the mean-teacher framework is implemented here. That is, it involves the teacher-student approach initialized using the source model. Suppose that $\\Theta_s = \\{\\theta_f, \\theta_g\\}$, the parameters of the student model $\\Theta_s$ are adjusted by back-propagating the losses incurred by the teacher model. The parameters of the teacher model $\\Theta_t$ is adapted using the exponential moving average of the student model parameters. The update formula is expressed:\n$\\Theta_t^j = \\alpha \\Theta_{t-1}^j + (1 - \\alpha)\\Theta_s^j$ (17)\nwhere $\\alpha$ is the smoothing coefficient simply set at 0.999. This strategy alleviates the over-fitting risk of noisy pseudo labels in the beginning of the training process."}, {"title": "4.9. Curriculum Learning", "content": "TFDA implements the curriculum learning strategy [25, 5] focusing on easy samples first before turning into hard samples, thus avoiding early memorization of noisy pseudo labels. Since a model is confident to the reliable group $\\mathcal{R}$, their predictions are likely to be correct. Hence, the priority is to learn the reliable group first where the non-reliable group $\\overline{\\mathcal{R}}$ is restricted in the beginning of the training process. This is achieved by setting the tradeoff coefficient:\n$\\mu_r = (1 - a \\exp(-\\frac{j}{d_i}))^{-1}$ (18)\nwhere $d^j_i = \\frac{1}{\\tau_c^j}$ denotes the difficulty score. $a, \\mu$ are empirically set to 0.005 and 1. This setting implies to prevent the non-reliable group to be learned in the beginning of the training process. The learning process of the non-reliable group commences as the training process progresses and the overall reliability improves. Besides, the dynamics of $\\mu_r$ is determined directly from the difficulty score meaning that the change is minimal if the current batch of samples at the epoch $j$ is difficult. $\\mu_{cons}, \\mu_u$ exponentially decay.\n$\\mu' = \\mu^{-1} \\exp(-\\beta)$ (19)\n$\\mu_{cons}' = \\mu_{cons}^{-1} \\exp(-\\beta)$ (20)\n$\\mu_u' = \\mu_u^{-1} \\exp(-\\beta)$ (21)\nwhere $\\mu_0, \\mu_{cons}, \\mu_u, \\beta$ are respectively set as 10.5, 0.5, 0.5, 1e-4. This setting allows them to be active in the beginning of the training process but to be slow in the end of the training process. That is, fine-grained pseudo labels are supposed to be achieved in the end of the training process."}, {"title": "4.10. Theoretical Analysis", "content": "Given $P_S, P_T$ as the distribution of labeled source and unlabeled target examples respectively over source $X_S$ and target $X_T$ input spaces, where $P_S \\neq P_T$. Let $P := \\{x_1,\u2026, x_n\\} \\subset X$ denote n uniformly distributed unlabeled training data from $P_T$. We consider $F : X \\rightarrow Z$ as a continous logits output by a feature extractor, and $G : X \\rightarrow [K]$ the discrete labels induced by $F : G(x) := argmax_i F(x)_i$. $K$ is the number of classes given by the ground truth $G^*(x)$ for $G^* : X \\rightarrow [K]$ and $Q_i := \\{x : G^*(x) = i\\}$ as the set of examples with ground-truth label i. Let define $A(x)$ as the augmentation function of input x, where $A(x) := \\{x'|\\exists T \\in T_{wa} such that ||x' \u2013 T(x)|| \\le r\\}$, $T_{wa}$ denote some set of augmented data, $N(x) := \\{x'|A(x) \\cap A(x') \\neq \\emptyset\\}$ as the neighborhoods of x, and $N(S) := \\cup_{x \\in S} N(x)$ as the neighborhood set of S. Based on self-learning expansion assumption [26], let define (a,b)-multiplicative-expansion:\n$P_i(N(S)) \\ge min \\{bP_i(S), 1\\}$ (22)\nfor $P_i(S) \\le 1/2, b > 1$, where $P_i$ be the distribution of subset S on class i data and b represents an expansion factor that corresponds to the strength of the data augmentation. Let also define (c,p)-constant-expansion:\n$P(N^*(S)\\setminus S) \\ge min \\{p, P(S)\\}$ (23)\nfor $P(S) \\ge c$ and $P(S \\cap Q_i) \\le P(Q_i)/2$ for all i, where $N^*(S)$ is the neighborhood of S with neighbors restricted to the same class: $N^*(S) := \\cup_{i \\in [K]}(N(S \\cap Q_i) \\cap Q_i)$. Our algorithms leverage expansion by using cross-entropy and transductive label propagation loss (5) as consistency regularization to encourage predictions of a classifier G to be consistent under different transformations of the data. Furthermore, let consider side information [27] $s \\in S$ which can be accessed from $x \\in X$. In the case of contrastive learning, given $(x,x^*) \\in X^2$, $s := 1(x = x^*)$ where side information indicates whether the pair should be considered as positive or negative. We follow the self-learning expansion and separation assumptions as in [26] and $x^{-1}$-informative condition assumption as in [27] as detailed below:\nAssumption 1. (multiplicative-expansion) Assume P satisfies (1/2,b)-expansion on X for b > 1, ground-truth classes $G^*$ are separated, and the consistency regularization loss as $R_A(G) := [E_P [1(\\exists x' \\in A(x) such that F(x') \\neq F(x))]$."}, {"title": "4.11. Complexity Analysis", "content": "Suppose that E, N, M respectively stand for the number of epochs, the number of target-domain samples and the size of memory bank where M < N, the complexity of TFDA is approximated to be \u2248 O(E.M.N). Since the number of epochs and the size of memory bank are bounded and usually small, the complexity of TFDA is \u2248 O(N). Detailed derivations of the algorithm's complexity and pseudo-code can be found in the appendix."}, {"title": "6. Conclusion", "content": "This paper presents Time Frequncy Domain Adaptation (TFDA) to overcome the absence of source-domain samples in time-series unsupervised domain adaptation. TFDA is built upon the dual-branch network architecture processing the temporal and frequency features separately while final predictions are drawn from the confidence score. It relies on neighborhood pseudo labelling aided by the contrastive learning strategy in both time and frequency domains to pull similar samples while pushing dissimilar samples. The domain adaptation step is achieved by enforcing consistencies between the time and frequency features. In addition, the uncertainty reduction strategy is implemented to alleviate the prediction's uncertainties due to the domain shifts and the curriculum learning strategy is designed to prevent early memorization of noisy pseudo labels. That is, the curriculum learning strategy prioritizes in learning reliable samples while avoiding those of unreliable samples. Rigorous experiments are performed to numerically validate the efficacy of TFDA. It is demonstrated that TFDA delivers the most encouraging results across 15 cross-domain scenarios using the three datasets with noticeable margins to its competitors. Our ablation study further substantiates the efficacy of each learning component while the analysis of neighborhood size exhibits the advantage of the neighborhood pseudo-labelling strategy. Notwithstanding that TFDA delivers satisfactory performances compared to prior arts, TFDA assumes that the source model can be shared when performing domain adaptations. The access of source model is prohibited in some applications due to the privacy constraints. Our future work is directed to study the topic of black box domain adaptation."}, {"title": "A. Detailed Theoretical Analysis", "content": "Given $P_S", "P": {"F": "X \\rightarrow Z$ as a continous logits output by a feature extractor", "G": "X \\rightarrow [K"}, "F": "G(x) := argmax_i F(x)_i$. $K$ is the number of classes given by the ground truth $G^*(x)$ for $G^* : X \\rightarrow [K", "Q_i": {"x": "G^*(x) = i\\"}, "A(x)": {"N(x)": {"N(S)": "cup_{x \\in S} N(x)$ as the neighborhood set of S. Based on self-learning expansion assumption [26"}}}]}