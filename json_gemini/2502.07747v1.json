{"title": "WHODUNIT: Evaluation benchmark for culprit detection in mystery stories", "authors": ["Kshitij Gupta"], "abstract": "We present a novel data set, WHODUNIT, to assess the deductive reasoning capabilities of large language models (LLM) within narrative contexts. Constructed from open domain mystery novels and short stories, the dataset challenges LLMs to identify the perpetrator after reading and comprehending the story. To evaluate model robustness, we apply a range of character-level name augmentations, including original names, name swaps, and substitutions with well-known real and/or fictional entities from popular discourse. We further use various prompting styles to investigate the influence of prompting on deductive reasoning accuracy.\nWe conduct evaluation study with state-of-the-art models, specifically GPT-4o, GPT-4-turbo, and GPT-4o-mini, evaluated through multiple trials with majority response selection to ensure reliability. The results demonstrate that while LLMs perform reliably on unaltered texts, accuracy diminishes with certain name substitutions, particularly those with wide recognition. This dataset is publicly available here.", "sections": [{"title": "1 Introduction", "content": "Large Language Models (LLMs) have demonstrated exceptional capabilities in a wide array of natural language tasks, from text generation and summarization to complex reasoning and inference (Brown, 2020). The release of the transformer architecture by Vaswani (2017) marked a pivotal advancement in the field, enabling models to handle long-range dependencies in text more effectively through self-attention mechanisms. This breakthrough not only enhanced model scalability but also laid the foundation for the development of increasingly sophisticated LLMs that are now capable of handling nuanced and context-rich tasks. With the emergence of models such as BERT(Kenton and Toutanova, 2019), GPT-2(Radford et al., 2019), and later ChatGPT(OpenAI, 2022), the field of natural language processing has seen rapid innovation, driving significant improvements in model performance and expanding potential applications.\nChatGPT demonstrated that LLMs could deliver highly interactive, contextually relevant responses in real-time, broadening their accessibility to non-technical users and sparking widespread integration in industries. This release emphasized the need for systematic evaluation frameworks to understand the capabilities, limitations, and potential biases of these models as they are adopted in real-world applications.\nOver recent years, several significant benchmarks have been introduced, such as MMLU(Hendrycks et al., 2020), HELM(Liang et al., 2022), Open LLM Leaderboard\u00b9, and AlpacaEval\u00b2. These benchmarks have been critical in capturing LLM reasoning capabilities and enabling comparisons among state-of-the-art models.\nThis paper contributes to these efforts by introducing a novel dataset specifically designed to assess deductive reasoning within narrative contexts. To build this dataset we take inspiration from a recent interview(Huang and Sutskever, 2023) between Ilya Sutskever and Jensen Huang about \"next word prediction\" being sufficient for understanding. Our benchmark aims to provide deeper insights into the adaptability and inference capabilities of leading models, including GPT-4o, GPT-4-turbo, and GPT-4o-mini (Achiam et al., 2023), especially in tasks involving complex narrative comprehension. We believe that such a benchmark will help future model iteration on LLMs deductive reasoning capabilities as well as complex long-form narrative comprehension.\nThis paper is organized as follows: Section 2 reviews relevant prior research, while Section 3 de-"}, {"title": "2 Related Works", "content": "Foundational LLMs, such as GPT-2 and GPT-3, demonstrated strong performance across various text-based tasks, though they initially struggled with complex, multi-step reasoning (Radford et al., 2019; Brown, 2020).\nCoT prompting, which encourages models to break down problems into logical steps, has been shown to enhance accuracy and coherence in deductive tasks (Wei et al., 2022). Additional methods, like Self-Reflection prompting, further improve reliability by having models verify and refine their responses, leading to more thoughtful answers (Shinn et al., 2024; Madaan et al., 2024).\nLLMs' abilities to handle narrative reasoning-tracking characters, plot progression, and thematic elements\u2014have also been a focal area of Al research. Studies have shown that while models can generate coherent stories, they often struggle with consistency over long narratives (Ammanabrolu et al., 2021; Rashkin et al., 2020). Enhanced approaches have aimed to improve narrative coherence, though challenges remain, particularly in maintaining character roles and logical plot flow.\nSeveral benchmarks assess LLMs' reasoning and comprehension, including MMLU, HELM, and Big-Bench (BBH), which evaluate performance across diverse tasks (Hendrycks et al., 2020; Liang et al., 2022; Srivastava et al., 2022). These benchmarks incorporate tasks requiring reasoning and narrative comprehension, though few focus specifically on deductive reasoning within mystery narratives."}, {"title": "3 Dataset Preparation", "content": "In this section, we outline our dataset preparation, validation process. To release this dataset for open source use, we focus on books that have entered the public domain, so we use Project Gutenberg\u00b3 as our primary story source. We then obtained the list of 500+ Mystery and Detective story titles, that are of interest to us. Additionally, to maintain sufficient variability and diversity in the dataset, we ensured that we represent all the broad characteristics of the stories. Each selected novel features an identifiable culprit, ensuring that the task involves pinpointing to perpetrator. The novels span a diverse range of authors and storytelling styles, encompassing classic WhoDunIt detective novels by authors such as Agatha Christie. As shown in Figure 1, the stories vary in length, covering short, medium and full narratives, providing a broad spectrum of text. By including works from different writers and narrative traditions, we ensure that the models encounter a variety of narrative structures, reasoning styles, and linguistic expressions used to describe mystery and crime.\nSince these stories are very popular and have been in the public discourse for a long time, for most of the stories, we find the identity of the culprit from services like Cliffnotes\u2074. This provides us confidence about the identity of the culprit of the story, and hence the accuracy of our dataset. Secondly, for others we read them ourselves to figure out the culprit of the story.\nSince these stories are in public domain, any model has most likely already been trained on them. Additionally, model would also have trained on any notes/blog posts about these stories. Thus the identity of culprit is probably already in model's memory. To further investigate whether the model depends on memorized data from pre-training or can genuinely engage in contextual reasoning, we applied a series of character-name substitutions. Each augmentation is intended to disrupt potential memorized associations with names, forcing the model to rely on contextual cues and relationships between characters, rather than merely recognizing famous names."}, {"title": "4 Experimental Setup", "content": "We conducted our experiments on three OpenAI models: GPT-4o, GPT-4-turbo, and GPT-4o-mini (Achiam et al., 2023), using OpenAI's Batch API6 via the chat-completions endpoint. These models represent a spectrum of capabilities within the GPT-4 family, allowing us to examine how model size and design impact performance in narrative deduction tasks.\n4.1 Prompting Techniques\nTo assess the models' reasoning abilities, we applied four prompting styles:\n1.  Basic Prompting: Basic prompting without additional guidance, providing a baseline for model performance (Brown, 2020).\n2.  Self-Reflection Prompting: The model is encouraged to review its response for accuracy, simulating a reflective process that can improve answer quality (Shinn et al., 2024).\n3.  Chain-of-Thought(CoT) Prompting: Instructs the model to reason through tasks step-by-step, enhancing clarity and accuracy in complex problem-solving (Wei et al., 2022).\n4.  CoT + Self-Reflection: Combines step-by-step reasoning with self-reflection, prompting the model to refine its answer after an initial response for improved reliability (Madaan et al., 2024).\nTo reduce the variability of responses, and ensure we capture the maximum level of LLM reasoning, we consider a 10-shot prompting for each prompt variety and use the most frequent response as the answer(Wang et al., 2022).\nWith basic prompt as baseline, the self-reflexion is better than that signifying that reflective check"}, {"title": "5 Results and Analysis", "content": "To ensure robust and reliable results, we evaluated each model's performance by conducting 10 independent calls for each configuration(Wang et al., 2022). In each trial, we maintained consistent input conditions-specifically, the same story, augmentation technique, and prompting style. This multi-call approach enabled us to assess the stability and accuracy of each model's outputs under identical conditions, providing a solid basis for comparative analysis across different model setups.\n5.1 Model Comparison\nThe GPT-4-turbo and GPT-4o model demonstrated similar high accuracies of 83.5% and 82.7%, respectively, showcasing their robust capabilities in handling reasoning tasks. The GPT-4o-mini, while smaller, achieved an accuracy of 74.1%, indicating its proficiency despite having fewer parameters. Figure 2 summarizes the accuracy of each model across different configurations, highlighting the comparable performance of GPT-4-turbo and GPT-40 due to their advanced reasoning and inference abilities.\n5.2 Impact of Document Length on Model Accuracy\nFigure 3 demonstrates how model accuracy is influenced by the number of pages in a document. The results indicate that gpt-4o and gpt-4-turbo exhibit strong resilience to increasing document lengths, maintaining consistent accuracy with only a minor decline as the number of pages grows. This suggests that these models are better equipped to handle long-context scenarios without significant performance degradation.\nOn the other hand, gpt-4o-mini shows a pronounced decline in accuracy as the number of pages increases. This steep drop-off highlights its limitations in processing and retaining information in longer documents. The disparity between gpt-4o-mini and the other models becomes more evident as the document length increases.\n5.3 Data Augmentation Analysis\nThe models achieved similar highest accuracy on the original text. However, when all character names were swapped, there was a noticeable drop in accuracy, suggesting that extensive alterations to familiar name patterns hinder the model's understanding of the narrative.\nInterestingly, the accuracy increased for the Harry Potter, Hollywood, and Bollywood versions of the text, with the model performing similarly across these three cases. This indicates that the model benefits from contexts associated with well-known entities, possibly due to pre-training on a large corpus containing such references. Figure 4 summarizes the accuracy of each text variation, highlighting how character name familiarity and context influence model performance.\nThe table below specifies the meaning of different augmentation styles used in the analysis:\n5.4 Prompting Technique Analysis\nPrompting techniques had a notable impact on the model's ability to deduce the culprit's identity, with each method contributing differently to accuracy.\n*   Normal Prompting: As a baseline, normal prompting resulted in a relatively lower precision, as the model produced direct responses without deeper reasoning (Brown, 2020).\n*   Self-Reflection Prompting: Accuracy improved with Self-Reflection prompting, where the model refined responses through internal checks, leading to greater consistency in deductions (Shinn et al., 2024).\n*   Chain-of-Thought (CoT) Prompting: CoT prompting further increased accuracy by guiding the model through a structured reasoning process, allowing it to systematically address key narrative elements (Wei et al., 2022).\n*   Chain-of-Thought + Self-Reflection (COT + Self-Reflection): The combination of CoT and Self-Reflection yielded similar results as CoT, as the model generated logical step-by-step responses and then refined them, demonstrating the enhanced performance in narrative deduction (Madaan et al., 2024).\nFigure 5 presents the accuracy achieved by each prompting technique, with substantial gains observed by adding CoT and Self-Reflexion, underscoring the effectiveness of combining structured reasoning and reflective validation."}, {"title": "6 Conclusion and Future Work", "content": "We conclude by releasing our deductive reasoning capability benchmark, called WHODUNIT. We use this dataset to examine the deductive reasoning capabilities of large language models (LLMs) in complex narrative contexts, specifically focusing on mystery narratives that require nuanced inference and multi-step reasoning. Using a structured evaluation framework, we assessed the effects of model architecture, data augmentation, and various prompting techniques on the deductive accuracy of these LLM configurations GPT-4o, GPT-4-turbo, and GPT-4o-mini. Our findings indicate that a combination of structured reasoning and reflective validation techniques, namely Chain-of-Thought and Self-Reflection prompting, significantly enhances model performance. Our results indicate that before a detective level reasonable understanding the models still have some progress to go in long-form narrative comprehension, and have to build robustness to changes in character names, while keeping the story plot intact. A key aspect of future work would be building long form comprehensive puzzle dataset, that would be able"}, {"title": "Limitations", "content": "This study is limited to short and medium-length stories due to the model's context length constraints, which restrict the analysis of longer narratives."}, {"title": "A Appendix", "content": "A.1 Extract from A Case of Identity by Arthur Conan Doyle\nCulprit: James Windibank\nPoint of Reveal:\n\"My dear fellow,\u201d said Sherlock Holmes\nas we sat on either side of the fire in his\nlodgings at Baker Street, \u201clife is infinitely\nstranger than anything which the mind\nof man could invent. We would not dare\nto conceive the things which are really\nmere commonplaces of existence.\n\"Certainly,\" said Holmes, stepping over\nand turning the key in the door. \"I let you\nknow, then, that I have caught him!\"\n\"What! where?\" shouted Mr. Windibank,\nturning white to his lips and glancing\nabout him like a rat in a trap.\n\"Oh, it won't do really it won't,\u201d\nsaid Holmes suavely. \"There is no pos-\nsible getting out of it, Mr. Windibank.\nIt is quite too transparent, and it was\na very bad compliment when you said\nthat it was impossible for me to solve\nso simple a question. That's right! Sit\ndown and let us talk it over.\"\nOur visitor collapsed into a chair, with\na ghastly face and a glitter of moisture\non his brow. \"It\u2014it's not actionable,\" he\nstammered.\nAs I expected, his reply was typewritten\nand revealed the same trivial but charac-\nteristic defects. The same post brought\nme a letter from Westhouse & Marbank,\nof Fenchurch Street, to say that the de-\nscription tallied in every respect with\nthat of their employe, James Windibank.\nVoila tout\" \"And Miss Sutherland?\" \"If I\ntell her she will not believe me. You may\nremember the old Persian saying, 'There\nis danger for him who taketh the tiger\ncub, and danger also for whoso snatches\na delusion from a woman.' There is as\nmuch sense in Hafiz as in Horace, and as\nmuch knowledge of the world.\"\nA.2 Extract from Silver Blaze by Arthur Conan Doyle\nCulprit: John Straker\nPoint of Reveal:\nI am afraid, Watson, that I shall have\nto go,\" said Holmes, as we sat down\ntogether to our breakfast one morning.\n\"Go! Where to?\" \"To Dartmoor; to\nKing's Pyland.\"\n\"The real murderer is standing immedi-\nately behind you.\" He stepped past and\nlaid his hand upon the glossy neck of the\nthoroughbred.\n\"The horse!\" cried both the Colonel and\nmyself.\n\"Yes, the horse. And it may lessen his\nguilt if I say that it was done in self-\ndefence, and that John Straker was\na man who was entirely unworthy of\nyour confidence. But there goes the\nbell, and as I stand to win a little on\nthis next race, I shall defer a lengthy\nexplanation until a more fitting time.\"\nMy eyes fell upon the sheep, and I asked\na question which, rather to my surprise,\nshowed that my surmise was correct.\n\"When I returned to London I called upon\nthe milliner, who had recognised Straker\nas an excellent customer of the name\nof Derbyshire, who had a very dashing\nwife, with a strong partiality for expen-\nsive dresses. I have no doubt that this\nwoman had plunged him over head and\nears in debt, and so led him into this mis-\nerable plot.\" \"You have explained all but\none thing,\" cried the Colonel \"Where was\nthe horse?\" \"Ah, it bolted, and was cared\nfor by one of your neighbours. We must\nhave an amnesty in that direction, I think.\nThis is Clapham Junction, if I am not mis-\ntaken, and we shall be in Victoria in less\nthan ten minutes. If you care to smoke\na cigar in our rooms, Colonel, I shall be\nhappy to give you any other details which\nmight interest you."}]}