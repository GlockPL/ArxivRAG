{"title": "Generative AI for Internet of Things Security: Challenges and Opportunities", "authors": ["Yan Lin Aung", "Ivan Christian", "Ye Dong", "Xiaodong Ye", "Sudipta Chattopadhyaya", "Jianying Zhou"], "abstract": "As Generative AI (GenAI) continues to gain prominence and utility across various sectors, their integration into the realm of\nInternet of Things (IoT) security evolves rapidly. This work delves into an examination of the state-of-the-art literature and practical\napplications on how GenAI could improve and be applied in the security landscape of IoT. Our investigation aims to map the current\nstate of GenAI implementation within IoT security, exploring their potential to fortify security measures further. Through the\ncompilation, synthesis, and analysis of the latest advancements in GenAI technologies applied to IoT, this paper not only introduces\nfresh insights into the field, but also lays the groundwork for future research directions. It explains the prevailing challenges within\nIoT security, discusses the effectiveness of GenAI in addressing these issues, and identifies significant research gaps through MITRE\nMitigations. Accompanied with three case studies, we provide a comprehensive overview of the progress and future prospects of\nGenAI applications in IoT security. This study serves as a foundational resource to improve IoT security through the innovative\napplication of GenAI, thus contributing to the broader discourse on IoT security and technology integration.\nKeywords: Generative AI for Cyber Security, Large Language Models for Cyber Security, Artificial Intelligence for Cyber\nSecurity, Internet of Things Security, MITRE ATT&CK ICS Mitigations", "sections": [{"title": "1. Introduction", "content": "The development of Generative AI (GenAI) and Large Lan-\nguage Models (LLMs) signifies an advancement in artificial in-\ntelligence, distinguished by its capability to generate diverse\ncontent, including texts, images, and code. This capability has\nbrought GenAI tools into the spotlight, facilitating their integra-\ntion into daily life to address various pertinent issues and tasks.\nGiven their utility in tasks such as data analysis and content\ngeneration, GenAI and LLMs are actively explored for their\npotential in more complex applications. GenAI has garnered\nsignificant attention in the field of cyber security, with recent\nstudies underscoring its potential to enhance security measures,\nsimulate attacks for training and testing, and refine threat de-\ntection systems through advanced data analytics. Examples in-\nclude studies conducted by Sedjelmaci et al. [1], Gupta et al.\n[2], and Hassanin and Moustafa [3], all of which focus on the\npotential advantages that GenAI could offer as a tool to auto-\nmate various complex security tasks.\nInternet of Things (IoT) is increasingly recognized as a criti-\ncal area requiring detailed attention and innovative approaches,\nas IoT devices become more integrated into daily life and indus-\ntrial systems. As IoT devices are heterogeneous in nature, the\nsecurity of these devices requires specialized knowledge and\nexpertise. GenAI has the potential to enhance existing methods\nor develop new approaches for IoT security, thereby reducing"}, {"title": "1.1. Internet of Things (IoT)", "content": "IoT is a transformative concept in connectivity, where an ex-\ntensive network enables devices ranging from household ap-\npliances to medical equipment to connect directly to the In-\nternet, facilitating seamless data exchange without human in-\ntervention. This innovation has broad applications in smart\nhomes, healthcare, transportation and urban development, sig-\nnificantly improving operational efficiency Kimani et al. [4].\nAlwahedi et al. [5], Chui et al. [6] present a similar perspec-\ntive, who describe the IoT as a network that connects physical\nobjects through embedded sensors and software. This config-\nuration not only facilitates the exchange of real-time data, but"}, {"title": "1.2. IoT Security Challenges", "content": "The potential vulnerabilities of IoT devices pose a significant\nsecurity threat to IoT ecosystems. Their interconnected nature\nexposes them to a variety of cyber threats, data breaches, and\nprivacy violations Hassija et al. [7]. Insufficient security up-\ndates, inadequate security measures, and difficulties in manag-\ning dynamic device configurations are among the most common\nsecurity issues. These vulnerabilities mainly consist of commu-\nnication vulnerabilities, operating system vulnerabilities, and\nsoftware vulnerabilities. There is an ongoing research effort to\nenhance the overall security of IoT to effectively address these\nissues.\nThe diverse application of IoT devices, from home automa-\ntion to medical systems, makes them an attractive target for ma-\nlicious activity. Therefore, it is imperative to implement protec-\ntive measures such as authentication protocols, intrusion detec-\ntion systems, and machine learning algorithms to fortify these\nnetworks against potential threats. Various methods have been\nemployed to address these issues, including deep learning Hus-\nsain et al. [8] and blockchain technology Sultan et al. [9]."}, {"title": "1.3. Generative AI and Large Language Models", "content": "In the context of GenAI development, LLMs could be viewed\nas a breakthrough in AI innovation due to their ability to gener-\nate, classify and reason based on the datasets with which they\nare trained Jo [10]. Through advancement in algorithms and\ncomputational power, GenAI has become increasingly impor-\ntant in a wide range of domains, including cyber security. With\nthe capability to generate novel data instances from learned pat-\nterns, this technology offers a revolutionary approach to data\nanalysis and simulation, demonstrating its potential for trans-\nformative applications in the digital world. LLMs, such as\nChatGPT OpenAI [11] and Gemini Wu et al. [12], represent a\nsignificant advancement in GenAI, particularly in the process-\ning and generation of natural language. These models have\nevolved to understand context, generate coherent responses,\nand even detect anomalies in text, making them invaluable tools\nthat extend beyond simple communication. LLMs demonstrate\nthe increasing sophistication of AI's ability to handle complex,\nnuanced tasks, mirroring human-like understanding and inter-\naction with large volumes of data."}, {"title": "2. Background", "content": "In recent years, cyber threats have highlighted the importance\nof developing adaptive defense mechanisms against evolving\nattack vectors to prevent situations such as a botnet attack by\nadvanced persistent threat (APT) Daws [13]. As the cyber se-\ncurity landscape evolves, GenAI has emerged as an essential\ntool for enhancing security measures. GenAI, characterized by\nits ability to produce new content that mimics real-world phe-\nnomena, facilitates a spectrum of security applications, from\npassive threat detection to active mitigation.\nIn the realm of security, the evolution of GenAI has under-\nscored its role as a double-edged sword. On the one hand, these\ntechnological advances represent a significant step forward in\ndigital transformation, enhancing security through automated\nresponses, threat intelligence, and malware detection Gupta\net al. [2]. Their ability to generate highly realistic content across\nvarious mediums illustrates the potential to increase threat de-\ntection and response measures. On the other hand, the same ca-\npabilities that contribute to security enhancements also present\nnew vulnerabilities, as GenAI models have been exploited by\nrogue actors for offensive purposes. This includes generat-\ning deepfake videos for disinformation campaigns, crafting\nconvincing phishing emails, and spreading misinformation on\nsocial media, introducing new challenges and risks Eze and\nShamir [14], Mitra et al. [15]."}, {"title": "2.1. Evolution of AI in Security", "content": "In this section, we briefly review the landscape of AI within\ncyber security research."}, {"title": "2.1.1. Machine Learning (ML)", "content": "Detection methods in network security initially relied on tra-\nditional machine learning algorithms in the early days. These\nmethods process large volumes of log data, identify specific\npatterns, and perform verification. Techniques such as linear re-\ngression and decision trees effectively handle massive data and\nwork well in practical applications. For example, some machine\nlearning-based intrusion detection systems (IDS) analyze user\nor device behavior to identify abnormal patterns. Security op-\neration centers (SOC) use machine learning to detect abnormal\nactivities that deviate from normal behavior. These methods en-\nhance efficiency and flexibility in security monitoring, enabling\nreal-time threat detection. However, the analysis of patterns and"}, {"title": "2.1.2. Deep Learning (DL)", "content": "With larger and more complex behaviors being collected, the\nlimitations of traditional ML methods become apparent in terms\nof the models' capabilities to predict, classify, and learn effec-\ntively. There arises a need to solve more robust, comprehensive,\nand large-scale problems that ML algorithms would have diffi-\nculty solving. The evolution of ML is followed by the devel-\nopment of deep learning (DL) algorithms, which address more\ncomplex problems such as image recognition Alzubaidi et al.\n[17], sentiment analysis Zhang et al. [18], deep anomaly detec-\ntion Pang et al. [19], and natural language processing Ghosh\net al. [20]. The ability of deep learning to solve more complex\nproblems has become a foundation for further improvements."}, {"title": "2.1.3. Generative Adversarial Networks (GANs)", "content": "Following the adoption of DL, Generative Adversarial Net-\nworks (GANs) have introduced a novel dimension to cyber se-\ncurity. The application of GANs is twofold: enhancing se-\ncurity defenses by increasing their ability to detect sophisti-\ncated threats Park et al. [21], Yinka-Banjo and Ugot [22], and\ncontributing to the development of complex threats such as\nAI-driven malware or phishing emails. A growing number\nof attacks are leveraging AI-driven techniques as threat actors\nevolve their strategies. This approach, when combined with\nconventional attack methods, enables attackers to inflict even\ngreater damage Kaloudi and Li [23]."}, {"title": "2.1.4. Recent Application of GenAI", "content": "Generative Pre-trained Transformers (GPTs) represent the\nlatest advancement in this evolution, extending the capability\nof AI into natural language processing. This development has\na notable contribution to security, as it could be used to en-\nhance security, for example, by developing robust security poli-\ncies to protect against ransomware attacks. A study compar-\ning GPTs with conventional policy-making sources found that\nGPT-generated policies outperform those derived from security\nvendors and government agencies in terms of effectiveness and\nethical compliance, particularly with tailored input and expert\noversight McIntosh et al. [24]. GPTs could also be used to in-\nvestigate the potential for AI misuse Renaud et al. [25], such\nas generating malware using LLMs Pa Pa et al. [26], Greshake\net al. [27]. Indirect prompt injection facilitates remote exploita-\ntion of LLM-integrated applications, posing threats such as data\ntheft and contamination of information ecosystems. Several\npractical demonstrations emphasize the risks associated with\nthe execution of arbitrary code and the manipulation of func-\ntionality."}, {"title": "2.2. Applications of GenAI in Security", "content": "GenAI has significantly transformed security practices by in-\ntroducing advanced capabilities for threat detection, simulation,\nand data protection. The applications of GenAI in this domain\ninclude, but are not limited to, the following:"}, {"title": "Enhanced Threat Intelligence:", "content": "The GenAI model is able to\nanalyze large amounts of data to predict and simulate emerging\nthreats, providing security professionals with information on\npotential vulnerabilities and attack vectors Gupta et al. [28], Al-\nwahedi et al. [5]. Organizations must understand the character-\nistics of new and evolving threats to prepare more effectively\nand ensure that they remain one step ahead of cybercriminals."}, {"title": "Sophisticated Phishing Attack Simulations:", "content": "GenAI assists in\nthe development of more effective training programs due to its\nability to generate convincing phishing emails and social engi-\nneering tactics Bethany et al. [29]. Employees are educated\nabout the nuances of phishing attacks through these simula-\ntions, thereby significantly reducing the likelihood of successful\nbreaches."}, {"title": "Automated Security Testing:", "content": "GenAI could automate the cre-\nation of test cases for secure software, ensuring that applica-\ntions are robust against a wide range of attacks Hilario et al.\n[30], Deng et al. [31]. This involves generating malicious in-\nputs to test the resilience of systems to injection attacks and\nother vulnerabilities. This capability is crucial in sectors such\nas banking and e-commerce, where identity theft poses signifi-\ncant risks."}, {"title": "Synthetic Identity Fraud Detection:", "content": "GenAI models could\nhelp in designing algorithms that detect and prevent fraudu-\nlent activities by understanding patterns of synthetic identity\nfraud Ahmadi [32]."}, {"title": "Adaptive Defense Mechanisms:", "content": "GenAI models are capable\nof simulating a variety of attack scenarios, enabling security\nsystems to create dynamic defensive strategies Neupane et al.\n[33], Kucharavy et al. [34]. This approach helps to develop\nresilient systems that could defend against sophisticated and\nadaptive threats. Sai et al. [35] describe ten security products\nthat leverage GenAI to enhance their security measures. These\ninclude Google Cloud Security AI Workbench, Microsoft Se-\ncurity Copilot, and SentinelOne Purple AI. Additionally, 11\napplications of GenAI were identified in the security domain,\nincluding threat intelligence, security questionnaires, bridging\nthe gap between technical experts and non-experts, vulnerabil-\nity scanning and filtering, and secure code generation."}, {"title": "2.3. Applications of GenAI in IoT Security", "content": "As researchers explore applications and investigations in-\nvolving GenAI, we observe early works, though emerging, on\nthe use of GenAI in IoT security given the increasing prevalence\nof IoT devices and their vulnerabilities. Therefore, further in-\nvestigation is necessary on how GenAI could be integrated to\nimprove IoT security measures and strategies. Relevant pub-\nlications have been gathered to compile and explore this area,\nexamining how GenAI could address IoT security. Our find-\nings highlight useful ideas and set the stage for future research\nin this area."}, {"title": "3. Survey Methodology", "content": "Our research methodology focuses on gathering papers from\nconferences, journals, workshops, and publications centered\non or related to our investigation on the application of GenAI\nfor IoT security. Our search process includes several different\nsearch methods, databases, and search engines to ensure that\nwe collect as much relevant work as possible."}, {"title": "3.1. Search Methods", "content": "We used a structured approach in our literature search to have\na comprehensive coverage and relevance of our survey on the\nintersection of GenAI and IoT security.\nOWASP Framework Insights: Our search strategy was en-\nriched by the inclusion of keywords from the OWASP IoT Top\n10 and GenAI-related terms, such as \u201cweak passwords + IoT +\nLarge Language Model\u201d. This approach uncovers research ad-\ndressing the security challenges identified by OWASP and areas\nyet to be explored by GenAI solutions. By analyzing the find-\nings from these searches, we evaluated the potential role that\nGenAI could play in enhancing IoT security.\nMITRE ATT&CK Framework Integration: We also in-\ncorporated the MITRE ATT&CK framework, focusing on tac-\ntics and techniques pertinent to Industrial Control Systems\n(ICS). The application of ICS matrix from this framework\nprovided a structured approach for identifying and analyzing\nthreats specific to the Industrial Internet of Things (IIoT) sec-\ntor. Keywords such as \"hardcoded credentials + IoT + LLMS\"\nwere employed to refine our search, ensuring a focused exami-\nnation of the literature."}, {"title": "3.2. Sources", "content": "As part of the compilation of our sources for the application\nof GenAI in IoT security, we systematically gathered research\nfrom various conferences and journals, enhanced by contribu-\ntions from leading academics and expanded searches in public\nrepositories. During the selection process, we sought to include\nworks that have made significant contributions to cyber security\nand IoT, which have been subjected to rigorous peer reviews\nand are relevant to our study.\nAcademic Publications: We prioritized the sourcing of\nconferences and journals well known for their contributions to\ncyber security and IoT. This included key venues such as IEEE\nTransactions on Dependable and Secure Computing (TDSC),\nTransactions on Information Forensics and Security (TIFS), In-\nternational Journal of Critical Infrastructure Protection (IJCIP),\nTransactions on the Internet of Things (TIOT), IoT Journal,\nComputers & Security, and ACM Transactions on Privacy and\nSecurity (TOPS). Each source was selected for its relevance,\nrigorous peer review, and ability to provide the most recent and\nimpactful research findings.\nOther Sources: Considering all the recent research on\nGenAI, there are likely many studies yet to be accounted for in\npublications. As such, papers available on arXiv are considered\nas a possible source of contributions if the papers have relevant\nimplementations and results. We have also looked into possible"}, {"title": "4. Source Analysis Using MITRE ATT&CK ICS Mitiga- tion Techniques", "content": "We rely on ATT&CK ICS Mitigations framework MITRE\n[36] to categorize the techniques used in the sources as illus-\ntrated in Figure 1. IoT systems have similar, if not all, methods\nto compromise them as ICS. Although sources may not directly\naddress the issue in the context of IoT, they are included due to\ntheir relevance.\nIn the following subsections, we first explain the details and\nfindings about the mitigation techniques. It should be noted\nthat there are some overlaps, as a study might address more\nthan one mitigation technique. Subsequently, we provide the\npotential for using GenAI to secure IoT networks and systems.\nEach work is discussed according to the following capabilities:\n\u2022 External Threat Detection (ETD) refers to the ability of\nGenAI to detect or prevent external threats, be malicious\nor aimed at scanning vulnerabilities (e.g., fuzzing).\n\u2022 Internal Anomaly Detection (IAD) measures GenAI's\nability to identify and detect anomalies within the system,\nsuch as secure coding practices, vulnerabilities in software\nor hardware components.\n\u2022 Response Automation (RA) measures the ability of\nLLMs to generate an automated response based on their\nfunctions. These responses could take the form of alerts,\ndocuments, or software patches, ultimately improving the\nsecurity of the IoT system.\n\u2022 Research Maturity (RM) measured by the security field\nthat GenAI addresses and potentially improves. Each\nGenAI focuses on a specific security niche and aims to\nresolve existing issues within that niche. If the field is\nnot well explored, it indicates low research maturity and is\nripe for exploration and development. In contrast, if estab-\nlished standards or tools are available to improve system\nsecurity, the niche exhibits high maturity.\n\u2022 Development Potential (DP) measures GenAI's poten-\ntial for further development of the current implementation\nevaluated based on the tool's ability to address specific\nsecurity functions. In particular, GenAI application with\nhigh DP implies that the application itself has the poten-\ntial to be scaled or extended towards other security func-\ntion while low DP means the application is self-contained\nand rather complete.\n\u2022 Impact on Security (IS) refers to the significance and\nscope that the proposed GenAI tool is capable of address-\ning in the security field.\nIt is important to note that certain capabilities are mutually\nexclusive. For instance, a particular GenAI application may"}, {"title": "4.1. Application Developer Guidance", "content": "This section discusses the use of GenAI to guide software de-\nvelopers in creating secure software from the outset. The tool\nhelps developers by providing guidance on secure software de-\nvelopment or preparing development policies for software se-\ncurity. Since most IoT devices and systems consist of a signif-\nicant portion of software, this would benefit developers of IoT\ndevices and systems.\nLLMSecGuard Kavian et al. [37] focuses on minimizing\nvulnerabilities and hard-coded credentials in production code.\nThrough the use of a static code analyzer, LLMSecGuard itera-\ntively analyzes the code to identify vulnerabilities. The code\nand analysis results are then presented to developers to cre-\nate secure software that demonstrates the capabilities of LLMs.\nA fine-tuned LLMSecGuard could be used to assist in secure\nsoftware development for IoT systems. For example, incorpo-\nrating LLMSecGuard as part of the testing phase during soft-\nware development ensures code security for software in the IoT.\nThis enables developers to create secure software without hard-\ncoded credentials or keys oversight. The impact of LLMSec-\nGuard on the security field is limited to automating the patching\nprocess.\nLLift Li et al. [38] investigated Use Before Initialization (UBI)\nvariables within the Linux kernel to uncover any bugs. LLift\nhas a 50% precision rate, with 5 out of 10 reported positives\nbeing true vulnerabilities. It also has a 100% recall rate, as\nit did not misidentify any real bugs in the Rnd-300 dataset Li\net al. [39]. LLift helps users create secure code by identifying\nUBI bugs. LLift could be implemented for IoT systems running\nembedded Linux, effectively identifying UBI bugs. By fine-\ntuning LLift, developers could remove UBI bugs during testing\nand production, enhancing coding security, and mitigating risks\nin IoT systems.\nThe development potential for LLift includes adding an auto-\nmated patcher and improving explainability and live detection.\nUBI bugs are critical in Linux kernels, potentially leading to\nprivilege escalation and information leakage. LLift is among\nthe few tools that address UBI bugs and its role in detecting\nthese bugs is crucial for IoT security, especially given the use\nof embedded Linux by various vendors. With further improve-\nments, LLift could significantly impact IoT security by effec-\ntively patching UBI bugs.\nHuntGPT Ali and Kostakos [40]: GenAI, LLMs in partic-\nular, remains a black box in terms of its training and decision-"}, {"title": "4.2. Exploit Protection", "content": "This section describes the application of GenAI to protect\nsystems from exploits. Protection could be achieved by block-\ning code execution and automated scripts. LLMs could high-\nlight important components and automate the hardening of sys-\ntem security in IoT environments.\nLLMind Cui et al. [44] is an assistant that could perform com-\nplex tasks on an IoT network, acting as a gateway to control\nvarious devices. It is used to control a Wi-Fi router, a mobile\nrobot, and security cameras in a smart home system. Imple-\nmentation of LLMind is similar to giving prompts to a secre-\ntary, who then executes tasks based on generated finite-state\nmachine code. The study shows that LLMind successfully per-\nformed tasks such as object detection, human recognition, and\nreport generation. Although not directly related to security, LL-\nMind has the potential to protect systems from exploits by ex-\necuting device-specific security hardening techniques. For ex-\nample, it could update the allowed IP list for a security camera\nif an unauthorized remote connection is detected. This poten-\ntial of LLMind to receive prompts, generate scripts, and execute\nthem could be exploited for the security of IoT. LLMind is able\nto complete tasks autonomously for the given queries and could\nbe improved to execute security-specific tasks. The tool's cur-\nrent impact on security is limited due to its specific capabilities\nin physical and network protection.\nWang et al. [45] experimented with preventing attackers from"}, {"title": "4.3. Limit Hardware Installation", "content": "LLMs could be utilized to restrict additional installations in\nan IoT system by employing an observer, such as a CCTV,\nto ensure the integrity of the physical installation and prevent\nunauthorized USB devices from being inserted. Although not\nall studies directly address this mitigation technique for IoT,\nthis section explores its potential use based on existing research.\nVIoTGPT Zhong et al. [49]: To limit the installations of\nrogue devices, the traditional method uses CCTV to monitor the\nsystem. However, this lacks intelligent alerts to detect anoma-\nlies. VIoTGPT combines LLM with a vision-based model to\nhandle tasks involving images and text queries. It uses tools\nfor face recognition, vehicle re-identification, anomaly detec-\ntion, and action recognition, all fine-tuned with specific domain\nknowledge. The output includes decisions, recommended tools,\nand tool output descriptions. Fine-tuned with public video\ndatasets, web-scraped data, and self-made datasets, VIoTGPT\nidentifies and describes tasks such as anomaly detection and\naction analysis with 30-50% accuracy in the test set and 60-\n70% accuracy in the validation set. By integrating LLM and\nimage-based models, VIoTGPT could create descriptions and\nrecommend tools for certain tasks.\nFor IoT systems, VIoTGPT's anomaly detection could mit-\nigate insider threats by identifying actions like inserting rogue\ndevices. This allows VIoTGPT to alert users of potential threats\nand limit hardware installations, preventing rogue devices with\nmalicious programs from being connected to the IoT system.\nVIOTGPT requires human prompts and automatically provides"}, {"title": "4.4. Mechanical Protection Layers", "content": "This section discusses the application of LLM to enhance\nthe protection of the mechanical layer in IoT, pertaining to the\nhardware of IoT devices. This encompasses the security of the\ndesign and physical safeguarding of IoT devices exploring the\npotential of LLM to aid in designing secure hardware.\nSaha et al. [50]: A critical aspect of IoT systems is hardware\ndesign, which could inherently contain vulnerabilities. A vul-\nnerable design could be exploited at the hardware level, mak-\ning it difficult for software to prevent access by malicious ac-\ntors. In their study, Saha et al. trained an LLM to critique the\ndesign of system-on-chip (SoC) integrated circuits to evaluate\ntheir security. Although not specifically focused on IoT, this\nstudy demonstrates the potential of LLM to assess the security\nof SoC design. Tests such as security verification, countermea-\nsure development, security assessment, and vulnerability inser-\ntion were conducted to create a more secure SoC. These tests\nare crucial because SoC security depends on a human-mistake-\nfree and vulnerability-free initial design. LLM's adaptability\nallows for dynamic implementation of security tasks in SoC\ndesign. The study also suggests that LLM could improve the\nsecurity of current and future SoC designs, helping to patch\nhardware design vulnerabilities in IoT devices and systems.\nThe proposed tool addresses T0880 tactic and prevents vul-\nnerabilities and exploits from hardware design. Its response\nautomation capabilities depend heavily on user instructions and\nsecurity rules. In terms of research maturity, very few works\naddress hardware design to improve security. The development\npotential includes full automation of design critique to mini-\nmize user inputs and support diverse security standards. Design\ncritique and improvement could defend against zero-day vul-\nnerabilities from hardware weaknesses and prevent hardware\nexploits and side-channel attacks. This is the only LLM im-\nplementation that addresses possible exploits in an IoT setting\nusing Mechanical Protection Layers."}, {"title": "4.5. Network Intrusion Prevention", "content": "This section explains how LLM protects IoT systems from\nnetwork intrusions in ICS by using network intrusion detection\nor prevention modules. Although not all studies focus on IoT,\ntheir potential for IoT implementation is discussed.\nBERTIDS G. Lira et al. [51] is a LLM-based tool for net-\nwork intrusion detection. It processes and understands net-\nwork log data to identify and classify anomalies. BERTIDS is\nadaptive and continuously learns new behavior to combat new\nthreats, allowing it to detect network attacks that evade rule-\nbased detectors. Using the NSL-KDD dataset Tavallaee et al.\n[42], BERTIDS achieved the highest accuracy, precision, and\nF1 score (above 98%) compared to other methods. Although"}, {"title": "4.6. Software Update", "content": "This section outlines studies and experiments aimed at mit-\nigating attacks and enhancing security by patching vulnerabil-\nities and updating software within IoT systems. Although not\nall studies directly address improving IoT security using LLM,\nthere is potential for further research and exploration to con-\ntribute to IoT security.\nIslam et al. [55] proposed an LLM-based tool to patch vul-\nnerable code. The LLM is trained using semantic reward and\nreinforcement learning. It takes C code as input and produces\na patched version with fewer or no vulnerabilities. The study\nshows successful patching of vulnerabilities that improve the\nsecurity of IoT devices by preventing initial access points for\nattackers. There is potential in this work to ensure that IoT\nsoftware, possibly at the firmware or operating system level,\nhas minimal vulnerabilities. The study demonstrates that the\npatch fixes common and known vulnerabilities, indicating a fur-\nther potential for LLM to improve in terms of fixes. The LLM\ncould be trained using open source datasets, such as Automated\nCVEFixes by Bhandari et al. [56], that focus on IoT. With\ndatasets specializing in IoT, the LLM can be further trained to\npatch software that prevents the exploitation of public-facing\ndevices. LLM could be applied as a tool for automated vulner-\nability patching to address security weaknesses in the context\nof the IoT. The tool is capable of autonomously patching vul-\nnerable code with minimal human input. Potential for further\nimprovements include additional modules for automated imple-\nmentation or replacement tasks. Its impact on security is high,\nincreasing efficiency and effectiveness in software security im-\nprovement.\nDefectHunter Wang et al. [57] is another LLM-based imple-\nmentation for patching vulnerabilities. It serves a similar pur-\npose to Islam et al. [55] since both use LLMs to repair and\npatch vulnerable code. However, DefectHunter differs in its de-\nsign, utilizing attention models instead of reinforcement learn-\ning and semantic rewards. Both studies demonstrate that cur-\nrent LLMs could effectively patch vulnerable code when given\nas prompts. To apply LLM to IoT, it is necessary to incorporate\nIoT-specific training datasets, such as the QEMU dataset Zhou\net al. [58], Pongo-70B Jin [59], and CWE-754 dataset NVD\n[60]. This would enable the LLM to understand and patch IoT-specific vulnerabilities and defects. Potential improvements\ninclude modules to optimize processing time and training the\nmodel with IoT-specific dataset. Its impact on security is sig-\nnificant due to the automation of vulnerability patching, which\nallows faster software review and more efficient code produc-\ntion, leading to a more secure system."}, {"title": "4.7. Threat Intelligence Program", "content": "This section outlines the research conducted on LLMs to mit-\nigate attacks by developing threat intelligence policies. These\nmitigation efforts encompass various approaches, including the\nformulation of security policies for organizations and incident\nresponse plans.\nAttackGen Adams [61] is an LLM-powered incident response\ntool that helps organizations prepare for cyber attacks by un-\nderstanding possible attack vectors. It automatically generates\nthese scenarios based on industry type, attack vectors, and or-\nganization size. AttackGen uses these parameters to create de-\ntailed incident response scenarios, with OpenAI as the default\nmodel. In its default setting, AttackGen could generate general\nincident response plans and evaluation metrics. It is a viable\ntool for generating threat intelligence to mitigate attacks. Ex-\ntending it to IoT systems would involve modifying the prompt\nto focus on the IoT context. This could help generate specific\nincident response plans for IoT. AttackGen helps prevent ex-\nternal threats by providing incident reports and playbooks for\nuser training, addressing potential attacks and protection meth-\nods with potential for further specialization and contextual rel-\nevance. Its impact on security is high due to its pioneering role\nin automated report generation and playbook creation, signifi-\ncantly affecting the field of security. Section 5 discusses a case\nstudy on AttackGen with the necessary modifications for IoT\nimplementation.\nMcIntosh et al. [24] investigated whether GPTs could generate\nbetter cyber security policies than humans. Using a ransomware\nattack as a case study, they found that GPTs outperformed hu-\nmans in terms of completeness, effectiveness, and efficiency.\nGPTs scored higher on these metrics, indicating that they could\ngenerate more secure policies. Although not yet tested in IoT,\nthe results suggest that GPTs could also be effective in this con-\ntext. Transfer learning could also further enhance the LLM fo-\ncus on IoT, potentially leading to GPTs outperforming human\npolicies in this area. Its impact on security is significant due to\nits novelty and effectiveness."}, {"title": "4.8. User Training", "content": "This section explains how LLMs have been used in studies\nto improve human skills in IoT security, similar to concepts in\ngeneric cyber security. LLM applications focus on improving\nawareness of common exploitation methods, such as phishing\nemails and social engineering.\nBethany et al. [29] implemented LLM to generate spear-\nphishing emails to gain access to the system. Over 11 months,"}, {"title": "4.9. Vulnerability Scanning", "content": "This section explains how LLMs could enhance IoT security\nby identifying and fixing vulnerabilities in devices. It covers\nboth finding and fixing these vulnerabilities, including secu-\nrity testing during development to prevent issues before deploy-\nment.\nLLM4Vuln Sun et al. [63] studied the reasoning abilities of\nLLM to identify vulnerabilities and understand the key com-\nponents affecting this process. The authors focused on smart\ncontracts and identified knowledge retrieval, tool invocation,\nprompt schemes, and instruction following as critical factors.\nThe experimental results showed that knowledge retrieval is\ncrucial and that GPT-4 performed best among LLMs. Us-\ning LLM4Vuln, nine zero-day vulnerabilities in bug bounty\nprograms were identified. This work suggests that applying"}, {"title": "5. Case Study", "content": "This section discusses three case studies: AttackGen Adams\n[61", "46": "and ChatIoT Dong et al.\n[79"}]}