{"title": "RS-MOCO: A deep learning-based topology-preserving image registration method for cardiac T1 mapping", "authors": ["Chiyi Huang", "Longwei Sun", "Dong Liang", "Haifeng Wang", "Hongwu Zeng", "Yanjie Zhu"], "abstract": "Cardiac T1 mapping can evaluate various clinical symptoms of myocardial tissue. However, there is currently a lack of effective, robust, and efficient methods for motion correction in cardiac T1 mapping. In this paper, we propose a deep learning-based and topology-preserving image registration framework for motion correction in cardiac T1 mapping. Notably, our proposed implicit consistency constraint dubbed BLOC, to some extent preserves the image topology in registration by bidirectional consistency constraint and local anti-folding constraint. To address the contrast variation issue, we introduce a weighted image similarity metric for multimodal registration of cardiac T1-weighted images. Besides, a semi-supervised myocardium segmentation network and a dual-domain attention module are integrated into the framework to further improve the performance of the registration. Numerous comparative experiments, as well as ablation studies, demonstrated the effectiveness and high robustness of our method. The results also indicate that the proposed weighted image similarity metric, specifically crafted for our network, contributes a lot to the enhancement of the motion correction efficacy, while the bidirectional consistency constraint combined with the local anti-folding constraint ensures a more desirable topology-preserving registration mapping.", "sections": [{"title": "1. Introduction", "content": "Magnetic resonance cardiac T1 mapping is a useful technique that quantitatively assesses the longitudinal relaxation time (T1) of myocardial region. The obtained myocardial T1 map can be used as a pathophysiological biomarker in various cardiac diseases, such as diffuse myocardial fibrosis [1], myocardial infarction [2], and cardiac amyloidosis [3]. Typical cardiac T1 mapping techniques include MOLLI [4], SASHA [5], and STONE [6]. These techniques acquire several cardiac T1-weighted (T1w) images with differ-ent inversion times (TIs) using electrocardiogram gating. Subsequently, pixel-wise curve fitting is applied to multiple T1w images to obtain myocardial T1 maps. However, due to the non-rigid motion of the heart, misalignment in myocardial position and shape between different T1w images can result in significant motion artifacts in the fitted T1 maps, leading to errors in myocardial T1 quantification.\nTo mitigate this impact, image registration is commonly per-formed to align the myocardial region of multiple T1w images. Nevertheless, there exist substantial and non-uniform contrast variations between T1w images with different TIs, making myocardial registration challenging. As shown in Fig. 1, the signal intensities of the myocardium, blood pool, and fat vary with TIs and experi-ence signal nulling at different inversion times [7]. Distinguishing myocardium from the blood pool is difficult when they manifest similar signal intensities (shown in Fig. 1(3)), resulting in registra-tion errors in these regions. In other words, these multi-modality image characteristics make traditional intensity-based registration methods inadequate in effectively solving the motion correction issue in cardiac T1 mapping.\nTo address this issue, Roujol et al. [8] simultaneously esti-mated motion fields and intensity variations using adaptive affine registration and refined deformable registration. However, specific parameter settings may not meet the correction requirements for all motion artifact scenarios. Huizinga et al. [9] and Tao et al. [10] employed a groupwise registration approach based on principal component analysis to address motion correction in cardiac T1 mapping, avoiding the significant contrast variation issues faced by pairwise registration. Nevertheless, their approach did not consider topology preservation in deformation, which may lead to undesir-able warping. Zhang et al. [11] performed pairwise multimodal registration of cardiac T1w images using normalized gradient fields as the similarity metric and applied additional regularization con-straints to prevent erroneous deformations. El-Rewaidy et al. [12] proposed a non-rigid registration framework based on an active shape model for motion correction of cardiac T1 mapping. This method first extracts the myocardium contours using an active shape model and then performs contour-based registration on the myocardium. However, this method may fail in image registration due to the incorrect extraction results of myocardium contours. In recent years, deep learning-based registration methods have shown higher efficiency and robustness compared to traditional registra-tion algorithms and have gradually approached or even surpassed them in accuracy [13]. Gonzales et al. [14] proposed a groupwise motion correction network based on U-net, which predicts relative displacement vector fields between all T1w images in a ShMOLLI series, avoiding the challenges posed by large contrast variations, but is unable to correct severe motion artifacts. Li et al. [15] used sparse coding to achieve contrast separation and obtain T1w images with similar contrast for intensity-based registration. Inspired by disentangled representation learning, Yang et al. [16] decomposed cardiac qMRI images into anatomical representations and contrast representations to facilitate intensity-based registration.\nIn summary, both conventional and deep learning-based meth-ods either employ direct multi-modality image registration of cardiac T1w images or execute intensity-based registration through utilizing groupwise registration or synthesizing T1w images with little contrast differences. Although the aforementioned registration-based motion correction approaches have achieved promising results, most of them do not consider the topological preservation properties in the ideal registration mapping. Topological preser-vation means that the mapping between the moved image and the moving image should be continuous, invertible, and bijective. In terms of image appearance, this implies that the deformed image (moved) should exhibit consistent local topological structure and spatial correspondence with the original image (moving), and should not contain regions with discontinuities, folds, or abnormal distortions. It is noteworthy that topology-preserving registration refers to the process of aligning the anatomical structures within the moving image with their corresponding anatomical structures in the fixed image, in terms of both position and shape, without disrupting the local topology of the anatomical structures in the moving image. Furthermore, unique anatomical structures present only in the fixed image will not result in the emergence of equivalent structures in the deformed image (moved image), as these anatomical structures do not exist in the moving image. Additionally, studies have shown that using segmentation labels for supervised or semi-supervised registration can improve registration performance [17]. Attention modules incorporated into the backbone of convolutional neural networks also make efforts to the enhancement of network efficiency[18].\nTherefore, this paper proposes a deep learning-based, bidirec-tional consistent, and local neighborhood-consistent image regis-tration method for motion correction in cardiac T1 mapping. The main idea is to utilize a deformable registration network with an implicit regularization constraint (dubbed BLOC), which consists of a bidirectional consistency constraint and a local anti-folding constraint. BLOC constraint achieves topology preservation by employing the local anti-folding constraint to the predicted bidirec-tional deformation fields, and then inverting the two deformation fields to add consistency constraints between the original input image and its re-deformed image predicted by the network using the inversed deformation field on both sides. The proposed BLOC constraint ensures the invertibility and bijection of the registration mapping, thereby reducing abnormal deformations such as discon-tinuities, folds, or excessive distortions. To address the contrast variation issue, a weighted image similarity metric is designed for multi-modality image registration. Additionally, we integrate the dual-domain attention modules into the backbone network and leverage an additional semi-supervised myocardium segmentation network to perform weak supervision for the registration network, thereby improving registration accuracy. The main contributions of this paper are as follows:\n1. A deformable registration network with a dual-domain at-tention module and a weighted image similarity metric is proposed to effectively learn the multi-modality image reg-istration mapping of cardiac T1w images under significant and non-uniform contrast variations;\n2. A BLOC constraint is utilized in the deformable registration network to ensure the topology preservation in image regis-tration, bringing about more desirable non-rigid registration outcomes;\n3. An additional semi-supervised myocardium segmentation network is incorporated to provide weakly-supervised pseudo-labels of myocardium segmentation to assist the deformable registration network."}, {"title": "2. Related work", "content": "VoxelMorph [17, 19] is a deep learning-based medical image registration framework that is widely used and has established a foundation for subsequent research. For topology preservation in medical image registration, many studies [20-27] have been proposed. For example, ICNet [26] ensures the inherent inverse-consistent property for diffeomorphic mapping through the ap-plication of inverse-consistent and anti-folding constraints on the displacement vector field. CycleMorph [22] applied the cycle con-sistency constraint between the original moving image and its re-deformed image using two registration networks. SYMnet [24] simultaneously estimates two symmetric deformation fields and employs a combination of forward mapping and inverse backward mapping to guarantee the reversibility and inverse consistency of the registration mapping. Additionally, research has shown that deep learning-based image registration and segmentation may im-prove both performances by mutual supervised learning [28-30]. DeepAtlas [29] first proposed a joint learning of two deep neural networks for image registration and segmentation respectively, achieving significant improvements in segmentation and registra-tion accuracy.\nThe attention module is a special neural network that can be grafted into different positions of the backbone network. It applies different weights to different parts of the network in order to focus on important feature spaces or channels, thus capturing those most critical features from the input images. In recent years, the atten-tion module has rapidly evolved, encompassing spatial attention, channel attention, and self-attention, among others. The SE-Net introduced by Hu et al. [31] proposed a channel attention module that explicitly models the interdependencies between channels to recalibrate channel responses and focus on important channel infor-mation. Woo et al. [18] proposed an attention module that combines feature channels and spatial information, simultaneously attend-ing to important channel and spatial information. Furthermore, there is also the cross-modal attention module [32] designed for multimodal medical image registration, which establishes spatial correspondences between features from different modalities for capturing information more superiorly."}, {"title": "3. Method", "content": "The framework of the proposed RS-MOCO method consists of three components, as illustrated in Fig. 2 (a-c). The three com-ponents are: (1) an affine registration network (AffN) based on CNN(Convolutional Neural Network) (areas (a) in light green) for pre-training, achieving initial linear affine registration, (2) a weakly-supervised and topology-preserving deformable registra-tion network (RegN) based on U-net architecture (areas (b) in light yellow), and (3) a semi-supervised myocardium segmentation network (SegN) for providing pseudo-labels of myocardium seg-mentation for RegN, also based on U-net architecture (areas (c) in light blue). The input of the network is the pair of the moving image X and the fixed image Y. A_X is the output of the affine registration network, which registers X to Y, while M_YX and M_XY are the deformable registration results that register Y to A_X and A_X to Y."}, {"title": "3.1. Affine registration network (AffN)", "content": "Our method begins by utilizing a CNN-based affine registration network, AffN, to rectify linear misalignment among multiple Tlw images of cardiac T1 mapping. Pre-alignment using affine regis-tration may help address the severe misalignment which is hard to deal with using deformable registration [33-35]. Then, the six transformation parameters predicted by the proposed AffN can be applied to the spatial transformer network, STN [36], to execute the corresponding translation, scaling, and rotation on input images. STN is a differentiable module providing smooth deformed feature maps by employing bilinear interpolation. It can be inserted at any position within a convolutional network architecture.\nThe AffN can be parameterized as the following optimization problem:\n$A_ = \\underset{A}{\\text{argmin}} L_{dissim} (Y, F_A(X, A_g))$\nWhere represents the AffN, registering the moving image X to the fixed image Y with parameters A, illustrated in Eq (2), and $L_{dissim}$ denotes the image difference between Y and the moved image $F_A(X, A_g)$ after the affine transformation.\n$A_g = \\begin{bmatrix} a_{11} & a_{12} & a_{13} \\ a_{21} & a_{22} & a_{23} \\ \\end{bmatrix}$\nThe detailed network architecture is shown in Fig. 3. The AffN consists of six downsampling modules (ADSM) and two fully connected layers. Additionally, dropout layers are added at the end of the sixth downsampling block and the first fully connected layer to alleviate overfitting."}, {"title": "3.2. Deformable registration network (RegN)", "content": "3.2.1. Baseline design\nGenerally, the training process of deep learning-based regis-tration network training aims to minimize the difference between the original fixed image and the deformed moving image. In this study, the proposed RegN simultaneously predicts the bidirectional deformation fields from A_X to Y which is marked as $\u03a6_{XY}$ and from Y to A_X which is $\u03a6_{YX}$, as shown in Fig. 2 (b). To achieve this, RegN minimizes the differences of the following image pairs, which are connected by yellow dashed lines in Fig. 2 (b): direction (1): the input image A_X and the output image $M_{YX}$ which is warped from Y by STN [36] using $\u03a6_{YX}$, and direction (2): the input image Y and the output image $M_{XY}$ which is warped from A_X by STN [36] using $\u03a6_{XY}$. Typically, a regularization term, such as L2-norm, is applied to both $\u03a6_{XY}$ and $\u03a6_{YX}$ to control the smoothness of deformations and reduce folds, thereby guaranteeing the regis-tration process an ideal topology-preserving transformation [19]. However, the sole application of the L2-norm often fails to achieve satisfactory results. The excessive use of L2-norm as a global constraint may limit normal deformations and lead to a decrease in registration accuracy, while insufficient use cannot guarantee smoothness and bijection, making it challenging to preserve the topology.\n3.2.2. The BLOC constraint\nTo address the issue mentioned in section 3.2.1, we introduce the BLOC constraint which includes a bidirectional consistency constraint and a local anti-folding constraint. As marked with yellow dotted lines in Fig. 2 (b), the bidirectional consistency constraint minimizes the difference between the input image and its reversely predicted image which is warped from the output image using the inverse deformation field. Specifically, the proposed bidirectional consistency constraint minimizes the differences in the following image pairs in RegN: side (1): image A_X and its reversely predicted image $M_{XY\\_inv}$ which is warped from the output image $M_{XY}$ by STN using inverse deformation field $\u03a6_{XY}^{-1}$ of $\u03a6_{XY}$, and side (2): image Y and its reversely predicted image $M_{YX\\_inv}$ which is warped form the output image $M_{YX}$ by STN using the reverse deformation filed $\u03a6_{YX}^{-1}$ of $\u03a6_{YX}$. It is noteworthy that each value in the deformation field $\u03a6_{XY}$ and $\u03a6_{YX}$ respectively corresponds to the coordinate displacement of each pixel in the input images A_X and Y of RegN, while the values in the inverse deformation fields $\u03a6_{XY}^{-1}$ and $\u03a6_{YX}^{-1}$ should theoretically correspond to the pixel coordinate displacement of $M_{XY}$ and $M_{YX}$, which are obtained by warping from A_X and Y through the deformation fields $\u03a6_{XY}$ and $\u03a6_{YX}$. Therefore, to solve the inverse deformation fields $\u03a6_{XY}^{-1}$ and $\u03a6_{YX}^{-1}$ from $\u03a6_{XY}$ and $\u03a6_{YX}$, our study employs the deformation fields $\u03a6_{XY}$ and $\u03a6_{YX}$ to warp themselves respectively and then multiply them by -1, thereby establishing the elements' corresponding relationship between $\u03a6_{XY}^{-1}$ and $M_{XY}$, as well as between $\u03a6_{YX}^{-1}$ and $M_{YX}$. In doing so, the spatial transformer network (STN) is also used for the warping operation. In this design, the reversibility of the deformation field and the effectiveness of the reverse deformation field are collectively constrained to ensure the reversibility and bijection of the registration mapping, thereby achieving topology preservation.\nTo further limit local folds, our study also employs the local orientation consistency constraint [24] on the deformation fields $\u03a6_{xy}$ and $\u03a6_{yx}$ as the anti-folding constraint. For the anti-folding constraint, our method calculates the Jacobian matrix of the pre-dicted deformation fields $\u03a6_{xy}$ and $\u03a6_{yx}$, with the computation of the Jacobian matrix referencing Eq (3), in which $\\Phi_{x}(p)$ represents the partial derivative of the x-component $\u03a6_{x}(p)$ with respect to x at point p. Subsequently, the anti-folding constraint loss function is computed using the determinant of the Jacobian matrix. The positive Jacobian determinant leads to a bijective mapping which preserves the topology in the neighborhood while the negative\n$J_{\\Phi} (p) = \\begin{bmatrix} \\frac{\\partial \\Phi_x(p)}{\\partial x} & \\frac{\\partial \\Phi_x(p)}{\\partial y} \\\\ \\frac{\\partial \\Phi_y(p)}{\\partial x} & \\frac{\\partial \\Phi_y(p)}{\\partial y} \\end{bmatrix}$\nIn a word, RegN integrates the bidirectional consistency con-straint and the local anti-folding constraint as an overall regulariza-tion term dubbed BLOC, which jointly helps preserve the topology of the images before and after deformation.\n3.2.3. Network structure\nAs shown in Fig. 4, RegN is a 2D CNN architecture consisting of encoder and decoder modules with skip connections similar to VoxelMorph [17]. The final two parallel convolutional layers gen-erate symmetric dense displacement vector fields for bidirectional registration. RegN comprises an input layer, four downsampling blocks (DDSM), four upsampling blocks (DUSM), and two output layers. Each DUSM first establishes a skip connection between the feature maps from the previous DDSM of its same-level DDSM and the feature maps that have undergone one round of transpose convo-lution, followed by two convolutional layers. The last upsampling block is followed by two parallel convolutional layers serving as the network outputs. Additionally, a dual-domain attention module called Convolutional Block Attention Module (CBAM) [18] is incorporated at the end of the input layer and the last DUSM, thereby enhancing network performance.\n3.2.4. Weakly-supervised learning\nAs shown in Fig. 2 (b-c), RegN is essentially a weakly-supervised registration network, with its weak supervision information from the myocardium segmentation pseudo-labels derived from the myocardium segmentation network SegN. The specific implemen-tation details will be elaborated in section 3.4.2."}, {"title": "3.3. Myocardium segmentation network (SegN)", "content": "3.3.1. Network structure\nSegN builds upon the architecture of the widely-used U-net [37] and utilizes a similar structure with encoder and decoder components connected through skip connections. As shown in Fig. 5, the encoder of SegN consists of one input layer and four downsampling blocks (SDSM), while the decoder of SegN is composed of four upsampling blocks (SUSM) and one output layer. Each SUSM connects feature maps from the previous SDSM of its same-level SDSM and feature maps which are obtained from the previous SUSM and then undergone one round of transpose convolution, followed by two convolutional layers. The final layer of SegN is a 1\u00d71 convolutional layer, responsible for producing the segmentation map. Similar to previous network designs, the CBAM attention module is employed at the end of the input layer and the final SUSM.\n3.3.2. Semi-supervised learning\nSegN is a semi-supervised myocardium segmentation network whose labels are partly from manual myocardium segmentation labels and partly from deformed manual myocardium segmentation labels from RegN, with the loss function defined in section 3.4.3."}, {"title": "3.4. Loss function.", "content": "3.4.1. Loss function of AffN\nMean-Square Error (MSE), Normalized Cross Correlation(NCC), Mutual Information (MI) [38], Normalized Gradient Fields (NGF) [11, 39], and Modality Independent Neighborhood Descriptor (MIND) [40], are typically used as similarity loss functions in deep learning-based image registration methods. In our study, we treated the registration of cardiac T1w images as a multimodal registration and proposed a weighted image similarity metric, WLs, to address significant contrast variation issue by simultaneously considering signal intensity and structural variations in the registration pair. Considering the contrast variations in cardiac T1w images, NCC and MI are selected to represent intensity similarity, while NGF and MIND are chosen to represent structural similarity.\nSpecifically, the expression for WLs is defined as Eq (4). Weight a, b, c, and d represent the weights of NCC, MI, NGF, and MIND respectively. I and J are the registration pair.\n$WLs(I, J) = a \\cdot NCC(I, J) + b \\cdot MI(I, J) +c \\cdot NGF(I, J) + d \\cdot MIND(I, J)$\nConsequently, the overall loss function of AffN is:\n$L_{AffN} = -WLs(A\\_X,Y)$"}, {"title": "3.4.2. Loss function of RegN", "content": "Image similarity loss function: Image similarity loss function encompasses two components: the baseline design and the BLOC constraint. -WLs(A_X, M_YX) \u2013 WLs(Y, M_XY) is associated with the baseline design. Meanwhile, -WLs(Y, M_YX_inv) \u2013 WLs(A_X, M_XY_inv) corresponds to the bidirectional consistency constraint within the BLOC constraint. Similar to AffN, WLs is also used as the image similarity metric in RegN. As described in section 3.2, the image similarity loss function of RegN is expressed as follows:\n$L_{reg\\_s} = -WLs(Y, M_{YX}\\_{inv}) - WLs(A\\_X, M_{XY}\\_{inv}) - WLs(A\\_X, M_{YX}) \u2013 WLs(Y, M_{XY})$\nWeakly-supervised loss function: We utilize the myocardium segmentation results obtained from SegN as weak supervision information for RegN. The soft multi-class dice coefficient (D) [29] expressed at Eq (7) is used to measure the similarity of myocardium segmentation. It should be noted that the pseudo-labels used in RegN are all sourced from the myocardium segmentation outcomes of SegN rather than manually segmented labels.\n$D(S_1, S) = 1 - \\frac{2 \\cdot \\sum_{x} S_{I}(x) S_{J}(x)}{\\sum_{x} S_{I}(x) + \\sum_{x} S_{J}(x)}$\n$L_{reg\\_a} = D_r(S\\_X \\circ \\Phi_{XY}, S\\_Y) +D_r(S\\_Y \\circ \\Phi_{YX}, S\\_X)$\nThe weakly-supervised label similarity loss function, $L_{reg\\_a}$, is designed for RegN in Eq (8), where $D_r(\u00b7,\u00b7)$ computes the dice loss between the myocardium segmentation outcome (segmented by SegN) of image Y and the deformed myocardium segmenta-tion outcome (segmented by SegN and then warped by RegN) of image A_X, the other direction likewise. S_X and S_Y are the myocardium segmentation outcomes of A_X and Y in SegN, $\\circ$ represents the warping performed through STN [36] and $\u03a6_{XY}$ represents the registration mapping predicted by RegN.\nLocal anti-folding loss function: To address the issue of local folding, local orientation consistency constraint $L_{Jdet}$ [24] is also used with the expression as follows:\n$L_{Jdet} = \\sum_{p\\in \\Omega} (-\\sigma J_{\\Phi_{XY}} (p)]) + \\sum_{p\\in \\Omega} (-\\sigma J_{\\Phi_{YX}} (p)])$\nWhere $|J_{\\Phi_{XY}} (p)|$ represents the determinant of the Jacobian matrix of deformation field $\u03a6_{xy}$ at position p. Therefore, an acti-vation function, $\\sigma(\u00b7)$, which maintains the positive value and makes the negative value zero, is utilized to penalize the regions that are not topology-preserving. $\\Omega$ denotes the total number of elements in $|J_{\\Phi_{XY}} (p)|$. The local anti-folding constraint allows for a more adaptive focus on preserving the topology at a local level rather than considering the global smoothness. Therefore, the degree of topology preservation can be improved by combining it with the proposed bidirectional consistency constraint to be an overall constraint, BLOC. By working with $L_2$-norm which is marked as $L_{smooth}$, a balance can be achieved between registration accuracy and deformation field smoothness."}, {"title": "3.4.3. Loss function of SegN", "content": "Semi-supervised loss function: The label similarity metric ex-pressed at Eq (7) is also used in the overall training loss function ($L_{SegN}$) of SegN.\n$L_{SegN}= \\begin{cases} \\lambda \\gamma D_r(X_1 \\circ \\Phi_{XY},S\\_Y)+\\frac{1}{\\lambda}D_r(S\\_X,X_1), \\text{ if A\\_X is labeled.} \\\\ \\lambda \\gamma D_r(Y_1 \\circ \\Phi_{YX},S\\_X)+\\frac{1}{\\lambda}D_r(S\\_Y,Y_1), \\text{ if Y is labeled.} \\\\ \\lambda \\gamma D_r(Y \\circ \\Phi_{YX},S\\_X)+\\frac{1}{\\lambda}D_r(S\\_Y,Y_1), \\text{ if A\\_X and Y are labeled.} \\end{cases}$\nWhere $X_1$ and $Y_1$ represent manual myocardial segmenta-tion labels for A_X and Y. $D_r(\u00b7,\u00b7)$ represents the dice coefficient between the deformed myocardium segmentation outcome (seg-mented manually and then warped by RegN) and the myocardium segmentation outcome (segmented by SegN), while $D_r(\u00b7,\u00b7)$ repre-sents the dice coefficient between the myocardium segmentation outcome (segmented by SegN) and the manual myocardium seg-mentation label. The combination of $D_r(\u00b7,\u00b7)$ part and $D_r(\u00b7,\u00b7)$ part makes SegN a semi-supervised network. \u03bb, and $\\gamma$ are the weights of unsupervised and supervised learning."}, {"title": "3.5. Network training", "content": "The training of RS-MOCO can be summarized in the following steps:\n1. AffN is firstly employed for pre-training to achieve initial linear affine registration and correct partial misalignment caused by motion. Then, the pre-trained AffN model is integrated into the deformable registration network as its pre-alignment module;\n2. RegN is utilized for deformable registration training to correct the vast majority of misalignment and achieve more precise registration results;\n3. SegN is used for myocardium segmentation training to ob-tain pseudo-labels of myocardium segmentation. It is worth noting that SegN is semi-supervised, with some pseudo-labels derived from the distorted ground truth labels through the trained RegN;\n4. Re-train the weakly-supervised RegN using the pseudo-labels of myocardium segmentation generated by SegN;\n5. Repeating steps 3 and 4, RegN and SegN are trained alter-natively, to continuously improve the performance of both networks."}, {"title": "4. Results", "content": "4.1. Datasets\nThis study utilized the publicly available dataset, T1Dataset210 [12], from Harvard Dataverse. Imaging was performed using a 1.5T Philips Achieva system (Philips Healthcare, Best, Netherlands) with a 32-channel cardiac coil. T1 mapping was performed in 210 consecutive patients (134 males; age 57\u00b114 years) with known or suspected cardiovascular diseases referred for a clinical cardiac MR exam. The imaging protocol was the free-breathing, respiratory-navigated, slice-interleaved T1 mapping sequence [6]. Each patient data consisted of five short axial slices covering the LV from base to apex. At each slice location, 11 T1w images were acquired at differ-ent inversion times, TI;. The epicardial and endocardial boundaries of all images in the database (N = 11550 images) were manually delineated, with each contour starting from a myocardium point closest to the anterior insertion of the right ventricle into the LV.\nFurthermore, the generalization performance of different meth-ods was tested on an external dataset, SZC-T1, which was ob-tained at Shenzhen Children's Hospital. The SZC-T1 dataset con-sisted of cardiac T1 mapping images from 8 patients(6 males; age 10\u00b13 years) acquired using the MOLLI sequence [4] on a 3.0T SIEMENS Skyra with an 18-channel cardiac coil. Patients underwent respiratory training before scanning, and all images were acquired under free-breathing using a prospective electrocar-diogram gating technique. Each patient data consisted of 8-9 short axial slices covering the LV from base to apex with each slice comprising of 8 T1w images acquired at different inversion times."}, {"title": "4.2. Implementation", "content": "4.2.1. Execution specifics\nDuring training and testing, we crop each T1w image in the internal dataset from 320*320 to a size of 144*160 and perform normalization. All models are trained using the Adam optimizer with an initial learning rate of 1e-4 for affine registration, le-3 for deformable registration and segmentation, and a batch size of 16. The parameter sizes of the three networks, AffN, RegN, and SegN, are approximately 1020k, 1517k, and 1946k respectively. During the training of one batch of data, the GPU memory us-age of these networks is approximately 4238MiB, 5104MiB, and 3306MiB respectively. Considering both model performance and computational cost, training was halted when no further improve-ment in performance on the validation set was observed in order to prevent overfitting and simultaneously eliminate unnecessary computational expenses. Based on our experimental experience, AffN achieves optimal performance around five epochs of training. Furthermore, the overall model reaches peak performance when RegN and SegN are alternately trained at a ratio of 2 epochs to 0.5 epochs and this process is repeated three times. The weights of different components in WLs were determined through experiments using the hyperparameter optimization tool, Optuna. Based on the experimental results, the weights for WLs in this study were set as: 1.1, 4, 3.3 and 8.3, respectively. Also, the weights for the Jacobian determinant regularization loss and the L2-norm loss of the deformation field are set to 1000 and 8 according to Optuna. We conduct experiments using triple fold cross validation, with each experiment having 92,400 registration pairs available for training. All experiments are based on PyTorch 1.11.0 and deployed on a server equipped with an RTX A6000 GPU."}, {"title": "4.2.2. Evaluation metrics", "content": "This study quantitatively evaluates the motion correction ef-fect of cardiac T1 mapping using the Dice Similarity Coefficient (DSC) which quantifies the degree of overlap between the pre-dicted myocardial segmentation labels and the manual myocardial segmentation labels, Hausdorff Distance (HD) which quantifies the similarity of myocardial contours between the predicted and manual myocardial segmentation labels, and the number of non-positive Jacobian determinants ($|J|\u22640$) which quantifies the num-ber of pixels within a deformation field that is in a state of folding. The smaller value of $|J|\u22640$ indicates better topology preservation performance. For qualitative evaluation, a three-parameter signal model is employed to fit the T1 map for each STONE or MOLLI series. During testing, the 11th or 8th T1w image of each STONE or MOLLI series is selected as the fixed image, while the remaining images serve as moving images. Additionally, the testing time is measured for different methods to compare the efficiency of motion correction in each STONE or MOLLI series."}, {"title": "4.2.3. Comparison methods", "content": "We employed the Cb-Reg scheme (a part of work by El-Rewaidy et al. [12]), which utilizes manually delineated myocar-dial contours for local registration, to register the internal dataset T1Dataset210 and external dataset SZC-T1. It is noteworthy that Cb-Reg executes registration utilizing manually delineated my-ocardial contours, rather than using myocardial contours auto-matically extracted by the active shape model. In addition, this study compares various medical image registration and motion correction methods for cardiac T1 mapping. We implemented the classic symmetric image normalization method (SyN) [41, 42] using the Python-based ANTs package. We compared our ap-proach with DisQ (DisQ) [16], a method specifically designed for motion correction in cardiac T1 mapping, proposed by Yang et al. Additionally, we utilized VoxelMorph (VM) [17], a widely used unsupervised registration method based on deep learning, for intensity-based registration."}, {"title": "4.2.3. Ablation study", "content": "Our research involves extensive ablative experiments. The first part aims to validate the effectiveness of WLs by comparing its results with those obtained by NCC, MI, NGF, and MIND individ-ually used in image similarity loss function of AffN and RegN. The second part aims to verify the effectiveness of each module in RS-MOCO. Specifically, we test and compare the network results with each module removed separately, including AffN, SegN, CB\u0410\u041c, and BLOC."}, {"title": "4.3. Motion correction of cardiac T1 mapping", "content": "4.3.1. Qualitative results analysis\nMotion correction effects on Tlw images: Fig. 6 presents a comparative analysis of the effectiveness of different methods for motion correction on the internal dataset, T1dataset210 [12"}]}