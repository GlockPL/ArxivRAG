{"title": "Simulation-based Scenario Generation for Robust Hybrid AI for Autonomy", "authors": ["Hambisa Keno", "Nicholas J. Pioch", "Christopher Guagliano", "Timothy H. Chung"], "abstract": "Application of Unmanned Aerial Vehicles (UAVs) in search and rescue, emergency management, and law enforcement has gained traction with the advent of low-cost platforms and sensor payloads. The emergence of hybrid neural and symbolic AI approaches for complex reasoning is expected to further push the boundaries of these applications with decreasing levels of human intervention. However, current UAV simulation environments lack semantic context suited to this hybrid approach. To address this gap, HAMERITT (Hybrid Ai Mission Environment for RapId Training and Testing) provides a simulation-based autonomy software framework that supports the training, testing and assurance of neuro-symbolic algorithms for autonomous maneuver and perception reasoning. HAMERITT includes scenario generation capabilities that offer mission-relevant contextual symbolic information in addition to raw sensor data. Scenarios include symbolic descriptions for entities of interest and their relations to scene elements, as well as spatial-temporal constraints in the form of time-bounded areas of interest with prior probabilities and restricted zones within those areas. HAMERITT also features support for training distinct algorithm threads for maneuver vs. perception within an end-to-end mission run. Future work includes improving scenario realism and scaling symbolic context generation through automated workflow.", "sections": [{"title": "Introduction", "content": "Under DARPA's Assured Neuro-Symbolic Reasoning and Learning (ANSR) program (DARPA 2024), STR and Microsoft Corporation have developed a simulation-based autonomy framework entitled HAMERITT (Hybrid Ai Mission Environment for RapId Training and Testing). Figure 1 depicts HAMERITT's high-level architecture, which is composed of four modules. This paper focuses primarily on the Scenario & Data Generation module, which includes tools to define mission guidance, configure the underlying simulation for perception and maneuver mission threads, and support scenario randomization. HAMERITT uses an interactive Microsoft UAV simulator based on the former AirSim open source platform (Shah et al. 2017; Wang et al. 2022) to provide enhanced environmental realism and simulation complexity. The target platform is a small UAV such as ModalAI's Sentinel (Figure 1, right) (ModalAI 2024). An Algorithm Development Kit (ADK) implements Application Programming Interfaces (APIs) in the Robot Operation System 2 (ROS 2) to expose simulated data suited to symbolic reasoning, such as mission objectives, spatiotemporal constraints, and other contextual knowledge. The ADK API also exposes sensor data suited to neural machine learning, such as UAV camera feeds, depth map, and odometry (Figure 1, center). The ADK includes support for training and testing ANSR performer algorithms (TA1 = algorithms, TA2 = assurance) and metrics generation in concert with the government evaluation team's test harness and adversarial AI red teaming (Figure 1, left). A pipeline for building a Common Operational Picture (COP) will support integrating maneuver and perception models into an end-to-end system, including exposure of the COP to end users via a ROS 2 to tak.gov bridge. Collectively, these capabilities enable HAMERITT clients to train against a vast variety of multi-modal scenarios to develop robust maneuver and perception algorithms for UAV urban search missions. In Phase 2 of ANSR, HAMERITT will integrate the performer algorithms into an overall ANSR system that provides a highly accurate Common Operational Picture for increasingly challenging scenarios, and transition the technology via integration with tak.gov, an open-source situational awareness framework widely used across military and civilian communities of interest.\n\nThe ADK was used by performer teams to train and test hybrid Al models for an interim Phase 1 evaluation. This HAMERITT release included diverse scenarios for single UAV search missions for entities of interest in urban environments, leveraging the Microsoft simulator to present challenging environmental conditions and perturbations (e.g., snow, fog, foliage, wind, time of day). The ADK provided support for two complementary mission threads (perception and maneuver) and included additional AI tools such as an automated path planner and fine-grained navigation between client-provided maneuver waypoints via Nav2 (see https://docs.nav2.org/)."}, {"title": "Scenario and Data Generation", "content": "HAMERITT's unique contribution as a simulation-based autonomy environment is the multi-modal scenario data it provides, driven by mission objectives. The mission objective dictates the symbolic mission description data, the configuration of target entities including their trajectories, UAV sensor payloads, UAV trajectories and the environment in the simulation. Accordingly, upon requesting a random scenario from the HAMERITT system, two JSON-formatted files are generated: the mission description JSON, and the simulation configuration JSON. The mission description JSON is a structured representation of the mission objective, spatial-temporal constraints, prior beliefs in target entity locations, and scene description around target entities. The simulation configuration JSON specifies the starting state and trajectories for all mobile entities in the scene, the environmental conditions, the UAV payload configuration, and perturbation settings used to promote robustness of trained models.\n\nHAMERITT currently supports two classes of scenarios. The Area Search Scenario has the objective of locating a target of interest within one or more regions on the map designated as areas of interest (AOIs). In Figure 2 (top), the target of interest is in the south-west quadrant on the map. The scenario description JSON represents this as the AOI for the search mission. The polygonal representation of the AOI provides symbolic cues for perception AI client solutions by providing a layer of disambiguation between entities. For example, to disambiguate two cars of interest with identical colors and models, the symbolic guidance could specify that one of them is outside the AOI. Similarly, maneuver AI client solutions can use the AOI as guidance for formulating search patterns. The scenario description file for area search further extends the set of symbolic context information by breaking up the AOI into sub-quadrants. The probability that a sub-quadrant contains the target entity is included as part of the mission description JSON as a prior on target entity location. Optionally, an AOI can be bound to a time window, providing a temporal disambiguation dimension.\n\nHAMERITT also generates Route Search scenarios. The route search scenario has the objective of locating targets of interest on or along the periphery of a route of interest. The route of interest is represented as a sequence of line segments, while the periphery is represented by a search band as shown in Figure 2 (bottom).\n\nBoth the area search and the route search scenarios are designed for dense urban environment to present challenges for both maneuver and perception algorithms. Occlusions from trees and buildings provide limited field-of-view for cameras on the UAV. The limited detection range for the cameras compounds this challenge by requiring UAVs to execute low-altitude flights in a crowded environment. Similarly, partial occlusions and images at arbitrary orientations due to UAV rotational maneuvers add to the perception challenge. The perception reasoner is also expected to fuse neural information, such as images containing a car, with symbolic information on which region that car is expected to be found. They also may need to recognize contextual objects in the scene around the car against the guidance provided as pre-mission symbolic context. For example, they may be asked to find a red sedan that has a garage to its right side.\n\nHAMERITT includes vignettes for Moving Target Pursuit. These vignettes are aimed at increasing the complexity of the challenge problems. The maneuver challenge for these vignettes involves achieving camera pose to place the dynamic target in view continuously. The perception challenge involves reasoning about the target in the presence of confusers and reacquiring the target when temporarily out of view."}, {"title": "Contextual symbolic information", "content": "As discussed above, the scenario description file provides a set of contextual symbolic information that are intended to augment the neural data stream from sensors. This information consists of two main types: constraints or scene descriptions.\n\nHAMERITT uses three types of constraints in specifying a scenario. The Area of Interest (AOI) is a soft-spatial constraint. In the area search context, it specifies the region of the map where the target of interest is expected to be found. A solution for searching this area of interest can fly the UAV outside of the AOI itself without violating this constraint. Optionally, the AOI constraint can have a no-later-than (NLT) and a no-earlier-than (NET) temporal constraint specifying the valid period for the spatial AOI constraint.\n\nThe Keep Out Zone (KOZ) constraint is a hard spatial constraint. A UAV flight path that intersects one or more keep out zone polygons violates this constraint. Like the AOI constraint, we can apply optional temporal bounds to the KOZ constraints. HAMERITT uses the KOZs as levers for introducing both maneuver and perception challenges. For example, the KOZs can restrict UAV avenues of approach to target entity that provide occlusion free vantage points. HAMERITT also uses a combination of time bound KOZS and known target entity trajectories to restrict UAV access to portions of the entity trajectory. For example, to prevent a UAV detecting a target car while the car is on a particular street, the polygon bounding the street, and the projected interval for the car on the street can be mapped into KOZ and time bound on the KOZ respectively. Figure 2 (bottom) depicts this use case where we deny the UAV access to two streets (yellow boxes) going from North to South and West to East at the precise time interval where two cars of interest will traverse a portion of their trajectories (red curves) along those streets.\n\nArea Priors are sub-regions on the map with probabilities for containing the target entity. We can loosely interpret these priors as soft spatial constraints. That is, they can be considered as a high-resolution variation of the AOI where they represent a more fine-grained belief on where the target of interest is expected to be found. Figure 2 (top) shows an example of these Area Priors where the sub quadrant that contains the entity of interest has the highest prior. This symbolic context information can inform explicit search strategy or search policy generated from learning-based methods, for example a more frequent revisit of the sub-quadrant with the highest prior until target detection. In addition to constraints, HAMERITT provides scene descriptions as a second class of contextual symbolic information. The purpose of these scene descriptions is to enhance the performance of a perception reasoner in the presence of ambiguities. For example, a search scenario can ask for locating a blue Chevy Impala in a one square mile area covering multiple city blocks. A UAV flying over this area can detect multiple instances of blue Chevy Impalas. However, if the perception reasoner is provided additional descriptions about the scene around the particular blue Chevy Impala, it can augment the raw sensor data with this scene description to disambiguate the target car from similar looking cars within the perimeter of the city blocks of interest.\n\nHAMERITT uses a simple list of symbolic operators to represent the relationship between a target entity and its surrounding scene environment. A relationship has the following format. [Related entity] [relationship operator] [Target entity] [(Optional) Related entity attributes]. For example, the symbolic relationship shown in Figure 4 is rep-"}, {"title": "Simulation Environment", "content": "Microsoft has developed an advanced UAV simulator platform for HAMERITT to meet the ANSR program's mission-focused needs. The extended platform exposes a common interface and communication layer for robotics applications via the ROS 2 pub/sub framework, allowing rapid integra-"}, {"title": "Dataset for evaluation", "content": "HAMERITT generated more than 9,000 scenario variations for area search and route search in a suburban neighborhood environment developed under previous research (Chung and"}, {"title": "Future extensions", "content": "Future extensions to our work include the following. First, we will extend HAMERITT APIs to enable integration of hybrid Al models for the partial mission threads into an end-to-end system. Second, we plan on increasing the complexity of scenarios from search only to include search, follow, track, and avoid tasks, while migrating from a suburban neighborhood to a denser city environment. Third, we plan to automate the scenario generation and randomization scheme and increase the variety of training conditions using UC Berkeley's SCENIC framework (Fremont et al. 2019). Fourth, we will expose HAMERITT's Common Operating picture (COP) to end-users via a ROS 2 interface for the tak.gov platform to support transition to DoD and law enforcement communities. Finally, we plan on increasing the fidelity of the UAV dynamics through PX4 integration (Lorenz, Honegger, and Pollefeys 2015) to enhance robustness of hybrid AI maneuver models in advance of live field tests for sim2real transfer evaluation."}, {"title": "Conclusion", "content": "In conclusion, HAMERITT provides an interactive simulation-based data generation framework to foster development of robust hybrid neuro-symbolic AI models for perception and maneuver. It provides scenario configuration tools for specifying semantic mission objectives, contextual knowledge, and environmental conditions. The HAMERITT ADK exposes UAV data feeds and ground truth via a ROS 2 interface, including pixel-level camera and depth imagery, with semantic labels and target entity bounding boxes for Al model training. A Microsoft UAV simulation environment is used to create realistic scenes and behaviors embodying challenging urban search tasks, with configurable scripting of target entity locations and behaviors, and a range of environmental variations including weather, time of day, visibility, and more. For the ANSR program Evaluation 1, HAMERITT delivered more than 9000 scenario variations for Area Search and Route Search in a typical neighborhood environment. Future work includes expansion to more complex missions, increased automation for scenario generation, integration of perception and maneuver models into an end-to-end system, and transfer to a physical UAV platform for live field tests."}]}