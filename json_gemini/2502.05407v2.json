{"title": "The Complexity of Learning Sparse Superposed Features with Feedback", "authors": ["Akash Kumar"], "abstract": "The success of deep networks is crucially attributed to their ability to capture latent features within\na representation space. In this work, we investigate whether the underlying learned features of a model\ncan be efficiently retrieved through feedback from an agent, such as a large language model (LLM), in\nthe form of relative triplet comparisons. These features may represent various constructs, including\ndictionaries in LLMs or components of a covariance matrix of Mahalanobis distances. We analyze the\nfeedback complexity associated with learning a feature matrix in sparse settings. Our results establish\ntight bounds when the agent is permitted to construct activations and demonstrate strong upper bounds\nin sparse scenarios when the agent's feedback is limited to distributional information. We validate our\ntheoretical findings through experiments on two distinct applications: feature recovery from Recursive\nFeature Machine-trained models and dictionary extraction from sparse autoencoders trained on Large\nLanguage Models.", "sections": [{"title": "Introduction", "content": "In recent years, neural network-based models have achieved state-of-the-art performance across a wide\narray of tasks. These models effectively capture relevant features or concepts from samples, tailored to the\nspecific prediction tasks they address (Yang and Hu, 2021b; Bordelon and Pehlevan, 2022a; Ba et al., 2022b).\nA fundamental challenge lies in understanding how these models learn such features and determining\nwhether these features can be interpreted or even retrieved directly (Radhakrishnan et al., 2024). Recent\nadvancements in mechanistic interpretability have opened multiple avenues for elucidating how transformer-\nbased models, including Large Language Models (LLMs), acquire and represent features (Bricken et al.,\n2023; Doshi-Velez and Kim, 2017). These advances include uncovering neural circuits that encode specific\nconcepts (Marks et al., 2024b; Olah et al., 2020), understanding feature composition across attention\nlayers (Yang and Hu, 2021b), and revealing how models develop structured representations (Elhage et al.,\n2022). One line of research posits that features are encoded linearly within the latent representation space\nthrough sparse activations, a concept known as the linear representation hypothesis (LRH) (Mikolov et al.,\n2013; Arora et al., 2016). However, this hypothesis faces challenges in explaining how neural networks\nfunction, as models often need to represent more distinct features than their layer dimensions would\ntheoretically allow under purely linear encoding. This phenomenon has been studied extensively in the\ncontext of large language models through the lens of superposition (Elhage et al., 2022), where multiple\nfeatures share the same dimensional space in structured ways.\nRecent efforts have addressed this challenge through sparse coding or dictionary learning, proposing\nthat any layer l of the model learns features linearly:\n$x \\approx D_e a_e(x) + \\epsilon_e(x),$"}, {"title": "Problem Setup", "content": "We denote by $V \\subseteq \\mathbb{R}^p$ the space of activations or representations and by $X \\subseteq \\mathbb{R}^d$ the space of samples. For\nthe space of feature matrices (for a dictionary or Mahalanobis distances), denoted as $\\mathcal{M}_F$, we consider the\nfamily of symmetric positive semi-definite matrices in $\\mathbb{R}^{p \\times p}$, i.e. $\\mathcal{M}_F = {\\Phi \\in Sym^+(\\mathbb{R}^{p \\times p})}$. We denote a\nfeedback set as $\\mathcal{F}$ which consists of triplets $(x, y, z) \\in V^3$ with corresponding signs $l \\in {+1,0, -1}$.\nWe use the standard notations in linear algebra over a space of matrices provided in Appendix B.\nAn agent provides feedback on activations in V through relative triplet comparisons\n$(x, y, z) \\in V$. Each comparison evaluates linear combinations of feature vectors:\n$\\sum_{i=1}^p x_i u_i$ (\"feature i\") is more similar to $\\sum_{i=1}^p y_i u_i$ (\"feature i\") than to  $\\sum_{i=1}^p z_i u_i$ (\"feature i\")\nWe study both sparse and non-sparse activation feedbacks, where sparsity is defined as:"}, {"title": "Sparse Feature Learning with Constructive Feedback", "content": "Here, we study the feedback complexity in the setting where agent is allowed to pick/construct any\nactivation from $\\mathbb{R}^p$.\ncan be simplified to pairwise comparisons with equality constraints with a\nsimple manipulation as follows.\nLet $\\Phi^* \\in \\mathcal{M}_F$ be a target feature matrix in representation space $\\mathbb{R}^p$ used for oblivious learning.\nGiven a feedback set\n$\\mathcal{F} = {(x, y, z) \\in \\mathbb{R}^{3p} | (x - y)^T \\Phi^* (x - y) \\geq (x - z)^T \\Phi^* (x - z)},$\nsuch that any $\\Phi' \\in VS(\\mathcal{F}, \\mathcal{M}_F)$ is feature equivalent to $\\Phi^*$, there exists a pairwise feedback set\n$\\mathcal{F}' = {(y', z') \\in \\mathbb{R}^{2p} | y'^T \\Phi^* y' = z'^T \\Phi^* z'}$\nsuch that $\\Phi' \\in VS(\\mathcal{F}', \\mathcal{M}_F)$.\nProof. WLOG, assume $x \\neq z$ for all $(x, y, z) \\in \\mathcal{F}$. For any triplet $(x, y, z) \\in \\mathcal{F}$: Case (i): If $(x-y)^T \\Phi^* (x-\ny) = (x - z)^T \\Phi^* (x - z)$, then $(x - y, x - z)$ satisfies the equality. Case (ii): If $(x - y)^T \\Phi^* (x - y) >\n(x - z)^T \\Phi^* (x - z)$, then for some $\\lambda > 0$:\n$(x - y)^T \\Phi^* (x - y) = (1 + \\lambda)(x - z)^T \\Phi^* (x - z)$\nimplying $(x - y, \\sqrt{1 + \\lambda}(x - z))$ satisfies the equality.\nThus, each triplet in $\\mathcal{F}$ maps to a pair in $\\mathcal{F}'$, preserving feature equivalence under positive scaling.\nThis implies that if triplet comparisons are used in Algorithm 1, equivalent pairwise comparisons exist\nsatisfying:"}, {"title": "Constructive feedbacks: Worst-case lower bound", "content": "To learn a symmetric PSD matrix, learner needs at most $p(p + 1)/2$ constraints for linear programming\ncorresponding to the number of degrees of freedom. So, the first question is are there pathological cases of\nfeature matrices in $\\mathcal{M}_F$ which would require at least $p(p + 1)/2$ many triplet feedbacks in Algorithm 1.\nThis indeed is the case, if a target matrix $\\Phi^* \\in Sym^+(\\mathbb{R}^{p \\times p})$ is full rank.\nIn the following proposition proven in Appendix D, we show a strong lower bound on the worst-case\n$\\Phi^*$ that turns out to be of order $\\Omega(p^2)$.\nIn the constructive setting, the worst-case feedback complexity of the class MF with general\nactivations is at the least $(\\frac{p(p+1)}{2} -1)$.\nProof Outline. As discussed in Eq. (1) and Eq. (2), for a full-rank feature matrix $\\Phi^* \\in \\mathcal{M}_F$, the span of\nany feedback set $\\mathcal{F}$, i.e., $span({xx^T - yy^T}_{(x,y)\\in \\mathcal{F}})$, must lie within the orthogonal complement $\\mathcal{O}_{\\Phi^*}$ of\n$\\Phi^*$ in the space of symmetric matrices $Sym(\\mathbb{R}^{p \\times p})$. Conversely, if $\\Phi^*$ has full rank, then $\\mathcal{O}_{\\Phi^*}$ is contained\nwithin this span. This necessary condition requires the feedback set to have a size of at least $\\frac{p(p+1)}{2} -1$,\ngiven that $dim(Sym(\\mathbb{R}^{p \\times p})) = \\frac{p(p+1)}{2}$.\nSince the worst-case bounds are pessimistic for oblivious learning of Eq. (1) a general question is how\nfeedback complexity varies over the feature model $\\mathcal{M}_F$. In the following subsection, we study the feedback\ncomplexity for feature model based on the rank of the underlying matrix, showing that the bounds can be\ndrastically reduced."}, {"title": "Feature learning of low-rank matrices", "content": "As stated in Proposition 1, the learner requires at least $\\frac{p(p+1)}{2} -1$ feedback pairs to annihilate the orthogonal\ncomplement $\\mathcal{O}_{\\Phi^*}$. However, this requirement decreases with a lower rank of $\\Phi^*$. We illustrate this in Fig. 1\nfor a feature matrix $\\Phi \\in \\mathbb{R}^{10 \\times 10}$ of rank 4 trained via Recursive Feature Machines (Radhakrishnan et al.,\n2024).\nConsider an activation $a \\in \\mathbb{R}^p$ in the nullspace of $\\Phi^*$. Since $\\Phi^*a = 0$, it follows that $a^T \\Phi^* a = 0$.\nMoreover, for another activation $\\beta \\notin span(a)$ in the nullspace, any linear combination $aa + b\\beta$ satisfies\n$(aa + b\\beta)^T \\Phi^* (aa + b\\beta) = 0$.\nThis suggests a strategy for designing effective feedback based on the kernel $Ker(\\Phi^*)$ and the null\nspace $null(\\Phi^*)$ of $\\Phi^*$ (see Appendix B for table of notations). This intuition is formalized by the\neigendecomposition of the feature matrix:\n$\\Phi^* = \\sum_{i=1}^r \\lambda_i u_i u_i^T,$\nwhere {$\\lambda_i$} are the eigenvalues and {$u_i$} are the orthonormal eigenvectors. Since $\\Phi^* \\geq 0$ this decomposition\nis unique with non-negative eigenvalues.\nTo teach $\\Phi^*$, the agent can employ a dual approach: teaching the kernel associated with the eigen-\nvectors in this decomposition and the null space separately. Specifically, the agent can provide feedbacks\ncorresponding to the eigenvectors of $\\Phi^*$'s kernel and extend the basis {$u_i$} for the null space. We first\npresent the following useful result (see proof in Appendix E)."}, {"title": "Sparse Feature Learning with Sampled Feedback", "content": "In general, the assumption of constructive feedback may not hold in practice, as ground truth samples from\nnature or induced representations from a model are typically independently sampled from the representation\nspace. The literature on Mahalanobis distance learning and dictionary learning has explored distributional\nassumptions on the sample/activation space (Mason et al., 2017; Gribonval et al., 2014).\nIn this section, we consider a more realistic scenario where the agent observes a set of representa-\ntions/activations $V_n := {a_1, a_2, ..., a_n} \\sim \\mathcal{D}_V$, with $\\mathcal{D}_V$ being an unknown measure over the continuous"}, {"title": "Experimental Setup", "content": "We empirically validate our theoretical framework for learning feature matrices. Our experiments2 examine\ndifferent feedback mechanisms and teaching strategies across both synthetic tasks and large-scale neural\nnetworks.\nWe evaluate four feedback mechanisms: (1) uses Lemma 3 to\nconstruct feedback based on $\\Phi$'s low rank structure, (2) Sparse Constructive builds 2-sparse feedbacks using\nthe basis in Eq. (4), (3) Random Sampling generates feedbacks spanning $\\mathcal{O}_{\\Phi^*}$ from a Lebesgue distribution,\nand (4) Sparse Sampling creates feedbacks using s-sparse samples drawn from a sparse distribution (see\nDefinition 1).\nWe implement a teaching agent with access to the target feature matrix to enable\nnumerical analysis. The agent constructs either specific basis vectors or receives activations from distribu-\ntions (Lebesgue or Sparse) based on the chosen feedback method. For problems with small dimensions, we\nutilize the cvxpy package to solve constraints of the form {$aa^T - yy^T$}. When handling larger dimensional\nfeatures (5000 \\times 5000), where constraints scale to millions $(p(p + 1)/2 \\approx 12.5M)$, we employ batch-wise\ngradient descent for matrix regression."}, {"title": "Additional Experiments", "content": "We evaluate our methods on large-scale models: Pythia-70M (Biderman et al., 2023) and Board Games\nModels (Karvonen et al., 2024). These models present significant computational challenges, as different\nfeedback methods generate millions of constraints. This scale necessitates specialized approaches for both\nmemory management and computational efficiency.\nThe high dimensionality of model dictionaries makes storing\ncomplete activation indices for each feature prohibitively memory-intensive. We address this by enforcing\nconstant sparsity constraints, limiting activations to a maximum sparsity of 3. This constraint enables\nefficient storage of large-dimensional arrays while preserving the essential characteristics of the features.\nTo efficiently handle constraint satisfaction at scale, we reformulate the\nproblem as a matrix regression task, as detailed in Fig. 4. The learner maintains a low-rank decomposition\nof the feature matrix $\\Phi$, assuming $\\Phi = U U^T$, where $U$ represents the learned dictionary. This formulation\nallows for efficient batch-wise optimization over the constraint set while maintaining feasible memory\nrequirements.\nWe use the publicly available repository for dictionary learning\nvia sparse autoencoders on neural network activations (Marks et al., 2024a). We consider the dictionaries\ntrained for Pythia-70M (Biderman et al., 2023) (a general-purpose LLM trained on publicly available\ndatasets). We retrieve the corresponding autoencoders for attention output layers which have dimensions\n32768 \u00d7 512. Note that $p(p + 1)/2 \\approx .512M$. For the experiments, we use 3-sparsity on uniform sparse\ndistributions. We present the plots for ChessGPT in two parts in Fig. 5 and Fig. 5 for different feedback\nmethods."}]}