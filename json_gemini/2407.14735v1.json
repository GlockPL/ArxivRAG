{"title": "ECRTime: Ensemble Integration of Classification and Retrieval for Time Series Classification", "authors": ["Fan Zhao", "You Chen"], "abstract": "Deep learning-based methods for Time Series Classification (TSC) typically utilize deep networks to extract features, which are then processed through a combination of a Fully Connected (FC) layer and a SoftMax function. However, we have observed the phenomenon of inter-class similarity and intra-class inconsistency in the datasets from the UCR archive and further analyzed how this phenomenon adversely affects the \"FC+SoftMax\u201d paradigm. To address the issue, we introduce ECR, which, for the first time to our knowledge, applies deep learning-based retrieval algorithm to the TSC problem and integrates classification and retrieval models. Experimental results on 112 UCR datasets demonstrate that ECR is state-of-the-art(sota) compared to existing deep learning-based methods. Furthermore, we have developed a more precise classifier, ECRTime, which is an ensemble of ECR. ECRTime surpasses the currently most accurate deep learning classifier, InceptionTime, in terms of accuracy, achieving this with reduced training time and comparable scalability.", "sections": [{"title": "1. Introduction", "content": "Time series data is extensively applied in various domains, including weather modeling, retail operations, financial forecasting, and many other sectors. This paper specifically focuses on the classification of univariate time series data. In academia, this field primarily consists of two methodological categories: distance-based and feature-based approaches. Distance-based methods, which serve as the foundational baseline in the field, classify data by computing similarities in the original raw time series, using pre-established distance metrics like Dynamic Time Warping (DTW) or Euclidean distance. DTW is notably effective in handling translational variances compared to the Euclidean distance. On the other hand, feature-based approaches extract feature vectors from the raw data and then employ classifiers such as Support Vector Machines (SVM), logistic regression, and decision trees to determine classification results.\nRecent years have seen a growing body of research utilizing deep learning, especially deep convolutional network techniques, to address TSC challenges. Typically, these methods begin by extracting features using a deep network, and then proceed to classification through a FC layer combined with a SoftMax function. In the training phase, the FC layer fundamentally learns a weight matrix $W_{dc}$ where d denotes the dimension of the feature vector, and c indicates the number of classes. This process is tantamount to learning a proxy(d *1 dimension) for each class, leading to the convergence of features from a particular class near their respective proxy. During the testing phase, the classification is determined by applying the SoftMax to the distances between the test sequence features and the proxies for all classes."}, {"title": "2. Related work", "content": "2.1. State-Of-The-Art Time Series Classifiers\nThe time series classification (TSC) problem represents a foundational challenge within the domain, with the academic community having proposed a multitude of effective algorithms to contend with this intricacy. Backoff-2023[4] summarizes the current eight state-of-the-art (SOTA) Time Series Classification (TSC) classifiers, which are HIVE-COTE 2.0[5], Hydra-MR[6], InceptionT[3], RDST[7], WEASEL-D[8], RSTSF[9], FreshPRINCE[10] and PF[11]. We categorize them into ensemble-based and feature-based methods. Among these, the most accurate ensemble method is HIVE-COTE 2.0, which is also currently the best time series classifier. It employs more advanced ensemble techniques compared to its predecessor, Hive-COTE 1.0[12]. It includes the following: STC, Temporal Dictionary Ensemble (TDE)[13], Diverse Representation Canonical Interval Forest (DrCIF), and Arsenal. Among these methods, DrCIF, developed by the authors of this paper, extends the Canonical Interval Forest (CIF) [14]. Meanwhile, Arsenal, an ensemble of compact ROCKET classifiers, generates valuable probability values for each class during predictions using CAWPE. Presently, these ensemble methods represent the state-of-the-art in time series classification. Nevertheless, they typically exhibit high time complexity, posing substantial challenges for practical application. In our research, we employed an ensemble approach that balances high accuracy with comparatively lower time complexity.\nHydra-MR stands as the most accurate feature-based method to date, achieving an excellent balance between accuracy and time consumption. It amalgamates the Hydra algorithm[6] with the MR (MultiRocket) model[15]. Building on the foundational work of Rocket[16] and MiniRocket[17], MultiRocket introduces a variety of pooling operations and transformations, enhancing the diversity of feature distributions. This advancement not only boosts classification accuracy but also maintains computational efficiency. HYDRA, a dictionary-based method, transforms input time series data using a collection of randomly selected convolutional kernels grouped together. It quantifies the frequency of kernels that most closely match the input time series at each point in time. These quantifications are then utilized to train a linear classifier.\n2.2. Deep learning-based methods\nThe current academic emphasis on resolving TSC challenges predominantly resides in the domain beyond deep learning, where non-deep learning methods prevail in terms of both prevalence and performance. DL-review[18], as an influential work in the field of Time Series Classification (TSC) within the deep learning domain, summarizes nine advanced deep learning-based time series classifiers, including: Resnet[2], FCN[2], Encoder[19], MLP[2], Time-CNN[20], TWISEN[21], MCDCNN[22], MCNN[23], and t-LeNeT[24]. Among these, Resnet and FCN exhibit relatively optimal performance. Resnet consists of three residual blocks, each followed by a Global Average Pooling (GAP) layer and a softmax classifier at the end. The number of neurons in the classifier corresponds to the number of classes in the dataset. Within each residual block, three convolutions are initially performed, the output of which is added to the block's input before being passed to the subsequent layer. FCN comprises three convolutional blocks, each containing three sequential operations: a convolution, batch normalization, and a ReLU activation function. The output of the third convolutional block undergoes averaging across the entire time dimension, forming the Global Average Pooling (GAP) layer. Subsequently, a conventional softmax classifier is connected to the output of the GAP layer. Subsequently, it was found in the [25] that directly ensembling these deep learning models could further enhance the algorithm's performance. Based on this discovery, InceptionT[3] was initially inspired by the Inception-v4[26] network from computer vision tasks and designed the \"AlexNet\" of TSC - the Inception net. It then ensembled these five models, ultimately achieving an accuracy on UCR85 comparable to HIVE-COTE 1.0. Moreover, Backoff-2023[4] comprehensively reviews and summarizes numerous deep learning models in current TSC tasks, ultimately concluding that InceptionT is currently the best deep learning-based time series classifier."}, {"title": "3. Method", "content": "In this section, we present the overall network framework of the ECR module, which serves as the ensemble component of ECRTime. Subsequently, detailed descriptions of each module within the network are provided. Ultimately, the final result is generated through a straightforward but effective ensemble strategy."}, {"title": "3.1. ECR Framework", "content": "Fig. 5 illustrates the overall structure of the ECR, which includes two stages: training and inference, as shown in Fig. 5(a) and Fig. 5(b) respectively.\nWe use $x \\in R^{1\\times L}$ to represent a single time series, 1 to indicate that it is univariate, and L to represent the length of the series. During the training phase, each mini-batch input is denoted as X, the input label set as Y, and the batch size as B. Each mini-batch includes C different categories, and each category contains m samples, thus resulting in $B = C \\times m, X \\in R^{B\\times 1\\times L}, Y \\in \\{1, 2, ..., C\\}^B$.\nAs shown in Fig. 5(a), the training framework consists of two independent forward branches: one trained based on classification method and the other based on retrieval method, both sharing the same input X. During training, X passes through the classification backbone and retrieval backbone to extract feature vectors $F_{cls} \\in R^{B\\times d \\times L}$ and $F_{Ret} \\in R^{B\\times d \\times L}$, respectively. Note that the two backbones have the same structure but do not share weights. d represents the number of channels in the feature vector. Subsequently, $F_{cls}$ and $F_{ret}$ are both dimensionally reduced to $F_{CLS} \\in R^{B\\times d}$ and $F_{ret} \\in R^{B\\times d}$ through Global Average Pooling(GAP) on the L dimension. In the classification branch, $F'_{cls}$ is followed by a Fully Connected Layer, and the output is then fed into the classification loss for learning. In the retrieval branch, $F_{ret}$, after undergoing L2 norm operation, is input into the retrieval loss.\nIn the inference phase shown in Fig. 5(b), for the test sequence, features are extracted based on the backbone networks in the two branches, and then both are reduced in dimension and normalized through Global Average Pooling and L2 Normalization. Additionally, we will pre-extract features of all sequences in the training set in this manner and construct both a classification feature library and a retrieval feature library. Subsequently, the classification and retrieval features of the test sequence are compared with corresponding library features in the Distance module. If there are N features in the library, 1 \u00d7 N classification distance vectors and retrieval distance vectors are outputted respectively. Finally, the predicted category is outputted by ensembling these two types of distances. In the following sections, we will specifically introduce the key modules in the training and inference, including: Backbone, Loss, Distance and Ensemble."}, {"title": "3.2. Backbone network structure", "content": "During these years of rapid development in deep learning, many backbone networks for feature extraction have emerged, yet ResNet[27], based on residual connections, remains the preferred choice in numerous application scenarios. The residual structure, without introducing additional parameters and computational load, can effectively mitigate gradient vanishing on one hand, ensuring the continuity of parameter learning; on the other hand, deeper networks can be constructed based on residual connections, and generally speaking, the deeper the network, the stronger its feature extraction capability. Existing works such as [2, 28, 29] have already applied ResNet in the TSC field. Based on the structures validated in these methods, we designed the backbone module of this paper, as shown in Fig. 6."}, {"title": "3.3. Loss", "content": "As shown in Fig. 5(a), the training phase employs two types of loss functions: the classification branch utilizes cross-entropy loss, denoted as $L_{cls}$, and the retrieval branch employs the hard version of triplet loss, denoted as $L_{Ret}$. Based on the symbol definitions in Section 3.1, $L_{cls}$ is defined in the following form:\n$L_{cls} = (- \\frac{1}{B}) \\sum_{i=1}^{B} \\sum_{j=1}^{C} 1(y = j) log[ \\frac{e^{z_j}}{ \\sum_{k=1}^{C}e^{z_k}}]$\n(1)\nIn Eq. (1), z represents the vector obtained after $F_{Cls}$ passes through the FC layer, and the indicator function 1(y = j) is defined as follow:\n$1(y = j) = \\begin{cases} 1, y = j \\\\ 0, y \\neq j \\end{cases}$\n(2)\nBased on Eq. (2), Eq. (1) can be further simplified to the following form:\n$L_{cls} = (-\\frac{1}{B}) \\sum_{i=1}^{B} log[ \\frac{e^{z_j}}{ \\sum_{k=1}^{C}e^{z_k}}]$\n(3)\nFor retrieval tasks, triplet loss[30] is generally used. It originally works on an anchor series A, a positive sample P from the same class and a negative sample N from a different class. The objective is to minimize the distance between A \u2013 P, while push away the N. The formula of triplet loss is as follow:\n$L_{Triplet} = \\frac{1}{H_p} \\sum_{i=1}^{H_p} [ ||g_A - g_P||_2 - \\frac{1}{H_N} \\sum_{j=1}^{H_N} ||g_A - g_N||_2 + \\alpha ]_+$\n(4)\nEq. (4) iterates over and calculates each sample in the mini-batch input, taking the average as the final loss. In this context, g denotes the vector after L2 norm, H indicates the count of positive or negative samples. The term $\\alpha$ represents the margin between positive and negative samples. Additionally, the subscripts P and N correspond to positive and negative samples, respectively. The original triplet loss introduces many easily satisfied triplets, which lack contribution to the training, leading to slower and less efficient convergence. Therefore, this paper follows the approach in [30] and uses hard triplet loss for training. This loss narrows the distance between the anchor sample and the farthest positive, while increasing the distance between the anchor and the closest negative, defined as follow:\n$L_{Ret} = [max_{i \\in [0,H_p)}(||g_A - g_P||_2) - min_{j \\in [0,H_N)}(||g_A - g_N||_2) + \\alpha]_+$\n(5)"}, {"title": "3.4. Distance", "content": "In the training phase, two pivotal modules, the Backbone and the Loss, have been delineated earlier. Subsequently, in the testing phase, we elucidate the Distance module, conceived on the 1-NN classifier paradigm. As depicted in the testing procedure (Fig. 5(b)), each time series input $x^i$ undergoes feature extraction via the classification and retrieval backbone, followed by processing through GAP and L2Norm, yielding output vectors $f_{cls}^i$ and $f_{ret}^i$. Concurrently, features are extracted from every sequence in the training set in a similar fashion, leading to the formation of two libraries: the classification library $F_{cls_{lib}} = \\{j \\in [0, N) | f_{cls}^j\\}$ and the retrieval library $F_{Ret_{lib}} = \\{j \\in [0, N) | f_{ret}^j\\}$, where N signifies the total number of sequences in the training set.\nIn the Distance module, by iterating and calculating the Euclidean distance between $f_{cls}^i$ and all features in the classification library $F_{cls_{lib}}$, we obtain $D(f_{cls}^i, F_{cls_{lib}}) = \\{D_{cls}^1, D_{cls}^2, ..., D_{cls}^N\\}$, representing the distance between $f_{cls}^i$ and $F_{cls - lib}$. The distance between vector $f_{ret}^i$ and the retrieval library $F_{Ret_{lib}}$ is denoted as $D(f_{ret}^i, F_{Ret_{lib}}) = \\{D_{ret}^1, D_{ret}^2, ..., D_{ret}^N\\}$, calculated in a similar manner."}, {"title": "3.5. Ensemble", "content": "Following the Distance module is the Ensemble module, and this paper involves two stages of ensemble operations, as illustrated in Fig. 7. The first stage ensembles classification and retrieval models to obtain ECR, and the second stage ensembles multiple ECRs to derive the final ECRTime model. In the first ensemble, as shown in Fig. 5(b), we average all corresponding elements in sets $D(f_{cls}^i, F_{cls_{lib}})$ and $D(f_{ret}^i, F_{ret-lib})$ to obtain the final distance set $D(f^i, F_{lib}) = \\{(D_{cls}^1 + D_{ret}^1)/2, (D_{cls}^2 + D_{ret}^2)/2,..., (D_{cls}^N + D_{ret}^N)/2\\}$. Finally, the category of the corresponding sequence in the library, predicted for the test sequence $x^i$, is identified by taking $arg min(*)$ of $D(f^i, F_{lib})$.\nIt is important to note that L2 normalization is applied to the classification features during testing to ensure uniformity in the value ranges of $D(f_{cls}^i, F_{cls_{lib}})$ and $D(f_{ret}^i, F_{ret_{lib}})$. This uniformity is crucial as it prevents the averaging of prediction results from being skewed by differing value ranges. Additionally, for two vectors with an L2 norm of 1, their Euclidean distance can be reformulated as $\\sqrt{2(1 - cos \\theta)}$ where $\\theta$ is the angle between the vectors. This ensures that both parties being averaged have the same value range, which is [0, 2].\n$Y_{i,c} = \\frac{1}{n} \\sum_{j=1}^{n} \\sigma(\\chi_i, \\theta_j) [ \\forall i \\in[1,C] ]$\n(6)\nFurthermore, in the second ensemble, based on Eq. (6), multiple ECRs are integrated to obtain the final ECRTime model presented in this paper. In the formula, $y_{i,c}$ represents the ensemble's output probability that the input time series, $x_i$ belongs to class c, This is equivalent to the average logistic output $\\sigma$ across n randomly initialized ECRs."}, {"title": "4. Experiments and results", "content": "4.1. Experiment setup\nIn this section, we evaluate the ECR and ECRTime on 112 datasets in the UCR univariate time series archive. ECRTime refers to an ensemble of three ECR modules, while the \"ECR-Time(n)\" notation is used to denote an ensemble of n ECR modules. \"UCR112\" is used to denote the 112-version of the UCR archive in the following text. The experimental results are available on the website\u00b9. Initially, the experimental setup is introduced.\nDatasets and SOTAS: To compare with numerous advanced algorithms while avoiding excessively time-consuming experiments, we followed the approach used in [5, 4], conducting experimentation with the 112 equal length problems in the 2019 version of the UCR archive. The comparison includes classifiers based on deep learning summarized in DL-review[18] and state-of-the-art classifiers in the field of Time Series Classification(TSC) compiled in Backoff-2023[4]. The corresponding comparison results are respectively sourced from 2 and 3.\nConfiguring ECRTime: Since the datasets in the UCR only consist of training and test sets, lacking a validation set, it is not possible to tune hyperparameters such as epochs. Therefore, we refer to the ResNet classifier in DL-review[18] for hyperparameter settings. During the training phase, we set each mini-batch input to contain 4 categories, with 4 samples per category, resulting in a batch size of 16. The margin in the hard triplet loss is set to 0.1, and the optimizer used is Adam. For the classification branch, the learning rate is set at 1e-3, and for the retrieval branch, the learning rate is set at 1e-4. The scheduler used is ReduceLROnPlateau from PyTorch, the number of training epochs is set to 1500. Experimental environment configuration: PyTorch 2.0, Python 3.9."}, {"title": "4.2. Comparing with deep learning-based methods", "content": "To facilitate a comparison with a range of deep learning classifiers, we evaluated ECR against the eight methods detailed in DL-review[18]. For result validation, we adhered to DL-review's methodology, training ECR for five iterations on UCR112. During these iterations, only the random seed varied, while the model's structure and training hyperparameters remained unchanged. The final reported accuracy represents the mean of these iterations. Fig. 8 features a critical difference diagram that illustrates the accuracy comparisons between ECR and various deep learning models. The horizontal thick line across different models indicates no significant difference between them (p-value>0.05). It is noted that ECR significantly outperforms all methods depicted in the figure (p-value<0.05), including ResNet and FCN, which were identified as the most precise deep learning classifiers in DL-review at that time. In the subsequent Section 4.5.5, the discussion will focus on how ECRTime, an ensemble of ECR, markedly surpasses ECR, indicating that ECRTime also surpasses the aforementioned deep learning-based methods. Consequently, to reduce the redundancy of the experiments, we refrained from conducting a parallel comparative analysis for ECRTime as in Fig. 8."}, {"title": "4.3. Comparing with SOTAs", "content": "In the preceding section, we discussed ECR's significant outperformance of most deep learning classifiers on UCR112. This section broadens the comparative analysis to include all Time Series Classification (TSC) methods. We evaluated ECR against the eight leading state-of-the-art (SOTA) classifiers listed in Backoff-2023[4], namely: (1) HIVE-COTE 2.0[5], (2) Hydra-MR[6], (3) InceptionT[3], (4) RDST[7], (5) WEASEL-D[8], (6) RSTSF[9], (7) FreshPRINCE[10], and (8) PF[11]. Of these, HIVE-COTE 2.0 is recognized as the most accurate algorithm for TSC issues, albeit with considerable computational demands. InceptionT, on the other hand, is currently the most accurate deep learning-based TSC classifier. Detailed analysis of these SOTA classifiers can be found on website 4. Adhering to the methodology outlined in Backoff-2023, we conducted training and testing on the original UCR112 train/test set, as depicted in Fig. 9. The results indicate that ECR outperforms PF (the leading distance-based method), FreshPRINCE (the top feature-based method), and RSTSF (the foremost interval-based method). However, it is surpassed by the other five methodologies.\nTo extend our comparative analysis, we utilized the more efficacious ECRTime, an ensemble of three ECR models, against other SOTA methods. We provided scatter charts for detailed pairwise comparisons: between ECRTime and the most accurate deep learning-based method, InceptionT, as illustrated in Fig. 10(a), and with the leading algorithm, HIVE COTE 2.0, in Fig. 10(b). As depicted in Fig. 1, ECRTime marginally outperforms InceptionT, thereby becoming the most precise deep learning classification method currently used in TSC, although its margin over the second-ranked Hydra-MR is not statistically significant (p-value>0.05). Nonetheless, it considerably trails behind HIVE-COTE 2.0 (HC2), the most accurate classifier. In Fig. 10(a), ECRTime and InceptionT demonstrate comparable performance on half of the UCR112, each exhibiting superiority in the remaining datasets, with ECRTime having a narrow advantage (Wins: 29 versus 27). Fig. 10(b) shows a notable gap between ECRTime and HC2 (Wins: 23 versus 44), with ECR-Time displaying over a 20% shortfall in datasets such as Rocket, SemgHandMovementCh2, and SemgHandSubjectCh2. Future efforts will be directed towards enhancing ECRTime's performance in these specific datasets.\nUpon synthesizing the comparison results, it becomes clear that the ECRTime model introduced in this study matches the current top-performing deep learning classifier, InceptionT, in terms of overall effectiveness. To conduct a more detailed analysis of their strengths and weaknesses, we compared them based on the dataset types present in UCR112, namely the sequence source types. As depicted in Fig. 12(a), UCR112 encompasses 13 dataset types[4]. The DEVICE, IMAGE, MOTION, SENSOR, SIMULATED, and SPECTRO categories, which constitute 85% of the datasets, are the most significant, with DEVICE and SIMULATED being the smallest (9 datasets each) and IMAGE being the largest (32 datasets). The \"others\" category comprises 7 dataset types, each containing only 1-3 datasets. Due to the dominance of the first six categories in UCR112, we utilized boxplots to illustrate the accuracy variances between ECRTime and InceptionT across these categories. As shown in Fig. 12(b), ECRTime exceeds InceptionT in the DEVICE and SENSOR categories, equals InceptionT in the IMAGE and SPECTRO categories, and is marginally less effective than InceptionT in the MOTION and SIMULATED categories. These insights provide valuable guidance for researchers in choosing the most suitable approaches for diverse practical applications."}, {"title": "4.4. Runtime analysis", "content": "To enable a comparison of time efficiency with ECRTime, we extracted the average training time of various state-of-the-art methods on UCR142 from Backoff-2023 as an approximate for the time spent on UCR112. These comparative findings are presented in Table 2. ECRTime exhibits a reduced training duration compared to InceptionT. While it is more time-intensive than other CPU-based methods like RDST and Hydra-MR, leveraging parallel training on multiple GPUs can decrease its training time, as ECRTime is GPU-based. It is important to note that for this study, ECRTime was trained using an RTX3060 GPU, a less powerful consumer-grade graphics card. Utilizing more advanced graphics cards could lead to a further decrease in training duration."}, {"title": "4.5. Sensitivity study", "content": "We explore the effect of key parameter choices on accuracy over UCR112 for ECR and ECRTime:\n1-NN classifier versus SoftMax classifier.\nhard triplet loss versus triplet loss.\nensemble in ECR.\nensemble in ECRTime.\nbatch size."}, {"title": "4.5.1. 1-NN classifier versus SoftMax classifier", "content": "In Section 1, the phenomenon of \"inter-class similarity and intra-class inconsistency\" within UCR datasets was explored, and its adverse effect on the SoftMax classifier was analyzed. Consequently, the implementation of a 1-NN classifier was suggested as a potential mitigation strategy. This subsection details comparative experiments conducted on UCR112, contrasting the 1-NN classifier with the SoftMax classifier, based on ECR's classification sub-model. As depicted in Fig. 14(a), the integration of a 1-NN classifier with the classification network backbone shows a marginally better performance than the \"FC+SoftMax\" approach, though the difference is not statistically significant (p-value>0.05). Specifically, the average accuracies of these two methods on UCR112 were calculated to be 84.04% and 83.52%, respectively, signifying a modest improvement of 0.5% with the 1-NN classifier. Remarkably, for the HEMODYNAMICS-type PigCVP dataset, accuracy using the SoftMax classifier was a mere 31.25%, which notably increased to 87.98% when employing the 1-NN classifier, offering insightful implications for practical applications."}, {"title": "4.5.2. hard triplet loss versus triplet loss", "content": "To assess the impact of hard triplet loss versus triplet loss on the model, we separately trained the retrieval sub-model of ECR on UCR112 using each loss type. The findings, as illustrated in Fig. 14(b), indicate that hard triplet loss significantly enhances performance compared to standard triplet loss. Notably, the model employing hard triplet loss surpasses the latter in 82 of the 112 datasets, often by margins exceeding 5%, and with the greatest improvement approaching 50%. Furthermore, while the model underperforms relative to the triplet loss in 23 datasets, the performance decrease generally remains below 5%. These outcomes establish hard triplet loss as a considerably more effective option than traditional triplet loss."}, {"title": "4.5.3. batch size", "content": "The critical difference diagram presented in Fig. 17 elucidates the effect of batch size on ECR's performance. A horizontal line across different models in the diagram suggests no substantial difference in their performance across the 112 datasets, with a slight advantage for ECR(batch size equal to 16). Additionally, the diagram indicates that at batch sizes of 64 and 128, ECR does not demonstrate a significant benefit over ResNet (p-value>0.05). ECR's performance markedly surpasses that of other deep learning methods only at batch sizes of 32 and 16 (p-value<0.05). In this study, the chosen default batch size for ECR is 16."}, {"title": "4.5.4. ensemble in ECR", "content": "Fig. 15 shows the pairwise comparison results of the retrieval module vs. classification module, ECR vs. classification module, and ECR vs. retrieval module. As depicted in Fig. 15(a), a parity in performance is observed in only 17 of the 112 datasets, while each module exhibits strengths in the remaining 95 datasets. Remarkably, the retrieval module secures a performance edge exceeding 20% in datasets such as PigAirwayPressure and Wine. To harness the benefits of both modules, we integrated the classification and retrieval submodules to form the ECR model. This integration's efficacy, as demonstrated in Fig. 15(b), Fig. 15(c), and Fig. 18, reveals that the composite ECR model surpasses the performance of each individual submodule, thereby confirming the ensemble strategy's effectiveness. Additionally, an evaluation of ECR in contrast to classification(2) and retrieval(2), detailed in Fig. 16, establishes that ensembling two classification submodules or two retrieval submodules is less effective compared to an ensemble comprising one of each. Classification(2) refers to the approach of ensembling two classification models, following the method outlined in Eq. (6). Similarly, retrieval(2) follows a comparable approach. This finding underscores the complementary nature of the submodules within ECR, effectively balancing their respective strengths and limitations."}, {"title": "4.5.5. ensemble in ECRTime", "content": "The final ECRTime model presented in this study, which attains enhanced performance through the integration of multiple ECRs, was subjected to a comparative analysis focusing on the number of modules in the ensemble as a key hyperparameter. Fig. 19 illustrates that the performance of ECRTime significantly increases when the number of ECRs increases from 1 to 3. However, further expansion to 4 and 5 does not yield a notable improvement in performance, while concurrently increasing training duration. To strike an optimal balance between accuracy and computational efficiency, thereby boosting practical usability, this study finalizes the ensemble at three modules.\nA detailed examination of the enhancements achieved by ensembling three ECR models is conducted through a pairwise comparison between ECRTime and ECR on UCR112, employing scatter charts as presented in Fig. 16(c). This figure reveals that the ensembled ECRTime model exhibits improvements in 62 of the 112 datasets, though these improvements predominantly fall within a 5% range. A marginal decrease in performance is observed in 16 datasets, while the remaining 34 datasets exhibit no variation. Furthermore, a post-hoc statistical analysis confirms a significant distinction between ECRTime and ECR (p-value<0.05). In conclusion, ECRTime demonstrates better performance than ECR in time series classification tasks."}, {"title": "5. Conclusion", "content": "In the domain of deep learning-based time series classification employing the \"FC+SoftMax\" paradigm, replacing the SoftMax classifier with a 1-NN classifier has resulted in enhanced performance. Furthermore, to explicitly adapt to the classification objectives of the 1-NN classifier, we innovatively introduce a deep learning-based retrieval method for TSC issues. By combining this with the classification model in an ensemble, we present the ECRTime framework in this paper.\nECRTime exhibits a highly competitive and advanced standard in terms of accuracy and time complexity, matching or surpassing current state-of-the-art (SOTA) methods in Time Series Classification (TSC) tasks. In future research, we aim to delve deeper into the potential applications of retrieval methods within time series classification and to expand our exploration into the realm of multi-dimensional time series classification."}]}