{"title": "Enhancing the De-identification of Personally Identifiable Information in Educational Data", "authors": ["Yuntian Shen", "Zilyu Ji", "Jionghao Lin", "Kenneth R. Koedinger"], "abstract": "Abstract\u2014Protecting Personally Identifiable Information (PII), such as names, is a critical requirement in learning technologies to safeguard student and teacher privacy and maintain trust. Accurate PII detection is an essential step toward anonymizing sensitive information while preserving the utility of educational data. Motivated by recent advancements in artificial intelligence, our study investigates the GPT-40-mini model as a cost-effective and efficient solution for PII detection tasks. We explore both prompting and fine-tuning approaches and compare GPT-40- mini's performance against established frameworks, including Microsoft Presidio and Azure AI Language. Our evaluation on two public datasets, CRAPII and TSCC, demonstrates that the fine-tuned GPT-40-mini model achieves superior performance, with a recall of 0.9589 on CRAPII. Additionally, fine-tuned GPT-40-mini significantly improves precision scores (a threefold increase) while reducing computational costs to nearly one-tenth of those associated with Azure AI Language. Furthermore, our bias analysis reveals that the fine-tuned GPT-40-mini model consistently delivers accurate results across diverse cultural backgrounds and genders. The generalizability analysis using the TSCC dataset further highlights its robustness, achieving a recall of 0.9895 with minimal additional training data from TSCC. These results emphasize the potential of fine-tuned GPT-40-mini as an accurate and cost-effective tool for PII detection in educa- tional data. It offers robust privacy protection while preserving the data's utility for research and pedagogical analysis. Our code is available on GitHub: https://github.com/AnonJD/PrivacyAI", "sections": [{"title": "I. INTRODUCTION", "content": "PERSONALLY Identifiable Information (PII) includes the information (e.g., names, email addresses, and phone numbers) that can identify an individual. Protecting PII in edu- cational data is paramount as learning technologies, including artificial intelligence-powered systems, become increasingly integral to education across all levels. For instance, online human tutoring platforms collect vast amounts of interaction data, including conversational dialogues between students and tutors [1]. While the analysis of such educational data offers insights for data-informed research and improved pedagogical practices [2], [3], [4], it also introduces significant privacy risks due to the sensitive nature of PII [5]. Safeguarding PII is essential to prevent unauthorized access and misuse [6]. Moreover, robust privacy protections are vital for fostering trust among educational stakeholders\u2014students, educators, and parents\u2014and ensuring the responsible adoption of learn- ing technologies [7]. These efforts align with global regulatory frameworks, such as the General Data Protection Regulation (GDPR) and the Family Educational Rights and Privacy Act (FERPA), which mandate the protection of personal data [8]. Given the vast amounts of data collected by learning sys- tems, automating the anonymization of PII in the education domain has become a critical necessity. Previous work has explored rule-based, statistical-based, and neural network- based approaches to detect PII in education-related tasks, such as essay grading [3], [9]. Though showing effectiveness, given the advent of advanced artificial intelligence (AI) models, Pii detection can be further enhanced in detection accuracy, robustness, and generalizability when applied to diverse and complex educational datasets. Moreover, many previous works [10], [11], [12], [13] focus solely on redacting PII from the original data (e.g., the name John from the original sentence \"Thanks, John\" was processed by redacting \u201cThanks, [REDACTED]\u201d). While this approach mitigates certain risks, it falls short of ensuring comprehensive privacy protection, especially given that current models still fail to achieve perfect accuracy in PII detection [14]. This raises concerns about potential PII leakage. Thus, these challenges underscore the urgent need for more advanced, scalable, and robust methods to facilitate the anonymization process in educational data, ensuring comprehensive protection of PII and mitigating the risks of unintended exposure. As proposed by [6], the Hidden in Plain Sight (HIPS) method introduces the protection of PII in datasets by first identifying PII entities and then replacing them with synthetic information that retains contextual characteristics. Unlike tra- ditional redaction methods that use generic tokens such as [REDACTED] to redact PII, the first step of the HIPS method replaces PII with tokens that indicate the type of information, such as <Name>, <Email>, or <Address>. The process of identifying PII entities relies on Named Entity Recognition (NER), a task in natural language processing that aims to locate and classify specific entities within text into predefined categories, such as names, email addresses, and phone num- bers [15]. Once NER is performed on the data corpus, the original PII entities can be replaced with synthetic information while retaining their contextual relevance. For example, a sentence such as \u201c{John Smith}Name lives at {123 Main"}, {"title": "II. RELATED WORK", "content": "A significant aspect of the deployment of learning tech- nologies in the actual learning and teaching environment is ensuring data privacy. To address the concern about data privacy, two commonly used deidentification methods are direct redaction and Hidden-In-Plain-Sight (HIPS) [10], [20]. Both approaches aim to safeguard PII by concealing sensitive data but differ significantly in their implementation and impact on downstream data usability. Redaction is one of the most widely used methods for PII protection in education-related research [12], [21]. In this approach, sensitive information is replaced with generic place- holders, such as \u201c[REDACTED]\u201d, effectively removing it from the dataset. For example, the sentence: \u201cJohn Smith contacted the office via john.smith@example.com\" can be redacted as \u201c[REDACTED] contacted the office via [REDACTED].\" While redaction is effective at concealing sensitive information, maintaining consistently high accuracy in PII detection often comes at a significant cost. For instance, the study by [17] employed prompting with the GPT-4 model, which incurs expenses of $30.00 per 1M input tokens and $60.00 per 1M output tokens. Given the vast amounts of data collected from learning systems, it is crucial to strike a balance between cost and performance to ensure practical scalability. The HIPS method offers a more nuanced approach to pro- tecting PII [6]. Instead of simply redacting sensitive informa- tion, HIPS replaces PII entities with synthetic but semantically equivalent placeholders that retain the category of the original information [16]. Compared to the redaction method, HIPS could effectively enhance privacy protection. Even if some PII entities are missed during the initial detection step, their replacement with synthetic counterparts ensures no sensitive information is exposed. For example, In [22], the MIST system is used to identify PII entities, after which the HIPS method is used to replace those identified entities with realistic surrogates across two corpora. Following substitution, expert annotators examine the anonymized corpus to detect leaked PII\u2014the entities that MIST failed to identify. On average, only 26.8% of the leaked PII are detected, and 62.8% of the entities considered leaked by human attackers are actually not leaked PII. In [20], Osborne et al. introduce BRATsynthetic as a novel HIPS replacement strategy that leverages a Markov chain-based approach to dynamically substitute PII entities with realistic surrogates. This method notably reduces the risk of PII leakage due to false negatives in PHI detection. For instance, under a 5% false negative error rate, document-level leakage is decreased from 94.2% (using a traditional HIPS replacement) to 57.7%. It should be noted that the effectiveness of the HIPS method relies heavily on the accuracy of the Named Entity Recognition (NER) step. Misidentified entities (false positives) could lead to unnecessary replacements, disrupting the dataset's integrity [5], [23]. Conversely, undetected PII (false negatives) could leave sensitive information exposed. Thus, enhancing precision is important. However, existing work in the AI in the education field that focuses on developing Named Entity Recognition (NER) systems for downstream HIPS replacement still demon- strates low precision scores. For example, a study reported a precision score of 0.24 [24]. Given the advantages of using the HIPS method compared to redaction, our study focuses on the application of the HIPS method and particularly aims to enhance the detection of PII entities."}, {"title": "B. Large Language Models for Data Privacy", "content": "Recent advancements in LLMs, such as GPT-4, which are trained on extensive datasets from diverse domains, enable them to capture long-range dependencies and contextual nu- ances that are crucial for identifying PII. Studies leveraging GPT-based models have demonstrated their ability to achieve high recall scores, effectively identifying a broad range of PII entities [25]. Additionally, LLMs can leverage this internal knowledge to distinguish actual PII from non-PII. Some recent evidence supports this view: for instance, a recent study prompts GPT-3 for a NER task, suggesting that fine-tuning such large models could yield more notable results [25], especially since fine-tuned LLMs tend to outperform their prompted counterparts on NLP tasks [26], [27]. The approach of fine-tuning an LLM for PII identification aligns well with the emerging AI-for-education domain, where labeled text data for PII identification are often scarce and fragmented. Due to this limited availability, a model can be trained on data that are not representative of the actual use case, and less experienced users may require a tool that can quickly adapt to their specific domain. Consequently, a source model capable of learning effectively from sparse and unrepresentative datasets is needed. Previous work has shown that an LLM can be fine-tuned with just a few la- beled examples (few-shot learning) [27]. Although studies also indicate that successful few-shot learning is achievable with other architectures, these typically require carefully designed learning strategies and meticulous parameter tuning to prevent overfitting [28], [29]. In contrast, larger LLMs have been proven to be more resistant to overfitting as their size increases [27], [30], potentially owing to their memorization dynamics [31]. A final advantage of fine-tuning an LLM for PII de-identification lies in its lower financial and computational cost compared to prompt-engineering an LLM for PII de-identification, which often requires multiple demonstrations in the input prompts [25]. The above observation highlights the potential for fine-tuning large models, with GPT emerging as a promising candidate. Several studies have utilized prompted GPT approaches to de-identify PII entities, demonstrating encouraging results [17], [25]. With the growing availability of cost-effective fine-tuning APIs \u00b9 and the lack of prior work using fine-tuned GPT for PII identification, we aim to explore this approach further."}, {"title": "III. METHODS", "content": "Our study utilized the Cleaned Repository of Annotated Per- sonally Identifiable Information (CRAPII)\u00b2 dataset [14], which comprises 22,688 samples of student writings collected from a massive open online course (MOOC) offered by a university in the United States. The course focused on critical thinking through design, teaching learners strategies such as story- telling and visualization to solve real-world problems [14]. The dataset includes seven PII categories as direct identifiers: Names, Email Addresses, Usernames, IDs, Phone Numbers, Personal URLs, and Street Addresses [14]. A sample of the dataset is shown in Table I. In total, the dataset contains 4,871 labeled words categorized as PII entities. To enable entity-based matching during our analysis, we extracted the character-wise positions of all annotated PII entities within the text."}, {"title": "B. Models for PII Detection", "content": "Microsoft Presidio.3 It is an open-source toolkit designed for detecting and anonymizing PII across various text and image formats. It offers pre-built NER (Named Entity Recog- nition) models, such as en_core_web_lg and en_core_web_trf, which utilize linguistic patterns and deep learning techniques to classify words or phrase into predefined named entities (e.g., names, emails, and phone numbers). Additionally, Presidio provides options for integrating external machine learning models for enhancing PII detection. In our study, Presidio serves as one of the baseline models for detecting PII entities. As indicated in previous work [14], en_core_web_lg is a standard NER model based on the spaCy framework that primarily relies on statistical tech- niques, while the transformer-based en_core_web_trf lever- ages pre-trained transformers, capturing long-range dependen- cies for more accurate context-based entity recognition. Thus, we primarily used these two configurations: en_core_web_lg and en_core_web_trf, as depicted in Fig. 1 (1). Azure AI Language. It offers a cloud-based PII detection service capable of identifying and redacting sensitive informa- tion such as phone numbers and email addresses. Our study adopted Azure AI Language as one of the baseline models for detecting PII entities in our dataset, as illustrated in Fig. 1 (\u2461). We used asynchronous processing through the REST API to handle texts up to 125,000 characters per document. This approach is necessary because the longest transcript in our GPT-40-mini (Prompting). Motivated by the effectiveness of prompting LLMs in de-identifying PII, as demonstrated in a recent study [17], our study adapts their prompting strategy with modifications to fit our task. Instead of em- ploying GPT-4, as used in their work [17], we opted for GPT-40-mini, which requires only 1/200 of the cost per million input tokens and 1/100 of the cost per million output tokens compared to GPT-48. Then, we modified the prompt structure by leveraging special identifiers for labeling detected entities rather than using a redaction method such as replacing detected PII with a generic label like [REDACTED] as shown in their work [17]. Inspired by the GPT-NER method [25], special identifiers can be used to mark entities, preserving non-PII content and ensuring precise PII detection. This method also reduces issues such as hallucinations and over-labeling that can arise with generative models. In particular, we require the detected entity positions to be an exact match to the true entity positions, but GPT often struggles with positional accuracy in long texts due to hallucinations and counting limitations [32]. To address this, we let GPT label detected PII entities by surrounding them with special identifiers for different categories, as outlined in Table II, and subsequently extract them using regular expressions, ensuring accurate detection and positioning."}, {"title": "GPT-40-mini (Fine-tuning).", "content": "Recent studies [4] have demonstrated the effectiveness of fine-tuning LLMs for NER tasks, specifically showing that fine-tuned LLMs significantly outperform prompting-based approaches in accurately identi- fying entities. Inspired by these findings, our study employed a fine-tuning strategy on GPT-40-mini for PII detection. We utilized the same approach of incorporating special tokens, as shown in Table II. Then, GPT-40-mini was fine-tuned on the training dataset and evaluated on the test dataset to assess its performance. The detailed structure of the system, user, and assistant prompts used during the fine-tuning process is presented in Table IV, while the implementation process is illustrated in Fig. 1 (4)."}, {"title": "Verifier Models.", "content": "To improve the precision (Equation 1) of PII detection while maintaining recall (Equation 2), we propose the addition of a verifier model as a second step to verify whether predictions are accurately identified as PII. This approach is inspired by recent studies [34], [35] that integrate verifiers into multi-step reasoning tasks in LLMs. For the implementation of verifier models, we propose two variants: Verifier Model I (Without CoT) and Verifier Model II (With CoT). These verifier models assess detected entities within their surrounding context to eliminate false positives while retaining true PII entities, thereby enhancing the precision of PII detection systems. Both verifiers are fine-tuned versions of the GPT-40-mini model. The process of the verifier model approach is illustrated in Fig. 1 (5). The Verifier Model II (With CoT) incorporates Chain- of-Thought (CoT) reasoning, a method shown to enhance decision-making by breaking down complex problems into intermediate steps [36]. The Verifier Model II (With CoT) aims to improve interpretability and robustness by generating reasoning before the final classification. However, it generates more output tokens, leading to higher computational costs. The Verifier Model I (Without CoT), which directly classifies"}, {"title": "C. Splitting Data for Training and Testing", "content": "Our study focuses on four specific categories from the CRAPII dataset for PII detection: NAME, URL_PERSONAL, EMAIL, and PHONE_NUM. To support the training and evalu- ation requirements of our experiments, the 22,688 files in the CRAPII dataset are split into three distinct sets: Base Train Set (25%, 5,672 files), Verifier Train Set (15%, 3,403 files), and Test Set (60%, 13,613 files). This split ensures that all sets contain a sufficient number of entities from each category, including rare categories such as PHONE_NUM, which only has 15 entities in total."}, {"title": "D. Evaluation Metrics", "content": "When evaluating the performance of a model designed to detect PII, it is essential to assess the model's ability to correctly identify true PII entities while minimizing incorrect classifications. The True Positives (TP) indicate the number of correctly identified PII entities. The False Positives (FP) rep- resent the number of non-PII entities incorrectly classified as PII, which can reduce the utility of the dataset by unnecessarily removing valuable information. The False Negatives (FN) denote the number of missed detections of actual PII entities, which could result in privacy breaches and violations of legal regulations. To evaluate the model's capability in accurately detecting PII, we adopt the evaluation method suggested in [15]. This method considers a PII entity to be correctly identified only if it is an exact match with the corresponding entity in the text data. To provide a comprehensive assessment of the model's performance, we consider multiple metrics that capture different aspects of the model's effectiveness. Precision (Equation 1) measures the proportion of correct PII predictions out of all entities that the model classified as PII. High precision means that when the model identifies words as PII, it is very likely to be correct. This is particularly important when false positives (incorrectly labeling non-PII as PII) are costly or disruptive, such as when anonymizing educational datasets where unnecessary removal of non-PII data can reduce the value of the dataset for analysis."}, {"title": "E. Analysis of Cultural and Gender Bias in Name Detection by Models", "content": "Evaluating the model's performance in detecting <NAME_STUDENT> entities across different cultural and gender distributions is quite important. Models trained on imbalanced datasets may underperform in identifying names of groups that are underrepresented in training data. Specifically, if the training data lacks sufficient representation of names from certain cultural backgrounds, the model may exhibit a lower recall or precision for those names. This dimension of model evaluation is necessary to ensure fairness and inclusivity in PII detection systems, especially as names serve as direct identifiers with critical privacy implications. We analyzed the cultural and gender distributions of the names in the <NAME_STUDENT> entities in detail by using a two-step approach. First, we used a rule-based name parser10 to split each name into components, typically a first name and a last name. We then determined the gender of each name based on the first name and matched the nationality using the last name. This method aligns with the approach described in the CRAPII paper [14]. In the second step, we mapped the identified countries to their respective regional cultures using the ISO-3166 dataset with the UN regional codes\u00b9\u00b9. Specifically, we relied on the all.format file, which includes detailed regional and sub-regional classifica- tions for each country. For example, \"Nigeria\" maps to the Africa region, while \"United States of America\" maps to the Americas. The ISO-3166 dataset provides five cultural regions: Asia, Americas, Europe, Africa, and Oceania. Notably, no names in the CRAPII dataset belonged to Oceania, so we focused on the remaining four cultural groups."}, {"title": "F. Analysis of Models' Generalizability", "content": "To analyze the generalizability of our investigated models, we employed the TSCC dataset, as introduced in Section III-A. Notably, the TSCC dataset has been pre-redacted, with most redacted words replaced by placeholders indicating their name entity types, such as <STUDENT> and <TEACHER>. To evaluate the model's ability to generalize across diverse contexts, it was necessary to replace these placeholders with synthetic entities that reflect diversity in gender and cultural backgrounds. This replacement ensures a realistic evaluation of the models' performance when encountering unseen data with varying demographic characteristics. To generate a diverse and representative set of synthetic names, we systematically cre- ated a mapping of first and last names categorized by gender and cultural groups. This process involved the following steps:"}, {"title": "IV. RESULTS AND DISCUSSION", "content": "The performance metrics of all proposed PII detection models are summarized in Table VII. A. Overall-Level Analysis of Model Performance 1) Presidio Models: For the two Presidio models utilizing different SpaCy configurations, en_core_web_trf consistently outperforms en_core_web_lg across all metrics, as shown in Table VII. The transformer-based en_core_web_trf achieves higher overall precision (0.2092 vs. 0.1505) and recall (0.8368 vs. 0.7103), likely due to its enhanced ability to capture long-range dependencies in text. However, both configurations exhibit low precision, which is likely due to the inclusive detection approach of the models. Although this approach enables the identification of a wide range of entities, including less common ones, it also leads to a significant number of false positives, thereby reducing overall precision."}, {"title": "2) Azure Al Language:", "content": "The Azure AI Language model achieves an overall precision of 0.2462 and a recall of 0.9212, with the recall being the second highest across all models, slightly lower than the fine-tuned GPT-4o-mini model. Its strong recall highlights its ability to capture most true pos- itives, reflected in the low number of false negatives (228). However, the low precision of the model, driven by a high number of false positives (8,160), limits its reliability for applications that require accurate predictions. The F\u2081 score of 0.3885 and F5 score of 0.8333 further emphasize its recall- oriented nature, indicating that while Azure AI Language improves recall compared to rule-based methods, it struggles to maintain precision, resulting in an imbalanced trade-off. 3) Prompting GPT-40-mini: The prompting GPT-40-mini model achieves an overall precision of 0.6593 and recall of 0.7781, resulting in an F\u2081 score of 0.7138 and an F5 score of 0.7727. Although the model demonstrates notable improve- ments in precision compared to rule-based approaches such as Presidio, its relatively low recall, as evidenced by the 642 false negatives, indicates that a significant number of true positives are missed. This limitation suggests that the model may not be ideal for contexts that require exhaustive PII detection. Despite these challenges, the improvement in precision highlights the potential of GPT-40-mini's prompting capabilities, particularly for scenarios where accuracy is prioritized over comprehensive detection. 4) Fine-tuned GPT-40-mini: The fine-tuned GPT-40-mini model demonstrates strong overall performance, achieving the highest recall among all models at 0.9589. This high recall ensures that nearly all PII entities are identified, making the model highly effective for comprehensive privacy protection. Its precision of 0.6042 represents a notable improvement over both the Presidio and Azure AI Language models, highlighting the benefits of fine-tuning in balancing precision and recall. The model achieves the highest F5 score (0.9377) among all models, balancing high recall with reasonable precision. This highlights the potential of fine-tuning GPT-40-mini for PII detection in educational texts, offering clear advantages over baseline and prompting models. 5) Verifier Models: The Verifier Model I (Without CoT) achieves the highest precision (0.8893) among all models by not defaulting to retaining entities when uncertain. However, this less conservative approach leads to the wrong removal of some true positives during verification, resulting in a lower recall of 0.8023. The Verifier Model II (With CoT) demonstrates a more balanced trade-off with a recall of 0.8648, as its conservative behavior defaults to retaining entities (T) when uncertainty arises. Notably, the precision scores for"}, {"title": "B. PII Category-Level Analysis of Model Performance", "content": "1) Name Detection (NAME_STUDENT): The Presidio mod- els demonstrate low precision (0.1626 and 0.2408) due to over- identifying common names, leading to a high number of false positives, but maintain moderate recall (0.6916 and 0.8322). The Fine-tuned GPT-40-mini model achieves the highest recall (0.9605) and F5 score (0.9398), making it the most reliable for comprehensive name detection, despite a moderate precision of 0.6109. The Verifier Model I (Without CoT) achieves the highest precision (0.8830) but sacrifices recall (0.8038). For names as a direct identifier, we recommend the Fine-tuned GPT-40-mini model, given its superior recall and F5 score. 2) URL Detection (URL_PERSONAL): The Fine-tuned GPT-40-mini model achieves the highest recall (0.9387) and F5 score (0.9069), indicating a strong performance in cap- turing true positives. However, its precision (0.4914) remains moderate, suggesting room for improvement in reducing false positives. The Verifier Model I (Without CoT) significantly im- proves precision, achieving the highest value (0.9877) and F\u2081 score (0.8587), but at the cost of reduced recall (0.7594). This demonstrates the verifier model's effectiveness in filtering false positives while highlighting the inherent trade-off between precision and recall, as no model achieves high performance in both metrics simultaneously. 3) Email Detection (EMAIL): All models demonstrate strong performance in detecting email entities, with recall values consistently high across both rule-based and GPT- based methods. The Presidio models and Azure Al Language achieve the highest recall (0.9839), missing only one true email entity out of 61, followed closely by the Fine-tuned GPT-40-mini model and both Verifier models with a recall of 0.9677. In terms of precision, Azure AI Language achieves the highest value (0.8841), while the Presidio models (0.8592), Fine-tuned GPT-40-mini model (0.8571), and Verifier Model I (Without CoT) (0.8824) also perform well. In general, email detection appears to be a relatively straightforward task, with most models achieving strong performance in both recall and precision, as reflected by their high F\u2081 and F5 scores. 4) Phone Number Detection (PHONE_NUM): Five models, including both Presidio models, Azure AI Language, Fine- tuned GPT-40-mini, and Verifier Model II (With CoT), achieve the highest recall of 0.8889 for phone number detection. However, Presidio and Azure Al Language exhibit low pre- cision, with Azure showing the lowest precision of 0.0473. In contrast, GPT-based models demonstrate higher precision, with the Fine-tuned GPT-40-mini model reaching 0.6667. The Verifier Model I (Without CoT) records the lowest recall (0.2222), suggesting that it likely removed many true positives from the Fine-tuned GPT-40-mini model's detected entities, possibly due to the lack of Chain-of-Thought reasoning. The Verifier Model II (With CoT) achieves the highest F\u2081 (0.8000) and F5 (0.8814) scores, balancing strong precision and recall."}, {"title": "C. Impact of Low-Precision PII Detection: Examples of Se- mantic Disruption", "content": "To better understand how low-precision PII detection can disrupt the semantic integrity of datasets and hinder down- stream data analysis for educational research, we present three examples. These examples demonstrate cases where Presidio and Azure AI Language incorrectly identify non-PII entities as PII (false positives), resulting in unnecessary replacements that alter the intended meaning of the data. Such disruptions can negatively impact the utility of the data for educational insights and analysis. In contrast, all GPT-based models successfully identify these cases as non-PII (true negatives), thereby pre- serving the semantic meaning and ensuring the dataset's utility for downstream research tasks. In Example 1, Presidio incorrectly identifies Jesus Christ, Mary, Joseph, and Jesus as PII. However, these names are not sensitive information in this context but are instead cen- tral to the story's historical and cultural narrative. The clue \"Nazareth\" is a key component of the story, as it is widely recognized as the hometown of Jesus Christ. Replacing the associated names with synthetic alternatives disrupts the edu- cational purpose of the text, as students may no longer connect \"Nazareth\" to its religious significance. This could lead to misunderstandings and confusion in the learning process. Original: At the beginning of the story, you do not know the names of the characters. Then at the end, I drop the first clue \"Nazareth\" - which is well known to be the home town of Jesus Christ. You can maybe guess that the family are Mary and Joseph with Jesus as a boy. Replaced: At the beginning of the story, you do not know the names of the characters. Then at the end, I drop the first clue \"Nazareth\" - which is well known to be the home town of Elias Carson. You can maybe guess that the family are Lena and Daniel with Elijah as a boy. The incorrect anonymization of names changes the intended meaning of the text, as the connection between \"Nazareth\" and its historical and religious significance is lost. This disruption affects students' understanding and the utility of the data in educational contexts. Moreover, anonymization negatively impacts the utility of the text for machine learning applications. If the anonymized text is used to train or fine- tune a language model or included in a knowledge base for a Retrieval-Augmented Generation (RAG) pipeline, it may result in incorrect or misleading responses to queries about \u201cNazareth\u201d [37]. Repeated inclusion of anonymized instances, such as associating \"Nazareth\" with unrelated names like"}, {"title": "D. Cost Analysis", "content": "Table VIII presents the cost associated with each PII detection model, complementing the performance metrics in Table VII. The results emphasize the potential of GPT-based approaches, particularly the Fine-tuned GPT-40-mini model, for high-quality PII detection at significantly lower costs. The Fine-tuned GPT-40-mini model achieves the highest overall recall (0.9589) and F5 score (0.9377), outperforming both the free Presidio models and the expensive Azure AI Language model. While the Presidio models incur no cost, their low precision (0.1505 and 0.2092) and F5 scores (0.6214 and 0.7503) highlight their limitations in balancing false positives and true positives. In contrast, the Azure AI Language model, though more precise, costs $63.27 ($4.90 per 1M tokens), which is approximately 6 times higher than the Fine- tuned GPT-40-mini model ($0.92 per 1M tokens). Then, the Verifier models marginally increase the total cost to $13.97 (Without CoT) and $14.69 (With CoT), enhancing precision for applications where minimizing false positives is critical. Despite the additional cost, these models remain far more economical than Azure AI Language model while retaining GPT's high recall and semantic accuracy. Thus, GPT-based models, led by the Fine-tuned GPT-40-mini model, outperform both Presidio and Azure AI Language in balancing cost and performance. This underscores their potential as an efficient and scalable solution for PII detection in educational data."}, {"title": "E. Name Culture and Gender Bias Analysis", "content": "Based on the detection performance in Table VII, we se- lected three models-Presidio with en_core_web_trf, Azure AI Language, and Fine-tuned GPT-40-mini\u2014for the analysis of cultural and gender bias in name detection. The total number of entities for each gender and culture group and their recall are shown in Table IX. Gender Analysis. The results indicate that the recall scores between male and female names across the three models are similar. For Presidio and Azure AI Language, there is a marginally higher recall for female names compared to male names. Specifically, Azure Al Language achieves a recall of 0.9541 for female names and 0.9494 for male names. In contrast, the fine-tuned GPT-40-mini model performs slightly better on male names (0.9646) compared to female names (0.9591). However, the differences in recall for male and female names are minimal, suggesting consistent performance between gender groups in all models. Culture Analysis. The cultural analysis reveals more signif- icant differences in model performance. Both Microsoft mod- els show lower recall for African and Asian names. In partic- ular, Presidio exhibits a notable performance gap, with recall rates of 0.7647 for African names and 0.8640 for Asian names, compared to 0.9024 for European and 0.9091 for American names. Azure Al Language also shows a lower recall for African names (0.9244), although the gap is less pronounced than in Presidio. These results suggest inherent biases in the Microsoft models, possibly stemming from imbalances in the training data or gaps in cultural representation. In contrast, the fine-tuned GPT-40-mini model achieves consistent and high recall across all cultural groups. It performs with recall scores of 0.9756 for European names, 0.9790 for American names, 0.9840 for Asian names, and 0.9748 for African names. This minimal variation in recall across cultural groups demonstrates the model's ability to mitigate cultural bias and generalize effectively across diverse name distributions. Therefore, the gender analysis does not show significant differences in recall for male and female names across all models, indicating consistent performance in this aspect. How- ever, cultural analysis reveals that both Presidio and Azure"}, {"title": "F. Generalizability Analysis", "content": "To further evaluate the performance of different models for PII detection, we further used the TSCC dataset (as introduced in Section III-A) to evaluate the models that were implemented on the CRAPII dataset. Table X presents the performance for different PII detection models on the TSCC dataset. The metrics are the same as those presented in Table VII. We selected one Presidio model Presidio (en_core_web_trf) model as it demonstrated higher precision and recall compared to the en_core_web_lg variant (Model 1 from Table VII). As shown in Table X, the Presidio (en_core_web_trf) model demonstrates relatively high recall (0.9368) and low precision (0.3596). This is likely due to its conservative approach to entity detection, which enables it to capture a wide range of entities, including rare or unconventional names. This conser- vatism results in a large number of false positives (2,694), the highest among all six models"}]}