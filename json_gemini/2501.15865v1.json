{"title": "Transfer of Knowledge through Reverse Annealing: A Preliminary Analysis of the Benefits and What to Share", "authors": ["Eneko Osaba", "Esther Villar-Rodriguez"], "abstract": "Being immersed in the NISQ-era, current quantum annealers present limitations for solving optimization problems efficiently. To mitigate these limitations, D-Wave Systems developed a mechanism called Reverse Annealing, a specific type of quantum annealing designed to perform local refinement of good states found elsewhere. Despite the research activity around Reverse Annealing, none has theorized about the possible benefits related to the transfer of knowledge under this paradigm. This work moves in that direction and is driven by experimentation focused on answering two key research questions: i) is reverse annealing a paradigm that can benefit from knowledge transfer between similar problems? and ii) can we infer the characteristics that an input solution should meet to help increase the probability of success? To properly guide the tests in this paper, the well-known Knapsack Problem has been chosen for benchmarking purposes, using a total of 34 instances composed of 14 and 16 items.", "sections": [{"title": "INTRODUCTION", "content": "A quantum annealer (QA, (1)) is a specific kind of quantum device designed to deal with optimization problems by means of a process inspired by classical Simulated Annealing (2). These computers leverage quantum mechanics to efficiently explore solution spaces in an attempt to find the optimum value of a given objective function. Today, advances in quantum technologies have contributed to the building of intermediate-scale QAs that implement quantum annealing for programmable use. There are different platforms for building quantum annealers, such as optical tweezers (3) or superconducting integrated circuits (4), with the latter being the most recognized to date. Additionally, several companies are working on this technology and building their own devices, such as NEC\u00b9, Qilimanjaro\u00b2, and D-Wave Systems\u00b3.\nHowever, all the progress made in recent years was born in the NISQ-era (5), when quantum devices present great limitations in solving optimization problems efficiently, even when these problems are small- or medium-sized. As a consequence, the community as a whole is striving to devise schemes and mechanisms to address the current limitations and take advantage of the potential that quantum computing currently offers. Among the most common strategies are the design and implementation of advanced hybrid"}, {"title": "METHOD", "content": "RA is a specific type of quantum annealing designed to perform local refinement of good states found elsewhere (15). To achieve this, RA resorts to a time-dependent Hamiltonian:\n$H(t) = A(s(t))H_0 + B(s(t))H_1$\nin which $s(t) \u2208 [0, 1]$, and $A(s)$ and $B(s)$ are time-dependent amplitudes that must satisfy $A(0) \u226b B(0)$ and $A(1) \u226a B(1)$. Additionally, $H_0$ defines the initial Hamiltonian, while the final Hamiltonian $H_1$ corresponds to the unconstrained optimization problem, with a ground state that represents the computational solution. In contrast to forward annealing, RA reverses the time-evolution procedure by starting in an eigenstate of $H_1$ and evolving under Equation (1) in the opposite direction. Thus, $H(t) = H(1)$ at t=0, and the process is divided into three different steps in which the Hamiltonian:"}, {"title": null, "content": "1. First evolves backward to a previously specified point $s_p$ in the control schedule in a time $t_r = t_1$ coined ramp-time.\n2. Then is paused for a time $t_p = t_2 - t_1$ (this step is optional).\n3. It finally evolves forward from $s_p$ at $t_2$ to the final Hamiltonian at time T for a $t_q = T - t_2$ quench time.\nTherefore, the RA Schedule can be defined as (18):\n$s(t) = \begin{cases}\n1 + s_p\\frac{t}{t_1},-1 & 0\u2264 t \u2264t_1, \\ \ns_p, & t_1 \u2264 t \u2264t_2, \\ \ns_p+\\frac{1-s_p}{T-t_2}(t-t_2), & t_2 \u2264 t \u2264 T.\n\\end{cases}$"}, {"title": "EXPERIMENTATION & DISCUSSION", "content": "Before starting with the description of the experimentation, it is important to note that there is no metric that accurately indicates how similar two problems are to each other (in order to make them good candidates for ToK). The existence of such a metric would be very advantageous for this purpose. More specifically, similarity should be measured in terms of overlap in the energy landscape of a unified search space (34). However, in the real world, it is not possible to determine this overlap beforehand without having executed and, therefore, solved the problem. Given this circumstance, similarity becomes a matter of intuition and subject to the domain knowledge acquired by the expert. This situation does not detract an iota of value because, in real industrial contexts, most problems have a repetitive nature: a pool of recurring customers in routing problems, production of similar materials with stable task typologies and machines, etc. In such situations, ToK is a promising strategy to resort to past solutions in order to improve the results or speed up the computation of a new, yet similar, task.\nWith this in mind, the experimentation carried out in this paper uses the well-known KP as a benchmarking problem. In a nutshell, KP consists of a set P composed of n items, describing each item $p_i$ by profit ($v_i$) and weight ($w_i$), which must be packed into a container with a maximum capacity W. The objective, therefore, is to select a subset of items to be stored that, without exceeding W, maximizes the profit obtained. It is worth noting that the metric used in this study for measuring the quality of a solution corresponds to the energy provided by the quantum annealer, which should be minimized. That is, the less energy, the better the solution.\nAiming to provide an answer to the above-presented RQs, we have designed two separate experiments focused on two parent-instances of the KP, which are composed of 14 ($s_{14}$) and 16 ($s_{16}$) items, respectively. Both instances have been generated ad hoc for this study with the values v and w randomly selected from {1,2,3,4}. Finally, $W = (\\sum_{i=1}^{n} W_i)/2$.\nTaking these cases, each descendant-instance has been generated by applying the following strategy:\n\u2022 First, the newly generated descendant-instance starts out as an exact copy of the corresponding parent-instance.\n\u2022 Then, a set P' is created, consisting of all the unique items in P along with their energy impact. Provided that each item $p_i$ in P is described as a tuple $v_i, w_i$, a unique item in P' means that it differs from the others in at least one element of the tuple."}, {"title": null, "content": "\u2022 Next, a certain number of items of the descendant-instance are modified following this criterion: when the purpose is to increase the energy impact of an item $p_i$, it is replaced by the next highest energetic item in P'. Analogously, $p_i$ is replaced by the next lowest energy item in P' when the objective is to reduce the energy. It should be noted that the items with the highest and lowest energy are never modified in the creation of descendant-instances.\nFollowing this strategy, 16 descendant-instances have been created for each parent-instance, equally divided into four categories:\n\u2022 X_L2L - Lowest-Energy-to-Lower-Energy: X% of the less energetic variables (i.e., items) of the parent-instance are selected and modified so that their energetic impact is even lower.\n\u2022 X_L2H - Lowest-Energy-to-Higher-Energy: X% of the less energetic variables of the parent-instance are selected and modified so that their energetic impact is greater.\n\u2022 X_H2L - Highest-Energy-to-Lower-Energy: X% of the highest energetic items of the parent-instance are selected and modified so that their energetic impact is lower.\n\u2022 X_H2H - Highest-Energy-to-Higher-Energy: X% of the highest energetic variables are selected and modified so that their energetic impact is even greater.\nIt is noteworthy that solutions to these problems are represented by a (n + s)-long vector, where n is the number of items that compose the instance and s are slack terms introduced by the penalties. For both $s_{14}$ and $s_{16}$, s = 5, so that the decision variables for each problem are 19 and 21, respectively. In our study, the variables eventually modified correspond only to the first n items.\nSystematically, knowledge transfer is materialized in our experimentation by taking a descendant-instance as the source-task and a parent-instance as the target-task to be solved. That is, the goal is to solve a parent-instance leveraging the knowledge of a previously solved descendant-instance."}, {"title": "RQ1: Is RA a paradigm that can benefit from knowledge transfer between problem instances with similar characteristics?", "content": "A second set of tests has been conducted for properly answering RQ1, consisting of solving each target-instance s14 and s16 by means of RA procedure and using as input solution the best solutions found for each descendant-instance through the first tests summarized in Table 1.\nA fixed RA schedule has been used for all the tests, [(0.0, 1.0), (2.5, 0.5), (102.5, 0.5), (102.75, 1.0)], which has been obtained through an empirical procedure performed in lab. For the sake of fair comparison, the annealing_time of all the forward annealing processes has been adjusted to the RA schedule duration so that all runs carried out in this research access the quantum computer the same amount of time. We recommend papers such as (18) to readers interested in the analysis of the reverse annealing schedule. Lastly, reinitialize_state=True.\nFor each (source instance - target instance) combination, 10 independent runs have been executed, with Table 2 depicting the best result found among these executions, along with the average and the standard deviation. As an example, 10 independent runs have been executed to solve s14, using the best solution found for s14_0.2_L2L as the input bitstring in the RA process (i.e., source of knowledge). For this combination, the energy of the best solution found is -12421, while the average and standard deviation are -12420.2 and 0.74, respectively. For comparison purposes, we also depict in Table 2 the baseline results obtained by s14 and s16 by means of forward annealing. In these cases, the source of knowledge has been represented as \u201c\u2013\u201d."}, {"title": "RQ2: Can we infer the characteristics that an input solution should meet to help increase the probability of succeeding in a RA process?", "content": "Although there is a widespread belief in the literature that RA is more effective when the initial state is \"close\" to the ground state (24), there is no exact definition for the term \u201cclose\u201d in this context. Some"}, {"title": "CONCLUSIONS & FURTHER WORK", "content": "In this work, we have preliminarily studied the influence of transferring knowledge between similar tasks through the reverse annealing mechanism implemented by D-Wave. To do that, two research questions have been posed:\nRQ1: Is RA a paradigm that can benefit from knowledge transfer between problem instances with similar characteristics?\nRQ2: Can we infer the characteristics that an input solution should meet to help increase the probability of succeeding in a RA process?\nFirstly, answering RQ1 and in view of the positive results obtained, the transfer of knowledge in quantum computing appears to be a promising research avenue that undoubtedly deserves further investigation. As for RA, it is commonly applied as a local refinement procedure right after an optimization process carried out by forward annealing or a classical optimization technique. In this work, RA serves as a mechanism for knowledge transfer, allowing the reuse of a solution obtained in an independent optimization process.\nIt is important to highlight that, aside from the results regarding performance, knowledge sharing pursues savings in the use of computational resources. These savings are mainly materialized by resorting to previous outcomes when solving a new task under the assumption that industries are likely to face tasks that have a lot in common with each other. This is especially useful in real-world environments where companies accumulate results from past planning exercises and continually receive new tasks that are sometimes not very distinct from those already executed.\nSecondly, answering RQ2 and according to the results depicted, the closeness in terms of energy is not related to the performance of RA, and only the closeness with respect to the Hamming distance is. This means that the neighborhood must be based on solution codification and not energy, making it a priority to organize the coding of the target problem so that it fits as much as possible with the source problem through a unified search space (34).\nIn light of these positive results, there are several open research questions that should be further studied in subsequent investigations, which can be summarized as:"}, {"title": null, "content": "\u2022 Conduct a more in-depth study, including a comparison of computational resources and time and using other optimization problems with benchmarking purposes, such as the Traveling Salesman Problem or the Bin Packing Problem. Potential limitations when applying RA to more real-world scenarios will also be studied.\n\u2022 Define a similarity measure for transfer of knowledge purposes. This means, given a potential source-task and its results, designing a metric that calculates how good a candidate source-task is for knowledge transfer purposes. The findings provided by the experimentation of this paper, particularly that focused on Hamming distance, are a good starting point for formulating this metric. Thus, a validated and accepted-by-the-community metric would be a milestone for the transfer of knowledge research line.\n\u2022 Finally, inspired by the findings described in (36), further experiments will be carried out with larger instances, with the intention of determining whether the conclusions presented in this study are replicable in such cases."}, {"title": "CONFLICT OF INTEREST STATEMENT", "content": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest."}, {"title": "AUTHOR CONTRIBUTIONS", "content": "E.O. and E.V.R. conceived the research and the experiments. E.O. and E.V.R developed the code and conducted the experimentation. E.O. and E.V.R. wrote and reviewed the manuscript."}, {"title": "FUNDING", "content": "This work was supported by the Basque Government through Plan complementario comunicaci\u00f3n cu\u00e1ntica (EXP. 2022/01341) (A/20220551). and by the Spanish CDTI through Misiones Ciencia e Innovaci\u00f3n 2021 program (CUCO, MIG-20211005)."}]}