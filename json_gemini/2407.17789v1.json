{"title": "Very Large-Scale Multi-Agent Simulation in AgentScope", "authors": ["Xuchen Pan", "Dawei Gao", "Yuexiang Xie", "Zhewei Wei", "Yaliang Li", "Bolin Ding", "Ji-Rong Wen", "Jingren Zhou"], "abstract": "Recent advances in large language models (LLMs) have opened new avenues for applying multi-agent\nsystems in very large-scale simulations. However, there remain several challenges when conducting\nmulti-agent simulations with existing platforms, such as limited scalability and low efficiency, unsatisfied\nagent diversity, and effort-intensive management processes. To address these challenges, we develop\nseveral new features and components for AgentScope, a user-friendly multi-agent platform, enhancing\nits convenience and flexibility for supporting very large-scale multi-agent simulations. Specifically, we\npropose an actor-based distributed mechanism as the underlying technological infrastructure towards great\nscalability and high efficiency, and provide flexible environment support for simulating various real-world\nscenarios, which enables parallel execution of multiple agents, centralized workflow orchestration, and\nboth inter-agent and agent-environment interactions among agents. Moreover, we integrate an easy-to-use\nconfigurable tool and an automatic background generation pipeline in AgentScope, simplifying the process\nof creating agents with diverse yet detailed background settings. Last but not least, we provide a\nweb-based interface for conveniently monitoring and managing a large number of agents that might deploy\nacross multiple devices. We conduct a comprehensive simulation to demonstrate the effectiveness of the\nproposed enhancements in AgentScope, and provide detailed observations and discussions to highlight the\ngreat potential of applying multi-agent systems in large-scale simulations. The source code is released on\nGitHub\u00b9 to inspire further research and development in large-scale multi-agent simulations.", "sections": [{"title": "1 Introduction", "content": "Large language models (LLMs), such as GPT-4 (OpenAI, 2023), Claude3.5 (ANTHROP, 2024), Qwen2 (Yang\net al., 2024), Llama3 (Meta, 2024), and so on (Anil et al., 2023; GLM et al., 2024; MistralAI, 2024; Yang et al.,\n2023), notable for their vast number of parameters and extensive training on diverse large-scale datasets,\ndemonstrate remarkable capabilities in understanding, generating, and interacting with human language.\nRecent advancements in LLMs have sparked a revolution in natural language processing and relevant fields,\npaving the way for novel applications that were previously inconceivable.\nBuilding on the capabilities of LLMs, there is a growing interest in the development of intelligent agents\nthat are empowered to resolve practical tasks (Hong et al., 2023; Ren et al., 2024). As the scope of these\nintelligent agents spans a wide array of applications, their potential to redefine the landscape of simulations\nbecomes increasingly evident (Matsumoto et al., 2024; Sorokovikova et al., 2024; Sreedhar and Chilton, 2024;\nYue et al., 2024). Traditional simulations heavily rely on predefined rules and sophisticated mechanisms to\ngenerate simulated scenarios, necessitating lots of expertise and human interventions (Macal and North, 2010).\nWith the incorporation of LLM-empowered agents, simulations are expected to become more interactive,\nadaptive, and realistic, while requiring substantially fewer human efforts.\nRecently, several platforms (Hong et al., 2023; Wu et al., 2023; Team, 2023) have been proposed to\nstreamline the development of multi-agent systems, providing some fundamental functionalities including\nunified LLM services, various tools, and advanced reasoning algorithms. Despite significant progress, we\nidentify several challenges in conducting simulations with multi-agent platforms, particularly when the number\nof agents becomes extremely large. We summarize these challenges below.\n(i) Scalability and Efficiency Limitations The scale of involved agents can be critical when conducting\ncertain simulations, since simulations at a small scale run the risk of inaccurately representing real-world\ncomplexities, making simulations less realistic and reliable (Macal and North, 2010; Macal, 2016). However,\nincreasing the scale of agents brings challenges to the simulation platform in terms of scalability and efficiency.\nSpecifically, it is non-trivial to efficiently organize agents to execute their tasks and communications following\nan appropriate order, with the aim of reducing the running time while ensuring accurate results. Moreover,\nthe simulation platform should be capable of handling high-frequency access to support both inter-agent and\nagent-environment interactions in large-scale agent-based simulations.\n(ii) Unsatisfied Population Distributions and Agent Diversity For a large-scale simulation, it is\nessential that the involved agents exhibit diverse behaviors while generally following a specific population\ndistribution (Gao et al., 2023; Ren et al., 2024). Assigning agents with simple backgrounds may result in a\nsignificant number of highly homogenized agents, making it difficult to derive meaningful insights. Besides,\nexisting studies rarely consider how to specify population distributions of agents from various perspectives,\nsuch as age, education, occupation, etc. which reduces the realism of the simulations.\n(iii) Difficult Management Processes As the scale of agents increases, it becomes rather effort-\nintensive to manage the simulations, including initialization, execution, and termination of a large number of\nagents spread across multiple devices, as well as monitoring their status, behaviors, and interactions (Mou\net al., 2024). Such difficulties in managing make it challenging to promptly identify valuable group-level\nand individual-level behaviors, which can further hinder the discovery of critical insights for optimizing\nsimulations and advancing research. Therefore, an easy-to-use tool for managing large-scale agents is a\nnecessary functionality that should be provided by the agent-based simulation platforms.\nTo tackle these challenges, we adopt a user-friendly multi-agent platform, named AgentScope (Gao et al.,\n2024), as the foundation framework to provide the basic functionalities, and further develop several new\nfeatures and components upon it to improve its usability, convenience, and flexibility for supporting very\nlarge-scale multi-agent simulations.\nTo be specific, we propose a distributed mechanism based on the actor model (Agha, 1985), featuring\nautomatic parallel execution and centralized workflow orchestration to provide great scalability and high\nefficiency for multi-agent-based simulations. The proposed actor-based distributed mechanism enables us to\nfurther expand the scale of agents in the simulation with a limited number of devices, and provides linear\nbenefit on running time from the addition of devices. We support both inter-agent and agent-environment\ninteractions in the simulations. Agents can initiatively communicate with other agents and the environment,\nand can respond to messages from other agents and changes in the environment. Furthermore, a multi-layer\nenvironment structure is proposed to support group-wise information synchronization, enhancing the flexibility\nof AgentScope for simulating various real-world scenarios.\nBesides, to satisfy the requirements of population distribution and agent diversity, we integrate a\nconfiguration tool in AgentScope and provide automatic background generation. Users only need to simply\nspecify the distributions of the population from several aspects, a large number of agents with detailed\nand diverse characteristics can be effortlessly generated accordingly. These agents can be managed and\nmonitored conveniently through AgentScope-Manager, a proposed module for simplifying the organization and\nobservation process of large-scale agent-based simulations. Using a web-based visual interface, AgentScope-\nManager provides a comprehensive overview of all agents across multiple devices, allowing users to efficiently\nconfigure, launch, and terminate these agents.\nWith such an agent-based simulation platform, we conduct a comprehensive simulation on the classic \"guess\nof the average\" game (Nagel, 1995; Camerer et al., 2004) to demonstrate the improvements and advances\nbrought by the infrastructure introduced above. Firstly, we conduct agent-based simulations involving 1\nmillion agents using only 4 devices, showing the scalability and efficiency of the platform. Then, we incorporate\nagents using different LLMs of different sizes, equipped with different prompts and diverse background settings,\nresulting in various and realistic behaviors in the simulations. We provide comprehensive observations on\nboth collective and individual behaviors, drawing meaningful and valuable insights from a series of simulation\nexperiments, along with further discussions on helpful tips and open questions. These experimental results\nconfirm the feasibility and great potential of conducting large-scale agent-based simulations in AgentScope.\nWe have released the source code at https://github.com/modelscope/agentscope for future research."}, {"title": "2 Related Works", "content": "LLM-Empowered Agent Platforms With the advances of LLMs, a significant number of agent platforms\nhave been developed to integrate LLMs into real-world applications and assist humans in problem-solving (Wu\net al., 2023; Hong et al., 2023; Li et al., 2023b; Significant-Gravitas, 2023; Team, 2023; Gao et al., 2024). These\nplatforms can be categorized into single-agent platforms and multi-agent platforms. The single-agent platforms\ninclude AutoGPT (Significant-Gravitas, 2023), LangChain (langchain ai, 2024a), ModelScope-Agent (Li et al.,\n2023a), and Transformers Agents (Wolf et al., 2020), which are proposed to resolve practical tasks using\nLLMs. On the other hand, multi-agent platforms like MetaGPT (Hong et al., 2023), Auto-Gen (Wu et al.,\n2023), CAMEL Li et al. (2023b), and LangSmith (langchain ai, 2024b) employ multi-agent collaboration\nto tackle more complex challenges, including software programming (Hong et al., 2023; Qian et al., 2023),\ndata science (Hong et al., 2024), social simulation (Park et al., 2023), game-playing (Gao et al., 2024), etc.\nAlthough remarkable progress has been made, applications built on these platforms can currently be limited\nin the scale of agents and suffer from low efficiency, hindering their potential for large-scale simulations.\nTo address these limitations, we enhance AgentScope with new features and components to support very\nlarge-scale agent-based applications and improve the running efficiency of these applications.\nAgent-Based Simulation Frameworks Due to the ability of LLMs to imitate human behaviors, agent-\nbased simulation has become an attractive topic in the research community (G\u00fcrcan, 2024; Matsumoto\net al., 2024; Sorokovikova et al., 2024; Sreedhar and Chilton, 2024; Ye and Gao, 2024; Team et al., 2024;\nPark et al., 2022). Previous studies have explored the integration of LLMs in various fields, including\neducation (Yue et al., 2024), economic (Matsumoto et al., 2024), societal study (Park et al., 2023; Ye and\nGao, 2024; Gao et al., 2023; Ren et al., 2024), transportation (Jin et al., 2023), healthcare (Zhang et al.,\n2023) etc. Recently, researchers have built up several LLM-based or agent-based simulation frameworks. For\ninstance, Vidur (Agrawal et al., 2024) is a simulation framework that focuses on providing high-throughput\nLLM services, Ataei et al. (2024) is proposed for design requirements elicitation, Cheng et al. (2023) is\ndeveloped to evaluate the level of caricature, and Ren et al. (2024) is designed to simulate the behaviors of\nweb search users. However, these existing frameworks are domain-specific, making it challenging for users to\nconduct large-scale agent-based simulations for a wide variety of applications. To tackle this, we design a\nmulti-agent-based simulation platform AgentScope and provide easy-to-use configurable tools to ease the\nheavy workload associated with conducting various large-scale simulations."}, {"title": "3 Infrastructure", "content": "To provide the basic functionalities required for conducting agent-based simulations, including LLM services,\nmemory management, and agent interactions, we adopt AgentScope, a user-friendly multi-agent platform\ndesigned for flexible Standard Operating Procedure (SOP) tasks, as our foundation framework. We further\ndevelop several new features and components, making it more convenient and feasible to support very\nlarge-scale simulations involving multiple agents.\nSpecifically, we first design an actor-based distributed mechanism (Sec. 3.1) that serves as the underlying\ntechnological infrastructure for conducting large-scale simulations, providing great scalability and high\nefficiency. Building upon such an infrastructure, we enable both inter-agent interactions and agent-environment\ninteractions (Sec. 3.2) to facilitate multi-agent simulations, which forms the core components that drive the\nsimulated dynamics. To improve the diversity of agents involved in the simulations, we allow users to set\nheterogeneous configurations for agents by specifying their population distributions and detailed background\nsettings (Sec. 3.3). Furthermore, we build a graphical user interface to monitor and manage the distributed\nagents on different devices, making it easy to observe and organize large-scale agents in the simulations\n(Sec. 3.4). In the following subsections, we elaborate on the details of these proposed enhancements."}, {"title": "3.1 Actor-based Distributed Mechanism", "content": "The actor model is a mathematical model of concurrent computation, where each actor acts as a basic\ncomputing unit, receives messages, and computes independently (Agha, 1985). Based on the actor model, we\nbuild a distributed mechanism to provide great scalability and high efficiency for agent-based simulation.\nThe proposed actor-based distributed mechanism serves as the basic technological infrastructure, featuring\nautomatic parallel execution and centralized workflow orchestration.\nAutomatic Parallel Execution In a multi-agent simulation, the interactions between agents follow an\natomized pattern, where interactions occur within small isolated cliques (Matsumoto et al., 2024; Sorokovikova\net al., 2024). Such a pattern holds significant potential for parallelization, leading to substantial gains in\nefficiency. However, achieving parallelization is non-trivial as it requires the formal definition of interactions,\nthe identification of potential parallelizable computations, and subsequent optimization.\nTo provide automatic parallelization in AgentScope, we first format the inter-agent interactions in the\nsimulation as a communication graph, where each vertex $v$ represents an agent, and each directed edge $e$\nrepresents a message passing from one agent to another. Note that the communication graph can be a\ndirected cyclic graph that might be highly dynamic and uncertain, which is different from the concept of a\ncomputational graph in machine learning (Ansel et al., 2024) and thus makes it much more challenging in\nproviding automatic parallelization.\nWith the communication graph, we can dynamically identify the agents that are ready to be executed,\nwhich indicates that they do not depend on the outputs of others or that all their dependencies have been\nfulfilled. These agents are executed automatically in parallel, utilizing the maximum available resources. As\nthey finish one by one, more blocked agents become active and begin their executions.\nSuch a design of automatic parallel execution is well-suited for the actor-based distributed mechanism.\nNote that we employ the multi-process mode rather than the asynchronous programming to further improve\nefficiency, wherein each agent can run in a separate process and be treated as an independent node in the\ncommunication graph. As a result, an agent's internal computations can only be triggered when it receives\nthe required messages. In this way, each agent only relies on those from which they receive the necessary\nmessages, and the communication graph automatically divides into independent subgraphs based on their\ndependencies. With these advanced designs and implementations in AgentScope, users only need to specify\nthe message passing paths among agents, the multi-agent simulation can be automatic parallel execution\nwithout additional effort.\nAn example of automatic parallel execution is shown in Fig. 1, where agent-B and agent-C are independent\nof each other but rely on the messages from agent-A, allowing them to be executed in parallel once the\nexecution of agent-A is completed. In contrast, agent-D and agent-E cannot be executed in parallel, as\nagent-E depends on messages from both agent-B and agent-D.\nCentralized Workflow Orchestration In addition to the proposed automatic parallel execution, the\nworkload associated with simulation orchestration is also important for supporting very large-scale simulations,\nas users need to set up and manage distributed agents across multiple devices. These requirements might\nnot be well satisfied when there is a lack of a complete and explicit view of the entire workflow during the\ndevelopment and execution phases.\nTo resolve these issues, we further enhance the proposed actor-based distributed mechanism by allowing\nusers to orchestrate the simulation explicitly and centrally. For simplicity, we refer to the central process that"}, {"title": "3.2 Agent-Environment Interactions", "content": "The agent-environment interactions are crucial alongside the above inter-agent communication in simulations,\nwhich allows agents to access the environment, respond to changes in it, and alter it if needed. Considering\nthe large number of agents, the agent-environment interactions should be capable of handling high-frequency\naccess. For example, in a social simulation like AI town (Park et al., 2023), the environment includes timeline\nand map with the interactive items on it. Agents might frequently check and interact with the items on the\nmap, and the change of these items should also trigger the reactions of agents.\nTo satisfy such requirements, we abstract the environment operations into registering, querying, updating,\nremoving, and monitoring by providing a base class, which can be adapted to various underlying storage\ndatabases, including key-value stores, relational databases, NoSQL databases, and so on. We provide two\ndimensions for users to perform agent-environment interactions, i.e., timeline and location. For the timeline,\nusers can set specific triggers to make the agents access the global time and adjust their behaviors accordingly.\nFor the location, the environment serves as a map maintaining the locations of agents and providing hook\nfunctions to trigger the interactions with agents or items nearby. Such a design provides a flexible environment\nsupport for simulating various real-world scenarios."}, {"title": "3.3 Heterogeneous Configurations", "content": "In a simulation, agents are expected to act as humans with diverse backgrounds, including different ages,\ngenders, careers, nationalities, education, experiences, etc. An intuitive approach is to add these background\nsettings of agents in their system prompts, providing guidance for agents on the roles to play and actions\nto take. However, for large-scale simulations, providing diverse, heterogeneous, and reasonable background\nsettings for agents can be laborious and time-consuming, especially when precise control of different population\ndistributions is required in certain simulations. This problem motivates us to provide tools in AgentScope to\nassist users in effortlessly setting up large-scale agents with diverse background settings.\nConfigurable Tool Specifically, users can begin by defining the total population of the simulation, and\nthen specify the distributions of the population from various perspectives. We provide some widely-used\ndistribution templates in AgentScope for convenient usage, from the aspects of age, gender, occupation,\nnationality, and education. Besides, the proposed configurable tool allows for easy extension of new aspects,\nenhancing its flexibility to meet diverse requirements. Listing 1 in Appendix A shows an example configuration\nfile for a group of people with different educational levels, in which a distribution can be specified by the\nproportions of its different components.\nAutomatic Background Generation Pipeline After configurations have been provided via the above\ntool, more detailed and heterogeneous background settings can be automatically generated to instantiate\nthe agents. Specifically, when users start a simulation, we draw specific values from the distributions based\non the configurations, convert them into a JSON format, and fill them into a meta prompt to produce the\ncompleted instructions for background generation tasks. These instructions are utilized by LLMs to generate\nheterogeneous background settings. To introduce more diversity, the generation process involves adjusting\nthe random seed and the temperature used by LLMs. Several examples of the generated background settings\ncan be found in Sec. 4.5, along with the results and analysis of the simulations involving diverse agents. The\nadopted meta prompt can be found in Appendix B."}, {"title": "3.4 Management for Large-scale Agents", "content": "In a simulation, users need to manage and monitor a large number of agents distributed across different\ndevices, which might become intractable to handle manually as the scale and complexity of the simulation\nincrease. To tackle this, we incorporate advanced forms of agent management and monitoring, named\nAgentScope-Manager. Specifically, when users start a simulation, servers are first launched on all the\nremote devices, which provide resident services to remotely create, monitor, and stop distributed agents. These\nservers are responsible for managing the lifecycle of distributed agents and synchronizing their information to\na web-based visual interface, as illustrated in Fig. 4. The web-based visual interface provides a comprehensive\noverview of all registered servers and all deployed agents on different devices, from which users can view the\nserver's identity, IP address, running status, and utilization of computing resources.\nThe AgentScope-Manager also simplifies the management and monitoring processes for conducting multiple\nsimulations. Since the servers can be reused in different simulations, users don't need to restart the distributed\nservers between two simulations. Users can efficiently configure, launch, and terminate servers and agents\nduring the simulations as needed. With such a design, we streamline the management process by focusing\non servers rather than individual agents, thereby improving the efficiency and effectiveness of managing\nlarge-scale agent systems in AgentScope.\nIn a nutshell, based on AgentScope, we implement an actor-based distributed mechanism that serves as\nthe underlying technological infrastructure, which is well-designed for both inter-agent and agent-environment\ninteractions, and provides great scalability and high efficiency in conducting large-scale agent-based simulations\nBuilding on the infrastructure, we provide heterogeneous configurations and the management server, enhancing\nthe diversity of agents and simplifying the observation and organization of the simulation process."}, {"title": "4 Experiments", "content": "In this section, we conduct large-scale simulations to show the improvements and advances brought by the\nproposed infrastructure and components in AgentScope. Meanwhile, we provide detailed observations and\nin-depth discussions on the agents' collective and individual behaviors, drawing valuable insights."}, {"title": "4.1 Settings", "content": "We set up a large number of agents to participate in the classic game guess the $\\frac{2}{3}$ of the average, where each\nagent reports a real number between 0 and 100 and the agent who reports a number closest to $\\frac{2}{3}$ of the\naverage of all the reported numbers wins the game. In this game, intuitively the highest possible average is\n100. Therefore, for winning the game, agents tend to report a number no larger than $100 \\times \\frac{2}{3} = 66\\frac{2}{3}$. Once\nall agents adopt this strategy, $66\\frac{2}{3}$ becomes the new highest possible average and thus they tend to report a\nnumber no larger than $66\\frac{2}{3}\\times \\frac{2}{3} = 44\\frac{4}{9}$. This process continues until the average becomes 0 and all agents\nreport 0, indicating that the game has reached its Nash equilibrium. However, considering that agents may\nnot always be rational, those agents who report 0 cannot always win the game since the average does not\nconverge to 0 immediately. Agents should carefully take into account the possible actions of others before\nreporting their numbers. Meanwhile, agents can adjust their strategies in a multi-round game according to\nthe average reported numbers in previous rounds.\nNote that all the experiments in this section follow the aforementioned settings. With this\ngame, we aim to demonstrate the capabilities of AgentScope in supporting large-scale agent-based simulations,\nand show how agents perform considerations and reasoning concerning their system prompts, background\nsettings, and other information obtained in the simulations.\nDevices & LLMs The experiments are conducted on a cluster containing multiple devices, each of which\nis equipped with 8 A100-80G GPUs, a 64-core CPU, and 1 TB of memory. We adopt vLLM (Kwon et al.,\n2023) as the LLM inference engine to handle highly concurrent service requests. We utilize six powerful and\npopular open-source LLMs of different sizes. We adopt their instruction versions due to their enhanced ability\nto follow instructions. The details of the adopted LLMs are provided below:\n\u2022 Llama3-8B / Llama3-70B (Meta, 2024): A series of open-source LLMs developed by Meta, which\nhave been pre-trained and fine-tuned on a massive corpus.\n\u2022 Qwen2-7B / Qwen2-72B (Yang et al., 2024): The second generation of Qwen open-source LLMs,\ndeveloped by Alibaba.\n\u2022 MistralAI-8x7B / MistralAI-8x22B (MistralAI, 2024): The open-source mixture-of-experts (MOE)\nLLMs released by MistralAI, where each MOE LLM consists of eight 7B/22B models."}, {"title": "4.2 Scalability and Efficiency", "content": "First of all, we conduct a series of experiments to show the scalability and efficiency of the agent-based\nsimulations supported by the proposed actor-based distributed mechanism (see Sec. 3.1). Specifically, we\nillustrate how the overall simulation running time changes as the number of participating agents grows when\nusing LLMs of different sizes, including Llama3-8B and Llama3-70B. In addition to the model sizes, the\nsystem prompt provided to agents is also a factor that can influence the running time, since some prompts\n(e.g., Prompt 2) may encourage agents to generate longer responses and thereby lead to longer response time.\nFrom the experimental results shown in Fig. 5, we can obtain the following observations and insights.\n(i) We support an agent-based simulation involving 1 million agents, which can be completed\nin 12 minutes using 4 devices. In Fig. 5a, we fix the device number to 4 and record the simulation\nrunning time as the number of agents grows from 100 to 1M. It can be observed that the simulation involving\n1 million agents finishes in 12 minutes when using Llama3-8B with Prompt 1, while it takes 85 minutes if\nwe choose Prompt 2, as the number of averaged response tokens grows by more than 150-fold\u00b2. For the\nheaviest inference workload, i.e., when agents adopt Llama3-70B and Prompt 2, it takes around 10.6 hours\nto complete the simulation.\n(ii) The proposed actor-based distributed mechanism significantly improves the efficiency of\nlarge-scale agent-based simulations. To better demonstrate the improvements brought by the proposed\nactor-based distributed mechanism, we adopt a dummy model request (i.e., agents sleep for 1 second and\ngenerate random numbers rather than posting the requests) in the simulation to remove the impact of the\nLLM inference speed. The experimental results summarized in Fig. 5b show that, completing an agent-based\nsimulation with the proposed actor-based distributed mechanism involving 1 million agents only takes 40\nseconds, whereas simulations using serial execution or asynchronous mode in Python (adopted by existing\nworks (Wu et al., 2023; Hong et al., 2023)) require around 12 days and 8.6 hours, respectively.\n(iii) Increasing the number of devices can proportionally reduce the simulation running time.\nAs shown in Fig. 5c, we maintain the number of agents at 10,000 and vary the number of devices used in the\nsimulation. For Llama3-70B with Prompt 2, the simulation running time decreases from 22 minutes to 5.6\nminutes as the number of devices increases from 1 to 4. Such a phenomenon can be attributed to a reduction\nin the number of agents served within one device. As a comparison, we increase the number of devices from\n1 to 4, and deploy 10,000 agents on each device, respectively. As illustrated in Fig. 5d, the running time\nremains nearly the same as the number of devices and agents increases, which demonstrates the horizontal\nscalability of AgentScope.\nIn summary, the proposed actor-based distributed mechanism in AgentScope enhances the efficiency in\nconducting very large-scale agent-based simulations, and offers great scalability by allowing users to expand\nthe scale of agents from the addition of devices."}, {"title": "4.3 Simulation Results and Analysis", "content": "In this section, we add some detailed information with six LLMs and two system prompts. We summarize\nthe experimental results in Fig. 6, from which we derive the insights below, and provide more detailed results\n(e.g., distributions and statistics of the reported numbers) and individual-level observations in Appendix D\nand Appendix E.1, respectively.\nFrom the comparisons in the figures, we observe that when utilizing a basic system prompt Prompt 1 with\nmost LLMs, agents generally tend to report numbers around 50. However, it is worth noting that agents with\nMistralAI-8\u00d77B and MistralAI-8\u00d722B, report smaller numbers (36.63 and 31.69 in average, respectively)\nthan other agents. These results indicate that without providing specific instructions in system prompts, the\nperformance of agents can be different due to the LLMs they adopt, influenced by factors such as model sizes\nand model architectures."}, {"title": "4.4 Detailed Instructions in System Prompts", "content": "To further explore the impact of behavioral guidance on agents, we incorporate more detailed instructions\ntailored for this game in the system prompts. Specifically, we remind agents that all their competitors are\nrational and will try to adjust the reported numbers by analyzing others' strategies, resulting in Prompt 3\nand Prompt 4 respectively. With adding such behavioral guidance in the system prompts, we expect agents\ncan engage in more thoughtful and diverse considerations before reporting their numbers, thereby making\nsimulations more practical, meaningful, and interesting.\nThe comparisons among different system prompts are illustrated in Fig. 8. In general, from the figure we\ncan observe that the reported numbers are closer to 0 when using Prompt 3 and Prompt 4 than those of\nPrompt 1 and Prompt 2. These experimental results indicate that detailed instructions are more effective\nthan general guidance (e.g., \"think step by step\") in encouraging agents to perform thoughtful considerations\nand take rational actions. Several case studies shown in Appendix E.3 confirm the improvements brought by\nadding detailed instructions in the system prompts.\nFurthermore, in a multi-round game illustrated in Fig. 7, agents using Prompt 3 and Prompt 4 can\nconverge to the Nash equilibrium faster than those using Prompt 1 and Prompt 2. For example, agents with\nQwen2-72B report 35.30, 6.11, 1.55, and 1.69 in average at the third round when using Prompt 1, Prompt 2,\nPrompt 3, and Prompt 4, respectively, while in the fifth round, the average of reported numbers become\n25.16, 2.02, 0.14, and 0.15.\nIt is worth noting that the impact of the system prompts on different LLMs can be different. For example,\nfrom the perspective of the range of the reported numbers (i.e., the maximum and minimum value of reported\nnumbers among all agents), employing Prompt 3 and Prompt 4 in Qwen-72B can significantly reduce the\nmaximum number, while that of Mistral-8\u00d722B remains unchanged. Besides, using detailed instructions in\nsystem prompts might increase the token number of responses, as summarized in Appendix C, because agents\nare likely to consider multiple aspects before providing an answer."}, {"title": "4.5 Diverse Background Settings", "content": "The diversity of agents is a critical factor in agent-based simulations. In Sec. 3.3, we introduce the proposed\nconfigurable tool and background generation pipeline designed to automatically instantiate agents with\ndiverse background settings. In this subsection, we conduct simulation experiments involving diverse agents,\nconsidering their educational levels and occupations.\nSpecifically, we divide the agents into several groups, each of which consists of 200 agents. For each group,\nwe manually provide a basic configuration and utilize LLMs to generate a detailed description for each agent,\nthereby further enhancing the diversity of the agents. These generated background settings are added to the\nsystem prompts and labeled as \"character background\", using Prompt 5."}, {"title": "4.6 Mixture of LLMS", "content": "In this subsection"}, {"title": "Very Large-Scale Multi-Agent Simulation in AgentScope", "authors": ["Xuchen Pan", "Dawei Gao", "Yuexiang Xie", "Zhewei Wei", "Yaliang Li", "Bolin Ding", "Ji-Rong Wen", "Jingren Zhou"], "abstract": "Recent advances in large language models (LLMs) have opened new avenues for applying multi-agent\nsystems in very large-scale simulations. However, there remain several challenges when conducting\nmulti-agent simulations with existing platforms, such as limited scalability and low efficiency, unsatisfied\nagent diversity, and effort-intensive management processes. To address these challenges, we develop\nseveral new features and components for AgentScope, a user-friendly multi-agent platform, enhancing\nits convenience and flexibility for supporting very large-scale multi-agent simulations. Specifically, we\npropose an actor-based distributed mechanism as the underlying technological infrastructure towards great\nscalability and high efficiency, and provide flexible environment support for simulating various real-world\nscenarios, which enables parallel execution of multiple agents, centralized workflow orchestration, and\nboth inter-agent and agent-environment interactions among agents. Moreover, we integrate an easy-to-use\nconfigurable tool and an automatic background generation pipeline in AgentScope, simplifying the process\nof creating agents with diverse yet detailed background settings. Last but not least, we provide a\nweb-based interface for conveniently monitoring and managing a large number of agents that might deploy\nacross multiple devices. We conduct a comprehensive simulation to demonstrate the effectiveness of the\nproposed enhancements in AgentScope, and provide detailed observations and discussions to highlight the\ngreat potential of applying multi-agent systems in large-scale simulations. The source code is released on\nGitHub\u00b9 to inspire further research and development in large-scale multi-agent simulations.", "sections": [{"title": "1 Introduction", "content": "Large language models (LLMs), such as GPT-4 (OpenAI, 2023), Claude3.5 (ANTHROP, 2024), Qwen2 (Yang\net al., 2024), Llama3 (Meta, 2024), and so on (Anil et al., 2023; GLM et al., 2024; MistralAI, 2024; Yang et al.,\n2023), notable for their vast number of parameters and extensive training on diverse large-scale datasets,\ndemonstrate remarkable capabilities in understanding, generating, and interacting with human language.\nRecent advancements in LLMs have sparked a revolution in natural language processing and relevant fields,\npaving the way for novel applications that were previously inconceivable.\nBuilding on the capabilities of LLMs, there is a growing interest in the development of intelligent agents\nthat are empowered to resolve practical tasks (Hong et al., 2023; Ren et al., 2024). As the scope of these\nintelligent agents spans a wide array of applications, their potential to redefine the landscape of simulations\nbecomes increasingly evident (Matsumoto et al., 2024; Sorokovikova et al., 2024; Sreedhar and Chilton, 2024;\nYue et al., 2024). Traditional simulations heavily rely on predefined rules and sophisticated mechanisms to\ngenerate simulated scenarios, necessitating lots of expertise and human interventions (Macal and North, 2010).\nWith the incorporation of LLM-empowered agents, simulations are expected to become more interactive,\nadaptive, and realistic, while requiring substantially fewer human efforts.\nRecently, several platforms (Hong et al., 2023; Wu et al., 2023; Team, 2023) have been proposed to\nstreamline the development of multi-agent systems, providing some fundamental functionalities including\nunified LLM services, various tools, and advanced reasoning algorithms. Despite significant progress, we\nidentify several challenges in conducting simulations with multi-agent platforms, particularly when the number\nof agents becomes extremely large. We summarize these challenges below.\n(i) Scalability and Efficiency Limitations The scale of involved agents can be critical when conducting\ncertain simulations, since simulations at a small scale run the risk of inaccurately representing real-world\ncomplexities, making simulations less realistic and reliable (Macal and North, 2010; Macal, 2016). However,\nincreasing the scale of agents brings challenges to the simulation platform in terms of scalability and efficiency.\nSpecifically, it is non-trivial to efficiently organize agents to execute their tasks and communications following\nan appropriate order, with the aim of reducing the running time while ensuring accurate results. Moreover,\nthe simulation platform should be capable of handling high-frequency access to support both inter-agent and\nagent-environment interactions in large-scale agent-based simulations.\n(ii) Unsatisfied Population Distributions and Agent Diversity For a large-scale simulation, it is\nessential that the involved agents exhibit diverse behaviors while generally following a specific population\ndistribution (Gao et al., 2023; Ren et al., 2024). Assigning agents with simple backgrounds may result in a\nsignificant number of highly homogenized agents, making it difficult to derive meaningful insights. Besides,\nexisting studies rarely consider how to specify population distributions of agents from various perspectives,\nsuch as age, education, occupation, etc. which reduces the realism of the simulations.\n(iii) Difficult Management Processes As the scale of agents increases, it becomes rather effort-\nintensive to manage the simulations, including initialization, execution, and termination of a large number of\nagents spread across multiple devices, as well as monitoring their status, behaviors, and interactions (Mou\net al., 2024). Such difficulties in managing make it challenging to promptly identify valuable group-level\nand individual-level behaviors, which can further hinder the discovery of critical insights for optimizing\nsimulations and advancing research. Therefore, an easy-to-use tool for managing large-scale agents is a\nnecessary functionality that should be provided by the agent-based simulation platforms.\nTo tackle these challenges, we adopt a user-friendly multi-agent platform, named AgentScope (Gao et al.,\n2024), as the foundation framework to provide the basic functionalities, and further develop several new\nfeatures and components upon it to improve its usability, convenience, and flexibility for supporting very\nlarge-scale multi-agent simulations.\nTo be specific, we propose a distributed mechanism based on the actor model (Agha, 1985), featuring\nautomatic parallel execution and centralized workflow orchestration to provide great scalability and high\nefficiency for multi-agent-based simulations. The proposed actor-based distributed mechanism enables us to\nfurther expand the scale of agents in the simulation with a limited number of devices, and provides linear\nbenefit on running time from the addition of devices. We support both inter-agent and agent-environment\ninteractions in the simulations. Agents can initiatively communicate with other agents and the environment,\nand can respond to messages from other agents and changes in the environment. Furthermore, a multi-layer\nenvironment structure is proposed to support group-wise information synchronization, enhancing the flexibility\nof AgentScope for simulating various real-world scenarios.\nBesides, to satisfy the requirements of population distribution and agent diversity, we integrate a\nconfiguration tool in AgentScope and provide automatic background generation. Users only need to simply\nspecify the distributions of the population from several aspects, a large number of agents with detailed\nand diverse characteristics can be effortlessly generated accordingly. These agents can be managed and\nmonitored conveniently through AgentScope-Manager, a proposed module for simplifying the organization and\nobservation process of large-scale agent-based simulations. Using a web-based visual interface, AgentScope-\nManager provides a comprehensive overview of all agents across multiple devices, allowing users to efficiently\nconfigure, launch, and terminate these agents.\nWith such an agent-based simulation platform, we conduct a comprehensive simulation on the classic \"guess\nof the average\" game (Nagel, 1995; Camerer et al., 2004) to demonstrate the improvements and advances\nbrought by the infrastructure introduced above. Firstly, we conduct agent-based simulations involving 1\nmillion agents using only 4 devices, showing the scalability and efficiency of the platform. Then, we incorporate\nagents using different LLMs of different sizes, equipped with different prompts and diverse background settings,\nresulting in various and realistic behaviors in the simulations. We provide comprehensive observations on\nboth collective and individual behaviors, drawing meaningful and valuable insights from a series of simulation\nexperiments, along with further discussions on helpful tips and open questions. These experimental results\nconfirm the feasibility and great potential of conducting large-scale agent-based simulations in AgentScope.\nWe have released the source code at https://github.com/modelscope/agentscope for future research."}, {"title": "2 Related Works", "content": "LLM-Empowered Agent Platforms With the advances of LLMs, a significant number of agent platforms\nhave been developed to integrate LLMs into real-world applications and assist humans in problem-solving (Wu\net al., 2023; Hong et al., 2023; Li et al., 2023b; Significant-Gravitas, 2023; Team, 2023; Gao et al., 2024). These\nplatforms can be categorized into single-agent platforms and multi-agent platforms. The single-agent platforms\ninclude AutoGPT (Significant-Gravitas, 2023), LangChain (langchain ai, 2024a), ModelScope-Agent (Li et al.,\n2023a), and Transformers Agents (Wolf et al., 2020), which are proposed to resolve practical tasks using\nLLMs. On the other hand, multi-agent platforms like MetaGPT (Hong et al., 2023), Auto-Gen (Wu et al.,\n2023), CAMEL Li et al. (2023b), and LangSmith (langchain ai, 2024b) employ multi-agent collaboration\nto tackle more complex challenges, including software programming (Hong et al., 2023; Qian et al., 2023),\ndata science (Hong et al., 2024), social simulation (Park et al., 2023), game-playing (Gao et al., 2024), etc.\nAlthough remarkable progress has been made, applications built on these platforms can currently be limited\nin the scale of agents and suffer from low efficiency, hindering their potential for large-scale simulations.\nTo address these limitations, we enhance AgentScope with new features and components to support very\nlarge-scale agent-based applications and improve the running efficiency of these applications.\nAgent-Based Simulation Frameworks Due to the ability of LLMs to imitate human behaviors, agent-\nbased simulation has become an attractive topic in the research community (G\u00fcrcan, 2024; Matsumoto\net al., 2024; Sorokovikova et al., 2024; Sreedhar and Chilton, 2024; Ye and Gao, 2024; Team et al., 2024;\nPark et al., 2022). Previous studies have explored the integration of LLMs in various fields, including\neducation (Yue et al., 2024), economic (Matsumoto et al., 2024), societal study (Park et al., 2023; Ye and\nGao, 2024; Gao et al., 2023; Ren et al., 2024), transportation (Jin et al., 2023), healthcare (Zhang et al.,\n2023) etc. Recently, researchers have built up several LLM-based or agent-based simulation frameworks. For\ninstance, Vidur (Agrawal et al., 2024) is a simulation framework that focuses on providing high-throughput\nLLM services, Ataei et al. (2024) is proposed for design requirements elicitation, Cheng et al. (2023) is\ndeveloped to evaluate the level of caricature, and Ren et al. (2024) is designed to simulate the behaviors of\nweb search users. However, these existing frameworks are domain-specific, making it challenging for users to\nconduct large-scale agent-based simulations for a wide variety of applications. To tackle this, we design a\nmulti-agent-based simulation platform AgentScope and provide easy-to-use configurable tools to ease the\nheavy workload associated with conducting various large-scale simulations."}, {"title": "3 Infrastructure", "content": "To provide the basic functionalities required for conducting agent-based simulations, including LLM services,\nmemory management, and agent interactions, we adopt AgentScope, a user-friendly multi-agent platform\ndesigned for flexible Standard Operating Procedure (SOP) tasks, as our foundation framework. We further\ndevelop several new features and components, making it more convenient and feasible to support very\nlarge-scale simulations involving multiple agents.\nSpecifically, we first design an actor-based distributed mechanism (Sec. 3.1) that serves as the underlying\ntechnological infrastructure for conducting large-scale simulations, providing great scalability and high\nefficiency. Building upon such an infrastructure, we enable both inter-agent interactions and agent-environment\ninteractions (Sec. 3.2) to facilitate multi-agent simulations, which forms the core components that drive the\nsimulated dynamics. To improve the diversity of agents involved in the simulations, we allow users to set\nheterogeneous configurations for agents by specifying their population distributions and detailed background\nsettings (Sec. 3.3). Furthermore, we build a graphical user interface to monitor and manage the distributed\nagents on different devices, making it easy to observe and organize large-scale agents in the simulations\n(Sec. 3.4). In the following subsections, we elaborate on the details of these proposed enhancements."}, {"title": "3.1 Actor-based Distributed Mechanism", "content": "The actor model is a mathematical model of concurrent computation, where each actor acts as a basic\ncomputing unit, receives messages, and computes independently (Agha, 1985). Based on the actor model, we\nbuild a distributed mechanism to provide great scalability and high efficiency for agent-based simulation.\nThe proposed actor-based distributed mechanism serves as the basic technological infrastructure, featuring\nautomatic parallel execution and centralized workflow orchestration.\nAutomatic Parallel Execution In a multi-agent simulation, the interactions between agents follow an\natomized pattern, where interactions occur within small isolated cliques (Matsumoto et al., 2024; Sorokovikova\net al., 2024). Such a pattern holds significant potential for parallelization, leading to substantial gains in\nefficiency. However, achieving parallelization is non-trivial as it requires the formal definition of interactions,\nthe identification of potential parallelizable computations, and subsequent optimization.\nTo provide automatic parallelization in AgentScope, we first format the inter-agent interactions in the\nsimulation as a communication graph, where each vertex $v$ represents an agent, and each directed edge $e$\nrepresents a message passing from one agent to another. Note that the communication graph can be a\ndirected cyclic graph that might be highly dynamic and uncertain, which is different from the concept of a\ncomputational graph in machine learning (Ansel et al., 2024) and thus makes it much more challenging in\nproviding automatic parallelization.\nWith the communication graph, we can dynamically identify the agents that are ready to be executed,\nwhich indicates that they do not depend on the outputs of others or that all their dependencies have been\nfulfilled. These agents are executed automatically in parallel, utilizing the maximum available resources. As\nthey finish one by one, more blocked agents become active and begin their executions.\nSuch a design of automatic parallel execution is well-suited for the actor-based distributed mechanism.\nNote that we employ the multi-process mode rather than the asynchronous programming to further improve\nefficiency, wherein each agent can run in a separate process and be treated as an independent node in the\ncommunication graph. As a result, an agent's internal computations can only be triggered when it receives\nthe required messages. In this way, each agent only relies on those from which they receive the necessary\nmessages, and the communication graph automatically divides into independent subgraphs based on their\ndependencies. With these advanced designs and implementations in AgentScope, users only need to specify\nthe message passing paths among agents, the multi-agent simulation can be automatic parallel execution\nwithout additional effort.\nAn example of automatic parallel execution is shown in Fig. 1, where agent-B and agent-C are independent\nof each other but rely on the messages from agent-A, allowing them to be executed in parallel once the\nexecution of agent-A is completed. In contrast, agent-D and agent-E cannot be executed in parallel, as\nagent-E depends on messages from both agent-B and agent-D.\nCentralized Workflow Orchestration In addition to the proposed automatic parallel execution, the\nworkload associated with simulation orchestration is also important for supporting very large-scale simulations,\nas users need to set up and manage distributed agents across multiple devices. These requirements might\nnot be well satisfied when there is a lack of a complete and explicit view of the entire workflow during the\ndevelopment and execution phases.\nTo resolve these issues, we further enhance the proposed actor-based distributed mechanism by allowing\nusers to orchestrate the simulation explicitly and centrally. For simplicity, we refer to the central process that"}, {"title": "3.2 Agent-Environment Interactions", "content": "The agent-environment interactions are crucial alongside the above inter-agent communication in simulations,\nwhich allows agents to access the environment, respond to changes in it, and alter it if needed. Considering\nthe large number of agents, the agent-environment interactions should be capable of handling high-frequency\naccess. For example, in a social simulation like AI town (Park et al., 2023), the environment includes timeline\nand map with the interactive items on it. Agents might frequently check and interact with the items on the\nmap, and the change of these items should also trigger the reactions of agents.\nTo satisfy such requirements, we abstract the environment operations into registering, querying, updating,\nremoving, and monitoring by providing a base class, which can be adapted to various underlying storage\ndatabases, including key-value stores, relational databases, NoSQL databases, and so on. We provide two\ndimensions for users to perform agent-environment interactions, i.e., timeline and location. For the timeline,\nusers can set specific triggers to make the agents access the global time and adjust their behaviors accordingly.\nFor the location, the environment serves as a map maintaining the locations of agents and providing hook\nfunctions to trigger the interactions with agents or items nearby. Such a design provides a flexible environment\nsupport for simulating various real-world scenarios."}, {"title": "3.3 Heterogeneous Configurations", "content": "In a simulation, agents are expected to act as humans with diverse backgrounds, including different ages,\ngenders, careers, nationalities, education, experiences, etc. An intuitive approach is to add these background\nsettings of agents in their system prompts, providing guidance for agents on the roles to play and actions\nto take. However, for large-scale simulations, providing diverse, heterogeneous, and reasonable background\nsettings for agents can be laborious and time-consuming, especially when precise control of different population\ndistributions is required in certain simulations. This problem motivates us to provide tools in AgentScope to\nassist users in effortlessly setting up large-scale agents with diverse background settings.\nConfigurable Tool Specifically, users can begin by defining the total population of the simulation, and\nthen specify the distributions of the population from various perspectives. We provide some widely-used\ndistribution templates in AgentScope for convenient usage, from the aspects of age, gender, occupation,\nnationality, and education. Besides, the proposed configurable tool allows for easy extension of new aspects,\nenhancing its flexibility to meet diverse requirements. Listing 1 in Appendix A shows an example configuration\nfile for a group of people with different educational levels, in which a distribution can be specified by the\nproportions of its different components.\nAutomatic Background Generation Pipeline After configurations have been provided via the above\ntool, more detailed and heterogeneous background settings can be automatically generated to instantiate\nthe agents. Specifically, when users start a simulation, we draw specific values from the distributions based\non the configurations, convert them into a JSON format, and fill them into a meta prompt to produce the\ncompleted instructions for background generation tasks. These instructions are utilized by LLMs to generate\nheterogeneous background settings. To introduce more diversity, the generation process involves adjusting\nthe random seed and the temperature used by LLMs. Several examples of the generated background settings\ncan be found in Sec. 4.5, along with the results and analysis of the simulations involving diverse agents. The\nadopted meta prompt can be found in Appendix B."}, {"title": "3.4 Management for Large-scale Agents", "content": "In a simulation, users need to manage and monitor a large number of agents distributed across different\ndevices, which might become intractable to handle manually as the scale and complexity of the simulation\nincrease. To tackle this, we incorporate advanced forms of agent management and monitoring, named\nAgentScope-Manager. Specifically, when users start a simulation, servers are first launched on all the\nremote devices, which provide resident services to remotely create, monitor, and stop distributed agents. These\nservers are responsible for managing the lifecycle of distributed agents and synchronizing their information to\na web-based visual interface, as illustrated in Fig. 4. The web-based visual interface provides a comprehensive\noverview of all registered servers and all deployed agents on different devices, from which users can view the\nserver's identity, IP address, running status, and utilization of computing resources.\nThe AgentScope-Manager also simplifies the management and monitoring processes for conducting multiple\nsimulations. Since the servers can be reused in different simulations, users don't need to restart the distributed\nservers between two simulations. Users can efficiently configure, launch, and terminate servers and agents\nduring the simulations as needed. With such a design, we streamline the management process by focusing\non servers rather than individual agents, thereby improving the efficiency and effectiveness of managing\nlarge-scale agent systems in AgentScope.\nIn a nutshell, based on AgentScope, we implement an actor-based distributed mechanism that serves as\nthe underlying technological infrastructure, which is well-designed for both inter-agent and agent-environment\ninteractions, and provides great scalability and high efficiency in conducting large-scale agent-based simulations\nBuilding on the infrastructure, we provide heterogeneous configurations and the management server, enhancing\nthe diversity of agents and simplifying the observation and organization of the simulation process."}, {"title": "4 Experiments", "content": "In this section, we conduct large-scale simulations to show the improvements and advances brought by the\nproposed infrastructure and components in AgentScope. Meanwhile, we provide detailed observations and\nin-depth discussions on the agents' collective and individual behaviors, drawing valuable insights."}, {"title": "4.1 Settings", "content": "We set up a large number of agents to participate in the classic game guess the $\\frac{2}{3}$ of the average, where each\nagent reports a real number between 0 and 100 and the agent who reports a number closest to $\\frac{2}{3}$ of the\naverage of all the reported numbers wins the game. In this game, intuitively the highest possible average is\n100. Therefore, for winning the game, agents tend to report a number no larger than $100 \\times \\frac{2}{3} = 66\\frac{2}{3}$. Once\nall agents adopt this strategy, $66\\frac{2}{3}$ becomes the new highest possible average and thus they tend to report a\nnumber no larger than $66\\frac{2}{3}\\times \\frac{2}{3} = 44\\frac{4}{9}$. This process continues until the average becomes 0 and all agents\nreport 0, indicating that the game has reached its Nash equilibrium. However, considering that agents may\nnot always be rational, those agents who report 0 cannot always win the game since the average does not\nconverge to 0 immediately. Agents should carefully take into account the possible actions of others before\nreporting their numbers. Meanwhile, agents can adjust their strategies in a multi-round game according to\nthe average reported numbers in previous rounds.\nNote that all the experiments in this section follow the aforementioned settings. With this\ngame, we aim to demonstrate the capabilities of AgentScope in supporting large-scale agent-based simulations,\nand show how agents perform considerations and reasoning concerning their system prompts, background\nsettings, and other information obtained in the simulations.\nDevices & LLMs The experiments are conducted on a cluster containing multiple devices, each of which\nis equipped with 8 A100-80G GPUs, a 64-core CPU, and 1 TB of memory. We adopt vLLM (Kwon et al.,\n2023) as the LLM inference engine to handle highly concurrent service requests. We utilize six powerful and\npopular open-source LLMs of different sizes. We adopt their instruction versions due to their enhanced ability\nto follow instructions. The details of the adopted LLMs are provided below:\n\u2022 Llama3-8B / Llama3-70B (Meta, 2024): A series of open-source LLMs developed by Meta, which\nhave been pre-trained and fine-tuned on a massive corpus.\n\u2022 Qwen2-7B / Qwen2-72B (Yang et al., 2024): The second generation of Qwen open-source LLMs,\ndeveloped by Alibaba.\n\u2022 MistralAI-8x7B / MistralAI-8x22B (MistralAI, 2024): The open-source mixture-of-experts (MOE)\nLLMs released by MistralAI, where each MOE LLM consists of eight 7B/22B models."}, {"title": "4.2 Scalability and Efficiency", "content": "First of all, we conduct a series of experiments to show the scalability and efficiency of the agent-based\nsimulations supported by the proposed actor-based distributed mechanism (see Sec. 3.1). Specifically, we\nillustrate how the overall simulation running time changes as the number of participating agents grows when\nusing LLMs of different sizes, including Llama3-8B and Llama3-70B. In addition to the model sizes, the\nsystem prompt provided to agents is also a factor that can influence the running time, since some prompts\n(e.g., Prompt 2) may encourage agents to generate longer responses and thereby lead to longer response time.\nFrom the experimental results shown in Fig. 5, we can obtain the following observations and insights.\n(i) We support an agent-based simulation involving 1 million agents, which can be completed\nin 12 minutes using 4 devices. In Fig. 5a, we fix the device number to 4 and record the simulation\nrunning time as the number of agents grows from 100 to 1M. It can be observed that the simulation involving\n1 million agents finishes in 12 minutes when using Llama3-8B with Prompt 1, while it takes 85 minutes if\nwe choose Prompt 2, as the number of averaged response tokens grows by more than 150-fold\u00b2. For the\nheaviest inference workload, i.e., when agents adopt Llama3-70B and Prompt 2, it takes around 10.6 hours\nto complete the simulation.\n(ii) The proposed actor-based distributed mechanism significantly improves the efficiency of\nlarge-scale agent-based simulations. To better demonstrate the improvements brought by the proposed\nactor-based distributed mechanism, we adopt a dummy model request (i.e., agents sleep for 1 second and\ngenerate random numbers rather than posting the requests) in the simulation to remove the impact of the\nLLM inference speed. The experimental results summarized in Fig. 5b show that, completing an agent-based\nsimulation with the proposed actor-based distributed mechanism involving 1 million agents only takes 40\nseconds, whereas simulations using serial execution or asynchronous mode in Python (adopted by existing\nworks (Wu et al., 2023; Hong et al., 2023)) require around 12 days and 8.6 hours, respectively.\n(iii) Increasing the number of devices can proportionally reduce the simulation running time.\nAs shown in Fig. 5c, we maintain the number of agents at 10,000 and vary the number of devices used in the\nsimulation. For Llama3-70B with Prompt 2, the simulation running time decreases from 22 minutes to 5.6\nminutes as the number of devices increases from 1 to 4. Such a phenomenon can be attributed to a reduction\nin the number of agents served within one device. As a comparison, we increase the number of devices from\n1 to 4, and deploy 10,000 agents on each device, respectively. As illustrated in Fig. 5d, the running time\nremains nearly the same as the number of devices and agents increases, which demonstrates the horizontal\nscalability of AgentScope.\nIn summary, the proposed actor-based distributed mechanism in AgentScope enhances the efficiency in\nconducting very large-scale agent-based simulations, and offers great scalability by allowing users to expand\nthe scale of agents from the addition of devices."}, {"title": "4.3 Simulation Results and Analysis", "content": "In this section, we add some detailed information with six LLMs and two system prompts. We summarize\nthe experimental results in Fig. 6, from which we derive the insights below, and provide more detailed results\n(e.g., distributions and statistics of the reported numbers) and individual-level observations in Appendix D\nand Appendix E.1, respectively.\nFrom the comparisons in the figures, we observe that when utilizing a basic system prompt Prompt 1 with\nmost LLMs, agents generally tend to report numbers around 50. However, it is worth noting that agents with\nMistralAI-8\u00d77B and MistralAI-8\u00d722B, report smaller numbers (36.63 and 31.69 in average, respectively)\nthan other agents. These results indicate that without providing specific instructions in system prompts, the\nperformance of agents can be different due to the LLMs they adopt, influenced by factors such as model sizes\nand model architectures."}, {"title": "4.4 Detailed Instructions in System Prompts", "content": "To further explore the impact of behavioral guidance on agents, we incorporate more detailed instructions\ntailored for this game in the system prompts. Specifically, we remind agents that all their competitors are\nrational and will try to adjust the reported numbers by analyzing others' strategies, resulting in Prompt 3\nand Prompt 4 respectively. With adding such behavioral guidance in the system prompts, we expect agents\ncan engage in more thoughtful and diverse considerations before reporting their numbers, thereby making\nsimulations more practical, meaningful, and interesting.\nThe comparisons among different system prompts are illustrated in Fig. 8. In general, from the figure we\ncan observe that the reported numbers are closer to 0 when using Prompt 3 and Prompt 4 than those of\nPrompt 1 and Prompt 2. These experimental results indicate that detailed instructions are more effective\nthan general guidance (e.g., \"think step by step\") in encouraging agents to perform thoughtful considerations\nand take rational actions. Several case studies shown in Appendix E.3 confirm the improvements brought by\nadding detailed instructions in the system prompts.\nFurthermore, in a multi-round game illustrated in Fig. 7, agents using Prompt 3 and Prompt 4 can\nconverge to the Nash equilibrium faster than those using Prompt 1 and Prompt 2. For example, agents with\nQwen2-72B report 35.30, 6.11, 1.55, and 1.69 in average at the third round when using Prompt 1, Prompt 2,\nPrompt 3, and Prompt 4, respectively, while in the fifth round, the average of reported numbers become\n25.16, 2.02, 0.14, and 0.15.\nIt is worth noting that the impact of the system prompts on different LLMs can be different. For example,\nfrom the perspective of the range of the reported numbers (i.e., the maximum and minimum value of reported\nnumbers among all agents), employing Prompt 3 and Prompt 4 in Qwen-72B can significantly reduce the\nmaximum number, while that of Mistral-8\u00d722B remains unchanged. Besides, using detailed instructions in\nsystem prompts might increase the token number of responses, as summarized in Appendix C, because agents\nare likely to consider multiple aspects before providing an answer."}, {"title": "4.5 Diverse Background Settings", "content": "The diversity of agents is a critical factor in agent-based simulations. In Sec. 3.3, we introduce the proposed\nconfigurable tool and background generation pipeline designed to automatically instantiate agents with\ndiverse background settings. In this subsection, we conduct simulation experiments involving diverse agents,\nconsidering their educational levels and occupations.\nSpecifically, we divide the agents into several groups, each of which consists of 200 agents. For each group,\nwe manually provide a basic configuration and utilize LLMs to generate a detailed description for each agent,\nthereby further enhancing the diversity of the agents. These generated background settings are added to the\nsystem prompts and labeled as \"character background\", using Prompt 5."}, {"title": "4.6 Mixture of LLMS", "content": "In this subsection, we conduct a simulation experiment involving agents employing a mixture of LLMs.\nSpecifically, we configure agents employing Llama3-70B, MistraAI-8\u00d722B, and Qwen2-72B, with 500 agents\nassigned to each LLM. We conduct both individual-level simulations, where each agent plays the game\nindependently, and group-level simulations, where agents using the same LLMs form a group.\nIndividual-Level Simulation The simulation results are illustrated in Fig. 11. At the first round of the\ngame, we observe that agents with Llama3-70B exhibit similar behaviors, tending to report numbers around\n33, while agents with MistralAI-8\u00d722B consistently report 0. On the other hand, agents with Qwen2-72B\nexhibit more diverse behaviors, reporting a wider range of numbers, with most of them falling between 0\nand 50. These behaviors can be attributed to the preferences of the LLMs, which may be related to their\narchitectures, training corpus, etc.\nAs the game progresses round by round, agents are informed of the winning number from the previous\nround and adjust their strategies accordingly. As shown in Figure 11b, the majority of agents report numbers\nclose to the winning number in the previous round, with approximately 59.7% reporting numbers smaller\nthan the previous winning number. We present a typical response in Appendix E.6, where an agent adopts a\nconservative strategy and chooses a number slightly smaller than the winner number 15.90.\nIn the pie chart of Fig. 11, we further show the winners of each round in the simulation, grouped by\ntheir employed LLMs. To reduce the randomness in the simulation, we regard those agents whose reported\nnumbers fall within the range of \u00b10.5 from $\\frac{2}{3}$ of the average as the winners. The figure shows that in the"}, {"title": "4.7 Further Discussions", "content": "In this subsection, we provide further discussions on usage tips and open questions when conducting large-scale\nagent-based simulations."}, {"title": "5 Conclusions", "content": "In this paper, we first discuss several key"}]}]}