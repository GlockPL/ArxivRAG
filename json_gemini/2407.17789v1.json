{"title": "Very Large-Scale Multi-Agent Simulation in AgentScope", "authors": ["Xuchen Pan", "Dawei Gao", "Yuexiang Xie", "Zhewei Wei", "Yaliang Li", "Bolin Ding", "Ji-Rong Wen", "Jingren Zhou"], "abstract": "Recent advances in large language models (LLMs) have opened new avenues for applying multi-agent systems in very large-scale simulations. However, there remain several challenges when conducting multi-agent simulations with existing platforms, such as limited scalability and low efficiency, unsatisfied agent diversity, and effort-intensive management processes. To address these challenges, we develop several new features and components for AgentScope, a user-friendly multi-agent platform, enhancing its convenience and flexibility for supporting very large-scale multi-agent simulations. Specifically, we propose an actor-based distributed mechanism as the underlying technological infrastructure towards great scalability and high efficiency, and provide flexible environment support for simulating various real-world scenarios, which enables parallel execution of multiple agents, centralized workflow orchestration, and both inter-agent and agent-environment interactions among agents. Moreover, we integrate an easy-to-use configurable tool and an automatic background generation pipeline in AgentScope, simplifying the process of creating agents with diverse yet detailed background settings. Last but not least, we provide a web-based interface for conveniently monitoring and managing a large number of agents that might deploy across multiple devices. We conduct a comprehensive simulation to demonstrate the effectiveness of the proposed enhancements in AgentScope, and provide detailed observations and discussions to highlight the great potential of applying multi-agent systems in large-scale simulations. The source code is released on GitHub\u00b9 to inspire further research and development in large-scale multi-agent simulations.", "sections": [{"title": "Introduction", "content": "Large language models (LLMs), such as GPT-4 (OpenAI, 2023), Claude3.5 (ANTHROP, 2024), Qwen2 (Yang et al., 2024), Llama3 (Meta, 2024), and so on (Anil et al., 2023; GLM et al., 2024; MistralAI, 2024; Yang et al., 2023), notable for their vast number of parameters and extensive training on diverse large-scale datasets, demonstrate remarkable capabilities in understanding, generating, and interacting with human language. Recent advancements in LLMs have sparked a revolution in natural language processing and relevant fields, paving the way for novel applications that were previously inconceivable.\nBuilding on the capabilities of LLMs, there is a growing interest in the development of intelligent agents that are empowered to resolve practical tasks (Hong et al., 2023; Ren et al., 2024). As the scope of these intelligent agents spans a wide array of applications, their potential to redefine the landscape of simulations becomes increasingly evident (Matsumoto et al., 2024; Sorokovikova et al., 2024; Sreedhar and Chilton, 2024; Yue et al., 2024). Traditional simulations heavily rely on predefined rules and sophisticated mechanisms to generate simulated scenarios, necessitating lots of expertise and human interventions (Macal and North, 2010). With the incorporation of LLM-empowered agents, simulations are expected to become more interactive, adaptive, and realistic, while requiring substantially fewer human efforts.\nRecently, several platforms (Hong et al., 2023; Wu et al., 2023; Team, 2023) have been proposed to streamline the development of multi-agent systems, providing some fundamental functionalities including unified LLM services, various tools, and advanced reasoning algorithms. Despite significant progress, we identify several challenges in conducting simulations with multi-agent platforms, particularly when the number of agents becomes extremely large. We summarize these challenges below.\n(i) Scalability and Efficiency Limitations The scale of involved agents can be critical when conducting certain simulations, since simulations at a small scale run the risk of inaccurately representing real-world complexities, making simulations less realistic and reliable (Macal and North, 2010; Macal, 2016). However, increasing the scale of agents brings challenges to the simulation platform in terms of scalability and efficiency. Specifically, it is non-trivial to efficiently organize agents to execute their tasks and communications following an appropriate order, with the aim of reducing the running time while ensuring accurate results. Moreover, the simulation platform should be capable of handling high-frequency access to support both inter-agent and agent-environment interactions in large-scale agent-based simulations.\n(ii) Unsatisfied Population Distributions and Agent Diversity For a large-scale simulation, it is essential that the involved agents exhibit diverse behaviors while generally following a specific population distribution (Gao et al., 2023; Ren et al., 2024). Assigning agents with simple backgrounds may result in a significant number of highly homogenized agents, making it difficult to derive meaningful insights. Besides, existing studies rarely consider how to specify population distributions of agents from various perspectives, such as age, education, occupation, etc. which reduces the realism of the simulations.\n(iii) Difficult Management Processes As the scale of agents increases, it becomes rather effort- intensive to manage the simulations, including initialization, execution, and termination of a large number of agents spread across multiple devices, as well as monitoring their status, behaviors, and interactions (Mou et al., 2024). Such difficulties in managing make it challenging to promptly identify valuable group-level and individual-level behaviors, which can further hinder the discovery of critical insights for optimizing simulations and advancing research. Therefore, an easy-to-use tool for managing large-scale agents is a necessary functionality that should be provided by the agent-based simulation platforms.\nTo tackle these challenges, we adopt a user-friendly multi-agent platform, named AgentScope (Gao et al., 2024), as the foundation framework to provide the basic functionalities, and further develop several new features and components upon it to improve its usability, convenience, and flexibility for supporting very large-scale multi-agent simulations.\nTo be specific, we propose a distributed mechanism based on the actor model (Agha, 1985), featuring automatic parallel execution and centralized workflow orchestration to provide great scalability and high efficiency for multi-agent-based simulations. The proposed actor-based distributed mechanism enables us to further expand the scale of agents in the simulation with a limited number of devices, and provides linear benefit on running time from the addition of devices. We support both inter-agent and agent-environment interactions in the simulations. Agents can initiatively communicate with other agents and the environment, and can respond to messages from other agents and changes in the environment. Furthermore, a multi-layer environment structure is proposed to support group-wise information synchronization, enhancing the flexibility of AgentScope for simulating various real-world scenarios.\nBesides, to satisfy the requirements of population distribution and agent diversity, we integrate a configuration tool in AgentScope and provide automatic background generation. Users only need to simply specify the distributions of the population from several aspects, a large number of agents with detailed and diverse characteristics can be effortlessly generated accordingly. These agents can be managed and monitored conveniently through AgentScope-Manager, a proposed module for simplifying the organization and observation process of large-scale agent-based simulations. Using a web-based visual interface, AgentScope- Manager provides a comprehensive overview of all agents across multiple devices, allowing users to efficiently configure, launch, and terminate these agents.\nWith such an agent-based simulation platform, we conduct a comprehensive simulation on the classic \"guess of the average\" game (Nagel, 1995; Camerer et al., 2004) to demonstrate the improvements and advances brought by the infrastructure introduced above. Firstly, we conduct agent-based simulations involving 1 million agents using only 4 devices, showing the scalability and efficiency of the platform. Then, we incorporate agents using different LLMs of different sizes, equipped with different prompts and diverse background settings, resulting in various and realistic behaviors in the simulations. We provide comprehensive observations on both collective and individual behaviors, drawing meaningful and valuable insights from a series of simulation experiments, along with further discussions on helpful tips and open questions. These experimental results confirm the feasibility and great potential of conducting large-scale agent-based simulations. We have released the source code at https://github.com/modelscope/agentscope for future research."}, {"title": "Related Works", "content": "LLM-Empowered Agent Platforms With the advances of LLMs, a significant number of agent platforms have been developed to integrate LLMs into real-world applications and assist humans in problem-solving (Wu et al., 2023; Hong et al., 2023; Li et al., 2023b; Significant-Gravitas, 2023; Team, 2023; Gao et al., 2024). These platforms can be categorized into single-agent platforms and multi-agent platforms. The single-agent platforms include AutoGPT (Significant-Gravitas, 2023), LangChain (langchain ai, 2024a), ModelScope-Agent (Li et al., 2023a), and Transformers Agents (Wolf et al., 2020), which are proposed to resolve practical tasks using LLMs. On the other hand, multi-agent platforms like MetaGPT (Hong et al., 2023), Auto-Gen (Wu et al., 2023), CAMEL Li et al. (2023b), and LangSmith (langchain ai, 2024b) employ multi-agent collaboration to tackle more complex challenges, including software programming (Hong et al., 2023; Qian et al., 2023), data science (Hong et al., 2024), social simulation (Park et al., 2023), game-playing (Gao et al., 2024), etc. Although remarkable progress has been made, applications built on these platforms can currently be limited in the scale of agents and suffer from low efficiency, hindering their potential for large-scale simulations. To address these limitations, we enhance AgentScope with new features and components to support very large-scale agent-based applications and improve the running efficiency of these applications.\nAgent-Based Simulation Frameworks Due to the ability of LLMs to imitate human behaviors, agent- based simulation has become an attractive topic in the research community (G\u00fcrcan, 2024; Matsumoto et al., 2024; Sorokovikova et al., 2024; Sreedhar and Chilton, 2024; Ye and Gao, 2024; Team et al., 2024; Park et al., 2022). Previous studies have explored the integration of LLMs in various fields, including education (Yue et al., 2024), economic (Matsumoto et al., 2024), societal study (Park et al., 2023; Ye and Gao, 2024; Gao et al., 2023; Ren et al., 2024), transportation (Jin et al., 2023), healthcare (Zhang et al., 2023) etc. Recently, researchers have built up several LLM-based or agent-based simulation frameworks. For instance, Vidur (Agrawal et al., 2024) is a simulation framework that focuses on providing high-throughput LLM services, Ataei et al. (2024) is proposed for design requirements elicitation, Cheng et al. (2023) is developed to evaluate the level of caricature, and Ren et al. (2024) is designed to simulate the behaviors of web search users. However, these existing frameworks are domain-specific, making it challenging for users to conduct large-scale agent-based simulations for a wide variety of applications. To tackle this, we design a multi-agent-based simulation platform AgentScope and provide easy-to-use configurable tools to ease the heavy workload associated with conducting various large-scale simulations."}, {"title": "Infrastructure", "content": "To provide the basic functionalities required for conducting agent-based simulations, including LLM services, memory management, and agent interactions, we adopt AgentScope, a user-friendly multi-agent platform designed for flexible Standard Operating Procedure (SOP) tasks, as our foundation framework. We further develop several new features and components, making it more convenient and feasible to support very large-scale simulations involving multiple agents.\nSpecifically, we first design an actor-based distributed mechanism (Sec. 3.1) that serves as the underlying technological infrastructure for conducting large-scale simulations, providing great scalability and high efficiency. Building upon such an infrastructure, we enable both inter-agent interactions and agent-environment interactions (Sec. 3.2) to facilitate multi-agent simulations, which forms the core components that drive the simulated dynamics. To improve the diversity of agents involved in the simulations, we allow users to set heterogeneous configurations for agents by specifying their population distributions and detailed background settings (Sec. 3.3). Furthermore, we build a graphical user interface to monitor and manage the distributed agents on different devices, making it easy to observe and organize large-scale agents in the simulations (Sec. 3.4). In the following subsections, we elaborate on the details of these proposed enhancements."}, {"title": "Actor-based Distributed Mechanism", "content": "The actor model is a mathematical model of concurrent computation, where each actor acts as a basic computing unit, receives messages, and computes independently (Agha, 1985). Based on the actor model, we build a distributed mechanism to provide great scalability and high efficiency for agent-based simulation."}, {"title": "Automatic Parallel Execution", "content": "In a multi-agent simulation, the interactions between agents follow an atomized pattern, where interactions occur within small isolated cliques (Matsumoto et al., 2024; Sorokovikova et al., 2024). Such a pattern holds significant potential for parallelization, leading to substantial gains in efficiency. However, achieving parallelization is non-trivial as it requires the formal definition of interactions, the identification of potential parallelizable computations, and subsequent optimization.\nTo provide automatic parallelization in AgentScope, we first format the inter-agent interactions in the simulation as a communication graph, where each vertex $v$ represents an agent, and each directed edge $e$ represents a message passing from one agent to another. Note that the communication graph can be a directed cyclic graph that might be highly dynamic and uncertain, which is different from the concept of a computational graph in machine learning (Ansel et al., 2024) and thus makes it much more challenging in providing automatic parallelization.\nWith the communication graph, we can dynamically identify the agents that are ready to be executed, which indicates that they do not depend on the outputs of others or that all their dependencies have been fulfilled. These agents are executed automatically in parallel, utilizing the maximum available resources. As they finish one by one, more blocked agents become active and begin their executions.\nSuch a design of automatic parallel execution is well-suited for the actor-based distributed mechanism. Note that we employ the multi-process mode rather than the asynchronous programming to further improve efficiency, wherein each agent can run in a separate process and be treated as an independent node in the communication graph. As a result, an agent's internal computations can only be triggered when it receives the required messages. In this way, each agent only relies on those from which they receive the necessary messages, and the communication graph automatically divides into independent subgraphs based on their dependencies. With these advanced designs and implementations in AgentScope, users only need to specify the message passing paths among agents, the multi-agent simulation can be automatic parallel execution without additional effort.\nAn example of automatic parallel execution is shown in Fig. 1, where agent-B and agent-C are independent of each other but rely on the messages from agent-A, allowing them to be executed in parallel once the execution of agent-A is completed. In contrast, agent-D and agent-E cannot be executed in parallel, as agent-E depends on messages from both agent-B and agent-D."}, {"title": "Centralized Workflow Orchestration", "content": "In addition to the proposed automatic parallel execution, the workload associated with simulation orchestration is also important for supporting very large-scale simulations, as users need to set up and manage distributed agents across multiple devices. These requirements might not be well satisfied when there is a lack of a complete and explicit view of the entire workflow during the development and execution phases.\nTo resolve these issues, we further enhance the proposed actor-based distributed mechanism by allowing users to orchestrate the simulation explicitly and centrally. For simplicity, we refer to the central process that runs the simulation as the center. For each distributed agent, we adopt a proxy in the center that serves as the substitute for it, hiding the remote calculation from users and being responsible for invoking functions and receiving messages from the corresponding distributed agent. With the proxy, users can specify the communications between distributed agents in the center.\nHowever, when implementing such a centralized workflow orchestration, a question arises: How can sequential execution at the center be compatible with automatic parallel execution? To tackle this, we elaborate on the concept of placeholder, which ensures that the workflow execution in the center is not blocked by the calculations in distributed agents. In the central process, once an agent proxy receives a message, it immediately returns a placeholder and forwards the message to its corresponding distributed agents. For a distributed agent, when receiving a message, it first checks if the message contains a placeholder to decide whether it needs to request and wait for the actual value from the agents indicated on the placeholder. Agents execute their inner computations accordingly as soon as they receive all actual values in placeholders.\nFig. 2 shows how the placeholder works. From the example we can see that, agent-A receives a greeting message x and sends a response message y to agent-B. After that, agent-B replies with a message z when it receives y. In fact, from the view of computation, the center sends message x to agent-A, provides the placeholder of y to agent-B, and requests for the real value of z to construct the workflow. Upon receiving the placeholder of y, agent-B sends a request and waits for agent-A to finish calculating y. When agent-B receives y, it begins to calculate and return z to the center. Note that the construction of the workflow graph (the green part) and the computation (the blue part) start at the same time, while the construction of the workflow graph is instantaneous. In this way, we allow the independent distributed agents to run in parallel.\nIn summary, enhanced by the proposed actor-based distributed mechanism, AgentScope offers high efficiency in inter-agent communications, enables parallel execution of multi-agents, and allows centralized workflow orchestration to simplify usage."}, {"title": "Agent-Environment Interactions", "content": "The agent-environment interactions are crucial alongside the above inter-agent communication in simulations, which allows agents to access the environment, respond to changes in it, and alter it if needed. Considering the large number of agents, the agent-environment interactions should be capable of handling high-frequency access. For example, in a social simulation like AI town (Park et al., 2023), the environment includes timeline and map with the interactive items on it. Agents might frequently check and interact with the items on the map, and the change of these items should also trigger the reactions of agents.\nTo satisfy such requirements, we abstract the environment operations into registering, querying, updating, removing, and monitoring by providing a base class, which can be adapted to various underlying storage databases, including key-value stores, relational databases, NoSQL databases, and so on. We provide two dimensions for users to perform agent-environment interactions, i.e., timeline and location. For the timeline, users can set specific triggers to make the agents access the global time and adjust their behaviors accordingly. For the location, the environment serves as a map maintaining the locations of agents and providing hook functions to trigger the interactions with agents or items nearby. Such a design provides a flexible environment support for simulating various real-world scenarios."}, {"title": "Heterogeneous Configurations", "content": "In a simulation, agents are expected to act as humans with diverse backgrounds, including different ages, genders, careers, nationalities, education, experiences, etc. An intuitive approach is to add these background settings of agents in their system prompts, providing guidance for agents on the roles to play and actions to take. However, for large-scale simulations, providing diverse, heterogeneous, and reasonable background settings for agents can be laborious and time-consuming, especially when precise control of different population distributions is required in certain simulations. This problem motivates us to provide tools in AgentScope to assist users in effortlessly setting up large-scale agents with diverse background settings.\nConfigurable Tool Specifically, users can begin by defining the total population of the simulation, and then specify the distributions of the population from various perspectives. We provide some widely-used distribution templates in AgentScope for convenient usage, from the aspects of age, gender, occupation, nationality, and education. Besides, the proposed configurable tool allows for easy extension of new aspects, enhancing its flexibility to meet diverse requirements. \nAutomatic Background Generation Pipeline After configurations have been provided via the above tool, more detailed and heterogeneous background settings can be automatically generated to instantiate the agents. Specifically, when users start a simulation, we draw specific values from the distributions based on the configurations, convert them into a JSON format, and fill them into a meta prompt to produce the completed instructions for background generation tasks. These instructions are utilized by LLMs to generate heterogeneous background settings. To introduce more diversity, the generation process involves adjusting the random seed and the temperature used by LLMs."}, {"title": "Management for Large-scale Agents", "content": "In a simulation, users need to manage and monitor a large number of agents distributed across different devices, which might become intractable to handle manually as the scale and complexity of the simulation increase. To tackle this, we incorporate advanced forms of agent management and monitoring, named AgentScope-Manager. Specifically, when users start a simulation, servers are first launched on all the remote devices, which provide resident services to remotely create, monitor, and stop distributed agents. These servers are responsible for managing the lifecycle of distributed agents and synchronizing their information to a web-based visual interface. The web-based visual interface provides a comprehensive overview of all registered servers and all deployed agents on different devices, from which users can view the server's identity, IP address, running status, and utilization of computing resources.\nThe AgentScope-Manager also simplifies the management and monitoring processes for conducting multiple simulations. Since the servers can be reused in different simulations, users don't need to restart the distributed servers between two simulations. Users can efficiently configure, launch, and terminate servers and agents during the simulations as needed. With such a design, we streamline the management process by focusing on servers rather than individual agents, thereby improving the efficiency and effectiveness of managing large-scale agent systems in AgentScope.\nIn a nutshell, based on AgentScope, we implement an actor-based distributed mechanism that serves as the underlying technological infrastructure, which is well-designed for both inter-agent and agent-environment interactions, and provides great scalability and high efficiency in conducting large-scale agent-based simulations Building on the infrastructure, we provide heterogeneous configurations and the management server, enhancing the diversity of agents and simplifying the observation and organization of the simulation process."}, {"title": "Experiments", "content": "In this section, we conduct large-scale simulations to show the improvements and advances brought by the proposed infrastructure and components in AgentScope. Meanwhile, we provide detailed observations and in-depth discussions on the agents' collective and individual behaviors, drawing valuable insights."}, {"title": "Settings", "content": "We set up a large number of agents to participate in the classic game guess the $\\frac{2}{3}$ of the average, where each agent reports a real number between 0 and 100 and the agent who reports a number closest to $\\frac{2}{3}$ of the average of all the reported numbers wins the game. In this game, intuitively the highest possible average is 100. Therefore, for winning the game, agents tend to report a number no larger than $100 \\times \\frac{2}{3} = 66\\frac{2}{3}$. Once all agents adopt this strategy, $66\\frac{2}{3}$ becomes the new highest possible average and thus they tend to report a number no larger than $66\\frac{2}{3} \\times \\frac{2}{3} = 44\\frac{4}{9}$. This process continues until the average becomes 0 and all agents report 0, indicating that the game has reached its Nash equilibrium. However, considering that agents may not always be rational, those agents who report 0 cannot always win the game since the average does not converge to 0 immediately. Agents should carefully take into account the possible actions of others before reporting their numbers. Meanwhile, agents can adjust their strategies in a multi-round game according to the average reported numbers in previous rounds.\nNote that all the experiments in this section follow the aforementioned settings. With this game, we aim to demonstrate the capabilities of AgentScope in supporting large-scale agent-based simulations, and show how agents perform considerations and reasoning concerning their system prompts, background settings, and other information obtained in the simulations.\nDevices & LLMs The experiments are conducted on a cluster containing multiple devices, each of which is equipped with 8 A100-80G GPUs, a 64-core CPU, and 1 TB of memory. We adopt vLLM (Kwon et al., 2023) as the LLM inference engine to handle highly concurrent service requests. We utilize six powerful and popular open-source LLMs of different sizes. We adopt their instruction versions due to their enhanced ability to follow instructions. The details of the adopted LLMs are provided below:\n\u2022 Llama3-8B / Llama3-70B (Meta, 2024): A series of open-source LLMs developed by Meta, which have been pre-trained and fine-tuned on a massive corpus.\n\u2022 Qwen2-7B / Qwen2-72B (Yang et al., 2024): The second generation of Qwen open-source LLMs, developed by Alibaba.\n\u2022 MistralAI-8x7B / MistralAI-8x22B (MistralAI, 2024): The open-source mixture-of-experts (MOE) LLMs released by MistralAI, where each MOE LLM consists of eight 7B/22B models."}, {"title": "Scalability and Efficiency", "content": "First of all, we conduct a series of experiments to show the scalability and efficiency of the agent-based simulations supported by the proposed actor-based distributed mechanism (see Sec. 3.1). Specifically, we illustrate how the overall simulation running time changes as the number of participating agents grows when using LLMs of different sizes, including Llama3-8B and Llama3-70B. In addition to the model sizes, the system prompt provided to agents is also a factor that can influence the running time, since some prompts (e.g., Prompt 2) may encourage agents to generate longer responses and thereby lead to longer response time. From the experimental results shown in Fig. 5, we can obtain the following observations and insights.\n(i) We support an agent-based simulation involving 1 million agents, which can be completed in 12 minutes using 4 devices. In Fig. 5a, we fix the device number to 4 and record the simulation running time as the number of agents grows from 100 to 1M. It can be observed that the simulation involving 1 million agents finishes in 12 minutes when using Llama3-8B with Prompt 1, while it takes 85 minutes if we choose Prompt 2, as the number of averaged response tokens grows by more than 150-fold2. For the heaviest inference workload, i.e., when agents adopt Llama3-70B and Prompt 2, it takes around 10.6 hours to complete the simulation.\n(ii) The proposed actor-based distributed mechanism significantly improves the efficiency of large-scale agent-based simulations. To better demonstrate the improvements brought by the proposed actor-based distributed mechanism, we adopt a dummy model request (i.e., agents sleep for 1 second and generate random numbers rather than posting the requests) in the simulation to remove the impact of the LLM inference speed. The experimental results summarized in Fig. 5b show that, completing an agent-based simulation with the proposed actor-based distributed mechanism involving 1 million agents only takes 40 seconds, whereas simulations using serial execution or asynchronous mode in Python (adopted by existing works (Wu et al., 2023; Hong et al., 2023)) require around 12 days and 8.6 hours, respectively.\n(iii) Increasing the number of devices can proportionally reduce the simulation running time. As shown in Fig. 5c, we maintain the number of agents at 10,000 and vary the number of devices used in the simulation. For Llama3-70B with Prompt 2, the simulation running time decreases from 22 minutes to 5.6 minutes as the number of devices increases from 1 to 4. Such a phenomenon can be attributed to a reduction in the number of agents served within one device. As a comparison, we increase the number of devices from 1 to 4, and deploy 10,000 agents on each device, respectively. As illustrated in Fig. 5d, the running time remains nearly the same as the number of devices and agents increases, which demonstrates the horizontal scalability of AgentScope.\nIn summary, the proposed actor-based distributed mechanism in AgentScope enhances the efficiency in conducting very large-scale agent-based simulations, and offers great scalability by allowing users to expand the scale of agents from the addition of devices."}, {"title": "Simulation Results and Analysis", "content": "In this section, we add some detailed information with six LLMs and two system prompts. We summarize the experimental results in Fig. 6, from which we derive the insights below, and provide more detailed results (e.g., distributions and statistics of the reported numbers) and individual-level observations in Appendix D and Appendix E.1, respectively.\nFrom the comparisons in the figures, we observe that when utilizing a basic system prompt Prompt 1 with most LLMs, agents generally tend to report numbers around 50. However, it is worth noting that agents with MistralAI-8\u00d77B and MistralAI-8\u00d722B, report smaller numbers (36.63 and 31.69 in average, respectively) than other agents. These results indicate that without providing specific instructions in system prompts, the performance of agents can be different due to the LLMs they adopt, influenced by factors such as model sizes and model architectures."}, {"title": "Detailed Instructions in System Prompts", "content": "To further explore the impact of behavioral guidance on agents, we incorporate more detailed instructions tailored for this game in the system prompts. Specifically, we remind agents that all their competitors are rational and will try to adjust the reported numbers by analyzing others' strategies, resulting in Prompt 3 and Prompt 4 respectively. With adding such behavioral guidance in the system prompts, we expect agents can engage in more thoughtful and diverse considerations before reporting their numbers, thereby making simulations more practical, meaningful, and interesting.\nThe comparisons among different system prompts are illustrated in Fig. 8. In general, from the figure we can observe that the reported numbers are closer to 0 when using Prompt 3 and Prompt 4 than those of Prompt 1 and Prompt 2. These experimental results indicate that detailed instructions are more effective than general guidance (e.g., \"think step by step\") in encouraging agents to perform thoughtful considerations and take rational actions. Several case studies shown in Appendix E.3 confirm the improvements brought by adding detailed instructions in the system prompts.\nFurthermore, in a multi-round game illustrated in Fig. 7, agents using Prompt 3 and Prompt 4 can converge to the Nash equilibrium faster than those using Prompt 1 and Prompt 2. For example, agents with Qwen2-72B report 35.30, 6.11, 1.55, and 1.69 in average at the third round when using Prompt 1, Prompt 2, Prompt 3, and Prompt 4, respectively, while in the fifth round, the average of reported numbers become 25.16, 2.02, 0.14, and 0.15.\nIt is worth noting that the impact of the system prompts on different LLMs can be different. For example, from the perspective of the range of the reported numbers (i.e., the maximum and minimum value of reported numbers among all agents), employing Prompt 3 and Prompt 4 in Qwen-72B can significantly reduce the maximum number, while that of Mistral-8\u00d722B remains unchanged. Besides, using detailed instructions in system prompts might increase the token number of responses, as summarized in Appendix C, because agents are likely to consider multiple aspects before providing an answer."}, {"title": "Diverse Background Settings", "content": "The diversity of agents is a critical factor in agent-based simulations. In Sec. 3.3, we introduce the proposed configurable tool and background generation pipeline designed to automatically instantiate agents with diverse background settings. In this subsection, we conduct simulation experiments involving diverse agents, considering their educational levels and occupations.\nSpecifically, we divide the agents into several groups, each of which consists of 200 agents. For each group, we manually provide a basic configuration and utilize LLMs to generate a detailed description for each agent, thereby further enhancing the diversity of the agents. These generated background settings are added to the system prompts and labeled as \"character background\", using Prompt 5."}, {"title": "Mixture of LLMS", "content": "In this subsection, we conduct a simulation experiment involving agents employing a mixture of LLMs. Specifically, we configure agents employing Llama3-70B, MistraAI-8\u00d722B, and Qwen2-72B, with 500 agents assigned to each LLM. We conduct both individual-level simulations, where each agent plays the game independently, and group-level simulations, where agents using the same LLMs form a group.\nIndividual-Level Simulation The simulation results are illustrated in Fig. 11. At the first round of the game, we observe that agents with Llama3-70B exhibit similar behaviors, tending to report numbers around 33, while agents with MistralAI-8\u00d722B consistently report 0. On the other hand, agents with Qwen2-72B exhibit more diverse behaviors, reporting a wider range of numbers, with most of them falling between 0 and 50. These behaviors can be attributed to the preferences of the LLMs, which may be related to their architectures, training corpus, etc.\nAs the game progresses round by round, agents are informed of the winning number from the previous round and adjust their strategies accordingly. As shown in Figure 11b, the majority of agents report numbers close to the winning number in the previous round, with approximately 59.7% reporting numbers smaller than the previous winning number. We present a typical response in Appendix E.6, where an agent adopts a conservative strategy and chooses a number slightly smaller than the winner number 15.90.\nIn the pie chart of Fig. 11, we further show the winners of each round in the simulation, grouped by their employed LLMs. To reduce the randomness in the simulation, we regard those agents whose reported numbers fall within the range of \u00b10.5 from of the average as the winners. The figure shows that in the first and fifth rounds, agents equipped with Qwen2-72B outperform other agents, while agents equipped with MistralAI-8\u00d722B emerge as winners in the second, third, and fourth rounds. Notably, almost all agents tend to report numbers near 0 in the final round, indicating agents can perform reasonable considerations and behaviors to promote this game approach to its Nash equilibrium.\nGroup-Level Simulation In the group-level simulation, agents are divided into three groups. Each agent reports a number, and the average number among the agents within each group is regarded as the reported number of this group. Finally, the group that reports a number that is closest to the $\\frac{2}{3}$ of the average among the groups' reported numbers wins the game. The system prompt adopted, which specifies the above game rules, is shown in Prompt 6.\nMeanwhile, we modify the information announced between different rounds in a multi-round game. Starting from the second round, in addition to the winning number of the previous round, all agents are informed of the reported numbers from all three groups in the previous round. This provides additional guidance for agents to adjust their strategies. Such a group-wise synchronization is implemented based on the agent-environment interaction mechanism (see Sec. 3.2), allowing agents within the same group to share an interactive environment for synchronization.\nThe simulation results are shown in Fig. 12. From the figures, it can be observed that agents within the same group quickly converge to"}]}