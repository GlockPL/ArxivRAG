{"title": "Al on My Shoulder: Supporting Emotional Labor in Front-Office Roles with an LLM-based Empathetic Coworker", "authors": ["VEDANT DAS SWAIN", "QIUYUE \"JOY\" ZHONG", "JASH RAJESH PAREKH", "YECHAN JEON", "ROY ZIMMERMAN", "MARY CZERWINSKI", "JINA SUH", "VARUN MISHRA", "KOUSTUV SAHA", "JAVIER HERNANDEZ"], "abstract": "Client-Service Representatives (CSRs) are vital to organizations. Frequent interactions with disgruntled clients, however, disrupt their mental well-being. To help CSRs regulate their emotions while interacting with uncivil clients, we designed Pro-Pilot, an LLM-powered assistant, and evaluated its efficacy, perception, and use. Our comparative analyses between 665 human and Pro-Pilot-generated support messages demonstrate Pro-Pilot's ability to adapt to and demonstrate empathy in various incivility incidents. Additionally, 143 CSRs assessed Pro-Pilot's empathy as more sincere and actionable than human messages. Finally, we interviewed 20 CSRs who interacted with Pro-Pilot in a simulation exercise. They reported that Pro-Pilot helped them avoid negative thinking, recenter thoughts, and humanize clients; showing potential for bridging gaps in coworker support. Yet, they also noted deployment challenges and emphasized the irreplaceability of shared experiences. We discuss future designs and societal implications of AI-mediated emotional labor, underscoring empathy as a critical function for Al assistants in front-office roles.", "sections": [{"title": "1 INTRODUCTION", "content": "When we engage an organization for their product or service, our initial contact is with staff known as front-office workers or Client Service Representatives (CSRs). They are the first line of response for the organization. Unlike other roles within an organization, a CSR's task involves frequent interactions with clients and individuals outside an organization [58]. These interactions require CSRs to manage their emotions constantly to complete tasks. Essentially they exert emotional labor to appear professional [58]. The crucial challenge for a CSR is engaging with a client who starts behaving uncivilly by communicating in a rude, aggressive, and emotionally charged way [50]. No matter the type of request, a CSR's role is to resolve a client's concern and comply with the adage, \"the customer is always right.\" Unfortunately, this leads to an emotional dissonance between what a CSR expresses and what they actually feel [49]. Ultimately, such workers are vulnerable to excessive stress and eventual burnout. Not only do CSRs report being emotionally depleted and detached, but they also report a lack of accomplishment [14]. Clearly, CSRs play a critical role within the organization, but, we have witnessed little innovation in alleviating their emotional toll. Our paper investigates how AI-coworkers help CSRs regulate their emotions in the face of client incivility."}, {"title": "2 BACKGROUND", "content": "The related work introduces the nature of their work, the role of emotion regulation, and the relevant concepts from HCI literature."}, {"title": "2.1 Front-Office Work and Incivility", "content": "People who work front-office are the human touch-points for direct interaction with clients 1. The end-user, or client, can directly observe and experience the activities of front-office workers [134]. Front-office work spans a variety of organizational sectors including health (e.g., front-desk), hospitality (e.g., air staff), retail (e.g., store associates), and technology (e.g., customer service). For front-office roles, or \"pink-collar\" work, organizations seek to hire individuals who can emotionally invest in their clients, meet their needs and please them [59]. Our research focuses on online front-office work where the employee frequently interacts with their client via text-based communication. This paper refers to these workers as Client Support Representatives or (CSRs).\nToday, CSRs cater to a variety of clients and it is common to encounter high-maintenance clients who have unrea- sonable service demands [45]. Unfortunately, these demands translate into rude and discourteous behaviors. Koopmann et al. defines client incivility as \"low-quality interpersonal treatment that employees receive during service interactions.\" Unlike overt verbal abuse, such as calling the CSR names and expletives, or downright violence, incivility is more implicit. According to Andersson and Pearson, the intent to harm is ambiguous and can be deflected, e.g., \"I didn't mean to be rude; I was just in a hurry\" [4]. Organizational psychologists have noted a possible reason for incivility to be the increase in client entitlement while seeking services [130] and a lack of consideration for others [95]. Meanwhile, a CSR role is often low-wage, considered low-skill, and lacks the decision-latitude needed to respond to mistreatment from clients [45]. Coupled together, incivility creates a dynamic between the client and CSR, where the latter feels injustice and negative emotion [45]. Therefore, a CSR's job involves emotional labor because of two processes; managing the interpersonal demands of interaction and controlling their own negative emotions [49]. Facing client incivility regularly puts a CSR at the risk of experiencing emotional exhaustion (lack of motivation and focus), depersonalization (detachment from others' emotions), and reduced accomplishment (feeling of low effectiveness) [79]. The reduced emotional health of CSRs affects organizations as well. They risk an increased turnover and rise in negative work attitudes [14]. Given the large volume of workers in this role, we need to urgently design solutions for their wellbeing."}, {"title": "2.2 Social Support and Emotion Regulation", "content": "At work, social support is known to be an important moderator for incivility [57, 106, 128]. One kind of social support is emotional support, where a coworker provides sympathy and understanding [20]. This form of support can help reduce work-related stress [60]. Studies have shown that CSRs with more supportive coworkers are able to recover from the negative effects of client incivility, by being able to recognize emotions and guide constructive actions in response [127, 129]. Yet, in practice, CSRs are known to receive low levels of emotional support [122] as coworkers can favor client interests over that of an employee [131]. A coworker with high emotional intelligence is someone capable of expressing compassion in a way that helps the CSR cope with negative emotions and proceed to their goal [75]. This behavior of coworkers was the primary metaphor we used to conceive PRO-PILOT.\nEmotional support can be viewed as a form of emotional coping, or Emotional Regulation (ER). Unlike traditional discussions of ER, coworker support is other-directed [131]. Conversely, CSRs are trained to and expected to regulate"}, {"title": "2.3 HCI and Al for Emotion Labor", "content": "A worker performs emotional labor when their job role expects them to either maintain certain emotions or evoke certain emotions [58]. The HCI community has primarily studied this phenomenon in the scope of crowd work [82] and particularly content moderation [40, 125]. Online communities rely on volunteer moderation, and users who participate as moderators often work in a way analogous to front-office work (Section 2.1). Even in an online - primarily text-based interaction, content moderators have described adopting emotion management techniques to tackle their tasks (e.g., receiving threatening messages from users) [40]. Content moderators differ from CSRs, as they are less likely to have synchronous interactions. Having said that, these workers are also subject to reduced emotional wellbeing, such as lack of appreciation and negativity [125]. Another key distinction between content moderation and CSRs is the context of employment. The former is often a voluntary role, whereas the latter is likely to be one's primary employment. These differences significantly change the socio-organizational dynamics between the worker-client and among the workers. The unique normative structure of emotional labor for CSRs motivated us to conduct a user evaluation to inspect PRO-PILOT with actual users.\nSince the emotional labor in content moderation is largely composed of harmful content and secondary trauma, solutions have focused on dynamic content filtering and modulation [27, 67]. These approaches of preventing or reducing exposure [116] are incompatible with CSR roles where the emotional labor is not caused by explicitly harmful content but by incivility, which is inherently ambiguous, and originates from the client [4]. Cook et al.'s approach to inject positive stimuli in between tasks could be compatible, but their effectiveness was mixed [24]. Alternatively, Osawa suggested an on-task solution for face-to-face emotion labor where enhanced glasses make the user's eyes appear to be emotionally invested [92]. The equivalent of this type of substitution of emotional labor would be the introduction of Al-powered chatbots. Arguably, these chatbots have reinforced client- interactions [118], but on one hand, chatbots relieve the task burden of routine inquiries; on the other hand, a large proportion of clients still prefer human CSRs for more complex complaints and better emotional support [41]. Thus conversational agents do not sufficiently mitigate the challenges of emotional labor on CSR.\nHCI research so has explored the future of work across many occupations, but pink-collar work such as that of CSRs has been under-explored. Moreover, the role of LLMs in mitigating issues in worker wellbeing remains an open question [33]. Our research aims to highlight the needs of these workers by inspiring interest into the role of AI in scaffolding emotional labor."}, {"title": "3 PRO-PILOT: SYSTEM DESCRIPTION", "content": "In traditional front-office work, coworkers are an important social resource. When a CSR encounters uncivil clients, they often consult their coworkers to assuage the excessive emotional labor [44, 129]. Such consultations can be challenging to interleave into the ongoing task of addressing an aggressive client. Thus, we used OpenAI's GPT-40 [1] to design an emotional support utility that can be embedded into the CSR's task environment. Our utility differs from typical conceptions of Al-assistants for work, or \"copilots,\" that provide informational support by enabling better problem solving [25], such as coding assistance [88]. Instead, our utility leverages LLMs to provide emotional support by enabling ER through cognitive change [49]. Throughout the paper, we refer to our overarching system for empathetic support as PRO-PILOT. This section explains how PRO-PILOT was implemented. First, we describe how we harnessed domain knowledge and real complaint datasets to generate uncivil client interactions. Second, we describe how PRO-PILOT produces empathetic messages for CSRs who are involved in uncivil interactions. Later, in Section 4.4, we compare how PRO-PILOT performs against other state-of-the-art LLMs (GPT, Llama, Mistral), which additionally justifies our approach for designing and fine-tuning PRO-PILOT for the purposes of our study."}, {"title": "3.1 Compiling Interactions with Uncivil Clients", "content": "To design empathetic messages, we need to expose PRO-PILOT to interactions between CSRs and uncivil clients. However, actual logs of CSRs interactions tend to be protected by organizations for a variety of safety and privacy reasons. Moreover, clients from individual organizations are likely to be limited by specific scenarios. We addressed these constraints by synthetically generating a comprehensive set of client-CSR interactions. We used a real world corpus of publicly posted client complaints on Twitter [5], which was collected for the \"study of modern customer support practices and impact.\" These data served as examples to build life-like, multi-turn, text-based conversations between a CSR agent and a client seeking support over a live chat interface. The complaints in the data varied across industrial sectors, with mobiles and airlines having the largest volume."}, {"title": "3.1.1 Diversifying Complaints", "content": "PRO-PILOT should be robust to all kinds of complaint scenarios. To ensure our client interaction dataset captures the variety of complaints, we distilled five categories for complaints based on prior analyses of customer complaints [22] - Service Quality, Product Issues, Pricing & Charges, Policy, Resolution. Four authors encoded a random sample of 15 complaints to refine the category definitions (Section A.1.1). After finalizing definitions, two authors independently encoded a random sample of 250 complaints. A third author encoded any complaints with disagreements. We also identified the sector, or domain, of each of these complaints. For the initial complaint generation, we prompt the LLM with definitions of complaint categories and a set of examples to generate a new complaint for any given input domain and category."}, {"title": "3.1.2 Prompting for Incivility", "content": "Once a complaint was initiated, we created a distinct Client-Agent to carry forward a turn-by-turn interaction with a CSR. Recent explorations with LLMs show that chat agents can be infused with specific personalities and reliably respond to fit the specified personality [109]. Uncivil clients are likely to induce stressful scenarios in emotional labor [4]. We refer to Andersson and Pearson's definition of incivility to design a role for Client-Agent. To respond to the client, we set up another agent, Rep-Agent, to act as \"a service representative chatting with a customer online.\" Both agents included an intermediate step to contextualize the input with respect to the conversation history so that the subsequent response maintains continuity. By having Client-Agent and the Rep-Agent converse, we were able to design multi-turn conversations where Client-Agent is acting uncivil to the Rep-Agent. We refer to these synthetic, multi-turn conversations as incidents. To capture the variety of scenarios in front-office work, we varied incidents across 3 domains - airlines and hotels, which have been used as representative scenarios in the literature [46], and mobiles, which are extensively represented in the real world complaint dataset [5]. For each domain and each complaint category, we generated 3 incidents. Each incident contained 5 total turns, with the Client-Agent awaiting a response to their last message. The incomplete conversation was purposefully intended to assess how PRO-PILOT could digest ongoing incidents and provide support."}, {"title": "3.2 Emotional Regulation with Empathy", "content": "A coworker with high emotional intelligence can mitigate the client incivility by helping CSRs regulate their emo- tions [131]. The primary component of PRO-PILOT, Emo-Reframe, was designed to reflect this social phenomenon."}, {"title": "3.2.1 Examples of Human Reframing", "content": "Prior work has shown that LLMs can help individuals perform self-directed ER [112]. We leveraged Sharma et al.'s dataset 2 on cognitive restructuring and emotional reframing to seed examples of our own implementation [112]. This dataset contains tuples of a situation that triggers a negative thought and a corresponding reframed thought for ER. Client incivility differentiates itself from everyday negative thinking, which often stems from abstract concerns. By contrast, incivility is interpersonal in nature and causes an ego threat-an attack on one's self-esteem and image leading to retaliatory thoughts [46]. Thus, we identified situations in the dataset that were interpersonal, involved at least two individuals (e.g., \u201cI was talking to a friend who got me angry\") and described a confrontation, in-the-moment conflict (e.g., \"I get so annoyed and frustrated when my baby cries\"). Moreover, we narrowed down examples that labeled retaliatory negative thoughts, such as blaming and labeling 3."}, {"title": "3.2.2 Reframing Chain-of-Thought", "content": "Our approach adapts Sharma et al.'s situation-based reframing approach by orienting it as other-directed and specific front-office client incivility. However, the fast-paced nature of front-office work can make it impractical for CSRs to disclose their situations or thoughts. Thus, to automate this process, we describe our sequence of LLM prompts:\n(1) Summarize the particulars of the complaint and specify the client's negative behavior with evidence. To reflect the ego threat [46], the situation describes how the CSR may be perceived as a result of the interaction.\n(2) Derive a negative thought from the situation using examples.\n(3) Reappraise the situation and thought as input to produce a reframe using examples.\nSince the dataset was designed around self-directed ER, the outputted reframe message goes through a rudimentary prompt to rephrase it as a message addressed to the CSR."}, {"title": "4 TECHNICAL EVALUATION: INSPECTING THE EFFICACY AND PERCEPTION OF PRO-PILOT", "content": "Our central metaphor for the design of PRO-PILOT is the support of human coworkers [131]. Therefore, before embedding PRO-PILOT into a real-time interaction, we first evaluated the quality of the support messages that Emo-Reframe produces. To answer RQ I, we analyzed the messages to provide empirical, statistical evidence on the differences and similarities between PRO-PILOT and a human coworker."}, {"title": "4.1 Method: Comparing PRO-PILOT to Coworker Empathy", "content": "We first conducted two online studies on Prolific [93] and then analyzed these messages through different linguistic markers and statistical models.\nPhase I - Writing Empathetic Messages for CSRs: Participants read incidents of client incivility (Section 3.1.2) and provided an empathetic message as if they were a coworker. Eligible participants needed to have at least 1 year of relevant experience, have encountered uncivil clients, and primarily interact with clients via computer-mediated communication (e.g., live chat). Each participant was randomly assigned a scenario (airlines, hotel, or mobile devices) and they viewed 6 incidents (at least one of each complaint category). Participants were guided to write an empathetic message using Downward-Arrow-Technique (DAT) [18] that leads them to first consider the CSR's emotion, then their thought, and finally describe a message to overcome the thought. Their messages are indicated by the notation, Human. To foster more variety in the task, we injected contextual information about the CSR in some of the incidents. Research on workplaces has revealed behavioral indicators of worker mental state, such as focused, stressed, and bored [78, 87]. Based on these studies we randomly assigned descriptions of CSR mental state for 2 incidents (Section A.1.2). As per organizational psychology, personality can serve as an important context to explain how workers perceive situations [39]. Participants were asked to think of an actual coworker and select their personality as either resilient (organized and dependable), undercontrolled (competitive and high energy), or overcontrolled (detail-oriented) archetype [39]. 2 incidents included descriptions of these personalities (Section A.1.3). 116 CSRs successfully completed the writing task and they received $8 for the 30 minutes of their time.\nPhase II - Scoring Empathetic Messages from coworkers: Participants read incidents of client incivility and rated the perceived empathy of multiple empathetic support messages. They were not explicitly informed which messages originated from PRO-PILOT and which ones were from humans. To represent multiple dimensions of empathy, we included five dimensions drawn from the literature sincerity, compassion, warmth, actionability, and relatability [89, 112]. Participants were screened using the same criteria but did not overlap with the previous task. Participants rated these on a 7-point semantic scale. 143 CSRs evaluated the 10 incidents each and were compensated $5 for the 15 minute task.\nAnalysis: The inherent characteristics of language are associated with its effectiveness in communication. Research on linguistics has revealed certain linguistic attributes that are important to explain social support and psychotherapy [91]. More recent works have also stressed the importance of language in human-AI interaction [124]. In fact, contemporary studies have already validated linguistic models of empathy [17, 119]. Our analyses include such models and go beyond to measure additional metrics that help interpret PRO-PILOT'S messages in light of Human's messages (retrieved from Phase I). First, we tested how easily CSRs can read and comprehend messages (Syntax and Structure), because these attributes can determine how meaningful the support message is to the reader [12, 48, 80]. Second, we measured the style and meaning of messages to capture social aspects of communication (Linguistic Style & Semantics). The attributes here capture more colloquial conceptions of human empathy [96, 112, 133]. Further, we inspected the words that were used in the messages to identify relevant psycholinguistic markers that reflect social support [120]. The differences we measured provide a linguistic landscape of messages, but empathy is highly contextual and its appropriateness varies by situation [133]. Consequently, we also compared the differences in perceived empathy scores from ratings in Phase II. For every comparison we performed a paired t-test and computed the effect sizes of differences using Cohen's d."}, {"title": "4.2 Lexico-Semantic Analyses", "content": "We operationalized the different lexico-semantic aspects of messages based on domain literature to understand the differences between PRO-PILOT and Human. We only report on statistically significant and theoretically relevant metrics. Below, we describe the theory-driven rationale behind the choice and operationalization of the measures, along with our observations."}, {"title": "4.2.1 Syntax and Structure", "content": "We analyze the arrangement and construction of language in support messages.\nVerbosity and Repeatability The length and thoroughness of messages explain their effectiveness in providing support [48, 105]. The richness of expressions in communication can be described using verbosity and repeatability [72]. Verbosity describes the level of detail and conciseness in supportive communication. We operationalized verbosity as the number of words per thought reframing. Repeatability accounts for the reuse of words in a piece of text. Higher repeatability indicates a lack of conciseness. Drawing on prior work [42, 105, 132], we operationalized repeatability as the normalized occurrence of non-unique words. PRO-PILOT's reframings were 68% longer (Cohen's d=1.60) and 36% more repeatable (Cohen's d=1.54) than Human messages. Sociolinguistic theory argues that the use of more words can indicate sincerity and effort in putting one's point across [12]. Having said that, PRO-PILOT's verbose messages might not always be compatible with the urgency of certain demanding conversations.\nReadability. Apart from the shape of the message, the vocabulary and style can also determine how easily it can be read. Therefore, we turn to the measure of readability, to understand how PRO-PILOT'S messages might be comprehended [80, 123]. According to Wang et al. people perceive AI as more intelligent when the readability is higher [124]. Per prior"}, {"title": "4.2.2 Linguistic Style & Semantics", "content": "We analyzed the distinctive tones, flow, and meaning through which messages express support.\nDynamic Language. Sincerity in communication is an important indicator of empathy [89]. Individuals who tell stories, and communicate with more attention to the world around them, i.e., incorporate more lived narratives, are perceived as more socially engaged [96]. Pennebaker et al. describes this aspect of one's language as dynamic; and it differs from intricate, analytical language that academics might use to organize complex concepts, which is categorical [96]. Pennebaker et al. designed a bipolar index, the Categorical-dynamic index (CDI), where a higher CDI indicates a categorical style of writing, and a lower CDI indicates a dynamic or narrative style of writing. Here, CDI is measured based on the percentage of words per style-related parts of speech as:"}, {"title": "4.3 Psycholinguistic Analysis", "content": "Psycholinguistic markers play a vital role in understanding the nuances of interpersonal communication and social support. We used the Linguistic Inquiry and Word Count (LIWC) lexicon [120] to analyze these differences. LIWC provides a comprehensive framework to categorize language into several dimensions We primarily focused on comparing the differences in affect-given its relevance to empathy [133], and in interpersonal focus- a notable category in psycholinguistic research [97], and which were not captured in the other lexico-semantic analyses."}, {"title": "4.3.1 Affect", "content": "Affect reflects the emotions conveyed in the language. Our analysis shows that PRO-PILOT's responses exhibited significantly lower occurrences of positive affect words (-11.55%, Cohen's d=-0.16) and sadness-related words (-74.87%, Cohen's d=-0.31). These results indicate that PRO-PILOT may aim for emotional neutrality, but it occasionally leans towards stronger negative expressions. Interestingly, PRO-PILOT's responses also showed a higher occurrence of anger-related words (61.77%, Cohen's d=0.47). To clarify, PRO-PILOT is not necessarily sounding more angry, but possibly describing anger (of the client and CSR) more often. In fact, these results are in line with the results on adaptability"}, {"title": "4.3.2 Interpersonal Focus", "content": "Pronouns are indicative of interpersonal focus and narrative style. PRO-PILOT's responses use significantly fewer first-person singular pronouns (I, us) (-67.36%, Cohen's d=-0.58) and first-person plural pronouns (we, us) (-75.43%, Cohen's d=-0.36), reflecting a less personal or collective identity focus. This reduction suggests that PRO-PILOT's responses are less likely to include self-referential language, aligning with a more objective or detached communication style. These results further reinforce our results on dynamics (Section 4.2.2) that PRO-PILOT uses a relatively more objective but detached communication style."}, {"title": "4.4 Robustness", "content": "The results so far indicate that PRO-PILOT has promise in producing empathetic messages, but it begs the question: do we need a carefully crafted, domain-driven sequence of prompts (Section 3.2.2) for this? We replicated the analyses above with messages produced by zero-shot prompting of other LLMs- GPT-4 [1], GPT-40 [1], LLaMA-3.1 [2], and Mistral- 7B [65]. These LLMs vary in their architectures, training data, and optimization methods. We tested the differences using the Kruskal-Wallis test [81] and found PRO-PILOT's responses to be closer to humans, more empathetic, and more controllable. The results of this benchmarking are reported in Now, one might ask if PRO-PILOT's messages, with all its linguistic distinctions, matter to the CSRs? To answer this, we checked the differences in CSR's evaluation of PRO-PILOT and Human's messages."}, {"title": "5 PRO-PILOT: USER EVALUATION", "content": "After establishing that PRO-PILOT can produce situationally appropriate messages, we set out to study how CSRs might actually interact with such an AI-assistant. The critical nature of front-office work raised practical and ethical challenges of deploying a prototype into actual workflows. Therefore, to answer RQ II, we chose to design a simulation exercise where real CSRs could interact with uncivil clients using PRO-PILOT. We deployed PRO-PILOT as a technology probe [62] a functional piece of technology that is presented to learn its use and about the users.\nParticipants & Recruitment: We used Meta ads to recruit 20 CSRs from the U.S. and conducted remote user-study sessions between July and August 2024. Eligible participants had at least 1 year of experience in front-office roles. They were further vetted based on their responses to two free-form questions to describe their role and a previous incivility incident. These participants represented a variety of industrial sectors, such as finance, education, airlines, consulting, and technology."}, {"title": "5.1 Task Environment", "content": "We wanted to study the role of PRO-PILOT'S core component Emo-Reframe (Section 3) in realistic cases of incivility. Thus, we built a web-based prototype environment that resembles typical client interaction interfaces that a CSR might use. Additionally, to isolate the role of Emo-Reframe, we added two new components to PRO-PILOT that represent other forms of intelligent assistance:\n(1) Client Simulant: LLMs have been successfully applied in previous research to simulate challenging interlocu- tors [110]. Following the same principle, we devised a simulation exercise where participants needed to interact with complaining clients. We reused the Client-Agent described in Section 3.1.2 to continue a conversation until their complaint is resolved, or 10-12 turns, whichever occurs sooner.\n(2) Info-Guide Panel: Typically, AI assistants at work provide problem solving support [88]. We replicated this functionality by augmenting PRO-PILOT with LLM-powered generated troubleshooting guidelines. These were a trace of suggestions to help the CSR solve the specific complaint.\n(3) Emo-Label Panel: It is common for CSR interfaces to have sentiment tags highlighting how the client feels and anticipate their behaviors. A CSR's ability to understand the emotional perspective of others can mitigate the negative effects of incivility [101, 103, 108]. We implemented an ensemble sentiment classifier that uses soft-voting to combine the estimates from NLTK [52], TextBlob [77], and Transformers [126]. The output was in the form of a 7-point scale, ranging from very negative to very positive.\n(4) Emo-Reframe Panel: This panel is an instantiation of the Emo-Reframe component (Section 3.2.2). For this evaluation, Emo-Reframe outputs both the inferred thought and perceived reframe.\nAll of PRO-PILOT'S panels were placed on the sides to keep them glanceable, while the main chat remained the primary area of focus. These panels are dynamically updated after every new response from the client. For the purposes of the study, we included a simple semantic differential Likert scale under each panel to ensure that the participant"}, {"title": "5.2 Study Protocol", "content": "Every user session was facilitated over Zoom and lasted at most 90 minutes. All interviews were led by the first author, with the second author observing. Participants accessed the simulation exercise via a unique URL to our study portal. They were tasked to role-play as a CSR who needs to resolve client complaints. The session was divided into two phases. First, participants completed the simulation exercise. To emulate realistic workplace demands, participants were informed that the clients would be rating their complaint resolution skills, and this subjective rating would determine their bonus compensation. Then, they reflected on their interaction with PRO-PILOT through our interview. The bonus incentive was minor deception, and all participants were paid the full $50 in the form of a gift card."}, {"title": "5.2.1 Simulation Exercise", "content": "In line with prior studies of front-office worker behavior [46], each participant was randomly assigned a domain, either airlines or hotels. Before starting the exercise, participants completed a pre-task survey describing their experience interacting with their typical client. We included multiple instruments to capture how the client treated them [115], the cognitive demands and resources available to them [38], and how they affectively perceived the conversations [10]. To familiarize participants with the interface, they first interacted with a civil client with only Info-Guide supporting them. Once they became accustomed to this process, they proceeded to the main exercise. Participants needed to handle complaints from three clients one civil and two uncivil. They only received suggestions and insight from Emo-Label, and Emo-Reframe for the last uncivil client. At the end of every client interaction, they responded to the same survey questions as the pre-task survey. Additionally, they also reported how they perceived PRO-PILOT based on dimensions of AI-mediated support [76]. The survey measurements can be found in Section A.2. This iterative task setup let us compare participants' experiences when dealing with uncivil clients, with and without emotional support, and to examine how these factors influenced their performance and emotional responses."}, {"title": "5.2.2 Semi-Structured Interview", "content": "After interacting with clients, participants proceeded with a semi-structured interview. They answered a series of open-ended questions to provide deeper insight into their primary goals when dealing with uncivil clients, their attitude towards emotional well-being, and their evaluation of PRO-PILOT, especially, in comparison to human coworker support."}, {"title": "5.3 Thematic Analysis", "content": "We performed inductive coding to identify PRO-PILOT's role in front-office work [13]. Two authors carefully read each transcript and performed open-coding. The authors first coded the transcripts independently and then met frequently to reconcile disagreements. They iteratively improved the codes in 20% chunks. Next, we conducted affinity mapping of 258 initial codes using Miro. We merged similar codes together and pruned out codes outside the scope of our research. During clustering, we first organized concepts related to the socio-organizational norms of front-office work. Based on the gaps in these norms we clustered codes related to the capabilities of PRO-PILOT. Our main findings comprise 128 codes which were organized into a four-level thematic structure. We primarily elaborate on the broad themes of Utility, Complementarity, and Pitfalls by anchoring them in the normative patterns that emerged from Reactions to Client Incivility and Role of Coworkers in ER. provides an overview of the main themes, and their relationship, that we cover in the remaining findings."}, {"title": "6 FINDINGS: CLARIFYING THE ROLE OF PRO-PILOT IN UNCIVIL INTERACTIONS", "content": "\u201cAs much as people say, \"don't let it bother you, try to let it slide off your back,\" it does, very much, take its toll.\u201d \u2013 P14\nThe negativity of clients can be contagious [7], and participants described their attitude turning negative (P06), lowered productivity (P08), feeling drained or depressed (P18, P20), and even wanting to reciprocate the incivility (P19). Furthermore, participants also recognized that client incivility can be a form of micro-trauma [117] that was only apparent after several shifts or even years (P14). Many of them work in the fear that a dissatisfied client might report them (P01) and subsequently feel trapped in their role (P04). Given these experiences, the participants in our study were uniquely positioned to assess PRO-PILOT.\nRelatability of the Simulation: Participants had to interact with an uncivil client that replicates emotionally challenging situations of front-office work. During the interactions, several participants exhibited observable reactions to incivility, such as defensively laughing (P06, P18), eye-rolling (P10), and verbally labeling the client (e.g., \"spicy\"-P05)."}, {"title": "6.1 Utility: Functions of Embedding Empathetic Al into Uncivil Conversations", "content": "We structured the probe so that participants could disentangle the role of each component of PRO-PILOT. Before elaborating on the findings, we inspected the ratings provided by the participants during the study. A non-parametric Kruskal-Wallis test [81", "38": "were lower when CSRs had access to PRO-PILOT while interacting with an uncivil Client-Agent. This result provides preliminary evidence that PRO-PILOT's Emo-Reframe is capable of mitigating the emotional labor-induced demands on a worker The same test also revealed that PRO-PILOT's different panels significantly differed in helpfulness. Fig. 7 shows that Emo-Reframe was as helpful as Info-Guide, and both were rated higher than Emo-Label. Therefore, on-task emotional reframing was not considered an additional load, and rather, as helpful as information support.\n\"It's kind of like someone telling you, \"calm down\" - nobody wants that. But, if somebody is genuinely calm in their tone and they say, \"Hey, let's take a second to like, take a deep breath, and like analyze the situation and stuff.\" It's a lot better"}]}