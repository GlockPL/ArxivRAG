{"title": "Sound Check: Auditing Audio Datasets", "authors": ["WILLIAM AGNEW", "JULIA BARNETT", "ANNIE CHU", "RACHEL HONG", "MICHAEL FEFFER", "ROBIN NETZORG", "HARRY H. JIANG", "EZRA AWUMEY", "SAUVIK DAS"], "abstract": "Generative audio models are rapidly advancing in both capabilities and public utilization-several powerful generative audio models have readily available open weights, and some tech companies have released high quality generative audio products. Yet, while prior work has enumerated many ethical issues stemming from the data on which generative visual and textual models have been trained, we have little understanding of similar issues with generative audio datasets, including those related to bias, toxicity, and intellectual property. To bridge this gap, we conducted a literature review of hundreds of audio datasets and selected seven of the most prominent to audit in more detail. We found that these datasets are biased against women, contain toxic stereotypes about marginalized communities, and contain significant amounts of copyrighted work. To enable artists to see if they are in popular audio datasets and facilitate exploration of the contents of these datasets, we developed a web tool audio datasets exploration tool at https://audio-audit.vercel.app/.", "sections": [{"title": "1 INTRODUCTION", "content": "Deep learning and ML-based techniques achieve state-of-the-art performance for a broad range of audio processing tasks ranging from speech transcription [135], pitch estimation [86, 97] to acoustic event classification [163]. Beyond solving foundational problems in areas like signal processing, speech processing, and music information retrieval (MIR), these technologies support an increasing number of higher-level human-AI interactions. For example, virtual avatars, assistive technologies for individuals with visual impairments, as well as novel user interface navigation paradigms utilize advances in audio AI techniques to improve the quality and fidelity of user experiences where audio is a primary interaction modality [41, 157, 171]. More recently, generative AI has led to the development of audio based technologies that can perform several different tasks including making reservations, and text-to-song prompting systems [78, 167].\nWhile the harms of discriminative audio AI have received some treatment by prior work in HCI [165], the harms of generative audio technologies are less understood. Recent events suggest generative AI audio will have unique social and legal implications spanning individuals' right of publicity, misinformation and copyright law, especially when these systems are trained on stolen data. For example, the recently deployed generative AI platform SUNO AI, has been accused of unlawfully using artists' copyrighted music to provide its users with a steady stream of royalty-free music [117]. Another Al-music generation platform, Udio, has been sued by huge players in the music industry such as UMG Recordings, Capitol Records, and Sony who alleged they unlawfully used their recordings to train their model, which Udio essentially conceded to in pre-litigation documents [156]. Other companies such as OpenAI have been embroiled in legal disputes over the unauthorized use of individuals' personal identities, like when the company released a voice eerily similar to Scarlet Johansson's to narrate its GPT-4 Chatbot after the actor rejected OpenAI's request to use her actual voice [151]. Generative audio is also poised to open new and exacerbate existing abuse vectors from misinformation peddling (e.g., deepfake audio imitating President Biden [113]) to voice cloning scams (e.g., where attackers scam unsuspecting grandparents with phone calls impersonating the voice of loved ones [116]). Since the harms and uses of generative AI technologies are largely driven by the data on which they are trained, it is imperative that we have a better understanding of the datasets that are being used to train these models.\nOur paper lays the groundwork for the comprehensive analysis of the audio data currently used to train Al models spanning the domains of music, speech, and sound. This work is motivated by the fact that while the downstream ethical risks and harms of generative text and vision models have been the subject of significant prior work [13, 14, 17, 69], there has been comparatively little focus and understanding of these issues in the context of generative audio, leading to a \"documentation debt\" [10] where widely used audio datasets are often poorly documented and understood. Inspired by audits of vision and text datasets that helped crystallize discussion of the ethical harms present in those modalities of generative AI, in this paper we ask the following questions:\n(RQ1) What audio datasets are being used currently? What is the dsitribution of their use?\n(RQ2) From where are these audio datasets sourced? What licenses are these data under?\n(RQ3) Do these datasets contain toxic content?\n(RQ4) Who is represented and not represented in audio datasets?\nTo answer these questions, we conducted a comprehensive literature review of audio datasets, studying their size, sourcing, contents, usage, and other aspects. From this literature review, we identify seven audio datasets that are representative of the field due to their size, popularity, and overlaps with other popular datasets. We analyze the transcripts, metadata, and genres of these datasets to understand what their contents are, who is represented in these datasets, and where their data were sourced from. We choose to conduct a broad audit of audio dataset practices given the paucity of existing studies of audio datasets. While audio is a deep and rich modality, we believe an assessment of the modality as a whole is needed to scope more specific audits and help uncover relations between audio and other modalities.\nOur literature review identified 175 unique audio datasets that were used between May 2023 and May 2024. These datasets vary significantly in size and popularity, with a few datasets and data sources constituting the majority of publicly available audio (RQ1). We find that 36% of datasets were scraped from the web, 49% were created, 13% were augmented (modifying an existing dataset to the extent such that it constitutes a new dataset), and 2% were purchased from online marketplaces. 35% of datasets are potentially copyright infringing, meaning there is at least some portion of the data for which access beyond private listening requires purchasing licenses (RQ2). We find audio datasets have a wide range of contents, with representative audio datasets containing narrations of public domain (and therefore typically decades old) books, readings of sentences from The Glasglow Herald, and samples of audio from Youtube"}, {"title": "1.1 Audio Al", "content": "The main architectures used in current audio modeling are quite similar to those utilized in image and text, with slight adjustments made to handle the specifics of audio or speech data, such as the Audio Spectrogram Transformer [61], which utilize frequency representations of audio like spectrograms to better model the different audio modalities. LALMs often will combine pre-trained LLMs with audio-specific encoders to extend LLM capabilities to audio modalities [29, 62, 150]. Generative approaches to audio often borrow from LLMs [23] or diffusion models that instead act on spectrograms or waveforms directly [96]. To derive models from audio datasets, a number of methods have been introduced mirroring developments in deep learning for text and images, including RNNs [149], CNNs [65, 74], and combinations of the two [47], have been proposed for the audio domain. Similarly, researchers have more recently turned to techniques leveraging transformer architectures [2, 46, 56] and diffusion [52, 162], especially as generative AI (GenAI) has captured public interest.\nWhile there are many semantically distinct audio modalities, they largely fall into three categories: music, speech, and (environmental) sound-largely referred to as audio by the community. Historically, these modeling in each of these modalities has primarily fallen under separate fields, but recent advances in Large Audio Language Models (LALMs) have seen these distinct modalities being united under single frameworks [60, 62]. These models aim to perform classical tasks, such as Automatic Speech Recognition, Audio Captioning, Note Identification, under a single modeling paradigm [150] and support applications spanning accessibility technologies to music generation.\nAt present a number of challenges exist in the the domain of AI Audio. Many of these problems stem from the limitations of AI-models regarding their ability to pick up on contextual cues traditionally only understood through knowledge and familiarity with the nuances of human communication, such as idiomatic or sarcastic language)[153]. Similarly, accents and speech impediments may prove obstacles to model performance[165]. Proposed solutions to these problems include the use of synthetic data to approximate data from populations not well represented in the AI training data like stutterers [67].\nFor further information on AI for audio, Civit et al. [30] provide a review of music generation, Mehrish et al. [107] review Al for speech processing, and Kelley and Dickerson [82], Nogueira et al. [120], and Palaniappan et al. [125] review Al for sound processing in several major application areas."}, {"title": "1.2 Ethics of Audio Al", "content": "In light of the recent turn to GenAI and improvements of other ML-based audio technologies, some researchers have started to grapple with corresponding ethical concerns and implications. However, as detailed by the literature review conducted by Barnett [7] surveying generative audio research papers, few authors have contemplated the potential negative impacts of their work. Even further, Morreale et al. [110] find that audio datasets are often created without permission of audio owners and creators. Some of these harms have started to be addressed, especially recently, such such as training data attribution of generative audio models [8, 25].\nShelby et al. [142] highlight the sociotechnical nature of AI harms, and emphasize that harms cannot exist independent of societal norms and structures-they have to exist in a set of systems. Ruha Benjamin [11] sheds light on how technological harms (not unlike most societal harms) have a disproportionate effect on people of color; technologies were built for the people in power and \"often adopt the default norms and power structures of society.\" Audio harms are no exception; they can even be magnified when we do not understand the contents of the data. White voice actors doing \"black\" accents is akin to blackface through the audio medium, and voice actors note this is something that can poison datasets. In a similar vein, modern voice cloning models boast of being able to capture diverse voices, but both being able and being unable to model voice archetypes like a \"gay voice\" comes with a host of both safety and representational harms [144]-being unable to could result in harms of not representing all types of voices, while being able to could lead to harmful stereotyping and or require data collection that could put participants at risk.\nAudio deepfakes present a whole new set of harms separate from those already realized by visual and even video deepfakes. In 2023 alone, music featuring deepfake voices of popular artists went viral on social media [36, 51], prompting the music industry to start grappling with intellectual property concerns entailed by generative audio models [71, 79, 127, 145] and even take down online communities where deepfake audio was proliferating [70]. Audio deepfakes are particularly dangerous in the case of phishing and fraud, where bad actors can impersonate voices with high believability and deceive people or even bypass voice security systems [66, 87, 146].Many audio papers, especially text-to-speech papers, note the potential for misuse in form of audio deepfake [85, 87, 161] and some even noted they had no plans to release their models due to the strong potential for misuse via deepfake [87].\nEven within audio harms, there are potential risks specific to sub-fields in audio such as speech generation, music generation, and even the sub-sub-fields like text-to-speech (TTS). Hutiri et al. [76] detail the specific harms inherent to speech generators such as voice clones of voice actors, \"bringing back the dead\", and audio deepfakes of public figures. Batlle-Roca et al. [9] focus on the specific aspect of transparency within generative music and highlight the link between transparency and creativity, originality, and ownership of AI-generated music, suggesting that we should move towards more transparent AI-based music generation. Within TTS there are specific questions with regards to liability of harmful speech [68] as well as harms of the reverse-a high potential for hallucination in speech-to-text [89] with an estimate of about 1% of audio transcriptions being entirely hallucinated.\nOther ethical quandaries remain regarding the contribution of these models to climate change [48], speaker privacy and security [27, 124], creativity [84], GenAI's effect on music creators as a whole [7, 92] and the ethics of using voice synthesis on deceased people [51, 92]. Beyond risks for misinformation and economic harms to artists, recent high-profile instances of fraud (e.g., the transfer of millions of dollars to scammers leveraging GenAI to deceive targets [98, 108]), physiognomy (e.g., gender and sexual orientation classification [91]), and surveillance (e.g., gunshot detection for predictive policing [39]) illustrate the real-world privacy, security, and ethical risks of these technologies."}, {"title": "1.3 Dataset Audits", "content": "HCI research has shed light on the often overlooked human labor underlying much of what Al systems are currently capable of [53]. The human labor involved, which might include data cleaning, annotation and tagging, up to the creation of the data AI are trained on contribute significantly to model performance [94]. Researchers in this space must address challenges stemming from opaque data collection and processing techniques on the part of AI developers, which are now increasingly being trained on individuals personal or copyrighted data [93, 139].\nAudio Al is a complex and rapidly growing field, and if harms are not addressed early then they will be snowballed as the field progresses. In this work we examine the current state of audio datasets and highlight potential ways to employ these datasets more ethically and how to curate more ethically sourced datasets in the future.\nAudits of datasets have proven vital for understanding the behavior and forecasting biases, toxicity, and other harms of downstream models. Prabhu and Birhane [131] found that the 80 Million Tiny Images dataset contained racist and non-consensual intimate imagery (NCII), leading to the creators to take down this dataset [80]. Birhane et al. [18] and Thiel [152] uncover evidence of child sexual abuse material (CSAM) in the LAION5B text-image dataset [141], leading to its removal [32]. While dataset audits incorporate a variety of methods and aims-representation, toxicity, privacy, or copyright concerns-they all help determine how the targeted dataset's contents align with expectations in efforts to achieve accountability [19]. Paullada et al. [128] surveyed dataset audits and found they reveal representational harms and the presence of problematic content overlooked during data curation. Despite the impact of audits, Bender et al. [10] argue that machine learning faces a dataset \u201cdocumentation debt\", with many popular datasets having little if any documentation. Audio suffers acutely from documentation debt, with very few analyses of audio datasets outside of their suitability for increasing technical measures of performance, with the notable exception of bias and representation audits of Mozilla Common Voice [143]. In this paper, we undertake a broad, domain-wide audit of audio datasets, assessing changing data practices and uncovering a range of risks and harms caused by audio datasets.\""}, {"title": "2 LITERATURE REVIEW OF CURRENT AUDIO DATASETS AND MODELS", "content": "As a first step to understanding current audio dataset practices, we conducted a broad literature review of audio datasets created or used between May 2023 and May 2024.\nIn order to understand how many audio datasets exist, the distribution of their usage in the research community, and how these datasets were sourced, we conduct a literature review on audio modelling papers submitted to arXiv, a preprint platform previous studies have found to be an effective source for current and important audio AI papers [7]. We search for papers uploaded between May 1 2023 and May 1 2024 to capture 1 year of data and annotate the datasets included in these papers. We chose this time frame to capture the most recent usage of datasets in a field that has undergone rapid changes in recent years with the introduction of transformers [158] and rapidly growing academic and commercial interest in generative AI. We analyzed audio modelling papers until we approached saturation of datasets (i.e., until we found most of the datasets used were either one-offs or common repeats). We first detail how we conducted this review and then discuss the contents and usage of the identified datasets."}, {"title": "2.1 Literature Review Methodology", "content": "We were interested in identifying audio datasets currently used by researchers to both include in our audit and provide an overview of the data landscape. We chose to conduct a systematic literature review of one year of arXiv [5] computer science works about audio models. We chose one year since there has been a paradigmatic shift in audio generative models, driven in part by the recent advances in large language models and both their translation to text-to-audio models and adopted language-model-style generation as seen in AudioLM [23], MusicLM [2], SoundStorm [24], VampNet [56], and more-researchers and commercial developers alike are largely abandoning the early approaches we saw in 2020-2022 such as the music transformer [75]. Since 2023, approaches towards building Large Audio Language Models (LALMs) largely involve combining many datasets from a broad range of tasks in speech, audio, and music processing [29, 63, 150], often using proprietary language models like the GPT model family to supplement existing data with additional question-answer pairs [44, 60]. One such dataset, OpenASQA, combines a total of 13 publicly available audio, music, and speech datasets to train their LALM, LTU-AS, and uses GPT-3.5-Turbo to generate QA pairs [62]. As researchers move towards curating giant meta-datasets of datasets, it becomes exceedingly vital to understand the origins, licensing, and limits of the many datasets that feed the creation of LALMs.\nWe chose to focus on arXiv submissions because Barnett's [7] recent systematic literature review on the ethical implications of generative audio models resulted in a final corpus comprised of 91% arXiv works even after starting from a 50/50 split of arXiv and ACM works. Though it is difficult to quantify the most influential papers in anything other than citations, which is certainly not a perfect metric, we verified that all the major audio generation papers such as the ones already mentioned in this paper were present in arXiv as well to justify this focus of our exploratory systematic literature review.\nFollowing Barnett's literature review [7], we used the following query on arXiv (once for music, once for speech). This query searches all fields on arXiv including title, abstract, and keywords of papers in this database, but does not search the full text of articles."}, {"title": "2.2 Analysis of Current Audio Datasets", "content": "We then analyzed the 175 audio datasets found through our literature review in order to understand practices, uses, and creation methods. For each dataset, we noted the number of times papers in our corpus used it, the number of the times it had been cited overall (beyond our sample), its size in hours, the categorization of its contents (music/speech/general sound), how its corresponding data was collected, and concerning copyright infringement of the dataset (see Table 1)."}, {"title": "2.2.1 Dataset Labeling and Categorization.", "content": "Calculating Dataset Content Duration (Hours) In order to calculate the duration of each dataset, we conducted a thorough investigation and made necessary assumptions. When explicitly stated, we listed the exact duration of the dataset. When we were provided with number of files and average file length, we performed the calculation. When we were provided with number of files and access to individual files, we got the average file length based on a small sample and multiplied by number of files in the dataset. If we did not have easy access to the data, then we made the following assumptions unless explicitly instructed to do otherwise. We assumed:\n\u2022 Average song length: 3 minutes\n\u2022 Average childrens' song length: 1.5 minutes\n\u2022 Single sentence utterance: average is 12 words, which using average speech length is 5 seconds in English\n\u2022 Single word utterance: 1 second\n\u2022 Phonetically dense sentences: 15 seconds\n\u2022 Anything from YouTube: we examined the data and noted 10 or 30 seconds\nOriginal Content (Yes/No): A dataset is considered original content if audio samples were new recordings, synthesized data from an existing source, created new data using a model trained on an existing source (such as generating fake chorales with a neural network like JS Fake Chorales [130]), converted an existing source from one modality to another (for example, WSJ0 [57], which includes speech recordings made from its sister WSJ text corpus), or added significant data derived from an existing source, such as crowdsourced annotations to tag songs (e.g., MagnaTagATune [90], Free Music Archive [43]). They are not regarded as the original creator if the dataset solely consists of scraped or crawled videos or their links to another source.\nPotential for Copyright Infringement (Yes/No): We adopt a conservative and stringent approach to assessing whether a dataset has the potential for copyright infringement. For example, any datasets scraping from Youtube are classified as having potential for copyright infringement as YouTube hosts a wide variety of content, much of which is protected by copyright. Scraping and distributing this content without proper authorization violates YouTube's terms of service and copyright laws. For annotation-based datasets that provide links to audio recordings, we assess the original sources from which users can obtain the respective audio recordings. As such, we categorize MTG-Jamendo [21] (including its derivative, Song Describer Dataset [105], and Free Music Archive [43] as not infringing upon copyright. This is determined based on the fact that the sources, Jamendo.com and freemusicarchive.org, offer music within the public domain, allowing songs to be freely listened to and downloaded. Conversely, we categorize Million Song Dataset [12] and MagnaTagATune [90] as having potential for copyright infringement as their audio sources, 7digital.com and magnatune.com, necessitate purchasing licenses for access beyond private listening. So while music on these sites may be free to listen to, they are not necessarily free to download and use.\nMethod of Dataset Creation (Scraped, Created, or Augmented): We take a single-label over a multi-label approach. If any portion of the dataset undergoes scraping, we categorize it as 'scraped'. For instance, if a dataset is partially created through scraping a website and partially created by augmented an existing dataset, we denote it as 'scraped'. If the dataset is a direct subset of another, we label it as 'augmented'. We note online marketplaces as such. For all other datasets, we denote as 'created'.\nWe built a database of meta-data for each of these datasets, available at [redacted for blind review], which contains more granular information such as links to download, original purpose of the dataset, whether it was free to access, whether it was scraped or created, and if applicable, the language or genre of the contents."}, {"title": "2.2.2 Distribution and Usage of Datasets.", "content": "Of the 175 datasets, the vast majority of them were only used in one (n = 99; 57%) or two papers (n = 45; 26%). The full distribution can be found in Figure 2. Only a handful of datasets were used more than 5 times. Speech datasets had the largest skew: most datasets were only used by one paper, while VCTK [168] was used by 14. Speech datasets were also the largest by number of hours (see Appendix 2.2.1) We documented 573,522 hours of speech data (median = 59 hours), the vast majority of which came from VoxPopuli [160], a 400,000 hour dataset consisting of European parliament event recordings, and the Spotify Podcast Dataset [31], 100,000 hours of Spotify Podcasts. Music datasets totaled 74,139 hours, with a similar skew (median of 19 hours) driven by The Million Song Dataset [12] (50,000 hours), Irish Massive ABC Notation Dataset [166] (7,200 hours), and Free Music Archive [43] (5,920 hours). These findings stand in contrast to text and image modalities, where there exist a smaller number of very large, widely used datasets that have significant source overlaps [55, 137, 141, 148], and pose a challenge for auditors, policymakers, or practitioners attempting to assess or shape audio dataset practices.\nWe also calculated the total citations these datasets had received\u00b9 to gauge popularity relative to usage-it is important to note that oftentimes when someone cites a dataset, they are doing so in acknowledgement of the field (e.g., in the related literature section) as opposed to actually using that data for training or evaluation. As seen in Figure 4, both usage and citations are quite fragmented, but actual citations have a heavier focus on a few important datasets. Similar to usage and hours, speech dominated the total citation count receiving 39,511 cumulative citations (median= 202), with LibriSpeech [126] in the lead with 6,136 citations. Music was second with 14,346 cumulative citations (median= 98);"}, {"title": "2.2.3 Language Contents of Datasets.", "content": "When considering the linguistic diversity in speech datasets, the inclusion of underrepresented languages is frequently not prioritized, with many datasets predominantly featuring only one language. Out of the 77 speech datasets we examined, the majority-61 of them-were monolingual, with 50 solely in English, followed by 7 in Mandarin. In contrast, 16 datasets encompassed between 2-30 languages, while only two datasets included more than 50 languages."}, {"title": "2.2.4 Sources of Datasets.", "content": "The two most salient audio data sources were YouTube (n = 25 datasets) and LibriVox (n = 13). Other standouts were freesound.org (n = 6), Spotify (n = 4), and VCTK [168] (n = 3). Other popular sources for audio content included podcasts (n = 6), marketplace websites (n = 4), TED talks (n = 4), TV shows (n = 3), and parliament/public speeches (n = 3). We found that LibriVox and its derivatives were referenced in 35 out of the 59 speech papers included in our literature review. LibriSpeech [126], a dataset comprised of public domain audiobooks read by volunteers across various languages, serves as a foundation for 13 derivative datasets, including both direct derivatives like the LibriSpeech dataset[126] and Musan [147], as well as derivatives of derivatives, such as LibriLight [81] and LibriMix [37].\nWe find that 13 datasets stem from LibriVox, categorized into 5 direct derivatives (LibriSpeech [126], LJSpeech [77], Multilingual LibriSpeech [132], Musan [147], CML-TTS [123]) and 6 second-order derivatives, (LibriLight [81], DNS Challenge Dataset [49], LibriTTS [172], HiFi TTS [6], LibriMix [37], RealEdit [129]).\nThe most cited derivative datasets include LibriSpeech (n = 12), LJSpeech (n = 9), LibriTTS [172] (2nd order) (n = 9), and LibriLight with (n = 6). This trend aligns with the overall popularity of these datasets, gauged by citation numbers, with the exception of Musan [147], cited only once in our papers, yet potentially ranking as the 2nd most popular among the 13 derivatives. It's crucial to emphasize that LibriVox predominantly comprises century-old texts, encompassing outdated and potentially problematic language, cultural perspectives, and social norms. This finding corroborates our outcomes discussed later. Consequently, researchers utilizing LibriVox should be mindful of the potential introduction of bias and toxicity inherent in this dataset."}, {"title": "2.2.5 Takeaways from Literature Review.", "content": "The composition of audio datasets used by the research and commercial audio community is vastly different to that of text and vision. It is extremely fragmented-beyond a few notable datasets (e.g., VCTK [159] and AudioSet [59]), researchers are prone to using a few one-off datasets that suit their needs. These datasets also come with their own suite of problems; much of the contents in these datasets are likely stolen from creators without their knowledge, potentially infringing on someone's copyright, or using content at scales beyond original understanding of data providers. There is no standardized way to prepare, create, release, or even discuss audio datasets used in research. Much of the work done in this literature review was scrappy scaffolding to understand the composition of datasets-future datasets should prepared and released in a much more mindful and documented manner which we will suggest below."}, {"title": "3 AUDIT OF AUDIO DATASETS", "content": "In this section we audit seven representative datasets, assessing contents, biases, toxicity, sources, and copyright status to address RQ2, RQ3, and RQ4:\n(1) AudioSet [59], a dataset of 2 million 10-second YouTube clips, comprising a range of music, speech, and sounds;\n(2) Mozilla Common Voice 17 [4], a corpus of crowd-sourced sentences read by volunteers;\n(3) VCTK [159], a dataset of sentences read from the Herald, a Scottish newspaper, and several shorter accent elicitation texts;\n(4) LibriVox [95], a dataset of volunteer recordings of public domain books;\n(5) Free Music Archive [43], a music-specific dataset scraped from an online repository;\n(6) Jamendo [21], another scraped music-specific dataset, and lastly;\n(7) the Lakh MIDI Dataset [136], a subset of the Million Song Dataset [12], which is a currently unavailable dataset of music taken by The Echo Nest, a now defunct music analytics company.\nThese datasets represent some of the largest and most popular datasets in our survey, and they cover music, sound, and speech subdomains.\nTranscription and Textual Analysis. We first obtain high-quality transcripts. While Common Voice, VCTK, LibriVox, and the Lakh MIDI datasets contain transcripts, we found the transcripts included with AudioSet Youtube videos were of lower quality and not well-aligned. Therefore, we use Whisper-large [135] to transcribe over 50,000 randomly selected AudioSet YouTube clips. We use Whisper-large with prompting improvements for music transcription from Zhuo et al. [174] to transcribe Jamendo and Free Music Archive. After converting to text, we use prior text dataset audit techniques and tools. For toxicity analysis, we use the pysentimento library used to detect hate content [16], as well as Surge Al's profanity list [3]. To detect language, we use the langdetect library [143] along with Whisper language predictions on AudioSet, Jamendo, and Free Music Archive clips. To investigate the dataset content in relation to sociodemographic identities, we search for a set of keywords encompassing race, gender, religion, and sexual orientation, using lists established from prior work [45, 69, 100]. Finally, we track common words and calculate pointwise mutual information between common words and identity keywords in order to determine stereotypical associations [138].\nWe recognize the various limitations of these audit libraries and techniques, especially as hate speech models and profanity detection are more likely to wrongly flag data relating to LGBTQ+ or Black voices as toxic content [45, 140]. In addition, language predictions are unreliable and rely on text content [103]. Despite these challenges, as our goal in this work was to present findings from a broad audit of these datasets to identify concerns that may warrant further, more in-depth investigation in future work, we argue that our findings are still useful indicators of broad trends of bias or toxicity."}, {"title": "3.1 Overview of Audio Datasets", "content": "Size. Al in text, image, and video modalities has increasingly come to rely on extremely large datasets, often scrapped from the web, rather than smaller, purpose-made datasets. We assess the size of different audio datasets to understand which datasets and data sources may meet a need for larger audio datasets. In Figures 4 and 5, we present the total size of each dataset in hours of content. Despite the current popularity of each dataset, we find a wide variation in length: the Mozilla Common Voice dataset is nearly two orders of magnitude larger than VCTK dataset, despite both being speech datasets. In particular, we find that several of the largest audio datasets are no longer publicly available, including the Spotify Podcast Dataset and the Million Song Dataset. Of the remaining largest audio datasets, several contain highly specific contents, such as recordings of the proceedings of the European Parliment (VoxPopuli [160]), or traditional Irish music (Irish Massive ABC Notation Dataset [166])."}, {"title": "3.2 Toxicity", "content": "In this section we assess toxicity in selected audio datasets (RQ3). In Figure 10, we show the most common profane words in the datasets. We note that profanity is not the same as toxicity, and in some contexts these words are neither profane or toxic. We find that, while all datasets contain at least some profane words, FMA and LibriVox contain by far the most, with many thousands of occurrences of racist and queerphobic terms. This finding may be due to LibriVox's sourcing from public domain texts, which are at a minimum 70 years old and generally much older, and represent times where where toxic dialogues about marginalized populations were more overt.\nIn Figure 11, we present the number of hours of content in each dataset classified as toxic by the pysentimento toxicity classifier. This classifier considers not just profanity but additional textual cues to assess whether a text is toxic. Examples of and further discussion of sentences classified as toxic are availible in Appendix A.2. While we find that each dataset has only approximately 1% of content flagged as toxic, this still amounts to hundreds of hours of toxic content. While levels of toxicity are low relative to the size of each dataset, large language models have displayed an ability to recall text encountered only a few times during training [26], raising the possibility that large audio models will exhibit similar behavior with even small amounts of profane or toxic content."}, {"title": "3.3 Audio Datasets Licensing", "content": "In Table 3, we summarize licenses of audio datasets (RQ2). Mozilla Common Voice, VCTK, and LibriVox have permissive licenses that allow any use with minimal restrictions. The other four datasets all have licenses that potentially impact the ability of these datasets to be used for training or commercial applications. Lakh is derived from the Million Song Dataset, itself derived from Echo Nest, a music data service, which is subject to the Echo Nest License [115], which prohibits commercial use. Lakh also contains many copyright tags, and we present the most frequent tags in Figure 12. AudioSet is derived from YouTube videos, which are licensed either under Creative Common Licenses [169] with different levels of permissiveness, or the YouTube License [170], where the creator retains all ownership. However, YouTube can use or modify videos only as a feature of YouTube. We present the most common YouTube channel names in Figure 12 in our appendix. Free Music Archive and Jamendo data are covered under several Creative Commons and other licenses, including many that prohibit commercial use and derivatives, and that require artist attribution, derivative work to have the same license, and restrict use to personal use only. In short, our analysis uncovers extensive presence of copyrighted material in these datasets from a broad range of artists."}, {"title": "4 DISCUSSION", "content": "In this paper we found 175 audio datasets that are in recent use. The distribution of their usage is long-tailed, with a small number used frequently, and a majority only used once or twice ("}]}