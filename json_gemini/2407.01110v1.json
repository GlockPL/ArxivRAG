{"title": "SecGenAI: Enhancing Security of Cloud-based Generative AI Applications within Australian Critical Technologies of National Interest", "authors": ["Christoforus Yoga Haryanto", "Emily Lomempow", "Minh Hieu Vu", "Yulia Nurliana", "Trung Duc Nguyen", "Sona Taheri"], "abstract": "The rapid advancement of Generative AI (GenAI) technologies offers transformative opportunities within Australia's critical technologies of national interest while introducing unique security challenges. This paper presents SecGenAI, a comprehensive security framework for cloud-based GenAI applications, with a focus on Retrieval-Augmented Generation (RAG) systems. SecGenAI addresses functional, infrastructure, and governance requirements, integrating end-to-end security analysis to generate specifications emphasizing data privacy, secure deployment, and shared responsibility models. Aligned with Australian Privacy Principles, AI Ethics Principles, and guidelines from the Australian Cyber Security Centre and Digital Transformation Agency, SecGenAI mitigates threats such as data leakage, adversarial attacks, and model inversion. The framework's novel approach combines advanced machine learning techniques with robust security measures, ensuring compliance with Australian regulations while enhancing the reliability and trustworthiness of GenAI systems. This research contributes to the field of intelligent systems by providing actionable strategies for secure GenAI implementation in industry, fostering innovation in AI applications, and safeguarding national interests.", "sections": [{"title": "I. INTRODUCTION", "content": "Generative AI (GenAI) technologies offer transformative opportunities for Australia's critical national technologies while introducing unique security challenges [1]. This paper presents SecGenAI, a security framework for cloud-based GenAI applications, focusing on Retrieval-Augmented Generation (RAG) systems. SecGenAI addresses functional, infrastructure, and governance requirements, integrating end-to-end security analysis to generate specifications emphasizing data privacy, secure deployment, and shared responsibility models.\nA. Background on Generative AI\nGenAI leverages deep learning on extensive datasets to generate new content [1]. In Australia's Critical Technologies list, AI is recognized as pivotal for innovation [2], [3], [4], [5], [6], but brings security challenges [7], [8], [9], [10], [11], [12], [13], [14]. GenAI systems employ deep learning architectures [15], [16], [17], [18], [19], characterized by high-fidelity outputs, comprehensive data representations, adaptability, and autonomous decision-making.\nB. Importance in the Australian Context\nAustralian Al guidelines emphasize secure, responsible AI deployment [2], [3], [4], [8]. Public GenAI chatbots face stringent requirements for personal and confidential data [8]. This paper proposes a secure RAG system within the SecGenAI framework to mitigate security risks [20], [21], [22], prioritizing cybersecurity and adhering to principles of confidentiality, integrity, and availability.\nC. The Objective of SecGenAI Framework\nSecGenAI aims to develop comprehensive security specifications for cloud-based GenAI applications, focusing on RAG systems, addressing functional, infrastructure, and governance requirements in the context of Australian Critical Technologies [2], [3], [4], [5], [6], [8], [20], [23], [24], [25].\n1) Problem Statements: This paper addresses five key questions regarding GenAI security, CIA requirements, RAG implementation options, Australian context constraints, and alignment with AI Ethics and Privacy Principles.\n2) Out-of-Scope: The study excludes public data-reliant GenAI applications, endpoint implementations, highly specialized use cases, non-security technical requirements, and non-AWS cloud platforms.\nD. Definitions\nKey terms defined: 1) Functional: System operations and processes. 2) Infrastructure: Hardware, software, network, and infrastructural components. 3) Governance: Policies, procedures, and processes overseeing system operations.\nE. Report Structure\nThis report is structured as follows: 1) Understanding GenAI Security. 2) Critical Analysis. 3) SecGenAI Framework Requirements Specifications. 4) Discussions and Recommendations. This structure ensures a thorough exploration of GenAI security challenges and our proposed solutions, building on the work of Lewis et al. [20], Zeng et al. [21], and Zou et al. [22]."}, {"title": "II. UNDERSTANDING GENAI SECURITY", "content": "This section covers key concepts, the current state of GenAI security, and RAG's potential to enhance security, highlighting unique challenges like jailbreaking attacks and data leakage.\nA. Foundational Concepts in Generative AI Security\nGenAI uses massive datasets to generate outputs from user prompts [1]. RAG integrates information retrieval to enhance contextual relevance [20]. GenAI often uses GANs [15], [16] and Transformer models [17]. Foundation Models (FMs) serve as a basis for specialized applications [26]. Security in these systems focuses on protecting data from unauthorized access, disclosure, and disruption [27], emphasizing confidentiality, integrity, and availability [28], [29].\nIn Australia, Critical Technologies of National Interest impact national interests, defense, economy, and social cohesion [4], [5], [6]. AI development is guided by Australian Privacy Principles [30], AI Ethics Principles, and AI Ethics Framework [2], [3], [8].\nAl's evolving nature introduces new security challenges [24], including dual-use potential [23]. Specific threats include jailbreaking attacks [14], data leakage [9], adversarial attacks [15], [16], and model poisoning [14]. Countermeasures include homomorphic encryption [31], Zero Trust Architecture [32], data masking [33], and differential privacy techniques [34], [35]. Additional strategies involve continuous authentication [36] and Attribute-Based Access Control (ABAC) [37].\nCloud environments add complexities and opportunities for enhanced security and scalability [38]. Major providers offer secure Al deployment solutions, implementing the Shared Responsibility Model [39], [40], [41].\nB. The Current State of GenAI Security\nTo understand GenAI security, we must compare it with traditional security [14], summarized below:"}, {"title": "III. CRITICAL ANALYSIS", "content": "This chapter examines the security aspects of GenAI applications, focusing on RAG systems in the context of Australian Critical Technologies of National Interest. Our analysis reveals eight key security challenges: 1) Vulnerability to Novel Attacks: RAG models are vulnerable to embedding inversion, attribute inference, and membership inference attacks [7], jailbreaking attacks [9], [49], and prompt injection attacks [22], [49]. 2) Expanded Attack Surface: Massive untrusted datasets increase data poisoning risks [22]. 3) Deep Integration Risks: Unmediated integration with powerful systems creates attractive targets [19], while traditional access control and isolation are challenging to apply. 4) Data Leakage: Complex models may inadvertently leak sensitive data [19], [42]. 5) Malicious Use: Strong generative capabilities can be abused to create harmful content at scale [14], [19]. 6) Challenges in Applying Traditional Security Measures: Monolithic architecture complicates the application of standard security practices [19]. 7) Incomplete Solutions for Privacy and Bias: RAG reduces but does not eliminate these issues [42]. 8) Persistent Hallucinations: RAG may still generate problematic content absent from source documents [42], [50].\nThese challenges have four significant implications for Australian Critical Technologies of National Interest: 1) APP Compliance: Organizations must actively protect personal information in RAG systems, especially to fulfil APP 11 [30]. Emphasis is needed on preventing private data leakage from both knowledge bases and training data [21], [30], [49], [51]. 2) Framework Alignment: Strong coordination between functional, infrastructure, and governance aspects is crucial [2], [3], [7], [8], [16], [22], [25], [42], [52], [53]. 3) Dual Use and Misuse Potential: RAG models could generate harmful content, necessitating oversight [4], [5], [6], [11], [12], [23]. 4) Ethical Considerations: Bias, fairness, transparency, and accountability must be addressed at model and system levels [2], [5], [6], [26], [44], [47].\nThis analysis forms of the SecGenAI framework, which addresses these challenges comprehensively.\nA. Functional Security Analysis\nOur functional security analysis is based on the seminal work by Lewis et al. [20] titled \u201cRetrieval-Augmented Generation for Knowledge-Intensive NLP Tasks", "follows": 1, "Input": "Susceptible to injection attacks if not properly handled [14]. 2) Query Encoder: Risks include unauthorized access, data poisoning, or tampering [22], [49]. 3) Document Retrieval: Can expose sensitive information without robust encryption and access controls [19]. 4) Maximum Inner Product Search: Sensitive vectors could lead to data inference attacks if not securely managed [19]. 5) Seq2Seq Model: Vulnerable to model inversion attacks and manipulation [7]. Generative parts are also vulnerable to hallucinations [42], [50]. 6) Marginalisation Process: Data aggregation can expose patterns or sensitive information if not handled securely [7], [21]. Further, the above components and concerns are mapped to the root cause, listed in the table:"}, {"title": "B. Infrastructure Security Analysis", "content": "This section explores the infrastructure security of RAG systems based on Intel's fast RAG infrastructure model [56] consisting of: 1) Private Knowledge Base: Stores raw data [56]. 2) Vector Database: Repository for processed data [56]. 3) Input/Output Guard Railing: Manages prompts and returns answers, detecting harmful prompts and preventing prompt injections. [56]. 4) Embedding Model and Retrieval Vector Search: Transform raw data into refined vectors stored in the vector database [56].\nThe primary goal of designing an IT infrastructure for GenAI and RAG is to satisfy the CIA triad: 1) Confidentiality: Keep data private and accessible only by authorized entities. Components with sensitive data should be in separate network environments to prevent unauthorized access [29]. 2) Integrity: Ensure data remains accurate and unaltered during processing and storage. Use encryption techniques like AES for data at rest and TLS for data in transit [27]. 3) Availability: Ensure data and systems are available to authorized users when needed. Implement redundancy and failover mechanisms to maintain service continuity [63]. To achieve these goals, components should be on different servers with minimal access rights to others.\nTo ensure data confidentiality: 1) At-Rest Data Encryption: Encrypt the vector database and private knowledge base using AES [27]. 2) In-Flight Data Encryption: Use RSA or SSL/TLS with HMAC for data movement to ensure a secure channel [64].\nTo ensure data integrity: 1) Hashing and Digital Signature: Verify data integrity during transit and storage using hashing techniques and digital signatures [65]. 2) Appropriate Placement of Integrity Measure: Apply digital signatures to data exchanges between systems and users.\nTo ensure availability [63]: 1) Denial-of-Service Attack Mitigation: Use firewalls to detect and drop malicious connections. 2) Disaster Recovery Plans: Establish protocols to restore services quickly after an attack. 3) Automated Recovery: Continuous monitoring with logs for analysis and automated recovery of overloaded or shutdown servers.\nWith a cloud system design, achieving the CIA triad is more efficient. Amazon Web Services (AWS) offers comprehensive solutions, while other providers like Azure or Google Cloud Platform offer equivalent functionality. This paper uses AWS as an example.\nInfrastructure Methods for RAG Security consist of: 1) Sandbox GenAI Infrastructure: Divide infrastructures into clusters across availability zones. Use access control to create a private network connecting servers. 2) Database Infrastructure Connection: Control access for GenAI and RAG components connecting to databases and enable encryptions. 3) Network Security Settings: Separate public and private network zones. 4) External Attack Prevention: Detect and filter network attacks using suitable services and automate accordingly. 5) Disaster Recovery and Incident Response: Implement data and instance backup and recovery and automate accordingly. Detailed infrastructure requirement specifications will be outlined in Chapter IV.B.\nC. Governance Framework Analysis\n1) ISO 38500 Evaluate-Direct-Monitor (EDM): We employ this approach to ensure reliability and bias-free sources [66] even if the sources are not academic in nature.\na) Evaluate: Assess current governance frameworks, identify gaps, and analyze their applicability to GenAI.\nb) Direct: Provide directives on implementing governance frameworks effectively.\nc) Monitor: Assess current governance frameworks, identify gaps, and analyze their applicability to GenAI.\n2) Evaluating the Australian Guidelines\nThe strengths of current Australian guidelines include 1) A Comprehensive Risk Management Framework: ACSC's recommendations emphasize systematic threat assessment and mitigation [25], 2) Holistic Ethical Integration: Australia's AI Ethics Principles incorporate security with other ethical dimensions [2], 3) Public Sector Focus: Clear directives for data privacy and protection [8], and 4) Shared Responsibility Model: Clear segregation of responsibilities between vendors and users.\nWhereas, its limitations include: 1) Lack of Technical Specificity: ACSC guidance often lacks detailed technical specifications [25], 2) Rapidly Evolving Threat Landscape: AI threats evolve quickly, necessitating frequent updates, 3) Broad and Inclusive Principles: Can be difficult to translate into concrete security measures [2]. 4) Interim Nature: Lacks a long-term strategy and doesn't fully address risks associated with generative AI [8].\n3) Evaluating Casey-Alvarenga's SRM\nThe Shared Responsibility Model (SRM) divides responsibilities between Cloud Service Providers (CSPs) and customers with some shared responsibilities [67], [68]. Noting some source reliability and bias: 1) Fundamental of SRM: Provide foundational knowledge but may lack practical insights [67], [68]. 2) Cloud Service Provider SRM: Offer detailed models but may emphasize strengths over weaknesses [39], [40], [41]. 3) Third-Party Expert and Consulting: Provide balanced views but may have their own biases [69], [70], [71], [72], [73]. Shared responsibilities include security configurations, compliance, encryption, and IAM collaboration [69]."}, {"title": "IV. SECGENAI FRAMEWORK REQUIREMENTS SPECIFICATIONS", "content": "These specifications build on top of the critical analysis and propose the minimum requirements for securely implementing GenAI applications within Australian Critical Technologies of National Interest, assuming all basic cloud-based application requirements are already met.\nA. Functional Requirements Specifications\nBuilding on Chapter III's analysis of GenAI security challenges, this section outlines specific functional requirements to mitigate these risks. The requirements are categorized under Identity and Access Management, Data Confidentiality and Integrity, and Model Security."}, {"title": "V. DISCUSSIONS AND RECOMMENDATIONS", "content": "This discussion evaluates how the SecGenAI framework mitigates critical security challenges in GenAI systems through functional, infrastructure, and governance measures.\nA. SecGenAI Framework as the End-to-End Solution\nThe SecGenAI Framework addresses security gaps in cloud-based GenAI, particularly RAG technology, by delivering: 1) Functional Requirements: Ensuring identity and access management, data integrity through homomorphic encryption, data masking, and model security safeguards. 2) Infrastructure Requirements: Securing cloud infrastructure for RAG, isolating components, securing connections, preventing attacks, and ensuring business continuity with AWS services. 3) Governance Requirements: Aligning GenAI with ethical principles and regulatory standards, clearly defining roles and obligations of CSPs and customers.\nB. SecGenAI Framework Implementation Spectrum\nImplementation can vary based on the organization's risk profile: 1) Full Model: \"Ideal security\" for large enterprises and high-risk organizations. 2) SaaS Model: \"Multi-tenant\" for small-to-medium enterprises. 3) Hybrid Model: Combines elements of both, balancing security, cost, and efficiency. Each approach has trade-offs in terms of security, cost, and complexity.\nC. Future Works\nWhile this report focuses on GenAI security, future work should address cost-effective multi-tenant solutions for small businesses and the development of a prioritization matrix for hybrid solutions.\nD. Recommendations\nBased on the analysis, we recommend the following '4A' approach::\n1) Adopt: Australian organisations should adopt the SecGenAI Framework as a comprehensive guide for securing cloud-based GenAI systems.\n2) Adapt: Choose between \"ideal security design,\" \"multitenant design,\" or a hybrid approach based on specific needs and constraints.\n3) Adept: Build proficiency in secure GenAI implementation through continuous monitoring, regular audits, and updates.\n4) Advance: Encourage collaboration and information sharing among organisations, industry bodies, and government agencies to refine and adapt the SecGenAI framework over time."}, {"title": "VI. CONCLUSION", "content": "In conclusion, the SecGenAI framework provides comprehensive and actionable recommendations for enhancing the security of cloud-based GenAI systems, particularly those using RAG technology. By adopting this framework and following the evidence-based recommendations, organizations can effectively mitigate risks, ensure compliance, and realize the transformative potential of GenAI securely and responsibly. This paper serves as a valuable resource not just for implementation, but also for guiding policymakers, and engaging stakeholders in the development of secure GenAI systems. However, it is important to recognize that GenAI security is an ongoing process requiring continuous vigilance, adaptation, and collaboration. Therefore, further research and development will be essential to refine and extend the SecGenAI framework as GenAI and the threat landscape continue to evolve."}, {"title": "VII. ACKNOWLEDGEMENTS", "content": "This work was part of a class project report made possible through RMIT University's Industrial Awareness Project in collaboration with our industry partner. We would like to thank Dr. Amy Corman and Dr. Mahshid Sadeghpour for their guidance and support throughout this project."}]}