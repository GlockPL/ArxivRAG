{"title": "DBHP: Trajectory Imputation in Multi-Agent Sports Using Derivative-Based Hybrid Prediction", "authors": ["Hanjun Choi", "Hyunsung Kim", "Minho Lee", "Chang-Jo Kim", "Jinsung Yoon", "Sang-Ki Ko"], "abstract": "Many spatiotemporal domains handle multi-agent trajectory data, but in real-world scenarios, collected trajectory data are often partially missing due to various reasons. While existing approaches demonstrate good performance in trajectory imputation, they face challenges in capturing the complex dynamics and interactions between agents due to a lack of physical constraints that govern realistic trajectories, leading to suboptimal results. To address this issue, the paper proposes a Derivative-Based Hybrid Prediction (DBHP) framework that can effectively impute multiple agents' missing trajectories. First, a neural network equipped with Set Transformers produces a naive prediction of missing trajectories while satisfying the permutation-equivariance in terms of the order of input agents. Then, the framework makes alternative predictions leveraging velocity and acceleration information and combines all the predictions with properly determined weights to provide final imputed trajectories. In this way, our proposed framework not only accurately predicts position, velocity, and acceleration values but also enforces the physical relationship between them, eventually improving both the accuracy and naturalness of the predicted trajectories. Accordingly, the experiment results about imputing player trajectories in team sports show that our framework significantly outperforms existing imputation baselines.", "sections": [{"title": "1 Introduction", "content": "Various spatiotemporal domains such as transportation, robotics, surveillance, and sports handle multi-agent trajectory data. In particular, with the recent advancement of computer vision and sensing technologies, a growing number of groups are collecting these types of data for various use cases. However, acquiring a complete set of trajectory data is still very challenging as there are many practical possibilities of missing partial trajectories. Wearable devices such as GPS trackers or motion sensors may experience temporary signal loss or malfunction, obstructing the collection of complete trajectory data. Similarly, computer vision systems often fail to detect agents in occluded regions or in low-lighting conditions. In particular, some domains pose unique challenges for trajectory data collection, such as sports games with broadcasting camera view where players can disappear from the view depending on their relative positions to the ball.\nThe prevalence of missing values in multi-agent trajectory data calls for developing effective imputation techniques. One of the simple yet powerful solutions is to employ naive rule-based imputation methods such as forward/backward fill or linear interpolation. However, they cannot capture the complex dynamics and interactions between agents, resulting in suboptimal performance. On this account, many studies have proposed deep learning-based imputation methods that consider the spatiotemporal dependencies of the multi-agent movements. Though they aimed to improve accuracy by modeling such dependencies, most of them failed to significantly outperform the aforementioned naive baselines.\nTo address this issue, this paper proposes a framework named Derivative-Based Hybrid Prediction (DBHP) that imputes missing values in multi-agent trajectory data with high accuracy by enforcing the physical restrictions that realistic trajectories should satisfy. First, a deep neural network equipped with Set Transformers (Lee et al. 2019) and agent-wise bidirectional LSTMs (Hochreiter and Schmidhuber 1997) produces a series of predictions for missing values. In addition to this direct prediction of players' positions, the framework makes alternative predictions named Derivative-Accumulating Predictions (DAPs) by accumulating the predicted velocity and acceleration on the nearest observed positions for each missing segment in either direction. Then, the framework compromises by properly determining weights between the three types of predictions, i.e., neural network output, forward and backward DAPs, to make the best final prediction.\nIn the experiments, we evaluated the performance of our proposed framework on the three benchmark datasets collected from popular team sports: soccer, basketball, and American football. The experimental results demonstrate that our framework significantly outperforms existing baselines for multi-agent trajectory imputation in terms of accuracy. In particular, leveraging the derivative information was found to be effective in improving the physical plausibility of the imputed trajectories. Lastly, we present the additional possibility of utilizing our framework for other practical tasks, such as estimating match statistics with incomplete tracking data and forecasting future trajectories of players in sports.\nIn summary, the main contributions are as follows:\n1. We introduce a multi-agent trajectory prediction model employing Set Transformers to ensure the permutation-equivariance of the agents. This architecture itself imputes missing values more accurately than previous state-of-the-art imputation models.\n2. We propose the DAP mechanism that assembles smoother predictions than the outputs of the above neural network by leveraging the physical relationships between the position, velocity, and acceleration.\n3. We propose the DBHP framework combining the above predictions by a weighted sum, where the weights are learned to maximize their relative advantages.\n4. We demonstrate that the proposed framework has the capability to generalize across various sports games and is applicable to practical missing scenarios."}, {"title": "2 Related Work", "content": "Though many studies have proposed methods for imputing time series data, not all of them have addressed the specific challenges of multi-agent trajectories with complex interactions and dynamics. To name a few, TimesNet (Wu et al. 2023) and TIDER (Liu et al. 2023a) were designed to impute multivariate time series by modeling their temporal patterns such as multi-periodicity, seasonality, or local biases, but they are inappropriate for multi-agent spatiotemporal domains such as team sports since the behaviors of agents are highly uncertain without repeating patterns. SPIN (Marisca, Cini, and Alippi 2022) regarded the interaction between data acquired from multiple sensors, but it assumed that the sensors' locations are fixed and thus is not applicable to our case of moving agents. Other studies have also addressed multi-agent trajectory imputation (Liu et al. 2023b; Choi and Lee 2023; Fang et al. 2024); however, they are limited to scenarios where agents' positions remain fixed, making them unsuitable for our research involving moving agents.\nOn the other hand, recent studies designed to impute multi-agent trajectories focus on modeling agents' complex interactions and dynamics. BRITS (Cao et al. 2018) proposed an RNN-based multi-agent imputation model that incorporates the observed features at missing time steps and past information, but it is prone to compounding errors caused by an incorrect prediction at an early stage. To address this issue, non-autoregressive imputation frameworks such as NAOMI (Liu et al. 2019) and NRTSI (Shan, Li, and Oliva 2023) were proposed, but they can only handle the case when all agents have the same missing period. Omidshafiei et al. Omidshafiei et al. (2022) recently proposed Graph Imputer that is applicable to practical scenarios such as missing player trajectories out of the camera view in team sports. Note that many studies (Yeh et al. 2019; Zhan et al. 2019; Kamra et al. 2020; Li et al. 2020; Sun et al. 2022b,a) have proposed frameworks for multi-agent trajectory prediction, but they are designed to forecast future trajectories in a unidirectional manner and cannot leverage the information of the future observations."}, {"title": "3 Proposed Framework", "content": "Our study about multi-agent trajectory imputation assumes a scenario where the missing time intervals of each agent could differ from those of others. To elaborate, let the trajectories of K players be $X_{1:T} = \\{x^k_{1:T}\\}_{k=1}^K$, where each agent k's input features $x^k_t$ at each time t consist of their (x, y) position $p^k_t = (p^k_{t,x}, p^k_{t,y})$, velocity $v^k_t = (v^k_{t,x}, v^k_{t,y})$, and acceleration $a^k_t = (a^k_{t,x}, a^k_{t,y})$. Here, the velocity and acceleration are calculated from the position values by the following approximations:\n$v^k_t \\approx \\frac{p^k_t - p^k_{t-1}}{\\Delta t}$,\n$a^k_t \\approx \\frac{v^k_{t+1} - v^k_t}{\\Delta t}$     (1)\nwhere $\\Delta t$ is the difference between adjacent time steps.\nIn our scenario, each $x^k_{1:T}$ has missing parts identified by a masking sequence $m^k_{1:T} = (m^k_1, ..., m^k_T)$ where $m^k_t = 1$ if $x^k_t$ is observed and 0 if it is missing. Note that the model may improperly exploit the information at the endpoints of masked segments in this setting since Eq. (1) uses the positional information at adjacent time steps when approximating the derivatives. To prevent this, we also mask the two frames adjacent to each missing segment to simulate a real situation where the model could not know the velocity and acceleration at those points.\nGiven this setting, an imputation model aims to take the incomplete data $\\{m^k_{1:T}x^k_{1:T}\\}_{k=1}^K$ as input and produce imputed trajectories $\\{\\hat{x}^k_{1:T}\\}_{k=1}^K$. Combining these imputed trajectories with the observed fragments results in complete trajectories $\\{\\overline{x}^k_{1:T}\\}_{k=1}^K$, i.e.,\n$\\overline{x}^k_t = m^k_t x^k_t + (1 - m^k_t) \\hat{x}^k_t,$     (2)\nfor k = 1,..., K.\nThe novelty of the proposed framework lies in the mechanism of enhancing the model performance by integrating positions directly predicted by a neural network and those resulting from accumulating predicted derivatives (i.e., velocity and acceleration values). See Figure 1 illustrating the overall architecture of our framework.\nNeural Network-Based Direct Prediction This section describes the neural network architecture producing naive predictions of imputed trajectories. It takes partially observed trajectories $\\{m^k_{1:T}x^k_{1:T}\\}_{k=1}^K$ as an input and predicts each agent k's full trajectory\n$\\hat{X}^{k,d}_{1:T} = \\{(\\hat{p}^{k,d}_{t,x}, \\hat{p}^{k,d}_{t,y}, \\hat{v}^{k,d}_{t,x}, \\hat{v}^{k,d}_{t,y}, \\hat{a}^{k,d}_{t,x}, \\hat{a}^{k,d}_{t,y})\\}^{T}_{t=1},$     (3)\nwhere the superscript d stands for \u201cdirect prediction\u201d.\nTo build an effective neural architecture for modeling multiple trajectories, we should enforce a strong inductive bias called the permutation-equivariance. Since there is no semantic order of agents in our multi-agent systems, a permutation in the order of input agents should not affect the output value for each agent and only change the output order by the same permutation. We utilize the encoder module of the Set Transformer (Lee et al. 2019) to ensure the permutation-equivariance of outputs. A Set Transformer consists of an encoder that produces permutation-equivariant representations of multi-agent inputs and a decoder that produces a single permutation-invariant output shared for all agents. It is natural to only employ its encoder part for our permutation-equivariant task, but to improve the model performance, we also attach the permutation-invariant embedding that results from a full Set Transformer architecture, including the encoder and decoder parts.\nTo be specific, we obtain permutation-equivariant agent-wise embeddings $\\{z^k_t\\}_{k=1}^K$ from the encoder of a Set Transformer and a single permutation-invariant embedding $z_t$ from a full Set Transformer for each time step t:\n$(z^1_t, ..., z^K_t) = \\text{ST-Encoder}(m^1_tx^1_t, ..., m^K_tx^K_t)$,\n$z_t = \\text{SetTransformer}(m^1_tx^1_t, ..., x^K_t)$.     (4)\nFrame-by-frame application of the Set Transformer to the input features yields embeddings $\\{(z^1_t, ..., z^K_t, z_t)\\}_{t=1}^T$. Then, bidirectional LSTMs (Hochreiter and Schmidhuber 1997) sharing weights across agents extract the sequential information from the concatenated sequence $\\{(x^k_t, z^k_t, z_t)\\}_{t=1}^T$ per agent k by updating joint hidden states:\n$h^{k,f}_t = \\text{LSTM}(x^k_t, z^k_t, z_t; h^{k,f}_{t-1}),$     (5)\n$h^{k,b}_t = \\text{LSTM}(x^k_t, z^k_t, z_t; h^{k,b}_{t+1})$.     (6)\nLastly, a fully-connected layer decodes the joint hidden state to output a prediction $\\hat{x}^{k,d}_t$ at each time t:\n$\\hat{x}^{k,d}_t = FC(h^{k,f}_t, h^{k,b}_t)$.     (7)\nWe call the prediction obtained in this phase the direct prediction (DP) and combine it with the other predictions from later phases to get more accurate final prediction.\nDerivative-Accumulating Prediction We start from the following relationships between the position, velocity, and acceleration derived from Eq. (1):\n$v^k_{t+1} \\approx v^k_t + a^k_t \\Delta t$,\n$p^k_{t+1} \\approx p^k_t + v^k_{t+1} \\Delta t.$     (8)\nTaking this into account, we compute Derivative-Accumulating Prediction (DAP) with improved stability by enforcing the physical relationships in Eq. (8), as an alternative to the direct imputation result. To elaborate, let $(t_s, t_e)$ be an arbitrary missing segment for a player k. Then, we recursively predict positions inside the segment by accumulating velocities and accelerations in either direction. Along the forward direction, we start from the observed position $p^k_{t_s}$ and recursively add predicted velocities and accelerations to obtain predictions $p^{k,f}_t$ based on Eq. (8):\n$\\hat{p}^{k,f}_{t_s} = p^k_{t_s}, $     (9)\n$\\hat{v}^{k,f}_t \\approx \\hat{v}^{k,d}_{t-1}$     (10)\n$\\hat{p}^{k,f}_t \\approx \\hat{p}^{k,f}_{t-1} + (\\hat{v}^{k,d}_{t-1} + \\hat{a}^{k,d}_{t-1} \\Delta t) \\Delta t,$     (11)\n$t_s < t < t_e.$\nLikewise, we start from the observed position $p^k_{t_e}$ at the opposite endpoint and recursively subtract the predicted derivatives to obtain backward predictions $\\hat{p}^{k,b}_t$.\nAdopting DAPs instead of direct predictions carries several advantages. First, since the loss between these DAPs and the ground truth more penalizes unstable predictions of the velocity and acceleration, minimizing it improves the smoothness of the predicted derivatives. Considering that existing position-oriented imputation models suffer from fluctuating trajectories, these smooth derivatives have a clear advantage in that they result in more plausible positional predictions. Furthermore, enforcing the relationships between the physical quantities imposes an additional inductive bias to the model, which makes it more data-efficient.\nDynamic Hybrid Prediction Though DAP has a clear advantage over direct prediction, it also has a potential drawback called the error compounding problem. Namely, since we only rely on the observation at an endpoint as an anchor and the predicted derivatives that are accumulated on the anchor, the prediction error tends to grow as the number of iterations in Eq. (11) or its backward counterpart increases. On the contrary, the direct predictions resulting from Eq. (7) are robust against this problem since they do not strictly depend on predictions at other time steps.\nTo address this trade-off, we take a hybrid approach named Derivative-Based Hybrid Prediction (DBHP) to leverage the advantages of DP and DAP. That is, instead of solely relying on one of the aforementioned predictions $\\{\\hat{p}^{k,d}_{1:T}, \\hat{p}^{k,f}_{1:T}, \\hat{p}^{k,b}_{1:T}\\}$, we compromise between them by computing a weighted sum."}, {"title": "4 Main Experiments", "content": "One of the most challenging domains for multi-agent trajectory prediction is team sports since the movements and interactions of players are highly dynamic and complex. Thus, we conduct experiments on team sports data to evaluate the imputation performance of our proposed framework on this challenging domain."}, {"title": "4.1 Experimental Settings", "content": "Data preparation In the experiments, we independently train models and evaluate the performance on three public datasets collected from three popular team sports: soccer, basketball, and American football. The soccer dataset is provided by Metrica Sports and contains tracking data of 22 players collected from 3 matches. For basketball, we use 100 matches among 631 matches of SportsVU's NBA dataset, where each match contains trajectories of 10 players. The American football dataset is from the Kaggle competition with NFL's Next Gen Stats data, where we adopt the preprocessed version of NRTSI (Shan, Li, and Oliva 2023) containing 9,543 5-second time series. The original sampling rates of the three datasets are 25Hz, 25Hz, and 10Hz, respectively, but we downsampled them to a common rate of 10Hz for consistency. For soccer and basketball, 200 frames were used as input data with 22 players and 10 players, respectively, while for American football, 50 frames and 6 offensive players were used as input data.\nMissing scenarios To evaluate the model performance on various missing patterns, we consider the following three scenarios that may occur during data acquisition processes:\n\u2022 Uniform missing scenario: All players have missing values at the same time interval. Note that among the baselines, NAOMI (Liu et al. 2019) and NRTSI (Shan, Li, and Oliva 2023) are designed to only handle this scenario and not capable of the following other scenarios.\n\u2022 Agent-wise missing scenario: Individual players have missing values at different time intervals.\n\u2022 Broadcasting camera scenario: A virtual camera follows the ball and only captures the players inside the camera view, resulting in missing values for the remaining players. Following Graph Imputer (Omidshafiei et al. 2022), we conduct an experiment only on the soccer dataset for this scenario."}, {"title": "4.2 Experimental Results", "content": "Table 1 exhibits the trajectory imputation performance of the aforementioned models on different datasets and missing scenarios. Experimental results show that our proposed framework significantly outperforms other baselines. Since the lack of permutation equivalence is considered as one of the main limitations of baselines, we attach the Set Transformer encoder to NAOMI which is a competitive baseline model and report the result with the name NAOMI-ST. The comparison between NAOMI and NAOMI-ST shows that the permutation equivariance is indeed an important cause. We also replace Bi-LSTM from DBHP which is employed for sequential modeling by a transformer module and report the result with the name DBHP-TF. The comparison between DBHP-TF and DBHP validates our choice of Bi-LSTM for sequential modeling as DBHP performs slightly better than DBHP-TF.\nAnother observed advantage of our proposed framework is data efficiency. For the soccer dataset with only two matches of training data, other neural network baselines are even worse than the linear interpolation. Given that baselines such as NAOMI and NRTSI outperform the linear interpolation on both basketball and American football datasets with sufficient training data, the main reason for their poor performance on the soccer dataset appears to be the shortage of training data. On the other hand, our framework exhibits way better performance than all baselines including the linear interpolation on the soccer dataset as well as the basketball and American football datasets. Considering the difficulty in acquiring complete trajectory data in many domains, we believe that our framework can be efficiently applied to various domains even with a small amount of training data."}, {"title": "4.3 Ablation Studies", "content": "In addition to the main experiments, we have carried out ablation studies to explore the impacts of each component introduced in DBHP framework. We also conduct comparative analyses on different window sizes and missing rates for our proposed model. For simplicity, both experiments were conducted only on the soccer dataset.\nImpact of the derivative information as input To empirically justify the use of derivative features in DP and DAP, we compared the performance of our dynamic DBHP on the broadcasting camera scenario with those trained without accelerations (i.e., using positions and velocities) and even velocities (i.e., only using positions) of observed trajectories. Furthermore, we made DP only predict positions and velocities, and DAP estimate positions only based on predicted velocities. We trained the models with these \"velocity-only\" DAP and compared the performance with their counterparts that exploited predicted acceleration values."}, {"title": "5 Applications", "content": "In this section, we explore the possibility of leveraging our framework for practical tasks. As examples, we present two promising applications in soccer domain: pitch control analysis (Spearman et al. 2017) and approximating match statistics from incomplete tracking data.\nPitch control analysis We show that our framework can be used to perform pitch control (Spearman et al. 2017) analysis, which is a well-established technique in soccer analytics, in partially-observable settings. Pitch control can be used to quantify how soccer players control regions on the pitch at each time step by relying on physics-based modeling. In Figure 5, the pitch image corresponding to each model represents the difference between pitch control results where one from the ground-truth trajectory and the other from the partial observations where the missing trajectory is imputed by the model. If a specific area of the pitch is shaded with a darker color, it indicates a greater difference. Figure 5 shows that DBHP achieves the most similar result compared to other baselines.\nApproximation of match statistics In this section, we explore how accurately our method can estimate statistics for the entire match when imputed trajectories are merged with known observations. To elaborate, we compare the total distance covered by a player and the number of sprints estimated by each method, as they are widely used as indicators for players' physical performance or fitness. We first compute velocities from the observed/imputed positions based on Eq. 1 and obtain speed values by calculating the norms of these velocity vectors. Then, we compute the distance covered by each player by summing up the speed values multiplied by $\\Delta t$ = 0.1s. For the latter, if a player runs faster than 6 m s\u207b\u00b9 for consecutive frames, we detect his/her movement during the frames as a sprint. Then, we count the number of sprints the player made during the given period."}, {"title": "6 Conclusions", "content": "This paper proposes DBHP, a trajectory imputation framework that imputes missing values of multiple agents with improved quality. It consists of a neural network that makes an initial prediction in a permutation-equivariant manner and an additional scheme for incorporating derivatives to refine the imputation results. The experiments conducted on the sports datasets with various missing scenarios demonstrate the effectiveness of our approach in imputing multi-agent trajectories with not only higher accuracy but also improved reality. Though our study focused on the performance of our framework on team sports data, we believe it can also be applied to other spatiotemporal domains. Future work will further investigate its application to practical tasks in team sports and other domains that require complete trajectories of multiple agents."}, {"title": "A Appendix / Supplemental Material", "content": null}, {"title": "A.1 Dataset Statistics", "content": null}, {"title": "A.2 Hybrid with static or Dynamic Weights", "content": "In this section, we conduct additional experiments to validate the necessity of dynamic hybrid prediction in the multi-agent trajectory imputation task. Accordingly, we introduce another two different hybrid schemes, DBHP-S and DBHP-S2, which use predefined static weights instead of learnable weights.\nAs defined in the Derivative-Accumulating Prediction in Section 3, let $(t_s, t_e)$ be an arbitrary missing segment for player k. The DBHP-S and DBHP-S2 are based on the assumption that DAPs become less accurate as they correspond to time steps further away from the observed anchors (i.e., $p^k_{t_s}$ or $p^k_{t_e}$). For DBHP-S, we assign large weights to forward DAPs near the left endpoint, to DP in the middle, and to backward DAPs near the right endpoint, respectively. Then, we combine the DP and bidirectional DAPs in either direction by predetermined weights as follows:\n$\\hat{p}^{k,s}_t = \\begin{cases}\n        \\frac{t-t_s}{t_m - t_s}\\hat{p}^{k,d}_t + \\frac{t_m - t}{t_m - t_s}\\hat{p}^{k,f}_t& \\text{if } t_s < t < t_m,\n        \\frac{t_e - t}{t_e - t_m}\\hat{p}^{k,d}_t + \\frac{t - t_m}{t_e - t_m}\\hat{p}^{k,b}_t & \\text{if } t_m < t < t_e.\n    \\end{cases}$     (18)\nwhere $t_m = (t_s + t_e)/2$ is the midpoint of the segment. For DBHP-S2, we assign large weights to forward DAP near the left endpoint and to backward DAP near the right endpoint. For a player k's missing segment $(t_s t_e)$, we combine DAPs in either direction using predetermined weights as follows:\n$\\hat{p}^{k,s2}_t =  \\frac{t_e - t}{t_e - t_s}\\hat{p}^{k,f}_t + \\frac{t - t_s}{t_e - t_s}\\hat{p}^{k,b}_t.$     (19)"}, {"title": "A.3 Impact of loss functions", "content": "We compare the predictions of DP, DAPs, DBHP-S, DBHP-S and DBHP trained with different combinations of loss terms. Table 7 shows that DBHP achieves the best performance when all introduced loss functions are used. To be specific, the model trained with only $\\mathcal{L}_d$ minimizes the MAE (Mean Absolute Error) between the positions predicted by DP and the ground truth, so DAPs based on the predicted derivatives are not trained. On the other hand, while models trained only with $\\mathcal{L}_f$ or $\\mathcal{L}_b$ predict DAPs better than the model trained only with $\\mathcal{L}_d$, the final performance of DBHP is inaccurate as the positions predicted by DP are not trained. Models trained with $\\mathcal{L}_d + \\mathcal{L}_f$ or $\\mathcal{L}_d + \\mathcal{L}_b$ achieve accurate predictions for both DP and DAPs, even though the weights between the three components are not trained. Lastly, the comparison between the model trained only with $\\mathcal{L}_h$ and the proposed model indicates that directly enforcing the predictions of DP and DAPs with auxiliary loss terms such as $\\mathcal{L}_d$, $\\mathcal{L}_f$"}, {"title": "A.4 Adaptation to Trajectory Forecasting", "content": "Forecasting future trajectories of multiple agents is another important task for various applications such as crowd navigation, autonomous driving, and behavior analysis. Especially, in team sports we are dealing with, predicting players' future trajectories can serve as a tool for counterfactual analysis to evaluate players' actual movements compared to the \u201caverage\u201d movements for a given situation.\nThus, we investigate our framework's ability to adapt to the trajectory forecasting task. Since we cannot access the future information in the forecasting task, we deploy unidirectional LSTMs in DP and DBHP instead of the bidirectional ones. Also, we make DBHP obtain final predictions only based on DP and DAP-F, i.e.,\n$\\hat{p}_t = \\lambda^d_t \\hat{p}^d_t + \\lambda^f_t \\hat{p}^f_t.$     (20)\nTo evaluate this DBHP forecaster, we compared its performance with that of some baselines (forward fills and BRITS) which are applicable to the forecasting task. Specifically, for the soccer dataset with window sizes 50, 100, and 200, we made the models observe the first half of the trajectories and predict the remaining half, respectively. For reference, we also measured the performance of the trajectory imputation models trained for the uniform missing scenario with a missing rate of 0.5.\nAccording to Table 8, our framework consistently outperforms other forecasting baselines, but the performance is worse than the imputation task with the same setting. In particular, the DBHP forecaster does not improve that much from DAP-F's performance as its imputation counterpart does. This is because it cannot leverage information from the future with the assistance of DAP-B. On the other hand, it seems that DAP-F forecasts trajectories more accurately than DP, demonstrating the effectiveness of using derivative information for trajectory forecasting.\nOne thing that we want to point out is that predicting players' future trajectories is a stochastic task since there is great uncertainty in the dynamic nature of sports games. This implies that the predicted trajectories can be realistic even if they are very different from true trajectories in terms of position error. On this account, most studies for trajectory forecasting employ architectures based on Variational Autoencoder (VAE) and make the model generate multiple outputs for the same input to encourage diversity. These are the key differences from our trajectory imputation task, which is rather deterministic in that the missing movement is somewhat determined given its start/end points and other players' movements. We leave further fine-tuning our derivative-based framework and comparing its performance with state-of-the-art trajectory forecasters as future work."}]}