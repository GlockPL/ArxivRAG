{"title": "Can LLMs Serve As Time Series Anomaly Detectors?", "authors": ["Manqing Dong", "Hao Huang", "Longbing Cao"], "abstract": "An emerging topic in large language models (LLMs) is their application to time series forecasting, characterizing mainstream and patternable characteristics of time series. A relevant but rarely explored and more challenging question is whether LLMs can detect and explain time series anomalies, a critical task across various real-world applications. In this paper, we investigate the capabilities of LLMs, specifically GPT-4 and LLaMA3, in detecting and explaining anomalies in time series. Our studies reveal that: 1) LLMs cannot be directly used for time series anomaly detection. 2) By designing prompt strategies such as in-context learning and chain-of-thought prompting, GPT-4 can detect time series anomalies with results competitive to baseline methods. 3) We propose a synthesized dataset to automatically generate time series anomalies with corresponding explanations. By applying instruction fine-tuning on this dataset, LLaMA3 demonstrates improved performance in time series anomaly detection tasks. In summary, our exploration shows the promising potential of LLMs as time series anomaly detectors.", "sections": [{"title": "1 Introduction", "content": "With the capabilities of Large Language Models (LLMs) demonstrated in handling various tasks, particularly for natural language processing (NLP) [Achiam et al., 2023] and computer vision (CV) [Liu et al., 2024b], LLMs-based time series analysis emerges as a promising topic [Zhang et al., 2024]. Their primary focus is on time series forecasting, which is an increasingly concerned topic for its broad and lasting roles in wide applications. Their studies can be broadly classified into two groups: (1) prompt engineering approaches, where time series are treated as a series of tokens, either directly fed into the LLMs [Gruver et al., 2023] or combined with instruction prompts [Xue and Salim, 2023], to conduct time series forecasting in a sentence-to-sentence fashion; and (2) aligning approaches, which use LLMs as backbones to train encoders transforming time series into embeddings and decoders translating the LLM outputs into the required output, or even utilizing the middle layers of the LLMs via strategies like pretraining [Ansari et al., 2024] or parameter-efficient fine-tuning (PEFT) [He et al., 2022, Zhou et al., 2023, Jin et al., 2024]. In contrast, time series anomaly detection, while increasingly studied in deep anomaly detection [Pang et al., 2021], has been rarely explored in the realm of LLMs.\nLLMs-based time series anomaly detection exhibits significant challenges differing from LLMs-based time series forecasting. The latter captures mainstream and patternable characteristics in time series, while the former needs to handle anomaly complexities including point and contextual exceptions. The limited work available on LLMs for time series anomaly detection [Zhou et al., 2023, Zhang et al., 2023, Liu et al., 2024a] does not explicitly verify or address these issues. They also overlook the textual reasoning ability of LLMs, treating both the input and output of LLMs as time series, without the explanation of how LLMs make their decisions. This motivates us to investigate an important capability area of LLMs in this paper: can LLMs serve as explainable time series anomaly detectors?"}, {"title": "2 Related Work", "content": "Transformers have demonstrated remarkable success in natural language processing (NLP) and, given their proficiency in handling sequential data, a significant number of transformer-based models have been proposed for time series forecasting. Early works focused on modifications to transformer modules, ranging from position embeddings [Nie et al., 2022] to attention mechanisms [Zhou et al., 2021], to better fit time series analysis [Zhou et al., 2023]. Most approaches can be regarded as aligning approaches, as they start training from transformer backbones (such as BERT [Kenton and Toutanova, 2019], GPT-2 [Radford et al., 2019], and T5 [Raffel et al., 2020]), and train the encoder, decoder, or middle layers of the transformers via fine-tuning [Zhou et al., 2023, Chang et al., 2024, Cao et al., 2024] or full parameter pretraining [Ansari et al., 2024]. However, these models often overlook the rich textual information within the pretrained models, where the fine-tuned model is still primarily used to process only time series data.\nStarting with ChatGPT [Ouyang et al., 2022], we have witnessed the power of large language models (LLMs) such as GPTs [Achiam et al., 2023] and LLaMAs [Touvron et al., 2023a,b]. These models, with larger parameters and trained on more extensive datasets [Hoffmann et al., 2022], exhibit powerful reasoning capabilities for handling complex tasks. This has triggered initial research in time series analysis, where some studies directly treat the time series as tokens and feed them into LLMs for forecasting [Gruver et al., 2023], or incorporate time series data with instruction prompts [Xue and Salim, 2023] or chain-of-thought prompts [Liu et al., 2024c]. Some even further fine-tune the LLMs [Jin et al., 2024]. However, these outputs remain within the time series domain, limiting their applicability to tasks such as generating descriptions for time series data.\nFew works have investigated utilizing LLMs for time series anomaly detection, a critical task in various real-world applications. Zhou et al. [2023] is likely the first to fine-tune language models for time series anomaly detection. They fine-tuned a general model for diverse time series tasks, such as classification, anomaly detection, forecasting, and few-shot or zero-shot learning, treating anomaly detection as a binary classification problem and adding layers on top of transformer modules for classification. Liu et al. [2024a] used LLMs as the teacher model and trained a student network to mimic the LLM outputs, identifying anomalies as points with distinct values between the teacher and student networks. However, these works did not utilize the reasoning ability of LLMs to provide textual explanations for detections. Zhang et al. [2023] evaluated GPT-4 and Claude-2 with prompt engineering for human mobility trajectory behavior anomaly detection, asking the models to provide explanations for the detections. However, they treated anomaly detection as a binary classification task (i.e., whether a given human mobility trajectory behavior sequence contains anomalies) and did not delve into the explanations provided by the LLMs. In this work, we focus on detecting specific anomaly points or segments within a time series and investigate whether LLMs can accurately capture the indices of anomalies and explain their detection results. To the best of our knowledge, this is one of the first comprehensive studies on time series anomaly detection using LLMs."}, {"title": "3 Can LLMs Be Directly Applied for Time Series Anomaly Detection?", "content": "We begin with an empirical study on evaluating two representative large language models (LLMs), GPT-4 and LLaMA-3, in identifying and explaining anomalies in time series data. Our approach involves interpreting time series data as text tokens and tasking the LLMs with: i) determining the presence of anomalies, and ii) if anomalies are identified, providing the indices for the anomalies and explaining the reasons. We assess the LLMs in terms of their capabilities in detecting five representative types of time series anomalies: global point anomaly, local point anomaly, seasonality anomaly, trend anomaly, and shape anomaly. Detailed descriptions of these anomalies can be found in Section 5.1, and examples of each anomaly type are provided in Appendix A.4.\nIn Figure 1, the top part illustrates the performance of these LLMs on a short time series with shape anomalies at indices 17, 18, and 19. Unfortunately, after five trials, neither model achieves accurate results. Similar outcomes are observed for other anomaly types, including local point anomalies, seasonality anomalies, and trend anomalies. However, both LLaMA-3 and GPT-4 perform well in detecting global point anomalies. This indicates that LLMs cannot be directly applied to detect most typical time series anomalies.\nUpon examining the intermediate reasoning steps of these LLMs, it appears that they involve simplistic methodologies, such as Isolation Forest [Liu et al., 2008] and the z-score technique, as shown in the figure. These approaches make it easier to identify global point anomalies. Unlike GPT-4, which may leverage external tools including Python, LLaMA-3's responses are solely derived from its textual reasoning capabilities. This occasionally results in hallucinated calculations and indices in its responses. Despite this, LLaMA-3 seems to intuitively understand the indices and corresponding values in the time series, particularly in the example shown in the figure, recognizing the significance of indices 4 and 12 for the value 5, even though these are not the actual anomalies.\nIn summary, the operational logic of these LLMs for time series anomaly detection can be characterized as follows: they first select a suitable anomaly detection strategy, identify the time series sequences within the input, and then construct their responses based on this strategy. However, based on our exploration, we cannot directly apply LLMs for time series anomaly detection, in particular, comprehensive anomaly types in time series."}, {"title": "4 How to Make LLMs An Explainable Time Series Anomaly Detector via Prompt Engineering?", "content": "Since LLMs seem to grasp the overall shape of time series, we add prompts to guide the LLMs to also consider the visual representation of the time series for anomaly detection.\nIn-context learning [Dong et al., 2023] In-context learning is a common prompting approach that includes n-shot examples in the prompts to help LLMs with target tasks. For time series anomaly detection, we include examples of five anomaly types: global point anomalies, local point anomalies, seasonality anomalies, trend anomalies, and shape anomalies, respectively. More details about these types of anomalies can be found in Section 5.1. \nChain-of-thought Prompting [Wei et al., 2022b] Chain-of-thought prompting further guides LLMs to decompose complex questions into detailed intermediate reasoning steps. For time series anomaly detection, humans typically first look at the whole time series to detect whether there are anomalies."}, {"title": "4.2 Performance on Trial Examples", "content": "We apply the above prompting strategies to design the trial examples for the five types of anomalies and evaluate the ability of the LLMs in identifying and explaining such anomalies in time series. \nGenerally, we observe that LLaMA-3 does not show significant improvement with different prompt designs and example cases, while GPT-4 demonstrates impressive results with any kind of prompts. For each case, we conduct five trials, and a detailed analysis of the responses from GPT-4 and LLaMA-3 reveals the following: GPT-4's responses are more consistent, suggesting that GPT-4 genuinely understands the prompts and examples. These instructions \"activate\" GPT-4 to consider different perspectives and provide correct results. In contrast, LLaMA-3 more likely provides varied responses to the same prompt. For more obvious anomalies, such as global point anomalies and trend anomalies (see Figure 7 in Appendix), LLaMA-3 provides more stable results with correctly identified anomalies and explanations. In summary, we observe more emergent abilities [Wei et al., 2022a] in GPT-4, where simple instructions can activate its capability of time series anomaly detection, leading to more accurate identification and explanation of time series anomalies. Although LLaMA-3 does not exhibit these abilities to the same extent (potentially due to its smaller parameter size compared to GPT-4), it still shows some capabilities in grasping the overall shape of time series."}, {"title": "4.3 LLM against Anomaly Detection Baselines", "content": "Given the impressive performance of GPT-4 on all trial examples with different prompts, we now evaluate how GPT-4 performs time series anomaly detection compared to classic anomaly detection baseline methods.\nWe evaluate the performance on four common time series anomaly detection datasets [Paparrizos et al., 2022]: YAHOO, ECG, SVDB, and IOPS, which include anomalies in monitoring services and ECG recordings. In our study, we carefully curate the datasets to encompass a broad spectrum of patterns. In each dataset, we select 100 distinct time series segments with length 1,080 that demonstrate maximum variability. We utilize the initial 50% of each time series as training data. We use F-score and Range-F [Paparrizos et al., 2022] to evaluate the performance. Range-F is an extension of the F-score, where a detection is considered accurate if the identified anomaly falls within the same window as the actual anomaly; in this case, we set the window size to 5.\nIn our comparison, we evaluate a range of time series anomaly detection methods. This includes traditional approaches such as Isolation Forest (IForest) [Liu et al., 2008], Matrix Profile (MP) [Yeh et al., 2016], and Autoencoder [Sakurada and Yairi, 2014]. Additionally, we explore forecasting-based methods, namely LSTM [Malhotra et al., 2015], Prophet [Taylor and Letham, 2018], Informer [Zhou et al., 2021], DLinear [Zeng et al., 2023] and TimesNet [Wu et al., 2022]. For these forecasting methods, anomalies are defined as observations deviating from the forecasted values by more than a 3-\u03c3 (three standard deviations) threshold.\nWe structure the time series segments using multi-modal prompts analogous to the example depicted in Figure 1, then feed the prompts to GPT-4 through the OpenAI API services3. Additionally, we craft a specific prompt designed to parse the output into a desired JSON format. This format encompasses two key components: a list of indices identifying the anomalous points, and a textual explanation that elucidates the rationale behind the identification of these anomalies."}, {"title": "5 Can LLMs be Improved via Instruction Fine-tuning?", "content": "While GPT-4 can be \"activated\" as an effective explainable time series anomaly detector, particularly for shorter time series, LLaMA-3 does not benefit as much from prompt engineering, primarily due to its smaller parameter size. Therefore, we aim to investigate whether LLaMA-3's performance can be improved via fine-tuning. Given the scarcity of time series with anomalies and corresponding textual explanation datasets, we propose a time series and text explanation generator TTGenerator to create the instruction datasets for fine-tuning LLaMA-3."}, {"title": "5.1 Time Series and Text Explanation Generator: TTGenerator", "content": "Formally, a time series dataset X with T timestamps can be represented as an ordered sequence of data points: $X = (x_1, x_2,\u2026\u2026,x_T)$, where $x_i$ is the data point at timestamp i (i \u2208 T). Generally, a time series is viewed as a combination of trend, seasonality, and noise components:\n$X = s(T) + \\tau(T) + \\epsilon$ (1)\nwhere s() represents the base shapelet function approximating the detrended series, which could be a combination of sine and square wave functions, i.e., $\\sum_n(A_n sin(2\\pi\\omega_n T))$, where A is the amplitude and $\\omega_n$ as the frequency. Alternatively, time series can be generated via Inverse Fast Fourier Transform (IFFT), i.e., $\\sum_n(A_n \\exp^{i2\\pi\\omega_n T}); \\tau(.)$ models the overall trend of the series, which could be linear or exponential; and e represents the noises which could be just white noises.\nFollowing Lai et al. [2021], we examine various types of time series anomalies, including point-wise and pattern-wise anomalies. Point-wise anomalies are defined as unexpected incidents at individual time points:\n$|x_t - \\hat{x_t}| > \\delta$ (2)\nThis includes local point anomalies, where $\\delta = \\lambda \\cdot \\sigma(X[x-C \\leq x \\leq x+C])$ with C as the context window size, and global point anomalies, where $\\delta = \\lambda \\cdot \\sigma(X)$, representing significant spikes or dips in the time series. Here, \u03c3 denotes the standard deviation and A sets the threshold level. Pattern-wise anomalies represent anomalous subsequences characterized by changes in seasonality, trend, or shape. Specifically, within a time series data X, an underlying subsequence $X_{i,j}$ from timestamp i to j can be considered anomalous if:\n$sim(X_{i,j}, \\hat{X_{i,j}}) > \\delta$ (3)\nThis indicates significant deviation from the expected values $X_{i,j}$. A seasonality anomaly may occur with an amplitude change (i.e., a modified $A_n$ in s($T_{i,j}$)) or a period change (i.e., a modified $\\hat{\\omega}_n$ in s($T_{i,j}$)). Trend anomalies may involve a change point (where trends differ before and after point i, with 1 < i < N), or a trend break (where the trend changes at i and then reverts at j, with 1 < i < j < N). Shape change anomalies may manifest as a pattern change (where the base pattern shifts starting at i and continues to j, with 1 < i < N), or a pattern break (where the base pattern changes at i but returns to normal by j, with 1 < i < j < N).\nAfter generating the base time series and the anomalies, we utilize a template to produce a description of the time series. This description includes: (i) details about the base time series such as seasonality, trend, and noise; and (ii) specifics about the anomalies, including the types of anomalies and their starting and ending indices. For time series that do not contain anomalies, the description will state: \u201cThere is no obvious anomaly in this time series\". To enhance the diversity of the dataset, we employ GPT-4 to rewrite the description for each sample.\nIn summary, TTGenerator synthesizes time series with outliers by (i) selecting random seasonality and trend patterns, (ii) inserting various types of outliers, and (iii) generating descriptions for the time series and the anomalies."}, {"title": "5.2 Instruction Fine-tuning on LLaMA\u0417", "content": "With TTGenerator, we generate the instruction dataset as follows: 1) Random Selection of Length: We randomly select the length of the generated time series from various time series lengths. We do not consider longer time series due to the context window length limitation for the LLMs, such as the 8k token limit for LLaMA3. 2) Sample Generation: We generate a single sample that includes the time series values, labels for the anomalies, and explanations for both the base time series and the anomalies. 3) Text Prompt Formation: We concatenate the information of a time series to form the text prompt to train the model as:\nwhere {instruction} refers to the general instruction and {requirements} specify that the output should be formatted in JSON with anomaly and reason as the two keys. 4) Repetition: Finally, we repeat the procedures 1)-3) n times to create the final dataset, where n is the dataset size. To fine-tune the instruction dataset on LLaMA3, we use a parameter-efficient fine-tuning (PEFT) approach, specifically LoRA [Hu et al., 2021], to obtain the fine-tuned model. "}, {"title": "5.3 Results", "content": "We evaluate the performance on three synthesized datasets generated by TTGenerator for five types of time series anomalies: global point anomaly, local point anomaly, seasonality anomaly, trend anomaly, and shape anomaly. The datasets have different time series lengths of 100, 200, and 400.\nWe compare the performance of the original LLaMA3 with our fine-tuned version. The results are shown in Table 4. Generally, for both models, the performance decreases as the length of the time series increases. Despite the relatively low F-score for point-aware anomalies, the Range-F score is relatively high, indicating that the model is able to capture the correct anomalies but may hallucinate in the surrounding indices. Comparing point-aware and context-aware anomalies, both models provide more stable performance on context-aware anomalies compared to point-aware anomalies across different time series lengths. Comparing the original and fine-tuned versions of LLaMA3, the ability to detect local point anomalies and shape anomalies does not seem to benefit much from the instruction fine-tuning. However, we observe general improvements in the average F-score and Range-F, with significant improvements in detecting seasonality anomalies.\nSimilar to GPT-4, LLaMA3 exhibits hallucinations in its detection results. Table 5 presents these findings. Interestingly, we observe a decreasing trend in the number of hallucinated time series segments with the fine-tuned LLaMA3 compared to GPT-4's performance (Appendix B.2), while LLaMA3 tends to hallucinate more indices than GPT-4."}, {"title": "6 Conclusion", "content": "In this paper, we comprehensively investigate the capability of Large Language Models (LLMs) in time series anomaly detection by addressing three key questions: Can LLMs be directly applied for explainable time series anomaly detection? How can LLMs detect and explain time series anomalies via prompt engineering? Can we improve LLMs' detection performance through instruction fine-tuning? The answers to these questions are: No, Yes, and Yes, respectively, with evidence showing that GPT-4 demonstrates competent performance compared to baseline methods with minimal effort in prompt engineering, and LLaMA3 achieves better performance after instruction fine-tuning. In summary, LLMs show promising potential for time series anomaly detection, while customized prompts and instructions are essential."}, {"title": "A.1 Benchmark Dataset Settings", "content": "We selected four widely used time series anomaly detection datasets: YAHOO, ECG, SVDB, and IOPS, as referenced in the paper by Paparrizos et al. (2022) [Paparrizos et al., 2022]. The original datasets can be downloaded from the repository4. We constructed the evaluation dataset by manually selecting segments from the time series data. First, we determined the window size for each time series using the Fast Fourier Transform (FFT) and then computed the median window size across the dataset. The segment length was set to four times the median window size, resulting in a segment length of 1080 based on the window sizes of the four datasets. Each time series was partitioned into multiple segments of this length. We manually inspected the segments with a length of 1080 for each dataset, selecting time series with diverse distributions. From these, we randomly extracted 100 segments for evaluation. "}, {"title": "A.2 Baselines Settings", "content": "[Liu et al., 2008] We use the Scikit-learn implementation with n_estimators set to 100. Following the approach in Wu et al. [2022], we employ the Fast Fourier Transform to determine the optimal window size for each time series.\n[Yeh et al., 2016] We use the Stumpy implementation and set the window size for each time series based on the Fast Fourier Transform strategy.\n[Sakurada and Yairi, 2014] Following the parameter settings suggested in Paparrizos et al. [2022], we use three encoder and three decoder layers with ReLU as the activation function. The window size is adjusted to match the length of the test data.\n[Taylor and Letham, 2018] We use the official Facebook implementation and detect anomalies using the forecasted yhat_upper and yhat_lower bounds.\n[Malhotra et al., 2015], [Zhou et al., 2021], TimesNet [Wu et al., 2022], and DLinear [Zeng et al., 2023] Implementations are sourced from NeuralForecasts. Anomalies are detected by applying the 3-\u03c3 rule, which flags any data point deviating more than three standard deviations from the mean."}, {"title": "A.3 Prompt Settings", "content": "The prompt we used for inference contains two parts: the instruction part and the requirements part."}, {"title": "A.5 TTGenerator Details", "content": "Generally, a time series is viewed as a combination of trend, sea- sonality, and noise, as described in equation 1. For the seasonality component, we use one of three methods: i) A single sine wave function, i.e., A sin(2\u03c0\u03c9T + \u03b2), where A is the amplitude (ranging from 1 to 1000), w is the frequency (ranging from 1 to 10), and \u03b2 is a phase shift (ranging from 0 to 2\u03c0). ii) A combination of sine wave functions, i.e., \u2211n (An sin(2\u03c0\u03c9\u03b7\u03a4)), where $A_n=\\frac{1}{2^{n+1}}$, following the settings in Lai et al. [2021], and n is randomly sampled in the range of 3 to 10. iii) An IFFT function, i.e., \u2211n (An exp*", "in": "1\": \"2n+1,"}, {"title": "A.6 LLM Settings", "content": "For both models, we employ a rerun strategy: if the model fails to provide the required JSON- formatted response, we automatically rerun the code until the response adheres to the specified format. If the model fails more than five trials, we return the default response as {anomaly: [], reason: \"\"}."}]}