{"title": "Can LLMs Serve As Time Series Anomaly Detectors?", "authors": ["Manqing Dong", "Hao Huang", "Longbing Cao"], "abstract": "An emerging topic in large language models (LLMs) is their application to time series forecasting, characterizing mainstream and patternable characteristics of time series. A relevant but rarely explored and more challenging question is whether LLMs can detect and explain time series anomalies, a critical task across various real-world applications. In this paper, we investigate the capabilities of LLMs, specifically GPT-4 and LLaMA3, in detecting and explaining anomalies in time series. Our studies reveal that: 1) LLMs cannot be directly used for time series anomaly detection. 2) By designing prompt strategies such as in-context learning and chain-of-thought prompting, GPT-4 can detect time series anomalies with results competitive to baseline methods. 3) We propose a synthesized dataset to automatically generate time series anomalies with corresponding explanations. By applying instruction fine-tuning on this dataset, LLaMA3 demonstrates improved performance in time series anomaly detection tasks. In summary, our exploration shows the promising potential of LLMs as time series anomaly detectors.", "sections": [{"title": "1 Introduction", "content": "With the capabilities of Large Language Models (LLMs) demonstrated in handling various tasks, particularly for natural language processing (NLP) [Achiam et al., 2023] and computer vision (CV) [Liu et al., 2024b], LLMs-based time series analysis emerges as a promising topic [Zhang et al., 2024]. Their primary focus is on time series forecasting, which is an increasingly concerned topic for its broad and lasting roles in wide applications. Their studies can be broadly classified into two groups: (1) prompt engineering approaches, where time series are treated as a series of tokens, either directly fed into the LLMs [Gruver et al., 2023] or combined with instruction prompts [Xue and Salim, 2023], to conduct time series forecasting in a sentence-to-sentence fashion; and (2) aligning approaches, which use LLMs as backbones to train encoders transforming time series into embeddings and decoders translating the LLM outputs into the required output, or even utilizing the middle layers of the LLMs via strategies like pretraining [Ansari et al., 2024] or parameter-efficient fine-tuning (PEFT) [He et al., 2022, Zhou et al., 2023, Jin et al., 2024]. In contrast, time series anomaly detection, while increasingly studied in deep anomaly detection [Pang et al., 2021], has been rarely explored in the realm of LLMs.\nLLMs-based time series anomaly detection exhibits significant challenges differing from LLMs-based time series forecasting. The latter captures mainstream and patternable characteristics in time series, while the former needs to handle anomaly complexities including point and contextual exceptions. The limited work available on LLMs for time series anomaly detection [Zhou et al., 2023, Zhang et al., 2023, Liu et al., 2024a] does not explicitly verify or address these issues. They also overlook the textual reasoning ability of LLMs, treating both the input and output of LLMs as time series, without the explanation of how LLMs make their decisions. This motivates us to investigate an important capability area of LLMs in this paper: can LLMs serve as explainable time series anomaly detectors?"}, {"title": "2 Related Work", "content": "Transformers have demonstrated remarkable success in natural language processing (NLP) and, given their proficiency in handling sequential data, a significant number of transformer-based models have been proposed for time series forecasting. Early works focused on modifications to transformer modules, ranging from position embeddings [Nie et al., 2022] to attention mechanisms [Zhou et al., 2021], to better fit time series analysis [Zhou et al., 2023]. Most approaches can be regarded as aligning approaches, as they start training from transformer backbones (such as BERT [Kenton and Toutanova, 2019], GPT-2 [Radford et al., 2019], and T5 [Raffel et al., 2020]), and train the encoder, decoder, or middle layers of the transformers via fine-tuning [Zhou et al., 2023, Chang et al., 2024, Cao et al., 2024] or full parameter pretraining [Ansari et al., 2024]. However, these models often overlook the rich textual information within the pretrained models, where the fine-tuned model is still primarily used to process only time series data.\nStarting with ChatGPT [Ouyang et al., 2022], we have witnessed the power of large language models (LLMs) such as GPTs [Achiam et al., 2023] and LLaMAs [Touvron et al., 2023a,b]. These models, with larger parameters and trained on more extensive datasets [Hoffmann et al., 2022], exhibit powerful reasoning capabilities for handling complex tasks. This has triggered initial research in time series analysis, where some studies directly treat the time series as tokens and feed them into LLMs for forecasting [Gruver et al., 2023], or incorporate time series data with instruction prompts [Xue and Salim, 2023] or chain-of-thought prompts [Liu et al., 2024c]. Some even further fine-tune the"}, {"title": "3 Can LLMs Be Directly Applied for Time Series Anomaly Detection?", "content": "We begin with an empirical study on evaluating two representative large language models (LLMs), GPT-4 and LLaMA-3, in identifying and explaining anomalies in time series data. Our approach involves interpreting time series data as text tokens and tasking the LLMs with: i) determining the"}, {"title": "4 How to Make LLMs An Explainable Time Series Anomaly Detector via Prompt Engineering?", "content": "Since LLMs seem to grasp the overall shape of time series, we add prompts to guide the LLMs to also consider the visual representation of the time series for anomaly detection.\nIn-context Learning [Dong et al., 2023] In-context learning is a common prompting approach that includes n-shot examples in the prompts to help LLMs with target tasks. For time series anomaly detection, we include examples of five anomaly types: global point anomalies, local point anomalies, seasonality anomalies, trend anomalies, and shape anomalies, respectively. More details about these types of anomalies can be found in Section 5.1.\nChain-of-thought Prompting [Wei et al., 2022b] Chain-of-thought prompting further guides LLMs to decompose complex questions into detailed intermediate reasoning steps. For time series anomaly detection, humans typically first look at the whole time series to detect whether there are anomalies."}, {"title": "4.1 Prompting Strategies", "content": "Multi-modal Instruction"}, {"title": "4.2 Performance on Trial Examples", "content": "We apply the above prompting strategies to design the trial examples for the five types of anomalies and evaluate the ability of the LLMs in identifying and explaining such anomalies in time series. \nGenerally, we observe that LLaMA-3 does not show significant improvement with different prompt designs and example cases, while GPT-4 demonstrates impressive results with any kind of prompts. For each case, we conduct five trials, and a detailed analysis of the responses from GPT-4 and LLaMA-3 reveals the following: GPT-4's responses are more consistent, suggesting that GPT-4 genuinely understands the prompts and examples. These instructions \"activate\" GPT-4 to consider different perspectives and provide correct results. In contrast, LLaMA-3 more likely provides varied responses to the same prompt. For more obvious anomalies, such as global point anomalies and trend anomalies , LLaMA-3 provides more stable results with correctly identified anomalies and explanations. In summary, we observe more emergent abilities [Wei et al., 2022a] in GPT-4, where simple instructions can activate its capability of time series anomaly detection, leading to more accurate identification and explanation of time series anomalies. Although LLaMA-3 does not exhibit these abilities to the same extent (potentially due to its smaller parameter size compared to GPT-4), it still shows some capabilities in grasping the overall shape of time series."}, {"title": "4.3 LLM against Anomaly Detection Baselines", "content": "Given the impressive performance of GPT-4 on all trial examples with different prompts, we now evaluate how GPT-4 performs time series anomaly detection compared to classic anomaly detection baseline methods.\nWe evaluate the performance on four common time series anomaly detection datasets : YAHOO, ECG, SVDB, and IOPS, which include anomalies in monitoring services and ECG recordings. In our study, we carefully curate the datasets to encompass a broad spectrum of patterns. In each dataset, we select 100 distinct time series segments with length 1,080 that demonstrate maximum variability. We utilize the initial 50% of each time series as training data.\nIn our comparison, we evaluate a range of time series anomaly detection methods. This includes traditional approaches such as Isolation Forest (IForest) [Liu et al., 2008], Matrix Profile (MP) [Yeh et al., 2016], and Autoencoder (AE) [Sakurada and Yairi, 2014]. Additionally, we explore forecasting-based methods, namely LSTM [Malhotra et al., 2015], Prophet [Taylor and Letham, 2018], Informer [Zhou et al., 2021], DLinear [Zeng et al., 2023] and TimesNet [Wu et al., 2022]. For these forecasting methods, anomalies are defined as observations deviating from the forecasted values by more than a 3-\u03c3 (three standard deviations) threshold.\nWe structure the time series segments using multi-modal prompts analogous to the example depicted in Figure 1, then feed the prompts to GPT-4 through the OpenAI API services. Additionally, we craft a specific prompt designed to parse the output into a desired JSON format. This format encompasses two key components: a list of indices identifying the anomalous points, and a textual explanation that elucidates the rationale behind the identification of these anomalies."}, {"title": "5 Can LLMs be Improved via Instruction Fine-tuning?", "content": "While GPT-4 can be \"activated\" as an effective explainable time series anomaly detector, particularly for shorter time series, LLaMA-3 does not benefit as much from prompt engineering, primarily due to its smaller parameter size. Therefore, we aim to investigate whether LLaMA-3's performance can be improved via fine-tuning. Given the scarcity of time series with anomalies and corresponding textual explanation datasets, we propose a time series and text explanation generator TTGenerator to create the instruction datasets for fine-tuning LLaMA-3."}, {"title": "5.1 Time Series and Text Explanation Generator: TTGenerator", "content": "Formally, a time series dataset X with T timestamps can be represented as an ordered sequence of data points: \\(X = (x_1, x_2,\u2026\u2026,x_T)\\), where \\(x_i\\) is the data point at timestamp i (i \u2208 T). Generally, a time series is viewed as a combination of trend, seasonality, and noise components:\n\\(X = s(T) + T(T) + \\epsilon\\) \nwhere s() represents the base shapelet function approximating the detrended series, which could be a combination of sine and square wave functions, i.e., \\(\\sum_{n}(A_n sin(2\\pi\\omega_nT))\\), where A is the amplitude and wn as the frequency. Alternatively, time series can be generated via Inverse Fast Fourier Transform (IFFT), i.e., \u03a3\u03b7(An expni); (.) models the overall trend of the series, which could be linear or exponential; and e represents the noises which could be just white noises.\nFollowing Lai et al. [2021], we examine various types of time series anomalies, including point-wise and pattern-wise anomalies. Point-wise anomalies are defined as unexpected incidents at individual time points:\n\\(X_t - x_t > \\delta\\) \nThis includes local point anomalies, where \\(\u03b4 = \u03bb\u00b7 \u03c3(X_{[x\u2212C\u2264x\u2264x+C]})\\) with C as the context window size, and global point anomalies, where \\(\u03b4 = \u03bb\u00b7 \u03c3(\u03a7)\\), representing significant spikes or dips in the time series. Here, o denotes the standard deviation and A sets the threshold level. Pattern-wise anomalies represent anomalous subsequences characterized by changes in seasonality, trend, or shape. Specifically, within a time series data X, an underlying subsequence Xi,j from timestamp i to j can be considered anomalous if:\nsim(Xi,j, Xi,j) > \u03b4"}, {"title": "5.2 Instruction Fine-tuning on LLaMA\u0417", "content": "With TTGenerator, we generate the instruction dataset as follows: 1) Random Selection of Length: We randomly select the length of the generated time series from various time series lengths. We do not consider longer time series due to the context window length limitation for the LLMs, such as the 8k token limit for LLaMA3. 2) Sample Generation: We generate a single sample that includes the time series values, labels for the anomalies, and explanations for both the base time series and the anomalies. 3) Text Prompt Formation: We concatenate the information of a time series to form the text prompt to train the model as:\nwhere {instruction} refers to the general instruction and {requirements} specify that the output should be formatted in JSON with anomaly and reason as the two keys. 4) Repetition: Finally, we repeat the procedures 1)-3) n times to create the final dataset, where n is the dataset size. To fine-tune the instruction dataset on LLaMA3, we use a parameter-efficient fine-tuning (PEFT) approach, specifically LoRA [Hu et al., 2021], to obtain the fine-tuned model."}, {"title": "5.3 Results", "content": "We evaluate the performance on three synthesized datasets generated by TTGenerator for five types of time series anomalies: global point anomaly, local point anomaly, seasonality anomaly, trend anomaly, and shape anomaly. The datasets have different time series lengths of 100, 200, and 400. \nWe compare the performance of the original LLaMA3 with our fine-tuned version. The results are shown in Table 4. Generally, for both models, the performance decreases as the length of the time series increases. Despite the relatively low F-score for point-aware anomalies, the Range-F score is relatively high, indicating that the model is able to capture the correct anomalies but may hallucinate in the surrounding indices. Comparing point-aware and context-aware anomalies, both models provide more stable performance on context-aware anomalies compared to point-aware anomalies across different time series lengths. Comparing the original and fine-tuned versions of LLaMA3, the ability to detect local point anomalies and shape anomalies does not seem to benefit much from the instruction fine-tuning. However, we observe general improvements in the average F-score and Range-F, with significant improvements in detecting seasonality anomalies.\nSimilar to GPT-4, LLaMA3 exhibits hallucinations in its detection results."}, {"title": "6 Conclusion", "content": "In this paper, we comprehensively investigate the capability of Large Language Models (LLMs) in time series anomaly detection by addressing three key questions: Can LLMs be directly applied for explainable time series anomaly detection? How can LLMs detect and explain time series anomalies via prompt engineering? Can we improve LLMs' detection performance through instruction fine-tuning? The answers to these questions are: No, Yes, and Yes, respectively, with evidence showing that GPT-4 demonstrates competent performance compared to baseline methods with minimal effort in prompt engineering, and LLaMA3 achieves better performance after instruction fine-tuning. In summary, LLMs show promising potential for time series anomaly detection, while customized prompts and instructions are essential."}, {"title": "A Experimental Settings", "content": "We selected four widely used time series anomaly detection datasets: YAHOO, ECG, SVDB, and IOPS, as referenced in the paper by Paparrizos et al. (2022) [Paparrizos et al., 2022]. The original datasets can be downloaded from the repository4. We constructed the evaluation dataset by manually selecting segments from the time series data. First, we determined the window size for each time series using the Fast Fourier Transform (FFT) and then computed the median window size across the dataset. The segment length was set to four times the median window size, resulting in a segment length of 1080 based on the window sizes of the four datasets. Each time series was partitioned into multiple segments of this length. We manually inspected the segments with a length of 1080 for each dataset, selecting time series with diverse distributions. From these, we randomly extracted 100 segments for evaluation.\nWe use the Scikit-learn implementation with n_estimators set to 100. Following the approach in Wu et al. [2022], we employ the Fast Fourier Transform to determine the optimal window size for each time series.\nWe use the Stumpy implementation and set the window size for each time series based on the Fast Fourier Transform strategy.\nFollowing the parameter settings suggested in Paparrizos et al. [2022], we use three encoder and three decoder layers with ReLU as the activation function. The window size is adjusted to match the length of the test data.\nWe use the official Facebook implementation and detect anomalies using the forecasted yhat_upper and yhat_lower bounds.\nImplementations are sourced from NeuralForecasts. Anomalies are detected by applying the 3-\u03c3 rule, which flags any data point deviating more than three standard deviations from the mean.\nThe prompt we used for inference contains two parts: the instruction part and the requirements part."}, {"title": "A.1 Benchmark Dataset Settings", "content": "A.2 Baselines Settings"}, {"title": "A.3 Prompt Settings", "content": "Instruction Prompt"}, {"title": "A.4 Trial Examples", "content": "The details about the trial examples used in Sections 3 and 4 are shown in Figure 7, where the explanation part describes the ideal explanation for those anomalies. When constructing in-context learning and chain-of-thought prompts with n-shot examples, we use distinct anomaly types to formulate the prompt. For example, when inferring on a time series with shape anomalies, we will randomly choose examples of other types of anomalies, such as local point anomalies. Specifically, we set n to 1 to obtain the results shown in Figure 1."}, {"title": "A.5 TTGenerator Details", "content": "Generally, a time series is viewed as a combination of trend, seasonality, and noise, as described in equation 1. For the seasonality component, we use one of three methods: i) A single sine wave function, i.e., A sin(2\u03c0\u03c9T + \u03b2), where A is the amplitude (ranging from 1 to 1000), w is the frequency (ranging from 1 to 10), and \u03b2 is a phase shift (ranging from 0 to 2\u03c0). ii) A combination of sine wave functions, i.e., \u2211n (An sin(2\u03c0\u03c9\u03b7\u03a4)), where An =, following the settings in Lai et al. [2021], and n is randomly sampled in the range of 3 to 10. iii) An IFFT function, i.e., \u2211n (An exp*\"\"i), where n is randomly selected in the range of 0 to 10. To determine the seasonality for a time series, we randomly sample from these three methods with probabilities [0.25, 0.25, 0.5]. For the trend component, we consider either a linear trend, polynomial trend, or no trend, with sampling probabilities [0.3, 0.1, 0.6], assuming most time series have no trend and more linear trends than polynomial trends. For the linear trend, we randomly sample the slope in"}, {"title": "A.6 LLM Settings", "content": "For both models, we employ a rerun strategy: if the model fails to provide the required JSON- formatted response, we automatically rerun the code until the response adheres to the specified format. If the model fails more than five trials, we return the default response as {anomaly: [], reason: \"\"}."}, {"title": "B Complementary Results", "content": "Figure 16 and Figure 17 present additional examples of responses generated by GPT-4 and LLaMA3 on the trial cases. The responses produced by LLaMA3 are significantly more unstable compared to those from GPT-4. For instance, when identifying global point anomalies, LLaMA3 can yield different outputs for the same prompt. Although LLaMA3 does not benefit much from prompt engineering, differences can still be observed before and after applying prompting strategies. In some cases, LLaMA3 provides responses that closely match the ideal answers.\nThe evaluation metric range-F score evaluates the model's precision in detecting anomalies. Specifically, it questions how closely the model's predicted anomaly positions align with the actual anomaly positions. Figure 22 illustrates the variation of the F-score as the range-F window size changes across different benchmark datasets. Generally, enlarging the window size enhances the model's performance, with notable improvements observed in the YAHOO dataset. This suggests that, compared to other datasets, the model's predictions for anomaly positions in the YAHOO dataset are significantly closer to their actual locations."}, {"title": "B.1 Example Responses Given Different Prompt Strategies On Trial Cases", "content": "B.2 More results on GPT-4"}, {"title": "B.3 More results on LLAMA3", "content": "Due to the very limited context window of 8K tokens in LLaMA3, we attempted evaluation on LLaMA3 using four benchmark datasets. However, for the ECG and SVDB datasets, which contain about 30% anomalies, LLaMA3 often failed to provide complete responses in many trials. As a result, we have not included the results for these four datasets in the main context. On the other hand, for the YAHOO dataset, the model was able to provide more complete responses. Therefore, we report the results for the YAHOO dataset in table 13. We observe that after fine-tuning, LLaMA3 slightly outperforms GPT-4 on the YAHOO dataset."}, {"title": "C Related Works for Time Series Anomaly Detection", "content": "Traditional methods for detecting anomalies in time series data can be broadly categorized into several approaches. Prediction-based methods are the most prevalent, involving the training of a robust time series forecasting model, such as Prophet [Taylor and Letham, 2018] or the more recent transformer-based models like Informer [Zhou et al., 2021]. Anomalies are identified as points exhibiting significant deviations from forecasted values. Clustering-based approaches, exemplified by Isolation Forest (IForest) [Liu et al., 2008], utilize binary tree structures based on space partitioning, where nodes closer to the root are more likely to be anomalies. Pattern-matching approaches, such as Matrix Profile (MP) [Yeh et al., 2016], detect anomalies as subsequences with notably large nearest- neighbor distances. Reconstruction-based approaches, represented by Autoencoders [Sakurada and Yairi, 2014], learn to reconstruct data, flagging as outliers those points that significantly diverge from the reconstructed values. The primary issue is that while most of them excel at capturing specific types of anomalies, they are also difficult to explain in terms of their detection results."}, {"title": "D Limitation and Future Work", "content": "Although we have observed that GPT-4 can deliver good performance with minimal instructions, its current lack of public fine-tuning capabilities on GPT-4 prevents us from exploring whether fine-tuning on GPT-4 could achieve state-of-the-art (SOTA) performance. We are in the process"}]}