{"title": "Online Energy Optimization in GPUs: A Multi-Armed Bandit Approach", "authors": ["Xiongxiao Xu", "Solomon Abera Bekele", "Brice Videau", "Kai Shu"], "abstract": "Energy consumption has become a critical design metric and a limiting factor in the development of future computing architectures, from small wearable devices to large-scale leadership computing facilities. The predominant methods in energy management optimization are focused on CPUs. However, GPUs are increasingly significant and account for the majority of energy consumption in heterogeneous high performance computing (HPC) systems. Moreover, they typically rely on either purely offline training or a hybrid of offline and online training, which are impractical and lead to energy loss during data collection. Therefore, this paper studies a novel and practical online energy optimization problem for GPUs in HPC scenarios. The problem is challenging due to the inherent performance-energy trade-offs of GPUs, the exploration & exploitation dilemma across frequencies, and the lack of explicit performance counters in GPUs. To address these challenges, we formulate the online energy consumption optimization problem as a multi-armed bandit framework and develop a novel bandit based framework ENERGYUCB. ENERGYUCB is designed to dynamically adjust GPU core frequencies in real-time, reducing energy consumption with minimal impact on performance. Specifically, the proposed framework ENERGYUCB (1) balances the performance-energy trade-off in the reward function, (2) effectively navigates the exploration & exploitation dilemma when adjusting GPU core frequencies online, and (3) leverages the ratio of GPU core utilization to un-core utilization as a real-time GPU performance metric. Experiments on a wide range of real-world HPC benchmarks demonstrate that ENERGYUCB can achieve substantial energy savings. The code of ENERGYUCB is available at https://github.com/XiongxiaoXu/EnergyUCB-Bandit.", "sections": [{"title": "1 Introduction", "content": "Energy efficiency is one of the most pressing global is-sues on Earth, and has a wide spectrum of impacts on so-ciety, from environmental sustainability to economic sta-bility and social development (Reddy et al. 2000; Berndt1990). One significant aspect of this broader energy concernis energy consumption of computing architectures, rang-ing from everyday hand-held gadgets (Hussein, Bhat, andDoppa 2022; Sarmad, Fatima, and Tayyub 2022), such assmartphones and wearable health devices, to the world'sfastest and most powerful supercomputers (Wright and al.2010; Atchley et al. 2023), such as Frontier supercomputerat Oak Ridge National Laboratory and Aurora supercom-puter at Argonne National Laboratory. For example, Aurorasupercomputer, recently announced as the second-fastest su-percomputer around the world in 2024, is expected to reach60MW peak power, which can afford power needs of a mid-sized U.S. city\u00b9. In the Summer of 2022, the RIKEN Cen-ter for Computational Science was forced to power off 1/3of the Fugaku supercomputer for most of the remainingyear, due to soaring energy prices in Japan\u00b2. These lead-ership computing systems are extremely important to var-ious facets of society, including drug discovery (Acharyaet al. 2020), cosmology (Frontiere et al. 2022), pandemicresponse (Mustafa and Makhawi 2023), etc., making theirenergy efficiency a crucial element for a sustainable future.\nAlthough extensive work has achieved promisingprogress in reducing the energy consumption of computingsystems, they mainly target on CPUs (Zhu, Melhem, andChilders 2003; Yang et al. 2015; Cerf et al. 2021; Wanget al. 2021b; Wu and Taylor 2023). The rapidly growingimportance of GPUs has shifted the focus, particularly inAI model training, such as large language models (LLMs)"}, {"title": "2 Related Work", "content": "This work is primarily related to two lines of research: (1)energy consumption optimization in CPUs/GPUs and (2)multi-armed bandits and its applications"}, {"title": "Energy Consumption Optimization in CPUs/GPUs", "content": "Energy consumption optimization in CPUs is an importanttask and a significant amount of work (Zhu, Melhem, andChilders 2003; Kim et al. 2013; Shafik et al. 2015; Chenand Marculescu 2015; Wu et al. 2016; Wang et al. 2017;Abera, Balakrishnan, and Kumar 2018; Bekele, Balakrish-nan, and Kumar 2019; Wu, Taylor, and Lan 2023; Ali et al.2023) have emerged. (Zhu, Melhem, and Childers 2003) isone of pioneer works to adapt adjust frequency/voltage forenergy consummation optimization on multiprocessor sys-tems. (Yang et al. 2015) leverages regression-based learningto characterize performance-energy trade-offs in heteroge-neous system including CPU, DSP and FPGA cores. (Wanget al. 2021b) uses reinforcement learning for runtime poweroptimization on CPU while considering power capping anduncore frequency scaling. (Wu and Taylor 2023) combineslinear, nonlinear, tree-, and rule-based ML methods throughensemble learning to model power consumption for two par-allel cancer deep learning CANDLE benchmarks.\nGPU energy optimization is an under-exploredtask (Wang 2010; Lin, Tang, and Wang 2011; Bridges,Imam, and Mintz 2016). (Huang, Guo, and Shen 2019)offline conducts a global-based neural network for GPUenergy management based on task characteristics. (Wanget al. 2021a) is the most related to ours and presents GPOEOto dynamically optimize energy configuration. However,GPOEO first collects offline data to train, and then deploythe well-trained model online on an NVIDIA RTX3080TiGPU. Unlike the above work, our framework eliminatesthe need for offline training and learns online entirely fromscratch. Additionally, our evaluation dataset and platformare based on a new GPU architecture, Intel PVC, recentlyinstalled at the Aurora supercomputer."}, {"title": "Multi-Armed Bandits and Its Applications", "content": "Multi-armed bandit (MAB) (Lattimore and Szepesv\u00e1ri2020) is a sequential decision-making framework to bal-ance the exploration & exploitation dilemma and it is widelyused in various applications such as clinical trails (Durandet al. 2018), dynamic pricing (Misra, Schwartz, and Aber-nethy 2019), recommended systems (Zhou et al. 2017),anomaly detection (Ding, Li, and Liu 2019), telecommuni-cation (Soemers et al. 2018). For example, in clinical trials,bandit algorithms are used to dynamically adjust the alloca-tion of treatments to patients based on observed outcomes,with the goal of optimizing patient welfare and efficientlyidentifying the most effective treatments. Some notewor-thy variants consider additional factors, including contextualbandits (Li et al. 2010; Chu et al. 2011; Xu, Xie, and Lui2021), conversational bandits (Zhang et al. 2020), and neu-ral bandits (Ban, He, and Cook 2021). However, no existingwork attempts to leverage bandits to optimize GPU energyconsumption, especially in HPC scenarios."}, {"title": "3 Preliminaries", "content": "In this section, we introduce the architecture of the PVC,multi-armed bandits, and problem definition."}, {"title": "The Aurora Node Architecture", "content": "A single Aurora node, as shown in Figure 2, comprises oftwo Intel Xeon CPU Max Series processors, known as Sap-phire Rapids or SPR, equipped with on-package High Band-width Memory (HBM), and six Intel Data Center GPU MaxSeries, also known as Ponte Vecchio or PVC. Each XeonCPUs have 52 cores, with two hardware threads per core,and are outfitted with 64GB of HBM. The PVC is built onthe Xe Core architecture. Each Xe core is composed of 8vector and 8 matrix engines, supported by 512 KB of L1cache. They are interconnected using the Intel XeLink inter-faces. Every node includes 8 HPE Slingshot-11 Network In-terface Cards (NICs). A group of 16 Xe cores forms a slice,and 4 such slices are combined with a substantial L2 cacheand 4 HBM2E memory controllers to create a stack or tile."}, {"title": "Multi-Armed Bandits", "content": "Basic Formulation. In many real-world scenarios, it is im-portant to balance the exploration & exploitation dilemma,i.e., exploiting the current accumulated observations and ex-ploring new knowledge through searching unknown spaces.A classic formulation of the decision-making framework toaddress the exploration & exploitation dilemma is the K-armed bandit problem. Formally, there are K finite arms. Ateach time step $t \\in {1, 2, ..., T}$, one arm out of the K armsis pulled, and let $I_t \\in {1,2..., K}$ be the arm pulled at timestep t. After $I_t$ is pulled, the associated reward $r_t$ of the arm$I_t$ is observed by the bandit algorithm. Given a fixed timecost T, the goal of the algorithm is to maximize the totalrewards over a sequence of time steps T as follows:\n$\\max \\sum_{t=1}^{T} r_t$                                                                                                                                                                                 (1)\nThe decision $I_t$ at each time step t involves choosing be-tween exploiting the arm with the highest accumulated re-wards until time t 1 and exploring other arms to gathermore knowledge about their potential rewards."}, {"title": "Reward Model", "content": "The generated reward of each arm i fol-lows a probability distribution $D_i \\in {D_1, D_2, ..., D_k}$ withmean $\\mu_i \\in {\\mu_1, \\mu_2, \u2026, \\mu_\u03ba}$. When pulling an arm i, thereward will be sampled independently from the distributionDi. In other words, given the history up to time t - 1 and thechoice of arm $I_t$ at time t, the reward is drawn independentlywith respect to the distribution of the chosen arm. In a for-mal way, let $H_{t\u22121} = {(I_1,r_1,), (I_2, r_2, ), ..., (I_{t\u22121},r_{t-1})}$denote the history of observations until time t \u2013 1. The ex-pected reward for arm i can be written as follows:\n$E[r_t | H_{t-1}, I_t = i] = \\mu_i$                                                                                                                                                                       (2)\nIt implies the reward generated by arm i is randomly dis-turbed by noise."}, {"title": "Cumulative Regret", "content": "The performance of the bandit algo-rithm is measured by the gap between the evaluated algo-rithm and the Oracle algorithm which can choose the bestarm all the time. Formally, let $I^* = \\arg \\max_{i=1,2,..., \u039a} \\mu_i$and $\\mu^* = \\mu_{I^*}$ be the index of the best arm selected by Or-acle algorithm and the associated highest expected reward.We define the cumulative regret at time T as follows:\n$R(T) = \\sum_{t=1}^{T}(\\mu^* \u2013 \\mu_{I_t})$                                                                                                                                                                   (3)\nThe goal of the bandit algorithm is to minimize regret inEq. 3 or equally maximize reward in Eq. 1."}, {"title": "Problem Definition", "content": "Following the above notations, we give a formal problemdefinition for the online energy consumption in GPUs.\nOnline Energy Consumption in GPUs. Given an ap-plication running on GPUs at the default maximum fre-quency, the task is to dynamically adjust the frequencyof GPU cores so that the energy can be saved when theapplication completes. Specifically, at each time step t,the algorithm sets a particular frequency and observesdata from hardware counters in GPUs, leading to a re-ward rt. By incorporating this feedback, the algorithmacumulates the knowledge and updates the strategy forfrequency adjustment. The process continues until the ap-plication completes at time T.\nThere are two key points to emphasize. (1) The problem isset in a fully online environment. This means that the al-gorithm cannot access any prior information regarding pro-files of GPUs and applications under frequencies. Instead,the algorithm must learn and adapt by directly interactingwith real-time data from the GPUs' hardware counters. (2)The time cost T varies across different applications and fre-quencies. Since each application requires a distinct work-load, their completion times T will differ. Additionally, thehistory of frequency changes affects the processing speed ofGPUs, leading to variations in the completion time T."}, {"title": "4 Methodology", "content": "In this section, we first model online energy consumption inGPUs as a multi-armed bandit problem, and then propose aENERGYUCB framework for it."}, {"title": "Modeling Online Energy Consumption in GPUs", "content": "We model online energy consumption in GPUs as a multi-armed bandit problem, including frequency modeling, re-ward formulation, and time cost modeling.\nFrequency Modeling. Modern circuit technologies inte-grate voltage regulates in a chip, supporting DVFS. In thisregard, GPUs in Aurora system support software control-lable, discrete voltage and frequency states that can be ad-justed to meet specific performance and energy goals. Thereare finite discrete GPU core frequencies available in the sys-tem. In a formal way, let $f_i$ be a frequency and K be thenumber of frequencies. We can model multiple frequencychoices ${f_1, f_2,...,f_k}$ as a set of arms ${1,2, . . ., K}$.For example, the GPU core frequencies can be adjustedfrom 0.8GHz to 1.6GHz with 0.1GHz interval, i.e., $f_i E${0.8GHz, 0.9GHz, . . ., 1.6GHz}. By modeling frequenciesas arms, we define the exploration space of the algorithm asa finite set of K frequency options. The bounded space en-ables the algorithm quickly identify the optimal frequency,thus ensuring energy savings. Note that we do not have tomodel the state, a concept that is typically required in re-inforcement learning (RL) (Kaelbling, Littman, and Moore1996). The burdensome design of states in RL leads to longconvergence time (Beggs 2005), during which a large quan-tity of energy will be wasted.\nReward Formulation. The modeling of the reward func-tion is crucial to guiding the convergence direction of thealgorithm. On Aurora supercomputer, the default setting op-erates at maximum frequency. Our objective is to minimizeenergy consumption by adjusting the GPU core frequencies.However, lowering the frequency reduces performance, ex-tending execution time T and potentially increasing over-all energy consumption. This intricate performance-energytrade-off requires careful design.\nPVC GPUs have a monotonic energy counter and a times-tamp counter to track energy consumption at each time stept. Therefore, the energy consumption between two times-tamps (t1, t2) can be calculated by taking the difference be-tween the respective records. However, explicit lightweightperformance counters that indicate the progress of offloadkernels are not available in the GPUs. To address the lim-itation, we propose to leverage the utilization metrics pro-vided by the GPUs. In detail, the GPUs have a active-time counter to record when the resource is actively run-ning workloads (Oneapi.org 2024) between two timestamps(t1, t2). The utilization is calculated by taking the percent-age of active time between the two timestamps. The utiliza-tion metric is essential in systems as it indicates the compo-nent currently used by the workload, allowing us to infer thebehaviors of the workload.\nIn this work, we leverage the ratio of GPU core utilization(including compute engines) and GPU uncore utilization (in-cluding copy engines responsible for data movement) as aneffective proxy for performance. A higher ratio indicates thatthe workload is compute-bound and more sensitive to corefrequency scaling, while a lower ratio suggests the workloadis memory-bound and more sensitive to data movement. Ac-"}, {"title": "5 Experiments", "content": "In this section, we introduce the details of experiments, in-cluding experimental setup and experimental results."}, {"title": "Experimental Setup", "content": "Experimental Platform. We conducted experiments on asingle node of the Aurora system as shown in Figure 2 withGEOPM (Global Extensible Open Power Manager) (Eastepet al. 2017) for telemetry monitoring and frequency con-trol. GEOPM is a versatile tool that allows users to mon-itor system energy and power consumption while optimiz-ing hardware settings to achieve energy efficiency or perfor-mance objectives. GEOPM consists of two primary compo-nents: the GEOPM Service and the GEOPM Runtime. TheGEOPM Service provides user-level access to detailed hard-ware metrics and control options through a secure interface.Concurrently, the GEOPM Runtime leverages the GEOPMService to adjust hardware settings based on real-time hard-ware metrics and feedback from application profiling.\nDataset Collection. We conducted our experiments usingthe SPEChpc 2021 benchmark suite (Li et al. 2022), specif-ically employing the MPI+OMP target offloading versionof the tiny benchmarks to fully leverage all six GPUs inthe system. The tiny suite consists of seven benchmarks:505.lbm, 518.tealeaf, 519.clvleaf, 521.miniswp, 528.pot3d,532.sph_exa, and 535.weather. All of them are used for datacollection. We set a 10ms sampling period for monitoringduring the experiments. For each application, we test allavailable frequencies and collect the corresponding traces.\nBaselines. To the best of our knowledge, this is the first workto address the problem of online GPU energy consumptionoptimization without relying on any offline training. To thisend, we compare ENERGYUCB with baselines as follows:\n\u2022 {1.6GHz, 1.5GHz,..., 0.8GHz} represent the availablefrequency options for GPU cores on the Aurora super-computer where the maximum frequency 1.6GHz is thedefault setting. Each frequency setting is static, meaningthat the GPU cores maintain this frequency throughoutthe entire execution time of an application.\n\u2022 RDFreq (Random Dynamic Frequency) selects a dif-ferent frequency at random at each time t.\n\u2022 RRFreq (Round-Robin Frequency) cycles througheach frequency in a circular order at each time t\n\u2022 (e-greedy) is a popular exploration & exploitation strate-gies in the literature. In our context, it explores less fre-quently chosen options with probability e and exploitsthe frequencies that have the highest reward according tohistory with probability 1 \u0395.\nMetrics. To evaluate the algorithms, we use energy con-sumption and cumulative regret discussed in the Section 3.\nImplementation Details. The available frequency optionsare {0.8GHz, 0.9GHz, ..., 1.6GHz}, with a total of K = 9choices. The frequency adjustment interval is set to 10ms,matching the sampling period of GEOPM. For ENER-GYUCB, We set C as 4 in the pure exploration phase anda as 1 in the exploration & exploitation phase. For e-greedyalgorithm, we choose \u20ac = 0.10. We repeat the experiments10 times and report average values to avoid randomness."}, {"title": "Experimental Results", "content": "Comparison of Energy Consumption. We compare theproposed ENERGYUCB with the baselines in terms of en-ergy consumption. The results are shown in the Table 1. Ac-cordingly, we have the following observations:\n\u2022 There is no single optimal static frequency for all HP applications. For instance, GPUs consume the least en-ergy when operating at 1.5 GHz for the 505.lbm appli-cation. However, for applications like 521.miniswp and532.sph_exa, the optimal frequency for minimal energyconsumption is 0.8 GHz. This variation occurs is becausedifferent applications, consisting of compute-bound ap-plications and memory-bound applications (Wang et al.2021b), exhibit different behaviors in response to fre-quency changes. For instance, 505.lbm is compute-bound, so lowering the frequency significantly extends itsexecution time, resulting in higher energy consumption."}, {"title": "6 Social Impact", "content": "The intersection of AI and HPC (Yi and Loia 2019; Xu et al.2023; Cruz-Camacho et al. 2023) is an active research topicwith significant potential to drive social development. Thiswork emerged from a close collaboration between AI andHPC experts. The HPC expertise played a pivotal role inshaping our approach, ensuring both practical applicabilityand potential impact, from problem selection to algorithmd"}]}