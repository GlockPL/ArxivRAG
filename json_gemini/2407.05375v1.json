{"title": "Online Drift Detection with Maximum Concept Discrepancy", "authors": ["Ke Wan", "Yi Liang", "Susik Yoons"], "abstract": "Continuous learning from an immense volume of data streams becomes exceptionally critical in the internet era. However, data streams often do not conform to the same distribution over time, leading to a phenomenon called concept drift. Since a fixed static model is unreliable for inferring concept-drifted data streams, establishing an adaptive mechanism for detecting concept drift is crucial. Current methods for concept drift detection primarily assume that the labels or error rates of downstream models are given and/or underlying statistical properties exist in data streams. These approaches, however, struggle to address high-dimensional data streams with intricate irregular distribution shifts, which are more prevalent in real-world scenarios. In this paper, we propose MCD-DD, a novel concept drift detection method based on maximum concept discrepancy, inspired by the maximum mean discrepancy. Our method can adaptively identify varying forms of concept drift by contrastive learning of concept embeddings without relying on labels or statistical properties. With thorough experiments under synthetic and real-world scenarios, we demonstrate that the proposed method outperforms existing baselines in identifying concept drifts and enables qualitative analysis with high explainability.", "sections": [{"title": "1 INTRODUCTION", "content": "Continuously learning from evolving data streams is crucial for numerous online services to derive real-time insights."}, {"title": "1.1 Background and Motivation", "content": "Continuously learning from evolving data streams is crucial for numerous online services to derive real-time insights [7, 58, 59].\n*Equal contributions. \u00a7 Corresponding author."}, {"title": "1.2 Main Idea and Challenges", "content": "Detecting concept drifts from data streams presents numerous challenges, mainly centered around the representation of ever-changing data distributions (i.e., concept representation) and the measurement of their differences (i.e., drift quantification). It also necessitates the continuous monitoring of the dynamic shifts in data distributions as they evolve, which is crucial for accurately identifying arbitrary drifts (i.e., online updates). Furthermore, in real-world scenarios, there is often a lack of ground truth labels for concept drifts as well as downstream tasks, making an unsupervised approach (i.e., data distribution-based) preferable to a supervised approach (i.e., error rate-based) in practice. To address these objectives, we propose a novel method for continuously identifying concept drifts in an unsupervised and online manner, that can effectively handle arbitrary data distributions with high interpretability.\nThe main idea of this work is to employ a new measure Maximum Concept Discrepancy for concept drift detection, inspired by the maximum mean discrepancy [44] with a kernel function. Through a deep neural network, we encode a set of sample data points in a short time period into a compact representation that captures the concept observed during the period. We leverage contrastive learning accompanied by time-aware sampling strategies to learn the embedding space of concepts. This entails the generation of positive sample pairs drawn from temporally proximate distributions and that of negative sample pairs from temporally distant distributions, while also introducing controlled perturbations. The embedding space is continuously updated to bring positive samples closer together and push negative samples further apart. Concept drifts are then identified by evaluating the discrepancy between the representations of concepts in consecutive time periods. In addition, the maximum concept discrepancy between two concepts can be bounded with a statistical significance. It can function as a theoretical threshold for detecting concept drifts, providing high interpretability and practicality for our method. In consequence, our method is capable of continuously identifying various types of concept drift from data streams without any supervision. It effectively addresses the aforementioned challenges for concept drift detection while keeping the advantages of both online statistical approaches and offline deep kernel-based approaches."}, {"title": "1.3 Summary", "content": "As a concrete implementation of our main idea, we propose an algorithm MCD-DD (Maximum Concept Discrepancy-based Drift Detector), aiming at unsupervised online concept drift detection from data streams. The main contributions of this work can be summarized as follows:\n\u2022 To the best of our knowledge, this is the first work to propose a dynamically updated measure, maximum concept discrepancy, for unsupervised online concept drift detection.\n\u2022 We propose a novel method MCD-DD equipped with the sample set encoder and drift detector, optimized by contrastive objective with time-aware sampling strategies. For reproducibility, the source code of MCD-DD is publicly available\u00b9.\n\u2022 Theoretical analysis of learning the maximum concept discrepancy provides its statistical interpretation and complexity.\n\u2022 Comprehensive experiments are conducted on 11 data sets with varying complexities of drifts. MCD-DD achieves state-of-the-art results in three performance metrics and demonstrates better interpretability in qualitative analysis, compared with baselines."}, {"title": "2 RELATED WORK", "content": ""}, {"title": "2.1 Concept Drift Detection", "content": "Concept drift detection is essential in employing a model robustly in data streams [1, 4, 19, 35]. Error rate-based drift detection is the most commonly used supervised method for detecting concept drift [6, 15, 33, 42, 56]. This approach continuously monitors the performance of downstream models in data streams. It relies on a trained predictive model and assesses whether concept drift has occurred by examining the consistency of the model's predictive performance over different time intervals [4]. For an unsupervised approach [20], it is common to conduct statistical tests on the two samples from different periods to determine whether they originate from the same concept [8, 23, 29, 34, 39], called data distribution-based detection, which is the scope of this work. While some error rate-based detectors [6, 38] can be adopted for this setting, it is not straightforward to apply them to multivariate data streams. It is also worth noting that some recent works try variants for concept drift detection with a pre-trained model [9, 62], active learning [63], imbalanced [31] or resource-constrained [52] streaming settings."}, {"title": "2.2 Contrastive Learning in Data Streams", "content": "Contrastive learning, as an effective self-supervised learning paradigm [10], is widely applied in various detection tasks in data streams [52, 54, 61]. The nature of data streams with scarce or delayed labels and lack of external supervision leads to the adoption of continual learning with contrastive losses. The pseudo-labeling for preparing positive and negative samples is a critical design factor and its strategy ranges from model confidence-based [61], learnable focuses [54], to class prototype [52] tailored for downstream tasks. Despite the advancements in contrastive learning, current techniques have yet to be explored for learning separable embeddings of probability distributions representing varying concepts or for application in two-sample tests with statistical bounds, both of which are addressed in this study."}, {"title": "2.3 Maximun Mean Discrepancy", "content": "The utilization of Maximum Mean Discrepancy (MMD) has been widespread, primarily serving to map data into high-dimensional spaces and thereby enhancing separability for downstream tasks [28]. MMD has been also actively applied for designing generative models [13, 32] and detecting whether two samples originate from the same distribution [22] with the Gaussian kernel function [23] or the deep kernels [34] to achieve greater flexibility and expressiveness. The idea of Maximum Concept Discrepancy (MCD) in this study draws inspiration from MMD-based approaches but is specifically tailored for unsupervised online concept drift detection by integrating a deep encoder for sample sets to represent data distributions and continuous learning strategies to dynamically optimize the projected space encompassing varying concepts."}, {"title": "3 PRELIMINARIES", "content": ""}, {"title": "3.1 Concept Drift", "content": "Concept drift is a phenomenon referring to the arbitrary changes in the statistical properties of a target domain of data over time. Formally, concept drift at time t is defined as the change in the joint probability of data points X and labels y at time t, denoted as \\(P_t(X, y) \\)\u2260 \\(P_{t+1}(X, y)\\). Concept drift primarily originates from one of the following three sources [35]: (i) \\(P_t(Y|X) \\)\u2260 \\(P_{t+1}(Y|X)\\), when the conditional distribution of the target variable Y given the covariate X undergoes drift; (ii) \\(P_t(X) \\)\u2260 \\(P_{t+1}(X)\\), when the distribution of the covariate experiences drift; and (iii) combination of (i) and (ii). In addition to varying sources, concept drift can also be distinguished into four types based on the specific nature of the drift occurrence: sudden, reoccurring, gradual, and incremental. For additional references, we direct readers to recent surveys [1, 4, 35].\nThis work aims to develop an unsupervised method for detecting various types of drift caused by the source described in (ii)."}, {"title": "3.2 Problem Setting", "content": "Given a continuously evolving data stream \\(X = \\{x_t\\}_{t=0}^{\\infty}\\), we maintain the latest context of the data stream by employing a sliding window \\(W_t\\) of size W updated by a slide of size S (i.e., \\(W_t = \\{x_{t-i}\\}_{i=0}^{W-1}\\) and \\(S_t = \\{x_{t-i}\\}_{i=0}^{S-1}\\)). The window and slide sizes can be defined either in terms of the number of data points or a time period.\nThen, a window \\(W_t\\) consists of non-overlapping slides indexed by \\(j = 1,..., N_{sub}\\) where \\(N_{sub} = W/S\\) is the number of slides in a window (i.e., \\(W_t = \\bigcup_{j=1}^{N_{sub}} S^j\\) and \\(S^j = \\{x_{t-(N_{sub}-j)*S-i}\\}_{i=0}^{S-1}\\)). In the rest of the paper, we use the term sub-window instead of slide for consistency. It is worth noting that the context within a sub-window is set to be sufficiently compact to ensure that the data points it contains adhere to the same underlying distribution.\nFor every sliding window in X, the problem of unsupervised online concept drift detection is to identify whether the concept drift has occurred in a new sub-window \\(S^{N_{Sub}}\\) compared with the existing data points in the current window \\(W_t \\backslash S^{N_{Sub}}\\, without using any labels for drifts and downstream tasks."}, {"title": "3.3 Maximum Mean Discrepancy", "content": "Maximum Mean Discrepancy (MMD) [44] is a statistical measure that compares two probability distributions through a kernel, especially when the distributions are unknown and only samples are available. MMD evaluates the distance between the mean embeddings of two distributions in the Reproducing Kernel Hilbert Space (RKHS) H [5]. Given \\(X \\sim P\\), \\(Y \\sim Q\\), and a kernel \\(f(\\cdot)\\), we have:\n\\[\nMMD(P, Q) = \\sup_{f \\in H, ||f||_H \\le 1} ||E[f(x)] - E[f(Y)]||^2.\n\\]\nWhen we have samples \\(\\{X_i\\}_{i=1}^n\\) from probability distribution P and \\(\\{Y_i\\}_{i=1}^n\\) from probability distribution Q, the empirical Maximum Mean Discrepancy (MMD) can be written as:\n\\[\nMMD(P, Q) = \\sup_{f \\in H, ||f||_H \\le 1} ||\\frac{1}{n} \\sum_{i=1}^n f(X_i) - \\frac{1}{n} \\sum_{i=1}^n f(Y_i)||^2.\n\\]"}, {"title": "4 PROPOSED METHOD", "content": ""}, {"title": "4.1 Overview", "content": "The proposed method MCD-DD exploits maximum concept discrepancy for detecting concept drift, enabled by a deep encoder for data distribution embedding and contrastive learning for effective unsupervised training. The overall procedure of MCD-DD is illustrated in Figure 2 and outlined in Algorithm 1. For each new sliding window, MCD-DD follows the prequential evaluation scheme (i.e., test-and-train) [18]. First, MCD-DD samples sets of data points in sub-windows and embeds them through a sample set encoder. The discrepancy between sample sets from adjacent sub-windows is calculated, and if it exceeds a threshold, MCD-DD asserts that concept drift has occurred between them. Second, the sample set encoder is updated by considering the sliding window as the context for learning the latest concepts. Specifically, we treat sample sets from the same sub-window as positive pairs and construct negative pairs by leveraging temporal gaps between sub-windows and noise augmentation to distort the original distribution. In the meantime, MCD-DD dynamically adjusts the threshold for drift detection in the next sliding window by analyzing the positive sample pairs. Finally, the encoder is updated by aiming to minimize the distance between embeddings of positive sample pairs while simultaneously maximizing the distance between those of negative pairs."}, {"title": "4.2 Sample Set Encoder", "content": "We use a set of data points sampled in each sub-window to estimate its data distribution that represents a concept in the sub-window. Specifically, for a given sub-window \\(S^j \\subset W_t\\), we perform sampling without replacement from it to obtain a sample set of size m:\n\\[\nM_j = \\{x_i \\in S^j\\}_{i=1}^m\n\\]\nThe sample set is passed to a sample set encoder, denoted as set-enc(). It translates the probability distribution \\(P_t(S^j)\\) of the sub-window into the compact representation in the projected space, which we call concept representation \\(h^j\\) of \\(S^j\\):\n\\[\nh^j = \\text{set-enc}(M_j) = \\frac{1}{m} \\sum_{i=1}^m f(x_i \\in M^j),\n\\]\nwhere \\(f(\\cdot)\\) is an encoding model with a deep neural network."}, {"title": "4.3 Drift Detector", "content": "For each sub-window \\(S^j\\) in a sliding window \\(W_t\\), we obtain the concept representations \\(\\{h^j\\}_{j=1}^{N_{sub}}\\) by the sample set encoder. Then, to effectively quantify the distance between the concept representations from two adjacent sub-windows, we introduce a new measure Maximum Concept Discrepancy (MCD) inspired by MMD:\n\\[\nMCD(P, Q) = \\sup_{||f||_2 \\le L} ||E[f(x)] - E[f(Y)] ||^2,\n\\]\nwhere the function \\(f(\\cdot)\\) is approximated by a deep neural network and is constrained to be Lipschitz continuous [21]. This ensures the convergence of optimizing f and prevents MCD from becoming infinitely large. Moreover, it makes MCD between two sets of independent data from the same distribution bounded, providing the theoretical foundation for our drift detection.\nWhen we have samples \\(M^j \\sim P\\) and \\(M^{j'} \\sim Q\\) by Eq. (3), the empirical MCD can be derived from Eq. (5) and Eq. (4) as:\n\\[\nMCD(P, Q) = \\sup_{||f||_2 \\le L} ||\\frac{1}{m} \\sum_{i=1}^m f(x_i \\in M^j) - \\frac{1}{m} \\sum_{i=1}^m f(x_i \\in M^{j'})] ||^2\n\\]\n\\[\n= \\sup_{||f||_2 \\le L} ||h^j - h^{j'}||^2\n\\]\nBased on MCD, if the discrepancy between the data distributions of two adjacent sub-windows exceeds a given threshold \\(\\sigma\\),\n\\[\nMCD(P_t(S^j), P_t(S^{j-1})) = ||h^j \u2013 h^{j-1}||^2 > \\sigma,\n\\]\nthen we determine that a concept drift happened between them:\n\\[\nP_t(S^j) \\neq P_t(S^{j-1}).\n\\]\nThe threshold \\(\\sigma\\) can be controlled dynamically using a bootstrapping strategy, allowing it to adjust to the varying distances between sample sets within the same concept. By analyzing the historical collection of MCD values between sample sets in the same sub-windows (i.e., those with identical data distributions), we adjust the threshold \\(\\sigma\\) for each sliding window within a predefined statistical significance level (e.g., 0.05). It is worth noting that this historical MCD information can be obtained during the optimization of the encoder without necessitating additional computations."}, {"title": "4.4 Optimization", "content": "To optimize the sample set encoder, we employ contrastive learning [27] to enhance the separability of various concepts. The primary challenge lies in determining positive and negative sample pairs that are to be closer and further apart, respectively. This challenge is particularly pronounced in unsupervised scenarios, where we lack any prior information regarding the underlying concepts and true drifts. In MCD-DD, we exploit the concept of temporal coherence [43, 53], which is a fundamental characteristic observed in temporal data. It suggests that data points that are close in time are more likely to exhibit similar characteristics. We exploit this insight to create positive and negative samples used for optimization."}, {"title": "4.4.1 Preparing Positive Samples", "content": "MCD-DD generates a positive sample pair by choosing two sets of data points from the same sub-window, assuming that these sets follow the same distributions.\nIn each sub-window \\(S^{t_j}\\), MCD-DD conducts sampling similar to Eq. (3) to select two sets of data points, which we treat as positive sample pairs. These pairs are denoted as \\(M_{p1i}\\) and \\(M_{p2i}\\). To generate a diverse set of positive sample pairs, we repeat this sampling process k times, resulting in \\(\\{M_{p1i}\\}_{i=1}^k\\) and \\(\\{M_{p2i}\\}_{i=1}^k\\). Subsequently, the sample set encoder in Eq. (4) computes the embeddings for the k positive sample pairs, yielding \\(\\{h_{p1i}\\}_{i=1}^k\\) and \\(\\{h_{p2i}\\}_{i=1}^k\\)."}, {"title": "4.4.2 Preparing Negative Samples", "content": "MCD-DD generates a negative sample pair to learn diversity in concept drift. Specifically, MCD-DD selects two sets of data points respectively from the different sub-windows that are temporally distant, whose distributions are likely to differ. MCD-DD also employs an efficient data augmentation technique to improve the generalization of negative pairs by introducing noise to each sampled data point:\n\\[\nx' = x + \\delta,\n\\]\nwhere the noise \\(\\delta\\) is generated from a standard probability distribution (e.g., the Gaussian distribution \\(G(\\mu, \\epsilon)\\)). By incorporating these two principles, temporal gap (i.e., drift diversity) and noise augmentation (i.e., concept diversity), we prepare two types of negative sample pairs.\nWeak negative samples: The first type of negative samples involves sampling pairs of data points from the same sub-windows but adding a small degree of noise into one of the sets. Specifically, given a sub-window \\(S^{t_j}\\), the k weak negative sample pairs are prepared:\n\\[\n\\{M_{wn1}^i\\}_{i=1}^k \\text{ and } \\{M_{wn2}^i + \\delta_1\\}_{i=1}^k,\n\\]\nwhere \\(\\delta_1 \\sim G(0, \\epsilon_{small})\\) and G is a Gaussian distribution. Finally, the corresponding two set sample embeddings are derived:\n\\[\n\\{h_{wn1}^i\\} \\text{ and } \\{h_{wn2}^i\\}\n\\]\nStrong negative samples: The second type of negative samples involves sampling pairs of data points from the two sub-windows that are temporally distant and more substantial noise is added to one of the sets. Specifically, given a sub-window \\(S^{t_j}\\) and \\(S^{t_{j'}}}\\), the k strong negative sample pairs are prepared:\n\\[\n\\{M_{sn1}^i\\}_{i=1}^k \\text{ and } \\{M_{sn2}^i + \\delta_2\\}_{i=1}^k,\n\\]\nwhere \\(\\delta_2 \\sim G(0, \\epsilon_{big})\\). Similarly, the corresponding two set sample embeddings are derived:\n\\[\n\\{h_{sn1}^i\\} \\text{ and } \\{h_{sn2}^i\\}.\n\\]\nNote that the temporal gap between two sub-windows can be adjusted within the context of a window (i.e., \\(1 \\le |j-j'| \\le N_{sub}-1\\)). By default, MCD-DD adopts the largest temporal gap by setting \\(j' = N_{sub}\\) and \\(j = 1\\) so as to maximize the likelihood that the samples within each window exhibit distinct data distributions."}, {"title": "4.4.3 Learning Objective", "content": "By putting the positive, weak negative, and strong negative samples altogether, the final loss for the sample set encoder is formulated in the form of InfoNCE loss [37]:\n\\[\nL = \\log \\sum_{j=1}^{N_{sub}} \\sum_{k=1}^k \\frac{\\exp(MCD_{p1})}{\\exp(MCD_{p2}) + \\exp(MCD_{wn}) + \\exp(MCD_{sn})} + \\frac{\\lambda}{m} \\sum_{i=1}^{m} (||\\sqrt{x_i} f(x_i)||_2 - L)^2,\n\\]\nwhere \\(MCD_{p2} = ||h_{p1}^j - h_{p2}^j||^2\\), \\(MCD_{wn} = ||h_{wn1}^j - h_{wn2}^j||^2\\), and \\(MCD_{sn} = ||h_{sn1}^j - h_{sn2}^j||^2\\) are MCD values between the probability distributions of two sub-windows chosen for each sample type. The last term is the gradient penalty to ensure the L-Lipschitz continuity [26] of the encoding model \\(f(\\cdot)\\) where L is a constant and the coefficient \\(\\lambda\\) is the regularization parameter."}, {"title": "5 THEORETICAL ANALYSIS", "content": ""}, {"title": "5.1 Upper Bound of MCD", "content": "Given two sample sets of data points drawn from the same distribution, we study the upper bound of MCD between the two sets, which can serve as a theoretical threshold for detecting concept drifts in two sub-windows for MCD-DD.\nTheorem 1. Assume that the sets \\(\\{X_i\\}_{i=1}^n\\) and \\(\\{Y_i\\}_{i=1}^n\\) are independently and identically distributed (i.i.d.), both drawn from the probability distribution \\(p(x)\\) with a mean \\(\\mu\\) and variance \\(\\sigma\\). If f is a Lipschitz continuous function with Lipschitz constant L, we have:\n\\[\nP( | \\sum_{i=1}^n f(X_i) - \\sum_{i=1}^n f(Y_i) | > G(1-\\frac{\\alpha}{2}) \\sqrt{\\frac{L^2 \\sigma^2}{n}} ) \\le \\alpha,\n\\]\nwhere G() is the standard Gaussian distribution function. Therefore, for a given significance level \\(\\alpha\\), \\(G(1-\\frac{\\alpha}{2}) \\sqrt{\\frac{L^2 \\sigma^2}{n}}\\) is an upper bound for the MCD \\(|\\sum_{i=1}^n f(X_i) - \\sum_{i=1}^n f(Y_i)|\\).\nPROOF. By the Central Limit Theorem, \\(\\sum_{i=1}^n f(X_i) - \\sum_{i=1}^n f(Y_i)\\) converges to the Guassain distribution. Moreover, we have:\n\\[\nE( \\sum_{i=1}^n f(X_i) - \\sum_{i=1}^n f(Y_i)) = 0.\n\\]\nSince f is a L-Lipschitz continuous function, we have:\n\\[\nVar( \\sum_{i=1}^n f(X_i) - \\sum_{i=1}^n f(Y_i)) \\le \\frac{2L^2\\sigma^2}{n}.\n\\]\nWhen we approximate the distribution of \\(\\sum_{i=1}^n f(X_i) - \\sum_{i=1}^n f(Y_i)\\) as the Gaussian distribution, we have:\n\\[\nP( | \\sum_{i=1}^n f(X_i) - \\sum_{i=1}^n f(Y_i) | > G(1-\\frac{\\alpha}{2}) \\sqrt{\\frac{L^2 \\sigma^2}{n}} ) \\le \\alpha.\n\\]\nTherefore, for the null hypothesis \\(H_0: \\{\\{X_i\\}_{i=1}^n\\} \\text{ and } \\{\\{Y_i\\}_{i=1}^n\\}\\) are drawn from the same probability distribution, given a significance level \\(\\alpha\\), \\(G(1-\\frac{\\alpha}{2}) \\sqrt{\\frac{L^2 \\sigma^2}{n}}\\) can serve as the threshold for rejecting \\(H_0\\). In the scenario where \\(\\{X_i\\}_{i=1}^n\\) and \\(\\{Y_i\\}_{i=1}^n\\) are multivariate random variables, hypothesis testing can similarly be conducted using the chi-squared distribution.\nThis theoretical bound can serve as a guide to set the threshold in a hypothesis testing framework. However, deriving the exact rejection threshold analytically may not always be feasible. As suggested in Section 4.3, the empirical threshold for rejecting the null hypothesis can be used by estimating statistics of historical MCD values meeting the hypothesis with a pre-defined significance."}, {"title": "5.2 Complexity of MCD-DD", "content": "We analyze the time complexity of MCD-DD mainly for sampling, training, and inference. Recall that we use a sliding window with \\(N_{sub}\\) sub-windows, k sets of m samples, and an encoder with the parameter size p and training epochs e. Since we sample in each sub-window, the time complexity for constructing positive and negative samples is \\(O(mkN_{sub})\\). The time complexity for training the encoder is \\(O(mkep)\\). For inference, since we need to calculate the differences of sample sets in each sub-window sequentially, the time complexity is \\(O(mkN_{sub}^2)\\). Finally, the total complexity is \\(O(mk(N_{sub}^2 + ep))\\). Since typically p > e, m, k, \\(N_{sub}\\), the time complexity of MCD-DD is mostly controlled by the encoder complexity."}, {"title": "6 EXPERIMENTS", "content": "We conducted thorough experiments to evaluate the performance of MCD-DD on 7 synthetic data sets and 4 real-world data sets. The results are briefly summarized as follows:\n\u2022 MCD-DD outperforms existing baselines in detecting concept drifts in terms of Precision, F1, and MCC scores and shows high interpretablity with varying drift types (Section 6.2).\n\u2022 Through ablation analysis, the three sampling strategies introduced in contrastive learning for MCD are demonstrated to be effective (Section 6.3)."}, {"title": "6.2 Drift Detection Accuracy", "content": "6.2.1 Synthetic Data Sets. As shown in Table 2, MCD-DD achieved the highest precision across all simulated data sets, with the scores being almost all 1 or very close to 1, demonstrating its Eagle Eye capability in drift point detection. Moreover, except for data sets with incremental drift, our method outperformed others in terms of F1-score and MCC as well.\nVisualization of MCD in each window: In Figure 3, We further analyzed the concept drift capability of MCD-DD. We calculated MCD values between the most recent data distributions in each new sub-window (SNsub) and all preceding data distributions within the same window (SN\u00b9 to SNsub-1). The horizontal axis represents the locations of Ssub at each time step t, and the vertical axis encompasses preceding sub-windows in the same window. Then, each cell indicates the learned MCD between sub-window pairs. For various types of concept drift, the heatmap patterns exhibit distinctive shapes: sudden drift manifests as lower triangular patterns starting at the drift point, reoccurring drift as two lower triangles, gradual drift progressively forms lower triangular patterns from top to bottom, and incremental drift results in fainter lower triangles due to more subtle distributional changes. We further investigated the model's performance with even more subtle and slower incremental drifts and real-world data sets in Appendix A.3. These demonstrations highlight the interpretive strength of MCD-DD in capturing the dynamics of drift occurrences.\n6.2.2 Real-world Data Sets. As shown in Table 2, MCD-DD demonstrated superior performances over other baseline algorithms across a variety of drift scenarios within the INSECTS, including INSECTS_Sud (sudden drift), INSECTS_Grad (gradual drift), and INSECTS_IncreRec (incremental drift and reoccurring). Figure 4 shows the heatmap of MCD for INSECTS_Sud. These results highlight MCD-DD's robust capability in effectively detecting and adapting to different types of drift phenomena, ranging from abrupt changes to slow evolutions and cyclic variations. Despite exhibiting slightly weaker performance than MMD-DK when applied to the EEG, known for its high frequency of sudden drifts, it is noteworthy that MCD-DD still consistently achieved the highest MCC value."}, {"title": "6.3 Ablation Study", "content": "We conducted ablation studies on the strategies for obtaining positive and negative sample pairs. Specifically, we evaluated the performance of MCD-DD under various configurations: the complete MCD-DD setup, MCD-DD without weak negative sample pairs (i.e., MCD-DD-WN), MCD-DD without strong negative sample pairs (i.e., MCD-DD-SN), and MCD-DD utilizing only positive sample pairs, eliminating all negative samples (i.e., MCD-DD-(WN,SN)).\nFigure 5 shows the results of precision, while the results of other metrics showed similar trends (Appendix A.3). In summary, MCD-DD achieved the highest precision across all data sets and the absence of each type of negative sample pairs leads to lower performances in most cases. Specifically, removing weak negative sample pairs resulted in diminished effectiveness in detecting gradual, subtle concept drifts, like GM_Rec and EEG. Eliminating strong negative sample pairs adversely affected performance in more challenging drift detection scenarios (e.g., high overlap distributions, incremental drift), even failing to identify any drifts GamLog_Sud, along with notably poor performances in GM_Inc and INSECTS_Grad. Retaining only positive sample pairs yielded comparable results in simpler tasks but significantly underperformed in more complex simulated and real-world data sets compared to strategies incorporating negative sample pairs. These ablation study findings demonstrate the efficacy of the sampling strategies proposed particularly in dealing with complex drift scenarios."}, {"title": "6.4 Sensitivity Analysis", "content": "6.4.1 Effects of main Hyperparameters. We conducted a sensitivity analysis of the main hyperparameters used in MCD-DD: the sliding window size W, the number of samples k, the degree of noise \\(\\epsilon\\), and the regularization coefficient \\(\\lambda\\). Figure 6 shows the MCC results on the synthetic data sets, and the results of other metrics showed similar trends. For W we varied it from half to two times the default value. Figure 6a demonstrates that MCD-DD shows comparable performances over varying window sizes with the peak performances at window sizes around the default value. Since the window size determines the context of current concepts used for training the encoder, the smaller size is preferable in practice for efficiency, as long as it includes temporally distant different distributions. Regarding the number k of sampling in each sub-window, Figure 6b shows that the higher number of sampling leads to increased performance. Nevertheless, sampling frequencies beyond the default value (k = 10) lead to only marginal improvements. In constructing negative sample pairs, the perturbation degree \\(\\delta\\) with \\(\\epsilon_{small}\\) and \\(\\epsilon_{big}\\) controls the relative degrees of noise for weak and strong negative samples. Figure 6c indicates that too low or too high ratios of small and big noise perform poorly, particularly in challenging cases (e.g., GamLog_Sud and LogGamWei_Sud). The default ratios of 1: 10 were demonstrated to be the most optimal in most cases. Finally, regarding the regularization coefficient \\(\\lambda\\) for gradient penalty to ensure L-Lipschitz continuity in the optimization, Figure 6d shows that either too light or too heavy penalties can reduce the model's effectiveness on challenging cases, making \\(\\lambda\\) = 1 a suitable choice.\nFigure 7 shows the sensitivity analysis results on real-world data sets, demonstrating similar trends with the synthetic data sets. While the default values for W are not annotated in the figure given the varying lengths of each data set, it is found that setting W to 10% of the total length of each data set is a suitable choice.\n6.4.2 Effects of Encoder Size. We also conducted a sensitivity analysis of the encoder on processing time (Table 3) and detection accuracy (Figure 8) by varying its hidden size from 50 to 300. The results indicate that, in general, the encoder's hidden size does not have a significant impact on performance. However, particularly in the data streams with complex drifts (e.g., GamLog_Sud or GamGM_SudGrad), the encoder with too low or too high hidden sizes degrades the detection accuracy owing to lacking expressiveness or overfitting in representing the complex concepts."}, {"title": "6.5 Qualitative Analysis", "content": "To more vividly showcase how MCD-DD maps original data distributions to the appropriate embedding space, facilitating the identification of varying distribution changes, we visualized the embedding spaces generated from the compared algorithms in two-dimensional space by t-SNE [48]. The seven challenging distributions used to generate data points are detailed in Appendix A.4. In Figure 9, points in each t-SNE plot demonstrate the representations of a set of data, including 500 data points. Different colors represent their different underlying probability distributions. Figure 9a demonstrates the difficulty of distinguishing distributions in the original space, showing highly intermingled clusters. Figure 9b shows that the Gaussian kernel mapping used by MMD-GK uniformly distributes all distributions across the space, aligning with the outcomes of prior studies [34]. While the deep kernel by MMD-DK achieved more separable embeddings, as shown in Figure 9c, MCD-DD exhibits even better separation, particularly in handling more complex distributions. This aspect justifies the superior performance of MCD-DD in concept drift detection across various scenarios."}, {"title": "6.6 Drift Detection Threshold Analysis", "content": "As discussed in Section 4.3, the drift detection threshold \\(\\sigma\\) of MCD-DD is dynamically controlled by tracking the historical MCD values with a predefined statistical significance level (e.g., 0.05). To further understand its dynamicity, we analyzed the changes in the threshold over sliding windows in synthetic data sets with different drift types. Figure 10 shows that the thresholds were consistent over time in most cases, indicating that MCD is optimized robustly to varying drift types. GM_Grad notably exhibited a significant increase in the threshold values after the first drift was observed around 10,000, but it quickly converged to a constant value and the corresponding detection accuracy remained high as shown in Section 6.2."}, {"title": "7 CONCLUSION", "content": "We proposed MCD-DD, an unsupervised online concept drift detection method, exploiting a new measure called maximum concept discrepancy. MCD-DD leverages contrastive learning to obtain quality concept representations from sampled data points and optimize the maximum concept discrepancy. It is facilitated by sampling strategies based on temporal consistency and perturbations for robust optimization. The theoretical analysis demonstrated that MCD-DD can also be used within the hypothesis testing framework. Experimental results on multiple synthetic and real-world data sets showed that the proposed method achieves superior detection accuracy and higher interpretability than existing baselines.\nFor future work, we consider exploiting MCD histories learned throughout data streams. It can provide a systematic understanding of the patterns, duration, and strengths of concept drifts, as glimpsed in the heatmap visualization analyses. Further, assuming partial concept labels are available, adopting weak supervision philosophy can be promising. Estimating the degree of differences between partially labeled concepts can function as pseudo-labels to help us optimize the encoder more effectively."}, {"title": "A APPENDIX", "content": ""}, {"title": "A.1 Data Sets", "content": "A.1.1 Synthetic Data Sets. The synthetic data sets used for model performance evaluation feature two types of drifts: primary and complex. Primary drift tasks involve concept drifts that are relatively easy to distinguish within the data stream. Complex drift tasks, however, present higher distribution similarity, increased dimensionality, and a greater number of drift events, making them more challenging to discern.\nFor primary tasks, drift is simulated by adjusting the weighting of two Gaussian distributions, \\(G_1\\) and \\(G_2\\). Both distributions conform to a 5-dimensional Gaussian distribution with a mean vector \\(\\mu = [20, 20, 20, 20, 20]\\) and covariance matrices \\(\\Sigma_1 = 10^2I\\) and \\(\\Sigma_2 = 50^2I\\), where I denotes the identity matrix. These distributions form the basis for diverse Gaussian mixtures, with the weighting factor p controlling the proportion of each distribution in the mixture. The mixture model is represented by the equation: \\(N(\\mu, \\Sigma_1) \\times p + N(\\mu, \\Sigma_2) \\times (1 \u2013 p)\\). Each primary drift task involves a data set of 30,000 instances. Within this framework, different types of primary drift tasks are simulated by varying p:\nPrimary Task 1-GM_Sud: Initially, p is set to 0.2. To induce a sudden drift at the 21,000th instance, p is shifted to 0.8, significantly changing the mixture's composition and simulating a sudden change in the underlying data structure.\nPrimary Task 2-GM_Rec: Initially, p is set to 0.8, giving prominence to \\(G_1\\). At the 15,000th instance, p changes to 0.2, thus shifting the mixture's balance towards \\(G_2\\). Finally, at the 25,000th instance, p returns to 0.8, reinstating the initial distribution emphasis. This pattern creates a reoccurring drift in the data stream.\nPrimary Task 3-GM_Inc: Initially set at 0.2, the weighting factor p undergoes specific adjustments to introduce incremental drifts at predetermined intervals within the data set. Specifically, p linearly increases from 0.2 to 0.8 between the 12,000th and 12,600th instances, then decreases back to 0.2 between the 18,000th and 19,200th instances, and finally increases again to 0.8 between the 24,000th and 25,200th instances. Outside these intervals, p remains constant, ensuring no drift occurs in the intervening segments. This design results in multiple incremental drifts across the data set. These linear transitions facilitate incremental drifts, modifying the data distribution across two Gaussian components.\nPrimary Task 4-GM_Grad: In the gradual drift task, p fluctuates between 0.2 and 0.8. The drift periods where p = 0.8 occur during the intervals (10000, 11000), (12001, 15000), and (18000, 21000). Conversely, in the intervening periods (11001,12000), (15001,18000), and (21001,24000), p reverts to 0.2. This oscillation creates a gradual drift pattern by alternating phases of drift and stability.\nComplex drift tasks, conversely, involve a mixture of distributions like Gamma, Lognormal, and Weibull. These distributions exhibit substantial overlap in their probability density functions and possess similar statistical characteristics, leading to lower discriminability and making the detection of drifts more challenging. These tasks are further compounded by introducing multiple drifts of different natures within the data stream. Also, each complex drift task involves a data set of 30,000 instances, where every dimension conforms to the same distribution pattern, ensuring consistency across the multidimensional data space.\nComplex Task 1-GamLog_Sud: Initially, data is generated from a Gamma distribution (Gamma (1.5, 20)) across 5 dimensions. At the 21,000th instance, there is a sudden shift to a 5-dimensional Log-normal distribution with parameters \\(\\mu = log(30) \u2013 0.5\\) and \\(\\sigma = 0.5\\). This transition represents a complex and sudden drift, with the overlap between the two distributions making the drift challenging to identify.\nComplex Task 2-LogGamWei_Sud: The data stream, consisting of 20 dimensions, initially follows a Log-normal distribution (Lognormal(log(30) \u2013 0.5,0.5)). At the 15,000th instance, there is a sudden drift to a Gamma distribution (Gamma (1.5, 20)), and at the 24,000th instance, it transitions to a Weibull distribution (Weibull(1.5, 20)). These successive drifts add higher complexity.\nComplex Task 3-GamGM_SudGrad: This data stream consists of 20 dimensions, each following the same distribution. Initially, the data follows a Gamma distribution (Gamma(2, 10)). At the 11,000th instance, a sudden drift occurs, transitioning the data to a Gaussian mixture. Subsequently, the task experiences gradual drifts, where the weighting factor p alternates between 0.2 and 0.8 during specific intervals. This alternation leads to shifting dominance between two Gaussian distributions (N(20, 102) and N(20, 502)), creating a complex pattern of both sudden and gradual drifts.\nA.1.2 Real-World Data Sets. Here we provide detailed descriptions of the real-world data sets employed to evaluate the performance of our detector: INSECTS and EEG. These data sets are instrumental in assessing how effectively the detector adapts to real-world concept drift scenarios.\nINSECTS: The INSECTS data sets consist of optical sensor readings obtained from monitoring mosquitoes. Concept drifts are induced by varying temperatures, which affect the insects' activity levels in alignment with their circadian rhythms. This data set offers a dynamic setting of concept drifts. We utilized three specific data sets from the collection, each representing one or more distinct types of drift: (i) INSECTS_Sud: This subset exhibits five sudden drifts, initiated at a temperature of 30\u00b0C, with a sudden shift to 20\u00b0C, and subsequently to approximately 35\u00b0C among other changes. The stream captures several rapid transitions in temperature, illustrating sudden concept drifts throughout. (ii) INSECTS_Grad: Illustrating both gradual and incremental drifts, this data set simulates a scenario where temperatures slowly transition over time, presenting a nuanced evolution of environmental conditions. (iii) INSECTS_IncreRec: Features a unique pattern of reoccurring incremental drifts, where temperature gradually increases or decreases in cycles. This data set is pivotal for studying the model's performance in scenarios where drift patterns repeat over time, challenging the detection mechanism with both incremental and reoccurring drift phenomena.\nEEG: The EEG data set encompasses multivariate time-series data from a single continuous EEG recording using the Emotiv EEG Neuroheadset over a span of 117 seconds. Eye states were captured through video recording concurrent with the EEG data collection and were subsequently annotated manually to indicate moments of eye closure (\"1\") and eye opening (\"0\"). This data set provides a sequential record of neurological activity, with values arranged in the order they were measured, presenting a unique challenge for detecting shifts in physiological states over time."}, {"title": "A.2 Implementation Details", "content": "A.2.1 Implementation of compared algorithms. For MCD-DD, we set m = 30 (or 50 for a larger sub-window size such as in INSECTS_IncreRec), k = 10, \\(\\lambda\\) = 1, \\(\\epsilon_{small}\\) = 1, \\(\\epsilon_{big}\\) = 10, and L = 1. The encoder function was implemented as a two-layer MLP with a ReLU activation function. For synthetic data sets, the two-layer encoder features 100 units in both hidden and output layers. For the INSECTS data set, reflecting its more complex drift types and higher dimensionality, the encoder dimensions are increased to 200 (hidden) and 150 (output). For the EEG data set, which involves smaller window sizes, the dimensions are adjusted to 150 (hidden) and 100 (output). In all data sets, the encoder function has been trained for a single epoch with a learning rate of 0.005 for every sliding window. For the implementation of baselines, we referred to alibi-detect [49] and used sufficiently high permutations (200) for the statistical method and the default projection and the best epochs for the learning-based method.\nA.2.2 Evaluation Scheme. For a fair comparison, all algorithms followed the prequential evaluation scheme [18] and used the same sliding window with the window size W of 10% of the total length of each data set and \\(N_{sub}\\) = 10. Each algorithm compares every new sub-window with the preceding one in a window to identify concept drift with a significance level of 0.05 if applicable.\nA.2.3 Computing Platform. All experiments were conducted on a Linux server equipped with an Intel Xeon CPU @ 2.20GHz, 12GB RAM, and 226GB of storage where Ubuntu 22.04 LTS, Python 3.10, and PyTorch 2.1.0+cu122 were installed. An NVIDIA Tesla V100-SXM2-16GB GPU was used for the deep learning-based algorithms."}, {"title": "A.3 Additional Performance Analysis Results", "content": "For subtle and slow drift types, we have considered adaptively adjusting the training process to achieve better detection outcomes. In this regard, an incremental drift was introduced by linearly transitioning the weighting factor p from 0.0 to 1.0 between the 15,000th and 24,000th instances. Specifically, for this incremental drift scenario, a specialized training strategy was implemented that alternates between exclusively using positive sample pairs and a mix of both positive and negative sample pairs, aimed at better adapting to and learning the nuanced shifts present. Keeping other parameters constant, MCD-DD achieved a precision of 0.80, significantly outperforming other baseline algorithms with a maximum precision of 0.55. Similar to the visualization discussed in Section 6.2, Figure 11a illustrates the progression of MCD in this scenario. In addition, Figures 11b and 11c show the heatmaps of MCD for the other two types of INSECTS data sets. While it is challenging to accurately identify the exact starting points for gradual and incremental drifts in real data streams, the heatmap shows higher MCD values around the true drift indicators (in the yellow boxes). Figure 12 shows the ablation study results with F1 and MCC. Table 4 compares the performance of MCD-DD with ADWIN [6] adopted for an unsupervised setting with unidimensional data stream."}, {"title": "A.4 Details of Qualitative Analysis", "content": "For the seven distributions, Dist1 is a normal distribution N (20, 102), generating samples in a 5-dimensional space. Dist2 is a normal distribution with increased variance N(20, 502). Dist3 is a mixture of two normal distributions, giving each sample a 50% probability of originating from either N(20, 102) or N(20, 502). Dist4 is a uniform distribution spanning from 0 to 40, U(0, 40). Dist5 follows a gamma distribution with shape and scale parameters set to 2 and 10, respectively, Gamma(2, 10). Dist6 utilizes a Weibull distribution with shape and scale parameters of 2 and 20, Weibull(2, 20). Lastly, Dist7 is a log-normal distribution chosen to approximate a mean close to 20 by setting a standard deviation of 0.5 and a location parameter \\(\\mu\\) to log(20) \u2013 0.52, Lognormal(\\((\\mu\\), 0.52)."}]}