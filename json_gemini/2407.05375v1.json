{"title": "Online Drift Detection with Maximum Concept Discrepancy", "authors": ["Ke Wan", "Yi Liang", "Susik Yoons"], "abstract": "Continuous learning from an immense volume of data streams becomes exceptionally critical in the internet era. However, data streams often do not conform to the same distribution over time, leading to a phenomenon called concept drift. Since a fixed static model is unreliable for inferring concept-drifted data streams, establishing an adaptive mechanism for detecting concept drift is crucial. Current methods for concept drift detection primarily assume that the labels or error rates of downstream models are given and/or underlying statistical properties exist in data streams. These approaches, however, struggle to address high-dimensional data streams with intricate irregular distribution shifts, which are more prevalent in real-world scenarios. In this paper, we propose MCD-DD, a novel concept drift detection method based on maximum concept discrepancy, inspired by the maximum mean discrepancy. Our method can adaptively identify varying forms of concept drift by contrastive learning of concept embeddings without relying on labels or statistical properties. With thorough experiments under synthetic and real-world scenarios, we demonstrate that the proposed method outperforms existing baselines in identifying concept drifts and enables qualitative analysis with high explainability.", "sections": [{"title": "1 INTRODUCTION", "content": "1.1 Background and Motivation\nContinuously learning from evolving data streams is crucial for numerous online services to derive real-time insights [7, 58, 59]."}, {"title": "2 RELATED WORK", "content": "2.1 Concept Drift Detection\nConcept drift detection is essential in employing a model robustly in data streams [1, 4, 19, 35]. Error rate-based drift detection is the most commonly used supervised method for detecting concept drift [6, 15, 33, 42, 56]. This approach continuously monitors the performance of downstream models in data streams. It relies on a trained predictive model and assesses whether concept drift has occurred by examining the consistency of the model's predictive performance over different time intervals [4]. For an unsupervised approach [20], it is common to conduct statistical tests on the two samples from different periods to determine whether they originate from the same concept [8, 23, 29, 34, 39], called data distribution-based detection, which is the scope of this work. While some error rate-based detectors [6, 38] can be adopted for this setting, it is not straightforward to apply them to multivariate data streams. It is also worth noting that some recent works try variants for concept drift detection with a pre-trained model [9, 62], active learning [63], imbalanced [31] or resource-constrained [52] streaming settings.\n2.2 Contrastive Learning in Data Streams\nContrastive learning, as an effective self-supervised learning paradigm [10], is widely applied in various detection tasks in data streams [52, 54, 61]. The nature of data streams with scarce or delayed labels and lack of external supervision leads to the adoption of continual learning with contrastive losses. The pseudo-labeling for preparing positive and negative samples is a critical design factor and its strategy ranges from model confidence-based [61], learnable focuses [54], to class prototype [52] tailored for downstream tasks. Despite the advancements in contrastive learning, current techniques have yet to be explored for learning separable embeddings of probability distributions representing varying concepts or for application in two-sample tests with statistical bounds, both of which are addressed in this study.\n2.3 Maximun Mean Discrepancy\nThe utilization of Maximum Mean Discrepancy (MMD) has been widespread, primarily serving to map data into high-dimensional spaces and thereby enhancing separability for downstream tasks [28]. MMD has been also actively applied for designing generative models [13, 32] and detecting whether two samples originate from the same distribution [22] with the Gaussian kernel function [23] or the deep kernels [34] to achieve greater flexibility and expressiveness. The idea of Maximum Concept Discrepancy (MCD) in this study draws inspiration from MMD-based approaches but is specifically tailored for unsupervised online concept drift detection by integrating a deep encoder for sample sets to represent data distributions and continuous learning strategies to dynamically optimize the projected space encompassing varying concepts."}, {"title": "3 PRELIMINARIES", "content": "3.1 Concept Drift\nConcept drift is a phenomenon referring to the arbitrary changes in the statistical properties of a target domain of data over time. Formally, concept drift at time t is defined as the change in the joint probability of data points X and labels y at time t, denoted as \\(P_t(X, y) \\neq P_{t+1}(X, y)\\). Concept drift primarily originates from one of the following three sources [35]: (i) \\(P_t(Y|X) \\neq P_{t+1}(Y|X)\\), when the conditional distribution of the target variable Y given the covariate X undergoes drift; (ii) \\(P_t(X) \\neq P_{t+1}(X)\\), when the distribution of the covariate experiences drift; and (iii) combination of (i) and (ii). In addition to varying sources, concept drift can also be distinguished into four types based on the specific nature of the drift occurrence: sudden, reoccurring, gradual, and incremental. For additional references, we direct readers to recent surveys [1, 4, 35].\nThis work aims to develop an unsupervised method for detecting various types of drift caused by the source described in (ii).\n3.2 Problem Setting\nGiven a continuously evolving data stream \\(X = \\{x_t\\}_{t=0}\\), we maintain the latest context of the data stream by employing a sliding window \\(W_t\\) of size W updated by a slide of size S (i.e., \\(W_t = \\{x_{t-i}\\}_{i=0}^{W-1}\\) and \\(S_t = \\{x_{t-i}\\}_{i=0}^{S-1}\\)). The window and slide sizes can be defined either in terms of the number of data points or a time period.\nThen, a window \\(W_t\\) consists of non-overlapping slides indexed by \\(j = 1,..., N_{\\text{sub}}\\) where \\(N_{\\text{sub}} = W/S\\) is the number of slides in a window (i.e., \\(W_t = \\bigcup_{j=1}^{N_{\\text{sub}}} S^j_{\\text{sub}}\\) and \\(S^j_{\\text{sub}} = \\{x_{t-(N_{\\text{sub}}-j)*S-i}\\}_{i=0}^{S-1}\\)).\nIn the rest of the paper, we use the term sub-window instead of slide for consistency. It is worth noting that the context within a sub-window is set to be sufficiently compact to ensure that the data points it contains adhere to the same underlying distribution.\nFor every sliding window in X, the problem of unsupervised online concept drift detection is to identify whether the concept drift has occurred in a new sub-window \\(S^N_{\\text{sub}}\\) compared with the existing data points in the current window \\(W_t \\backslash S^N_{\\text{sub}}\\), without using any labels for drifts and downstream tasks (see Figure 1).\n3.3 Maximum Mean Discrepancy\nMaximum Mean Discrepancy (MMD) [44] is a statistical measure that compares two probability distributions through a kernel, especially when the distributions are unknown and only samples are available. MMD evaluates the distance between the mean embeddings of two distributions in the Reproducing Kernel Hilbert Space (RKHS) H [5]. Given \\(X \\sim P\\), \\(Y \\sim Q\\), and a kernel f(.), we have:\n\\[MMD(P, Q) = \\underset{f\\in H,||f||_H\\leq1}{sup} ||E[f(x)] - E[f(Y)]||^2. \\quad\\quad (1)\\]\nWhen we have samples \\{\\(X_i\\)\\}_{i=1}^n from probability distribution P and \\{\\(Y_i\\)\\}_{i=1}^n from probability distribution Q, the empirical Maximum Mean Discrepancy (MMD) can be written as:\n\\[MMD(P, Q) = \\underset{f\\in H,||f||_H\\leq1}{sup} ||\\frac{1}{n}\\sum_{i=1}^n f(X_i) - \\frac{1}{n}\\sum_{i=1}^n f(Y_i)||^2. \\quad\\quad (2)\\]"}, {"title": "4 PROPOSED METHOD", "content": "4.1 Overview\nThe proposed method MCD-DD exploits maximum concept discrepancy for detecting concept drift, enabled by a deep encoder for data distribution embedding and contrastive learning for effective unsupervised training. The overall procedure of MCD-DD is illustrated in Figure 2 and outlined in Algorithm 1. For each new sliding window, MCD-DD follows the prequential evaluation scheme (i.e., test-and-train) [18]. First, MCD-DD samples sets of data points in sub-windows and embeds them through a sample set encoder. The discrepancy between sample sets from adjacent sub-windows is calculated, and if it exceeds a threshold, MCD-DD asserts that concept drift has occurred between them. Second, the sample set encoder is updated by considering the sliding window as the context for learning the latest concepts. Specifically, we treat sample sets from the same sub-window as positive pairs and construct negative pairs by leveraging temporal gaps between sub-windows and noise augmentation to distort the original distribution. In the meantime, MCD-DD dynamically adjusts the threshold for drift detection in the next sliding window by analyzing the positive sample pairs. Finally, the encoder is updated by aiming to minimize the distance between embeddings of positive sample pairs while simultaneously maximizing the distance between those of negative pairs.\n4.2 Sample Set Encoder\nWe use a set of data points sampled in each sub-window to estimate its data distribution that represents a concept in the sub-window. Specifically, for a given sub-window \\(S^j \\subset W_t\\), we perform sampling without replacement from it to obtain a sample set of size m:\n\\[M^j = \\{x_i \\in S^j\\}_{i=1}^m \\quad\\quad (3)\\]\nThe sample set is passed to a sample set encoder, denoted as set-enc(). It translates the probability distribution \\(P_t(S^j)\\) of the sub-window into the compact representation in the projected space, which we call concept representation \\(h^j\\) of \\(S^j\\):\n\\[h^j = \\text{set-enc}(M^j) = \\frac{1}{m} \\sum_{i=1}^m f(x_i \\in M^j), \\quad\\quad (4)\\]\nwhere f(.) is an encoding model with a deep neural network.\n4.3 Drift Detector\nFor each sub-window \\(S^j_{\\text{sub}}\\) in a sliding window \\(W_t\\), we obtain the concept representations \\{\\(h^j\\)\\}_{j=1}^{N_{\\text{sub}}} by the sample set encoder. Then, to effectively quantify the distance between the concept representations from two adjacent sub-windows, we introduce a new measure Maximum Concept Discrepancy (MCD) inspired by MMD:\n\\[MCD(P, Q) = \\underset{|lf||_2\\leq L}{sup} ||E[f(x)] - E[f(Y)] ||^2, \\quad\\quad (5)\\]\nwhere the function f(.) is approximated by a deep neural network and is constrained to be Lipschitz continuous [21]. This ensures the convergence of optimizing f and prevents MCD from becoming infinitely large. Moreover, it makes MCD between two sets of independent data from the same distribution bounded, providing the theoretical foundation for our drift detection.\nWhen we have samples \\(M^j \\sim P\\) and \\(M^{j'} \\sim Q\\) by Eq. (3), the empirical MCD can be derived from Eq. (5) and Eq. (4) as:\n\\[MCD(P,Q) = \\underset{|lf||_2\\leq L}{sup} ||\\frac{1}{m} \\sum_{i=1}^m f(x_i \\in M^j) - \\frac{1}{m} \\sum_{i=1}^m f(x_i \\in M^{j'})] ||^2, \\quad\\quad (6)\\]\n\\[=\\underset{|lf||_2\\leq L}{sup} ||h^j - h^{j'}||^2\\]\nBased on MCD, if the discrepancy between the data distributions of two adjacent sub-windows exceeds a given threshold \u03c3,\n\\[MCD(P_t(S^j), P_t(S^{j-1})) = ||h^j - h^{j-1}||^2 > \\sigma, \\quad\\quad (7)\\]\nthen we determine that a concept drift happened between them:\n\\[P_t(S^j) \\neq P_t(S^{j-1}). \\quad\\quad (8)\\]\nThe threshold \u03c3 can be controlled dynamically using a bootstrapping strategy, allowing it to adjust to the varying distances between sample sets within the same concept. By analyzing the historical collection of MCD values between sample sets in the same sub-windows (i.e., those with identical data distributions), we adjust the threshold \u03c3 for each sliding window within a predefined statistical significance level (e.g., 0.05). It is worth noting that this historical MCD information can be obtained during the optimization of the encoder without necessitating additional computations.\n4.4 Optimization\nTo optimize the sample set encoder, we employ contrastive learning [27] to enhance the separability of various concepts. The primary challenge lies in determining positive and negative sample pairs that are to be closer and further apart, respectively. This challenge is particularly pronounced in unsupervised scenarios, where we lack any prior information regarding the underlying concepts and true drifts. In MCD-DD, we exploit the concept of temporal coherence [43, 53], which is a fundamental characteristic observed in temporal data. It suggests that data points that are close in time are more likely to exhibit similar characteristics. We exploit this insight to create positive and negative samples used for optimization.\n4.4.1 Preparing Positive Samples. MCD-DD generates a positive sample pair by choosing two sets of data points from the same sub-window, assuming that these sets follow the same distributions.\nIn each sub-window \\(S^j\\), MCD-DD conducts sampling similar to Eq. (3) to select two sets of data points, which we treat as positive sample pairs. These pairs are denoted as \\(M_{p1}^j\\) and \\(M_{p2}^j\\). To generate a diverse set of positive sample pairs, we repeat this sampling process k times, resulting in \\{\\(M_{p1i}^j\\)\\}_{i=1}^k and \\{\\(M_{p2i}^j\\)\\}_{i=1}^k. Subsequently, the sample set encoder in Eq. (4) computes the embeddings for the k positive sample pairs, yielding \\{\\(h_{p1i}^j\\)\\}_{i=1}^k and \\{\\(h_{p2i}^j\\)\\}_{i=1}^k.\n4.4.2 Preparing Negative Samples. MCD-DD generates a negative sample pair to learn diversity in concept drift. Specifically, MCD-DD selects two sets of data points respectively from the different sub-windows that are temporally distant, whose distributions are likely to differ. MCD-DD also employs an efficient data augmentation technique to improve the generalization of negative pairs by introducing noise to each sampled data point:\n\\[x' = x + \\delta, \\quad\\quad (9)\\]\nwhere the noise \u03b4 is generated from a standard probability distribution (e.g., the Gaussian distribution G(\u00b5, \u0454)). By incorporating these two principles, temporal gap (i.e., drift diversity) and noise augmentation (i.e., concept diversity), we prepare two types of negative sample pairs.\nWeak negative samples: The first type of negative samples involves sampling pairs of data points from the same sub-windows but adding a small degree of noise into one of the sets. Specifically, given a sub-window \\(S^j\\), the k weak negative sample pairs are prepared:\n\\[\\{\\(M_{wn1i}^j\\)\\}_{i=1}^k \\text{and} \\{\\(M_{wn2i}^j + \\delta_1\\)\\}_{i=1}^k, \\quad\\quad (10)\\]\nwhere \\(\\delta_1 \\sim G(0, \\epsilon_{\\text{small}})\\) and G is a Gaussian distribution. Finally, the corresponding two set sample embeddings are derived:\n\\[\\{\\(h_{wn1i}^j\\)\\}_{i=1}^k \\text{and} \\{\\(h_{wn2i}^j\\)\\}_{i=1}^k \\quad\\quad (11)\\]\nStrong negative samples: The second type of negative samples involves sampling pairs of data points from the two sub-windows that are temporally distant and more substantial noise is added to one of the sets. Specifically, given a sub-window \\(S^j\\) and \\(S^{j'}\\), the k strong negative sample pairs are prepared:\n\\[\\{\\(M_{sn1i}^j\\)\\}_{i=1}^k \\text{and} \\{\\(M_{sn2i}^{j'} + \\delta_2\\)\\}_{i=1}^k \\quad\\quad (12)\\]\nwhere \\(\\delta_2 \\sim G(0, \\epsilon_{\\text{big}})\\). Similarly, the corresponding two set sample embeddings are derived:\n\\[\\{\\(h_{sn1i}^j\\)\\}_{i=1}^k \\text{and} \\{\\(h_{sn2i}^{j'}\\)\\}_{i=1}^k \\quad\\quad (13)\\]\nNote that the temporal gap between two sub-windows can be adjusted within the context of a window (i.e., \\(1 \\leq |j-j'| \\leq N_{\\text{sub}}-1\\)). By default, MCD-DD adopts the largest temporal gap by setting j = \\(N_{\\text{sub}}\\) and j' = 1 so as to maximize the likelihood that the samples within each window exhibit distinct data distributions.\n4.4.3 Learning Objective. By putting the positive, weak negative, and strong negative samples altogether, the final loss for the sample set encoder is formulated in the form of InfoNCE loss [37]:\n\\[L = log\\sum_{j=1}^{N_{\\text{sub}}} \\frac{\\sum_{k=1}^k exp(MCD_{p1}^{j,k})}{\\sum_{k=1}^k (exp(MCD_{p2}^{j,k}) + exp(MCD_{wn}^{j,k}) + exp(MCD_{sn}^{j,k}))} + \\lambda\\sum_{i=1}^m (||\\sqrt{x_i}f(x_i)||_2 - L)^2, \\quad\\quad (14)\\]\nwhere \\(MCD_{p1}^{j,k} = ||h_{p1i}^j - h_{p2i}^j||^2\\), \\(MCD_{wn}^{j,k} = ||h_{wn1i}^j - h_{wn2i}^j||^2\\), and \\(MCD_{sn}^{j,k} = ||h_{sn1i}^j - h_{sn2i}^{j'}||^2\\) are MCD values between the probability distributions of two sub-windows chosen for each sample type. The last term is the gradient penalty to ensure the L-Lipschitz continuity [26] of the encoding model f(.) where L is a constant and the coefficient \u03bb is the regularization parameter."}, {"title": "5 THEORETICAL ANALYSIS", "content": "5.1 Upper Bound of MCD\nGiven two sample sets of data points drawn from the same distribution, we study the upper bound of MCD between the two sets, which can serve as a theoretical threshold for detecting concept drifts in two sub-windows for MCD-DD.\nTheorem 1. Assume that the sets \\{\\(X_i\\)\\}_{i=1}^n, and \\{\\(Y_i\\)\\}_{i=1}^n are independently and identically distributed (i.i.d.), both drawn from the probability distribution p(x) with a mean \u00b5 and variance \u03c3. If f is a Lipschitz continuous function with Lipschitz constant L, we have:\n\\[P(\\Big|\\frac{1}{n} \\sum_{i=1}^n f(X_i) - \\frac{1}{n} \\sum_{i=1}^n f(Y_i)\\Big| > G^{-1}(1-\\frac{\\alpha}{2}) \\sqrt{\\frac{L^2 \\sigma^2}{n}}) \\leq \\alpha, \\quad\\quad (15)\\]\nwhere G(.) is the standard Gaussian distribution function. Therefore, for a given significance level \u03b1, \\(G^{-1}(1-\\frac{\\alpha}{2}) \\sqrt{\\frac{L^2 \\sigma^2}{n}})\\) is an upper bound for the MCD |\\(\\frac{1}{n} \\sum_{i=1}^n f(X_i) - \\frac{1}{n} \\sum_{i=1}^n f(Y_i)\\)|.\nPROOF. By the Central Limit Theorem, \\(\\frac{1}{n} \\sum_{i=1}^n f(X_i) - \\frac{1}{n} \\sum_{i=1}^n f(Y_i)\\) converges to the Guassain distribution. Moreover, we have:\n\\[E(\\frac{1}{n} \\sum_{i=1}^n f(X_i) - \\frac{1}{n} \\sum_{i=1}^n f(Y_i)) = 0. \\quad\\quad (16)\\]\nSince f is a L-Lipschitz continuous function, we have:\n\\[Var(\\frac{1}{n} \\sum_{i=1}^n f(X_i) - \\frac{1}{n} \\sum_{i=1}^n f(Y_i)) \\leq \\frac{2L^2 \\sigma^2}{n}. \\quad\\quad (17)\\]\nWhen we approximate the distribution of \\(\\frac{1}{n} \\sum_{i=1}^n f(X_i) - \\frac{1}{n} \\sum_{i=1}^n f(Y_i)\\) as the Gaussian distribution, we have:\n\\[P(\\Big|\\frac{1}{n} \\sum_{i=1}^n f(X_i) - \\frac{1}{n} \\sum_{i=1}^n f(Y_i)\\Big| > G^{-1}(1-\\frac{\\alpha}{2}) \\sqrt{\\frac{L^2 \\sigma^2}{n}}) \\leq \\alpha. \\quad\\quad (18)\\]\nTherefore, for the null hypothesis \\(H_0\\): \\{\\(X_i\\)\\}_{i=1}^n and \\{\\(Y_i\\)\\}_{i=1}^n are drawn from the same probability distribution, given a significance level \u03b1, \\(G^{-1}(1-\\frac{\\alpha}{2}) \\sqrt{\\frac{L^2 \\sigma^2}{n}})\\) can serve as the threshold for rejecting \\(H_0\\). In the scenario where \\{\\(X_i\\)\\}_{i=1}^n and \\{\\(Y_i\\)\\}_{i=1}^n are multivariate random variables, hypothesis testing can similarly be conducted using the chi-squared distribution.\nThis theoretical bound can serve as a guide to set the threshold in a hypothesis testing framework. However, deriving the exact rejection threshold analytically may not always be feasible. As suggested in Section 4.3, the empirical threshold for rejecting the null hypothesis can be used by estimating statistics of historical MCD values meeting the hypothesis with a pre-defined significance.\n5.2 Complexity of MCD-DD\nWe analyze the time complexity of MCD-DD mainly for sampling, training, and inference. Recall that we use a sliding window with \\(N_{\\text{sub}}\\) sub-windows, k sets of m samples, and an encoder with the parameter size p and training epochs e. Since we sample in each sub-window, the time complexity for constructing positive and negative samples is O(mk\\(N_{\\text{sub}})\\). The time complexity for training the encoder is O(mkep). For inference, since we need to calculate the differences of sample sets in each sub-window sequentially, the time complexity is O(mk\\(N_{\\text{sub}}^2\\)). Finally, the total complexity is O(mk(\\(N_{\\text{sub}}^2\\) + ep)). Since typically p > e, m, k, \\(N_{\\text{sub}}\\), the time complexity of MCD-DD is mostly controlled by the encoder complexity."}, {"title": "6 EXPERIMENTS", "content": "We conducted thorough experiments to evaluate the performance of MCD-DD on 7 synthetic data sets and 4 real-world data sets. The results are briefly summarized as follows.\n\u2022 MCD-DD outperforms existing baselines in detecting concept drifts in terms of Precision, F1, and MCC scores and shows high interpretablity with varying drift types (Section 6.2).\n\u2022 Through ablation analysis, the three sampling strategies introduced in contrastive learning for MCD are demonstrated to be effective (Section 6.3)."}, {"title": "7 CONCLUSION", "content": "We proposed MCD-DD, an unsupervised online concept drift detection method, exploiting a new measure called maximum concept discrepancy. MCD-DD leverages contrastive learning to obtain quality concept representations from sampled data points and optimize the maximum concept discrepancy. It is facilitated by sampling strategies based on temporal consistency and perturbations for robust optimization. The theoretical analysis demonstrated that MCD-DD can also be used within the hypothesis testing framework. Experimental results on multiple synthetic and real-world data sets showed that the proposed method achieves superior detection accuracy and higher interpretability than existing baselines.\nFor future work, we consider exploiting MCD histories learned throughout data streams. It can provide a systematic understanding of the patterns, duration, and strengths of concept drifts, as glimpsed in the heatmap visualization analyses. Further, assuming partial concept labels are available, adopting weak supervision philosophy can be promising. Estimating the degree of differences between partially labeled concepts can function as pseudo-labels to help us optimize the encoder more effectively."}, {"title": "A APPENDIX", "content": "A.1 Data Sets\nA.1.1 Synthetic Data Sets. The synthetic data sets used for model performance evaluation feature two types of drifts: primary and complex. Primary drift tasks involve concept drifts that are relatively easy to distinguish within the data stream. Complex drift tasks, however, present higher distribution similarity, increased dimensionality, and a greater number of drift events, making them more challenging to discern.\nFor primary tasks, drift is simulated by adjusting the weighting of two Gaussian distributions, G\u2081 and G2. Both distributions conform to a 5-dimensional Gaussian distribution with a mean vector \u00b5 =\n[20, 20, 20, 20, 20] and covariance matrices \u03a3\u2081 = 102I and \u03a32 =\n502I, where I denotes the identity matrix. These distributions form the basis for diverse Gaussian mixtures, with the weighting factor p controlling the proportion of each distribution in the mixture. The mixture model is represented by the equation: N(\u00b5, \u03a3\u2081) \u00d7 p +\nN(\u00b5, \u03a32) \u00d7 (1 \u2013 p). Each primary drift task involves a data set of\n30,000 instances. Within this framework, different types of primary drift tasks are simulated by varying p:\nPrimary Task 1-GM_Sud: Initially, p is set to 0.2. To induce\na sudden drift at the 21,000th instance, p is shifted to 0.8, significantly changing the mixture's composition and simulating a sudden change in the underlying data structure.\nPrimary Task 2-GM_Rec: Initially, p is set to 0.8, giving prominence to G1. At the 15,000th instance, p changes to 0.2, thus shifting the mixture's balance towards G2. Finally, at the 25,000th instance, p returns to 0.8, reinstating the initial distribution emphasis. This pattern creates a reoccurring drift in the data stream.\nPrimary Task 3-GM_Inc: Initially set at 0.2, the weighting factor p undergoes specific adjustments to introduce incremental drifts at predetermined intervals within the data set. Specifically, p linearly increases from 0.2 to 0.8 between the 12,000th and 12,600th instances, then decreases back to 0.2 between the 18,000th and\n19,200th instances, and finally increases again to 0.8 between the 24,000th and 25,200th instances. Outside these intervals, p remains constant, ensuring no drift occurs in the intervening segments. This design results in multiple incremental drifts across the data set. These linear transitions facilitate incremental drifts, modifying the data distribution across two Gaussian components.\nPrimary Task 4-GM_Grad: In the gradual drift task, p fluctuates between 0.2 and 0.8. The drift periods where p = 0.8 occur during the intervals (10000, 11000), (12001, 15000), and (18000, 21000). Conversely, in the intervening periods (11001,12000), (15001,18000), and (21001,24000), p reverts to 0.2. This oscillation creates a gradual drift pattern by alternating phases of drift and stability.\nComplex drift tasks, conversely, involve a mixture of distributions like Gamma, Lognormal, and Weibull. These distributions exhibit substantial overlap in their probability density functions and possess similar statistical characteristics, leading to lower discriminability and making the detection of drifts more challenging. These tasks are further compounded by introducing multiple drifts of different natures within the data stream. Also, each complex drift task involves a data set of 30,000 instances, where every dimension conforms to the same distribution pattern, ensuring consistency across the multidimensional data space.\nComplex Task 1-GamLog_Sud: Initially, data is generated from a Gamma distribution (Gamma (1.5, 20)) across 5 dimensions. At the 21,000th instance, there is a sudden shift to a 5-dimensional Log-normal distribution with parameters \u00b5 = log(30) 0.5 and\n\u03c3 = 0.5. This transition represents a complex and sudden drift, with the overlap between the two distributions making the drift challenging to identify.\nComplex Task 2-LogGamWei_Sud: The data stream, consisting of 20 dimensions, initially follows a Log-normal distribution\n(Lognormal(log(30) \u2013 0.5,0.5)). At the 15,000th instance, there\nis a sudden drift to a Gamma distribution (Gamma (1.5, 20)), and at the 24,000th instance, it transitions to a Weibull distribution (Weibull(1.5, 20)). These successive drifts add higher complexity.\nComplex Task 3-GamGM_SudGrad: This data stream consists of 20 dimensions, each following the same distribution. Initially, the data follows a Gamma distribution (Gamma(2, 10)). At the 11,000th instance, a sudden drift occurs, transitioning the data to a Gaussian mixture. Subsequently, the task experiences gradual drifts, where the weighting factor p alternates between 0.2 and 0.8 during specific intervals. This alternation leads to shifting dominance between two Gaussian distributions (N(20, 102) and N(20, 502)), creating a complex pattern of both sudden and gradual drifts.\nA.1.2 Real-World Data Sets. Here we provide detailed descriptions of the real-world data sets employed to evaluate the performance of our detector: INSECTS and EEG. These data sets are instrumental in assessing how effectively the detector adapts to real-world concept drift scenarios.\nINSECTS: The INSECTS data sets consist of optical sensor readings obtained from monitoring mosquitoes. Concept drifts are induced by varying temperatures, which affect the insects' activity levels in alignment with their circadian rhythms. This data set offers a dynamic setting of concept drifts. We utilized three specific data sets from the collection, each representing one or more distinct\ntypes of drift: (i) INSECTS_Sud: This subset exhibits five sudden drifts, initiated at a temperature of 30\u00b0C, with a sudden shift to 20\u00b0C, and subsequently to approximately 35\u00b0C among other changes. The stream captures several rapid transitions in temperature, illustrating sudden concept drifts throughout. (ii) INSECTS_Grad: Illustrating both gradual and incremental drifts, this data set simulates a scenario where temperatures slowly transition over time, presenting a nuanced evolution of environmental conditions. (iii) INSECTS_IncreRec: Features a unique pattern of reoccurring incremental drifts, where temperature gradually increases or decreases in cycles. This data set is pivotal for studying the model's performance in scenarios where drift patterns repeat over time, challenging the detection mechanism with both incremental and reoccurring drift phenomena.\nEEG: The EEG data set encompasses multivariate time-series data from a single continuous EEG recording using the Emotiv EEG Neuroheadset over a span of 117 seconds. Eye states were captured through video recording concurrent with the EEG data collection and were subsequently annotated manually to indicate moments of eye closure (\"1\") and eye opening (\"0\"). This data set provides a sequential record of neurological activity, with values arranged in the order they were measured, presenting a unique challenge for detecting shifts in physiological states over time."}, {"title": "A.2 Implementation Details", "content": "A.2.1 Implementation of compared algorithms. For MCD-DD, we set m = 30 (or 50 for a larger sub-window size such as in INSECTS_IncreRec), k = 10, \u03bb = 1, \\(\\epsilon_{\\text{small}}\\) = 1, \\(\\epsilon_{\\text{big}}\\) = 10, and L = 1. The encoder function was implemented as a two-layer MLP with a ReLU activation function. For synthetic data sets, the two-layer encoder features 100 units in both hidden and output layers. For the INSECTS data set, reflecting its more complex drift types and higher dimensionality, the encoder dimensions are increased to 200 (hidden) and 150 (output). For the EEG data set, which involves smaller window sizes, the dimensions are adjusted to 150 (hidden) and 100 (output). In all data sets, the encoder function has been trained for a single epoch with a learning rate of 0.005 for every sliding window. For the implementation of baselines, we referred to alibi-detect [49", "18": "and used the same sliding window with the window size W of 10% of the total length of each data set and \\(N_{\\text{sub}}\\) = 10. Each algorithm compares every new sub-window with the preceding one in a window to identify concept drift with a significance level of 0.05 if applicable.\nA.2.3 Computing Platform. All experiments were conducted on a Linux server equipped with an Intel Xeon CPU @ 2.20GHz, 12GB RAM, and 226GB of storage where Ubuntu 22.04 LTS, Python 3.10, and PyTorch 2.1.0+cu122 were installed. An NVIDIA Tesla V100-SXM2-16GB GPU was used for the deep learning-based algorithms.\nA.3 Additional Performance Analysis Results\nFor subtle and slow drift types, we have considered adaptively adjusting the training process to achieve better detection outcomes. In this regard, an incremental drift was introduced by linearly"}]}