{"title": "SAMBA: SYNCHRONIZED SET-OF-SEQUENCES\nMODELING FOR MULTIPLE OBJECT TRACKING", "authors": ["Mattia Segu", "Luigi Piccinelli", "Siyuan Li", "Yung-Hsu Yang", "Bernt Schiele", "Luc Van Gool"], "abstract": "Multiple object tracking in complex scenarios - such as coordinated dance perfor-\nmances, team sports, or dynamic animal groups - presents unique challenges. In\nthese settings, objects frequently move in coordinated patterns, occlude each other,\nand exhibit long-term dependencies in their trajectories. However, it remains a key\nopen research question on how to model long-range dependencies within track-\nlets, interdependencies among tracklets, and the associated temporal occlusions.\nTo this end, we introduce Samba, a novel linear-time set-of-sequences model de-\nsigned to jointly process multiple tracklets by synchronizing the multiple selec-\ntive state-spaces used to model each tracklet. Samba autoregressively predicts the\nfuture track query for each sequence while maintaining synchronized long-term\nmemory representations across tracklets. By integrating Samba into a tracking-\nby-propagation framework, we propose SambaMOTR, the first tracker effectively\naddressing the aforementioned issues, including long-range dependencies, track-\nlet interdependencies, and temporal occlusions. Additionally, we introduce an ef-\nfective technique for dealing with uncertain observations (MaskObs) and an ef-\nficient training recipe to scale SambaMOTR to longer sequences. By modeling\nlong-range dependencies and interactions among tracked objects, SambaMOTR\nimplicitly learns to track objects accurately through occlusions without any hand-\ncrafted heuristics. Our approach significantly surpasses prior state-of-the-art on\nthe DanceTrack, BFT, and SportsMOT datasets.", "sections": [{"title": "INTRODUCTION", "content": "Multiple object tracking (MOT) involves detecting multiple objects while keeping track of individual\ninstances throughout a video stream. It is critical for multiple downstream tasks such as sports\nanalysis, autonomous navigation, and media production (Luo et al., 2021). Traditionally, MOT\nmethods are validated on relatively simple settings such as surveillance datasets (Milan et al., 2016),\nwhere pedestrians exhibit largely linear motion and diverse appearance, and rarely interact with each\nother in complex ways. However, in dynamic environments like team sports, dance performances,\nor animal groups, objects frequently move in coordinated patterns, occlude each other, and exhibit\nnon-linear motion with long-term dependencies in their trajectories (Fig. 1). Modeling the long-term\ninterdependencies between objects in these settings, where their movements are often synchronized\nor influenced by one another, remains an open problem that current methods fail to address.\nCurrent tracking-by-detection methods (Bewley et al., 2016; Wojke et al., 2017; Zhang et al., 2022;\nCao et al., 2023) often rely on heuristics-based models like the Kalman filter to independently model\nthe trajectory of objects and predict their future location. However, these methods struggle with the\nnon-linear nature of object dynamics such as motion, appearance, and pose changes. Tracking-by-\npropagation (Sun et al., 2020; Meinhardt et al., 2022; Zeng et al., 2022) offers an alternative by\nmodeling tracking as an end-to-end autoregressive object detection problem, leveraging detection\ntransformers (Carion et al., 2020; Zhu et al., 2020) to propagate track queries over time. Their flex-\nible design fostered promising performance in settings with complex motion, pose, and appearance\npatterns, such as dance (Sun et al., 2022), sports (Cui et al., 2023), and bird (Zheng et al., 2024)\ntracking datasets. However, such methods only propagate the temporal information across adjacent\nframes, failing to account for long-range dependencies. MeMOTR (Gao & Wang, 2023) attempts a\npreliminary solution to this problem by storing temporal information through an external heuristics-"}, {"title": "PRELIMINARIES", "content": "Before introducing SambaMOTR (Sec. 4), we present the necessary background and notation on\nselective state-space models (Sec. 3.1) and tracking-by-propagation (Sec. 3.2)."}, {"title": "SELECTIVE STATE-SPACE MODELS", "content": "Inspired by classical state-space models (SSMs) (Kalman, 1960), structured SSMs (S4) (Gu et al.,\n2021) introduce a sequence model whose computational complexity scales linearly, rather than\nquadratically, with the sequence length. This makes S4 a principled and efficient alternative to\ntransformers (Vaswani et al., 2017). By further introducing a selection mechanism - i.e. rendering\nthe SSM parameters input-dependent - Mamba (Gu & Dao, 2023) can model time-variant systems,\nbridging the performance gap with transformers (Vaswani et al., 2017).\nWe here formally define selective SSMs (S6) (Gu & Dao, 2023). Let $x(t)$ be the in-\nput signal at time $t$, $h(t)$ the hidden state, and $y(t)$ the output signal. Given the system\nA, control B, and output C matrices, we define the continuous linear time-variant SSM in\nEq. (1). The discrete-time equivalent system (Eq. (2)) of the defined SSM is obtained through\na discretization rule. The chosen discretization rule is typically the zero-order hold (ZOH)\nmodel: $\\bar{A}(t) = exp(\\Delta(t)A(t))$, $B(t) = (\\Delta(t)A(t))^{-1}(exp(\\Delta(t)A(t)) \u2013 I) \\cdot \\Delta(t)B(t)$:\n$h'(t) = A(t)h(t) + B(t)x(t)$\n(1)\n$h_t = \\bar{A}(t)h_{t-1} + \\bar{B}(t)x_t$\n(2)\n$y(t) = C(t)h(t)$\n$y_t = \\bar{C}(t)h_t$\n$x_t$, $h_t$, $y_t$ are the observations sampled at time t of the input signal $x(t)$, hidden state h(t), and\noutput signal y(t). While S4 learns a linear time-invariant (LTI) system with $\\Delta(t) = \\Delta$, $A(t) = A$,\n$B(t) = B$ and $C(t) = C$, S6 introduces selectivity to learn a time-variant system by making $\\Delta(t)$,\n$B(t)$ and $C(t)$ dependent on the input x(t), i.e. $\\Delta(t) = softplus(\\Delta + s_{\\Delta}(x(t)))$, $B(t) = s_B(x(t))$,\n$C(t) = s_C(x(t))$, where $s_\\Delta = softplus$, and $s_\\Delta$, $s_B$, $s_C$ are learnable linear mappings.\nIn this paper, we propose to treat tracking-by-propagation as a sequence modeling problem. Given\nthe discrete sequence of historical track queries for a certain tracklet, our query propagation mod-"}, {"title": "TRACKING-BY-PROPAGATION", "content": "Tracking-by-propagation methods alternate between a detection stage and a propagation stage, rely-\ning on a DETR-like (Carion et al., 2020) transformer object detector and a query propagation mod-\nule. At a time step t, the backbone and transformer encoder extract image features for a frame $I_t$.\nThe detection stage involves feeding both a fixed-length set of learnable detect queries $Q^{det}$ to the\ntransformer decoder to detect newborn objects and a variable-length set of propagated track queries\n$Q^{trk}_t$ to re-detect tracked ones. At time $t = 0$, the set of track queries is empty, i.e. $Q^{trk}_t = E^{trk}_t = \\emptyset$.\nDetect and track queries $[Q^{det}, Q^{trk}_t]$ interact in the decoder with image features to generate the cor-\nresponding output embeddings $[E^{det}, E^{trk}_t]$ and bounding box predictions $[D^{det}, D^{trk}_t]$. We denote\nthe set of embeddings corresponding to newborn objects as $\\hat{E}^{det}_t$, and $\\hat{E}^{trk}_t = [\\hat{E}^{det}_t, E^{trk}_t]$ as the\nset of embeddings corresponding to the tracklets $S_t$ active at time t. During the propagation stage, a\nquery propagation module $\\Phi(\\cdot)$ typically takes as input the set of embeddings $\\hat{E}^{trk}_t$ and outputs re-\nfined tracked queries $Q^{trk}_{t+1} = \\Phi(\\hat{E}^{trk}_t)$ to re-detect the corresponding objects in the next frame.\nAlthough prior work failed to properly model long-range history and tracklet interactions (Zeng\net al., 2022; Gao & Wang, 2023; Meinhardt et al., 2022), and given that multiple objects often move\nsynchronously (Fig. 1), we argue that the future state of objects in a scene can be better predicted by\n(i) considering both their historical positions and appearances, and (ii) estimating their interactions.\nIn this work, we cast query propagation as a set-of-sequences modeling problem. Given a set of\nmultiple tracklets, we encode the history of each tracklet in a memory representation using a state-\nspace model and propose memory synchronization to account for their joint dynamics."}, {"title": "METHOD", "content": "In this section, we introduce SambaMOTR, an end-to-end multiple object tracker that combines\ntransformer-based object detection with our set-of-sequences model Samba to jointly model the\nlong-range history of each tracklet and the interaction across tracklets to propagate queries. First, in\nSec. 3.2 we provide background on the tracking-by-propagation framework and motivate the need\nfor better modeling of both temporal information and tracklets interaction. Then, we describe the\nSambaMOTR architecture (Sec. 4.1) and introduce Samba (Sec. 4.2), our novel set-of-sequences\nmodel based on synchronized state spaces that jointly models the temporal dynamics of a set of se-\nquences and their interdependencies. Finally, in Sec. 4.3 we describe SambaMOTR's query propa-\ngation strategy based on Samba, our effective technique MaskObs to deal with occlusions in SSMs, a\nrecipe to learn long-range sequence models with limited compute, and our simple inference pipeline."}, {"title": "ARCHITECTURE", "content": "Similar to other tracking-by-propagation methods (Meinhardt et al., 2022; Zeng et al., 2022; Gao &\nWang, 2023), the proposed SambaMOTR architecture (Fig. 2) is composed of a DETR-like (Carion\net al., 2020) object detector and a query propagation module. As object detector, we use Deformable-\nDETR (Zhu et al., 2020) with a ResNet-50 (He et al., 2016) backbone followed by a transformer\nencoder to extract image features and a transformer decoder to detect bounding boxes from a set of\ndetect and track queries. As query propagation module, we use our set-of-sequences model Samba.\nEach sequence is processed by a Samba unit synchronized with all others. A Samba unit consists of\ntwo Samba blocks (Sec. 4.2) interleaved with LayerNorm (Ba et al., 2016) and a residual connection."}, {"title": "SAMBA: SYNCHRONIZED STATE-SPACE MODELS FOR SET-OF-SEQUENCES MODELING", "content": "Set-of-sequences modeling involves simultaneously modeling a set of temporal sequences and the\ninterdependencies among them. In MOT, set-of-sequences models can capture long-range temporal\nrelationships within each tracklet as well as complex interactions across tracklets. To this end, we\nintroduce Samba, a linear-time set-of-sequences model based on the synchronization of multiple\nstate-space models. In this paper, we leverage Samba as a set-of-queries propagation network to\njointly model multiple tracklets and their interactions in a tracking-by-propagation framework."}, {"title": "SAMBAMOTR: END-TO-END TRACKING-BY-PROPAGATION WITH SAMBA", "content": "As described in Sec. 3.2, the query propagation module $\\Phi(\\cdot)$\ntakes as input the decoder output embeddings $\\hat{E}^{trk}_t$ and outputs refined track queries $Q^{trk}_{t+1} =\n\\Phi(\\hat{E}^{trk}_t)$. SambaMOTR extends this paradigm by accounting for the temporal information and\ntracklets interaction. In particular, we use our Samba module $\\Phi(\\cdot)$ to compress the history of each\ntracklet into a hidden state $h_t^i$ and synchronize it across tracklets to derive the synchronized mem-\nory $\\bar{h}_t^i$. Notice that $h_0^i = 0$ for a newborn object $i$. At time t, we first enrich the detector out-\nput embeddings $\\hat{E}^{trk}_t$ with position information by summing to them sine-cosine positional encod-\nings $PE(\\cdot)$ of the corresponding bounding boxes coordinates $\\hat{D}^{trk}_t$ to implicitly model object mo-\ntion and appearance, obtaining the set of input observations $X^{trk}_t = \\hat{E}^{trk}_t + PE(\\hat{D}^{trk}_t)$. Given the\nset of input observations $X^{trk}_t$ and past synchronized hidden states $H_{t-1}$ for all tracklets in the set"}, {"title": "EXPERIMENTS", "content": "In this section, we present experimental results to validate SambaMOTR. We describe our evaluation\nprotocol (Sec. 5.1) and report implementation details (Sec. 5.2). We then compare SambaMOTR\nto the previous state-of-the-art methods (Sec. 5.3) and conduct an ablation study (Sec. 5.4) on the\nmethod components. We provide more ablations in the appendix. Qualitative results can be found\nin Fig. 1 and at the anonymous project page https://anonymous-samba.github.io/."}, {"title": "EVALUATION PROTOCOL", "content": "Datasets. To evaluate SambaMOTR, we select a variety of challenging datasets exhibiting highly\nnon-linear motion in crowded scenarios, with frequent occlusions and uniform appearances. All\ndatasets present scenes with objects moving synchronously. Thus, they represent a suitable bench-\nmark for assessing the importance of modeling tracklet interaction. DanceTrack (Sun et al., 2022)\nis a multi-human tracking dataset composed of 100 group dancing videos. The Bird Flock Track-\ning (BFT) (Zheng et al., 2024) dataset includes 106 clips from the BBC documentary series Earth-\nflight (Downer & Tennant, 2011). SportsMOT (Cui et al., 2023) consists of 240 video sequences"}, {"title": "IMPLEMENTATION DETAILS", "content": "Following prior works (Gao & Wang, 2023; Zhang et al., 2023), we apply random resize, random\ncrop, and photometric augmentations as data augmentation. The shorter side of the input image is\nresized to 800 preserving the aspect ratio, and the maximum size is restricted to 1536. For a fair\ncomparison with prior work (Sun et al., 2020; Zeng et al., 2022; Gao & Wang, 2023), we use the\nDeformable-DETR (Zhu et al., 2020) object detector with ResNet-50 (He et al., 2016) and initialize\nit from COCO (Lin et al., 2014) pre-trained weights. Similar to MeMOTR (Gao & Wang, 2023),\nwe inject track queries after one decoder layer. We run our experiments on 8 NVIDIA RTX 4090\nGPUs, with batch size 1 per GPU. Each batch element contains a video clip with 10 frames, and we\ncompute and backpropagate the gradients only over the last 5. We sample uniformly spaced frames\nat random intervals from 1 to 10 within each clip. We utilize the AdamW optimizer (Loshchilov &\nHutter, 2017) with initial learning rate of $2.0 \\times 10^{-4}$. For simplicity, $T_{det}$ = $T_{track}$ = $T_{mask}$ = 0.5.\n$N_{miss}$ is 35, 20, and 50 on DanceTrack, BFT, and SportsMOT, respectively, due to different dataset\ndynamics. On DanceTrack (Sun et al., 2022), we train SambaMOTR for 15 epochs on the training\nset and drop the learning rate by a factor of 10 at the 10th epoch. On BFT (Sun et al., 2022), we\ntrain for 20 epochs and drop the learning rate after 10 epochs. On SportsMOT (Cui et al., 2023), we\ntrain for 18 epochs and drop the learning rate after 8 and 12 epochs. SambaMOTR\u2019s inference runs\nat 16 FPS on a single NVIDIA RTX 4090 GPUs."}, {"title": "COMPARISON WITH THE STATE OF THE ART", "content": "We compare SambaMOTR with multiple tracking-by-detection and tracking-by-propagation ap-\nproaches on the DanceTrack (Tab. 1), BFT (Tab. 2) and SportsMOT (Tab. 3) datasets. All meth-\nods are trained without using additional datasets. Since trackers use various object detectors with\ndifferent baseline performance, we report the detector used for each method. For fair comparison,\nwe report the performance of tracking-by-propagation methods with Deformable DETR (Zhu et al.,\n2020), marking the best in bold. We underle the overall best result. Tracking-by-detection methods\noften use the stronger YOLOX-X (Ge et al., 2021), but tracking-by-propagation consistently outper-\nforms them, with SambaMOTR achieving the highest HOTA and AssA across all datasets.\nDanceTrack. The combination of highly irregular motion and crowded scenes with frequent occlu-\nsions and uniform appearance historically made DanceTrack challenging for tracking-by-detection\nmethods. Despite their higher DetA when using the strong object detector YOLOX-X (Ge et al.,\n2021), tracking-by-propagation significantly outperforms them (see MeMOTR (Gao & Wang, 2023)\nand SambaMOTR). SambaMOTR sets a new state of the art, with +3.8 HOTA and +5.2 AssA\non the strongest competitor MeMOTR. Our method owes this performance improvement to its bet-\nter modeling of the historical information, our effective strategy to learn accurate sequence models\nthrough occlusions, and our modeling of tracklets interaction (group dancers move synchronously).\nBFT. Bird flocks present similar appearance and non-linear motion. For this reason, OC-SORT\nworks best among tracking-by-detection methods. Nevertheless, bird flocks move synchronously,\nand interaction among tracklets is an essential cue for modeling joint object motion. Thanks to our\nproposed sequence models synchronization, SambaMOTR achieves +2.8 HOTA and +4.9 AssA\nover the best competitor overall (OC-SORT), and an impressive +6.3 HOTA and +12.5 improve-\nment over the previous best tracking-by-propagation method TrackFormer (Meinhardt et al., 2022).\nSportsMOT. Sports scenes typically present non-linear motion patterns that the Kalman filter strug-\ngles to model, hence the underwhelming performance of ByteTrack (Zhang et al., 2022). For this\nreason, trackers that model non-linear motion either explicitly (OC-SORT (Cao et al., 2023)) or im-"}, {"title": "ABLATION STUDIES", "content": "We ablate the effect of each component of our method in Tab. 4, as detailed in Sec. 4 and illustrated\nin Fig. B. Additional ablation studies are presented in App. \u0421.2.\nSSM. Line (a) shows the benefits of a sequential representation for tracking. We use a vanilla se-\nquence model, such as Mamba, as the baseline for query propagation, establishing a robust founda-\ntion that outperforms MeMOTR's EMA-based history and temporal attention module.\nMaskObs. Handling track queries during occlusions (line b) with MaskObs - which masks uncertain\nobservations from the state update and relies on long-term memory and interactions with visible\ntracklets - leads to significant overall improvements (+1.3 HOTA), highlighting the effectiveness of\nmanaging occluded objects.\nSync. Making tracklets aware of each other through our synchronization mechanism (line c) re-\nsults in over 1% improvement across all metrics, demonstrating how modeling interactions between\ntracklets enhances tracking accuracy by capturing joint dynamics and coordinated movements."}, {"title": "LIMITATIONS", "content": "Following the tracking-by-propagation paradigm, our model drops tracklets that are inactive for\nmore than Nmiss frames to decrease the risk of ID switches. However, in some datasets like\nSportsMOT (Cui et al., 2023) football players may disappear from the camera view for multiple sec-\nonds, outliving the $N_{miss}$ threshold. We argue that future work should complement tracking-by-\npropagation with long-term re-identification to tackle this issue. Furthermore, in this paper, we in-\ntroduced Samba, a set-of-sequences model. Our ablation study (Tab. 4) shows that Samba signifi-\ncantly outperforms the already strong SSM baseline. However, this comes with the trade-off of in-\ncreased computational complexity. In particular, SSMs have linear complexity in time and linear\ncomplexity in the number of sequences (tracklets) independently modeled. Samba retains linear-\ntime complexity, which enables it to track for indefinitely long-time horizons, but quadratic com-\nplexity in the number of sequences due to the use of self-attention in memory synchronization. Our\nablations show that this trade-off is worth the performance improvement."}, {"title": "CONCLUSION", "content": "The proposed SambaMOTR fully leverages the sequential nature of the tracking task by using our\nset-of-sequences model, Samba, as a query propagation module to jointly model the temporal history\nof each tracklet and their interactions. The resulting tracker runs with linear-time complexity and can\ntrack objects across indefinitely long sequences. SambaMOTR surpasses the state-of-the-art on all\nbenchmarks, reporting significant improvements in association accuracy compared to prior work."}, {"title": "APPENDIX", "content": "In this appendix, we report additional discussions and experiments. First, we provide background on\nsequence models in App. A. Then, we report additional implementation details for SambaMOTR in\nApp. B. We show a schematic illustration of the Samba block in Fig. A and our method components\nin Fig. B. Finally, we provide additional results App. C, conducting several ablation studies on\nspecific design choices that contributed to SambaMOTR's performance."}, {"title": "BACKGROUND ON SEQUENCE MODELS.", "content": "Sequence Models. Sequence models are a class of machine learning models dealing with sequential\ndata, i.e. where the order of elements is important. Applications of sequence models are widespread\nacross different fields, such as natural language processing (Vaswani et al., 2017; Gu & Dao, 2023),\ntime series forecasting (Wen et al., 2022) and video analysis (Venugopalan et al., 2015). Several ar-\nchitectures have been proposed to process sequences, each with its own strengths and limitations.\nRecurrent neural networks (RNNs) handles sequential data by maintaining a hidden state that up-\ndates as the network processes each element in a sequence. However, RNNs often struggle with\nlong sequences due to issues like vanishing or exploding gradients (Pascanu et al., 2013). Long\nshort-term memory (LSTM) networks (Hochreiter & Schmidhuber, 1997) introduce gating units\nto mitigate RNN's vanishing gradient problem. Transformers (Vaswani et al., 2017) rely on self-\nattention mechanisms to weigh the importance of different parts of the input data. Unlike RNNs and\nLSTMs, transformers process entire sequences simultaneously, making them efficient at modeling\nlong-range dependencies at the cost of quadratic computational complexity wrt. sequence length.\nBuilding on the idea of modeling temporal dynamics like RNNs and LSTMs, structured state-space\nmodels (Gu et al., 2021) introduce a principled approach to state management inspired by classical\nSSMs (Kalman, 1960). Despite excelling at modeling long-range dependencies in continuous sig-\nnals, structured SSMs lag behind transformers on discrete modalities such as text. Recently, selec-\ntive state-space models (Mamba) (Gu & Dao, 2023) improved over prior work by making the SSM\nparameters input-dependent, achieving the modeling power of Transformers while scaling linearly\nwith sequence length.\nSet-of-sequences Models. Only few approaches (Yang et al., 2017; Amiridi et al., 2022; Wu et al.,\n2024) explore the task of set-of-sequences modeling, which we define as the task of simultaneously\nmodeling multiple temporal sequences and their interdependencies to capture complex relationships\nand interactions across different data streams. Set-of-sequences modeling has applications in mul-\ntivariate time series analysis (Amiridi et al., 2022), dynamic graph modeling (Wu et al., 2024), and\nsensor data fusion (Yang et al., 2017). However, existing techniques involve complex and expensive\ndesigns. We here introduce Samba, a linear-time set-of-sequences model based on the synchroniza-\ntion of multiple selective state-space models to account for the interaction across sequences."}, {"title": "SAMBAMOTR - ADDITIONAL DETAILS", "content": "SambaMOTR builds on Samba to introduce linear-time sequence modeling in tracking-by-\npropagation, treating each tracklet as a sequence of queries and autoregressively predicting the fu-\nture track query. By inducing synchronization on the SSMs' memories across an arbitrary number\nof sequences, Samba elegantly models tracklet interaction and query propagation under occlusions."}, {"title": "SAMBA", "content": "We illustrate a Samba set-of-sequences model in Fig. A. A Samba model (Fig. A) is composed of\na set of siamese Samba units (one for each sequence being modeled) with shared weights. Each\nSamba unit is synchronized with others through our synchronized SSM layer. In particular, a Samba\nunit is composed of N non-linear Samba blocks. To obtain a non-linear Samba unitblock that can be\nembedded into a neural network, we wrap the synchronized SSM layer following the Mamba (Gu &\nDao, 2023) architecture. A linear projection expands the input dimension D by an expansion factor\nE, followed by a causal convolution and a SiLU (Hendrycks & Gimpel, 2016) activation before be-\ning fed to the sync SSM layer. The output of a residual connection is passed to a SiLU before being\nmultiplied by the output of the synchronized SSM and passed to an output linear projection. More-"}, {"title": "SCHEMATIC ILLUSTRATION OF OUR CONTRIBUTIONS", "content": "We provide a schematic illustration of our contributions towards building Samba in Fig. B, disen-\ntangling them from one another to make the functioning of each component clear.\nMamba is the underlying sequence model, shown in the first row (Mamba). The second row depicts\nour strategy to deal with uncertain observations by ignoring them in the state update (Occlusion\nMasking). Synchronization across multiple sequence models using our synchronization module to\nlet their hidden states communicate to model sequence interaction is shown in the third row (Sync).\nThe last row illustrates our efficient training strategy to learn long-range dynamics from longer\nsequences at a comparable computational expense for backpropagation (Longer).\nEach of these components is ablated in Tab. 4 by incrementally adding them within our framework,\nshowing the effectiveness of each towards the impressive final performance of SambaMOTR."}, {"title": "ADDITIONAL RESULTS", "content": "We report additional results on the popular MOT17 pedestrian tracking benchmark in App. C.1. We\nextend our ablation study in App. C.2, investigating the effectiveness of synchronization, the use of\npositional embeddings and the effectiveness of residual prediction."}, {"title": "MOT17", "content": "While MOT17 served as a benchmark of paramount importance to advance the state of current\nmultiple object tracking algorithms, its very small size is reducing its significance as a training\ndataset. Since MOT17 only counts 7 training videos, modern tracking solutions complement its\ntraining with additional detection datasets and increasingly stronger detectors to improve the overall"}]}