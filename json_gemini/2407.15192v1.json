{"title": "Error Detection and Constraint Recovery in Hierarchical Multi-Label Classification without Prior Knowledge", "authors": ["Joshua Shay Kricheli", "Khoa Vo", "Spencer Ozgur", "Aniruddha Datta", "Paulo Shakarian"], "abstract": "Recent advances in Hierarchical Multi-label Classification (HMC), particularly neurosymbolic-based approaches, have demonstrated improved consistency and accuracy by enforcing constraints on a neural model during training. However, such work assumes the existence of such constraints a-priori. In this paper, we relax this strong assumption and present an approach based on Error Detection Rules (EDR) that allow for learning explainable rules about the failure modes of machine learning models. We show that these rules are not only effective in detecting when a machine learning classifier has made an error but also can be leveraged as constraints for HMC, thereby allowing the recovery of explainable constraints even if they are not provided. We show that our approach is effective in detecting machine learning errors and recovering constraints, is noise tolerant, and can function as a source of knowledge for neurosymbolic models on multiple datasets, including a newly in-troduced military vehicle recognition dataset.", "sections": [{"title": "1 INTRODUCTION", "content": "Hierarchical Multi-label Classification (HMC) extends the idea of multi-label classification to impose a hierarchy among labels [13, 14, 29, 30] and has been applied to a variety of applications [4, 19, 20]. A separate line of machine learning research deals with the training of a secondary model to identify failures in the first [8, 11, 24, 27] - which has been referred to as \u201cmetacognition\u201d [17, 21] and typically the secondary model is a black-box model. Recent research trends (specifically neurosymbolic AI [10, 26]) have led to the expression of such hierarchical relationships as constraints on the learning process [4, 13, 33] or leveraging constraints to make corrections to the machine learning model [7, 15]. A key assumption in these approaches is that the constraints are known a-priori. Meanwhile, a metacognitive approach known as Error Detection Rules (EDR) allows for the learning of rules to predict failures [32] based on conditions derived from domain knowledge and/or complementary models for the same task trained on the same data. The key intuition of this paper is that we can modify the ideas of [32] to predict errors and recover constraints of an HMC model without a-prior knowledge of the constraints. Our contributions are as follows:\n\u2022 We extend the EDR framework of [32] to address the HMC problem without prior knowledge of the hierarchy by both extending the language of that work and presenting a new Focused-EDR which addresses an objective function mismatch of [32] by leveraging approximate optimization of the ratio of two submodular functions;\n\u2022 We demonstrate how our new approach, provides significant improvement in the detection of errors when compared to a black-box baseline neural error detector and the detection algorithm of [32] on three different HMC datasets;\n\u2022 We show our approach can recover constraints and that both the F1-score of constraints recovered as well as error F1 degrades gracefully with noise - with noise injected in a manner to remove certain classes from consideration;\n\u2022 We show the recovered constraints can then be used as a source for in neurosymbolic model learning (i.e., Logic Tensor Networks (LTN) [4]) to provide improved model performance and reduce the number of inconsistencies;\n\u2022 We introduce (and release 1) an open-source HMC dataset of ~10K images of military vehicles.\nThe rest of the paper is organized as follows. We provide an overview of related work in Section 2, introduce our Focused EDR approach in Section 3, followed by our experimental results and discussion in Section 4."}, {"title": "2 RELATED WORK", "content": "In Hierarchical Multi-label Classification (HMC), pre-defined con-straints are crucial for shaping effective prediction models [14, 22, 29], which, in general assume that constraints are known a-priori. Neurosymbolic approaches such as [4, 13, 33] also assum the existence of a-prior constraints. In contrast, Semantic Probabilistic Layers (SPL) identify constraint relationships from data but lack explainability, encoding constraints in a deep probabilistic circuit that is not directly interpretable [1]. The approach presented in this work does not assume knowledge of constraints yet allows recovery of interpretable constraints. This work also deals with error detection in ML models or \u201cmetacognition\" [17, 21, 31]. Recent efforts include neurosymbolic methods [7, 9, 16] that rely on"}, {"title": "3 APPROACH", "content": "We now describe some technical preliminaries for our problem and two key extensions we make to the EDR framework of [32]. Specifically, we extend the EDR method to capture the HMC case and we address the objective function mismatch in the detection algorithm. In our setup, we assume that the hierarchical data has G levels of granularities $G := {g_i}_1$, each with a corresponding label set yg. In this work we focus in the case of G = 2, and denote G:= {fine, coarse}. The framework can extend for G > 2, but we leave evaluation of the approach beyond two levels to future work. Let X, Y be all the possible examples and predicted labels, respectively. We thus have $Y = \\bigcup_{g \\in G} Y_g$, as all the possible predicted labels, and define $Y_g := \\bigcup_{g \\in G} Y_g$. Define a labeled training set $T := {(x,gt(x))\\} \\subset X \\times Y$ composed of Nr images and corresponding ground-truth labels. We assume the existence of a well-trained model f\u00ee returning one class per level of granularity for a given sample. We then define an Error Prediction Problem per class y \u2208 yg, which is predicting where f\u00f4 predicted y incorrectly.\nIntuitively, this reads that if one of the conditions in set $D_{Cy}$ are observed for sample X and the model assigns class y to it, then the model has made an error predicting x to be of class y. The authors learn the rules through a constrained submodular optimization technique that optimizes target class precision as opposed to accuracy of detecting errors."}, {"title": "4 EXPERIMENTAL RESULTS", "content": "We experimented on three datasets in our work - our Military Vehi-cles dataset and subsets of 50 classes from the ImageNet [25] dataset and 36 classes from the OpenImage [18] dataset. For each of those, we first trained a main model f\u00ee using the Binary Cross-Entropy (BCE) loss while employing a fitting State of the Art (SOTA) ar-chitecture and corresponding hyperparameters which we found to perform favorably among other architecture (the Vision Trans-former [12] b_16 for the Military Vehicles and OpenImage and DINO V2 [23] s_14 for ImageNet). In the Military Vehicles dataset, there are a total of 9, 444 images and we took a ratio of 80: 20 between train and test. For the ImageNet50 dataset, we kept the original ratio from the paper of 1, 300 images in the train set and 50 in the test set for each fine grain class, as well as 2000 train and 400 test images per fine grain class for the OpenImage36 dataset. In all datasets, we had ground truth constraints which we used to compute the fraction of samples violating ground truth constraints in the test set and/or determining the ability to recover constraints.\nFor error detection, we evaluated three approaches: Focused EDR (f-EDR, this paper), DetRuleLearn [32], and a neural (black-box) error prediction model inspired by related work (e.g., [8] - with an SOTA neural architecture) that effectively treats error detection as a binary classification problem. For these neural error detection baselines, we used the same model architec-ture of our base model but retrained for this classification problem. Rules for both f-EDR and DetRuleLearn were trained on the same training data used for the base models. Conditions for the rules were derived from both the class of complementary granularity (e.g., fine for coarse predictions and vice-versa), lesser-performed models trained on the same data, and binary classification models for the same class (much in the same way additional models were used in [32]). We note that both f-EDR and DetRuleLearn used the same set of conditions to learn rules. Results of this experiment are shown in Table 3 where we provide the balanced accuracy and F1-score of the total error - which is defined as applying a logical OR on all the per-class error classes. In all experiments, f-EDR signifi-cantly outperforms both DetRuleLearn and the neural-based error"}]}