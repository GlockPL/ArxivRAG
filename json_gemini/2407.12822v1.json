{"title": "Lightweight Large Language Model for Medication Enquiry: Med-Pal", "authors": ["Kabilan Elangovan", "Jasmine Chiat Ling Ong", "Liyuan Jin", "Benjamin Jun Jie Seng", "Yu Heng Kwan", "Lit Soo Tan", "Ryan Jian Zhong", "Justina Koi Li Ma", "Yu He Ke", "Nan Liu", "Kathleen M Giacomini", "Daniel Shu Wei Ting"], "abstract": "Large Language Models (LLMs) show promise in augmenting digital health applications. However,\ndevelopment and scaling of large models face computational constraints, data security concerns and\nlimitations of internet accessibility in some regions. We developed and tested Med-Pal, a medical\ndomain-specific LLM-chatbot fine-tuned with a fine-grained, expert curated medication-enquiry dataset\nconsisting of 1,100 question and answer pairs. We trained and validated five light-weight, open-source\nLLMs of smaller parameter size (7 billion or less) on a validation dataset of 231 medication-related\nenquiries. We introduce SCORE, an LLM-specific evaluation criteria for clinical adjudication of LLM\nresponses, performed by a multidisciplinary expert team. The best performing lighted-weight LLM was\nchosen as Med-Pal for further engineering with guard-railing against adversarial prompts. Med-Pal\noutperformed Biomistral and Meerkat, achieving 71.9% high-quality responses in a separate testing\ndataset. Med-Pal's light-weight architecture, clinical alignment and safety guardrails enable\nimplementation under varied settings, including those with limited digital infrastructure.", "sections": [{"title": "Introduction", "content": "Accelerated by the COVID-19 pandemic, the healthcare sector is transitioning from physical,\u00b9 in-person\nservice to web-based, digital health tools\u00b2 integrations. Accessible digital healthcare communication\ntools ultimately promote healthcare literacy, provide valuable insights to patients regarding their medical\nconditions, and improve overall healthcare outcomes through patient empowerment and enhanced\ncommunication with providers\u00b3. However, this ease of access to healthcare providers invariably\ncontribute substantially to the clerical workload, cognitive burden of healthcare professionals, and extra\nhuman capitals as operational costs. Large Language Models (LLMs) when optimised with comparable\nclinical alignment, are expected as to serve as useful tools in summarizing clinical documents and\nanswering patients' enquiry. With further advancements and refinements, it has promise its significant\nrole in digital health so as to facilitating patient centred care and improve healthcare workload efficiency.\nLarge language model (LLM) based chatbots have been evaluated in drafting clinician responses to\npatient enquiries5-7, showing promise as an aid to clinicians while demonstrating high degree of fluency,\nempathy and personalization. However, the usability and clinical adoption of generalist LLM models\nface challenges including the lack of consistency, perpetration of bias and suboptimal factual accuracy\nof responses5. The safety-critical nature of medical conversations and the importance of maintaining\ntrust between patients and healthcare providers necessitates significant improvements to existing\ngeneralist models. 8 Various methodologies have been developed to adapt LLMs for medical tasks, with\nthe objective of improving relevancy, accuracy and consistency of LLM outputs. These include pre-\ntraining LLMs using biomedical domain knowledge or electronic health records (e.g. Med-Palm-2,\nGatorTron); fine-tuning LLMs through provision of additional curated training datasets 10; or retrieval\naugmented generation (RAG) to provide medical domain knowledge for LLM response synthesis. 11\nThese techniques have bolstered the capability of LLMs to provide responses grounded in medical\ndomain knowledge.\nHowever, when adopting LLM-based chatbots in clinical practice, important considerations of\npracticality and health equity need to be taken into account for long-term scalable deployment solutions.\nThese include the need to ensure data security, engineering cost-effective and computing resource\nefficient pipelines, shortening inference time and maintaining accessibility via devices and platforms\n(eg, smartphones and Facebook Messenger). 12 Medical chatbots can fill gaps in access to quality\nservice and health information; but may widen health disparities gap in populations with low digital\nconnectivity. 13 With regards to device deployment of local LLMs, it is an advantageous feature which\nenables the chatbot to function in regions with poor internet connectivity, e.g, in low and middle income\ncountries (LMICs). This may aid in mitigating health disparity gap related to digital connectivity. In\naddition, offline chatbots help mitigate concerns regarding the privacy risks associated with sharing\nconfidential patient data over the internet. Thus, finetuning smaller biomedical domain specific LLM is\nexpected as a superior option than pretraining, as this choice is driven by the need to balance model\ncapability with computational resource constraints and extensive hardware demands, or RAG, which is\nfurther restrained by scalability and operational costs, for such challenges."}, {"title": "Methods", "content": "In this paper, we describe the training of 5 different fine-tuned, light-weight LLMs in answering\nmedication-related enquiries and performed validation of model performances. This is followed by\ntesting the performance of Med-Pal, the selected best performing fine-tuned LLM and benchmarked\nperformance against 2 other light-weight open-source models: Biomistral, a pre-trained medical-\ndomain specific LLM (7 billion parameter size)14 and Meerkat, a fine-tuned medical-domain specific\nLLM (7 billion parameter size)15."}, {"title": "Dataset description", "content": "We developed an expert curated, fine-grained training dataset consisting of 1,100 question and answer\npairs. This include 110 medications that is currently mostly prescribed within inpatient and outpatient\nsubspeciality clinics in the Singapore Health Services system (Supplementary Table 4, covering over\n70% of all medications annually prescribed in Singapore. This comprehensive dataset covers enquires\non medications across 14 different Anatomical Therapeutic Categories (ATC) (See entary Table 1);\nspanning 12 different broad domains: medication administration, adverse drug reaction, cautions and\ncontraindications, dosage form, dosage regimen, drug interaction efficacy, drug-drug interaction, food-\ndrug interaction, medication efficacy, indication, mechanism of action, pregnancy and lactation and\nmedication storage. Each question and answer pair was created by a board certified, registered clinical\npharmacist with > 10 years of experience, using a proprietary drug monograph database and publicly\navailable drug information leaflets as reference standards.\nWe split our dataset into 80:20 (training: validation). A total of 231 medication-related enquiries formed\nour validation dataset. Validation questions were open sourced, posed by members of the public on the\ninternet (randomly sampled from internet sources listed in supplementary Table 2). Questions selected\nwere broadly distributed across different domains and medication ATC categories.\nTesting dataset comprised of 35 questions randomly selected by JO (Principal Pharmacist) from open\nsourced online patient forums (supplementary Table 3). These questions were not used in the training\nor validation process. Validation and test questions were selected if they made reference made to at\nleast one medication class or one specific medication within question.\nValidation and test questions were classified by ATC category, question category and level of difficulty\n(low, medium, high). Level of difficulty was assigned based on the following guiding considerations 16,17:"}, {"title": "Med-Pal Chatbot Development", "content": "We first fine-tuned five open-source LLMs using our training dataset. We chose LLMs of parameter size\nof 7 billion or less: Llama-7b, Falcon-7b, Mistral-7b, Danube-1.8b and TinyLlama-1.1b. Following this,\nwe compared the performance of fine-tuned models on our validation questions. The best performing\nfine-tuned LLM model was selected and applied safeguards against adversarial attacks. We\nbenchmarked the performance of this final model (Med-Pal) against current state-of-the-art biomedical\nLLM models of similar parameter size."}, {"title": "Fine-Tuning Experiment Configurations", "content": "In our fine-tuning approach, we prioritized a balance between efficiency and learning by employing the\nfollowing hyperparameters: a learning rate of 2e-4 (0.0002), a training batch size of 4, and an evaluation\nbatch size of 8. To ensure reproducibility, a random seed of 42 was used. Furthermore, we leveraged\ngradient accumulation steps of 4, resulting in an effective training batch size of 16. The Adam optimizer\nwith \u03b2\u2081 set to 0.9, \u03b22 set to 0.999, and \u025b set to 1e-8 was chosen for optimization. To guide the learning\nrate throughout training, a cosine annealing scheduler was implemented. Finally, the number of epochs\nwas set to 3.\nTo promote efficient fine-tuning of these large models with limited computational resources, we\nemployed Native AMP with Low-Rank Adaptation (LORA). This technique focuses on adapting a low-\nrank subspace of the model parameters, significantly reducing computational costs. We set the LORA\nrank (r) to 8 and LORA alpha to 16, with a dropout rate of 0.1. Additionally, we targeted specific modules\nfor adaptation depending on the base LLM architecture.\nTo ensure a controlled comparison between the 5 LLMs within our computational constraints, we\nemployed a consistent hyperparameter configuration for fine-tuning with variations in the base model\nand target modules. For Llama_7b (h2oai/h2ogpt-4096-llama2-7b-chat), targeting the q_proj and v_proj\nmodules. We maintained this focus on the q_proj and v_proj modules with the Mistral_7b\n(mistralai/Mistral-7B-Instruct-v0.2), Tiny-Llama_1.1b (TinyLlama/TinyLlama-1.1B-Chat-v1.0), and\nDanube_1.8b (h2oai/h2o-danube-1.8b-chat). However, for the Falcon_7b (tiiuae/falcon-7b-instruct), we\nuniquely targeted the query_key_value modules, providing a contrast in our adaptation approach. This"}, {"title": "System Prompts", "content": "For all three LLMs, we adopted the system prompt \"Med-Pal: A friendly medication chatbot designed to\nprovide clear, concise, and accurate information on medication-related queries. Responses should be\nstraightforward, easily understandable by laypersons, and free from repetition. Focus on delivering\nrelevant and factual drug information in each interaction.\" This prompt guided the fine-tuning process\ntowards the desired conversational style and factual accuracy for the Med-Pal chatbot application."}, {"title": "Experimental Platform", "content": "The experimental platform for this study was a Windows 11 operating system utilizing Windows\nSubsystem for Linux 2 (WSL2). The hardware comprised a single GPU system with an NVIDIA RTX\n4090, with 24 GB VRAM, and powered by a 12th Gen Intel(R) Core(TM) i9-12900K CPU. Python\nprogramming language Version 3.10 was used within the Linux subsystem for executing the LLM fine-\ntuning jobs. Google Cloud Platform, Vertex Al was utilised to run the inference of BioMistral and Meerkat\nmodels, with 2xA100 GPU 40GB as default setup."}, {"title": "LLM Inference Configuration", "content": "In order to standardise the inference pipelines between the LLMs (fine-tuned or pre-trained), key\nparameters were carefully selected to harmonize the response quality and consistency. The\ntemperature parameter was set at 0.2 to curb variability, fostering more predictable outputs. The\ngeneration was constrained by a 'max_new_tokens' limit of 512, providing a balance between depth\nand succinctness while allowing sufficient contextual detail for coherent responses. A sampling strategy\nenabled by 'do_sample' introduced controlled diversity, enhancing the richness of the responses\nwithout compromising their relevance. To ensure focused content generation, 'top_p' and 'top_k' were\nadjusted to 0.95 and 100, respectively, prioritizing high-probability tokens and curating the selection\npool to the most relevant options. These configurations were deliberately chosen to refine the efficiency,\ncoherence, and applicability of the outputs and were kept consistent throughout the experiments for a\nfair comparative analysis between the LLMs' responses."}, {"title": "LLM Guard-railing", "content": "We further detail a sophisticated guard-railing mechanism implemented through the 'Ilm-guard' library\nto ensure the safety and accuracy of our healthcare-focused language model's outputs. This strategy\ninvolves pre-emptive content guidelines and a dual-layered scanning approach, pivotal for filtering\ninappropriate or harmful medical advice.\nOur strategy is underpinned by explicit content guidelines, categorically prohibiting certain phrases and\ntopics. Examples include prohibitions against suggesting the \"recreational use\" of drugs, advising to\n\"buy online without prescription,\" and citing \"unverified online pharmacies.\u201d These guidelines extend to"}, {"title": "Quantitative Evaluation", "content": "We introduce a simplified clinical evaluation criteria known as SCORE (Table 1), to evaluate responses\nfrom the various chatbots. There is currently no standardized checklist for chatbot evaluation used for\nmedical tasks. Current, natural language processing (NLP) or LLM model evaluation metrics rely on\nautomated methods, such as bilingual evaluation understudy, 14 but they fail to fully capture the\ncomplexity and nuances of medical retrieval tasks. SCORE measures performance of chatbot on clinical\ndomains of safety, clinical accuracy, bias, reproducibility and ease of understanding. All criteria are\ngraded on a 3-point Likert scale. Evaluation of responses from 3 fine-tuned LLMs at model validation\nstage was performed by a board certified pharmacist with > 10 years of clinical practice experience.\nComparative performance of Med-Pal against 2 other light-weighted biomedical domain LLMs\n(BioMistral and Meerkat) at model testing stage was performed by a 8-member multi-disciplinary team\nconsisting of registered physicians, pharmacists and nurses. 2 members (1 physician, 1 pharmacist)\nhas practiced for < 2 years, 2 members (2 physicians) has practiced between 5 \u2013 10 years, the rest (1\nphysician, 2 pharmacist, 1 nurse) has practiced for > 10 years."}, {"title": "Statistical Analysis", "content": "We calculated medians and quartiles of SCORE results for all LLM responses. Using a 3-point Likert\nscale suggest a non-normal data distribution and hence Kruskal-Wallis test was used to compare\ndifferences in medians between different LLMs, with two-tailed tests set at level of significance of P<\n0.05. We used the Dunn's test with Bonferroni correction for post hoc pairwise comparison to determine\ndifferences between groups. We adjusted significance level to P<0.005 to account for multiple tests.\nWe used the Fleiss' Kappa statistic to evaluate inter-rater variability. Mode imputation was performed\nfor all non-valid grading responses. We did not perform any data imputation for missing values."}, {"title": "Ethics Approval", "content": "Ethics approval was not required as training, validation and testing datasets did not contain any\nidentifiable patient information and was obtained from open sources."}, {"title": "Results", "content": "Fine-tuned Mistral_7b performed best in median total score (14, IQR 13-14), followed by Llama_7b (13,\nIQR 12-14), Falcon_7b (13, IQR 12\u201314), and TinyLlama_.1.1b (13, IQR 11\u201314), while Danube_1.8b\nperformed poorest in overall score (11, IQR 10 \u2013 12). (Figure 1) A p-value of < 0.05 suggest significant\ndifferences exist between different groups. Post hoc analysis revealed that all comparisons between"}, {"title": "Guardrail results", "content": "We created different adversarial prompts e.g. prompt injection, jailbreaking, prompt leak and tested\nthese questions on Med-Pal. We performed a visual inspection of Med-Pal responses and present a\nrandom sample of the results in Figure 7. Med-Pal was able to answer appropriately during this red-\nteaming experiment."}, {"title": "Discussion", "content": "We demonstrate the performance of a fine-tuned, lightweight, LLM-based medical chatbot in a wide\nvariety of medication-related inquiries. Med-Pal responded with high degree of clinical accuracy, safety,\nand free from bias, as substantiated by the validation scores obtained. We demonstrated the chatbot's"}, {"title": "A Comprehensive Workflow for Medical Domain Chatbot", "content": "In this paper we illustrate a 3-stage, development and evaluation workflow for a medical domain specific\nmedical chatbot (Figure 8). This methodological approach in Med-Pal's development process is\ndesigned to be a transparent and comprehensive framework that can be adopted by future projects\naiming to leverage LLMs for medical chatbot applications. In this workflow, we optimized clinical\naccuracy and patient safety through task-specific fine-tuning and implementation of safeguards against\npotential misuse."}, {"title": "Stage 1: Selection of the Optimal LLM through Comparative Analysis", "content": "Following the fine-tuning process, a systematic evaluation was conducted to identify the optimal LLM\nfor the Med-Pal chatbot application. This evaluation aimed to assess the quality and task-specific\nperformance of various fine-tuned LLM models against an independent validation set. We used an\nobjective, quantitative approach to evaluation of fine-tuned models using the SCORE rubric (Table 1)\nto select the LLM that best aligns with the desired characteristics of Med-Pal chatbot. This systematic\napproach not only facilitated model selection but also provided valuable insights into the strengths and\nweaknesses of each fine-tuned LLM's performance within the context of the Med-Pal application."}, {"title": "Stage 2: Testing of Fine-Tuning Efficacy against a Pre-Trained Healthcare LLM", "content": "Following the selection of the best performing LLM on validation dataset, we tested performance of our\nfine-tuned against pre-trained LLMs for biomedical domain. The models were evaluated on a distinct\ntest set not used in training or validation. This comparison aims to demonstrate the added value of fine-\ntuning a general-purpose LLM for the specialized task of the Med-Pal chatbot compared to relying solely\non a pre-trained medical model like BioMistral-7b."}, {"title": "Stage 3: Guard-railing Med-Pal for Safe and Responsible Operation", "content": "The final stage facilitates responsible operation of the Med-Pal chatbot through the implementation of\nsafeguards (guardrails). We began by prospectively identifying potential risks, such as the chatbot\ndispensing medical advice, promoting specific medications, or straying from factual drug information.\nOnce these risks are identified, we developed and implemented safeguards to mitigate them. These\ntechniques might involve restricting the chatbot's response repertoire to pre-approved information,\nincorporating fact-checking mechanisms to verify responses against reliable sources, or implementing\nlimitations to prevent the chatbot from offering medical advice.\nTo further assess the effectiveness of these safeguards, we employed a rigorous testing methodology\nthrough the crafting highly curated adversarial prompts, ranging from misdirection to prompt injections,\ndesigned to test Med-Pal's vulnerability in scenarios without guardrails and then again with the\nsafeguards deployed using the Ilm-guard library. This comprehensive testing approach allowed us to\nevaluate the efficacy of the implemented safeguards and ensure the Med-Pal chatbot operates\nresponsibly within its intended scope.\nIn the development of Med-Pal we chose to fine-tune instead of using a retrieval augmented generation\n(RAG) approach. RAG allows LLMs to tailor responses to specified tasks through provision of contextual\nknowledge e.g. clinical guidelines, medical textbooks, institution specific protocols. 25 RAG operates in"}, {"title": "Clinical Utility", "content": "LLM-based medical chatbots shows strong potential in enhancing patient-provider communication by\nproviding timely, accurate, and personalized responses to patient enquiries.31,32 The ability of LLMs to\nquickly synthesize and relay complex medical information in can significantly ease the burden on\nhealthcare providers by reducing the time needed to respond to patient queries and potentially\ndecreasing the cognitive load on clinicians, who are often overwhelmed by high volumes of patient\nmessages and administrative tasks. 32\nWe highlight several contributions of our paper that accelerate implementation of LLM-based chatbots\nin medicine. Firstly, we created an expert curated, fine-grained dataset of medication information on a\nbroad question type across various medication classes. This dataset can be updated for future fine-\ntuning or customization of LLMs, and to be used as a benchmarking dataset for medical chatbots. We\nintroduced a three-stage workflow that enhances the transparency and comprehensiveness of LLM-\nbased chatbot developments. This workflow includes rigorous guard-railing protocols that prevent the\nmodel from generating inappropriate content, thereby ensuring safe interactions with users. Moving\nforward, direct patient feedback on chatbot responses will further validate usability of Med-Pal.\nWe designed Med-Pal as a lightweight model, rendering it beneficial for deployment in areas with limited\ninternet connectivity. By running on edge devices like mobile phones as a lightweight LLM, Med-Pal\ncan deliver essential medical information in real-time, directly to the user's device, thus ensuring\naccessibility even in remote or underserved regions. This capability promotes delivery of equitable care,\nas it enables individuals in low-connectivity environments to access the same quality of healthcare\ninformation as those in more developed areas. 33 Furthermore, the local processing of queries on\npersonal devices mitigates potential privacy concerns, as sensitive patient data does not need to be\ntransmitted over the internet. This approach not only enhances data security but also aligns with HIPAA\nregulations concerning patient confidentiality and data protection.34"}, {"title": "Limitations", "content": "Our study is not without limitations. In view of practical considerations, we fine-tuned an exhaustive list\nof LLMs and chose only 2 LLMs for comparison against Med-Pal's performance. Our fine-tuning dataset\nmay not encapsulate the entire scope of medication-related questions. Slight inter-rater agreement on\nSCORE grades, as indicated by Fleiss' Kappa, suggests that more consistent and clear guidelines may\nbe needed for evaluators to assess responses effectively."}, {"title": "Conclusion", "content": "In conclusion, through this study we have comprehensively delineated the staged process involved in\nthe development of an instruction-tuned lightweight LLM model tailored for medication inquiries. Our\ninvestigation underscores the crucial necessity of instruction tuning for LLMs to attain optimal and\ncontrolled responses, particularly within healthcare contexts where precision and reliability are\nparamount. Moreover, our emphasis on the utilization of lightweight LLMs underscores their potential\nutility in advancing the delivery of equitable care. By shedding light on these key considerations, our\nstudy contributes to the broader discourse on enhancing computational models for healthcare\napplications, ultimately striving towards more effective and inclusive healthcare provision."}, {"title": "Data availability", "content": "All LLMs prompts are included in the manuscript. For any additional information about the fine-tuning\nand validation QnA datasets, please contact the corresponding authors."}, {"title": "Code availability", "content": "Code can be provided based on personal requests, please contact the corresponding authors."}, {"title": "Author Contributions", "content": "These authors have contributed equally: Kabilan Elangovan, Jasmine Ong.\nContributions:\nK.E, J.O., D.T. conceived the idea and designed the projects. K.E. and L.J. conducted all the technical\nfine-tuning and guard-railing experiments. J.O. and K.E. performed data collation, data analysis and"}, {"title": "Ethics Declarations", "content": "The authors declare no competing interests."}]}