{"title": "Code Readability in the Age of Large Language Models: An Industrial Case Study from Atlassian", "authors": ["Wannita Takerngsaksiri", "Micheal Fu", "Chakkrit Tantithamthavorn", "Jirat Pasuksmit", "Kun Chen", "Ming Wu"], "abstract": "Programmers spend a significant amount of time reading code during the software development process. This trend is amplified by the emergence of large language models (LLMs) that automatically generate code. However, little is known about the readability of the LLM-generated code and whether it is still important from practitioners' perspectives in this new era. In this paper, we conduct a survey to explore the practitioners' perspectives on code readability in the age of LLMs and investigate the readability of our LLM-based software development agents framework, HULA, by comparing its generated code with human-written code in real-world scenarios. Overall, the findings underscore that (1) readability remains a critical aspect of software development; (2) the readability of our LLM-generated code is comparable to human-written code, fostering the establishment of appropriate trust and driving the broad adoption of our LLM-powered software development platform.", "sections": [{"title": "1 INTRODUCTION", "content": "Code readability has long been a key focus in software engineering research [3, 8, 9, 19, 24, 39]. For example, Minelli et al. found that programmers dedicate approximately 70% of their time to reading and understanding source code [26]. Similarly, as Guido Van Rossum, the creator of Python, has noted: \"Code is read more often than it is written\" [15]. Thus, writing readable code not only facilitates better comprehension of its functionality [19] but also significantly reduces software maintenance costs.\nIn the age of large language models (LLMs) for code, these models have demonstrated remarkable results across various software development tasks [42] (e.g., code completion [37, 38], test case generation [2, 35], code review automation [17, 20, 30, 40], vulnerability detection and repair [10\u201312]). Recently, there has been a growing interest in integrating LLMs into modern Integrated Development Environments (IDEs) (e.g., GitHub Copilot [13]) to assist software engineers in implementing new features, improving code quality, fixing bugs, and resolving software development tasks.\nAt Atlassian, code readability has always been a cornerstone of software development, as it plays a critical role in facilitating software evolution and maintenance. In the age of large language models (LLMs), like those integrated into Jira (a task management platform) [4], the importance of code readability is amplified. Readable code ensures that teams can efficiently collaborate, debug, and enhance their software, reducing technical debt and long-term costs. Recently, we introduced HULA, a human-in-the-loop software development agents framework powered by large language models [36]. While HULA aims to streamline development tasks, a crucial question arises: does readability retain its value in this LLM-assisted paradigm, and if so, why? Additionally, how readable is the code it generates compared to human-written code? Understanding and ensuring code readability in LLM-generated code is vital for Atlassian, since it directly impacts the productivity and satisfaction of software development teams, enabling teams to work efficiently.\nIn this paper, we aim to investigate the practitioners' perceptions on the importance, the challenges, and the state of practice of code readability, and investigate the readability of LLM-generated code and human-written code in the context of enterprise software development tasks. Thus, we address the following two RQs.\nRQ1) How and why code readability is important in the age of large language models for code?\nThrough an online survey of 118 practitioners, we found that 81% of practitioners agreed that code readability is important. The key motivation is to reduce maintenance costs in the long term, while the key challenging factor is time constraints. Although code readability is currently improved via code review comments, 72% of practitioners agreed to consider adopting LLMs as an alternative. 39% of practitioners perceived that LLM-generated code is more readable than human-written code, followed by 34% perceived that the readability of both LLM-generated and human-written code"}, {"title": "2 MOTIVATION AND RELATED WORKS", "content": "In this section, we discuss motivation and related work to formulate the research questions.\nMotivation. Code readability is a cornerstone of software development at Atlassian, particularly as we integrate LLMs into Jira and other platforms [4, 36]. With the adoption of LLM-powered tools, the size and complexity of codebases are expected to grow rapidly as the majority of the codebase could be generated by LLMs [14]. This paradigm shift raises concerns among Atlassian software engineers and customers regarding the readability of LLM-generated code, which may increase technical debts, incur maintenance costs, and negatively affect enterprise coding standards. Therefore, it is of utmost importance to understand whether readability retains its value in this LLM-assisted paradigm, and if so, why? And, how readable is LLM-generated code compared to human-written code?\nRelated Works. Code readability is a property that influences how easily a given piece of code can be read and understood [5]. Over the past 20 years [3, 8, 9, 19, 24, 39], prior studies have focused on investigating factors influencing code readability and developing metrics, models, and tools to quantify code readability. For example, Buse and Weimer [5, 6] found that the average lines of code and average number of identifiers per line are closely associated with code readability. Similarly, Posnett et al. [31] identified associations between readability and metrics such as the number of lines, Halstead Volume, and character entropy. Furthermore, Scalabrino et al. [32, 33] emphasized that readability is influenced not only by code structure but also by textual features such as code comments. Moreover, Alawad et al. [3] observed a negative correlation between readability and code complexity, reporting that higher complexity is often associated with lower readability.\nIn the age of large language models (LLMs), studying code readability is more crucial than ever. While LLMs have now been seamlessly integrated into software development tools, workflows, and platforms like GitHub Copilot [13], IntelliJ IDEA [18], ChatGPT [28], and Atlassian's Jira AI [4, 36], they also introduce new challenges. Practitioners often raised concerns about the quality of LLM-generated code. For example, Liu et al. [21] found that 47% of ChatGPT-generated code snippets suffer from maintainability issues. Majdinasab et al. [22] discovered that 27% of code suggested by GitHub Copilot contains code vulnerabilities. Similarly, Perry et al. [29] found that users who had access to an AI assistant wrote significantly less secure code than those without access. Such concerns often lead to a lack of trust in the adoption of LLM-powered software development tools.\nWhile many studies flag issues on LLM-generated code in the security aspect, it is still unclear on the readability aspect of how readable is LLM-generated code compared to human-written code. Recently, Madi [1] found that code generated by GitHub Copilot is comparable in complexity and readability to code written by human pair programmers in the live coding of a controlled environment. However, little is known about the code readability of LLM-generated code on production in real-world scenarios and how the practitioners perceived code readability in the age of large language models. The importance of code readability and the gap in literature lead us to formulate the following research questions: (RQ1) How and why code readability is important in the age of large language models for code? and (RQ2) How readable is the LLM-generated code compared to human-written code?"}, {"title": "3 (RQ1) HOW AND WHY CODE READABILITY\nIS IMPORTANT IN THE AGE OF LARGE\nLANGUAGE MODELS FOR CODE?", "content": "3.1\nApproach\nThe practitioners' survey aims to explore four main topics of code readability: the importance, the challenges, the state of practice and the readability of LLM-generated code. In this section, we describe the design of our survey study and the participant selection process.\nSurvey. We design the 15-minute Google Form with four main sections: the importance of code readability, the challenges of code readability, the state of code readability, and the readability of LLM-generated code. The themes for the Likert scales of agreement questions (e.g., motivations for code readability) are derived from the literature review. Specifically, we categorized factors identified in the literature into themes, which formed the design of our survey questions (i.e., Q1.3, Q2.2, Q3.1). The full list of our survey questions and themes can be found on our GitHub repository [34]. Lastly, the survey obtained Ethical Permission from the Monash University Human Research Ethics Committee (MUHREC, Project ID 42299) before conducting the research.\nParticipant. We recruit participants through advertisements within Atlassian and public channels, including social media platforms like programming-related Facebook groups and personal LinkedIn networks. The participants can opt-in to win one of three gift cards of $20 as a token of appreciation. Finally, during 3 weeks of advertisement in June 2024, we received 118 survey responses with diverse backgrounds. We summarize the attributes of our participants' demographic in Figure 1.\n3.2 Results"}, {"title": "4 (RQ2) HOW READABLE IS THE\nLLM-GENERATED CODE COMPARED TO\nHUMAN-WRITTEN CODE?", "content": "4.1 Approach\nThe empirical study aims to understand code readability via static code analysis. In this section, we describe the design of our case study on HULA [36] over our internal dataset.\nLarge Language Model. We evaluate the code readability using our Human-in-the-loop Software Development Agents framework, HULA [36]. HULA is Atlassian's LLM-based agents framework for software development available internally in Jira Software. Specifically, the framework is used to generate a code patch given a code repository and a description of the Jira issue to be resolved. In this version, HULA uses GPT-4 [28] as a based LLM and the framework is evaluated without additional human feedback.\nDatasets. We evaluate HULA via the internal dataset [36], which includes a set of completed software development tasks (i.e., Jira issues, repositories and corresponding pull requests from BitBucket) at Atlassian. The dataset consists of 144 Jira issues with 250 coding files spanning six programming languages: TypeScript, Java, Kotlin, Python, Go and Scala.\nCode Readability Measurement. Following the recent study on code readability [1], we cautiously select the following eight static analysis metrics that are language-agnostic (i.e., can be used in multilingual) via the Multimetric library [41].\nFirst, we use Line of Code to evaluate the total number of lines of code in the file and Comment Ratio to evaluate the percentage of the lines of comment to code. Then, Cyclomatic Complexity [25] is used to evaluate the number of decision paths of the code, expressing the code complexity. Next, Maintainability Index [27] is used to measure how maintainable the code is. Lastly, we utilize Halstead Metrics [16], a set of metrics designed to quantify various aspects of code. These metrics are employed to evaluate key attributes, including Difficulty (the difficulty of the program to write or understand), Vocabulary (the number of unique operators and unique operands"}, {"title": "4.2 Results", "content": "Figure 2 shows the results of this research question, covering the case study of HULA on our internal dataset. Table 5 shows the statistical significance and the effect size of the result.\nOur case study on the HULA framework reveals that the generated code is comparable to the human-written code, with only minor differences. Figure 2 shows that HULA, with a GPT-4 based model, generates code that is highly similar to humans with only a slightly longer code but with no statistically significant difference in Cyclomatic Complexity and comment ratio. On Halstead's metrics, our LLM-generated code has marginally higher values on difficulty, vocabulary, volume, and time required. These results indicate that the HULA framework can produce code that closely resembles human-written code in terms of code readability, indicating the promising performance of LLM in production."}, {"title": "5 THREAT TO VALIDITY", "content": "Threats to internal validity. We use an online survey to study practitioners' perceptions of code readability. We design the questions based on literature reviews to mitigate the hallucination on factors related to code readability. However, we acknowledge the limitations that the justifications might be beyond the literature review which we sourced from.\nThreats to external validity. Our survey was derived from the perceptions of 118 practitioners with different backgrounds and work experiences in coding (see Figure 1). Nonetheless, we acknowledge that the results may differ when surveying different population groups. Additionally, the empirical study is a case study of our HULA framework, we acknowledge that the results may differ when experimenting with different models and datasets.\nThreat to construct validity. We use an empirical study with static code analysis as a proxy for code readability measurement between LLM-generated and Human code. We cautiously follow the existing work on selecting the metrics representing code readability. However, we acknowledge the limitations that the metrics might not completely represent the code readability from all perspectives."}, {"title": "6 CONCLUSION AND IMPLICATIONS", "content": "In this paper, we investigate the practitioners' perceptions on the importance, the challenges, and the state of practice of code readability, and investigate the readability of LLM-generated code and human-written code in the context of enterprise software development tasks. Our findings underscore that readability remains a critical aspect of software development, even in the age of large language models (LLMs). Moreover, the code generated by our LLM-powered framework, HULA, is shown to be comparable in readability to human-written code. This supports the establishment of appropriate trust and drives the broad adoption of our LLM-powered software development platform. Practitioners can confidently integrate LLMs into their workflows, knowing that code readability will not be compromised. This fosters more effective teamwork, simplifies maintenance tasks, and ensures the long-term success of software projects."}]}