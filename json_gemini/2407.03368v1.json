{"title": "Predict. Optimize. Revise. On Forecast and Policy Stability in Energy Management Systems", "authors": ["Evgenii Genov", "Julian Ruddick", "Christoph Bergmeir", "Majid Vafaeipour", "Thierry Coosemans", "Salvador Garc\u00eda", "Maarten Messagie"], "abstract": "This research addresses the challenge of integrating forecasting and optimization in energy management systems, focusing on the impacts of switching costs, forecast accuracy, and stability. It proposes a novel framework for analyzing online optimization problems with switching costs and enabled by deterministic and probabilistic forecasts. Through empirical evaluation and theoretical analysis, the research reveals the balance between forecast accuracy, stability, and switching costs in shaping policy performance. Conducted in the context of battery scheduling within energy management applications, it introduces a metric for evaluating probabilistic forecast stability and examines the effects of forecast accuracy and stability on optimization outcomes using the real-world case of the Citylearn 2022 competition. Findings indicate that switching costs significantly influence the trade-off between forecast accuracy and stability, highlighting the importance of integrated systems that enable collaboration between forecasting and operational units for improved decision-making. The study shows that committing to a policy for longer periods can be advantageous over frequent updates. Results also show a correlation between forecast stability and policy performance, suggesting that stable forecasts can mitigate switching costs. The proposed framework provides valuable insights for energy sector decision-makers and forecast practitioners when designing the operation of an energy management system.", "sections": [{"title": "I. INTRODUCTION", "content": "Managing energy assets in a grid system is a complex task that requires decision-making under uncertainty. The dynamics and stochasticity of the environment create a constantly evolving and inherently complex system. This reality necessitates making decisions with an incomplete knowledge of the future and for a limited time window, a scenario frequently approached through the lens of online optimization. In many applications, the future is reasonably predictable. Indeed, it is possible to make predictions about future cost function with a significant accuracy, particularly near future.\nTo effectively manage this, it is useful to combine the forecast of the problem environment with the optimization of the decision-making process. This combination of forecasting and decision-making is often referred to as the predict, then optimize problem, or an online optimization with predictions. The online optimization problems with predictions are commonly seen in energy applications such as electric vehicle charging [1] [2], battery scheduling [3][4] and energy and flexibility dispatch problems [5] [6]. In number of these applications, the decision-maker is faced with switching costs, which are the costs associated with updating the operational plan. For instance, transitioning from $x_{t-1}$ to $x_t$ typically incurs a switching cost or ramp cost, $d(x_t - x_{t-1})$. Consequently, the stage cost becomes time-coupled and is defined as: $C_t(x_{t\u22121},x_t) := f_t(x_t) + d(x_t - x_{t-1})$.\nIn the energy sector, the switching costs can arise from various factors, such as the physical limitations of ramping up or down energy production [7], managing server load balancing [8] and payment of network fees associated with energy trading [9]. While there has been a significant amount of research on online optimization problems with predictions, there is a gap in the literature on the impact of switching costs on the interaction between forecast model and the optimization algorithm. We address this gap by studying two aspects of the combined system: time-coupling and forecast stability.\nSwitching costs are a direct consequence of time-coupling, when the action $x_t$ at time $t$ influences the future actions $x_{t+1}$ and system states $S_{t+1}$, as defined by Lin et al. [8]. Errors in forecasts act as 'switching incentive' compelling policy revisions using more accurate predictions aligned with up-to-date information and the actual state of the system. This perspective suggests a balancing act between forecast accuracy and switching costs. This paper explores how this trade-off influences the system's design and operation, suggesting a nuanced view of forecasting's role in optimization.\nIn principle, forecasts used in optimization can be updated every time new information becomes available, often span multiple steps ahead and are revised periodically. Transitioning from the concept of time-coupling, we speculate that switching costs not only underscore the importance of forecast accuracy but also elevate the value of forecast stability. In this context, a stable forecast with minimal variation despite periodic updates, minimizes the need for frequent policy changes, effectively reducing switching costs. Consequently, this research aims to answer the following questions:\n\u2022 Do switching costs influence the balance between forecast accuracy and stability?\n\u2022 What are the optimal strategies for forecast revision in the presence of such costs?\n\u2022 And how can integrated systems be designed to effectively balance these considerations for improved decision-making in energy management?"}, {"title": "A. Related work", "content": "The problem of decision making with no complete information is often called an online optimization problem. According to Powell [10], the problem involves two main challenges: modelling the sequence of decisions and designing a policy to maximize the objective. Our focus is on a type of optimization problem that depends on the current state, uses a direct lookahead approach, and includes switching costs. The exact details of this problem are given in the Problem Statement in the Section II-A.\nLiterature solutions for integrating forecasting and optimization are classified based on the linkage of these subproblems. There are three categories: Direct, Indirect, and Semi-direct methods.\nDirect methods engage with the optimization problem during training of the forecast making it an integrated approach which is known as 'predict and optimize'. Such approach is proposed in Elmachtoub and Grigas [11], with optimization cost integrated directly into the forecast loss function to align forecasts with end-use optimization. This optimizes the prediction model in the forecasting stage for better decision-making in the optimization stage. The computational burden is partially resolved by using a simplified loss function, however more complex problems can still pose significant computational challenges. There are also other works that design an alternative task-specific loss function, such as reported in Mandi et al. [12], and tested on a real-world energy management problem.\nIndirect methods regard the two subproblems as separate, also referred in literature as 'predict, then optimize'. This approach is regarded as standard and is widely applied in practice. In the study by Vanderschueren et al. [13], an empirical evaluation of direct and indirect approaches is conducted in the context of cost-sensitive classification. Although the study is not directly applicable to the scheduling problems, it is interesting to note that those authors find that the indirect approach where optimization is performed on the predictions of the classifier outperforms the integrated approach. Therefore, the effectiveness of cost-sensitive classification may not always align with the intuitively expected benefits of integrated training within the 'predict and optimize'.\nThe third category, Semi-direct methods, considers characteristics of the optimization problem but abstains from direct interaction during training of the forecast. These methods can take various forms, as potential improvements can occur at any stage outside of the training process. An example is found in the work by Kazmi and Paskevich [14], where those authors propose a Bayesian Optimization approach for integrating the downstream optimization problem into the hyperparameter tuning process of the forecast model.\nThere is a noticeable gap in the literature when it comes to studying operational aspects of forecasting model and optimization deployment. For forecasting, the frequency of the forecast revision can be interpreted as both the frequency of the forecast model deployment and the frequency of model training. The latter aspect is studied by Spiliotis and Petropoulos [15], where those authors investigate different scenarios of updating the model fit for univariate exponential smoothing (ES) and univariate gradient boosting models (LightGBM).\nWe are particularly interested in the applications of optimization with predictions in environments where switching costs are present. This topic has featured in research on online convex optimization (OCO) problems. In control theory, a widespread strategy for tackling online multi-step optimization challenges is the employment of the Receding Horizon Control (RHC) algorithm, also referred to as model predictive control (MPC). When rerun at every time step, this method commits to the first step of the future horizon while treating later decisions as advisory. The research conducted by Chen et al. [16] sheds light on the role of noisy prediction in the design of the OCO algorithm. Those authors propose a model that simulates realistic prediction errors. Using this model, they show analytically that an alternative Averaging Fixed Horizon Control (AFHC) algorithm can achieve sublinear regret and a constant competitive ratio, which indicate a desirable level of optimality in reference to the theoretical best policy. Those authors state that other algorithms can reach better performance if they can use the predictions more efficiently. A later work, Chen et al. [17], introduces a class of policies known as Committed Horizon Control (CHC), which extends the principles of Receding Horizon Control (RHC) and Adaptive Forward Horizon Control (AFHC) through the integration of a commitment concept. This concept involves specifying a predetermined number of steps that the algorithm executes. The analysis of the generalized problem reveals a trade-off set by the varying levels of switching costs and quality of the predictions. The general observation is that the level of commitment is problem-specific and depends on the nature of the switching costs and the quality of the predictions. Therefore, the results show that the commitment level should be tuned for maximizing the performance of the policy.\nCurrent work sets to explore the performance of commitment-based policies in the context of energy management systems. We are particularly interested in analyzing the forecast and planning stability, as a potential factor that influences the performance of the policy. A comprehensive study of forecast stability is made by Godahewa et al. [18]."}, {"title": "B. Contents and Contributions", "content": "Through a systematic review of the literature, it becomes evident that the effects of predictions on online optimization problems with switching costs are not well understood. This present research aims to address this gap by studying the impact of forecast stability and accuracy on the performance of the policy in the context of energy management systems. The principle contributions are as follows:\n\u2022 First, we conduct a theoretical analysis of the performance bounds on the solving algorithm in an online optimization problem with switching costs. We discuss the role of policy commitment and draw a parallel to stability. A trade off is demonstrated between forecast accuracy and switching costs, with the commitment level regulating the balance between the two.\n\u2022 We investigate the effect of forecast accuracy and stability on the downstream performance of the optimization policy. We extend the definition of forecast stability towards probabilistic forecasts and propose a metric for measuring horizontal and vertical stability of scenario sets.\n\u2022 An empirical evaluation of the stability of deterministic and probabilistic scenario sets is conducted. We use the case study of the integrated forecasting and optimization energy management problem from the Citylearn 2022 competition. Based on the case study, we analyze the relationship between forecast accuracy, stability and the performance of the policy. We show that running the policy for a longer period provides a simple mechanism to avoid switching costs while maintaining or improving the performance.\n\u2022 Lastly, the paper concludes with a discussion of the general implications of the results for the design of the energy management systems followed by suggested future research directions."}, {"title": "II. METHODOLOGY", "content": "This paper addresses the challenge of optimizing battery storage management within a multi-agent energy management system. The setting of the problem is first outlined in the CityLearn Challenge 2022 [32] and based on a real-world dataset from a grid-interactive community. More generally, we consider an online optimization with switching costs. The problem is solved with model predictive control (MPC) and full details of the objective score and relevant constraints are provided in Appendix A. The problem includes finding an optimal state-dependent policy $X^{MPC} (S_t|0_{LA})$. The decision-maker is faced with a sequence of decisions, where the decision at each step is based on the current state $S_t$ of the system and the direct lookahead approximation $(_{LA}$. Using the framework proposed by Powell [10], we use the following formulation:\n$X^{MPC} (S_t|0_{LA}) = arg \\underset{X_{t+1},..., X_{t+H}}{min} [\\underset{i \\in n}{min} (\\Sigma_{t'=t+1}^{t+H} W_i C(x; S) + \\beta ||X_{tt'} - X_{t(t'-1)}||)] $  (1)\nIn this formulation:\n\u2022 $X^{MPC}(S_t|0_{LA})$ Represents the optimal set of decisions (battery charging $x^{pos}_{tt}$ and discharging $x^{reg}_{tt}$ actions) made by the MPC at time t based on the current state $S_t$ and the lookahead approximation model $(_{LA}$. This model enables predicting future costs within a horizon H, taking into account the expected electric load and PV generation.\n\u2022 $C(x; S)$ is the cost function, which is a function of actions $x = x_t, ...X_{t+H}$ and states $S = S_t, ...S_{t+H}$.\n\u2022 $W_s$ Weight factor for scenarios $s$, indicating the importance of different scenarios in the decision-making process. We assume that the weight factors are equal for all scenarios. In the deterministic case, the number of scenarios is equal to 1.\n\u2022 $h(x_{tt'}; 0)$ Represents the cost of the set of decisions $X_{t+1}, ..., X_{t+H}$ given the future forecast scenarios generated by the model $0_{LA}$.\n\u2022 $\\beta ||X_{tt'} - X_{t(t'-1)}||$ is a switching cost, where $\\beta \\in R^+$, and $|| ||$ can be any norm in $R^n$. The switching cost is imposed by ramping costs, integral to the objective function.\nOptimized battery schedules are evaluated using a set of KPIs. The optimization targets the minimization of the equally weighted sum of the normalized electricity cost C and carbon emissions G. The optimization score is defined as:\n$Average Score = avg( \\frac{C_{entry}}{C_{no\\,battery}} ,\\frac{G_{entry}}{G_{no\\,battery}})$ (2)\nWhen grid-related Key Performance Indicators (KPIs) are included, the average includes the grid score D. The grid\nscore is computed as the mean of the normalized ramping KPI R and the Load Factor KPI (1 \u2013 L). The grid score, D, introduces switching costs in the optimization by accounting for the ramping costs associated with frequent changes in forecasting. Therefore, in order to provide a comprehensive analysis of the impact of switching costs on the optimization, in this study we consider both optimizations with and without the grid score. The average score with the grid cost is defined as:\n$Average Score (with grid cost) = avg( \\frac{C_{entry}}{C_{no\\,battery}} ,\\frac{G_{entry}}{G_{no\\,battery}};D)$ (3)\nAll the scores range from 0 to 1 because they are normalized by the no-battery scenario, representing the improvement as a fraction of the metric compared to the no-battery scenario. "}, {"title": "B. Optimization", "content": "The optimal policy is computed for the current state of the system and the forecast for the next H time steps. An online optimization algorithm typically determines the optimal actions $X_{t+1},..., X_{t+H}$ given a prediction window of length H. Every v time steps, the optimization is rerun to generate a new plan. This algorithm is referred to as a Fixed Horizon Control (FHC) algorithm.\nIn the context of the online optimization algorithms, the term \"commitment\" refers to the duration or number of time steps for which the optimized policy is committed to before the optimization process is rerun to generate a new plan. This concept plays a crucial role in determining how frequently the optimization is updated based on new information, accumulation of forecast errors and changes in the system's state. An FHC algorithm with the shortest commitment is the Receding Horizon Control (RHC) algorithm. In RHC, the commitment is v = 1, indicating that the optimization is rerun at every time step.\nSimilar to the optimization, the forecast is also run in a rolling origin fashion. The optimal policy is then applied to the system for the next VF time steps and the process is repeated every VF steps. In summary, both the forecast and the optimization have the same rolling origin setup and need to be updated at certain intervals while committing to v steps. Ultimately, at each time step, the decision-maker is faced with a decision to either reuse the current plan or to revise it. Similarly, the forecast can be reused or revised. The resulting decision matrix is shown in Table I."}, {"title": "C. Theoretical Analysis of Performance Bounds", "content": "In this section, we analyze the upper bound on the performance of the FHC algorithm with a limited commitment v. We focus on the cost difference between the optimal policy and the policy produced by the FHC algorithm. Specifically, we examine the impact of the commitment v, which defines how often the policy and forecast are updated. Our goal is to show how the performance bound is influenced by a trade-off between forecast accuracy and switching costs.\nTo illustrate this, we consider two models of forecast error: independent and identically distributed (i.i.d.) noise, noise with exponentially decaying correlation and a probabilistic forecast. We start with the deterministic case (point forecast) and then extend to the probabilistic case (set of scenarios). Following the derivation in Chen et al. [17], we derive the average-case performance of the FHC algorithm by taking the expectation of the cost difference with respect to the prediction noise $(e(t))=1$.\nHere, OPT represents the optimal policy that would achieve the lowest possible cost if there were perfect information and no prediction errors.\n$E cost(FHC) < E cost(OPT) + \\frac{2TBD}{v} + 2GE\\Sigma_{t=1}^{T} || Y_t - Y_{t|t-v}^2 (t)||$ (4)\n$E cost(FHC) < E cost(OPT) + \\frac{2TBD}{v} + 2GT || f_v || .$ (5)\nThe term $|| f_v ||$ is the a-norm of the prediction error covariance, where a is the exponent of the H\u00f6lder condition. The two noise models (i.i.d. and exponentially decaying correlation) are explained below.\nIndependent and Identically Distributed Noise: The i.i.d. noise is a simple and understandable baseline for forecast error, without time dependency. For i.i.d. noise, we have:\n$f(s) = \\begin{cases}  I, s = 0\\\\  0, otherwise.  \\end{cases}$\nThe statistical properties of prediction errors in this context are:\n$E [e(s)e(s)^T] = R_e$\n$trace(R_e) = \\sigma^2$\nThis leads to the upper bound on the FHC cost:\n$E cost(FHC(v)) \\leq E cost(OPT) + \\frac{2TBD}{v} + 2GT\\sigma^a$ (6)\nThe upper bound on the competitive difference depends on v only in the first term (in the denominator). Therefore, the optimal cost is minimized when v = H, i.e., the commitment level reaches the maximum allowable duration and corresponds to the forecast horizon length. The first term represents switching costs, so a shorter commitment period leads to more frequent updates and higher switching costs. The second term, representing i.i.d. noise, is independent of \u03c5.\nExponentially Decaying Correlation: A more realistic model of prediction noise uses correlations that decay exponentially over time. For this, given a < 1, the Frobenius norm of the correlation structure is:\n$||f(s) ||_F =  \\begin{cases}   \\sigma a^s, s \\geq 0\\\\   0,  s < 0 \\end{cases}$ (7)\nWe then express the prediction error covariance as:\n$||f_v ||^2 = \\Sigma_{s=0}^{v} trace((R_e f (s) f (s)^T) = \\Sigma_{s=0}^{v} ||f(s)||^2_F (1/2,  (R_e))^2$\n$\\Sigma_{s=0}^{v} ||f(s)||^2_F =  \\Sigma_{s=0}^{v} a^{2s} = \\frac{1-\\alpha^{2v}}{1-\\alpha^2} $ \nGiven that h exhibits G-Lipschitz continuity (a = 1), the norm of the correlation function $|| f_r ||$ is bounded by:\n$||f_v|| \\leq  \\frac{\\epsilon \\sigma(1 - \\alpha^{2(v+1)/2})}{1-\\alpha^2}$ (8)\nPlugging this into the expression for the expected competitive difference of the FHC algorithm, we get:\n$Ecost (FHC(v)) \\leq \\\\ E cost (OPT) + 2  [\\frac{TBD}{v} + 2GT\\sigma \\frac{(1 - \\alpha^{2(v+1)/2}}{1-\\alpha^2}]$  (9)\n$< E cost (OPT) + 2  [\\frac{TBD}{v} + 2GT \\sigma  \\frac{\\alpha^{2v+2}}{2(a^2 - 1)}$] $ [7]\nTo simplify, we group the parameters independent of v:\n$A=\\frac{2TBD}{v} B=\\frac{1}{a^2-1} C = GT\\sigma \\alpha^2$\nThus, the expected competitive difference of the FHC algorithm is:\n$E cost(FHC(v)) \\leq E cost(OPT) + A+\\frac{B(C\\alpha^2 - 1)}{v} $ (10)\nThe competitive difference behavior depends on two main components. The term $\\frac{1}{v}$ decreases with v, while the term $B(C\\alpha^2 - 1)$ increases with v. Since $C\\alpha^2 $ approaches 0 as v increases, the second term is bound by B. Therefore, the minimal competitive difference is a trade-off between switching costs (first term) and forecast errors (second term)."}, {"title": "D. Forecast", "content": "Following the solution implemented in the winning submission of the competition, the forecasts are generated with gradient boosting regression trees and the linear least squares regression model. The gradient boosting implementation is LightGBM [33]. Predictions are made for the next 24 hours with 24 independent models. The scenario sets are generated with added gaussian noise. The details of the forecast models and the generation of the scenario sets are outlined in the competition paper by Nweye et al. [32] and the code repository of the winner solution is available on GitLab [34]. The evaluation conducted in this study is available in the code repository [35].\nWhile typical forecasting models use a building's own historical data for training, in this case, we apply forecasts to out-of-sample buildings using a model trained on an isolated set of buildings. This setup follows the problem setting given in the Citylearn Challenge 2022 [32]. Although this train-test splitting is not typical in forecasting, the setup is still relevant to real-world scenarios, as the lack of historical data within the test subset is compensated by the availability of perfect weather forecast and similarity between the train and test sets.\nIn practical applications, the forecast is issued periodically for a finite number of future time steps. This process is run iteratively in a rolling origin fashion, where the forecast is updated every of time steps. This approach involves continuously moving the time window forward by a certain step size after each forecasting iteration. For example, if we have a window size of 3 and a step size of 1, we would first generate the predictions and optimize for the steps 1-3, then at a second iteration, the forecasts are issued for the steps 2-4.\nAs a potential factor influencing the performance of the policy, we are interested in the stability of the forecast. The stability of the forecast is defined as the consistency of the predictions over time. Following the categorization, first proposed by Godahewa et al. [18], we distinguish vertical and horizontal stability. The difference between the two concepts is illustrated in Figure 3. We define the vertical stability as the difference between the predictions produced at different origins for the same time period, marked with the overlap area in Figure 2. If the forecast revisions are vertically stable, the corresponding adjustment costs in policy are set to be minimal. Horizontal stability characterizes the difference between predictions generated at the same origin. The horizontally stable forecasts are meant to reduce fluctuations between time steps within a prediction window."}, {"title": "III. EXPERIMENTATION AND RESULTS", "content": "Compared to theoretical analysis, practical setups are more complex. They often deal with non-trivial correlation structures in forecast errors and the potential for non-convex behaviors in optimization. This complexity is due to the necessity for cooperative behavior across multiple buildings. Additionally, various temporal dependencies emerge from switching costs and system feedback. To confirm the initial theoretical findings, we proceed with evaluating the performance of the FHC algorithm with different combinations of forecast and optimization commitment in a real-world scenario.\nAccording to the decision matrix in Figure I, at every time step the forecast and optimization plans can be updated or retained. Therefore, the forecast and optimization run with commitment periods UF and vo. respectively. We evaluate the performance of the FHC algorithm with different combinations of forecast and optimization commitment. The result is shown in Tables IIa and IIb. The scores in the tables indicate that updating the optimization plan more frequently than the forecast offers no added benefit. The optimal performance is achieved when the forecast and optimization are updated at the same frequency. Therefore, in the following analysis, we set v = VF = VO.\nFurther, we investigate the relationship between the performance of the FHC algorithm and properties of the forecast, namely accuracy and stability. In Figure 4, the accuracy and stability of the deterministic and stochastic forecasts are evaluated for different commitment periods. The comparison"}, {"title": "IV. DISCUSSION", "content": "The observations from the results are consistent with the theoretical analysis of the upper bound on the competitive difference of the FHC algorithm. We observe that the optimal commitment period is dependent on the forecast properties. The inclusion of switching costs in the optimization problem changes the relationship between desired forecast properties and the optimization score. The forecast error is broadly lower with shorter commitment periods, however, the horizontal and vertical stability become also relevant. In the theoretical analysis, we see that for a more realistic model of the prediction noise with exponentially decaying correlation, a trade-off emerges between the forecast error and the switching costs. Through testing with real data, we observe that switching costs can be partially mitigated by committing to more stable forecasts and optimization plans.\nThe addition of switching costs makes the algorithmic problem harder as it forces current actions to depend on beliefs about future cost functions. In Figure 5, we can see that the shape of the final load curve is significantly different when switching costs are included into the optimization. Without switching costs, the battery is charged and discharged while following the price and emissions cost signals. The resulting net load curve (in green) is compared to the perfect scenario (in yellow), where the battery is charged and discharged following the perfect forecast. In the case with switching costs, the optimal policy is regulating the net load curve to a smoother shape with less drops and peaks. The charging and discharging actions are the means of such regulation. However, due to the error in the forecast, the actual net load curve (in green) is not as smooth and flat as the optimal policy (in yellow). It generally follows the optimal policy, but with oscillation around it.\nMinimal commitment periods v of the control algorithm, combined with imperfect predictions, can lead to a scenario where the control strategy is constantly \"chasing\" the optimal state based on imperfect prediction. This can aggravate the impact of switching costs, as the control actions may change frequently in response to new information, even when such changes are not cost-effective in the long run. While traditional forward-looking RHC formulations can include terms in the objective function to penalize switching costs, the longer commitment period provides a native mechanism that respects past actions of the FHC algorithm. This mechanism can reduce the need for frequent adjustments, thus avoiding some of the switching costs.\nWe identify two reasons for underperformance of the algorithm with a minimal commitment period (RHC, equivalent to FHC with vo = 1). Firstly, when the policy is computed for a period in a problem with switching cost, the past decisions are calculated as optimal with respect to future decisions given the forecast, however, after the policy is reviewed at the next iteration with an updated forecast, the optimality of the executed decision at the recent time step does not hold, since the future policies within the same horizon are reviewed. A simple illustrative example would be the battery is discharged first with an outlook for charging in the future when the price is more favorable. Once the forecast and policy updates, the updated policy is discharging again, however the battery has been discharged earlier. The second reason is that while the objective cost function does include the term for the switching costs $\\beta ||X_t-X_{t\u22121}||$, the switching costs are computed pairwise between loads at close time instances. However, since the total charging capacity of batteries is finite and limited, it is advantageous to regulate switching costs within longer action windows.\nWhen prediction is inaccurate in the look-ahead window, the RHC is more effective than FHC with a commitment period. If we make predictions accurate for a small window y and then inaccurate for the remaining (\u03c9 \u2013 \u03b3) steps of the lookahead window, the fixed horizon policy is affected by the inaccurate predictions whereas RHC only acts on the correct ones. This is typically the case for a multi-step horizon forecast when the nearest steps are predicted at a higher accuracy. The situation changes for a stochastic MPC, generally hedged better against prediction errors. We can see from the results that FHC with longer commitment period becomes viable when the optimization is computed for a set of scenarios, as opposed to a deterministic point forecast."}, {"title": "V. CONCLUSION", "content": "In conclusion, this study highlights the critical role that switching costs, forecast accuracy, and stability play in the design and operation of energy management systems. In summary, our analysis shows that in systems where forecasts guide decision making, stability of predictions can reduce the frequency and severity of policy revisions, thereby mitigating the financial and operational impacts of switching costs. Our findings have significant implications for the design of energy management systems. They suggest that enhancing the stability of forecasts can improve system performance by reducing the need for frequent adjustments and managing the trade-offs between immediate and future resource allocation more effectively. Furthermore, we propose a novel approach to evaluating the stability of probabilistic forecasts using the Earth Mover's Distance, which provides a robust measure of the dissimilarity between scenario sets.\nLooking ahead, there are questions remaining to be addressed. For future research, we recommend further exploration into methods that enhance forecast stability without compromising accuracy. It would be beneficial to extend this work to other applications with switching costs, such as supply chain management and financial trading. Furthermore, from literature and current findings, there are indications that methods like AFHC and stochastic FHC, show more robustness in hedging against the forecast errors by aggregating policies with different underlying scenarios. However, they require more computational resources and are more complex to implement. An interesting avenue for future research would be defining the criteria for problems where these methods are most effective. These efforts would contribute to a deeper understanding of forecast-dependent optimization and improve the operational strategies of energy management systems facing an evolving energy landscape."}, {"title": "APPENDIX", "content": "Optimized battery schedules are evaluated using a set of KPIs, each of which is targeted for minimization. The optimization targets the minimization of the equally weighted sum of the normalized electricity cost C and carbon emissions G. The optimization score is defined as:\n$Average Score = avg( \\frac{C_{entry}}{C_{no\\,battery}} ,\\frac{G_{entry}}{G_{no\\,battery}})$ (20)\nWhen grid-related KPIs are included, the average includes the grid score D. The grid score is computed as the mean of the normalized ramping KPI R and the Load Factor KPI (1 \u2013 L). The grid score, D, introduces switching costs in the optimization by accounting for the ramping costs associated with frequent changes in forecasting. Therefore, in order to provide a comprehensive analysis of the impact of switching costs on the optimization, in this study we consider both optimizations with and without the grid score. The average score with the grid cost is defined as:\n$Average Score (with grid cost) = avg( \\frac{C_{entry}}{C_{no\\,battery}} ,\\frac{G_{entry}}{G_{no\\,battery}};D)$ (21)\nAll the scores range from 0 to 1 because they are normalized by the no-battery scenario, representing the improvement as a fraction of the metric compared to the no-battery scenario.\nThe normalized electricity cost, C, as delineated in Eq. 22, is the ratio of electricity spending in a given policy, Cpolicy, to the spending in a reference scenario without battery intervention, Cnobattery The cost metric c is further defined in Eq. 23 as the aggregate of the non-negative product of district-level net electricity price, Eh \u00d7 Th($), where En denotes the electricity consumption of the district at the hour h and Th specifies the electricity rate corresponding to that hour.\n$C = \\frac{C_{submission}}{C_{nobattery}}$ (22)\n$c = \\sum_{n-1}^{h=0} max (0, E_h \u00d7 T_h)$ (23)\nSimilarly, the normalized carbon emissions, G, is defined in Eq. 24 as the ratio of district carbon emissions for a given policy, gpolicy, relative to the emissions in the aforementioned baseline scenario, Inobattery. The emission metric g is elaborated in Eq. 25 as the sum of carbon emissions, measured in (kgCO2e/kWh), given by Eh \u00d7 Oh. Here, Oh represents the carbon intensity for the hour h.\n$G = \\frac{I_{submission}}{I_{nobattery}}$ (24)\n$g = \\sum_{n-1}^{h=0} max (0, E_h \u00d7 O_h)$ (25)\nLastly, the evaluation metric includes a grid-related KPI, D. The metric follows grid-level objectives, such as the minimization of ramping and load factor. It is defined as the mean of the normalized ramping KPI, R, and the Load Factor KPI,"}]}