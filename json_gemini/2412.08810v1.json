{"title": "Efficient Dynamic Attributed Graph Generation", "authors": ["Fan Li", "Xiaoyang Wang", "Dawei Cheng", "Cong Chen", "Ying Zhang", "Xuemin Lin"], "abstract": "Data generation is a fundamental research problem in data management due to its diverse use cases, ranging from testing database engines to data-specific applications. However, real-world entities often involve complex interactions that cannot be effectively modeled by traditional tabular data. Therefore, graph data generation has attracted increasing attention recently. Although various graph generators have been proposed in the literature, there are three limitations: i) They cannot capture the co-evolution pattern of graph structure and node attributes. ii) Few of them consider edge direction, leading to substantial information loss. iii) Current state-of-the-art dynamic graph generators are based on the temporal random walk, making the simulation process time-consuming. To fill the research gap, we introduce VRDAG, a novel variational recurrent framework for efficient dynamic attributed graph generation. Specifically, we design a bidirectional message-passing mechanism to encode both directed structural knowledge and attribute information of a snapshot. Then, the temporal dependency in the graph sequence is captured by a recurrence state updater, generating embeddings that can preserve the evolution pattern of early graphs. Based on the hidden node embeddings, a conditional variational Bayesian method is developed to sample latent random variables at the neighboring timestep for new snapshot generation. The proposed generation paradigm avoids the time-consuming path sampling and merging process in existing random walk-based methods, significantly reducing the synthesis time. Finally, comprehensive experiments on real-world datasets are conducted to demonstrate the effectiveness and efficiency of the proposed model.", "sections": [{"title": "I. INTRODUCTION", "content": "In industrial practice, a DBMS is required to adequately test its database engine and applications with representative data and workloads that accurately mimic the data processing envi- ronments at customer deployments [45], [46], [48]. However, due to privacy restrictions, actual data and workloads from enterprises are not usually available to database vendors [30]. A popular and effective solution is data generation, such as relational data generation [4], [9], [40], [46], [63]. The syn- thetic data, which can capture desired schematic properties and statistical profiles of the original data, has been widely used in the assessment of the performance impacts of engine upgrades, business data masking, and application-specific benchmarking. Although significant efforts have been made towards the generation of relational data, conventional tabular data cannot effectively model the complex relationships among entities in real-world applications. As a ubiquitous data structure, graphs are adopted to model these data interactions [26], [55], [57], such as web links [47] and friendships among people [8]. In particular, there are several strong motivations for studying graph generation in data management: (1) A lack of realistic graphs for evaluating the performance of the graph processing systems [35]. (2) Synthetic graphs that capture the distribution of the real-life network can be used in many social analysis tasks [52], [58], such as community detection [34] and network representations [37]. (3) The simulated graph anonymizes node entities and their link relationships, preventing information leakage of private data [59]. Nevertheless, most existing studies primarily focus on the generation of static graph structures, overlooking the dynamic nature of networks and rich node attribute information, which are two important characteristics present in most real-world graphs [27]. For instance, we consider a graph-based applica- tion: fraud detection on financial transaction graphs. Potential fraudsters are subject to the limited time of activities and would change their attacking strategies over time, leading to the co-evolution of topology connection (e.g., change of trans- action objects) and node attributes (e.g., change of location, transaction amount, etc) [7]. As the network data with user profiles and transaction records is sensitive, we cannot directly access the source data from financial institutions. Therefore, the high-quality synthetic data, which preserves the properties of the real network, can greatly facilitate the graph mining community, enabling the analysis of dynamic node behaviors and subsequently the design of effective prediction models. This, in turn, will help prevent financial losses caused by high- risk transactions. Thus, ignoring the dynamic feature and node information of graphs will cause significant information loss, and it is necessary to study how to generate realistic dynamic attributed graphs effectively and efficiently. In the literature, extensive studies have been conducted on static graph generation. Traditional approaches, such as random graph models [3], [56] and block-based models [16], [21] generate realistic graphs with predefined rules. To further generate network data for benchmarking the graph processing system and analyzing social networks, a line of efficient and scalable generators [12], [35], [52] has been introduced. However, these methods rely on specific statistical assumptions in simulation and fail to capture structure distribution directly from observed graphs. To address this, a variety of data-driven deep generators including the VAE-based [10], [19], RNN-based [29], [64], and GAN-based methods [5], [58] have been"}, {"title": "II. PRELIMINARY", "content": "A. Problem Definition\nA dynamic attributed graph $G = {G_t(V, E_t, X_t)|t = 1,2,..., T}$ is a sequence of attributed graph snapshots $G_t(V, E_t, X_t)$ across timesteps $t = 1, 2, ..., T$. $V$ denotes all the unique nodes in the dynamic graph $G$ (i.e., $V = \\cup_{t=1}^T V_t$) and $|V| = N$. Then, the snapshot in timestep $t$ can also be reformulated as $G_t(V, E_t, X_t)$. In this way, the structure evolution can be reflected as the change of edges $E_t$ over time. The attribute evolution can be reflected as the change of attribute matrix $X_t \\in R^{N \\times F}$ across time, where $F$ denotes the dimension of the attribute vector $x$ for each node $v$.\nAs graph structure $(V, E_t)$ can be modeled as adjacency matrix $A_t \\in R^{N \\times N}$, the dynamic attributed graph can be reformulated as $G = {G_t(A_t, X_t)|t = 1, 2, ..., T}$.\nProblem statement. Given a dynamic attributed graph $G = {G_t(A_t, X_t)|t = 1,2,...,T}$ sampled from a complex joint distribution of graph topology, node attributes and temporal properties, we aim to estimate the underlying distribution by training a graph generator $p_\\theta(G)$ to maximize the likelihood of generating $G$. Subsequently, we can simulate new dynamic attributed graph $G = {G_t(A_t, X_t)|t = 1, 2, ..., T}$.\nB. Variational AutoEncoder\nVariational autoencoder (VAE) [18] has emerged as a pow- erful probabilistic generative model for approximating the complex distribution of data space $p(x)$. It introduces a vector of latent variable $z$, which can be sampled from a prior distribution $p(z)$. Using the sampled $z$, we can explicitly reconstruct $x$ by employing a conditional distribution $p_\\theta(x|z)$ that depends on $z$, as follows:\n$p(x) = \\int p_\\theta(x|z)p(z)dz$\nwhere $p_\\theta(x|z)$ is modeled as a nonlinear neural network. The objective of the model is to maximize the likelihood of data $p(x)$. However, the introduction of a highly nonlinear mapping from $z$ to $x$ leads to the intractable inference of the true posterior $p(z|x)$. Consequently, the VAE proposes a variational approximation $q_\\varphi(x|z)$ as a replacement for the posterior and maximizes a variational lower bound, given by:\n$logp(x) \\geq -KL(q_\\varphi(x|z)||p(z)) + E_{q_\\varphi(x|z)}[logp_\\theta(x|z)]$"}, {"title": "III. THE PROPOSED APPROACHES", "content": "In this section, we first give the overall pipeline of our VRDAG. Then, we present the technical details of the three sub-modules in our generation pipeline, including latent vari- able sampler, attributed graph generator, and recurrence state updater. Next, we discuss the joint optimization strategy in our model and present the overall generative process. Finally, we give a detailed complexity analysis.\nA. Overall Pipeline\nConsider a dynamic attributed graph $G = {G_t(A_t, X_t)|t = 1,2,..., T}$, our goal is to learn a deep graph generator $p_\\theta$ that captures temporal dependencies between snapshots in the original graph. To achieve this, we propose to model each snapshot $G_t$ with a graph-based VAE conditioned on the historical hidden node states $H_{t-1} \\in R^{N \\times d_h}$ updated by a GRU-based recurrent model, where $d_h$ is the dimensionality of $H_{t-1}$. A bi-flow GNN is developed to encode both struc- tural and attribute information into $H_{t-1}$. The above design allows our architecture to sample temporal latent variables $Z_t \\in R^{N \\times d_z}$ for nodes at each timestep $t$, where $d_z$ denotes the dimensionality of $Z_t$. In our implementation, we treat the sampling distribution as a learnable prior distribution $p_\\phi$ conditioned on $H_{t-1}$. The sampled high-level node latent variables capture the co-evolution patterns of topology and attribute data and will be sent into the decoder for snapshot generation at each timestep. The decoder is an attributed graph generator that consists of a MixBernoulli sampler and an attention-based attribute simulator for generating structure and attribute, respectively.\nDuring training, with the original graph $G$ as input, we aim to learn the parameterized prior distribution $p_\\phi$ by minimizing its discrepancy with the posterior distribution $q_\\psi$ that can be modeled by maximizing the likelihood of generating the original graph sequence $G$. Specifically, we optimize structure and attribute reconstruction tasks to approximate posterior dis- tribution and train our attributed graph generator for decoding $Z_t$. During inference, with the parameterized prior distribution and attributed graph decoder trained on the original graph $G$, we sample the temporal latent variables from $p_\\phi$ and decode the new snapshot $G_t$ recurrently. Finally, we obtain the generated graph sequence $\\tilde{G} = {\\tilde{G_t}(\\tilde{A_t}, \\tilde{X_t})|t = 1, 2, ..., T}$.\nB. Latent Variable Sampler\nTo learn the prior distribution used to sample temporal latent variables $Z_t$, we propose to approximate it by performing max- imum a posteriori (MAP) inference on the parameters during training. Therefore, we then design a posterior distribution that takes into account not only the previous state $H_{t-1}$ but also"}, {"title": "1) Prior Distribution:", "content": "The prior latent distribution is ap- plied in the generation stage where the model simulates the new dynamic graph autoregressively from scratch. Thus, the prior distribution is only conditioned on the hidden state $H_{t-1}$ updated by recurrence updater as $p_\\phi(Z_t|H_{t-1})$. We can find that $H_{t-1}$ is the function of $G0$, the conditional prior distribution can be reformulated as $P(Z_t| G0(z_{i,t}|h_{i,t-1}) = N(z_{i,t}|\\mu_{i,t}, diag(\\sigma^2_{i,t}))$where $z_{i,t}$ is the latent embedding for node i at the current step t, $h_{i,t-1}$ denotes the historical hidden state of node i. Specifically, we choose the multi-layer perceptron (MLP) as the prior VAE network and use the reparameterization trick to express $z_{i,t}$ as a deterministic variable. This sampling process for latent variables can be formulated as:\n$\\mu_{i,t} = W_{prior}(\\sigma(W_{prior}h_{i,t-1}))$\n$\\sigma_{i,t} = exp(W_{prior}(\\sigma(W_{prior}h_{i,t-1})))$\n$Z_{i,t} = \\mu_{i,t} + \\epsilon \\cdot \\sigma_{i,t}, \\epsilon \\sim N(0,1)$where $W_{prior} \\in R^{d_z \\times d_h}, W_{prior} \\in R^{d_h \\times d_h}$ are learnable weight matrices in the prior network. $\\sigma(.)$ denotes a nonlinear transformation of the Leaky Rectified Linear Unit. $exp(.)$ is exponential operation. $d_z, d_h$ are the size of latent variables and hidden states, respectively."}, {"title": "2) Posterior Distribution:", "content": "During training, the model is trained by maximizing the likelihood of generating input dynamic attributed graph $G$. Thus, the posterior latent dis- tribution $q_\\psi$ is conditioned not only on hidden state $H_{t-1}$ but also on the observed snapshot $G_t(A_t, X_t)$ at timestep t to sample temporal latent variables for graph reconstruction task. To learn the prior distribution, we try to minimize its discrepancy with the posterior distribution.\nBefore modeling the latent space, we hope to incorporate knowledge of the message flow dynamics and node attributes into the node embeddings. To address this, a bi-flow graph encoder $$\\epsilon$$ is proposed. In particular, we divide the node state into in-flow state $in\\text{hit}$ and out-flow state $out\\text{hit}$, which denote the node status in different information-flow neigh- borhoods. To aggregate structural and attribute knowledge from two neighborhoods, we adopt GIN [61], a GNN variant with strong discriminative power. The bidirectional message- passing mechanism can be formulated as:\n$in\\text{hit} = f_{in}^{(l)}((1 + \\epsilon_{in})h_{i,t-1}^{(l-1)} + \\sum_{v_j \\in N_{in}(v_i)} h_{j,t}^{(l-1)})$\n$out\\text{hit} = f_{out}^{(l)}((1 + \\epsilon_{out})h_{i,t-1}^{(l-1)} + \\sum_{v_j \\in N_{out}(v_i)} h_{j,t}^{(l-1)})$where $in\\text{hist}$ are in-flow and out-flow state for node $v_i$ at timestep t in l-th encoder layer. $f_{in}^{(l)}, f_{out}^{(l)}$ are MLPs for in- flow encoder and out-flow encoder in l-th layer, respectively. $N_{in}(v_i)$ and $N_{out}(v_i)$ represent the sets of in-neighborhood and out-neighborhood of node $v_i$. In each layer, we apply a node state aggregator $f_{agg}$ which takes the concatenation of in and out node embedding as input and outputs the hop-level node state $h_i^{(l)}$. The aggregation operation can be written as:\n$h_i^{(l)} = f_{agg}([in\\text{hout}])$"}, {"title": "C. Attributed Graph Generator", "content": "Existing attributed graph generators can only synthesize attributes with pre-defined statistical distributions and ignore the inherent dependency between topology and attributes in the generation process. Besides, they fail to handle temporal information as they focus on static generation. To this end, we propose a data-driven factorized attributed graph generator for the decoding process in this subsection.\nIn real-world scenarios, node attributes and graph struc- ture are co-evolving and mutually influence each other over time [54]. For example, consider a co-author network, forming a link (i.e., a new collaboration) extends the research scope (e.g., having new research topics) and increases the impact of the authors (e.g., having a higher value of h-index). This attribute evolution can in turn help authors to establish new connections [53]. Motivated above, we design a recurrent generation method that can effectively model this co-evolution process.\nFor each timestep, it is natural for us to define the joint distribution across time $p_\\psi(A_t, X_t|Z  Xt|Zt, Ht-1) since that Ht-1 is the function of GAt|Z  Xt|Z  At|Z  X0 = p(Xt|Z  i=1p(A_{i,t}|Z  0 = Softmax(\\sum_{1 0, the generation of the individual edge is not independent, and the choice of mixture component $$\\alpha_{ki}$$ allows the model to sample from the best distribution based on the entire graph state, which also makes the different rows of adjacency can be computed in parallel, unlike the traditional autoregressive scheme [29], which is only conditioned on the partially generated components."}, {"title": "2) Attribute Decoder:", "content": "Given the generated adjacency $A_t$ and node states $S_t$, we adopt a vanilla graph attention network [50] to simulate a message passing on the generated graph structure and then produce node attributes:\n$\\tilde{X_t} = \\sigma(MLP_{attr}(GAT(S_t, \\tilde{A_t}))) $where $\\tilde{X_t} \\in R^{N \\times F}$ is the matrix of decoded attributes. The attentive graph neural network is denoted as $GAT(., .)$ and the MLP is represented as $MLP_{attr}$. $\\sigma(.)$ denotes a nonlinear activation function such as RELU or Sigmoid.\nD. Recurrence State Updater\nIn the update stage, we first encode observed snapshot $G_t$ with the bi-flow encoder as $\\epsilon(G_t) \\in R^{N \\times d_\\epsilon}$. Next, to learn the vector representation of time $t$ which can be fed into the neural network to capture both periodic and non-periodic patterns in graph sequence, we use the following TIME2VEC [17] technique:\n$f_T(t)[r] =\n\\begin{cases}\nwr t + \\varphi_r & if r = 0\\\\\nsin(w_r t + \\varphi_r), & if 1 0 \\\\\nlog p(G  q_\\psi(Zt, \\tilde{A_t}, \\tilde{X_t}) $ reflects the step-wise reconstruction loss which can be naturally decomposed into structure reconstruction loss $L_{struc}^{(t)}$ and attribute reconstruction loss $L_{attr}^{(t)}$ as:\n$L_{rec}^{(t)} = -log p(A_t, X_t|Z  truc + L_{attr}^{(t)}$"}, {"title": "Algorithm 1:", "content": "The VRDAG inference algorithm\nInput : T: time length, p: prior network, $\\epsilon$: bi-flow encoder, po: attribute graph generator, fr: TIME2Vec function,\nGRU: GRU update cell\nOutput: G: Synthetic dynamic attributed graph\n1 ($\\tilde{G}$, Ho) \u2190 (\u00d8, 0);\n2 for each t \u2208 [0, ..., T \u2013 1] do\n3  // Temporal latent variables sampling\n  $\\tilde{Z}_{t+1}$~P(Ht);\n4  // Attribute Graph Generation\n  $\\tilde{A}_{t+1}$ ~ P(At+1|Z  \\tilde{X_t});\n6  Get generated snapshot $G_{t+1}(\\tilde{A}_{t+1}, \\tilde{X}_{t+1})$;\n7  // Hidden State Update\n  $H_{t+1}$ = GRU([$\\epsilon(G_{t+1})||\\tilde{Z}_{t+1}||f_T(t+1)]$, $H_{t}$);\n8  $\\tilde{G}$ \u2190 $\\tilde{G}$U{$G_{t+1}(\\tilde{A}_{t+1}, \\tilde{X}_{t+1})$};\n9 end for\n10 return $\\tilde{G}$;\nFor the structure reconstruction criterion $L_{struc}^{(t)}$, we com- pute binary cross entropy (BCE) loss between $A_t$ and $A_t$ as:\n$L_{struc}^{(t)} = - \\frac{1}{|V|}  \\sum_{i=1}^{|V|}  [A_{ij,t}log \\tilde{A}_{ij,t} + (1-A_{ij,t})log(1-\\tilde{A}_{ij,t})]$\nFor attribute reconstruction loss $L_{attr}^{(t)}$, instead of using mean square error (MSE), a common criterion in feature reconstruction [15], [36], we adopt scaled cosine error (SCE), which can be formulated as:\n$L_{attr}^{(t)} = \\frac{1}{|V|}  (1 - \\frac{  }{\\parallel  \\parallel_2 \\parallel  \\parallel_2})^\\alpha, \\alpha \\geq 1, $\nwhere $x_{i,t}$, $X_{i,t}$ denote original and generated node attributes for $v_i$ at timestep t, respectively. $\\alpha$ is the scaling factor. Unlike MSE, this SCE is not sensitive to the impact of vector norm and dimensionality, improving the training stability of representation learning. Moreover, this criterion is selective enough to focus on those harder ones among imbalanced easy- and-hard samples. For easy samples with high-confidence pre- dictions, their corresponding cosine errors are usually smaller than 1 and decay faster to zero than hard samples when $\\alpha$>1. Thus, we can adaptively down-weight easy samples' loss in training and focus more on those hard ones.\nF. Generative Process\nWith the trained model, we can generate a new dynamic at- tributed graph G from scratch. The overall VRDAG inference algorithm is described in Algorithm 1. Before the generative process, we initialize an empty set to collect generated graph snapshots and initialize the hidden state Ho \u2208 R^{N\u00d7dh} as a zero vector matrix (Line 1). During recurrent generation, we sample the new latent node representation \\tilde{Z}{t+1} from the prior distribution p(Ht) that is conditioned on historical graph information Ht at each step (Line 3). Then, we generate the adjacency matrix of the graph at step t + 1 using the trained MixBernoulli sampler (Line 4). Subsequently, we synthesize node attributes with the attribute decoder based on"}, {"title": "G. Complexity Analysis", "content": "In this subsection, we provide a detailed complexity analysis of model parameters, model training, and model inference. For simplicity, we use d to denote hidden units of deep neural networks utilized in our architecture. O denotes model parameters. $L_m$ denotes the layer number of MLP used in our bi-flow encoder and L is the number of GNN layers. r is the number of sampled neighbors per node. Q denotes the number of negative samples used in the structure reconstruction task. S represents the number of training epochs and l' denotes the length of random walk. M denotes the number of temporal edges. C represents the number of components in the mixture model of TIGGER [11].\nModel complexity. For model complexity, we analyze each learnable module including bi-flow encoder ($O(L \\times L_m \\times d^2 + Fd)$), the prior/posterior distribution ($O(d^2)$), MixBernoulli Sampler ($O(d^2 + Kd)$), attribute decoder ($O(d^2)$), learnable time vector ($O(d_T)$), and GRU cell ($O(d^2 + d \\times d_T)$). The overall model complexity O(|\u03b8|) can be simplified to $O(L \u00d7 L_m \u00d7 d^2 + Fd + d \u00d7 d_T)$.\nTraining complexity. For model training, the prior and poste- rior distribution sampling both take a complexity of O(Nd2). The complexity of bi-flow graph encoding has a complexity of $O(L(Nd_T + L_mNd^2))$. Topology decoding and attribute decoding cost $O(N^2d)$ and $O(L(Nd_T + Nd^2))$, respectively. The complexity of time vectorization and GRU updates are $O(dT)$ and $O(N(d^2 + d \u00d7 d_T))$. Calculating $L_{prior}^{(t)}$, L_{struc}^{(t)}, and $L_{attr}^{(t)}$ take a complexity of O(Nd), O(Nr + NQ), and O(Nd), respectively. The complexity of the backward process is O(|\u03b8|). Considering the length of time steps T and training epochs S, the final training complexity is $O(TS(N^2d + L(Ndr + L_mNd^2)))$.\nInference complexity. For complexity analysis of model in- ference, the computation of posterior sampling, loss function, and backward propagation in the training stage are removed. Then, we obtain the inference complexity as $O(T(N^2d + L(Ndr + L_mNd^2)))$. The most efficient temporal random walk-based generator TIGGER [11] has a complexity of $O(M \u00d7 l' \u00d7 (N + C'))$. As M \u00bb N in many real-world dynamic graphs, our VRDAG, which eliminates the need for extensive path sampling, can greatly facilitate generation efficiency."}, {"title": "H. Extension", "content": "As stated in Section II, we consider all unique nodes V = U1 V in the dynamic graph G and model the structural evolution as changes in Et. To extend our architecture to support flexible node addition and deletion, we discuss the potential solutions: (1) For node deletion, we consider each node vi and maintain a counter to track its consecutive time steps of isolation from other nodes in the graph. If this count reaches the predefined threshold Tdel, we remove its hidden node state in the sequential generation, ensuring it no longer exists in the new snapshot generation. (2) For node addition, we propose to train a predictor to estimate the newly added node number, Nadd, based on the hidden graph state htt-1 hit, which is calculated as the average hidden node state. Additionally, we parameterize a distribution p\u03c9 to sample the initial hidden states H\u2208 RNaddxdh for these added nodes. The distribution is conditioned on the time vector fr(t) and the hidden graph state htt. Then, we stack the original hidden node state Ht with the sampled H and feed them into our attributed graph decoder to generate the new snapshot."}, {"title": "IV. EXPERIMENTS", "content": "A. Experiment Settings\n1) Dataset and Baselines: We use six dynamic graph datasets including five publicly available graphs (Emails- DNC (Email) [43], Bitcoin-Alpha (Bitcoin) [22], Wiki-Vote (Wiki) [25], Brain [60], and GDELT [69]) and a guaranteed-loan network (Guarantee) collected from a major commer- cial bank. The detailed dataset descriptions can be found in Appendix A-A [1]. For compared baselines, we adopt four dynamic graph generators (i.e., TagGen [68], Dymond [65], TGGAN [67], and TIGGER [11]) and two powerful static graph generators including GRAN [29] and GenCAT [32]. GenCAT is the latest state-of-the-art attributed graph generator. Detailed descriptions for the compared methods can be found in Appendix A-B [1]. We have provided detailed dataset statistics in TABLE I.\n2) Evaluation Metrics: The evaluation metrics are catego- rized into graph structure metrics, node attribute metrics, and difference metrics. We leave the detailed node attribute metrics in Appendix A-C [1].\nGraph structure metrics. To evaluate structure genera- tion performance, we consider eight widely used network properties [11], [20], [58], including in/out-degree distri- bution (In/Out-deg dist), clustering coefficients distribution (Clus dist), power-law exponent of in/out-degree distribution (In/Out-PLE), wedge count, number of components (NC), and size of the largest connected components (LCC). For the degree distribution and clustering coefficient distribution, we compute the Maximum Mean Discrepancy (MMD) [58] to quantify the distribution difference between the original snap- shot and the synthetic snapshot for each unique timestep. The average distribution discrepancy across the graph sequence is then reported. Regarding other node or graph-level metrics, we follow the approach described in [68] and extend them to the dynamic setting by measuring the average discrepancy in percentage as:\n$M_{avg}(G, \\tilde{G}) = Mean_{t=1:T} \\frac{|M(G_t) - M(\\tilde{G}_t)|}{M(G_t)}$\nwhere M(\u00b7) denotes a specific metric function.\nDifference metrics. To measure the difference between two consecutive snapshots, we compute the differences for each pair of nodes with the same ID in the neighboring snapshots using three structural properties (degree, clustering coefficient, and coreness) and two attribute metrics (MAE and RMSE), and report the average result of each metric. Specifically, consider the consecutive snapshots Gt and Gt+1, the node with the same ID on two graphs is denoted as vi,t and vi,t+1, respectively. For structure difference, we let the structural property (e.g., degree) for the node as Ps, and the topology difference Ds can be measured as:\n$D_s(G_t, G_{t+1}) = \\frac{1}{N} \\sum_{i=1}^N |P_s(v_{i,t}) - P_s(v_{i,t+1})|$\nFor attribute discrepancy, we denote Xi,t, Xi,t+1 as attribute data of vi in the two consecutive snapshots. The MAE and RMSE can be calculated as:\n$MAE(X_t, X_{t+1}) = \\frac{1}{N} \\sum_{i=1}^N |x_{i,t} - x_{i,t+1}|$\n$RMSE(X_t, X_{t+1}) = \\frac{1}{N} \\sqrt{  (x_{i,t} - x_{i,t+1})^2}$"}, {"title": "V. RELATED WORK", "content": "In this section, we summarize the related works regarding relational data generation, static/dynamic graph generation, and the variational recurrent model (See Appendix B-A [1]).\nRelational data generation. In recent years, generating synthetic relational data has attracted significant interest in database research. To benchmark data management solutions, Arasu et al. [4] study the problem of synthetic databases and propose a declarative approach for specifying data characteris- tics using cardinality constraints. This work is later extended in Hydra [46] to incorporate dynamism in the generation process. After that, PiGen [44] expands the scope of the supported constraints to the general projection operator, leading to more satisfactory database generation. For practical cloud database evaluation, Yang et al. [63] consider data generation from query workloads with supervised autoregressive models. Mo- tivated by scalability testing for database systems, the Dataset Scaling Problem (DSP) [49] which aims to generate scaled relational tables with the given factor has been introduced. Dscaler [66] further considers non-uniform scaling (nuDSP), allowing tables to scale by different factors.\nStatic graph generation. The generation of realistic graph data is a long-standing research problem. Traditional graph generators have focused on various families of random graph models, such as the Barab\u00e1si-Albert model [3], stochastic block models [2], Kronecker graph models [24], and exponen- tial random graph models [41]. To generate large-scale graphs for graph processing system benchmarking, TrillionG [35] proposes a scope-based model by generalizing the random graph model [3]. FastSGG [52] can efficiently generate high-quality social networks using user-defined configurations. However, the graph generators mentioned above are limited to reproducing specific statistical properties and fall short of capturing complex graph data distributions. To address this, data-driven deep learning methods have been introduced. VAE- based methods [19], [31] parameterize variational autoencoder with graph neural network (GNN) [28] to generate individual entries in adjacency matrix independently. RNN-based gener- ation models, such as GraphRNN [64] and GRAN [29], model the probability of generating edges at each step using a specific output distribution conditioned on the already generated graph. Bojchevski et al. [5] employ Generative Adversarial Networks (GANs) to learn the distribution of biased random walks over the input graph for network generation, achieving superior performance. Most existing static graph generators primarily focus on the generation of structures while ignoring node attributes. Pfeiffer et al. [39] introduce the Attributed Graph Model (AGM) framework to jointly model network structure and vertex attributes. Nonetheless, the AGM is limited in com- puting edge probabilities conditioned on correlated attributes and lacks the ability to synthesize accurate node attributes. To address attribute generation, Largeron et al. [23] propose ANC, which generates numeric node attribute values following a nor- mal distribution. While simple, this method is not suitable for generating real-world graphs. Recently, Maekawa et al. [32] introduce GenCAT, which can generate attributes following user-specified distributions, providing greater flexibility."}, {"title": "VI. CONCLUSION", "content": "In this paper, we propose VRDAG, a data-driven varia- tional recurrent framework, for efficient dynamic attributed graph generation. In particular, we first introduce a bi-flow graph encoder to preserve relational knowledge in the newly generated snapshot. Then, a recurrence updater is applied to update hidden node states. Next, a learned prior distribution is used to generate temporal latent variables based on the hidden states of early graphs. This technique can capture dependencies between and within topological and node attribute evolution processes. Sampled latent variables are subsequently fed into a factorized decoder with a MixBernoulli sampler and an attentive attribute decoder to generate the new snapshot. We obtain the final graph sequence by recurrently synthesizing snapshots in this manner. Extensive experimental results show VRDAG's effectiveness in generating high-quality dynamic attributed networks. Moreover, the efficiency evaluation proves that our recurrent model significantly reduces generation time compared to existing state-of-the-art deep generative methods."}]}