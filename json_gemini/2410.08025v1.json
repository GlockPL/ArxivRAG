{"title": "THE COMPUTATIONAL COMPLEXITY OF CIRCUIT DISCOVERY FOR INNER INTERPRETABILITY", "authors": ["Federico Adolfi", "Todd Wareham", "Martina G. Vilas"], "abstract": "Many proposed applications of neural networks in machine learning, cogni-\ntive/brain science, and society hinge on the feasibility of inner interpretability via\ncircuit discovery. This calls for empirical and theoretical explorations of viable al-\ngorithmic options. Despite advances in the design and testing of heuristics, there\nare concerns about their scalability and faithfulness at a time when we lack under-\nstanding of the complexity properties of the problems they are deployed to solve.\nTo address this, we study circuit discovery with classical and parameterized com-\nputational complexity theory: (1) we describe a conceptual scaffolding to reason\nabout circuit finding queries in terms of affordances for description, explanation,\nprediction and control; (2) we formalize a comprehensive set of queries that cap-\nture mechanistic explanation, and propose a formal framework for their analysis;\n(3) we use it to settle the complexity of many query variants and relaxations of\npractical interest on multi-layer perceptrons (part of, e.g., transformers). Our find-\nings reveal a challenging complexity landscape. Many queries are intractable (NP-\nhard, -hard), remain fixed-parameter intractable (W[1]-hard) when constrain-\ning model/circuit features (e.g., depth), and are inapproximable under additive,\nmultiplicative, and probabilistic approximation schemes. To navigate this land-\nscape, we prove there exist transformations to tackle some of these hard problems\n(NP- vs. \u03a3-complete) with better-understood heuristics, and prove the tractabil-\nity (PTIME) or fixed-parameter tractability (FPT) of more modest queries which\nretain useful affordances. This framework allows us to understand the scope and\nlimits of interpretability queries, explore viable options, and compare their re-\nsource demands among existing and future architectures.", "sections": [{"title": "1 INTRODUCTION", "content": "As artificial neural networks (ANNs) grow in size and capabilities, Inner Interpretability \u2014 an\nemerging field tasked with explaining their inner workings (R\u00e4uker et al., 2023; Vilas et al., 2024a)\nattempts to devise scalable, automated procedures to understand systems mechanistically. Many\nproposed applications of neural networks in machine learning, cognitive and brain sciences, and\nsociety, hinge on the feasibility of inner interpretability. For instance, we might have to rely on\ninterpretability methods to improve system safety (Bereska & Gavves, 2024), detect and control\nvulnerabilities (Garc\u00eda-Carrasco et al., 2024), prune for efficiency (Hooker et al., 2021), find and\nuse task subnetworks (Zhang et al., 2024), explain internal concepts underlying decisions (Lee et al.,\n2023), experiment with neuro-cognitive models of language, vision, etc. (Lindsay, 2024; Lindsay\n& Bau, 2023; Pavlick, 2023), describe determinants of ANN-brain alignment (Feghhi et al., 2024;\nOota et al., 2023), improve architectures, and extract domain insights (R\u00e4uker et al., 2023). We\nwill have to solve different instances of these interpretability problems, ideally automatically, for\nincreasingly large models. We therefore need efficient interpretability procedures, and this requires\nempirical and theoretical explorations of viable algorithmic options.\nCircuit discovery and its challenges. Since top-down approaches to inner interpretability (see Vilas\net al., 2024a) work their way down from high-level concepts or algorithmic hypotheses (Lieberum\net al., 2023), there is interest in a complementary bottom-up methodology: circuit discovery (see Shi\net al., 2024; Tigges et al., 2024). It centers around neuron- and circuit-level isolation or description\n(e.g., Hoang-Xuan et al., 2024; Lepori et al., 2023) and attempts to build up higher-level abstractions\nfrom this low-level foundation. The motivation is the circuit hypothesis: that models implement\ntheir capabilities via small subnetworks (Shi et al., 2024). Advances in the design and testing of\ninterpretability heuristics (see Shi et al., 2024; Tigges et al., 2024) come alongside interest in the\nautomation of circuit discovery (e.g., Conmy et al., 2023; Ferrando & Voita, 2024; Syed et al., 2023)\nand at the same time concerns about its feasibility (Voss et al., 2021; R\u00e4uker et al., 2023). One\nissue is the challenge of scaling up methods to larger networks, more naturalistic datasets, and more\ncomplex tasks (e.g., Lieberum et al., 2023; Marks et al., 2024), given their search over large search\nspaces involving some manual-intensive steps (Voss et al., 2021). A related issue is that current\nheuristics, though sometimes promising (e.g., Merullo et al., 2024), often yield discrepant results\n(see e.g., Shi et al., 2024; Niu et al., 2023; Zhang & Nanda, 2023). They often find circuits that\nare not functionally faithful (Yu et al., 2024a), or that lack the expected affordances (e.g., effects on\nbehavior; Shi et al., 2024). This questions whether certain localization methods yield results that\ninform editing (Hase et al., 2023), and vice versa (Wang & Veitch, 2024). More broadly, we run into\n'interpretability illusions' (Friedman et al., 2024) when our simplifications (e.g., circuits) mimic the\nlocal input-output behavior of the system but lack global faithfulness (Jacovi & Goldberg, 2020) .\nExploring viable algorithmic options. These challenges come at a time when, despite emerg-\ning theoretical frameworks (e.g., Vilas et al., 2024a; Geiger et al., 2024), there are notable gaps\nin the formalization and analysis of the computational problems that interpretability heuristics at-\ntempt to solve (see e.g., Wang & Veitch, 2024, \u00a78). Issues around scalability of circuit discovery\nand faithfulness have a natural formulation in the language of Computational Complexity Theory\n(Arora & Barak, 2009; Downey & Fellows, 2013). A fundamental source of breakdown of scala-\nbility - which lack of faithfulness is one manifestation of is the intrinsic resource demands of\ninterpretability problems. In order to design efficient and effective solutions, we need to understand\nthe complexity properties of circuit discovery queries and the constraints that might be leveraged to\nyield the desired results. Though a decade of experimental efforts has made promising inroads, the\ncomplexity-theoretic properties that naturally impact scalability and faithfulness remain open ques-\ntions (see e.g., Subercaseaux, 2020, \u00a76C). We settle them here by complementing these efforts with\na systematic study of the computational complexity of circuit discovery for inner interpretability. We\npresent a framework that allows us to (a) understand the scope and limits of interpretability queries\nfor description/explanation and prediction/control, (b) explore viable options, and (c) compare their\nresource demands among existing and future architectures."}, {"title": "1.1 CONTRIBUTIONS", "content": "\u2022 We present a conceptual scaffolding to reason about circuit finding queries in terms of\naffordances for description, explanation, prediction and control.\n\u2022 We formalize a comprehensive set of queries that capture mechanistic explanation, and\npropose a formal framework for their analysis.\n\u2022 We use this framework to settle the complexity of many query variants, parameterizations,\napproximation schemes and relaxations of practical interest on multi-layer perceptrons,\nrelevant to various architectures such as transformers.\n\u2022 We demonstrate how our proof techniques can also be useful to draw links between inter-\npretability and explainability by using them to improve existing results on the latter."}, {"title": "1.2 OVERVIEW OF RESULTS", "content": "\u2022 We uncover a challenging complexity landscape (see Table 4) where many queries are\nintractable (NP-hard, \u03a3-hard), remain fixed-parameter intractable (W[1]-hard) when con-"}, {"title": "2 MECHANISTIC UNDERSTANDING OF NEURAL NETWORKS", "content": "Mechanistic understanding is a contentious topic (Ross & Bassett, 2024), but for our purposes it\nwill suffice to adopt a pragmatic perspective. In many cases of practical interest, we want our inter-\npretability methods to output objects that allow us to, in some limited sense, (1) describe or explain\nsuccinctly, and (2) control or predict precisely. Such objects (e.g., circuits) should be 'efficiently\nqueriable'; they are often referred to as \u201ca way of making an explanation tractable\" (Cao & Yamins,\n2023). Roughly, this means that we would like short descriptions (e.g., small circuits) with use-\nful affordances (e.g., to readily answer questions and perform interventions of interest). Circuits\nhave the potential to fulfill these criteria (Olah et al., 2020). Here we preview some special circuits\nwith useful properties which we formalize and analyze later on. Table 1 maps the main circuits we\nstudy to their corresponding affordances for description, explanation, prediction and control. Formal\ndefinitions of circuit queries are given alongside results in Section 4 (see also Appendix)."}, {"title": "3 INNER INTERPRETABILITY QUERIES AS COMPUTATIONAL PROBLEMS", "content": "We model post-hoc interpretability queries on neural networks as computational problems in order\nto analyze their intrinsic complexity properties. These circuit queries also formalize criteria for\ndesired circuits, including those appearing in the literature, such as 'faithfulness', 'completeness',\nand 'minimality' (Wang et al., 2022; Yu et al., 2024a)."}, {"title": "3.1 QUERY VARIANTS: COVERAGE, SIZE AND MINIMALITY", "content": "The coverage of a circuit refers to the domain over which it behaves in a certain way (e.g., faithful\nto the model's prediction). Local circuits do so over a restricted set of inputs. Global circuits do\nso over all possible inputs. The size of a circuit is measured in number of neurons. Some circuit\nqueries will require circuits of bounded size whereas others leave the size unbounded. A circuit with\na certain property (e.g., local sufficiency) is minimal if there is no subset of its neurons that also has\nthat property (not to be confused with minimum size among all such circuits present in the network)."}, {"title": "3.2 CLASSICAL AND PARAMETERIZED COMPLEXITY", "content": "We prove theorems about interpretability queries building on techniques from classical (Garey &\nJohnson, 1979) and parameterized complexity (Downey & Fellows, 2013). Here we give a brief,\ninformal overview of the main concepts underlying our analyses (see Appendix for extensive formal\ndefinitions). We will explore beyond classical polynomial-time tractability (PTIME) by studying\nfixed-parameter tractability (FPT). This allows a more fine-grained look at the sources of complex-\nity of problems. NP-hard queries are considered intractable because they cannot be computed by\npolynomial-time algorithms. However, a relaxation of interest is to allow unreasonable resource\ndemands as long as they are contained in problem parameters that can be kept small in practice.\nParameterizing a given neural network and requested circuit leads to parameterized problems (see\nTable 3 for problem parameters we study later). Parameterized queries in FPT admit fixed-parameter\ntractable algorithms. W-hard queries, however, do not. We study counting problems via analogous\nclasses #P and #W[1]. We also investigate completeness for NP and classes higher up the polyno-\nmial hierarchy such as \u2211 and I to explore the possibility to tackle hard interpretability problems\nwith better-understood methods for well-known NP-complete problems (de Haan\n& Szeider, 2017).\nMost proof techniques involve various kinds of reductions between computational problems."}, {"title": "3.3 APPROXIMATION", "content": "Although sometimes computing optimal solutions is intractable, it is conceivable we could devise\ntractable interpretability procedures to obtain approximate solutions that are useful in practice. We\nconsider 5 notions of approximation: additive, multiplicative, and three probabilistic schemes (see\nAppendix for formal definitions). Additive approximation algorithms return solutions at most a\nfixed distance c away from optimal (e.g., from the minimum-sized circuit), ensuring that errors\ncannot get impractically large (c-approximability). Multiplicative approximation returns solutions\nat most a factor of optimal away. Some hard problems allow for polynomial-time multiplicative\napproximation schemes (PTAS) where we can get arbitrarily close to optimal solutions as long as\nwe expend increasing compute time (Ausiello et al., 1999). Finally, consider three other types of\nprobabilistic polynomial-time approximability (henceforth 3PA) that may be acceptable in situations\nwhere always getting the correct output for an input is not required: (1) algorithms that always run in\npolynomial time and produce the correct output for a given input in all but a small number of cases\n(Hemaspaandra & Williams, 2012); (2) algorithms that always run in polynomial time and produce\nthe correct output for a given input with high probability (Motwani & Raghavan, 1995); and (3)\nalgorithms that run in polynomial time with high probability but are always correct (Gill, 1977)."}, {"title": "3.4 MODEL ARCHITECTURE", "content": "The Multi-Layer Perceptron (MLP) is a natural first step in our exploration because (a) it is proving\nuseful as a stepping stone in current experimental (e.g., Lampinen et al., 2024) and theoretical work"}, {"title": "4 RESULTS & DISCUSSION: THE COMPLEXITY OF CIRCUIT DISCOVERY", "content": "In this section we present each circuit query with its computational problem and a discussion of the\ncomplexity profile we obtain across variants, relaxations, and parameterizations. For an overview of\nthe results for all queries, see Table 4. Proofs of the theorems can be found in the Appendix."}, {"title": "4.1 SUFFICIENT CIRCUIT", "content": "Sufficient circuits (SCs) are sets of neurons connected end-to-end that suffice, in isolation, to repro-\nduce some model behavior over an input domain. Therefore, they are conceptually related to the\ndesired outcome of masking components that do not contribute to the behavior of interest (small,\nparameter-efficient subnetworks). SCs remain relevant as, despite valid criticisms of zero-ablation\n(e.g., Conmy et al., 2023), circuit discovery through pruning might be justified (Yu et al., 2024a).\nWe find that many variants of SC are NP-hard (see Table 4). Counterintuitively, this intractability\ndoes not depend straightfowardly on parameters such as network depth (W[1]-hard relative to P).\nTherefore, hardness is not mitigated by keeping models shallow. Given this barrier, we explore\nthe possibility of obtaining approximate solutions but find that hard SC variants are inapproximable\nrelative to all schemes in Section 3.3. An alternative is to consider the membership of these problems\nin a well-studied class whose solvers are better understood than interpretability heuristics (de Haan\n& Szeider, 2017). We prove that local versions of SC are NP-complete. This implies there exist\nefficient transformations from instances of SC to those of the satisfiability problem (SAT), opening\nup the possibility to borrow techniques that work reasonably well in practice for SAT (Biere et al.,\n2021). Interestingly, this is not possible for the global version, which we prove is complete for a\nclass higher up the complexity hierarchy (\u03a3-complete). This result establishes a formal separation\nbetween local and global query complexity that partly explains \u2018interpretability illusions' (Friedman\net al., 2024; Yu et al., 2024a) arising in practice due to local but not global faithfulness.\nNext we explore the following alternative scenario. Given a model and a target behavior, if we\nknew that SCs with some desired property (e.g., minimality) are abundant, this would provide some\nconfidence in the ability of heuristic search to stumble upon one of them. To explore this, we analyze\nvarious queries where the output is a count of the number of SCs (i.e., counting problems). We find\nthat both local and global, bounded and unbounded variants are #P-complete and remain intractable\n(#W[1]-hard) when parameterized by many network features including depth (Table 3).\nThe hardness profile of SC over all these variants calls for exploring more substantial relaxations. We\nintroduce the notion of quasi-minimality of SCs for this purpose and later demonstrate its usefulness\nbeyond this particular problem. Any neuron in a minimal/minimum SC is a breaking point in the\nsense that removing it will break the target behavior. In quasi-minimal SCs we are guaranteed to\nknow at least one neuron that causes this breakdown, though there may be other neurons that do not."}, {"title": "4.2 GNOSTIC NEURON", "content": "Gnostic neurons, sometimes called 'grandmother neurons' in neuroscience (Gale et al., 2020) and\n'concept neurons' or 'object detectors' in AI (e.g., Bau et al., 2020), are one of the oldest and still\ncurrent interpretability queries of interest (see also 'knowledge neurons'; Niu et al., 2023).\nIt is probably not a coincidence that (i) the idea and search for such neurons has emerged early and\nremained popular, and (ii) it is a tractable problem. BGN is in PTIME. Alternatives might require\nGNs to have some behavioral effect when intervened; such variants would remain tractable."}, {"title": "4.3 CIRCUIT ABLATION AND CLAMPING", "content": "The idea that some neurons perform key subcomputations for certain tasks naturally leads to the\nhypothesis that ablating them should have downstream effects on the corresponding model behav-\niors. Searching for neuron sets with this property has been one strategy (i.e., zero-ablation) to get at\nimportant circuits (Wang & Veitch, 2024). The circuit ablation (CA) problem formalizes this idea.\nA difference between CAs and minimal SCs is that the former can be interpreted as a possibly non-\nminimal breaking set in the context of the whole network whereas the latter is by default a minimal\nbreaking set when the SC is taken in isolation. In this sense, CA can be seen as a less stringent\ncriterion for circuit affordances. A related idea is circuit clamping (CC): fixing the activations of\ncertain neurons to a level that produces a change in the behavior of interest."}, {"title": "4.4 CIRCUIT PATCHING", "content": "A critique of zero-ablation is the arbitrariness of the value, leading to alternatives such as mean-\nablation (e.g., Wang et al., 2022). A related contrast is studying circuits in isolation versus embedded\nin surrounding subnetworks. Activation patching (Ghandeharioun et al., 2024; Zhang & Nanda,\n2023) and path patching (Goldowsky-Dill et al., 2023) try to pinpoint which activations play an\nin-context role in model behavior over a domain, which inspires the circuit patching (CP) problem.\nWe find that local/global variants are intractable (NP-hard) in a way that does not depend on pa-\nrameters such as network depth or size of the patched circuit (W[1]-hard), and are inapproximable\n({c, PTAS, 3PA}-inapprox.). Although we also prove the local variant of CP is NP-complete and\ntherefore approachable in practice with solvers for hard problems not available for the global vari-\nants (see remarks in Section 4.1), these complexity barriers motivate exploring further relaxations.\nWith some modifications the idea of quasi-minimality can be repurposed to do useful work here."}, {"title": "4.5 NECESSARY CIRCUIT", "content": "The criterion of necessity is a stringent one, and consequently necessary circuits (NCs) carry power-\nful affordances (see Table 1). Since neurons in NCs collectively interact with all possible sufficient\ncircuits for a target behavior, they are candidates to describe key task subcomputations and interven-\ning on them is guaranteed to have effects even in the presence of high redundance.\nUnfortunately both local and global versions of NC are NP-hard (in \u03a3; Table 4), remain intractable\neven when keeping parameters such as network depth, number of input and output neurons, and\nothers small (Table 3), and does not admit any of the available approximation schemes (Section 3.3).\nTractable versions of NC are unlikely unless substantial restrictions or relaxations are introduced."}, {"title": "4.6 CIRCUIT ROBUSTNESS", "content": "A behavior of interest might be over-determined or resilient in the sense that many circuits in the\nmodel implement it and one can take over when the other breaks down. This is related to the notion\nof redundancy used in neuroscience (e.g., Nanda et al., 2023). Intuitively, when a model implements\na task in this way, the behavior should be more robust to a number of perturbations. The possibility\nof verifying it experimentally motivates the circuit robustness (CR) problem.\nWe find that Local CR is coNP-complete while Global CR is in \u03a0 and coNP-hard. It remains\nfixed-parameter intractable (coW[1]-hard) relative to model parameters (Table 3). Pushing further,\nwe explore parameterizing CR by {|H|} and prove fixed-parameter tractability of {|H|}-CR which\nholds both for the local and global versions. There exist algorithms for CR that scale well as long as\n|H| is reasonable; a scenario that might be useful to probe robustness in practice. This wraps up our\nresults for circuit queries. We briefly digress into explainability before discussing some implications."}, {"title": "4.7 SUFFICIENT REASONS", "content": "Understanding the sufficient reasons (SR) for a model decision in terms of input features consists\nof knowledge of values of the input components that are enough to determine the output. Given a\nmodel decision on an input, the most interesting reasons are those with the least components.\nTo demonstrate the usefulness of our framework beyond inner interpretability, we show how it links\nto explainability. Using our techniques for circuit queries, we significantly tighten existing results\nfor SR (Barcel\u00f3 et al., 2020; W\u00e4ldchen et al., 2021) by proving that hardness (NP-hard, W[1]-hard,\n3PA-inapprox.) holds even when the model has only one hidden layer."}, {"title": "5 IMPLICATIONS, LIMITATIONS, AND FUTURE DIRECTIONS", "content": "We presented a framework based on parameterized complexity to accompany experiments on inner\ninterpretability with theoretical explorations of viable algorithms. With this grasp of circuit query\ncomplexity, we can understand the challenges of scalability and the mixed outcomes of experiments\nwith heuristics for circuit discovery. We can explain 'interpretability illusions' (Friedman et al.,\n2024) due to lack of faithfulness, minimality (e.g., Shi et al., 2024; Yu et al., 2024a) and other affor-\ndances (Wang & Veitch, 2024; Hase et al., 2023), in terms of the kinds of circuits that our current\nheuristics are well-equipped to discover. For instance, consider the algorithm for automated circuit\ndiscovery proposed by Conmy et al. (2023), which eliminates one network component at a time if\nthe consequence on behavior is reasonably small. Since this algorithm runs in polynomial time,\nit is not likely to solve the problems proven hard here, such as MINIMAL SUFFICIENT CIRCUIT.\nHowever, one reason we observe interesting results in some cases is because it is well-equipped to\nsolve QUASI-MINIMAL CIRCUIT problems. As our conceptual and formal analyses show, quasi-\nminimal circuits can mimic various desirable aspects of sufficient circuits (Table 1), and the former\ncan be found tractably (results for Problem 2 and Problem 7). Indeed, from our proof of tractability\nof QMSC (see Appendix) we get a hint on how to improve the running time of the algorithm in\nConmy et al. (2023) while retaining guarantees of quasi-minimality; namely, by using a variant of\nbinary search to cut the number of forward passes from n to log2(n). At the same time, understand-\ning these properties of circuit discovery heuristics helps us explain observed discrepancies: why\nwe often see (1) lack of faithfulness (i.e., global coverage is out of reach for QMC algorithms), (2)\nnon-minimality (i.e., QM circuits can have many non-breaking points), and (3) large variability in\nperformance across tasks and analysis parameters (e.g., Shi et al., 2024; Conmy et al., 2023).\nOur results for inner interpretability complement those of explainability (e.g., Barcel\u00f3 et al., 2020;\nBassan et al., 2024; W\u00e4ldchen et al., 2021). These two complexity aspects can be studied together\nfor different architectures to assess their intrinsic interpretability. As in explainability, our findings\nsuggest interpretability methods can be sought relative to additional query restrictions or relaxations.\nWe have explored many and some yield tractability while retaining affordances of practical interest.\nOne possibly fruitful avenue we have not explored is to conduct an empirical and formal charac-\nterization of learned weights in search of structure that could potentially distinguish conditions of\n(in)tractability. Another avenue is to design queries that partially rely on mid-level abstractions\n(Vilas et al., 2024a) to bridge the gap between circuits and human-intelligible algorithms (e.g., key-\nvalue mechanisms; Geva et al., 2022; Vilas et al., 2024b)."}]}