{"title": "From LLMs to LLM-based Agents for Software Engineering: A Survey of Current, Challenges and Future", "authors": ["Haolin Jin", "Linghan Huang", "Haipeng Cai", "Jun Yan", "Bo Li", "Huaming Chen"], "abstract": "With the rise of large language models (LLMs), researchers are increasingly exploring their applications in various vertical domains, such as software engineering. LLMs have achieved remarkable success in areas including code generation and vulnerability detection. However, they also exhibit numerous limitations and shortcomings. LLM-based agents, a novel technology with the potential for Artificial General Intelligence (AGI), combine LLMs as the core for decision-making and action-taking, addressing some of the inherent limitations of LLMs such as lack of autonomy and self-improvement. Despite numerous studies and surveys exploring the possibility of using LLMs in software engineering, it lacks a clear distinction between LLMs and LLM-based agents. It is still in its early stage for a unified standard and benchmarking to qualify an LLM solution as an LLM-based agent in its domain. In this survey, we broadly investigate the current practice and solutions for LLMs and LLM-based agents for software engineering. In particular we summarise six key topics: requirement engineering, code generation, autonomous decision-making, software design, test generation, and software maintenance. We review and differentiate the work of LLMs and LLM-based agents from these six topics, examining their differences and similarities in tasks, benchmarks, and evaluation metrics. Finally, we discuss the models and benchmarks used, providing a comprehensive analysis of their applications and effectiveness in software engineering. We anticipate this work will shed some lights on pushing the boundaries of LLM-based agents in software engineering for future research.", "sections": [{"title": "I. INTRODUCTION", "content": "SOFTWARE engineering (SE) has seen its booming research and development with the aid of artificial intelligence techniques. Traditional approaches leveraging neural networks and machine learning have facilitated various SE topics such as bug detection, code synthesis, and requirements analysis [1] [2]. However, they often present limitations, including the need for exclusive feature engineering, scalability issues, and the adaptability across diverse codebases. The rise of Large Language Models (LLMs) has embarked on new solutions and findings in this landscape. LLMs, such as GPT [3] and Codex [4], have demonstrated remarkable capabilities in handling downstream tasks in SE, including code generation, debugging, and documentation. These models leverage vast amounts of training data to generate human-like text, offering unprecedented levels of fluency and coherence. Studies have shown that LLMs can enhance productivity in software projects by providing intelligent code suggestions, automating repetitive tasks, even generating entire code snippets from natural language descriptions [5].\nDespite their potential, there are significant challenges in applying LLMs to SE. One major issue is their limited context length [6], which restricts the model's ability to comprehend and manage extensive codebases, making it challenging to maintain coherence over prolonged interactions. Hallucinations is another main concern, where the model generates code that appears plausible but is actually incorrect or nonsensical [7], potentially introducing bugs or vulnerabilities if not carefully reviewed by experienced developers. Additionally, the inability of LLMs to use external tools restricts their access to real-time data and prevent them from performing tasks outside their training scope. It diminishes their effectiveness in dynamic environments. These limitations significantly impact the application of LLMs in SE, and also highlight the need for expert developeers to critically refine and validate LLM-generated code for accuracy and security [8]. In complex projects, the static nature of LLMs can hinder their ability to adapt to changing requirements or efficiently incorporate new information. Moreover, LLMs typically cannot interact with external tools or databases, further limits their utility in dynamic and evolving SE contexts.\nTo address these challenges, LLM-based agents have emerged [9] [10], combining the strengths of LLMs with external tools and resources to enable more dynamic and autonomous operations. These agents leverage recent advancements in AI, such as Retrieval-Augmented Generation (RAG) and tool utilization, to perform more complex and contextually aware tasks [11]. For instance, OpenAI's Codex has been integrated into GitHub Copilot [12], enabling real-time code suggestions and completion within development environments. Unlike static LLMs, LLM-based agents can perform a wide range of tasks, such as autonomously debugging code by identifying and fixing errors, proactively refactoring code to enhance efficiency or readability, and generating adaptive test cases that evolve alongside the codebase. These features make LLM-based agents a powerful tool for SE, capable of handling more complex and dynamic workflows than traditional LLMs."}, {"title": "II. EXISTING WORKS AND THE SURVEY STRUCTURE", "content": "In recent years, large language models have been primarily applied to help programmers generate code and fix bugs. These models understand and complete code or text based on the user's input, leveraging their training data and reasoning capabilities. In previous survey papers, such as Angela Fan's research [8], there has not been much elaboration on requirement engineering. As mentioned in the paper, software engineers are generally reluctant to rely on LLMs for higher-level design goals. However, with LLMs achieving remarkable improvements in contextual analysis and reasoning abilities through various methods like prompt engineering and Chain-of-Thought (COT) [16], their applications in requirement engineering are gradually increasing. Table I summarizes and categorizes the tasks in requirement engineering. Many studies utilize models for requirement classification and generation. Since the collection primarily focuses on the latter half of 2023 and before April 2024, and some papers address multiple tasks, the table does not reflect the exact number of papers we have collected.\nWhile other works have surveyed LLMs applications in some SE tasks [17] [8] [18], they lack a wider coverage of the general SE area to incorporate recent research developments. More importantly, a focus of LLMs is the main contributions of these works, but there is no distinguish the capabilities"}, {"title": "III. PRELIMINARIES", "content": "In this section, we introduce the foundational concepts of large language models, including the evolution of their frameworks and an overview of their architectures. Subsequent to this, we will discuss LLM-based agents, exploring both single-agent and multi-agent systems. We will also covers the background of these systems and their applications and distinctions in the field of software engineering."}, {"title": "A. Large Language Model", "content": "There is an inherent connection between large language models and natural language processing (NLP), with the historical development of natural language technologies tracing back to the 1950s. The earliest attempts to generate language dialogues through machines using specific rules can be traced to the period between 1950 and 1970. The advent of machine learning technologies in the 1980s and the groundbreaking introduction of neural networks in the 1990s indicated a new era for NLP [23]. These advancements facilitated significant progress in the NLP field, especially in the development of technologies for text translation and generation. The development of Long Short-Term Memory (LSTM) and Recurrent Neural Networks (RNN) during this period enabled more effective handling of the sequential nature of language data [24] [25]. These models addressed challenges associated with the lack of dependency in context, thereby enhancing the application of NLP in various domains.\nIn 2017 the new framework called \"Transformer\" introduced by Google's research team [26]. The transformer model based on the self-attention mechanism which significantly improved the effectiveness of language models. The inclusion of positional encoding not only solved the long-sequence dependency issue but also enabled parallel computation, which was a considerable improvement over previous models. In 2018, OpenAI developed the Generative Pre-trained Transformer (GPT) [3], a model based on the transformer architecture. The core idea behind GPT-1 was to utilize a large corpus of unlabelled text for pre-training to learn the patterns and structures of language, followed by fine-tuning for specific tasks. Over the next two years, OpenAI released GPT-2 and GPT-3 which increased the parameter count to 175 billions and also demonstrated strong capabilities in context understanding and text generation [27]. GPT-4 launched by OpenAI in 2023, represents a milestone following GPT-3.5. Although GPT-4 maintains a similar parameter count of approximately 175 billion, its performance and diversity have seen considerable improvements. Through more refined training techniques and algorithm optimizations, GPT-4 enhanced the capability of language understanding and generation, particularly outperformed in handling complex texts and special contexts. Compared to other contemporary models like Google's PaLM or Meta's OPT, GPT-4 continues to stand out in multi-task learning and logical consistency in the text generation. While Google's PaLM model boasts up to 54 billion parameters, GPT-4 shows superior generalization abilities across a broader range of NLP tasks [28]. On the open-source large models, Meta's OPT model with a parameter size similar to the GPT-4 offers direct competition. Despite OPT's advantages in openness and accessibility, GPT-4 still maintains a lead in specific application areas such as creative writing and complex problem solving [29]."}, {"title": "B. Model Architecture", "content": "There are three common LLM architectures, the Encoder-Decoder architecture, exemplified by the traditional transformer model. This architecture comprises six encoders and six decoders, data input into the system will first passes through the encoder, where it undergoes sequential feature extraction via the model's self-attention mechanism. Subsequently, the decoders utilize the word vectors produced by the encoders to generate outputs, this technique is common to see in machine translation tasks, where the encoder processes word vectors from one language through several attention layers and feed-forward networks, thereby creating representations of the context. The decoder then uses this information to incrementally construct the correct translated text. A recent example of this architecture is the CodeT5+ model, launched by Salesforce AI Research in 2023 [30]. This model is an enhancement of the original T5 architecture, which designed to improve performance in code understanding and generation tasks. It incorporates a flexible architecture and diversified pre-training objectives to optimize its effectiveness in these specialized areas. This development highlights the competency of Encoder-Decoder architectures in tackling increasingly complex NLP challenges.\nThe Encoder-only architecture, as the name suggests it eliminates the decoder from the entire structure making the data more compact. Unlike RNNs, this architecture is stateless and uses a masking mechanism that allows input processing without relying on hidden states, and also accelerating parallel processing speeds and providing excellent contextual awareness. BERT (Bidirectional Encoder Representations from Transformers) is a representative model of this architecture, this model is a large language model built solely on the encoder architecture. BERT leverages the encoder's powerful feature extraction capabilities and pre-training techniques to learn bidirectional representations of text, achieving outstanding results in sentiment analysis and contextual analysis [31].\nThe Decoder-only archiecture, in the transformer framework primarily involves the decoder receiving processed word vectors and generating output. Utilizing the decoder to directly generate text accelerates tasks such as text generation and sequence prediction. This characteristic with high scalability is known as auto-regressiveness, which is why popular models like GPT use this architecture. In 2020, the exceptional performance of GPT-3 and its remarkable few-shot learning capabilities demonstrated the vast potential of the decoder-only architecture [32]. Given the enormous computational cost and time required to train a model from scratch, and the exponential increase in the number of parameters, many researchers now prefer to leverage pre-trained models for further research. The most popular open-source pre-trained language model LLaMA, developed by Meta AI also employs the decoder-only architecture [33], as mentioned earlier, the autoregressiveness and simplicity of this structure make the model easier to train and fine-tune."}, {"title": "C. Large Language Model Based Agent", "content": "The concept of agents even trace back to the 19th century and is often referred to as intelligent agents, envisioned to possess intelligence comparable to humans. Over the past few decades, as AI technology has evolved, the capabilities of AI agents have significantly advanced, particularly with the reinforcement learning. This development has enabled AI agents to autonomously handle tasks and learn and improve based on specified reward/punishment rules. Notable milestones include AlphaGo [34], which leveraged reinforcement learning to defeat the world champion in Go competition.\nThe success of GPT has further propelled the field, with researchers exploring the use of large language models as the \"brain\" of AI agents, thanks to GPT's powerful text understanding and reasoning capabilities. In 2023, a research team from Fudan University [10] conducted a comprehensive survey on LLM-based agents, examining their perception, behavior, and cognition. Traditional LLMs typically generate responses based solely on given natural language descriptions, lacking the ability for independent thinking and judgment. LLM-based agents able to employ multiple rounds of interaction and customized prompts to gather more information, which enable the model to think and make decisions autonomously. In 2023, Andrew Zhao proposed the ExpeL framework [35], which utilizes ReAct as the planning framework combined with an experience pool [36]. This allows the LLM to extract insights from past records to aid in subsequent related queries, by letting the LLM analyze why previous answers were incorrect, it learns from experience to identify the problems.\nAt the same time, the application of LLM-based embodied agents has also become a hot research area in recent years. LLM-based Embodied Agents are intelligent systems that integrate LLMs with embodied agents [37]. These systems can not only process natural language but also complete tasks through perception and actions in physical or virtual environments. By combining language understanding with actual actions, these agents can perform tasks in more complex environments. This integration often involves using visual domain technologies to process and understand visual data and reinforcement learning algorithms to train agents to take optimal actions in the environment. These algorithms guide the agent through reward mechanisms to learn how to make optimal decisions in different situations, while the LLM acts as the brain to understand user instructions and generate appropriate feedback. In 2023, Guanzhi Wang introduced VOYAGER, an open-ended embodied agent with large language models [38]. It uses GPT-4 combined with input prompts, an iterative prompting mechanism, and a skill library enabling the LLM-based agents to autonomously learn and play the game Minecraft, becoming the first lifelong learning agent in the game."}, {"title": "IV. REQUIREMENT ENGINEERING AND AND DOCUMENTATION", "content": "Requirement Engineering is a critical field within software engineering and plays an essential role in the software development process, its primary task is to ensure that the software system meets the needs of all relevant stakeholders. Typically, requirement engineering in project development involves many steps, where developers need to fully understand the users' needs and expectations to ensure that the development direction of the software system aligns with actual requirements. The collected requirements are then organized and evaluated by the development group. Requirements Specification is the process of formally documenting the analyzed requirements, the specification must be accurate and concise, and the requirement verification must be conducted to ensure that developers are building what users need and that it aligns with the specifications. Requirement engineering also includes requirement management, a task that spans the entire software development life-cycle, developers need to continuously track, control, and respond to any changes occurring during development, ensuring that these changes do not negatively impact the project's progress and overall quality."}, {"title": "A. LLMs Tasks", "content": "In the field of requirement engineering, LLMs have demonstrated significant potential in automating and enhancing tasks such as requirement elicitation, classification, generation, specification generation, and quality assessment. Requirement classification and extraction is a crucial task in requirement engineering during the development process. It is common to encounter situations where clients present multiple requirements at once, necessitating manual classification by developers. By categorizing requirements into functional and non-functional requirements, developer can better understand and manage them, thanks to the strong performance of LLMs in classification tasks, many relevant frameworks have been developed. The PRCBERT framework, utilizing the BERT pre-trained language model, transforms classification problems into a series of binary classification tasks through flexible prompt templates, significantly improving classification performance [48]. Studies have shown that the PRCBERT achieved an F1 score of 96.13% on the PROMISE dataset which outperform the previous state-of-arts NORBERT [49] and BERT-MLM models [31]. Additionally, the application of ChatGPT in requirement information retrieval has shown promising results, by classifying and extracting information from requirement documents, ChatGPT achieved comparable or even better F$\\beta$ scores under zero-shot settings, particularly in feature extraction tasks, where its performance surpassed baseline models [50]. As seen in Table I, there is also substantial literature and research on using LLMs to automatically generate requirements and descriptions in requirement engineering.\nBy automating the generation and description of requirements, the efficiency and accuracy of requirement elicitation can be improved. Research indicates that LLMs hold significant potential in requirements generation task. For example, using ChatGPT to generate and gather user requirements, studies found that participants with professional knowledge could use ChatGPT more effectively, indicating the influence of domain expertise on the effectiveness of LLM-assisted requirement elicitation [51]. The study employed qualitative assessments of the LLMs' output against predefined criteria for requirements matches, including full matches, partial matches, and the relevancy of the elicited requirements, although their success varied depending on the complexity of the task and the experience of the users, the result showing that LLMs could effectively assist in eliciting requirements, and its particularly useful in identifying, and suggesting requirements based on the large corpus of training data they provided. The SRS (Software Requirement Specification) generation is an important task which the developer normally spent a lot of time to refine and verified. In [52], researchers use both iterative prompting and a single comprehensive prompt to assess the performance of LLMs to generate SRS. The experiment conducted on GPT-4 and CodeLlama-34b one close-source LLM and one open-source LLM for comprehensive evaluation, the generated SRS will compare with human-crafted SRS and finally scored by the likert scale. The result indicate that, the human-generated SRS was overall superior, but CodeLlama often came close, sometimes outperforming in specific categories. The CodeLlama scored higher in completeness and internal consistency than GPT-4 but less concise, so this stuy demonstrated the potential of using fine-tuned LLMs to generate SRS and increase the overall project productivity. Another paper also explores using LLMs for generating specifications. In [53], the authors introduce a framework called SpecGen for generating program specifications. The framework primarily uses GPT-3.5-turbo as the base model and employs prompt engineering combined with multi-turn dialogues to generate the specifications. SpecGen applies four mutation operators to modify these specifications and finally uses a heuristic selection strategy to choose the optimal variant. The results show that SpecGen can generate 70% of the program specifications, outperforming traditional tools like Houdini [54] and Daikon\u00b9.\nFurthermore, designing prompt patterns can significantly enhance LLMs' capabilities in tasks such as requirement elicitation and system design. The paper provides a catalog of 13 prompt patterns, each aimed at addressing specific challenges in software development [55]. The experiments test the efficacy of these patterns in real world scenarios to validate their usefulness. By applying different prompt patterns, the study found that these patterns could help generate more structured and modular results and reduce common errors. Automated requirement completeness enhancement is another important benefit brought by the LLMs in requirement generation. The study [56] use BERT's Masked Language Model (MLM) can detect and fill in missing parts in natural language requirements, significantly improving the completeness of requirements. BERT's MLM achieved a precision of 82%, indicating that 82% of the predicted missing terms were correct."}, {"title": "B. LLM-based Agents Tasks", "content": "Currently the application of LLM-based agents in the requirement engineering is till quite nascent, but there are some useful researches to help us to see the potential possibility. LLM-based agents bring both efficiency and accuracy for tasks like requirement elicitation, classification, generation, and verification. Compared to traditional LLMs, these systems exhibit higher levels of automation and precision through task division and collaboration. The application of multi-agent systems in semi-structured document generation has shown significant effectiveness. In [60], a multi-agent framework is introduced that combines semantic recognition, information retrieval, and content generation tasks to streamline the creation and management of semi-structured documents in the public administration domain. The proposed framework involves three main types of agents: Semantics Identification Agent, Information Retrieval Agent, and Content Generation Agent. By avoiding the overhead of a single model, each agent is assigned a specific task with minimal user intervention, following the designed framework and workflow.\nAdditionally, the AI-assisted software development framework (AISD) also showcases the autonomy brought by the LLM-based agents in requirement engineering. [61] proposes the AISD framework, which continuously improves and optimizes generated use cases and code through ongoing user feedback and interaction. In the process of the experiment, humans need to first give a fuzzy requirement definition, and then LLM-based agent will improve the requirement case according to this information, and then design the model and generate the system according to the case, and then the generated results will let humans judge whether the requirements are met or not. The study results indicate that AISD significantly increased use case pass rates to 75.2%, compared to only 24.1% without human involvement. AISD demonstrates the agents' autonomous learning ability by allowing LLMs to generate all code files in a single session, continually refining and modifying based on user feedback. This also ensures code dependency and consistency, further proving the importance of human involvement in the requirement analysis and system testing stages.\nFurthermore, in generating safety requirements for autonomous driving, LLM-based agents have shown unique advantages by introducing multimodal capabilities. The system employs LLMs as automated agents to generate and refine safety requirements with minimal human intervention until the verification stage, which is unattainable with only LLMs. [62] describes an LLM prototype integrated into the existing Hazard Analysis and Risk Assessment (HARA) process, significantly enhancing efficiency by automatically generating specific safety-related requirements. The study through three design iterations progressively improved the LLM prototype's efficiency by completing within a day compared to months manually. In agile software development, the quality of user stories directly impacts the development cycle and the realization of customer expectations. [63] demonstrates the successful application of the ALAS system in six agile teams at the Austrian Post Group IT. The ALAS system significantly improved the clarity, comprehensibility, and alignment with business objectives of user stories through automated analysis and enhancement. The entire agent framework allows the model to perform specific roles in the Agile development process, the study results indicated that the ALAS-improved user stories received high satisfaction ratings from team members."}, {"title": "C. Analysis", "content": "The application of LLM-based agents in requirement engineering has demonstrated significant efficiency improvements and quality assurance. Through multi-agent collaboration and automated processing, these systems not only reduce manual intervention but also enhance the accuracy and consistency of requirement generation and verification. We can see that the tasks of LLM-based agents are no longer limited to simply generating requirements or filling in the gaps in descriptions. Instead, they involve the implementation of an automated process, with the generation of requirement documents being just one part of it, integrating LLM into agents enhances the overall system's natural language processing and reasoning capabilities. In the real-world application, many tasks can no longer be accomplished by simple LLMs alone, especially for high-level software design. The emergence of LLM-based agents addresses this issue through a multi-agent collaborative system centered around LLMs, these agents continuously analyze and refine the deficiencies in the requirement documents, this is might be the main application trend of LLM-based agents in requirements engineering in the future.\nThe application of LLM-based agents in requirements engineering is still relatively limited, with most efforts focusing on"}, {"title": "V. CODE GENERATION AND SOFTWARE DEVELOPMENT", "content": "Code generation and software development are core areas within software engineering which plays a crucial role in the software development process. The primary objective of using LLMs in code generation is to enhance development efficiency and code quality through automation processes, thereby meeting the needs of both developers and users.\nIn recent years, the application of LLMs in code generation and software development has made significant progress, this has changed the way developers work and revealed a shift in automated development processes. Compared to requirement engineering, research on the application of LLMs and LLM-based agents in code generation and software development is more extensive and in-depth. Using natural language processing and generation technologies, LLMs can understand and generate complex code snippets, assisting developers in automating various stages from code writing and debugging to software optimization. The decoder-based large language models such as GPT-4 have shown significant potential in code generation by providing accurate code suggestions and automated debugging, greatly improving development efficiency. Recently, the application of LLM-based agents in software development is also gaining attention, these intelligent agents can not only perform complex code generation tasks but also engage in autonomous learning and continuous refinement, thereby offering flexible assist in dynamic development environments. Tools like GitHub Copilot [12], which integrate LLMs, have already demonstrated their advantages in enhancing programming efficiency and code quality."}, {"title": "A. LLMs Tasks", "content": "Large language models have optimized various tasks in code generation and software development through automation and reasoning, covering areas such as code generation, debugging, code comprehension, code completion, code transformation, and multi-turn interactive code generation. The primary method is generating executable code from natural language descriptions, where models utilize previously learnt code snippets or apply few-shot learning to better understand user requirements. Nowadays the AI tools integrates deeply with IDEs like Visual Studio Code\u00b2 and JetBrains\u00b3 to enhance code writing and translation tasks such as OpenAI's Codex model [67]. Codex fine-tuned on public code from GitHub, demonstrate the capability to generate Python functions from doc-strings also outperformed other similar models on the HumanEval benchmark.\nIn [68], researchers comprehensively evaluated the performance of multiple LLMs on L2C(language to code) tasks. The results showed that GPT-4 demonstrates strong capability in tasks such as semantic parsing, mathematical reasoning, and Python programming. With instruction tuning and support from large-scale training data, the model can understand and generate code that aligns with user intent, achieving high-precision code generation. Applying LLMs to text-to-database management and query optimization is also a novel research direction in natural language to code generation task. By converting natural language queries into SQL statements, LLMs help developers quickly generate efficient database query code. In [69], proposed the SQL-PaLM framework which significantly enhances the execution accuracy and exact match rate for text-to-SQL tasks through a few-shot prompt and instruction fine-tuning, providing an effective solution for complex cross-domain SQL generation tasks. The improvements in accuracy and exact match achieved in the SQL-PaLM model are considered state-of-the-art (SOTA) in tested benchmarks, the SQL-PaLM performed promise results comparing with existing methods such as T5-3B + PICARD, RASAT + PICARD, and even GPT-4, achieving the highest test accuracy of 77.3% and an execution accuracy of 82.7%. Multilingual code generation is another important application of LLMs, particularly suited to the transformer architecture. In [70], researchers introduced the CodeGeeX model, which was pre-trained on multiple programming languages and performed well in multilingual code generation and translation tasks. Experimental results showed that CodeGeeX outperformed other multilingual models on the HumanEval-X benchmark.\nAlthough current LLMs possess excellent code generation capabilities, with accuracy and compile rates reaching usable levels, the quality of generated code often depends on the user's prompts. If the prompts are too vague or general, the LLM typically struggles to understand the user's true requirements, making it difficult to generate the desired code in a single attempt. In [71], researchers introduced \"print debugging\" technique, using GPT-4 to track variable values and execution flows, which enhancing the efficiency and accuracy by using in-context learning techniques. This method is particularly suitable for medium-difficulty problems on Leet-code, compared to the rubber duck debugging method, print"}, {"title": "B. LLM-based Agents Tasks", "content": "LLM-based agents have shown significant potential and advantages by substantially improving task efficiency and effectiveness through multi-agent collaboration. Unlike traditional LLMs, LLM-based agents adopt a division of labor approach, breaking down complex tasks into multiple subtasks handled by specialized agents, this method can enhance task efficiency and improves the quality and accuracy of generated code to mitigate the hallucination from the single LLM.\nIn [76], researchers proposed a self-collaboration framework where multiple ChatGPT (GPT-3.5-turbo) agents act as different roles to collaboratively handle complex code generation tasks. Specifically, the introduction of Software Development Methodology (SDM) divides the development process into three stages: analysis, coding, and testing. Each stage is managed by specific roles, and after completing their tasks, each role provides feedback and collaborates with others to improve the quality of the generated code. Experiment shows that this self-collaboration framework significantly improves performance on both the HumanEval and MBPP benchmarks, with the highest improvement reaching 29.9% in HummanEval compared to the SOTA model GPT-4. This result demonstrating the potential of collaborative teams in complex code generation tasks. Although it lacks external tool integration and dynamic adjustment capabilities, this framework exhibits common characteristics of LLM-based agents, such as role distribution, self-improvement ability, and excellent autonomous decision-making, these combined capabilities qualify it to be considered an LLM-based agent. Similarly, In [77], the LCG framework improved code generation quality also through multi-agent collaboration and chain-of-thought techniques, once again demonstrating the effectiveness of multi-agent collaboration in the software development process.\nThe limitations of context windows was not discussed in previous studies, this has been thoroughly explored in a 2024 by University of Cambridge team. In [78], researchers introduced the L2MAC framework, which dynamically manages memory and execution context through a multi-agent system to generate large codebases, and achieved SOTA performance in generating large codebases for system design tasks. The framework is primarily divided into the following components: the processor, which is responsible for the actual generation of task outputs; the Instruction Registry, which stores program prompts to solve user tasks; and the File Storage, which contains both final and intermediate outputs. The Control Unit periodically checks the outputs to ensure that the generated content is both syntactically and functionally correct. The researchers conducted multiple experiments and compared with many novel methods like GPT-4, Reflexion, and Auto-GPT, achieving a Pass@1 score of 90.2% on the HumanEval benchmark, showcasing its superior performance in generating large-scale codebases.\nRecently, many studies have begun to use LLM-based agents to simulate real software development processes, the paper [79] introduced the MetaGPT framework, which enhanced problem-solving capabilities through standard operating procedures (SOPs) encoded in multi-agent collaboration. The entire process of the multi-collaboration framework simulates the waterfall life-cycle of software development, with each agent playing different roles and collaborating to achieve the goal of automating software development. LLM-based agents have also shown strong ability in automated software development, [80] proposed a multi-GPT agent framework that automates tasks such as project planning, requirement engineering, software design, and debugging, illustrating the"}, {"title": "C. Analysis", "content": "The main differences between LLM-based agents and traditional LLMs in software development applications mainly focus on the efficiency and autonomy, particularly in task division and collaboration. Traditional LLMs typically use a single model to handle specific tasks, such as generating code from text and code completion. However, this approach has limitations when dealing with complex tasks, especially regarding context window restrictions and the need for continuous feedback. LLM-based agents handle different subtasks through collaboration with clear division of labor, thereby enhancing task efficiency and quality. For example, in a code generation task, one agent generates the initial code, another designs test cases, and a third executes tests and provides feedback, thus achieving iterative optimization. Through task division, multi-agent systems, and tool integration, LLM-based agents can tackle more complex and broader tasks, improving the quality and efficiency of code generation. This approach overcomes the limitations of traditional LLMs also provides new directions and ideas for future software development research and applications, to frees programmers from the boring test suite generation.\nIn software engineering task handling, there are subtle differences between LLMs and LLM-based agents in terms of task focus, approach, complexity and scalability, automation level, and task management. LLMs primarily focus on enhancing the code generation capabilities of a single LLM, including debugging, precision, evaluation. These methods typically improve specific aspects of code generation or evaluation through a single model, concentrating on performance enhancement within existing constraints, such as context windows and single-task execution. In contrast, LLM-based agents emphasize handling more complex and broader tasks through the collaboration of multiple specialized LLMs or frameworks, integrating tool usage, iterative testing, and multi-agent coordination to optimize the whole development process and easily surpass the state-of-art model in common benchmarks. The emeergence of multi-agent systems also brings more possibilities, this system can imitate the real software developer to perform the scrum development. Figure. 5 utilize studies [77] and [75] showcase the differences between LLM-based agents and LLMs on the same code generation task. The LLM-based agents system are able to perform multi-agent collaboration and simulate the real scrum development team in the industry. In contrast the LLMs on the right are normally use multi-LLMs to analysis mistakes from the test cases, and refine the initial generated code, but they lack autonomy and efficiency, as the test cases are manually generated by humans."}, {"title": "VI. AUTONOMOUS LEARNING AND DECISION MAKING", "content": "Autonomous Learning and Decision Making is a critical and evolving field in modern software engineering, especially under the influence of artificial intelligence and big data. The core task of autonomous learning and decision making is to achieve automated data analysis, model building, and decision optimization through machine learning algorithms and intelligent systems, thereby enhancing the autonomy and intelligence of systems.\nIn this process, LLMs and LLM-based agents bring numerous possibilities, following the development of NLP technology, a lot of achievements have been made in the application of LLMs in this field. These models can handle complex language tasks and also demonstrate powerful reasoning and decision-making abilities, the research on voting inference using multiple LLMs calls has revealed new methods for op-timizing performance, with the frequently used method called majority vote [89], this improves the accuracy of inference systems and ensures the selection of the optimal possibility. Additionally, the performance of LLMs in tasks such as automated debugging and self-correction has enhanced the system's autonomous learning capabilities, achieving efficient error identification and correction. At the same time, the application of LLM-based agents in autonomous learning and decision-making is also a novel but popular topic, these agents can perform complex reasoning and decision-making tasks with the help from the LLM, and also improve their adaptability in dynamic environments through continuous learning and optimization. In this context, we have collected nineteen research papers on LLM-based agents in this field. This survey will provides a general review of these studies, analyzing the specific applications and technical implementations in"}, {"title": "A. LLMs Tasks", "content": "The API call for the LLMs is one common applications", "90": "researchers explored the impact of increasing LLM calls on the performance of composite reasoning systems. Paper analyze the voting inference design systems", "91": "the SELF-DEBUGGING method was proposed", "92": "which simulates the scientific debugging process through LLMs", "aspects": "feasibility, debugger ablation, language model change, developer benefit, developer acceptance, and qualitative analysis. Result have shown that AutoSD can generate effective patches and also improve developers' accuracy in evaluating patched code by providing explanations, its explainability function makes it easier for developers to understand and accept automatically generated patches. Although the above two studies primarily focus on automated debugging techniques, the frameworks designed in these studies automatically determine the optimal repair solution based on the debugging results after collecting sufficient information, and provide specific code implementations, which demonstrated the capability of autonomous decision-making and learning.\nSince the rise of LLMs applied to various fields, one research direction has been the rational analysis of their creativity and the exploration of their potential for continuous learning, this creativity also highly determined by the decision making capability of the"}]}