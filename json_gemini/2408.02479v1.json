{"title": "From LLMs to LLM-based Agents for Software Engineering: A Survey of Current, Challenges and Future", "authors": ["Haolin Jin", "Linghan Huang", "Haipeng Cai", "Jun Yan", "Bo Li", "Huaming Chen"], "abstract": "With the rise of large language models (LLMs), researchers are increasingly exploring their applications in various vertical domains, such as software engineering. LLMs have achieved remarkable success in areas including code generation and vulnerability detection. However, they also exhibit numerous limitations and shortcomings. LLM-based agents, a novel technology with the potential for Artificial General Intelligence (AGI), combine LLMs as the core for decision-making and action-taking, addressing some of the inherent limitations of LLMs such as lack of autonomy and self-improvement. Despite numerous studies and surveys exploring the possibility of using LLMs in software engineering, it lacks a clear distinction between LLMs and LLM-based agents. It is still in its early stage for a unified standard and benchmarking to qualify an LLM solution as an LLM-based agent in its domain. In this survey, we broadly investigate the current practice and solutions for LLMs and LLM-based agents for software engineering. In particular we summarise six key topics: requirement engineering, code generation, autonomous decision-making, software design, test generation, and software maintenance. We review and differentiate the work of LLMs and LLM-based agents from these six topics, examining their differences and similarities in tasks, benchmarks, and evaluation metrics. Finally, we discuss the models and benchmarks used, providing a comprehensive analysis of their applications and effectiveness in software engineering. We anticipate this work will shed some lights on pushing the boundaries of LLM-based agents in software engineering for future research.", "sections": [{"title": "I. INTRODUCTION", "content": "SOFTWARE engineering (SE) has seen its booming research and development with the aid of artificial intelligence techniques. Traditional approaches leveraging neural networks and machine learning have facilitated various SE topics such as bug detection, code synthesis, and requirements analysis. However, they often present limitations, including the need for exclusive feature engineering, scalability issues, and the adaptability across diverse codebases. The rise of Large Language Models (LLMs) has embarked on new solutions and findings in this landscape. LLMs, such as GPT and Codex, have demonstrated remarkable capabilities in handling downstream tasks in SE, including code generation, debugging, and documentation. These models leverage vast amounts of training data to generate human-like text, offering unprecedented levels of fluency and coherence. Studies have shown that LLMs can enhance productivity in software projects by providing intelligent code suggestions, automating repetitive tasks, even generating entire code snippets from natural language descriptions. Despite their potential, there are significant challenges in applying LLMs to SE. One major issue is their limited context length, which restricts the model's ability to comprehend and manage extensive codebases, making it challenging to maintain coherence over prolonged interactions. Hallucinations is another main concern, where the model generates code that appears plausible but is actually incorrect or nonsensical, potentially introducing bugs or vulnerabilities if not carefully reviewed by experienced developers. Additionally, the inability of LLMs to use external tools restricts their access to real-time data and prevent them from performing tasks outside their training scope. It diminishes their effectiveness in dynamic environments. These limitations significantly impact the application of LLMs in SE, and also highlight the need for expert developeers to critically refine and validate LLM-generated code for accuracy and security. In complex projects, the static nature of LLMs can hinder their ability to adapt to changing requirements or efficiently incorporate new information. Moreover, LLMs typically cannot interact with external tools or databases, further limits their utility in dynamic and evolving SE contexts. To address these challenges, LLM-based agents have emerged, combining the strengths of LLMs with external tools and resources to enable more dynamic and autonomous operations. These agents leverage recent advancements in AI, such as Retrieval-Augmented Generation (RAG) and tool utilization, to perform more complex and contextually aware tasks. For instance, OpenAI's Codex has been integrated into GitHub Copilot, enabling real-time code suggestions and completion within development environments. Unlike static LLMs, LLM-based agents can perform a wide range of tasks, such as autonomously debugging code by identifying and fixing errors, proactively refactoring code to enhance efficiency or readability, and generating adaptive test cases that evolve alongside the codebase. These features make LLM-based agents a powerful tool for SE, capable of handling more complex and dynamic workflows than traditional LLMs."}, {"title": "II. EXISTING WORKS AND THE SURVEY STRUCTURE", "content": "In recent years, large language models have been primarily applied to help programmers generate code and fix bugs. These models understand and complete code or text based on the user's input, leveraging their training data and reasoning capabilities. In previous survey papers, such as Angela Fan's research, there has not been much elaboration on requirement engineering. As mentioned in the paper, software engineers are generally reluctant to rely on LLMs for higher-level design goals. However, with LLMs achieving remarkable improvements in contextual analysis and reasoning abilities through various methods like prompt engineering and Chain-of-Thought (COT), their applications in requirement engineering are gradually increasing. Table I summarizes and categorizes the tasks in requirement engineering. Many studies utilize models for requirement classification and generation. Since the collection primarily focuses on the latter half of 2023 and before April 2024, and some papers address multiple tasks, the table does not reflect the exact number of papers we have collected. While other works have surveyed LLMs applications in some SE tasks, they lack a wider coverage of the general SE area to incorporate recent research developments. More importantly, a focus of LLMs is the main contributions of these works, but there is no distinguish the capabilities"}, {"title": "III. PRELIMINARIES", "content": "In this section, we introduce the foundational concepts of large language models, including the evolution of their frameworks and an overview of their architectures. Subsequent to this, we will discuss LLM-based agents, exploring both single-agent and multi-agent systems. We will also covers the background of these systems and their applications and distinctions in the field of software engineering."}, {"title": "A. Large Language Model", "content": "There is an inherent connection between large language models and natural language processing (NLP), with the historical development of natural language technologies tracing back to the 1950s. The earliest attempts to generate language dialogues through machines using specific rules can be traced to the period between 1950 and 1970. The advent of machine learning technologies in the 1980s and the groundbreaking introduction of neural networks in the 1990s indicated a new era for NLP. These advancements facilitated significant progress in the NLP field, especially in the development of technologies for text translation and generation. The development of Long Short-Term Memory (LSTM) and Recurrent Neural Networks (RNN) during this period enabled more effective handling of the sequential nature of language data. These models addressed challenges associated with the lack of dependency in context, thereby enhancing the application of NLP in various domains. In 2017 the new framework called \"Transformer\" introduced by Google's research team. The transformer model based on the self-attention mechanism which significantly improved the effectiveness of language models. The inclusion of positional encoding not only solved the long-sequence dependency issue but also enabled parallel computation, which was a considerable improvement over previous models. In 2018, OpenAI developed the Generative Pre-trained Transformer (GPT), a model based on the transformer architecture. The core idea behind GPT-1 was to utilize a large corpus of unlabelled text for pre-training to learn the patterns and structures of language, followed by fine-tuning for specific tasks. Over the next two years, OpenAI released GPT-2 and GPT-3 which increased the parameter count to 175 billions and also demonstrated strong capabilities in context understanding and text generation. GPT-4 launched by OpenAI in 2023, represents a milestone following GPT-3.5. Although GPT-4 maintains a similar parameter count of approximately 175 billion, its performance and diversity have seen considerable improvements. Through more refined training techniques and algorithm optimizations, GPT-4 enhanced the capability of language understanding and generation, particularly outperformed in handling complex texts and special contexts. Compared to other contemporary models like Google's PaLM or Meta's OPT, GPT-4 continues to stand out in multi-task learning and logical consistency in the text generation. While Google's PaLM model boasts up to 54 billion parameters, GPT-4 shows superior generalization abilities across a broader range of NLP tasks. On the open-source large models, Meta's OPT model with a parameter size similar to the GPT-4 offers direct competition. Despite OPT's advantages in openness and accessibility, GPT-4 still maintains a lead in specific application areas such as creative writing and complex problem solving."}, {"title": "B. Model Architecture", "content": "There are three common LLM architectures, the Encoder-Decoder architecture, exemplified by the traditional transformer model. This architecture comprises six encoders and six decoders, data input into the system will first passes through the encoder, where it undergoes sequential feature extraction via the model's self-attention mechanism. Subsequently, the decoders utilize the word vectors produced by the encoders to generate outputs, this technique is common to see in machine translation tasks, where the encoder processes word vectors from one language through several attention layers and feed-forward networks, thereby creating representations of the context. The decoder then uses this information to incrementally construct the correct translated text. A recent example of this architecture is the CodeT5+ model, launched by Salesforce AI Research in 2023. This model is an enhancement of the original T5 architecture, which designed to improve performance in code understanding and generation tasks. It incorporates a flexible architecture and diversified pre-training objectives to optimize its effectiveness in these specialized areas. This development highlights the competency of Encoder-Decoder architectures in tackling increasingly complex NLP challenges. The Encoder-only architecture, as the name suggests it eliminates the decoder from the entire structure making the data more compact. Unlike RNNs, this architecture is stateless and uses a masking mechanism that allows input processing without relying on hidden states, and also accelerating parallel processing speeds and providing excellent contextual awareness. BERT (Bidirectional Encoder Representations from Transformers) is a representative model of this architecture, this model is a large language model built solely on the encoder architecture. BERT leverages the encoder's powerful feature extraction capabilities and pre-training techniques to learn bidirectional representations of text, achieving outstanding results in sentiment analysis and contextual analysis. The Decoder-only archiecture, in the transformer framework primarily involves the decoder receiving processed word vectors and generating output. Utilizing the decoder to directly generate text accelerates tasks such as text generation and sequence prediction. This characteristic with high scalability is known as auto-regressiveness, which is why popular models like GPT use this architecture. In 2020, the exceptional performance of GPT-3 and its remarkable few-shot learning capabilities demonstrated the vast potential of the decoder-only architecture. Given the enormous computational cost and time required to train a model from scratch, and the exponential increase in the number of parameters, many researchers now prefer to leverage pre-trained models for further research. The most popular open-source pre-trained language model LLaMA, developed by Meta AI also employs the decoder-only architecture, as mentioned earlier, the autoregressiveness and simplicity of this structure make the model easier to train and fine-tune."}, {"title": "C. Large Language Model Based Agent", "content": "The concept of agents even trace back to the 19th century and is often referred to as intelligent agents, envisioned to possess intelligence comparable to humans. Over the past few decades, as AI technology has evolved, the capabilities of AI agents have significantly advanced, particularly with the reinforcement learning. This development has enabled AI agents to autonomously handle tasks and learn and improve based on specified reward/punishment rules. Notable milestones include AlphaGo, which leveraged reinforcement learning to defeat the world champion in Go competition. The success of GPT has further propelled the field, with researchers exploring the use of large language models as the \"brain\" of AI agents, thanks to GPT's powerful text understanding and reasoning capabilities. In 2023, a research team from Fudan University conducted a comprehensive survey on LLM-based agents, examining their perception, behavior, and cognition. Traditional LLMs typically generate responses based solely on given natural language descriptions, lacking the ability for independent thinking and judgment. LLM-based agents able to employ multiple rounds of interaction and customized prompts to gather more information, which enable the model to think and make decisions autonomously. In 2023, Andrew Zhao proposed the ExpeL framework, which utilizes ReAct as the planning framework combined with an experience pool. This allows the LLM to extract insights from past records to aid in subsequent related queries, by letting the LLM analyze why previous answers were incorrect, it learns from experience to identify the problems. At the same time, the application of LLM-based embodied agents has also become a hot research area in recent years. LLM-based Embodied Agents are intelligent systems that integrate LLMs with embodied agents. These systems can not only process natural language but also complete tasks through perception and actions in physical or virtual environments. By combining language understanding with actual actions, these agents can perform tasks in more complex environments. This integration often involves using visual domain technologies"}, {"title": "IV. REQUIREMENT ENGINEERING AND AND DOCUMENTATION", "content": "Requirement Engineering is a critical field within software engineering and plays an essential role in the software development process, its primary task is to ensure that the software system meets the needs of all relevant stakeholders. Typically, requirement engineering in project development involves many steps, where developers need to fully understand the users' needs and expectations to ensure that the development direction of the software system aligns with actual requirements. The collected requirements are then organized and evaluated by the development group. Requirements Specification is the process of formally documenting the analyzed requirements, the specification must be accurate and concise, and the requirement verification must be conducted to ensure that developers are building what users need and that it aligns with the specifications. Requirement engineering also includes requirement management, a task that spans the entire software development life-cycle, developers need to continuously track, control, and respond to any changes occurring during development, ensuring that these changes do not negatively impact the project's progress and overall quality."}, {"title": "A. LLMs Tasks", "content": "In the field of requirement engineering, LLMs have demonstrated significant potential in automating and enhancing tasks such as requirement elicitation, classification, generation, specification generation, and quality assessment. Requirement classification and extraction is a crucial task in requirement engineering during the development process. It is common to encounter situations where clients present multiple requirements at once, necessitating manual classification by developers. By categorizing requirements into functional and non-functional requirements, developer can better understand and manage them, thanks to the strong performance of LLMs in classification tasks, many relevant frameworks have been developed. The PRCBERT framework, utilizing the BERT pre-trained language model, transforms classification problems into a series of binary classification tasks through flexible prompt templates, significantly improving classification performance. Studies have shown that the PRCBERT achieved an F1 score of 96.13% on the PROMISE dataset which outperform the previous state-of-arts NORBERT and BERT-MLM models. Additionally, the application of ChatGPT in requirement information retrieval has shown promising results, by classifying and extracting information from requirement documents, ChatGPT achieved comparable or even better F\\u03b2 scores under zero-shot settings, particularly in feature extraction tasks, where its performance surpassed baseline models. As seen in Table I, there is also substantial literature and research on using LLMs to automatically generate requirements and descriptions in requirement engineering. By automating the generation and description of requirements, the efficiency and accuracy of requirement elicitation can be improved. Research indicates that LLMs hold significant potential in requirements generation task. For example, using ChatGPT to generate and gather user requirements, studies found that participants with professional knowledge could use ChatGPT more effectively, indicating the influence of domain expertise on the effectiveness of LLM-assisted requirement elicitation. The study employed qualitative assessments of the LLMs' output against predefined criteria for requirements matches, including full matches, partial matches, and the relevancy of the elicited requirements, although their success varied depending on the complexity of the task and the experience of the users, the result showing that LLMs could effectively assist in eliciting requirements, and its particularly useful in identifying, and suggesting requirements based on the large corpus of training data they provided. The SRS (Software Requirement Specification) generation is an important task which the developer normally spent a lot of time to refine and verified. In , researchers use both iterative prompting and a single comprehensive prompt to assess the performance of LLMs to generate SRS. The experiment conducted on GPT-4 and CodeLlama-34b one close-source LLM and one open-source LLM for comprehensive evaluation, the generated SRS will compare with human-crafted SRS and finally scored by the likert scale. The result indicate that, the human-generated SRS was overall superior, but CodeLlama often came close, sometimes outperforming in specific categories. The CodeL-lama scored higher in completeness and internal consistency than GPT-4 but less concise, so this stuy demonstrated the potential of using fine-tuned LLMs to generate SRS and increase the overall project productivity. Another paper also explores using LLMs for generating specifications. In , the authors introduce a framework called SpecGen for generating program specifications. The framework primarily uses GPT-3.5-turbo as the base model and employs prompt engineering combined with multi-turn dialogues to generate the specifications. SpecGen applies four mutation operators to modify these specifications and finally uses a heuristic selection strategy to choose the optimal variant. The results show that SpecGen can generate 70% of the program specifications, outperforming traditional tools like Houdini and Daikon. Furthermore, designing prompt patterns can significantly enhance LLMs' capabilities in tasks such as requirement elicitation and system design. The paper provides a catalog of 13 prompt patterns, each aimed at addressing specific challenges in software development. The experiments test the efficacy of these patterns in real world scenarios to validate their usefulness. By applying different prompt patterns, the study found that these patterns could help generate more structured and modular results and reduce common errors. Automated requirement completeness enhancement is another important benefit brought by the LLMs in requirement generation. The study use BERT's Masked Language Model (MLM) can detect and fill in missing parts in natural language requirements, significantly improving the completeness of requirements. BERT's MLM achieved a precision of 82%, indicating that 82% of the predicted missing terms were correct. There is also the application of LLMs in ambiguity detection tasks, aimed at detecting ambiguities in natural language"}, {"title": "B. LLM-based Agents Tasks", "content": "Currently the application of LLM-based agents in the requirement engineering is till quite nascent, but there are some useful researches to help us to see the potential possibility. LLM-based agents bring both efficiency and accuracy for tasks like requirement elicitation, classification, generation, and verification. Compared to traditional LLMs, these systems exhibit higher levels of automation and precision through task division and collaboration. The application of multi-agent systems in semi-structured document generation has shown significant effectiveness. In , a multi-agent framework is introduced that combines semantic recognition, information retrieval, and content generation tasks to streamline the creation and management of semi-structured documents in the public administration domain. The proposed framework involves three main types of agents: Semantics Identification Agent, Information Retrieval Agent, and Content Generation Agent. By avoiding the overhead of a single model, each agent is assigned a specific task with minimal user intervention, following the designed framework and workflow. Additionally, the AI-assisted software development framework (AISD) also showcases the autonomy brought by the LLM-based agents in requirement engineering. proposes the AISD framework, which continuously improves and optimizes generated use cases and code through ongoing user feedback and interaction. In the process of the experiment, humans need to first give a fuzzy requirement definition, and then LLM-based agent will improve the requirement case according to this information, and then design the model and generate"}, {"title": "C. Analysis", "content": "The application of LLM-based agents in requirement engineering has demonstrated significant efficiency improvements and quality assurance. Through multi-agent collaboration and automated processing, these systems not only reduce manual intervention but also enhance the accuracy and consistency of requirement generation and verification. We can see that the tasks of LLM-based agents are no longer limited to simply generating requirements or filling in the gaps in descriptions. Instead, they involve the implementation of an automated process, with the generation of requirement documents being just one part of it, integrating LLM into agents enhances the overall system's natural language processing and reasoning capabilities. In the real-world application, many tasks can no longer be accomplished by simple LLMs alone, especially for high-level software design. The emergence of LLM-based agents addresses this issue through a multi-agent collaborative system centered around LLMs, these agents continuously analyze and refine the deficiencies in the requirement documents, this is might be the main application trend of LLM-based agents in requirements engineering in the future. The application of LLM-based agents in requirements engineering is still relatively limited, with most efforts focusing on"}, {"title": "V. CODE GENERATION AND SOFTWARE DEVELOPMENT", "content": "Code generation and software development are core areas within software engineering which plays a crucial role in the software development process. The primary objective of using LLMs in code generation is to enhance development efficiency and code quality through automation processes, thereby meeting the needs of both developers and users. In recent years, the application of LLMs in code generation and software development has made significant progress, this has changed the way developers work and revealed a shift in automated development processes. Compared to requirement engineering, research on the application of LLMs and LLM-based agents in code generation and software development is more extensive and in-depth. Using natural language processing and generation technologies, LLMs can understand and generate complex code snippets, assisting developers in automating various stages from code writing and debugging to software optimization. The decoder-based large language models such as GPT-4 have shown significant potential in code generation by providing accurate code suggestions and automated debugging, greatly improving development efficiency. Recently, the application of LLM-based agents in software development is also gaining attention, these intelligent agents can not only perform complex code generation tasks but also engage in autonomous learning and continuous refinement, thereby offering flexible assist in dynamic development environments. Tools like GitHub Copilot, which integrate LLMs, have already demonstrated their advantages in enhancing programming efficiency and code quality."}, {"title": "A. LLMs Tasks", "content": "Large language models have optimized various tasks in code generation and software development through automation and reasoning, covering areas such as code generation, debugging, code comprehension, code completion, code transformation, and multi-turn interactive code generation. The primary method is generating executable code from natural language descriptions, where models utilize previously learnt code snippets or apply few-shot learning to better understand user requirements. Nowadays the AI tools integrates deeply with IDEs like Visual Studio Code and JetBrains to enhance code writing and translation tasks such as OpenAI's Codex model. Codex fine-tuned on public code from GitHub, demonstrate the capability to generate Python functions from doc-strings also outperformed other similar models on the HumanEval benchmark. In , researchers comprehensively evaluated the performance of multiple LLMs on L2C(language to code) tasks. The results showed that GPT-4 demonstrates strong capability in tasks such as semantic parsing, mathematical reasoning, and Python programming. With instruction tuning and support from large-scale training data, the model can understand and generate code that aligns with user intent, achieving high-precision code generation. Applying LLMs to text-to-database management and query optimization is also a novel research direction in natural language to code generation task. By converting natural language queries into SQL statements, LLMs help developers quickly generate efficient database query code. In , proposed the SQL-PaLM framework which significantly enhances the execution accuracy and exact match rate for text-to-SQL tasks through a few-shot prompt and instruction fine-tuning, providing an effective solution for complex cross-domain SQL generation tasks. The improvements in accuracy and exact match achieved in the SQL-PaLM model are considered state-of-the-art (SOTA) in tested benchmarks, the SQL-PaLM performed promise results comparing with existing methods such as T5-3B + PICARD, RASAT + PICARD, and even GPT-4, achieving the highest test accuracy of 77.3% and an execution accuracy of 82.7%. Multilingual code generation is another important application of LLMs, particularly suited to the transformer architecture. In , researchers introduced the CodeGeeX model, which was pre-trained on multiple programming languages and performed well in multilingual code generation and translation tasks. Experimental results showed that CodeGeeX outperformed other multilingual models on the HumanEval-X benchmark. Although current LLMs possess excellent code generation capabilities, with accuracy and compile rates reaching usable levels, the quality of generated code often depends on the user's prompts. If the prompts are too vague or general, the LLM typically struggles to understand the user's true requirements, making it difficult to generate the desired code in a single attempt. In , researchers introduced \"print debugging\" technique, using GPT-4 to track variable values and execution flows, which enhancing the efficiency and accuracy by using in-context learning techniques. This method is particularly suitable for medium-difficulty problems on Leetcode, compared to the rubber duck debugging method, print"}, {"title": "B. LLM-based Agents Tasks", "content": "LLM-based agents have shown significant potential and advantages by substantially improving task efficiency and effectiveness through multi-agent collaboration. Unlike traditional LLMs, LLM-based agents adopt a division of labor approach, breaking down complex tasks into multiple subtasks handled by specialized agents, this method can enhance task efficiency and improves the quality and accuracy of generated code to mitigate the hallucination from the single LLM. In , researchers proposed a self-collaboration framework where multiple ChatGPT (GPT-3.5-turbo) agents act as different roles to collaboratively handle complex code generation tasks. Specifically, the introduction of Software Development Methodology (SDM) divides the development process into three stages: analysis, coding, and testing. Each stage is managed by specific roles, and after completing their tasks, each role provides feedback and collaborates with others to improve the quality of the generated code. Experiment shows that this self-collaboration framework significantly improves performance on both the HumanEval and MBPP benchmarks, with the highest improvement reaching 29.9% in HummanEval compared to the SOTA model GPT-4. This result demonstrating the potential of collaborative teams in complex code generation tasks. Although it lacks external tool integration and dynamic adjustment capabilities, this framework exhibits common characteristics of LLM-based agents, such as role distribution, self-improvement ability, and excellent autonomous decision-making, these combined capabilities qualify it to be considered an LLM-based agent. Similarly, In , the LCG framework improved code generation quality also through multi-agent collaboration and chain-of-thought techniques, once again demonstrating the effectiveness of multi-agent collaboration in the software development process. The limitations of context windows was not discussed in previous studies, this has been thoroughly explored in a 2024 by University of Cambridge team. In , researchers introduced the L2MAC framework, which dynamically manages memory and execution context through a multi-agent system to generate large codebases, and achieved SOTA performance in generating large codebases for system design tasks. The framework is primarily divided into the following components: the processor, which is responsible for the actual generation of task outputs; the Instruction Registry, which stores program prompts to solve user tasks; and the File Storage, which contains both final and intermediate outputs. The Control Unit periodically checks the outputs to ensure that the generated content is both syntactically and functionally correct. The researchers conducted multiple experiments and compared with many novel methods like GPT-4, Reflexion, and Auto-GPT, achieving a Pass@1 score of 90.2% on the HumanEval benchmark, showcasing its superior performance in generating large-scale codebases. Recently, many studies have begun to use LLM-based agents to simulate real software development processes, the paper introduced the MetaGPT framework, which enhanced problem-solving capabilities through standard operating procedures (SOPs) encoded in multi-agent collaboration. The entire process of the multi-collaboration framework simulates the waterfall life-cycle of software development, with each agent playing different roles and collaborating to achieve the goal of automating software development. LLM-based agents have also shown strong ability in automated software development, proposed a multi-GPT agent framework that automates tasks such as project planning, requirement engineering, software design, and debugging, illustrating the"}, {"title": "C. Analysis", "content": "The main differences between LLM-based agents and traditional LLMs in software development applications mainly focus on the efficiency and autonomy, particularly in task division and collaboration. Traditional LLMs typically use a single model to handle specific tasks, such as generating code from text and code completion. However, this approach has limitations when dealing with complex tasks, especially regarding context window restrictions and the need for continuous feedback. LLM-based agents handle different subtasks through collaboration with clear division of labor, thereby enhancing task efficiency and quality. For example, in a code generation task, one agent generates the initial code, another designs test cases, and a third executes tests and provides feedback, thus achieving iterative optimization. Through task division, multi-agent systems, and tool integration, LLM-based agents can tackle more complex and broader tasks, improving the quality and efficiency of code generation. This approach overcomes the limitations of traditional LLMs also provides new directions and ideas for future software development research and applications, to frees programmers from the boring test suite generation."}, {"title": "VI. AUTONOMOUS LEARNING AND DECISION MAKING", "content": "Autonomous Learning and Decision Making is a critical and evolving field in modern software engineering, especially under the influence of artificial intelligence and big data. The core task of autonomous learning and decision making is to achieve automated data analysis, model building, and decision optimization through machine learning algorithms and intelligent systems, thereby enhancing the autonomy and intelligence of systems. In this process, LLMs and LLM-based agents bring numerous possibilities, following the development of NLP technology, a lot of achievements have been made in the application of LLMs in this field. These models can handle complex language tasks and also demonstrate powerful reasoning and decision-making abilities, the research on voting inference using multiple LLMs calls has revealed new methods for op-"}, {"title": "VII. SOFTWARE DESIGN AND EVALUATION", "content": "The application of LLMs to software design and evaluation has very similar overlaps with previous topics, software design is an early phase of software development, and the quality of the design directly impacts the quality of furture development. Modern software engineering methodologies emphasize the integration of design and development to ensure that decisions made during the design phase seamlessly translate into high-quality code. Consequently, the research on software design often explores aspects related to code generation and development by utilizing LLMs for software development with a certain framework and special architecture design. Software design frameworks often involve multiple stages of continuous refinement to achieve optimal results, which can be considered part of LLM applications in software development. Similarly, and highlight the frequent use of tools or API interfaces when using LLMs to assist in development and design, demonstrating an overlap with the topic of code generation and software development. LLMs in software design and evaluation also intersect extensively with autonomous learning and decision making, these two topics are interrelated fields. Software design needs to consider system adaptability and learning capabilities to handle dynamic environments, therefore design evaluations involving autonomous learning and decision making naturally become a focal point of intersection for these two topics. Many LLM techniques and methods find similar applications in both fields, for example LLMs based on reinforcement learning can be used for automated design decisions and evaluations, as well as for self-learning and optimization. Common applications of LLMs in software engineering involve fine-tuning models with prompt engineering techniques to continuously enhance performance particularly in software design and evaluation, more sample learning is often required to ensure that the model outputs align with user expectations. Additionally, requirement elicitation and specification in requirement engineering can also be considered part of software design and evaluation. This section reviews the main research achievements of LLMs in software design and evaluation in recent years, discussing their application scenarios and practical effects."}, {"title": "A. LLMs Tasks", "content": "In recent years, there has been extensive research on the use of LLMs in tasks such as automation, optimization, and code understanding. ChatGPT has been widely utilized for various software engineering tasks and demonstrated excellent performance in tasks like log summarization, pronoun resolution, and code summarization, achieving a 100% success rate in both log summarization and pronoun resolution tasks. However, its performance on tasks such as code review and vulnerability detection is relatively poor, which shows that it needs further improvement for more complex tasks. Another framework EvaluLLM addresses the limitations of traditional reference-based evaluation metrics (such as BLEU and ROUGE) by using LLMs to assess the quality of natural language generation (NLG) outputs. The EvaluLLM introduces a new evaluation method that compares generative outputs in pairs and uses win rate metrics to measure model performance, this approach can simplifies the evaluation process also ensures consistency with human assessments, showcasing the broad application prospects of LLMs in gener-"}, {"title": "VIII. SOFTWARE TEST GENERATION", "content": "In software development, a crucial component is software testing, which need to continuously been conducted from the initial system development to the final deployment. In industry, agile development is commonly used which test system continuously at every stage to ensure the robustness of the entire system, whenever new code is committed to the GitHub, tests are conducted to ensure the usability of the updated version. A common approach is to use Jenkins to achieve continuous integration and continuous deployment. Jenkins automatically hooks into the developer's action of pushing code to GitHub and runs a test suite against the new version. Although the entire process leans towards automated development, creating and refining test cases still requires large human effort. Typical roles in development involve software testing, such as writing unit tests, integration tests, and fuzz tests. Researchers have been attempting to use AI to help generate test cases since before the 2000. Initial implementations typically involved simpler forms of AI and machine learning to automate parts of the test case generation process. Over time, more sophisticated methods such as natural language processing and machine learning models have been applied to improve the precision and scope of test case generation. Online tools like Sofys, which use machine learning to generate context-based paths in applications, also exist to aid in generating test suites. Using large language models to generate test cases is a relatively new attempt but has been developing rapidly. In 2020, researchers utilized pre-trained language models fine-tuned on labeled data to generate test cases. They developed a sequence-to-sequence transformer-based model called \"ATHENATEST\" and compared its generated results with EvoSuite and GPT-3, demonstrating better test coverage. More research and models are being dedicated to test suite generation experiments, for instance, the Codex model, mentioned earlier in the code generation section, combined with chain-of-thought prompting, achieved high-quality test suite generation with CodeCoT, even in zero-shot scenarios. The introduction of LLMs aims to automate and streamline the testing process, making it more rigorous and capable of addressing aspects that humans might easily overlook."}, {"title": "A. LLMs Tasks", "content": "The application of LLMs in software test generation is extensive and encompasses more than just test suite generation. The reviewed paper included in this survey covers several aspects, including security test generation, bug reproduction, general bug reproduction, fuzz testing, and coverage-driven test generation. These tasks are achieved through various models and techniques, significantly improving software quality and reducing developers' workload. aims to evaluate the effectiveness of using GPT-4 to generate security tests, demonstrating how to conduct supply chain attacks by exploiting dependency vulnerabilities. The study experimented with different prompt styles and templates to explore the effectiveness of varying information inputs on test generation quality, the results showed that tests generated by ChatGPT successfully discovered 24 proof-of-concept vulnerabilities in 55 applications, outperforming existing tools TRANSFER and SIEGE. This research introduces a new method for generating security tests using LLMs and provides empirical evidence of LLM's potential in the security testing domain, offering developers a novel approach to handling library vulnerabilities in applications. Another application is bug reproduction, which allows testers to locate and fix bugs more quickly and efficiently. addresses the limitations of current bug reproduction methods, which are constrained by the quality and clarity of handcrafted patterns and predefined vocabularies. The paper proposes and evaluates a new method framework called AdbGPT, which uses a large language model to automatically reproduce errors from Android bug reports. AdbGPT is described as outperforming current SOTA approaches in the context of automated bug replay for only Android system. The experimental results show that AdbGPT achieved accuracies of 90.4% and 90.8% in S2R entity extraction and a success rate of 81.3% in error reproduction, significantly outperforming the baseline ReCDroid and ablation study versions. By introducing prompt engineering, few-shot learning, and chain-of-thought reasoning, AdbGPT demonstrates the powerful capabilities of LLMs in automated error reproduction. It also uses GUI encoding to convert the GUI view hierarchy into HTML-like syntax, providing LLMs with a clear understanding of the current GUI state. While AdbGPT is specialized for Android systems, proposes the LIBRO framework, which uses LLMs to generate bug reproduction tests from bug reports."}, {"title": "B. LLM-based Agents Tasks", "content": "In the field of software test generation, the application of LLM-based agents demonstrates their potential in automated test generation. While relying on LLM-based agents for software test generation might seem excessive, more research is directed towards vulnerability detection and system maintenance. LLM-based agents can enhance test reliability and quality by"}]}