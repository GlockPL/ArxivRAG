{"title": "Deep Learning for Spatio-Temporal Fusion in Land Surface Temperature Estimation: A Comprehensive Survey, Experimental Analysis, and Future Trends", "authors": ["Sofiane Bouaziz", "Adel Hafiane", "Rapha\u00ebl Canals", "Rachid Nedjai"], "abstract": "The rapid advancements in satellite remote sensing have enhanced the capability to monitor and analyze the Earth's surface. Among the many variables captured through satellite sensors, Land Surface Temperature (LST) plays a critical role in understanding key environmental processes. However, obtaining high-resolution LST data remains a challenge, as satellite sensors often face a trade-off between spatial and temporal resolutions. In response, Spatio-Temporal Fusion (STF) has emerged as a powerful method to integrate two satellite data sources, one providing high spatial but low temporal resolution, and the other offering high temporal but low spatial resolution. Although a range of STF techniques have been proposed, from traditional methods to cutting-edge deep learning (DL) models, most have focused on surface reflectance, with limited application to LST estimation. DL approaches, in particular, show promise in improving the spatial and temporal resolutions of LST by capturing complex, non-linear relationships between input and output LST data. This paper offers a comprehensive review of the latest advancements in DL-based STF techniques for LST estimation. We analyze key research developments, mathematically formulate the STF problem, and introduce a novel taxonomy for DL-based STF methods. Furthermore, we discuss the challenges faced by current methods and highlight future research directions. In addition, we present the first open-source benchmark STF dataset for LST estimation, consisting of 51 pairs of MODIS-Landsat images spanning from 2013 to 2024. To support our findings, we conduct extensive experiments on state-of-the-art methods and present both quantitative and qualitative assessments. This is the first survey paper focused on DL-based STF for LST estimation. We hope it serves as a valuable reference for researchers and paves the way for future research in this field.", "sections": [{"title": "I. INTRODUCTION", "content": "OVER the past decade, urbanization has intensified globally, with cities hosting an ever-increasing proportion of the world's population. As of 2020, more than half of the global population lives in urban areas, with European urbanization rates reaching 74% as early as 2017 [1]. However, this rapid expansion has amplified several environmental challenges, including the Urban Heat Island (UHI) effect, increased air and water pollution, and reduced green spaces. These issues collectively contribute to higher energy demands, deteriorating air quality, and adverse public health impacts, such as respiratory illnesses and heat-related mortality, particularly in densely populated regions [2]\u2013[4].\nLand Surface Temperature (LST) emerged as an important variable for understanding and managing various environmental challenges. Physically, LST represents the thermal radiation emitted from the Earth's surface, influenced by how incoming solar energy interacts with the ground or the canopy in vegetated areas [5]. LST is regarded as a critical component of Earth system data by NASA and other international organizations [6], and is recognized by the Global Climate Observing System as one of the ten essential climate variables in the land biosphere [7]. It plays a key role in revealing the temporal and spatial dynamics of the surface's equilibrium state [8], [9]. This knowledge is fundamental for a wide array of applications, including climate monitoring [10], [11], urban planning [12], [13], and natural resource management [14], [15]. Satellites are the primary tool for collecting and measuring LST globally at a different scale averaged over space [16], which offers consistent LST data across large areas with frequent revisit times. As a result, many thermal infrared (TIR) sensors have been deployed on satellites, which lead to the development of various techniques for estimating LST at different spatial and temporal resolutions [17]\u2013[23]. While satellite technology has made substantial advances in capturing precise LST observations, technical and budgetary constraints still impose a trade-off between spatial and temporal resolutions [24], [25]. Spatial resolution refers to the level of detail captured within a single pixel in an LST observation [26]. While Temporal resolution refers to the frequency of LST observations over time for a specific region [27]. However, simultaneously achieving both high spatial and high temporal resolution remains challenging, as higher spatial detail often necessitates a reduced frequency of re-visiting, while frequent observations generally rely on coarser spatial resolution [28].\nTwo main approaches have been identified in the literature for producing LST data with high spatial and temporal resolution [29]: spatial downscaling [28] and Spatio-Temporal fusion (STF) [30]. Spatial downscaling, also known as thermal sharpening or disaggregation, improves spatial resolution by assuming a consistent relationship between LST and auxiliary data at different scales [31]\u2013[34]. For example, the thermal"}, {"title": "II. SATELLITE-DERIVED LST", "content": "In this section, we will define LST, explain how it is derived from satellite observations, and discuss the challenges associated with the trade-off between spatial and temporal resolution in satellite data.\nA. LST Concept and Retrieval\nLST is defined as the thermodynamic temperature at the surface of objects. In RS, this surface layer is continuous and projected across all visible components within the sensor's instantaneous field of view (IFOV), as shown in Figure 4. RS LST is called radiometric temperature [103], as it requires eliminating atmospheric effects and correcting for emissivity. Its formula is described in the equation 1 [16], [104], [105].\n$T_{\\varepsilon}(\\theta_{v}, \\varphi_{v}) = B^{-1}\\left[\\frac{A}{B}\\right]$\n(1)\n$A = R_{x}(\\theta_{v}, \\varphi_{v}) - R_{ata\\uparrow} (\\theta_{v}, \\varphi_{v}) \\newline - \\tau_{\\lambda} (\\theta_{v}, \\varphi_{v}) [1 - \\varepsilon_{\\lambda} (\\theta_{v}, \\varphi_{v})] R_{ata\\downarrow}$\n$B = \\tau_{\\lambda} (\\theta_{v}, \\varphi_{v}) \\varepsilon_{\\lambda} (\\theta_{v}, \\varphi_{v})$\nwhere Ts is the radiometric temperature, \u03b8v and \u03c6v represent the viewing zenith and azimuth angles, \u03bb is the channel- effective wavelength. B\u22121 is the inverse function of Planck's law, which converts the measured radiance into temperature. Rx, Rata\u2191, and Rata\u2193 are the at-sensor observed radiance, upward atmospheric radiance, and downward atmospheric radiance respectively, \u03c4\u03bb is the channel atmospheric transmittance, and \u03b5\u03bb is the channel land surface emissivity (LSE).\nThe radiometric temperature has four properties:\n1) It is independent of spatial scale, meaning it can be applied across various scales [107].\n2) The depth of penetration depends on the wavelength used. In TIR range (\u03bb \u2248 10 \u00b5m), the depth varies from 1 to 100 \u00b5m, leading to the term skin temperature [103]. In the microwave range (\u03bb \u2248 1 cm), the depth ranges from 0.1 to 10 cm, hence the term subsurface temperature [108].\n3) It is affected by the viewing angle, making it directional [103].\n4) It represents an average temperature derived from all homogeneous and isothermal elements within the IFOV [103]\nRetrieving LST from these radiances presents a challenging and ill-posed problem due to the following reasons:"}, {"title": "III. STF PROBLEM FORMULATION", "content": "This section defines the STF problem mathematically, in- troduces the relevant notations, and explains how DL is integrated. It also categorizes the various loss functions used during the training process and presents the evaluation metrics employed to assess model performance.\nA. Mathematical Definition of STF\nThe STF problem can be viewed as a multi-objective optimization problem, wherein the goal is to simultaneously enhance both the spatial and temporal resolution, as shown in equation 2.\n$max (F(R_{s}), F(R_{t}))$\n(2)\nwhere, F(Rs) and F(Rt) represent the objectives correspond- ing to spatial and temporal resolution enhancement, respec- tively. However, an additional, often overlooked, objective is the gap filling in the high-resolution image. This makes the STF problem a tri-objective optimization problem that aims to balance spatial and temporal resolution enhancement along with the efficient filling of gaps.\nSTF methods are primarily based on the use of known char- acteristics of image pixel values over time, called temporal variations, and at different spatial scales, called spatial vari- ations, to estimate HSHT satellite images. For LST, temporal variations refer to changes in the values observed in the same area over time, while differences in spatial variations refer to changes in the number and type of pixels between LSHT and HSLT images.\nLet X1 and X2 represent the data from two satellites: the first, X1, provides LST data with LSHT, and the second, X2, provides LST data with HSLT. Let t1, t2, t3 be three distinct time steps, and let s denote the region of interest. Therefore, X1(s, ti) and X2(s, ti) for i \u2208 {1, 2, 3} represent the LST data from the first or second satellite at time ti at location s. Given two pairs of satellite images, P1 = {X1(s, t1), X2(s,t1)} and P3 = {X1(s, t3), X2(s, t3)}, at times t1 and t3, along with the image X1(s, t2) at time t2, the objective of STF is to predict X2(s,t2), as illustrated on Figure 4. The various notations used in this formulation are summarized in Table III.\nGiven the previous description, the predicted high spatial resolution image at time t2, denoted as X2(s,t2)), can be defined as in equation 3. The goal is for X2(s,t2) to be as close as possible to the real X2(s,t2).\n$X_{2}(s,t_{2}) = f (P_{1}, P_{3}, X_{1} (s, t_{2})) .$\n(3)\nHowever, this problem cannot be adequately solved using linear methods [48], [112], [113]. As a result, non-linear approaches, such as DL, are more suitable. DL is a subset of machine learning that employs neural networks with multiple layers to learn complex and non-linear relationships in data. To account for these non-linear dependencies, the function f is modified to include weights W that are optimized during training, as shown in equation 4.\n$X_{2}(s, t_{2}) = f (P_{1}, P_{3}, X_{1} (s, t_{2})|W)$.\n(4)\nIn certain cases, relying on two pairs of images may not be optimal, as it requires waiting for a future pair, P3, captured"}, {"title": "B. Loss functions", "content": "The weights W introduced in Equation 4 are learned us- ing a loss function that measures the difference between X2(s,t2) and X2(s,t2) in different levels and is denoted as Loss [X2, X2]. Common forms of the loss function are presented in this subsection.\n1) Content Loss: It ensures that the reconstructed image preserves the overall texture and tone of the ground truth image. It includes metrics such as the Mean Squared Error (MSE), which quantifies the average squared difference between the pixel intensities of the predicted and reference images, as shown in Equation 5. Another example is the Mean Absolute Error (MAE), Euclidean distance [114], Frobenius norm [115], Kullback-Leibler (KL) Divergence [116], and the Huber loss [117]. Additionally, some works incorpo- rate satellite-derived indices, such as the NDVI [118] and NDBI [119], into the loss function to guide the fusion process.\n$L_{content} = \\frac{1}{N} \\sum_{i=1}^{N} (X_{2}(s_{i}, t_{2}) - \\widehat{X_{2}(s_{i}, t_{2})})^{2}$\n(5)\n2) Vision loss: It quantifies the overall quality of the image, particularly from a human visual perception standpoint. A common measure used to assess it is the Structural Similarity Index (SSIM) [120], which evaluates the similarity of images by considering three aspects: luminance, contrast, and structure, as formulated in Equation 6. Another example is the multi-scale SSIM (MS-SSIM) [121].\n$L_{vision} = \\frac{(2\\mu_{X_{2}(s,t_{2})} \\mu_{\\widehat{X_{2}(s,t_{2})}} + C_{1})(2\\sigma_{X_{2}}\\widehat{X_{2}(s,t_{2})} + C_{2})}{(\\mu^{2}_{X_{2}(s,t_{2})} + \\mu^{2}_{\\widehat{X_{2}(s,t_{2})}} + C_{1})(\\sigma^{2}_{X_{2}(s,t_{2})} + \\sigma^{2}_{\\widehat{X_{2}(s,t_{2})}} + C_{2})}$\n(6)\nwhere $\\mu_{X_{2}(s,t_{2})}$ and $\\mu_{\\widehat{X_{2}(s,t_{2})}}$ are the means of the predicted and ground truth images, $\\sigma^{2}_{X_{2}(s,t_{2})}$ and $\\sigma^{2}_{\\widehat{X_{2}(s,t_{2})}}$ are their variances, and $\\sigma_{X_{2}}\\widehat{X_{2}(s,t_{2})}$ is the covariance between the predicted image X2(s, t2) and the ground truth image $\\widehat{X_{2}(s,t_{2})}$. Constants C1 and C2 are used to stabilize the division.\nAdditionally, Sobel loss calculates the MSE loss of features after passing through the Sobel operator [122]. This loss"}, {"title": "C. Evaluation Metrics", "content": "Similar to computer vision (CV) tasks, STF models utilize a range of evaluation metrics that can be categorized into three key groups: Error Assessment Metrics, Quality Assessment Metrics, and Computational Assessment Metrics"}, {"title": "IV. TAXONOMY OF DL-BASED STF METHODS", "content": "In this section, we propose a new taxonomy to classify Deep Learning (DL)-based Spatio-Temporal Fusion (STF) methods. We constructed this taxonomy, we selected 30 methods based on recency, consistency, and relevance. The classification is organized around four key criteria, as illustrated in Fig- ure 5: Architecture, Learning Algorithm, Training Strategy, and Incorporation of Pre-trained Models. For each criterion, we categorize the methods into corresponding sub-criteria, ensuring a structured analysis that captures the diversity and unique characteristics of each approach.\nA. Architectures\nThe primary criterion for differentiating DL-based STF methods is the underlying model architecture, which can be based on CNNs, AEs, GANs, Vision transformers, or RNNs.\n1) Convolutional Neural Networks: CNNs are among the most well-known and widely used architectures designed to efficiently process grid-like data structures such as images [132]\u2013[134]. CNNs are a feed-forward neural network that has significantly advanced the field of image analysis and CV [135]. One of the key advantages of CNNs over traditional neural networks is their ability to automatically identify and learn relevant features from input data without requiring human supervision [136]. This makes CNNs highly effective at extracting complex spatial hierarchies from images, such as edges, textures, and shapes. A CNN consists of a series of layers between the input and output, typically including: convolutional, pooling, normalization, activation, and fully connected layers [137].\n\u2022 Convolutional Layers: Perform convolution operations using multiple local filters to extract spatial features from the input data, which produce feature maps that capture important patterns.\n\u2022 Pooling Layers: Reduce the spatial dimensions of feature maps, which helps to decrease computational load and makes the learned features more robust to variations and distortions in the input.\n\u2022 Normalization Layers: Improve the stability and convergence of the network during training.\n\u2022 Activation Layers: Apply non-linear functions, like Rectified Linear Unit (ReLU) [138], to increase the network's ability to model complex relationships within data.\n\u2022 Fully Connected Layers: Integrate the features learned from previous layers and use them to make final predictions or classifications.\nCNNs have evolved considerably since their introduction in the 1980s [139]. [140] introduced LeNet-5 in 1998, a CNN model designed to classify handwritten digits from the MNIST dataset, based on convolutional and fully connected layers. In 2012, AlexNet [132] revolutionized CNNs by achieving state-of-the-art results on the ImageNet dataset [141] through deeper architecture, smaller filters, and an increased number of hidden units. VGG [142] maintained strong performance with a simpler design, while GoogLeNet [143] used Inception mod- ules for multi-scale feature learning. In 2016, ResNet [144] introduced residual connections for very deep networks, also excelling on ImageNet. Later models like DenseNet [145], ResNeXt [146] and EfficientNet [147] enhanced feature reuse and scaling efficiency.\nCNN-based STF methods leverage CNN to automatically cap- ture and model the complex, non-linear relationships between LSHT and HSLT image pairs. These learned relationships are then used to predict target images at a fine spatial resolution. Although CNNs are primarily designed for spatial modeling, they can be adapted to incorporate temporal information. This is achieved by processing multiple temporal images through"}, {"title": "2) Autoencoder", "content": "An AE is an unsupervised learning neural network designed to learn efficient and informative represen- tations of input data [150]. It consists of two main com- ponents: the encoder, which transforms the input data into a compressed, high-level feature representation, and the de- coder, which reconstructs the original input from this compact representation [151], [152]. The objective of an AE is to minimize the difference between the original and reconstructed data [153], which enables it to extract meaningful, non-linear features and identify patterns without the need for labeled training data [154]. The basic architecture of a standard AE is illustrated in Figure 7. It consists of three main components: an input layer, a hidden layer, and an output layer. The hidden layer acts as a bottleneck with fewer neurons, forcing the model to learn a compact input data representation [155]. The encoder network maps the input X to a latent representation H using an encoding function, fe. The decoder network then reconstructs the original input, X', from H using a decoding function, ge, as described in Equation 15 [153].\n$H = f_{\\theta}(X) = s(WX + b)$\n$X' = g_{\\theta}(H) = s(W'H + b')$\n(15)\nwhere s is a non-linear activation function such as sigmoid or ReLU. W and W' represent the weight matrices, while b and b' denote the bias vectors. The autoencoder adjusts these weights and biases during training to minimize the reconstruction error explained in Equation 16 [156].\n$\\min J_{AE} (\\theta) = \\min_{\\theta} \\frac{1}{n} \\sum_{i=1}^{n} l (x_{i}, x') = \\min_{\\theta} \\frac{1}{n} \\sum_{i=1}^{n} l (x_{i}, g_{\\theta} (f_{\\theta} (x_{i}))) $\n(16)\nwhere xi and x' denote, respectively, the i-th dimension of the input data and its reconstructed output. The parameter n represents the total number of samples in the training dataset. The term l signifies the reconstruction error between the original and reconstructed data, previously defined in Equation 10. Stacked AE (SAE) enhance the capability of traditional AE by stacking multiple encoding and decoding layers. This layer-wise approach allows for deeper networks, improving"}, {"title": "3) Generative Adversarial Networks", "content": "GANs are a powerful class of machine learning models that facilitate unsupervised learning by generating synthetic data closely resembling real- world data [124]. At the core of GANs are two neural networks: the Generator and the Discriminator [172]. The Gen- erator creates artificial data, while the Discriminator evaluates whether it is real or fake, based on its resemblance to real samples [173]. Through a competitive process, in which the Generator continuously improves its ability to create realistic data, and the Discriminator refines its ability to distinguish real from fake, the two networks engage in a dynamic adver- sarial game [174]. Over time, this iterative learning process allows the Generator to produce compelling outputs, often indistinguishable from real data. GANs have been successfully applied to various domains, including image generation [175], super-resolution [176], denoising [177], and image-to-image translation [178]. The basic architecture of a standard GAN is illustrated in Figure 9.\nThe loss function used for the Discriminator is derived from the binary cross-entropy formula, which is formulated in equation 17 [179].\n$L(\\widehat{y}, y) = - [y \\cdot log(\\widehat{y}) + (1 - y) \\cdot log(1 - \\widehat{y})]$\n(17)\nwhere y and \u0177 correspond to the original and fake data, respectively.\nIn the training of D, the real data \u00b5(x) is assigned a label y = 1 (real data), and the output of the Discriminator for real data is \u0177 = D(x). \u00b5 denotes the true, real data distribution from which the training dataset is sampled. Substituting this into Equation 17, we get the loss defined in Equation 18.\n$L(D(x), 1) = log(D(x))$\n(18)\nFor data sampled from G, the assigned label is y = 0 (fake data), and the predicted output is given as \u0177 = D(G(z)). By substituting these values into Equation 17, the resulting expression is defined in Equation 19.\n$L(D(G(z)), 0) = log(1 - D(G(z)))$\n(19)\nThe discriminator's objective is to classify its input accurately as either fake or real. Consequently, the associated loss func- tions for G and D must be optimized. The final loss function of D is expressed in Equation 20.\n$L^{(D)} = max[log(D(x)) + log(1 - D(G(z)))]$\n(20)\nThe generator's objective is to compete against the discrimi- nator by minimizing the optimization problem. Accordingly, the generator's loss function is formulated in Equation 21.\n$L^{(G)} = min[log(D(x)) + log(1 - D(G(z)))]$\n(21)\nBy combining the loss functions of the generator and discrim- inator, we can frame the optimization as a min-max problem. This is expressed in Equation 22.\n$L = \\min_{G} \\max_{D} [log(D(x)) + log(1 - D(G(z)))]$\n(22)"}, {"title": "4) Vision Transformes", "content": "Transformer-based models were initially developed for natural language processing to model sequential dependencies through self-attention mech- anisms [189], achieving remarkable success in tasks like machine translation and text generation [190]. This success inspired [191] to adapt Transformers to CV, proposing the Vision Transformers (ViTs), which redefined feature extraction in image tasks [139], [192]. In ViTs, images are split into fixed-sized patches, flattened into vectors, and passed through a linear projection to create patch embeddings. Positional embeddings have been added to retain spatial information. The embeddings are processed through a Transformer encoder, consisting of multi-head attention and feed-forward layers, with skip connections and LayerNorm to ensure stability. A final MLP Head maps the output to predictions. When trained on large datasets like JFT-300M [193], ViT outperformed convolutional architectures like ResNets [194].\nIn a self-attention layer, the input vector X is initially trans- formed into three distinct vectors: the query vector (Q), the key vector (K), and the value vector (V). These vectors are of fixed dimensions and are generated by multiplying the input with corresponding learnable weight matrices, denoted as WQ, WK, and Wv. Mathematically, this process is expressed as in Equation 24.\n$Q = W_{Q}X, K=W_{K}X, V = W_{V}X$\n(24)\nwhere WQ, WK, and Wv are learnable parameters.\nOnce these vectors are obtained, the scaled dot-product atten- tion mechanism is applied to compute the attention scores, as shown in Equation 25.\n$Attention(Q, K, V) = Softmax(\\frac{QK^{T}}{\\sqrt{d_{k}}})V$\n(25)\nwhere dk represents the dimensionality of the key vector, and its square root is used to improve gradient stability. The Softmax function normalizes the attention weights and converts them into a probability distribution.\nWhile a single self-attention mechanism effectively models dependencies between token entities, it may lack the capacity to capture complex relationships from diverse perspectives. To address this limitation, the multi-head self-attention mech- anism (Figure 12 (b)) was introduced by [189]. It allows the model to attend to the information from multiple repre- sentation sub-spaces jointly. Mathematically, this process is expressed as in equation 26.\n$MultiHead(Q, K, V) = Concat(head_{1}, ..., head_{h})W^{O}$\n$head_{i} = Attention(QW^{Q}_{i}, KW^{K}_{i}, VW^{V}_{i})$\n(26)\nwhere WO denotes a linear mapping function used to combine the multi-head representations. Here, h is a hyperparameter"}, {"title": "5) Recurrent Neural Networks", "content": "RNN are a class of super- vised machine learning models designed to process sequential or time-series data [150]. They incorporate feedback connec- tions that allow outputs from previous steps to be used as inputs for the current step [202]. This recurring process of utilizing feedback connections gives the network its name and helps it to retain information from past inputs through a hidden state [203]. At each time step t, an RNN processes an input vector xt and updates its hidden state ht, as shown in equation 27. The basic architecture of a standard RNN is illustrated in Figure 14.\n$h_{t} = \\sigma_{h} (W_{xh}x_{t} + W_{hh}h_{t-1} + b_{h})$,\n(27)\nwhere Wch is the weight matrix mapping the input to the hidden layer, Whh is the weight matrix representing the recurrent connection, bh is the bias term, and \u03c3h is the activation function, typically chosen as the hyperbolic tangent (tanh) or RELU [204], [205]. The output at time step t is computed according to equation 28.\n$y_{t} = \\sigma_{y} (W_{hy}h_{t} + b_{y})$,\n(28)\nwhere Why denotes the weight matrix connecting the hidden and output layers, by is the bias term for the output layer, and \u03c3y is the activation function applied at the output.\nRNNs have many variants that address their limitations and expand their capabilities. Long Short-Term Memory networks (LSTMs) [206] introduced gating mechanisms to overcome the vanishing gradient problem and better model long-term de- pendencies. Bidirectional LSTMs [207] process sequences in both forward and backward directions to capture context from past and future tokens. Stacked LSTMs [208] stack multiple"}, {"title": "B. Learning Algorithms", "content": "Various types of learning algorithms have been integrated into STF frameworks, and they are generally classified into four categories: supervised, unsupervised, self-supervised, and collaborative learning.\n1) Supervised Learning: Supervised learning involves training a model on labeled data, where the input data is paired with corresponding output labels [213]. In STF, this means that X2(s, ti) is known. Most approaches listed in IV rely on supervised learning.\n2) Unsupervised Learning: Unsupervised learning consists of training a model on input data without labels, where the algorithm must identify patterns within the data [213]. In STF,"}, {"title": "C. Training Strategy", "content": "Training strategies refer to the techniques used to enhance the performance of a neural network during the training process. These strategies are employed in STF methods and can be categorized into four main classes: Residual Learning, Attention mechanisms, Normalization, and Dropout.\n1) Residual Learning: Residual learning, first intro- duced [144] for image recognition tasks, is a technique de- signed to address the challenges of vanishing and exploding gradients in training deep neural networks. The idea behind residual learning is the introduction of skip connections, which directly add the input from a previous layer to the output of the current layer [215]. This allows the network to learn residual mappings, rather than the original function itself, which makes it easier for deep networks to converge during training and prevents degradation in performance as the network depth increases [216]. Mathematically, it can be defined as described in Equation 29.\n$F(x) := H(x) - x$\n(29)\nwhere H (x) is the desired underlying function, and F(x) is the residual mapping. Thus, the final output of a residual learning block is F(x) +x = H(x). In STF, residual learning is widely used to preserve important spatial and temporal features while reducing computational complexity [217]. Based on Table V, it is evident that residual learning is the most commonly adopted training strategy in STF methods. The extensive use of residual learning in various approaches highlights its importance in improving model convergence, preserving critical spatial and temporal features, and mitigating computational complexity.\n2) Attention Mechanism: Attention mechanisms in DL fo- cus on identifying and prioritizing the most relevant parts of the input for a specific task, as previously described in Section IV-A4. In STF, attention mechanisms have been applied in four levels: channel attention, spatial attention, temporal attention, and feature attention. Channel attention prioritizes specific spectral bands, but it is less applicable to LST data, which typically consists of a single band. Spatial attention focuses on identifying critical regions within the spatial domain. Temporal attention captures significant changes across time. Feature attention evaluates the importance of entire feature maps. As shown in Table V, all transformer-based STF methods incorporate spatial attention. This is expected, as transformers rely on attention mechanisms, with spatial attention central to capturing spatial relationships.\n3) Normalization: Normalization is a transformation ap- plied to ensure that data exhibits specific statistical prop- erties, which can enhance both the training efficiency and the generalization capability of DL [218]. In the literature, normalization typically encompasses five operations: center- ing, scaling, decorrelating, standardizing, and whitening [218]. For STF, five primary types of normalization are employed: Batch Normalization (BN), Group Normalization(GN), In- stance Normalization (IN), Spectral Normalization (SN), and Switchable Normalization (SwN). BN [219] operates over mini-batch inputs to mitigate issues such as internal covariate shift during backpropagation. Given a neuron activation a, BN standardizes the neuron across m mini-batch samples as defined in Equation 30.\n$\\widehat{a}^{(i)} = \\frac{a^{(i)} - \\mu}{\\sqrt{\\sigma^{2} + \\epsilon}}$\n(30)\nwhere \u03f5 > 0 prevents numerical instability, and \u00b5 and \u03c32 denote the mean and variance of the mini-batch, respectively. GN [220] divides neurons into predefined groups and stan- dardizes the activations within each group for individual samples. IN [221] normalizes each image individually, remov- ing instance-specific contrast information. This is particularly beneficial in tasks like style transfer. SN [222] is primarily used in GANs. It stabilizes the training process of the discrim- inator by normalizing the spectral norm of weight matrices by controlling the Lipschitz constant of the model's layers. SwN [223] combines three types of statistics: channel-wise, layer-wise, and mini-batch-wise. Table V classifies each DL- based method into its respective normalization category.\n4) Dropout : Dropout is a regularization method that helps reduce overfitting by randomly deactivating neurons of the neural network during training [224]. As presented in Table V, dropout in STF is not that much popular, with only five works applying it, but it's still an interesting research direction."}, {"title": "D. Incorporation of Pre-trained Models", "content": "DL models typically involve many parameters, which can lead to overfitting when trained on small datasets, and result in poor generalization [225]. Many DL tasks are also interrelated, making pre-train models on other datasets beneficial [226]. The effectiveness of pretraining was first demonstrated in the field of CV by [142].\nPretraining offers a promising solution for STF methods by addressing three challenges. First, STF-specific data is often limited. This is due to the acquisition of pairs of coarse and fine resolution images captured simultaneously for the same region. This requirement for temporal and spatial alignment reduces the number of available pairs significantly, as both datasets must overlap in time and coverage. For instance, the CIA dataset includes only 17 pairs, while the LGC dataset contains just 14 pairs [148]. Furthermore, external factors, such as weather conditions, can introduce inconsistencies, further complicating data distribution and reducing the amount"}, {"title": "V. EXPERIMENT STUDY", "content": "A. Dataset\nThe open-source code to generate the dataset is available on GitHub\u00b2. Please note that you must first authenticate via GEE to download it.\n1) Study Area: The study area is Orl\u00e9ans M\u00e9tropole (Figure 15)", "retrevial": "In this study", "datasets": "MODIS/Terra LST and Emissivity Daily Global 1-km (MOD11A1, Collection 6) for coarse-resolution LST data, and Landsat"}]}