{"title": "End-Cloud Collaboration Framework for Advanced AI Customer Service in E-commerce", "authors": ["Liangyu Teng", "Yang Liu", "Jing Liu", "Liang Song"], "abstract": "In recent years, the e-commerce industry has seen a rapid increase in the demand for advanced AI-driven customer service solutions. Traditional cloud-based models face limitations in terms of latency, personalized services, and privacy concerns. Furthermore, end devices often lack the computational resources to deploy large AI models effectively. In this paper, we propose an innovative End-Cloud Collaboration (ECC) framework for advanced Al customer service in e-commerce. This framework integrates the advantages of large cloud models and mid/small-sized end models by deeply exploring the generalization potential of cloud models and effectively utilizing the computing power resources of terminal chips, alleviating the strain on computing resources to some extent. Specifically, the large cloud model acts as a teacher, guiding and promoting the learning of the end model, which significantly reduces the end model's reliance on large-scale, high-quality data and thereby addresses the data bottleneck in traditional end model training, offering a new paradigm for the rapid deployment of industry applications. Additionally, we introduce an online evolutive learning strategy that enables the end model to continuously iterate and upgrade based on guidance from the cloud model and real-time user feedback. This strategy ensures that the model can flexibly adapt to the rapid changes in application scenarios while avoiding the uploading of sensitive information by performing local fine-tuning, achieving the dual goals of privacy protection and personalized service. To conclude, we implement in-depth corpus collection (e.g., data organization, cleaning, and preprocessing) and train an ECC-based industry-specific model for e-commerce customer service. Our ECC framework not only improves the response efficiency and service quality but also establishes a practical benchmark for customer service model development.", "sections": [{"title": "I. INTRODUCTION", "content": "Deep learning is an effective techique widely used in the field of Artificial Intelligence (AI) [1]. By introducing multiple layers of neural networks, deep learning has been able to capture high-level abstractions in data and has been applied to various field including computer vision [2], natural language processing and so on [3]. In recent years, with the advent of Large Language Models (LLMs) such as GPT- 3 [4], Gemini [5], ChatGLM [6] and GPT-4 [7], scaling laws [8] have become increasingly evident, demonstrating that as model parameters scale up, both the performance and generalization abilities of the models significantly improve. The trend of increasingly powerful comprehensive capabilities of models has catalyzed extensive utilization of these models in research across diverse industries including manufacturing [9], education [10], healthcare [11], and finance [12].\nThe e-commerce domain is an important application sce- nario for LLMs [13]. Well-trained e-commerce LLMs can act as intelligent customer service systems, offering person- alized services that enhance customer satisfaction and drive sales. These systems provide round-the-clock support, rapid responses, and cost-efficiency. As a result, the use of LLMs in e-commerce customer service has become a research hotspot.\nLeveraging LLMs for customer service in e-commerce has emerged as a novel application due to their powerful generalization capabilities and extensive knowledge. However, this approach faces challenges. According to [14], LLMs' human-like text generation arises from emergent abilities re- quiring large model sizes, leading to significant computational costs. Mainstream models, with billions to trillions of parame- ters, demand extensive computational resources. For instance, training GPT-4 costs over 10 million USD and requires more than 10,000 high-performance GPUs, making it impractical to train and deploy on end devices. Additionally, general LLMs lack specialized domain data, hindering their direct application in certain domains. Increasing parameter counts also heighten security and privacy risks due to immature understanding of LLM mechanisms.\nTo address the aforementioned problems, it is necessary to fundamentally shift the technical approach of LLMs by integrating them with terminals. The End-Cloud Collaboration (ECC) technology [15] offers a new perspective for research in the field of LLMs, becoming a new paradigm for large model applications on the end. In this paradigm, end models can accurately understand user needs and provide timely, personalized responses. Meanwhile, the large models in the cloud are adept at handling complex problems, taking over when end models are unable to perform complex tasks, thus meeting users' deeper needs.\nThis paper constructs an ECC framework for Chinese e- commerce customer service, leveraging large cloud models to train mid/small-sized end models. We use the Gemini 1.5"}, {"title": "II. RELATED WORK", "content": "Edge computing addresses cloud computing's limitations in latency, bandwidth, and privacy by moving computation closer to the data source, thus reducing latency and band- width needs. However, it also faces constraints like limited computational resources and storage. To address these limita- tions, researchers have proposed the concept of edge-cloud collaboration [19], [20], which combines the strengths of both to create a more efficient and scalable platform. This paper adapts this concept to focus on end devices and cloud computing, termed end-cloud collaboration, leveraging the computational resources of both to enable real-time, efficient, and secure AI applications.\nA classical example of edge-cloud collaboration is Fed- erated Learning (FL) [21]. Through FL, end devices can learn from each other and improve the global model with- out compromising data privacy. End-cloud collaboration has been shown to be effective in improving the performance of machine learning models and reducing the danger of data leakage."}, {"title": "B. Large Language Models", "content": "Large Language Models (LLMs) have been shown to achieve state-of-the-art performance on a wide range of natural language processing tasks, such as text generation and machine translation. LLMs are typically trained on large amounts of text data using unsupervised learning techniques, such as autoregressive language modeling and masked lan- guage modeling.\nNowadays, the most popular LLMs are based on Trans- former [22], which uses self-attention mechanisms to capture"}, {"title": "C. Fine-tuning Technicals", "content": "In the field of natural language processing, the current mainstream paradigm is to pre-train LLMs on large-scale text corpora and then fine-tune them on specific tasks using supervised learning techniques. Fine-tuning involves training a pre-trained language model on a specific dataset to improve its performance on a specific task. Compared with the pre-trained model without fine-tuning, the fine-tuned model can achieve better performance on the specific task [24].\nThe traditional approach of fine-tuning, also known as full fine-tuning, is to train the entire model on the specific dataset. This approach requires training and storing a separate model for each task, leading to high computational costs, large storage requirements, and a significant need for labeled data. To address these challenges, researchers have proposed Parameter-Efficient Fine-tuning Techniques (PEFT), which aim to improve the performance of LLMs on specific tasks using a smaller dataset and fewer computational resources [25]. Methods such as Prefix-Tuning [16], P-Tuning-v2 [17], and LoRA [18] are examples of PEFT techniques."}, {"title": "III. END-CLOUD COLLABORATION FRAMEWORK FOR ADVANCED E-COMMERCE CUSTOMER SERVICE MODEL", "content": "In this paper, we design and implement an innovative ECC framework that leverages the power of cloud LLMs (in our experiment, we choose Gemini 1.5 pro) and the flexibility of the lightweight mid/small-sized model (e.g., ChatGLM3-6B) to jointly build an efficient and responsive AI IoT solution. This framework enhances interaction between the end and cloud, improving service intelligence and data processing efficiency.\nThe large model in the cloud serves as the knowledge center and data processing engine, extracting abstract knowledge from vast amounts of data to generate high-quality datasets for specific tasks. The mid/small-sized end model, deployed locally, is trained by both a natural dataset and the generated dataset. It provides real-time interaction and service execution, optimizing based on user feedback and cloud guidance.\nAs shown in Fig. 1, the ECC framework consists of two main components: the cloud model, the end model. The cloud model is responsible for generating high-quality datasets and supervisory information for the end model. The end model is responsible for real-time interaction with users and providing personalized services. During the training phase, the cloud model generates high-quality datasets, which are used to train the end model. During the inference phase, the end model interacts with users in real-time and provides personalized services based on the training results."}, {"title": "IV. EXPERIMENT", "content": "We mainly used two datasets, Taobao and Jing Dong e- commerce conversation datasets respectively. Taobao and Jing Dong are the two largest e-commerce platforms in China, and their conversation datasets are widely used in the field of Chinese e-commerce customer service.\nTaobao E-commerce Dialogue Corpus (ECD) [28] consists of 1 million session-response pairs for training, 10,000 pairs for validation, and 10,000 pairs for testing. Similar to ECD, Jing Dong Dialogue Corpus (JDDC) [29] is also a widely used Chinese e-commerce conversation dataset with more than 1 million multi-turn dialogues, 20 million utterances, and 150 million words, which contains conversations about after-sales topics between users and customer service staffs in E-commerce scenario.\nTable I shows an example of a dialogue in the ECD after preprocessing and translating to English. It demonstrates the characteristics of briefness and colloquial language typical in e-commerce domain dialogues.\nBesides, we also use the cloud model, Gemini 1.5 pro, to generate a high-quality dataset for training the end model. We"}, {"title": "V. CONCLUSION", "content": "In this paper, we propose and implement an ECC frame- work and apply it in the field of e-commerce customer service. This framework successfully integrates the large language model Gemini 1.5 pro with the mid-sized model ChatGLM3- 6B, addressing the issues of traditional customer service's lack of personalized service and the difficulty of quickly adapting to market changes. The ECC framework leverages the strengths of both cloud-based and end-side models to create a highly flexible and efficient system.\nThe cloud model serves as the knowledge center and data processing engine, generating high-quality datasets optimized for specific tasks to ensure the accuracy and practicality of the outputs of the end model. It also serves as an evaluation criterion for the end-side model by comparing the similarity between the output of the end model and the output text of the cloud model. The end-side model, on the other hand, acts as a fast-responding intelligent agent and is deployed on local devices to perform real-time computations. It is trained using both natural datasets and the datasets generated by the cloud model. This model focuses on real-time interaction and service execution, adapting and optimizing its performance based on user feedback and guidance from the cloud model, i.e., a method of constantly fine-tuning itself using the output data from the cloud model as labels when users are dissatisfied with the response from the end-side model, thus enhancing the level of personalized service. Through this mechanism, we achieves online evolutive learning of the end model and promotes the intelligent upgrading of e-commerce customer service systems.\nThe ECC framework not only improves response speed and personalization in customer service but also ensures that sensitive data is processed locally on end devices. This design significantly reduces security risks and privacy issues during data transmission, enhancing data security and privacy protection.\nIn conclusion, the ECC framework not only enhances the efficiency and responsiveness of e-commerce customer service but also sets the stage for future advancements in AI-driven customer service systems. Future work will focus on further optimizing the ECC framework, exploring its application in other domains such as healthcare, finance, and education, and enhancing its adaptability to a wider range of business scenarios. We anticipate that the ECC framework will play a pivotal role in the evolution of intelligent customer service systems, fostering innovation and improving user satisfaction across various industries, including potential advancements in multimodal capabilities and multi-agent systems, thereby further enriching the customer service landscape."}]}