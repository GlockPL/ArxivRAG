{"title": "Can LLMs Obfuscate Code? A Systematic Analysis of Large Language Models into Assembly Code Obfuscation", "authors": ["Seyedreza Mohseni", "Seyedali Mohammadi", "Deepa Tilwani", "Yash Saxena", "Gerald Ndwula", "Sriram Vema", "Edward Raff", "Manas Gaur"], "abstract": "Malware authors often employ code obfuscations to make their malware harder to detect. Existing tools for generating obfuscated code often require access to the original source code (e.g., C++ or Java), and adding new obfuscations is a non-trivial, labor-intensive process. In this study, we ask the following question: Can Large Language Models (LLMs) potentially generate a new obfuscated assembly code? If so, this poses a risk to anti-virus engines and potentially increases the flexibility of attackers to create new obfuscation patterns. We answer this in the affirmative by developing the METAMORPHASM benchmark comprising METAMORPHASM DATASET (MAD) along with three code obfuscation techniques: dead code, register substitution, and control flow change. The METAMORPHASM systematically evaluates the ability of LLMs to generate and analyze obfuscated code using MAD, which contains 328,200 obfuscated assembly code samples. We release this dataset and analyze the success rate of various LLMs (e.g., GPT-3.5/4, GPT-40-mini, Starcoder, CodeGemma, CodeLlama, CodeT5, and LLaMA 3.1) in generating obfuscated assembly code. The evaluation was performed using established information-theoretic metrics and manual human review to ensure correctness and provide the foundation for researchers to study and develop remediations to this risk. The source code can be found at the following GitHub link: https://github.com/mohammadi-ali/MetamorphASM.", "sections": [{"title": "Introduction", "content": "Writing metamorphic malware is non-trivial. It requires coding up multiple obfuscations, and it is a double-edged sword for malware delivery. Metamorphic malware is harder for Anti-Viruses to catch, but it also makes the malware larger because it needs to keep around the code for re-writing itself. Malware authors would generally prefer their programs to be smaller with less code so that they are not easily flagged in reporting or logging tools as something for Security Operations Center (SOC) analysts to investigate and thus discover the malware.\nLarge Language Models (LLMs) pose a new potential threat. Instead of including a large metamorphic code engine, they can simply call out over the internet to commercial LLMs to be rewritten one piece at a time. The code is far smaller since APIs for internet communication are built into and readily available on almost all operating systems. We find it important to evaluate such possibilities given the wide array of attack patterns in malware and the exist of a live and motivated adversary (Kolosnjaji et al. 2018; Biggio and Roli 2018; Demetrio et al. 2021; Biggio et al. 2014; Demontis et al. 2019).\nA web call out to a Microsoft or Google domain is also innocuous and a strategy employed by sophisticated malware when possible to make their traffic nearly impossible for SOC analysts to detect. Being smaller and obfuscated, the malware can potentially reap the benefit of metamorphic engines without the cons. Access to API keys is a minor hindrance in this case, as theft of API keys for malicious use is a common attack pattern often achieved by simply scraping GitHub repositories (Lehmann, Kinder, and Pradel 2020).\nAn important question, then, is how reliably can malware use these LLMs to re-write themselves. While a low error rate is tolerable as it imposes only minor opportunity cost to the attacker (they don't successfully propagate to a device, but may have another chance to get to the same device later) and prior work has shown malware execution can be surprisingly robust to random code corruption (Fleshman et al. 2018). We also wish to know if smaller local LLMs can perform this task, not because malware would use one (the size of the malware would explode and become obviously detectable in a log file), but it is important for security researchers to test locally what is achievable without being restricted to API calls that they may not have the budget for.\nFigure 1 presents a schematic of the architecture of the classic obfuscation engine method compared to the proposed obfuscation engine using an LLM. In the classic obfuscation engine, the components can be classified as follows: (a) Assembler/Disassembler: These components are responsible for converting binary code to assembly code or vice versa. (b) Configuration Unit: This unit provides necessary data to the code analyzer and obfuscator units to ensure efficient obfuscation. Typically, this unit is integrated within the mutation engine and supplies additional data to other units. (c) Code Analyzer: This unit enhances the reliability of the"}, {"title": "Background of Code Obfuscation Techniques", "content": "Mathematically, we can show obfuscation with this definition: Code obfuscator is defined as a function f that transforms original source code P into an obfuscated version of source code P'. Formally, this can be represented as $f : P \\rightarrow P'$. Where P is the space of all possible programs and P' is the space of all possible obfuscated programs.\nThe obfuscation function f must ensure that the obfuscated program P' behaves identically to the original program P for all inputs. So, we will have:\n$\\forall x \\in X P(x) \\sim P'(x)$\nWhere X represents the set of all possible inputs x for which P(x) and P'(x) have a valid outcome without any error.\nDead Code Insertion: In dead code insertion, malware inserts sections of code that are irrelevant to the program's normal operation. This technique can take various forms, such as adding redundant instructions, unused variables, or unreachable code branches. These additional code segments alter the structure and behavior of the malware without affecting its functionality, causing it to appear different each time it is executed. Consequently, traditional signature-based antivirus detection methods become less effective against metamorphic malware employing this technique.\nRegister Substitution: In this technique, the malware replaces register names used within its instructions with alternative register names. For example, if the original malware code uses the EAX register for a specific computation, the register substitution technique might replace instances of"}, {"title": "METAMORPHASM DATASET (MAD)", "content": "The MAD, consisting of generated assembly code snippets, is generated through a four-step process:\nStep 1. The source of assembly codes. The source code comes from the extraction and disassembling of a large number of Dynamic Link Library and Program Executable, which Microsoft provided for Windows users, specifically Windows 7 and Windows 8.1. We used Windows Dynamic Link Library and Executive files because most of the metamorphic victims in the past and present are Windows users, and malware uses many standard libraries of .Net for reshaping code. We also use many open-source x64-based real assembly files or static libraries to generate assembly files.\nStep 2. Code extraction and pre-processing. We use command prompt and open source software such as recompiling and disassembly tools to generate assembly code from original files. Most of the assembly code has a large section of data, which does not have a useful code for training LLMs. During the pre-processing step, we remove these sections and use only code sections to generate datasets. Another consideration for pre-processing is removing and purging near- and far-range JMPs or CALL instructions from the original code because all of these parameters are related to the local machines and temporary files, which causes a loss of generality concept during the training process of LLM. After cleaning up these large quantities of opcode, and after human evaluations and verification of large corpus, which took almost two months as full-time laboring, we break down this large corpus assembly code into small snippet assembly, each typically comprising twenty instructions. These snippets were then stored.\nStep 3. Obfuscating assembly codes. After generating the clean assembly code snippets, the next step is to obfuscate each snippet using specific Python scripts. These scripts are designed to create three separate databases, each corresponding to a different obfuscation technique: dead code insertion, register substitution, and code flow alteration. To insert dead code, we use a dictionary of nearly 40 assembly instructions that do not affect the code's functionality but alter its structure. The script randomly inserts these \u201cneutral assembly instructions\u201d and saves the output in a Python dictionary as key-value pairs. For the code flow alteration dataset, the script reads each entry from the original database (created in step 2) and randomly rearranges parts of the code to obfuscate the original assembly snippet, then saves the result in the code flow change database. The final register substitution database involves reading the original database and randomly renaming specific registers (e.g., EAX, EBX, or ECX) by swapping them with other unused registers, with the results saved in the register dataset. By merging these three data into one unified MAD dataset.\nStep 4. Final validations and verification. The original code and the obfuscated code generated by three techniques is manually evaluated by human experts who have more than twenty years of experience in assembly and machine code"}, {"title": "Models and Evaluation", "content": "Models: We conducted the benchmarking of METAMORPHASM utilizing a diverse array of large language models (LLMs), which we categorized into open source (o) and proprietary (p) types, further divided into a mixture of experts (MoE) and non-mixture of experts (n-MoE) models. Access to proprietary LLMs was facilitated through APIs, which are computationally demanding and financially expensive. Therefore, we selected 15,000 assembly code samples - 5,000 per obfuscation mechanism - to ensure a fair and reasonable comparison - from our extensive repository of 300,000 examples. For our proprietary LLM evaluations, we included the GPT-40-mini (p) (Achiam et al. 2023), an MoE model adept at handling complex assembly code patterns (OpenAI 2024). Competing against GPT-40-mini, we employed the open-source DeepSeekCoder-v2 (o; 236B; MoE model)(Zhu et al. 2024) and Codestral (MistralAI 2024) (0; 22B; n-MoE model), both of which have undergone extensive training on assembly codes and are proficient in generating such codes. Considering their established effectiveness in advanced coding tasks, CodeLLAMA (0; 34B) (Roziere et al. 2023) and LLAMA 3.1(MetaAI 2024) (p; 405B; n-MoE) were also included in our benchmarking process. Lastly, CodeGemma (0; 7B)(Team 2024) and the trainable CodeT5 (0; 1.2B) (Wang et al. 2021) were considered models suitable for conducting future white box studies into obfuscation using LLMs. Except for CodeT5, all the LLMs were subjected to examination using zero-shot prompting (see Tables 1, 2, 3 for zero-shot prompting template) and in-context learning, with test setups including 1, 3, 5, 10, and 15 shots (see Table 4 for few shot prompting template).\nEvaluation\nTo measure the obfuscation level, we consider two metrics. First, we compute the character-wise Delta Entropy (\u0394), which is a derived measure from Shannon Entropy. Analysts commonly use this measure as a first-pass analysis, with original code and obfuscated code. In the context of code obfuscation, it quantifies the complexity and diversity"}, {"title": "Results and Discussion", "content": "Interpretation: The MAD includes both original and obfuscated code, with an expected delta entropy range of around 10%-20%. This range is crucial for defining an effective obfuscation engine; a delta entropy exceeding this range risks altering the code's functionality, while a value below 10 percent indicates minimal obfuscation. The range was defined after three human experts examined the code obfuscation from eight LLMs and picked GPT-40-mini as the closest to human-performed code obfuscation (see Table 8). Additionally, maintaining a cosine similarity above 0.9 is essential, as it confirms the preservation of functional similarity between the original and obfuscated code, thereby serving as a measure of the obfuscation's success in maintaining the code's integrity without compromising its functionality. The threshold for cosine similarity was set following human evaluation, where experts reviewed the top three LLMs across three obfuscation techniques. We calculated the cosine similarity between the original and obfuscated code produced by top-3 LLMs, achieving an average of 0.9.\nDiscussion: In a comparative analysis of general-purpose LLMS, LLAMA 3.1 exhibits notably underperformed, especially in control flow change techniques, where it only achieves a 4.27% entropy rate in single-shot scenarios, highlighting its inadequate code mutation capabilities. In more complex tasks requiring 10 to 15 shots, LLAMA 3.1 fails to generate any valid assembly instructions and demonstrates considerable variability in cosine similarity, deviating from the expected range of 0.90 to 0.97. In contrast, GPT-40-mini demonstrates robust performance across both entropy and cosine similarity metrics, excelling particularly in control flow change obfuscation with high entropy due to the insertion of numerous JMP and Section commands. Following closely, dead code insertion shows commendable results, and register substitution ranks third, indicating lower entropy typically associated with changes in one or two register names. Although GPT-3.5 outperforms LLAMA 3.1, it slightly trails GPT-40-mini but maintains a cosine similarity within the desired range of 0.90 to 0.97.\nCodestral stands out among specialized large language models for its effective performance in dead code and control flow change tasks, with cosine similarity values ranging from 0.90 to 0.98 (see Tables 5, 7). However, it struggles with register substitution, indicating difficulties in modifying register names effectively Table 6. DeepSeekCoder follows with higher performance, reflected in its elevated cosine similarity scores. These suggest that it accurately replicates the original assembly code, hinting at its specialized training in assembly language, making it a proficient ob-"}, {"title": "Related Work", "content": "Numerous classical software obfuscation techniques have been developed to safeguard against software tampering and reverse engineering, thereby preventing unauthorized access to source codes (Nagra and Collberg 2009; Hosseinzadeh et al. 2018; Xu et al. 2020; Ahire and Abraham 2020). Tools such as LOKI and OBFUS reflect practical applications of these methodologies (Schloegel et al. 2022; Kang et al. 2021). The LLVM (Low-Level Virtual Machine) is particularly notable for its flexibility and extensibility in both obfuscation and de-obfuscation, commonly employing techniques like control flow alteration and dead code insertion (Junod et al. 2015; Garba and Favaro 2019). This study extends existing research by examining the potential of LLMs to develop obfuscation engines (Gupta et al. 2023). While much of the existing research in this field concentrates on detection and defense, this effort focuses on utilizing LLMs trained in high-level programming languages, which are traditionally easier for experts to manage and understand (Muennighoff et al. 2023). However, training these models presents significant challenges due to the syntactic diversity and complexity of programming paradigms, requiring substantial resources (Hou et al. 2023). Our dataset and trained models can test the robustness and reliability of traditional and LLM-based detection systems. MAD enables studying other challenges in malware dataset construction, such as lack of diversity, data augmentation, and availability (Saul et al. 2024; Liu et al. 2024; Joyce et al. 2023b,a; Patel et al. 2023) but are beyond the scope of this article."}, {"title": "Conclusion", "content": "In this work, we provide MAD, which is a dataset for assembly code obfuscation for prompting and in-context learning of the LLM. Our dataset can obfuscate snippets assembly code by applying three major obfuscation techniques: a) inserting dead instructions code, b) register substitution, and c) changing control flow. For the purpose of demonstrating the trainability and reliability of our dataset, we tested our dataset by pre-training and prompting a couple of well-known models, such as the GPT family, CodeLLAMA, CodeGemma, Starcoder, Codestral, and DeepSeekCoder-v2. We also fine-tuned CodeT5 on our dataset, leveraging its open-source nature and transparent, white-box architecture. In order to measure the performance of models, we used Cosine similarity and Shannon entropy to measure the level of obfuscation between the original code and the generated code by the models. As shown in this paper, surprisingly, the GPT family (which is not a special coder LLM) has outstanding performance for obfuscation assembly code over even specialized coder LLM such as DeepSeekCoder-v2, Codestral, CodeLLAMA, CodeGemma, and Starcoder. The experiments demonstrated that even the pre-trained models show high performance on the obfuscation task, but it does not necessarily lead to high grounding performance, and GPT is still dominant."}]}