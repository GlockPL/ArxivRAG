{"title": "Med-gte-hybrid: A contextual embedding\ntransformer model for extracting actionable\ninformation from clinical texts", "authors": ["Aditya Kumar", "Simon Rauch", "Mario Cypko", "Oliver Amft"], "abstract": "Abstract - We introduce a novel contextual embedding\nmodel med-gte-hybrid that was derived from the gte-large\nsentence transformer to extract information from unstruc-\ntured clinical narratives. Our model tuning strategy for med-\ngte-hybrid combines contrastive learning and a denois-\ning autoencoder. To evaluate the performance of med-gte-\nhybrid, we investigate several clinical prediction tasks in\nlarge patient cohorts extracted from the MIMIC-IV dataset,\nincluding Chronic Kidney Disease (CKD) patient prognosis,\nestimated glomerular filtration rate (eGFR) prediction, and\npatient mortality prediction. Furthermore, we demonstrate\nthat the med-gte-hybrid model improves patient stratifica-\ntion, clustering, and text retrieval, thus outperforms current\nstate-of-the-art models on the Massive Text Embedding\nBenchmark (MTEB). While some of our evaluations focus\non CKD, our hybrid tuning of sentence transformers could\nbe transferred to other medical domains and has the poten-\ntial to improve clinical decision-making and personalised\ntreatment pathways in various healthcare applications.\n\nIndex Terms- Chronic kidney disease, sentence trans-\nformers, contrastive learning, prognostic modelling, mor-\ntality risk prediction, eGFR prediction, unstructured clinical\ndata, embedding models, patient stratification, information\nretrieval, digital medicine, healthcare Al", "sections": [{"title": "I. INTRODUCTION", "content": "Besides structured data, patient care information in Elec-\ntronic Health Records (EHRs) comprises data in unstructured\nform (i.e., clinical notes). While EHR information may overlap\nbetween structured and unstructured sections, some crucial\ninformation remains only in the unstructured sections [1]\u2013\n[5]. Relevant information for clinical decisions can easily be\noverlooked when dealing with large amounts of notes. Previ-\nous investigations have already found that clinical text alone\ncan often provide sufficient information for decisions [2], [6],\n[7]. However, extracting actionable information from clinical\ntext remains difficult due to language variability, inconsis-\ntent use of medical terminology, and lack of standardised\nformatting [8]. In addition, the lack of structure introduces\nambiguities and inconsistencies in the text. Thus, it is still\ndifficult to accurately interpret and analyse clinical notes for\ndecision support systems. As a result, the development of\nadvanced natural language processing (NLP) models that can\nextract and represent information from clinical narrative has\nbecome a focal point of research in digital medicine [2], [9],\n[10].\n\nContextual embedding models have emerged as a powerful\ntool for transforming unstructured texts into dense vector\nrepresentations to encode rich semantic information [11],\n[12]. However, existing models often struggle with lengthy\nand complex medical documents. The issue is particularly\npressing given the increasing volume of clinical data and the\nneed for accurate information retrieval [13]. Current domain-\nspecific embedding models, including ClinicalBERT [14] and\nBioBERT [15], have demonstrated effectiveness in specific\nclinical applications, but tend to lag behind generalist models\nin handling tasks, including semantic text similarity analy-\nsis [16], [17]. Notably, generalist models often outperform\ntheir clinical counterparts because of their broader exposure to\nvarious language contexts, resulting in enhanced understanding\nand retrieval capabilities [16]\u2013[18]. However, a limitation of\ngeneralist models is their inability to effectively understand\nand process specialised medical terminology [17]. In particu-\nlar, the precise meaning of medical text can vary profoundly\ndepending on its context, which can lead to semantic misrep-\nresentations. Consequently, the absence of a domain-specific\nmodel that is explicitly designed to process long-context tasks\nis an open challenge in the clinical domain.\n\nOur work introduces a clinically specialised sentence trans-\nformer, termed med-gte-hybrid, designed for long-context\ntasks within the clinical domain (see Fig. 1). The model is\nbased on gte-large 1 sentence transformer, an extension of\nthe gte model [19]. For the gte-large model, self-supervised\nfine-tuning strategies have already been investigated. Here we\ncombine for the first time, Simple Contrastive Learning (Sim-\nCSE) [20] and Transfomer-based Sequential Denoising Auto-\nEncoder (TSDAE) [21] to fine-tune the gte-large generalist\nmodel and derive the hybrid model med-gte-hybrid.With med-\ngte-hybrid, we aim to overcome the limitations of existing\ncontextual embedding models, especially for long-context\ntasks in the clinical domain. This work makes the following\ncontributions:\n\n1) We propose a novel, specialised sentence transformer\nmed-gte-hybrid that combines contrastive learning (Sim-"}, {"title": "II. RELATED WORKS", "content": "Embedding models can be broadly classified into generalist\nmodels and domain-specific models. Popular generalist models\ninclude Bidirectional Encoder Representations from Trans-\nformers (BERT) [12], numerous variations of BERT [22]-\n[24], Jina embeddings [25], and Big Bird [26]. Generalist\nmodels are trained on diverse, large-scale datasets and are\ncapable of handling a wide range of tasks across various do-\nmains. In contrast, domain-specific models, including clinical\nembedding models, are fine-tuned or trained on specialised\ndatasets, enabling them to capture the semantic and contextual\nintricacies of domain-specific language, for example medical\nterminology in healthcare. Popular variations of BERT and\nBigBird are ClinicalBERT [14], BioBERT [15], PubMed-\nBERT [27], Med-BERT [28], Clinical-Longformer [29], and\nClinical-BigBird [30]. Med-BERT is designed for structured\nEHR. One major limitation of existing clinical models is their\ninsufficient ability to process and understand the nuances of\nlonger clinical texts (i.e. exceeding 2000 tokens). Many current\nmodels were developed primarily with shorter contexts in\nmind, and therefore struggle to maintain context over extended\npassages. Understanding patient reports is critical in healthcare\nsettings, where detailed patient information is essential [31],\n[32].\n\nIn addition to the scope of training data used, embedding\nmodels can be further distinguished into word-embedding\nmodels and sentence transformers. Word embeddings cap-\nture the meaning of individual tokens by encoding them\nas dense vectors in a continuous space [10], [33]. In con-\ntrast, sentence transformers can handle multiple sentences at"}, {"title": "III. METHODS", "content": "We attempt to balance computational efficiency, general-\nization, and performance, by focusing on models with 250-\n500 million parameters and an embedding dimension of 1024.\nModels in the above size range have sufficient complexity to\ncapture relevant clinical features, while avoiding the computa-\ntional overhead associated with larger models [43]. We focused\non top-ranked state-of-the-art generalist models of the Massive\nText Embedding Benchmark (MTEB) leaderboard on Hugging\nFace\u00b2. MTEB [44] provides a standardised comparison for\nembedding models across various tasks. We examined the top\nfour public models as of June 2024: bge-large, uae-large-v1,\nmxbai-large-v1, and gte-large, all of which had demonstrated\nto scale across a range of tasks, including classification,\nclustering, retrieval, and semantic textual similarity. The gte-\nlarge model performed best and hence was selected as base\nmodel for fine-tuning on clinical texts."}, {"title": "B. Model fine-tuning", "content": "Traditional supervised learning methods are often not prac-\ntical for fine-tuning due to a lack of labels and the amount\nof data needed. While supervised learning is used for specific\nclassification tasks, the resulting fine-tuned model may not\ngeneralise across the text domain [45]. Domain adaptation\nusing supervised fine-tuning is typically done for datasets with\nwell-defined semantic structures [46]. In the present work,\nwe employed two self-supervised approaches for fine-tuning,\nnamely SimCSE and TSDAE.\n\na) SimCSE: SimCSE is an effective framework for self-\nsupervised contrastive learning from unlabelled text corpora.\nThe key idea is to create positive and negative pairs from\nthe input sentences and use contrastive learning to train\nthe model. Given a set of sentences $S = {S_1, S_2, . . . , S_n}$,\nfor each sentence $s_i$, positive pairs are created by applying\ndropout during the encoding process twice, generating two\ndifferent embeddings for the same sentence, denoted as $z_i^{(1)}$\nand $z_i^{(2)}$, which form a positive pair. The intuition is that\ndespite the slight variation due to dropout, the model should\nlearn that the two embeddings represent the same semantic\nmeaning. For negative pairs, other sentences $s_j$ from the\ndataset ($i\\neq j$) are randomly sampled, and their embeddings\n$z_j$ are paired with $z_i^{(1)}$. Here, the intuition is that random\nsampling yields sentences of different meaning, thus repre-\nsenting meaningful examples of negative pairs. The model then\nuses InfoNCE loss [47], to maximise the similarity of positive\npairs $sim(z_i^{(1)}, z_i^{(2)})$ and minimise similarity of negative pairs\n$sim(z_i, z_j)$, where $j \\neq i$. The loss for a single sentence $s_i$\nis expressed as:\n\n$L_i = -log\\frac{exp(sim(z_i^{(1)},z_i^{(2)})/\\tau)}{\\sum_j exp(sim(z_i^{(1)},z_j)/\\tau)}$\n\nwhere $\\tau$ is a parameter controlling the sharpness of the\ndistribution. The model is trained by minimising the total con-\ntrastive loss across all sentences $L = \\sum_i L_i$, where it learns\nto pull the embeddings of positive pairs closer together while\npushing the embeddings of negative pairs further apart. The\nprocess enhances the quality of sentence representations, thus\nallowing the model to better capture semantic similarities and\ndifferences. In summary, SimCSE adapts pre-trained models to\nthe specific characteristics of the text in the training data and\nenables them to generate versatile embeddings for different\ntasks.\n\nb) TSDAE: TSDAE is a sentence transformer training\nmethod for domain adaptation. The approach is to treat the\nembedding model like a denoising auto-encoder, training it to\nreconstruct corrupted sentences. The process starts with a set\nof sentences $S = {S_1, S_2, . . . , S_n}$. For each sentence $s_i$, a\ncorruption function is applied, typically removing or masking\na certain percentage of the words, resulting in a corrupted\nsentence $s_i^{corrupt}$. The model's task is to reconstruct the"}, {"title": "IV. EVALUATION AND CLINICAL PREDICTION TASKS", "content": "We utilised the MIMIC-IV v2.2 dataset [48] for both fine-\ntuning and evaluation purposes. For model fine-tuning, the\nMIMIC-IV-Note subset [49], comprising over 2 million un-\nstructured and unlabeled clinical notes, was utilised. Each note\nis associated with a unique patient and admission identifier to\nprecisely link to an individual patient and a specific hospital\nvisit. Clinical notes were recorded during standard patient care.\nIn a pre-processing step, we removed line breaks and special\ncharacters, including \"==\" and \"__\", which were used to mask\npersonal information. To segment texts into sentences, we\nused the sentence tokeniser of the nltk library 3. The sentence\ntokeniser identified abbreviations and other contextual clues\nto decide whether a period ends a sentence or not. Since\nclinical notes often do not follow rigid grammar rules, sentence\nfragments with less than five words were removed. The afore-\nmentioned pre-processing preserves the structure of clinical\nnotes and allows the sentence transformer models to generate\nrobust embeddings."}, {"title": "B. Evaluation data subset", "content": "We extracted two further data subsets from the MIMIC-\nIV database for evaluation: the CKD cohort and the mortality\ncohort. We labelled the patients, e.g., with eGFR values in the\nCKD subset. For CKD prognosis, a cohort of 3932 patients\ndiagnosed with CKD, amounting to 10,000 admission cases\nwas extracted. An example of the extracted data is shown in\nFig. 2. For mortality prediction, a separate cohort of 10,000\npatients was extracted.\nFurthermore, we employed non-MIMIC datasets to further\nevaluate performance across a variety of tasks. In particular,\nscientific medical and biomedical datasets from MTEB were\nused, which are similar to clinical notes in their use of medical\nterminology, but have a more rigid grammatical structure.\nIn particular, we used BIOSSES, MedrxivS2S, MedrxivP2P,\nPubHealthQA, and MedQA datasets. Additionally, the Mayo\ndataset [50], which is not part of MTEB, was used to provide\nan additional evaluation benchmark in the clinical domain."}, {"title": "C. Clinical prediction tasks", "content": "The capabilities of the med-gte-hybrid were explored across\nthree distinct clinical prediction tasks: CKD prognosis, eGFR\nprediction, and mortality prediction. CKD prognosis and eGFR\nare closely related, as eGFR serves as a key prognostic\nindicator of CKD progression. The first two tasks demonstrate\nthe dual capability of the med-gte-hybrid model in handling\nboth, classification (CKD prognosis) and regression (eGFR\nprediction) tasks. In the eGFR prediction task, we analysed\nwhether the model can infer eGFR values from clinical texts\nthat do not explicitly mention eGFR, i.e., testing the ability of\nthe model to capture contextual information. For the mortality\nprediction task, we included patients without CKD, to high-\nlight the model's robustness and versatility in handling diverse\nhealthcare prediction tasks. Furthermore, we investigated the\ncapability of med-gte-hybrid model to cluster relevant features\nand support patient stratification by grouping similar patient\nprofiles.\nAll clinical prediction tasks were evaluated using a 5-fold\ncross-validation with a stratified 80/20 train-test data split to\nmaintain consistent class imbalance across all folds. Besides\naverage performance, we report the standard deviation across\nfolds to interpret model stability. Furthermore, we compared"}, {"title": "D. MTEB evaluation", "content": "Two sentence similarity tasks were selected, which used\nMayo and BIOSSES datasets to evaluate the models' ability\nto measure semantic textual similarity between clinical sen-\ntence pairs. The performance for the aforementioned tasks\nare reported using Spearman's correlation between annotated\nand model-derived cosine similarities. Spearman's correlation"}, {"title": "E. Model inspection", "content": "To better understand the nature of the embeddings produced\nby our fine-tuned models, we examined the embedding space.\nWe applied UMAP to reduce the high-dimensional embedding\nvectors of each admission into a two-dimensional space for visualisation. Our aim was to investigate\nwhether the embedding space clusters relevant clinical features\nand exhibits discernible patterns. Additionally, we employed\nSHapley Additive exPlanations (SHAP) to analyse classifier\npredictions. With SHAP we could identify features (i.e. tokens\nand phrases) that influenced the classifier's output."}, {"title": "V. RESULTS", "content": "a) CKD prognosis task: Results of the CKD prognosis\ntask are shown in Fig. 3 (a,b). ClinicalBERT showed the\nlowest performance and was outperformed by the general\nembedding model gte-large with an Area Under the Receiver\nOperating Characteristic (AUROC) of 0.70 and an Area Under\nthe Precision Recall Curve (AUPRC) of 0.52. Med-gte-tsdae\nyielded a larger AUROC of 0.75 and AUPRC of 0.58. The\nSimCSE fine-tuned model further enhanced performance to\n0.81 and 0.67. Finally, med-gte-hybrid yielded the highest\nperformance with 0.84 and 0.74 for AUROC and AUPRC\nrespectively."}, {"title": "VI. CONCLUSION", "content": "We propose med-gte-hybrid, a specialised sentence trans-\nformer model tailored for the clinical domain. The med-gte-\nhybrid is designed to effectively handle long-context tasks and\nextract detailed narrative insights from clinical texts. Med-gte-\nhybrid consistently outperformed state-of-the-art embedding\nmodels and achieved the best overall performance in clinical\nprediction tasks, including CKD prognosis, eGFR prediction,\nand mortality prediction. Furthermore, our transformer fine-\ntuning approach enhanced patient stratification and facilitated\nthe clustering of similar clinical profiles. Clustering and SHAP\nanalyses confirmed the med-gte-hybrid model's ability to cap-\nture meaningful clinical narratives. Our findings highlight the\npotential of our clinical text fine-tuning approach to advance\nclinical decision support systems by integrating narrative-\nbased insights and long-context clinical data.\n\nVI. DATA AVAILABILITY STATEMENT\n\nMIMIC-IV version 2.2 is available under restricted access\ndue to privacy and ethical considerations. Access to the dataset\ncan be requested via the PhysioNet platform [64], where\napplicants must complete a data use agreement and fulfil\nnecessary requirements for access approval, including training\non human subjects research. For more information, or to\nrequest access, please visit: https://physionet.org/\ncontent/mimiciv/2.2/."}]}