{"title": "FedAlign: Federated Domain Generalization with Cross-Client Feature Alignment", "authors": ["Sunny Gupta", "Vinay Sutar", "Varunav Singh", "Amit Sethi"], "abstract": "Federated Learning (FL) offers a decentralized paradigm for collaborative model training without direct data sharing, yet it poses unique challenges for Domain Generalization (DG), including strict privacy constraints, non-i.i.d. local data, and limited domain diversity. We introduce FedAlign, a lightweight, privacy-preserving framework designed to enhance DG in federated settings by simultaneously increasing feature diversity and promoting domain invariance. First, a cross-client feature extension module broadens local domain representations through domain-invariant feature perturbation and selective cross-client feature transfer, allowing each client to safely access a richer domain space. Second, a dual-stage alignment module refines global feature learning by aligning both feature embeddings and predictions across clients, thereby distilling robust, domain-invariant features. By integrating these modules, our method achieves superior generalization to unseen domains while maintaining data privacy and operating with minimal computational and communication overhead.", "sections": [{"title": "Introduction", "content": "Conventional machine learning techniques are built on the assumption that training and test data are identically and independently distributed (IID). However, this assumption is often violated in real-world applications where models frequently encounter Out-of-Distribution (OOD) data, leading to significant performance degradation on unseen domains [Recht et al., 2019]. For instance, a model trained on cartoon images may fail to generalize to sketches due to domain shifts. Domain Generalization (DG) aims to address this limitation by equipping models with the ability to generalize effectively to unseen data distributions [Zhou et al., 2022].\nDespite the promise of DG, many existing approaches depend on centralized datasets, a condition that is infeasible in scenarios where data is distributed across multiple clients. Federated Learning (FL) [McMahan et al., 2017] provides a decentralized alternative by enabling collaborative model training without exposing raw data. However, integrating DG within FL poses unique challenges, including limited domain diversity at the client level and stringent privacy constraints inherent in decentralized environments.\nFederated Domain Generalization (FDG) focuses on learning domain-invariant features-label-relevant attributes that remain stable across diverse domains. Current FDG approaches predominantly employ two main strategies:\nThese methods use adversarial objectives to align representations [Micaelli and Storkey, 2019; Peng et al., 2019; Xu et al., 2023; Zhang et al., 2021], but they often incur high computational overhead and can suffer from training instabilities such as model collapse [Arjovsky et al., 2017].\nBy aligning features across clients, this line of work aims to mitigate domain discrepancies [Nguyen et al., 2022; Yao et al., 2022; Zhang et al., 2021]. However, limited domain diversity at the client level and strict privacy constraints can hinder alignment effectiveness at scale.\nAn alternative solution space involves Federated Style Transfer [Yang and Soatto, 2020; Yoon et al., 2021], which augments local data diversity via techniques like AdaIN [Huang and Belongie, 2017] and CycleGAN [Zhu et al., 2017]. While effective at generating domain-varied samples, these approaches often demand additional models for feature extraction and high-dimensional embedding exchanges, resulting in: Substantial communication overhead, Heightened privacy risks [Chen et al., 2023; Park et al., 2024], Limited improvements in domain-invariant feature learning.\nTo address these challenges, we propose FedAlign, a federated domain generalization framework:\nFedAlign introduces a novel feature-sharing mechanism that enriches each client's domain exposure without revealing raw data. This strategy perturbs domain-invariant features and redistributes them across clients in a privacy-preserving manner, broadening the effective training distribution while upholding confidentiality.\nA two-step alignment process ensures consistent performance across varied domains: Supervised Contrastive Loss encourages representations of samples with identical labels to converge, effectively reducing intra-class variance across domains. Jensen-Shannon Divergence enforces prediction consistency by aligning output distributions for both original and perturbed data, further bolstering out-of-distribution robustness.\nUnlike adversarial training or style transfer-based methods, FedAlign's lightweight feature-sharing mechanism imposes negligible additional overhead, making it well-suited for large-scale FL systems.\nBy focusing on privacy-preserving feature transfers and a dual-stage alignment of representations and predictions, FedAlign addresses the critical limitations of existing FDG methods specifically, the interplay of limited local data, insufficient domain diversity, and strict privacy constraints."}, {"title": "Related Work", "content": ""}, {"title": "Representation Alignment", "content": "Another prominent line of research in Domain Generalization (DG) focuses on representation alignment-reducing domain-specific variations by aligning feature distributions across multiple domains. Notable examples include:\nApproaches like DANN [Ganin and Lempitsky, 2015; Ganin et al., 2016; Gong et al., 2019] deploy a domain classifier to guide alignment, ensuring the extracted features are domain-invariant. By training the feature extractor and domain classifier in an adversarial manner, these methods successfully mitigate domain discrepancies.\nCORAL [Sun and Saenko, 2016] aligns second-order statistics (e.g., covariance matrices) between source and target feature distributions, thereby reducing mismatches in feature representations.\nMethods grounded in Maximum Mean Discrepancy (MMD) [Tzeng et al., 2014; Wang et al., 2018, 2020] leverage kernel-based metrics to align representations across domains, promoting more universal feature embeddings.\nAlthough these alignment techniques have demonstrated improved performance on unseen domains, they commonly assume centralized access to all training domains. Such an assumption conflicts with the privacy-preserving requirements of Federated Learning (FL), where data cannot be directly exchanged among clients or with a central server. Consequently, adapting representation alignment methods to FL necessitates innovative strategies that ensure robust domain generalization without violating data privacy constraints."}, {"title": "Style Transfer", "content": "A range of style transfer-based domain generalization (DG) methods [Volpi and Murino, 2019; Volpi et al., 2018; Xu et al., 2020] aim to enrich domain diversity, thereby improving model robustness on unseen target domains. These approaches can be broadly separated into two main categories:\nIn the first category, generative models are employed to synthesize data with diverse styles [Palakkadavath et al., 2024; Robey et al., 2021]. By enhancing variability in color, texture, and other visual attributes, these methods reduce reliance on domain-specific features. However, generative modeling often demands substantial computational resources and can encounter training instability\u2014including model collapse in adversarial training-thereby jeopardizing convergence and overall performance."}, {"title": "Federated Domain Generalization", "content": "Most existing Federated Domain Generalization (FDG) methods aim to learn domain-invariant representations across heterogeneous clients. Common strategies include federated adversarial learning and federated representation alignment, yet each approach faces notable challenges:\nApproaches like FedADG [Zhang et al., 2021] employ a global discriminator to extract universal feature representations while preserving local data privacy. Although this technique can mitigate domain discrepancies, it often incurs high computational costs and risks training instability, including potential model collapse.\nMethods such as FedSR [Nguyen et al., 2022] harness L2-norm and conditional mutual information regularization to align feature distributions among clients. These strategies, however, struggle in large-scale federated learning settings, particularly due to limited domain diversity at the individual client level. As a result, models may fail to robustly capture the full variability needed for strong out-of-distribution generalization.\nTo alleviate the challenge of limited local data diversity, CCST [Chen et al., 2023] incorporates cross-client style transfer based on AdaIN [Huang and Belongie, 2017]. By generating synthetic samples styled after other domains, CCST expands the effective training distribution. However, this method relies heavily on pre-trained VGG networks [Simonyan, 2014] for feature extraction and image reconstruction, demanding the transmission of high-dimensional representations. This not only introduces significant communication and computational overhead but also raises privacy risks, as intercepted data could be used to reconstruct original samples [Li et al., 2021; Mothukuri et al., 2021]. Moreover, relying on a pre-trained network can partially contradict domain generalization principles if the target domain is inadvertently included in the pre-training dataset.\nSome FDG methods adopt alternative optimization or aggregation mechanisms to promote generalization across domains:\n\u2022 FedIIR [Guo et al., 2023] aligns client gradients to implicitly learn domain-invariant relationships, improving out-of-distribution generalization.\n\u2022 GA [Zhang et al., 2023] adjusts aggregation weights dynamically to minimize performance disparities among clients, boosting generalization."}, {"title": "Methodology", "content": ""}, {"title": "Preliminary", "content": "Federated Domain Generalization (FDG) aims to train models collaboratively across multiple clients, where each client holds data from distinct domains. The goal is to develop a global model that generalizes effectively to unseen target domains without direct access to their data. Let X and Y denote the input and target spaces, respectively. Consider M source domains:\n$S_{source} = \\{S_i | i = 1, 2, . . ., M\\}$, (1)\nwith each domain sampled from a unique joint distribution $P_i(x, y)$, where $x \\in X$ and $y \\in Y$. These distributions differ significantly across domains, such that $P_i(x,y) \\neq P_j(x,y)$ for $i \\neq j$, reflecting real-world domain shifts in data distribution.\nIn a federated learning setting, data from each domain $S_i$ is distributed across K clients, denoted as $D_k \\subset S_i$. Each client performs local training on its private dataset and communicates only model updates or minimal statistics with a central server to preserve privacy. The objective of FDG is to collaboratively train a global model $f : X \\rightarrow Y$ that minimizes the prediction error on an unseen target domain $S_{target}$:\n$\\min_f E_{(x,y)\\sim S_{target}} [l(f(x), y)]$, (2)\nwhere $l()$ is a task-specific loss function, such as cross-entropy. Importantly, the unseen target domain $S_{target}$ is inaccessible during training, and its joint distribution $P_{target}(x, y)$ differs from all source domain distributions $P_i(x, y)$, i.e., $P_{target}(x, y) \\neq P_i(x, y)$ for all $i \\in \\{1, 2, ..., M\\}$."}, {"title": "Framework Overview", "content": "An illustration of the proposed FedAlign framework is provided in Fig. 2, and the detailed algorithmic steps can be found in Algorithm 1. Our approach integrates MixStyle-based cross-client feature augmentation with multi-level alignment objectives, enabling more robust domain-invariant feature extraction and improved generalization in federated settings."}, {"title": "Client-Side Processing and Augmentation", "content": "Given a batch of samples $X \\in R^{B\\times C\\times H \\times W}$, where B denotes the batch size, C the number of channels, and H and W the image height and width, respectively, we first apply MixStyle-based augmentation to generate two additional augmented batches:\n$X^{(1)} = M(X), X^{(2)} = M(X)$, (3)\nwhere $M(\\cdot)$ represents the MixStyle module (described in Algorithm 2). This module interpolates channel-wise statistics (mean and standard deviation) between two randomly selected samples, effectively increasing diversity in the feature space and enhancing model robustness to domain shifts."}, {"title": "Representation Extraction and Prediction", "content": "After MixStyle augmentation, the FedAlign framework extracts representations and generates predictions for each of the augmented batches. Let Z represent the latent feature space. We decompose the model f into two components:\n$f = g \\circ h$, (4)\n$Z = h(X), Z^{(1)} = h(X^{(1)}), Z^{(2)} = h(x^{(2)})$, (5)\n$\\hat{Y} = g(Z), \\hat{Y}^{(1)} = g(Z^{(1)}), \\hat{Y}^{(2)} = g(Z^{(2)})$. (6)"}, {"title": "Loss Functions", "content": "The final step involves computing the overall loss by integrating three key objectives that collectively ensure domain-invariant feature learning and robust prediction consistency:\nSupervised Contrastive Loss (Lsc): Encourages alignment of representations $(Z, Z^{(1)}, Z^{(2)})$ for samples sharing the same class label, thereby promoting discriminative yet domain-invariant features.\nRepresentation Consistency Loss (LRC): Uses Mean Squared Error (MSE) to minimize the discrepancy between the original and augmented representations Z and $\\{Z^{(1)}, Z^{(2)}\\}$, thus reinforcing representation stability under distribution shifts.\nJensen-Shannon Divergence (LJs): Enforces prediction consistency by minimizing the divergence between $\\hat{Y}$ and $\\{\\hat{Y}^{(1)}, \\hat{Y}^{(2)}\\}$. This ensures that the model's outputs remain reliable even after augmentation.\nBy integrating these alignment mechanisms, FedAlign drives the extraction of domain-invariant features and bolsters the global model's capacity to generalize effectively across heterogeneous domains."}, {"title": "Cross-Client Feature Augmentation with MixStyle", "content": ""}, {"title": "MixStyle-Based Cross-Client Feature Augmentation", "content": "To tackle the challenge of limited domain diversity in federated learning, we incorporate an enhanced version of MixStyle a computationally lightweight data augmentation strategy. By perturbing style information (e.g., color and texture), MixStyle effectively simulates additional, previously unseen domains, thus broadening the training data distribution and bolstering model robustness against domain shifts."}, {"title": "Adversarial Training", "content": "To further enhance domain-invariant feature learning, we incorporate adversarial training by employing a domain discriminator that distinguishes between original and augmented representations. Simultaneously, the feature extractor is optimized to minimize the discriminator's ability to differentiate domains, thereby promoting domain invariance. The domain discriminator itself comprises fully connected layers with dropout, batch normalization, and non-linear activations, ensuring robust performance across feature dimensions. This adversarial mechanism effectively mitigates domain shift and bolsters generalization across diverse client data distributions."}, {"title": "Representation Alignment", "content": "To promote domain-invariant feature learning, FedAlign incorporates two complementary losses that align representations across original and augmented samples.\nSupervised Contrastive Loss (Lsc)\nThis component aligns features of samples sharing the same label, thereby improving the class-level coherence of the learned representations. Formally, for a batch index set $I = \\{1,2,..., B\\}$, we define:\n$L_{SC} = \\frac{1}{\\mid I \\mid} \\sum_{i \\in I} - \\log \\frac{\\sum_{a \\in A(i)} \\exp(\\text{sim}(z_i, z_a) / T)}{\\sum_{p \\in P(i)} \\exp(\\text{sim}(z_i, z_p) / T)}$, (12)\nwhere:\n\u2022 $P(i)$ is the set of indices for samples having the same label as i.\n\u2022 $\\text{sim}(z_i, z_p)$ indicates the cosine similarity between $z_i$ and $z_p$.\n\u2022 $T$ is a temperature parameter used to control the concentration of the distribution.\nBy maximizing similarity for positive pairs $(z_i, z_p)$ while minimizing similarity for negative pairs, $L_{SC}$ encourages class-aligned and discriminative representations.\nRepresentation Consistency Loss (LRC)\nTo further ensure stability and consistency in the feature space, we incorporate a Mean Squared Error (MSE) term between original and augmented representations:\n$L_{RC} = \\frac{1}{\\text{mix_feat}} \\mid\\mid h(X) - h(X_{aug}) \\mid\\mid^2$, (13)"}, {"title": "Style Mixing Mechanism", "content": "Consider a batch of input samples $X = \\{x_i | i = 1, . . ., B\\}$, where B is the batch size. For each sample x, MixStyle computes the channel-wise mean $\\mu(x)$ and standard deviation $\\sigma(x)$ as:\n$\\mu(x) = \\frac{1}{H W} \\sum_{h=1}^{H} \\sum_{w=1}^{W} x_{c,h,w}$, (7)\n$\\sigma(x) = \\sqrt{\\frac{1}{H W} \\sum_{h=1}^{H} \\sum_{w=1}^{W} (x_{c,h,w} - \\mu(x)_c)^2}$, (8)\nwhere H and W are the height and width of the feature map, and c indexes the channels. Given two samples $x_i$ and $x_j$, the style statistics are interpolated as:\n$\\mu_{mix} = \\lambda \\cdot \\mu(x_i) + (1 - \\lambda) \\cdot \\mu(x_j)$, (9)\n$\\sigma_{mix} = \\lambda \\cdot \\sigma(x_i) + (1 - \\lambda) \\cdot \\sigma(x_j)$, (10)\nwhere $\\lambda \\sim Beta(\\alpha, \\alpha)$ is sampled from a Beta distribution. The augmented sample is then produced by:\n$X_{aug} = \\frac{x_i}{\\mu(X_i)} \\sigma_{mix} + \\mu_{mix}$. (11)"}, {"title": "Total Representation Alignment Loss", "content": "We combine these objectives into a single representation alignment loss, which balances both discriminative class alignment and robust consistency:\n$L_{RA} = L_{SC} + L_{RC}$. (14)\nThrough this unified formulation, FedAlign learns domain-invariant and stable feature embeddings that enhance its ability to generalize effectively to unseen target domains."}, {"title": "Prediction Alignment", "content": "In addition to feature-level alignment, FedAlign imposes consistency on the model's outputs through Jensen-Shannon (JS) Divergence, which measures the stability of predictions across original and augmented samples. Formally, for predictions $\\hat{Y}, \\hat{Y}^{(1)}$, and $\\hat{Y}^{(2)}$ (corresponding to $X, X^{(1)}$, and $X^{(2)}$, respectively), the JS Divergence loss is defined as:\n$L_{JS} = \\frac{1}{3} [KL(\\hat{Y}||\\overline{Y}) + KL(\\hat{Y}^{(1)}||\\overline{Y}) + KL(\\hat{Y}^{(2)}||\\overline{Y})]$, (15)\nwhere:\n\u2022 $\\overline{Y} = (\\hat{Y} + \\hat{Y}^{(1)} + \\hat{Y}^{(2)})$ is the mean prediction distribution across the original and augmented samples.\n\u2022 KL denotes the Kullback-Leibler Divergence, quantifying how one probability distribution diverges from a second, reference distribution.\nBy enforcing prediction consistency, $L_{JS}$ encourages the network to produce stable outputs despite the domain-perturbing augmentations, thereby promoting robust and domain-invariant classification performance."}, {"title": "Total Loss Function", "content": "The final loss function for FedAlign combines the primary classification objective with both representation and prediction alignment terms:\n$L = L_{CLS} + \\lambda_1(L_{SC} + L_{RC}) + \\lambda_2L_{JS}$, (16)\nwhere:\n\u2022 $L_{CLS}$ is the cross-entropy loss for classification.\n\u2022 $\\lambda_1$ and $\\lambda_2$ are hyperparameters that balance the influence of the representation and prediction alignment terms, respectively.\nBy integrating these complementary objectives, FedAlign fosters domain-invariant representations and stable predictions, culminating in a robust federated learning framework with strong generalization to unseen domains."}, {"title": "Experiments", "content": "Datasets. We evaluate FedAlign on four widely used domain generalization benchmarks, each offering distinct characteristics and posing unique challenges:\n\u2022 PACS [Li et al., 2017]: This dataset contains 9,991 samples spread across four domains: Art Painting, Cartoon, Photo, and Sketch. Comprising 7 classes, PACS is known for its substantial inter-domain variability, making it a stringent testbed for domain generalization methods.\n\u2022 OfficeHome [Venkateswara et al., 2017]: OfficeHome includes 15,588 samples from four domains: Art, Clipart, Product, and Real World, covering 65 categories. It is frequently employed in both domain adaptation and domain generalization tasks due to the diversity of object appearances arising from everyday office and home environments.\n\u2022 miniDomainNet [Zhou et al., 2021]: A subset of DomainNet, miniDomainNet contains 140,006 images from four domains-Clipart, Infograph, Painting, and Real-and spans 126 categories. Its large-scale, heterogeneous nature presents significant challenges for learning domain-invariant representations.\n\u2022 Caltech (Caltech-101) [Griffin et al., 2007]: Often referred to as Caltech-101, this dataset comprises 9,146 images across 101 object categories. Despite its relatively smaller size, its broad range of object classes allows for a robust evaluation of domain generalization strategies.\nEvaluation Protocol. To thoroughly assess generalization performance, we employ the widely adopted leave-one-domain-out protocol. Specifically, for each dataset, one domain is designated as the test set while the remaining domains are collectively used as the training set. This procedure is repeated for every domain, ensuring that each serves once as the unseen target domain. By systematically testing across multiple distribution shifts, this protocol enables a comprehensive evaluation of the model's ability to generalize to novel domains.\nComputational and Transmission Overhead. Although sample statistics (e.g., mean and variance) are shared among clients in FedAlign, the corresponding computational and transmission overhead is minimal when compared to the cost of model training and communication. Furthermore, adversaries cannot reconstruct samples solely from these statistics, preserving data privacy. As demonstrated in Figure 5, FedAlign achieves superior performance with minimal upload ratios, underscoring its efficiency in both reducing communication overhead and mitigating privacy risks.\nData Partitioning. We follow the partitioning strategy presented in Section 3.1 of our overall methodology. Specifically, each dataset is split among a predefined number of clients, with variations in the composition of local training data across clients. This setup simulates realistic non-IID distributions commonly observed in federated learning environments, thereby providing a stringent assessment of each method's robustness to data heterogeneity."}, {"title": "Experimental Results", "content": ""}, {"title": "Quantitative Performance and Comparative Analysis", "content": "As shown in Table 1, FedAlign consistently outperforms all baseline methods across the evaluated datasets, achieving the highest overall average accuracy. Notably, FedAlign also secures the top accuracy in each target domain for both the PACS and miniDomainNet benchmarks, underscoring its robust generalization capabilities.\nFurthermore, we observe that most existing methods explicitly designed for Federated Domain Generalization (FDG) often fail to maintain stable performance across different datasets; in some cases, they even lag behind classical federated learning approaches such as FedAvg and FedProx. This indicates that many current FDG algorithms may not sufficiently address the challenges of learning domain-invariant features under federated constraints, emphasizing the need for a more robust solution like FedAlign."}, {"title": "Scalability and Robustness Analysis", "content": "In addition to superior average accuracy, Figure 4 illustrates the resilience of FedAlign under varying client sizes, encompassing both small- and large-scale client settings. While the performance of all baseline methods deteriorates markedly as the number of participating clients increases, FedAlign maintains a consistent advantage. This robustness highlights FedAlign's ability to adapt to diverse federated learning scenarios, effectively balancing scalability with state-of-the-art performance."}, {"title": "Representation Distribution via t-SNE", "content": "To further evaluate the effectiveness of the proposed FedAlign framework, we examine the distribution of learned representations using t-SNE visualizations. As shown in Figure 3, we compare the representation spaces across four domains\u2014Photo, Art, Cartoon, and Sketch\u2014under two settings: the baseline method (FedAvg, top row) and our FedAlign framework (bottom row). These visual comparisons provide valuable insights into the ability of FedAlign to learn domain-invariant features.\nDistinct and Compact Clusters\nIn challenging domains such as Photo and Art, FedAlign yields more distinct and compact clusters. This indicates that the framework effectively mitigates distributional gaps among diverse domains, suggesting stronger domain alignment than the baseline.\nImproved Intra-Class Coherence\nWithin each cluster, samples from the same class are more tightly grouped under FedAlign. This suggests a higher degree of feature alignment across clients and domains, translating to enhanced generalization performance.\nEnhanced Inter-Class Separability\nFedAlign also achieves better separation between different classes, reducing overlap and confusion in the representation space. As a result, the learned features exhibit higher discriminative power, critical for robust domain generalization.\nOverall, the compactness of clusters and the improved class separation observed in t-SNE plots confirm that FedAlign effectively handles domain shifts, thereby offering more robust and generalized feature representations compared to traditional federated learning baselines.\nImplications for Domain Generalization\nThe observed improvements in representation distribution underscore the efficacy of FedAlign in promoting feature alignment across diverse domains. By learning robust, domain-invariant features, FedAlign substantially boosts generalization performance, particularly when tackling previously unseen target domains. This enhanced resilience to domain shifts is crucial for real-world Federated Domain Generalization (FDG) applications, where heterogeneity is often unavoidable. The t-SNE visualizations confirm that FedAlign successfully narrows the gaps between source domains while preserving strong predictive accuracy, thereby demonstrating its potential to handle challenging and heterogeneous federated environments."}, {"title": "Conclusion", "content": "In this paper, we present FedAlign, a novel framework for Federated Domain Generalization (FDG) that addresses the challenges of limited local data and client heterogeneity. It aims to significantly enhance model generalization by introducing an efficient cross-client feature extension module, that enriches and diversifies representations. Additionally, it employs a dual-stage alignment strategy targeting both feature representations and output predictions to robustly extract domain-invariant features. Extensive evaluations on multiple standard benchmark datasets demonstrate that our framework consistently outperforms state-of-the-art methods, delivering superior accuracy and strong scalability across varying client populations."}]}