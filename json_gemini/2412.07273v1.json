{"title": "Temporal-Aware Evaluation and Learning for Temporal Graph Neural Networks", "authors": ["Junwei Su", "Shan Wu"], "abstract": "Temporal Graph Neural Networks (TGNNs) are a family of graph neural networks designed to model and learn dynamic information from temporal graphs. Given their substantial empirical success, there is an escalating interest in TGNNs within the research community. However, the majority of these efforts have been channelled towards algorithm and system design, with the evaluation metrics receiving comparatively less attention. Effective evaluation metrics are crucial for providing detailed performance insights, particularly in the temporal domain. This paper investigates the commonly used evaluation metrics for TGNNs and illustrates the failure mechanisms of these metrics in capturing essential temporal structures in the predictive behaviour of TGNNs. We provide a mathematical formulation of existing performance metrics and utilize an instance-based study to underscore their inadequacies in identifying volatility clustering (the occurrence of emerging errors within a brief interval). This phenomenon has profound implications for both algorithm and system design in the temporal domain. To address this deficiency, we introduce a new volatility-aware evaluation metric (termed volatility cluster statistics), designed for a more refined analysis of model temporal performance. Additionally, we demonstrate how this metric can serve as a temporal-volatility-aware training objective to alleviate the clustering of temporal errors. Through comprehensive experiments on various TGNN models, we validate our analysis and the proposed approach. The empirical results offer revealing insights: 1) existing TGNNs are prone to making errors with volatility clustering, and 2) TGNNs with different mechanisms to capture temporal information exhibit distinct volatility clustering patterns. Moreover, our empirical findings demonstrate that our proposed training objective effectively reduces volatility clusters in error.", "sections": [{"title": "1 Introduction", "content": "Many real-world problems and systems are naturally modeled as temporal graphs (also referred to as dynamic graphs), characterized by continuously changing relationships, nodes, and attributes. To address this temporal dynamic nature, Temporal Graph Neural Networks (TGNNs), the temporal counterparts to GNNs, have emerged as promising deep learning models capable of modelling time-varying graph structures (Kazemi et al. 2020; Skarding, Gabrys, and Musial 2021; Zhang et al. 2023; Xu et al. 2020a). Unlike their static counterparts, TGNNs excel at capturing temporal dependencies and learning temporal representations within the context of temporal graphs. Consequently, they are widely employed in applications such as traffic prediction (Zhao et al. 2019; Guo et al. 2019; Zhang et al. 2020), financial analysis (Wang et al. 2021a; Su, Wu, and Li 2024), social network (Zhang et al. 2021b), recommender systems (Kumar, Zhang, and Leskovec 2019), and climate modeling (Khodayar and Wang 2018).\nGiven their substantial empirical success, there is growing interest in TGNNs within the research community. However, most efforts have been concentrated on algorithm and system design, with various classes of TGNNs emerging based on their mechanisms for capturing temporal information (e.g., RNN-based, memory-based, and attention-based; see related work for more details). Conversely, the evaluation of TGNNs has received comparatively less attention. There are only a few benchmark studies on TGNNs that predominantly investigate how various combinations of learning settings and datasets impact the performance of TGNN models. Notably, these benchmarks typically utilize common instance-based evaluation metrics like Average Precision (AP) and Area Under the ROC Curve (AU-ROC), where each test sample is considered identically and independently. An intriguing finding from these benchmark studies is that almost all existing TGNNs demonstrate remarkable (and similar) performance when evaluated against these instance-based metrics. This uniformity in performance poses a significant challenge in model selection for practical applications, as distinguishing between models based on these metrics alone becomes difficult. Therefore, there is an urgent need to develop more nuanced evaluation metrics that can better capture the unique capabilities and efficiencies of different TGNN architectures.\nIn addition to model selection, this paper argues that instance-based evaluation metrics are insufficient and ineffective at capturing the temporal structure of the predictive behavior of TGNNs. Data samples in temporal graphs could exhibit temporal correlation, impacting the predictions made by TGNNs and introducing patterns such as volatility clusters periods where large fluctuations are grouped together. This aspect is crucial for the functionality of temporal algorithms and systems in TGNNs. For example, in financial trading algorithms or risk management systems, accurately measuring and predicting volatility clusters can be crucial for effective strategy deployment and risk assessment. Similarly, in fault-tolerant systems, understanding volatility clusters can aid in preemptively identifying periods of potential system stress or failure, thereby enabling proactive maintenance or system adjustments to prevent downtime. Adequate performance evaluation ensures that these systems are not only accurate but also robust and responsive under varying temporal dynamics. This, in turn, aids in optimizing operational efficiency, improving decision-making processes, and ensuring reliability in critical applications where timing and the evolution of data play a vital role. Therefore, developing and refining evaluation metrics that can effectively measure the performance of TGNNs is essential for advancing these technologies and their applications.\nContribution. This paper aims to spotlight an underexplored aspect of TGNNs\u2014the evaluation metrics. We examine and highlight the inadequacies of current evaluation metrics in capturing the temporal structures of TGNNs and propose a novel performance metric tailored to detect nuanced temporal information such as volatility clusters. The key contributions and findings of this paper are summarized and highlighted as follows\n1. We present a mathematical formulation of existing evaluation metrics alongside a formal definition aimed at measuring the expressiveness of these metrics. This foundational framework is crucial for analyzing evaluation metrics comprehensively and formalizing the limitations inherent in current TGNN evaluation approaches. Utilizing this framework, we formally prove that instance-based evaluation metrics such as AP and AU-ROC resemble a simple counting process and fail to capture temporal structures (e.g., volatility clusters) in the predictions of TGNNS (Theorem 3.1).\n2. Building on the insights from our analysis, we propose a novel evaluation metric, named volatility-cluster statistics (VCS). Inspired by Hopkins statistics (Hopkins and Skellam 1954), VCS serves as a complementary evaluation metric designed to detect and evaluate volatility clusters in the prediction errors of TGNNs. VCS offers crucial insights into the temporal structure of the prediction errors (error pattern) of TGNNs and helps differentiate the performance of various TGNN models.\n3. Beyond its use in evaluation, we demonstrate that the concept of VCS can also function effectively as a regularization technique to mitigate volatility clusters in errors with appropriate modifications. We introduce a method termed volatility-cluster-aware (VCA) learning, which is a smooth and differentiable extension of VCS. VCA helps mitigate volatility clusters in the prediction errors of TGNNs. This capability is particularly valuable in the design of systems and algorithms for critical areas such as fault-tolerant systems.\n4. We validate our findings and the effectiveness of our metrics through extensive empirical studies consisting of five datasets and six SOTA methods. Our empirical results reveal several key insights: 1) existing TGNNs tend to produce volatility cluster in errors, particularly in RNN-based and memory-based models; 2) different types of TGNNs manifest varying error patterns\u2014for instance, memory-based TGNNs generally exhibit clustered errors towards the end of the testing period, whereas RNN-based TGNNs tend to show them at the beginning. These observations indicate fundamental differences in how these models process temporal information and provide directions for model-specific improvements; 3) our proposed VCA learning objective serves as an effective regularization tool, making existing TGNNs less susceptible to volatility clustering in errors."}, {"title": "2 Related Works", "content": "Temporal Graph Neural Network. Temporal graph representation learning has garnered substantial attention in recent years, driven by the imperative to model and analyze evolving relationships and temporal dependencies within temporal graphs (we refer the reader to (Skarding, Gabrys, and Musial 2021; Kazemi et al. 2020) for more comprehensive surveys). TGNNs, as temporal counterparts to GNNs, have emerged as promising neural models for temporal graph representation learning(Sankar et al. 2020; Poursafaei et al. 2022; Xu et al. 2020a; Su, Zou, and Wu 2024b; Wang et al. 2021c; Kumar, Zhang, and Leskovec 2019; Trivedi et al. 2019; Zhang et al. 2023; Pareja et al. 2020; Trivedi et al. 2017; Xu et al. 2020b; Luo and Li 2022) and have shown SOTA performance in many temporal-related tasks. Roughly speaking, existing TGNNs can be categorized into three types based on the mechanism used for capturing temporal information: RNN-based (Trivedi et al. 2019), attention-based (Wang et al. 2021b), and memory-based TGNNs (Rossi et al. 2021). Due to its potential and practical significance, there has been a recent surge in both theoretical exploration (Souza et al. 2022) and architectural innovation (Rossi et al. 2021; Wang et al. 2021c; Kumar, Zhang, and Leskovec 2019; Trivedi et al. 2019; Zhang et al. 2023) related to TGNNs. In addition, there are works dedicated to optimizing both the inference and training efficiency of TGNNs, employing techniques such as incremental learning (Su et al. 2023; Su, Zou, and Wu 2024a), computation duplication (Wang and Mendis 2023), CPU-GPU communication optimization (Zhou et al. 2022), staleness (Sheng et al. 2024), and caching (Wang et al. 2021c). Despite all these efforts, the evaluation metrics of TGNNs remain underexplored. In this paper, we address this gap and focus on studying the evaluation metrics of TGNNs.\nEvaluation of TGNNs. Evaluation is core to machine learning research (Zhang et al. 2021a). Because of this, evaluation and benchmarking have been extensively studied in static graph representation learning (Dwivedi et al. 2023; Errica et al. 2019; Hu et al. 2020; Lv et al. 2021). Due to the dynamic nature of temporal graphs, properly evaluating temporal link prediction problems has been challenging and complicated with different issues as documented in (Junuthula, Xu, and Devabhaktuni 2018; Haghani and"}, {"title": "3 Preliminary and Background", "content": "In this section, we provide a concise introduction to TGNNs. Due to space limitations, a more detailed description is available in the supplementary material for completeness. We use lowercase letters to denote scalars and graph-related objects, and lower and uppercase boldface letters to denote vectors and matrices, respectively.\nEvent-based Representation of Temporal Graphs. In this paper, we adopt the event-based representation of temporal graphs, as described in previous works (Skarding, Gabrys, and Musial 2021; Zhang et al. 2023). A temporal graph $G$ in this representation consists of a node set $\\nu = \\{1,..., N\\}$ and an event set $E = \\{e_{ij}(t)\\}$, where $i, j \\in V$. The node set $V$ represents the entities in the graphs. The event set $\\& represents a stream of events, with each edge $e_{ij} (t)$ corresponding to an interaction event between node $i$ and node $j$ at timestamp $t > 0$. Node features and edge features for $v_i$ and $e_{ij}$ are denoted by $f_i(t)$ and $f_{ij} (t)$, respectively. In the case of non-attributed graphs, we assume $f(t) = 0$ and $f_{ij}(t) = 0$, representing zero vectors.\nTemporal Graph Neural Networks (TGNNs). TGNNS, extended from the standard GNN to the temporal graph, can be viewed as an embedding function (encoder) for finding the temporal representation of vertices in temporal graphs (Su, Zou, and Wu 2024b; Rossi et al. 2021). The learned embedding can then be used as input for different downstream tasks. A canonical formulation of the TGNN encoder is to extend the message-passing scheme from GNNs to include time information. The formulation of TGNNs for learning the representation of vertex $i$ is given by:\n$h_i(t) = emb(\\{m_{ij}, j \\in N_i(t)\\}),$\n$m_{ij} (t) = msg(h_i(t^{-}), h_j (t^{-}), f_{ij} (t), f_i(t), f_j (t), \\Delta t),$\nwhere $h_i (t)$ and $h_j(t^{-})$ are the embedding of nodes $i$ and $j$ before time $t$ (i.e., at the time of the previous interaction involving node $i$ or $j$), $m_{ij} (t)$ is the message from vertex $j$ to $i$ at time $t$ generated from the event $e_{ij} (t)$, $N_i(t)$ is the temporal neighbours of nodes $i$ up to time $t$, $h_i(t)$ is temporal embedding/representation of nodes $i$ at time $t$, and $msg(.)$ (e.g., MLP), and $emb(.)$ (e.g., GCN) are learnable functions. After obtaining the embeddings $h_i(t)$ and $h_j(t)$ in the prescribed manner, an extra simple MLP layer (or decoder in other forms) can be used for the down-stream tasks.\nTGNNS Training and Evaluation TGNNs are frequently trained in a self-supervised manner using link prediction tasks (Poursafaei et al. 2022; Huang et al. 2024), which are commonly conceptualized as a binary classification problem aimed at predicting whether a link will form between two nodes. Consequently, the performance of TGNNs is often evaluated with respect to their success in link prediction tasks. Therefore, in this paper, we concentrate our discussion on link prediction, though the analysis and arguments can be naturally extended to other downstream tasks such as node classification. More formally, we can assign labels for"}, {"title": "4 Methodology", "content": "Building on the previous discussion regarding the limitations of existing evaluation metrics, this section introduces a novel temporal-aware evaluation metric derived from the concept of Hopkins statistics (Banerjee and Dave 2004). Specifically, we focus on detecting volatility clusters within predictions, which have significant implications for algorithms and systems, as discussed earlier. Additionally, based on this proposed evaluation metric, we introduce a novel temporal-aware learning objective for TGNNs. The pseudocode for the complete procedure is provided in the supplementary material.\nVolatility-Cluster Statistics (VCS)\nGiven a test period $T_{test}$ with an event sequence $E_{test}$, let $Y$ and $\\hat{Y}$ represent the ground truth and the predictions of the model on the test set, respectively. Let $E_{disg}$ denote the set of disagreement events with cardinality $k$. We first compute the sum of distances from the disagreement set to the test set as:\n$D_{disg} = \\sum_{e\\in E_{disg}} d(e, E_{test}),$ (4.1)\n$d(e, E_{test}) = \\min \\{|t_e - t_{e'}|e' \\in E_{test}, e'\\neq e\\}.$ (4.2)\n$d(e, E_{test})$ calculates the time difference between event $e$ and the closest event in the test set. Then, $D_{disg}$ is a sum"}, {"title": "Volatility-Cluster-Aware (VCA) Learning", "content": "In the previous section, we introduced a new statistical measure for detecting volatility clusters in the temporal dimension. We discussed how the error pattern of the system can have significant implications in real-time systems, especially concerning fault-tolerant aspects of development. Typically, real-time systems prefer more uniform error distributions. Thus, an important question arises: can we use the proposed measure to help TGNNs learn a model (weight) from the hypothesis space that exhibits a more uniform error pattern?\nA straightforward idea is to incorporate $T(E_{disg}, E_{test}, \\tau)$ as a regularization term in the learning objective. However, a technical challenge arises due to the non-differentiability of the distance function $d(e, E)$, which is due to the $min$ operator. To address this, we propose the following modification with a smooth and differentiable version that mimics the $min$ function:\n$d_{soft} (e, E) = \\log \\bigg(\\sum_{e'\\in E,e'\\neq e} \\exp(-\\beta |t_e-t_{e'}|)\\bigg) / \\beta,$\nwhere $\\beta$ is a positive parameter that controls the sharpness of the approximation. As $\\beta$ increases, the approximation becomes closer to the actual minimum function. This approach turns the non-differentiable minimum into a differentiable function by summing over exponentially scaled, inverted distances,\n$T_{soft} (E_{disg}, E_{test}) = \\frac{D_r}{D_r + D_{disg}}$\nwhere $D_r$ and $D_{disg}$ are defined similarly as before with the distance function replaced with $d_{soft} (.).$ We can then incorporate this into the learning process and term the modified objective VCA.\n$\\hat{L}(Y, \\hat{Y}) = L(\\hat{Y}, Y) + \\gamma \\bigg| \\frac{1}{2} - T_{soft} (E_{disg}, E_{test})\\bigg|^2, $ (4.4)\nwhere $L(\\hat{Y}, Y)$ is the standard loss function for training TGNNs (e.g., cross-entropy), and $\\gamma$ is a hyper-parameter"}, {"title": "5 Empirical Study", "content": "In this section, we present an empirical study to further illustrate the problem addressed in this paper. The study aims to answer the following key questions:\n1. Do existing TGNNs exhibit volatility clusters in errors?\n2. Do existing TGNNs exhibit different error distributions?\n3. Is VCS effective in detecting volatility clusters in errors?\n4. Can VCA mitigate volatility clusters in errors?\nExperimental Settings\nDatasets and Baselines. We use five public dynamic graph benchmark datasets: Reddit, Wikipedia, MOOC, LastFM, and GDELT (Poursafaei et al. 2022). We evaluate six state-of-the-art TGNN models, with two models from each of the three categories of TGNNs mentioned: TGN (Rossi et al. 2021) & Tiger (Zhang et al. 2023) (memory-based TGNNs), TCL (Wang et al. 2021b) & TGAT (Xu et al. 2020a) (attention-based TGNNs), and JOIDE (Kumar, Zhang, and Leskovec 2019) & DyRep (Trivedi et al. 2019) (RNN-based TGNNs). We adopt the implementation of these baselines from (Zhou et al. 2022; Poursafaei et al. 2022; Huang et al. 2024). Detailed descriptions of the datasets and models are provided in the supplementary material for completeness.\nEvaluation Task and Metrics. Following the approaches outlined in (Poursafaei et al. 2022; Huang et al. 2024; Yu et al. 2023), we evaluate models for temporal link prediction, which involves predicting the probability of a link forming between two nodes at a specific time. We use a multi-layer perceptron (MLP) that takes the concatenated representations of two nodes as input and outputs the probability of a link. For evaluation metrics, we focus on AP and the proposed VCS. We train each model with and without VCA to observe the effect of our proposed learning objective. For all experiments, we follow the standard procedure and split datasets chronologically with a ratio of 70%/15%/15% for training, validation, and testing, respectively. Each experiment is conducted with five independent trials, and the average results are reported\nExperimental Results\nTemporal Error Pattern. Our first experiment aims to demonstrate the temporal error patterns of various models and how our proposed metrics can effectively differentiate and reveal insightful information regarding these patterns. Fig. 4 illustrates that different types of TGNNs exhibit distinct error pattern behaviours. Specifically, memory-based TGNNs tend to produce volatility clusters in errors toward the end of the test period, RNN-based TGNNs are more prone to errors at the beginning of the test period and attention-based TGNNs exhibit a more uniform distribution in errors. This temporal structure in the prediction errors of memory-based and RNN-based TGNNs is reflected by a larger VCS value in Table 1. This confirms that existing TGNNs indeed generate volatility clusters in errors, and different TGNN mechanisms induce varying volatility patterns. Furthermore, this demonstrates that VCS is an effective measure for detecting volatility clusters in errors.\nEffectiveness of VCA. Our next experiment aims to demonstrate the effectiveness of our proposed learning objective, VCA, as defined in Eq. 4.4, in regulating the behavior of TGNNs. As shown in Table 1, TGNN models trained with our proposed objective significantly reduce volatility clusters in errors, as evidenced by decreased VCS values. The improvement in attention-based TGNNs (e.g., TCL & TGAT) is relatively small because these models already exhibit a fairly uniform error distribution. This confirms that VCA is indeed effective in mitigating volatility clusters in errors. Such a property can be particularly beneficial for critical real-time systems where fault tolerance is important, and a more uniformly distributed error is preferred.\nAblation Study. The final part of the empirical study focuses on the hyper-parameters of VCS and VCA. The key hyper-parameter in VCS is $\\tau$, which represents the number of independent trials conducted to compute the reference distance for random errors. As shown in Fig. 4(a), we found that increasing leads to a smaller variance in value but incurs a higher computational cost. However, we find that T = 5 already provides a sufficiently robust estimation. The main hyper-parameter in VCA is y in Eq.4.4, which controls the regularization effect of the proposed learning objective. Our experiment shows that increasing y results in a more uniform error pattern but worsens predictive performance (smaller AP). Thus, there is a trade-off between achieving this uniform error distribution and maintaining predictive performance. This trade-off does not undermine the effectiveness of our proposed learning objective, as the primary goal is to make the error distribution more uniform. Whether this trade-off is favourable depends on the application scenario. However, as indicated in Table 1, y = 0.1 provides a significant improvement in VCS without significantly affecting the model's accuracy."}, {"title": "6 Discussion", "content": "Conclusion. In this paper, we investigate the evaluation metrics for TGNNs. Specifically, we have identified the pitfalls and limitations of currently used instance-based measures, such as AP and AU-ROC, in capturing temporal structures in prediction errors, such as volatility clusters. To address this issue, we propose VCS, a metric that effectively captures volatility clusters in errors for TGNNs. Furthermore, we extend this proposed evaluation metric as a regularizer, introducing VCA to mitigate volatility clusters in errors.\nLimitation and future works\nIn this paper, we focus on volatility clusters in errors. However, other important temporal structures, such as the time"}, {"title": "A Proof for the Failure of Existing Evaluation Metric", "content": "In this appendix, we provide a proof for Theorem 3.1.\nProof. Let $Y_1$ and $Y_2$ be two distinct predictions for the set $E$ with ground-truth $Y$ with\n$\\mu(\\hat{Y}_1, Y,E) = \\mu(\\hat{Y}_2, Y, E),$\nwhere\n$H(Y, \\hat{Y}) = \\sum_{k=1}^{\\epsilon}1[y_k \\neq \\hat{y}_k].$\nLet $\\mu(.)$ be an given instance-based evaluation metric. By definition 2, we can rewrite $\\mu(\\hat{Y}_1, Y, E)$, $\\mu(\\hat{Y}_2, Y, E)$ as,\n$\\mu(\\hat{Y}_1, Y,E) = g (\\{f(Y_i, \\hat{Y}_i)|Y_i, \\hat{Y}_i \\in Y, \\hat{Y}_1\\}),$\n$\\mu(\\hat{Y}_2, Y,E) = g (\\{f(Y_i, \\hat{Y}_i)|Y_i, \\hat{Y}_i \\in Y, \\hat{Y}_2\\}).$\nAs link-prediction problem can be reduced to a binary classification problem, this means that $f(.)$ can be written as,\n$f(Y_i, \\hat{Y}_i) = c\\cdot 1[Y_i \\neq \\hat{Y}_i],$\nwhere c is some constant that weight the wrong prediction. Without loss of generality, we assume\n$H(Y, \\hat{Y}_1) = H(Y, \\hat{Y}_2) = k,$\nfor some positive integer k. Then, we can rewrite $\\mu(\\hat{Y}_1, Y, E)$, $\\mu(\\hat{Y}_2, Y, E)$ as,\n$\\mu(\\hat{Y}_1, Y,E) = g (\\{f(Y_i, \\hat{Y}_i)|Y_i, \\hat{Y}_i \\in Y, \\hat{Y}_1\\})$\n$= g(k\\cdot c)$\n$= g (\\{f(Y_i, \\hat{Y}_i)|Y_i, \\hat{Y}_i \\in Y, \\hat{Y}_2\\})$\n$= \\mu(\\hat{Y}_2, Y,E)$"}, {"title": "B Algorithm and Further Discussion", "content": "Training Procedure of TGNNS\nThe training procedure of an TGNN involves capturing temporal dynamics and learning representations of nodes in a dynamic graph. The process typically follows an encoder-decoder framework. In the encoder, the TGNN takes a dynamic graph as input and generates dynamic representations of nodes. This is achieved by using message-passing mechanisms to propagate information through the graph and incorporating temporal neighbors' interactions. The decoder utilizes the node representations generated by the encoder to perform downstream tasks, such as temporal link prediction or node classification. TGNNs are commonly trained using a self-supervised temporal link prediction task, where the decoder predicts the likelihood of an edge between two nodes based on their representations.\nThe training procedure of an TGNN involves several steps. First, the dataset is divided into training, validation, and test sets using a chronological split. Specifically, given an event set from time interval [0, T], the chronological split partitions the dataset into [0, $T_{train}$] (training set), [$T_{train}$, $T_{validation}$] (validation set), and [$T_{validation}$, $T_{test}$] (test set). From now on, we focus on the training set and drop the subscript. The training set is then further divided into temporal batches, where each batch consists of consecutive events in the dynamic graph. Additionally, negative events are sampled from the rest of the graph to provide the negative signal. During training, TGNNs often adopt a lag-one procedure. This means that the model uses the information from the previous batch to update its state and generate node embeddings for the current batch. This lag-one scheme helps maintain temporal consistency and ensures that the model captures the correct temporal patterns. Fig. 5 provides a graphical illustration of the training flow between epochs. The pseudo-code of the training procedure with cross-entropy is summarized in Algorithm 1.\nAlgorithm 1: Standard Training Procedure for TGNN\nInitialization: $H_0 \\leftarrow F$ {Intialize embedding with feature vector of vertices and edge}\nfor t=1 to T do\nfor $B_i \\in B_1, ..., B_K$ do\n$B^-$ Sample negative events\n$\\tilde{B} = B\\cup B^-$\n$B_{i-1}$ Temporal batch from last iteration\n$M_i = msg(H_{i-1}, B_{i-1})$\n$H_i = emb(M_i, H_{i-1}, A_i)$, {where $A_i$ is the (Temporal) neighbourhood of vertex }\nCompute the loss (e.g., binary cross-entropy) and run the training procedure (e.g., backpropagation)\n$L(H_i, B_i)$\nend for\nend for"}, {"title": "C Additional Experiment Details", "content": "Hardware and Software\nAll the experiments of this paper are conducted on the following machine\nCPU: two Intel Xeon Gold 6230 2.1G, 20C/40T, 10.4GT/s, 27.5M Cache, Turbo, HT (125W) DDR4-2933\nGPU: four NVIDIA Tesla V100 SXM2 32G GPU Accelerator for NV Link\nMemory: 256GB (8 x 32GB) RDIMM, 3200MT/s, Dual Rank\nOS: Ubuntu 18.04LTS\nDataset\nDescription We use the following public datasets provided by the authors of JODIE (Kumar, Zhang, and Leskovec 2019). (1) Wikipedia dataset contains edits of"}, {"title": "Algorithm 2: VCS", "content": "Input: $E_{test}, Y, \\hat{Y}$\nInitialization: $T$\nFind the set of disagreement $E_{disg}$ based on $Y$ and $\\hat{Y}$ Compute $D_{disg}$ as\n$D_{disg} = \\sum_{e\\in E_{disg}} d(e, E_{test}),$\n$d(e, E_{test}) = \\min_{e' \\in E_{test}, e' \\neq e} \\{|t_e - t_{e'}|\\}.$\nfor i=1 to $\\tau$ do\nsample a random set form $E^{(t)}$ of the same cardinality as $E_{disg}$.\ncompute $D_r^{(t)}$ as above.\nend for\nCompute and return the VCS as\n$VCS = |1/2 - T(E_{disg}, E_{test}, \\tau)|,$\n$\\frac{1}{2}$\\\n\\end{aligned}\n+ $D_{disg}$"}, {"title": "Algorithm 3: VCA", "content": "Initialization: $H_0 \\leftarrow F$ {Intialize embedding with feature vector of vertices and edge}\nInitialization: $\\gamma$, $\\tau$\nfor t=1 to T do\nfor $B_i \\in B_1, ..., B_K$ do\n$B^-$ Sample negative events\n$\\tilde{B} = B \\cup B^-$\n$B_{i-1}$ Temporal batch from last iteration\n$M_i = msg(H_{i-1}, B_{i-1})$\n$H_i = emb(M_i, H_{i-1}, A_i)$\nGet the prediction and ground truth for the batch $Y(B_{i-1})$, $\\hat{Y}(B_{i-1})$\nSuppose the disagreement between prediction and ground truth is k, sample k random samples from the dataset.\nCompute the loss and run the training procedure (e.g., backpropagation)\n$L(B_{i-1})+\\gamma \\bigg| \\frac{1}{2} - T_{soft} (E_{disg}, E_{test}, \\tau) \\bigg|$\nend for\nend for"}]}