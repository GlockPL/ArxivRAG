{"title": "A Prompt Refinement-based Large Language Model for Metro Passenger Flow Forecasting under Delay Conditions", "authors": ["Ping Huang", "Yuxin He", "Hao Wang", "Jingjing Chen", "Qin Luo"], "abstract": "Accurate short-term forecasts of passenger flow in metro systems under delay conditions are crucial for emergency response and service recovery, which pose significant challenges and are currently under-researched. Due to the rare occurrence of delay events, the limited sample size under delay condictions make it difficult for conventional models to effectively capture the complex impacts of delays on passenger flow, resulting in low forecasting accuracy. Recognizing the strengths of large language models (LLMs) in few-shot learning due to their powerful pre-training, contextual understanding, ability to perform zero-shot and few-shot reasoning, to address the issues that effectively generalize and adapt with minimal data, we propose a passenger flow forecasting framework under delay conditions that synthesizes an LLM with carefully designed prompt engineering. By Refining prompt design, we enable the LLM to understand delay event information and the pattern from historical passenger flow data, thus overcoming the challenges of passenger flow forecasting under delay conditions. The propmpt engineering in the framework consists of two main stages: systematic prompt generation and prompt refinement. In the prompt generation stage, multi-source data is transformed into descriptive texts understandable by the LLM and stored. In the prompt refinement stage, we employ the multidimensional Chain of Thought (CoT) method to refine the prompts. We verify the proposed framework by conducting experiments using real-world datasets specifically targeting passenger flow forecasting under delay conditions of Shenzhen metro in China. The experimental results demonstrate that the proposed model performs particularly well in forecasting passenger flow under delay conditions.", "sections": [{"title": "INTRODUCTION", "content": "Metro, with its efficient, fast and environmentally friendly features, has become a key tool for easing urban traffic congestion and reducing environmental pollution. The operational efficiency of the metro system directly affects the daily travel of urban residents and the operational efficiency of the city. metro delays, such as those caused by equipment failures, extreme weather, traffic accidents, or large-scale social events, are frequent and unpredictable, and have a serious impact on safety, service efficiency, and the operation of the entire urban transportation system. These delay events not only disrupt the normal operation of the transportation system, but also cause fluctuations in passenger flow, which can have a significant impact on the passenger experience and transportation organization. For example, extreme weather conditions may lead to the temporary closure of multiple metro stations, major traffic accidents may cause prolonged line blockages, and large-scale social events may lead to a spike in passenger traffic in certain areas. All these scenarios require more flexibility and accuracy in traffic forecasting systems. In this context, how to accurately predict changes in metro passenger flow when delays occur, and timely adjust the operation plan and resource allocation has become a major challenge for transportation managers. The unpredictability and suddenness of delay events often make it difficult for the rail transit system to respond quickly and effectively, thus affecting the efficiency of emergency response and resource dispatching by transportation management.\nIn addition, in the case of a delay event, the travel behavior of passengers and the distribution of passenger flow will change significantly. Traditional passenger flow forecasting methods based on historical data are often difficult to adapt to these dynamic and complex passenger flow changes, resulting in less accurate forecasts. For example, an unexpected equipment failure may lead to the suspension of service on a major route, forcing passengers to switch to other transportation modes or routes, in which case the original passenger flow pattern will change significantly. Existing passenger flow forecasting models, which are usually based on passenger flow patterns under regular conditions, fail to adequately take into account the impact of such events on passenger flow dynamics.\nCurrently, passenger flow forecasting methods mainly include three categories: traditional statistical learning, traditional machine learning methods, and deep learning methods. In the early days, statistical methods such as ARIMA models (1,2) for time series analysis and vector autoregression (VAR) (3) models were widely used for their efficient handling of small datasets and their utility in short- and medium-term forecasting. These models rely on the statistical properties of historical data to predict future passenger flows, mainly by analyzing trends and seasonal patterns in the data. With the improvement of technology and computational power, traditional machine learning techniques such as Support Vector Machines (SVM) (4) and K-Nearest Neighbor (K-NN) (5,6) are beginning to be applied to passenger prediction, gaining attention for their powerful ability to handle high-dimensional data and capture complex nonlinear relationships in passenger data. These methods improve the accuracy and efficiency of prediction by learning decision boundaries or patterns from data. Moving deeper into the deep learning era, methods for passenger prediction have become more diverse and powerful. Deep learning models such as Convolutional Neural Networks (CNNs) (7) and Recurrent Neural Networks (RNNs) (8) are becoming mainstream due to their advantages in handling large-scale datasets and complex model structures. CNNs efficiently capture spatial dependencies through their convolutional layers, while RNNs optimize the processing of time series data. These models not only improve prediction accuracy, but are also able to handle the nonlinear and high-dimensional nature of traffic data. Despite the success of CNNs and RNNs in the field of passenger prediction, they still have limitations in dealing with non-Euclidean-structured data. At this point, Graph Convolutional Networks (GCNs) emerged with their unique advantages in dealing with graph-structured data (9). GCNs provide a new approach for modeling dynamic changes in passenger flow by propagating information among nodes and being able to capture complex spatial dependencies and network structural properties. However, GCN often encounters the problem of excessive smoothing when dealing with global spatial patterns, limiting its ability to capture long-range dependencies. To overcome these limitations, attention-based models, such as Transformer (10), have been introduced to passenger flow prediction. These models are able to model dynamic dependencies in time and space more flexibly through a dynamic attention mechanism"}, {"title": "RELATED WORK", "content": "In this section, we review two aspects of related work, one on models related to passenger forecasting, and the other on LLMs.\nModels Related to Passenger Flow Forecasting\nTraditional statistical learning methods, such as ARIMA models and exponential smoothing, have long been used to work with linear time-series data. They rely on the statistical properties of historical data to predict upcoming traffic flows. By capturing the time-dependent and seasonal patterns inherent in traffic data, these methods provide a solid foundation for short- and medium-term traffic forecasting. These methods perform well in terms of stability and explanatory power, but are typically only applicable to relatively simple forecasting problems. With the development of data science, machine learning methods such as support vector machines (SVMs) and decision trees have been introduced to the field of traffic prediction, providing the ability to deal with nonlinear problems.While traditional machine learning\nLarge Language Models\nThe application of LLMs in traffic prediction is an emerging research area, e.g., Transformer-based GPTs (13) contain billion-level parameters and extensive contextual understanding on massive datasets through pre-training on large-scale corpora, and they utilize their powerful linguistic modeling capabilities to process traffic data (e.g., traffic flow, delay information, etc.), which have made excellent progress so far. For example, TEST, proposed by Sun et al. (14) activates the ability of LLM to process time series data by transforming them into LLM-compatible representations, and in particular, enables LLM to better accept the embedding of these data by creating soft prompts. Similarly, TEMPO, proposed by Cao et al. (15) effectively learns time series representations by decomposing time series data into three components: trend, seasonality and residuals, and utilizing soft prompts to guide the model to adapt to different types of time series data. In addition, TrafficGPT, proposed by Zhang et al. (16) creates a novel system capable of processing and analyzing traffic data, providing insightful decision support, and assisting humans in traffic control decision making through natural language conversations by combining ChatGPT with a traffic base model. The study of Xue et al. (17) improves traffic control decision making based on the development of a new prompt-mining framework by developing a new language-based passenger mobility prediction. The framework employs language modeling to transform numerical data into natural language sentences to predict passenger mobility. The study breaks through the limitation of fixed templates in traditional methods and improves the accuracy and efficiency of prediction by dynamically generating and refining prompts. Further, Liang et al. (18) focuses on the utilization of LLMs for passenger flow prediction in the context of public events. They proposed a framework based on LLMs (LLM-MPE) to process and predict changes in pedestrian flow demand due to public events. This study first converted unstructured event descriptions obtained from online sources into a standardized format,"}, {"title": "METHODOLOGY", "content": "In this paper, we propose a new approach to metro passenger flow prediction under delay events using LLMs. Our goal is to develop a passenger flow prediction model that can combine delay data information with history metro passenger flow data to predict passenger flow. In the following sections, we provide a comprehensive overview of our approach. First, we describe the problem statement. Then, we present the overall framework of the model, focusing on generating and refining effective prompts, which is crucial for LLM models, As shown in Figure 1.\nProblem Statement\nMetro delays refer to deviations of the metro running time from the scheduled timetable, which are caused by a variety of reasons including, but not limited to, technical failures, emergencies, weather effects, human factors, and maintenance work. The objective of this study is to use historical passenger flow information as well as information on delay events to predict access to delay-affected stations in the subway network, which is a type of spatial-temporal prediction problem. In our research framework, we focus on predicting the metro traffic flow at a future time step. Specifically, the traffic flow prediction problem can be formulated as predicting future flow values based on available historical data, which can be expressed by the following equation:\n${Xt+1, Xt+2, ..., Xt+u} = F{(Xt-d+1, \u2026, Xt\u22121, Xt), A, E}$                         (1)\nHere, the function $F(\u00b7)$ is an LLM model for passenger traffic forecasting that learns the mapping relationship between inputs and outputs and predicts the traffic attributes for the next $u$ time steps based on the flow attributes for the past $d$ time steps. $Xt+1, Xt+2, \u2026, Xt+u$ represent successive future predicted values and $Xt-d+1, ..., Xt\u22121, Xt$ represent continuous historical observations. $A \u2208 R^{n\u00d7n}$ denotes the binary adjacency matrix that only contains 0 and 1, where $n$ is the number of orbital stations. $E \u2208 {ET, EL, EH}$ represents the subway delay event information, where $E_T$ represents the time of the delay event, $E_L$ represents the metro line where the delay event occurs, and $E_H$ represents the specific textualized representation of the subway delay event.\nOverview\nIn this section, we elaborate two phases, namely the systematic prompt generation phase, and the prompt refinement phase. In the prompt generation phase, complex temporal and spatial traffic data and delay event information are transformed into a textual information format that can be understood by the model, followed by the prompt refinement phase, where we refine the prompt templates and input and output prompts through a well-designed incorporation of CoT in order to motivate step-by-step inference of the model and improve the accuracy and reliability of the predictions. The final model outputs the prediction results in JSON format.\nSystematic prompt generation phase\nIn this framework, the systematic prompt generation phase is the key starting point, and the inputs to the LLM model are the first step in the prompt generation phase and are responsible for covering all the relevant information. In this study, the inputs to the model are divided into three main parts: the inputs of delay event information, the inputs of historical passenger flow data, and the inputs of the adjacency matrix. The input of delay event information mainly includes a detailed description of the comprehensive information about the train delay event, which mainly includes: the type of fault that caused the delay (train faults, signaling faults, power supply faults, and other types of faults), the specific time of occurrence (date and moment), the location (specific stations as well as line segments), and the expected scope of impact of the delay (number of stations and line segments affected). The inputs of historical passenger flow data include inflow as well as outflow at all stations on all subway lines, allowing historical passenger flow data to be collected for similar time periods as the delay event, in order to provide sufficient background information for the model as well as a basis for comparison. The inputs to the adjacency matrix reveal direct connections between stations, allowing LLM to better learn about the relationships between stations that interact with each other and their potential impact on changes in passenger flow. Since the above model inputs are not yet systematized, it is difficult for the LLM to accurately understand the task and follow up on them, so we next aggregated the above inputs into a repository of information that prepares the LLM to analyze and understand the inputs, and to generate the appropriate prompts. Subsequently, the LLM analyzes and extracts the inputs from the information database in depth, and converts the complex input data into systematic descriptive text that can be understood by the LLM. At this stage, we make it generate a large number of systematized descriptive texts through instructions to build a library of templates for generating prompts.\nPrompt refinement phase\nIn this framework, the prompt refinement phase is an important step to improve the prediction performance of LLM models. In the prompt refinement phase, the main task is to fine-tune the design of the prompts by incorporating CoT to enhance the reasoning ability and prediction accuracy of LLM. The core of this phase is to refine the input prompts as well as the command output prompts in order to better guide the model for deep logical reasoning and accurate prediction.\nWe perform an initial screening and modification of the descriptive text created in the systematic prompt generation phase. By evaluating the logical clarity as well as the predictive power of each prompt, we can filter out the prompt words that can effectively trigger the LLM to perform more correct reasoning and prediction. In this process, we value the accuracy and completeness of each prompt in describing the"}, {"title": "Passenger flow forecasting under delay conditions via LLM", "content": "When predicting passenger flow, the process is mainly divided into two stages: the training process and the testing process. We train the LLM to adapt to passenger flow forecasting tasks under delay conditions. During the model training process, we continuously record the impact of different prompt templates on the accuracy of passenger flow predictions. In the testing process, we fill data information into the generated and refined prompt templates, which serve as input prompts for the LLM, in order to validate the effectiveness of the refinement methods. The results of the predictions are output in JSON format for subsequent evaluation of forecasting performance."}, {"title": "EXPERIMENTAL SETTINGS AND RESULTS", "content": "In this section, we will first describe our experiments, which include the datasets we used, the evaluation methods we employed, the baseline models we compared them to, followed by the results of our experiments.\nDataset Description\nIn order to validate our large language-based model for predicting metro passenger flow under delay events, the historical passenger flow dataset and delay event data used in this study were selected for experiments.\nHistorical passenger flow dataset\nThe data used in our experiments come from the AFC system of Shenzhen Metro Company in China, and the time span of Shenzhen Metro AFC swipe data is from August 5 to September 26, 2019, a period of 53 days, which includes 8 lines and 166 stations of Shenzhen Metro as of 2019. Each row of this AFC dataset represents a passenger's card swipe transaction, which includes information such as date and time of card swipe, type of entry and exit, device code, metro line, and line station,\nDelayed event dataset\nThe delay event dataset provides detailed information on 15 failure events that occurred from August 1, 2019 to September 30, 2019 for a variety of reasons. The delay event dataset records information about the type of fault, time of occurrence, detailed fault description, and impact on train operations for each delay event\nEvaluation Metrics\nThe most common metrics evaluated in passenger flow forecasting tasks include Root Mean Square Error (RMSE) and Mean Absolute Error (MAE). These two metrics provide quantitative measures of the performance of the prediction model, where RMSE gives more weight to large errors and MAE treats all error sizes equally. These two metrics are chosen for the performance evaluation of our experiments, with the following formulas:\n$RMSE = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (Y_i - \\hat{Y}_i)^2}$                                       (2)\n$MAE = \\frac{1}{n} \\sum_{i=1}^{n} |Y_i - \\hat{Y}_i|$                                         (3)\nWhere $n$ signifies the total number of samples, $y_i$ denotes the true value of passenger flow, and $\\hat{y}_i$ denotes the predicted value of passenger flow.\nBaseline Models\nWe have selected some representative models in the field of passenger flow prediction as Baseline Models, which are:\nARIMA: A classical statistical model for time series forecasting.\nSVR: A machine learning method for regression analysis that uses SVM to predict continuous values.\nLSTM: A classical RNN variant with memory gating mechanism.\nGC-LSTM (20): A spatio-temporal prediction model combining GCN and LSTM.\nInformer (21): A variant of the Transformer model incorporating the Probabilistic Sparse (ProbSparse) self-attention mechanism.\nCase Study\nOur experiments were conducted using the well-known GPT-4 developed by OpenAI, focusing on the passenger inflow and outflow under the delay events from September 18 to September 26, 2019, due to the multiple delays that occurred during train movement in the interval during that period, and the multiple occurrences on September 26 in Shenzhen Metro Line 1 due to power supply failures as well as train failures on that day alone On September 26, there were a number of train delays on Shenzhen Metro Line 1 due to power supply failures and train breakdowns, of which Airport East Station, as the final arrival station for many of the affected trains on Metro Line 1, experienced significant delays in final arrival times due to train delays and breakdowns. In addition, our study focuses on the passenger flow forecast for Airport East Station on the morning of September 26, as the breakdowns were concentrated in the morning of September 26th. We use the historical passenger flow data and delay event information from August 5 to August 31, 2019, as the training set, and the dataset from September 1 to September 26 as the testing set.\nResults\nOur experimental prediction results are shown demonstrating the performance of different models in predicting passenger outflow under delayed conditions, where P1 is the prediction model for passenger flow in the prompt generation phase of our experiment, and P2 is the prediction model after our well-designed prompt refinement phase. We can directly observe that the P2 model refined by our prompts, compared with the P1 model without prompt refinement, can reflect the prediction performance improvement in both evaluation indexes, which verifies the effectiveness of the prompt refinement method. Combined with the baseline model specifically, traditional models such as ARIMA and SVR have poorer prediction performance due to the fact that these methods can only extract simple linear relationships of the data, and it is difficult to effectively capture the complex nonlinear relationships in the nonlinear passenger flow data. Based on deep learning LSTM, GC-LSTM and Informer models perform better in the prediction task compared to traditional models, especially GC-LSTM, which performs well in both RMSE and MAE, this is due to the fact that GC-LSTM can more effectively deal with spatio-temporal data with complex spatial structure and time dependence, and the traffic changes between neighboring locations often have strong correlations, and GC-LSTM is able to model such proximity effects through graph convolution operations. The prediction performance of our proposed model, the preliminary P1 model, already outperforms the conventional model in terms of RMSE and MAE, which demonstrates that the prediction method based on large language modeling has potential and is worth exploring in depth. However, the preliminary P1 model has obvious shortcomings compared to GC-LSTM, which is due to the fact that the initially generated prompt word templates are structured but not yet refined, so the prediction performance has shortcomings compared to GC-LSTM. The P2 model, which has been refined in many ways, has significantly improved its prediction performance, with the"}, {"title": "CONCLUSIONS", "content": "In this study, we propose a refinement-based passenger flow prediction method based on large language models (LLMs), especially for passenger flow under delay events. We introduce a two-stage process, including a systematic prompt generation phase and a prompt refinement phase, which enhances the model's comprehension and reasoning ability in delay situations by systematically processing complex traffic temporal and spatial data as well as delay event information. Specifically, for the prompt generation phase, this study transforms multi-source data into descriptive text that can be understood by the LLM and builds an information repository to summarize the data as well as the descriptive text. In the prompt refinement phase, we combined the Chain of Thought (CoT) method to further improve the model's prediction performance under the influence of delay events by refining the prompt words in multiple dimensions. Thereafter, by conducting comparative experiments, we verified that the performance of our passenger flow prediction method under the influence of delay events has significantly improved compared with the baseline model. Besides, the comparison experiments also reflect the model performance enhancement before and after prompt word refinement, which is a strong proof of reflecting our prompt word refinement framework. In order to further improve the ability of LLMs-based metro passenger flow prediction under delay conditions, future research can consider more information about external factors, such as large-scale events, social media data, weather data, etc., to assist the LLMs model's more comprehensive understanding ability. In addition, a more in-depth study of the design and refinement strategies of prompt words and exploring more refinement methods are challenging topics for future research."}]}