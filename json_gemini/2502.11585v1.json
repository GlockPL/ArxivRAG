{"title": "Calibration of Vehicular Traffic Simulation Models by Local Optimization*", "authors": ["Davide Andrea Guastella", "Alejandro Morales-Hern\u00e1ndez", "Bruno Cornelis", "Gianluca Bontempi"], "abstract": "Simulation is a valuable tool for traffic management experts to assist them in refining and im- proving transportation systems and anticipating the impact of possible changes in the infrastructure network before their actual implementation. Calibrating simulation models using traffic count data is challenging because of the complexity of the environment, the lack of data, and the uncertainties in traffic dynamics.\nThis paper introduces a novel stochastic simulation-based traffic calibration technique. The novelty of the proposed method is: (i) it performs local traffic calibration, (ii) it allows calibrating simulated traffic in large-scale environments, (iii) it requires only the traffic count data. The local approach enables decentralizing the calibration task to reach near real-time performance, enabling the fostering of digital twins. Using only traffic count data makes the proposed method generic so that it can be applied in different traffic scenarios at various scales (from neighborhood to region). We assess the proposed technique on a model of Brussels, Belgium, using data from real traffic monitoring devices. The proposed method has been implemented using the open-source traffic simulator SUMO. Experimental results show that the traffic model calibrated using the proposed method is on average 16% more accurate than those obtained by the state-of-the-art methods, using the same dataset. We also make available the output traffic model obtained from real data.", "sections": [{"title": "Introduction", "content": "City administrations aim at sustainable development, where reducing the human footprint is a priority. Tackling sustainable development in densely urbanized environments poses the challenge of driving disruptive changes in complex environments. A major challenge in the traffic domain is providing traffic management experts with smart methods to analyze and evaluate traffic policies and avoid congestion, a major cause of CO2 emissions [1]. On the one hand, the impact of the control strategies on road infrastructures is not observable until they are deployed in the real world [2]. On the other hand, test- ing control strategies in real-life settings are expensive, risky, and often unfeasible [3]. In this context, urban traffic simulation models have become an indispensable asset, providing an in-silico environment where it is possible to design and assess alternative control strategies before the deployment. The most important requirement for a traffic model is its realism. If the dynamics of simulated traffic are close to reality, then traffic management experts can reliably assess the consequences of control strategies in the real world [4].\nThis paper addresses the problem of estimating traffic simulation models using traffic count data acquired from traffic monitoring devices. We propose a local optimization method that calibrates the simulated traffic to match the input traffic data as much as possible. First, we partition the city network into a set of non-overlapping regions, where a region delimits a part of the road network. We create simulated vehicles starting from each region. The number of vehicles is progressively calibrated to minimize the difference between the real and simulated traffic. Although our proposal can be implemented"}, {"title": "Motivation", "content": "The intuition behind the local calibration is to constrain both in space and time the task of calibrating the traffic to the observed data. This is challenging, as the calibration problem is underdetermined [5]: the available data can be used to define a virtual representation of traffic that is faithful to input information but not to the real dynamics of traffic [6]. Our objective is to estimate traffic that matches the input data, without necessarily ensuring the accuracy of vehicle trajectories considering the real traffic demand or addressing uncertainties deriving from traffic counts.\nBy isolating parts of the road network, it is possible to vary traffic parameters locally, analyze the local error, and evaluate the impact of local parameters on nearby regions. A further motivation to perform local traffic calibration is related to computational advantages, as it is possible to distribute the load of the traffic calibration over different computational modules, one for each region and time interval. This is effective when considering traffic count data streams in large-scale environments."}, {"title": "Related Work", "content": "The implementation of realistic traffic simulation models has been addressed from different perspectives and has employed various strategies to enhance model accuracy, scalability, and applicability in diverse urban settings. Sha et al. [7] propose a Bayesian optimization framework for the calibrating problem of traffic simulation models. Bayesian optimization is an approach to optimize expensive objective functions. Hence, the benefits of the suggested calibration method because traffic simulations are generally expensive in terms of simulation time and resource consumption. The key idea of Bayesian optimization is to choose more promising values for future evaluation based on previous results. This is achieved by constructing a surrogate model which is a probability model of the original objective function and is easier to optimize (i.e. it is computationally efficient). The proposed method calibrates simulation parameters such as the vehicles' maximum speed, acceleration, deceleration, and minimum gap after the leading vehicle for four types of vehicles, resulting in 16 parameters to be calibrated (one per vehicle type). The objective function to minimize is the sum of the root mean square percentage error (RMSPE) of traffic count and speed. The authors validate their proposal using a model of a section of the New Jersey Turnpike and compare their results to those obtained by the Simultaneous Perturbation Stochastic Approximation (SPSA), a stochastic approximation algorithm well suited for optimizing functions involving a high number of parameters. The minimum value of the objective function achieved using Bayesian optimization and SPSA is 6.87% and 7.41%, respectively. While Bayesian optimization guarantees good results when considering several variables in a large-scale scenario, the SPSA technique showed convergence issues [8]. In addition to the inherent limitations of Bayesian optimization-based methods (e.g., computational complexity is proportional to the number of observed points), the primary drawback of this study is in the actual problem design. Since the authors optimize several parameters for four different vehicle types, they do not consider the traffic dynamics observed throughout the day. Therefore, the calibrated model uses the same parameter values for each vehicle without considering that these may be different at different times. Furthermore, the authors do not consider the number of vehicles entering/leaving the simulation in the area of study. This can have an impact on the traffic counts seen throughout the simulation, ultimately lowering the performance indicator used as the optimization objective.\nA more realistic approach to calibrate traffic simulation scenarios is to tune the traffic demand as the set of vehicle trips (or routes) from origin to destination that are produced on a road during a specific period. Gonzalez-Delicado et al. [9] propose a method to create simulated traffic from traffic"}, {"title": "Problem Statement", "content": "Let $\\mathcal{R} = {\\rho_1, \\rho_2,..., \\rho_k}$ be a set of k regions and $\\mathcal{T} = {t_1,t_2,..., t_l}$ the set of l time instants (in seconds) when the traffic data is aggregated. We define the calibration problem as the minimization of the differences between the real and simulated amount of vehicles observed in each region and time interval:\n$\\argmin_{M} \\sum_{i=1}^{l-1} \\sum_{j=1}^{k}|y(\\rho_j, \\delta_i) - \\hat{y}(\\rho_j, \\delta_i; M)|$ (1)\nwhere $\\delta_i = (t_i, t_{i+1}), 1 < i < l$ is a time interval, $y(\\rho_j, \\delta_i) > 0$ is the average real traffic observed in the region $\\rho_j$, during the time interval $\\delta_i$, $\\hat{y}(\\rho_j, \\delta_i; M) > 0$ is a function that takes in input the traffic model M, the region $\\rho_j$ and the time interval $\\delta_i$, and returns the average amount of simulated vehicles observed in the region $\\rho_j$ during time interval $\\delta_i$.\nWe use Equation 1 to measure the global accuracy of the traffic model. During the calibration process, the difference $|y(\\rho_j, \\delta_i) - \\hat{y}(\\rho_j, \\delta_i; M)|$ is calculated for each region and time interval, and it is used to adjust the amount of local traffic in the simulation."}, {"title": "Proposed Method", "content": "The proposed technique aims to estimate a traffic model M that minimizes the difference between real and simulated traffic counts. Herein, estimating a traffic model refers to constructing a set of routes that are associated each one to a vehicle and a starting time. The amount of traffic observed in the simulation should match the input data in the same points where real traffic is observed. To achieve this, the calibration process iteratively regulates the amount of vehicles and adjusts the routes to minimize the difference between real and simulated traffic counts. While our method does not estimate OD matrices (a computationally intensive task for high-dimensional problems) the resulting estimated routes can be used to infer origin-destination pairs.\nWe begin by partitioning the environment into a set $\\mathcal{R}$ of non-overlapping regions. Each region contains the edges that intersect the most with the polygon of the region. Mobility is strongly influenced by the morpho-spatial reconfiguration of cities, resulting in different mobility patterns. The goal of dividing the environment into regions is to capture mobility patterns across neighborhoods and calibrate traffic based on the physical characteristics of the urban landscape. The shape of regions is arbitrary. These can be modeled according to the administrative boundaries, or socio-economic indicators. The choice of shape can lead to the emergence of mobility patterns related to the properties of the urban environment.\nAfter separating the environment in regions, we create simulated traffic in each region. First, we create a regional route for each vehicle by exploiting the local calibration error (average difference between real and simulated traffic counts). A regional route is defined as an ordered sequence of regions where a vehicle travels to reach its destination. A regional route $\\Phi$ can be defined as [18]:\n$\\Phi = (\\rho_1,..., \\rho_k), k \\leq |\\mathcal{R}|$ (2)\nwhere $\\rho_1$ and $\\rho_k$ are respectively the vehicle's origin and destination regions. Then, we allocate a vehicle to the regional route, and perform a route assignment procedure to evaluate the edges, in each region in $\\Phi$, that allows the vehicle to reach its destination.\nWe iteratively adjust the traffic model M to match the real traffic count data. Because the impact of vehicles in a congested road network cannot be anticipated, we perform several simulations and regulate at each iteration the vehicles in the traffic model M so that the resulting traffic counts observed in the simulation match the real ones. We calculate the error between the real and the simulated traffic counts to evaluate our proposal. The traffic calibration is iterated for a fixed number of times until there is no improvement in the objective function (Equation 1).\nFollowing, we list the parameters required by the proposed calibration technique:\n\u2022 Initial traffic: the traffic model M to calibrate.\n\u2022 Stopping criterion: the stop condition for the calibration algorithm."}, {"title": "Traffic Model Initialization", "content": "The first step of the proposed method is to initialize the traffic model M to calibrate. The traffic model can be initialized using a calibrated model from a different day, using a model created according to the number of vehicles in the input dataset, or randomly. In the following, we introduce a procedure to randomly initialize the traffic model M. For the sake of simplicity, we do not consider regional routes to create the initial random traffic model. This is adjusted in the subsequent calibration phase.\nAt each instant t, we calculate the number of vehicles present in the simulation. Let $\\gamma$ be the expected total number of vehicles that must be present in the simulation at each time instant. If the number of vehicles in the simulation is less than $\\gamma$, then new vehicles are added to the simulation until the number of vehicles in the simulation is equal to $\\gamma$. The number of vehicles in the initial traffic definition affects only the speed at which the proposed calibration method converges. Thus, we consider $\\gamma$ a parameter required by the proposed calibration technique when the initial traffic model is created randomly.\nTo create simulated vehicles, we first choose randomly the origin and destination edges from the road network, then build a route using the Dijkstra algorithm [19]. The search graph corresponds to the road network, where the junctions are the vertex, and the roads are modeled as edges of the graph. The Dijkstra algorithm outputs a route, consisting of an ordered set of edges in the road network. In the Dijkstra algorithm, the edges are discriminated by their weight. We use the edge travel time to assign a weight to each edge [20]. This is estimated by dividing the road length by the maximum allowed speed on the edge:\n$\\lambda(e) = \\frac{l(e)}{s_{max}(e)}$ (3)\nwhere $l(e)$ is the length of the edge e, $s_{max}(e)$ is the maximum allowed speed on edge e.\nThe output of this step is a traffic model M where each vehicle is associated with a unique identifier, a starting time, and a route. For the sake of simplicity, we do not consider the traffic light programs, the car-following model (describing the speed of cars as a function of their leading cars' position), the intersection model (determining the behavior of vehicles at the intersections), and the lane-changing model (determining the lane choice in a multi-lane road). Then, the traffic simulator outputs the number of vehicles observed in the same points where the traffic monitoring devices (and where the input traffic counts were obtained to calibrate traffic) are situated in reality."}, {"title": "Traffic Model Calibration", "content": "We calibrate the traffic model M obtained from the previous step so that simulating the set of vehicles in M minimizes the difference between simulated and real traffic counts (Equation 1). Algorithm 1 lists the steps of the proposed calibration technique. This operates iteratively by calibrating the traffic model and evaluating it through simulation. This is because it is impossible to anticipate the effect of vehicles in a congested road network.\nThe algorithm takes as input a set $\\mathcal{R}$ of regions, the traffic model M, a set of time intervals $\\Delta$, and an edge weighting function $\\lambda$. First, the algorithm computes the average traffic error $\\epsilon_p$ for each region $\\rho \\in \\mathcal{R}$ during the time interval $\\delta_i = [t_i, t_{i+1}]$ using the traffic model M (line 6). Then, we calculate the amount $d_p$ of vehicles to add or remove from the region $\\rho \\in \\mathcal{R}$, considering the error from the previous calibration iteration. This error is calculated as the difference between the average of the real and the simulated traffic counts in the region $\\rho$, multiplied by a convergence rate q (line 7). The value of q affects"}, {"title": "Complexity Analysis", "content": "Analyzing the complexity of Algorithm 2, line 12 is executed $\\beta * m$ times, with a complexity of $O(\\beta * m)$ following the Big O notation for the worst case, where $\\beta$ corresponds to the computational complexity of Dijkstra's algorithm and m the regional route length. Following the complexity analysis in the worst case, the complexity of this code section dominates the complexity of the whole algorithm (w.r.t. the complexity of line 8 O(m) and block of lines 4-7 O(m)). Hence, we can assume that the computational complexity of adding a vehicle is directly related to the length of the regional routes and the computational complexity of Dijkstra's algorithm. As a result, the complexity of addressing traffic underflow in Algorithm 1 (lines 15-17) is $O(\\beta* m * log(under flow_p))$, where $under flow_p$ corresponds to the underflow error (the number of vehicles we must add) for region p and it is assumed to decrease over time (hence the logarithmic scale). Given that addressing traffic overflow only means removing vehicles from the traffic model, its computational complexity $O(log(overflow_p))$ is much less than the complexity of treating traffic underflow. Consequently, the computational complexity of the block of lines 5-21 in Algorithm 1 is $O(l * k * \\beta * m * log(under flow_p))$ which represents addressing traffic underflow on each region (k in total) and on each time interval (l in total) in the worst case. Lastly, the computational complexity of the complete calibration process can be represented as $S * O(max{l * k * \\beta * m *log(under flow_p), SIMM})$, where S is the number of iterations and SIMM corresponds to the time needed by the algorithm to perform a traffic simulation with a given model M.\nIn expensive black-box settings, such as traffic calibration where the simulation is typically assumed to be a black box, the computational complexity of an optimization algorithm can be evaluated through the worst-case expected running time [21]. Then, the running time (or optimization time) of an algorithm for a given function f can be measured by the number of function evaluations that the algorithm performs until (and including) the evaluation of an optimal solution for f. Considering this in the context of traffic calibration algorithms, we can assume that performing a traffic simulation will be always the most complex and demanding task during the calibration. Therefore, the overall complexity of the calibration can be summarized as $S * O(SIMM)$ and it is directly related to the number of traffic simulations performed during the calibration.\nA similar analysis can be performed for the space complexity of the algorithm. The space complexity of Algorithm 2 is dominated by the space complexity of the Dijkstra algorithm, and the space needed to allocate the route of the new vehicle added to the model. The former can be assumed constant since the traffic network does not change during the calibration. However, the latter changes depending on the regions and pivot edges selected to make the regional route. The generated route is added to the model by keeping a record of all the routes obtained for each of the vehicles in the model. For algorithm 1, the space complexity is mainly dominated by the objective evaluation at line 22 which requires loading the real values and the simulation results, hence a space complexity of $2 * l * k^2$, where l is the number of time intervals and k the number of regions. Adding or removing vehicles from the traffic model depends only on the traffic underflow or overflow respectively, and the result is reflected in the XML route files used as input for the simulation. This property demonstrates the advantage of our proposal given that it is a well-known challenge dealing with large and sparse OD matrices to perform the traffic calibration."}, {"title": "Experimental Design", "content": "This section presents the results obtained by the proposed traffic calibration technique. First, we describe the scenarios and the error metrics used to evaluate our proposal. Then, we provide details on the results of the calibration technique and compare them to those obtained by one technique available with the SUMO simulator, and by a calibration technique based on a standard optimization method.\nAll experiments have been carried out on a server machine equipped with Intel Xeon Gold 6242 processors, and Linux operating system (kernel version 4.15). We do not consider any particular opti- mization technique to perform parallel computation. The proposed method calibrates traffic sequentially in each time slot. Contrarily, in the SPSA-based method the traffic in each time slot is calculated inde- pendently from the other. However, in the case of the latter method, the temporal correlation of traffic between consecutive time slots is not guaranteed."}, {"title": "Scenario Description", "content": "We evaluate the proposed technique on a model of the city of Brussels (Belgium). The modeled area includes mostly primary roads (including the inner ring\u00b9), secondary and tertiary roads. For creating the road network model in SUMO, we first extract the area of interest using OpenStreetMap (OSM) and then, we use the tools available with SUMO to convert the OSM map into a convenient format that the simulator can use."}, {"title": "Simulation Tool", "content": "We use the open-source traffic simulator SUMO. SUMO can be used for microscopic simulation, where each vehicle and its dynamics are modeled individually, and mesoscopic simulation, where the movements of vehicles are modeled with queues and the traffic at intersections is modeled using a coarse model. We configure SUMO with a simplified microscopic model. This is done by simulating partially the behavior of vehicles in the intersections. When simulating traffic without considering the intersections, vehicles are still subject to right-of-way rules (waiting at traffic lights and minor roads) but they will appear instantly on the other side of the intersection after passing the stop line. The vehicles cannot block the intersection, wait within the intersection for left turns nor collide on the intersection. In this work, we model junctions according to a microscopic model if the target queue of vehicles is jammed (that is, the occupancy of the edge is higher than 40%). By using this configuration, the time required to perform a 24-hour simulation did not exceed 11 minutes, considering the Brussels scenario."}, {"title": "Evaluation Metrics", "content": "We evaluate the accuracy of the proposed method using a 3-fold cross-validation: we divide the set of traffic monitoring devices into training (70%) and testing (30%) sets. For each fold, we calibrate the traffic model using the data from the sensors in the training set. Then, we evaluate the performance of the model considering the data collected from the devices in the test set.\nTo assess the performance of the simulated traffic, we evaluate the following metrics to compare the simulated traffic counts to the ground truth (the input data):\n\u2022 Traffic volume: the sum of the number of vehicles in the simulation and the ground truth. This measure is calculated in every region and time interval.\n\u2022 Mean Absolute Error (MAE): the absolute difference between the number of vehicles in the simulation and the real data. This metric indicates the number of vehicles that are exceeding in the simulation compared to the reality. The MAE is calculated using the following formula:\n$MAE(\\hat{y}, y) = \\frac{1}{n} \\sum_{i=1}^{n}|\\hat{y_i} - y_i|$ (5)\nwhere n is the number of traffic monitoring devices, and $\\hat{y}$ and y the simulated and the real traffic volume respectively.\n\u2022 Root Mean Square Error (RMSE): The square root of the sum of the squared differences between the predicted and observed traffic counts, divided by the number of observations:\n$RMSE(\\hat{y}, y) = \\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}(\\hat{y_i}-y_i)^2}$ (6)\nwhere n is the number of traffic monitoring devices, and $\\hat{y}$ and y the simulated and the real traffic volume respectively.\n\u2022 Geoffrey E. Harvers (GEH) statistic: the GEH is used to compare two sets of traffic volumes and can be determined by using the following formula [22]:"}, {"title": "Baseline Techniques", "content": "We compare the results obtained by the proposed technique to those obtained by RouteSampler\u00b3, a tool available with SUMO, and to those obtained by a calibration method based on the Simultaneous Perturbation Stochastic Approximation (SPSA) optimization technique.\nRouteSampler takes as input a random traffic definition and filters the routes to match the real traffic density values. The traffic density is used to indicate the usual amount of traffic that should pass through the edges of the road network. Based on this information, the tool selects the routes from an initial set of trips in such a way that the input traffic density values are matched to the output routes set [23]. We used the default parameters for RouteSampler.\nSPSA is an optimization technique widely employed in scenarios where traditional gradient-based methods are unsuitable because of the high number of variables. SPSA estimates gradients through stochastic parameter perturbations, assessing the objective function at these perturbed positions. By leveraging finite-difference approximations, SPSA explores the parameter space to converge towards the optimal solution. The idea behind SPSA is as follows: let us consider an initial vector for the parameters $\\theta_0$, and set other hyper-parameters such as the step size A, the number of iterations k, and the perturbation scaling factor $a_k$. At each iteration k, SPSA generates a random perturbation vector $\\Delta_k$. The objective function is then evaluated at two points: $J(\\theta_k + c_k\\Delta_k)$ and $J(\\theta_k \u2013 c_k\\Delta_k)$, where $c_k$ is a scaling factor. The next step is to approximate the gradient of the objective function using the perturbation:\n$\\nabla J(\\theta_k) \\approx \\frac{J(\\theta_k + c_k\\Delta_k) \u2013 J(\\theta_k \u2013 c_k\\Delta_k)}{2c_k\\Delta_k}$ (8)\nThen, the parameters are updated using the gradient approximation as follows:\n$\\theta_{k+1} = \\theta_k \u2013 a_k \\nabla J(\\theta_k)$ (9)"}, {"title": "Experimental Results", "content": "Herein, we report the results obtained by the proposed method on the Brussels data acquired the Novem- ber 30, 2023, using regions of size 2000m\u00b2, a re-routing factor of 0.2, and a convergence rate value of 0.15. We calculate the results as the average of the 3-fold validation errors. The results for the remaining days and regions' sizes are available in Appendix B, Appendix C, and Appendix D.\nFigure 2 shows the trend of the objective function over the number of calibration iterations. This is calculated as the average of the value of the objective function over the 50 experiments performed. The objective function tends to converge after a few iterations (about 10), in all the experiments. This indicates that by using the proposed technique, it is possible to compute realistic traffic simulation models in a limited time (minutes). However, few calibration iterations can lead to local optima. By allowing the objective function to increase (therefore, introducing errors) it is possible to escape local optima at the cost of a higher computational time required by the technique."}, {"title": "Discussion", "content": "An important aspect of traffic calibration is having access to data from the real world. Different stud- ies [13, 26] agree that data quality and availability are fundamental requirements in calibrating traffic simulation models. The use of CCTV-based monitoring infrastructures can be an obstacle: cameras cannot be installed in all areas of an urban environment, and data is not always available to the commu- nity [27]. The limitations of the proposed method relate mainly to the available data. The traffic data may be incomplete or subject to errors due to inaccuracies in traffic monitoring devices, which can affect the model's accuracy. Furthermore, there may be gaps in data coverage in areas where these devices are"}, {"title": "Conclusion and Future Works", "content": "This work presents a simulation-based method optimization technique for estimating traffic models from real measurements. Our proposal iteratively calibrates traffic models by removing or adding vehicles so that the difference between the traffic observed in the simulation and the reality is minimized. We use the open-source simulator SUMO for simulating traffic. Compared to the state-of-the-art methods, our proposal does not require pre-calibrated OD matrices, allows calibrating traffic locally in space and time, and ensures temporal coherence of traffic conditions across consecutive time intervals. By performing local optimization, it is possible to identify parts of the environment where the calibration technique outputs less accurate traffic. This information can be used to conduct further analysis in the input data or vary the parameters of the calibration technique to produce an accurate model without interfering with the other regions.\nWe compare the results obtained by our proposal to those obtained by standard calibration methods: one available with SUMO, and one based on the SPSA optimization technique. The results prove that the proposed technique outperforms the two baseline methods.\nIn future works, we will investigate methods to generate simulated traffic based on the attractiveness of places over time and define new mechanisms for calibrating multi-modal traffic, thus taking into account different types of mobility. Also, more data will be provided and released to the community. This will be beneficial to build a collection of scenarios and assess the accuracy of the calibrated model under different traffic days (for instance, comparing all the weekends of week days)."}]}