{"title": "Multi-Output Distributional Fairness via Post-Processing", "authors": ["Gang Li", "Qihang Lin", "Ayush Ghosh", "Tianbao Yang"], "abstract": "The post-processing approaches are becoming prominent techniques to enhance machine learning models' fairness because of their intuitiveness, low computational cost, and excellent scalability. However, most existing post-processing methods are designed for task-specific fairness measures and are limited to single-output models. In this paper, we introduce a post-processing method for multi-output models, such as the ones used for multi-task/multi-class classification and representation learning, to enhance a model's distributional parity, a task-agnostic fairness measure. Existing techniques to achieve distributional parity are based on the (inverse) cumulative density function of a model's output, which is limited to single-output models. Extending previous works, our method employs an optimal transport mapping to move a model's outputs across different groups towards their empirical Wasserstein barycenter. An approximation technique is applied to reduce the complexity of computing the exact barycenter and a kernel regression method is proposed for extending this process to out-of-sample data. Our empirical studies, which compare our method to current existing post-processing baselines on multi-task/multi-class classification and representation learning tasks, demonstrate the effectiveness of the proposed approach.", "sections": [{"title": "Introduction", "content": "In machine learning, multi-output learning is a broadly defined domain [65, 44], where the goal is to simultaneously predict multiple outputs given an input, such as multi-label classification, multi-class classification, multi-target regression, etc. In contrast to conventional single-output learning like binary classification, multi-output learning is characterized by its multi-variate nature, whose outputs exhibit rich information for further handling. Multi-output learning is important for real-world decision-making where final decisions are made by considering and weighting multiple factors and criteria. For example, when applied to college admission, the predicted multi-outputs can represent a prospective student's likelihoods of accepting the offer, needing financial aid, completing the degree, finding a job at graduation, etc. Those outputs are weighted to guide admission decisions though the weights may vary with colleges, majors and years [37].\nHowever, multi-output learning for decision-making faces the challenge of bias and fairness. There is plenty of evidence indicating the discriminatory impact of ML-based decision-making on individuals and groups [51, 20, 11, 9, 56], such as racial bias in assessing the risk of recidivism [27] and gender bias in job advertising [61]. \u03a4o mitigate the bias in machine learning, numerous fairness criteria and algorithms have been proposed [17, 8]. These methods introduce statistical constraints during training or post-process the predictions to ensure fair treatment in accordance with corresponding fairness notions such as Demographic Parity [12, 13], Equality of Odds or Equal Opportunity [31, 7], Strong Demographic Parity [2, 38] and AUC fairness [62, 66, 67]. Nevertheless, almost all existing methods focus on ensuring fairness for binary classification or regression within the context of single-output models. Extending fairness to multi-output settings, such as multi-label/multi-class classification and representation learning remains underexplored and non-trivial.\nA naive approach for multi-output fairness is to apply an existing fairness-enhancing algorithm for single-output models to each output individually. However, removing unfairness in each output may not help reduce the unfairness in the joint distribution of the outputs. Consider a model with two outputs and the distributions of the outputs on two groups are presented in Figure 1(a). The outputs have the same marginal distribution in both groups, so each dimension of the outputs is"}, {"title": "Related work", "content": "The existing methods to achieve algorithmic fairness include three primary categories: 1) pre-processing methods that exclude sensitive features from data prior to training machine learning models [24, 23, 39, 19]; 2) in-processing methods, which attain fairness during the training phase of the learning model [1, 29, 70, 40, 33, 22, 49, 67]; and 3) post-processing methods designed to alleviate unfairness in the model inferences after the learning process [31, 43, 18, 52, 46, 63]. The pre-processing methods are inadequate if the sensitive information can be inferred from the remaining variables. The in-processing methods have high computational cost since they typically require re-training a model when the tolerance of unfairness changes. Our method belongs to the last category, which can be directly applicable to any pre-trained model and thus avoids the high computational cost from re-training a model."}, {"title": "Preliminaries", "content": "We consider a general multi-output machine learning problem, e.g., multi-output classification, multi-output regression and representation learning. Let (X, S) be a random vector, where X \u2208 Rd is the feature vector and S\u2208 S is a sensitive attribute. It is assumed that S = [m] := {1, ..., m}. A sample from the distribution of (X, S) is denoted by (x,s). We denote by f* : Rd \u00d7 S \u2192 Rk a machine learning model learned to generate a k-dimensional output. For example, f* can be a multi-task regression model to predict a vector of continuous values, a multi-class/multi-task classification model that returns the probability of each class/task, or a feature extractor that outputs a high-dimensional vector of an input data such as an image.\nThe focus of this work is not to train the model f*. Assuming f* is already obtained, this paper studies how to measure and improve its fairness using a post-processing method to modify the output f*(X, S). More specifically, given f*, we consider a numerical approach for building a mapping f: Rd \u00d7 S \u2192 Rk that approximates f* but produces an output f(X, S) more fair than f*(X, S). Here, the approximation error is measured by\n\\(R(f) = E||f^*(X, S) \u2013 f(X, S)||^2.\\) (1)\nIf f* performs well for the task it was built for and the performance metric is continuous, a small R(f) also ensures f has a reasonably good performance, too."}, {"title": "Distributional Parity", "content": "Many existing definitions and measures of fairness in literature are task-specific including, for example, demographic parity, equalized odds and equal opportunity [24, 31], which are specific to classification problems. In order to be task-agnostic and model-agnostic, we are interested in the fairness measure that is applied to the distribution of f(X, S) and f*(X, S). A measure of this kind is the strong demographic parity introduced by [2, 38, 15], which essentially indicates that a model f(x, s) is fair only when f(X, s) has the same distribution for any s \u2208 S. Although they only consider a single-output model, their fairness measure also applies to the multi-output case. Next we present their fairness measure formally with the name multi-output distributional parity. This new name helps differentiate it from the traditional demographic parity for binary classification [12]."}, {"title": "Wasserstein Distance and Wasserstein Barycenters of Discrete Distributions", "content": "It is challenging and, sometimes, unnecessary to obtain a model f that exactly satisfies the distributional parity in Definition 1. In practice, a model slightly violating Definition 1 can be acceptable for some applications. To quantify the extent to which a model f satisfies the distributional parity, a statistical distance is often introduced to measure the difference between the distributions of f(X, s) and f(X, s') for any s and s' in S. Following the literature [15, 30], we utilize the Wasserstein distance that conveys the distinction between probability measures by quantifying the expense associated with transforming one probability measure into another.\nDefinition 2 (Wasserstein-2 distance). Let \u00b5 and v be two probability measures on Rk with finite second moments. The squared Wasserstein-2 distance between \u00b5 and v is defined as\n\\(W_2^2(\\mu,\\nu) = \\inf_{\\Upsilon\\in\\Gamma_{\\mu,\\nu}} \\int_{\\mathbb{R}^k \\times \\mathbb{R}^k} ||x - y||^2d\\gamma(x, y)\\) (3)\nwhere \u0393\u03bc,\u03bd is the set of probability measures on Rk \u00d7 Rk such that its marginal distributions are equal to \u00b5 and v, i.e., for all \u03b3 \u2208 \u0393\u03bc,\u03bd and all measurable sets A, B C Rk it holds that \u03b3(A \u00d7 Rk) = \u03bc(A) and \u03b3(Rk \u00d7 B) = \u03bd(\u0392).\nSuppose probability measures \u03bcand v both have density functions and the infimum in (3) is obtained at \u03b3*. There exists a mapping \u03a4\u03bc,\u03bd: Rk \u2192 Rk such that \u03b3* = (Id,T\u03bc,\u03bd)#\u03bc, where # denotes the pushforward operator on measures and Id denotes the identity mapping[58]. Here, \u03a4\u03bc,\u03bd is known as the optimal transport mapping from u to v. With the Wasserstein distance, we can characterize the geometric average of finitely many probability distributions by the Wasserstein-2 barycenter, which will be later used in the measure of unfairness considered in this paper.\nDefinition 3 For probability measures v\u2081, ...,vm and p\u2081, ...,pm such that pi > 0, \u03a3_{i=1}^m Pi = 1, the weighted Wasserstein-2 barycenter is given by\n\\(\u03bd^* = arg\\min_\u03bd \\Psi(\u03bd) := \\sum_{i=1}^m p_iW^2(\u03bd_i,\u03bd)\\) (4)"}, {"title": "Post-processing with Distributional Parity Constraint", "content": "Let ps = P(S = s) and vf|s be the probability distribution of f(X, S) conditioning on S s for s\u2208 S. Following [16], we then measure the unfairness of model f by the sum of the weighted distances between Vf|s to their weighted Wasserstein-2 barycenters, namely,\n\\(U(f) = \\min_\u03bd \\sum_{s \\in S} p_s W^2(v_{f|s}, \u03bd).\\) (5)\nAs Wasserstein-2 distance serves as a distance metric on the space of probability distributions, W2(vf\\s, vf\\s') = 0 if and only if vf\\s = vf\\s' [41, 53]. Hence, U(f) = 0 if and only if for any s, s' \u2208 S,vf\\s = vf|s', satisfying the distributional parity. However, when some level of unfairness is allowed, we only need to ensure U(f) \u2264 \u03b1U(f*), where \u03b1 \u2208 [0, 1] represent the tolerance of unfairness"}, {"title": "Structure of Optimal Solution", "content": "Problem (6) has been thoroughly studied by [15, 16] under the setting that f is a single-output model. They provide an intuitive closed form of the optimal solution of (6) for any \u03b1 \u2208 [0, 1] using the cumulative density function (CDF) of vf*\\s for each s. As they only focus on a single-output model, we extend their results to the multi-output case with some modifications in their proofs. We present the extension of their results in this section and highlight the main difference.\nWhen \u03b1 = 0 in (6), the optimal solution of (6) can be characterized by the following theorem.\nTheorem 1 (Extension of Theorem 2.3 in [15]) Suppose vf*\\s has density and finite second moments for each s \u2208 S. Then\n\\(\\min_{U(f)=0} R(f) = \\min_\u03bd \\sum_{s \\in S} p_sW^2 (v_{f^* \\vert s}, v) = U(f^*).\\) (7)\nMoreover, if fo and vo solve the first and second minimization in (7), respectively, then vo is the distribution of fo and\n\\(f_o(x, s) = T_{f^*\\vert s, v_0} (f^*(x, s))\\)\nwhere Tf*|s,vo : Rk \u2192 Rk is the optimal transport mapping from vf*\\s to vo.\nBy Definition 3, vo solving the second minimization in (7) is the barycenter of {Vf*\\s}ses. This suggests a post-processing method by transporting the output f* (X,S) when S = s to that barycenter.\nWhen k = 1, Theorem 1 is reduced to the structural results obtained by [15, 30] (see, e.g., Theorem 2.3 in [15]). Indeed, when k = 1,\n\\(T_{f^*\\vert s, v_0} (f^*(x, s)) = \\sum_{s' \\in S} p_s' \\frac{Q_{f^*\\vert s'}}{F_{f^*\\vert s}}(f^* (x, s)),\\)\nwhere Ff*is is the CDF of vf*|s and Qf*|s is the quantile function vf*|s, i.e., Qf*|s(t) = inf{y \u2208 R : Ff*\\s(y) \u2265 t}.\nIn practice, when some level of unfairness is acceptable, one can select \u03b1 > 0 in (6). When \u03b1 = 1, f = f* is the optimal solution. When \u03b1 \u2208 (0, 1), a closed form of the optimal solution for (6) is derived by [16, 41]. Although they are originally studied only under the single-output case, the same result holds for a multi-output model by almost the same proof. This closed form is presented in the following proposition, which motivates the way of trading off the error and fairness in our post-processing method in the next section.\nProposition 1 (Proposition 4.1 in [16]) Suppose vf*\\s has density and finite second moments for each s \u2208 S. For any \u03b1 \u2208 [0,1], the optimal solution to (6), denoted by f\u03b1, satisfies (up to a zero-measure set)\n\\(f_\u03b1(x, s) = \\sqrt{\u03b1}f^*(x, s) + (1 - \\sqrt{\u03b1})f_o(x, s),\\) (10)\nwhere fo is defined in Eq. (8)."}, {"title": "Fair Post-Processing with Finite Samples", "content": "Theorem 1 and Proposition 1 only characterize the optimal solution to (6) when vf*is has density. However, in practice, we only have access to a finite set of outputs of f*, denoted by {f*(xi, si)}i=1n, where {(xi, Si)}i=1n is a dataset sampled from the distribution of (X, S). As a result, we are not able to compute vo and Tf*\\s,vo exactly and apply (10). To address this issue when k = 1, a plug-in principle is applied by replacing ps, Ff*\\s(t), and Qf*\\s(t) in (9) using their empirical approximation based on finite data sample[15, 30]. Because f* is a multi-output mapping in our case, (9) is not applicable. That said we can still employ the plug-in principle by approximating vo and Tf*|s,vo in (8) by finite data sample."}, {"title": "Approximate Barycenter", "content": "Consider approximating vo and Tf*\\s,vo by a collection of datasets Ds = {(x_i,s)}i=1^{n_s} for s \u2208 S. We denote the empirical distribution of f* on Ds by vf*(Ds), i.e., Vf*(Ds) = 1/n_s \u2211_{i=1}^{n_s} \u03b4_{f*(x_i,s)} for s \u2208 S, where \u03b4 is the Dirac measure. Consider two discrete distributions in Rk: \u03bc = \u2211_{i=1}^{n_\u03bc} p_i \u03b4\u03b5\u03bci and \u03bd = \u2211_{j=1}^{n_\u03bd} \u03c1_j \u03b4\u03b5\u03bdj, where\u2208 Rk, \u00a6 \u2208 Rk, pi > 0, pj> 0, \u2211_{i=1}^{n_\u03bc}p_i = 1 and \u2211_{i=1}^{n_p}\u03c1_i = 1. As a special case of (3), the squared Wasserstein-2 distance between \u03bc and \u03bd is\n\\(W^2(\\mu, \\nu) = \\min_{\\Upsilon \\in \\Pi^{\\mu\\nu}} \\sum_{i=1}^{n_\\mu} \\sum_{j=1}^{n_\\nu} C_{ij} \\gamma_{ij}\\) (11)\ns.t. \\(\\sum_{i=1}^{n_\\mu} \\gamma_{ij} = p_j, \\sum_{j=1}^{n_\\nu} \\gamma_{ij} = p_i, \\forall i.\nwhere cij = || - ||2 and \u03b3ij represents the mass located i transported to j in order to move distribution \u03bc to \u03bd. Also, \u03b3 can be viewed as a discrete distribution in Rk \u00d7 Rk supported on (i,j) for j = 1, ..., n\u03bc and i = 1, ...,nv. Suppose \u03b3* \u2208 Ruxnv is the optimal solution of (11). The optimal transportation from u to \u03bd and from \u03bd to \u03bc, denoted by T\u03bc,\u03bd and T\u03bd,\u03bc respectively, are random mappings such that\n\\(P(T_{\\mu,\\nu}(\\xi_j) = \\xi_i) = \\frac{\\gamma_{ij}}{P_j},\\) (12)\nfor j = 1, ..., \u03b7\u03bc and i = 1, ..., \u03b7\u03bd.\nWith W\u00b2(\u03bc,\u03bd) given in (11), the barycenter of discrete distributions vi for i = 1,...,m is also defined as the solution of (4). Since vf*(D) is the discrete approximation of vf*|s, we propose to approximate vo in Theorem 1 by the barycenter of {Vf*\\s}ses with the weights ps = Ns / (\u03a3'\u03b5\u03b7\u03c2 ns'). Unfortunately, Wasserstein barycenters are NP-hard to compute [4]. Although (4) can be formulated as a multi-marginal optimal transport problem [3] and solved as a linear program [6], its computational complexity scales exponentially in terms of m. To reduce the exponential computing complexity, instead of computing the barycenter exactly, we adopt the approach by [42] to construct its approximation. This approach achieves a good balance between runtime and approximation error in practice. We present this approach in the next section."}, {"title": "Approximate Barycenter with Finite Samples", "content": "The approach by [42] first computes the optimal transport mapping between Vf*(Ds) to vf*(D') for each pair of s and s' in S, i.e., Tvf*(Ds),Vf*(Dr) Satisfying (12). For simplicity of notation, we denote Tvf*(Ds), Vf*(Dr) by Ts,s'. Then, they define a mapping M(f* (x1, s)) = \u2211s'\u2208s ps'ETs,s' (f*(x2, s)), where ps = ns/(\u2211s'es ns') and the expectation is taken over the random output of Ts,s' following distribution in (12). Here, M(f*(x, s)) is the weight average of the expected outcomes after trans-porting f*(x, s) to each of the |S| distributions. Finally, the approximate barycenter is constructed as a discrete distribution with \u2211ses ns supports defined as follows \u03bdo = \u2211ses i=1 \u03b4M(f(x,s)). Compared to the exact barycenter, this approximation requires solving |S|(|S| \u2013 1)/2 optimal transport mapping between two discrete distributions and thus has a polynomial time complexity.\nLet m = |S| and vs = vf*(Ds) in (4). Leto be optimal solution of (4), i.e, the barycenter of {Vf*(Ds)}ses. It is shown by [42] that \u03a8(\u03bf)/\u03a8(0) \u2264 2. This bound is significant because there is no polynomial-time algorithm can achieve a ratio arbitrarily close to one with high probability [4]. Although Proposition 1 is derived for continuous distribution, it motivates a heuristic post-processing method to update the output f*(x, s) to\n\\(f_\u03b1(x_i, s) := \\sqrt{\u03b1}f^*(x, s) + (1 - \\sqrt{\u03b1})T_{v_{f^*(D_s)},\\tilde{v}_o} (f^*(x_i, s))\\) (13)"}, {"title": "Post-Process Out-of-Sample Data", "content": "Note that fa(x, s) is defined for (x, s) \u2208 D, only because the optimal transport mapping Tvf* (D\u2082),\u016c0 in (13) is only defined on f*(x,s) with (x,s) \u2208 Ds. To extend the definition of fa(xi,s) from Ds to any (x, s) \u2208 Rd \u00d7 S, we extrapolate Tvf*(D\u2082),\u00f1o over Rk using the Nadaraya-Watson kernel regression method [50].\nLet K : Rk \u2192 R+ be a kernel function satisfying K(z) = K(\u2212z)and \u222bRk K(z)dz = 1. Leth > 0 be a bandwidth. For any (x, s) \u2208 Rd \u00d7 S, the kernel regression estimator of Tvf*(D\u2082),\u00f1o (f*(x, s)) is\n\\(\\tilde{T}_{v_{f^*(D_s)},\\tilde{v}_o} (f^*(x, s)) := \\frac{\\sum_{i=1}^{n_s} K ((f^*(x, s) - f^*(x_i, s))/h) T_{v_{f^*(D_s)}, \\tilde{v}_o} (f^*(x_i, s))}{\\sum_{i=1}^{n_s}K ((f^*(x, s) - f^*(x_i, s))/h)}\\) (14)\nRecall that Tvf*(D), is a randomly mapping (see (12)), so is Tvf*(D\u2082),\u00f1o. We show in the lemma below that, if h approaches zero and the out-of-sample data comes from the distribution of (X, S), the violation of the distributional parity after post-processing is bounded by the distance between empirical distribution and ground-truth distribution.\nLemma 1 lim U(f(X, S)) = \u039f (\u2211 W\u00b2 (Vf*|s, V f*(Ds)) , where f(x, s) := Tvf*(D\u2082),vo (f*(x, s)).\nh\u21920 s\u2208S\nAfter extrapolating Tvf* (D\u2082), o to Tvf*(D\u2082), defined above, we can extend (13) for any out-of-sample data by updating f*(x, s) to\n\\(f_\u03b1(x, s) := \\sqrt{\u03b1}f^*(x, s) + (1 - \\sqrt{\u03b1})\\tilde{T}_{v_{f^*(D_s)},\\tilde{v}_o} (f^*(x, s)).\\) (15)\nWe then formally present this post-processing method in Algorithm 2. Note that when (x, s) \u2208 Ds, we still apply the original mapping in (13) instead of its extrapolation (15)."}, {"title": "Experiments", "content": "In this section, we apply the proposed post-processing method to machine learning models with multiple outputs, including multi-label/multi-class classification and representation learning. Datasets. In our experiments, we include four datasets from various domains, including marketing domain(Customer dataset 2), medical diagnosis( Chexpert Dataset [36]), face recognition (CelebA dataset[45] and UTKFace dataset[71]). The details of these datasets are provided in Section B.1. Baselines. To verify the effectiveness, we compare our method with existing post-processing techniques: Hu et al. (2023)[34], the only method in the literature for multi-label classification, and Xian et al (2023)[63], the superior of the only two available approaches for multi-class classification. Due to the limited post-processing methods in the literature for multi-output problems, we also incorporate an in-processing method, Adversarial Debiasing(Adv Debiasing)[70], which can be extended for postprocessing. Specifically, for Adv Debiasing, both Predictor Block and Adversary Block are implemented by a two-layer neural network with 128 hidden units and tanh function,"}, {"title": "Multi-label classification", "content": "For multi-label classification tasks, we experiment on CelebA dataset [45] and Chexpert dataset [36]. Firstly, one ResNet50[32] and one DenseNet121[35] and are trained on the CelebA and Chexpert data respectively, then post-processing methods are applied to the predicted probabilities of each task. We compare our method with Adv Debiasing and the post-processing method Hu et al. (2023)[34], which essentially independently applies the post-processing method for a single-output model in [30, 15, 16] to each coordinate of the output of a multi-task classification model. As their method also balances fairness and classification performance, we vary parameter \u03b1 for their method in {0, 0.2, 0.4, 0.6, 0.8, 1.0}. The results are summarized in Figure 2(a) and 2(b). We can observe that, at the same level of accuracy, our method achieves much lower unfairness than baselines. This can be seen more clearly on the left end of the curves where the unfairness is close to zero. On CheXpert dataset, although Adv Debiasing may achieve smaller unfairness, it brings a significant undesirable performance decrease."}, {"title": "Multi-class classification", "content": "To verify the effectiveness of our proposed method on multi-class classification tasks, we apply our method to the customer dataset. A classic multi-class logistic regression model is built first on the training data and then post-processing methods are applied to the predicted probabilities of each class. We compare our method with Xian et al (2023)[63] and Adv Debiasing. Note that method [63] directly produces the class labels instead of score function, so we can only perform the comparison on the classification accuracy and the unfairness based on Equation 2, which is in favor of their method. Following their paper, the parameter a for [63] are in {1, 0.16, 0.14, 0.12, 0.1, 0.08, 0.06, 0.04, 0.02, 0.01, 0.008, 0.006, 0.004, 0.002, 0.001, 0.0.}. We present the result in Figure 2(c). From that figure, we can see that our method achieves a better balance between accuracy and unfairness than baselines, especially when a higher level of fairness is desired."}, {"title": "Representation learning", "content": "In this part, we explore the fair representation learning for self-supervised learning(SSL) models and large pre-trained foundation models. We experiment on CelebA dataset and UTKFace dataset[71].\nDue to the scarcity of the postprocessing methods for self-supervised representation learning in existing literature, we still compare our method with the post-processing method Hu et al. (2023)[34] and Adv Debiasing. For CelebA dataset, we first train an SSL model to learn representations with a dimension of 128, by employing the algorithm proposed in [68] on the whole training dataset. Then we apply post-processing methods to eliminate the sensitive information in the raw representations. Specifically, for Adv Debiasing, we utilize the raw representations as the labels for the Predictor as there is no task-specific labels in self-supervised learning. In other words, we aim for the model to remove sensitive information while altering the raw representation as minimally as possible. With processed representations, we also build a multi-label logistic regression model to evaluate the performance on downstream tasks. For UTKFace dataset, the raw representations are generated by the image encoder of a released CLIP model [55] pre-trained on 400M text-image pairs, with a dimension of 512.\nWe evaluate the unfairness of the representations as well as the accuracy performance of the downstream tasks. The results are summarized in Figure 3 and 4. By examining the representations of Figure 3(a) and 4(a), it's evident that both the SSL model and CLIP model disclose sensitive attributes prominently. Even after applying post-processing techniques proposed in Hu et al. (2023)[34], this exposure persists, as depicted in Figure 3(b) and Figure 4(b). However, through our proposed methods illustrated in Figure 3(c) and Figure 4(c), we are able to achieve fairer representations with respect to sensitive groups. Notably, from Figure 3(d) and 4(d), we can observe that our method achieves a tradeoff between downstream performance and distributional parity, whereas Hu et al. (2023)[34] fails to improve the distributional parity because, as discussed in Figure 1, the elimination of unfairness in individual outputs may not necessarily mitigate unfairness in the joint distribution of outputs."}, {"title": "Conclusion and Discussion", "content": "In this paper, we have proposed a post-processing method to enhance fairness for multi-output machine learning models, which is underexplored in the literature. Our approach employs an optimal transport to move a model's outputs across different groups towards their empirical Wasserstein barycenter to achieve the model's distributional parity. We have developed an approximation technique to reduce the complexity of computing the exact barycenter and a kernel regression method for extending this process to out-of-sample data. Extensive experimental results on multi-class/multi-task classification and representation learning demonstrate the effectiveness of our method. One limitation of our work is that the notion of fairness in Definition 1 we pursue is strong while a weak notion such as (2) might be sufficient for some applications. To achieve a strong sense of fairness may lead to more decreases in the predictive performance than targeting at a weak sense. Another limitation is the lack of theoretical convergence analysis of the proposed method as the training sample size increases, which is an important future work."}, {"title": "Proofs", "content": "Before providing the proof of Theorem 1, let's review some additional results about Optimal Transport theory.\nThe next result shows that as long as two measures admit a density with finite second moments, there exists a unique deterministic optimal transport map between them.\nLemma 2 (Theorem 1.22 in [58]) Let \u00b5,v be two measures on Rk with finite second moments such that \u00b5 has a density and let X ~ \u03bc. Then there exists a unique deterministic mapping T : Rk \u2192 Rk such that\n\\(W_2^2(\\mu,\\nu) = E||X \u2013 T(X)||^2,\\)\nthat is (X,T(X)) ~ \u04ef \u2208 \u0393\u03bc,\u03bd where \u04ef is an optimal coupling."}, {"title": "Proof of Theorem 1", "content": "This proof is originally from the proof of Theorem 2.3 in [15]. The only change is replacing the cumulative density function and its inverse to the optimal transport mapping. We include this proof here mainly for the sake of completeness.\nTheorem 1 Suppose vf*|s has density and finite second moments for each s \u2208 S. Then\n\\(\\min_{U(f)=0} R(f) = U(f^*) = \\min_\u03bd \\sum_{s \\in S} p_s W^2(v_{f^* \\vert s}, v).\\)\nMoreover, if fo and vo solve the first and second minimization in (7), respectively, then vo is the density of fo and\n\\(f_o(x, s) = T_{f^*\\vert s, v_0} (f^*(x, S))\\)\nwhere Tf*|s,vo: Rk \u2192 Rk is the optimal transport mapping from vf*|s to vo.\nProof First, we'd like to show that\n\\min_{U(f)=0} Elf*(X, S) - f(X, S)||\u00b2 \u2265 min \u2211ps W\u00b2(vf* |s, v).\n\u03bd\ns\u2208S\nLet \u04ef : Rd \u00d7 S \u2192 Rk be the minimizer of the l.h.s of the above equation and denoted by v\u00f5 the distribution of \u011f. Since vf*|s admits density, with Lemma 2, for each s \u2208 S there exists Tf*|s,\u011f such that\n\\sum_{s\\in S} p_sW^2(v_{f^*\\vert s}, v_{\\tilde{g}}) = \\sum_{s\\in S} p_s \\int_\\mathcal{X} ||f^*(x, s) - T_{f^*\\vert s,\\tilde{g}}(f^*(x, s)) ||^2d v_{f^*\\vert s}(x)\n= \\sum_{s\\in S} p_s E [||f^*(x, s) - T_{f^*\\vert s,\\tilde{g}}(f^*(x, s))||^2 | S=s]\n= \\sum_{s\\in S} p_s \\sum_x || f^*(x, s) - T_{f^*\\vert s,\\tilde{g}}(f^*(x, s))||^2 dP_{X \\vert S=s}(x)\n= E [\\sum_{s\\in S} p_s || f^*(X, S) - T_{f^*\\vert s,\\tilde{g}}(f^*(X, S))||^2 | S=s]\n= E ||f^*(X, S) - \\tilde{g}(X, S)||^2\nwhere we define \u011f(x,s) = Tf*|s,\u011d(f*(x,s)) for all (x, s) \u2208 Rd \u00d7 S. With optimal transportation, \u011f(X,s) S = s follow the distribution v\u00f5 for any s\u2208 S. Then we have\nU(\\tilde{g}) = \\min_\u03bd \\sum_{s\\in S} p_s W^2(v_{\\tilde{g} \\vert s}, v) = 0\nwhich indicates \u011f is fair. By optimality of \u011f we have\nE||f^*(X, S) - \\tilde{g}(X, S)||^2 \u2265 E||.f^*(X, S) - \\hat{g}(X, S')||^2\nDue to definition of W2, for each s \u2208 S we have\nW^2(v_{f^*\\vert s}, V_{\\tilde{g}}) \u2264 E[|| f^*(X, S) - \\hat{g}(X, S)||^2 | S = s]\nThen we can conclude\n\\sum_{s\\in S} p_sW^2(v_{f^*\\vert s}, V_{\\tilde{g}}) = \\min_{U(f)=0} E|| f^* (X, S) - f(X, S)||^2"}, {"title": "Proof of Lemma 1", "content": "Lemma 1 Let f(x", "s)": "Tvf* (D\u2082),vo (f* (x, s))\n\\lim_{h \u2192 0} U(f(X, S)) = \u039f (\\sum_{s\u2208S} W\u00b2 (Vf*|s, V f*(Ds"}]}