{"title": "Error-Feedback Model for Output Correction in Bilateral Control-Based Imitation Learning", "authors": ["Hiroshi Sato", "Masashi Konosu", "Sho Sakaino", "Toshiaki Tsuji"], "abstract": "In recent years, imitation learning using neural networks has enabled robots to perform flexible tasks. However, since neural networks operate in a feedforward structure, they do not possess a mechanism to compensate for output errors. To address this limitation, we developed a feedback mechanism to correct these errors. By employing a hierarchical structure for neural networks comprising lower and upper layers, the lower layer was controlled to follow the upper layer. Additionally, using a multi-layer perceptron in the lower layer, which lacks an internal state, enhanced the error feedback. In the character-writing task, this model demonstrated improved accuracy in writing previously untrained characters. In the character-writing task, this model demonstrated improved accuracy in writing previously untrained characters. Through autonomous control with error feedback, we confirmed that the lower layer could effectively track the output of the upper layer. This study represents a promising step toward integrating neural networks with control theories.", "sections": [{"title": "I. INTRODUCTION", "content": "In recent years, imitation learning has gained significant attention for enabling robots to perform complex actions [1] [2] [3]. Imitation learning is a type of supervised learning in which neural networks (NNs) learn from human demonstrations. Furthermore, research on imitation learning using position and force information has advanced. Specifically, bilateral control-based imitation learning has proven effective in reproducing human force application [4] [5] [6] [7]. Bilateral control is a teleoperation technology that uses two robots: one interacts with the environment, while the other is operated by a human applying force. By collecting data with this technology, both position and force response and command values can be obtained, allowing robots to replicate human operational sensations. The use of force-based imitation learning shows promise for replacing human tasks with robots. However, in conventional bilateral control-based imitation learning, NN has a feedforward structure and does not control output errors, as shown in Fig. 1. Hence, errors during the autonomous operation of the NN are not compensated. This issue is observed not only in bilateral control-based imitation learning but also in many NN-based imitation learning approaches.\nTraditionally, NNs have required an internal state to retain memory for handling time-series data. However, this NN struggles to integrate with controllers due to the significant influence of the internal state. This suggests that the system's non-Markovian nature complicates NN control. Generally, systems are more likely to exhibit Markovian properties when the sampling period is shortened. Therefore, to realize effective NN control, it is essential to establish a structure with independent components for the short-sampling-period NN, which exhibits Markovian properties and is easier to control, and the long-sampling-period NN, which has non-Markovian properties and enables complex time-series inference.\nIn this study, we developed a control system for a hierarchical model with different sampling periods. The hierarchical model comprises an upper layer that makes long-term predictions and a lower layer that makes short-term predictions. The upper layer is a strong non-Markovian system that predicts action plans based on past information. Conversely, the lower-layer is a strong Markovian system that predicts command values and states with a short sampling period. This type of model has been proposed in previous research [8], demonstrating its effectiveness for long-term tasks. However, prior studies employed Long Short-Term Memories (LSTMs) with internal states for the Markovian lower-layer. Therefore, we employed a multilayer perceptron (MLP), which lacks an internal state, to construct a control system for the output. During the control process, the error in the robot's state predicted by the upper"}, {"title": "II. RELATED WORKS", "content": "Integrating control with NNs has been extensively studied using world models [9] [10] [11]. A world model is an NN that learns the structure of the environment from observation data, representing it in a latent space. By incorporating a mechanism to control errors in this latent space, it becomes possible to combine NNs with control. However, these methods assume constant dynamics, which poses challenges for tasks involving contact or multiple actions, as dynamic changes over time complicate mapping to the latent space."}, {"title": "B. Bilateral Control-Based Imitation Learning", "content": "Bilateral control-based imitation learning uses bilateral control during the data collection phase. Bilateral control is a teleoperation technique that synchronizes the positions and forces of two robots: a leader and a follower. The leader receives forces from a human operator, while the follower interacts with the environment. Using this control method to perform tasks, the response values of both the leader and follower are collected. The leader's response value serves as the command for the follower. As a result, the response and command values of the follower can be collected separately. An NN is then trained to predict the next command value of the follower based on its current response value. Once trained, the NN enables autonomous movements that replicate bilateral control, allowing the execution of tasks requiring force control."}, {"title": "C. Hierarchical Model", "content": "A hierarchical model processes information at different levels of abstraction in each-layer, breaking down complex tasks into manageable sub-tasks. [12] [8]. Hayashi et al. proposed a hierarchical model for bilateral control-based imitation learning [8]. Here, f and I represent the follower and leader, respectively, and the subscript t indicates the operational step of the NN. The upper-layer infers the state 10 steps ahead $\\hat{f}_{k+10}^{upper}$ and provides it to the lower-layer. Conversely, the lower-layer considers the follower's current state $f_e$ and state $\\hat{f}_{k+10}^{upper}$ provided by the upper-layer as inputs. It then predicts the follower's next state $f_{k+1}$ and leader's next state $\\hat{l}_{k+1}$.\nThe hierarchical model has been shown to be effective for long-term tasks. Additionally, it has been confirmed that the model can accomplish tasks even when the lower layer receives unlearned information from the upper layer. However, without a control mechanism for the lower layer to follow the upper layer, there is concern about a decrease in task performance accuracy."}, {"title": "III. PROPOSED METHOD", "content": "In this study, a hierarchical model was employed to separate the Markovian and non-Markovian aspects of the system. The hierarchical model is the same as those used in previous research [8]. The upper-layer infers task plans over a long period, handling the non-Markovian properties of the system. In contrast, the lower-layer performs short-period inference of commands and states based on the current state and a few steps ahead of the follower's state. Given that it performs short-period inference and involves predictions that interpolate between different steps, the lower-layer system is considered to exhibit high Markovian properties. Based on this reasoning, control was constructed for the Markovian aspects of this hierarchical model."}, {"title": "B. hierarchical model with error-feedback mechanism", "content": "In this study, we propose an error feedback model, as shown in Fig. 3. This model is designed to control the system to reduce the error between the outputs. In the proposed method, the upper-layer generates the state one step ahead $\\hat{f}_{k+1}^{upper}$ and state ten steps ahead $\\hat{f}_{k+10}^{upper}$. Additionally, the error between the output of the lower-layer $f_{k+1}$ and upper-layer output $\\hat{f}_{k+1}^{upper}$ was calculated. Here, the error calculation is defined simply as the difference $\\hat{f}_{k+1}^{upper} - f_{k+1}$. Extending this to various control mechanisms is a future work, but the simple difference worked well in this study. Subsequently, the information from the upper-layer given to the lower-layer, $\\hat{f}_{k+1}^{upper}$, is defined as follows:\n$$\\tilde{f}_{k+1}^{upper} = F_{10}(\\hat{f}_{k+10}^{upper} + (\\hat{f}_{k+1}^{upper} - f_{k+1}))$$\nBy adding the error to the upper-layer output, it is expected that the lower-layer will generate an output that has been corrected for errors.\nIt should be noted that $\\hat{f}_{k+10}^{upper}$ is updated every ten steps, while $\\hat{f}_{k+1}^{upper}$ is updated at each time step. This was standardized to enable comparison with previous research [8]. Additionally, this mechanism was applied during the robot's autonomous operation. Therefore, the learning process does not include an error feedback mechanism, similar to conventional hierarchical models."}, {"title": "C. NN Design of the lower-layer", "content": "To address the Markovian properties of the system, the lower-layer is designed as a simple multi-layer perceptron (MLP) without internal states, as illustrated in Fig. 5. The network comprises four layers of fully connected layers with 200 dimensions using the Tanh function as the activation function for all layers except for the final one. Additionally, for comparison, the lower layer using the conventional long short-term memory (LSTM) architecture is also presented in Fig. 4. The LSTM network is comprised of three layers of 200-dimensional LSTM units and a fully connected layer, resulting in a total of four layers.\nIn this study, the states predicted by the upper-layer are assumed to be known. Specifically, time-series states of the follower are stored in advance through bilateral control, and this data is utilized. This allows for the comparison of different lower-layers using the same predictions from the upper-layer."}, {"title": "IV. EXPERIMENT METHOD", "content": "In this study, CRANE-X7, manufactured by RT Corporation, was employed. The manipulator has seven degrees of freedom, and the gripper has one degree of freedom. The gripper was replaced by a cross-structured hand [6]. Given that controlling a manipulator with seven degrees of freedom can be challenging for humans, joint 2 was fixed using position control, effectively reducing the system to a six degrees of freedom manipulator. Each axis of the manipulator was controlled by a position and force hybrid controller, with a control period of 500 Hz [4]. The joint angles @ were measured by rotary encoders at each joint, and the angular velocities $\\dot{\\Theta}$ were calculated by its pseudodifferential. The torques T were estimated using a reaction force estimation observer [13]."}, {"title": "B. Verification of autonomous operation", "content": "In the experiment, a writing task was conducted using the robot. The robot wrote the characters while holding the pen from the beginning, as shown in Fig. 6. The characters drawn by the robot were captured by an Intel RealSense D435i mounted on the top of the whiteboard.\n1) Preliminary: As a preliminary experiment, we investigated the amount of information required as the upper-layer output. Specifically, in Fig. 3, the upper layer outputs one of the following three: $\\hat{f}_{k+1}^{upper} = [\\theta]$, $\\hat{f}_{k+1}^{upper} = [\\theta, \\omega]$, $\\hat{f}_{k+1}^{upper} = [\\theta, \\omega, \\tau]$. The lower-layers were trained to write the character 'A' using two model types: LSTM and MLP. With the learned NNs, the robot performed the operation of writing 'A.' In the autonomous operation, the upper-layer outputs, which were collected in advance by the bilateral control, were used. The optimal amount of information for the upper-layer outputs were selected by the evaluation described below."}, {"title": "2) Evaluation of error-feedback model", "content": "A comparison was conducted between the conventional hierarchical model and proposed hierarchical model. The lower-layer models, which were highly evaluated in the preliminary experiments, were utilized. An experiment was conducted to write three different types of characters: character 'A,' '4,' and 'B.' Specifically, 'A'is a learned character, while '4' and 'B' are characters that had not been learned.\nCharacter '4' was selected because it has a shape that is similar to 'A' but somewhat different, while character 'B' was chosen for its distinct shape compared to 'A.' To enable the writing of these characters, the upper-layer outputs were modified to correspond to each respective character. The upper-layer outputs was determined based on the follower's state, which was previously collected through bilateral control. Meanwhile, the lower-layer NN remained unchanged from the preliminary experiments. In conventional imitation learning, the NN must be retrained for each new character. When the upper-layer outputs for an unlearned character are used, errors are expected in the NN's output. Therefore, we aimed to verify whether the proposed method could suppress these errors and generate command values that align with the upper-layer outputs."}, {"title": "C. Training NN", "content": "We collected training data and validation data by using bilateral control to write character 'A.' The training data were collected seven times, five of which were used as training data and two as validation data. Fig. 7 is a diagram that is drawn when the data is collected. This is the image of the characters on the whiteboard captured by a camera and superimposed after binarization.\nWhen training NN using time-series data, the learning efficiency can be improved by reducing the sampling frequency. For this purpose, the joint information acquired at 2-ms intervals was sampled every 10 steps by shifting the starting point, creating a data set with 20-ms intervals [14]. This process increased the amount of data by a factor of 10. Additionally, a 20 rad/s low-pass filter was applied to the teacher data to remove high-frequency components. The input data were augmented with normally distributed noise with a variance of 0.01. The length of each sequence was unified by padding, which copies the last value. The data were normalized to mean 0 and standard deviation 1 during training. Mean Squared Error (MSE) was used as the loss function and Adam was used for optimization. The learning rate was set to 0.0001, and the batch size to 16, and the number of epochs to 1000."}, {"title": "D. Evaluation Method", "content": "Evaluation of autonomous movements was performed in two ways: assessing the diagrams drawn by the robot and evaluating the joint angles during autonomous movements. Autonomous movements were performed five times, and the means and standard deviations were calculated for both evaluation methods. The outputs from the upper-layer in this study were collected using bilateral control. Therefore, the upper-layer outputs of the drawn characters and joint angle information were collected in advance.\n1) IoU: Intersection over Union (IoU) was used to evaluate the accuracy of the diagrams. The diagrams drawn by the robot were captured by a camera and binarized in black and white. The IoU is calculated as follows:\n$$IoU = \\frac{B_{upper} \\cap B_{output}}{B_{upper} \\cup B_{output}}$$\nwhere $B_{upper}$ represents the character area drawn in the upper-layer output, and $B_{output}$ denotes the character area drawn by the autonomous motion of NN. As this value approaches 1, it indicates a higher degree of match between the two characters. By comparing the IoU values, we evaluated whether the autonomous control followed the upper-layer output.\n2) MSE of Angles: The joint angles of autonomous movement were evaluated. The purpose of this study is to control the lower-layer to approach the upper-layer outputs. In other words, by calculating the error between the joint angles obtained by autonomous movements and joint angles of the upper-layer output, it is possible to evaluate the follow-up to the upper-layer outputs. We termed this as Angular Error and calculated it as follows:\n$$Angular Error = \\sum_{k=0}^{n} \\sum_{i=0}^{n} (\\Theta_{i,k}^{upper} - \\Theta_{i,k}^{robot})^2$$\nwhere k, k = 0, k = n, $\\Theta_{i,k}^{upper}$, and $\\Theta_{i,k}^{robot}$ denote specific time, task start time, task end time, the angle of the upper-layer output, and the angle response value of the robot during autonomous operation. By comparing these values, we evaluated the tracking performance of the robot relative to the upper-layer output."}, {"title": "V. EXPERIMENT", "content": "The results of the preliminary experiments are shown in Fig. 8. The black line in the figure represents the drawing made by autonomous actions, while the light red color indicates the upper-layer output. Comparing the drawn characters with the IoU, LSTM and MLP achieved the highest values when using"}, {"title": "B. Evaluation of error-feedback model", "content": "To verify the effectiveness of the proposed method, tasks were conducted to write several characters: 'A,' '4' and 'B.' The results with the error-feedback model are described as 'w/ feedback.'\n1) character A: The upper part of Fig. 9 presents the results for the task of writing character 'A.' Using the error-feedback model, no increase in IoU was observed for either LSTM or MLP, though a decrease in Angle Error was confirmed. In the error-feedback model, there was no significant difference between LSTM and MLP, but the LSTM model showed slightly higher IoU results. Overall, it can be concluded that the conventional LSTM provides sufficient performance in writing character 'A,' as the lower-layer have learned these characters. The observed decrease in Angle Error, while not affecting the IoU, suggests successful approximation of the upper-layer output.\n2) character 4: The middle part of the Fig. 9 presents the results for the task of writing character '4.' In the error-feedback model, MLP showed an increase in IoU, while LSTM showed a slight increase. Similarly, MLP reduced the Angle Error, and LSTM showed a slight reduction. When comparing the performance of LSTM and MLP, MLP achieved a larger IoU and a smaller Angle Error than LSTM. These results indicate that using MLP with the error-feedback model improved task accuracy. Given that MLP does not have an internal state, it made appropriate predictions based on error feedback without being influenced by past memories.\n3) character B: The bottom part of the Fig. 9 presents the results for the task of writing character 'B.' In the error-feedback model, no increase in IoU was observed for either LSTM or MLP. However, a decrease in Angle Error was noted. When comparing LSTM and MLP, MLP exhibited a smaller Angle Error than LSTM.\nThese results suggest that NN model faced difficulties in performing the task of writing the character 'B.' However, with the error-feedback model using MLP, there was a significant reduction in Angle Error. This indicates that the followability to the upper-layer outputs improved. The low IoU values are thought to be due to the pen not making contact with the board, despite following the upper-layer outputs.\nThe difficulty in performing the task of writing the character 'B' may be attributed to the fact that the motion for 'B' involved extrapolation beyond the learned data. In particular, the second stroke falls outside the range of the motion used for drawing 'A.' As a result, the lower-layer may not have learned the skills necessary for writing 'B,' making it challenging to follow the upper-layer output."}, {"title": "VI. CONCLUSION", "content": "In this study, we proposed an error-feedback model for a hierarchical NN that addresses output errors through feedback. The method calculates output errors between upper and lower layers and incorporates them into a lower-layer input. In the writing task experiments, the model accurately followed the upper-layer output. Additionally, using an MLP in the lower-layer enhanced tracking performance and improved the accuracy of character generation. It is believed that these results represent a significant first step toward integrating NNs with control theory."}, {"title": "VII. FUTURE WORKS", "content": "The next step is to develop an lower-layer that can more accurately follow the upper-layer output. In this study, the lower-layer learned to write only character 'A.' To enable the lower-layer to more flexibly follow the upper-layer output, it is necessary for lower layer to learn a wider range of behaviors. Thus, it is essential to verify whether teaching a variety of behaviors to the lower-layer improves their ability to follow the upper-layer output.\nAdditionally, the next challenge is the extension to the lower-layer, where only the trajectory is provided from the upper-layer. In this study, the outputs of the upper-layer were angle, angular velocity, and torque. However, in many cases, it is difficult to obtain all three of these physical quantities. If the lower-layer only require the angle information from"}]}