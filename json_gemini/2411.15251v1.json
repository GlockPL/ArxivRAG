{"title": "Optimized Vessel Segmentation: A Structure-Agnostic Approach with Small Vessel Enhancement and Morphological Correction", "authors": ["Dongning Song", "Weijian Huang", "Jiarun Liu", "Md Jahidul Islam", "Hao Yang", "Shanshan Wang"], "abstract": "Accurate segmentation of blood vessels is essential for various clinical assessments and postoperative analyses. However, the inherent challenges of vascular imaging-such as sparsity, fine granularity, low contrast, data distribution variability, and the critical need for preserving topological structure-make generalized vessel segmentation particularly complex. While specialized segmentation methods have been developed for specific anatomical regions, their over-reliance on tailored models hinders broader applicability and generalization. General-purpose segmentation models introduced in medical imaging often fail to address critical vascular characteristics, including the connectivity of segmentation results. To overcome these limitations, we propose an optimized vessel segmentation framework: a structure-agnostic approach incorporating small vessel enhancement and morphological correction for multi-modality vessel segmentation. To train and validate this framework, we compiled a comprehensive multi-modality dataset spanning 17 datasets and benchmarked our model against six SAM-based methods and 17 expert models. The results demonstrate that our approach achieves superior segmentation accuracy, generalization, and a 34.6% improvement in connectivity, underscoring its clinical potential. An ablation study further validates the effectiveness of the proposed improvements. We will release the code and dataset at github.com following the publication of this work.", "sections": [{"title": "I. INTRODUCTION", "content": "Vessel segmentation plays a crucial role in analyzing various related diseases [1]. However, manual observation by doctors is often time-consuming, tedious, and requires a high level of expertise [2]. Therefore, developing an automatic, accurate, and highly generalizable vessel segmentation method using computer technology holds significant promise for clinical applications.\nIn medical image analysis, many pioneers have developed automated vessel segmentation models to reduce clinical workloads and enhance diagnostic efficiency. Early research primarily focused on traditional machine learning algorithms."}, {"title": "II. RELATED WORK", "content": "Accurate segmentation of blood vessels is crucial for evaluating various disorders, particularly cardiovascular diseases, as well as for surgical planning and monitoring treatment progress. This process plays a vital role in clinical analysis. With advancements in deep learning, there has been growing recognition of the importance of integrating multi-scale information in vessel segmentation. As a result, numerous methods have been proposed for the automated segmentation of blood vessels.\nIn fundus retinal vessel segmentation, Wu et al. [13] proposed SCS-Net, which combines a semantic context aggregation module to enhance multi-scale information extraction and an adaptive feature fusion module to improve integration across adjacent layers. Jiang et al. [14] introduced Covi-Net, which integrates a Local and Global Feature Aggregation (LGFA) module, preserving the ability to process local information while facilitating the processing of distant global information. Kang et al. [15] proposed CFI-Net, a model that employs joint refinement downsampling to mitigate spatial information loss caused by downsampling, preserving the details and edge features of retinal vessels. In OCTA image segmentation, Ning et al. [16] proposed FR-Net, an efficient and accurate network that leverages a modified Recurrent ConvNeXt Block within a full-resolution convolutional framework. This network reduces parameters and accelerates inference speed. Ma et al. [17] addressed data imbalance in the OCTA dataset by proposing CoSNet, which utilizes global contrastive learning to allow the network to learn both local and global features. Additionally, Ma et al. [18] proposed OCTA-Net, which uses a coarse segmentation module to generate preliminary vessel confidence maps and a fine segmentation module to refine the contours and shapes of retinal microvessels. In coronary artery segmentation, Chang et al. [19] proposed SERegUNet, which combines a RegNet encoder with squeezeand-excitation blocks to enhance feature extraction. Liu et al. [20] introduced FR-UNet, which uses a multi-resolution convolutional mechanism to expand both horizontally and vertically while maintaining full image resolution. Despite their contributions, the aforementioned methods are specialized models tailored to specific datasets, and their performance may significantly degrade when applied to new data or different scenarios, which hinder deployment and limit their generalization to other vascular regions."}, {"title": "A. Vessel Segmentation Methods", "content": "Accurate segmentation of blood vessels is crucial for evaluating various disorders, particularly cardiovascular diseases, as well as for surgical planning and monitoring treatment progress. This process plays a vital role in clinical analysis. With advancements in deep learning, there has been growing recognition of the importance of integrating multi-scale information in vessel segmentation. As a result, numerous methods have been proposed for the automated segmentation of blood vessels.\nIn fundus retinal vessel segmentation, Wu et al. [13] proposed SCS-Net, which combines a semantic context aggregation module to enhance multi-scale information extraction and an adaptive feature fusion module to improve integration across adjacent layers. Jiang et al. [14] introduced Covi-Net, which integrates a Local and Global Feature Aggregation (LGFA) module, preserving the ability to process local information while facilitating the processing of distant global information. Kang et al. [15] proposed CFI-Net, a model that employs joint refinement downsampling to mitigate spatial information loss caused by downsampling, preserving the details and edge features of retinal vessels. In OCTA image segmentation, Ning et al. [16] proposed FR-Net, an efficient and accurate network that leverages a modified Recurrent ConvNeXt Block within a full-resolution convolutional framework. This network reduces parameters and accelerates inference speed. Ma et al. [17] addressed data imbalance in the OCTA dataset by proposing CoSNet, which utilizes global contrastive learning to allow the network to learn both local and global features. Additionally, Ma et al. [18] proposed OCTA-Net, which uses a coarse segmentation module to generate preliminary vessel confidence maps and a fine segmentation module to refine the contours and shapes of retinal microvessels. In coronary artery segmentation, Chang et al. [19] proposed SERegUNet, which combines a RegNet encoder with squeezeand-excitation blocks to enhance feature extraction. Liu et al. [20] introduced FR-UNet, which uses a multi-resolution convolutional mechanism to expand both horizontally and vertically while maintaining full image resolution. Despite their contributions, the aforementioned methods are specialized models tailored to specific datasets, and their performance may significantly degrade when applied to new data or different scenarios, which hinder deployment and limit their generalization to other vascular regions."}, {"title": "B. Segment Anything Models", "content": "In recent years, visual foundational models tailored for specific segmentation tasks have gained increasing attention. The Segment Anything Model (SAM) [8], the first large foundational model designed for segmentation, has not only demonstrated outstanding performance on natural images but also shown remarkable promise for generalization in medical image analysis. Huang et al. [9] evaluated SAM\u2019s applicability in medical contexts, highlighting its significant potential in medical image segmentation. Ma et al. [21] proposed MedSAM, trained on a large dataset of over 1 million images across 11 imaging modalities, which outperformed U-Net expert models in segmentation tasks. SAM-med2d [22] and Medical SAM Adapter [23] introduced Adapter modules, while SAMed [24] utilized LoRA for efficient fine-tuning, achieving high performance across multiple medical image segmentation tasks. Chai et al. [25] developed a staged fine-tuning approach that integrates a complementary CNN encoder with the SAM architecture, focusing on fine-tuning only the CNN and SAM decoder to minimize computational resources and training time. Similarly, Lin et al. [26] proposed SAMUS, which integrates a parallel CNN branch to inject local features into the ViT encoder, with position and feature adapters to modify SAM for clinically friendly deployment on smaller input sizes. Qin et al. [27] introduced DB-SAM, combining a ViT branch and a convolution branch to bridge the domain gap between natural images and 2D/3D medical images.\nDespite the impressive performance of SAM in general medical segmentation, its results in vascular imaging may not be as favorable. While SAM\u2019s ViT-based image encoder excels at global context modeling and provides a larger receptive field, it tends to capture global and low-frequency information [28]. However, vessel images are characterized by fine-grained and sparse features, with numerous micro-vessels, posing a challenge for the ViT encoder, which is less effective at capturing detailed, high-frequency information. While fine-tuning SAM on vascular data can improve performance, it often results in the loss of small vessels and fragmentation.\nTo address these issues, Ke et al. [28] proposed HQ-SAM, which introduced a learnable high-quality output token into the SAM mask decoder to predict more accurate masks. They also fused mask encoding with early and final ViT features to enhance mask details. Yuan et al. [29] proposed RWKV-SAM, which combined convolution and RWKV operations with an efficient decoder and multi-scale tokens to generate high-quality segmentation masks. Despite these advancements, there is still no universal segmentation model specifically designed for vascular imaging. Furthermore, existing methods often overlook topological preservation in segmentation, limiting their effectiveness in universal vessel segmentation."}, {"title": "C. Topology Correction-Based Post-Processing Method", "content": "The connectivity of vascular structure segmentation holds significant clinical value in medical applications [12], [30]. Although it may not lead to a large improvement in overlap metrics such as the Dice score, it considerably boosts the practical interpretability and visual quality for physicians [11]. The issue of connectivity differs from general segmentation tasks, since the area prone to disconnection normally arise in thin microstructure, which is less highlighted in overlap-oriented optimizations [31]. As a consequence, common segmentation optimization algorithms mostly fail to handle this, resulting in vessel discontinuities. To address this challenge, various research has proposed additional post-processing strategies that enhance segmentation connectivity.\nTeichmann et al. proposed ConvCRF [32], which combines the structured modeling capabilities of Conditional Random Fields (CRF) with the feature extraction power of Convolutional Neural Networks (CNN) to effectively execute CRF on GPUs. Jha et al. introduced a dual UNet architecture [33], where two UNets are employed to generate coarse and refined segmentation results, respectively. Ye et al. designed VSR-Net [34], which utilizes a Curve Clustering Module (CCM) to build fragmented clusters, then patches the broken segments with a specially designed Curve Merging Module (CMM). Wang et al. introduced SegRefiner [35], which incorporates a diffusion model to refine coarse masks by employing a discrete diffusion process."}, {"title": "III. METHOD", "content": "To adapt the universal segmentation model for vessel segmentation while maintaining its strong generalization capability and leveraging its pre-trained weights, we developed OVS-Net. The model consists of five main modules: the macro vessel extraction module, the micro vessel enhancement module, the mask prediction module, the prompt encoder module, and the morphological correction-based post-processing network module. The overall architecture is illustrated in Figure 2. The macro vessel extraction module retains the ViT image encoder backbone from SAM and introduces feature and spatial adapters to better align the model with vascular characteristics. The micro vessel enhancement module uses a convolutional network based on ConvNext and FPN to improve the extraction of small vessel features. We kept the original design of the prompt encoder. The mask prediction module builds on the SAM mask decoder backbone, with enhanced feature connections to improve segmentation accuracy. Finally, the morphological correction-based post-processing network module is based on a simple U-Net architecture, designed to refine the pre-segmentation mask, ensuring improved connectivity and structural integrity in the final output. For vascular images, the network performs two segmentation predictions. The primary segmentation network, comprising the macro vessel extraction module, micro vessel enhancement module, prompt encoder module, and mask prediction module, generates the initial vessel segmentation mask. The post-processing network then generates a secondary prediction to repair disconnected vessels while preserving the intended separations. A detailed description of the implementation of each module is provided in the following sections."}, {"title": "A. Overview", "content": "To adapt the universal segmentation model for vessel segmentation while maintaining its strong generalization capability and leveraging its pre-trained weights, we developed OVS-Net. The model consists of five main modules: the macro vessel extraction module, the micro vessel enhancement module, the mask prediction module, the prompt encoder module, and the morphological correction-based post-processing network module. The overall architecture is illustrated in Figure 2. The macro vessel extraction module retains the ViT image encoder backbone from SAM and introduces feature and spatial adapters to better align the model with vascular characteristics. The micro vessel enhancement module uses a convolutional network based on ConvNext and FPN to improve the extraction of small vessel features. We kept the original design of the prompt encoder. The mask prediction module builds on the SAM mask decoder backbone, with enhanced feature connections to improve segmentation accuracy. Finally, the morphological correction-based post-processing network module is based on a simple U-Net architecture, designed to refine the pre-segmentation mask, ensuring improved connectivity and structural integrity in the final output. For vascular images, the network performs two segmentation predictions. The primary segmentation network, comprising the macro vessel extraction module, micro vessel enhancement module, prompt encoder module, and mask prediction module, generates the initial vessel segmentation mask. The post-processing network then generates a secondary prediction to repair disconnected vessels while preserving the intended separations. A detailed description of the implementation of each module is provided in the following sections."}, {"title": "B. Macro Vessel Extraction Module", "content": "The original SAM architecture consists of three main components: the image encoder, the prompt encoder, and the mask decoder. The image encoder is based on the ViT network, pre-trained with Masked Autoencoders (MAE) [36], and is responsible for encoding the input image. The encoded image is then combined with the prompt encoding from the prompt encoder before being passed to the mask decoder. Due to the superior receptive field of the ViT encoder, we retain the original SAM ViT encoder architecture, using it as the backbone for the macro vessel extraction module.\nTo enable more efficient fine-tuning, we introduce an Adapter into each ViT block while freezing the parameters of the original ViT encoder during training. The Adapter consists of two components: a feature adapter and a spatial adapter, with the latter augmented by residual connections to enhance performance. Specifically, the spatial adapter is applied with skip connections after the Multi-Head Self-Attention (MHSA) layer, followed by the addition of the feature adapter after LayerNorm. This structure allows for effective feature extraction while preserving spatial information, enabling the model to adapt to the vessel segmentation task and ensuring successful macro-vessel extraction, all while keeping the ViT encoder parameters frozen. The procedures for the spatial adapter and feature adapter are outlined as follows:\n$SA(X) = X + W_2G(W_1 X)$\n$FA(X) = W_2G(W_1 \\cdot X)$\nwhere $W_1 \\in \\mathbb{R}^{D \\times D}$, $W_2 \\in \\mathbb{R}^{D \\times D}$, and $G$ denotes the GELU function.\nWith this design, we can fine-tune the model more efficiently while keeping the ViT encoder parameters frozen. Additionally, to improve the model\u2019s ability to extracting micro-vessel features, we incorporated a convolution-based micro vessel enhancement module."}, {"title": "C. Micro Vessel Enhancement Module", "content": "The micro vessel enhancement module is built on ConvNext-tiny [37] and consists of four ConvNext stages. To enhance its ability to capture micro-vessel features, we integrate Convolutional Block Attention Module (CBAM) blocks into each ConvNext stage. This integration enriches feature representation while suppressing background noise and interference from surrounding tissues, especially in areas requiring focused attention. The four ConvNext stages contain 3, 3, 9, and 3 ConvNext blocks, respectively, resulting in feature dimensions of 96, 192, 384, and 768.\nTo further refine the extracted features, we introduce a feature pyramid after the ConvNext stages. This addition enhances the multi-scale representation of the convolutional features, improving their compatibility with the global features from the macro vessel extraction module. We use cross-attention to fuse the global and micro-vessel features. The micro vessel enhancement module adapts its attention based on the macro vessels, allowing it to focus more effectively on important features. Likewise, the global features extracted by the macro vessel extraction module are integrated with micro-vessel features to capture finer vascular details. This synergy enables the model to more accurately extract information from vessels of varying sizes."}, {"title": "D. Mask Prediction Module", "content": "The mask prediction module is based on the original mask decoder from SAM, which consists of a lightweight transformer layer and a segmentation head for mask prediction. Although this step is fundamental to segmentation, we aim to improve accuracy by incorporating ideas from prior work [28], which emphasize the need for both rich global semantic context and fine local boundary details. To better integrate global and local features, we introduce a fusion of high-level and low-level features within the mask decoder. Specifically, we combine the shallow features from the first ConvNext stage with the mask features produced by the two-way transformer in the mask decoder. The shallow features capture more local information and edge details, which are crucial for accurately delineating vessel boundaries. By fusing these shallow features with the global mask features, we inject local details into the segmentation process, thereby improving the overall accuracy of the mask prediction. This fusion approach allows the model to better preserve fine vascular details, ensuring that small vessels and complex structures are accurately segmented. The combination of high-level and low-level features helps the model achieve a more comprehensive understanding of the vascular structures, improving its segmentation performance across varying vessel sizes and shapes."}, {"title": "E. Morphological Correction based Post-Process Network", "content": "Unlike typical segmentation tasks, vessel segmentation imposes stringent requirements on the connectivity of the segmentation results. This connectivity is essential for accurate hemodynamic analysis, which aids in assessing patient health and prognosis, ultimately improving healthcare outcomes. To meet these requirements, we introduce a post-processing network based on morphological correction. The principle is inspired by Masked Image Modeling (MIM), but instead of masking random regions, we mask the fragmented areas of the vascular masks.\nGiven a network with both fragmented predicted masks and ground truth masks, the network is trained to predict the missing (i.e., fragmented) vascular structures. This allows the model to learn the correct connections at points of disconnection and repair the broken vessels. Simultaneously, for vessels that are meant to remain disconnected, the network ensures that these discontinuities are preserved. The post-processing is performed using a simple U-Net architecture, with MSE loss and ClDice loss [12] as the loss functions. By training on a dataset that includes fragmented examples, even a basic U-Net model can learn to effectively repair disconnected vessels."}, {"title": "IV. EXPERIMENT", "content": "1) Dataset: To train a generalizable vessel segmentation model and assess its generalization capability, we constructed the largest vessel segmentation dataset, comprising 17 publicly available or request-access datasets. These datasets cover four types of images: X-ray Coronary Artery, Fundus Retina, OCTA Retina, and X-ray Pelvic Iliac Artery. Specifically, the coronary artery dataset includes 134XCA [38] (also known as DCA1) and XCAD [39]; the fundus dataset includes ARIA [40], CHASE_DB1 [41], DR-HAGIS [42], DRIVE [43], FIVES [44], HRF [45], IOSTAR [46], Les-AV [47], ORVS [48], and STARE [49]; the OCTA dataset includes ROSE-1 [18], ROSSA [50], and OCTA500 [51], with 39 pixel-level annotated images selected from ROSE-1; and the Pelvic-Iliac artery dataset is DrSAM [52].\nWe used 15 of these datasets for training and internal validation, each containing separate training, validation, and test sets. In addition, we evaluated the out-of-domain generalization of our model using the test sets from two additional datasets as external validation. Detailed information on the datasets is"}, {"title": "A. Experimental Setup", "content": "We used the SAM model with a ViT-B architecture as the backbone, loading the corresponding pre-trained weights. In the macro vessel extraction module, we froze the ViT parameters during training, allowing only the adapters to be trained. The network and training were implemented in PyTorch on a Tesla V100-PCIE-32GB GPU. The principal segmentation network, as the initial module in our framework, was trained for 20 epochs with a batch size of 2, a learning rate of 0.001, and the AdamW optimizer. We used a combination of binary cross-entropy and Dice loss to improve vessel detection accuracy. The post-processing network, following the primary segmentation, was trained for 5 epochs with the same batch size, learning rate, and optimizer. Here, we applied Mean Squared Error (MSE) and ClDice loss to refine the segmentation results, ensuring more precise vessel delineation.\nFor evaluation metrics, we selected Dice and Intersection over Union (IoU) to assess the overall segmentation performance. Additionally, recognizing that improvements in connectivity may not significantly affect pixel-based metrics such as Dice, we introduced additional metrics to evaluate the connectivity of the segmentation results: ClDice and the normalized Betti number $\\beta_0$. The normalized Betti number $\\beta_0$ is calculated as follows:\n$\\beta_0 = \\frac{1}{N} \\sum_{i=1}^N |CC(X_i) - CC(Y_i)|$\nWhich, referring to the methodology above, we split a mask into multiple 64\u00d764 patches, where N represents the number of patches and CC denotes the number of disconnected components within a patch."}, {"title": "B. Comparing with SAM Based Method", "content": "In this section, we validate the performance of our proposed method by comparing OVS-Net with several state-of-the-art SAM-based segmentation networks, including MedSAM [21], MSA [23], SAM-Med2D [22], Finetune-SAM [53], SAMUNet [54], and HQ-SAM [28], on both internal and external validation datasets. To ensure a fair comparison, we trained these SAM methods on the constructed vessel dataset, adhering to their respective default training protocols. The performance scores for different anatomical locations and modalities on both the internal and external validation datasets are presented in Table II. Thanks to its multi-scale vessel extraction capability and morphological correction-based post-processing network, OVS-Net outperformed the other methods, achieving the highest average Dice, IoU, and ClDice scores, along with the lowest Bo score. Compared to the second-best SAM method, OVS-Net improved the average Dice score by 1.46 and improved connectivity by 34.6%. Figure 3 visualizes the segmentation results across various datasets, showing that our method effectively captures small vessels and addresses vessel discontinuities. Figure 4 further visualizes the radar chart comparing OVS-Net and the suboptimal SAM method on datasets with complex vascular structures, highlighting our method\u2019s superior performance on high-resolution datasets with intricate and fine vessels (e.g., Dr-Hagis, ORVS, HRF). This demonstrates the effectiveness of OVS-Net in handling small vessel segmentation, which is crucial for clinical applications where precise vessel delineation impacts diagnostic and therapeutic decisions. Furthermore, OVS-Net maintained its competitive edge on the external dataset, achieving the best performance with a 1.79 improvement in average Dice scores and a 30.7% improvement in connectivity. These results not only demonstrate the effectiveness of OVS-Net but also highlight its strong generalization ability across diverse datasets and imaging modalities, underscoring its potential for broader clinical applications."}, {"title": "C. Comparing with Task-Specific Expert Methods", "content": "In this section, we present a comprehensive quantitative comparison of our method against various expert models on both internal and external validation datasets, providing a clear perspective on its performance relative to established benchmarks. The score comparisons for representative datasets are shown in Tables III, IV, and V, while external validation dataset scores are provided in Table VI. The scores of expert models are taken from [55], [56], [57], [58], [59], and [46], with [57] being the only source reporting standard deviation. We also plotted a bar chart in Figure 5 to compare the scores of OVS-Net with the expert models. For the expert model selection, we chose the model with the highest Dice score for comparison.\nIn Table III, we compare the segmentation scores of our method with 11 prominent expert models, including U-Net [60], U-Net++ [61], Attention-Unet [62], CE-Net [63], CAUNet [64], CS2-Net [65], FR-Net [16], DE-DCGCN-EE [66], GT-DLA-dsHFF [67], and SPIRONet [55], across two coronary artery datasets. Our method outperforms all others in coronary artery segmentation, achieving average Dice scores of 80.55 and 83.14, surpassing the latest state-of-the-art methods. This notable improvement underscores the effectiveness of our model in accurately delineating vascular structures, which is crucial for clinical decision-making in cardiovascular health.\nFor retinal fundus datasets, Table IV compares our approach with five expert models: U-Net [60], U-Net++ [61], AttentionUNet [62], CS-Net [69], and H2Former [70] across three datasets. On all three fundus datasets, our method consistently achieves the highest average Dice and IoU scores, demonstrating its robustness in handling variations in retinal images. While OVS-Net achieves the highest Dice score on the DRIVE dataset, it records a slightly lower IoU compared to CS-Net."}, {"title": "D. Ablation Study", "content": "To validate the effectiveness of the proposed improvements, we conducted a series of ablation studies on the internal validation dataset. In these experiments, we incrementally added the adapter, micro vessel enhancement module, feature concatenation in the Mask Decoder, and the morphological correction-based post-processing network to the baseline model. The Dice score and Betti number Bo were used as performance metrics, and the results for each configuration are reported in Table VIII. The experimental results show that each modification improves SAM\u2019s performance on vascular imaging, with the micro vessel enhancement module and post-processing network having the most significant impact on segmentation accuracy.\nAfter integrating the micro vessel enhancement module, we observed a 1.31-point increase in the average Dice score, indicating a significant improvement in segmentation precision. To better illustrate this improvement, we visualized the feature activation maps before and after incorporating the module, as shown in Figure 6. In this visualization, we selected the four channels with the highest mean activation for closer examination. The feature maps show a clear enhancement in delineating vascular boundaries and a stronger focus on small vessel after the module was added. This suggests that the micro vessel enhancement module helps the network capture features more effectively across different vessel sizes, which is crucial for accurate segmentation in complex vascular structures.\nFurthermore, after incorporating the post-processing network, we observed a reduction of 0.14 in the Betti number Bo, indicating improved connectivity in the segmentation results. To visually demonstrate this, Figure 7 compares the segmentation outcomes from the Primary Segmentation phase, before and after applying the post-processing network. In this figure, blue boxes highlight areas where the network successfully preserved inherent disconnections in the ground truth, while green boxes show where it effectively corrected segmentation breaks. Importantly, the post-processing network not only repairs these breaks but also preserves natural disconnections found in the original data, which is valuable for clinical applications as it ensures the segmented results align with the anatomical features of vascular structures."}, {"title": "V. CONCLUSION", "content": "In this paper, we propose OVS-Net, a novel network exploring the Segment Anything Model (SAM) for optimized vessel segmentation. OVS-Net features five key modules: a macro vessel extraction module, micro vessel enhancement module, prompt encoder, mask prediction module, and a morphological correction-based post-processing network. The hybrid encoder architecture exploits SAM\u2019s Vision Transformer (ViT) for macro feature extraction with a convolution-based module for enhancing fine vessel structures and edges, critical for precise segmentation. Low-level feature fusion in the mask prediction module integrates global and local features, enabling accurate segmentation across varying scales and complexities. The post-processing network further improves clinical relevance by correcting vessel disconnections while preserving natural anatomical gaps, ensuring segmentation results are both accurate and meaningful.\nComprehensive experiments across 17 datasets demonstrate that OVS-Net achieves superior segmentation accuracy, enhanced connectivity, and robust generalization across diverse imaging modalities. While this study focuses on technical evaluation, future work will aim to integrate OVS-Net into clinical workflows, conducting user studies to assess its practical impact and potential to improve diagnostic and therapeutic outcomes, ultimately benefiting patient care."}]}