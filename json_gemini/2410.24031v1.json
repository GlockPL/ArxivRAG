{"title": "A MULTI-MODAL APPROACH FOR FACE ANTI-SPOOFING IN NON-CALIBRATED SYSTEMS USING DISPARITY MAPS", "authors": ["Ariel Larey", "Eyal Rond", "Omer Achrack"], "abstract": "Face recognition technologies are increasingly used in various applications, yet they are vulnerable to face spoofing attacks. These spoofing attacks often involve unique 3D structures, such as printed papers or mobile device screens. Although stereo-depth cameras can detect such attacks effectively, their high-cost limits their widespread adoption. Conversely, two-sensor systems without extrinsic calibration offer a cost-effective alternative but are unable to calculate depth using stereo techniques. In this work, we propose a method to overcome this challenge by leveraging facial attributes to derive disparity information and estimate relative depth for anti-spoofing purposes, using non-calibrated systems. We introduce a multi-modal anti-spoofing model, coined Disparity Model, that incorporates created disparity maps as a third modality alongside the two original sensor modalities. We demonstrate the effectiveness of the Disparity Model in countering various spoof attacks using a comprehensive dataset collected from the Intel\u00ae RealSense\u2122\u2122 ID Solution F455. Our method outperformed existing methods in the literature, achieving an Equal Error Rate (EER) of 1.71% and a False Negative Rate (FNR) of 2.77% at a False Positive Rate (FPR) of 1%. These errors are lower by 2.45% and 7.94% than the errors of the best comparison method, respectively. Additionally, we introduce a model ensemble that addresses 3D spoof attacks as well, achieving an EER of 2.04% and an FNR of 3.83% at an FPR of 1%. Overall, our work provides a state-of-the-art solution for the challenging task of anti-spoofing in non-calibrated systems that lack depth information.", "sections": [{"title": "Introduction", "content": "In recent years, face recognition technologies have seen a significant increase in popularity across a wide line of products, including access control systems, phone unlocking mechanisms, digital payment platforms, and attendance tracking systems. Despite their widespread adoption, these systems remain susceptible to substantial security risks, such as Face-Spoofing (FS) or Face Presentation Attacks (FPA). Consequently, detecting spoof attempts in modern face recognition systems has become an active area of research in both academia and industry. As a result, numerous papers and datasets have been introduced in this field (Zhang et al. [2022a], Steiner et al. [2016]), and anti-spoofing modules are increasingly being integrated into modern products prior to the face recognition phase (See Appendix A for more details).\nThe domain of spoof attacks can be categorized into two primary types: 2D attacks (e.g., printed papers, different types of screens) and 3D attacks (e.g., 3D masks made from rigid materials, silicone masks, fabric masks). For 2D attacks, stereo-depth cameras have demonstrated promising results (Zhang et al. [2019]). However, stereo-depth cameras could be expensive and less feasible for widespread adoption in most real-life scenarios. On the other hand, Near-IR (NIR) sensors are less-expensive than stereo-depth cameras, and are used as a preferable option for lower-budget use cases and"}, {"title": "Related work", "content": "FAS is an active research area in both industry and academia, where various sensors are examined and utilized to counter different spoofing attacks.\nMulti-Modality FAS Multi-modality is a robust mechanism that enables FAS systems to integrate various physical attributes from different sensors. Jiang et al. [2019] utilized visible light and NIR sensors with three levels of data fusion. In the Data Level Fusion, data from both modalities are concatenated across the channels and are used as input to a Convolutional Neural Network (CNN). In the Feature Maps Level Fusion, feature maps are computed separately for each modality via a CNN, then they are concatenated across the channels and are used as input to a sub-network classification module. In the Fully Connected Level Fusion, fusion is applied only to the final layers of the network. The final prediction probability is a weighted average of the probabilities from all three fusion sub-models. In Zhang et al. [2022a], the authors utilized active stereo depth input, comprising RGB and NIR data. They integrated these inputs into a single decision at the CNN level using the Squeeze and Excitation (SE) mechanism (Hu et al. [2018]). In Lin et al. [2024], the authors used Visual Transformer (ViT) blocks as a backbone for each modality (RGB and NIR). They also introduced a decision mechanism based on uncertainty estimation, with the authors adaptation of Monte Carlo sampling (Kendall et al. [2015]) to evaluate the feature unreliability in each modality. Based on the uncertainty score, they weighted the prediction in cross-modal attention fusion. Yu et al. [2020a] proposed using Central Difference Convolution (CDC) (Yu et al. [2020b]) to enhance the model's ability to capture intrinsic live or spoof features from each modality separately. Subsequently, the features are concatenated and processed by a single sub-model that produces a binary mask, where the final score is determined by averaging the values of the mask.\nDepth-based FAS The primary motivation for employing depth sensing in FAS systems is its robustness against 2D spoof attacks, which are the most common attacks in real-life scenarios. Atoum et al. [2017] utilized two streams during the process. The first stream employs a trained depth estimator using images extracted from a single source,"}, {"title": "Method", "content": "3.1 Camera sensors process\nStandard RGB cameras are designed to produce visually appealing images based on human visual perception. Thus, various Digital Signal Processors (DSPs) are employed to process raw images and enhance their visual appeal. However, in Facial Anti-Spoofing (FAS) systems, the objective is fundamentally different. The primary goal is to extract features pertinent to distinguish between live and spoof images, rather than generating visually appealing images. Therefore, in our pipeline, the demosaicing algorithm (Li et al. [2008]) is not performed, and instead the raw Bayer pattern from the sensor, reshaped into four channels, is used. Specifically, two four-channel images are produced: one from the left sensor (s1) and one from the right sensor (sr). Further details are provided in Appendix B.\n3.2 Disparity maps\nCertain forms of Spoof attacks are characterized by a unique facial structure. For instance, two-dimensional spoof attacks are composed of a plane within a sphere, whereas alternative attacks might be performed via other geometric structures, such as a cylinder. Occasionally, the information provided by texture alone is insufficient for the precise operation of anti-spoofing systems, necessitating the incorporation of three-dimensional geometric knowledge. In response to the absence of depth data in the system's ASIC, and the lack of intrinsic and extrinsic information from the sensors, we acquire three-dimensional knowledge through a specialized methodology.\nTwo images are under consideration, the initial one being derived from the left sensor (s1), and the subsequent one from the right sensor (sr). Both images are applied to a Face Detector (FD) model followed by a Facial landmarks extractor (LE). The latter yields 45 facial landmarks distributed across the face. Both the FD and LE models are specifically trained to process data from the Intel\u00ae RealSense\u2122 ID Solution F455 and are dedicated to this domain. For additional details, please refer to Appendix C. Formally, this can be expressed as:\n$rect_k = FD(s_k)$\n$lms_k = LE(rect_k, s_k)$\nWhere k \u2208 {l, r} refers to the sensor, $rect_k$ is the rectangle circumscribing the face captured by sensor k, and $lms_k$ represents 45 facial landmarks extracted from sensor k image, while each facial landmark is a two-dimensional point within the image."}, {"title": "Method", "content": "To estimate relative depth, we utilize pairs of landmarks from two sensors, each projected from the same 3D point on the sphere. For a given point on the face, denoted as $P_i$, and its corresponding facial landmarks from each sensor, $lms_{l,i}$ and $lms_{r,i}$ we can determine the disparity in each dimension by subtracting the former from the latter:\n$disp_{i,x} = lms_{r,i,x} - lms_{l,i,x}$\n$disp_{i,y} = lms_{r,i,y} \u2013 lms_{l,i,y}$\nWhere i \u2208 {1,45} is the facial landmark index, x and y represent the horizontal and vertical dimension within the image respectively, and $disp_{i,d}$ is the disparity of facial landmark i over dimension d.\nUnderstanding disparity, the difference in image location of an object seen along two different lines of sight, can provide valuable insights into the depth relationships between facial features. For instance, in a capture of live instance in frontal pose, the tip of the nose should exhibit greater disparity than the pupil of the eye, given that the nose is closer to the camera system, unlike in some 2D spoof attacks. Another significant advantage of understanding disparity is the capability to estimate the depth of the entire head in relation to its size. This becomes particularly crucial when attempting to detect spoof attacks that are often carried out using smaller images. In calibrated stereo systems, disparity is typically computed using predefined system information. However, in our approach, we have calculated it utilizing the knowledge of facial attributes.\nFinally, to complete the spatial disparity information of the face, we perform a linear interpolation (LI) across the pixels of the left sensor. This process is guided by the sparse disparity values derived from the facial landmarks.\n$dispmap_x = LI(lms_{l,x}, disp_x)$\n$dispmap_y = LI(lms_{l,y}, disp_y)$\nWhere x and y represent the horizontal and vertical dimensions of the image respectively. $dispmap_d$ is the disparity-map calculated using the sparse disparity $(disp_d)$ over dimension d. The linear interpolation is implemented using the SciPy 3 library (Virtanen et al. [2020]). Figure 1 presents live and spoof examples of disparity maps and their process steps.\n3.3 Disparity Model\nData-process A dedicated deep learning model to predict 2D spoof attacks is developed by utilizing relative disparity knowledge. Given that the disparity map contains spatial pixel-wise data, it can be processed by convolutional neural network (CNN) kernels along with their corresponding texture maps on a pixel-wise basis. Specifically, the model's input comprises ten channels from three modalities: four channels from the left sensor, four channels from the right sensor, and two channels are the disparity maps both for horizontal and vertical dimensions. The complete multi-modal data process is illustrated in Figure 2. The four-channel images from both sensors are first applied to a face-detection model and cropped around the detected face with extension of 15% per dimension. The image from the right sensor is then aligned to the left crop with four degrees of freedom in terms of scale and translation. Subsequently, the disparity maps, created based on the spatial structure of the left sensor, are cropped and concatenated with the two sensors crops. Finally, the 10-channels input is resized to 128x128 pixels and is fed into the disparity model.\nModel Details To achieve optimal product efficiency and the ability to operate on an edge device, the disparity model is based on a modified version of MobileNetV2 architecture (Sandler et al. [2018]). The Disparity model comprises 27 convolution layers, each followed by a batch normalization layer and a ReLU activation function. This model contains approximately 1 million trainable parameters.\nIn security systems it is essential to obtain reliable predictive probabilities. This is particularly crucial when integrating multiple models, each with distinct probability decision thresholds. However, the conventional SoftMax loss function tends to exhibit overconfidence, which subsequently results in outputs that are unreliable as probability distributions (Sensoy et al. [2018], Achrack et al. [2020], Neumann et al. [2018]). To address this issue, a high Evidential Deep Learning loss is employed during the training of the model, thereby ensuring the generation of stable and well-calibrated outputs (Sensoy et al. [2018])."}, {"title": "Data Augmentations", "content": "The disparity model employs a multi-modal approach, which results in a unique methodology for data augmentations during training. This technique comprises three levels of augmentation:\n\u2022 Landmarks Augmentations. Augmentations are performed on facial landmarks to enhance stability against landmark extractor errors, which could lead to errors in the disparity maps. These augmentations include noising random number of landmarks, with random translation values per landmark. Another type of facial landmark augmentation simulates landmark extractor bias for an entire facial organ region (e.g., a shift in nose landmarks coordinates). For this augmentation, a facial organ is uniformly sampled, and all landmarks in that region are translated by the same magnitude. In both augmentations, the magnitude of translation is determined by a uniform sampling method, with a maximum limit set to 6% of the respective facial dimension. Additionally, we introduce the outlier augmentation, where the magnitude of the translation is uniformly sampled between 6% to 14% of the face size per dimension. In this scenario, up to four facial landmarks are translated with a larger magnitude to simulate outliers.\n\u2022 Sensor Intensity Augmentations. To enhance robustness against a range of variables that influence the intensity of sensor outputs, a series of standard augmentations are applied directly to the output channels of these sensors. These augmentations include color jittering and mean-variance adjustments, which modify the brightness and contrast within the image. Additionally, noise is introduced to alter the intensity of individual pixels across the image, and motion blur is applied to mimic the blurring effect caused by head movements. It is important to note that these augmentations are exclusively applied to the direct outputs of the sensors, and not to the disparity maps.\n\u2022 Spatial Augmentations. These augmentations, which include horizontal flipping, rotation, and shearing, are designed to effectively expand the training dataset. Furthermore, a cut-out augmentation technique is employed, wherein a specific region of the input is masked to minimize the model's dependency on particular regions during training. The ratio between the face and the background size is also augmented, and is being uniformly sampled between 40% to 80% during the cropping process. Additionally, the bounding box of the face undergoes a random translation, up to 20% of its size, prior to the cropping process. This is done to enhance the model's robustness against the face detector 's errors. The same set of spatial augmentations is applied across all modalities including the disparity maps."}, {"title": "Model Ensemble setup", "content": "The disparity model is designed to counteract unique structures of spoof attacks, particularly 2D attacks, by using additional proxy-depth knowledge. However, the disparity maps can mislead the model in 3D attacks scenarios where face geometry closely mimics reality. To address this, two additional models are trained to address 3D attacks.\nThe first additional model, referred to as the Left Model, processes inputs from the left sensor's four channels. The second model, coined as the Right Model, is designed to process data from the right sensor's four channels. Both these models share the same architectural design as the Disparity Model, with the exception of the input layer size. They also employ the same data augmentation techniques, barring the landmarks augmentations. Eventually, these three models are integrated into a 3-model-ensemble. The final decision is determined by an 'OR' operation applied to the spoof predictions. I.e. if any one of the models predicts a spoof attack for a given system input, the ensemble prediction is classified as a spoof attack.\nEach model's decision threshold is determined using a dedicated software that seeks an optimal threshold combination among the models. This search is conducted in two stages: initially at high level with high granularity iterations, followed by a more detailed search with smaller granularities, centered around the results from the high-level search. This approach ensures a comprehensive and precise threshold determination."}, {"title": "Experiments", "content": "4.1 Data\nIn this study, we demonstrate our multi-modal approach, using data collected from the Intel\u00ae RealSenseTM ID Solution F455 NIR sensors, which comprises two non-calibrated sensors. The data was captured using 20 distinct systems, to avoid over-fitting to a single device. The collected live samples contained 10.7K different identities in various conditions, with total amount of approximately 1.7M images. These conditions included diverse background lighting, distances from the device (up to 2 meters), head poses (up to 40 degrees for yaw, pitch, and roll), locations (both indoors and outdoors), occluding accessories (such as hats, sunglasses, and face COVID-19 masks), and facial expressions (Figure 3).\nMoreover, variety of spoof attacks were collected. The 2D attacks involved printed papers of different sizes (A3, A4), television screens, and mobile phone screens as well as curved screens. In each 2D spoof attack, a face that fulfilled the real footage criteria was displayed. The 3D attacks incorporated cut papers placed over a live instance's face that revealed its nose, papers rolled into a cylinder, and latex masks worn by live individuals. In total, 2M various spoof data were collected (Figure 4).\nThe dataset was divided such that 85% was allocated for training and 15% for validation. Additionally, an external test set comprising approximately 100,000 samples of both live and spoof attacks was collected separately to enhance the generalization of the evaluation. It is important to note that each dataset contained different individual subjects. In the test and validation datasets, the proportion of 2D attacks within the total spoof data is larger than that of 3D attacks. This is based on the belief that 2D attacks more accurately reflect real-life scenarios, as they are easier to produce using simple means.\n4.2 Metrics\nIn our convention, live samples are classified as positive instances, while samples of spoof attacks are classified as negative instances. Consequently, the False Negative Rate (FNR) represents the proportion of failures among all live"}, {"title": "Experimental Setup", "content": "The disparity model is specifically designed to counter 2D attacks by leveraging additional proxy-depth knowledge. Consequently, we train and evaluate it using only live and 2D attacks samples. As baselines, we implemented four other anti-spoofing approaches inspired by the literature.\nThe first approach, termed Facial Features Pairs, involves calculating the Euclidean distance between all pairs of facial landmarks (Anthony and Ay [2022]), resulting in a 2025-feature vector derived from 45 facial landmarks of each sensor source. Several multi-layer perceptrons (MLPs) were examined using the feature vectors as inputs, and we report the results for the MLP with the best performance.\nAdditionally, we trained a CNN model that processes data from both sensors as an 8-channel input. This model shares the same architecture as the disparity model, except for the first input layer. Another approach examined is the Patch-CNN, where patches of the concatenated data are processed by a shared CNN, and the final prediction is averaged among all patch outputs, as described in Atoum et al. [2017].\nFurthermore, we implemented the Multilevel Fusion model architecture from Jiang et al. [2019], adjusting the model size to approximately 1 million trainable parameters, similar to the size of the disparity model. In the original paper, the authors integrated data from Visual and NIR sensors at three steps of the deep learning pipeline (Jiang et al. [2019]). Here, we perform the same integration, but by using data from the two NIR sensors of the Intel\u00ae RealSense\u2122 ID Solution F455 device.\nAll models were trained on the same dataset using the TensorFlow framework (Abadi [2016]) and two GeForce GTX 1080 Ti GPUs. We employed the ADAM optimizer (Kingma [2014]) with a momentum of 0.9 and a learning rate of 1e-4. The training process involved a batch size of 32 over 20 epochs, where the checkpoint with the highest accuracy on the validation set was reported.\nFinally, we trained the Left and Right models as complementary components of the model ensemble, specifically designed to address 3D attacks. These models share the same architecture and training procedure as the Disparity Model, with the addition of incorporating instances of 3D attacks into the dataset."}, {"title": "Results", "content": "5.1 Disparity Maps Examples\nFigure 5 and Figure 6 illustrate additional examples of live and spoof disparity maps, respectively. In these figures, each row corresponds to a different subject. The leftmost column displays the original image. Moving from left to right, the subsequent columns show the disparity maps generated along the horizontal axis $(dispmap_x)$ and the vertical axis"}, {"title": "Attacks Comparison", "content": "In Table 1, we present our experimental results for the Disparity Model on the test benchmark, which includes both live and 2D attacks. Additionally, we provide results for other anti-spoofing methods across various metrics. The best result in each metric is highlighted in bold. We observe that our method achieves better results than other previous approaches in all metrics.\nThe Facial Features Pairs approach, which utilizes distances between facial landmarks including their sparse disparity information, performs poorly in our challenging domain. This can be attributed to its lack of texture information and the absence of spatial disparity information, which our method includes. Texture-based approaches that directly use the sensors data show better performance, with the Multilevel Fusion model outperforming the others with an EER of 4.16%.\nHowever, our multi-modal method, which incorporates disparity maps in addition to raw sensors data as texture, demonstrates superior performance compared to the Multilevel Fusion model. Specifically, our method improves the EER by 2.45% and the FNR by 3.35%, 3.27%, and 7.94% at spoof acceptance rates of $\\frac{5}{100}$, $\\frac{3}{100}$, and $\\frac{1}{100}$, respectively.\nFurthermore, the ablation study presented in Table 2 highlights the significance of disparity maps in the disparity model. The results indicate that integrating disparity maps with the raw data from the right sensor (that includes an IR channel) outperforms the integration with the data from the left sensor. However, the combination of all components results in the highest performance.\nMoreover, we analyzed the weights from the first convolutional layer of the Disparity model to assess the impact of each input type on the model's output. The disparity maps reached a maximum of value of 480, while the raw sensor data values could attain up to 1024. To ensure a fair comparison, the kernel weights of the disparity maps were scaled by a factor of $\\frac{480}{1024}$. The normalized histogram of the first layer's weights, as shown in Figure 7, indicates that the weight values corresponding to the disparity maps are distributed similarly to those of the raw sensor data. This suggests that both input types contribute equally to the model's decision making."}, {"title": "Model Ensemble", "content": "Our ensemble comprises three models: the Left Model, the Right Model, and the Disparity Model. This ensemble was evaluated on the complete test set, which includes both 2D and 3D attacks. As presented in Table 3, the overall benchmark, encompassing all types of spoof attacks, yielded an Equal Error Rate (EER) of 2.04%, while for a false acceptance rate of $\\frac{1}{100}$, FNR is 3.83%. Among the various spoof attack means, the tablet screen, mobile phone screen, and desktop screen exhibited the lowest EER of 0.74%, 0.75%, and 0.86%, respectively. In contrast, the challenging 3D Latex Masks, had the highest EER of 3.57%."}, {"title": "Conclusion", "content": "A crucial component in anti-spoofing systems is depth information, which is essential for addressing 2D attacks that exhibit unique 3D structures. However, systems that provide depth information are typically expensive and challenging to scale across large, distributed edge device networks. Conversely, non-calibrated systems are more cost-effective but lack depth information.\nIn this work, we introduce a novel method that overcomes this trade-off by leveraging facial feature knowledge to create proxy-depth maps from pairs of sensors. Our pipeline involves acquiring and processing images from both sensors, detecting faces, and extracting facial landmarks from each image. Using these pairs of facial landmarks, we calculate disparity in each dimension and interpolate all disparity points to produce a disparity map containing relative depth information.\nWe demonstrate the effectiveness of our method by incorporating the disparity maps as an additional input to a FAS system for edge devices. Our multi-modality anti-spoofing model provides a robust solution for FAS systems in real-life scenarios, outperforming other methods. Specifically, our method was tested on a large benchmark with approximately 100,000 samples, achieving an Equal Error Rate (EER) of 1.75%, which is 2.45% lower than the best compared method results. The Importance of the Disparity maps, is reflected in the conducted ablation study and in the CNN weights analysis as well. Furthermore, we show the effectiveness of a three-model ensemble over a larger benchmark that includes 3D attacks, achieving an EER of 2.04% and an FNR of 3.83% at a $\\frac{1}{100}$ miss acceptance rate.\nOverall, our work provides state-of-the-art (SOTA) results for non-calibrated sensor systems in the anti-spoofing task. The study was performed with data collected from the Intel\u00ae RealSenseTM ID Solution F455 device, but our methodology can be performed on other types of non-calibrated sensors as well."}, {"title": "Appendix", "content": "A Face Authentication pipeline\nA typical pipeline for Face Authentication (FA) begins with image acquisition. The face within the image is detected using a dedicated face detector model, which predicts the bounding box around the face. Once the face is detected, by utilizing a dedicated anti-spoof model, it undergoes discrimination based on various features to determine whether it is a live face or a spoof attack. If the anti-spoofing step identifies the processed image as a spoof, the pipeline is terminated. Otherwise, representative features are extracted from the image in the final step. These image features are then compared to other features representing a specific identity to ascertain whether the captured image corresponds to that specific identity. Figure 8 illustrates the FA pipeline.\nB Raw Bayer Pattern Process\nIn our pipeline the raw Bayer pattern of the sensor is processed directly (without demosaicing). The Bayer pattern of each sensor consists of 2x2 pixels, where each pixel within this pattern is considered as a single channel, resulting in a four-channel input for each sensor. An example for left sensor pattern is presented in Figure 9.\nC Supplementary Models\nAs part of the pipeline, each sensor's data is cropped around the face using a dedicated face detector (FD) model. This FD model processes a single channel from the sensor (green) and predicts the coordinates of a bounding box around the face, along with a confidence score. The architecture of the FD model is based on YOLO, and it refines its initial anchors during the detection process (Redmon [2016]). The model is trained on grayscale images from approximately 200,000 subjects and is subsequently fine-tuned with around 5,000 annotated samples collected from the Intel\u00ae RealSenseT\u2122 ID Solution F455. Another integral component of our pipeline is the Facial Landmarks Extractor (LE). Similar to the Face Detector (FD), the LE processes a single channel and predicts the coordinates of 45 facial landmarks: 5 for each eyebrow, 7 for each eye, 9 for the nose, and 12 for the lips. The architecture of the LE is a variation of U-Net (Ronneberger et al. [2015]), followed by a CNN regressor to predict the 45 2D coordinates. It is trained using approximately 240,000 images rendered from 3D scans under various environmental conditions, head"}]}