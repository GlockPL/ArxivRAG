{"title": "Eco-Aware Graph Neural Networks for Sustainable Recommendations", "authors": ["Antonio Purificato", "Fabrizio Silvestri"], "abstract": "Recommender systems play a crucial role in alleviating information overload by providing personalized recommendations tailored to users' preferences and interests. Recently, Graph Neural Networks (GNNs) have emerged as a promising approach for recommender systems, leveraging their ability to effectively capture complex relationships and dependencies between users and items by representing them as nodes in a graph structure.\nIn this study, we investigate the environmental impact of GNN-based recommender systems, an aspect that has been largely overlooked in the literature. Specifically, we conduct a comprehensive analysis of the carbon emissions associated with training and deploying GNN models for recommendation tasks. We evaluate the energy consumption and carbon footprint of different GNN architectures and configurations, considering factors such as model complexity, training duration, hardware specifications and embedding size.\nBy addressing the environmental impact of resource-intensive algorithms in recommender systems, this study contributes to the ongoing efforts towards sustainable and responsible artificial intelligence, promoting the development of eco-friendly recommendation technologies that balance performance and environmental considerations. Code is available at:\nhttps://github.com/antoniopurificato/gnn_recommendation_and_environment.", "sections": [{"title": "Introduction", "content": "Recommender systems (RSs) play a crucial role in mitigating information overload by providing personalized recommendations, benefiting users and service providers across various platforms, including e-commerce (e.g., Tmall, Amazon) (Ge et al., 2020) and social networks (e.g., Gowalla, Facebook) (Peng et al., 2020; Zhao et al., 2016). Different approaches have been proposed, ranging from collaborative filtering techniques that leverage user-item interactions to content-based methods that analyze item features (Chen et al., 2018) to sequential recommendation, aiming to capture the sequential patterns in user behavior and provide recommendations based on the current context or session (Betello et al., 2024b;\nBacciu et al., 2023).\nIn addition to sequential recommendation, Graph Neural Networks (GNNs) have emerged as a promising approach for recommender systems (Liu et al., 2024;\nMancino et al., 2023). GNNs can effectively capture the complex relationships and dependencies between users and items by representing them as nodes in a graph structure. By propagating and aggregating information along the edges of the graph, GNNs can learn rich representations that encode high-order connectivity patterns, leading to improved recommendation performance (Wu et al.,\n2022). Furthermore, GNNs can naturally incorporate various types of auxiliary information, such as user profiles, item attributes, and social connections, into the graph structure, enabling the exploitation of heterogeneous data sources for more accurate recommendations (Purificato et al., 2024). Nowadays, resource-intensive algorithms have become prevalent in modern recommender systems, resulting in higher energy consumption for recommendation experiments (Betello\net al., 2024a). However, despite some studies having been carried out in regarding the environmental impact of SRSs (Betello et al., 2024a; Spillo et al., 2023), only\none work presented an analysis of the computational consumption of GNN-based\nRSS Spillo et al. (2023).\nIn this work, we analyse the environmental impact of GNN-based RSs experiments by faithfully replicating representative experimental pipelines. Through a comprehensive comparative analysis, we shed light on the carbon emissions attributable to the training and deployment of GNN-based RSs. Our study serves\nas a clarion call for sustainability, underscoring the need to reconcile the pursuit of technological advancements with environmental consciousness within the realm of RSs. This study aims to answer to the following research questions:\n*   RQ1: Which model performs the best, and what are the trade-offs in terms of resource consumption?\n*   RQ2: How does the embedding size of the GNN affect the environmental impact of the results?"}, {"title": "Related Work", "content": "In the Glasgow Agreement (Hunter et al., 2021), participating nations committed to reducing CO2 emissions, underscoring the urgent need for environmental action. This commitment is particularly relevant to our field, as the environmental impact of GPU training in machine learning is significant. The energy consumption associated with these computational processes contributes significantly to CO2 emissions, exacerbating climate change (Patterson et al., 2021).\nIt is therefore our responsibility to raise awareness of this issue.\nAlthough the environmental impact of deep learning algorithms has been investigated in certain domains, such as Natural Language Processing (Bender\net al., 2021; Wang et al., 2023) and Information Retrieval (Scells et al., 2022), there is a dearth of research examining the environmental footprint of Recommender Systems.\nSpillo et al. (2023) benchmark several state-of-the-art recommendation algorithms in terms of both recommendation performance and carbon emissions and"}, {"title": "Method", "content": "In this study, we use CodeCarbon\u00b9 (Courty et al., 2023), a tool designed to track\nthe power consumption of both CPUs and GPUs. This allows us to measure\ncarbon dioxide equivalent (CO2-eq), a widely accepted standard used by numer-\nous organisations and governments to monitor emissions of various greenhouse\ngases (Kim and Neff, 2009). CO2-eq facilitates the comparison of greenhouse gas\nemissions by converting quantities of different gases into an equivalent amount of\nCO2, based on their respective global warming potentials. By using CodeCarbon,\nwe can accurately assess the environmental impact of our training processes, in\nline with our commitment to sustainability and responsible research practices in\nmachine learning.\nOur decision to focus specifically on CO2-eq emissions is motivated by several\nfactors. First, CO2-eq is a widely recognized and accepted metric for quantifying\nthe combined impact of various greenhouse gases on global warming, allowing us\nto provide a standardized and comparable measure of the overall environmental impact Betello et al. (2024a); Spillo et al. (2023). Second, CO2 emissions are particularly relevant in the context of energy-intensive machine learning training\nprocesses, which typically rely on electricity generated from fossil fuel sources.\nTracking CO2-eq emissions allows us to directly assess the carbon footprint as-\nsociated with the energy consumption of our experiments.\nThe Neural Graph Collaborative Filtering (NGCF) model (Wang et al., 2019)\nrepresents user-item interactions as a bipartite graph and learns user and item"}, {"title": "Calculating CO2 Emissions", "content": "In this study, we use CodeCarbon\u00b9 (Courty et al., 2023), a tool designed to track\nthe power consumption of both CPUs and GPUs. This allows us to measure\ncarbon dioxide equivalent (CO2-eq), a widely accepted standard used by numer-\nous organisations and governments to monitor emissions of various greenhouse\ngases (Kim and Neff, 2009). CO2-eq facilitates the comparison of greenhouse gas\nemissions by converting quantities of different gases into an equivalent amount of\nCO2, based on their respective global warming potentials. By using CodeCarbon,\nwe can accurately assess the environmental impact of our training processes, in\nline with our commitment to sustainability and responsible research practices in\nmachine learning.\nOur decision to focus specifically on CO2-eq emissions is motivated by several\nfactors. First, CO2-eq is a widely recognized and accepted metric for quantifying\nthe combined impact of various greenhouse gases on global warming, allowing us\nto provide a standardized and comparable measure of the overall environmental impact Betello et al. (2024a); Spillo et al. (2023). Second, CO2 emissions are particularly relevant in the context of energy-intensive machine learning training\nprocesses, which typically rely on electricity generated from fossil fuel sources.\nTracking CO2-eq emissions allows us to directly assess the carbon footprint as-\nsociated with the energy consumption of our experiments."}, {"title": "Models", "content": "The Neural Graph Collaborative Filtering (NGCF) model (Wang et al., 2019)\nrepresents user-item interactions as a bipartite graph and learns user and item"}, {"title": "Experimental Pipeline", "content": "To evaluate the impact of different embedding sizes on the model's performance\nand computational requirements, experiments with embedding sizes of 32, 64,\n128, and 256 are conducted. The results of these experiments are presented\nin Section 5. Prior to commencing the training process, we initialize a Code-\nCarbon tracker to monitor the carbon emissions associated with the training\nprocess. Additionally, we utilize the DeepSpeed\u00b2 library to compute the number\nof floating-point operations (FLOPs) required for each model configuration.\nDuring the training process, the CodeCarbon library is used to log the power\nconsumption every 30 seconds, allowing us to track the energy consumption\nin real-time. Upon completion of the training, we compute the total carbon\nemissions and various performance metrics, as described in Section 4.\nIn the next Section we will presents the experimental setup and describe the\ndifferent metrics and datasets used in the experiments."}, {"title": "Experiments", "content": "Our analyses encompass a collection of datasets, ensuring comprehensive and\nrobust insights. By incorporating datasets with diverse characteristics, such as\nvarying user and item counts, we aim to unravel the intricate interplay between\nthese factors and our findings. This approach enables us to capture a view of\nreal-world scenarios, thereby fortifying the applicability of our conclusions across\na broad spectrum of contexts. All the statistics of these datasets are presented\nin Table 1.\nMovieLens\u00b3: The MovieLens dataset (Harper and Konstan, 2015) is widely\nrecognized as a benchmark for evaluating recommendation algorithms. We\nutilize MovieLens 1M (ML-1M).\nAmazon: These datasets consist of product reviews collected from Ama-\nzon.com (McAuley et al., 2015). The data are organized into distinct datasets\nbased on Amazon's primary product categories. For our study, we focus on\nthe \"Beauty\" category (Beauty).\nDianPing: This dataset contains the user reviews as well as the detailed\nbusiness meta data information crawled from a famous Chinese online review\nwebsite4.\nOur data preprocessing pipeline adheres to well-established practices in the\nfield. We adopt an implicit approach, treating all interactions as binary events\nwithout considering rating values, as done in (Kang and McAuley, 2018; Sun\net al., 2019).\nFor dataset partitioning, we employ a widely-used strategy in sequential rec-\nommendation tasks (Sun et al., 2019; Kang and McAuley, 2018). The most\nrecent interaction for each user is held out for testing, while the second-to-last\ninteraction is reserved for validation. The remaining interactions constitute the\ntraining set, providing a chronological sequence of user behavior."}, {"title": "Datasets", "content": "Our analyses encompass a collection of datasets, ensuring comprehensive and\nrobust insights. By incorporating datasets with diverse characteristics, such as\nvarying user and item counts, we aim to unravel the intricate interplay between\nthese factors and our findings. This approach enables us to capture a view of\nreal-world scenarios, thereby fortifying the applicability of our conclusions across\na broad spectrum of contexts. All the statistics of these datasets are presented\nin Table 1.\nMovieLens\u00b3: The MovieLens dataset (Harper and Konstan, 2015) is widely\nrecognized as a benchmark for evaluating recommendation algorithms. We\nutilize MovieLens 1M (ML-1M).\nAmazon: These datasets consist of product reviews collected from Ama-\nzon.com (McAuley et al., 2015). The data are organized into distinct datasets\nbased on Amazon's primary product categories. For our study, we focus on\nthe \"Beauty\" category (Beauty).\nDianPing: This dataset contains the user reviews as well as the detailed\nbusiness meta data information crawled from a famous Chinese online review\nwebsite4.\nOur data preprocessing pipeline adheres to well-established practices in the\nfield. We adopt an implicit approach, treating all interactions as binary events\nwithout considering rating values, as done in (Kang and McAuley, 2018; Sun\net al., 2019).\nFor dataset partitioning, we employ a widely-used strategy in sequential rec-\nommendation tasks (Sun et al., 2019; Kang and McAuley, 2018). The most\nrecent interaction for each user is held out for testing, while the second-to-last\ninteraction is reserved for validation. The remaining interactions constitute the\ntraining set, providing a chronological sequence of user behavior."}, {"title": "Metrics", "content": "To evaluate the performance of sequential recommendation algorithms, we em-\nployed four widely adopted metrics commonly used in Information Retrieval (IR)\n(Kang and McAuley, 2018; Purificato et al., 2024): Precision, Recall, Normal-\nized Discounted Cumulative Gain (NDCG), and Hit Ratio (HIT). These metrics\nprovide a comprehensive assessment of the recommendation system's ability to\nidentify relevant items and rank them effectively.\n*   Precision: This metric calculates the proportion of correctly identified rele-\nvant items among the recommended items. It measures the system's ability\nto avoid irrelevant recommendations.\n*   Recall: It quantifies the fraction of correctly identified relevant items among\nthe recommendations relative to the total number of relevant items in the\ndataset. This metric evaluates the system's capability to retrieve as many\nrelevant items as possible.\n*   Normalized Discounted Cumulative Gain (NDCG): This metric evaluates the\nperformance of a ranking system by considering the position of relevant items\nin the ranked list. It assigns higher scores to relevant items ranked higher,\nas they are typically where a user's attention is focused. NDCG captures the\nimportance of ranking relevant items at the top of the recommendation list.\n*   Hit Ratio (HIT): Is a key metric in recommendation systems that measures\nwhether relevant items appear within the top K positions of a model's rec-\nommendation list. For each user, if at least one relevant item is included\nin the top K recommendations, it counts as a \"hit.\" The HIT@K score is\nthen calculated as the proportion of users for whom the model successfully\nincludes at least one relevant item within the top K.\nEmissions: Represents the CO2-eq (measured in Kg) required for training a\nsingle model and is the sum of the single CO2-eq emissions over each epoch.\nBy employing these four metrics, we can comprehensively assess the recommen-\ndation system's ability to identify relevant items, rank them effectively, and\nprovide high-quality recommendations tailored to the user's preferences and in-\nterests."}, {"title": "Reproducibility", "content": "In order to facilitate a rigorous and unbiased comparison, a standardized exper-\nimental setup was adopted for all models. The training regime consisted of 400\nepochs, with batch sizes of 2048 and 4096 for the training and validation stages,\nrespectively. The optimization was carried out using the Adam algorithm, with\na learning rate fixed at 0.001. Furthermore, to mitigate the effects of random ini-\ntialization and promote reproducibility, an identical seed was employed across\nall experiments. In order to see how all the experiments evolve over time, no\nearly stopping procedures were applied."}, {"title": "Hardware", "content": "All experiments were performed on a single NVIDIA RTX A6000 with 10752\nCUDA cores and 48 GB of RAM. The code is written in Python 3 and to train\nall the models it was used the RecBole library (Xu et al., 2023).\nIn the next Section we will present the results of the proposed study, in terms\nof performance metrics and environmental impact."}, {"title": "Results", "content": "As shown in Table 2, LightGCN outperforms all competitors across all datasets,\nwith the most significant lead observed on the Beauty dataset, while the gap\nnarrows on the ML-1M dataset. LightGCN's superior performance can be at-\ntributed to two key factors: firstly, it is an advancement over NGCF, with its\nadvantages clearly demonstrated in prior experiments (He et al., 2020). Secondly,\nboth LightGCL and SimGCL, although promising, involve higher computational\ncomplexity, and 400 epochs may not suffice for them to converge to optimal re-\nsults. In terms of carbon emissions, NGCF remains the most efficient on two out\nof the three datasets a somewhat unexpected outcome, given that LightGCN is\ntouted by its authors as being more lightweight than NGCF. The best trade-off\nin terms of performance-emission will probably remain LightGCN, which is the\nsecond-best model in terms of environmental impact on two of the three datasets."}, {"title": "RQ1: Which model excels, and at what cost?", "content": "As shown in Table 2, LightGCN outperforms all competitors across all datasets,\nwith the most significant lead observed on the Beauty dataset, while the gap\nnarrows on the ML-1M dataset. LightGCN's superior performance can be at-\ntributed to two key factors: firstly, it is an advancement over NGCF, with its\nadvantages clearly demonstrated in prior experiments (He et al., 2020). Secondly,\nboth LightGCL and SimGCL, although promising, involve higher computational\ncomplexity, and 400 epochs may not suffice for them to converge to optimal re-\nsults. In terms of carbon emissions, NGCF remains the most efficient on two out\nof the three datasets a somewhat unexpected outcome, given that LightGCN is\ntouted by its authors as being more lightweight than NGCF. The best trade-off\nin terms of performance-emission will probably remain LightGCN, which is the\nsecond-best model in terms of environmental impact on two of the three datasets."}, {"title": "Embedding Size and Environmental Impact", "content": "Figure 1 shows that increasing the size of the embeddings generally leads to a\nhigher environmental impact across all models and datasets. This trend is par-\nticularly pronounced in the DianPing dataset, which contains a large number\nof interactions. Interestingly, on the DianPing dataset, NGCF has a higher cost\nthan SimGCL, despite SimGCL being computationally more expensive. How-\never, on the other datasets, SimGCL consistently remains the most computa-\ntionally demanding model. The same Figure also illustrates how the dataset size\naffects CO2-eq costs. On the ML-1M dataset, the costs are significantly lower\ncompared to those on the DianPing dataset. This not only depends from the\nnumber of users and the number of items, but also from the interactions be-\ntween users and items. On the DianPing and Beauty datasets, as the embedding\nsize increases, emissions also increase, as expected. It is interesting to note that\non the ML-1M dataset, for the NGCF and LightGCL models, emissions related\nto an embedding size of 256 are higher compared to those with an embedding\nsize of 128. This result requires more detailed investigation in future work, par-\nticularly on how each parameter of a model influences the environmental impact\nof the respective model."}, {"title": "Conclusions", "content": "In this study, we examined the environmental impact of GNN-based recom-\nmender systems, an aspect often overlooked in AI research. Our analysis of\ncarbon emissions and energy consumption across different GNN architectures\nand configurations highlights how model complexity, training duration, hard-\nware specifications, and embedding size affect their environmental footprint.\nWhile GNNs provide significant benefits in capturing complex relationships\nfor recommendation tasks, our findings show that these gains can come with\nconsiderable environmental costs, especially when large datasets or extensive\nembeddings are used. By emphasizing these trade-offs, our study contributes to\nthe discourse on sustainable AI, encouraging the integration of environmental\nconsiderations into the development of recommender systems. Future research\nshould focus on optimizing GNN architectures to balance performance with sus-\ntainability, exploring new algorithms and energy-efficient methods.\nWe hope this work inspires further efforts to develop eco-friendly AI tech-\nnologies that align with global sustainability goals."}]}