{"title": "Leveraging Transfer Learning and Multiple Instance Learning for HER2 Automatic Scoring of H&E Whole Slide Images", "authors": ["Rawan S. Abdulsadig", "Bryan M. Williams", "Nikolay Burlutskiy"], "abstract": "Expression of human epidermal growth factor receptor 2 (HER2) is an important biomarker in breast cancer patients who can benefit from cost-effective automatic Hematoxylin and Eosin (H&E) HER2 scoring. However, developing such scoring models requires large pixel-level annotated datasets. Transfer learning allows prior knowledge from different datasets to be reused while multiple-instance learning (MIL) allows the lack of detailed annotations to be mitigated. The aim of this work is to examine the potential of transfer learning on the performance of deep learning models pre-trained on (i) Immunohistochemistry (IHC) images, (ii) H&E images and (iii) non-medical images. A MIL framework with an attention mechanism is developed using pre-trained models as patch-embedding models. It was found that embedding models pre-trained on H&E images consistently outperformed the others, resulting in an average AUC-ROC value of 0.622 across the 4 HER2 scores (0.59 \u2013 0.80 per HER2 score). Furthermore, it was found that using multiple-instance learning with an attention layer not only allows for good classification results to be achieved, but it can also help with producing visual indication of HER2-positive areas in the H&E slide image by utilising the patch-wise attention weights.", "sections": [{"title": "1. Introduction and Related Work", "content": "When suspecting breast cancer, pathologists perform microscopic analysis of breast tissue samples obtained using a needle biopsy (ame, 2019). The sample is stained with Hematoxylin and Eosin (H&E) to examine the presence of cancer and with Immunohistochemistry (IHC) for the assessment of human epidermal growth factor receptor 2 (HER2), which helps to indicate whether the patient is eligible for targeted anti-HER2 therapies. There is an interest in developing automatic deep learning approaches for IHC HER2 scoring to reduce pathologists' workload (Qaiser et al., 2018). An automatic H&E HER2 scoring is even more preferable and cost effective approach than using IHC HER2 staining (Oliveira et al., 2020).\nModel-based transfer learning is a common technique in deep learning where the knowledge learnt from a source-domain is \"transferred\" to a different domain, then adapted to suit the problem domain of concern. This technique helps cut down the computational time needed and most importantly the target-domain data required to train the model (Zhuang et al., 2019). Transfer learning becomes especially handy when dealing with medical data that is either scarce or hard to obtain, more specifically in the case of medical imaging data.\nTo date, few studies have attempted to pre-train models with histopathology images due to a lack of labeled images and experimental studies comparing the effect of transfer learning from different medical imaging domains. Sun et al. evaluated the effect of transfer learning from ImageNet to H&E images. The transferred model captured Gabor filters derived and colour specific features generalisable across different types of histopathology images.\nMultiple-instance learning (MIL) has been shown to be efficient when there is lack of detailed annotations since the method is based on the assumption that negatively labeled bags of patches only contain negative instances, while positive bags contain at least one positive patch (Carbonneau et al., 2018) mitigating the need for accurate annotations. Courtiol et al. used an ImageNet pre-trained ResNet model for slide-level classification of TCGA-Lung and Camelyon-16 datasets. Oliveira et al. attempted to use IHC patches to pre-train an embedding model in a MIL framework for predicting HER2 scores from H&E whole slide images (WSIs). Although the paper showed that using IHC patches for pre-training the model helped to achieve high accuracy, the study did not show the performance of pre-training on different source domains."}, {"title": "2. Methodology", "content": "Three types of source classification tasks were examined: 1. Different type of images and a different classification task: a dataset of non-medical images. 2. Same type of images but a different classification task: H&E images of a different type of tissue and annotated with different information. 3. Different type of images but the same classification task: IHC images of breast tissue which show the information of concern, and annotated with HER2.\nThe HER2 Scoring Contest dataset of H&E and IHC whole slide images was considered to be the main dataset providing the H&E stained WSIs annotated with their HER2 scores, in addition to the IHC stained WSIs representing the third type of source task (i.e. different type of images, same classification task). The PatchCamelyon dataset was chosen to represent the second type of source task (i.e. same type of images, different classification task) as it was found to be well prepared for training in terms of the annotations, the balanced classes and the size of the images. On the other hand, ImageNet was chosen to represent the first source task of non-medical images (i.e. different type of images, different classification task) since it is a rich dataset that is often used to pre-train image classification models in practice. Figure 1 illustrates a general overview of the methodology\u00b9.\nPatches were extracted from the H&E and IHC WSIs at 0.5 \u00b5m magnification level using handcrafted thresholds operating on the hue, saturation and value (HSV) colour space. The patches were augmented by randomly varying brightness, contrast, saturation and hue, as well as applying affine transformations (rotations, shear, translation and scaling), in addition to Gaussian noise."}, {"title": "3. Experiments and Results", "content": "Obtaining prior knowledge from the three source tasks was done by pre-training an AlexNet CNN architecture on ImageNet, PatchCamelyon and the constructed IHC HER2 (52 WSIS providing \u2248 380,000 224 \u00d7 224 patches) datasets. For ImageNet, PyTorch's off-the-shelf pre-trained AlexNet model was used, while pre-training on PatchCamelyon (PCAM) and IH\u0421 was carried out locally and tested to obtain their performance measures in their respective classification tasks.  The convolutional layers of these pre-trained AlexNet models were then used in the MIL framework as patch-embedding models.\nConsidering the multi-class classification problem of HER2 scoring, bags of 100 patches were formed by sampling eligible patches from the selected slides during the 5-fold cross evaluation training. The slides were split into 44 training slides and 8 testing slides. Each epoch was done by training the MIL model on 6,400 bags of patches and validated on 2,500 bags, and those models were then tested on 2,500 bags from the testing slides. Those bags were partitioned in batches of 64 bags.\nThe training bags were not repeated during the training process, every epoch introduced different sampled bags. This was done as a bag-level augmentation method in order to cover all possible variations of bags that can be constructed from each training slide, while validation and testing bags were kept fixed.\nThe weights of the patch-embedding models remained frozen during the training of the MIL model, while the rest of the layers were updated. The choice to freeze the patch-embedding model weights was made to avoid complexity of training and to explore the effect of the un-modified prior knowledge these models provided on the classification performance.\nAdam optimiser was used for training, and the optimisation parameters were searched for in a grid of learning rate values [1e-03,1e-04, 1e-05, 1e-06] against weight decay values [1e-03,1e-04,1e-05,1e-06, 1e-07]. The set of values resulting in the minimum validation loss were used to train each model type in the 5-fold cross-evaluation setup, these models were then tested and their performance metrics were obtained along with their 95% confidence intervals."}, {"title": "4. Conclusions and Future Work", "content": "A cost-effective automatic H&E HER2 scoring model was developed. Transfer learning from a similar staining, H&E to H&E, demonstrated to be more beneficial than from IHC to H&E images neither than from non-medical ImageNet to H&E images. Potentially, a further hyper-parameter tuning could improve IHC to H&E transfer which was suggested by the wide confidence intervals. In this paper, MIL demonstrated to be a promising approach where only a limited number of slide level annotated WSIs were available. Optimising the models and exploring fine-tuning strategies for the MIL pipeline could further boost performance and provide a better understanding of transfer learning contribution across different datasets."}], "equations": ["ak = Softmax(w\u2081 Tanh(w\u2082Vk))", "A = \u2211ak Vk", "CI (95%) = Mean \u00b1 1.96 * Standard Error = Mean \u00b1 1.96 *"]}