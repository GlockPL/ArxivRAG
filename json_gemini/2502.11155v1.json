{"title": "Uncertainty-Aware Search and Value Models:\nMitigating Search Scaling Flaws in LLMs", "authors": ["Fei Yu", "Yingru Li", "Benyou Wang"], "abstract": "Value model-guided search is effective in steer-\ning the generation but suffers from scaling\nflaws: Its superiority diminishes with larger\nsample sizes, underperforming non-search\nbaselines. This limitation arises from relia-\nbility degradation in value models in unseen\nreasoning paths. To address this, we propose\nan uncertainty-aware search framework that in-\ncludes two key components: (1) uncertainty-\naware value models that incorporate uncer-\ntainty into predictions, and (2) an uncertainty-\naware selection process using the proposed ef-\nficient Group Thompson Sampling algorithm.\nExperiments on GSM8K show that our method\nmitigates search scaling flaws, achieving 90.5%\ncoverage at 16 samples compared to 85.8%\nfor conventional value-guided search. This\nwork establishes the first systematic integration\nof uncertainty quantification in LLM search\nparadigms.", "sections": [{"title": "1 Introduction", "content": "Test-time scaling (Brown et al., 2024; Snell et al.,\n2024; Wu et al., 2024) boosts performance sig-\nnificantly on multi-step mathematical reasoning\ntasks (Cobbe et al., 2021; Hendrycks et al., 2021).\nValue Model (VM)-guided search (Yu et al., 2024;\nWan et al., 2024) efficiently solves more problems\nby steering the generation toward more effective\nreasoning paths.\nHowever, a recent study (Yu et al., 2025) iden-\ntifies scaling flaws in conventional VM-guided\nsearch: it outperforms repeated sampling (i.e. non-\nsearch baseline) at small sample sizes but improves\nmore slowly, leading to inferior performance at\nlarger sample sizes. As shown in Table 1, VM-\nguided search surpasses repeated sampling at a\nsample size of 1 (75.4% v.s. 52.9%), but loses the\nsuperiority as the sample sizes increase to 8 and 16\n(85.8% v.s. 90.8%)."}, {"title": "2 Background", "content": "This section first defines the problem and intro-\nduces the primary solution framework \u2013 search.\nThen, we introduce outcome value models em-\nployed in search, and highlight the issues associ-\nated with search and value models.\nProblem definition A mathematical reasoning\nquestion q requires both the intermediate steps and\nthe final answer as output: The solution path is\nrepresented as S = [s\u00b9, . . ., sT, a], where s\u00b2 is the\ni-th step, a is the answer, and T is the step count.\nSearch Search explores correct solutions more\nefficiently by guiding the process towards more"}, {"title": "3\nUncertainty-Aware Value Modelling", "content": "In this section, we first explain the motivation\nfor uncertainty-aware value modelling. Then,\nwe describe the technique used to implement the\nuncertainty-aware value model in Section 3.1 and\nhow to utilize it in Section 3.2. Finally, we intro-\nduce the training process in Section 3.3.\nMotivation The performance of VMs heavily de-\npends on the training data. Quantifying uncertainty\ncan reveal the sufficiency of similar training data.\nSpecifically, when sufficient similar data is avail-\nable in training, the VM offers low-uncertainty, reli-\nable predictions during testing. Conversely, scarce\nsimilar data leads to high uncertainty and reduced\nprediction reliability. By quantifying this uncer-\ntainty and evaluating candidates in an uncertainty-\naware manner, we can make more informed deci-\nsions during the search process."}, {"title": "3.1 Uncertainty-Aware Value Model", "content": "Ensemble++ Ensemble++ (Li et al., 2024a,b) is\nan ensemble-based approach that captures data un-\ncertainty by modelling the posterior distribution.\nWhen test data resembles sufficiently seen data, the\nposterior distribution is concentrated; otherwise,\nit is more dispersed. This approach is simple to\nimplement, requiring only a learnable linear trans-\nformation of the existing representation x. It learns\nto map a predefined distribution pc, like a Gaussian,\nto the target posterior distribution.\nUVM We borrow Ensemble++ (Li et al.,\n2024a,b) to model uncertainty-aware values as il-\nlustrated in Figure 2 (i). There are three processes\ninvolved in UVM: (1) representation encoding (2)\nindex sampling (3) index mapping\nRepresentation encoding: The last hidden\nstates from a LLM backbone (parameterized by\n0) serve as the representation x. Specifically, for\na given question q and a partial path S(1:t), the\nrepresentation x is obtained as:\nx = LLM(q, S(1:t); 0) (1)\nIndex sampling: This process samples an index\nfrom the predefined distribution, i.e. \u03da ~ p\u00a2\nIndex mapping: The index is mapped to the\nposterior value by summing a mean value term and"}, {"title": "an uncertainty term:", "content": "\u03c5 = xb + x(W + Wo)\u00a2T (2)\nmean estimator\nuncertainty estimator\nThrough these processes, a trained UVM maps\nthe predefined distribution pe to the posterior value\ndistribution p(v|q, S'(1:t)).\nAdditional parameters Here, Wd\u00d7m and bd\u00d71\nare learnable parameters, while Waxm are frozen\nparameters that are randomly initialized. d rep-\nresents the dimension of the backbone's hidden\nstates x\u00b9\u00d7d. m is a hyperparameter for the dimen-\nsion of the index \u00a2\u00b9\u00d7m. Notably, UVM is simple\nand straightforward to implement on top of OVM,\nrequiring only an additional linear transformation.\nUVM architectural insight It extends conven-\ntional approaches through a dual-branch architec-\nture, as shown in Figure 2:\n\u2022 Deterministic Branch (blue): Maintain stan-\ndard value estimation, equivalent to OVM\n\u2022 Uncertainty Branch (orange): Learn distribu-\ntion through ensemble perturbations\nIntuitive explanation UVM can be regarded as\na last-layer ensemble of m components, controlled\nby the index vector \u00a2\u00b9\u00d7m: (1) When \u00a2\u00b9\u00d7m is a\nzero vector [0, . . ., 0], UVM retains only the deter-\nministic branch, degenerating to OVM (2) When\n1\u00d7m is a one-shot index vector, with a 1 in the\ni-th position and Os elsewhere, it queries the i-th\ncomponent for the prediction (3) When \u00a2\u00b9\u00d7m is a\nnon-one-shot vector, it is equivalent to use a linear\ncombination of the m components."}, {"title": "3.2 Accessing Values", "content": "Although the explicit formalization of p(v|q, S(1:t))\nis unavailable, we can sample values and compute\nthe distribution's mean and standard deviation.\nSampling from posterior value distribution To\nderive a posterior value, we (1) sample an index\n\u03b6 ~ pc and (2) map it to the value sample v using\nEquation 1-2. Notably, deriving multiple poste-\nrior values only requires one-time representation\nencoding, i.e. forward pass through the LLM back-\nbone (Equation 1), followed by multiple posterior\nvalue mappings (Equation 2) with repeated index\nsampling and mapping."}, {"title": "3.3 Uncertainty-Aware Value Learning", "content": "UVM does not require any additional training data\nand can use the same training dataset as OVM. The\ntraining dataset construction is described in Ap-\npendix A.1, which consists of (q, S(1:T), y) tuples,\nwhere y denotes the correctness of the final answer.\nGiven the same training dataset, the key differ-\nence in value learning between OVM and UVM\nlies in their training objectives:\nTraining loss of OVM OVM learns single-point\nestimates (Figure 2 (ii)). Its loss is the Mean\nSquared Error (MSE) with respect to the binary\nlabel y, for each (q, S'(1:T), y) tuple:\nLOVM(q, S(1:T), y) = \u2211(OVM(q, S(1:1)) \u2013 y)\u00b2 (3)\nwhere OVM(\u00b7) evaluates and maps a given partial\npath S(1:T) and the question q to a value scalar.\nTraining loss of UVM UVM is learning a\nposterior value distribution, which complicates\nits learning (Figure 2 (iii)). Following Ensem-\nble++ (Li et al., 2024a,b), a discrete coordi-"}, {"title": "4 Uncertainty-Aware Selection", "content": "This section describes (1) the implementation of\nposterior value sampling during inference and (2)\nuncertainty-aware selection with the accessibility\nto the posterior value distribution. We propose a\nnovel algorithm, Group Thompson Sampling, to ef-\nfectively and efficiently select multiple candidates."}, {"title": "Posterior value sampling of UVM during infer-ence", "content": "Following Ensemble++ (Li et al., 2024a,b),\na m-dimensional continuous Gaussian distribution\nis used as the index distribution pe to access the\nexpressive posterior value distribution during infer-\nence, as described in Section 3.2. Intuitively, we\nare training m individual components during value\nlearning, and then combine them linearly to make\npredictions during inference."}, {"title": "Top-1 probability for candidate selection", "content": "For\neach step t, we evaluate and rank K candidates in\nthe set S(1:t) based on their posterior value distri-\nbution. Specifically, we assess the probability of\neach candidate being the best, i.e. the likelihood of\nit having the highest value, within the set, referred\nto as the top-1 probability\np(S(1:t) is the best among S(1:t))\n= Ev\u00bf~p(v\\q,S(1:t)),vj~p(v|q,S(1:t)) \u221aj\u2260i\n\u03a0\u0399\u03c5\u03b5 \u2265 3)\nj\u2260i (5)\nWe perform candidate selection by sampling from\nthe top-1 probability distribution\nS(1:t) ~ p(S(1:t) is the best among S(1:t)) (6)\nWe use top-1 probability for candidate selec-\ntion instead of the well-known Upper Confidence\nBound (UCB) 2 for two main reasons:\n\u2022 Top-1 probability better captures the distri-\nbution's characteristics, balancing mean and\nvariance. In candidate selection, it is impor-\ntant to balance the predicted mean value with\nthe uncertainty (i.e., the distribution's vari-\nance). Candidates with extreme uncertainty\nwill be prioritized by UCB, potentially over-\nlooking the mean value prediction in such\ncases. In contrast, top-1 probability provides\na more balanced approach that not overempha-\nsizes uncertainty.\n\u2022 Top-1 probability inherently ranks candidates\nagainst each other. UCB evaluates each can-\ndidate independently, without considering its\nrelation to others. In contrast, top-1 probabil-\nity intrinsically compares each candidate to\nall others in the set, ranking them based on\nthe likelihood of being the best in the set."}, {"title": "Group Thompson Sampling: An efficient algo-rithm for group selection based on top-1 proba-bility", "content": "Group Thompson Sampling is an exten-\nsion of the Thompson sampling algorithm, de-\nsigned to efficiently select a group of candidates\nbased on their top-1 probability. Thompson sam-\npling (Thompson, 1933; Russo et al., 2018) is a\nstraightforward method for selecting a single can-\ndidate, by performing one posterior sampling and\nchoosing the one with the highest sampled value\nvi ~p(v/q, S(1:t)), ), Vi\nS(1:t) = argmax vi (7)\nTo extend this for selecting multiple candidates, we\nintroduce Group Thompson Sampling algorithm in\nAlgorithm 1. This method repeats Thompson sam-\npling b times to select b candidates, incorporating a\nmechanism to avoid duplication."}, {"title": "Algorithmic innovation", "content": "Group Thompson Sam-\npling addresses two key challenges in uncertainty-\naware search:\n\u2022 Computational efficiency: Avoid explicit top-1\nprobability estimation through smart sampling\n\u2022 Comprehensive selection range: Ensure that\ncandidates with varying levels of uncertainty\nare appropriately considered for selection\nthrough an uncertainty-aware stochastic se-\nlection mechanism"}, {"title": "5 Experiment Results", "content": "This section outlines our experiment settings and\npresents the results of overall performance and ab-\nlation studies."}, {"title": "5.1 Experimental Settings", "content": "Benchmarks and models We conduct experi-\nments on GSM8K (Cobbe et al., 2021) using Mis-\ntral 7B (Jiang et al., 2023). We use the official\ntraining split and test split for all the experiments.\nBaselines We compare our method, UVM-\nguided search, with two baselines: (1) repeated\nsampling, which directly samples multiple solu-\ntion paths without any search mechanism, and (2)\nconventional OVM-guided search, which does not\nincorporate uncertainty.\nEvaluation Following the study of search scal-\ning flaws (Yu et al., 2025), we evaluate our method\nusing coverage \u2013 the fraction of problems whose\ncorrect solutions for which the correct solution is\ncovered by the generated paths, i.e., at least one\nsampled path is correct. This metric is also referred\nto as pass@k, where k denotes the number of gen-\nerated paths.\nScaling beam search Yu et al. (2025) observes\nscaling flaws related to both sample sizes and can-\ndidate sizes. We also investigate the effectiveness\nof our methods on with respect to these two factors:\nSample size: This refers to the number of com-\nplete solution paths generated by the algorithm.\nFor beam search, it corresponds to the beam size\nb, while for repeated sampling, it is the number of\nattempts. We consider sample sizes of 1, 2, 4, 8,\n16, and 32. For beam search experiments, we fix\nthe number of generated paths per beam K/b at 8.\nCandidate size: This represents the number of\ncandidates considered during the search process.\nIn these experiments, we fix the sample size at 16,\nwhere OVM-guided search underperforms repeated\nsampling. We conduct experiments with candidate\nsizes of 32, 64, 128, and 256.\nEach experiment is repeated three times, and we\nreport the average coverage along with its standard\ndeviation."}, {"title": "5.2 Implementation", "content": "Training generators We train the base models\n(i.e. Mistral 7B) on the official training set. We use\nthe newline character as the marker for the end of\neach step. Supervised fine-tuning is performed for\n2 epochs with a batch size of 128. We use a linear\nlearning rate scheduler with a maximum learning\nrate of 2e-6. The AdamW optimizer (Loshchilov\nand Hutter, 2019) is used for training.\nBuilding training dataset for UVMs The\ndataset construction process is introduced in Ap-\npendix A.1. We sample 50 solution paths per prob-\nlem in the training set. We use a decoding tempera-\nture of 0.7 and top-k set to 50 for dataset collection.\nThe maximum new token length is 400. We apply\nvllm (Kwon et al., 2023) to accelerate the genera-\ntion process.\nTraining UVMs/OVMs To construct UVMs, we\nset the number of components to 10. UVMs are\ninitialized from the corresponding generator check-\npoints and trained for one epoch, using the same\nbackbone learning rate scheduler. The maximum\nlearning rate for the uncertainty-aware value head\nis set to 2e-3, with a batch size of 128. The opti-\nmizer used for training is AdamW. After training,\nwe derive OVMs by setting \u00a2 = 0.\nStep-level beam search The hyperparameters\nfor decoding are consistent with those used in the\nUVMs' training dataset collection. The maximum\nnumber of steps is 10."}, {"title": "5.3 Overall Performance", "content": "We present the overall performance in Figure 1,\nshowing that UVM-guided search consistently out-\nperforms conventional OVM-guided search both\nwhen scaling sample sizes and scaling candidate\nsizes.\nScaling flaws UVM-guided search mitigates the\nscaling flaws of conventional VM-guided search.\nAs shown in Figure 1(a), VM-guided search leads\nto over 20% higher coverage than repeated sam-\npling when the sample size is 1. However, its ad-\nvantage diminishes as the sample size scales to 8.\nIn contrast, our UVM-guided search continues to\noutperform repeated sampling at this sample size\nand remains comparable even at a sample size of\n16.\nMoreover, as shown in Figure 1(b), the perfor-\nmance of conventional VM-guided search deterio-"}, {"title": "Convergent points of coverage", "content": "UVM-guided\nsearch ultimately converges to higher coverage\nthan conventional VM-guided search. As illus-\ntrated in Figure 1(a), UVM-guided search outper-\nforms conventional VM-guided search once the\nsample size increases to 4. It reaches the perfor-\nmance comparable to the best result of conventional\nVM-guided search (among all tested sample sizes)\nusing only 25% of its budget. Furthermore, it ulti-\nmately achieves 4.2% higher coverage at the largest\ntested sample size, 32.\nThese results highlight the effectiveness of our\nmethod in enhancing search scaling."}, {"title": "5.4 Ablation Study", "content": "In this section, we conduct ablation studies on the\ndesign choices of uncertainty-aware selection and\ndemonstrate the superiority of the Group Thomp-\nson Sampling algorithm in Figure 3.\nBaselines We consider two deterministic base-\nlines for uncertainty-aware selection: UCB ranking\nand the naive top-1 probability ranking.\nUCB ranking: UCB scores each candidate by\nsumming the mean and standard deviation of the\nposterior value distribution, which are computed\nusing 100,000 sampled posterior values. Then, can-\ndidates with the highest UCB scores are selected.\nNaive top-1 probability ranking: This method\nexplicitly calculates the probability of each can-\ndidate being the best, as described in Equation 5,\nusing 100,000 sampled posterior values. It ranks\nand selects candidates based on the highest proba-\nbilities, rather than sampling from the probability\ndistribution."}, {"title": "Top-1 probability ranking v.s. UCB ranking", "content": "Top-1 probability is better for candidate evalua-\ntion. As shown in Figure 3, UCB ranking per-\nforms poorly, even underperforming the conven-\ntional OVM baseline. In contrast, the top-1 proba-\nbility ranking surpasses the UCB, highlighting the\neffectiveness of using top-1 probability for candi-\ndidate evaluation."}, {"title": "Group Thompson Sampling v.s. top-1 prob-ability ranking", "content": "Group Thompson Sampling is"}, {"title": "6 Analysis", "content": "In this section, we conduct in-depth analyses of\nVM selection failures, which are the underlying\ncauses of search scaling flaws (Yu et al., 2025).\nSpecifically, we investigate the effectiveness of\nUVM in mitigating selection failures across var-\nious sparsity of correct paths among candidates.\nSelection stages We define a selection stage as\ncomprising three key components: (1) the candi-\ndate set (2) the evaluation scores assigned to each\ncandidate (3) the selected candidates from the set.\nThe presence of correct paths within the can-\ndidate set depends on the quality of candidates\ngenerated during the generation stage. In this sec-\ntion, we focus on the effectiveness of the selection\nstages and exclude issues related to the generation\nstages. Therefore, we only consider those selection\nstages where correct paths are present within the\ncandidate set."}, {"title": "Selection failures", "content": "When correct paths are present\nin the candidate set, a selection failure is identified\nif none of the correct paths are selected.\nIn this section, we analyze the distribution of\nselection failures and compare the effectiveness of\nUVM and OVM across various scenarios.\nExperimental Setup We extract all selection\nstages during the OVM-guided search with b =\n8, K = 64, as this setup begins to experience\nscaling issues while retaining a reasonable com-\nputational cost for correct path labeling and target\nselection stage identification.\nCorrect path labeling To identify the correct\ncandidate paths, we complete each partial path by\nrolling out 4 samples and checking whether any\nof them reach the correct answer. A candidate is\ndeemed a correct path if at least one of its rollouts\nleads to the correct final answer.\nTarget selection stage identification Given the\ncorrectness of all candidate paths across all selec-\ntion stages, we can filter all the selection stages\nwhere correct paths are available among the candi-\ndate set for the subsequent studies.\nAnalysis on Correct Path Sparsity Correct path\nsparsity refers to the fraction of correct paths within\nthe candidate set. As sparsity increases\u2014i.e.,\nfewer correct paths are present among the candi-\ndates-identifying the correct paths becomes more\nchallenging for VMs (Yu et al., 2025).\nSimilar to the analysis in Yu et al. (2025), we\ncategorize the correct path sparsity of all targeted\nselection stages (where correct paths are available)\ninto three uniform groups. We then apply both\nOVM and UVM selection to the candidate sets\nwithin these stages. Then we plot the distribution\nof selection failures, where no correct path is iden-\ntified, across the three sparsity groups in Figure 4."}, {"title": "UVM is effective across all correct path sparsitygroups.", "content": "As shown in Figure 4, UVM consistently\nreduces the frequency of selection failures across\nall sparsity groups. Specifically, it reduces selec-\ntion failures by 6% in the low-sparsity group, 6%\nin the medium-sparsity group, and 14% in the high-\nsparsity group."}, {"title": "UVM is most effective in high-sparsity regimes.", "content": "Notably, although higher correct path sparsity in-\ncreases the difficulty of the selection task, UVM\ncontinues to perform well, and even offers greater\nbenefits in reducing selection failures in high-\nsparsity regimes (14% failure reduction). This\ndemonstrates its ability to retain high-uncertainty"}, {"title": "7 Discussion", "content": "Quantifying uncertainty in current search-based\nmethods has several practical implications for LLM\nreasoning tasks as follows: (1) Discovering cor-\nrect solutions: Correct solutions may lie along\npaths that are underrepresented in the training\ndata. By incorporating uncertainty, our approach\nincreases the likelihood of discovering these so-\nlutions. (2) Improved performance with limited\nresources: Uncertainty-aware search methods en-\nhance performance without a significant increase in\ncomputational resources. This is because the pro-\ncess of quantifying uncertainty is computationally\ninexpensive. (3) Adaptability to real-world applica-\ntions: Real-world applications often encounter out-\nof-distribution data. Methods that account for un-\ncertainty are better equipped to handle such cases,\nenabling more reliable performance in deployment\nscenarios where the data may differ from training\ndistributions."}, {"title": "8 Conclusion", "content": "VM-guided search suffers from search scaling\nflaws due to the use of imperfect VMs, which could\nproduce unreliable predictions when the evaluated\ndata is underrepresented in the training data. To ad-\ndress these issues, we propose an uncertainty-aware\nsearch framework, including training uncertainty-\naware VMs and applying uncertainty-aware se-\nlection during the search. Experiment results in\nGSM8K show the effectiveness of our methods."}, {"title": "Limitation", "content": "While uncertainty can indicate the reliability of\nVM predictions, it alone cannot guarantee correct\npredictions. This highlights that, although uncer-\ntainty can be useful, effective selection still heavily\ndepends on the performance of the VMs. In sce-\nnarios where VMs perform poorly, such as in the\nmore challenging MATH dataset (Hendrycks et al.,\n2021), uncertainty alone offers limited assistance\nand proves ineffective. In such scenarios, improv-\ning the quality of the VMs should be prioritized\nover merely equipping them with uncertainty qual-\nifications. Besides, uncertainty does not fully cap-\nture the accuracy of value predictions. It is possible\nfor a low-uncertainty prediction to still be incorrect,\na scenario that is not addressed in this paper."}, {"title": "A Appendix", "content": "Construction of VMs' Training Dataset\nThe training dataset is created using the genera-\ntor and the question-answer pairs. For each pair\n(q, a) \u2208 Q, the generator produces n solution paths,\nresulting in a total of |Q| \u00d7 n question-solution\npairs. The label y for each solution S is assigned\nbased on the correctness of the final answer, which\nis determined by comparing it to the ground truth\nanswer a. A label of 1 indicates the answer is\ncorrect, while 0 indicates it is incorrect. This pro-\ncess forms a training dataset consisting of (q, S, y)\ntuples for value model training.\nDetailed UVM Structure\nGiven the representation x, the sampled index is\nmapped to the posterior value sample as:\n\u03c5\nHere, u and po are hyperparameters. Specifically, u\ncontrols the tradeoff between the uncertainty terms\nW, Wo and the mean value term b, and po controls\nthe tradeoff between the posterior term W and the\nprior term Wo.\nStep-Level Beam Search\nThe algorithm is shown in Algorithm 2."}]}