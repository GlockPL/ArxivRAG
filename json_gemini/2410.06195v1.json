{"title": "ENTERING REAL SOCIAL WORLD! BENCHMARKING THE THEORY OF MIND AND Socialization CAPABILITIES OF LLMS FROM A FIRST-PERSON PERSPECTIVE", "authors": ["Guiyang Hou", "Wenqi Zhang", "Yongliang Shen", "Zeqi Tan", "Sihao Shen", "Weiming Lu"], "abstract": "In the social world, humans possess the capability to infer and reason about others' mental states (such as emotions, beliefs, and intentions), known as the Theory of Mind (ToM). Simultaneously, humans' own mental states evolve in response to social situations, a capability we refer to as socialization. Together, these capabilities form the foundation of human social interaction. In the era of artificial intelligence (AI), especially with the development of large language models (LLMs), we raise an intriguing question: How do LLMs perform in terms of ToM and socialization capabilities? And more broadly, can these AI models truly enter and navigate the real social world? Existing research evaluating LLMs' ToM and socialization capabilities by positioning LLMs as passive observers from a third-person perspective, rather than as active participants. However, compared to the third-person perspective, observing and understanding the world from an ego-centric first-person perspective is a natural approach for both humans and AI agents. The ToM and socialization capabilities of LLMs from a first-person perspective, a crucial attribute for advancing embodied AI agents, remain unexplored. To answer the aforementioned questions and bridge the research gap, we introduce EgoSocialArena, a novel framework designed to evaluate and investigate the ToM and socialization capabilities of LLMs from a first-person perspective. It encompasses two evaluation environments: static environment and interactive environment, with seven scenarios: Daily Life, Counterfactual, New World, Blackjack, Number Guessing, and Limit Texas Hold'em, totaling 2,195 data entries. With EgoSocialArena, we have conducted a comprehensive evaluation of nine advanced LLMs and observed some key insights regarding the future development of LLMs as well as the capabilities levels of the most advanced LLMs currently available.", "sections": [{"title": "INTRODUCTION", "content": "In the complex social interactions of humans, two fundamental cognitive capabilities play crucial roles: Theory of Mind (ToM) and Socialization. ToM is a fundamental psychological process, defined as the capacity to reason about others' mental states beliefs, intents, desires, emotions, knowledge, etc (Premack & Woodruff, 1978; Ma et al., 2023; Chen et al., 2024). Socialization refers to the capability for own mental state evolution in response to social situations. As illustrated in Figure 1(A), When the little boy receives a birthday gift or achieves good grades, he feels very happy. These intertwined capabilities are central to humans' social life.\nWith the advent of the era of LLMs, powerful models like GPT-4 (Achiam et al., 2023) and Claude (Anthropic, 2024) have demonstrated remarkable competence in multiple tasks and domains. It raises intriguing questions: How do LLMs perform in terms of ToM and socialization capabilities? And more broadly, can these AI models truly enter and navigate the real social world to achieve efficient human-computer interaction?\nTo evaluate the ToM and socialization capabilities of LLMs, multiple benchmarks have been pro- posed, such as SocialIQA (Sap et al., 2022), NormBank (Ziems et al., 2023), BigToM (Gandhi et al.,"}, {"title": "RELATED WORK", "content": "Existing ToM Benchmarks Previous evaluations for the ToM of LLMs primarily focus on testing models using narrative stories, also referred to as reading comprehension scenarios. Specifically, Le et al. (2019) proposed the ToMi benchmark based on the classic Sally-Anne test. Wu et al. (2023) introduced the HI-ToM benchmark, which focuses on higher-order belief reasoning and sets up scenarios where agents can communicate with each other. Gandhi et al. (2023) proposed Big- ToM, which presents a framework for designing a ToM benchmark from synthetic templates for evaluating different aspects of LLMs' ToM capabilities (e.g., desire and belief). Xu et al. (2024) introduced OpenToM, which assigns personalities to agents in the stories and ensures that the story- lines are more reasonable and logical. Chen et al. (2024) proposed ToMBench, which systematically evaluates LLMs across all dimensions of ToM capabilities. Unlike the above methods that require LLMs to read stories and answer related questions, some studies evaluate LLMs' performance by inputting dialogues to them. Kim et al. (2023) proposed FanToM, which tests LLMs on their ability to infer the mental states of characters in everyday conversations. Chan et al. (2024) introduced NegotiationToM, which restricts the dialogue content to negotiation scenarios.\nExisting Socialization Benchmarks Sap et al. (2022) proposed SocialIQA and used it to evaluate LLMs. SocialIQA contains many questions related to social commonsense. Ziems et al. (2023) introduced NormBank, a large repository of social norms knowledge, which can be used to as- sess social norm-related tasks. Li et al. (2024) reorganized and classified existing datasets related to social intelligence. Xu et al. (2023) studied LLMs' understanding of the world and explored how different persuasion strategies could modify LLMs' worldviews. Different from our work, the aforementioned ToM and socialization benchmarks evaluate LLMs by placing them in a passive observer's third-person perspective."}, {"title": "EGOSOCIALARE\u039d\u0391", "content": "EgoSocialArena provides a systematic approach to convert third-person perspective ToM bench- marks into first-person perspective, constructs Rule-based Agents at different cognitive levels and Reinforcement Learning (RL) Agents, and includes various scenarios to evaluate LLMs' ToM and socialization capabilities from a first-person perspective."}, {"title": "CONVERTING EXISTING THIRD-PERSON TOM BENCHMARKS TO A FIRST-PERSON PERSPECTIVE", "content": "Foundation and Inspiration In LLM-based Agent applications, system message serves as a crit- ical component, functioning to pre-set the model's role and background. As illustrated in Figure 2(A), system message \"You are name and live in a town...\" is used. Interestingly, in the domain of LLM self-awareness research (Laine et al., 2024), a similar linguistic construct is employed. As illustrated in Figure 2(B), researchers employ the pronoun \"you\" to probe LLMs' potential self- awareness. Inspired by and building upon studies in these two domains, we systematically modify system message, story, question, and answer options to transform third-person ToM benchmarks into a first-person perspective.\nConversion Method As illustrated in Figure 2(C), unlike instructing LLMs in system message that \"you are a helpful assistant.\", we inform LLMs in system message that they have personally experi- enced certain social events, similar to deploy LLM-based Agent. As illustrated in Figure 2(D), we employ the pronoun \"you\" to replace specific characters in stories and questions, thereby situating LLMs within particular roles. This approach enables the models to experience social events from a first-person perspective. The framing of questions is akin to that employed in self-awareness re- search. For modifications to answer options, consider LLMs answer from a first-person perspective, substituting 'I' for specific character in the options. Higher-order ToM questions from third-person perspective benchmarks, after conversion, are still used to evaluate the ToM capabilities of LLMs from a first-person perspective. In contrast, first-order ToM questions, after conversion, form an assessment of LLMs' mental states following social events, which we include in the scope of evalu- ating socialization capabilities."}, {"title": "INTRIGUING AND DISTINCTIVE SOCIAL SITUATIONS", "content": "As illustrated in Figure 3, we design three particularly interesting scenarios-Counterfactual, New World, and Blackjack-all used to evaluate the socialization capabilities of LLMs.\nCounterfactual In real social situations, the rules of Rock-Paper-Scissors are: rock beats scissors, scissors beat paper, and paper beats rock. An LLM can relatively easily establish a belief based on this situation. In contrast, we define a counterfactual situation for the Rock-Paper-Scissors game (scissors beat rock, paper beats scissors, and rock beats paper) to explore whether an LLM can establish a belief that matches this counterfactual situation.\nNew World We design stories that describe new social world scenarios that are significantly dif- ferent from the current social world. We aim to investigate whether LLMs can demonstrate cognitive flexibility and achieve substantive shifts in their understanding and reasoning about the social world.\nBlackjack In the single-turn card game scenario, it is necessary to analyze the game situation, i.e., analyze own cards in Self-belief and the opponent's cards in External-belief. This forms a comprehensive mental estimation of the current game situation. We experiment with the blackjack card game, and its specific rules can be found in A.1."}, {"title": "INTERACTIVE ENVIRONMENT", "content": "In the interactive environment, many studies adopt two different LLMs to interact (e.g., GPT-3.5 vs GPT-4). However, we have observed a phenomenon in such experiments: \"Babysitting\u201d weaker model distracts the stronger model. When comparing the ToM capabilities of the Deepseek-v2"}, {"title": "RULE-BASED AGENTS AT DIFFERENT COGNITIVE LEVELS", "content": "Agents' actions at lower cognitive levels follow relatively simple and fixed rules. As the cognitive level increases, agents' actions adhere to more complex rule patterns, exhibiting capabilities and behavior strategies that approximate human cognitive models. We establish rule-based agents at different cognitive levels as opponents and denote the action of LLM Agent and rule-based Agent as $a_m^t$ and $a_r^t$ in round t, respectively.\nScenario: Number Guessing Level 1: $a_r^t = C$. In this pattern, we conduct experiments with the rule-based Agent's actions remaining constant at 50. Level 2: $a_r^t = f(t) = 50 \u2013 5(t \u2014 1)$. In this pattern, we conduct experiments with the rule-based Agent's action sequence of round 1: 50, round 2: 45, ..., round 9: 10, round 10: 5, an arithmetic sequence with the first term 50 and a common difference of 5. Level 3: $a_r^t = f(a_m^{t-1}, a_r^{t-1}) = 0.8 \\times \\frac{a_r^{t-1}+a_m^{t-1}}{2}$. In this pattern, we conduct experiments with the rule-based Agent's action copying the gold value from the previous round. The rules of number guessing can be found in A.1."}, {"title": "REINFORCEMENT LEARNING AGENTS", "content": "In the Limit Texas Hold'em scenario, we train two reinforcement learning agents as opponents: Deep Q-network (DQN)-Aggressive (Mnih et al., 2015) and DQN-Conservative (Mnih et al., 2015). By adapting the reward function, RL agents are given different game personalities. For DQN- Aggressive, we encourage the action of raising and calling during the game. In contrast, for DQN- Conservative, we encourage the action of folding during the game. The rules of Limit Texas Hold'em"}, {"title": "INTERACTION", "content": "During the interaction between an LLM and a rule-based agent in Number Guessing scenario, as illustrated in Figure 3, each round will involve asking the LLM M ToM questions $Q_{ng}^t$ regarding the opponent's behavior:\n$A_{ng}^t = M(Q_{ng}^t \\oplus H^{<t} \\oplus P_{ng}^t), t \\in \\{1, 2, ..., N\\} \\quad\\quad(1)$\nwhere $P_{ng}^t$ is a prompt for leading to the answer, t represents the current round number, $H^{<t}$ represents game history information, $A_{ng}^t$ represents LLM's response.\nAfter multiple rounds of game interaction between the LLM and the RL Agent in Limit Texas Hold'em scenario, asking the LLM M ToM questions $Q_{lth}^t$ regarding the opponent's play style:\n$A_{lth}^t = M(Q_{lth}^t\\oplus H^{<t} \\oplus P_{lth}^t), t = N \\quad\\quad (2)$\nwhere $P_{lth}^t$ is a prompt for leading to the answer, t represents the current round number, $H^{<t}$ represents game history information, $A_{lth}^t$ represents LLM's response."}, {"title": "DATA CONSTRUCTION", "content": "The conversion of the third-person perspective ToM benchmark to the first-person perspective is achieved through GPT-40, followed by manual verification and correction. The game hands for Limit Texas Hold'em and Blackjack card games are generated by RLcard (Zha et al., 2019). Addi- tionally, we manually construct scenarios for both the new world and counterfactual situations. After the data collection, following Chen et al. (2024)'s method, we conduct two rounds of validation to ensure the data's correctness and quality. In 1st round, author A would first complete all samples created by author B. For stories, questions, and answer options where there are disagreements, au- thors A and B would discuss and modify them to reach a consensus as much as possible. In 2nd round, for samples where consensus is still not reached, another author C would discuss with authors A and B to determine the final answer. After two rounds of discussion, the final average agreement reaches 97.6%."}, {"title": "DATA STATISTICS", "content": "EgosocialArena includes two evaluation environments: static environment and interactive environ- ment, with seven scenarios: Daily Life, Counterfactual, New World, Blackjack, Number-Guessing, and Limit Texas Hold'em, totaling 2,195 data entries. A comparison with existing ToM benchmarks is shown in Table 1."}, {"title": "EXPERIMENTAL SETUP", "content": "We evaluate a total of 9 popular LLMs, including GPT-40\u00b9, 01-preview\u00b2, GPT-4-Turbo (Achiam et al., 2023), GPT-3.5-Turbo (Achiam et al., 2023), Claude-3.5-sonnet-202406203, LLaMa- 3-8B-Chat4, LLaMa-3-70B-Chat, LLaMa-3-8B-Instruct-Turbo, and LLaMa-3.1-405B-instruct- Turbo (Dubey et al., 2024). To account for the potential influence of model parameters and in- struction tuning, we specifically compare LLaMa-3-8B-Chat with LLaMa-3-8B-Instruct-Turbo, as well as LLaMa-3-8B-Chat with LLaMa-3-70B-Chat.\nTo establish a human performance baseline, we recruit 10 graduate students, all of whom have received a good basic education and possess mature cognitive abilities, to complete responses to the questions in EgoSocialArena. The average accuracy of their responses will serve as the human performance baseline. No extra tutorials or examples are provided to ensure a fair comparison."}, {"title": "EVALUATION METHOD", "content": "For Daily Life, New World, and CounterFactful scenarios, we present LLMs with a story, a question, and several options, then ask them to pick the correct answer. Using the accuracy of answering questions as the evaluation metric for these scenarios. In the interactive environments of Number Guessing and Texas Hold'em, the evaluation of these scenarios also has standard answers because we propose agents with stable capabilities and behavioral strategies as opponents of LLMs. For the Blackjack scenario, we conducted a manual evaluation. To ensure the quality of the manual evaluation, we measure the average consistency score between evaluators, which reached 96.3%."}, {"title": "EXPERIMENTAL RESULTS", "content": "The performance of ToM and socialization capabilities from the LLMs' first-person perspective is shown in Table 2 and 3, respectively. Based on the experimental results, we have obtained some key insights:"}, {"title": "QUALITATIVE ANALYSIS", "content": "Analysis of Model Failure Causes and Be- havioral Patterns in Number Guessing Sce- nario Mid-point Belief, Strange Guess and Get Back on Track As shown in Figure 4, in the scenario of Number Guessing (Level 2: Arithmetic sequence), we thoroughly investi- gate the belief state evolution pattern of GPT-4- Turbo regarding the opponent's proposed num- bers. In round 1, with no available informa- tion, the GPT-4-Turbo model thinks the oppo- nent will choose the number 50 within the range of 1-100. The same phenomenon is observed in the GPT-3.5-Turbo model, called \"mid-point belief\". Sometimes, the GPT-4-Turbo model continuously believes the opponent will choose progressively smaller numbers throughout the entire interaction, as depicted by the GPT-4-Turbo guess1 curve in Figure 4. Although this is very close to the gold number, it does not capture that the opponent's chosen numbers form an arithmetic sequence. Another situation occurs when the GPT-4-Turbo model makes a \"strange guess\" in the initial rounds, thinking the opponent will sud- denly choose larger numbers. After several rounds, it captures that the opponent's chosen numbers form an arithmetic sequence, called \"Get Back on Track\". Overall, despite the statistical results indicating that the GPT-4-Turbo model does not establish a belief regarding the Level 2 opponent in the Number Guessing scenario, the phenomena we observed suggest that it has started to grasp some patterns.\nAnalysis of our research and current studies centered on outcomes and benefits Many cur- rent works focus on designing various strategies to improve the performance of LLMs in static or interactive environments. For example, making an LLM display anger to enhance its performance in negotiation scenarios, or using carefully crafted prompt engineering to analyze an opponent's behavior from multiple perspectives to achieve higher payoffs. Unlike these approaches, we funda- mentally explore the ToM capabilities of LLMs from a first-person perspective in various scenarios. Based on the behavior patterns of LLMs that we observed in our experiments, such as the excellent performance of the o1-preview and Claude models in the situated new world scenarios, it indicates that these models have significant potential for further exploration in fields like role-playing and simulation, as well as entering the real social world."}, {"title": "CONCLUSION", "content": "In this paper, considering the limitations of existing ToM and socialization benchmarks, the im- portance of first-person ToM and socialization capabilities in LLMs, and the natural approach of observing and understanding the world from an ego-centric first-person perspective for both humans and AI agents, we propose the EgoSocialArena framework. This framework is designed to compre- hensively evaluate and probe the first-person ToM and socialization capabilities of LLMs in both static and interactive environments, covering multiple scenarios. To avoid the \"babysitting\" prob- lem during the evaluation process and achieve fair and comprehensive assessments, we construct rule-based agents at different cognitive levels and train RL agents. We collect a total of 2195 test data entries and test multiple advanced and popular LLMs, revealing some interesting and key in- sights, and highlighting a significant potential for enhancing the first-person ToM and socialization capabilities of LLMs, allowing them to truly enter the social world."}]}