{"title": "GeMuCo: Generalized Multisensory Correlational Model for Body Schema Learning", "authors": ["Kento Kawaharazuka", "Kei Okada", "Masayuki Inaba"], "abstract": "Humans can autonomously learn the relationship between sensation and motion in their own bodies, estimate and control their own body states, and move while continuously adapting to the current environment. On the other hand, current robots control their bodies by learning the network structure described by humans from their experiences, making certain assumptions on the relationship between sensors and actuators. In addition, the network model does not adapt to changes in the robot's body, the tools that are grasped, or the environment, and there is no unified theory, not only for control but also for state estimation, anomaly detection, simulation, and so on. In this study, we propose a Generalized Multisensory Correlational Model (GeMuCo), in which the robot itself acquires a body schema describing the correlation between sensors and actuators from its own experience, including model structures such as network input/output. The robot adapts to the current environment by updating this body schema model online, estimates and controls its body state, and even performs anomaly detection and simulation. We demonstrate the effectiveness of this method by applying it to tool-use considering changes in grasping state for an axis-driven robot, to joint-muscle mapping learning for a musculoskeletal robot, and to full-body tool manipulation for a low-rigidity plastic-made humanoid.", "sections": [{"title": "I. INTRODUCTION", "content": "Humans can continuously estimate and control their phys-ical state by autonomously learning the relationship between various sensations and movements of their body, allowing them to adapt to the current environment and keep moving. A human can compensate for the lack of some their senses by using various other senses, just as a blindfolded human can roughly determine the position of their hand or a grasped tool from their own proprioception. Even in a complex body structure with joints, muscles, and tendons, the body gradually learns how to move by constantly learning the correlation between sensation and motion in an autonomous manner. Even if the body changes over time, or if the tools to be manipulated or the state of grasping changes, a human can detect and adapt to these changes, and can always estimate and control the state of the body appropriately. In this study, this human function is expressed in terms of a body schema, which represents the relationship between various sensors and actuators considering the body structure [1], [2]. We have considered the following four requirements that a body schema should have in an intelligent robot system (Fig. 1).\n\u2022 Multisensory Correlation - capable of expressing cor-relation among various sensors and actuators"}, {"title": "A. Multisensory Correlation", "content": "Multisensory Correlation is not simply a matter of dealing with multiple sensors. It is necessary to express correlations among various sensors so that the model can cope with situations such as when a certain sensor is un-available, or when a certain control input is not desired to"}, {"title": "B. General Versatility", "content": "For General Versatility, previous learning methods have generally been structured to achieve one goal, e.g. motion control [6], recognition [7], and anomaly detection [8]. On the other hand, there are few examples of integrating these multiple tasks in a single network. If control, state estimation, anomaly detection, simulation, etc. can be handled in a unified manner using a general-purpose computation proce-dure based on a single model, the learning results can be uniformly reflected in these components, and manageability can be improved."}, {"title": "C. Autonomous Acquisition", "content": "For Autonomous Acquisition, it is important not to use manually constructed assumptions for each robot, no matter how complex the body structure is. Although various learning-based control methods have been developed for complex robots such as those with flexible links [9], these methods make many assumptions on the structure of the problem and cannot be used for musculoskeletal structures, flexible tools, flexible objects, etc. in a unified manner. While there have been many attempts using imitation learning [10] and reinforcement learning [11], there are limited methods that allow actual robots to learn from experience without human intervention. Also, autonomous acquisition should not be limited to the mere acquisition of a model through learning. For truly autonomous acquisition, it is necessary for a robot to acquire even the structure of the model itself autonomously. Although the most common network structure determination method is Neural Architecture Search (NAS) for deep neural networks [12], these are parameter searches of neural networks, and the input/output of the network is generally fixed. Note that some methods utilizing mutual information and self-organizing maps have also been developed [13], [14]."}, {"title": "D. Change Adaptability", "content": "For Change Adaptability, existing methods rarely incor-porate information about gradual model changes directly into the models [15], [16]. In reinforcement learning [3] and supervised learning [6], adaptive behavior is generated by collecting a large amount of data in various environments. In other words, if the purpose of the behavior is uniquely determined, adaptive behavior can be produced by collecting data in various environmental conditions. On the other hand, if the purpose of the behavior is not uniquely determined and the model is to be used for various control, state estimation, anomaly detection, etc., it is difficult to obtain the change adaptability by simply inputting a large amount of data into the network."}, {"title": "E. Body Schema in Robotics", "content": "Research on body schema learning in robotics has been conducted extensively [2], [17]. The simplest example of body schema would be a generic robot model. Efforts to identify models with parameters such as link length, weight, and inertia have been numerous [18]. However, these efforts are limited to easily modelable robots and cannot handle Multisensory Correlation. There have also been attempts at body schema learning in more challenging setups, such as when the link structure is unknown [19], but these still make numerous assumptions about the robot's body structure. Recently, body schema learning methods using deep learning have been developed to overcome these limi-tations [5], but the network structure is human-designed and lacks Autonomous Acquisition and Change Adaptability. Conversely, methods that heavily address Change Adapt-ability often lack Multisensory Correlation and General Versatility [15], [16]. Furthermore, alongside the recent development of foundational models, models that learn ma-nipulation strategies end-to-end based on diverse sensory and linguistic inputs have emerged [20]. However, due to these models being very large and learning policies directly from teaching data, they lack General Versatility, Autonomous Acquisition, and Change Adaptability."}, {"title": "F. Our Contributions", "content": "From the above discussion, a body schema learning method that satisfies all the four requirements does not exist. Therefore, the purpose of this study is to improve the robot's adaptive ability by modeling a body schema with these characteristics and having it learn autonomously. Drawing on our experiments which include tool-tip manipulation learning considering grasping state changes of axis-driven robots [21], joint-muscle mapping learning for musculoskeletal humanoid robots [22], and whole-body tool manipulation learning for low-rigidity humanoid robots [23], we propose a theoretical framework that consolidates these, called the Generalized Multisensory Correlation Model (GeMuCo). In this model, when the values of sensors and actuators are collectively represented by the variable x, the network structure is $(x,m) \\rightarrow x$, using the mask variable m to represent the correlation between various sensors and actuators. This is a static body schema for static motions, i.e. motions for which there is a one-to-one correspondence between a certain control input and a sensation. Note that, in the case of dynamic motions, the network structure becomes a time-evolving dynamic body schema with different times at the input and output of the network [24]. In this study, we mainly discuss static body schema. Our contributions of GeMuCo are as follows:\n\u2022 Multisensory correlation modeling by mask expression\n\u2022 Versatile realization of control, state estimation, simu-lation, and anomaly detection by a single network\n\u2022 Automatic acquisition of model structure including model input/output and their correlation\n\u2022 Change adaptability by a mechanism of parametric bias"}, {"title": "II. GEMUCO: GENERALIZED MULTISENSORY CORRELATIONAL MODEL", "content": "The overall system of Generalized Multisensory Correla-tional Model (GeMuCo) is shown in Fig. 2. First, various sensory and control input data are collected (Data Collec-tor), and GeMuCo is trained based on these data (Network Trainer). In this process, the input/output of the network and the feasible mask set can be automatically determined from the data (Structure Determinator). During operation, GeMuCo always collects sensory and control input data and continuously updates part or all of it based on these data (Online Updater). Given a target state, GeMuCo calculates the control input to realize the state and commands to the robot (Controller). Based on some sensors and actuators, the current latent state of the robot is calculated, and sensor values that cannot be directly obtained are estimated (State Estimator). Anomaly detection is performed based on the prediction errors of the sensor values (Anomaly Detector). GeMuCo can also be used to simulate the actual robot behavior based on the control input (Simulator)."}, {"title": "A. Network Structure of GeMuCo", "content": "The network structure of GeMuCo is shown in the left figure of Fig. 2. First, we consider that there is a latent state z that can represent the current sensory and control inputs x. This means that when there exist, e.g. four kinds of sensory and control inputs $x = X{1,2,3,4}$, all values of $X{1,2,3,4}$ can be inferred by this z. Moreover, this z can be inferred using some or all of $x{1,2,3,4}$. This means that each of the sensory and control inputs are correlated with each other via z. On the other hand, these relationships are difficult to handle as they are to construct a practical data structure of the model. Therefore, we expand this model and consider a model where the network inputs are $x{1,2,3,4}$ and the mask variable m, the middle layer is the latent state z, and the network output is $x{1,2,3,4}$. Here, we call the network from the input to the middle layer Encoder, and the network from the middle layer to the output Decoder. Let h denote"}, {"title": "1) Mask Variable", "content": "m ($\u2208$ {0,1}$^{N_{sensor}}$ where $N_{sensor}$ is the number of sensors and actuators) is a variable that masks the input $x{1,2,3,4}$. If i-th line of m is 0, we set $x_{i}$ = 0 and mask it completely. On the other hand, if x is 1, the current value $x_{i}$ is used as network input. In other words, some of the inputs are masked by m, and z is computed from a limited number of network inputs. This makes it possible to infer the masked values and to use them for state estimation and anomaly detection. Of course, not all m is acceptable, and it is necessary to maintain a set of feasible masks M. Note that the input and output of the network need not be the same. In this study, we represent the values used for the network input as $x_{in}$ and the values used for the network output as $x_{out}$, and all the values used for the input/output of the network are expressed as x."}, {"title": "2) Parametric Bias", "content": "As a characteristic structure, p, parametric bias (PB) [25], is given as network input. This is a mechanism that has been mainly used in imitation learning and has been utilized in cognitive robotics research for the purpose of extracting multiple attractor dynamics from the obtained experience. The extraction of object dynamics from multimodal sensations [26] and the extraction of changes in hand-eye dynamics due to tool grasping [27] are being conducted. On the other hand, we do not directly use the parametric bias in the context of imitation learning in this study. We embed information on changes in the body, tools, and environment into this parametric bias, and update it according to the current state to adapt to the environment. From the above, h, $h_{enc}$, and $h_{dec}$ can be expressed as follows."}, {"title": "B. Basic Usage of GeMuCo", "content": "The six basic usages (a)-(f) of GeMuCo and their applica-tion to the training and online update of GeMuCo and to the state estimation, control, and simulation using GeMuCo are"}, {"title": "C. Data Collection for GeMuCo", "content": "In order to train GeMuCo, the necessary data of x needs to be collected. There are two main methods: random action and human teaching. In random action, \u00e6 is obtained from random control inputs. It is also possible to consider a mapping from some random number to the control input, and use this mapping to operate the robot while applying constraints. In human teaching, a human directly decides the motion commands by using VR devices, sensor gloves, GUI applications, and so on. Data can be collected more efficiently for tasks that are difficult to perform by random action.\nIt is not necessary to collect data for all x at all times. For example, it is acceptable if the robot vision is occasionally blocked, or if there are long intervals between some of the data collections. It is also acceptable to install a special sensor only when collecting data for training purposes. Also, x to be collected is not necessarily limited to the information directly obtained from the robot's sensors. It is possible to process the values of existing sensors before inputting them to the network, e.g. object recognition results obtained from image information or sound information related to specific frequencies, etc."}, {"title": "D. Training of GeMuCo", "content": "Although the training of GeMuCo described in this section is executed after the automatic determination of the network structure, it is explained first since it is necessary for the automatic structure determination as well.\nWhen data D of x is obtained, the output is usually inferred by taking $x_{in}$ as input and training GeMuCo so that it becomes close to $x_{out}$ using the mean squared error as the loss function. Here, it is necessary to include a mask variable m in the training for GeMuCo. First, we prepare a set of feasible masks M. Then, for each $x_{in}$, we use each m in M to mask a part of the corresponding $x_{in}$ and create $x_{masked}$. By inputting $x_{masked}$ and the corresponding m, we train the weight W of the network. In addition, \u00e6 is not always available for all the modalities. For example, there may be a situation where $x{1,2,4}$ is available but $x_{3}$ is not. In this case, for the mask of x, m that can mask the data that cannot be obtained is chosen. If such m is not included in M, we do not train using this data. For the loss function, the mean squared error is calculated only for the obtained data, and the weight W is updated.\nIn addition, when parametric bias p is used as input, it is necessary to add one more step to the training method. In this case, we take data while changing the state of the body, tools, and environment. Let $D_{k}$ = {$X_{1},X_{2},...X_{T_{k}}$}\n(1 \u2264 k \u2264 K) where K is the total number of states and $T_{k}$ is the number of data in the state k. Thus, the data used for training is D = {(D1, p1), (D2, P2),\u00b7\u00b7\u00b7, (Dk, pk)}. Here, pk is the parametric bias for the state k, which is a variable with a common value for the data Dk but a different value for different data. Using this data D, we simultaneously update the network weight W and parametric bias pk. In other words, pk is introduced so that the data Dk of x in each state k with different dynamics can be represented by a single network. This allows us to embed the dynamics of each state k into pk, which can be applied to state recognition and adaptation to the current environment. Note that pk is trained with an initial value of 0."}, {"title": "E. Automatic Structure Determination of GeMuCo", "content": "We describe a method for automatically determining the network structure of GeMuCo. Specifically, we determine $x_{in}$, $x_{out}$, and a set of feasible masks M. If this network structure can be determined automatically from the given data, not only human work can be reduced, but also the autonomy of the robot can be dramatically improved. In other words, the robot can autonomously determine and train the network structure from the obtained data, and automatically construct state estimators, controllers, and so on based on the trained network structure. This operation mainly consists of determining network outputs that can be inferred from the latent space, and determining combinations of network inputs and masks that can infer the latent space, as shown in (a) of Fig. 4. Note that the number of layers and units of the network are given externally by humans, and these are not automatically determined (there are various mechanisms such as NAS for these [12])."}, {"title": "1) Network Training", "content": "In order to determine $x_{in}$, $x_{out}$ and a set of feasible masks M, GeMuCo h is trained once using the obtained data D. The input/output of the network is determined based on the inference error when using the trained h. Here, in order to calculate the inference error for each mask m, when training the network as in Section II-D, a set of all possible masks $M_{all}$ (all $2^{N_{sensor}}$ \u2013 1 combinations excluding masks that are all zero) is used. m is randomly selected from $M_{all}$ each time."}, {"title": "2) Determination of Network Output", "content": "We determine the network output $x_{out}$ of GeMuCo. This can be judged from whether a given value $x_{i}$ is deducible from other values $x_{j} (i \u2260 j)$. If it is deducible, then $x_{i}$ is related to other sensors and actuators, and should be inferred as an output of the network. On the other hand, if it is not deducible, it should not be inferred because it will negatively influence the training of the network. As shown in (b) of Fig. 4, a value x is inferred from other values \u00e6; and its inference error is Li. We collect only $x_{i}$ for which $L_{i} < C_{th}^{out}$, and construct $x_{out}$ using them. Sensor values not adopted here are not utilized as part of the network output."}, {"title": "3) Determination of Network Input", "content": "We determine the network input $x_{in}$ of GeMuCo. At the same time, we also"}, {"title": "F. Online Update of GeMuCo", "content": "When the robot's physical state, tools, or surrounding en-vironment changes, a model adapted to the current state can be used by updating GeMuCo for accurate state estimation and control. There are three possible ways to update the network: updating W, updating p, and updating W and p simultaneously. This corresponds to (c) and (d), or a combination of them in Fig. 3. When data D is obtained, the loss function is computed and the gradient descent method is used to update only W, only p, or W and p simultaneously. In the case of offline update, the network is updated once after a certain amount of data has been accumulated. In the case of online update, the network is updated gradually. When the number of data exceeds a determined threshold, data is discarded from the oldest. In addition to the actual D, if there are any constraints such as origin, geometric model, minimum and maximum values, etc., the data representing these constraints can also be added to D during the training. In the case of updating only p, only some dynamics are changed and the structure of the overall network is kept the same, thus overfitting for the current data is unlikely to occur. On the other hand, it should be noted that updating Wor updating W and p simultaneously changes the structure of the entire network, and thus overfitting is likely to occur."}, {"title": "G. Optimization Computation by Iterative Forward and Backward Propagations", "content": "We describe the optimization computation that is fre-quently used in the state estimation, control, and simula-tion, which will be explained subsequently. This operation corresponds to (e) and (f) of Fig. 3, where the procedure of iterative optimization of \u00e6 or z based on a certain loss function is shown. As an example, let us assume that z is optimized based on the loss function for $x_{out}$ and that there is the relation $x_{out}$ = $h_{dec}(z)$.\n1) Assign the initial value $z_{init}$ to the variable $z_{opt}$ to be optimized\n2) Infer the predicted value of $x_{out}$ as $x_{out}^{pred} = h_{dec}(z_{opt})$\n3) Calculate the loss L using the loss function $h_{loss}$\n4) Calculate $dL/dz_{opt}$ using the backward propagation\n5) Update $z_{opt}$ by gradient descent method\n6) Repeat processes 2)\u20135) to optimize $z_{opt}$\nWe now describe process 5) in detail. Process 5) performs the following operation,\n$z_{opt} \\leftarrow z_{opt} - \u03b3 \\frac{\u2202L}{\u2202z_{opt}}$\nwhere y is the learning rate. y can be a constant, but we can also try various \u03b3 as variables to achieve faster convergence. For example, we determine the maximum value $\u03b3_{max}$ of \u03b3, divide [0, $\u03b3_{max}$] equally into $N_{batch}$ values ($N_{batch}$ is a constant that expresses the batch size of training), and update $z_{opt}$ with each y. Then, we select $z^{opt}$ with the smallest L in steps 2) and 3), and repeat steps 4) and 5) with various y for the $z_{opt}$"}, {"title": "H. State Estimation using GeMuCo", "content": "In state estimation, the sensor values that are currently unavailable are estimated from the network. For this purpose, (a), (b), (e), and (f) in Fig. 3 are used. If $x_{out}$ contains the value to be estimated, we consider the execution of (a) or (b), and if (a) and (b) are not possible, we consider the execution of (e). If $x_{out}$ does not contain the value to be estimated, we consider the execution of (f).\nIn (a), we consider a mask m, which is set to 0 for the unavailable data and 1 for the available data. If this mask m is included in the set of feasible masks M, then by inputting this m and $x_{masked}$ with 0 for the unavailable data into the network, we can estimate the currently unavailable data.\nSimilarly, in (b), if the network has all necessary inputs, the remaining data can be estimated directly. Even when the inputs are not available, if there exists a feasible m, the missing data can be estimated in the same way as in (a).\nIf there is no feasible m in the form of (a) and (b), state estimation is performed in the form of (e). This corresponds to the case where the loss function is set as follows in Section II-G,\n$h_{loss}(x_{out}^{pred}, x_{data}) = ||m_{x_{out}}(x_{out}^{pred} - x_{data})||^{2}$ \nwhere $x_{data}$ is the currently obtained data of $x_{out}$ with some unavailable data. Also, $m_{x_{out}}$ is a mask that is 0 for unavailable data and 1 for available data. || denotes"}, {"title": "I. Control Using GeMuCo", "content": "Depending on the structure of the network, either (a), (b), (e), or (f) in Fig. 3 is computed, as in Section II-H. The calculation depends on whether the control input is contained in $x_{in}$ or $x_{out}$, and whether the target state can be input directly or the target state needs to be expressed in the form of a loss function.\nIf the control input is contained in $x_{out}$ and all target states can be input directly from $x_{in}$, then either (a) or (b) is performed. That is, $x_{out} = h(x_{in}, m)$.\nIf the control input is contained in $x_{out}$ and the target state must be expressed in the form of a loss function, (e) is executed. This corresponds to the case where the loss function is executed in the form of $h_{loss} (x_{pred}, x_{ref})$ in Section II-G. Here, $x_{ref}$ is the target state of $x_{out}$, and $h_{loss}$ can take various forms, e.g. $||Ax_{out}^{pred}-x_{ref}||^{2}$, $||x_{out}^{pred}-x_{ref}||^{2}+ ||x_{out}^{pred}||^{2}$, etc. ($x_{out}^{(pred,ref)}$ represents the {1,2}-th sensor value in $x_{out}^{(pred,ref)}$, and A denotes a certain transformation matrix). $z_{opt}$ is optimized from this loss function, and the obtained $x_{out}^{pred}$ is used as the control input.\nIf the control input is not included in $x_{out}$, (f) is exe-cuted. This means that the variable $z_{opt}$ to be optimized and its initial value $z_{init}$ in Section II-G are changed to $x_{in}^{opt}$ and $x_{in}^{init}$, respectively. Since the loss function can also include the loss with respect to $x_{in}^{opt}$, the loss function is $h_{loss}(x_{out}^{pred}, x_{in}^{pref}, x_{in}^{opt})$, unlike Eq. 5. In other words, the error is propagated directly to the network input $x_{in}$ instead of the latent representation z. The obtained $x_{in}^{opt}$ is used as the control input."}, {"title": "J. Simulation using GeMuCo", "content": "In simulation, the current robot state is estimated from the control input and some constraints. The simulation can be performed in the form of (a), (b), (e), or (f), which is almost the same as the state estimation in Section II-H. The only difference is the loss functions in (e) and (f). Since the loss function does not have the current data $x_{data}$ as in the state estimation but instead has the control input value $x_{send}$ that is actually commanded, the loss function becomes $h_{loss}(x_{out}^{pred}, x_{send})$. This loss function describes various con-straints on the motion of the robot, such as joint torque, muscle tension, and motion speed. Based on the control input and the constraints given in the form of a loss function, the current state is estimated and transitioned."}, {"title": "K. Anomaly Detection using GeMuCo", "content": "Anomaly detection is performed with respect to the amount of error between the current value $x_{out}$ and the estimated value $x_{out}^{est}$. One of the simplest anomaly detection methods is to set a threshold value for $||x_{out} - x_{out}^{est} ||^{2}$ and consider an anomaly when the error is larger than the threshold. On the other hand, the mean and variance of the error can be used to detect anomalies more accurately. First, we collect the state estimation data $x_{out}^{est}$ and the current state data $x_{data}$ in the normal state without any anomaly. For this data, we calculate the mean \u00b5 and variance \u2211 of the error $e_{data}$ = $x_{data}$ - $x_{out}^{est}$. When actually detecting an anomaly, the difference $e_{out}$ between the current value $x_{out}$ and the estimated value $x_{out}^{est}$ is always obtained, and the Mahalanobis distance $d = \u221a((e_{out} \u2013 \u03bc)^{T}\u03a3^{-1}(e_{out} \u2013 \u03bc))$ is calculated for it. When d exceeds the threshold value, we assume that an anomaly has been detected."}, {"title": "III. EXPERIMENTS", "content": "In this study, we utilize the proposed body schema model of GeMuCo for (i) adaptive tool-tip control learning con-sidering the change in grasping state, (ii) complex tendon-driven body control learning for musculoskeletal humanoids, and (iii) full-body tool manipulation learning for low-rigidity humanoids. (i) uses the simplest network structure, and due to its simplicity, no mask expression is required after the network structure is automatically determined. (ii) uses a more complex network structure but without parametric bias, in which the entire network is trained online. (iii) uses the most complex network structure, which contains all the elements of GeMuCo. These are newly interpreted experiments of [21]\u2013[23] using the GeMuCo framework.\nThe reason for adopting each network structure is as below. When utilizing parametric bias, it is necessary to collect data while varying the state. Therefore, parametric bias is employed in cases where it is easy to vary the state, such as in (i) and (iii) scenarios involving changes in grasping state or tool conditions. On the other hand, for aspects such as correction of sim-to-real gap and body changes due to aging or deterioration, as in (ii), it is challenging to capture data while varying the state. Therefore, parametric bias is not used in such cases. Additionally, depending on the task, the collection of sensor values and the automatic determination of network input and output result in the determination of the network structure."}, {"title": "A. Adaptive Tool-Tip Control Learning Considering Online Changes in Grasping State", "content": "Various studies have been conducted on tool manipulation, but they do not take into consideration the fact that the grasping position and angle of a tool changes gradually during tool manipulation. Moreover, few studies have dealt with deformable tools, and generally, only rigid tools fixed"}, {"title": "B. Complex Tendon-driven Body Control Learning for Mus-culoskeletal Humanoids", "content": "We perform body schema learning that can handle state estimation, control, and simulation of musculoskeletal hu-manoids in a unified manner. By updating this network online based on the sensor data of the actual robot, the state estimation, control, and simulation of musculoskeletal humanoids can be performed more accurately and continu-ously. Note that the control is based on muscle length-based control, and dynamic factors including hysteresis due to high friction between muscles and bones are not handled in this experiment, resulting in handling only static relationships. In addition, since parametric bias is not used in this study, we do not obtain data for various body states.\nExperimental Setup: In this experiment, we use a musculoskeletal humanoid Musashi [28] as shown in (a) of Fig. 7. We mainly use the 3 degrees of freedom (DOFs) of the shoulder and the 2 DOFs of the elbow as the joint angle \u03b8. Ten muscles move the 5 DOFs of the shoulder and elbow, of which one muscle is a biarticular muscle. For each muscle, muscle length l is obtained from an encoder and muscle tension f from a loadcell. Although joint angle \u03b8 of musculoskeletal humanoids cannot be directly obtained because their joints are usually ball joints, Musashi can measure the joint angle with its pseudo-ball joint module [28]. Even if the joint angle cannot be directly measured, O can be obtained by first estimating the rough joint angle based on muscle length changes and then correcting them using AR markers attached to the hand [29]. In this study, we set x = {0, f, l}.\nThis musculoskeletal humanoid has a geometric model that is a representation of the muscle route by connecting the start, relay, and end points of the muscle with straight lines. Given a certain joint angle, muscle length can be obtained from the distance between the muscle relay points. By considering the elongation of the nonlinear elastic element attached to the muscle depending on muscle tension, the muscle length can be obtained from the given joint angle and the muscle tension. On the other hand, since it is difficult to simulate the wrapping of the muscle around the joint and its change over time, this geometric model is quite different from that of the actual robot and some learning using the actual robot sensor data is necessary.\nNetwork Structure: We obtain 10000 data points from the random joint angle and muscle tension movements of the simulation. The automatic determination of the network structure based on the obtained data is shown in (b) of Fig. 7. First, $L_{{1,2,3}}$ is computed to determine the network output. While $L_{1}$ and $L_{3}$ are almost equally small, $L_{2}$ is somewhat larger. We now consider the cases where 0.247 < $C_{th}^{out}$ = 0.30, i.e. all sensors are used for output, and where"}, {"title": "C. Full-Body Tool Manipulation Learning for Low-Rigidity Humanoids", "content": "In this experiment", "Setup": "In this experiment", "Light": 40, "Middle": 80, "Heavy": 120, "Short": 176, "Long": 236}]}