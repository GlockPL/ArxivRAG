{"title": "Solving Linear-Gaussian Bayesian Inverse Problems with Decoupled Diffusion Sequential Monte Carlo", "authors": ["Filip Ekstr\u00f6m Kelvinius", "Zheng Zhao", "Fredrik Lindsten"], "abstract": "A recent line of research has exploited pre-trained generative diffusion models as priors for solving Bayesian inverse problems. We contribute to this research direction by designing a sequential Monte Carlo method for linear-Gaussian inverse problems which builds on \"decoupled diffusion\", where the generative process is designed such that larger updates to the sample are possible. The method is asymptotically exact and we demonstrate the effectiveness of our Decoupled Diffusion Sequential Monte Carlo (DDSMC) algorithm on both synthetic data and image reconstruction tasks. Further, we demonstrate how the approach can be extended to discrete data.", "sections": [{"title": "Introduction", "content": "Generative diffusion models Sohl-Dickstein et al. (2015); Ho et al. (2020); Song et al. (2021b) have sparked an enormous interest from the research community, and shown impressive results on a wide variety of modeling task, ranging from image synthesis (Dhariwal and Nichol, 2021; Rombach et al., 2022; Saharia et al., 2022) and audio generation Chen et al. (2020); Kong et al. (2021) to molecule and protein generation Hoogeboom et al. (2022); Xu et al. (2022); Corso et al. (2023). A diffusion model consists of a neural network which implicitly, through a generative procedure, defines an approximation of the data distribution, $p_\\theta(x)$. While methods (e.g. Ho and Salimans, 2022) exist where the model is explicitly trained to define a conditional distribution $p_\\theta(x|y)$, this conditional training is not always possible. Alternatively, a domain-specific likelihood $p(y|x)$ might be known, and in this case, using $p_\\theta(x)$ as a prior in a Bayesian inverse problem setting, i.e., sampling from the posterior distribution $p_\\theta(x|y) \\propto p(y|x)p_\\theta(x)$, becomes an appealing alternative. This approach is flexible since many different likelihoods can be used with the same diffusion model prior, without requiring retraining or access to paired training data. Previous methods for posterior sampling with diffusion priors, while providing impressive results on tasks like image reconstruction (Kawar et al., 2022; Chung et al., 2023; Song et al., 2023), often rely on approximations and fail or perform poorly on simple tasks (Cardoso et al., 2024, and our Section 5.1), making it uncertain to what extent they can solve Bayesian inference problems in general.\nSequential Monte Carlo (SMC) is a well-established method for Bayesian inference, and its use of sequences of distributions makes it a natural choice to combine with diffusion priors. It also offers asymptotical guarantees, and the combination of SMC and diffusion models has recently seen a spark of interest Trippe et al. (2023); Dou and Song (2023); Wu et al. (2023); Cardoso et al. (2024). Moreover, the design of an efficient SMC algorithm involves a high degree of flexibility while guaranteeing asymptotic exactness, which makes it an interesting framework for continued exploration.\nAs previous (non-SMC) works on posterior sampling has introduced different approximations, and SMC offers a flexible framework with asymptotic guarantees, we aim to further investigate the use of SMC for Bayesian inverse problems with diffusion priors. In particular, we target the case of linear-Gaussian likelihood models. We develop a method which we call Decoupled Diffusion SMC (DDSMC) utilizing and extending a previously introduced technique for posterior sampling based on decoupled diffusion (Zhang et al., 2024). With this approach, it is possible to make larger updates to the sample during the generative procedure, and it also opens up new ways of taking the conditioning on y into account in the design of the SMC proposal distribution. We show how this method can effectively perform posterior sampling for both synthetic data and image reconstruction tasks. We also further generalize DDSMC for discrete data."}, {"title": "Background", "content": "As mentioned in the introduction, we are interested in sampling from the posterior distribution $p_\\theta(x|y) \\propto p(y|x)p_\\theta(x)$, where the prior $p_\\theta(x)$ is implicitly defined by a pre-trained diffusion model and the likelihood is linear-Gaussian, i.e., $p(y|x) = \\mathcal{N}(y|Ax, \\sigma^2I)$. We will use the notation $p_\\theta(\\cdot)$ for any distribution that is defined via the diffusion model, the notation $p(\\cdot)$ for the likelihood (which is assumed to be known), and $q(\\cdot)$ for any distribution related to the fixed forward diffusion process (see next section).", "2.1 Diffusion Models": "Diffusion models are based on transforming data, $x_0$, to Gaussian noise by a Markovian forward process of the form\u00b9\n$q(x_{t+1}|x_t) = \\mathcal{N}(x_{t+1}|x_t, \\beta_{t+1}I)$.\n(1)\nThe generative process then consists in trying to reverse this process, and is parametrized as a backward Markov process\n$p_\\theta(x_{0:T}) = p_\\theta(x_T) \\prod_{t=0}^{T-1} p_\\theta(x_t|x_{t+1})$.\n(2)\nThe reverse process $p_\\theta$ is fitted to approximate the reversal of the forward process, i.e., $p_\\theta(x_t|x_{t+1}) \\approx q(x_t|x_{t+1})$, where the latter can be expressed as\n$q(x_t|x_{t+1}) = \\int q(x_t|x_{t+1},x_0)q(x_0|x_{t+1})dx_0$\n(3)\nWhile $q(x_t|x_{t+1}, x_0)$ is available in closed form, $q(x_0|x_{t+1})$ is not, thereby rendering Equation (3) intractable. In practice, this is typically handled by replacing the conditional $q(x_0|x_{t+1})$ with a point estimate $f_\\theta(x_{t+1})(x_0)$, where $f_\\theta(x_{t+1})$ is a \"reconstruction\" of $x_0$, computed by a neural network. This is typically done with Tweedie's formula, where $f_\\theta(x_{t+1}) = x_{t+1} + \\sigma_{t+1}^2 s_\\theta(x_{t+1}, t+1) \\approx E[x_0|x_{t+1}]$ and $s_\\theta(x_{t+1}, t+1)$ is a neural network which approximates the score $\\nabla_{x_{t+1}} \\log q(x_{t+1})$ (and using the true score would result in the reconstruction being equal to the expected value). With this approximation, the backward kernel becomes $p_\\theta(x_t|x_{t+1}) = q(x_t|x_{t+1}, x_0 = f_\\theta(x_{t+1}))$.\nProbability Flow ODE Song et al. (2021b) described how diffusion models can be generalized as time-continuous stochastic differential equations (SDEs), and how sampling form a diffusion model can", "2.2 Sequential Monte Carlo": "Sequential Monte Carlo (SMC; see, e.g., Naesseth et al., 2019, for an overview) is a class of methods that enable sampling from a sequence of distributions {$\\pi_t(x_{t:T})\\}_{t=0}^T, which are known and can be evaluated up to a normalizing constant, i.e., $\\tilde{\\pi}_t(x_{t:T}) = \\pi_t(x_{t:T})/Z_t$, where $t(x_{t:T})$ can be evaluated pointwise. In an SMC algorithm, a set of $N$ samples, or particles, are generated in parallel, and they are weighted such that a set of (weighted) particles {$(x_{t:T}^i, w_t^i)$}$\\_{i=1}^N$ are approximate draws from the target distribution $\\pi_t(x_{t:T})$. For each $t$, an SMC algorithm consists of three steps. The resampling step samples a new set of particles {$(x_{t:T}^i)$}$\\_{i=1}^N$ from Multinomial({$(x_{t:T}^i)\\}_{i=1}^N$; {$w_t^i\\}_{i=1}^N$})\u00b2. The second step is the proposal step, where new samples {$x_{t-1:T}^i\\}_{i=1}^N$ are proposed as $x_{t-1}^i \\sim r_{t-1}(x_{t-1}|x_{t:T}^i)$, $x_{t-1:T}^i = (x_{t-1}^i, x_{t:T}^i)$, and finally a weighting step, $w_{t-1}^i \\propto \\frac{\\gamma_{t-1}(x_{t-1:T}^i)}{(r_{t-1}(x_{t-1}^i|x_{t:T}^i)\\gamma_t(x_{t:T}^i))}$. To construct an SMC algorithm, it is hence necessary to determine two components: the target distributions {$\\pi_t(x_{t:T})\\}_{t=0}^T$ (or rather, the unnormalized distributions {$\\gamma_t(x_{t:T})\\}_{t=0}^T$), and the proposals {$r_{t-1}(x_{t-1}|x_{t:T})\\}_{t=1}^T$.\nSMC as a General Sampler Even though SMC relies on a sequence of (unnormalized) distributions, it can still be used as a general sampler to sample from some \"static\" distribution $\\pi(x)$ by introducing auxiliary variables $x_{0:T}$ and constructing a sequence of distributions over {$x_{t:T}\\}_{t=0}^T$. As long as the marginal distribution of $x_0$ w.r.t. the final distribution $\\pi_0(x_{0:T})$"}, {"title": "Decoupled Diffusion SMC", "content": "The sequential nature of the generative diffusion model naturally suggests that SMC can be used for the Bayesian inverse problem, by constructing a sequence of target distributions based on Equation (2). This approach has been explored in several recent works (Wu et al., 2023; Cardoso et al., 2024, see also Section 4). However, Zhang et al. (2024) recently proposed an alternative simulation protocol for tackling inverse problems with diffusion priors, based on a \"decoupling\" argument: they propose to simulate (approximately) from $p_\\theta(x_0|x_{t+1}, y)$ and then push this sample forward to diffusion time t by sampling from the forward kernel $q(x_t|x_0)$ instead of $q(x_t|x_0, x_{t+1})$. The motivation is to reduce the autocorrelation in the generative process to enable making transitions with larger updates and thus correct larger, global errors. The resulting method is referred to as Decoupled Annealing Posterior Sampling (DAPS).\nTo leverage this idea, we can realize that the SMC framework is in fact very general and, as discussed in Section 2.2, the sequence of target distributions can be seen as a design choice, as long as the final target $\\pi_0(x_{0:T})$ admits the distribution of interest as a marginal. Thus, it is possible to use the DAPS sampling protocol as a basis for SMC. This corresponds to redefining the prior over trajectories, from Equation (2) to $p_\\theta(x_{0:T}) = p_\\theta(x_T) \\prod_{t=0}^{T-1} p_\\theta(x_t|x_{t+1})$ where\n$p_\\theta(x_t|x_{t+1}) = q(x_t|x_0 = f_\\theta(x_{t+1})).\n(4)\nConceptually, this corresponds to reconstructing $x_0$ conditionally on the current state $x_{t+1}$, followed by adding noise to the reconstructed sample using the forward model. As discussed by Zhang et al. (2024), and also proven by us in Appendix A, the two transitions can still lead to the same marginal distributions for all time points t, i.e., $\\int p_\\theta(x_{t:T})dx_{t+1:T} = \\int p_\\theta(x_{t:T})dx_{t+1:T}$, under the assumption that $x_0 = f_\\theta(x_{t+1})$ is a sample from $p_\\theta(x_0)$. This can be approximately obtained by, e.g., solving the reverse-time PF-ODE, and using this solution as reconstruction model $f_\\theta(x_{t+1})$.", "3.1 Target Distributions": "Generalizing the DAPS Prior By rewriting the conditional forward kernel $q(x_t|x_{t+1}, x_0)$ using Bayes theorem,\n$q(x_t|x_{t+1}, x_0) = \\frac{q(x_{t+1}|x_t)q(x_t|x_0)}{q(x_{t+1}|x_0)}$,\n(5)\nwe can view the standard diffusion backward kernel Equation (3) as applying the DAPS kernel, but conditioning the sample on the previous state $x_{t+1}$, which acts as an \"observation\" with likelihood $q(x_t|x_{t+1})$. We can thus generalize the kernel in Equation (3) by annealing this likelihood with the inverse temperature \u03b7,\n$p_\\eta(x_t|x_{t+1}) \\propto \\int q(x_{t+1}|x_t)^\\eta q(x_t|x_0)d_{f_\\theta(x_{t+1})}(x_0)dx_0$\n(6)\nwhich allows us to smoothly transition between the DAPS (\u03b7 = 0) and standard (\u03b7 = 1) backward kernels.\nLikelihood Having defined the prior as the generalized DAPS prior $p(x_{t:T})$, we also need to incorporate the conditioning on the observation y. A natural starting point would be to choose as targets\n$\\gamma_t(x_{t:T}) = p(y|x_t)p(x_{t:T})$,\n(7)\nas this for t = 0 leads to a distribution with marginal $p(x|y)$. However, the likelihood $p(y|x_t) = \\int p(y|x_0)p_\\theta(x_0|x_t)dx_0$ in Equation (7) is not tractable for t > 0, and needs to be approximated. As the reconstruction $f_\\theta(x_{t+1})$ played a central role in the prior, we can utilize this also for our likelihood. Song et al. (2023) proposed to use a Gaussian approximation $p_\\theta(x_0|x_t) := \\mathcal{N}(x_0|f_\\theta(x_t), p_t^2I)$, resulting in\n$p(y|x_t) \\approx p(y|x_t) = \\mathcal{N}(y|Af_\\theta(x_t), \\sigma^2I + p_t^2 A A^T)$,\n(8)\nas the likelihood is linear and Gaussian. From hereon we will use the notation $p_t$ for any distribution derived from the Gaussian approximation $p_\\theta(x_0|x_t)$. As for t = 0 the likelihood is known, we can rely on the consistency of SMC to obtain asymptotically exact samples, even if using approximate likelihoods in the intermediate targets.\nPutting it Together To summarize, we define a sequence of intermediate target distributions for SMC according to\n$\\gamma_t(x_{t:T}) = p(y|x_t)p_\\theta(x_T) \\prod_{s=t}^{T-1} p(x_s|x_{s+1})$\n$\\propto \\frac{p(y|x_t)}{p(y|x_{t+1})} p_\\theta(x_t|x_{t+1})\\gamma_{t+1}(x_{t+1:T})$,\n(9)", "3.2 Proposal": "As the efficiency of the SMC algorithm in practice very much depends on the proposal, we will, as previous works on SMC (e.g., TDS (Wu et al., 2023) and MCGDiff (Cardoso et al., 2024)), use a proposal which incorporates information about the measurement y. Again we are inspired by DAPS where the Gaussian approximation $p_\\theta(x_0|x_t)$ plays a central role. In their method, they use this approximation as a prior over $x_0$, which together with the likelihood $p(y|x_0)$ form an (approximate) posterior\n$p_\\theta(x_0|x_{t+1}, y) \\propto p(y|x_0)p_\\theta(x_0|x_{t+1}).$\n(12)\nThe DAPS method is designed for general likelihoods and makes use of Langevin dynamics to sample from this approximate posterior. However, in the linear-Gaussian case we can, similarly to Equation (8), obtain", "3.3 D3SMC \u2013 A Discrete Version": "We also extend our DDSMC algorithm to a discrete setting which we call Discrete Decoupled Diffusion SMC (D3SMC). Using x to denote a one-hot encoding of a single variable, we target the case where the measurement can be described by a transition matrix $Q_y$ as\n$p(y|x_0) = Categorical(p = x_0Q_y)$,\n(21)\nand when the data consists of D variables, the measurement factorizes over these variables (i.e., for each of the D variables, we have a corresponding measurement). This setting includes both inpainting (a variable is observed with some probability, otherwise it is in an \"unknown\" state) and denoising (a variable randomly transitions into a different state). To tackle this problem, we explore the D3PM-uniform model (Austin et al., 2021) and derive a discrete analogy to DDSMC which uses the particular structure of D3PM. We elaborate on the D3PM model in general and our D3SMC algorithm in particular in Appendix E."}, {"title": "Related Work", "content": "SMC and Diffusion Models The closest related SMC methods for Bayesian inverse problems with diffusion priors are the Twisted Diffusion Sampler (TDS) (Wu et al., 2023) and Monte Carlo Guided Diffusion (MCGDiff) (Cardoso et al., 2024). TDS is a general approach for solving inverse problems, while MCGDiff specifically focuses on the linear-Gaussian setting. These methods differ in the choices of intermediate targets and proposals. TDS makes use of the reconstruction network to approximate the likelihood at time t as $p(y|x_0 = f_\\theta(x_t))$ and then add the score of this approximate likelihood as a drift in the transition kernel. This requires differentiating through the reconstruction model w.r.t. $x_t$, which can incur a significant computational overhead. MCGDiff instead uses the forward diffusion model to push the observation y \"forward in time\". Specifically, they introduce a potential function at time t which can be seen as a likelihood corresponding to the observation model $\\hat{y}_t = Ax_t$, where $\\hat{y}_t$ is a noised version (according to the forward model at time t) of the original observation y. DDSMC differs from both of these"}, {"title": "Experiments", "content": "We first experiment on synthetic data, and use the Gaussian mixture model problem from Cardoso et al. (2024). Here, the prior on x is a Gaussian mixture, and both the posterior and score are therefore known on closed form (we give more details in Appendix F.1), enabling us verify the efficiency of DDSMC while ablating all other errors. As a metric, we use the sliced Wasserstein distance Flamary et al. (2021) between 10k samples from the true posterior and each sampling algorithm.\nWe start with investigating the influence of \u03b7 and the reconstruction function $f_\\theta$ in Table 1. We run DDSMC with N = 256 particles, and use T = 20 steps in the generative process. As a reconstruction, we compare Tweedie's formula and the DDIM ODE solver Song et al. (2021a), see Equation (66) in the appendix, where we solve the ODE for the \"remaining steps\" t, t - 1,..., 0. In the table, we see that using Tweedie's reconstruction requires a larger value of \u03b7. This can be explained by the fact that \u03b7 = 0 (DAPS prior) requires exact samples from $p_\\theta(x_0|x_t)$ for the DAPS prior to agree with the original prior (see Appendix A), and this distribution is more closely approximated using the ODE reconstruction. For higher dimensions (i.e., $d_x$ = 800) and using \u03b7 > 0, Tweedie's formula works slightly better than the ODE solver. Qualitatively, we find that using a smaller \u03b7 and/or using Tweedie's reconstruction tends to concentrate the samples around the different modes, see Figure 1 for an example of $d_x$ = 800 and $d_y$ = 1 (additional examples in Appendix F.1). This plot also shows how, in high dimensions, using a smaller \u03b7 is preferable, which could be attributed to lower \u03b7 enabling larger updates necessary in higher dimensions.\nNext, we compare DDSMC with other methods, both SMC-based (MCGDiff and TDS) and non-SMC-based (DDRM, DCPS, DAPS). For all SMC methods, we use 256 particles, and accelerated sampling according to DDIM Song et al. (2021a) with 20 steps, which we also used for DAPS to enabling evaluating the benefits of our generalization of the DAPS method without confounding the results with the effect of common hyperparameters. For DDRM and"}, {"title": "Gaussian Mixture Model", "content": "Image Restoration We now turn our attention to the problem of image restoration, and use our method for inpainting, outpainting, and super-resolution on the FFHQ (Karras et al., 2019) dataset, using a pretrained model by Chung et al. (2023). We implement DDSMC in the codebase of DCPS, and follow their protocol of using 100 images from the validation set and compute LPIPS (Zhang et al., 2018) as a quantitative metric. The results can be found in Table 3, in addition to numbers for DDRM, DCPS, DAPS, and MCGDiff. We used 5 particles for our method, and when using the PF-ODE as reconstruction, we used 5 ODE steps. Further implementation details are available in Appendix F.2. It should be noted that LPIPS measures perceptual similarity between the sampled image and the ground truth, which is not the same as a measurement of how well the method samples from the true posterior. Specifically, it does not say anything about diversity of samples or how well the model captures the posterior uncertainty. Nevertheless, the numbers indicate that we perform on par with previous methods. Notably, MCGDiff, which is also an SMC method and have the same asymptotic guarantees in terms of posterior sampling, performs similar or worse to DDSMC.\nInspecting the generated images, we can see a visible effect when altering the reconstruction function and \u03b7, see Figure 3 and more examples in Appendix F.2. It seems like increasing \u03b7 and/or using the PF-ODE as a reconstruction function adds more details to the image. With the GMM experiments in mind, where we saw that lower \u03b7 and using Tweedie's formula as reconstruction function made samples more concentrated around the modes, it can be argued that there is a similar effect here: using Tweedie's formula and lower \u03b7 lead to sampled images closer to a \"mode\" of images, meaning details are averaged out. On the other hand, changing to ODE-reconstruction and increasing \u03b7 further away from the mode, which corresponds to"}, {"title": "Image Restoration", "content": "Discrete Data As a proof of concept of our discrete algorithm D3SMC (see detailed description of the algorithm in Appendix E), we try denoising on the binary MNIST dataset (i.e., each pixel is either 0 or 1), cropped to 24\u00d724 pixels to remove padding. As a backbone neural network, we used a U-Net (Ronneberger et al., 2015) trained with cross-entropy loss. We use a measurement model $y = xQ_y$ with $Q_y = (1 - \\beta_y)I + \\beta_y \\mathbf{1}\\mathbf{1}^T/d$ and $B_y = 0.6$, i.e., for the binary case, this means that the observed pixel has the same value as the original image with probability 0.7, and changed with probability 0.3. We present qualitative results for running D3SMC with N = 5 particles in Figure 4, and more qualitative results can be found in Appendix F.3. While the digits are often recovered, there are cases when they are not (e.g., a 4 becoming a 9, and a 9 becoming a 7). However, looking at multiple draws in the appendix, we can see how the model in such cases can sample different digits, suggesting a multi-modal nature of the posterior."}, {"title": "Discrete Data", "content": "In this paper, we have designed an SMC algorithm, DDSMC, for posterior sampling with diffusion priors which we also extended to discrete data. The method is based on decoupled diffusion, which we generalize by introducing a hyperparameter that allows bridging between full decoupling and standard diffusion (no decoupling). We demonstrate the superior performance of DDSMC compared to the state-of-the-art on a synthetic problem, which enables a quantitative evaluation of how well the different methods approximate the true posterior. We additionally test DDSMC on image reconstruction where it performs on par with previous methods. Specifically, it performs slightly better than the alternative SMC-based method MCGDiff, while slightly underperforming compared to DCPS. However, while LPIPS indeed is a useful quantitative metric for evaluating image reconstruction, it does not inherently capture how well a method approximates the true posterior, which is the aim of our method. We found that the methods performing particularly well on image reconstruction struggle on the synthetic task, highlighting a gap between perceived image quality and their ability to approximate the true posterior."}, {"title": "Proofs", "content": "The marginal distributions $p(xt)$ and $p_\\theta(xt)$ are equal, as follows from the following proposition, inspired by Zhang et al. (2024).\nProposition A.1. Conditioning on a sample $x_t \\sim p(x_t)$ to sample $x_0 \\sim p(x_0|x_t)$, and then forgetting about $x_t$ when sampling $x_{t-1} \\sim p(x_{t-1}|x_0)$, leads to a draw from $p(x_{t-1})$.\nProof.\n$p(x_{t-1}) = \\int p(x_{t-1}|x_0) p(x_0)dx_0 =$\n(22)\n$= \\int \\int p(x_{t-1}|x_0) \\frac{p(x_0|x_t)p(x_t)}{p(x_t)}dx_tdx_0 =$\n(23)\n$= \\int \\int p(x_{t-1}|x_0)p(x_0|x_t)p(x_t)dx_0dx_t =$\n(24)\n$= \\int E_{x_0|x_t}p(x_{t-1}|x_0)p(x_t)dx_t =$\n(25)\nRemark A.2. Proposition A.1 is the same as the proposition in (Zhang et al., 2024), but without conditioning on y. Our proof can be used also for the conditional case (by only adding the corresponding conditioning on y), but is different from the one by Zhang et al. (2024) as it does not rely on the assumption of their graphical model."}, {"title": "Equality between marginals", "content": "In the DDPM (Ho et al., 2020) or Variance-preserving (VP) (Song et al., 2021b) formulation of a diffusion model, the forward process can described by\n$q(x_{t+1}|x_t) = \\mathcal{N}(x_{t+1}|\\sqrt{1 - \\beta_{t+1}}x_t, \\beta_{t+1}I)$,\n(26)\nwhich leads to\n$q(x_t|x_0) = \\mathcal{N}(x_t|\\sqrt{\\bar{a}_t}x_0, (1 - \\bar{a}_t)I)$,\n(27)\nwhere $\\bar{a}_t = \\prod_{s=1}^{t} a_s$ with $a_s = 1 - \\beta_s$.", "B DDSMC for DDPM/VP diffusion models": "Target distribution The target distribution changes as the transition $p_\\theta^\\prime(x_t|x_{t+1}) = \\int q(x_t|x_0)d_{f_\\theta(x_{t+1})}(x_0)dx_0$ changes when $q(x_t|x_0)$ changes. The new expression is now $p_\\theta(x_t|x_{t+1}) = \\mathcal{N} (\\sqrt{\\bar{a}_t}f_\\theta(x_{t+1}), (1 - \\bar{a}_t)I)$\nProposal In the DDPM formulation, we reuse the same Gaussian prior over $x_0$ given $x_t$ as before, $p_\\theta (x_0|x_t) = \\mathcal{N}(f_\\theta(x_t), p_t^2I)$ and hence the same posterior $p_\\theta(x_0|x_{t+1},y) = \\mathcal{N}(\\mu_t(x_{t+1},y), M_{t+1})$. However, we use $q(x_t|x_0) = \\mathcal{N}(x_t|\\sqrt{\\bar{a}_t}x_t, \\lambda_t^\\prime I)$ which means that the proposal becomes\n$r_t(x_t|x_{t+1},y) = \\int q(x_t|x_0)p_\\theta(x_0|x_{t+1}, y)dx_0$\n(28)\n$= \\mathcal{N}(\\sqrt{\\bar{a}_t}\\mu_t(x_{t+1}, y), \\lambda^2I + \\bar{a}_tM_{t+1}^{-1})$.\n(29)\nTo match the prior in case of non-informative measurements, we set $\\lambda^2 = 1 - \\bar{a}_t - \\bar{a}_tp_{t+1}^2 = 1 - \\bar{a}_t(1 + p_{t+1}^2)$."}, {"title": "Target distribution", "content": "In this section, we write down the main components in an SMC algorithm, the target distributions and proposals, for Twisted Diffusion Sampler (TDS) (Wu et al., 2023) and Monte Carlo Guided Diffusion (MCGDiff) (Cardoso et al., 2024),", "B.1 Target Distribution": "TDS approximates the intractable likelihood $p(y|x_t)$ by $p(y|x_t) := p(y|x_0 = f_\\theta(x_t))$. The intermediate target distributions for TDS are hence\n$\\gamma^{TDS}(x_{t:T}) = \\hat{p}(y|x_t)p(x_T) \\prod_{s=t}^{T-1} p_\\theta(x_s|x_{s+1})$,\n(30)\nwhere\n$p_\\theta(x_s|x_{s+1}) = \\mathcal{N} (x_s|x_{s+1} + \\beta_{s+1}s_\\theta(x_{s+1}, s + 1), \\beta_{s+1}^2I)$.\n(31)\n$= \\mathcal{N} (x_s|\\frac{1 - \\beta_{s+1}}{\\sigma_{s+1}^2}x_{s+1} + \\frac{\\beta_{s+1}}{\\sigma_{s+1}^2}f_\\theta(x_{s+1}), \\beta_{t+1}^2)$,", "3.1 Target Distributions": "(32)\nProposal In TDS, they use the proposal\n$r_t^{TDS}(x_t|x_{t+1}, y) = \\mathcal{N} (x_t|x_{t+1} + \\beta_{t+1}(s_\\theta(x_{t+1}, t + 1) + \\nabla_{x_{t+1}} \\log\\hat{p}(y|x_{t+1})), \\beta_{t+1})$\n(33)\n$= \\mathcal{N} (x_t|\\frac{1 - \\beta_{t+1}}{\\sigma_{t+1}^2}x_{t+1} + \\frac{\\beta_{t+1}}{\\sigma_{t+1}^2}f_\\theta(x_{t+1}) + \\nabla_{x_{t+1}} \\log\\hat{p}(y|x_{t+1}), \\beta_{t+1})$,", "B.2 Proposal": "(34)\nwhere again the last equality is from rewriting the score according to Tweedie's formula. This proposal is reminiscent of classifier guidance (Dhariwal and Nichol, 2021), where the unconditional score is combined with the gradient of some log likelihood, in this case the log likelihood $\\log \\hat{p}(y|x_{t+1})$ from the target distribution. As this likelihood relies on the reconstruction $f_\\theta(x_{t+1})$, computing the gradient of $\\log \\hat{p}(y|x_{t+1})$ with respect to $x_{t+1}$ means differentiating through the reconstruction, which could be computationally very expensive. On the other hand, this proposal is not limited to the linear-Gaussian case, but works with any differentiable $\\hat{p}(y|x_{t+1})$.", "C Comparison with TDS and MCGDiff": "MCGDiff relies on the DDPM or Variance-preserving formulation of diffusion models when describing their method, and we will use it here. To discuss MCGDiff, we will work under their initial premises that y ="}]}