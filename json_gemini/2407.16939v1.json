{"title": "Early screening of potential breakthrough technologies with\nenhanced interpretability: A patent-specific hierarchical attention\nnetwork model", "authors": ["Jaewoong Choi", "Janghyeok Yoon", "Changyong Lee"], "abstract": "Despite the usefulness of machine learning approaches for the early screening of potential\nbreakthrough technologies, their practicality is often hindered by opaque models. To address this, we\npropose an interpretable machine learning approach to predicting future citation counts from patent\ntexts using a patent-specific hierarchical attention network (PatentHAN) model. Central to this\napproach are (1) a patent-specific pre-trained language model, capturing the meanings of technical\nwords in patent claims, (2) a hierarchical network structure, enabling detailed analysis at the claim\nlevel, and (3) a claim-wise self-attention mechanism, revealing pivotal claims during the screening\nprocess. A case study of 35,376 pharmaceutical patents demonstrates the effectiveness of our\napproach in early screening of potential breakthrough technologies while ensuring interpretability.\nFurthermore, we conduct additional analyses using different language models and claim types to\nexamine the robustness of the approach. It is expected that the proposed approach will enhance\nexpert-machine collaboration in identifying breakthrough technologies, providing new insight derived\nfrom text mining into technological value.", "sections": [{"title": "1. Introduction", "content": "Breakthrough technologies have received significant attention from both industry and academia as\nkey enablers of sustainable growth and competitive edge. Prior studies have presented a range of\napproaches, from qualitative methods such as Delphi and SWOT to quantitative models (e.g.,\nstochastic models and machine learning models), utilizing diverse data sources such as experts'\nopinions, patents, scientific publications, and technology news and blogs (Lee, 2021). Among others,\nmachine learning (ML) models integrated with patent databases are acknowledged for their\neffectiveness in identifying potential breakthrough technologies. This is attributed to the\ncomprehensive coverage and structured information of patent databases, coupled with the predictive\ncapabilities of ML models to analyze large datasets and uncover novel insights (Kim et al., 2019; Lee\net al., 2018). However, the practicality of this approach is often hindered by the opacity of ML models\n(Kim et al., 2022), particularly when evaluating early-stage technological ideas (Hong et al., 2022).\nPrevious patent-based ML approaches to identifying potential breakthrough technologies can\nbe classified into two categories according to the input data used: bibliometric and textual\ninformation. The former employs ML models to associate ex-ante patent quality indicators as inputs\nand patent forward citations as outputs, to predict future citation counts of relevant patents as a proxy\nof technological value. Although this approach has further been extended to interpretable models and\nproven useful in various contexts (Kim et al., 2022), it can only be performed at later stages of\ntechnology development because it requires patent information such as patent family and\nclassification codes available at the time or after a patent is granted. The latter leverages ML models\nto examine the relationships between textual information of patents as inputs and patent forward\ncitations as outputs. This approach has proven effective in evaluating early-stage technological ideas,\nwhere ex-ante patent quality indicators are unavailable but technical descriptions of ideas exist (Hong\net al., 2022; Woo et al., 2019). However, this approach relies on black-box models, underscoring the\nneed to develop interpretable models that enable experts to grasp the underlying mechanisms of\nprediction processes.\nDeveloping interpretable ML models with textual information of patents presents several\nchallenges. Text data is inherently high-dimensional and sparse, typically represented by a large\nnumber of features (e.g., words and tokens). Although text data can be transformed into dense\nembeddings using pre-trained language models (PLMs) such as word2vec and BERT, which capture\nrich linguistic patterns and meanings, interpreting the specific dimensions or components within dense\nembeddings can be non-trivial, as they often represent latent features derived from large amounts of\ntextual data. Moreover, their high dimensionality and complex relationships make it challenging to\ninterpret how individual features contribute to machine predictions. Furthermore, the technical content"}, {"title": "3. Methodology", "content": "The overall process of the proposed approach is shown in Fig. 1. The proposed approach is designed\nto be implemented in four steps after patent database construction: (1) data collection and\npreprocessing; (2) estimation of the technological value of patents; (3) performance evaluation, and\n(4) prediction result interpretation."}, {"title": "3.1. Data collection and preprocessing", "content": "Once a target technology domain is determined, relevant patents can be collected from the USPTO\ndatabase. The raw patent documents are usually provided in HTML or XML formats, containing a\nmixture of structured and unstructured data. The patents are parsed by the type of information such as\npatent number, class, or text, and then stored in a relational patent database for efficient management.\nThe database should have three key categories of patent information. First, basic information\ncomprises bibliographic information such as registration date and classification code, which can be\nused to define the scope and period of analysis (Choi and Yoon, 2022). Second, textual information\nincludes patent titles, abstracts, and claims, which describe the technical contents of patents. We focus\nprimarily on independent claims representing key technical elements of each patent. Lastly,\ntechnological value information refers to citation information (Hong et al., 2022; Lee et al., 2018),\npatent maintenance (Choi et al., 2020), or technology transfer (Kim et al., 2022), while their\nimplications are different. In this study, forward citation information is utilized as a proxy for the\npotential of breakthrough technologies. Patent-to-patent citation relationships and citation dates are\ncollected to estimate the number of forward citations over different observation periods."}, {"title": "3.2. Estimation of the technological value of patents.", "content": "This step aims to capture the complex meaning of technical descriptions as well as the nonlinear\nrelationships between input and output indicators. To this end, inspired by a hierarchical attention\nnetwork model (Yang et al., 2016), we develop a PatentHAN model by using PatentBERT and a\ntransformer encoder. As shown in Fig.2., the PatentHAN model has a hierarchical structure; (1)\nBeginning from the token-level encoder, words of patent claims are transformed into dense\nembedding vectors using PatentBERT, generating individual claim vectors. (2) In the claim-level\nencoder, the interactive relationships between claim vectors are captured using a claim-wise self-\nattention mechanism, generating a patent representation vector. (3) In the prediction layer, the patent\nvector is forwarded to the feed-forward neural network layer for patent class prediction. Detailed\nimplementations of each component are as follows.\nThis component generates dense embedding vectors, considering the complex meaning of\npatent texts. Specifically, token-level encoders recognize tokens from patent claims, generate their\nembedding vectors using PatentBERT, and provide a claim vector by averaging its constituent token\nvectors. Here, PatentBERT, distinguished for its advanced performance across various patent natural\nlanguage processing tasks, is employed as the main PLM of our token encoder. Its exceptional\ncomprehension of patent text, encompassing semantic and syntactic relationships between words,\nstems from fine-tuning the BERT model on large-scale patent datasets. Moreover, given that the token\nrecognition ability is depending on the training corpus, PatentBERT is indispensable for precise word\nidentification in patent texts. The resulting output from this component is detailed as follows:\n$P = (E_1, E_2, ..., E_m)$\nwhere E\u00a1 represents the ith claim vector, with dimension of de, obtained by averaging token\nClaim-level encoder: The claim-level encoder extracts claim structure information to generate\nan intermediate patent representation, S, using claim vectors, P. As shown in Fig. 3, this step utilizes\nthe stacked claim encoders and a feedforward neural network with tanh activation (Devlin et al., 2018;\nVaswani et al., 2017). In each claim encoder, the single-head self-attention mechanism is employed\nand the output is calculated as Equation 2 and 3. Here, claim-wise attention mechanism enables the\nmodel to concentrate on the most semantically significant claims, by assigning different weights to\neach claim. Once trained, the attention mechanism is already computed during the model's training\nand inference processes; no additional steps are required to interpret machine predictions.\n$Att(P) = LayerNorm(P + SingleHead(P))$\n$SingleHead(P) = head \u00d7 W^o$\nwhere LayerNorm denotes the process of layer normalization. $W^o \u2208 R^{d_e\u00d7d_e}$ signifies the weight\nmatrix responsible for dimension transformation. The value of the head is calculated as follows:\n$head = Attention(Q, K, V) = Softmax(Q \u00d7 K^T /\u221a{d_e}) \u00d7 V$\n$Q = P \u00d7 W^Q, K = P \u00d7 W^K,V = P \u00d7 W^V$\nHere, $W^Q$, $W^K$, and $W^V$ represent the query, key, and vector weight matrices of the single\nhead, respectively. The SoftMax function denotes an m\u00d7m matrix, where the entry at the ath row and\njth columns refers to the attention weight that the ath claim pays to the jth claim. In this context, V holds\nthe claim information for the subsequent layers and the Softmax layer serves as a gate, which impedes\nclaims with low attention scores from propagating their information extensively. Finally, the output of\nthe attention layer is fed into a feed-forward neural network with the residual mechanism and layer\nnormalization as Equation 6.\n$P' = LayerNorm (Att(P) + Gelu(Att(P) \u00d7 W^r) \u00d7 W^s$\nHere, the matrix $W^r$ serves as a transformation weight matrix, altering the dimensionality of\nAtt(P), whereas $W^s$ is a weight matrix incorporating dropout to revert the raw dimensionality.\nSubsequently, $P'$ is fed into multiple claim encoders to construct the matrix Z, utilized for computing\nthe intermediate patent representation S in Equation 7. After mean pooling, Z is multiplied by Wt and\nfed into the hyperbolic tangent function, commonly employed in neural networks for nonlinear\ntransformations.\n$S = Tanh(Avg(Z) \u00d7 W^t)$\nPrediction layer: Finally, the prediction layer is added to the claim-level encoder to determine\nwhether the given patent is a potential breakthrough technology or marginal technology. The output of\nthe claim-level encoder (S) is utilized to calculate the raw score for each class, as denoted in Equation\n8, where the scores for potential breakthrough technologies ($t_{PBT}$) and marginal technologies ($t_{MT}$)\nare fed into a SoftMax for computing loss.\n$[t_{PBT}, t_{MT}] = S\u00d7W$"}, {"title": "3.3. Evaluation of model performance", "content": "The performance of the proposed approach and its ability to classify patents according to their\nexpected technological value classes are carefully evaluated for multiple metrics. Accuracy is used to\nreflect the overall correctness of a model's predictions, essentially quantifying the proportion of\ncorrectly classified instances (Equation 9). Precision refers to the ratio of the correctly labeled positive\nexamples to the total examples labeled as positive (Equation 10), whereas recall represents the ratio of\nthe correctly labeled positive examples to the total number of positive examples (Equation 11). In this\ncase, precision pertains to the proportion of predictions that are correctly identified as potential\nbreakthrough technologies out of all the predictions labeled as potential breakthrough technologies.\n$ACCURACY =\n\\frac{(TP+TN)}{(TP+TN+FP+FN)}$\n$PRECISION =\n\\frac{TP}{TP+FP}$\n$RECALL =\n\\frac{TP}{TP+FN}$\nwhere, true positive (TP) represents examples that are correctly identified as potential breakthrough\ntechnologies, whereas false positive (FP) refers to examples that are incorrectly labeled as potential\nbreakthrough technologies.\nThese metrics indicate how well a model performs in terms of correct predictions; however, it\nmay not be the most suitable metric in cases of imbalanced datasets. For cases of imbalanced datasets,\nwhere the number of patents corresponding to potential breakthrough technologies is less than that of\nmarginal technologies, other metrics such as MCC can be effective (Chicco and Jurman, 2020). MCC\nis a well-balanced metric that assesses the classifier performance by considering the TP, TN, FP, and\nFN (Equation 12). Its value ranges from \u20131 to 1, with '1' indicating perfect classification, '0'\nindicating no better than random classification, and '-1' indicating complete disagreement between\npredicted and actual values.\n$MCC =\n\\frac{(TP \u00d7 TN) \u2013 (FP \u00d7 FN)}{\\sqrt{(TP + FP)(TP + FN)(TN + FP)(TN + FN)}}$"}, {"title": "3.4. Interpretation of model predictions", "content": "Once the best-performing model is developed, the predictions for a set of patents can be\nobtained. For instance, if a patent is predicted as a potential breakthrough technology, it is expected to\nhave the potential for ground-breaking innovation in the future. Meanwhile, patents that are predicted\nas marginal technologies are likely to have less technological impact on follow-up patents. In addition\nto the predictions, we can identify the relative importance of each claim for the prediction in a\nquantitative manner, using claim-wise attention scores. As indicated in Equation 4, SoftMax serves as\nthe attention weight matrix utilized to compute the weight of each claim for an input patent and we"}, {"title": "4. Empirical analysis and results", "content": "We conducted a case study of pharmaceutical technology for several compelling reasons. Firstly, in\nthe pharmaceutical industry, an individual patent frequently serves as a direct representation of a\nproduct, thus establishing a strong connection between the technological merits of the patent and its\ncommercial value (Chen and Chang, 2010). Secondly, given the relative ease with which\nmanufacturing processes can be replicated in this field and the potential for replication with only a\nfraction of the original investment, the importance of rigorous patent management is pronounced\ncompared to other sectors (Chaudhuri, 2005). Finally, there exists a demand in practice for objective\nand reliable information based on scientific methods to forecast the prospects of pharmaceutical\ntechnology development, due to the substantial investment and high risks of R&D activities. Hence,\nfailure in decision-making can result in significant financial losses for companies, and unfortunately,\nsuch failures are not uncommon (DiMasi et al., 2003). In this context, the proposed method can\neffectively narrow down the pool of potential breakthrough technologies by filtering marginal\ntechnologies in the early stages of technology development."}, {"title": "4.2. PatentHAN approach to early screening potential breakthrough technologies", "content": "A total of 35,376 patents in the field of pharmaceutical technology were obtained from the USPTO for\na reference period spanning 10 years (2000\u20132009). Information including the patent numbers,\npublication years, patent claims, and count of forward citations were extracted from these patents and\nsubsequently stored in our relational patent database. Technological value classes were defined based\non the count of forward citations received within 3, 5, and 10 years after patent registration (Table 2).\nFollowing previous studies (Hong et al., 2022; Woo et al., 2019), the patents that received a large\nnumber of forward citations within the specific period, essentially exceeding the top 10%, were\ncategorized as potential breakthrough technologies. The results of labeling is not reported here in its\nentirety owing to lack of space, but part of them is shown in Table 3.\nFor the pre-processing of independent claims, first, their stop words and claim index were\nremoved, the text was lowered, and accent representations were removed. Next, the maximum length\nof tokens for each claim was set as 512. Note that the maximum number of claims should be\ndetermined in structuring each patent into a unified form for computational complexity and\ngeneralized performance. We set it as 18 according to the top 20% of the number of independent\nclaims, thus implying that most of the patents had less than 18 independent claims. Patents with\nclaims fewer than this value were processed with padding, whereas patents with more claims were cut"}, {"title": "4.2.2. Estimation of the technological value of patents", "content": "First of all, it is noteworthy that the hyperparameters, such as learning rate and batch size, should be\ncarefully determined. This exhaustive task often relies on the size and the nature of the data set.\nAlthough models with complex structures and numerous parameters may exhibit high performance in\ntypical tasks such as natural language processing, computer vision, or speech recognition, these tasks\ncan lead to overfitting issues, ultimately resulting in poor generalized performance. We tested, several\nlearning rates (1e-4, 5e-5, 3e-5, 2e-5, 1e-5, 1e-6) and batch sizes (64, 128, 256, 512), and the optimal\nlearning rate and batch size were determined as 2e-5 and 512, respectively. The epochs were set to\n100, and the early stopping technique was adopted to avoid overfitting and enable efficient learning.\nFor the development of the PatentHAN model, we used PyTorch and HuggingFace packages and set\nthe number of claim encoders to 4. For training details, the cross-entropy loss function and Adam\noptimizer were employed during the training process. Under this setting, our models were trained to\nclassify patents according to the expected forward citation counts over the next 3, 5, and 10 years\nimmediately after patent registration. That is, patents were divided into potential breakthrough\ntechnology or marginal technology groups based on citation counts, and then random sampling was\napplied within each group with a sampling rate proportional to the population of each group. Here, we\nused a stratified 5-fold cross-validation technique to accurately evaluate the imbalanced datasets.\nAlso, 80% of the total patents were used as the training dataset, while the remaining 20% were used\nas the test dataset."}, {"title": "4.2.3. Evaluation of model performance", "content": "The validity of the models was investigated based on their ability to screen potential breakthrough\ntechnologies (Table 5). We employed a stratified five-fold cross-validation technique to accurately\nassess the imbalance datasets in our case study. The accuracies for the short-term, mid-term, and long-\nterm periods were 0.895, 0.917, and 0.886, respectively. In addition, we computed the precision,\nrecall, F1-score, and MCC of each class by forecasting horizon. Overall, it is observed that the\nproposed approach is effective in filtering patents with marginal technological values, thereby\nreducing the set of potential breakthrough technologies. The obtained recall values indicated that our\nmodel successfully identified a significant portion of marginal technologies across all forecast\nhorizons. The proposed approach provided somewhat conservative predictions for potential\nbreakthrough technologies. The performance in this category was relatively low, but the F1 scores and\nMCC indicated that the proposed approach is more effective compared with random classifications.\nThe precision values for the short-term, mid-term, and long-term forecasts of breakthrough\ntechnologies were approximately 46.3%, 50.6%, and 53.8%, whereas the recall values were\napproximately 16.8%, 14.6%, and 22.1%, respectively."}, {"title": "4.2.4. Interpretation of model predictions", "content": "In addition to the predictions regarding potential breakthrough technologies or marginal technologies,\na claim-wise attention score was calculated for each prediction (Fig. 4.). Examining independent\nclaims with comparatively high attention scores elucidates the reasons behind the predictions, whether\nthe given patent is breakthrough technologies or not. For instance, as shown on the left side of Fig. 4.,"}, {"title": "5. Discussion", "content": "The outcomes and implications of the proposed approach may vary according to the analysis context.\nIn this regard, we performed further experiments to examine the effects of different encoding layers or\nclaim types, which are adaptable to the given context. First, we examined the impact of using other\nPLMs as encoding layers in the proposed approach. Specifically, we employed PLMs such as BERT\n(Devlin et al., 2018), SciBERT (Beltagy et al., 2019), BioBERT (Lee et al., 2020), and PubMedBERT\n(Gu et al., 2021), of which training datasets are different. Table 6 shows the robust performance of the\nproposed approach using other PLMs. It was observed that SciBERT is the most effective for the\nthree forecasting tasks, exhibiting slightly improved performance compared to the baseline model.\nThis is because the target domain is the pharmaceutical field, where understanding the given textual\ninformation requires scientific knowledge, even though the data type is patent. Therefore, when using\nthe proposed approach in practice, it is important to test various PLMs trained on data types or\ndomains similar to the target domain.\nSecondly, we examined the effects of incorporating dependent claims as additional input data.\nPatents consist of two types of claims: independent claims and dependent claims. An independent\nclaim outlines the fundamental technical aspects of an invention and establishes its scope, while a\ndependent claim elaborates on specific technical details, relying on an independent claim for context.\nTable 7 provides the performance of the proposed method when only independent claims are used\ncompared to when both independent and dependent claims are utilized. It was observed that utilizing\nonly independent claims as input yields higher performance in terms of accuracy and MCC, compared\nto incorporating both types of claims. This is because independent claims convey more pivotal\ninformation, while dependent claims provide specific and verbose details. Therefore, we can conclude\nthat the existence of pivotal technical elements or functions may be crucial in determining the\npotential of breakthrough technologies."}, {"title": "5.2. Implications for academia and practice", "content": "The case study showed that the proposed approach is effective for early screening potential\nbreakthrough technologies from patent text, providing enhanced interpretability. Therefore, the\nproposed approach is expected to have significant implications for both theory and practice. From an\nacademic perspective, this study contributes to technology innovation research by suggesting an\ninterpretable ML method for early screening of potential breakthrough technologies. This is made\nthrough the development of PatentHAN, enabling the identification of pivotal claims in the screening\nprocess. Unlike previous methods based on opaque ML models, the proposed approach incorporates\nthe claim-wise attention scores, thereby enhancing experts' understanding of the model predictions.\nAlthough the focus of this study is an early screening of potential breakthrough technologies, the\nproposed approach can be applied to solve other research questions where the comprehension and\ninterpretation of technical contents are important. These may include but are not limited to technology\nvaluation (Kim et al., 2023), technology opportunity analysis (Choi et al., 2023; Seol et al., 2023),\ninventor scouting (Chung et al., 2021) and patent-trademark linking (Ko et al., 2020). From a practical\nperspective, the proposed approach is expected to advance the timing of screening potential\nbreakthrough technologies, as it requires only textual descriptions of technologies as input. Therefore,\ngiven sufficient technical descriptions, proof-of-concept or prototype-stage technologies can be\nevaluated with the proposed approach. The proposed approach and interpretable results can\nsignificantly aid practitioners in making informed decisions regarding breakthrough technologies\nwhile facilitating effective communications between stakeholders."}, {"title": "6. Conclusion", "content": "This study has proposed an interpretable ML approach for early screening of potential breakthrough\ntechnologies. Central to this approach is the development of a PatentHAN model, which provides\ninterpretable results in predicting the number of forward citations from patent text. The core\ncomponents of this model include: (1) PatentBERT is utilized as text encoding layer to covert patent\nclaim texts into dense embedding vectors that capture their intricate semantic meanings; (2) a\nhierarchical network structure, where individual claim vectors are organized to create a\ncomprehensive patent representation vector, is designed to facilitate detailed claim-level analysis; and\n(3) a claim-wise attention mechanism, which enables the model to concentrate on the most\nsemantically significant parts by assigning weights to each claim, is employed to effectively interpret\nmachine predictions by identifying pivotal claims during the screening process. The case study of\npharmaceutical technology confirmed that the proposed approach is effective in screening potential\nbreakthrough technologies and claim-wise attention scores support machine-experts collaborations by\nrevealing the most pivotal technical elements from patent texts.\nDespite its effectiveness, this study is subject to several limitations. First, the proposed\napproach utilizes the number of forward citations as a single proxy of technological value. However,\nincorporating other indicators such as technology transfer and patent renewal data is required in future\nworks, for comprehensive evaluation of potential breakthrough technologies (Choi et al., 2020; Kim\net al., 2022; Ko et al., 2019). Second, the screening performance can be further improved with the\nlatest models. Although we used an appropriate PLM for patent text processing, the latest large\nlanguage models such as PaLM2 (Anil et al., 2023), and GPT-4 (Achiam et al., 2023) could provide\nmore accurate predictions. Third, quantitative indicators on the market, technology or regulation\nfactors or image data of patents can be used as additional input data (Choi et al., 2022; Choi et al.,\n2021; Jee et al., 2022), and the development of multi-modal models could potentially enhance the\naccuracy and reliability (Chung and Sohn, 2020). Lastly, this study solely focused on a single case\nstudy on pharmaceutical technology. To establish the external validity of our approach, further testing\nshould be performed on technologies across diverse domains. Nonetheless, we argue that the proposed\napproach and interpretable results make significant contributions to both academia and practice."}]}