{"title": "Early screening of potential breakthrough technologies with enhanced interpretability: A patent-specific hierarchical attention network model", "authors": ["Jaewoong Choi", "Janghyeok Yoon", "Changyong Lee"], "abstract": "Despite the usefulness of machine learning approaches for the early screening of potential breakthrough technologies, their practicality is often hindered by opaque models. To address this, we propose an interpretable machine learning approach to predicting future citation counts from patent texts using a patent-specific hierarchical attention network (PatentHAN) model. Central to this approach are (1) a patent-specific pre-trained language model, capturing the meanings of technical words in patent claims, (2) a hierarchical network structure, enabling detailed analysis at the claim level, and (3) a claim-wise self-attention mechanism, revealing pivotal claims during the screening process. A case study of 35,376 pharmaceutical patents demonstrates the effectiveness of our approach in early screening of potential breakthrough technologies while ensuring interpretability. Furthermore, we conduct additional analyses using different language models and claim types to examine the robustness of the approach. It is expected that the proposed approach will enhance expert-machine collaboration in identifying breakthrough technologies, providing new insight derived from text mining into technological value.", "sections": [{"title": "1. Introduction", "content": "Breakthrough technologies have received significant attention from both industry and academia as key enablers of sustainable growth and competitive edge. Prior studies have presented a range of approaches, from qualitative methods such as Delphi and SWOT to quantitative models (e.g., stochastic models and machine learning models), utilizing diverse data sources such as experts' opinions, patents, scientific publications, and technology news and blogs (Lee, 2021). Among others, machine learning (ML) models integrated with patent databases are acknowledged for their effectiveness in identifying potential breakthrough technologies. This is attributed to the comprehensive coverage and structured information of patent databases, coupled with the predictive capabilities of ML models to analyze large datasets and uncover novel insights (Kim et al., 2019; Lee et al., 2018). However, the practicality of this approach is often hindered by the opacity of ML models (Kim et al., 2022), particularly when evaluating early-stage technological ideas (Hong et al., 2022).\nPrevious patent-based ML approaches to identifying potential breakthrough technologies can be classified into two categories according to the input data used: bibliometric and textual information. The former employs ML models to associate ex-ante patent quality indicators as inputs and patent forward citations as outputs, to predict future citation counts of relevant patents as a proxy of technological value. Although this approach has further been extended to interpretable models and proven useful in various contexts (Kim et al., 2022), it can only be performed at later stages of technology development because it requires patent information such as patent family and classification codes available at the time or after a patent is granted. The latter leverages ML models to examine the relationships between textual information of patents as inputs and patent forward citations as outputs. This approach has proven effective in evaluating early-stage technological ideas, where ex-ante patent quality indicators are unavailable but technical descriptions of ideas exist (Hong et al., 2022; Woo et al., 2019). However, this approach relies on black-box models, underscoring the need to develop interpretable models that enable experts to grasp the underlying mechanisms of prediction processes.\nDeveloping interpretable ML models with textual information of patents presents several challenges. Text data is inherently high-dimensional and sparse, typically represented by a large number of features (e.g., words and tokens). Although text data can be transformed into dense embeddings using pre-trained language models (PLMs) such as word2vec and BERT, which capture rich linguistic patterns and meanings, interpreting the specific dimensions or components within dense embeddings can be non-trivial, as they often represent latent features derived from large amounts of textual data. Moreover, their high dimensionality and complex relationships make it challenging to interpret how individual features contribute to machine predictions. Furthermore, the technical content"}, {"title": "2. Background", "content": "Breakthrough technologies have been analyzed with patent citation information, as it signifies the impact of patents on follow-up technologies. In this regard, many researchers have suggested patent-based approaches to estimate the potential of breakthrough technologies by predicting the number of forward citations. Initially, there have been scientific methods such as curve fitting methods and stochastic processes to provide forward-looking insights on potential breakthrough technologies, by estimating future citation count of relevant patents. Shin et al. (2013) adopted curve-fitting techniques to estimate both the expected number of patent citations and its variance, as a proxy for assessing the future returns and risks associated with technology of interest. Some researchers introduced a stochastic patent citation analysis method such as Pareto, Negative binomial distribution model, or Hawkes process to estimate the future impacts of a period of interest (Jang et al., 2017; Lee et al., 2012). Lee et al. (2016) and Lee et al. (2017) suggested a stochastic technology life cycle analysis, utilizing hidden Markov models and time-series patent indicators, to study the technological progression over its life cycle. Although previous studies have been valuable in providing quantitative outcomes and scientific methods regarding breakthrough technologies, their applicability is limited when relevant technologies are at the early stages of technology development without sufficient historical citation data (Lee et al., 2018).\nAs a remedy, several researchers have developed ML models to identify potential breakthrough technologies at the early stages of development by predicting the future values of individual patents. For instance, Lee et al. (2018) utilized artificial neural networks to capture the nonlinear relationships between technological values and ex-ante patent indicators that can be determined immediately after relevant patents are issued. Specifically, they employed 18 patent indicators representing technological characteristics \u2013 such as novelty, scientific intensity, growth speed, technological scope, and patent development efforts and capabilities as input variables. However, these approaches, which rely on patent information as their inputs, are impractical for screening potential breakthrough technologies in the early stages of technology development, especially when technologies are at the proof-of-concept or prototype stage. Such methods are typically applied after relevant technologies have been patented, as they rely on information available upon patent registration, such as patent families or scientific references.\nIn this context, recent studies have aimed to accelerate the screening of potential breakthrough technologies by using patent text as inputs (Hong et al., 2022). These approaches have"}, {"title": "3. Methodology", "content": "The overall process of the proposed approach is shown in Fig. 1. The proposed approach is designed to be implemented in four steps after patent database construction: (1) data collection and preprocessing; (2) estimation of the technological value of patents; (3) performance evaluation, and (4) prediction result interpretation."}, {"title": "3.1. Data collection and preprocessing", "content": "Once a target technology domain is determined, relevant patents can be collected from the USPTO database. The raw patent documents are usually provided in HTML or XML formats, containing a mixture of structured and unstructured data. The patents are parsed by the type of information such as patent number, class, or text, and then stored in a relational patent database for efficient management. The database should have three key categories of patent information. First, basic information comprises bibliographic information such as registration date and classification code, which can be used to define the scope and period of analysis (Choi and Yoon, 2022). Second, textual information includes patent titles, abstracts, and claims, which describe the technical contents of patents. We focus primarily on independent claims representing key technical elements of each patent. Lastly, technological value information refers to citation information (Hong et al., 2022; Lee et al., 2018), patent maintenance (Choi et al., 2020), or technology transfer (Kim et al., 2022), while their implications are different. In this study, forward citation information is utilized as a proxy for the potential of breakthrough technologies. Patent-to-patent citation relationships and citation dates are collected to estimate the number of forward citations over different observation periods."}, {"title": "3.2. Estimation of the technological value of patents.", "content": "This step aims to capture the complex meaning of technical descriptions as well as the nonlinear relationships between input and output indicators. To this end, inspired by a hierarchical attention network model (Yang et al., 2016), we develop a PatentHAN model by using PatentBERT and a transformer encoder. As shown in Fig.2., the PatentHAN model has a hierarchical structure; (1) Beginning from the token-level encoder, words of patent claims are transformed into dense embedding vectors using PatentBERT, generating individual claim vectors. (2) In the claim-level encoder, the interactive relationships between claim vectors are captured using a claim-wise self-attention mechanism, generating a patent representation vector. (3) In the prediction layer, the patent vector is forwarded to the feed-forward neural network layer for patent class prediction. Detailed implementations of each component are as follows.\nP = (E_1, E_2, ..., E_m)\nwhere E\u00a1 represents the ith claim vector, with dimension of de, obtained by averaging token"}, {"title": "3.3. Evaluation of model performance", "content": "The performance of the proposed approach and its ability to classify patents according to their expected technological value classes are carefully evaluated for multiple metrics. Accuracy is used to reflect the overall correctness of a model's predictions, essentially quantifying the proportion of correctly classified instances (Equation 9). Precision refers to the ratio of the correctly labeled positive examples to the total examples labeled as positive (Equation 10), whereas recall represents the ratio of the correctly labeled positive examples to the total number of positive examples (Equation 11). In this case, precision pertains to the proportion of predictions that are correctly identified as potential breakthrough technologies out of all the predictions labeled as potential breakthrough technologies."}, {"title": "3.4. Interpretation of model predictions", "content": "Once the best-performing model is developed, the predictions for a set of patents can be obtained. For instance, if a patent is predicted as a potential breakthrough technology, it is expected to have the potential for ground-breaking innovation in the future. Meanwhile, patents that are predicted as marginal technologies are likely to have less technological impact on follow-up patents. In addition to the predictions, we can identify the relative importance of each claim for the prediction in a quantitative manner, using claim-wise attention scores. As indicated in Equation 4, SoftMax serves as the attention weight matrix utilized to compute the weight of each claim for an input patent and we use the matrix of the last claim encoder for interpretation. Specifically, during training, the claim-wise attention weights are updated through the backpropagation of errors. Thus, the model learns to assign higher attention weights to claims that contribute more to the final prediction, consequently improving the model's ability to capture pivotal claims of each patent."}, {"title": "4. Empirical analysis and results", "content": "We conducted a case study of pharmaceutical technology for several compelling reasons. Firstly, in the pharmaceutical industry, an individual patent frequently serves as a direct representation of a product, thus establishing a strong connection between the technological merits of the patent and its commercial value (Chen and Chang, 2010). Secondly, given the relative ease with which manufacturing processes can be replicated in this field and the potential for replication with only a fraction of the original investment, the importance of rigorous patent management is pronounced compared to other sectors (Chaudhuri, 2005). Finally, there exists a demand in practice for objective and reliable information based on scientific methods to forecast the prospects of pharmaceutical technology development, due to the substantial investment and high risks of R&D activities. Hence, failure in decision-making can result in significant financial losses for companies, and unfortunately, such failures are not uncommon (DiMasi et al., 2003). In this context, the proposed method can effectively narrow down the pool of potential breakthrough technologies by filtering marginal technologies in the early stages of technology development."}, {"title": "4.2. PatentHAN approach to early screening potential breakthrough technologies", "content": "A total of 35,376 patents in the field of pharmaceutical technology were obtained from the USPTO for a reference period spanning 10 years (2000\u20132009). Information including the patent numbers, publication years, patent claims, and count of forward citations were extracted from these patents and subsequently stored in our relational patent database. Technological value classes were defined based on the count of forward citations received within 3, 5, and 10 years after patent registration (Table 2). Following previous studies (Hong et al., 2022; Woo et al., 2019), the patents that received a large number of forward citations within the specific period, essentially exceeding the top 10%, were categorized as potential breakthrough technologies. The results of labeling is not reported here in its entirety owing to lack of space, but part of them is shown in Table 3.\nFor the pre-processing of independent claims, first, their stop words and claim index were removed, the text was lowered, and accent representations were removed. Next, the maximum length of tokens for each claim was set as 512. Note that the maximum number of claims should be determined in structuring each patent into a unified form for computational complexity and generalized performance. We set it as 18 according to the top 20% of the number of independent claims, thus implying that most of the patents had less than 18 independent claims. Patents with claims fewer than this value were processed with padding, whereas patents with more claims were cut to preserve the preceding claims in order."}, {"title": "4.2.2. Estimation of the technological value of patents", "content": "First of all, it is noteworthy that the hyperparameters, such as learning rate and batch size, should be carefully determined. This exhaustive task often relies on the size and the nature of the data set. Although models with complex structures and numerous parameters may exhibit high performance in typical tasks such as natural language processing, computer vision, or speech recognition, these tasks can lead to overfitting issues, ultimately resulting in poor generalized performance. We tested, several learning rates (1e-4, 5e-5, 3e-5, 2e-5, 1e-5, 1e-6) and batch sizes (64, 128, 256, 512), and the optimal learning rate and batch size were determined as 2e-5 and 512, respectively. The epochs were set to 100, and the early stopping technique was adopted to avoid overfitting and enable efficient learning. For the development of the PatentHAN model, we used PyTorch and HuggingFace packages and set the number of claim encoders to 4. For training details, the cross-entropy loss function and Adam optimizer were employed during the training process. Under this setting, our models were trained to classify patents according to the expected forward citation counts over the next 3, 5, and 10 years immediately after patent registration. That is, patents were divided into potential breakthrough technology or marginal technology groups based on citation counts, and then random sampling was applied within each group with a sampling rate proportional to the population of each group. Here, we used a stratified 5-fold cross-validation technique to accurately evaluate the imbalanced datasets. Also, 80% of the total patents were used as the training dataset, while the remaining 20% were used as the test dataset.\nParts of the results are given in Table 4, due to lack of space. The last three columns indicate the predicted value categories for the test dataset. Patents exhibit diverse dynamics, with many falling under the category of marginal technologies. Given that only a minority of patents receive multiple citations, while the majority remain uncited throughout their lifespan, it would be natural that most patents were predicted as marginal technologies. For instance, patent 6010682 ('Liposoluble compounds useful as magnetic resonance imaging agents') was predicted as marginal technologies for all forecasting horizons, whereas patent 7645568 (\u2018Xenograft heart valves') was identified as breakthrough technologies for all forecasting horizons. Interestingly, patents 6013628 (\u2018Method for treating conditions of the eye using polypeptides') and 7438910 (\u2018Therapeutic human anti-IL1-R1 monoclonal antibody') were initially regarded as marginal technologies for short-term forecasting but as potential breakthrough technologies for long-term forecasting, which implies that they have minimal impacts at the outset of their life cycles but gain recognition as valuable technologies after undergoing market verification processes."}, {"title": "4.2.3. Evaluation of model performance", "content": "The validity of the models was investigated based on their ability to screen potential breakthrough technologies (Table 5). We employed a stratified five-fold cross-validation technique to accurately assess the imbalance datasets in our case study. The accuracies for the short-term, mid-term, and long-term periods were 0.895, 0.917, and 0.886, respectively. In addition, we computed the precision, recall, F1-score, and MCC of each class by forecasting horizon. Overall, it is observed that the proposed approach is effective in filtering patents with marginal technological values, thereby reducing the set of potential breakthrough technologies. The obtained recall values indicated that our model successfully identified a significant portion of marginal technologies across all forecast horizons. The proposed approach provided somewhat conservative predictions for potential breakthrough technologies. The performance in this category was relatively low, but the F1 scores and MCC indicated that the proposed approach is more effective compared with random classifications. The precision values for the short-term, mid-term, and long-term forecasts of breakthrough technologies were approximately 46.3%, 50.6%, and 53.8%, whereas the recall values were approximately 16.8%, 14.6%, and 22.1%, respectively."}, {"title": "4.2.4. Interpretation of model predictions", "content": "In addition to the predictions regarding potential breakthrough technologies or marginal technologies, a claim-wise attention score was calculated for each prediction (Fig. 4.). Examining independent claims with comparatively high attention scores elucidates the reasons behind the predictions, whether the given patent is breakthrough technologies or not. For instance, as shown on the left side of Fig. 4., the patent (registration number: 6664289) was predicted as a potential breakthrough technology, its 24th claim is recognized as a pivotal claim with the highest score of 0.556. The invention pertains to an aqueous nasal solution designed for treating and preventing microbial infections and encompasses a broad-spectrum microbicide, including aqueous chlorine or bromine, hypochlorite ion, and/or chloride, bromide, or iodide ion. In this context, the 24th claim was recognized as the most pivotal, as it provides a wide spectrum of antimicrobial agents for the treatment and prevention of various microbes, which are not specified in other claims. In addition, this claim encompasses various concentrations of chemical substances, implying that the invention can be adjusted to suit specific environments or purposes. Also, by specifying concentration ranges for each chemical substance, this claim helps meet safety regulations and compliance with regulatory agencies, which plays a crucial role in verifying the safety and efficacy of the relevant product.\nOn the right side of Fig. 4, for the patent (registration number: 7588786) predicted as marginal technologies, its independent claims and corresponding attention scores are provided. The given invention pertains to a eutectic-based self-nano emulsified drug delivery system, which is primarily utilized for administering poorly water-soluble drugs to patients. This claim describes ubiquinone dissolution under 37 degrees Celsius using ubiquinone and volatile essential oils, but its broad scope may diminish patentability and value. In addition, lacking practical information for the in vivo delivery system could reduce patent utility. In summary, the flexible and extendable purpose and scope such as materials and conditions in the independent claims is observed in the patents in potential breakthrough technologies. Therefore, the provision of clear evidence or key technical elements rather than merely providing lengthy and verbose content is likely to determine the technological scope of patents and further their potential values."}, {"title": "5. Discussion", "content": "The outcomes and implications of the proposed approach may vary according to the analysis context. In this regard, we performed further experiments to examine the effects of different encoding layers or claim types, which are adaptable to the given context. First, we examined the impact of using other PLMs as encoding layers in the proposed approach. Specifically, we employed PLMs such as BERT (Devlin et al., 2018), SciBERT (Beltagy et al., 2019), BioBERT (Lee et al., 2020), and PubMedBERT (Gu et al., 2021), of which training datasets are different. Table 6 shows the robust performance of the proposed approach using other PLMs. It was observed that SciBERT is the most effective for the three forecasting tasks, exhibiting slightly improved performance compared to the baseline model. This is because the target domain is the pharmaceutical field, where understanding the given textual information requires scientific knowledge, even though the data type is patent. Therefore, when using the proposed approach in practice, it is important to test various PLMs trained on data types or domains similar to the target domain."}, {"title": "5.1. Validation of the proposed approach", "content": "The outcomes and implications of the proposed approach may vary according to the analysis context. In this regard, we performed further experiments to examine the effects of different encoding layers or claim types, which are adaptable to the given context. First, we examined the impact of using other PLMs as encoding layers in the proposed approach. Specifically, we employed PLMs such as BERT (Devlin et al., 2018), SciBERT (Beltagy et al., 2019), BioBERT (Lee et al., 2020), and PubMedBERT (Gu et al., 2021), of which training datasets are different. Table 6 shows the robust performance of the proposed approach using other PLMs. It was observed that SciBERT is the most effective for the three forecasting tasks, exhibiting slightly improved performance compared to the baseline model. This is because the target domain is the pharmaceutical field, where understanding the given textual information requires scientific knowledge, even though the data type is patent. Therefore, when using the proposed approach in practice, it is important to test various PLMs trained on data types or domains similar to the target domain."}, {"title": "5.2. Implications for academia and practice", "content": "The case study showed that the proposed approach is effective for early screening potential breakthrough technologies from patent text, providing enhanced interpretability. Therefore, the proposed approach is expected to have significant implications for both theory and practice. From an academic perspective, this study contributes to technology innovation research by suggesting an interpretable ML method for early screening of potential breakthrough technologies. This is made through the development of PatentHAN, enabling the identification of pivotal claims in the screening process. Unlike previous methods based on opaque ML models, the proposed approach incorporates the claim-wise attention scores, thereby enhancing experts' understanding of the model predictions. Although the focus of this study is an early screening of potential breakthrough technologies, the proposed approach can be applied to solve other research questions where the comprehension and interpretation of technical contents are important. These may include but are not limited to technology valuation (Kim et al., 2023), technology opportunity analysis (Choi et al., 2023; Seol et al., 2023), inventor scouting (Chung et al., 2021) and patent-trademark linking (Ko et al., 2020). From a practical perspective, the proposed approach is expected to advance the timing of screening potential breakthrough technologies, as it requires only textual descriptions of technologies as input. Therefore, given sufficient technical descriptions, proof-of-concept or prototype-stage technologies can be evaluated with the proposed approach. The proposed approach and interpretable results can significantly aid practitioners in making informed decisions regarding breakthrough technologies while facilitating effective communications between stakeholders."}, {"title": "6. Conclusion", "content": "This study has proposed an interpretable ML approach for early screening of potential breakthrough technologies. Central to this approach is the development of a PatentHAN model, which provides interpretable results in predicting the number of forward citations from patent text. The core components of this model include: (1) PatentBERT is utilized as text encoding layer to covert patent claim texts into dense embedding vectors that capture their intricate semantic meanings; (2) a hierarchical network structure, where individual claim vectors are organized to create a comprehensive patent representation vector, is designed to facilitate detailed claim-level analysis; and (3) a claim-wise attention mechanism, which enables the model to concentrate on the most semantically significant parts by assigning weights to each claim, is employed to effectively interpret machine predictions by identifying pivotal claims during the screening process. The case study of pharmaceutical technology confirmed that the proposed approach is effective in screening potential breakthrough technologies and claim-wise attention scores support machine-experts collaborations by revealing the most pivotal technical elements from patent texts.\nDespite its effectiveness, this study is subject to several limitations. First, the proposed approach utilizes the number of forward citations as a single proxy of technological value. However, incorporating other indicators such as technology transfer and patent renewal data is required in future works, for comprehensive evaluation of potential breakthrough technologies (Choi et al., 2020; Kim et al., 2022; Ko et al., 2019). Second, the screening performance can be further improved with the latest models. Although we used an appropriate PLM for patent text processing, the latest large language models such as PaLM2 (Anil et al., 2023), and GPT-4 (Achiam et al., 2023) could provide more accurate predictions. Third, quantitative indicators on the market, technology or regulation factors or image data of patents can be used as additional input data (Choi et al., 2022; Choi et al., 2021; Jee et al., 2022), and the development of multi-modal models could potentially enhance the accuracy and reliability (Chung and Sohn, 2020). Lastly, this study solely focused on a single case study on pharmaceutical technology. To establish the external validity of our approach, further testing should be performed on technologies across diverse domains. Nonetheless, we argue that the proposed approach and interpretable results make significant contributions to both academia and practice."}]}