{"title": "THE PROBABILISTIC TSETLIN MACHINE: A NOVEL APPROACH TO UNCERTAINTY QUANTIFICATION", "authors": ["K. Darshana Abeyrathna", "Sara El Mekkaoui", "Andreas Hafver", "Christian Agrell"], "abstract": "Tsetlin Machines (TMs) have emerged as a compelling alternative to conventional deep learning methods, offering notable advantages such as smaller memory footprint, faster inference, fault-tolerant properties, and interpretability. Although various adaptations of TMs have expanded their applicability across diverse domains, a fundamental gap remains in understanding how TMs quantify uncertainty in their predictions. In response, this paper introduces the Probabilistic Tsetlin Machine (PTM) framework, aimed at providing a robust, reliable, and interpretable approach for uncertainty quantification. Unlike the original TM, the PTM learns the probability of staying on each state of each Tsetlin Automaton (TA) across all clauses. These probabilities are updated using the feedback tables that are part of the TM framework: Type I and Type II feedback. During inference, TAs decide their actions by sampling states based on learned probability distributions, akin to Bayesian neural networks (BNNs) when generating weight values. In our experimental analysis, we first illustrate the spread of the probabilities across TA states for the noisy-XOR dataset. Then we evaluate the PTM alongside benchmark models using both simulated and real-world datasets. The experiments on the simulated dataset reveal the PTM's effectiveness in uncertainty quantification, particularly in delineating decision boundaries and identifying regions of high uncertainty. Moreover, when applied to multiclass classification tasks using the Iris dataset, the PTM demonstrates competitive performance in terms of predictive entropy and expected calibration error, showcasing its potential as a reliable tool for uncertainty estimation. Our findings underscore the importance of selecting appropriate models for accurate uncertainty quantification in predictive tasks, with the PTM offering a particularly interpretable and effective solution.", "sections": [{"title": "1 Introduction", "content": "Tsetlin Machines (TMs) are a promising alternative to current-day deep learning Granmo (2018). Initially, TMs were able to perform classification tasks with binary features, competitively against the state-of-the-art machine-learning approaches. Subsequently, different adaptations of TMs have been proposed to tackle a wide array of challenges across diverse fields. These adaptations cater to scenarios involving continuous inputs and outputs Darshana Abeyrathna et al. (2020), deterministic learning processes Abeyrathna et al. (2020), natural language processing (NLP) applications Saha et al. (2021); Bhattarai et al. (2022), image analysis tasks Granmo et al. (2019), as well as tasks related to compact pattern representation Abeyrathna et al. (2021b).\nFurthermore, since TMs come with multiple advantages over state-of-the-art machine learning approaches, such as requiring a smaller memory footprint Granmo et al. (2019); Abeyrathna et al. (2020), faster inference Wheeldon et al. (2020b), having fault-tolerant properties Shafik et al. (2020), and interpretability Wang et al. (2017); Abeyrathna et al. (2021b), TM-based hardware has been implemented and rigorously tested, demonstrating their viability and efficacy"}, {"title": "2 Uncertainty Quantification", "content": "Overview: Modeling uncertainty in scientific matters is not unique to artificial intelligence (AI) and is not just a contemporary concern. Figures like Huyghens, Pascal, Chevalier de Mer\u00e9, and Jacques Bernoulli had mentioned the concept back in the 17th century in their work. Some challenges in knowledge representation and reasoning due to imprecision, uncertainty, and conflicting information were apparent with the rise of computer science. However, up until the 1980s, this was discussed separately from probability theory and decision-making concerns Den\u0153ux et al. (2020).\nIn the past few decades, the potential of AI has become increasingly evident within the field of applied sciences Abdar et al. (2022). However, AI systems need to estimate their uncertainty to make safe decisions in domains where mistakes are costly. Hence, for AI-based predictive models, uncertainty quantification serves as a measure of the model's confidence or reliability in making predictions under limited domain knowledge, incomplete or noisy data, or inherent randomness in the system and enhances the trust in their predictions Seoni et al. (2023).\nOne of the many separations of uncertainty estimations involves separating uncertainty introduced by the AI model stemming from issues like a poor representation of the training data and insufficient knowledge, from uncertainty arising from the data itself due to reasons such as uninformative, incomplete, conflicting, or noisy data. These are called epistemic uncertainty and aleatoric uncertainty, respectively Der Kiureghian and Ditlevsen (2009). Although epistemic uncertainty can be reduced by improving training and model architecture, aleatoric uncertainty arising from data is irreducible Gawlikowski et al. (2021).\nUncertainty can be quantified using two common methods: ensemble learning and probabilistic machine learning. The latter, also known as Bayesian machine learning, applies probability theory to extract information from data Ghahramani (2015). However, probabilistic methods face computational challenges, especially when dealing with large or complex data or models, such as deep learning models. One can mitigate this issue by using approximation methods, such as variational inference and Markov Chain Monte Carlo, to estimate posterior distributions Murphy (2023). However, one has to balance the trade-off between computation and accuracy when using these methods Seoh (2020). Ensemble learning approaches, on the other hand, involve training several separate models and the final prediction is a collective effort of all. To estimate the uncertainty of the predictions, the models' divergence is utilized. Ensemble learning approaches also have associated limitations, namely, long training time, lack of interpretability, and sensitivity to noisy data and outliers.\nTo quantitatively assess the predictive accuracy and quantification of uncertainty of the models in scenarios with a discrete output space Y, we employ several metrics: entropy, mutual information, and variance. These metrics are specifically chosen to measure the uncertainty of the models. For each test sample xi, these quantities are calculated as follows:\nEvaluation metrics:\nPredictive Mean: For each test example, we generate K prediction samples with each model. The Predictive Mean represents the average predicted probabilities across the K samples and serves as a point estimate of the target. It is calculated as follows:\n$p(Y|X_i) = \\frac{1}{K} \\sum_{j=1}^K p_j(Y|X_i)$"}, {"title": "3 Tsetlin Machines", "content": "Structure: Depending on the task at hand, a suitable Tsetlin Machine setup has to be used. For instance, if the goal is to classify samples into two classes, the basic TM designed for binary classification can be utilized. This TM is also the basis for most of the other versions of TMs, such as the multiclass Tsetlin machine (MTM) Granmo (2018), the regression Tsetlin machine (RTM) Darshana Abeyrathna et al. (2020), and the convolutional Tsetlin machine (CTM) Granmo et al. (2019). In this paper, we use the basic TM for binary classification tasks (which we call TM) to explain the probabilistic Tsetlin machine (PTM), and the concept remains the same for all the other versions of the TMs.\nThe way TM addresses the pattern classification problem is, that it represents classes through a learned set of sub-patterns. In the TM, these sub-patterns are captured by clauses in the form of conjunctions of literals. TM receives features in binary form. Hence, a literal refers to either a propositional variable or its negation. TM uses a m number of clauses to learn patterns, half of them recognizing patterns related to class 1, while the rest learning patterns of class 0. Mathematically, a clause can be written as,\n$C_j = 1 \\land (\\bigwedge_{k \\in I_j^+} x_k) \\land (\\bigwedge_{k \\in I_j^-} \\neg x_k)$"}, {"title": "4 Probabilistic Tsetlin Machines", "content": "In the PTM, our aim is to, instead of a single state update of TAs, consider the state of each TA to be represented by a distribution over all 2N potential states. We identify the state probability vector of the TA representing the kth literal in the jth clause as SPVj,k \u2208 [0, 1]2N. The learning process of PTM is summarized in Algorithm 1. As in the TM, the learning of the PTM starts by selecting the number of clauses m, the target T, and the specificity s. Unlike in the TM where the states of the TAs are randomly initialized to either Nth or N + 1th state, each state probability vector SPVj,k is initialized as, p(Sn) = p(SN+1) = 0.5 and p(Si) = 0 for _i \u2260 N, N + 1, with p(Si) being the probability of staying at state i.\nIn each learning step n, literals included in the jth clause are decided by sampling the states for TAs from their corresponding SPVj,k (also explained in Algorithm 2). The candidate clauses to receive Type I feedback are selected stochastically with probability$\\frac{T-max(-T,min(T,v))}{2T}$ and those to receive Type II feedback are selected stochastically with probability$\\frac{T+max(-T,min(T,v))}{2T}$. Here, the target T, specified by the user, determines the number of clauses involved in learning each sub-pattern.\nWe still utilize the Type I and Type II feedback in the training phase of PTM. However, since we need to update the probability vector SPVj,k, instead of making state transitions depending on the type of feedback TAs receive, we"}, {"title": "5 Experiments and Results", "content": "This section describes the experiments we conducted and the results we obtained. First, we introduce the benchmark methods used for comparison with the proposed PTM. Then, we illustrate what the probability vectors for different TAs look like for the noisy-XOR dataset. Finally, we use both synthetic and real-world data to demonstrate how accurately PTM can quantify uncertainties compared to the benchmark methods."}, {"title": "5.1 Benchmark Methods", "content": "We compare our proposed PTM with different machine learning techniques for uncertainty quantification:\nGaussian Process (GP): A GP Williams and Rasmussen (2006) is a Bayesian, non-parametric learning method for regression and classification problems. It models the probability distribution over possible functions based on observed data. The GP is defined by a mean function and a covariance or kernel function, which determine the similarity between data points.\nMultilayer Perceptron with Monte Carlo dropout (MLP-MCd): MLP-MCd is a neural network technique that integrates dropout layers not only during training for regularization but also during inference for uncertainty estimation Gal and Ghahramani (2016). By performing multiple forward passes with random neuron deactivation, the MLP generates a distribution of outputs offering insights into the model's uncertainty.\nRandom Forests (RF): RF Breiman (2001) is an ensemble machine learning technique that involves constructing multiple decision trees and combining their predictions to obtain an output with a measure of confidence. RF operates by using a technique called bagging, which helps to reduce variance without increasing bias. Furthermore, RF utilizes random subsets of features at each split point in the tree-building process."}, {"title": "5.2 Steady state probabilities (SSPs) for the noisy-XOR dataset", "content": "To illustrate what the probability vectors look like, we utilize a variant of the noisy-XOR dataset, initially introduced in Granmo (2018). In this adapted version, we eliminated redundant features and introduced a 30% random inversion in the XOR outputs. Subsequently, we task the PTM with learning the distinctive patterns for classes 1 and 0 using merely 4 clauses, m = 4, with each clause dedicated to a specific pattern.\nFor reference, the distributions in the absence of noise are depicted in Figure 1. Here, TA-1, TA-2, TA-3, and TA-4 make decisions regarding inclusion and exclusion of the literals X1, \u00acX1,X2, and \u00acx2, respectively. As anticipated, C1 and c3 discern the patterns for class 1, while C2 and C4 learn those for class 0. For instance, c\u2081 grasps the pattern (0, 1) by including x\u2081 and x2 in the clause, thereby yielding an output of 1 solely when 21 is 0 and 22 is 1 in the sample.\nIn contrast to the clear and straightforward inclusions and exclusions of literals in clauses observed when the data is noise-free, the TAs adapt their representations to accommodate the uncertainty inherent in noisy data, as evident in Figure 2. While one might assume, based on prior knowledge about clause allocation to the classes, that c\u2081 has learned the pattern (0, 1) and c3 has learned the pattern (1, 0), the precise composition of the patterns can vary. In other words, even though it's apparent that c\u2081 includes 21 and 22, and c3 includes x1 and \u00acx2 in their clauses with higher probabilities, the pattern can be disturbed depending upon the decisions of the other TAs due to the shared probabilities among TA states of them."}, {"title": "5.3 Illustration using a synthetic dataset", "content": "Our experimental analysis assesses the models using a simple simulated dataset comprising 1000 labeled examples. Each data point in this dataset consists of two features, denoted as X1 and X2, and is assigned one of two labels: 0 or 1.\nTo evaluate the models and gain insights into their performance, we generate 2000 additional unlabeled test examples. These test examples are randomly distributed over a larger range than the training data points. The dataset is represented in Figure 4."}, {"title": "5.4 Multiclass classification using the Iris dataset", "content": "In this section, we evaluate the performance of the multiclass PTM on the Iris dataset, comparing it with the GP, MLP-MCd, and RF. We allocate 80% of the dataset for training the models and the remaining 20% for testing. The evaluation metrics include predictive entropy, mutual information, and ECE.\nFigure 5 illustrates the results, highlighting that both predictive entropy and mutual information are significantly higher for incorrect predictions, which aligns with the expected behavior of a good probabilistic model. Table 6 presents the ECE for each model, where lower values indicate better model calibration. The ECE values in the table indicate effective calibration across all models."}, {"title": "6 Conclusion", "content": "In conclusion, the Probabilistic Tsetlin Machine (PTM) framework introduced in this paper offers a promising solution to address the challenge of uncertainty quantification in predictive tasks with Tsetlin Machines. Through experimental analysis, we have demonstrated the effectiveness of the PTM in accurately quantifying uncertainties. The experiments conducted on both simulated and real-world datasets showcase the PTM's competitive performance in terms of predictive entropy and expected calibration error. Moving forward, further exploration of the PTM's capabilities and its application across diverse datasets and domains could yield valuable insights into its potential for addressing complex predictive challenges while providing transparent uncertainty estimates. When utilized to its full potential, the PTM not only computes uncertainty estimations but could also provide reasons for higher and lower uncertainties, making it a valuable asset in various domains where wrong predictions are costly."}]}