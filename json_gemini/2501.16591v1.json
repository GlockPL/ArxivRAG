{"title": "Applying Ensemble Models based on Graph Neural Network and\nReinforcement Learning for Wind Power Forecasting", "authors": ["Hongjin Song", "Qianrun Chen", "Tianqi Jiang", "Yongfeng Li", "Xusheng Li", "Wenjun Xi", "Songtao Huang"], "abstract": "Accurately predicting the wind power output of a wind farm across various time scales utilizing Wind Power\nForecasting (WPF) is a critical issue in wind power trading and utilization. The WPF problem remains unresolved\ndue to numerous influencing variables, such as wind speed, temperature, latitude, and longitude. Furthermore,\nachieving high prediction accuracy is crucial for maintaining electric grid stability and ensuring supply security.\nIn this paper, we model all wind turbines within a wind farm as graph nodes in a graph built by their geographical\nlocations. Accordingly, we propose an ensemble model based on graph neural networks and reinforcement learning\n(EMGRL) for WPF. Our approach includes: (1) applying graph neural networks to capture the time-series data\nfrom neighboring wind farms relevant to the target wind farm; (2) establishing a general state embedding that\nintegrates the target wind farm's data with the historical performance of base models on the target wind farm; (3)\nensembling and leveraging the advantages of all base models through an actor-critic reinforcement learning\nframework for WPF.", "sections": [{"title": "1 Introduction", "content": "With the development of the economy and science, human demand for energy is increasing daily. Over the\npast few decades, humans have heavily relied on fossil fuels for energy. However, the extensive use of fossil fuels\nhas significantly harmed nature and humanity, contributing to the greenhouse effect and global warming. Currently,\nalmost 99% of the world's population breathes air of a quality below World Health Organization standards.\nApproximately 8 million people die annually from household (indoor) and ambient (outdoor) air pollution. The\nWorld Health Organization estimates that in the Western Pacific region alone, 2.2 million individuals die each year\ndue to air pollution (WHO, 2022). Consequently, as a clean, cheap, and renewable energy compared to traditional\nfossil fuels, wind power has attracted wide attention from governments and research institutions. According to the\nGlobal Wind Report 2022, the year 2021 is one of the best on record for the wind energy industry, with 93.6 GW\nof new capacity installed globally. At present, the total global wind power capacity stands at 837GW. The use of\nwind energy can help people avoid emitting carbon dioxide equivalent to South America's annual carbon emissions,\nabout 1.2 billion tons (Council, 2022).\nAs a significant component of smart grids, wind power plays a crucial role in the generation and supply of\nenergy (Wang et al., 2021). Wind power forecasting (WPF) is essential for the rational scheduling and optimization\nof wind power in one or more wind farms. Due to the significant instability and unpredictability of wind power\nsupply, it has always been a complex challenge for researchers to achieve high-precision wind prediction.\nBased on the time scale of prediction, WPF can be broadly categorized into four types (Chang et al., 2014;\nWang et al., 2011):\nVery-short-term forecasting: The time range is a few minutes to an hour.\n\u2022 Short-term forecasting: The time range is a few hours to a day.\n\u2022 Standard-term forecasting: The time range is a few days to a week.\n\u2022 Long-term forecasting: The time range is a few weeks or more ahead.\nVery-short-term forecasting is mainly used for the regular cleaning of the electricity market and real-time\noperation of the grid. Short-term forecasting plays a significant role in financial market scheduling and informed\nload decision-making. Standard-term forecasting is employed for energy valuation and grid system control, while\nlong-term forecasting mainly guides optimal cost assessment and feasibility method design for the wind farm\nplanning.\nFrom a modeling perspective, wind power forecasting methods can be subdivided into traditional methods\n(Sideratos & Hatziargyriou, 2007; Shi et al., 2011) and machine learning methods (Demolli et al., 2019; J\u00f8rgensen\n& Shaker, 2020). Although current methods have achieved significant success for WPF, numerous variables\n(temperature, altitude, position, humidity, pressure, etc.) could influence the results.\nEach methods has its advantages in specific aspects. Therefore, leveraging and ensembling these models to\noptimize prediction accuracy for WPF is a promising method."}, {"title": "2 Related Works", "content": "In this paper, we model all wind turbines within a wind farm as graph nodes in a graph constructed based on\ntheir geographical locations. Consequently, we propose an ensemble model based on graph neural network and\nreinforcement learning (EMGRL) for WPF. Our approach includes: (1) applying graph neural networks to capture\nthe time-series data from neighboring wind farms relevant to the target wind farm; (2) establishing a general state\nembedding that integrates the target wind farm's data with the historical performance of base models on the target\nwind farm; (3) ensembling and leveraging the advantages of all base models through an actor-critic reinforcement\nlearning framework for WPF. We demonstrate that the EMGRL model outperforms state-of-the-art (SOTA)\nbaselines by up to 12.89% in comparison trials on open datasets for WPF.\nThe remainder of this paper is organized as follows: Section 2 introduces related works on WPF, including\ntraditional and machine learning methods. Section 3 summarizes the basic technologies and depicts the problem\ndefinition of this paper. Section 4 proposes the ensemble model based on graph neural networks and reinforcement\nlearning (EMGRL). Section 5 reports the results of comprehensive experiments on real-world wind farms datasets,\ncomparing EMGRL with baseline methods. Finally, conclusions are presented in Section 6."}, {"title": "2.1 Traditional Methods", "content": "Compared to machine learning methods, traditional methods emphasize wind power prediction through rule-\nbased modeling. These traditional approaches can be classified into persistence, physical, and statistical methods."}, {"title": "2.1.1 Persistence Methods", "content": "The general idea of persistence forecasting is to use the average value of historical wind power to predict that\nfuture wind power will be the same as the current value. Persistence forecasting is typically used as a baseline\nmeasure of the accuracy of other prediction methods rather than as a practical method, especially for short-term\nforecasts (Bludszuweit et al., 2008).\n$P_{t+\\Delta t} = P_t$ (1)\nwhere the wind power $P_{t+\\Delta t}$ at a future time step it is predicted to be the same as the current wind power $P_t$.\nSince the persistence method pays little attention to parameters, it is not reasonable to use it when the forecast\nduration is longer than a few hours."}, {"title": "2.1.2 Physical method", "content": "The physical method typically uses historical weather data from the wind farm, such as temperature, surface\npressure and the number of obstacles, etc., to forecast wind speed and create wind power maps using wind turbine"}, {"title": "2.1.3 Statistical method", "content": "Statistical methods for wind power forecasting include the autoregressive integrated moving average model\n(ARIMA) (Nelson, 1998), Kalman filter (Welch, 2020) and Bayesian model (Pole et al., 2018), which aim to\ndetermine the relationship between input variables and output using historical datasets.\nThe ARIMA technique is commonly utilized in time series forecasting tasks, including wind power\nforecasting. The usual steps of ARIMA include (1) model identification, (2) model ordering, (3) parameter\nestimation, and (4) prediction (Kavasseri & Seetharaman, 2009).\nYatiyana et al. (Yatiyana et al., 2017) used the ARIMA model to establish a wind power forecasting model in\nWestern Australia, significantly improving the reliability and quality of the wind power system. Although ARIMA\naccurately captures the conditional mean, it excludes the time-varying variations of wind power generation. Tian\net al. (Tian et al., 2018) proposed a novel wind power forecasting algorithm based on the ARIMA-LGARCH model,\nconsidering the impact of random wind power volatility on prediction accuracy. To analyze the non-stationary and\nautocorrelation aspects of wind power time series data, the ARIMA and Logarithmic Generalized Autoregression\nConditional Heteroscedasticity (LGARCH) models were utilized. The model's feasibility and efficacy were"}, {"title": "2.2 Machine Learning methods", "content": "Machine learning methods can be further classified into traditional and deep learning approaches. Traditional\nmachine learning methods focus on modeling and predicting wind power through feature engineering. In contrast,\ndeep learning methods primarily use neural networks to directly output prediction results based on big data."}, {"title": "2.2.1 Traditional Machine Learning methods", "content": "The goal of machine learning is to create algorithms that learn from data and generate predictions and allow\ncomputers to update themselves. Because machine learning algorithms can accurately characterize the behavior of\ndatasets, input features are modeled based on expected outputs, and output features are predicted based on previous\ndata. Hence, machine learning is one of the effective methods for wind power prediction (Demolli et al., 2019).\nThe SVM method performs well in wind power prediction tasks. Zeng et al. (Zeng & Qiao, 2011) proposed\na statistical method for wind power prediction based on SVM. The model predicts the wind speed first, and then\nthe wind power is expected using the wind turbine's power and wind speed characteristics. According to simulation\nfindings based on data from the National Renewable Energy Laboratory (NREL), this model has higher accuracy\nfor very short-term and short-term WPF compared to models based on the continuous model and radial basis\nfunction neural network. Many scholars have proposed improved SVM methods for wind power forecasting. Liu\net al. (Liu et al., 2020) proposed a support vector machine (JAYA-SVM) short-term wind speed prediction model\nbased on the JAYA algorithm. The hyperparameters of the SVM are optimized using the JAYA optimization\nalgorithm using the most representative features in the input data.\nIn addition to SVM, traditional machine learning algorithms such as KNN (Mahaseth et al., 2022), XGBoost\n(Jiading et al., 2022) and Random Forest (RF) (Lahouar & Slama, 2017; Shi et al., 2018) have also been used in\nwind power prediction tasks. However, traditional machine learning methods require manual extraction and\ncleaning of data, followed by feature engineering. The selection of features largely determines the model's\neffectiveness. Therefore, traditional machine learning methods have significant limitations in the application of\nflexible wind power prediction scenarios."}, {"title": "2.2.2 Deep Learning methods", "content": "Deep learning can refine data using representation and machine learning models without the need for\npreprocessing steps such as feature selection, dimension compression, and format conversion. The primary\nadvantage of deep learning over traditional methods is its ability to automatically extract features. Advances in\nmodern computing power and neural network theory have provided extensive application potential for deep\nlearning models.\nConvolutional neural networks (CNNs) can be combined with radial basis function neural networks\n(RBFNNs) for wind power generation prediction (Hong & Rioflorido, 2019). CNNs are used to extract wind power\nfeatures through convolution, kernel, and pool operations, while supervised RBFNNs handle uncertain features.\nTesting has shown that this method consistently achieves excellent wind power forecasts, with values exceeding\n0.9 in both winter and summer, indicating outstanding 24-hour-ahead predictions. Devi et al. (Devi et al. 2020)\nintroduced an enhanced long short-term memory network, the Augmented Forgetting Gate Network (LSTM-EFG),\nto forecast subsequence data extracted using Ensemble Empirical Pattern Decomposition (EEMD). The cuckoo\nsearch optimization algorithm (CSO) was incorporated into the parameter design process. Experimental results\ndemonstrate that this model significantly improves prediction accuracy and avoids the defects of traditional models.\nKisvari et al. (Kisvari et al., 2021) proposed a method based on a gated recursive deep learning model combined\nwith traditional machine learning hyperparameter tuning. They successfully developed a novel gated recurrent unit\n(GRU) neural network, which includes 12 features such as generator temperature, gearbox temperature, and wind\nspeed at different heights. In practical tests, the GRU's prediction accuracy surpassed that of LSTM and was less\nsensitive to noise in SCADA datasets. The attention mechanism also proves valuable in wind power prediction.\nNiu et al. (Niu et al. 2021) introduced an attention-based gated recurrent unit sequence model (AGRU) to improve\nprediction performance, using hidden GRU modules to connect and activate tasks across different prediction steps.\nA new data-driven model based on the principles of deep learning-convolutional long short-term memory\n(CLSTM), evolutionary algorithms, a neural architecture search process, and integrated deep reinforcement\nlearning (RL) strategy was proposed by Jalali et al. (Jalali et al., 2021). Initially, mutual information is used to\nextract features from unprocessed wind power time series data. The architecture of the deep CLSTM model is then\noptimized through the neural architecture search procedure. Finally, the RL algorithm-based AI model is integrated\nto minimize the wind power prediction gap between two datasets. This algorithm demonstrates excellent seasonal\nperformance when compared to 14 state-of-the-art models. Chen et al. (Chen et al., 2021) proposed a dynamic\nintegrated wind speed forecasting model based on deep reinforcement learning, considering the time-varying\ncharacteristics of wind speed series. The first part involves using real-time wavelet packet decomposition enhanced\ndeep echo state network to construct the basic model with different vanishing moments. The second part\ndetermines the weight allocation of the basic learner using a multi-modal optimization method. The third part\nembeds the non-dominated solution of combined weights in a deep reinforcement learning environment, enabling\ndynamic selection. By carefully designing the reinforcement learning environment, a dynamic non-dominated"}, {"title": "3 Problem Preliminary", "content": "solution can be selected in each prediction round according to the time-varying properties of wind speed.\nAdditionally, combining various models to improve prediction performance through ensemble methods\nintegrates the advantages of different models and offers good generalization ability (Du et al., 2019; Dong et al.,\n2021; Jaseena & Kovoor, 2021; Duan et al., 2022)."}, {"title": "3.1 Ensemble learning", "content": "Ensemble learning first extracts the characteristics of the data through a series of prescribed mathematical\nmethods. Based on the obtained data characteristics, various algorithms are selected to generate weak prediction\nresults. Finally, ensemble learning acquires new knowledge and achieves better prediction results through an\nadaptive voting scheme (Dong et al., 2022).\nThe comprehensive structure of ensemble learning is illustrated in Figure 1. Ensemble learning methods can\ngenerally be subdivided into Bootstrap aggregating (Bagging), Boosting, and Stacking. The bagging method\nrandomly samples training subsets from the training set and then uses these subsets to perform parallel training\nwhile integrating the base learners into the ensemble model. The Boosting method first trains a basic learner with\nbetter performance from the initial training set, then adjusts the sample distribution according to the performance\nof the basic learner to increase the weight of the samples incorrectly predicted by the basic learner in the previous\ntraining. This process is repeated for the next basic learner with the optimized sample distribution, and the\noperations continue until completion. Finally, a weighted combination of the basic learners is performed. The\nStacking model builds a meta-model using predictions from multiple base models to generate the final forecast.\nThe Stacking model is composed of multiple layers, with each layer consisting of several machine learning models.\nThe predictions from these models are used to train the next layer model."}, {"title": "3.2 Graph neural network", "content": "Graph Neural Network (GNN) is an emerging framework that uses deep learning to directly learn from graph-\nstructured data. Its excellent performance has attracted significant attention and in-depth exploration from scholars.\nBy formulating specific strategies for the nodes and edges of the graph, GNN transforms the graph data into a\nstandardized representation, which is then input into neural networks for training. This approach has achieved\nremarkable results in information aggregation, action recognition, and time series prediction.\nGNNs are typically built on the message-passing neural network framework. As shown in Figure 2, the GNN\nmessage-passing process can be divided into three stages:\n(1) Message Computation\nIn the Message Computation stage, function MC\u00b9 is used to calculate the information value $m_u^l$ of node u in\nlayer l\n$m_u^l = MC^l(h_u^l)$ (2)\n(2) Message Aggregation\nIn the Message Aggregation stage, the function MA\u00b9 is used to integrate the information of node u\u00a1 in the\nneighborhood of node U located in layer l\n$a_v^l = MA^l(\\left\\{m_{u_i}^l, u_i \\in N(v)\\right\\})$ (3)\n(3) Message Update\nIn the Message Update stage, the function MU\u00b9 updates node V at layer based on the neighborhood\naggregation information $a_v^l$ and its own information $m_v^l$\n$h_v^{l+1} = MU^l(a_v^l, m_v^l)$ (4)"}, {"title": "3.3 Reinforcement learning", "content": "Reinforcement learning is a field within machine learning (Sutton et al., 1998). It encompasses a class of\nlearning methods that learn by interacting with the environment and using feedback from it. With the recent\ndevelopment of artificial intelligence (AI), reinforcement learning has emerged as one of the three main machine\nlearning paradigms, alongside supervised learning and unsupervised learning, due to its powerful autonomous\nlearning capabilities.\nThe core of reinforcement learning is to study the interaction between the agent and the environment. By\ncontinuously learning the optimal policy, the agent makes sequential decisions based on the current state of the\nenvironment to maximize cumulative reward. This process can be described as a Markov Decision Process (MDP),\nas shown in Figure 3."}, {"title": "3.4 Problem definition", "content": "The main objective of wind power prediction is to forecast wind power over a period based on historical wind\npower data from a specific area (wind farm) and the wind power characteristics of neighboring areas. For time\nseries data, as shown in Figure 4, different base models often perform differently at the same stage of the data.\nTherefore, identifying the model that performs best at a certain stage is more valuable and easier to implement\nthan directly using a single learner for predictions. This strategy allows us to find the best model to adapt to\nchanging data distributions and make accurate predictions.\nWe aim to solve two problems: (1) What is the next value in the time series data? (2) Which base model is\nbetter at predicting the next value? For problem (1), we use various time series prediction methods as base models\nto make simultaneous predictions. For problem (2), we use reinforcement learning to assign weights to each base\nmodel, reflecting their respective contributions to the prediction results in ensemble learning. In this prediction\ntask, it is necessary to splice and embed the data of each wind farm and the loss data of each learner, then calculate\nthe weight of each base learner using reinforcement learning, and finally make the prediction.\n$W_{final} = Predict(b_1, b_2, b_3 \u2026 b_n), n \u2208 N$ (5)\nwhere Predict stands for the prediction function, $b_i$ stands for base model i in an ensemble model, and N\nrepresents the number of base models selected."}, {"title": "4 Methods", "content": "In this section, we introduce and detail an ensemble model for wind power forecasting (WPF) based on a"}, {"title": "4.1 The overview of EMGRL", "content": "graph neural network and reinforcement learning (EMGRL)."}, {"title": "4.2 State embedding generation", "content": ""}, {"title": "4.3 Training and Prediction Pipeline", "content": "The state embedding consists of two parts: spatio-temporal sequence embedding and model loss embedding.\nFor the spatio-temporal sequence embedding part, we obtained each wind farm's compressed time sequence data\nvector through a dilated convolutional neural network (as shown in Figure 6). Based on time series data, we further\nconsider the spatial characteristics of wind power. We input the timing vectors of all wind farms, including\ngeographical location information, into the GNN network. As shown in Figure 6, we compute the embedding of\nwind farm A among wind farms (A, B, C, D, E, F). Through training, the GNN network can simultaneously\nintegrate the information of neighboring wind farms into wind farm A's time sequence data vector, obtaining the\nspatio-temporal sequence embedding of wind farm A. The computation of the spatio-temporal sequence\nembedding for other wind farms follows the same process as for wind farm A. We denote the space-time\nembedding vector of wind farm A as $STSEA$, which represents the raw input data of the wind farm. The following\nexpression shows the relationship between the two:\n$STSEA = GNN(\\{\\ Dilated$\\ CNN(t_k)\\}), k \u2208 \\{A, B, C, D, E, F\\}$ (6)\nFor the mode loss embedding part, we integrate all the basic models in the learning model, conducted training\non the historical data of all wind farms, and learned the internal parameters of each basic model. Using wind farm\nA as an example, we obtained the predicted losses of all basic models on wind farm A in each training session,\nspliced the losses, and compressed them through a dilated convolutional neural network to obtain the model loss\nembedding of wind farm A. Let $L_{i}^{t-1}$ represent the loss of basic model i on the time sequence data of wind farm A\nat time t 1, and let N represent the number of basic models. The computation of this method is shown in the\nformula:\n$MLE_{A}^{t-1} = MLP(\\{L_{i}^{t-1}\\}, i \u2208 \\{1, \u2026, N\\})$ (7)\nHence, we obtain the embedding vector $SEA$ of wind farm A through splicing:\n$SEA = (STSEA, MLE_{A}^{t-1})$ (8)"}, {"title": "4.4 Algorithm", "content": "We outline the following processes for the training and prediction phases of the reinforcement learning model\n(as shown in Figure 7). Our reinforcement learning algorithm is based on the Actor-critic framework. At timestep\nt, the state $s_t$ describes the information of the input time series and the historical performance of the base models,\nrepresented as $SE_k, k \u2208 \\{A, B, C, D, E, F\\}$. We input $SE_k$ into Actor module, which selects and outputs the\nappropriate actions according to a predetermined policy. The output value of the actor is $a_t = (W_1^t, ..., W_N^t)$, and\neach element of the vector corresponds to the weight of the N base models in the wind power prediction results.\nBased on the weight $a_t$, we can output the ensemble prediction $y_t$ of wind farm k through the ensemble model.\nThe reward $r_t$ is calculated by comparing $y_t$ with the real data. Meanwhile, we also obtain the next state $s'_t$ after\nthe EMGRL model takes action $a_t$. We then save the transition $(s_t, a_t, r_t, s'_t)$ into the replay buffer for later training.\nWe update the actor A($s_t$) and critic Q($s_t, a_t$) using the sampled transitions from the replay buffer. Through\ncontinuous iterative training, highly accurate wind power prediction results for each wind farm can be achieved.\nThe EMGRL algorithm is:"}, {"title": "5 Experiment", "content": "In this section, we conduct numerical experiments to demonstrate the performance of the EMGRL in wind\npower forecasting (WPF)."}, {"title": "5.1 Dataset", "content": ""}, {"title": "5.1.1 NREL Dataset", "content": "In this experiment, we use an open-source dataset from the National Renewable Energy Laboratory (NREL)\n(Draxl et al., 2015). The NREL dataset contains wind data from 2010 to 2011 for four offshore wind farms (A, B,\nC, and D) located on the east coast of the United States. The data is sampled at 10-minutes intervals, with the wind\nturbine output power ranging from 0 to 16MW. We use the wind power data from 2010 for model training and the\nwind power data from 2011 for testing. The specific locations of the wind farms are shown in Fig. 8."}, {"title": "5.1.2 GEFC Dataset", "content": "The second Dataset we use is from Global Energy Forecasting Competition (GEFC) 2012 - Wind Forecasting.\nThe GEFC dataset includes three years of historical data from seven wind farms, spanning from the first hour of\nJuly 1, 2009 to the 12th hour of June 28, 2012. The historical data consists of hourly wind power measurements\nfor each wind farm and forecasts of zonal and meridional wind components, wind speed, and direction for the next\n1 to 48 hours. In this dataset, the period from July 1, 2009 to December 31, 2010, is used for model training, and\nthe period from January 1, 2011 to June 28, 2012 is used for model testing. The wind power values are normalized\nto the interval between 0 and 1 to ensure that the original data features of the wind farm cannot be identified (Li\n& Chiang, 2016)."}, {"title": "5.2 Baseline methods", "content": "\u2022 Autoregressive Integrated Moving Average (ARIMA) (Wang & Hu, 2015)\n\u2022 Support Vector Regression (SVR) (Dhiman et al., 2019)\n\u2022 LightGBM (Ren et al., 2022)\n\u2022 Long short-term memory network (LSTM) (Ko et al., 2020)\n\u2022 Superposition Graph Neural Network (SGNN) (Yu et al., 2020)\n\u2022 COBRT (Guo & Chiang, 2016)\nSDAE (Yan et al., 2018)"}, {"title": "5.3 Settings", "content": "In this paper, our integration model contains four basic models: ARIMA, LightGBM, LSTM, and SGNN.\nARIMA is adept at thoroughly learning the linear characteristics of historical data, while LightGBM excels at\nhandling the nonlinear aspects of time series data. LSTM can retain long-term data elements and learn data patterns,\nwhereas SGNN analyzes data from a graph perspective to extract spatial features more effectively. Each of these\nfour basic learning models brings unique strengths to wind power prediction. By leveraging their respective\nadvantages and allocating weights reasonably, our integrated learning model aims to achieve the best\ncomprehensive prediction results."}, {"title": "5.4 Evaluation", "content": "In this paper, we use Mean Absolute Error (MAE) and Root Mean Square Error (RMSE) as the evaluation\nmetrics for the proposed model.\n\u2022 MAE: Mean Absolute Error calculates the average of the absolute error between the predicted value \u0177\nand the true value y\u00a1, and is less sensitive to outliers.\n$MAE = \\frac{1}{n} \\sum_{i=1}^{n}|y_i - \\hat{y}_i|$ (9)\n\u2022 RMSE: Root Mean Square Error is the square root of the ratio of the square of the deviation between the\nreal value $y_i$ and the predicted value \u0177 and the number of observations n, which can calculate the\ndeviation between the predicted value and the real value. RMSE is sensitive to outliers in the data."}, {"title": "5.5 Results", "content": "We compare the EMGRL model with seven baseline models (ARIMA, SVR, LightGBM, LSTM, SGNN,\nSDAE, and COBRT) under both datasets. For the NREL dataset, we compute the RMSE of the model on the data\nfrom four wind farms (A, B, C, and D) through multiple average calculations. For the GEFC dataset, we compute\nthe MAE and RMSE of the model on the data from seven wind farms through multiple average results.\n\u2022 Algorithm performance in NREL Datasets\nAs shown in Table 1, the EMGRL model achieves the lowest RMSE values for the four wind farms in the\nNREL dataset. Compared to SGNN, which performs the best among the basic models, EMGRL outperforms\nSGNN by approximately 9.62%, 10.44%, 6.57%, and 6.34% for wind farms A, B, C, and D, respectively. We\nvisualize the RMSE values of EMGRL and each base model in Figure 10 and compared RMSE values of EMGRL\nand SGNN in Figure 11.\n$"}, {"title": "6 Conclusion", "content": "RMSE = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}$\nIn this paper, we model all wind turbines within a wind farm as graph nodes in a wind farm graph constructed\nbased on their geographical locations. We propose an ensemble model based on graph neural networks and\nreinforcement learning (EMGRL) for wind power forecasting (WPF). Our approach includes: (1) setting up a\ngraph neural network to extract the spatial features of wind farm data; (2) generating an embedded vector that"}]}