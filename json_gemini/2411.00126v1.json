{"title": "TRAINING AND EVALUATING CAUSAL FORECASTING MODELS FOR TIME-SERIES", "authors": ["Thomas Crasson", "Yacine Nabet", "Mathias L\u00e9cuyer"], "abstract": "Deep learning time-series models are often used to make forecasts that inform\ndownstream decisions. Since these decisions can differ from those in the training\nset, there is an implicit requirement that time-series models will generalize outside\nof their training distribution. Despite this core requirement, time-series models are\ntypically trained and evaluated on in-distribution predictive tasks. We extend the\northogonal statistical learning framework to train causal time-series models that\ngeneralize better when forecasting the effect of actions outside of their training\ndistribution. To evaluate these models, we leverage Regression Discontinuity De-\nsigns popular in economics to construct a test set of causal treatment effects.", "sections": [{"title": "1 INTRODUCTION", "content": "Deep learning models have recently seen major improvements, including in time-series modelling\nLiu et al. (2024); Nie et al. (2023); Chen et al. (2023); Das et al. (2024); Zhang & Yan (2023).\nTime-series models are often used to make forecasts that inform decisions, such forecasting demand\nfor goods or transportation to optimize pricing, or forecasting health markers to optimize treatment\ndecisions Makridakis et al. (2022); Nowroozilarki et al. (2021); Makridakis et al. (2023).\nThe decision making procedures that leverage time-series forecast typically optimize for a given\noutcome, such as revenue or health outcome, and lead to actions that differ from those observed\nin the training data. This results in a key implicit requirement on time-series models: that they\nwill generalize outside of the observational distribution. Despite this requirement, the only complex\ntasks on which time-series forecasting models are trained and evaluated are in-distribution predictive\ntasks Liu et al. (2024); Melnychuk et al. (2022); Lim (2018); Nie et al. (2023); Chen et al. (2023);\nDas et al. (2024); Zhang & Yan (2023); Nowroozilarki et al. (2021); Makridakis et al. (2022; 2023).\nIn this work, we develop a training and evaluation procedure for causal forecasting time-series mod-\nels. Causal models aim to learn the causal relationship between a treatment (e.g., price) and its effect\non a specific outcome (e.g., demand), conditioned on other, observational features. That is, they aim\nto capture the change in outcome caused by a change in treatment, and not just predict the outcome\nfrom an in-distribution observed treatment. As a result, they generalize better when forecasting the\neffect of actions outside of their training distribution.\nA few causal forecasting models have been proposed, but they use approaches that do not map\nto well defined causal effects Bica et al. (2020a;b); Melnychuk et al. (2022), do not correct for\nregularization bias Li et al. (2020a); Bica et al. (2020a;b); Melnychuk et al. (2022); Lim (2018), or\ntake inspiration from causal frameworks for heuristics Brodersen et al. (2015); Schultz et al. (2024).\nIn this work, we leverage the orthogonal statistical learning framework of Foster & Syrgkanis (2023)\nto learn a causal forecasting model. We extend this framework to a well-defined time-series causal\nproblem and to high-dimensional treatments, and instantiate it on top of state-of-the-art backbone\ntime-series models to support complex use-cases."}, {"title": "2 CAUSAL FORECASTING WITH ORTHOGONAL LEARNING", "content": "In the reminder of this paper, we use a demand forecasting task for passenger rails as a running\nexample. For each scheduled train, models aim to predict the daily number of seats sold at a given\nprice using temporal information and other meta-data (see \u00a74.1 for details). The end goal of these\nforecasts is to set prices to maximize revenue. In \u00a74, we evaluate our models on this task using a\nproprietary dataset, as well as on a public health forecasting dataset Johnson et al. (2016).\nWe abstract our forecasting task as a dataset of N observed time-series (N trains) indexed by n,\nwith time indexed by t. Each time-series n consists in stationary context features $S_n$, temporal\n(non-stationary) features measured at each time step $X_{1:t}$, a treatment at each time step $T_{n:t}$, and real\nvalued outcomes $Y_{n:t}$ ($Y_t \\in \\mathbb{R}$). The objective is to predict each outcome $Y_n$ using static, temporal,\nand treatment features, as well as past outcomes up to a time $\\tau < t$ ($Y_{\\tau+1:t-1}$ is unknown). We thus\nseek to learn $\\hat{Y}_n \\approx f(S_n, X_{i:t}, T_{i:\\tau{}}, Y_{\\tau})$, such that $Y_n$ is close to $Y_\\tau$. This setting differs from\nstandard time-series forecasting tasks Liu et al. (2024), but is more relevant to causal tasks (\u00a72).\nWe next formalize causal effects, show their importance to our task, and introduce orthogonal learn-\ning theory that we leverage in our models (\u00a72.1). We then extend orthogonal learning to time-series\nmodels (\u00a72.2), and instantiate this theory with deep learning architectures (\u00a72.3)."}, {"title": "2.1 BACKGROUND: CAUSAL TREATMENT EFFECTS AND ORTHOGONAL LEARNING", "content": "To formalize the importance of causality in forecasting for optimizing decisions, we first need to\nintroduce treatment effects. In the reminder of this paper, we use the potential outcomes (or Rubin's)\nmodel of causal inference Holland (1986); Imbens & Rubin (2015), and flexible data models from\nthe causality Robinson (1988); Nie & Wager (2020); Chernozhukov et al. (2018).\nPotential Outcomes represent the values of an outcome under different possible treatments. Con-\nsider our demand forecasting setting with two possible prices (treatments) $T_1$ and $T_2$. For a given\ntime-series $n$ and time step $t$, we define the potential outcomes $Y^n_t(T_1)$ and $Y^n_t(T_2)$ as the value of\nthe demand $Y_n$ we would observe under each price. Of course, we only ever observe one potential\noutcome, as $Y = 1_{T_1}Y_n(T_1) + 1_{T_2}Y_n(T_2)$ where 1 is the indicator function.\nTreatment Effects represent the causal effect of a change in treatment (price) on the outcome of\ninterest (demand). Formally, the treatment effect of going from price $T_1$ to $T_2$, for time-series $n$,\nat time step $t$, is $Y^n_t(T_2) - Y^n_t(T_1)$. The fundamental challenge of causal inference is that we\ncan only ever observe one potential outcome, for the treatment we chose. As a result, we cannot\ntrain a supervised treatment effects model. However, we can estimate expected causal effects under\nunconfoundedness, the main assumption in the literature which we make when learning our models:\nAssumption 1 (Unconfoundedness). Consider a set of possible treatments $T$. We say that the time-\nseries $(Y_t(T_t), T_t, S, X_t)$ are (conditionally) uncounfounded if, for every time-step $t > \\tau$:\n$\\left\\{Y_t(T_t), T_t \\in T\\right\\} \\perp T_t \\mid S, X_{1:t}, T_{1:\\tau}, Y_{1:\\tau}$"}, {"title": "2.2 ORTHOGONAL LEARNING FOR TIME SERIES MODELS", "content": "We adapt the orthogonal statistical learning framework described above by making two key ex-\ntensions: defining daily treatment effects with an observation cut-off; and extending the R-loss to\ncategorical and linear effects with various encodings for $\\theta$'s predictions.\nTreatment effects in time series. The first step is to formalize the treatment effects to predict,\nand the context to predict them with. In this paper, we focus on daily treatment effects defined\nin Proposition 1. While technically past prices are likely to causally impact demand at $t$, domain\nknowledge tells us that the price at $t$ is the dominant factor. This modelling choice lets us focus on\nsingle-day treatments, though supporting sequences of treatments is an interesting avenue for future\nwork. Focusing on a time-step $t$, this implies that $Y = Y_t$ in Equation 1 and $T = T_t$ in Equation 2.\nDefining the relevant feature set ($W$ in Eq. 1, 2) is more tricky. Recall from \u00a72 that our time\nseries consist in static ($S$) and temporal ($X_{1:t}$) features. These features are naturally included ($W$\n$\\approx (S, X_{1:t})$). In time-series, results from past time steps, such as past prices and associated demands\n$(T_{1:t-1}, Y_{1:t-1})$, are typically very predictive. However, both the uncondoundedness Assumption\n1 and the orthogonal leaning data model (Eq. 1, 2) implicitly assume that features $W$ follow the\nobservational distribution at training and prediction time. This assumption is not verified when\nmodels are used to influence past decisions, and $T_{<t}, Y_{<t}$ cannot be included in $X$. This is an\nimportant point: observational past treatment are very predictive of future demand, but confound\nthe daily treatment effect and are the cause of reversed elasticity predictions we observed (\u00a72.1,\nFigure 1). To avoid this confounding, we introduce a cut-off $\\tau$ after which treatments can deviate\nfrom the distribution. That is, in time-steps $1:\\tau$ the model is not used to affect treatments, while\nfor $t > \\tau$, the treatment $T_t$ can differ from the training distribution. We then set the features as\n$W = (S, X_{1:t}, T_{1:\\tau}, Y_{1:\\tau}) \\approx W_t$, which we use as input for our daily treatment effect of $T_t$ on $Y_t$.\nHigh dimensional effects. The other extension we require is support for higher-dimensional treat-\nments. We consider both categorical and linear treatments and treatment effects. We start with\ncategorical treatments, for which we propose two different encodings. In our demand forecasting\ndataset, possible prices are discrete, following a large but tractable set of possible values (about\nthirty possible prices) of size $d \\approx |T|$. We extend the approach of Robinson (1988); Nie & Wager\n(2020); Foster & Syrgkanis (2023) (Equations 1, 2) to model each time-step $t$ as follows:\n$Y_t = T^T_t\\theta_0(W_t) + f_0(W_t) + \\epsilon_1, \t E[\\epsilon_1 \\mid W_t, T_t] = 0 \n T_t = e_0(W_t) + \\epsilon_2, \t E[\\epsilon_2 \\mid W_t] = 0_d \nwhere $T_t$ is a d-dimensional column vector encoding the treatment, $\\theta_0(W_t) \\in \\mathbb{R}^d$ outputs a column\nvector treatment effect, and $0_d$ is the d-dimensional zero vector. The R-loss becomes:\n$l(\\theta, m, e, z) = (Y_t - m(W_t) - (T_t - e(W_t))^T\\theta(W_t))^2 \nWe consider two encodings for the categorical treatment $T_t$ and treatment effect $\\theta(W_t)$. In the one-\nhot encoding, $T_t$ is a one-hot vector of the treatment. As a result, the $i^{th}$ dimension of the treatment\neffect model encodes the CATE compared to $f_0$. That is, $\\theta(W_t)_i = [E[Y_t(T_i) - f_0(W_t) \\mid W_t]$.\nIn the cumulative encoding, the treatment model encodes the treatment effect of incremental price\nchanges, such that the cumulative predictions encode the CATE: $\\sum^i_{j=1}\\theta(W_t)_j = E[Y_t(T_i) - f_0(W_t) \\mid W_t]$. In this case, $T_t$ is a vector of ones in dimensions $1:i$, and zeros after. While\nwe do not do it in this work, the cumulative encoding can be useful to encode constraints, such as\nfixing the sign of incremental effects of price changes.\nGiven true categorical treatments and our flexible deep-learning models, we can reasonably assume\nthat $\\theta_0 \\in \\Theta$, and thus $\\theta^* = \\theta_0$. With enough treatment variation, our model will converge to the true\nCATE. In practice however, demand forecasting datasets only see local variation around a typical\nprice for any particular value of features $W_t$. As a result, a small risk under the R-loss only ensures\nan accurate $\\theta$ around likely prices. The model is under-constrained further from typical prices, where\nit will not learn relevant treatment effects. This is a fundamental limitation of any causal approach,\nas local variations around a typical price implies a lack of positivity for most dimensions of $\\theta(W_t)$.\nIn such cases, adding structure to the treatment effect model is practically useful. To this end, we also\nconsider a linear encoding for the treatment effect. Concretely, we use the data model of Equations"}, {"title": "2.3 CAUSAL TIME SERIES FORECASTING MODELS WITH DEEP LEARNING", "content": "To instantiate the theory described in \u00a72.2, we extend time-series architectures for deep learning,\nthat we use as backbones for models $m, e, \\theta$. We then adapt the training procedure to fit Algorithm\n1. Finally, we change the prediction procedure to output causal forecasts.\nBackbone Time-Series Model Architecture with Orthogonal Learning. Our time-series back-\nbone takes as input static features $S$, temporal features $X_{1:t}$, and treatments and outcome values\nbefore $\\tau$, $T_{1:\\tau}$ and $Y_{1:\\tau}$. It is then used in three models: $e(\\cdot)$, which predicts the treatment sequence\n$T_{>\\tau}$; $m(\\cdot)$, which predicts expected outcomes (without knowing the treatments); and $\\theta(\\cdot)$, which\npredicts a vector of treatment effects (interpreted differently depending on the encoding, see \u00a72.2).\nOur inputs are non-traditional, and the reason why our main backbone is a modified TFT Lim et al.\n(2020) (modification details in Appendix C.3). We also experiment with the state-of-the-art iTrans-\nformer architecture Liu et al. (2024), passing static features' embeddings along temporal ones, and\ntraining with randomly sampled $t$ values by truncating the time-series at $t$, as the iTransformer pro-\ncesses entire time-series without a causal structure (i.e., the model \u201cknows the future\u201d). This results\nin very slow training and prediction, and we can only apply it to one of our datasets.\nFitting a Causal Orthogonal Time-Series Model. We fit our models following Algorithm 1. We\ntrain both models $m(W_t), e(W_t)$ as estimators for $E[Y_t \\mid W_t]$ and $[E[T_{>\\tau} \\mid W_t]$ on subset $S_1$. $m(\\cdot)$ is\ntrained with the mean squared error (MSE) loss. The loss for $e(\\cdot)$ depends on the encoding function.\nWe use the cross entropy for the one-hot encoding case, the binary cross-entropy for the cumulative\nencoding, and the MSE for the linear encoding. In all cases, we train $\\theta(\\cdot)$ by minimizing the R-loss\n$l(., m, e, z_t)$ from Eq. 5 with data points $z_t \\in S_2$.\nForecasting with a Causal Orthogonal Time-Series Model. $\\Theta$ predicts causal changes of out-\ncomes under different treatments. However, to optimize downstream decisions (e.g. chose prices to\nmaximize revenue) we need a proper forecast for the outcome $Y_t$. Our final estimator combines all\nmodels following Eq. 3: $\\hat{Y}_t(W_t) = m(W_t) + (T_t - e(W_t))^T\\theta(W_t)$.\nThis way under $g_0$ we have $\\hat{Y}_t(W) = f_0(W_t) + e_0(W)^T\\theta_0(W_t) + (T_t - e_0(W_t))^T\\theta(W_t) = f_0(W_t) + T_t\\Theta(W_t)$. When $\\theta(\\cdot)$ is close to the CATE, our predictions change causally with $T_t$."}, {"title": "3 REGRESSION DISCONTINUITY DESIGN FOR CAUSAL MODEL EVALUATION", "content": "Once our causal forecasting models are fitted, how can we measure their performance? This is a core\nchallenge in causal models, which fundamentally rely on untestable assumptions Pearl (2009), such"}, {"title": "3.1 BACKGROUND: REGRESSION DISCONTINUITY DESIGNS", "content": "Regression Discontinuity Designs (RDD) leverage a continuity assumption to estimate a treatment\neffect at a cut-off point that triggers a change in treatment Hahn et al. (2001); Imbens & Lemieux\n(2008); Lee & Lemieux (2010). We present a slightly non-traditional version that conditions on\nadditional variables, needed for our demand forecast setting. Formally, RDDs require a variable X\nwith an associated cut-off value c that corresponds to a change in treatment. That is, $T = T_1$ when\n$X < c$, and $T = T_2$ when $X > c$. RDDs provide identifyability under the following assumption:\nAssumption 2 (Continuity). The potential outcomes' conditional expectation, $E[Y(T_2) \\mid X = x,V]$\nand $[E[Y(T_1) \\mid X = x,V]$ respectively, are both continuous in x.\nUnder assumption 2, we can estimate the CATE at the cutoff $X = c$:\nProposition 4 (CATE Identifyablity from RDD). Under Assumption 2, we have that:\nE[Y (T_2) - Y (T_1) \\mid X = c, V] = \\lim_{x \\to c^+}E[Y \\mid X = x, V] - \\lim_{x \\to c^-} E[Y \\mid X = x, V]\nPractical estimators based on Proposition 4 typically fit linear or polynomial models $g : X, V \\to Y$,\nusing an indicator variable for the cut-off to measure the discontinuity at the point of change of\ntreatment $X = c$. This discontinuity captures the CATE at $X = c$. Since we are interested in the\nlimit at $X = c$, one often uses a weight kernel $K(\\cdot)$ that decreases the importance of datapoints\nfurther from the cut-off $X = c$. Typical weight kernels include the rectangular \"window\" kernel of\nwidth $h$, or a triangular kernel in which weights decay linearly when moving away from $X = c$,\nuntil they reach zero outside of $[c \u2013 h, c + h]$."}, {"title": "3.2 ESTIMATING TREATMENT EFFECTS IN TIME SERIES", "content": "RDDs are attractive to evaluate our models, as Assumption 2 differs from uncounfoundedness (As-\nsumption 1) which underpins the learning of causal models. To causally evaluate models, we want\nto compare a model's CATE prediction on a given time-series $n$ at time-step $t$, to another estimate\nof this CATE used as ground truth. We obtain this ground truth by framing observed changes in\ntreatment on individual time-series as an RDD. Consider time-series $n$. We call $t^n_i$ the $i^{th}$ switch-\ning time-step at which a price change happens, with $T_1 \\approx T_{t^n_i-1} \\neq T_{t^n_i+1} \\approx T_2$. Because we\nuse aggregated time-series (e.g., at the daily level), and treatment changes happen in the middle of\nan observation, $t^n_i$ is often ill defined. While this deviates from traditional RDD formulations, in\nwhich $E [Y \\mid X = c, V] = E[Y (T_2) \\mid X = c, V]$, Prop. 4 and associated estimators still apply.\nAnother deviation from \u00a73.1 is that our time-steps are discrete, so we technically cannot take the\nupper- and lower-limits at the $t^n_i$. We follow Lee & Card (2008) and assume that specification\nerrors at the (the deviation from g's estimates and the true conditional expectation on each side of the\ncut-off) are zero in expectation. Formally:\nAssumption 3 (Unbiased specification errors). Consider (continuous at c) RDD models $g_{T_1}: x \\to\ng(T_1,x)$ and $g_{T_2}: x \\to g(T_2, x)$ for time-series $n$. For $i \\in \\{1,2\\}$, $E[Y_{t^n_i}(T_i) - g_{T_i}(c) | V] = 0$"}, {"title": "3.3 CAUSAL TEST SETS TO EVALUATE CAUSAL FORECASTING MODELS", "content": "Proposition 5 lets us estimate the CATE on a specific time-series $n$, at a specific time $t^n_i$, for a specific\ntreatment change $T_{t^n_i-1} \\to T_{t^n_i+1}$. We call this quantity $CATE_{t^n_i}$. To create our causal test set, we\ntake the in-distribution task test set $S_{test}$, and collect all $CATE$ values that we can estimate from\nit in $S_{CATE}$. We only include switch-times $t^n_i$ that have at least three time-steps without treatment\nchanges strictly before and after $t^n_i$, to have enough data for the RDD estimator.\nGiven enough data, we create a small dataset $D_r$ to fit our RDD model $g$, including all time-steps\nwith constant treatments around $t^n_i$. Formally, $D_r = \\{t : \\forall t' \\in [t,t^n_i-1], T_t = T_{t^n_i-1}\\} \\cup \\{t : \n\\forall t' \\in [t^n_i+1, t], T_t = T_{t^n_i+1}\\}$ (note that $t^n_i \\notin D_r$). In tasks with known cyclical patterns, such as\nour demand prediction task with day of the week effects (see \u00a73.2), we create a set of comparable\ntime-series $S_n$ (using a rule informed by domain knowledge) on which we fit a linear regression\nmodel with time interactions $Y \\sim V + V \\times t$. For days of the week, this gives us parameters\n$\\alpha_{1,j}, \\alpha_{2,j}$ for $j \\in \\{1,...,7\\}$. We then compute the residuals $Y_t = Y_t - \\sum_{j=1}^7(1_{t = j}\\alpha_{1,j} + t\\alpha_{2,j})$, on\nwhich we fit our RDD model. From early experiments, we noticed that $L2$ regularized linear models\nperform best for $g$. We fit such a model with weight kernel $K(.)$ of window size $h$ on dataset $D_r$\nusing the following specification:\n$Y_t = \\beta_0 + \\beta_1(t - t^n_i) + \\beta_21_{t>t^n_i} + \\beta_31_{t>t^n_i}(t - t^n_i) + \\epsilon$\nParameter $\\beta_2$ corresponds to the estimate of $CATE_{t^n_i}$ that we put in our causal test set $S_{CATE}$. Figure\n2 represents the estimation of different $CATE_{t^n_i}$ for a given time series, with and without correction.\nSmall sample sizes in RDD datasets make the final causal test set $S_{CATE}$ noisy. We filter outliers\nby cutting the 2.5% tails of the distribution on each side. With this test set of causal effect, we"}, {"title": "4 EVALUATION", "content": "can evaluate predictions of causal effects from our models, as described in \u00a72.3. We use traditional\nmetrics such as the root-mean-square error (RMSE) or the mean absolute error (MAE). We can\ncompare such metrics to causal effects estimated with non-causal models, by predicting with those\nmodels at different treatments (prices) and subtracting the results to estimate their predicted CATE."}, {"title": "4.1 DEMAND FORECASTING DATASET", "content": "Dataset. Each time-series is a sequence of prices and number of sales for one train. Temporal\nfeatures include the weekday of the timestep and the number of days before departure. Stationary\nfeatures include the departure and arrival terminals and departure date time. The dataset consists\nin about 300,000 training time-series, and validation and test sets of around 100,000 each. All the\nfigures and metrics regarding this dataset have been anonymized. Time steps $t$ are normalized to\n[-1, 0] (all time series have the same length).\nExperimental setup. We set $\\tau = 0.33$, and forecast all outcomes $(Y_t)_{t>\\tau}$. Baseline (non-causal)\nmodels are trained with the MSE loss, and include a well-tuned LGBM model (used in production)\nand two deep learning architectures: the state-of-the-art iTransformer Liu et al. (2024), and a custom\nversion of the Temporal Fusion Transformer (TFT) Lim et al. (2020). The TFT maps well to our\nrequirements (see \u00a72), and we modify it for performance (details in Appendix C.3). We tune all\nmodels' hyper-parameters separately and equally, and report metrics by training and testing with 5\nrandom seeds on final hyper-parameters, and reporting the mean and standard-deviation. The RDD\ndataset uses a linear weights kernel with $h = 14$ time steps. Keeping all switching times with at\nleast 3 data points strictly before and after the price change retains 70% of observed price changes.\nResults. Table 1 shows the performance of several models. We can see that non-causal models\nperform best in-distribution, and the LGBM is best among them in both RMSE and MAE. This is\nexpected, as the observed prices are very informative in-distribution, since operators use their ex-\nperience to set prices based on the demand they expect. On causal tasks however, causal models\noutperform the baselines, with linear models being particularly accurate in terms of RDD RMSE,\nwhich is expected in high teatment dimension d (\u00a72.2). The Causal iTransformer with linear ac-\ntivation has an RDD RMSE 37% better than the baseline TFT, the next best non-causal model, a\nsignificant improvement. Figure 3a corresponds to the same time series as figure 1b-1a, and shows\nthat the causal model captures the correct CATE sign (increasing prices decreases the demand fore-\ncast). Figure 3b shows that the causal TFT's CATE distribution is qualitatively much better: model\npredicts fewer positive CATE effects than baselines on the test set, and those positive CATES are\nsmaller in magnitude."}, {"title": "4.2 MIMIC HEALTH PREDICTION DATASET", "content": "We also evaluate our approach on a public dataset, and release the code to replicate experiments\nhere: https://github.com/wiremind/causal-forecasting.\nDataset. We use MIMIC-extract library Wang et al. (2020) to process MIMIC-III Johnson et al.\n(2016). Every time-series represents data from one patient who stayed between 30 and 60 hours"}, {"title": "C IMPLEMENTATION DETAILS", "content": null}, {"title": "C.1 CAUSAL TRANSFORMER", "content": "We use the Causal Transformer (Melnychuk et al., 2022) in order to get a reference model for\ncomparison. We use the public github repository (https://github.com/Valentyn1997/\nCausalTransformer/tree/main).\nMelnychuk et al. (2022) train an auto regressive\nmodel, like us using 25 vital signals, the age, the gender and the ethnicity to estimate the\nblood pressure of patient. In that context, the relevant features for predicting blood pressure\nat time $t$ are all the vitals before time $t$, static features and all treatments up until time $t$.\nNonetheless, when evaluating for time $\\tau + l$ for $l$ in [1,5], the model had knowledge of vitals\nat time $\\tau + 1$, enabling the model to perform very well for $l = 1$ and leaking information\nfor all\\tau$ (https://github.com/Valentyn1997/CausalTransformer/blob/\nc49a24faa57af966501e241f57a26b528f874a53/src/data/mimic_iii/real_\ndataset.py#L67). This leak manifested as extremely good performance for $l = 1$, followed by\na large drop of performances at $l > 2$. In our evaluation, we fix the leak from the future, and obtain\nresults consistent with other models trained on this dataset during our study."}, {"title": "C.2 RDD", "content": "Algorithm 2 describes how to compute the dataset of RDD values in full details."}, {"title": "C.3 TFT", "content": "We developed a custom version of the Temporal Fusion Transformer Lim et al. (2020). We focused\non this architecture as it supports static features, past and futures features as input, and temporally\ncausal processing of the input, where most architectures focus on predicting future time step from\nthe previous ones Liu et al. (2024), Zhang & Yan (2023), Wu et al. (2021), Nie et al. (2023). We apply\nseveral changes to the original TFT:"}, {"title": "D ADDITIONAL RESULTS", "content": null}, {"title": "D.1 ADDITION MIMIC-II RESULTS", "content": "Table 3 shows MAE results for in-distribution forecasts. Table 4 shows MAE results for causal\neffects using our RDD dataset. Results show the same effects as those described in \u00a74.2 for the\nRMSE and RDD RMSE."}, {"title": "E EXTENDED RELATED WORK", "content": "Our two background sections \u00a72.1 and \u00a73.1 already discuss the closest related work. In this section", "Y^{in})i\\in[t": "t+h", "from\n$(Y^{in})i\\in[0": "t", "Y^{in})i\\in[1": "t", "X)i\\in[1": "t", "Y^n)i\\in[0": "t", "X)i\\in[0": "t+1", "X)i\\in[t+1": "t+h"}]}