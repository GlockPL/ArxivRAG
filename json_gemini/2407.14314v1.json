{"title": "EmoCAM: Toward Understanding What Drives\nCNN-based Emotion Recognition", "authors": ["Youssef Doulfoukar", "Laurent Mertens", "Joost Vennekens"], "abstract": "Convolutional Neural Networks are particularly suited for\nimage analysis tasks, such as Image Classification, Object Recognition or\nImage Segmentation. Like all Artificial Neural Networks, however, they\nare \"black box\" models, and suffer from poor explainability. This work\nis concerned with the specific downstream task of Emotion Recognition\nfrom images, and proposes a framework that combines CAM-based tech-\nniques with Object Detection on a corpus level to better understand on\nwhich image cues a particular model, in our case EmoNet, relies to assign\na specific emotion to an image. We demonstrate that the model mostly\nfocuses on human characteristics, but also explore the pronounced effect\nof specific image modifications.", "sections": [{"title": "Introduction", "content": "Thanks to recent progress, image analysis problems such as Object Detection\nusing Artifical Neural Networks (ANN) can be more or less considered to be\nsolved [8, 19]. However, higher-order tasks, such as identifying the emotion con-\ntent of an entire image, remain more challenging. Convolutional Neural Network\n(CNN) models such as EmoNet [9] present a promising approach in this area,\nbut its results are not yet completely convincing. This raises the question to\nwhich extent this network is actually picking up meaningful cues in the images,\nand to what extent it is learning spurious correlations that may be present in\nthe private dataset on which it was trained.\nANNs are still considered \"black box\" models, and the domain that attempts\nto untangle how they make the predictions they make, i.e., to improve their\nexplainability, is a very active one [2, 16, 18]. One of the techniques for this is\nClass Activation Maps [20], or CAM, which allows to highlight those parts of the\nimage that contributed most to a model's (say, a CNN image classifier) output.\nThis technique allows to visually inspect individual images or videos, but does\nnot immediately allow for an automated global analysis on a corpus level."}, {"title": "Methodology", "content": "We start our analysis by applying, for a given CNN model M and corpus D, the\nfollowing steps to each image I \u2208 D, schematically illustrated in Fig. 1.\nFirst, we process I with the object detection network of our choice, in casu,\nYOLOv3 [14] trained on the Open Images dataset.4 We opted for this particu-\nlar pretrained network as other popular Object Detection dataset choices such\nas PASCAL VOC (20 classes) and MS-COCO (80 classes) are too restricted\nin the classes they propose. By contrast, Open Images, which contains 601\nclasses, presents a nice balance between human-related classes (e.g., \u201chuman"}, {"title": "Results", "content": "We tested our proposed approach using the EmoNet model and the FindingEmo\ndataset. EmoNet is a model obtained through replacing the last layer of an\nAlexNet model pretrained on the ImageNet [4] corpus. This last layer was then\ntrained on a private dataset of 137,482 images annotated for the emotion they\nevoke in the observer with one of 26 custom emotion labels. We use the Python\nport by L. Mertens [10] of the original Matlab release.\nFindingEmo is an image dataset consisting of 25,869 images annotated for,\na.o., the dominant emotion in the picture, using one of the 24 emotion labels\nin Plutchik's Wheel of Emotions [13]. All images represent multiple people in\nvarious natural settings and with varying degrees of interaction among them.\nWe first present detailed results for Grad-CAM [17] in Sec. 3.1, and follow\nthis up with an exploration of the effect of using other CAM-based methods in\nSec. 3.2. Finally, we briefly explore the effect on the predicted label of artificially\nadding certain objects to images, attempting to answer the question whether the\npresence of certain objects can cause a specific label to be predicted."}, {"title": "Results for Grad-CAM", "content": "A heatmap depicting M'A as obtained using Grad-CAM together with EmoNet\napplied on the FindingEmo corpus can be found in Fig. 3. We limit ourselves to\nthe 25 most prominent Open Images classes (as determined by the average of\nthe corresponding row in MA). A clear conclusion to be drawn from this graph\nis that human features do indeed contribute the most to the decision making,\nmost particularly the human face which, except for \"Clothing\", represents the\nmost important class for each EmoNet label.\nAdditionally, some more specific associations do manifest themselves. Clear\nexamples are the association between \"Sports equipment\" and \"Excitement\", and\n\"Food\" and \"Craving\", both of which seem logical. Less clear is, e.g., the associa-\ntion between \"Furniture\" and \"Interest\", or \"Plant\" and \"Surprise\", which hint of\nspurious associations resulting from biases in either or both the EmoNet training\ndataset and FindingEmo."}, {"title": "Comparison of CAM Methods", "content": "To answer the question to what extent different CAM methods yield different\nresults, we performed a Representational Similarity Analysis [1] as follows. For"}, {"title": "Prediction Stability", "content": "To illustrate how the obtained knowledge can be applied to fool the network\nby creating an adversarial attack, consider the image shown in Fig. 4. We know\nfrom Sec. 3.1 that there is a high association between the object category \"Sports\nequipment\" and EmoNet label \"Excitement\". This inspired us to take an image\nlabeled with high probabilty as \"Joy\" (92.9%; Excitement: 1.8%). After altering\nthis image by pasting a rugby ball on top of the head of one of the two main\nsubjects, the prediction changes to 66.1% \"Excitement\" (\"Joy\": 30.2%), demon-\nstrating the dramatic effect the presence of a particular object can have on the\nmodel's output.\nNote that the position of the pasted object greatly influences the effect it\nhas. Moving the rugby ball to the immediate right of the subject's face alters\nthe predictions to 43.9% \"Joy\" and 42.1% \"Excitement\", while moving it to the"}, {"title": "Limitations and Future Work", "content": "Although the currently described approach already provides valuable insights,\nsome limitations are to be noted.\nFirst, the approach is, by definition, heavily dependent on the choice of Ob-\nject Detection network and its corresponding classes and performance. The up-\nside is that, as a plug-and-play component, different Object Detection networks\ncan be chosen for different tasks, allowing to pick object classes tailored to the\ntask at hand.\nSecond, our current implementation does not take into account the size of\nthe bounding boxes, which can result in suboptimal results. Consider, e.g., the\nexample shown in Fig. 7. Although the subject's ear is clearly not the most\nimportant contributing element in the picture, because of the small size of the\n\"Human ear\" bounding box the average CAM activation is nonetheless the high-\nest, spuriously pushing this object class to the top. Two main paths could be\nexplored to counter this issue. The most straightforward would be to develop a\nscoring function that does take into account the bounding box size, or the acti-\nvation distribution within it. Alternatively, segmentation models could be used"}, {"title": "Conclusion", "content": "We propose the novel EmoCAM approach to explaining CNN decisions, specif-\nically with the downstream task of Emotion Recognition from images in mind.\nOur objective is threefold: 1) better understanding what parts of the input image\nthe model uses to make its decision, 2) allowing to check whether or not the in-\nformation used by the model aligns with expectations from a human perspective,\nand 3) uncovering potential model biases. We have demonstrated our approach\nusing the EmoNet model, FindingEmo dataset and multiple CAM techniques.\nUsing our approach, we found that EmoNet indeed shows a strong focus on hu-\nman elements, most notably (parts of) the human face, which is encouraging as\nit aligns with our understanding of human emotion recognition from Psychol-\nogy. Nevertheless, we also found the model output to be quite unstable, in that\nadding specific objects (e.g., a rugby ball) to an image can dramatically alter its\noutput and steer it towards a specific target emotion (e.g., \u201cExcitement\u201d)."}]}