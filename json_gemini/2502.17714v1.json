{"title": "On the usability of generative AI: Human generative AI", "authors": ["Anna Ravera", "Cristina Gena"], "abstract": "Generative Al systems are transforming content creation, but their usability remains a key challenge. This paper\nexamines usability factors such as user experience, transparency, control, and cognitive load. Common challenges\ninclude unpredictability and difficulties in fine-tuning outputs. We review evaluation metrics like efficiency,\nlearnability, and satisfaction, highlighting best practices from various domains. Improving interpretability,\nintuitive interfaces, and user feedback can enhance usability, making generative Al more accessible and effective.", "sections": [{"title": "1. Introduction and background", "content": "Today's generative Al systems are increasingly widespread and despite continuous updates and new\nfeatures they present significant usability issues. Among the primary problems observed in the analysis\nof the most generative Al systems, control during interaction stands out [1]. The issue of user control\nversus automation focuses on Al and is crucial in every human-computer interaction design. It applies\nto a vast range of objects and processes involving some degree of automation, such as household\nappliances, smartphones, and car safety devices. It is essential to design the experience so that the\nlevel of control users have over operations is clear. Each case is unique, and it is not always true that\ngreater user or machine control is the best solution.\nSpecifically, in Al, the analysis of control and interaction involves the dual role of Al systems as both\n\"assistive tools\" and \"colleagues\" [2, 3, 4]. This leads to the ideal scenario of \"Human-Machine\nTeaming,\" where humans and Al collaborate to achieve a common goal. The balance is achieved\nthrough the Hybrid Intelligence approach, which surpasses the CITL and HITL paradigms (Computer in\nthe Loop and Human in the Loop). This approach enables the accomplishment of complex goals by\ncombining human and artificial intelligence to collectively achieve superior results, improving\ncontinuously through shared learning [5]. Some significant usability issues stem from the paradigm\nshift in human-Al interaction and the failure of interfaces to adapt to and to personalize to new user\nneeds [6, 7, 8, 9]. Interaction has shifted from a GUI-based model within the broader command-based\ninteraction paradigm-where users reach the desired result independently through commands and\nhypertext links [10] to an intent-based model [11].\nIn command-based interaction, users do not necessarily need a clear idea of what they want to\nachieve at the start; they can refine their search and define the desired content progressively, as the\nstate evolves after each command [12]. In contrast, interaction with Al systems involves a paradigm\nwhere users express the desired outcome without specifying \"how\" to achieve it. This reverses the\nlocus of control in the interaction.\nInteraction can still be iterative when the Al's output does not meet user expectations, allowing users\nto refine or modify the result. This is an intent-based interaction. However, difficulties in obtaining the\ndesired outcome arise from both the Al's interpretation and the translation of intentions into prompts.\nAn evolution in the user experience of Al systems is necessary, integrating GUI-like characteristics with\nintent-based interaction [13].\nAccording to [14] successful UX framework for Al systems can be composed of the following\nelements: Context, Interaction, and Trust. Implementing features respecting this framework can\nsignificantly enhance user experience in terms of research and interface design. Among these, trust\nrequires particular attention. The trust relationship between humans and Al determines the success of\nthe interaction, beyond the technical efficiency of the generated output. A successful interaction\ninvolves completing tasks without unexpected issues, errors, or unnecessary additional activities. Trust\nbecomes the key to system adoption: if users trust the system, they will continue to use it; otherwise,\nthey will abandon it.\nRegaining lost trust is a long and difficult process.\nThe intent-based interaction model [15] typically involves either voice interaction or prompt-based\ninteraction. While voice interaction improves accessibility, it is not suitable for complex tasks.\nPromptbased interaction, on the other hand, faces its own challenges. Despite being established as the\nprimary mode of interaction, prompt-based interaction often fails to help users achieve satisfactory\nresults independently without the right tools and guidance. Writing an effective prompt requires\ncertain skills and considerations to achieve the desired outcome. The written prompt represents only\nthe \"tip of the iceberg\" with the submerged portion consisting of additional information in the user's\nmind (or yet to be formulated). These implicit elements often play a more critical role in enabling the\nAl to deliver precise and in-depth content aligned with user intentions.\nAnother issue tied to usability relates to the black-box nature of Al systems. These systems, often\ngenerative but not exclusively, are opaque to users. Users are often unaware of how the Al arrives at\nits outputs, how accurate the results are, why certain content is included while others are not, and\nwhich sources were used. Unlike non-Al systems, where outputs are predetermined and based on\nalgorithms and rules, Al systems produce outputs that may be unexpected and non-deterministic [16].\nThis unpredictability and lack of transparency can lead to damage to user expectations.\nIn this rapidly evolving Al landscape, improving system usability and user experience focuses on the\nconscious integration of an HCAI (Human-Centered Al) approach in interface design [1]. This approach\nshould consider all stakeholders involved in Al systems, account for real user needs, their ability to\nexpress themselves effectively through prompts, and the effort required to adapt to new intent-based\ninteraction systems.\nThis paper has been organized as follows: in Section 2 we present the shift from From Conduit\nMetaphor to Prompt Engineering; in Section 3 we present and discuss a prototype we design for usable\ngenerative Al systems; in Section 4 we present a usability test performed on the prototype, while in\nSection 5 we present the results and we conclude the paper."}, {"title": "2. From Conduit Metaphor to Prompt Engineering", "content": "Communication between humans occurs in a multimodal manner and an important part of\ncommunication as a whole is non-verbal communication, which includes body language, eye\nlanguage, touch and other forms of expression without words [17]. Although these are the\ncharacteristics of human-tohuman communication, this is not the model used for the design of most\ntechnological interfaces that require machine-to-human communication.\nFor this type of design, one of the most famous communication models is used, which is one of the\nmost well-known in communication theory. This model suggests that a speaker encodes their thoughts\nby placing them into symbols-words-and a receiver decodes these received words, assigning them\nmeaning. This communication paradigm emerged in the 1950s, focuses on the message, and is called\nthe conduit metaphor [18]. According to this model, meaning exists within the message itself, and\ncommunication is successful if the sender and the receiver share the same rules for encoding and\ndecoding messages. This was one of the first models presented to describe the communication process.\nToday, we know that the exchange of information does not occur in this way [19], but despite this, the\nmodel has shaped the way interaction between humans and machines has often been designed,\nparticularly between humans and linguistic interfaces, such as LLMs, and consequently, generative Al\nsystems.\nThe metaphor of the conduit and the functioning of the prompt as a mode of interaction between\nAl and humans have one thing in common. In fact, in both cases it is taken for granted that the person\nwho is communicating is clear in mind the concept he or she wants to communicate, but the reality is\nnot so clear and defined. Indeed, in human conversation, there is support for the interlocutor to shape\nthe message, its content and meaning continuously and it is evident that in the case of interaction with\na generative Al, for example, this cannot be possible in the current state of development of technology.\nIndeed, during a conversation, implicit feedback is sought from the interlocutor, which can be\nexpressed not only through words, but also through the wide range of non-verbal communication,\nwhich is just as important as verbal communication. The 'effort' of communication is distributed among\nthe interlocutors and the responsibility for the success of the conversation is shared [20].\nToday, interaction via prompts does not allow this type of interaction. In fact, just as interaction\nbetween human beings takes place in the manner just described, so a non-expert user approaches the\nuse of generative Al with this innate mode of conversation. What is sought is a collaborative interaction,\na shared work in which the Al behaves, precisely, like a peer with whom the user is having a\nconversation. There is a need for a shift towards shared control and equal contribution to the\nconversation, [20, 11]. These needs fully reflect the principles and goals of the Human Centered Al\napproach which allows an ethical and usable approach, especially in the long run, for a fruitful and\neffective human-Al interaction. In practice, this approach [20] translates into a necessary redesign of\nconversational interfaces taking into account HCAl principles and the nature of human communication,\nwhich is multimodal."}, {"title": "3. Interface Development", "content": "It became clear how necessary a human-centered approach is for the design of Al systems and beyond\n[1]. Then, the criticalities of the main generative Al systems present today were exposed together with\nan analysis of their functions and use. Next, one of the main ways of interacting with Al, the prompt,\nwas presented, and prompt engineering techniques were analysed, all accompanied by an analysis of\nthe ease of use of the prompt tool and the difficulties non-expert users encounter when interacting\nwith Al.\nAt this stage, it is necessary to shift the focus of observation and focus on another of the components\nof the interaction that can play the role of modifying the satisfaction and success of the interaction\nitself and more generally improve the human-Al systems relationship: the interface.\nIn fact, an interface of a hypothetical generative Al system for text and image generation will be\nproposed below, which attempts to encapsulate the issues discussed so far, considering the\nhumancentered approach, use by non-expert users, intuitiveness, collaboration and the\ncommunication mode through which humans interact."}, {"title": "3.1. The interface as a whole", "content": "With regard to the desktop interface as a whole, we chose to maintain a structure similar to that already\npresent in other generative Al systems and typical of conversational interfaces even before the\nintegration of Al. This makes it possible to maintain consistency between known interfaces of similar\nsystems and to ensure that the user is not disoriented and can recognize buttons and functions present.\nThe name chosen for the application is manifest of its intended purpose: H-gAI, Human generative Al.\nThe interface, see Fig. 1, presents a dialogue screen with most of the space dedicated to chat. On\nthe right-hand side, at the top, there is access to the profile and profile settings and on the left-hand\nside the history of past chats. The floating bar on the left side can be hidden for more chat space.\nThere is also a button to create a new conversation, in addition to the history and the possibility to\nsearch for a chat in the archive.\nChecking the system status. During the conversation, the user is always in control of the state the\nsystem is in, an important principle of human-centered Al system design. In fact, from figure 1 it can be\nseen that there are two indicators useful to the user. The first is located inside the box in which the\ngenerated content is inserted and consists of the warning that the system is generating the response.\nThe other indicator is located at the bottom of the box containing the generated output and indicates\nthe progress status of the content, so the user is always in control of the length of the response and\nthe level of completion of the content.\nWarning: About errors and biased content. A further difference from other generative Al systems is\nfound in the first response message of the Al after the user's first prompt and can be seen in 1 in the\npurple box with white text. This is a warning message that appears every time the user starts a new\nconversation and warns of the possibility of the Al making mistakes and generating results that are\nsubject to different types of bias. As present in the guidelines for the design of human - centered Al\nsystems [21] it is very important to make the user aware of what the Al system can do and its\nlimitations. In other generative Al systems analyzed the reminder about the possibility of making\nmistakes is usually found below the input box of the prompt, while we decided in this case to make it\nmore prominent and actively propose it to the user at every interaction to remind them of the\nimportance of fact-checking and not to assume as true and correct all Al generated content. At the\nsame time it is a message that does not hinder or slow down the interaction.\nReturning to the floating sidebar, in the portion below the history there are links to the project\nfolder and the prompt library. we decided to introduce these two elements to improve workflow and\nuser chat management.\nProjects. The project folder provides access to a real archive, where the user can create folders in which\nto place conversations relating to the same topic, as if it were the computer's local file management.\nIn the generative Al systems analyzed so far, conversations cannot be organized into themes and\nfolders, but we think that for a continuous and wide use of Al systems it can be a useful function to\nkeep an order in the conversations and the materials generated.\nPrompt library. Access to the prompt library, on the other hand, consists of a link to a new page where\nthere is an archive of prompts used and loaded by the users themselves divided into categories, so that\nthe user using the Al system can draw inspiration from or use prompts already used that have\ngenerated a satisfactory result for other users previously. The last elements are found under access to\nprojects and the prompt library: direct access to memory management, user's guide, settings.\nConversational memory. Like some of the best-known generative Al systems present today, we have\nintroduced conversational memory. This function allows for a deeper relationship of the user with the\nAl system and avoids the repetition of ancillary contextual explanations that would slow down the\ninteraction. With this function on the interaction screen the user can always check what has been\nstored by the Al and modify the elements in the memory at will. Still on the subject of memory and\nthe user's full control over the items to be stored, there is a button on the conversation screen, above\nthe prompt entry box, which is always present from the moment a chat is started, allowing the user to\ndecide whether to keep that specific conversation in memory or not. By default, the memory is not\nactivated, so it is up to the user to actively decide as he or she wishes.\nUser's Guide. The user's guide to the use of the Al system is essential for proper interaction and for\nthe user to get the best out of the Al system while maintaining his or her sense of mastery. A\ncomprehensive guide to all the functions present with examples and demonstrations is presented to\nthe user the first time they register. Thereafter, it remains accessible at any time in the floating sidebar.\nInformation and research. To the left of the input box for the prompt is a clickable icon of a question\nmark, see Fig. 1. This icon gives the user access to a box that overlaps the chat and allows searching for\nany item, whether it be a prompt setting or a specific function. From this section, there is also a link to\nsome useful features such as reporting a problem, keyboard shortcuts for some quick functions, privacy\npolicy and the app's terms of service."}, {"title": "3.2. Modes of interaction", "content": "Starting from this basis, which at the same time retains some elements already present in other\ngenerative\nAl interfaces and adds new ones, the reasoning for implementation proceeds both by considering the\nguidelines for the design of Al systems and the principles for the development of human-centred\ngenerative Al.\nOne of the first elements to consider concerns the mode of interaction. We kept the prompt\ninteraction mode alongside the voice interaction mode."}, {"title": "3.2.1. Voice interaction", "content": "Although voice mode does not meet all the needs of use of generative Al systems, it is useful for\nnoncomplex tasks and, as seen above, broadens the possibility of using the Al system, making\ninteraction more accessible and intuitive even for users who have difficulty in writing. Although not\npresent in all generative Al systems in the desktop version, we have chosen to include it, allowing for\nadditional voluntary customisation by the user.\nThe voice interaction mode is activated by clicking on the microphone icon next to the text input\nbox and allows an instant speech-to-text transcription of what the user says. In addition, the response\nprovided by the Al system is also kept in writing in addition to being spoken aloud. Speech interaction\npreferences can be managed by double-clicking on the microphone icon 2.\nA control panel will then open from which certain settings can be managed. It is in fact possible to\nselect from four different types of voices, depending on the user's preference, and it is also possible\nto change the speed at which the voice of the Al system is played. As a final control panel setting, we\nhave included an 'automatic voice assistance' mode.\nVoice assistance. The voice assistance mode, which can be activated from the voice interaction control\npanel, allows voice assistance to intervene in the event of user difficulties.\nThe user can activate this function from the control panel and, during a conversation, if the Al system\nrecognizes after sending a few prompts that the user is unable to express the desired content or is\nunable to create an effective prompt, the Al system will intervene by asking the user if he/she prefers\nto use voice interaction to better express what he/she wants to achieve. The microphone icon will then\nactivate allowing the user to intervene. This is not, however, a function that stops the interaction; the\nuser can disregard the Al's advice and continue writing the prompt.\nEach control panel setting has a detailed explanation of operation that can be reached by clicking\nthe information icon at the end of each function description."}, {"title": "3.2.2. Interaction vAl prompts", "content": "In designing an Al system that would be more human - centered than the existing ones, we still chose\nto retain the interaction mode via prompts. The main reason for this choice is the consistency for the\nuser and the familiarity he or she possesses with both chatbot interaction systems that do not\nintegrate Al, but especially with the generative Al systems already present and in use. Moreover, it\nwould not make sense to disrupt an interaction paradigm that has established itself as the main one\nin human-Al interaction.\nInteraction via prompts occurs as in any other generative Al system: there is, in fact, a text input bar\nin which the user can write his/her requests and then press the enter button to generate the required\ncontent. Up to this point, nothing different from the familiar interfaces is noticeable. To improve the\ninteraction with the Al and amplify the user's sense of control over the operation, there's a control\npanel for this mode of interaction as well, which is activated by pressing the icon next to the\nmicrophone. The control panel opens in a vertical section at the side of the chat, so as not to get in the\nway of the user's flow of conversation, and presents a real dashboard from which the user can control\ncertain parameters of the interaction (Figure 3).\nThe use of the control panel is absolutely optional and the interaction can be successful even without\nthe user controlling the parameters. The presence of this possibility helps, at the same time, to\nmaintain its sense of mastery and to refine the required result.\nWe have divided the user-accessible controls in the control panel into three different sections: i)\nBasic output controls; ii) Response models; iii) Assistance in writing the prompt. Some of the reported\ncontrols, even according to what happens in generative Al systems, seem designed for experienced\nusers. In reality, they are all first described in detail in the user guide, their use is entirely optional, but\nthey represent useful parameters on which to intervene in order to maximize the result the user\ndesires. Basic output controls. In the first section of the control panel, among the basic controls, we\ndecided to include the possibility of changing the language of the generated content by opening the\ndrop-down menu. There are some controls which can also be added directly into the prompt by the\nuser, but which can be selected from a pre-selected menu. It is indeed possible to act on the style, tone\nand length of the content. Adjusting these parameters in advance allows for quick interaction and saves\nthe user a lot of editing once the content has been generated. The user can find eight different types\nof tone, from which he/she can choose: formal, informal, persuasive, neutral (default option),\nempathetic, inspirational, didactic, humorous, and eight types of style: descriptive, formal, informal,\nfriendly, motivational, neutral, creative, instructive.\nA further function, which can be activated by the user in this section, concerns the possibility\nof showing, in the result generated by the Al, the parts of the prompt used to obtain the result to allow\nthe user to see which parts of the input were more or less useful in the generation. This function is\nparticularly useful in a learning phase and when approaching the generative Al system and\nexperimenting with prompting techniques. Providing feedback of this kind makes it possible to improve\nthe interaction and to understand which elements of the prompt were 'successful' in the realization of\nthe content and which details, on the other hand, turned out to be superfluous.\nResponse patterns. As in other generative Al systems when writing the prompt, it is possible to request\nthe Al to take on a certain role (roleplay mode ) when generating the response. We find the possibility\nfor the user to create roles that he or she uses most often and save them in the control panel for easier\nand faster interaction if certain roles are used frequently.\nPrompt writing assistance. As the last section of the control panel, the user can receive assistance\nwhen writing the prompt. Therefore, one of the user's difficulties in writing the prompt lies in\nremembering the important elements that must be entered for the Al system to generate an effective\nresult and to avoid an unnecessarily long conversation. We can notice four of the simplest but\ncomprehensive methods for producing effective prompts from which the user can choose. The Al\nsystem will assist him/her in composition by following him/her step by step: the two prompt writing\nframeworks, COSTAR [22] and CARE\u00b9, together with two basic prompt engineering techniques: Chain\nof Thoughts [23] and Few Shots [24] (Fig. 3)."}, {"title": "3.2.3. End of interaction", "content": "Once the interaction between the user and the Al system is complete, it is possible to perform actions\non the generated response through the clickable icons that appear at the end of the interaction below\nthe content (Fig. 4).\nIt is indeed possible to have a read aloud of the generated answer with a click on the microphone\nicon, it is possible to share the conversation and copy the text, delete the answer or re-generate it. In\naddition to the simple re-generation of the answer, it is possible to perform more precise actions with\na double click of the pointer that opens an interaction box. It is indeed possible, for the response\nobtained, to change the style, tone, length and language with a link to the parameters in the control\npanel seen above."}, {"title": "4. Usability Testing", "content": "In order to test the Figma-based prototype and its functionalities and to reason about the necessary\nmodifications, we carried out a classical usability test with 5 users. During the test, the users had to\nachieve certain goals and during the execution they had to explain aloud the actions they were\nperforming using the Thinking Aloud technique. A tester was always present during the test. The test\nwas divided into three different parts:\n1. In the first part of the test, the tester introduced the participants to the application's\nfunctionality, provided a brief description, and explained the purpose of the test and the tasks\nthey were supposed to complete. The tester also asked if they had ever used a generative Al\nsystem and addressed any questions or doubts they had. This phase lasted approximately 10\nminutes.\n2. During the second phase, each user performed the tasks described below. All users performed\nthe same tasks. During the execution each user described step by step the actions they were\nperforming using Thinking Aloud protocol and at the same time we took notes on their actions,\nexpressions and movements in the interface. This phase lasted a total of 15 minutes.\n3. During the third and final phase of the test, the tester asked all users for general feedback on\ntheir thoughts about the interface and how they used it; the duration of this phase was about 5\nminutes.\nThe tasks assigned to users were as follows:\nTask 1: Change the response style of the Al system: You are on the main page of the Al system and are\nabout to start a conversation. In this app you can set a priori parameters for the response, we ask you\nto change the style of the response.\nTask 2: Change the playback speed of reading aloud: in this Al system you can also interact with voice\ninteraction and you can change parameters on how the Al responds to you, change the playback\nspeed. Task 3: Response regeneration: you have a chat but you are not satisfied with the response\nand want to regenerate it and change the style.\nTask 4: Search for how to delete chat history. You are on the Al system and want to do a general search,\ne.g. you want to search how to delete the history.\nUpon completion of the tasks, we assigned each participant a score on a scale of 1 to 3, where 1\nmeans that the task was not completed, 2 that it was completed with some difficulty, 3 that it was\ncompleted quickly and without difficulty, see Table 4. We also included the age group and an 'exp'\ncolumn indicating experience, i.e. whether the users had ever used a generative Al system"}, {"title": "5. Discussion and Conclusion", "content": "The user test was very useful, providing insights into both the strengths and areas for improvement in\nthe design. The similarity between the presented system and familiar generative Al systems or chatbots\nhelped users recognize icons and functions easily. However, some features placed on the main screen\nto simplify the user experience caused confusion, as many users resorted to the settings to adjust\nparameters. This highlighted the necessity of having a clear and complete user guide readily available\nto help users understand how to perform various actions.\nTask execution times were longer in the first task, averaging 52 seconds, likely due to a lack of\nfamiliarity with the interface. However, the times improved with each subsequent task, dropping to\n30.2 seconds by the fourth task, indicating increasing comfort with the system. Task 4, being more\ncomplex, had the highest failure rate at 80% underscoring the importance of a more intuitive interface\nand clearer guidance, especially regarding the functions near the prompt input box.\nThe test emphasized the importance of balancing additional functions on the main screen while\nmaintaining familiar reference points for users. This balance is crucial for user confidence and ease of\nnavigation. The results suggest that human-centered interfaces for generative Al systems will become\nmore common, with a focus on providing intuitive, user-friendly designs and comprehensive guides to\nhelp users fully understand the system's capabilities.\nThe proposal aims to apply human-centered design principles to create a feasible, user-friendly\ninterface for generative Al systems, without disrupting existing design practices. It focuses on\nenhancing user control and awareness during Al interactions, highlighting both the user's ability to\nmaster the system and the potential mistakes Al can make. The goal is to foster collaboration, co-\ncreativity, and sustainable interaction, emphasizing human-Al collaboration in a work environment. A\nhuman-centered approach will be crucial for the success of the third wave of Al, which seeks to create\na holistic and ethical paradigm for human-Al collaboration, leading to better outcomes through\ncollective efforts."}]}