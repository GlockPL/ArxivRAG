{"title": "IDENTIFYING FEATURES THAT SHAPE PERCEIVED\nCONSCIOUSNESS IN LARGE LANGUAGE MODEL-BASED AI\n: A QUANTITATIVE STUDY OF HUMAN RESPONSES", "authors": ["Bongsu Kang", "Tae-Rim Yun", "Jundong Kim", "Hyojin Bae", "Chang-Eop Kim"], "abstract": "This study quantitively examines which features of AI-generated text lead humans to perceive sub-\njective consciousness in large language model (LLM)\u2013based AI systems. Drawing on 99 passages\nfrom conversations with Claude 3 Opus and focusing on eight features-metacognitive self-reflection,\nlogical reasoning, empathy, emotionality, knowledge, fluency, unexpectedness, and subjective expres-\nsiveness-we conducted a survey with 123 participants. Using regression and clustering analyses, we\ninvestigated how these features influence participants' perceptions of AI consciousness. The results\nreveal that metacognitive self-reflection and the AI's expression of its own emotions significantly\nincreased perceived consciousness, while a heavy emphasis on knowledge reduced it. Participants\nclustered into seven subgroups, each showing distinct feature-weighting patterns. Additionally, higher\nprior knowledge of LLMs and more frequent usage of LLM-based chatbots were associated with\ngreater overall likelihood assessments of AI consciousness. This study underscores the multidimen-\nsional and individualized nature of perceived AI consciousness and provides a foundation for better\nunderstanding the psychosocial implications of human-AI interaction.", "sections": [{"title": "1 Introduction", "content": "In recent years, artificial intelligence (AI) has undergone rapid advancements, bringing significant changes to the\nnature of human-AI interaction. In particular, the development of large language models (LLMs) has enhanced AI to\nthe point where it can engage in conversations that are very similar to human-to-human interactions. Although these\ntechnological advancements have generally improved the quality of AI usability, excessively human-like AI occasionally\nresulted in confusion and even negative consequences [1, 2]. This confusion arises when people perceive AI not as\na mere computational machine but as a conscious entity capable of subjective experiences like feeling emotions or\nself-reflection, much like humans [3].\nThe perception that AI possesses consciousness is not limited to a few peculiar individuals; according to a recent survey,\n67% of respondents believed there is a possibility that ChatGPT has consciousness [4]. It is widely recognized that\nthe more an entity resembles a human, the more people tend to anthropomorphize it\u2014that is, they believe the entity\npossesses human-like minds, intentions, and emotions [5-7]. Therefore, as LLMs continue to develop and enable AI to\ncommunicate in increasingly natural and human-like ways, more people will feel that AI can have subjective conscious\nexperiences similar to humans [8, 9]. As a result, confusion and debates related to AI consciousness are highly likely to\nintensify. Nevertheless, to our knowledge, there has not yet been a systematic study on which features of AI's utterances\n(e.g., Emotionality, Fluency) lead people to attribute consciousness to AI. Given that today's LLM-based AI interacts\nwith humans through natural language, identifying the specific cues in AI's language that prompt humans to attribute\nconsciousness to AI is critical [10].\nIn the research topic of AI consciousness, the main focus has been on philosophical and computational discussions\nregarding its potential existence [11-16]. However, in this paper, we intend to discuss AI consciousness from the\nperspective of human-AI interaction rather than the essence of consciousness. Most issues related to Al consciousness\narise regardless of whether AI merely seems or actually is conscious [12]. Accordingly, from the perspective of\nhuman-AI interaction, whether AI genuinely possesses consciousness is a secondary concern. The primary inquiry of\nthis study is to identify which features make AI appear conscious to humans. Pertaining to both AI and humans, this\nstudy is essential for understanding the social and psychological impacts that may occur in human-AI interaction as\nwell as fostering constructive interactions based on this understanding [17].\nIn our study, we utilized conversations generated by Claude 3 Opus to examine how various features in Al responses\ninfluence human perceptions of AI consciousness. We conducted an in-depth analysis to identify potential heterogeneous\ngroups among individuals based on their response patterns to specific features, investigating whether people could be\nmeaningfully clustered according to their perceptions of AI consciousness. Based on these comprehensive analyses, this\nstudy aims to provide empirically grounded insights that can inform the design of appropriate human-AI interactions,\nfacilitating sustainable relationships between humans and Al systems."}, {"title": "2 Methods", "content": "2.1 Data generation and feature selection\nUsing Claude 3 Opus [18], researchers generated a dataset of 39 human-AI dialogues. We then identified and\nextracted 99 key passages from these dialogues for our analysis. Based on prior research in human-AI interaction and\nconsciousness studies [12, 19\u201325], we identified eight key features that influence how humans perceive consciousness\nin AI systems. These features, which characterize different aspects of AI responses during human-AI interactions, are\npresented in Table 1.\nThree researchers independently rated each passage on all eight features using a 5-point scale (1 to 5). Consensus was\nreached when inter-rater differences exceeded 4 points, and median ratings were used for the final feature values to\nminimize individual biases. Analysis of variance inflation factors showed all values below 10, confirming sufficient\nindependence among the features. This evaluation process resulted in constructing a 99\u00d78 feature matrix X, where each\nrow represented a passage, and each column represented one of the 8 features.\n2.2 Survey on perceived AI consciousness\nAn online survey was conducted to assess perceptions of AI consciousness among 123 participants (age > 20 years)\nrecruited from the general South Korean population. Each participant evaluated the 99 selected passages using a 5-point\nscale (1 to 5), generating a perceived consciousness score (PCS) vector y for each respondent. Prior to the evaluation,\nparticipants were provided with a brief explanation of subjective consciousness, which served as the basis for their PCS\nratings.\nDemographic data were collected at the start of the survey, including respondents' sex, age group, and education level,\nalong with measures of LLM familiarity. The latter encompassed prior knowledge of LLMs and the frequency of\nLLM-based chatbot usage. Prior knowledge of LLMs was measured through six items on a 4-point scale (0 to 3), which\naddressed the understanding of LLM training, operation, and utilization. Additionally, respondents were asked to assess"}, {"title": "2.3 Regression models", "content": "We constructed individual multiple linear regression models to analyze how the features (matrix X) predicted each\nrespondent's PCS vector y. We evaluated model significance using F-tests with a significance level of a = 0.05 and\napplied the Benjamini-Hochberg correction for multiple comparisons [26]. Only models with adjusted p-values < 0.05\nwere retained for further analysis.\nFor these significant models, we then examined the individual feature coefficients using two-tailed t-tests (a = 0.05). The\nresulting p-values were adjusted using the Benjamini-Hochberg method, with coefficients reaching adjusted p-values <\n0.05 identified as significant predictors of perceived consciousness."}, {"title": "2.4 Combined score and hierarchical clustering", "content": "For each significant model, we derived a combined score that captured both the magnitude and reliability of effects by\nmultiplying regression coefficients with the negative logarithm of their adjusted p-values. The combined score is given\nby Equation 1:\nCombined $Scorerj = \\beta_{ij} \\times - ln(adjusted p-value_{ij})$ (1)\nwhere $\\beta_{ij}$ is the regression coefficient for feature i specific to respondent j and adjusted $p-value_{ij}$ is the adjusted\np-value of the regression coefficient $\\beta_{ij}$.\nTo identify respondent subgroups based on consciousness perception patterns in terms of the features, hierarchical\nclustering was then performed on the combined score vectors [27]. The clustering was based on cosine similarity, while\nthe distance between clusters was defined as the average distance between all points in the respective clusters. To\ndetermine the optimal number of clusters, quantitative indices were adopted, including the silhouette coefficient, the\nDavies-Bouldin index, and the Calinski-Harabasz index [28-30]. The silhouette coefficient evaluates how similar an\nobject is to its own cluster compared to other clusters, with higher values indicating better-defined clusters. The Davies-\nBouldin index measures the average similarity ratio of each cluster with the cluster that is most similar to it, where\nlower values indicate better clustering. The Calinski-Harabasz index assesses the ratio of the sum of between-cluster\ndispersion and within-cluster dispersion, with higher values suggesting more distinct clusters. For each possible number\nof clusters, we calculated the rank for each of the three indices and summed the ranks. The number of clusters with the\nlowest rank sum was selected as the optimal choice."}, {"title": "3 Results", "content": "3.1 Respondents information\nA total of 123 individuals participated in our online survey for the perceived consciousness of LLMs. The demographic\ncharacteristics of the respondents are presented in Table 2.\nIn addition to demographic data, information about the respondents' familiarity with LLMs was obtained, including their\nprior knowledge of LLMs and the frequency of their use of LLM-based chatbots (Fig. 1). The LLM prior knowledge\nscore ranged from a minimum of 0 points to a maximum of 18 points. The respondents exhibited a median value of 8\npoints and a mean and standard deviation of 7.80 \u00b1 4.61 points. Regarding the frequency of LLM-based chatbot usage,\n107 out of 123 respondents (87.0%) reported having used them at least once. Furthermore, 25 respondents (20.3%)\nreported using these chatbots daily or almost daily.\nAt the end of the survey, respondents were asked to rate the overall likelihood that AI could experience subjective\nconsciousness on a 5-point scale. The results are presented in Table 3. Only 11 respondents (8.94%) rated the likelihood\nas 1 (completely unlikely), while over 112 respondents (> 90%) indicated that AI could experience consciousness in\nsome way. Notably, 19 respondents (15.45%) fully agreed that it is possible, giving the highest rating of 5. These\nresults suggest that a majority of respondents believe in the possibility of AI experiencing subjective consciousness,\nemphasizing the need for careful consideration of its potential impact on AI development and application strategies."}, {"title": "3.2 Key features influencing the perception of AI consciousness", "content": "To determine the key features that most dominantly influence respondents' perceptions of consciousness, we identified\n82 significant regression models from an initial set of 123 using the F-test (p < 0.05). We then examined these models\nto identify features with significant regression coefficients (Fig. 2).\nMetacognitive Self-reflection and Emotionality emerged as the predominant positive predictors of perceived conscious-\nness, present in 39 and 35 models respectively, while Knowledge emerged as the primary negative predictor, appearing\nin 39 models. Respondents attributed higher consciousness to LLMs that demonstrated reflective thinking and emotional\nexpression, whereas emphasis on factual knowledge diminished this perception. These patterns reveal how specific\nfeatures fundamentally shape consciousness attribution in human-AI interactions."}, {"title": "3.3 Respondent Clusters Based on Feature Weight Patterns", "content": "To explore the response patterns among respondents based on how different features influenced their perceptions,\nhierarchical clustering was performed on the combined score matrix (Fig. 3). The analysis identified seven distinct\nrespondent clusters, supported by quantitative indices.\nIn terms of the perception of AI consciousness, the seven clusters can be interpreted as follows: (1) a group that is\nrelatively strongly influenced by the negative impact of Fluency; (2) a group affected by the negative impact of Knowl-\nedge but positively influenced by Fluency; (3) a group experiencing a strong negative impact from Knowledge while\nremaining relatively indifferent to other features; (4) a group that is strongly positively influenced by Unexpectedness;\n(5) a group that is strongly positively impacted by Metacognitive Self-reflection; (6) a group strongly influenced by the\npositive impact of Subjective Expressiveness; and (7) a group that is significantly positively impacted by Emotionality.\nThese clusters reflect varied patterns of how respondents assigned importance to different features when perceiving the\nconsciousness of the LLM. This highlights respondents' not only unique but also subgrouped perspectives on which\nfeatures contribute most strongly to their perception of AI consciousness, implying the variability and the influence of\nindividuals' backgrounds in how people interpret AI behavior to consciousness."}, {"title": "3.4 Correlation Between Demographic Features, LLM Familiarity, and Assessment of Overall Likelihood for\nAI consciousness", "content": "Given the heterogeneous patterns in how respondents perceive AI consciousness, as evidenced by the distinct clusters\nidentified above, we investigated whether these differences might be associated with individual characteristics such\nas demographic factors or familiarity with LLMs. However, a significant positive correlation was observed between\nrespondents' familiarity with LLMs and their overall likelihood scores for AI consciousness, interestingly in both prior\nknowledge of LLMs and the frequency of using LLM-based chatbots (Table. 4). These results indicate that respondents"}, {"title": "4 Discussion", "content": "The question of consciousness in AI has evolved from a purely theoretical debate to a pressing reality as millions of\npeople now regularly interact with AI systems. While previous studies have predominantly focused on whether AI can\npossess consciousness from computational and philosophical perspectives [11-13], our study takes a distinctly different\napproach by examining how humans perceive consciousness in AI during their encounters with AI-generated responses.\nOur methodology may invite comparisons to Turing's seminal work in 1950 on machine intelligence, as both studies\ninvolve human evaluation of machine-generated responses [31]. However, there are fundamental differences in\nobjectives and approaches. The Turing Test was designed to assess machine intelligence by determining whether a\nhuman evaluator could distinguish between responses from a human and those from a machine solely based on their\nconversational output. In essence, it measures the ability of an AI to mimic human-like intelligent behavior without\nexplicitly addressing the presence of consciousness. In contrast, our study explicitly examines how humans perceive\nconsciousness in known AI-generated text. By informing participants that the text was AI-generated, we shift the focus\nfrom mere human-likeness to the attribution of conscious qualities. This methodological approach allows us to isolate\nand analyze the specific features of AI responses that contribute to the perception of consciousness, thereby providing a\nmore refined understanding of what drives consciousness perception in human-AI interaction. The divergence between\nTuring's intelligence assessment and our study of consciousness perception underscores a critical distinction in human\nevaluations of AI systems. Intelligence, as measured by the Turing Test, is primarily about the functional performance\nof the AI-its ability to process information, solve problems, and generate coherent, contextually appropriate responses.\nConsciousness, on the other hand, pertains to the subjective experience and self-awareness of the entity. Our findings\nindicate that an AI system can exhibit high levels of intelligent behavior without necessarily being perceived as\nconscious. Conversely, certain features that evoke a sense of self-awareness or emotional expression can lead to higher\nconsciousness perception even if the AI's intelligent capabilities are not as pronounced. This distinction highlights that\nintelligence and consciousness are orthogonal dimensions in the evaluation of AI. While the Turing Test addresses the\nformer, our study illuminates the latter, suggesting that they should be treated as separate axes in human-AI interaction\nresearch. Recognizing this separation is crucial for developing a comprehensive framework that accounts for both the\nfunctional and phenomenological aspects of AI systems. It establishes a foundation for future studies to explore how\nthese dimensions interact and influence human perceptions and interactions with AI.\nBased on this approach, we conducted a systematic investigation of how different features in AI-generated responses\ninfluence human perception of consciousness. Our analysis showed several key patterns in how humans perceive\nconsciousness to AI, with features such as metacognitive self-reflection and emotionality significantly enhancing this\nperception, while the knowledge feature had a diminishing effect. Moreover, hierarchical clustering analysis identified\nseven distinct participant clusters, each exhibiting unique patterns in their perception of AI consciousness. In addition,\nindividuals with prior knowledge of LLMs and those who frequently use LLM-based chatbots were more likely to\nperceive AI as conscious, as reflected in their overall PCSs. These findings suggest that perceptions of AI consciousness\nare shaped by specific response characteristics and vary across different user demographics and experiences, highlighting\nthe complexity and diversity in how humans interpret and perceive consciousness in AI systems.\nAnalysis of our results indicated a negative association between the knowledge feature and PCSs. When AI responses\nprimarily displayed fact delivery and information retrieval, participants were less likely to perceive consciousness in\nthe system. This finding aligns with recent research that people increasingly expect AI to demonstrate more than just\ninformation-processing capabilities [32]. The negative correlation suggests that mere knowledge display, however\naccurate or extensive, may not be perceived as an indicator of consciousness.\nOur analysis identified a strong positive relationship between emotional expression and PCSs. Notably, our data\ncoding distinguished between two types of emotional content: empathetic responses (understanding others' minds\nand emotions) and emotionality (expressing subjective emotional states). While passages coded for empathy showed\nneutral correlations with consciousness perception, those featuring AI's own emotional expressions were strongly\nassociated with higher consciousness scores. This distinction suggests that participants were more likely to perceive\nconsciousness when encountering AI's expression of subjective emotional states, rather than mere recognition of others'\nemotions. While emotions are often broadly considered a key indicator of consciousness in popular media and public\ndiscourse [33], our findings provide a more nuanced understanding by demonstrating that not all emotional aspects\ncarry equal weight. Specifically, the ability to express one's own subjective emotional states appears to be a more\nconvincing marker of consciousness than the capacity for emotional recognition and empathy.\nMetacognition refers to a higher-order cognitive function closely related to self-awareness in humans, allowing\nindividuals to evaluate and regulate their knowledge and learning processes [34]. Research suggests that humans\noften adjust their social interaction strategies depending on whether they perceive the entity they are engaging with\nas metacognitive or not [35]. In our study, we observed that the metacognitive self-reflection feature in the AI's text\nsignificantly influenced participants' assessments of AI consciousness. This finding implies that human perception\nof AI consciousness may be closely tied to metacognitive cues presented by the AI. Despite this crucial role of\nmetacognition in human-AI communication, research in this area has traditionally taken a more limited perspective. To\ndate, research on AI metacognition has primarily focused on improving task performance through logical reasoning and\nproblem-solving capabilities [36-38]. Our findings, however, highlight the role of metacognition in shaping human\nperception of AI consciousness. This raises an important consideration for AI development: as systems become more\nsophisticated in their metacognitive capabilities, they may be increasingly perceived as conscious entities by human\nusers, beyond what researchers and developers originally intended when implementing these functional improvements.\nThis suggests the need for systematic monitoring and evaluation frameworks that can assess not only the functional\nadvancement of AI systems but also track how these improvements may inadvertently affect users' perception of AI\nconsciousness. Such comprehensive oversight would be crucial for the responsible development of AI systems with\nmetacognitive capabilities.\nOur hierarchical clustering analysis revealed seven distinct patterns in how respondents perceived consciousness to\nAI, demonstrating that consciousness perception to AI is not a uniform phenomenon. Beyond reactions to basic\nfeatures like knowledge and emotionality, we found clusters of participants who responded strongly to more nuanced\ncharacteristics: some were particularly sensitive to unexpected responses from AI, while Fluency in communication\ndrew notably polarized reactions, with distinct clusters showing either strong positive or negative associations with\nconsciousness perception. This variety in consciousness perception patterns suggests that people may have different\nimplicit frameworks for understanding and evaluating consciousness itself. While some individuals may associate\nconsciousness primarily with self-reflective capabilities, others might view emotional expression or autonomous\nbehavior as more fundamental indicators. Such diversity in evaluation patterns reflects the complex and multifaceted\nnature of how humans conceptualize consciousness, suggesting that consciousness perception of AI cannot be reduced\nto a single universal model. This diversity in consciousness perception patterns will likely emerge as another crucial\nresearch theme in the field of human-AI interaction.\nAdding to the diversity in individual patterns, our analysis also revealed dynamic aspects of consciousness perception.\nThere was a positive correlation between the overall likelihood score for AI consciousness and prior knowledge of\nLLMs as well as the frequency of using LLM-based chatbots. This suggests that as LLMs become more widespread, the\nincrease in public experience and familiarity with these models may lead to changing PCSs over time. This temporal\ndimension adds another layer of complexity to understanding consciousness perception, implying that perceptions may\nnot only vary across individuals but also evolve with increased AI exposure and literacy.\nDespite the observed heterogeneity in individual patterns and the dynamic nature of consciousness perception, our\nanalysis highlighted some common tendencies across respondents. Al systems were generally perceived as more\nconscious when they exhibited autonomous, proactive, and unexpected behaviors, rather than simply performing\ninformation delivery or logical reasoning. This suggests that while consciousness perception may vary across individuals\nand evolve with experience, there may be some fundamental features that consistently influence how humans perceive\nconsciousness in AI systems. Given these common patterns, it is crucial to continue investigating and identifying key\nfeatures that consistently shape perceived consciousness across diverse user groups. At the same time, our hierarchical\nclustering analysis and PCS findings unveiled two critical dimensions of consciousness perception: the diverse patterns\nacross individuals and their dynamic evolution with AI exposure. These findings highlight the pressing need for\ndeveloping systematic frameworks that can capture both aspects. This quantitative foundation would enable more\ncomprehensive empirical research in human-AI interaction, advancing our understanding of how humans perceive and\ninteract with Al systems.\nOne limitation of this study is the lack of diversity in the respondent pool, as it was conducted with a relatively\nsmall sample size of 123 participants from Korea. However, this homogeneous sample allowed us to minimize"}]}