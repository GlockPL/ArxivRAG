{"title": "Data Selection for Task-Specific Model Finetuning", "authors": ["Zifan Liu", "Amin Karbasi", "Theodoros Rekatsinas"], "abstract": "Finetuning foundation models for specific tasks is an emerging paradigm in modern machine learning. The efficacy of task-specific finetuning largely depends on the selection of appropriate training data. We present a framework to select data for task-specific model finetuning, guided by a small but representative set of examples from the target task. To do so, we formulate data selection for task-specific finetuning as an optimization problem with a distribution alignment loss based on optimal transport to capture the discrepancy between the selected data and the target distribution. In addition, we add a regularizer to encourage the diversity of the selected data and incorporate kernel density estimation into the regularizer to reduce the negative effects of near-duplicates among the candidate data. We connect our optimization problem to nearest neighbor search and design efficient algorithms to compute the optimal solution based on approximate nearest neighbor search techniques. We evaluate our method on data selection for both continued pretraining and instruction tuning of language models. We show that instruction tuning using data selected by our method with a 1% selection ratio often outperforms using the full dataset and beats the baseline selection methods by 1.5 points in F1 score on average.", "sections": [{"title": "1 Introduction", "content": "Finetuning foundation models [3] is the de-facto paradigm for building machine learning applications that focus on specific tasks. Models such as BERT [10] and LLaMA [43] are large-scale models pretrained on massive unlabeled data across a wide range of domains. Those models can be specialized to downstream tasks through finetuning. Finetuning can take a variety of forms depending on the target task. For instance, continued pretraining [17] extends the pretraining stage of a model on a dataset that is more closely related to a target domain. As another setting, instruction tuning [51] trains a generative foundation model on instruction-response pairs to improve its performance in responding to task-specific instructions.\nFinetuning foundation models can lead to significant improvement in downstream tasks, but the effectiveness heavily relies on the right choice of training data [17, 30, 48, 47]. However, the data repositories that one considers during training of generative models tend to be large\u2014consider for example the use of Common Crawl\u00b9, which contains 250 billion web pages, or The Pile [14]\u2014and"}, {"title": "2 Background and Overview", "content": "In this section, we provide background information that is essential for the problem, followed by a formal statement of the problem and an overview of our proposed framework."}, {"title": "2.1 Background", "content": "We introduce the notations that will be used throughout the paper and the optimal transport problem.\nNotation We use $\\mathbb{R}_{>0}$ to represent the set of non-negative real numbers, and $\\mathbb{R}_{>0}$ to represent the set of positive real numbers. Let $N$ be a positive integer and we use $[N]$ to denote the set of integers from 1 to $N$. We use bold letters to denote matrices and the corresponding plain letters with subscripts to denote the entries in the matrix. For example, $\\mathbf{y} \\in \\mathbb{R}^{M \\times N}$ is a matrix with size $M \\times N$, and $y_{ij}$ or $y_{i,j}$ is the entry in the $i^{th}$ row and the $j^{th}$ column (1-indexed)."}, {"title": "Optimal Transport between Discrete Distributions", "content": "We introduce the optimal transport problem, which forms the basis of our data selection framework. Let $(A, f)$ be a metric space where $A$ is a finite set and $f : A \\times A \\rightarrow \\mathbb{R}_{>0}$ is a distance function. Consider two discrete distributions $\\mu$ on $U \\subset A$ and $\\nu$ on $V \\subset A$, where both $U$ and $V$ are finite sets. Let $u_i$ be the $i^{th}$ example in $U$ and $\\mu_i = \\mu(u_i)$ be the probability of $u_i$. Similarly, let $v_j$ be the $j^{th}$ example in $V$ and $\\nu_j = \\nu(v_j)$ be the probability of $v_j$. Let $\\gamma \\in \\mathbb{R}_{>0}^{|U|\\times|V|}$ be a transport of probability mass between $\\mu$ and $\\nu$, where $\\gamma_{ij}$ is amount of probability mass transported from $u_i$ to $v_j$. Assume that the cost of transporting one unit of probability mass from $u_i$ to $v_j$ is $f(u_i, v_j)$, the distance between $u_i$ and $v_j$. Optimal transport is the problem of transporting all the probability mass from $U$ to $V$ with a minimal cost:\n$\\min_{\\gamma \\in \\mathbb{R}^{|U|\\times|V|}_{\\ge 0}} \\sum_{i=1}^{|U|} \\sum_{j=1}^{|V|} \\gamma_{ij}f(u_i, v_j) \\text{ subject to } \\sum_{j=1}^{|V|} \\gamma_{ij} = \\mu_i, \\forall i \\in [[U]], \\sum_{i=1}^{|U|} \\gamma_{ij} = \\nu_j, \\forall j \\in [[V]]$"}, {"title": "2.2 Task-Specific Data Selection Problem Statement", "content": "We now introduce the problem of data selection for task-specific finetuning. We assume access to a set of $M$ representative examples $Q = \\{q_i\\}_{i=1}^M$ from the target task, which we call query examples. Consider a data repository $D = \\{x_j\\}_{j=1}^N$ containing $N$ candidate examples. Note that $Q$ and $D$ are multisets that may contain duplicates. We aim to select $B$ examples from the repository guided by the query examples. The selected examples will be used to finetune a model to tailor it to the target task. We adopt the model-agnostic formulation above for the generality of the solution. However, our framework can be applied to model-specific selection by using model-specific data representations; an example evaluation for model-specific instruction tuning is presented in Section 5.1."}, {"title": "2.3 Framework Overview", "content": "Our framework takes the candidate examples and the query examples as inputs and outputs a set of task-specific examples by the following workflow. 1. (Encoding) We first encode the query examples and the candidate examples into the same metric space with a specified distance function. 2. (Probability Assignment) We determine the probability mass assigned to each candidate example by solving an optimization problem. 3. (Sampling) We take a random sample with replacement from the candidate examples following a categorical distribution where the probability is determined by the assignment in the previous step."}, {"title": "3 Data Selection and Optimal Transport", "content": "Data selection for task-specific finetuning can be expressed as an optimization problem for proba- bility assignment to the candidates in the data repository. First, we discuss the formulation of the optimization problem and then show the existence of closed-form solutions. In addition, we propose a regularization term that addresses the problem of near-duplicates among the candidates. The proofs of the theorems in this section are provided in Appendix B."}, {"title": "3.1 Optimization Problem", "content": "Consider the metric space $(Z, f)$ where $Z = Q \\cup D$ contains all the examples and $f : Z \\times Z \\rightarrow \\mathbb{R}$ is a distance function. Let $d \\in \\mathbb{R}^{M \\times N}$ be the distance matrix, where $d_{ij} = f(q_i, x_j)$ is the distance between the $i^{th}$ query example and the $j^{th}$ candidate example.\nWe propose an optimization problem that transports probability mass from the query examples to the candidates. The objective is a linear combination of a probability transport cost for distribution alignment and a regularization term to encourage diversity. Formally, given $d \\in \\mathbb{R}^{M \\times N}$, we consider the following optimization problem, which we refer to as Problem RT (regularized transport):\n$\\min_{\\gamma \\in \\mathbb{R}^{M \\times N}_{\\ge 0}} \\frac{\\alpha}{MN} \\sum_{i=1}^M \\sum_{j=1}^N \\gamma_{ij} d_{ij} + (1 - \\alpha)G(\\gamma) \\text{ subject to } \\sum_{j=1}^N \\gamma_{ij} = \\frac{1}{M}, \\forall i \\in [M]$"}, {"title": "3.2 Closed-Form Solution", "content": "When $G = G_{\\infty}$, Problem RT can be solved by standard linear programming techniques, but they run in $\\Omega((MN)^2)$ time, which is prohibitively expensive. Instead, we show the existence of a closed-form solution that can be computed in $O(MN \\log N)$ time (see Section 4 for the algorithm).\nUsing $G_{\\infty}$ as the regularization function, we get an optimal solution by transporting the probability of each query example evenly to its $K$-nearest neighbors among the candidates, where $K$ is determined by the tradeoff between distribution alignment and diversity:\nTheorem 3.1. Given $d \\in \\mathbb{R}^{M \\times N}$ where $N > 1$, consider Problem RT with $G(\\gamma) = G_{\\infty}(\\gamma) = \\frac{C}{M} \\max_{i\\in[M],j\\in[N]} |\\gamma_{ij} - \\frac{1}{MN}|$. For all $i \\in [M]$, let $j_1,...,j_N$ be a reordering of $[N]$ such that $d_{ij_1} < ... < d_{ij_N}$. Consider $\\gamma^* \\in \\mathbb{R}^{M \\times N}_{\\ge 0}$ whose entries are $\\frac{1}{KM}$ if $j \\in \\{j_1,...,j_K\\}$ and $0$ otherwise, where $K = \\max\\{k \\in [N]|\\sum_{l=1}^{k}(d_{ij_{l+1}} - d_{ij_l})< (1 - \\alpha)M\\}$. Assume $K < N/2$, and then $\\gamma^*$ is a minimizer of Problem RT. $\\gamma^*$ is the unique minimizer if $\\sum_{l=1}^{K+1}(d_{ij_{l+1}} - d_{ij_l}) > (1 - \\alpha)M$ and $\\exists i \\in [M]$ such that $d_{ij_{K+1}} = d_{ij_K}$.\nSimilarly, there exists a closed-form solution that can be computed in $O(MN \\log N)$ time when $G = G_{TV}$ (see Appendix A for the solution and the algorithm)."}, {"title": "3.3 Addressing Near-Duplicates via Kernel Density Estimation", "content": "When there exists a large fraction of near-duplicates among the candidates, $G_{\\infty}$ fails to charac- terize the diversity of probability assignment since it treats near-duplicates as distinct examples. Consequently, the contents in the near-duplicates will be over-sampled. For example, if 100 of the K-nearest neighbors of a query example are duplicates and the others are distinct, the content in the duplicates will receive 100 times as much probability mass as any other example.\nTo address the near-duplicate problem, we propose a regularization function incorporating kernel density estimation (KDE) [36], which is a non-parametric method to estimate the probability density function from finite examples. We determine the duplication level of a point by the kernel density estimate at its position. We use the Epanechnikov kernel such that given $D$, the density estimate at point x is $\\sum_{x' \\in D} \\frac{1}{h^d} K(\\frac{x - x'}{h}) = \\sum_{x' \\in D} \\frac{1}{h^d} \\text{max}(1 - \\frac{f(x)}{h^2}, 0)$, where $h > 0$ is the kernel size and $f$ is the distance function. For example, for a point x in $D$ whose distance to any other point is larger than h, the density estimate at x is 1. If we create two duplicates of x and add them to D, the density estimate at x increases to 3.\nOur KDE-based regularization function is $G_{KDE}(\\gamma) = M \\max_{i \\in [M], j \\in [N]} p_j|\\frac{\\gamma_{ij}}{\\sum_{j' \\in [N]} \\gamma_{ij'}} - \\frac{1}{MN}|$, where $p_j = \\sum_{x' \\in D} K(\\frac{x_j - x'}{h})$ is the density estimate at $x_j$. $G_{KDE}(\\gamma)$ compares $\\gamma$ to the probability assignment that is proportional to the inverse of the density, and penalizes the largest gap weighted by the density. Note that $G_{\\infty}$ is a special case of $G_{KDE}(\\gamma)$ with $p_j = 1$ for all $j \\in [N]$.\nThe optimal solution to Problem RT when $G = G_{KDE}$ can be obtained by assigning the probability mass of each query example to the nearest neighbors among the candidates, weighted by the inverse of their density estimate, as is shown by the following theorem.\nTheorem 3.2. Given $d \\in \\mathbb{R}^{M \\times N}$ and $p_1,...,p_v \\in \\mathbb{R}_{>0}$, consider Problem RT with $G(\\gamma) = G_{KDE}(\\gamma) = M \\max_{i \\in [M], j \\in [N]} p_j|\\frac{\\gamma_{ij}}{\\sum_{j' \\in [N]} \\gamma_{ij'}} - \\frac{1}{M\\sum_{j' \\in [N]} 1/p_{j'}}|$, For all $i \\in [M]$, let $j_1,...,j_k$ be a reordering of $[N]$ such that $d_{ij_1} \\le ... \\le d_{ij_N}$. Let $s_k = \\sum_{l=1}^k 1/p_{j_l}$, and $s$ be a discrete variable that takes value from $S = \\{s_k|i \\in [M], k \\in [N]\\} \\cup \\{0\\}$. Let $c(s) = \\sum_{i=1}^M c_i(s)$, where $c_i(s) = 0$ if $s \\le s_1$ and $c_i(s) = \\frac{1}{p_{j_k}}$ if $s_{k-1} < s < s_k$ for any $k > 2$. Let $s^* = \\text{max}\\{s \\in S| c(s) \\le (1 - \\alpha)M\\}$, and $K_i = \\text{max}\\{k \\in \\{0, ..., N - 1\\}|s_k \\le s^*\\}$. Assume $s^* < \\sum_{j=1}^N 1/p_j$, and then $\\gamma^*$ is a minimizer of Problem RT where $\\forall i \\in [M], k \\in [N]$:\n$\\gamma^*_{i,j_k} = \\begin{cases} \\frac{1}{M s^* p_{j_k}}, & \\text{if } k \\le K_i \\\\ \\frac{1}{M \\sum_{l=1}^{K_i + 1} 1/(M s^* \\cdot p_{j_l})}, & \\text{if } k = K_i + 1 \\\\ 0, & \\text{otherwise} \\end{cases}$\n$\\gamma^*$ is the unique minimizer if $\\nexists s \\in S \\text{ such that } c(s) = (1 - \\alpha)M \\text{ and } \\exists i \\in [M] \\text{ such that } d_{ij_k} = d_{ij_{k+1}} \\text{ or } d_{ij_{k+1}} = d_{ij_{k+2}}^*$.\nIntuitively, we count candidate $x_j$ as $1/p_j$ examples. For each query example, the optimal solution assigns probability mass to the candidates in its neighborhood proportional to their adjusted counts. The size of the neighborhood is determined by the limit $s^*$ on the sum of the adjusted counts.\nIn Figure 1, we show an example comparing the optimal transport with $G_{\\infty}$ and $G_{KDE}$. When $G = G_{\\infty}$, the probability is transported uniformly to the candidates regardless of their relative positions. When $G = G_{KDE}$, the clustered candidates receive less probability due to their high density, and they will be less over-represented when we take samples according to the assigned probability."}, {"title": "4 Efficient Probability Assignment Algorithms for Data Selection", "content": "We propose efficient algorithms to assign probability mass to the candidates according to the optimal solutions to Problem RT. For $G = G_{\\infty}$ and $G = G_{KDE}$, the corresponding algorithms are KNN- Uniform (Algorithm 1) and KNN-KDE (Algorithm 2). Each algorithm takes the query examples and the candidates as input and outputs the probability assigned to each candidate.\nBoth algorithms prefetch the L nearest neighbors of each query example from the candidates as the first step, where L is a limit on the neighborhood size. Specifically, GETKNN(Q, D, L) returns the"}, {"title": "5 Experiments", "content": "We evaluate our framework on data selection for task-specific instruction tuning and domain-specific continued pretraining, using different encodings as needed. We show that 1) our framework out- performs the state-of-the-art methods on data selection for task-specific instruction tuning and domain-specific continued pretraining by up to 6 points and 3 points in F1 score respectively; 2) our framework is robust to duplicates, exhibiting consistent performance when 1% of the candidate examples are duplicated up to 1000 times, while baseline methods show a drop of 2 points in F1 score (see Appendix E.1); 3) our method is efficient, requiring 28 hours to preprocess 150 million candidate examples and less than 1 hour for each task-specific selection (see Appendix E.2)."}, {"title": "5.1 Evaluation on Task-Specific Instruction Tuning", "content": "We select training data to perform instruction tuning to tailor a model to specific downstream tasks. We assume access to several query examples that represent the use cases of the target task and a repository of instruction-response pairs to select from. The detailed setting is as follows.\nTarget Tasks, Model, and Data Repository We consider three tasks from standard benchmarks for language model evaluation. The properties are shown in Table 1. We use two models: LLAMA-2- 7B [43] and MISTRAL-7B [22]. We use a combination of FLAN V2 [31], CoT [45], DOLLY [8], and OPEN ASSISTANT [26] as the data repository for selection, which contains 270K examples.\nEncoding We encode the examples using rescaled and randomly projected gradients from a LLAMA- 2-7B model finetuned on a random 5% of the data repository. The encoding process follows Xia et al. [47], who show that gradient-based encoding is essential to capture the utility of training examples in instruction tuning. We use $l_2$ distance as the distance function. See Appendix C for the details."}, {"title": "5.2 Evaluation on Domain-Specific Continued Pretraining", "content": "In this experiment, we select data for domain-specific continued pretraining to adapt a model to a specific domain. We assume access to a set of annotated data for a domain-specific task that serves as query examples and a repository of unlabeled data to select from. We continue pretraining the base model on the selected data and then perform supervised finetuning using the annotated data.\nTarget Tasks and Data Repository We consider four datasets focused on classification tasks across diverse domains. The properties are provided in Table 3. We select data for continued pertaining from a data repository consisting of 150M sequences crafted by Xie et al. [48] from The Pile [14]."}, {"title": "6 Related Works", "content": "Task-Specific Data Selection Similarity-based methods [39, 17, 2, 50] retrieves the top ones from the candidates, ranked by their similarity to the representative examples from the target task. The features used for similarity computation can be embeddings or ngrams for texts. Another line of works [35, 48] use two generative models where one learns the distribution of the target-task data and the other learns the general-purpose data. Model-specific data selection methods [12, 47] choose data to maximize the model performance on the target task. Given the high cost of actually training a model and evaluating it on the target task, these methods often estimate the model performance by approximation. DSDM [12] approximate the model performance using datamodels [21], a function"}, {"title": "7 Conclusion", "content": "In this paper, we proposed a framework for data selection for task-specific model finetuning, based on optimal transport, which allows a smooth tradeoff between distribution alignment and diversity. We incorporated kernel density estimation to make the selection robust to near-duplicates. Experimentally we showed that our method is effective in both task-specific instruction tuning and domain-specific continued pretraining. A potential direction for future work is to incorporate more efficient variants of optimal transport, such as Sinkhorn distances [9], to further improve the computational efficiency. One limitation of our framework is the reliance on a set of representative examples to guide the selection, which may not be easy to craft. The representative examples may also contain biases that can be exaggerated through the selection process, leading to negative social impacts. In practice, additional effort must be allocated to ensure the quality of the representative examples and the size of the representative examples needs to be decided according to the budget of human effort."}]}