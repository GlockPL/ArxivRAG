{"title": "Few-Shot Load Forecasting Under Data Scarcity in Smart Grids: A Meta-Learning Approach", "authors": ["Georgios Tsoumplekas", "Christos L. Athanasiadis", "Dimitrios I. Doukas", "Antonios Chrysopoulos", "Pericles A. Mitkas"], "abstract": "Despite the rapid expansion of smart grids and large volumes of data at the individual consumer level, there are still various cases where adequate data collection to train accurate load forecasting models is challenging or even impossible. This paper proposes adapting an established model-agnostic meta-learning algorithm for short-term load forecasting in the context of few-shot learning. Specifically, the proposed method can rapidly adapt and generalize within any unknown load time series of arbitrary length using only minimal training samples. In this context, the meta-learning model learns an optimal set of initial parameters for a base-level learner recurrent neural network. The proposed model is evaluated using a dataset of historical load consumption data from real-world consumers. Despite the examined load series' short length, it produces accurate forecasts outperforming transfer learning and task-specific machine learning methods by 12.5%. To enhance robustness and fairness during model evaluation, a novel metric, mean average log percentage error, is proposed that alleviates the bias introduced by the commonly used MAPE metric. Finally, a series of studies to evaluate the model's robustness under different hyperparameters and time series lengths is also conducted, demonstrating that the proposed approach consistently outperforms all other models.", "sections": [{"title": "I. INTRODUCTION", "content": "In recent years, power grids have undergone significant transformations, leading to the emergence of smart grids. Notably, modern power grids have largely shifted away from the traditional paradigm governed by a few big energy producers and multiple smaller consumers. The penetration of renewable energy sources and the appearance of various types of consumers, such as small residential, larger industrial, and even commercial ones (e.g., electric vehicle charging stations), create new challenges [1]. Consequently, accurate load forecasting, a common desideratum in the energy sector, becomes even more imperative in today's power grids to ensure their security, efficiency, adaptability, and trustworthiness [2].\nTowards this direction, the widespread adoption of advanced metering infrastructure (AMI) in many countries marks an important milestone. Collecting significant volumes of fine-grained consumption data from individual consumers enables load forecasting at a residential level, unlocking new opportunities for both power providers and load consumers [3]. In particular, accurate load forecasting allows for a more precise response to consumer demands, which helps minimize production costs and resource waste while improving the network's reliability during peak load periods. This holds particular significance within the context of modern active distribution networks, characterized by the widespread integration of active assets, i.e., photovoltaic (PV) units and battery energy storage systems, as well as the increasing electrification of traditional fuel-based activities like transportation and heating [4]. At the same time, a better understanding of customer profiles allows for better load balancing through the strategic promotion of demand response programs to consumers who are more likely to participate [4].\nThe abundance of consumers' load consumption data has favored deep learning (DL) techniques for load forecasting in recent years. However, due to the dynamic and ever-changing nature of smart grids, there are various cases where consumption data might be scarce or hard to obtain. Specifically, the increasing penetration of smart grids has led to the addition of newly connected consumers for which historical consumption data is typically sparse. At the same time, meter failures can lead to data corruption, resulting in only a few useful measurements, even for older consumers. Finally, integrating novel assets, such as PV units and heat pumps, can significantly change load consumption patterns, rendering users' historical data immaterial. Under these scenarios, standard DL methods cannot be effectively trained and produce accurate forecasts.\nRecently, few-shot learning [5] (FSL) has emerged as a learning paradigm allowing fast adaptation to novel tasks using only a few training samples. This approach is largely inspired by human learning, where learning a new concept or task is possible given only a few examples or demonstrations [6]. A common approach to achieve this type of rapid adaptation is using meta-learning [7] or learning-to-learn. Specifically, meta-learning methods extract information across tasks that share an underlying common structure and leverage it as prior knowledge to adapt to a new task with the same structure without extensive training. Meta-learning techniques in the context of FSL have successfully been applied to various domains, including computer vision [8], [9] and reinforcement learning [10]. Yet their application in load forecasting has only recently been explored [11]\u2013[13].\nThis paper investigates the potential of meta-learning in"}, {"title": "II. RELATED WORK", "content": "Since few-shot load forecasting stands at the intersection of load forecasting and FSL, some pertinent work in these areas is discussed before proceeding to existing approaches that combine the two fields."}, {"title": "A. Load Forecasting", "content": "Although there is no universal agreement on the individual time horizons, load forecasting can be split into short-term (a few hours to a few days), mid-term (a month to a year), and long-term (up to several years) forecasting. The proposed method fits within the short-term load forecasting (STLF) framework since it forecasts the load of the next seven days. Due to its aforementioned significance, STLF has been extensively researched in the past few decades, with older approaches including various statistical methods, such as autoregressive moving averages with exogenous variables (ARMAX) models [15]. However, during the last two decades, ML and DL techniques have been the primary methods applied for STLF, including support vector machines (SVMs) [16], convolutional neural networks (CNNs) [17], recurrent neural networks (RNNs) [18], LSTMs [1], and attention-based models [19]. More recently, probabilistic approaches have also been examined [20]. However, a common characteristic of these approaches is that they use large amounts of data for their training, rendering their application in data-scarce scenarios challenging."}, {"title": "B. Meta-Learning", "content": "The most common approach in FSL is the meta-learning paradigm, which extracts the shared structure among a set of learning tasks and leverages it to generalize to new ones with only a few samples. Meta-learning can generally be classified into (a) metric-based, (b) optimization-based, and (c) model-based meta-learning. Metric-based meta-learning models typically have a backbone that extracts meaningful and transferable representations and an appropriate metric applied to these representations [8], [21], [22]. Optimization-based meta-learning relies on learning how to effectively optimize a model to adapt to a new task using only a few training samples, which could include finding a suitable model initialization [9], [14] or learning rates [23]. Finally, model-based meta-learning employs a meta-learner module that learns how to adapt a base learner to each task [24], and also includes memory-based meta-learning, where an external memory is leveraged to enable faster adaptation of the model to new tasks [25], [26]. The proposed method can be classified as an optimization-based meta-learning algorithm, as its objective is to learn a model initialization that can be easily adapted with only a few gradient steps for each task."}, {"title": "C. Few-Shot Load Forecasting", "content": "Traditionally, most of the research related to FSL has been focused on image classification [8], [21], [22] and reinforcement learning [10], [24], while techniques focusing on load forecasting typically assumed the existence of adequate data to approach the problem with task-specific ML methods [3]. As a result, the intersection of these two areas has been largely unexplored, with only a limited number of existing works.\nIn [11], few-shot load forecasting is cast as a bi-level optimization problem, where in the upper level, the model's hyperparameters are tuned using a tree-based search method, while in the lower level, a meta-learning model similar to that in [9] is leveraged for forecasting. On the other hand, the authors in [12] perform clustering on the load time series based on a set of extracted features and determine a specific prototype for each cluster. An LSTM model is trained for each prototype and then fine tuned separately on each time series in the cluster. In [13], a transfer learning model and a meta-learning approach based on MAML [9] are tested for STLF on individual consumers, achieving promising results. Finally, federated learning has also been leveraged for few-shot hourly load forecasting of different buildings [27] by discriminating buildings into distinct clusters, extracting each cluster's shared structure using an LSTM and fine-tuning a multi-layer perceptron module for each building. Our proposed method bears similarities with the lower-level optimization in [11]. However, the robustness to hyperparameter selection achieved by modifying the original MAML obviates the need for an upper-level optimization, thus reducing the computational complexity. At the same time, our proposed method does not involve clustering of tasks, as in [12], [27], further enhancing its computational efficiency."}, {"title": "III. METHODOLOGY", "content": "This section delineates the proposed method applied for load forecasting under the FSL regime. First, the mathematical formulation of time series forecasting in the context of FSL is rigorously defined. Then, the proposed methodology is described."}, {"title": "A. Problem Formulation", "content": "In subsequent analysis, the theoretical framework introduced in [28] is adopted and extended to the meta-learning setting for univariate time series forecasting. Specifically, the problem of forecasting a single time series is formalized, following a standard ML approach. This formalization will prove useful later since it will constitute the basis upon which another layer of learning will be added to define the final meta-learning framework of few-shot time series forecasting.\nGiven a sufficiently large univariate time series, it can be broken down into subsequences that are sequentially fed into an ML model, forming the dataset $D := \\{(x_j, y_j)\\}_{j=1}^N$ of N samples. For that dataset, $x_j \\in \\mathbb{R}^{T_1}$ constitutes an input subsequence of length $T_1$, while $y_j \\in \\mathbb{R}^{T_O}$ is the corresponding output subsequence of length $T_O$. Under this setting, the goal of a typical ML approach would be to train a model $f : \\mathbb{R}^{T_1} \\rightarrow \\mathbb{R}^{T_O}$, parameterized by $\\theta$, to generalize within this dataset. Assuming that there is an underlying joint distribution $p$ that generates this dataset, such that $(x_j, y_j) \\sim p(x, y)$ and given an arbitrary loss function $L : \\mathbb{R}^{T_O} \\times \\mathbb{R}^{T_O} \\rightarrow \\mathbb{R}$, then the optimal set of parameters $\\theta^*$ for this model is defined as:\n$\\theta^* = \\underset{\\theta}{\\text{argmin }} E_{(x,y)\\sim p(x,y)} [L(f(x; \\theta), y)]$\nExtending this formalization, let us assume that there are L available time series that do not necessarily have the same length. Each one of these time series is characterized by its respective dataset $D_i = \\{(x_{ij}, y_{ij})\\}_{j=1}^{N_i}, i = 1, \\dots, L$, where $N_i$ is the number of samples for the i-th time series. Similarly to the single time series case, we assume an underlying joint distribution $p_i$ that generates the i-th time series' data, such that $(x_{ij}, y_{ij}) \\sim p_i(x, y)$. Following the meta-learning terminology, each time series is considered a separate task. As a consequence, they constitute a set of tasks $\\{T_i\\}_{i=1}^L$ where each one of them is the realization of a task distribution $q$ such that $T_i \\sim q(T)$. Under this setting, the aim of the previously defined model f is to find an optimal set of parameters $\\theta^*$ that minimizes the loss across all given tasks. These optimal parameters would, therefore, satisfy:\n$\\theta^* = \\underset{\\theta}{\\text{argmin }} E_{T \\sim q(T)} [E_{(x,y)\\sim p(x,y)} L(f(x; \\theta), y)]$"}, {"title": "B. Proposed Method", "content": "The proposed method mainly draws inspiration from MAML++ [14], a meta-learning approach that is a variant of the MAML [9] algorithm. Before proceeding with the description of the proposed method, it is essential to provide an overview of MAML to understand the underlying logic behind the final model and highlight the reasons for its adoption.\nMAML is a gradient-based meta-learning method that aims to generalize within each given task by performing only a few gradient steps on the task's support set. MAML learns an appropriate set of initial parameters to achieve this, granting it this fast adaptation capability. In other words, MAML learns parameters that can be easily fine-tuned within each task. To find this optimal set of initial model parameters, MAML leverages the fact that each task is a realization of a common task distribution and has a shared underlying structure. MAML extracts this transferable knowledge and leverages it to adapt to each task despite the scarcity of training data.\nGoing back to (3), in the context of MAML, $\\theta^*$ refers to the optimal set of initial parameters found by minimizing the expression's right-hand side using stochastic gradient descent. The parameter values used to evaluate the model on a task's query set are also formed after fine-tuning the support set. In MAML, this fine-tuning is defined as taking $N_s$ gradient steps on the support set of the task starting from the shared initial parameters. Altogether, MAML can be broken down into two optimization loops or otherwise levels of learning:\nInner Loop Optimization (Base Learner): Given a set of initial parameters $\\theta_0$ and a task $T_i$ with an associated dataset $D_i = \\{D_i^s, D_i^q\\}$, the set of updated parameters is computed by taking $N_s$ gradient steps on the support set $D_i^s$. More specifically, the updated parameters after k gradient steps on $D_i^s$ can be expressed as:\n$\\theta_k = \\theta_{k-1} - \\alpha \\nabla_{\\theta_{k-1}} L_{D_i^s}(f_{\\theta_{k-1}}(x))$\nwhere $\\alpha > 0$ is the inner loop learning rate and the dependence of $\\theta_k$ by $D_i^s$ is explicitly denoted and given by unrolling (4).\nOuter Loop Optimization (Meta-Learner): Guided by (3), the next step is to calculate the mean loss on all of the meta-train set tasks' query sets and optimize the initial parameters by performing stochastic gradient descent using that loss. Specifically, the meta-learner's loss function is defined as:\n$L_{meta}(\\theta_0) = \\sum_{i=1}^M L_{D_i^q}(f_{\\theta_{N_s}}(\\theta_0))$\nwhere M is the total number of training tasks and $f_{\\theta_{N_s}}(\\theta_0)$ is the value of the loss function evaluated on the query set of task $T_i$ using the fine-tuned parameters that occurred after $N_s$ inner loop optimization steps. The initial model parameters can then be optimized by taking a gradient step using the meta-learner's loss function:\n$\\theta_0 = \\theta_0 - \\beta \\nabla_{\\theta_0} L_{meta}(\\theta_0)$\nwhere $\\beta > 0$ is the outer loop learning rate.\nDuring testing, MAML utilizes the already learned initial parameters and adapts them to the support set of the test task following the same procedure described in the inner loop optimization. After acquiring the adapted parameters, these are utilized for evaluation in the query set.\nDespite MAML's success and widespread use in various applications spanning from image classification to reinforcement learning, there are reportedly various challenges associated with using it. These include its training instability, high computational complexity, and the need for careful hyperparameter tuning [14]. To mitigate MAML's aforementioned issues, an updated version of MAML suitable for load forecasting in the context of FSL is proposed. Our method is based on the work of Antoniou et al. [14], which extends the MAML architecture and has the following main features:\nMulti-Step Loss Function. To achieve stability during training, optimization based on gradients of all inner loop steps is required. In MAML, the gradient step on the outer loop is performed using the base learner's loss value on a task's query set after the inner loop gradient steps have been performed, as seen in (5). However, failing to consider the gradients during the intermediate steps explicitly is one of the main causes of instability since it hinders smooth gradient propagation in the network. By leveraging an outer loop loss function that is a weighted average of the query set losses of every inner loop gradient step, we ensure that gradients from all inner loop steps are included both explicitly (through the current step's query set loss) and implicitly (by unrolling the inner loop during subsequent steps) in the outer loop optimization procedure. More specifically, this multi-step loss is defined as:\n$\\mathcal{L}_{meta}(\\theta_0) = \\sum_{i=1}^M \\sum_{k=1}^{N_S} \\upsilon_k L_{D_i^q}(f_{\\theta_k}(\\theta_0))$\nwhere $L_{D_i^q}(f_{\\theta_k}(\\theta_0))$ is the base learner's query set loss on a training task $D_i \\in \\mathcal{D}_{meta-train}$ after k inner loop gradient steps and $\\upsilon_k$ is the loss weight during that step.\nIt must be highlighted that to ensure stability during the early stages of training, all loss weight values are set to be close to each other. However, as training progresses, it is crucial to prioritize the last gradient step's loss to enhance the effect of minimizing the loss after the last step of the inner loop. The rationale behind this decision stems from the fact that query set evaluation is performed using the model parameters after that step during testing. A weight matrix can be defined, $V \\in \\mathbb{R}^{N_e \\times N_s}$, where $N_e$ is the number of training epochs, and $v_{e,k} \\in V$ corresponds to the loss weight after the $k^{th}$ inner loop gradient step during the $e^{th}$ training epoch. A training epoch is equivalent to one outer-loop optimization step in the proposed method. During the first inner loop gradient step, all loss weights are equal:\n$\\upsilon_{1,k} = \\frac{1}{N_s}$\nIn the subsequent steps, the loss weights of intermediate steps are reduced following a method similar to simulated annealing. In contrast, the loss weight of the last step is analogously increased. The rest of matrix V can be defined as:\n$\\upsilon_{e,k} =\\begin{cases}\n\\max{\\{\\upsilon_{e-1,k} - \\frac{\\gamma}{N_s - 1}, \\frac{1}{N_s}\\}}, & k = 2, 3, .., N_s-1 \\\\\n\\min{\\{\\upsilon_{e-1,k} + \\gamma(N_s - 1), \\nu\\}}, & k = N_s\n\\end{cases}$\nwhere $\\gamma_2$ is the decay rate, $0 < \\gamma < 1$, and $\\nu$ is the maximum value of the intermediate steps' loss weights. From the above definition, $\\sum_{k=1}^{N_s} \\upsilon_{e,k} = 1$, and so the role of these values as weights for the calculation of a weighted average loss is apparent. Given that the inner loop steps and the total number of training epochs are known beforehand, V can be calculated for the whole training procedure, hence not imposing any additional computational burden during each epoch. In (7), the $e$ indices have been omitted for simplicity.\nHigher-order derivatives computation annealing. One of the simplest ways to reduce MAML's computational complexity is by omitting the calculation of second-order derivatives. This simplification was initially suggested by Finn et al. [9], who empirically showed that this approximation leads to speedups up to 33% without any significant performance"}, {"title": "IV. EXPERIMENTS", "content": "This section evaluates the proposed method's ability to adapt quickly and produce accurate forecasts for new load time series under various FSL settings. More specifically, the experimental setup includes the dataset, the experiment and model settings, the baselines, and the evaluation metrics. Next, the main findings that demonstrate the superiority of our method are presented, and the method's performance is also evaluated for time series of different lengths. Finally, we conduct a series of ablation studies, to assess the robustness of the proposed method under various architectural design choices."}, {"title": "A. Experimental Setup", "content": "Dataset. A set of univariate load time series from European load consumers was used for the experiments. Each time series is the aggregate load of 50 individual consumers, consists of 15-minute interval energy measurements, and was collected from October 1, 2020, to April 1, 2022. Each time series constitutes a separate task; thus, for the rest of this paper, time series and task are used interchangeably. The meta-train set contains 40 tasks of length between two and four months, starting from the first day of any of the months in the examined period. The meta-test set contains 15 time series starting from each month in the total examined period, with five each having a length of one, two, and three months, resulting in a total of 240 test tasks.\nLonger time series were used during meta-training than meta-testing, emulating the real-world scenario where an energy provider trains a meta-learning model on energy consumption data from older clients and tests it on new clients with limited available data. Due to their short length, individual time series cannot encapsulate seasonality. Nonetheless, the basic hypothesis is that the proposed model can extract the necessary knowledge to learn the underlying seasonal component by training on a set of time series that will cover all months of the calendar year.\nThe problem is formulated as a sequence-to-sequence forecasting problem. Each sample consists of measurements taken over a week; the corresponding outputs are the measurements for the following day. Support set samples are obtained by splitting the part of the time series that belongs to the support set into samples with non-overlapping input sequences. However, for query set samples, we use overlapping input sequences, shifted by one day, to get more samples from a smaller part of the time series. To allow for a fair evaluation across different tasks, all query sets have a fixed length of seven samples, each with an output sequence corresponding to a different day of the week. The support sets have varying lengths, allowing for training with a different number of samples (shots).\nBaseline Models. Following [30], two different baselines corresponding to two different training frameworks were introduced: (a) a task-specific and (b) a task-independent learning framework. Task-specific learning refers to the standard ML approach, where a separate model is trained for each task. On the other hand, task-independent learning involves training a single model using all data available in the meta-train set. Consequently, the model is fine-tuned on the support set and evaluated on the query set for each testing task. This is similar to transfer learning, where the combination of the meta-training tasks corresponds to the source task, and each meta-testing task is the target task. For brevity, the task-specific model will be referred to as TS-LSTM, and the task-independent model as TI-LSTM.\nExperimental Details. To ensure a fair comparison, all three models use the same LSTM backbone consisting of an LSTM layer followed by a linear layer with 32 hidden units. The number of inner loop training steps for the proposed method, the number of fine-tuning epochs for TI-LSTM, and the number of training epochs for TS-LSTM are all set to 1. The proposed method and TI-LSTM are trained for 150 epochs on the meta-train set. Finally, the proposed method uses first-order gradient approximation for the first 50 epochs.\nEvaluation Metrics. For the evaluation of the proposed method and baselines, both Mean Squared Error (MSE) and Mean Absolute Percentage Error (MAPE) are reported. MSE is also used as the base loss function in the optimization process. Moreover, a novel evaluation metric is introduced, the Mean Absolute Log Percentage Error (MALPE), which is defined as follows:\n$MALPE = \\frac{100\\%}{N} \\sum_{i=1}^N |\\log(\\frac{\\hat{y_i}}{y_i})|$\n$\\hat{y_i}$ is the forecast value, $y_i$ is the corresponding actual value, and N is the number of query set samples in each task. The proposed metric replaces the relative error in MAPE with the logarithm of the predicted to true values ratio. MALPE is symmetric, and its formulation is derived following [31] where the use of the logarithm is theoretically justified to mitigate the bias introduced by the relative error. Specifically, evaluating models on MAPE leads to biased results since MAPE favors underforecasting models and strictly penalizes overforecasting ones. Finally, it is worth noting that since we refer to a set of testing tasks, all metrics are calculated for each task separately, and the mean and standard deviation values are reported."}, {"title": "B. Main Results", "content": "The results obtained for the main experiment setting are summarized in Fig. 2. Specifically, the proposed method and the baselines are evaluated in each of the 240 meta-test set tasks, and the corresponding MSE, MAPE, and MALPE boxplots are created for each model. Our proposed model outperforms both baselines in all three metrics, improving MSE by 12.5% compared to TI-LSTM (0.035 vs 0.040), the second-best performing model. Additionally, the proposed model demonstrates increased performance robustness for different tasks, as the results are more concentrated towards the median reported value than the other two models.\nInterestingly, the performance gap between the proposed method and TI-LSTM is smaller than that between TI-LSTM and TS-LSTM, outlining the importance of incorporating prior knowledge to quickly adapt to novel tasks with few samples. At the same time, explicitly incorporating prior knowledge in the model as an inductive bias (in the proposed method as optimal initial parameters) is more effective than implicit incorporation through model pretraining. The fact that our meta-learning method manages to outperform TI-LSTM is particularly encouraging, especially in the light of various recent studies highlighting the strong performance of fine-tuning-based models for FSL problems [32], [33].\nThe forecasts of the baselines and the proposed method on the first three days of a meta-test task's query set with a total length of 1 month are illustrated in Fig. 3. The three days to be forecast in the query set can be seen by the periodic patterns of the actual time series. Following the results presented in Fig. 2, the proposed meta-learning method and TI-LSTM produce more accurate forecasts than TS-LSTM, whose forecasts are discerned by large fluctuations and deviations from the actual values. On the other hand, while the disparity between the proposed method and TI-LSTM is subtle, it is evident that the former model produces smoother results that better match the actual time series.\nFinally, Table I contains the mean monthly metric values for each model averaged over all meta-test set tasks for 3 months. Each task in this setting consists of a 3-month support set, followed by a 1-month query set corresponding to a different month of the year. The proposed model outperforms TI-LSTM for 10 out of 14 examined months while being marginally inferior to TI-LSTM for the remaining months due to their high variability, slightly favoring TI-LSTM's predictions. The proposed method's consistent performance across all months substantiates our hypothesis that it can learn the underlying seasonality even when trained on sub-seasonal time series."}, {"title": "C. Effect of support set size", "content": "This study investigates how varying the size of each task's support set affects model performance. It is expected to be more challenging for models to generalize based on tasks with fewer samples since there is less data to which they can adapt. At the same time, moving further away from the few-shot regime toward time series with more data, it is anticipated that the gap between meta-learning and task-specific approaches will become smaller.\nTable II provides the model performance metric values for a 1-month query set when the support set ranges from one to 12 months. As anticipated, the proposed model outperforms both baseline models when the support set size of the new input tasks does not exceed six months (five for MAPE and MALPE metrics), verifying meta-learning's effectiveness under data scarcity. By analyzing the MSE values, it is clear that our proposed model attains an MSE of 0.028 with just three months of training data. In contrast, the TI-LSTM model reaches a comparable error level only after training with eight months of historical data. This implies that our proposed method achieves similar performance with five months less data pinpointing its practical efficacy in data scarce settings. However, when the support set length exceeds a limit, our model starts underfitting the data provided, emphasizing the need for additional inner loop steps.\nOn the other hand, both TI-LSTM's and TS-LSTM's performance improves when increasing the support set size, but only TI-LSTM manages to outperform the proposed method when moving further away from the few-shot data regime. Nonetheless, it is evident that leveraging prior knowledge to improve model performance and facilitate adaptation to new tasks is crucial in both data regimes and becomes increasingly important when training samples are extremely scarce (e.g., 32.1% improvement in MALPE between our method and TS-LSTM for support set size of one month vs 6.21% improvement for support set size of 12 months)."}, {"title": "D. Ablation Study", "content": "This subsection reports the results of a series of experiments that aim to shed further light on the proposed method's performance. By altering various experimental and model configurations, the proposed method's robustness under these variations and its efficacy under scenarios of extreme data scarcity are demonstrated."}, {"title": "Second Order Derivatives", "content": "In the first of these experiments, the varying number of training epochs incorporating second-order gradients in the optimization process impact on the proposed model's performance is investigated. Table III presents the mean and standard deviation metric values on the meta-test set when training the model for a different number of epochs with second-order derivatives activated (denoted as s.o.). Using only first-order approximation decreases performance, suggesting that second-order gradients carry essential information for generalizing to unknown tasks. However, using second-order derivatives throughout all training epochs also harms model performance, possibly due to overfitting since the number of training tasks is limited. As a result, combining both approaches is optimal. The proposed model uses second-order gradients for the main experiment and subsequent ablation studies for the last 100 training epochs. This leads to the best MSE and second-best MAPE and MALPE results across all examined variations."}, {"title": "Base Learner Depth", "content": "Next, the impact of the base model depth on performance is examined. Based on the work in [34], gradient-based meta-learning models, like the one proposed, can benefit from deeper architectures since the early layers of these networks extract the task representations (task represen-"}, {"title": "V. CONCLUSION", "content": "During the past few decades, load forecasting approaches have typically assumed the existence of large volumes of data for training and evaluation. However, adapting to load consumption time series with limited data is critical, allowing for seamless forecasting to newly integrated consumers and active assets while increasing robustness under equipment failures that may lead to corrupted data.\nIn this paper, the adaptation of a meta-learning algorithm has been proposed to solve the problem of few-shot load"}]}