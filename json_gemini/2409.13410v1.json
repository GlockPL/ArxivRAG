{"title": "Sine Wave Normalization for Deep Learning-Based Tumor Segmentation in CT/PET Imaging", "authors": ["Jintao Ren", "Muheng Li", "Stine Sofia Korreman"], "abstract": "This report presents a normalization block for automated tumor segmentation in CT/PET scans, developed for the autoPET III Challenge. The key innovation is the introduction of the SineNormal, which applies periodic sine transformations to PET data to enhance lesion detection. By highlighting intensity variations and producing concentric ring patterns in PET highlighted regions, the model aims to improve segmentation accuracy, particularly for challenging multitracer PET datasets. The code for this project is available on GitHub.", "sections": [{"title": "1 Introduction", "content": "Positron Emission Tomography (PET) combined with Computed Tomography (PET/CT) is a vital tool for diagnosing, managing, and treating oncological diseases. PET/CT provides both anatomical and metabolic insights, allowing precise tumor localization and characterization. However, PET intensity values vary significantly due to factors like tracer type, patient metabolism, imaging protocols, and scanner sensitivity, complicating lesion detection and segmentation. Normalizing PET data is essential to reduce this variability and ensure consistent input for deep learning models. Accurate tumor segmentation remains a primary challenge, crucial for quantitative analysis and personalized therapy planning.\nThe autoPET III Challenge [2] addresses this issue by providing a multi-tracer, multicenter dataset, focusing on the development of robust deep learning"}, {"title": "2 Method", "content": "2.1 Sine Normal Transformation\nA key contribution of this work is the introduction of the SineNormal, a module specifically designed to enhance PET data processing in the context of tumor segmentation. PET images, which represent metabolic activity, often exhibit complex intensity patterns. The SineNormal applies periodic sine wave transformations to the PET input, aiming to capture subtle variations in intensity and spatial features that are critical for accurate lesion detection.\nThe primary function of the SineNormal is to amplify these metabolic variations through non-linear transformations. By leveraging sine functions with different frequency constants, the module highlights both small and large-scale intensity gradients, which may correspond to tumor boundaries and metabolic heterogeneities within the lesion.\nGiven an input tensor $X_{PET} \\in \\mathbb{R}^{D\\times H\\times W}$, where D, H, and W are the spatial dimensions of the PET image, the transformation applied by the SineNormal can be described as follows:\n$y = sin(a X_{PET}),$ (1)\nhere, a is a vector of constants a = [$a_1, a_2, . . ., a_c$] where c represents the number of channels after the input is repeated. The sine function is applied element-wise to the PET image data, where each constant $a_i$ corresponds to a different frequency component. This transformation introduces oscillations into the image, creating concentric ring patterns around high-intensity regions, such as tumor cores, thereby enhancing contrast and highlighting critical features [7].\n2.2 UNet architecture\nThe network architecture is based on the nnUNet ResEnc(M) plan, which em-ploys a residual encoder [1] and normal CNN decoder structure to extract and reconstruct features for segmentation tasks. The network consists of 6 stages, with progressively increasing feature channels to capture increasingly abstract representations of the input. The feature sizes for each stage are set to [32, 64,"}, {"title": "2.3 SineNormalBlock", "content": "The SineNormalBlock was applied to the input PET channel after 0-1 normalization, generating two sine-transformed channels with constants a = 20 and a = 30. These transformed channels were concatenated with the original PET and CT inputs, resulting in four channels (CT, PET, and two sine-normalized PET channels) being fed into the U-Net encoder.\nThe following code defines the SineNormalBlock in PyTorch:"}, {"title": "2.4 Training configurations", "content": "The entire training dataset (n=1611) was used without splitting. The network was trained with a batch size of 8 and a patch size of 112 \u00d7 160 \u00d7 128 voxels. CT images were first clipped at the 0.05-99.5 percentile and then normalized using z-score scaling, while PET images were normalized to a 0-1 range. The training"}, {"title": "3 Post Processing", "content": "AutoPET III imposes a 5-minute limit per patient. To maximize computational efficiency, we implemented both a dynamic sliding window approach and dy-namic test-time augmentation (TTA). For the sliding window approach, we ini-tialized the step size at 0.5 for all axes. In the coronal and sagittal planes, steps were limited to a maximum of 4, starting from the image center. Step sizes in these planes were dynamically adjusted based on coverage, increasing by 0.1 per iteration until coverage exceeded 80%.\nAdditionally, TTA was adjusted based on the number of sliding window steps in the axial direction. When the axial plane had 8 steps, only half of the mirroring axes were applied. For cases with more than 8 steps, mirroring was reduced to one-quarter of the mirroring axes. For cases with fewer than 8 steps, all axes were used for mirroring in the TTA."}, {"title": "4 Discussion and Future Work", "content": "The goal of this report was to present our approach to tumor segmentation using sine wave normalization in CT/PET imaging. The effectiveness of the approach was not tested due to time constraints. The method should be further thoroughly evaluated using proper data splitting and validation. Future work will involve rigorous evaluation to assess the model's performance and potential for clinical application."}]}