{"title": "RoCP-GNN: Robust Conformal Prediction for Graph Neural Networks in Node-Classification", "authors": ["Akansha"], "abstract": "Graph Neural Networks (GNNs) have emerged as powerful tools for predicting outcomes in graph-structured data. However, a notable limitation of GNNs is their inability to provide robust uncertainty estimates, which undermines their reliability in contexts where errors are costly. One way to address this issue is by providing prediction sets that contain the true label with a predefined probability margin. Our approach builds upon conformal prediction (CP), a framework that promises to construct statistically robust prediction sets or intervals. There are two primary challenges: first, given dependent data like graphs, it is unclear whether the critical assumption in CP - exchangeability - still holds when applied to node classification. Second, even if the exchangeability assumption is valid for conformalized link prediction, we need to ensure high efficiency, i.e., the resulting prediction set or the interval length is small enough to provide useful information. In this article, we propose a novel approach termed Robust Conformal Prediction for GNNs (RoCP-GNN), which integrates conformal prediction (CP) directly into the GNN training process. This method generates prediction sets, instead of just point predictions, that are valid at a user-defined confidence level, assuming only exchangeability. Our approach robustly predicts outcomes with any predictive GNN model while quantifying the uncertainty in predictions within the realm of graph-based semi-supervised learning (SSL). It is model-agnostic and can be coupled with any classification model. Experimental results demonstrate that GNN models with size loss provide a statistically significant increase in performance. We validate our approach on standard graph benchmark datasets by coupling it with various state-of-the-art GNNS in node classification. The code will be made available after publication.", "sections": [{"title": "I. INTRODUCTION", "content": "In recent years, the explosion of data across various domains has led to an increased interest in harnessing the power of graph structures for modeling complex relationships [1]-[5]. Graphs, which consist of nodes representing entities and edges representing their connections, have emerged as a fundamental data representation in fields such as social networks [2], [6], [7], recommendation systems [8]-[12], drug discovery [13], [14], fluid simulation [15], [16], biology [17], [18], and more. The inherent ability of graphs to capture intricate relationships between entities makes them invaluable for analyzing complex systems. The growing diversity and complexity of graph-structured data underscore the need for sophisticated tools to analyze and comprehend these intricate relationships. This demand has catalyzed the development of various Graph Neural Networks (GNNs) [5], [19]\u2013[22], which have demonstrated remarkable efficacy across a wide spectrum of downstream tasks. GNNs extend traditional neural networks by incorporating graph structure into their architecture, allowing for the effective processing of graph-structured data. They have shown significant promise in improving predictive performance and uncovering hidden patterns in complex datasets.\nAs GNNs find increasing deployment in high-stakes settings, understanding the uncertainty inherent in their predictions becomes paramount. One prominent approach to uncertainty quantification involves constructing prediction sets that outline a plausible range of values the true outcome may encompass. While numerous methods have been proposed to achieve this objective [23]\u2013[25], many lack rigorous guarantees regarding their validity, specifically the probability that the prediction set covers the true outcome [26]. This lack of rigor hinders their reliable deployment in situations where errors can have significant consequences. Therefore, acknowledging the necessity of advanced uncertainty quantification can enhance the reliability of GNN predictions and foster their broader applicability in critical domains. We aim to propose a method that can be integrated into any prediction model without increasing the computational cost.\nConformal prediction (CP) [26]\u2013[29] represents a promising framework for constructing prediction sets while ensuring a statistically valid coverage guarantee, that is, the output set encompasses the true label with any user-defined probability. CP operates independently of data distribution and relies on the principle of exchangeability, where every permutation of instances (in our context, nodes) is considered equally likely. In essence, this means that the ordering of random variables is inconsequential. This characteristic positions CP as a robust approach for uncertainty quantification in graph-based scenarios, as exchangeability relaxes the stringent assumption of independent and identically distributed (i.i.d.) data.\nDespite the success of Conformal Prediction (CP) in various machine learning domains, its application in the graph domain remains underexplored, with only limited work conducted so far. This is primarily due to the intrinsic structure of graphs, where all nodes are interrelated in a complex manner.\nPresent work. Current research in the graph domain predominantly utilizes Conformal Prediction (CP) in two ways: as a wrapper mechanism for determining prediction sets [30], [31], or as a means to design effective post-hoc calibration functions for pre-trained Graph Neural Network (GNN) classifiers, thereby enhancing the efficiency of their predictions [32].\nIn light of these existing approaches, our research aims to develop a novel methodology that addresses three key objectives:\n1) Optimization of Prediction Set Size: We seek to minimize the size of prediction sets obtained through CP while maintaining valid coverage.\n2) Preservation of Classification Accuracy: Our approach aims to maintain, or potentially improve, the classification accuracy of the underlying GNN model.\n3) End-to-End Training Framework: We propose to develop an integrated training objective that simultaneously optimizes prediction set size, ensures valid coverage, and maintains classification accuracy in a single, cohesive process.\nBy addressing these objectives, we aim to advance the state-of-the-art in conformal prediction for graph-structured data, offering a more efficient and accurate approach to uncertainty quantification in GNN classifiers.\nTo achieve these objectives, we leverage an additional conformal step that consists of two substeps to reduce inefficiency. During training, we reserve a small fraction of the training set and divide it into two subsets: train-calib and train-pred. The train-calib subset is used to implement a smooth calibration step [32], [33], while the train-pred subset is utilized for prediction and loss computations (details are provided in Section ??). We use a fixed size set for training and vary train-calib and train-pred set size (details are provided in ablation Section ??). We observe that if we use more points for train-calib...... and if we use less points for calib it affect the quality of the generated prediction sets. It is an open question to ask how many is the right number in each set.\nThis study focuses on quantifying the uncertainty in predictions produced by Graph Neural Networks (GNNs) for node classification tasks. Our main contributions can be summarized as follows:\n1) Integration of Conformal Prediction during Training: We pioneer the integration of conformal prediction (CP) directly into the training process, moving beyond traditional post-hoc methods. By embedding CP within the training pipeline, our model not only enhances prediction accuracy but also increases the precision of prediction sets, advancing the state-of-the-art in uncertainty quantification.\n2) Development of Novel Size-Loss Metric: We introduce a novel size-loss metric for the graph domain, aimed at optimizing the generation of compact prediction sets. This"}, {"title": "II. BACKGROUND AND PROBLEM FRAMEWORK", "content": "This section outlines the problem formulation addressed in this article. Additionally, we provide relevant background information essential for understanding the application of conformal prediction (CP) as a wrapper to achieve marginal coverage at test time.\nA. Problem settings\nThis study focuses on node classification within a graph in transductive settings. We define an undirected graph G = (V, E, X, A), comprising |V| = n nodes and edges E \u2286 V \u00d7 V. Each node vi \u2208 V is associated with a feature vector xi \u2208 Rd, where X \u2208 Rn\u00d7d represents the input feature matrix, and the adjacency matrix A \u2208 {0,1}n\u00d7n is such that\n$$A_{ij} =\n\\begin{cases}\n1 & \\text{ if } (v_i, v_j) \\in E, \\\\\n0 & \\text{ otherwise.}\n\\end{cases}$$\nFurthermore, we have labels {yi}vi\u2208V, where yi \u2208 Y = {1,..., K} represents the ground-truth label for node vi. The dataset is denoted as D := (X, Y), initially partitioned into training/calibration/test sets, with the training set further randomly split into train/valid sets, denoted as Dtrain, Dvalid, Dcalib, and Dtest of fixed sizes. During the training phase, the data {(xv, Yv)}v\u2208Dtrain\u222aDvalid, the attribute information {xv} v\u2208Dcalib\u222aDtest, and the entire graph structure (V, E, A) are accessible to the GNN for computing training node representations, while {Yv}v\u2208Dcalib\u222aDtest remain unseen.\nB. Graph Neural Networks in Node Classification\nGraph Neural Networks (GNNs) are designed to learn compact representations that integrate both the structural information of the network and the attributes of the nodes. This learning process is facilitated through a series of propagation layers [4]. Each layer performs two key operations:\n1. Aggregation: This step iteratively collects information from the neighboring nodes. Mathematically, it is expressed as:\n$$h_{u}^{(l)}=U P^{(l-1)}\\left(h_{u}^{(l-1)}, A G G^{(l-1)}\\left\\{h_{v}^{(l-1)} \\mid v \\in N_{u}\\right\\}\\right)$$\nIn this equation, $h_{u}^{(l-1)}$ denotes the node representation at the (l \u2013 1)-th layer, initially set to the node's feature vector at the first layer. Nu represents the set of neighbors for node u. The aggregation function, represented as AGG(1-1)(\u00b7), gathers information from the neighbors at the (l \u2212 1)-th layer and is defined as:\n$$A G G^{(l-1)}: \\mathbb{R}^{d^{(l-1)}} \\times \\mathbb{R}^{d^{(l-1)}} \\rightarrow \\mathbb{R}^{d^{(l-1)}}$$\n2. Update: The update function, referred to as UP(l\u22121)(\u00b7), combines the aggregated information into the node's representation at the (l \u2013 1)-th layer and is defined as:\n$$U P^{(l-1)}: \\mathbb{R}^{d^{(l-1)}} \\times \\mathbb{R}^{d^{(l-1)}} \\rightarrow \\mathbb{R}^{d^{(l)}}.$$\nThrough iterative application of this message-passing mechanism, GNNs refine node representations by considering their neighbors' relationships. For node classification tasks, a GNN with parameters \u03b8 outputs a probability distribution p\u03b8(xv) over all possible classes for each node v. We use p\u03b8,j(x) to represent the predicted probability of node v belonging to class j, where j = 1, 2, ..., K, that is p\u03b8,j(xv) = P\u03b8(Y = yj|X = xv). In classification tasks, for an input node feature vector xv, we aim to estimate the posterior distribution over a set of classes {1, 2, ..., K}, denoted"}, {"title": "C. Conformal Prediction", "content": "Let's examine the fundamental concept of Conformal Prediction (CP) without delving into any complex network structures or entity relationships. CP is a statistical methodology designed to generate prediction intervals that encompass the true outcome with a user-defined level of confidence. This approach provides intuitive uncertainty estimates, requiring only the assumption of data exchangeability. In this work, for computational efficacy we focus solely on the split conformal approach\u00b2, also known as the inductive conformal method, as introduced by Papadopoulos et al. [35].\nThe CP process can be broken down into three key stages, given a predetermined error rate \u03f5:\n1. Defining Non-conformity Measures: The first step involves establishing a heuristic metric, known as the non-conformity score S : X \u00d7 Y \u2192 R. This score quantifies how well a label y aligns with the prediction for input x. In a classification context, this might be represented by the predicted probability of a particular class y.\n2. Calculating the Quantile: The next phase involves determining the (1 \u2212 \u03f5)-quantile of the non-conformity scores derived from the calibration dataset Dcalib. This is expressed as: \u1fc6 = quantile({S(x1, y1), ..., S(xp, Yp)}, (1 \u2212 \u03f5)(1 + 1/p)), where p denotes the size of Dcalib.\n3. Constructing the Prediction Set: For a new test sample xp+1, we form a prediction set:\n$$C(x_{p+1}; \\tilde{\\eta})=\\left\\{y \\in Y: S(x_{p+1}, y) \\leq \\tilde{\\eta}\\right\\}$$\nAssuming the exchangeability of {$(z_i)_{i=1}^{p+1}$}= {$(x_i, Y_i)_{i=1}^{p+1}$}, it follows that Sp+1 := S(xp+1, Yp+1) is exchangeable with {$S_i\\}_{i=1}^{p}$. Consequently, C(xp+1) encompasses the true label with the specified coverage probability [34]: $$\\mathbb{P}\\left\\{Y_{p+1} \\in C\\left(x_{p+1}; \\tilde{\\eta}\\right)\\right\\} \\geq \\mathbb{P}\\left\\{S_{p+1} \\leq \\text { quantile }\\left(\\left\\{S_{i}\\right\\}_{i=1}^{p}, 1-\\epsilon\\right)\\right\\} \\geq 1-\\epsilon$$\nThis equality holds due to the exchangeability property of {$S_i\\}_{i=1}^{p}$. It's worth noting that this framework is versatile and can accommodate various non-conformity scores."}, {"title": "D. Adaptive Prediction Set (APS)", "content": "For test time coverage we use adaptive prediction set (APS) as non-conformity score proposed by [36] specifically designed for classification tasks. This score calculates the cumulative sum of ordered class probabilities until the true class is encountered. Formally, we denote the cumulative probability up to the k-th most promising class as $S_{\\theta}(x, k)=\\sum_{j=1}^{k} p_{\\theta, \\pi(j)}(x)$, where \u03c0 is a permutation of Y such that p\u03b8,\u03c0(1)(x) \u2265 p\u03b8,\u03c0(2)(x) \u2265 ... \u2265 p\u03b8,\u03c0(K)(x). Subsequently, the prediction set is constructed as C(x; \u1fc6) = {\u03c0(1),...,\u03c0(k*)}, where k* = inf{k : $\\sum_{j=1}^{k} p_{\\theta, \\pi(j)}(x) \\geq \\tilde{\\eta}$}\nE. Evaluation metrics\nTo evaluate the effectiveness of conformal prediction as a wrapper method, we employ two key metrics. These metrics are essential for assessing both the validity of marginal coverage and the degree of inefficiency. The first metric, termed 'Coverage', quantifies the empirical marginal coverage across the test dataset Dtest. It is calculated as follows:\n$$Coverage :=\\frac{1}{\\left|D_{\\text {test }}\\right|} \\sum_{i \\in D_{\\text {test }}} I\\left(Y_{i} \\in C\\left(X_{i}\\right)\\right)$$\nFor classification tasks, we measure inefficiency by examining the cardinality of the prediction set. This is represented by the 'Ineff' metric:\n$$Ineff :=\\frac{1}{\\left|D_{\\text {test }}\\right|} \\sum_{i \\in D_{\\text {test }}}\\left|C\\left(X_{i}\\right)\\right|$$\nIt's worth noting that a higher value of 'Ineff' indicates greater inefficiency, as it suggests larger prediction sets. It's crucial to understand that this measure of inefficiency in conformal prediction is separate from the accuracy of the underlying model's original predictions.\u201d\nF. Conformal prediction in GNNs\nThe application of Conformal Prediction (CP) for uncertainty quantification in Graph Neural Networks (GNNs) for node classification in transductive settings has been demonstrated to be feasible by Huang et al. [32]. This feasibility stems from CP's reliance on the exchangeability assumption. The authors investigate the exchangeability of node information and establish its validity under a permutation invariant condition, which ensures that the model's output and non-conformity scores remain consistent regardless of node ordering. This permutation invariant condition is crucial as it enables the application of CP to GNN models, even though GNN training utilizes both calibration and test information. Importantly, different calibration sets do not affect non-conformity scores, which is a typical scenario in GNN models. This property allows for the valid application of CP in transductive GNN settings. Extending these findings, Gazin et al. [37] have derived generalized theoretical results for transductive settings in regression tasks, further broadening the applicability of CP in graph-based machine learning models."}, {"title": "III. RELATED WORK", "content": "The literature presents several methods for uncertainty quantification in Graph Neural Networks (GNNs) for node classification tasks. These include model-agnostic calibration methods [24], [38]\u2013[40] and specialized techniques that leverage network principles such as homophily [23], [41]. Recently, Lin et al. [42] developed Graph Neural Stochastic Diffusion (GNSD), which integrates Q-Wiener process theory into graph domains to better handle uncertainty in node classification. To address high computational costs, they propose an approximation strategy for discretization sampling of the Q-Wiener process. However, these uncertainty quantification methods may fail to provide statistically rigorous and empirically valid coverage guarantees. In contrast, our approach leverages Conformal Prediction (CP) to achieve valid marginal coverage both theoretically and practically.\nCP remains relatively unexplored in the graph data domain, with most CP applications in GNNs focusing on inductive settings. For instance, Tibshirani et al. [43] address covariate shift, where input feature distributions change between source and target domains. Gibbs and Candes [44], [45] propose adaptive CP for forming prediction sets in online settings with time-varying data distributions. Their approach maintains desired coverage frequency over extended periods by continuously re-estimating the parameter governing distribution shift. Plachy, Makur, and Rubinstein [46] tackle label shift in federated learning, where multiple clients collaboratively train models while maintaining decentralized data. Akansha [47] applies CP to obtain confidence intervals under conditional data shift. This method is model-agnostic and can be coupled with any state-of-the-art GNN classifier model.\nOur work builds upon and extends the research of Huang et al. [32], who also aim to produce prediction sets containing the true class with a user-specified small marginal error probability while improving prediction set efficiency. Their approach involves a correction model that leverages node dependencies and utilizes a calibration set to adjust the base GNN's predictions, ensuring prediction intervals meet a desired coverage probability. This is achieved by computing non-conformity scores for the calibration set and using these scores to adjust future predictions. In contrast, our work proposes a novel end-to-end training setup that offers significant advantages. Our method integrates uncertainty quantification directly into the GNN training process, eliminating the need for separate calibration steps and offering improved computational efficiency. Crucially, our end-to-end setup simultaneously enhances both the prediction accuracy and the reliability of confidence intervals. This integrated approach not only streamlines the process but also potentially leads to more robust and accurate uncertainty estimates in GNN-based node classification tasks."}, {"title": "IV. ROCP-GNN: ROBUST CONFORMAL PREDICTION", "content": "To get the model parameters \u03b8 in traditional GNN classifier the model is trained to optimize cross-entropy loss but this training step is not aware of the efficiency for the post-hoc conformal prediction steps. In robust conformal prediction (RoCP) we propose an efficiency aware size loss which we integrate with cross-entropy loss on which the final GNN classifier will train. This ensures to maintain good prediction accuracy alongside efficient prediction sets in downstream steps. For this we leverage Dvalid and split it into Dtrain-calib and Dtrain-pred for conformlization. RoCP then use half of the Dvalid denoted by Dtrain-calib for calibration and other half of it denoted by Dtrain-pred for prediction and loss computation. After training any existing CP method can be used to get valid coverage. Given a miscoverage \u03f5 the framework follows following steps:\nA. Differentiable calibration and prediction steps\nTo apply CP during training we need differentiable calibration and prediction steps. We use threshold conformal predictor (THR) [48] to construct prediction sets $C_{\\theta}(x, \\tilde{\\eta}):=\\left\\{k: p_{\\theta, j}(x)=: S_{\\theta}(x, k) \\geq \\tilde{\\eta}\\right\\}$. Here subscript made dependence of confidence sets $C_{\\theta}$ on the prediction model and ultimately on parameters \u03b8. \u1fc6 is computed as $$(1+\\left|D_{\\text {train-calib }}\\right|)^{-1}$$-quantile of the conformity scores. We use $S_{\\theta}(x_v, Y_v) := p_{\\theta, y}(x_v)$ as conformity scores. We apply THR on logits to construct $C_{\\theta}\\left(x_{v}, \\tilde{\\eta}\\right)$ for $v \\in D_{\\text {train-pred }}$. We ultimately want these confidence sets $C_{\\theta}\\left(x_{v}, \\tilde{\\eta}\\right)$ to be differentiable with respect to the prediction p\u03b8(x) and \u1fc6 to be differentiable with respect to the predictions p\u03b8(xv), where $v \\in D_{\\text {train-calib }}$. Note that, this allows to differentiate $C_{\\theta}(x;\\tilde{\\eta})$ through both prediction and calibration steps with respect to the parameters \u03b8. Prediction step involves thresholding of the conformity scores $S_{\\theta}(x; k)$ which can be smoothed using the sigmoid function $\\sigma(z)=\\frac{1}{1+\\exp (-z)}$ and a temperature parameter T [33]:\n$$\\tilde{C}_{\\theta, k}(x; \\tilde{\\eta}):=\\sigma\\left(\\frac{E_{\\theta}(x, k)-\\tilde{\\eta}}{T}\\right)$$\nEssentially, $\\tilde{C}_{\\theta, k}(x; \\tilde{\\eta}) \\in[0,1]$ represents a soft assignment of class k to the confidence set. For T\u2192 0, the 'hard' confidence set will be recovered, i.e., $\\tilde{C}_{\\theta, k}(x; \\tilde{\\eta})=1$ for $k \\in C_{\\theta}(x; \\tilde{\\eta})$ and 0 otherwise. For THR, the conformity scores are naturally differentiable with respect to the parameters \u03b8 because E(x,k) = \u03c0\u03b8,k(x). Calibration step involves to compute a differentiable quantile \u1fc6. For which can be done using any smooth sorting approach [33], [49], [50]. These"}, {"title": "B. RoCP-GNN training", "content": "The robust CP (RoCP) performs differentiable CP during stochastic gradient decent (SGD) training. On Dtain-calib we calibrate \u1fc6 by computing \u03f5(1 + |Dtrain-calib|)^{-1}-quantile of the conformity scores in a differentiable manner and then compute C\u03b8(xv; \u1fc6) only for v \u2208 Dtrain-pred. Then in expectation across all random split of Dvalid set for T, \u03b4 \u2192 0, CP guarantees coverage 1 \u2013 \u03f5 on Dtrain-pred. Assuming empirical coverage of 1-\u03f5 in practice then we define size loss as\n$$L_{\\text {size-loss }}:=\\frac{1}{\\left|D_{\\text {train-pred }}\\right|} \\sum_{v \\in D_{\\text {train-pred }}} \\sum_{k} \\tilde{C}_{\\theta}(x_{v})$$\nwhere $\\tilde{C}_{\\theta}(x):=\\sum_{k=1}^{K} \\frac{\\tilde{C}_{\\theta, k}(X_v ; \\tilde{\\eta})}{\\tau}$. By default, we use \u03c4 = 1 in order to not penalize singletons. Now let us define the loss function on which our GNN is finally training on\n$$L_{\\mathrm{ROCP}-\\mathrm{GNN}}:=L_{\\mathrm{cross}-\\mathrm{entropy }}+\\lambda L_{\\mathrm{size}-\\mathrm{loss }}$$\nwhere $L_{\\text {cross-entropy }}=\\frac{1}{\\left|D_{\\text {train }}\\right|} \\sum_{v \\in D_{\\text {train }}} l\\left(Y_{v}, \\hat{Y}_{v}\\right)$ where l is the individual loss on each instances on training sample and \u0176 is the predicted label through the model prediction p\u03b8(xv) for v \u2208 Dtrain and \u03bb is the size weight parameter. We emphasize that RoCP training optimizes the model parameters \u03b8, on which the confidence sets $C_{\\theta}$ depend through the model predictions p\u03b8. Here, Lsize-loss is a \u201csmooth\u201d size loss intended to minimize the expected inefficiency, i.e., E[[|C\u03b8(X; \u03c4)|], and should not be confused with the statistic in Equation (3) used for evaluation in the end as post-hoc. Remember that $C_{\\theta, k}(x ; \\tilde{\\eta})$ can be understood as a soft assignment of class k to the confidence set C\u03b8(x; \u1fc6). By default, we use \u03c4 = 1 which can be interpreted as target size, in order to not penalize singletons. After training, any CP method can be applied to re-calibrate \u1fc6 on a held-out calibration set Dcalib as usual; i.e., the thresholds \u1fc6 obtained during training are not kept. This ensures that we obtain a coverage guarantee of CP."}, {"title": "VI. OPEN QUESTIONS AND FUTURE DIRECTIONS", "content": null}, {"title": "VII. CONCLUSION", "content": "This survey has delved into the depths of over-squashing, unearthing its origins in information compression across distant nodes. We've journeyed through a diverse array of strategies aimed at mitigating its impact \u2013 from innovative graph rewiring methods and curvature-based approaches to spectral techniques and the promise of graph transformers. As we tread this path, a nuanced interplay between over-smoothing and over-squashing has come into focus, demanding a balanced resolution. This exploration stands as a testament to the ongoing dialogue among researchers, driven by the pursuit of more refined and capable Graph Neural Networks. In closing, the quest to unravel over-squashing continues to be a beacon guiding our pursuit of more effective models, driven by the dynamic nature of graph data.\nACKNOWLEDGMENT\nI extend my heartfelt appreciation to Dr. Karmvir Singh Phogat for providing invaluable insights and essential feedback on the research problem explored in this article. His thoughtful comments significantly enriched the quality and lucidity of this study."}]}