{"title": "RoCP-GNN: Robust Conformal Prediction for Graph Neural Networks in Node-Classification", "authors": ["Akansha"], "abstract": "Graph Neural Networks (GNNs) have emerged as powerful tools for predicting outcomes in graph-structured data. However, a notable limitation of GNNs is their inability to provide robust uncertainty estimates, which undermines their reliability in contexts where errors are costly. One way to address this issue is by providing prediction sets that contain the true label with a predefined probability margin. Our approach builds upon conformal prediction (CP), a framework that promises to construct statistically robust prediction sets or intervals. There are two primary challenges: first, given dependent data like graphs, it is unclear whether the critical assumption in CP - exchangeability - still holds when applied to node classification. Second, even if the exchangeability assumption is valid for conformalized link prediction, we need to ensure high efficiency, i.e., the resulting prediction set or the interval length is small enough to provide useful information. In this article, we propose a novel approach termed Robust Conformal Prediction for GNNs (RoCP-GNN), which integrates conformal prediction (CP) directly into the GNN training process. This method generates prediction sets, instead of just point predictions, that are valid at a user-defined confidence level, assuming only exchangeability. Our approach robustly predicts outcomes with any predictive GNN model while quantifying the uncertainty in predictions within the realm of graph-based semi-supervised learning (SSL). It is model-agnostic and can be coupled with any classification model. Experimental results demonstrate that GNN models with size loss provide a statistically significant increase in performance. We validate our approach on standard graph benchmark datasets by coupling it with various state-of-the-art GNNS in node classification. The code will be made available after publication.", "sections": [{"title": "I. INTRODUCTION", "content": "In recent years, the explosion of data across various domains has led to an increased interest in harnessing the power of graph structures for modeling complex relationships [1]-[5]. Graphs, which consist of nodes representing entities and edges representing their connections, have emerged as a fundamental data representation in fields such as social networks [2], [6], [7], recommendation systems [8]-[12], drug discovery [13], [14], fluid simulation [15], [16], biology [17], [18], and more. The inherent ability of graphs to capture intricate relationships between entities makes them invaluable for analyzing complex systems. The growing diversity and complexity of graph-structured data underscore the need for sophisticated tools to analyze and comprehend these intricate relationships. This demand has catalyzed the development of various Graph Neural Networks (GNNs) [5], [19]\u2013[22], which have demonstrated remarkable efficacy across a wide spectrum of downstream tasks. GNNs extend traditional neural networks by incorporating graph structure into their architecture, allowing for the effective processing of graph-structured data. They have shown significant promise in improving predictive performance and uncovering hidden patterns in complex datasets.\nAs GNNs find increasing deployment in high-stakes settings, understanding the uncertainty inherent in their predictions becomes paramount. One prominent approach to uncertainty quantification involves constructing prediction sets that outline a plausible range of values the true outcome may encompass. While numerous methods have been proposed to achieve this objective [23]\u2013[25], many lack rigorous guarantees regarding their validity, specifically the probability that the prediction set covers the true outcome [26]. This lack of rigor hinders their reliable deployment in situations where errors can have significant consequences. Therefore, acknowledging the necessity of advanced uncertainty quantification can enhance the reliability of GNN predictions and foster their broader applicability in critical domains. We aim to propose a method that can be integrated into any prediction model without increasing the computational cost.\nConformal prediction (CP) [26]\u2013[29] represents a promising framework for constructing prediction sets while ensuring a statistically valid coverage guarantee, that is, the output set encompasses the true label with any user-defined probability. CP operates independently of data distribution and relies on the principle of exchangeability, where every permutation of instances (in our context, nodes) is considered equally likely. In essence, this means that the ordering of random variables is inconsequential. This characteristic positions CP as a robust approach for uncertainty quantification in graph-based scenarios, as exchangeability relaxes the stringent assumption of independent and identically distributed (i.i.d.) data.\nDespite the success of Conformal Prediction (CP) in various machine learning domains, its application in the graph domain remains underexplored, with only limited work conducted so far. This is primarily due to the intrinsic structure of graphs, where all nodes are interrelated in a complex manner.\nCurrent research in the graph domain predominantly utilizes Conformal Prediction (CP) in two ways: as a wrapper mechanism for determining prediction sets [30], [31], or as a means to design effective post-hoc calibration functions for pre-trained Graph Neural Network (GNN) classifiers, thereby enhancing the efficiency of their predictions [32].\nIn light of these existing approaches, our research aims to develop a novel methodology that addresses three key objectives:\n1) Optimization of Prediction Set Size: We seek to minimize the size of prediction sets obtained through CP while maintaining valid coverage.\n2) Preservation of Classification Accuracy: Our approach aims to maintain, or potentially improve, the classification accuracy of the underlying GNN model.\n3) End-to-End Training Framework: We propose to develop an integrated training objective that simultaneously optimizes prediction set size, ensures valid coverage, and maintains classification accuracy in a single, cohesive process.\nBy addressing these objectives, we aim to advance the state-of-the-art in conformal prediction for graph-structured data, offering a more efficient and accurate approach to uncertainty quantification in GNN classifiers.\nTo achieve these objectives, we leverage an additional conformal step that consists of two substeps to reduce inefficiency. During training, we reserve a small fraction of the training set and divide it into two subsets: train-calib and train-pred. The train-calib subset is used to implement a smooth calibration step [32], [33], while the train-pred subset is utilized for prediction and loss computations (details are provided in Section ??). We use a fixed size set for training and vary train-calib and train-pred set size (details are provided in ablation Section ??). We observe that if we use more points for train-calib...... and if we use less points for calib it affect the quality of the generated prediction sets. It is an open question to ask how many is the right number in each set.\nThis study focuses on quantifying the uncertainty in predictions produced by Graph Neural Networks (GNNs) for node classification tasks. Our main contributions can be summarized as follows:\n1) Integration of Conformal Prediction during Training: We pioneer the integration of conformal prediction (CP) directly into the training process, moving beyond traditional post-hoc methods. By embedding CP within the training pipeline, our model not only enhances prediction accuracy but also increases the precision of prediction sets, advancing the state-of-the-art in uncertainty quantification.\n2) Development of Novel Size-Loss Metric: We introduce a novel size-loss metric for the graph domain, aimed at optimizing the generation of compact prediction sets. This innovative loss function can be integrated into any GNN model, enabling it to deliver precise predictions while minimizing the size of the prediction sets. This enhancement leads to improved computational efficiency and interpretability.\n3) Empirical Validation on Diverse Graph Datasets: Extensive experiments across various benchmark graph datasets demonstrate the efficacy of RoCP-GNN. Our approach not only maintains but also improves prediction accuracy\u00b9 while simultaneously enhancing the precision of prediction sets across diverse datasets.\n4) Model Agnostic and Implementation Simplicity: Our method is model-agnostic, offering seamless integration with any graph node classifier model. Its straightforward implementation makes it accessible to a broad spectrum of researchers and practitioners, facilitating widespread adoption and fostering collaborative advancements in uncertainty-aware machine learning frameworks."}, {"title": "II. BACKGROUND AND PROBLEM FRAMEWORK", "content": "This section outlines the problem formulation addressed in this article. Additionally, we provide relevant background information essential for understanding the application of conformal prediction (CP) as a wrapper to achieve marginal coverage at test time.\nThis study focuses on node classification within a graph in transductive settings. We define an undirected graph G = (V, E, X, A), comprising |V| = n nodes and edges E \u2286 V \u00d7 V. Each node $v_i \u2208 V$ is associated with a feature vector $x_i \u2208 R^d$, where X \u2208 $R^{n\u00d7d}$ represents the input feature matrix, and the adjacency matrix A \u2208 ${0,1}^{n\u00d7n}$ is such that $A_{ij}$ = 1 if $(v_i, v_j) \u2208 E$, and $A_{ij}$ = 0 otherwise. Furthermore, we have labels {Yi}vi\u2208V, where $y_i \u2208 Y = {1,..., K}$ represents the ground-truth label for node vi. The dataset is denoted as D := (X, Y), initially partitioned into training/calibration/test sets, with the training set further randomly split into train/valid sets, denoted as Dtrain, Dvalid, Dcalib, and Dtest of fixed sizes. During the training phase, the data {(xv, Yv)}v\u2208Dtrain\u222aDvalid, the attribute information {v}v\u2208Dcalib\u222aDtest, and the entire graph structure (V, E, A) are accessible to the GNN for computing training node representations, while {Y}v\u2208Dcalib\u222aDtest remain unseen.\nGraph Neural Networks (GNNs) are designed to learn compact representations that integrate both the structural information of the network and the attributes of the nodes. This learning process is facilitated through a series of propagation layers [4]. Each layer performs two key operations:\n1. Aggregation: This step iteratively collects information from the neighboring nodes. Mathematically, it is expressed as:\n$h_u^{(l)} = UP^{(l-1)}(h_u^{(l-1)}, AGG^{(l-1)}\\{h_v^{(l-1)} | v \\in N_u\\})$\nIn this equation, $h_u^{(l-1)}$ denotes the node representation at the (l \u2013 1)-th layer, initially set to the node's feature vector at the first layer. Nu represents the set of neighbors for node u. The aggregation function, represented as AGG(l-1)(\u00b7), gathers information from the neighbors at the (l\u22121)-th layer and is defined as:\nAGG(l\u22121) : $R^{d(l\u22121)}$ \u00d7 $R^{d(l\u22121)}$ \u2192 $R^{d(l\u22121)}$.\n2. Update: The update function, referred to as UP(l\u22121)(\u00b7), combines the aggregated information into the node's representation at the (l \u2013 1)-th layer and is defined as:\nUP(l\u22121): $R^{d(l\u22121)}$ \u00d7 $R^{d(l\u22121)}$ \u2192 $R^{d(l)}$.\nThrough iterative application of this message-passing mechanism, GNNs refine node representations by considering their neighbors' relationships. For node classification tasks, a GNN with parameters 0 outputs a probability distribution po(xv) over all possible classes for each node v. We use Po,j(x) to represent the predicted probability of node v belonging to class j, where j = 1, 2, ..., K, that is po,j(xv) = Po(Y = yj|X = xv). In classification tasks, for an input node feature vector xv, we aim to estimate the posterior distribution over a set of classes {1,2,..., K}, denoted as po(xv) for all v, where 0 denotes the parameters of the classifier model in our case it is a GNN. We use poj(xv) to represent the predicted probability of node v belonging to class j, where j = 1, 2, . . ., K, that is po,j(xv) = P(Y = Yj | X = x). Bayes' decision rule is then applied to select the class with the highest posterior probability, optimizing the 0-1 classification loss. This method enables models \u03c0\u03bf(\u03c7\u03c5) with parameters 0 to achieve high accuracy on test datasets. However, high accuracy alone does not ensure safe and reliable deployment in practice. Conformal prediction (CP) [34] addresses this limitation by introducing a post-training calibration step that guarantees a specified coverage level. By generating confidence sets C(X) C {1,2,..., K}, CP ensures that the true class Y is included with a confidence level of 1 \u2014 \u0454, i.e., P(Y \u2208 C'(X)) \u2265 1 \u2014 \u0454, assuming that the calibration examples (X, \u03a5\u03c5), v \u2208 Dcalib, are exchangeably sampled from the test distribution."}, {"title": "C. Conformal Prediction", "content": "Let's examine the fundamental concept of Conformal Prediction (CP) without delving into any complex network structures or entity relationships. CP is a statistical methodology designed to generate prediction intervals that encompass the true outcome with a user-defined level of confidence. This approach provides intuitive uncertainty estimates, requiring only the assumption of data exchangeability. In this work, for computational efficacy we focus solely on the split conformal approach\u00b2, also known as the inductive conformal method, as introduced by Papadopoulos et al. [35].\nThe CP process can be broken down into three key stages, given a predetermined error rate 6:\n1. Defining Non-conformity Measures: The first step involves establishing a heuristic metric, known as the non-conformity score S: XXY \u2192 R. This score quantifies how well a label y aligns with the prediction for input x. In a classification context, this might be represented by the predicted probability of a particular class y.\n2. Calculating the Quantile: The next phase involves determining the (1 \u2013 \u20ac)-quantile of the non-conformity scores derived from the calibration dataset Dcalib. This is expressed as: \u1fc6 = quantile({S(x1, y1), ..., S(Xp, Yp)}, (1-6)(1+)), where p denotes the size of Dcalib.\n3. Constructing the Prediction Set: For a new test sample Xp+1, we form a prediction set:\nC(xp+1; \u1fc6) = {y \u2208 Y : S(Xp+1, y) \u2264 \u1fc6}\nAssuming the exchangeability of {(zi)} = {(xi, Yi)} +1, it follows that Sp+1 := S(Xp+1, Yp+1) is exchangeable with {S}. Consequently, C(Xp+1) encompasses the true label with the specified coverage probability [34]: P{Yp+1 \u2208 C(Xp+1; \u1fc6)} = P{Sp+1 > quantile({S}=1,1-6) \u2265 > 1-6. This equality holds due to the exchangeability property of {S}1. It's worth noting that this framework is versatile and can accommodate various non-conformity scores."}, {"title": "D. Adaptive Prediction Set (APS)", "content": "For test time coverage we use adaptive prediction set (APS) as non-conformity score proposed by [36] specifically designed for classification tasks. This score calculates the cumulative sum of ordered class probabilities until the true class is encountered. Formally, we denote the cumulative probability up to the k-th most promising class as So(x,k) = $\\sum_{j=1}^{k} P_{\\theta,\\pi(j)}(x)$, where \u03c0 is a permutation of Y such that $p_{\\theta,\\pi(1)}(x) \\geq P_{\\theta,\\pi(2)}(x) \\geq ... \\geq P_{\\theta,\\pi(K)}(x)$. Subsequently, the prediction set is constructed as C(x; \u1fc6) = {\u03c0(1),...,\u03c0(k*)}, where k* = inf{k : $\\sum_{j=1}^{k} P_{\\theta,\\pi(j)} (x) \\geq \\tilde{\\eta}$ }."}, {"title": "E. Evaluation metrics", "content": "To evaluate the effectiveness of conformal prediction as a wrapper method, we employ two key metrics. These metrics are essential for assessing both the validity of marginal coverage and the degree of inefficiency. The first metric, termed 'Coverage', quantifies the empirical marginal coverage across the test dataset Dtest. It is calculated as follows:\nCoverage := $\\frac{1}{|D_{test}|}\\sum_{i \\in D_{test}}I(Y_i \\in C(X_i))$\nFor classification tasks, we measure inefficiency by examining the cardinality of the prediction set. This is represented by the 'Ineff' metric:\nIneff := $\\frac{1}{|D_{test}|}\\sum_{i \\in D_{test}}|C(X_i)|$"}, {"title": "F. Conformal prediction in GNNs", "content": "The application of Conformal Prediction (CP) for uncertainty quantification in Graph Neural Networks (GNNs) for node classification in transductive settings has been demonstrated to be feasible by Huang et al. [32]. This feasibility stems from CP's reliance on the exchangeability assumption. The authors investigate the exchangeability of node information and establish its validity under a permutation invariant condition, which ensures that the model's output and non-conformity scores remain consistent regardless of node ordering. This permutation invariant condition is crucial as it enables the application of CP to GNN models, even though GNN training utilizes both calibration and test information. Importantly, different calibration sets do not affect non-conformity scores, which is a typical scenario in GNN models. This property allows for the valid application of CP in transductive GNN settings. Extending these findings, Gazin et al. [37] have derived generalized theoretical results for transductive settings in regression tasks, further broadening the applicability of CP in graph-based machine learning models."}, {"title": "III. RELATED WORK", "content": "The literature presents several methods for uncertainty quantification in Graph Neural Networks (GNNs) for node classification tasks. These include model-agnostic calibration methods [24], [38]-[40] and specialized techniques that leverage network principles such as homophily [23], [41]. Recently, Lin et al. [42] developed Graph Neural Stochastic Diffusion (GNSD), which integrates Q-Wiener process theory into graph domains to better handle uncertainty in node classification. To address high computational costs, they propose an approximation strategy for discretization sampling of the Q-Wiener process. However, these uncertainty quantification methods may fail to provide statistically rigorous and empirically valid coverage guarantees. In contrast, our approach leverages Conformal Prediction (CP) to achieve valid marginal coverage both theoretically and practically.\nCP remains relatively unexplored in the graph data domain, with most CP applications in GNNs focusing on inductive settings. For instance, Tibshirani et al. [43] address covariate shift, where input feature distributions change between source and target domains. Gibbs and Candes [44], [45] propose adaptive CP for forming prediction sets in online settings with time-varying data distributions. Their approach maintains desired coverage frequency over extended periods by continuously re-estimating the parameter governing distribution shift. Plachy, Makur, and Rubinstein [46] tackle label shift in federated learning, where multiple clients collaboratively train models while maintaining decentralized data. Akansha [47] applies CP to obtain confidence intervals under conditional data shift. This method is model-agnostic and can be coupled with any state-of-the-art GNN classifier model.\nOur work builds upon and extends the research of Huang et al. [32], who also aim to produce prediction sets containing the true class with a user-specified small marginal error probability while improving prediction set efficiency. Their approach involves a correction model that leverages node dependencies and utilizes a calibration set to adjust the base GNN's predictions, ensuring prediction intervals meet a desired coverage probability. This is achieved by computing non-conformity scores for the calibration set and using these scores to adjust future predictions. In contrast, our work proposes a novel end-to-end training setup that offers significant advantages. Our method integrates uncertainty quantification directly into the GNN training process, eliminating the need for separate calibration steps and offering improved computational efficiency. Crucially, our end-to-end setup simultaneously enhances both the prediction accuracy and the reliability of confidence intervals. This integrated approach not only streamlines the process but also potentially leads to more robust and accurate uncertainty estimates in GNN-based node classification tasks."}, {"title": "IV. ROCP-GNN: ROBUST CONFORMAL PREDICTION", "content": "To get the model parameters @ in traditional GNN classifier the model is trained to optimize cross-entropy loss but this training step is not aware of the efficiency for the post-hoc conformal prediction steps. In robust conformal prediction (RoCP) we propose an efficiency aware size loss which we integrate with cross-entropy loss on which the final GNN classifier will train. This ensures to maintain good prediction accuracy alongside efficient prediction sets in downstream steps. For this we leverage Dvalid and split it into Dtrain-calib and Dtrain-pred for conformlization. RoCP then use half of the Dvalid denoted by Dtrain-calib for calibration and other half of it denoted by Dtrain-pred for prediction and loss computation. After training any existing CP method can be used to get valid coverage. Given a miscoverage e the framework follows following steps:\nTo apply CP during training we need differentiable calibration and prediction steps. We use threshold conformal predictor (THR) [48] to construct prediction sets $C_{\\theta}(x,\\tilde{\\eta}) := \\{k : p_{\\theta,j}(x) =: S_{\\theta}(x,k) \\geq \\tilde{\\eta}\\}$. Here subscript made dependence of confidence sets $C_{\\theta}$ on the prediction model and ultimately on parameters \u03b8. \u1fc6 is computed as (1 + |Dtrain-calib|)-quantile of the conformity scores. We use $S_{\\theta}(x_v, Y_v) := p_{\\theta,y} (x_v)$ as conformity scores. We apply THR on logits to construct $C_{\\theta} (x_\\upsilon, \\tilde{\\eta})$ for v \u2208 Dtrain-pred. We ultimately want these confidence sets $C_{\\theta}(x_\\upsilon, \\tilde{\\eta})$ to be differentiable with respect to the prediction $p_{\\theta}(x)$ and \u1fc6 to be differentiable with respect to the predictions $p_{\\theta}(x_\\upsilon)$, where $v \u2208 Dtrain-calib$. Note that, this allows to differentiate $C_{\\theta}(x;\\tilde{\\eta})$ through both prediction and calibration steps with respect to the parameters \u03b8.\nPrediction step involves thresholding of the conformity scores $S_{\\theta}(x; k)$ which can be smoothed using the sigmoid function $\\sigma(z) = \\frac{1}{1+exp(-z)}$ and a temperature parameter T [33]:\n$\\tilde{C_{\\theta,k}}(x; \\tilde{\\eta}) := \\sigma(\\frac{p_{\\theta}(x, k) \u2013 \\tilde{\\eta}}{T})$\nEssentially, C\u03b8,k(x; \u1fc6) \u2208 [0,1] represents a soft assignment of class k to the confidence set. For T\u2192 0, the 'hard' confidence set will be recovered, i.e., C\u03b8,k(x; \u1fc6) = 1 for k \u2208 C\u03b8(x; \u1fc6) and 0 otherwise. For THR, the conformity scores are naturally differentiable with respect to the parameters @ because E(x,k) = \u03c0\u03b8,\u03ba(X).\nCalibration step involves to compute a differentiable quantile \u1fc6. For which can be done using any smooth sorting approach [33], [49], [50]. These often come with a \u201cdispersion\u201d hyper-parameter \u03b4 such that smooth sorting approximates \u201chard\u201d sorting for \u03b4 \u2192 0. Overall, this results in the threshold \u1fc6 being differentiable with respect to the predictions of the calibration examples {$p_{\\theta}(x_v)$}$_{v\u2208D_{train-calib}}$ and the model's parameters 0.\nAs this approximation is using smooth operations, the coverage guarantee seems lost. However, in the limit of T, \u03b4 \u2192 0 we recover the original non-smooth computations and the corresponding coverage guarantee. Thus, it is reasonable to assume that, in practice, we empirically obtain coverage close to (1 \u2013 \u20ac). We found that this is sufficient because these smooth variants are only used during training. At test time, we use the original (non-smooth) implementations and the coverage guarantee follows directly from [36], [48]."}, {"title": "B. RoCP-GNN training", "content": "The robust CP (RoCP) performs differentiable CP during stochastic gradient decent (SGD) training. On Dtain-calib we calibrate \u1fc6 by computing \u20ac(1 + |Dtrain-calib|)-quantile of the conformity scores in a differentiable manner and then compute $C_{\\theta}(x_\\upsilon; \\tilde{\\eta})$ only for v \u2208 Dtrain-pred. Then in expectation across all random split of Dvalid set for T,\u03b4 \u2192 0, CP guarantees coverage 1 \u2013 \u20ac on Dtrain-pred. Assuming empirical coverage of 1-6 in practice then we define size loss as\n$L_{size-loss} := \\frac{1}{|D_{train-pred}|} \\sum_{v\u2208D_{train-pred}} \\sum_{k} \\tilde{C_{\\theta}}(x_v),$\nwhere $C_\\theta(x) := \\frac{1}{N} \\sum_{k=1}^K \\tilde{C_{\\theta,k}}(X_\\upsilon; \\tilde{\\eta}) \u2013 \\tau)$. By default, we use t = 1 in order to not penalize singletons. Now let us define the loss function on which our GNN is finally training on\n$L_{ROCP-GNN} := L_{cross-entropy} + \\lambda L_{size-loss}$\nwhere $L_{cross-entropy} = \\frac{1}{|D_{train}|} \\sum_{v \\in D_{train}} l(Y_v, \\hat{y_v})$ where l is the individual loss on each instances on training sample and \u0177 is the predicted label through the model prediction po(xv) for v \u2208 Dtrain and A is the size weight parameter. We emphasize that RoCP training optimizes the model parameters 0, on which the confidence sets Co depend through the model predictions pe. Here, Lsize-loss is a \u201csmooth\u201d size loss intended to minimize the expected inefficiency, i.e., E[[Co(X;T)|], and should not be confused with the statistic in Equation (3) used for evaluation in the end as post-hoc. Remember that C\u03c0,\u03ba(x; \u1fc6) can be understood as a soft assignment of class k to the confidence set Co(x; \u1fc6). By default, we use r = 1 which can be interpreted as target size, in order to not penalize singletons. After training, any CP method can be applied to re-calibrate \u1fc6 on a held-out calibration set Dcalib as usual; i.e., the thresholds \u1fc6 obtained during training are not kept. This ensures that we obtain a coverage guarantee of CP."}, {"title": "V. EXPERIMENTS AND RESULTS", "content": "The common datasets employed for node and graph classification tasks in the models listed in Table ?? are presented in Table I, along with detailed dataset statistics. It's important to note that this list is not exhaustive, as there are numerous other datasets, including synthetic and large-scale real-world ones, utilized for various research purposes. Table I displays the statistics of the datasets used in this study, where H(G) represents the graph's homophily, as defined in [51], calculated as\nH(G) = $\\frac{1}{\\sum_{v\\in V}}$ {$\\frac{\\text{#v's neighbors with the same label}}{\\text{#v's neighbors}}$}\nFor node classification tasks, we employ a diverse set of 12 datasets, encompassing graphs of varying sizes and characteristics.\nCora [52], CiteSeer [53], and PubMed [54] are examples of paper citation networks. In these datasets, node features are represented as bag-of-words extracted from paper content, and the goal is to classify research topics. Notably, these datasets exhibit high homophily. In contrast, the Film dataset is created based on actor co-occurrences on Wikipedia pages and is categorized into five groups. This dataset poses a node classification task with low homophily characteristics. TwitchDE, on the other hand, is a social network comprising German gamer accounts from Twitch, categorized as suitable for work or adult profiles. The classification task involves profiling these accounts. The Tolokers dataset represents a collaboration network derived from the crowdsourcing platform Toloka. The objective here is to determine user activity, considering the challenge of class imbalance, with the evaluation metric being the area under the ROC curve. Cornell, Texas, Wisconsin are additional node classification tasks, each originating from university-related interactions. The Cornell dataset comprises research paper citation data. The Texas dataset represents friendships in a Texas college, and the Wisconsin dataset is derived from a university-related network. Node features and specific targets for these datasets can vary. Chameleon [55], Squirrel [55], Actor [56] are also novel datasets introduced for node classification. Chameleon captures interactions within a university community. Squirrel is a network of interactions among squirrels in a park. The Actor dataset models collaborations among actors in the film industry. Each of these datasets presents unique characteristics and classification tasks.\nFor graph classification tasks, we utilize the following datasets: NCI-1 and NCI-109 datasets involve classifying molecules as cancerous or non-cancerous. The node input features are represented as one-hot encodings of atom types, while edges signify chemical bonds. In datasets like Reddit-B, Reddit-5K, and Reddit-12K, interactions between users in Reddit discussion threads are captured. The primary task associated with these datasets is to determine the type of subreddit to which a discussion belongs. Collab comprises ego-networks from three distinct scientific collaboration fields. Unlike the previous datasets, Reddit tasks, and Collab, these datasets do not have node input features. Enzymes is a bioinformatics dataset for graph classification. It involves classifying enzymes based on their structures and functions. The BZR dataset is a small molecule dataset used for graph classification tasks. It is commonly employed for evaluating graph-based machine learning algorithms. MUTAG is another bioinformatics dataset for graph classification, primarily used for evaluating chemical informatics algorithms. The task is to predict mutagenicity. PTC is a bioinformatics dataset for graph classification, focusing on carcinogenicity prediction. The graphs represent chemical compounds. COX2 is a small molecule dataset, often used to assess graph-based machine learning models in chemistry-related tasks. The classification task is centered around predicting the inhibition of the COX-2 enzyme. Proteins is a bioinformatics dataset used for graph classification. The task is to classify proteins based on their functions. These datasets are from Tudataset [57]."}, {"title": "VI. OPEN QUESTIONS AND FUTURE DIRECTIONS", "content": null}, {"title": "VII. CONCLUSION", "content": "This survey has delved into the depths of over-squashing, unearthing its origins in information compression across distant nodes. We've journeyed through a diverse array of strategies aimed at mitigating its impact \u2013 from innovative graph rewiring methods and curvature-based approaches to spectral techniques and the promise of graph transformers. As we tread this path, a nuanced interplay between over-smoothing and over-squashing has come into focus, demanding a balanced resolution. This exploration stands as a testament to the ongoing dialogue among researchers, driven by the pursuit of more refined and capable Graph Neural Networks. In closing, the quest to unravel over-squashing continues to be a beacon guiding our pursuit of more effective models, driven by the dynamic nature of graph data."}]}