{"title": "Multimodal Auto Validation For Self-Refinement in Web Agents", "authors": ["Ruhana Azam", "Tamer Abuelsaad", "Aditya Vempaty", "Ashish Jagmohan"], "abstract": "As our world digitizes, web agents that can automate complex and monotonous tasks are becoming essential in streamlining workflows. This paper introduces an approach to improving web agent performance through multi-modal validation and self-refinement. We present a comprehensive study of different modalities (text, vision) and the effect of hierarchy for the automatic validation of web agents, building upon the state-of-the-art Agent-E web automation framework. We also introduce a self-refinement mechanism for web automation, using the developed auto-validator, that enables web agents to detect and self-correct workflow failures. Our results show significant gains on Agent-E's (a SOTA web agent) prior state- of-art performance, boosting task-completion rates from 76.2% to 81.24% on the subset of the WebVoyager benchmark. The approach presented in this paper paves the way for more reliable digital assistants in complex, real-world scenarios.", "sections": [{"title": "Introduction", "content": "Recent studies indicate that an estimated 92% of jobs now require digital skills [Bergson-Shilcock and Taylor, 2023], driving companies to focus on workflow automation. Generative AI and other automation tools are particularly promising, with the potential to handle 60-70% of an employee's tasks and contribute between $2.6 trillion and $4.4 trillion to global GDP [Chui et al., 2023]. In this landscape, web agents can play an essential role in alleviating workloads. Acting as personal assistants, they can manage schedules, automate routine activities, and efficiently complete simple tasks. By reducing cognitive load, saving time, and optimizing workflows, these tools help individuals and businesses operate more efficiently.\nEarlier web agents were primarily rule-based, which limited their adaptability across diverse scenarios. However, advances in Large Language Models (LLMs), known for achieving human-like performance in various tasks [Liang et al., 2022], have sparked renewed interest in leveraging LLMs for web automation. Initial successes have been reported, with LLM-based approaches achieving success rates of 75% in WebArena benchmarks [Pan et al., 2024] and 73.1% in WebVoyager [Abuelsaad et al., 2024]. While these results are promising, they highlight the need for further improvements to meet the reliability standards required for widespread adoption.\nWe propose using a self-refinement method [Madaan et al., 2023] to enhance web navigation agents. This method employs a validator to provide feedback and self-correct workflow failures. Like many real-life planning settings, web- navigation, in non-synthetic settings, does not have an inherent reward model. Drawing inspiration from LLM-as-a-judge [Zheng et al., 2024], we aim to build a"}, {"title": "Background", "content": "Self-Improving Agents Recent research has focused on enhancing the capabilities of LLMs during training or inference without additional human supervision [Wei et al., 2022, Chen et al., 2023, Wang et al., 2023, Kojima et al., 2023]. Techniques like chain-of-thought prompting and self-consistency, as used in Huang et al. [2022], aim to generate higher-quality outputs. Other methods, such as Self-refine [Madaan et al., 2023], Reflexion [Shinn et al., 2023], and REFINER [Paul et al., 2024], focus on iterative refinement of outputs using actor-critic pipelines or task decomposition. These approaches have been successfully applied to web agents, improving the performance of LLMs in web automation tasks [Putta et al., 2024, Pan et al., 2024, Lutz et al., 2024].\nWeb Agents The reasoning and planning capabilities in large language models (LLMs) have sparked interest in developing autonomous web agents capable of navigating complex online environments. Several frameworks have emerged to enhance LLM performance in agentic settings, such as chain-of- thought prompting [Wei et al., 2022] and the ReAct paradigm [Yao et al., 2022b], which combine reasoning and action steps. Leveraging such paradigms has shown promising results in prompting web agents [He et al., 2024]. Moreover, using these paradigms with multimodal observations has been shown to boost performance [Koh et al., 2024] further.\nResearchers have also explored the use of more traditional search procedures in conjunction with self-critique mechanisms. Putta et al. [2024] has used self-critique as an intermediate reward signal for Monte Carlo Tree Search (MCTS) [Putta et al., 2024]. A similar approach by Lutz et al. [2024] includes a planner that backtracks using self-critique feedback. These labeled trajectories are then used in context to plan future tasks. Other work, inspired by Reflexion [Shinn et al., 2023], has focused on providing reward signals based on visual information at the end of each workflow [Pan et al., 2024].\nWebsites are textually represented with Document Object Models (DOMS). While most works have focused on the use of raw DOM and/or screenshot signals for planning [He et al., 2024, Pan et al., 2024, Putta et al., 2024, Lutz et al., 2024], a different line of work has focused on the effect of making DOMs more interpretable for LLM-based planners. Abuelsaad et al. [2024] utilizes a hierarchy of agents to create a more interpretable understanding of the DOM and sequence of actions for the planner agent.\nWeb Navigation Benchmarks As the capabilities of digital web agents have improved, bench- marking methods have become increasingly sophisticated. While early research relied on simplified"}, {"title": "Self-Refinement For Web-Navigation", "content": "In this paper, we propose a self-refinement mechanism for web navigation tasks. A web navigation agent plans and executes a workflow for a given task, after which a validator assesses whether the task was successfully completed and provides feedback. If the task is incomplete, the agent revises its plan based on the feedback and reattempts the task. This mechanism is illustrated in Figure 1."}, {"title": "Problem Setting", "content": "In Section 3.1, we specify our problem setting and explain how the task of web navigation can be viewed as a planning problem. Before implementing the self-refinement method, we need to build a validator agent. In Section 3.2, we introduce our methods for building the validator. Finally, in Section 3.3, we discuss our implementation of the self-refinement method.\nThe web can be formalized as a Markov Decision Process (MDP) defined by the tuple (S, A, P, R, \u03b3), where S represents web pages, A denotes user actions (e.g., link clicks), P comprises mostly deterministic state transitions, R quantifies reward function, and y models exploration depth. This formulation frames web navigation as a planning problem: given M = (S, A, R, P, \u03b3), find the policy \u03c0* that maximizes expected cumulative reward $E [\\sum_{t=0} \\gamma^{t}R(s_{t}, a_{t})]$. Although the state and action space is known in such a setting, the transition probability and the reward model are unknown. To this end, in Section 3.2, we attempt to build a validation model that can act as a reward signal in any web navigation environment."}, {"title": "Validation Methods", "content": "In this section, we describe our method for building a domain-agnostic web validator, which can act as a reward signal. Building on the concepts of LLM-as-a-judge [Zheng et al., 2024] and self- critique mechanisms, we utilize (V)LLMs for validation. Moreover, given that the (V)LLMs are highly sensitive to their context windows, we investigate the use of text, vision, multimodality, and hierarchical task summarization for an LLM-based validator.\nPrior work has suggested that providing multimodal observations leads to the best performance in LLM-based planners [Koh et al., 2024, He et al., 2024]. Other research has pointed out that DOM observations are difficult for an LLM-based planner to interpret due to their size and verbosity, often containing irrelevant information for the task at hand. While different methods of prompting planner agents have been tested, the best practice for validation remains unclear. To address this, we investigate the use of text, vision, multimodality, and hierarchical task summarization for an LLM-based validator.\nWe utilize Agent-E [Abuelsaad et al., 2024], a multi-agent system implemented using the Auto- Gen [Wu et al., 2024] framework. Using a hierarchy, Agent-E breaks down fine-grained navigation"}, {"title": "Self-Refine", "content": "Utilizing the self-refine method [Madaan et al., 2023], our approach introduces a self-correcting mechanism for workflow failures. Our system comprises a web navigation agent that plans and executes workflows, complemented by a validator that assesses task completion and provides critical feedback. In cases where a task remains incomplete, the agent leverages the validator's feedback to revise its strategy and reattempt the task. We implement this iterative refinement process within Agent-E by integrating a verifier agent into the existing chat structure, which already includes the planner and user agent. Figure 4 provides a visual representation of the multiagent system at play."}, {"title": "Experiments & Results", "content": "In this section, we show how self-refinement can enhance web navigation without requiring additional human supervision. First, in Section 4.1, we demonstrate the effectiveness of our validation model. Our results highlight the characteristics of various modalities and state representations in prompting (V)LLMs-based validator models. While the validator is not perfect, we show in Section 4.2 that it still leads to significant performance improvements in web navigation tasks when combined with a self-refinement mechanism. Finally, in Section 4.3, we discuss key insights from our experiments to serve as valuable guidance for future practitioners.\nDataset Our experiments are benchmarked using WebVoyager. This dataset comprises 643 tasks that require agents to interact with live websites. These tasks span 15 diverse websites covering various aspects of daily life, including shopping, finding news articles, and booking flights.\nEvaluation Method Since most tasks in the WebVoyager benchmark are open-ended and occur on live websites, there may be more than one correct workflow. A human annotator is employed to observe the agents' workflows and labels each task as 'complete' or 'incomplete.' A task is considered complete only if the agent successfully finishes all parts of the instructed task and remains on the designated website. The Validator Accuracy measures the percentage of times the validator's label and human annotator's labels match.\nModels We use Agent-E as our base web-navigation agent. To remain consistent with prior work benchmarks on WebVoyager [He et al., 2024, Abuelsaad et al., 2024], we utilize GPT-4-Turbo (gpt-4-turbo-preview) as a planner and browser navigator in our Agent-E implementation. For the validator, we use GPT4-Omni, GPT-4-Turbo (for text), and GPT-4V (for vision). Our exact implementation of Agent-E and validator is available at https://anonymous.4open.science/r/Agent-E-7E43."}, {"title": "Validator Results", "content": "This section demonstrates the effectiveness of different validation models that receive different modalities of the workflow. For this experiment, we run Agent-E over each WebVoyager task. We"}, {"title": "Self-Refinement Results", "content": "In Section 4.1, we demonstrate that our validators can, in some cases, detect failed workflows. In this section, we leverage these validators using a self-refinement approach. In this experiment, Agent-E completes and revises its workflows based on feedback from our validator. The experiment is conducted on 322 tasks from the WebVoyager dataset, with the selected tasks evenly distributed across the websites specifically, the task_id with an even number in the WebVoyager dataset."}, {"title": "Technical Challenges and Observations", "content": "During our experimentation, we encountered several technical challenges and made noteworthy observations:\nScreenshot Acquisition Due to variability in website loading times and browser performance, screenshot capture for sequence information was often unsuccessful. To mitigate this issue, we implemented multiple screenshot attempts. Yet, in some cases, all attempts failed. When presenting results for the vision validator, we omitted tasks where no screenshots were captured throughout the workflow.\nJSON Formatting Our validator is prompted to output two parts: 1) the task evaluation and 2) the feedback. To ensure reliable parsing of these two parts, we required the agent to output them in JSON format. In instances where the JSON formatting failed, we had the validator label the workflow as incomplete and proceed with the refinement process.\nModality Specific Performance The combined vision and text approach demonstrated comparable performance to text-only methods and surpassed vision-only approaches in most tasks. We made two notable observations in cases which led to such performance:\n\u2022 For question-answering tasks, the model can more easily verify answers when explicitly stated in text rather than inferred from a series of screenshots. This explains the large jump in performance between the screenshot and multimodal validator for tasks like Google.\n\u2022 The vision-based models exhibited superior performance on complex websites such as booking.com and flights.com. Oftentimes, the navigator would unsuccessfully utilize filters and widgets on such websites, yet the planner agent would assume that the task was completed successfully. In such cases, the task log verifier was seen to be overly optimistic about the task completion. An example can be seen in Figure 5.\nThe variability in performance across different modalities and websites underscores the importance of implementing robust, multi-modal validation strategies. Future implementations can consider adaptive approaches that can dynamically select the most appropriate validation method based on the task and website characteristics. Additionally, practitioners should be prepared to handle technical issues such as inconsistent screenshot capture and JSON parsing failures, potentially by implementing fallback mechanisms or alternative data collection methods."}, {"title": "Conclusion", "content": "In this study, we developed an effective validator and integrated it into a self-refinement mechanism. This approach allowed web agents to detect and self-correct workflow errors without additional human supervision. Our experiments on the WebVoyager benchmark demonstrated significant improvements, boosting task completion rates from 76.20% to 81.24%, surpassing prior state-of-the-art performance. While the overall performance across modalities was comparable, with success rates ranging from 79.25% to 81.24%, we observed significant task-specific variations in effectiveness. This highlights that the best modality for validation is task-dependent, suggesting the need for specialized validators.\nWhile we encountered technical challenges, particularly in screenshot acquisition, our findings underscore the complexity of real-world web environments and provide valuable insights for future research. This work contributes to the development of more reliable and adaptable web agents. It brings us closer to the goal of creating autonomous digital assistants capable of navigating the intricacies of the modern web."}]}