{"title": "Assessing the State of AI Policy", "authors": ["Joanna F. DeFranco", "Luke Biersmith"], "abstract": "The deployment of artificial intelligence (AI) applications has accelerated rapidly. Al enabled technologies are facing the public in many ways including infrastructure, consumer products and home applications. Because many of these technologies present risks either in the form of physical injury, or bias, potentially yielding unfair outcomes, policy makers must consider the need for oversight. Most policymakers, however, lack the technical knowledge to judge whether an emerging AI technology is safe, effective, and requires oversight, therefore policy makers must depend on expert opinion. But policymakers are better served when, in addition to expert opinion, they have some general understanding of existing guidelines and regulations. This work provides an overview [the landscape] of AI legislation and directives at the international, U.S. state, city and federal levels. It also reviews relevant business standards, and technical society initiatives. Then an overlap and gap analysis are performed resulting in a reference guide that includes recommendations and guidance for future policy making", "sections": [{"title": "I. INTRODUCTION", "content": "POLICIES, regulations, standards, laws, trail advances in the associated, new technology. The delay is usually due to the time required to understand the safety and ethical consequences of the technology. That is, any policy framework is informed by science \u2013 and the science always occurs first. Before making claims resulting in regulations to address the claims, the science needs to occur first. When policy tries to predict science, it can result in confusion or worse. For example, soon after the introduction of the railway technology it was thought by some that the speed of a train (either riding or watching one) could cause mental unrest. In response, regulations were considered that required six-foot walls around the tracks. Historically this reaction to innovation is not unusual. The introduction of phones and electricity caused similar safety fears. But once the benefits and issues are understood, policy can be considered (e.g., Interstate Commerce Act in 1887 aimed to regulate and oversee the railroad industry [2]).\nRecent attention to Chatbots highlight the need for regulation given the widespread use and acknowledgement that this type of technology is \u201cunchecked and unregulated\" for inaccuracies, bias, discrimination, and cause privacy violations [3]. Often the challenge in creating laws and regulations is the lack of basic understanding from the law makers. In addition, there is a divergence around the interpretation of ethical principles \u2013 which can turn into uncertainty when prioritizing solutions to addressing ethical principles [4]. The purposes of this work, then, is to serve as a blueprint and facilitate a legal response for responsible and informed policy that manages the risk in using \u0391\u0399."}, {"title": "II. PREVIOUS AND RELATED WORK", "content": "Given the rapid acceleration of AI technologies over the past few years and their increasing integration with everyday life, the relationship between technology and laws, policies, and regulations has been a consistent subject of debate and study. There have been hefty fines for companies that violate data privacy laws (e.g., HIPAA, GDPR) but privacy violations are not the only risk for AI. There are major concerns such as safety, fairness, and ethics at stake. This section aims to provide a brief but substantive analysis of previous work related to this topic.\nAI Ethics in the Public, Private, and non-government (NGO) Sectors [5], aims to map the ethical implications of Al by looking at ongoing work across three distinct sectors. The research prioritized principles, frameworks, and policy strategies aimed at the ethical use and implementation of AI technologies. By examining over one hundred documents from 25 different countries across a set time frame, the authors of this research were able to identify key differences in how Al technologies are being discussed in public, private, and NGO spheres. The paper aggregated ethics codes, principles, frameworks, guidelines, and policy strategies in order to understand how different organizations and sectors view Al ethics, their role in society, and what frameworks exist to manage them. The results of the research analyzed key differences by sector through the following topics: participatory engagement, engagement with law and regulation, consensus topics or areas of agreement, ethical breadth and depth, prominent sectoral differences, and finally omitted topics. The work concluded that public and NGO documents or frameworks were much more participatory in their creation and engagement with the law whereas the private sector was more concerned with privacy and customer related issues [5]. Overall, the work provided a strong analysis of frameworks and guidelines pertaining to AI ethics that exist across the public, private, and NGO sectors.\nIn another study that performed a systematic assessment of the Al policies of 25 countries it was discovered that a large number of countries do not have or are in the process of developing an Al policy. In addition, the policies analyzed had significant differences but overlapped in frequently discussing"}, {"title": "III. Methodology", "content": "The focus of this paper, as stated above, is to provide a"}, {"title": "IV. AI ASSURANCE INITIATIVES", "content": "The large scope of AI and Al assurance issues need to be easily accessible and understandable. In this section we provide an overview of the current landscape of AI assurance initiatives that includes existing laws, directives, reports, and working groups across sectors would be beneficial to assist in policymaker understanding across several categories.\n\nA. U.S. Federal\nThere has been significant activity by the U.S. government with respect to Al and AI assurance, and directives and initiatives have been launched across a broad range of agencies. A sampling of these appears in Table 1 (links to policies"}, {"title": "B. U.S. State", "content": "According to the US Chamber of Commerce, every state has Al legislation either enacted or pending, in 2021 (see Figure 1).\nThese legislative efforts are important for systems builders and users alike."}, {"title": "C. City", "content": "Modern cities represent an ecosystem composed of residents, businesses, schools, and government. As such, cities need to establish a strategy to not only take advantage of the technological opportunities but also protect its citizens from danger. Therefore, a city has a responsibility to create a governance structure and strategy for the development and application of AI in its city's ecosystem \u2013 in particular how the city can most effectively, efficiently, and ethically perform AI risk assessment, use and development of AI systems used in their city.\nSome cities have not published their own strategy which may indicate defaulting to their state or countries strategic plan/effort towards AI. For example, London, usually listed at in the top five wealthiest cities, uses the UK's guidance [15] for AI and the city of Moscow uses Russia's Al strategy [16]. The challenge in creating a response to innovative technology is understanding it. In other words, although they understand there is risk - they do not understand the technology causing the risk. Lack of understanding slows the creation of laws and regulations as the risks and issues need to be understood before consensus is achieved, and unfortunately, some law makers lack in understanding basic AI concepts [17].\nSome cities have developed their own AI strategies. An analysis was performed on AI strategies of three cities that represent major parts of the world (New York City/US, Hong Kong/Asia, and Paris/Europe). The results showed that NYC created a 5-part AI strategy [18], Paris established a 4-part action plan [19], and Hong Kong developed Al guidance consisting of a 4-part practice guide [20]. A qualitative analysis was performed on those results and determined the emerging five overlapping themes among the three AI strategies"}, {"title": "D. International", "content": "Assessing international standards for AI and AI assurance is more difficult, given that civil liberties, privacy, data protection, and security norms and laws are different in each country and differ from that in the U.S. But there are consistent themes across the landscape of international AI assurance initiatives. International activity largely occurs in Europe and the Asia- Pacific sub-regions, where there are significant economic drivers for Al policy and innovation (see Table 5 - links to policies available https://shorturl.at/cgjDL)."}, {"title": "E. Industry Guidelines", "content": "Many of the largest companies in the world, including Microsoft, IBM and Intel have succeeded at rapidly broadening our understanding of AI technology and have created various principles, reports and guidelines that highlight the need to make Al safe and reliable. A sample of these appears in Table 6 (links to policies available https://shorturl.at/cgjDL)."}, {"title": "F. Professional and Technical Societies", "content": "Numerous professional and technical organization, such as the IEEE, have produced AI and Al assurance guidelines. As sample appears in Table 7 (links to policies available https://shorturl.at/cgjDL)."}, {"title": "V. OVERLAP, GAP ANALYSIS AND ROADMAP FOR FUTURE GUIDANCE", "content": "To develop a roadmap for responsible AI, we qualitatively analyzed the six category tables for emerging themes. This analysis resulted in eleven themes outlined in table 8. The categories have some expected overlap across the initiatives described.\nThere are also some appropriate non-overlapping categories, for example, one of the Federal governments and International main concerns is to establish strategies to stay competitive, thus, it is appropriate that the other categories drill down into initiative areas that support the overarching effort to stay competitive such as developing technology that benefits society as a whole \u2013 augmenting human capability, society, and the economy. The city category has some non- overlapping categories involving focus on law and compliance training as well as developing a workforce that can evaluate, apply, and effectively use the available AI technology."}, {"title": "VI. AI TRAINING FOR EXECUTIVES AND LEGISLATORS", "content": "Policymakers have a wealth of resources available to consult in efforts to reduce the potential for AI technology risks for the public. Given that policymakers at all echelons are entrusted with the power to shape the course of Al technology in the future, it is critical that technical and non-technical individuals alike can adequately understand such complex topics as AI and AI assurance. In this regard, education is key and in particular policy makers need to understand that public facing AI, should be explainable, safe, secure, trustworthy, ethical, and fair [23]. It is also important to place a focus on the competencies and skills required of the work force in the AI Sector. The United Nations Educational, Scientific and Cultural Organization (UNESCO), along with urging governments to implement a global AI Ethical Framework, has as a \"Readiness Assessment\" tool available for all to determine the skillset necessary to keep in line with AI regulations [24].\nThere are many online opportunities for AI education. For policy makers it is important to differentiate between technical and nontechnical courses and certifications. For example, there are online course offerings in artificial intelligence and machine learning basics for non-technical professionals (e.g., IEEE, Stanford)"}, {"title": "VII. POLICY CONSIDERATIONS FOR AI AND AI ASSURANCE", "content": "Despite considerable progress being made on Al assurance at all levels, interpreting, reconciling and applying these can be overwhelming as the policy makers face the following risks:\n1. harmonizing the requirements of existing legislation, professional standards, and other mandates and guidance on artificial intelligence,\n2. keeping up with the pace of change,\n3. and technical knowledge gaps limiting AI technology understanding."}, {"title": "VIII. DISCUSSION AND CONCLUSIONS", "content": "The need for Al expertise in policy makers is real. When analyzing the current landscape, policymakers need to be educated on the key tenets of AI assurance in order to facilitate United States AI competitiveness while also safeguarding the safety and dignity of the citizens. Without individuals who can communicate the practical benefits and risks to the average citizen, these technologies may seem \"scary.\" Therefore, policymakers need to be educated on the key tenets of AI assurance in order to facilitate United States A\u0399 competitiveness while also safeguarding the safety and dignity of the citizens. Legislators and policymakers can rely on experts, but they should have some minimal understanding of \u0391\u0399.\nWe will emphasize that Individuals with non-technical backgrounds can make a significant impact on technical fields, given that they understand their proper role and function. Following are recommendations to facilitate makings this impact:\n*   Emphasize effective inter-agency cooperation\n*   Engage the expertise of professional engineers (PE) to take some of the responsibility.\n*   Select committees in both the House and Senate designed specifically for the research, assessment, and development of current Al technologies and assurance standards\n    *   Committees should balance between both technical and non-technical legislators with assistance from outside sources\n*   Presidential Council on Artificial Intelligence Technologies would place the topic at the forefront and should act on developing the American plan for remaining globally competitive in AI while ensuring safety and reliability\n    *   For example, use Alabama S.B. 78 as a frame of reference for an effective, bipartisan way forward\n*   Continue to utilize budgetary tools to fund scientific research and development, particularly for younger populations\n*   Prioritizing the development of STEM fields will have an enormous impact on closing technical \"knowledge gaps\"\nThis list clearly can be expanded to implement responsible AI by helping to inform legislators, policy makers and other responsible government officials at all levels."}]}