{"title": "Intent-Aware Dialogue Generation and Multi-Task Contrastive Learning for Multi-Turn Intent Classification", "authors": ["Junhua Liu", "Yong Keat Tan", "Bin Fu", "Kwan Hui Lim"], "abstract": "Generating large-scale, domain-specific, multilingual multi-turn dialogue datasets remains a significant hurdle for training effective Multi-Turn Intent Classification models in chatbot systems. In this paper, we introduce Chain-of-Intent, a novel mechanism that combines Hidden Markov Models with Large Language Models (LLMs) to generate contextually aware, intent-driven conversations through self-play. By extracting domain-specific knowledge from e-commerce chat logs, we estimate conversation turns and intent transitions, which guide the generation of coherent dialogues. Leveraging LLMs to enhance emission probabilities, our approach produces natural and contextually consistent questions and answers. We also propose MINT-CL, a framework for multi-turn intent classification using multi-task contrastive learning, improving classification accuracy without the need for extensive annotated data. Evaluations show that our methods outperform baselines in dialogue quality and intent classification accuracy, especially in multilingual settings, while significantly reducing data generation efforts. Furthermore, we release MINT-E, a multilingual, intent-aware multi-turn e-commerce dialogue corpus to support future research in this area.", "sections": [{"title": "1 Introduction", "content": "Chatbots are essential on international e-commerce platforms, offering 24/7 customer service. Users typically engage with these chatbots through multi-turn conversations to achieve their goals. Therefore, it is crucial for the chatbot to accurately identify the user's intent at each turn using a Multi-Turn Intent Classification (MTIC) model. To improve accuracy, MTIC models should consider"}, {"title": "2 Intent-aware Question Answer Dialogues", "content": ""}, {"title": "2.1 Single-turn", "content": "In a closed domain question answering (QA) system, we have a set of predetermined intent classes $I = {l_i}_{i=1}^{k}$, ranging from informational queries to action-oriented requests. Here, we assume that a dataset of single-turn question-intent pairs $D = (x_i, y_i)$ can be easily accessible, where $x_i$ denotes the question and $y_i \\in I$ is its labelled intent. This dataset is described as single-turn because all $x_i$ on their own are standalone complete utterances and are semantically clear for intent inference."}, {"title": "2.2 Multi-turn", "content": "The key difference between single-turn and multi-turn QA is the presence of history. In a multi-turn conversation C with number of turns t, we have an alternating sequence of t question and answer pairs, and each question is associated with an intent. Formally, $C = {(q_1, I_1, a_1), ..., (q_t, I_t, a_t)}$, where $q_t$ is the question at t-th turn, $I_t$ is its intent, and $a_t$ is the corresponding answer. We now define the task for e-commerce multi-turn conversation question generation. Given an intent $I_t$, and a conversation history"}, {"title": "3 Intent-aware Dialogue Generation", "content": "Figure 3 shows the detail workflow of intent-aware dialogue generation, which comprises two main stages: domain knowledge extraction and question generation."}, {"title": "3.1 Domain Knowledge Extraction", "content": "As LLMs do not possess domain-specific knowledge out-of-the-box, this step is imperative to extract the knowledge to be injected into the conversation generation process, bridging the gap for business usage. There are two domain-specific knowledge to account for when generating a conversation, namely the number of turns in each conversation and the intent transition from intents of historical questions. These two combined will guide the generation of each conversation."}, {"title": "3.1.1 Turn Number Estimation", "content": "From the real-life chat logs between the platform user and agent, the probability distribution of the number of turns of each conversation $P(T)$ is observed. Before generating a conversation, the number of turns in the conversation T is first decided by sampling from $P(T)$."}, {"title": "3.1.2 Intent Transition Matrix", "content": "Other than the number of turns, we also need to know the sensible sequence of intents that users might have in a conversation. Just like the number of turns, the intent transition information is also gathered from the chat logs. One limitation here is that the intent from chat logs is inferred by an intent recognition model trained on the single-turn data D. Each $q_t$ is inferred separately without considering $h_t$ to obtain $I_t$ for the t-th turn. That said, by the Law of Large Numbers, if we gather the statistics from a reasonable large number of chat logs, the intent transition matrix obtained will provide a good estimation to true intents. Hereby, the initial intent distribution $P(I_1)$ is specified in a row matrix, while the intent transition $P(I_t | I_{t-1})$ is defined in another $|I|\\times|I|$ matrix. Note that the $P(I_t | I_{t-1})$ here is time invariant, the probability of $P(I_j|I_i)$ will be the same regardless of t. Using this statistical approach, we are able to sample a probabilistic chain of intent with the sampled number of turns and intent transition matrix. The sampled chain of intent plays a crucial role in the following question generation process."}, {"title": "3.2 Chain-of-Intent", "content": "We introduce Chain-of-Intent, an effective method for self-play generation of intent-aware dialogues. Our approach utilizes a HMM to generate sequences of user intents in specific domains and integrates LLMs to produce coherent and context-aware dialogues."}, {"title": "3.2.1 Intent Sampling with HMM", "content": "The HMM models the user's interaction with the chatbot, where the intents are the hidden states and the utterances are the observations. To capture realistic intent flows within specific domains, we extract domain knowledge from historical chat logs by calculating:\n\n*   The turn distribution $P(T)$: the probability distribution of the number of turns in a conversation.\n*   The initial intent distribution $P_{init}$: the probability distribution of intents at the first turn.\n*   The intent transition distribution $P_{trans}$: the probability of transitioning from one intent to another.\n\nUsing these distributions, we sample the number of turns T from P(T), the initial intent $I_1$ from $P_{init}$, and subsequent intents $I_t$ from $P_{trans}$ based on $I_{t-1}$.\nFormally, we define the HMM as:\n$P(S_{1:T}, Y_{1:T}) = P(S_1)P(Y_1|S_1) \\prod_{t=2}^{T} P(S_t|S_{t-1})P(Y_t|S_t)$(1)\nIn our case, $S_t$ corresponds to the intent $I_t$, and $Y_t$ corresponds to the user's utterance (question) at turn t. The observation model $P(Y_t | S_t)$ is modeled by uniformly sampling a question $X_t$ from the set of questions in the single-turn dataset D that are labeled with intent $I_t$:\n$P(X_{1:T}, I_{1:T}) = P(I_1)P(X_1|I_1) \\prod_{t=2}^{T} P(I_t|I_{t-1})P(X_t|I_t)$ (2)\nAfter sampling intents and utterances according to this model, we obtain a sequence of questions $q_{1:T}$."}, {"title": "3.2.2 Limitations of Classic HMMs", "content": "While HMMs can model sequences of intents and generate corresponding utterances, they have significant limitations in capturing the dependencies present in natural human conversations. Specifically, classic HMMs assume that observations (utterances) are conditionally independent given the current state (intent), and that the next state depends only on the current state. This independence assumption neglects the rich context and dependencies in multi-turn dialogues, such as anaphora resolution and ellipsis. For example:"}, {"title": "3.2.3 Enhancing HMMs with LLMs", "content": "To overcome these limitations, we integrate LLMs into the HMM framework, allowing us to generate dialogues that are coherent and context-aware. Specifically, we leverage the LLM's in-context learning ability to generate each user utterance $q_t$ and the corresponding chatbot response $a_t$, conditioning on the conversation history up to turn t - 1.\nFor question generation at turn t, we construct an instruction prompt $S_q(I_t, X_t)$ that includes the current intent $I_t$ and a sample question $X_t$ associated with $I_t$ (to provide context and clarify the intent). This prompt guides the LLM to generate a user question $q_t$ that is coherent with the conversation history $h_t = {(q_1, a_1),..., (q_{t-1}, a_{t-1})}$. The complete input prompt for question generation is:\n$P_q = {S_q(I_t, X_t), h_t}$\nSimilarly, for answer generation, we provide a simple guidance $S_a$ along with the conversation history and the current question $q_t$. The complete input prompt for answer generation is:\n$P_a = {S_a, h_t, q_t}$\nBy generating both questions and answers in this way, the LLM can utilize all previous utterances and intents, effectively capturing dependencies and producing more natural dialogues.\nFormally, we generalize Equation 2 to:\n$P(q_{1:T}, I_{1:T}) = P(I_1)P(X_1|I_1)P(q_1|I_1, X_1)$\n$\\times[\\prod_{t=2}^{T}P(I_t|I_{t-1})P(X_t|I_t)P(a_{t-1}|q_{1:t-1})$$\n$\\times P(q_t| I_t, X_t, q_{1:t-1}, a_{1:t-1})$ (3)\nThis formulation captures the dependencies between the generated questions and answers and their history, overcoming the limitations of classic HMMs.\nThis generative process results in a conversation:\n$C = {(q_1, I_1, a_1), ..., (q_T, I_T, a_T)}$"}, {"title": "3.2.4 Answer Ranking", "content": "For each conversation, we generate an alternative response for the last turn using a smaller LLM, namely Meta-Llama-3-8B-Instruct [9]. This produces an alternative conversation $C_{llama}$, where the last answer is replaced with $a_{llama}$\nTo evaluate and compare the quality of the responses, we perform a point-wise evaluation using GPT-4, asking it to rate the quality of the last answer in each conversation on a scale from 1 to 10, given the chat history and the last question, we use an input prompt:\n$P_e = {S_e, h_t, q_T, a_T}$\nwhere $S_e$ is the instruction for evaluation.\nBy comparing the scores of C and $C_{llama}$, we can determine which answer is better. This ranking information is useful for downstream tasks, such as training the MTIC model with multi-task contrastive learning, as described in Section 4."}, {"title": "3.3 MINT-E", "content": "Using the proposed pipeline, we present MINT-E, a large multilingual intent-aware multi-turn e-commerce dialogues corpus. The statistics of MINT-E, together with two existing dialogue corpus, namely Ubuntu Dialogue Corpus (UDC) and MSDialog, is shown in Table 1. The statistics of MINT-E are obtained by averaging across all markets. Only markets with language separable by white spaces, such as BR, ID, MY, PH, SG, and VN, are included.\nAs ID is the main market with the most traffic online, we observe the top 15 intents based on the question-level ratio in ID generated dataset. The top user intent is to check delivery status, which makes up to 13.8% of the questions. We also observed a long-tailed distribution with the top 10 intents taking up more than 50% of the questions. The detail distribution is included in Appendix.\nNotably, while MSDialog contains only 12 unique intents and UDC lacks intent annotations altogether, MINT-E encompasses 381 distinct intents. This extensive range allows for more granular intent classification, reflecting the complexity and variety of real-world user interactions in e-commerce settings.\nMoreover, MINT-E is a multilingual corpus, covering eight different markets with diverse languages. In contrast, both UDC and MSDialog are predominantly in English. This multilingual aspect of MINT-E makes it particularly valuable for developing and evaluating MTIC models in diverse linguistic environments, addressing the challenges associated with intent classification across different languages and cultures.\nAlthough MINT-E has fewer sessions and questions compared to UDC and MSDialog, the data is richer in terms of intent diversity and domain specificity. The average number of words per question in MINT-E is around 11, similar to UDC, which suggests concise and natural conversational exchanges typical in chatbot interactions. MSDialog, on the other hand, has a much higher average of 75.91 words per question, indicating longer and more complex queries that may not reflect typical user behavior in e-commerce platforms. Additionally, MINT-E focuses specifically on e-commerce dialogues, providing domain-specific context that is highly relevant for training and evaluating chatbot systems in this sector. The corpus includes real-world scenarios and user intents that are common in online shopping experiences, making it a practical resource for both researchers and practitioners.\nIn summary, MINT-E's advantages over benchmark datasets like UDC and MSDialog include:\n(1) Extensive Intent Coverage: With 381 unique intents, MINT-E allows for detailed and nuanced intent classification, capturing the complexities of user interactions in e-commerce."}, {"title": "4 Multi-Turn Intent Classification", "content": "To assess the effectiveness of the MINT-E corpus, we focus on a relevant downstream task: Multi-Turn Intent Classification (MTIC). This section details the MTIC task, introduces our proposed training framework MINT-CL, which incorporates multi-task contrastive learning, and describes the experimental settings used to evaluate our approach."}, {"title": "4.1 Task Definition", "content": "In MTIC, the goal is to predict the user's intent at the current turn of a conversation by considering both the current utterance and the preceding dialogue context. Given a conversation with a sequence of user utterances ${q_1, q_2,, q_t}$, the task is to determine the intent $I_t$ associated with the latest utterance $q_t$, utilizing the information from all previous turns. The input of the model concatenates all user utterances into a single sequence $q_{all}$, separated by commas:\n$q_{all} = < q_1 >, < q_2 >,..., < q_t > $"}, {"title": "4.2 Language Model", "content": "The language model used for classification is designed to handle the hierarchical nature of intents, organized into a three-level taxonomy. To capture both local and global hierarchical information, we combine a label-attention mechanism with a hierarchical text classification (HTC) approach inspired by HiTIN [61]."}, {"title": "4.2.1 Text Representation", "content": "We utilize the XLM-ROBERTa-base model to obtain contextual embeddings of the input text. Specifically, we extract the embedding corresponding to the [CLS] token to represent the entire input sequence:\n$H = \\Phi_{XLM-R}(q_{all})[CLS] \\in \\mathbb{R}^d$\nwhere $\\Phi_{XLM-R}$ denotes the XLM-ROBERTa encoder, and d is the dimension of the hidden state. The encoder is further pre-trained on our in-domain corpus to enhance its representation capabilities."}, {"title": "4.2.2 Label-Attention Mechanism", "content": "To leverage local information at each level of the intent hierarchy, we employ a label-attention mechanism with separate classifier heads for each layer. For each layer l, we compute an intermediate representation $L_l$:\n$L_l = \\begin{cases}\nH\\cdot W^1 + b^1, & \\text{if } l = 1,\\\\\n(H \\oplus L_{l-1})W^l + b^l, & \\text{if } l > 1,\n\\end{cases}$\nwhere $W^l \\in \\mathbb{R}^{d \\times d}$ for l = 1 and $W^l \\in \\mathbb{R}^{2d \\times d}$ for l > 1, $b \\in \\mathbb{R}^d$, and $\\oplus$ denotes concatenation. This setup allows each layer to incorporate information from the previous layer's output.\nThe logits for each layer are then calculated as:\n$H_{local} = L_lW^l + b^l$\nwhere $W^l \\in \\mathbb{R}^{d \\times |I_l|}$ and $b^l \\in \\mathbb{R}^{|I_l|}$, with $|I_l|$ being the number of classes at layer l."}, {"title": "4.2.3 Hierarchical Text Classification Component", "content": "To capture global hierarchical information, we integrate an HTC component inspired by HiTIN. In this approach, a tree network is constructed based on the intent taxonomy, and messages are propagated in a bottom-up manner. The text representation H is broadcast to the leaf nodes, and through hierarchical message passing, we obtain global logits $H_{global}^l$ for each layer."}, {"title": "4.2.4 Ensembling and Prediction", "content": "We combine the local and global logits for each layer:\n$\\Upsilon_l = softmax(H_{local} + H_{global})$\nTo ensure consistency across the hierarchy, we perform a beam search over the three layers to predict the final intent."}, {"title": "4.3 MINT-CL", "content": "To enhance the model's performance, we introduce MINT-CL, a multi-task learning framework that incorporates a response ranking task using contrastive learning for MTIC. This framework effectively aids LLM in learning more robust representations by distinguishing between high-quality and lower-quality responses."}, {"title": "4.3.1 Response Ranking Task", "content": "For each conversation, we generate two responses for the last turn: a high-quality response $a^+$ and a lower-quality response $a^-$. These responses are obtained from different models or configurations, such as using different language models or varying the generation settings.\nWe create input pairs by concatenating the conversation history with each response, separated by the [SEP] token:\n$c^+ = q_{all} [SEP] a^+ $\n$c^- = q_{all} [SEP] a^-$ (4)\nThese inputs are then encoded using the same encoder:\n$H_c^+ = \\Phi_{XLM-R}(c^+) [CLS]$\n$H_c^- = \\Phi_{XLM-R}(c^-)[CLS]$ (5)"}, {"title": "4.3.2 Contrastive Loss", "content": "We employ a contrastive loss similar to [11] to encourage the model to assign higher scores to better responses:\n$L_{contrastive} = -log(\\frac{exp(L^+)}{exp(L^+) + exp(L^-)})$ (6)\nwhere\n$L^+ = \\mathbf{H_c^+ W^z} + b^z$\n$L^- = \\mathbf{H_c^- W^z} + b^z$\nand $\\mathbf{W^z \\in \\mathbb{R}^{d \\times 1}}$ and $b^z \\in \\mathbb{R}$ are the weights and bias for the ranking task."}, {"title": "4.3.3 Combined Training Objective", "content": "The final loss function is a weighted sum of the intent classification loss $L_{intent}$ and the contrastive loss $L_{contrastive}$:\n$L = L_{intent} + \\lambda L_{contrastive}$\nHere, $\\lambda$ is a hyperparameter that balances the contribution of the contrastive loss. Through manual tuning, we found that setting $\\lambda = 0.3$ yields the best results."}, {"title": "5 Experiments", "content": "To evaluate our proposed methods, we conducted a series of experiments across datasets from eight different markets. The assessment employed two main metrics: the quality of the generated dialogues and the accuracy on the downstream MTIC tasks. This section outlines the datasets used, the experimental setups, the experimental results and discussion."}, {"title": "5.1 Datasets", "content": "We utilized e-commerce question-intent datasets from eight markets: Brazil (BR), Indonesia (ID), Malaysia (MY), the Philippines (PH), Singapore (SG), Thailand (TH), Taiwan (TW), and Vietnam (VN). Table 2 provides details on the primary languages, number of intents, and the size of the datasets for each market. Among these, SG, MY, and PH primarily use English, while the others communicate in their native languages during conversations.\nTo extract domain-specific knowledge, we collected about 100,000 online chatbot sessions from each market. This data helped us estimate the market-specific turn distribution $P(T)$, initial intent distribution $P(I_1)$, and intent transition distribution $P(I_t | I_{t-1})$."}, {"title": "5.2 Settings for Dialogue Quality Evaluation", "content": "We evaluated the quality of the synthetic dialogues using the GPT-4 model. The assessment focused on language fluency, logical flow of topics, and the coherence of questions within each session. Conversations were rated on a scale from 1 to 10, where 1 indicated poor quality and 10 represented excellent quality. The overall score was calculated by averaging the ratings across all evaluated conversations. The prompt for this evaluation can be found in Appendix A.4.\nSince our task setting is relatively new, we compared our method against the following baselines:\n(1) Random: Intents and questions were randomly selected without any domain knowledge, although the turn distribution $P(T)$ was maintained."}, {"title": "5.3 Settings for Downstream Task", "content": "To further validate our approach, we test the models on the MTIC task. In this task, given a conversation history of user questions $h_t$ and the last question $q_t$, the goal is to predict the intent $I_t$ of the last question using all previous questions $q_{1...t-1}$ as context. The test sets were drawn from online chat logs, with the intents of the last questions manually annotated. Earlier questions in the conversations were not annotated. We excluded single-turn conversations to focus on the multi-turn aspect. We designed several experiments to understand the impact of our methods."}, {"title": "5.3.1 Baseline: Single-Turn Data (ST)", "content": "As a starting point, we trained the model using only the single-turn question-intent pairs from our datasets. The model was optimized using standard cross-entropy loss for intent classification."}, {"title": "5.3.2 Incorporating Multi-Turn Data (MT)", "content": "To evaluate the effect of multi-turn data, we added the generated multi-turn dialogues from the MINT-E corpus to the training set. Each multi-turn conversation was broken down into training samples by concatenating the conversation history up to each turn:\n${(q_1, I_1), (q_1, q_2, I_2), . . ., (q_1, q_2, ..., q_t, I_t)}$\nThis approach allowed the model to learn from the context provided by earlier turns."}, {"title": "5.3.3 Multi-Task Learning Strategies", "content": "We explored two multi-task learning strategies to enhance the model's performance:\n\n*   Binary Classification for Response Ranking (RR): We introduced an auxiliary task where the model predicts whether a given response is of high quality. Responses were labeled as high-quality (1) or lower-quality (0), and the model was trained using binary cross-entropy loss alongside the intent classification loss.\n*   Contrastive Learning for Response Ranking (CR): Instead of assigning labels, we used contrastive learning to teach the model to differentiate between better and worse responses. The model learned to assign higher scores to superior responses within a pair."}, {"title": "5.3.4 Training Details", "content": "For both multi-task learning approaches, the intent classification and response ranking tasks shared the same encoder weights (XLM-ROBERTa-base). To balance the number of samples for the response ranking task, we randomly selected responses from different intents to serve as negative examples.\nWe fine-tuned the XLM-ROBERTa-base model with a learning rate of $2 \\times 10^{-5}$, using a batch size of 32 over three epochs. The hyperparameter $\\lambda$, which controls the weight of the contrastive loss, was set to 0.3 based on validation results."}, {"title": "5.4 Results and Discussion", "content": ""}, {"title": "5.4.3 Discussion and Limitations", "content": "Our experiments show that integrating domain knowledge with LLM, as done in MINT-CL, noticeably enhances dialogue quality and improves performance on downstream tasks. The results suggest that leveraging multi-turn data and multi-task learning is beneficial, especially in markets where the language model performs well.\nHowever, challenges persist in low-resource languages where LLMs are less effective. Future work could focus on improving language models for these languages or exploring alternative methods to generate high-quality dialogues in multilingual settings."}, {"title": "6 Ablation Study", "content": ""}, {"title": "6.1 Component Ablation", "content": ""}, {"title": "6.1.1 Effect of Removing LLM Enhancement", "content": "We examine the impact of individual components in the generation pipeline, specifically the HMM base model and the LLM enhancement, on overall performance.\nFirstly, we explore using HMM without LLM enhancement by randomly sampling utterances from similar questions under the intents generated by HMM. As shown in Table 3, the dialogue quality decreases by an average of 0.88 points without LLM generation. This drop occurs because the original HMM is limited by its emission independence, generating utterances conditioned solely on the current intent without considering prior context. Nevertheless, the HMM-only variant still achieves competitive performance compared to the golden baseline, demonstrating the strength of intent modeling."}, {"title": "6.1.2 Impact of Removing the Chain of Intent", "content": "Next, we investigate the effect of removing the \"chain of intent\" generated by the HMM, which relies on prior distribution data from real chat logs. When the Markovian constraint is removed and intent is randomly sampled at each turn, we observe a decline in the natural flow of conversation. This results in reduced human-likeness, limited topic diversity, and a lack of authentic multi-turn conversational dynamics. Despite this, high-quality intent sequences remain effective in generating intent-aware dialogues, supporting prior findings that adding intent structure improves dialogue generation quality [14, 41]."}, {"title": "6.2 Generation Quality in Low Resource Languages", "content": ""}, {"title": "6.2.1 Effect of Token Fertility", "content": "Table 5 illustrates that MINT-CL shows weaker results on classification tasks in low-resource languages where LLM-generated content may be of lower quality. We investigated this issue from two key aspects: token fertility and average words per sentence."}, {"title": "6.2.2 Impact of Sentence Length", "content": "Additionally, we observe that the average number of words per question in MINT-E exceeds that of the golden dataset by 4 words, as shown in Table 6. This discrepancy in sentence length may introduce extraneous information during model training, further affecting classification task performance. Overall, these analyses confirm that LLM generation quality plays a crucial role in the effectiveness of our pipeline, particularly in low-resource language scenarios."}, {"title": "7 Related Work", "content": "Multi-turn Dialogue Generation (MTDG) emerge from both academics and industry due to its relevance to real-world applications such as chatbots and information-seeking systems [20]. However, they face challenges such as the data sparsity [17, 54, 55]. Moreover, MTDG requires more complex information and constraints [3, 56, 58], posing additional challenges. In general, dialogue generation are categorised in open-domain generation and task-oriented generation [22]."}, {"title": "8 Conclusion", "content": "Effective Multi-Turn Intent Classification (MTIC) in chatbot systems requires large-scale, domain-specific, multilingual multi-turn dialogue datasets. Creating such datasets require tremendous time and resources. To tackle this challenge, we first proposed Chain-of-Intent mechanism, which leverages LLM-enhanced HMMs to model sequences of user intents based on prior knowledge extracted from historical chat logs. By sampling intent transitions and turn distributions, the LLM effectively capture realistic intent flows and generates coherent and contextually appropriate multi-turn dialogues. Furthermore, we introduced MINT-CL, a framework that employs multi-task contrastive learning for MTIC, which is able to learn robust representations by incorporating additional training signals, thereby improving intent classification accuracy in multilingual and resource-constrained settings. Lastly, we released MINT-E, a multilingual, intent-aware, multi-turn e-commerce dialogue corpus generated using our framework. Our experiments demonstrate promising results in quality evaluation of the dataset and model performance for MTIC downstream tasks across languages."}, {"title": "A Prompts", "content": ""}, {"title": "A.1 Prompt for question generation", "content": "The prompts for GPT-4 will typically involve three distinct roles: system, user, and assistant. In the following example, the messages for each role are clearly distinguished by their respective role, denoted by [role] tags. Variables are encapsulated in between \"{\" and \"}\" symbols.\nPrompt for question generation"}, {"title": "A.2 Prompt for answer generation", "content": ""}, {"title": "A.3 Prompt for answer rating", "content": ""}, {"title": "A.4 Prompt for session quality rating", "content": ""}]}