{"title": "United in Diversity? Contextual Biases in LLM-Based Predictions of the 2024 European Parliament Elections", "authors": ["Leah von der Heyde", "Anna-Carolina Haensch", "Alexander Wenz"], "abstract": "Large language models (LLMs) are perceived by some as having the potential to revolutionize social science research, considering their training data includes information on human attitudes and behavior. If these attitudes are reflected in LLM output, LLM-generated \u201csynthetic samples\" could be used as a viable and efficient alternative to surveys of real humans. However, LLM-synthetic samples might exhibit coverage bias due to training data and fine-tuning processes being unrepresentative of diverse linguistic, social, political, and digital contexts. In this study, we examine to what extent LLM-based predictions of public opinion exhibit context-dependent biases by predicting voting behavior in the 2024 European Parliament elections using a state-of-the-art LLM. We prompt GPT-4-Turbo with anonymized individual-level background information, varying prompt content and language, ask the LLM to predict each person's voting behavior, and compare the weighted aggregates to the real election results. Our findings emphasize the limited applicability of LLM-synthetic samples to public opinion prediction. We show that (1) the LLM-based prediction of future voting behavior largely fails, (2) prediction accuracy is unequally distributed across national and linguistic contexts, and (3) improving LLM predictions requires detailed attitudinal information about individuals for prompting. In investigating the contextual differences of LLM-based predictions of public opinion, our research contributes to the understanding and mitigation of biases and inequalities in the development of LLMs and their applications in computational social science.", "sections": [{"title": "1. Background", "content": "Large language models (LLMs) have recently emerged as a new tool for researchers in computational social science, potentially complementing existing methods for better understanding human attitudes and behavior. For example, research has started to assess to what extent LLM-generated \"synthetic samples\u201d can be used as a viable and efficient alternative for collecting data about public opinion (Argyle et al., 2023, Bisbee et al., 2024, Dominguez-Olmedo et al., 2023, Sanders et al., 2023). Textual LLM output reflects a probability of how likely a given word is followed by another word, conditional on the training data and contextual information provided in the specific prompt. Since LLMs are trained on large amounts of human-generated text data, their output potentially reflects human attitudes and behaviors. Thus, researchers hope that by conditioning an LLM with specific individual-level information in a prompt, the LLM could be prompted to respond from that individual's perspective. This approach could then be scaled up, synthesizing public opinion data for entire human samples with LLMs. Such samples could ease the collection of previously unobserved public opinion data, including, but not limited to, data about hard-to-survey populations, sensitive topics, or future outcomes, and allow for fast and low-cost questionnaire pre-testing and pilot studies.\nHowever, previous research has found biases in LLM output with regard to various outcomes, including political attitudes and psychological measures (Atari et al., 2023, Durmus et al., 2023, Santurkar et al., 2023, von der Heyde et al., 2024, Sanders et al., 2023, Kim & Lee, 2023, Lee et al., 2023, Wang et al., 2023). Specifically, depending on the target population, it is possible that LLM-synthetic samples are affected by coverage bias due to unrepresentative training data regarding linguistic, social, political, and digital contexts, such as native language prevalence, social structure, party system, and online behavior (von der Heyde et al., 2024). With more than 50% of internet content estimated to be English, the amount of available native-language training data for LLMs is considerably smaller for countries with any other native language (W3Techs, 2024). Moreover, the relationship between societal and political structure and public opinion formation differs between countries, and may not be sufficiently represented in LLM training data. Finally, it is very likely that the training data is affected by coverage bias caused by the \u201cdigital divide\u201d (Lutz, 2019). There may be differences between the respective target population and those who contributed to the specific texts selected for training LLMs (Clemmensen et al., 2023, Shaw & Hargittai, 2018, Hoffmann et al., 2015, Blank, 2013, c.f. International Telecommunication Union, 2022). For instance, the training data for GPT-3 is made up of few sources of internet text, which generally tend to be authored by rather small and homogenous communities. For example, it heavily relies on the English-only Wikipedia, which is largely written by U.S.-based males (Wikipedia, 2023, c.f. Hill & Shaw, 2013). Such biases can challenge the validity of findings using LLM-synthetic samples, and risk reinforcing existing biases in social science research, policymaking, and society. Therefore, computational social scientists need to investigate the conditions under which LLM-generated synthetic samples can be applied for public opinion prediction by comparing different linguistic, political, social, and digital contexts.\nLLM-synthetic samples estimating public opinion, particularly vote choice, have yielded promising results in the context of the U.S. general population (Argyle et al., 2023, Lee et al., 2023, Kim & Lee, 2023). Other research has challenged these results, particularly in other"}, {"title": "2. Data and Methods", "content": "To examine biases of LLM-synthetic samples in a variety of linguistic, social, political, and digital contexts, our study spans all 27 EU member states (EU-27). For an additional in-depth investigation of differences in LLMs' predictive performance across languages, we select five countries differing in native language internet coverage, linguistic prevalence within the EU, language family, as well as in population size, geographic and political position within, and attitudinal position towards Europe (for details, see Appendix III): France, Germany, Poland, Slovakia, and Sweden, with Ireland serving as an English-language baseline.\nTo create a realistic sample of individual-level profiles on which we base our predictions of vote choice in the 2024 European Parliament elections, we rely on the most recent available Eurobarometer survey data (EB 99.4) from May-June 2023. This data has been collected with face-to-face interviews of EU citizens aged 15 years and over and resident in the EU-27, based on stratified, multi-stage probability samples (European Commission, 2024). From this data, only voting-eligible EU citizens are selected, resulting in a sample of about n=1000 per EU member state (with the exception of Luxembourg and Malta, with a sample size of about n=500 each) or about 26,000 respondents in total. For summary statistics of all variables, see the online appendix.\nSimulating a realistic use-case, we use one of the currently most popular and powerful LLMs at the time of data collection, GPT-4-Turbo (version 2024-04-09). This model has the most recent training data corpus of all GPT models, with a cutoff date in December 2023, while being cheaper than the standard GPT-4. Further, it is supposed to have better multilingual capacities, be better at solving complex instructions, and less likely to \u201challucinate\u201d, that is, provide fabricated output (OpenAl, n.d.). Finally, while it is more expensive than GPT-3.5-Turbo, its performance in predicting public opinion is better when adding information beyond demographics (Lee et al., 2023), and in different languages (Wang et al., 2023)."}, {"title": "2.2. Prompt creation", "content": "For each individual in the Eurobarometer sample, we create a description including socio-demographic and attitudinal information with which we prompt the LLM using second-person pronouns (Bisbee et al., 2024). Prompts vary with regards to citizens' age, gender, education, socio-economic class, occupation status, and urbanity. Additionally, the profiles include information about individuals' political interest, ideology, trust in the EU, and"}, {"title": "2.3. LLM configuration", "content": "We automate the collection of the GPT-based data through the Azure-OpenAl and OpenAI APIs (OpenAl et al., 2023). We employ zero-shot prompting we do not provide the LLM with any example outputs and do not specify a custom system message priming the LLM to behave in a certain way, having included a format request directly in the prompt instead. In line with previous studies (Bisbee et al., 2024, Aher et al., 2023, Tjuatja et al., 2024, Lee et al., 2023), we configure the LLM to a temperature of 0.9 (on a scale of 0 to 1, 0 leads to more deterministic, that is, repetitive outputs, while 1 allows for more probabilistic outputs, sampling from the entire probability distribution of possible completions). To further control the LLM's completions' length, we limit the output to a maximum of 40 tokens one token corresponding to approximately 160 characters in the English language. Having tested exemplary completions in all target languages, 40 tokens allow for a response including a complete sentence with all necessary information. As previous research showed little variance in individual vote choice predictions when prompting GPT repeatedly (von der Heyde et al., 2024), we only prompt the LLM once per individual. We collect the data shortly before the European elections are held (between June 6 and 9, 2024, depending on the member state), between May 29 and June 4, 2024."}, {"title": "2.4. Vote choice extraction", "content": "Since we prompted the LLM to keep its responses concise, we expect token probabilities to not differ much from the displayed text output \u2013 that is, we expect the displayed output to mostly correspond to the token with the highest probability. Therefore, we do not use token probabilities for analytical purposes, but rather examine the actual text output. Instruction-tuned models like GPT-4-Turbo have the advantage of making the text output directly accessible to users. We consider this to be the most straightforward approach we would expect users of LLM-synthetic samples to apply.\nVote choices are extracted from LLM completions based on a set of predefined keywords per competing party, as well as non-voting and invalid voting (see the online appendix). As European elections typically feature a large number of very small political parties beyond the ones established in national politics, votes for parties that do not meet the respective country's electoral threshold in the official results (Sabbati & Grosek, 2024), or, in cases of no threshold, parties that do not obtain a seat in the newly elected parliament (European Parliament, 2024), are summarized as \u201cOther\u201d for the analyses that follow. As this study aims to depict a realistic use-case as opposed to optimizing predictions a priori, completions that do not contain a definite party choice are recorded as missing and only counted for turnout calculation if the prediction clearly states the person would have voted, but not for vote share calculations (see the online appendix for proportions of missing values)."}, {"title": "2.5. Analysis", "content": "We weight the extracted results with the Eurobarometer-provided weights to better approximate the target population. To answer our first research question, we compare the aggregate predicted voting behavior when prompted in English to the official national-level results across all 27 countries, differentiating between turnout and party vote shares among voters. Specifically, we compare the mean and variance of predicted and actual turnout, as well as several metrics for correct party vote share prediction, including prediction of the winning party, the rank ordering of parties, and average absolute differences in party vote shares per country as well as across European parliamentary groups as announced in the post-election constitutive session (European Parliament, 2024).\nTo tackle our second research question, we contrast the differences in predicted turnout and party vote shares within the EU-27. We compare countries according to whether they have compulsory voting, their European region (as defined by EuroVoc, n.d.), and their language family (Wikipedia, 2024a). We also analyze the LLM's predictive performance based on prompts in English and the five selected countries' native languages.\nRegarding our third research question, we compare whether predictions containing the full set of information in the prompt perform better than those based solely on socio-demographic information.\nData collection and analysis are conducted using the software R, version 4.3.2 (R Core Team, 2024), especially the packages tidyverse (Wickham et al., 2019), mice (van Buuren, 2018), rgpt3 (Kleinberg, 2024), and survey (Lumley, 2024)."}, {"title": "3. Results", "content": null}, {"title": "3.1. Overall prediction of EU election results", "content": "Despite the capabilities of GPT-4-Turbo, we are still far from using it as a reliable prediction tool for public opinion: Predictions of turnout and party vote shares in the 2024 European elections based on synthetic samples of the voting population fail. With an average predicted turnout of 83%, predictions based on GPT-4-Turbo overestimate turnout by 34 percentage points on average, not capturing the substantial variation between countries (Figure A1). Predictions of turnout almost all range above the total range of actual turnout. Considering party vote shares, GPT-4-Turbo-based predictions mostly fail to predict the winner (11 out of 27) or ranking of parties (Figure 2), with the LLM only identifying 8% of party ranks correctly on average (with a median of 0%). Predictions of individual party vote shares often differ greatly from the actual result (for details, see Figure A2), with average differences of seven to over 15 percentage points per country. This average per country masks a high variation between parties, with larger differences between predicted and actual vote shares especially for parties not belonging to the Green or Left parliamentary groups (Figure A3), confirming findings from previous research (von der Heyde et al., 2024, Motoki et al., 2023) and including the two biggest groups left and right of center. The latter have suffered substantial national losses in recent years, which may not have been picked up by GPT-4-Turbo by way of its training data."}, {"title": "3.2. Differences in predictive performance across countries", "content": "For English prompting overall, GPT-4-Turbo's predictive performance of turnout is higher for countries with high actual turnout (Figure 3), while it overestimates turnout especially for countries with typically low actual turnout. This pattern can be explained by the LLM's tendency to predict rather high turnout regardless of country, and holds even for the four countries with compulsory voting. The difference between predicted and actual turnout is among the lowest for Belgium and Luxembourg, Western European countries with French as an official language, one of the most dominant languages in Europe. In contrast, for Greece and Bulgaria, which are situated in South-East Europe and whose native languages use cyrillic alphabets and are less commonly used, the differences are among the highest."}, {"title": "3.3. Differences in predictive performance across prompt languages", "content": "Compared to Ireland, where English is a native language, English-prompted turnout predictions differ similarly for Germany and France (around 20 percentage points, Figure 5A), but are much higher for Sweden, Poland, and Slovakia (above 30 percentage points). Overall, there is a notable jump in overestimations from Western to Eastern European countries, with Sweden in the middle. In all of the five countries examined, prompting in the native language leads to an even bigger overestimation of turnout than when prompting in English. The difference in difference of turnout estimation between English and native-language prompting is especially strong for France, followed by Slovakia. While there is barely a difference in Poland, the overestimation in the former is particularly large, at over 40 percentage points. When it comes to differences in party vote shares, the pattern somewhat reverses (Figure 5B). Here, native-language prompting tends to outperform English-language prompting, at least in Germany and Sweden. For France and Poland, differences between prompt languages are not very large. Notably, the average difference between predicted and actual vote shares is highest for the benchmark Ireland."}, {"title": "3.4. Differences in predictive performance between prompt versions", "content": "When prompting GPT-4-Turbo in English with only demographic information about European citizens, the LLM tends to overestimate turnout even more (Figure 6A), and make even less accurate predictions of individual party vote shares than when prompted with additional attitudinal information for most countries (Figure 6B). Even in Belgium, where the full prompt led to an underestimation of turnout, GPT-4-Turbo overestimates turnout given only demographic information. For eight countries, predicted vote shares based on demographic information are closer to the actual result than those based on more detailed information. This includes Baltic states, some Eastern European countries, as well as Luxembourg and Malta. The apparent randomness of these results suggests an underlying randomness in when LLM-based predictions of voting behavior are correct, questioning the reliability of the method.\nPer-country-averages of absolute differences between predicted and actual vote shares for"}, {"title": "4. Discussion", "content": "Our results show that overall, GPT-4-Turbo fails at predicting turnout and party vote shares in the 2024 European elections based on synthetic samples of the voting population it overestimates turnout and is largely unable to accurately predict the winner, rank ordering, or individual party vote shares. Only providing socio-demographic information about individual voters further worsens the results, casting doubts on the feasibility of using LLM-based synthetic samples as a supplement or substitution of detailed survey data. Finally, GPT-4-Turbo is especially bad at predicting voting behavior for Eastern European countries and countries with native Slavic languages, regardless of language used or the amount of information provided in the prompt, suggesting systematic contextual biases.\nAs our findings show, LLM-based predictions of public opinion do not live up to the hope of being a general-purpose, resource-efficient alternative predictive tool ahead of future events, as they are not able to capture the complex mechanisms behind public opinion formation equally across contexts. Relatedly, previous research has found that LLMs are better at retrodiction, i.e. retroactively imputing past opinions, than at predicting attitudes on new survey items, policy issues or events that occurred past its training data, instead generalizing along broad ideological lines without regard for nuance (Kim & Lee, 2023, Sanders et al., 2023) something that is reflected in the response distributions, which are different from human-generated survey data, often being less diverse (Bisbee et al., 2024,"}]}