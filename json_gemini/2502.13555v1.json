{"title": "Democratizing Large Language Model-Based Graph Data Augmentation\nvia Latent Knowledge Graphs", "authors": ["Yushi Feng", "Tsai Hor Chan", "Guosheng Yin", "Lequan Yu"], "abstract": "Data augmentation is necessary for graph representation learning due to the scarcity and noise present in graph data.\nMost of the existing augmentation methods overlook the context information inherited from the dataset as they rely\nsolely on the graph structure for augmentation. Despite the success of some large language model-based (LLM)\ngraph learning methods, they are mostly white-box which require access to the weights or latent features from the\nopen-access LLMs, making them difficult to be democratized for everyone as existing LLMs are mostly closed-source\nfor commercial considerations. To overcome these limitations, we propose a black-box context-driven graph data\naugmentation approach, with the guidance of LLMs - DemoGraph. Leveraging the text prompt as context-related\ninformation, we task the LLM with generating knowledge graphs (KGs), which allow us to capture the structural\ninteractions from the text outputs. We then design a dynamic merging schema to stochastically integrate the LLM-\ngenerated KGs into the original graph during training. To control the sparsity of the augmented graph, we further\ndevise a granularity-aware prompting strategy and an instruction fine-tuning module, which seamlessly generates\ntext prompts according to different granularity levels of the dataset. Extensive experiments on various graph learning\ntasks validate the effectiveness of our method over existing graph data augmentation methods. Notably, our approach\nexcels in scenarios involving electronic health records (EHRs), which validates its maximal utilization of contextual\nknowledge, leading to enhanced predictive performance and interpretability.", "sections": [{"title": "1. Introduction", "content": "Graph representation learning has received increas-\ning attention in recent years. It achieves great success\nin solving tasks where relational features are important,\nsuch as recommendation systems [1, 2], citation net-\nworks [3], and medical records analysis [4, 5]. However,\nthe scarcity and noise present in graph data pose great\nchallenges for effective graph learning, necessitating the\ndevelopment of graph data augmentation algorithms.\nExisting graph data augmentation methods focus on\ngraph structures for data augmentation, such as ran-\ndomly dropping nodes or edges, adding Gaussian noise\nto the node or edge attributes, or applying graph-based\ntransformations such as sub-sampling and node permu-\ntation. While these methods have demonstrated some\nsuccesses in graph representation learning scenarios,\nthey do not consider the context or attributes associated\nwith the graph data. This prompts some recent works\n[6, 7, 8, 9, 10, 11, 12] which leverage LLM for graph\nrepresentation learning. Despite their success, they are\nmostly white-box which require access to the weights\nor latent features from the LLMs, making them difficult\nto be democratized as existing LLMs are mostly closed-\nsource for commercial considerations. As a result, the\nresulting augmented graph becomes less identifiable due\nto a lack of contextual guidance. Furthermore, most of\nthese augmentation methods leverage in-domain knowl-\nedge under a close-world setting, which does not borrow\nthe vast repositories of knowledge in the open world.\nAdditionally, the sparsity of the augmented graph is not\nwell studied, although some methods, such as DropEdge,\nattempt to sparsify the graph for augmentation. Without\nproper sparsity control, the augmented graph would be\nover-sparsified and likely reduced to trivial graphs (i.e.,\nuninformative graphs). These limitations pop the neces-"}, {"title": "2. Related Works", "content": "Graph Neural Networks (GNNs). GNNs are gaining\nsignificant success in many problem domains [13, 14,\n15, 16, 17, 18]. They learn node representation by ag-\ngregating information from the neighboring nodes on\nthe graph topology. Most of the existing GNN architec-\ntures are on homogeneous graphs [19, 20, 21, 22]. There\nare also GNN architectures operating on heterogeneous\ngraphs to learn its enriched structural information and\ncomplex relations [23, 14, 24, 25, 26]. However, due\nto limited samples, it is difficult to approximate the true\ndata distribution, especially in the graph domain. Hence,\nan effective graph data augmentation algorithm is needed\nto boost the performance of GNNs.\nGraph Data Augmentation. Graph data augmentation\n(GDA) aims to enhance the utility of the input graph\ndata and produce graph samples close to the true data\ndistribution to alleviate the finite sample bias [27]. Most\nof the existing works focus on perturbating the graph\nstructures or node features/labels to achieve augmen-\ntation, such as node dropping [28], edge perturbation\n[29, 30], graph rewriting [31, 32, 33], graph sampling\n[34, 35, 36], graph diffusion [37, 38, 36, 39] or pseudo-\nlabelling [40]. There are also works that adopt a learn-\nable graph data augmenter and design specific losses for\ntraining [41, 18, 42, 43, 44, 45]. However, these meth-\nods mainly focus on the graph structures without con-\nsidering the contextual information or introducing open-\nworld knowledge. Recent works [6, 8, 11, 12, 10, 46]\non LLM-based GDA have achieved promising improve-\nments. However, current LLM-based methods are mostly\nwhite-box which require access to the weights or latent\nfeatures from the LLMs. It is computationally ineffi-\ncient and impractical, as SOTA LLMs are costly for\nlarge-scale experiments and often closed-source. More-\nover, these methods mostly focus on node-level context\nand neglect the higher-order graph structures. Hence, a\nblack-box LLM-based GDA framework with awareness\nof higher-level graph structure is needed to address these\nlimitations.\nGraph Learning in Healthcare. Knowledge distilla-\ntion from massive EHRs has been a popular topic in\nhealthcare informatics. To address the longitudinal fea-\ntures in the EHR data, several early works [47, 48, 49]"}, {"title": "3. Preliminaries", "content": "Graphs. A graph $G$ is a collection of vertices $V$ and\nedges $\\mathcal{E}$, typically represented as $G = (V, \\mathcal{E})$. Each edge\n$e \\in \\mathcal{E}$ is an ordered or unordered pair of vertices rep-\nresenting the connection between them. In the context\nof graph neural networks, each vertex $v_i$ is often associ-\nated with a feature vector $x_i$ in the feature space $\\mathcal{X}$. A\nknowledge graph (KG) is a specialized type of graph\ndenoted as $KG = (V, \\mathcal{E}, R)$, where $R$ is a set of relation\ntypes. A KG can be constructed from a set of triples\n$\\mathcal{T} = \\{(h_i, r_i, t_i)\\}_{i=1}^n$ where $h_i, t_i$, and $r_i$ are the $i$-th head\nand tail nodes respectively, and $r_i$ is the relation type for\nthe $i$-th triple.\nGraph Data Augmentation (GDA). Given $G = (V, \\mathcal{E})$,\nGDA aims to derive an augmented graph $G_{aug} =$\n$(V_{aug}, \\mathcal{E}_{aug})$, where $V_{aug}$ and $\\mathcal{E}_{aug}$ represent the aug-\nmented set of nodes and edges, respectively. The aug-\nmentation process should preserve or enhance the in-\nherent structure and properties of $G$, while facilitating\nimproved performance of a GNN (denoted as $M$) on\ndownstream tasks."}, {"title": "4. Methodology", "content": "Our proposed framework consists of two main mod-\nules: a knowledge graph construction module with lever-\naging knowledge from LLMs, and a graph data augmen-\ntation module with dynamic knowledge injection. Figure\n2 and Algorithm 1 provide an overview of the workflow\nof our framework."}, {"title": "4.1. Context-Driven Knowledge Retrieval", "content": "General Prompting Strategy. The cornerstone of our\nframework is the construction of KGs using LLMs. The\ncontext-aware KGs serve as enriched contextual do-\nmain knowledge that augments the original graph $G_o$\ntowards the true representation $G_t$. The KG construc-\ntion is facilitated through a prompting mechanism that\nsteers the LLM toward generating subgraphs focused\non specific concepts. The generation process in gen-\neral can be formulated as $\\mathcal{T} \\leftarrow \\text{LLM}(\\text{prompt})$, where\n$\\mathcal{T} = \\{(h_i, r_i, t_i)\\}$ represents the set of triples indicating\nthe relationships between generated concepts. A knowl-\nedge graph $KG$ can then be constructed from $\\mathcal{T}$. We\ndesign modularized prompts (with placeholders for the\ndescriptions) that are based on all the available informa-\ntion (e.g., the summary of datasets, task descriptions)\nof the working graph dataset, such that context knowl-\nedge can be maximally utilized. One example of the\nprompting design on the EHR context is:"}, {"title": "4.2. Augmentation with Generated KGs", "content": "Dynamic Graph Merging. Given a constructed $KG$\nfrom $\\mathcal{T}$ on a sparsity level $s$, we design a dynamic\nmerging schema to merge $KG$ into $G_o$. This allows\nthe model to see more augmented samples $G_{aug}$ as a dif-\nferent merged graph is obtained in each optimization\nstep. For each concept node $v_c \\in V_{KG}$ in $KG$, we select\na subset of nodes $V_o^c = \\{z \\vert z \\in V_o\\} \\subseteq V_o$, where $n_c$\nis the predetermined number of edges per concept node.\nWe connect the concept nodes and the selected nodes\nfrom $V_o^c$ to obtain an edge set\n$\\mathcal{E}_{conn} = \\{(v_c, z) \\vert \\forall v_c \\in V_{KG}, z \\in V_o^c\\}.\nAfter that, the augmented graph $G_{aug} = (V_{aug}, \\mathcal{E}_{aug})$ can\nbe obtained by joining the edge sets and node sets, i.e.,\n$\\mathcal{E}_{aug} = \\mathcal{E}_{conn} \\cup \\mathcal{E}_0 \\cup \\mathcal{E}_{KG}$ and $V_{aug} = V_0 \\cup V_{KG}$.\nThis dynamic merging is not a one-off operation but\nan iterative process. Each training epoch sees the refresh-\nment of KGs based on the model's current state, thereby\nkeeping the graph data dynamic and contextually rich.\nAs the model training proceeds, it continually refines\nthe edge weights and node features based on the newly\nincorporated KGs. This iterative update ensures that the\nmodel does not overfit and generalizes well on unseen\ndata.\nDue to the computation limitations, the number of\nLLM inferences is limited. Therefore, we precompute\nKG offline and merge it with $G_o$ stochastically during\ntraining. Under sufficient computational conditions, the\ndynamic merging schema allows for online prompting\nwhere an up-to-date KG can be generated after every op-\ntimization step. On the other hand, the LLM can also be"}, {"title": "4.3. Adaptability to Other Graph Datasets", "content": "Since EHR contains enriched contextual information\nthat allows for flexible prompting design, we use the\nEHR dataset to illustrate our prompting strategy. How-\never, our prompting strategy is adaptable to other graph\ndatasets, as the placeholders in the modularized prompts\ncan be replaced by information on the target datasets. We\ncan also incrementally enlarge the KG such that knowl-\nedge from the existing domain can be leveraged to the\ntarget domain. We employ a highly-adaptive customiza-\ntion strategy that tailors the prompt structure based on\nthe specific dataset in use. This strategy includes un-\nderstanding the data's content and structure and then\nadjusting the prompts to ensure the generated KGs are\noptimally suited for the data in question."}, {"title": "5. Experiments", "content": "5.1. Experimental Settings\nDatasets and Tasks. (1) We perform experiments\non generic graph benchmarks (Cora, PPI, Actor, and\nCiteseer), where we benchmark our method on node\nclassification tasks. (2) We validate the scalability of\nDemoGraph on two large-scale datasets OGBN-\nproducts and OGBN-arxiv [3] against additional LLM-\nbased methods. Table B.9 and B.10 provide a summary\nof these graph datasets from small to large-scales. (3)\nAdditionally, we highlight an application of our method\non a large-scale EHR dataset MIMIC-III [57]. It\ncontains a publicly available dataset of 46,520 inten-\nsive care unit (ICU) patients over 11 years. We perform\nfour supervised tasks - in-hospital mortality prediction"}, {"title": "5.5. Ablated Analysis", "content": "The Effect of Augmented KGs. We study the effect of\naugmented KGs on downstream task performance (Table\n5), including three scenarios: with KG, without KG, and\nwith a biased (or wrong) KG augmented from another\ndataset (i.e. PPI). It is observed that the model performs\nworse than the baseline (i.e., w/o any augmentations)\nwhen the wrong context is applied, indicating a biased\naugmented graph. On the other hand, improved perfor-\nmance is observed when a context-driven KG is applied,\nthus validating the effectiveness of our method. A visual-\nization of the effect of DemoGraph on node embeddings\ncan also be found in Figure 4.\nThe Effect of Dynamic Merging. We evaluate the con-\ntribution of the dynamic merging schema, as summarized\nin Table 6, where static merging means that the KG are\nmerged into $G_o$ offline before training. We observe that\nthe performance improved on all generic graph datasets\nwith dynamic merging, which validates the contributions\nof the schema.\nThe Effect of Sparsity Control. We demonstrate\nhow different levels of sparsity affect the performance of\ngraph data augmentation. We control the level of sparsity\nusing the number of edges per concept $\\vert \\mathcal{E}_{conn} \\vert$ used for\nKG generation. Table 7 presents the results of this study.\nGiven a fixed number of concepts, the performance im-\nproves when $\\vert \\mathcal{E}_{conn} \\vert$ increases, demonstrating the effec-\ntiveness of graph merging. However, when $\\vert \\mathcal{E}_{conn} \\vert$ is too\nlarge compared to the original graph size, the augmented\ngraph would be biased from too many noisy connections,\nand hence the observed performance deteriorates.\nThe Influence of Different Granularity and Instruc-\ntion Fine-tuning. We evaluate the influence of different\ngranularity and instruction fine-tuning (IFT) on augmen-\ntation performance. From Table 8, it is observed that the\nperformance is improved when an appropriate $s$ is cho-\nsen, while adopting a multi-granularity ($s_0 + s_1$) could\npotentially lead to over-sparsification. With KG concepts\npruned by IFT, the performance is consistently improved\non different granularity levels."}, {"title": "6. Conclusion", "content": "We propose a novel framework for graph data augmen-\ntation, namely DemoGraph, which leverages the open-\nworld knowledge in LLMs to perform context-driven\ngraph data augmentation. Our method directly operates\non knowledge graphs constructed from LLM outputs and\ndoes not require access to model weights and features,\nwhich enables democratization to most of the closed-\naccess LLMs. To tackle the sparsity induced by gener-\nated knowledge graphs, we design a granularity-aware\nprompting strategy to control the sparsity while maxi-\nmizing the utility of domain knowledge. Experiments on\ngeneric graph datasets and a medical records dataset with\nan array of GNN architectures validate that our method\ncan better augment the graph data than existing methods.\nAblation analysis on key components and hyperparam-\neters of our method validates the significance of our\nmethod and robustness to variations. Our method also\nhas a wide range of potential application fields beyond\nmedical record analysis such as molecular chemistry, rec-\nommendation, computational biology, social networks,\nand citation networks etc."}, {"title": "Appendix A. Broader Impact and Limitations", "content": "Border Impacts. The DemoGraph framework offers\nsignificant extensibility across diverse applications due\nto its versatile core methodologies, notably in Computa-\ntional Biology, Computer Vision, and sequence data.\nIn computational biology, it enhances drug discovery\nand protein structure prediction by generating biologi-\ncally plausible augmentations for protein graphs, lever-\naging domain knowledge about amino acid sequences\nand protein interactions [66, 67, 68]. This addresses the\nchallenge of relying on vast, high-quality datasets [69].\nFor histopathology analysis, DemoGraph collaborates\nwell with typical multiple-instance learning methods and\ncan integrate the biological and clinical information de-\nscribed in the clinical reports with the LLM components\n[70, 71, 72].\nIn recommendation systems, DemoGraph can facili-\ntate graph-based methods as well as collaborative filter-\ning (CF) methods which mitigate the bias inherent from\nthe noisy user-iterm interaction. The use of LLM can\neffectively mine the contextual information from item\ndescriptions to provide more accurate recommendations\nto users [13, 73, 74, 2, 65, 75].\nLimitations. Since our method operates on latent\nknowledge graphs, it is difficult to generate KGs and per-\nform instruction fine-tuning online in general scenarios\ndue to the limitations of computational resources. How-\never, under sufficient computational power, the LLM can\nbe updated simultaneously during GNN training via in-\nstruction fine-tuning (e.g., after every backpropagation\nstep) such that the generated KGs can be closer to the\ndomain context, which is a promising extension in future\nworks."}, {"title": "Appendix B. Additional Dataset Information", "content": "We present additional information on the datasets used\nin the experiments. Tables B.11 and B.9 present the\nsummary information on generic graph datasets and the\nMIMIC-III dataset.\n\u2022 Cora Dataset: The Cora dataset includes 2,708 sci-\nentific publications across seven classes, forming a\ncitation network with 5,429 links. Each publication\nis represented by a binary word vector indicating\nthe presence or absence of 1,433 unique words.\n\u2022 Protein-Protein Interaction (PPI) Dataset: The PPI\ndataset consists of graphs representing interactions\nbetween proteins in various human tissues. Nodes\nreflect gene expressions, and edges denote protein\ninteractions."}, {"title": "Appendix C. Evaluation Metrics", "content": "We provide detailed definitions of the evaluation met-\nrics. For multi-class and multi-label classification tasks,\nthe weighted averaging method is adopted for some met-\nrics.\n\u2022 Classification metrics:\nAccuracy: the fraction of correct predictions\nto the total number of ground truth labels.\nF-1 score: The F-1 score for each class is\ndefined as\nF-1 score = 2 * precision * recall\nprecision + recall\nwhere 'recall' is the fraction of correct pre-\ndictions to the total number of ground truths\nin each class and precision is the fraction of\ncorrect predictions to the total number of pre-\ndictions in each class.\nAUC: the area under the receiver operating\ncurve (ROC) which is the plot of the true pos-\nitive rate (TPR/Recall) against the false posi-\ntive rate (FPR).\nAUPR: the area under the precision-recall\ncurve.\nJaccard index: measures the similarity be-\ntween the true binary labels and the predicted\nbinary labels by the ratio of the size of the\nintersection of the true positive labels and\nthe predicted positive labels to the size of the"}, {"title": "Appendix D. Additional Information of Related\nMethods", "content": "We provide supplementary information on the baseline\nmethods and related works employed in our study. All\nbaseline models were trained for 50 epochs with the\noption of early stopping. We choose the model at the\ne"}]}