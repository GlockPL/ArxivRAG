{"title": "Contextual Dual Learning Algorithm with Listwise Distillation for Unbiased Learning to Rank", "authors": ["Lulu Yu", "Keping Bi", "Shiyu Ni", "Jiafeng Guo"], "abstract": "Unbiased Learning to Rank (ULTR) aims to leverage biased implicit user feedback (e.g., click) to optimize an unbiased ranking model. The effectiveness of the existing ULTR methods has primarily been validated on synthetic datasets. However, their performance on real-world click data remains unclear. Recently, Baidu released a large publicly available dataset of their web search logs. Subsequently, the NTCIR-17 ULTRE-2 task released a subset dataset extracted from it. We conduct experiments on commonly used or effective ULTR methods on this subset to determine whether they maintain their effectiveness. In this paper, we propose a Contextual Dual Learning Algorithm with Listwise Distillation (CDLA-LD) to simultaneously address both position bias and contextual bias. We utilize a listwise-input ranking model to obtain reconstructed feature vectors incorporating local contextual information and employ the Dual Learning Algorithm (DLA) method to jointly train this ranking model and a propensity model to address position bias. As this ranking model learns the interaction information within the documents list of the training set, to enhance the ranking model's generalization ability, we additionally train a pointwise-input ranking model to learn the listwise-input ranking model's capability for relevance judgment in a listwise manner. Extensive experiments and analysis confirm the effectiveness of our approach.", "sections": [{"title": "1 Introduction", "content": "Learning to Rank (LTR) is an important component in many real-world systems. Generally, the field of LTR utilizes human annotations as the training data where the relevance of documents is annotated by human experts. As human annotations are expensive to obtain and potentially misaligned with user preferences in the specific system, many researchers seek to leverage implicit user feedback"}, {"title": "2 Related Work", "content": ""}, {"title": "2.1 Unbiased Learning to Rank (ULTR)", "content": "To leverage biased user feedback (e.g., click) for optimizing Learning to Rank (LTR) systems, a significant amount of research on ULTR has been proposed to acquire an unbiased ranking model. There are two primary streams for ULTR. One trend depends on click models [3,9,15], which assume user browsing behavior to estimate the examination probability. By maximizing the likelihood of the observed data, unbiased relevance estimation can be accurately obtained. Reliable relevance estimation requires the same query-document pair to appear multiple times. However, this can be challenging for long-tail queries and some sparse systems, e.g., personal search. The other trend derives from counterfactual learning, which addresses bias with inverse propensity score [2,12,14]. The key point is how to estimate propensity using bias factors appropriately. Ai et al. [2] propose a Dual Learning Algorithm jointly learning an unbiased ranking model and an unbiased propensity model. Subsequent methods [6,22] for improving propensity estimation can be integrated into the DLA framework."}, {"title": "2.2 ULTR on the Baidu-ULTR Dataset", "content": "Research [5,7,20,21] on Baidu-ULTR dataset [23] concerning ULTR mostly revolves around two public competitions: WSDM Cup 2023 - unbiased learning-to-rank and the ULTRE-2 task at NTCIR-17. They improve performance by combining the output of the BERT models with traditional LTR features [5,7,21] or pseudo relevance feedback [20]. However, they do not extensively explore the effectiveness of ULTR methods for the competition.\nThus, in this work, we explore whether existing ULTR methods can maintain their performance on real-world click data. Moreover, we propose a Contextual Dual Learning Algorithm with Listwise Distillation (CDLA-LD), using the self-attention mechanism to model the local context information and listwise distillation to enhance the ranking model's generality capabilities."}, {"title": "3 Preliminaries", "content": "In this section, we formulate Learning to Rank (LTR) with implicit user feedback, i.e., click, and introduce the core idea of the Dual Learning Algorithm (DLA) [2]."}, {"title": "3.1 Problem Formulation", "content": "For a user query q, \\(\\pi_q\\) is the ranked list of documents for q. Let \\(d_i \\in \\pi_q\\) be a document displayed at position i and \\(x_i\\) be the feature vector of q-di pair. We use binary Bernoulli variables \\(r_i\\), \\(e_i\\), and \\(c_i\\) to denote whether \\(d_i\\) is relevant, examined, and clicked, respectively. LTR aims to find a function f mapping from feature vector \\(x_i\\) to relevance \\(r_i\\), i.e., ranking model. Assuming that we already know the true relevance \\(r_i\\) (full information setting), then we can formulate the local ranking loss \\(\\mathcal{L}_{full-info}\\) as,\n\\(\\mathcal{L}_{full-info}(f, q | \\pi_q) = \\sum_{d_i \\in \\pi_q} \\Delta(f(x_i), r_i | \\pi_q),\\)\nwhere \\(\\Delta\\) is a loss function computing the individual loss on each document. When we replace the true relevance \\(r_i\\) with the implicit user feedback, i.e., click \\(c_i\\) in Eq.1, then the empirical local ranking loss is derived as follows,\n\\(\\mathcal{L}_{naive}(f, q | \\pi_q) = \\sum_{d_i \\in \\pi_q} \\Delta(f(x_i), c_i | \\pi_q).\\)\nAs different biases exist in clicks, this naive loss function is biased. Unbiased Learning to Rank (ULTR) methods aim to learn an unbiased ranking model f with these biased clicks."}, {"title": "3.2 Dual Learning Algorithm (DLA)", "content": "Based on the examination hypothesis,\n\\(p(c_i = 1 | \\pi_q) = p(r_i = 1 | \\pi_q)p(e_i = 1 | \\pi_q),\\)\nJoachims et al. [12] propose the Inverse Propensity Weighting (IPW) method to acquire an unbiased ranking objective. According to Eq.3, Ai et al. [2] discover that the problem of estimating examination propensity is symmetric with the problem of estimating real document relevance from user clicks. Thus, they propose the Dual Learning Algorithm (DLA) to solve the two problems simultaneously. Specifically, in DLA, an unbiased ranking model f and an unbiased propensity model g can be jointly learned by optimizing the following local loss,\n\\(\\mathcal{L}_{IPW}(f, q | \\pi_q) = \\sum_{d_i \\in \\pi_q, c_i=1} \\frac{\\Delta(f(x_i), c_i | \\pi_q)}{g(i)},\\)\n\\(\\mathcal{L}_{IRW}(g, q | \\pi_q) = \\sum_{d_i \\in \\pi_q, c_i=1} \\frac{\\Delta(g(i), c_i | \\pi_q)}{f(x_i)},\\)"}, {"title": "4 Contextual Dual Learning Algorithm with Listwise Distillation (CDLA-LD)", "content": "Users often interact with relevant documents from a list rather than independently evaluate each document. Thus, modeling this interaction and obtaining the reconstructed document representation containing local context information is ignorant. Utilizing more representative vectors may estimate the position bias more accurately and realistically."}, {"title": "4.1 Overview", "content": "The overall architecture of our proposed CDLA-LD is shown in Fig. 1 where n represents the list length, 10 in our work. It mainly consists of two procedures: the Contextual Dual Learning Algorithm (CDLA) and the Listwise Distillation (LD).\nTaking the documents list as the input of a listwise-input ranking model, it first passes through a transformer encoder module to obtain document vectors integrated with contextual information. These vectors are then used to estimate relevance. Similar to DLA, to address position bias, this ranking model is learned jointly with the propensity model. Concurrently, we train a pointwise-input ranking model distilling the knowledge learned from the listwise-input one."}, {"title": "4.2 Contextual Dual Learning Algorithm (CDLA)", "content": "Inspired by the self-attention mechanism [17], which integrates the context information by computing a multiple-weighted sum of the vectors in the current sequence. Therefore, we utilize the Transformer Encoder [19] to obtain context-included vectors and then generate the relevance estimation through the Deep Neural Model (DNN). These two parts, Transformer Encoder and DNN constitute the listwise-input ranking model.\nWe directly employ the Dual Learning Algorithm (DLA) [2] to address the position bias. We also consider that the examination probability solely depends on the position, unlike [6] considering both position and click factors. Thus, we jointly optimize the listwise-input ranking model and the propensity model using Eq. 5."}, {"title": "4.3 Listwise Distillation", "content": "The Transformer Encoder component in the listwise-input ranking model models the interaction information among documents and, through training, learns the implicit interaction patterns among documents in the training set. During the inference stage, on the one hand, interactions within its lists may differ from those present in the training set, thereby compromising the generalization ability of the ranking model. On the other hand, introducing the Transformer Encoder structure could increase computational overhead, thus reducing inference efficiency.\nTo enhance the generalization ability and improve inference efficiency, inspired by knowledge distillation, we introduce a pointwise-input ranking model to learn the relevance judgment capabilities of the listwise-input ranking model in a listwise manner. We utilize the local listwise distillation loss as follows to train a pointwise-input ranking model,\n\\(\\mathcal{L}_{distillation} = \\sum_{d_i \\in \\pi_q}  \\frac{e^{f(x_i)}}{\\sum_{x_j \\in \\pi_q} e^{f(x_j)}}  \\log \\frac{e^{h(x_i|\\pi_q)}}{\\sum_{x_k \\in \\pi_q} e^{h(x_k|\\pi_q)}},\\)\nwhere h represents the pointwise-input ranking model.\nThe pointwise-input ranking model (i.e., student model) is employed for relevance evaluation, while the listwise-input ranking model serves as an intermediate auxiliary model (i.e., teacher model).\nNote that due to the inability to accurately assess the ranking performance of the listwise-input ranking model, the training of the two ranking models is conducted simultaneously."}, {"title": "5 Experiments", "content": "We present our experimental settings and empirical results, substantiating the effectiveness of our method through the investigation of the following research questions (RQs):\n\u2022 RQ1: How does CDLA-LD perform compared to other Unbiased Learning to Rank (ULTR) methods on real-world click data?\n\u2022 RQ2: Is the propensity estimation of each position by CDLA-LD more accurate compared to other ULTR methods?\n\u2022 RQ3: Is it effective for CDLA-LD to conduct debiasing when training the listwise-input ranking model?\n\u2022 RQ4: Is each component of CDLA-LD necessary?"}, {"title": "5.1 Experimental Settings", "content": "Datasets. We conduct a series of experiments on a subset [16] of the Baidu-ULTR dataset [23], the first billion-level dataset for ULTR collected from the mobile web search engine of Baidu. This subset involves 1,052,295 searching sessions (34,047 unique queries) with click information and 7,008 expert annotated queries with the frequency of queries, where each query-document pair is annotated with 5-level labels.\nFollowing [23], the expert annotation dataset is split into validation and test sets according to a 20% - 80% scheme. For training data, we remove the sessions with less than 10 consecutively recorded candidate documents, as well as those without any clicks at the top 10 position. In addition, we also split the left sessions into train, validation, and test sets according to a 80% - 10% - 10% scheme. The final training data contains 485,342 sessions (33,302 unique queries).\nThis subset provides us with three types of features, i.e., heuristic features (e.g., TF-IDF, BM25), as well as a score feature and 768 dimensions' embedding features extracted from a pre-trained model\u00b3.\nBaselines. We compare our CDLA-LD with the following baselines, which are widely used or effective. Note that for the sake of comparability, we apply listwise loss to all the methods described below.\n\u2022 Naive: It directly trains the model with clicks without debiasing.\n\u2022 IPW: Inverse Propensity Weighting is one of the first ULTR algorithms proposed under the framework of counterfactual learning [12], which weights the training loss with the probability of the document being examined in the search session."}, {"title": "5.2 Performance Comparison of Different ULTR Methods (RQ1)", "content": "Tab. 1 shows the overall performance comparison of different ULTR methods. In contrast to the Naive, IPW even yields inferior performance, and DLA does not demonstrate significant improvement, while XPA and IBOM-DLA, which introduce complex information to model the propensity model, show different degrees of improvement on nDCG. The UPE method, designed to address the propensity overestimation, also shows improvements in most metrics compared to DLA. These results once again highlight the impact of propensity estimation on the performance of ranking models.\nUnlike XPA and IBOM, which modify the propensity model's modeling, our CDLA-LD considers implicit interactions between documents to obtain reconstructed feature vectors of documents that contain local context information. It shows varying degrees of enhancement across all the metrics compared to all the baselines."}, {"title": "5.3 Propensity Analysis (RQ2)", "content": "Fig. 2(a) displays normalized propensity (\\(\\frac{g(i)}{g(1)}\\)) estimated from AllPairs, DLA, UPE, CDLA-LD, and the click-through rate (CTR) per position. The propensity learned by DLA is somewhat chaotic. The propensity learned by UPE and All-Pairs is close to CTR. Nevertheless, the performance of the IPW method using propensity estimated by AllPairs is significantly lower compared to UPE. This may be because, under UPE, the ranking and propensity models are trained simultaneously rather than fixing the propensity for training the ranking model.\nCDLA-LD learns that the propensity decreases gradually with increasing position. The specific normalized propensity for each position is as follows: 1.000, 0.994, 0.962, 0.924, 0.897, 0.897, 0.893, 0.890, 0.889, 0.888. This propensity closely reflects the actual likelihood of users browsing each position in real-world scenarios, especially in mobile search engines. For instance, the examination probability for the first two positions is approximately equal, as the first two positions are usually seen simultaneously after the documents list is returned."}, {"title": "5.4 Study on When to Debias (RQ3)", "content": "Our approach, CDLA-LD, involves training an unbiased listwise-input ranking model and distilling it so that a pointwise-input ranking model learns the implicit relevance judgment capability of the listwise-input ranking model. Similarly, one can consider fitting click signals with the listwise-input model, whose outputs represent the click probability, and subsequently training an unbiased pointwise-input ranking model based on it. We refer to the latter as C-DLA-LD in short, where C and LD denote Contextual and Listwise Distillation, respectively.\nTab. 2 presents the performance comparison between CDLA-LD and C-DLA-LC, while Fig. 2(b) illustrates the learned normalized propensity of both methods. The debiasing effect is pronounced when training the listwise-input ranking"}, {"title": "5.5 Ablation Study (RQ4)", "content": "Compared to DLA, CDLA-LD initially introduces a listwise-input ranking model and subsequently incorporates listwise distillation. Thus, we solely evaluate the performance of the listwise-input ranking model itself on the test set, excluding listwise distillation.\nFrom Tab. 3, the performance of the listwise-input ranking model on the test set significantly lags behind that of CDLA-LD. This indicates discrepancies in the interaction of document lists between the test and training sets. On the one hand, the number of documents on the list for training and testing can seldom be exactly aligned, while on the other hand, it may stem from inherent inconsistencies in document relevance distribution."}, {"title": "6 Conclusion", "content": "In this work, we propose a Contextual Dual Learning Algorithm with Listwise Distillation (CDLA-LD) to mitigate both position and contextual biases. Specifically, we jointly train an unbiased listwise-input ranking model and an unbiased propensity model to address position bias. The listwise-input ranking model uses a Transformer Encoder, which can model the cross-document interactions and then capture local context information within the documents list. Considering the data mismatching between the training set and the test set, in order to enhance the generalization capability of the ranking model, we introduce a pointwise-input ranking model to distill the ability to estimate relevance from the listwise-input ranking model in a listwise manner.\nCompared to other effective ULTR methods, our approach performs the best on real-world click data collected from the user logs in the Baidu web search engine. Furthermore, the propensity estimation learned by CDLA-LD intuitively aligns closely with real-world scenarios. We also validate the necessity of introducing listwise distillation.\nIn subsequent work, we may consider incorporating interaction information derived from the position and click of documents within document lists when modeling the propensity model."}]}