{"title": "Language Models' Factuality Depends on the Language of Inquiry", "authors": ["Tushar Aggarwal", "Kumar Tanmay", "Ayush Agrawal", "Kumar Ayush", "Hamid Palangi", "Paul Pu Liang"], "abstract": "Multilingual language models (LMs) are ex-\npected to recall factual knowledge consistently\nacross languages, yet they often fail to transfer\nknowledge between languages even when they\npossess the correct information in one of the\nlanguages. For example, we find that an LM\nmay correctly identify Rashed Al Shashai as\nbeing from Saudi Arabia when asked in Arabic,\nbut consistently fails to do so when asked in\nEnglish or Swahili. To systematically inves-\ntigate this limitation, we introduce a bench-\nmark of 10,000 country-related facts across\n13 languages and propose three novel met-\nrics-Factual Recall Score, Knowledge Trans-\nferability Score, and Cross-Lingual Factual\nKnowledge Transferability Score-to quan-\ntify factual recall and knowledge transferabil-\nity in LMs across different languages. Our\nresults reveal fundamental weaknesses in to-\nday's state-of-the-art LMs, particularly in cross-\nlingual generalization where models fail to\ntransfer knowledge effectively across differ-\nent languages, leading to inconsistent perfor-\nmance sensitive to the language used. Our find-\nings emphasize the need for LMs to recognize\nlanguage-specific factual reliability and lever-\nage the most trustworthy information across\nlanguages. We release our benchmark and eval-\nuation framework to drive future research in\nmultilingual knowledge transfer. The data and\ncodes are available at this link.", "sections": [{"title": "1 Introduction", "content": "Large Language Models (LLMs) are often per-\nceived as vast knowledge reservoirs, capable of\nrecalling factual information across multiple lan-\nguages (Wang et al., 2024). However, what if\ntheir knowledge is locked within linguistic bound-\naries and unable to be transferred across languages?\nDespite advancements in multilingual LMs such\nas Llama (Touvron et al., 2023a; Dubey et al.,\n2024), Gemma (Team et al., 2024a), DeepSeek\n(DeepSeek-AI et al., 2024), and Phi (Abdin et al.,\n2024; Li et al., 2023), our study reveals a striking\nasymmetry in their factual recall across languages:\nconsider the example in Figure 1, where an LM\nis tasked with a simple factual query: \u201cRashed Al\nShashai is from which country?\" When asked in\nArabic, several state-of-the-art LMs correctly gen-\nerate the response: \u201cSaudi Arabia.\u201d However, when\nposed in English, Hindi, or Swahili, the same mod-\nels fail to recall the fact. This example suggests\nthat models can correctly retrieve country-specific\nfacts in the language associated with that country\nbut struggle to do so in others.\nThis raises a critical question-do these models\ntruly internalize and transfer factual knowledge\nacross languages, or do they merely encode isolated\nlinguistic silos?"}, {"title": "2 Related Work", "content": "This limitation has significant implications for\nmultilingual AI development and real-world ap-\nplications. Many LM-based systems such as\nretrieval-augmented generation (RAG) pipelines,\nmultilingual search engines, and cross-lingual rea-\nsoning models-assume that factual knowledge is\nconsistently available and transferable across lan-\nguages.\nOur findings reveal that LMs often rely on\nlanguage-specific memorization rather than true\ncross-lingual knowledge generalization. This\nover-reliance can introduce biases, inconsistencies,\nand reliability issues in multilingual AI applica-\ntions (Chua et al., 2024).\nTo systematically analyze the factual inconsisten-\ncies, we introduce a carefully curated dataset com-\nprising country-related facts translated into 13 lan-\nguages. This benchmark evaluates LMs on multiple\ndimensions-factual recall, in-context recall, and\ncounter-factual context adherence\u2014across high-,\nmedium-, and low-resource languages. This bench-\nmark comprises of 802 instances for factual recall,\n156 instances for In-context recall, and 1404 in-\nstances for counter-factual context adherence as\nshown in Table 1.\nFactual recall assesses the LM's ability to recall\ncountry-specific facts consistently across multiple\nlanguages. We evaluate factual recall using three\nmetrics: (a) Factual Recall Score (FRS): Measures\nhow accurately a model recalls a fact in a given lan-\nguage, (b) Knowledge Transferability Score (KTS):\nQuantifies how well factual knowledge is trans-\nferred across languages, and (c) Cross-Lingual Fac-\ntual Knowledge Transferability (X-FaKT) Score:\nCombines the assessment of factual recall and\ncross-lingual transfer ability. FRS and KTS mea-\nsure the effectiveness of cross-lingual knowledge\ntransfer, and X-FaKT Score integrates factual re-\ncall with transferability to provide a robust measure\nof multilingual generalization. These metrics of-\nfer a more nuanced evaluation than a simple error\nrate, allowing for a deeper understanding of cross-\nlingual generalization.\nIn-Context Recall (Machlab and Battle, 2024)\nmeasures the general performance of the models in\nmultilingual contexts. Inspired by (Du et al., 2024),\nwe also study how factual knowledge of models\naffects their performance in handling in-context\ntasks in the multilingual setting (Counterfactual\nContext Adherence). For this, we design a dataset\nwhere factual knowledge conflicts with in-context\ninstructions.\nMultilingual Transformers. Early work by\n(Petroni et al., 2019) explored whether LMs can\nstore factual knowledge about entities, setting the\nstage for later investigations into multilingual LMs.\nNotable multilingual models such as mBERT (De-\nvlin et al., 2019), XLM-R (Conneau et al., 2020),\nmT5 (Xue et al., 2021), and BLOOM (Workshop\net al., 2023) have demonstrated varying levels of\nperformance across different languages. These\nmodels, trained on diverse multilingual corpora,\nshow that LMs exhibit language-dependent capabil-\nities in factual recall. Research has highlighted sys-\ntematic biases in factual retrieval across languages\n(Artetxe et al., 2020; Liu et al., 2020; Kassner et al.,\n2021), which is a key challenge in multilingual\nLMs. While multilingual QA benchmarks like\nXQUAD (Artetxe et al., 2020), MLQA (Lewis et al.,\n2020), and TyDiQA (Clark et al., 2020) assess fac-\ntual consistency, they do not directly measure the\ntransfer of knowledge between languages. Recent\nwork by (Wang et al., 2024) raised questions about\nLMs' ability to recall factual knowledge in reason-"}, {"title": "3 Dataset", "content": "ing tasks, while (Fierro et al., 2025) emphasized\nthe need for more robust methodologies for evalu-\nating knowledge in multilingual LMs. Our study\nbuilds on these insights by introducing a bench-\nmark specifically designed to assess cross-lingual\nfactual knowledge transferability.\nCross-Lingual Knowledge Transfer in LMs.\nRecent works have sought to understand the fac-\ntors that influence cross-lingual knowledge trans-\nfer in multilingual models. Studies suggest that\nmultilingual LMs exhibit zero-shot and few-shot\ngeneralization across languages (Nooralahzadeh\net al., 2020; Pfeiffer et al., 2020), but empirical\nevidence indicates that this transfer is often asym-\nmetric, with high-resource languages benefiting\nmore than lower-resource ones (Hu et al., 2020).\n(Muller et al., 2021) investigated the connection be-\ntween cross-lingual similarity in hidden representa-\ntions and downstream task performance, revealing\nthat LMs with stronger representation alignment\nacross languages perform better. (Chai et al., 2022)\nexplored cross-linguality from a language struc-\nture perspective, emphasizing the importance of\ncompositional properties in facilitating knowledge\ntransfer. More recent work has focused on cross-\nlingual transfer from high-resource to low-resource\nlanguages (Zhao et al., 2024a,b), further underscor-\ning the asymmetries in cross-lingual knowledge\nintegration. Our work contributes to this area by\nevaluating the effectiveness of factual knowledge\ntransfer across languages using a comprehensive\nset of metrics designed to measure both factual\nrecall and transferability.\nContext Sensitivity and Counterfactual Rea-\nsoning. LMs are known to be highly sensitive\nto contextual cues, which can sometimes override\nfactual knowledge when the context is misleading\n(Brown et al., 2020; Tirumala et al., 2022; Du et al.,\n2024). (Ghosh et al., 2025) provides an in-depth\nreview of multilingual reasoning in LMs. Counter-\nfactual reasoning, in which models must consider\nhypothetical situations, has been studied in various\ncontexts (Wu et al., 2023). These studies show that\nLMs optimized for factual recall often struggle with\ncounterfactual tasks, especially when faced with\nconflicting contextual instructions. While most\nprior evaluations have focused on monolingual set-\ntings (Shwartz et al., 2020; Wang et al., 2020), our\nwork extends these investigations into the multilin-\ngual domain. By introducing tasks like in-context\nrecall and counterfactual adherence, we analyze\nhow multilingual models handle both factual ac-\nWe introduce a new multilingual dataset designed\nto evaluate three key capabilities of LMs: (a) Fac-\ntual Recall, (b) In-context Recall, and (c) Counter-\nFactual Context Adherence. The number of in-\nstances in our dataset is given in the Table 1. Given\nthe multilingual nature of our study, we categorize\nlanguages based on their resource availability in\nexisting LM training corpora:\nHigh-resource: English, Chinese, French,\nJapanese.\nMedium-resource: Hindi, Russian, Arabic,\nGreek.\nLow-resource: Nepali, Ukrainian, Turkish,\nSwahili, Thai.\nThese languages correspond to countries\nstrongly associated with their usage: the United\nStates, China, France, Japan, India, Russia, Saudi\nArabia, Greece, Nepal, Ukraine, Turkey, Kenya,\nand Thailand. Now, we describe our datasets in"}, {"title": "3.1 Factual Recall", "content": "curacy and contextual reasoning across languages,\nrevealing important challenges in balancing factual\nknowledge and context sensitivity.\nThis task evaluates an LM's ability to recall\ncountry-specific facts across multiple languages.\nFor example, given the query, In which country\nis Mumbai located?, the model should correctly\nrespond with India when asked in different lan-\nguages.\nTo construct the dataset, we curated a diverse\nset of entities\u2014including cities, artists, sports fig-\nures, landmarks, festivals, and politicians for 13\nselected countries. We then created standardized\ntemplates for factual queries and translated them\ninto each language using the Google Translate\nAPI (Google, n.d.). All translations were manu-\nally verified and refined as needed with the assis-\ntance of ChatGPT. In total, our dataset consists of\n805 unique factual questions, each available in 13\nlanguage versions."}, {"title": "3.2 In-Context Recall", "content": "The in-context recall task evaluates how effectively\nan LM utilizes contextual information to answer\na question, ensuring that internal knowledge does\nnot influence the model's output.\nBuilding on the work of (Feng and Steinhardt,\n2024), we constructed our dataset by focusing on\ncommon person names associated with each coun-\ntry. For each example, we sampled two names and\npaired them with two different countries, creating\ncontext-based prompts as shown in violet color in\nFigure 2. To enhance dataset efficiency, we inten-\ntionally avoided associating a name with its most\ncommonly linked country within the example."}, {"title": "3.3 Counter-Factual Context Adherence", "content": "This task evaluates an LM's susceptibility to coun-\nterfactual information by assessing whether it ad-\nheres to the provided context when answering a\nquestion. Ideally, the model should rely solely on\nthe given context, but in some cases, its internal\nknowledge may interfere or override it, leading to\nunintended responses (Du et al., 2024). To investi-\ngate this, we curated a list of well-known personal-\nities strongly associated with specific countries and\ndeliberately introduced counterfactual information\ninto the context.\nFor the example given in Figure 2, if the model\ndefaults to its internal knowledge and answers\nUnited States, it demonstrates a resistance to the\ncontextual information. Conversely, if it follows"}, {"title": "4 Experiments", "content": "the counterfactual context and answers India, it\nsuggests a higher reliance on the provided context\nrather than pre-existing knowledge.\nOne might expect these models to perform near-\nperfectly on these tasks, as they are very simple.\nHowever, despite the simplicity of these tasks, the\nperformance varies across languages and models.\nIn this section, we discuss our experimental setup,\nmetric formulation, and both quantitative and quali-\ntative analyses. We present the results of our experi-\nments evaluating LMs on our dataset across diverse\nmultilingual tasks. These experiments assess how\nlanguage and country-specific factual knowledge\ninfluence LMs responses in a multilingual setting.\nAll experiments were conducted using the latest\nmodels, with Qwen-2.5-72B-Inst (Qwen et al., 2025)\nserving as the evaluator (Li et al., 2024)."}, {"title": "4.1 Experimental Setup", "content": "Models We evaluated 14 models of varying sizes,\ntrained on different compositions of multilingual\ndata, and fine-tuned using various preference opti-\nmization strategies (Ouyang et al., 2022; Rafailov\net al., 2024), for our multilingual study. These\ninclude Deepseek (DeepSeek-AI et al., 2024),\nQwen (Yang et al., 2024), Gemma (Team et al.,\n2024b), and Llama (Touvron et al., 2023b) families.\nFurther details of the models evaluated are given in\nTable A.1.\nCompute Details All our experiments were con-\nducted on a set of 4 NVIDIA A100 GPUs, each\nwith 80GB of VRAM.\nEvaluation To evaluate all models on the curated\ndatasets (Section 3), we used a temperature setting\nof 0 and a maximum token limit of 128. Specifi-\ncally, we tested the models' performance on Fac-\ntual Recall and In-Context Recall across different\nsettings. For evaluation, we designed our metrics\nand utilized Qwen-2.5-72B-Inst as the evaluator (Li\net al., 2024), with a maximum token limit of 256 to\nsupport reasoning. Evaluation prompts are shown\nin Figures 11 and 12."}, {"title": "4.2 Metric Definition and Formulation", "content": "This section introduces our carefully designed met-\nrics to evaluate factual recall and knowledge trans-\nferability across languages in LMs. We propose\ntwo key metrics: the Factual Recall Score (FRS)"}, {"title": "4.2.1 Associative vs. Non-Associative Knowledge", "content": "and the Knowledge Transferability Score (KTS).\nTo establish a common metric for evaluating the\nmodel's performance in our benchmark, we com-\npute their harmonic mean, which is defined as the\nCross-Lingual Factual Knowledge Transferability\nScore (X-FaKT), to ensure a balanced assessment\nwhile penalizing large disparities between them.\nOur metrics incorporate an inverse formulation\nwith a correction factor to maintain a bounded\nrange of [0, 1]. A higher error rate results in a lower\nmetric value due to the inverse transformation, en-\nsuring that better model performance corresponds\nto higher scores.\nWe categorize our dataset into two groups: asso-\nciative and non-associative knowledge. The cate-\ngorization is defined as follows: we consider 13\nlanguages, each associated with a corresponding\ncountry (i.e., the ith language belongs to the ith\ncountry).\nAssociative = {Q\u2208 Questions : QE\nLanguage; \u2227 output(Q) = Country; ^ i = j}\nNon-associative = {Q \u2208 Questions : Q\u2208\nLanguage / output(Q) = Country; ^ i \u2260 j}\nWe denote the mean error rate for a country-\nspecific fact asked in the language strongly associ-\nated with that country as passoc., and the mean error\nrate for a country-specific fact asked in a language\nnot associated with that country as \u00b5non-assoc. \u2022"}, {"title": "4.2.2 Factual Recall Score (FRS)", "content": "Factual recall evaluates the model's ability to cor-\nrectly retrieve both associative and non-associative\nknowledge. We define the Factual Recall Score\n(FRS) as:\nFRS =\n3\n(\n2\n1\n1\n\u00b5assoc. + \u00b5non\u2212assoc. + 1\n)\n(1)\n\u2022 When both errors are zero (\u00b5assoc. =\n0, \u00b5non-assoc. = 0), the model has a perfect\nfactual recall, yielding an FRS score of 1.\n\u2022 When both errors are high, the denominator in-\ncreases, resulting in a lower FRS score closer\nto 0, indicating poor factual recall."}, {"title": "4.2.3 Knowledge Transferability Score (KTS)", "content": "Knowledge transferability quantifies how well\na model maintains consistent factual knowledge\nacross languages. We define the Knowledge Trans-\nferability Score (KTS) as:\nKTS = 2 (\n1\n\u00b5assoc.\n\u00b5non\u2212assoc. + 1\n) \u2212 1\n2\n(2)\nwhere:\n\u2022 \u00b5assoc.\n\u00b5non-assoc. captures the absolute\ndifference between associative and non-\nassociative recall errors.\n\u2022 When both errors are zero (\u00b5assoc. =\n0, \u00b5non-assoc. = 0), there is perfect factual\nknowledge transfer, resulting in a KTS score\nof 1.\n\u2022 When both errors are high but equal (e.g.,\n\u00b5assoc. = 20, \u00b5non-assoc. = 20), KTS remains\n1, indicating that while factual recall is poor,\nthe model exhibits consistent errors across lan-\nguages.\n\u2022 When errors differ significantly (e.g., \u00b5assoc. =\n20, \u00b5non-assoc. = 2 or vice versa), the abso-\nlute difference increases, leading to a lower\nKTS, highlighting a lack of knowledge trans-\nfer across languages."}, {"title": "4.2.4 Cross-Lingual Factual Knowledge Transferability Score (X-FAKT)", "content": "To ensure a balanced evaluation of factual recall\nand cross-lingual transferability, we compute their\nharmonic mean:\nX-FAKT = 2\u00d7 FRS \u00d7 KTS\nFRS + KTS\n(3)\nwhere:\n\u2022 The harmonic mean penalizes large disparities\nbetween factual recall (FRS) and knowledge\ntransferability (KTS), ensuring that both con-\ntribute meaningfully to the final score.\n\u2022 If either FRS or KTS is significantly lower,\nthe overall score remains low, discouraging\nmodels from excelling in one metric while\nperforming poorly in the other.\n\u2022 A high X-FAKT score indicates that the model\nis both factually accurate and consistent across\nmultiple languages.\nThis formulation provides a holistic evaluation\nof factual knowledge retention and cross-lingual\nconsistency, making it a robust metric for assessing\nmultilingual model performance."}, {"title": "4.3 Quantitative Analysis", "content": "cal reasoning.\nSpurious correlation leads to in-context recall\nfailures. We observe that some models tend\nto associate names with cultural origins, even\nwhen contextual evidence contradicts this assump-\ntion. Figures 6 demonstrate the model response\nwhen prompted Mistral-7B-v0.2 with the contextual\nunderstanding-based question in English.\nDespite the explicit context stating that Li Wei\nresides in Russia, the model disregards this infor-\nmation and defaults to cultural associations. This\nbehavior reveals a limitation in integrating contex-\ntual evidence when making country-specific infer-\nences.\nModels favor factual knowledge over context.\nWe also observed that some models prioritize their\ninternal factual knowledge over contextual infor-\nmation when responding to questions about well-\nknown personalities. Figures 7 demonstrate the\nmodel response when prompted Llama-3-70B with\nthe factual retrieval query in English.\nIn this case, despite being explicitly told that\n'George Washington' lived in 'India', the model\nrelied on its factual knowledge, correcting the given\nfact and asserting that 'George Washington' lived in\nthe 'United States'. This response demonstrates the\nmodel's strong reliance on factual accuracy, rather"}, {"title": "4.3.1 Performance on Factual Recall task", "content": "4.4 Qualitative Analysis\nThe error rate across different LMs (Figure 3)\nreveals a clear pattern in performance across\nlanguages and model sizes. Notably, all mod-\nels demonstrate superior performance on high-\nresource languages like English and French, with\nerror rates consistently below 15% for most model\nvariants. This performance gradually deteriorates\nas the model size decreases, with smaller models\nshowing significantly higher error rates across all\nlanguages. However, an interesting observation\nemerges with languages like Swahili and Turkish,\nwhich despite being low-resource languages, ex-\nhibit relatively better performance with error rates\ncomparable to mid-resource languages. This can\nbe attributed to their use of Latin script, facilitating\nbetter knowledge transfer from English.\nA compelling pattern emerges when examining\nlanguages that share similar scripts, and strong cor-\nrelations in model performance among languages\nthat share similar scripts. For example, the error\npatterns for Hindi-Nepali and Russian-Ukrainian\npairs show remarkable similarities, suggesting that\nthe models effectively leverage shared scriptural\ncharacteristics during learning. These patterns in-\ndicate that script similarity plays a crucial role in\nthe model's ability to generalize across languages,\npotentially offering insights into how these mod-\nels transfer knowledge between different language\npairs and scripts.\nKnowledge Transferability Analysis: From Ta-\nble 2, Llama-3-70B emerges as the clear leader with"}, {"title": "4.3.2 Performance on In-Context Recall task", "content": "Figure 13 demonstrates the incorrectness rate for\nthe in-context recall capabilities of different LMs.\nDespite being a simple task, certain models such as\nDeepSeek-7B, Orca-2-7B, Phi-3-4B, Llama-3.2-1B, and\nMistral-7B-v0.2 perform poorly across multiple lan-\nguages. This suggests that these models struggle to\neffectively utilize contextual information when gen-\nerating outputs. Interestingly, even for languages\nlike Swahili and Turkish, which showed better\nscores in the Factual Recall task, models demon-"}, {"title": "4.3.3 Performance on Counter-Factual Context Adherence task", "content": "strate poor performance on this context-dependent\ntask. This stark contrast suggests that the bene-\nfits of Latin script-based knowledge transfer ob-\nserved in the Factual Recall task do not extend to\nin-context learning scenarios, where performance\ndepends primarily on the model's ability to process\nand utilize contextual information.\nAs mentioned in the dataset section, we inten-\ntionally paired cross-entities as context. This setup\nappears to induce a regional bias, which negatively\nimpacts model performance. The structured entity-\ncontext pairing in the dataset may have led to spuri-\nous correlations (Yang et al., 2023; Ye et al., 2024),\nreducing model accuracy in in-context recall tasks.\nSome models struggle to effectively leverage con-\ntextual information, revealing potential weaknesses\nin their retrieval and in-context learning mecha-\nnisms.\nFigure 5 illustrates the error rates of LMs in the\nCounterfactual Context Adherence task. Notably,\nLatin-script languages (English, French, Swahili,\nand Turkish), which performed well in factual re-\ncall tasks, exhibited significantly higher error rates\nin counterfactual adherence. This suggests a funda-\nmental trade-off in the models' capabilities: their\nstrength in accurately retrieving factual informa-\ntion appears to come at the expense of their abil-\nity to maintain adherence to counterfactual con-\ntexts. This inverse relationship raises important\nquestions about the inherent limitations and trade-\noffs in LMs' learning mechanisms, particularly in\nhow they balance factual knowledge with hypot-"}, {"title": "5 Conclusions", "content": "than adapting to the context provided. It suggests\nthat when it comes to well-known historical figures,\nmodels may prioritize prior knowledge over the\nspecific context they are given.\nLinguistic variability in word interpretation.\nLMs can interpret words differently depending\non the language. Figures 8 and 9 demonstrate\nthe model responses when prompted Llama-3-70B\nwith the same queries but in different languages.\nThis highlights challenges in multilingual consis-\ntency, where the model misinterprets 'Dijon' as\n'De Janeiro' in Hindi, revealing inconsistencies in\ncross-lingual factual retrieval.\nChallenges with using LMs as evaluators. We\nused a zero-shot prompt with Llama-3-70B as an\nevaluator and found that its inherent factual knowl-\nedge can skew assessments. For example, when\nevaluating a Gemma-2-27B response to the counter-\nfactual context task-\"Catherine the Great lives\nin India\"-the evaluator corrected it, asserting that\nshe lived in \"Russia\u201d, despite the provided ground\ntruth. This bias highlights the need to control eval-\nuators' factual knowledge to ensure consistent eval-\nuation.\nOur study reveals a critical limitation in multilin-\ngual LMs: their inability to consistently transfer\nfactual knowledge across languages. Our bench-"}, {"title": "6 Limitations", "content": "mark provides a standardized framework to eval-\nuate both current and future LMs on their factual\nconsistency and cross-lingual generalization, en-\nabling a more systematic comparison of their ca-\npabilities. Moreover, it can serve as a valuable\nresource to promote research in interpretability by\nhelping analyze how and where factual knowledge\nis stored and retrieved across languages, foster-\ning a deeper understanding of LM internals. We\nemphasize the need for AI systems with internal\nawareness of their language-specific strengths and\nweaknesses-a concept we term calibrated multi-\nlingualism. Under this paradigm, a model would\nautonomously leverage the most reliable internal\nrepresentations for any given multilingual query.\nWe also find that LMs, when used as evalua-\ntors, are biased by their internal factual knowledge,\nwhich may not align with the intended input-output-\nground-truth context. This underscores the need\nto control the evaluator's factual knowledge for\nmore reliable assessments. Ultimately, enabling AI\nto cross-generalize across languages is crucial for\ninclusive and equitable technology, ensuring lan-\nguage is no barrier to reliable knowledge access.\nOur study provides valuable insights into cross-\nlingual knowledge transfer in LMs but has some\nlimitations. First, our benchmark, though compre-\nhensive in country-related facts, covers only 13\nlanguages, limiting its representation of diverse lin-\nguistic families. Second, we evaluated only open-\nsource LMs, excluding proprietary models that may\nexhibit different transfer patterns. Third, our fact\ncollection used a standardized template for con-\nsistency, which may not reflect the diversity of\nreal-world queries. Lastly, our focus on country-\nrelated facts means our findings may not generalize\nto other domains like science, history, or culture."}, {"title": "7 Ethics Statement", "content": "This research is conducted with a strong commit-\nment to ethical principles, ensuring data privacy\nand consent by using publicly available informa-\ntion and adhering to data protection regulations.\nWe acknowledge potential biases in multilingual\nlanguage models and aim to highlight and address\nthese through our benchmark. Transparency and\nreproducibility are promoted by making our dataset\nand evaluation framework publicly available. Our\nresearch aligns with the broader goals of fairness,"}, {"title": "8 Acknowledgment", "content": "transparency, and social responsibility.\nWe thank Alessandro Sordoni, Prachi Jain, Rishav\nHada, Chanakya Ekbote, Anirudh Buvanesh, and\nAnkur Sikarwar for their valuable feedback. We\nacknowledge the support of Ayush Agrawal's PhD\nadvisors, Aaron Courville and Navin Goyal."}]}