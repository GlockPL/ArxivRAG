{"title": "Interpretable Recognition of Fused Magnesium Furnace Working Conditions with Deep Convolutional Stochastic Configuration Networks", "authors": ["Weitao Li", "Xinru Zhang", "Dianhui Wang", "Qianqian Tong", "Tianyou Chai"], "abstract": "To address the issues of a weak generalization capability and interpretability in working condition recognition model of a fused magnesium furnace, this paper proposes an interpretable working condition recognition method based on deep convolutional stochastic configuration networks (DCSCNs). Firstly, a supervised learning mechanism is employed to generate physically meaningful Gaussian differential convolution kernels. An incremental method is utilized to construct a DCSCNS model, ensuring the convergence of recognition errors in a hierarchical manner and avoiding the iterative optimization process of convolutional kernel parameters using the widely used backpropagation algorithm. The independent coefficient of channel feature maps is defined to obtain the visualization results of feature class activation maps for the fused magnesium furnace. A joint reward function is constructed based on the recognition accuracy, the interpretable trustworthiness evaluation metrics, and the model parameter quantity. Reinforcement learning (RL) is applied to adaptively prune the convolutional kernels of the DCSCNs model, aiming to build a compact, highly performed and interpretable network. The experimental results demonstrate that the proposed method outperforms the other deep learning approaches in terms of recognition accuracy and interpretability.", "sections": [{"title": "I. INTRODUCTION", "content": "MAGNESIUM oxide, as the main component of fused magnesium sand (also known as fused magnesia), is an alkaline refractory raw material widely used in aerospace, nuclear furnaces, electronics, and other fields. As the world's largest producer and supplier of fused magnesium, China faces challenges such as low grade, large composition fluctuations, and complex mineral composition in its magnesite ore. Therefore, a unique three-phase alternating current fused magnesium furnace is required for smelting. The smelting process of an fused magnesium furnace involves simultaneous feeding and smelting. Raw materials are poured into the furnace by a machine, and high-temperature arcs in the furnace heat the raw materials to generate magnesium oxide crystals [1], [2], [3].\nTo ensure the quality of electric fused magnesia, it is necessary to monitor the production process and prevent possible abnormal working conditions during smelting, including underburn, overheating, and abnormal exhaust [4]. The underburn condition is caused by impurities and complex minerals in the raw materials, resulting in incomplete combustion in the fused magnesium furnace. During this condition, the furnace wall in certain areas becomes red and bright. The overheating condition is characterized by a brighter flame at the furnace mouth, which may produce adverse substances such as magnesium smoke and magnesium oxide. The abnormal exhaust working condition involves the ejection of high-temperature molten metal from the furnace mouth, resulting in drastic changes in current. When these abnormal working conditions occur, they need to be promptly detected and addressed to avoid energy waste, reduction of the utilization rate and grade of magnesia sand, furnace lining burn-through, and potential hazards to operators due to raw material leakage. Presently, the inability to directly observe the internal molten pool in the furnace due to the presence of burning flames at the furnace mouth renders the diagnosis of abnormal working conditions in magnesium furnaces contingent upon manual decision-making [5]. However, each inspector is responsible for multiple furnaces, and subjective factors such as their experience, sense of responsibility, and labor intensity, as well as objective factors such as high temperature, noise, dust, water mist, and inherent white spots on the furnace wall in a complex firing environment, make it difficult to make manual decisions. This can easily lead to missed or erroneous inspections, resulting in irreversible losses such as the burn-through of fused magnesium furnaces and difficulties in meeting the real-time inspection requirements for operation and maintenance.\nIn recent years, with the continuous development of artificial intelligence technology, the use of machine learning and deep learning for the abnormal working condition diagnosis of fused magnesium furnaces has received widespread attention. These methods collect and process production data from the furnaces, extract various feature parameters, and utilize algorithms for the automatic diagnosis of abnormal working conditions. For example, the work in [6] proposes a magnesium furnace abnormal working condition diagnosis method based on Bayesian networks, which introduces transfer learning to address the problem of limited abnormal working condition data. The work in [7] applies semi-supervised learning to automatically label unlabeled current data and train classifiers"}, {"title": "II. INTERPRETABLE FUSED MAGNESIUM FURNACE WORKING CONDITION RECOGNITION MODEL", "content": "The proposed interpretable working condition recognition model for a fused magnesium furnace based on DCSCNs utilizes a three-layer structure for information coupling, including the training layer, feedback layer, and testing layer. The model structure is illustrated in Figure 1.\nThe training layer consists of data augmentation, preprocessing, and DCSCNs modules. Initially, fused magnesium furnace training images undergo data augmentation and preprocessing to enlarge the dataset. These processed samples are then fed into the DCSCNs. A supervised mechanism is opted for the adaptive selection of new convolutional kernel parameters to avoids the need for the iterative backpropagation for updating convolutional kernel parameters. This process starts with a single-kernel and single-layer configuration (represented as \"Incremental convolutional feature extraction layer 1\", the yellow box as the constructed convolution, and the blue box as the convolution to be constructed). The training set is passed through this layer to obtain the feature map. The feature map is then used for classifying the working conditions of the fused magnesium furnace through a fully connected layer. If the recognition error meets the preset criteria, training is halted. Otherwise, the number of single-layer convolutional kernels continues to increase one by one at a time (indicated as the second yellow box of the incremental convolutional feature extraction layer 1) until it reaches the maximum allowable kernels (C1) for that layer. If the error still does not meet the criteria, a second incremental convolutional feature extraction layer is added (represented as \"Incremental convolutional feature extraction layer 2\"). This process is repeated until the error converges or the maximum number Lmax of convolutional layers is reached.\nThe feedback layer encompasses an interpretability assessment module and a network width adaptive adjustment module based on RL. After the construction of Lmax \u2013 1 layers in the DCSCNS, the extracted feature maps are fed into the feedback layer (indicated by the blue arrow). These are upsampled to the original input image size and are superimposed with the original image. The superimposed image is re-inputted into the incremental convolutional network to obtain class scores. Channel feature independence scores are calculated, and a linear combination of the class scores, channel feature independence scores, and feature maps is used to construct a class activation mapping (CAM) and a measure index of interpretability trustworthiness. Meanwhile, the Gaussian differential convolutional kernels generated are then fed into a RL pruning module (indicated by the green arrow). The kernels are ranked based on their channel feature independence scores, and a joint reward function that combines accuracy, a measure index of interpretability trustworthiness, and the volume of network parameters is formulated. Convolutional kernels for each layer of the network are adaptively pruned through RL, enabling the self-adaptive adjustment of network width (indicated by the red arrow).\nIn the testing layer, the constructed interpretable deep stochastic configuration convolutional network is used to obtain the optimal recognition results for the test samples of fused magnesium furnace working conditions."}, {"title": "III. INTERPRETABLE WORKING CONDITION RECOGNITION METHOD BASED ON DEEP CONVOLUTIONAL STOCHASTIC CONFIGURATION NETWORKS", "content": "In the production process of fused magnesium furnaces, there are relatively few instances of abnormal working conditions. This leads to an imbalance issue in the image samples, which can cause over-fitting of the learner. To address this problem, this paper employs a non-generative approach to augment the image data. Techniques such as horizontal flipping, contrast and brightness adjustment, and adding noise are applied to increase the diversity of the data and alleviate over-fitting, enabling the learner to better adapt to the variations in magnesium furnace images across different scenarios.\nHorizontal flipping can be described as follows:\n$I(x,y) = I' (w \u2212 x \u2212 1, y)$       (1)\nwhere, $I'(x, y)$ represents the pixel value of the original image at coordinates (x,y), $I(x, y)$ denotes the pixel value of the data enhanced image at (x, y), and w denotes the width of the original image.\nContrast and brightness adjustment can be described as follows:\n$I(x,y) = 1.5(I'(x, y) \u2013 0.5) + 0.5$           (2)\nTo prevent pixel value overflow, each value in the original image is subtracted by 0.5, multiplied by the contrast enhancement coefficient of 1.5, and then added by 0.5. This simultaneously enhances the brightness and contrast of the image.\nAdding Gaussian noise can be described as follows:\n$I(x,y) = I'(x, y) + N(0, \u03b7\u00b2)$        (3)\nwhere, $N(0, \u03b7\u00b2)$ represents Gaussian noise with a mean of 0 and a standard deviation of \u03b7\u00b2. By adjusting the value of \u03b7, the intensity of the noise can be controlled.\nThe collected images may contain some information unrelated to the fused magnesium furnace. To reduce the impact of such information, the center of the image is cropped to 1080 \u00d7 1080 and resized to 256 x 256. The input values are normalized to the range of [-1,1] for subsequent image processing convenience.\nTo address the issues of structure design, hyperparameter tuning, and interpretability in CNNs, this paper proposes an efficient method for constructing interpretable CNNs as shown"}, {"title": "B. Deep convolutional stochastic configuration networks", "content": "in Figure 2, called the DCSCNs, inspired by the stochastic configuration network [29], [30], [25]. This strategy starts from a single convolutional kernel in a single layer and incrementally generates new stochastic convolutional kernels with strong interpretability to construct the CNNs. It overcomes the tediousness of manually designing network structures and tuning hyperparameters using traditional gradient descent methods. The supervised learning mechanism is employed in the selection of convolutional kernel parameters, ensuring the global approximation capability of the deep learning model.\nThe stochastic configuration convolutional generation strategy adaptively determines the range of convolutional kernel parameters and randomly generates new kernel parameters within this range, including weights and biases. The deep neural network is constructed starting from zero convolutional kernels, and interpretable new convolutional kernels are generated using the supervised learning mechanism, ensuring the improvement of network performance. Finally, the output weights of the network are updated using the least squares method, and the generation of convolutional kernels stops when the network error is below the predefined threshold.\nLet F = [f1, f2,..., fm]: Rd1\u00d7d2\u00d7d3 \u2192 Rm be a set of real-valued functions, where the L2 norm is defined as:\n$||F|| = \\sqrt{(\u03a3_{i=1}^{m} \u222b_D |f_i(x)|^2dx)}<\u221e$  (4)\nThe inner product between the real-valued functions F and G = [91,92,\u2026\u2026,9m]: Rd1\u00d7d2\u00d7d3 \u2192 Rm can be represented as:\n$(F,G) = \u2211_{q=1}^{m} (f_q, g_q) = \u2211_{q=1}^{m} \u222b_D f_q(x)g_q(x)dx$       (5)\nGiven an input matrix I and a convolutional kernel K of size p\u00d7 n, the element at position (i, j) in the output matrix S after the cross-correlation operation is defined as:\n$S(i, j) = (I*K)(i, j) = \u03a3_{\u03c1}\u03a3_{n}I(i+\u03c1,j+n)K(p,n)$   (6)\nwhere, * denotes the cross-correlation operator and I (i+p, j+ n)K(p, n) represents the element at position (i + p, j + n) in the input matrix I multiplied by the element at position (p, n) in the convolutional kernel K.\nGiven a target function F: Rd \u2192 Rm, assuming a DCSCNS consists of Lmax convolutional layers, each layer with C\u2081, . . ., C1, ..., CLmax (l \u2208 [1, Lmax]) convolutional kernels with a size of k \u00d7 k, the DCSCNs can be represented as:\n$F(x) = \\sum_{l=1}^{Lmax} \\sum_{C=1}^{Cl} O^l_c A^l_c (W^l_c, b^l_c, I^l)$            (7)\nwhere, We and by are the parameters of the Cth convolutional kernel in the 1th layer,\n$W_{C,[1,1]}^{l}:W_{C,[1,k]}^{l}:W_{C,[k,1]}^{l}:W_{C,[k,k]}^{l}$\nkernel in the lth layer, WI\u00b9 is the input of the lth layer, A\u0108 represents the convolutional function, including convolutional operation, activation function, and downsampling operation, O is the output weight, and the error e' = F \u2013 Fl = [e1, e,..., em].\nAssuming the function space span (\u0413) composed of Fis dense in the L2 space, \u2200A \u2208 \u0413, 0 < ||A|| < b, where b \u2208 R+. Given p > 0 and a non-negative contraction sequence {uc}, {uc} satisfying limc\u2192+\u221e uc = 0 and \u03a3C=1 uc = \u221e, the parameters of the Cth convolutional kernel in the lth layer are randomly generated if they satisfy:\n$(e'_{c,q}, A_c)^2 \u2265 \u03c1u_c b^2 ||e'_{c-1,q}||^2$     (8)\nwhere, $q = 1,2,...,m$. Then, the condition limi\u2192+\u221e ||F - F\u00b9|| = 0 holds; otherwise, the parameters of the Cth convolutional kernel in the lth layer are regenerated. When the number of convolutional kernels in the Ith layer increases to Cit if the error el is still greater than the predetermined value, a new convolutional kernel is added as the first kernel of the l + 1th layer, and it satisfies:\n$(e_{ci,q}, A_{1+1})^2 \u2265 \u03c1u_{c,1} b^2 ||e_{ci-1,q}||^2$            (9)\nThen, the condition lim\u012b\u2192+\u221e ||F \u2013 F\u00b9|| = 0; otherwise, the parameters of the first convolutional kernel in the (l+1)th layer are regenerated until the termination condition for kernel augmentation is met.\nTherefore, the construction problem of a DCSCNs can be described as follows: Given training image data X = {X1,X2, ..., XN}, where xi \u2208 Rd1\u00d7d2\u00d7d3, and the corresponding outputs Y = {Y1, Y2,...,YN}, where yi \u2208 Rm represents the image category label. Let I\u012e denote the tth channel of the Ith layer convolution of input data I\u00b9, for t = 1, 2, . . ., C\u0131\u22121. The feature map Mo, representing the output of the Cth convolutional kernel in the 1th layer, can be expressed as:\n$M^l_c = g(\\sum_{t=1}^{C_{1-1}} W^l_c * I^l_t + b^l_c)$   (10)\nwhere, g(\u00b7) is the activation function, and My has dimensions H \u00d7 W. After max pooling, My obtains the downsampled feature map Ab:\n$A^l_c = \\underset{m=1,..., k-1}{max} \\underset{n=1,..., k-1}{max} M^l_c \\Psi \\Omega$          (11)\nwhere, \u03a8 \u2208 [h, h+m], h = 1, 2, . . ., H represents the length range of the feature map, and \u03a9 \u2208 [w, w + n] with w = 1,2,..., W represents the width range of the feature map.\nBased on Equation (11), the feature map set A = [A1, A2,..., Ac] of the Ith layer convolution can be obtained. Multiplying A by the output weights O of the convolutional network yields the output Fl for the Cth convolutional kernel in the 1th layer:\n$F^l = \\sum_{l=1}^{L_{max}} \\sum_{C=1}^{C_l} O^l_c A^l_c$   (12)"}, {"title": "The output weights $O^l_c$ are updated using the least squares method:", "content": "$O^l_c = [O^l_{c,1},..., O^l_{c,m}] = arg \\underset{O}{\\text{min}} \\sum Y - \\sum_{c=1}^{C_l} O^{'l}_c A^l_c$  (13)\nThe error el for the Cth convolutional kernel in the [th convolutional layer is defined as:\n$e^l_c = Y \u2013 F^l = [e^l_{c,1},e^l_{c,2},..., e^l_{c,m}]$    (14)\nIf the L2 norm $||e^l_c||_2$ of e' is greater than the desired error limit \u0113, new parameters for the convolutional kernel with weights WC+1 and biases bc+1 are generated until the stopping criterion is met.\nConvolutional kernel parameter selection strategy: The construction of convolutional kernels in deep learning models directly affects the correlation between the learned model and input data. In a deep convolutional network with good performance, the convolutional kernels should follow a Gaussian distribution [31]. The highlight regions of the furnace wall and furnace mouth exhibit distinct texture characteristics, with significant brightness variations at the boundaries. Gaussian differential convolutional kernels, which involve Gaussian smoothing and differencing operations on images, can enhance texture information to distinguish image regions where texture is weakened or lost due to fog occlusion. Therefore, Gaussian differential convolutional kernels are selected for the DCSCNS, defined as follows [25]:\n$\\psi(x,y) = \\frac{1}{2 \\pi \\sigma^2} e^{-\\frac{x^2+y^2}{2 \\sigma^2}} - \\frac{1}{2 \\pi (r \\sigma)^2} e^{-\\frac{x^2+y^2}{2 (r \\sigma)^2}}$           (15)\nwhere, & represents the standard deviation, controlling the width range of the convolutional kernel, and r represents the scale factor. Smaller r values can detect fine edges and details, while larger r values can detect rough edges and contour structures. Different combinations of & and r yield different information about the magnesium furnace conditions.\nUnlike traditional methods that iteratively update convolutional kernel parameters using gradient descent algorithms, this study adopts a strategy of randomly selecting parameters to generate different convolutional kernels, where & and r follow uniform distributions. The weights We of the convolutional kernels follow a Gaussian differential distribution as shown in Equation (15), and the biases by are selected from a uniform distribution as shown in the following equation:\n$b \\sim U(0, 1)$   (16)\nBy generating Tmax candidate Gaussian differential convolutional kernels based on Equation (15) and Equation (16), the convergence score oc,q of each candidate convolutional kernel can be evaluated using Equation(17):\n$\\sigma^l_{c,q} = \\frac{((e^l_{c-1,q}), A^l_{c,q})^2}{(A^l_{c,q})^T A^l_{c,q}} - (\u03b6 + r) u_c (e^l_{c,q})^T e^l_{c,q}$      (17)\nwhere, $A^l_{c,q} = [A^l_{c,1}, A^l_{c,2},.., A^l_{c,m}]$. Candidate Gaussian differential convolutional kernels satisfying Equation (18) are retained:\n$\\sum_{q=1}^{m} \u03c3^l_{c,q} > 0$     (18)\nThe candidate Gaussian differential convolutional kernel with the highest convergence score $\\sum_{q=1}^{m} \u03c3^l_{c,q}$ is selected as the Cth convolutional kernel in the Ith layer. If none of the Tmax candidate Gaussian differential convolutional kernels meet the requirements, new \u00a7 and r values are selected based on Equation (15) to generate a new Gaussian differential convolutional kernel. This process continues until a convolutional kernel in the 1th layer satisfies the condition in Equation (18).\nAssuming that the number of convolutional kernels in the 1th layer of DCSCNs is Cl, it can be derived that the lth layer convolution satisfies [25]:\n$||e^l_c||^2 \u2264 (\u03b6 + r) u_c (\u03a3_{i=1}^{C_l}) ||e^{l-1}_c||^2$        (19)\nThe output error el+1 of the first Gaussian differential convolutional kernel generated in the l+1th layer convolution is given by:\n$||e_1||^2 = ||e^{'l}_c - O^l_{+1} A^l_{+1}||^2$          (20)"}, {"title": "where, $O^{l+1} = [O^l_{1,1}, O^l_{1,2},..., O^l_{1,m}]$. Let $O^{'+1} = [O^{'l}_{1,1}, O^{'l}_{1,2},..., O^{'l}_{1,m}$ represent the optimal output weights. Then O1+1 can be expressed as:", "content": "$O^{l+1}_{1,q} = \\frac{(e^l_{ci,q}, A^l_{+1})}{||A^l_{+1}||^2}$  (21)\nBy transforming $||e^{l+1}||^2$ using Equations (18-21), we have:\n$||e^{l+1}||^2 \u2264 ||e^l_c - O^{'l}_{+1} A^l_{+1}||^2 = ||e^l_c||^2 \u2013 \u03a3_{l=1}^{CL} ||e^{l+1}_{l,q}||^2 \u2264 ||e^l_c||^2$      (22)\nThus\n$||e^{l+1}||^2 \u2264 ||e^l_c||^2 \u2264 ||e^{l+1}||^2 (\u03b6 + r) u \u03a3_{i=1}^{CL} ||e^l||^2$         (23)\nFrom this, it can be proven that the output error e1+1 of the DCSCNs monotonically decreases, indicating the convergence of the network."}, {"title": "C. Interpretability evaluation", "content": "To ensure the reliability and interpretability of the recognition results for working conditions in the fused magnesium furnace, it is important for operators to understand the trustworthy decision-making process of deep learning models. The DCSCNs ensures global convergence to obtain reliable recognition results [25]. The Gaussian distribution convolutional kernels generated based on supervised learning have a strong correlation with the input data, ensuring the interpretability of the model mechanism. Class activation mapping visualization, as a visual interpretability verification, represents the distribution of importance in the data. It utilizes the gradient information of the last convolutional layer as the category score for channel feature maps and calculates the category importance by weighting the feature maps. Finally, the feature activation mapping is superimposed on the original image to obtain the interpretable visualization of feature data as shown in Figure 3.\nThe feature maps set Al in the Ith layer is upsampled to the original input size using bilinear interpolation and normalized to the range [0, 1]. The oth channel feature map A from A', when overlaid with the original image xi, can be denoted as A:\n$A^{p} = A^{p} \\bigotimes x_i$     (24)\nwhere, \u2297 represents element-wise multiplication. A is then fed into a DCSCNs model \u2206, and the softmax function produces category scores S:\n$S = Softmax (\u0394 (A))$  (25)\nThe DCSCNs model A predicts the category result y\u00ba for xi, where q = [1,\u2026\u2026,m], and the category score for the oth channel feature map is denoted as Soq. The definition of the channel feature independence coefficient is as follows:\n$FC = \\frac{||A^{p}||* ||A^{p}|| \\ominus \u2261}{||A^{p}||*}$ (26)"}, {"title": "Based on Lo, the interpretable trustworthiness evaluation index can be defined to measure the deviation between the predicted target and the true target, determining whether the interpretability result is consistent with the true result. The interpretable trustworthiness evaluation index for the ith", "content": "where, $A^{l} \\in R^{H \\times W \\times C_l}$, and $A^{\\rho} \\in R^{H \\times W}$ represents the \u03c1, \u03c1 \u2208 [1, C\u03b9] feature channel. $||\\cdot||*$ represents the nuclear norm, \u2299 represents the Hadamard product, and \u2261 represents the convolutional kernel mask matrix, where the oth row is zero and the other rows are 1. By multiplying all the feature maps in Al by Soq and FC, and then summing them, the CAM for sample xi under the [th layer DCSCNs model can be obtained:\n$\\pounds^p = ReLU (\\sum_{\\rho} F^C S A_i^p)$  (27)\nwhere, A\u00b9 \u2208 RH\u00d7W\u00d7C\u0131, and A\u2208 RH\u00d7W represents the \u03c1, \u03c1 \u2208 [1, C\u03b9] feature channel. ||\u00b7 ||* represents the nuclear norm, \u2299 represents the Hadamard product, and \u2261 represents the convolutional kernel mask matrix, where the oth row is zero and the other rows are 1. By multiplying all the feature maps in Al by Sog and FC, and then summing them, the CAM for sample xi under the [th layer DCSCNs model can be obtained:"}, {"title": "D. Adaptive pruning mechanism for convolutional kernels based on RL", "content": "sample is defined as the intersection over union (IoU) between the highlighted region di of the interpretability result and the true annotated region di:\n$IoU = \\frac{d_i \\cap d'_i}{d_i \\cup d'_i}$   (28)\nwhere, din di represents the area of intersection between di and di, and di Udi represents the area of union between di and d\u012b. The interpretable trustworthiness evaluation index IoU\u00b9 for the lth layer network can be obtained from IoUi:\n$IoU^l = \\frac{\\sum_{i=1}^N IU_i}{N}$      (29)\nAction Set: A continuous action set A = {a} represents the pruning ratio of each layer convolutional kernels, where \u03b1\u2208 (0,1).\nState Set: The state set of the [th layer convolutional layer is denoted as S = {l, C\u0131, C\u0131\u22121, h, w, al\u22121}, where l represents the current convolutional layer, Ci represents the number of convolutional kernels in the current layer, Cl-1 represents the number of convolutional kernels in the previous layer, h represents the length of the input feature map, w represents the width of the input feature map, and al-1 represents the action of the previous layer.\nReward Function: To balance feature independence, model accuracy, and interpretable trustworthiness, the joint reward function is defined as follows:\n$R = ACC_{val} + IoU_{val} \u2013 \u03b2 \u00d7 PA$ (30)\nwhere, ACCval is the accuracy of the pruned model on the validation set, IoUval is the interpretable trustworthiness evaluation index of the final layer feature map in the pruned model on the validation set, PA is the parameter count after pruning, and \u1e9e is the weight coefficient.\nTraining Strategy: The DDPG RL algorithm is used, where the actor network performs action selection, including the policy network \u03bc and the target policy network \u03bc'. The critic network evaluates values, including the value network Q and the target value network Q'. The objective function of the critic value network is:\n$Loss = \\frac{1}{2N} \\sum [y_i - Q(s_t, a_t | \\omega)]^2$  (31)\nwhere, N is the number of samples, Q (st, at | w) is the value of evaluating state st and action at in the critic value network with parameters w, yt is the target value:\nyt = Rt + yQ' (St+1, \u03bc' (St+1 | \u03c9) | \u03c9')  (32)\nwhere, \u03bc' (st+1 | w) is the action prediction for state st+1 at time t + 1 using the actor target policy network, w' is the parameter of Q', and y is the discount factor.\nThe actor policy network is updated using policy gradients:\n$\\nabla_{\\theta_{\\mu}} J \\approx \\frac{1}{N} \\sum_t \\nabla_a Q(s, a | \\omega)|_{s=s_t, a=\\mu(s_t)}$        (33)\n$\\nabla_{\\mu} \\mu (s_t | \\theta_{\\mu})$\nwhere 9th is the parameter of the policy network \u03bc.\nUpdate the target policy network \u03bc' and the target value network Q' :\n$\\theta_{\\mu'} \\gets \\tau \\theta_{\\mu} + (1 \u2212 \u03c4)\u03b8_{\\mu'}$  (34)\n$\\omega' \\gets \\tau \\omega + (1 \u2212 \u03c4)\u03c9'$     (35)\nwhere, T is the learning rate, \u0442\u2208 (0, 1)."}, {"title": "IV. EXPERIMENTAL ANALYSIS", "content": "To verify the effectiveness of the proposed method, production videos were selected from an fused magnesium furnace factory in Liaoning Province. The videos were frame-separated to obtain images with a resolution of 1080 \u00d7 1920. After image data augmentation, a total of 12,000 image samples were obtained. Figures 5 to 8 show the partial results of data augmentation for normal, underburn, overheated, and abnormal exhaust working conditions, respectively. The working conditions of the fused magnesium furnace images were annotated by experts. Randomly, 60% of the data (7,200 images in total) were selected as the training set, with each of the four condition samples accounting for a quarter of the training set. Additionally, 20% of the data (2,400 images in total) were chosen as the validation set, and the remaining 20% (2,400 samples) were used as the test set. The experimental setup included an Intel i9-10900K processor, 16GB of memory, and an RTX 3060 graphics card."}, {"title": "B. Performance evaluation metrics", "content": "The accuracy (Ra) is defined as the ratio of the number of correctly classified samples to the total number of samples, and it is calculated as follows:\n$R_a = \\frac{TP+TN}{N}$ (36)\nwhere, TP represents the number of samples that are truly positive and are correctly predicted as positive, and TN represents the number of samples that are truly negative and are correctly predicted as negative.\nThe parameter count (PA) measures the memory size occupied by the model, which is the sum of the parameter count of the convolutional layers (CA) and the fully connected layers (FA), and it is calculated as follows:\n$PA = \\sum_{i=1}^{L_{max}} (CA_i + FA_i)$ = $\\sum_{i=1}^{L_{max}} (k*k x C_{i-1} + 1) x C_i + (m_{in} + 1) x m$ (37)\nwhere, Cl-1 is the number of convolutional kernels in the 1th layer, Ci is the number of convolutional kernels in the 1th layer, min is the number of input neurons in the fully connected layer, and m is the dimension of the network output."}, {"title": "C. Experiment results and analysis", "content": "Experiment results of the deep convolutional stochastic configuration networks: The parameter settings for the DC-SCNs are as follows: the preferred error limit is \u0113 = 0.01, the maximum number of candidate Gaussian differential convolutional kernels is Tmax = 100, the standard deviation & ranges from 0.5 to 5, the scale factor r ranges from 0.8 to 1.5, and the sizes of the Gaussian differential convolutional kernels is k = {3,5,7}. The maximum number of convolutional layers in the network is Lmax = 10, the maximum number of convolutional kernels per layer is CLmax = 50, a sigmoid activation function is used, the pooling layer adopts the maximum pooling method with a kernel size of kp = 2, and a non-negative contraction sequence is defined as uc = \u311c, where C ranges from 1 to Cmax. A pooling layer is inserted after every two convolutional layers.\nBy fixing the kernel size to k = 3, Figure 10 shows the recognition accuracy curves of the training and testing sets for an 8-layer DCSCNs model. It can be observed that the multi-layer network exhibits better convergence compared to a single-layer network, with an accuracy of 94.53% on the training set and 92.78% on the testing set. The multi-layer DCSCNs achieves an improvement of 14.78% and 19.89% in accuracy compared to the single-layer DCSCNs on the training and testing sets, respectively, while the training time increases by 73.21%.\nResults of the interpretability evaluation experiment: Figure 11 depicts the class activation mapping for the four working conditions in the deep convolutinal stochastic configuration network, with varying numbers of convolutional layers. The highlighted regions of the figure denotes the activation region, which represents the area of focus for this convolutional layer. When l = 1, the highlighted regions are small and dispersed, indicating that the network is unable to effectively focus on the target region. This suggests that the network is unable to extract sufficient feature information at this number of layers. When l = 4, the highlighted region becomes larger and is in closer proximity to the target region, indicating an improvement in feature extraction. When I is further increased to 8, the highlighted region encompasses the entire target region, indicating that as the number of convolutional layers increases and the amount of computation increases, the network is able to extract more critical and complete feature information. Therefore, in this paper, l is set to 8.\nThe class activation mapping maps for the four working conditions under l = 8 are presented in Fig. 12(a)-12(d). It can be observed that the highlighted regions with the various working conditions exhibit complete and continuous characteristics, allowing for the clear recognition of the target region. This suggests that when I is 8, the DCSCNs are capable of adapting to the image data of different working conditions, effectively extracting the key features of each working condition, and accurately locating the target region of interest. Specifically, under normal working conditions, the network focuses on the position of the flame at the furnace opening. Under under-burning working conditions, the network is able to focus on the position of the furnace wall burning red and the furnace opening. Under overheating working conditions, the network accurately locates the position of the flame at the furnace opening. Under abnormal exhaust working conditions, the network is able to recognise the region where the solution overflows from the furnace opening. In conclusion, the proposed model provides reliable technical support for practical species for fused magnesium furnace working condition recognition."}, {"title": "D. Ablation Experiments", "content": "To validate the effectiveness of each module proposed in this study", "variations": "without Gaussian convolutional kernels, without the adaptive kernel pruning mechanism, and without both Gaussian convolutional kernels and the adaptive kernel pruning mechanism. An 8-layer DCSCNs is employed for these experiments. The results are presented in Table 1.\nAs can be inferred from Table 1, the proposed algorithm shows improvements in both training and testing accuracy rates compared to the methods without Gaussian convolutional kernels and those also without the adaptive kernel pruning mechanism module. Specifically, the training and testing accuracy rates are enhanced by 0.92%, 0.58%, 0.71%, and 0.56%, respectively. Furthermore, compared to the method lacking the adaptive kernel pruning mechanism, our approach reduced the parameter size by 31.4MB, and the training and inference time are decreased by 12136.911s and 0.005s, respectively. Therefore, the utilization of meaningful Gaussian differential convolutional kernels enables the model to better adapt to the complex scenarios encountered in fused magnesium furnace working conditions, thereby ensuring continual improvements in accuracy. CAM is employed for visualizing feature importance, and the interpretable trustworthiness index is defined, thereby making the working condition recognition more accurate and trustworthy. Moreover, the adaptive"}]}