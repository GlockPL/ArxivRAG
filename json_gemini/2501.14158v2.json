{"title": "Advancing MRI Reconstruction: A Systematic Review of Deep Learning and Compressed Sensing Integration", "authors": ["Mojtaba Safari", "Zach Eidex", "Chih-Wei Chang", "Richard L.J. Qiu", "Xiaofeng Yang"], "abstract": "Magnetic resonance imaging (MRI) is a non-invasive imaging modality and provides comprehensive anatomical and functional insights into the human body. However, its long acquisition times can lead to patient discomfort, motion artifacts, and limiting real-time applications. To address these challenges, strategies such as parallel imaging have been applied, which utilize multiple receiver coils to speed up the data acquisition process. Additionally, compressed sensing (CS) is a method that facilitates image reconstruction from sparse data, significantly reducing image acquisition time by minimizing the amount of data collection needed. Recently, deep learning (DL) has emerged as a powerful tool for improving MRI reconstruction. It has been integrated with parallel imaging and CS principles to achieve faster and more accurate MRI reconstructions. This review comprehensively examines DL-based techniques for MRI reconstruction. We categorize and discuss various DL-based methods, including end-to-end approaches, unrolled optimization, and federated learning, highlighting their potential benefits. Our systematic review highlights significant contributions and underscores the potential of DL in MRI reconstruction. Additionally, we summarize key results and trends in DL-based MRI reconstruction, including quantitative metrics, the dataset, acceleration factors, and the progress of and research interest in DL techniques over time. Finally, we discuss potential future directions and the importance of DL-based MRI reconstruction in advancing medical imaging. To facilitate further research in this area, we provide a GitHub repository that includes up-to-date DL-based MRI reconstruction publications and public datasets- https://github.com/mosaf/Awesome-DL-based-CS-MRI.", "sections": [{"title": "1. Introduction", "content": "Magnetic resonance imaging (MRI) is a powerful diagnostic modality widely used for lesion detection and prognosis, radiation treatment planning, and post-treatment follow-up [1, 2]. It offers high-resolution imaging of soft tissues, making it indispensable for numerous clinical applications. Nonetheless, the Lancet Oncology Commission recently emphasized a critical shortfall of MRI scanners and other imaging technologies in low-income and middle-income countries, contributing to an estimated 2.5 million annual deaths worldwide [3]. This shortfall is partly attributable to the high costs associated with installing, operating, and maintaining MRI systems. As of 2020, there were only seven MRI scanners per million people globally, underscoring the limited availability of this vital technology [4].\nIn addition to financial constraints, lengthy MRI acquisition times hinder the daily throughput of patients and exacerbate wait times [5]. Prolonged scan durations also increase the probability of voluntary and involuntary patient movements, resulting in motion artifacts that degrade image quality [6]. Such artifacts not only compromise diagnostic accuracy but also impose a substantial financial burden, with an estimated annual cost of $364,000 per scanner attributable to motion-related issues [7].\nTo address the dual challenges of high cost and extended scan times, advanced MRI reconstruction methods have been developed. In particular, compressed sensing (CS) MRI reconstruction leverages the sparsity of MRI images in certain transform domains to recover high-quality images from undersampled k-space data (see Section 1.1.2). Traditional CS approaches employ randomness in sampling patterns alongside sparsity-enforcing optimization techniques, thereby reducing the number of measurements needed and accelerating the imaging process. By maintaining diagnostic image quality while lowering scan times, CS-based strategies can alleviate financial constraints and increase patient throughput.\nIn recent years, deep learning (DL) techniques have emerged as a promising complement or alternative to classical CS methods for MRI reconstruction. Unlike CS, which depends on explicit sparsity constraints, DL-based methods learn sophisticated mappings from undersampled to fully sampled images directly from training data (see Section 1.1.3). These methods can offer faster reconstruction times and exhibit robust performance in mitigating diverse artifacts and noise. While DL approaches do not explicitly enforce sparsity, their hierarchical structures can implicitly capture sparse representations. Consequently, integrating DL with CS principles can further enhance reconstruction quality and efficiency, thereby bridging the gap between traditional inverse problem formulations and modern data-driven strategies.\nFinally, modern MRI scanners largely rely on multi-coil acquisitions, which increase the signal-to-noise ratio (SNR) and enable accelerated imaging through parallel imaging (see Section 1.1.1) techniques. Although single-coil data commonly serve"}, {"title": "1.1. Conventional MRI acceleration techniques", "content": null}, {"title": "1.1.1. Parallel imaging", "content": "Parallel Imaging (PI) techniques, developed in the late 1990s, have greatly improved MRI by reducing scan times while preserving image quality [8]. PI speeds up image acquisition by using the spatial information from multiple receiver coils. These coils capture the same reduced amount of data, and the acceleration achieved results in undersampled aliased images unless advanced optimization techniques such as generalized autocalibrating partially parallel acquisitions (GRAPPA) [9] or sensitivity encoding (SENSE) [10] are employed. Unlike traditional MRI, which uses a single coil, PI uses an array of coils, each with a unique spatial sensitivity profile (see Figure 1).\nThe underlying principle of PI is to use the different spatial sensitivities of multiple coils to reconstruct the missing k-space data. This process reduces the number of phase-encoding steps needed, thereby shortening the scan time. The reconstruction algorithms, specific to each PI technique, then use this coil sensitivity information to fill in the gaps in the acquired data [12, 13]. There are two fundamental PI techniques as shown in Figure 2.\nPI is a valuable technique in MRI but has its limitations. One primary limitation is noise amplification, quantified by the geometry factor (g-factor), which increases with higher acceleration factors. The g-factor reflects the noise penalty arising from under-sampling the k-space and the subsequent reconstruction process, thereby significantly degrading image quality, particularly in regions with intrinsically low SNR [10]. Moreover, PI is susceptible to various artifacts, including aliasing artifacts resulting from under-sampling. Inaccurate estimation of coil sensitivities or limited k-space data can produce distorted images, potentially obscuring critical anatomical features and adversely affecting diagnostic confidence [9]. Consequently, precise calibration of coil sensitivities is critical in accelerated acquisitions, although this process can be labor-intensive. Notably, for fully sampled data, explicit sensitivity maps are not always necessary, as alternative methods such as root-sum-of-squares reconstruction may be used. However, in undersampled scenarios-where the primary goal is to shorten scan times-accurate coil sensitivity information remains crucial to effectively separate aliased signals and maintain robust image fidelity. Changes in the patient's position or anatomy during the scan can further complicate calibration, emphasizing the need for careful management of coil sensitivities."}, {"title": "1.1.2. Compressed sensing", "content": "MRI requires densely sampled k-space to avoid violating the Nyquist criteria [15, 16], which results in longer acquisition times for high-resolution images. To reduce the imaging time, k-space can be undersampled in the phase encoding direction by increasing the spacing between k-space lines and, therefore, covering the field of view in a shorter amount of time. Figure 3 illustrates the k-space sampling patterns for fully sampled, 2D undersampled, and 3D undersampled MRI data, demonstrating how CS achieves efficient data acquisition. This is particularly advantageous in MRI, where the acquisition of k-space data is inherently time-consuming. CS achieves this by exploiting two main principles: sparsity [17, 14] and incoherence [18]. Figure 2 illustrates the CS MRI image reconstruction steps."}, {"title": null, "content": "Reconstructing an image from undersampled data involves solving an optimization problem that enforces both sparsity and data consistency. Let yo \u2208 CN be the undersampled k-space acquired with sampling mask \u03a9, and let x \u2208 CM be the fully sampled data to be recovered, where N \u00ab M to accelerate MRI acquisition. The corresponding compressed sensing formulation is:\narg min || y \u2212 E\u03a9x ||2 + \u03b2 || \u03c4(x) ||1                                                                                     (1)\nx\nwhere \u03c4(\u00b7) is a sparsity-promoting transform (e.g., wavelet transform), \u03b2 is the regularization parameter. The encoding operator E\u03a9 = \u03a9FS accounts for the coil sensitivity map S and the Fourier transform F. This formulation enforces sparsity in the chosen transform domain while ensuring fidelity to the measured multi-coil k-space data.\nSeveral iterative algorithms have been developed to solve this optimization problem efficiently. Basis Pursuit solves the l\u2081-minimization problem directly. The iterative shrinkage-thresholding algorithm (ISTA) [19] is an iterative method that alternates between gradient descent and soft-thresholding steps to enforce sparsity. Total variation minimization (TV) enhances edge preservation by minimizing the total variation of the image. However, CS algorithms are unable to completely reconstruct the high-frequency texture content of images [20], limiting them to acceleration factors between 2.5 and 3 [21]. In addition, these iterative techniques inevitably increase reconstruction time."}, {"title": "1.1.3. Deep learning-based compressed sensing", "content": "DL has become a transformative tool in the field of MRI, revolutionizing image acquisition, reconstruction, and analysis. By utilizing sophisticated neural network architectures, DL techniques deliver substantial enhancements in image quality, acquisition speed, and diagnostic accuracy, often surpassing conventional methods in various aspects. This section provides an in-depth exploration of the fundamental principles, methodologies, and applications of deep learning-based MRI reconstruction.\nFor image reconstruction, DL methods have shown the potential to reconstruct high-quality images from undersampled k-space data, markedly reducing scan times. Traditional MRI reconstruction methods rely on iterative algorithms that are computationally intensive and time-consuming. In contrast, DL approaches, such as convolutional neural networks (ConvNets), can learn to map reconstructed undersampled k-space data (e.g., zero-filled images) to high-quality fully sampled images, effectively suppressing artifacts and restoring missing information. This capability enables rapid and accurate image reconstruction [22]. Moreover, DL models have demonstrated superior reconstruction performance, especially at higher acceleration rates, when compared to conventional CS models [23, 24].\nConventional CS relies on explicit sparse representations and iterative optimization to recover images from undersampled data, whereas DL techniques learn relevant features and structures directly from training data. Nevertheless, there is a strong synergy between CS and DL. By combining data fidelity constraints and sampling strategies from CS with the powerful feature extraction and representation capabilities of neural networks, these hybrid methods can achieve superior reconstruction accuracy and speed.\nMany state-of-the-art approaches [25, 26] incorporate elements of both CS and DL through model unrolling or learned regularizers, thereby enforcing sparsity or promoting implicit sparse representations within the network [27, 28, 29]. In these methods, each iteration of a classical CS optimization algorithm is mapped to one or more layers in a neural network, thereby blending theoretical guarantees from inverse problems with the data-driven adaptability of DL. This integration can help preserve important image details and reduce artifacts while substantially lowering reconstruction times compared to purely iterative CS methods.\nTable 1 provides a concise summary of the most relevant survey articles, revealing technical differences compared to our review. While previous reviews, such as those by [30] and [31], have focused on specific aspects of DL-based MRI reconstruction, our review provides a comprehensive analysis that includes detailed explanations of MRI imaging techniques, k-space trajectories, sampling patterns, and clinical applications. By categorizing DL methods and providing quantitative metrics and research trends,"}, {"title": null, "content": "our review offers a broader and more detailed perspective on the advancements and challenges in this field.\nEach study is systematically referenced throughout the manuscript to ensure cohesive integration and enhance the reader's understanding of how these studies contribute to the broader context of DL-based MRI reconstruction.\nThe PubMed database was meticulously searched on February 1st, 2024 and revised in January 1st 2025, using the terms \u201cdeep learning reconstruction\" OR \u201cfastMRI\u201d OR \u201cunrolled optimization\u201d OR \u201cMRI reconstruction\u201d OR \u201cMRI acceleration\" for articles published from January 2016 to January 2025. Relevant studies were carefully screened by title and abstract content. Of the 886 publications identified by PubMed, 130 articles were included. Figure 4 illustrates the entire literature screening and selection process."}, {"title": "1.2. k-space trajectories", "content": "Various trajectories have been developed in MRI for traversing k-space, including Cartesian, spiral, radial, and random trajectories [37]. The Cartesian trajectory, as depicted in Figure 5a, consists of parallel lines equidistant from each other, with each line representing a frequency-encoding readout. The image can be reconstructed using a fast Fourier transform (FFT), but each line requires a separate RF pulse, prolonging imaging time.\nThe radial trajectory was first used by [38] and shown in Figure 5b, consists of spokes starting from the center, with an oversampling center in k-space that makes it robust to motion artifacts [39]. However, under-sampling in the azimuthal direction increases streak artifacts [40].\nThe spiral trajectory shown in Figure 5c was introduced to decrease the MRI acquisition time. It starts at the center of the k-space and spirals outward, similar to radial sampling, and is robust to motion artifacts. However, hardware limitations restrict imaging efficiency and increase image blurring."}, {"title": "1.2.1. Sampling patterns", "content": "Many sampling strategies, when integrated with DL, facilitate accelerated MRI without severely compromising image quality [41]. These strategies provide undersampled k-space data to DL-based methods, which recover high-fidelity images by exploiting learned representations. Figure 6 illustrates some widely used sampling patterns.\nA prevalent method for data sampling is uniform Cartesian sampling, where data points are collected following a regularly spaced Cartesian grid. Although straightforward, this technique may cause coherent aliasing artifacts that reduce the efficacy of CS [42]. In contrast, random Cartesian sampling randomly places sampled points"}, {"title": null, "content": "across the Cartesian grid, resulting in incoherent aliasing, which generally leads to better reconstruction quality [14].\nWhile Cartesian sampling is often depicted in a line-based format, it is not exclusively limited to this structure. Variable density Poisson sampling-commonly known as \u201cCartesian Poisson\u201d sampling-randomly selects points from an underlying Cartesian grid according to a specified density profile. This randomness can help distribute aliasing artifacts more uniformly, thereby improving CS reconstructions. Likewise, pseudo-non-Cartesian methods such as CIRCUS [43] may appear to diverge from traditional line-based formats but can still be mapped onto a Cartesian grid. These techniques leverage the straightforwardness of FFT-based reconstruction while utilizing incoherence properties that are crucial to compressed sensing.\nBeyond strictly Cartesian formats, radial sampling evenly distributes spokes through k-space, allowing for oversampling of the center, which is beneficial for motion robustness [44]. A variant known as golden angle radial sampling positions consecutive radial spokes using the golden angle increment, improving coverage over time for dynamic and real-time imaging [45]. Meanwhile, spiral sampling traverses k-space along spiral trajectories, accommodating rapid acquisitions suitable for functional MRI and angiography [46].\nRandomization strategies are also significant in Poisson disk sampling, which guarantees that no two sampled points are too closely spaced. This characteristic produces a quasi-uniform yet random arrangement, enhancing incoherence and benefiting various MRI applications under CS [47]. Furthermore, k-t sampling, as demonstrated by k-t FOCUSS, combines k-space (spatial) and t-space (temporal) sampling to facilitate accelerated dynamic imaging by leveraging spatiotemporal sparsity [48]. In both two and three dimensions, non-Cartesian sampling can adopt various forms (e.g., radial, spiral) [49], with three-dimensional expansions allowing for volumetric imaging and potentially enhancing efficiency.\nIn recent years, optimized sampling patterns derived from machine learning and advanced optimization algorithms have gained significant importance. By tailoring sampling masks to the unique characteristics of the target images or applications, these methods enhance reconstruction outcomes further [50]. Ultimately, designing sampling patterns to achieve the necessary incoherence is crucial for CS. When these strategies are integrated with DL, undersampled measurements can often be reconstructed with high fidelity, thereby reducing scan times while maintaining image quality."}, {"title": "2. Deep learning", "content": null}, {"title": "2.1. Convolutional neural network", "content": "Convolutional neural networks, also known as ConvNets, are a type of deep neural networks that are designed to analyze grid-like data such as images and speech [51]. They have gained widespread recognition after the success of AlexNet [52] and have since been used to achieve state-of-the-art performance in various medical image processing and analysis tasks. ConvNets typically consist of multiple layers, with each layer including a convolutional operator, batch normalization layers, nonlinear activation functions, and dropout layers. Nonlinear activation functions facilitate the learning of complex functions. Finally, weight regularization and dropout layers mitigate overfitting. During convolution, trainable convolution kernels slide over the images to extract multiple feature maps called channels.\nThe network's parameters are computed using a backpropagation algorithm that calculates the gradient of the cost function with respect to the parameters in each layer. (Batch) Normalization layers are crucial in training deep ConvNets to prevent vanishing and exploding gradients. In addition, residual blocks [53] are a popular choice for building advanced ConvNets due to their ability to prevent gradient vanishing and facilitate smoother error surfaces [54]. By incorporating skip-layer connections between input and output, residual blocks can help reduce the risk of local minima. Furthermore, when combined with (batch) normalization layers, residual blocks can effectively address the problems of vanishing and exploding gradients."}, {"title": "2.2. Network architectures", "content": null}, {"title": "2.2.1. U-Net", "content": "Several DL models with different architectures have been proposed to enhance the performance and generalization of ConvNets. Among them, U-Net, with its elegant design that utilizes skip connections between the encoder and decoder, is the best-known architecture in computer vision [55, 56]. It has been extensively exploited in different medical applications such as image synthesis [57], segmentation [58, 59], and registration [60]. In recent years, U-net architectures have incorporated residual and attention layers as a backbone to increase the network's depth and improve performance."}, {"title": "2.2.2. Transformer architectures", "content": "ConvNets have demonstrated impressive efficacy in various medical imaging tasks. However, they are limited by the local context of convolutional operations limits their ability to capture global contextual information. To overcome this limitation, transformers with long-range dependencies have been developed to capture global context [61]. However, transformer models with more trainable parameters require larger databases for training, which can be a challenge in medical imaging, where data scarcity and computational resources may be constrained.\nTo address these challenges, various variations have been proposed, such as Swin Transformers [62], Vision CNN-Transformer [63, 64], and ReconFormer [65], which aims to reduce model size while improving or maintaining performance. For instance, Swin Transformers employ hierarchical feature maps and shifted windows to achieve computational efficiency, whereas Vision CNN-Transformer integrates convolutional layers with Transformer blocks to leverage the strengths of both paradigms. ReconFormer is a lightweight recurrent transformer model that iteratively reconstructs high-fidelity MRI images from highly undersampled k-space data.\nRecent advancements further demonstrate the potential of transformers in MRI reconstruction, exemplified by SLATER, a zero-shot learned adversarial transformer that employs cross-attention blocks to enhance sensitivity to global spatial interactions [66]. By decoupling the MRI prior from the imaging operator through a combination of generative pretraining and zero-shot optimization, SLATER achieves superior performance across diverse datasets and under-sampling patterns, thereby underscoring the transformative impact of transformer-based models in medical imaging. Ongoing research continues to explore unrolled and hybrid approaches to bolster the adaptability and clinical utility of these architectures [67]."}, {"title": "2.3. Generative learning paradigms", "content": null}, {"title": "2.3.1. Generative adversarial network", "content": "Generative adversarial networks (GANs) are implicit generative models. Unlike explicit generative models, GANs do not attempt to directly define the likelihood function. Instead, they aim to generate samples that are indistinguishable from real data through an adversarial process between a generator and a discriminator. The GAN, initially introduced in 2014, consists of two networks, generative and discriminator [68]. The former is trained to generate artificial data samples to approximate the target data distribution, and the latter is simultaneously trained to distinguish the artificial data from real ground truth data. Thus, the discriminators encourage the generator to generate data samples with a distribution similar to the target distribution. Variations of GANs have been developed to perform tasks including image-to-image translation, such as conditional GAN [69], StyleGAN [70], CycleGAN [71], and Pix2Pix [72]. GANs are widely used in medical imaging for tasks such as image registration, image synthesis, MRI image reconstruction, and MRI artifact reduction [73, 74, 75, 76]."}, {"title": "2.3.2. Diffusion model", "content": "The stable diffusion model, inspired by nonequilibrium thermodynamics, aims to simplify complex and difficult-to-calculate distributions using tractable ones like normal Gaussian distributions [77]. This model is comprised of two steps - the forward and reverse processes (Figure 7). During the forward process, Gaussian noise is added to the initial image xo over T steps until the data at step T becomes normal Gaussian noise x\u0442 ~ \u2116(0, I). In the reverse process, the model learns to recover the original image xo from its noisy version given at a step t\u2208 (0,T] [78].\nDiffusion-based reconstruction models represent a significant advancement in MRI reconstruction techniques. This emerging approach shows promise for improving reconstruction accuracy and robustness, particularly in scenarios where traditional methods face limitations. The stable diffusion models have been employed for medical imaging tasks such as denoising [79], synthesis [80], MRI distortion reduction [6], and MRI image reconstruction [81, 82, 83].\nWhile diffusion models provide a robust framework for image reconstruction similar to other generative models like GANs and VAEs, it is important to note that they are not standalone MRI reconstruction methods. Instead, they offer a versatile and powerful approach that can be integrated into the broader MRI reconstruction pipeline, complementing existing techniques and addressing specific challenges."}, {"title": "3. Deep learning for MRI reconstruction", "content": "The framework for DL-based MRI reconstruction models can be divided into two main approaches: physics-driven and fully data-driven models. While all DL-based methods rely on data for training, physics-driven models incorporate domain-specific knowledge, such as sampling patterns and physical constraints, into the reconstruction process, whereas fully data-driven models leverage the data alone to learn the reconstruction. Within these categories, there are two types of models: end-to-end and unrolled. End-to-end models take in zero-filled k-space and output fully sampled k-space. They typically utilize a regularization term listed in Table 2 to enforce the uniqueness of the reconstructed images. On the other hand, unrolled models are more complex and further classified into two types: unrolled optimization and closed-form models known for the \"data consistency (DC) layer.\" unrolled optimization models iteratively optimize the reconstruction process, while DC layer models use a closed-form equation to ensure data consistency. Table 3 presents a summary comparing DL-based MRI reconstruction methods. These models are utilized in various training scenarios, including federated learning and self-supervised training."}, {"title": "3.1. End-to-end models", "content": "DL end-to-end models are specifically designed to tackle the MRI reconstruction problem without enforcing any data acquisition model. To achieve this, these models rely on a neural network to accurately predict fully sampled data from undersampled data [89, 23, 91]. Additionally, these models are trained using various regularization techniques that help address the ill-posed inverse problem. Table 2 lists common regularization techniques utilized in these models.\nThe end-to-end approach readily employs the same baseline models that are used for image-to-image translation, such as the U-net [92, 93], Swin transformers [94], and GANs [95, 96], making it easy to implement and allowing for the use of very deep and complex networks. However, they require a larger sample dataset than unrolling MRI reconstruction models and tend to predict images with synthetic data. Table 4 provides a list of selected references that used end-to-end DL models to solve DL-based MRI reconstruction algorithms."}, {"title": "3.2. unrolled model", "content": null}, {"title": "3.2.1. unrolled optimization", "content": "Unrolling in the DL-based MRI reconstruction context means transforming the iterative steps of an optimization algorithm into a deep neural network architecture, particularly ConvNets. Each iteration of the algorithm given in Equation 1 is mapped to a layer or a set of layers in the network. This approach allows the network to learn the parameters of the reconstruction process directly from training data, which can lead to more efficient and accurate reconstructions. The unrolled DL-based MRI reconstruction models have been shown to outperform end-to-end methods using a network with a smaller number of trainable parameters [120, 121, 122, 123, 124].\nHowever, the iterative nature of the unrolled optimization method may increase the computation time during both the training and inference steps, as the network's weights are updated during training, and multiple iterative steps are performed during inference to ensure data consistency. Table 5 provides a list of references that used unrolled optimization models to solve DL-based MRI reconstruction algorithms."}, {"title": "3.2.2. Data consistency layer", "content": "The more popular approach is to train the unrolled models similarly to the end-to-end models as follows:\narg min ||x \u2212 f\u03c8 (x\u03a9)||1 + \u03bb  ||y\u03a9 \u2212 E\u03a9x||2                                                                                       (2)"}, {"title": "3.3. Federated learning", "content": "Federated learning (FL) is a promising framework that enables the collaborative training of learning-based models across multiple institutions without the need for sharing local private data [182]. The objective of FL models is to learn a global model by taking the average of local models [39] or by ensuring the proximity of local models to the global model [183]. When applied to MRI image reconstruction, the FL offers unique advantages tailored to the specific challenges and requirements as follows:\n\u2022 MR images often contain sensitive patient information that needs to be protected. FL enables MRI models to be trained directly on the devices where the images are acquired without the need to transmit patient data to a centralized location. This decentralization of data ensures that patient privacy and confidentiality are maintained.\n\u2022 MRI machines can vary in their hardware specifications and imaging protocols, which can lead to challenges in standardizing image reconstruction algorithms. However, FL accommodates this heterogeneity by allowing models to be trained collaboratively across different types of MRI machines, ensuring that the reconstruction algorithms are robust and adaptable to various configurations."}, {"title": "3.4. Assessment", "content": "The previous sections covered three major DL-based MRI reconstruction training approaches: end-to-end, unrolled optimization, and the DC layer. While these methods can be applied to both supervised and self-supervised frameworks, the unrolled optimization and DC layer approaches are typically used for self-supervised training (see Table 8). A summary of the advantages and disadvantages of each approach is provided in Table 9."}, {"title": "4. Benchmark Competitions in MRI Reconstruction", "content": "Large-scale competitions are instrumental in driving the progress of DL methods for MRI reconstruction. By uniting diverse datasets, standardizing evaluation protocols, and establishing clear metrics for comparison, these events create an environment that encourages rigorous benchmarking of innovative architectures and algorithms. This not only accelerates methodological development but also enhances transparency in the field, ultimately benefiting researchers and patients.\nA notable initiative is the Multi-Coil MRI Reconstruction Challenge [117] \u00b9, which aims to evaluate the generalizability of reconstruction models across different coil configurations. This challenge focuses on raw multi-coil 3D k-space data of T1w brain images from 167 healthy volunteers. The datasets were obtained from 12-channel and 32-channel receiver coils, comprising 70% and 30% of the data, respectively. Participants could thoroughly evaluate algorithm performance across varied coil arrays. This carefully curated dataset highlights the strengths and weaknesses in coil-sensitivity estimation, artifact correction, and network generalization.\nThe fastMRI Challenge [200], initiated by Facebook AI Research \u00b2 in collaboration with NYU Langone Health \u00b3, presents a significant large-scale benchmark focused on raw multi-coil, primarily 2D k-space data, with the exception of the breast dataset, which is acquired in 3D. This challenge encompasses a variety of tasks, ranging from reconstructions to more extensive clinical evaluations. Its publicly accessible dataset spans several anatomies, including brain (6,970 samples), knee (1,500 samples), breast"}, {"title": "5. Evaluation metrics", "content": null}, {"title": "5.1. Quantitative metrics", "content": "When testing MRI reconstruction models, the quality of reconstructed images is quantitatively assessed by comparing them with the ground truth. Retrospective"}, {"title": null, "content": "under-sampling of the k-space allows the reporting of indices to quantify the quality of the reconstructed images.\nMost studies quantitatively compare predicted images with ground truth images. As indicated in Figure 9a, most of these studies use the structural similarity (SSIM) [206] index and peak signal-to-noise ratio (PSNR) to compare reconstructed image with ground truth image. SSIM ranges between -1 and 1, with the best similarity achieved by an SSIM equal to one. A higher PSNR indicates a better reconstruction. The logarithmic operator quantifies image quality that closely aligns with human perception [207].\nThe normalized mean square error (NMSE) has become more popular since 2022 to quantify the quality of reconstructed images. Smaller NMSE values indicate better image reconstruction. Nonetheless, it might favor image smoothness rather than sharpness.\nHowever, other metrics such as root mean square error, mean square error, mean absolute error, and Fr\u00e9chet inception distance are rarely used, especially after a recommendation made in 2018 by Zbontar, et al. [97] (see Figure 9).\nRegarding the training methods, the unrolled models, including the unrolled optimization and DC layer, are the most commonly used, with a growing use of the DC layer since 2020, which is expected to continue this trend in the future. More details about these trends are illustrated in Figure 9b.\nOur systematic review found that around 39% of studies used institutional datasets, while fastMRI was the most frequently used public dataset. The majority of private datasets use single-coil images compared to the latter's raw multi-coil raw 2D k-space data. The fastMRI dataset consists of three imaging regions: the brain, pelvis, prostate, and knee regions. Less commonly used datasets include IXI, Calgary, and MRIdata, with only around 7%, 6%, and 4% usage rates, respectively (see Figure 9c).\nIn addition, most studies reviewed by this study tested their proposed model using acceleration factor (R) 2 < R < 6. The least simulated acceleration factor was R > 12 and 6 < R < 8 with 14.6% and 7.3% of usage, respectively. The percentage of acceleration usage is summarized in Figure 9d."}, {"title": "5.2. Clinical evaluations", "content": "The metrics presented in Section 5.1 quantify the quality of image reconstruction, but their results may not directly correlate with clinical outcomes. Several studies have been conducted to evaluate the clinical significance of MRI reconstruction using DL models. For example, a study found that DL-based MRI reconstruction models and fully sampled MRI images showed no significant differences (p-values > 0.05) in the organ-based image quality of the liver, pancreas, spleen, and kidneys, number and measured diameter of the detected lesions while reducing the imaging time by more than 85% [208]."}, {"title": "6. Discussion", "content": "This systematic review investigates the contemporary development of using DL for MRI acceleration to enhance reconstruction efficiency and image quality. In this work, we characterized the potentials and limitations of individual methods using DL or CS for MRI reconstruction and demonstrated that the integration of CS and DL can potentially lead to a promising future direction for MRI reconstruction."}, {"title": "6.1. Advancements and impact", "content": "DL-based MRI reconstruction methods have demonstrated remarkable capabilities in accelerating MRI acquisition without compromising image quality. Techniques such as U-nets, GANs, transformers, and diffusion models have shown superior performance in reconstructing high-quality images from undersampled k-space data. These methods leverage neural networks to learn complex mappings from undersampled to fully sampled data, enabling faster and more accurate image reconstructions compared to traditional CS methods.\nAlthough DL is distinct from CS, certain DL approaches integrate CS-inspired principles. For instance, unrolled networks convert iterative optimization steps in traditional CS algorithms into trainable neural network layers, pairing the interpretability of CS with the efficiency of DL. Data consistency layers further elevate reconstruction fidelity by enforcing adherence to the acquired k-space data. These hybrid methods underscore the potential of merging CS principles with DL frameworks, yielding enhanced robustness and generalization across varied clinical scenarios."}, {"title": "6.2. The Role of Multi-Coil Data in MRI Reconstruction", "content": "Multi-coil data play a pivotal role in modern MRI reconstruction, capitalizing on spatial sensitivity profiles from multiple coils to enhance reconstruction accuracy and expedite acquisitions. Most studies examined in this review evaluated their methods on both single-coil and multi-coil datasets. For example, resources such as fastMRI provide raw k-space data for multi-coil acquisitions while offering single-coil reconstructions for more streamlined evaluations. This dual-validation approach bolsters robustness across acquisition settings and allows direct comparisons with established methods.\nDespite widespread adoption, challenges remain in fully leveraging multi-coil data for realistic demonstrations. A major hurdle is the significant computational demand associated with estimating coil sensitivity maps-often obtained through the ESPIRIT algorithm-which can hinder real-time clinical applications. Future research should focus on integrating sensitivity estimation within reconstruction workflows, especially"}, {"title": "6.3. Limitations and challenges", "content": "Integrating DL with CS in MRI has shown significant promise in enhancing image quality and reducing acquisition times. This innovative approach holds great potential for revolutionizing clinical practice. However, several challenges must be addressed to fully realize this potential.\nA primary limitation lies in the high computational load that characterizes many DL models. Given their reliance on GPU-accelerated hardware and substantial memory resources, these models may be inaccessible in cost-constrained settings. Developing more efficient algorithms that preserve high performance while reducing computational demands represents a vital step toward broader clinical adoption.\nData availability and quality also pose critical concerns. Large, high-quality datasets are essential for training robust DL models, yet many institutions cannot access extensive databases. Although resources like the fastMRI dataset have been invaluable, they primarily offer multi-coil data that can be converted into single-coil reconstructions. Moreover, the shortage of raw 3D and 4D k-space data with pathologies constrains model generalization to different clinical contexts.\nAnother key challenge is achieving model generalizability. DL models trained on specific datasets may struggle to perform well on data from different institutions or with varying imaging protocols. This lack of robustness is problematic, especially when dealing with diverse patient anatomies and pathological conditions. Ensuring that models are adaptable and perform consistently across various scenarios remains a complex task. Overfitting to specific datasets and the difficulty in generalizing to new data are ongoing issues that need to be addressed.\nArtifacts prevalent in DL-generated MRI data include synthetic structures or \"hallucinations,\" which can arise at high acceleration factors, as well as blurring or smoothing artifacts that obscure critical details. Incoherent aliasing may also emerge from suboptimal under-sampling or model limitations, yielding misleading features that compromise diagnostic integrity. Such artifacts hinder clinical efficacy by masking true pathologies or introducing fictitious anatomical features.\nAddressing these challenges requires a multidisciplinary approach, involving collaboration between researchers, clinicians, and regulatory agencies. By focusing on model generalizability, workflow integration, computational efficiency, and regulatory compliance, the deployment of DL-based MRI reconstruction models in clinical practice can be effectively realized"}]}