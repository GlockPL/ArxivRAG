{"title": "Ontology-Aware RAG for Improved Question-Answering in\nCybersecurity Education", "authors": ["Chengshuai Zhao", "Garima Agrawal", "Tharindu Kumarage", "Zhen Tan", "Yuli Deng", "Ying-Chih Chen", "Huan Liu"], "abstract": "Integrating AI into education has the potential to transform\nthe teaching of science and technology courses, particularly\nin the field of cybersecurity. Al-driven question-answering\n(QA) systems can actively manage uncertainty in cyberse-\ncurity problem-solving, offering interactive, inquiry-based\nlearning experiences. Large language models (LLMs) have\ngained prominence in AI-driven QA systems, offering ad-\nvanced language understanding and user engagement. How-\never, they face challenges like hallucinations and limited\ndomain-specific knowledge, which reduce their reliability in\neducational settings. To address these challenges, we propose\nCyberRAG, an ontology-aware retrieval-augmented gener-\nation (RAG) approach for developing a reliable and safe\nQA system in cybersecurity education. CyberRAG employs\na two-step approach: first, it augments the domain-specific\nknowledge by retrieving validated cybersecurity documents\nfrom a knowledge base to enhance the relevance and accuracy\nof the response. Second, it mitigates hallucinations and mis-\nuse by integrating a knowledge graph ontology to validate the\nfinal answer. Experiments on publicly available cybersecurity\ndatasets show that CyberRAG delivers accurate, reliable re-\nsponses aligned with domain knowledge, demonstrating the\npotential of AI tools to enhance education.", "sections": [{"title": "Introduction", "content": "The use of AI in education has the potential to transform the\nway science and technology courses are taught. In scientific\nlearning, students are expected to engage in problem-solving\nand exploration, yet traditional classroom methods often fo-\ncus on the passive acquisition of established knowledge.\nThis approach limits opportunities for students to experience\nthe process of knowledge creation, leading to lower cogni-\ntive engagement. Cybersecurity is a problem-based learn-\ning domain where students must master complex tools, de-\nvelop defense techniques, and uncover new threats, which\nnecessitates a re-imagination of traditional education prac-\ntices (Shivapurkar, Bhatia, and Ahmed 2020).\nPrior research highlights that managing uncertainty is a\ncrucial component of the learning process, as students often\nstruggle with acquiring new skills, applying diverse method-\nologies, and forming new understandings (Jordan 2015). Ed-\nucators can effectively manage this uncertainty by increas-\ning it through the introduction of authentic, ambiguous chal-\nlenges to stimulate critical thinking, maintaining it to en-\ncourage deeper exploration and problem-solving, and re-\nducing it by identifying optimal solutions to help students\nintegrate new insights with existing knowledge (Chen, Be-\nnus, and Hernandez 2019). AI-driven question-answering\n(QA) systems can help manage this uncertainty in technical\nproblem-solving by supporting self-paced learning, signifi-\ncantly enhancing cognitive engagement (Means 2021).\nIn recent years, large language models (LLMs) have\nbecome central to AI-driven technologies. While LLM-\npowered QA systems hold great promise for enhancing\nlearning, they also face challenges such as hallucination and\nlimited domain knowledge, which can undermine their ef-\nfectiveness (Agrawal et al. 2024a; Huang et al. 2023; Zhang\net al. 2023; Xu, Jain, and Kankanhalli 2024). In cyberse-\ncurity education, where precision is critical, ensuring the\naccuracy of AI-generated content is essential. For exam-\nple, in tasks such as identifying vulnerabilities or interpret-\ning security policies, inaccurate AI responses could lead to\nmisinformation, compromising the learning experience and,\npotentially, real-world security (Kumarage et al. 2024). A\npromising solution to address this challenge is the retrieval-\naugmented generation (RAG) approach (Lewis et al. 2020),\nwhere the model generates responses by retrieving informa-\ntion from a validated knowledge base, thereby enhancing the\naccuracy and reliability.\nAlthough the RAG approach helps reduce hallucinations\nand address domain knowledge issues to some extent, the\nreliability of LLM-generated answers remains a concern\nfor achieving educational goals. Students may ask ques-\ntions that fall outside the scope of the augmented cyberse-\ncurity knowledge base. In such cases, LLMs rely on their\nown parametric knowledge to generate responses, which can\nexpose the QA system to risks of misinformation or mis-\nuse (Tan et al. 2024a,b; Kumarage et al. 2024). In an edu-\ncational setting, it is also crucial to prevent students from\nmanipulating the AI system for unintended purposes. There\nis a strong need to provide a validation system to ensure the\naccuracy and safety of LLM-generated responses. One po-\ntential solution is reinforcement learning from human feed-\nback (RLHF) (Christiano et al. 2017). However, this method\nrequires verification by cybersecurity experts, making it\nlabor-intensive, costly, and time-consuming. Preferably, an\nautomatic validation approach is needed. Domain-specific\nknowledge graphs, which structure expert knowledge and\ncapture the interactions between key entities in alignment\nwith domain rules (Abu-Salih 2021), offer a promising\ndirection. The knowledge graph ontology encodes these\nrules (Kejriwal 2019). By leveraging this ontology, LLM re-\nsponses can be validated by fact-checking against the prede-\nfined rules, ensuring greater accuracy and reliability without\nthe need for constant human oversight.\nIn this paper, we propose CyberRAG, an ontology-aware\nRAG approach for developing a reliable QA system in\ncybersecurity education, comprising two key components.\nFirst, we utilize RAG methods to retrieve validated cyber-\nsecurity documents from a knowledge base, enhancing both\nthe accuracy and relevance of the answers. Through finely\ncrafted prompts, CyberRAG improves QA performance by\nleveraging both cybersecurity content and the natural lan-\nguage processing capabilities of LLMs. Additionally, we in-\ntroduce an ontology-based validation approach that uses a\ncybersecurity knowledge graph ontology to automatically\nverify LLM-generated responses, thereby preventing poten-\ntial risks of misuse and hallucination. We conduct com-\nprehensive experiments on publicly available datasets to\ndemonstrate the effectiveness of CyberRAG in delivering\nreliable and accurate answers. Our research explores the\npotential of integrating AI into education, emphasizing its\ntransformative impact on traditional methods. This approach\nextends beyond cybersecurity and can also be applied to\nother educational subjects. Our contributions can be sum-\nmarized as follows:\n\u2022 We propose CyberRAG, a novel and reliable computa-\ntional framework aimed at creating an interactive and se-\ncure environment for cybersecurity education.\n\u2022 We design finely crafted prompts that enable CyberRAG\nto produce accurate and relevant answers by integrating a\ncybersecurity knowledge base with the vast prior knowl-\nedge present in LLMs.\n\u2022 We explore the use of knowledge graph ontology to val-\nidate LLM-generated responses, ensuring accuracy and\npreventing potential misuse of QA systems in education."}, {"title": "Related Work", "content": "Generative models have the potential to transform tradi-\ntional education by enabling personalized learning and au-\ntomating content creation, making education more adaptive\nand accessible (George 2023). The integration of LLMs in\neducation has further enhanced conversational capabilities,\nsupporting self-paced learning through AI-driven question-\nanswering tools and bots (Moore et al. 2023; Upadhyay et al.\n2024). However, the use of LLMs also presents challenges,\nparticularly the risks of hallucinations and inaccurate re-\nsponses, which are critical concerns in educational contexts\nand must be carefully managed to ensure responsible imple-\nmentation (Yan et al. 2024; Li et al. 2023). To address these\nissues, retrieval-augmented generation (RAG) methods are\nused by combining LLMs with real-time knowledge base\nretrieval to improve response accuracy ensuring content is\ncurrent and reliable in educational settings (Dakshit 2024;\nLiu et al. 2024; Modran et al. 2024)."}, {"title": "RAG in Education", "content": null}, {"title": "LLM-generated Answer Validation", "content": "However, most LLM approaches are currently limited to\nhandling simple queries, as generating complex answers\nfrom extensive knowledge articles and course materials\nsourced from diverse knowledge bases remains challenging,\noften leading to issues with the correctness of the answers\n(Elmessiry and Elmessiry 2024). Jeong et al. (Jeong et al.\n2024) proposed an adaptive QA approach to handle complex\nquestions, while Li et al. (Li, Liu, and Gao 2024) developed\nan evaluation framework for grounded and modular assess-\nment of RAG responses.\nVarious domains are using knowledge graphs to enhance\nLLMs' reasoning and retrieval capabilities (Hussien et al.\n2024; Agrawal et al. 2024b; De Santis et al. 2024). An on-\ntology within a KG, which defines the rules of a specific\ndomain, can also be used to validate LLM responses by\nchecking the correctness of relationships between key en-\ntities (Agrawal et al. 2024a). This capability is particularly\nvaluable in educational settings, where ensuring the accu-\nracy of LLM-generated content is crucial. While some stu-\ndent questions may extend beyond the scope of the aug-\nmented course material or knowledge base, ontology-aware\nvalidation offers a promising solution. However, research\nin this area remains limited. Our ontology-aware methods\nmark a significant advancement in this field."}, {"title": "AI for Cybersecurity Education", "content": "Learning cybersecurity is crucial for national security, safe-\nguarding critical infrastructure, and ensuring defense (Al-\nDaajeh et al. 2022; Newhouse et al. 2017; Rahman et al.\n2020). However, mastering this complex field requires deep\nknowledge of concepts, tools, and attack-defense simula-\ntions (Cheung et al. 2011; Schneider 2013; Ai et al. 2024).\nWhile AI shows promising potential in enhancing cogni-\ntive learning, research on its application in cybersecurity ed-\nucation remains limited (Laato et al. 2020; Grover, Broll,\nand Babb 2023; Wei-Kocsis et al. 2023; Ferrari, Wong, and\nKhmelevsky 2024). Previous efforts include structured flow\ngraphs from CTF texts for vulnerability analysis (Pal et al.\n2021) and knowledge graphs for guiding student projects\n(Deng et al. 2019, 2021; Deng, Zeng, and Huang 2021).\nAdditionally, a semi-automated approach has been used to\ncreate knowledge graphs from unstructured course mate-\nrial, improving student learning (Agrawal et al. 2022). The\nAISecKG ontology(Agrawal et al. 2023) further advanced\nthis by generating cybersecurity KG and the CyberQ dataset\n(Agrawal et al. 2024c) for LLM-based question-answering.\nHowever, a significant gap remains: the lack of a self-\npaced learning cybersecurity QA system. To address this, we\nleverage the CyberQ dataset to retrieve structured, authenti-\ncated cybersecurity content using RAG and validate LLM\noutputs with the AISecKG ontology, particularly for queries\nbeyond the scope of the CyberQ dataset. Our approach en-\nhances the accuracy, reliability, and safety of AI-driven edu-\ncation tools, effectively addressing this critical research gap."}, {"title": "Preliminaries", "content": "In this section, we will outline the fundamental concepts un-\nderlying our proposed CyberRAG framework."}, {"title": "Problem Formulation", "content": "We consider cybersecurity problem-based learning to be\na question-answering (QA) problem. Specifically, students\nraise a series of questions $Q = {q_1, q_2, ..., q_{|Q|}}$ , we ex-\npect the model to output corresponding responses as answers\n$A = {a_1, a_2, ..., a_{|A|}}$ , where $|Q| = |A|$ in our scenario."}, {"title": "RAG System", "content": "We employ a retrieval-augmented generation (RAG) system\nas a base framework to solve our problem because of its\nimpressive capacity for hallucination mitigation. A classic\nRAG approach entails two parts:\n\u2022 A retriever R that can effectively retrieve reference doc-\numents $D = {d_1, d_2, ..., d_{|D|}}$ from the knowledge base\nK (e.g., knowledge graph, QA database, and text materi-\nals) based on query-document relevance.\n\u2022 A generation model (e.g., large language model) G that\nprovides answers using the documents and human in-\nstructions $I = {1_1, 1_2, ..., i_{|1|}}$."}, {"title": "Knowledge Graph Ontology", "content": "In the context of our CyberRAG framework, we incorporate\nknowledge graph ontology to validate the LLM-generated\nresponses. A knowledge graph (KG) is a structured repre-\nsentation of knowledge in which entities (a.k.a, nodes) are\nconnected by relationships (a.k.a, edges). Formally, we de-\nfine a knowledge graph as a tuple $G = (E, R)$, where\n$E = {e_1, e_2, ..., e_{|E|}}$ represents the set of entities, and\n$R = {r_1, r_2, ..., r_{|R|}}$ represents the set of relationships be-\ntween these entities. Each relationship $r \\in R$ can be viewed\nas a directed edge connecting two entities $e_i$ and $e_j$ in the\ngraph, thereby forming a triplet $(e_i, r, e_j)$.\nTo further formalize the structure and semantics of the\ndomain knowledge represented in our system, we utilize an\nontology O. An ontology is a formal specification of a set\nof concepts within a domain and the relationships between\nthose concepts. Formally, we define an ontology O as a tuple\n$O = (C, R_c, H_c)$, where $C = {c_1, c_2, ..., c_{|C|}}$ is a set of\nconcepts, $R_c = {r^c_1, r^c_2, ..., r^c_{|r_c|}}$ is a set of conceptual\nrelationships, and $H_c \\subseteq C \\times C$ is a hierarchical structure\n(e.g., a taxonomy) that organizes these concepts."}, {"title": "Method", "content": "In this section, we first introduce our approach to Cyber-\nRAG. The detailed design of each component is then dis-\ncussed in the subsequent sections."}, {"title": "CyberRAG", "content": "Our proposed framework, named CyberRAG, comprises\ntwo key components: a retrieval-augmented generation\n(RAG) system and an ontology-based answer validation\nmodule. By leveraging the RAG system with carefully\ncrafted prompts, CyberRAG effectively addresses students'\nquestions by utilizing cybersecurity knowledge materi-\nals and the natural language understanding capabilities of\nLLMs. The ontology-based validation approach ensures that\nthe responses provided to students are both reliable and se-\ncure. An overview of CyberRAG is presented in Fig. 1."}, {"title": "Cybersecurity Knowledge Retrieval", "content": "To retrieve cybersecurity material from the knowledge base,\nthe first step is to design an effective retriever. We utilize\na dual-encoder dense retriever containing two encoders: a\nquestion encoder $E_Q$, which projects student queries into a\nshared semantic latent space, and a document encoder $E_D$,\nwhich embeds knowledge base documents into correspond-\ning vector representations. These encoders are optimized to\nmaintain semantic proximity between queries and relevant\ndocuments, ensuring that encoded representations are well-\naligned in the latent space, thereby facilitating accurate re-\ntrieval. Note that the question encoder and the document en-\ncoder can be the same in some settings. Then, the retriever\ncan retrieve the top k documents according to the query-\ndocument similarity.\nSpecifically, given a query $q_i \\in Q$ and a document $d_j \\in\nD$, they are encoded by query encoder $E_Q$ and document\nencoder $E_D, respectively.\n$h_{q_i} = E_Q(q_i)$\n$h_{d_j} = E_D(d_j)$\nwhere $h_{q_i}$ and $h_{d_j}$ are latent representations of query $q_i$ and\ndocument $d_j$.\nThen, the semantic relevance between the question and\nthe document is defined by cosine similarity between their\nlatent vectors:\n$sim(h_{q_i}, h_{d_j}) = \\frac{h_{q_i} \\cdot h_{d_j}}{||h_{q_i}|| ||h_{d_j}||}$\nwhere $h_{q_i} \\cdot h_{d_j}$ are inner product of two vectors and $||h_{q_i}||$\nand $||h_{d_j}||$ are the magnitudes (a.k.a. Euclidean norms) of $q_i$\nand $d_j$, respectively.\nBased on the similarities. top-k relevant course docu-\nments can be retrieved.\n$D = R(Q, K)$"}, {"title": "Cybersecurity Answer Generation", "content": "After retrieving relevant cybersecurity documents, the next\nstep is to prompt the generative model (i.e., LLMs) to\ngenerate answers. The most challenging aspect is design-\ning a prompt that maximizes the effectiveness of both the\nretrieved information and the generative model. An ideal\nprompt should guide the model to summarize the informa-\ntion when the retrieved documents are highly relevant and\nencourage the model to generate new responses by lever-\naging its own knowledge when the retrieved information is\ninsufficient or incomplete.\nWe design the prompt as illustrated in the Answer Gen-\neration Prompt. The proposed prompt consists of three key\nelements:\n\u2022 Documents: The documents relevant to the student's\nquery are retrieved by the retriever from the knowledge\nbase, using the method outlined in the previous section.\n\u2022 Questions: These are queries raised by students, which\nthe generative model is tasked with answering.\n\u2022 Instructions: These are rules and prompts designed by\ndomain experts. The first two instructions guide the gen-\nerative model to answer students' questions by refer-\nencing the retrieved documents. The third instruction\nencourages the model to generate responses based on\nits own knowledge when the documents are insuffi-\ncient. Thus the proposed framework can address stu-\ndents' queries, whether or not they are covered by the\nknowledge base.\nThe final prompt is given as input to the generative model to\ngenerate the answer to the student's query:\n$A = G(D, Q, I)$"}, {"title": "Ontology-based Answer Validation", "content": "For ontology validation, we used AISecKG (Agrawal 2023),\na cybersecurity education ontology that defines relation-\nships between concepts, applications, and roles within the\ncybersecurity domain. AISecKG organizes these into three\nbroad categories with 12 entity types. Concepts include\nfeatures, functions, data, attacks, vulnerabilities, and tech-\nniques, while applications cover tools, systems, and apps.\nRoles consist of users, attackers, and security teams. The on-\ntology defines nine core relationships between these entities,\nrepresented by 68 unique edges. For example, tuples such\nas ('attacker', 'can_exploit', 'feature') and (\u2018security team',\n'can_analyze', 'feature') illustrate entities and these relation-\nships. These triples represent the fundamental domain rules\nthat govern cybersecurity information at a schema level. By\nleveraging these ontology-based triples along with the nat-\nural language understanding capabilities of LLMs, an au-\ntomatic answer validation system can be developed for the\ncybersecurity domain.\nSpecifically, given the question Q and the corresponding\nresponse A provided by the generative language model, the\nvalidation model V takes the QA contexts, ontology rules\ndenoted by $O = {0_1, 0_2, ..., 0_{|0|}}$, and validation human in-\nstruct I' as the input, then produces the validation result R.\n$R = V(Q, A, O, I')$"}, {"title": "Experiment and Discussion", "content": null}, {"title": "Dataset", "content": "In this work, we use CyberQ (Agrawal et al. 2024c),\nan open-source cybersecurity dataset containing around\n4,000 open-ended questions and answers on topics such\nas cybersecurity concepts, tool usage, setup instructions,\nattack analysis, and defense techniques. The questions\nvary in complexity, answer length, and vocabulary. The\ndataset was developed using facts from AISecKG (Agrawal\n2023), a cybersecurity knowledge graph, and a three-step\nLLM prompting method. The Zero-shot (ZS) method gen-\nerated 1,027 QA pairs for simple WH-questions on cy-\nbersecurity entities. The Few-shot (FS) method produced\n332 medium-complexity QA pairs related to setup and\ntools. The Ontology-Driven approach generated 2,171 high-\ncomplexity QA pairs covering attack and defense scenar-\nios. The dataset includes 30 very short, 1,061 short, and\n2,439 long questions. These cybersecurity questions and an-\nswers are comprehensive, challenging, and not straightfor-\nward, making them ideal for our goal of developing an inter-\nactive QA system to teach cybersecurity to students."}, {"title": "Experiment and Parameter Settings", "content": "The knowledge base for our experiments is the CyberQ\ndataset (Agrawal et al. 2024c), and the cybersecurity knowl-\nedge graph ontology utilized in this work is AISecKG\n(Agrawal 2023). In future work, the knowledge base can\nbe expanded to include other PDF documents containing\ncybersecurity-related coursework material. For brevity, we\nwill refer to the CyberQ dataset as our KB and AISecKG as\nour ontology. We conduct the main experiments in two sce-\nnarios: within the knowledge base (In-KB) and outside the\nknowledge base (Out-of-KB). For the In-KB scenario, stu-\ndents' queries can be answered using existing documents in\nthe knowledge base, while the Out-of-KB scenario involves\nqueries for which relevant documents are not present in the\nknowledge base.\nWe consider BERTScore (Zhang et al. 2020), ME-\nTEOR (Banerjee and Lavie 2005), ROUGE-1 (Lin 2004),\nand ROUGE-2 (Lin 2004) as metrics to evaluate the perfor-\nmance of the generated response. It is important to note that\nthe ground truth answers in the CyberQ dataset are annotated\nby human cybersecurity experts. Unless otherwise specified,\neach experiment is run 10 times, with average scores and\nstandard deviations recorded.\nWe use the Contriever (Izacard et al. 2022) as the re-\ntriever for document retrieval, employing cosine similar-\nity as the semantic distance metric to identify and retrieve\nthe most relevant documents from the knowledge base. For\nthe generative language model, we utilize LLaMA3-8B-\nInstruct (Dubey et al. 2024), with an input text length of 256\nand max-length padding. During the answer generation pro-\ncess, the number of beams for beam search is set to 4. The\nontology-based validation model is formulated using an-\nother instance of LLaMA3-8B-Instruct (Dubey et al. 2024),\nwith an input text length of 512 and max-length padding.\nFor all other parameters not explicitly mentioned, default\nsettings are applied."}, {"title": "Research Questions", "content": "To assess our approach, we employ the following evaluation\nmethodology and begin by posing the following research\nquestions (RQs):\n\u2022 RQ1: How does the integration of a knowledge base en-\nhance the performance of the CyberRAG framework in\ngenerating accurate and relevant answers for both In-KB\nand Out-of-KB queries?\n\u2022 RQ2: What is the impact of the knowledge base and the\ngenerative language model on the overall performance of\nCyberRAG, and how does their ablation affect the sys-\ntem's ability to answer students' questions?\n\u2022 RQ3: How does the integration of a knowledge base in-\nfluence the quality and reliability of answers generated\nby the CyberRAG framework, and what are the key ben-\nefits observed from the retrieval process?\n\u2022 RQ4: How effective is the ontology-based validation\nmodel in ensuring the accuracy, relevance, and scope of\nanswers generated by CyberRAG. Can this validate and\nprevent potential misuse behaviors?"}, {"title": "Quantitative Results", "content": "To address RQ1, we design a comparative experiment. As\nshown in Table 1, @ CyberRAG consistently achieves good\nperformance across all datasets and scenarios. For instance,\nthe In-KB question-answering on the FS dataset gives a\nBertScore of 0.9461, a METEOR of 0.8588, a ROUGE-1 of\n0.7882, and a ROUGE-2 of 0.7195. These results demon-\nstrate that the answers generated by CyberRAG not only\nalign well with the semantic meaning of the ground truth\nbut also closely match in exact word terms.  Compared\nwith the Out-of-KB, the model shows relatively higher per-\nformance for In-KB questions. For example, in the ZS sub-\nset for In-KB questions, the model achieves a BERTScore\nof 0.9294, and for more complex questions in the OD sub-\nset, it reaches 0.9331. In contrast, for Out-of-KB questions,\nthe BERTScore is 0.8720 in ZS and 0.8783 for the OD sub-\nset. This indicates that the integration of the knowledge base\nprovides a solid reference for generating answers for open-\nended questions in cybersecurity, enhancing the model's per-\nformance across both simple and complex queries.. Cy-\nberRAG provides semantically meaningful and high-quality\nanswers for questions outside the knowledge base. For ex-\nample, in the OD dataset with the Out-of-KB settings, the\nBERTScore is 0.8783, while the METEOR, ROUGE-1, and\nROUGE-2 are 0.3912, 0.2587, and 0.1234, respectively.\nThis suggests that while the generated answers may not ex-\nactly match the ground truth in wording, they are highly\nsimilar to expert-certified answers in meaning. Further-\nmore, the results show a very low standard deviation (std) in\nboth In-KB and the Out-of-KB settings, with std values con-\nsistently below 0.0011. This demonstrates that CyberRAG\nis both stable and reliable in producing accurate answers.\nOverall, these findings suggest that our proposed method is\npromising for answering cybersecurity-related questions."}, {"title": "Ablation Study", "content": "We conducted an ablation study to investigate RQ2; we\nconsider two scenarios: (i) CyberRAG is built solely on a\nquestion-answering dataset, such as CyberQ, without utiliz-\ning the generative language model. In this case, the QA sys-\ntem is unable to answer questions beyond the scope of the\ntraining dataset, which is undesirable as it limits the breadth\nof cybersecurity education. (ii) CyberRAG without aug-\nmenting the knowledge base. In this case, the model essen-\ntially reverts to functioning as a generative language model,\nanswering questions in a zero-shot manner. As shown in\nFig. 1, the results under zero-shot settings are considerably\ninferior. Compared to the In-KB scenarios, the model un-\nder zero-shot setting lacks access to the ground truth infor-\nmation for reference, leading to significant drop in perfor-\nmances. When comparing the zero-shot results with Out-of-\nKB scenarios, the latter demonstrates a better performance.\nThis is because, although Out-of-kb can not be answered\ndirectly using documents from the knowledge base, these\ndocuments still provide relevant and supplementary infor-\nmation that may help in formulating the answers. In conclu-\nsion, both the knowledge base and the generative language\nmodel play significant roles in enhancing the performance\nof a QA systems in cybersecurity education."}, {"title": "Retrieval Analysis", "content": "To research RQ3, we design a retrieval analysis. First, we\nacquire the documents retrieved from the knowledge base\nand then compare the response produced by CyberRAG with\nthe ground truth to explore how CyberRAG benefits from\nthe retrieval augmentation process. We consider the Faith-\nfulness, Answer Relevancy, Context Precision, Context Re-\ncall, and Context Entity Recall as metrics and use the RA-\nGAS (ES et al. 2024) package to evaluate our method."}, {"title": "Answer Validation Analysis with Case Study", "content": "We designed an answer validation analysis to explore RQ4.\nWe simulate a case-study with an out-of-domain query, such\nas, \"How to make money in the stock market?\" a query that\ncan be considered an unintended or misused case. As shown\nin Fig. 2, although the generative language model produces\nthe corresponding answer, it is filtered out by the validation\nmodel because it fails to adhere to cybersecurity knowledge\ngraph ontology. Conversely, when a relevant cybersecurity\nquestion is posed, it smoothly passes the validation test,\nhighlighting the critical role the ontology-based validation\nmodel in ensuring accuracy and preventing potential misuse.\nFig. 2 illustrates the data flow in the case study, demonstrat-\ning the transparency and reliability of CyberRAG."}, {"title": "Conclusion", "content": "The rapid advancement of AI is transforming education,\nparticularly in technical fields like cybersecurity. AI-driven\nQA systems enhance cognitive engagement by manag-\ning uncertainty in problem-based learning. Our proposed\nCyberRAG introduces a novel, ontology-aware retrieval-\naugmented generation approach to create a reliable QA\nsystem for cybersecurity education. By leveraging domain\nknowledge and an ontology-based validation model, Cyber-\nRAG ensures relevance, accuracy, and safety of responses.\nComprehensive experiments demonstrate its dependability\nin real-world scenarios, fostering a more interactive and se-\ncure learning environment. This research highlights the po-\ntential of AI to transform educational practices, not only in\ncybersecurity but across various subjects. As AI in education\nevolves, future research will explore innovative methods like\nvirtual environments to further enhance students' practical\nexperiences using LLM agents."}]}