{"title": "Self-Directed Turing Test for Large Language Models", "authors": ["Weiqi Wu", "Hongqiu Wu", "Hai Zhao"], "abstract": "The Turing test examines whether Als can exhibit human-like behaviour in natural language conversations. Traditional Turing tests adopt a rigid dialogue format where each participant sends only one message each time and require continuous human involvement to direct the entire interaction with the test subject. This fails to reflect a natural conversational style and hinders the evaluation of Large Language Models (LLMs) in complex and prolonged dialogues. This paper proposes the Self-Directed Turing Test, which extends the original test with a burst dialogue format, allowing more dynamic exchanges by multiple consecutive messages. It further efficiently reduces human workload by having the LLM self-direct the majority of the test process, iteratively generating dialogues that simulate its interaction with humans. With the pseudo-dialogue history, the model then engages in a shorter dialogue with a human, which is paired with a human-human conversation on the same topic to be judged using questionnaires. We introduce the X-Turn Pass-Rate metric to assess the human likeness of LLMs across varying durations. While LLMs like GPT-4 initially perform well, achieving pass rates of 51.9% and 38.9% during 3 turns and 10 turns of dialogues respectively, their performance drops as the dialogue progresses, which underscores the difficulty in maintaining consistency in the long term.", "sections": [{"title": "1 Introduction", "content": "The Turing Test, originally called the imitation game by Alan Turing in 1950, is a test of whether a machine can behave indistinguishably from a human (Turing, 1950). During the test, a human integrator converses in natural language with both a human and an AI, then tries to identify which is which. The AI is considered to pass the test if it can convincingly mimic human responses so that the integrator misidentifies it as a human participant. Contemporary Large Language Models (LLMs) demonstrate remarkable language generation capabilities in various scenarios (Wu et al., 2024a). These advancements have sparked increasing interest in whether the latest LLMs can pass the Turing test (Jones and Bergen, 2024).\nHowever, the traditional Turing test has several limitations: (1) The dialogue follows a strict ping-pong structure, unlike natural communication where people may send multiple messages in a row. (2) The need for continuous human involvement in interactions with the test subject limits test duration to under ten minutes, leaving LLM performance in prolonged interactions unexplored. (3) Measuring test duration in minutes ignores individual differences in reading, thinking, and typing speeds, potentially disadvantaging some participants.\nTo address these issues, we propose Self-Directed Turing Test, a new framework designed to conduct an efficient Turing test for LLMs with an extended dialogue format that aligns more closely with daily communication among humans. Firstly, we break the constraint of single message each turn to allow users to send multiple messages in rapid succession without waiting for a response, and the response may also consist of multiple messages. As illustrated in Figure 1, this dynamic exchange holds a mirror up to natural text-based human communication, challenging LLMs to maintain coherence and relevance in more diverse interactions. We construct chatbots for the test by prompting LLMs with dialogue history from a real-life human.\nGiven the exhausting nature of long Turing tests, we propose enhancing efficiency by approximating real human-machine interactions through automated dialogue generation techniques (Soudani et al., 2024), and using questionnaires instead of having evaluators engage in extended conversa-"}, {"title": "2 Related Work", "content": "Turing Test Turing test and its variations have been extensively applied to assess AI in exhibiting human-like abilities across multiple domains, including dialogue interaction (Jones and Bergen, 2024; Lowe et al., 2017), question answering(Ng et al., 2024), text generation (Helm et al., 2023; Uchendu et al., 2021), and visual tasks (Zhang et al., 2022; Geman et al., 2014). These evaluations, which involve distinguishing between human-generated and AI-generated content (Gao and Emami, 2023) or inferring from solely the content (Jannai et al., 2023), serve as essential benchmarks for AI models. Existing works proposing the limitations of Turing tests focus on whether passing the test indicates intelligence accurately (Freitas et al., 2020) or comprehensively (Lee et al.,"}, {"title": "Role-play with LLMS", "content": "A common tactic in Turing tests is to assign LLMs the role of a specific human character (Jannai et al., 2023), leveraging their proficiency in adopting varied attributes and conversational styles (Wu et al., 2024b; Shanahan et al., 2023; Wang et al., 2023a). Prompting the model with character profiles (Li et al., 2023; Tao et al., 2023; Wang et al., 2023b; Chen et al., 2023c) or key utterances (Han et al., 2022; Boyd et al., 2020) proves to be a more efficient method, compared with fine-tuning on massive character data (Shao et al., 2023; Zhou et al., 2023; Lu et al., 2024). By utilizing the dialogue history of the designated individual, we can develop a role-playing chatbot that effectively handles various dialogue forms and scenarios."}, {"title": "Dialogue Generation", "content": "The development of synthetic dialogue data has provided a more efficient and scalable approach to data creation and augmentation (Soudani et al., 2024; Chen et al., 2024; Zhou et al., 2017). Advancements in dialogue generation have been facilitated by LLMs (Abdullin et al., 2024; Chen et al., 2023b,a; Kim et al., 2022a; Abbasiantaeb et al., 2023), which excel at creating contextually relevant and diverse conversations by prompted turn-by-turn (Lee et al., 2022; Kim et al., 2022b) or even in just one go (Jandaghi et al., 2023; Chen et al., 2023a). By iteratively generating dialogues that imitate interactions with a human, we can efficiently simulate the Turing test over extensive turns and facilitate further judgment."}, {"title": "3 Self-Directed Turing Test", "content": ""}, {"title": "3.1 Burst Dialogue v.s. Ping-pong Dialogue", "content": "Conversations with a ping-pong structure are considered the standard form of human-machine interaction and are commonly used in the Turing Test, where each user message is followed by a system response to form a strict back-and-forth pattern. However, in real life, people usually send multiple messages in rapid succession without waiting for the other's response and the response can also consist of multiple messages. We define this communication pattern as Burst Dialogue and delve into the performance of LLMs in this communication setting.\nIn ping-pong dialogue, a turn is naturally formed by pairing each user message with the corresponding system response. In contrast, burst dialogue involves a more flexible information exchange, where interruption and continuation can happen frequently for both sides. For simplicity, a turn of burst dialogue is defined as a consecutive series of user messages followed by the system's responses before the next user message. Despite potential unbalanced exchange, burst dialogue is more dynamic and aligns more closely with the natural human communication pattern. It challenges the LLM to handle overlapping and rapidly evolving conversational contexts, thereby testing its ability to maintain coherence and relevance in real-time interactions. Hence, we extend the classical ping-pong dialogue setting to assess the capability of LLMs to manage more complex and realistic conversational dynamics."}, {"title": "3.2 Chatbot Construction", "content": "The Turing test necessitates the deployment of an LLM as a chatbot to judge its text-based conversation ability. Instead of manually crafting detailed profiles for individuals, we construct the chatbot based on real-life dialogue history, which provides essential clues for generating responses that emulate the target personality, linguistic style and content. To achieve this, we gather multi-turn text-based social platform chat records for each target individual, which are burst conversational data consisting of timestamps and message content. The LLM is then instructed to maintain consistency with the conversation style. For ping-pong dialogues, we retain only the first message of a consecutive series from the same person and manually filter out meaningless turns.\nTo implement a burst messaging system, we employ three modules working synchronously as shown in Figure 2: \u2022 Input Listener: to collect user messages; \u2022 Model Caller: to query the LLM to generate responses; \u2022 Output Sender: to manage the delivery of system responses based on the timestamps. The system introduces a brief time interval t1 before processing the first batch of user inputs to allow the user to fully express themselves. After t1, Input Listener processes all user messages collectively for Model Caller to generate a response. Following the given burst dialogue data and the in-"}, {"title": "3.3 Pseudo-Dialogue Generation", "content": "To enhance the efficiency of the Turing test, we propose to let the LLMs direct the progression of the test by synthesizing extended user-machine interaction through dialogue generation. Classical open-domain conversational data generation generally includes three steps: (1) Input generation: Provide fundamental information to initiate the conversation that specifies the topic and personalized style, i.e., conversation seed; (2) Utterance generation: Utilize the conversation seed to generate a multi-turn conversation; (3) Quality filtering: Eliminate samples fail to meet the quality criteria (Soudani et al., 2024). The quality filtering step is omitted as our dialogue generation process aims to reflect the genuine evolving performance of the LLM over prolonged interaction.\nTo generate N = mn turns of pseudo-dialogue, we first utilize the LLM to produce n distinct topics T = {t1, t2,...,tn}. Based on the dialogue history H of the target individual, we iteratively prompt the LLM to generate a m-turn dialogue between the individual and another human for each topic. If a dialogue does not have enough turns, we continue generating dialogue for the current topic until the requirement is met. If the dialogue exceeds m turns, the excess turns are truncated. The generated dialogue is appended to the dialogue history H for subsequent iteration, as detailed in Algorithm 1. The prompts used to generate topics and pseudo-dialogue are demonstrated in B.3.\nThe N-turn pseudo-dialogues are incorporated into the prompt of the chatbot, which then interacts with a human for an additional m turns to evaluate the performance of LLMs over (N + m) turns of interaction by judging the last m-turn dialogue. Without loss of generality, we set m to 10."}, {"title": "Algorithm 1 Pseudo-Dialogue Generation", "content": "Require: Number of Turns m, Dialogue History\nH, Topics T = {t1, t2,...,tn}\nEnsure: Pseudo-Dialogue D\n1: D \u2190 {}\n2: for each ti \u2208 T do\n3: pd \u2190 {}\n4: while len(pd) < m do\n5: pd \u2190 pdULLM(ti, m, H)\n6: if len(pd) > m then\n7: pd - pd[:m]\n8: end if\n9: end while\n10: D\u2190 DUpd\n11: H \u2190 concat(H, str(pd))\n12: end for\n13: return D"}, {"title": "4 Experiments", "content": ""}, {"title": "4.1 Test Setup", "content": "We provide 100 turns of dialogue history in the context and evaluate the capabilities of GPT-4, Claude-3-Sonnet and Qwen-110B to respond like a human in real-life conversation across 25 topics including education, technology, art and more. These topics are carefully selected to cover a broad range of scenarios where conversational AI can be applied while avoiding appearing in the dialogue history. We split 10 topics for ping-pong dialogue and 15 for burst dialogue.\nHuman Judges In total, 236 native speakers participate in our survey as volunteered human judges. These judges are recruited from diverse backgrounds to ensure a wide range of perspectives, tasked with evaluating pairs of conversations and distinguishing the human-human conversation from the human-machine one.\nLLM Judges Exploring whether LLM can distinguish between humans and itself can also provide insights into its understanding of social interactions among humans. We select GPT-4 and Qwen-110B to serve as LLM judges. To mitigate the effects of position bias (Zheng et al., 2023), we randomly assign the positions of the interaction pieces during the evaluation."}, {"title": "4.2 Metric: X-Turn Pass Rate", "content": "In the evolving landscape of human-AI interaction, the ability of an LLM to sustain human-like conversation over an arbitrary number of turns can be more revealing when assessing its human likeness. Thus, we propose the X-turn Pass Rate metric to evaluate the possibility that the model can pass the Turing test within specified turns of dialogue. To compute the metric over N pairs of X-turn dialogues, we ask K judges (with K = 1 for each LLM judge) to differentiate between each pair, comprising a human-human and a human-machine conversation. We record the number of judges who accurately identify the human-machine conversation in each pair as C = {C1, C2, ..., CN}, where Ci represents the count for the i-th pair. The pass rate for the model in X turns is then calculated by:\nPass Rate =1-  \u2211 Ci / K"}, {"title": "4.3 Results", "content": "Table 1 shows the pass rates under different dialogue settings and judges. The 110-turn Turing test is conducted with a sequence of 100-turn pseudo-dialogue generation followed by a 10-turn interaction between human and machine. The results highlight a significant influence of dialogue length on model performance. According to the human judges, GPT-4 maintains a consistently higher average pass rate across all tested turns compared with other models, achieving the best average 3-turn pass rate of 51.9%. However, as the dialogue progresses, the average word count per message has significantly increased and both models generally exhibited a significant decrease in their pass rates, showcasing the necessity of long Turing tests.\nGap Between Human and LLM Judgment As the number of testing turns increases, all judges become increasingly adept at distinguishing between LLM and human interlocutors, resulting in a decreasing pass rate with an increased number of turns. However, the disparity between human and AI evaluation is evident. Human judges generally perceive GPT-4 and Claude-3-Sonnet as more human-like in conversations, whereas both LLMs tend to prefer Qwen-110B. Moreover, when presented with identical dialogues, human judges are generally more accurate in differentiating between LLM and human, contributing to a lower pass rate. This gap highlights the insufficiency of models in understanding and simulating real-world communications. Consequently, analysis in subsequent sections will primarily rely on assessments from human judges.\nComparison Between Dialogue Settings Comparing the extended burst dialogue setting with the classical ping-pong setting reveals notable differences. Although characterized by more complex information exchanges, all models better mimic human messaging habits in the number of words per message under the burst setting. However, performance variations exist between the two formats, with Claude-3-Sonnet and Qwen-110B excelling in burst dialogues, while GPT-4 performs better in ping-pong dialogues. Therefore, as a natural form of textual communication in human life, challenges presented by burst dialogue are also worthy of attention."}, {"title": "5 Discussion", "content": "In this section, we investigate other significant factors that have an impact on the Self-Directed Turing Test framework and ultimate evaluation results."}, {"title": "5.1 Dialogue History Quantity", "content": "A pivotal consideration of having LLM play a specific role in giving utterances is determining the necessary amount of utterances. To explore this, we analyze how the quantity of dialogue history provided for the model affects the pass rates of the Turing test, as presented in Table 2. Generally, providing more dialogue history enables models to better simulate human conversational styles, thereby increasing their pass rate. This effect is particularly pronounced in burst dialogue, where additional dialogue examples are markedly effective. However, the benefit of increasing given dialogue diminishes once a certain threshold is surpassed. Moreover, the consistency of the dialogue style plays a crucial role. Redundant or low-quality data can lead to"}, {"title": "5.2 Topic Analysis", "content": "Considering the varying amounts and qualities of data in the pretraining corpora for different topics, the capacity of models to generate contextually appropriate responses could be different. It is necessary to investigate the impact of topics on the test while ensuring a comprehensive and balanced distribution. As shown in Figure 6, there is an evident disparity in how different models perform on distinct topics at shorter dialogue duration (3-turn and 10-turn). For instance, GPT-4 excels in Technology, while Claude-3-Sonnet shows a higher aptitude in School-related topics and Qwen-110B has a relative strength in Climate discussions. However, a common challenge among all three models is observed in the Art category, suggesting that the creative and interpretive nature of artistic discussions presents a difficulty for LLMs in achieving human-level conversation. However, as dialogue lengthens to 100 turns, the overall average performance declines and the ability to sustain consistent"}, {"title": "5.3 Participant Distribution", "content": "Focusing on the 10-turn Turing test, we analyze how participant distribution impacts the evaluation. Figure 4 provides a comprehensive overview of participant demographics and their corresponding accuracy in the Turing Test: (1) Age Impact: The age group distribution reveals varied levels of accuracy in distinguishing AI from human participants, with the age groups 18-24 and 25-30 achieving the highest accuracy rates. It highlights the influence of age on technological adaptability and cognitive acuity. (2) Educational Influence: There is a noticeable trend where participants with higher educational levels exhibit higher accuracy rates. This suggests that educational background may play a crucial role in understanding and interacting with AI, possibly due to better critical thinking skills and familiarity with technology. (3) AI Usage and Knowledge: Both groups of participants can distinguish between human and AI responses with moderate accuracy, even those who claim to have no experience with AI. As anticipated, participants who report previous AI usage or knowledge demonstrate higher accuracy."}, {"title": "6 Case Study", "content": ""}, {"title": "6.1 Pseudo-Dialogue Samples", "content": "We examine the capabilities of LLMs in maintaining consistency and naturalness in generating pseudo-dialogues, using GPT-4 and Qwen-110B as examples. This assessment reflects the expected quality of subsequent human-machine interactions. As presented in Figure 5, GPT-4 exhibits robustness in long dialogues, showing minimal degradation in the quality of language style imitation in its responses. Nonetheless, the model displays a reduced initiative in engaging with topics, with responses predominantly echoing agreement rather than fostering deep discussions. While for Qwen-110B, there is a noticeable shift in its conversational style by the 100th turn, marked by increasingly verbose replies and unconventional emoticon use, diverging from typical human conversational patterns. The comparative analysis emphasizes GPT-4's enhanced ability to preserve human-like qualities over prolonged interactions compared to Qwen-110B, despite still failing to deceive humans effectively."}, {"title": "6.2 Interaction Samples", "content": "Figure 7 highlights the differences between AI and human responses at the first and 101st turn (after 100 pseudo-dialogue turns) in two distinct dialogue settings. In both dialogue types, the LLMs initially mirror human conversational tactics effectively, utilizing informal slang and abbreviations, and maintaining brevity. However, as the conversations progress to the 101st turn, notable discrepancies begin to appear. Notably, in the Ping-Pong dialogue format, Qwen begins to produce overly lengthy responses, a deviation from the concise exchanges typically observed in natural human interactions. This extended message length makes the conversation feel less natural and more mechanical, as reported by most of the judges. Moreover, while the use of emoticons by LLMs aims to enhance"}, {"title": "7 Conclusion", "content": "In summary, our study introduces the Self-Directed Turing Test framework, designed to effectively and efficiently evaluate the human likeness of LLMs through pseudo-dialogue generation with extended dialogue settings. With the definition of the X-Turn Pass-Rate metric, our experiments reveal that GPT-4 outperforms other tested models across most configurations and evaluation criteria, achieving an averaged 51.9% and 38.9% pass rate in 3-turn and 10-turn dialogue respectively. However, as dialogue length increases through iteratively generating dialogues that approximate human-machine interactions, the pass rates for all models significantly drop. Moreover, burst dialogue presents a greater challenge in maintaining consistency and human-like responses. Our analysis highlights the critical influence of dialogue duration and complexity on LLM's performance in Turing tests and suggests directions for refining evaluation methods to enhance efficiency and reliability."}, {"title": "Limitations", "content": "While our study presents an innovative approach to efficiently evaluating LLMs using the extended Turing test framework, the following limitations must be acknowledged: (1) Responses from LLMS are inherently influenced by user inputs and previous LLM-generated dialogue quality. Hence, using static evaluation techniques like questionnaires instead of real-time communication cannot eliminate the impact of the preferences of users participating in the conversation, which forms a trade-off between efficiency and accuracy. (2) Although we considered various participant factors such as age, educational background, and familiarity with AI, the subjective nature of human judgment in evaluating Al responses can lead to inconsistencies, which is an intrinsic characteristic of the Turing test."}, {"title": "Ethics Statement", "content": "Our research involves collecting dialogue data and questionnaires from real human participants, and as such, we adhere to stringent ethical guidelines to ensure the privacy, consent, and well-being of all participants involved. Key ethical considerations include: (1) Informed Consent: All participants are provided with detailed information about the study's purpose, procedures, and their rights. They can withdraw from the study at any time without any consequences. (2) Data Anonymization: To protect the privacy of participants, all collected dialogue data and questionnaires are anonymized. Personal identifiers are removed to ensure that individual participants cannot be traced from the data. (3) Data Security: Collected data and information is stored securely and access is restricted to authorized personnel only. We employ robust data protection measures to prevent unauthorized access, disclosure, or misuse of the data."}, {"title": "Appendix", "content": ""}, {"title": "A Questionnaire Demonstration", "content": "Each questionnaire consists of 11 questions: five are designed to collect anonymous personal information, five pertain to the Turing test, and one asks respondents to explain their strategies for distinguishing between human and AI during the test. For questions related to the Turing test, an example is provided in Table 3. The response of User B, which are the focus of comparison, are highlighted in the questionnaire system for clarity."}, {"title": "B Prompt Demonstration", "content": ""}, {"title": "B.1 Chatbot Construction", "content": "Table 4-5 present the prompts used to construct the chatbot under different dialogue settings. The dialogue history will be released after being accepted."}, {"title": "B.2 Topic Generation", "content": "Before generating pseudo-dialogue, we generate 10 topics using GPT-4, Qwen-110B and Claude-3-Sonnet with the prompt \"Generate 10 diverse topics for daily conversations without repetition.\".\nThe topics generated by GPT-4 are:\n\u2022 Travel Experiences: Share your travel experiences and discuss future travel plans.\n\u2022 Culinary Exploration: Talk about recent new dishes or restaurants you've tried, and recommend your favourites.\n\u2022 Movies: Discuss the latest movies you've seen and share your impressions.\n\u2022 Book Recommendations: Share the books you've recently read and discuss your reading list.\n\u2022 Health and Fitness: Talk about your health habits and how to maintain vitality and wellness.\n\u2022 Technology Trends: Exchange insights on emerging technologies, such as smart homes and AI technologies.\n\u2022 Learning Experiences: Share insights from your course studies and discuss effective learning techniques.\n\u2022 Music and Arts: Talk about your favorite music genres, musicians, or singers.\n\u2022 Cultural Differences: Discuss the different cultures you have experienced and how to understand and adapt to these cultural differences.\n\u2022 Future Plans: Discuss your short-term or long-term career goals and life plans.\nThe topics generated by Qwen-110B are:\n\u2022 Weather Changes: Discuss how to adjust your clothing or activity plans in current season.\n\u2022 Culinary Sharing: Introduce special dishes or restaurants, discuss the taste of food, the environment, and unique dining experiences.\n\u2022 Movie Recommendations: Evaluate the plot, performances of actors, or the director's style of recently watched movies.\n\u2022 Travel Stories: Narrate interesting stories from your travels, experiences of cultural differences, or scenic spots, and explore the meaning and gains of traveling.\n\u2022 Pet Anecdotes: Share the cute behaviors, habits of your pets, or warm interactions with them, reflecting deep pet-human relationships.\n\u2022 Work/Study Pressure: Exchange methods for coping with stress, such as time management skills, relaxation activities, or psychological adjustment strategies.\n\u2022 Healthy Living: Discuss the importance of a healthy diet and regular exercise, share wellness tips or personal fitness plans.\n\u2022 Musical Taste: Explore how different music styles affect emotions and recommend newly discovered artists or songs.\n\u2022 Technology Insights: Introduce the latest technological products and discuss how these innovations impact daily life or future prospects.\n\u2022 Weekend Plans: Share your weekend plan and best ways to spend the leisure time.\nThe topics generated by Claude-3-Sonnet are:\n\u2022 Recent Activities: Updates on recent happenings and interesting events."}, {"title": "B.3 Pseudo-Dialogue Generation", "content": "For each of the previously generated topics, we generate the corresponding pseudo-dialogue using the prompt in Table 6-7."}, {"title": "B.4 LLMs as Judge", "content": "We use the prompt in Table 8 to employ LLMs as Turing test judges."}]}