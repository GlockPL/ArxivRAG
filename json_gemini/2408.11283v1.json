{"title": "Inference Plans for Hybrid Particle Filtering", "authors": ["ELLIE Y. CHENG", "ERIC ATKINSON", "GUILLAUME BAUDART", "LOUIS MANDEL", "MICHAEL CARBIN"], "abstract": "Advanced probabilistic programming languages (PPLs) use hybrid inference systems to combine symbolic exact inference and Monte Carlo methods to improve inference performance. These systems use heuristics to partition random variables within the program into variables that are encoded symbolically and variables that are encoded with sampled values, and the heuristics are not necessarily aligned with the performance evaluation metrics used by the developer. In this work, we present inference plans, a programming interface that enables developers to control the partitioning of random variables during hybrid particle filtering. We further present SIREN, a new PPL that enables developers to use annotations to specify inference plans the inference system must implement. To assist developers with statically reasoning about whether an inference plan can be implemented, we present an abstract-interpretation-based static analysis for SIREN for determining inference plan satisfiability. We prove the analysis is sound with respect to SIREN's semantics. Our evaluation applies inference plans to three different hybrid particle filtering algorithms on a suite of benchmarks and shows that the control provided by inference plans enables speed ups of 1.76x on average and up to 206x to reach target accuracy, compared to the inference plans implemented by default heuristics; the results also show that inference plans improve accuracy by 1.83x on average and up to 595x with less or equal runtime, compared to the default inference plans. We further show that the static analysis is precise in practice, identifying all satisfiable inference plans in 27 out of the 33 benchmark-algorithm combinations.", "sections": [{"title": "1 INTRODUCTION", "content": "Probabilistic programming languages (PPLs) support primitives for modeling random variables and performing probabilistic inference [Goodman and Stuhlm\u00fcller 2014; Holtzen et al. 2020; Murray and Sch\u00f6n 2018; Narayanan et al. 2016; Tolpin et al. 2016]. They provide high-level abstractions for probabilistic modeling that hide away the complex details of inference algorithms while leveraging common programming language constructs such as functions, loops, and control flow. PPLs serve as an expressive and accessible tool for solving such problems. Users can focus on modeling the problem, rather than the details of inference techniques.\nHybrid Inference Systems. Hybrid inference systems \u2013 such as delayed sampling [Lund\u00e9n 2017; Murray et al. 2018], semi-symbolic inference [Atkinson et al. 2022], Sequential Monte Carlo with belief propagation [Azizian et al. 2023], and automatically marginalized MCMC [Lai et al. 2023] \u2013 automatically incorporate exact inference with Monte Carlo methods to improve performance. They utilize a symbolic encoding of random variables to represent some or all parts of the model, enabling symbolic computation that lowers the variance of estimations. Hybrid inference algorithms that apply to particle filters [Gordon et al. 1993] implement an automatic Rao-Blackwellization of the particle filter [Doucet et al. 2000]; hybrid inference algorithms that apply to MCMC algorithms automatically implement collapsed sampling [Liu 1994]. In this work, we focus on hybrid inference systems that perform symbolic computations dynamically at runtime. These systems are able to take advantage of exact inference opportunities that only become available once the inference system replaces some variables with concrete Monte Carlo samples."}, {"title": "2 EXAMPLE", "content": "To demonstrate how a developer can use inference plans to customize and improve inference perfor- mance, we present a simplified example adapted from Bilik and Tabrikian [2010]. Figure 2 shows a cartoon diagram of a radar tracker. The goal of the radar tracker is to track the movement of an aircraft by estimating the position and altitude of the aircraft as it moves over time. The radar tracker can be specified as a probabilistic model. The model captures both the aircraft's movement noise and also the radar's mea- surement noise. The movement noise captures the uncertainty in the model's belief of the aircraft move- ment relative to its previous position due to external"}, {"title": "2.1 Specification in S\u0131reN", "content": "Figure 3 presents two versions of the SIREN program that implements the radar tracker. The programs share the same probabilistic model, but differ in the annotations used to specify random variable encodings. Each program models the movement noise q and white noise r defined on Lines 10 and 11 with Inverse-Gamma distributions. The step function defined on Lines 1-9 updates the predicted position and altitude and conditions the model on radar measurement data.\nOn Lines 3 and 4, the x positions and alt altitudes are modeled as Gaussian random walks, i.e. as Gaussian distributions with a mean equal to the respective previous value. They have variance equal to q. Lines 5 and 6 model the measurement noise v. If the current estimated altitude alt is less than 5, the program models the measurement noise as r+other; the variable other models the additional spiking noise as a separate, time-varying Inverse-Gamma distribution. Otherwise, the program models the measurement noise as only the white noise r. The measured position and altitude are modeled as Gaussian distribution centered around the estimated position x and estimated altitude alt, respectively, and with the measurement noise as variance.\nLines 7 and 8 condition the model on the measured position being equal to the data value x_o and on the measured altitude being equal to a_o. The fold_resample operation on Line 12 iterates step on the measurement data (provided by program inputs stored in variable data) with initial position 0, altitude 10, and the noises q and r. The program returns the final accumulator: the list of estimated positions, estimated altitudes, the movement noise, and the white noise."}, {"title": "2.2 Inference Plans", "content": "Each random variable in Figure 3 has an optional distribution encoding annotation that specifies how the inference system should encode the variable. The inference system should encode a variable annotated with symbolic as a symbolic expression representing the corresponding distribution, and should encode one annotated with sample with a concrete sample drawn from the distribution.\nThe two programs in Figure 3 differ in only the annotations on Lines 3 and 11.\nThe annotations control the execution of SIREN's hybrid particle filtering implementation \u2013 a combination of particle filtering with symbolic computation. Each particle contains a symbolic"}, {"title": "2.2.1 Accuracy and Performance", "content": "To deploy the radar tracker, the developer must ensure that it will achieve adequate performance. In this aircraft tracking application, the program must be within the acceptable margins of error and allowable latency or it can lead to catastrophic collisions [Ali et al. 2015]. This is challenging because the accuracy and runtime of hybrid particle filtering depend on both the number of particles and the inference plan used to perform inference.\nParticle Count. While the runtime of a particle filter typically varies proportionally to the particle count, the relationship between accuracy and particle count is difficult to determine. In general, developers need to search for a particle count that meets their accuracy and runtime constraints.\nInference Plan. A hybrid inference system's accuracy and runtime also depend on the inference plan. This enables developers to use inference plans to control the inference system's performance and improve upon the system's default performance (i.e. its accuracy and runtime under the default inference plan automatically selected by the system when no annotations are present in the program). However, as inference plans operate by adjusting the partition between symbolic and sampled variables, the effect on accuracy and runtime is often hard to predict. Keeping variables symbolic can reduce the number of particles the system requires to achieve adequate accuracy, but this behavior is not guaranteed. Additionally, different inference plans can achieve higher accuracy for different variables. In an application such as radar tracking where highly accurate results are required within a time constraint, the developer can determine the program's behavior by executing it with different inference plans to build a performance profile. The developer can then choose the best inference plan and particle count to use in production."}, {"title": "2.2.2 Unsatisfiable Annotations", "content": "According to the performance profiles, the developer may select either the Symbolic x Plan of Figure 3a with 8 particles or the Symbolic r Plan of Figure 3b with 16 particles as the configuration to deploy in production with acceptable accuracy and latency. However, this profile also demonstrates the challenges in drawing conclusions from empirical data: The Symbolic r Plan is unsatisfiable in general.\nTo collect the performance profile, we generated the data for the performance profile assuming the aircraft stays at its cruising altitude of 10. If we instead generate data to model a descent where the aircraft eventually descends to an altitude below 5, the input altitude data passed to the variable a_o on Line 1 will be different. Then, the performance profile may no longer be valid. Namely, with the original generated cruising data, the estimated altitude was never less than 5. However, with the generated descent data, the probability of the estimated altitude being less than 5 is significantly higher and, as a result, so is the probability of encountering an unsatisfiable annotation. The symbolic annotation on r is unsatisfiable in those executions because the inference runtime cannot evaluate the program while encoding r symbolically.\nIn Figure 3b, if the altitude of the aircraft is at or above 5, then the observed variables on Lines 7 and 8 have symbolic Gaussian distributions with variance X_r. The Inverse-Gamma distribution of X_r is conjugate with the Gaussian distribution, which means that the inference system can find a closed-form solution to the model and can encode r symbolically. However, if the altitude of the aircraft drops below 5, the program specifies that the observed variables have symbolic Gaussian distributions with variance equal to the sum of two Inverse-Gamma random variables: r and other. This sum does not have an Inverse-Gamma distribution and is not conjugate with the Gaussian distributions on Lines 7 and 8. Without a conjugacy relationship to exploit, the inference system cannot solve the model analytically, even though the developer annotated variable r as symbolic."}, {"title": "Dynamic Encoding Cast", "content": "In such a sce- nario, Siren, like other hybrid inference systems [Atkinson et al. 2022; Azizian et al. 2023; Lund\u00e9n 2017; Murray et al. 2018], will, conceptually, dynamically cast the offend- ing symbolic annotation to a sample annota- tion, changing the underlying distribution encoding to a concrete sample. However, Figure 5 illustrates the impact of such a co- ercion. Figure 5 shows the accuracy of the position and altitude of a simulated aircraft over 100 timesteps using the two programs in the two different flight modes. In Fig- ure 5a, where the aircraft is cruising at alti- tude 10, the pattern observed in the perfor- mance profiles is replicated. The Symbolic x Plan consistently achieves better accu- racy for the x position, and the Symbolic r Plan for alt. In either case, both plans have errors less than 1 for both variables at all timesteps. However, when the aircraft is descending, this pattern is broken. In Fig- ure 5b, the aircraft is now operating in a noisier environment. The accuracy and runtime of a probabilistic model inherently depend on the conditioned inputs, so both plans experience an error spike in alt. The Symbolic x Plan still maintains a relatively low error for x, whereas the Symbolic r Plan has a significant error spike at around 60 timesteps such that the estimation error of x is a magnitude larger than before. This error spike cannot be explained by the noisier environment alone, because the Symbolic x Plan does not exhibit a similar x error spike. The accuracy degradation in x by the Symbolic r Plan is due to a dynamic encoding cast on an unsatisfiable annotation."}, {"title": "Performance Degradation", "content": "A dynamic encoding cast has implications for inference performance, as it means that the runtime cannot implement the annotated inference plan and has to implement a different inference plan to continue execution. While flexible and enables the program execution to continue, it can cause imprecision that is unacceptable in certain applications. In this example, casting the unsatisfiable annotation causes a significant decrease in accuracy in x. The significant accuracy degradation negates the advantage the Symbolic r Plan has over the Symbolic x Plan for alt. Given the possible impact on accuracy, the developer should use the Symbolic x Plan instead."}, {"title": "2.3 Inference Plan Satisfiability Analysis", "content": "To enable developers to ensure their program is free from dynamic encoding casts, SIREN performs the inference plan satisfiability analysis to determine whether the annotated inference plan is satisfiable during all possible executions of the program using the hybrid inference algorithm.\nAbstract Interpretation. The analysis uses an abstract interpretation of the program. It main- tains abstract symbolic distributions of random variables and uses abstract expressions to over- approximate program executions. Consider the unsatisfiable plan from Figure 3b. On Line 6, because the analysis does not know the exact value of alt, it uses an abstract value to over-approximate the subexpressions in the branches. If alt is above 5, the abstract subexpression is X_r, referring to"}, {"title": "3 LANGUAGE SYNTAX AND SEMANTICS", "content": "We present the syntax and semantics of the first-order functional PPL, SIREN, adapted from Staton [2017]. We have extended the language to support distribution encoding annotations and adapted it to use hybrid inference, and specify its semantics via the hybrid inference interface."}, {"title": "3.1 Syntax", "content": "Figure 6 presents the syntax of Siren. An ex- pression e is a value v (constant; variable; pair; or the application of an operator, e.g., arithmetic operation, distribution, or list), a function appli- cation, a conditional, or a local definition. We add the classic fold operator as well. SIREN supports probabilistic operators. The expression let x \u2190 op(v) in e introduces a new local random variable x with distribution op(v) to be used in e. Option- ally, a symbolic or sample annotation adorns a random variable declaration. The observe (v1, v2) expression conditions the model on a variable with distribution v\u2081 having value v2. The resample"}, {"title": "3.2 Operational Semantics", "content": "While SIREN has an ideal measure-based semantics (see Appendix A), the measure is, in general, intractable. An alternative is to interpret the model as a weighted sampler that returns a value and a score measuring the likelihood of the result with respect to the model. To approximate the posterior distribution, a weighted sampler launches a set of independent executions of the sampler, the particles, and returns a categorical distribution that associates each value with its score. SIREN implements a particle filter which occasionally resamples the set of particles according to their score during executions. Following [Lund\u00e9n et al. 2021], we add an explicit resample operator to the language to enable programs to explicitly trigger resampling.\u00b9 We present the operational semantics of SIREN which is a big-step semantics extended with checkpoints for resampling."}, {"title": "3.2.1 Hybrid Inference Interface", "content": "Hybrid inference algorithms reduce variance in particle filters by computing closed-form distributions where possible and only drawing random samples if symbolic computation fails. We first present definitions for the hybrid inference interface, an extension of the symbolic interface [Atkinson et al. 2022], that underpins our operational semantics.\nSymbolic Expressions. Figure 7 presents the grammar of symbolic expressions used by hybrid inference algorithms implementing the hybrid inference interface. It specifies a grammar of distri- butions D that includes, but is not limited to, Gaussian, Bernoulli, Inverse-Gamma, and Dirac Delta distributions. D can also be a sampled-Delta distribution (denoted as \u03b4_s), which is a Dirac Delta distribution that is used only to represent a sample drawn from a probability distribution. Figure 7 further specifies a grammar of expressions E that uses operators to combine constant values c and random variables X. The operators include standard arithmetic and comparison operators and a conditional operator ite.\nSymbolic State. A symbolic state g \u2208 RV \u2192 A \u00d7 D \u00d7 N is a finite mapping whose domain is the set of random variable names, where A = {sample, symbolic, \u03b5}. It maps each random variable to an entry consisting of an optional annotation (\u03b5 represents no annotation), a symbolic representation of a distribution, and a data field that is implementation-specific. We use the notation g(X)_a for the annotation of the variable X, use g(X)_d for its distribution, and use g(X)_n for the data field. The entire entry we refer to as g(X).\nInterface. The hybrid inference interface uses three operations to manipulate the symbolic state, shown in Figure 8. The Assume operation takes an annotation, a distribution, and a symbolic state, and returns a new random variable with the updated symbolic state. The OBSERVE operation conditions the symbolic state on the input variable having the given value and returns the updated state and a score for the particle filter to use as the weight. The VALUE operation replaces the input"}, {"title": "3.2.2 Unsatisfiable Annotation", "content": "When a distribution encoding annotation is unsatisfiable, the SIREN runtime performs a dynamic encoding cast, enabling the execution to continue. In particular, the VALUE operation executes as if the annotation of the input random variable is \u03b5 even if the annotation of the input random variable is symbolic."}, {"title": "3.2.3 Big-step Semantics with Checkpoints", "content": "Next, we present the semantics of SIREN. Figures 9 to 11 show a fragment, and the full semantics is in Appendix B. A particle is represented by a pair (expression, symbolic state). A SIREN program is described by three types of rules:\nParticle Evaluation. The evaluation relation e, g \u21d3 e', g', w evaluates a particle (e, g) and returns an updated particle (e', g'), the associated score w, and a resample flag r indicating if the evaluation was interrupted.\nParticle Set Evaluation. The evaluation relation {ei, gi} 1e into a distribution D using N particles.\nParticle Evaluation. Figure 9 shows a fragment of the particle evaluation rules. A constant v is already fully reduced so the resample flag r is set to true. Since it is a deterministic value, the associated score is 1. The resample operator interrupts reductions by setting the resample flag r to true; it reduces to the unit value. The semantics of if v then e\u2081 else e2 consists of two cases. If e1 and e2 are pure (i.e. they do not perform any observe or resample) and the condition v is not a constant (i.e. it contains some symbolic random variables) then the rule reduces to an ite symbolic"}, {"title": "3.3 Implementing the Hybrid Inference Interface", "content": "The Siren semantics enables inference plans to be used with different hybrid particle filtering algorithms by unifying across these algorithms using the hybrid inference interface. Only the implementation of the interface operations from Figure 8 is required to extend SIREN with a new algorithm. To illustrate how the interface can be implemented, we present the implementation for"}, {"title": "3.3.1 Semi-symbolic Inference", "content": "Semi-symbolic inference (SSI) implements the hybrid inference interface using a series of helper functions. For example, SSI defines the VALUE operation \u2013 which replaces a random variable with a sample from its distribution \u2013 using the HOIST and INTERVENE helper functions. The HOIST function manipulates a particular random variable to have no parent variables and INTERVENE updates the random variable with the drawn sample. The VALUE Operation is defined as follows:\nVALUE(X, g) = let g' = HOIST(X, g) in let v = DRAW(g'(X)_a)in (v, INTERVENE(X, \u03b4_s (v), g'))\nWe defer a full discussion of the implementation of VALUE, HOIST and other helper functions to [Atkinson et al. 2022]. However, the SSI implementation of the hybrid inference interface depends on a key core operation called SWAP. A partial definition of SWAP is as follows:\nSWAP(X1, X2, g) = match g(X1)_d, g(X2)_d with | N(\u00b5o, varo), N(\u00b5, var) if (\u00b5 = a * X\u2081 + b) \u2227 const(varo, var) : let (\u00b5', var') = ((a * \u00b5\u2081) + b, (a * a) * varo) in let (var'', \u00b5'') = (1 / (1 / varo + 1 / var), (\u00b5\u2081 / var + X\u2082 / var) * var'') in (g[X\u2081 \u2192 N((\u00b5' - b) / a, var' / (a * a))][X\u2082 \u2192 N(\u00b5'', var' + var)], true) | _ : (g, false)\nThe swap operation enables the SSI runtime to symbolically transform different conjugate distri- butions in different cases; here we show the case for linear-Gaussians. When 1) both X\u2081 and X\u2082 are Gaussian-distributed, 2) the variance of each distribution is constant (i.e., does not depend on any random variables), and 3) the mean of X\u2082 is expressible as an affine function of X\u2081, the swAP operation performs linear-Gaussian swapping. Note that all operations inside the SWAP construct symbolic expressions and perform no actual computation (e.g. a * a construct a symbolic expression representing a\u00b2). The swap operation computes the new parameters of the swapped distributions according to the standard rules for conjugate priors [Fink 1997] and updates the new distributions in the symbolic state. It returns the updated state which represents the same distribution but where X\u2082 no longer depends on X\u2081 and X\u2081 now depends on X\u2082. It also returns a true flag indicating a swap occurred. If no conjugate distributions are available, the SWAP operation returns a false flag, indicating that exact inference is not possible and the algorithm must use approximate sampling.\nThe success and failure of the swap transformation determine whether the SSI runtime encodes a random variable symbolically or samples it, influencing the inference plan it implements. For example, in Figure 3a the x variable in Line 3 and the observed Gaussian in Line 7 are linear- Gaussians. The SWAP function will apply the linear-Gaussian swapping, maintaining \u00d7 symbolically. Whereas, if v is non-constant, the linear-Gaussian case will not apply. If no other conjugate prior case applies, the SSI runtime will be forced to sample x."}, {"title": "3.3.2 Delayed Sampling", "content": "Delayed sampling (DS) is a hybrid inference algorithm that also exploits conjugacy relationships [Lund\u00e9n 2017; Murray et al. 2018]. It is an alternative implementation of the interface that represents the symbolic state using a forest of disjoint trees, where each node in each tree is a random variable.\nWhile we defer the full discussion of DS to prior work, we note here that compared to SSI, DS specifies additional information about each random variable, as each node is one of 3 types - Initialized, Marginalized, or Realized \u2013 and the inference plan satisfiability analysis needs to incorporate this additional information. In particular, Initialized nodes represent random variables that have a conditional distribution dependent on their parent; Marginalized nodes represent variables that have marginal distributions, and may need to track an optional prior distribution (and a reference to its original parent); and Realized nodes represent variables that have been replaced by a constant value through sampling or observing. The DS symbolic state uses the data field g(X)_n to track the node type for each random variable, where Srv \u2286 RV are the children of the node:\nN ::= marginalized(Srv) | marginalized(X, D, Srv) | initialized(X, Srv) | realized\nDS maintains invariants about the symbolic state, including that each tree contains at most one path of Marginalized nodes. These invariants further influence the inference plans implemented by the DS runtime and require DS to implement the symbolic interface using a series of unique helper functions. For example, DS implements the VALUE operation using the helpers GRAFT and REALIZE:\nVALUE(X, g) = let g' = GRAFT(X, g) in let v = DRAW(g'(X)_a)in (v, REALIZE(X, \u03b4_s (v), g'))\nWhile we defer the full details to prior work [Lund\u00e9n 2017; Murray et al. 2018], we note that Graft and REALIZE utilize the node types to manipulate the symbolic state. These operations determine whether the DS runtime samples random variables as well as the default inference plan when no annotations are provided."}, {"title": "4 INFERENCE PLAN SATISFIABILITY ANALYSIS", "content": "Using the symbolic and sample distribution encoding annotations, developers can express an inference plan specifying their requirements for how each random variable is encoded. However, the hybrid inference runtime performs a dynamic encoding cast when an annotation is unsatisfiable, enabling the program execution to continue at the risk of potential accuracy degradation. In this section, we present the inference plan satisfiability analysis, a static analysis that identifies unsatisfiable annotations to assist developers with reasoning about which inference plans to use. If the analysis passes, the inference system is guaranteed to encode all sample variables with samples and all symbolic variables symbolically. We next formalize the analysis as an abstract interpretation and prove its soundness."}, {"title": "4.1 Abstract Hybrid Inference", "content": "Our analysis performs an abstract interpretation of the program with an abstraction of the hybrid inference interface. We construct abstract symbolic expressions and abstract symbolic states that the abstract interface operates over and manipulates. The abstract interface operations mirror the concrete operations, except that Observe and VALUE do not perform scoring or sampling."}, {"title": "4.2 Abstract Interpretation Rules", "content": "Figure 14 presents a fragment of the interpretation rules of a SIREN program using the abstract hybrid inference operations. We present here only the rules that differ from the concrete semantics and include the full abstract semantics in Appendix C.\nConditionals. When Value* returns UnkC, the analysis cannot determine which branch of a conditionsl is taken, so it interprets both branches and joins the resulting abstract expressions with RENAME_JOIN to approximate the program execution.\nFold. If the fold operation receives a list argument \u00ce that is not a constant list, such as UnkE (0), the analysis over-approximates the operation by computing the abstract fixpoint of the function f. The analysis first interprets f on (\u00ce, \u00f4). Since \u00ce is not a constant list, it is either UnkE (S) or TopE, each of which also over-approximates any particular item in the list, respectively. The analysis computes (\u00f4j, \u011dj) using RENAME_JOIN, which are the over-approximations of the current inputs and the inputs of the next iteration for f. If they are weakly equal to the current inputs, no further application of f could be different; the fixpoint computation stops when \u00fb and \u00f4j are equal and \u011d and \u011dj are weakly equal with respect to (\u00ce, \u00f4).\nDuring fixpoint computations, the analysis could be joining UnkE (\u015arv) expressions. However, \u015arv can grow arbitrarily large. To bound the growth, the analysis widens the joined expression by converting UnkE (\u015arv) to TopE if |\u015arv| \u2265 N for some parameter N. Our implementation uses N = 4, but the parameter may be adjusted for greater precision at the cost of more fixpoint iterations.\nParticle Set and Model Evaluation. Unlike the concrete semantics, the abstract semantics spawns only a singleton set of particles to evaluate, as there are no weights to consider. All possible particles from a program are accounted for in a single abstract particle evaluation. Thus, there is no abstract equivalent of the resampling step, and resample is a no-op. The abstract interpretation of a program is then simply whether the abstract particle evaluation rules encounter failures or not."}, {"title": "4.3 Implementing the Abstract Hybrid Inference Interface", "content": "By relying on the abstract hybrid inference interface, the analysis is unified across different hybrid particle filtering algorithms. Only the implementation of the interface is required to extend the analysis to a new algorithm. This section presents how the analysis implements an abstract version of the hybrid interface for SSI and DS. While we defer the full details to Appendix C.2, we note the similarity of the abstract operations to the concrete operations from Section 3.3, except that the abstract operations have extensions to handle the analysis's imprecision. We present here the abstract version of SSI's swap operation and how the analysis incorporates the additional information in DS's node types."}, {"title": "4.3.1 Semi-Symbolic Inference", "content": "Each SSI operation has an abstract version that mirrors the concrete operation and differs only in how it handles abstract values like UnkD (\u015arv). For instance, the VALUE operation depends on HOIST and INTERVENE, and it uses UnkC instead of drawing values. However, for VALUE, there is the additional difference that it returns fail if the input variable has the symbolic annotation i.e. the concrete random variables represented by the abstract random variable may have an unsatisfiable annotation.\nVALUE(X, \u011d) = if \u011d(X)_a = symbolic then fail else let \u011d' = HOIST(X, \u011d) in (UnkC, INTERVENE (X, \u03b4_s (UnkC), \u011d'))\nWe describe the abstract swap operation used in SSI to show how implementations handle abstract values. The abstract version of the swap operation simulates the concrete function by detecting conjugacy and performing computation where it can, as defined in Section 3.3.1."}, {"title": "4.3.2 Delayed Sampling", "content": "The abstract node types of DS can be Initialized, Marginalized, or Realized. Initialized and Marginalized nodes still track their parent variables, their prior distributions (using abstract expressions), and their children. The fourth abstract node type, TopN, is the top of all node states. It indicates that the analysis does not know the node's type. No prior and no parent to the random variable are tracked for TopN, only its children.\n\u00d1 ::= marginalized(\u015arv) | marginalized(X, D, \u015crv) | initialized(X, \u015crv) | realized | TopN(\u015crv)"}, {"title": "4.4 Properties", "content": "In this section, we show that the inference plan satisfiability analysis is sound. The approach is mostly standard [Cousot and Cousot 1977, 1992], except for how it handles random variable names and the variable sets in abstract expressions. We will highlight these nonstandard elements throughout the formal development. First, we define the collecting semantics for sets of program states that serves as the basis of our soundness proof. The collecting semantics accumulates from program executions the information relevant to the program properties under study. The abstract states computed by the analysis must over-approximate the collected concrete states to ensure soundness. Next, we define the abstraction and concretization functions that relate abstract values to concrete values. Finally, we present key lemmas and theorems that prove the analysis is sound."}, {"title": "4.4.1 Collecting Semantics", "content": "The collecting semantics is a forward collecting semantics [Cousot and Cousot 1992] based on our operational semantics. The program states collected differ between our three types of evaluation rules. Even though the operational semantics uses weight values and performs resampling, the collecting semantics ignores these aspects. The analysis only depends on the possible particles produced during program execution. The resampling step does not introduce any new particles to the execution, only duplicating or removing existing particles. Additionally, weight values do not affect the representation of random variables. As such, weights are not collected and the resampling step in the particle set evaluation rules is a no-op.\nWhen a symbolic distribution encoding annotation is unsatisfiable, the SIREN runtime performs a dynamic encoding cast by sampling the annotated random variable anyway, enabling the execution to continue. The cast is the event that the inference plan satisfiability analysis must detect. In the collecting semantics, the VALUE function must return the fail value if the annotation of the input"}, {"title": "4.4.2 Abstraction", "content": "The abstraction function a maps sets of concrete values to an abstract value. We define the function first for singleton sets of concrete values. The abstraction of sets of multiple values is then the join of the corresponding abstracted values.\nConcrete random variables and abstract random variables have different namespaces. To account for this, the abstraction function assumes the existence of a default mapping RV_canon : RV \u2192 RV that maps concrete variable names to abstract variable names. The abstractions of both random variables and symbolic states use this to produce the appropriate name in abstract values.\nDefinition 4.1 (Abstraction Function). We define the abstraction function a as follows. The default mapping function RV_canon maps every concrete variable to a unique, canonical abstract variable.\n\u03b1({c}) = \u0109 \u03b1({X}) = X = RV canon(X) \u03b1({(01, 02)}) = (\u03b1({01}), \u03b1({02}))\n\u03b1({E1 + E2}) = \u03b1({E\u2081}) + \u03b1({E2}) \u03b1({g}) = (\u03b1{9(X)} | X \u2208 dom(9)}\n\u03b1({symbolic}) = symbolic \u03b1({fail}) = fail \u03b1({\u03b4\u03c5}) = v\u03b5\u03c2, \u03b1({v})"}, {"title": "4.4.3 Concretization", "content": "The concretization function y plays the opposite role to the abstraction function: it maps every abstract value to a set of concrete values. While we formalize abstraction with a default mapping function, the concretization needs to account for all possible mappings. We first define a version of the concretization function that is parameterized by a surjective function RV : RV \u2192 RV that maps concrete random variables to abstract random variables. The function must be surjective since every abstract random variable must have a corresponding concrete random variable. The function does not have to be injective, because an abstract variable can represent multiple concrete variables that share properties in the symbolic state. The concretizations for UnkE (Sr) and UnkD (\u015crv) incorporate the variable set \u015ar by ensuring that the concretization includes only those expressions whose free variables are a subset of \u015ary. We formalize this using the operation FV(E, RV) that returns the set of free variables in E, mapped to abstract names using RV. Finally, we define the concretization function by taking the union over all possible name-mapping functions; the set resulting from the concretization function is closed under name re-mappings.\nDefinition 4.2 (Concretization Function). We define the concretization function y as follows. First, we define y as a function that takes in an abstract state and the name-mapping function RV. The"}, {"title": "4.4.4 Soundness of Analysis", "content": "We now present the key ideas and properties necessary to prove the soundness of the analysis and defer the full formalization and proofs to Appendix D. Our treatment of soundness is limited in that we assume the analysis has a sound implementation of the symbolic interface, and show that under this assumption, the overall analysis is sound. We formalize this assumption as follows:\nASSUMPTION 4.1 (ABSTRACT HYBRID INFERENCE INTERFACE SOUNDNESS). For every i \u2208 {ASSUME, VALUE, OBSERVE} and input values vi, we have that i(vi) \u2208 \u03b3(\u0390(\u03b1({v}))).\nBecause of the join operation on abstract symbolic states, an abstract operation might compute an abstract symbolic state that has variables that are not reachable from the computed expression. The concretization of abstract symbolic states retains those unreachable variables in the concrete symbolic states. Symbolic states with different domains are not strictly equal. However, unreachable variables do not alter the evaluated expression nor the reachable entries in the resulting symbolic state. To account for this property, we define a weak equivalence relation for concrete symbolic states, analogous to the weak equivalence relation for abstract states.\nThe formalization uses an auxiliary operation \u2193* for repeatedly evaluating a particle until it has terminated, which we define precisely in Appendix D. We write configuration sets that have weakly equivalent symbolic states as Sc = S_c \u21d4 S = {(e, g', r) | (e, g, r) \u2208 Sc, g =_e g'}. We use an aux- iliary operation to drop the resample flag in configurations: FORGETR(Sc) = {(e, g) | (e, g, r) \u2208 Sc}. We first show the analysis is sound when the particle evaluation terminates, and resuming particle evaluation preserves the soundness of the analysis."}, {"title": "4.4 4 Properties"}]}