{"title": "Inference Plans for Hybrid Particle Filtering", "authors": ["ELLIE Y. CHENG", "ERIC ATKINSON", "GUILLAUME BAUDART", "LOUIS MANDEL", "MICHAEL CARBIN"], "abstract": "Advanced probabilistic programming languages (PPLs) use hybrid inference systems to combine symbolic exact inference and Monte Carlo methods to improve inference performance. These systems use heuristics to partition random variables within the program into variables that are encoded symbolically and variables that are encoded with sampled values, and the heuristics are not necessarily aligned with the performance evaluation metrics used by the developer. In this work, we present inference plans, a programming interface that enables developers to control the partitioning of random variables during hybrid particle filtering. We further present SIREN, a new PPL that enables developers to use annotations to specify inference plans the inference system must implement. To assist developers with statically reasoning about whether an inference plan can be implemented, we present an abstract-interpretation-based static analysis for SIREN for determining inference plan satisfiability. We prove the analysis is sound with respect to SIREN's semantics. Our evaluation applies inference plans to three different hybrid particle filtering algorithms on a suite of benchmarks and shows that the control provided by inference plans enables speed ups of 1.76x on average and up to 206x to reach target accuracy, compared to the inference plans implemented by default heuristics; the results also show that inference plans improve accuracy by 1.83x on average and up to 595x with less or equal runtime, compared to the default inference plans. We further show that the static analysis is precise in practice, identifying all satisfiable inference plans in 27 out of the 33 benchmark-algorithm combinations.", "sections": [{"title": "1 INTRODUCTION", "content": "Probabilistic programming languages (PPLs) support primitives for modeling random variables and performing probabilistic inference [Goodman and Stuhlm\u00fcller 2014; Holtzen et al. 2020; Murray and Sch\u00f6n 2018; Narayanan et al. 2016; Tolpin et al. 2016]. They provide high-level abstractions for probabilistic modeling that hide away the complex details of inference algorithms while leveraging common programming language constructs such as functions, loops, and control flow. PPLs serve as an expressive and accessible tool for solving such problems. Users can focus on modeling the problem, rather than the details of inference techniques.\nHybrid Inference Systems. Hybrid inference systems \u2013 such as delayed sampling [Lund\u00e9n 2017;\nMurray et al. 2018], semi-symbolic inference [Atkinson et al. 2022], Sequential Monte Carlo with belief propagation [Azizian et al. 2023], and automatically marginalized MCMC [Lai et al. 2023] automatically incorporate exact inference with Monte Carlo methods to improve performance. They utilize a symbolic encoding of random variables to represent some or all parts of the model, enabling symbolic computation that lowers the variance of estimations. Hybrid inference algorithms that apply to particle filters [Gordon et al. 1993] implement an automatic Rao-Blackwellization of the particle filter [Doucet et al. 2000]; hybrid inference algorithms that apply to MCMC algorithms automatically implement collapsed sampling [Liu 1994]. In this work, we focus on hybrid inference systems that perform symbolic computations dynamically at runtime. These systems are able to take advantage of exact inference opportunities that only become available once the inference system replaces some variables with concrete Monte Carlo samples."}, {"title": "Objective Oblivious Heuristics", "content": "When a hybrid inference system cannot solve the entire program with symbolic computation, it must partition the random variables into variables that it encodes symbolically and variables it encodes with concrete sampled values. Different partitions make different subsets of random variables more accurate. Choosing which partition to use then depends on 1) the probabilistic model and 2) the metrics used by the developer to evaluate the program. Hybrid inference systems automatically choose a partition to use based on the program structure using built-in heuristics. However, they are oblivious to the objectives of the developer and to how the developer measures performance. Their selected partition might not produce good inference performance as a result. In these cases, developers need an interface for applying alternative heuristics that incorporate their evaluation objectives to achieve better performance."}, {"title": "Inference Plans", "content": "In this work, we present inference plans, a programming interface that gives developers fine-grained control over how random variables are partitioned into sampled and symbolic variables during hybrid inference. An inference plan consists of a sequence of distribution encoding annotations that specify whether the inference runtime should encode each random variable with a symbolic distribution or an approximate Monte Carlo sample. Using these annotations, developers can apply heuristics best-suited to their applications and performance metrics. Our evaluation shows that the control provided by inference plans enables speed ups of 1.76x on average and up to 206x to reach target accuracy, compared to the inference plans implemented by default heuristics; the results also show that inference plans improve accuracy by 1.83x on average and up to 595x with less or equal runtime, compared to the default inference plans."}, {"title": "Satisfiability Analysis", "content": "A key challenge in delivering the inference plans interface is that, depending on the program, the inference algorithm may not be able to maintain a random variable symbolically if the corresponding inference problem is too hard for the system to solve exactly."}, {"title": "Objective Oblivious Heuristics", "content": "When a hybrid inference system cannot solve the entire program with symbolic computation, it must partition the random variables into variables that it encodes symbolically and variables it encodes with concrete sampled values. Different partitions make different subsets of random variables more accurate. Choosing which partition to use then depends on 1) the probabilistic model and 2) the metrics used by the developer to evaluate the program. Hybrid inference systems automatically choose a partition to use based on the program structure using built-in heuristics. However, they are oblivious to the objectives of the developer and to how the developer measures performance. Their selected partition might not produce good inference performance as a result. In these cases, developers need an interface for applying alternative heuristics that incorporate their evaluation objectives to achieve better performance."}, {"title": "Inference Plans", "content": "In this work, we present inference plans, a programming interface that gives developers fine-grained control over how random variables are partitioned into sampled and symbolic variables during hybrid inference. An inference plan consists of a sequence of distribution encoding annotations that specify whether the inference runtime should encode each random variable with a symbolic distribution or an approximate Monte Carlo sample. Using these annotations, developers can apply heuristics best-suited to their applications and performance metrics. Our evaluation shows that the control provided by inference plans enables speed ups of 1.76x on average and up to 206x to reach target accuracy, compared to the inference plans implemented by default heuristics; the results also show that inference plans improve accuracy by 1.83x on average and up to 595x with less or equal runtime, compared to the default inference plans."}, {"title": "Satisfiability Analysis", "content": "A key challenge in delivering the inference plans interface is that, depending on the program, the inference algorithm may not be able to maintain a random variable symbolically if the corresponding inference problem is too hard for the system to solve exactly."}, {"title": "Dynamic Encoding Cast", "content": "In such a scenario, Siren, like other hybrid inference systems [Atkinson et al. 2022; Azizian et al. 2023; Lund\u00e9n 2017; Murray et al. 2018], will, conceptually, dynamically cast the offending symbolic annotation to a sample annotation, changing the underlying distribution encoding to a concrete sample. However, Figure 5 illustrates the impact of such a coercion. Figure 5 shows the accuracy of the position and altitude of a simulated aircraft over 100 timesteps using the two programs in the two different flight modes. In Figure 5a, where the aircraft is cruising at altitude 10, the pattern observed in the performance profiles is replicated. The Symbolic x Plan consistently achieves better accuracy for the x position, and the Symbolic r Plan for alt. In either case, both plans have errors less than 1 for both variables at all timesteps. However, when the aircraft is descending, this pattern is broken. In Figure 5b, the aircraft is now operating in a noisier environment. The accuracy and runtime of a probabilistic model inherently depend on the conditioned inputs, so both plans experience an error spike in alt. The Symbolic x Plan still maintains a relatively low error for x, whereas the Symbolic r Plan has a significant error spike at around 60 timesteps such that the estimation error of x is a magnitude larger than before. This error spike cannot be explained by the noisier environment alone, because the Symbolic x Plan does not exhibit a similar x error spike. The accuracy degradation in x by the Symbolic r Plan is due to a dynamic encoding cast on an unsatisfiable annotation."}, {"title": "Performance Degradation", "content": "A dynamic encoding cast has implications for inference performance, as it means that the runtime cannot implement the annotated inference plan and has to implement a different inference plan to continue execution. While flexible and enables the program execution to continue, it can cause imprecision that is unacceptable in certain applications. In this example, casting the unsatisfiable annotation causes a significant decrease in accuracy in x. The significant accuracy degradation negates the advantage the Symbolic r Plan has over the Symbolic x Plan for alt. Given the possible impact on accuracy, the developer should use the Symbolic x Plan instead."}, {"title": "2.3 Inference Plan Satisfiability Analysis", "content": "To enable developers to ensure their program is free from dynamic encoding casts, SIREN performs the inference plan satisfiability analysis to determine whether the annotated inference plan is satisfiable during all possible executions of the program using the hybrid inference algorithm.\nAbstract Interpretation. The analysis uses an abstract interpretation of the program. It main-tains abstract symbolic distributions of random variables and uses abstract expressions to over-approximate program executions. Consider the unsatisfiable plan from Figure 3b. On Line 6, because the analysis does not know the exact value of alt, it uses an abstract value to over-approximate the subexpressions in the branches. If alt is above 5, the abstract subexpression is $X_r$, referring to"}, {"title": "Inference Plans for Hybrid Particle Filtering", "content": "the abstract random variable from Line 11. If alt is below 5, the subexpression is $X_r + UnkC$. The abstract value UnkC represents some unspecified constant. All random samples are constant values, so other evaluates to UnkC. The analysis over-approximates the subexpressions as a single abstract expression: UnkE ({Xr}) an unspecified abstract expression that references $X_r$.\nUnsatisfiable Inference Plan. The analysis also approximates how the system decides when to perform symbolic computations. The Line 7 variable has the abstract distribution $N(UnkC, UnkE({Xr}))$. The variance is the expression computed on Line 6. The inference algorithm cannot perform symbolic computations when the variance is a complex expression. Because r (corresponding to $X_r$) is annotated with symbolic, the variable will be dynamically cast in those instances. The analysis rejects the program, correctly identifying that the inference plan is unsatisfiable in some executions.\nSatisfiable Inference Plan. The satisfiability analysis will always reject unsatisfiable inference plans, but it may be overly conservative and erroneously reject satisfiable plans. Nevertheless, the analysis is precise in practice. For example, it correctly determines the program in Figure 3a is satisfiable. At Line 7, the observed variable has the symbolic distribution $N(X_x, UnkC)$, where $X_x$ refers to the symbolic random variable created on Line 3. The variance is an unknown constant, the mean is a linear expression, and $X_x$ also has a Gaussian symbolic distribution. This model only consists of linear-Gaussian distributions a class of probabilistic models that the inference algorithm can solve entirely symbolically. Thus, x will always be encoded symbolically as the annotation requires. No annotations are violated, so the analysis accepts the inference plan."}, {"title": "2.4 Summary", "content": "Using annotations, developers can select alternative inference plans that are better aligned with their objectives. With the satisfiability analysis, the developer can further guarantee the inference plan will always be satisfiable in any execution. If SIREN successfully compiles a program, then any variable annotated with symbolic will always be represented symbolically in any execution, and any variable annotated with sample will always be sampled. This provides developers with the guarantee that their program performance will not be degraded by unsatisfiable annotations."}, {"title": "3 LANGUAGE SYNTAX AND SEMANTICS", "content": "We present the syntax and semantics of the first-order functional PPL, SIREN, adapted from Staton [2017]. We have extended the language to support distribution encoding annotations and adapted it to use hybrid inference, and specify its semantics via the hybrid inference interface."}, {"title": "3.1 Syntax", "content": "Figure 6 presents the syntax of Siren. An expression e is a value v (constant; variable; pair; or the application of an operator, e.g., arithmetic operation, distribution, or list), a function application, a conditional, or a local definition. We add the classic fold operator as well. SIREN supports probabilistic operators. The expression let x \u2190 op(v) in e introduces a new local random variable x with distribution op(v) to be used in e. Optionally, a symbolic or sample annotation adorns a random variable declaration. The observe (\u03c51, \u03c52) expression conditions the model on a variable with distribution v\u2081 having value v2. The resample"}, {"title": "3.2 Operational Semantics", "content": "While SIREN has an ideal measure-based semantics (see Appendix A), the measure is, in general, intractable. An alternative is to interpret the model as a weighted sampler that returns a value and a score measuring the likelihood of the result with respect to the model. To approximate the posterior distribution, a weighted sampler launches a set of independent executions of the sampler, the particles, and returns a categorical distribution that associates each value with its score. SIREN implements a particle filter which occasionally resamples the set of particles according to their score during executions. Following [Lund\u00e9n et al. 2021], we add an explicit resample operator to the language to enable programs to explicitly trigger resampling.\u00b9 We present the operational semantics of SIREN which is a big-step semantics extended with checkpoints for resampling."}, {"title": "3.2.1 Hybrid Inference Interface", "content": "Hybrid inference algorithms reduce variance in particle filters by computing closed-form distributions where possible and only drawing random samples if symbolic computation fails. We first present definitions for the hybrid inference interface, an extension of the symbolic interface [Atkinson et al. 2022], that underpins our operational semantics.\nSymbolic Expressions. Figure 7 presents the grammar of symbolic expressions used by hybrid inference algorithms implementing the hybrid inference interface. It specifies a grammar of distributions D that includes, but is not limited to, Gaussian, Bernoulli, Inverse-Gamma, and Dirac Delta distributions. D can also be a sampled-Delta distribution (denoted as \u03b4\u03c2), which is a Dirac Delta distribution that is used only to represent a sample drawn from a probability distribution. Figure 7 further specifies a grammar of expressions E that uses operators to combine constant values c and random variables X. The operators include standard arithmetic and comparison operators and a conditional operator ite.\nSymbolic State. A symbolic state g \u2208 RV \u2192 A \u00d7 D \u00d7 N is a finite mapping whose domain is the set of random variable names, where A = {sample, symbolic, e}. It maps each random variable to an entry consisting of an optional annotation (\u025b represents no annotation), a symbolic representation of a distribution, and a data field that is implementation-specific. We use the notation g(X)a for the annotation of the variable X, use g(X)d for its distribution, and use g(X)n for the data field. The entire entry we refer to as g(X).\nInterface. The hybrid inference interface uses three operations to manipulate the symbolic state, shown in Figure 8. The Assume operation takes an annotation, a distribution, and a symbolic state, and returns a new random variable with the updated symbolic state. The OBSERVE operation conditions the symbolic state on the input variable having the given value and returns the updated state and a score for the particle filter to use as the weight. The VALUE operation replaces the input"}, {"title": "Inference Plans for Hybrid Particle Filtering", "content": "variable with a sample from its distribution, turning it into a sampled-Delta distribution. These operations decide whether the runtime samples a random variable or encodes a random variable symbolically in the symbolic state. By doing so, they determine the default inference plan in the absence of annotations. We will discuss different implementations of the interface in Section 3.3.\n3.2.2 Unsatisfiable Annotation. When a distribution encoding annotation is unsatisfiable, the SIREN runtime performs a dynamic encoding cast, enabling the execution to continue. In particular, the VALUE operation executes as if the annotation of the input random variable is \u025b even if the annotation of the input random variable is symbolic.\n3.2.3 Big-step Semantics with Checkpoints. Next, we present the semantics of SIREN. Figures 9 to 11 show a fragment, and the full semantics is in Appendix B. A particle is represented by a pair (expression, symbolic state). A SIREN program is described by three types of rules:\n\u2022 Particle Evaluation. The evaluation relation e, g \u2193r e', g', w evaluates a particle (e, g) and returns an updated particle (e', g'), the associated score w, and a resample flag r indicating if the evaluation was interrupted.\n\u2022 Particle Set Evaluation. The evaluation relation {ei, gi}1<i<N \u2193\u2193 D gathers the results of a set of particles into a distribution D.\n\u2022 Model Evaluation. The evaluation relation e \u2193\u2193N D evaluates a program expression e into a distribution D using N particles.\nParticle Evaluation. Figure 9 shows a fragment of the particle evaluation rules. A constant v is already fully reduced so the resample flag r is set to true. Since it is a deterministic value, the associated score is 1. The resample operator interrupts reductions by setting the resample flag r to true; it reduces to the unit value. The semantics of if v then e\u2081 else e2 consists of two cases. If e1 and e2 are pure (i.e. they do not perform any observe or resample) and the condition v is not a constant (i.e. it contains some symbolic random variables) then the rule reduces to an ite symbolic"}, {"title": "3.3 Implementing the Hybrid Inference Interface", "content": "The Siren semantics enables inference plans to be used with different hybrid particle filtering algorithms by unifying across these algorithms using the hybrid inference interface. Only the implementation of the interface operations from Figure 8 is required to extend SIREN with a new algorithm. To illustrate how the interface can be implemented, we present the implementation for"}, {"title": "Inference Plans for Hybrid Particle Filtering", "content": "two algorithms \u2013 semi-symbolic inference [Atkinson et al. 2022] and delayed sampling [Lund\u00e9n 2017; Murray et al. 2018] - to illustrate 1) how to detect opportunities for symbolic computation during inference and 2) how to extend the symbolic state with additional runtime information. We note that the interface is more general; for evaluation in Section 5, we implement a third inference algorithm - Sequential Monte Carlo with belief propagation [Azizian et al. 2023] \u2013 that exhibits both features. The full implementations of these algorithms are quite complex, so we defer the full details to the respective works. In this section, we focus on presenting only details that pertain to either 1) how an inference algorithm's internal control flow relates to its inference plans, and 2) providing a semantic foundation for the analysis and its soundness (in particular, for Section 4.3).\n3.3.1 Semi-symbolic Inference. Semi-symbolic inference (SSI) implements the hybrid inference interface using a series of helper functions. For example, SSI defines the VALUE operation \u2013 which replaces a random variable with a sample from its distribution \u2013 using the HOIST and INTERVENE helper functions. The HOIST function manipulates a particular random variable to have no parent variables and INTERVENE updates the random variable with the drawn sample. The VALUE operation is defined as follows:\nVALUE(X, g) = let g' = HOIST(X, g) in let v = DRAW(g'(X)d)in (v, INTERVENE(X, \u03b4\u03c2 (v), g'))\nWe defer a full discussion of the implementation of VALUE, HOIST and other helper functions to [Atkinson et al. 2022]. However, the SSI implementation of the hybrid inference interface depends on a key core operation called SWAP. A partial definition of SWAP is as follows:\nSWAP(X1, X2, g) = match g(X1)d, g(X2)d with\n| N(\u03bc\u03bf, varo), N(\u00b5, var) if (\u00b5 = a * X\u2081 + b) ^ const(varo, var) :\nlet (\u00b5\u00b4, var) = ((a * \u03bc\u2081) + b, (a * a) * varo) in\nlet (var'', \u03bc'') = (1 / (1 / varo + 1 / var), (\u03bc, / var + X2 / var) * var'') in\n(g[\u03a7\u2081 \u2192 \u039d((\u03bc' - b) / a, var' / (a * a))][X2 \u2192 N(\u00b5\u00b4, var + var)], true)\n|_ : (g, false)\nThe swap operation enables the SSI runtime to symbolically transform different conjugate distributions in different cases; here we show the case for linear-Gaussians. When 1) both X\u2081 and X2 are Gaussian-distributed, 2) the variance of each distribution is constant (i.e., does not depend on any random variables), and 3) the mean of X2 is expressible as an affine function of X\u2081, the SWAP operation performs linear-Gaussian swapping. Note that all operations inside the SWAP construct symbolic expressions and perform no actual computation (e.g. a * a construct a symbolic expression representing a\u00b2). The swap operation computes the new parameters of the swapped distributions according to the standard rules for conjugate priors [Fink 1997] and updates the new distributions in the symbolic state. It returns the updated state which represents the same distribution but where X2 no longer depends on X\u2081 and X\u2081 now depends on X2. It also returns a true flag indicating a swap occurred. If no conjugate distributions are available, the SWAP operation returns a false flag, indicating that exact inference is not possible and the algorithm must use approximate sampling.\nThe success and failure of the swap transformation determine whether the SSI runtime encodes a random variable symbolically or samples it, influencing the inference plan it implements. For example, in Figure 3a the x variable in Line 3 and the observed Gaussian in Line 7 are linear-Gaussians. The SWAP function will apply the linear-Gaussian swapping, maintaining \u00d7 symbolically. Whereas, if v is non-constant, the linear-Gaussian case will not apply. If no other conjugate prior case applies, the SSI runtime will be forced to sample x."}, {"title": "Inference Plans for Hybrid Particle Filtering", "content": "3.3.2 Delayed Sampling. Delayed sampling (DS) is a hybrid inference algorithm that also exploits conjugacy relationships [Lund\u00e9n 2017; Murray et al. 2018]. It is an alternative implementation of the interface that represents the symbolic state using a forest of disjoint trees, where each node in each tree is a random variable.\nWhile we defer the full discussion of DS to prior work, we note here that compared to SSI, DS specifies additional information about each random variable, as each node is one of 3 types Initialized, Marginalized, or Realized \u2013 and the inference plan satisfiability analysis needs to incorporate this additional information. In particular, Initialized nodes represent random variables that have a conditional distribution dependent on their parent; Marginalized nodes represent variables that have marginal distributions, and may need to track an optional prior distribution (and a reference to its original parent); and Realized nodes represent variables that have been replaced by a constant value through sampling or observing. The DS symbolic state uses the data field g(X)n to track the node type for each random variable, where Srv \u2286 RV are the children of the node:\nN ::= marginalized(Srv) | marginalized(X, D, Srv) | initialized(X, Srv) | realized\nDS maintains invariants about the symbolic state, including that each tree contains at most one path of Marginalized nodes. These invariants further influence the inference plans implemented by the DS runtime and require DS to implement the symbolic interface using a series of unique helper functions. For example, DS implements the VALUE operation using the helpers GRAFT and REALIZE:\nVALUE(X, g) = let g' = GRAFT(X, g) in let v = DRAW(g'(X)d) in (v, REALIZE(X, \u03b4\u03c2 (\u03c5), g'))\nWhile we defer the full details to prior work [Lund\u00e9n 2017; Murray et al. 2018], we note that GRAFT and REALIZE utilize the node types to manipulate the symbolic state. These operations determine whether the DS runtime samples random variables as well as the default inference plan when no annotations are provided."}, {"title": "4 INFERENCE PLAN SATISFIABILITY ANALYSIS", "content": "Using the symbolic and sample distribution encoding annotations, developers can express an inference plan specifying their requirements for how each random variable is encoded. However, the hybrid inference runtime performs a dynamic encoding cast when an annotation is unsatisfiable, enabling the program execution to continue at the risk of potential accuracy degradation. In this section, we present the inference plan satisfiability analysis, a static analysis that identifies unsatisfiable annotations to assist developers with reasoning about which inference plans to use. If the analysis passes, the inference system is guaranteed to encode all sample variables with samples and all symbolic variables symbolically. We next formalize the analysis as an abstract interpretation and prove its soundness."}, {"title": "4.1 Abstract Hybrid Inference", "content": "Our analysis performs an abstract interpretation of the program with an abstraction of the hybrid inference interface. We construct abstract symbolic expressions and abstract symbolic states that the abstract interface operates over and manipulates. The abstract interface operations mirror the concrete operations, except that Observe and VALUE do not perform scoring or sampling."}, {"title": "4.3 Implementing the Abstract Hybrid Inference Interface", "content": "By relying on the abstract hybrid inference interface, the analysis is unified across different hybrid particle filtering algorithms. Only the implementation of the interface is required to extend the analysis to a new algorithm. This section presents how the analysis implements an abstract version of the hybrid interface for SSI and DS. While we defer the full details to Appendix C.2, we note the similarity of the abstract operations to the concrete operations from Section 3.3, except that the abstract operations have extensions to handle the analysis's imprecision. We present here the abstract version of SSI's swap operation and how the analysis incorporates the additional information in DS's node types.\n4.3.1 Semi-Symbolic Inference. Each SSI operation has an abstract version that mirrors the concrete operation and differs only in how it handles abstract values like UnkD (\u015arv). For instance, the VALUE operation depends on HOIST and INTERVENE, and it uses UnkC instead of drawing values. However, for VALUE, there is the additional difference that it returns fail if the input variable has the symbolic annotation i.e. the concrete random variables represented by the abstract random variable may have an unsatisfiable annotation.\n4.3.2 Delayed Sampling. The abstract node types of DS can be Initialized, Marginalized, or Realized. Initialized and Marginalized nodes still track their parent variables, their prior distributions (using abstract expressions), and their children. The fourth abstract node type, TopN, is the top of all node states. It indicates that the analysis does not know the node's type. No prior and no parent to the random variable are tracked for TopN, only its children."}, {"title": "4.4 Properties", "content": "In this section, we show that the inference plan satisfiability analysis is sound. The approach is mostly standard [Cousot and Cousot 1977, 1992], except for how it handles random variable names and the variable sets in abstract expressions. We will highlight these nonstandard elements throughout the formal development. First, we define the collecting semantics for sets of program states that serves as the basis of our soundness proof. The collecting semantics accumulates from program executions the information relevant to the program properties under study. The abstract states computed by the analysis must over-approximate the collected concrete states to ensure soundness. Next, we define the abstraction and concretization functions that relate abstract values to concrete values. Finally, we present key lemmas and theorems that prove the analysis is sound."}, {"title": "Inference Plans for Hybrid Particle Filtering", "content": "First, we define a weak equivalence comparison between two symbolic states that only compares random variables that are reachable from the given expression."}, {"title": "5 EVALUATION", "content": "In this section, we empirically evaluate the efficacy of SIREN on a set of probabilistic programs. We also empirically evaluate how good the inference plan satisfiability analysis is at identifying whether an inference plan is satisfiable. We seek to answer these research questions:\nRQ1. Can inference plans improve hybrid particle filtering performance?\nRQ2. How precise is the inference plan satisfiability analysis? Section 4.4 proves the analysis is sound, so it will never state an unsatisfiable inference plan is satisfiable. The task remains to empirically determine whether the analysis can detect satisfiable inference plans in practice."}, {"title": "5.1 Benchmarks", "content": "We evaluate the performance of different hybrid particle filtering algorithms on a set of benchmark programs. We describe here the benchmarks and identify the variables evaluated for accuracy. The following benchmarks are benchmarks with multiple inference plans from prior work on SSI and DS by Atkinson et al. [2022] and Baudart et al. [2020]: Outlier, Tree, SLAM, and Wheels. We describe the programs and the evaluated variables in Appendix E, and also include the source code and the annotations of each evaluated inference plan.\nWe also added the following additional benchmarks, each of which cannot be solved purely with exact inference. They demonstrate the advantages of using inference plans for improving performance against the default behavior.\nAircraft is the program presented in Section 2.\nNoise is a one-dimensional particle filter with a hidden state modeled by Gaussian distributions (x) with variance modeled by an Inverse-Gamma distribution (q). Observations are made on Gaussian distributions centered around the previous state with variance also modeled by an inverse-Gamma distribution (r). This program is adapted from Dun\u00edk et al. [2017].\nRadar is a radar tracker with glint noise modeled as a random, rarely occurring spike [Wu 1993]. The observation noise is modeled by the sum of two independent Inverse-Gamma distributions (r and other) if the env random variable \u2013 modeled by a Bernoulli \u2013 indicates a spike. This differs from the Aircraft program in that it only models the Gaussian-distributed x position, and the Bernoulli random variable determines whether to observe a spike in the measurement noise.\nEnvNoise is similar to Radar, but the noise variable other is modeled by the more flexible Beta distribution [Arazo et al. 2019; Ma and Leijon 2011]."}, {"title": "5.2 Methodology", "content": "We implemented SIREN in Python. In addition to semi-symbolic inference and delayed sampling, we also implemented a third hybrid inference algorithm: SMC with belief propagation (SMC with BP) [Azizian et al. 2023]. The algorithm swaps parent-child dependencies using conjugate distributions similar to SSI and maintains node types in the data field like DS."}, {"title": "5.2.1 RQ1 Methodology", "content": "To determine SIREN's performance for RQ1, we execute each benchmark 100 times for 100 timesteps with an exponentially increasing particle count from 1 to 1024. We execute each benchmark using all satisfiable inference plans, except for SLDS with SSI and DS, where due to the large number of inference plans, we sort the plans by the number of symbolic variables in descending order and only compare the first 4 plans (and any plans tied with those) against the plan with all sampled variables and the default plan. We set the timeout to 300 seconds. We measure the accuracy by the Mean Squared Error of the posterior expected value of the variable compared to its ground truth value, which is available as all data were generated by sampling from the prior. For each benchmark, we compute the speedup each inference plan achieves compared to the default plan to reach the target accuracy, defined as the 90th percentile of error by the default plan using the greatest particle count evaluated that did not timeout. Following Atkinson et al. [2022] and Baudart et al. [2020], reaching target accuracy is defined as $log(P_{90\\%(loss)}) \u2013 log(loss_{target}) < 0.5$. We also compute the summary statistics of the increase in accuracy each plan achieves compared to the default plan with less than or equal runtime. We conduct experiments on a 60-vCPU Intel Xeon Cascade Lake (up to 3.9 GHz) node with 240 GB RAM."}, {"title": "5.2.2 RQ2 Methodology", "content": "To determine SIREN's analysis precision for RQ2, we enumerated all satisfiable and unsatisfiable inference plans, and measured if the inference plan satisfiability analysis correctly determines the satisfiability of each plan."}, {"title": "5.3 Results", "content": "Across all benchmarks, variables, and inference algorithms, using the best inference plans produces an average speedup of 1.76x to reach the same target accuracy compared to the default plans, with a maximum speedup of 206x. The best inference plans achieve 1.83x better accuracy with equal or less runtime compared to the default plans, with a maximum increase of 595x. See Appendix F for the breakdowns for each benchmark.\nFor each particle count, we plot the median runtime to the 90th percentile of error for each variable using different satisfiable inference plan. For the plots of the remaining algorithms and benchmarks, see Appendix F."}, {"title": "RQ2 Results", "content": "To evaluate the analysis precision for RQ2, we run the analysis on all 11 benchmarks and 3 inference algorithms. We manually count"}, {"title": "Aliasing", "content": "The loss of precision in SLDS executed with SSI is due to aliasing. When joining expressions in conditionals and fold fixpoint computations, the analysis loses information. This introduces an aliasing problem because inconsistent branch conditions are not detected. This is illustrated in the following program,\nwhere cond and obs are constants. Because cond and ! cond are inconsistent branch conditions and the else-branches are both constants, in any execution SSI only needs a conjugacy relation for either x1 or var1. Such a single-variable conjugacy relation always exists, so annotating both x1 and var1 symbolic will not throw an error in any execution. However, the analysis approximates the observed Gaussian distribution as $N(X_{x1}, X_{var1})$, meaning that the distribution is potentially depending on both x1 and var1, which would require a conjugacy relationship for both variables simultaneously. SSI does not support this, so the analysis concludes that SSI may throw an error when in fact no such error-throwing execution exists. This problem manifests in SLDS with SSI but does not affect any other benchmarks."}, {"title": "Widening Expressions", "content": "In SLAM with SSI, the analysis widens abstract expressions to UnkE (Srv) when the expression tree depth is over the preset threshold because large symbolic expressions can be computationally expensive. It also widens UnkE (Sr) to Tope when the number of variables in \u015ary is over the preset threshold to hasten the convergence of the fixpoint computation during a fold because \u015ary can grow indefinitely large. However, the TopE expression is not precise enough for the analysis to"}]}