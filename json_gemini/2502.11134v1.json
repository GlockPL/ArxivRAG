{"title": "Solving Online Resource-Constrained Scheduling for Follow-Up Observation in Astronomy: a Reinforcement Learning Approach", "authors": ["Yajie Zhang", "Ce Yu", "Chao Sun", "Jizeng Wei", "Junhan Ju", "Shanjiang Tang"], "abstract": "In the astronomical observation field, determining the allocation of observation resources of the telescope array and planning follow-up observations for targets of opportunity (ToOs) are indispensable components of astronomical scientific discovery. This problem is computationally challenging, given the online observation setting and the abundance of time-varying factors that can affect whether an observation can be conducted. This paper presents ROARS, a reinforcement learning approach for online astronomical resource-constrained scheduling. To capture the structure of the astronomical observation scheduling, we depict every schedule using a directed acyclic graph (DAG), illustrating the dependency of timing between different observation tasks within the schedule. Deep reinforcement learning is used to learn a policy that can improve the feasible solution by iteratively local rewriting until convergence. It can solve the challenge of obtaining a complete solution directly from scratch in astronomical observation scenarios, due to the high computational complexity resulting from numerous spatial and temporal constraints. A simulation environment is developed based on real-world scenarios for experiments, to evaluate the effectiveness of our proposed scheduling approach. The experimental results show that ROARS surpasses 5 popular heuristics, adapts to various observation scenarios and learns effective strategies with hindsight.", "sections": [{"title": "1. Introduction", "content": "Astronomical sky surveys, the primary avenue for exploring the universe, have generated numerous scientific breakthroughs [1, 2]. Observation scheduling constrained by time-varying observation conditions and shared limited resources is a crucial problem for survey observation, using a telescope array with multiple telescopes. The visibility of celestial objects changes in real time and the lifetime of expensive astronomical observation equipment is limited [3]. So efficient observation scheduling and resource management are conducive to maximizing scientific output. Making follow-up observations for targets of opportunity (ToOs) in sky surveys refers to gathering additional data to further understand specific transient phenomena of great scientific interest identified during the initial survey [4]. It requires the use of various instruments and specific filters as astronomers are committed to unveil more details, enhancing the comprehensive exploration of the cosmos.\nThe complexity of the astronomical observation task scheduling problem has been proved to be NP-hard [5]. The difficulty of solving resource-constrained task scheduling for online follow-up observations optimally is rooted in its intricate nature. In the process of time-domain sky survey, it is a kind of closed-loop scheduling to deal with ToOs that appear suddenly. The multi-band follow-up scheduling algorithm needs to deal with the uncertainty of resource availability (including observable time limited by observation conditions, telescope filters, etc.), target properties (arrival time, duration, and requirements for observation band, exposure time and observation mode), etc. Note that these target priority constraints are determined by astronomers for scientific discovery after the target appears, and there are no prior probability distributions. Specifically, incoming follow-up observation targets have various precedence relations and observation band requirements, often requiring simultaneous observations by multiple telescopes with different filters across bands, as illustrated in Fig. 1. As the Earth rotates, the visibility of each target changes over time. The observation time window of the target is affected by the positions of the observation sites and the target and changes with time, which is an important computational challenge in our scheduling problem. Through observation sites that distributed around the world, different ToOs can be coordinated observation. Careful consideration of execution order and time-varying constraints is essential for coordinated and timely observations. In distributed telescope array environment, the variance in available observation time across sites, coupled with potential competition for target observations due to their distribution, presents greater challenges to the execution of observation plans [6]. The majority of these issues are addressed using integer linear programming (ILP) and meticulously designed heuristics. For example, the Zwicky Transient Facility allocates survey fields to time blocks, minimizing the need for filter changes and ensuring precise control over the number of exposures per field [7]. Similar optimization objectives are considered for the Large Synoptic Survey Facility using genetic algorithms [8]. Moreover, heuristic methods are widely employed for solving this problem within the astronomical field, e.g., lowest airmass [9], smallest telescope slew angle [10], for finding optical counterparts to transients. However, for practical large-scale survey observation, determining when and where to apply these heuristics, and establishing their prioritization, is both inflexible and time-consuming. In addition, meta-heuristic algorithm has been used for agile earth observation satellite scheduling problem [11], but there are significant differences in the observation modes of satellites and telescopes.\nRevisiting the above challenges, given the problem scale and computational complexity, we investigate the use of reinforcement learning (RL) approaches for this real-world resource-constrained scheduling problem. RL benefits from abundant training data generated by repetitive scheduling decisions in astronomical observation systems, allowing for effective learning. Meanwhile, RL has the capability to model intricate systems and decision-making strategies through deep neural networks, akin to the architectures employed for gaming agents [12]. This is achieved by integrating various input signals to enable online application in stochastic environments [13]. However, the application of RL-based scheduling to astronomical observation domains is not straightforward given the lack of well-suited model and benchmark. The processing of high-priority follow-up tasks and the efficient generation of observation plans during the survey are essential to the guarantee of astronomical discoveries. Therefore, as the key to developing effective observation resource allocation plans, the effective acquisition astronomical observation knowledge and observation modeling are pressing issues that demand urgent attention.\nTo our knowledge, the combination of online resource management, astronomical follow-up ToO observation and telescope array is not considered in the literature so far. So in this paper we contribute by, first, defining and modeling the real-world resource-constrained scheduling problem in telescope array setting, considering both multiple telescopes in one observation site (we call intra-site) and geographically distributed in multiple sites. Second, we propose a new approach to tackle the problem using deep reinforcement learning (DRL), named ROARS, for a Reinforcement learning approach for Online Astronomical Resource-Constrained Scheduling. A directed acyclic graph (DAG) is used to extracts the problem-specific knowledge and model the temporal dependency of the problem. High quality solutions with different sizes and structures are learned by iteratively refining [14] existing solutions towards optimality using DRL. Because the approach of obtaining a complete solution directly from scratch, as employed in previous similar works [13, 15, 16], becomes challenging to achieve feasibility when scaling up the observation scheduling. Here we focus on online setting where the follow-up observation tasks arrive dynamically with unpredictable constrains and cannot be preempted once scheduled. The proposed ROARS is evaluated through extensive simulations performed on real-world data. Our preliminary results show that ROARS is able to generate solutions of consistent quality in various astronomical observation scenarios, thereby facilitating robust and rapid schedule adaptation amidst uncertainty. The quality of schedules generated by ROARS can exceed those of the heuristic baselines and offline scheduling scenarios, where the entire observation task sequence is known prior to scheduling. The approach can also be extended to distributed telescope array observation environments with robustness performance."}, {"title": "2. Related Work", "content": "Resource scheduling and optimization problems, pervasive and fundamental issues in complex system, have been extensively studied from both theoretical and empirical perspectives [17, 18]. There are numerous studies demonstrating effective use of DRL in several real-world resource scheduling scenarios, such as smart manufacturing [19], city-wide firefighting [20], steel production [21, 22], resource provisioning in Internet of Things ecosystem [23, 24], logistics and retail [21]. Existing studies demonstrate that RL exhibits effectiveness in terms of the solution quality, and can achieve substantial time savings compared to the classical heuristic approaches [25]. Therefore, DRL is extensively investigated as an effective approach for controlling complex systems.\nDespite the clear need, there is an absence of research undertaken in the area of intelligent astronomical observation resource allocation for telescope array. Nowadays, resource allocation and management methods in most astronomical survey observation projects can be divided into two types, based on ILP algorithms [26, 27] and human-generated heuristics [4]. Nevertheless, with the increase of the number of telescopes and observation targets, especially in the environment of telescope array observation, fine-scale observation strategy optimization requires extensive manual intervention, which exceeds the ability of conventional planning algorithms and classical solvers. For the observation environment using a distributed telescope array, a flexible multilevel global scheduling model is proposed for a generic telescope array scheduling problem by Zhang et al. [3]. While their algorithm produces long-term scheduling solutions in survey observation mode, it does not undertake precise resource coordination for follow-up observations of ToOs. Jia et al. implements a telescope array observation simulator and applies DRL into a space debris observation scenario [6]. But since publication, there is currently no established general approach for resource management in online follow-up astronomical observation using an array of multiple telescopes.\nThe follow-up observation scheduling problem in astronomy can be seen as a special resource-constrained project scheduling problems (RCPSP [28]). In order to achieve the robust scheduling [29, 30], researchers propose multiple heuristic and meta-heuristic procedures to allocate time buffers in a given schedule while ensuring adherence to a predefined project due date [31]. By contrast, inserting time buffers in a proactive way to deal with scheduling uncertainties is not in line with the principle of telescopic observation, because the telescope is expensive and has limited life, observation time is a very valuable resource. Li et al. develop efficient approximate dynamic programming (ADP) algorithms for RCPSP with uncertain task duration, using constraint programming and a hybrid ADP framework to enhance performance and efficiency [32]. Brvcic et al. address the issue of inflexibility in proactive-reactive scheduling by introducing threshold-based cost functions for deviation penalties in projects with stochastic task duration [33]. While Xie et al. focus on RCPSP with uncertain resource availability [34], they use a new Markov decision process model and a rollout-based ADP algorithm, significantly improving performance over heuristic methods. Compared with these traditional problems, the problem of RCPSP in time-domain survey to be solved in this paper focuses more on fast processing of special targets to ensure their observation quality, rather than maintaining the stability of the original tasks.\nWith the development of deep learning technology in recent years, one research [13] presents an example solution that transforms the problem of packing tasks with diverse resource demands into a learning problem. The resource allocation strategies are directly learned from experience. However, it only considers a single-cluster situation, and factors such as the dependency between jobs have not been investigated. Another research [35] relies on the graph neural network to address RCPSP of varying sizes, including in presence of uncertain task duration. Cai et al. further solves the RCPSP with resource disruptions, and uses proximal policy optimization (PPO) to train the model in an end-to-end way for performance optimization [36]. Their work is relevant for us, but for the follow-up observation scenario in astronomical domain, scheduling strategies should consider real locations of telescopes, distributions of observation targets, and filter requirements. The constrained observation conditions are closely related to these time-varying factors. Therefore, the current industrial scheduling methods are difficult to be directly applied in the field of astronomical observation.\nIn other recent work, the local rewriting is proposed for combinatorial optimization [14], the performance is assessed across three distinct domains: online job scheduling, expression simplification, and vehicle routing. It has shown better performance than heuristics using multiple metrics in solving complex problems where generating an entire solution directly is challenging. Given its effectiveness in capturing hierarchical and sequential structures, and order constraints [37], the Child-Sum Tree-LSTM architecture is well-suited for the dynamic and complex nature of resource scheduling in astronomical observations. So it is clear that despite a lack of exploration into a general intelligent resource management approach in the astronomical observation domain, the existence of mature and extensive research supports the exploration as a feasible approach for tackling the application challenges."}, {"title": "3. Follow-up observation scheduling in astronomy", "content": "In this section, the problem setting and parameters are presented first, followed by its MDP formulation, which lays the foundation for our ROARS algorithm to be developed in the succeeding sections.\n3.1. Problem statement\nFormally, the resource-constrained scheduling problem for follow-up observations in astronomy can be defined by a tuple (M, N, R) where: M represents a set of ToOs that have been identified for key follow-up observations; N is a set of observation sites, which can include one or multiple geographically distributed observation sites, each equipped with multiple telescopes; R is a set of resource types, which represents the types of observation bands (filters) configured at each site. Detailed parameter descriptions and notations are presented in Table 1. We suppose to have an astronomical observation environment with d types of filters. All sites have a full set of filters R, each telescope providing one. Tasks with different filters can overlap on the same site, maximizing telescope resource use.\nNote that the follow-up observation monitoring for target i, can be performed by a group of observation tasks K with different numbers according to its required single exposure time. Each observation task j of target i can be specified as $v_j = (f_i, A_j, e_i)$. It is worth noting that the band requirements and exposure time are the same for each exposure (i.e. observation task) of each target, so $f_j$ and $E_j$ are equal to $f_i$ and $E_i$ respectively. $A_j$ denotes the required beginning observation time of task j. We assume that the above properties of each follow-up target is known upon arrival, and are not dependent on the site. Note that in this paper, ToOs are preprocessed, divided into observation tasks based on the observation mode. We operate under the assumption that observation tasks arrive at the telescope array in real-time, at discrete intervals. A waiting task queue is available, capable of accommodating up to W tasks. When a new follow-up observation task is received, it can be promptly assigned or added to a queue. If the queue reaches its capacity, scheduling the new task requires the immediate execution of at least one task in the waiting queue to accommodate the incoming task. W can be adjusted based on the practical observation scale. Additionally, we assume a fixed filter requirement throughout the entire execution of the observation tasks, with no allowance for preemption.\n3.2. Observation impact factors\nThere are various of time-varying features that influence the feasibility and quality of the observation. This paper utilizes airmass [38] as the evaluation metric to determine whether a telescope is suitable for observing a target. The airmass measures the atmospheric thickness through which astronomical light passes before reaching the telescope, which is influenced by zenith angle, altitude, atmospheric conditions, and etc. Lower airmass observations are preferred in astronomy for better image quality and less atmospheric distortion [9]. Meanwhile, the optical radiation from the sun will also affect the resolution and clarity of the observations to some extent, so the sun's position and radiation need to be taken into account as well. The relative location of the observation site and the target, and the observation time determine the astronomical observation conditions, which vary with time. Hence, these spatial and temporal constraints significantly increase the computational cost of resource allocation calculations.\n3.3. MDP formulation\nTherefore, the follow-up observation scheduling for ToOs can be modeled as an MDP with the following components.\n3.3.1. Stages\nThe decision stages are the time periods at which observation scheduling decisions are made. Let t denote the time period (stage) and T be the set of all time periods.\n3.3.2. States\nState of the system S, encompasses all relevant information at decision stage t. According to the above assumptions and definitions, the states of the system at any time t can be defined by: current time t, the current time in the scheduling horizon, current availability of observation sites, visibility window and observation quality of tasks, exposure requirements.\n3.3.3. Decisions\nAt each decision stage, the following decisions need to be made (defined as the solution): target selection, which observation task j to observe, which site s to use for the observation, and when to start the observation $B_j$. So it can be formulated by a binary decision variable $x_{s,j,f,t} \\in \\{0, 1\\}$ indicating whether site s is assigned to observe task j in band f at time t.\n3.3.4. Astronomical objectives and cost function\nSwiftly addressing the incoming follow-up observation tasks in astronomical science is crucial for timely capturing transient celestial events and phenomena. Because the rapid response enables scientists to gather critical data, facilitating real-time analysis and enhancing the chances of making groundbreaking discoveries in the dynamic and evolving cosmos. Therefore, we adopt the average task slowdown as the primary optimization objective. Formally, for each observation task j of target i, it can be defined as:\n$\\eta_j = \\frac{C_j - A_j}{E_i}$ (1)\nwhere $A_j$ and $B_j$ denote the required beginning observation time and scheduled beginning observation time, respectively. And $C_j = B_j + E_i$ is the task completion time. The objective function to minimize the sum of slowdowns for all tasks can be written as:\n$min \\sum_{j \\in K} \\eta_j = min \\sum_{j \\in K} \\frac{(B_j + E_i) - A_j}{E_i}$ (2)\nNormalizing the completion time by the observation task's exposure time mitigates potential bias towards lengthy observations, a situation that may arise when optimizing for objectives like mean completion time. The value of $\\eta$ is \u2265 1. Therefore, our focus is on developing a schedule that minimizes the overall task slowdown by assigning follow-up ToO observations to telescopes equipped with the necessary filters, while adhering to the constraints of observation conditions. That means to get $B_j$ closer to $A_j$, the slowdown $\\eta$ closer to 1.\nThe cost-to-go function $J_t(S_t)$ represents the minimum expected cost from stage t to the end of the planning horizon, given the current state $S_t$. Based on the decision $x_{s,j,f,t}$, the state transition function describes how the state evolves from $S_t$ to $S_{t+1}$ can be formulated as $f(S_t, x_{s,j,f,t})$.The immediate cost $g(S_t, x_{s,j,f,t})$ represents the cost incurred at stage t due to decision $x_{s,j,f,t}$. The cost-to-go function at stage t is recursively defined as the immediate cost plus the expected cost-to-go from the next stage onward [39]:\n$J_t(S_t) = min_{x_{s,j,f,t}} [g(S_t, x_{s,j,f,t}) + E[J_{t+1}(S_{t+1})|S_t, x_{s,j,f,t}]]$ (3)"}, {"title": "4. A RL approach: ROARS", "content": "4.1. Graph representation\nBased on the above problem definition, the online resource-constrained follow-up observation scheduling problem is solved by a reinforcement learning based approach named ROARS, depicted in Fig. 3. Each schedule is depicted as a DAG, illustrating the interdependence of observation task scheduling times. In this representation, each observation task $v_j$ corresponds to a node in the DAG of scheduling, with an additional node $v_0$ representing the observation telescope. If an observation task $v_j$ is scheduled upon arrival at time $A_j$ (i.e., $B_j = A_j$), we include a directed edge $(v_0, v_j)$ in the graph. Alternatively, there must exist at least one task $v_{j'}$ such that $C_{j'} = B_j$ (meaning task j begins immediately after task j'). We include an edge $(v_{j'}, v_j)$ for each such task $v_{j'}$ in the graph.\nFor the follow-up observation task embedding, in intra-site telescope array setting with D kinds of resources (filters), we embed each task into a vector of dimension (D\u00d7($E_{max}$+1) + 1). Here, $E_{max}$ represents the maximum exposure duration for an observation task. For distributed telescope array, it will be a (N \u00d7 D \u00d7 ($E_{max}$ + 1) + 1)-dimensional vector, N denotes the number of observation sites. This vector encodes details about task attributes and the observation site's status during task execution. The specifics of the task embedding are outlined below. Consider a task $v_j = (p_j, A_j, E_i)$ for target i. We represent the total resources utilization across all takes at each time step t as $p' = (p_1, p_2, \u2026, p_D)$. Taking intra-site observations as an example, each observation task $v_j$ is represented as a (D x ($E_{max}$ + 1) + 1)-dimensional vector, where the first D dimensions of the vector are $p_j$, representing its observation resource requirement. The D \u00d7 $E_i$ dimensions of the vector are the concatenation of $p'_{B_j}, p'_{B_j+1}, \u2026, p'_{B_j+E_i-1}$, which describes the utilization of the observation resources during the execution of the task $v_j$. Specifically, when the energy consumption $E_i$ is less than the maximum allowed energy $E_{max}$, the subsequent D \u00d7 ($E_{max}$ - $E_i$) dimensions are set to zero. The final dimension of the embedding vector signifies the task's slowdown in the current schedule. Each task $v_j$ is represented by its embedding denoted as $e_j$. Additionally, the embedding of the observation telescope, denoted as $v_0$, is represented by a zero vector, $e_0 = 0$.\n4.2. Model specification and rewriting\nAfter constructing the graph representation, we train a neural-based policy to iteratively refine the current scheduling solution by locally rewriting parts of it until convergence. This approach draws inspiration from [14]. We employ the end-to-end reinforcement learning to train the policy, encouraging the cumulative enhancement of the solution. For the telescope observation scheduling problem, finding a feasible solution that meets the constraints of observation time and geographical location is straightforward. Additionally, the search space displays favorable local structures that facilitate incremental enhancements to the solution. Thus, a comprehensive solution offers a contextual basis for enhancement through a rewriting-based approach, facilitating the computation of additional features, a challenge when generating a solution from scratch. Various solutions may converge towards optimization through a shared pathway, which could be encapsulated as local rewriting rules. Furthermore, straightforward rules such as task swapping could enhance performance. These aspects enable the application of the rewriting formulation to diverse instances of follow-up observation scheduling. We can train the neural network to investigate relationships among diverse solutions within the search space. Our rewriting strategy incorporates a region-selection policy and a rule-selection policy.\nEach solution represents a state, and every local region, along with its corresponding rewriting rule, acts as an action. Algorithm 1 describes steps for a single rewriting. The rewriting rules involve relocating the present task $v_j$ to be positioned as a child of another job $v_{j'}$ or $v_0$ within the graph. This results in scheduling observation task $v_j$ to commence either after task $v_{j'}$ concludes or at its arrival time $A_j$. As depicted in Fig. 3, $s_t$ represents the dependency graph of the observation task schedule. Each circle with an index greater than 0 denotes a task node, while node 0 serves as an additional representation of the observation site. The graph's edges denote the observation dependencies among follow-up tasks. The region-picking policy chooses a task $w_t$ from all task nodes for rescheduling, while the rule-picking policy determines a movement action $u_t$ for $w_t$. Afterwards, $s_t$ is modified to obtain a new dependency graph $s_{t+1}$.\nLet U be the rewriting rule set, shown in Fig. 3. Assume that $s_t$ represents the current solution (or state) at iteration t. Firstly, a state-dependent region set $\u03a9(s_t)$ is computed, which is problem-dependent, and covers all follow-up observation task nodes for scheduling. We then select a region $\u03c9_t \u2208 \u03a9(s_t)$ using the region-picking policy $\u03c0_\u03c9(\u03c9_t | s_t)$. For each $\u03c9_t \u2208 \u03a9(s_t)$, we calculate a score $Q(s_t, w_t)$, which reflects the potential benefit of rewriting. A higher score suggests that rewriting $s_t[\u03c9_t]$ may be advantageous.\nAfterwards, a rewriting rule $u_t$ is selected for the region $\u03c9_t$ using the rule-picking policy $\u03c0_u(u_t | s_t[\u03c9_t])$, where $s_t[\u03c9_t]$ denotes a subset of the state $s_t$. The chosen rewriting rule $u_t \u2208 U$ is then applied to $s_t[\u03c9_t]$, resulting in the subsequent state represented as $s_{t+1} = f(s_t, w_t, u_t)$. The rewriting sequence in the forward pass can be denoted as\n$s_T = (s_0, (\u03c9_0, u_0)), (s_1, (\u03c9_1, u_1)), \u2026, (s_{T-1}, (\u03c9_{T-1}, u_{T-1}))$. (6)\nHence, commencing with an initial solution (or state) $s_0$, our aim is to discover a sequence of rewriting steps $s_T$ that minimizes the final cost $c(s_T)$.\nNote that we both use fully connected neural networks for the prediction of region score and selection of a rewriting rule.\n4.3. Training details\nOur region-picking policy $\u03c0_\u03c9$ and rule-picking policy $\u03c0_u$ are trained in the meantime. The reward function of training can be defined as $r(s_t, (w_t, u_t)) = c(s_t) - c(s_{t+1})$. For $\u03c0_\u03c9$, we express the parameterization as a softmax function of the $Q(s_t, w_t; \u03b8)$:\n$\\pi_{\\omega} (\\omega_t | s_t; \\theta) = \\frac{exp (Q (s_t, \\omega_t; \\theta))}{\\sum_{\\omega_l} exp (Q (s_t, \\omega_l; \\theta))}$ (7)\nThe training of $Q(s_t, w_t; \u03b8)$ involves aligning it with the cumulative reward obtained from the present learning policies $\u03c0_\u03c9$ and $\u03c0_u$:\n$L(\\theta) = \\frac{1}{T} \\sum_{t=0}^{T-1} \\big( \\sum_{t'=t}^{T-1} \\gamma^{t'-t}r (s_{t'}, (w_{t'}, u_{t'})) - Q (s_t, \\omega_t; \\theta) \\big)^2$ (8)\nHere, T represents the episode length, indicating the count of rewriting steps, while \u03b3 signifies the decay factor. Regarding the rule-picking policy, we employ the advantage actor-critic mechanism, leveraging $Q(s_t, \u03c9_t; \u03b8)$ as the critic. This approach mitigates bootstrapping-related issues that may arise from sample insufficiency and training instability. The advantage function can be represented as:\n$\\Delta(s_t, (w_t, u_t)) = \\sum_{t'=t}^{T-1} \\gamma^{t'}r (s_{t'}, (w_{t'}, u_{t'})) - Q (s_t, \\omega_t; \\theta)$ (9)\nThe loss function of the rule selector can be represented as:\n$L_u(\\phi) = - \\frac{1}{T} \\sum_{t=0}^{T-1} \\Delta(s_t, (w_t, u_t)) log \\pi_u (u_t | s_t[w_t]; \\phi)$ (10)\nMoreover, we denote the overall loss function as $L(\u03b8, \u03c6) = L_u(\u03c6) + \u03b1L_\u03c9(\u03b8)$, where \u03b1 serves as a hyperparameter.\nDuring the training process, \u03b1 is set to 10. The numbers of region picking and rule picking are both 15 for intra-site telescope array, while both 30 for distributed array, which are sufficient for figuring out a competitive scheduling solution. The hyperparameter specifying the total number of rewriting steps is set to 100 iterations. For all tasks in our evaluation, suppose the probability of re-sampling the region for rewriting is 1 \u2013 pc, pc starts with a initial value of 0.5, and is gradually decayed by 0.8 every 1000 time steps until it reaches a minimum value of 0.01, at which point it remains constant. We set the decay factor for the cumulative reward to \u03b3 = 0.9, and the initial learning rate to 1e-4, which is then decayed by a factor of 0.9 every 1000 time steps. Furthermore, we maintain a fixed batch size of 128 during training. The model is optimized using the Adam, with all weights initialized uniformly randomly within the range of [-0.1, 0.1]."}, {"title": "5. Experiment", "content": "The tested algorithms were implemented in Python. In our evaluation, the neural networks are implemented using PyTorch [41]. All implementation and experiments were performed on an Ubuntu server featuring a 4-core Intel Xeon CPU (clocked at 2.2 GHz), 32 GB of memory, and a Tesla V100 GPU.\n5.1. Setup\nWe conduct experiments on simulated data based on various scenarios in real-life settings to investigate the effectiveness of ROARS in terms of solution quality, computational speed, robustness and scalability. We develop a simulator environment to model the observations of both intra-site and distributed telescope arrays, including the diverse conditions, telescope states, and follow-up targets for telescope arrays to test the algorithm under varied settings. These conditions act as constraints, aiding in determining available resources for a target at a given time. As shown in Fig. 4, we select 5 real observation sites worldwide to simulate the formation of the telescope array. The position of the ToOs are generated from 100 sky fields with the configuration parameters described later. In addition, we simulate the arrival of ToOs within 4 hours. Since different ToOs have varying observation requirements and need to be monitored over a period of time, the generated instances are based on a collection of observation tasks according to the duration and exposure time required by the ToOs. The simulator serves for both model training and evaluation. Note that the coordinate of the targets and observation sites are collected from real observations. According to the configuration of the real telescope array under construction, we use u, g and i bands as possible filter requirement inputs. In addition, We generated one hundred thousand follow-up observation task sequences randomly, allocating 80% for training and reserving 10% each for validation and testing. The waiting task queue length, denoted as W, is fixed at 10. Initial schedules were generated using the First Come First Serve (FCFS) method, known for its low overhead during construction.\n5.1.1. Evaluation metric.\nAccording to the actual astronomical observation needs, we utilize the average task slowdown $\u03b7_j = (C_j - A_j) / E_i$ as the evaluation metric. It is preferred that follow-up observation tasks be handled as soon as possible after arrival.\n5.1.2. Task properties.\nIn order to adequately test the robustness and generalization of ROARS, various observation task properties are evaluated: (1) Average arrival rate of ToOs: the probability of a new ToO arrival, the Steady task frequency sets it to be 10% (because normally targets that need to be followed up in the sky survey observation are in the minority), and Dynamic task frequency indicates that the ToO arrival rate varies randomly at each time step; (2) Duration of the follow-up observation: the time from the beginning when the opportunity target requires observation monitoring to the end, Long for the time duration requirement of the target is in [120, 240] minutes, Short for [60, 119] minutes, and Non-uniform task duration; (3) Resource distribution: observation tasks might have different resource requirements, we consider Uniform resource as the ToO selects two of the three possible resources with the same probability to observe simultaneously, while Non-uniform refers to simultaneous observations of one, two or three of bands required with 10%, 20% and 30% probability, respectively; (4) Single exposure time: length of each observation task, Long means single exposure time is in [10, 20] minutes, Short for [1, 9] minutes, and Non-uniform exposures; (5) Observation mode: the two ways to make a series of sequential observations in astronomy, one is to perform observations that follow immediately on from one another (Exposure count), the other is to monitor the target with required Cadence.\n5.1.3. Baselines on heuristics.\nFor intra-site telescope array scenarios, we implement 5 online heuristic approaches that are popular in existing machine scheduling and RCPSP problems for comparison. Shortest Task First (STF) allocates the tasks with the shortest exposure time in the waiting task queue at each time step. First Come First Serve (FCFS) schedules each observation task in the increasing order based on the arrival time. Earliest Due Date (EDD) schedules the observation tasks with the earliest end time. Shortest Processing Time (SPT) prioritizes targets with the shortest duration (from the time required to start monitoring to its fade) to be monitored. And Resource Intensity Priority schedules the target with the highest resource requirements first. In this paper, resource demand intensity is defined as the number of required observation resource types multiplied by the total exposures. In addition, we have also tried to employ the optimal solver (e.g. Gurobi [42] and CBC [43]) for the problem in this context, but both seem intractable in general. Therefore, we omit the comparison.\nFor scenarios of distributed observation sites, heuristically obtaining a feasible solution is more complicated. It involves two steps of selecting the follow-up task and selecting the site, so we correspondingly design the following baselines. We make heuristic site selections based on equipment priority factor and observation quality, which are what astronomers tend to do in the current study. In practical observations, the equipment priority factor for each site is usually related to the weather changes, which can be predicted or obtained in real time. Here we use the airmass of each schedule to represent the observation quality, while generate the equipment priority factor of each site randomly as input. It should be noted that ROARS has not been specifically optimized for these two parameters. The heuristic baselines are Shortest Task best Quality site First (SQTF), Shortest Task best Priority site First (SPTF), First come Task best Quality site First (FQTF), First come Task best Priority site First (FPTF), shortest Processing best Quality site First (PQTF), shortest Processing best Priority site First(PPTF), earliest Due Task best Quality site First (DQTF), earliest Due Task best Quality site First (DPTF), Shortest Task best Quality site First (RQTF), and Shortest Task best Quality site First (RPTF).\n5.1.4. Baselines on offline scheduling.\nIn order to evaluate the effectiveness of these algorithms, we examine an offline scenario where the complete task sequence is known beforehand. This is equivalent to simulating an unbounded waiting task queue. This setting, with additional prior knowledge, serves as a strong baseline for evaluation. We utilize STF-offline, a basic heuristic approach that schedules tasks in ascending order of duration."}, {"title": "5.2. Result comparison", "content": "Our first experiment compares the solution quality in terms of the average slowdown and computation time, as demonstrating in Table 3. In this experiment, training and testing instances are with steady task frequency, observation mode with cadence, non-uniform duration of follow-up task observation (20% long, 80% short), non-uniform resource distribution, and non-uniform single exposure time (20% short, 80% long). We conduct the experiments on one thousand different instances and average the results. It can be seen that ROARS outperforms both online heuristic baselines and the offline approach. It is more time-efficient than STF, EDD, and Offline. For the solution quality, ROARS can achieve nearly a 50% improvement compared to STF and SPT, which are the better performing heuristics. The average slowdown of Offline approach is comparable to that of ROARS, but is much more time-consuming. The Offline approach takes the knowledge of the entire incoming task sequence into account, which is helpful but costs larger time for analysis.\n5.2.1. Results on generalization of various distributions.\nOur second experiment evaluates the proposed ROARS on different distributions of the incoming ToO observation tasks. As shown in Fig. 5, we perform ablation experiments in different scenarios for each property. We can observe that for"}]}