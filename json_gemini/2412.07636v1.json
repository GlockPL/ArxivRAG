{"title": "TrojanWhisper: Evaluating Pre-trained LLMs to Detect and Localize Hardware Trojans", "authors": ["Md Omar Faruque", "Peter Jamieson", "Ahmad Patooghy", "Abdel-Hameed A. Badawy"], "abstract": "Existing Hardware Trojans (HT) detection methods face several critical limitations: logic testing struggles with scalability and coverage for large designs, side-channel analysis requires golden reference chips, and formal verification methods suffer from state-space explosion. The emergence of Large Language Models (LLMs) offers a promising new direction for HT detection by leveraging their natural language understanding and reasoning capabilities. For the first time, this paper explores the potential of general-purpose LLMs in detecting various HTs inserted in Register Transfer Level (RTL) designs, including SRAM, AES, and UART modules. We propose a novel tool for this goal that systematically assesses state-of-the-art LLMs (GPT-40, Gemini 1.5 pro, and Llama 3.1) in detecting HTs without prior fine-tuning. To address potential training data bias, the tool implements perturbation techniques, i.e., variable name obfuscation, and design restructuring, that make the cases more sophisticated for the used LLMs. Our experimental evaluation demonstrates perfect detection rates by GPT-40 and Gemini 1.5 pro in baseline scenarios (100%/100% precision/recall), with both models achieving better trigger line coverage (TLC: 0.82-0.98) than payload line coverage (PLC: 0.32-0.46). Under code perturbation, while Gemini 1.5 pro maintains perfect detection performance (100%/100%), GPT-40 (100%/85.7%) and Llama 3.1 (66.7%/85.7%) show some degradation in detection rates, and all models experience decreased accuracy in localizing both triggers and payloads. This paper validates the potential of LLM approaches for hardware security applications, highlighting areas for future improvement. Trojan Whisper's HT detection results will be available here https://github.com/HSTRG1/TrojanWhisper.git.", "sections": [{"title": "I. INTRODUCTION", "content": "The globalization of the semiconductor supply chain has created significant security vulnerabilities through the potential insertion of Hardware Trojans (HTs) - malicious modifications inserted by rouge threat actors or rouge Computer-aided design (CAD) tools to integrated circuits (ICs) that can leak information, alter functionality, degrade performance, or deny service [1]. This security challenge is particularly acute for System-on-Chip (SoC) designers who, faced with time-to-market pressures and resource constraints, increasingly rely on third-party Intellectual Property (3PIP) cores and outsourced design services. These 3PIPs come in three distinct forms: Soft IPs (RTL code in Verilog/VHDL), Firm IPs (synthesized netlists and placed RTL blocks), and Hard IPs (GDSII files and physical layouts)."}, {"title": "", "content": "Early detection of HTs in Soft RTL IPs is crucial, as remediation becomes exponentially costlier in later design stages. This issue is challenging in commercial IP cores, where identifying malicious modifications within thousands of lines of RTL code is formidable [2]. Manual inspection is inadequate for large-scale designs, as RTL HTs blend with legitimate functionality and can evade conventional verification through carefully crafted activation conditions. The taxonomy of Shakya et. al. [1] highlights the spectrum of RTL HTs, from simple to highly sophisticated mechanisms with extremely low activation probabilities (6.4271e-23), emphasizing the need for automated and scalable detection methods."}, {"title": "", "content": "HT detection methods before this can be categorized into four main approaches. Test pattern generation methods [3] attempt to expose HTs through test vectors but cannot guarantee the detection of stealthily triggered HTs. Formal verification approaches [4], [5] convert designs into proof-checking formats but suffer from state explosion and limited detection scope due to predefined properties. Code analysis techniques like FANCI [6] and VeriTrust [7] examine RTL code using coverage metrics but require manual analysis and can be bypassed by sophisticated HTs, as DeTrust [8] demonstrated. Machine learning (ML) and graph matching approaches have shown promise, with methods ranging from graph similarity [9] and control-flow matching [10] to neural networks [11] and gradient boosting [12]. However, these approaches typically require golden references, extensive feature engineering, or suffer from limited generalization to new RTL designs and HT types. Graph Neural Network (GNN) approaches like GNN4TJ [2] have improved detection capabilities but still face scalability and novel HT detection challenges."}, {"title": "", "content": "The limitations of existing approaches motivate our investigation of Large Language Models (LLMs) for more robust and automated HT detection. Given the scarcity of labeled HT datasets, their ability to reason about hardware security implications without extensive domain-specific training data or golden reference designs is crucial [13]."}, {"title": "", "content": "In this paper, we present Trojan Whisper, a novel LLM approach for HT detection in RTL designs (to the line-level granularity) that leverages state-of-the-art LLMs (GPT-40, Gemini 1.5 pro, and Llama 3.1) through carefully crafted prompts encoding hardware security domain knowledge. According to our assessments, LLMs offer unique advantages in HT"}, {"title": "", "content": "detection: 1) They can process RTL code in its native form; 2) Understand structural and semantic properties without explicit feature engineering. Our key contributions include: \u2460 To the best of our knowledge, it is one of the first systematic evaluations of LLMs for HT detection; \u2461 A novel LLM HT signature generation engine for HT detection; \u2462 Comprehensive evaluation metrics for assessing LLM HT detection; 4 A novel perturbation engine that validates detection robustness through code transformations while maintaining functional equivalence and synthesizability; \u2464 Empirical comparison with existing detection methods."}, {"title": "II. BACKGROUND ON RTL HT", "content": "HTs at the RTL level represent malicious modifications to the behavioral hardware description that define a circuit's operation and data flow [1]. Unlike gate- or layout-level HTs that manipulate physical circuit elements, RTL HTs operate at a higher abstraction level by altering the behavioral specification of the design using Hardware Description Languages (HDL) like Verilog or VHDL."}, {"title": "", "content": "As defined by Shakya et. al. [1], these modifications manifest themselves in two fundamental components: a trigger mechanism and a payload. The trigger can be implemented through conditional statements that activate under specific circumstances (e.g., when certain internal states or input patterns occur). These time-based counters activate after a predetermined number of cycles or always-on conditions. The payload, embedded within the RTL code, can manipulate control signals, modify data paths, or introduce unintended state transitions, potentially leading to three primary malicious effects identified in their comprehensive HT taxonomy:"}, {"title": "\u2460 Functionality Change HT (Type 1):", "content": "Once triggered, these HTs modify the circuit's intended behavior by altering or corrupting outputs or computations."}, {"title": "", "content": "In this Functionality change HT code snippet [14] in Listing 1, the HT triggers when it detects the specific byte pattern 0xAB (lines 3-9). Once triggered, the payload inverts all subsequently received data until the module is rested (lines 12-13), thus corrupting the UART receiver's functionality."}, {"title": "\u2461 Information Leakage HT (Type 2):", "content": "These HTs create covert channels to leak sensitive data. An example case of Information Leakage HT [14] is shown in Fig. 1 (b), the HT activates when address \u2018ADDR' (0xAA) is read repeatedly (lines 2-8). The payload leaks memory contents by returning data from sequential memory locations (indexed by 'mn')"}, {"title": "", "content": "instead of the requested address (lines 11-15), creating a covert channel to leak the SRAM contents."}, {"title": "\u2462 Denial of Service HT (Type 3):", "content": "These HTs aim to degrade or disable hardware functionality, making it partially or entirely unusable."}, {"title": "", "content": "As shown in the code snippet in Listing 2, the Denial of Service HT (example taken from [14]) triggers when it detects a specific pattern in the input 'state' (plaintext) and 'key' (lines 3-9). When the counter 'pq' reaches 0xFF, the payload blocks the initial XOR operation of the AES encryption (lines 11-18), effectively denying the encryption service."}, {"title": "III. PROPOSED METHODOLOGY", "content": "Our research methodology consists of three main components: A HT Signature Generation Engine, B Perturbation Generation Engine, and LLM HT Detection Engine, which will be discussed in the following subsection."}, {"title": "A. HT Signature Generation Engine", "content": "We propose an iterative HT signature generation and ranking methodology that systematically learns detection patterns from the Trust-Hub [15] dataset $D = {(C_i, T_i, M_i)}$, comprising clean RTL code $C_i$, HT-infected code $T_i$, and metadata $M_i$. Our multi-stage pipeline employs an LLM through function $L(C_i, T_i, M_i)$ to extract HT signatures $P = {P_1, P_2, ..., P_m}$ for both trigger mechanisms and payload patterns. These signatures undergo refinement $R(P) \\rightarrow S'$ using similarity metric $\\phi (p_x,p_y) > 0$, where similar signatures are merged and generalized to improve cross-variant detection."}, {"title": "", "content": "Each signature $s'_i$ undergoes validation through $V(s'_i)$ against a separate validation set $D_{val}$, producing performance vectors $v_j = [\\alpha_j, \\beta_j, \\gamma_j]$ that capture detection rate, false positive rate, and generalization capability. A ranking system $W(v_j)$ assigns weights $w_j$ based on these metrics, creating an ordered set $S = {(s_1, W_1), ..., (s_q, W_q)}$. The system implements continuous improvement through an iterative process $I(S, F)$, analyzing failure cases to refine existing signatures. To address emerging threats, our system incorporates a zero-day detection mechanism $N(Z)$ that analyzes novel HT patterns $Z$ and generates corresponding signatures $S_{new}$, where $S^{t+1} = S^t \\cup {s_{new}}$. This creates a dynamic, hierarchical signature database that continuously adapts to new threats while maintaining high detection reliability through systematic validation and ranking."}, {"title": "B. Perturbation Generation Engine", "content": "Our perturbation engine powered by an LLM agent addresses a challenge in LLM HT detection: the potential overlap between open-source HT RTL designs and the models' training data. This overlap could lead to unreliable detection results based on memorization rather than understanding hardware security principles. The engine implements a systematic approach to code transformation while maintaining functional equivalence and synthesizability. At its core, the framework applies three key transformation strategies."}, {"title": "\u2460 Variable name obfuscation:", "content": "First, it performs comprehensive variable name obfuscation, replacing meaningful identifiers with arbitrary combinations of letters while preserving module interfaces and port names. This tests the LLMs' understanding of circuit functionality independent of descriptive naming conventions."}, {"title": "\u2461 Addition of synthesizable redundant logic:", "content": "It then introduces additional synthesizable logic structures, including redundant registers and alternative combinational implementations, which challenge the models to maintain accurate detection despite these variations."}, {"title": "\u2462 Restructuring:", "content": "Lastly, it restructures state machines and control logic while preserving original functionality, testing the models' comprehension of behavioral equivalence. Critically, all transformations adhere to strict synthesizability constraints, ensuring modified designs remain implementable in hardware."}, {"title": "C. LLM HT Detection Engine", "content": "The LLM detection engine combines HT signature-based identification with in-context learning for HT analysis. The engine first applies the detected HT signatures derived from our HT Signature Generation Engine to identify potential trigger mechanisms and payload patterns in the RTL code. These detection HT signatures, generated through systematic analysis of HT characteristics, help pinpoint suspicious circuit elements and behavioral patterns. The engine employs an in-context learning approach for HT classification by providing type-specific examples and attributes for each HT category (functionality modification, information leakage, and denial of service). The system processes RTL designs through this two-stage analysis: first applying detection HT signatures to identify the presence of HTs and locate suspicious components, then using contextual understanding to classify the type of identified HTs. Results are structured as XML outputs detailing the number of potential detected HTs, their identified trigger/payload components, and HT categorization."}, {"title": "IV. EVALUATION METRICS", "content": "Our evaluation framework employs a set of metrics to assess three aspects of HT detection in RTL IP cores: \u2460 core detection capabilities, 2 line localization precision, and \u2462 HT category classification accuracy. These metrics provide a detailed, multi-dimensional evaluation of agent performance across various levels. Our test dataset consists exclusively of HT-infected RTL modules with no HT-free designs. However, our line-level approach allows for an effective"}, {"title": "", "content": "evaluation, as most of the codebase represents clean design code, creating a \"negative\" class for detection. The following subsections describe these metrics."}, {"title": "A. HT Detection Metrics", "content": "HT detection metrics are based on classification methods to evaluate the agent's ability to detect HTs at the RTL IP core level (Verilog file). Therefore, we call these broad metrics to determine whether an agent detects hidden HTs. We will describe the True Positives, False Positives, and False Negatives for these metrics from the perspective of how good the agent is classifying the existence of an HT where the number of HTs in a design is set to the parameter k."}, {"title": "1) True Positives (TP):", "content": "Count of successfully detected (either trigger or payload signatures Fig. 1 (a)) HTs. For example, if a module contains 4 HTs (k = 4) and the agent detects all 4, TP = 4. TP requires correct identification of triggers (such as specific signals or states for activation) or payloads (like malicious modifications to signals or information flows)."}, {"title": "2) False Positives (FP):", "content": "Instances where clean RTL code is mistakenly flagged as containing HTs. For example, if the agent claims to find 6 HTs in code with a k = 4 in the actual design, FP = 2 (indicating two false alarms). Lowering FP reduces unnecessary investigations, enhancing efficiency."}, {"title": "3) False Negatives (FN):", "content": "HTs that are present in the RTL but missed by the agent. If there are 4 HTs and only two are identified, FN = 2, indicating missed detections that can lead to security risks."}, {"title": "", "content": "We provide these factors as a tuple {k, #TP, #FP, #FN} such that the closer the 2nd number is to k and the lower #FP and #FN suggest the tool is better. Note that there is no true negative classification at this granularity level since the benchmarks entirely consist of HT-infected RTL designs."}, {"title": "B. Localization Precision Metrics", "content": "Localization precision provides a line-by-line analysis of the agent's ability to classify Verilog RTL Lines-of-Code (LoC). These metrics describe how accurately the agent identifies specific HT lines (which include a distinction between the payload and trigger) in the code. In this regard, we note that when compared to the structural netlist implementations, RTL behavioral designs do not have a simple one-to-one relationship. A single line of RTL code can correspond to many nodes within the structural netlist. Similarly, inferred structures such as Finite State Machines (FSMs) and inferred memories in synthesizable Verilog might result in non-obvious LoC mappings. Because of these, this classification approach describes an agent's capability of detection but is pinpoint accurate as an identification of HTs."}, {"title": "", "content": "Our confusion matrix for this purpose is defined by TRUE-NESS reflecting the correct classification and POSITIVENESS indicating whether a line has the presence of an HT or not."}, {"title": "Trigger Line Coverage (TLC):", "content": "Assesses how accurately the agent identifies the precise RTL lines of code related to the HT trigger. TLC is a percentage calculated by\n$TLC = \\frac{LOCTP_{trigger}}{LOCTP_{trigger} + LoCFP_{trigger}}$ (1)"}, {"title": "Payload Line Coverage (PLC):", "content": "Measures the agent's accuracy in identifying specific LoC related to HT payloads, calculated similarly to TLC.\n$PLC = \\frac{LOCTP_{payload}}{LOCTP_{payload} + LoCFP_{payload}}$ (2)"}, {"title": "Accuracy of Classification (AC)", "content": "is a measure of how accurate the agent is and is calculated as\n$AC = \\frac{LoCTP_{payload} + LoCTP_{trigger} + LoCTP_{clean}}{LOC}$ (3)"}, {"title": "", "content": "The final metric, AC, provides a summary value, allowing us to compare the quality of LLM detection between systems."}, {"title": "C. HT Category Classification Accuracy Metric", "content": "Our last metric evaluates how effective the agent is at providing a deeper understanding of what the HT is doing based on the known taxonomy of HTs."}, {"title": "HT Category Classification Accuracy (TCCA)", "content": "measures the LLM's ability to classify an HT correctly. Taking Type-2 (Information Leakage) HTs as an example, TCCA evaluates both correctly classified Type-2 HTs and false positives where non-Type-2 HTs or legitimate components are incorrectly classified as Type-2. In a design with six Type-2 HTs (k = 6), if the LLM detects and correctly classifies 4 Type-2 HTs but also incorrectly flags 2 (either other HT types or legitimate circuits) as Type-2, the TCCA_Type2 would be 4/(4+2) = 66.7%."}, {"title": "V. EXPERIMENTAL RESULTS", "content": "We use Icarus Verilog (version 11.0) to ensure functional equivalence of the obfuscation designs with the original implementation, confirming that our obfuscation techniques preserve the intended circuit behavior. Our main system components are built in a Python 3.10.14 environment with the core LLM interactions handled through multiple API interfaces: OpenAI's GPT-40 API, Google's Generative AI SDK (version 0.8.3) for Gemini 1.5 Pro, and the Groq Client library for LLama3.1. Environment management uses python-dotenv (1.0.1) for secure API key handling, while XML processing relies on the ElementTree library from Python's standard library."}, {"title": "A. Performance Evaluation", "content": "Our experimental results are presented in two tables: Table III shows detection performance without obfuscation/perturbation, and Table IV presents results with these techniques"}, {"title": "", "content": "applied. We first calculated the individual row metrics (HT1, HT2, HT3 Cases) using only the samples of that particular HT type - for instance, HT1 cases consider only the 4 Type-1 HTs, with their detection performance tuple {k = 4, TP, FP, FN} and corresponding TLC, PLC, AC, and TCCA metrics computed for just these samples. We then considered all HT samples together rather than averaging across HT types for the aggregate metrics. For the detection performance tuple k, TP, FP, FN, we summed the total number of HTs (k=14) across all samples, along with the total number of true positives (TP), false positives (FP), and false negatives (FN) identified across all samples. Similarly, for metrics like TLC, PLC, AC, and TCCA, we considered the total correctly identified lines or HT-type classifications across all 14 samples divided by the total number of relevant lines or HT-type classifications, rather than taking the average of the three category-specific metrics."}, {"title": "\u2460 Baseline Case:", "content": "In the baseline evaluation shown in Table III, GPT-40 and Gemini 1.5 demonstrate perfect detection rates, successfully identifying all 14 HTs without any FPs or FNs in their aggregate performance. Llama 3.1, while"}, {"title": "", "content": "detecting all true HTs, generated four FPs in HT2 test cases, resulting in a performance tuple of {14, 14, 4,0}. For localization precision, GPT-40 achieved the highest trigger line coverage (TLC) of 0.98, though its payload line coverage (PLP) was lower at 0.32. Gemini 1.5 showed more balanced but slightly lower localization metrics with TLC of 0.82 and PLP of 0.46. The AC is strong across all models, with GPT-40 achieving 0.92, Gemini 1.5 at 0.89, and Llama 3.1 maintaining 0.87, indicating robust performance in correctly identifying clean versus HT-infected code. However, the HT classification accuracy (TCCA) varied significantly across models, with GPT-4o achieving 0.714, followed by Gemini 1.5 at 0.571, and Llama 3.1 at 0.444, suggesting that while overall detection and classification accuracy (line) was robust and precise categorization of HT types remains challenging."}, {"title": "\u2461 Perturbed Case:", "content": "The introduction of obfuscation techniques (Table IV) provides a more reliable assessment of true detection capabilities by mitigating potential training data advantages. Here, we see different performance across models. Gemini 1.5 maintained a perfect detection rate with an ideal performance tuple of {14, 14,0,0} even under obfuscation. In contrast, Llama 3.1's and GPT-40's performance showed some degradation, particularly in HT2 cases where both the agents missed two HTs (FN=2). All models experienced decreased trigger line coverage (TLC), with GPT-40 dropping to 0.86 from 0.98, Gemini 1.5 to 0.73 from 0.82, and Llama 3.1"}, {"title": "Generalization vs. Memorization:", "content": "Gemini 1.5 pro's ability to maintain perfect detection performance even under obfuscation (while other models degraded) demonstrates that LLMs can perform HT detection beyond a simple comparison with"}, {"title": "B. Comparison with other Detection Methods", "content": "Compared to existing approaches in the literature, as shown in Table VI, our LLM-based method using Gemini 1.5 pro achieves superior performance with 100/100% (Precision/Recall) detection rate while providing HT localization capabilities. Among neural network-based approaches, GNN variants show strong but varying performance - GCN [18] achieves 98.9/88.4% with localization support, while Topology-GNN [19] and basic GNN [2] achieve 93.35/91.38% and 92/97% respectively without localization capabilities. Language-based methods and recent gradient boosting approaches demonstrate high effectiveness, with NLP-based methods [17] reaching 97.94/97.77% and decision-tree gradient boosting [16] achieving 99/98%, both supporting localization. Graph-theoretical approaches show mixed results - network analysis [20] achieves 98/98% with localization support, while graph matching [10] and graph isomorphism [23] report 100% recall but lack localization capabilities. Traditional machine learning methods like gradient boosting [12] and ML-Immune [21] show varying performance (100% and 87/85% respectively), while flow analysis [22] achieves perfect recall but with significantly longer processing time (292.85s). While our LLM approach has a relatively higher processing time of 10.91s compared to some newer techniques, it offers a better balance of detection accuracy and localization capability."}, {"title": "C. Limitations", "content": "Most of the limitations of this work have to do with those imposed by using LLMs. These issues include token count impacting scalability, which limits the handling of larger designs (a possible workaround could be partitioning larger designs). The probabilistic behavior of LLMs imposes non-determinism, HT signatures leaking out, and potential circumvention. The perturbation engine is implementing basic code transformations. A small sample of benchmark RTL designs to test our ideas on. The cost for running locally vs. the risks of using the cloud and risk privacy for critical designs."}, {"title": "VI. CONCLUSION AND FUTURE WORK", "content": "This work represents one of the first systematic investigations into leveraging LLMs for HT detection in RTL designs. Our experimental results reveal three critical findings. First, Gemini 1.5's perfect precision/recall (100%/100%), even"}, {"title": "", "content": "under obfuscation, demonstrates LLMs' ability to detect HTs beyond simple historical HT design memorization. Second, we identified a detection-localization gap: models maintain good precision/recall in detecting HT presence (Gemini 1.5 pro: 100%/100%, GPT-40: 100%/85.7%, Llama 3.1: 66.7%/85.7%) but struggle with precise localization under obfuscation (TLC: 0.72-0.86, PLC: 0.20-0.33). Finally, the consistently high detection rates (especially of Gemini 1.5 pro and GPT-40) validate LLM approaches as a promising complement to existing HT detection methods while highlighting areas for improvement in localization precision and HT categorization."}, {"title": "", "content": "Future work will focus on increasing the dataset to include more designs and either better obfuscate or include designs outside the scope of a trained LLM. This will help clarify whether the agents themselves provide the measured capabilities as emergent skills or the transformer focuses on variations from statistical HDL designs."}]}