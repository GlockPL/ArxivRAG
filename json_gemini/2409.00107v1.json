{"title": "Evaluating the Impact of Multiple DER Aggregators on Wholesale Energy Markets: A Hybrid Mean Field Approach", "authors": ["Jun He", "Andrew L. Liu"], "abstract": "The integration of distributed energy resources (DERs) into wholesale energy markets can greatly enhance grid flexibility, improve market efficiency, and contribute to a more sustainable energy future. As DERS such as solar PV panels and energy storage proliferate, effective mechanisms are needed to ensure that small prosumers can participate meaningfully in these markets. To address this, the Federal Energy Regulatory Commission (FERC) in the U.S. issued Order 2222 in 2020, to enable DERs to aggregate and participate in wholesale markets alongside traditional resources. However, detailed mechanisms are still under development, and there remains uncertainty about which approaches are most effective for ensuring small-scale participation.\nIn response to this challenge, we study a wholesale market model featuring multiple DER aggregators, each controlling a portfolio of DER resources and bidding into the market on behalf of the DER asset owners. The key of our approach lies in recognizing the repeated nature of market interactions the ability of participants to learn and adapt over time. Specifically, Aggregators repeatedly interact with each other and with other suppliers in the wholesale market, collectively shaping wholesale electricity prices (aka the locational marginal prices (LMPs)). We model this multi-agent interaction using a mean-field game (MFG), which uses market information reflecting the average behavior of market participants to enable each aggregator to predict long-term LMP trends and make informed decisions. Unlike traditional game models, where the strategies of all individual agents must be considered, the mean-field approach focuses on the collective impact, simplifying the decision-making process.\nFor each aggregator, because they control the DERs within their portfolio under certain contract struc- tures, we employ a mean-field control (MFC) approach (as opposed to a MFG) to learn an optimal policy that maximizes the total rewards of the DERs under their management. This approach accounts for various uncertainties, such as solar output variability, demand fluctuations, and LMP dynamics, allowing aggregators to learn how to better manage their resources and optimize their market participation strategies.\nThe innovation of our work lies in the combination of a hybrid MFG and MFC approach, which allows for the scalable modeling of multiple DER aggregators interacting within a wholesale market. This hybrid approach effectively captures both the decentralized decision-making of individual aggregators and their collective impact on market dynamics. We also propose a reinforcement learning (RL)-based method to help each agent learn optimal strategies within the MFG framework, enhancing their ability to adapt to market conditions and uncertainties. Unlike descriptive models that merely outline market participant behavior, our model is prescriptive, designed for control automation. With the installation of grid edge devices running our RL algorithms, market participants can automatically achieve the market outcomes described in this paper.", "sections": [{"title": "1 Introduction", "content": "The growing adoption of distributed energy resources (DERs), such as solar photovoltaic (PV) panels and en-ergy storage systems, will lead to significant changes in the dynamics of electricity markets. Once considered peripheral, these resources are now central to discussions about enhancing grid flexibility, improving market efficiency, and promoting sustainability. The FERC Order 2222 [1] issued in 2020 recognizes the potential of DERs to improve grid reliability and economic efficiency and encourages the participation of DERs in wholesale energy markets, allowing them to compete alongside traditional power resources. However, it also introduces significant challenges, particularly in ensuring meaningful participation for small-scale prosumers those who both produce and consume electricity.\nWhile the FERC order lays the groundwork for DER-integration into wholesale markets, the detailed mechanisms are still under development, with different RTOS/ISOs proposing different approaches. There remains uncertainty about which approaches are most effective for integrating these resources into market operations. Current research predominantly focuses on how a single aggregator manages its portfolio of DER assets, often assuming that the whole energy prices (aka the locational marginal prices (LMPs)) are exogenously given and remain unaffected by the aggregator's actions. These models typically optimize the aggregator's strategy to maximize rewards based on these fixed LMPs, without considering the feedback loop between the aggregator's decisions and market prices.\nIn contrast, our work addresses a more complex setting where multiple aggregators operate within the same market, each capable of influencing LMPs endogenously. In this setting, the aggregators are engaged in a non-cooperative game, which we model as a mean field game (MFG). An MFG is a game-theoretic framework used to study the behavior of a large number of interacting agents whose decisions are influenced by the average behavior of the group. In an MFG, each agent, like an aggregator, optimizes its own strategy based on both its individual objectives and the 'mean field,' which represents the average effect or state of all agents in the market. This allows each agent to account for how their actions, combined with those of many others, impact key market outcomes like prices.\nAnother innovation in our approach is that within each aggregator, we employ a mean field control (MFC) approach, as opposed to a centralized optimization, to manage the portfolio of DERS. MFC focuses on finding a policy for a representative agent (the mean field) that, when applied across all agents, optimizes the overall collective outcome, rather than solving a complex optimization problem for each individual DER owner. This approach reflects a cooperative framework (in contrast to the non-cooperative interactions among different aggregators in an MFG), where the DER assets are treated as if they are working together to maximize their collective rewards. The MFC method is more scalable than centralized optimization and is well-suited for incorporating reinforcement learning (RL) techniques. This allows the aggregator to learn and adapt to uncertainties such as solar output variability, demand fluctuations, and LMP dynamics, ultimately developing optimal bidding strategies over time."}, {"title": "2 Wholesale Market Model and Locational Marginal Prices", "content": "In this section, we present a wholesale energy market model. Consider a power system network with M buses, L transmission lines, and G generators. Each bus $m \\in \\{1, ..., M\\}$ serves $N_m$ household agents, consisting of $N^p_m$ prosumers and $N^c_m$ consumers. Each generator $g\\in \\{1,...,G\\}$ has an associated cost function $C_g(.)$. Since each generator is linked to a specific bus, let $G_m \\subset \\{1, ..., G\\}$ denote the set of generators located at bus m. Clearly, $\\bigcup_{m=1}^M G_m = \\{1, ..., G\\}$ and $G_m \\cap G_{m'} = \\emptyset$ for any distinct $m, m' \\in \\{1, ..., M\\}.\nLet $t \\in \\{1,2,...\\}$ represent the timestep, with each timestep corresponding to a fixed time interval, such as an hour. At each time t, an aggregator at bus m collects the bids (which are determined through the MFC approach to be described in the next section) from all the agents under its management and submits the aggregated bids to the system operator. For prosumers, the specific quantity $d^i_{mt}$ represents the net demand, defined as the prosumer's demand minus the solar output from their own solar panel outputs. If $d^i_{mt} \\geq 0$, it indicates net energy demand; if $d^i_{mt} < 0$, it represents net supply.\nTo avoid (unrealistic) scenarios where the net energy supply from prosumers exceeds the total demand of all pure consumers, we assume that the total demand of all agents (both prosumers and consumers) in the system is always greater than or equal to the total PV generation from all prosumers across all M buses."}, {"title": "3 Aggregators' Problem \u2013 A Two-Phase Learning Approach", "content": "In this section, we consider the problem faced by aggregators managing DERs, specifically prosumers with photovoltaic (PV) panels and energy storage systems. Aggregators develop strategies to optimally charge and discharge these storages under their control using RL algorithms. The RL algorithm employed here is sophisticated, involving a two-phase learning approach. The key elements in presenting the algorithm are listed below.\nTime: At each timestep t = 0, 1, 2, ..., each aggregator performs reinforcement learning using algorithms such as Proximal Policy Optimization (PPO), Trust Region Policy Optimization (TRPO), Soft Actor-Critic (SAC), and others for $T_{train}$ steps. We use $\\tau = 1,2,...,T_{train}$ to denote training timesteps, during which aggregators learn a policy. The actual play phase involves submitting bids and calculating LMPs, and these two phases are detailed in Section 4.\nM\nProsumers: We consider a total of N heterogeneous prosumers in this game, where $N = \\sum_{m=1} N_m$. Each prosumer i is assigned a fixed type $\\theta \\in \\Theta$ throughout the game, where $\\Theta$ is a finite set. Prosumers of the same type $\\theta$ share the same net demand distribution, bus location, and reward function. For simplicity, we assume all prosumers at the same bus have the same type, which differs across buses. Thus, the set $\\Theta$ corresponds to the set of buses $\\{1, ..., M\\}$.\nAggregators: The assumption of prosumer types allows us to designate an aggregator as a \"representa- tive\" for each type. In our setup, each bus has one aggregator who employs an RL algorithm for all prosumers at that bus. Let $H_{im}$ denote the storage capacity of the i-th prosumer at bus m. The aggregator for bus m thus has a total storage capacity of $I_m = \\sum_{i=1}^{N_m} H_{im}$. This is the essential idea of the MFC approach as described in [3], which significantly reduces computational costs since typically $|\\Theta|$ is much less than N.\nLMP Beliefs: Let H be the total number of timesteps in one day. Define two mappings: h(\u00b7) and k(\u00b7), which map the time index to the corresponding timestep of the day and the day index, respectively. In our case, $h(t) = t \\mod H$ and $k(t) = \\lfloor t/H\\rfloor$. Each aggregator maintains its own belief about the LMPs for each timestep of the day, represented as a vector of length H. Let $\\hat{\\Lambda}_{mt} \\in \\mathbb{R}^H$ denote the LMP belief of Aggregator m at time t. After the system operator solves the economic dispatch problem, the aggregator is updated with the new LMP $\\Lambda_{mt}$ for its bus and updates its belief according to:"}, {"title": "4 The Two-Phase RL Algorithm", "content": "We now propose a two-phase distributed mean-field RL algorithm based on the setup above. The algorithm comprises two phases: the training phase, where each aggregator trains its policy using RL algorithms for a specified number of steps, and the actual play phase, where all prosumers use their aggregators' trained policies and submit their bids to the system operator to solve an economic dispatch problem and update the LMPs. The algorithm is presented in Algorithm 1.\nTraining Phase: At each time t, each aggregator fixes its LMP belief and performs RL using an algorithm such as PPO, TRPO, SAC, etc., for $T_{train}$ steps."}, {"title": "5 Numerical Experiment", "content": "In this section, we conduct numerical experiments to analyze market behavior under the mean-field game framework described earlier."}, {"title": "5.1 Test Case", "content": "We utilize the 37-bus synthetic network from [9], which corresponds to the geographical layout of the Hawaiian island of Oahu. We modify this case by mapping each power plant from Hawaiian Electric [10] to its nearest bus. After modification, the network comprises a total of 26 generators: 4 oil, 2 biomass, 17 (grid-scale) solar, and 3 wind generators. We assume quadratic cost functions for all oil and biomass generators, applying coefficients from [11], [12] to these respective generator types. The ranges for these coefficients are presented in Table 1. Additionally, the generation cost for solar and wind generators is set to zero, with actual outputs adjusted by a capacity factor based on weather conditions. Let (a, b, c) denote a triangular distribution with lower limit a, upper limit b, and mode c. In our simulation, we assume that solar generation follows"}, {"title": "5.2 Results", "content": "We employ PPO as the learning algorithm and set $T_{train} = 3,600$, with H = 12 (corresponding to 2-hour timesteps). The simulation is run for a period of 50 days and repeated 5 times using different random seeds.\nThe experiments were conducted on a Windows 11 system equipped with a 13th Gen Intel(R) Core(TM) i7-13700KF (24 cores) and NVIDIA GeForce RTX 4070. Figures 2, 3, and 4 display the hub prices, storage levels and charging/discharging actions, and renewable generators' capacity factors, respectively.\nAdditionally, to study the impacts of energy storage coupled with the RL algorithms on LMP volatility, we adopt the incremental mean volatility (IMV) measure from [16] as the metric. We also compare the average cumulative ex-post cost (the product of the bidding quantity and the real-time LMP) across all"}, {"title": "5.3 Discussion", "content": "Our results indicate that prosumers can learn strategies to charge when prices are low and discharge when prices are high using our algorithm. As shown in Figure 2b, hub prices stabilize towards an equilibrium, and prosumer actions illustrated in Figure 3b align with a mean-field equilibrium (MFE). Some fluctuations are observed at the 9th timestep in a day, likely due to variations in the solar/wind capacity factor. Since prices are determined by the next cheapest generator available to supply an additional unit of power, fluctuations in renewable capacity factors can lead to increased or decreased reliance on non-renewable sources, making prices sensitive to small changes in charging/discharging actions. Overall, our model demonstrates the potential for mitigating extreme price swings and fostering a more stable market environment under decentralized decision-making."}, {"title": "6 Conclusion", "content": "In this paper, we propose a decentralized, mean-field-based model where aggregators make informed charging and discharging decisions on behalf of the prosumers they manage. These decisions are guided by LMPs in a wholesale energy market, which encapsulate information about aggregate demand, supply dynamics, and network constraints. Additionally, we introduce a two-phase learning algorithm within the hybrid MFC and MFG framework, leveraging RL to iteratively learn optimal policies for aggregators while facing various uncertainties from renewable output, demand fluctuations, and evolving market dynamics.\nOur numerical experiments suggest that the proposed approach can achieve convergence to an MFE, where both the aggregators' strategies and the LMPs stabilize. Additionally, comparisons between scenarios with and without energy storage show that integrating energy storage with our RL-based algorithms can effectively reduce extreme LMP volatility, promoting a more stable market environment under decentralized, aggregator-led decision-making. This approach also provides cost benefits to consumers by optimizing the use of energy storage.\nFuture work will focus on providing a theoretical foundation for our model, specifically proving the convergence of the two-phase RL algorithm to an MFE. Additionally, we plan to explore the use of different RL algorithms to further enhance performance under various market conditions."}]}