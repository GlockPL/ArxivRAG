{"title": "Differentially Private Multimodal Laplacian Dropout (DP-MLD) for EEG Representative Learning", "authors": ["Xiaowen FU", "Bingxin WANG", "Xinzhou GUO", "Guoqing LIU", "Yang XIANG"], "abstract": "Recently, multimodal electroencephalogram (EEG) learning has shown great promise in disease detection. At the same time, ensuring privacy in clinical studies has become increasingly crucial due to legal and ethical concerns. One widely adopted scheme for privacy protection is differential privacy (DP) because of its clear interpretation and ease of implementation. Although numerous methods have been proposed under DP, it has not been extensively studied for multimodal EEG data due to the complexities of models and signal data considered there. In this paper, we propose a novel Differentially Private Multimodal Laplacian Dropout (DP-MLD) scheme for multimodal EEG learning. Our approach proposes a novel multimodal repre- sentative learning model that processes EEG data by language models as text and other modal data by vision transformers as images, incorporating well-designed cross-attention mechanisms to effectively extract and integrate cross-modal features. To achieve DP, we design a novel adaptive feature-level Laplacian dropout scheme, where randomness allocation and performance are dynamically optimized within given privacy budgets. In the experiment on an open-source multimodal dataset of Freezing of Gait (FoG) in Parkinson's Disease (PD), our proposed method demonstrates an approximate 4% improvement in classification accuracy, and achieves state-of-the-art performance in multi- modal EEG learning under DP.", "sections": [{"title": "I. INTRODUCTION", "content": "Electroencephalography (EEG) is a novel tool for real- time brain activity monitoring [1] which bears significant advantages in portability, non-invasiveness, and high temporal resolution [2]. In particular, EEG is often used in clinical settings in diagnosing and monitoring various neurological conditions, including the detection of abnormal sleep patterns [3], the identification and management of epilepsy [4], the assessment of attention deficit hyperactivity disorder (ADHD) [5], and moreover, the evaluation of Parkinson's disease (PD) [6]. Despite the wide applications of EEG data, the analysis of it might suffer from issues induced by low signal-to-noise ratios and non-stationarity. To address these issues, deep learn- ing techniques have shown considerable promise [7]-[10]. Besides, advances in multimodal data acquisition technologies enable comprehensive collections of various physiological signals, thereby improving model accuracy by integrating richer data inputs [11], and multimodal deep learning has demonstrated significant potentials in FoG detection with EEG data [12]. Research on multimodal EEG deep learning has laid the groundwork for exploring complex interactions between brain functions and related physiological activities [13]. Despite these advances, the accuracy of some current methods re- mains insufficient for reliable clinical application, and the integration of multimodal data is not yet state-of-the-art [13]. There is considerable potential for improving techniques for multimodal integration to enhance their effectiveness and robustness. In this paper, we propose a novel approach for multimodal EEG learning, treating EEG data similarly to natural language in language models like BERT and handling other modalities as images in Vision Transformers (ViT). We also introduce cross-attention decoders to extract cross- modal features, and consider privacy protection to ensure the security of sensitive clinical data, which is commonly ignored in previous multimodal EEG studies [13]. Privacy protection is crucial in multimodal EEG studies due to the sensitive nature of the clinical data involved [14]. There exist critical needs for robust privacy-preserving schemes that safeguard private information without compro- mising performance, and differential privacy (DP) [15] stands out as a widely adopted one. DP ensures that the inclusion or exclusion of any single individual data has minimal impact on the outcome of data analysis, thereby limiting the ability of adversaries to infer personal information from aggregated datasets. Various approaches within the DP framework have been proposed, primarily categorized into two streams: DP- SGD [16] and feature-level perturbation [17]. Adding noise to gradients through the established DP-SGD method [16], [18] is less feasible for large-scale models due to the in- creased computational and memory overhead for the large number of parameters, as well as the risk of destabilizing the training process with excessive noise. In contrast, feature- level perturbations [19]-[21], which add noise directly to features extracted via deep learning models, offer a more straightforward and explicit approach. In the context of feature-level privacy protection with DP, some research considers using standard dropout techniques combined with Laplacian noise [17], [19]. However, there is a notable research gap in applying feature-level DP specifically to multimodal EEG data due to the complexity and sensitivity of neurological information. In particular, whereas dropout can be advantageous by preventing attackers from inferring feature values and making it difficult to determine if a feature is dropped, existing methods that apply a uniform dropout rate across all features [17] may not provide optimal obfuscation, especially where attackers test it extensively. To this end, we propose to assign an element-wise dropout rate to each feature to accommodate the scenario that some features may be more critical for performance [22]-[24] or contain highly sensitive information [25]. Further, both dropout and adding Laplacian noise to the feature induce randomness in order to protect pri- vacy, so we consider a dual scheme with element-wise dropout rate and Laplacian noise scale to optimize the performance under given privacy budget, which is an improvement of traditionally sequential privacy budget calculations of dropout and Laplacian noises addition. In this paper, we introduce a novel approach called Laplacian dropout with DP, which involves adaptive randomness allocation to both element-wise dropout and Laplacian noise addition. These parameters are automatically optimized to maximize performance within a given total privacy budget. During training, we utilize a two- step minimization approach for both model parameters and privacy parameters, incorporating Gumbel-Softmax [26] to optimize the privacy parameters. This method is objective- driven and offers a more intuitive privacy guarantee, setting a basis for future advancements in the field. We apply our method to freezing of gait (FoG) detection for PD diseases. PD is one of the highest ranked common neurodegenerative conditions, with its prevalence rising with age [27], [28]. Among the various symptomatic challenges it presents, FoG is particularly debilitating, affecting over two-thirds of patients in the later stages of the disease [29]. FoG is characterized by sudden and involuntary cessation of movement, which makes patients feel as if their feet are glued to the ground, and often results in falls and significantly reduce the quality of life of patients [30], [31]. Therefore, The automatic detection of FoG is crucial to ensure the safety of PD patients, and existing literature has shown that EEG is valuable in predicting FoG [32]. In the experiment, we use a multimodal EEG dataset for FoG classification [33], which includes EEG along with other physiological signals such as electromyography (EMG), electrocardiography (ECG), motion data from accelerometers (ACC) and Skin Conductor (SC). In summary, we propose Differentially Private Multimodal Laplacian Dropout (DP-MLD) for EEG Representative Learn- ing, and the framework is illustrated in Fig. 1. Our main contributions are: 1) We introduce a novel multimodal EEG learning algo-"}, {"title": "II. RELATED WORKS", "content": "This section covers the background on multimodal EEG and performance comparison on the FoG detection dataset [33], differential privacy (DP), and general multimodal deep learn- ing techniques under DP, including traditional feature-level perturbation methods that inspired our approach. Gumbel- Softmax (GS) technique is also reviewed, which is used in our training. Additionally, we compare the advantages of our method with existing approaches.\nA. Multimodal EEG\nMultimodal EEG is extensively studied across various applications, such as emotion recognition [34]\u2013[39], brain- computer interface (BCI) systems development [40]\u2013[43], epilepsy research [44]\u2013[47], Alzheimer's disease diagnosis [48]\u2013[52], and seizure detection [53]\u2013[55]. How to improve prediction accuracy of FoG in Parkinson's Disease with multimodal EEG dataset [33] is a widely dis- cussed topic. An ensemble technique is proposed and achieve an accuracy of 88.47% [56]. A proxy measurement (PM) model based on a long-short-term-memory (LSTM) network achieves an accuracy of 93.6% \u00b1 1.8% [57]. SVM and KNN with handcrafted features achieve an accuracy of 88% [58]. Multimodal DNN reaches a detection sensitivity of 0.81 and specificity of 0.88 [59]. An ensemble model comprising two neural networks (NNs) achieves optimal accuracies of 92.1% one second prior and 86.2% five seconds prior to the event [60]. However, there still exists a strong need to improve the prediction accuracy of FoG in Parkinson's Disease given the severe consequences of falls for the old people. Besides, there is a lack of consideration for privacy protection, which is especially critical when utilizing clinical datasets. This oversight highlights the need for integrating robust privacy measures in future multimodal EEG research.\nB. Differential Privacy\nDifferential Privacy (DP) is a scheme for privacy protection that if changing an individual data in the data set does not cause much change in the outcome, the adversarial may not be able to speculate the real data set as defined in Definition 1 below.\nDefinition 1: (Differential privacy, [15]) A mechanism A is said to satisfy \u03f5-differential privacy (\u03f5-DP) if for all pairs x, x\u2032 \u2208 X which differ in only one entry, and for any outcome O \u2286 range(A), we have\n$$ln(\\frac{Pr(A(x) \\in O)}{Pr(A(x') \\in O)}) < \\epsilon$$\nIn Definition 1, \u03f5 is a parameter controlling privacy leakage and is known as privacy budget. A smaller \u03f5 indicates better privacy protection at the potential cost of statistical accuracy and efficiency.\nTo achieve DP, we often need to add some amount of noise to the data or the estimate, and the amount is often determined by the sensitivity defined in Definition 2.\nDefinition 2: (Sensitivity, [15]) The sensitivity of a function \u0393 is the smallest number S(\u0393) such that for all x, x\u2032 \u2208 X which differ in a single entry,\n$$||\u0393(x) \u2212 \u0393(x')||1 \u2264 S(\u0393)$$\nwhere || \u00b7 ||1 stands for L1 norm.\nFor a random algorithm \u0393, to achieve \u03f5-DP, we often consider the Laplace mechanism in Definition 3.\nDefinition 3: (Laplace mechanism, [15]) For all function \u0393 that maps data sets to Rd, F(x) + w is \u03f5-DP, where w = {wk}k=1 is the added Laplacian noise with entry wk \u223c Lap(S(\u0393)/\u03f5), and Lap denotes a zero-mean Laplacian distribution with scale S(\u0393)/\u03f5.\nWe then introduce a property of Laplacian distribution, which will be used in our process of noise generation:\nProperty 1: If t \u223c Lap(1), then bt \u223c Lap(b).\nDP for traditional tasks has been widely studied, includ- ing count queries [61], histograms [62], and other statistical estimates [63]. Recent research on multimodal deep learning under DP, which is closest to our topic, is introduced in the next section.\nC. Multimodal Deep Learning under DP\nTraining in DP [64] can be broadly categorized into two methods: adding noise to gradients, and to extracted features [19]. As for the gradient noise injection method, the most widely used scheme is DP-SGD [16], [65], which injects noise into the gradients before each update to the model weights. Further expansion on DP-SGD includes a stateful DP mecha- nism (DP-FTRL) [66], a matrix factorization scheme based on DP-FTRL (MF-DP-FTRL) [67], etc. However, implementing DP-SGD is not straightforward when the model is large and complex.\nResearch in DP also extends to multimodal learning, an area that is rapidly gaining interest. For instance, the pri- vatization of tensor fusion in multimodal settings is ex- plored, employing techniques like CP decomposition and"}, {"title": "III. DP-MLD: MULTIMODAL LAPLACIAN DROPOUT WITH DIFFERENTIAL PRIVACY", "content": "In this section, we introduce our proposed DP-MLD for EEG representative learning, which includes a novel multi- modal EEG learning algorithm and an adaptive feature-level Laplacian dropout scheme under DP.\nA. Multimodal Representative Learning\nWe present the framework of our proposed method for handling multimodal data, which we categorize into two main modalities: EEG data xe and Other Modal (OM) data xo. In the example application to the FoG classification dataset, EEG data xe is collected via devices measuring electrical activity, while OM data xo includes ACC and SC data collected by sensors.\nWe treat EEG data as textual information, considering the inherent sequential nature of both the EEG data and text, and apply Bert [77] to extract semantic features. This approach is supported by findings suggesting that EEG signals can convey textual semantic meaning, which can be effectively extracted using large language models [78]. Whereas previous work has also explored treating EEG as images and applying models designed for image feature extraction [78], our experiments demonstrate that Bert performs better on the dataset used in this research. In contrast to previous exploration [78], which primarily focuses on single-modal EEG feature extraction, our study considers the multimodal scenario where OM data is transformed into image tensors through interpolation and reshaping. These tensors are then input into an image-based model such as ViT [79]. We also design the cross-modal feature extraction scheme, which extends beyond previous research that only considers single-modal exploration with only EEG data [78]. Our approach prioritizes configurations that demonstrate superior performance in our experiments, leading us to choose BERT, ViT, and 3-layer decoders for EEG, OM, and cross- modal feature extraction, respectively. We also explore other options, including treating EEG as an image, treating OM as text, using single-stream cross-attention modules with a 12- layer encoder and concatenated embeddings for cross-modal feature extraction, and ALBEF pretraining, which shows less efficiency.\nIn the following parts, we give a detailed introduction to some key elements of our multimodal EEG learning scheme, which includes processing EEG data as text for language mod- els and other modal data as images for vision transformers, and incorporating well-designed cross-attention mechanisms to effectively extract and integrate cross-modal features.\n1) EEG Feature Learning via Bert: Bert (Bidirectional Encoder Representations from Transformers) [77] is a transfor- mative model in natural language processing, capturing deep bidirectional context features. Building upon recent research on the application of large language models to EEG [78], which proposes that EEG signals can be processed as text or images to extract semantic features, we adopt the approach of treating EEG data analogously to textual data. We concep- tualize each EEG signal as a sequential string of information. To be specific, with the EEG signal input from differential channels xe \u2208 Rde , we apply a string transformation he to it and transform the time-series data to a string data. Then the semantic meaning of the EEG signal is extracted with a Bert-based encoder:\n$$f_e = F_{Bert}(h_e(x_e)).$$\n2) Other Modal (OM) Feature Learning via ViT: As for the other modal data, including the data from Accelerator (ACC) and Skin Conductor (SC), we denote as \"OM (other modal)\" data for short. When incorporating OM data into our analysis, we use a series of preprocessing techniques, such as interpolation and reshaping skills. These techniques enable us to effectively transform the diverse data types into a unified image tensor format. By transforming the diverse data modalities into a unified image representation, we are able to harness the power of established image models, such as Vision Transformer (ViT) [79], which have demonstrated remarkable capabilities in various computer vision tasks.\nTo be specific, the preprocessing function ho is applied to transform the raw OM data into an image tensor suitable for processing by ViT. This might involve reshaping and interpolation methods to format the data into a consistent image shape, typically H \u00d7 W \u00d7 C where H, W, and C are the height, width, and number of channels of the image, respectively. Then the image semantic of OM data is extracted with a ViT-based encoder:\n$$f_o = F_{ViT}(h_o(x_o)).$$\n3) Cross-Modal Feature Learning: In order to capture the intricate dependencies and interactions between the EEG and OM data, we propose a multimodal representative learning framework to extract interactive features from EEG and OM data, which we refer to cross-modal features. The cross-modal features are extracted via cross-attention modules, specifically a decoder. These cross-attention modules facilitate the inte- gration of the EEG and OM data by enabling cross-modal interactions. To be specific, we employ L layers decoders with a cross- attention module to extract the cross-attention feature. The cross attention layer CAl is designed in (8) with l = 1, \u00b7 \u00b7 \u00b7 , L as:\n$$C A_l = softmax(\\frac{W_Q h_o(x_o) (W_K h_e(x_e))^T}{\\sqrt{d_k}})W_V h_e(x_e),$$\nwhere in the cross-attention module, WQ is the projection matrix of query Q with OM, and WK, WV are the projection matrices of key K and value V with EEG, which follow the notations of the attention mechanism [80]. Then the cross- modal based feature is extracted with CA constructed with L layers of CA l:\n$$f_c = C A(h_e(x_e), h_o(x_o)).$$\nB. Laplacian Dropout DP Scheme\n1) Element-Wise Laplacian Dropout: We observe a high adaptability between adding Laplacian noise and dropout to achieve DP. Intuitively, dropping out some features can prevent attackers from inferring their values, even making it difficult to know whether the feature is dropped or not. Though some previous research explores adding Laplacian noise after dropout and calculating the corresponding privacy guarantee level [17], we believe that assigning the same dropout prob- ability to each feature may not ensure effective obfuscation. Indeed, an attacker could potentially infer individual features after repeated access to the algorithm. Therefore, we pro- pose incorporating element-wise randomness into our dropout design, adjusting the scale of Laplacian noise accordingly. This approach ensures that the performance is automatically optimized within the specified privacy budget.\nFormally, consider we have a k-dim feature f = (f1, . . . , fk) to be privately protected. Suppose we allocate a unique dropout rate to each of them: w = (w1, . . . , wk). For each feature fi , it suffices to first generate a mask indicator mi with a Bernoulli distribution:\n$$m_i = \\begin{cases} 0, & \\text{with probability } w_i \\\\ 1, & \\text{with probability } 1 - w_i. \\end{cases}$$\nThen the feature after dropout is f \u2299 m, where m is the indicator vector m = (m1, . . . , mk) and \u2299 means element- wise multiplication.\nWe then explore the relationship for privacy budget allo- cation between the element-wise dropout rate and Laplacian"}, {"title": "IV. EXPERIMENTS", "content": "A. Dataset Description\nWe conduct experiments on an open-source multimodal dataset of FoG in PD [33]. This dataset encompasses data from multiple sources: electroencephalogram (EEG), skin conduc- tance (SC), and acceleration (ACC), collected during walking tasks using various sensors. Twelve PD patients participated in the experiments, generating a total of 3 hours and 42 minutes of valid data. They first sort out the original data header, and unify the data sampling frequency to 500Hz. Then they segment and label the data. After this preprocess, there are 3003 datasets, each containing EEG data with 30 channels, OM data with 25 dimensions (including 24 dimensions of ACC data and 1 dimension of SC), and corresponding labels indicating the presence or absence of FoG. We split the dataset into 70% training data and 30% test data. Additionally, we use accuracy and macro-F1 score as the metrics for comparison. Accuracy measures the proportion of correct predictions out of the total predictions. Macro-F1 calculates the average F1 score across all classes, treating each class equally.\nB. Overall Performance\nThe performance comparison on the FoG dataset [33] is pre- sented in Table I, where our proposed DL-MLD demonstrates significant advantages despite the additional considerations for privacy protection. DL-MLD shows an approximate 4% improvement in accuracy with a common standard privacy budget \u03f5 = 1.0. This highlights the dual strength of our approach: enhancing performance while ensuring robust pri- vacy protection, thereby establishing a new basis for future advancements in the field. Besides, considering that while our method achieves pri- vacy protection, the related works we compare with does not consider privacy protection. Therefore, for fairness and generalization, we also propose a \u201cnon-private\u201d variant of our method, which preserves the multimodal learning scheme and removes the feature-level DP scheme. Notably, our non-private variant also shows a significant improvement, enhancing per- formance by approximately 5%. This result again underscores the effectiveness of our proposed multimodal representative deep learning scheme.\nC. Privacy Budget\nIn this section, we evaluate the performance of our proposed DP-MLD under three different privacy budgets, denoted by\n effectiveness of our method in automatically balancing dropout and Laplacian noise for every feature.\nNow we compare our method with the classical feature-level perturbation approach introduced in Section II-C and highlight the advantages of our approach in terms of implementation and privacy protection. In the classical method [17], the uniform variance of the Laplacian noise \u03f5\u2032 and the dropout rate \u03bc are set as hyperparameters. As a result, the privacy guarantee for the entire algorithm is calculated as \u03f5 = \u03bc + (1 \u2212 \u03bc) exp(\u03f5\u2032). Under this model, hyperparameters may be optimized using external techniques such as Bayesian optimization, which can be computationally expensive. Additionally, the risk of expos- ing features is relatively high due to the uniform hyperparam- eters for dropout rate and Laplacian noise scale. In contrast, our approach alters the management of privacy parameters. We ensure that the entire algorithm adheres to a predefined privacy guarantee, denoted as \u03f5. This allows each element-wise feature to dynamically decide between remaining inactive or adding noise to optimize performance within the specified privacy constraints. Our method of allocating the privacy budget be- tween dropout and Laplacian noise offers a novel perspective on privacy parameter training, rather than treating them as fixed hyperparameters. Moreover, the element-wise parameter approach provides better privacy protection compared to the uniform parameters used in the traditional method.\n2) Two-step Optimization for training: Given that the pri- vacy budget is fixed and denoted as \u03f5, the variance of Lapla- cian noise can be expressed as a function of the corresponding dropout rate w, formulated in vector form as \u03f5(w). Then the loss function is described with the general model parameters p, the dropout rate parameter w and the corresponding Laplacian noise parameter \u03f5(w):\n$$ \\min_{p,w} L(f(D; p, w, \\epsilon(w)); y). $$\nL(f(D; p, w, \u03f5(w))) represents the loss of the downstream task, where f(D) denotes the predictions made by model f on data D, and y represents the true labels. For instance, in the FoG classification task, L could be chosen as the cross-entropy loss.\nTo make the scheme more concise, we consider Property 1 of Laplacian noise. Then the feature after dropout and Lapla- cian noise perturbation can be written as fp(D) \u2299 m + \u03f5(w)t with t \u223c Lap(1). Based on the loss function and the re- formulation, we propose a two-step optimization for training the model:\nStep 1, given privacy parameters w, masking parameter m is generated with the Bernoulli distribution with (10) accordingly. Then the goal is to optimize model parameters p as (17) where the process is standard as that in common deep learning:\n$$ \\min_p E_{w,t} L(f_p(D) \\odot m + \\frac{1}{\\epsilon(w)} t). $$\nStep 2, given model parameters p, our goal is to optimize w, the dropout rates, as (18):\n$$ \\min_w E_{p,t} L(f_p(D) \\odot m + \\frac{1}{\\epsilon(w)} t). $$\nHowever, training w with the masking term m in the loss function poses challenges, and thus we adopt the technique of GS reviewed in Section II-D to make the scheme trainable. To be specific, we introduce a categorical vector vi = (vi1 , vi2) inferring the category of being dropped out or not for the i-th feature, then the masking vector is set as mi = vi2 . Denote the class probabilities of being dropped out as \u03c0i = (wi , 1 \u2212 wi), then following the idea of Gumbel-Max technique [76], the onehot categorical vector can be generated as:\n$$ v_i^{hard} = onehot(\\arg \\max_j [g_j + \\log(\\pi_{ij})]), j = 1, 2, $$\nwhere gj are i.i.d samples drawn from Gumbel(0, 1), i.e gj = \u2212 log(\u2212 log (uj)), uj \u223c U(0, 1) for j = 1, 2, and \u201chard\u201d means generating the vector via argmax. When testing, the masking vector mi = vi2 can be generated via (19). But when training, the challenge of backpropagation for argmax arises. We adopt GS technique [26], which uses the softmax func- tion as a continuous, differentiable approximation to argm\u0430\u0445. We generate categorical vector vsoft as in (20), where the \u201csoft\u201d means generating the vector via softmax.\n$$ v_i^{soft} = \\frac{\\exp ((g_j + \\log (\\pi_{ij})) /\\tau)}{\\sum_{k=1}^2 \\exp ((g_k + \\log (\\pi_{ik})) /\\tau)}, j = 1, 2. $$\nTo summarize, with given dropout rate w, we can generate the masking term variable m from function m(v(\u03c0, u|w)). where v(\u03c0, u|w) is a function mapping from class probabilities \u03c0 = \u03c0(w) and uniform drawn variable u to the categorical vector v via (20) in training and via (19) in testing. With v = v(\u03c0, u|w), m(v) is a function to generate masking variable m = m(v) with mi = vi2 . Then the optimization with regards to the dropout parameter w is:\n$$ \\min_{w} E_{t,u} L\\bigg[ f_p(D) \\odot m(v(\\pi, u|w)) + \\frac{1}{\\epsilon(w)} t \\bigg]. $$\nC. Algorithm Summary\nTo summarize, we first design a multimodal learning mech- anism summarized in Algorithm 1 to extract representative features, and then apply the two-step optimization for Lapla- cian dropout with DP. The whole process of our proposed method is summarized in Algorithm 2.\nAlgorithm 1 Multimodal EEG representative learning Am\n1: INPUT: EEG data xe, OM (other modal) data xo. 2: Extract EEG features via text-based encoder Bert with text-targeted transformation: fe = FBert (he (xe)) 3: Extract other modality features via image-based en- coder ViT with image-targeted transformation: fo = FVIT (ho (xo)) 4: Extract cross-modal features via cross-attention-based decoder: fc = CA(he (xe) , ho (xo)) 5: Combine and normalize features: f = Normalization([fe , fo , fc ]) 6: OUTPUT: Multimodal feature Am (xe , xo) = f\nAlgorithm 2 DP-MLD for EEG representative learning 1: INPUT: EEG data xe, other modal data xo, label y. 2: Extract multimodal feature via Algorithm Am (xe, xo). 3: Apply Laplacian dropout to get noised feature f = Am(xe , xo) \u2299 m(v(\u03c0, u/w)) + \u03f5(w)t 4: Two-step optimization with loss L(Classifier(f), y) via (17) and (21) and using soft Gumbel-Softmax applied in training process."}, {"title": "V. CONCLUSIONS AND DISCUSSION", "content": "To conclude, we develop a novel Differentially Private Mul- timodal Laplacian Dropout (DP-MLD) for EEG representative learning. In the design of multimodal feature extraction, we"}]}