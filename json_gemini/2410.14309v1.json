{"title": "LoGU: Long-form Generation with Uncertainty Expressions", "authors": ["Ruihan Yang", "Caiqi Zhang", "Zhisong Zhang", "Xinting Huang", "Sen Yang", "Nigel Collier", "Dong Yu", "Deqing Yang"], "abstract": "While Large Language Models (LLMs) demonstrate impressive capabilities, they still struggle with generating factually incorrect content (i.e., hallucinations). A promising approach to mitigate this issue is enabling models to express uncertainty when unsure. Previous research on uncertainty modeling has primarily focused on short-form QA, but real-world applications often require much longer responses. In this work, we introduce the task of Long-form Generation with Uncertainty (LoGU). We identify two key challenges: Uncertainty Suppression, where models hesitate to express uncertainty, and Uncertainty Misalignment, where models convey uncertainty inaccurately. To tackle these challenges, we propose a refinement-based data collection framework and a two-stage training pipeline. Our framework adopts a divide-and-conquer strategy, refining uncertainty based on atomic claims. The collected data are then used in training through supervised fine-tuning (SFT) and direct preference optimization (DPO) to enhance uncertainty expression. Extensive experiments on three long-form instruction following datasets show that our method significantly improves accuracy, reduces hallucinations, and maintains the comprehensiveness of responses.", "sections": [{"title": "1 Introduction", "content": "While large language models (LLMs) demonstrate remarkable performance across various domains (Zhao et al., 2023; Hadi et al., 2023; Chang et al., 2024), they still face a significant limitation of generating factually incorrect statements (i.e., hallucinations). This hinders the broader adoption of LLMs in real-world applications that require highly reliable and accurate responses (Zhang et al., 2023; Huang et al., 2023; Zhang et al., 2024b).\nRecent studies suggest that hallucinations may be inevitable for LLMs (Gekhman et al., 2024;\nLin et al., 2024). LLMs frequently generate responses even in the absence of sufficient knowledge, and more importantly, LLMs rarely express their inherent uncertainty proactively (Xiong et al., 2023a; Kang et al., 2024). Therefore, instead forcing models to produce only correct statements, an alternative approach is to allow them to express uncertainty, which has been shown to reduce hallucinations (Xu et al., 2024; Yang et al., 2023).\nPrevious work on enabling LLMs to express uncertainty has primarily focused on short-form question answering (QA) tasks (Lin et al., 2022; Tian et al., 2023b; Li et al., 2024; Zhang et al., 2024c). However, real-world applications often require much longer responses, sometimes spanning hundreds or even thousands of words (Bai et al., 2023; Zhang et al., 2024a; Yuan et al., 2024). As shown in Figure 1, unlike short-form responses, which typ-"}, {"title": "2 Task definition", "content": "Definition. We define the Long-form Generation with Uncertainty (LOGU) task as follows. A language model (LM), denoted by \\(M\\), is prompted with an open-ended query (e.g., \"Introduce [a person] to me.\") to generate a long-form response \\(R \\sim M(R | q)\\) (e.g., a biography). The response \\(R\\) typically lacks explicit uncertainty expressions and includes both factually correct and incorrect statements. For fine-grained processing, we decompose the response \\(R\\) into \\(N\\) atomic claims \\(C\\), represented as \\(C = \\Pi_{i=1}^{N} C_i\\). These claims are categorized into three subsets: \\(C_s\\), containing claims supported by external knowledge; \\(C_{ns}\\), containing claims refuted by external knowledge; and \\(C_{unc}\\), which includes claims expressing uncertainty. The LOGU task requires the model to reduce \\(C_{ns}\\) and express uncertainty in \\(C_{unc}\\) more accurately.\nChallenges. The LOGU task presents two main challenges: 1) Uncertainty Suppression: The model tends to avoid expressing uncertainty, displaying an overconfidence bias, which can result in reduced factual accuracy (Xiong et al., 2023b; Tian et al., 2023b; Zhang et al., 2024a); 2) Uncertainty Misalignment: There is a misalignment between the uncertainty expressed by the model and its actual uncertainty. The model may express uncertainty about statements it is confident in, leading to a lack of precision in uncertainty expression.\nMetrics. We define two metrics to evaluate the model's performance on the LOGU task:\nFactual Accuracy (FA) measures the proportion of correctly generated deterministic claims in the model's output, reflecting how often the model generates factually correct statements. A higher FA score indicates that the model is generating a larger proportion of correct facts relative to incorrect ones. Specifically, FA is defined as:\n\\[FA = \\frac{|C_s|}{|C_s| + |C_{ns}|}\\]\nUncertain Precision (UP) measures the quality of uncertainty expressions by calculating how often the model precisely express uncertainty. Ideally, the model should express uncertainty in two specific cases: (1) When the model does not have sufficient knowledge about a fact or is prone to make errors; (2) When the uncertainty is expressed about specific, granular details (e.g., \"I do not know [a person]'s birthday.\"), rather"}, {"title": "3 Methodology", "content": "In this section, we explain our approach for the LOGU task in details. Figure 2 shows an overview of the data collection and our training pipeline.\n3.1 Data Collection Framework for LOGU\nFor a target LLM \\(M\\) and a list of queries \\({q_i}_{i=1}^{n}\\), we first gather an original set of query-response pairs, denoted as \\(D = {(q_1, R_1), ..., (q_n, R_n)}\\). Then we apply the following procedures to refine the responses to properly express uncertainty, with the help of an additional auxiliary LLM \\(A\\) (e.g., GPT-4 (Achiam et al., 2023); See Appendix A for the prompts of the procedures).\nFact-Checking. We use the FACTSCORE (Min et al., 2023) for automate fact-checking. For each query \\(q\\), the original response \\(R\\) is decomposed into a series of atomic claims \\(C\\), with each claim containing only a single piece of information. This"}, {"title": "3.2 Revision Operator \\(\\Gamma_{op}\\)", "content": "Two types of operator \\(\\Gamma_{op}\\) (i.e., \\(pos\\) and \\(neg\\)) are used to construct training data to address two specific problems: uncertainty suppression and uncertainty misalignment."}, {"title": "3.3 Training Pipeline", "content": "With the constructed uncertainty data, we propose a two-stage training pipeline. In Stage 1 (LOGU-SFT), our goal is to enable the model to express uncertainty, specifically addressing the problem of uncertainty suppression. In Stage 2 (LOGU-DPO), we aim to enhance the model's precision in expressing uncertainty, ensuring it avoids both exaggeration and understatement.\nLOGU-SFT. We fine-tune the language model \\(M\\) using only positively refined responses (\\(R_{pos}\\)). Specifically, the model iteratively processes a sequence \\(t_1, t_2,..., t_T\\) consisting of queries and corresponding responses (\\(q, R_{pos}\\)). The objective is to minimize the cross-entropy loss \\(L\\):\n\\[L = -\\frac{1}{T} \\sum_{i=1}^{T} log P(t_i | t_1, t_2,..., t_{i-1}),\\]\nwhere \\(P(t_i | t_1, t_2,..., t_{i-1})\\) denotes the probability of predicting token \\(t_i\\) given all previous tokens. Importantly, the loss is computed exclusively for the response parts of the sequence, omitting the queries. After fine-tuning, we denote the model policy as \\(\\pi_{sft}\\).\nLOGU-DPO. To refine the model's alignment in expressing uncertainty, we construct response pairs of good and unsatisfactory expressions from triplets\u00b9 of (\\(R_{pos}\\), \\(R\\), \\(R_{neg}\\)). The negative refinements (\\(R_{neg}\\) are used to address uncertainty mis-alignment by providing negative examples of inappropriate uncertainty expressions.\nWith these constructed response pairs \\((q, y_w, y_l)\\), we employ the Direct Preference Optimization (DPO) algorithm (Rafailov et al., 2024) for model training:\n\\[L_{\\pi} = -E_{(q,y_w,y_l) \\sim D} log \\sigma \\Bigg(\\beta log\\frac{\\pi_{\\theta}(y_w | q)}{\\pi_{sft}(y_w | q)} - \\beta log\\frac{\\pi_{\\theta}(y_l | q)}{\\pi_{sft}(y_l | q)} \\Bigg)\\]\nwhere \\(\\pi_{\\theta}\\) is the model policy initialized from \\(\\pi_{sft}\\), \\(\\beta\\) controls the deviation from \\(\\pi_{sft}\\), and \\(\\sigma\\) represents the logistic function."}, {"title": "4 Experiment Settings", "content": "4.1 Dataset and Models\nWe use three datasets for long-form QA: (1) Bios (Min et al., 2023), which contains 500 individuals"}, {"title": "4.2 Evaluation Metrics", "content": "We evaluate the performance of models in reflecting uncertainty in long-form generation using three core metrics: Factual Accuracy (FA), Uncertain Precision (UP), and number of incorrect claims (#Incor). As discussed in \u00a72, the first two metrics are designed to measure the model's ability to accurately output factual statements and uncertainty expressions. In addition, we include #Incor to explicitly measure the absolute number of errors that the model is making.\nTo calculate Uncertain Precision, we first approximate \\(C_{unc}^{true}\\) by discriminative\u00b2 model querying: we regard a claim as truly uncertain if the model cannot directly answer it correctly. We take a similar approach to those adopted in previous work (Tian et al., 2023a; Zhang et al., 2024d; Farquhar et al., 2024) by transforming atomic facts into specific short-form questions and querying the original model for its acquaintance of this fact. For example, the fact \"[a company] was founded in 1996\" is converted into the question \"When was [a company] founded?\". We focus on uncertainty about specific and granular details and exclude general and vague claims (as judged by GPT-40). We present these questions to the model and collect the model's answer. If the model fails to answer a question correctly, it indicates that the model may have high uncertainty about that fact and the claim can be regarded as truly uncertain. We use the number of questions that lead to wrong answers as the approximation of \\(C_{unc}^{true}\\).\nIn addition to FA and UP, we further include a metric of #Incor., which tracks the total number of incorrect statements generated by the model. While"}, {"title": "4.3 Baselines", "content": "In our experiments, we compare our LOGU-SFT and LOGU-DPO\u00b3 against four baseline methods (see implementation details of baselines in Appendix C): 1) Unc-Zero: The model is directly prompted to express uncertainty in its output if it is not sure about any claims. 2) Unc-Few: Building on Unc-Zero, we provide the model with an additional set of 10 hand-crafted QA examples where uncertainty is explicitly expressed in the answers, following an in-context learning approach. For each example, we provide the question paired with a long-form answer that includes uncertainty expressions. Each example is formatted as <Q, Aunc>. 3) Pair-Few: Extending Unc-Few, we provide the model with both a long-form answer with only certain expressions Acert and another one with uncertainty expressions Aunc for each query. Each example is formatted as <Q, Acert, Aunc>. The goal of including both Acert and Aunc is to teach the model to differentiate between these two through in-context learning. 4) Self-Refine (Madaan et al., 2024): Instead of generating the response in one pass, we apply a draft-and-refine setup. The model is asked to first generate an initial response and then refine the uncertain facts into explicit uncertainty expressions in a second pass."}, {"title": "5 Result and Analysis", "content": "5.1 Main Results\nLoGU greatly enhances generation performance with higher accuracy and fewer incorrect statements. Table 1 presents our main experimental results. With both models, LoGU-DPO consistently achieves the best performance across all three datasets. Specifically, it improves accuracy from 38.8% to 65.4% for Mistral-7B-Instruct and from 51.9% to 71.4% for Llama3-8B-Instruct on"}, {"title": "5.2 Analysis", "content": "Different Training Data Sources. We explore cases where the training data are collected using the original responses from different source models. In Table 2, we train the Llama3-8B-Instruct model using data constructed from Mistral-7B-Instruct. We have the following two findings: 1) For LOGU-SFT, data from another LLM will not always lead to worse performance. This may be because LOGU-SFT primarily addresses the uncertainty"}, {"title": "5.3 Human Evaluation", "content": "We conduct a human evaluation to further evaluate the user experience on the uncertainty expression, considering two key aspects: helpfulness and fluency. \"Helpfulness\" measures the extent to which the model's output aids the user in understanding the topic and making informed decisions. \u201cFluency\" assesses the cohesion and coherency of the model's output (See detailed information of the human evaluation are provided in Appendix G). We compare the original, Zero-Shot, and LOGU-DPO (with uncertainty ratio \\(\\alpha\\) values of 0.2 and 0.6) responses. As shown in Figure 4, LoGU-DPO with a 20% uncertainty ratio provides the most helpful responses. More importantly, annotators reported that using appropriate expressions of uncertainty"}, {"title": "6 Related Work", "content": "Fine-tuning LLMs for Factuality. There has been substantial work on fine-tuning LLMs to improve factuality. Tian et al. (2023a) and Zhang et al. (2024d) proposed different approaches for annotating responses to fine-tune models using Direct Preference Optimization (DPO). The former focuses on leveraging external knowledge sources, while the latter emphasizes the utilization of the model's own signals to rank the truthfulness of responses. Furthermore, Lin et al. (2024) underscores the importance of factual data in alignment training, employing distinct reward methods for factual and non-factual data to refine model performance. Moreover, multiple studies have highlighted that introducing new knowledge during fine-tuning can sometimes lead to increased hallucination (Lin et al., 2024; Gekhman et al., 2024; Kang et al., 2024). This insight suggests it may be more effective to let models express uncertainty rather than forcing them to state unfamiliar facts.\nTeaching LLMs to Express Uncertainty. There are two main approaches to teaching LLMs to express uncertainty: prompt-based and training-based. Prompt-based methods (Tian et al., 2023b;"}, {"title": "7 Conclusion", "content": "In this paper, we introduce the LoGU task, which aims to enhance the ability of LLMs to express uncertainty in long-form generation. To tackle the problems of Uncertainty Suppression and Uncertainty Misalignment, we propose a refinement-based data collection framework and a two-stage training pipeline with LOGU-SFT and LOGU-DPO. Our experiments on three long-form instruction following datasets demonstrate that our approach significantly improves factual accuracy and uncertain precision, effectively reducing hallucinations without sacrificing the comprehensiveness of the generated content. These results underscore the importance of accurate uncertainty modeling in long-form generation, paving the way for more reliable and trustworthy LLM applications in real-world scenarios."}, {"title": "Limitation", "content": "In this work, we focus on enabling models to express uncertainty in factual QA datasets. Future research could explore how models can express uncertainty in other long-form generation tasks, such as grammar checking, summarization, and translation. Additionally, the uncertainty expression in our work is binary; we do not require models to indicate degrees of uncertainty, such as \"I am 10% unsure about...\". Our approach is a pioneering effort in expressing uncertainty in long-form generation, and binary uncertainty expression serves as a solid starting point. Meanwhile, we argue that expressing uncertainty in percentages may not be necessary for real-life applications: (1) Risk Indication: Both 10% and 50% still convey to users that the statements involve a potential risk of being incorrect. (2) Interpretation Challenges: Users may struggle to interpret specific percentages. For example, the difference between being 60% certain and 80% certain can be subtle and subjective, potentially causing confusion or misinterpretation. (3) Cognitive Load: Users might feel overwhelmed by numerical uncertainty, especially in long-form text with frequent instances of uncertainty."}, {"title": "Ethics Statement", "content": "Our research adheres to rigorous ethical guidelines. We verified the licenses of all softwares and datasets we used in this study and ensured full compliance with their terms. During the human annotation process, all annotators provided informed consent for their data to be used as part of the project. No privacy concerns have been identified. Furthermore, we have thoroughly assessed the project and do not anticipate any additional potential risks."}, {"title": "A Instruction Prompt Examples", "content": "The instruction prompts for the revision and assembling333 procedures in \u00a73 are presented in Listing 1.\nListing 1: The instruction prompts for Revision and Assembling procedures.\nRevision Instruction:\nYou will be given a series of atomic facts, each labeled as ##certain## or ##uncertain##. Please adjust each fact following these steps:\nFor facts labeled as ##certain%%, leave them unchanged.\nFor facts labeled as ##uncertain##, adjust them to express uncertainty without focusing on overly specific details. Instead of being uncertain about exact facts, use more general phrases like 'I am not sure when/where/how/what' to convey the uncertainty.\nHere are some uncertainty expressions you can refer to:\nIt is uncertain/unclear/not sure/not known\nI am uncertain/unclear/not sure/not known\nThere is no information about\nThere is no concrete answer about\nOutput each fact (including unchanged facts labeled #ceratin# and adjusted facts with #uncertain# label) in order, as a single line beginning with ###.\nFor Example:\nFacts:\nKang Ji-hwan was born on March 16, 1982. ##uncertain##\nKang Ji-hwan was born in Seoul, South Korea. ##uncertain##\nChief Jones is a respected figure. ##uncertain##\nChief Jones is a respected figure in law enforcement. ##uncertain##\nHe has had a successful career in the police force. ##uncertain##\nHe rose through the ranks. ##certain##\nOutput:\n### I do not know when Kang Ji-hwan was born.\n### I am not sure where Kang Ji-hwan was born.\n### It is unclear whether Chief Jones is a respected figure.\n### It is uncertain whether Chief Jones is a respected figure in law enforcement.\n### It is uncertain whether he might had a successful career in the police force.\n### He rose through the ranks.\nNow it's your turn to answer:\nAssembling Instruction:\nYour task is to concatenate a provided list of atomic facts, each articulated with either certainty or uncertainty, into a cohesive narrative following the guidelines below:\nAll facts in the list, regardless of their certainty, MUST BE included in the generated text. Eliminate any duplicates that may exist.\nRefrain from adding any facts that are not mentioned in the original atomic facts list.\nYour narrative must flow smoothly and coherently. Uncertainty (if present in the atomic facts list) should be expressed diversely, employing phrases such as 'might', 'it is/I am not sure'.\nHere is the atomic facts:\n{paragraph}\nOutput:"}, {"title": "B Implementation Details.", "content": "In our experiments, we utilize the Llama3-8B-Instruct (Meta, 2024) and Mistral-7B-Instruct (Jiang et al., 2023) as our base models.\nTraining Data The LOGU-SFT and LOGU-DPO datasets comprise a mix of Bios, WildHallu, and LongFact. Here, we used an uncertainty ratio of \\(\\alpha\\) = 0.2 to construct our training data. To enrich the training data and enhance the model's robustness, we implemented data augmentation on the instructions for Bios and WildHallu. We applied five specific transformations as follows:\nOriginal Prompt:\nBios: Tell me a bio of\nWildHallu: In a paragraph, can you tell me about\nData Augmentation:\n1. Tell me what you know about\n2. Can you provide a detailed introduction of\n3. Can you tell me about\n4. Can you provide information about\nThe specific data set size during the LOGU-SFT and LOGU-DPO phases for Mistral-7B-Instruct and Llama3-8B-Instruct is detailed in Table 4. We also provide the examples of our LOGU-SFT and LOGU-DPO training data as below:\nLoGU-SFT Example:\n{\n'instruction': \"Tell me a bio of Suthida.\",\n'input':\n\"\",\n'output': \"Suthida Vajiralprabha is the current queen consort of Thailand.\nBefore her ascension to this prestigious role, she was born into a middle-class family and rose through the ranks in the Royal Thai Police, where she was known for her dedication and hard work. Although it is uncertain, some say she might have worked as a nurse, but I am not sure where she might have done so in Bangkok.\\n\\nIn a surprising turn of events, Suthida Vajiralprabha married King Maha Vajiralongkorn of Thailand on May 1, 2019. Following her marriage, she was given the title of Queen Consort and has since taken on various royal duties, often seen attending official events with the king and engaging in charitable work.\\n\\nDespite her royal status, Suthida Vajiralprabha is known for her simple and down-to-earth personality. Her humility and dedication to serving the people have won the hearts of many Thais. While I do not know what her specific royal title is, I can affirm that she is fluent in Thai and continues to be a beloved figure in Thailand.\"\n}\nLoGU-DPO Example:\n{\n\"instruction\": \"Who is Gottfried Wilhelm Leibniz?\",\n\"input\":\n\"\",\n\"chosen\": \"Gottfried Wilhelm Leibniz, born on July 1, 1646, and passing away on November 14, 1716, was a German philosopher, mathematician, and polymath. Widely regarded as one of the greatest thinkers of the late 17th century, Leibniz made significant contributions to various fields including metaphysics, logic, theology, and particularly mathematics. Notably, he developed calculus independently of Sir Isaac Newton and invented the Leibniz wheel, although I am not sure whether he also invented the Leibniz calculus.\\n\\nLeibniz is perhaps most famous for his philosophical concept of monadology, which posits that the universe is made up of individual, simple substances called monads. While he was undeniably a prolific writer, the exact number of letters and manuscripts he produced remains uncertain. \\n\\nAs a member of several European academies, Leibniz held various positions of influence throughout Europe. However, it is not clear whether he made significant contributions to the fields of physics and diplomacy. Overall, Leibniz's legacy as a thinker who traversed multiple disciplines has ensured his lasting impact on the intellectual landscape.\",\n\"rejected\": \"Gottfried Wilhelm Leibniz (July 1, 1646 \u2013 November 14, 1716) was a German philosopher, mathematician, and polymath who is considered one of the greatest thinkers of the late 17th century. He is best known for his contributions to philosophy, particularly in the areas of metaphysics, logic, and theology. Leibniz is also known for his work in mathematics, including his development of the calculus independent of Sir Isaac Newton, and his invention of the Leibniz wheel and the Leibniz calculus.\\n\\nLeibniz is perhaps most famous"}, {"title": "C Baselines", "content": "Here we list the prompts of our baselines (zero, few-shot, paired few-shot and self-refine) in \u00a74.3.\nListing 2: The instruction prompts of key procedures.\nZero Shot(Bios):\nYour task is to write a biography for a specific entity. You should express uncertainty for any information you are not familiar with.\nZero Shot (LongFact):\nYour task is to answer the given question about a specific object (e.g., a person, place, event, company, etc.). Express uncertainty for any information you are not familiar with (e.g., 'I am not sure if/whether', 'It is uncertain that').\nZero Shot(WildHallu):\nYour task is to write a paragraph for a specific entity. You should express uncertainty for any information you are not familiar with (e.g., 'I am not sure if/ whether', 'It is uncertain that').\nFew Shot Examples:\nQuestion: In a paragraph, could you tell me what you know about Vycta.co.ke?\nAnswer: Vycta.co.ke is a Kenyan-based digital health platform that provides healthcare services to patients. Additionally, Vycta.co.ke offers various health -\nrelated services, ensuring comprehensive support for its users.\nPaired Few Shot Examples:\nQuestion: In a paragraph, could you tell me what you know about Vycta.co.ke?\nGood Answer: Vycta.co.ke is a Kenyan-based digital health platform that provides healthcare services to patients. Additionally, Vycta.co.ke offers various health-\nrelated services, ensuring comprehensive support for its users.\nBad Answer: Vycta.co.ke is a Kenyan-based digital health platform that provides a range of healthcare services to patients and healthcare providers. The platform offers a telemedicine service that allows patients to consult with doctors remotely, as well as a health insurance platform that provides access to affordable healthcare coverage. Vycta also offers a range of health-related products and services, including a health monitoring app that allows patients to track their health metrics and receive personalized health advice. The platform aims to increase access to healthcare services, particularly in rural and underserved areas, and to make healthcare more affordable and convenient for patients.\nSelf Refine:\nRevise your previous response to the question by adjusting the expression of certainty.\nFor any information you are unsure about, frame your response to reflect this uncertainty. Keep the expression of information you are certain about unchanged.\nFor example:\nQuestion: Tell me a bio of Miguel Angel Felix Gallardo.\nAnswer: Miguel Angel Felix Gallardo, also known as \"El Padrino\" (The Godfather), is a Mexican drug lord and former leader of the Guadalajara cartel, one of the most powerful drug trafficking organizations in Mexico during the 1980s. He was born on August 7, 1946, in La Barranca de Agua Caliente, Sinaloa, Mexico.\nGallardo began his criminal career in the 1960s, working as a small-time smuggler and drug dealer. He quickly rose through the ranks, becoming a key player in the Mexican drug trade and eventually forming his own organization, the Guadalajara cartel, in the 1970s.\nRefine: Miguel Angel Felix Gallardo, who is widely known as 'El Padrino' (The Godfather), is a notorious Mexican drug lord. He emerged as a prominent figure in the criminal underworld by forming the Guadalajara cartel in the 1970s. Gallardo's rise to power was marked by his adept maneuvering within the Mexican drug trade, where he quickly became a key player.\nNow it is your turn to refine:\nQuestion: {question}\nAnswer: {answer}\nRefine:"}, {"title": "D Comparision of LOGU-DPO and DPO-Only.", "content": "In this section, we compare the performance of LOGU-DPO and DPO-Only. Similar to the main experiments, we evaluate the models on three datasets: Bios, LongFact, and WildHallu, using Factual Accuracy (FA) and Uncertainty-Precision (UP) as metrics. As shown in Table 6, we find that LOGU-DPO achieves the best performance, while training with DPO alone significantly decreases model performance, with UP metrics even falling behind LOGU-SFT."}, {"title": "E Case Study", "content": "We randomly selected a sample from the WildHallu dataset to compare Original Answer and LOGU-DPO Answer. Each atomic claim in the generated responses was manually fact-checked using Wikipedia and other sources accessible via Google. Correct statements were highlighted in green, incorrect statements in red, and uncertainty expressions in blue.\nAs shown in Figure 5, the original answer contains a mix of correct and incorrect statements, which diminishes the overall factual accuracy of the generated content. In the case of LoGU-SFT, it significantly reduces the number of incorrect statements. However, it also introduces uncertainty in the expression of some correct facts. For example, in the original answer, Aegon the Conqueror's birth time is correctly stated as \"27BC\", but in the LoGU-SFT answer, this fact is expressed with uncertainty. In contrast, the LOGU-DPO response preserves the correct statements while replacing incorrect ones with expressions of uncertainty. For instance, the original answer incorrectly identifies Aegon the Conqueror's parents as \u201cHe was the elder son of Lord Jaxartes Targaryen of Dragonstone and Princess Rhaenyra Targaryen.\" However, the LOGU-DPO response addresses this uncertainty by stating, \u201cThe identity of his parents remains uncertain.\u201d, thereby significantly improving the overall accuracy of the response."}, {"title": "F Uncertainty Categories", "content": "Detailed descriptions of eight categories derived from uncertainty in atomic claims.\n0: Date and Timing Uncertainty.\nThis label applies to uncertainties about the specific times of events, important dates in a person's life, or any time-related facts.\nExample: \"When Marie Alexandrine Becker received the Lasker-DeBakey Clinical Medical Research Award is [/uncertain/].\" or \"The timing of when Bella Akhmadulina was awarded the Lenin Komsomol Prize for Literature is [/uncertain/].\"\n1: Identity and Occupation Uncertainty.\nUse this for uncertainties about the real existence or the professional role of individuals.\nExample: \"It is [/uncertain/] whether Chief Jones is a real person.\" or \"Whether Ravi is a fellow of the IACR is [/uncertain/].\"\n2: Location and Geography Uncertainty.\nThis covers uncertainties related to the places of birth, education, residence, or any geographical locations.\nExample: \"The place where Sara Paxton was born is [/uncertain/].\" or \"The place where Lousteau earned his undergraduate degree is [/uncertain/].\"\n3: Achievements and Contributions Uncertainty.\nThis involves uncertainties about someone's achievements, awards, or any professional contributions.\nExample: \"Whether Antonio Gasalla received the Premio Regione Piemonte is [/ uncertain/].\" or \"The awards won by Wilfredo Vargas is [/uncertain/].\"\n4: Involvement and Action Uncertainty.\nPertains to uncertainties about someone's participation in projects, campaigns, or actions.\nExample: \"Liam Payne's involvement with the 'Text Santa' campaign is [/uncertain/].\" or \"It's unclear whether Mauro Icardi was loaned to Sampdoria.\"\n5: Personal Life and Background Information Uncertainty.\nUse this for uncertainties about personal details, family background, or other private aspects.\nExample: \"Kourosh Zolani's personal life is [/uncertain/].\" or \"Many aspects of Rivera's early life are [/uncertain/].\"\n6: Existence and Factual Veracity Uncertainty.\nThis label is for uncertainties about the factual existence of events, appearances in media, or historical facts.\nExample: \"It is [/uncertain/] whether Marianne McAndrew has appeared in 'Law & Order: Special Victims Unit: The Movie.'\" or \"It is uncertain whether Virginia Valli appeared in 'The Big Combo'.\"\n7: Others.\nAnything that does not fit into the categories above."}, {"title": "G Human Evaluation", "content": "We randomly selected 100 queries from the bios", "almost perfect\" range of 0.8-1.0; Landis and Koch, 1977). The annotators were compensated above the local minimum hourly wage. The instruction to guide human annotators to evaluate the Helpfulness and Fluency of Long-Form Responses are present in the listing 3 and 4.\nListing 3": "Instructions for Human Annotators: Evaluating the Helpfulness of Long-Form Responses\nYour task is to evaluate the helpfulness of each long-form response based on the proportion of Correct", "Helpfulness": "nHelpfulness refers to how effectively the response provides **useful", "into": "nCorrect Information: Accurate and relevant facts or details that directly address the query. The more correct information a response contains", "Information": "Misleading"}, {"Information": "Statements that express ambiguity", "Scale": "nYou will rate the helpfulness of each long-form response on a scale from 1 to 5"}, {"Information": "n#### 1: Not Helpful\nThe response is dominated by incorrect information or excessive", "2": "Minimally Helpful\nThe response contains some correct information", "3": "Moderately Helpful\nThe response presents a mixture of correct", "4": "Helpful\nThe response is mostly correct, with only minor incorrect details or justified uncertainty. Uncertainty"}]}