{"title": "Investigating Cost-Efficiency of LLM-Generated Training Data\nfor Conversational Semantic Frame Analysis", "authors": ["Shiho Matta", "Yin Jou Huang", "Fei Cheng", "Hirokazu Kiyomaru", "Yugo Murawaki"], "abstract": "Recent studies have demonstrated that few-shot\nlearning allows LLMs to generate training data\nfor supervised models at a low cost. How-\never, the quality of LLM-generated data may\nnot entirely match that of human-labeled data.\nThis raises a crucial question: how should one\nbalance the trade-off between the higher qual-\nity but more expensive human data and the\nlower quality yet substantially cheaper LLM-\ngenerated data? In this paper, we synthesized\ntraining data for conversational semantic frame\nanalysis using GPT-4 and examined how to al-\nlocate budgets optimally to achieve the best per-\nformance. Our experiments, conducted across\nvarious budget levels, reveal that optimal cost-\nefficiency is achieved by combining both hu-\nman and LLM-generated data across a wide\nrange of budget levels. Notably, as the bud-\nget decreases, a higher proportion of LLM-\ngenerated data becomes more preferable.", "sections": [{"title": "Introduction", "content": "It is costly to construct training data with human\nannotation for supervised learning models (SLMs).\nIn recent years, large language models (LLMs) like\nGPT-4 have demonstrated remarkable abilities in\ngenerating coherent text, understanding context,\nand following complex specifications to accom-\nplish tasks (Brown et al., 2020; OpenAI, 2024).\nTherefore, there have been many attempts to lever-\nage existing LLMs as data annotators to generate\ntraining data for SLMs, aiming to reduce data costs.\nStudies have indicated that using LLM-generated\ndata can cut costs significantly while maintaining a\nreasonable performance against human-annotated\ndata for certain tasks (Wang et al., 2021; Ding et al.,\n2023).\nIn this paper, we focus on the task of analyz-\ning semantic frames in Japanese technical expert-\ninterviewer dialogues in the EIDC dataset (Okahisa\net al., 2022; Chika et al., 2024). Semantic frame\nanalysis (SFA) captures salient knowledge ex-\nchanged between speakers by extracting seman-\ntic frames, which represent events within a given\ncontext. A semantic frame consists of a trigger,\nwhich is a predicate that represents the main action\nof the event, and arguments of the trigger, which\nare the details of the event. In Figure 1, two se-\nmantic frames are annotated: \"line up\" (frame type\nPLACE) and \"fry\" (BAKE_FRY). The first frame\nhas one Object argument, while the second has\nTime and Temperature as arguments. Colloquial\ninterview dialogues often contain repetitions and\nconfirmations of technical details, and as shown,\nthe interviewer's question introduces a new argu-\nment to the frame.\nHuman-annotated data is typically expensive,\nand the EIDC dataset is no exception. The collec-\ntion of one dialogue and its semantic frame anno-\ntation cost approximately $133 (Chika, personal\ncommunication, 01/2024). On the other hand, the\naverage annual research grant for doctoral students\nat Japanese universities is approximately $4,000.\nEven if the entire amount were allocated to data\ncollection, it would only yield 30 dialogues, which\nshould not be optimal for supervised learning. In\ncontrast, a GPT-4-generated dialogue and SFA la-\nbel pair in our experiments cost only $3.\nAlthough LLM-generated data is cheap, it typ-"}, {"title": "Related Work", "content": "Semantic Frame Analysis (SFA) in Dialogues.\nSemantic frame analysis is a task inspired by frame-\nsemantic parsing (FSP) and semantic role label-\ning (SRL). Unlike the FrameNet project used in\nFSP (Baker et al., 1998) or PropBank used in SRL\n(Kingsbury and Palmer, 2002), the frame design in\nsemantic frame analysis differs in two key ways:\n(1) the trigger type is curated for each topic domain\nand is predicate-centered, and (2) the argument\ntypes are common among different domains. Here,\nwe refer to the process of identifying the span and"}, {"title": "Preliminaries", "content": "We define semantic frame analysis (SFA) and intro-\nduce the EIDC dataset we used in this study.", "subsections": [{"title": "Semantic Frame Analysis (SFA)", "content": "Semantic frame analysis aims to extract semantic\nframes, which represent events, in a given context.\nThe core of a semantic frame is a trigger, which is\na predicate and the main action of the event. Since\neach frame has only one trigger, we refer to the\nframe type by the trigger type from now on without\nfurther notice. The event can also include associ-\nated details, such as the object, instrument, or tem-\nperature, referred to as frame arguments, linked to\nthe event-evoking trigger. Note that different from\nframe designs such as the FrameNet project (Baker\net al., 1998), all frames share common argument\ntypes in the EIDC dataset.\nSFA consists of two parts: Trigger Detection\nand Argument Detection. In this work, we for-\nmulate SFA as a sequence labeling task to capture\nentities scattered across multiple utterances. There-\nfore, detection means identifying both the span and\nthe type of an entity. In addition to entity span and\ntype, an argument must link to a detected trigger.\nA visual example of SFA annotation is presented\nin Figure 1. We designed a novel prompting and\noutput format for an LLM to handle SFA efficiently\n(Section 4.2), and utilized an architecture that can\nhandle both sequence labeling and relation extrac-\ntion at the same time (Section 5.3)."}]}, {"title": "Technical Interview Dialogue Dataset with\nSFA Annotation", "content": "In this paper, we utilize the cooking section of the\nEIDC dataset (Okahisa et al., 2022; Chika et al.,\n2024). Note that from now on, by the EIDC dataset,\nwe refer to the cooking section without further no-\ntice. The dataset is comprised of technical inter-\nview dialogues with SFA annotations.\nTechnical Interview Dialogues. The EIDC\ndataset contains interview dialogues where an ex-\npert discusses cooking processes with an inter-\nviewer. The expert introduces and explains a recipe\nspontaneously or in response to the interviewer's\nquestions. The interviewer is asked to actively elicit\nknowledge about the cooking process through in-\nteractions, such as asking questions.\nAnnotation for Semantic Frame Analysis.\nEach dialogue in the EIDC dataset comes with\nmanual annotations of SFA. Since these dialogues\npertain to the cooking domain, the semantic frames\nare designed to capture cooking-related events. For\nexample in Figure 1, when a speaker mentions the\naction of lining something up, the predicate of this\nevent will be annotated with a \"PLACE\" type of\ntrigger. If the event also involves an object being\nlined up, that object will be annotated as an \"Ob-\nject\" type of argument, and linked to the trigger.\nThe complete list of trigger and argument types can\nbe found in Appendix A.4."}, {"title": "Data Synthesis With an LLM", "content": "This section presents our methodology for con-\nstructing training data for conversational semantic\nframe analysis using an LLM, as illustrated in the\noverview in Figure 2. We use an LLM to label\neither human dialogues or pseudo-dialogues also\ngenerated by an LLM, resulting in 2 pseudo-data\nvariants: Human-Pseudo and Pseudo-Pseudo.", "subsections": [{"title": "Pseudo-dialogue Generation", "content": "To generate pseudo-dialogues, the LLM is\nprompted with few-shot dialogues and asked to\ngenerate new ones that are close to the few-shots\nin format but contain different contents (Figure 3).\nFor the few-shot examples, we not only sample\nfrom a preserved pool of human dialogues but\nalso adopt the self-instruct strategy (Wang et al.,\n2023b) to sample from the previously generated\npseudo-dialogues to increase diversity. The pre-\nfiltering and post-filtering methods, along with the"}, {"title": "Pseudo-labels by LLM", "content": "We design a novel multi-step labeling approach to\nconvert SFA into a text generation task that can be\nefficiently managed by an LLM. An example of\nthis pseudo-labeling process is illustrated in Fig-\nure 4. The system prompt includes definitions of\ntrigger and argument types as specified in the an-\nnotation guidelines, along with few-shot examples\nto demonstrate the SFA process in a text gener-\nation format. In each example, such as the one\nin Figure 4, entities like \"line up\" and \"Gyozas\"\nare tagged with entity tags such as \" in the\nfirst step. In step 2, the LLM identifies all trig-\ngers within these entities. Finally, in step 3, the\narguments for each trigger are determined using\nrelation triplets. The output can then be seamlessly\nconverted into sequence labeling data for our SLM."}, {"title": "Data Variants", "content": "We construct three data variants with the dia-\nlogues and annotations sources from either hu-\nman or LLM: Human-Human, Human-Pseudo, and\nPseudo-Pseudo. In this context, \"Human\" refers\nto data collected from humans, while \"Pseudo\"\ndenotes data generated by an LLM. We did not\nconsider a Pseudo-Human variant because human\nannotation is too precious to be assigned to lower-\nquality LLM-generated dialogues.\nHuman-Pseudo. In this data variant, SFA labels\nare assigned by an LLM to human dialogues sam-"}]}, {"title": "Experiments", "content": "To investigate how LLM-generated data can con-\ntribute to optimal cost-efficiency, we first defined\nthe budget ranges and assembled both human and\nLLM-generated data according to these budget set-\ntings. From the EIDC dataset, we sampled up to\n$12,800 to create the Human-Human data. We\nthen synthesized two types of LLM-generated data:\nHuman-Pseudo for $12,800 and Pseudo-Pseudo\nfor $840. Finally, we investigated the optimal ra-\ntio for combining Human-Human data with LLM-\ngenerated data under each budget to achieve the\nbest SFA performance. To do this, we trained an\nSLM using different data combinations and evalu-\nated its performance based on trigger detection and\nargument detection. The following subsections pro-\nvide detailed descriptions of the experimental pro-\ncess, results, and analyses. Note that to fit within\nthe context length limits of both the LLM and our\nSLM, we divide dialogues into smaller sessions\nusing a heuristic method. Hereafter, a 'dialogue'\nwill refer to a 'dialogue session' unless otherwise\nspecified. Each session typically consists of about\n10 utterances.", "subsections": [{"title": "Details of Data Synthesis Procedures", "content": "Pseudo Dialogue Generator. As introduced in\nSection 4.1, we adopted the self-instruct strategy\n(Wang et al., 2023b) to bootstrap pseudo-dialogue\ngeneration. Mostly following the settings in their\nwork, we provide the model with 8 dialogues\nas few-shots: 6 human dialogues and 2 pseudo-\ndialogues for topic diversity. Since we did not have\npseudo-dialogues when we started, we first created\na few pseudo-dialogues with few-shot examples\ncontaining only human dialogues. Afterward, we\nmoved on to mixing few-shot examples. Before\nadding pseudo-dialogues back into the dialogue\npool, we filtered them by ROUGE-L score (<0.7)\nagainst existing dialogues to ensure that the newly\ngenerated ones were not extremely similar to the\nexisting ones. None of the pseudo-dialogues ex-\nceeded this limit. We then filtered the most similar\nones using ROUGE-L to reduce them to the de-\nsired size shown in Table 1, which ended with a\nmax ROUGE-L score of 0.52. We used GPT-4-\n0613 (accessed 01/2024) and set the generation\ntemperature to 0.7.\nPseudo SFA Labeler. We adopted GPT-4-0613\n(accessed 01/2024) to generate pseudo-labels for\nSFA. For few-shots, we sampled 3 complete hu-"}, {"title": "Budget Settings and Data Statistics", "content": "We provide detailed information on the budget set-\ntings, costs, and basic statistics for the three types\nof data variants: Human-Human, Human-Pseudo,\nand Pseudo-Pseudo.\nTotal Data Sizes and Costs. As shown in Ta-\nble 1, we collected up to $12,800 for both Human-\nHuman and Human-Pseudo data, which roughly\naligns with the three-year total of scholarship funds\nfor a PhD student at a Japanese university. For\nHuman-Human data, we extracted $12,800 worth\nof human dialogue and label pairs from the EIDC\ndataset, out of a maximum of 4,600 sessions and a\ntotal cost of $40,000 of the original dataset. In the\nEIDC dataset, the costs for human dialogues and\nhuman labels are roughly the same. For Human-\nPseudo data, we repeatedly applied pseudo-labels\nto the existing human dialogues in the EIDC dataset\nuntil the cost reached $12,800, which was calcu-\nlated based on the cumulative costs of the human\ndialogues and OpenAI API usage. Notably, the\npseudo-labels accounted for only 3% of the total\ncost of Human-Pseudo data. As a result, we were\nable to annotate more dialogues than the Human-\nHuman data. For Pseudo-Pseudo data, due to"}, {"title": "SLM and Evaluation Metrics for SFA", "content": "We adopt JaMIE (Cheng et al., 2022) as our SLM\nfor SFA. JaMIE is an architecture featuring one\nencoder and multiple decoders for sequence label-\ning and can handle relation extraction by design.\nWe employ the Japanese DeBERTa-V2-base as the\npre-trained encoder for JaMIE and train the rela-\ntion decoders from scratch. Refer to the training\nhyperparameters in Appendix A.5.\nWe evaluate the performance of SFA using a"}]}, {"title": "Main Results", "content": "We report on the cost-efficiency of incorporating\nHuman-Pseudo and Pseudo-Pseudo data."}, {"title": "Findings", "content": "We further investigated whether Pseudo-Pseudo\ndata is inferior to Human-Pseudo data because of\nthe pseudo-dialogues it contains. Additionally, we\nevaluated the effectiveness of LLM-generated data\nfrom a data augmentation perspective.\nHuman-Pseudo vs. Pseudo-Pseudo. We ob-\nserved no significant disadvantage caused by re-\nplacing human dialogues with pseudo-dialogues in\nthe training data. With the same budget of $1,600,\none could achieve a slightly higher performance in\ntrigger detection using Pseudo-Pseudo data com-\npared to Human-Pseudo data (0.596 vs. 0.571).\nAdditionally, by comparing the data points using\nall LLM-generated data in both plots, we noticed\nthat Pseudo-Pseudo data achieves the same level\nof performance while costing about 1/10 of Human-\nPseudo data ($200 vs. $1,600 in trigger detection).\nFrom a Data Augmentation Perspective. We\nreview the effectiveness of LLM-generated data\nfrom a data augmentation perspective (Figure 7).\nIn this setting, we trained the SLM first using all\nLLM-generated data, i.e., either all Human-Pseudo\nor Pseudo-Pseudo data, then continued training it\non different costs of Human-Human data, rang-\ning from $800 to $12,800. The result shows that\nwhen the amount of Human-Human data is lim-\nited (lower than $3,200), both Human-Pseudo and\nPseudo-Pseudo data help boost performance. The\neffectiveness of LLM-generated data is more sig-\nnificant when the budget for Human-Human data is\nlow. Notably, while the cost of Pseudo-Pseudo data\nis significantly cheaper than Human-Pseudo data\nin this setting ($840 vs. $12,800), the former is\narguably competitive against the latter as the max\nperformance gap (green line vs. red line) is less\nthan 0.02 F1 score."}, {"title": "Conclusion", "content": "In this work, we explored the feasibility of using\nLLM-generated training data for Japanese conver-\nsational semantic frame analysis (SFA) and exam-\nined its cost-efficiency when combined with hu-\nman data under various budgets. Our findings show\nthat combining both data types is ideal for optimal\nperformance across a wide range of budgets, with\nmore LLM-generated data favored as the budget de-\ncreases. Additionally, we compared two variants of\nLLM-generated data: Human-Pseudo and Pseudo-\nPseudo. The results indicate that it is viable to use\nfully synthesized data, i.e. Pseudo-Pseudo, as it\nsignificantly lowers the cost to achieve the same\nlevel of performance as Human-Pseudo.\nIn this study, we provided insights specifically\non conversational SFA. We believe our conclusions\ncan be extended to similar information extraction\ntasks such as relation extraction and frame semantic\nparsing, which future work could explore."}, {"title": "Limitations", "content": "While we believe the conclusions of our work are\ncomprehensive under our settings, there are sev-\neral limitations. Firstly, we conducted experiments\nonly with GPT-4, as it was the most powerful LLM\navailable at the time and we observed that less pow-\nerful LLMs were unable to handle this task, as men-\ntioned in Section 5.1. Secondly, we did not conduct\na qualitative analysis comparing LLM-generated\ndata to human data. Certain aspects of the LLM-\ngenerated data, such as the increased entity fre-\nquency we observed in the pseudo-dialogues (Ap-\npendix A.4), could indeed affect its effectiveness.\nLastly, estimating the effective budget range for\nLLM-generated data is not straightforward when\nadapting to new tasks. The effective range can\nvary significantly depending on the specific data\nand tasks involved. We believe future work should\nexplore different LLMs, compare LLM and hu-\nman data more deeply, and better estimate effective\nbudget range to fully understand the potential and\nlimitations of LLM-generated data."}, {"title": "Appendix", "content": null, "subsections": [{"title": "Prompt For Pseudo-dialogue Generation\nBy LLM", "content": "An example prompt for pseudo-dialogue generation\nis shown in Figure 8."}, {"title": "Prompt For LLM SFA Labeling", "content": "The prompt provided to the LLM for SFA labeling\nis shown in Figure 9, 10, 11."}, {"title": "Length Distribution of Pseudo-dialogues", "content": "We present the length distributions of human di-\nalogues and pseudo-dialogues. We observed that\nGPT-4 generally followed the length specification\nin the instruction, resulting in an average length of\n127 tokens (token count by Japanese DeBERTa-V2\ntokenizer) compared to an average of 136 tokens\nin human dialogue sessions. Moreover, pseudo-\ndialogues have a more compact distribution, which\nmeans there are fewer extremely short or long out-\nliers."}, {"title": "Label Distribution in Pseudo-dialogues", "content": "We present the label distributions across three\ndata types: Human-Human, Human-Pseudo, and\nPseudo-Pseudo in Figure 13. When comparing\nHuman-Human to Human-Pseudo, we observe that\nreplacing human labelers with GPT-4 leads to fluc-\ntuations in certain label types. Specifically, there\nis a decrease in types such as \"BAKE_FRY\" and\n\"SIMMER\" in triggers and \"Manner\" in arguments,\nand an increase in types like \"PLACE\" in triggers\nand \"Instrument\" in arguments. While we believe\nthat these fluctuations will not be a significant issue,"}]}]}