{"title": "Memory-enhanced Invariant Prompt Learning for Urban Flow Prediction under Distribution Shifts", "authors": ["Haiyang Jiang", "Tong Chen", "Wentao Zhang", "Nguyen Quoc Viet Hung", "Yuan Yuan, Yong Li", "Lizhen Cui"], "abstract": "Urban flow prediction is a classic spatial-temporal forecasting task that estimates the amount of future traffic flow for a given location. Though models represented by Spatial-Temporal Graph Neural Networks (STGNNs) have established themselves as capable predictors, they tend to suffer from distribution shifts that are common with the urban flow data due to the dynamics and unpredictability of spatial-temporal events. To generalize STGNNs to out-of-distribution (OOD) data, a key strategy is to discover and disentangle the causal, invariant patterns from the ones that are variant and dependent on the spatial-temporal environments. However, to achieve this, existing OOD-robust methods heavily rely on learning and mimicking the underlying environments to facilitate changes in the data and consequently introduce different variant patterns. Unfortunately, in spatial-temporal applications, the dynamic environments can hardly be quantified via a fixed number of parameters, whereas learning time- and location-specific environments can quickly become computationally prohibitive. In this paper, we propose a novel framework named Memory-enhanced Invariant Prompt learning (MIP) for urban flow prediction under constant distribution shifts. Specifically, MIP is equipped with a learnable memory bank that is trained to memorize the causal features within the spatial-temporal graph. By querying a trainable memory bank that stores the causal features, we adaptively extract invariant and variant prompts (i.e., patterns) for a given location at every time step. Then, instead of intervening the raw data based on simulated environments, we directly perform intervention on variant prompts across space and time. With the intervened variant prompts in place, we use invariant learning to minimize the variance of predictions, so as to ensure that the predictions are only made with invariant features. With extensive comparative experiments on two public urban flow datasets, we thoroughly demonstrate the robustness of MIP against OOD data.", "sections": [{"title": "I. INTRODUCTION", "content": "Urban flow prediction, which involves forecasting traffic, pedestrian, and public transportation dynamics, is essential for efficient urban planning and management. Applications include smart city [1]\u2013[3], public transportation manage- ment [4]\u2013[7], and ride-sharing services [8], [9]. The insights from predictive models support both immediate traffic man- agement and long-term infrastructure planning, contributing to smarter, more sustainable urban environments with improved mobility and resource allocation.\nUrban flow data is typically structured as a spatial-temporal graph, whose nodes are commonly traffic sensors or geograph- ical locations (e.g., grids [10]), and are connected by edges based on physical proximity. Based on the time-dependent node features, the task is to predict the traffic flow associated with each node in the spatial-temporal graph at certain time steps. Given the characteristics of urban flow data, Spatial- Temporal Graph Neural Networks (STGNNs) [6], [7], [11] have emerged as a natural choice to capture urban flow dy- namics and make predictions based on historical observations. These models typically consist of two components: Graph Neural Networks (GNNs) [6], [7] for extracting spatial correla- tions between locations from the graph topology; and sequen- tial models for capturing temporal evolutions, where typical examples include Recurrent Neural Networks (RNNs) [6], [12] and Temporal Convolution Networks (TCNs) [7], [11].\nAlong this line of work, some STGNNs further improve their predictive capability by introducing dynamic graph structures based on the similarity between temporal features of nodes [13]\u2013[15], or mining the complex combinatorial effect between spatial and temporal features [16], [17].\nDespite the diversity in model designs, these models often assume that the urban flow data adheres to the independent and identically distributed (I.I.D.) assumption, which is challeng- ing to guarantee in real-world applications. After deploying a model trained with historical observations, inference is usually performed with newly arrived, unseen data points, which may contain different patterns from the training data. This phenomenon is known as distribution shift, or out-of- distribution (OOD) during test time. In urban flow prediction, the spatial-temporal regularity can be easily disturbed by unexpected events like traffic accidents or extreme weather. Furthermore, during inference, it is impractical to assume any prior knowledge on the occurrence of such disturbing factors that lead to OOD data, weakening the accuracy of predictions and the utility of existing STGNNs.\nPredicting urban flow with OOD data incurs non-trivial challenges. In Fig. 2, we provide a real example drawn from the same day (Wednesday) of two weeks from the METR- LA traffic dataset (see Section V for details), where node A (Fig. 2a) is a traffic speed sensor, and nodes B (Fig. 2b) and C (Fig. 2c) are its two closest sensors. In the spatial-temporal graph, both B and C are one-hop neighbor nodes of sensor A. One direct observation is that, distribution shifts constantly happen within consecutive time intervals, evidenced by the continuous traffic speed fluctuation over time. Although some STGNNs are able to capture periodical patterns as long-range dependencies (e.g., the same day of different weeks should have similar trends), distribution shifts that break such long- term regularity are still inevitable in complex urban flow data.\nBy comparing records from two Wednesdays, both nodes A and B are more congestive (i.e., lower speeds) between 8:00 and 12:00 in Week 3 than in Week 13, while the traffic speed between 12:00 and 20:00 in Week 13 is consistently lower than that in Week 3 at node C. As a result, in scenarios where Week 3 is a part of training data but the prediction is made with newly observed data in Week 13, the generalizability of STGNNs will be substantially limited.\nFurthermore, the heterogeneity of distribution shifts at dif- ferent locations further creates an obstacle for learning useful spatial correlations in the graph-structured urban flow data. As shown in Fig. 2, being the direct neighbors of node A, nodes B, and C exhibit distinct patterns when the new data drifts away from the earlier distribution. Since GNNs typically learn node representations by aggregating neighboring features in a predefined manner [18], [19], the impact from distribution shifts in nodes B and C will spill over onto node A, introducing more noisy signals for predicting its future traffic conditions.\nA straightforward remedy is to perform retraining every time new data points arrive to keep the STGNN model as up-to-date as possible. Unfortunately, this not only increases the com- putational costs linearly, but also challenges turnaround time in high-throughput applications (e.g., many traffic forecasting tasks [6], [20], [21] only have a 5-minute interval). Thus, before entering the update cycle, the ideal STGNN should be capable of serving accurate predictions for a reasonable period of time by generalizing to changed data distributions.\nWith the presence of distribution shifts in urban flow pre- diction, a key to enhancing the generalizability of STGNNs is to discover and leverage the invariant (i.e., causal) pat- terns within spatial-temporal data. Many studies on OOD generalization [22], [23] point out that distribution shifts are driven by the dynamics of underlying environments, where invariant risk minimization [24]\u2013[26] can be leveraged to optimize the model with augmented data drawn from diverse environments. However, directly augmenting urban flow data without substantial knowledge/heuristics on relevant external factors is prone to generating artificial distribution changes that are noisy and even misleading. As such, an alternative is to decouple invariant patterns from variant ones learned from the data [27], [28]. For example, when handling graph-structured data, [29]\u2013[31] learn two disentangled graph structures that contain either invariant or variant connections between nodes. Unfortunately, these models are misaligned with urban flow prediction tasks as they only focus on a static graph topology that does not assume the temporal evolution of node features.\nTo this end, we aim to build an OOD-robust STGNN that can distinguish invariant spatial-temporal patterns from urban flow data. Specifically, we propose Memory-enhanced Invariant Prompt learning (MIP), a novel solution to urban flow"}, {"title": "II. RELATED WORK", "content": "In this section, we review and summarize the research backgrounds that are relevant to our work.\nA. Deep Learning for Urban Flow Prediction\nAs a typical spatial-temporal prediction task, the most important part of urban flow prediction is to jointly learn time series features and topology features. Some early meth- ods [34]\u2013[36] utilize recurrent neural network (RNN) modules to learn temporal features from urban flow data. RNN-based models are adept at capturing temporal dependencies in se- quential data; early methods, such as those by [34]\u2013[36], utilize RNN modules to learn temporal features from urban flow data. RNN-based approaches often face challenges with long sequences, including inefficiencies and potential gradient issues when combined with graph convolution networks. Some models [9], [37] convert the road network to a two-dimensional grid and apply traditional convolutional neural networks to predict urban flows.\nRecently, spatial-temporal neural networks (STGNNs) have established themselves as state-of-the-art choices for urban flow prediction. STGNNs consist of GNN-based modules and sequential models that are alternately stacked, where typical variants include DCRNN [6], GWNet [7], STGCN [11] and ST-MGCN [38]. Furthermore, attention mechanisms, including multi-head attention, are additionally used in fusing spatial and temporal information, such as GMAN [39], ASTGCN [40], and PDFormer [41]. Moreover, introducing some trainable fea- tures can also improve the performance of STGNNs, even with naive backbone models, such as STID [20], STAEformer [21], and MegaCRN [42]. Besides, some physical theories can also guide spatial-temporal prediction, such as PGML [43] and STDEN [44]. However, these methods are designed based on the I.I.D assumption, making the extracted patterns solely dependent on the observed samples. Thus, these methods are prone to incorrect predictions when facing unobserved data with distribution shifts.\nB. Handling Out-of-Distribution (OOD) Data in Prediction\nIn the context of time series prediction where there are no spatial dependencies among observations, there are some representative studies that focus on OOD generalization. For example, CoST [45] leverages inductive biases in the model architecture to learn disentangled seasonal and trend represen- tations. CaseQ [46] is a novel hierarchical branching structure for learning context-specific representations of sequences. It could dynamically evolve its architecture to adapt to variable contexts. AdaRNN [47] splits historical time sequences into different classes with large distribution gaps and dynamically matches input data to these classes to identify contextual information. Dish-TS [48] separately learns the distribution of input and output spaces, which naturally captures the distribution difference. However, these models do not account for spatial information and thus are incompatible with urban flow prediction.\nTo tackle spatial distribution shifts, graph-based invariant learning is a common practice. It focuses on extracting features that are consistent across various conditions, which are then incorporated into the prediction model to enhance its accuracy. According to causal theory [27], [28], previous studies [29], [31] assume data always contain both invariant and variant patterns, while graph models sometimes make predictions based on the variant part and would fail on OOD data. Some models learn a mask over the graph adjacency matrix to separate the invariant and variant parts, such as DIDA [29], DIR [31], and CIE [30], where the disentangled invariant patterns are fed into an auxiliary model to facilitate accurate predictions. By performing interventions with the extracted variant patterns, the model is trained to better distinguish the invariant predictive signals from variant ones. Despite their applicability to graph-structured data, these models only con- sider static graphs without temporal evolutions, highlighting"}, {"title": "III. PRELIMINARIES", "content": "We hereby introduce some key preliminaries in the context of this work.\nA. Problem Formulation\nIn urban flow data, a geolocation graph can be defined as: G = {V,E}, where V is the set of N nodes and E is the set of edges. Usually, the nodes represent sensors or geographical regions that carry continuous traffic records, and an edge will connect two nodes if their physical distance is smaller than a predefined threshold. Moreover, $A \\in {0,1}^{N \\times N}$ is the adjacency matrix derived from the graph, where for node indexes n,v < N, each entry A[n,v] = 1 if (n,v) \u2208 E and A[n, v] = 0 if (n,v) \u2209 E. At each time step t \u2264 T, all nodes' dynamic features are represented via a matrix $X_t \\in R^{N \\times k}$, with k representing the dimensionality of time- varying features. In practice, $X_t[n] \\in R^k$ encodes k observed urban flow signals (e.g., in- and out-flows) of node n at time t. Note that for urban flow prediction tasks, only the node features change over time, whereas the geolocation graph structure stays unchanged [6], [11], [12], [50]. Following the commonly adopted setting [7], given the observed T historical observations {$X_t$}$_{t=1}^{T}$ and the geolocation graph G, the task objective is to train a model that predicts the next T urban flow signals {$\\{X_t\\}_{t=T+1}^{T+T}$}:\n$Y \\sim f_\\theta(X, G),$ (1)\nwhere $X, Y \\in R^{T \\times N \\times k}$ are respectively the tensorized versions of input {$\\{X_t\\}_{t=1}^{T}$} and output {$\\{X_{t'}\\}_{t=T+1}^{T+T}$}, and $f_\\theta(\\cdot)$ is the prediction model parameterized by \u03b8.\nUsually, the optimization of \u03b8 is based on the I.I.D assump- tion, which means the training data and the testing data are drawn from the same distribution. In practice, this assumption can hardly be guaranteed as the training and testing data are drawn from different environments E. In this study, we aim to develop a model with high generalization capabilities when the test data is OOD. Specifically, the optimal model parameter \u03b8* should achieve minimal risk on an OOD test set:\n$\\min_{\\theta} E_{(X', Y') \\sim p(X',Y'|E_{test})}L(f_\\theta(X', G), Y'),$\ns.t. $\\theta^* = arg \\min_{\\theta} E_{(X,Y) \\sim p(X,Y|E_{train})} L(f_\\theta (X, G), Y),$ (2)\nwhere $E_{train} \\neq E_{test}$ and $L(\\cdot)$ quantifies the prediction error.\nB. Invariant Learning under Distribution Shifts\nAs the traffic flows between geographically connected nodes, it necessitates the use of a graph neural network (GNN) to explore the spatial-temporal interactions among different nodes. Intuitively, GNNs learn a node's representation by propagating features from locally connected nodes. Denoting an arbitrary GNN model as m, for a specific node n, its representation learning process at time t can be abstracted as the following:\n$F_t (n) = m(G_n, X),$ (3)\nwhere $F_t (n)$ denotes the time-dependent latent features of node n, $G_n \\in G$ is n's ego graph that consists of node n and its neighbour nodes within predefined hops, and $X_t$ denotes the node features correspond to $G_n$ at time t. The model m is designed to capture both spatial and temporal features from the ego graph. Drawing on causality theory [27], [28], several studies [29], [31] propose the following assumption:\nAssumption 1: For an arbitrary node n and time t, given $G_n, X_t$ and the corresponding label $y_n$ drawn from any distribution, the extracted features $F_t (n)$ contains both variant patterns $F_t^v(n)$ and invariant patterns $F_t^i(n)$. Then, there exists a prediction function pred($\\cdot$), for which the invariant feature $F_t^i(n)$ is sufficiently predictive for label $y_n$ and the variant feature $F_t^v(n)$ does not hold causation to $y_n$, i.e., $y_n \\underline{||} F_t^v(n) | F_t^i(n)$. By using $\\underline{||}$ and || to respectively denote dependent and non-dependent relationships, this as- sumption can be expressed as $y_n \\underline{||} F_t^v(n)|F_t^i(n)$.\nThis assumption is represented through a Structural Causal Model (SCM) depicted in Fig.1, where each arrow in the SCM illustrates a relationship between two variables. Typically, $F_t (n)$ extracted from $G_t$ contains both variant and invariant features (line 0), jointly driving the prediction pred($F_t(n)$) to approximate $y_n$ (line 2). By disentangling the effect of invariant feature $F_t^i(n)$ (line 1) with variant feature $F_t^v(n)$ (line 3), we aim to remove the spurious relationship between"}, {"title": "IV. MIP: THE PROPOSED METHOD", "content": "In this section, we introduce a universal framework named Memory-enhanced Invariant Prompt learning (MIP) for urban flow prediction under OOD scenarios, whose main compo- nents are depicted in Figure 1. In what follows, we unfold the design of MIP by introducing the design of the memory bank, as well as the backbones for invariant learning (i.e., $f_{\\theta_2}(\\cdot)$) and spatial-temporal prediction (i.e., $f_{\\theta_1} (\\cdot)$).\nA. Memory Bank and Semantic Graph Construction\nA key advantage of our MIP is that, instead of generating intervened environment $E_s$ and simulating subsequent changes in the learned latent patterns, MIP directly intervenes the latent space to mimic the changes in the learned representations after environmental intervention. To facilitate this, we first need to mine the latent patterns correlated with the predicted labels from the time-varying node features. Therefore, we extract and store these representative causal features with a memory bank [42]. The memory bank can be represented as $\\Phi \\in R^{M \\times d}$, where M and d represent the number of virtual nodes and their dimensions, respectively. Essentially, each of the M virtual nodes in the memory bank is assigned a d-dimensional prototype vector $\\Phi[m] \\in R^d$ (m < M) that summarizes a part of the latent, invariant features within the spatial- temporal node features X. The memory bank supports two subsequent computations: generating variant and invariant prompts through a querying process, which is covered in Section IV-B; and providing a semantic graph in addition to the geographical graph for learning a node's spatial-temporal representation, which we will introduce below.\nIn urban flow prediction tasks, constructing the original graph solely based on physical distances between nodes can introduce biases during GNN's information propagation. This is because geographic proximity does not necessarily imply similar temporal patterns, especially in OOD scenarios. For instance, consider two connected nodes representing adjacent city blocks. If one block experiences a traffic accident leading to road closure and reduced traffic flow, it does not mean the neighboring block will exhibit a similar pattern. Instead, the adjacent block is likely to experience increased traffic flow as people will seek alternative routes. To address this limitation, we introduce an auxiliary graph based on the semantic distance between causal node representations, which are constructed from highly invariant features from the memory bank \u03a6. This semantic graph is able to complement the geolocation- based graph, thus providing additional predictive signals. This memory bank-based semantic graph is constructed as the following:\n$E_1 = W_A\\Phi,$\n$E_2 = W_B\\Phi,$\nA = softmax ($E_1 E_2^T$), (6)\nwhere $W_A, W_B \\in R^{N \\times M}$ are trainable projection matrices that map the M prototype vectors in the memory bank into N node representations $E_1$ and $E_2$. The row-wise softmax is responsible for scaling each node's similarity with other nodes into a distribution. As the memory bank already encapsulates critical information of the urban flow, the newly developed semantic adjacency matrix provides additional information propagation channels between nodes. Notably, different from variants that build a semantic graph for each time step based on extracted node features, our semantic graph is solely based on the memory bank. As the memory bank stays fixed and is trained to contain only invariant patterns, the same semantic graph is shared across all time steps for node representation learning. This design not only ensures efficiency, but also helps with our model's robustness in OOD scenarios as the causal edges in the memory bank-based semantic graph are free from fluctuations caused by the time-varying node features.\nB. Learning Invariant and Variant Prompts\nAs a core part of OOD generalization, we discuss given all nodes' temporal features $X_t \\in R^{N \\times k}$ correspond to time t, how to separate causal and spurious patterns \u2013 which we term invariant and variant prompts in this work. Firstly, we project the input $X_t$ into a query matrix $Q_t \\in R^{N \\times d}$.\n$Q_t = X_t W_Q + b_q,$ (7)\nwhere $W_Q \\in R^{k \\times d}$ and $b_q \\in R^d$ are trainable parameters of the linear layer. As $Q_t$ contains both invariant and variant patterns, we further disentangle them by querying the invariant memory bank. To obtain invariant prompts, we multiply the query matrix $Q_t$ with the memory bank \u03a6 to obtain a prompt score $S_t \\in R^{N \\times M}$, and then get the invariant prompt by aggregating the memory bank items with this score. This process can be formulated as:\n$S_t = softmax (Q_t \\Phi^T),$\n$H_t^i = S_t \\Phi,$ (8)\nwhere $H_t^i \\in R^{N \\times d}$ is the computed invariant prompt. Similarly, the variant prompt can be extracted in an analogous process, with a minor modification:\n$S_t = softmax (-Q_t \\Phi^T),$\n$H_t^v = S_t \\Phi,$ (9)\nwhere a negation is applied before the softmax function when calculating $S_t$, so as to flip the score distribution and assign higher weights to invariant patterns that are less relevant to the memory \u03a6. As this is executed for all time steps, we can obtain a sequence of T prompts {$H_1^i, H_2^i, ..., H_T^i$} and {$H_1^v, H_2^v, ..., H_T^v$}. By respectively concatenating invariant and variant prompts across time, we can obtain two prompt tensors $H_I, H_V \\in R^{T \\times N \\times d}$ for subsequent computations.\nC. Intervention Mechanism\nGiven the analysis in Section III-B, the data X comprises invariant and variant components that are respectively encoded into $H_I$ and $H_V$, where $H_V$ is associated with the environ- ment but unrelated to the label Y. As per our discussions earlier, the key to OOD generalization is to ensure that the invariant, causal patterns $H_I$ are fully distinguished from the variant ones $H_V$. To facilitate this, a common practice is to alter the input data's distribution with interventions on the environment, from which multiple versions of $H_V$ can be extracted. Intuitively, through invariant risk minimization, the model is able to deliver consistent predictions with minimal variance regardless of the environments. That is, a sufficiently informative $H_I$ can be isolated from the noises in $H_V$, such that the predictions are always based on the causal patterns in $H_I$. However, directly intervening in the environments is a less favorable option for urban flow prediction tasks, as this intervention mechanism [31], [32], [51] commonly needs to additionally parameterize and learn the underlying environ- ments in order to alter the raw data distribution. Consequently, this brings a dilemma where a fixed number of environments across all time steps can hardly capture the evolving nature of such spatial-temporal graphs, while simulating a set of environments for every time step can in turn introduce noises and challenge efficiency.\nAs such, we innovatively propose to generate spatial- temporal interventions in the latent space, which more ef- fectively mimics the changes in the learnable patterns after possible distribution shifts within the input data. Specifically, given the invariant and variant prompts $H_I, H_V$ extracted from X, we exchange a predefined ratio of features within $H_V$ between different nodes and time points. The details of spatial-temporal intervention are described in Algorithm 1. With Algorithm 1, we simplify the intervention process into the following:\n$\\hat{H}_V = INTERVENE(H_V, r),$ (10)\nwhere $\\hat{H}_V$ denotes the intervened variant prompts after feature exchanges have taken place for rN nodes in the graph. Note that, the swap is not constrained to node features at the same time step, so as to account for the spatial-temporal fluctuations within the variant patterns. Also, by producing intervened variant prompts with representations learned from the original input data, the generated $\\hat{H}_V$ remains plausible and challenging for refining the invariant prompts $H_I$.\nD. Invariant Learning\nAfter obtaining the intervened variant prompts $\\hat{H}_V$, we are able to train the prompt extractor described in Section IV-B via invariant learning, so as to distinguish the invariant and variant prompts. To achieve this, the invariant and the intervened variant prompts are concatenated and then input into a supplementary predictor $pred(\\cdot)$ to generate predictions:\n$\\hat{Y} = pred(H_I || \\hat{H}_V, A),$ (11)\nwhere || denotes tensor concatenation along the last dimension, $\\hat{Y} \\in R^{T \\times N \\times k}$ is the predicted urban flow at all locations and time steps. The choice of $pred(\\cdot)$ is flexible with most STGNNs. Notably, $pred(\\cdot)$ is only responsible for differenti- ating invariant and variant prompts and will not be used for computing the final predictions. Hence, we adopt GWNet [7], a simple yet effective STGNN to serve as $pred(\\cdot)$.\nFor training, we first define the loss for a single node n at one time step t:\n$l(t,n) = \\sum_{k'=1}^{k}|\\hat{Y}[t, n, k'] \u2013 Y[t, n, k']]|,$ (12)\nbased on which the invariant learning loss is defined:\n$L_{inv} = E_{(t,n)} l(t, n) + \\lambda_1 Var_{(t,n)} l(t, n),$\nt$\\in [1,T], n \\in [1, N],$ (13)\nwhere the first and second terms respectively reduce the mean and variance of the prediction error across locations and time steps. More specifically, the first term ensures that $pred(\\cdot)$ is optimized towards correctly predicting the urban flow in different environments with H, while the second term enforces that when the predictions are conditioned on H, there are minimal performance fluctuations despite the presence of noisy signals carried by the intervened variant prompts $H_V$.\nE. Backbone Model for Spatial-Temporal Prediction\nOnce the invariant features $H_I$ are extracted with the invariant learning process, a spatial-temporal backbone model needs to be in place for producing the final predictions. In MIP, our backbone model consists of alternately stacked GNN layers and temporal Transformer layers.\nGNN Layer. The GNN layer is fed with both the geographical and semantic adjacency matrices A, A and the invariant prompts $H_I$ to learn node representations with information propagation. Since the geographical adjacency matrix A is symmetric and hardly captures the directed nature of inter- actions in urban flow data, we derive forward and backward transition matrices from A through a bidirectional, degree- weighted random walk process [6]:\n$P^f = D^{-1} A, P^b = (D^T)^{-1} A^T,$ (14)\nwhere D is the degree matrix of A. By incorporating the semantic adjacency matrix, the propagation process in the GNN from layer l to l + 1 is summarized as follows:\n$\\hat{G}^{l+1} = \\sum_{z=0}^{Z} (P^z G^l W_z + P^z_b G^l W_z + \\hat{A}^z G^l W_z),$ (15)\nwhere z < Z controls the order of the information prop- agation, and $W_z^{(k)} \\in R^{d \\times d}$ denotes the learnable weights. Notably, the GNN layer only processes one graph snapshot at a time, and the initial node embeddings are set to $G^0 = H_I$ when l = 0.\nTemporal Transformer Layer. Once the GNN layer pro- cesses all graphs at all time steps, we can collect T feature matrices produced by the final graph propagation layer, de- noted by $G_1^l, G_2^l, ..., G_T^l \\in R^{N \\times d}$. For a certain node n, we can stack all its d-dimensional, time-sensitive features across T steps into a matrix, denoted by $G_n \\in R^{T \\times d}$. With that, we learn the dependencies across all temporal features of a node through a transformer layer as:\n$\\hat{G}'_n = softmax(\\frac{G_n W_Q (G_n W_K)^T}{\\sqrt{d}}) (G_n W_V),$ (16)\n$Z_n = MLP(\\hat{G}'_n),$"}, {"title": "V. EXPERIMENTS", "content": "where $W_Q, W_K ,W_V \\in R^{d \\times d}$ are trainable query, key and value projection weights, and MLP denotes a feedforward multilayer perceptron.\nPrediction Layer. After obtaining N outputs for all nodes $\\hat{H}'_1, \\hat{H}'_2, ..., \\hat{H}'_N \\in R^{T \\times d}$, we can stack all feature matrices into $\\hat{Z} \\in R^{T \\times N \\times d}$. Then, we generate the final predictions with an MLP:\n$\\hat{Y} = MLP (\\hat{Z}'),$ (17)\nwhere the MLP projects $\\hat{Z}$ into $\\hat{Y} \\in R^{T \\times N \\times k}$ that carries the predicted urban flow per time step per location.\nF. Model Optimization\nNow, we detail the optimization strategy for MIP. Firstly, based on the prediction $\\hat{Y} \\in R^{T \\times N \\times k}$ generated by the backbone model, the prediction error is quantified as follows:\n$L_{task} = \\frac{1}{T N} \\sum_{t,n,k'=1}^{T,N,k}|\\hat{Y}[t, n, k'] \u2013 Y[t, n, k']]|.$ (18)\nIn addition, as we extract invariant prompts from a memory bank, we use an auxiliary regularization loss to enhance the quality of features stored within the memory bank:\n$L_{reg} = \\frac{1}{T,N} \\sum_{t,n}^{T,N} max \\{max \\{||\\hat{H}_I^t[n] \u2013 \\Phi[a]||^2 \u2013 ||\\hat{H}_I^t[n] \u2013 \\Phi[b]||^2\\} + \\kappa, 0\\} + \\sum_{t,n}^{T,N} ||\\hat{H}_I^t[n] \u2013 \\Phi[a]||^2,$\nwhere \u03ba is a distance margin, a, b are the indices of the most and second similar virtual nodes w.r.t. node n based on the similarity score $S_t$ computed in Eq.8. Intuitively, the first term encourages the top two queried memory bank features to encode different information, while the second term aims to better align node n's invariant feature with the top feature queried from the memory bank. As such, the combination of these two regularization terms improves the diversity and representativeness of all M prototype features in the memory bank, thus refining the learned invariant features of each node at different time steps. Finally, the optimization objective aims to minimize the following overall loss:\n$L = L_{task} + L_{inv} + \\lambda_2L_{reg},$ (20)\nwith a balancing hyperparameter \u03bb2. As MIP is being trained towards convergence, the intervention on variant patterns, i.e., $\\hat{H}_V = Intervene (H_V,r)$ is re-executed in every training epoch, so as to inject more variations in the supervision signals. It is worth noting that, once MIP is trained, only the spatial-temporal backbone model described in Section IV-E is activated for making predictions in the inference stage.\nG. Discussions\nInference Time Complexity Analysis. Although MIP trains two models during the training phase, it exclusively utilizes the prediction model during inference, enabling it to deliver precise predictions with reduced time consumption. Thus, the time consumption in the inference stage is much smaller than in the training stage. The time complexity of extracting"}, {"title": "VI. CONCLUSION", "content": "In this section, we experimentally evaluate our model's generalizability under OOD settings in urban flow prediction tasks. Specifically, we aim to answer the following research questions (RQs): RQ1: Can MIP yield state-of-the-art per- formance in urban flow prediction with distributional shifts? RQ2: What is the contribution of each core component of MIP? RQ3: What is the sensitivity of MIP to its key hyperpa- rameters? RQ4: Is MIP capable of learning invariant patterns from urban flow data to ensure generalizability? RQ5: What is the scalability and efficiency of MIP?\nA. Experimental Settings\n1) Datasets: We evaluate our model on two well- established benchmarks, namely METR-LA [6] and NY- CBike [9]. METR-LA [6] is a traffic speed prediction dataset collected with 207 sensors across Los Angeles. NYCBike1 [9] is a dataset of bike rental records in New York City, where the city is divided into 8 \u00d7 16 equally-sized grids. A high-level summary of the datasets used is shown in Table I.\n2) Evaluation Protocol: We split both datasets chronolog- ically: the first 60% is for training, the following 10% for validation, and three test sets are constructed by evenly slicing the remaining data (10% for each). This is to fully mimic real- world application scenarios where a trained model is expected to provide predictions for multiple consecutive time periods with varying distributions. For convenience, we number the tree test sets with 0, 1, and 2. Generally, as test sets 0-2 become farther apart from the training set in time, their distribution shifts tend to become stronger. Based on the number of time steps available, we predict the next 12 time steps based on the past 12 on METR-LA and predict the next 6 time steps based on the past 6 on NYCBike. Similar to previous studies [7], [49], [50], We evaluate all methods in terms of Mean Absolute Error (MAE), Root Mean Square Error (RMSE), and Mean Absolute Percentage Error (MAPE). For all three metrics, lower results indicate better performance.\n3) Baselines: We compare MIP with the following state- of-the-art baselines:"}]}