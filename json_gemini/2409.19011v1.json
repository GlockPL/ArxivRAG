{"title": "Identification and Mitigating Bias in Quantum Machine Learning", "authors": ["Nandhini Swaminathan", "David Danks"], "abstract": "As quantum machine learning (QML) emerges as a promising field at the intersection of quantum computing and artificial intelligence, it becomes crucial to address the biases and challenges that arise from the unique nature of quantum systems. This research includes work on identification, diagnosis, and response to biases in Quantum Machine Learning. This paper aims to provide an overview of three key topics: How does bias unique to Quantum Machine Learning look? Why and how can it occur? What can and should be done about it?", "sections": [{"title": "I. INTRODUCTION", "content": "In classical machine learning, the importance of fairness and bias mitigation has become increasingly recognized, leading to significant research efforts and practical implementations. As Quantum Machine Learning (QML) rapidly advances and finds applications in critical domains such as drug discovery, finance, and cryptography, it becomes imperative to extend these fairness considerations to the quantum realm. While recent work has begun to address fairness in QML (e.g., development of interpretable models like Q-LIME and Q-Shapley), a comprehensive examination of biases specific to quantum systems has yet to be established. This research aims to fill that gap with these key contributions:\n1) We identify and analyze several critical instances of bias in QML systems, including the sources of these biases (i.e., data, algorithm, and measurement) and their implications for QML model performance and fairness.\n2) We present quantitative simulation results demonstrating the tangible impact of encoding bias on QML outcomes.\n3) We provide an overview of current mitigation strategies for these biases, drawing from both classical and quan- tum techniques."}, {"title": "II. SOURCES & TYPES OF BIASES", "content": "We propose that quantum-specific biases in QML can arise through features of the data, algorithms, or measurements and consider each of them.\n\nData Representation Bias\n1) Encoding Bias arises from the interaction between the transformation of classical data into quantum states, and the quantum algorithm.\nTo examine this bias, we conducted an experiment\u00b9 using various encoding techniques applied to a fixed QNN architec- ture on the MNIST dataset for classification tasks. Our results (see Figure. 1) show the significant impact of encoding choice on model performance:\n\u2022 Basis Encoding exhibited consistently low accuracy across all epochs, indicating limited learning capacity with this encoding method.\n\u2022 Angle Encoding demonstrated rapid improvement in ac- curacy, quickly reaching and maintaining high perfor- mance levels after just a few epochs.\n\u2022 Hybrid Parameterized Encoding, tested with different rotation axes ($R_x$, $R_y$, $R_z$), showed varying behaviors:\n\t- $R_x$ encoding exhibited fluctuating performance with an overall upward trend.\n\t- $R_y$ encoding showed the most rapid initial improve- ment followed by consistently high accuracy.\n\t- $R_z$ encoding initially maintained poor accuracy and experienced a significant drop before recovering in later epochs.\n\nOur experiment demonstrates Encoding bias in QML. We observe that angle and $R_y$ encoding were the most robust. Current approaches to mitigate this bias involve comprehen- sive simulation and analysis of various encoding strategies and algorithmic combinations, as demonstrated in our experiment.\n\nAlgorithmic Biases\n1) Inductive Bias is due to the assumptions required for an algorithm to appropriately model or predict previously unseen scenarios. As the number of qubits n increases, the dimension of the Hilbert space grows exponentially, and random quantum states tend to be almost orthogonal to each other due to the \"concentration of measure\" phe- nomenon. Kuebler et al [kubler2021inductive] leverage this to demonstrate that the largest eigenvalue of a kernel matrix constructed from the inner products of these quantum states is extremely small, meaning that the kernel can only represent nearly constant functions. This severely limits its ability to learn complex func- tions unless the dataset is exponentially large. However,"}, {"title": "Measurement Biases", "content": "1) State-Dependent Bias is a measurement bias where qubits in different states have unequal probabilities of being measured correctly, typically favoring the lower energy state (0) over the higher energy state (1). This bias arises from qubits' natural tendency to relax to the lower energy state. An experiment by Tannu and Qureshi [tannu2019mitigating] demonstrated this phenomenon and found that the fidelity of an all-zero state was 84%, but it dropped to 62% for an all-one state, even though these states are logically interchangeable for many prob- lems (i.e., choice of a variable value as 0 vs. 1 is arbitrary). Proposed mitigation strategies for this bias in- clude the \"Invert-And-Measure\u201d [tannu2019mitigating] method where the higher energy qubits are inverted via an \"X\" gate and then measured.\n2) Sampling Bias arises when the limited number of mea- surements performed on a quantum system is insufficient to fully capture its state, leading to an incomplete and potentially inaccurate representation of the system. Quantum measurements project the state of a system onto a basis, collapsing the wavefunction into a specific outcome. To obtain the full probability distribution, one would need to perform a vast number of measure- ments on different bases. However, in practice, only a limited number of measurements can be performed due to constraints on time, resources, and experimental capabilities. This restricts the sampling to a subspace of the Hilbert space, making it impossible to reconstruct the full probability distribution for higher-order systems. Currently, solutions to this include Quantum State To- mography with Compressed Sensing."}, {"title": "III. CONCLUSION", "content": "This research examines five biases unique to QML: Encod- ing, Inductive, Realizability, State-Dependent, and Sampling. These biases, stemming from quantum properties, challenge QML's reliability and performance. Our experiment on Encod- ing bias demonstrates this. We used a QNN with different en- codings on the MNIST dataset. The results provide empirical evidence of bias in QML systems, highlighting how different quantum encodings can lead to varying model performances even when the underlying architecture remains constant. While recent advancements in interpretable QML models appear promising, substantial work remains to be done."}]}