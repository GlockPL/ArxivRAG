{"title": "EasyRec: Simple yet Effective Language Models for Recommendation", "authors": ["Xubin Ren", "Chao Huang"], "abstract": "Deep neural networks have become a powerful technique for learning representations from user-item interaction data in collaborative filtering (CF) for recommender systems. However, many existing methods heavily rely on unique user and item IDs, which limits their ability to perform well in practical zero-shot learning scenarios where sufficient training data may be unavailable. Inspired by the success of language models (LMs) and their strong generalization capabilities, a crucial question arises: How can we harness the potential of language models to empower recommender systems and elevate its generalization capabilities to new heights? In this study, we propose EasyRec - an effective and easy-to-use approach that seamlessly integrates text-based semantic understanding with collaborative signals. EasyRec employs a text-behavior alignment framework, which combines contrastive learning with collaborative language model tuning, to ensure a strong alignment between the text-enhanced semantic space and the collaborative behavior information. Extensive empirical evaluations across diverse real-world datasets demonstrate the superior performance of EasyRec compared to state-of-the-art alternative models, particularly in the challenging text-based zero-shot recommendation scenarios. Furthermore, the study highlights the potential of seamlessly integrating EasyRec as a plug-and-play component into text-enhanced collaborative filtering frameworks, thereby empowering existing recommender systems to elevate their recommendation performance and adapt to the evolving user preferences in dynamic environments. For better result reproducibility of our EasyRec framework, the model implementation details, source code, and datasets are available at the link: https://github.com/HKUDS/EasyRec.", "sections": [{"title": "1 INTRODUCTION", "content": "Deep learning has established itself as a highly promising and powerful solution for capturing user preferences in the context of online recommender systems [42, 50]. This approach harnesses the power of deep neural networks to learn rich and meaningful user and item representations by analyzing the complex patterns of user-item interactions. This, in turn, enables recommendation algorithms to accurately infer user preferences and provide highly relevant and personalized recommendations [30, 41].\nIn recent years, there has been a notable surge of advancements in enhancing recommender systems through the incorporation of neural network-powered collaborative filtering frameworks, particularly in the domain of graph neural networks (GNNs) [10, 32, 37]. By effectively leveraging the inherent graph structure present in the data, GNNs have demonstrated exceptional capabilities in capturing high-order relationships and complex dependencies among users and items. Notable examples of such GNN-based approaches include NGCF [32] and LightGCN [10]. These methods have showcased impressive performance in recommendation tasks by virtue of their ability to model the collaborative signals present in the data through recursive message passing mechanisms.\nThe issue of data scarcity in recommender systems poses a significant challenge for existing deep collaborative filtering models, hindering their ability to learn precise user/item representations, particularly when dealing with sparse interaction data [9, 18, 26, 33]. This challenge primarily arises from the limited availability of training labels, which in turn impedes the models' capacity to capture the intricate relationships and dependencies that exist between users and items. To alleviate data scarcity effects, recent studies explored the potential of self-supervised learning to provide effective data augmentation. For example, in terms of contrastive augmentation, methods like SGL [34] and NCL [19] leverage graph contrastive learning to supplement the supervised recommendation task with the cross-view mutual information maximization. For generative augmentation, approaches such as AutoCF [36] are built upon the masked autoencoding mechanism, enabling the models to reconstruct the interaction structures for self-supervision.\nWhile the recent advancements in self-supervised learning techniques have offered promising avenues for mitigating the impact of data scarcity in current collaborative filtering models, they also come with a significant limitation [45]. This limitation stems from the inherent design of the models, which heavily relies on using unique identities (IDs) to represent users and items throughout the entire process of learning representations. In practical recommenders, however, we often come across new recommendation data collected from different domains or time periods, involving diverse sets of users and items. This creates a challenge as existing ID-based recommendation models struggle to effectively incorporate and adapt to such new data, especially when there is a change in the set of identity tokens of users and items for zero-shot recommendation. The rigid dependence on user and item IDs in these models hinders their ability to generalize and perform well in scenarios where the user and item spaces are not static or fully overlapping. For instance, the constant generation of new items like videos and social media content necessitates accurate recommendations in real-life recommender systems, even when there are limited interaction observations. While cross-domain recommendation"}, {"title": "2 PRELIMINARIES", "content": "In recommender systems, we have a set of users U and a set of items I, along with the interactions between them (e.g., clicks, purchases). For each user u \u2208 U, we define $N_u$ as the set of items that user u has interacted with. Likewise, for each item i \u2208 I, we define $N_i$ as the set of users who have interacted with that item. To represent these user-item interactions, we can use an interaction matrix $A_{|U| \\times |I|}$, where the entry $A_{u,i}$ is 1 if user u has interacted with item i, and 0 otherwise. The primary goal of a recommender model is to estimate the probability $p_{u,i}$ of a future interaction between a user u and an item i. This predicted probability can then be used to generate personalized item recommendations for each user, tailored to their individual preferences and past behavior.\nText-based Zero-Shot Recommendation is essential in recommender systems, as it can address the common cold-start problem. In real-world scenarios, new users and new items often lack sufficient interaction data, making it challenging to provide effective personalized recommendations. By leveraging the textual descriptions of users and items, such as product titles, details, and user profiles, the language models can construct semantic representations to enable text-based recommendations for these cold-start situations. This overcomes the limitations of traditional collaborative filtering methods, by offering a distinct advantage over the traditional ID-based paradigm. By leveraging robust language models, this approach exhibits remarkable potential in \"zero-shot\u201d scenarios, where the testing data have not been previously encountered.\nFormally, we define $P_u$ and $P_i$ as the generated text-based profiles of user u and item i, respectively, which are encoded into"}, {"title": "3 METHODOLOGY", "content": "In this section, we first discuss how we gather textual profiles for users and items in recommender systems, which are essential for pre-training and evaluating our model. Next, we'll dive into the specifics of EasyRec and its training approach. Lastly, we'll introduce our method for diversifying user profiles, which improves the model's ability to adapt to various situations."}, {"title": "3.1 Collaborative User and Item Profiling", "content": "In real-world recommenders, the only available information may be raw text data, such as product titles and categories, associated with the items. Privacy concerns often make it difficult to collect comprehensive user-side information. Furthermore, directly leveraging such textual information may overlook the crucial collaborative relationships needed for accurate user behavior modeling and preference understanding. To address these limitations, we propose to generate textual profiles by leveraging large language models (e.g., GPT, LLAMA series) [25] to inject collaborative information into the textual profiles. This allows us to capture both the semantic"}, {"title": "3.1.1 Item Profiling.", "content": "Given the raw item information, such as title $h_i$, categories $c_i$, and description $d_i$ (e.g., book summary), we aim to generate a comprehensive item profile $P_i$ that captures both the semantic and collaborative aspects. To reflect user-item interactions, we incorporate the textual information (e.g., posted reviews $r_{u,i}$) provided by the item's corresponding users. Formally, the item profile generation process is:\n$P_i = LLM(M_i, h_i, c_i, \\{r_{u,i}\\} ) \\text{ or } LLM(M_i, h_i, d_i)$, (4)\nHere, $M_i$ represents the generation instruction, while $h_i$ and $d_i$ serve as input. By leveraging large language models (LLMs), we can generate a concise yet informative item profile $P_i$."}, {"title": "3.1.2 User Profiling.", "content": "In practical scenarios, privacy concerns often limit the feasibility of generating user profiles based on demographic information. Instead, we can profile users by considering their collaborative relationships, using the generated profile information from their interacted items. This approach allows the user profiles to effectively capture the collaborative signals that reflect their preferences. Formally, the user profile generation process is:\n$P_u = LLM(M_u, \\{h_i, P_i, r_{u,i} | i \\in N_u\\} )$. (5)\nHere, $M_u$ represents the instruction for generating the user profile using a large language model (LLM). We sample a set of interacted items $N_u$ from the user's purchase history. We then combine the user's feedback $r_{u,i}$ with the pre-generated item profiles $P_i$ to create the user's text description $P_u$, which captures their preferences."}, {"title": "3.1.3 Advantages of Collaborative Profiling.", "content": "Our collaborative user and item profiling framework offers two key advantages for real-world recommendation scenarios which are elaborated as:\n\u2022 Collaborative Information Preserved. Our collaborative pro-filing approach goes beyond just the original textual content, also capturing the semantics of user/item characteristics and their interaction patterns. By encoding these rich profiles into a shared feature space using a recommendation-oriented language model, the resulting embeddings of interacted users and items are brought closer together. This enables the recommenders to better identify relevant matches, even for \"zero-shot\" users and items (those without prior interactions) which are ubiquitous in real-world scenarios. The system can leverage the collaborative signals encoded within the text-based profiles to make better recommendations, bridging the gap for these cold-start cases."}, {"title": "3.2 Profile Embedder with Collaborative LM", "content": "So far, we have generated rich textual profiles for users and items, moving beyond conventional ID-based embeddings. However, directly encoding these textual profiles into latent embeddings for making recommendations may have two key limitations:\n\u2022 Capturing Recommendation-Specific Semantics. The text-based embeddings, while expressive, may not be optimized for the specific semantics and relationships most relevant to the recommendation task. For example, consider two item profiles: (1) \"This user is passionate about advanced AI techniques, focusing on deep learning and AI research works\". (2) \"With a passion for advanced Al development, this user delves into science fiction and AI-themed novels\". Though the profiles share textual similarity about AI, their target audiences differ - the first caters to Al scientists, the second to sci-fi readers. Directly encoding these profiles may overlook nuanced, recommendation-specific semantics. Refinement is needed to better align embeddings with the specific context and requirements of the recommendation system, beyond just textual similarity.\n\u2022 Overlooking High-Order Collaborative Signals. While tex-tual profiles offer rich semantic information, relying solely on them may cause us to overlook valuable high-order collaborative patterns that emerge from complex user-item interactions [32, 36]. These higher-order signals, such as transitive associations and community-level preferences, can provide additional insights that complement the textual data for user preference learning in recommender systems.\nTo address these limitations, we propose a collaborative language modeling paradigm that seamlessly integrates the strengths of the semantic richness of the profiles and the valuable collaborative signals encoded from complex user-item interaction behaviors."}, {"title": "3.2.1 Bidirectional Transformer Encoder as Embedder.", "content": "We leverage a multi-layer bidirectional Transformer encoder as the embedder backbone, considering two key benefits: 1) Efficient Encoding: The encoder-only architecture focuses solely on generating effective text representations, enabling faster inference in recommendation systems. 2) Flexible Adaptation: By building on pre-trained Transformer models, we can leverage transfer learning to optimize the embedder for specific recommendation tasks.\nLet's consider a user's profile as a passage of n words: $P = W_1,..., W_n$. We start by adding a special token [CLS] at the beginning of the word sequence. The tokenization layer then encodes the input sequence into initial embeddings, which serve as the input"}, {"title": "3.2.2 Collaborative LM with Contrastive Learning.", "content": "The motivation behind fine-tuning the collaborative language model using contrastive learning is to effectively capture and incorporate high-order collaborative signals into the recommendation model. Traditional recommenders using Bayesian Personalized Ranking (BPR) [27] optimize encoded embeddings with only one negative item per training sample. This approach limits the model's ability to capture complex global user-item relationships."}, {"title": "3.3 Augmentation with Profile Diversification", "content": "The goal of our profile diversification approach is to enhance the model's ability to generalize to unseen users and items. Representing each user or item with a single profile inherently limits the diversity of the representations, which can negatively impact the model's performance and generalization. To address this, we propose augmenting the existing user/item profiles to allow for multiple profiles per entity. These augmented profiles capture the same semantic meaning, such as the personalized interaction preferences of users or the varied characteristics of items. Our two specific augmentation methods introduce controlled variations in the profiles while preserving the core semantic meaning.\nInspired by self-instruction mechanisms [40, 40], large language models (LLMs) can be leveraged to rephrase user or item profiles while preserving their underlying meaning. This allows generating multiple semantically similar yet distinctly worded profiles from a single input. Applying this iterative rephrasing process can create a diverse set of augmented profiles, substantially expanding the available training data. This data augmentation technique is particularly valuable when the original dataset is limited, as the LLM-generated profiles can improve model generalization and robustness.\nBy leveraging large language models for profile diversification, we can create a set of diverse profiles for each user u and item i.\n\\{P\\}_u = \\{P_u; P^1, P^2, ..., P^t\\}, (13)\n\\{P\\}_i = \\{P_i; P^1, P^2, ..., P^t\\}. (14)"}, {"title": "4 EVALUATION", "content": "This section evaluates the performance of the proposed EasyRec framework in addressing the following research questions (RQs):\n\u2022 RQ1: How effectively does the proposed EasyRec perform in matching unseen users and items (zero-shot) within text-based recommendation scenarios?\n\u2022 RQ2: How effectively does EasyRec integrate with and enhance various recommenders within text-based collaborative filtering scenarios, leveraging its capabilities as a language embedder?\n\u2022 RQ3: How effective is our proposed profile diversification mechanism for data augmentation in improving the performance of the recommendation language model?\n\u2022 RQ4: How well can our proposed text-based EasyRec paradigm adapt to accommodate changes in users' dynamic preferences?"}, {"title": "4.1 Experimental Settings", "content": "4.1.1 Datasets. To assess our proposed model's capability in encoding user/item textual profiles into embeddings for recommendation, we curated diverse datasets across various domains and platforms. A portion was used for training, while the remainder served as test sets for zero-shot evaluation. The dataset statistics are shown in Table 1. Due to the page limit, we place the detail of data resources are described in Appendix A.2.1\n4.1.2 Evaluation Protocols. We employ two commonly used ranking-based evaluation metrics, Recall@N and NDCG@N, to"}, {"title": "4.2 Performance Comparision for Text-based Recommendation (RQ1)", "content": "We evaluate the performance of various language models (LMs) for zero-shot text-based recommendation on the unseen Sports, Steam, and Yelp datasets. This approach directly leverages the encoded embeddings derived from user/item profiles to make recommendations, without any additional training on the target datasets."}, {"title": "4.2.1 Baseline Methods and Settings.", "content": "For our comparative evaluation, we included a diverse set of language models as text embedders: (i) General Language Models: BERT [4], ROBERTa [21], and"}, {"title": "4.2.2 Result Analysis.", "content": "The overall comparison of different models is presented in Table 3. This evaluation reveals several noteworthy observations, which are outlined below:\n\u2022 Superiority across Diverse Datasets. Our evaluation consis-tently shows that the EasyRec outperforms all other models across the three datasets spanning different platforms. This provides strong evidence for the effectiveness of the EasyRec. We attribute these improvements to two key factors: i) By injecting collaborative signals into the language models, we effectively optimized our EasyRec using supervised contrastive learning within the recommendation context. This approach allows the model to inherently encode user and item text embeddings that are well-suited for recommendation tasks. ii) By integrating a diverse array of datasets across multiple categories and utilizing data augmentation techniques to enrich the text descriptions for training, our EasyRec exhibits impressive generalization capabilities, enabling it to effectively handle unseen data.\n\u2022 Scaling Law Investigation of EasyRec Model. Our experi-ments revealed that as the size of the EasyRec model increases (from small to large), its performance consistently improves across all three datasets. This observation reflects a scaling law,"}, {"title": "4.2.3 Impact of Training Objectives.", "content": "Furthermore, we evaluate the impact of different training objectives on the language model's learning process. To this end, we implemented EasyRec-Large training using BPR loss (i.e., one negative item per training sample) for comparison with the contrastive learning results. This approach allows us to directly assess how the choice of training objective influences model performance. As shown in Table 4, the performance of the model trained with contrastive learning generally outperforms that of the model trained with BPR loss. This outcome highlights the effectiveness of employing contrastive learning to better incorporate collaborative information into the language models, thereby enhancing their overall performance in recommendation tasks."}, {"title": "4.3 Performance of Text-enhanced CF (RQ2)", "content": "In addition to our investigation of zero-shot recommendation scenarios, we explore the potential of EasyRec as an enhancement when integrated with CF models. To assess the effectiveness of various LMs in CF, we employ two widely used ID-based methods as backbone models: GCCF [2] and LightGCN [10], which were chosen for their proven effectiveness and efficiency. Furthermore, we utilize the advanced model-agnostic text-enhanced framework RLMRec [25] with contrastive alignment to conduct our investigation. We compare the large versions of both EasyRec and other open-source LMs. The key findings from the results in Table 5 are:"}, {"title": "4.4 Effectiveness of Profile Diversification (RQ3)", "content": "In this section, we examine the impact of diversifying user and item profiles with large language models (LLMs) on model performance. As mentioned in Section 3.3, we perform LLM-based diversification three times on the original generated profiles. This process continuously increases the number of profiles in the training set. To investigate whether data augmentation positively affects model performance, we conduct experiments with three variants of the EasyRec under different numbers of diversified profiles. The results are shown in Figure 4, leading to the following key observations:\n\u2022 Effectiveness of Profile Diversification. The increase in the number of diversified profiles (from 0 to 3) enhances model performance, particularly for larger models. This finding underscores the effectiveness of our augmentation approach using LLMs for profile diversification, and emphasizes the significance of increasing training data for improved outcomes.\n\u2022 Scaling Relationship: The scaling experiments on both model size and data size reveal a crucial relationship that influences model performance. This demonstrates that our approach of training the language model with collaborative signals follows a scaling law, indicating that model performance benefits from both increased capacity and data volume. Such scaling laws are vital as they provide insights into how model capacity and data availability interact, guiding future research and development."}, {"title": "4.5 Model Fast Adaptation Case Study (RQ4)", "content": "As mentioned in Section 3.1.3, a key advantage of EasyRec is its ability to empower recommender systems to efficiently adapt to shifts"}, {"title": "5 RELATED WORK", "content": "LMs-Powered Recommender Systems. Recent advancements in recommender systems increasingly incorporate textual modalities [45], thus enhancing traditional approaches. The semantic representations encoded by pre-trained language models are essential features for improving recommender models, particularly in click-through rate prediction [8, 35] and transferable sequence recommendations [13]. These embeddings capture informative content relevant to recommendation tasks [28]. Some works also leverage text-based agents to enhance performance [47, 48]. A notable recent contribution is RLMRec [25], a text-enhanced framework that improves ID-based recommenders using principles from information theory. However, many prior studies have relied on general text embeddings, such as BERT-based models [5, 45] or proprietary OpenAI embeddings [25], rather than those specifically tailored for recommendation purposes. A recent work BLAIR [12] leverages the item metadata and interaction-level user feedback on this item for LMs training, yielding promising results in query-based item retrieval. In contrast, our approach assigns each user and item a collaboratively generated profile that reflects their preferences. EasyRec optimizes the learned correlations between user and item entities using CF signals, which not only demonstrates impressive zero-shot performance but also enhances text-augmented results.\nCross-Domain Recommendation. The fundamental concept behind cross-domain recommendation is to enhance recommendations in one domain by leveraging data from another domain, which is typically more abundant, to address data sparsity and improve"}, {"title": "6 CONCLUSION", "content": "The EasyRec framework effectively integrates LMs to enhance recommendation tasks. Our new paradigm, which is both straightforward and effective, has consistently proven to excel across various scenarios, including text-based zero-shot recommendation and text-enhanced collaborative filtering. At the heart of EasyRec's success lies an innovative methodology that combines collaborative language model tuning with the transformative capabilities of contrastive learning. This unique approach has empowered EasyRec to capture nuanced semantics and high-order collaborative signals-critical elements that have been instrumental in driving remarkable improvements in recommendation performance. Our extensive experiments, which span a diverse array of datasets, have consistently validated the superiority of EasyRec over existing language models. This robust and generalized performance underscores the framework's remarkable capacity to adapt to dynamic user preferences, making it well-suited for real-world industry scenarios. Furthermore, the consistent improvements observed across different settings indicate that EasyRec is not only effective but also versatile in its application. Looking ahead, the potential for EasyRec to be seamlessly integrated with multi-modal information presents an enticing frontier for our future investigations."}, {"title": "A APPENDIX", "content": "A.1 Implementation and Training Details\nWe implemented our EasyRec and conducted all experiments using PyTorch [24]. For the transformer-based encoder backbone, we adopted the architecture of RoBERTa [21] and utilized its pretrained parameters as initialization. We trained three versions of EasyRec with varying parameter sizes (small, base, and large), as detailed in Table 2. For the loss function, we set the hyperparameters \u03c4 to 0.05 and \u03bb to 0.1. The token masking ratio for masked language modeling is 0.15, and the learning rate is set to 5 \u00d7 10\u22125. We train the model for 25 epochs. For profile augmentation, we set the diversification time t for LLM-based methods to 3, resulting in 4 user profiles and 5 item profiles per dataset. During training, we evaluate the model every 1000 steps and use the validation interactions from each training dataset to select the optimal model parameters, employing the Recall@20 metric. Detailed implementation of our model is provided in our anonymous released code."}, {"title": "A.2 Datasets and User/Item Profiles", "content": "In this section, we provide detailed information on the datasets, as well as the processes for profile generation and diversification, including instructions, examples, and associated costs."}, {"title": "A.2.1 Details of Dataset.", "content": "We utilize datasets from Amazon review data [22] across six categories to form the training data: Arts, Crafts and Sewing (Arts), Movies and TV (Movies), Video Games (Games), Home and Kitchen (Home), Electronics (Electronics), and Tools and Home Improvement (Tools). For the test datasets, we use one domain, Sports and Outdoors (Sports), from the Amazon review data, along with two cross-platform datasets: Steam and Yelp, for comprehensive evaluation. For the datasets from the Amazon platform, we first filter the data to include only those with a rating score greater than 3 and apply a 10-core filtering to densify the dataset. Subsequently, for each category, we split the interactions into training, validation, and test splits in a ratio of 8:1:1. In contrast, for the Steam and Yelp datasets, we directly use the data processed in previous work [25], which maintains a split ratio of 3:1:1."}, {"title": "A.2.2 Details of Profile Generation.", "content": "After data processing, each dataset contains a split of training interactions. We use these interactions to generate user and item profiles following the paradigm described in Section 3.1, as this requires user-item interaction information. For the Steam and Yelp datasets, we directly use the provided profiles, which adhere to the same generation protocol. It is important to note that, for each dataset, the profiles are generated exclusively based on the training interactions. This approach ensures that the validation and test interactions are reserved for evaluation purposes, preventing data leakage and allowing for a more accurate assessment of the model's generalization performance on unseen recommendation data."}, {"title": "A.2.3 Details of Profile Diversification.", "content": "As described in Section 3.3, we also conduct profile diversification using large language models (LLMs) to enhance the diversity of the training and test datasets, thereby improving and better evaluating the model's generalization ability across different user and item profiles. For each user or item, we perform t iterations of diversification starting from the initially generated profile. This means that we obtain the first diversified profile based on the original profile and then use this diversified profile for further diversification with the LLMs.\nFor reference, examples of user and item profile diversification are provided in Figure A and Figure A, respectively. As illustrated in the case of user profile diversification, the profiles for the same user differ at the word level while still representing the same preferences. Such diversification significantly enhances the diversity and quality of the textual data while also increasing the overall dataset size."}, {"title": "A.2.4 Cost of Generation and Diversification.", "content": "We summarize the total number of tokens and the associated costs for utilizing the proprietary model for profile generation and diversification in Table 6. It is worth noting that the profiles for the Steam and Yelp datasets have already been generated; therefore, the number of profiled datasets and diversified datasets differs. As shown in the results, the total number of tokens required to process both profile generation and diversification is approximately 322 million, including both input and output tokens. This generally incurs a cost of around 200 dollars with GPT-3.5-Turbo API to process the entire dataset, making it an affordable option."}, {"title": "A.3 Details of Text-based Recommendation", "content": "A.3.1 Baseline Models. In this section, we provide a detailed description of the language models compared in this work.\n(i) General Language Models.\n\u2022 BERT [4]: A landmark transformer-based model renowned for strong language understanding through bidirectional training. We use the pooled BERT output as the text embedding.\n\u2022 ROBERTa [21]: An optimized BERT that employs dynamic masking and larger datasets. We use the final [CLS] token embedding."}]}