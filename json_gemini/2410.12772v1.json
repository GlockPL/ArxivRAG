{"title": "Vaccinating Federated Learning for Robust Modulation Classification in Distributed Wireless Networks", "authors": ["Hunmin Lee", "Hongju Seong", "Wonbin Kim", "Hyeokchan Kwon", "Daehee Seo"], "abstract": "Automatic modulation classification (AMC) serves a vital role in ensuring efficient and reliable communication services within distributed wireless networks. Recent developments have seen a surge in interest in deep neural network (DNN)-based AMC models, with Federated Learning (FL) emerging as a promising framework. Despite these advancements, the presence of various noises within the signal exerts significant challenges while optimizing models to capture salient features. Furthermore, existing FL-based AMC models commonly rely on linear aggregation strategies, which face notable difficulties in integrating locally fine-tuned parameters within practical non-IID (Independent and Identically Distributed) environments, thereby hindering optimal learning convergence. To address these challenges, we propose FedVaccine, a novel FL model aimed at improving generalizability across signals with varying noise levels by deliberately introducing a balanced level of noise. This is accomplished through our proposed harmonic noise resilience approach, which identifies an optimal noise tolerance for DNN models, thereby regulating the training process and mitigating overfitting. Additionally, FedVaccine overcomes the limitations of existing FL-based AMC models' linear aggregation by employing a split-learning strategy using structural clustering topology and local queue data structure, enabling adaptive and cumulative updates to local models. Our experimental results, including IID and non-IID datasets as well as ablation studies, confirm FedVaccine's robust performance and superiority over existing FL-based AMC approaches across different noise levels. These findings highlight FedVaccine's potential to enhance the reliability and performance of AMC systems in practical wireless network environments.", "sections": [{"title": "I. INTRODUCTION", "content": "VER the course of time, there has been a rapid evolution in wireless communication technologies, particularly in their applications integrated with the Internet of Things (IoT), providing substantial benefits to global-wide users [1], [2]. Notably, the infusion of Artificial Intelligence (AI) technology into wireless communication has significantly contributed to enhancing the efficiency of various communication systems, encompassing network optimization [3], resource management [4], Multiple-Input and Multiple-Output (MIMO) system operation [5], enhancing network security [6], and optimizing Quality of Service (QoS) [7].\nThe incorporation of AI in wireless networks, particularly in the domain of Automatic Modulation Classification (AMC) tasks, has led to significant performance improvement in the modulation recognition systems [8]. Given the widespread utilization of AMC techniques in practical scenarios, such as cellular networks, Wi-Fi systems, satellite communication, radar systems, and other wireless technologies, the integration of AI technology in AMC has brought high-performance and effective AMC schemes across diverse conditions in the wireless IoT network [9]. AMC technology contends with a multitude of signals emanating from diverse user devices dispersed across varied environments. Within this distributed framework, the conventional paradigm of centralized learning presents notable drawbacks in terms of privacy concerns and resource constraints, including large communication bandwidth costs and storage expenses associated with transmitting and storing locally curated datasets to a central server.\nFederated learning (FL) emerges as a suitable paradigm for addressing those constraints, primarily due to its intrinsic characteristics that preserve privacy, alleviate communication overhead, and substantially reduce storage utilization [10]. The decentralized nature of FL enables local model training on edge devices, eliminating the necessity to transmit raw data to a central server. The adaptability of the FL framework within the heterogeneous nature of user data enhances operational effectiveness across distributed IoT systems, concurrently promoting cost efficiency and fortifying the system against faults. Furthermore, the continuous learning capability after deployment inherent in FL proves pivotal for time-sensitive applications, as evidenced by its application in modulation classification within dynamic communication landscapes [9], [11], [12]. Therefore, the manifold advantages of FL illustrate a necessary framework for addressing AMC challenges in wireless networks.\nHowever, in the context of a distributed wireless system, where data is collected from diverse devices under certain user conditions, the impact of noise becomes particularly pronounced. The performance of AMC models is heavily dependent on the quality of the input datasets, making the inherent noise in wireless signals a critical challenge to their resilience. Existing research in AMC [8], [9], [11], [13]\u2013[17] has predominantly evaluated model effectiveness under specific noise conditions, typically quantified by Signal-to-Noise Ratio (SNR). These studies consistently demonstrate that models trained on high SNR data perform well, while those exposed to low SNR data struggle.\nThis emphasis on high SNR data aligns with the conven-tional wisdom that low-noise signals simplify the training of deep neural network (DNN)-based modulation decoders by enabling the extraction of clear, distinguishable features. However, this focus inadvertently fosters a bias, suggesting that high SNR conditions are universally optimal for training DNN models. This perspective risks promoting overfitting, as models trained exclusively on high SNR data may fail to generalize across diverse noise environments. In real-world applications, wireless communication systems often encounter a broad range of noise levels, resulting in significant noise variance that AMC models must contend with. The prevailing focus on high SNR conditions in training does not adequately address this variability, thereby undermining the generalizability and robustness of AMC models in practical, noise-prone environments. Addressing this gap is crucial for developing more resilient and adaptable AMC systems capable of maintaining performance across varying and unpredictable noise conditions.\nFurthermore, recent research has proposed the utilization of FL in AMC models, aiming to harness the benefits of FL methodologies within distributed environments [13]\u2013[16], [18]\u2013[21]. Prior studies on FL-based AMC models have predominantly revolved around addressing the challenges posed by non-IID (Independent and Identically Distributed) environ-ments within distributed settings. However, existing works often narrowly target singular non-IID issues, especially a class imbalance problem [13], [18], [22], overlooking the myriad of other non-IID complexities inherent in distributed datasets. These complexities encompass variations in dataset volume, statistical distributions across distributed clients, incongruent features, and SNR discrepancies.\nMoreover, the current FL-based AMC models predomi-nantly rely on a linear aggregation approach, which exhibits notable limitations in seamlessly integrating locally optimized parameters. This process often leads to information loss during aggregation, thereby compromising the efficacy of collaborative learning, particularly within non-IID environments. Importantly, this challenge is not unique to FL-based AMC models but is also pervasive in conventional Federated Averaging (FedAvg)-based methodologies [23], [24]. Addressing these limitations is paramount for advancing the effectiveness and scalability of FL-based AMC models in real-world distributed settings. To summarize, the existing constraints in FL-based AMC classification can be delineated as follows:\n\u2022 The enduring challenge posed by diverse noise sources in modulation signals highlights the critical importance of implementing effective noise management strategies in distributed wireless networks.\n\u2022 The common practice of exclusively evaluating models based on specific SNR values may foster a bias towards the belief that consistently high SNR levels are necessary for AMC model training, potentially resulting in overfitting issues in real-world scenarios characterized by diverse SNR ranges.\n\u2022 The existing aggregation process in FL-based AMC mod-els, relying on linear-based parameter aggregation, faces challenges in effectively integrating models trained under non-IID conditions, thereby constraining its performance in heterogeneous environments.\nTo address these challenges, we introduce a novel FL framework FedVaccine. This framework is grounded on two fundamental principles. Firstly, inspired by the concept of vaccination in the medical domain, FedVaccine incorporates a controlled noise exposure strategy during DNN model training to foster resilient modulation classification performance across diverse noise levels. Leveraging our harmonic noise resilience methodology, we systematically explore the optimal noise tolerance within signals, thereby achieving a delicate balance between dataset robustness and model regularization to mitigate overfitting issues. We comprehensively investigate the impact of noise tolerance of the DNN-based AMC model, revealing that models trained with balanced levels of noise exhibit superior performance over those trained solely with high SNR signals, thus enhancing the model's resilience and generalizability.\nSecondly, diverging from conventional linear aggregation methods employed in FL, FedVaccine adopts a split learning approach. This strategy entails partitioning multiple participant local parameter sets into distinct clusters and subsequently integrating intra-cluster models while cumulatively updating across inter-cluster iterations. Moreover, we incorporate an adaptive queue data structure to mitigate bias within non-IID settings, thereby addressing practical memory constraints within local devices. This nuanced approach fine-tunes the global model to preserve pre-trained parameter attributes, thereby minimizing information loss during the integration process.\nOur extensive experimentation, spanning a wide range of noise levels and three prevalent non-IID scenarios, demonstrates the remarkable performance enhancement of FedVaccine compared to existing FL-based AMC models. These results underscore FedVaccine's efficacy in achieving accurate and resilient modulation classification, thereby making significant contributions to the advancement of wireless communication technology. In summary, the contributions of our work are summarized as follows:\n\u2022 Noise-Resilient Training Strategy: We introduce a har-monic noise resilience approach that achieves balanced noise tolerance, regularized model training, and enhances the generalizability of modulation classification across diverse noise levels.\n\u2022 Introduction of FedVaccine: We propose a novel Fed-erated Learning framework named FedVaccine, designed to address practical non-IID issues and enhance optimization for robust modulation classification performance.\n\u2022 Comprehensive Experimental Validation: We conduct extensive experiments and ablation studies to evaluate FedVaccine's performance and demonstrate its efficiency"}, {"title": "II. RELATED WORKS", "content": "AMC technology is a critical component of modern wireless systems, providing a range of advantages that include improved adaptability, optimized spectral efficiency, guaranteed QoS, and support for cognitive radio functionalities [11]. By allowing wireless IoT networks to function efficiently in dynamic and challenging environments, AMC technology enhances the ability of communication systems to coordinate, optimize, and maintain consistent, reliable performance in the face of fluctuating conditions inherent in contemporary wireless frameworks.\nAdvancements in machine learning have significantly impacted the field of AMC, leading to the widespread adop-tion of machine learning frameworks within this domain, as highlighted in previous studies [9], [25]. Various machine learning methodologies have been applied, including Sup-port Vector Machines (SVM) [26], [27], Bayesian networks [28], [29], random forests [30], [31], and ensemble learning approaches [32]. These methods have proven effective in accurately identifying modulation types by leveraging features intrinsic to the models. Building on the success of these traditional machine learning techniques, DNN architectures have gained prominence in AMC tasks [8], [17]. In particular, Convolutional Neural Networks (CNNs) have become a favored choice due to their ability to efficiently extract both local and global features within the spatial domain, resulting in superior performance in AMC applications [12], [33]\u2013[35]. Moreover, recognizing the significance of temporal at-tributes inherent in modulation signals, there has been a concerted exploration into extracting temporal dynamics for effective classification. Recurrent Neural Network (RNN)-based models have thus been applied and developed to cap-ture temporal dependencies, employing architectures such as Gated Recurrent Unit (GRU) [36], Long Short-Term Memory (LSTM) network [35], and transformer model [37]. Furthermore, diverse deep learning paradigms have been harnessed to enhance performance and construct scalable, efficient architectures within the AMC domain. These include methodologies such as transfer learning [38], reinforcement learning [39], adversarial learning [40], and meta learning strategies [41], all contributing to augmenting the capabilities of AMC systems."}, {"title": "B. Denoising in Modulation Classification", "content": "As advanced machine learning paradigms were applied in AMC tasks, the quality of the signal datasets holds paramount importance during model training. As the widely known expression Garbage-in, Garbage-out represents, it is widely recognized that the persistence of unexpected noise within signals has presented a longstanding challenge throughout the history of wireless signal processing. Notably, the term 'noise' encompasses a spectrum of definitions across various domains. In the context of this study, noise refers to an unforeseen disturbance detected at the receiver, originating from either internal or external sources.\nWithin the AMC domain, numerous studies have been dedicated to addressing the noise inherent within signals. Bagga et al., [42] was one of the pioneering AMC studies considering SNR conditions, introducing a model utilizing wavelet transform and a statistical parametric-based method to build an AMC model. Moreover, as the usage of machine learning models evolves, subsequent studies have predomi-nantly focused on developing robust models based on machine learning approaches [9], [11], [43]. More recently, there has been a surge in leveraging DNN models for AMC across varying SNR conditions [8], [11], [44]\u2013[46]. Hu et al., [44] proposed a modulation classifier utilizing LSTM, demonstrat-ing superior performance when SNR exceeds 10dB and out-performing Expectation Maximization-based algorithms across diverse SNR ranges. Han et al., [45] transformed time-domain signals into frequency-based features through a combination of CNN and stacked autoencoder, employing the Probabilistic Neural Network (PNN) model for AMC across multiple SNR ranges. Furthermore, Khan et al., [46] designed an AMC model based on a 3D CNN architecture under various noise environments, including additive white Gaussian noise and Rayleigh/Rician channel, leveraging spatiotemporal informa-tion for robust model training. Collectively, diverse model architectures have been proposed to mitigate noise under varying conditions, aiming to construct a resilient classifier capable of handling noisy signal environments effectively."}, {"title": "C. Federated Learning for Modulation Classification", "content": "Federated Learning (FL) [10] has gained widespread recog-nition as an apt framework for distributed environments, har-nessing collective knowledge from participating local devices to facilitate collaborative learning. Likewise, FL has garnered considerable interest within the domain of modulation classifi-cation technology, seeking to establish an adaptive framework tailored to the distributed IoT environment [13]\u2013[15], [18], [19], [21], [22], [47], [48]. Shi et al., [14] leveraged FL in the AMC field, which observed the impact of training the DNN model over different scenarios across edge models, including various training dataset volumes, different SNR, varying numbers of edge clients within the distributed environment. Inspired by this, diverse studies were proposed that applied FL in AMC task, which can be narrowed down to two large categories: enhancing privacy [19], [21], [47], [49], and achieving optimization under non-IID conditions [13], [15], [18], [22]."}, {"title": "1) Security in AMC Federated Learning:", "content": "To ensure privacy, Majeed et al., [19] leveraged the blockchain framework in FL-based AMC to enhance security levels across participants in wireless IoT-edge systems. Wei et al., [21] experimentally explored diverse attack scenarios in FL in the AMC setting, comparing the performance variance using multiple deep learning models using a public dataset. Additionally, Shi et al., [47] employed a differential privacy scheme, preserving performance and enhancing the privacy level during FL operation. Apart from the countermeasures for adversarial attacks, Zhang et al., [49] proposed a new poisoning attack method for modulation recognition FL framework in an IoT environment. Although FL has significantly increased the privacy level compared to centralized learning, this study implies that it still involves vulnerability to adversarial attacks and malicious activities."}, {"title": "2) Non-IID Optimization in AMC Federated Learning:", "content": "In the domain of FL, it is well recognized that non-IID datasets present significant challenges to achieving optimal convergence. Recent research efforts have increasingly focused on addressing the non-IID characteristics commonly encoun-tered in distributed environments, particularly within the AMC domain. A prominent challenge in this context is the class imbalance problem, which often arises in non-IID classifi-cation tasks in distributed learning settings. To mitigate this issue, Wang et al. [13] proposed FedeAMC, a method that ad-dresses class imbalances by utilizing a balanced cross-entropy function to effectively distribute class type weights. Similarly, Siriwardana et al. [18] employed data augmentation techniques to enhance the performance of FL-based AMC, particularly in low Signal-to-Noise Ratio (SNR) and non-IID scenarios, effectively addressing class imbalance concerns. Additionally, the Federated Imbalanced Learning (FIL) approach [22] was introduced to tackle class imbalance, demonstrating superior performance compared to traditional FedAvg methods in such environments. Furthermore, FedBKD [15] proposed a model that creates synthetic datasets using variational autoencoders on the server side, combined with bidirectional knowledge distillation techniques to train local models. This approach effectively mitigates heterogeneity from both data and model perspectives within the distributed learning framework."}, {"title": "III. PRELIMINARIES", "content": "Modulation classification is a fundamental component in modern wireless communication systems, enabling the identification and cat-egorization of modulation schemes within received signals. Its primary goal is automatic and accurate recognition of modulation types without human intervention, ensuring reliable communication across diverse user environments [11]. Through analysis of signal features like constellation, spec-tral characteristics, and temporal properties, AMC algorithms classify signals into predefined types such as amplitude mod-ulation (AM), frequency modulation (FM), phase shift keying (PSK), and quadrature amplitude modulation (QAM). Previous studies [9], [26], [27] have successfully extracted relevant features from signals and mapped them to modulation classes using various machine learning techniques. These technologies are crucial for adaptive radio applications, promoting efficient spectrum utilization and robust communication in dynamic environments."}, {"title": "2) Preliminaries of Noise:", "content": "In the wireless communication domain, noise has been a long-lasting challenge stemming from internal and external factors. Internally generated noise, including Gaussian noise [50], equipment noise [50], impulse noise [51], and synchronization noise [52], originates within communication systems, partly within the control of station operators. Mitigating internal noise involves strategies [50], [53], [54] such as low-noise amplifiers, filtering methodolo-gies, error correction models, shielding techniques, and de-sign optimizations aimed at enhancing the system's resilience against noise interference. Conversely, external noise presents a more daunting challenge as its origins lie beyond station operators' influence, characterized by its unpredictable nature and persistence as a perturbation regardless of station con-dition. Common sources of external noise include frequency interference [55], multipath fading [56], and shadowing [50]. These sources, contributing to diminishing signal charac-teristics, are significant concerns for optimizing distributed system operation. The unpredictable nature of noise compo-nents, coupled with SNR variations, presents challenges in training accurate modulation classification models. Previous studies on AMC using DNN approaches have emphasized the importance of clean, high SNR signals while discerning modulation types [8], [9], [12]\u2013[15], [17], [18], [22], [25], [33]\u2013[35], [35]\u2013[37], highlighting the necessity of denoising datasets. As wireless system deployments continue to expand, understanding and mitigating noise's impact on AMC be-comes integral to advancing reliable and adaptive modulation classification techniques for evolving wireless communication systems."}, {"title": "B. Federated Learning-based AMC in IoT Network", "content": "FL is a decentralized machine learning approach where model training is conducted collabo-ratively across multiple participant devices without centraliz-ing raw data [10]. Let w\u1d62 denote the local model with index i, trained locally using resources and datasets D\u1d62 specific to each local node, with a task-based loss function L(\u00b7) as detailed in equation (1). The objective function in equation (2) guides the iterative update process with time t for optimizing w towards minimizing the local loss function.\n$w_i^{(t+1)} = w_i^{(t)} - \\eta \\nabla L(w_i^{(t)}, D_i)$\n(1)\n$\\lim_{t\\rightarrow T} w^{(t)} :\\rightarrow \\min_w L(w, \\mathbb{D})$\n(2)\nSubsequently, the fine-tuned local models w\u1d62\u1d57 from all local nodes undergo aggregation at the global server, synchronized in a timely manner. The aggregation process, depicted in equation (3), constructs a global model W through element-wise matrix aggregation across each layer, where q\u1d62 signifies the weights assigned to each model based on the dataset volume.\n$W = \\frac{1}{\\sum \\mathbb{V}_i} \\sum q_i W_i$\n(3)\nThis global model is then redistributed back to the participating devices, facilitating the update of their local models. This cycle initiates successive rounds of equations from (1) to (3), iteratively refining the global model."}, {"title": "2) Modulation Classification in FL Environment:", "content": "In dis-tributed wireless environments, the application of FL to modulation classification emerges as a noteworthy approach. This involves the collaborative participation of numerous IoT devices, each equipped with signal communication functions. The deployment of the FL framework in modulation classifi-cation within distributed wireless environments affords several merits. Foremost is the commitment to data privacy, as sen-sitive signal information remains decentralized on individual devices, mitigating concerns related to data security and reg-ulatory compliance. Furthermore, the collaborative nature of FL leverages the collective knowledge of diverse participant user devices, thereby enhancing the accuracy of modulation classification. This decentralized approach proves particularly advantageous in scenarios where centralized methods face impracticalities, either due to the scale of IoT devices or concerns pertaining to communication latency. Thus, FL-based modulation classification stands out as a promising paradigm for optimizing the efficiency, accuracy, and privacy aspects of wireless communication systems within distributed environments."}, {"title": "C. Non-IID Problem in Distributed Environment", "content": "In a distributed environment within wireless communication systems, signals traverse diverse regions or channels and are subject to disparate environmental conditions, interference, and noise levels. The characteristics of regional noise profiles have significant variability, inducing dissimilarities in received signals.In modulation classification, wherein the objective is to discern the modulation type of a received signal, these fluctuations in regional noise and other conditions present challenges, giving rise to non-IID problems. This section defines and categorizes prevalent non-IID scenarios encoun-tered in FL-based modulation classification tasks within a distributed wireless environment, where we will implement these scenarios in the experiment section (Sections Vand VI).\nThe issue of class imbalance is a prevalent challenge under non-IID conditions [13], [18], [22]. This problem occurs when class instances are unevenly distributed, as illustrated in equation (4) where D(\u00b7) represents distribution, c is a class, U(\u00b7) indicates uniform distribution, and y represents ground-truth class. Such imbalance reduces the model's sensitivity to minority classes and introduces significant bias during the fine-tuning process, thereby imped-ing the development of a generalizable performance in FL environments.\n$\\mathbb{D}(y) \\propto \\mathbb{U}(0, |v_c| - 1) \\text{ s.t. } y \\in \\mathbb{D}$\n(4)\nThe dataset volume imbalance arises from an uneven distribution of data samples among local users. Devices or sensors responsible for data collection may contribute varying volumes of local datasets, resulting in some users generating significantly more samples than others. This imbalance poses challenges for machine learning models trained on such datasets, as it can lead to biases favoring specific users with larger datasets, potentially skewing global model performance in FL. This imbalance is quantified in equation (5), where n(\u00b7) represents a number of samples, i and j denote arbitrary local users.\n$n(\\mathbb{D}_i) \\neq n(\\mathbb{D}_j) \\text{ where } i \\neq j$\n(5)\nThe feature variance issue reflects the variations from the inherent features across the unique local datasets. Let X be the input signals with classes y, where D \u220b (X, y), and f(X) indicates the feature extractor using input X. We define the non-IID case 3 as follows:\n$f(X_i) \\neq f(X_j) \\text{ where } i \\neq j$\n(6)\nIn the context of modulation signals, the modulation scheme itself remains consistent across different devices; however, variability is introduced by external factors, such as noise af-fecting the original modulated signal. In this study, we applied a specific SNR range that varies across different regions, with the implementation details provided in Section VI-A."}, {"title": "IV. METHODOLOGY", "content": "Prior to presenting our methodology, we define the prevail-ing problems in the modulation classification domain within distributed user environments. Our investigation is centered on two key challenges. Firstly, we explore the inherent noise complexities in practical modulation signals and highlight the gap between conventional AMC studies and real-world settings. Secondly, we explain the persistent issue of non-IID data distribution and inefficiencies in conventional FL models during optimization in parameter aggregation."}, {"title": "1) Balancing Noise and Signal in Modulation Classification:", "content": "In spite of the well-established notion that modulated signals characterized by low noise facilitate the effective extraction of discernible features by DNN models for modu-lation classification [48], real-world signals frequently exhibit noise stemming from various sources of interference. This phenomenon invariably leads to a noticeable deterioration in model performance during the practical inference phase, necessitating the formulation of effective strategies to reduce the disparity between real-world test inference and the prepara-tory phase of model training. Traditional methodologies for noise reduction, as discussed in Section II-B, typically entail key challenges. It encompasses the risk of information loss during denoising procedures and imposing substantial com-putational overhead on lightweight user devices during real-time operations. Recent endeavors have geared towards the adoption of AI-based techniques, encompassing the extraction of salient feature representations, the harnessing of advanced machine learning models for efficacious feature learning, or the assumption of constrained environmental conditions, such as specific SNRs. Despite their commendable contributions towards enhancing classification accuracy, prior AMC schemes remain susceptible to the intrinsic noise prevalent in signals, constituting a foundational impediment necessitating redress.\nOur investigation takes a new approach by prioritizing the equilibrium between authentic signal components and noise within modulation signals. Diverging from conventional methodologies that train DNN classifiers using modulated signals with an arbitrary range of SNR, our approach en-deavors to pinpoint an optimal noise bandwidth intrinsic to the signal spectrum, thereby enabling the DNN classifier to achieve generalizable performance across a diverse array of incoming signals characterized by varying SNRs.\nNotably, our proposed methodology, harmonic noise re-silience approach, orchestrates the equilibrium of extracted features between noise and genuine signal components, while concurrently regulating the training process to delineate a robust decision boundary. By identifying a balanced noise level that maximizes model performance, our approach aims to facilitate harmonious interaction between noise and signal to enhance the generalizability of handling signals with diverse SNRs. We introduce our harmonic noise resilience methodol-ogy in Section IV-B."}, {"title": "2) Federated Learning Design for AMC:", "content": "In distributed computing environments, FL presents a notable advantage by enabling the collaborative aggregation of knowledge dispersed among locally trained DNN models, all converging towards a common task objective. Recent investigations [13]\u2013[16], [18] underscore the efficacy of FL models in AMC, thereby enhancing practicality through distributed modeling. Despite the advancements, prior studies have predominantly focused on an isolated and singular non-IID issue, particularly class imbalance, whereas the challenges inherent in a distributed modulation classification environment are manifold, as eluci-dated in the preceding Section III-C. To achieve real-world deployment readiness, it is imperative to delve further into and address additional challenges that align with practical scenarios.\nBeyond the limited exploration of non-IID problems, con-ventional FedAvg-based AMC methodologies encounter sig-nificant hurdles during the aggregation phase of locally trained parameters. Specifically, the rudimentary linear aggregation of parameter collections fails to facilitate optimal integration across heterogeneously fine-tuned parameter sets tailored to their respective datasets. In fact, this challenge extends beyond the AMC domain, encompassing various domains leveraging FL models.\nTo address these challenges, we propose a new FL model, FedVaccine, designed to iteratively refine the global model. Our approach aims to alleviate the influence of non-IID distributions while rectifying the shortcomings associated with linear aggregation, achieved through the iterative re-training of the global model using cluster configuration. Moreover, we merge the harmonic noise resilience method into FedVaccine, enhancing the generalizability. FedVaccine design is delineated in Section IV-C."}, {"title": "B. Harmonic Noise Resilience", "content": "In this section, we introduce a methodology for determining the optimized noise level within the training dataset for mod-ulation classification, namely the 'Harmonic noise resilience' approach. Let W be an initialized parameter for the DNN-based modulation classification model, yielding a modulation prediction \u0177 through the function f(W, X). The prediction is evaluated with ground truth y using a cross-entropy function in equation (7), where i signifies the sample index and j represents the class index, respectively. Using a predefined function in equation (2), it iteratively updates the W by leveraging equation (7).\n$L(y_{ij}, \\hat{y_{ij}}) = - \\frac{1}{\\mathbb{D}} \\sum_\\mathbb{V} \\sum_\\mathbb{V} y_{ij} log(\\hat{y_{ij}})$\n(7)\nHere, the training dataset X \u220b x(i.\u0435., D \u220b (X, y)), can be factorized into original signal s(t) and noise signal e(t) over time t using equation (8).\n$x = s(t) + e(t)$\n(8)\nIn equation (8), e(t) consists of an arbitrary range of noise levels, with R\u2096(t) denoting an arbitrary noise composed of trigonometric function signal from source k and \u03a3\u2096 R\u2096(t) indicating the combined noise forming e(t), as described as follows:\n$e_t = \\sum_k R_k(t), \\text{e.g. } R(t) = A sin_k(\\omega t + \\phi)$\n(9)\nwhere A represents amplitude, \u03c9 is the angular frequency, and \u03c6 is the phase angle. Next, the SNR of x is defined by equations (10) and (11), with the time interval [0, \u03b6]. Using these two equations, we measure the quality of signal x with respect to noise.\n$SNR(x) = \\frac{P_{signal}}{P_{noise}}$\n(10)\n$P_{signal} = \\frac{1}{\\zeta} \\int_0^{\\zeta} s(t)^2 dt, \\; P_{noise} = \\frac{1}{\\zeta} \\int_0^{\\zeta} e(t)^2 dt$\n(11)\nThe following equation (12) demonstrates the selection of the training dataset using a threshold \u03b8, which filters noise ranges based on SNR values, specifically retaining those higher than \u03b8. By default, this includes the highest SNR range.\n$X \\ni \\begin{cases} X \\text{ if } SNR(x) > \\theta \\\\ \\O \\text{ otherwise } \\end{cases}$\n(12)\nWith the prepared dataset, parameter W is fine-tuned using X filtered with \u03b8, aiming to minimize loss using equation (13).\n$\\arg \\min_t [\\mathcal{L}(y_i, \\hat{y_i}), f(W_\\theta^{(t)}, x(t)))] :\\rightarrow W_\\theta^{(t)}$\n(13)\nSubsequently, an evaluation function E(\u00b7) is defined to compute the ratio of correctly classified elements using the test dataset Dtest, as depicted in equation (14), where N represents the total number of samples in Dtest, and I(\u00b7) denotes an indicator function that returns 1 if the condition inside the parentheses is true, otherwise 0.\n$E(W_\\theta^{(t)}, \\mathbb{D}_{test}) = \\frac{\\sum_{i=1}^N I(y_i = \\hat{y_i})}{\\mathbb{N}}$\n(14)\nFinally, our objective function is defined in equation (15), finding \u03b8 that returns the highest performance across various SNR values.\n$\\arg \\max_\\theta [\\mathcal{U} E(W_\\theta^{(t)}, \\mathbb{D}_{test})]$\n(15)"}, {"title": "C. FedVaccine Model", "content": "In this section, we introduce a new FL framework FedVaccine. The foundational architecture of FedVaccine is in the iterative update progression by clusters, facilitating the transfer of acquired knowledge from a clustered set of models to the subsequent cluster. In contrast to conventional FL models' [23], [57] linear aggregation approach, where the parameters of all participants jointly merge and generate a representative model, our approach of sequential cluster-wise integration aims to mitigate information loss during the aggregation of knowledge. Specifically, the local models were fundamentally fine-tuned with local datasets, with personalized adaptation within the unique local environment. However, during inte-gration, simply merging models in a linear fashion dilutes the inherent capability across heterogeneous parameters. This information loss becomes much more pronounced in non-IID scenarios, where local attributes are highly distinguishable and explicit. Therefore, our sequential update approach strategy is simple yet offers significant advantages, particularly in non-IID scenarios, where it effectively addresses challenges arising from parameter heterogeneity and subsequent discordance during the aggregation process. Additionally, the weighted aggregation method allows for normalizing and balancing the contributions of models based on their significance. This equilibrium is particularly crucial in scenarios where certain local models possess more pertinent or accurate information for specific tasks, serving as an effective strategy in practical non-IID scenarios.\nMoreover, by employing a threshold parameter \u03b8 during the dataset preprocessing stage, we optimize the classification performance by selecting an appropriate SNR range to curate the most effective training dataset to impart resilience to adverse noises. The selection of a minimum threshold range aims to balance a reasonable variance of SNR to adaptively train models, serving as a regularization strategy that enhances the generalizability of models within diverse noise levels.\nFinally, our proposed framework incorporates a queue data structure Q for individual local devices, allowing each device to manage a designated memory capacity resource for the storage of supplementary data. To ensure the model maintains its currency and adapts to evolving performance requirements, the First-In-First-Out (FIFO) method is implemented within the queue. This involves the storage of newly acquired datasets while systematically removing outdated ones. During the dataset storage process, a condition is enforced to approximate the class label distribution of the stored dataset to a ground truth uniform distribution D with an error term \u03ba, as denoted in equation (16), where D(y) signifies the distribution of the label vector y.\n$\\mathbb{D}(y) \\approx \\mathbb{D} + \\kappa, s.t. \\; \\mathbb{D} \\approx y \\sim \\mathbb{U}(a, b), \\\\ \\text{where } a \\le y \\le b \\text{ and } y \\in \\mathbb{y}$\n(16)\nAdditionally, upon the acquisition of fresh datasets, the Jensen-Shannon (JS) Divergence D(P||Q) between the label distribution of the acquired dataset and our ground truth D is computed in equations (17) and (18).\n$D_{KL}(\\mathbb{D}(y)|\\mathbb{D}) = \\sum_\\mathbb{V} (\\mathbb{D}(y_i) \\times log(\\frac{\\mathbb{D}(y_i)}{\\mathbb{D}}))$\n(17)\n$\\mathbb{D}(P||Q) = \\frac{1}{2} D_{KL}(P||\\frac{P+Q}{2}) + \\frac{1}{2} D_{KL}(Q||\\frac{P+Q}{2})$\n(18)\nwhere P \u2194 D(y), D \u2194 Q\nThe resulting disparity \u1e12 informs the identification of spe-cific elements q to be removed, as illustrated in equation (19), where Q.pop(n) represents the indicator function that pops the element n from Q.\n$\\hat{\\mathbb{D}} = \\mathbb{D} - \\mathbb{D}(P||Q), s.t. \\; \\hat{\\mathbb{D}} \\leftrightarrow q \\subset Q \\\\ Q.pop(n) : \\text{ pop n from Q, where } n \\in q$\n(19)\nThis mechanism allows focused preservation of new input data, significantly mitigating non-IID attributes and effectively reducing the non-IID effect while training for modulation classification tasks. The proposed FedVaccine is elucidated in detail in the algorithm 1."}, {"title": "V. EXPERIMENT 1: HARMONIC NOISE RESILIENCE", "content": "In this section, we implement the process defined in sec-tion IV-B and report the corresponding results after conducting a thorough analysis to derive optimal \u03b8 for robust generaliza-tion within the AMC model."}, {"title": "A. Setting", "content": "In the initial phases of our analysis", "features": "CNN and GRU. This assessment is concentrated on a model trained with an SNR re-duction strategy, aiming to systematically assess the influence of both the degree and volume of noise within the training data. For each model, we adopt the pre-designed architectures proposed by O'Shea et al. [33"}]}