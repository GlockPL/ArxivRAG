{"title": "A SAT-based approach to rigorous verification of Bayesian networks", "authors": ["Ignacy Stepka", "Nicholas Gisolfi", "Artur Dubrawski"], "abstract": "Recent advancements in machine learning have accelerated its widespread adoption across various real-world applications. However, in safety-critical domains, the deployment of machine learning models is riddled with challenges due to their complexity, lack of interpretability, and absence of formal guarantees regarding their behavior. In this paper, we introduce a verification framework tailored for Bayesian networks, designed to address these drawbacks. Our framework comprises two key components: (1) a two-step compilation and encoding scheme that translates Bayesian networks into Boolean logic literals, and (2) formal verification queries that leverage these literals to verify various properties encoded as constraints. Specifically, we introduce two verification queries: if-then rules (ITR) and feature monotonicity (FMO). We benchmark the efficiency of our verification scheme and demonstrate its practical utility in real-world scenarios.", "sections": [{"title": "1 Introduction", "content": "In recent years, artificial intelligence (AI) has attracted significant research interest, fueled by its potential to revolutionize various practical applications. Among the many AI models, Bayesian networks (BNs) [6] stand out in fields that demand extensive expert knowledge. One of the most impactful areas for BNs research is healthcare industry [20,17,32]. Their adaptive nature, which allows for construction based on either data, expert input, or both [10], is particularly valuable in incorporating the nuanced expertise of medical professionals. This feature is crucial in healthcare, where understanding the decision-making process can make a profound difference in patient outcomes.\nDespite their potential, BNs remain underutilized in real-world clinical practice [19]. The healthcare sector, characterized by its high stakes and stringent safety requirements, demands absolute reliability and accountability. Even minor errors can have severe consequences, thus placing a serious responsibility on medical practitioners. From our review of recent literature, such as [19], we posit that the limited adoption of BNs (and other AI systems) in such critical environments is partly due to a lack of comprehensive understanding of these models' strengths and weaknesses, what they learned, the reasons for particular decisions, as well as their potential limitations. This situation mirrors challenges faced in other safety-critical industries, such as avionics, where rigorous software certification protocols [31,5,7] are essential before deployment and have been established for a long time. This provides evidence that implementing similar AI verification schemes could be pivotal in facilitating the integration of AI into complex, high-stakes environments.\nTo bridge this gap, we propose a formal verification approach for BNs, aimed at enhancing their deployment by ensuring rigorous verifications and sanity checks. This approach seeks to confirm that a given model adheres to critical design specifications, which is especially important in scenarios where errors can be life-threatening. By enabling comprehensive testing for all potential adverse scenarios, our method guarantees that under specified conditions, the model will never execute undesired actions. This not only increases confidence in the model's reliability but also paves the way for broader adoption of AI in critical domains like healthcare.\nIn this paper, we introduce a novel scheme that first compiles Bayesian networks into Multi-valued Decision Diagrams (MDDs)[28] and then encodes these diagrams as Boolean algebra formulae, specifically in Conjunctive Normal Form (CNF)[1]. While previous approaches have compiled BNs into Boolean algebra for inference purposes [18], our method offers two highly desirable properties due to the compilation algorithm: it transforms the probabilistic representation of BNs into Boolean algebra formulae in a bounded time and graph size, and the compiled form is easier to understand, facilitating the development of complex verification queries.\nThe main contribution of this paper lies in the introduction of formal verification queries, enabling exact verification of desired specifications. We define two novel verification queries for Boolean-encoded Bayesian networks. The first, \"if-then rules,\" verifies whether a premise resulting in a desired outcome is always true for the model. The second, \"feature monotonicity,\" checks if the relationship between a set of facts (i.e., feature assignments) and the outcome variable is monotonic (positive or negative). Unlike existing approximate monotonicity verification methods [13], our approach provides exact verification within a SAT formalism. Furthermore, to facilitate model debugging, we define the verification queries using a proof-by-contradiction approach, enabling the enumeration of counterexamples that do not satisfy the query. This allows developers and experts to identify and address specific aspects of the model that fail to meet the verification criteria.\nOur approach can significantly enhance the deployment of Bayesian networks in real-world settings by ensuring their adherence to critical design specifications. Additionally, our framework can function as a standalone testing component, performing sanity checks within a larger testing suite to establish a safe and responsible deployment process, akin to accreditation processes in [15]."}, {"title": "2 Related Work", "content": "Many safety-critical industries, such as automotive and aerospace, have rigorous testing and certification protocols [3,7] to ensure quality and reliability. However, no such widely accepted framework currently exists for Artificial Intelligence, though several works aim to address this capability gap, such as [16,15].\nClosely related is the field of software verification, which is well-established and applied across various real-world applications, including the avionics industry [31]. There are multiple methods for performing formal verification of software, which can be categorized into distinct groups based on varying underlying paradigms. Relevant to our work are the following methods: (1) Deductive Verification [12], which involves propagating formal specifications through a program and verifying them with symbolic execution using, for example, a SAT solver [29]. (2) Design by Refinement [2], which is based on successive refinement of a solution in a step-by-step manner, with each step containing a formal proof verified by an automated solver. (3) Model Checking [22], which performs exhaustive exploration to automatically verify properties of a given model, providing a sound and complete verification result.\nIn this paper, we adapt the model checking approach to Bayesian networks to verify their adherence to certain properties, inspired by deductive verification methods. Moreover, our method can be employed as a verification element in a design-by-refinement effort, thanks to our verification queries' proof-by-contradiction approach, which allows for the enumeration of counterexamples that break constraints.\n2.1 AI Verification\nSoftware verification techniques cannot be immediately applied to AI systems due to the complexity, probabilistic nature and stochastic processes of model fitting. Verification of AI and machine learning models presents new challenges, such as building compact logical representations. Recent efforts have focused primarily on neural networks [33,8,14,25,24], given their widespread use in numerous applications. However, research has also extended to other model classes, such as Random Forests [15] and other tree ensembles [23]."}, {"title": "3 Compilation and Encoding Procedure", "content": "In this section, we present a compilation and encoding procedure that transforms a probabilistic model into a Boolean algebra formula. This process consists of the following two consecutive steps:\n1. Utilizing the approach proposed by [28], compile the BN model into a Multi-valued Decision Diagram (MDD) [21]. The MDD represents the BN's probabilistic decision function in a symbolic and deterministic form.\n2. Leveraging the scheme from [1], encode the MDD into a Conjunctive Normal Form (CNF) formula, representing the decision function as a Boolean algebra formula.\n3.1 Bayesian networks\nBayesian networks belong to the family of probabilistic graphical models. They are represented by a directed acyclic graph (see an example in Fig. 1) with a set of nodes and edges, that stand for variables and conditional dependencies, respectively. In this work, we assume that there exists one binary class label in the BN, that we will call Y. We can represent the decision function as a conditional probability of a class Y given the evidence, X i.e., P(Y|X1, X2, ..., Xn). For a more detailed introduction to Bayesian networks, refer to [6].\n3.2 Compiling BN into MDD\nIn order to transform the model from a probabilistic representation to a symbolic one, a compilation method is needed. There exist a number of such compilation"}, {"title": "3.3 Encoding MDD into CNF formula", "content": "The next step is a transformation of the MDD into a CNF formula using an encoding algorithm adapted from [1]. We choose this particular encoding scheme because it provides many desirable properties accelerating automated theorem proving and results in a compact representation. For clarity, we present the exact encoding scheme in Tab. 1. The notation for that table is as follows: vi is an i-th node in the graph, Eij is an outgoing edge from vi to vj, xij is a variable assignment and dij serves as an incoming edge to vi from vj.\nThis encoding scheme mixes two types of approaches. First, it employs Tseitin [30] clauses (T1-T5) aiming to build a consistent representation of the decision diagram in propositional logic. Second, it adds path-based clauses (P1-P4) which"}, {"title": "4 Verification", "content": "In this section, we introduce two verification queries and the intuition behind them. All queries presented in this section are formulated in a proof by contradiction manner, which by default enables enumeration of all SAT models which, in fact, are counterexamples that break the asserted properties of the model. Obtaining counterexamples is an important aspect of running verification queries, as it allows decision-makers to empirically examine instances that disprove the model's adherence to the desired specification.\n4.1 Verification Query #1: If-Then Rules (ITR)\nThe ITRM,R,c query verifies whether a model M, for a given set of rules R defined over ordinal variables X, will always predict the desired outcome class c for the outcome variable Y. The template for defining R is as follows: if X1 \u2265 t1 and X2 \u2265 t2 then Y = c, where ti represents the index of ti-th value in Xi. The proposed verification algorithm (see Alg. 1) constructs a formula that asserts a conjunction of all constrained variables. First, each variable is encoded as disjunction of all its values satisfying the threshold. Then, the algorithm asserts that the outcome variable Y belongs to any class outside the desired range.\nWith that formulation, whenever a ITRM, R, verification query evaluates to UNSAT, then ITRM,R,c = True. In other words, we can say that the model M adheres to the rule R evaluating in class c. Alternatively, when a task evaluates to SAT, we have evidence that an undesired class can be obtained within the asserted range. In simpler terms, this verification query can be intuitively understood as checking for the existence of an unwanted Y class within all feasible hyperrectangles formed under specified constraints over X."}, {"title": "4.2 Verification Query #2: Feature Monotonicity (FMO)", "content": "The FMOM,X*,x\u2081 query verifies whether a given feature xi influences the Y variable monotonically, given a partial assignment over some predefined set of other features ox* s.t. xi \u2209 X*. In simple words, given a fixed set of facts, it assesses whether a given feature has a monotonic relationship w.r.t. the outcome variable.\nDefinition 1 (Partial assignment). Partial assignment \u00f3x* is a set of variable assignments over a subset X* of variables from X. For example, for a set of variables X* = {X1,X2,X3}, a partial assignment $x* assigns exemplar values to variables in X* in the following way: $x* = (x1 = 0, Xx2 = 3, x7 = 1).\nDefinition 2 (Positive Monotonic). We say that the prediction function f : X \u2192 Y is positive monotonic whenever, given increasing values of the variable x, the assignments over Y are non-decreasing.\nDefinition 3 (Negative Monotonic). We say that the prediction function f: X \u2192 Y is negative monotonic whenever, given increasing values of the variable x, the assignments over Y are non-increasing.\nDefinition 4 (Feature Monotonicity). We say that a model M is feature monotonic (FMOM,\u00a2x*,x\u2081), whenever given a \u00f3x*, the M's prediction function f is both positive and negative monotonic w.r.t. variable xi.\nIn this paper, we focus on a binary classification scenario, however, both introduced verification queries support a multi-class classification scenario. Therefore, in a binary setting, FMOM,$x* ,x; checks whether with gradually increasing values of xi the predicted class flips at most once. To give more intuition, for example, in a loan approval scenario, this query allows checking whether having increasingly higher credit score will result in an approval decision going from negative to positive with only one flip of the decision along the entire credit score range. In order to define FMOM,\u00a2x*,x\u2081in a proof-by-contradiction manner, it is essential to assert that an undesired relationship exists along the entire domain of xi. This can be done via assertion of existence of patterns that do not follow the desired monotonicity. To cover both positive and negative monotonic relationships, if either pattern of prediction changes (on the three consecutive values in the xi domain is in place): High-Low-High (HLH) or Low-High-Low (LHL) is in place, then the FMOM,x,x\u2081is violated. Examples of monotonic"}, {"title": "5 Experiments", "content": "In this section, we present two experiments that showcase the utility of the proposed verification framework. In Sec. 5.1, we present a runtime efficiency benchmark concerning different parts of the framework on a few Bayesian networks from literature. Next, in Sec. 5.2, we walk through a comprehensive case study to show the real-world use case of our verification framework in a loan approval scenario. The code used for the experiments is publicly available in an online repository.\n5.1 Benchmarking on Publicly Available Bayesian networks\nWe compiled and encoded five different Bayesian network models from a popular online repository. Subsequently, we executed verification queries on their encoded representations and recorded the respective runtimes. Given the exponential complexity of the compilation algorithm [28], the results presented in Tab. 2 confirm the substantial compilation time increase given larger Bayesian networks. However, it is worth to mention, that this is only an initial cost, which is required to obtain an encoded representation of the model. After that step, any number of verification queries can be executed in a timely manner.\nNext, we verify time efficiency of verification queries. Verification tasks are solved using Minisat SAT solver [29]. While SAT solvers have exponential complexity, they are very capable of swiftly handling large numbers of clauses. As experiments show, the time of solving a single verification task is measured in milliseconds for small BNs, up to low number of seconds for larger ones.\nWe contend that such performance properties enable construction of a comprehensive verification suite using the proposed framework. Although there is a relatively high initial entry time cost for compilation, running multiple verification queries becomes rapid after this process, as the entire verification effort requires only one compilation for a given model.\nOur experiments show that our SAT formalism is able to be applied to existing Bayesian network models without needing to train new models from scratch. This means that our methods can serve as a reliability assurance layer when connected to existing or legacy systems that implement Bayesian networks.\n5.2 Empirical utility study\nIn this experiment, we present a study exemplifying the utility of the proposed framework in a verification and validation scenario. Imagine a scenario, where a bank wants to deploy a Bayesian network model to assess whether a loan applicant should be approved for a loan. Since banking industry is highly regulated, the bank would have to meet certain regulatory requirements and prove that their model adheres to required norms and specifications, in order to deploy that model. Below, we simulate this environment and show the practical utility of the proposed framework.\nData For experiments, we selected a dataset from [9], namely Credit10k. It contains 10 thousand samples of credit data organized into 12 discrete columns. We split the data to two train and test subsets, having a 7:3 size ratio.\nBayesian networks We employ the pgmpy library [4] to train 10 Bayesian networks, with the CreditWorthiness variable as the root node having outgoing edges only. The training process involves two steps: structure learning and parameter estimation. For structure learning, 10% of the training data is randomly sampled for each task, and a Tree Search estimator (chosen randomly between tan and chow-liu) is used. Subsequently, model parameters are estimated using the entire training set, with the selection of either Maximum Likelihood or Bayesian estimator chosen at random. In the final step, we perform inference on the test data and calculate accuracy to facilitate later analysis.\nVerifying ITRM,R,C To conduct verification queries, we first define a set of expert rules for compliance assessment. For this experiment, we derived 11 rules, as detailed in Tab.3. Subsequently, we performed ITRM,R, verification on all involved Bayesian networks. The quantitative results are summarized in Tab.4."}, {"title": "6 Conclusions", "content": "In this work, we presented a SAT-based approach for verifying the adherence of Bayesian networks to specific design specifications. We introduced two verification queries aimed at assessing key behavioral aspects, facilitating efficient and effective testing of BN models prior to deployment\u2014especially critical in safety-critical and high-stakes applications. Our method provides a practical solution for conducting both quick sanity checks and comprehensive verification procedures. By demonstrating its capability to handle reasonably sized BNs within a feasible timeframe, we established the viability of integrating our approach into a comprehensive testing suite. To underscore the real-world applicability of our framework, we showcased a case study illustrating its effectiveness in identifying potential errors within a real-world BN model.\nIn future work, we aim to extend our approach to multi-class and multi-label BN classifiers, thereby broadening its applicability across various domains. Additionally, we plan to develop a model refinement framework that incorporates verification results, enabling retraining of models while accounting for the identified counterexamples."}]}