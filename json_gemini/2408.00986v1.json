{"title": "A SAT-based approach to rigorous verification\nof Bayesian networks", "authors": ["Ignacy Stepka", "Nicholas Gisolfi", "Artur Dubrawski"], "abstract": "Recent advancements in machine learning have accelerated\nits widespread adoption across various real-world applications. However,\nin safety-critical domains, the deployment of machine learning models\nis riddled with challenges due to their complexity, lack of interpretabil-\nity, and absence of formal guarantees regarding their behavior. In this\npaper, we introduce a verification framework tailored for Bayesian net-\nworks, designed to address these drawbacks. Our framework comprises\ntwo key components: (1) a two-step compilation and encoding scheme\nthat translates Bayesian networks into Boolean logic literals, and (2)\nformal verification queries that leverage these literals to verify various\nproperties encoded as constraints. Specifically, we introduce two verifi-\ncation queries: if-then rules (ITR) and feature monotonicity (FMO). We\nbenchmark the efficiency of our verification scheme and demonstrate its\npractical utility in real-world scenarios.", "sections": [{"title": "Introduction", "content": "In recent years, artificial intelligence (AI) has attracted significant research inter-\nest, fueled by its potential to revolutionize various practical applications. Among\nthe many AI models, Bayesian networks (BNs) [6] stand out in fields that de-\nmand extensive expert knowledge. One of the most impactful areas for BNs\nresearch is healthcare industry [20,17,32]. Their adaptive nature, which allows\nfor construction based on either data, expert input, or both [10], is particularly\nvaluable in incorporating the nuanced expertise of medical professionals. This\nfeature is crucial in healthcare, where understanding the decision-making process\ncan make a profound difference in patient outcomes.\nDespite their potential, BNs remain underutilized in real-world clinical prac-\ntice [19]. The healthcare sector, characterized by its high stakes and stringent\nsafety requirements, demands absolute reliability and accountability. Even mi-\nnor errors can have severe consequences, thus placing a serious responsibility\non medical practitioners. From our review of recent literature, such as [19], we"}, {"title": "", "content": "posit that the limited adoption of BNs (and other AI systems) in such critical\nenvironments is partly due to a lack of comprehensive understanding of these\nmodels' strengths and weaknesses, what they learned, the reasons for particular\ndecisions, as well as their potential limitations. This situation mirrors challenges\nfaced in other safety-critical industries, such as avionics, where rigorous software\ncertification protocols [31,5,7] are essential before deployment and have been es-\ntablished for a long time. This provides evidence that implementing similar AI\nverification schemes could be pivotal in facilitating the integration of AI into\ncomplex, high-stakes environments.\nTo bridge this gap, we propose a formal verification approach for BNs, aimed\nat enhancing their deployment by ensuring rigorous verifications and sanity\nchecks. This approach seeks to confirm that a given model adheres to critical\ndesign specifications, which is especially important in scenarios where errors can\nbe life-threatening. By enabling comprehensive testing for all potential adverse\nscenarios, our method guarantees that under specified conditions, the model\nwill never execute undesired actions. This not only increases confidence in the\nmodel's reliability but also paves the way for broader adoption of AI in critical\ndomains like healthcare.\nIn this paper, we introduce a novel scheme that first compiles Bayesian net-\nworks into Multi-valued Decision Diagrams (MDDs)[28] and then encodes these\ndiagrams as Boolean algebra formulae, specifically in Conjunctive Normal Form\n(CNF)[1]. While previous approaches have compiled BNs into Boolean algebra\nfor inference purposes [18], our method offers two highly desirable properties due\nto the compilation algorithm: it transforms the probabilistic representation of\nBNs into Boolean algebra formulae in a bounded time and graph size, and the\ncompiled form is easier to understand, facilitating the development of complex\nverification queries.\nThe main contribution of this paper lies in the introduction of formal verifi-\ncation queries, enabling exact verification of desired specifications. We define two\nnovel verification queries for Boolean-encoded Bayesian networks. The first, \"if-\nthen rules,\" verifies whether a premise resulting in a desired outcome is always\ntrue for the model. The second, \"feature monotonicity,\" checks if the relation-\nship between a set of facts (i.e., feature assignments) and the outcome variable\nis monotonic (positive or negative). Unlike existing approximate monotonicity\nverification methods [13], our approach provides exact verification within a SAT\nformalism. Furthermore, to facilitate model debugging, we define the verifica-\ntion queries using a proof-by-contradiction approach, enabling the enumeration\nof counterexamples that do not satisfy the query. This allows developers and\nexperts to identify and address specific aspects of the model that fail to meet\nthe verification criteria.\nOur approach can significantly enhance the deployment of Bayesian networks\nin real-world settings by ensuring their adherence to critical design specifications.\nAdditionally, our framework can function as a standalone testing component,\nperforming sanity checks within a larger testing suite to establish a safe and\nresponsible deployment process, akin to accreditation processes in [15]."}, {"title": "Related Work", "content": "Many safety-critical industries, such as automotive and aerospace, have rigorous\ntesting and certification protocols [3,7] to ensure quality and reliability. However,\nno such widely accepted framework currently exists for Artificial Intelligence,\nthough several works aim to address this capability gap, such as [16,15].\nClosely related is the field of software verification, which is well-established\nand applied across various real-world applications, including the avionics indus-\ntry [31]. There are multiple methods for performing formal verification of soft-\nware, which can be categorized into distinct groups based on varying underlying\nparadigms. Relevant to our work are the following methods: (1) Deductive Veri-\nfication [12], which involves propagating formal specifications through a program\nand verifying them with symbolic execution using, for example, a SAT solver [29].\n(2) Design by Refinement [2], which is based on successive refinement of a solu-\ntion in a step-by-step manner, with each step containing a formal proof verified\nby an automated solver. (3) Model Checking [22], which performs exhaustive ex-\nploration to automatically verify properties of a given model, providing a sound\nand complete verification result.\nIn this paper, we adapt the model checking approach to Bayesian networks\nto verify their adherence to certain properties, inspired by deductive verifica-\ntion methods. Moreover, our method can be employed as a verification element\nin a design-by-refinement effort, thanks to our verification queries' proof-by-\ncontradiction approach, which allows for the enumeration of counterexamples\nthat break constraints."}, {"title": "AI Verification", "content": "Software verification techniques cannot be immediately applied to AI systems\ndue to the complexity, probabilistic nature and stochastic processes of model\nfitting. Verification of AI and machine learning models presents new challenges,\nsuch as building compact logical representations. Recent efforts have focused\nprimarily on neural networks [33,8,14,25,24], given their widespread use in nu-\nmerous applications. However, research has also extended to other model classes,\nsuch as Random Forests [15] and other tree ensembles [23]."}, {"title": "", "content": "In this work, our objective is to expand the field of formal verification of AI\nto include Bayesian network (BN) models. Specifically, we aim to enable model\nchecking of BNs using the deductive verification paradigm. In recent years, [28]\nintroduced an approach to Bayesian network compilation, enabling the efficient\nrepresentation of BNs in the symbolic form of ordered decision diagrams [21].\nThis advancement opens new possibilities for formal verification. Previous works,\nsuch as [27,26], proposed several verification queries executable on the compiled\nBN. Our proposal goes a step further by encoding the network into Boolean\nalgebra, opening a new avenue for Bayesian network verification. This develop-\nment is crucial not only for verifying individual networks but also for integrating\nthem into larger systems, aligning with the industry's widespread acceptance of\nthe Boolean algebra formalism.\nAs mentioned before, the primary contribution of this paper is the introduc-\ntion of formal verification queries, facilitating the exact verification of specified\nrequirements. Our novel \"if-then\" verification query represents a new concept,\nwhile our \"feature monotonicity\" query is related to existing proposals for ap-\nproximate monotonicity verification in Bayesian networks [13]. However, our ap-\nproach to monotonicity verification is distinct as it allows for exact verification\nand is specifically designed for Boolean logic."}, {"title": "Compilation and Encoding Procedure", "content": "In this section, we present a compilation and encoding procedure that transforms\na probabilistic model into a Boolean algebra formula. This process consists of\nthe following two consecutive steps:\n1. Utilizing the approach proposed by [28], compile the BN model into a Multi-\nvalued Decision Diagram (MDD) [21]. The MDD represents the BN's prob-\nabilistic decision function in a symbolic and deterministic form.\n2. Leveraging the scheme from [1], encode the MDD into a Conjunctive Normal\nForm (CNF) formula, representing the decision function as a Boolean algebra\nformula."}, {"title": "Bayesian networks", "content": "Bayesian networks belong to the family of probabilistic graphical models. They\nare represented by a directed acyclic graph (see an example in Fig. 1) with a\nset of nodes and edges, that stand for variables and conditional dependencies,\nrespectively. In this work, we assume that there exists one binary class label in\nthe BN, that we will call $Y$. We can represent the decision function as a condi-\ntional probability of a class $Y$ given the evidence, $X$ i.e., $P(Y|X_1, X_2, ..., X_n)$.\nFor a more detailed introduction to Bayesian networks, refer to [6]."}, {"title": "Compiling BN into MDD", "content": "In order to transform the model from a probabilistic representation to a symbolic\none, a compilation method is needed. There exist a number of such compilation"}, {"title": "Encoding MDD into CNF formula", "content": "The next step is a transformation of the MDD into a CNF formula using an\nencoding algorithm adapted from [1]. We choose this particular encoding scheme\nbecause it provides many desirable properties accelerating automated theorem\nproving and results in a compact representation. For clarity, we present the\nexact encoding scheme in Tab. 1. The notation for that table is as follows: $v_i$ is\nan $i$-th node in the graph, $E_{ij}$ is an outgoing edge from $v_i$ to $v_j$, $x_{ij}$ is a variable\nassignment and $d_{ij}$ serves as an incoming edge to $v_i$ from $v_j$.\nThis encoding scheme mixes two types of approaches. First, it employs Tseitin\n[30] clauses (T1-T5) aiming to build a consistent representation of the decision\ndiagram in propositional logic. Second, it adds path-based clauses (P1-P4) which"}, {"title": "Verification", "content": "In this section, we introduce two verification queries and the intuition behind\nthem. All queries presented in this section are formulated in a proof by contra-\ndiction manner, which by default enables enumeration of all SAT models which,\nin fact, are counterexamples that break the asserted properties of the model. Ob-\ntaining counterexamples is an important aspect of running verification queries,\nas it allows decision-makers to empirically examine instances that disprove the\nmodel's adherence to the desired specification."}, {"title": "Verification Query #1: If-Then Rules (ITR)", "content": "The $ITR_{M,R,c}$ query verifies whether a model $M$, for a given set of rules $R$\ndefined over ordinal variables $X$, will always predict the desired outcome class $c$\nfor the outcome variable $Y$. The template for defining $R$ is as follows: if $X_1 \\geq t_1$\nand $X_2 \\geq t_2$ then $Y = c$, where $t_i$ represents the index of $t_i$-th value in $X_i$. The\nproposed verification algorithm (see Alg. 1) constructs a formula that asserts\na conjunction of all constrained variables. First, each variable is encoded as\ndisjunction of all its values satisfying the threshold. Then, the algorithm asserts\nthat the outcome variable $Y$ belongs to any class outside the desired range.\nWith that formulation, whenever a $ITR_{M, R, c}$ verification query evaluates to\nUNSAT, then $ITR_{M,R,c} = True$. In other words, we can say that the model $M$"}, {"title": "Verification Query #2: Feature Monotonicity (FMO)", "content": "The $FMO_{M,X^*,x_i}$ query verifies whether a given feature $x_i$ influences the $Y$\nvariable monotonically, given a partial assignment over some predefined set of\nother features $o_{X^*}$ s.t. $x_i \\notin X^*$. In simple words, given a fixed set of facts, it\nassesses whether a given feature has a monotonic relationship w.r.t. the outcome\nvariable.\nDefinition 1 (Partial assignment). Partial assignment $\\delta_{X^*}$ is a set of vari-\nable assignments over a subset $X^*$ of variables from $X$. For example, for a set of\nvariables $X^* = {x_1,x_2,x_3}$, a partial assignment $\\delta_{X^*}$ assigns exemplar values\nto variables in $X^*$ in the following way: $\\delta_{X^*} = (x_1 = 0, x_2 = 3, x_7 = 1)$.\nDefinition 2 (Positive Monotonic). We say that the prediction function $f$ :\n$X \\rightarrow Y$ is positive monotonic whenever, given increasing values of the variable\n$x$, the assignments over $Y$ are non-decreasing.\nDefinition 3 (Negative Monotonic). We say that the prediction function\n$f$ : $X \\rightarrow Y$ is negative monotonic whenever, given increasing values of the\nvariable $x$, the assignments over $Y$ are non-increasing.\nDefinition 4 (Feature Monotonicity). We say that a model $M$ is feature\nmonotonic ($FMO_{M,\\delta_{X^*},x_i}$), whenever given a $\\delta_{X^*}$, the $M$'s prediction function\n$f$ is both positive and negative monotonic w.r.t. variable $x_i$.\nIn this paper, we focus on a binary classification scenario, however, both in-\ntroduced verification queries support a multi-class classification scenario. There-\nfore, in a binary setting, $FMO_{\\delta_{X^*},x_i}$ checks whether with gradually increasing\nvalues of $x_i$ the predicted class flips at most once. To give more intuition, for\nexample, in a loan approval scenario, this query allows checking whether having\nincreasingly higher credit score will result in an approval decision going from\nnegative to positive with only one flip of the decision along the entire credit\nscore range. In order to define $FMO_{\\delta_{X^*},x_i}$in a proof-by-contradiction man-\nner, it is essential to assert that an undesired relationship exists along the entire\ndomain of $x_i$. This can be done via assertion of existence of patterns that do not\nfollow the desired monotonicity. To cover both positive and negative monotonic\nrelationships, if either pattern of prediction changes (on the three consecutive\nvalues in the $x_i$ domain is in place): High-Low-High (HLH) or Low-High-Low\n(LHL) is in place, then the $FMO_{\\delta_{X^*},x_i}$is violated. Examples of monotonic"}, {"title": "", "content": "More formally, the proposed algorithm (Alg. 2) creates three copies $M_1, M_2$,\n$M_3$ of the model $M$ and adds constraints that enforce an increasing assignment\nof the feature $x_i$ in these models in the following way: $a = x_i^{M_1} < x_i^{M_2} <\nx_i^{M_3}$. Then, it adds constraints that break the monotonicity by enforcing a non-\nmonotonic assignment over class variables between these models $B_{HLH} = y^{M_2} <\ny^{M_3}, y^{M_1}$, where $y$ corresponds to the output class for a given model. To account\nfor all possibilities, it is essential to also test for a polar opposite scenario of Low-\nHigh-Low (LHL), which requires only a flip of the sign $B_{HLH}$, that is, $B_{HLH} =$\ny^{M_2} > y^{M_3}, y^{M_1}.\nObtaining a CNF encoding of the $>$\ninequality between two variables (see\nlines 6-9 in Alg. 2) can be achieved via encoding the pairwise upper triangle (al-\nternatively, for $<$, the lower triangle) of the 2D Cartesian product matrix of their\npossible feature values. In this matrix, each cell is a conjunction of coordinates\nxy and all cells are connected by disjunction. This approach produces a formula\nin Disjunctive Normal Form (DNF) which, using Tseitin transformation [30],\nis translated from DNF representation to CNF in polynomial time.\nThe outcome of $B_{HLH}$ and $B_{HLH}$ is interpreted jointly, therefore, if either of\nthem is satisfied (i.e., evaluate to SAT): $B_{HLH} \\lor B_{HLH}$, the model is not monotone\nw.r.t. X (recall that the proof is done by contradiction, i.e., if constraints can\nbe satisfied, the model does not adhere to verified property). When the formula"}, {"title": "Experiments", "content": "In this section, we present two experiments that showcase the utility of the\nproposed verification framework. In Sec. 5.1, we present a runtime efficiency\nbenchmark concerning different parts of the framework on a few Bayesian net-\nworks from literature. Next, in Sec. 5.2, we walk through a comprehensive case\nstudy to show the real-world use case of our verification framework in a loan\napproval scenario. The code used for the experiments is publicly available in an\nonline repository2."}, {"title": "Benchmarking on Publicly Available Bayesian networks", "content": "We compiled and encoded five different Bayesian network models from a pop-\nular online repository3. Subsequently, we executed verification queries on their\nencoded representations and recorded the respective runtimes. Given the expo-\nnential complexity of the compilation algorithm [28], the results presented in\nTab. 2 confirm the substantial compilation time increase given larger Bayesian\nnetworks. However, it is worth to mention, that this is only an initial cost, which\nis required to obtain an encoded representation of the model. After that step,\nany number of verification queries can be executed in a timely manner.\nNext, we verify time efficiency of verification queries. Verification tasks are\nsolved using Minisat SAT solver [29]. While SAT solvers have exponential com-\nplexity, they are very capable of swiftly handling large numbers of clauses. As\nexperiments show, the time of solving a single verification task is measured in\nmilliseconds for small BNs, up to low number of seconds for larger ones.\nWe contend that such performance properties enable construction of a com-\nprehensive verification suite using the proposed framework. Although there is\na relatively high initial entry time cost for compilation, running multiple verifi-\ncation queries becomes rapid after this process, as the entire verification effort\nrequires only one compilation for a given model.\nOur experiments show that our SAT formalism is able to be applied to exist-\ning Bayesian network models without needing to train new models from scratch.\nThis means that our methods can serve as a reliability assurance layer when\nconnected to existing or legacy systems that implement Bayesian networks."}, {"title": "Empirical utility study", "content": "In this experiment, we present a study exemplifying the utility of the proposed\nframework in a verification and validation scenario. Imagine a scenario, where a\nbank wants to deploy a Bayesian network model to assess whether a loan appli-\ncant should be approved for a loan. Since banking industry is highly regulated,\nthe bank would have to meet certain regulatory requirements and prove that\ntheir model adheres to required norms and specifications, in order to deploy\nthat model. Below, we simulate this environment and show the practical utility\nof the proposed framework.\nData For experiments, we selected a dataset from [9], namely Credit10k. It\ncontains 10 thousand samples of credit data organized into 12 discrete columns.\nWe split the data to two train and test subsets, having a 7:3 size ratio.\nBayesian networks We employ the pgmpy library [4] to train 10 Bayesian net-\nworks, with the CreditWorthiness variable as the root node having outgoing\nedges only. The training process involves two steps: structure learning and pa-\nrameter estimation. For structure learning, 10% of the training data is randomly\nsampled for each task, and a Tree Search estimator (chosen randomly between\ntan and chow-liu) is used. Subsequently, model parameters are estimated us-\ning the entire training set, with the selection of either Maximum Likelihood or\nBayesian estimator chosen at random. In the final step, we perform inference on\nthe test data and calculate accuracy to facilitate later analysis.\nVerifying $ITR_{M,R,C}$ To conduct verification queries, we first define a set of\nexpert rules for compliance assessment. For this experiment, we derived 11 rules,\nas detailed in Tab.3. Subsequently, we performed $ITR_{M,R,C}$ verification on all\ninvolved Bayesian networks. The quantitative results are summarized in Tab.4."}, {"title": "", "content": "The results indicate that some models have learned decision functions that\nadhere to the specified requirements more closely than others. Notably, BN4\ncomplies with the majority of the rules (7 out of 11). Conversely, several models\nfail to exhibit the expected behavior. Interestingly, higher compliance with expert\nrules does not correlate with reduced accuracy, suggesting that adherence to\nthese rules does not necessarily compromise performance.\nTo illustrate the verification capability, we analyze an example of UNSAT and\nSAT queries for the BN4 model. Fig.3 visualizes an $ITR_{M,R,\\hat{c}}$evaluation resulting\nin UNSAT (i.e., adherence to specification) where R and $\\hat{c}$are set to the values of\nrule0 from Tab.3. The query's interpretation is straightforward: the model will\nnever alter the predicted class, in this case, from Positive to Negative, given\nthe constraints of R (with permitted values shown in green).\nNext, we analyze the $ITR_{M,R,c}$ query that evaluates to SAT for M = BN4.\nThe first such query (in lexical order) corresponds to rule4 from Tab.3. Fig.3\npresents the verification query (top) along with two counterexamples (bottom)\nthat demonstrate combinations of feature values leading to the undesired predic-\ntion outcome. For instance, a partial assignment including Age = 0 (or Age = 1\nin the second counterexample), Debit = 0, and Profession = 0 results in a\nNegative outcome for the CreditWorthiness variable, thus invalidating the ex-\npected behavior."}, {"title": "", "content": "Verifying $FMO_{\\delta_{X^*},x_i}$ The process of performing $FMO_{\\delta_{X^*},x_i}$ verification\nis similar to $ITR_{M,R,C}$. Here, we provide a simplified overview of a single such\nquery in practice. For our example, we define the following:\n$\\delta_{X^*} = (X_{Worth} = 2, X_{Debit} = 0, X_{Profes.} = 1,X_{WrkHis.} = 3, X_{PaymHis.} = 3)$\n$X_i \\notin X^*.\nIn human-readable terms, this definition corresponds to a person with high\nnet worth, no debt, a medium-income profession, a stable work history, and\nan excellent payment history. This individual should receive a creditworthiness\nassessment that is monotonic with respect to their assets. Specifically, under the\ngiven partial assignment, we should never observe a situation where a person with\nAssets = Poor or Assets = Wealthy receives a CreditWorthiness = Positive\nrating, while a person with Assets = Average receives a CreditWorthiness =\nNegative rating.\nAfter running this $FMO_{\\delta_{X^*},x_i}$ query on all models used in the previous\nverification task, we obtained the following results: B0, B1, B2, B3, B6, B8, B9$\\in$\nUNSAT and B4, B5, B7 $\\in$ SAT. This result indicates that models B4, B5, and B7\ndo not adhere to the aforementioned query. For further analysis, counterexam-\nples could be presented to experts with the goal of explaining which feature\ncombinations lead to violations of this $FMO_{\\delta_{X^*},x_i}$."}, {"title": "Conclusions", "content": "In this work, we presented a SAT-based approach for verifying the adherence of\nBayesian networks to specific design specifications. We introduced two verifica-\ntion queries aimed at assessing key behavioral aspects, facilitating efficient and\neffective testing of BN models prior to deployment\u2014especially critical in safety-\ncritical and high-stakes applications. Our method provides a practical solution\nfor conducting both quick sanity checks and comprehensive verification proce-\ndures. By demonstrating its capability to handle reasonably sized BNs within a\nfeasible timeframe, we established the viability of integrating our approach into\na comprehensive testing suite. To underscore the real-world applicability of our\nframework, we showcased a case study illustrating its effectiveness in identifying\npotential errors within a real-world BN model.\nIn future work, we aim to extend our approach to multi-class and multi-\nlabel BN classifiers, thereby broadening its applicability across various domains.\nAdditionally, we plan to develop a model refinement framework that incorpo-\nrates verification results, enabling retraining of models while accounting for the\nidentified counterexamples."}, {"title": "Acknowledgments", "content": "This work was partially supported by DARPA (award HR00112420329), U.S.\nArmy (award W911NF-20-D0002), and by a Space Technology Research Insti-\ntutes grant from NASA's Space Technology Research Grants Program."}]}