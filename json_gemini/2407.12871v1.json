{"title": "METATOOL: FACILITATING LARGE LANGUAGE MODELS TO MASTER TOOLS WITH META-TASK AUGMENTATION", "authors": ["Xiaohan Wang", "Dian Li", "Yilin Zhao", "Sinbadliu", "Hui Wang"], "abstract": "Utilizing complex tools with Large Language Models (LLMs) is a critical component for grounding AI agents in various real-world scenarios. The core challenge of manipulating tools lies in understanding their usage and functionality. The prevailing approach involves few-shot prompting with demonstrations or fine-tuning on expert trajectories. However, for complex tools and tasks, mere in-context demonstrations may fail to cover sufficient knowledge. Training-based methods are also constrained by the high cost of dataset construction and limited generalizability. In this paper, we introduce a new tool learning methodology (MetaTool) that is generalizable for mastering any reusable toolset. Our approach includes a self-supervised data augmentation technique that enables LLMs to gain a comprehensive understanding of various tools, thereby improving their ability to complete tasks effectively. We develop a series of meta-tasks that involve predicting masked factors of tool execution. These self-supervised tasks enable the automatic generation of high-quality QA data concerning tool comprehension. By incorporating meta-task data into the instruction tuning process, the proposed MetaTool model achieves significant superiority to open-source models and is comparable to GPT-4/GPT-3.5 on multiple tool-oriented tasks.", "sections": [{"title": "1 INTRODUCTION", "content": "Distinguished from other species, a critical characteristic of human beings' advanced intelligence is the use of complex tools, which expands the frontiers neural intelligence can reach. With the advent of powerful foundation models (e.g. large language models, multi-modal models), AI has the potential to solve complex tasks as a general agent, equipped with the abilities to make long-term plans, use external tools, reflect on its own behavior, etc. Using tools crucially endows LLMs the power from external mechanisms and to exert effect on a larger scale.\nExisting tool learning research majorly falls into two paradigms: tool-augmented learning and tool-oriented learning Qin et al. (2023b). The former aims at augmenting the model with complementary resources (e.g. retriever, search engine), and the latter focuses on achieving certain task objectives with tools (e.g. web navigationRawles et al. (2023); Hong et al. (2024), embodied manipulationChi et al. (2023)). While augmenting LLMs with tools requires appropriate tool selection, tool-oriented tasks raise more challenges in tool manipulation given that the orientation is tool output and state change. This work focuses on learning tool manipulation in the tool-oriented paradigm with large language models.\nTo utilize tools with LLMs, a mainstream way is to provide the \"cookbook\" of tools with zero-shot prompting or demonstrations of tool usage with few-shot promptingXu et al. (2023); Brown et al. (2020). It may work on simple tool sets, however, for complex tools like software or machines, demonstrations can not exhaust all scenarios, and manuals are also limited in length. Ultimately, it's impractical to expect a system to be intelligent enough to master any tool without experience of"}, {"title": "2 RELATED WORKS", "content": "Recent studies have shed light on the potential of utilizing tools to augment LLMs with external factual knowledge Qin et al. (2023a); Nakano et al. (2021); Song et al. (2023); Hao et al. (2024); Shen et al. (2024); Gao et al. (2023); Wu et al. (2023); Qian et al. (2023); Zhuang et al. (2024); Schick et al. (2024) and complete tasks in complex environments Gupta & Kembhavi (2023). With"}, {"title": "2.1 TOOL LEARNING", "content": "the burgeoning intelligence in reasoning and perception, LLMs' tool-use capability can be widely applied in the automation of various domains including Embodied AI Wang et al. (2024c;b), web manipulation Rawles et al. (2023); Hong et al. (2024); Yang et al. (2023); Deng et al. (2024); He et al. (2024); Zhou et al. (2023), and image/video editing Wang et al. (2024a); Argaw et al. (2022); Hang et al. (2024); Fu et al. (2023). Effectively mastering complex tools challenges the model to comprehend the precondition and potential outcome of using tools. In this paper, we aim to facilitate LLMs for tool-oriented tasks by learning robust tool understanding."}, {"title": "2.2 TOOL UNDERSTANDING", "content": "As noted by Hernik & Csibra (2009), when learning to utilize a specific tool, children perceive it as an object with particular functions, engaging in a cognitive process to understand its purpose and operation. Analogously, a comprehensive understanding of the tools' functionalities is indispensable for enabling the controller to use tools proficiently. In real-world scenarios, tools are typically accompanied by a manual (or tutorial), which provides sufficient relevant details about their func- tionalities and usage. Endowed with strong few-shot learning Brown et al. (2020) and zero-shot learning Wei et al. (2021) capabilities, foundation models can be prompted to unravel tools' func- tionalities and comprehend how to use them. To this end, we can construct suitable task-specific prompts either through manual design Vemprala et al. (2024) or retrieval Zhou et al. (2022). However, prompting is restricted by input context length, thus the situation may be more challenging with multiple complex tools with long descriptions. While most training-based tool learning methods rely on extensive expert-annotated solution data for goal-oriented tasks, the knowledge contained in the tool execution process itself remains unutilized. We propose a self-supervised data augmentation method to efficiently endow LLMs the comprehension of a set of tools."}, {"title": "3 METHOD", "content": "In this section, we first formalize the tool-oriented task with a close toolset. Then we define five general meta-tasks that are key to tool understanding and show how to generate datasets of them in an integral self-supervised way. In the end, we describe several training schemes to augment the tool-oriented training with meta-tasks data."}, {"title": "3.1 PROBLEM FORMALIZATION", "content": "A tool task can be defined as a tuple $(S, A, T, g)$, where $S, A, T$ is the state space, action space, and toolset, and $g$ is the goal state of the task. Toolset $T = \\{t\\}_{N}$ consists of $N$ tools, each as a state transition function $s' = t(s, \\theta)$ that formalizes the outcome of state change when feeding the input parameters $\\theta$ into the tool. An action $a = (t, \\theta) \\in A$ specifies the tool and its input. As an autonomous agent, an LLM should iteratively respond with actions and inputs according to the state until it reaches the goal. Broadly, when the tools can not alter any external state, tool output like retrieval results can be regarded as the state thus the goal state is the desired information."}, {"title": "3.2 SELF-SUPERVISED META-TASKS FOR TOOL UNDERSTANDING", "content": "We enhance the tool understanding of the model with self-supervised surrogate (pretext) tasks in- stead of in-context descriptions or demonstrations. Formally, we regard tools as external systems that implement state transition mappings. Tool understanding, therefore, involves comprehending the perception-action process of these systems (referred to as tool execution) and should be general- izable to various task objectives.\nMeta-task definition. We first generate single-step tool execution data $D = \\{s, a, s'\\}$ by stochas- tically sampling initial state $s \\in S$ and action $a \\in A$, and obtaining the tool output $s'$. Five surrogate tasks (meta-tasks) are designed based on the unsupervised dataset $D$. Basically, the model is required to predict masked factors of the execution process in line with the idea of Masked Au- toencoder (MAE) He et al. (2022). We define the meta-tasks as below:\n\u2022 Effect: The model predicts the outcome state $P(s'|a, s)$ given the initial state and the action."}, {"title": "3.3 \u039c\u0395\u03a4\u0391-TASK AUGMENTATION", "content": "With the data of meta-tasks, we explore several manners to augment the tool manipulation ability to achieve task goals: 1) In-context learning: To enhance the tool understanding of LLMs in a training-free way, we incorporate several demonstrations of each meta-tasks in the system prompt. Existing works may include demonstrations in the tool cookbook, yet not in a systematic way. 2) Self-supervised Learning: Since we aim to build the model's tool understanding as the foundation of tool-oriented learning, an intuitive manner is to train the LLM first on the metasets as the surrogate"}, {"title": "4 EXPERIMENTS", "content": "To evaluate LLMs' ability on tool-oriented tasks, we develop 3 tasks emphasizing closed toolset manipulation rather than long-term planning and reflection which are also crucial abilities for AI agents. The key challenge of these tasks is effectively utilizing tools to achieve the goal, which requires the model to understand the rules (preconditions) and the mechanisms of the toolset. The task definition and dataset construction are elaborated below."}, {"title": "4.1 TASK SETUP", "content": "SpellAnyWord (SAW). In this task, the agent needs to sequentially construct a string that contains the target string as a continuous substring. The initial state of the task is a void string. Two non- degradable tools (functions) are avaliable: Add: to add two adjacent letters in the alphabet to the end of the current string. The tool input $\\theta$ should be the preceding letter (e.g. passing 'a' to Add on current string\" will result in 'ab'). Swap: to swap the position of two adjacent letters in the current string. The input should be the preceding letter (e.g. passing 'a' to Swap on 'ab' will result in 'ba'). An example task: The target string is 'any'. A successful action sequence can be [Add('a'), Add('n'), Add('y'), Swap('a'), Add('o')], which will result in a state sequence ['ab', 'abno', 'abnoyz', 'banoyz', 'banyoz'] and the final string 'banyoz' has 'any' as a substring.\nBlocks Wolrd (BW). In this scenario, the agent needs to stack several blocks on the table into a target state with one hand. Only one block can be moved at a time. Two tools (functions) are avaliable: Pick: to pick a block in the hand. The tool input should be the target block indicated by its color (e.g. Pick('yellow')). Blocks cannot be picked if there are blocks on top of them or there's already a block in the hand. Stack: to stack the block in the hand onto the target block or table. The input should be the color of the target block or 'table' (e.g. Stack('white'), Stack('table')). Blocks cannot be stacked on a block with another block already on top of it or there's no block in the hand.\nLogistics (LOG). The agent needs to solve a logistics problem by arranging trucks and airplanes to transport the package to the target location. Locations are grouped by cities. Trucks can be used to move packages between locations in the same city and planes can be used to move packages between cities. Two tools (functions) are available: Truck: to transport the truck and the package (if there is any) from one location to another. Plane: to transport the airplane and the package (if there is any) from one location to another. The tool input should be the starting and ending location indicated by numbers. (e.g. Truck(1,2), Plane(2,4)). An action is invalid when there is no truck or airplane at the starting location."}, {"title": "4.2 IMPLEMENTATION DETAILS", "content": "Our model is fine-tuned based on LLaMA3-8b-instruct AI@Meta (2024) with parameter-efficient fine-tuning method Qlora Dettmers et al. (2024) on 8 A100 GPUs. We utilize the instruction tuning version of LLaMA3 since comprehending tool-oriented tasks with specific objectives is the basis of tool understanding and manipulation. For tool-oriented task training, we construct instruction- solution pairs from the task goals and annotated solutions. For meta-task training, we formulate the"}, {"title": "4.3 RESULTS ANALYSIS", "content": "Overall comparison. We evaluate the success rate (SR%) of completing each task and show the performances of several models in Table 1. Overall, SOTA closed-source LLMs show impressive zero-shot performance on tool-oriented tasks compared with open-source LLMs including LLaMA3 and Vicuna. By training on both meta-tasks and solution data, our model MetaTool gains signifi- cant improvement (+22.7%SR on average) compared with LLaMA3 (baseline) and surpasses GPT- 4/GPT-3.5-turbo in the SAW/BW tasks (+3.5%/11.0%SR). Both GPT and LLaMA3 show weaker performances when provided with meta-task demonstrations (IC) since demonstrating limited cases can be redundant or misleading without proper design. LLaMA3-SS that trained on meta-tasks first gains limited improvement compared with the baseline. We conjecture that learning meta-tasks with- out practicing tool manipulation (training on action sequences) cannot effectively facilitate tool-use ability with tool understanding. Also fine-tuning with specific QA data may affect the basic linguis- tic ability of the model.\nAblation study. We study the ablation of different data components and report the performances in Table 2. Merely training on solution data improves the model performance to an extent compared with the baseline LLaMA3 (+8.5% on average). It's worth noticing that only training on meta-tasks can improve the model's zero-shot performance on tool-oriented tasks (line 2), contrary to providing demonstrations of meta-tasks in the system prompt (LLaMA3-IC in Table 1). When removing QA data from each meta-task, the model performance shows varying degrees of degradation, which ver- ifies the profits of meta-tasks. The meta-tasks of effect and decision-making have a relatively greater influence on the model's tool understanding capability. Theoretically, these meta-tasks represent the causal mechanism of tools, which is the basis of high-level understanding or skills."}, {"title": "5 CONCLUSION AND FUTURE DISCUSSION", "content": "In this work, we show that tool understanding can be disentangled from other agentic capabilities such as planning and decision-making that facilitate the tool-use tasks. While multiple abilities have emerged in prior open-source LLMs, comprehending tools as external mechanisms and functions is the foundation of tool usage and remains insufficient. We propose the MetaTool method to train an LLM with self-supervised surrogate tasks concerning the functionality and causality of tools. Our model archives 22.7% SR improvement on average on three tool-oriented tasks and showcases effective tool manipulation ability.\nDespite the availability of some tool learning methods, the gap between open-source large language models and SOTA closed-source models remains unignorable. One potential way to close that gap is to improve LLMs' zero/few-shot tool understanding capability that can effectively conjecture the tool usage and functionality from the prompts. Another future direction for learning complex tools is to improve data efficiency so that the model can be trained to master certain downstream tasks with minimum effort. Generally, we propose MetaTool as a methodology to pave the way for future tool-use research."}]}