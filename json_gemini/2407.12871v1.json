{"title": "METATOOL: FACILITATING LARGE LANGUAGE MODELS TO MASTER TOOLS WITH META-TASK AUGMENTATION", "authors": ["Xiaohan Wang", "Dian Li", "Yilin Zhao", "Sinbadliu", "Hui Wang"], "abstract": "Utilizing complex tools with Large Language Models (LLMs) is a crit-ical component for grounding AI agents in various real-world scenar-ios. The core challenge of manipulating tools lies in understanding their usage and functionality. The prevailing approach involves few-shot prompting with demonstrations or fine-tuning on expert trajectories. However, for complex tools and tasks, mere in-context demonstrations may fail to cover sufficient knowledge. Training-based methods are also constrained by the high cost of dataset construction and limited gener-alizability. In this paper, we introduce a new tool learning methodology (MetaTool) that is generalizable for mastering any reusable toolset. Our approach includes a self-supervised data augmentation technique that enables LLMs to gain a comprehensive understanding of various tools, thereby improving their ability to complete tasks effectively. We de-velop a series of meta-tasks that involve predicting masked factors of tool execution. These self-supervised tasks enable the automatic gener-ation of high-quality QA data concerning tool comprehension. By incor-porating meta-task data into the instruction tuning process, the proposed MetaTool model achieves significant superiority to open-source models and is comparable to GPT-4/GPT-3.5 on multiple tool-oriented tasks.", "sections": [{"title": "INTRODUCTION", "content": "Distinguished from other species, a critical characteristic of human beings' advanced intelligence is the use of complex tools, which expands the frontiers neural intelligence can reach. With the advent of powerful foundation models (e.g. large language models, multi-modal models), AI has the potential to solve complex tasks as a general agent, equipped with the abilities to make long-term plans, use external tools, reflect on its own behavior, etc. Using tools crucially endows LLMs the power from external mechanisms and to exert effect on a larger scale.\nExisting tool learning research majorly falls into two paradigms: tool-augmented learning and tool-oriented learning Qin et al. (2023b). The former aims at augmenting the model with complementary resources (e.g. retriever, search engine), and the latter focuses on achieving certain task objectives with tools (e.g. web navigationRawles et al. (2023); Hong et al. (2024), embodied manipulationChi et al. (2023)). While augmenting LLMs with tools requires appropriate tool selection, tool-oriented tasks raise more challenges in tool manipulation given that the orientation is tool output and state change. This work focuses on learning tool manipulation in the tool-oriented paradigm with large language models.\nTo utilize tools with LLMs, a mainstream way is to provide the \"cookbook\" of tools with zero-shot prompting or demonstrations of tool usage with few-shot promptingXu et al. (2023); Brown et al. (2020). It may work on simple tool sets, however, for complex tools like software or machines, demonstrations can not exhaust all scenarios, and manuals are also limited in length. Ultimately, it's impractical to expect a system to be intelligent enough to master any tool without experience of using it. Besides, prior training-based methods mainly adopt supervised fine-tuning with annotated solutions on the basis of pre-trained LLMs Qin et al. (2023c); Patil et al. (2023). Regardless of the difficulties of annotating the optimal actions for complex tasks, training on a limited amount of data is prone to overfitting action patterns. Without truly understanding the dynamics of tool execution, it's hard to generalize to diverse task scenarios through flexible tool manipulation. For instance in Figure 1, understanding the usage or functionality of hammers (e.g. nailing, smashing) enables the robot to build a cabin better and generalize the skills to chair or table construction.\nTowards the issues above, our insight is that generalizable tool manipulation should be achieved on the foundation of comprehensive tool understanding, which is learnable with a practical amount of data. In this paper, we propose a data augmentation method (MetaTool) that enhances LLM's understanding of an external toolset and boosts the learning of tool-oriented tasks. Given a callable toolset (e.g. APIs, programs), a meta-set consisting of question-answering data of 6 meta-tasks is constructed by calling the tools in a self-supervised way. The meta-tasks are designed concerning the causality of the toolset as an autonomous system and its functionality as a function. Then we augment the solution data of tool-oriented tasks with the meta-set to fine-tune the pre-trained LLM. Evaluated on three tool-oriented tasks, our method significantly improves the success rate (+22.7%) of the open-source LLM (e.g. LLaMA-3) and is competitive with GPT-4/3.5-turbo. Moreover, we also explore the mechanism of enhancing tool manipulation capability with meta-task data. The overall contribution can be summarized in three-folds:\n\u2022 We introduce a new tool learning paradigm that facilitates the task performance of LLMs with task-agnostic tool understanding.\n\u2022 We propose an integral set of self-supervised tasks that dissect the tool execution process and enable efficient data generation and augmentation.\n\u2022 Extensive evaluation on tool-oriented tasks verifies that MetaTool significantly enhances open-source LLMs compared with conventional instruction tuning methods."}, {"title": "RELATED WORKS", "content": "Recent studies have shed light on the potential of utilizing tools to augment LLMs with external factual knowledge Qin et al. (2023a); Nakano et al. (2021); Song et al. (2023); Hao et al. (2024); Shen et al. (2024); Gao et al. (2023); Wu et al. (2023); Qian et al. (2023); Zhuang et al. (2024); Schick et al. (2024) and complete tasks in complex environments Gupta & Kembhavi (2023). With the burgeoning intelligence in reasoning and perception, LLMs' tool-use capability can be widely applied in the automation of various domains including Embodied AI Wang et al. (2024c;b), web manipulation Rawles et al. (2023); Hong et al. (2024); Yang et al. (2023); Deng et al. (2024); He et al. (2024); Zhou et al. (2023), and image/video editing Wang et al. (2024a); Argaw et al. (2022); Hang et al. (2024); Fu et al. (2023). Effectively mastering complex tools challenges the model to comprehend the precondition and potential outcome of using tools. In this paper, we aim to facilitate LLMs for tool-oriented tasks by learning robust tool understanding."}, {"title": "TOOL UNDERSTANDING", "content": "As noted by Hernik & Csibra (2009), when learning to utilize a specific tool, children perceive it as an object with particular functions, engaging in a cognitive process to understand its purpose and operation. Analogously, a comprehensive understanding of the tools' functionalities is indispens-able for enabling the controller to use tools proficiently. In real-world scenarios, tools are typically accompanied by a manual (or tutorial), which provides sufficient relevant details about their func-tionalities and usage. Endowed with strong few-shot learning Brown et al. (2020) and zero-shot learning Wei et al. (2021) capabilities, foundation models can be prompted to unravel tools' func-tionalities and comprehend how to use them. To this end, we can construct suitable task-specific prompts either through manual design Vemprala et al. (2024) or retrieval Zhou et al. (2022). How-ever, prompting is restricted by input context length, thus the situation may be more challenging with multiple complex tools with long descriptions. While most training-based tool learning methods rely on extensive expert-annotated solution data for goal-oriented tasks, the knowledge contained in the tool execution process itself remains unutilized. We propose a self-supervised data augmentation method to efficiently endow LLMs the comprehension of a set of tools."}, {"title": "METHOD", "content": "In this section, we first formalize the tool-oriented task with a close toolset. Then we define five general meta-tasks that are key to tool understanding and show how to generate datasets of them in an integral self-supervised way. In the end, we describe several training schemes to augment the tool-oriented training with meta-tasks data."}, {"title": "PROBLEM FORMALIZATION", "content": "A tool task can be defined as a tuple $(S, A, T, g)$, where $S, A, T$ is the state space, action space, and toolset, and $g$ is the goal state of the task. Toolset $T = \\{t\\}_N$ consists of $N$ tools, each as a state transition function $s' = t(s, \\theta)$ that formalizes the outcome of state change when feeding the input parameters $\\theta$ into the tool. An action $a = (t, \\theta) \\in A$ specifies the tool and its input. As an autonomous agent, an LLM should iteratively respond with actions and inputs according to the state until it reaches the goal. Broadly, when the tools can not alter any external state, tool output like retrieval results can be regarded as the state thus the goal state is the desired information."}, {"title": "SELF-SUPERVISED META-TASKS FOR TOOL UNDERSTANDING", "content": "We enhance the tool understanding of the model with self-supervised surrogate (pretext) tasks in-stead of in-context descriptions or demonstrations. Formally, we regard tools as external systems that implement state transition mappings. Tool understanding, therefore, involves comprehending the perception-action process of these systems (referred to as tool execution) and should be general-izable to various task objectives.\nMeta-task definition. We first generate single-step tool execution data $D = \\{s, a, s'\\}$ by stochas-tically sampling initial state $s \\in S$ and action $a \\in A$, and obtaining the tool output $s'$. Five surrogate tasks (meta-tasks) are designed based on the unsupervised dataset $D$. Basically, the model is required to predict masked factors of the execution process in line with the idea of Masked Au-toencoder (MAE) He et al. (2022). We define the meta-tasks as below:\n\u2022 Effect: The model predicts the outcome state $P(s'|a, s)$ given the initial state and the action.\n\u2022 Decision-making: The model decides a feasible action $P(a|s, s')$ given the initial and outcome state.\n\u2022 Reversion: The model deduces the initial state $P(s|a, s')$ given the action and the outcome state.\n\u2022 Input Boundary: The model determines whether an action can be successfully executed given the current state: $P(1_{s' \\neq s} |a, s)$.\n\u2022 Output Boundary: The model determines whether a state can be reached with any action given the current state: $P(1_{\\exists (t, \\theta), s'=t(s, \\theta)} |s, s')$.\n\u2022 Counterfact: The model predicts the new outcome state $P(s''|a, s', a')$ if a new action $a'$ were executed given that the current action $a$ results in the current outcome $s'$.\nEffect, decision-making, reversion meta-tasks emphasize the causality of a tool, regarding the action as the intervention to the state Pearl (2009); Pearl & Mackenzie (2018) and the outcome as the causal effect is determined by the tool mechanism. On top of that, counterfact task is the composition of reversion and effect, further imagining the outcome altered from the fact in effect task and raising higher requirements for causal reasoning Bareinboim et al. (2015); Zhang & Bareinboim (2016). When implemented as APIs, tools may receive non-executable inputs and result in ineffective out-comes. Thus the input and output domains are also unique features of a tool as a function. We consider Input boundary meta-task that emphasizes the tool affordance that refers to what actions can be executed considering the situation and the precondition. Output boundary meta-task em-phasizes the functionality of tools, that is, what goals can and cannot be achieved given the current state.\nMetaset construction. Based on the single-step data $D$, datasets of meta-tasks (referred to as metasets) are constructed by automatically generating question-answering pairs, showcased in Fig-ure 2. For each sample and each meta-task, we insert the variables of states and actions into 5 templates (diversified with GPT-4) to obtain diverse QA data."}, {"title": "\u039c\u0395\u03a4\u0391-TASK AUGMENTATION", "content": "With the data of meta-tasks, we explore several manners to augment the tool manipulation ability to achieve task goals: 1) In-context learning: To enhance the tool understanding of LLMs in a training-free way, we incorporate several demonstrations of each meta-tasks in the system prompt. Existing works may include demonstrations in the tool cookbook, yet not in a systematic way. 2) Self-supervised Learning: Since we aim to build the model's tool understanding as the foundation of tool-oriented learning, an intuitive manner is to train the LLM first on the metasets as the surrogate tasks and then on the solution data of tool-oriented tasks. In order to maintain the general ability of the model in the first stage, only the parameters of the query and value projection layers of the Transformer are updated instead of full-parameter training. We also propose to train the model on metasets separately to build the tool-use ability step by step. 3) Data augmentation: We also utilize the metasets as the augmented data of conventional instruction tuning methods that the metasets are mixed with solution data and the model is trained uniformly. The model trained on the mixed data is referred to as MetaTool."}, {"title": "EXPERIMENTS", "content": "To evaluate LLMs' ability on tool-oriented tasks, we develop 3 tasks emphasizing closed toolset manipulation rather than long-term planning and reflection which are also crucial abilities for AI agents. The key challenge of these tasks is effectively utilizing tools to achieve the goal, which requires the model to understand the rules (preconditions) and the mechanisms of the toolset. The task definition and dataset construction are elaborated below.\nSpellAnyWord (SAW). In this task, the agent needs to sequentially construct a string that contains the target string as a continuous substring. The initial state of the task is a void string. Two non-degradable tools (functions) are avaliable: Add: to add two adjacent letters in the alphabet to the end of the current string. The tool input $\\theta$ should be the preceding letter (e.g. passing 'a' to Add on current string\" will result in 'ab'). Swap: to swap the position of two adjacent letters in the current string. The input should be the preceding letter (e.g. passing 'a' to Swap on 'ab' will result in 'ba'). An example task: The target string is 'any'. A successful action sequence can be [Add('a'), Add('n'), Add('y'), Swap('a'), Add('o')], which will result in a state sequence ['ab', 'abno', 'abnoyz', 'banoyz', 'banyoz'] and the final string 'banyoz' has 'any' as a substring.\nBlocks Wolrd (BW). In this scenario, the agent needs to stack several blocks on the table into a target state with one hand. Only one block can be moved at a time. Two tools (functions) are avaliable: Pick: to pick a block in the hand. The tool input should be the target block indicated by its color (e.g. Pick('yellow')). Blocks cannot be picked if there are blocks on top of them or there's already a block in the hand. Stack: to stack the block in the hand onto the target block or table. The input should be the color of the target block or 'table' (e.g. Stack('white'), Stack('table')). Blocks cannot be stacked on a block with another block already on top of it or there's no block in the hand.\nLogistics (LOG). The agent needs to solve a logistics problem by arranging trucks and airplanes to transport the package to the target location. Locations are grouped by cities. Trucks can be used to move packages between locations in the same city and planes can be used to move packages between cities. Two tools (functions) are available: Truck: to transport the truck and the package (if there is any) from one location to another. Plane: to transport the airplane and the package (if there is any) from one location to another. The tool input should be the starting and ending location indicated by numbers. (e.g. Truck(1,2), Plane(2,4)). An action is invalid when there is no truck or airplane at the starting location.\nDatasets collection. For the SAW task, we randomly sample 2k target strings (from 2 letters to 10 letters) as task goals. We modify the BW and LOG tasks from the prior LLM benchmark Valmeekam et al. (2024) into the tool-use version, thus 2k goals for each task are adopted following the original configuration. Optimal action sequences are obtained with heuristic strategy as the solution data. For each annotated action, we generate a thought with one of 5 templates (diversified with GPT-4). The thoughts analyze the situation and what to do following ReACT Yao et al. (2022) to leverage the model's reasoning ability. Thus the solution contains a sequence of thought-tool-input tuples. Besides the 3 tasks we define, MetaTool can be easily generalized to other tool-oriented tasks by writing the system prompt and developing the tool functions or APIs as the external environment. The meta-task data can then be generated automatically."}, {"title": "IMPLEMENTATION DETAILS", "content": "Our model is fine-tuned based on LLaMA3-8b-instruct AI@Meta (2024) with parameter-efficient fine-tuning method Qlora Dettmers et al. (2024) on 8 A100 GPUs. We utilize the instruction tuning version of LLaMA3 since comprehending tool-oriented tasks with specific objectives is the basis of tool understanding and manipulation. For tool-oriented task training, we construct instruction-solution pairs from the task goals and annotated solutions. For meta-task training, we formulate the task objectives and the tool execution outcome as question-answering pairs. For each task, we train the model on 10k meta-task data and 10k solution data for 3 epochs with AdamW optimizer and the learning rate of 2e-4. The models are tested in a simulated environment that receives the action of using a tool and returns the outcome and current state. We evaluated the model performance on 100 unseen cases of each three tasks."}, {"title": "RESULTS ANALYSIS", "content": "Overall comparison. We evaluate the success rate (SR%) of completing each task and show the performances of several models in Table 1. Overall, SOTA closed-source LLMs show impressive zero-shot performance on tool-oriented tasks compared with open-source LLMs including LLaMA3 and Vicuna. By training on both meta-tasks and solution data, our model MetaTool gains signifi-cant improvement (+22.7%SR on average) compared with LLaMA3 (baseline) and surpasses GPT-4/GPT-3.5-turbo in the SAW/BW tasks (+3.5%/11.0%SR). Both GPT and LLaMA3 show weaker performances when provided with meta-task demonstrations (IC) since demonstrating limited cases can be redundant or misleading without proper design. LLaMA3-SS that trained on meta-tasks first gains limited improvement compared with the baseline. We conjecture that learning meta-tasks with-out practicing tool manipulation (training on action sequences) cannot effectively facilitate tool-use ability with tool understanding. Also fine-tuning with specific QA data may affect the basic linguis-tic ability of the model.\nAblation study. We study the ablation of different data components and report the performances in Table 2. Merely training on solution data improves the model performance to an extent compared with the baseline LLaMA3 (+8.5% on average). It's worth noticing that only training on meta-tasks can improve the model's zero-shot performance on tool-oriented tasks (line 2), contrary to providing demonstrations of meta-tasks in the system prompt (LLaMA3-IC in Table 1). When removing QA data from each meta-task, the model performance shows varying degrees of degradation, which ver-ifies the profits of meta-tasks. The meta-tasks of effect and decision-making have a relatively greater influence on the model's tool understanding capability. Theoretically, these meta-tasks represent the causal mechanism of tools, which is the basis of high-level understanding or skills."}, {"title": "CONCLUSION AND FUTURE DISCUSSION", "content": "In this work, we show that tool understanding can be disentangled from other agentic capabilities such as planning and decision-making that facilitate the tool-use tasks. While multiple abilities have emerged in prior open-source LLMs, comprehending tools as external mechanisms and functions is the foundation of tool usage and remains insufficient. We propose the MetaTool method to train an LLM with self-supervised surrogate tasks concerning the functionality and causality of tools. Our model archives 22.7% SR improvement on average on three tool-oriented tasks and showcases effective tool manipulation ability.\nDespite the availability of some tool learning methods, the gap between open-source large language models and SOTA closed-source models remains unignorable. One potential way to close that gap is to improve LLMs' zero/few-shot tool understanding capability that can effectively conjecture the tool usage and functionality from the prompts. Another future direction for learning complex tools is to improve data efficiency so that the model can be trained to master certain downstream tasks with minimum effort. Generally, we propose MetaTool as a methodology to pave the way for future tool-use research."}]}